<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.SD](#cs.SD) [Total: 8]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Demonstrating Superresolution in Radar Range Estimation Using a Denoising Autoencoder](https://arxiv.org/abs/2506.14906)
*Robert Czupryniak,Abhishek Chakraborty,Andrew N. Jordan,John C. Howell*

Main category: eess.SP

TL;DR: 论文利用机器学习方法实现雷达遥感中的超分辨率测距，通过降噪自编码器优化亚波长散射体间距估计，并验证了信号设计对性能的关键影响。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决传统雷达在亚波长范围内测距精度不足的问题，探索机器学习在超分辨率测距中的应用潜力。

Method: 采用降噪自编码器，训练数据为带限约束下的波形，优化远小于带限逆的间距精度。分析了三种脉冲信号（sinc、三角波、Bessel）的性能。

Result: 自编码器实现有效降维，瓶颈层输出与真实间距强相关。Bessel信号表现最佳，三角波次之，sinc最差。

Conclusion: 信号设计对机器学习超分辨率测距至关重要，Bessel信号为最优选择。

Abstract: We apply machine learning methods to demonstrate range superresolution in remote sensing radar detection. Specifically, we implement a denoising autoencoder to estimate the distance between two equal intensity scatterers in the subwavelength regime. The machine learning models are trained on waveforms subject to a bandlimit constraint such that ranges much smaller than the inverse bandlimit are optimized in their precision. The autoencoder achieves effective dimensionality reduction, with the bottleneck layer exhibiting a strong and consistent correlation with the true scatterer separation. We confirm reproducibility across different training sessions and network initializations by analyzing the scaled encoder outputs and their robustness to noise. We investigate the behavior of the bottleneck layer for the following types of pulses: a traditional sinc pulse, a bandlimited triangle-type pulse, and a theoretically near-optimal pulse created from a spherical Bessel function basis. The Bessel signal performs best, followed by the triangle wave, with the sinc signal performing worst, highlighting the crucial role of signal design in the success of machine-learning-based range resolution.

</details>


### [2] [Metasurfaces-Integrated Doubly-Dispersive MIMO: Channel Modeling and Optimization](https://arxiv.org/abs/2506.14985)
*Kuranage Roche Rayan Ranasinghe,Hyeon Seok Rou,Iván Alexander Morales Sandoval,Giuseppe Thadeu Freitas de Abreu,George C. Alexandropoulos*

Main category: eess.SP

TL;DR: 提出了一种新型的MPDD信道模型，用于MIMO系统中RIS和SIM的集成，并探讨了其在DD环境中的波形优化应用。


<details>
  <summary>Details</summary>
Motivation: 扩展DD框架到MIMO系统，尤其是在RIS和SIM增强的环境中，解决现有挑战。

Method: 引入MPDD信道模型，集成RIS和SIM，并应用于OFDM、OTFS和AFDM等波形。

Result: 模型展示了在SIM辅助无线系统中增强波形性能的潜力。

Conclusion: MPDD模型为动态环境中的无线通信提供了灵活且可编程的解决方案。

Abstract: The doubly-dispersive (DD) channel structure has played a pivotal role in wireless communications, particularly in high-mobility scenarios and integrated sensing and communications (ISAC), due to its ability to capture the key fading effects experienced by a transmitted signal as it propagates through a dynamic medium. However, extending the DD framework to multiple-input multiple-output (MIMO) systems, especially in environments artificially enhanced by reconfigurable intelligent surfaces (RISs) and stacked intelligent metasurfaces (SIM), remains a challenging open problem. In this chapter, a novel metasurfaces-parametrized DD (MPDD) channel model that integrates an arbitrary number of RISs, while also incorporating SIM at both the transmitter and receiver is introduced. Next, the application of this model to some key waveforms optimized for DD environments -- namely orthogonal frequency division multiplexing (OFDM), orthogonal time frequency space (OTFS), and affine frequency division multiplexing (AFDM) -- is discussed. Finally, the programmability of the proposed model is highlighted through an illustrative application, demonstrating its potential for enhancing waveform performance in SIM-assisted wireless systems.

</details>


### [3] [Secure Time-Modulated Intelligent Reflecting Surface via Generative Flow Networks](https://arxiv.org/abs/2506.14992)
*Zhihao Tao,Athina P. Petropulu*

Main category: eess.SP

TL;DR: 提出了一种基于生成AI的TM-IRS参数设计方法，用于多用户OFDM系统的定向调制，通过GFlowNets高效学习参数配置，显著提升系统安全性。


<details>
  <summary>Details</summary>
Motivation: 现有TM-IRS设计方法仅适用于单用户场景，无法满足多用户需求，需开发更高效的方法。

Method: 使用生成AI和GFlowNets建模TM-IRS参数选择为MDP，以最大化授权方向的总速率。

Result: 实验表明，该方法显著提升多用户OFDM系统的安全性，且GFlowNets在极少训练样本下高效收敛。

Conclusion: 提出的方法在多用户场景下高效且安全，代码开源以促进可复现性。

Abstract: We propose a novel directional modulation (DM) design for OFDM transmitters aided by a time-modulated intelligent reflecting surface (TM-IRS). The TM-IRS is configured to preserve the integrity of transmitted signals toward multiple legitimate users while scrambling the signal in all other directions. Existing TM-IRS design methods typically target a single user direction and follow predefined rule-based procedures, making them unsuitable for multi-user scenarios. Here, we propose a generative AI-based approach to design good sets of TM-IRS parameters out of a set of all possible quantized ranges of parameters. The design objective is to maximize the sum rate across the authorized directions. We model the TM-IRS parameter selection as a deterministic Markov decision process (MDP), where each terminal state corresponds to a specific configuration of TM-IRS parameters. GFlowNets are employed to learn a stochastic policy that samples TM-IRS parameter sets with probability proportional to their associated sum rate reward. Experimental results demonstrate that the proposed method effectively enhances the security of the TM-IRS-aided OFDM systems with multi-users. Also, despite the vast size of the TM-IRS configuration space, the GFlowNet is able to converge after training on fewer than 0.000001% of all possible configurations, demonstrating remarkable efficiency compared to exhaustive combinatorial search. Implementation code is available at https://github.com/ZhihaoTao/GFN4TM-RIS to facilitate reproducibility.

</details>


### [4] [Fiber Signal Denoising Algorithm using Hybrid Deep Learning Networks](https://arxiv.org/abs/2506.15125)
*Linlin Wang,Wei Wang,Dezhao Wang,Shanwen Wang*

Main category: eess.SP

TL;DR: 本文提出了一种基于混合深度学习网络（HDLNet）的信号去噪算法，用于光纤分布式声学传感（DAS）系统，并结合车辆检测与跟踪算法，实现了信号去噪与特征提取的完整处理。


<details>
  <summary>Details</summary>
Motivation: 随着光纤DAS系统在智能交通系统（ITS）中的应用需求增加，需要有效的信号处理方法以推动其普及。

Method: 采用自监督的混合深度学习网络（HDLNet），结合去噪自动编码器（DAE）和长短期记忆网络（LSTM），并引入逐行匹配算法进行车辆检测与跟踪。

Result: 在自建的高速公路隧道数据集上实验，显示HDLNet的去噪性能优于空间域DAE。

Conclusion: 提出的混合网络在信号去噪和特征提取方面表现优异，为光纤DAS系统在ITS中的应用提供了有效解决方案。

Abstract: With the applicability of optical fiber-based distributed acoustic sensing (DAS) systems, effective signal processing and analysis approaches are needed to promote its popularization in the field of intelligent transportation systems (ITS). This paper presents a signal denoising algorithm using a hybrid deep-learning network (HDLNet). Without annotated data and time-consuming labeling, this self-supervised network runs in parallel, combining an autoencoder for denoising (DAE) and a long short-term memory (LSTM) for sequential processing. Additionally, a line-by-line matching algorithm for vehicle detection and tracking is introduced, thus realizing the complete processing of fiber signal denoising and feature extraction. Experiments were carried out on a self-established real highway tunnel dataset, showing that our proposed hybrid network yields more satisfactory denoising performance than Spatial-domain DAE.

</details>


### [5] [Out-of-Band Modality Synergy Based Multi-User Beam Prediction and Proactive BS Selection with Zero Pilot Overhead](https://arxiv.org/abs/2506.15136)
*Kehui Li,Binggui Zhou,Jiajia Guo,Feifei Gao,Guanghua Yang,Shaodan Ma*

Main category: eess.SP

TL;DR: 提出了一种基于OOB模态协同（OMS）的多用户毫米波通信方案，通过视觉和位置反馈实现多基站协调，减少信令开销。


<details>
  <summary>Details</summary>
Motivation: 多基站多用户系统中，传统方法在波束跟踪和基站选择时存在高信令开销和协调延迟问题。

Method: 利用视觉和位置两种OOB模态进行用户识别和跟踪，设计BEM-GBPN网络预测波束增益和最优波束。

Result: 仿真显示，该方案在零导频开销下实现91%的最优传输速率，显著提升协调效率。

Conclusion: OMS方案有效解决了多基站系统中的波束预测和协调问题，性能优于现有方法。

Abstract: Multi-user millimeter-wave communication relies on narrow beams and dense cell deployments to ensure reliable connectivity. However, tracking optimal beams for multiple mobile users across multiple base stations (BSs) results in significant signaling overhead. Recent works have explored the capability of out-of-band (OOB) modalities in obtaining spatial characteristics of wireless channels and reducing pilot overhead in single-BS single-user/multi-user systems. However, applying OOB modalities for multi-BS selection towards dense cell deployments leads to high coordination overhead, i.e, excessive computing overhead and high latency in data exchange. How to leverage OOB modalities to eliminate pilot overhead and achieve efficient multi-BS coordination in multi-BS systems remains largely unexplored. In this paper, we propose a novel OOB modality synergy (OMS) based mobility management scheme to realize multi-user beam prediction and proactive BS selection by synergizing two OOB modalities, i.e., vision and location. Specifically, mobile users are initially identified via spatial alignment of visual sensing and location feedback, and then tracked according to the temporal correlation in image sequence. Subsequently, a binary encoding map based gain and beam prediction network (BEM-GBPN) is designed to predict beamforming gains and optimal beams for mobile users at each BS, such that a central unit can control the BSs to perform user handoff and beam switching. Simulation results indicate that the proposed OMS-based mobility management scheme enhances beam prediction and BS selection accuracy and enables users to achieve 91% transmission rates of the optimal with zero pilot overhead and significantly improve multi-BS coordination efficiency compared to existing methods.

</details>


### [6] [Probabilistic Trajectory GOSPA: A Metric for Uncertainty-Aware Multi-Object Tracking Performance Evaluation](https://arxiv.org/abs/2506.15148)
*Yuxuan Xia,Ángel F. García-Fernández,Johan Karlsson,Yu Ge,Lennart Svensson,Ting Yuan*

Main category: eess.SP

TL;DR: 本文提出了一种用于评估多目标跟踪算法的轨迹广义最优子模式分配（GOSPA）度量的泛化版本，该度量考虑了轨迹级不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有的多目标跟踪算法需要一种能够同时考虑存在不确定性和状态估计不确定性的度量方法。

Method: 通过扩展概率GOSPA度量，将其表述为多维分配问题，并证明其线性规划松弛形式也是有效的度量。

Result: 该度量保留了TGOSPA的可解释性，并能分解为直观的成本项，如定位误差、存在概率不匹配误差等。

Conclusion: 仿真研究表明，该提出的度量方法有效且实用。

Abstract: This paper presents a generalization of the trajectory general optimal sub-pattern assignment (GOSPA) metric for evaluating multi-object tracking algorithms that provide trajectory estimates with track-level uncertainties. This metric builds on the recently introduced probabilistic GOSPA metric to account for both the existence and state estimation uncertainties of individual object states. Similar to trajectory GOSPA (TGOSPA), it can be formulated as a multidimensional assignment problem, and its linear programming relaxation--also a valid metric--is computable in polynomial time. Additionally, this metric retains the interpretability of TGOSPA, and we show that its decomposition yields intuitive costs terms associated to expected localization error and existence probability mismatch error for properly detected objects, expected missed and false detection error, and track switch error. The effectiveness of the proposed metric is demonstrated through a simulation study.

</details>


### [7] [Enhancing eLoran Timing Accuracy via Machine Learning with Meteorological and Terrain Data](https://arxiv.org/abs/2506.15235)
*Taewon Kang,Seunghyeon Park,Pyo-Woong Son,Jiwon Seo*

Main category: eess.SP

TL;DR: 论文提出了一种结合加权线性回归（WLR）和各向异性广义回归神经网络（AGRNN）的WLR-AGRNN模型，用于提高eLoran/GPS时间差（TD）的估计精度，以弥补GNSS的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 全球导航卫星系统（GNSS）易受信号干扰，需要互补的定位、导航和定时（PNT）系统。eLoran作为补充方案，但其主要误差源是信号传播延迟（ASF），受地面导电性和天气条件影响。

Method: 通过时间间隔计数器测量GPS与eLoran的TD，分析其与11种气象因素的相关性。提出WLR-AGRNN模型，结合WLR和AGRNN，并引入地形高程加权气象数据。

Result: 基于四个月数据的实验表明，WLR-AGRNN模型优于现有TD估计方法，显著提高了eLoran/GPS TD的估计精度。

Conclusion: WLR-AGRNN模型有效改善了eLoran/GPS TD的估计准确性，为eLoran实现与GPS相当的定时精度提供了可能。

Abstract: The vulnerabilities of global navigation satellite systems (GNSS) to signal interference have increased the demand for complementary positioning, navigation, and timing (PNT) systems. To address this, South Korea has decided to deploy an enhanced long-range navigation (eLoran) system as a complementary PNT solution. Similar to GNSS, eLoran provides highly accurate timing information, which is essential for applications such as telecommunications, financial systems, and power distribution. However, the primary sources of error for GNSS and eLoran differ. For eLoran, the main source of error is signal propagation delay over land, known as the additional secondary factor (ASF). This delay, influenced by ground conductivity and weather conditions along the signal path, is challenging to predict and mitigate. In this paper, we measure the time difference (TD) between GPS and eLoran using a time interval counter and analyze the correlations between eLoran/GPS TD and eleven meteorological factors. Accurate estimation of eLoran/GPS TD could enable eLoran to achieve timing accuracy comparable to that of GPS. We propose two estimation models for eLoran/GPS TD and compare their performance with existing TD estimation methods. The proposed WLR-AGRNN model captures the linear relationships between meteorological factors and eLoran/GPS TD using weighted linear regression (WLR) and models nonlinear relationships between outputs from expert networks through an anisotropic general regression neural network (AGRNN). The model incorporates terrain elevation to appropriately weight meteorological data, as elevation influences signal propagation delay. Experimental results based on four months of data demonstrate that the WLR-AGRNN model outperforms other models, highlighting its effectiveness in improving eLoran/GPS TD estimation accuracy.

</details>


### [8] [Reinforcement Learning-Based Policy Optimisation For Heterogeneous Radio Access](https://arxiv.org/abs/2506.15273)
*Anup Mishra,Čedomir Stefanović,Xiuqiang Xu,Petar Popovski,Israel Leyva-Mayorga*

Main category: eess.SP

TL;DR: 论文研究了无线网络中IoT设备与宽带用户共存时的资源分配问题，提出了一种基于强化学习的访问策略，显著提升了IoT用户的延迟性能。


<details>
  <summary>Details</summary>
Motivation: 未来无线网络需要灵活高效的资源共享，特别是在IoT设备与宽带用户共存的情况下，如何优化资源分配以满足不同服务的需求。

Method: 采用无授权访问框架，结合正交RAN切片或共享访问方式，为IoT用户提出基于双Q学习的强化学习方法，优化其重复传输策略。

Result: 提出的RL策略显著改善了IoT用户的延迟性能，同时保持了宽带用户的吞吐量和能效；RAN共享在低IoT流量下更节能，而RAN切片在高流量下表现更优。

Conclusion: 研究表明，基于强化学习的资源分配策略能有效平衡IoT和宽带用户的需求，为未来无线网络设计提供了重要参考。

Abstract: Flexible and efficient wireless resource sharing across heterogeneous services is a key objective for future wireless networks. In this context, we investigate the performance of a system where latency-constrained internet-of-things (IoT) devices coexist with a broadband user. The base station adopts a grant-free access framework to manage resource allocation, either through orthogonal radio access network (RAN) slicing or by allowing shared access between services. For the IoT users, we propose a reinforcement learning (RL) approach based on double Q-Learning (QL) to optimise their repetition-based transmission strategy, allowing them to adapt to varying levels of interference and meet a predefined latency target. We evaluate the system's performance in terms of the cumulative distribution function of IoT users' latency, as well as the broadband user's throughput and energy efficiency (EE). Our results show that the proposed RL-based access policies significantly enhance the latency performance of IoT users in both RAN Slicing and RAN Sharing scenarios, while preserving desirable broadband throughput and EE. Furthermore, the proposed policies enable RAN Sharing to be energy-efficient at low IoT traffic levels, and RAN Slicing to be favourable under high IoT traffic.

</details>


### [9] [Urban RIS-Assisted HAP Networks: Performance Analysis Using Stochastic Geometry](https://arxiv.org/abs/2506.15338)
*Islam M. Tanash,Ayush Kumar Dwivedi,Taneli Riihonen*

Main category: eess.SP

TL;DR: 本文研究了基于可重构智能表面（RIS）的高空平台（HAP）网络，通过统计建模和仿真验证了系统性能的提升。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决城市环境中HAP和RIS不规则部署带来的信道统计特性问题，并提升连接性和数据卸载效率。

Method: 采用泊松点过程建模HAP和RIS的不规则分布，布尔矩形模型模拟建筑物遮挡，基于广义Beta prime分布统计信道特性。

Result: 分析得出覆盖概率和遍历容量的解析表达式，仿真显示性能显著提升，且遮挡效应有助于减少其他可见HAP的干扰。

Conclusion: 该系统可有效增强城市环境中的连接性，支持高效数据卸载。

Abstract: This paper studies a high-altitude platform (HAP) network supported by reconfigurable intelligent surfaces (RISs). The practical irregular placement of HAPs and RISs is modeled using homogeneous Poisson point processes, while buildings that cause blockages in urban areas are modeled as a Boolean scheme of rectangles. We introduce a novel approach to characterize the statistical channel based on generalized Beta prime distribution. Analytical expressions for coverage probability and ergodic capacity in an interference-limited system are derived and validated through Monte Carlo simulations. The findings show notable performance improvements and reveal the impact of various system parameters, including blockages effect which contribute in mitigating interference from the other visible HAPs. This proposed system could enhance connectivity and enable effective data offloading in urban environments.

</details>


### [10] [Effect of Signal Quantization on Performance Measures of a 1st Order One Dimensional Differential Microphone Array](https://arxiv.org/abs/2506.15463)
*Shweta Pal,Arun Kumar,Monika Agrawal*

Main category: eess.SP

TL;DR: 本文研究了信号量化对一维一阶差分麦克风阵列（DMA）性能的影响，发现量化主要影响零点深度（ND），而对波束图形状、方向性因子（DF）和前背比（FBR）影响较小。


<details>
  <summary>Details</summary>
Motivation: 量化是数据采集中的关键环节，但其对一维一阶差分麦克风阵列性能的影响尚未被研究。

Method: 通过分析量化波束形成输出的表达式，研究了量化对波束图、DF、FBR和ND的影响。

Result: 波束图形状不受量化位数影响，DF和FBR保持不变，ND随量化位数增加而改善，但随零点靠近声源方向而降低。

Conclusion: 量化主要影响ND，对DMA的其他性能指标影响较小，为实际系统设计提供了参考。

Abstract: In practical systems, recorded analog signals must be digitized for processing, introducing quantization as a critical aspect of data acquisition. While prior studies have examined quantization effects in various signal processing contexts, its impact on differential microphone arrays (DMAs), particularly in one-dimensional (1D) first-order configurations, remains unexplored. This paper investigates the influence of signal quantization on performance of first-order 1D DMAs across various beampatterns. An analytical expression for quantized beamformed output for a first-order 1D DMA has been formulated. The effect of signal quantization has been studied on array performance measures such as the Beampattern, Directivity Factor (DF), Front-to-Back Ratio (FBR), and null depth (ND). Simulation results reveal that beampattern shape remains structurally invariant across quantization bit depths, with quantization primarily affecting ND. DF and FBR remain constant with the varying number of quantization bits. Additionally, ND is shown to be frequency-independent; however, it increases with increasing quantization bit depths, enhancing interference suppression. The study also examines the effect of steering nulls across the azimuthal range, showing that ND degrades as the null moves closer to the source look direction, indicating reduced interference suppression.

</details>


### [11] [Analyzing URA Geometry for Enhanced Spatial Multiplexing and Extended Near-Field Coverage](https://arxiv.org/abs/2506.15470)
*Ahmed Hussain,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil*

Main category: eess.SP

TL;DR: 论文研究了近场波束聚焦的深度（beamdepth）及其对多用户和速率的影响，发现宽或高矩形阵列（URA）比方形阵列具有更高的和速率。


<details>
  <summary>Details</summary>
Motivation: 未来无线通信系统可能在高频段部署大型天线阵列，工作在辐射近场区域。近场波束聚焦可实现空间复用，但阵列几何形状对性能的影响尚不明确。

Method: 推导了广义均匀矩形阵列（URA）的beamdepth，定义了有效波束聚焦瑞利距离（EBRD），分析了阵列几何形状对beamdepth和EBRD的影响。

Result: 方形URA的beamdepth最窄，但宽或高URA的EBRD更大，多用户和速率是方形URA的3.5倍。

Conclusion: 宽或高URA因扩展的EBRD和更好的空间复用能力，在实际应用中优于方形URA。

Abstract: With the deployment of large antenna arrays at high frequency bands, future wireless communication systems are likely to operate in the radiative near-field. Unlike far-field beam steering, near-field beams can be focused within a spatial region of finite depth, enabling spatial multiplexing in both the angular and range dimensions. This paper derives the beamdepth for a generalized uniform rectangular array (URA) and investigates how array geometry influences the near-field beamdepth and the limits where near-field beamfocusing is achievable. To characterize the near-field boundary in terms of beamfocusing and spatial multiplexing gains, we define the effective beamfocusing Rayleigh distance (EBRD) for a generalized URA. Our analysis reveals that while a square URA achieves the narrowest beamdepth, the EBRD is maximized for a wide or tall URA. However, despite its narrow beamdepth, a square URA may experience a reduction in multiuser sum rate due to its severely constrained EBRD. Simulation results confirm that a wide or tall URA achieves a sum rate of 3.5 X more than that of a square URA, benefiting from the extended EBRD and improved spatial multiplexing capabilities.

</details>


### [12] [Near-Field SWIPT with gMIMO in the Upper Mid-Band: Opportunities, Challenges, and the Way Forward](https://arxiv.org/abs/2506.15670)
*Özlem Tugfe Demir,Mustafa Ozger,Ferdi Kara,Woong-Hee Lee,Emil Björnson*

Main category: eess.SP

TL;DR: 论文探讨了在7-24 GHz频段将SWIPT与gMIMO技术结合，利用近场传播实现高效能、高容量通信系统，支持6G网络需求。


<details>
  <summary>Details</summary>
Motivation: 研究旨在满足6G无线网络对高效能和高速通信的需求，探索近场SWIPT与gMIMO结合的潜力。

Method: 利用球形波传播和近场SWIPT，通过波束聚焦和大规模空间复用提升频谱效率，并讨论信道估计、预编码策略和动态阵列配置。

Result: 通过案例研究验证了在密集动态环境中优化能量收集和数据吞吐的可行性。

Conclusion: 研究为能源自主的IoE部署和智能工厂网络等下一代无线技术应用提供了理论支持。

Abstract: This paper explores the integration of simultaneous wireless information and power transfer (SWIPT) with gigantic multiple-input multiple-output (gMIMO) technology operating in the upper mid-band frequency range (7-24 GHz). The near-field propagation achieved by gMIMO introduces unique opportunities for energy-efficient, high-capacity communication systems that cater to the demands of 6G wireless networks. Exploiting spherical wave propagation, near-field SWIPT with gMIMO enables precise energy and data delivery, enhancing spectral efficiency through beamfocusing and massive spatial multiplexing. This paper discusses theoretical principles, design challenges, and enabling solutions, including advanced channel estimation techniques, precoding strategies, and dynamic array configurations such as sparse and modular arrays. Through analytical insights and a case study, this paper demonstrates the feasibility of achieving optimized energy harvesting and data throughput in dense and dynamic environments. These findings contribute to advancing energy-autonomous Internet-of-Everything (IoE) deployments, smart factory networks, and other energy-autonomous applications aligned with the goals of next-generation wireless technologies.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [13] [Thinking in Directivity: Speech Large Language Model for Multi-Talker Directional Speech Recognition](https://arxiv.org/abs/2506.14973)
*Jiamin Xie,Ju Lin,Yiteng Huang,Tyler Vuong,Zhaojiang Lin,Zhaojun Yang,Peng Su,Prashant Rawat,Sangeeta Srivastava,Ming Sun,Florian Metze*

Main category: eess.AS

TL;DR: 论文提出了一种名为directional-SpeechLlama的新方法，利用智能眼镜的麦克风阵列实现定向语音识别、声源定位和旁听者干扰抑制。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在语音识别方面表现出色，但其在多通道音频和空间线索处理方面的能力尚未充分研究。

Method: 提出了两种关键技术：序列化定向输出训练（S-DOT）和对比方向数据增强（CDDA），以增强模型对方向性的理解。

Result: 实验结果表明，directional-SpeechLlama能有效捕捉文本线索与空间音频之间的关系，在语音识别和声源定位任务中表现优异。

Conclusion: 该研究为多通道音频处理提供了新思路，并展示了Speech LLMs在空间音频理解方面的潜力。

Abstract: Recent studies have demonstrated that prompting large language models (LLM) with audio encodings enables effective speech recognition capabilities. However, the ability of Speech LLMs to comprehend and process multi-channel audio with spatial cues remains a relatively uninvestigated area of research. In this work, we present directional-SpeechLlama, a novel approach that leverages the microphone array of smart glasses to achieve directional speech recognition, source localization, and bystander cross-talk suppression. To enhance the model's ability to understand directivity, we propose two key techniques: serialized directional output training (S-DOT) and contrastive direction data augmentation (CDDA). Experimental results show that our proposed directional-SpeechLlama effectively captures the relationship between textual cues and spatial audio, yielding strong performance in both speech recognition and source localization tasks.

</details>


### [14] [Factorized RVQ-GAN For Disentangled Speech Tokenization](https://arxiv.org/abs/2506.15456)
*Sameer Khurana,Dominik Klement,Antoine Laurent,Dominik Bobos,Juraj Novosad,Peter Gazdik,Ellen Zhang,Zili Huang,Amir Hussein,Ricard Marxer,Yoshiki Masuyama,Ryo Aihara,Chiori Hori,Francois G. Germain,Gordon Wichern,Jonathan Le Roux*

Main category: eess.AS

TL;DR: HAC是一种分层神经语音编解码器，通过将瓶颈分解为声学、音素和词汇三个层次，结合知识蒸馏目标，实现了语音的离散表示。


<details>
  <summary>Details</summary>
Motivation: 提出一种统一的神经语音编解码器，以同时捕捉声学细节和词汇语义，为下游任务提供更好的语音表示。

Method: HAC通过分层瓶颈结构（声学、音素、词汇）和两个知识蒸馏目标（HuBERT和LaBSE）实现语音编码。

Result: 实验表明HAC的令牌集能够解耦音素和词汇语义，并在自然度和重建质量上优于单层基线。

Conclusion: HAC作为一种统一的离散语音表示，有望在语音生成和理解任务中发挥重要作用。

Abstract: We propose Hierarchical Audio Codec (HAC), a unified neural speech codec that factorizes its bottleneck into three linguistic levels-acoustic, phonetic, and lexical-within a single model. HAC leverages two knowledge distillation objectives: one from a pre-trained speech encoder (HuBERT) for phoneme-level structure, and another from a text-based encoder (LaBSE) for lexical cues. Experiments on English and multilingual data show that HAC's factorized bottleneck yields disentangled token sets: one aligns with phonemes, while another captures word-level semantics. Quantitative evaluations confirm that HAC tokens preserve naturalness and provide interpretable linguistic information, outperforming single-level baselines in both disentanglement and reconstruction quality. These findings underscore HAC's potential as a unified discrete speech representation, bridging acoustic detail and lexical meaning for downstream speech generation and understanding tasks.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [15] [pycnet-audio: A Python package to support bioacoustics data processing](https://arxiv.org/abs/2506.14864)
*Zachary J. Ruff,Damon B. Lesmeister*

Main category: cs.SD

TL;DR: 论文介绍了一种基于被动声学监测的野生动物研究方法，利用自动化录音设备（ARUs）收集数据，并通过pycnet-audio工具实现自动化信号检测。


<details>
  <summary>Details</summary>
Motivation: 传统手动处理大规模声学数据效率低下，需要一种自动化解决方案以提高效率和准确性。

Method: 使用ARUs在野外长时间录音，通过pycnet-audio工具和PNW-Cnet模型自动检测目标物种的叫声及其他信号。

Result: PNW-Cnet模型已扩展至检测约80种森林野生动物叫声及多种人为和环境噪声。

Conclusion: pycnet-audio为声学数据提供了一种高效的处理流程，适用于大规模野生动物监测项目。

Abstract: Passive acoustic monitoring is an emerging approach in wildlife research that leverages recent improvements in purpose-made automated recording units (ARUs). The general approach is to deploy ARUs in the field to record on a programmed schedule for extended periods (weeks or months), after which the audio data are retrieved. These data must then be processed, typically either by measuring or analyzing characteristics of the audio itself (e.g. calculating acoustic indices), or by searching for some signal of interest within the recordings, e.g. vocalizations or other sounds produced by some target species, anthropogenic or environmental noise, etc. In the latter case, some method is required to locate the signal(s) of interest within the audio. While very small datasets can simply be searched manually, even modest projects can produce audio datasets on the order of 105 hours of recordings, making manual review impractical and necessitating some form of automated detection. pycnet-audio (Ruff 2024) is intended to provide a practical processing workflow for acoustic data, built around the PNW-Cnet model, which was initially developed by the U.S. Forest Service to support population monitoring of northern spotted owls (Strix occidentalis caurina) and other forest owls (Lesmeister and Jenkins 2022; Ruff et al. 2020). PNW-Cnet has been expanded to detect vocalizations of ca. 80 forest wildlife species and numerous forms of anthropogenic and environmental noise (Ruff et al. 2021, 2023).

</details>


### [16] [A Comparative Evaluation of Deep Learning Models for Speech Enhancement in Real-World Noisy Environments](https://arxiv.org/abs/2506.15000)
*Md Jahangir Alam Khondkar,Ajan Ahmed,Masudul Haider Imtiaz,Stephanie Schuckers*

Main category: cs.SD

TL;DR: 该研究对比了三种语音增强模型（Wave-U-Net、CMGAN和U-Net）在噪声抑制、感知质量和说话人特征保留方面的性能，发现U-Net在噪声抑制上表现最佳，CMGAN在感知质量上领先，而Wave-U-Net在说话人特征保留上更优。


<details>
  <summary>Details</summary>
Motivation: 语音增强在嘈杂环境中对提高语音信号的可懂度和质量至关重要，但现有模型在噪声抑制、感知质量和说话人特征保留之间的平衡上存在不足，缺乏性能对比研究。

Method: 研究选择了Wave-U-Net、CMGAN和U-Net三种模型，并在SpEAR、VPQAD和Clarkson数据集上进行了性能评估。

Result: U-Net在噪声抑制上表现最佳（SNR提升显著），CMGAN在感知质量上得分最高（PESQ分数领先），Wave-U-Net在说话人特征保留上表现突出（VeriSpeak分数提升）。

Conclusion: 研究表明不同模型在语音增强的不同方面各有优势，为语音生物识别、法医音频分析等应用提供了优化选择依据。

Abstract: Speech enhancement, particularly denoising, is vital in improving the intelligibility and quality of speech signals for real-world applications, especially in noisy environments. While prior research has introduced various deep learning models for this purpose, many struggle to balance noise suppression, perceptual quality, and speaker-specific feature preservation, leaving a critical research gap in their comparative performance evaluation. This study benchmarks three state-of-the-art models Wave-U-Net, CMGAN, and U-Net, on diverse datasets such as SpEAR, VPQAD, and Clarkson datasets. These models were chosen due to their relevance in the literature and code accessibility. The evaluation reveals that U-Net achieves high noise suppression with SNR improvements of +71.96% on SpEAR, +64.83% on VPQAD, and +364.2% on the Clarkson dataset. CMGAN outperforms in perceptual quality, attaining the highest PESQ scores of 4.04 on SpEAR and 1.46 on VPQAD, making it well-suited for applications prioritizing natural and intelligible speech. Wave-U-Net balances these attributes with improvements in speaker-specific feature retention, evidenced by VeriSpeak score gains of +10.84% on SpEAR and +27.38% on VPQAD. This research indicates how advanced methods can optimize trade-offs between noise suppression, perceptual quality, and speaker recognition. The findings may contribute to advancing voice biometrics, forensic audio analysis, telecommunication, and speaker verification in challenging acoustic conditions.

</details>


### [17] [An accurate and revised version of optical character recognition-based speech synthesis using LabVIEW](https://arxiv.org/abs/2506.15029)
*Prateek Mehta,Anasuya Patil*

Main category: cs.SD

TL;DR: 开发了一种基于OCR的语音合成系统，帮助视障人士通过声音获取文本内容。


<details>
  <summary>Details</summary>
Motivation: 视障人士依赖盲文和音频资源有限，无法自由选择书籍，语音是更有效的沟通方式。

Method: 使用LabVIEW实现OCR技术，将文本转换为语音。

Result: 系统准确、可靠、成本低且用户友好。

Conclusion: OCR语音合成系统为视障人士提供了更便捷的文本访问方式。

Abstract: Knowledge extraction through sound is a distinctive property. Visually impaired individuals often rely solely on Braille books and audio recordings provided by NGOs. Due to limitations in these approaches, blind individuals often cannot access books of their choice. Speech is a more effective mode of communication than text for blind and visually impaired persons, as they can easily respond to sounds. This paper presents the development of an accurate, reliable, cost-effective, and user-friendly optical character recognition (OCR)-based speech synthesis system. The OCR-based system has been implemented using Laboratory Virtual Instrument Engineering Workbench (LabVIEW).

</details>


### [18] [SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning](https://arxiv.org/abs/2506.15154)
*Anuradha Chopra,Abhinaba Roy,Dorien Herremans*

Main category: cs.SD

TL;DR: SonicVerse是一个多任务音乐描述模型，通过结合音乐特征检测任务（如调性检测、人声检测等）生成丰富的音乐描述，提升音乐数据库和AI研究的质量。


<details>
  <summary>Details</summary>
Motivation: 为音乐片段生成准确的描述，丰富音乐数据库并推动音乐AI研究。

Method: 采用基于投影的架构，将音频输入转换为语言标记，同时通过辅助头检测音乐特征，并将特征输出投影为语言标记以增强描述输入。

Result: 实验表明，结合音乐特征能显著提升生成描述的质量和细节。

Conclusion: SonicVerse通过多任务学习生成详细音乐描述，为音乐AI研究提供了新工具。

Abstract: Detailed captions that accurately reflect the characteristics of a music piece can enrich music databases and drive forward research in music AI. This paper introduces a multi-task music captioning model, SonicVerse, that integrates caption generation with auxiliary music feature detection tasks such as key detection, vocals detection, and more, so as to directly capture both low-level acoustic details as well as high-level musical attributes. The key contribution is a projection-based architecture that transforms audio input into language tokens, while simultaneously detecting music features through dedicated auxiliary heads. The outputs of these heads are also projected into language tokens, to enhance the captioning input. This framework not only produces rich, descriptive captions for short music fragments but also directly enables the generation of detailed time-informed descriptions for longer music pieces, by chaining the outputs using a large-language model. To train the model, we extended the MusicBench dataset by annotating it with music features using MIRFLEX, a modular music feature extractor, resulting in paired audio, captions and music feature data. Experimental results show that incorporating features in this way improves the quality and detail of the generated captions.

</details>


### [19] [Exploiting Music Source Separation for Automatic Lyrics Transcription with Whisper](https://arxiv.org/abs/2506.15514)
*Jaza Syed,Ivan Meresman Higgs,Ondřej Cífka,Mark Sandler*

Main category: cs.SD

TL;DR: 该论文研究了音乐源分离对自动歌词转录（ALT）的影响，使用Whisper模型评估了不同音频输入的效果，并提出改进方法，显著降低了词错误率（WER）。


<details>
  <summary>Details</summary>
Motivation: 尽管自动语音识别（ASR）技术取得了显著进展，但ALT仍面临音乐伴奏干扰的挑战。音乐源分离技术的进步为提升ALT性能提供了可能，但其影响尚未系统研究。

Method: 使用Whisper模型评估原始音频、分离人声和人声干声在短形式和长形式转录任务中的表现，并提出改进算法。

Result: 在短形式任务中，通过拼接方法降低了WER；在长形式任务中，利用源分离作为人声活动检测器，进一步降低了WER。

Conclusion: 该方法在开源系统中实现了最佳性能，并发布了首个公开可用的长形式歌词转录数据集MUSDB-ALT。

Abstract: Automatic lyrics transcription (ALT) remains a challenging task in the field of music information retrieval, despite great advances in automatic speech recognition (ASR) brought about by transformer-based architectures in recent years. One of the major challenges in ALT is the high amplitude of interfering audio signals relative to conventional ASR due to musical accompaniment. Recent advances in music source separation have enabled automatic extraction of high-quality separated vocals, which could potentially improve ALT performance. However, the effect of source separation has not been systematically investigated in order to establish best practices for its use. This work examines the impact of source separation on ALT using Whisper, a state-of-the-art open source ASR model. We evaluate Whisper's performance on original audio, separated vocals, and vocal stems across short-form and long-form transcription tasks. For short-form, we suggest a concatenation method that results in a consistent reduction in Word Error Rate (WER). For long-form, we propose an algorithm using source separation as a vocal activity detector to derive segment boundaries, which results in a consistent reduction in WER relative to Whisper's native long-form algorithm. Our approach achieves state-of-the-art results for an open source system on the Jam-ALT long-form ALT benchmark, without any training or fine-tuning. We also publish MUSDB-ALT, the first dataset of long-form lyric transcripts following the Jam-ALT guidelines for which vocal stems are publicly available.

</details>


### [20] [Diff-TONE: Timestep Optimization for iNstrument Editing in Text-to-Music Diffusion Models](https://arxiv.org/abs/2506.15530)
*Teysir Baoueb,Xiaoyu Bie,Xi Wang,Gaël Richard*

Main category: cs.SD

TL;DR: 本文提出了一种利用现有文本到音乐扩散模型进行乐器编辑的方法，无需额外训练，同时保持生成速度和原始内容。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到音乐生成模型为音乐创作提供了新工具，但如何精确控制生成结果仍是一大挑战。本文旨在解决这一问题，通过编辑乐器音色而不影响音频内容。

Method: 利用预训练的文本到音乐扩散模型，通过选择适当的中间时间步（由乐器分类器确定），在保留原始内容的同时实现乐器编辑。

Result: 实验表明，该方法能有效平衡内容保留和音色调整，且不增加模型训练负担或降低生成速度。

Conclusion: 该方法为乐器编辑提供了一种高效且无需额外训练的解决方案，扩展了文本到音乐模型的应用场景。

Abstract: Breakthroughs in text-to-music generation models are transforming the creative landscape, equipping musicians with innovative tools for composition and experimentation like never before. However, controlling the generation process to achieve a specific desired outcome remains a significant challenge. Even a minor change in the text prompt, combined with the same random seed, can drastically alter the generated piece. In this paper, we explore the application of existing text-to-music diffusion models for instrument editing. Specifically, for an existing audio track, we aim to leverage a pretrained text-to-music diffusion model to edit the instrument while preserving the underlying content. Based on the insight that the model first focuses on the overall structure or content of the audio, then adds instrument information, and finally refines the quality, we show that selecting a well-chosen intermediate timestep, identified through an instrument classifier, yields a balance between preserving the original piece's content and achieving the desired timbre. Our method does not require additional training of the text-to-music diffusion model, nor does it compromise the generation process's speed.

</details>


### [21] [Versatile Symbolic Music-for-Music Modeling via Function Alignment](https://arxiv.org/abs/2506.15548)
*Junyan Jiang,Daniel Chin,Liwei Lin,Xuanjie Liu,Gus Xia*

Main category: cs.SD

TL;DR: 论文提出了一种参数高效的方法，通过预训练语言模型和轻量级适配器统一音乐内容的理解与生成任务。


<details>
  <summary>Details</summary>
Motivation: 许多音乐AI模型依赖于人工标注的标签，而音乐内容本身（如音符序列）可以自然表达这些标注，因此希望通过音乐模态统一任务。

Method: 使用预训练语言模型处理参考和目标序列，并通过轻量级适配器连接两者。

Result: 实验表明，该方法在和弦识别、旋律生成和鼓轨生成等任务中表现优异。

Conclusion: 该方法为音乐内容的理解与生成任务提供了高效统一的解决方案，所有资源已公开。

Abstract: Many music AI models learn a map between music content and human-defined labels. However, many annotations, such as chords, can be naturally expressed within the music modality itself, e.g., as sequences of symbolic notes. This observation enables both understanding tasks (e.g., chord recognition) and conditional generation tasks (e.g., chord-conditioned melody generation) to be unified under a music-for-music sequence modeling paradigm. In this work, we propose parameter-efficient solutions for a variety of symbolic music-for-music tasks. The high-level idea is that (1) we utilize a pretrained Language Model (LM) for both the reference and the target sequence and (2) we link these two LMs via a lightweight adapter. Experiments show that our method achieves superior performance among different tasks such as chord recognition, melody generation, and drum track generation. All demos, code and model weights are publicly available.

</details>


### [22] [TTSOps: A Closed-Loop Corpus Optimization Framework for Training Multi-Speaker TTS Models from Dark Data](https://arxiv.org/abs/2506.15614)
*Kentaro Seki,Shinnosuke Takamichi,Takaaki Saeki,Hiroshi Saruwatari*

Main category: cs.SD

TL;DR: TTSOps是一个自动化闭环框架，用于从嘈杂的网络语音数据构建多说话人TTS系统，解决了传统方法对高质量数据的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 传统TTS训练需要高质量数据，限制了扩展性和说话人多样性。TTSOps利用现代TTS模型对噪声的鲁棒性，探索低质量但信息丰富的样本。

Method: TTSOps包含三个核心组件：自动化数据收集、动态数据清洗方法选择，以及基于预测MOS的评估循环数据选择。

Result: 在日语YouTube数据上的实验表明，TTSOps在合成语音的自然度和说话人多样性上优于传统方法。

Conclusion: TTSOps通过闭环框架优化数据和模型，显著提升了TTS系统的性能和多样性。

Abstract: This paper presents TTSOps, a fully automated closed-loop framework for constructing multi-speaker text-to-speech (TTS) systems from noisy, uncurated web-scale speech data, often referred to as ``dark data,'' such as online videos. Conventional TTS training pipelines require well-curated corpora with high acoustic quality and accurate text-speech alignment, which severely limits scalability, speaker diversity, and real-world applicability. While recent studies have proposed acoustic-quality-based data selection techniques, they often overlook two critical aspects: (1) the inherent robustness of modern TTS models to noise, and (2) the potential contribution of perceptually low-quality yet informative samples. To address these issues, TTSOps introduces a data-centric training pipeline that integrates three core components: (1) automated data collection from dark data sources, (2) utterance-level dynamic selection of data cleansing methods based on training data quality, and (3) evaluation-in-the-loop data selection using automatically predicted mean opinion scores (MOS) to estimate each utterance's impact on model performance. Furthermore, TTSOps jointly optimizes the corpus and the TTS model in a closed-loop framework by dynamically adapting both data selection and data cleansing processes to the characteristics of the target TTS model. Extensive experiments on Japanese YouTube data demonstrate that TTSOps outperforms conventional acoustic-quality-based baselines in both the naturalness and speaker diversity of synthesized speech.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.SD](#cs.SD) [Total: 8]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Demonstrating Superresolution in Radar Range Estimation Using a Denoising Autoencoder](https://arxiv.org/abs/2506.14906)
*Robert Czupryniak,Abhishek Chakraborty,Andrew N. Jordan,John C. Howell*

Main category: eess.SP

TL;DR: 论文利用机器学习方法（去噪自编码器）在亚波长范围内实现雷达探测的距离超分辨率，并通过信号设计优化性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何在亚波长范围内通过机器学习提高雷达探测的距离分辨率。

Method: 使用去噪自编码器训练模型，优化波形在带宽限制下的距离分辨率，分析不同脉冲类型的性能。

Result: 自编码器实现了有效的降维，瓶颈层与真实散射体间距强相关；球形贝塞尔函数脉冲性能最佳。

Conclusion: 信号设计对基于机器学习的距离分辨率至关重要，贝塞尔脉冲表现最优。

Abstract: We apply machine learning methods to demonstrate range superresolution in
remote sensing radar detection. Specifically, we implement a denoising
autoencoder to estimate the distance between two equal intensity scatterers in
the subwavelength regime. The machine learning models are trained on waveforms
subject to a bandlimit constraint such that ranges much smaller than the
inverse bandlimit are optimized in their precision. The autoencoder achieves
effective dimensionality reduction, with the bottleneck layer exhibiting a
strong and consistent correlation with the true scatterer separation. We
confirm reproducibility across different training sessions and network
initializations by analyzing the scaled encoder outputs and their robustness to
noise. We investigate the behavior of the bottleneck layer for the following
types of pulses: a traditional sinc pulse, a bandlimited triangle-type pulse,
and a theoretically near-optimal pulse created from a spherical Bessel function
basis. The Bessel signal performs best, followed by the triangle wave, with the
sinc signal performing worst, highlighting the crucial role of signal design in
the success of machine-learning-based range resolution.

</details>


### [2] [Metasurfaces-Integrated Doubly-Dispersive MIMO: Channel Modeling and Optimization](https://arxiv.org/abs/2506.14985)
*Kuranage Roche Rayan Ranasinghe,Hyeon Seok Rou,Iván Alexander Morales Sandoval,Giuseppe Thadeu Freitas de Abreu,George C. Alexandropoulos*

Main category: eess.SP

TL;DR: 论文提出了一种新的MPDD信道模型，用于MIMO系统，结合了RIS和SIM技术，并探讨了其在OFDM、OTFS和AFDM波形中的应用。


<details>
  <summary>Details</summary>
Motivation: 扩展DD框架到MIMO系统，尤其是在RIS和SIM增强的环境中，是一个未解决的挑战。

Method: 引入了一种基于超表面的MPDD信道模型，整合了多个RIS和SIM技术。

Result: 模型展示了在SIM辅助的无线系统中优化波形性能的潜力。

Conclusion: MPDD模型为动态环境中的无线通信提供了新的解决方案，并展示了其可编程性。

Abstract: The doubly-dispersive (DD) channel structure has played a pivotal role in
wireless communications, particularly in high-mobility scenarios and integrated
sensing and communications (ISAC), due to its ability to capture the key fading
effects experienced by a transmitted signal as it propagates through a dynamic
medium. However, extending the DD framework to multiple-input multiple-output
(MIMO) systems, especially in environments artificially enhanced by
reconfigurable intelligent surfaces (RISs) and stacked intelligent metasurfaces
(SIM), remains a challenging open problem. In this chapter, a novel
metasurfaces-parametrized DD (MPDD) channel model that integrates an arbitrary
number of RISs, while also incorporating SIM at both the transmitter and
receiver is introduced. Next, the application of this model to some key
waveforms optimized for DD environments -- namely orthogonal frequency division
multiplexing (OFDM), orthogonal time frequency space (OTFS), and affine
frequency division multiplexing (AFDM) -- is discussed. Finally, the
programmability of the proposed model is highlighted through an illustrative
application, demonstrating its potential for enhancing waveform performance in
SIM-assisted wireless systems.

</details>


### [3] [Secure Time-Modulated Intelligent Reflecting Surface via Generative Flow Networks](https://arxiv.org/abs/2506.14992)
*Zhihao Tao,Athina P. Petropulu*

Main category: eess.SP

TL;DR: 提出了一种基于生成AI的TM-IRS参数设计方法，用于多用户OFDM系统的安全增强。


<details>
  <summary>Details</summary>
Motivation: 现有TM-IRS设计方法仅适用于单用户场景，无法满足多用户需求。

Method: 使用GFlowNets学习TM-IRS参数选择的随机策略，以最大化授权方向的总速率。

Result: 实验表明，该方法显著提升了多用户OFDM系统的安全性，且训练效率极高。

Conclusion: 生成AI方法在多用户TM-IRS设计中表现出高效性和实用性。

Abstract: We propose a novel directional modulation (DM) design for OFDM transmitters
aided by a time-modulated intelligent reflecting surface (TM-IRS). The TM-IRS
is configured to preserve the integrity of transmitted signals toward multiple
legitimate users while scrambling the signal in all other directions. Existing
TM-IRS design methods typically target a single user direction and follow
predefined rule-based procedures, making them unsuitable for multi-user
scenarios. Here, we propose a generative AI-based approach to design good sets
of TM-IRS parameters out of a set of all possible quantized ranges of
parameters. The design objective is to maximize the sum rate across the
authorized directions. We model the TM-IRS parameter selection as a
deterministic Markov decision process (MDP), where each terminal state
corresponds to a specific configuration of TM-IRS parameters. GFlowNets are
employed to learn a stochastic policy that samples TM-IRS parameter sets with
probability proportional to their associated sum rate reward. Experimental
results demonstrate that the proposed method effectively enhances the security
of the TM-IRS-aided OFDM systems with multi-users. Also, despite the vast size
of the TM-IRS configuration space, the GFlowNet is able to converge after
training on fewer than 0.000001% of all possible configurations, demonstrating
remarkable efficiency compared to exhaustive combinatorial search.
Implementation code is available at https://github.com/ZhihaoTao/GFN4TM-RIS to
facilitate reproducibility.

</details>


### [4] [Fiber Signal Denoising Algorithm using Hybrid Deep Learning Networks](https://arxiv.org/abs/2506.15125)
*Linlin Wang,Wei Wang,Dezhao Wang,Shanwen Wang*

Main category: eess.SP

TL;DR: 本文提出了一种基于混合深度学习网络（HDLNet）的信号去噪算法，用于光纤分布式声学传感（DAS）系统，并结合车辆检测与跟踪算法，实现了信号去噪与特征提取的完整处理。


<details>
  <summary>Details</summary>
Motivation: 随着光纤DAS系统在智能交通系统（ITS）中的应用需求增加，需要有效的信号处理方法以推动其普及。

Method: 采用自监督的混合深度学习网络（HDLNet），结合去噪自动编码器（DAE）和长短期记忆网络（LSTM），并引入逐行匹配算法进行车辆检测与跟踪。

Result: 在真实高速公路隧道数据集上的实验表明，HDLNet的去噪性能优于空间域DAE。

Conclusion: 提出的混合网络在信号去噪和特征提取方面表现出色，为光纤DAS系统在ITS中的应用提供了有效解决方案。

Abstract: With the applicability of optical fiber-based distributed acoustic sensing
(DAS) systems, effective signal processing and analysis approaches are needed
to promote its popularization in the field of intelligent transportation
systems (ITS). This paper presents a signal denoising algorithm using a hybrid
deep-learning network (HDLNet). Without annotated data and time-consuming
labeling, this self-supervised network runs in parallel, combining an
autoencoder for denoising (DAE) and a long short-term memory (LSTM) for
sequential processing. Additionally, a line-by-line matching algorithm for
vehicle detection and tracking is introduced, thus realizing the complete
processing of fiber signal denoising and feature extraction. Experiments were
carried out on a self-established real highway tunnel dataset, showing that our
proposed hybrid network yields more satisfactory denoising performance than
Spatial-domain DAE.

</details>


### [5] [Out-of-Band Modality Synergy Based Multi-User Beam Prediction and Proactive BS Selection with Zero Pilot Overhead](https://arxiv.org/abs/2506.15136)
*Kehui Li,Binggui Zhou,Jiajia Guo,Feifei Gao,Guanghua Yang,Shaodan Ma*

Main category: eess.SP

TL;DR: 提出了一种基于OOB模态协同（OMS）的移动管理方案，通过视觉和位置反馈实现多用户波束预测和主动基站选择，显著减少信令开销。


<details>
  <summary>Details</summary>
Motivation: 多用户毫米波通信中，多基站协调和波束跟踪导致高信令开销，现有OOB模态方法在多基站系统中效率不足。

Method: 结合视觉和位置两种OOB模态，设计BEM-GBPN网络预测波束增益和最优波束，实现用户切换和波束切换。

Result: 仿真结果表明，方案在零导频开销下达到最优传输速率的91%，显著提升多基站协调效率。

Conclusion: OMS方案有效解决了多基站系统中的波束预测和协调问题，显著提升了系统性能。

Abstract: Multi-user millimeter-wave communication relies on narrow beams and dense
cell deployments to ensure reliable connectivity. However, tracking optimal
beams for multiple mobile users across multiple base stations (BSs) results in
significant signaling overhead. Recent works have explored the capability of
out-of-band (OOB) modalities in obtaining spatial characteristics of wireless
channels and reducing pilot overhead in single-BS single-user/multi-user
systems. However, applying OOB modalities for multi-BS selection towards dense
cell deployments leads to high coordination overhead, i.e, excessive computing
overhead and high latency in data exchange. How to leverage OOB modalities to
eliminate pilot overhead and achieve efficient multi-BS coordination in
multi-BS systems remains largely unexplored. In this paper, we propose a novel
OOB modality synergy (OMS) based mobility management scheme to realize
multi-user beam prediction and proactive BS selection by synergizing two OOB
modalities, i.e., vision and location. Specifically, mobile users are initially
identified via spatial alignment of visual sensing and location feedback, and
then tracked according to the temporal correlation in image sequence.
Subsequently, a binary encoding map based gain and beam prediction network
(BEM-GBPN) is designed to predict beamforming gains and optimal beams for
mobile users at each BS, such that a central unit can control the BSs to
perform user handoff and beam switching. Simulation results indicate that the
proposed OMS-based mobility management scheme enhances beam prediction and BS
selection accuracy and enables users to achieve 91% transmission rates of the
optimal with zero pilot overhead and significantly improve multi-BS
coordination efficiency compared to existing methods.

</details>


### [6] [Probabilistic Trajectory GOSPA: A Metric for Uncertainty-Aware Multi-Object Tracking Performance Evaluation](https://arxiv.org/abs/2506.15148)
*Yuxuan Xia,Ángel F. García-Fernández,Johan Karlsson,Yu Ge,Lennart Svensson,Ting Yuan*

Main category: eess.SP

TL;DR: 本文提出了一种广义的轨迹最优子模式分配（GOSPA）度量方法，用于评估提供轨迹估计的多目标跟踪算法，考虑了轨迹级不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法未充分处理轨迹估计中的不确定性，需要一种更全面的度量方法。

Method: 基于概率GOSPA度量，结合多维分配问题，提出多项式时间可计算的线性规划松弛方法。

Result: 新度量保留了TGOSPA的可解释性，分解后得到直观的成本项，如定位误差和存在概率不匹配误差。

Conclusion: 通过仿真研究验证了所提度量的有效性。

Abstract: This paper presents a generalization of the trajectory general optimal
sub-pattern assignment (GOSPA) metric for evaluating multi-object tracking
algorithms that provide trajectory estimates with track-level uncertainties.
This metric builds on the recently introduced probabilistic GOSPA metric to
account for both the existence and state estimation uncertainties of individual
object states. Similar to trajectory GOSPA (TGOSPA), it can be formulated as a
multidimensional assignment problem, and its linear programming
relaxation--also a valid metric--is computable in polynomial time.
Additionally, this metric retains the interpretability of TGOSPA, and we show
that its decomposition yields intuitive costs terms associated to expected
localization error and existence probability mismatch error for properly
detected objects, expected missed and false detection error, and track switch
error. The effectiveness of the proposed metric is demonstrated through a
simulation study.

</details>


### [7] [Enhancing eLoran Timing Accuracy via Machine Learning with Meteorological and Terrain Data](https://arxiv.org/abs/2506.15235)
*Taewon Kang,Seunghyeon Park,Pyo-Woong Son,Jiwon Seo*

Main category: eess.SP

TL;DR: 论文研究了eLoran/GPS时间差（TD）与气象因素的关系，提出WLR-AGRNN模型以提高TD估计精度。


<details>
  <summary>Details</summary>
Motivation: GNSS易受干扰，需补充PNT系统（如eLoran），但eLoran的主要误差源（ASF）难以预测。

Method: 测量GPS与eLoran的TD，分析其与11种气象因素的关系，提出WLR-AGRNN模型。

Result: WLR-AGRNN模型在四个月数据中表现优于其他模型，显著提升TD估计精度。

Conclusion: WLR-AGRNN模型有效改善eLoran/GPS TD估计，为eLoran提供高精度时间信息。

Abstract: The vulnerabilities of global navigation satellite systems (GNSS) to signal
interference have increased the demand for complementary positioning,
navigation, and timing (PNT) systems. To address this, South Korea has decided
to deploy an enhanced long-range navigation (eLoran) system as a complementary
PNT solution. Similar to GNSS, eLoran provides highly accurate timing
information, which is essential for applications such as telecommunications,
financial systems, and power distribution. However, the primary sources of
error for GNSS and eLoran differ. For eLoran, the main source of error is
signal propagation delay over land, known as the additional secondary factor
(ASF). This delay, influenced by ground conductivity and weather conditions
along the signal path, is challenging to predict and mitigate. In this paper,
we measure the time difference (TD) between GPS and eLoran using a time
interval counter and analyze the correlations between eLoran/GPS TD and eleven
meteorological factors. Accurate estimation of eLoran/GPS TD could enable
eLoran to achieve timing accuracy comparable to that of GPS. We propose two
estimation models for eLoran/GPS TD and compare their performance with existing
TD estimation methods. The proposed WLR-AGRNN model captures the linear
relationships between meteorological factors and eLoran/GPS TD using weighted
linear regression (WLR) and models nonlinear relationships between outputs from
expert networks through an anisotropic general regression neural network
(AGRNN). The model incorporates terrain elevation to appropriately weight
meteorological data, as elevation influences signal propagation delay.
Experimental results based on four months of data demonstrate that the
WLR-AGRNN model outperforms other models, highlighting its effectiveness in
improving eLoran/GPS TD estimation accuracy.

</details>


### [8] [Reinforcement Learning-Based Policy Optimisation For Heterogeneous Radio Access](https://arxiv.org/abs/2506.15273)
*Anup Mishra,Čedomir Stefanović,Xiuqiang Xu,Petar Popovski,Israel Leyva-Mayorga*

Main category: eess.SP

TL;DR: 论文研究了无线网络中异构服务资源的高效共享，提出了一种基于强化学习的IoT设备传输策略优化方法，显著提升了延迟性能。


<details>
  <summary>Details</summary>
Motivation: 未来无线网络需要灵活高效的资源共享，尤其是延迟敏感的IoT设备与宽带用户的共存问题。

Method: 采用无授权访问框架，结合双Q学习的强化学习方法优化IoT设备的传输策略。

Result: RL策略显著提升了IoT用户的延迟性能，同时保持了宽带用户的吞吐量和能效。

Conclusion: 在不同IoT流量下，RAN共享和切片各有优势，RL策略能适应不同场景。

Abstract: Flexible and efficient wireless resource sharing across heterogeneous
services is a key objective for future wireless networks. In this context, we
investigate the performance of a system where latency-constrained
internet-of-things (IoT) devices coexist with a broadband user. The base
station adopts a grant-free access framework to manage resource allocation,
either through orthogonal radio access network (RAN) slicing or by allowing
shared access between services. For the IoT users, we propose a reinforcement
learning (RL) approach based on double Q-Learning (QL) to optimise their
repetition-based transmission strategy, allowing them to adapt to varying
levels of interference and meet a predefined latency target. We evaluate the
system's performance in terms of the cumulative distribution function of IoT
users' latency, as well as the broadband user's throughput and energy
efficiency (EE). Our results show that the proposed RL-based access policies
significantly enhance the latency performance of IoT users in both RAN Slicing
and RAN Sharing scenarios, while preserving desirable broadband throughput and
EE. Furthermore, the proposed policies enable RAN Sharing to be
energy-efficient at low IoT traffic levels, and RAN Slicing to be favourable
under high IoT traffic.

</details>


### [9] [Urban RIS-Assisted HAP Networks: Performance Analysis Using Stochastic Geometry](https://arxiv.org/abs/2506.15338)
*Islam M. Tanash,Ayush Kumar Dwivedi,Taneli Riihonen*

Main category: eess.SP

TL;DR: 研究高海拔平台（HAP）网络与可重构智能表面（RIS）的结合，通过统计建模分析覆盖概率和容量，显示性能提升。


<details>
  <summary>Details</summary>
Motivation: 探索HAP和RIS在复杂城市环境中的实际部署效果，解决干扰和遮挡问题。

Method: 使用泊松点过程建模HAP和RIS的不规则分布，布尔矩形建模建筑物遮挡，基于广义Beta prime分布分析信道。

Result: 覆盖概率和容量显著提升，干扰得到有效抑制。

Conclusion: 该系统可提升城市环境中的连接性和数据卸载效率。

Abstract: This paper studies a high-altitude platform (HAP) network supported by
reconfigurable intelligent surfaces (RISs). The practical irregular placement
of HAPs and RISs is modeled using homogeneous Poisson point processes, while
buildings that cause blockages in urban areas are modeled as a Boolean scheme
of rectangles. We introduce a novel approach to characterize the statistical
channel based on generalized Beta prime distribution. Analytical expressions
for coverage probability and ergodic capacity in an interference-limited system
are derived and validated through Monte Carlo simulations. The findings show
notable performance improvements and reveal the impact of various system
parameters, including blockages effect which contribute in mitigating
interference from the other visible HAPs. This proposed system could enhance
connectivity and enable effective data offloading in urban environments.

</details>


### [10] [Effect of Signal Quantization on Performance Measures of a 1st Order One Dimensional Differential Microphone Array](https://arxiv.org/abs/2506.15463)
*Shweta Pal,Arun Kumar,Monika Agrawal*

Main category: eess.SP

TL;DR: 本文研究了信号量化对一维一阶差分麦克风阵列（DMA）性能的影响，发现量化主要影响零深（ND），而波束形状、方向性因子（DF）和前背比（FBR）保持不变。


<details>
  <summary>Details</summary>
Motivation: 量化是数据采集中的关键环节，但其对一维一阶DMA性能的影响尚未被研究，因此本文旨在填补这一空白。

Method: 通过分析推导量化波束形成输出的表达式，并模拟量化对不同性能指标（如波束图、DF、FBR和ND）的影响。

Result: 量化主要影响ND，ND随量化位数增加而提高；波束形状、DF和FBR不受量化影响；ND随零深靠近主瓣方向而降低。

Conclusion: 量化对一维一阶DMA的性能影响有限，但对干扰抑制能力（ND）有显著影响，尤其在零深位置变化时。

Abstract: In practical systems, recorded analog signals must be digitized for
processing, introducing quantization as a critical aspect of data acquisition.
While prior studies have examined quantization effects in various signal
processing contexts, its impact on differential microphone arrays (DMAs),
particularly in one-dimensional (1D) first-order configurations, remains
unexplored. This paper investigates the influence of signal quantization on
performance of first-order 1D DMAs across various beampatterns. An analytical
expression for quantized beamformed output for a first-order 1D DMA has been
formulated. The effect of signal quantization has been studied on array
performance measures such as the Beampattern, Directivity Factor (DF),
Front-to-Back Ratio (FBR), and null depth (ND). Simulation results reveal that
beampattern shape remains structurally invariant across quantization bit
depths, with quantization primarily affecting ND. DF and FBR remain constant
with the varying number of quantization bits. Additionally, ND is shown to be
frequency-independent; however, it increases with increasing quantization bit
depths, enhancing interference suppression. The study also examines the effect
of steering nulls across the azimuthal range, showing that ND degrades as the
null moves closer to the source look direction, indicating reduced interference
suppression.

</details>


### [11] [Analyzing URA Geometry for Enhanced Spatial Multiplexing and Extended Near-Field Coverage](https://arxiv.org/abs/2506.15470)
*Ahmed Hussain,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil*

Main category: eess.SP

TL;DR: 本文研究了大型天线阵列在高频段部署时的近场波束聚焦问题，推导了广义均匀矩形阵列（URA）的波束深度，并探讨了阵列几何形状对近场波束聚焦能力的影响。


<details>
  <summary>Details</summary>
Motivation: 随着高频段大型天线阵列的部署，未来无线通信系统可能工作在辐射近场区域，需要研究近场波束聚焦及其对空间复用能力的影响。

Method: 通过定义有效波束聚焦瑞利距离（EBRD）来表征近场边界，分析不同几何形状的URA对波束深度和EBRD的影响。

Result: 方形URA的波束深度最窄，但EBRD受限；宽或高的URA能最大化EBRD，从而提高多用户总速率。仿真结果显示，宽或高的URA的总速率是方形URA的3.5倍。

Conclusion: 宽或高的URA在近场波束聚焦和空间复用方面表现更优，适合未来无线通信系统的部署。

Abstract: With the deployment of large antenna arrays at high frequency bands, future
wireless communication systems are likely to operate in the radiative
near-field. Unlike far-field beam steering, near-field beams can be focused
within a spatial region of finite depth, enabling spatial multiplexing in both
the angular and range dimensions. This paper derives the beamdepth for a
generalized uniform rectangular array (URA) and investigates how array geometry
influences the near-field beamdepth and the limits where near-field
beamfocusing is achievable. To characterize the near-field boundary in terms of
beamfocusing and spatial multiplexing gains, we define the effective
beamfocusing Rayleigh distance (EBRD) for a generalized URA. Our analysis
reveals that while a square URA achieves the narrowest beamdepth, the EBRD is
maximized for a wide or tall URA. However, despite its narrow beamdepth, a
square URA may experience a reduction in multiuser sum rate due to its severely
constrained EBRD. Simulation results confirm that a wide or tall URA achieves a
sum rate of 3.5 X more than that of a square URA, benefiting from the extended
EBRD and improved spatial multiplexing capabilities.

</details>


### [12] [Near-Field SWIPT with gMIMO in the Upper Mid-Band: Opportunities, Challenges, and the Way Forward](https://arxiv.org/abs/2506.15670)
*Özlem Tugfe Demir,Mustafa Ozger,Ferdi Kara,Woong-Hee Lee,Emil Björnson*

Main category: eess.SP

TL;DR: 论文探讨了在7-24 GHz频段内，将SWIPT与gMIMO技术结合的潜力，利用近场传播实现高效能、高容量的6G通信系统。


<details>
  <summary>Details</summary>
Motivation: 满足6G无线网络对高效能和高速通信的需求，推动能量自主的物联网和智能工厂网络发展。

Method: 利用球形波传播和近场SWIPT，结合gMIMO技术，通过波束聚焦和大规模空间复用提高频谱效率。

Result: 通过理论分析和案例研究，证明了在密集动态环境中优化能量收集和数据吞吐的可行性。

Conclusion: 该研究为下一代无线技术中的能量自主应用提供了重要支持。

Abstract: This paper explores the integration of simultaneous wireless information and
power transfer (SWIPT) with gigantic multiple-input multiple-output (gMIMO)
technology operating in the upper mid-band frequency range (7-24 GHz). The
near-field propagation achieved by gMIMO introduces unique opportunities for
energy-efficient, high-capacity communication systems that cater to the demands
of 6G wireless networks. Exploiting spherical wave propagation, near-field
SWIPT with gMIMO enables precise energy and data delivery, enhancing spectral
efficiency through beamfocusing and massive spatial multiplexing. This paper
discusses theoretical principles, design challenges, and enabling solutions,
including advanced channel estimation techniques, precoding strategies, and
dynamic array configurations such as sparse and modular arrays. Through
analytical insights and a case study, this paper demonstrates the feasibility
of achieving optimized energy harvesting and data throughput in dense and
dynamic environments. These findings contribute to advancing energy-autonomous
Internet-of-Everything (IoE) deployments, smart factory networks, and other
energy-autonomous applications aligned with the goals of next-generation
wireless technologies.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [13] [Thinking in Directivity: Speech Large Language Model for Multi-Talker Directional Speech Recognition](https://arxiv.org/abs/2506.14973)
*Jiamin Xie,Ju Lin,Yiteng Huang,Tyler Vuong,Zhaojiang Lin,Zhaojun Yang,Peng Su,Prashant Rawat,Sangeeta Srivastava,Ming Sun,Florian Metze*

Main category: eess.AS

TL;DR: 论文提出了一种名为directional-SpeechLlama的新方法，利用智能眼镜的麦克风阵列实现定向语音识别、声源定位和旁听者对话抑制。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）在语音识别方面表现出色，但其在多通道音频与空间线索处理方面的能力尚未充分研究。

Method: 提出两种关键技术：序列化定向输出训练（S-DOT）和对比方向数据增强（CDDA），以增强模型对方向性的理解。

Result: 实验结果表明，directional-SpeechLlama能有效捕捉文本线索与空间音频的关系，在语音识别和声源定位任务中表现优异。

Conclusion: 该研究为多通道音频处理提供了新思路，展示了LLM在空间音频理解方面的潜力。

Abstract: Recent studies have demonstrated that prompting large language models (LLM)
with audio encodings enables effective speech recognition capabilities.
However, the ability of Speech LLMs to comprehend and process multi-channel
audio with spatial cues remains a relatively uninvestigated area of research.
In this work, we present directional-SpeechLlama, a novel approach that
leverages the microphone array of smart glasses to achieve directional speech
recognition, source localization, and bystander cross-talk suppression. To
enhance the model's ability to understand directivity, we propose two key
techniques: serialized directional output training (S-DOT) and contrastive
direction data augmentation (CDDA). Experimental results show that our proposed
directional-SpeechLlama effectively captures the relationship between textual
cues and spatial audio, yielding strong performance in both speech recognition
and source localization tasks.

</details>


### [14] [Factorized RVQ-GAN For Disentangled Speech Tokenization](https://arxiv.org/abs/2506.15456)
*Sameer Khurana,Dominik Klement,Antoine Laurent,Dominik Bobos,Juraj Novosad,Peter Gazdik,Ellen Zhang,Zili Huang,Amir Hussein,Ricard Marxer,Yoshiki Masuyama,Ryo Aihara,Chiori Hori,Francois G. Germain,Gordon Wichern,Jonathan Le Roux*

Main category: eess.AS

TL;DR: HAC是一种分层神经语音编解码器，通过知识蒸馏将瓶颈分解为声学、音素和词汇三个层次，实现解耦和高质量重建。


<details>
  <summary>Details</summary>
Motivation: 现有语音编解码器通常仅关注单一层次，缺乏对语音多层次结构的统一表示。HAC旨在填补这一空白，通过分层建模结合声学细节和词汇语义。

Method: HAC利用HuBERT和LaBSE的知识蒸馏目标，分别提取音素和词汇信息，构建分层瓶颈。

Result: 实验表明HAC生成的标记集解耦且可解释，优于单层基线，保留了自然性和语义信息。

Conclusion: HAC作为一种统一离散语音表示，有望在下游任务中结合声学和词汇信息。

Abstract: We propose Hierarchical Audio Codec (HAC), a unified neural speech codec that
factorizes its bottleneck into three linguistic levels-acoustic, phonetic, and
lexical-within a single model. HAC leverages two knowledge distillation
objectives: one from a pre-trained speech encoder (HuBERT) for phoneme-level
structure, and another from a text-based encoder (LaBSE) for lexical cues.
Experiments on English and multilingual data show that HAC's factorized
bottleneck yields disentangled token sets: one aligns with phonemes, while
another captures word-level semantics. Quantitative evaluations confirm that
HAC tokens preserve naturalness and provide interpretable linguistic
information, outperforming single-level baselines in both disentanglement and
reconstruction quality. These findings underscore HAC's potential as a unified
discrete speech representation, bridging acoustic detail and lexical meaning
for downstream speech generation and understanding tasks.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [15] [pycnet-audio: A Python package to support bioacoustics data processing](https://arxiv.org/abs/2506.14864)
*Zachary J. Ruff,Damon B. Lesmeister*

Main category: cs.SD

TL;DR: 该论文介绍了被动声学监测技术及其自动化处理工具pycnet-audio，用于高效分析野生动物的声音数据。


<details>
  <summary>Details</summary>
Motivation: 传统手动处理大规模声学数据效率低下，需要自动化工具来支持野生动物研究和监测。

Method: 利用PNW-Cnet模型扩展的pycnet-audio工具，自动化检测目标物种的声音及环境噪音。

Result: PNW-Cnet已扩展到可检测约80种森林野生动物及多种噪音，显著提升数据处理效率。

Conclusion: pycnet-audio为声学数据提供了一种实用的自动化处理方案，适用于野生动物监测和研究。

Abstract: Passive acoustic monitoring is an emerging approach in wildlife research that
leverages recent improvements in purpose-made automated recording units (ARUs).
The general approach is to deploy ARUs in the field to record on a programmed
schedule for extended periods (weeks or months), after which the audio data are
retrieved. These data must then be processed, typically either by measuring or
analyzing characteristics of the audio itself (e.g. calculating acoustic
indices), or by searching for some signal of interest within the recordings,
e.g. vocalizations or other sounds produced by some target species,
anthropogenic or environmental noise, etc. In the latter case, some method is
required to locate the signal(s) of interest within the audio. While very small
datasets can simply be searched manually, even modest projects can produce
audio datasets on the order of 105 hours of recordings, making manual review
impractical and necessitating some form of automated detection. pycnet-audio
(Ruff 2024) is intended to provide a practical processing workflow for acoustic
data, built around the PNW-Cnet model, which was initially developed by the
U.S. Forest Service to support population monitoring of northern spotted owls
(Strix occidentalis caurina) and other forest owls (Lesmeister and Jenkins
2022; Ruff et al. 2020). PNW-Cnet has been expanded to detect vocalizations of
ca. 80 forest wildlife species and numerous forms of anthropogenic and
environmental noise (Ruff et al. 2021, 2023).

</details>


### [16] [A Comparative Evaluation of Deep Learning Models for Speech Enhancement in Real-World Noisy Environments](https://arxiv.org/abs/2506.15000)
*Md Jahangir Alam Khondkar,Ajan Ahmed,Masudul Haider Imtiaz,Stephanie Schuckers*

Main category: cs.SD

TL;DR: 论文比较了三种语音增强模型（Wave-U-Net、CMGAN和U-Net）在噪声抑制、感知质量和说话人特征保留方面的表现，发现U-Net在噪声抑制上表现最佳，CMGAN在感知质量上领先，而Wave-U-Net在说话人特征保留上更优。


<details>
  <summary>Details</summary>
Motivation: 语音增强（尤其是去噪）对提升语音信号的可懂度和质量至关重要，但现有模型在噪声抑制、感知质量和说话人特征保留之间的平衡上存在不足，缺乏全面的性能比较。

Method: 研究对Wave-U-Net、CMGAN和U-Net三种模型在SpEAR、VPQAD和Clarkson数据集上进行了性能评估，重点关注噪声抑制、感知质量和说话人特征保留。

Result: U-Net在噪声抑制上表现最佳（SNR提升显著），CMGAN在感知质量上得分最高（PESQ分数突出），Wave-U-Net在说话人特征保留上表现最优（VeriSpeak分数提升）。

Conclusion: 研究表明不同模型在语音增强的不同方面各有优势，可为语音生物识别、法医音频分析、通信和说话人验证等应用提供优化方案。

Abstract: Speech enhancement, particularly denoising, is vital in improving the
intelligibility and quality of speech signals for real-world applications,
especially in noisy environments. While prior research has introduced various
deep learning models for this purpose, many struggle to balance noise
suppression, perceptual quality, and speaker-specific feature preservation,
leaving a critical research gap in their comparative performance evaluation.
This study benchmarks three state-of-the-art models Wave-U-Net, CMGAN, and
U-Net, on diverse datasets such as SpEAR, VPQAD, and Clarkson datasets. These
models were chosen due to their relevance in the literature and code
accessibility. The evaluation reveals that U-Net achieves high noise
suppression with SNR improvements of +71.96% on SpEAR, +64.83% on VPQAD, and
+364.2% on the Clarkson dataset. CMGAN outperforms in perceptual quality,
attaining the highest PESQ scores of 4.04 on SpEAR and 1.46 on VPQAD, making it
well-suited for applications prioritizing natural and intelligible speech.
Wave-U-Net balances these attributes with improvements in speaker-specific
feature retention, evidenced by VeriSpeak score gains of +10.84% on SpEAR and
+27.38% on VPQAD. This research indicates how advanced methods can optimize
trade-offs between noise suppression, perceptual quality, and speaker
recognition. The findings may contribute to advancing voice biometrics,
forensic audio analysis, telecommunication, and speaker verification in
challenging acoustic conditions.

</details>


### [17] [An accurate and revised version of optical character recognition-based speech synthesis using LabVIEW](https://arxiv.org/abs/2506.15029)
*Prateek Mehta,Anasuya Patil*

Main category: cs.SD

TL;DR: 开发了一种基于OCR的语音合成系统，帮助视障人士通过声音获取知识。


<details>
  <summary>Details</summary>
Motivation: 视障人士通常依赖盲文书籍和音频记录，但这些方式限制了他们的选择。语音是更有效的沟通方式。

Method: 使用LabVIEW实现OCR系统，将文本转换为语音。

Result: 系统准确、可靠、成本低且用户友好。

Conclusion: OCR语音合成系统为视障人士提供了更便捷的知识获取途径。

Abstract: Knowledge extraction through sound is a distinctive property. Visually
impaired individuals often rely solely on Braille books and audio recordings
provided by NGOs. Due to limitations in these approaches, blind individuals
often cannot access books of their choice. Speech is a more effective mode of
communication than text for blind and visually impaired persons, as they can
easily respond to sounds. This paper presents the development of an accurate,
reliable, cost-effective, and user-friendly optical character recognition
(OCR)-based speech synthesis system. The OCR-based system has been implemented
using Laboratory Virtual Instrument Engineering Workbench (LabVIEW).

</details>


### [18] [SonicVerse: Multi-Task Learning for Music Feature-Informed Captioning](https://arxiv.org/abs/2506.15154)
*Anuradha Chopra,Abhinaba Roy,Dorien Herremans*

Main category: cs.SD

TL;DR: 论文提出了一种多任务音乐描述模型SonicVerse，结合音乐特征检测任务生成详细描述，提升音乐AI研究。


<details>
  <summary>Details</summary>
Motivation: 为音乐片段生成准确描述，丰富音乐数据库并推动音乐AI研究。

Method: 采用基于投影的架构，将音频输入转换为语言标记，同时通过辅助头检测音乐特征，增强描述输入。

Result: 实验表明，结合音乐特征提高了生成描述的细节和质量。

Conclusion: SonicVerse模型能生成丰富描述，并支持长音乐片段的详细时间描述。

Abstract: Detailed captions that accurately reflect the characteristics of a music
piece can enrich music databases and drive forward research in music AI. This
paper introduces a multi-task music captioning model, SonicVerse, that
integrates caption generation with auxiliary music feature detection tasks such
as key detection, vocals detection, and more, so as to directly capture both
low-level acoustic details as well as high-level musical attributes. The key
contribution is a projection-based architecture that transforms audio input
into language tokens, while simultaneously detecting music features through
dedicated auxiliary heads. The outputs of these heads are also projected into
language tokens, to enhance the captioning input. This framework not only
produces rich, descriptive captions for short music fragments but also directly
enables the generation of detailed time-informed descriptions for longer music
pieces, by chaining the outputs using a large-language model. To train the
model, we extended the MusicBench dataset by annotating it with music features
using MIRFLEX, a modular music feature extractor, resulting in paired audio,
captions and music feature data. Experimental results show that incorporating
features in this way improves the quality and detail of the generated captions.

</details>


### [19] [Exploiting Music Source Separation for Automatic Lyrics Transcription with Whisper](https://arxiv.org/abs/2506.15514)
*Jaza Syed,Ivan Meresman Higgs,Ondřej Cífka,Mark Sandler*

Main category: cs.SD

TL;DR: 本文研究了音乐源分离对自动歌词转录（ALT）的影响，使用Whisper模型评估了不同音频输入的效果，并提出优化方法，显著降低了词错误率（WER）。


<details>
  <summary>Details</summary>
Motivation: 尽管自动语音识别（ASR）取得进展，但ALT仍因音乐伴奏干扰而具有挑战性。音乐源分离技术的进步为提升ALT性能提供了可能，但其效果尚未系统研究。

Method: 使用Whisper模型评估原始音频、分离人声和人声干声在短形式和长形式转录任务中的表现，并提出优化算法。

Result: 提出的方法在短形式和长形式任务中均显著降低WER，并在Jam-ALT基准测试中达到开源系统的最佳性能。

Conclusion: 音乐源分离可有效提升ALT性能，无需额外训练或微调。同时发布了首个公开的长形式歌词转录数据集MUSDB-ALT。

Abstract: Automatic lyrics transcription (ALT) remains a challenging task in the field
of music information retrieval, despite great advances in automatic speech
recognition (ASR) brought about by transformer-based architectures in recent
years. One of the major challenges in ALT is the high amplitude of interfering
audio signals relative to conventional ASR due to musical accompaniment. Recent
advances in music source separation have enabled automatic extraction of
high-quality separated vocals, which could potentially improve ALT performance.
However, the effect of source separation has not been systematically
investigated in order to establish best practices for its use. This work
examines the impact of source separation on ALT using Whisper, a
state-of-the-art open source ASR model. We evaluate Whisper's performance on
original audio, separated vocals, and vocal stems across short-form and
long-form transcription tasks. For short-form, we suggest a concatenation
method that results in a consistent reduction in Word Error Rate (WER). For
long-form, we propose an algorithm using source separation as a vocal activity
detector to derive segment boundaries, which results in a consistent reduction
in WER relative to Whisper's native long-form algorithm. Our approach achieves
state-of-the-art results for an open source system on the Jam-ALT long-form ALT
benchmark, without any training or fine-tuning. We also publish MUSDB-ALT, the
first dataset of long-form lyric transcripts following the Jam-ALT guidelines
for which vocal stems are publicly available.

</details>


### [20] [Diff-TONE: Timestep Optimization for iNstrument Editing in Text-to-Music Diffusion Models](https://arxiv.org/abs/2506.15530)
*Teysir Baoueb,Xiaoyu Bie,Xi Wang,Gaël Richard*

Main category: cs.SD

TL;DR: 本文探讨了利用预训练的文本到音乐扩散模型进行乐器编辑的方法，通过选择合适的时间步长，在保留原音频内容的同时实现乐器音色的调整。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到音乐生成模型为音乐创作提供了创新工具，但如何精确控制生成过程以实现特定效果仍是一个挑战。

Method: 利用预训练的文本到音乐扩散模型，通过乐器分类器选择中间时间步长，在不额外训练模型的情况下实现乐器编辑。

Result: 该方法在保留原音频内容的同时，成功调整了乐器音色，且未影响生成速度。

Conclusion: 通过选择合适的时间步长，可以高效实现乐器编辑，为音乐创作提供了新的可能性。

Abstract: Breakthroughs in text-to-music generation models are transforming the
creative landscape, equipping musicians with innovative tools for composition
and experimentation like never before. However, controlling the generation
process to achieve a specific desired outcome remains a significant challenge.
Even a minor change in the text prompt, combined with the same random seed, can
drastically alter the generated piece. In this paper, we explore the
application of existing text-to-music diffusion models for instrument editing.
Specifically, for an existing audio track, we aim to leverage a pretrained
text-to-music diffusion model to edit the instrument while preserving the
underlying content. Based on the insight that the model first focuses on the
overall structure or content of the audio, then adds instrument information,
and finally refines the quality, we show that selecting a well-chosen
intermediate timestep, identified through an instrument classifier, yields a
balance between preserving the original piece's content and achieving the
desired timbre. Our method does not require additional training of the
text-to-music diffusion model, nor does it compromise the generation process's
speed.

</details>


### [21] [Versatile Symbolic Music-for-Music Modeling via Function Alignment](https://arxiv.org/abs/2506.15548)
*Junyan Jiang,Daniel Chin,Liwei Lin,Xuanjie Liu,Gus Xia*

Main category: cs.SD

TL;DR: 论文提出了一种参数高效的方法，通过预训练语言模型和轻量级适配器统一音乐内容的理解与生成任务。


<details>
  <summary>Details</summary>
Motivation: 现有音乐AI模型通常依赖人工标注标签，而许多标注（如和弦）可以直接用音乐模态表达，这为统一理解和生成任务提供了可能。

Method: 使用预训练语言模型处理参考和目标序列，并通过轻量级适配器连接两者。

Result: 实验表明，该方法在和弦识别、旋律生成和鼓轨生成等任务中表现优异。

Conclusion: 该方法为音乐内容的理解与生成任务提供了一种高效统一的解决方案，且代码和模型权重已公开。

Abstract: Many music AI models learn a map between music content and human-defined
labels. However, many annotations, such as chords, can be naturally expressed
within the music modality itself, e.g., as sequences of symbolic notes. This
observation enables both understanding tasks (e.g., chord recognition) and
conditional generation tasks (e.g., chord-conditioned melody generation) to be
unified under a music-for-music sequence modeling paradigm. In this work, we
propose parameter-efficient solutions for a variety of symbolic music-for-music
tasks. The high-level idea is that (1) we utilize a pretrained Language Model
(LM) for both the reference and the target sequence and (2) we link these two
LMs via a lightweight adapter. Experiments show that our method achieves
superior performance among different tasks such as chord recognition, melody
generation, and drum track generation. All demos, code and model weights are
publicly available.

</details>


### [22] [TTSOps: A Closed-Loop Corpus Optimization Framework for Training Multi-Speaker TTS Models from Dark Data](https://arxiv.org/abs/2506.15614)
*Kentaro Seki,Shinnosuke Takamichi,Takaaki Saeki,Hiroshi Saruwatari*

Main category: cs.SD

TL;DR: TTSOps是一个自动化闭环框架，用于从嘈杂的网络语音数据构建多说话人TTS系统，解决了传统方法对高质量数据的依赖问题。


<details>
  <summary>Details</summary>
Motivation: 传统TTS系统需要高质量、对齐良好的数据，限制了可扩展性和说话人多样性。TTSOps旨在利用现代TTS模型的噪声鲁棒性和低质量但信息丰富的样本。

Method: TTSOps结合了自动化数据收集、动态数据清洗方法选择和基于预测MOS的评估循环数据选择，并在闭环框架中联合优化数据和模型。

Result: 在日语YouTube数据上的实验表明，TTSOps在合成语音的自然度和说话人多样性上优于传统方法。

Conclusion: TTSOps通过数据驱动的闭环优化，显著提升了TTS系统的性能和适用性。

Abstract: This paper presents TTSOps, a fully automated closed-loop framework for
constructing multi-speaker text-to-speech (TTS) systems from noisy, uncurated
web-scale speech data, often referred to as ``dark data,'' such as online
videos. Conventional TTS training pipelines require well-curated corpora with
high acoustic quality and accurate text-speech alignment, which severely limits
scalability, speaker diversity, and real-world applicability. While recent
studies have proposed acoustic-quality-based data selection techniques, they
often overlook two critical aspects: (1) the inherent robustness of modern TTS
models to noise, and (2) the potential contribution of perceptually low-quality
yet informative samples. To address these issues, TTSOps introduces a
data-centric training pipeline that integrates three core components: (1)
automated data collection from dark data sources, (2) utterance-level dynamic
selection of data cleansing methods based on training data quality, and (3)
evaluation-in-the-loop data selection using automatically predicted mean
opinion scores (MOS) to estimate each utterance's impact on model performance.
Furthermore, TTSOps jointly optimizes the corpus and the TTS model in a
closed-loop framework by dynamically adapting both data selection and data
cleansing processes to the characteristics of the target TTS model. Extensive
experiments on Japanese YouTube data demonstrate that TTSOps outperforms
conventional acoustic-quality-based baselines in both the naturalness and
speaker diversity of synthesized speech.

</details>

{"id": "2506.15843", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2506.15843", "abs": "https://arxiv.org/abs/2506.15843", "authors": ["Ninghe Liu", "Yu Xi Huang", "Simon Mahler", "Changhuei Yang"], "title": "Optimized cerebral blood flow measurement in speckle contrast optical spectroscopy via refinement of noise calibration", "comment": "5 pages, 3 figures", "summary": "Speckle contrast optical spectroscopy (SCOS) offers a non-invasive and\ncost-effective method for monitoring cerebral blood flow (CBF). However,\nextracting accurate CBF from SCOS necessitates precise noise pre-calibration.\nErrors from this can degrade CBF measurement fidelity, particularly when the\noverall signal level is low. Such errors primarily stem from residual speckle\ncontrast associated with camera and shot noise, whose fluctuations exhibit a\ntemporal structure that mimics cerebral blood volume (CBV) waveforms. We\npropose an optimization-based framework that performs an adaptive refinement of\nnoise calibration, mitigating the CBV-mimicking artifacts by reducing the\nCBF-CBV waveform correlation. Validated on 10 human subjects, our approach\neffectively lowered the signal threshold for reliable CBF signal from 97 to 26\nelectrons per pixel for a 1920x1200 pixels SCOS system. This improvement\nenables more accurate and robust CBF measurements in SCOS, especially at large\nsource-detector (SD) distances for deeper tissue interrogation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u566a\u58f0\u6821\u51c6\u51cf\u5c11CBV\u6ce2\u5f62\u6a21\u62df\u7684\u4f2a\u5f71\uff0c\u63d0\u9ad8SCOS\u4e2dCBF\u6d4b\u91cf\u7684\u51c6\u786e\u6027\u3002", "motivation": "SCOS\u7528\u4e8e\u76d1\u6d4bCBF\u65f6\uff0c\u566a\u58f0\u6821\u51c6\u8bef\u5dee\u4f1a\u5bfc\u81f4\u6d4b\u91cf\u5931\u771f\uff0c\u5c24\u5176\u662f\u5728\u4f4e\u4fe1\u53f7\u6c34\u5e73\u4e0b\u3002", "method": "\u91c7\u7528\u4f18\u5316\u6846\u67b6\u81ea\u9002\u5e94\u8c03\u6574\u566a\u58f0\u6821\u51c6\uff0c\u964d\u4f4eCBF-CBV\u6ce2\u5f62\u76f8\u5173\u6027\u3002", "result": "\u572810\u540d\u53d7\u8bd5\u8005\u4e2d\u9a8c\u8bc1\uff0c\u4fe1\u53f7\u9608\u503c\u4ece97\u964d\u81f326\u7535\u5b50/\u50cf\u7d20\uff0c\u63d0\u9ad8\u4e86\u6d4b\u91cf\u53ef\u9760\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86SCOS\u5728\u4f4e\u4fe1\u53f7\u548c\u5927SD\u8ddd\u79bb\u4e0b\u7684CBF\u6d4b\u91cf\u51c6\u786e\u6027\u3002"}}
{"id": "2506.15950", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15950", "abs": "https://arxiv.org/abs/2506.15950", "authors": ["Saeed Razavikia", "Carlo Fischione"], "title": "On Designing Modulation for Over-the-Air Computation -- Part I: Noise-Aware Design", "comment": null, "summary": "Over-the-air computation (OAC) leverages the physical superposition property\nof wireless multiple access channels (MACs) to compute functions while\ncommunication occurs, enabling scalable and low-latency processing in\ndistributed networks. While analog OAC methods suffer from noise sensitivity\nand hardware constraints, existing digital approaches are often limited in\ndesign complexity, which may hinder scalability and fail to exploit spectral\nefficiency fully. This two-part paper revisits and extends the ChannelComp\nframework, a general methodology for computing arbitrary finite-valued\nfunctions using digital modulation. In Part I, we develop a novel constellation\ndesign approach that is aware of the noise distribution and formulates the\nencoder design as a max-min optimization problem using noise-tailored distance\nmetrics. Our design supports noise models, including Gaussian, Laplace, and\nheavy-tailed distributions. We further demonstrate that, for heavy-tailed\nnoise, the optimal ChannelComp setup coincides with the solution to the\ncorresponding max-min criterion for the channel noise with heavy-tailed\ndistributions. Numerical experiments confirm that our noise-aware design\nachieves a substantially lower mean-square error than leading digital OAC\nmethods over noisy MACs. In Part II, we consider a constellation design with a\nquantization-based sampling scheme to enhance modulation scalability and\ncomputational accuracy for large-scale digital OAC.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u5b57\u8c03\u5236\u7684\u566a\u58f0\u611f\u77e5\u661f\u5ea7\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8e\u65e0\u7ebf\u591a\u5740\u4fe1\u9053\u4e2d\u7684\u7a7a\u4e2d\u8ba1\u7b97\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5747\u65b9\u8bef\u5dee\u3002", "motivation": "\u73b0\u6709\u6570\u5b57\u7a7a\u4e2d\u8ba1\u7b97\u65b9\u6cd5\u8bbe\u8ba1\u590d\u6742\u4e14\u9891\u8c31\u6548\u7387\u4e0d\u8db3\uff0c\u800c\u6a21\u62df\u65b9\u6cd5\u6613\u53d7\u566a\u58f0\u548c\u786c\u4ef6\u9650\u5236\u3002", "method": "\u63d0\u51fa\u566a\u58f0\u611f\u77e5\u7684\u661f\u5ea7\u8bbe\u8ba1\uff0c\u91c7\u7528\u6700\u5927\u6700\u5c0f\u4f18\u5316\u95ee\u9898\uff0c\u652f\u6301\u9ad8\u65af\u3001\u62c9\u666e\u62c9\u65af\u548c\u91cd\u5c3e\u566a\u58f0\u6a21\u578b\u3002", "result": "\u566a\u58f0\u611f\u77e5\u8bbe\u8ba1\u5728\u566a\u58f0\u591a\u5740\u4fe1\u9053\u4e0a\u6bd4\u73b0\u6709\u6570\u5b57\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u5747\u65b9\u8bef\u5dee\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5927\u89c4\u6a21\u6570\u5b57\u7a7a\u4e2d\u8ba1\u7b97\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.15972", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15972", "abs": "https://arxiv.org/abs/2506.15972", "authors": ["Haiyang Miao", "Jianhua Zhang", "Pan Tang", "Heng Wang", "Lei Tian", "Guangyi Liu"], "title": "Theoretical Analysis of Near-Field MIMO Channel Capacity and Mid-Band Experimental Validation", "comment": null, "summary": "With the increase of multiple-input-multiple-output (MIMO) array size and\ncarrier frequency, near-field MIMO communications will become crucial in 6G\nwireless networks. Due to the increase of MIMO near-field range, the research\nof near-field MIMO capacity has aroused wide interest. In this paper, we focus\non the theoretical analysis and empirical study of near-field MIMO capacity.\nFirst, the near-field channel model is characterized from the electromagnetic\ninformation perspective. Second, with the uniform planar array (UPA), the\nchannel capacity based on effective degree of freedom (EDoF) is analyzed\ntheoretically, and the closed-form analytical expressions are derived in\ndetail. Finally, based on the numerical verification of near-field channel\nmeasurement experiment at 13 GHz band, we reveal that the channel capacity of\nUPA-type MIMO systems decreases continuously with the communication distance\nincreasing. It can be observed that the near-field channel capacity gain is\nrelatively obvious when large-scale MIMO is adopted at both receiving and\ntransmitter ends, but the near-field channel capacity gain may be limited in\nthe actual communication system with the small antenna array at receiving end.\nThis work will give some reference to the near-field communication systems.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u8fd1\u573aMIMO\u901a\u4fe1\u7684\u5bb9\u91cf\u95ee\u9898\uff0c\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u63ed\u793a\u4e86\u8fd1\u573a\u4fe1\u9053\u5bb9\u91cf\u968f\u8ddd\u79bb\u589e\u52a0\u800c\u4e0b\u964d\u7684\u89c4\u5f8b\uff0c\u5e76\u6307\u51fa\u5927\u89c4\u6a21MIMO\u5728\u8fd1\u573a\u901a\u4fe1\u4e2d\u7684\u4f18\u52bf\u3002", "motivation": "\u968f\u7740MIMO\u9635\u5217\u89c4\u6a21\u548c\u8f7d\u6ce2\u9891\u7387\u7684\u589e\u52a0\uff0c\u8fd1\u573aMIMO\u901a\u4fe1\u57286G\u7f51\u7edc\u4e2d\u53d8\u5f97\u81f3\u5173\u91cd\u8981\uff0c\u56e0\u6b64\u7814\u7a76\u8fd1\u573aMIMO\u5bb9\u91cf\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u9996\u5148\u4ece\u7535\u78c1\u4fe1\u606f\u89d2\u5ea6\u5efa\u7acb\u8fd1\u573a\u4fe1\u9053\u6a21\u578b\uff0c\u7136\u540e\u57fa\u4e8e\u5747\u5300\u5e73\u9762\u9635\u5217\uff08UPA\uff09\u548c\u6709\u6548\u81ea\u7531\u5ea6\uff08EDoF\uff09\u7406\u8bba\u5206\u6790\u4fe1\u9053\u5bb9\u91cf\uff0c\u5e76\u901a\u8fc713 GHz\u9891\u6bb5\u7684\u5b9e\u9a8c\u8fdb\u884c\u6570\u503c\u9a8c\u8bc1\u3002", "result": "\u7814\u7a76\u53d1\u73b0\uff0cUPA\u578bMIMO\u7cfb\u7edf\u7684\u4fe1\u9053\u5bb9\u91cf\u968f\u901a\u4fe1\u8ddd\u79bb\u589e\u52a0\u800c\u6301\u7eed\u4e0b\u964d\uff0c\u5927\u89c4\u6a21MIMO\u5728\u8fd1\u573a\u901a\u4fe1\u4e2d\u80fd\u5e26\u6765\u660e\u663e\u5bb9\u91cf\u589e\u76ca\uff0c\u4f46\u63a5\u6536\u7aef\u5929\u7ebf\u9635\u5217\u8f83\u5c0f\u65f6\u589e\u76ca\u6709\u9650\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8fd1\u573a\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7406\u8bba\u53c2\u8003\uff0c\u5f3a\u8c03\u4e86\u5927\u89c4\u6a21MIMO\u5728\u8fd1\u573a\u901a\u4fe1\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2506.15998", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.15998", "abs": "https://arxiv.org/abs/2506.15998", "authors": ["Chen Xu", "Xianghao Yu", "Fan Liu", "Shi Jin"], "title": "Exploiting Both Pilots and Data Payloads for Integrated Sensing and Communications", "comment": null, "summary": "Integrated sensing and communications (ISAC) is one of the key enabling\ntechnologies in future sixth-generation (6G) networks. Current ISAC systems\npredominantly rely on deterministic pilot signals within the signal frame to\naccomplish sensing tasks. However, these pilot signals typically occupy only a\nsmall portion, e.g., 0.15% to 25%, of the time-frequency resources. To enhance\nthe system utility, a promising solution is to repurpose the extensive random\ndata payload signals for sensing tasks. In this paper, we analyze the ISAC\nperformance of a multi-antenna system where both deterministic pilot and random\ndata symbols are employed for sensing tasks. By capitalizing on random matrix\ntheory (RMT), we first derive a semi-closed-form asymptotic expression of the\nergodic linear minimum mean square error (ELMMSE). Then, we formulate an ISAC\nprecoding optimization problem to minimize the ELMMSE, which is solved via a\nspecifically tailored successive convex approximation (SAC) algorithm. To\nprovide system insights, we further derive a closed-form expression for the\nasymptotic ELMMSE at high signal-to-noise ratios (SNRs). Our analysis reveals\nthat, compared with conventional sensing implemented by deterministic signals,\nthe sensing performance degradation induced by random signals is critically\ndetermined by the ratio of the transmit antenna size to the data symbol length.\nBased on this result, the ISAC precoding optimization problem at high SNRs is\ntransformed into a convex optimization problem that can be efficiently solved.\nSimulation results validate the accuracy of the derived asymptotic expressions\nof ELMMSE and the performance of the proposed precoding schemes. Particularly,\nby leveraging data payload signals for sensing tasks, the sensing error is\nreduced by up to 5.6 dB compared to conventional pilot-based sensing.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u57286G\u7f51\u7edc\u4e2d\u5229\u7528\u968f\u673a\u6570\u636e\u8d1f\u8f7d\u4fe1\u53f7\u8fdb\u884c\u611f\u77e5\u4efb\u52a1\u7684\u6027\u80fd\u4f18\u5316\uff0c\u901a\u8fc7\u968f\u673a\u77e9\u9635\u7406\u8bba\u63a8\u5bfc\u4e86ELMMSE\u7684\u6e10\u8fd1\u8868\u8fbe\u5f0f\uff0c\u5e76\u63d0\u51fa\u4e86\u4f18\u5316\u7684\u9884\u7f16\u7801\u65b9\u6848\u3002", "motivation": "\u63d0\u5347\u7cfb\u7edf\u6548\u7528\uff0c\u5229\u7528\u968f\u673a\u6570\u636e\u8d1f\u8f7d\u4fe1\u53f7\u8fdb\u884c\u611f\u77e5\u4efb\u52a1\uff0c\u4ee5\u5f25\u8865\u4f20\u7edf\u786e\u5b9a\u6027\u5bfc\u9891\u4fe1\u53f7\u8d44\u6e90\u5360\u7528\u5c11\u7684\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u968f\u673a\u77e9\u9635\u7406\u8bba\u63a8\u5bfcELMMSE\u7684\u6e10\u8fd1\u8868\u8fbe\u5f0f\uff0c\u5e76\u901a\u8fc7SAC\u7b97\u6cd5\u4f18\u5316\u9884\u7f16\u7801\u95ee\u9898\u3002", "result": "\u5728\u9ad8\u4fe1\u566a\u6bd4\u4e0b\uff0c\u611f\u77e5\u6027\u80fd\u7684\u9000\u5316\u53d6\u51b3\u4e8e\u53d1\u5c04\u5929\u7ebf\u5c3a\u5bf8\u4e0e\u6570\u636e\u7b26\u53f7\u957f\u5ea6\u7684\u6bd4\u4f8b\uff0c\u4f18\u5316\u540e\u7684\u9884\u7f16\u7801\u65b9\u6848\u5c06\u611f\u77e5\u8bef\u5dee\u964d\u4f4e\u4e865.6 dB\u3002", "conclusion": "\u5229\u7528\u6570\u636e\u8d1f\u8f7d\u4fe1\u53f7\u8fdb\u884c\u611f\u77e5\u4efb\u52a1\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e3a\u672a\u67656G\u7f51\u7edc\u7684ISAC\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.15754", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.15754", "abs": "https://arxiv.org/abs/2506.15754", "authors": ["Tahitoa Leygue", "Astrid Sabourin", "Christian Bolzmacher", "Sylvain Bouchigny", "Margarita Anastassova", "Quoc-Cuong Pham"], "title": "Explainable speech emotion recognition through attentive pooling: insights from attention-based temporal localization", "comment": null, "summary": "State-of-the-art transformer models for Speech Emotion Recognition (SER) rely\non temporal feature aggregation, yet advanced pooling methods remain\nunderexplored. We systematically benchmark pooling strategies, including\nMulti-Query Multi-Head Attentive Statistics Pooling, which achieves a 3.5\npercentage point macro F1 gain over average pooling. Attention analysis shows\n15 percent of frames capture 80 percent of emotion cues, revealing a localized\npattern of emotional information. Analysis of high-attention frames reveals\nthat non-linguistic vocalizations and hyperarticulated phonemes are\ndisproportionately prioritized during pooling, mirroring human perceptual\nstrategies. Our findings position attentive pooling as both a performant SER\nmechanism and a biologically plausible tool for explainable emotion\nlocalization. On Interspeech 2025 Speech Emotion Recognition in Naturalistic\nConditions Challenge, our approach obtained a macro F1 score of 0.3649.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\uff08SER\uff09\u4e2d\u7684\u6c60\u5316\u7b56\u7565\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u591a\u67e5\u8be2\u591a\u5934\u6ce8\u610f\u529b\u7edf\u8ba1\u6c60\u5316\u65b9\u6cd5\uff0c\u6027\u80fd\u4f18\u4e8e\u5e73\u5747\u6c60\u5316\uff0c\u5e76\u63ed\u793a\u4e86\u60c5\u611f\u4fe1\u606f\u7684\u5c40\u90e8\u5316\u7279\u5f81\u3002", "motivation": "\u73b0\u6709SER\u6a21\u578b\u5728\u65f6\u95f4\u7279\u5f81\u805a\u5408\u65b9\u9762\u4f9d\u8d56\u6c60\u5316\u65b9\u6cd5\uff0c\u4f46\u9ad8\u7ea7\u6c60\u5316\u7b56\u7565\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u7cfb\u7edf\u6bd4\u8f83\u4e86\u591a\u79cd\u6c60\u5316\u7b56\u7565\uff0c\u5305\u62ec\u63d0\u51fa\u7684\u591a\u67e5\u8be2\u591a\u5934\u6ce8\u610f\u529b\u7edf\u8ba1\u6c60\u5316\u65b9\u6cd5\uff0c\u5e76\u901a\u8fc7\u6ce8\u610f\u529b\u5206\u6790\u5b9a\u4f4d\u60c5\u611f\u4fe1\u606f\u3002", "result": "\u65b0\u65b9\u6cd5\u5728\u5b8fF1\u5206\u6570\u4e0a\u6bd4\u5e73\u5747\u6c60\u5316\u63d0\u9ad8\u4e863.5\u4e2a\u767e\u5206\u70b9\uff0c\u53d1\u73b015%\u7684\u5e27\u5305\u542b80%\u7684\u60c5\u611f\u7ebf\u7d22\u3002", "conclusion": "\u6ce8\u610f\u529b\u6c60\u5316\u4e0d\u4ec5\u6027\u80fd\u4f18\u8d8a\uff0c\u8fd8\u80fd\u89e3\u91ca\u60c5\u611f\u5b9a\u4f4d\uff0c\u4e0e\u4eba\u7c7b\u611f\u77e5\u7b56\u7565\u4e00\u81f4\u3002"}}
{"id": "2506.16228", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2506.16228", "abs": "https://arxiv.org/abs/2506.16228", "authors": ["Tobias Cord-Landwehr", "Tobias Gburrek", "Marc Deegen", "Reinhold Haeb-Umbach"], "title": "Spatio-spectral diarization of meetings by combining TDOA-based segmentation and speaker embedding-based clustering", "comment": "Accepted at Interspeech 2025", "summary": "We propose a spatio-spectral, combined model-based and data-driven\ndiarization pipeline consisting of TDOA-based segmentation followed by\nembedding-based clustering. The proposed system requires neither access to\nmulti-channel training data nor prior knowledge about the number or placement\nof microphones. It works for both a compact microphone array and distributed\nmicrophones, with minor adjustments. Due to its superior handling of\noverlapping speech during segmentation, the proposed pipeline significantly\noutperforms the single-channel pyannote approach, both in a scenario with a\ncompact microphone array and in a setup with distributed microphones.\nAdditionally, we show that, unlike fully spatial diarization pipelines, the\nproposed system can correctly track speakers when they change positions.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6a21\u578b\u548c\u6570\u636e\u9a71\u52a8\u7684\u7a7a\u95f4-\u9891\u8c31\u8bf4\u8bdd\u4eba\u5206\u5272\u4e0e\u805a\u7c7b\u65b9\u6cd5\uff0c\u65e0\u9700\u591a\u901a\u9053\u8bad\u7ec3\u6570\u636e\u6216\u9ea6\u514b\u98ce\u914d\u7f6e\u4fe1\u606f\uff0c\u9002\u7528\u4e8e\u7d27\u51d1\u548c\u5206\u5e03\u5f0f\u9ea6\u514b\u98ce\u9635\u5217\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u5355\u901a\u9053\u65b9\u6cd5\u5728\u91cd\u53e0\u8bed\u97f3\u5206\u5272\u548c\u8bf4\u8bdd\u4eba\u4f4d\u7f6e\u53d8\u5316\u65f6\u7684\u6027\u80fd\u4e0d\u8db3\u95ee\u9898\u3002", "method": "\u7ed3\u5408TDOA\u5206\u5272\u548c\u5d4c\u5165\u805a\u7c7b\uff0c\u65e0\u9700\u591a\u901a\u9053\u8bad\u7ec3\u6570\u636e\u6216\u9ea6\u514b\u98ce\u914d\u7f6e\u4fe1\u606f\u3002", "result": "\u5728\u7d27\u51d1\u548c\u5206\u5e03\u5f0f\u9ea6\u514b\u98ce\u9635\u5217\u4e2d\u663e\u8457\u4f18\u4e8e\u5355\u901a\u9053\u65b9\u6cd5\uff0c\u5e76\u80fd\u6b63\u786e\u8ddf\u8e2a\u79fb\u52a8\u8bf4\u8bdd\u4eba\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u591a\u79cd\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u8d8a\uff0c\u5c24\u5176\u9002\u7528\u4e8e\u91cd\u53e0\u8bed\u97f3\u548c\u8bf4\u8bdd\u4eba\u4f4d\u7f6e\u53d8\u5316\u7684\u60c5\u51b5\u3002"}}
{"id": "2506.16011", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16011", "abs": "https://arxiv.org/abs/2506.16011", "authors": ["Rang Liu", "Ming Li", "Mehdi Zafari", "Bjorn Ottersten", "A. Lee Swindlehurst"], "title": "Multi-Domain Optimization Framework for ISAC: From Electromagnetic Shaping to Network Cooperation", "comment": "10 pages, 5 figures, submitted to IEEE", "summary": "Integrated sensing and communication (ISAC) has emerged as a key feature for\nsixth-generation (6G) networks, providing an opportunity to meet the dual\ndemands of communication and sensing. Existing ISAC research primarily focuses\non baseband optimization at individual access points, with limited attention to\nthe roles of electromagnetic (EM) shaping and network-wide coordination. The\nintricate interdependencies between these domains remain insufficiently\nexplored, leaving their full potential for enhancing ISAC performance largely\nuntapped. To bridge this gap, we consider multi-domain ISAC optimization\nintegrating EM shaping, baseband processing, and network cooperation strategies\nthat facilitate efficient resource management and system-level design. We\nanalyze the fundamental trade-offs between these domains and offer insights\ninto domain-specific and cross-domain strategies contributing to ISAC\nperformance and efficiency. We then conduct a case study demonstrating the\neffectiveness of joint multi-domain optimization. Finally, we discuss key\nchallenges and future research directions to connect theoretical advancements\nand practical ISAC deployments. This work paves the way for intelligent and\nscalable ISAC architectures, providing critical insights for their seamless\nintegration into next-generation wireless networks.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e86\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u57286G\u7f51\u7edc\u4e2d\u7684\u591a\u57df\u4f18\u5316\uff0c\u5305\u62ec\u7535\u78c1\u6210\u5f62\u3001\u57fa\u5e26\u5904\u7406\u548c\u7f51\u7edc\u534f\u4f5c\uff0c\u5206\u6790\u4e86\u5176\u6027\u80fd\u63d0\u5347\u6f5c\u529b\u4e0e\u6311\u6218\u3002", "motivation": "\u73b0\u6709ISAC\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u5728\u5355\u4e2a\u63a5\u5165\u70b9\u7684\u57fa\u5e26\u4f18\u5316\uff0c\u5ffd\u89c6\u4e86\u7535\u78c1\u6210\u5f62\u548c\u7f51\u7edc\u534f\u8c03\u7684\u4f5c\u7528\uff0c\u9650\u5236\u4e86ISAC\u6027\u80fd\u7684\u8fdb\u4e00\u6b65\u63d0\u5347\u3002", "method": "\u63d0\u51fa\u591a\u57dfISAC\u4f18\u5316\u6846\u67b6\uff0c\u6574\u5408\u7535\u78c1\u6210\u5f62\u3001\u57fa\u5e26\u5904\u7406\u548c\u7f51\u7edc\u534f\u4f5c\u7b56\u7565\uff0c\u5206\u6790\u5176\u76f8\u4e92\u4f9d\u8d56\u5173\u7cfb\u53ca\u6027\u80fd\u6743\u8861\u3002", "result": "\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u8054\u5408\u591a\u57df\u4f18\u5316\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5176\u5728\u63d0\u5347ISAC\u6027\u80fd\u65b9\u9762\u7684\u6f5c\u529b\u3002", "conclusion": "\u672c\u6587\u4e3a\u667a\u80fd\u53ef\u6269\u5c55\u7684ISAC\u67b6\u6784\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u5e76\u6307\u51fa\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\uff0c\u4ee5\u63a8\u52a8\u5176\u5728\u5b9e\u9645\u7f51\u7edc\u4e2d\u7684\u90e8\u7f72\u3002"}}
{"id": "2506.15759", "categories": ["cs.SD", "cs.MM", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.15759", "abs": "https://arxiv.org/abs/2506.15759", "authors": ["Siyi Xie", "Hanxin Zhu", "Tianyu He", "Xin Li", "Zhibo Chen"], "title": "Sonic4D: Spatial Audio Generation for Immersive 4D Scene Exploration", "comment": "17 pages, 7 figures. Project page:\n  https://x-drunker.github.io/Sonic4D-project-page/", "summary": "Recent advancements in 4D generation have demonstrated its remarkable\ncapability in synthesizing photorealistic renderings of dynamic 3D scenes.\nHowever, despite achieving impressive visual performance, almost all existing\nmethods overlook the generation of spatial audio aligned with the corresponding\n4D scenes, posing a significant limitation to truly immersive audiovisual\nexperiences. To mitigate this issue, we propose Sonic4D, a novel framework that\nenables spatial audio generation for immersive exploration of 4D scenes.\nSpecifically, our method is composed of three stages: 1) To capture both the\ndynamic visual content and raw auditory information from a monocular video, we\nfirst employ pre-trained expert models to generate the 4D scene and its\ncorresponding monaural audio. 2) Subsequently, to transform the monaural audio\ninto spatial audio, we localize and track the sound sources within the 4D\nscene, where their 3D spatial coordinates at different timestamps are estimated\nvia a pixel-level visual grounding strategy. 3) Based on the estimated sound\nsource locations, we further synthesize plausible spatial audio that varies\nacross different viewpoints and timestamps using physics-based simulation.\nExtensive experiments have demonstrated that our proposed method generates\nrealistic spatial audio consistent with the synthesized 4D scene in a\ntraining-free manner, significantly enhancing the immersive experience for\nusers. Generated audio and video examples are available at\nhttps://x-drunker.github.io/Sonic4D-project-page.", "AI": {"tldr": "Sonic4D\u662f\u4e00\u4e2a\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u4e3a4D\u573a\u666f\u751f\u6210\u7a7a\u95f4\u97f3\u9891\uff0c\u63d0\u5347\u6c89\u6d78\u5f0f\u4f53\u9a8c\u3002", "motivation": "\u73b0\u67094D\u751f\u6210\u65b9\u6cd5\u5ffd\u7565\u4e86\u7a7a\u95f4\u97f3\u9891\u7684\u751f\u6210\uff0c\u9650\u5236\u4e86\u6c89\u6d78\u5f0f\u4f53\u9a8c\u3002", "method": "\u5206\u4e3a\u4e09\u4e2a\u9636\u6bb5\uff1a1) \u751f\u62104D\u573a\u666f\u548c\u5355\u58f0\u9053\u97f3\u9891\uff1b2) \u901a\u8fc7\u89c6\u89c9\u5b9a\u4f4d\u7b56\u7565\u4f30\u8ba1\u58f0\u6e90\u4f4d\u7f6e\uff1b3) \u57fa\u4e8e\u7269\u7406\u6a21\u62df\u5408\u6210\u7a7a\u95f4\u97f3\u9891\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u751f\u6210\u4e0e4D\u573a\u666f\u4e00\u81f4\u7684\u771f\u5b9e\u7a7a\u95f4\u97f3\u9891\uff0c\u65e0\u9700\u8bad\u7ec3\u3002", "conclusion": "Sonic4D\u663e\u8457\u63d0\u5347\u4e864D\u573a\u666f\u7684\u6c89\u6d78\u5f0f\u4f53\u9a8c\u3002"}}
{"id": "2506.16231", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2506.16231", "abs": "https://arxiv.org/abs/2506.16231", "authors": ["Doyeop Kwak", "Youngjoon Jang", "Seongyu Kim", "Joon Son Chung"], "title": "EDNet: A Distortion-Agnostic Speech Enhancement Framework with Gating Mamba Mechanism and Phase Shift-Invariant Training", "comment": null, "summary": "Speech signals in real-world environments are frequently affected by various\ndistortions such as additive noise, reverberation, and bandwidth limitation,\nwhich may appear individually or in combination. Traditional speech enhancement\nmethods typically rely on either masking, which focuses on suppressing\nnon-speech components while preserving observable structure, or mapping, which\nseeks to recover clean speech through direct transformation of the input. Each\napproach offers strengths in specific scenarios but may be less effective\noutside its target conditions. We propose the Erase and Draw Network (EDNet), a\ndistortion-agnostic speech enhancement framework designed to handle a broad\nrange of distortion types without prior assumptions about task or input\ncharacteristics. EDNet consists of two main components: (1) the Gating Mamba\n(GM) module, which adaptively combines masking and mapping through a learnable\ngating mechanism that selects between suppression (Erase) and reconstruction\n(Draw) based on local signal features, and (2) Phase Shift-Invariant Training\n(PSIT), a shift tolerant supervision strategy that improves phase estimation by\nenabling dynamic alignment during training while remaining compatible with\nstandard loss functions. Experimental results on denoising, dereverberation,\nbandwidth extension, and multi distortion enhancement tasks show that EDNet\nconsistently achieves strong performance across conditions, demonstrating its\narchitectural flexibility and adaptability to diverse task settings.", "AI": {"tldr": "EDNet\u662f\u4e00\u4e2a\u901a\u7528\u7684\u8bed\u97f3\u589e\u5f3a\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u63a9\u853d\u548c\u6620\u5c04\u6280\u672f\uff0c\u9002\u5e94\u591a\u79cd\u5931\u771f\u7c7b\u578b\uff0c\u65e0\u9700\u4efb\u52a1\u6216\u8f93\u5165\u7684\u5148\u9a8c\u5047\u8bbe\u3002", "motivation": "\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u8bed\u97f3\u4fe1\u53f7\u5e38\u53d7\u591a\u79cd\u5931\u771f\u5f71\u54cd\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u6548\u679c\u6709\u9650\uff0c\u9700\u66f4\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "EDNet\u5305\u542bGating Mamba\u6a21\u5757\uff08\u81ea\u9002\u5e94\u9009\u62e9\u63a9\u853d\u6216\u91cd\u5efa\uff09\u548cPhase Shift-Invariant Training\uff08\u6539\u8fdb\u76f8\u4f4d\u4f30\u8ba1\uff09\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cEDNet\u5728\u53bb\u566a\u3001\u53bb\u6df7\u54cd\u3001\u5e26\u5bbd\u6269\u5c55\u548c\u591a\u5931\u771f\u589e\u5f3a\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "EDNet\u5177\u6709\u67b6\u6784\u7075\u6d3b\u6027\u548c\u9002\u5e94\u6027\uff0c\u9002\u7528\u4e8e\u591a\u6837\u5316\u7684\u8bed\u97f3\u589e\u5f3a\u4efb\u52a1\u3002"}}
{"id": "2506.16070", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16070", "abs": "https://arxiv.org/abs/2506.16070", "authors": ["Mathushaharan Rathakrishnan", "Samiru Gayan", "Rohit Singh", "Amandeep Kaur", "Hazer Inaltekin", "Sampath Edirisinghe", "H. Vincent Poor"], "title": "Towards AI-Driven RANs for 6G and Beyond: Architectural Advancements and Future Horizons", "comment": null, "summary": "It is envisioned that 6G networks will be supported by key architectural\nprinciples, including intelligence, decentralization, interoperability, and\ndigitalization. With the advances in artificial intelligence (AI) and machine\nlearning (ML), embedding intelligence into the foundation of wireless\ncommunication systems is recognized as essential for 6G and beyond. Existing\nradio access network (RAN) architectures struggle to meet the ever growing\ndemands for flexibility, automation, and adaptability required to build\nself-evolving and autonomous wireless networks. In this context, this paper\nexplores the transition towards AI-driven RAN (AI-RAN) by developing a novel\nAI-RAN framework whose performance is evaluated through a practical scenario\nfocused on intelligent orchestration and resource optimization. Besides, the\npaper reviews the evolution of RAN architectures and sheds light on key\nenablers of AI-RAN including digital twins (DTs), intelligent reflecting\nsurfaces (IRSs), large generative AI (GenAI) models, and blockchain (BC).\nFurthermore, it discusses the deployment challenges of AI-RAN, including\ntechnical and regulatory perspectives, and outlines future research directions\nincorporating technologies such as integrated sensing and communication (ISAC)\nand agentic AI.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e866G\u7f51\u7edc\u4e2dAI\u9a71\u52a8\u7684\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\uff08AI-RAN\uff09\u7684\u8fc7\u6e21\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578bAI-RAN\u6846\u67b6\uff0c\u5e76\u901a\u8fc7\u5b9e\u9645\u573a\u666f\u8bc4\u4f30\u5176\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\u67b6\u6784\u96be\u4ee5\u6ee1\u8db3\u7075\u6d3b\u6027\u3001\u81ea\u52a8\u5316\u548c\u9002\u5e94\u6027\u7684\u9700\u6c42\uff0c\u963b\u788d\u4e86\u81ea\u6f14\u8fdb\u548c\u81ea\u4e3b\u65e0\u7ebf\u7f51\u7edc\u7684\u53d1\u5c55\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u79cd\u65b0\u578bAI-RAN\u6846\u67b6\uff0c\u5e76\u8bc4\u4f30\u5176\u5728\u667a\u80fd\u7f16\u6392\u548c\u8d44\u6e90\u4f18\u5316\u65b9\u9762\u7684\u6027\u80fd\u3002", "result": "\u8bba\u6587\u5c55\u793a\u4e86AI-RAN\u6846\u67b6\u7684\u5b9e\u9645\u5e94\u7528\u6548\u679c\uff0c\u5e76\u8ba8\u8bba\u4e86\u5176\u5173\u952e\u652f\u6301\u6280\u672f\uff08\u5982\u6570\u5b57\u5b6a\u751f\u3001\u667a\u80fd\u53cd\u5c04\u9762\u7b49\uff09\u3002", "conclusion": "AI-RAN\u662f6G\u7f51\u7edc\u7684\u91cd\u8981\u53d1\u5c55\u65b9\u5411\uff0c\u4f46\u4ecd\u9762\u4e34\u6280\u672f\u548c\u76d1\u7ba1\u6311\u6218\uff0c\u672a\u6765\u9700\u7ed3\u5408\u96c6\u6210\u611f\u77e5\u901a\u4fe1\u548c\u4ee3\u7406AI\u7b49\u6280\u672f\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2506.16020", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16020", "abs": "https://arxiv.org/abs/2506.16020", "authors": ["Zijing Zhao", "Kai Wang", "Hao Huang", "Ying Hu", "Liang He", "Jichen Yang"], "title": "VS-Singer: Vision-Guided Stereo Singing Voice Synthesis with Consistency Schr\u00f6dinger Bridge", "comment": "Accepted by Interspeech 2025", "summary": "To explore the potential advantages of utilizing spatial cues from images for\ngenerating stereo singing voices with room reverberation, we introduce\nVS-Singer, a vision-guided model designed to produce stereo singing voices with\nroom reverberation from scene images. VS-Singer comprises three modules:\nfirstly, a modal interaction network integrates spatial features into text\nencoding to create a linguistic representation enriched with spatial\ninformation. Secondly, the decoder employs a consistency Schr\\\"odinger bridge\nto facilitate one-step sample generation. Moreover, we utilize the SFE module\nto improve the consistency of audio-visual matching. To our knowledge, this\nstudy is the first to combine stereo singing voice synthesis with visual\nacoustic matching within a unified framework. Experimental results demonstrate\nthat VS-Singer can effectively generate stereo singing voices that align with\nthe scene perspective in a single step.", "AI": {"tldr": "VS-Singer\u662f\u4e00\u4e2a\u89c6\u89c9\u5f15\u5bfc\u6a21\u578b\uff0c\u901a\u8fc7\u573a\u666f\u56fe\u50cf\u751f\u6210\u5e26\u6709\u623f\u95f4\u6df7\u54cd\u7684\u7acb\u4f53\u6b4c\u58f0\u3002", "motivation": "\u63a2\u7d22\u5229\u7528\u56fe\u50cf\u7a7a\u95f4\u7ebf\u7d22\u751f\u6210\u5e26\u6709\u623f\u95f4\u6df7\u54cd\u7684\u7acb\u4f53\u6b4c\u58f0\u7684\u6f5c\u5728\u4f18\u52bf\u3002", "method": "\u6a21\u578b\u5305\u542b\u4e09\u4e2a\u6a21\u5757\uff1a\u6a21\u6001\u4ea4\u4e92\u7f51\u7edc\u3001\u4e00\u81f4\u6027Schr\u00f6dinger\u6865\u89e3\u7801\u5668\u548cSFE\u6a21\u5757\u3002", "result": "\u5b9e\u9a8c\u8bc1\u660eVS-Singer\u80fd\u6709\u6548\u4e00\u6b65\u751f\u6210\u4e0e\u573a\u666f\u89c6\u89d2\u4e00\u81f4\u7684\u7acb\u4f53\u6b4c\u58f0\u3002", "conclusion": "\u8be5\u7814\u7a76\u9996\u6b21\u5c06\u7acb\u4f53\u6b4c\u58f0\u5408\u6210\u4e0e\u89c6\u89c9\u58f0\u5b66\u5339\u914d\u7ed3\u5408\u5728\u4e00\u4e2a\u7edf\u4e00\u6846\u67b6\u4e2d\u3002"}}
{"id": "2506.16741", "categories": ["eess.AS", "cs.AI"], "pdf": "https://arxiv.org/pdf/2506.16741", "abs": "https://arxiv.org/abs/2506.16741", "authors": ["Hyun Joon Park", "Jeongmin Liu", "Jin Sob Kim", "Jeong Yeol Yang", "Sung Won Han", "Eunwoo Song"], "title": "RapFlow-TTS: Rapid and High-Fidelity Text-to-Speech with Improved Consistency Flow Matching", "comment": "Accepted on Interspeech 2025", "summary": "We introduce RapFlow-TTS, a rapid and high-fidelity TTS acoustic model that\nleverages velocity consistency constraints in flow matching (FM) training.\nAlthough ordinary differential equation (ODE)-based TTS generation achieves\nnatural-quality speech, it typically requires a large number of generation\nsteps, resulting in a trade-off between quality and inference speed. To address\nthis challenge, RapFlow-TTS enforces consistency in the velocity field along\nthe FM-straightened ODE trajectory, enabling consistent synthetic quality with\nfewer generation steps. Additionally, we introduce techniques such as time\ninterval scheduling and adversarial learning to further enhance the quality of\nthe few-step synthesis. Experimental results show that RapFlow-TTS achieves\nhigh-fidelity speech synthesis with a 5- and 10-fold reduction in synthesis\nsteps than the conventional FM- and score-based approaches, respectively.", "AI": {"tldr": "RapFlow-TTS\u662f\u4e00\u79cd\u5feb\u901f\u9ad8\u4fdd\u771f\u7684TTS\u58f0\u5b66\u6a21\u578b\uff0c\u901a\u8fc7\u6d41\u5339\u914d\u8bad\u7ec3\u4e2d\u7684\u901f\u5ea6\u4e00\u81f4\u6027\u7ea6\u675f\uff0c\u51cf\u5c11\u751f\u6210\u6b65\u9aa4\uff0c\u540c\u65f6\u4fdd\u6301\u5408\u6210\u8d28\u91cf\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8eODE\u7684TTS\u751f\u6210\u9700\u8981\u5927\u91cf\u6b65\u9aa4\uff0c\u5bfc\u81f4\u8d28\u91cf\u4e0e\u63a8\u7406\u901f\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u3002RapFlow-TTS\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5229\u7528\u6d41\u5339\u914d\u8bad\u7ec3\u4e2d\u7684\u901f\u5ea6\u4e00\u81f4\u6027\u7ea6\u675f\uff0c\u7ed3\u5408\u65f6\u95f4\u95f4\u9694\u8c03\u5ea6\u548c\u5bf9\u6297\u5b66\u4e60\u6280\u672f\uff0c\u51cf\u5c11\u751f\u6210\u6b65\u9aa4\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0cRapFlow-TTS\u5728\u5408\u6210\u6b65\u9aa4\u4e0a\u6bd4\u4f20\u7edf\u65b9\u6cd5\u51cf\u5c115-10\u500d\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u4fdd\u771f\u8bed\u97f3\u5408\u6210\u3002", "conclusion": "RapFlow-TTS\u6210\u529f\u5b9e\u73b0\u4e86\u5feb\u901f\u4e14\u9ad8\u8d28\u91cf\u7684\u8bed\u97f3\u5408\u6210\uff0c\u4e3aTTS\u9886\u57df\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16184", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16184", "abs": "https://arxiv.org/abs/2506.16184", "authors": ["Shan Shan", "Chongjun Ouyang", "Yong Li", "Yuanwei Liu"], "title": "Multigroup Multicast Design for Pinching-Antenna Systems: Waveguide-Division or Waveguide-Multiplexing?", "comment": null, "summary": "This article addresses the design of multigroup multicast communications in\nthe pinching-antenna system (PASS). A PASS-enabled multigroup transmission\nframework is proposed to maximize multicast rates under a couple of\ntransmission architectures: waveguide-division (WD) and waveguide-multiplexing\n(WM). 1) For WD, an element-wise sequential optimization strategy is proposed\nfor pinching beamforming, i.e., optimizing the activated positions of pinching\nantennas along dielectric waveguides. Meanwhile, a log-sum-exp projected\ngradient descent algorithm is proposed for transmit power allocation across\nwaveguides. 2) For WM, a majorization-minimization (MM)-based framework is\nproposed to tackle the problem's non-smoothness and non-convexity. On this\nbasis, a low-complexity element-wise sequential optimization method is\ndeveloped for pinching beamforming using the MM surrogate objective.\nFurthermore, the optimal transmit beamformer structure is derived from the MM\nsurrogate objective using the Lagrange duality, with an efficient transmit\nbeamforming algorithm proposed using projected adaptive gradient descent.\nNumerical results demonstrate that: i) both WD and WM architectures in PASS\nachieve significant multicast rate improvements over conventional MIMO\ntechniques, especially for systems with large service areas; ii) WM is more\nrobust than WD in dense deployments, while WD excels when user groups are\nspatially separated.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8ePASS\u7684\u591a\u7ec4\u591a\u64ad\u901a\u4fe1\u8bbe\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7WD\u548cWM\u4e24\u79cd\u67b6\u6784\u4f18\u5316\u591a\u64ad\u901f\u7387\uff0c\u5e76\u63d0\u51fa\u4e86\u76f8\u5e94\u7684\u6ce2\u675f\u6210\u5f62\u548c\u529f\u7387\u5206\u914d\u7b97\u6cd5\u3002", "motivation": "\u89e3\u51b3PASS\u7cfb\u7edf\u4e2d\u591a\u7ec4\u591a\u64ad\u901a\u4fe1\u7684\u8bbe\u8ba1\u95ee\u9898\uff0c\u4ee5\u6700\u5927\u5316\u591a\u64ad\u901f\u7387\u3002", "method": "1) WD\u67b6\u6784\uff1a\u91c7\u7528\u5143\u7d20\u7ea7\u987a\u5e8f\u4f18\u5316\u7b56\u7565\u548clog-sum-exp\u6295\u5f71\u68af\u5ea6\u4e0b\u964d\u7b97\u6cd5\uff1b2) WM\u67b6\u6784\uff1a\u57fa\u4e8eMM\u6846\u67b6\u5904\u7406\u975e\u5149\u6ed1\u548c\u975e\u51f8\u95ee\u9898\uff0c\u5e76\u5f00\u53d1\u4f4e\u590d\u6742\u5ea6\u4f18\u5316\u65b9\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0cPASS\u7684WD\u548cWM\u67b6\u6784\u5728\u591a\u64ad\u901f\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edfMIMO\u6280\u672f\uff0cWM\u5728\u5bc6\u96c6\u90e8\u7f72\u4e2d\u66f4\u7a33\u5065\uff0cWD\u5728\u7528\u6237\u7ec4\u7a7a\u95f4\u5206\u79bb\u65f6\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "PASS\u7cfb\u7edf\u5728\u591a\u64ad\u901a\u4fe1\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0cWD\u548cWM\u67b6\u6784\u5404\u6709\u9002\u7528\u573a\u666f\u3002"}}
{"id": "2506.16127", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16127", "abs": "https://arxiv.org/abs/2506.16127", "authors": ["Shoutrik Das", "Nishant Singh", "Arjun Gangwar", "S Umesh"], "title": "Improved Intelligibility of Dysarthric Speech using Conditional Flow Matching", "comment": "Accepted at Interspeech 2025", "summary": "Dysarthria is a neurological disorder that significantly impairs speech\nintelligibility, often rendering affected individuals unable to communicate\neffectively. This necessitates the development of robust dysarthric-to-regular\nspeech conversion techniques. In this work, we investigate the utility and\nlimitations of self-supervised learning (SSL) features and their quantized\nrepresentations as an alternative to mel-spectrograms for speech generation.\nAdditionally, we explore methods to mitigate speaker variability by generating\nclean speech in a single-speaker voice using features extracted from WavLM. To\nthis end, we propose a fully non-autoregressive approach that leverages\nConditional Flow Matching (CFM) with Diffusion Transformers to learn a direct\nmapping from dysarthric to clean speech. Our findings highlight the\neffectiveness of discrete acoustic units in improving intelligibility while\nachieving faster convergence compared to traditional mel-spectrogram-based\napproaches.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u5229\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u7279\u5f81\u53ca\u5176\u91cf\u5316\u8868\u793a\u66ff\u4ee3\u6885\u5c14\u9891\u8c31\u8fdb\u884c\u8bed\u97f3\u751f\u6210\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u6d41\u5339\u914d\u548c\u6269\u6563\u53d8\u6362\u5668\u7684\u975e\u81ea\u56de\u5f52\u65b9\u6cd5\uff0c\u7528\u4e8e\u5c06\u6784\u97f3\u969c\u788d\u8bed\u97f3\u8f6c\u6362\u4e3a\u6e05\u6670\u8bed\u97f3\u3002", "motivation": "\u6784\u97f3\u969c\u788d\u4e25\u91cd\u5f71\u54cd\u8bed\u97f3\u6e05\u6670\u5ea6\uff0c\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u8bed\u97f3\u8f6c\u6362\u6280\u672f\u3002", "method": "\u91c7\u7528\u81ea\u76d1\u7763\u5b66\u4e60\u7279\u5f81\u548c\u91cf\u5316\u8868\u793a\uff0c\u7ed3\u5408\u6761\u4ef6\u6d41\u5339\u914d\u4e0e\u6269\u6563\u53d8\u6362\u5668\uff0c\u5b9e\u73b0\u975e\u81ea\u56de\u5f52\u7684\u8bed\u97f3\u8f6c\u6362\u3002", "result": "\u79bb\u6563\u58f0\u5b66\u5355\u5143\u663e\u8457\u63d0\u9ad8\u4e86\u8bed\u97f3\u6e05\u6670\u5ea6\uff0c\u4e14\u6536\u655b\u901f\u5ea6\u4f18\u4e8e\u4f20\u7edf\u6885\u5c14\u9891\u8c31\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u63d0\u5347\u6784\u97f3\u969c\u788d\u8bed\u97f3\u6e05\u6670\u5ea6\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4e14\u6548\u7387\u66f4\u9ad8\u3002"}}
{"id": "2506.16751", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16751", "abs": "https://arxiv.org/abs/2506.16751", "authors": ["Akanksha Singh", "Yi-Ping Phoebe Chen", "Vipul Arora"], "title": "H-QuEST: Accelerating Query-by-Example Spoken Term Detection with Hierarchical Indexing", "comment": null, "summary": "Query-by-example spoken term detection (QbE-STD) searches for matching words\nor phrases in an audio dataset using a sample spoken query. When annotated data\nis limited or unavailable, QbE-STD is often done using template matching\nmethods like dynamic time warping (DTW), which are computationally expensive\nand do not scale well. To address this, we propose H-QuEST (Hierarchical\nQuery-by-Example Spoken Term Detection), a novel framework that accelerates\nspoken term retrieval by utilizing Term Frequency and Inverse Document\nFrequency (TF-IDF)-based sparse representations obtained through advanced audio\nrepresentation learning techniques and Hierarchical Navigable Small World\n(HNSW) indexing with further refinement. Experimental results show that H-QuEST\ndelivers substantial improvements in retrieval speed without sacrificing\naccuracy compared to existing methods.", "AI": {"tldr": "H-QuEST\u6846\u67b6\u901a\u8fc7TF-IDF\u7a00\u758f\u8868\u793a\u548cHNSW\u7d22\u5f15\u52a0\u901fQbE-STD\uff0c\u663e\u8457\u63d0\u5347\u68c0\u7d22\u901f\u5ea6\u4e14\u4e0d\u635f\u5931\u51c6\u786e\u6027\u3002", "motivation": "\u4f20\u7edf\u6a21\u677f\u5339\u914d\u65b9\u6cd5\uff08\u5982DTW\uff09\u5728\u6807\u6ce8\u6570\u636e\u6709\u9650\u65f6\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u6269\u5c55\u6027\u5dee\uff0c\u9700\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7ed3\u5408TF-IDF\u7a00\u758f\u8868\u793a\u548cHNSW\u7d22\u5f15\uff0c\u901a\u8fc7\u5206\u5c42\u7ed3\u6784\u4f18\u5316\u68c0\u7d22\u8fc7\u7a0b\u3002", "result": "\u5b9e\u9a8c\u663e\u793aH-QuEST\u5728\u68c0\u7d22\u901f\u5ea6\u4e0a\u6709\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u51c6\u786e\u6027\u3002", "conclusion": "H-QuEST\u4e3aQbE-STD\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16191", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16191", "abs": "https://arxiv.org/abs/2506.16191", "authors": ["Hyeonho Noh", "Hyeonsu Lyu", "Moe Z. Win", "Hyun Jong Yang"], "title": "DCFNet: Doppler Correction Filter Network for Integrated Sensing and Communication in Multi-User MIMO-OFDM Systems", "comment": null, "summary": "Integrated sensing and communication (ISAC) is a headline feature for the\nforthcoming IMT-2030 and 6G releases, yet a concrete solution that fits within\nthe established orthogonal frequency division multiplexing (OFDM) family\nremains open. Specifically, Doppler-induced inter-carrier interference (ICI)\ndestroys sub-carrier orthogonality of OFDM sensing signals, blurring\nrange-velocity maps and severely degrading sensing accuracy. Building on\nmulti-user multi-input-multi-output (MIMO) OFDM systems, this paper proposes\nDoppler-Correction Filter Network (DCFNet), an AI-native ISAC model that\ndelivers fine range-velocity resolution at minimal complexity without altering\nthe legacy frame structure. A bank of DCFs first shifts dominant ICI energy\naway from critical Doppler bins; a compact deep learning network then\nsuppresses the ICI. To further enhance the range and velocity resolutions, we\npropose DCFNet with local refinement (DCFNet-LR), which applies a generalized\nlikelihood ratio test (GLRT) to refine target estimates of DCFNet to sub-cell\naccuracy. Simulation results show that DCFNet-LR runs $143\\times$ faster than\nmaximum likelihood search and achieves significantly superior performance,\nreducing the range RMSE by up to $2.7 \\times 10^{-4}$ times and the velocity\nRMSE by $6.7 \\times 10^{-4}$ times compared to conventional detection methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDCFNet\u7684AI\u539f\u751fISAC\u6a21\u578b\uff0c\u7528\u4e8e\u89e3\u51b3OFDM\u7cfb\u7edf\u4e2d\u591a\u666e\u52d2\u6548\u5e94\u5f15\u8d77\u7684ICI\u95ee\u9898\uff0c\u5e76\u901a\u8fc7DCFNet-LR\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u8303\u56f4\u548c\u901f\u5ea6\u5206\u8fa8\u7387\u3002", "motivation": "\u89e3\u51b3OFDM\u7cfb\u7edf\u4e2d\u591a\u666e\u52d2\u6548\u5e94\u5bfc\u81f4\u7684ICI\u95ee\u9898\uff0c\u63d0\u5347ISAC\u7684\u611f\u77e5\u7cbe\u5ea6\u3002", "method": "\u63d0\u51faDCFNet\u6a21\u578b\uff0c\u7ed3\u5408\u591a\u7528\u6237MIMO OFDM\u7cfb\u7edf\uff0c\u901a\u8fc7Doppler-Correction Filter\u548c\u6df1\u5ea6\u5b66\u4e60\u7f51\u7edc\u6291\u5236ICI\uff0c\u5e76\u5f15\u5165DCFNet-LR\u8fdb\u884c\u5c40\u90e8\u4f18\u5316\u3002", "result": "DCFNet-LR\u6bd4\u6700\u5927\u4f3c\u7136\u641c\u7d22\u5feb143\u500d\uff0c\u8303\u56f4\u548c\u901f\u5ea6RMSE\u5206\u522b\u964d\u4f4e\u81f32.7\u00d710^-4\u548c6.7\u00d710^-4\u500d\u3002", "conclusion": "DCFNet\u548cDCFNet-LR\u663e\u8457\u63d0\u5347\u4e86ISAC\u7684\u611f\u77e5\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4f4e\u590d\u6742\u5ea6\u3002"}}
{"id": "2506.16225", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16225", "abs": "https://arxiv.org/abs/2506.16225", "authors": ["Jiale Liu", "Dandan Peng", "Huan Wang", "Chenyu Liu", "Yan-Fu Li", "Min Xie"], "title": "AeroGPT: Leveraging Large-Scale Audio Model for Aero-Engine Bearing Fault Diagnosis", "comment": null, "summary": "Aerospace engines, as critical components in aviation and aerospace\nindustries, require continuous and accurate fault diagnosis to ensure\noperational safety and prevent catastrophic failures. While deep learning\ntechniques have been extensively studied in this context, they output logits or\nconfidence scores, necessitating post-processing to derive actionable insights.\nFurthermore, the potential of large-scale audio models in this domain remains\nlargely untapped. To address these limitations, this paper proposes AeroGPT, a\nnovel framework that transfers knowledge from general audio domain to\naero-engine bearing fault diagnosis. AeroGPT is a framework based on\nlarge-scale audio model that incorporates Vibration Signal Alignment (VSA) to\nadapt general audio knowledge to domain-specific vibration patterns, and\ncombines Generative Fault Classification (GFC) to directly output interpretable\nfault labels. This approach eliminates the need for post-processing of fault\nlabels, supports interactive, interpretable, and actionable fault diagnosis,\nthereby greatly enhancing industrial applicability. Through comprehensive\nexperimental validation on two aero-engine bearing datasets, AeroGPT achieved\nexceptional performance with 98.94% accuracy on the DIRG dataset and perfect\n100% classification on the HIT bearing dataset, surpassing traditional deep\nlearning approaches. Additional Qualitative analysis validates the\neffectiveness of our approach and highlights the potential of large-scale\nmodels to revolutionize fault diagnosis.", "AI": {"tldr": "AeroGPT\u662f\u4e00\u4e2a\u57fa\u4e8e\u5927\u89c4\u6a21\u97f3\u9891\u6a21\u578b\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u632f\u52a8\u4fe1\u53f7\u5bf9\u9f50\u548c\u751f\u6210\u5f0f\u6545\u969c\u5206\u7c7b\uff0c\u76f4\u63a5\u8f93\u51fa\u53ef\u89e3\u91ca\u7684\u6545\u969c\u6807\u7b7e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u822a\u7a7a\u53d1\u52a8\u673a\u8f74\u627f\u6545\u969c\u8bca\u65ad\u7684\u51c6\u786e\u6027\u548c\u5b9e\u7528\u6027\u3002", "motivation": "\u822a\u7a7a\u53d1\u52a8\u673a\u7684\u6545\u969c\u8bca\u65ad\u9700\u8981\u9ad8\u7cbe\u5ea6\u548c\u53ef\u64cd\u4f5c\u6027\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u9700\u540e\u5904\u7406\u4e14\u672a\u5145\u5206\u5229\u7528\u5927\u89c4\u6a21\u97f3\u9891\u6a21\u578b\u7684\u6f5c\u529b\u3002", "method": "\u63d0\u51faAeroGPT\u6846\u67b6\uff0c\u7ed3\u5408\u632f\u52a8\u4fe1\u53f7\u5bf9\u9f50\uff08VSA\uff09\u548c\u751f\u6210\u5f0f\u6545\u969c\u5206\u7c7b\uff08GFC\uff09\uff0c\u76f4\u63a5\u8f93\u51fa\u6545\u969c\u6807\u7b7e\u3002", "result": "\u5728DIRG\u6570\u636e\u96c6\u4e0a\u8fbe\u523098.94%\u51c6\u786e\u7387\uff0cHIT\u8f74\u627f\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0100%\u5206\u7c7b\u51c6\u786e\u7387\u3002", "conclusion": "AeroGPT\u5c55\u793a\u4e86\u5927\u89c4\u6a21\u6a21\u578b\u5728\u6545\u969c\u8bca\u65ad\u4e2d\u7684\u6f5c\u529b\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002"}}
{"id": "2506.16969", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2506.16969", "abs": "https://arxiv.org/abs/2506.16969", "authors": ["Aref Farhadipour", "Homayoon Beigi", "Volker Dellwo", "Hadi Veisi"], "title": "State-Space Models in Efficient Whispered and Multi-dialect Speech Recognition", "comment": "paper is in 4+1 pages", "summary": "Whispered speech recognition presents significant challenges for conventional\nautomatic speech recognition systems, particularly when combined with dialect\nvariation. However, utilizing an efficient method to solve this problem using a\nlow-range dataset and processing load is beneficial. This paper proposes a\nsolution using a Mamba-based state-space model and four fine-tuned\nself-supervised models consisting of Wav2Vec2, WavLM, HuBERT, and Whisper to\naddress the dual challenges of whispered speech and dialect diversity. Based on\nour knowledge, this represents the best performance reported on the wTIMIT and\nCHAINS datasets for whispered speech recognition. We trained the models using\nwhispered and normal speech data across Singaporean, US, and Irish dialects.\nThe findings demonstrated that utilizing the proposed Mamba-based model could\nwork as a highly efficient model trained with low amounts of whispered data to\nsimultaneously work on whispered and normal speech recognition. The code for\nthis work is freely available.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eMamba\u7684\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u548c\u56db\u79cd\u81ea\u76d1\u7763\u6a21\u578b\uff08Wav2Vec2\u3001WavLM\u3001HuBERT\u3001Whisper\uff09\uff0c\u7528\u4e8e\u89e3\u51b3\u4f4e\u8bed\u8bed\u97f3\u8bc6\u522b\u548c\u65b9\u8a00\u591a\u6837\u6027\u7684\u53cc\u91cd\u6311\u6218\uff0c\u5e76\u5728wTIMIT\u548cCHAINS\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u5728\u5904\u7406\u4f4e\u8bed\u8bed\u97f3\u548c\u65b9\u8a00\u53d8\u5316\u65f6\u9762\u4e34\u663e\u8457\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u4e14\u4f4e\u8d44\u6e90\u6d88\u8017\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eMamba\u7684\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u548c\u56db\u79cd\u81ea\u76d1\u7763\u6a21\u578b\uff08Wav2Vec2\u3001WavLM\u3001HuBERT\u3001Whisper\uff09\uff0c\u7ed3\u5408\u65b0\u52a0\u5761\u3001\u7f8e\u56fd\u548c\u7231\u5c14\u5170\u65b9\u8a00\u7684\u4f4e\u8bed\u548c\u6b63\u5e38\u8bed\u97f3\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728wTIMIT\u548cCHAINS\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u8be5\u6a21\u578b\u5728\u4f4e\u8bed\u6570\u636e\u91cf\u4e0b\u9ad8\u6548\u5904\u7406\u4f4e\u8bed\u548c\u6b63\u5e38\u8bed\u97f3\u8bc6\u522b\u7684\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684Mamba\u6a21\u578b\u662f\u4e00\u79cd\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u4f4e\u8bed\u548c\u6b63\u5e38\u8bed\u97f3\u8bc6\u522b\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002"}}
{"id": "2506.16198", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16198", "abs": "https://arxiv.org/abs/2506.16198", "authors": ["Haofan Dong", "Ozgur B. Akan"], "title": "MASC: Integrated Sensing and Communications for the Martian Internet of Space", "comment": "11 pages, 9 figures, journal", "summary": "Mars exploration missions increasingly demand reliable communication systems,\nyet harsh environmental conditions -- particularly frequent dust storms,\nextreme Doppler effects, and stringent resource constraints -- pose\nunprecedented challenges to conventional communication approaches. This paper\npresents the Martian Adaptive Sensing and Communication (MASC) system\nspecifically designed for the Martian environment. MASC establishes a\nphysically interpretable channel model and develops three key components:\nenvironment-aware hybrid precoding, adaptive parameter mapping, and robust\ncommunication precoding. Simulation results demonstrate that MASC maintains 45\npercent sensing coverage under severe dust conditions compared to only 5\npercent with conventional methods, provides up to 2.5 dB\nsignal-to-interference-plus-noise ratio (SINR) improvement at 50 percent\nchannel state information (CSI) uncertainty, and yields 80 percent higher\ncapacity in moderate dust storms. Using an epsilon-constraint multi-objective\noptimization approach, we enable mission planners to select operational modes\nranging from communication-priority (0.33 bps/Hz capacity, 28 percent sensing\ncoverage) to sensing-priority (90 percent coverage with minimal capacity),\noffering a versatile framework that balances environmental awareness with\nhyper-reliable data transmission. This work provides a validated blueprint for\nintegrated sensing and communication (ISAC) in non-terrestrial networks (NTN),\na key enabler for achieving ubiquitous connectivity in the 6G era.", "AI": {"tldr": "MASC\u7cfb\u7edf\u4e3a\u706b\u661f\u73af\u5883\u8bbe\u8ba1\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6280\u672f\u63d0\u5347\u901a\u4fe1\u548c\u611f\u77e5\u6027\u80fd\uff0c\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "motivation": "\u706b\u661f\u63a2\u7d22\u4efb\u52a1\u9700\u8981\u53ef\u9760\u7684\u901a\u4fe1\u7cfb\u7edf\uff0c\u4f46\u6781\u7aef\u73af\u5883\u6761\u4ef6\uff08\u5982\u6c99\u5c18\u66b4\u3001\u591a\u666e\u52d2\u6548\u5e94\u548c\u8d44\u6e90\u9650\u5236\uff09\u5bf9\u4f20\u7edf\u65b9\u6cd5\u6784\u6210\u6311\u6218\u3002", "method": "MASC\u7cfb\u7edf\u5305\u62ec\u73af\u5883\u611f\u77e5\u6df7\u5408\u9884\u7f16\u7801\u3001\u81ea\u9002\u5e94\u53c2\u6570\u6620\u5c04\u548c\u9c81\u68d2\u901a\u4fe1\u9884\u7f16\u7801\uff0c\u91c7\u7528\u591a\u76ee\u6807\u4f18\u5316\u65b9\u6cd5\u3002", "result": "MASC\u5728\u6076\u52a3\u6761\u4ef6\u4e0b\u4fdd\u630145%\u611f\u77e5\u8986\u76d6\u7387\uff08\u4f20\u7edf\u65b9\u6cd5\u4ec55%\uff09\uff0cSINR\u63d0\u53472.5 dB\uff0c\u5bb9\u91cf\u63d0\u9ad880%\u3002", "conclusion": "MASC\u4e3a6G\u65f6\u4ee3\u7684\u975e\u5730\u9762\u7f51\u7edc\u63d0\u4f9b\u4e86\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7684\u53ef\u884c\u65b9\u6848\uff0c\u5e73\u8861\u73af\u5883\u611f\u77e5\u4e0e\u9ad8\u53ef\u9760\u6027\u4f20\u8f93\u3002"}}
{"id": "2506.16538", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16538", "abs": "https://arxiv.org/abs/2506.16538", "authors": ["Yunkee Chae", "Kyogu Lee"], "title": "Towards Bitrate-Efficient and Noise-Robust Speech Coding with Variable Bitrate RVQ", "comment": "Accepted to Interspeech 2025", "summary": "Residual Vector Quantization (RVQ) has become a dominant approach in neural\nspeech and audio coding, providing high-fidelity compression. However, speech\ncoding presents additional challenges due to real-world noise, which degrades\ncompression efficiency. Standard codecs allocate bits uniformly, wasting\nbitrate on noise components that do not contribute to intelligibility. This\npaper introduces a Variable Bitrate RVQ (VRVQ) framework for noise-robust\nspeech coding, dynamically adjusting bitrate per frame to optimize\nrate-distortion trade-offs. Unlike constant bitrate (CBR) RVQ, our method\nprioritizes critical speech components while suppressing residual noise.\nAdditionally, we integrate a feature denoiser to further improve noise\nrobustness. Experimental results show that VRVQ improves rate-distortion\ntrade-offs over conventional methods, achieving better compression efficiency\nand perceptual quality in noisy conditions. Samples are available at our\nproject page: https://yoongi43.github.io/noise_robust_vrvq/.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u53ef\u53d8\u6bd4\u7279\u7387RVQ\uff08VRVQ\uff09\u6846\u67b6\uff0c\u7528\u4e8e\u566a\u58f0\u9c81\u68d2\u7684\u8bed\u97f3\u7f16\u7801\uff0c\u52a8\u6001\u8c03\u6574\u6bcf\u5e27\u6bd4\u7279\u7387\u4ee5\u4f18\u5316\u7387\u5931\u771f\u6743\u8861\u3002", "motivation": "\u4f20\u7edfRVQ\u5728\u8bed\u97f3\u7f16\u7801\u4e2d\u56e0\u566a\u58f0\u5bfc\u81f4\u538b\u7f29\u6548\u7387\u4e0b\u964d\uff0c\u6807\u51c6\u7f16\u89e3\u7801\u5668\u5747\u5300\u5206\u914d\u6bd4\u7279\u7387\uff0c\u6d6a\u8d39\u5728\u65e0\u52a9\u4e8e\u6e05\u6670\u5ea6\u7684\u566a\u58f0\u6210\u5206\u4e0a\u3002", "method": "\u5f15\u5165VRVQ\u6846\u67b6\uff0c\u52a8\u6001\u8c03\u6574\u6bd4\u7279\u7387\uff0c\u4f18\u5148\u5904\u7406\u5173\u952e\u8bed\u97f3\u6210\u5206\u5e76\u6291\u5236\u566a\u58f0\uff1b\u540c\u65f6\u96c6\u6210\u7279\u5f81\u53bb\u566a\u5668\u63d0\u5347\u566a\u58f0\u9c81\u68d2\u6027\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0cVRVQ\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u538b\u7f29\u6548\u7387\u548c\u611f\u77e5\u8d28\u91cf\u3002", "conclusion": "VRVQ\u6846\u67b6\u5728\u566a\u58f0\u9c81\u68d2\u7684\u8bed\u97f3\u7f16\u7801\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u4f18\u5316\u4e86\u7387\u5931\u771f\u6743\u8861\u3002"}}
{"id": "2506.16208", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16208", "abs": "https://arxiv.org/abs/2506.16208", "authors": ["Saeed Razavikia", "Carlo Fischione"], "title": "On Designing Modulation for Over-the-Air Computation -- Part II: Pyramid Sampling", "comment": null, "summary": "Over-the-air computation (OAC) harnesses the natural superposition of\nwireless signals to compute aggregate functions during transmission, thereby\ncollapsing communication and computation into a single step and significantly\nreducing latency and resource usage. In Part I, digital OAC was formulated as a\nnoise-aware constellation design problem by casting encoder design as a max-min\noptimization that aligns minimum Euclidean distances between superimposed\nconstellation points with squared differences of their corresponding function\noutputs.\n  In this paper, Part II, we address the prohibitive complexity and\nquantization challenges inherent in digital OAC constellation design for\nlarge-scale edge networks. More precisely, we introduce a pyramid sampling\nstrategy that judiciously selects a subset of superimposed constellation points\nto reduce the encoder design complexity from $\\mathcal{O}(q^K)$ to\n$\\mathcal{O}(q^{K-p+1})$, where $p\\in\\{1,\\dots, K\\}$ denotes the sampling\norder, $q$ levels of modulation, and $K$ denotes the number nodes in the\nnetwork. Under the assumption of symmetric aggregation, this approach enables a\ncontrolled trade-off between computational complexity and function computation\naccuracy. As a special case, we propose majority-based sampling ($p=K$), which\nconfines aggregation to only $q$ consensus points, inherently avoiding\ndestructive overlaps and permitting the use of standard digital modulations\n(e.g., QAM, PSK, ASK) without bespoke constellation designs. We also show via\nseveral simulations, across various aggregation functions, modulation levels,\nand noise levels, that moderate sampling orders attain acceptable performance\nwith orders-of-magnitude fewer constraints than exhaustive designs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u91d1\u5b57\u5854\u91c7\u6837\u7b56\u7565\uff0c\u7528\u4e8e\u964d\u4f4e\u5927\u89c4\u6a21\u8fb9\u7f18\u7f51\u7edc\u4e2d\u6570\u5b57OAC\u661f\u5ea7\u8bbe\u8ba1\u7684\u590d\u6742\u6027\uff0c\u901a\u8fc7\u9009\u62e9\u90e8\u5206\u53e0\u52a0\u661f\u5ea7\u70b9\uff0c\u5c06\u590d\u6742\u5ea6\u4ece$\\mathcal{O}(q^K)$\u964d\u81f3$\\mathcal{O}(q^{K-p+1})$\uff0c\u5e76\u5728\u5bf9\u79f0\u805a\u5408\u5047\u8bbe\u4e0b\u5b9e\u73b0\u8ba1\u7b97\u590d\u6742\u6027\u4e0e\u8ba1\u7b97\u7cbe\u5ea6\u7684\u6743\u8861\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21\u8fb9\u7f18\u7f51\u7edc\u4e2d\u6570\u5b57OAC\u661f\u5ea7\u8bbe\u8ba1\u7684\u9ad8\u590d\u6742\u6027\u548c\u91cf\u5316\u6311\u6218\u3002", "method": "\u5f15\u5165\u91d1\u5b57\u5854\u91c7\u6837\u7b56\u7565\uff0c\u9009\u62e9\u90e8\u5206\u53e0\u52a0\u661f\u5ea7\u70b9\u4ee5\u51cf\u5c11\u8bbe\u8ba1\u590d\u6742\u5ea6\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u591a\u6570\u91c7\u6837\u7684\u7279\u6b8a\u65b9\u6848\uff08$p=K$\uff09\u3002", "result": "\u901a\u8fc7\u591a\u79cd\u6a21\u62df\u9a8c\u8bc1\uff0c\u4e2d\u7b49\u91c7\u6837\u987a\u5e8f\u5728\u6027\u80fd\u53ef\u63a5\u53d7\u7684\u60c5\u51b5\u4e0b\u663e\u8457\u51cf\u5c11\u4e86\u7ea6\u675f\u6570\u91cf\u3002", "conclusion": "\u91d1\u5b57\u5854\u91c7\u6837\u7b56\u7565\u6709\u6548\u964d\u4f4e\u4e86\u6570\u5b57OAC\u661f\u5ea7\u8bbe\u8ba1\u7684\u590d\u6742\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u8ba1\u7b97\u7cbe\u5ea6\u3002"}}
{"id": "2506.16729", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16729", "abs": "https://arxiv.org/abs/2506.16729", "authors": ["Shoichi Koyama", "Kenji Ishizuka"], "title": "Learning Magnitude Distribution of Sound Fields via Conditioned Autoencoder", "comment": "To appear in Forum Acusticum 2025", "summary": "A learning-based method for estimating the magnitude distribution of sound\nfields from spatially sparse measurements is proposed. Estimating the magnitude\ndistribution of acoustic transfer function (ATF) is useful when phase\nmeasurements are unreliable or inaccessible and has a wide range of\napplications related to spatial audio. We propose a neural-network-based method\nfor the ATF magnitude estimation. The key feature of our network architecture\nis the input and output layers conditioned on source and receiver positions and\nfrequency and the aggregation module of latent variables, which can be\ninterpreted as an autoencoder-based extension of the basis expansion of the\nsound field. Numerical simulation results indicated that the ATF magnitude is\naccurately estimated with a small number of receivers by our proposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7a00\u758f\u7a7a\u95f4\u6d4b\u91cf\u4f30\u8ba1\u58f0\u573a\u7684\u5e45\u5ea6\u5206\u5e03\u3002", "motivation": "\u5728\u76f8\u4f4d\u6d4b\u91cf\u4e0d\u53ef\u9760\u6216\u65e0\u6cd5\u83b7\u53d6\u65f6\uff0c\u4f30\u8ba1\u58f0\u5b66\u4f20\u9012\u51fd\u6570\uff08ATF\uff09\u7684\u5e45\u5ea6\u5206\u5e03\u5bf9\u7a7a\u95f4\u97f3\u9891\u5e94\u7528\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\uff0c\u7f51\u7edc\u67b6\u6784\u7684\u5173\u952e\u7279\u70b9\u662f\u8f93\u5165\u548c\u8f93\u51fa\u5c42\u6839\u636e\u58f0\u6e90\u548c\u63a5\u6536\u5668\u4f4d\u7f6e\u4ee5\u53ca\u9891\u7387\u8fdb\u884c\u6761\u4ef6\u5316\uff0c\u5e76\u5305\u542b\u6f5c\u5728\u53d8\u91cf\u7684\u805a\u5408\u6a21\u5757\u3002", "result": "\u6570\u503c\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u901a\u8fc7\u5c11\u91cf\u63a5\u6536\u5668\u51c6\u786e\u4f30\u8ba1ATF\u5e45\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u7a00\u758f\u6d4b\u91cf\u4e0b\u7684\u58f0\u573a\u5e45\u5ea6\u4f30\u8ba1\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16236", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16236", "abs": "https://arxiv.org/abs/2506.16236", "authors": ["Romain Charbonnier", "Thierry Tenoux", "Yoann Corre"], "title": "Refining Ray-Tracing Accuracy and Efficiency in the Context of FRMCS Urban Railway Channel Predictions", "comment": "Presented at Workshop \"Emerging information and communication\n  technologies for smart railway Challenges and Opportunities for mmWave, THz,\n  ISAC, 5G and 6G\" in IEEE VTC-Spring 2025 Conference, June 2025, Oslo, Norway", "summary": "The upcoming roll-out of the new wireless communication standard for wireless\nrailway services, FRMCS, requires a thorough understanding of the system\nperformance in real-world conditions, since this will strongly influence the\ndeployment costs and the effectiveness of an infrastructure planned for\ndecades. The virtual testing of the equipment and network performance in\nrealistic simulated scenarios is key; its accuracy depends on the reliability\nof the predicted radio channel properties. In this article, the authors explain\nhow they are evolving a ray-tracing (RT) tool to apply it to the specific case\nof simulating the radio link between the FRMCS fixed infrastructure and an\nantenna placed on the roof of a train moving in an urban environment. First, a\ndynamic version of the RT tool is used to capture the rapid variations of all\nchannel metrics; a compromise is sought between computation time and accuracy.\nBesides, a hybridization of RT and physical optics (PO) allows the integration\nof objects near the track, such as catenary pylons, into the simulation. A case\nstudy shows that the scattering by metallic pylons brings a significant\ncontribution.", "AI": {"tldr": "\u8bba\u6587\u63a2\u8ba8\u4e86\u5982\u4f55\u6539\u8fdb\u5c04\u7ebf\u8ffd\u8e2a\u5de5\u5177\u4ee5\u6a21\u62dfFRMCS\u65e0\u7ebf\u901a\u4fe1\u6807\u51c6\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u7684\u6027\u80fd\uff0c\u91cd\u70b9\u5173\u6ce8\u52a8\u6001\u73af\u5883\u548c\u9644\u8fd1\u7269\u4f53\u7684\u5f71\u54cd\u3002", "motivation": "FRMCS\u4f5c\u4e3a\u65b0\u7684\u65e0\u7ebf\u94c1\u8def\u901a\u4fe1\u6807\u51c6\uff0c\u5176\u6027\u80fd\u76f4\u63a5\u5f71\u54cd\u90e8\u7f72\u6210\u672c\u548c\u957f\u671f\u57fa\u7840\u8bbe\u65bd\u6548\u679c\uff0c\u56e0\u6b64\u9700\u8981\u51c6\u786e\u6a21\u62df\u771f\u5b9e\u73af\u5883\u4e2d\u7684\u65e0\u7ebf\u7535\u94fe\u8def\u3002", "method": "\u4f5c\u8005\u5f00\u53d1\u4e86\u52a8\u6001\u5c04\u7ebf\u8ffd\u8e2a\u5de5\u5177\uff0c\u7ed3\u5408\u7269\u7406\u5149\u5b66\u65b9\u6cd5\uff0c\u6a21\u62df\u5217\u8f66\u5728\u57ce\u5e02\u573a\u666f\u4e2d\u79fb\u52a8\u65f6\u7684\u65e0\u7ebf\u7535\u94fe\u8def\uff0c\u5e76\u8003\u8651\u4e86\u8f68\u9053\u9644\u8fd1\u7269\u4f53\uff08\u5982\u7535\u7ebf\u6746\uff09\u7684\u5f71\u54cd\u3002", "result": "\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u91d1\u5c5e\u7535\u7ebf\u6746\u7684\u6563\u5c04\u5bf9\u65e0\u7ebf\u7535\u94fe\u8def\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u6539\u8fdb\u7684\u5c04\u7ebf\u8ffd\u8e2a\u5de5\u5177\u80fd\u66f4\u51c6\u786e\u5730\u6a21\u62dfFRMCS\u5728\u590d\u6742\u73af\u5883\u4e2d\u7684\u6027\u80fd\uff0c\u4e3a\u90e8\u7f72\u63d0\u4f9b\u53ef\u9760\u4f9d\u636e\u3002"}}
{"id": "2506.16833", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16833", "abs": "https://arxiv.org/abs/2506.16833", "authors": ["Jianyuan Feng", "Guangzheng Li", "Yangfei Xu"], "title": "Hybrid-Sep: Language-queried audio source separation via pre-trained Model Fusion and Adversarial Diffusion Training", "comment": "Submitted to WASAA 2025", "summary": "Language-queried Audio Separation (LASS) employs linguistic queries to\nisolate target sounds based on semantic descriptions. However, existing methods\nface challenges in aligning complex auditory features with linguistic context\nwhile preserving separation precision. Current research efforts focus primarily\non text description augmentation and architectural innovations, yet the\npotential of integrating pre-trained self-supervised learning (SSL) audio\nmodels and Contrastive Language-Audio Pretraining (CLAP) frameworks, capable of\nextracting cross-modal audio-text relationships, remains underexplored. To\naddress this, we present HybridSep, a two-stage LASS framework that synergizes\nSSL-based acoustic representations with CLAP-derived semantic embeddings. Our\nframework introduces Adversarial Consistent Training (ACT), a novel\noptimization strategy that treats diffusion as an auxiliary regularization loss\nwhile integrating adversarial training to enhance separation fidelity.\nExperiments demonstrate that HybridSep achieves significant performance\nimprovements over state-of-the-art baselines (e.g., AudioSep, FlowSep) across\nmultiple metrics, establishing new benchmarks for LASS tasks.", "AI": {"tldr": "HybridSep\u7ed3\u5408\u81ea\u76d1\u7763\u5b66\u4e60\u548c\u5bf9\u6bd4\u8bed\u8a00-\u97f3\u9891\u9884\u8bad\u7ec3\u6846\u67b6\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u65b9\u6cd5\u63d0\u5347\u8bed\u8a00\u67e5\u8be2\u97f3\u9891\u5206\u79bb\u6027\u80fd\uff0c\u5f15\u5165\u5bf9\u6297\u4e00\u81f4\u6027\u8bad\u7ec3\u4f18\u5316\u7b56\u7565\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u590d\u6742\u542c\u89c9\u7279\u5f81\u4e0e\u8bed\u8a00\u4e0a\u4e0b\u6587\u5bf9\u9f50\u53ca\u5206\u79bb\u7cbe\u5ea6\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u9884\u8bad\u7ec3\u81ea\u76d1\u7763\u5b66\u4e60\u548cCLAP\u6846\u67b6\u7684\u6f5c\u529b\u5c1a\u672a\u5145\u5206\u6316\u6398\u3002", "method": "\u63d0\u51faHybridSep\u6846\u67b6\uff0c\u7ed3\u5408SSL\u58f0\u5b66\u8868\u5f81\u548cCLAP\u8bed\u4e49\u5d4c\u5165\uff0c\u5f15\u5165\u5bf9\u6297\u4e00\u81f4\u6027\u8bad\u7ec3\uff08ACT\uff09\u4f18\u5316\u7b56\u7565\u3002", "result": "\u5b9e\u9a8c\u663e\u793aHybridSep\u5728\u591a\u4e2a\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\uff08\u5982AudioSep\u3001FlowSep\uff09\uff0c\u4e3aLASS\u4efb\u52a1\u8bbe\u7acb\u65b0\u6807\u6746\u3002", "conclusion": "HybridSep\u901a\u8fc7\u6574\u5408SSL\u548cCLAP\uff0c\u7ed3\u5408ACT\u7b56\u7565\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8bed\u8a00\u67e5\u8be2\u97f3\u9891\u5206\u79bb\u7684\u6027\u80fd\u3002"}}
{"id": "2506.16304", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16304", "abs": "https://arxiv.org/abs/2506.16304", "authors": ["Junyi Jiang", "Wei Chen", "Xin Guo", "Shenghui Song", "Ying Jun", "Zhang", "Zhu Han", "Merouane Debbah", "Khaled B. Letaief"], "title": "A Tractable Approach to Massive Communication and Ubiquitous Connectivity in 6G Standardization", "comment": null, "summary": "The full-scale 6G standardization has attracted considerable recent\nattention, especially since the first 3GPP-wide 6G workshop held in March 2025.\nTo understand the practical and fundamental values of 6G and facilitate its\nstandardization, it is crucial to explore the theoretical limits of spectrum,\nenergy, and coverage efficiency considering practical hardware and signaling\nconstraints. In this paper, we present a mean-field-approximation-based\ninvestigation on two out of six use case scenarios defined by IMT-2030, namely,\nmassive communication and ubiquitous connectivity. Being aware of the\nlimitation in interference cancellation owing to constrained cost and hardware\ncomplexity, we investigate the spectrum reuse architecture in both usage\nscenarios. We propose a tractable spectrum reuse with low signaling overhead\nconsumed for channel estimation and channel state information (CSI) feedback.\nOur analysis indicates that the massive communication over cellular and\ndevice-to-device (D2D) networks can benefit from channel orthogonalization,\nwhile it is unnecessary to share the CSI of interfering links. Moreover,\ndeploying relays or movable base stations, e.g. unmanned aerial vehicle, yields\nsubstantial energy and spectrum gain for ubiquitous connectivity, despite\nintroducing interference. As such, the mean-field-optimization-based evaluation\nis expected to positively impact 6G and NextG standardization in 3GPP and other\nstandardization bodies.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba8\u4e866G\u6807\u51c6\u5316\u4e2d\u7684\u9891\u8c31\u3001\u80fd\u91cf\u548c\u8986\u76d6\u6548\u7387\u7684\u7406\u8bba\u6781\u9650\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5747\u503c\u573a\u8fd1\u4f3c\u7684\u9891\u8c31\u91cd\u7528\u67b6\u6784\uff0c\u9002\u7528\u4e8e\u5927\u89c4\u6a21\u901a\u4fe1\u548c\u6cdb\u5728\u8fde\u63a5\u573a\u666f\u3002", "motivation": "\u7406\u89e36G\u7684\u5b9e\u9645\u548c\u57fa\u7840\u4ef7\u503c\uff0c\u4fc3\u8fdb\u5176\u6807\u51c6\u5316\uff0c\u63a2\u7d22\u9891\u8c31\u3001\u80fd\u91cf\u548c\u8986\u76d6\u6548\u7387\u7684\u7406\u8bba\u6781\u9650\u3002", "method": "\u91c7\u7528\u5747\u503c\u573a\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u7814\u7a76\u4e24\u79cdIMT-2030\u5b9a\u4e49\u7684\u7528\u4f8b\u573a\u666f\uff0c\u63d0\u51fa\u4f4e\u4fe1\u4ee4\u5f00\u9500\u7684\u9891\u8c31\u91cd\u7528\u67b6\u6784\u3002", "result": "\u5927\u89c4\u6a21\u901a\u4fe1\u53ef\u901a\u8fc7\u4fe1\u9053\u6b63\u4ea4\u5316\u83b7\u76ca\uff0c\u800c\u6cdb\u5728\u8fde\u63a5\u901a\u8fc7\u90e8\u7f72\u4e2d\u7ee7\u6216\u79fb\u52a8\u57fa\u7ad9\u83b7\u5f97\u663e\u8457\u80fd\u6548\u548c\u9891\u8c31\u589e\u76ca\u3002", "conclusion": "\u57fa\u4e8e\u5747\u503c\u573a\u4f18\u5316\u7684\u8bc4\u4f30\u6709\u671b\u5bf96G\u548cNextG\u6807\u51c6\u5316\u4ea7\u751f\u79ef\u6781\u5f71\u54cd\u3002"}}
{"id": "2506.16889", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.16889", "abs": "https://arxiv.org/abs/2506.16889", "authors": ["Junghyun Koo", "Marco A. Martinez-Ramirez", "Wei-Hsiang Liao", "Giorgio Fabbro", "Michele Mancusi", "Yuki Mitsufuji"], "title": "ITO-Master: Inference-Time Optimization for Audio Effects Modeling of Music Mastering Processors", "comment": "ISMIR 2025", "summary": "Music mastering style transfer aims to model and apply the mastering\ncharacteristics of a reference track to a target track, simulating the\nprofessional mastering process. However, existing methods apply fixed\nprocessing based on a reference track, limiting users' ability to fine-tune the\nresults to match their artistic intent. In this paper, we introduce the\nITO-Master framework, a reference-based mastering style transfer system that\nintegrates Inference-Time Optimization (ITO) to enable finer user control over\nthe mastering process. By optimizing the reference embedding during inference,\nour approach allows users to refine the output dynamically, making micro-level\nadjustments to achieve more precise mastering results. We explore both\nblack-box and white-box methods for modeling mastering processors and\ndemonstrate that ITO improves mastering performance across different styles.\nThrough objective evaluation, subjective listening tests, and qualitative\nanalysis using text-based conditioning with CLAP embeddings, we validate that\nITO enhances mastering style similarity while offering increased adaptability.\nOur framework provides an effective and user-controllable solution for\nmastering style transfer, allowing users to refine their results beyond the\ninitial style transfer.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86ITO-Master\u6846\u67b6\uff0c\u901a\u8fc7\u63a8\u7406\u65f6\u4f18\u5316\uff08ITO\uff09\u5b9e\u73b0\u66f4\u7cbe\u7ec6\u7684\u97f3\u4e50\u6bcd\u5e26\u98ce\u683c\u8fc1\u79fb\u63a7\u5236\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u57fa\u4e8e\u56fa\u5b9a\u5904\u7406\uff0c\u9650\u5236\u4e86\u7528\u6237\u6839\u636e\u827a\u672f\u610f\u56fe\u5fae\u8c03\u7ed3\u679c\u7684\u80fd\u529b\u3002", "method": "\u7ed3\u5408\u63a8\u7406\u65f6\u4f18\u5316\uff08ITO\uff09\uff0c\u52a8\u6001\u4f18\u5316\u53c2\u8003\u5d4c\u5165\uff0c\u652f\u6301\u7528\u6237\u5fae\u8c03\u3002\u63a2\u7d22\u4e86\u9ed1\u76d2\u548c\u767d\u76d2\u65b9\u6cd5\u5efa\u6a21\u6bcd\u5e26\u5904\u7406\u5668\u3002", "result": "ITO\u63d0\u5347\u4e86\u4e0d\u540c\u98ce\u683c\u7684\u6bcd\u5e26\u6027\u80fd\uff0c\u901a\u8fc7\u5ba2\u89c2\u8bc4\u4f30\u3001\u4e3b\u89c2\u6d4b\u8bd5\u548cCLAP\u5d4c\u5165\u9a8c\u8bc1\u4e86\u98ce\u683c\u76f8\u4f3c\u6027\u548c\u9002\u5e94\u6027\u3002", "conclusion": "ITO-Master\u6846\u67b6\u63d0\u4f9b\u4e86\u9ad8\u6548\u4e14\u7528\u6237\u53ef\u63a7\u7684\u6bcd\u5e26\u98ce\u683c\u8fc1\u79fb\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2506.16767", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16767", "abs": "https://arxiv.org/abs/2506.16767", "authors": ["Esa Ollila", "Xavier Mestre", "Elias Raninen"], "title": "Beamforming design for minimizing the signal power estimation error", "comment": null, "summary": "We study the properties of beamformers in their ability to either maintain or\nestimate the true signal power of the signal of interest (SOI). Our focus is\nparticularly on the Capon beamformer and the minimum mean squared error (MMSE)\nbeamformer. The Capon beamformer, also known as the minimum power\ndistortionless response (MPDR) or the minimum variance distortionless response\n(MVDR) beamformer, is a widely used method in array signal processing. A\ncurious feature of both the Capon and the MMSE beamformers is their tendency to\neither overestimate or underestimate the signal power. That is, they are not\nasymptotically unbiased (as the sample size approaches infinity). To address\nthis issue, we propose to shrink the Capon beamformer by finding a scaling\nfactor that minimizes the mean squared error (MSE) of the signal power\nestimate. The new beamformer, referred to as the Capon$^+$ beamformer, is\nevaluated against the Capon and MMSE beamformers in terms of bias, signal power\nMSE, and signal waveform MSE. The Capon$^+$ beamformer strikes a better balance\nbetween signal power and waveform estimation while also exhibiting minimal\nbias, which approaches zero as the sample size increases.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86Capon\u548cMMSE\u6ce2\u675f\u5f62\u6210\u5668\u5728\u4fe1\u53f7\u529f\u7387\u4f30\u8ba1\u4e2d\u7684\u504f\u5dee\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684Capon\u207a\u6ce2\u675f\u5f62\u6210\u5668\uff0c\u901a\u8fc7\u7f29\u653e\u56e0\u5b50\u4f18\u5316\u4fe1\u53f7\u529f\u7387\u4f30\u8ba1\u7684\u5747\u65b9\u8bef\u5dee\u3002", "motivation": "Capon\u548cMMSE\u6ce2\u675f\u5f62\u6210\u5668\u5728\u4fe1\u53f7\u529f\u7387\u4f30\u8ba1\u4e2d\u5b58\u5728\u504f\u5dee\u95ee\u9898\uff0c\u65e0\u6cd5\u968f\u7740\u6837\u672c\u91cf\u589e\u52a0\u800c\u6e10\u8fd1\u65e0\u504f\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684Capon\u207a\u6ce2\u675f\u5f62\u6210\u5668\uff0c\u901a\u8fc7\u6700\u5c0f\u5316\u4fe1\u53f7\u529f\u7387\u4f30\u8ba1\u7684\u5747\u65b9\u8bef\u5dee\u6765\u4f18\u5316\u7f29\u653e\u56e0\u5b50\u3002", "result": "Capon\u207a\u6ce2\u675f\u5f62\u6210\u5668\u5728\u4fe1\u53f7\u529f\u7387\u548c\u6ce2\u5f62\u4f30\u8ba1\u4e4b\u95f4\u53d6\u5f97\u4e86\u66f4\u597d\u7684\u5e73\u8861\uff0c\u4e14\u504f\u5dee\u6700\u5c0f\uff0c\u968f\u7740\u6837\u672c\u91cf\u589e\u52a0\u8d8b\u8fd1\u4e8e\u96f6\u3002", "conclusion": "Capon\u207a\u6ce2\u675f\u5f62\u6210\u5668\u5728\u4fe1\u53f7\u529f\u7387\u4f30\u8ba1\u4e2d\u8868\u73b0\u4f18\u4e8e\u4f20\u7edfCapon\u548cMMSE\u6ce2\u675f\u5f62\u6210\u5668\uff0c\u89e3\u51b3\u4e86\u504f\u5dee\u95ee\u9898\u3002"}}
{"id": "2506.17055", "categories": ["cs.SD", "cs.IR", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2506.17055", "abs": "https://arxiv.org/abs/2506.17055", "authors": ["Charilaos Papaioannou", "Emmanouil Benetos", "Alexandros Potamianos"], "title": "Universal Music Representations? Evaluating Foundation Models on World Music Corpora", "comment": "Accepted at ISMIR 2025", "summary": "Foundation models have revolutionized music information retrieval, but\nquestions remain about their ability to generalize across diverse musical\ntraditions. This paper presents a comprehensive evaluation of five\nstate-of-the-art audio foundation models across six musical corpora spanning\nWestern popular, Greek, Turkish, and Indian classical traditions. We employ\nthree complementary methodologies to investigate these models' cross-cultural\ncapabilities: probing to assess inherent representations, targeted supervised\nfine-tuning of 1-2 layers, and multi-label few-shot learning for low-resource\nscenarios. Our analysis shows varying cross-cultural generalization, with\nlarger models typically outperforming on non-Western music, though results\ndecline for culturally distant traditions. Notably, our approaches achieve\nstate-of-the-art performance on five out of six evaluated datasets,\ndemonstrating the effectiveness of foundation models for world music\nunderstanding. We also find that our targeted fine-tuning approach does not\nconsistently outperform probing across all settings, suggesting foundation\nmodels already encode substantial musical knowledge. Our evaluation framework\nand benchmarking results contribute to understanding how far current models are\nfrom achieving universal music representations while establishing metrics for\nfuture progress.", "AI": {"tldr": "\u8be5\u8bba\u6587\u8bc4\u4f30\u4e86\u4e94\u79cd\u97f3\u9891\u57fa\u7840\u6a21\u578b\u5728\u516d\u79cd\u4e0d\u540c\u97f3\u4e50\u4f20\u7edf\u4e2d\u7684\u8de8\u6587\u5316\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u8f83\u5927\u6a21\u578b\u5728\u975e\u897f\u65b9\u97f3\u4e50\u4e0a\u8868\u73b0\u66f4\u597d\uff0c\u4f46\u6587\u5316\u8ddd\u79bb\u8f83\u8fdc\u65f6\u6027\u80fd\u4e0b\u964d\u3002", "motivation": "\u7814\u7a76\u57fa\u7840\u6a21\u578b\u662f\u5426\u80fd\u591f\u6cdb\u5316\u5230\u591a\u6837\u5316\u7684\u97f3\u4e50\u4f20\u7edf\u4e2d\uff0c\u586b\u8865\u8de8\u6587\u5316\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u7684\u7a7a\u767d\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u65b9\u6cd5\uff1a\u63a2\u6d4b\u6a21\u578b\u56fa\u6709\u8868\u793a\u3001\u9488\u5bf9\u6027\u76d1\u7763\u5fae\u8c031-2\u5c42\u3001\u591a\u6807\u7b7e\u5c11\u6837\u672c\u5b66\u4e60\u3002", "result": "\u6a21\u578b\u5728\u4e94\u79cd\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u4f73\u6027\u80fd\uff0c\u4f46\u6587\u5316\u8ddd\u79bb\u8f83\u8fdc\u65f6\u8868\u73b0\u4e0b\u964d\uff1b\u9488\u5bf9\u6027\u5fae\u8c03\u4e0d\u603b\u662f\u4f18\u4e8e\u63a2\u6d4b\u3002", "conclusion": "\u57fa\u7840\u6a21\u578b\u5df2\u5177\u5907\u5927\u91cf\u97f3\u4e50\u77e5\u8bc6\uff0c\u4f46\u4ecd\u9700\u6539\u8fdb\u4ee5\u5b9e\u73b0\u901a\u7528\u97f3\u4e50\u8868\u793a\uff1b\u63d0\u51fa\u4e86\u8bc4\u4f30\u6846\u67b6\u548c\u57fa\u51c6\u3002"}}
{"id": "2506.16957", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.16957", "abs": "https://arxiv.org/abs/2506.16957", "authors": ["Zisheng Wang", "Feng Li", "Hangbin Zhao", "Zihuan Mao", "Yaodong Zhang", "Qisheng Huang", "Bo Cao", "Mingming Cao", "Baolin He", "Qilin Hou"], "title": "Wi-Fi Sensing Tool Release: Gathering 802.11ax Channel State Information from a Commercial Wi-Fi Access Point", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Wi-Fi sensing has emerged as a powerful technology, leveraging channel state\ninformation (CSI) extracted from wireless data packets to enable diverse\napplications, ranging from human presence detection to gesture recognition and\nhealth monitoring. However, CSI extraction from commercial Wi-Fi access point\nlacks and out of date. This paper introduces ZTECSITool,a toolkit designed to\ncapture high-resolution CSI measurements from commercial Wi-Fi 6 (802.11ax)\naccess points, supporting bandwidths up to 160 MHz and 512 subcarriers.\nZTECSITool bridges a critical gap in Wi-Fi sensing research, facilitating the\ndevelopment of next-generation sensing systems. The toolkit includes customized\nfirmware and open-source software tools for configuring, collecting, and\nparsing CSI data, offering researchers a robust platform for advanced sensing\napplications. We detail the command protocols for CSI extraction, including\nband selection,STA filtering, and report configuration, and provide insights\ninto the data structure of the reported CSI. Additionally, we present a\nPython-based graphical interface for real-time CSI visualization and analysis", "AI": {"tldr": "ZTECSITool\u662f\u4e00\u4e2a\u7528\u4e8e\u4eceWi-Fi 6\u8bbe\u5907\u6355\u83b7\u9ad8\u5206\u8fa8\u7387CSI\u6570\u636e\u7684\u5de5\u5177\u5305\uff0c\u586b\u8865\u4e86\u5546\u4e1aWi-Fi\u63a5\u5165\u70b9\u5728CSI\u63d0\u53d6\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "motivation": "\u5546\u4e1aWi-Fi\u63a5\u5165\u70b9\u7684CSI\u63d0\u53d6\u529f\u80fd\u4e0d\u8db3\u4e14\u8fc7\u65f6\uff0c\u9650\u5236\u4e86Wi-Fi\u611f\u77e5\u6280\u672f\u7684\u53d1\u5c55\u3002", "method": "\u5f00\u53d1\u4e86ZTECSITool\u5de5\u5177\u5305\uff0c\u5305\u62ec\u5b9a\u5236\u56fa\u4ef6\u548c\u5f00\u6e90\u8f6f\u4ef6\uff0c\u652f\u6301\u9ad8\u5e26\u5bbd\u548c\u591a\u5b50\u8f7d\u6ce2\u7684CSI\u6570\u636e\u91c7\u96c6\u4e0e\u89e3\u6790\u3002", "result": "\u63d0\u4f9b\u4e86CSI\u63d0\u53d6\u7684\u8be6\u7ec6\u534f\u8bae\u548cPython\u56fe\u5f62\u754c\u9762\uff0c\u652f\u6301\u5b9e\u65f6\u6570\u636e\u53ef\u89c6\u5316\u548c\u5206\u6790\u3002", "conclusion": "ZTECSITool\u4e3a\u4e0b\u4e00\u4ee3Wi-Fi\u611f\u77e5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u7814\u7a76\u5e73\u53f0\u3002"}}
{"id": "2506.17010", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17010", "abs": "https://arxiv.org/abs/2506.17010", "authors": ["Kuranage Roche Rayan Ranasinghe", "Bruno S. Chang", "Giuseppe Thadeu Freitas de Abreu"], "title": "Low-Complexity Receiver Design for Affine Filter Bank Modulation", "comment": "Submitted to an IEEE conference. arXiv admin note: substantial text\n  overlap with arXiv:2505.03589", "summary": "We propose a low-complexity receiver structure for the recently introduced\nAffine Filter Bank Modulation (AFBM) scheme, which is a novel waveform designed\nfor integrated sensing and communications (ISAC) systems operating in\ndoubly-dispersive (DD) channels. The proposed receiver structure is based on\nthe Gaussian Belief Propagation (GaBP) framework, making use of only\nelement-wise scalar operations to perform detection of the transmitted symbols.\nSimulation results demonstrate that AFBM in conjunction with GaBP outperforms\naffine frequency division multiplexing (AFDM) in terms of bit error rates\n(BERs) in DD channels, while achieving very low out-of-band emissions (OOBE) in\nhigh-mobility scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u7684\u63a5\u6536\u5668\u7ed3\u6784\uff0c\u7528\u4e8e\u65b0\u578b\u6ce2\u5f62AFBM\uff0c\u57fa\u4e8eGaBP\u6846\u67b6\uff0c\u6027\u80fd\u4f18\u4e8eAFDM\u3002", "motivation": "\u4e3aISAC\u7cfb\u7edf\u5728\u53cc\u5206\u6563\u4fe1\u9053\u4e2d\u8bbe\u8ba1\u9ad8\u6548\u63a5\u6536\u65b9\u6848\u3002", "method": "\u57fa\u4e8eGaBP\u6846\u67b6\uff0c\u4ec5\u4f7f\u7528\u6807\u91cf\u64cd\u4f5c\u8fdb\u884c\u7b26\u53f7\u68c0\u6d4b\u3002", "result": "\u5728BER\u548cOOBE\u65b9\u9762\u4f18\u4e8eAFDM\u3002", "conclusion": "AFBM\u7ed3\u5408GaBP\u5728\u53cc\u5206\u6563\u4fe1\u9053\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2506.17108", "categories": ["eess.SP", "cs.IT", "math.IT", "stat.ML"], "pdf": "https://arxiv.org/pdf/2506.17108", "abs": "https://arxiv.org/abs/2506.17108", "authors": ["Levli Citron", "Kobi Cohen", "Qing Zhao"], "title": "Searching for a Hidden Markov Anomaly over Multiple Processes", "comment": "13 pages, 9 figures", "summary": "We address the problem of detecting an anomalous process among a large number\nof processes. At each time t, normal processes are in state zero (normal\nstate), while the abnormal process may be in either state zero (normal state)\nor state one (abnormal state), with the states being hidden. The transition\nbetween states for the abnormal process is governed by a Markov chain over\ntime. At each time step, observations can be drawn from a selected subset of\nprocesses. Each probed process generates an observation depending on its hidden\nstate, either a typical distribution under state zero or an abnormal\ndistribution under state one. The objective is to design a sequential search\nstrategy that minimizes the expected detection time, subject to an error\nprobability constraint. In contrast to prior works that assume i.i.d.\nobservations, we address a new setting where anomalies evolve according to a\nhidden Markov model. To this end, we propose a novel algorithm, dubbed Anomaly\nDetection under Hidden Markov model (ADHM), which dynamically adapts the\nprobing strategy based on accumulated statistical evidence and predictive\nbelief updates over hidden states. ADHM effectively leverages temporal\ncorrelations to focus sensing resources on the most informative processes. The\nalgorithm is supported by an asymptotic theoretical foundation, grounded in an\noracle analysis that characterizes the fundamental limits of detection under\nthe assumption of a known distribution of the hidden states. In addition, the\nalgorithm demonstrates strong empirical performance, consistently outperforming\nexisting methods in extensive simulations.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9690\u9a6c\u5c14\u53ef\u592b\u6a21\u578b\u7684\u5f02\u5e38\u68c0\u6d4b\u7b97\u6cd5\uff08ADHM\uff09\uff0c\u7528\u4e8e\u5728\u591a\u4e2a\u8fc7\u7a0b\u4e2d\u52a8\u6001\u8bc6\u522b\u5f02\u5e38\u8fc7\u7a0b\uff0c\u6700\u5c0f\u5316\u68c0\u6d4b\u65f6\u95f4\u5e76\u6ee1\u8db3\u9519\u8bef\u6982\u7387\u7ea6\u675f\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u89c2\u6d4b\u72ec\u7acb\u540c\u5206\u5e03\uff0c\u4f46\u5b9e\u9645\u5f02\u5e38\u53ef\u80fd\u968f\u65f6\u95f4\u52a8\u6001\u53d8\u5316\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u80fd\u5229\u7528\u65f6\u95f4\u76f8\u5173\u6027\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51faADHM\u7b97\u6cd5\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u63a2\u6d4b\u7b56\u7565\uff0c\u7ed3\u5408\u7edf\u8ba1\u8bc1\u636e\u548c\u9690\u72b6\u6001\u9884\u6d4b\u66f4\u65b0\uff0c\u805a\u7126\u4e8e\u4fe1\u606f\u91cf\u6700\u5927\u7684\u8fc7\u7a0b\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660eADHM\u5728\u5df2\u77e5\u9690\u72b6\u6001\u5206\u5e03\u4e0b\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\uff0c\u5b9e\u9a8c\u663e\u793a\u5176\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "ADHM\u901a\u8fc7\u5229\u7528\u65f6\u95f4\u76f8\u5173\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5f02\u5e38\u68c0\u6d4b\u6548\u7387\uff0c\u9002\u7528\u4e8e\u52a8\u6001\u53d8\u5316\u7684\u5f02\u5e38\u573a\u666f\u3002"}}
{"id": "2506.17189", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17189", "abs": "https://arxiv.org/abs/2506.17189", "authors": ["Muhammad Umer", "Muhammad Ahmed Mohsin", "Aamir Mahmood", "Haejoon Jung", "Haris Pervaiz", "Mikael Gidlund", "Syed Ali Hassan"], "title": "On Energy-Efficient Passive Beamforming Design of RIS-Assisted CoMP-NOMA Networks", "comment": "Accepted and presented at IEEE ICC'25 [SAC-12 Track]. arXiv admin\n  note: substantial text overlap with arXiv:2504.00975", "summary": "This paper investigates the synergistic potential of reconfigurable\nintelligent surfaces (RIS) and non-orthogonal multiple access (NOMA) to enhance\nthe energy efficiency and performance of next-generation wireless networks. We\ndelve into the design of energy-efficient passive beamforming (PBF) strategies\nwithin RIS-assisted coordinated multi-point (CoMP)-NOMA networks. Two distinct\nRIS configurations, namely, enhancement-only PBF (EO) and enhancement &\ncancellation PBF (EC), are proposed and analyzed. Our findings demonstrate that\nRIS-assisted CoMP-NOMA networks offer significant efficiency gains compared to\ntraditional CoMP-NOMA systems. Furthermore, we formulate a PBF design problem\nto optimize the RIS phase shifts for maximizing energy efficiency. Our results\nreveal that the optimal PBF design is contingent upon several factors,\nincluding the number of cooperating base stations (BSs), the number of RIS\nelements deployed, and the RIS configuration. This study underscores the\npotential of RIS-assisted CoMP-NOMA networks as a promising solution for\nachieving superior energy efficiency and overall performance in future wireless\nnetworks.", "AI": {"tldr": "\u7814\u7a76RIS\u548cNOMA\u7684\u534f\u540c\u6f5c\u529b\uff0c\u63d0\u5347\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u7684\u80fd\u6548\u548c\u6027\u80fd\uff0c\u63d0\u51fa\u4e24\u79cdRIS\u914d\u7f6e\u5e76\u5206\u6790\u5176\u6548\u679c\u3002", "motivation": "\u63a2\u7d22\u5982\u4f55\u901a\u8fc7RIS\u548cNOMA\u7684\u7ed3\u5408\u63d0\u5347\u65e0\u7ebf\u7f51\u7edc\u7684\u80fd\u6548\u548c\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7f51\u7edc\u63d0\u4f9b\u66f4\u4f18\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u4e24\u79cdRIS\u914d\u7f6e\uff08EO\u548cEC\uff09\uff0c\u5e76\u4f18\u5316RIS\u76f8\u4f4d\u504f\u79fb\u4ee5\u6700\u5927\u5316\u80fd\u6548\u3002", "result": "RIS\u8f85\u52a9\u7684CoMP-NOMA\u7f51\u7edc\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7cfb\u7edf\uff0c\u80fd\u6548\u4f18\u5316\u4f9d\u8d56\u4e8e\u57fa\u7ad9\u6570\u91cf\u3001RIS\u5143\u7d20\u548c\u914d\u7f6e\u3002", "conclusion": "RIS\u8f85\u52a9\u7684CoMP-NOMA\u7f51\u7edc\u662f\u5b9e\u73b0\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u9ad8\u6548\u80fd\u7684\u6709\u524d\u666f\u65b9\u6848\u3002"}}
{"id": "2506.17200", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17200", "abs": "https://arxiv.org/abs/2506.17200", "authors": ["Qingqing Wu", "Yanze Zhu", "Qiaoyan Peng", "Wanming Hao", "Yanzhao Hou", "Fengyuan Yang", "Wencai Yan", "Guoning Wang", "Wen Chen", "Chi Qiu"], "title": "Intelligent Reflecting Surfaces for THz Communications: Fundamentals, Key Solutions, and System Prototyping", "comment": null, "summary": "Intelligent reflecting surfaces (IRSs) have emerged as a cost-effective\ntechnology for terahertz (THz) communications by enabling programmable control\nof the wireless environment. This paper provides a comprehensive overview of\nIRSs-aided THz communications, covering hardware designs, advanced signal\nprocessing techniques, and practical deployment strategies. It first examines\nkey THz reconfigurable metasurface architectures, including electronic,\noptical, phase-change material, and micro-electromechanical systems\n(MEMS)-based implementations, highlighting their reconfiguration mechanisms and\nchallenges. Then, fundamental effects including near field and beam squint in\nwideband THz systems are analyzed, along with their impacts on system\nperformance. The paper further explores conventional and beam-squint-assisted\nchannel estimation methods, innovative beam management strategies, and\ndeployment considerations across large- and small-scale scenarios. Practical\nexperiments at 220 gigahertz (GHz) validate the effectiveness of IRS in\nimproving signal strength and communication reliability for both single-user\nand multi-user setups.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u667a\u80fd\u53cd\u5c04\u9762\uff08IRS\uff09\u5728\u592a\u8d6b\u5179\uff08THz\uff09\u901a\u4fe1\u4e2d\u7684\u5e94\u7528\uff0c\u6db5\u76d6\u786c\u4ef6\u8bbe\u8ba1\u3001\u4fe1\u53f7\u5904\u7406\u6280\u672f\u548c\u90e8\u7f72\u7b56\u7565\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u6709\u6548\u6027\u3002", "motivation": "\u63a2\u7d22IRS\u5728THz\u901a\u4fe1\u4e2d\u7684\u6f5c\u529b\uff0c\u4ee5\u4f4e\u6210\u672c\u5b9e\u73b0\u5bf9\u65e0\u7ebf\u73af\u5883\u7684\u53ef\u7f16\u7a0b\u63a7\u5236\u3002", "method": "\u5206\u6790\u4e86\u591a\u79cdTHz\u53ef\u91cd\u6784\u8d85\u8868\u9762\u67b6\u6784\uff0c\u7814\u7a76\u4e86\u8fd1\u573a\u6548\u5e94\u548c\u6ce2\u675f\u503e\u659c\u95ee\u9898\uff0c\u5e76\u63d0\u51fa\u4e86\u4fe1\u9053\u4f30\u8ba1\u548c\u6ce2\u675f\u7ba1\u7406\u7b56\u7565\u3002", "result": "220 GHz\u5b9e\u9a8c\u8868\u660e\uff0cIRS\u80fd\u663e\u8457\u63d0\u5347\u4fe1\u53f7\u5f3a\u5ea6\u548c\u901a\u4fe1\u53ef\u9760\u6027\u3002", "conclusion": "IRS\u662f\u63d0\u5347THz\u901a\u4fe1\u6027\u80fd\u7684\u6709\u6548\u6280\u672f\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u524d\u666f\u3002"}}
{"id": "2506.17205", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2506.17205", "abs": "https://arxiv.org/abs/2506.17205", "authors": ["Jennifer Bondarchuk", "Anthony Trezza", "Donald J. Bucci Jr"], "title": "Efficient Implementation of Multi-sensor Adaptive Birth Samplers for Labeled Random Finite Set Tracking", "comment": "Accepted to the 2024 Proc. IEEE 27th Int. Conf. Inf. Fusion. arXiv\n  admin note: text overlap with arXiv:2307.06401", "summary": "Adaptive track initiation remains a crucial component of many modern\nmulti-target tracking systems. For labeled random finite sets multi-object\nfilters, prior work has been established to construct a labeled multi-object\nbirth density using measurements from multiple sensors. A naive construction of\nthis adaptive birth set density results in an exponential number of newborn\ncomponents in the number of sensors. A truncation procedure was provided that\nleverages a Gibbs sampler to truncate the birth density, reducing the\ncomplexity to quadratic in the number of sensors. However, only a limited\ndiscussion has been provided on additional algorithmic techniques that can be\nemployed to substantially reduce the complexity in practical tracking\napplications. In this paper, we propose five efficiency enhancements for the\nlabeled random finite sets multi-sensor adaptive birth procedure. Simulation\nresults are provided to demonstrate their computational benefits and show that\nthey result in a negligible change to the multi-target tracking performance.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e94\u79cd\u6548\u7387\u63d0\u5347\u65b9\u6cd5\uff0c\u7528\u4e8e\u6539\u8fdb\u591a\u4f20\u611f\u5668\u81ea\u9002\u5e94\u51fa\u751f\u8fc7\u7a0b\uff0c\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u51e0\u4e4e\u4e0d\u5f71\u54cd\u591a\u76ee\u6807\u8ddf\u8e2a\u6027\u80fd\u3002", "motivation": "\u81ea\u9002\u5e94\u8f68\u8ff9\u521d\u59cb\u5316\u662f\u73b0\u4ee3\u591a\u76ee\u6807\u8ddf\u8e2a\u7cfb\u7edf\u7684\u5173\u952e\u90e8\u5206\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0a\u5b58\u5728\u4e0d\u8db3\uff0c\u5c24\u5176\u662f\u5728\u591a\u4f20\u611f\u5668\u573a\u666f\u4e2d\u3002", "method": "\u63d0\u51fa\u4e86\u4e94\u79cd\u6548\u7387\u589e\u5f3a\u6280\u672f\uff0c\u7528\u4e8e\u4f18\u5316\u6807\u8bb0\u968f\u673a\u6709\u9650\u96c6\u591a\u4f20\u611f\u5668\u81ea\u9002\u5e94\u51fa\u751f\u8fc7\u7a0b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8fd9\u4e9b\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u5bf9\u591a\u76ee\u6807\u8ddf\u8e2a\u6027\u80fd\u7684\u5f71\u54cd\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6548\u7387\u589e\u5f3a\u65b9\u6cd5\u5728\u591a\u4f20\u611f\u5668\u81ea\u9002\u5e94\u51fa\u751f\u8fc7\u7a0b\u4e2d\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u6548\u7387\u3002"}}

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 16]
- [eess.AS](#eess.AS) [Total: 6]
- [cs.SD](#cs.SD) [Total: 19]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Two-Stage Prony-Based Estimation of Fractional Delay and Doppler Shifts in OTFS Modulation](https://arxiv.org/abs/2506.17599)
*Yutaka Jitsumatsu,Liangchen Sun*

Main category: eess.SP

TL;DR: 提出了一种基于Prony技术的两阶段估计方法，用于高移动环境中的分数延迟和多普勒频移估计，提升ISAC系统的性能。


<details>
  <summary>Details</summary>
Motivation: 解决多径信道中分数延迟和多普勒频移引起的干扰问题，提高ISAC系统在高移动环境中的估计精度。

Method: 采用两阶段估计方法：第一阶段利用M个子通道和N次重复的OTFS导频信号联合求解Prony方程估计多普勒频率；第二阶段对每个多普勒分量应用DFT和Prony方法估计延迟。

Result: 在无噪声条件下，能准确估计多达N-1个延迟-多普勒参数；在噪声环境中，采用启发式模型选择策略提高性能。

Conclusion: 数值模拟验证了该方法的高估计精度，展示了其在未来ISAC框架中的潜力。

Abstract: This paper addresses the estimation of fractional delay and Doppler shifts in
multipath channels that cause doubly selective fading-an essential task for
integrated sensing and communication (ISAC) systems in high-mobility
environments. Orthogonal Time Frequency Space (OTFS) modulation enables simple
and robust channel compensation under such conditions. However, fractional
delay and Doppler components introduce inter-path interference, degrading
estimation accuracy. We propose a two-stage estimation method based on Prony's
technique using OTFS pilot signals with M subchannels and N pilot repetitions.
In the first stage, Doppler frequencies are estimated by jointly solving M
coupled Prony equations, exploiting the periodicity of the pilot signal. In the
second stage, delays are estimated by applying the discrete Fourier transform
(DFT) and Prony's method to each Doppler component obtained in the first stage.
The proposed method can accurately estimate up to N-1 delay-Doppler parameters
under noiseless conditions. In noisy environments, conventional information
criteria such as AIC and BIC yield suboptimal performance; thus, a heuristic
model order selection is adopted. Numerical simulations confirm that the
proposed method achieves high estimation accuracy, highlighting its potential
for future ISAC frameworks.

</details>


### [2] [Rethinking the Role of Operating Conditions for Learning-based Multi-condition Fault Diagnosis](https://arxiv.org/abs/2506.17740)
*Pengyu Han,Zeyi Liu,Shijin Chen,Dongliang Zou,Xiao He*

Main category: eess.SP

TL;DR: 该论文研究了多工况故障诊断中工况对故障信息的影响，提出了一种两阶段诊断框架，结合域泛化编码器和重训练策略，以提高诊断性能。


<details>
  <summary>Details</summary>
Motivation: 多工况故障诊断中，数据分布差异导致传统方法性能下降，而现有域泛化方法可能因工况影响而学习到工况特定信息，降低泛化能力。

Method: 提出两阶段诊断框架，结合域泛化编码器和重训练策略，提取工况不变故障特征并缓解源域过拟合。

Result: 在真实齿轮箱数据集上的实验验证了该方法的有效性。

Conclusion: 该框架能有效提升工况影响显著场景下的故障诊断性能。

Abstract: Multi-condition fault diagnosis is prevalent in industrial systems and
presents substantial challenges for conventional diagnostic approaches. The
discrepancy in data distributions across different operating conditions
degrades model performance when a model trained under one condition is applied
to others. With the recent advancements in deep learning, transfer learning has
been introduced to the fault diagnosis field as a paradigm for addressing
multi-condition fault diagnosis. Among these methods, domain generalization
approaches can handle complex scenarios by extracting condition-invariant fault
features. Although many studies have considered fault diagnosis in specific
multi-condition scenarios, the extent to which operating conditions affect
fault information has been scarcely studied, which is crucial. However, the
extent to which operating conditions affect fault information has been scarcely
studied, which is crucial. When operating conditions have a significant impact
on fault features, directly applying domain generalization methods may lead the
model to learn condition-specific information, thereby reducing its overall
generalization ability. This paper investigates the performance of existing
end-to-end domain generalization methods under varying conditions, specifically
in variable-speed and variable-load scenarios, using multiple experiments on a
real-world gearbox. Additionally, a two-stage diagnostic framework is proposed,
aiming to improve fault diagnosis performance under scenarios with significant
operating condition impacts. By incorporating a domain-generalized encoder with
a retraining strategy, the framework is able to extract condition-invariant
fault features while simultaneously alleviating potential overfitting to the
source domain. Several experiments on a real-world gearbox dataset are
conducted to validate the effectiveness of the proposed approach.

</details>


### [3] [Machine Learning-Based Near-Field Localization in Mixed LoS/NLoS Scenarios](https://arxiv.org/abs/2506.17810)
*Parisa Ramezani,Seyed Jalaleddin Mousavirad,Mattias O'Nils,Emil Björnson*

Main category: eess.SP

TL;DR: 提出了一种基于机器学习的近场源3D定位方法，解决了传统MUSIC算法计算复杂度高的问题。


<details>
  <summary>Details</summary>
Motivation: 传统MUSIC算法在近场场景中因3D网格搜索导致计算复杂度高，限制了其应用。

Method: 使用卷积神经网络（CNN）学习接收信号协方差矩阵特征向量与源3D位置之间的映射关系。

Result: 数值模拟验证了所提CNN方法的有效性和时间效率。

Conclusion: 基于CNN的定位方法在近场混合LOS/NLOS场景中具有高效性和实用性。

Abstract: The conventional MUltiple SIgnal Classification (MUSIC) algorithm is
effective for angle-of-arrival estimation in the far-field and can be extended
for full source localization in the near-field. However, it suffers from high
computational complexity, which becomes especially prohibitive in near-field
scenarios due to the need for exhaustive 3D grid searches. This paper presents
a machine learning-based approach for 3D localization of near-field sources in
mixed line-of-sight (LoS)/non-LoS scenarios. A convolutional neural network
(CNN) learns the mapping between the eigenvectors of the received signal's
covariance matrix at the anchor node and the sources' 3D locations. The
detailed description of the proposed CNN model is provided. The effectiveness
and time efficiency of the proposed CNN-based localization approach is
corroborated via numerical simulations.

</details>


### [4] [Near-Field Propagation and Spatial Non-Stationarity Channel Model for 6-24 GHz (FR3) Extremely Large-Scale MIMO: Adopted by 3GPP for 6G](https://arxiv.org/abs/2506.17887)
*Huixin Xu,Jianhua Zhang,Pan Tang,Hongbo Xing,Haiyang Miao,Nan Zhang,Jian Li,Jianming Wu,Wenfei Yang,Zhening Zhang,Wei Jiang,Zijian He,Afshin Haghighat,Qixing Wang,Guangyi Liu*

Main category: eess.SP

TL;DR: 论文提出了一种针对XL-MIMO系统的信道建模框架，结合了近场传播和空间非平稳性（SNS）特征，并被3GPP采纳。


<details>
  <summary>Details</summary>
Motivation: 6-24 GHz频段和XL-MIMO的部署需要解决现有3GPP信道模型中远场和空间平稳性假设失效的问题。

Method: 通过建模球形波源距离和随机方法分别处理近场传播和SNS效应，同时引入物理阻塞模型。

Result: 近场模型显示出更高的信道容量潜力，SNS导致更显著的传播衰落。

Conclusion: 该框架为XL-MIMO系统提供了更准确的信道建模方法。

Abstract: Next generation cellular deployments are expected to exploit the 6-24 GHz
frequency range 3 (FR3) and extremely large-scale multiple-input
multiple-output (XL-MIMO) to enable ultra-high data rates and reliability.
However, the significantly enlarged antenna apertures and higher carrier
frequencies render the far-field and spatial stationarity assumptions in the
existing 3rd generation partnership project (3GPP) channel models invalid,
giving rise to new features such as near-field propagation and spatial
non-stationarity (SNS). Despite extensive prior research, incorporating these
new features within the standardized channel modeling framework remains an open
issue. To address this, this paper presents a channel modeling framework for
XL-MIMO systems that incorporates both near-field and SNS features, adopted by
3GPP. For the near-field propagation feature, the framework models the
distances from the base station (BS) and user equipment to the spherical-wave
sources associated with clusters. These distances are used to characterize
element-wise variations of path parameters, such as nonlinear changes in phase
and angle. To capture the effect of SNS at the BS side, a stochastic-based
approach is proposed to model SNS caused by incomplete scattering, by
establishing power attenuation factors from visibility probability and
visibility region to characterize antenna element-wise path power variation. In
addition, a physical blocker-based approach is introduced to model SNS effects
caused by partial blockage. Finally, a simulation framework for near-field and
SNS is developed within the structure of the existing 3GPP channel model.
Performance evaluations demonstrate that the near-field model captures higher
channel capacity potential compared to the far-field model. Coupling loss
results indicate that SNS leads to more pronounced propagation fading relative
to the spatial stationary model.

</details>


### [5] [ISAC Network Planning: Sensing Coverage Analysis and 3-D BS Deployment Optimization](https://arxiv.org/abs/2506.18009)
*Kaitao Meng,Kawon Han,Christos Masouros,Lajos Hanzo*

Main category: eess.SP

TL;DR: 论文研究了集成感知与通信（ISAC）网络中基站部署对感知与通信性能权衡的影响，提出了一种同时最大化目标定位覆盖和保证通信性能的设计。


<details>
  <summary>Details</summary>
Motivation: 解决ISAC网络中如何通过基站部署优化感知与通信性能的权衡问题，确保全区域一致的高定位精度。

Method: 采用基于飞行时间（ToF）的定位方法，从定位性能覆盖角度分析部署问题，最小化区域Cramer-Rao下界（A-CRLB），推导了基站数量固定时服务区域缩放对A-CRLB的影响规律。

Result: 证明了服务区域缩放因子κ与A-CRLB的关系（κ^{2β}），提出了感知区域维度与A-CRLB的近似缩放规律，并发现协作基站扩展覆盖但对A-CRLB改善有限。

Conclusion: 通过理论分析和设计，为ISAC网络中的基站部署提供了优化方法，平衡了感知与通信性能。

Abstract: Integrated sensing and communication (ISAC) networks strive to deliver both
high-precision target localization and high-throughput data services across the
entire coverage area. In this work, we examine the fundamental trade-off
between sensing and communication from the perspective of base station (BS)
deployment. Furthermore, we conceive a design that simultaneously maximizes the
target localization coverage, while guaranteeing the desired communication
performance. In contrast to existing schemes optimized for a single target, an
effective network-level approach has to ensure consistent localization accuracy
throughout the entire service area. While employing time-of-flight (ToF) based
localization, we first analyze the deployment problem from a
localization-performance coverage perspective, aiming for minimizing the area
Cramer-Rao Lower Bound (A-CRLB) to ensure uniformly high positioning accuracy
across the service area. We prove that for a fixed number of BSs, uniformly
scaling the service area by a factor \kappa increases the optimal A-CRLB in
proportion to \kappa^{2\beta}, where \beta is the BS-to-target pathloss
exponent. Based on this, we derive an approximate scaling law that links the
achievable A-CRLB across the area of interest to the dimensionality of the
sensing area. We also show that cooperative BSs extends the coverage but yields
marginal A-CRLB improvement as the dimensionality of the sensing area grows.

</details>


### [6] [Cooperative Bistatic ISAC Systems for Low-Altitude Economy](https://arxiv.org/abs/2506.18067)
*Zhenkun Zhang,Yining Xu,Cunhua Pan,Hong Ren,Yiming Yu,Jiangzhou Wang*

Main category: eess.SP

TL;DR: 提出了一种基于MIMO-OFDM蜂窝网络的协作双基地ISAC框架，通过低复杂度算法和鲁棒融合方案，解决了低空经济中的多目标定位和速度估计问题。


<details>
  <summary>Details</summary>
Motivation: 低空经济的快速发展需要高精度多目标定位和速度估计的ISAC系统，而传统架构存在硬件和覆盖限制。

Method: 采用CP张量分解提取参数，并设计基于MST的鲁棒融合方案，实现联合3D位置和速度重建。

Result: 仿真验证了该框架在计算效率和低空场景感知性能上的优越性。

Conclusion: 该框架为低空经济应用提供了高效的ISAC解决方案。

Abstract: The burgeoning low-altitude economy (LAE) necessitates integrated sensing and
communication (ISAC) systems capable of high-accuracy multi-target localization
and velocity estimation under hardware and coverage constraints inherent in
conventional ISAC architectures. This paper addresses these challenges by
proposing a cooperative bistatic ISAC framework within MIMO-OFDM cellular
networks, enabling robust sensing services for LAE applications through
standardized 5G New Radio (NR) infrastructure. We first develop a
low-complexity parameter extraction algorithm employing CANDECOMP/PARAFAC (CP)
tensor decomposition, which exploits the inherent Vandermonde structure in
delay-related factor matrices to efficiently recover bistatic ranges, Doppler
velocities, and angles-of-arrival (AoA) from multi-dimensional received signal
tensors. To resolve data association ambiguity across distributed
transmitter-receiver pairs and mitigate erroneous estimates, we further design
a robust fusion scheme based on the minimum spanning tree (MST) method,
enabling joint 3D position and velocity reconstruction. Comprehensive
simulation results validate the framework's superiority in computational
efficiency and sensing performance for low-altitude scenarios.

</details>


### [7] [Coherent Track-Before-Detect](https://arxiv.org/abs/2506.18177)
*Mingchao Liang,Florian Meyer*

Main category: eess.SP

TL;DR: 本文提出了一种基于综合信号模型的相干TBD方法，用于复杂环境中多目标跟踪，克服了传统方法的局限性，并通过实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 在复杂环境中准确跟踪未知且随时间变化的目标数量是一个重要挑战，传统方法因预处理步骤可能丢失关键信息，而现有TBD方法因简化假设导致性能受限。

Method: 提出了一种新的相干TBD方法，基于综合信号模型考虑传感器数据相关性和幅度波动，并开发了基于因子图的可扩展BP方法进行高效贝叶斯推断。

Result: 实验结果表明，该方法在合成和真实数据上均优于现有最先进的传统MOT方法。

Conclusion: 相干TBD方法能够更准确地表示数据生成过程的物理特性，适用于多种雷达、声纳及传感通信系统问题。

Abstract: Accurately tracking an unknown and time-varying number of objects in complex
environments is a significant challenge but a fundamental capability in a
variety of applications, including applied ocean sciences, surveillance,
autonomous driving, and wireless communications. Conventional Bayesian
multiobject tracking (MOT) methods typically employ a detect-then-track (DTT)
approach, where a frontend detector preprocesses raw sensor data to extract
measurements for MOT. The irreversible nature of this preprocessing step can
discard valuable object-related information, particularly impairing the ability
to resolve weak or closely spaced objects. The track-before-detect (TBD)
paradigm offers an alternative by operating directly on sensor data. However,
existing TBD approaches introduce simplifications to facilitate the development
of inference methods, such as assuming known signal amplitudes or conditional
independence between sensor measurements given object states. These assumptions
can lead to suboptimal performance and limit the applicability of the resulting
TBD methods in realistic scenarios.
  This paper introduces coherent TBD based on a comprehensive signal model for
sensor data. The new model accounts for sensor data correlations and amplitude
fluctuations, enabling the accurate representation of the physics of the
data-generating process in TBD. Coherent TBD is suitable for a wide range of
problems in active and passive radar, active and passive sonar, as well as
integrated sensing and communication systems. Based on a factor graph
representation of the new measurement model, a scalable belief propagation (BP)
method is developed to perform efficient Bayesian inference. Experimental
results, performed with both synthetic and real data, demonstrate that the
proposed method outperforms state-of-the-art conventional MOT methods.

</details>


### [8] [Multimodal Visual Image Based User Association and Beamforming Using Graph Neural Networks](https://arxiv.org/abs/2506.18218)
*Yinghan Li,Yiming Liu,Wei Yu*

Main category: eess.SP

TL;DR: 提出一种多模态数据融合方法，结合视觉图像和射频信号优化无线网络中的用户关联和波束成形，提升性能并降低开销。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖大量射频导频获取信道状态信息，导致高开销和延迟，且优化问题复杂。

Method: 利用视觉图像增强信道感知，结合检测神经网络和GNN进行联合优化。

Result: 仿真显示该方法性能优越，复杂度低且可解释性强。

Conclusion: 多模态融合方法优于传统射频导频方法，是有效的解决方案。

Abstract: This paper proposes an approach that leverages multimodal data by integrating
visual images with radio frequency (RF) pilots to optimize user association and
beamforming in a downlink wireless cellular network under a max-min fairness
criterion. Traditional methods typically optimize wireless system parameters
based on channel state information (CSI). However, obtaining accurate CSI
requires extensive pilot transmissions, which lead to increased overhead and
latency. Moreover, the optimization of user association and beamforming is a
discrete and non-convex optimization problem, which is challenging to solve
analytically. In this paper, we propose to incorporate visual camera data in
addition to the RF pilots to perform the joint optimization of user association
and beamforming. The visual image data helps enhance channel awareness, thereby
reducing the dependency on extensive pilot transmissions for system
optimization. We employ a learning-based approach based on using first a
detection neural network that estimates user locations from images, and
subsequently two graph neural networks (GNNs) that extract features for system
optimization based on the location information and the received pilots,
respectively. Then, a multimodal GNN is constructed to integrate the features
for the joint optimization user association and beamforming. Simulation results
demonstrate that the proposed method achieves superior performance, while
having low computational complexity and being interpretable and generalizable,
making it an effective solution as compared to traditional methods based only
on RF pilots.

</details>


### [9] [LLM-Integrated Digital Twins for Hierarchical Resource Allocation in 6G Networks](https://arxiv.org/abs/2506.18293)
*Majumder Haider,Imtiaz Ahmed,Zoheb Hassan,Kamrul Hasan,H. Vincent Poor*

Main category: eess.SP

TL;DR: 论文提出了一种名为LLM-DTNet的分层框架，结合数字孪生（DTs）和大语言模型（LLMs），用于下一代无线网络的实时资源管理优化。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络需要智能、可扩展且上下文感知的无线资源管理（RRM），以应对超密集部署、多样化服务需求和动态网络条件。

Method: 提出了LLM-DTNet框架，通过多层DT架构与基于LLM的编排相结合，实现异构网络的实时自适应RRM。

Result: 该框架在主动和情境感知的网络管理中表现出色，适用于地面和非地面应用。

Conclusion: 未来研究方向包括可扩展的DT建模、安全的LLM-DT集成、能效优化和多模态数据处理。

Abstract: Next-generation (NextG) wireless networks are expected to require
intelligent, scalable, and context-aware radio resource management (RRM) to
support ultra-dense deployments, diverse service requirements, and dynamic
network conditions. Digital twins (DTs) offer a powerful tool for network
management by creating high-fidelity virtual replicas that model real-time
network behavior, while large language models (LLMs) enhance decision-making
through their advanced generalization and contextual reasoning capabilities.
This article proposes LLM-driven DTs for network optimization (LLM-DTNet), a
hierarchical framework that integrates multi-layer DT architectures with
LLM-based orchestration to enable adaptive, real-time RRM in heterogeneous
NextG networks. We present the fundamentals and design considerations of
LLM-DTNet while discussing its effectiveness in proactive and situation-aware
network management across terrestrial and non-terrestrial applications.
Furthermore, we highlight key challenges, including scalable DT modeling,
secure LLM-DT integration, energy-efficient implementations, and multimodal
data processing, shaping future advancements in NextG intelligent wireless
networks.

</details>


### [10] [ARSAR-Net: Adaptively Regularized SAR Imaging Network via Non-matrix-inversion ADMM](https://arxiv.org/abs/2506.18324)
*Shiping Fu,Yufan Chen,Zhe Zhang,Xiaolan Qiu,Qixiang Ye*

Main category: eess.SP

TL;DR: 提出了一种自适应正则化的SAR成像网络（ARSAR-Net），通过可学习的正则化器提升泛化能力，解决了传统展开网络在场景适应性上的不足。


<details>
  <summary>Details</summary>
Motivation: 传统基于ADMM展开的SAR成像网络因正则化器经验设计而缺乏跨场景泛化能力，限制了其实际应用。

Method: 引入可学习的正则化器，构建ARSAR-Net，并采用非矩阵逆ADMM算法替代低效的矩阵逆运算。

Result: 实验表明，ARSAR-Net成像速度提升50%，PSNR提高2.0 dB，且对复杂场景适应性更强。

Conclusion: ARSAR-Net为高效计算和泛化能力强的SAR成像系统提供了新范式。

Abstract: Deep unfolding networks have constituted an emerging method for synthetic
aperture radar (SAR) imaging. However, baseline unfolding networks, when
unfolded from the alternating direction method of multipliers (ADMM), lack
generalization capability across scenes as the regularizers are empirically
designed. In this study, we introduce a learnable regularizer to the unfolding
network and create an adaptively regularized SAR imaging network (ARSAR-Net),
which pursues generalization capability across scenes, including varying
sparsity levels and heterogeneous scenes with offshore ships, islands, urban
areas, and mountainous terrain. In practice, the vanilla ARSAR-Net suffers from
inherent structural limitations in 2D signal processing, primarily due to its
reliance on matrix inversion. To conquer this challenge, we introduce the
non-matrix-inversion ADMM algorithm, which replaces inefficient matrix
inversion with efficient linear approximations. Extensive validation through
simulated and real-data experiments (including GF-3 satellite echoes)
demonstrates ARSAR-Net's triple advantage: (1) 50\% faster imaging speed
compared to existing unfolding networks, (2) up to 2.0 dB PSNR improvement in
imaging quality, and (3) enhanced adaptability to complex heterogeneous scenes.
These advancements establish a new paradigm for computationally efficient and
generalizable SAR imaging systems.

</details>


### [11] [Generative Diffusion Receivers: Achieving Pilot-Efficient MIMO-OFDM Communications](https://arxiv.org/abs/2506.18419)
*Yuzhi Yang,Omar Alhussein,Atefeh Arani,Zhaoyang Zhang,Mérouane Debbah*

Main category: eess.SP

TL;DR: 本文提出了一种基于扩散模型的MIMO-OFDM接收器，通过结合传统信号估计和生成模型，显著降低了信道重建误差。


<details>
  <summary>Details</summary>
Motivation: 传统无线接收器在信道矩阵表征方面存在不足，而神经网络虽具潜力，但与传统方法结合时面临挑战。扩散模型因其抗噪性成为新选择。

Method: 利用扩散模型重新评估MIMO-OFDM接收器，引入想象-筛选策略指导扩散过程，并适应不同噪声水平和导频方案。

Result: 在低导频条件下，信道重建误差降低至领先深度学习模型的一半，性能随想象规模增大而提升。

Conclusion: 扩散模型为MIMO-OFDM接收器提供了高效且灵活的解决方案，显著提升了性能并降低了成本。

Abstract: This paper focuses on wireless multiple-input multiple-output
(MIMO)-orthogonal frequency division multiplex (OFDM) receivers. Traditional
wireless receivers have relied on mathematical modeling and Bayesian inference,
achieving remarkable success in most areas but falling short in their ability
to characterize channel matrices. Neural networks (NNs) have demonstrated
significant potential in this aspect. Nevertheless, integrating traditional
inference methods with NNs presents challenges, particularly in tracking the
error progression. Given the inevitable presence of noise in wireless systems,
generative models that are more resilient to noise are garnering increased
attention. In this paper, we propose re-evaluating the MIMO-OFDM receiver using
diffusion models, which is a common generative approach. With diffusion models,
we can effectively leverage prior knowledge of channel matrices and incorporate
traditional signal estimation components. Specifically, we explore the
diffusion system and introduce an imagination-screening strategy to guide the
diffusion process. Furthermore, diffusion models enable adaptation to varying
noise levels and pilot schemes using the same NN, significantly reducing
training and deployment costs. Simulated results reveal that, for pilot
densities ranging from 4-6 pilots per 64-subcarrier block and signal-to-noise
ratios (SNRs) from -4 dB to 0 dB, our proposed receiver reduces
channel-reconstruction error by up to two times compared to leading
deep-learning models, with the most pronounced improvements observed in
low-pilot conditions. Additionally, performance enhancements can be achieved
with a larger imagination size, despite increased computational complexity.

</details>


### [12] [A New Pathway to Integrated Learning and Communication (ILAC): Large AI Model and Hyperdimensional Computing for Communication](https://arxiv.org/abs/2506.18432)
*Wei Xu,Zhaohui Yang,Derrick Wing Kwan Ng,Robert Schober,H. Vincent Poor,Zhaoyang Zhang,Xiaohu You*

Main category: eess.SP

TL;DR: 本文探讨了6G网络中人工智能与无线通信的无缝集成，提出了集成学习与通信（ILAC）的统一框架，以解决通信限制对学习性能的影响，并通过案例研究展示了优化解决方案。


<details>
  <summary>Details</summary>
Motivation: 6G网络的快速发展需要AI与无线通信的集成，以支持高效通信和强大学习性能的智能应用。

Method: 提出了ILAC框架，结合Dinkelbach和交替优化算法，优化任务分配、模型大小选择、带宽分配和传输功率控制。

Result: 通过案例研究，实现了学习性能与通信约束之间的最优平衡。

Conclusion: ILAC框架为6G网络中AI与通信的集成提供了实用解决方案，解决了实际挑战。

Abstract: The rapid evolution of forthcoming sixth-generation (6G) wireless networks
necessitates the seamless integration of artificial intelligence (AI) with
wireless communications to support emerging intelligent applications that
demand both efficient communication and robust learning performance. This dual
requirement calls for a unified framework of integrated learning and
communication (ILAC), where AI enhances communication through intelligent
signal processing and adaptive resource management, while wireless networks
support AI model deployment by enabling efficient and reliable data exchanges.
However, achieving this integration presents significant challenges in
practice. Communication constraints, such as limited bandwidth and fluctuating
channels, hinder learning accuracy and convergence. Simultaneously, AI-driven
learning dynamics, including model updates and task-driven inference, introduce
excessive burdens on communication systems, necessitating flexible,
context-aware transmission strategies. Finally, we present a case study on a
cost-to-performance optimization problem, where task assignments, model size
selection, bandwidth allocation, and transmission power control are jointly
optimized, considering computational cost, communication efficiency, and
inference accuracy. Leveraging the Dinkelbach and alternating optimization
algorithms, we offer a practical and effective solution to achieve an optimal
balance between learning performance and communication constraints.

</details>


### [13] [Sizing Antenna Arrays for Near-field Communication and Sensing](https://arxiv.org/abs/2506.18465)
*Marcin Wachowiak,André Bourdoux,Sofie Pollin*

Main category: eess.SP

TL;DR: 本文分析了近场通信和传感系统的关键性能指标，重点研究了其随天线阵列孔径变化的缩放行为，并提供了设计大型天线阵列的实用指南。


<details>
  <summary>Details</summary>
Motivation: 研究近场通信和传感系统中天线阵列孔径对性能的影响，为系统设计提供理论支持。

Method: 通过分析近场波束聚焦、近场区域范围和可分辨波束点数量等指标，推导了多种标准阵列几何结构的解析表达式。

Result: 发现近场波束聚焦的最小深度随孔径增加快速饱和，而近场区域范围与孔径呈二次方关系；可分辨波束点数量与孔径呈线性关系。

Conclusion: 研究结果为近场通信和传感应用中孔径需求的设计提供了实用指导。

Abstract: This paper presents key performance metrics for near-field communication and
sensing systems with a focus on their scaling behavior as a function of the
antenna array aperture. Analytical expressions are derived for several standard
array geometries to enable the design of the large antenna arrays for given
system requirements. First, the near-field beam focusing is analyzed and the
minimum beamdepth is observed to rapidly saturate to a low asymptotic limit as
the array aperture increases. In contrast, the near-field region span is shown
to scale quadratically with the array aperture. Based on these two metrics, the
maximum number of resolvable beamspots at 3 dB separation is derived
analytically, exhibiting a linear dependence on the array aperture. Finally,
the number of significant singular values of a channel observed at the array's
broadside is estimated, showing a power-law dependence on the aperture. The
resulting expressions provide practical design guidelines for evaluating
aperture requirements in near-field communication and sensing applications.

</details>


### [14] [Fast State-Augmented Learning for Wireless Resource Allocation with Dual Variable Regression](https://arxiv.org/abs/2506.18748)
*Yigit Berkay Uslu,Navid NaderiAlizadeh,Mark Eisen,Alejandro Ribeiro*

Main category: eess.SP

TL;DR: 论文提出了一种基于图神经网络（GNN）的资源分配方法，通过动态输入对偶变量优化网络性能，避免了传统对偶次梯度方法的缺点。


<details>
  <summary>Details</summary>
Motivation: 解决多用户无线网络中资源分配问题，优化网络效用函数，同时满足用户平均性能约束。

Method: 使用状态增强的GNN参数化资源分配策略，将对偶变量视为动态输入，并通过离线训练学习拉格朗日最大化策略。

Result: 在传输功率控制的案例中，算法表现出优越性能，并通过数值实验验证。

Conclusion: 该方法有效提升了对偶变量初始化和训练效率，并提供了收敛性和最优性间隙的概率界限。

Abstract: We consider resource allocation problems in multi-user wireless networks,
where the goal is to optimize a network-wide utility function subject to
constraints on the ergodic average performance of users. We demonstrate how a
state-augmented graph neural network (GNN) parametrization for the resource
allocation policy circumvents the drawbacks of the ubiquitous dual subgradient
methods by representing the network configurations (or states) as graphs and
viewing dual variables as dynamic inputs to the model, viewed as graph signals
supported over the graphs. Lagrangian maximizing state-augmented policies are
learned during the offline training phase, and the dual variables evolve
through gradient updates while executing the learned state-augmented policies
during the inference phase. Our main contributions are to illustrate how
near-optimal initialization of dual multipliers for faster inference can be
accomplished with dual variable regression, leveraging a secondary GNN
parametrization, and how maximization of the Lagrangian over the multipliers
sampled from the dual descent dynamics substantially improves the training of
state-augmented models. We demonstrate the superior performance of the proposed
algorithm with extensive numerical experiments in a case study of transmit
power control. Finally, we prove a convergence result and an exponential
probability bound on the excursions of the dual function (iterate) optimality
gaps.

</details>


### [15] [Variational Bayesian Channel Estimation and Data Detection for Cell-Free Massive MIMO with Low-Resolution Quantized Fronthaul Links](https://arxiv.org/abs/2506.18863)
*Sajjad Nassirpour,Toan-Van Nguyen,Hien Q. Ngo,Le-Nam Tran,Tharmalingam Ratnarajah,Duy H. N. Nguyen*

Main category: eess.SP

TL;DR: 论文研究了在无小区大规模MIMO网络中联合信道估计与数据检测（JED）问题，提出基于变分贝叶斯（VB）推断的方法，比较了量化-估计（Q-E）和估计-量化（E-Q）两种方法，并验证了其优于传统LMMSE方法的性能。


<details>
  <summary>Details</summary>
Motivation: 无小区大规模MIMO网络中，前传链路带宽有限，用户数量不断增加，传统的联合信道估计与数据检测方法面临挑战。

Method: 提出基于变分贝叶斯（VB）推断的方法，比较了Q-E和E-Q两种策略，分别对信号进行量化后估计和先估计后量化。

Result: VB(Q-E)和VB(E-Q)方法在符号错误率、信道估计误差等方面优于LMMSE方法，且VB(Q-E)表现更优。

Conclusion: 基于VB的方法在有限前传带宽下显著提升了性能，尤其是Q-E策略更有效。

Abstract: We study the joint channel estimation and data detection (JED) problem in a
cell-free massive multiple-input multiple-output (CF-mMIMO) network, where
access points (APs) communicate with a central processing unit (CPU) over
fronthaul links. However, the bandwidth of these links is limited, and thus,
presents challenges to the applicability of CF-mMIMO, especially with an
ever-increasing number of users. To address this, we propose a method based on
variational Bayesian (VB) inference for performing the JED process, where the
APs forward low-resolution quantized versions of the signals to the CPU. We
consider two approaches: \emph{quantization-and-estimation} (Q-E) and
\emph{estimation-and-quantization} (E-Q). In the Q-E approach, each AP uses a
low-bit quantizer to quantize the signal before forwarding it to the CPU, while
in the E-Q approach, each AP first performs local channel estimation and then
sends a low-bit quantized version of the estimated channel to the CPU. We
evaluate the performance of our VB-based approach under perfect fronthaul link
(PFL) with unquantized received signals, Q-E, and E-Q in terms of symbol error
rate (SER), normalized mean square error (NMSE) of the channel estimation,
computational complexity, and fronthaul signaling overhead. We also compare
these results with those of the linear minimum mean squared error (LMMSE)
method under the PFL scenario. Our numerical results show that both the VB(Q-E)
and VB(E-Q) approaches achieve superior performance compared to LMMSE(PFL),
benefiting from the nonlinear modeling inherent in VB. Furthermore, the VB(Q-E)
method outperforms VB(E-Q) due to errors in the local channel estimation
process at the APs within the VB(E-Q) approach.

</details>


### [16] [Achieving 70 Gb/s Over A VCSEL-Based Optical Wireless Link Using A Multi-Mode Fiber-Coupled Receiver](https://arxiv.org/abs/2506.18864)
*Hossein Kazemi,Isaac N. O. Osahon,Nikolay Ledentsov Jr.,Ilya Titkov,Nikolay Ledentsov,Harald Haas*

Main category: eess.SP

TL;DR: 本文展示了一种基于激光的光无线通信系统，使用940 nm单模VCSEL和多模光纤耦合接收器，实现了超过70 Gb/s的数据速率，且发射功率低于5 mW。


<details>
  <summary>Details</summary>
Motivation: 探索低成本、低功耗的VCSEL在下一代LiFi连接中的潜力，以实现超高速室内光无线通信。

Method: 采用940 nm单模VCSEL和多模光纤耦合接收器，结合高速光纤光电接收器，避免接收器限制通信带宽。

Result: 实现了超过70 Gb/s的数据速率，发射功率低于5 mW，验证了系统的超高速和高效能特性。

Conclusion: 实验证明了低成本、低功耗的VCSEL在下一代LiFi连接中的可行性，为超高速室内光无线通信开辟了新应用。

Abstract: In this paper, we demonstrate a laser-based optical wireless communication
(OWC) system employing a 940 nm single-mode (SM) vertical cavity surface
emitting laser (VCSEL) and a multi-mode (MM) fiber-coupled receiver, achieving
a record data rate beyond 70 Gb/s, while the optical transmit power is below 5
mW. The use of a high speed fiber-optic photoreceiver avoids limiting the
communication bandwidth by the receiver, enabling ultra-high capacity and
energy-efficient light fidelity (LiFi) links to unlock new applications. This
work experimentally validates the feasibility of ultra-high speed indoor OWC
systems using a single low-power and low-cost VCSEL for next-generation LiFi
connectivity.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [17] [Enhancing Few-shot Keyword Spotting Performance through Pre-Trained Self-supervised Speech Models](https://arxiv.org/abs/2506.17686)
*Alican Gok,Oguzhan Buyuksolak,Osman Erman Okman,Murat Saraclar*

Main category: eess.AS

TL;DR: 论文提出了一种基于自监督学习的训练方案，用于提升少样本关键词识别的准确率，特别适用于资源受限的边缘设备。


<details>
  <summary>Details</summary>
Motivation: 解决现有少样本关键词识别系统在资源受限环境下准确率低的问题。

Method: 利用自监督学习模型（如Wav2Vec 2.0）进行特征提取，结合Sub-center ArcFace损失函数增强类间分离性和类内紧凑性，并通过注意力降维和轻量级ResNet15学生模型实现高效部署。

Result: 在GSC数据集上，10样本分类准确率从33.4%提升至74.1%，显著优于现有方法。

Conclusion: 提出的训练方案显著提升了少样本关键词识别的性能，适用于实际应用场景。

Abstract: Keyword Spotting plays a critical role in enabling hands-free interaction for
battery-powered edge devices. Few-Shot Keyword Spotting (FS-KWS) addresses the
scalability and adaptability challenges of traditional systems by enabling
recognition of custom keywords with only a few examples. However, existing
FS-KWS systems achieve subpar accuracy at desirable false acceptance rates,
particularly in resource-constrained edge environments. To address these
issues, we propose a training scheme that leverages self-supervised learning
models for robust feature extraction, dimensionality reduction, and knowledge
distillation. The teacher model, based on Wav2Vec 2.0 is trained using
Sub-center ArcFace loss, which enhances inter-class separability and
intra-class compactness. To enable efficient deployment on edge devices, we
introduce attention-based dimensionality reduction and train a standard
lightweight ResNet15 student model. We evaluate the proposed approach on the
English portion of the Multilingual Spoken Words Corpus (MSWC) and the Google
Speech Commands (GSC) datasets. Notably, the proposed training method improves
the 10-shot classification accuracy from 33.4% to 74.1% on 11 classes at 1%
false alarm accuracy on the GSC dataset, thus making it significantly
better-suited for a real use case scenario.

</details>


### [18] [Low-resource keyword spotting using contrastively trained transformer acoustic word embeddings](https://arxiv.org/abs/2506.17690)
*Julian Herreilers,Christiaan Jacobs,Thomas Niesler*

Main category: eess.AS

TL;DR: 提出了一种名为ContrastiveTransformer的新方法，用于生成声学词嵌入（AWE），以支持极低资源关键词检测。


<details>
  <summary>Details</summary>
Motivation: 解决极低资源语言（如Luganda和Bambara）中的关键词检测问题。

Method: 使用ContrastiveTransformer（仅编码器模型），通过NT-Xent损失直接优化嵌入空间。

Result: 在Luganda和Bambara两种语言中，该方法优于现有AWE方法，包括基于大规模预训练自监督模型的方法。

Conclusion: ContrastiveTransformer在极低资源关键词检测任务中表现出优越性能。

Abstract: We introduce a new approach, the ContrastiveTransformer, that produces
acoustic word embeddings (AWEs) for the purpose of very low-resource keyword
spotting. The ContrastiveTransformer, an encoder-only model, directly optimises
the embedding space using normalised temperature-scaled cross entropy (NT-Xent)
loss. We use this model to perform keyword spotting for radio broadcasts in
Luganda and Bambara, the latter a severely under-resourced language. We compare
our model to various existing AWE approaches, including those constructed from
large pre-trained self-supervised models, a recurrent encoder which previously
used the NT-Xent loss, and a DTW baseline. We demonstrate that the proposed
contrastive transformer approach offers performance improvements over all
considered existing approaches to very low-resource keyword spotting in both
languages.

</details>


### [19] [Blind Source Separation in Biomedical Signals Using Variational Methods](https://arxiv.org/abs/2506.18281)
*Yasaman Torabi,Shahram Shirani,James P. Reilly*

Main category: eess.AS

TL;DR: 提出了一种基于变分自编码器（VAE）的无监督方法，用于分离重叠的心音和肺音，无需标记数据或先验知识。


<details>
  <summary>Details</summary>
Motivation: 临床环境中，心音和肺音常互相干扰，手动分离困难且易出错，因此需要一种自动化的解决方案。

Method: 使用VAE将混合信号编码到结构化潜在空间，并通过概率解码器重构各成分。

Result: 实验结果显示，潜在空间中形成对应心音和肺音的聚类，重构信号保留了原始频谱特征。

Conclusion: 该方法为盲源分离提供了鲁棒且可解释的解决方案，适用于便携式诊断工具和智能听诊系统。

Abstract: This study introduces a novel unsupervised approach for separating
overlapping heart and lung sounds using variational autoencoders (VAEs). In
clinical settings, these sounds often interfere with each other, making manual
separation difficult and error-prone. The proposed model learns to encode mixed
signals into a structured latent space and reconstructs the individual
components using a probabilistic decoder, all without requiring labeled data or
prior knowledge of source characteristics. We apply this method to real
recordings obtained from a clinical manikin using a digital stethoscope.
Results demonstrate distinct latent clusters corresponding to heart and lung
sources, as well as accurate reconstructions that preserve key spectral
features of the original signals. The approach offers a robust and
interpretable solution for blind source separation and has potential
applications in portable diagnostic tools and intelligent stethoscope systems.

</details>


### [20] [Infant Cry Emotion Recognition Using Improved ECAPA-TDNN with Multiscale Feature Fusion and Attention Enhancement](https://arxiv.org/abs/2506.18402)
*Junyu Zhou,Yanxiong Li,Haolin Yu*

Main category: eess.AS

TL;DR: 提出了一种改进的ECAPA-TDNN方法，用于婴儿哭声情感识别，结合多尺度特征融合和注意力增强，在公开数据集上达到82.20%的准确率。


<details>
  <summary>Details</summary>
Motivation: 婴儿哭声情感识别在育儿和医疗应用中至关重要，但现有方法难以有效整合多尺度特征和时频关系。

Method: 改进的ECAPA-TDNN，结合多尺度特征融合和注意力增强。

Result: 准确率82.20%，参数1.43 MB，FLOPs 0.32 Giga，优于基线方法。

Conclusion: 该方法在婴儿哭声情感识别中表现出色，具有实际应用潜力。

Abstract: Infant cry emotion recognition is crucial for parenting and medical
applications. It faces many challenges, such as subtle emotional variations,
noise interference, and limited data. The existing methods lack the ability to
effectively integrate multi-scale features and temporal-frequency
relationships. In this study, we propose a method for infant cry emotion
recognition using an improved Emphasized Channel Attention, Propagation and
Aggregation in Time Delay Neural Network (ECAPA-TDNN) with both multi-scale
feature fusion and attention enhancement. Experiments on a public dataset show
that the proposed method achieves accuracy of 82.20%, number of parameters of
1.43 MB and FLOPs of 0.32 Giga. Moreover, our method has advantage over the
baseline methods in terms of accuracy. The code is at
https://github.com/kkpretend/IETMA.

</details>


### [21] [Fully Few-shot Class-incremental Audio Classification Using Multi-level Embedding Extractor and Ridge Regression Classifier](https://arxiv.org/abs/2506.18406)
*Yongjie Si,Yanxiong Li,Jiaxin Tan,Qianhua He,Il-Youp Kwak*

Main category: eess.AS

TL;DR: 论文提出了一种解决Few-shot Class-incremental Audio Classification (FCAC)问题的新方法，适用于训练样本稀缺的情况。


<details>
  <summary>Details</summary>
Motivation: 由于数据稀缺和高收集成本，许多基础类别的训练样本难以充足收集，因此探讨了更现实的Fully FCAC (FFCAC)问题。

Method: 方法包括一个多级嵌入提取器和一个岭回归分类器，嵌入提取器在基础会话中训练并在增量会话中冻结，分类器在每次增量会话中更新。

Result: 在三个公开数据集上的实验表明，该方法在准确性和复杂性上优于现有方法。

Conclusion: 该方法为解决FFCAC问题提供了有效方案，代码已开源。

Abstract: In the task of Few-shot Class-incremental Audio Classification (FCAC),
training samples of each base class are required to be abundant to train model.
However, it is not easy to collect abundant training samples for many base
classes due to data scarcity and high collection cost. We discuss a more
realistic issue, Fully FCAC (FFCAC), in which training samples of both base and
incremental classes are only a few. Furthermore, we propose a FFCAC method
using a model which is decoupled into a multi-level embedding extractor and a
ridge regression classifier. The embedding extractor consists of an encoder of
audio spectrogram Transformer and a fusion module, and is trained in the base
session but frozen in all incremental sessions. The classifier is updated
continually in each incremental session. Results on three public datasets show
that our method exceeds current methods in accuracy, and has advantage over
most of them in complexity. The code is at https://github.com/YongjieSi/MAR.

</details>


### [22] [Efficient and Generalizable Speaker Diarization via Structured Pruning of Self-Supervised Models](https://arxiv.org/abs/2506.18623)
*Jiangyu Han,Petr Pálka,Marc Delcroix,Federico Landini,Johan Rohdin,Jan Cernocký,Lukáš Burget*

Main category: eess.AS

TL;DR: 论文研究了通过结构化剪枝和知识蒸馏压缩自监督学习（SSL）模型，以减少计算和内存成本，同时保持性能。实验显示模型大小减少80%，推理速度提升4倍，并在多个数据集上达到先进性能。


<details>
  <summary>Details</summary>
Motivation: 自监督学习模型（如WavLM）在说话人日志任务中表现优异，但其高计算和内存成本限制了实时和资源受限场景的应用。

Method: 采用结构化剪枝和知识蒸馏技术，研究基于MACs的剪枝目标、模块化和渐进式剪枝策略，并分析训练数据量的影响。

Result: 模型大小减少80%，推理速度提升4倍，在多个数据集上达到先进性能，且在CHiME-6数据集上表现优异。

Conclusion: 该方法有效压缩SSL模型，显著提升效率，同时保持性能，为资源受限场景提供了实用解决方案。

Abstract: Self-supervised learning (SSL) models such as WavLM have brought substantial
improvements to speaker diarization by providing rich contextual
representations. However, the high computational and memory costs of these
models hinder their deployment in real-time and resource-constrained scenarios.
In this work, we present a comprehensive study on compressing SSL-based
diarization models through structured pruning guided by knowledge distillation.
Building upon our previous work, we extend the analysis to include pruning
objectives based on multiply-accumulate operations (MACs), investigate
module-wise and progressive pruning strategies, and examine the impact of
training data quantity. Experimental results show that our method reduces model
size by up to 80% without degrading performance, achieving up to 4x faster
inference on a single GPU. We further perform large-scale evaluations on a
diverse compound dataset comprising eight public diarization corpora, where our
best pruned model achieves state-of-the-art performance across most conditions.
Additionally, we show strong generalization to the CHiME-6 dataset, attaining
performance comparable to the third-place system in the CHiME-7 challenge
without any domain adaptation. All models and code are publicly released to
support reproducibility and future research.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [23] [Zero-Shot Cognitive Impairment Detection from Speech Using AudioLLM](https://arxiv.org/abs/2506.17351)
*Mostafa Shahin,Beena Ahmed,Julien Epps*

Main category: cs.SD

TL;DR: 提出了一种基于零样本学习的语音认知障碍检测方法，利用多模态模型Qwen2-AudioLLM，通过提示指令实现分类，性能接近监督方法且具有跨语言和任务的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 认知障碍的早期检测对干预至关重要，传统方法依赖人工标注且泛化性差，因此探索零样本学习方法。

Method: 使用Qwen2-AudioLLM模型处理语音和文本输入，通过提示指令分类正常认知与认知障碍。

Result: 在英语和多语言数据集上，零样本方法性能接近监督方法，表现出跨语言和任务的泛化性与一致性。

Conclusion: 零样本语音检测方法为认知障碍早期筛查提供了高效且泛化性强的工具。

Abstract: Cognitive impairment (CI) is of growing public health concern, and early
detection is vital for effective intervention. Speech has gained attention as a
non-invasive and easily collectible biomarker for assessing cognitive decline.
Traditional CI detection methods typically rely on supervised models trained on
acoustic and linguistic features extracted from speech, which often require
manual annotation and may not generalise well across datasets and languages. In
this work, we propose the first zero-shot speech-based CI detection method
using the Qwen2- Audio AudioLLM, a model capable of processing both audio and
text inputs. By designing prompt-based instructions, we guide the model in
classifying speech samples as indicative of normal cognition or cognitive
impairment. We evaluate our approach on two datasets: one in English and
another multilingual, spanning different cognitive assessment tasks. Our
results show that the zero-shot AudioLLM approach achieves performance
comparable to supervised methods and exhibits promising generalizability and
consistency across languages, tasks, and datasets.

</details>


### [24] [Adaptive Control Attention Network for Underwater Acoustic Localization and Domain Adaptation](https://arxiv.org/abs/2506.17409)
*Quoc Thinh Vo,Joe Woods,Priontu Chowdhury,David K. Han*

Main category: cs.SD

TL;DR: 提出了一种多分支网络架构，用于在复杂海洋环境中准确预测移动声源与接收器之间的距离，结合CNN和Conformer，并引入自适应增益控制层，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 海洋环境复杂多变，声源定位困难，需克服高背景噪声、不规则几何形状和变化的声学特性等挑战。

Method: 采用多分支网络架构，结合CNN提取空间特征和Conformer捕捉时间依赖，输入为对数梅尔频谱和GCC-PHAT特征，并引入自适应增益控制层。

Result: 在跨域测试中，仅需少量数据微调即可优于现有方法，为水下声源定位设定了新基准。

Conclusion: 该方法在复杂海洋环境中表现出色，为声源定位提供了高效解决方案。

Abstract: Localizing acoustic sound sources in the ocean is a challenging task due to
the complex and dynamic nature of the environment. Factors such as high
background noise, irregular underwater geometries, and varying acoustic
properties make accurate localization difficult. To address these obstacles, we
propose a multi-branch network architecture designed to accurately predict the
distance between a moving acoustic source and a receiver, tested on real-world
underwater signal arrays. The network leverages Convolutional Neural Networks
(CNNs) for robust spatial feature extraction and integrates Conformers with
self-attention mechanism to effectively capture temporal dependencies. Log-mel
spectrogram and generalized cross-correlation with phase transform (GCC-PHAT)
features are employed as input representations. To further enhance the model
performance, we introduce an Adaptive Gain Control (AGC) layer, that adaptively
adjusts the amplitude of input features, ensuring consistent energy levels
across varying ranges, signal strengths, and noise conditions. We assess the
model's generalization capability by training it in one domain and testing it
in a different domain, using only a limited amount of data from the test domain
for fine-tuning. Our proposed method outperforms state-of-the-art (SOTA)
approaches in similar settings, establishing new benchmarks for underwater
sound localization.

</details>


### [25] [From Generality to Mastery: Composer-Style Symbolic Music Generation via Large-Scale Pre-training](https://arxiv.org/abs/2506.17497)
*Mingyang Yao,Ke Chen*

Main category: cs.SD

TL;DR: 论文提出了一种两阶段训练方法，通过预训练和微调结合，解决了作曲家风格音乐生成中的数据稀缺问题，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决作曲家风格音乐生成中因数据稀缺导致的风格和音乐元素建模困难问题。

Method: 采用两阶段训练：先在广泛音乐数据上预训练REMI模型，再用轻量级适配器模块在少量作曲家数据上微调。

Result: 实验表明，该方法在风格准确性和音乐性上优于基线，实现了更精确的风格建模和更好的音乐美学。

Conclusion: 通过通用预训练和风格微调，模型能有效学习音乐概念并提升风格理解。

Abstract: Despite progress in controllable symbolic music generation, data scarcity
remains a challenge for certain control modalities. Composer-style music
generation is a prime example, as only a few pieces per composer are available,
limiting the modeling of both styles and fundamental music elements (e.g.,
melody, chord, rhythm). In this paper, we investigate how general music
knowledge learned from a broad corpus can enhance the mastery of specific
composer styles, with a focus on piano piece generation. Our approach follows a
two-stage training paradigm. First, we pre-train a REMI-based music generation
model on a large corpus of pop, folk, and classical music. Then, we fine-tune
it on a small, human-verified dataset from four renowned composers, namely
Bach, Mozart, Beethoven, and Chopin, using a lightweight adapter module to
condition the model on style indicators. To evaluate the effectiveness of our
approach, we conduct both objective and subjective evaluations on style
accuracy and musicality. Experimental results demonstrate that our method
outperforms ablations and baselines, achieving more precise composer-style
modeling and better musical aesthetics. Additionally, we provide observations
on how the model builds music concepts from the generality pre-training and
refines its stylistic understanding through the mastery fine-tuning.

</details>


### [26] [Algebraic Structures in Microtonal Music](https://arxiv.org/abs/2506.17778)
*Veronica Flynn,Carmen Rovi*

Main category: cs.SD

TL;DR: 论文探讨了音乐理论中的群论结构，特别是24音微音音乐中的数学描述及其与群论的联系。


<details>
  <summary>Details</summary>
Motivation: 研究动机是将音乐理论中的音阶划分（如24音微音音乐）与群论结构联系起来，扩展Crans、Fiore和Satyendra的研究。

Method: 方法是将24音微音音乐中的音符编号，并用数学方式描述音乐动作，分析其群论结构。

Result: 结果表明，24音微音音乐中的和声结构可以用群论结构解释。

Conclusion: 结论是音乐理论与群论之间存在深刻的联系，24音微音音乐为这种联系提供了新的视角。

Abstract: We will discuss how certain group theory structures are found in music
theory. Western music splits the octave into 12 equal tones called half-steps.
We can take this division further and split the octave into 24 equal tones by
splitting each half-step in two, called a quarter-step. By assigning each of
these 24 notes a number, we can discuss musical actions mathematically. In this
paper, we analyze 24-tone microtonal music and explore how musical and harmonic
structures in this system can be interpreted in terms of group-theoretic
structures. This work extends the study by Crans, Fiore, and Satyendra.

</details>


### [27] [SLAP: Siamese Language-Audio Pretraining Without Negative Samples for Music Understanding](https://arxiv.org/abs/2506.17815)
*Julien Guinot,Alain Riou,Elio Quinton,György Fazekas*

Main category: cs.SD

TL;DR: SLAP是一种新型多模态预训练框架，通过避免负样本需求解决内存问题，并减少模态差距。


<details>
  <summary>Details</summary>
Motivation: 解决多模态联合嵌入空间中的内存需求和模态差距问题。

Method: 采用BYOL范式进行多模态音频-文本训练，无需负样本。

Result: 在文本-音乐检索和零样本分类任务上优于CLAP，并在多个MIR任务中表现优异。

Conclusion: SLAP具有高效、可扩展性强的特点，适合单GPU大规模训练。

Abstract: Joint embedding spaces have significantly advanced music understanding and
generation by linking text and audio through multimodal contrastive learning.
However, these approaches face large memory requirement limitations due to
relying on large batch sizes to effectively utilize negative samples. Further,
multimodal joint embedding spaces suffer from a modality gap wherein embeddings
from different modalities lie in different manifolds of the embedding space. To
address these challenges, we propose Siamese Language-Audio Pretraining (SLAP),
a novel multimodal pretraining framework that allows learning powerful
representations without negative samples. SLAP adapts the Bootstrap Your Own
Latent (BYOL) paradigm for multimodal audio-text training, promoting
scalability in training multimodal embedding spaces.
  We illustrate the ability of our model to learn meaningful relationships
between music and text -- specifically, we show that SLAP outperforms CLAP on
tasks such as text-music retrieval and zero-shot classification. We also
observe competitive downstream performance on several MIR tasks, including with
larger or supervised models (genre and instrument classification,
auto-tagging). Additionally, our approach has attractive properties, such as a
quantifiably reduced modality gap and improved robustness to batch size
variations on retrieval performance. Finally, its novel formulation unlocks
large-scale training on a single GPU through gradient accumulation.

</details>


### [28] [CultureMERT: Continual Pre-Training for Cross-Cultural Music Representation Learning](https://arxiv.org/abs/2506.17818)
*Angelos-Nikolaos Kanatas,Charilaos Papaioannou,Alexandros Potamianos*

Main category: cs.SD

TL;DR: CultureMERT-95M是一个多文化适应的音乐基础模型，通过两阶段持续预训练策略提升跨文化音乐表示学习，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有音乐基础模型对多样音乐传统的适应性有限，需改进跨文化音乐表示学习。

Method: 提出两阶段持续预训练策略，结合学习率重预热和重衰减，训练于650小时多文化音乐数据。

Result: 在非西方音乐自动标注任务中平均提升4.9%的ROC-AUC和AP，同时在西方基准上遗忘最小。

Conclusion: 多文化适应模型在跨文化任务中表现最佳，并公开模型以促进研究。

Abstract: Recent advances in music foundation models have improved audio representation
learning, yet their effectiveness across diverse musical traditions remains
limited. We introduce CultureMERT-95M, a multi-culturally adapted foundation
model developed to enhance cross-cultural music representation learning and
understanding. To achieve this, we propose a two-stage continual pre-training
strategy that integrates learning rate re-warming and re-decaying, enabling
stable adaptation even with limited computational resources. Training on a
650-hour multi-cultural data mix, comprising Greek, Turkish, and Indian music
traditions, results in an average improvement of 4.9% in ROC-AUC and AP across
diverse non-Western music auto-tagging tasks, surpassing prior
state-of-the-art, with minimal forgetting on Western-centric benchmarks. We
further investigate task arithmetic, an alternative approach to multi-cultural
adaptation that merges single-culture adapted models in the weight space. Task
arithmetic performs on par with our multi-culturally trained model on
non-Western auto-tagging tasks and shows no regression on Western datasets.
Cross-cultural evaluation reveals that single-culture models transfer with
varying effectiveness across musical traditions, whereas the multi-culturally
adapted model achieves the best overall performance. To support research on
world music representation learning, we publicly release CultureMERT-95M and
CultureMERT-TA-95M, fostering the development of more culturally aware music
foundation models.

</details>


### [29] [GD-Retriever: Controllable Generative Text-Music Retrieval with Diffusion Models](https://arxiv.org/abs/2506.17886)
*Julien Guinot,Elio Quinton,György Fazekas*

Main category: cs.SD

TL;DR: 论文提出了一种名为GDR的新框架，利用扩散模型在检索优化的潜在空间中生成查询，提高了文本-音乐检索的性能和可控性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态对比模型在文本-音频检索中表现良好，但缺乏用户可控性和交互性。文本-音乐检索中自由语言的模糊性导致结果不灵活或不满意。

Method: GDR框架结合扩散模型生成查询，支持负提示和DDIM反转等生成工具，实现检索行为的后处理操控。

Result: GDR在检索性能上优于对比教师模型，并支持非联合训练编码器的音频潜在空间检索。

Conclusion: GDR为文本-音乐检索任务提供了增强的交互控制，开辟了检索控制的新方向。

Abstract: Multimodal contrastive models have achieved strong performance in text-audio
retrieval and zero-shot settings, but improving joint embedding spaces remains
an active research area. Less attention has been given to making these systems
controllable and interactive for users. In text-music retrieval, the ambiguity
of freeform language creates a many-to-many mapping, often resulting in
inflexible or unsatisfying results.
  We introduce Generative Diffusion Retriever (GDR), a novel framework that
leverages diffusion models to generate queries in a retrieval-optimized latent
space. This enables controllability through generative tools such as negative
prompting and denoising diffusion implicit models (DDIM) inversion, opening a
new direction in retrieval control. GDR improves retrieval performance over
contrastive teacher models and supports retrieval in audio-only latent spaces
using non-jointly trained encoders. Finally, we demonstrate that GDR enables
effective post-hoc manipulation of retrieval behavior, enhancing interactive
control for text-music retrieval tasks.

</details>


### [30] [Human Voice is Unique](https://arxiv.org/abs/2506.18182)
*Rita Singh,Bhiksha Raj*

Main category: cs.SD

TL;DR: 该论文首次提出了一个客观计算人类声音独特性的框架，基于统计方法分析声音信号的可测量特征，并探讨了其对语音处理应用的影响。


<details>
  <summary>Details</summary>
Motivation: 随着声音作为生物特征在多种应用中的普及，需要验证其作为唯一生物标识符的有效性。

Method: 基于统计方法，分析声音信号中与发声过程因果相关但不相互依赖的可测量特征。

Result: 研究表明，在100亿人口中，两人声音相同的概率从几千分之一到万亿分之一以下不等。

Conclusion: 声音可以作为唯一生物标识符，其独特性量化结果对语音处理应用的设计具有重要影响。

Abstract: Voice is increasingly being used as a biometric entity in many applications.
These range from speaker identification and verification systems to human
profiling technologies that attempt to estimate myriad aspects of the speaker's
persona from their voice. However, for an entity to be a true biometric
identifier, it must be unique. This paper establishes a first framework for
calculating the uniqueness of human voice objectively. The approach in this
paper is based on statistical considerations that take into account a set of
measurable characteristics of the voice signal that bear a causal relationship
to the vocal production process, but are not inter-dependent or derivable from
each other. Depending on how we quantize these variables, we show that the
chances of two people having the same voice in a world populated by 10 billion
people range from one in a few thousand, to one in a septillion or less. The
paper also discusses the implications of these calculations on the choices made
in voice processing applications.

</details>


### [31] [JIS: A Speech Corpus of Japanese Idol Speakers with Various Speaking Styles](https://arxiv.org/abs/2506.18296)
*Yuto Kondo,Hirokazu Kameoka,Kou Tanaka,Takuhiro Kaneko*

Main category: cs.SD

TL;DR: 构建日本偶像语音语料库（JIS），用于推动语音生成AI研究，包括TTS和VC，并支持更严格的说话人相似性评估。


<details>
  <summary>Details</summary>
Motivation: 为研究语音生成AI（如TTS和VC）提供特定类别的语音数据（年轻女性偶像），以支持更精确的说话人相似性评估和个性化语音生成研究。

Method: 构建JIS语料库，包含特定类别的说话人（日本年轻女性偶像），并提供相关文化背景和基本分析。

Result: JIS语料库将免费分发，支持非商业基础研究，并促进个性化语音生成等新研究方向。

Conclusion: JIS为语音生成AI研究提供了独特资源，有望推动说话人相似性评估和个性化语音生成的发展。

Abstract: We construct Japanese Idol Speech Corpus (JIS) to advance research in speech
generation AI, including text-to-speech synthesis (TTS) and voice conversion
(VC). JIS will facilitate more rigorous evaluations of speaker similarity in
TTS and VC systems since all speakers in JIS belong to a highly specific
category: "young female live idols" in Japan, and each speaker is identified by
a stage name, enabling researchers to recruit listeners familiar with these
idols for listening experiments. With its unique speaker attributes, JIS will
foster compelling research, including generating voices tailored to listener
preferences-an area not yet widely studied. JIS will be distributed free of
charge to promote research in speech generation AI, with usage restricted to
non-commercial, basic research. We describe the construction of JIS, provide an
overview of Japanese live idol culture to support effective and ethical use of
JIS, and offer a basic analysis to guide application of JIS.

</details>


### [32] [Rethinking Mean Opinion Scores in Speech Quality Assessment: Aggregation through Quantized Distribution Fitting](https://arxiv.org/abs/2506.18307)
*Yuto Kondo,Hirokazu Kameoka,Kou Tanaka,Takuhiro Kaneko*

Main category: cs.SD

TL;DR: 提出了一种新的分数聚合方法，通过建模评分者内部连续评分的假设，提升语音质量评估（SQA）模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统MOS评分（1-5分）存在局限性，假设评分者内部使用连续评分后选择最接近的离散评分。

Method: 通过量化潜在连续分布来建模评分生成过程，并用其峰值替代MOS作为新的代表值。

Result: 实验表明，用该方法替代MOSNet的预测目标能提升性能。

Conclusion: 提出的方法有效提升了MOS预测模型的准确性。

Abstract: Speech quality assessment (SQA) aims to evaluate the quality of speech
samples without relying on time-consuming listener questionnaires. Recent
efforts have focused on training neural-based SQA models to predict the mean
opinion score (MOS) of speech samples produced by text-to-speech or voice
conversion systems. This paper targets the enhancement of MOS prediction
models' performance. We propose a novel score aggregation method to address the
limitations of conventional annotations for MOS, which typically involve
ratings on a scale from 1 to 5. Our method is based on the hypothesis that
annotators internally consider continuous scores and then choose the nearest
discrete rating. By modeling this process, we approximate the generative
distribution of ratings by quantizing the latent continuous distribution. We
then use the peak of this latent distribution, estimated through the loss
between the quantized distribution and annotated ratings, as a new
representative value instead of MOS. Experimental results demonstrate that
substituting MOSNet's predicted target with this proposed value improves
prediction performance.

</details>


### [33] [Large-Scale Training Data Attribution for Music Generative Models via Unlearning](https://arxiv.org/abs/2506.18312)
*Woosung Choi,Junghyun Koo,Kin Wai Cheuk,Joan Serrà,Marco A. Martínez-Ramírez,Yukara Ikemiya,Naoki Murata,Yuhta Takida,Wei-Hsiang Liao,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: 论文探讨了在音乐生成模型中使用遗忘方法进行训练数据归因（TDA），以识别特定输出对应的训练数据点，支持更公平的艺术贡献认可和AI伦理问题。


<details>
  <summary>Details</summary>
Motivation: 解决AI生成音乐中原创艺术家未被充分认可的问题，推动更公平的贡献分配和AI伦理。

Method: 应用基于遗忘的归因方法于文本到音乐的扩散模型，通过网格搜索验证超参数配置，并与基于相似性的方法对比。

Result: 遗忘方法可有效应用于音乐生成模型，实现大规模TDA，为更道德的音乐创作AI系统铺路。

Conclusion: 基于遗忘的TDA方法在音乐生成领域具有可行性，有助于提升AI系统的伦理性和责任感。

Abstract: This paper explores the use of unlearning methods for training data
attribution (TDA) in music generative models trained on large-scale datasets.
TDA aims to identify which specific training data points contributed to the
generation of a particular output from a specific model. This is crucial in the
context of AI-generated music, where proper recognition and credit for original
artists are generally overlooked. By enabling white-box attribution, our work
supports a fairer system for acknowledging artistic contributions and addresses
pressing concerns related to AI ethics and copyright. We apply unlearning-based
attribution to a text-to-music diffusion model trained on a large-scale dataset
and investigate its feasibility and behavior in this setting. To validate the
method, we perform a grid search over different hyperparameter configurations
and quantitatively evaluate the consistency of the unlearning approach. We then
compare attribution patterns from unlearning with those from a similarity-based
approach. Our findings suggest that unlearning-based approaches can be
effectively adapted to music generative models, introducing large-scale TDA to
this domain and paving the way for more ethical and accountable AI systems for
music creation.

</details>


### [34] [Selecting N-lowest scores for training MOS prediction models](https://arxiv.org/abs/2506.18326)
*Yuto Kondo,Hirokazu Kameoka,Kou Tanaka,Takuhiro Kaneko*

Main category: cs.SD

TL;DR: 论文提出了一种新的语音质量评估指标N_low-MOS，假设人类评分时更关注低质量语音段，并通过实验验证其优于传统MOS。


<details>
  <summary>Details</summary>
Motivation: 传统语音质量评估（SQA）依赖主观评分（MOS），但评分可能因忽略低质量段而产生偏差。论文假设人类评分更关注低质量段，提出更可靠的N_low-MOS指标。

Method: 分析VCC2018和BVCC数据集，提出N_low-MOS（最低N个评分的均值），并将其用于MOSNet训练。

Result: 实验表明，N_low-MOS在LCC和SRCC指标上优于传统MOS，表明其更能反映主观语音质量。

Conclusion: N_low-MOS是更可靠的语音质量评估指标，能提升MOSNet对语音转换模型的比较能力。

Abstract: The automatic speech quality assessment (SQA) has been extensively studied to
predict the speech quality without time-consuming questionnaires. Recently,
neural-based SQA models have been actively developed for speech samples
produced by text-to-speech or voice conversion, with a primary focus on
training mean opinion score (MOS) prediction models. The quality of each speech
sample may not be consistent across the entire duration, and it remains unclear
which segments of the speech receive the primary focus from humans when
assigning subjective evaluation for MOS calculation. We hypothesize that when
humans rate speech, they tend to assign more weight to low-quality speech
segments, and the variance in ratings for each sample is mainly due to
accidental assignment of higher scores when overlooking the poor quality speech
segments. Motivated by the hypothesis, we analyze the VCC2018 and BVCC
datasets. Based on the hypothesis, we propose the more reliable representative
value N_low-MOS, the mean of the $N$-lowest opinion scores. Our experiments
show that LCC and SRCC improve compared to regular MOS when employing N_low-MOS
to MOSNet training. This result suggests that N_low-MOS is a more intrinsic
representative value of subjective speech quality and makes MOSNet a better
comparator of VC models.

</details>


### [35] [AI-Generated Song Detection via Lyrics Transcripts](https://arxiv.org/abs/2506.18488)
*Markus Frohmann,Elena V. Epure,Gabriel Meseguer-Brocal,Markus Schedl,Romain Hennequin*

Main category: cs.SD

TL;DR: 论文提出了一种通过自动语音识别（ASR）模型转录歌词来检测AI生成音乐的方法，解决了现有音频检测器在泛化和抗干扰方面的不足。


<details>
  <summary>Details</summary>
Motivation: AI生成音乐工具的快速发展需要准确的检测方法，但现有音频检测器在泛化和抗干扰方面表现不佳，且依赖完美歌词的局限性限制了实际应用。

Method: 使用通用ASR模型转录歌曲歌词，并结合多种检测器（如Whisper large-v2和LLM2Vec嵌入）进行检测。

Result: 在多语言、多风格的歌词数据集上表现出色，尤其在抗干扰和泛化能力上优于现有音频检测方法。

Conclusion: 该方法填补了实际应用中的空白，为AI生成音乐的检测提供了更鲁棒的解决方案。

Abstract: The recent rise in capabilities of AI-based music generation tools has
created an upheaval in the music industry, necessitating the creation of
accurate methods to detect such AI-generated content. This can be done using
audio-based detectors; however, it has been shown that they struggle to
generalize to unseen generators or when the audio is perturbed. Furthermore,
recent work used accurate and cleanly formatted lyrics sourced from a lyrics
provider database to detect AI-generated music. However, in practice, such
perfect lyrics are not available (only the audio is); this leaves a substantial
gap in applicability in real-life use cases. In this work, we instead propose
solving this gap by transcribing songs using general automatic speech
recognition (ASR) models. We do this using several detectors. The results on
diverse, multi-genre, and multi-lingual lyrics show generally strong detection
performance across languages and genres, particularly for our best-performing
model using Whisper large-v2 and LLM2Vec embeddings. In addition, we show that
our method is more robust than state-of-the-art audio-based ones when the audio
is perturbed in different ways and when evaluated on different music
generators. Our code is available at
https://github.com/deezer/robust-AI-lyrics-detection.

</details>


### [36] [Smooth Operators: LLMs Translating Imperfect Hints into Disfluency-Rich Transcripts](https://arxiv.org/abs/2506.18510)
*Duygu Altinok*

Main category: cs.SD

TL;DR: 提出了一种利用大型语言模型（LLMs）处理不流畅语音的新方法，通过结合声学特征和不同质量的文本输入，生成带时间戳的完整不流畅标注转录。


<details>
  <summary>Details</summary>
Motivation: 提升自动语音和语言处理系统的性能，推动更具包容性的语音技术的发展。

Method: 整合声学特征与不同质量的文本输入（如干净转录、时间对齐转录或ASR输出），利用LLMs生成带时间戳的不流畅标注转录。

Result: 实验表明，即使文本输入不完美，只要包含时间戳线索，LLMs仍能有效生成完整的不流畅标注转录。

Conclusion: LLMs在处理不完美提示时表现出鲁棒性，为不流畅语音标注提供了高效解决方案。

Abstract: Accurate detection of disfluencies in spoken language is crucial for
enhancing the performance of automatic speech and language processing systems,
as well as fostering the development of more inclusive speech and language
technologies. Leveraging the growing trend of large language models (LLMs) as
versatile learners capable of processing both lexical and non-lexical inputs
(e.g., audio and video), we propose a novel approach to transcribing
disfluencies as explicit tokens with timestamps, enabling the generation of
fully annotated disfluency-rich transcripts. Our method integrates acoustic
representations extracted from an audio encoder with textual inputs of varying
quality: clean transcriptions without disfluencies, time-aligned transcriptions
from aligners, or outputs from phoneme-based ASR models -- all of which may
contain imperfections. Importantly, our experiments demonstrate that textual
inputs do not need to be flawless. As long as they include timestamp-related
cues, LLMs can effectively smooth the input and produce fully
disfluency-annotated transcripts, underscoring their robustness in handling
imperfect hints.

</details>


### [37] [TCDiff++: An End-to-end Trajectory-Controllable Diffusion Model for Harmonious Music-Driven Group Choreography](https://arxiv.org/abs/2506.18671)
*Yuqin Dai,Wanlu Zhu,Ronghui Li,Xiu Li,Zhenyu Zhang,Jun Li,Jian Yang*

Main category: cs.SD

TL;DR: TCDiff++是一个音乐驱动的端到端框架，用于生成和谐的群舞，解决了多舞者碰撞、单舞者脚滑和长群舞生成中的突然交换问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在群舞生成中存在多舞者碰撞、单舞者脚滑和长群舞生成中的突然交换问题，需要一种更高效的解决方案。

Method: 使用舞者定位嵌入和距离一致性损失解决碰撞问题；引入交换模式嵌入和Footwork Adaptor减少脚滑；采用长群扩散采样策略和序列解码器层优化长序列生成。

Result: TCDiff++在长时场景中表现优异，实现了高质量且连贯的群舞生成。

Conclusion: TCDiff++通过多种创新方法有效解决了群舞生成中的关键问题，显著提升了生成质量。

Abstract: Music-driven dance generation has garnered significant attention due to its
wide range of industrial applications, particularly in the creation of group
choreography. During the group dance generation process, however, most existing
methods still face three primary issues: multi-dancer collisions, single-dancer
foot sliding and abrupt swapping in the generation of long group dance. In this
paper, we propose TCDiff++, a music-driven end-to-end framework designed to
generate harmonious group dance. Specifically, to mitigate multi-dancer
collisions, we utilize a dancer positioning embedding to better maintain the
relative positioning among dancers. Additionally, we incorporate a
distance-consistency loss to ensure that inter-dancer distances remain within
plausible ranges. To address the issue of single-dancer foot sliding, we
introduce a swap mode embedding to indicate dancer swapping patterns and design
a Footwork Adaptor to refine raw motion, thereby minimizing foot sliding. For
long group dance generation, we present a long group diffusion sampling
strategy that reduces abrupt position shifts by injecting positional
information into the noisy input. Furthermore, we integrate a Sequence Decoder
layer to enhance the model's ability to selectively process long sequences.
Extensive experiments demonstrate that our TCDiff++ achieves state-of-the-art
performance, particularly in long-duration scenarios, ensuring high-quality and
coherent group dance generation.

</details>


### [38] [Evaluating Multichannel Speech Enhancement Algorithms at the Phoneme Scale Across Genders](https://arxiv.org/abs/2506.18691)
*Nasser-Eddine Monir,Paul Magron,Romain Serizel*

Main category: cs.SD

TL;DR: 研究了性别和语音内容对多通道语音增强算法的影响，发现算法在女性语音上表现更好，尤其在特定音素类别中。


<details>
  <summary>Details</summary>
Motivation: 现有算法通常在语句级别评估，忽略了不同音素类别和性别间的声学特性差异。

Method: 通过分析音素和性别特定的频谱特征，实验评估了算法的性能。

Result: 算法在女性语音上干扰更少、伪影更少，尤其在爆破音、摩擦音和元音中表现更优。

Conclusion: 性别和音素类别对语音增强算法性能有显著影响，需在评估中加以考虑。

Abstract: Multichannel speech enhancement algorithms are essential for improving the
intelligibility of speech signals in noisy environments. These algorithms are
usually evaluated at the utterance level, but this approach overlooks the
disparities in acoustic characteristics that are observed in different phoneme
categories and between male and female speakers. In this paper, we investigate
the impact of gender and phonetic content on speech enhancement algorithms. We
motivate this approach by outlining phoneme- and gender-specific spectral
features. Our experiments reveal that while utterance-level differences between
genders are minimal, significant variations emerge at the phoneme level.
Results show that the tested algorithms better reduce interference with fewer
artifacts on female speech, particularly in plosives, fricatives, and vowels.
Additionally, they demonstrate greater performance for female speech in terms
of perceptual and speech recognition metrics.

</details>


### [39] [Frequency-Weighted Training Losses for Phoneme-Level DNN-based Speech Enhancement](https://arxiv.org/abs/2506.18714)
*Nasser-Eddine Monir,Paul Magron,Romain Serizel*

Main category: cs.SD

TL;DR: 论文提出了一种基于感知的SDR损失函数变体，用于多通道语音增强，通过频率相关加权策略改善语音清晰度。


<details>
  <summary>Details</summary>
Motivation: 传统训练损失函数（如SDR）可能无法保留对音素清晰度至关重要的频谱细节，因此需要改进。

Method: 设计了时间-频率域中的感知SDR损失变体，采用固定和自适应频率加权策略，并在FaSNet模型上训练。

Result: 实验显示，标准指标（如SDR）改进有限，但感知加权指标显著提升，且频谱和音素分析表明辅音重建更好。

Conclusion: 感知加权SDR损失能更好地保留关键声学线索，提升语音增强效果。

Abstract: Recent advances in deep learning have significantly improved multichannel
speech enhancement algorithms, yet conventional training loss functions such as
the scale-invariant signal-to-distortion ratio (SDR) may fail to preserve
fine-grained spectral cues essential for phoneme intelligibility. In this work,
we propose perceptually-informed variants of the SDR loss, formulated in the
time-frequency domain and modulated by frequency-dependent weighting schemes.
These weights are designed to emphasize time-frequency regions where speech is
prominent or where the interfering noise is particularly strong. We investigate
both fixed and adaptive strategies, including ANSI band-importance weights,
spectral magnitude-based weighting, and dynamic weighting based on the relative
amount of speech and noise. We train the FaSNet multichannel speech enhancement
model using these various losses. Experimental results show that while standard
metrics such as the SDR are only marginally improved, their perceptual
frequency-weighted counterparts exhibit a more substantial improvement.
Besides, spectral and phoneme-level analysis indicates better consonant
reconstruction, which points to a better preservation of certain acoustic cues.

</details>


### [40] [MuseControlLite: Multifunctional Music Generation with Lightweight Conditioners](https://arxiv.org/abs/2506.18729)
*Fang-Duo Tsai,Shih-Lun Wu,Weijaw Lee,Sheng-Ping Yang,Bo-Rui Chen,Hao-Chung Cheng,Yi-Hsuan Yang*

Main category: cs.SD

TL;DR: MuseControlLite是一种轻量级机制，通过时间变化的音乐属性和参考音频信号，优化文本到音乐生成模型的精确控制。


<details>
  <summary>Details</summary>
Motivation: 现有文本到音乐生成模型在时间相关条件控制上表现不佳，需要更高效的微调方法。

Method: 在解耦的交叉注意力层中添加旋转位置嵌入，减少可训练参数。

Result: 控制精度从56.6%提升至61.1%，参数减少6.75倍，优于MusicGen-Large和Stable Audio Open ControlNet。

Conclusion: MuseControlLite以更低成本实现了更高的控制精度，适用于多种音乐属性控制和音频修复任务。

Abstract: We propose MuseControlLite, a lightweight mechanism designed to fine-tune
text-to-music generation models for precise conditioning using various
time-varying musical attributes and reference audio signals. The key finding is
that positional embeddings, which have been seldom used by text-to-music
generation models in the conditioner for text conditions, are critical when the
condition of interest is a function of time. Using melody control as an
example, our experiments show that simply adding rotary positional embeddings
to the decoupled cross-attention layers increases control accuracy from 56.6%
to 61.1%, while requiring 6.75 times fewer trainable parameters than
state-of-the-art fine-tuning mechanisms, using the same pre-trained diffusion
Transformer model of Stable Audio Open. We evaluate various forms of musical
attribute control, audio inpainting, and audio outpainting, demonstrating
improved controllability over MusicGen-Large and Stable Audio Open ControlNet
at a significantly lower fine-tuning cost, with only 85M trainble parameters.
Source code, model checkpoints, and demo examples are available at: https:
//MuseControlLite.github.io/web/.

</details>


### [41] [USAD: Universal Speech and Audio Representation via Distillation](https://arxiv.org/abs/2506.18843)
*Heng-Jui Chang,Saurabhchand Bhati,James Glass,Alexander H. Liu*

Main category: cs.SD

TL;DR: USAD提出了一种统一的音频表示学习方法，通过从特定领域的自监督学习模型中蒸馏知识，训练一个适用于多种音频类型的单一模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有自监督学习模型在音频领域中的局限性，即模型通常专注于单一任务（如语音或非语音），缺乏通用性。

Method: 采用层到层的蒸馏技术，从特定领域的自监督学习模型中提取知识，训练一个学生模型，使其能够处理多种音频类型（语音、声音、音乐）。

Result: 在多个基准测试和数据集上表现优异，包括帧级和实例级语音处理任务、音频标记和声音分类，在SUPERB和HEAR基准测试中接近最先进水平。

Conclusion: USAD展示了统一音频表示学习的潜力，能够通过单一模型处理多种音频任务，且性能接近专用模型。

Abstract: Self-supervised learning (SSL) has revolutionized audio representations, yet
models often remain domain-specific, focusing on either speech or non-speech
tasks. In this work, we present Universal Speech and Audio Distillation (USAD),
a unified approach to audio representation learning that integrates diverse
audio types - speech, sound, and music - into a single model. USAD employs
efficient layer-to-layer distillation from domain-specific SSL models to train
a student on a comprehensive audio dataset. USAD offers competitive performance
across various benchmarks and datasets, including frame and instance-level
speech processing tasks, audio tagging, and sound classification, achieving
near state-of-the-art results with a single encoder on SUPERB and HEAR
benchmarks.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.SD](#cs.SD) [Total: 8]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [SIM-Enabled Hybrid Digital-Wave Beamforming for Fronthaul-Constrained Cell-Free Massive MIMO Systems](https://arxiv.org/abs/2506.19090)
*Eunhyuk Park,Seok-Hwan Park,Osvaldo Simeone,Marco Di Renzo,Shlomo Shamai*

Main category: eess.SP

TL;DR: 提出了一种结合波域波束成形和数字处理的混合波束成形框架，以解决CF-mMIMO系统中AP密集部署的高成本和前传需求问题。


<details>
  <summary>Details</summary>
Motivation: 解决CF-mMIMO系统中AP密集部署带来的高实现成本和前传需求挑战。

Method: 结合堆叠智能超表面（SIM）的波域波束成形与传统数字处理，提出联合优化问题，并开发交替优化算法。

Result: 数值结果表明，所提方案优于传统混合方案，并在多数情况下以较少RF链实现接近全数字性能。

Conclusion: 所提混合波束成形框架在成本和性能上具有显著优势，适用于CF-mMIMO系统。

Abstract: As the dense deployment of access points (APs) in cell-free massive
multiple-input multiple-output (CF-mMIMO) systems presents significant
challenges, per-AP coverage can be expanded using large-scale antenna arrays
(LAAs). However, this approach incurs high implementation costs and substantial
fronthaul demands due to the need for dedicated RF chains for all antennas. To
address these challenges, we propose a hybrid beamforming framework that
integrates wave-domain beamforming via stacked intelligent metasurfaces (SIM)
with conventional digital processing. By dynamically manipulating
electromagnetic waves, SIM-equipped APs enhance beamforming gains while
significantly reducing RF chain requirements. We formulate a joint optimization
problem for digital and wave-domain beamforming along with fronthaul
compression to maximize the weighted sum-rate for both uplink and downlink
transmission under finite-capacity fronthaul constraints. Given the high
dimensionality and non-convexity of the problem, we develop alternating
optimization-based algorithms that iteratively optimize digital and wave-domain
variables. Numerical results demonstrate that the proposed hybrid schemes
outperform conventional hybrid schemes, that rely on randomly set wave-domain
beamformers or restrict digital beamforming to simple power control. Moreover,
the proposed scheme employing sufficiently deep SIMs achieves near
fully-digital performance with fewer RF chains in most simulated cases, except
in the downlink at low signal-to-noise ratios.

</details>


### [2] [EEG Foundation Challenge: From Cross-Task to Cross-Subject EEG Decoding](https://arxiv.org/abs/2506.19141)
*Bruno Aristimunha,Dung Truong,Pierre Guetschel,Seyed Yahya Shirazi,Isabelle Guyon,Alexandre R. Franco,Michael P. Milham,Aviv Dotan,Scott Makeig,Alexandre Gramfort,Jean-Remi King,Marie-Constance Corsi,Pedro A. Valdés-Sosa,Amit Majumdar,Alan Evans,Terrence J Sejnowski,Oren Shriki,Sylvain Chevallier,Arnaud Delorme*

Main category: eess.SP

TL;DR: 论文介绍了一个基于大规模EEG数据集的竞赛，包含两个挑战：跨任务和跨被试的零样本解码，以及从EEG数据预测心理健康指标。


<details>
  <summary>Details</summary>
Motivation: 当前EEG解码模型通常基于少量被试和单一任务训练，缺乏泛化能力。本研究旨在推动跨任务和跨被试的通用模型开发，并为心理健康研究提供客观生物标志物。

Method: 使用包含3000多名被试的多任务高密度EEG数据集，设计了两个挑战任务，并提供了可调神经网络基线模型。

Result: 提出了跨任务和跨被试的零样本解码方法，以及心理健康指标的预测模型。

Conclusion: 该竞赛有望推动计算精神病学和神经技术的发展，促进基础神经科学和临床研究的突破。

Abstract: Current electroencephalogram (EEG) decoding models are typically trained on
small numbers of subjects performing a single task. Here, we introduce a
large-scale, code-submission-based competition comprising two challenges.
First, the Transfer Challenge asks participants to build and test a model that
can zero-shot decode new tasks and new subjects from their EEG data. Second,
the Psychopathology factor prediction Challenge asks participants to infer
subject measures of mental health from EEG data. For this, we use an
unprecedented, multi-terabyte dataset of high-density EEG signals (128
channels) recorded from over 3,000 child to young adult subjects engaged in
multiple active and passive tasks. We provide several tunable neural network
baselines for each of these two challenges, including a simple network and
demographic-based regression models. Developing models that generalise across
tasks and individuals will pave the way for ML network architectures capable of
adapting to EEG data collected from diverse tasks and individuals. Similarly,
predicting mental health-relevant personality trait values from EEG might
identify objective biomarkers useful for clinical diagnosis and design of
personalised treatment for psychological conditions. Ultimately, the advances
spurred by this challenge could contribute to the development of computational
psychiatry and useful neurotechnology, and contribute to breakthroughs in both
fundamental neuroscience and applied clinical research.

</details>


### [3] [From High-SNR Radar Signal to ECG: A Transfer Learning Model with Cardio-Focusing Algorithm for Scenarios with Limited Data](https://arxiv.org/abs/2506.19358)
*Yuanyuan Zhang,Haocheng Zhao,Sijie Xiong,Rui Yang,Eng Gee Lim,Yutao Yue*

Main category: eess.SP

TL;DR: 提出了一种基于雷达信号的心电图（ECG）恢复方法，适用于数据稀缺的新场景。通过心脏定位跟踪算法（CFT）和迁移学习模型（RFcardi），仅需少量雷达-ECG配对数据即可实现高效ECG恢复。


<details>
  <summary>Details</summary>
Motivation: 现有雷达信号恢复ECG的方法依赖高质量信号和大量训练数据，限制了在新场景中的应用。本研究旨在解决数据稀缺问题。

Method: 提出CFT算法精确定位心脏位置以获取高质量雷达信号，并设计RFcardi模型利用心脏特征稀疏性提取信息，仅需少量配对数据微调模型。

Result: 实验表明CFT能动态定位心脏，RFcardi模型在小规模训练数据下仍能生成准确的ECG恢复结果。

Conclusion: 该方法在数据稀缺场景下实现了高效ECG恢复，具有实际应用潜力。

Abstract: Electrocardiogram (ECG), as a crucial find-grained cardiac feature, has been
successfully recovered from radar signals in the literature, but the
performance heavily relies on the high-quality radar signal and numerous
radar-ECG pairs for training, restricting the applications in new scenarios due
to data scarcity. Therefore, this work will focus on radar-based ECG recovery
in new scenarios with limited data and propose a cardio-focusing and -tracking
(CFT) algorithm to precisely track the cardiac location to ensure an efficient
acquisition of high-quality radar signals. Furthermore, a transfer learning
model (RFcardi) is proposed to extract cardio-related information from the
radar signal without ECG ground truth based on the intrinsic sparsity of
cardiac features, and only a few synchronous radar-ECG pairs are required to
fine-tune the pre-trained model for the ECG recovery. The experimental results
reveal that the proposed CFT can dynamically identify the cardiac location, and
the RFcardi model can effectively generate faithful ECG recoveries after using
a small number of radar-ECG pairs for training. The code and dataset are
available after the publication.

</details>


### [4] [Holographic Communication via Recordable and Reconfigurable Metasurface](https://arxiv.org/abs/2506.19376)
*Jinzhe Wang,Qinghua Guo,Xiaojun Yuan*

Main category: eess.SP

TL;DR: 提出了一种基于可记录和可重构超表面（RRM）的新型全息通信方案，无需信道估计即可实现与现有RHS方案相当的性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于可重构全息表面（RHS）的方案需要信道状态信息（CSI），而信道估计在超表面通信中具有挑战性。

Method: 结合全息记录的记录和重构过程，引入RRM，无需信道估计。

Result: 提出的RRM方案在无需信道估计的情况下，性能与具有完美CSI的RHS方案相当。

Conclusion: RRM方案为未来无线通信网络提供了一种有前景的替代方案。

Abstract: Holographic surface based communication technologies are anticipated to play
a significant role in the next generation of wireless networks. The existing
reconfigurable holographic surface (RHS)-based scheme only utilizes the
reconstruction process of the holographic principle for beamforming, where the
channel sate information (CSI) is needed. However, channel estimation for CSI
acquirement is a challenging task in metasurface based communications. In this
study, inspired by both the recording and reconstruction processes of
holography, we develop a novel holographic communication scheme by introducing
recordable and reconfigurable metasurfaces (RRMs), where channel estimation is
not needed thanks to the recording process. Then we analyze the input-output
mutual information of the RRM-based communication system and compare it with
the existing RHS based system. Our results show that, without channel
estimation, the proposed scheme achieves performance comparable to that of the
RHS scheme with perfect CSI, suggesting a promising alternative for future
wireless communication networks.

</details>


### [5] [Low-Complexity Semantic Packet Aggregation for Token Communication via Lookahead Search](https://arxiv.org/abs/2506.19451)
*Seunghun Lee,Jihong Park,Jinho Choi,Hyuncheol Park*

Main category: eess.SP

TL;DR: 论文提出了一种名为SemPA-Look的框架，通过优化令牌分组以最大化令牌相似性（ATS），解决了在中断信道下令牌通信的语义失真问题。


<details>
  <summary>Details</summary>
Motivation: 令牌通信（TC）在远程AI生成内容（AIGC）和无线LLM应用中至关重要，但令牌间的依赖性使其在中断信道下容易失真。

Method: 提出SemPA-Look框架，结合残差语义分数（RSS）和前瞻搜索算法，以线性复杂度优化令牌分组。

Result: 实验表明，SemPA-Look在ATS和LPIPS得分上与穷举搜索相当，同时计算复杂度降低40倍。

Conclusion: SemPA-Look在保持语义完整性的同时显著降低了计算复杂度，适用于远程AIGC和其他TC应用。

Abstract: Tokens are fundamental processing units of generative AI (GenAI) and large
language models (LLMs), and token communication (TC) is essential for enabling
remote AI-generate content (AIGC) and wireless LLM applications. Unlike
traditional bits, each of which is independently treated, the semantics of each
token depends on its surrounding context tokens. This inter-token dependency
makes TC vulnerable to outage channels, where the loss of a single token can
significantly distort the original message semantics. Motivated by this, this
paper focuses on optimizing token packetization to maximize the average token
similarity (ATS) between the original and received token messages under outage
channels. Due to inter-token dependency, this token grouping problem is
combinatorial, with complexity growing exponentially with message length. To
address this, we propose a novel framework of semantic packet aggregation with
lookahead search (SemPA-Look), built on two core ideas. First, it introduces
the residual semantic score (RSS) as a token-level surrogate for the
message-level ATS, allowing robust semantic preservation even when a certain
token packet is lost. Second, instead of full search, SemPA-Look applies a
lookahead search-inspired algorithm that samples intra-packet token candidates
without replacement (fixed depth), conditioned on inter-packet token candidates
sampled with replacement (fixed width), thereby achieving linear complexity.
Experiments on a remote AIGC task with the MS-COCO dataset (text captioned
images) demonstrate that SemPA-Look achieves high ATS and LPIPS scores
comparable to exhaustive search, while reducing computational complexity by up
to 40$\times$. Compared to other linear-complexity algorithms such as the
genetic algorithm (GA), SemPA-Look achieves 10$\times$ lower complexity,
demonstrating its practicality for remote AIGC and other TC applications.

</details>


### [6] [Coherent and Noncoherent Detection in Dense Arrays: Can We Ignore Mutual Coupling?](https://arxiv.org/abs/2506.19470)
*Aniol Martí,Luca Sanguinetti,Jaume Riba,Meritxell Lamarca*

Main category: eess.SP

TL;DR: 研究了密集部署天线MIMO系统中互耦合的影响，比较了相干和非相干检测方法的性能。


<details>
  <summary>Details</summary>
Motivation: 探讨互耦合对MIMO系统性能的影响，特别是在天线密集部署时。

Method: 基于多端口通信理论，分析了单用户上行链路场景中的相干和非相干检测方法。

Result: 相干检测更准确但对耦合模型失配敏感，性能下降严重；非相干检测误差较高但更鲁棒。

Conclusion: 在密集天线部署中，非相干检测因鲁棒性更优，而相干检测可能因模型失配失效。

Abstract: This paper investigates the impact of mutual coupling on MIMO systems with
densely deployed antennas. Leveraging multiport communication theory, we
analyze both coherent and noncoherent detection approaches in a single-user
uplink scenario where the receiver ignores mutual coupling effects. Simulation
results indicate that while coherent detection is generally more accurate, it
is highly sensitive to mismatches in the coupling model, leading to severe
performance degradation when antennas are closely spaced, to the point of
becoming unusable. Noncoherent detection, on the other hand, exhibits a higher
error probability but is more robust to coupling model mismatches.

</details>


### [7] [Neural Collapse based Deep Supervised Federated Learning for Signal Detection in OFDM Systems](https://arxiv.org/abs/2506.19476)
*Kaidi Xu,Shenglong Zhou,Geoffrey Ye Li*

Main category: eess.SP

TL;DR: 提出了一种基于神经崩溃（NC）的深度监督联邦学习算法（NCDSFL），以解决无线网络中数据异构性问题。


<details>
  <summary>Details</summary>
Motivation: 未来无线网络依赖AI，但物理层实体观测到的无线环境数据有限且异构，联邦学习虽能解决观测限制，但面临数据异构性挑战。

Method: 提出NCDSFL算法，结合神经崩溃理论，优化深度监督联邦学习。

Result: 未明确提及具体结果，但算法旨在提升数据异构性下的学习效果。

Conclusion: NCDSFL算法有望解决无线网络中联邦学习的数据异构性问题。

Abstract: Future wireless networks are expected to be AI-empowered, making their
performance highly dependent on the quality of training datasets. However,
physical-layer entities often observe only partial wireless environments
characterized by different power delay profiles. Federated learning is capable
of addressing this limited observability, but often struggles with data
heterogeneity. To tackle this challenge, we propose a neural collapse (NC)
inspired deep supervised federated learning (NCDSFL) algorithm.

</details>


### [8] [Experimental Assessment of A Framework for In-body RF-backscattering Localization](https://arxiv.org/abs/2506.19499)
*Noa Jie Vives Zaguirre,Oscar Lasierra,Filip Lemic,Gerard Calvo Bartra,Pablo José Galván Calderón,Gines Garcia-Aviles,Sergi Abadal,Xavier Costa-Pérez*

Main category: eess.SP

TL;DR: 本文提出了一种基于射频反向散射的体内定位实验框架，评估了其在真实条件下的性能，并探讨了优化设备配置和干扰缓解的重要性。


<details>
  <summary>Details</summary>
Motivation: 传统胃肠道诊断方法（如成像和内窥镜）具有侵入性和分辨率限制，需要创新替代方案。

Method: 采用射频反向散射技术，实验包括体内反向散射设备和体外天线配置，研究在不同组织中的谐波生成和接收。

Result: 结果显示设备定位、天线选择和增益设置对性能有显著影响，生物组织密度增加导致衰减加剧。

Conclusion: 研究强调了干扰缓解和改进传播模型的重要性，以提升体内定位性能。

Abstract: Localization of in-body devices is beneficial for Gastrointestinal (GI)
diagnosis and targeted treatment. Traditional methods such as imaging and
endoscopy are invasive and limited in resolution, highlighting the need for
innovative alternatives. This study presents an experimental framework for
Radio Frequency (RF)-backscatter-based in-body localization, inspired by the
ReMix approach, and evaluates its performance in real-world conditions. The
experimental setup includes an in-body backscatter device and various off-body
antenna configurations to investigate harmonic generation and reception in air,
chicken and pork tissues. The results indicate that optimal backscatter device
positioning, antenna selection, and gain settings significantly impact
performance, with denser biological tissues leading to greater attenuation. The
study also highlights challenges such as external interference and plastic
enclosures affecting propagation. The findings emphasize the importance of
interference mitigation and refined propagation models to enhance performance.

</details>


### [9] [Reconfigurable Intelligent Surfaces for 6G and Beyond: A Comprehensive Survey from Theory to Deployment](https://arxiv.org/abs/2506.19526)
*Prasetyo Putranto,Anis Amazigh Hamza,Sameh Mabrouki,Nasrullah Armi,Iyad Dayoub*

Main category: eess.SP

TL;DR: 本文综述了可重构智能表面（RIS）技术，涵盖理论基础、设计、实际部署及标准化进展，旨在为6G网络提供全面视角。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络研究的推进，RIS技术因其对传播环境的控制能力而备受关注，但现有研究多聚焦孤立方面，缺乏综合视角。

Method: 通过整合文献，综述RIS的用例、控制机制、信道探测方法及估计策略，并探讨标准化与工业视角。

Result: 提供了RIS技术的最新进展和实际挑战的综合分析，支持其从研究向实际应用的过渡。

Conclusion: 本文为RIS技术的学术研究和工业实践提供了全面指导，强调了标准化和实际部署的重要性。

Abstract: As the wireless research community moves toward shaping the vision of
sixth-generation (6G) networks, reconfigurable intelligent surfaces (RIS) have
emerged as a promising technology for controlling the propagation environment.
Although RIS has not yet been standardized, its versatile applications and
enabling capabilities have attracted growing attention in both academia and
industry. This survey presents a comprehensive review of RIS technology
spanning theoretical foundations, design aspects, and practical deployment
considerations. In contrast to existing surveys that focus on isolated aspects,
this work offers an integrated view covering use cases, control mechanisms,
channel sounding methodologies, and channel estimation strategies. Each of
these topics is reviewed through the lens of recent literature, synthesizing
the latest advancements to provide updated insights for both academic
researchers and industry practitioners. It further addresses emerging topics
such as standardization activities and industrial perspectives, which are often
overlooked in prior literature. By bridging theoretical insights with practical
challenges, this survey aims to provide a holistic understanding of RIS and
support its evolution from a research concept toward real-world implementation.

</details>


### [10] [A Wireless Self-Calibrating Ultrasound Microphone Array with Sub-Microsecond Synchronization](https://arxiv.org/abs/2506.19612)
*Dennis Laurijssen,Rens Baeyens,Walter Daems,Jan Steckel*

Main category: eess.SP

TL;DR: 提出了一种分布式无线自校准超声麦克风网络系统架构，用于同步空中声学传感。


<details>
  <summary>Details</summary>
Motivation: 为生物声学研究和工业声学监测中的声源定位应用提供可扩展、可部署的超声阵列基础。

Method: 节点通过HTC Vive Lighthouse的红外光学跟踪系统定位，自校准后通过Sub-1GHz RF链路同步信号，Wi-Fi 6传输数据。

Result: 原型系统验证了无线数据采集和同步能力。

Conclusion: 该架构为可扩展的超声阵列应用奠定了基础。

Abstract: We present a novel system architecture for a distributed wireless,
self-calibrating ultrasound microphone network for synchronized in-air acoustic
sensing. Once deployed the embedded nodes determine their position in the
environment using the infrared optical tracking system found in the HTC Vive
Lighthouses. After self-calibration, the nodes start sampling the ultrasound
microphone while embedding a synchronization signal in the data which is
established using a wireless Sub-1GHz RF link. Data transmission is handled via
the Wi-Fi 6 radio that is embedded in the nodes' SoC, decoupling
synchronization from payload transport. A prototype system with a limited
amount of network nodes was used to verify the proposed distributed microphone
array's wireless data acquisition and synchronization capabilities. This
architecture lays the groundwork for scalable, deployable ultrasound arrays for
sound source localization applications in bio-acoustic research and industrial
acoustic monitoring.

</details>


### [11] [On Error Rate Approximations for FSO Systems with Weak Turbulence and Pointing Errors](https://arxiv.org/abs/2506.19627)
*Carmen Álvarez Roa,Yunus Can Gültekin,Kaiquan Wu,Cornelis Willem Korevaar,Alex Alvarado*

Main category: eess.SP

TL;DR: 该论文提出了在弱湍流条件下，针对自由空间光传输系统中脉冲幅度调制（PAM）的平均误码率（BER）和符号错误率（SER）的简单且准确的近似表达式。


<details>
  <summary>Details</summary>
Motivation: 自由空间光传输的性能受大气衰减、湍流、几何扩展和指向误差的影响，现有模型为积分方程，难以直接计算BER和SER。

Method: 提出简单且准确的近似表达式，并通过蒙特卡洛模拟验证其准确性。

Result: 数值结果表明，提出的表达式具有极高的准确性，并进行了两种渐近分析以验证其实用性。

Conclusion: 论文提出的近似表达式为弱湍流条件下的PAM系统提供了高效且准确的性能评估工具。

Abstract: Atmospheric attenuation, atmospheric turbulence, geometric spread, and
pointing errors, degrade the performance of free-space optical transmission. In
the weak turbulence regime, the probability density function describing the
distribution of the channel fading coefficient that models these four effects
is known in the literature. This function is an integral equation, which makes
it difficult to find simple analytical expressions of important performance
metrics such as the bit error rate (BER) and symbol error rate (SER). In this
paper, we present simple and accurate approximations of the average BER and SER
for pulse-amplitude modulation (PAM) in the weak turbulence regime for an
intensity modulation and direct detection system. Our numerical results show
that the proposed expressions exhibit excellent accuracy when compared against
Monte Carlo simulations. To demonstrate the usefulness of the developed
approximations, we perform two asymptotic analyses. First, we investigate the
additional transmit power required to maintain the same SER when the spectral
efficiency increases by 1 bit/symbol. Second, we study the asymptotic behavior
of our SER approximation for dense PAM constellations and high transmit power.

</details>


### [12] [Beyond 200 Gb/s/lane: An Analytical Approach to Optimal Detection in Shaped IM-DD Optical Links with Relative Intensity Noise](https://arxiv.org/abs/2506.19684)
*Felipe Villenas,Kaiquan Wu,Yunus Can Gültekin,Jamal Riani,Alex Alvarado*

Main category: eess.SP

TL;DR: 论文提出了一种适用于IM-DD光链路的符号错误率（SER）分析表达式，考虑了RIN的信号依赖性，适用于概率和几何整形系统。


<details>
  <summary>Details</summary>
Motivation: 随着数据中心IM-DD系统速率提升至400 Gb/s/通道及以上，增加光功率会导致RIN问题，需要开发更准确的SER分析方法。

Method: 开发了一个考虑RIN信号依赖性的SER分析表达式，无需对星座几何或概率分布做假设。

Result: 提出的表达式与概率和几何整形系统的数值模拟完全匹配。

Conclusion: 该表达式为IM-DD系统性能分析提供了更准确的工具，适用于多种整形技术。

Abstract: Next-generation intensity-modulation (IM) and direct-detection (DD) systems
used in data centers are expected to operate at 400 Gb/s/lane and beyond. Such
rates can be achieved by increasing the system bandwidth or the modulation
format, which in turn requires maintaining or increasing the signal-to-noise
ratio (SNR). Such SNR requirements can be achieved by increasing the
transmitted optical power. This increase in optical power causes the emergence
of relative intensity noise (RIN), a signal-dependent impairment inherent to
the transmitter laser, which ultimately limits the performance of the system.
In this paper, we develop an analytical symbol error rate (SER) expression for
the optimal detector for the IM-DD optical link under study. The developed
expression takes into account the signal-dependent nature of RIN and does not
make any assumptions on the geometry or probability distribution of the
constellation. Our expression is therefore applicable to general
probabilistically and/or geometrically shaped systems. Unlike results available
in the literature, our proposed expression provides a perfect match to
numerical simulations of probabilistic and geometrically shaped systems.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [13] [Loss functions incorporating auditory spatial perception in deep learning -- a review](https://arxiv.org/abs/2506.19404)
*Boaz Rafaely,Stefan Weinzierl,Or Berebi,Fabian Brinkmann*

Main category: eess.AS

TL;DR: 综述论文探讨了用于双耳信号生成的损失函数，重点关注空间感知线索，尤其是定位和房间响应，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 传统信号相关差异度量无法捕捉空间音频质量的关键感知特性，因此需要研究更符合感知的损失函数。

Method: 基于Spatial Audio Quality Inventory (SAQI)框架，综述了双耳信号生成中的损失函数，强调定位线索（如ITD、ILD）和房间声学特性。

Result: 文献显示定位线索（如ITD、ILD）在损失函数设计中占据主导，而混响等房间声学特性研究较少。

Conclusion: 未来研究应开发更符合感知的损失函数，以更好地捕捉听众的空间体验。

Abstract: Binaural reproduction aims to deliver immersive spatial audio with high
perceptual realism over headphones. Loss functions play a central role in
optimizing and evaluating algorithms that generate binaural signals. However,
traditional signal-related difference measures often fail to capture the
perceptual properties that are essential to spatial audio quality. This review
paper surveys recent loss functions that incorporate spatial perception cues
relevant to binaural reproduction. It focuses on losses applied to binaural
signals, which are often derived from microphone recordings or Ambisonics
signals, while excluding those based on room impulse responses. Guided by the
Spatial Audio Quality Inventory (SAQI), the review emphasizes perceptual
dimensions related to source localization and room response, while excluding
general spectral-temporal attributes. The literature survey reveals a strong
focus on localization cues, such as interaural time and level differences
(ITDs, ILDs), while reverberation and other room acoustic attributes remain
less explored in loss function design. Recent works that estimate room acoustic
parameters and develop embeddings that capture room characteristics indicate
their potential for future integration into neural network training. The paper
concludes by highlighting future research directions toward more perceptually
grounded loss functions that better capture the listener's spatial experience.

</details>


### [14] [Kling-Foley: Multimodal Diffusion Transformer for High-Quality Video-to-Audio Generation](https://arxiv.org/abs/2506.19774)
*Jun Wang,Xijuan Zeng,Chunyu Qiang,Ruilong Chen,Shiyao Wang,Le Wang,Wangjing Zhou,Pengfei Cai,Jiahui Zhao,Nan Li,Zihan Li,Yuzhe Liang,Xiaopeng Wang,Haorui Zheng,Ming Wen,Kang Yin,Yiran Wang,Nan Li,Feng Deng,Liang Dong,Chen Zhang,Di Zhang,Kun Gai*

Main category: eess.AS

TL;DR: Kling-Foley是一种大规模多模态视频到音频生成模型，通过多模态扩散变换器和模块化设计提升音频与视频的同步性和语义对齐。


<details>
  <summary>Details</summary>
Motivation: 解决视频与音频生成中的语义对齐和同步性问题，同时扩展音频生成的多样性。

Method: 结合多模态扩散变换器、视觉语义表示模块和音频-视觉同步模块，引入通用潜在音频编解码器和立体声渲染方法。

Result: 在分布匹配、语义对齐、时间对齐和音频质量方面达到公开模型中的最优性能。

Conclusion: Kling-Foley通过多模态整合和模块化设计，显著提升了视频到音频生成的质量和同步性。

Abstract: We propose Kling-Foley, a large-scale multimodal Video-to-Audio generation
model that synthesizes high-quality audio synchronized with video content. In
Kling-Foley, we introduce multimodal diffusion transformers to model the
interactions between video, audio, and text modalities, and combine it with a
visual semantic representation module and an audio-visual synchronization
module to enhance alignment capabilities. Specifically, these modules align
video conditions with latent audio elements at the frame level, thereby
improving semantic alignment and audio-visual synchronization. Together with
text conditions, this integrated approach enables precise generation of
video-matching sound effects. In addition, we propose a universal latent audio
codec that can achieve high-quality modeling in various scenarios such as sound
effects, speech, singing, and music. We employ a stereo rendering method that
imbues synthesized audio with a spatial presence. At the same time, in order to
make up for the incomplete types and annotations of the open-source benchmark,
we also open-source an industrial-level benchmark Kling-Audio-Eval. Our
experiments show that Kling-Foley trained with the flow matching objective
achieves new audio-visual SOTA performance among public models in terms of
distribution matching, semantic alignment, temporal alignment and audio
quality.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [15] [SHAMaNS: Sound Localization with Hybrid Alpha-Stable Spatial Measure and Neural Steerer](https://arxiv.org/abs/2506.18954)
*Diego Di Carlo,Mathieu Fontaine,Aditya Arie Nugraha,Yoshiaki Bando,Kazuyoshi Yoshii*

Main category: cs.SD

TL;DR: 提出了一种结合α稳定模型和神经网络的声音源定位技术，通过物理信息神经网络（Neural Steerer）插值测量导向向量，提升多声源场景下的定位性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在多声源场景下定位不准确的问题，利用α稳定模型和神经网络提升鲁棒性。

Method: 使用物理信息神经网络（Neural Steerer）插值测量导向向量，结合α稳定模型估计声源到达方向（DOA）。

Result: 实验结果表明，该方法在多声源场景下优于现有技术。

Conclusion: 结合α稳定模型和神经网络的方法在多声源定位中表现优异，具有实际应用潜力。

Abstract: This paper describes a sound source localization (SSL) technique that
combines an $\alpha$-stable model for the observed signal with a neural
network-based approach for modeling steering vectors. Specifically, a
physics-informed neural network, referred to as Neural Steerer, is used to
interpolate measured steering vectors (SVs) on a fixed microphone array. This
allows for a more robust estimation of the so-called $\alpha$-stable spatial
measure, which represents the most plausible direction of arrival (DOA) of a
target signal. As an $\alpha$-stable model for the non-Gaussian case ($\alpha$
$\in$ (0, 2)) theoretically defines a unique spatial measure, we choose to
leverage it to account for residual reconstruction error of the Neural Steerer
in the downstream tasks. The objective scores indicate that our proposed
technique outperforms state-of-the-art methods in the case of multiple sound
sources.

</details>


### [16] [IndieFake Dataset: A Benchmark Dataset for Audio Deepfake Detection](https://arxiv.org/abs/2506.19014)
*Abhay Kumar,Kunal Verma,Omkar More*

Main category: cs.SD

TL;DR: 论文介绍了IndieFake数据集（IFD），填补了现有音频深度伪造检测数据集中缺乏南亚口音的空白，并展示了其在多样性和挑战性上的优势。


<details>
  <summary>Details</summary>
Motivation: 现有音频深度伪造数据集缺乏多样化的口音和文化背景，尤其是南亚地区，导致模型在真实场景中表现不佳。

Method: 构建了包含50名印度英语使用者的27.17小时真实和伪造音频的IFD数据集，并评估了其与现有数据集的性能对比。

Result: IFD在性能上优于ASVspoof21（DF），且比In-The-Wild（ITW）数据集更具挑战性。

Conclusion: IFD填补了数据集的多样性缺口，为音频深度伪造检测提供了更全面的基准。

Abstract: Advancements in audio deepfake technology offers benefits like AI assistants,
better accessibility for speech impairments, and enhanced entertainment.
However, it also poses significant risks to security, privacy, and trust in
digital communications. Detecting and mitigating these threats requires
comprehensive datasets. Existing datasets lack diverse ethnic accents, making
them inadequate for many real-world scenarios. Consequently, models trained on
these datasets struggle to detect audio deepfakes in diverse linguistic and
cultural contexts such as in South-Asian countries. Ironically, there is a
stark lack of South-Asian speaker samples in the existing datasets despite
constituting a quarter of the worlds population. This work introduces the
IndieFake Dataset (IFD), featuring 27.17 hours of bonafide and deepfake audio
from 50 English speaking Indian speakers. IFD offers balanced data distribution
and includes speaker-level characterization, absent in datasets like ASVspoof21
(DF). We evaluated various baselines on IFD against existing ASVspoof21 (DF)
and In-The-Wild (ITW) datasets. IFD outperforms ASVspoof21 (DF) and proves to
be more challenging compared to benchmark ITW dataset. The dataset will be
publicly available upon acceptance.

</details>


### [17] [A Fourier Explanation of AI-music Artifacts](https://arxiv.org/abs/2506.19108)
*Darius Afchar,Gabriel Meseguer-Brocal,Kamil Akesbi,Romain Hennequin*

Main category: cs.SD

TL;DR: 论文探讨了生成式AI在音乐创作中的影响，分析了合成内容的检测方法，并提出了一种简单有效的AI生成音乐检测标准。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在音乐创作中迅速普及，但引发了版权、就业和伦理问题，同时现有的AI检测系统不透明且私有化。

Method: 研究分析了生成模型中常用的反卷积模块，数学证明了其输出存在系统性频率伪影，并提出了一种简单可解释的检测标准。

Result: 实验验证了理论发现，并在开源模型和商业AI音乐生成器上测试，检测准确率超过99%。

Conclusion: 提出的方法简单高效，检测准确率与基于深度学习的方法相当，为AI生成音乐的检测提供了新思路。

Abstract: The rapid rise of generative AI has transformed music creation, with millions
of users engaging in AI-generated music. Despite its popularity, concerns
regarding copyright infringement, job displacement, and ethical implications
have led to growing scrutiny and legal challenges. In parallel, AI-detection
services have emerged, yet these systems remain largely opaque and privately
controlled, mirroring the very issues they aim to address. This paper explores
the fundamental properties of synthetic content and how it can be detected.
Specifically, we analyze deconvolution modules commonly used in generative
models and mathematically prove that their outputs exhibit systematic frequency
artifacts -- manifesting as small yet distinctive spectral peaks. This
phenomenon, related to the well-known checkerboard artifact, is shown to be
inherent to a chosen model architecture rather than a consequence of training
data or model weights. We validate our theoretical findings through extensive
experiments on open-source models, as well as commercial AI-music generators
such as Suno and Udio. We use these insights to propose a simple and
interpretable detection criterion for AI-generated music. Despite its
simplicity, our method achieves detection accuracy on par with deep
learning-based approaches, surpassing 99% accuracy on several scenarios.

</details>


### [18] [A Robust Method for Pitch Tracking in the Frequency Following Response using Harmonic Amplitude Summation Filterbank](https://arxiv.org/abs/2506.19253)
*Sajad Sadeghkhani,Maryam Karimi Boroujeni,Hilmi R. Dajani,Saeid R. Seydnejad,Christian Giguère*

Main category: cs.SD

TL;DR: 本文提出了一种基于谐波结构的F0估计算法（HAS），用于改进FFR中F0提取的准确性，相比传统ACF方法显著降低了误差。


<details>
  <summary>Details</summary>
Motivation: FFR中的F0提取对研究语音神经编码至关重要，但现有方法在动态F0变化时表现不佳。

Method: 引入刺激感知滤波器（HAS），选择性地聚合F0及其谐波的振幅，并在已知刺激F0范围内评估候选F0。

Result: HAS方法在16名听力正常受试者的FFR数据中，将RMSE降低了8.8%至47.4%。

Conclusion: HAS是首个基于谐波结构的FFR F0估计算法，显著优于传统ACF方法。

Abstract: The Frequency Following Response (FFR) reflects the brain's neural encoding
of auditory stimuli including speech. Because the fundamental frequency (F0), a
physical correlate of pitch, is one of the essential features of speech, there
has been particular interest in characterizing the FFR at F0, especially when
F0 varies over time. The standard method for extracting F0 in FFRs has been the
Autocorrelation Function (ACF). This paper investigates
harmonic-structure-based F0 estimation algorithms, originally developed for
speech and music, and resolves their poor performance when applied to FFRs in
two steps. Firstly, given that unlike in speech or music, stimulus F0 of FFRs
is already known, we introduce a stimulus-aware filterbank that selectively
aggregates amplitudes at F0 and its harmonics while suppressing noise at
non-harmonic frequencies. This method, called Harmonic Amplitude Summation
(HAS), evaluates F0 candidates only within a range centered around the stimulus
F0. Secondly, unlike other pitch tracking methods that select the highest peak,
our method chooses the most prominent one, as it better reflects the underlying
periodicity of FFRs. To the best of our knowledge, this is the first study to
propose an F0 estimation algorithm for FFRs that relies on harmonic structure.
Analyzing recorded FFRs from 16 normal hearing subjects to 4 natural speech
stimuli with a wide F0 variation from 89 Hz to 452 Hz showed that this method
outperformed ACF by reducing the average Root-Mean-Square-Error (RMSE) within
each response and stimulus F0 contour pair by 8.8% to 47.4%, depending on the
stimulus.

</details>


### [19] [Learning to assess subjective impressions from speech](https://arxiv.org/abs/2506.19335)
*Yuto Kondo,Hirokazu Kameoka,Kou Tanaka,Takuhiro Kaneko,Noboru Harada*

Main category: cs.SD

TL;DR: 本文提出了一种训练神经网络模型的方法，用于评估语音中的主观印象并打分，基于个性化主观语音描述符（SVDs），并通过实验证明比较类别评分（CCR）训练优于绝对类别评分（ACR）训练。


<details>
  <summary>Details</summary>
Motivation: 受自动语音质量评估（SQA）启发，研究如何通过神经网络模型评估语音中的主观印象（如“可爱的声音”），并解决个性化SVDs（如“我最喜欢的声音”）在有限数据下的训练问题。

Method: 设计了一个框架，支持个性化SVDs，并编译了包含ACR和CCR标签的数据集。评估指标为ppref（预测排序准确性），同时研究了基于ACR和RankNet（基于CCR）的学习方法。

Result: 实验发现，即使在训练数据有限的情况下，ppref表现中等，且CCR训练优于ACR训练。

Conclusion: 结果表明，基于个性化SVDs的评估模型可以通过CCR数据有效训练，尤其是在数据有限的情况下。

Abstract: We tackle a new task of training neural network models that can assess
subjective impressions conveyed through speech and assign scores accordingly,
inspired by the work on automatic speech quality assessment (SQA). Speech
impressions are often described using phrases like `cute voice.' We define such
phrases as subjective voice descriptors (SVDs). Focusing on the difference in
usage scenarios between the proposed task and automatic SQA, we design a
framework capable of accommodating SVDs personalized to each individual, such
as `my favorite voice.' In this work, we compiled a dataset containing speech
labels derived from both abosolute category ratings (ACR) and comparison
category ratings (CCR).
  As an evaluation metric for assessment performance, we introduce ppref, the
accuracy of the predicted score ordering of two samples on CCR test samples.
Alongside the conventional model and learning methods based on ACR data, we
also investigated RankNet learning using CCR data. We experimentally find that
the ppref is moderate even with very limited training data. We also discover
the CCR training is superior to the ACR training. These results support the
idea that assessment models based on personalized SVDs, which typically must be
trained on limited data, can be effectively learned from CCR data.

</details>


### [20] [ClearerVoice-Studio: Bridging Advanced Speech Processing Research and Practical Deployment](https://arxiv.org/abs/2506.19398)
*Shengkui Zhao,Zexu Pan,Bin Ma*

Main category: cs.SD

TL;DR: ClearerVoice-Studio是一个开源的AI语音处理工具包，专注于语音增强、分离、超分辨率等任务，提供预训练模型和优化工具，已在学术和工业界产生广泛影响。


<details>
  <summary>Details</summary>
Motivation: 旨在将前沿研究与实际应用结合，填补通用语音平台与特定任务需求之间的差距。

Method: 提供预训练模型（如FRCRN和MossFormer）、模型优化工具、多格式音频支持和用户友好界面。

Result: 快速获得3000 GitHub星和239次分叉，展示了其广泛影响。

Conclusion: ClearerVoice-Studio是一个功能强大且实用的工具包，未来将继续扩展其功能和社区影响力。

Abstract: This paper introduces ClearerVoice-Studio, an open-source, AI-powered speech
processing toolkit designed to bridge cutting-edge research and practical
application. Unlike broad platforms like SpeechBrain and ESPnet,
ClearerVoice-Studio focuses on interconnected speech tasks of speech
enhancement, separation, super-resolution, and multimodal target speaker
extraction. A key advantage is its state-of-the-art pretrained models,
including FRCRN with 3 million uses and MossFormer with 2.5 million uses,
optimized for real-world scenarios. It also offers model optimization tools,
multi-format audio support, the SpeechScore evaluation toolkit, and
user-friendly interfaces, catering to researchers, developers, and end-users.
Its rapid adoption attracting 3000 GitHub stars and 239 forks highlights its
academic and industrial impact. This paper details ClearerVoice-Studio's
capabilities, architectures, training strategies, benchmarks, community impact,
and future plan. Source code is available at
https://github.com/modelscope/ClearerVoice-Studio.

</details>


### [21] [TTSDS2: Resources and Benchmark for Evaluating Human-Quality Text to Speech Systems](https://arxiv.org/abs/2506.19441)
*Christoph Minixhofer,Ondrej Klejch,Peter Bell*

Main category: cs.SD

TL;DR: 本文介绍了TTSDS2，一种改进的TTS评估指标，在多语言和多领域中表现优于其他16种指标，并发布了相关资源。


<details>
  <summary>Details</summary>
Motivation: 由于TTS系统评估的主观指标难以比较，客观指标缺乏验证，且现有指标难以区分高质量合成语音和真实语音，因此需要更可靠的评估方法。

Method: 提出TTSDS2，一种改进的TTS评估指标，并通过多语言和多领域的数据集验证其有效性。

Result: TTSDS2在所有评估领域和主观评分中均表现出高于0.50的Spearman相关性，优于其他16种指标。

Conclusion: TTSDS2是一种更稳健的TTS评估指标，并提供了相关资源以支持未来研究。

Abstract: Evaluation of Text to Speech (TTS) systems is challenging and
resource-intensive. Subjective metrics such as Mean Opinion Score (MOS) are not
easily comparable between works. Objective metrics are frequently used, but
rarely validated against subjective ones. Both kinds of metrics are challenged
by recent TTS systems capable of producing synthetic speech indistinguishable
from real speech. In this work, we introduce Text to Speech Distribution Score
2 (TTSDS2), a more robust and improved version of TTSDS. Across a range of
domains and languages, it is the only one out of 16 compared metrics to
correlate with a Spearman correlation above 0.50 for every domain and
subjective score evaluated. We also release a range of resources for evaluating
synthetic speech close to real speech: A dataset with over 11,000 subjective
opinion score ratings; a pipeline for continually recreating a multilingual
test dataset to avoid data leakage; and a continually updated benchmark for TTS
in 14 languages.

</details>


### [22] [Vo-Ve: An Explainable Voice-Vector for Speaker Identity Evaluation](https://arxiv.org/abs/2506.19446)
*Jaejun Lee,Kyogu Lee*

Main category: cs.SD

TL;DR: Vo-Ve是一种新型的可解释性语音向量嵌入，通过显式语音属性类别概率捕捉说话人身份，与传统方法性能相当且更易解释。


<details>
  <summary>Details</summary>
Motivation: 传统说话人嵌入缺乏可解释性，Vo-Ve旨在提供一种既能评估说话人相似性又能解释语音属性的方法。

Method: 提出Vo-Ve嵌入，包含显式语音属性类别的概率，通过分析验证其性能。

Result: Vo-Ve在说话人相似性评估上与传统技术相当，同时提供语音属性的可解释性。

Conclusion: Vo-Ve因其高解释性，有望提升多种语音任务的评估方案。

Abstract: In this paper, we propose Vo-Ve, a novel voice-vector embedding that captures
speaker identity. Unlike conventional speaker embeddings, Vo-Ve is explainable,
as it contains the probabilities of explicit voice attribute classes. Through
extensive analysis, we demonstrate that Vo-Ve not only evaluates speaker
similarity competitively with conventional techniques but also provides an
interpretable explanation in terms of voice attributes. We strongly believe
that Vo-Ve can enhance evaluation schemes across various speech tasks due to
its high-level explainability.

</details>

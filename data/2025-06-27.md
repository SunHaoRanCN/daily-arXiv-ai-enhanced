<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SD](#cs.SD) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Precise Near-Field Beam Training with DFT Codebook based on Amplitude-only Measurement](https://arxiv.org/abs/2506.20783)
*Zijun Wang,Shawn Tsai,Rama Kiran,Rui Zhang*

Main category: eess.SP

TL;DR: 提出了一种低复杂度的近场波束训练方案，利用远场用户的DFT码本，通过分析近场波束模式和推导闭式表达式，实现了高效的用户距离估计和性能提升。


<details>
  <summary>Details</summary>
Motivation: 极大规模天线阵列（ELAAs）在高频段的近场通信需求推动了波束训练和信号处理设计的进步，但现有方法复杂度较高。

Method: 分析近场波束模式，推导波束宽度和中心增益的闭式表达式，定义角度依赖的修正瑞利距离，提出O(1)复杂度的距离估计方法，并通过最大似然估计（MLE）进一步优化。

Result: 仿真结果显示，单用户和多用户场景下SNR提升达2.38 dB，且可达速率接近理想信道状态信息下的性能。

Conclusion: 所提方案在低复杂度下显著提升了近场通信性能，为ELAAs的实际应用提供了高效解决方案。

Abstract: Extremely large antenna arrays (ELAAs) operating in high-frequency bands have
spurred the development of near-field communication, driving advancements in
beam training and signal processing design. In this work, we present a
low-complexity near-field beam training scheme that fully utilizes the
conventional discrete Fourier transform (DFT) codebook designed for far-field
users. We begin by analyzing the received beam pattern in the near field and
derive closed-form expressions for the beam width and central gain. These
analytical results enable the definition of an angle-dependent, modified
Rayleigh distance, which effectively distinguishes near-field and far-field
user regimes. Building on the analysis, we develop a direct and computationally
efficient method to estimate user distance, with a complexity of O(1), and
further improve its accuracy through a simple refinement. Simulation results
demonstrate significant gains in both single- and multi-user settings, with up
to 2.38 dB SNR improvement over exhaustive search. To further enhance
estimation accuracy, we additionally propose a maximum likelihood estimation
(MLE) based refinement method, leveraging the Rician distribution of signal
amplitudes and achieving accuracy close to the Cramer--Rao bound (CRB).
Simulation shows the single-user and multi-user achievable rates can both
approach those obtained with ideal channel state information.

</details>


### [2] [Physical Limits of Entanglement-Based Quantum Key Distribution over Long-Distance Satellite Links](https://arxiv.org/abs/2506.20798)
*Mohammad Taghi Dabiri,Mazen Hasna,Saif Al-Kuwari,Khalid Qaraqe*

Main category: eess.SP

TL;DR: 论文分析了基于纠缠的卫星间量子密钥分发（QKD）协议在长距离自由空间光（FSO）信道中的性能，重点研究了光子级建模和实际损伤的影响。


<details>
  <summary>Details</summary>
Motivation: 现有文献未充分解决长距离卫星间QKD链路中的光子损耗、指向误差和背景噪声等物理层挑战，这些因素会严重影响密钥生成率和量子比特误码率（QBER）。

Method: 通过光子级建模，开发了信号检测概率、背景光子影响、多对发射和QBER的解析表达式，并结合链路距离、发射器跟踪抖动、接收器对准误差等关键参数进行分析。

Result: 仿真结果表明系统性能对跟踪误差和接收器视场限制具有非线性敏感性，并确定了在保持QBER低于可接受阈值的同时最大化密钥生成率的最优参数范围。

Conclusion: 该模型为可靠高效地部署基于纠缠的卫星间QKD系统提供了实用的设计指导。

Abstract: Entanglement-based quantum key distribution (QKD) protocols, such as E91 and
BBM92, offer strong information-theoretic security and are naturally suited for
satellite-to-satellite QKD (SatQKD) links. However, implementing these
protocols over long-distance inter-satellite free-space optical (FSO) channels
poses critical physical-layer challenges that are not addressed in the existing
literature. In particular, photon losses due to beam divergence, pointing
errors, and background noise can severely degrade the key generation rate and
quantum bit error rate (QBER), especially under narrow receiver field-of-view
(FoV) constraints. This paper presents a comprehensive performance analysis of
entanglement-based inter-satellite QKD, focusing on photon-level modeling and
the impact of practical impairments. We develop analytical expressions for
signal detection probabilities, background photon influence, multi-pair
emissions, and QBER, incorporating key parameters such as link distance,
transmitter tracking jitter, receiver misalignment, and photon pair generation
rate. Simulation results reveal the nonlinear sensitivity of system performance
to tracking error and FoV limitations, and highlight optimal parameter regimes
that jointly maximize secret key rate while maintaining QBER below acceptable
thresholds. The proposed model provides actionable design insights for reliable
and efficient deployment of entanglement-based SatQKD systems.

</details>


### [3] [Compact Analytical Model for Real-Time Evaluation of OAM-Based Inter-Satellite Links](https://arxiv.org/abs/2506.20823)
*Mohammad Taghi Dabiri,Mazen Hasna*

Main category: eess.SP

TL;DR: 提出了一种高效分析框架，用于评估轨道角动量（OAM）光束在指向误差下的星间通信系统性能，通过解析模型减少计算时间并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 传统蒙特卡洛方法计算量大，无法满足动态低地球轨道（LEO）卫星星座对实时链路适配的需求。

Method: 开发了精确的解析模型，分析OAM光束对准误差引起的模态间串扰，并推导出高效的比特误码率（BER）优化表达式。

Result: 提出的方法显著减少了计算时间，同时保持高精度，非对称OAM模式集在指向误差下表现优于对称配置。

Conclusion: 该框架为高机动性光无线系统（如LEO卫星网络）提供了实时优化的可行性，并通过蒙特卡洛仿真验证了其实际适用性。

Abstract: This paper presents an efficient analytical framework for evaluating the
performance of inter-satellite communication systems utilizing orbital angular
momentum (OAM) beams under pointing errors. An accurate analytical model is
first developed to characterize intermodal crosstalk caused by beam
misalignment in OAM-based inter-satellite links. Building upon this model, we
derive efficient expressions to analyze and optimize system performance in
terms of bit error rate (BER). Unlike traditional Monte Carlo-based methods
that are computationally intensive, the proposed approach offers accurate
performance predictions. This enables a substantial decrease in computation
time while maintaining high accuracy, thanks to the use of analytical
expressions for both crosstalk and BER. This fast and accurate evaluation
capability is particularly critical for dynamic low Earth orbit (LEO) satellite
constellations, where network topology and channel conditions change rapidly,
requiring real-time link adaptation. Furthermore, we systematically design and
evaluate asymmetric OAM mode sets, which significantly outperform symmetric
configurations in the presence of pointing errors. Our results also reveal key
insights into the interaction between beam divergence, tracking accuracy, and
link distance, demonstrating that the proposed framework enables real-time
optimization of system parameters with high fidelity. The analytical findings
are rigorously validated against extensive Monte Carlo simulations, confirming
their practical applicability for high-mobility optical wireless systems such
as LEO satellite networks.

</details>


### [4] [Doppler Estimation and Compensation Techniques in LoRa Direct-to-Satellite Communications](https://arxiv.org/abs/2506.20858)
*Jamil Farhat,Gianni Pasolini,Enrico Paolini,Muhammad Asad Ullah,Richard Demo Souza*

Main category: eess.SP

TL;DR: 本文提出四种框架用于LoRa DtS连接中的多普勒效应估计与补偿，并通过数值比较分析其性能，探讨了关键参数间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: LEO卫星在LoRa DtS连接中因多普勒效应导致性能下降，需研究补偿方法以提高通信质量。

Method: 提出四种多普勒估计与补偿框架，并与理想无多普勒场景进行数值性能比较。

Result: 分析了扩频因子等关键参数与多普勒效应的相互作用，为优化LoRa DtS配置提供依据。

Conclusion: 研究结果为实现稳健的LoRa DtS连接配置提供了实用指导。

Abstract: Within the LPWAN framework, the LoRa modulation adopted by LoRaWAN technology
has garnered significant interest as a connectivity solution for IoT
applications due to its ability to offer low-cost, low-power, and long-range
communications. One emerging use case of LoRa is DtS connectivity, which
extends coverage to remote areas for supporting IoT operations. The satellite
IoT industry mainly prefers LEO because it has lower launch costs and less path
loss compared to Geostationary orbit. However, a major drawback of LEO
satellites is the impact of the Doppler effect caused by their mobility.
Earlier studies have confirmed that the Doppler effect significantly degrades
the LoRa DtS performance. In this paper, we propose four frameworks for Doppler
estimation and compensation in LoRa DtS connectivity and numerically compare
the performance against the ideal scenario without the Doppler effect.
Furthermore, we investigate the trade-offs among these frameworks by analyzing
the interplay between spreading factor, and other key parameters related to the
Doppler effect. The results provide insights into how to achieve robust LoRa
configurations for DtS connectivity.

</details>


### [5] [Quantum-Accelerated Wireless Communications: Concepts, Connections, and Implications](https://arxiv.org/abs/2506.20863)
*Naoki Ishikawa,Giuseppe Thadeu Freitas de Abreu,Petar Popovski,Robert W. Heath Jr*

Main category: eess.SP

TL;DR: 量子计算在通信系统中具有潜力，但实际应用仍需探索。本文介绍了量子计算基础及其与无线系统的数学联系，总结了量子加速通信系统的设计趋势，并强调经典启发式方法对量子参数的优化作用。


<details>
  <summary>Details</summary>
Motivation: 探索量子计算在通信系统中的实际应用潜力，并促进量子信息处理与未来通信系统的跨学科研究。

Method: 通过系统回顾前沿研究，总结量子加速通信系统的设计趋势，并分析经典启发式方法对量子参数的优化作用。

Result: 揭示了量子计算与无线系统之间的数学联系，并展示了经典与量子计算的互补优势。

Conclusion: 量子计算在通信系统中具有潜力，经典启发式方法可优化量子参数，推动跨学科研究。

Abstract: Quantum computing is poised to redefine the algorithmic foundations of
communication systems. While quantum superposition and entanglement enable
quadratic or exponential speedups for specific problems, identifying use cases
where these advantages yield engineering benefits is, however, still
nontrivial. This article presents the fundamentals of quantum computing in a
style familiar to the communications society, outlining the current limits of
fault-tolerant quantum computing and uncovering a mathematical harmony between
quantum and wireless systems, which makes the topic more enticing to wireless
researchers. Based on a systematic review of pioneering and state-of-the-art
studies, we distill common design trends for the research and development of
quantum-accelerated communication systems and highlight lessons learned. The
key insight is that classical heuristics can sharpen certain quantum
parameters, underscoring the complementary strengths of classical and quantum
computing. This article aims to catalyze interdisciplinary research at the
frontier of quantum information processing and future communication systems.

</details>


### [6] [Co-Design of Sensing, Communications, and Control for Low-Altitude Wireless Networks](https://arxiv.org/abs/2506.20970)
*Haijia Jin,Jun Wu,Weijie Yuan,Fan Liu,Yuanhao Cui*

Main category: eess.SP

TL;DR: 该论文研究了多无人机协同系统中集成感知、通信和控制的联合设计，提出了一种基于交替优化的非凸问题解决方法，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着物联网服务和6G技术的发展，无人机在低空无线网络中扮演关键角色。研究如何优化无人机协同系统中的感知、通信和控制性能，以支持稳定控制和目标定位。

Method: 通过联合考虑控制性能（LQR成本）和定位性能（Fisher信息矩阵行列式），提出加权优化问题。采用交替优化方法分解非凸问题，结合DC编程和PGD方法求解。

Result: 仿真结果表明，所提方法优于基准方案，揭示了控制与感知性能之间的权衡。

Conclusion: 该研究为多无人机协同系统中的资源分配和性能优化提供了有效解决方案，具有实际应用潜力。

Abstract: The rapid advancement of Internet of Things (IoT) services and the evolution
toward the sixth generation (6G) have positioned unmanned aerial vehicles
(UAVs) as critical enablers of low-altitude wireless networks (LAWNs). This
work investigates the co-design of integrated sensing, communication, and
control ($\mathbf{SC^{2}}$) for multi-UAV cooperative systems with finite
blocklength (FBL) transmission. In particular, the UAVs continuously monitor
the state of the field robots and transmit their observations to the robot
controller to ensure stable control while cooperating to localize an unknown
sensing target (ST). To this end, a weighted optimization problem is first
formulated by jointly considering the control and localization performance in
terms of the linear quadratic regulator (LQR) cost and the determinant of the
Fisher information matrix (FIM), respectively. The resultant problem,
optimizing resource allocations, the UAVs' deployment positions, and multi-user
scheduling, is non-convex. To circumvent this challenge, we first derive a
closed-form expression of the LQR cost with respect to other variables.
Subsequently, the non-convex optimization problem is decomposed into a series
of sub-problems by leveraging the alternating optimization (AO) approach, in
which the difference of convex functions (DC) programming and projected
gradient descent (PGD) method are employed to obtain an efficient near-optimal
solution. Furthermore, the convergence and computational complexity of the
proposed algorithm are thoroughly analyzed. Extensive simulation results are
presented to validate the effectiveness of our proposed approach compared to
the benchmark schemes and reveal the trade-off between control and sensing
performance.

</details>


### [7] [Analysis of Null Related Beampattern Measures and Signal Quantization Effects for Linear Differential Microphone Arrays](https://arxiv.org/abs/2506.21043)
*Shweta Pal,Arun Kumar,Monika Agrawal*

Main category: eess.SP

TL;DR: 本文提出了一种评估差分麦克风阵列（DMA）波束功率模式中零点的深度和宽度的方法，并研究了量化效应对不同阶数DMA性能的影响。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏直接评估零点效能的指标，本文旨在填补这一空白，为DMA的应用提供更深入的分析工具。

Method: 提出了零点深度（ND）和零点宽度（NW）作为评估指标，研究了1至3阶线性DMA在不同波束模式下的量化效应，并推导了N阶DMA的量化波束输出表达式。

Result: 仿真和实验室实验验证了ND和NW的有效性，量化比特数和深度对ND和NW的影响得到了分析。

Conclusion: 本文提出的方法能够有效评估DMA的零点性能，为实际应用提供了理论支持。

Abstract: A differential microphone array (DMA) offers enhanced capabilities to obtain
sharp nulls at the cost of relatively broad peaks in the beam power pattern.
This can be used for applications that require nullification or attenuation of
interfering sources. To the best of our knowledge, the existing literature
lacks measures that directly assess the efficacy of nulls, and null-related
measures have not been investigated in the context of differential microphone
arrays (DMAs). This paper offers new insights about the utility of DMAs by
proposing measures that characterize the nulls in their beam power patterns. We
investigate the performance of differential beamformers by presenting and
evaluating null-related measures namely null depth (ND) and Null Width (NW) as
a function of depth level relative to the beam power pattern maxima. A study of
signal quantization effects due to data acquisition for 1st, 2nd and 3rd order
linear DMAs and for different beampatterns i.e. dipole, cardioid, hypercardioid
and supercardioid is presented. An analytical expression for the quantized
beamformed output for any general $ N^{th} $ order DMA is formulated.
Simulation results of the variation of ND with number of quantization bits and
the variation of NW as a function of depth are also presented and inferences
are drawn. Lab experiments are conducted in a fully anechoic room to support
the simulation results. The measured beampattern exhibits a pronounced null
depth, confirming the effectiveness of the experimental setup.

</details>


### [8] [Point Cloud Environment-Based Channel Knowledge Map Construction](https://arxiv.org/abs/2506.21112)
*Yancheng Wang,Wei Guo,Guanying Chen,Ye Zhang,Shuguang Cui*

Main category: eess.SP

TL;DR: 本文提出了一种联合模型和数据驱动的方法，利用点云环境数据和少量位置标记的信道信息构建信道知识图（CKM），显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 现有CKM构建方案因使用过于简化的环境信息而准确性不足，本文旨在解决这一问题。

Method: 提出基于时延的共焦椭球体点选择器筛选相关点云子集，并训练神经网络估计信道增益。

Result: 实验显示，该方法在PDP和无线电地图构建中分别实现了2.95 dB和1.04 dB的RMSE，优于传统方法。

Conclusion: 该方法通过结合点云数据和少量信道样本，显著提升了CKM构建的准确性。

Abstract: Channel knowledge map (CKM) provides certain levels of channel state
information (CSI) for an area of interest, serving as a critical enabler for
environment-aware communications by reducing the overhead of frequent CSI
acquisition. However, existing CKM construction schemes adopt over-simplified
environment information, which significantly compromises their accuracy. To
address this issue, this work proposes a joint model- and data-driven approach
to construct CKM by leveraging point cloud environmental data along with a few
samples of location-tagged channel information. First, we propose a novel point
selector to identify subsets of point cloud that contain environmental
information relevant to multipath channel gains, by constructing a set of
co-focal ellipsoids based on different time of arrival (ToAs). Then, we trained
a neural channel gain estimator to learn the mapping between each selected
subset and its corresponding channel gain, using a real-world dataset we
collected through field measurements, comprising environmental point clouds and
corresponding channel data. Finally, experimental results demonstrate that: For
CKM construction of power delay profile (PDP), the proposed method achieves a
root mean squared error (RMSE) of 2.95 dB, significantly lower than the 7.32 dB
achieved by the conventional ray-tracing method; for CKM construction of
received power values, i.e., radio map, it achieves an RMSE of 1.04 dB,
surpassing the Kriging interpolation method with an RMSE of 1.68 dB.

</details>


### [9] [Characterization of Rydberg-Atom Signal Reception of Dual-Frequency Signals Coupled with Two Energy Levels](https://arxiv.org/abs/2506.21123)
*Hao Wu,Chongwu Xie,Xinyuan Yao,Kang-Da Wu,Shanchi Wu,Rui Ni,Guo-Yong Xiang,Chen Gong*

Main category: eess.SP

TL;DR: 论文分析了基于里德堡原子的多频信号传感器中的多用户干扰问题，提出了联合响应系数，并通过实验验证了误码率和符号错误率。


<details>
  <summary>Details</summary>
Motivation: 里德堡原子传感器在多频信号测量中具有潜力，但多用户干扰问题限制了其应用，因此需要分析干扰特性。

Method: 通过联合响应系数分析两个不同载频信号的相互干扰，并计算误码率和符号错误率。

Result: 实验验证了干扰对误码率和符号错误率的影响。

Conclusion: 研究为里德堡原子传感器在多用户通信中的应用提供了干扰分析基础。

Abstract: Rydberg atomic sensors have been adopted for novel radio frequency (RF)
measurement technique and the sensing capability for signals in multiple
frequencies makes it attractive for multi-user communication. However, unlike
traditional antennas where the signals in multiple frequencies are orthogonal,
the received signals of atomic sensors corresponding to different energy levels
will be downconverted to the baseband simultaneously, resulting in multi-user
interference. Thus, in this paper, we analyze the mutual interference
characteristics of two RF signals with different carrier frequencies coupling
different energy levels. We introduce the joint response coefficient based on
the receiver characteristics and analyze the interference of one user to
another. We analyze the bit-error rate (BER) and symbol-error rate (SER) for
two signals coupling two different energy levels. We also conduct experiments
to validate the BER and SER results.

</details>


### [10] [Adversarial Training: Enhancing Out-of-Distribution Generalization for Learning Wireless Resource Allocation](https://arxiv.org/abs/2506.21208)
*Shengjie Liu,Chenyang Yang*

Main category: eess.SP

TL;DR: 论文提出了一种基于对抗训练（AT）的方法，用于提升无监督训练的深度神经网络（DNN）在分布偏移（OOD）情况下的泛化能力，并通过优化混合预编码验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在资源分配中广泛应用，但其性能容易受到训练与测试数据分布偏移（如信道变化）的影响，因此需要提升其OOD泛化能力。

Method: 重新设计对抗训练以捕捉OOD性能退化，并提出一种一步梯度上升的对抗训练方法。

Result: 仿真结果表明，仅使用瑞利衰落信道进行训练时，该方法能显著提升多种DNN在不同信道分布下的OOD性能。

Conclusion: 通过对抗训练改进的DNN在分布偏移下表现出更强的泛化能力，为资源分配优化提供了更可靠的解决方案。

Abstract: Deep neural networks (DNNs) have widespread applications for optimizing
resource allocation. Yet, their performance is vulnerable to distribution
shifts between training and test data, say channels. In this letter, we resort
to adversarial training (AT) for enhancing out-of-distribution (OOD)
generalizability of DNNs trained in unsupervised manner. We reformulate AT to
capture the OOD degradation, and propose a one-step gradient ascent method for
AT. The proposed method is validated by optimizing hybrid precoding. Simulation
results showcase the enhanced OOD performance of multiple kinds of DNNs across
various channel distributions, when only Rayleigh fading channels are used for
training.

</details>


### [11] [Localization-Based Beam Focusing in Near-Field Communications](https://arxiv.org/abs/2506.21325)
*Nima Mozaffarikhosravi,Prathapasinghe Dharmawansa,Italo Atzeni*

Main category: eess.SP

TL;DR: 论文提出了一种基于定位的波束聚焦策略，利用毫米波和亚太赫兹频段的视距传播优势，并通过2D-MUSIC算法进行距离估计，与传统的零强迫方法相比，在特定条件下表现更优。


<details>
  <summary>Details</summary>
Motivation: 随着6G及以上无线通信系统向更高频段发展和大规模MIMO阵列的应用，近场区域扩展会影响波束成形和用户定位方案，因此需要新的解决方案。

Method: 提出基于定位的波束聚焦策略，利用视距传播特性，并通过2D-MUSIC算法分析距离估计。

Result: 数值结果表明，在视距传播主导、短相干块和高噪声功率条件下，所提方法比传统零强迫方法更有效。

Conclusion: 基于定位的波束聚焦策略在高频段和大带宽场景下具有优势，尤其在视距传播条件下表现更佳。

Abstract: Shifting 6G-and-beyond wireless communication systems to higher frequency
bands and the utilization of massive multiple-input multiple-output arrays will
extend the near-field region, affecting beamforming and user localization
schemes. In this paper, we propose a localization-based beam-focusing strategy
that leverages the dominant line-of-sight (LoS) propagation arising at mmWave
and sub-THz frequencies. To support this approach, we analyze the 2D-MUSIC
algorithm for distance estimation by examining its spectrum in simplified,
tractable setups with minimal numbers of antennas and users. Lastly, we compare
the proposed localization-based beam focusing, with locations estimated via
2D-MUSIC, with zero forcing with pilot-based channel estimation in terms of
uplink sum spectral efficiency. Our numerical results show that the proposed
method becomes more effective under LoS-dominated propagation, short coherence
blocks, and strong noise power arising at high carrier frequencies and with
large bandwidths.

</details>


### [12] [Integrating Movable Antennas and Intelligent Reflecting Surfaces for Coverage Enhancement](https://arxiv.org/abs/2506.21375)
*Ying Gao,Qingqing Wu,Weidong Mei,Guangji Chen,Wen Chen,Ziyuan Zheng*

Main category: eess.SP

TL;DR: 论文研究了IRS辅助的MA系统，通过联合优化MA位置、IRS反射系数和发射波束成形，提升多目标区域的无线覆盖。提出了三种覆盖增强方案，并开发了高效算法框架。仿真结果表明，MA方案优于固定天线方案，且MA与IRS元素的最优比例与成本比成反比。


<details>
  <summary>Details</summary>
Motivation: 解决无线覆盖扩展问题，通过IRS和MA的协同优化提升信号质量，同时平衡性能与成本。

Method: 提出三种覆盖增强方案（area-adaptive MA-IRS、area-adaptive MA-staIRS、shared MA-staIRS），并开发通用算法框架解决非凸优化问题。

Result: MA方案优于固定天线方案，area-adaptive MA-IRS性能最佳；MA与IRS元素比例与成本比成反比。

Conclusion: IRS辅助的MA系统能有效提升无线覆盖，MA方案在性能与成本间取得平衡，为未来无线网络设计提供参考。

Abstract: This paper investigates an intelligent reflecting surface (IRS)-aided movable
antenna (MA) system, where multiple IRSs cooperate with a multi-MA base station
to extend wireless coverage to multiple designated target areas. The objective
is to maximize the worst-case signal-to-noise ratio (SNR) across all locations
within these areas through joint optimization of MA positions, IRS reflection
coefficients, and transmit beamforming. To achieve this while balancing the
performance-cost trade-off, we propose three coverage-enhancement schemes: the
area-adaptive MA-IRS scheme, the area-adaptive MA-staIRS scheme, and the shared
MA-staIRS scheme, where staIRS denotes static IRSs with reflection coefficients
configured only once during installation. These schemes lead to challenging
non-convex optimization problems with implicit objective functions, which are
difficult to solve optimally. To address these problems, we propose a general
algorithmic framework that can be applied to solve each problem efficiently
albeit suboptimally. Simulation results demonstrate that: 1) the proposed
MA-based schemes consistently outperform their fixed-position antenna
(FPA)-based counterparts under both area-adaptive and static IRS
configurations, with the area-adaptive MA-IRS scheme achieving the best
worst-case SNR performance; 2) as transmit antennas are typically far fewer
than IRS elements, the area-adaptive MA-staIRS scheme may underperform the
baseline FPA scheme with area-adaptive IRSs in terms of the worst-case SNR, but
a modest increase in antenna number can reverse this trend; 3) under a fixed
total cost, the optimal MA-to-IRS-element ratio for the worst-case SNR
maximization is empirically found to be proportional to the reciprocal of their
unit cost ratio.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [13] [CodecSlime: Temporal Redundancy Compression of Neural Speech Codec via Dynamic Frame Rate](https://arxiv.org/abs/2506.21074)
*Hankun Wang,Yiwei Guo,Chongtian Shao,Bohan Li,Xie Chen,Kai Yu*

Main category: eess.AS

TL;DR: CodecSlime提出了一种动态帧率（DFR）的神经语音编解码方法，解决了固定帧率（FFR）在语音压缩中的冗余问题，显著提升了重建质量和比特率灵活性。


<details>
  <summary>Details</summary>
Motivation: 语音的时间信息密度不均匀，固定帧率编解码器在稳态段（如长元音和静音）浪费了大量标记，导致效率低下。

Method: CodecSlime结合了ScheDFR（推理适应）和Melt-and-Cool（训练适应）两种创新方法，支持动态帧率，无需监督且与架构无关。

Result: 在40 Hz DFR（约600 bps）下，CodecSlime的重建WER比传统FFR基线降低了46%，其他指标也表现优异，且支持多帧率推理。

Conclusion: CodecSlime显著提升了语音编解码的效率和质量，支持灵活的比特率与重建质量权衡，优于传统固定帧率方法。

Abstract: Neural speech codecs have been widely used in audio compression and various
downstream tasks. Current mainstream codecs are fixed-frame-rate (FFR), which
allocate the same number of tokens to every equal-duration slice. However,
speech is inherently non-uniform in temporal information density. As a result,
many tokens are wasted on steady-state segments like long vowels and silences.
To address this mismatch, we present CodecSlime, a plugin-style method for
compressing temporal redundancy through supporting dynamic frame rate (DFR) on
neural speech codecs for the first time. Our method is unsupervised and
architecture-agnostic, combining two key innovations, ScheDFR and
Melt-and-Cool, for adapting inference and training, respectively. When
integrated into a typical VQ-GAN codec backbone and operating at 40 Hz DFR
($\approx$ 600 bps), the reconstruction WER of CodecSlime is reduced by up to
46% relative to conventional FFR baselines with the same model architecture and
similar bitrates, while other metrics are also competitive. CodecSlime also
enables flexible trade-offs between reconstruction quality and bitrate: a
single model supports inference at multiple frame rates and consistently
outperforms FFR models at the corresponding frame rates. Audio samples are
available at https://acadarmeria.github.io/codecslime/.

</details>


### [14] [Post-training for Deepfake Speech Detection](https://arxiv.org/abs/2506.21090)
*Wanying Ge,Xin Wang,Xuechen Liu,Junichi Yamagishi*

Main category: eess.AS

TL;DR: 提出了一种后训练方法，通过桥接通用预训练和领域特定微调之间的差距，将自监督学习模型用于深度伪造语音检测。


<details>
  <summary>Details</summary>
Motivation: 解决自监督学习模型在深度伪造语音检测中通用预训练与领域特定微调之间的差距问题。

Method: 使用大规模多语言语音数据集（包含超过56,000小时的真实语音和18,000小时的带有各种伪影的语音）开发了AntiDeepfake模型系列。

Result: 实验结果表明，后训练模型对未见过的深度伪造语音表现出强大的鲁棒性和泛化能力。在Deepfake-Eval-2024数据集上进一步微调后，这些模型表现优于现有不利用后训练的最先进检测器。

Conclusion: 后训练方法显著提升了深度伪造语音检测的性能，模型检查点和源代码已公开。

Abstract: We introduce a post-training approach that adapts self-supervised learning
(SSL) models for deepfake speech detection by bridging the gap between general
pre-training and domain-specific fine-tuning. We present AntiDeepfake models, a
series of post-trained models developed using a large-scale multilingual speech
dataset containing over 56,000 hours of genuine speech and 18,000 hours of
speech with various artifacts in over one hundred languages. Experimental
results show that the post-trained models already exhibit strong robustness and
generalization to unseen deepfake speech. When they are further fine-tuned on
the Deepfake-Eval-2024 dataset, these models consistently surpass existing
state-of-the-art detectors that do not leverage post-training. Model
checkpoints and source code are available online.

</details>


### [15] [Performance improvement of spatial semantic segmentation with enriched audio features and agent-based error correction for DCASE 2025 Challenge Task 4](https://arxiv.org/abs/2506.21174)
*Jongyeon Park,Joonhee Lee,Do-Hyeon Lim,Hong Kook Kim,Hyeongcheol Geum,Jeong Eun Lim*

Main category: eess.AS

TL;DR: 该技术报告介绍了DCASE 2025挑战赛任务4的提交系统，通过结合额外的音频特征和改进标签校正系统，显著提升了音频分类性能。


<details>
  <summary>Details</summary>
Motivation: 混合音频中的细微线索难以仅通过梅尔频谱捕捉，因此需要引入额外特征以提供更多视角。

Method: 结合了频谱滚降和色度特征，并应用基于代理的标签校正系统，同时优化训练数据集。

Result: 实验表明，该系统将CA-SDRi指标相对提升了14.7%。

Conclusion: 通过多特征融合和数据集优化，显著提升了音频分类模型的性能。

Abstract: This technical report presents submission systems for Task 4 of the DCASE
2025 Challenge. This model incorporates additional audio features (spectral
roll-off and chroma features) into the embedding feature extracted from the
mel-spectral feature to im-prove the classification capabilities of an
audio-tagging model in the spatial semantic segmentation of sound scenes (S5)
system. This approach is motivated by the fact that mixed audio often contains
subtle cues that are difficult to capture with mel-spectrograms alone. Thus,
these additional features offer alterna-tive perspectives for the model.
Second, an agent-based label correction system is applied to the outputs
processed by the S5 system. This system reduces false positives, improving the
final class-aware signal-to-distortion ratio improvement (CA-SDRi) metric.
Finally, we refine the training dataset to enhance the classi-fication accuracy
of low-performing classes by removing irrele-vant samples and incorporating
external data. That is, audio mix-tures are generated from a limited number of
data points; thus, even a small number of out-of-class data points could
degrade model performance. The experiments demonstrate that the submit-ted
systems employing these approaches relatively improve CA-SDRi by up to 14.7%
compared to the baseline of DCASE 2025 Challenge Task 4.

</details>


### [16] [Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings](https://arxiv.org/abs/2506.21386)
*Ghazal Al-Shwayyat,Omer Nezih Gerek*

Main category: eess.AS

TL;DR: 研究结合传统信号处理与深度学习的混合模型，用于低资源阿拉伯方言识别，MFCC+CNN表现优于DWT+RNN。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言识别因语言多样性和标注数据稀缺而具挑战性，研究旨在解决低资源场景下的问题。

Method: 开发两种混合模型：MFCC+CNN和DWT+RNN，使用Common Voice阿拉伯数据集进行训练和评估。

Result: MFCC+CNN准确率达91.2%，显著优于DWT+RNN的66.5%，验证了卷积模型在低资源场景的有效性。

Conclusion: 研究为低资源阿拉伯方言识别提供了基准，建议未来采用更大标注数据集和自监督学习技术。

Abstract: Arabic dialect recognition presents a significant challenge in speech
technology due to the linguistic diversity of Arabic and the scarcity of large
annotated datasets, particularly for underrepresented dialects. This research
investigates hybrid modeling strategies that integrate classical signal
processing techniques with deep learning architectures to address this problem
in low-resource scenarios. Two hybrid models were developed and evaluated: (1)
Mel-Frequency Cepstral Coefficients (MFCC) combined with a Convolutional Neural
Network (CNN), and (2) Discrete Wavelet Transform (DWT) features combined with
a Recurrent Neural Network (RNN). The models were trained on a dialect-filtered
subset of the Common Voice Arabic dataset, with dialect labels assigned based
on speaker metadata. Experimental results demonstrate that the MFCC + CNN
architecture achieved superior performance, with an accuracy of 91.2% and
strong precision, recall, and F1-scores, significantly outperforming the
Wavelet + RNN configuration, which achieved an accuracy of 66.5%. These
findings highlight the effectiveness of leveraging spectral features with
convolutional models for Arabic dialect recognition, especially when working
with limited labeled data. The study also identifies limitations related to
dataset size, potential regional overlaps in labeling, and model optimization,
providing a roadmap for future research. Recommendations for further
improvement include the adoption of larger annotated corpora, integration of
self-supervised learning techniques, and exploration of advanced neural
architectures such as Transformers. Overall, this research establishes a strong
baseline for future developments in Arabic dialect recognition within
resource-constrained environments.

</details>


### [17] [ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing](https://arxiv.org/abs/2506.21448)
*Huadai Liu,Jialei Wang,Kaicheng Luo,Wen Wang,Qian Chen,Zhou Zhao,Wei Xue*

Main category: eess.AS

TL;DR: ThinkSound是一个基于Chain-of-Thought推理的视频到音频生成框架，通过分阶段生成和编辑音频，结合用户交互和自然语言指导，实现了高保真音频生成。


<details>
  <summary>Details</summary>
Motivation: 当前端到端视频到音频生成方法难以捕捉视觉内容的细微差别，需要更复杂的推理能力。

Method: ThinkSound将音频生成分为三个阶段：基础音效生成、交互式对象中心细化、自然语言指导的编辑，利用多模态大语言模型生成上下文对齐的推理。

Result: ThinkSound在音频指标和CoT指标上均达到最先进性能，并在Movie Gen Audio基准测试中表现出色。

Conclusion: ThinkSound通过分阶段推理和用户交互，显著提升了视频到音频生成的质量和灵活性。

Abstract: While end-to-end video-to-audio generation has greatly improved, producing
high-fidelity audio that authentically captures the nuances of visual content
remains challenging. Like professionals in the creative industries, such
generation requires sophisticated reasoning about items such as visual
dynamics, acoustic environments, and temporal relationships. We present
\textbf{ThinkSound}, a novel framework that leverages Chain-of-Thought (CoT)
reasoning to enable stepwise, interactive audio generation and editing for
videos. Our approach decomposes the process into three complementary stages:
foundational foley generation that creates semantically coherent soundscapes,
interactive object-centric refinement through precise user interactions, and
targeted editing guided by natural language instructions. At each stage, a
multimodal large language model generates contextually aligned CoT reasoning
that guides a unified audio foundation model. Furthermore, we introduce
\textbf{AudioCoT}, a comprehensive dataset with structured reasoning
annotations that establishes connections between visual content, textual
descriptions, and sound synthesis. Experiments demonstrate that ThinkSound
achieves state-of-the-art performance in video-to-audio generation across both
audio metrics and CoT metrics and excels in out-of-distribution Movie Gen Audio
benchmark. The demo page is available at https://ThinkSound-Demo.github.io.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [18] [A Multi-Stage Framework for Multimodal Controllable Speech Synthesis](https://arxiv.org/abs/2506.20945)
*Rui Niu,Weihao Wu,Jie Chen,Long Ma,Zhiyong Wu*

Main category: cs.SD

TL;DR: 提出了一种三阶段多模态可控语音合成框架，通过监督学习和知识蒸馏提升人脸编码器的泛化能力，并结合文本编码器增强语音多样性。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于人脸的方法因数据质量限制导致的鲁棒性和泛化性问题，以及文本提示方法在多样性和细粒度控制上的不足。

Method: 采用三阶段多模态框架，结合监督学习和知识蒸馏优化人脸编码器，同时训练文本编码器以整合文本-人脸和文本-语音数据。

Result: 实验表明，该方法在基于人脸和文本提示的语音合成中均优于单模态基线方法。

Conclusion: 该方法能有效生成高质量语音，解决了多模态数据依赖和性能限制问题。

Abstract: Controllable speech synthesis aims to control the style of generated speech
using reference input, which can be of various modalities. Existing face-based
methods struggle with robustness and generalization due to data quality
constraints, while text prompt methods offer limited diversity and fine-grained
control. Although multimodal approaches aim to integrate various modalities,
their reliance on fully matched training data significantly constrains their
performance and applicability. This paper proposes a 3-stage multimodal
controllable speech synthesis framework to address these challenges. For face
encoder, we use supervised learning and knowledge distillation to tackle
generalization issues. Furthermore, the text encoder is trained on both
text-face and text-speech data to enhance the diversity of the generated
speech. Experimental results demonstrate that this method outperforms
single-modal baseline methods in both face based and text prompt based speech
synthesis, highlighting its effectiveness in generating high-quality speech.

</details>


### [19] [PeakNetFP: Peak-based Neural Audio Fingerprinting Robust to Extreme Time Stretching](https://arxiv.org/abs/2506.21086)
*Guillem Cortès-Sebastià,Benjamin Martin,Emilio Molina,Xavier Serra,Romain Hennequin*

Main category: cs.SD

TL;DR: PeakNetFP是一种基于频谱峰值的神经音频指纹系统，结合了传统峰值方法和深度学习技术，在时间拉伸音频数据上表现优异，且参数和输入数据量大幅减少。


<details>
  <summary>Details</summary>
Motivation: 传统峰值音频指纹方法在时间拉伸音频数据上表现不佳，而深度学习方法如NeuralFP虽有效但计算成本高。PeakNetFP旨在结合两者的优势。

Method: PeakNetFP采用类似PointNet++的分层点特征提取技术，并使用对比学习进行训练，结合了峰值方法的稀疏性和神经网络的模式识别能力。

Result: PeakNetFP在50%至200%的时间拉伸范围内保持90%以上的Top-1命中率，参数和输入数据量分别比NeuralFP少100倍和11倍。

Conclusion: PeakNetFP成功融合了峰值方法的轻量化和神经网络的适应性，为音频指纹技术提供了高效且可扩展的解决方案。

Abstract: This work introduces PeakNetFP, the first neural audio fingerprinting (AFP)
system designed specifically around spectral peaks. This novel system is
designed to leverage the sparse spectral coordinates typically computed by
traditional peak-based AFP methods. PeakNetFP performs hierarchical point
feature extraction techniques similar to the computer vision model PointNet++,
and is trained using contrastive learning like in the state-of-the-art deep
learning AFP, NeuralFP. This combination allows PeakNetFP to outperform
conventional AFP systems and achieves comparable performance to NeuralFP when
handling challenging time-stretched audio data. In extensive evaluation,
PeakNetFP maintains a Top-1 hit rate of over 90% for stretching factors ranging
from 50% to 200%. Moreover, PeakNetFP offers significant efficiency advantages:
compared to NeuralFP, it has 100 times fewer parameters and uses 11 times
smaller input data. These features make PeakNetFP a lightweight and efficient
solution for AFP tasks where time stretching is involved. Overall, this system
represents a promising direction for future AFP technologies, as it
successfully merges the lightweight nature of peak-based AFP with the
adaptability and pattern recognition capabilities of neural network-based
approaches, paving the way for more scalable and efficient solutions in the
field.

</details>


### [20] [A Hierarchical Deep Learning Approach for Minority Instrument Detection](https://arxiv.org/abs/2506.21167)
*Dylan Sechet,Francesca Bugiotti,Matthieu Kowalski,Edouard d'Hérouville,Filip Langiewicz*

Main category: cs.SD

TL;DR: 该论文探讨了在音乐信息检索中通过层次分类方法识别乐器活动，特别是在数据有限的情况下，利用Hornbostel-Sachs分类系统提升乐器检测的可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决音乐信息检索中乐器识别问题，尤其是在数据有限的情况下，通过层次分类方法提升识别效果。

Method: 基于Hornbostel-Sachs分类系统，提出层次分类策略，并在MedleyDB数据集上进行评估。

Result: 展示了层次分类方法在粗粒度乐器检测上的可靠性，为未来研究提供了方向。

Conclusion: 层次分类方法在乐器识别中具有潜力，特别是在数据有限的情况下，为音乐信息检索领域提供了新的思路。

Abstract: Identifying instrument activities within audio excerpts is vital in music
information retrieval, with significant implications for music cataloging and
discovery. Prior deep learning endeavors in musical instrument recognition have
predominantly emphasized instrument classes with ample data availability.
Recent studies have demonstrated the applicability of hierarchical
classification in detecting instrument activities in orchestral music, even
with limited fine-grained annotations at the instrument level. Based on the
Hornbostel-Sachs classification, such a hierarchical classification system is
evaluated using the MedleyDB dataset, renowned for its diversity and richness
concerning various instruments and music genres. This work presents various
strategies to integrate hierarchical structures into models and tests a new
class of models for hierarchical music prediction. This study showcases more
reliable coarse-level instrument detection by bridging the gap between detailed
instrument identification and group-level recognition, paving the way for
further advancements in this domain.

</details>


### [21] [Integrating Vehicle Acoustic Data for Enhanced Urban Traffic Management: A Study on Speed Classification in Suzhou](https://arxiv.org/abs/2506.21269)
*Pengfei Fan,Yuli Zhang,Xinheng Wang,Ruiyuan Jiang,Hankang Gu,Dongyao Jia,Shangbo Wang*

Main category: cs.SD

TL;DR: 该研究公开了苏州城市道路声学数据集（SZUR-Acoustic Dataset），并提出了一种双模态特征融合深度卷积神经网络（BMCNN）来建模车辆噪声与行驶速度的关系。实验表明，BMCNN在两个数据集上表现优异，并验证了各模块对性能提升的贡献。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过声学数据建模车辆噪声与速度的关系，以支持智能城市交通管理系统，优化交通流控制并减少噪声污染。

Method: 提出BMCNN网络，结合自适应去噪和归一化预处理，并行提取MFCC和小波包能量特征，并通过跨模态注意力机制融合。

Result: BMCNN在SZUR-Acoustic数据集上分类准确率达87.56%，在IDMT-Traffic数据集上达96.28%。

Conclusion: 该方法可集成到智能城市交通管理系统中，用于实时噪声监测和速度估计，支持可持续城市规划。

Abstract: This study presents and publicly releases the Suzhou Urban Road Acoustic
Dataset (SZUR-Acoustic Dataset), which is accompanied by comprehensive
data-acquisition protocols and annotation guidelines to ensure transparency and
reproducibility of the experimental workflow. To model the coupling between
vehicular noise and driving speed, we propose a bimodal-feature-fusion deep
convolutional neural network (BMCNN). During preprocessing, an adaptive
denoising and normalization strategy is applied to suppress environmental
background interference; in the network architecture, parallel branches extract
Mel-frequency cepstral coefficients (MFCCs) and wavelet-packet energy features,
which are subsequently fused via a cross-modal attention mechanism in the
intermediate feature space to fully exploit time-frequency information.
Experimental results demonstrate that BMCNN achieves a classification accuracy
of 87.56% on the SZUR-Acoustic Dataset and 96.28% on the public IDMT-Traffic
dataset. Ablation studies and robustness tests on the Suzhou dataset further
validate the contributions of each module to performance improvement and
overfitting mitigation. The proposed acoustics-based speed classification
method can be integrated into smart-city traffic management systems for
real-time noise monitoring and speed estimation, thereby optimizing traffic
flow control, reducing roadside noise pollution, and supporting sustainable
urban planning.

</details>


### [22] [Exploring Adapter Design Tradeoffs for Low Resource Music Generation](https://arxiv.org/abs/2506.21298)
*Atharva Mehta,Shivam Chauhan,Monojit Choudhury*

Main category: cs.SD

TL;DR: 论文研究了在低资源音乐类型（如印度斯坦古典和土耳其Makam音乐）中，如何通过参数高效微调（PEFT）技术优化MusicGen和Mustango模型的适配器设计，发现卷积和Transformer适配器各有优势，并分析了计算资源与性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 研究适配器设计（架构、位置和大小）对低资源音乐类型生成模型性能的影响，以解决大规模音乐生成模型微调的高计算成本问题。

Method: 通过实验比较不同适配器配置（卷积和Transformer）在MusicGen和Mustango模型上的表现，分析其在印度斯坦古典和土耳其Makam音乐中的效果。

Result: 卷积适配器擅长捕捉局部音乐细节，Transformer适配器更适合长程依赖；Mustango生成多样性高但稳定性差，MusicGen训练更快且质量更高。

Conclusion: 适配器设计需根据任务需求选择，中规模适配器（40M参数）在表达力和质量间取得最佳平衡，Mustango和MusicGen各有优劣。

Abstract: Fine-tuning large-scale music generation models, such as MusicGen and
Mustango, is a computationally expensive process, often requiring updates to
billions of parameters and, therefore, significant hardware resources.
Parameter-Efficient Fine-Tuning (PEFT) techniques, particularly adapter-based
methods, have emerged as a promising alternative, enabling adaptation with
minimal trainable parameters while preserving model performance. However, the
design choices for adapters, including their architecture, placement, and size,
are numerous, and it is unclear which of these combinations would produce
optimal adapters and why, for a given case of low-resource music genre. In this
paper, we attempt to answer this question by studying various adapter
configurations for two AI music models, MusicGen and Mustango, on two genres:
Hindustani Classical and Turkish Makam music.
  Our findings reveal distinct trade-offs: convolution-based adapters excel in
capturing fine-grained local musical details such as ornamentations and short
melodic phrases, while transformer-based adapters better preserve long-range
dependencies crucial for structured improvisation. Additionally, we analyze
computational resource requirements across different adapter scales,
demonstrating how mid-sized adapters (40M parameters) achieve an optimal
balance between expressivity and quality. Furthermore, we find that Mustango, a
diffusion-based model, generates more diverse outputs with better adherence to
the description in the input prompt while lacking in providing stability in
notes, rhythm alignment, and aesthetics. Also, it is computationally intensive
and requires significantly more time to train. In contrast, autoregressive
models like MusicGen offer faster training and are more efficient, and can
produce better quality output in comparison, but have slightly higher
redundancy in their generations.

</details>


### [23] [Learnable Adaptive Time-Frequency Representation via Differentiable Short-Time Fourier Transform](https://arxiv.org/abs/2506.21440)
*Maxime Leiber,Yosra Marnissi,Axel Barrau,Sylvain Meignen,Laurent Massoulié*

Main category: cs.SD

TL;DR: 提出了一种可微分的短时傅里叶变换（STFT）方法，通过梯度优化参数，解决了传统方法依赖离散搜索的问题，并展示了其在提升时频表示和下游任务性能上的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统STFT参数调整依赖手动或启发式方法，效果不佳且计算量大。

Method: 提出了一种统一的可微分STFT框架，支持基于梯度的参数优化，并可无缝集成到神经网络中。

Result: 实验表明，该方法能显著提升时频表示质量，并改善下游任务性能。

Conclusion: 可微分STFT为信号分析提供了一种高效且灵活的优化途径。

Abstract: The short-time Fourier transform (STFT) is widely used for analyzing
non-stationary signals. However, its performance is highly sensitive to its
parameters, and manual or heuristic tuning often yields suboptimal results. To
overcome this limitation, we propose a unified differentiable formulation of
the STFT that enables gradient-based optimization of its parameters. This
approach addresses the limitations of traditional STFT parameter tuning
methods, which often rely on computationally intensive discrete searches. It
enables fine-tuning of the time-frequency representation (TFR) based on any
desired criterion. Moreover, our approach integrates seamlessly with neural
networks, allowing joint optimization of the STFT parameters and network
weights. The efficacy of the proposed differentiable STFT in enhancing TFRs and
improving performance in downstream tasks is demonstrated through experiments
on both simulated and real-world data.

</details>


### [24] [SmoothSinger: A Conditional Diffusion Model for Singing Voice Synthesis with Multi-Resolution Architecture](https://arxiv.org/abs/2506.21478)
*Kehan Sui,Jinxu Xiang,Fang Jin*

Main category: cs.SD

TL;DR: SmoothSinger是一种基于条件扩散模型的歌唱语音合成方法，通过统一框架直接优化低质量音频，避免了传统两阶段流程的失真问题，显著提升了合成语音的自然度和表现力。


<details>
  <summary>Details</summary>
Motivation: 歌唱语音合成（SVS）需要精确建模音高、时长和发音，但现有扩散模型在SVS中因复杂声学和音乐特性导致自然度下降。

Method: 采用参考引导的双分支架构，通过低质量音频引导去噪过程，并引入并行低频上采样路径以捕捉音高轮廓和长期频谱依赖。

Result: 在Opencpop数据集上的实验表明，SmoothSinger在客观和主观评估中均达到最优性能，显著减少了伪影并提升了自然度。

Conclusion: SmoothSinger通过统一框架和优化设计，显著提升了歌唱语音合成的质量和自然度，为SVS领域提供了新的解决方案。

Abstract: Singing voice synthesis (SVS) aims to generate expressive and high-quality
vocals from musical scores, requiring precise modeling of pitch, duration, and
articulation. While diffusion-based models have achieved remarkable success in
image and video generation, their application to SVS remains challenging due to
the complex acoustic and musical characteristics of singing, often resulting in
artifacts that degrade naturalness. In this work, we propose SmoothSinger, a
conditional diffusion model designed to synthesize high quality and natural
singing voices. Unlike prior methods that depend on vocoders as a final stage
and often introduce distortion, SmoothSinger refines low-quality synthesized
audio directly in a unified framework, mitigating the degradation associated
with two-stage pipelines. The model adopts a reference-guided dual-branch
architecture, using low-quality audio from any baseline system as a reference
to guide the denoising process, enabling more expressive and context-aware
synthesis. Furthermore, it enhances the conventional U-Net with a parallel
low-frequency upsampling path, allowing the model to better capture pitch
contours and long term spectral dependencies. To improve alignment during
training, we replace reference audio with degraded ground truth audio,
addressing temporal mismatch between reference and target signals. Experiments
on the Opencpop dataset, a large-scale Chinese singing corpus, demonstrate that
SmoothSinger achieves state-of-the-art results in both objective and subjective
evaluations. Extensive ablation studies confirm its effectiveness in reducing
artifacts and improving the naturalness of synthesized voices.

</details>

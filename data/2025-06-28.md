<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SD](#cs.SD) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Precise Near-Field Beam Training with DFT Codebook based on Amplitude-only Measurement](https://arxiv.org/abs/2506.20783)
*Zijun Wang,Shawn Tsai,Rama Kiran,Rui Zhang*

Main category: eess.SP

TL;DR: 提出了一种低复杂度的近场波束训练方案，利用传统的DFT码书，通过分析近场波束模式和推导闭式表达式，实现了高效的用户距离估计，显著提升了信噪比和可达速率。


<details>
  <summary>Details</summary>
Motivation: 极大规模天线阵列（ELAAs）在高频段的近场通信需求推动了波束训练和信号处理设计的进步，但现有方法复杂度高，需要低复杂度解决方案。

Method: 分析近场波束模式，推导波束宽度和中心增益的闭式表达式，定义角度依赖的修正瑞利距离，开发复杂度为O(1)的用户距离估计方法，并通过最大似然估计（MLE）进一步优化精度。

Result: 仿真结果显示，单用户和多用户场景下信噪比提升高达2.38 dB，可达速率接近理想信道状态信息下的性能。

Conclusion: 提出的低复杂度方案在近场通信中表现出色，显著提升了性能，且复杂度可控。

Abstract: Extremely large antenna arrays (ELAAs) operating in high-frequency bands have
spurred the development of near-field communication, driving advancements in
beam training and signal processing design. In this work, we present a
low-complexity near-field beam training scheme that fully utilizes the
conventional discrete Fourier transform (DFT) codebook designed for far-field
users. We begin by analyzing the received beam pattern in the near field and
derive closed-form expressions for the beam width and central gain. These
analytical results enable the definition of an angle-dependent, modified
Rayleigh distance, which effectively distinguishes near-field and far-field
user regimes. Building on the analysis, we develop a direct and computationally
efficient method to estimate user distance, with a complexity of O(1), and
further improve its accuracy through a simple refinement. Simulation results
demonstrate significant gains in both single- and multi-user settings, with up
to 2.38 dB SNR improvement over exhaustive search. To further enhance
estimation accuracy, we additionally propose a maximum likelihood estimation
(MLE) based refinement method, leveraging the Rician distribution of signal
amplitudes and achieving accuracy close to the Cramer--Rao bound (CRB).
Simulation shows the single-user and multi-user achievable rates can both
approach those obtained with ideal channel state information.

</details>


### [2] [Physical Limits of Entanglement-Based Quantum Key Distribution over Long-Distance Satellite Links](https://arxiv.org/abs/2506.20798)
*Mohammad Taghi Dabiri,Mazen Hasna,Saif Al-Kuwari,Khalid Qaraqe*

Main category: eess.SP

TL;DR: 论文分析了基于纠缠态的卫星间量子密钥分发（QKD）协议在实际自由空间光通信中的性能挑战，提出了光子级模型和关键参数分析。


<details>
  <summary>Details</summary>
Motivation: 现有文献未解决长距离卫星间自由空间光通信中的物理层挑战，如光子损耗和背景噪声对密钥生成率和量子比特错误率的影响。

Method: 开发了信号检测概率、背景光子影响、多对发射和QBER的解析表达式，结合链路距离、发射器抖动等参数进行建模。

Result: 仿真结果表明系统性能对跟踪误差和视场限制高度敏感，并确定了同时最大化密钥率和控制QBER的最优参数范围。

Conclusion: 模型为可靠高效部署基于纠缠态的卫星QKD系统提供了设计指导。

Abstract: Entanglement-based quantum key distribution (QKD) protocols, such as E91 and
BBM92, offer strong information-theoretic security and are naturally suited for
satellite-to-satellite QKD (SatQKD) links. However, implementing these
protocols over long-distance inter-satellite free-space optical (FSO) channels
poses critical physical-layer challenges that are not addressed in the existing
literature. In particular, photon losses due to beam divergence, pointing
errors, and background noise can severely degrade the key generation rate and
quantum bit error rate (QBER), especially under narrow receiver field-of-view
(FoV) constraints. This paper presents a comprehensive performance analysis of
entanglement-based inter-satellite QKD, focusing on photon-level modeling and
the impact of practical impairments. We develop analytical expressions for
signal detection probabilities, background photon influence, multi-pair
emissions, and QBER, incorporating key parameters such as link distance,
transmitter tracking jitter, receiver misalignment, and photon pair generation
rate. Simulation results reveal the nonlinear sensitivity of system performance
to tracking error and FoV limitations, and highlight optimal parameter regimes
that jointly maximize secret key rate while maintaining QBER below acceptable
thresholds. The proposed model provides actionable design insights for reliable
and efficient deployment of entanglement-based SatQKD systems.

</details>


### [3] [Compact Analytical Model for Real-Time Evaluation of OAM-Based Inter-Satellite Links](https://arxiv.org/abs/2506.20823)
*Mohammad Taghi Dabiri,Mazen Hasna*

Main category: eess.SP

TL;DR: 提出了一种高效分析框架，用于评估轨道角动量（OAM）光束在指向误差下的卫星间通信性能，通过解析模型减少计算时间并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 传统蒙特卡洛方法计算量大，无法满足动态低地球轨道（LEO）卫星网络实时优化的需求。

Method: 开发了描述OAM光束对准误差的解析模型，推导了比特误码率（BER）的高效表达式，并设计了非对称OAM模式集。

Result: 提出的方法显著减少了计算时间，同时保持高精度，非对称OAM模式集在指向误差下表现优于对称配置。

Conclusion: 该框架为高移动性光无线系统（如LEO卫星网络）提供了实时优化的可行性，并通过蒙特卡洛仿真验证了其准确性。

Abstract: This paper presents an efficient analytical framework for evaluating the
performance of inter-satellite communication systems utilizing orbital angular
momentum (OAM) beams under pointing errors. An accurate analytical model is
first developed to characterize intermodal crosstalk caused by beam
misalignment in OAM-based inter-satellite links. Building upon this model, we
derive efficient expressions to analyze and optimize system performance in
terms of bit error rate (BER). Unlike traditional Monte Carlo-based methods
that are computationally intensive, the proposed approach offers accurate
performance predictions. This enables a substantial decrease in computation
time while maintaining high accuracy, thanks to the use of analytical
expressions for both crosstalk and BER. This fast and accurate evaluation
capability is particularly critical for dynamic low Earth orbit (LEO) satellite
constellations, where network topology and channel conditions change rapidly,
requiring real-time link adaptation. Furthermore, we systematically design and
evaluate asymmetric OAM mode sets, which significantly outperform symmetric
configurations in the presence of pointing errors. Our results also reveal key
insights into the interaction between beam divergence, tracking accuracy, and
link distance, demonstrating that the proposed framework enables real-time
optimization of system parameters with high fidelity. The analytical findings
are rigorously validated against extensive Monte Carlo simulations, confirming
their practical applicability for high-mobility optical wireless systems such
as LEO satellite networks.

</details>


### [4] [Doppler Estimation and Compensation Techniques in LoRa Direct-to-Satellite Communications](https://arxiv.org/abs/2506.20858)
*Jamil Farhat,Gianni Pasolini,Enrico Paolini,Muhammad Asad Ullah,Richard Demo Souza*

Main category: eess.SP

TL;DR: 论文提出四种多普勒效应估计与补偿框架，用于提升LoRa DtS连接性能，并通过数值比较分析了其与理想场景的差异。


<details>
  <summary>Details</summary>
Motivation: LEO卫星的多普勒效应对LoRa DtS连接性能有显著负面影响，需研究补偿方法以提升性能。

Method: 提出四种多普勒估计与补偿框架，并通过数值模拟比较其性能。

Result: 分析了不同框架下扩频因子等参数与多普勒效应的权衡关系，为优化LoRa配置提供依据。

Conclusion: 研究为LoRa DtS连接提供了鲁棒性配置的指导，解决了多普勒效应带来的性能问题。

Abstract: Within the LPWAN framework, the LoRa modulation adopted by LoRaWAN technology
has garnered significant interest as a connectivity solution for IoT
applications due to its ability to offer low-cost, low-power, and long-range
communications. One emerging use case of LoRa is DtS connectivity, which
extends coverage to remote areas for supporting IoT operations. The satellite
IoT industry mainly prefers LEO because it has lower launch costs and less path
loss compared to Geostationary orbit. However, a major drawback of LEO
satellites is the impact of the Doppler effect caused by their mobility.
Earlier studies have confirmed that the Doppler effect significantly degrades
the LoRa DtS performance. In this paper, we propose four frameworks for Doppler
estimation and compensation in LoRa DtS connectivity and numerically compare
the performance against the ideal scenario without the Doppler effect.
Furthermore, we investigate the trade-offs among these frameworks by analyzing
the interplay between spreading factor, and other key parameters related to the
Doppler effect. The results provide insights into how to achieve robust LoRa
configurations for DtS connectivity.

</details>


### [5] [Quantum-Accelerated Wireless Communications: Concepts, Connections, and Implications](https://arxiv.org/abs/2506.20863)
*Naoki Ishikawa,Giuseppe Thadeu Freitas de Abreu,Petar Popovski,Robert W. Heath Jr*

Main category: eess.SP

TL;DR: 量子计算有望重新定义通信系统的算法基础，但目前确定其实际工程优势仍具挑战。本文介绍了量子计算的基础知识，揭示了量子与无线系统之间的数学和谐，并总结了量子加速通信系统的设计趋势。


<details>
  <summary>Details</summary>
Motivation: 探索量子计算在通信系统中的潜在优势，并促进量子信息处理与未来通信系统的跨学科研究。

Method: 通过系统回顾前沿研究，总结量子加速通信系统的设计趋势，并分析经典启发式方法如何优化量子参数。

Result: 揭示了量子与无线系统之间的数学和谐，强调了经典与量子计算的互补优势。

Conclusion: 本文旨在激发量子信息处理与未来通信系统前沿的跨学科研究。

Abstract: Quantum computing is poised to redefine the algorithmic foundations of
communication systems. While quantum superposition and entanglement enable
quadratic or exponential speedups for specific problems, identifying use cases
where these advantages yield engineering benefits is, however, still
nontrivial. This article presents the fundamentals of quantum computing in a
style familiar to the communications society, outlining the current limits of
fault-tolerant quantum computing and uncovering a mathematical harmony between
quantum and wireless systems, which makes the topic more enticing to wireless
researchers. Based on a systematic review of pioneering and state-of-the-art
studies, we distill common design trends for the research and development of
quantum-accelerated communication systems and highlight lessons learned. The
key insight is that classical heuristics can sharpen certain quantum
parameters, underscoring the complementary strengths of classical and quantum
computing. This article aims to catalyze interdisciplinary research at the
frontier of quantum information processing and future communication systems.

</details>


### [6] [Co-Design of Sensing, Communications, and Control for Low-Altitude Wireless Networks](https://arxiv.org/abs/2506.20970)
*Haijia Jin,Jun Wu,Weijie Yuan,Fan Liu,Yuanhao Cui*

Main category: eess.SP

TL;DR: 该论文研究了多无人机协同系统中集成感知、通信和控制的联合设计，提出了一种基于交替优化的非凸问题求解方法，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着物联网服务和6G技术的发展，无人机在低空无线网络中的作用日益重要，需要解决多无人机协同系统中的感知、通信和控制联合优化问题。

Method: 通过联合考虑控制性能（LQR成本）和定位性能（Fisher信息矩阵行列式），提出了一种基于交替优化（AO）的非凸问题分解方法，结合DC编程和PGD方法求解。

Result: 仿真结果表明，所提方法在控制与感知性能之间取得了有效平衡，优于基准方案。

Conclusion: 该研究为多无人机协同系统的集成设计提供了高效解决方案，揭示了控制与感知性能之间的权衡关系。

Abstract: The rapid advancement of Internet of Things (IoT) services and the evolution
toward the sixth generation (6G) have positioned unmanned aerial vehicles
(UAVs) as critical enablers of low-altitude wireless networks (LAWNs). This
work investigates the co-design of integrated sensing, communication, and
control ($\mathbf{SC^{2}}$) for multi-UAV cooperative systems with finite
blocklength (FBL) transmission. In particular, the UAVs continuously monitor
the state of the field robots and transmit their observations to the robot
controller to ensure stable control while cooperating to localize an unknown
sensing target (ST). To this end, a weighted optimization problem is first
formulated by jointly considering the control and localization performance in
terms of the linear quadratic regulator (LQR) cost and the determinant of the
Fisher information matrix (FIM), respectively. The resultant problem,
optimizing resource allocations, the UAVs' deployment positions, and multi-user
scheduling, is non-convex. To circumvent this challenge, we first derive a
closed-form expression of the LQR cost with respect to other variables.
Subsequently, the non-convex optimization problem is decomposed into a series
of sub-problems by leveraging the alternating optimization (AO) approach, in
which the difference of convex functions (DC) programming and projected
gradient descent (PGD) method are employed to obtain an efficient near-optimal
solution. Furthermore, the convergence and computational complexity of the
proposed algorithm are thoroughly analyzed. Extensive simulation results are
presented to validate the effectiveness of our proposed approach compared to
the benchmark schemes and reveal the trade-off between control and sensing
performance.

</details>


### [7] [Analysis of Null Related Beampattern Measures and Signal Quantization Effects for Linear Differential Microphone Arrays](https://arxiv.org/abs/2506.21043)
*Shweta Pal,Arun Kumar,Monika Agrawal*

Main category: eess.SP

TL;DR: 本文提出了一种评估差分麦克风阵列（DMA）零陷效用的新方法，包括零陷深度（ND）和零陷宽度（NW），并研究了量化效应对不同阶数DMA的影响。


<details>
  <summary>Details</summary>
Motivation: 现有文献缺乏直接评估DMA零陷效用的方法，本文旨在填补这一空白。

Method: 提出ND和NW作为评估指标，研究量化效应对不同阶数DMA的影响，并通过仿真和实验验证。

Result: 仿真和实验结果表明，量化位数和深度水平对ND和NW有显著影响，实验验证了零陷深度的有效性。

Conclusion: 本文提出的方法有效评估了DMA的零陷特性，为实际应用提供了理论支持。

Abstract: A differential microphone array (DMA) offers enhanced capabilities to obtain
sharp nulls at the cost of relatively broad peaks in the beam power pattern.
This can be used for applications that require nullification or attenuation of
interfering sources. To the best of our knowledge, the existing literature
lacks measures that directly assess the efficacy of nulls, and null-related
measures have not been investigated in the context of differential microphone
arrays (DMAs). This paper offers new insights about the utility of DMAs by
proposing measures that characterize the nulls in their beam power patterns. We
investigate the performance of differential beamformers by presenting and
evaluating null-related measures namely null depth (ND) and Null Width (NW) as
a function of depth level relative to the beam power pattern maxima. A study of
signal quantization effects due to data acquisition for 1st, 2nd and 3rd order
linear DMAs and for different beampatterns i.e. dipole, cardioid, hypercardioid
and supercardioid is presented. An analytical expression for the quantized
beamformed output for any general $ N^{th} $ order DMA is formulated.
Simulation results of the variation of ND with number of quantization bits and
the variation of NW as a function of depth are also presented and inferences
are drawn. Lab experiments are conducted in a fully anechoic room to support
the simulation results. The measured beampattern exhibits a pronounced null
depth, confirming the effectiveness of the experimental setup.

</details>


### [8] [Point Cloud Environment-Based Channel Knowledge Map Construction](https://arxiv.org/abs/2506.21112)
*Yancheng Wang,Wei Guo,Guanying Chen,Ye Zhang,Shuguang Cui*

Main category: eess.SP

TL;DR: 本文提出了一种联合模型和数据驱动的方法，利用点云环境数据和少量位置标记的信道信息构建信道知识地图（CKM），显著提高了准确性。


<details>
  <summary>Details</summary>
Motivation: 现有CKM构建方案过于简化环境信息，导致准确性不足。本文旨在通过结合点云数据和信道信息，提升CKM的构建精度。

Method: 提出了一种基于时间到达（ToA）的共焦椭球体点选择器，筛选与多径信道增益相关的点云子集，并训练神经网络估计信道增益。

Result: 实验结果显示，该方法在功率延迟剖面（PDP）和接收功率值（无线电地图）的CKM构建中，均显著优于传统方法。

Conclusion: 联合模型和数据驱动的方法有效提升了CKM构建的准确性，为环境感知通信提供了更可靠的支撑。

Abstract: Channel knowledge map (CKM) provides certain levels of channel state
information (CSI) for an area of interest, serving as a critical enabler for
environment-aware communications by reducing the overhead of frequent CSI
acquisition. However, existing CKM construction schemes adopt over-simplified
environment information, which significantly compromises their accuracy. To
address this issue, this work proposes a joint model- and data-driven approach
to construct CKM by leveraging point cloud environmental data along with a few
samples of location-tagged channel information. First, we propose a novel point
selector to identify subsets of point cloud that contain environmental
information relevant to multipath channel gains, by constructing a set of
co-focal ellipsoids based on different time of arrival (ToAs). Then, we trained
a neural channel gain estimator to learn the mapping between each selected
subset and its corresponding channel gain, using a real-world dataset we
collected through field measurements, comprising environmental point clouds and
corresponding channel data. Finally, experimental results demonstrate that: For
CKM construction of power delay profile (PDP), the proposed method achieves a
root mean squared error (RMSE) of 2.95 dB, significantly lower than the 7.32 dB
achieved by the conventional ray-tracing method; for CKM construction of
received power values, i.e., radio map, it achieves an RMSE of 1.04 dB,
surpassing the Kriging interpolation method with an RMSE of 1.68 dB.

</details>


### [9] [Characterization of Rydberg-Atom Signal Reception of Dual-Frequency Signals Coupled with Two Energy Levels](https://arxiv.org/abs/2506.21123)
*Hao Wu,Chongwu Xie,Xinyuan Yao,Kang-Da Wu,Shanchi Wu,Rui Ni,Guo-Yong Xiang,Chen Gong*

Main category: eess.SP

TL;DR: 分析了Rydberg原子传感器在多频信号接收中的互干扰特性，提出了联合响应系数，并通过实验验证了误码率和符号错误率。


<details>
  <summary>Details</summary>
Motivation: Rydberg原子传感器在多用户通信中具有潜力，但多频信号的非正交性会导致互干扰，需研究其特性。

Method: 通过联合响应系数分析两信号干扰，计算BER和SER，并进行实验验证。

Result: 实验验证了BER和SER的理论分析结果。

Conclusion: 研究为Rydberg原子传感器在多频信号接收中的互干扰问题提供了理论支持和实验验证。

Abstract: Rydberg atomic sensors have been adopted for novel radio frequency (RF)
measurement technique and the sensing capability for signals in multiple
frequencies makes it attractive for multi-user communication. However, unlike
traditional antennas where the signals in multiple frequencies are orthogonal,
the received signals of atomic sensors corresponding to different energy levels
will be downconverted to the baseband simultaneously, resulting in multi-user
interference. Thus, in this paper, we analyze the mutual interference
characteristics of two RF signals with different carrier frequencies coupling
different energy levels. We introduce the joint response coefficient based on
the receiver characteristics and analyze the interference of one user to
another. We analyze the bit-error rate (BER) and symbol-error rate (SER) for
two signals coupling two different energy levels. We also conduct experiments
to validate the BER and SER results.

</details>


### [10] [Adversarial Training: Enhancing Out-of-Distribution Generalization for Learning Wireless Resource Allocation](https://arxiv.org/abs/2506.21208)
*Shengjie Liu,Chenyang Yang*

Main category: eess.SP

TL;DR: 论文提出了一种基于对抗训练的方法，用于提升无监督训练的深度神经网络在分布外数据上的泛化能力，并在混合预编码优化中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在资源分配中广泛应用，但其性能易受训练与测试数据分布差异的影响，因此需要提升其在分布外数据上的泛化能力。

Method: 通过重新设计对抗训练方法以捕捉分布外性能下降，并提出一种一步梯度上升的对抗训练方法。

Result: 实验结果表明，该方法在仅使用瑞利衰落信道进行训练的情况下，显著提升了多种深度神经网络在不同信道分布下的分布外性能。

Conclusion: 该方法有效增强了深度神经网络在分布外数据上的泛化能力，为资源分配优化提供了新思路。

Abstract: Deep neural networks (DNNs) have widespread applications for optimizing
resource allocation. Yet, their performance is vulnerable to distribution
shifts between training and test data, say channels. In this letter, we resort
to adversarial training (AT) for enhancing out-of-distribution (OOD)
generalizability of DNNs trained in unsupervised manner. We reformulate AT to
capture the OOD degradation, and propose a one-step gradient ascent method for
AT. The proposed method is validated by optimizing hybrid precoding. Simulation
results showcase the enhanced OOD performance of multiple kinds of DNNs across
various channel distributions, when only Rayleigh fading channels are used for
training.

</details>


### [11] [Localization-Based Beam Focusing in Near-Field Communications](https://arxiv.org/abs/2506.21325)
*Nima Mozaffarikhosravi,Prathapasinghe Dharmawansa,Italo Atzeni*

Main category: eess.SP

TL;DR: 论文提出了一种基于定位的波束聚焦策略，利用毫米波和亚太赫兹频段的主导视距传播，并通过2D-MUSIC算法进行距离估计，与零强迫方法相比，在特定条件下更有效。


<details>
  <summary>Details</summary>
Motivation: 随着6G及更高频段无线通信系统的应用，近场区域的扩展影响了波束成形和用户定位方案，需要新的解决方案。

Method: 提出基于定位的波束聚焦策略，利用2D-MUSIC算法进行距离估计，并与零强迫方法进行比较。

Result: 数值结果表明，在视距传播主导、短相干块和高噪声功率条件下，所提方法更有效。

Conclusion: 基于定位的波束聚焦策略在高频段和大带宽场景下具有优势。

Abstract: Shifting 6G-and-beyond wireless communication systems to higher frequency
bands and the utilization of massive multiple-input multiple-output arrays will
extend the near-field region, affecting beamforming and user localization
schemes. In this paper, we propose a localization-based beam-focusing strategy
that leverages the dominant line-of-sight (LoS) propagation arising at mmWave
and sub-THz frequencies. To support this approach, we analyze the 2D-MUSIC
algorithm for distance estimation by examining its spectrum in simplified,
tractable setups with minimal numbers of antennas and users. Lastly, we compare
the proposed localization-based beam focusing, with locations estimated via
2D-MUSIC, with zero forcing with pilot-based channel estimation in terms of
uplink sum spectral efficiency. Our numerical results show that the proposed
method becomes more effective under LoS-dominated propagation, short coherence
blocks, and strong noise power arising at high carrier frequencies and with
large bandwidths.

</details>


### [12] [Integrating Movable Antennas and Intelligent Reflecting Surfaces for Coverage Enhancement](https://arxiv.org/abs/2506.21375)
*Ying Gao,Qingqing Wu,Weidong Mei,Guangji Chen,Wen Chen,Ziyuan Zheng*

Main category: eess.SP

TL;DR: 本文研究了IRS辅助的MA系统，通过联合优化MA位置、IRS反射系数和发射波束成形，最大化目标区域内的最差SNR，并提出三种覆盖增强方案。


<details>
  <summary>Details</summary>
Motivation: 扩展无线覆盖范围至多个目标区域，同时平衡性能与成本。

Method: 提出三种覆盖增强方案（area-adaptive MA-IRS、area-adaptive MA-staIRS、shared MA-staIRS）及通用算法框架。

Result: MA方案优于FPA方案，area-adaptive MA-IRS表现最佳；增加天线数可改善MA-staIRS性能；MA与IRS元素的最优比例与成本比成反比。

Conclusion: MA系统在覆盖增强方面具有潜力，但需权衡天线数量与成本。

Abstract: This paper investigates an intelligent reflecting surface (IRS)-aided movable
antenna (MA) system, where multiple IRSs cooperate with a multi-MA base station
to extend wireless coverage to multiple designated target areas. The objective
is to maximize the worst-case signal-to-noise ratio (SNR) across all locations
within these areas through joint optimization of MA positions, IRS reflection
coefficients, and transmit beamforming. To achieve this while balancing the
performance-cost trade-off, we propose three coverage-enhancement schemes: the
area-adaptive MA-IRS scheme, the area-adaptive MA-staIRS scheme, and the shared
MA-staIRS scheme, where staIRS denotes static IRSs with reflection coefficients
configured only once during installation. These schemes lead to challenging
non-convex optimization problems with implicit objective functions, which are
difficult to solve optimally. To address these problems, we propose a general
algorithmic framework that can be applied to solve each problem efficiently
albeit suboptimally. Simulation results demonstrate that: 1) the proposed
MA-based schemes consistently outperform their fixed-position antenna
(FPA)-based counterparts under both area-adaptive and static IRS
configurations, with the area-adaptive MA-IRS scheme achieving the best
worst-case SNR performance; 2) as transmit antennas are typically far fewer
than IRS elements, the area-adaptive MA-staIRS scheme may underperform the
baseline FPA scheme with area-adaptive IRSs in terms of the worst-case SNR, but
a modest increase in antenna number can reverse this trend; 3) under a fixed
total cost, the optimal MA-to-IRS-element ratio for the worst-case SNR
maximization is empirically found to be proportional to the reciprocal of their
unit cost ratio.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [13] [CodecSlime: Temporal Redundancy Compression of Neural Speech Codec via Dynamic Frame Rate](https://arxiv.org/abs/2506.21074)
*Hankun Wang,Yiwei Guo,Chongtian Shao,Bohan Li,Xie Chen,Kai Yu*

Main category: eess.AS

TL;DR: CodecSlime提出了一种动态帧率（DFR）的神经语音编解码器插件方法，通过减少冗余信息显著提升压缩效率。


<details>
  <summary>Details</summary>
Motivation: 当前固定帧率（FFR）编解码器在信息密度不均匀的语音中存在冗余，浪费资源。

Method: 结合ScheDFR和Melt-and-Cool技术，实现无监督、架构无关的动态帧率支持。

Result: 在40 Hz DFR下，重建WER相对FFR降低46%，同时支持多帧率灵活推理。

Conclusion: CodecSlime在压缩效率和重建质量上优于传统FFR方法，具有灵活性和高效性。

Abstract: Neural speech codecs have been widely used in audio compression and various
downstream tasks. Current mainstream codecs are fixed-frame-rate (FFR), which
allocate the same number of tokens to every equal-duration slice. However,
speech is inherently non-uniform in temporal information density. As a result,
many tokens are wasted on steady-state segments like long vowels and silences.
To address this mismatch, we present CodecSlime, a plugin-style method for
compressing temporal redundancy through supporting dynamic frame rate (DFR) on
neural speech codecs for the first time. Our method is unsupervised and
architecture-agnostic, combining two key innovations, ScheDFR and
Melt-and-Cool, for adapting inference and training, respectively. When
integrated into a typical VQ-GAN codec backbone and operating at 40 Hz DFR
($\approx$ 600 bps), the reconstruction WER of CodecSlime is reduced by up to
46% relative to conventional FFR baselines with the same model architecture and
similar bitrates, while other metrics are also competitive. CodecSlime also
enables flexible trade-offs between reconstruction quality and bitrate: a
single model supports inference at multiple frame rates and consistently
outperforms FFR models at the corresponding frame rates. Audio samples are
available at https://acadarmeria.github.io/codecslime/.

</details>


### [14] [Post-training for Deepfake Speech Detection](https://arxiv.org/abs/2506.21090)
*Wanying Ge,Xin Wang,Xuechen Liu,Junichi Yamagishi*

Main category: eess.AS

TL;DR: 提出了一种后训练方法，通过弥合通用预训练与领域特定微调之间的差距，将自监督学习模型用于深度伪造语音检测。


<details>
  <summary>Details</summary>
Motivation: 解决自监督学习模型在深度伪造语音检测中通用预训练与领域特定任务之间的差距问题。

Method: 使用大规模多语言语音数据集（含5.6万小时真实语音和1.8万小时含人工痕迹的语音）进行后训练，生成AntiDeepfake模型。

Result: 后训练模型在未见过的深度伪造语音上表现出强鲁棒性和泛化能力，进一步微调后性能超越现有最佳检测器。

Conclusion: 后训练方法显著提升了深度伪造语音检测的性能，模型和代码已开源。

Abstract: We introduce a post-training approach that adapts self-supervised learning
(SSL) models for deepfake speech detection by bridging the gap between general
pre-training and domain-specific fine-tuning. We present AntiDeepfake models, a
series of post-trained models developed using a large-scale multilingual speech
dataset containing over 56,000 hours of genuine speech and 18,000 hours of
speech with various artifacts in over one hundred languages. Experimental
results show that the post-trained models already exhibit strong robustness and
generalization to unseen deepfake speech. When they are further fine-tuned on
the Deepfake-Eval-2024 dataset, these models consistently surpass existing
state-of-the-art detectors that do not leverage post-training. Model
checkpoints and source code are available online.

</details>


### [15] [Performance improvement of spatial semantic segmentation with enriched audio features and agent-based error correction for DCASE 2025 Challenge Task 4](https://arxiv.org/abs/2506.21174)
*Jongyeon Park,Joonhee Lee,Do-Hyeon Lim,Hong Kook Kim,Hyeongcheol Geum,Jeong Eun Lim*

Main category: eess.AS

TL;DR: 该技术报告介绍了DCASE 2025挑战赛任务4的提交系统，通过加入额外音频特征和改进标签校正系统，显著提升了音频分类性能。


<details>
  <summary>Details</summary>
Motivation: 混合音频中的细微线索难以仅通过梅尔频谱捕捉，因此需要额外特征提供更多视角。

Method: 结合频谱滚降和色度特征，应用基于代理的标签校正系统，并优化训练数据集。

Result: 实验表明，该系统将CA-SDRi指标相对提升了14.7%。

Conclusion: 该方法有效提升了音频分类性能，尤其在复杂场景中表现优异。

Abstract: This technical report presents submission systems for Task 4 of the DCASE
2025 Challenge. This model incorporates additional audio features (spectral
roll-off and chroma features) into the embedding feature extracted from the
mel-spectral feature to im-prove the classification capabilities of an
audio-tagging model in the spatial semantic segmentation of sound scenes (S5)
system. This approach is motivated by the fact that mixed audio often contains
subtle cues that are difficult to capture with mel-spectrograms alone. Thus,
these additional features offer alterna-tive perspectives for the model.
Second, an agent-based label correction system is applied to the outputs
processed by the S5 system. This system reduces false positives, improving the
final class-aware signal-to-distortion ratio improvement (CA-SDRi) metric.
Finally, we refine the training dataset to enhance the classi-fication accuracy
of low-performing classes by removing irrele-vant samples and incorporating
external data. That is, audio mix-tures are generated from a limited number of
data points; thus, even a small number of out-of-class data points could
degrade model performance. The experiments demonstrate that the submit-ted
systems employing these approaches relatively improve CA-SDRi by up to 14.7%
compared to the baseline of DCASE 2025 Challenge Task 4.

</details>


### [16] [Hybrid Deep Learning and Signal Processing for Arabic Dialect Recognition in Low-Resource Settings](https://arxiv.org/abs/2506.21386)
*Ghazal Al-Shwayyat,Omer Nezih Gerek*

Main category: eess.AS

TL;DR: 研究探索了结合信号处理与深度学习的混合模型，用于低资源阿拉伯方言识别，MFCC+CNN表现优于DWT+RNN。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯方言识别因语言多样性和标注数据稀缺而具挑战性，尤其在低资源场景下。

Method: 开发了两种混合模型：MFCC+CNN和DWT+RNN，并在Common Voice阿拉伯数据集上评估。

Result: MFCC+CNN准确率达91.2%，显著优于DWT+RNN的66.5%。

Conclusion: 研究为低资源阿拉伯方言识别提供了基线，建议未来采用更大数据集和自监督学习。

Abstract: Arabic dialect recognition presents a significant challenge in speech
technology due to the linguistic diversity of Arabic and the scarcity of large
annotated datasets, particularly for underrepresented dialects. This research
investigates hybrid modeling strategies that integrate classical signal
processing techniques with deep learning architectures to address this problem
in low-resource scenarios. Two hybrid models were developed and evaluated: (1)
Mel-Frequency Cepstral Coefficients (MFCC) combined with a Convolutional Neural
Network (CNN), and (2) Discrete Wavelet Transform (DWT) features combined with
a Recurrent Neural Network (RNN). The models were trained on a dialect-filtered
subset of the Common Voice Arabic dataset, with dialect labels assigned based
on speaker metadata. Experimental results demonstrate that the MFCC + CNN
architecture achieved superior performance, with an accuracy of 91.2% and
strong precision, recall, and F1-scores, significantly outperforming the
Wavelet + RNN configuration, which achieved an accuracy of 66.5%. These
findings highlight the effectiveness of leveraging spectral features with
convolutional models for Arabic dialect recognition, especially when working
with limited labeled data. The study also identifies limitations related to
dataset size, potential regional overlaps in labeling, and model optimization,
providing a roadmap for future research. Recommendations for further
improvement include the adoption of larger annotated corpora, integration of
self-supervised learning techniques, and exploration of advanced neural
architectures such as Transformers. Overall, this research establishes a strong
baseline for future developments in Arabic dialect recognition within
resource-constrained environments.

</details>


### [17] [ThinkSound: Chain-of-Thought Reasoning in Multimodal Large Language Models for Audio Generation and Editing](https://arxiv.org/abs/2506.21448)
*Huadai Liu,Jialei Wang,Kaicheng Luo,Wen Wang,Qian Chen,Zhou Zhao,Wei Xue*

Main category: eess.AS

TL;DR: ThinkSound是一个基于Chain-of-Thought推理的框架，通过分阶段生成和编辑视频音频，结合多模态大语言模型和音频基础模型，显著提升了音频生成的质量和真实性。


<details>
  <summary>Details</summary>
Motivation: 当前端到端的视频到音频生成方法难以捕捉视觉内容的细微差别，需要更复杂的推理能力来模拟专业创作过程。

Method: ThinkSound将音频生成分为三个阶段：基础音效生成、交互式对象中心细化以及自然语言指导的编辑，利用多模态大语言模型生成上下文对齐的推理链。

Result: 实验表明，ThinkSound在音频生成和相关推理指标上达到最先进水平，并在Movie Gen Audio基准测试中表现优异。

Conclusion: ThinkSound通过分阶段推理和交互式编辑，显著提升了视频到音频生成的真实性和可控性。

Abstract: While end-to-end video-to-audio generation has greatly improved, producing
high-fidelity audio that authentically captures the nuances of visual content
remains challenging. Like professionals in the creative industries, such
generation requires sophisticated reasoning about items such as visual
dynamics, acoustic environments, and temporal relationships. We present
\textbf{ThinkSound}, a novel framework that leverages Chain-of-Thought (CoT)
reasoning to enable stepwise, interactive audio generation and editing for
videos. Our approach decomposes the process into three complementary stages:
foundational foley generation that creates semantically coherent soundscapes,
interactive object-centric refinement through precise user interactions, and
targeted editing guided by natural language instructions. At each stage, a
multimodal large language model generates contextually aligned CoT reasoning
that guides a unified audio foundation model. Furthermore, we introduce
\textbf{AudioCoT}, a comprehensive dataset with structured reasoning
annotations that establishes connections between visual content, textual
descriptions, and sound synthesis. Experiments demonstrate that ThinkSound
achieves state-of-the-art performance in video-to-audio generation across both
audio metrics and CoT metrics and excels in out-of-distribution Movie Gen Audio
benchmark. The demo page is available at https://ThinkSound-Demo.github.io.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [18] [A Multi-Stage Framework for Multimodal Controllable Speech Synthesis](https://arxiv.org/abs/2506.20945)
*Rui Niu,Weihao Wu,Jie Chen,Long Ma,Zhiyong Wu*

Main category: cs.SD

TL;DR: 提出一种三阶段多模态可控语音合成框架，解决现有方法在鲁棒性、多样性和细粒度控制上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于人脸的方法因数据质量限制难以泛化，文本提示方法多样性不足，多模态方法依赖完全匹配的训练数据。

Method: 采用三阶段框架，人脸编码器通过监督学习和知识蒸馏提升泛化能力，文本编码器结合文本-人脸和文本-语音数据增强多样性。

Result: 实验表明，该方法在基于人脸和文本提示的语音合成中均优于单模态基线方法。

Conclusion: 该框架能有效生成高质量语音，解决了多模态可控语音合成的关键挑战。

Abstract: Controllable speech synthesis aims to control the style of generated speech
using reference input, which can be of various modalities. Existing face-based
methods struggle with robustness and generalization due to data quality
constraints, while text prompt methods offer limited diversity and fine-grained
control. Although multimodal approaches aim to integrate various modalities,
their reliance on fully matched training data significantly constrains their
performance and applicability. This paper proposes a 3-stage multimodal
controllable speech synthesis framework to address these challenges. For face
encoder, we use supervised learning and knowledge distillation to tackle
generalization issues. Furthermore, the text encoder is trained on both
text-face and text-speech data to enhance the diversity of the generated
speech. Experimental results demonstrate that this method outperforms
single-modal baseline methods in both face based and text prompt based speech
synthesis, highlighting its effectiveness in generating high-quality speech.

</details>


### [19] [PeakNetFP: Peak-based Neural Audio Fingerprinting Robust to Extreme Time Stretching](https://arxiv.org/abs/2506.21086)
*Guillem Cortès-Sebastià,Benjamin Martin,Emilio Molina,Xavier Serra,Romain Hennequin*

Main category: cs.SD

TL;DR: PeakNetFP是一种基于频谱峰的神经音频指纹系统，结合了传统峰值方法和深度学习，性能优于传统方法，与NeuralFP相当，但更轻量高效。


<details>
  <summary>Details</summary>
Motivation: 传统音频指纹方法在处理时间拉伸音频时表现不佳，而现有深度学习方法（如NeuralFP）计算量大。PeakNetFP旨在结合两者的优势。

Method: 采用类似PointNet++的分层点特征提取技术，并使用对比学习进行训练。

Result: 在时间拉伸50%-200%的情况下，Top-1命中率超过90%，参数比NeuralFP少100倍，输入数据小11倍。

Conclusion: PeakNetFP为音频指纹技术提供了轻量高效的解决方案，结合了峰值方法的稀疏性和神经网络的适应性。

Abstract: This work introduces PeakNetFP, the first neural audio fingerprinting (AFP)
system designed specifically around spectral peaks. This novel system is
designed to leverage the sparse spectral coordinates typically computed by
traditional peak-based AFP methods. PeakNetFP performs hierarchical point
feature extraction techniques similar to the computer vision model PointNet++,
and is trained using contrastive learning like in the state-of-the-art deep
learning AFP, NeuralFP. This combination allows PeakNetFP to outperform
conventional AFP systems and achieves comparable performance to NeuralFP when
handling challenging time-stretched audio data. In extensive evaluation,
PeakNetFP maintains a Top-1 hit rate of over 90% for stretching factors ranging
from 50% to 200%. Moreover, PeakNetFP offers significant efficiency advantages:
compared to NeuralFP, it has 100 times fewer parameters and uses 11 times
smaller input data. These features make PeakNetFP a lightweight and efficient
solution for AFP tasks where time stretching is involved. Overall, this system
represents a promising direction for future AFP technologies, as it
successfully merges the lightweight nature of peak-based AFP with the
adaptability and pattern recognition capabilities of neural network-based
approaches, paving the way for more scalable and efficient solutions in the
field.

</details>


### [20] [A Hierarchical Deep Learning Approach for Minority Instrument Detection](https://arxiv.org/abs/2506.21167)
*Dylan Sechet,Francesca Bugiotti,Matthieu Kowalski,Edouard d'Hérouville,Filip Langiewicz*

Main category: cs.SD

TL;DR: 论文探讨了在音乐信息检索中识别乐器活动的重要性，提出了一种基于Hornbostel-Sachs分类的层次分类方法，并在MedleyDB数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决音乐信息检索中乐器活动识别的挑战，尤其是在细粒度标注有限的情况下，通过层次分类提升识别效果。

Method: 采用基于Hornbostel-Sachs分类的层次分类系统，结合多种策略将层次结构融入模型，并在MedleyDB数据集上进行评估。

Result: 展示了层次分类在粗粒度乐器检测上的可靠性，填补了细粒度识别与组级识别之间的差距。

Conclusion: 层次分类方法为音乐信息检索领域的进一步研究提供了新方向。

Abstract: Identifying instrument activities within audio excerpts is vital in music
information retrieval, with significant implications for music cataloging and
discovery. Prior deep learning endeavors in musical instrument recognition have
predominantly emphasized instrument classes with ample data availability.
Recent studies have demonstrated the applicability of hierarchical
classification in detecting instrument activities in orchestral music, even
with limited fine-grained annotations at the instrument level. Based on the
Hornbostel-Sachs classification, such a hierarchical classification system is
evaluated using the MedleyDB dataset, renowned for its diversity and richness
concerning various instruments and music genres. This work presents various
strategies to integrate hierarchical structures into models and tests a new
class of models for hierarchical music prediction. This study showcases more
reliable coarse-level instrument detection by bridging the gap between detailed
instrument identification and group-level recognition, paving the way for
further advancements in this domain.

</details>


### [21] [Integrating Vehicle Acoustic Data for Enhanced Urban Traffic Management: A Study on Speed Classification in Suzhou](https://arxiv.org/abs/2506.21269)
*Pengfei Fan,Yuli Zhang,Xinheng Wang,Ruiyuan Jiang,Hankang Gu,Dongyao Jia,Shangbo Wang*

Main category: cs.SD

TL;DR: 该研究公开了苏州城市道路声学数据集（SZUR-Acoustic Dataset），并提出了一种双模态特征融合深度卷积神经网络（BMCNN）来建模车辆噪声与行驶速度的耦合关系。实验表明BMCNN在两个数据集上表现优异，并验证了各模块对性能提升的贡献。


<details>
  <summary>Details</summary>
Motivation: 为智能城市交通管理系统提供实时噪声监测和速度估计方法，优化交通流量控制并减少路边噪声污染。

Method: 采用自适应去噪和归一化预处理，并行提取MFCC和小波包能量特征，并通过跨模态注意力机制融合特征。

Result: BMCNN在SZUR-Acoustic数据集上分类准确率为87.56%，在IDMT-Traffic数据集上为96.28%。消融实验验证了模块的有效性。

Conclusion: 该方法可集成到智能交通系统中，支持可持续城市规划和噪声污染控制。

Abstract: This study presents and publicly releases the Suzhou Urban Road Acoustic
Dataset (SZUR-Acoustic Dataset), which is accompanied by comprehensive
data-acquisition protocols and annotation guidelines to ensure transparency and
reproducibility of the experimental workflow. To model the coupling between
vehicular noise and driving speed, we propose a bimodal-feature-fusion deep
convolutional neural network (BMCNN). During preprocessing, an adaptive
denoising and normalization strategy is applied to suppress environmental
background interference; in the network architecture, parallel branches extract
Mel-frequency cepstral coefficients (MFCCs) and wavelet-packet energy features,
which are subsequently fused via a cross-modal attention mechanism in the
intermediate feature space to fully exploit time-frequency information.
Experimental results demonstrate that BMCNN achieves a classification accuracy
of 87.56% on the SZUR-Acoustic Dataset and 96.28% on the public IDMT-Traffic
dataset. Ablation studies and robustness tests on the Suzhou dataset further
validate the contributions of each module to performance improvement and
overfitting mitigation. The proposed acoustics-based speed classification
method can be integrated into smart-city traffic management systems for
real-time noise monitoring and speed estimation, thereby optimizing traffic
flow control, reducing roadside noise pollution, and supporting sustainable
urban planning.

</details>


### [22] [Exploring Adapter Design Tradeoffs for Low Resource Music Generation](https://arxiv.org/abs/2506.21298)
*Atharva Mehta,Shivam Chauhan,Monojit Choudhury*

Main category: cs.SD

TL;DR: 论文研究了在低资源音乐类型（如Hindustani古典和土耳其Makam音乐）中，如何通过参数高效微调（PEFT）技术优化MusicGen和Mustango模型的适配器设计，揭示了卷积和Transformer适配器在不同音乐特征上的表现差异，并分析了计算资源与性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 大规模音乐生成模型（如MusicGen和Mustango）的微调计算成本高，而参数高效微调（PEFT）技术（如适配器）可以低成本实现模型适应。然而，适配器的设计选择多样，缺乏对低资源音乐类型的优化指导。

Method: 研究比较了MusicGen和Mustango模型在Hindustani古典和土耳其Makam音乐上的不同适配器配置（如卷积和Transformer架构），分析其性能、计算资源需求和输出质量。

Result: 卷积适配器擅长捕捉局部音乐细节（如装饰音），而Transformer适配器更擅长保持长距离依赖（如即兴结构）。Mustango生成多样性高但稳定性差，MusicGen训练更快且质量更高。

Conclusion: 适配器设计需根据音乐特征选择，中规模适配器（40M参数）在表达力和质量间取得平衡。Mustango适合多样性需求，MusicGen适合高效高质量生成。

Abstract: Fine-tuning large-scale music generation models, such as MusicGen and
Mustango, is a computationally expensive process, often requiring updates to
billions of parameters and, therefore, significant hardware resources.
Parameter-Efficient Fine-Tuning (PEFT) techniques, particularly adapter-based
methods, have emerged as a promising alternative, enabling adaptation with
minimal trainable parameters while preserving model performance. However, the
design choices for adapters, including their architecture, placement, and size,
are numerous, and it is unclear which of these combinations would produce
optimal adapters and why, for a given case of low-resource music genre. In this
paper, we attempt to answer this question by studying various adapter
configurations for two AI music models, MusicGen and Mustango, on two genres:
Hindustani Classical and Turkish Makam music.
  Our findings reveal distinct trade-offs: convolution-based adapters excel in
capturing fine-grained local musical details such as ornamentations and short
melodic phrases, while transformer-based adapters better preserve long-range
dependencies crucial for structured improvisation. Additionally, we analyze
computational resource requirements across different adapter scales,
demonstrating how mid-sized adapters (40M parameters) achieve an optimal
balance between expressivity and quality. Furthermore, we find that Mustango, a
diffusion-based model, generates more diverse outputs with better adherence to
the description in the input prompt while lacking in providing stability in
notes, rhythm alignment, and aesthetics. Also, it is computationally intensive
and requires significantly more time to train. In contrast, autoregressive
models like MusicGen offer faster training and are more efficient, and can
produce better quality output in comparison, but have slightly higher
redundancy in their generations.

</details>


### [23] [Learnable Adaptive Time-Frequency Representation via Differentiable Short-Time Fourier Transform](https://arxiv.org/abs/2506.21440)
*Maxime Leiber,Yosra Marnissi,Axel Barrau,Sylvain Meignen,Laurent Massoulié*

Main category: cs.SD

TL;DR: 提出了一种可微分的短时傅里叶变换（STFT）方法，通过梯度优化参数，解决了传统方法依赖离散搜索的问题，并可无缝集成到神经网络中。


<details>
  <summary>Details</summary>
Motivation: 传统STFT参数调整依赖手动或启发式方法，效果不佳且计算量大，需要一种更高效的优化方式。

Method: 提出了一种统一的可微分STFT框架，支持基于梯度的参数优化，并可与其他网络权重联合优化。

Result: 实验证明，该方法能有效优化时频表示（TFR），并在下游任务中提升性能。

Conclusion: 可微分STFT为信号分析提供了更灵活和高效的参数优化方法，尤其在结合神经网络时表现突出。

Abstract: The short-time Fourier transform (STFT) is widely used for analyzing
non-stationary signals. However, its performance is highly sensitive to its
parameters, and manual or heuristic tuning often yields suboptimal results. To
overcome this limitation, we propose a unified differentiable formulation of
the STFT that enables gradient-based optimization of its parameters. This
approach addresses the limitations of traditional STFT parameter tuning
methods, which often rely on computationally intensive discrete searches. It
enables fine-tuning of the time-frequency representation (TFR) based on any
desired criterion. Moreover, our approach integrates seamlessly with neural
networks, allowing joint optimization of the STFT parameters and network
weights. The efficacy of the proposed differentiable STFT in enhancing TFRs and
improving performance in downstream tasks is demonstrated through experiments
on both simulated and real-world data.

</details>


### [24] [SmoothSinger: A Conditional Diffusion Model for Singing Voice Synthesis with Multi-Resolution Architecture](https://arxiv.org/abs/2506.21478)
*Kehan Sui,Jinxu Xiang,Fang Jin*

Main category: cs.SD

TL;DR: SmoothSinger是一种基于扩散模型的歌唱语音合成方法，通过统一框架直接优化低质量音频，避免了传统两阶段流程的失真问题。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像和视频生成中表现优异，但在歌唱语音合成中因复杂声学和音乐特性导致自然度下降。

Method: 采用参考引导的双分支架构，结合低频上采样路径，优化对齐训练中的时间失配问题。

Result: 在Opencpop数据集上，SmoothSinger在客观和主观评估中均达到最优效果。

Conclusion: SmoothSinger有效减少了合成语音的伪影，提升了自然度。

Abstract: Singing voice synthesis (SVS) aims to generate expressive and high-quality
vocals from musical scores, requiring precise modeling of pitch, duration, and
articulation. While diffusion-based models have achieved remarkable success in
image and video generation, their application to SVS remains challenging due to
the complex acoustic and musical characteristics of singing, often resulting in
artifacts that degrade naturalness. In this work, we propose SmoothSinger, a
conditional diffusion model designed to synthesize high quality and natural
singing voices. Unlike prior methods that depend on vocoders as a final stage
and often introduce distortion, SmoothSinger refines low-quality synthesized
audio directly in a unified framework, mitigating the degradation associated
with two-stage pipelines. The model adopts a reference-guided dual-branch
architecture, using low-quality audio from any baseline system as a reference
to guide the denoising process, enabling more expressive and context-aware
synthesis. Furthermore, it enhances the conventional U-Net with a parallel
low-frequency upsampling path, allowing the model to better capture pitch
contours and long term spectral dependencies. To improve alignment during
training, we replace reference audio with degraded ground truth audio,
addressing temporal mismatch between reference and target signals. Experiments
on the Opencpop dataset, a large-scale Chinese singing corpus, demonstrate that
SmoothSinger achieves state-of-the-art results in both objective and subjective
evaluations. Extensive ablation studies confirm its effectiveness in reducing
artifacts and improving the naturalness of synthesized voices.

</details>

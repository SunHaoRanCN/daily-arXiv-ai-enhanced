<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 31]
- [eess.AS](#eess.AS) [Total: 10]
- [cs.SD](#cs.SD) [Total: 23]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Biaxialformer: Leveraging Channel Independence and Inter-Channel Correlations in EEG Signal Decoding for Predicting Neurological Outcomes](https://arxiv.org/abs/2507.02879)
*Naimahmed Nesaragi,Hemin Ali Qadir,Per Steiner Halvorsen,Ilangko Balasingham*

Main category: eess.SP

TL;DR: Biaxialformer是一种基于Transformer的双阶段注意力框架模型，旨在同时捕捉EEG信号的时间和空间特征，解决了传统通道独立模型忽略通道间相关性的问题，并在预测昏迷患者神经学结果中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统基于Transformer的通道独立模型在多变量EEG信号中忽略了通道间相关性，导致信息丢失和预测准确性下降。

Method: 提出Biaxialformer模型，采用双阶段注意力框架，独立捕捉时间和空间特征，结合联合学习位置编码和可变感受野的标记化模块，并利用双极EEG信号增强空间特征提取。

Result: 在跨医院场景下，Biaxialformer的平均AUC为0.7688，AUPRC为0.8643，F1为0.6518，验证了其鲁棒性和泛化能力。

Conclusion: Biaxialformer通过同时建模时间和空间特征，显著提升了EEG信号解码的准确性，为神经学结果预测提供了新思路。

Abstract: Accurate decoding of EEG signals requires comprehensive modeling of both
temporal dynamics within individual channels and spatial dependencies across
channels. While Transformer-based models utilizing channel-independence (CI)
strategies have demonstrated strong performance in various time series tasks,
they often overlook the inter-channel correlations that are critical in
multivariate EEG signals. This omission can lead to information degradation and
reduced prediction accuracy, particularly in complex tasks such as neurological
outcome prediction. To address these challenges, we propose Biaxialformer,
characterized by a meticulously engineered two-stage attention-based framework.
This model independently captures both sequence-specific (temporal) and
channel-specific (spatial) EEG information, promoting synergy and mutual
reinforcement across channels without sacrificing CI. By employing joint
learning of positional encodings, Biaxialformer preserves both temporal and
spatial relationships in EEG data, mitigating the interchannel correlation
forgetting problem common in traditional CI models. Additionally, a
tokenization module with variable receptive fields balance the extraction of
fine-grained, localized features and broader temporal dependencies. To enhance
spatial feature extraction, we leverage bipolar EEG signals, which capture
inter-hemispheric brain interactions, a critical but often overlooked aspect in
EEG analysis. Our study broadens the use of Transformer-based models by
addressing the challenge of predicting neurological outcomes in comatose
patients. Using the multicenter I-CARE data from five hospitals, we validate
the robustness and generalizability of Biaxialformer with an average AUC
0.7688, AUPRC 0.8643, and F1 0.6518 in a cross-hospital scenario.

</details>


### [2] [Cross-Comparison of Neural Architectures and Data Sets for Digital Self-Interference Modeling](https://arxiv.org/abs/2507.03109)
*Gerald Enzner,Niklas Knaepper,Aleksej Chinaev*

Main category: eess.SP

TL;DR: 论文评估了不同神经网络模型在自干扰消除中的表现，发现Hammerstein模型在参数较少的情况下表现良好，而新的Wiener-Hammerstein模型进一步提升了泛化性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于评估不同神经网络模型在自干扰消除中的表现，尤其是在非设计数据上的泛化能力。

Method: 方法包括使用合成和真实数据对多种神经网络模型进行交叉比较，重点分析了Hammerstein和Wiener-Hammerstein模型。

Result: 结果显示，Hammerstein模型在参数较少的情况下表现良好，而Wiener-Hammerstein模型进一步提升了泛化性能。

Conclusion: 结论是Hammerstein模型在自干扰消除中具有高效性，而Wiener-Hammerstein模型在泛化能力上更优。

Abstract: Inband full-duplex communication requires accurate modeling and cancellation
of self-interference, specifically in the digital domain. Neural networks are
presently candidate models for capturing nonlinearity of the self-interference
path. This work utilizes synthetic and real data from different sources to
evaluate and cross-compare performances of previously proposed neural
self-interference models from different sources. The relevance of the analysis
consists in the mutual assessment of methods on data they were not specifically
designed for. We find that our previously proposed Hammerstein model represents
the range of data sets well, while being significantly smaller in terms of the
number of parameters. A new Wiener-Hammerstein model further enhances the
generalization performance.

</details>


### [3] [Enhancing Satellite Quantum Key Distribution with Dual Band Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2507.03246)
*Muhammad Khalil,Ke Wang,Jinho Choi*

Main category: eess.SP

TL;DR: 本文提出了一种新型混合卫星通信系统架构，结合量子密钥分发（QKD）和经典射频（RF）数据传输，通过双频段可重构智能表面（RIS）实现实时优化。


<details>
  <summary>Details</summary>
Motivation: 满足全球安全可靠通信的需求，利用量子光链的安全性和经典RF链的鲁棒性。

Method: 采用频率选择性RIS，实时独立优化量子（850 nm）和经典（S波段）信道，动态适应环境变化，如大气湍流和雨衰减。

Result: QBER从2.5%降至0.7%，SKR提升至每秒30,000比特以上，经典RF SNR在高仰角下增加约3 dB。

Conclusion: 混合RIS辅助卫星链路具有实现高效、安全全球通信的潜力。

Abstract: This paper presents a novel system architecture for hybrid satellite
communications, integrating quantum key distribution (QKD) and classical radio
frequency (RF) data transmission using a dual-band reconfigurable intelligent
surface (RIS). The motivation is to address the growing need for global,
secure, and reliable communications by leveraging the security of quantum
optical links and the robustness of classical RF channels within a unified
framework. By employing a frequency-selective RIS, the system independently
optimizes both quantum (850 nm) and classical (S-band) channels in real time,
dynamically adapting to environmental fluctuations such as atmospheric
turbulence and rain attenuation. The joint optimization of the quantum bit
error rate (QBER) and the classical signal-to noise ratio (SNR) is formulated
as a quadratic unconstrained binary optimization (QUBO) problem, enabling
efficient adaptive phase control utilizing both quantum and classical
computational methods. Comprehensive theoretical modeling and simulations,
benchmarked against experimental data from the Micius satellite, demonstrate
substantial performance gains. Notably, the RIS assisted system reduces QBER
from approximately 2.5% to 0.7%, increases the secure key rate (SKR) to over
30,000 bits per second, and enhances classical RF SNR by about 3 dB at high
elevation angles. These results illustrate the practical potential of hybrid
RIS-assisted satellite links to deliver robust, efficient, and secure global
communications.

</details>


### [4] [Specific Absorption Rate-Aware Multiuser MIMO Assisted by Fluid Antenna System](https://arxiv.org/abs/2507.03351)
*Yuqi Ye,Li You,Hao Xu,Ahmed Elzanaty,Kai-Kit Wong,Xiqi Gao*

Main category: eess.SP

TL;DR: 本文研究了6G网络中流体天线系统（FAS）的多用户MIMO通信，提出了一种SAR感知的两层迭代算法，以在满足SINR和FAS约束的同时最小化SAR值。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络的发展，需要创新技术满足更高性能指标，但电磁辐射（EM）的潜在危害引发担忧。

Method: 提出了一种SAR感知的两层迭代算法，优化SAR值并研究最小加权SINR最大化问题。

Result: 仿真结果表明，提出的SAR感知FAS设计优于自适应回退和固定位置天线设计。

Conclusion: SAR感知的FAS设计在6G网络中具有潜力，能有效平衡性能与辐射安全。

Abstract: With the development of the upcoming sixth-generation (6G) wireless networks,
there is a pressing need for innovative technologies capable of satisfying
heightened performance indicators. Fluid antenna system (FAS) is proposed
recently as a promising technique to achieve higher data rates and more
diversity gains by dynamically changing the positions of the antennas to form a
more desirable channel. However, worries regarding the possibly harmful effects
of electromagnetic (EM) radiation emitted by devices have arisen as a result of
the rapid evolution of advanced techniques in wireless communication systems.
Specific absorption rate (SAR) is a widely adopted metric to quantify EM
radiation worldwide. In this paper, we investigate the SAR-aware multiuser
multiple-input multiple-output (MIMO) communications assisted by FAS. In
particular, a two-layer iterative algorithm is proposed to minimize the SAR
value under signal-to-interference-plus-noise ratio (SINR) and FAS constraints.
Moreover, the minimum weighted SINR maximization problem under SAR and FAS
constraints is studied by finding its relationship with the SAR minimization
problem. Simulation results verify that the proposed SAR-aware FAS design
outperforms the adaptive backoff and fixed-position antenna designs.

</details>


### [5] [UWB TDoA Error Correction using Transformers: Patching and Positional Encoding Strategies](https://arxiv.org/abs/2507.03523)
*Dieter Coppens,Adnan Shahid,Eli De Poorter*

Main category: eess.SP

TL;DR: 论文提出了一种基于Transformer的TDoA定位校正方法，利用所有可用锚节点的原始CIR数据，在NLOS环境下显著提高了定位精度。


<details>
  <summary>Details</summary>
Motivation: 工业环境中多障碍物导致UWB定位系统因多径效应和NLOS条件而精度下降，现有方法排除NLOS链接导致几何精度稀释问题。

Method: 采用Transformer模型处理原始CIR数据，引入不同的CIR排序、分块和位置编码策略，分析其可扩展性和性能提升。

Result: 在几乎全为NLOS信号的复杂环境中，定位精度达到0.39米，比TDoA基线提高了73.6%。

Conclusion: 该方法在NLOS环境下显著提升了定位精度，解决了现有方法的局限性。

Abstract: Despite their high accuracy, UWB-based localization systems suffer
inaccuracies when deployed in industrial locations with many obstacles due to
multipath effects and non-line-of-sight (NLOS) conditions. In such
environments, current error mitigation approaches for time difference of
arrival (TDoA) localization typically exclude NLOS links. However, this
exclusion approach leads to geometric dilution of precision problems and this
approach is infeasible when the majority of links are NLOS. To address these
limitations, we propose a transformer-based TDoA position correction method
that uses raw channel impulse responses (CIRs) from all available anchor nodes
to compute position corrections. We introduce different CIR ordering, patching
and positional encoding strategies for the transformer, and analyze each
proposed technique's scalability and performance gains. Based on experiments on
real-world UWB measurements, our approach can provide accuracies of up to 0.39
m in a complex environment consisting of (almost) only NLOS signals, which is
an improvement of 73.6 % compared to the TDoA baseline.

</details>


### [6] [Implicit Neural Representation of Beamforming for Continuous Aperture Array (CAPA) System](https://arxiv.org/abs/2507.03609)
*Shiyong Chen,Jia Guo,Shengqian Han*

Main category: eess.SP

TL;DR: 提出了一种基于学习的连续孔径阵列（CAPA）系统下行链路波束成形优化方法，使用DNN（BeaINR和CoefINR）实现高效波束成形。


<details>
  <summary>Details</summary>
Motivation: CAPA系统中的波束成形需要高效优化，传统方法复杂度高，学习型方法有望提升性能。

Method: 提出BeaINR参数化波束成形函数，发现其最优解在信道函数子空间中，进而设计CoefINR学习加权系数。

Result: 仿真表明，基于INR的方法在频谱效率和推理时间上优于数值基线，CoefINR训练效率更高。

Conclusion: 学习型方法在CAPA系统中实现高效波束成形，CoefINR进一步降低复杂度。

Abstract: In this paper, a learning-based approach for optimizing downlink beamforming
in continuous aperture array (CAPA) systems is proposed, where a MIMO scenario
that both the base station (BS) and the user are equipped with CAPA is
considered. As the beamforming in the CAPA system is a function that maps a
coordinate on the aperture to the beamforming weight at the coordinate, a DNN
called BeaINR is proposed to parameterize this function, which is called
implicit neural representation (INR). We further find that the optimal
beamforming function lies in the subspace of channel function, i.e., it can be
expressed as a weighted integral of channel function. Based on this finding, we
propose another DNN called CoefINR to learn the weighting coefficient with INR,
which has lower complexity than learning the beamforming function with BeaINR.
Simulation results show that the proposed INR-based methods outperform
numerical baselines in both spectral efficiency (SE) and inference time, with
CoefINR offering additional training efficiency.

</details>


### [7] [Multipath-Enhanced Measurement of Antenna Patterns: Theory](https://arxiv.org/abs/2507.03639)
*Daniel D. Stancil*

Main category: eess.SP

TL;DR: 提出了一种利用多径传播而非抑制的MEAP天线模式测量技术，无需消声环境，通过参考天线校准多径信道矩阵，并利用球谐函数高效表示模式。


<details>
  <summary>Details</summary>
Motivation: 传统天线模式测量需抑制多径传播，而MEAP技术利用多径传播，避免了消声环境的需求。

Method: 使用参考天线校准多径信道矩阵，结合球谐函数进行模式表示。

Result: 数值计算验证了方法的可行性，实验部分在另一篇论文中描述。

Conclusion: MEAP技术为天线模式测量提供了一种无需消声环境的新方法。

Abstract: Traditional antenna pattern measurements involve minimizing the impact of
multipath propagation in the measurement environment. In contrast, this work
introduces a measurement approach that uses rather than mitigates multipath
propagation. This is referred to as the Multipath-Enhanced Antenna Pattern
(MEAP) Measurement technique. In this respect the approach has some kinship
with Multiple-Input Multiple-Output (MIMO) systems. The advantage in the case
of MIMO systems is increased capacity; in the MEAP approach the advantage is
elimination of the need for creating an anechoic environment. The approach uses
measurements with reference antennas to calibrate the multipath channel matrix,
and vector spherical harmonics for efficient pattern representation. After
presenting the mathematical details of the method, numerical calculations
illustrating the approach are presented. Experimental results are described in
a companion paper.

</details>


### [8] [Multipath-Enhanced Measurement of Antenna Patterns: Experiment](https://arxiv.org/abs/2507.03647)
*Daniel D. Stancil,Alexander R. Allen*

Main category: eess.SP

TL;DR: 本文通过实验验证了一种利用多径环境特性的天线模式测量技术，在家庭车库中进行了测试，并比较了三种分析方法的效果。


<details>
  <summary>Details</summary>
Motivation: 验证在真实多径环境中利用多径特性进行天线模式测量的可行性。

Method: 使用半波长电偶极子作为校准和测试天线，采用三种分析方法：矩阵反演法（3个感知天线）、最小二乘误差法（10个感知天线）和带恒定功率约束的最小二乘误差法（10个感知天线）。

Result: 带约束的最小二乘误差法效果最佳。

Conclusion: 实验证明了该技术在真实环境中的可行性，并确定了最优分析方法。

Abstract: In a companion paper we presented the theory for an antenna pattern measuring
technique that uses (rather than mitigates) the properties of a multipath
environment. Here we use measurements in a typical home garage to
experimentally demonstrate the feasibility of the technique. A half-wavelength
electric dipole with different orientations was used as both the calibration
and test antennas. For simplicity, we limited the modeling of the antenna
pattern to using only the three $l=1$ vector spherical harmonics. Three methods
were used to analyze the measurements: a matrix inversion method using only 3
sense antennas, a least-square-error technique, and a least-square-error
technique with a constant power constraint imposed. The two least-square-error
techniques used the measurements from 10 sense antennas. The constrained
least-square-error technique was found to give the best results.

</details>


### [9] [Performance Analysis of Data Detection in the THz-Band under Channel-Correlated Noise](https://arxiv.org/abs/2507.03702)
*Almutasem Bellah Enad,Hadi Sarieddeen,Jihad Fahs,Hakim Jemaa,Tareq Y. Al-Naffouri*

Main category: eess.SP

TL;DR: 提出了一种用于太赫兹通信系统的符号错误率分析框架，考虑了独立和相关的信道与噪声条件，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决太赫兹通信系统中因信道与噪声独立性假设导致的符号错误率（SER）误差问题。

Method: 推导了独立信道和噪声条件下的不匹配SER，以及相关条件下的精确SER，并利用copula方法建模依赖关系。

Result: 仿真表明，该框架能够修正因信道-噪声独立性假设导致的多dB SER误差。

Conclusion: 该框架为太赫兹通信系统提供了更准确的SER分析工具，尤其在相关条件下表现优异。

Abstract: We present a comprehensive symbol error rate (SER) analysis framework for
link-level terahertz (THz)-band communication systems under linear zero-forcing
(ZF) data detection. First, we derive the mismatched SER for indoor THz systems
under independent channel and noise assumptions, calculating the probability
density function of the ratio of Gaussian noise to $\alpha$-$\mu$ channels
resulting from ZF filtering. Next, we derive the precise SER under correlated
channel and noise conditions, modeling dependencies using the copula method.
Finally, we evaluate the SER for THz channels with correlated distortion noise
from hardware impairments. Simulations demonstrate that the proposed framework
corrects for multi-dB SERs resulting from the channel-noise independence
assumption.

</details>


### [10] [Improving SAGIN Resilience to Jamming with Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2507.03729)
*Leila Marandi,Khaled Humadi,Gunes Karabulut Kurt,Wessam Ajib,Wei-Ping Zhu*

Main category: eess.SP

TL;DR: 研究提出在固定无人机上部署RIS以对抗恶意干扰，优化RIS波束成形和LEO卫星发射功率以最大化SJNR，仿真显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有研究未考虑LEO卫星向地面用户发送信号时受到GEO卫星干扰的情况，需通过RIS和功率优化提升抗干扰能力。

Method: 采用交替优化（AO）和半定松弛（SDR）技术，假设RIS具备全局信道状态信息（CSI）。

Result: 仿真结果表明优化方案显著提升性能，且在高干扰功率和RIS单元较少时，无人机部署RIS更有效。

Conclusion: 在SAGIN中，RIS部署于无人机并结合优化技术可有效对抗干扰，尤其在高干扰环境下表现优越。

Abstract: This study investigates the anti-jamming space-air-ground integrated network
(SAGIN) scenario wherein a reconfigurable intelligent surface (RIS) is deployed
on a fixed Unmanned Aerial Vehicle (UAV) to counteract malevolent jamming
attacks. In contrast to existing research, in this paper, we consider that a
Low Earth Orbit (LEO) satellite is sending the signal to the user on the ground
in the presence of jamming from a Geostationary Equatorial Orbit (GEO)
satellite side. We aim to maximize the signal-to-jamming plus noise ratio
(SJNR) by optimizing the RIS beamforming and transmit power of the LEO
satellite. Assuming the availability of global channel state information (CSI)
at the RIS, we propose alternating optimization (AO) and semidefinite
relaxation (SDR) techniques to address the complexity. Simulation results show
that the optimization schemes lead to considerable performance improvements.
The results also indicate that, given the high jamming power and the relatively
small number of RIS elements, deploying the RIS on UAVs near the user is more
effective in mitigating the impact of jamming interferers.

</details>


### [11] [SHAP-AAD: DeepSHAP-Guided Channel Reduction for EEG Auditory Attention Detection](https://arxiv.org/abs/2507.03814)
*Rayan Salmi,Guorui Lu,Qinyu Chen*

Main category: eess.SP

TL;DR: SHAP-AAD框架通过DeepSHAP选择关键EEG通道，结合轻量级TCN实现高效听觉注意力检测，减少通道数但保持高精度。


<details>
  <summary>Details</summary>
Motivation: 传统EEG听觉注意力检测方法依赖过多电极，影响穿戴舒适性，需减少通道数同时保持性能。

Method: 两阶段框架：1) DeepSHAP分析CNN训练的alpha-power地图，选择关键通道；2) 用轻量级TCN训练所选通道。

Result: 32通道精度接近64通道（79.21% vs. 81.06%），8通道在某些情况下也表现良好。

Conclusion: SHAP-AAD在降低复杂度的同时保持了高性能，适用于实际应用。

Abstract: Electroencephalography (EEG)-based auditory attention detection (AAD) offers
a non-invasive way to enhance hearing aids, but conventional methods rely on
too many electrodes, limiting wearability and comfort. This paper presents
SHAP-AAD, a two-stage framework that combines DeepSHAP-based channel selection
with a lightweight temporal convolutional network (TCN) for efficient AAD using
fewer channels.DeepSHAP, an explainable AI technique, is applied to a
Convolutional Neural Network (CNN) trained on topographic alpha-power maps to
rank channel importance, and the top-k EEG channels are used to train a compact
TCN. Experiments on the DTU dataset show that using 32 channels yields
comparable accuracy to the full 64-channel setup (79.21% vs. 81.06%) on
average. In some cases, even 8 channels can deliver satisfactory accuracy.
These results demonstrate the effectiveness of SHAP-AAD in reducing complexity
while preserving high detection performance.

</details>


### [12] [Robust Node Localization for Rough and Extreme Deployment Environments](https://arxiv.org/abs/2507.03856)
*Abiy Tasissa,Waltenegus Dargie*

Main category: eess.SP

TL;DR: 论文提出了一种在恶劣环境下通过压缩感知方法识别易受干扰节点并稳健估计其位置的算法，同时设计了最优锚点配置以提高定位鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 针对无线传感器网络在恶劣环境（如强干扰、极端天气等）下定位误差大的问题，研究如何识别易受干扰节点并稳健估计其位置。

Method: 将问题建模为压缩感知问题，提出节点识别和稳健位置估计算法，并设计最优锚点配置。

Result: 数值结果表明，算法在少量锚点下实现了节点识别和稳健定位，且仅需目标到锚点的距离信息。

Conclusion: 该方法具有广泛适用性和鲁棒性，适用于恶劣环境下的传感器网络定位。

Abstract: Many applications have been identified which require the deployment of
large-scale low-power wireless sensor networks. Some of the deployment
environments, however, impose harsh operation conditions due to intense
cross-technology interference, extreme weather conditions (heavy rainfall,
excessive heat, etc.), or rough motion, thereby affecting the quality and
predictability of the wireless links the nodes establish. In localization
tasks, these conditions often lead to significant errors in estimating the
position of target nodes. Motivated by the practical deployments of sensors on
the surface of different water bodies, we address the problem of identifying
susceptible nodes and robustly estimating their positions. We formulate these
tasks as a compressive sensing problem and propose algorithms for both node
identification and robust estimation. Additionally, we design an optimal anchor
configuration to maximize the robustness of the position estimation task. Our
numerical results and comparisons with competitive methods demonstrate that the
proposed algorithms achieve both objectives with a modest number of anchors.
Since our method relies only on target-to-anchor distances, it is broadly
applicable and yields resilient, robust localization.

</details>


### [13] [A Variational Bayesian Detector for Affine Frequency Division Multiplexing](https://arxiv.org/abs/2507.03858)
*Can Zheng,Chung G. Kang*

Main category: eess.SP

TL;DR: 提出了一种基于变分贝叶斯的检测器，用于AFDM系统，通过最小化KL散度实现低复杂度软判决检测，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统检测方法（如ZF、LMMSE和MPA）在复杂多径信道下性能不足，需要一种更高效且鲁棒的检测器。

Method: 使用变分贝叶斯方法，通过最小化KL散度估计符号概率分布，实现低复杂度软判决检测。

Result: 相比传统方法，具有更低的误码率、更快的收敛速度和更强的鲁棒性。

Conclusion: 该检测器在计算效率和检测性能上均具有优势，适用于复杂多径信道。

Abstract: This paper proposes a variational Bayesian (VB) detector for affine frequency
division multiplexing (AFDM) systems. The proposed method estimates the symbol
probability distribution by minimizing the Kullback-Leibler (KL) divergence
between the true posterior and an approximate distribution, thereby enabling
low-complexity soft-decision detection. Compared to conventional approaches
such as zero-forcing (ZF), Linear minimum mean square rrror (LMMSE), and the
message passing algorithm (MPA), the proposed detector demonstrates lower bit
error rates (BER), faster convergence, and improved robustness under complex
multipath channels. Simulation results confirm its dual advantages in
computational efficiency and detection performance.

</details>


### [14] [Structure from Noise: Confirmation Bias in Particle Picking in Structural Biology](https://arxiv.org/abs/2507.03951)
*Amnon Balanov,Alon Zabatani,Tamir Bendory*

Main category: eess.SP

TL;DR: 论文探讨了冷冻电镜（cryo-EM）和冷冻电子断层扫描（cryo-ET）中确认偏误的挑战，指出模板匹配和深度神经网络方法可能在纯噪声中产生虚假结构，并提出缓解策略。


<details>
  <summary>Details</summary>
Motivation: 解决冷冻电镜和冷冻电子断层扫描中因先验期望导致的数据解释系统误差问题，特别是在粒子选取阶段。

Method: 结合理论分析和控制实验，研究模板匹配和深度神经网络在纯噪声中产生虚假结构的现象。

Result: 发现两种方法在纯噪声中均能产生持久分子结构（称为“噪声中的结构”），揭示了当前工作流程中的潜在偏误。

Conclusion: 提出缓解策略以减少偏误影响，并呼吁谨慎解释重建结果，尤其是依赖模板驱动的粒子选取时。

Abstract: Confirmation bias is a fundamental challenge in cryo-electron microscopy
(cryo-EM) and cryo-electron tomography (cryo-ET), where prior expectations can
lead to systematic errors in data interpretation. This bias may emerge at
multiple stages of the reconstruction pipeline, and in particular in the
critical particle picking stage, where 2D particles (in cryo-EM) or 3D
subtomograms (in cryo-ET) are extracted from highly noisy micrographs or
tomograms. Focusing on two widely used methodologies, template matching and
deep neural networks, we combine theoretical analysis with controlled
experiments to demonstrate that both methods, when applied to pure noise, can
produce persistent molecular structures, a phenomenon we term structure from
noise. This artifact highlights a critical vulnerability in current workflows:
the potential for particle-picking algorithms to inject strong prior-driven
bias into downstream analyses. We then propose practical mitigation strategies
to reduce the impact of such biases. Together, our findings deepen the
theoretical understanding of confirmation bias in cryo-EM and cryo-ET and call
for cautious interpretation of reconstructions, primarily when relying on
template-driven particle picking.

</details>


### [15] [SAFERad: A Framework to Enable Radar Data for Safety-Relevant Perception Tasks](https://arxiv.org/abs/2507.03959)
*Tim Brühl,Jenny Glönkler,Robin Schwager,Tin Stribor Sohn,Tim Dieter Eberhardt,Sören Hohmann*

Main category: eess.SP

TL;DR: 提出了一种基于雷达点潜在碰撞风险的动态过滤方法，通过计算关键性分数调整过滤策略，显著提高了关键场景的检测率。


<details>
  <summary>Details</summary>
Motivation: 未来高度自动化驾驶功能对雷达感知系统的错误率要求更高，传统严格过滤方法无法满足需求。

Method: 提出动态过滤算法，根据雷达点的潜在碰撞风险（关键性分数）调整过滤阈值，并引入关键性区域。

Result: 实验证明该方法在关键场景中召回率高，且非聚类关键点率降低了74.8%。

Conclusion: 动态过滤策略在保证低误报率的同时，显著提升了关键目标的检测能力。

Abstract: Radar sensors play a crucial role for perception systems in automated driving
but suffer from a high level of noise. In the past, this could be solved by
strict filters, which remove most false positives at the expense of undetected
objects. Future highly automated functions are much more demanding with respect
to error rate. Hence, if the radar sensor serves as a component of perception
systems for such functions, a simple filter strategy cannot be applied. In this
paper, we present a modified filtering approach which is characterized by the
idea to vary the filtering depending on the potential of harmful collision with
the object which is potentially represented by the radar point. We propose an
algorithm which determines a criticality score for each point based on the
planned or presumable trajectory of the automated vehicle. Points identified as
very critical can trigger manifold actions to confirm or deny object presence.
Our pipeline introduces criticality regions. The filter threshold in these
criticality regions is omitted. Commonly known radar data sets do not or barely
feature critical scenes. Thus, we present an approach to evaluate our framework
by adapting the planned trajectory towards vulnerable road users, which serve
as ground truth critical points. Evaluation of the criticality metric prove
high recall rates. Besides, our post-processing algorithm lowers the rate of
non-clustered critical points by 74.8 % in an exemplary setup compared to a
moderate, generic filter.

</details>


### [16] [MMOC: Self-Supervised EEG Emotion Recognition Framework with Multi-Model Online Collaboration](https://arxiv.org/abs/2507.03977)
*Hanqi Wang,Yang Liu,Peng Ye,Liang Song*

Main category: eess.SP

TL;DR: MMOC是一个自监督框架，通过多模型在线协作解决EEG情感识别中的数据漂移问题，在SEED和Dreamer数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: EEG情感识别中，监督学习依赖人工标注成本高且易偏，自监督学习虽能生成标签但受限于数据漂移。传统域适应和泛化方法无法完全解决复杂数据漂移问题。

Method: 提出MMOC框架，结合重建和对比学习的多模型训练，通过损失路由机制动态选择最适合的模型进行推理。

Result: 在SEED和Dreamer数据集上分别达到85.39%、68.77%和69.37%的准确率，显著优于现有方法。

Conclusion: MMOC有效缓解了数据漂移问题，为实际EEG情感识别提供了实用解决方案。

Abstract: Electroencephalography (EEG) emotion recognition plays a crucial role in
human-computer interaction, particularly in healthcare and neuroscience. While
supervised learning has been widely used, its reliance on manual annotations
introduces high costs and potential bias. Self-supervised learning (SSL) offers
a promising alternative by generating labels through pretext tasks. However,
high inter-subject variability in EEG signals leads to significant data drift,
limiting self-supervised models' generalization across unseen subjects.
Traditional domain adaptation (DA) methods require access to target-domain data
during training. Although domain generalization (DG) avoids this constraint, it
often falls short in handling complex data drift due to limited coverage of
possible target distributions. To tackle these challenges, we propose MMOC, a
self-supervised framework with multi-model online collaboration (MMOC), to
achieve online adaptation to unseen data. MMOC trains multiple base models
using diverse strategies rooted in reconstruction and contrastive learning,
enabling each model to develop distinct generalization capabilities. During
inference, MMOC dynamically activates the most suitable model for each test
sample via a loss-based routing mechanism that evaluates both contrastive and
reconstruction losses. This dual consideration allows for a comprehensive
measurement of data drift at both structural and semantic levels. Experimental
results on the SEED and Dreamer datasets show that MMOC achieves
state-of-the-art performance: 85.39% on SEED, and 68.77% and 69.37% on Dreamer
arousal and valence dimensions, respectively. MMOC effectively mitigates
inter-subject data drift, offering a practical solution for real-world EEG
emotion recognition.

</details>


### [17] [An Efficient Detector for Faulty GNSS Measurements Detection With Non-Gaussian Noises](https://arxiv.org/abs/2507.03987)
*Penggao Yan,Baoshan Song,Xiao Xia,Weisong Wen,Li-Ta Hsu*

Main category: eess.SP

TL;DR: 本文提出了一种基于jackknife技术的故障检测方法，适用于非高斯噪声环境下的线性伪距定位系统，具有高效的计算性能和等效于SS检测器的检测能力。


<details>
  <summary>Details</summary>
Motivation: 主流故障检测方法基于高斯假设，而非高斯故障检测方法缺乏严格的统计特性，实际应用中性能和可靠性受限。

Method: 利用jackknife技术推导测试统计量，无需限制性分布假设，结合Bonferroni校正构建假设检验。

Result: 全球仿真和真实卫星时钟异常检测实验表明，jackknife检测器与SS检测器性能相当，但计算效率提高四倍。

Conclusion: jackknife检测器在非高斯噪声环境中具有实时应用的潜力，兼具鲁棒性和高效性。

Abstract: Fault detection is crucial to ensure the reliability of navigation systems.
However, mainstream fault detection methods are developed based on Gaussian
assumptions on nominal errors, while current attempts at non-Gaussian fault
detection are either heuristic or lack rigorous statistical properties. The
performance and reliability of these methods are challenged in real-world
applications. This paper proposes the jackknife detector, a fault detection
method tailored for linearized pseudorange-based positioning systems under
non-Gaussian nominal errors. Specifically, by leveraging the jackknife
technique, a test statistic is derived as a linear combination of measurement
errors, eliminating the need for restrictive distributional assumptions while
maintaining computational efficiency. A hypothesis test with the Bonferroni
correction is then constructed to detect potential faults in measurements.
Theoretical analysis proves the equivalence between the jackknife detector and
the solution separation (SS) detector, while revealing the former's superior
computational efficiency. Through a worldwide simulation and a real-world
satellite clock anomaly detection experiment--both involving non-Gaussian
nominal errors--the proposed jackknife detector demonstrates equivalent
detection performance to the SS detector but achieves a fourfold improvement in
computational efficiency. These results highlight the jackknife detector's
substantial potential for real-time applications requiring robust and efficient
fault detection in non-Gaussian noise environments.

</details>


### [18] [Differentiable High-Performance Ray Tracing-Based Simulation of Radio Propagation with Point Clouds](https://arxiv.org/abs/2507.04021)
*Niklas Vaara,Pekka Sangi,Miguel Bordallo López,Janne Heikkilä*

Main category: eess.SP

TL;DR: 提出了一种基于点云的可微分射线追踪无线电传播模拟器，展示了其在室内场景中的高效性，并利用可微分性和语义标签学习环境的电磁特性。


<details>
  <summary>Details</summary>
Motivation: 射线追踪在无线电传播模拟中具有物理准确性，但其精度依赖于环境模型的质量和电磁特性。计算机视觉和机器学习的进步使得重建带有语义标签的详细环境模型成为可能。

Method: 开发了一种可微分射线追踪模拟器，直接在点云上操作，模拟多反射和散射路径，并在两个室内场景中验证其效率。

Result: 模拟器在90毫秒内完成多反射路径的模拟，展示了高效性，并利用可微分性和语义标签学习环境电磁特性。

Conclusion: 该方法结合了可微分射线追踪和语义标签，为无线电传播模拟提供了高效且可学习的解决方案。

Abstract: Ray tracing is a widely used deterministic method for radio propagation
simulations, capable of producing physically accurate multipath components. The
accuracy depends on the quality of the environment model and its
electromagnetic properties. Recent advances in computer vision and machine
learning have made it possible to reconstruct detailed environment models
augmented with semantic segmentation labels.
  In this letter, we propose a differentiable ray tracing-based radio
propagation simulator that operates directly on point clouds. We showcase the
efficiency of our method by simulating multi-bounce propagation paths with up
to five interactions with specular reflections and diffuse scattering in two
indoor scenarios, each completing in less than 90 ms. Lastly, we demonstrate
how the differentiability of electromagnetic computations can be combined with
segmentation labels to learn the electromagnetic properties of the environment.

</details>


### [19] [CSI-Free Symbol Detection for Atomic MIMO Receivers via In-Context Learning](https://arxiv.org/abs/2507.04040)
*Zihang Song,Qihao Peng,Pei Xiao,Bipin Rajendran,Osvaldo Simeone*

Main category: eess.SP

TL;DR: 提出了一种基于上下文学习（ICL）的无信道状态信息（CSI）符号检测方法，避免了传统方法的迭代优化和高计算复杂度问题。


<details>
  <summary>Details</summary>
Motivation: 原子接收器在多天线配置中因仅测量幅度而无相位信息，导致传统检测方法难以适用。现有解决方案存在级联信道估计误差和高计算复杂度问题。

Method: 采用上下文学习（ICL）方法，直接通过导频-响应对映射到数据符号预测，无需显式信道估计。

Result: 仿真结果表明，ICL在计算效率更高的同时，达到了与现有解决方案相当的准确性。

Conclusion: ICL方法为原子接收器的符号检测提供了一种高效且准确的替代方案。

Abstract: Atomic receivers based on Rydberg vapor cells as sensors of electromagnetic
fields offer a promising alternative to conventional radio frequency
front-ends. In multi-antenna configurations, the magnitude-only,
phase-insensitive measurements produced by atomic receivers pose challenges for
traditional detection methods. Existing solutions rely on two-step iterative
optimization processes, which suffer from cascaded channel estimation errors
and high computational complexity. We propose a channel state information
(CSI)-free symbol detection method based on in-context learning (ICL), which
directly maps pilot-response pairs to data symbol predictions without explicit
channel estimation. Simulation results show that ICL achieves competitive
accuracy with {higher computational efficiency} compared to existing solutions.

</details>


### [20] [Experimental Demonstration of Computational AoA Detection Using Conformal Frequency Diverse Metasurface Antennas](https://arxiv.org/abs/2507.04178)
*Idban Alamzadeh,Michael Inman,Mohammadreza F. Imani*

Main category: eess.SP

TL;DR: 论文提出了一种新型的共形频率多样性天线，用于广角AoA检测，实验验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 传统AoA检测方法（如机械旋转天线或共形阵列）体积大、重量重且成本高，不适用于机械和隐身要求严格的平台。

Method: 设计了一种共形频率多样性天线，通过频率扫描将角度信息编码，仅需两个接收单元即可实现全视野AoA检测。

Result: 实验验证了该天线的AoA检测能力，展示了其在大视野传感中的潜力。

Conclusion: 共形超表面为广角传感提供了一种新的硬件解决方案，适用于雷达、态势感知和导航等领域。

Abstract: Devices that detect angle-of-arrival (AoA) over a wide field of view are
crucial for various applications such as wireless communication and navigation.
They are often installed on platforms with challenging mechanical and stealth
constraints like vehicles, drones, and helmets, where traditional methods --
mechanically rotating antennas or conformal arrays -- tend to be bulky, heavy,
and costly. A recent work has proposed a conformal frequency diverse antenna
that is designed to produce angularly diverse patterns that encode angular
information into frequency sweeps. This capability allows AoA to be determined
across the entire horizon using only two receiving units. This paper
experimentally validates this concept, detailing the prototyping process and
practical design considerations. The AoA detection capabilities of the proposed
device are confirmed through experimental demonstrations. The proposed
conformal metasurfaces offer an alternative hardware solution for sensing over
large fields of view, with potential applications in radar sensing, situational
awareness, and navigation.

</details>


### [21] [Adaptive Resource Management in Cognitive Radar via Deep Deterministic Policy Gradient](https://arxiv.org/abs/2507.04195)
*Ziyang Lu,M. Cenk Gursoy,Chilukuri K. Mohan,Pramod K. Varshney*

Main category: eess.SP

TL;DR: 论文研究了认知雷达系统中的目标检测和多目标跟踪，提出了一种基于深度确定性策略梯度（DDPG）的强化学习方法，用于优化雷达资源分配。


<details>
  <summary>Details</summary>
Motivation: 解决在预算约束下，认知雷达对多机动目标进行扫描和跟踪的时间管理问题，以联合最大化扫描和跟踪性能。

Method: 采用深度确定性策略梯度（DDPG）的强化学习方法，提出了一种约束深度强化学习（CDRL）算法，同时更新DDPG神经网络和对偶变量。

Result: 数值结果表明，雷达能够自主分配时间，在不超出时间约束的情况下最大化奖励函数。

Conclusion: 提出的CDRL算法有效解决了雷达资源分配的优化问题，实现了性能最大化。

Abstract: In this paper, scanning for target detection, and multi-target tracking in a
cognitive radar system are considered, and adaptive radar resource management
is investigated. In particular, time management for radar scanning and tracking
of multiple maneuvering targets subject to budget constraints is studied with
the goal to jointly maximize the tracking and scanning performances of a
cognitive radar. We tackle the constrained optimization problem of allocating
the dwell time to track individual targets by employing a deep deterministic
policy gradient (DDPG) based reinforcement learning approach. We propose a
constrained deep reinforcement learning (CDRL) algorithm that updates the DDPG
neural networks and dual variables simultaneously. Numerical results show that
the radar can autonomously allocate time appropriately so as to maximize the
reward function without exceeding the time constraint.

</details>


### [22] [High-Availability Integrity Monitoring for Multi-Constellation GNSS Navigation with Non-Gaussian Errors](https://arxiv.org/abs/2507.04284)
*Penggao Yan,Ronghe Jin,Junyi Zhang,Cheng-Wei Wang,Li-Ta Hsu*

Main category: eess.SP

TL;DR: 提出了一种扩展的jackknife检测器，用于处理非高斯误差的多重故障检测，并开发了jackknife ARAIM算法，显著降低了垂直保护水平（VPL），提升了GNSS应用的完整性和可用性。


<details>
  <summary>Details</summary>
Motivation: 传统RAIM和ARAIM依赖高斯模型，对实际非高斯误差（如卫星钟差和轨道误差）过于保守，需改进。

Method: 提出扩展jackknife检测器和jackknife ARAIM算法，通过量化故障向量对位置解的影响，推导出紧密的完整性风险边界。

Result: 在单GPS星座下，VPL降低至45m；双星座（GPS-Galileo）下，VPL保持在40m以下，92%操作正常。

Conclusion: jackknife ARAIM显著提升LPV性能，支持200英尺决策高度，增强多星座GNSS应用的完整性和可用性。

Abstract: Global navigation satellite systems (GNSS) are essential for aviation,
requiring strict integrity monitoring to alert users to hazardously misleading
information. Conventional receiver autonomous integrity monitoring (RAIM) and
advanced RAIM (ARAIM) rely heavily on Gaussian models in bounding nominal
errors, which can be overly conservative with real-world non-Gaussian errors
with heavy tails, such as the satellite clock and orbit errors. This paper
proposes an extended jackknife detector capable of detecting multiple
simultaneous faults with non-Gaussian nominal errors. Furthermore, an integrity
monitoring algorithm, jackknife ARAIM, is developed by systematically
exploiting the properties of the jackknife detector in the range domain. A
tight bound of the integrity risk is derived by quantifying the impacts of
hypothetical fault vectors on the position solution. The proposed method is
examined in worldwide simulations, with the nominal measurement error simulated
based on authentic experimental data, which reveals different findings in
existing research. In a setting of a single Global Positioning System (GPS)
constellation, the proposed method reduces the 99.5 percentile vertical
protection level (VPL) 45m, where the VPL of the baseline ARAIM is larger than
50m in most user locations. For dual-constellation (GPS-Galileo) settings,
baseline ARAIM suffers VPL inflation over 60m due to the over-conservatism
induced by the heavy-tailed Galileo signal-in-space range errors, whereas the
proposed jackknife ARAIM retains VPL below 40m, achieving over 92% normal
operations for a 35m Vertical Alert Limit. These improvements have promising
potential to support localizer performance with vertical guidance (LPV) with a
decision height of 200 ft, enhancing integrity and availability for
multi-constellation GNSS applications.

</details>


### [23] [Near-Field ISAC for THz Wireless Systems](https://arxiv.org/abs/2507.04292)
*Fan Zhang,Tianqi Mao,Mingkun Li,Meng Hua,Jinshu Chen,Christos Masouros,Zhaocheng Wang*

Main category: eess.SP

TL;DR: 本文探讨了6G网络中太赫兹（THz）近场传播的特性及其在集成感知与通信（ISAC）系统中的应用潜力，分析了近场传播的三大特征，并提出了基于波数域的近场感知方法和资源分配框架。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC技术多基于远场平面波假设，难以适应THz近场传播的独特特性，因此需要研究近场ISAC以支持未来6G网络的高速率通信和精确感知。

Method: 分析了THz近场传播的三大特征，提出了基于波数域的近场感知方法和利用波束斜视效应的ISAC资源分配框架。

Result: 研究表明，THz近场传播特性可以显著提升通信和感知性能，提出的方法为未来ISAC系统提供了新的研究方向。

Conclusion: THz近场ISAC是一个新兴领域，未来研究应进一步探索其潜力，以支持6G网络的高性能需求。

Abstract: Sixth-generation (6G) wireless networks are expected not only to provide
high-speed connectivity but also to support reliable sensing capabilities,
giving rise to the integrated sensing and communication (ISAC) paradigm. To
enable higher data rates and more accurate sensing, terahertz (THz) systems
empowered by extremely large multiple-input-multiple-output (XL-MIMO)
technology are envisioned as key enablers for future ISAC systems. Owing to the
substantial increase in both effective array aperture and carrier frequency, a
considerable portion of future ISAC applications is anticipated to fall within
the near-field coverage region, instead of the conventional far-field. However,
most existing ISAC techniques are designed under the far-field planar wave
assumption, struggling to accommodate the unique characteristics of THz
near-field propagation. To motivate future research into near-field ISAC
research, we systematically investigate the characteristics of THz near-field
propagation and explore its potential to facilitate ISAC systems. Specifically,
we analyze three fundamental characteristics of THz near-field propagation and
review state-of-the-art techniques that exploit these features to boost both
communication and sensing performance. To further harness the angular-range
coupling effect, we zoom into a particularly interesting approach to near-field
sensing based on wavenumber domain. Besides, to exploit the beam squint effect,
an ISAC resource allocation framework is introduced to support integrated
multi-angle sensing and multi-user communication. Finally, we outline promising
directions for future research in this emerging area.

</details>


### [24] [Context-Aware Deep Learning for Robust Channel Extrapolation in Fluid Antenna Systems](https://arxiv.org/abs/2507.04435)
*Yanliang Jin,Runze Yu,Yuan Gao,Shengli Liu,Xiaoli Chu,Kai-Kit Wong,Chan-Byoung Chae*

Main category: eess.SP

TL;DR: 提出了一种名为CANet的深度学习模型，用于解决流体天线系统（FAS）中高分辨率信道状态信息获取的挑战，通过上下文自适应建模和跨尺度注意力机制提升信道外推精度。


<details>
  <summary>Details</summary>
Motivation: 流体天线系统（FAS）虽然具有空间灵活性，但在获取高分辨率信道状态信息（CSI）时面临显著挑战，导致开销较大。

Method: CANet结合上下文自适应建模和跨尺度注意力机制，基于ConvNeXt v2骨干网络，并引入空间振幅扰动策略和傅里叶域损失函数。

Result: 仿真结果表明，CANet在多种信噪比（SNR）水平下均优于基准模型。

Conclusion: CANet通过创新的建模和损失函数设计，显著提升了FAS中信道外推的准确性和鲁棒性。

Abstract: Fluid antenna systems (FAS) offer remarkable spatial flexibility but face
significant challenges in acquiring high-resolution channel state information
(CSI), leading to considerable overhead. To address this issue, we propose
CANet, a robust deep learning model for channel extrapolation in FAS. CANet
combines context-adaptive modeling with a cross-scale attention mechanism and
is built on a ConvNeXt v2 backbone to improve extrapolation accuracy for
unobserved antenna ports. To further enhance robustness, we introduce a novel
spatial amplitude perturbation strategy, inspired by frequency-domain
augmentation techniques in image processing. This motivates the incorporation
of a Fourier-domain loss function, capturing frequency-domain consistency,
alongside a spectral structure consistency loss that reinforces learning
stability under perturbations. Our simulation results demonstrate that CANet
outperforms benchmark models across a wide range of signal-to-noise ratio (SNR)
levels.

</details>


### [25] [Enhancing Data Processing Efficiency in Blockchain Enabled Metaverse over Wireless Communications](https://arxiv.org/abs/2507.04657)
*Liangxin Qian,Jun Zhao*

Main category: eess.SP

TL;DR: 论文提出了一种名为DAUR的算法，用于在区块链赋能的元宇宙无线通信系统中优化数据处理效率（DPE），通过联合计算和通信资源约束实现高效资源分配。


<details>
  <summary>Details</summary>
Motivation: 在快速发展的元宇宙环境中，数据处理效率成为关键挑战，尤其是在区块链赋能的无线通信系统中。

Method: 提出DPE-Aware User Association and Resource Allocation (DAUR)算法，将非凸的DPE最大化问题转化为可解的凸优化问题，优化用户关联、任务卸载比例等关键变量。

Result: 数值结果表明DAUR算法在提升数据处理效率方面表现优异。

Conclusion: DAUR算法为区块链赋能的元宇宙无线通信系统提供了一种高效的数据处理效率优化方案。

Abstract: In the rapidly evolving landscape of the Metaverse, enhanced by blockchain
technology, the efficient processing of data has emerged as a critical
challenge, especially in wireless communication systems. Addressing this
challenge, our paper introduces the innovative concept of data processing
efficiency (DPE), aiming to maximize processed bits per unit of resource
consumption in blockchain-empowered Metaverse environments. To achieve this, we
propose the DPE-Aware User Association and Resource Allocation (DAUR)
algorithm, a tailored optimization framework for blockchain-enabled Metaverse
wireless communication systems characterized by joint computing and
communication resource constraints. The DAUR algorithm transforms the nonconvex
problem of maximizing the sum of DPE ratios into a solvable convex optimization
problem. It alternates the optimization of key variables, including user
association, work offloading ratios, task-specific computing resource
distribution, bandwidth allocation, user power usage ratios, and server
computing resource allocation ratios. Our extensive numerical results
demonstrate the DAUR algorithm's effectiveness in DPE.

</details>


### [26] [Simultaneous Localization and Mapping Using Active mmWave Sensing in 5G NR](https://arxiv.org/abs/2507.04662)
*Tao Du,Jie Yang,Fan Liu,Jiaxiang Guo,Shuqiang Xia,Chao-Kai Wen,Shi Jin*

Main category: eess.SP

TL;DR: 利用毫米波5G NR系统进行主动感知，通过点云生成和优化算法实现高精度终端定位和无线电地图重建。


<details>
  <summary>Details</summary>
Motivation: 解决被动SLAM技术中因假设镜面反射和简化地图表示而导致的局限性。

Method: 使用毫米波5G NR系统提取点云，通过二进制搜索校准硬件延迟，利用点云配准算法估计终端姿态，并通过闭环检测和姿态图优化优化结果。

Result: 通过仿真和实验验证了系统的有效性，实现了精确的终端定位和详细的无线电地图重建。

Conclusion: 提出的方法克服了传统SLAM技术的限制，为毫米波5G NR系统的主动感知提供了有效解决方案。

Abstract: Millimeter-wave (mmWave) 5G New Radio (NR) communication systems, with their
high-resolution antenna arrays and extensive bandwidth, offer a transformative
opportunity for high-throughput data transmission and advanced environmental
sensing. Although passive sensing-based SLAM techniques can estimate user
locations and environmental reflections simultaneously, their effectiveness is
often constrained by assumptions of specular reflections and oversimplified map
representations. To overcome these limitations, this work employs a mmWave 5G
NR system for active sensing, enabling it to function similarly to a laser
scanner for point cloud generation. Specifically, point clouds are extracted
from the power delay profile estimated from each beam direction using a binary
search approach. To ensure accuracy, hardware delays are calibrated with
multiple predefined target points. Pose variations of the terminal are then
estimated from point cloud data gathered along continuous trajectory viewpoints
using point cloud registration algorithms. Loop closure detection and pose
graph optimization are subsequently applied to refine the sensing results,
achieving precise terminal localization and detailed radio map reconstruction.
The system is implemented and validated through both simulations and
experiments, confirming the effectiveness of the proposed approach.

</details>


### [27] [UAV-Assisted Integrated Communication and Over-the-Air Computation with Interference Awareness](https://arxiv.org/abs/2507.04807)
*Xunqiang Lan,Xiao Tang,Ruonan Zhang,Bin Li,Yichen Wang,Dusit Niyato,Zhu Han*

Main category: eess.SP

TL;DR: 论文提出了一种利用无人机（UAV）实现通信与空中计算（AirComp）集成的方案，通过优化传输策略、信号归一化因子、调度策略和无人机轨迹，提升性能并减少干扰。


<details>
  <summary>Details</summary>
Motivation: 在无线通信与AirComp共存的网络中，相互干扰是一个关键挑战，需要一种有效的方法来提升性能。

Method: 采用双层优化框架，外层通过深度强化学习优化无人机轨迹和调度，内层通过交替优化解决传输和计算问题。

Result: 仿真结果表明，所提方案在学习过程中收敛，并在多种情况下优于基线方法。

Conclusion: 无人机辅助的集成通信与AirComp方案能有效提升性能并减少干扰。

Abstract: Over the air computation (AirComp) is a promising technique that addresses
big data collection and fast wireless data aggregation. However, in a network
where wireless communication and AirComp coexist, mutual interference becomes a
critical challenge. In this paper, we propose to employ an unmanned aerial
vehicle (UAV) to enable integrated communication and AirComp, where we
capitalize on UAV mobility with alleviated interference for performance
enhancement. Particularly, we aim to maximize the sum of user transmission rate
with the guaranteed AirComp accuracy requirement, where we jointly optimize the
transmission strategy, signal normalizing factor, scheduling strategy, and UAV
trajectory. We decouple the formulated problem into two layers where the outer
layer is for UAV trajectory and scheduling, and the inner layer is for
transmission and computation. Then, we solve the inner layer problem through
alternating optimization, and the outer layer is solved through soft actor
critic based deep reinforcement learning. Simulation results show the
convergence of the proposed learning process and also demonstrate the
performance superiority of our proposal as compared with the baselines in
various situations.

</details>


### [28] [Exploring O-RAN Compression Techniques in Decentralized Distributed MIMO Systems: Reducing Fronthaul Load](https://arxiv.org/abs/2507.04997)
*Mostafa Rahmani,Junbo Zhao,Vida Ranjbar,Ahmed Al-Tahmeesschi,Hamed Ahmadi,Sofie Pollin,Alister G. Burr*

Main category: eess.SP

TL;DR: 论文探讨了在O-RAN中应用上行前传压缩技术以减轻DD-MIMO系统的前传负载，通过量化策略在降低数据率的同时保持链路性能。


<details>
  <summary>Details</summary>
Motivation: 随着高数据速率和系统可扩展性需求的增加，前传负载成为关键瓶颈，需通过压缩技术解决。

Method: 利用O-RAN压缩技术高效压缩前传信号，并通过BLER曲线评估系统性能。

Result: 量化策略显著降低前传负载，同时保持链路质量，验证了其在下一代无线网络中的可行性。

Conclusion: 研究表明量化技术在O-RAN中能平衡系统容量与性能，为DD-MIMO部署提供更高效和稳健的解决方案。

Abstract: This paper explores the application of uplink fronthaul compression
techniques within Open RAN (O-RAN) to mitigate fronthaul load in decentralized
distributed MIMO (DD-MIMO) systems. With the ever-increasing demand for high
data rates and system scalability, the fronthaul load becomes a critical
bottleneck. Our method uses O-RAN compression techniques to efficiently
compress the fronthaul signals. The goal is to greatly lower the fronthaul load
while having little effect on the overall system performance, as shown by Block
Error Rate (BLER) curves. Through rigorous link-level simulations, we compare
our quantization strategies against a benchmark scenario with no quantization,
providing insights into the trade-offs between fronthaul data rate reduction
and link performance integrity. The results demonstrate that our proposed
quantization techniques not only lower the fronthaul load but also maintain a
competitive link quality, making them a viable solution for enhancing the
efficiency of next-generation wireless networks. This study underscores the
potential of quantization in O-RAN contexts to achieve optimal balance between
system capacity and performance, paving the way for more scalable and robust
DD-MIMO deployments.

</details>


### [29] [Deep Learning Based Antenna Selection Technique for RIS-Empowered RQSM System](https://arxiv.org/abs/2507.05071)
*Burak Ahmet Ozden,Fatih Cogen,Erdogan Aydin*

Main category: eess.SP

TL;DR: 本文提出了一种基于深度神经网络（DNN）的天线选择方法，结合容量优化天线选择（COAS）技术，以提升RIS-RQSM系统的错误性能。通过蒙特卡洛模拟和计算复杂度分析，验证了DNN-COAS-RIS-RQSM系统的优越性。


<details>
  <summary>Details</summary>
Motivation: 可重构智能表面（RIS）技术因其低功耗控制无线传播的能力受到关注，而RQSM通过I/Q通道传输数据提高了频谱效率。然而，传统方法在错误性能上仍有改进空间。

Method: 提出DNN-COAS-RIS-RQSM系统，利用DNN优化天线选择，并结合COAS技术。通过QAM技术和瑞利衰落信道进行蒙特卡洛模拟。

Result: DNN-COAS-RIS-RQSM系统在错误性能上优于传统COAS-RIS-RQSM系统，同时分析了DNN与COAS的计算复杂度权衡。

Conclusion: DNN-COAS-RIS-RQSM系统在提升错误性能的同时，需权衡计算复杂度，为未来无线通信系统提供了优化方向。

Abstract: Reconfigurable intelligent surface (RIS) technology has attracted
considerable interest due to its ability to control wireless propagation with
minimal power usage. Receive quadrature spatial modulation (RQSM) scheme
transmits data bits in both in-phase ($I$) and quadrature ($Q$) channels,
doubling the number of active receive antenna indices and improving spectral
efficiency compared to the traditional receive spatial modulation (RSM)
technique. Also, capacity-optimized antenna selection (COAS) improves error
performance by selecting antennas with the best channel conditions. This paper
proposes a new deep neural network (DNN)-based antenna selection method,
supported by the COAS technique, to improve the error performance of the
RIS-RQSM system. Monte Carlo simulations of the proposed DNN-COAS-RIS-RQSM
system using the quadrature amplitude modulation (QAM) technique for Rayleigh
fading channels are performed and compared with the COAS-RIS-RQSM system. Also,
a comparative analysis of the computational complexities of the DNN and COAS
techniques is conducted to evaluate the trade-offs between error performance
and complexity.

</details>


### [30] [Real-Time Graph-based Point Cloud Networks on FPGAs via Stall-Free Deep Pipelining](https://arxiv.org/abs/2507.05099)
*Marc Neu,Isabel Haide,Timo Justinger,Till Rädler,Valdrin Dajaku,Torben Ferber,Jürgen Becker*

Main category: eess.SP

TL;DR: 提出了一种基于FPGA的深度流水线数据流架构，用于高效处理动态稀疏点云，满足实时触发系统的严格要求。


<details>
  <summary>Details</summary>
Motivation: 解决在高能物理探测器中部署图基点云网络（PCNs）时面临的实时性挑战，包括延迟和吞吐量的严格要求。

Method: 采用深度流水线数据流架构，设计专用处理单元支持核心图操作（如GraVNet卷积和凝聚点聚类），并在AMD Versal VCK190上实现。

Result: 相比GPU基线，FPGA实现实现了最高5.25倍的吞吐量提升，同时延迟保持在10微秒以下。

Conclusion: 该设计满足了粒子物理实验中实时触发系统的需求，并提供了开源参考实现。

Abstract: Graph-based Point Cloud Networks (PCNs) are powerful tools for processing
sparse sensor data with irregular geometries, as found in high-energy physics
detectors. However, deploying models in such environments remains challenging
due to stringent real-time requirements for both latency, and throughput. In
this work, we present a deeply pipelined dataflow architecture for executing
graph-based PCNs on FPGAs. Our method supports efficient processing of dynamic,
sparse point clouds while meeting hard real-time constraints. We introduce
specialized processing elements for core graph operations, such as GraVNet
convolution and condensation point clustering, and demonstrate our design on
the AMD Versal VCK190. Compared to a GPU baseline, our FPGA implementation
achieves up to 5.25x speedup in throughput while maintaining latencies below 10
{\mu}s, satisfying the demands of real-time trigger systems in particle physics
experiments. An open-source reference implementation is provided.

</details>


### [31] [A Federated Learning-based Lightweight Network with Zero Trust for UAV Authentication](https://arxiv.org/abs/2507.05111)
*Hao Zhang,Fuhui Zhou,Wei Wang,Qihui Wu,Chau Yuen*

Main category: eess.SP

TL;DR: 本文提出了一种基于联邦学习的轻量级网络（LSNet），用于增强无人机网络的安全性，通过频谱图实现无人机认证与拒绝，显著提升了准确性和存储效率。


<details>
  <summary>Details</summary>
Motivation: 无人机（UAV）在下一代网络中的应用日益广泛，但其动态性和移动性带来了严重的安全挑战，如干扰、窃听和网络攻击。

Method: 提出了一种轻量级频谱图网络（LSNet），结合联邦学习和零信任机制，用于无人机的认证与拒绝。

Result: 实验表明，LSNet在已知和未知无人机类型的识别上表现优异，准确率超过80%，AUROC为0.7，且模型紧凑、存储需求低。

Conclusion: LSNet在联邦学习场景中具有实际应用价值，能够有效应对无人机网络的安全挑战。

Abstract: Unmanned aerial vehicles (UAVs) are increasingly being integrated into
next-generation networks to enhance communication coverage and network
capacity. However, the dynamic and mobile nature of UAVs poses significant
security challenges, including jamming, eavesdropping, and cyber-attacks. To
address these security challenges, this paper proposes a federated
learning-based lightweight network with zero trust for enhancing the security
of UAV networks. A novel lightweight spectrogram network is proposed for UAV
authentication and rejection, which can effectively authenticate and reject
UAVs based on spectrograms. Experiments highlight LSNet's superior performance
in identifying both known and unknown UAV classes, demonstrating significant
improvements over existing benchmarks in terms of accuracy, model compactness,
and storage requirements. Notably, LSNet achieves an accuracy of over $80\%$
for known UAV types and an Area Under the Receiver Operating Characteristic
(AUROC) of $0.7$ for unknown types when trained with all five clients. Further
analyses explore the impact of varying the number of clients and the presence
of unknown UAVs, reinforcing the practical applicability and effectiveness of
our proposed framework in real-world FL scenarios.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [32] [On the Relationship between Accent Strength and Articulatory Features](https://arxiv.org/abs/2507.03149)
*Kevin Huang,Sean Foley,Jihwan Lee,Yoonjeong Lee,Dani Byrd,Shrikanth Narayanan*

Main category: eess.AS

TL;DR: 研究通过声学语音推断发音特征与口音强度的关系，发现舌位模式可区分美英方言。


<details>
  <summary>Details</summary>
Motivation: 探索口音强度与发音特征的关系，为语音处理应用提供自动化口音分析和发音建模。

Method: 利用自监督学习发音反演技术估计发音特征，通过音素级差异量化口音强度，分析美英方言的发音参数。

Result: 舌位模式能区分美英方言，尤其在rhotic和低后元音上差异显著。

Conclusion: 研究为语音处理中的口音分析和发音建模提供了新方法。

Abstract: This paper explores the relationship between accent strength and articulatory
features inferred from acoustic speech. To quantify accent strength, we compare
phonetic transcriptions with transcriptions based on dictionary-based
references, computing phoneme-level difference as a measure of accent strength.
The proposed framework leverages recent self-supervised learning articulatory
inversion techniques to estimate articulatory features. Analyzing a corpus of
read speech from American and British English speakers, this study examines
correlations between derived articulatory parameters and accent strength
proxies, associating systematic articulatory differences with indexed accent
strength. Results indicate that tongue positioning patterns distinguish the two
dialects, with notable differences inter-dialects in rhotic and low back
vowels. These findings contribute to automated accent analysis and articulatory
modeling for speech processing applications.

</details>


### [33] [Traceable TTS: Toward Watermark-Free TTS with Strong Traceability](https://arxiv.org/abs/2507.03887)
*Yuxiang Zhao,Yunchong Xiao,Yushen Chen,Zhikang Niu,Shuai Wang,Kai Yu,Xie Chen*

Main category: eess.AS

TL;DR: 提出了一种无需水印的TTS模型溯源框架，通过联合训练提升溯源能力，同时保持语音质量。


<details>
  <summary>Details</summary>
Motivation: 现有TTS溯源方法依赖显式水印，会降低语音质量且易受欺骗，需改进。

Method: 采用联合训练方法训练TTS模型和判别器，避免嵌入水印。

Result: 显著提升溯源泛化能力，语音质量保持甚至略有提升。

Conclusion: 首次实现无强水印的高溯源能力TTS，代码将公开。

Abstract: Recent advances in Text-To-Speech (TTS) technology have enabled synthetic
speech to mimic human voices with remarkable realism, raising significant
security concerns. This underscores the need for traceable TTS models-systems
capable of tracing their synthesized speech without compromising quality or
security. However, existing methods predominantly rely on explicit watermarking
on speech or on vocoder, which degrades speech quality and is vulnerable to
spoofing. To address these limitations, we propose a novel framework for model
attribution. Instead of embedding watermarks, we train the TTS model and
discriminator using a joint training method that significantly improves
traceability generalization while preserving-and even slightly improving-audio
quality. This is the first work toward watermark-free TTS with strong
traceability. To promote progress in related fields, we will release the code
upon acceptance of the paper.

</details>


### [34] [Prosody Labeling with Phoneme-BERT and Speech Foundation Models](https://arxiv.org/abs/2507.03912)
*Tomoki Koriyama*

Main category: eess.AS

TL;DR: 提出一种自动韵律标注模型，结合声学和语言学特征，用于训练可控韵律的文本转语音模型。


<details>
  <summary>Details</summary>
Motivation: 提高韵律标注的准确性，以支持更自然的文本转语音合成。

Method: 结合自监督学习（SSL）和Whisper编码器的声学特征，以及PnG BERT和PL-BERT等语言学特征，预测音素级韵律标签。

Result: 在日语韵律标签（如音高重音和短语断点）上，结合声学和语言学特征的模型表现优于单一输入，准确率分别为89.8%、93.2%和94.3%。

Conclusion: 声学和语言学特征的结合显著提升了韵律标注的准确性。

Abstract: This paper proposes a model for automatic prosodic label annotation, where
the predicted labels can be used for training a prosody-controllable
text-to-speech model. The proposed model utilizes not only rich acoustic
features extracted by a self-supervised-learning (SSL)-based model or a Whisper
encoder, but also linguistic features obtained from phoneme-input pretrained
linguistic foundation models such as PnG BERT and PL-BERT. The concatenation of
acoustic and linguistic features is used to predict phoneme-level prosodic
labels. In the experimental evaluation on Japanese prosodic labels, including
pitch accents and phrase break indices, it was observed that the combination of
both speech and linguistic foundation models enhanced the prediction accuracy
compared to using either a speech or linguistic input alone. Specifically, we
achieved 89.8% prediction accuracy in accent labels, 93.2% in high-low pitch
accents, and 94.3% in break indices.

</details>


### [35] [MMMOS: Multi-domain Multi-axis Audio Quality Assessment](https://arxiv.org/abs/2507.04094)
*Yi-Cheng Lin,Jia-Hung Chen,Hung-yi Lee*

Main category: eess.AS

TL;DR: MMMOS是一种无参考、多领域音频质量评估系统，通过估计四个正交轴（制作质量、制作复杂性、内容享受和内容实用性）来改进现有单MOS预测模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有非侵入式评估模型仅预测单一MOS，无法涵盖多样化感知因素且泛化能力有限，需要更全面的音频质量评估方法。

Method: MMMOS融合了三个预训练编码器（WavLM、MuQ和M2D）的帧级嵌入，评估了三种聚合策略和四种损失函数，并集成前八个模型。

Result: MMMOS在均方误差上减少20-30%，Kendall's τ提高4-5%，在六个制作复杂性指标中排名第一，并在32个挑战指标中的17个中位列前三。

Conclusion: MMMOS通过多维度评估和集成策略显著提升了音频质量评估的准确性和泛化能力。

Abstract: Accurate audio quality estimation is essential for developing and evaluating
audio generation, retrieval, and enhancement systems. Existing non-intrusive
assessment models predict a single Mean Opinion Score (MOS) for speech, merging
diverse perceptual factors and failing to generalize beyond speech. We propose
MMMOS, a no-reference, multi-domain audio quality assessment system that
estimates four orthogonal axes: Production Quality, Production Complexity,
Content Enjoyment, and Content Usefulness across speech, music, and
environmental sounds. MMMOS fuses frame-level embeddings from three pretrained
encoders (WavLM, MuQ, and M2D) and evaluates three aggregation strategies with
four loss functions. By ensembling the top eight models, MMMOS shows a 20-30%
reduction in mean squared error and a 4-5% increase in Kendall's {\tau} versus
baseline, gains first place in six of eight Production Complexity metrics, and
ranks among the top three on 17 of 32 challenge metrics.

</details>


### [36] [Ambisonics Encoder for Wearable Array with Improved Binaural Reproduction](https://arxiv.org/abs/2507.04108)
*Yhonatan Gayer,Vladimir Tourbabin,Zamir Ben-Hur,David Alon,Boaz Rafaely*

Main category: eess.AS

TL;DR: 研究提出了一种改进的Ambisonics信号匹配（ASM）编码器，通过将双耳信号匹配（BSM）项整合到优化框架中，提高了双耳再现的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前Ambisonics信号从可穿戴麦克风阵列编码的准确性受限于麦克风的非理想布局，影响了双耳再现的质量。

Method: 研究引入了改进的ASM编码器，通过将BSM项整合到损失函数中，优化了Ambisonic信号与头相关传递函数（HRTFs）的结合。

Result: 模拟研究表明，联合ASM-BSM优化可以显著提高双耳再现的准确性。

Conclusion: 改进的ASM编码器能够为虚拟和增强现实应用提供更高质量的Ambisonics双耳播放。

Abstract: Ambisonics Signal Matching (ASM) is a recently proposed signal-independent
approach to encoding Ambisonic signal from wearable microphone arrays, enabling
efficient and standardized spatial sound reproduction. However, reproduction
accuracy is currently limited due to the non-ideal layout of the microphones.
This research introduces an enhanced ASM encoder that reformulates the loss
function by integrating a Binaural Signal Matching (BSM) term into the
optimization framework. The aim of this reformulation is to improve the
accuracy of binaural reproduction when integrating the Ambisonic signal with
Head-Related Transfer Functions (HRTFs), making the encoded Ambisonic signal
better suited for binaural reproduction. This paper first presents the
mathematical formulation developed to align the ASM and BSM objectives in a
single loss function, followed by a simulation study with a simulated
microphone array mounted on a rigid sphere representing a head-mounted wearable
array. The analysis shows that improved binaural reproduction with the encoded
Ambisonic signal can be achieved using this joint ASM-BSM optimization, thereby
enabling higher-quality binaural playback for virtual and augmented reality
applications based on Ambisonics.

</details>


### [37] [The Overview of Segmental Durations Modification Algorithms on Speech Signal Characteristics](https://arxiv.org/abs/2507.04264)
*Kyeomeun Jang,Jiaying Li,Yinuo Wang*

Main category: eess.AS

TL;DR: 本文深入评估和分析了多种主流算法，这些算法可以任意修改语音信号的持续时间而不改变其基本特性（如音高轮廓、功率谱等）。


<details>
  <summary>Details</summary>
Motivation: 研究动机是为了实现语音信号中任意区域的持续时间修改，同时保持信号的关键特性不变，以满足多样化的应用需求。

Method: 方法包括通过指定修改的起始和结束时间或目标持续时间（固定值或缩放因子），同时支持同时修改多个区间。

Result: 结果表明，这些算法能够有效实现任意区域的持续时间修改，且不影响信号的基本特性。

Conclusion: 结论是这些算法为语音信号处理提供了灵活且高效的解决方案，适用于多种应用场景。

Abstract: This paper deeply evaluates and analyzes several mainstream algorithms that
can arbitrarily modify the duration of any portion of a given speech signal
without changing the essential properties (e.g., pitch contour, power spectrum,
etc.) of the original signal. Arbitrary modification in this context means that
the duration of any region of the signal can be changed by specifying the
starting and ending time for modification or the target duration of the
specified interval, which can be either a fixed value of duration in the time
domain or a scaling factor of the original duration. In addition, arbitrary
modification also indicates any number of intervals can be modified at the same
time.

</details>


### [38] [Long-Context Modeling Networks for Monaural Speech Enhancement: A Comparative Study](https://arxiv.org/abs/2507.04368)
*Qiquan Zhang,Moran Chen,Zeyang Song,Hexin Liu,Xiangyu Zhang,Haizhou Li*

Main category: eess.AS

TL;DR: 本文比较了Transformer、Conformer、Mamba和xLSTM在语音增强中的表现，发现xLSTM和Mamba优于其他模型，但xLSTM处理速度最慢。


<details>
  <summary>Details</summary>
Motivation: 缺乏对多种长上下文建模骨干网络在统一语音增强框架下的系统比较，以及探索xLSTM在语音增强中的潜力。

Method: 在统一框架下比较Transformer、Conformer、Mamba和xLSTM，考虑因果和非因果配置。

Result: xLSTM和Mamba性能优于Transformer和Conformer，Mamba在长语音输入时效率最高，xLSTM处理速度最慢。

Conclusion: xLSTM和Mamba在语音增强中表现优异，但需权衡性能和效率。

Abstract: Advanced long-context modeling backbone networks, such as Transformer,
Conformer, and Mamba, have demonstrated state-of-the-art performance in speech
enhancement. However, a systematic and comprehensive comparative study of these
backbones within a unified speech enhancement framework remains lacking. In
addition, xLSTM, a more recent and efficient variant of LSTM, has shown
promising results in language modeling and as a general-purpose vision
backbone. In this paper, we investigate the capability of xLSTM in speech
enhancement, and conduct a comprehensive comparison and analysis of the
Transformer, Conformer, Mamba, and xLSTM backbones within a unified framework,
considering both causal and noncausal configurations. Overall, xLSTM and Mamba
achieve better performance than Transformer and Conformer. Mamba demonstrates
significantly superior training and inference efficiency, particularly for long
speech inputs, whereas xLSTM suffers from the slowest processing speed.

</details>


### [39] [Spatial and Semantic Embedding Integration for Stereo Sound Event Localization and Detection in Regular Videos](https://arxiv.org/abs/2507.04845)
*Davide Berghi,Philip J. B. Jackson*

Main category: eess.AS

TL;DR: 本文介绍了针对DCASE2025任务3挑战赛的音频和音视频系统的改进方法，通过结合预训练语言对齐模型和跨模态融合，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统SELD架构因多通道输入限制而难以利用大规模预训练的问题，同时提升语义建模能力。

Method: 整合CLAP（音频）和OWL-ViT（视觉）的预训练模型，设计跨模态Conformer模块，并引入自相关声学特征和左右声道交换增强。

Result: 音频和音视频系统在开发集上显著超越基线，模型集成和视觉后处理进一步提升了性能。

Conclusion: 证明了跨模态融合和预训练模型的有效性，未来将探索各模态贡献和架构变体。

Abstract: This report presents our systems submitted to the audio-only and audio-visual
tracks of the DCASE2025 Task 3 Challenge: Stereo Sound Event Localization and
Detection (SELD) in Regular Video Content. SELD is a complex task that combines
temporal event classification with spatial localization, requiring reasoning
across spatial, temporal, and semantic dimensions. The last is arguably the
most challenging to model. Traditional SELD architectures rely on multichannel
input, which limits their ability to leverage large-scale pre-training due to
data constraints. To address this, we enhance standard SELD architectures with
semantic information by integrating pre-trained, contrastive language-aligned
models: CLAP for audio and OWL-ViT for visual inputs. These embeddings are
incorporated into a modified Conformer module tailored for multimodal fusion,
which we refer to as the Cross-Modal Conformer. Additionally, we incorporate
autocorrelation-based acoustic features to improve distance estimation. We
pre-train our models on curated synthetic audio and audio-visual datasets and
apply a left-right channel swapping augmentation to further increase the
training data. Both our audio-only and audio-visual systems substantially
outperform the challenge baselines on the development set, demonstrating the
effectiveness of our strategy. Performance is further improved through model
ensembling and a visual post-processing step based on human keypoints. Future
work will investigate the contribution of each modality and explore
architectural variants to further enhance results.

</details>


### [40] [Adaptive Slimming for Scalable and Efficient Speech Enhancement](https://arxiv.org/abs/2507.04879)
*Riccardo Miccini,Minje Kim,Clément Laroche,Luca Pezzarossa,Paris Smaragdis*

Main category: eess.AS

TL;DR: 论文提出了一种动态剪枝方法，应用于DEMUCS语音增强架构，使其能够根据输入自适应调整计算资源，实现性能与效率的动态平衡。


<details>
  <summary>Details</summary>
Motivation: 在资源受限设备上部署语音增强系统时，通常需要在性能与计算效率之间静态权衡。本文旨在通过动态剪枝技术解决这一问题。

Method: 引入动态剪枝技术，使DEMUCS模型能够以不同的利用率因子（UF）运行，并通过路由子网自适应选择最优UF。

Result: 动态剪枝模型在平均使用10%容量的情况下，语音质量与静态25%利用率相当或更好，同时减少29%的乘法累加运算（MACs）。

Conclusion: 动态路由的引入实现了Pareto最优，显著提升了资源利用效率。

Abstract: Speech enhancement (SE) enables robust speech recognition, real-time
communication, hearing aids, and other applications where speech quality is
crucial. However, deploying such systems on resource-constrained devices
involves choosing a static trade-off between performance and computational
efficiency. In this paper, we introduce dynamic slimming to DEMUCS, a popular
SE architecture, making it scalable and input-adaptive. Slimming lets the model
operate at different utilization factors (UF), each corresponding to a
different performance/efficiency trade-off, effectively mimicking multiple
model sizes without the extra storage costs. In addition, a router subnet,
trained end-to-end with the backbone, determines the optimal UF for the current
input. Thus, the system saves resources by adaptively selecting smaller UFs
when additional complexity is unnecessary. We show that our solution is
Pareto-optimal against individual UFs, confirming the benefits of dynamic
routing. When training the proposed dynamically-slimmable model to use 10% of
its capacity on average, we obtain the same or better speech quality as the
equivalent static 25% utilization while reducing MACs by 29%.

</details>


### [41] [The Extended SONICOM HRTF Dataset and Spatial Audio Metrics Toolbox](https://arxiv.org/abs/2507.05053)
*Katarina C. Poole,Julie Meyer,Vincent Martin,Rapolas Daugintis,Nils Marggraf-Turley,Jack Webb,Ludovic Pirard,Nicola La Magna,Oliver Turvey,Lorenzo Picinali*

Main category: eess.AS

TL;DR: 扩展的SONICOM HRTF数据集增加了测量对象至300人，包含合成HRTF和优化扫描，支持HRTF算法优化和机器学习研究，并提供了SAM工具箱用于数据分析。


<details>
  <summary>Details</summary>
Motivation: 提升个性化空间音频研究的效率和准确性，通过扩展数据集和工具支持更广泛的HRTF分析和合成。

Method: 扩展数据集至300人，使用Mesh2HRTF合成200人的HRTF，优化3D扫描数据，并开发SAM工具箱用于数据分析。

Result: 提供了更丰富的HRTF数据集和工具，支持算法优化、机器学习研究和形态学分析。

Conclusion: 扩展的SONICOM HRTF数据集和SAM工具箱为个性化空间音频研究提供了全面的资源。

Abstract: Headphone-based spatial audio uses head-related transfer functions (HRTFs) to
simulate real-world acoustic environments. HRTFs are unique to everyone, due to
personal morphology, shaping how sound waves interact with the body before
reaching the eardrums. Here we present the extended SONICOM HRTF dataset which
expands on the previous version released in 2023. The total number of measured
subjects has now been increased to 300, with demographic information for a
subset of the participants, providing context for the dataset's population and
relevance. The dataset incorporates synthesised HRTFs for 200 of the 300
subjects, generated using Mesh2HRTF, alongside pre-processed 3D scans of the
head and ears, optimised for HRTF synthesis. This rich dataset facilitates
rapid and iterative optimisation of HRTF synthesis algorithms, allowing the
automatic generation of large data. The optimised scans enable seamless
morphological modifications, providing insights into how anatomical changes
impact HRTFs, and the larger sample size enhances the effectiveness of machine
learning approaches. To support analysis, we also introduce the Spatial Audio
Metrics (SAM) Toolbox, a Python package designed for efficient analysis and
visualisation of HRTF data, offering customisable tools for advanced research.
Together, the extended dataset and toolbox offer a comprehensive resource for
advancing personalised spatial audio research and development.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [42] [Audio-JEPA: Joint-Embedding Predictive Architecture for Audio Representation Learning](https://arxiv.org/abs/2507.02915)
*Ludovic Tuncay,Etienne Labbé,Emmanouil Benetos,Thomas Pellegrini*

Main category: cs.SD

TL;DR: Audio-JEPA是一种基于JEPA框架的自监督学习方法，专为音频数据设计，通过预测掩码频谱块的潜在表示而非原始音频重构，性能与wav2vec 2.0和data2vec相当，但训练数据量更少。


<details>
  <summary>Details</summary>
Motivation: 针对音频数据的自监督学习需求，提出Audio-JEPA，旨在高效预测音频特征表示，减少训练数据依赖。

Method: 使用Vision Transformer主干网络，预测掩码的mel-spectrogram块的潜在表示，预训练基于AudioSet的无标签数据。

Result: 在X-ARES测试集（涵盖语音、音乐和环境声音任务）上表现与wav2vec 2.0和data2vec相当，训练数据量仅为它们的五分之一。

Conclusion: Audio-JEPA展示了在音频任务中的高效性，代码和预训练模型将开源。

Abstract: Building on the Joint-Embedding Predictive Architecture (JEPA) paradigm, a
recent self-supervised learning framework that predicts latent representations
of masked regions in high-level feature spaces, we propose Audio-JEPA (Audio
Joint-Embedding Predictive Architecture), tailored specifically for audio data.
Audio-JEPA uses a simple Vision Transformer backbone to predict latent
representations of masked spectrogram patches rather than reconstructing raw
audio. We pre-train on unlabeled AudioSet clips (10s, 32kHz) with random patch
masking on mel-spectrograms. We evaluate on the X-ARES suite covering speech,
music, and environmental sound tasks. Although our implementation is a
straightforward translation of the original model to audio, the results still
show comparable performance to wav2vec 2.0 and data2vec while using less than
one-fifth of their training data and with no hyper-parameter tuning. All code
and pretrained checkpoints will be released on GitHub.

</details>


### [43] [Toward Efficient Speech Emotion Recognition via Spectral Learning and Attention](https://arxiv.org/abs/2507.03251)
*HyeYoung Lee,Muhammad Nadeem*

Main category: cs.SD

TL;DR: 提出了一种基于1D-CNN和注意力机制的语音情感识别方法，通过MFCC特征和数据增强技术显著提升了模型性能，在多个数据集上达到高准确率。


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别方法难以捕捉细微情感变化且泛化能力不足，需改进以提升性能。

Method: 使用MFCC作为特征，结合数据增强和1D-CNN架构，引入通道和空间注意力机制以突出关键情感模式。

Result: 在多个数据集上表现优异，最高准确率达99.82%。

Conclusion: 该方法显著提升了语音情感识别的精度和泛化能力，适用于实际应用如辅助技术和人机交互。

Abstract: Speech Emotion Recognition (SER) traditionally relies on auditory data
analysis for emotion classification. Several studies have adopted different
methods for SER. However, existing SER methods often struggle to capture subtle
emotional variations and generalize across diverse datasets. In this article,
we use Mel-Frequency Cepstral Coefficients (MFCCs) as spectral features to
bridge the gap between computational emotion processing and human auditory
perception. To further improve robustness and feature diversity, we propose a
novel 1D-CNN-based SER framework that integrates data augmentation techniques.
MFCC features extracted from the augmented data are processed using a 1D
Convolutional Neural Network (CNN) architecture enhanced with channel and
spatial attention mechanisms. These attention modules allow the model to
highlight key emotional patterns, enhancing its ability to capture subtle
variations in speech signals. The proposed method delivers cutting-edge
performance, achieving the accuracy of 97.49% for SAVEE, 99.23% for RAVDESS,
89.31% for CREMA-D, 99.82% for TESS, 99.53% for EMO-DB, and 96.39% for EMOVO.
Experimental results show new benchmarks in SER, demonstrating the
effectiveness of our approach in recognizing emotional expressions with high
precision. Our evaluation demonstrates that the integration of advanced Deep
Learning (DL) methods substantially enhances generalization across diverse
datasets, underscoring their potential to advance SER for real-world deployment
in assistive technologies and human-computer interaction.

</details>


### [44] [Eigenvoice Synthesis based on Model Editing for Speaker Generation](https://arxiv.org/abs/2507.03377)
*Masato Murata,Koichi Miyazaki,Tomoki Koriyama,Tomoki Toda*

Main category: cs.SD

TL;DR: 提出了一种基于DNN的特征语音合成方法，通过模型编辑定义说话人空间，直接采样生成多样说话人语音。


<details>
  <summary>Details</summary>
Motivation: 说话人生成任务的关键是定义能代表多样说话人的空间，但现有方法对此尚不明确。

Method: 提出DNN基于特征语音合成方法，在DNN模型参数空间中定义说话人空间，直接采样新参数生成语音。

Result: 实验证明方法能生成多样说话人语音，并发现性别主导轴，可控制说话人属性。

Conclusion: 该方法有效定义说话人空间并生成多样语音，为说话人属性控制提供潜力。

Abstract: Speaker generation task aims to create unseen speaker voice without reference
speech. The key to the task is defining a speaker space that represents diverse
speakers to determine the generated speaker trait. However, the effective way
to define this speaker space remains unclear. Eigenvoice synthesis is one of
the promising approaches in the traditional parametric synthesis framework,
such as HMM-based methods, which define a low-dimensional speaker space using
pre-stored speaker features. This study proposes a novel DNN-based eigenvoice
synthesis method via model editing. Unlike prior methods, our method defines a
speaker space in the DNN model parameter space. By directly sampling new DNN
model parameters in this space, we can create diverse speaker voices.
Experimental results showed the capability of our method to generate diverse
speakers' speech. Moreover, we discovered a gender-dominant axis in the created
speaker space, indicating the potential to control speaker attributes.

</details>


### [45] [Speaker-agnostic Emotion Vector for Cross-speaker Emotion Intensity Control](https://arxiv.org/abs/2507.03382)
*Masato Murata,Koichi Miyazaki,Tomoki Koriyama*

Main category: cs.SD

TL;DR: 提出了一种跨说话者的情感强度控制方法，通过使用说话者无关的情感向量，解决了现有方法在跨说话者设置中失去说话者一致性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法（情感算术）在跨说话者设置中因情感向量不匹配而失去说话者一致性，需要改进。

Method: 提出了一种说话者无关的情感向量，用于捕捉多说话者共享的情感表达，适用于任意说话者。

Result: 实验表明，该方法在跨说话者情感强度控制中成功保持了说话者一致性、语音质量和可控性，即使对未见过的说话者也有效。

Conclusion: 说话者无关的情感向量方法在跨说话者情感强度控制中表现优异，解决了现有方法的局限性。

Abstract: Cross-speaker emotion intensity control aims to generate emotional speech of
a target speaker with desired emotion intensities using only their neutral
speech. A recently proposed method, emotion arithmetic, achieves emotion
intensity control using a single-speaker emotion vector. Although this prior
method has shown promising results in the same-speaker setting, it lost speaker
consistency in the cross-speaker setting due to mismatches between the emotion
vector of the source and target speakers. To overcome this limitation, we
propose a speaker-agnostic emotion vector designed to capture shared emotional
expressions across multiple speakers. This speaker-agnostic emotion vector is
applicable to arbitrary speakers. Experimental results demonstrate that the
proposed method succeeds in cross-speaker emotion intensity control while
maintaining speaker consistency, speech quality, and controllability, even in
the unseen speaker case.

</details>


### [46] [MaskBeat: Loopable Drum Beat Generation](https://arxiv.org/abs/2507.03395)
*Luca A. Lanzendörfer,Florian Grötschla,Karim Galal,Roger Wattenhofer*

Main category: cs.SD

TL;DR: MaskBeat是一种基于Transformer的方法，用于生成可循环的鼓点模式，通过双向注意力和迭代优化实现并行生成，并引入鼓点特定的损失函数。


<details>
  <summary>Details</summary>
Motivation: 传统的鼓点生成方法通常是顺序预测，缺乏并行性和音乐连贯性，MaskBeat旨在解决这一问题。

Method: 使用双向注意力和迭代优化，并行生成鼓点，同时引入鼓点特定的损失函数以捕捉音乐关系。

Result: 实验表明，MaskBeat生成的鼓点模式质量更高，音乐连贯性优于基线方法。

Conclusion: MaskBeat通过并行生成和鼓点特定优化，显著提升了鼓点生成的质量和连贯性。

Abstract: We present MaskBeat, a transformer-based approach for loopable drum pattern
generation. Rather than predicting drum hits sequentially, our method uses
bidirectional attention with iterative refinement, allowing instruments to be
generated in parallel while maintaining musical coherence. Additionally, we
introduce custom loss functions that capture drum-specific musical
relationships. Our experiments show that MaskBeat generates higher quality and
more musically coherent drum patterns than baseline approaches.

</details>


### [47] [Direction Estimation of Sound Sources Using Microphone Arrays and Signal Strength](https://arxiv.org/abs/2507.03466)
*Mahdi Ali Pour,Utku Gunay Acer*

Main category: cs.SD

TL;DR: 本文提出了一种基于三个驻极体麦克风的轻量级声源方向追踪方法，通过信号功率比较实现高精度方向估计。


<details>
  <summary>Details</summary>
Motivation: 声源方向追踪在安全系统、声学监测等领域至关重要，但现有系统面临精度和硬件复杂度挑战。

Method: 使用三个麦克风，通过分析信号平均功率推断声源方向。

Result: 系统定位误差小于6度，精度达98%，硬件设计简单且成本低。

Conclusion: 该方法为声源追踪提供了高效、可靠的解决方案，适用于多种应用场景。

Abstract: Sound-tracking refers to the process of determining the direction from which
a sound originates, making it a fundamental component of sound source
localization. This capability is essential in a variety of applications,
including security systems, acoustic monitoring, and speaker tracking, where
accurately identifying the direction of a sound source enables real-time
responses, efficient resource allocation, and improved situational awareness.
While sound-tracking is closely related to localization, it specifically
focuses on identifying the direction of the sound source rather than estimating
its exact position in space. Despite its utility, sound-tracking systems face
several challenges, such as maintaining directional accuracy and precision,
along with the need for sophisticated hardware configurations and complex
signal processing algorithms. This paper presents a sound-tracking method using
three electret microphones. We estimate the direction of a sound source using a
lightweight method that analyzes signals from three strategically placed
microphones. By comparing the average power of the received signals, the system
infers the most probable direction of the sound. The results indicate that the
power level from each microphone effectively determines the sound source
direction. Our system employs a straightforward and cost-effective hardware
design, ensuring simplicity and affordability in implementation. It achieves a
localization error of less than 6 degrees and a precision of 98%. Additionally,
its effortless integration with various systems makes it versatile and
adaptable. Consequently, this technique presents a robust and reliable solution
for sound-tracking and localization, with potential applications spanning
diverse domains such as security systems, smart homes, and acoustic monitoring.

</details>


### [48] [Robust Localization of Partially Fake Speech: Metrics, Models, and Out-of-Domain Evaluation](https://arxiv.org/abs/2507.03468)
*Hieu-Thi Luong,Inbal Rimons,Haim Permuter,Kong Aik Lee,Eng Siong Chng*

Main category: cs.SD

TL;DR: 论文探讨了部分音频深度伪造定位的挑战，指出当前评估方法（如EER）的局限性，并提出将其重构为序列异常检测问题，使用阈值依赖指标更符合实际需求。


<details>
  <summary>Details</summary>
Motivation: 部分音频深度伪造定位的研究较少，且现有方法在实际应用中的效果不明确，因此需要重新评估其性能。

Method: 将定位任务重构为序列异常检测问题，并使用精度、召回率等阈值依赖指标。分析了CFPRF框架的性能。

Result: CFPRF在域内数据上表现较好（7.61% EER），但在域外数据上表现较差（43.25%和27.59% EER）。增加部分伪造音频训练数据可提升性能。

Conclusion: 过度优化域内EER可能导致模型在真实场景中表现不佳，需改进评估方法并关注域外泛化能力。

Abstract: Partial audio deepfake localization pose unique challenges and remain
underexplored compared to full-utterance spoofing detection. While recent
methods report strong in-domain performance, their real-world utility remains
unclear. In this analysis, we critically examine the limitations of current
evaluation practices, particularly the widespread use of Equal Error Rate
(EER), which often obscures generalization and deployment readiness. We propose
reframing the localization task as a sequential anomaly detection problem and
advocate for the use of threshold-dependent metrics such as accuracy,
precision, recall, and F1-score, which better reflect real-world behavior.
Specifically, we analyze the performance of the open-source Coarse-to-Fine
Proposal Refinement Framework (CFPRF), which achieves a 20-ms EER of 7.61% on
the in-domain PartialSpoof evaluation set, but 43.25% and 27.59% on the
LlamaPartialSpoof and Half-Truth out-of-domain test sets. Interestingly, our
reproduced version of the same model performs worse on in-domain data (9.84%)
but better on the out-of-domain sets (41.72% and 14.98%, respectively). This
highlights the risks of over-optimizing for in-domain EER, which can lead to
models that perform poorly in real-world scenarios. It also suggests that while
deep learning models can be effective on in-domain data, they generalize poorly
to out-of-domain scenarios, failing to detect novel synthetic samples and
misclassifying unfamiliar bona fide audio. Finally, we observe that adding more
bona fide or fully synthetic utterances to the training data often degrades
performance, whereas adding partially fake utterances improves it.

</details>


### [49] [OMAR-RQ: Open Music Audio Representation Model Trained with Multi-Feature Masked Token Prediction](https://arxiv.org/abs/2507.03482)
*Pablo Alonso-Jiménez,Pedro Ramoneda,R. Oguz Araz,Andrea Poltronieri,Dmitry Bogdanov*

Main category: cs.SD

TL;DR: OMAR-RQ是一个开源的自监督音乐音频理解基础模型，通过掩码标记分类方法训练，在多个音乐信息检索任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 推动音乐音频理解研究，提供强大的多用途音乐信息检索表示。

Method: 使用自监督学习（掩码标记分类）和大规模音乐音频数据集（330,000小时）训练模型，并尝试不同输入特征和量化选项。

Result: 在音乐标记、音高估计、和弦识别、节拍跟踪、分割和难度估计等任务中表现优异。

Conclusion: 开源了训练和评估流程及模型权重，促进研究社区的发展。

Abstract: Developing open-source foundation models is essential for advancing research
in music audio understanding and ensuring access to powerful, multipurpose
representations for music information retrieval. We present OMAR-RQ, a model
trained with self-supervision via masked token classification methodologies
using a large-scale dataset with over 330,000 hours of music audio. We
experiment with different input features and quantization options, and achieve
state-of-the-art performance in music tagging, pitch estimation, chord
recognition, beat tracking, segmentation, and difficulty estimation among open
self-supervised models. We open-source our training and evaluation pipelines
and model weights, available at https://github.com/mtg/omar-rq.

</details>


### [50] [RECA-PD: A Robust Explainable Cross-Attention Method for Speech-based Parkinson's Disease Classification](https://arxiv.org/abs/2507.03594)
*Terry Yi Zhong,Cristian Tejedor-Garcia,Martha Larson,Bastiaan R. Bloem*

Main category: cs.SD

TL;DR: RECA-PD是一种新型、鲁棒且可解释的交叉注意力架构，用于基于语音的帕金森病早期检测，兼具高准确性和临床可解释性。


<details>
  <summary>Details</summary>
Motivation: 帕金森病（PD）影响全球超过1000万人，语音障碍常早于运动症状多年出现，因此语音成为早期非侵入性检测的重要模态。现有深度学习模型虽准确率高，但缺乏临床所需的可解释性。

Method: 提出RECA-PD架构，结合可解释的语音特征与自监督表示，通过交叉注意力机制实现高准确性和临床意义的解释。

Result: RECA-PD在语音PD检测中达到最先进性能，并提供更一致且临床有意义的解释。此外，通过分段长录音可缓解某些语音任务（如独白）的性能下降。

Conclusion: 研究表明性能和可解释性并非互斥。未来工作将提升解释对非专家的可用性，并探索严重程度估计以增强临床实用性。

Abstract: Parkinson's Disease (PD) affects over 10 million people globally, with speech
impairments often preceding motor symptoms by years, making speech a valuable
modality for early, non-invasive detection. While recent deep-learning models
achieve high accuracy, they typically lack the explainability required for
clinical use. To address this, we propose RECA-PD, a novel, robust, and
explainable cross-attention architecture that combines interpretable speech
features with self-supervised representations. RECA-PD matches state-of-the-art
performance in Speech-based PD detection while providing explanations that are
more consistent and more clinically meaningful. Additionally, we demonstrate
that performance degradation in certain speech tasks (e.g., monologue) can be
mitigated by segmenting long recordings. Our findings indicate that performance
and explainability are not necessarily mutually exclusive. Future work will
enhance the usability of explanations for non-experts and explore severity
estimation to increase the real-world clinical relevance.

</details>


### [51] [MusGO: A Community-Driven Framework For Assessing Openness in Music-Generative AI](https://arxiv.org/abs/2507.03599)
*Roser Batlle-Roca,Laura Ibáñez-Martínez,Xavier Serra,Emilia Gómez,Martín Rocamora*

Main category: cs.SD

TL;DR: 本文提出MusGO框架，用于评估音乐生成AI的开放性，基于13个类别（8个必需，5个可选），并评估了16个先进模型。


<details>
  <summary>Details</summary>
Motivation: 解决音乐生成AI中的伦理挑战，如透明度和责任问题，并推动开放模型的明确定义。

Method: 改编LLM开放性评估框架至音乐领域，通过MIR社区110名参与者的反馈完善为MusGO框架。

Result: 评估了16个模型，提供开放性排行榜，并公开接受公众和社区监督。

Conclusion: 旨在明确音乐生成AI的开放性概念，促进其透明和负责任的发展。

Abstract: Since 2023, generative AI has rapidly advanced in the music domain. Despite
significant technological advancements, music-generative models raise critical
ethical challenges, including a lack of transparency and accountability, along
with risks such as the replication of artists' works, which highlights the
importance of fostering openness. With upcoming regulations such as the EU AI
Act encouraging open models, many generative models are being released labelled
as 'open'. However, the definition of an open model remains widely debated. In
this article, we adapt a recently proposed evidence-based framework for
assessing openness in LLMs to the music domain. Using feedback from a survey of
110 participants from the Music Information Retrieval (MIR) community, we
refine the framework into MusGO (Music-Generative Open AI), which comprises 13
openness categories: 8 essential and 5 desirable. We evaluate 16
state-of-the-art generative models and provide an openness leaderboard that is
fully open to public scrutiny and community contributions. Through this work,
we aim to clarify the concept of openness in music-generative AI and promote
its transparent and responsible development.

</details>


### [52] [CLEP-DG: Contrastive Learning for Speech Emotion Domain Generalization via Soft Prompt Tuning](https://arxiv.org/abs/2507.04048)
*Jiacheng Shi,Yanfu Zhang,Ye Gao*

Main category: cs.SD

TL;DR: CLEP-DG框架通过改进CLAP模型，结合情感数据集微调和声学上下文提示调优，提升了语音情感识别的跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有语音情感识别模型在多样化声学条件下泛化能力不足，CLAP模型虽有多模态对齐能力，但缺乏专门的情感线索捕捉机制。

Method: 1. 微调CLAP得到CLEP，适应情感数据集；2. 引入ACPT策略，优化提示向量建模声学环境；3. 利用跨模态可迁移性训练分类器。

Result: 在五个基准数据集上，CLEP-DG优于现有CLAP方法，在监督和域泛化设置中均达到最优性能。

Conclusion: CLEP-DG通过改进CLAP和引入新策略，显著提升了语音情感识别的泛化能力和性能。

Abstract: Speech Emotion Recognition (SER) is fundamental to affective computing and
human-computer interaction, yet existing models struggle to generalize across
diverse acoustic conditions. While Contrastive Language-Audio Pretraining
(CLAP) provides strong multimodal alignment, it lacks dedicated mechanisms for
capturing emotional cues, making it suboptimal for SER. To address this, we
propose CLEP-DG, a framework that enhances CLAP's robustness in emotion
recognition. First, we fine-tune CLAP to obtain CLEP, adapting it on
large-scale emotional speech datasets to better encode emotion-relevant
features. Then, we introduce Acoustic Context Prompt Tuning (ACPT), a
text-driven augmentation strategy that optimizes learnable prompt vectors to
model diverse acoustic environments without additional labeled audio. Finally,
leveraging cross-modal transferability, we train a classifier on text-derived
embeddings and apply it to the audio encoder during inference, mitigating
domain shifts between textual supervision and audio-based emotion recognition.
Experiments across five benchmark datasets show that CLEP-DG outperforms prior
CLAP-based approaches, achieving state-of-the-art performance in both
supervised and domain generalization settings.

</details>


### [53] [High-Resolution Sustain Pedal Depth Estimation from Piano Audio Across Room Acoustics](https://arxiv.org/abs/2507.04230)
*Kun Fang,Hanwen Zhang,Ziyu Wang,Ichiro Fujinaga*

Main category: cs.SD

TL;DR: 本文提出了一种基于Transformer的高分辨率钢琴延音踏板深度估计方法，优于传统的二进制分类方法，并探讨了房间声学对估计的影响。


<details>
  <summary>Details</summary>
Motivation: 传统二进制分类方法无法捕捉踏板深度对音乐表达的细微影响，限制了实际应用。

Method: 采用Transformer架构进行连续踏板深度估计，并通过合成数据集研究房间声学的影响。

Result: 模型在二进制分类任务中表现优异，且在连续深度估计中提供更有音乐意义的预测；但模型对未见房间声学条件不鲁棒。

Conclusion: 连续踏板深度估计优于二进制方法，但房间声学条件对模型预测有显著影响，需进一步优化鲁棒性。

Abstract: Piano sustain pedal detection has previously been approached as a binary
on/off classification task, limiting its application in real-world piano
performance scenarios where pedal depth significantly influences musical
expression. This paper presents a novel approach for high-resolution estimation
that predicts continuous pedal depth values. We introduce a Transformer-based
architecture that not only matches state-of-the-art performance on the
traditional binary classification task but also achieves high accuracy in
continuous pedal depth estimation. Furthermore, by estimating continuous
values, our model provides musically meaningful predictions for sustain pedal
usage, whereas baseline models struggle to capture such nuanced expressions
with their binary detection approach. Additionally, this paper investigates the
influence of room acoustics on sustain pedal estimation using a synthetic
dataset that includes varied acoustic conditions. We train our model with
different combinations of room settings and test it in an unseen new
environment using a "leave-one-out" approach. Our findings show that the two
baseline models and ours are not robust to unseen room conditions. Statistical
analysis further confirms that reverberation influences model predictions and
introduces an overestimation bias.

</details>


### [54] [TTS-CtrlNet: Time varying emotion aligned text-to-speech generation with ControlNet](https://arxiv.org/abs/2507.04349)
*Jaeseok Jeong,Yuna Lee,Mingi Kwon,Youngjung Uh*

Main category: cs.SD

TL;DR: 提出了一种基于ControlNet的可控流匹配TTS方法（TTS-CtrlNet），通过冻结原始模型并引入可训练副本处理额外条件，实现细粒度、时变情感控制。


<details>
  <summary>Details</summary>
Motivation: 现有TTS方法通常仅支持语句级情感控制，且需大规模情感语音数据集进行微调，可能影响性能。

Method: 采用ControlNet思想，冻结原始TTS模型并引入可训练副本处理情感条件，提供架构设计、情感特定流步骤和灵活控制比例的实用方案。

Result: 实验表明TTS-CtrlNet能有效为现有TTS添加情感控制器，在情感相似性评分（Emo-SIM和Aro-Val SIM）上达到最优性能。

Conclusion: TTS-CtrlNet通过引入ControlNet实现了细粒度情感控制，同时保留了原始模型的零样本语音克隆和自然性能力。

Abstract: Recent advances in text-to-speech (TTS) have enabled natural speech
synthesis, but fine-grained, time-varying emotion control remains challenging.
Existing methods often allow only utterance-level control and require full
model fine-tuning with a large emotion speech dataset, which can degrade
performance. Inspired by adding conditional control to the existing model in
ControlNet (Zhang et al, 2023), we propose the first ControlNet-based approach
for controllable flow-matching TTS (TTS-CtrlNet), which freezes the original
model and introduces a trainable copy of it to process additional conditions.
We show that TTS-CtrlNet can boost the pretrained large TTS model by adding
intuitive, scalable, and time-varying emotion control while inheriting the
ability of the original model (e.g., zero-shot voice cloning & naturalness).
Furthermore, we provide practical recipes for adding emotion control: 1)
optimal architecture design choice with block analysis, 2) emotion-specific
flow step, and 3) flexible control scale.
  Experiments show that ours can effectively add an emotion controller to
existing TTS, and achieves state-of-the-art performance with emotion similarity
scores: Emo-SIM and Aro-Val SIM. The project page is available at:
https://curryjung.github.io/ttsctrlnet_project_page

</details>


### [55] [Machine Learning in Acoustics: A Review and Open-Source Repository](https://arxiv.org/abs/2507.04419)
*Ryan A. McCarthy,You Zhang,Samuel A. Verburg,William F. Jenkins,Peter Gerstoft*

Main category: cs.SD

TL;DR: 综述了机器学习（ML）在声学领域的应用，展示了Python实现的ML技术，包括分类、回归和生成模型，并提供了开源工具AcousticsML。


<details>
  <summary>Details</summary>
Motivation: 探讨ML在声学中的潜力，推动数据驱动方法的应用。

Method: 使用Python和深度学习技术，通过Jupyter笔记本示例展示ML在声学数据中的分类、生成和物理约束建模。

Result: 展示了ML在声学中的多样化应用，如分类、空间音频生成和物理信息神经网络。

Conclusion: ML为声学问题提供了高效的数据驱动解决方案，开源工具AcousticsML促进了可重复研究。

Abstract: Acoustic data provide scientific and engineering insights in fields ranging
from bioacoustics and communications to ocean and earth sciences. In this
review, we survey recent advances and the transformative potential of machine
learning (ML) in acoustics, including deep learning (DL). Using the Python
high-level programming language, we demonstrate a broad collection of ML
techniques to detect and find patterns for classification, regression, and
generation in acoustics data automatically. We have ML examples including
acoustic data classification, generative modeling for spatial audio, and
physics-informed neural networks. This work includes AcousticsML, a set of
practical Jupyter notebook examples on GitHub demonstrating ML benefits and
encouraging researchers and practitioners to apply reproducible data-driven
approaches to acoustic challenges.

</details>


### [56] [Self-supervised learning of speech representations with Dutch archival data](https://arxiv.org/abs/2507.04554)
*Nik Vaessen,David A. van Leeuwen,Roeland Ordelman*

Main category: cs.SD

TL;DR: 本文利用荷兰档案电视广播数据进行自监督学习，研究了数据质量对预训练的影响，探索了预处理策略，比较了单语和多语预训练效果，并训练出荷兰语的最先进模型。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用噪声较多的荷兰档案电视广播数据，通过自监督学习训练高效的语音基础模型。

Method: 分析数据质量对预训练的影响，使用Whisper和WhisperX预处理数据，比较单语和多语预训练效果，并基于wav2vec 2.0 XLS-R模型进行继续训练。

Result: 单语预训练对域外数据更鲁棒，最终训练出荷兰语的state-of-the-art模型。

Conclusion: 通过有效预处理和单语预训练，可以利用噪声数据训练高性能语音模型。

Abstract: This paper explores the use of Dutch archival television broadcast data for
self-supervised learning of speech foundation models, specifically wav2vec 2.0.
We first study data quality assumptions for pre-training, and show how music,
noise and speaker overlap affect SSL convergence and downstream fine-tuning
performance. Secondly, we explore effectively pre-processing strategies to
convert the noisy broadcast dataset into a qualitative dataset for
pre-training, by using Whisper and WhisperX., Thirdly, we compare mono-lingual
and multi-lingual pre-training with equivalent amounts of data, and show that
mono-lingual pre-training is more robust to out-of-domain data. Lastly, we
achieve a state-of-the-art LARGE wav2vec 2.0 model for the Dutch language, by a
continuation of pre-training a wav2vec 2.0 XLS-R model checkpoint with our 55k
hour archival dataset.

</details>


### [57] [Multi-Step Prediction and Control of Hierarchical Emotion Distribution in Text-to-Speech Synthesis](https://arxiv.org/abs/2507.04598)
*Sho Inoue,Kun Zhou,Shuai Wang,Haizhou Li*

Main category: cs.SD

TL;DR: 提出了一种多级分层情绪分布预测模块，用于文本转语音合成中的情绪渲染控制。


<details>
  <summary>Details</summary>
Motivation: 研究多级定量控制情绪渲染的需求，以提升语音合成的情感表现力。

Method: 引入多步分层情绪分布预测模块，量化句子、词和音素级别的情绪变化，利用全局情绪上下文优化局部情绪变化。

Result: 通过客观和主观评估验证，该框架显著提升了情感表现力，并实现了多粒度情绪渲染的精确控制。

Conclusion: 该方法有效捕捉了语音情绪的层次结构，兼容多种TTS系统，具有广泛的应用潜力。

Abstract: We investigate hierarchical emotion distribution (ED) for achieving
multi-level quantitative control of emotion rendering in text-to-speech
synthesis (TTS). We introduce a novel multi-step hierarchical ED prediction
module that quantifies emotion variance at the utterance, word, and phoneme
levels. By predicting emotion variance in a multi-step manner, we leverage
global emotional context to refine local emotional variations, thereby
capturing the intrinsic hierarchical structure of speech emotion. Our approach
is validated through its integration into a variance adaptor and an external
module design compatible with various TTS systems. Both objective and
subjective evaluations demonstrate that the proposed framework significantly
enhances emotional expressiveness and enables precise control of emotion
rendering across multiple speech granularities.

</details>


### [58] [Improving BERT for Symbolic Music Understanding Using Token Denoising and Pianoroll Prediction](https://arxiv.org/abs/2507.04776)
*Jun-You Wang,Li Su*

Main category: cs.SD

TL;DR: 提出了一种基于BERT的符号音乐理解预训练模型，通过两种新颖的预训练目标（标记校正和钢琴卷预测）提升性能，并在12个下游任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 提升符号音乐理解的性能，通过设计新的预训练目标来更好地捕捉音乐知识。

Method: 设计了两种预训练目标：标记校正（对噪声标记进行去噪）和钢琴卷预测（从噪声标记预测钢琴卷表示）。

Result: 在12个下游任务中表现优异，验证了预训练目标的有效性。

Conclusion: 提出的预训练目标能有效提升符号音乐理解模型的性能。

Abstract: We propose a pre-trained BERT-like model for symbolic music understanding
that achieves competitive performance across a wide range of downstream tasks.
To achieve this target, we design two novel pre-training objectives, namely
token correction and pianoroll prediction. First, we sample a portion of note
tokens and corrupt them with a limited amount of noise, and then train the
model to denoise the corrupted tokens; second, we also train the model to
predict bar-level and local pianoroll-derived representations from the
corrupted note tokens. We argue that these objectives guide the model to better
learn specific musical knowledge such as pitch intervals. For evaluation, we
propose a benchmark that incorporates 12 downstream tasks ranging from chord
estimation to symbolic genre classification. Results confirm the effectiveness
of the proposed pre-training objectives on downstream tasks.

</details>


### [59] [Fast-VGAN: Lightweight Voice Conversion with Explicit Control of F0 and Duration Parameters](https://arxiv.org/abs/2507.04817)
*Mathilde Abrassart,Nicolas Obin,Axel Roebel*

Main category: cs.SD

TL;DR: 该论文提出了一种基于卷积神经网络的方法，用于精确控制语音特征（如音高、时长和语速），并通过显式条件生成梅尔频谱图，实现灵活的语音转换。


<details>
  <summary>Details</summary>
Motivation: 语音特征（如音高、音节速率）的精确控制在语音转换领域仍具挑战性，且对身份转换和独立语音变换至关重要。

Method: 采用卷积神经网络，显式条件控制音高（F0）、音素序列、强度和说话人身份，生成梅尔频谱图，再通过通用神经声码器转换为波形。

Result: 在说话人转换和表达性语音任务中，该方法表现出高灵活性和良好的可理解性与说话人相似性。

Conclusion: 该方法为语音转换提供了直观且灵活的控制手段，同时保持了高质量的语音输出。

Abstract: Precise control over speech characteristics, such as pitch, duration, and
speech rate, remains a significant challenge in the field of voice conversion.
The ability to manipulate parameters like pitch and syllable rate is an
important element for effective identity conversion, but can also be used
independently for voice transformation, achieving goals that were historically
addressed by vocoder-based methods.
  In this work, we explore a convolutional neural network-based approach that
aims to provide means for modifying fundamental frequency (F0), phoneme
sequences, intensity, and speaker identity. Rather than relying on
disentanglement techniques, our model is explicitly conditioned on these
factors to generate mel spectrograms, which are then converted into waveforms
using a universal neural vocoder. Accordingly, during inference, F0 contours,
phoneme sequences, and speaker embeddings can be freely adjusted, allowing for
intuitively controlled voice transformations.
  We evaluate our approach on speaker conversion and expressive speech tasks
using both perceptual and objective metrics. The results suggest that the
proposed method offers substantial flexibility, while maintaining high
intelligibility and speaker similarity.

</details>


### [60] [Towards Human-in-the-Loop Onset Detection: A Transfer Learning Approach for Maracatu](https://arxiv.org/abs/2507.04858)
*António Sá Pinto*

Main category: cs.SD

TL;DR: 该研究探索了在非洲-巴西Maracatu传统音乐中，通过迁移学习策略改进音乐起始点检测的方法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统音乐中的复杂节奏模式对现有模型提出了挑战，研究旨在通过迁移学习解决这一问题，并减少标注需求。

Method: 采用两种预训练的时序卷积网络架构（分别用于起始点检测和节拍跟踪），通过分层微调策略对五种传统打击乐器进行优化。

Result: 在最佳情况下，F1分数达到0.998，性能提升超过50个百分点，跨任务适应对时间保持乐器尤为有效。

Conclusion: 该方法为代表性不足的音乐传统提供了高效解决方案，推动了更包容的音乐信息检索工具的发展。

Abstract: We explore transfer learning strategies for musical onset detection in the
Afro-Brazilian Maracatu tradition, which features complex rhythmic patterns
that challenge conventional models. We adapt two Temporal Convolutional Network
architectures: one pre-trained for onset detection (intra-task) and another for
beat tracking (inter-task). Using only 5-second annotated snippets per
instrument, we fine-tune these models through layer-wise retraining strategies
for five traditional percussion instruments. Our results demonstrate
significant improvements over baseline performance, with F1 scores reaching up
to 0.998 in the intra-task setting and improvements of over 50 percentage
points in best-case scenarios. The cross-task adaptation proves particularly
effective for time-keeping instruments, where onsets naturally align with beat
positions. The optimal fine-tuning configuration varies by instrument,
highlighting the importance of instrument-specific adaptation strategies. This
approach addresses the challenges of underrepresented musical traditions,
offering an efficient human-in-the-loop methodology that minimizes annotation
effort while maximizing performance. Our findings contribute to more inclusive
music information retrieval tools applicable beyond Western musical contexts.

</details>


### [61] [Music Boomerang: Reusing Diffusion Models for Data Augmentation and Audio Manipulation](https://arxiv.org/abs/2507.04864)
*Alexander Fichtinger,Jan Schlüter,Gerhard Widmer*

Main category: cs.SD

TL;DR: 本文探讨了Boomerang采样在音频领域的应用，用于数据增强和内容编辑，实验表明其在节奏保留和有限训练数据下提升性能。


<details>
  <summary>Details</summary>
Motivation: 研究Boomerang采样在音频领域的潜力，以支持数据增强和内容编辑任务。

Method: 在Stable Audio Open中实现Boomerang采样，用于增强节拍跟踪器的训练数据，并尝试替换录音中的乐器。

Result: 结果显示节奏结构得以保留，节拍跟踪器在有限数据下性能提升，且能实现单声道输入的乐器替换。

Conclusion: Boomerang采样在音频领域有潜力，尤其在数据增强和内容编辑方面，值得进一步探索。

Abstract: Generative models of music audio are typically used to generate output based
solely on a text prompt or melody. Boomerang sampling, recently proposed for
the image domain, allows generating output close to an existing example, using
any pretrained diffusion model. In this work, we explore its application in the
audio domain as a tool for data augmentation or content manipulation.
Specifically, implementing Boomerang sampling for Stable Audio Open, we augment
training data for a state-of-the-art beat tracker, and attempt to replace
musical instruments in recordings. Our results show that the rhythmic structure
of existing examples is mostly preserved, that it improves performance of the
beat tracker, but only in scenarios of limited training data, and that it can
accomplish text-based instrument replacement on monophonic inputs. We publish
our implementation to invite experiments on data augmentation in other tasks
and explore further applications.

</details>


### [62] [EXPOTION: Facial Expression and Motion Control for Multimodal Music Generation](https://arxiv.org/abs/2507.04955)
*Fathinah Izzati,Xinyue Li,Gus Xia*

Main category: cs.SD

TL;DR: Expotion是一个多模态音乐生成模型，结合面部表情、上半身动作和文本提示生成高质量音乐，通过参数高效微调和时间对齐策略提升效果。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过多模态视觉控制（面部表情和上半身动作）和文本提示生成更具表现力和时间准确性的音乐。

Method: 采用参数高效微调（PEFT）对预训练文本到音乐生成模型进行适配，并引入时间平滑策略对齐多模态数据。

Result: 实验表明，结合视觉特征和文本描述显著提升了生成音乐的质量，超越了现有基线方法和最先进的视频到音乐生成模型。

Conclusion: Expotion在多模态音乐生成中表现出色，同时提供了一个新的同步视频数据集，为未来研究提供了潜力。

Abstract: We propose Expotion (Facial Expression and Motion Control for Multimodal
Music Generation), a generative model leveraging multimodal visual controls -
specifically, human facial expressions and upper-body motion - as well as text
prompts to produce expressive and temporally accurate music. We adopt
parameter-efficient fine-tuning (PEFT) on the pretrained text-to-music
generation model, enabling fine-grained adaptation to the multimodal controls
using a small dataset. To ensure precise synchronization between video and
music, we introduce a temporal smoothing strategy to align multiple modalities.
Experiments demonstrate that integrating visual features alongside textual
descriptions enhances the overall quality of generated music in terms of
musicality, creativity, beat-tempo consistency, temporal alignment with the
video, and text adherence, surpassing both proposed baselines and existing
state-of-the-art video-to-music generation models. Additionally, we introduce a
novel dataset consisting of 7 hours of synchronized video recordings capturing
expressive facial and upper-body gestures aligned with corresponding music,
providing significant potential for future research in multimodal and
interactive music generation.

</details>


### [63] [Modeling the Difficulty of Saxophone Music](https://arxiv.org/abs/2507.04963)
*Šimon Libřický,Jan Hajič jr*

Main category: cs.SD

TL;DR: 提出了一种用于估计萨克斯管曲目难度的方法，基于音符对的过渡成本模型，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏教师指导，学习者需要自动化的难度评估工具，而管乐器在此领域研究较少。

Method: 采用成本遍历方法，将曲目建模为音符对序列，通过新收集的颤音速度录音估计过渡成本。

Result: 实验表明，仅需少量颤音即可准确估计成本，模型可扩展至其他木管乐器。

Conclusion: 该方法为管乐器音乐教育中的自动难度评估提供了实用解决方案。

Abstract: In learning music, difficulty is an important factor in choice of repertoire,
choice of tempo, and structure of practice. These choices are typically done
with the guidance of a teacher; however, not all learners have access to one.
While piano and strings have had some attention devoted to automated difficulty
estimation, wind instruments have so far been under-served. In this paper, we
propose a method for estimating the difficulty of pieces for winds and
implement it for the tenor saxophone. We take the cost-of-traversal approach,
modelling the part as a sequence of transitions -- note pairs. We estimate
transition costs from newly collected recordings of trill speeds, comparing
representations of saxophone fingerings at various levels of expert input. We
then compute and visualise the cost of the optimal path through the part, at a
given tempo. While we present this model for the tenor saxophone, the same
pipeline can be applied to other woodwinds, and our experiments show that with
appropriate feature design, only a small proportion of possible trills is
needed to estimate the costs well. Thus, we present a practical way of
diversifying the capabilities of MIR in music education to the wind family of
instruments.

</details>


### [64] [LAPS-Diff: A Diffusion-Based Framework for Singing Voice Synthesis With Language Aware Prosody-Style Guided Learning](https://arxiv.org/abs/2507.04966)
*Sandipan Dhar,Mayank Gupta,Preeti Rao*

Main category: cs.SD

TL;DR: LAPS-Diff是一种结合语言感知嵌入和声乐风格引导学习的扩散模型，专为宝莱坞印地语歌唱风格设计，显著提升了低资源场景下的合成歌声质量。


<details>
  <summary>Details</summary>
Motivation: 当前扩散模型在歌唱语音合成（SVS）中难以捕捉声乐风格、特定流派的音高变化和语言依赖特征，尤其是在低资源场景下。

Method: 提出LAPS-Diff，整合语言感知嵌入和风格编码器，利用预训练语言模型提取歌词表示，并结合音高提取模型优化声学特征生成。

Result: 通过主客观评估，LAPS-Diff在低资源数据集上的表现显著优于现有最佳模型。

Conclusion: LAPS-Diff为低资源场景下的SVS提供了有效解决方案，尤其在声乐风格和音高变化方面表现突出。

Abstract: The field of Singing Voice Synthesis (SVS) has seen significant advancements
in recent years due to the rapid progress of diffusion-based approaches.
However, capturing vocal style, genre-specific pitch inflections, and
language-dependent characteristics remains challenging, particularly in
low-resource scenarios. To address this, we propose LAPS-Diff, a diffusion
model integrated with language-aware embeddings and a vocal-style guided
learning mechanism, specifically designed for Bollywood Hindi singing style. We
curate a Hindi SVS dataset and leverage pre-trained language models to extract
word and phone-level embeddings for an enriched lyrics representation.
Additionally, we incorporated a style encoder and a pitch extraction model to
compute style and pitch losses, capturing features essential to the naturalness
and expressiveness of the synthesized singing, particularly in terms of vocal
style and pitch variations. Furthermore, we utilize MERT and IndicWav2Vec
models to extract musical and contextual embeddings, serving as conditional
priors to refine the acoustic feature generation process further. Based on
objective and subjective evaluations, we demonstrate that LAPS-Diff
significantly improves the quality of the generated samples compared to the
considered state-of-the-art (SOTA) model for our constrained dataset that is
typical of the low resource scenario.

</details>

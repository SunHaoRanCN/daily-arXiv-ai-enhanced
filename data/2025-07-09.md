<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 6]
- [eess.AS](#eess.AS) [Total: 9]
- [cs.SD](#cs.SD) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Iterative Sparse Asymptotic Minimum Variance Based Channel Estimation in Fluid Antenna System](https://arxiv.org/abs/2507.05625)
*Zhen Chen,Jianqing Li,Xiu Yin Zhang,Kai-Kit Wong,Chan-Byoung Chae,Yangyang Zhang*

Main category: eess.SP

TL;DR: 提出了一种基于最大似然（ML）的流体天线系统（FAS）信道估计方法，通过迭代断层扫描算法和空间相关性优化，显著提升了噪声抑制和估计精度。


<details>
  <summary>Details</summary>
Motivation: 现有FAS信道估计方法在噪声抑制方面存在局限性，亟需一种更高效的方法来提升估计精度。

Method: 采用ML框架，结合迭代断层扫描算法和空间相关性优化，以减少噪声干扰并提高估计准确性。

Result: 仿真结果表明，该方法在信道估计精度和鲁棒性上优于现有基准技术。

Conclusion: 该方法为FAS系统提供了一种高效的信道估计解决方案，具有实际应用潜力。

Abstract: With fluid antenna system (FAS) gradually establishing itself as a possible
enabling technology for next generation wireless communications, channel
estimation for FAS has become a pressing issue. Existing methodologies however
face limitations in noise suppression. To overcome this, in this paper, we
propose a maximum likelihood (ML)-based channel estimation approach tailored
for FAS systems, designed to mitigate noise interference and enhance estimation
accuracy. By capitalizing on the inherent sparsity of wireless channels, we
integrate an ML-based iterative tomographic algorithm to systematically reduce
noise perturbations during the channel estimation process. Furthermore, the
proposed approach leverages spatial correlation within the FAS channel to
optimize estimation accuracy and spectral efficiency. Simulation results
confirm the efficacy of the proposed method, demonstrating superior channel
estimation accuracy and robustness compared to existing benchmark techniques.

</details>


### [2] [Performance Analysis of Linear Detection under Noise-Dependent Fast-Fading Channels](https://arxiv.org/abs/2507.05897)
*Almutasem Bellah Enad,Jihad Fahs,Hadi Sarieddeen,Hakim Jemaa,Tareq Y. Al-Naffouri*

Main category: eess.SP

TL;DR: 本文提出了一种用于快速衰落信道中线性检测的性能分析框架，适用于相关信道和噪声模型，验证了其准确性。


<details>
  <summary>Details</summary>
Motivation: 为下一代无线通信系统中的检测算法设计和评估提供灵活且准确的工具。

Method: 通过表征零迫滤波后有效噪声的分布，推导了瑞利衰落和信道相关加性圆复高斯噪声下的符号错误率的半解析和渐近表达式。

Result: 数值模拟验证了该方法与基于积分的基准测试高度一致。

Conclusion: 该框架灵活且可扩展，适用于多种信道和噪声模型，是下一代通信系统检测算法设计和分析的有力工具。

Abstract: This paper presents a performance analysis framework for linear detection in
fast-fading channels with possibly correlated channel and noise. The framework
is both accurate and adaptable, making it well-suited for analyzing a wide
range of channel and noise models. As such, it serves as a valuable tool for
the design and evaluation of detection algorithms in next-generation wireless
communication systems. By characterizing the distribution of the effective
noise after zero-forcing filtering, we derive a semi-analytical and asymptotic
expression for the symbol error rate under Rayleigh fading and
channel-dependent additive circular complex Gaussian noise. The proposed
approach demonstrates excellent agreement with integration-based benchmarks as
confirmed by numerical simulations thus validating its accuracy. The framework
is flexible and can be extended to various channel and noise models, offering a
valuable tool for the design and analysis of detection algorithms in
next-generation communication systems.

</details>


### [3] [A Differential Evolution Algorithm with Neighbor-hood Mutation for DOA Estimation](https://arxiv.org/abs/2507.06020)
*Bo Zhou,Kaijie Xu,Yinghui Quan,Mengdao Xing*

Main category: eess.SP

TL;DR: 论文提出了一种基于差分进化与邻域变异（DE-NM）的算法，用于高效定位二维多信号分类（2D MUSIC）中的多峰谱峰，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统的二维MUSIC算法在DOA估计中计算成本高，限制了实时应用。

Method: 将峰值搜索问题重新表述为多模态优化问题，并提出了DE-NM算法。

Result: 仿真结果表明，该方法在保持估计精度的同时显著减少了计算时间。

Conclusion: 该方法为实时高分辨率DOA估计提供了有前景的解决方案。

Abstract: Two-dimensional (2D) Multiple Signal Classification algorithm is a powerful
technique for high-resolution direction-of-arrival (DOA) estimation in array
signal processing. However, the exhaustive search over the 2D an-gular domain
leads to high computa-tional cost, limiting its applicability in real-time
scenarios. In this work, we reformulate the peak-finding process as a
multimodal optimization prob-lem, and propose a Differential Evolu-tion
algorithm with Neighborhood Mutation (DE-NM) to efficiently lo-cate multiple
spectral peaks without requiring dense grid sampling. Simu-lation results
demonstrate that the proposed method achieves comparable estimation accuracy to
the traditional grid search, while significantly reduc-ing computation time.
This strategy presents a promising solution for real-time, high-resolution DOA
estimation in practical applications. The imple-mentation code is available at
https://github.com/zzb-nice/DOA_multimodel_optimize.

</details>


### [4] [RIS-Enabled Transmitter Design for Joint Radar and Communication](https://arxiv.org/abs/2507.06028)
*Emanuele Grossi,Marco Lops,Luca Venturino*

Main category: eess.SP

TL;DR: 提出了一种基于可重构智能表面（RIS）的双功能雷达通信（DFRC）发射机，用于高效且经济的ISAC系统波束控制。


<details>
  <summary>Details</summary>
Motivation: 解决集成感知与通信（ISAC）系统中高效且经济的波束控制问题。

Method: 联合设计源波形和RIS相位偏移以匹配期望的空间-频率辐射模式。

Result: 数值结果表明该RIS发射机在ISAC应用中具有潜力。

Conclusion: RIS支持的发射机在ISAC应用中表现出色。

Abstract: Achieving efficient and cost-effective transmit beampattern control for
integrated sensing and communication (ISAC) systems is a significant challenge.
This paper addresses this by proposing a dual-function radar communication
(DFRC) transmitter based on a reconfigurable intelligent surface (RIS)
illuminated by a limited number of active sources. We formulate and solve the
joint design of source waveforms and RIS phase shifts to match a desired
space-frequency radiation pattern, and we evaluate the resulting ISAC system's
performance in terms of radar detection probability and data transmission rate.
Numerical results demonstrate the promising capabilities of this RIS-enabled
transmitter for ISAC applications.

</details>


### [5] [Secure Communication of UAV-mounted STAR-RIS under Phase Shift Errors](https://arxiv.org/abs/2507.06048)
*Aseel Qsibat,Habiba Akhleifa,Abdelhamid Salem,Khaled Rabie,Xingwang Li,Thokozani Shongwe,Mohamad A. Alawad,Yazeed Alkhrijah*

Main category: eess.SP

TL;DR: 论文研究了基于无人机搭载的STAR-RIS的NOMA网络在被动窃听者存在下的安全通信能力，通过优化无人机位置和STAR-RIS功率分配系数提升系统保密速率。


<details>
  <summary>Details</summary>
Motivation: 探索在硬件限制和窃听威胁下，如何利用STAR-RIS和NOMA技术提升无线网络的安全性和频谱效率。

Method: 在Nakagami衰落和相位误差条件下，推导了用户保密速率的闭式表达式，并提出了联合优化无人机位置和STAR-RIS功率分配的框架。

Result: 提出的方法显著提升了STAR-RIS-NOMA配置下的安全传输性能，为6G网络设计提供了指导。

Conclusion: STAR-RIS与NOMA结合在无人机平台上能有效增强安全通信，适用于未来6G网络。

Abstract: This paper investigates the secure communication capabilities of a
non-orthogonal multiple access (NOMA) network supported by a STAR-RIS
(simultaneously transmitting and reflecting reconfigurable intelligent surface)
deployed on an unmanned aerial vehicle (UAV), in the presence of passive
eavesdroppers. The STAR-RIS facilitates concurrent signal reflection and
transmission, allowing multiple legitimate users-grouped via NOMA-to be served
efficiently, thereby improving spectral utilization. Each user contends with an
associated eavesdropper, creating a stringent security scenario. Under Nakagami
fading conditions and accounting for phase shift inaccuracies in the STAR-RIS,
closed-form expressions for the ergodic secrecy rates of users in both
transmission and reflection paths are derived. An optimization framework is
then developed to jointly adjust the UAV's positioning and the STAR-RIS power
splitting coefficient, aiming to maximize the system's secrecy rate. The
proposed approach enhances secure transmission in STAR-RIS-NOMA configurations
under realistic hardware constraints and offers valuable guidance for the
design of future 6G wireless networks.

</details>


### [6] [AI-based Environment-Aware XL-MIMO Channel Estimation with Location-Specific Prior Knowledge Enabled by CKM](https://arxiv.org/abs/2507.06066)
*Yuelong Qiu,Di Wu,Yong Zeng,Yanqun Tang,Nan Cheng,Chenhao Qi*

Main category: eess.SP

TL;DR: 提出了一种基于环境感知的信道估计框架，利用信道知识图（CKM）和AI技术学习信道概率密度函数（PDF），并通过PnP算法和Tweedie公式优化估计过程，显著提升6G及以后无线网络的性能。


<details>
  <summary>Details</summary>
Motivation: 随着无线链路密度的增加、信道维度的扩展以及高频段的使用，传统信道估计算法（如LS和MAP）在6G及以后网络中面临正交导频序列不足、信噪比低和复杂环境中信道统计分布复杂等挑战。

Method: 提出了一种新型CKM（CSFM），利用AI技术学习信道PDF；采用PnP算法解耦正则化MAP问题；利用Tweedie公式将信道得分函数与信道去噪器连接，实现高效处理。

Result: 仿真结果表明，所提出的CSFM-PnP信道估计技术在挑战性场景中显著优于传统技术。

Conclusion: 该框架通过环境感知和AI技术优化信道估计，为6G及以后网络的复杂信道环境提供了高效解决方案。

Abstract: Accurate and efficient acquisition of wireless channel state information
(CSI) is crucial to enhance the communication performance of wireless systems.
However, with the continuous densification of wireless links, increased channel
dimensions, and the use of higher-frequency bands, channel estimation in the
sixth generation (6G) and beyond wireless networks faces new challenges, such
as insufficient orthogonal pilot sequences, inadequate signal-to-noise ratio
(SNR) for channel training, and more sophisticated channel statistical
distributions in complex environment. These challenges pose significant
difficulties for classical channel estimation algorithms like least squares
(LS) and maximum a posteriori (MAP). To address this problem, we propose a
novel environment-aware channel estimation framework with location-specific
prior channel distribution enabled by the new concept of channel knowledge map
(CKM). To this end, we propose a new type of CKM called channel score function
map (CSFM), which learns the channel probability density function (PDF) using
artificial intelligence (AI) techniques. To fully exploit the prior information
in CSFM, we propose a plug-and-play (PnP) based algorithm to decouple the
regularized MAP channel estimation problem, thereby reducing the complexity of
the optimization process. Besides, we employ Tweedie's formula to establish a
connection between the channel score function, defined as the logarithmic
gradient of the channel PDF, and the channel denoiser. This allows the use of
the high-precision, environment-aware channel denoiser from the CSFM to
approximate the channel score function, thus enabling efficient processing of
the decoupled channel statistical components. Simulation results show that the
proposed CSFM-PnP based channel estimation technique significantly outperforms
the conventional techniques in the aforementioned challenging scenarios.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [7] [Comparative Analysis of Finite Difference and Finite Element Method for Audio Waveform Simulation](https://arxiv.org/abs/2507.05396)
*Juliette Florin*

Main category: eess.AS

TL;DR: 比较有限元法（FEM）和有限差分法（FDM）在波形分析中的准确性、可行性和计算时间，发现两者误差相似，但FEM更灵活且适用于复杂几何形状。


<details>
  <summary>Details</summary>
Motivation: 探讨FDM在波形分析中未被广泛使用的原因，并验证其与FEM的性能差异。

Method: 通过模拟吉他弦振动和自行车铃铛声音，比较FEM和FDM的准确性、计算时间和收敛性。

Result: FEM和FDM误差相近，FEM收敛更快，FDM计算更快但适用性有限。

Conclusion: FEM在工业中更受青睐，因其灵活性和适用性；FDM在特定情况下计算更快但限制较多。

Abstract: In many industries, including aerospace and defense, waveform analysis is
commonly conducted to compute the resonance of physical objects, with the
Finite Element Method (FEM) being the standard approach. The Finite Difference
Method (FDM) is seldom used, and this preference is often stated without formal
justification in the literature. In this work, the accuracy, feasibility, and
time of simulation of FEM and FDM are compared by simulating the vibration of a
guitar string. Python simulations for both methods are implemented, and their
results are compared against analytical solutions and experimental data.
Additionally, FDM is applied to analyze the sound of a cycling bell to assess
its reliability compared to a real cycling bell. Final results show that both
FEM and FDM yield similar error margins and accurately predict the system's
behavior. Moreover, the errors from FEM and FDM follow the same periodicity
with a phase shift when varying the assumed analytical tension and without a
phase shift when changing the time interval. However, FEM converges faster with
increasing mesh complexity, whereas FDM demonstrates quicker computational
performance and achieves stable solutions even with bigger time intervals.
Despite this FDM is limited to simpler configurations and often demands
extensive mathematical formulation, which can become cumbersome for intricate
shapes. For example, modeling a hemispherical object using FDM results in
significant simulation times and big calculations. In conclusion, while FDM may
offer faster convergence and computation time in certain cases, FEM remains the
preferred method in industrial contexts due to its flexibility, scalability,
and ease of implementation for complex geometries.

</details>


### [8] [Sample Rate Offset Compensated Acoustic Echo Cancellation For Multi-Device Scenarios](https://arxiv.org/abs/2507.05399)
*Srikanth Korse,Oliver Thiergart,Emanuel A. P. Habets*

Main category: eess.AS

TL;DR: 论文提出了一种多设备声学回声消除（AEC）方法，通过多通道卡尔曼滤波、采样率偏移（SRO）估计和远端信号重采样，解决了多设备间SRO导致的AEC性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 多设备场景中，采样率偏移（SRO）会阻碍AEC滤波器的收敛，降低性能。本文旨在解决这一问题。

Method: 将多设备AEC视为多通道AEC问题，结合多通道卡尔曼滤波、SRO估计和远端信号重采样。

Result: 实验表明，系统在SRO存在时能有效抑制多通道卡尔曼滤波的发散，适用于相关和非相关播放信号。对于相关信号，独立单通道AEC滤波器对SRO估计的快速收敛至关重要。

Conclusion: 该方法在多设备AEC场景中有效解决了SRO问题，提升了性能。

Abstract: Acoustic echo cancellation (AEC) in multi-device scenarios is a challenging
problem due to sample rate offset (SRO) between devices. The SRO hinders the
convergence of the AEC filter, diminishing its performance. To address this ,
we approach the multi-device AEC scenario as a multi-channel AEC problem
involving a multi-channel Kalman filter, SRO estimation, and resampling of
far-end signals. Experiments in a two-device scenario show that our system
mitigates the divergence of the multi-channel Kalman filter in the presence of
SRO for both correlated and uncorrelated playback signals during echo-only and
double-talk. Additionally, for devices with correlated playback signals, an
independent single-channel AEC filter is crucial to ensure fast convergence of
SRO estimation.

</details>


### [9] [Stereo Reproduction in the Presence of Sample Rate Offsets](https://arxiv.org/abs/2507.05402)
*Srikanth Korse,Andreas Walther,Emanuel A. P. Habets*

Main category: eess.AS

TL;DR: 论文提出了一种基于空间滤波的音频域SRO补偿方法，用于解决无线扬声器时钟偏移问题，并通过主观和客观测试验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 无线连接的扬声器在空间音频再现中因时钟偏移（SROs）导致同步问题，现有网络协议（如PTP和NTP）对SROs的影响研究不足。

Method: 使用空间滤波分离扬声器信号，结合原始播放信号估计SROs，并在空间音频再现前进行补偿。

Result: 主观听测和客观指标表明，该方法通过保留空间线索，有效减轻了SROs引起的感知退化。

Conclusion: 提出的补偿方法能够改善无线扬声器的空间音频再现质量。

Abstract: One of the main challenges in synchronizing wirelessly connected loudspeakers
for spatial audio reproduction is clock skew. Clock skew arises from sample
rate offsets ( SROs) between the loudspeakers, caused by the use of independent
device clocks. While network-based protocols like Precision Time Protocol (PTP)
and Network Time Protocol (NTP) are explored, the impact of SROs on spatial
audio reproduction and its perceptual consequences remains underexplored. We
propose an audio-domain SRO compensation method using spatial filtering to
isolate loudspeaker contributions. These filtered signals, along with the
original playback signal, are used to estimate the SROs, and their influence is
compensated for prior to spatial audio reproduction. We evaluate the effect of
the compensation method in a subjective listening test. The results of these
tests as well as objective metrics demonstrate that the proposed method
mitigates the perceptual degradation introduced by SROs by preserving the
spatial cues.

</details>


### [10] [Parametric Object Coding in IVAS: Efficient Coding of Multiple Audio Objects at Low Bit Rates](https://arxiv.org/abs/2507.05409)
*Andrea Eichenseer,Srikanth Korse,Guillaume Fuchs,Markus Multrus*

Main category: eess.AS

TL;DR: 3GPP IVAS编解码器通过参数化模式在低比特率下高效编码多个音频对象，利用对象元数据和输入音频生成参数信息，并通过立体声下混和参数信息重建空间音频场景。


<details>
  <summary>Details</summary>
Motivation: 解决在低比特率下高效编码和重建多个音频对象的需求，同时保持沉浸式音频体验。

Method: 通过提取方向信息、两个主导对象的索引及其功率比等参数信息，结合立体声下混进行编码和解码。

Result: 在24.4或32 kbit/s比特率下，能够忠实重建原始音频场景的空间图像，主观测试显示其沉浸式体验与独立编码（EVS）相当。

Conclusion: IVAS在低比特率和复杂度下提供了与独立编码相当的沉浸式音频体验。

Abstract: The recently standardized 3GPP codec for Immersive Voice and Audio Services
(IVAS) includes a parametric mode for efficiently coding multiple audio objects
at low bit rates. In this mode, parametric side information is obtained from
both the object metadata and the input audio objects. The side information
comprises directional information, indices of two dominant objects, and the
power ratio between these two dominant objects. It is transmitted to the
decoder along with a stereo downmix. In IVAS, parametric object coding allows
for transmitting three or four arbitrarily placed objects at bit rates of 24.4
or 32 kbit/s and faithfully reconstructing the spatial image of the original
audio scene. Subjective listening tests confirm that IVAS provides a comparable
immersive experience at lower bit rate and complexity compared to coding the
audio objects independently using Enhanced Voice Services (EVS).

</details>


### [11] [MMW: Side Talk Rejection Multi-Microphone Whisper on Smart Glasses](https://arxiv.org/abs/2507.05609)
*Yang Liu,Li Wan,Yiteng Huang,Yong Xu,yangyang shi,Saurabh Adya,ming sun,Florian Metze*

Main category: eess.AS

TL;DR: 提出了一种用于智能眼镜的多麦克风Whisper框架（MMW），通过Tri-Mamba架构、帧级侧语音抑制和GRPO策略，显著降低了嘈杂环境中的词错误率。


<details>
  <summary>Details</summary>
Motivation: 解决智能眼镜在嘈杂环境中因侧语音干扰导致的交互不可靠问题。

Method: 1. 基于Tri-Mamba的Mix Block融合多通道音频；2. 帧级侧语音抑制的Frame Diarization Mamba Layer；3. 使用GRPO策略联合优化帧级和语句级侧语音抑制。

Result: 在嘈杂环境中，MMW系统将词错误率（WER）降低了4.95%。

Conclusion: MMW框架有效提升了智能眼镜在嘈杂环境中的交互可靠性。

Abstract: Smart glasses are increasingly positioned as the next-generation interface
for ubiquitous access to large language models (LLMs). Nevertheless, achieving
reliable interaction in real-world noisy environments remains a major
challenge, particularly due to interference from side speech. In this work, we
introduce a novel side-talk rejection multi-microphone Whisper (MMW) framework
for smart glasses, incorporating three key innovations. First, we propose a Mix
Block based on a Tri-Mamba architecture to effectively fuse multi-channel audio
at the raw waveform level, while maintaining compatibility with streaming
processing. Second, we design a Frame Diarization Mamba Layer to enhance
frame-level side-talk suppression, facilitating more efficient fine-tuning of
Whisper models. Third, we employ a Multi-Scale Group Relative Policy
Optimization (GRPO) strategy to jointly optimize frame-level and
utterance-level side speech suppression. Experimental evaluations demonstrate
that the proposed MMW system can reduce the word error rate (WER) by 4.95\% in
noisy conditions.

</details>


### [12] [Frequency-Specific Neural Response and Cross-Correlation Analysis of Envelope Following Responses to Native Speech and Music Using Multichannel EEG Signals: A Case Study](https://arxiv.org/abs/2507.05635)
*Md. Mahbub Hasan,Md Rakibul Hasan,Md Zakir Hossain,Tom Gedeon*

Main category: eess.AS

TL;DR: 研究了语音和音乐包络跟随响应（EFRs）的频率特性，发现α、低γ和高γ波段是系统的峰值响应，可能与听觉认知功能相关。


<details>
  <summary>Details</summary>
Motivation: 探索语音和音乐包络跟随响应的频率特性及其在听觉认知中的作用。

Method: 采用时间平均频谱响应和交叉频谱密度分析技术，研究头皮四个位置的系统传递函数。

Result: α（8-11 Hz）、低γ（53-56 Hz）和高γ（78-81 Hz）波段是系统的峰值响应；交叉频谱密度显示10-13 Hz、27-29 Hz和62-64 Hz是常见频率。

Conclusion: 这些频率响应可能是语音和音乐感知的关键成分，反映了大脑的神经一致性。

Abstract: Although native speech and music envelope following responses (EFRs) play a
crucial role in auditory processing and cognition, their frequency profile,
such as the dominating frequency and spectral coherence, is largely unknown. We
have assumed that the auditory pathway - which transmits envelope components of
speech and music to the scalp through time-varying neurophysiological processes
- is a linear time-varying system, with the envelope and the multi-channel EEG
responses as excitation and response, respectively. This paper investigates the
transfer function of this system through two analytical techniques -
time-averaged spectral responses and cross-spectral density - in the frequency
domain at four different positions of the human scalp. Our findings suggest
that alpha (8-11 Hz), lower gamma (53-56 Hz), and higher gamma (78-81 Hz) bands
are the peak responses of the system. These frequently appearing dominant
frequency responses may be the key components of familiar speech perception,
maintaining attention, binding acoustic features, and memory processing. The
cross-spectral density, which reflects the spatial neural coherence of the
human brain, shows that 10-13 Hz, 27-29 Hz, and 62-64 Hz are common for all
channel pairs. As neural coherences are frequently observed in these
frequencies among native participants, we suggest that these distributed neural
processes are also dominant in native speech and music perception.

</details>


### [13] [Robust One-step Speech Enhancement via Consistency Distillation](https://arxiv.org/abs/2507.05688)
*Liang Xu,Longfei Felix Yan,W. Bastiaan Kleijn*

Main category: eess.AS

TL;DR: ROSE-CD提出了一种通过一致性蒸馏的鲁棒一步语音增强方法，解决了传统一致性模型对教师模型采样轨迹的依赖问题，显著提升了推理速度和性能。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型在语音增强中因多步迭代采样限制了实时性，而一致性蒸馏模型易受教师模型误差影响。

Method: 引入随机学习轨迹和时域辅助损失，联合优化一步模型，提升鲁棒性和性能。

Result: 在VoiceBank-DEMAND数据集上实现54倍加速和SOTA性能，泛化能力验证有效。

Conclusion: ROSE-CD是首个纯一步一致性蒸馏模型，显著优于教师模型，适用于实时语音增强。

Abstract: Diffusion models have shown strong performance in speech enhancement, but
their real-time applicability has been limited by multi-step iterative
sampling. Consistency distillation has recently emerged as a promising
alternative by distilling a one-step consistency model from a multi-step
diffusion-based teacher model. However, distilled consistency models are
inherently biased towards the sampling trajectory of the teacher model, making
them less robust to noise and prone to inheriting inaccuracies from the teacher
model. To address this limitation, we propose ROSE-CD: Robust One-step Speech
Enhancement via Consistency Distillation, a novel approach for distilling a
one-step consistency model. Specifically, we introduce a randomized learning
trajectory to improve the model's robustness to noise. Furthermore, we jointly
optimize the one-step model with two time-domain auxiliary losses, enabling it
to recover from teacher-induced errors and surpass the teacher model in overall
performance. This is the first pure one-step consistency distillation model for
diffusion-based speech enhancement, achieving 54 times faster inference speed
and superior performance compared to its 30-step teacher model. Experiments on
the VoiceBank-DEMAND dataset demonstrate that the proposed model achieves
state-of-the-art performance in terms of speech quality. Moreover, its
generalization ability is validated on both an out-of-domain dataset and
real-world noisy recordings.

</details>


### [14] [ContextASR-Bench: A Massive Contextual Speech Recognition Benchmark](https://arxiv.org/abs/2507.05727)
*He Wang,Linhan Ma,Dake Guo,Xiong Wang,Lei Xie,Jin Xu,Junyang Lin*

Main category: eess.AS

TL;DR: 提出ContextASR-Bench基准，用于评估上下文语音识别性能，涵盖多领域数据，并比较传统ASR与大型音频语言模型的表现。


<details>
  <summary>Details</summary>
Motivation: 传统ASR模型在上下文建模和世界知识推理方面表现不足，需要新基准评估其通用性和智能性。

Method: 开发ContextASR-Bench，包含40,000条数据，覆盖10多个领域，评估模型在不同上下文场景下的表现。

Result: 大型音频语言模型（LALMs）在上下文学习和世界知识方面显著优于传统ASR模型。

Conclusion: ContextASR-Bench为评估上下文ASR提供了全面工具，LALMs展现出更强的性能。

Abstract: Automatic Speech Recognition (ASR) has been extensively investigated, yet
prior evaluative efforts have largely been restricted to contextless paradigms.
This constraint stems from the limited proficiency of conventional ASR models
in context modeling and their deficiency in memory and reasoning based on world
knowledge. Recent breakthroughs in the development of Large Language Models
(LLMs) and corresponding Large Audio Language Models (LALMs) have markedly
enhanced the visibility of general artificial intelligence capabilities.
Consequently, there exists a compelling need for a benchmark that can evaluate
both the generality and intelligence of ASR systems. To address this gap, we
propose ContextASR-Bench: a comprehensive, large-scale benchmark designed to
assess contextual speech recognition. This benchmark encompasses up to 40,000
data entries across over 10 domains, enabling a thorough evaluation of model
performance in scenarios that omit or incorporate coarse-grained or
fine-grained contextual information. Moreover, diverging from conventional ASR
evaluations, our benchmark includes an analysis of model efficacy in
recognizing named entities mentioned within the auditory input. Our extensive
evaluation highlights that LALMs, with strong world knowledge and context
learning capabilities, outperform conventional ASR models by a large margin.
The dataset and evaluation code have been released at
https://github.com/MrSupW/ContextASR-Bench.

</details>


### [15] [Dynamic Slimmable Networks for Efficient Speech Separation](https://arxiv.org/abs/2507.06179)
*Mohamed Elminshawi,Srikanth Raj Chetupalli,Emanuël A. P. Habets*

Main category: eess.AS

TL;DR: 论文提出了一种动态可调网络（DSN）用于语音分离，通过根据输入信号动态调整计算复杂度，提高了资源受限设备上的效率。


<details>
  <summary>Details</summary>
Motivation: 传统语音分离系统使用静态网络架构，对所有输入段保持恒定计算复杂度，导致对简单段（如静音或非重叠语音）的处理效率低下。

Method: 结合可调网络和轻量级门控模块，动态确定网络宽度，并引入信号依赖的复杂度损失以平衡性能与效率。

Result: 在WSJ0-2mix和WHAM!数据集上的实验表明，DSN在性能和效率上优于静态网络。

Conclusion: DSN提供了一种更优的性能-效率权衡方案，适用于资源受限环境。

Abstract: Recent progress in speech separation has been largely driven by advances in
deep neural networks, yet their high computational and memory requirements
hinder deployment on resource-constrained devices. A significant inefficiency
in conventional systems arises from using static network architectures that
maintain constant computational complexity across all input segments,
regardless of their characteristics. This approach is sub-optimal for simpler
segments that do not require intensive processing, such as silence or
non-overlapping speech. To address this limitation, we propose a dynamic
slimmable network (DSN) for speech separation that adaptively adjusts its
computational complexity based on the input signal. The DSN combines a
slimmable network, which can operate at different network widths, with a
lightweight gating module that dynamically determines the required width by
analyzing the local input characteristics. To balance performance and
efficiency, we introduce a signal-dependent complexity loss that penalizes
unnecessary computation based on segmental reconstruction error. Experiments on
clean and noisy two-speaker mixtures from the WSJ0-2mix and WHAM! datasets show
that the DSN achieves a better performance-efficiency trade-off than
individually trained static networks of different sizes.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [16] [Adaptive Linearly Constrained Minimum Variance Volumetric Active Noise Control](https://arxiv.org/abs/2507.05657)
*Manan Mittal,Ryan M. Corey,Andrew C. Singer*

Main category: cs.SD

TL;DR: 本文提出了一种基于时间域的线性约束最小方差主动噪声控制（LCMV ANC）方法，用于空间控制滤波器设计，提供比传统多点误差最小化更灵活的空间响应控制。


<details>
  <summary>Details</summary>
Motivation: 传统体积噪声控制方法通过多点误差最小化抑制区域内的声能，但缺乏空间响应的灵活性。

Method: 采用LCMV ANC优化框架，通过定义线性约束优先在特定空间位置降噪，并基于FxLMS算法设计自适应滤波器。

Result: 仿真和实验结果表明，该方法在降噪和约束遵循方面优于传统的多点体积噪声控制方法。

Conclusion: LCMV ANC方法实现了有效、空间选择性和宽带噪声控制，为系统设计提供了更高灵活性。

Abstract: Traditional volumetric noise control typically relies on multipoint error
minimization to suppress sound energy across a region, but offers limited
flexibility in shaping spatial responses. This paper introduces a time-domain
formulation for linearly constrained minimum variance active noise control
(LCMV ANC) for spatial control filter design. We demonstrate how the LCMV ANC
optimization framework allows system designers to prioritize noise reduction at
specific spatial locations through strategically defined linear constraints,
providing a more flexible alternative to uniformly weighted multipoint error
minimization. An adaptive algorithm based on filtered-X least mean squares
(FxLMS) is derived for online adaptation of filter coefficients. Simulation and
experimental results validate the proposed method's noise reduction and
constraint adherence, demonstrating effective, spatially selective, and
broadband noise control compared to multipoint volumetric noise control.

</details>


### [17] [Beamforming with Random Projections: Upper and Lower Bounds](https://arxiv.org/abs/2507.05662)
*Manan Mittal,Ryan M. Corey,Andrew C. Singer*

Main category: cs.SD

TL;DR: 论文提出了一种基于多随机投影的数据驱动降维和波束成形方法，通过混合波束成形器在SNR和SINR增益上优于传统MVDR波束成形器。


<details>
  <summary>Details</summary>
Motivation: 分布式麦克风阵列中，不同阵列对声源的幅度和相位差异显著，传统波束成形器在噪声增益和干扰抑制之间存在权衡。

Method: 采用多随机投影作为预处理方案，通过数据驱动降维和混合波束成形器设计，平衡计算复杂度、噪声增益和干扰抑制。

Result: 混合波束成形器在SNR和SINR增益上优于MVDR，同时通过计算复杂度权衡实现更好的实时性能和更低计算需求。

Conclusion: 多随机投影方法为自适应波束成形器设计提供了新的自由度，能够更好地利用信号结构，并推导了压缩波束成形器输出功率的上下界。

Abstract: Beamformers often trade off white noise gain against the ability to suppress
interferers. With distributed microphone arrays, this trade-off becomes crucial
as different arrays capture vastly different magnitude and phase differences
for each source. We propose the use of multiple random projections as a
first-stage preprocessing scheme in a data-driven approach to dimensionality
reduction and beamforming. We show that a mixture beamformer derived from the
use of multiple such random projections can effectively outperform the minimum
variance distortionless response (MVDR) beamformer in terms of signal-to-noise
ratio (SNR) and signal-to-interferer-and-noise ratio (SINR) gain. Moreover, our
method introduces computational complexity as a trade-off in the design of
adaptive beamformers, alongside noise gain and interferer suppression. This
added degree of freedom allows the algorithm to better exploit the inherent
structure of the received signal and achieve better real-time performance while
requiring fewer computations. Finally, we derive upper and lower bounds for the
output power of the compressed beamformer when compared to the full complexity
MVDR beamformer.

</details>


### [18] [Non-Intrusive Binaural Speech Intelligibility Prediction Using Mamba for Hearing-Impaired Listeners](https://arxiv.org/abs/2507.05729)
*Katsuhiko Yamamoto,Koichi Miyazaki*

Main category: cs.SD

TL;DR: 论文提出了一种基于Mamba的语音清晰度预测（SIP）模型，替代了传统的Transformer模型，以降低计算和内存成本，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于Transformer的SIP模型在计算和内存成本上较高，限制了其在低延迟、高效能设备中的应用。

Method: 使用Mamba替代Transformer作为时间处理模块，构建非侵入式双耳SIP模型。

Result: 实验表明，提出的Mamba-based SIP模型在性能上与基线模型相当，同时参数数量较少。

Conclusion: 基于双向Mamba的SIP模型能有效捕捉双耳信号的上下文和空间信息，适合低延迟应用。

Abstract: Speech intelligibility prediction (SIP) models have been used as objective
metrics to assess intelligibility for hearing-impaired (HI) listeners. In the
Clarity Prediction Challenge 2 (CPC2), non-intrusive binaural SIP models based
on transformers showed high prediction accuracy. However, the self-attention
mechanism theoretically incurs high computational and memory costs, making it a
bottleneck for low-latency, power-efficient devices. This may also degrade the
temporal processing of binaural SIPs. Therefore, we propose Mamba-based SIP
models instead of transformers for the temporal processing blocks. Experimental
results show that our proposed SIP model achieves competitive performance
compared to the baseline while maintaining a relatively small number of
parameters. Our analysis suggests that the SIP model based on bidirectional
Mamba effectively captures contextual and spatial speech information from
binaural signals.

</details>


### [19] [Stable Acoustic Relay Assignment with High Throughput via Lase Chaos-based Reinforcement Learning](https://arxiv.org/abs/2507.05900)
*Zengjing Chen,Lu Wang,Chengzhi Xing*

Main category: cs.SD

TL;DR: 本研究提出了一种基于激光混沌的多处理学习（LC-ML）方法，用于水下声学网络中稳定的中继分配，实现了高吞吐量和快速稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决水下声学网络中稳定的中继分配问题，区别于现有文献，考虑了经典稳定配置和模糊稳定配置两种目标。

Method: 利用激光混沌生成的随机数，通过多处理学习中继分配，探索中继决策过程。

Result: 激光混沌随机数和多处理在交换过程中对高吞吐量和环境适应性有积极影响，模糊认知比精确认知更稳定。

Conclusion: 该方法为复杂水下环境中的中继选择提供了实用基础。

Abstract: This study addresses the problem of stable acoustic relay assignment in an
underwater acoustic network. Unlike the objectives of most existing literature,
two distinct objectives, namely classical stable arrangement and ambiguous
stable arrangement, are considered. To achieve these stable arrangements, a
laser chaos-based multi-processing learning (LC-ML) method is introduced to
efficiently obtain high throughput and rapidly attain stability. In order to
sufficiently explore the relay's decision-making, this method uses random
numbers generated by laser chaos to learn the assignment of relays to multiple
source nodes. This study finds that the laser chaos-based random number and
multi-processing in the exchange process have a positive effect on higher
throughput and strong adaptability with environmental changing over time.
Meanwhile, ambiguous cognitions result in the stable configuration with less
volatility compared to accurate ones. This provides a practical and useful
method and can be the basis for relay selection in complex underwater
environments.

</details>


### [20] [Differentiable Reward Optimization for LLM based TTS system](https://arxiv.org/abs/2507.05911)
*Changfeng Gao,Zhihao Du,Shiliang Zhang*

Main category: cs.SD

TL;DR: DiffRO方法通过直接基于神经编解码器令牌计算奖励，并利用Gumbel-Softmax技术使奖励函数可微分，提升了TTS系统的性能。结合多任务奖励模型，系统在发音准确性和情感控制方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统基于合成音频的RLHF方法在TTS系统中效率较低，DiffRO旨在通过直接处理神经编解码器令牌和引入可微分奖励优化训练过程。

Method: DiffRO直接计算神经编解码器令牌的奖励，使用Gumbel-Softmax技术使奖励函数可微分，并引入多任务奖励模型提供多角度反馈。

Result: DiffRO显著提升了TTS系统的发音准确性，在seed-tts-eval基准上达到SOTA WER结果，并能零样本控制情感和质量属性。

Conclusion: DiffRO通过可微分奖励和多任务奖励模型，有效优化了TTS系统的性能，展现了在发音和情感控制方面的潜力。

Abstract: This paper proposes a novel Differentiable Reward Optimization (DiffRO)
method aimed at enhancing the performance of neural codec language models based
text-to-speech (TTS) systems. In contrast to conventional reinforcement
learning from human feedback (RLHF) approaches applied to TTS, DiffRO directly
compute the rewards based on neural codec tokens, rather than relying on
synthesized audio. Furthermore, we employ the Gumbel-Softmax technique to
render the reward function differentiable, thereby streamlining the RLHF
training process. Additionally, we introduce a multi-task reward (MTR) model
which can provide feedback from different perspectives and find that it can
augment the system's capability to follow instructions effectively.Experimental
results indicate that DiffRO significantly improves the pronunciation accuracy
of the TTS system, achieving state-of-the-art (SOTA) WER results on the
seed-tts-eval benchmark. Moreover, with the integration of the MTR model, we
demonstrate the ability to control emotional and quality attributes in a
zero-shot manner.

</details>


### [21] [Contrastive and Transfer Learning for Effective Audio Fingerprinting through a Real-World Evaluation Protocol](https://arxiv.org/abs/2507.06070)
*Christos Nikou,Theodoros Giannakopoulos*

Main category: cs.SD

TL;DR: 论文提出了一种新的评估协议，模拟真实环境下的音频识别，并展示了现有CNN模型在噪声环境下的性能下降。通过改进训练增强管道和引入基于Transformer的模型，显著提升了识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有的音频指纹识别方法在受控条件下表现良好，但在真实噪声环境中性能显著下降。论文旨在通过新的评估协议和改进方法解决这一问题。

Method: 1. 提出新的评估协议，模拟移动设备在噪声环境下的录音；2. 改进训练增强管道，加入低通和高通滤波器；3. 开发基于Transformer的模型，并引入语义相关领域的知识迁移。

Result: 1. 现有CNN模型在噪声环境下性能显著下降；2. 改进的增强管道提升了性能；3. Transformer模型在所有噪声水平和查询时长下均优于CNN模型，最高提升18.5%。

Conclusion: 论文通过新评估协议和改进方法，显著提升了音频指纹识别在噪声环境下的鲁棒性，Transformer模型表现最佳。

Abstract: Recent advances in song identification leverage deep neural networks to learn
compact audio fingerprints directly from raw waveforms. While these methods
perform well under controlled conditions, their accuracy drops significantly in
real-world scenarios where the audio is captured via mobile devices in noisy
environments. In this paper, we introduce a novel evaluation protocol designed
to better reflect such real-world conditions. We generate three recordings of
the same audio, each with increasing levels of noise, captured using a mobile
device's microphone. Our results reveal a substantial performance drop for two
state-of-the-art CNN-based models under this protocol, compared to previously
reported benchmarks. Additionally, we highlight the critical role of the
augmentation pipeline during training with contrastive loss. By introduction
low pass and high pass filters in the augmentation pipeline we significantly
increase the performance of both systems in our proposed evaluation.
Furthermore, we develop a transformer-based model with a tailored projection
module and demonstrate that transferring knowledge from a semantically relevant
domain yields a more robust solution. The transformer architecture outperforms
CNN-based models across all noise levels, and query durations. In low noise
conditions it achieves 47.99% for 1-sec queries, and 97% for 10-sec queries in
finding the correct song, surpassing by 14%, and by 18.5% the second-best
performing model, respectively, Under heavy noise levels, we achieve a
detection rate 56.5% for 15-second query duration. All experiments are
conducted on public large-scale dataset of over 100K songs, with queries
matched against a database of 56 million vectors.

</details>


### [22] [Speech Quality Assessment Model Based on Mixture of Experts: System-Level Performance Enhancement and Utterance-Level Challenge Analysis](https://arxiv.org/abs/2507.06116)
*Xintong Hu,Yixuan Chen,Rui Yang,Wenxiang Guo,Changhao Pan*

Main category: cs.SD

TL;DR: 本文提出了一种基于自监督学习的语音质量评估系统，采用Mixture of Experts (MoE)分类头和合成数据增强，但句子级预测任务性能提升有限。


<details>
  <summary>Details</summary>
Motivation: 现有语音质量评估模型在不同粒度预测任务中表现差异显著，需改进。

Method: 基于wav2vec2等自监督模型，设计MoE架构，利用多商业生成模型的合成数据进行数据增强。

Result: 模型在句子级预测任务中性能提升有限，揭示了当前方法的局限性。

Conclusion: 研究为自动语音质量评估提供了新思路，并探讨了不同评估粒度性能差异的根本原因。

Abstract: Automatic speech quality assessment plays a crucial role in the development
of speech synthesis systems, but existing models exhibit significant
performance variations across different granularity levels of prediction tasks.
This paper proposes an enhanced MOS prediction system based on self-supervised
learning speech models, incorporating a Mixture of Experts (MoE) classification
head and utilizing synthetic data from multiple commercial generation models
for data augmentation. Our method builds upon existing self-supervised models
such as wav2vec2, designing a specialized MoE architecture to address different
types of speech quality assessment tasks. We also collected a large-scale
synthetic speech dataset encompassing the latest text-to-speech, speech
conversion, and speech enhancement systems. However, despite the adoption of
the MoE architecture and expanded dataset, the model's performance improvements
in sentence-level prediction tasks remain limited. Our work reveals the
limitations of current methods in handling sentence-level quality assessment,
provides new technical pathways for the field of automatic speech quality
assessment, and also delves into the fundamental causes of performance
differences across different assessment granularities.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 15]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.SD](#cs.SD) [Total: 9]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Foundation Models for Brain Signals: A Critical Review of Current Progress and Future Directions](https://arxiv.org/abs/2507.11783)
*Gayal Kuruppu,Neeraj Wagh,Yogatheesan Varatharajah*

Main category: eess.SP

TL;DR: 论文综述了10种早期EEG基础模型（EEG-FMs），分析了其方法、实证结果及研究空白，指出当前模型的局限性和未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 监督式EEG编码器在稳健性和标注依赖上的不足促使转向自监督的EEG基础模型（EEG-FMs），但其实际应用效果和长期研究方向尚不明确。

Method: 通过系统综述10种早期EEG-FMs，分析其方法（如基于序列的建模和Transformer架构）和自监督策略（如掩码序列重建）。

Result: 发现当前EEG-FMs评估方法不一致且有限，难以评估其实用性；未来需标准化评估、扩展规模并优化学习流程。

Conclusion: 未来应通过开发基准、工具和方法，结合领域专家合作，提升EEG-FMs的实用性和实际应用价值。

Abstract: Patterns of electrical brain activity recorded via electroencephalography
(EEG) offer immense value for scientific and clinical investigations. The
inability of supervised EEG encoders to learn robust EEG patterns and their
over-reliance on expensive signal annotations have sparked a transition towards
general-purpose self-supervised EEG encoders, i.e., EEG foundation models
(EEG-FMs), for robust and scalable EEG feature extraction. However, the
real-world readiness of early EEG-FMs and the rubric for long-term research
progress remain unclear. A systematic and comprehensive review of
first-generation EEG-FMs is therefore necessary to understand the current
state-of-the-art and identify key directions for future EEG-FMs. To that end,
this study reviews 10 early EEG-FMs and presents a critical synthesis of their
methodology, empirical findings, and outstanding research gaps. We find that
most EEG-FMs adopt a sequence-based modeling scheme that relies on
transformer-based backbones and the reconstruction of masked sequences for
self-supervision. However, model evaluations remain heterogeneous and largely
limited, making it challenging to assess their practical off-the-shelf utility.
In addition to adopting standardized and realistic evaluations, future work
should demonstrate more substantial scaling effects and make principled and
trustworthy choices throughout the EEG representation learning pipeline. We
believe that developing benchmarks, software tools, technical methodologies,
and applications in collaboration with domain experts may further advance the
translational utility and real-world adoption of EEG-FMs.

</details>


### [2] [Directional Measurements and Analysis for FR3 Low-Altitude Channels in a Campus Environment](https://arxiv.org/abs/2507.11846)
*Yulu Guo,Tongjia Zhang,Xiangwen Gu,Shu Sun,Meixia Tao,Ruifeng Gao*

Main category: eess.SP

TL;DR: 本文通过低空FR3频段信道测量，分析了路径损耗和功率角谱，发现近距离模型优于3GPP模型，且传播行为受环境条件显著影响。


<details>
  <summary>Details</summary>
Motivation: 研究低空FR3频段信道特性，为新兴中频通信系统的信道建模提供基础见解。

Method: 使用时域信道探测系统进行路径损耗测量和定向功率角谱测量。

Result: 近距离模型优于3GPP模型，传播行为受地面反射和散射效应显著影响。

Conclusion: 低空传播特性复杂，需考虑发射高度和地面散射机制的相互作用。

Abstract: In this paper, we present detailed low-altitude channel measurements at the
FR3 band in an outdoor campus environment. Using a time-domain channel sounder
system, we conduct two types of measurements: path loss measurements by moving
the transmitter (Tx) at one-meter intervals along a 26-point rooftop path, and
directional power angular spectrum measurements through antenna scanning at
half-power beam width intervals. The path loss analysis across different Rx
shows that the close-in model outperforms conventional 3GPP models and
height-corrected variants, with path loss exponents close to free space values
indicating line-of-sight dominance. The power angular spectrum measurements
show that propagation behavior varies significantly with environmental
conditions. Closer Rx exhibit stronger sensitivity to ground reflections during
downward Tx tilting, while obstructed links display uniform angular
characteristics due to dominant scattering effects, and corridor environments
produce asymmetric power distributions. These results indicate that
low-altitude propagation is characterized by complex interactions between Tx
height and ground scattering mechanisms, providing fundamental insights for
channel modeling in emerging mid-band communication systems.

</details>


### [3] [Joint UAV Placement and Transceiver Design in Multi-User Wireless Relay Networks](https://arxiv.org/abs/2507.11912)
*Tzu-Hsuan Chou,Nicolo Michelusi,David J. Love,James V. Krogmeier*

Main category: eess.SP

TL;DR: 提出了一种优化无人机中继放置、波束成形和接收组合的新方法，以提高非正交多用户无线中继网络中的最小信干噪比（SINR）。


<details>
  <summary>Details</summary>
Motivation: 在非正交多用户传输中，缺乏瞬时信道状态信息（CSI）导致无人机中继放置和波束成形优化困难，因此需要一种新方法来解决这一问题。

Method: 将设计分为两部分：基于波束成形的无人机放置优化和最小SINR最大化的收发器设计。提出了基于窄波束特性的预期SINR近似方法，并采用凸差框架优化无人机位置。随后，提出联合中继波束成形和接收组合（JRBC）算法优化收发器。

Result: 数值结果表明，该方法比现有技术方案提高了4.6 dB的SINR。

Conclusion: 通过优化无人机放置和收发器设计，显著提高了非正交多用户网络中的最小SINR。

Abstract: In this paper, a novel approach is proposed to improve the minimum
signal-to-interference-plus-noise-ratio (SINR) among users in non-orthogonal
multi-user wireless relay networks, by optimizing the placement of unmanned
aerial vehicle (UAV) relays, relay beamforming, and receive combining. The
design is separated into two problems: beamforming-aware UAV placement
optimization and transceiver design for minimum SINR maximization. A
significant challenge in beamforming-aware UAV placement optimization is the
lack of instantaneous channel state information (CSI) prior to deploying UAV
relays, making it difficult to derive the beamforming SINR in non-orthogonal
multi-user transmission. To address this issue, an approximation of the
expected beamforming SINR is derived using the narrow beam property of a
massive MIMO base station. Based on this, a UAV placement algorithm is proposed
to provide UAV positions that improve the minimum expected beamforming SINR
among users, using a difference-of-convex framework. Subsequently, after
deploying the UAV relays to the optimized positions, and with estimated CSI
available, a joint relay beamforming and receive combining (JRBC) algorithm is
proposed to optimize the transceiver to improve the minimum beamforming SINR
among users, using a block-coordinate descent approach. Numerical results show
that the UAV placement algorithm combined with the JRBC algorithm provides a
4.6 dB SINR improvement over state-of-the-art schemes.

</details>


### [4] [Scene Graph-Aided Probabilistic Semantic Communication for Image Transmission](https://arxiv.org/abs/2507.11913)
*Chen Zhu,Siyun Liang,Zhouxiang Zhao,Jianrong Bao,Zhaohui Yang,Zhaoyang Zhang,Dusit Niyato*

Main category: eess.SP

TL;DR: 提出了一种基于概率图的无线图像语义通信框架，通过两阶段压缩算法去除冗余信息，提升传输效率。


<details>
  <summary>Details</summary>
Motivation: 解决网络拥塞和传输效率问题，通过语义通信传输意义而非原始符号。

Method: 使用场景图表示高级语义，设计两阶段压缩算法去除可预测成分，发送端过滤冗余关系，接收端利用概率图恢复语义。

Result: 仿真结果表明，该方案在传输吞吐量和语义对齐方面表现优越。

Conclusion: 验证了利用高级语义进行图像通信的有效性，并提出了多轮语义压缩算法供进一步研究。

Abstract: Semantic communication emphasizes the transmission of meaning rather than raw
symbols. It offers a promising solution to alleviate network congestion and
improve transmission efficiency. In this paper, we propose a wireless image
communication framework that employs probability graphs as shared semantic
knowledge base among distributed users. High-level image semantics are
represented via scene graphs, and a two-stage compression algorithm is devised
to remove predictable components based on learned conditional and co-occurrence
probabilities. At the transmitter, the algorithm filters redundant relations
and entity pairs, while at the receiver, semantic recovery leverages the same
probability graphs to reconstruct omitted information. For further research, we
also put forward a multi-round semantic compression algorithm with its
theoretical performance analysis. Simulation results demonstrate that our
semantic-aware scheme achieves superior transmission throughput and satiable
semantic alignment, validating the efficacy of leveraging high-level semantics
for image communication.

</details>


### [5] [STFT-based Time-Frequency Mode Decomposition: A Fast and Robust Method for Multicomponent Signal Analysis](https://arxiv.org/abs/2507.11919)
*Wei Zhou,Wei-Jian Li,Wei-Xin Ren*

Main category: eess.SP

TL;DR: TFMD是一种新型的非迭代信号分解框架，通过将信号转换为时频域图像并分割高能量区域，实现快速、鲁棒和自适应的多组分信号分解。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在准确性、计算成本和先验信息需求之间的权衡问题。

Method: 将信号分解任务转化为图像分割问题，通过平滑、自适应阈值和连通区域标记等技术提取模式。

Result: 在合成信号和实际振动信号中表现出高精度和鲁棒性，尤其在噪声环境下表现优异。

Conclusion: TFMD提供了一种计算高效且功能强大的多组分信号分析方法，适用于大规模或时间敏感的应用。

Abstract: The decomposition of complex, multicomponent, and non-stationary signals into
their constituent modes is a fundamental yet significant challenge in science
and engineering. Existing methods often struggle with a trade-off among
accuracy, computational cost, and the need for prior information such as the
number of modes. This paper introduces time-frequency mode decomposition
(TFMD), a novel framework for the fast, robust, and adaptive decomposition of
such signals. TFMD operates on the principle that modes form contiguous
high-energy regions in the time-frequency domain. Its non-iterative pipeline
reframes signal decomposition as an image segmentation task: a signal is
transformed into a spectrogram, which is then smoothed to enhance the
continuity of these high-energy regions. A sequence of adaptive thresholding
and connected-component labeling with size-based filtering is then employed to
automatically segment the spectrogram and generate a mask for each mode. The
modes are finally reconstructed via the inverse short-time Fourier transform.
Validation on diverse synthetic signals demonstrates that TFMD accurately
determines the number of modes and reconstructs them with high fidelity. Its
performance is particularly strong in high-noise conditions. A comparative
analysis confirms that TFMD provides robust, competitive performance across a
wider variety of signal types, while a theoretical complexity analysis reveals
its superior computational efficiency stemming from its non-iterative design.
The method's practical utility is further demonstrated by successfully
extracting modal responses from a real-world footbridge vibration signal. TFMD
provides a computationally efficient and powerful paradigm for multicomponent
signal analysis, offering a compelling balance of accuracy, versatility, and
efficiency for large-scale or time-sensitive applications.

</details>


### [6] [DSSD: Efficient Edge-Device Deployment and Collaborative Inference via Distributed Split Speculative Decoding](https://arxiv.org/abs/2507.12000)
*Jiahong Ning,Ce Zheng,Tingting Yang*

Main category: eess.SP

TL;DR: 论文提出了一种分布式分割推测解码（DSSD）架构，通过设备与边缘协作减少通信延迟，同时保持推理质量。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在设备-边缘系统中部署时面临的资源限制和通信开销问题。

Method: 采用分布式分割推测解码（DSSD），将验证阶段分割在设备和边缘之间，减少上行传输。

Result: 实验表明DSSD在减少通信延迟的同时保持了推理质量，优于现有方法。

Conclusion: DSSD是一种高效的设备-边缘协作框架，显著提升了LLMs的部署效率。

Abstract: Large language models (LLMs) have transformed natural language processing but
face critical deployment challenges in device-edge systems due to resource
limitations and communication overhead. To address these issues, collaborative
frameworks have emerged that combine small language models (SLMs) on devices
with LLMs at the edge, using speculative decoding (SD) to improve efficiency.
However, existing solutions often trade inference accuracy for latency or
suffer from high uplink transmission costs when verifying candidate tokens. In
this paper, we propose Distributed Split Speculative Decoding (DSSD), a novel
architecture that not only preserves the SLM-LLM split but also partitions the
verification phase between the device and edge. In this way, DSSD replaces the
uplink transmission of multiple vocabulary distributions with a single downlink
transmission, significantly reducing communication latency while maintaining
inference quality. Experiments show that our solution outperforms current
methods, and codes are at:
https://github.com/JasonNing96/DSSD-Efficient-Edge-Computing

</details>


### [7] [Enhancing Situational Awareness in ISAC Networks via Drone Swarms: A Real-World Channel Sounding Data Set](https://arxiv.org/abs/2507.12010)
*Julia Beuster,Carsten Andrich,Sebastian Giehl,Marc Miranda,Lorenz Mohr,Dieter Novotny,Tom Kaufmann,Christian Schneider,Reiner Thomä*

Main category: eess.SP

TL;DR: 论文提出了一种基于6G网络中无人机群的多静态雷达感知方法，通过真实世界信道测量数据集验证了其潜力。


<details>
  <summary>Details</summary>
Motivation: 利用6G网络中的集成感知与通信（ISAC）和无人机设备（UAVs）提升多静态雷达感知能力，增强环境感知。

Method: 使用分布式地面和飞行传感器节点组成的测试平台，采集多路径环境下的双静态反射率数据。

Result: 展示了无人机群协作在多静态雷达跟踪和定位中的潜力，并公开数据集以支持未来ISAC算法开发。

Conclusion: 该方法为未来ISAC算法在真实环境中的应用提供了验证基础，减少对模拟的依赖。

Abstract: With the upcoming capabilities of integrated sensing and communication (ISAC)
and the incorporation of user equipment (UE) like unmanned aerial vehicles
(UAVs) in 6G mobile networks, there is a significant opportunity to enhance
situational awareness through multi-static radar sensing in meshed ISAC
networks. This paper presents a real-world channel sounding data set acquired
using a testbed with synchronized, distributed ground-based sensor nodes and
flying sensor nodes within a swarm of up to four drones. The conducted
measurement campaign is designed to sense the bi-static reflectivity of objects
such as parking cars, vertical take-off and landing (VTOL) aircraft, and small
drones in multi-path environments. We detail the rationale behind the selection
of the included scenarios and the configuration of the participating nodesand
present exemplary results to demonstrate the potential of using collaborating
drone swarms for multi-static radar tracking and localization in air-to-air
(A2A) and air-to-ground (A2G) scenarios. The data sets are publicly available
to support the development and validation of future ISAC algorithms in
real-world environments rather than relying solely on simulation.

</details>


### [8] [DoRF: Doppler Radiance Fields for Robust Human Activity Recognition Using Wi-Fi](https://arxiv.org/abs/2507.12132)
*Navid Hasanzadeh,Shahrokh Valaee*

Main category: eess.SP

TL;DR: 论文提出了一种基于Wi-Fi CSI的多普勒速度投影重建3D潜在运动表示的方法，通过构建统一的多普勒辐射场（DoRF）提升人类活动识别的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管Wi-Fi CSI在多普勒速度投影方面已有进展，但泛化能力仍不足以实际应用，因此需要一种更鲁棒的方法。

Method: 受神经辐射场（NeRF）启发，从一维多普勒速度投影重建3D潜在运动表示，并构建统一的DoRF。

Result: 实验表明，该方法显著提升了Wi-Fi HAR的泛化准确性。

Conclusion: DoRF在实用传感应用中具有巨大潜力。

Abstract: Wi-Fi Channel State Information (CSI) has gained increasing interest for
remote sensing applications. Recent studies show that Doppler velocity
projections extracted from CSI can enable human activity recognition (HAR) that
is robust to environmental changes and generalizes to new users. However,
despite these advances, generalizability still remains insufficient for
practical deployment. Inspired by neural radiance fields (NeRF), which learn a
volumetric representation of a 3D scene from 2D images, this work proposes a
novel approach to reconstruct an informative 3D latent motion representation
from one-dimensional Doppler velocity projections extracted from Wi-Fi CSI. The
resulting latent representation is then used to construct a uniform Doppler
radiance field (DoRF) of the motion, providing a comprehensive view of the
performed activity and improving the robustness to environmental variability.
The results show that the proposed approach noticeably enhances the
generalization accuracy of Wi-Fi-based HAR, highlighting the strong potential
of DoRFs for practical sensing applications.

</details>


### [9] [A Practical Analysis: Understanding Phase Noise Modelling in Time and Frequency Domain for Phase-Locked Loops](https://arxiv.org/abs/2507.12146)
*Carl Collmann,Bitan Banerjee,Ahmad Nimr,Gerhard Fettweis*

Main category: eess.SP

TL;DR: 该论文提出了一种针对USRP X310系列SDR设备的相位噪声建模方法，填补了现有文献中缺乏实测数据支持的空白。


<details>
  <summary>Details</summary>
Motivation: MIMO系统中相位噪声会显著降低性能，尤其是需要相位同步的数字波束成形应用。然而，SDR设备的相位噪声性能在数据手册中信息不足，现有文献也缺乏实测支持的系统建模。

Method: 基于测量数据，论文提出了USRP X310系列SDR的相位噪声建模方法，估计了PLL的关键性能指标（如周期抖动、振荡器常数和PLL带宽），并建立了相位噪声功率谱密度的参数化模型。

Result: 通过测量数据，论文得出了PLL性能指标的估计值，并提供了相位噪声PSD的参数化模型及其参数估计。

Conclusion: 该模型可用于进一步研究相位噪声对类似SDR设备实现的MIMO系统性能的影响。

Abstract: In MIMO systems, the presence of phase noise is a significant factor that can
degrade performance. For MIMO testbeds build from SDR devices, phase noise
cannot be ignored, particular in applications that require phase
synchronization. This is especially relevant in MIMO systems that employ
digital beamforming, where precise phase alignment is crucial. Accordingly,
accurate phase noise modelling of SDR devices is essential. However, the
information provided in data sheets for different SDR models varies widely and
is often insufficient for comprehensive characterization of their phase noise
performance. While numerical simulations of PLL phase noise behavior are
documented in the literature, there is a lack of extensive measurements
supported by appropriate system modelling. In this work, we present a practical
phase noise modeling methodology applied to an SDR from the USRP X310 series.
Based on measurement data, we derive estimates of key PLL performance
indicators such as cycle-to-cycle jitter, oscillator constants, and PLL
bandwidth. Furthermore, we propose a parametric model for the phase noise PSD
of the PLL circuit and provide corresponding parameter estimates. This model
can be used for further investigation into the impact of phase noise on MIMO
system performance implemented by similar SDR devices.

</details>


### [10] [PAPR of DFT-s-OTFS with Pulse Shaping](https://arxiv.org/abs/2507.12210)
*Jialiang Zhu,Sanoopkumar P. S.,Arman Farhang*

Main category: eess.SP

TL;DR: DFT-s-OTFS方案通过在多普勒维度应用DFT扩展，降低了OTFS的高PAPR问题。分析表明，交错分配策略比块分配策略PAPR更低，且简化了发射机设计。RRC脉冲的PAPR高于矩形脉冲。BER性能与未扩展的OTFS相同。


<details>
  <summary>Details</summary>
Motivation: 解决OTFS在多普勒bin数量大时的高PAPR问题。

Method: 采用DFT扩展OTFS（DFT-s-OTFS），分析不同脉冲整形滤波器和资源分配策略下的PAPR。

Result: 交错分配策略PAPR更低，RRC脉冲PAPR较高，BER性能与OTFS相同。

Conclusion: DFT-s-OTFS可有效降低PAPR，且不影响BER性能，适合上行链路场景。

Abstract: Orthogonal Time Frequency Space (OTFS) suffers from high peak-to-average
power ratio (PAPR) when the number of Doppler bins is large. To address this
issue, a discrete Fourier transform spread OTFS (DFT-s-OTFS) scheme is employed
by applying DFT spreading across the Doppler dimension. This paper presents a
thorough PAPR analysis of DFT-s-OTFS in the uplink scenario using different
pulse shaping filters and resource allocation strategies. Specifically, we
derive a PAPR upper bound of DFT-s-OTFS with interleaved and block Doppler
resource allocation schemes. Our analysis reveals that DFT-s-OTFS with
interleaved allocation yields a lower PAPR than that of block allocation.
Furthermore, we show that interleaved allocation produces a periodic
time-domain signal composed of repeated quadrature amplitude modulated (QAM)
symbols which simplifies the transmitter design. Based on our analytical
results, the root raised cosine (RRC) pulse generally results in a higher
maximum PAPR compared to the rectangular pulse. Simulation results confirm the
validity of the derived PAPR upper bounds. Furthermore, we also demonstrate
through BER simulation analysis that the DFT-s-OTFS gives the same performance
as OTFS without DFT spreading.

</details>


### [11] [Cell Sensing: Traffic detection](https://arxiv.org/abs/2507.12211)
*Saúl Fenollosa*

Main category: eess.SP

TL;DR: 提出了一种利用LTE信号进行交通监测的被动感知系统，通过双接收器架构分析CSI，有效隔离移动目标引起的多普勒频移，并在室内外测试中表现出高精度。


<details>
  <summary>Details</summary>
Motivation: 传统交通监测方法存在侵入性和扩展性问题，利用LTE信号提供了一种非侵入且可扩展的替代方案。

Method: 采用双接收器架构分析CSI，结合SDR平台和srsRAN软件，隔离多普勒频移并减少硬件引起的相位失真。

Result: 室内测试中速度高于6000 mm/min的目标检测准确率超过90%，室外测试中能可靠估计行人和车辆速度。

Conclusion: LTE被动感知在交通监测中可行，但需解决低速、方向模糊和多径衰落等问题，未来可结合AoA、机器学习和实时嵌入式系统优化。

Abstract: This work presents a passive sensing system for traffic monitoring using
ambient Long Term Evolution (LTE) signals as a non-intrusive and scalable
alternative to traditional surveillance methods. The approach employs a
dual-receiver architecture analyzing Channel State Information (CSI) to isolate
differential Doppler shifts induced by moving targets, effectively mitigating
hardware-induced phase impairments. Implemented with a Software Defined Radio
(SDR) platform and srsRAN software, the system demonstrated over 90% detection
accuracy for speeds above 6000 mm/min in controlled indoor tests, and provided
reliable speed estimations for pedestrians and vehicles in outdoor evaluations.
Despite challenges at low speeds, directional ambiguity, and multipath fading
in urban settings, the results validate LTE-based passive sensing as a feasible
traffic monitoring method, identifying critical areas for future research such
as angle-of-arrival (AoA) integration, machine learning, and real-time embedded
system development.

</details>


### [12] [Novel Approach to Dual-Channel Estimation in Integrated Sensing and Communications for 6G](https://arxiv.org/abs/2507.12221)
*Alejandro Castilla,Saúl Fenollosa,Monika Drozdowska,Alejandro Lopez-Escudero,Sergio Micò-Rosa,Narcis Cardona*

Main category: eess.SP

TL;DR: 本文探讨了6G中集成传感与通信（ISAC）的双通道模型，通过毫米波雷达提取双基地传感通道，并验证了通信通道估计方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要集成传感与通信，因此需要理解和建模双通道模型，以提升ISAC的准确性。

Method: 采用干扰提取、模块和相位相关分析、线性调频聚类和自动杂波减少等技术，从单基地测量中提取双基地传感通道。

Result: 在消声室中验证了方法的有效性，通过RMS DS、PDP和AoA分析展示了成功的通道提取，并与射线追踪模拟结果进行了对比。

Conclusion: 提出的方法为未来网络中完全集成传感与通信提供了创新性进展。

Abstract: Integrated Sensing and Communication (ISAC) design is crucial for 6G and
harmonizes environmental data sensing with communication, emphasizing the need
to understand and model these elements. This paper delves into dual-channel
models for ISAC, employing channel extraction techniques to validate and
enhance accuracy. Focusing on millimeter wave (mmWave) radars, it explores the
extraction of the bistatic sensing channel from monostatic measurements and
subsequent communication channel estimation. The proposed methods involve
interference extraction, module and phase correlation analyses, chirp
clustering, and auto-clutter reduction. A comprehensive set-up in an anechoic
chamber with controlled scenarios evaluates the proposed techniques,
demonstrating successful channel extraction and validation through Root Mean
Square Delay Spread (RMS DS), Power Delay Profile (PDP), and Angle of Arrival
(AoA) analysis. Comparison with Ray-Tracing (RT) simulations confirms the
effectiveness of the proposed approach, presenting an innovative stride towards
fully integrated sensing and communication in future networks.

</details>


### [13] [Frequency-responsive RCS characteristics and scaling implications for ISAC development](https://arxiv.org/abs/2507.12235)
*Saúl Fenollosa,Monika Drozdowska,Wenfei Yang,Sergio Micó-Rosa,Alejandro Castilla,Alejandro Lopez-Escudero,Jian Li,Narcis Cardona*

Main category: eess.SP

TL;DR: 研究了不同目标的雷达散射截面（RCS）随频率变化的特性，包括AGV、行人和全尺寸汽车，测量环境多样，方法包括背景扣除和时域门控。


<details>
  <summary>Details</summary>
Motivation: 分析RCS随频率和目标形状的变化，为6G标准中的集成感知与通信（ISAC）技术提供支持。

Method: 采用背景扣除和时域门控方法提取RCS，测量在FR2和FR3频段进行。

Result: RCS值随频率和目标形状变化显著，不同材料和形状的RCS缩放复杂。

Conclusion: 研究结果对提升传感系统和优化3GPP信道模型具有重要意义，尤其适用于6G ISAC技术。

Abstract: This paper presents an investigation on the Radar Cross-Section (RCS) of
various targets, with the objective of analysing how RCS properties vary with
frequency. Targets such as an Automated Guided Vehicle (AGV), a pedestrian, and
a full-scale car were measured in the frequency bands referred to in industry
standards as FR2 and FR3. Measurements were taken in diverse environments,
indoors and outdoors, to ensure comprehensive scenario coverage. The
methodology employed in RCS extraction performs background subtraction,
followed by time-domain gating to isolate the influence of the target. This
analysis compares the RCS values and how the points of greatest contribution
are distributed across different bands based on the range response of the RCS.
Analysis of the results demonstrated how RCS values change with frequency and
target shape, providing insights into the electromagnetic behaviour of these
targets. Key findings highlight how much scaling RCS values based on frequency
and geometry is complex and varies among different types of materials and
shapes. These insights are instrumental for advancing sensing systems and
enhancing 3GPP channel models, particularly for Integrated Sensing and
Communications (ISAC) techniques proposed for 6G standards.

</details>


### [14] [Leveraging Bi-Directional Channel Reciprocity for Robust Ultra-Low-Rate Implicit CSI Feedback with Deep Learning](https://arxiv.org/abs/2507.12301)
*Zhenyu Liu,Yi Ma,Rahim Tafazolli,Zhi Ding*

Main category: eess.SP

TL;DR: 论文提出Dual-ImRUNet框架，通过两个预处理模块实现超低反馈率和高环境鲁棒性，反馈开销减少85%。


<details>
  <summary>Details</summary>
Motivation: 现有方法在超低速率场景和多样化环境中性能下降，缺乏适应性。

Method: 提出双向相关性增强模块和输入格式对齐模块，结合基于Transformer的隐式CSI反馈网络。

Result: 反馈开销减少85%，并在未见环境中表现出鲁棒性。

Conclusion: Dual-ImRUNet在超低速率和多样化环境中表现优异。

Abstract: Deep learning-based implicit channel state information (CSI) feedback has
been introduced to enhance spectral efficiency in massive MIMO systems.
Existing methods often show performance degradation in ultra-low-rate scenarios
and inadaptability across diverse environments. In this paper, we propose
Dual-ImRUNet, an efficient uplink-assisted deep implicit CSI feedback framework
incorporating two novel plug-in preprocessing modules to achieve ultra-low
feedback rates while maintaining high environmental robustness. First, a novel
bi-directional correlation enhancement module is proposed to strengthen the
correlation between uplink and downlink CSI eigenvector matrices. This module
projects highly correlated uplink and downlink channel matrices into their
respective eigenspaces, effectively reducing redundancy for ultra-low-rate
feedback. Second, an innovative input format alignment module is designed to
maintain consistent data distributions at both encoder and decoder sides
without extra transmission overhead, thereby enhancing robustness against
environmental variations. Finally, we develop an efficient transformer-based
implicit CSI feedback network to exploit angular-delay domain sparsity and
bi-directional correlation for ultra-low-rate CSI compression. Simulation
results demonstrate successful reduction of the feedback overhead by 85%
compared with the state-of-the-art method and robustness against unseen
environments.

</details>


### [15] [Road Roughness Estimation via Fusion of Standard Onboard Automotive Sensors](https://arxiv.org/abs/2507.12317)
*Martin Agebjär,Gustav Zetterqvist,Fredrik Gustafsson,Johan Wahlström,Gustaf Hendeby*

Main category: eess.SP

TL;DR: 提出了一种基于卡尔曼滤波的方法，通过融合惯性和速度测量来估计道路粗糙度（IRI），为路面监测提供了一种经济高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 道路粗糙度对车辆振动和乘坐质量有显著影响，需要一种成本效益高的方法来监测路面状况。

Method: 通过系统识别物理车辆估计模型参数，然后基于卡尔曼滤波重建纵向道路轮廓以计算IRI值，同时探索了垂直和横向振动的IRI估计。

Result: 在230公里的真实数据验证中，IRI估计误差为参考值的1%到10%，但仅使用横向振动时精度显著下降。

Conclusion: 卡尔曼滤波方法在道路粗糙度监测中具有潜力，但横向振动的使用存在局限性。

Abstract: Road roughness significantly affects vehicle vibrations and ride quality. We
introduce a Kalman filter (KF)-based method for estimating road roughness in
terms of the international roughness index (IRI) by fusing inertial and speed
measurements, offering a cost-effective solution for pavement monitoring. The
method involves system identification on a physical vehicle to estimate
realistic model parameters, followed by KF-based reconstruction of the
longitudinal road profile to compute IRI values. It explores IRI estimation
using vertical and lateral vibrations, the latter more common in modern
vehicles. Validation on 230 km of real-world data shows promising results, with
IRI estimation errors ranging from 1% to 10% of the reference values. However,
accuracy deteriorates significantly when using only lateral vibrations,
highlighting their limitations. These findings demonstrate the potential of
KF-based estimation for efficient road roughness monitoring.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [16] [JSQA: Speech Quality Assessment with Perceptually-Inspired Contrastive Pretraining Based on JND Audio Pairs](https://arxiv.org/abs/2507.11636)
*Junyi Fan,Donald Williamson*

Main category: eess.AS

TL;DR: JSQA是一个两阶段框架，通过感知引导的对比学习预训练音频编码器，再微调用于MOS预测，显著提升语音质量评估性能。


<details>
  <summary>Details</summary>
Motivation: 语音质量评估（SQA）中，MOS标签的高方差和缺乏感知因素的融入导致模型性能不佳。

Method: JSQA框架：1）基于JND对的感知对比学习预训练音频编码器；2）微调用于MOS预测。

Result: 实验表明，感知对比预训练显著提升了模型性能。

Conclusion: 将感知因素融入预训练对SQA性能提升至关重要。

Abstract: Speech quality assessment (SQA) is often used to learn a mapping from a
high-dimensional input space to a scalar that represents the mean opinion score
(MOS) of the perceptual speech quality. Learning such a mapping is challenging
for many reasons, but largely because MOS exhibits high levels of inherent
variance due to perceptual and experimental-design differences. Many solutions
have been proposed, but many approaches do not properly incorporate perceptual
factors into their learning algorithms (beyond the MOS label), which could lead
to unsatisfactory results. To this end, we propose JSQA, a two-stage framework
that pretrains an audio encoder using perceptually-guided contrastive learning
on just noticeable difference (JND) pairs, followed by fine-tuning for MOS
prediction. We first generate pairs of audio data within JND levels, which are
then used to pretrain an encoder to leverage perceptual quality similarity
information and map it into an embedding space. The JND pairs come from clean
LibriSpeech utterances that are mixed with background noise from CHiME-3, at
different signal-to-noise ratios (SNRs). The encoder is later fine-tuned with
audio samples from the NISQA dataset for MOS prediction. Experimental results
suggest that perceptually-inspired contrastive pretraining significantly
improves the model performance evaluated by various metrics when compared
against the same network trained from scratch without pretraining. These
findings suggest that incorporating perceptual factors into pretraining greatly
contributes to the improvement in performance for SQA.

</details>


### [17] [Self-Boosted Weight-Constrained FxLMS: A Robustness Distributed Active Noise Control Algorithm Without Internode Communication](https://arxiv.org/abs/2507.12045)
*Junwei Ji,Dongyuan Shi,Zhengding Luo,Boxiang Wang,Woon-Seng Gan*

Main category: eess.AS

TL;DR: 提出了一种自增强权重约束滤波参考最小均方（SB-WCFxLMS）算法，用于分布式多通道主动噪声控制系统，无需节点间通信，显著降低了计算复杂性和通信开销。


<details>
  <summary>Details</summary>
Motivation: 传统集中式多通道主动噪声控制（MCANC）算法计算资源需求高，而分散式方法计算效率高但噪声抑制性能较差。分布式ANC方法虽能提升性能，但通信延迟影响系统稳定性。

Method: 设计了WCFxLMS算法以解决节点间串扰效应引起的发散问题，并采用自增强策略使每个ANC节点独立调整约束参数，无需节点间通信。

Result: 数值模拟验证了该系统的有效性和鲁棒性，结果表明该方法在资源需求最小的情况下实现了满意的噪声抑制性能。

Conclusion: 提出的SB-WCFxLMS算法在分布式MCANC系统中表现出色，兼顾了性能和资源效率。

Abstract: Compared to the conventional centralized multichannel active noise control
(MCANC) algorithm, which requires substantial computational resources,
decentralized approaches exhibit higher computational efficiency but typically
result in inferior noise reduction performance. To enhance performance,
distributed ANC methods have been introduced, enabling information exchange
among ANC nodes; however, the resulting communication latency often compromises
system stability. To overcome these limitations, we propose a self-boosted
weight-constrained filtered-reference least mean square (SB-WCFxLMS) algorithm
for the distributed MCANC system without internode communication. The WCFxLMS
algorithm is specifically designed to mitigate divergence issues caused by the
internode cross-talk effect. The self-boosted strategy lets each ANC node
independently adapt its constraint parameters based on its local noise
reduction performance, thus ensuring effective noise cancellation without the
need for inter-node communication. With the assistance of this mechanism, this
approach significantly reduces both computational complexity and communication
overhead. Numerical simulations employing real acoustic paths and compressor
noise validate the effectiveness and robustness of the proposed system. The
results demonstrate that our proposed method achieves satisfactory noise
cancellation performance with minimal resource requirements.

</details>


### [18] [VoxATtack: A Multimodal Attack on Voice Anonymization Systems](https://arxiv.org/abs/2507.12081)
*Ahmad Aloradi,Ünal Ege Gaznepoglu,Emanuël A. P. Habets,Daniel Tenbrinck*

Main category: eess.AS

TL;DR: VoxATtack是一种新型多模态去匿名化模型，结合声学和文本信息攻击语音匿名化系统，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 语音匿名化系统保留语言内容但可能暴露说话者语义模式，需研究其漏洞。

Method: 采用双分支架构，ECAPA-TDNN处理匿名语音，BERT编码文本，融合后基于置信权重提升性能。

Result: 在VPAC数据集上，VoxATtack在5/7基准测试中优于现有方法，数据增强后性能进一步提升。

Conclusion: 结合文本信息和数据增强揭示了当前语音匿名化方法的漏洞和数据集潜在弱点。

Abstract: Voice anonymization systems aim to protect speaker privacy by obscuring vocal
traits while preserving the linguistic content relevant for downstream
applications. However, because these linguistic cues remain intact, they can be
exploited to identify semantic speech patterns associated with specific
speakers. In this work, we present VoxATtack, a novel multimodal
de-anonymization model that incorporates both acoustic and textual information
to attack anonymization systems. While previous research has focused on
refining speaker representations extracted from speech, we show that
incorporating textual information with a standard ECAPA-TDNN improves the
attacker's performance. Our proposed VoxATtack model employs a dual-branch
architecture, with an ECAPA-TDNN processing anonymized speech and a pretrained
BERT encoding the transcriptions. Both outputs are projected into embeddings of
equal dimensionality and then fused based on confidence weights computed on a
per-utterance basis. When evaluating our approach on the VoicePrivacy Attacker
Challenge (VPAC) dataset, it outperforms the top-ranking attackers on five out
of seven benchmarks, namely B3, B4, B5, T8-5, and T12-5. To further boost
performance, we leverage anonymized speech and SpecAugment as augmentation
techniques. This enhancement enables VoxATtack to achieve state-of-the-art on
all VPAC benchmarks, after scoring 20.6% and 27.2% average equal error rate on
T10-2 and T25-1, respectively. Our results demonstrate that incorporating
textual information and selective data augmentation reveals critical
vulnerabilities in current voice anonymization methods and exposes potential
weaknesses in the datasets used to evaluate them.

</details>


### [19] [Soft-Constrained Spatially Selective Active Noise Control for Open-fitting Hearables](https://arxiv.org/abs/2507.12122)
*Tong Xiao,Reinhild Roden,Matthias Blau,Simon Doclo*

Main category: eess.AS

TL;DR: 提出了一种软约束的空间选择性主动噪声控制（SSANC）系统，通过频率无关参数在语音失真和噪声抑制之间进行权衡，显著提升了信噪比和语音质量。


<details>
  <summary>Details</summary>
Motivation: 旨在减少语音失真，同时实现噪声抑制，改进传统硬约束SSANC的局限性。

Method: 提出软约束SSANC系统，推导时域和频域公式，并通过仿真验证其性能。

Result: 仿真结果表明，软约束设计在广泛参数范围内显著提升信噪比、语音质量和可懂度（PESQ和ESTOI）。

Conclusion: 软约束SSANC系统优于硬约束设计，为噪声控制提供了更灵活的解决方案。

Abstract: Recent advances in spatially selective active noise control (SSANC) using
multiple microphones have enabled hearables to suppress undesired noise while
preserving desired speech from a specific direction. Aiming to achieve minimal
speech distortion, a hard constraint has been used in previous work in the
optimization problem to compute the control filter. In this work, we propose a
soft-constrained SSANC system that uses a frequency-independent parameter to
trade off between speech distortion and noise reduction. We derive both time-
and frequency-domain formulations, and show that conventional active noise
control and hard-constrained SSANC represent two limiting cases of the proposed
design. We evaluate the system through simulations using a pair of open-fitting
hearables in an anechoic environment with one speech source and two noise
sources. The simulation results validate the theoretical derivations and
demonstrate that for a broad range of the trade-off parameter, the
signal-to-noise ratio and the speech quality and intelligibility in terms of
PESQ and ESTOI can be substantially improved compared to the hard-constrained
design.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [20] [Towards Scalable AASIST: Refining Graph Attention for Speech Deepfake Detection](https://arxiv.org/abs/2507.11777)
*Ivan Viakhirev,Daniil Sirota,Aleksandr Smirnov,Kirill Borodin*

Main category: cs.SD

TL;DR: 论文通过改进AASIST架构，结合Wav2Vec 2.0编码器和多注意力模块，提升了语音防伪检测性能，在ASVspoof 5数据集上达到7.6%的EER。


<details>
  <summary>Details</summary>
Motivation: 语音转换和文本到语音技术的进步使得自动说话人验证系统更容易受到欺骗攻击，需要改进防伪检测方法。

Method: 结合冻结的Wav2Vec 2.0编码器，替换图注意力模块为多注意力模块，并引入可训练的上下文感知融合层。

Result: 在ASVspoof 5数据集上，改进后的系统EER为7.6%，优于基准模型。

Conclusion: 针对已有模型的针对性调整可以提升语音防伪检测性能，适用于实际场景。

Abstract: Advances in voice conversion and text-to-speech synthesis have made automatic
speaker verification (ASV) systems more susceptible to spoofing attacks. This
work explores modest refinements to the AASIST anti-spoofing architecture. It
incorporates a frozen Wav2Vec 2.0 encoder to retain self-supervised speech
representations in limited-data settings, substitutes the original graph
attention block with a standardized multi-head attention module using
heterogeneous query projections, and replaces heuristic frame-segment fusion
with a trainable, context-aware integration layer. When evaluated on the
ASVspoof 5 corpus, the proposed system reaches a 7.6\% equal error rate (EER),
improving on a re-implemented AASIST baseline under the same training
conditions. Ablation experiments suggest that each architectural change
contributes to the overall performance, indicating that targeted adjustments to
established models may help strengthen speech deepfake detection in practical
scenarios. The code is publicly available at
https://github.com/KORALLLL/AASIST_SCALING.

</details>


### [21] [A Multimodal Data Fusion Generative Adversarial Network for Real Time Underwater Sound Speed Field Construction](https://arxiv.org/abs/2507.11812)
*Wei Huang,Yuqiang Huang,Yanan Wu,Tianhe Xu,Junting Wang,Hao Zhang*

Main category: cs.SD

TL;DR: 提出了一种多模态数据融合生成对抗网络模型（MDF-RAGAN），用于高精度估计声速分布，无需现场水下数据测量。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖现场声纳观测数据，部署要求严格，限制了声速分布的估计精度和灵活性。

Method: 采用多模态数据融合生成对抗网络模型，嵌入注意力机制和残差模块，以捕捉全局空间特征和小扰动。

Result: 在真实数据集上，误差小于0.3m/s，优于CNN和SITP方法，RMSE降低65.8%。

Conclusion: MDF-RAGAN通过多源融合和跨模态注意力显著提升了声速分布估计的精度和匹配性。

Abstract: Sound speed profiles (SSPs) are essential parameters underwater that affects
the propagation mode of underwater signals and has a critical impact on the
energy efficiency of underwater acoustic communication and accuracy of
underwater acoustic positioning. Traditionally, SSPs can be obtained by
matching field processing (MFP), compressive sensing (CS), and deep learning
(DL) methods. However, existing methods mainly rely on on-site underwater sonar
observation data, which put forward strict requirements on the deployment of
sonar observation systems. To achieve high-precision estimation of sound
velocity distribution in a given sea area without on-site underwater data
measurement, we propose a multi-modal data-fusion generative adversarial
network model with residual attention block (MDF-RAGAN) for SSP construction.
To improve the model's ability for capturing global spatial feature
correlations, we embedded the attention mechanisms, and use residual modules
for deeply capturing small disturbances in the deep ocean sound velocity
distribution caused by changes of SST. Experimental results on real open
dataset show that the proposed model outperforms other state-of-the-art
methods, which achieves an accuracy with an error of less than 0.3m/s.
Specifically, MDF-RAGAN not only outperforms convolutional neural network (CNN)
and spatial interpolation (SITP) by nearly a factor of two, but also achieves
about 65.8\% root mean square error (RMSE) reduction compared to mean profile,
which fully reflects the enhancement of overall profile matching by
multi-source fusion and cross-modal attention.

</details>


### [22] [Schrödinger Bridge Consistency Trajectory Models for Speech Enhancement](https://arxiv.org/abs/2507.11925)
*Shuichiro Nishigori,Koichi Saito,Naoki Murata,Masato Hirano,Shusuke Takahashi,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: 论文提出了一种基于Schrödinger桥的一致性轨迹模型（SBCTM），用于语音增强，通过改进训练框架和引入辅助损失，显著提升了推理速度和质量。


<details>
  <summary>Details</summary>
Motivation: 解决Schrödinger桥在语音增强中因需要大量函数评估而导致的推理速度慢的问题，同时保持生成质量。

Method: 将一致性轨迹模型（CTM）技术应用于Schrödinger桥，并引入新的辅助损失（包括感知损失）改进训练框架。

Result: SBCTM实现了约16倍的实时因子（RTF）提升，并在质量和速度之间取得了良好的平衡。

Conclusion: SBCTM在语音增强领域展示了高效且高质量的推理能力，适用于需要快速响应的场景。

Abstract: Speech enhancement (SE) utilizing diffusion models is a promising technology
that improves speech quality in noisy speech data. Furthermore, the
Schr\"odinger bridge (SB) has recently been used in diffusion-based SE to
improve speech quality by resolving a mismatch between the endpoint of the
forward process and the starting point of the reverse process. However, the SB
still exhibits slow inference owing to the necessity of a large number of
function evaluations (NFE) for inference to obtain high-quality results. While
Consistency Models (CMs) address this issue by employing consistency training
that uses distillation from pretrained models in the field of image generation,
it does not improve generation quality when the number of steps increases. As a
solution to this problem, Consistency Trajectory Models (CTMs) not only
accelerate inference speed but also maintain a favorable trade-off between
quality and speed. Furthermore, SoundCTM demonstrates the applicability of CTM
techniques to the field of sound generation. In this paper, we present
Schr\"odinger bridge Consistency Trajectory Models (SBCTM) by applying the
CTM's technique to the Schr\"odinger bridge for SE. Additionally, we introduce
a novel auxiliary loss, including a perceptual loss, into the original CTM's
training framework. As a result, SBCTM achieves an approximately 16x
improvement in the real-time factor (RTF) compared to the conventional
Schr\"odinger bridge for SE. Furthermore, the favorable trade-off between
quality and speed in SBCTM allows for time-efficient inference by limiting
multi-step refinement to cases where 1-step inference is insufficient. Our
code, pretrained models, and audio samples are available at
https://github.com/sony/sbctm/.

</details>


### [23] [EME-TTS: Unlocking the Emphasis and Emotion Link in Speech Synthesis](https://arxiv.org/abs/2507.12015)
*Haoxun Li,Leyuan Qu,Jiaxi Hu,Taihao Li*

Main category: cs.SD

TL;DR: EME-TTS是一个结合情感和强调控制的TTS框架，通过弱监督学习和EPE块增强情感表达和强调稳定性。


<details>
  <summary>Details</summary>
Motivation: 探索情感TTS与强调控制的交互，提升情感语音的表达力和强调的稳定性。

Method: 采用弱监督学习（强调伪标签和方差特征）和EPE块增强情感与强调的交互。

Result: 实验表明EME-TTS能生成更自然的情感语音，同时保持强调的稳定性和区分性。

Conclusion: EME-TTS为情感和强调控制的结合提供了有效解决方案。

Abstract: In recent years, emotional Text-to-Speech (TTS) synthesis and
emphasis-controllable speech synthesis have advanced significantly. However,
their interaction remains underexplored. We propose Emphasis Meets Emotion TTS
(EME-TTS), a novel framework designed to address two key research questions:
(1) how to effectively utilize emphasis to enhance the expressiveness of
emotional speech, and (2) how to maintain the perceptual clarity and stability
of target emphasis across different emotions. EME-TTS employs weakly supervised
learning with emphasis pseudo-labels and variance-based emphasis features.
Additionally, the proposed Emphasis Perception Enhancement (EPE) block enhances
the interaction between emotional signals and emphasis positions. Experimental
results show that EME-TTS, when combined with large language models for
emphasis position prediction, enables more natural emotional speech synthesis
while preserving stable and distinguishable target emphasis across emotions.
Synthesized samples are available on-line.

</details>


### [24] [Stereo Sound Event Localization and Detection with Onscreen/offscreen Classification](https://arxiv.org/abs/2507.12042)
*Kazuki Shimada,Archontis Politis,Iran R. Roman,Parthasaarathy Sudarsanam,David Diaz-Guerra,Ruchi Pandey,Kengo Uchida,Yuichiro Koyama,Naoya Takahashi,Takashi Shibuya,Shusuke Takahashi,Tuomas Virtanen,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: DCASE2025挑战赛任务3聚焦于立体声音频数据的声音事件定位与检测（SELD），引入新的数据集和基线系统，并调整了评估指标以适应有限视野场景。


<details>
  <summary>Details</summary>
Motivation: 研究立体声音频数据在声音事件定位与检测中的应用，以解决更常见的有限视野场景下的问题。

Method: 使用立体声音频和视频数据作为输入，基线系统整合了事件分类、定位及屏幕内外分类任务。

Result: 基线系统在立体声音频数据上表现良好。

Conclusion: 立体声音频数据在有限视野场景下的SELD任务中具有潜力，新的评估指标和数据集为未来研究提供了基础。

Abstract: This paper presents the objective, dataset, baseline, and metrics of Task 3
of the DCASE2025 Challenge on sound event localization and detection (SELD). In
previous editions, the challenge used four-channel audio formats of first-order
Ambisonics (FOA) and microphone array. In contrast, this year's challenge
investigates SELD with stereo audio data (termed stereo SELD). This change
shifts the focus from more specialized 360{\deg} audio and audiovisual scene
analysis to more commonplace audio and media scenarios with limited
field-of-view (FOV). Due to inherent angular ambiguities in stereo audio data,
the task focuses on direction-of-arrival (DOA) estimation in the azimuth plane
(left-right axis) along with distance estimation. The challenge remains divided
into two tracks: audio-only and audiovisual, with the audiovisual track
introducing a new sub-task of onscreen/offscreen event classification
necessitated by the limited FOV. This challenge introduces the DCASE2025 Task3
Stereo SELD Dataset, whose stereo audio and perspective video clips are sampled
and converted from the STARSS23 recordings. The baseline system is designed to
process stereo audio and corresponding video frames as inputs. In addition to
the typical SELD event classification and localization, it integrates
onscreen/offscreen classification for the audiovisual track. The evaluation
metrics have been modified to introduce an onscreen/offscreen accuracy metric,
which assesses the models' ability to identify which sound sources are
onscreen. In the experimental evaluation, the baseline system performs
reasonably well with the stereo audio data.

</details>


### [25] [MambaRate: Speech Quality Assessment Across Different Sampling Rates](https://arxiv.org/abs/2507.12090)
*Panos Kakoulidis,Iakovi Alexiou,Junkwang Oh,Gunu Jho,Inchul Hwang,Pirros Tsiakoulis,Aimilios Chalamandaris*

Main category: cs.SD

TL;DR: MambaRate是一种预测音频MOS的模型，针对高采样率语音设计，利用自监督嵌入和选择性状态空间建模，在AudioMOS Challenge 2025中表现优于基线但未夺冠。


<details>
  <summary>Details</summary>
Motivation: 解决高采样率语音MOS预测中的采样率偏差问题，参与AudioMOS Challenge 2025 Track 3。

Method: 结合自监督嵌入和选择性状态空间建模，使用高斯径向基函数编码目标评分。

Result: 初始版本T16在少样本设置中优于基线14%，排名第四；在BVCC数据集上表现更优。

Conclusion: MambaRate在MOS预测任务中表现良好，但仍有改进空间。

Abstract: We propose MambaRate, which predicts Mean Opinion Scores (MOS) with limited
bias regarding the sampling rate of the waveform under evaluation. It is
designed for Track 3 of the AudioMOS Challenge 2025, which focuses on
predicting MOS for speech in high sampling frequencies. Our model leverages
self-supervised embeddings and selective state space modeling. The target
ratings are encoded in a continuous representation via Gaussian radial basis
functions (RBF). The results of the challenge were based on the system-level
Spearman's Rank Correllation Coefficient (SRCC) metric. An initial MambaRate
version (T16 system) outperformed the pre-trained baseline (B03) by ~14% in a
few-shot setting without pre-training. T16 ranked fourth out of five in the
challenge, differing by ~6% from the winning system. We present additional
results on the BVCC dataset as well as ablations with different representations
as input, which outperform the initial T16 version.

</details>


### [26] [Room Impulse Response Generation Conditioned on Acoustic Parameters](https://arxiv.org/abs/2507.12136)
*Silvia Arellano,Chunghsin Yeh,Gautam Bhattacharya,Daniel Arteaga*

Main category: cs.SD

TL;DR: 该研究提出了一种基于声学参数而非几何信息的房间脉冲响应（RIR）生成方法，通过感知驱动实现更灵活的RIR生成，并评估了四种生成模型，其中MaskGIT表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖房间的几何信息，限制了在未知布局或更注重感知真实性的场景中的适用性。

Method: 直接基于RIR声学参数（如混响时间和直达声与混响比）生成RIR，探索了自回归和非自回归模型在Descript音频编解码域中的应用。

Result: 提出的模型在客观和主观评估中表现优异，MaskGIT模型性能最佳。

Conclusion: 基于声学参数的方法在RIR生成中更具灵活性和感知驱动性，MaskGIT模型为最佳选择。

Abstract: The generation of room impulse responses (RIRs) using deep neural networks
has attracted growing research interest due to its applications in virtual and
augmented reality, audio postproduction, and related fields. Most existing
approaches condition generative models on physical descriptions of a room, such
as its size, shape, and surface materials. However, this reliance on geometric
information limits their usability in scenarios where the room layout is
unknown or when perceptual realism (how a space sounds to a listener) is more
important than strict physical accuracy. In this study, we propose an
alternative strategy: conditioning RIR generation directly on a set of RIR
acoustic parameters. These parameters include various measures of reverberation
time and direct sound to reverberation ratio, both broadband and bandwise. By
specifying how the space should sound instead of how it should look, our method
enables more flexible and perceptually driven RIR generation. We explore both
autoregressive and non-autoregressive generative models operating in the
Descript Audio Codec domain, using either discrete token sequences or
continuous embeddings. Specifically, we have selected four models to evaluate:
an autoregressive transformer, the MaskGIT model, a flow matching model, and a
classifier-based approach. Objective and subjective evaluations are performed
to compare these methods with state-of-the-art alternatives. Results show that
the proposed models match or outperform state-of-the-art alternatives, with the
MaskGIT model achieving the best performance.

</details>


### [27] [RUMAA: Repeat-Aware Unified Music Audio Analysis for Score-Performance Alignment, Transcription, and Mistake Detection](https://arxiv.org/abs/2507.12175)
*Sungkyun Chang,Simon Dixon,Emmanouil Benetos*

Main category: cs.SD

TL;DR: RUMAA是一种基于Transformer的音乐表演分析框架，统一了乐谱到表演的对齐、乐谱感知转录和错误检测，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法需要单独处理乐谱对齐、转录和错误检测的问题，通过统一框架提高效率和准确性。

Method: 使用预训练的乐谱和音频编码器，结合新颖的三流解码器，通过代理任务捕捉任务间的依赖关系。

Result: 在公开钢琴音乐数据集上，RUMAA在非重复乐谱上达到最优对齐性能，在重复乐谱上表现更优，同时提供良好的转录和错误检测结果。

Conclusion: RUMAA通过统一框架实现了高效的音乐表演分析，尤其在处理重复乐谱时具有显著优势。

Abstract: This study introduces RUMAA, a transformer-based framework for music
performance analysis that unifies score-to-performance alignment,
score-informed transcription, and mistake detection in a near end-to-end
manner. Unlike prior methods addressing these tasks separately, RUMAA
integrates them using pre-trained score and audio encoders and a novel
tri-stream decoder capturing task interdependencies through proxy tasks. It
aligns human-readable MusicXML scores with repeat symbols to full-length
performance audio, overcoming traditional MIDI-based methods that rely on
manually unfolded score-MIDI data with pre-specified repeat structures. RUMAA
matches state-of-the-art alignment methods on non-repeated scores and
outperforms them on scores with repeats in a public piano music dataset, while
also delivering promising transcription and mistake detection results.

</details>


### [28] [Quantize More, Lose Less: Autoregressive Generation from Residually Quantized Speech Representations](https://arxiv.org/abs/2507.12197)
*Yichen Han,Xiaoyang Hao,Keming Chen,Weibo Xiong,Jun He,Ruonan Zhang,Junjie Cao,Yue Liu,Bowen Li,Dongrui Zhang,Hui Xia,Huilei Fu,Kai Jia,Kaixuan Guo,Mingli Jin,Qingyun Meng,Ruidong Ma,Ruiqian Fang,Shaotong Guo,Xuhui Li,Yang Xiang,Ying Zhang,Yulong Liu,Yunfeng Li,Yuyi Zhang,Yuze Zhou,Zhen Wang,Zhaowen Chen*

Main category: cs.SD

TL;DR: QTTS是一种基于新型音频编解码器QDAC的TTS框架，通过多码本建模和并行预测策略，显著提升了语音合成的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有自回归TTS方法因单码本表示导致信息丢失，难以恢复细节（如韵律、音色），尤其在复杂场景（如歌唱或音乐合成）中表现不佳。

Method: QTTS采用QDAC编解码器，结合分层并行架构和延迟多头方法，实现高质量合成和快速推理。

Result: 实验表明，QTTS在合成质量和表达内容保留上优于基线方法。

Conclusion: 多码本建模是提升语音和音频生成保真度的有效方向。

Abstract: Text-to-speech (TTS) synthesis has seen renewed progress under the discrete
modeling paradigm. Existing autoregressive approaches often rely on
single-codebook representations, which suffer from significant information
loss. Even with post-hoc refinement techniques such as flow matching, these
methods fail to recover fine-grained details (e.g., prosodic nuances,
speaker-specific timbres), especially in challenging scenarios like singing
voice or music synthesis. We propose QTTS, a novel TTS framework built upon our
new audio codec, QDAC. The core innovation of QDAC lies in its end-to-end
training of an ASR-based auto-regressive network with a GAN, which achieves
superior semantic feature disentanglement for scalable, near-lossless
compression. QTTS models these discrete codes using two innovative strategies:
the Hierarchical Parallel architecture, which uses a dual-AR structure to model
inter-codebook dependencies for higher-quality synthesis, and the Delay
Multihead approach, which employs parallelized prediction with a fixed delay to
accelerate inference speed. Our experiments demonstrate that the proposed
framework achieves higher synthesis quality and better preserves expressive
content compared to baseline. This suggests that scaling up compression via
multi-codebook modeling is a promising direction for high-fidelity,
general-purpose speech and audio generation.

</details>

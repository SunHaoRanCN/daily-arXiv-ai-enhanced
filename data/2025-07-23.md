<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 8]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.SD](#cs.SD) [Total: 9]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [MSGM: A Multi-Scale Spatiotemporal Graph Mamba for EEG Emotion Recognition](https://arxiv.org/abs/2507.15914)
*Hanwen Liu,Yifeng Gong,Zuwei Yan,Zeheng Zhuang,Jiaxuan Lu*

Main category: eess.SP

TL;DR: 提出了多尺度时空图Mamba(MSGM)框架，通过多窗口时间分割、双模态空间图建模和Mamba架构的高效融合，在保持线性复杂度的同时实现了优秀的EEG情感识别性能，仅用一个MSST-Mamba层就在多个数据集上超越了现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于EEG的情感识别方法在捕获多尺度时空动态和确保实时应用的计算效率方面存在困难，往往过度简化时间粒度和空间层次结构，从而限制了准确性。

Method: 提出多尺度时空图Mamba(MSGM)框架，集成了多窗口时间分割、基于神经解剖学先验的双模态空间图建模(全局-局部图)、多深度图卷积网络(GCN)和token嵌入融合模块，以及Mamba的状态空间建模来实现线性复杂度的动态时空交互。

Result: 在SEED、THU-EP和FACED数据集上，MSGM仅使用一个MSST-Mamba层就超越了领域内的主要方法，在主体独立情感分类任务中表现优于基线方法，同时在NVIDIA Jetson Xavier NX上实现了鲁棒的准确性和毫秒级推理速度。

Conclusion: MSGM通过有效捕获细粒度情感波动和层次化大脑连接性，在保持计算效率的同时显著提升了EEG情感识别的性能，为实时应用提供了可行的解决方案。

Abstract: EEG-based emotion recognition struggles with capturing multi-scale
spatiotemporal dynamics and ensuring computational efficiency for real-time
applications. Existing methods often oversimplify temporal granularity and
spatial hierarchies, limiting accuracy. To overcome these challenges, we
propose the Multi-Scale Spatiotemporal Graph Mamba (MSGM), a novel framework
integrating multi-window temporal segmentation, bimodal spatial graph modeling,
and efficient fusion via the Mamba architecture. By segmenting EEG signals
across diverse temporal scales and constructing global-local graphs with
neuroanatomical priors, MSGM effectively captures fine-grained emotional
fluctuations and hierarchical brain connectivity. A multi-depth Graph
Convolutional Network (GCN) and token embedding fusion module, paired with
Mamba's state-space modeling, enable dynamic spatiotemporal interaction at
linear complexity. Notably, with just one MSST-Mamba layer, MSGM surpasses
leading methods in the field on the SEED, THU-EP, and FACED datasets,
outperforming baselines in subject-independent emotion classification while
achieving robust accuracy and millisecond-level inference on the NVIDIA Jetson
Xavier NX.

</details>


### [2] [Modeling and Analysis of Land-to-Ship Maritime Wireless Channels at 5.8 GHz](https://arxiv.org/abs/2507.15969)
*Shu Sun,Yulu Guo,Meixia Tao,Wei Feng,Jun Chen,Ruifeng Gao,Ye Li,Jue Wang,Theodore S. Rappaport*

Main category: eess.SP

TL;DR: 本文基于大规模测量活动研究了5.8 GHz频段陆地到船舶的海上无线信道特性，提出了新的大尺度路径损耗模型和海浪诱导固定点衰落概念，并通过多种模型分析了小尺度衰落特性，为海上无线系统设计提供了重要参考。


<details>
  <summary>Details</summary>
Motivation: 海上通信环境中波浪和风等因素会影响信号传播，需要建立准确的海上信道模型来设计稳健的海上通信系统。现有模型难以准确描述动态海洋环境下的信道特性，特别是海面起伏对接收功率的影响。

Method: 通过大规模5.8 GHz频段陆地到船舶测量活动，同时收集水文和气象信息；提出基于物理基础的大尺度路径损耗模型；引入海浪诱导固定点（SWIFT）衰落概念并建立包含船舶旋转运动的增强双射线模型；使用TWDP和非对称拉普拉斯分布等多种模型分析小尺度衰落；通过基尼指数和莱斯K因子研究信道稀疏性。

Result: 成功建立了高精度的动态海洋环境大尺度路径损耗模型；SWIFT衰落模型与测量数据高度吻合，特别适用于天线运动幅度较小的情况；非对称拉普拉斯分布在大多数情况下表现良好，而TWDP模型更好地捕捉了恶劣海况下的双峰衰落；获得了海上信道稀疏性和时间色散特性的量化参数。

Conclusion: 研究建立的信道模型和参数特性为海上无线系统的设计和部署提供了有价值的见解，特别是在理解海面动态对信号传播影响方面取得了重要进展，为未来海上通信系统优化奠定了理论基础。

Abstract: Maritime channel modeling is crucial for designing robust communication
systems in marine environments, where factors like waves and wind impact signal
propagation. This article investigates land-to-ship maritime wireless channel
characteristics at 5.8 GHz based upon an extensive measurement campaign, with
concurrent hydrological and meteorological information collection. First, a
novel large-scale path loss model with physical foundation and high accuracy is
proposed for dynamic marine environments. Then, we introduce the concept of
sea-wave-induced fixed-point (SWIFT) fading, a peculiar phenomenon in maritime
scenarios that captures the impact of sea surface fluctuations on received
power. An enhanced two-ray model incorporating vessel rotational motion is
propounded to simulate the SWIFT fading, showing good alignment with measured
data, particularly for modest antenna movements. Next, the small-scale fading
is studied by leveraging a variety of models including the two-wave with
diffuse power (TWDP) and asymmetric Laplace distributions, with the latter
performing well in most cases, while TWDP better captures bimodal fading in
rough seas. Furthermore, maritime channel sparsity is examined via the Gini
index and Rician $K$ factor, and temporal dispersion is characterized. The
resulting channel models and parameter characteristics offer valuable insights
for maritime wireless system design and deployment.

</details>


### [3] [Meta-Reinforcement Learning Optimization for Movable Antenna-aided Full-Duplex CF-DFRC Systems with Carrier Frequency Offset](https://arxiv.org/abs/2507.16132)
*Yue Xiu,Wanting Lyu,You Li,Ran Yang,Phee Lep Yeoh,Wei Zhang,Guangyi Liu,Ning Wei*

Main category: eess.SP

TL;DR: 该论文提出了一种基于可移动天线的无蜂窝双功能雷达通信系统，通过元强化学习优化天线位置和波束成形来缓解载波频率偏移对通信和感知性能的影响


<details>
  <summary>Details</summary>
Motivation: 在宽带场景下，载波频率偏移会严重降低无蜂窝双功能雷达通信系统的通信容量和感知精度，需要利用可移动天线的空间灵活性来动态缓解这种影响

Method: 提出基于元强化学习的两阶段交替优化策略：第一阶段采用带惩罚对偶分解的流形优化求解CFO鲁棒最坏情况子问题；第二阶段采用数据驱动方式联合优化可移动天线位置和波束成形向量

Result: 仿真结果表明，所提出的元强化学习方法在CFO影响下的通信和感知性能显著优于传统深度强化学习方案，与固定位置天线相比，可移动天线辅助的系统表现出更好的性能

Conclusion: 通过将可移动天线集成到无蜂窝双功能雷达通信框架中，并采用元强化学习优化策略，能够有效缓解载波频率偏移的影响，显著提升系统的通信和感知性能

Abstract: By enabling spectrum sharing between radar and communication operations, the
cell-free dual-functional radar-communication (CF-DFRC) system is a promising
candidate to significantly improve spectrum efficiency in future
sixth-generation (6G) wireless networks. However, in wideband scenarios,
synchronization errors caused by carrier frequency offset (CFO) can severely
reduce both communication capacity and sensing accuracy. To address this
challenge, this paper integrates movable antennas (MAs) into the CF-DFRC
framework, leveraging their spatial flexibility and adaptive beamforming to
dynamically mitigate CFO-induced impairments. To fully exploit the advantages
of MAs in wideband scenarios with CFO, we aim to maximize the worst-case
sum-rate of communication and sensing by jointly optimizing MA positions,
{beamforming}, and CFO parameters, subject to transmit power and MA positioning
constraints. Due to the non-convex nature of the problem, we propose a robust
meta reinforcement learning (MRL)-based two-stage alternating optimization
strategy. In the first stage, we employ manifold optimization (MO) with penalty
dual decomposition (PDD) to solve the CFO-robust worst-case subproblem. In the
second stage, we adopt to jointly optimize {the MA positions and beamforming
vectors} in a data-driven manner {for dynamic wireless environments}.
Simulation results show that the proposed MRL approach significantly
outperforms conventional deep reinforcement learning (DRL) schemes in both
communication and sensing performance under CFO impairments. Furthermore,
compared to fixed-position antennas (FPAs), the MA-aided CF-DFRC system
exhibits

</details>


### [4] [Joint Active and Passive Beamforming for Energy-Efficient STARS with Quantization and Element Selection in ISAC Systems](https://arxiv.org/abs/2507.16210)
*Li-Hsiang Shen,Yi-Hsuan Chiu*

Main category: eess.SP

TL;DR: 本文研究了同时发射反射可重构智能表面(STARS)辅助的集成感知通信(ISAC)系统，提出AQUES方案优化能效，实现全空间能效数据传输和目标感知


<details>
  <summary>Details</summary>
Motivation: 传统ISAC系统在全空间覆盖和能效优化方面存在局限性，需要利用STARS技术实现同时发射和反射功能，以提高系统的能源效率和感知通信性能

Method: 提出基于交替优化的联合主被动波束成形、量化和元素选择(AQUES)方案：使用拉格朗日对偶和Dinkelbach变换处理分数问题；采用连续凸近似(SCA)进行凸化；通过惩罚对偶分解(PDD)框架和惩罚凸凹规划(PCCP)求解幅度和相移；启发式搜索确定量化级别；整数松弛处理元素选择

Result: 仿真结果表明STARS-ISAC系统配合AQUES方案显著提升了能效，同时满足通信速率和感知质量要求。耦合STARS由于硬件复杂度降低，相比独立和松弛STARS表现出更优的能效性能。AQUES在各种网络参数和部署场景下均优于现有配置和基准方法

Conclusion: STARS技术结合优化的AQUES方案能够有效提升ISAC系统的能源效率，实现全空间覆盖的高效感知通信，为未来6G网络的绿色通信和智能感知提供了重要的技术解决方案

Abstract: This paper investigates a simultaneously transmitting and reflecting
reconfigurable intelligent surface (STARS)-aided integrated sensing and
communication (ISAC) systems in support of full-space energy-efficient data
transmissions and target sensing. We formulate an energy efficiency (EE)
maximization problem jointly optimizing dual-functional radar-communication
(DFRC)-empowered base station (BS) ISAC beamforming and STARS configurations of
amplitudes, phase-shifts, quantization levels as well as element selection.
Furthermore, relaxed/independent/coupled STARS are considered to examine
architectural flexibility. To tackle the non-convex and mixed-integer problem,
we propose a joint active-passive beamforming, quantization and element
selection (AQUES) scheme based on alternating optimization: Lagrangian dual and
Dinkelbach's transformation deals with fractions, whereas successive convex
approximation (SCA) convexifies the problem; Penalty dual decomposition (PDD)
framework and penalty-based convex-concave programming (PCCP) procedure solves
amplitude and phase-shifts; Heuristic search decides the quantization level;
Integer relaxation deals with the element selection. Simulation results
demonstrate that STARS-ISAC with the proposed AQUES scheme significantly
enhances EE while meeting communication rates and sensing quality requirements.
The coupled STARS further highlights its superior EE performance over
independent and relaxed STARS thanks to its reduced hardware complexity.
Moreover, AQUES outperforms existing configurations and benchmark methods in
the open literature across various network parameters and deployment scenarios.

</details>


### [5] [Liquid Intelligent Metasurface for Fluid Antennas-Assisted Networks](https://arxiv.org/abs/2507.16211)
*Li-Hsiang Shen*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的液体智能超表面辅助下行多用户MISO系统，通过流体天线和液体元件实现电磁和空间的联合重构，显著提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 传统可重构超表面辅助系统采用静态几何结构，限制了系统性能。为了突破这一限制，需要开发能够同时实现电磁重构和空间重构的新架构，以进一步提升多用户通信系统的和速率性能。

Method: 提出液体智能超表面(LIM)辅助的下行多用户MISO系统，基站和超表面分别配备流体天线和液体元件。建立和速率最大化问题，联合优化基站波束成形、LIM相移以及流体天线和液体元件的位置。采用交替优化方法，引入辅助变量，使用逐次凸近似(SCA)和惩罚凸-凹过程(PCCP)求解各子问题。

Result: 仿真结果表明，所提出的FAS-LIM架构在各种参数设置下，相比采用传统固定超表面和固定天线阵列的基准方法，在系统和速率性能方面有显著提升。

Conclusion: 液体智能超表面架构通过实现电磁和空间的联合重构能力，为多用户MISO系统提供了一种有效的性能增强方案，验证了流体天线和液体元件在无线通信系统中的应用潜力。

Abstract: This paper proposes a novel liquid intelligent metasurface (LIM)-assisted
downlink multi-user multiple-input single-output (MISO) system, wherein both
the base station (BS) and the metasurface are respectively equipped with fluid
antennas (FA) and liquid elements. Unlike conventional reconfigurable
metasurface-assisted systems with static geometries, the proposed architecture
enables joint electromagnetic and spatial reconfigurability by allowing both
the FA-empowered BS (FAS) and LIM to dynamically adjust their small-scale
positions in addition to beamforming and phase-shift controls. We formulate a
sum-rate maximization problem that jointly optimizes the BS beamforming, LIM
phase-shifts, and the positions of fluid antennas and liquid elements. The
problem is highly non-convex due to coupling between variables, fractional
expressions, unit-modulus constraints as well as spatial correlation functions.
To address these challenges, we adopt alternating optimization and introduce
auxiliary variables and employ successive convex approximation (SCA) as well as
the penalty convex-concave procedure (PCCP) to solve the respective
subproblems. Simulation results have demonstrated that the proposed FAS-LIM
architecture significantly outperforms benchmark methods employing conventional
fixed metasurface and fixed antenna arrays in terms of various parameter
settings.

</details>


### [6] [Latency Minimization Oriented Radio and Computation Resource Allocations for 6G V2X Networks with ISCC](https://arxiv.org/abs/2507.16375)
*Peng Liu,Xinyi Wang,Zesong Fei,Yuan Wu,Jie Xu,Arumugam Nallanathan*

Main category: eess.SP

TL;DR: 本文研究了6G网络中ISCC赋能的V2X系统，通过交替优化算法联合优化无线电资源和计算资源分配，以公平地最小化车辆感知完成延迟。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络的发展，需要将移动边缘计算(MEC)和集成感知通信(ISAC)相结合，实现集成感知、通信和计算(ISCC)，特别是在车联网(V2X)应用中，车辆需要同时进行环境感知和数据卸载处理。

Method: 提出了一种交替优化算法来解决复杂的混合整数非线性规划问题：1)通过分支定界法确定子带分配；2)通过连续凸近似优化发射功率控制；3)基于广义瑞利熵和公平性准则分别以闭式形式推导接收波束成形和计算资源分配。

Result: 仿真结果表明，所提出的联合资源分配设计显著降低了所有车辆中的最大任务完成延迟，并展示了系统性能与资源利用率之间的几个有趣权衡。

Conclusion: 该研究成功实现了ISCC赋能V2X系统中无线电资源和计算资源的联合优化，在保证检测概率约束的同时公平地最小化了车辆感知完成延迟，为6G网络中的车联网应用提供了有效的资源分配方案。

Abstract: Incorporating mobile edge computing (MEC) and integrated sensing and
communication (ISAC) has emerged as a promising technology to enable integrated
sensing, communication, and computing (ISCC) in the sixth generation (6G)
networks. ISCC is particularly attractive for vehicle-to-everything (V2X)
applications, where vehicles perform ISAC to sense the environment and
simultaneously offload the sensing data to roadside base stations (BSs) for
remote processing. In this paper, we investigate a particular ISCC-enabled V2X
system consisting of multiple multi-antenna BSs serving a set of single-antenna
vehicles, in which the vehicles perform their respective ISAC operations (for
simultaneous sensing and offloading to the associated BS) over orthogonal
sub-bands. With the focus on fairly minimizing the sensing completion latency
for vehicles while ensuring the detection probability constraints, we jointly
optimize the allocations of radio resources (i.e., the sub-band allocation,
transmit power control at vehicles, and receive beamforming at BSs) as well as
computation resources at BS MEC servers. To solve the formulated complex
mixed-integer nonlinear programming (MINLP) problem, we propose an alternating
optimization algorithm. In this algorithm, we determine the sub-band allocation
via the branch-and-bound method, optimize the transmit power control via
successive convex approximation (SCA), and derive the receive beamforming and
computation resource allocation at BSs in closed form based on generalized
Rayleigh entropy and fairness criteria, respectively. Simulation results
demonstrate that the proposed joint resource allocation design significantly
reduces the maximum task completion latency among all vehicles. Furthermore, we
also demonstrate several interesting trade-offs between the system performance
and resource utilizations.

</details>


### [7] [Hybrid RISs for Simultaneous Tunable Reflections and Sensing](https://arxiv.org/abs/2507.16550)
*George C. Alexandropoulos,Nir Shlezinger,Ioannis Gavras,Haiyang Zhang*

Main category: eess.SP

TL;DR: 该论文介绍了混合反射感知智能表面(HRISs)的概念，这是一种既能可控反射信号又能同时感知部分信号的新型智能表面技术，解决了传统RIS在信道估计等方面的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统的可重构智能表面(RIS)仅具备反射功能，在无线网络协调方面面临重大挑战，特别是在信道估计等相干通信必需功能方面存在困难，需要一种具备感知能力的新型智能表面解决方案。

Method: 提出了混合反射感知智能表面(HRISs)概念，使超表面能够以可控方式反射入射信号的同时感知其中一部分信号。论文详细介绍了HRISs的实现细节，建立了描述其双重功能的数学模型，并讨论了两个应用案例：同时通信感知和多用户上行链路信道估计。

Result: HRISs的感知能力有效支持了各种网络管理功能，包括信道参数估计和定位，最重要的是实现了计算自主和自配置的RIS。性能评估结果验证了HRISs在感知以及集成感知通信方面的作用。

Conclusion: 混合反射感知智能表面(HRISs)通过同时具备反射和感知双重功能，克服了传统RIS的局限性，为智能无线环境中的动态可编程信号传播提供了更完善的解决方案，在通信感知一体化应用中展现出显著优势。

Abstract: The concept of smart wireless environments envisions dynamic programmable
propagation of information-bearing signals through the deployment of
Reconfigurable Intelligent Surfaces (RISs). Typical RIS implementations include
metasurfaces with passive unit elements capable to reflect their incident waves
in controllable ways. However, this solely reflective operation induces
significant challenges in the RIS orchestration from the wireless network. For
example, channel estimation, which is essential for coherent RIS-empowered
wireless communications, is quite challenging with the available solely
reflecting RIS designs. This chapter reviews the emerging concept of Hybrid
Reflecting and Sensing RISs (HRISs), which enables metasurfaces to reflect the
impinging signal in a controllable manner, while simultaneously sensing a
portion of it. The sensing capability of HRISs facilitates various network
management functionalities, including channel parameter estimation and
localization, while, most importantly, giving rise to computationally
autonomous and self-configuring RISs. The implementation details of HRISs are
first presented, which are then followed by a convenient mathematical model for
characterizing their dual functionality. Then, two indicative applications of
HRISs are discussed, one for simultaneous communications and sensing and
another that showcases their usefulness for estimating the individual channels
in the uplink of a multi-user HRIS-empowered communication system. For both of
these applications, performance evaluation results are included validating the
role of HRISs for sensing as well as integrated sensing and communications.

</details>


### [8] [Generative Diffusion Models for Wireless Networks: Fundamental, Architecture, and State-of-the-Art](https://arxiv.org/abs/2507.16733)
*Dayu Fan,Rui Meng,Xiaodong Xu,Yiming Liu,Guoshun Nan,Chenyuan Feng,Shujun Han,Song Gao,Bingxuan Xu,Dusit Niyato,Tony Q. S. Quek,Ping Zhang*

Main category: eess.SP

TL;DR: 这篇论文全面综述了生成扩散模型(GDMs)在无线网络中的应用，分析了其技术优势，提出了多层无线网络架构，并系统回顾了现有的基于GDM的方案，最后提出了关键挑战和潜在解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能技术的快速发展，生成扩散模型在无线网络领域展现出巨大的赋能潜力，具有抗噪声、训练稳定性、可控性和多模态生成等优势。尽管已有多项研究关注无线网络中的GDMs，但仍缺乏对其技术演进的全面综述。

Method: 从数学原理出发分析GDMs的技术优势，展示六个代表性模型；提出包含感知层、传输层、应用层和安全平面的多层无线网络架构；介绍GDM在各层的核心机制；对现有基于GDM的方案进行严格回顾，重点分析其创新点、GDMs的作用、优势和劣势。

Result: 系统性地探索了GDMs在无线网络中的应用，建立了完整的技术架构框架，全面分析了现有方案的特点和性能，识别了该领域的关键技术挑战。

Conclusion: 提取了关键挑战并提供了潜在解决方案，旨在为该领域未来研究提供方向性指导，推动生成扩散模型在无线网络中的进一步发展和应用。

Abstract: With the rapid development of Generative Artificial Intelligence (GAI)
technology, Generative Diffusion Models (GDMs) have shown significant
empowerment potential in the field of wireless networks due to advantages, such
as noise resistance, training stability, controllability, and multimodal
generation. Although there have been multiple studies focusing on GDMs for
wireless networks, there is still a lack of comprehensive reviews on their
technological evolution. Motivated by this, we systematically explore the
application of GDMs in wireless networks. Firstly, starting from mathematical
principles, we analyze technical advantages of GDMs and present six
representative models. Furthermore, we propose the multi-layer wireless network
architecture including sensing layer, transmission layer, application layer,
and security plane. We also introduce the core mechanisms of GDM at each of the
layers. Subsequently, we conduct a rigorous review on existing GDM-based
schemes, with a focus on analyzing their innovative points, the role of GDMs,
strengths, and weaknesses. Ultimately, we extract key challenges and provide
potential solutions, with the aim of providing directional guidance for future
research in this field.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [9] [Distributed Asynchronous Device Speech Enhancement via Windowed Cross-Attention](https://arxiv.org/abs/2507.16104)
*Gene-Ping Yang,Sebastian Braun*

Main category: eess.AS

TL;DR: 本文提出了一种窗口化交叉注意力模块，用于处理时间不同步的多麦克风音频处理问题，解决了现有TAC模块在真实会议场景中因设备间时延和时钟漂移导致的性能不足问题


<details>
  <summary>Details</summary>
Motivation: 现有的多麦克风处理方法主要针对时间同步的麦克风设置设计，但在真实会议场景中，不同设备间存在时延和时钟漂移问题，导致流行的TAC模块无法有效处理时间异步的麦克风阵列

Method: 提出了一个窗口化交叉注意力模块，能够动态对齐所有麦克风间的特征。该模块对麦克风的排列和数量都具有不变性，可以轻松集成到现有模型中。同时为多说话人环境提出了最优训练目标

Result: 在具有未知时延和时钟漂移的多麦克风噪声混响环境中进行评估，实验结果表明该方法在iFaSNet和CRUSE模型上都优于TAC模块，收敛更快，学习效果更好

Conclusion: 窗口化交叉注意力模块有效解决了异步麦克风设置中的音频处理问题，为动态会议环境中的多设备音频处理提供了实用的解决方案

Abstract: The increasing number of microphone-equipped personal devices offers great
flexibility and potential using them as ad-hoc microphone arrays in dynamic
meeting environments. However, most existing approaches are designed for
time-synchronized microphone setups, a condition that may not hold in
real-world meeting scenarios, where time latency and clock drift vary across
devices. Under such conditions, we found transform-average-concatenate (TAC), a
popular module for neural multi-microphone processing, insufficient in handling
time-asynchronous microphones. In response, we propose a windowed
cross-attention module capable of dynamically aligning features between all
microphones. This module is invariant to both the permutation and the number of
microphones and can be easily integrated into existing models. Furthermore, we
propose an optimal training target for multi-talker environments. We evaluated
our approach in a multi-microphone noisy reverberant setup with unknown time
latency and clock drift of each microphone. Experimental results show that our
method outperforms TAC on both iFaSNet and CRUSE models, offering faster
convergence and improved learning, demonstrating the efficacy of the windowed
cross-attention module for asynchronous microphone setups.

</details>


### [10] [An approach to measuring the performance of Automatic Speech Recognition (ASR) models in the context of Large Language Model (LLM) powered applications](https://arxiv.org/abs/2507.16456)
*Sujith Pulikodan,Sahapthan K,Prasanta Kumar Ghosh,Visruth Sanka,Nihar Desai*

Main category: eess.AS

TL;DR: 本文分析了大语言模型(LLM)纠正自动语音识别(ASR)错误的能力，并提出了一种新的ASR性能评估指标，专门用于评估在LLM驱动应用中的ASR表现。


<details>
  <summary>Details</summary>
Motivation: 传统的ASR性能评估主要使用词错误率(WER)，但随着大语言模型在各种应用中的广泛采用，不同类型的ASR错误对下游任务的影响程度不同，需要探索更适合LLM驱动应用的ASR评估方法。

Method: 分析大语言模型纠正ASR错误的能力，研究不同类型ASR错误(插入、删除、替换)对LLM性能的影响，并基于此提出新的ASR性能评估指标。

Result: 提出了一种新的ASR性能评估指标，该指标专门针对LLM驱动的应用场景，能够更好地反映ASR错误对下游任务的实际影响。

Conclusion: 在LLM广泛应用的背景下，传统的WER指标可能不足以全面评估ASR在实际应用中的表现，需要开发更适合LLM驱动应用的ASR评估方法来指导系统优化。

Abstract: Automatic Speech Recognition (ASR) plays a crucial role in human-machine
interaction and serves as an interface for a wide range of applications.
Traditionally, ASR performance has been evaluated using Word Error Rate (WER),
a metric that quantifies the number of insertions, deletions, and substitutions
in the generated transcriptions. However, with the increasing adoption of large
and powerful Large Language Models (LLMs) as the core processing component in
various applications, the significance of different types of ASR errors in
downstream tasks warrants further exploration. In this work, we analyze the
capabilities of LLMs to correct errors introduced by ASRs and propose a new
measure to evaluate ASR performance for LLM-powered applications.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [11] [Nonlinear Framework for Speech Bandwidth Extension](https://arxiv.org/abs/2507.15970)
*Tarikul Islam Tamiti,Nursad Mamun,Anomadarshi Barua*

Main category: cs.SD

TL;DR: 本文提出了NDSI-BWE，一个新的对抗性带宽扩展框架，通过七个受非线性动力学系统启发的判别器来恢复丢失的高频成分，在带宽扩展任务上达到了新的最优性能。


<details>
  <summary>Details</summary>
Motivation: 在电信和高保真音频等受限资源应用中，恢复因带宽限制而丢失的高频成分至关重要。现有的带宽扩展方法在捕获复杂的时间动态行为方面存在不足。

Method: 提出NDSI-BWE框架，包含七个基于非线性动力学系统的判别器：多分辨率李雅普诺夫判别器(MRLD)、多尺度递归判别器(MS-RD)、多尺度去趋势分形分析判别器(MSDFA)、多分辨率庞加莱图判别器(MR-PPD)、多周期判别器(MPD)、多分辨率幅度判别器(MRAD)和多分辨率相位判别器(MRPD)。生成器采用基于ConformerNeXt的复值架构和双流Lattice-Net设计，同时细化幅度和相位。通过深度卷积实现八倍参数减少。

Result: 在六个客观评估指标和五名人类评判员的主观测试中，NDSI-BWE在带宽扩展任务上建立了新的最优性能标准，显著超越了现有方法。

Conclusion: NDSI-BWE通过结合多个受非线性动力学启发的判别器和先进的生成器架构，成功解决了带宽扩展中的高频恢复问题，为该领域建立了新的性能基准，为电信和音频处理应用提供了有效解决方案。

Abstract: Recovering high-frequency components lost to bandwidth constraints is crucial
for applications ranging from telecommunications to high-fidelity audio on
limited resources. We introduce NDSI-BWE, a new adversarial Band Width
Extension (BWE) framework that leverage four new discriminators inspired by
nonlinear dynamical system to capture diverse temporal behaviors: a
Multi-Resolution Lyapunov Discriminator (MRLD) for determining sensitivity to
initial conditions by capturing deterministic chaos, a Multi-Scale Recurrence
Discriminator (MS-RD) for self-similar recurrence dynamics, a Multi-Scale
Detrended Fractal Analysis Discriminator (MSDFA) for long range slow variant
scale invariant relationship, a Multi-Resolution Poincar\'e Plot Discriminator
(MR-PPD) for capturing hidden latent space relationship, a Multi-Period
Discriminator (MPD) for cyclical patterns, a Multi-Resolution Amplitude
Discriminator (MRAD) and Multi-Resolution Phase Discriminator (MRPD) for
capturing intricate amplitude-phase transition statistics. By using depth-wise
convolution at the core of the convolutional block with in each discriminators,
NDSI-BWE attains an eight-times parameter reduction. These seven discriminators
guide a complex-valued ConformerNeXt based genetor with a dual stream
Lattice-Net based architecture for simultaneous refinement of magnitude and
phase. The genertor leverage the transformer based conformer's global
dependency modeling and ConvNeXt block's local temporal modeling capability.
Across six objective evaluation metrics and subjective based texts comprises of
five human judges, NDSI-BWE establishes a new SoTA in BWE.

</details>


### [12] [A new XML conversion process for mensural music encoding : CMME\_to\_MEI (via Verovio)](https://arxiv.org/abs/2507.15991)
*David Fiala,Laurent Pugin,Marnix van Berchum,Martha Thomae,Kévin Roger*

Main category: cs.SD

TL;DR: 法国图尔大学音乐学研究团队开放了一个包含约3500个XML文件的15世纪音乐语料库，并开发了将CMME格式转换为MEI格式的工具，为古代记谱法音乐的数字化编码和编辑提供了新的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的CMME（计算机化定量音乐编辑）格式虽然专门为定量音乐设计，但其编辑和发布工具自2000年代以来未曾更新，无法满足现代音乐编码标准的要求，需要开发转换工具以适应更先进的MEI（音乐编码倡议）标准。

Method: 在2024年9月巴黎康多塞校区举办的研讨会上，汇集了定量音乐记谱法、XML格式和编程方面的专家，直接在开源渲染库Verovio中开发了转换器，实现从CMME到MEI定量格式的转换，随后实现了到MEI CMN格式的转换，使这些文件能够在MuseScore等常见编谱软件中加载。

Result: 成功开发了CMME到MEI的转换工具，使现有的CMME文件语料库获得了新生命力，并且由于独立的CMME编辑器仍能正常工作且尚无MEI的本地替代方案，该转换器为编码和编辑定量音乐提供了新的工作流程。

Conclusion: 通过开发CMME到MEI的转换工具，不仅使15世纪音乐的大型数字语料库能够适应现代编码标准，还为定量音乐的数字化研究和编辑提供了可持续的技术解决方案，推动了音乐学数字人文研究的发展。

Abstract: The Ricercar Lab - the musicological research team at the Center for advanced
Studies in the Renaissance at the University of Tours - has decided to make
available in open access, thanks to the support of the French digital
infrastructure Biblissima, a large corpus of about 3500 XML files of 15th-c.
music. This corpus was produced by the German musicologist Clemens Goldberg who
encoded since 2010 onwards the musical content of 34 major 15th-c. music
manuscripts and other complementary files, in order to offer on his
foundation's website PDF files of complete collections of works by Du Fay,
Binchois, Okeghem, Busnoys and most of their major contemporaries, focusing on
their secular output. This corpus was encoded in an XML format named CMME
(Computerized Mensural Music Editing), specifically conceived for mensural
music by Theodor Dumitrescu in the 2000s, together with editorial and
publication tools which have not been updated since then. This article focuses
on the development of a set of conversion tools for these CMME files to meet
more up-to-date standards of music encoding, namely MEI. A workshop was
organised in September 2024 at the Campus Condorcet in Paris, gathering experts
with a wide range of knowledge on mensural music notation, XML formats and
programming. A converter was developped directly in the open-source rendering
library Verovio, allowing the conversion from CMME to MEI mensural. A
conversion to MEI CMN was implemented afterwards, enabling to load these files
in common engraving softwares such as MuseScore with minimal loss of
information. With the availability of a direct import of CMME-XML into Verovio,
the corpus of existing CMME files gets a new life. Furthermore, since the
stand-alone CMME editor still works fine and no alternative is available yet
for native MEI, the converter offers a new pipeline for encoding and editing
mensural music.

</details>


### [13] [SDBench: A Comprehensive Benchmark Suite for Speaker Diarization](https://arxiv.org/abs/2507.16136)
*Eduardo Pacheco,Atila Orhon,Berkin Durmus,Blaise Munyampirwa,Andrey Leonov*

Main category: cs.SD

TL;DR: 该论文提出了SDBench，一个开源的说话人分割基准测试套件，集成了13个多样化数据集，并开发了SpeakerKit系统，实现了比Pyannote v3快9.6倍的推理速度且保持相当的错误率


<details>
  <summary>Details</summary>
Motivation: 现有的说话人分割系统在不同数据集上表现差异很大，且系统间比较缺乏统一标准和最佳实践，需要一个标准化的基准测试平台来实现可重现的评估和公平比较

Method: 构建了SDBench开源基准测试套件，集成13个多样化数据集，提供一致性和细粒度的性能分析工具；基于Pyannote v3开发了专注于推理效率的SpeakerKit系统，并进行消融研究优化

Result: SpeakerKit系统比Pyannote v3快9.6倍，同时保持相当的错误率；对6个先进系统（包括Deepgram、AWS Transcribe、Pyannote AI API）进行基准测试，揭示了准确性和速度之间的重要权衡关系

Conclusion: SDBench为说话人分割系统提供了标准化的评估平台，支持可重现评估和新系统的便捷集成；通过该平台开发的SpeakerKit实现了显著的推理速度提升，证明了基准测试套件在系统优化中的有效性

Abstract: Even state-of-the-art speaker diarization systems exhibit high variance in
error rates across different datasets, representing numerous use cases and
domains. Furthermore, comparing across systems requires careful application of
best practices such as dataset splits and metric definitions to allow for
apples-to-apples comparison. We propose SDBench (Speaker Diarization
Benchmark), an open-source benchmark suite that integrates 13 diverse datasets
with built-in tooling for consistent and fine-grained analysis of speaker
diarization performance for various on-device and server-side systems. SDBench
enables reproducible evaluation and easy integration of new systems over time.
To demonstrate the efficacy of SDBench, we built SpeakerKit, an inference
efficiency-focused system built on top of Pyannote v3. SDBench enabled rapid
execution of ablation studies that led to SpeakerKit being 9.6x faster than
Pyannote v3 while achieving comparable error rates. We benchmark 6
state-of-the-art systems including Deepgram, AWS Transcribe, and Pyannote AI
API, revealing important trade-offs between accuracy and speed.

</details>


### [14] [LABNet: A Lightweight Attentive Beamforming Network for Ad-hoc Multichannel Microphone Invariant Real-Time Speech Enhancement](https://arxiv.org/abs/2507.16190)
*Haoyin Yan,Jie Zhang,Chengqian Jiang,Shuang Zhang*

Main category: cs.SD

TL;DR: 提出了一种轻量级注意力波束成形网络(LABNet)，用于在边缘设备上实现实时多通道语音增强，同时保持麦克风不变性，具有超低资源开销和优异性能。


<details>
  <summary>Details</summary>
Motivation: 在ad-hoc阵列条件下，多通道语音增强系统需要处理不同数量的麦克风和阵列几何结构(麦克风不变性)，同时多通道录音会增加边缘设备应用的计算负担，因此需要轻量级和高效的部署方案。

Method: 设计了一个三阶段框架的轻量级注意力波束成形网络(LABNet)，包括高效的通道内建模和通道间交互，并开发了跨通道注意力模块来选择性地聚合来自各通道的特征。

Result: LABNet在保持麦克风不变性的同时，以超轻量的资源开销实现了令人印象深刻的性能表现。

Conclusion: LABNet在ad-hoc阵列处理方面显示出巨大潜力，成功实现了轻量级实时语音增强系统，同时保持了对不同麦克风配置的适应性。

Abstract: Multichannel speech enhancement (SE) aims to restore clean speech from noisy
measurements by leveraging spatiotemporal signal features. In ad-hoc array
conditions, microphone invariance (MI) requires systems to handle different
microphone numbers and array geometries. From a practical perspective,
multichannel recordings inevitably increase the computational burden for
edge-device applications, highlighting the necessity of lightweight and
efficient deployments. In this work, we propose a lightweight attentive
beamforming network (LABNet) to integrate MI in a low-complexity real-time SE
system. We design a three-stage framework for efficient intra-channel modeling
and inter-channel interaction. A cross-channel attention module is developed to
aggregate features from each channel selectively. Experimental results
demonstrate our LABNet achieves impressive performance with ultra-light
resource overhead while maintaining the MI, indicating great potential for
ad-hoc array processing.

</details>


### [15] [LENS-DF: Deepfake Detection and Temporal Localization for Long-Form Noisy Speech](https://arxiv.org/abs/2507.16220)
*Xuechen Liu,Wanying Ge,Xin Wang,Junichi Yamagishi*

Main category: cs.SD

TL;DR: 本研究提出LENS-DF，一个用于训练和评估音频深度伪造检测和时间定位的综合方案，能够在复杂现实音频条件下生成具有更长时长、噪声环境和多说话人特征的数据，实验表明该方案训练的模型性能显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的音频深度伪造检测方法在面对复杂现实音频条件（如长时长、噪声环境、多说话人等）时性能不佳，需要一个更加全面和现实的训练评估方案来提升检测和定位的鲁棒性。

Method: 提出LENS-DF方案，包含生成部分和检测定位协议两个组件。生成部分能够可控地从输入数据集产生具有关键特征（更长时长、噪声条件、多说话人）的音频；检测定位协议使用基于自监督学习前端和简单后端的模型进行训练和评估。

Result: 实验结果显示，使用LENS-DF生成数据训练的模型在音频深度伪造检测和定位任务上的性能consistently优于使用传统方案训练的模型。消融实验进一步验证了各种变化因素对现实挑战的影响和相关性。

Conclusion: LENS-DF是一个有效且实用的综合方案，能够显著提升音频深度伪造检测和时间定位在复杂现实条件下的鲁棒性，为该领域提供了更好的训练和评估框架。

Abstract: This study introduces LENS-DF, a novel and comprehensive recipe for training
and evaluating audio deepfake detection and temporal localization under
complicated and realistic audio conditions. The generation part of the recipe
outputs audios from the input dataset with several critical characteristics,
such as longer duration, noisy conditions, and containing multiple speakers, in
a controllable fashion. The corresponding detection and localization protocol
uses models. We conduct experiments based on self-supervised learning front-end
and simple back-end. The results indicate that models trained using data
generated with LENS-DF consistently outperform those trained via conventional
recipes, demonstrating the effectiveness and usefulness of LENS-DF for robust
audio deepfake detection and localization. We also conduct ablation studies on
the variations introduced, investigating their impact on and relevance to
realistic challenges in the field.

</details>


### [16] [Robust Bioacoustic Detection via Richly Labelled Synthetic Soundscape Augmentation](https://arxiv.org/abs/2507.16235)
*Kaspar Soltero,Tadeu Siqueira,Stefanie Gutschmidt*

Main category: cs.SD

TL;DR: 本研究提出了一个合成数据框架，通过将清洁背景噪声与目标鸟类叫声结合，自动生成大量标注训练数据，显著提升了生物声学检测模型的鲁棒性，有效解决了被动声学监测中手工标注数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 被动声学监测(PAM)分析受到创建标注训练数据需要大量人工工作的阻碍，这是计算生物声学领域的一个关键瓶颈，限制了生态评估能力的发展。

Method: 开发了一个合成数据框架，将清洁的背景噪声与孤立的目标鸟类叫声(小鸮)结合，在合成过程中自动生成动态标签（如边界框），从非常有限的源材料生成大量丰富标注的训练数据。

Result: 在合成数据上微调的模型在真实世界声景中表现良好，即使源鸟叫声的多样性大幅减少，性能仍然保持较高水平，表明模型学习到了泛化特征而没有过拟合。

Conclusion: 合成数据生成是从小型源数据集训练鲁棒生物声学检测器的高效策略，显著减少了手工标注工作量，克服了计算生物声学的关键瓶颈，增强了生态评估能力。

Abstract: Passive Acoustic Monitoring (PAM) analysis is often hindered by the intensive
manual effort needed to create labelled training data. This study introduces a
synthetic data framework to generate large volumes of richly labelled training
data from very limited source material, improving the robustness of bioacoustic
detection models. Our framework synthesises realistic soundscapes by combining
clean background noise with isolated target vocalisations (little owl),
automatically generating dynamic labels like bounding boxes during synthesis. A
model fine-tuned on this data generalised well to real-world soundscapes, with
performance remaining high even when the diversity of source vocalisations was
drastically reduced, indicating the model learned generalised features without
overfitting. This demonstrates that synthetic data generation is a highly
effective strategy for training robust bioacoustic detectors from small source
datasets. The approach significantly reduces manual labelling effort,
overcoming a key bottleneck in computational bioacoustics and enhancing
ecological assessment capabilities.

</details>


### [17] [Detect Any Sound: Open-Vocabulary Sound Event Detection with Multi-Modal Queries](https://arxiv.org/abs/2507.16343)
*Pengfei Cai,Yan Song,Qing Gu,Nan Jiang,Haoyu Song,Ian McLoughlin*

Main category: cs.SD

TL;DR: 本文提出了DASM（Detect Any Sound Model），一个基于查询的开放词汇声音事件检测框架，通过多模态查询引导，将SED重新定义为帧级检索任务，并采用双流解码器分离事件识别和时间定位，在开放词汇设置下显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的声音事件检测算法大多基于封闭集假设，只能检测预定义类别的声音事件。虽然最近有研究探索了基于语言驱动的零样本SED，但由于缺乏细粒度对齐和跨模态特征融合，性能仍不令人满意。因此需要开发能够检测任意声音类别的开放词汇SED方法。

Method: 提出DASM框架，将SED重新定义为帧级检索任务，通过文本或音频提示生成查询向量与音频特征进行匹配。采用双流解码器架构：跨模态事件解码器进行查询-特征融合并在片段级确定声音事件存在性；上下文网络建模时间依赖关系进行帧级定位。此外，提出推理时注意力掩码策略，利用基础类和新类之间的语义关系增强对新类的泛化能力。

Result: 在AudioSet Strong数据集上，DASM在开放词汇设置下比基于CLAP的方法提升7.8 PSDS，在封闭集设置下比基线提升6.9 PSDS。在DESED数据集的跨数据集零样本评估中，DASM获得42.2的PSDS1分数，甚至超越了有监督的CRNN基线。

Conclusion: DASM通过查询驱动的框架和双流解码器架构，有效平衡了定位精度和对新类的泛化能力，在开放词汇声音事件检测任务上取得了显著的性能提升，为解决开放词汇SED问题提供了有效的解决方案。

Abstract: Most existing sound event detection~(SED) algorithms operate under a
closed-set assumption, restricting their detection capabilities to predefined
classes. While recent efforts have explored language-driven zero-shot SED by
exploiting audio-language models, their performance is still far from
satisfactory due to the lack of fine-grained alignment and cross-modal feature
fusion. In this work, we propose the Detect Any Sound Model (DASM), a
query-based framework for open-vocabulary SED guided by multi-modal queries.
DASM formulates SED as a frame-level retrieval task, where audio features are
matched against query vectors derived from text or audio prompts. To support
this formulation, DASM introduces a dual-stream decoder that explicitly
decouples event recognition and temporal localization: a cross-modality event
decoder performs query-feature fusion and determines the presence of sound
events at the clip-level, while a context network models temporal dependencies
for frame-level localization. Additionally, an inference-time attention masking
strategy is proposed to leverage semantic relations between base and novel
classes, substantially enhancing generalization to novel classes. Experiments
on the AudioSet Strong dataset demonstrate that DASM effectively balances
localization accuracy with generalization to novel classes, outperforming
CLAP-based methods in open-vocabulary setting (+ 7.8 PSDS) and the baseline in
the closed-set setting (+ 6.9 PSDS). Furthermore, in cross-dataset zero-shot
evaluation on DESED, DASM achieves a PSDS1 score of 42.2, even exceeding the
supervised CRNN baseline. The project page is available at
https://cai525.github.io/Transformer4SED/demo_page/DASM/.

</details>


### [18] [TTMBA: Towards Text To Multiple Sources Binaural Audio Generation](https://arxiv.org/abs/2507.16564)
*Yuxuan He,Xiaoran Yang,Ningning Pan,Gongping Huang*

Main category: cs.SD

TL;DR: 本文提出了一种级联方法来生成具有时间和空间控制的文本到多源双耳音频(TTMBA)，解决了现有文本到音频生成方法只产生单声道输出而忽视空间信息的问题。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到音频(TTA)生成方法大多产生单声道输出，忽略了沉浸式听觉体验所必需的空间信息，因此需要开发能够生成具有空间感知的双耳音频的方法。

Method: 采用级联方法：1)使用预训练的大语言模型(LLM)将文本分割成包含每个声音事件时间和空间细节的结构化格式；2)使用预训练的单声道音频生成网络为每个事件创建不同持续时间的多个单声道音频；3)基于LLM的空间数据，使用双耳渲染神经网络将单声道音频转换为双耳音频；4)按开始时间排列双耳音频，生成多源双耳音频。

Result: 实验结果表明，所提出的方法在音频生成质量和空间感知准确性方面都表现出优越性。

Conclusion: 通过级联的方法成功实现了文本到多源双耳音频的生成，同时具备时间和空间控制能力，在音频质量和空间感知方面都取得了显著改进。

Abstract: Most existing text-to-audio (TTA) generation methods produce mono outputs,
neglecting essential spatial information for immersive auditory experiences. To
address this issue, we propose a cascaded method for text-to-multisource
binaural audio generation (TTMBA) with both temporal and spatial control.
First, a pretrained large language model (LLM) segments the text into a
structured format with time and spatial details for each sound event. Next, a
pretrained mono audio generation network creates multiple mono audios with
varying durations for each event. These mono audios are transformed into
binaural audios using a binaural rendering neural network based on spatial data
from the LLM. Finally, the binaural audios are arranged by their start times,
resulting in multisource binaural audio. Experimental results demonstrate the
superiority of the proposed method in terms of both audio generation quality
and spatial perceptual accuracy.

</details>


### [19] [SALM: Spatial Audio Language Model with Structured Embeddings for Understanding and Editing](https://arxiv.org/abs/2507.16724)
*Jinbo Hu,Yin Cao,Ming Wu,Feiran Yang,Jun Yang*

Main category: cs.SD

TL;DR: 本文提出了空间音频语言模型(SALM)，通过多模态对比学习将空间音频与语言连接，实现了零样本方向分类和基于文本的空间音频编辑功能。


<details>
  <summary>Details</summary>
Motivation: 现有的音频-语言模型在处理空间音频和感知空间声学场景方面存在困难，缺乏对空间音频环境的准确理解和解释能力。

Method: 设计了空间音频语言模型(SALM)框架，包含文本编码器和双分支音频编码器，通过结构化音频嵌入将空间声音分解为语义和空间组件，采用多模态对比学习实现空间音频与语言的桥接。

Result: SALM能够有效捕获和对齐跨模态表示，支持零样本方向分类，并具备高级编辑能力，可以使用基于文本的嵌入来改变方向性音频。

Conclusion: SALM成功实现了空间音频与语言的无缝对齐，能够分别和联合提取空间和语义信息，为空间音频理解和编辑提供了有效的解决方案。

Abstract: Spatial audio understanding is essential for accurately perceiving and
interpreting acoustic environments. However, existing audio-language models
struggle with processing spatial audio and perceiving spatial acoustic scenes.
We introduce the Spatial Audio Language Model (SALM), a novel framework that
bridges spatial audio and language via multi-modal contrastive learning. SALM
consists of a text encoder and a dual-branch audio encoder, decomposing spatial
sound into semantic and spatial components through structured audio embeddings.
Key features of SALM include seamless alignment of spatial and text
representations, separate and joint extraction of spatial and semantic
information, zero-shot direction classification and robust support for spatial
audio editing. Experimental results demonstrate that SALM effectively captures
and aligns cross-modal representations. Furthermore, it supports advanced
editing capabilities, such as altering directional audio using text-based
embeddings.

</details>

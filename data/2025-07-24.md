<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 18]
- [eess.AS](#eess.AS) [Total: 10]
- [cs.SD](#cs.SD) [Total: 5]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [PPAAS: PVT and Pareto Aware Analog Sizing via Goal-conditioned Reinforcement Learning](https://arxiv.org/abs/2507.17003)
*Seunggeun Kim,Ziyi Wang,Sungyoung Lee,Youngmin Oh,Hanqing Zhu,Doyun Kim,David Z. Pan*

Main category: eess.SP

TL;DR: 本文提出了一个目标条件强化学习框架，用于模拟电路器件尺寸设计，在PVT变化条件下实现高效策略训练和强泛化能力，相比现有方法在样本效率上提升1.6倍，仿真效率提升4.1倍。


<details>
  <summary>Details</summary>
Motivation: 模拟混合信号电路的器件尺寸设计是一个关键但具有挑战性的步骤，需要在满足多样化性能规范的同时考虑工艺、电压、温度(PVT)变化的影响。现有强化学习方法虽然在固定目标的自动化尺寸设计中显示出潜力，但训练一个能够在PVT变化下适应广泛设计规范的通用策略需要大量训练样本和资源。

Method: 提出目标条件强化学习框架，包含三个关键技术：1）帕累托前沿主导目标采样(Pareto-front Dominance Goal Sampling)，通过从先前实现目标的帕累托前沿采样目标来构建自动课程；2）保守事后经验回放(Conservative Hindsight Experience Replay)，通过为重新标记的目标分配保守虚拟奖励来稳定训练并加速收敛；3）失败时跳过仿真策略(Skip-on-Fail)，当标称角仿真未能满足目标规范时跳过全角仿真以减少仿真开销。

Result: 在基准电路上的实验表明，相比现有尺寸设计方法，该框架在样本效率上实现约1.6倍的提升，在仿真效率上实现约4.1倍的提升。代码和基准测试已在GitHub上公开。

Conclusion: 该研究成功解决了模拟电路器件尺寸设计中的关键挑战，通过目标条件强化学习框架显著提高了训练效率和泛化能力，为在PVT变化条件下的模拟电路自动化设计提供了有效解决方案。

Abstract: Device sizing is a critical yet challenging step in analog and mixed-signal
circuit design, requiring careful optimization to meet diverse performance
specifications. This challenge is further amplified under process, voltage, and
temperature (PVT) variations, which cause circuit behavior to shift across
different corners. While reinforcement learning (RL) has shown promise in
automating sizing for fixed targets, training a generalized policy that can
adapt to a wide range of design specifications under PVT variations requires
much more training samples and resources. To address these challenges, we
propose a \textbf{Goal-conditioned RL framework} that enables efficient policy
training for analog device sizing across PVT corners, with strong
generalization capability. To improve sample efficiency, we introduce
Pareto-front Dominance Goal Sampling, which constructs an automatic curriculum
by sampling goals from the Pareto frontier of previously achieved goals. This
strategy is further enhanced by integrating Conservative Hindsight Experience
Replay, which assigns relabeled goals with conservative virtual rewards to
stabilize training and accelerate convergence. To reduce simulation overhead,
our framework incorporates a Skip-on-Fail simulation strategy, which skips
full-corner simulations when nominal-corner simulation fails to meet target
specifications. Experiments on benchmark circuits demonstrate $\sim$1.6$\times$
improvement in sample efficiency and $\sim$4.1$\times$ improvement in
simulation efficiency compared to existing sizing methods. Code and benchmarks
are publicly available at https://github.com/SeunggeunKimkr/PPAAS

</details>


### [2] [Efficient and Distortion-less Spectrum Multiplexer via Neural Network-based Filter Banks](https://arxiv.org/abs/2507.17106)
*Jiazhao Wang,Wenchao Jiang*

Main category: eess.SP

TL;DR: 本文提出了一种基于神经网络滤波器组的频谱复用器，用于同时传输多个窄带物联网信号，实现了低失真（-39dB）、高效率（35倍提升）和高包接收率（98%）的性能表现。


<details>
  <summary>Details</summary>
Motivation: 现有频谱复用方法存在效率低和失真大的问题，需要一种新的解决方案来提高频谱利用率，同时实现多个窄带物联网信号的同时传输并减少失真。

Method: 采用模型驱动方法，将神经网络集成到滤波器组设计中，将神经网络模型解释为滤波器组。利用神经网络的高级学习能力实现无失真复用，并通过硬件加速提高效率。

Result: 实现了-39dB的归一化均方误差低失真水平，相比传统方法获得35倍执行效率提升和10dB信噪比增益。在实际应用中，对同构和异构物联网网络的标准接收器包接收率达到98%。

Conclusion: 基于神经网络的滤波器组频谱复用器在物联网信号传输中表现出显著的性能优势，能够有效处理多种信号类型和环境条件，为物联网网络的频谱利用提供了高效的解决方案。

Abstract: Spectrum multiplexer enables simultaneous transmission of multiple
narrow-band IoT signals through gateway devices, thereby enhancing overall
spectrum utilization. We propose a novel solution based on filter banks that
offer increased efficiency and minimal distortion compared with conventional
methods. We follow a model-driven approach to integrate the neural networks
into the filter bank design by interpreting the neural network models as filter
banks. The proposed NN-based filter banks can leverage advanced learning
capabilities to achieve distortionless multiplexing and harness hardware
acceleration for high efficiency. Then, we evaluate the performance of the
spectrum multiplexer implemented by NN-based filter banks for various types of
signals and environmental conditions. The results show that it can achieve a
low distortion level down to $-39$dB normalized mean squared error.
Furthermore, it achieves up to $35$ times execution efficiency gain and $10$dB
SNR gain compared with the conventional methods. The field applications show
that it can handle both the heterogeneous and homogeneous IoT networks,
resulting in high packet reception ratio at the standard receivers up to
$98\%$.

</details>


### [3] [Stacked Intelligent Metasurface Assisted Multiuser Communications: From a Rate Fairness Perspective](https://arxiv.org/abs/2507.17153)
*Junjie Fang,Chao Zhang,Jiancheng An,Hongwen Yu,Qingqing Wu,Mérouane Debbah,Chau Yuen*

Main category: eess.SP

TL;DR: 本文研究了堆叠智能超表面(SIM)在多用户下行系统中提升速率公平性的应用，提出了两种优化算法分别解决最大化最小速率和最大化几何平均速率问题，实现了公平性与系统性能的平衡。


<details>
  <summary>Details</summary>
Motivation: 传统单层可重构全息表面在多用户下行系统中存在速率公平性问题，需要通过堆叠智能超表面的多层结构来增强电磁波传播控制能力和信号处理性能，以解决用户间速率分配不公平的挑战。

Method: 针对最大化最小速率问题采用基于一致性ADMM的方法，将近似问题分解为具有闭式解的子问题；针对最大化几何平均速率问题开发了基于交替优化的算法，同样可得到闭式解并可无缝适应系统总速率最大化。

Result: 数值结果验证了所提算法的有效性和收敛性。最大化最小速率算法确保了近乎完美的公平性，最大化几何平均速率算法在公平性和系统总速率间取得平衡。两种算法在各自优化目标上均优于现有相关工作。

Conclusion: 堆叠智能超表面能够有效提升多用户下行系统的速率公平性，所提出的两种优化算法分别在保证公平性和平衡性能方面表现优异，且SIM在较低功耗下可实现与多天线数字波束成形相当的性能。

Abstract: Stacked intelligent metasurface (SIM) extends the concept of single-layer
reconfigurable holographic surfaces (RHS) by incorporating a multi-layered
structure, thereby providing enhanced control over electromagnetic wave
propagation and improved signal processing capabilities. This study
investigates the potential of SIM in enhancing the rate fairness in multiuser
downlink systems by addressing two key optimization problems: maximizing the
minimum rate (MR) and maximizing the geometric mean of rates (GMR). {The former
strives to enhance the minimum user rate, thereby ensuring fairness among
users, while the latter relaxes fairness requirements to strike a better
trade-off between user fairness and system sum-rate (SR).} For the MR
maximization, we adopt a consensus alternating direction method of multipliers
(ADMM)-based approach, which decomposes the approximated problem into
sub-problems with closed-form solutions. {For GMR maximization, we develop an
alternating optimization (AO)-based algorithm that also yields closed-form
solutions and can be seamlessly adapted for SR maximization. Numerical results
validate the effectiveness and convergence of the proposed algorithms.}
Comparative evaluations show that MR maximization ensures near-perfect
fairness, while GMR maximization balances fairness and system SR. Furthermore,
the two proposed algorithms respectively outperform existing related works in
terms of MR and SR performance. Lastly, SIM with lower power consumption
achieves performance comparable to that of multi-antenna digital beamforming.

</details>


### [4] [Design of a Noval Wearable ECG Monitoring Device](https://arxiv.org/abs/2507.17154)
*Ruihua Wang,Mingtong Chen,Zhengbao Yang*

Main category: eess.SP

TL;DR: 本研究开发了一种新型无线供电可穿戴心电监测设备，采用银镀层织物制作的一体式电极和导线，解决了传统心电监测设备功耗高、佩戴不适等问题


<details>
  <summary>Details</summary>
Motivation: 现有可穿戴智能心电解决方案在高精度心电诊断和传输过程中功耗过高，传统Ag/AgCl凝胶电极容易引起皮肤刺激、炎症和过敏反应，不适合长期动态监测

Method: 采用银镀层织物一体化切割制作电极和导线，导线部分切割成接近S形的弯曲结构以确保良好的延展性；通过优化算法和降低噪声功率来改善信噪比；设计无线供电系统

Result: 开发出小型化、可长期佩戴的无线心电监测设备，新型电极设计在日常服装运动中保持舒适性和信号完整性，改善了用户体验和信噪比

Conclusion: 通过创新的银镀层织物一体式电极设计和无线供电技术，成功解决了传统可穿戴心电监测设备的高功耗和佩戴不适问题，为长期心电监测提供了新的解决方案

Abstract: The aim of this project is to develop a new wireless powered wearable ECG
monitoring device. The main goal of the project is to provide a wireless,
small-sized ECG monitoring device that can be worn for a long period of time by
the monitored person. Electrocardiogram ECG reflects physiological and
pathological information about heart activity and is commonly used to diagnose
heart disease. Existing wearable smart ECG solutions suffer from high power
consumption in both ECG diagnosis and transmission for high accuracy.
Monitoring of ECG devices is mainly done by data extraction and acquisition,
pre-processing, feature extraction, processing and analysis, visualisation and
auxiliary procedures. During the pre-processing of the information, different
kinds of noise generated during the signal collection need to be taken into
account. The quality of the signal-to-noise ratio can usually be improved by
optimising algorithms and reducing the noise power. The choice of electrodes
usually has a direct impact on the signal-to-noise ratio and the user
experience, and conventional Ag/AgCl gel electrodes are not suitable for
long-term and dynamic monitoring as they are prone to skin irritation,
inflammation and allergic reactions. Therefore, a completely new way of
combining electrodes and wires will be used in the report. The electrodes and
wires are cut in one piece from a silver-plated fabric. The wire portion is cut
into a curved structure close to an S shape to ensure that it has good
ductility for comfort and signal integrity during daily movement of the
garment.

</details>


### [5] [Hybrid Semantic-Complementary Transmission for High-Fidelity Image Reconstruction](https://arxiv.org/abs/2507.17196)
*Hyelin Nam,Jihong Park,Jinho Choi,Seong-Lyun Kim*

Main category: eess.SP

TL;DR: 本文提出了混合语义通信(HSC)框架，通过在传统语义通信基础上增加互补表示(CR)来提高图像重建的保真度，解决了现有神经网络语义通信系统在细节重建方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的基于神经网络的语义通信系统在不同图像分布上训练，往往无法重建精细的图像特定细节，存在重建保真度有限的问题。

Method: 提出混合语义通信(HSC)框架，在语义表示(SR)基础上补充互补表示(CR)来捕获残余的图像特定信息。发射端构建CR，接收端将CR与语义通信结果结合以产生高保真度的重构图像。推导了重建误差的闭式表达式和相应的最优CR。

Result: 仿真结果显示，在各种信道和神经网络架构下，HSC相比不传输CR的基线语义通信系统大幅降低了均方误差(MSE)。

Conclusion: HSC框架通过灵活调节CR的传输负载来实现理想的保真度，有效解决了传统语义通信重建细节不足的问题，显著提升了图像重建质量。

Abstract: Recent advances in semantic communication (SC) have introduced neural network
(NN)-based transceivers that convey semantic representation (SR) of signals
such as images. However, these NNs are trained over diverse image distributions
and thus often fail to reconstruct fine-grained image-specific details. To
overcome this limited reconstruction fidelity, we propose an extended SC
framework, hybrid semantic communication (HSC), which supplements SR with
complementary representation (CR) capturing residual image-specific
information. The CR is constructed at the transmitter, and is combined with the
actual SC outcome at the receiver to yield a high-fidelity recomposed image.
While the transmission load of SR is fixed due to its NN-based structure, the
load of CR can be flexibly adjusted to achieve a desirable fidelity. This
controllability directly influences the final reconstruction error, for which
we derive a closed-form expression and the corresponding optimal CR. Simulation
results demonstrate that HSC substantially reduces MSE compared to the baseline
SC without CR transmission across various channels and NN architectures.

</details>


### [6] [HuiduRep: A Robust Self-Supervised Framework for Learning Neural Representations from Extracellular Spikes](https://arxiv.org/abs/2507.17224)
*Feng Cao,Zishuo Feng*

Main category: eess.SP

TL;DR: 本文提出HuiduRep框架，通过自监督表示学习解决细胞外记录中的峰值分类问题，在低信噪比和电极漂移等挑战性条件下实现了鲁棒的神经元活动解码


<details>
  <summary>Details</summary>
Motivation: 细胞外记录的峰值分类在低信噪比、电极漂移和跨会话变异性等条件下仍然具有挑战性，现有方法在这些困难条件下表现不佳，需要更鲁棒和通用的解决方案

Method: 提出HuiduRep自监督表示学习框架，结合对比学习和去噪自编码器从细胞外峰值波形中提取判别性和可泛化的特征，学习对噪声和漂移具有鲁棒性的潜在表示，并基于此构建无监督的峰值分类流水线

Result: 在混合数据集和真实世界数据集上的实验表明，HuiduRep展现出强鲁棒性，其峰值分类流水线的性能与KiloSort4和MountainSort5等最先进工具相匹配或超越

Conclusion: 自监督峰值表示学习具有作为细胞外记录鲁棒和可泛化处理基础工具的潜力，为神经科学中的大脑活动解码提供了新的有效途径

Abstract: Extracellular recordings are brief voltage fluctuations recorded near
neurons, widely used in neuroscience as the basis for decoding brain activity
at single-neuron resolution. Spike sorting, which assigns each spike to its
source neuron, is a critical step in brain sensing pipelines. However, it
remains challenging under low signal-to-noise ratio (SNR), electrode drift, and
cross-session variability. In this paper, we propose HuiduRep, a robust
self-supervised representation learning framework that extracts discriminative
and generalizable features from extracellular spike waveforms. By combining
contrastive learning with a denoising autoencoder, HuiduRep learns latent
representations that are robust to noise and drift. Built on HuiduRep, we
develop a spike sorting pipeline that clusters spike representations without
supervision. Experiments on hybrid and real-world datasets demonstrate that
HuiduRep achieves strong robustness and the pipeline matches or outperforms
state-of-the-art tools such as KiloSort4 and MountainSort5. These findings
demonstrate the potential of self-supervised spike representation learning as a
foundational tool for robust and generalizable processing of extracellular
recordings.

</details>


### [7] [Joint Resource Optimization Over Licensed and Unlicensed Spectrum in Spectrum Sharing UAV Networks Against Jamming Attacks](https://arxiv.org/abs/2507.17261)
*Rui Ding,Fuhui Zhou,Yuhang Wu,Qihui Wu,Tony Q. S. Quek*

Main category: eess.SP

TL;DR: 本文研究了在频谱稀缺环境下，通过联合优化功率分配、子信道分配和无人机轨迹来最大化UAV频谱共享网络的和速率，并提出了基于交替优化的低复杂度迭代算法来解决该非凸优化问题。


<details>
  <summary>Details</summary>
Motivation: UAV通信中用户密集且服务多样化导致频谱利用率稀缺，需要结合未授权频谱和授权频谱来提升网络容量，但未授权频谱的开放性使UAV容易受到潜在干扰器的安全威胁，因此需要在频谱共享UAV网络中考虑抗干扰技术。

Method: 将非凸优化问题分解为两个子问题：1)联合功率和子信道分配，2)UAV轨迹设计。采用交替优化方式提出低复杂度迭代算法，利用拉格朗日对偶分解来联合优化发射功率和子信道分配，然后设计基于连续凸近似的高效迭代算法来获得UAV轨迹的次优解。

Result: 仿真结果表明，所提出的算法与基准方案相比能够显著提升和传输速率。

Conclusion: 通过联合优化发射功率、子信道分配和UAV轨迹，所提出的交替优化算法能够有效解决频谱共享UAV网络中的和速率最大化问题，显著改善系统性能。

Abstract: Unmanned aerial vehicle (UAV) communication is of crucial importance in
realizing heterogeneous practical wireless application scenarios. However, the
densely populated users and diverse services with high data rate demands has
triggered an increasing scarcity of UAV spectrum utilization. To tackle this
problem, it is promising to incorporate the underutilized unlicensed spectrum
with the licensed spectrum to boost network capacity. However, the openness of
unlicensed spectrum makes UAVs susceptible to security threats from potential
jammers. Therefore, a spectrum sharing UAV network coexisting with licensed
cellular network and unlicensed Wi-Fi network is considered with the
anti-jamming technique in this paper. The sum rate maximization of the
secondary network is studied by jointly optimizing the transmit power,
subchannel allocation, and UAV trajectory. We first decompose the challenging
non-convex problem into two subproblems, 1) the joint power and subchannel
allocation and 2) UAV trajectory design subproblems. A low-complexity iterative
algorithm is proposed in a alternating optimization manner over these two
subproblems to solve the formulated problem. Specifically, the Lagrange dual
decomposition is exploited to jointly optimize the transmit power and
subchannel allocation iteratively. Then, an efficient iterative algorithm
capitalizing on successive convex approximation is designed to get a suboptimal
solution for UAV trajectory. Simulation results demonstrate that our proposed
algorithm can significantly improve the sum transmission rate compared with the
benchmark schemes.

</details>


### [8] [State Estimation with 1-Bit Observations and Imperfect Models: Bussgang Meets Kalman in Neural Networks](https://arxiv.org/abs/2507.17284)
*Chaehyun Jung,TaeJun Ha,Hyeonuk Kim,Jeonghun Park*

Main category: eess.SP

TL;DR: 本文提出了针对1比特量化观测数据的状态估计方法，通过Bussgang分解技术开发了Bussgang辅助卡尔曼滤波器及其深度学习变体，有效处理了量化失真和模型不匹配问题。


<details>
  <summary>Details</summary>
Motivation: 传统状态估计方法假设没有量化失真，但在实际应用中1比特量化不可避免且会造成严重信息损失，现有方法无法有效处理这种极端量化情况下的状态估计问题。

Method: 基于Bussgang分解技术开发Bussgang辅助卡尔曼滤波器，提出计算高效的简化版本，并结合抖动技术和门控循环单元(GRU)架构构建Bussgang辅助KalmanNet深度学习方法。

Result: 在Lorenz-Attractor模型和Michigan NCLT数据集上的仿真实验表明，所提方法即使在高度非线性、模型不匹配和1比特观测条件下也能实现准确的状态估计性能。

Conclusion: 通过将量化失真适当地集成到状态估计过程中，所提出的Bussgang辅助方法能够有效解决1比特量化环境下的状态估计问题，为处理极端量化条件提供了可行的解决方案。

Abstract: State estimation from noisy observations is a fundamental problem in many
applications of signal processing. Traditional methods, such as the extended
Kalman filter, work well under fully-known Gaussian models, while recent hybrid
deep learning frameworks, combining model-based and data-driven approaches, can
also handle partially known models and non-Gaussian noise. However, existing
studies commonly assume the absence of quantization distortion, which is
inevitable, especially with non-ideal analog-to-digital converters. In this
work, we consider a state estimation problem with 1-bit quantization. 1-bit
quantization causes significant quantization distortion and severe information
loss, rendering conventional state estimation strategies unsuitable. To address
this, inspired by the Bussgang decomposition technique, we first develop the
Bussgang-aided Kalman filter by assuming perfectly known models. The proposed
method suitably captures quantization distortion into the state estimation
process. In addition, we propose a computationally efficient variant, referred
to as the reduced Bussgang-aided Kalman filter and, building upon it, introduce
a deep learning-based approach for handling partially known models, termed the
Bussgang-aided KalmanNet. In particular, the Bussgang-aided KalmanNet jointly
uses a dithering technique and a gated recurrent unit (GRU) architecture to
effectively mitigate the effects of 1-bit quantization and model mismatch.
Through simulations on the Lorenz-Attractor model and the Michigan NCLT
dataset, we demonstrate that our proposed methods achieve accurate state
estimation performance even under highly nonlinear, mismatched models and 1-bit
observations.

</details>


### [9] [Non-Orthogonal AFDM: A Promising Spectrum-Efficient Waveform for 6G High-Mobility Communications](https://arxiv.org/abs/2507.17292)
*Yu Zhang,Qin Yi,Leila Musavian,Tongyang Xu,Zilong Liu*

Main category: eess.SP

TL;DR: 本文提出了一种频谱高效的非正交仿射频分复用(AFDM)波形，通过引入压缩因子实现可控的子载波重叠，并采用线性预编码和迭代检测技术来减少载波间干扰，为6G移动系统中的高移动性通信提供了平衡频谱效率和多普勒弹性的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有的正交频分复用技术在高移动性环境下面临频谱效率低和多普勒敏感性强的问题，需要为6G移动系统开发既能提高频谱效率又能抵抗高移动性信道条件的新型波形技术。

Method: 提出非正交AFDM波形设计方法：1）引入压缩因子实现可控的子载波重叠以提高频谱效率；2）在发送端采用线性预编码技术减少载波间干扰；3）在接收端设计迭代检测方案进一步抑制干扰。

Result: 仿真结果表明，即使在激进的压缩因子和高移动性信道条件下，所提出的技术能够有效减少干扰并保持稳健的误码率性能，验证了非正交AFDM波形的有效性。

Conclusion: 所提出的非正交AFDM波形为下一代无线网络提供了一个有前景的解决方案，能够在高动态环境中有效平衡频谱效率和多普勒弹性，适用于6G移动系统的高移动性通信场景。

Abstract: This paper proposes a spectrum-efficient nonorthogonal affine frequency
division multiplexing (AFDM) waveform for reliable high-mobility communications
in the upcoming sixth-generation (6G) mobile systems. Our core idea is to
introduce a compression factor to enable controllable subcarrier overlapping in
chirp-based AFDM modulation. To mitigate intercarrier interference (ICI), we
introduce linear precoding at the transmitter and an iterative detection scheme
at the receiver. Simulation results demonstrate that these techniques can
effectively reduce interference and maintain robust bit error rate (BER)
performance even under aggressive compression factors and high-mobility channel
conditions. The proposed non-orthogonal AFDM waveform offers a promising
solution for next-generation wireless networks, balancing spectrum efficiency
and Doppler resilience in highly dynamic environments.

</details>


### [10] [LightCom: A Generative AI-Augmented Framework for QoE-Oriented Communications](https://arxiv.org/abs/2507.17352)
*Chunmei Xu,Siqi Zhang,Yi Ma,Rahim Tafazolli*

Main category: eess.SP

TL;DR: 本文提出LightCom框架，通过轻量级编码和生成式AI解码技术，在低信噪比条件下实现面向用户体验质量(QoE)的通信系统，相比传统QoS驱动系统在鲁棒性和感知覆盖范围方面分别提升14dB和9dB。


<details>
  <summary>Details</summary>
Motivation: 数据密集型和沉浸式应用(如虚拟现实)对用户体验质量提出了严格要求，传统的基于服务质量(QoS)驱动的通信系统面临挑战，需要在低信噪比条件下提供更好的用户体验质量。

Method: 设计了LightCom框架，包含轻量级编码和生成式AI增强解码两部分：发射端采用基础低通滤波进行信源编码和最小化信道编码来降低处理复杂度和能耗；接收端使用生成式AI模型利用生成先验来推断语义和结构信息，从高度压缩和退化的信号中重建高保真内容；同时开发了重要性感知的功率分配策略。

Result: 仿真结果显示LightCom在鲁棒性方面实现了高达14dB的改善，在感知覆盖范围方面获得了9dB的提升，性能超越了依赖复杂信源和信道编码的传统QoS驱动系统。

Conclusion: 该研究实现了从传统的比特级保真度向以人为中心的QoE指标的范式转变，为构建更高效和更具弹性的无线网络铺平了道路，证明了生成式AI在通信系统中的巨大潜力。

Abstract: Data-intensive and immersive applications, such as virtual reality, impose
stringent quality of experience (QoE) requirements that challenge traditional
quality of service (QoS)-driven communication systems. This paper presents
LightCom, a lightweight encoding and generative AI (GenAI)-augmented decoding
framework, designed for QoE-oriented communications under low signal-to-noise
ratio (SNR) conditions. LightCom simplifies transmitter design by applying
basic low-pass filtering for source coding and minimal channel coding,
significantly reducing processing complexity and energy consumption. At the
receiver, GenAI models reconstruct high-fidelity content from highly compressed
and degraded signals by leveraging generative priors to infer semantic and
structural information beyond traditional decoding capabilities. The key design
principles are analyzed, along with the sufficiency and error-resilience of the
source representation. We also develop importance-aware power allocation
strategies to enhance QoE and extend perceived coverage. Simulation results
demonstrate that LightCom achieves up to a $14$ dB improvement in robustness
and a $9$ dB gain in perceived coverage, outperforming traditional QoS-driven
systems relying on sophisticated source and channel coding. This paradigm shift
moves communication systems towards human-centric QoE metrics rather than
bit-level fidelity, paving the way for more efficient and resilient wireless
networks.

</details>


### [11] [Partially Reflected Surface (PRS)-Loaded Graphene-Based Patch Antenna for 6G](https://arxiv.org/abs/2507.17393)
*Omar Osman,Abdullah Qayyum,Maziar Nekovee*

Main category: eess.SP

TL;DR: 本文提出了一种集成部分反射表面(PRS)的开槽贴片天线，工作在太赫兹频段用于6G通信，基于石墨烯材料设计，实现了70 GHz带宽和1.07 dBi增益提升


<details>
  <summary>Details</summary>
Motivation: 为6G通信系统开发高性能的太赫兹频段天线，需要提升天线的增益和辐射特性以满足未来无线通信的需求

Method: 设计了基于石墨烯材料的开槽贴片天线，集成5x4单元的部分反射表面(PRS)，使用Rogers RT Duroid 6010基板，通过优化PRS单元结构来增强天线整体性能

Result: 天线在750-820 GHz频段实现70 GHz带宽，PRS使天线增益提升1.07 dBi，改善了辐射方向图，在工作带宽内表现出稳定的特性

Conclusion: 集成PRS的石墨烯开槽贴片天线成功提升了太赫兹频段的天线性能，通过仿真验证了设计的有效性，为6G通信系统提供了可行的天线解决方案

Abstract: This work investigates a slotted patch antenna integrated with a partially
reflected surface (PRS) to operate in the TeraHertz (THz) frequency range for
6G. The antenna is based on graphene material, on a Rogers RT Duroid 6010
substrate. The proposed antenna achieves a bandwidth of 70 GHz (750 GHz to 820
GHz). The PRS sheet consists of 5x4 unit cells, which are optimised to enhance
the overall realized gain of the antenna. The overall realized gain has
increased by 1.07 dBi. Also, the PRS enhanced the antenna radiation pattern,
showing stable properties over the operating bandwidth. The improved antenna
performance is validated via simulations.

</details>


### [12] [Learning from Scratch: Structurally-masked Transformer for Next Generation Lib-free Simulation](https://arxiv.org/abs/2507.17396)
*Junlang Huang,Hao Chen,Zhong Guan*

Main category: eess.SP

TL;DR: 本文提出了一种基于神经网络的多级数据通路功耗和时序预测框架，使用CNN-Transformer混合架构直接从SPICE网表推断瞬态波形和传播延迟，在工业电路上达到SPICE级精度（RMSE低于0.0098）。


<details>
  <summary>Details</summary>
Motivation: 传统基于库的分析方法依赖于驱动器特性和负载简化，存在局限性。缺乏专门针对标准单元设计的语言化、网表感知的神经网络方法来进行功耗和时序预测。

Method: 采用两个预训练神经模型进行波形预测和延迟估计，直接从SPICE网表推断瞬态波形和传播延迟。使用混合CNN-Transformer架构和网表感知的节点级编码，实现递归传播策略进行多级时序预测，并使用专门的子网络分别处理主要延迟估计和串扰校正。

Result: 在多样化的工业电路上实现了SPICE级精度，RMSE始终低于0.0098。该框架能够准确捕获内在和耦合诱导的延迟效应，确保复杂信号路径中的精确时序对齐和完整波形可见性。

Conclusion: 提出的神经框架为传统功耗和时序引擎提供了可扩展、结构自适应的神经网络替代方案，对物理电路行为表现出高保真度，是首个专门针对标准单元的语言化、网表感知神经网络方法。

Abstract: This paper proposes a neural framework for power and timing prediction of
multi-stage data path, distinguishing itself from traditional lib-based
analytical methods dependent on driver characterization and load
simplifications. To the best of our knowledge, this is the first
language-based, netlist-aware neural network designed explicitly for standard
cells. Our approach employs two pre-trained neural models of waveform
prediction and delay estimation that directly infer transient waveforms and
propagation delays from SPICE netlists, conditioned on critical physical
parameters such as load capacitance, input slew, and gate size. This method
accurately captures both intrinsic and coupling-induced delay effects without
requiring simplification or interpolation. For multi-stage timing prediction,
we implement a recursive propagation strategy where predicted waveforms from
each stage feed into subsequent stages, cumulatively capturing delays across
the logic chain. This approach ensures precise timing alignment and complete
waveform visibility throughout complex signal pathways. The waveform prediction
utilizes a hybrid CNN-Transformer architecture with netlist-aware node-level
encoding, addressing traditional Transformers' fixed input dimensionality
constraints. Additionally, specialized subnetworks separately handle primary
delay estimation and crosstalk correction. Experimental results demonstrate
SPICE-level accuracy, consistently achieving RMSE below 0.0098 across diverse
industrial circuits. The proposed framework provides a scalable, structurally
adaptable neural alternative to conventional power and timing engines,
demonstrating high fidelity to physical circuit behaviors.

</details>


### [13] [Power Allocation and RIS Elements Optimisation for Reconfigurable Intelligent Surfaces assisted RSMA](https://arxiv.org/abs/2507.17419)
*Abdullah Qayyum,Maziar Nekovee*

Main category: eess.SP

TL;DR: 本文提出了一种优化的可重构智能表面辅助速率分割多址接入（ORIS-RSMA）方法，通过优化RIS元件数量和功率分配来最大化系统和速率。


<details>
  <summary>Details</summary>
Motivation: 在RIS辅助的RSMA系统中，需要优化RIS元件数量和功率分配策略，以提高系统性能并确保满足目标公共速率要求。

Method: 提出ORIS-RSMA方法，该方法确定最优的RIS元件数量，并对消息的公共部分和私有部分进行功率分配优化，同时在满足目标公共速率的约束下最大化和速率。

Result: 仿真结果表明，与传统的RIS-RSMA和RSMA方法相比，ORIS-RSMA方法能够实现更高的和速率性能。

Conclusion: 通过联合优化RIS元件数量和功率分配，ORIS-RSMA方法在RIS辅助的RSMA系统中取得了更优的性能表现，有效提升了系统和速率。

Abstract: This paper proposes power allocation and the number of reconfigurable
intelligent surfaces (RIS) elements optimisation in a RIS-assisted rate
splitting multiple access (RSMA) system. The optimised RIS-RSMA (ORIS-RSMA)
method determines the optimal number of RIS elements and the power allocation
factors for both common and private parts of a message. Additionally, it
maximises the sum rate while ensuring that a target common rate is satisfied.
The performance of the proposed ORIS-RSMA is compared to that of the
conventional RIS-RSMA and RSMA. Simulation results show that ORIS-RSMA achieves
a higher sum rate.

</details>


### [14] [Detecting Multiple Targets with Distributed Sensing and Communication in Cell-Free Massive MIMO](https://arxiv.org/abs/2507.17441)
*Zinat Behdad,Ozlem Tugfe Demir,Ki Won Sung,Cicek Cavdar*

Main category: eess.SP

TL;DR: 该论文研究了无小区大规模MIMO框架下集成感知通信系统的多目标检测问题，提出了启发式接入点模式选择算法和信道感知分布式感知方案，通过功率分配优化实现通信-感知性能平衡。


<details>
  <summary>Details</summary>
Motivation: 在无小区大规模MIMO系统中实现集成感知通信时，需要解决多目标检测的挑战，特别是如何在保证通信性能的同时优化感知能力，以及如何处理通信和感知之间的权衡问题。

Method: 采用以用户为中心的通信方法和分布式多目标感知方法；提出启发式接入点模式选择算法；设计基于信道感知的分布式感知方案，根据接收信号的信干比对本地测量进行加权；应用最大后验比率测试检测器；开发功率分配算法联合优化最小检测概率和通信信干噪比。

Result: 所提方案优于非加权方法；增加更多接收接入点的测试统计量可能因信道较弱而降低感知性能，但可通过优化加权指数来缓解；为感知区域分配更多感知接收接入点会导致最小通信信干噪比损失约10dB。

Conclusion: 该研究成功解决了无小区大规模MIMO集成感知通信系统中的多目标检测问题，提出的信道感知加权方案和功率分配算法能够有效平衡通信与感知性能，但需要在感知资源分配和通信性能之间做出权衡。

Abstract: This paper investigates multi-target detection in an integrated sensing and
communication (ISAC) system within a cell-free massive MIMO (CF-mMIMO)
framework. We adopt a user-centric approach for communication user equipments
(UEs) and a distributed sensing approach for multi-target detection. A
heuristic access point (AP) mode selection algorithm and a channel-aware
distributed sensing scheme are proposed, where local measurements at receive
APs (RX-APs) are weighted based on the received signals signal-to-interference
ratio (SIR). A maximum a posteriori ratio test (MAPRT) detector is applied
under two awareness levels at RX-APs. To balance the communication-sensing
trade-off, we develop a power allocation algorithm to jointly maximize the
minimum detection probability and communication
signal-to-interference-plus-noise ratio (SINR) while satisfying power
constraints. The proposed scheme outperforms non-weighted methods. Adding test
statistics from more RX-APs can degrade sensing performance due to weaker
channels, but this effect can be mitigated by optimizing the weighting
exponent. Additionally, assigning more sensing RX-APs to a sensing area results
in approximately 10 dB loss in minimum communication SINR due to limited
communication resources.

</details>


### [15] [Slow Fluid Antenna Multiple Access with Multiport Receivers](https://arxiv.org/abs/2507.17505)
*José P. González-Coma,F. Javier López-Martínez*

Main category: eess.SP

TL;DR: 该论文研究了为流体天线(FA)接收器配备多个射频链是否能改善慢速流体天线多址(FAMA)技术的性能，通过联合设计端口选择矩阵和合并向量，在有限射频链条件下实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的慢速FAMA技术仅在接收端具有信道状态信息，性能有限。研究者希望通过为流体天线接收器配备多个射频链来提升系统性能，探索多端口接收在流体天线系统中的潜力。

Method: 分析配备多端口接收器的慢速FAMA用户场景，选择流体天线的L个端口并进行合并以减少干扰。提出联合设计端口选择矩阵和每个接收器合并向量的方法。

Result: 联合设计方案相比参考方案获得了显著的性能增益，验证了在射频链数量有限的流体天线系统中多端口接收技术的有效性。

Conclusion: 为流体天线接收器配备多个射频链并采用联合优化的端口选择和信号合并策略，能够有效改善慢速FAMA技术的性能，展现了多端口接收在流体天线系统中的应用潜力。

Abstract: We investigate whether equipping fluid-antenna (FA) receivers with multiple
($L>1$) radiofrequency (RF) chains can improve the performance of the slow
fluid-antenna multiple access (FAMA) technique, which enables open-loop
connectivity with channel state information (CSI) available only at the
receiver side. We analyze the case of slow-FAMA users equipped with multiport
receivers, so that $L$ ports of the FA are selected and combined to reduce
interference. We show that a joint design of the port selection matrix and the
combining vector at each receiver yields significant performance gains over
reference schemes, demonstrating the potential of multiport reception in FA
systems with a limited number of RF chains.

</details>


### [16] [Joint Multi-Target Detection-Tracking in Cognitive Massive MIMO Radar via POMCP](https://arxiv.org/abs/2507.17506)
*Imad Bouhou,Stefano Fortunati,Leila Gharsalli,Alexandre Renaux*

Main category: eess.SP

TL;DR: 本文提出了一种基于POMCP的功率感知认知雷达框架，用于大规模MIMO雷达环境中多目标的联合检测和跟踪，通过自适应波形设计优化功率分配，提高低信噪比目标的检测概率和跟踪精度。


<details>
  <summary>Details</summary>
Motivation: 现有的均匀功率分配方法在不同信噪比条件下往往不是最优的，需要开发一种能够自适应分配发射功率的认知雷达框架，以提高多目标检测和跟踪性能，特别是针对弱信号或远距离目标的检测能力。

Method: 将基于部分可观测蒙特卡洛规划(POMCP)的单目标算法扩展到多目标场景，为每个目标分配独立的POMCP树；基于目标的估计距离和雷达截面积预测其未来角位置和期望接收功率；通过约束优化问题进行自适应波形设计，分配发射能量以增强弱目标或远距离目标的可检测性；修改部分可观测马尔可夫决策过程中的奖励函数以优先考虑准确的空间和功率估计。

Result: 仿真结果显示，所提出的认知雷达框架相比使用均匀或正交波形的方法，能够提高低信噪比目标的检测概率，并实现更准确的跟踪性能。多目标仿真验证了该方法在不同信噪比条件下的有效性。

Conclusion: 基于POMCP的功率感知认知雷达框架在多目标检测和跟踪方面表现出优异性能，特别是在处理不同信噪比目标时的自适应能力，展示了该框架在自适应、高效多目标雷达系统中的应用潜力。

Abstract: This correspondence presents a power-aware cognitive radar framework for
joint detection and tracking of multiple targets in a massive multiple-input
multiple-output (MIMO) radar environment. Building on a previous single-target
algorithm based on Partially Observable Monte Carlo Planning (POMCP), we extend
it to the multi-target case by assigning each target an independent POMCP tree,
enabling scalable and efficient planning.
  Departing from uniform power allocation-which is often suboptimal with
varying signal-to-noise ratios (SNRs)-our approach predicts each target's
future angular position and expected received power, based on its estimated
range and radar cross-section (RCS). These predictions guide adaptive waveform
design via a constrained optimization problem that allocates transmit energy to
enhance the detectability of weaker or distant targets, while ensuring
sufficient power for high-SNR targets. The reward function in the underlying
partially observable Markov decision process (POMDP) is also modified to
prioritize accurate spatial and power estimation.
  Simulations involving multiple targets with different SNRs confirm the
effectiveness of our method. The proposed framework for the cognitive radar
improves detection probability for low-SNR targets and achieves more accurate
tracking compared to approaches using uniform or orthogonal waveforms. These
results demonstrate the potential of the POMCP-based framework for adaptive,
efficient multi-target radar systems.

</details>


### [17] [SA-WiSense: A Blind-Spot-Free Respiration Sensing Framework for Single-Antenna Wi-Fi Devices](https://arxiv.org/abs/2507.17623)
*Guangteng Liu,Xiayue Liu,Zhixiang Xu,Yufeng Yuan,Hui Zhao,Yuxuan Liu,Yufei Jiang*

Main category: eess.SP

TL;DR: 提出了一个单天线Wi-Fi感知框架(SA-WiSense)，通过跨子载波信道状态信息比值(CSCR)方法和遗传算法子载波选择(GASS)技术，解决了随机相位偏移导致的盲点问题，实现了成本高效的非接触式人体呼吸监测。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi感知技术在非接触式人体呼吸监测中面临盲点问题，这是由随机相位偏移破坏呼吸信号互补性导致的。现有方法需要多天线，成本高且不适用于大多数只配备单天线的物联网设备。

Method: 提出SA-WiSense框架，包含两个核心技术：1)跨子载波CSI比值(CSCR)盲点缓解方法，利用子载波间CSI值的比值来消除随机相位偏移；2)基于遗传算法的子载波选择(GASS)方法，通过优化感知信噪比来选择最佳子载波组合。

Result: 使用ESP32微控制器进行实验验证，在最远8.0米距离内实现了91.2%的呼吸检测率，显著优于现有单天线方法的性能表现。

Conclusion: SA-WiSense框架成功解决了单天线Wi-Fi感知中的盲点问题，在保持成本效率的同时实现了高精度的呼吸监测，适用于物联网环境，为非接触式生理监测提供了实用的解决方案。

Abstract: Wi-Fi sensing offers a promising technique for contactless human respiration
monitoring. A key challenge, however, is the blind spot problem caused by
random phase offsets that corrupt the complementarity of respiratory signals.
To address the challenge, we propose a single-antenna-Wi-Fi-sensing
(SA-WiSense) framework to improve accuracy of human respiration monitoring,
robust against random phase offsets. The proposed SA-WiSense framework is
cost-efficient, as only a single antenna is used rather than multiple antennas
as in the previous works. Therefore, the proposed framework is applicable to
Internet of Thing (IoT), where most of sensors are equipped with a single
antenna. On one hand, we propose a cross-subcarrier channel state information
(CSI) ratio (CSCR) based blind spot mitigation approach for IoT, where the
ratios of two values of CSI between subcarriers are leveraged to mitigate
random phase offsets. We prove that the random phase offsets can be cancelled
by the proposed CSCR approach, thereby restoring the inherent complementarity
of signals for blind-spot-free sensing. On the other hand, we propose a genetic
algorithm (GA) based subcarrier selection (GASS) approach by formulating an
optimization problem in terms of the sensing-signal-to-noise ratio (SSNR) of
CSCR between subcarriers. GA is utilized to solve the formulated optimization
problem. We use commodity ESP32 microcontrollers to build an experiment test.
The proposed works are validated to achieve an detection rate of 91.2% for
respiration monitoring at distances up to 8.0 meters, substantially more
accurate than the state-of-the-art methods with a single antenna.

</details>


### [18] [Quaternion-Domain Super MDS for Robust 3D Localization](https://arxiv.org/abs/2507.17645)
*Alessio Lukaj,Keigo Masuoka,Takumi Takahashi,Giuseppe Thadeu Freitas de Abreu,Hideki Ochiai*

Main category: eess.SP

TL;DR: 本文提出了一种基于四元数代数的新型低复杂度三维定位算法QD-SMDS，通过将3D坐标表示为四元数并构造秩-1 Gram边核矩阵，显著提升了无线传感器网络中的定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的SMDS算法在实数域中运行，在面对测量误差时定位精度不够理想，且计算复杂度较高。需要一种能够更好地整合距离和角度信息、提高噪声抑制能力并降低计算复杂度的三维定位算法。

Method: 将原本在实数域开发的SMDS算法重新表述为基于四元数代数的形式，通过将3D坐标表示为四元数来构造秩-1的Gram边核(GEK)矩阵，该矩阵整合了节点间的相对距离和角度信息。利用奇异值分解(SVD)进行低秩截断以增强降噪效果。此外还提出了一个变体算法，通过利用四元数域GEK矩阵的固有结构来避免计算昂贵的SVD操作。

Result: 仿真结果表明，与原始SMDS算法相比，所提出的方法显著提高了定位精度，特别是在存在大量测量误差的场景中表现更佳。变体算法在不需要SVD的情况下也能达到相当的定位精度，有效降低了计算复杂度。

Conclusion: QD-SMDS算法通过四元数表示和秩-1 GEK矩阵的构造，成功提升了无线传感器网络三维定位的精度和鲁棒性。该方法在保持较低计算复杂度的同时，特别适用于测量误差较大的应用场景，为无线传感器网络定位提供了一种有效的解决方案。

Abstract: This paper proposes a novel low-complexity three-dimensional (3D)
localization algorithm for wireless sensor networks, termed quanternion-domain
super multi-dimensional scaling (QD-SMDS). The algorithm is based on a
reformulation of the SMDS, originally developed in the real domain, using
quaternion algebra. By representing 3D coordinates as quaternions, the method
constructs a rank-1 Gram edge kernel (GEK) matrix that integrates both relative
distance and angular information between nodes, which enhances the noise
reduction effect achieved through low-rank truncation employing singular value
decomposition (SVD), thereby improving robustness against information loss. To
further reduce computational complexity, we also propose a variant of QD-SMDS
that eliminates the need for the computationally expensive SVD by leveraging
the inherent structure of the quaternion-domain GEK matrix. This alternative
directly estimates node coordinates using only matrix multiplications within
the quaternion domain. Simulation results demonstrate that the proposed method
significantly improves localization accuracy compared to the original SMDS
algorithm, especially in scenarios with substantial measurement errors. The
proposed method also achieves comparable localization accuracy without
requiring SVD.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [19] [Does Language Matter for Early Detection of Parkinson's Disease from Speech?](https://arxiv.org/abs/2507.16832)
*Peter Plantinga,Briac Cordelle,Dominique Louër,Mirco Ravanelli,Denise Klein*

Main category: eess.AS

TL;DR: 本研究探讨了语言在帕金森病早期检测中的关键作用，发现纯文本模型可以匹配语音特征模型的性能，多语言Whisper模型表现优于自监督模型，AudioSet预训练在持续元音发声任务上有效但在自发语音上无效。


<details>
  <summary>Details</summary>
Motivation: 帕金森病语音检测领域存在数据收集和分析方法的争议，需要评估语言在帕金森病检测中的具体作用，以及不同预训练模型和数据类型对检测性能的影响。

Method: 测试了不同数据类型（纯文本、语音特征）和预训练目标的预训练模型，包括多语言和单语言Whisper模型、自监督模型，以及AudioSet预训练模型，分别在持续元音发声(SVP)任务和自发语音任务上进行评估。

Result: 发现三个主要结果：(1)纯文本模型的性能可以匹配语音特征模型；(2)多语言Whisper模型优于自监督模型，而单语言Whisper表现较差；(3)AudioSet预训练在SVP任务上提升性能，但在自发语音上无效。

Conclusion: 研究结果共同强调了语言在帕金森病早期检测中的关键作用，表明语言信息是帕金森病语音生物标志物检测的重要组成部分。

Abstract: Using speech samples as a biomarker is a promising avenue for detecting and
monitoring the progression of Parkinson's disease (PD), but there is
considerable disagreement in the literature about how best to collect and
analyze such data. Early research in detecting PD from speech used a sustained
vowel phonation (SVP) task, while some recent research has explored recordings
of more cognitively demanding tasks. To assess the role of language in PD
detection, we tested pretrained models with varying data types and pretraining
objectives and found that (1) text-only models match the performance of
vocal-feature models, (2) multilingual Whisper outperforms self-supervised
models whereas monolingual Whisper does worse, and (3) AudioSet pretraining
improves performance on SVP but not spontaneous speech. These findings together
highlight the critical role of language for the early detection of Parkinson's
disease.

</details>


### [20] [Towards Robust Speech Recognition for Jamaican Patois Music Transcription](https://arxiv.org/abs/2507.16834)
*Jordan Madden,Matthew Stone,Dimitri Johnson,Daniel Geddez*

Main category: eess.AS

TL;DR: 该研究通过构建40多小时的牙买加帕图瓦语音乐手动转录数据集，微调最先进的自动语音识别模型，开发了Whisper模型在牙买加帕图瓦语音频上的性能缩放定律，以提升该语言音乐的可访问性


<details>
  <summary>Details</summary>
Motivation: 现有语音识别系统在牙买加帕图瓦语音乐上表现糟糕，产生不准确的字幕，限制了可访问性并阻碍了下游应用的发展

Method: 采用数据驱动的方法，构建了超过40小时的手动转录牙买加帕图瓦语音乐数据集，使用该数据集对最先进的自动语音识别(ASR)模型进行微调，并基于结果开发Whisper模型的性能缩放定律

Result: 成功构建了牙买加帕图瓦语音乐的大规模转录数据集，并建立了Whisper模型在该语言音频上的性能缩放定律

Conclusion: 这项工作有望对牙买加帕图瓦语音乐的可访问性产生积极影响，并推动牙买加帕图瓦语言建模的未来发展

Abstract: Although Jamaican Patois is a widely spoken language, current speech
recognition systems perform poorly on Patois music, producing inaccurate
captions that limit accessibility and hinder downstream applications. In this
work, we take a data-centric approach to this problem by curating more than 40
hours of manually transcribed Patois music. We use this dataset to fine-tune
state-of-the-art automatic speech recognition (ASR) models, and use the results
to develop scaling laws for the performance of Whisper models on Jamaican
Patois audio. We hope that this work will have a positive impact on the
accessibility of Jamaican Patois music and the future of Jamaican Patois
language modeling.

</details>


### [21] [Evaluating Speech-to-Text x LLM x Text-to-Speech Combinations for AI Interview Systems](https://arxiv.org/abs/2507.16835)
*Nima Yazdani,Ali Ansari,Aruj Mahajan,Amirhossein Afsharrad,Seyed Shahabeddin Mousavi*

Main category: eess.AS

TL;DR: 本研究对语音对话AI系统中的STT、LLM和TTS组件组合进行了大规模实证比较，通过分析30万次AI面试数据，发现Google STT配合GPT-4.1表现最佳，但技术指标与用户满意度相关性较弱。


<details>
  <summary>Details</summary>
Motivation: 目前语音对话AI系统越来越依赖级联架构（STT+LLM+TTS），但对不同组件组合在生产环境中的系统性评估研究不足，需要为多模态对话AI系统的组件选择提供实用指导。

Method: 使用超过30万次AI面试数据进行大规模实证比较，开发基于LLM-as-a-Judge的自动化评估框架，评估对话质量、技术准确性和技能评估能力，分析四种生产配置的STT x LLM x TTS组合。

Result: Google STT与GPT-4.1的组合在对话质量和技术质量指标上显著优于其他替代方案；客观质量指标与用户满意度评分的相关性较弱，表明语音AI系统的用户体验依赖于技术性能之外的因素。

Conclusion: 为多模态对话AI系统的组件选择提供了实用指导，贡献了一套经过验证的语音交互评估方法，并揭示了技术性能与用户体验之间的复杂关系。

Abstract: Voice-based conversational AI systems increasingly rely on cascaded
architectures combining speech-to-text (STT), large language models (LLMs), and
text-to-speech (TTS) components. However, systematic evaluation of different
component combinations in production settings remains understudied. We present
a large-scale empirical comparison of STT x LLM x TTS stacks using data from
over 300,000 AI-conducted job interviews. We develop an automated evaluation
framework using LLM-as-a-Judge to assess conversational quality, technical
accuracy, and skill assessment capabilities. Our analysis of four production
configurations reveals that Google STT paired with GPT-4.1 significantly
outperforms alternatives in both conversational and technical quality metrics.
Surprisingly, we find that objective quality metrics correlate weakly with user
satisfaction scores, suggesting that user experience in voice-based AI systems
depends on factors beyond technical performance. Our findings provide practical
guidance for selecting components in multimodal conversational AI systems and
contribute a validated evaluation methodology for voice-based interactions.

</details>


### [22] [From Black Box to Biomarker: Sparse Autoencoders for Interpreting Speech Models of Parkinson's Disease](https://arxiv.org/abs/2507.16836)
*Peter Plantinga,Jen-Kai Chen,Roozbeh Sattari,Mirco Ravanelli,Denise Klein*

Main category: eess.AS

TL;DR: 本研究使用稀疏自编码器(SAEs)来解释基于语音的帕金森病检测系统的内部表征，发现了与帕金森病语音特征相关的可解释生物标志物，并证明了频谱流量与MRI扫描中壳核体积测量的相关性。


<details>
  <summary>Details</summary>
Motivation: 深度学习系统虽然能从原始音频中发现微妙信号，但其黑盒性质阻碍了临床应用。需要开发可解释的方法来理解语音基础的帕金森病检测系统的内部工作机制，以促进临床采用。

Method: 应用稀疏自编码器(SAEs)来揭示语音基础帕金森病检测系统的可解释内部表征。引入了一种新颖的基于掩码的激活方法，用于将SAEs适配到小型生物医学数据集，创建稀疏解耦的字典表征。

Result: 字典条目与帕金森病语音中的特征性构音缺陷具有强相关性，如模型注意力突出的低能量区域中频谱流量减少和频谱平坦度增加。频谱流量与MRI扫描中壳核的体积测量相关。

Conclusion: 稀疏自编码器能够揭示临床相关的生物标志物，为疾病监测和诊断提供潜在价值。该方法成功地将深度学习模型的黑盒表征转化为可解释的、与帕金森病病理生理机制相关的特征。

Abstract: Speech holds promise as a cost-effective and non-invasive biomarker for
neurological conditions such as Parkinson's disease (PD). While deep learning
systems trained on raw audio can find subtle signals not available from
hand-crafted features, their black-box nature hinders clinical adoption. To
address this, we apply sparse autoencoders (SAEs) to uncover interpretable
internal representations from a speech-based PD detection system. We introduce
a novel mask-based activation for adapting SAEs to small biomedical datasets,
creating sparse disentangled dictionary representations. These dictionary
entries are found to have strong associations with characteristic articulatory
deficits in PD speech, such as reduced spectral flux and increased spectral
flatness in the low-energy regions highlighted by the model attention. We
further show that the spectral flux is related to volumetric measurements of
the putamen from MRI scans, demonstrating the potential of SAEs to reveal
clinically relevant biomarkers for disease monitoring and diagnosis.

</details>


### [23] [Segmentation-free Goodness of Pronunciation](https://arxiv.org/abs/2507.16838)
*Xinwei Cao,Zijian Fan,Torbjørn Svendsen,Giampiero Salvi*

Main category: eess.AS

TL;DR: 本研究提出了两种新的发音评估方法GOP-SA和GOP-AF，解决了传统GOP方法需要预分割语音的限制，实现了在音素级发音评估任务上的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 传统的发音好坏度（GOP）方法需要预先将语音分割成音素单元，这限制了方法的准确性，并且无法使用现代基于CTC的声学模型进行评估。因此需要开发新的方法来克服这些限制。

Method: 首先提出自对齐GOP（GOP-SA），使CTC训练的ASR模型能够用于发音错误检测和诊断。然后定义了更通用的无对齐方法GOP-AF，该方法考虑目标音素的所有可能对齐方式，并提供了理论解释、数值稳定的实现方案和适当的归一化处理。

Result: 在CMU Kids和Speechocean762数据集上进行了广泛实验，验证了不同方法定义的有效性，分析了GOP-AF对声学模型尖锐度和目标音素周围上下文量的依赖性。在Speechocean762数据上与最新研究的比较显示，所提方法达到了音素级发音评估的最先进结果。

Conclusion: 提出的GOP-SA和GOP-AF方法成功解决了传统GOP方法的局限性，能够有效利用CTC声学模型进行发音评估，在音素级发音评估任务上实现了最优性能，为计算机辅助语言学习系统提供了更准确的发音诊断工具。

Abstract: Mispronunciation detection and diagnosis (MDD) is a significant part in
modern computer aided language learning (CALL) systems. Within MDD,
phoneme-level pronunciation assessment is key to helping L2 learners improve
their pronunciation. However, most systems are based on a form of goodness of
pronunciation (GOP) which requires pre-segmentation of speech into phonetic
units. This limits the accuracy of these methods and the possibility to use
modern CTC-based acoustic models for their evaluation. In this study, we first
propose self-alignment GOP (GOP-SA) that enables the use of CTC-trained ASR
models for MDD. Next, we define a more general alignment-free method that takes
all possible alignments of the target phoneme into account (GOP-AF). We give a
theoretical account of our definition of GOP-AF, an implementation that solves
potential numerical issues as well as a proper normalization which makes the
method applicable with acoustic models with different peakiness over time. We
provide extensive experimental results on the CMU Kids and Speechocean762
datasets comparing the different definitions of our methods, estimating the
dependency of GOP-AF on the peakiness of the acoustic models and on the amount
of context around the target phoneme. Finally, we compare our methods with
recent studies over the Speechocean762 data showing that the feature vectors
derived from the proposed method achieve state-of-the-art results on
phoneme-level pronunciation assessment.

</details>


### [24] [Enhancing Lung Disease Diagnosis via Semi-Supervised Machine Learning](https://arxiv.org/abs/2507.16845)
*Xiaoran Xua,In-Ho Rab,Ravi Sankarc*

Main category: eess.AS

TL;DR: 该研究使用半监督学习方法结合MFCC+CNN模型进行肺部疾病声音检测，通过引入Mix Match、Co-Refinement和Co Refurbishing等半监督学习模块，将检测准确率提升至92.9%，相比基线模型提高了3.8%。


<details>
  <summary>Details</summary>
Motivation: 传统的肺部疾病（包括肺癌和慢性阻塞性肺病）诊断方法成本高昂、耗时且具有侵入性。同时，肺部疾病声音检测面临个体差异大、标注数据不足等挑战，需要开发更有效的自动检测方法来减少对人工标注的依赖。

Method: 采用MFCC+CNN模型作为基础架构，结合半监督学习方法来提升检测性能。具体引入了三个半监督学习模块：Mix Match、Co-Refinement和Co Refurbishing，以充分利用未标注数据并减少对人工标注的依赖。

Result: 通过添加半监督学习模块，MFCC+CNN模型的准确率达到92.9%，相比基线模型提升了3.8%。该方法有效提升了肺部疾病声音检测的性能。

Conclusion: 半监督学习方法能够有效提升肺部疾病声音检测的准确性，通过减少对人工标注数据的依赖，为肺部疾病的早期诊断提供了一种更加经济高效的解决方案。该研究为肺部疾病声音检测领域做出了贡献，特别是在解决个体差异和标注数据不足等挑战方面。

Abstract: Lung diseases, including lung cancer and COPD, are significant health
concerns globally. Traditional diagnostic methods can be costly,
time-consuming, and invasive. This study investigates the use of semi
supervised learning methods for lung sound signal detection using a model
combination of MFCC+CNN. By introducing semi supervised learning modules such
as Mix Match, Co-Refinement, and Co Refurbishing, we aim to enhance the
detection performance while reducing dependence on manual annotations. With the
add-on semi-supervised modules, the accuracy rate of the MFCC+CNN model is
92.9%, an increase of 3.8% to the baseline model. The research contributes to
the field of lung disease sound detection by addressing challenges such as
individual differences, feature insufficient labeled data.

</details>


### [25] [Technical report: Impact of Duration Prediction on Speaker-specific TTS for Indian Languages](https://arxiv.org/abs/2507.16875)
*Isha Pandey,Pranav Gaikwad,Amruta Parulekar,Ganesh Ramakrishnan*

Main category: eess.AS

TL;DR: 本文研究了在印度等低资源语言环境下，使用连续归一化流(CNF)模型进行语音生成时，不同持续时间预测策略对零样本说话人特定生成的影响


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如许多印度语言）由于数据有限和语言结构多样性，高质量语音生成仍然是一个重大挑战。持续时间预测是语音生成管道中的关键组件，在建模韵律和语音节奏方面发挥重要作用。虽然一些生成方法选择省略显式持续时间建模，但往往以更长的训练时间为代价

Method: 使用公开可用的印度语言数据训练基于连续归一化流(CNF)的非自回归语音模型，并评估多种持续时间预测策略用于零样本、说话人特定的生成。通过语音填充任务进行比较分析，评估不同预测器的表现

Result: 比较分析揭示了微妙的权衡：基于填充的预测器在某些语言中提高了可懂度，而说话人提示预测器在其他语言中更好地保持了说话人特征。研究发现了针对特定语言和任务定制持续时间策略的重要性

Conclusion: 这些发现为设计和选择针对特定语言和任务的持续时间策略提供了指导，强调了在将先进生成架构适应到低资源、多语言环境时，持续时间预测等可解释组件的持续价值

Abstract: High-quality speech generation for low-resource languages, such as many
Indian languages, remains a significant challenge due to limited data and
diverse linguistic structures. Duration prediction is a critical component in
many speech generation pipelines, playing a key role in modeling prosody and
speech rhythm. While some recent generative approaches choose to omit explicit
duration modeling, often at the cost of longer training times. We retain and
explore this module to better understand its impact in the linguistically rich
and data-scarce landscape of India. We train a non-autoregressive Continuous
Normalizing Flow (CNF) based speech model using publicly available Indian
language data and evaluate multiple duration prediction strategies for
zero-shot, speaker-specific generation. Our comparative analysis on
speech-infilling tasks reveals nuanced trade-offs: infilling based predictors
improve intelligibility in some languages, while speaker-prompted predictors
better preserve speaker characteristics in others. These findings inform the
design and selection of duration strategies tailored to specific languages and
tasks, underscoring the continued value of interpretable components like
duration prediction in adapting advanced generative architectures to
low-resource, multilingual settings.

</details>


### [26] [SLASH: Self-Supervised Speech Pitch Estimation Leveraging DSP-derived Absolute Pitch](https://arxiv.org/abs/2507.17208)
*Ryo Terashima,Yuma Shirahata,Masaya Kawamura*

Main category: eess.AS

TL;DR: 本文提出了SLASH方法，一种基于自监督学习的语音信号基频估计方法，通过结合数字信号处理(DSP)的绝对基频值和可微分频谱图优化，显著改进了传统SSL方法仅依赖相对基频差异的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于自监督学习的基频估计方法主要依赖于通过音调移位获得的相对基频差异，这种方法存在局限性。需要一种能够更好地利用绝对基频值并提高估计准确性的方法。

Method: 提出SLASH方法，通过两个关键创新来改进SSL基频估计：1）引入从数字信号处理(DSP)中获得的先验基频分布；2）使用目标频谱图与可微分DSP生成频谱图之间的损失函数，通过梯度下降优化绝对基频。同时采用新颖的频谱图生成方法跳过复杂的波形生成过程，并通过可微分DSP准确预测语音中的非周期性成分。

Result: 实验结果表明，所提出的方法在基频估计任务上优于基线DSP方法和基于SSL的基频估计方法，这归功于SSL和DSP的有效整合。该方法还能准确预测语音信号中的非周期性成分，增强了在语音信号处理中的适用性。

Conclusion: SLASH方法通过有效整合自监督学习和数字信号处理技术，成功解决了传统SSL方法的局限性，在语音基频估计任务中取得了显著的性能提升，为语音信号处理提供了更有效的解决方案。

Abstract: We present SLASH, a pitch estimation method of speech signals based on
self-supervised learning (SSL). To enhance the performance of conventional
SSL-based approaches that primarily depend on the relative pitch difference
derived from pitch shifting, our method incorporates absolute pitch values by
1) introducing a prior pitch distribution derived from digital signal
processing (DSP), and 2) optimizing absolute pitch through gradient descent
with a loss between the target and differentiable DSP-derived spectrograms. To
stabilize the optimization, a novel spectrogram generation method is used that
skips complicated waveform generation. In addition, the aperiodic components in
speech are accurately predicted through differentiable DSP, enhancing the
method's applicability to speech signal processing. Experimental results showed
that the proposed method outperformed both baseline DSP and SSL-based pitch
estimation methods, attributed to the effective integration of SSL and DSP.

</details>


### [27] [Clustering-based hard negative sampling for supervised contrastive speaker verification](https://arxiv.org/abs/2507.17540)
*Piotr Masztalski,Michał Romaniuk,Jakub Żak,Mateusz Matuszewski,Konrad Kowalczyk*

Main category: eess.AS

TL;DR: 该论文提出了CHNS（基于聚类的困难负样本采样）方法，用于监督对比说话人表示学习，通过聚类相似说话人的嵌入并调整批次组成来优化困难和简单负样本的比例，在VoxCeleb数据集上相比基线方法实现了18%的相对EER和minDCF改进。


<details>
  <summary>Details</summary>
Motivation: 传统的说话人验证主要使用基于分类的方法，而对比学习作为替代方案正在兴起。对比方法可以从有效使用困难负样本对中受益，这些是由于相似性而对验证模型特别具有挑战性的不同类别样本。现有方法在困难负样本采样方面还有改进空间。

Method: 提出CHNS（clustering-based hard negative sampling）方法，专门用于监督对比说话人表示学习。该方法对相似说话人的嵌入进行聚类，并调整批次组成以在对比损失计算期间获得困难和简单负样本的最优比例。

Result: 在VoxCeleb数据集上使用两种轻量级模型架构进行实验评估，CHNS方法相比基线监督对比方法（有无基于损失的困难负样本采样）以及最先进的基于分类的说话人验证方法，在相对EER和minDCF上实现了高达18%的改进。

Conclusion: CHNS方法通过基于聚类的困难负样本采样策略，有效提升了监督对比学习在说话人验证任务中的性能，证明了合理的困难负样本采样对于对比学习的重要性，为说话人验证领域提供了一种有效的新方法。

Abstract: In speaker verification, contrastive learning is gaining popularity as an
alternative to the traditionally used classification-based approaches.
Contrastive methods can benefit from an effective use of hard negative pairs,
which are different-class samples particularly challenging for a verification
model due to their similarity. In this paper, we propose CHNS - a
clustering-based hard negative sampling method, dedicated for supervised
contrastive speaker representation learning. Our approach clusters embeddings
of similar speakers, and adjusts batch composition to obtain an optimal ratio
of hard and easy negatives during contrastive loss calculation. Experimental
evaluation shows that CHNS outperforms a baseline supervised contrastive
approach with and without loss-based hard negative sampling, as well as a
state-of-the-art classification-based approach to speaker verification by as
much as 18 % relative EER and minDCF on the VoxCeleb dataset using two
lightweight model architectures.

</details>


### [28] [Accent Normalization Using Self-Supervised Discrete Tokens with Non-Parallel Data](https://arxiv.org/abs/2507.17735)
*Qibing Bai,Sho Inoue,Shuai Wang,Zhongjie Jiang,Yannan Wang,Haizhou Li*

Main category: eess.AS

TL;DR: 提出了一种基于自监督离散token的口音标准化方法，能够将外国口音语音转换为本地化语音，同时保持说话人身份特征


<details>
  <summary>Details</summary>
Motivation: 现有的口音标准化方法在自然度、口音减少和音色保持方面存在不足，需要一种更有效的方法来处理多种英语口音的标准化问题

Method: 采用自监督离散token和非并行训练数据的新颖流水线：从源语音中提取token，通过专用模型进行转换，使用flow matching技术合成输出语音

Result: 在多种英语口音上，该方法在自然度、口音减少程度和音色保持方面均优于基于帧到帧的基线方法。通过token级别的语音分析验证了基于token方法的有效性

Conclusion: 基于token的口音标准化方法具有优越性能，并开发了两种时长保持方法，适用于配音等应用场景

Abstract: Accent normalization converts foreign-accented speech into native-like speech
while preserving speaker identity. We propose a novel pipeline using
self-supervised discrete tokens and non-parallel training data. The system
extracts tokens from source speech, converts them through a dedicated model,
and synthesizes the output using flow matching. Our method demonstrates
superior performance over a frame-to-frame baseline in naturalness,
accentedness reduction, and timbre preservation across multiple English
accents. Through token-level phonetic analysis, we validate the effectiveness
of our token-based approach. We also develop two duration preservation methods,
suitable for applications such as dubbing.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [29] [Weak Supervision Techniques towards Enhanced ASR Models in Industry-level CRM Systems](https://arxiv.org/abs/2507.16843)
*Zhongsheng Wang,Sijie Wang,Jia Wang,Yung-I Liang,Yuxi Zhang,Jiamou Liu*

Main category: cs.SD

TL;DR: 本文提出了一种针对CRM系统的行业特定ASR模型微调方案，通过改进语音识别准确性来提升客户类型识别和个性化服务能力，在实际工业应用中取得了显著效果。


<details>
  <summary>Details</summary>
Motivation: 在CRM系统设计中，准确识别客户类型并提供个性化服务是提高客户满意度和忠诚度的关键，但通用预训练ASR模型难以有效处理行业特定的语音识别任务，存在客户语音和意图识别的挑战。

Method: 创新性地提出了行业特定ASR模型的微调解决方案，针对特定行业场景对通用ASR模型进行精细化调优，以提升其在行业应用中的性能表现。

Result: 实验结果表明，该方法大幅提升了微调后ASR模型在行业应用中的性能，显著改善了ASR模型在行业CRM系统中的关键辅助作用。

Conclusion: 所提出的行业特定ASR模型微调方案能够有效解决CRM系统中的语音识别挑战，提升客户服务质量，该方法已在实际工业应用中得到采用，验证了其实用性和有效性。

Abstract: In the design of customer relationship management (CRM) systems, accurately
identifying customer types and offering personalized services are key to
enhancing customer satisfaction and loyalty. However, this process faces the
challenge of discerning customer voices and intentions, and general pre-trained
automatic speech recognition (ASR) models make it difficult to effectively
address industry-specific speech recognition tasks. To address this issue, we
innovatively proposed a solution for fine-tuning industry-specific ASR models,
which significantly improved the performance of the fine-tuned ASR models in
industry applications. Experimental results show that our method substantially
improves the crucial auxiliary role of the ASR model in industry CRM systems,
and this approach has also been adopted in actual industrial applications.

</details>


### [30] [On Temporal Guidance and Iterative Refinement in Audio Source Separation](https://arxiv.org/abs/2507.17297)
*Tobias Morocutti,Jonathan Greif,Paul Primus,Florian Schmid,Gerhard Widmer*

Main category: cs.SD

TL;DR: 本文提出了一种新的空间语义声场分割方法，通过增强事件检测和声源分离阶段的协同作用，在音频标记和声源分离性能上取得显著提升，在DCASE Challenge 2025 Task 4中获得第二名。


<details>
  <summary>Details</summary>
Motivation: 传统的空间语义声场分割系统采用两阶段流水线（音频标记+标签条件声源分离），但缺乏有效分离所需的细粒度时间信息，限制了分离效果。

Method: 1) 微调预训练Transformer进行活跃声音类别检测；2) 使用该微调Transformer的另一个实例执行声音事件检测，为分离模块提供详细的时变指导；3) 实现迭代精化机制，通过递归重用分离器前一次迭代的输出来逐步提高分离质量。

Result: 在音频标记和声源分离性能上均取得显著改进，系统在DCASE Challenge 2025 Task 4竞赛中获得第二名的优异成绩。

Conclusion: 通过增强事件检测和声源分离阶段之间的协同作用，成功解决了传统方法缺乏细粒度时间信息的问题，显著提升了空间语义声场分割的整体性能。

Abstract: Spatial semantic segmentation of sound scenes (S5) involves the accurate
identification of active sound classes and the precise separation of their
sources from complex acoustic mixtures. Conventional systems rely on a
two-stage pipeline - audio tagging followed by label-conditioned source
separation - but are often constrained by the absence of fine-grained temporal
information critical for effective separation. In this work, we address this
limitation by introducing a novel approach for S5 that enhances the synergy
between the event detection and source separation stages. Our key contributions
are threefold. First, we fine-tune a pre-trained Transformer to detect active
sound classes. Second, we utilize a separate instance of this fine-tuned
Transformer to perform sound event detection (SED), providing the separation
module with detailed, time-varying guidance. Third, we implement an iterative
refinement mechanism that progressively enhances separation quality by
recursively reusing the separator's output from previous iterations. These
advancements lead to significant improvements in both audio tagging and source
separation performance, as demonstrated by our system's second-place finish in
Task 4 of the DCASE Challenge 2025. Our implementation and model checkpoints
are available in our GitHub repository: https://github.com/theMoro/dcase25task4 .

</details>


### [31] [Application of Whisper in Clinical Practice: the Post-Stroke Speech Assessment during a Naming Task](https://arxiv.org/abs/2507.17326)
*Milena Davudova,Ziyuan Cai,Valentina Giunchiglia,Dragos C. Gruia,Giulia Sanguedolce,Adam Hampshire,Fatemeh Geranmayeh*

Main category: cs.SD

TL;DR: 本研究评估了Whisper自动语音识别模型在中风患者语音转录和语言功能评估中的应用效果，发现经过微调后的模型在转录准确性和语音质量预测方面表现显著提升，但在跨域泛化能力方面仍存在局限性。


<details>
  <summary>Details</summary>
Motivation: 中风后语言障碍的详细评估是一项认知复杂且需要大量临床医师参与的任务，限制了及时和规模化的诊断。研究者希望通过自动语音识别基础模型来增强人工评估，但其在语音和语言障碍语境下的有效性尚不确定。

Method: 使用最先进的ASR基础模型Whisper对中风患者在图片命名任务中的语音进行转录和分析。评估了逐字转录准确性以及模型支持下游语言功能预测的能力。通过微调Whisper模型来改善性能，并在未见过的TORGO数据集上进行泛化能力评估。

Result: 基线Whisper模型在单词语音表达上表现较差。微调后显著提高了转录准确性（健康语音的词错误率降低87.72%，患者语音降低71.22%）。模型的学习表征能够准确预测语音质量（健康人群平均F1 Macro为0.74，患者为0.75）。但在未见数据集上的评估显示泛化能力有限。

Conclusion: 虽然在跨域泛化方面仍存在挑战，但研究结果突出了基础模型在适当微调后推进中风相关语音和语言障碍自动评估和康复方面的潜力。强调了需要针对特定临床人群调整模型的重要性。

Abstract: Detailed assessment of language impairment following stroke remains a
cognitively complex and clinician-intensive task, limiting timely and scalable
diagnosis. Automatic Speech Recognition (ASR) foundation models offer a
promising pathway to augment human evaluation through intelligent systems, but
their effectiveness in the context of speech and language impairment remains
uncertain. In this study, we evaluate whether Whisper, a state-of-the-art ASR
foundation model, can be applied to transcribe and analyze speech from patients
with stroke during a commonly used picture-naming task. We assess both verbatim
transcription accuracy and the model's ability to support downstream prediction
of language function, which has major implications for outcomes after stroke.
Our results show that the baseline Whisper model performs poorly on single-word
speech utterances. Nevertheless, fine-tuning Whisper significantly improves
transcription accuracy (reducing Word Error Rate by 87.72% in healthy speech
and 71.22% in speech from patients). Further, learned representations from the
model enable accurate prediction of speech quality (average F1 Macro of 0.74
for healthy, 0.75 for patients). However, evaluations on an unseen (TORGO)
dataset reveal limited generalizability, highlighting the inability of Whisper
to perform zero-shot transcription of single-word utterances on out-of-domain
clinical speech and emphasizing the need to adapt models to specific clinical
populations. While challenges remain in cross-domain generalization, these
findings highlight the potential of foundation models, when appropriately
fine-tuned, to advance automated speech and language assessment and
rehabilitation for stroke-related impairments.

</details>


### [32] [BoSS: Beyond-Semantic Speech](https://arxiv.org/abs/2507.17563)
*Qing Wang,Zehan Li,Hang Lv,Hongjie Chen,Yaodong Song,Jian Kang,Jie Lian,Jie Li,Yongxiang Li,Zhongjiang He,Xuelong Li*

Main category: cs.SD

TL;DR: 该论文提出了超语义语音(BoSS)概念和口语交互系统能力等级框架(L1-L5)，旨在捕获语音交流中超越显式语义的隐式信号和上下文线索，以推进更智能的人机语音交互技术。


<details>
  <summary>Details</summary>
Motivation: 现代语音技术如ASR和TTS往往无法捕获语音交流中超越显式语义的维度，包括隐式信号和上下文线索，这些因素在塑造语音含义方面起着关键作用，因此需要更好地表征和评估语音智能的发展。

Method: 提出了口语交互系统能力等级框架(L1-L5)来描述从基本命令识别到类人社交交互的演进过程；定义了超语义语音(BoSS)概念，涵盖情感线索、上下文动态和隐式语义等多维特征；基于认知相关性理论和机器学习模型建立了BoSS的形式化框架，用于分析时间和上下文语音动态。

Result: 通过五个不同维度评估BoSS相关属性，发现当前的口语语言模型(SLMs)难以完全解释超语义信号，揭示了现有技术在处理语音交流复杂性方面的局限性。

Conclusion: 研究结果突出了推进BoSS研究的必要性，以实现更丰富、更具上下文感知能力的人机交流，为未来语音技术发展指明了方向。

Abstract: Human communication involves more than explicit semantics, with implicit
signals and contextual cues playing a critical role in shaping meaning.
However, modern speech technologies, such as Automatic Speech Recognition (ASR)
and Text-to-Speech (TTS) often fail to capture these beyond-semantic
dimensions. To better characterize and benchmark the progression of speech
intelligence, we introduce Spoken Interaction System Capability Levels (L1-L5),
a hierarchical framework illustrated the evolution of spoken dialogue systems
from basic command recognition to human-like social interaction. To support
these advanced capabilities, we propose Beyond-Semantic Speech (BoSS), which
refers to the set of information in speech communication that encompasses but
transcends explicit semantics. It conveys emotions, contexts, and modifies or
extends meanings through multidimensional features such as affective cues,
contextual dynamics, and implicit semantics, thereby enhancing the
understanding of communicative intentions and scenarios. We present a
formalized framework for BoSS, leveraging cognitive relevance theories and
machine learning models to analyze temporal and contextual speech dynamics. We
evaluate BoSS-related attributes across five different dimensions, reveals that
current spoken language models (SLMs) are hard to fully interpret
beyond-semantic signals. These findings highlight the need for advancing BoSS
research to enable richer, more context-aware human-machine communication.

</details>


### [33] [Audio-Vision Contrastive Learning for Phonological Class Recognition](https://arxiv.org/abs/2507.17682)
*Daiqi Liu,Tomás Arias-Vergara,Jana Hutter,Andreas Maier,Paula Andrea Pérez-Toro*

Main category: cs.SD

TL;DR: 该研究提出了一个结合实时磁共振成像(rtMRI)和语音信号的多模态深度学习框架，用于分类发音-音韵特征，在USC-TIMIT数据集上使用对比学习方法达到了0.81的F1分数，比单模态基线提升了0.23。


<details>
  <summary>Details</summary>
Motivation: 准确分类发音-音韵特征对理解人类语音产生机制和开发鲁棒的语音技术至关重要，特别是在临床环境中，针对性的音位分析和治疗可以提高疾病诊断准确性和个性化康复效果。

Method: 提出了一个多模态深度学习框架，结合实时磁共振成像(rtMRI)和语音信号来分类三个关键的发音维度：发音方式、发音部位和浊音特征。采用了四种音频/视觉配置进行分类：单模态rtMRI、单模态音频信号、多模态中间融合和基于对比学习的音频-视觉融合。

Result: 在USC-TIMIT数据集上的实验结果显示，基于对比学习的方法达到了最先进的性能，平均F1分数为0.81，比单模态基线绝对提升了0.23。结果证实了对比表示学习在多模态发音分析中的有效性。

Conclusion: 对比学习方法能够有效地融合rtMRI和语音信号，显著提升发音-音韵特征分类的性能，为多模态发音分析提供了新的解决方案，并将代码和处理后的数据集公开以支持未来研究。

Abstract: Accurate classification of articulatory-phonological features plays a vital
role in understanding human speech production and developing robust speech
technologies, particularly in clinical contexts where targeted phonemic
analysis and therapy can improve disease diagnosis accuracy and personalized
rehabilitation. In this work, we propose a multimodal deep learning framework
that combines real-time magnetic resonance imaging (rtMRI) and speech signals
to classify three key articulatory dimensions: manner of articulation, place of
articulation, and voicing. We perform classification on 15 phonological classes
derived from the aforementioned articulatory dimensions and evaluate the system
with four audio/vision configurations: unimodal rtMRI, unimodal audio signals,
multimodal middle fusion, and contrastive learning-based audio-vision fusion.
Experimental results on the USC-TIMIT dataset show that our contrastive
learning-based approach achieves state-of-the-art performance, with an average
F1-score of 0.81, representing an absolute increase of 0.23 over the unimodal
baseline. The results confirm the effectiveness of contrastive representation
learning for multimodal articulatory analysis. Our code and processed dataset
will be made publicly available at
https://github.com/DaE-plz/AC_Contrastive_Phonology to support future research.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 9]
- [eess.AS](#eess.AS) [Total: 6]
- [cs.SD](#cs.SD) [Total: 5]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Time and Frequency Synchronization for Multiuser OTFS in Uplink](https://arxiv.org/abs/2507.17966)
*Mohsen Bayat,Sanoopkumar P. S.,Arman Farhang*

Main category: eess.SP

TL;DR: 本文提出了高移动性场景下上行多用户OTFS系统的时间和频率同步技术，重点解决定时偏移和载波频率偏移的估计与校正问题。


<details>
  <summary>Details</summary>
Motivation: 在高移动性场景中，准确估计和校正定时偏移（TOs）和载波频率偏移（CFOs）对多用户OTFS系统的性能至关重要。

Method: 提出两种TO估计技术：基于SU-PCP的TO估计和基于MU-PCP的TO估计，并引入CPF-BEM模型简化CFO估计的多维搜索问题。

Result: 提出的技术能够有效分离用户信号并准确估计TO和CFO，提高了信道估计的准确性。

Conclusion: 所提方法为高移动性场景下的多用户OTFS系统提供了高效的时间和频率同步解决方案。

Abstract: In this paper, we propose time and frequency synchronization techniques for
uplink multiuser OTFS (MU-OTFS) systems in high-mobility scenarios. This work
focuses on accurately estimating and correcting timing offsets (TOs) and
carrier frequency offsets (CFOs). Specifically, TO estimation is essential for
locating users' pilots on the delay-time plane, while CFO estimation enhances
channel estimation accuracy. First, we propose a TO estimation technique for an
existing multiuser pilot structure in MU-OTFS. We replace the impulse pilot
(IMP) in this pilot structure with a more practical pilot with a cyclic prefix
(PCP), referred to as single-user-inspired PCP (SU-PCP). This structure employs
different Zadoff-Chu (ZC) sequences, which enables pilot separation via
correlation at the receiver side. Consequently, we introduce a
correlation-based TO estimation technique for uplink MU-OTFS using this pilot
structure. Next, a spectrally efficient and practical pilot pattern is
proposed, where each user transmits a PCP within a shared pilot region on the
delay-Doppler plane, referred to as MU-PCP. At the receiver, the second TO
estimation technique utilizes a bank of filters to separate different users'
signals and accurately estimate their TOs. Then, we derive a mathematical
threshold range to enhance TO estimation accuracy by finding the first major
peak in the correlation function rather than relying solely on the highest
peak. After locating the received users' pilot signals using one of the
proposed TO estimation techniques, our proposed CFO estimation technique
reduces the multi-dimensional maximum likelihood (ML) search problem into
multiple one-dimensional search problems. In this technique, we apply the
Chebyshev polynomials of the first kind basis expansion model (CPF-BEM) to
effectively handle the time-variations of the channel in obtaining the CFO
estimates for all the users.

</details>


### [2] [Metasurface-based Fluid Antennas: from Electromagnetics to Communications Model](https://arxiv.org/abs/2507.17982)
*Pablo Ramírez-Espinosa,Cleofás Segura-Gómez,Ángel Palomares-Caballero,F. Javier López-Martínez,David Morales-Jiménez*

Main category: eess.SP

TL;DR: 本文提出了一种基于超表面的流体天线系统（FAS）的完整分析模型，解决了电子可重构天线在理论建模上的挑战。


<details>
  <summary>Details</summary>
Motivation: 电子可重构天线在流体天线系统中的实现面临理论建模困难，限制了系统设计的理论指导。

Method: 利用电路理论重新构建FAS的信号模型，并通过动态超表面天线（DMA）实现FAS概念。

Result: 模型与全波仿真结果吻合良好，且DMA实现的FAS性能接近理想化的位置灵活天线。

Conclusion: 提出的分析模型为FAS系统设计提供了理论支持，并验证了DMA实现FAS的可行性。

Abstract: Fluid antenna systems (FASs) have become a popular topic in the wireless
community as an effective yet simple means of exploiting spatial diversity. Due
to the limitations of physically moving radiating elements, electronically
reconfigurable antennas are emerging as practical implementations of FASs,
since changing the radiation pattern is functionally equivalent to physically
moving the device. However, electronically reconfigurable antennas pose a
challenge in terms of analytical modeling, often requiring full-wave
simulations or measurements for their characterization; this severely limits
the extraction of theoretical insights useful for system design. Motivated by
these difficulties and the growing interest in FASs, we propose in this paper a
complete analytical model for metasurface-based embodiments of FASs.
Specifically, we advocate for the implementation of the FAS concept through
dynamic metasurface antennas (DMAs), hitherto proposed as array replacements in
multiple-input multiple-output (MIMO) systems. We leverage circuit theory to
rewrite the conventional signal model of FASs in terms of admittance matrices
accounting for the electromagnetic effects inherent to metasurfaces. The model
is validated with full-wave simulations, showing good agreement. We further
illustrate how to apply the model for standard performance analysis, and
provide closed-form expressions for key metrics, including the resulting signal
covariance matrix. Results confirm that practical DMA-based FASs can achieve
similar performance to that of idealized implementations of position-flexible
antennas.

</details>


### [3] [Multiple Active STAR-RIS-Assisted Secure Integrated Sensing and Communication via Cooperative Beamforming](https://arxiv.org/abs/2507.18035)
*Hyeonho Noh,Hyeonsu Lyu,Hyun Jong Yang*

Main category: eess.SP

TL;DR: 本文研究了由多个主动同时传输和反射可重构智能表面（STAR-RIS）支持的集成感知与通信（ISAC）网络，通过联合优化基站波束成形和STAR-RIS系数，最大化通信总速率，同时满足感知和安全性约束。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用STAR-RIS提升ISAC网络的性能，同时满足感知、安全和功率约束。

Method: 采用交替优化（AO）框架，将问题分解为子问题，分别通过KKT条件和SCA方法优化基站波束成形和STAR-RIS系数。

Result: 仿真表明，所提算法在通信总速率上显著优于被动RIS和单STAR-RIS基线，同时满足感知和安全约束。

Conclusion: 主动STAR-RIS在ISAC网络中具有显著优势，能够有效提升性能并满足多约束条件。

Abstract: This paper explores an integrated sensing and communication (ISAC) network
empowered by multiple active simultaneously transmitting and reflecting
reconfigurable intelligent surfaces (STAR-RISs). A base station (BS) furnishes
downlink communication to multiple users while concurrently interrogating a
sensing target. We jointly optimize the BS transmit beamformer and the
reflection/transmission coefficients of every active STAR-RIS in order to
maximize the aggregate communication sum-rate, subject to (i) a stringent
sensing signal-to-interference-plus-noise ratio (SINR) requirement, (ii) an
upper bound on the leakage of confidential information, and (iii) individual
hardware and total power constraints at both the BS and the STAR-RISs. The
resulting highly non-convex program is tackled with an efficient alternating
optimization (AO) framework. First, the original formulation is reformulated
into an equivalent yet more tractable representation and partitioned into
subproblems. The BS beamformer is updated in closed form via the
Karush-Kuhn-Tucker (KKT) conditions, whereas the STAR-RIS reflection and
transmission vectors are refined through successive convex approximation (SCA),
yielding a semidefinite program that is then solved via semidefinite
relaxation. Comprehensive simulations demonstrate that the proposed algorithm
delivers substantial sum-rate gains over passive-RIS and single STAR-RIS
baselines, all the while rigorously meeting the prescribed sensing and security
constraints.

</details>


### [4] [Geometrical portrait of Multipath error propagation in GNSS Direct Position Estimation](https://arxiv.org/abs/2507.18096)
*Jihong Huang,Rong Yang,Wei Gao,Xingqun Zhan,Zheng Yao*

Main category: eess.SP

TL;DR: 本文通过几何分析扩展了直接位置估计（DPE）的理论框架，提出了一种卫星圆形多径偏差（SCMB）模型，量化了多径和热噪声对CAF和PVT解的影响，并通过仿真和测试验证了其正确性。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对DPE理论中多径误差的理论表征，本文旨在填补这一空白。

Method: 通过几何分析量化多径误差对CAF和PVT解的影响，提出SCMB模型，并通过蒙特卡洛模拟和城市峡谷测试验证。

Result: 研究发现最大PVT偏差取决于各卫星通道中的最大多径误差，且PVT偏差随卫星仰角增加而增大。

Conclusion: 研究结果为从几何角度选择DPE卫星提供了参考，强调了高低仰角卫星组合的重要性。

Abstract: Direct Position Estimation (DPE) is a method that directly estimate position,
velocity, and time (PVT) information from cross ambiguity function (CAF) of the
GNSS signals, significantly enhancing receiver robustness in urban
environments. However, there is still a lack of theoretical characterization on
multipath errors in the context of DPE theory. Geometric observations highlight
the unique characteristics of DPE errors stemming from multipath and thermal
noise as estimation bias and variance respectively. Expanding upon the
theoretical framework of DPE noise variance through geometric analysis, this
paper focuses on a geometric representation of multipath errors by quantifying
the deviations in CAF and PVT solutions caused by off-centering bias relative
to the azimuth and elevation angles. A satellite circular multipath bias (SCMB)
model is introduced, amalgamating CAF and PVT errors from multiple satellite
channels. The boundaries for maximum or minimum PVT bias are established
through discussions encompassing various multipath conditions. The correctness
of the multipath geometrical portrait is confirmed through both Monte Carlo
simulations and urban canyon tests. The findings indicate that the maximum PVT
bias depends on the largest multipath errors observed across various satellite
channels. Additionally, the PVT bias increases with satellite elevation angles,
influenced by the CAF multipath bias projection. This serves as a reference for
selecting DPE satellites from a geometric standpoint, underscoring the
importance of choosing a balanced combination of high and low elevation angles
to achieve an optimal satellite geometry configuration.

</details>


### [5] [Envelope Control Enabled Probabilistic Shaping for Peak Power Constrained IM DD Systems](https://arxiv.org/abs/2507.18149)
*Dongdong Zou,Wei Wang,Jiawen Yao,Zhongxing Tian,Zeyu Feng,Huan Huang,Fan Li,Gordon Ning Liu,Gangxiang Shen,Yi Cai*

Main category: eess.SP

TL;DR: 提出了一种针对峰值功率受限IM-DD系统的间接概率整形方案，通过动态选择性映射和Turbo均衡器改善记忆效应，实验显示接收灵敏度提升1dB。


<details>
  <summary>Details</summary>
Motivation: IM-DD系统中概率整形的有效应用仍存在挑战，尤其是在有记忆效应的系统中。

Method: 采用动态选择性映射（DSLM）和修改的M-BCJR算法Turbo均衡器。

Result: 在56GBaud PAM8系统中，接收灵敏度提升1dB。

Conclusion: 该方案为有记忆效应的IM-DD系统提供了新的概率整形应用视角。

Abstract: Probabilistic shaping (PS) has attracted significant attention in
intensity-modulation and direct-detection (IM-DD) systems. However, due to the
unique system model and inherent constraints, the effective application of the
PS technique is still an open question in IM-DD systems, particularly in
systems with memory effects. In this paper, a novel indirect PS scheme tailored
for peak power constrained (PPC) IM-DD systems is proposed. The key idea lies
in strategically controlling the signal envelope to mitigate memory-induced
impairments, such as nonlinearity, overshoot, peak-to-average power ratio
enhancement, etc. The proposed scheme incorporates a dynamic selective mapping
(DSLM) mechanism at the transmitter, enabling an untypical bit-to-symbol
mapping in which the current symbol is not only determined by the current bits
pattern but also by previously generated symbols within a specified memory
length. At the receiver side, a turbo equalizer with a modified M-BCJR
algorithm is proposed to achieve the recovery of ambiguous bits induced by
DSLM. Experimental verification in a 56GBaud PAM8 system demonstrates that the
proposed scheme exhibits 1dB receiver sensitivity improvement over 2km
single-mode fiber transmission. In addition, the proposed scheme has also been
demonstrated to be compatible with the typical probabilistic amplitude shaping
architecture, enabling a simple and fine-granularity rate adaptation
capability. To the best of our knowledge, this work opens a new sight for the
application of the PS technique in PPC IM-DD systems with memory effects.

</details>


### [6] [GNSS Jammer and Spoofer Mitigation via Multi-Antenna Processing](https://arxiv.org/abs/2507.18166)
*Jonas Elmiger,Gian Marti,Christoph Studer*

Main category: eess.SP

TL;DR: SCHIEBER是一种多天线GNSS接收器方法，无需先验知识即可抑制干扰和欺骗攻击。


<details>
  <summary>Details</summary>
Motivation: GNSS信号易受干扰和欺骗攻击，现有方法需要先验知识或无法同时应对两种攻击。

Method: 采用自适应空间滤波技术抑制干扰，通过方向到达和伪距估计一致性检测识别欺骗信号。

Result: 通过GPS L1 C/A系统仿真验证了方法的有效性。

Conclusion: SCHIEBER能有效应对GNSS的干扰和欺骗攻击，无需先验信息。

Abstract: Modern positioning relies on radio signals from global navigation satellite
systems (GNSS). Their low receive power renders these radio signals susceptible
to jamming attacks, in which malicious transmitters emit strong interference to
disrupt signal acquisition. Moreover, GNSS are vulnerable to spoofing attacks,
in which malicious transmitters mimic legitimate satellites by transmitting
spurious GNSS signals. We propose SCHIEBER, a novel method for multi-antenna
GNSS receivers that mitigates jammers as well as spoofers without requiring any
prior knowledge of the receiver position or attack type: Jammers are mitigated
during signal acquisition using a recently developed adaptive spatial filtering
technique. Spoofers are identified and rejected after signal acquisition using
a novel approach that tests the consistency of acquired signals by comparing
their respective direction of arrival (DoA) and pseudorange estimates in a test
that is invariant with respect to the unknown receiver position. We demonstrate
the efficacy of our method using extensive simulations of a GPS L1 C/A system
under spoofing and jamming attacks.

</details>


### [7] [ICWLM: A Multi-Task Wireless Large Model via In-Context Learning](https://arxiv.org/abs/2507.18167)
*Yuxuan Wen,Xiaoming Chen,Maojun Zhang,Zhaoyang Zhang*

Main category: eess.SP

TL;DR: 论文提出了一种新型的无线原生基础模型ICWLM，用于物理层的多任务学习，解决了传统深度学习方法在数据稀缺和泛化能力上的不足。


<details>
  <summary>Details</summary>
Motivation: 无线通信技术的快速发展（如mMIMO和mmWave）带来了网络复杂性和计算需求的增加，传统深度学习方法在物理层性能提升上存在任务特定性和泛化能力不足的问题。

Method: 提出了ICWLM模型，直接在大规模混合无线数据集上训练，利用上下文学习（ICL）适应不同系统配置和信道条件，并采用动态权重平均（DWA）算法平衡多任务训练。

Result: ICWLM在多项物理层任务中表现优异，具有出色的泛化能力，能够适应未见过的系统配置。

Conclusion: ICWLM为未来无线网络提供了统一且自适应的AI模型范式，有望降低部署复杂性并提升智能资源管理能力。

Abstract: The rapid evolution of wireless communication technologies, particularly
massive multiple-input multiple-output (mMIMO) and millimeter-wave (mmWave),
introduces significant network complexity and computational demands.
Significant research efforts have been made to improve physical layer
performance by resorting to deep learning (DL) methods, which, however, are
usually task-specific and struggle with data scarcity and generalization. To
address these challenges, we propose a novel In-Context Wireless Large Model
(ICWLM), a wireless-native foundation model designed for simultaneous
multi-task learning at the physical layer. Unlike conventional methods that
adapt wireless data to pre-trained large language models (LLMs), ICWLM is
trained directly on large-scale, mixed wireless datasets from scratch. It
jointly solves multiple classical physical layer problems, including multi-user
precoding (sum-rate maximization and max-min SINR) and channel prediction. A
key innovation of ICWLM is its utilization of in-context learning (ICL),
enabling the model to adapt to varying system configurations and channel
conditions with minimal demonstration pairs, eliminating the need for extensive
retraining. Furthermore, we employ the Dynamic Weight Averaging (DWA) algorithm
to dynamically balance the individual task losses during multi-task training,
ensuring efficient and stable learning across diverse objectives. Extensive
simulation results demonstrate that ICWLM achieves competitive performance
compared to task-specific methods while exhibiting remarkable generalization
capabilities to unseen system configurations. This work offers a promising
paradigm for developing unified and adaptive AI models for future wireless
networks, potentially reducing deployment complexity and enhancing intelligent
resource management.

</details>


### [8] [Quantized Signal Recovery with Interference via Parametrized Look-Up Tables](https://arxiv.org/abs/2507.18370)
*Morriel Kasher,Michael Tinston,Predrag Spasojevic*

Main category: eess.SP

TL;DR: 论文提出了一种通过参数化查找表（LUT）优化低分辨率模数转换器（ADC）后校正的方法，并评估了三种分析估计器，特别适用于低分辨率、非线性或宽带量化器。


<details>
  <summary>Details</summary>
Motivation: 低分辨率ADC在信号处理中存在性能限制，需通过后校正技术提高精度。参数化LUT结合信号模型可优化性能。

Method: 提出三种分析估计器，并针对相位键控输入信号和线性调频干扰信号提出近似方法以提高估计问题的可解性。

Result: 仿真结果表明，该方法能高精度实时恢复输入信号瞬时值，显著优于传统线性滤波技术，且在非线性量化和时变干扰下表现稳健。

Conclusion: 参数化LUT结合分析估计器能显著提升低分辨率ADC性能，适用于复杂信号环境。

Abstract: Efficient all-digital post-correction of low-resolution analog-to-digital
converters can be achieved by using Look-Up Tables (LUTs). The performance of a
LUT can be optimized by incorporating a parametric model for the expected input
signal, noise level, and interference signals. We evaluate three analytical
estimators for integration with parametrized LUTs, especially with applications
to low-resolution, non-linear, or wideband quantizers. We also propose several
approximations to improve tractability of the estimation problem for
Phase-Shift Keyed input signals and Linear Frequency Modulated interference
signals. Simulated results validate the ability of our estimator to recover the
instantaneous value of the desired input signal in real-time with a high degree
of accuracy. This includes cancellation of harmonic distortion that aliases
into the desired signal bandwidth from front-end saturation due to high-power
out-of-band interference. Our estimators are shown to achieve a significant
gain over conventional linear-filtering techniques while also being robust to
changes in input parameters, non-linear quantizers, and time-variant
interference sources. For a tone input quantized to 3 bits and estimated with a
fixed 12-tap model order we achieve $>$10 dB improvement in Mean Square Error
and $>$20 dBc improvement in Spurious-Free Dynamic Range.

</details>


### [9] [A Foundation Model for Massive MIMO Precoding with an Adaptive per-User Rate-Power Tradeoff](https://arxiv.org/abs/2507.18587)
*Jérôme Emery,Ali Hasanzadeh Karkan,Jean-François Frigon,François Leduc-Primeau*

Main category: eess.SP

TL;DR: 提出了一种基于Transformer的基础模型，用于mMIMO预编码，旨在降低发射机能耗并动态适应用户速率需求，同时通过数据增强解决数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 解决大规模MIMO系统中预编码的高能耗和数据收集困难问题。

Method: 使用Transformer基础模型，结合数据增强方法（基于预训练特征提取器的余弦相似度）来适应数据稀缺环境。

Result: 在相同能耗下，零样本部署显著优于零强迫方法，接近加权最小均方误差性能且复杂度降低8倍。

Conclusion: 该工作通过解决数据可用性和训练复杂度问题，推动了深度学习在实际中的应用，并为资源分配和调度算法提供了更高效的控制手段。

Abstract: Deep learning (DL) has emerged as a solution for precoding in massive
multiple-input multiple-output (mMIMO) systems due to its capacity to learn the
characteristics of the propagation environment. However, training such a model
requires high-quality, local datasets at the deployment site, which are often
difficult to collect. We propose a transformer-based foundation model for mMIMO
precoding that seeks to minimize the energy consumption of the transmitter
while dynamically adapting to per-user rate requirements. At equal energy
consumption, zero-shot deployment of the proposed foundation model
significantly outperforms zero forcing, and approaches weighted minimum mean
squared error performance with 8x less complexity. To address model adaptation
in data-scarce settings, we introduce a data augmentation method that finds
training samples similar to the target distribution by computing the cosine
similarity between the outputs of the pre-trained feature extractor. Our work
enables the implementation of DL-based solutions in practice by addressing
challenges of data availability and training complexity. Moreover, the ability
to dynamically configure per-user rate requirements can be leveraged by higher
level resource allocation and scheduling algorithms for greater control over
energy efficiency, spectral efficiency and fairness.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [10] [ASR-Guided Speaker-Role Diarization and Diarization-Guided ASR Decoding](https://arxiv.org/abs/2507.17765)
*Arindam Ghosh,Mark Fuhs,Bongjun Kim,Anurag Chowdhury,Monika Woszczyna*

Main category: eess.AS

TL;DR: 本文提出了一种扩展端到端模型的方法，用于说话者角色分离（RD），通过简化训练、分离任务特定预测器以及利用RD后验活动改进ASR解码。


<details>
  <summary>Details</summary>
Motivation: 传统的说话者分离（SD）仅提供通用标签，而角色分离（RD）在实际应用中更有用。本文旨在将端到端ASR+SD框架扩展到RD。

Method: 1. 使用强制对齐和交叉熵损失简化训练；2. 为单词预测和角色预测设计独立的任务特定预测器；3. 利用RD后验活动优化ASR解码。

Result: 提出的方法在角色分离任务中表现更优，并减少了ASR解码中的小词删除错误。

Conclusion: 通过任务特定预测器和后验活动优化，端到端模型在RD任务中取得了更好的效果。

Abstract: From an application standpoint, speaker-role diarization (RD), such as doctor
vs. patient, host vs. guest, etc. is often more useful than traditional speaker
diarization (SD), which assigns generic labels like speaker-1, speaker-2 etc.
In the context of joint automatic speech recognition (ASR) + SD (who spoke
what?), recent end-to-end models employ an auxiliary SD transducer,
synchronized with the ASR transducer, to predict speakers per word. In this
paper, we extend this framework to RD with three key contributions: (1) we
simplify the training via forced alignment and cross-entropy loss instead of
RNNT loss, (2) we show that word prediction and role prediction require
different amounts of predictor's context, leading to separate task-specific
predictors, unlike existing shared-predictor models, and (3) we propose a way
to leverage RD posterior activity to influence ASR decoding and reduce
small-word deletion errors.

</details>


### [11] [A Concept-based approach to Voice Disorder Detection](https://arxiv.org/abs/2507.17799)
*Davide Ghia,Gabriele Ciravegna,Alkis Koudounas,Marco Fantini,Erika Crosetti,Giovanni Succo,Tania Cerquitelli*

Main category: eess.AS

TL;DR: 论文探讨了基于可解释AI（XAI）的概念模型（如CBM和CEM）在语音障碍诊断中的应用，旨在提高模型透明度和临床可信度。


<details>
  <summary>Details</summary>
Motivation: 语音障碍影响广泛人群，自动化非侵入性诊断技术可显著改善医疗水平，但现有DNN模型因复杂性缺乏透明度，限制了临床信任。

Method: 研究采用概念瓶颈模型（CBM）和概念嵌入模型（CEM）等可解释AI方法，对比传统深度学习模型。

Result: 概念模型在性能上与传统方法相当，同时提供了更透明和可解释的决策框架。

Conclusion: 可解释AI模型在语音障碍诊断中具有潜力，既能保持高性能，又能增强临床信任。

Abstract: Voice disorders affect a significant portion of the population, and the
ability to diagnose them using automated, non-invasive techniques would
represent a substantial advancement in healthcare, improving the quality of
life of patients. Recent studies have demonstrated that artificial intelligence
models, particularly Deep Neural Networks (DNNs), can effectively address this
task. However, due to their complexity, the decision-making process of such
models often remain opaque, limiting their trustworthiness in clinical
contexts. This paper investigates an alternative approach based on Explainable
AI (XAI), a field that aims to improve the interpretability of DNNs by
providing different forms of explanations. Specifically, this works focuses on
concept-based models such as Concept Bottleneck Model (CBM) and Concept
Embedding Model (CEM) and how they can achieve performance comparable to
traditional deep learning methods, while offering a more transparent and
interpretable decision framework.

</details>


### [12] [Recent Trends in Distant Conversational Speech Recognition: A Review of CHiME-7 and 8 DASR Challenges](https://arxiv.org/abs/2507.18161)
*Samuele Cornell,Christoph Boeddeker,Taejin Park,He Huang,Desh Raj,Matthew Wiesner,Yoshiki Masuyama,Xuankai Chang,Zhong-Qiu Wang,Stefano Squartini,Paola Garcia,Shinji Watanabe*

Main category: eess.AS

TL;DR: CHiME-7和8挑战赛聚焦多通道、可泛化的联合自动语音识别（ASR）和对话语音的说话人日志。论文分析了挑战赛设计、评估指标、数据集和基线系统，总结了参与者提交的关键趋势。


<details>
  <summary>Details</summary>
Motivation: 推动多通道语音识别和说话人日志技术的发展，解决复杂场景下的语音处理问题。

Method: 通过挑战赛形式，收集并分析32个系统，比较端到端ASR与混合系统的表现，评估神经语音分离和增强技术的效果。

Result: 1）端到端ASR系统成为主流；2）神经语音分离技术仍需改进；3）说话人日志细化是关键；4）下游任务评估与转录质量相关性弱；5）复杂环境下的语音转录仍具挑战性。

Conclusion: 尽管技术进步，复杂场景下的语音处理仍面临挑战，端到端ASR和说话人日志细化是未来研究方向。

Abstract: The CHiME-7 and 8 distant speech recognition (DASR) challenges focus on
multi-channel, generalizable, joint automatic speech recognition (ASR) and
diarization of conversational speech. With participation from 9 teams
submitting 32 diverse systems, these challenges have contributed to
state-of-the-art research in the field. This paper outlines the challenges'
design, evaluation metrics, datasets, and baseline systems while analyzing key
trends from participant submissions. From this analysis it emerges that: 1)
Most participants use end-to-end (e2e) ASR systems, whereas hybrid systems were
prevalent in previous CHiME challenges. This transition is mainly due to the
availability of robust large-scale pre-trained models, which lowers the data
burden for e2e-ASR. 2) Despite recent advances in neural speech separation and
enhancement (SSE), all teams still heavily rely on guided source separation,
suggesting that current neural SSE techniques are still unable to reliably deal
with complex scenarios and different recording setups. 3) All best systems
employ diarization refinement via target-speaker diarization techniques.
Accurate speaker counting in the first diarization pass is thus crucial to
avoid compounding errors and CHiME-8 DASR participants especially focused on
this part. 4) Downstream evaluation via meeting summarization can correlate
weakly with transcription quality due to the remarkable effectiveness of
large-language models in handling errors. On the NOTSOFAR-1 scenario, even
systems with over 50\% time-constrained minimum permutation WER can perform
roughly on par with the most effective ones (around 11\%). 5) Despite recent
progress, accurately transcribing spontaneous speech in challenging acoustic
environments remains difficult, even when using computationally intensive
system ensembles.

</details>


### [13] [SpecASR: Accelerating LLM-based Automatic Speech Recognition via Speculative Decoding](https://arxiv.org/abs/2507.18181)
*Linye Wei,Shuzhang Zhong,Songqiang Xu,Runsheng Wang,Ru Huang,Meng Li*

Main category: eess.AS

TL;DR: 提出了一种专为ASR设计的推测解码框架SpecASR，显著降低了实时ASR的延迟。


<details>
  <summary>Details</summary>
Motivation: LLM-based ASR的高解码延迟无法满足实时需求，现有推测解码方法未充分考虑ASR任务特性。

Method: 基于ASR解码的音频条件特性，提出自适应草稿序列生成、草稿序列复用策略和两阶段稀疏令牌树生成算法。

Result: SpecASR在保持识别精度的同时，比基线自回归解码和推测解码分别提速3.04x-3.79x和1.25x-1.84x。

Conclusion: SpecASR通过优化解码过程，显著提升了实时ASR的效率。

Abstract: Large language model (LLM)-based automatic speech recognition (ASR) has
recently attracted a lot of attention due to its high recognition accuracy and
enhanced multi-dialect support. However, the high decoding latency of LLMs
challenges the real-time ASR requirements. Although speculative decoding has
been explored for better decoding efficiency, they usually ignore the key
characteristics of the ASR task and achieve limited speedup. To further reduce
the real-time ASR latency, in this paper, we propose a novel speculative
decoding framework specialized for ASR, dubbed SpecASR. SpecASR is developed
based on our core observation that ASR decoding is audio-conditioned, which
results in high output alignment between small and large ASR models, even given
output mismatches in intermediate decoding steps. Therefore, SpecASR features
an adaptive draft sequence generation process that dynamically modifies the
draft sequence length to maximize the token acceptance length. SpecASR further
proposes a draft sequence recycling strategy that reuses the previously
generated draft sequence to reduce the draft ASR model latency. Moreover, a
two-pass sparse token tree generation algorithm is also proposed to balance the
latency of draft and target ASR models. With extensive experimental results, we
demonstrate SpecASR achieves 3.04x-3.79x and 1.25x-1.84x speedup over the
baseline autoregressive decoding and speculative decoding, respectively,
without any loss in recognition accuracy.

</details>


### [14] [Speech Enhancement with Dual-path Multi-Channel Linear Prediction Filter and Multi-norm Beamforming](https://arxiv.org/abs/2507.18350)
*Chengyuan Qin,Wenmeng Xiong,Jing Zhou,Maoshen Jia,Changchun Bao*

Main category: eess.AS

TL;DR: 提出了一种基于双路径多通道线性预测（MCLP）滤波器和多范数波束形成的语音增强方法。


<details>
  <summary>Details</summary>
Motivation: 解决高混响场景下语音增强的问题。

Method: 使用双路径MCLP滤波器和多范数波束形成，优化预测阶数选择。

Result: 在语音增强任务中表现优于基线方法，尤其在高混响环境下。

Conclusion: 该方法在高混响场景下具有显著优势，且预测阶数选择方法具有通用性。

Abstract: In this paper, we propose a speech enhancement method us ing dual-path
Multi-Channel Linear Prediction (MCLP) filters
  and multi-norm beamforming. Specifically, the MCLP part in
  the proposed method is designed with dual-path filters in both
  time and frequency dimensions. For the beamforming part, we
  minimize the power of the microphone array output as well as
  the l1 norm of the denoised signals while preserving source sig nals from the
target directions. An efficient method to select the
  prediction orders in the dual-path filters is also proposed, which
  is robust for signals with different reverberation time (T60) val ues and can
be applied to other MCLP-based methods. Eval uations demonstrate that our
proposed method outperforms the
  baseline methods for speech enhancement, particularly in high
  reverberation scenarios.

</details>


### [15] [Streaming Sortformer: Speaker Cache-Based Online Speaker Diarization with Arrival-Time Ordering](https://arxiv.org/abs/2507.18446)
*Ivan Medennikov,Taejin Park,Weiqing Wang,He Huang,Kunal Dhawan,Jinhan Wang,Jagadeesh Balam,Boris Ginsburg*

Main category: eess.AS

TL;DR: Streaming Sortformer通过动态更新的AOSC缓存实现实时多说话人跟踪，效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决传统说话人跟踪方法在实时性和低延迟场景下的不足。

Method: 采用Arrival-Order Speaker Cache（AOSC）动态存储和更新说话人嵌入，按到达时间排序。

Result: 在基准数据集上验证了方法的有效性和灵活性，适用于低延迟场景。

Conclusion: Streaming Sortformer为实时多说话人跟踪提供了可靠解决方案。

Abstract: This paper presents a streaming extension for the Sortformer speaker
diarization framework, whose key property is the arrival-time ordering of
output speakers. The proposed approach employs an Arrival-Order Speaker Cache
(AOSC) to store frame-level acoustic embeddings of previously observed
speakers. Unlike conventional speaker-tracing buffers, AOSC orders embeddings
by speaker index corresponding to their arrival time order, and is dynamically
updated by selecting frames with the highest scores based on the model's past
predictions. Notably, the number of stored embeddings per speaker is determined
dynamically by the update mechanism, ensuring efficient cache utilization and
precise speaker tracking. Experiments on benchmark datasets confirm the
effectiveness and flexibility of our approach, even in low-latency setups.
These results establish Streaming Sortformer as a robust solution for real-time
multi-speaker tracking and a foundation for streaming multi-talker speech
processing.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [16] [Speaker Disentanglement of Speech Pre-trained Model Based on Interpretability](https://arxiv.org/abs/2507.17851)
*Xiaoxu Zhu,Junhua Li*

Main category: cs.SD

TL;DR: 论文提出了一种基于可解释性的语音预训练模型说话人解耦方法，通过量化音色残留和改进解耦技术，显著优化了内容保留和音色分离效果。


<details>
  <summary>Details</summary>
Motivation: 语音预训练模型中音色与内容信息耦合紧密，现有方法缺乏直接量化音色残留的指标，且依赖间接评估。

Method: 提出InterpTRQE-SptME基准和InterpTF-SptME方法，利用SHAP技术量化音色残留并过滤音色信息。

Result: 实验显示SHAP Noise方法可将音色残留从18.05%降至接近0%，同时保持内容完整性。

Conclusion: 该方法显著优化了说话人解耦效果，提升了内容相关任务性能并防止音色隐私泄露。

Abstract: Speech pretrained models contain task-specific information across different
layers, but decoupling content and timbre information remains challenging as
removing speaker-specific information often causes content loss. Current
research lacks direct metrics to quantify timbre residual in model encodings,
relying on indirect evaluation through downstream tasks. This paper addresses
these challenges through interpretability-based speaker disentanglement in
speech pretraining models. We quantitatively evaluate timbre residual in model
embeddings and improve speaker disentanglement using interpretive
representations. Our contributions include: (1) InterpTRQE-SptME Benchmark - a
timbre residual recognition framework using interpretability. The benchmark
concatenates content embeddings with timbre embeddings for speaker
classification, then applies Gradient SHAP Explainer to quantify timbre
residual. We evaluate seven speech pretraining model variations. (2)
InterpTF-SptME method - an interpretability-based timbre filtering approach
using SHAP Noise and SHAP Cropping techniques. This model-agnostic method
transforms intermediate encodings to remove timbre while preserving content.
Experiments on VCTK dataset with HuBERT LARGE demonstrate successful content
preservation and significant speaker disentanglement optimization. Results show
the SHAP Noise method can reduce timbre residual from 18.05% to near 0% while
maintaining content integrity, contributing to enhanced performance in
content-related speech processing tasks and preventing timbre privacy leakage.

</details>


### [17] [Bob's Confetti: Phonetic Memorization Attacks in Music and Video Generation](https://arxiv.org/abs/2507.17937)
*Jaechul Roh,Zachary Novack,Yuefeng Peng,Niloofar Mireshghallah,Taylor Berg-Kirkpatrick,Amir Houmansadr*

Main category: cs.SD

TL;DR: 论文研究了歌词到歌曲生成模型（LS2）对训练数据记忆的脆弱性，提出了一种名为APT的攻击方法，通过同音替换改变歌词语义但保留声学结构，揭示了模型对训练内容的子词汇记忆现象。


<details>
  <summary>Details</summary>
Motivation: 探索歌词到歌曲生成模型在训练数据记忆方面的脆弱性，以及这种记忆对多模态生成系统的影响。

Method: 采用Adversarial PhoneTic Prompting（APT）攻击方法，通过同音替换修改歌词，测试模型对训练内容的记忆能力。

Result: 发现模型（如SUNO和YuE）能生成与训练内容高度相似的输出，甚至在文本到视频模型中触发视觉记忆。

Conclusion: 揭示了转录条件多模态生成系统中的关键漏洞，提出了关于版权、安全和内容来源的紧迫问题。

Abstract: Lyrics-to-Song (LS2) generation models promise end-to-end music synthesis
from text, yet their vulnerability to training data memorization remains
underexplored. We introduce Adversarial PhoneTic Prompting (APT), a novel
attack where lyrics are semantically altered while preserving their acoustic
structure through homophonic substitutions (e.g., Eminem's famous "mom's
spaghetti" $\rightarrow$ "Bob's confetti"). Despite these distortions, we
uncover a powerful form of sub-lexical memorization: models like SUNO and YuE
regenerate outputs strikingly similar to known training content, achieving high
similarity across audio-domain metrics, including CLAP, AudioJudge, and
CoverID. This vulnerability persists across multiple languages and genres. More
surprisingly, we discover that phoneme-altered lyrics alone can trigger visual
memorization in text-to-video models. When prompted with phonetically modified
lyrics from Lose Yourself, Veo 3 reconstructs visual elements from the original
music video -- including character appearance and scene composition -- despite
no visual cues in the prompt. We term this phenomenon phonetic-to-visual
regurgitation. Together, these findings expose a critical vulnerability in
transcript-conditioned multimodal generation: phonetic prompting alone can
unlock memorized audiovisual content, raising urgent questions about copyright,
safety, and content provenance in modern generative systems. Example
generations are available on our demo page (jrohsc.github.io/music_attack/).

</details>


### [18] [Resnet-conformer network with shared weights and attention mechanism for sound event localization, detection, and distance estimation](https://arxiv.org/abs/2507.17941)
*Quoc Thinh Vo,David Han*

Main category: cs.SD

TL;DR: 报告介绍了DCASE 2024任务3A的音频事件定位与检测（SELD）方法，使用音频输入（Track A），基于EINV2网络架构，通过数据增强和特征提取，在测试集上取得了显著结果。


<details>
  <summary>Details</summary>
Motivation: SELD在机器认知任务（如环境推断、导航等）中具有重要价值，DCASE 2024挑战赛新增了距离估计任务，需全面评估模型性能。

Method: 采用log-mel频谱和强度向量作为输入，结合多种数据增强技术，提出基于EINV2的网络架构。

Result: 在测试集上取得F-score 40.2%，角度误差（DOA）17.7度，相对距离误差（RDE）0.32。

Conclusion: 提出的方法在音频事件定位与检测任务中表现优异，为SELD领域提供了有效解决方案。

Abstract: This technical report outlines our approach to Task 3A of the Detection and
Classification of Acoustic Scenes and Events (DCASE) 2024, focusing on Sound
Event Localization and Detection (SELD). SELD provides valuable insights by
estimating sound event localization and detection, aiding in various machine
cognition tasks such as environmental inference, navigation, and other sound
localization-related applications. This year's challenge evaluates models using
either audio-only (Track A) or audiovisual (Track B) inputs on annotated
recordings of real sound scenes. A notable change this year is the introduction
of distance estimation, with evaluation metrics adjusted accordingly for a
comprehensive assessment. Our submission is for Task A of the Challenge, which
focuses on the audio-only track. Our approach utilizes log-mel spectrograms,
intensity vectors, and employs multiple data augmentations. We proposed an
EINV2-based [1] network architecture, achieving improved results: an F-score of
40.2%, Angular Error (DOA) of 17.7 degrees, and Relative Distance Error (RDE)
of 0.32 on the test set of the Development Dataset [2 ,3].

</details>


### [19] [The TEA-ASLP System for Multilingual Conversational Speech Recognition and Speech Diarization in MLC-SLM 2025 Challenge](https://arxiv.org/abs/2507.18051)
*Hongfei Xue,Kaixun Huang,Zhikai Zhou,Shen Huang,Shidong Shang*

Main category: cs.SD

TL;DR: TEA-ASLP系统在MLC-SLM 2025挑战赛中，通过改进Ideal-LLM模型和优化说话人日志ASR，显著降低了词错误率，分别获得任务I和任务II的第一和第二名。


<details>
  <summary>Details</summary>
Motivation: 解决多语言对话自动语音识别（ASR）和说话人日志ASR的挑战，提升模型性能。

Method: 任务I中整合语言识别和多语言MOE LoRA结构，任务II中替换为更适合的英语说话人日志模型。

Result: 任务I的词错误率降至9.60%，任务II降至17.49%，分别减少30.8%。

Conclusion: 系统在多语言和说话人日志ASR任务中表现优异，验证了方法的有效性。

Abstract: This paper presents the TEA-ASLP's system submitted to the MLC-SLM 2025
Challenge, addressing multilingual conversational automatic speech recognition
(ASR) in Task I and speech diarization ASR in Task II. For Task I, we enhance
Ideal-LLM model by integrating known language identification and a multilingual
MOE LoRA structure, along with using CTC-predicted tokens as prompts to improve
autoregressive generation. The model is trained on approximately 180k hours of
multilingual ASR data. In Task II, we replace the baseline English-Chinese
speaker diarization model with a more suitable English-only version. Our
approach achieves a 30.8% reduction in word error rate (WER) compared to the
baseline speech language model, resulting in a final WER of 9.60% in Task I and
a time-constrained minimum-permutation WER of 17.49% in Task II, earning first
and second place in the respective challenge tasks.

</details>


### [20] [DIFFA: Large Language Diffusion Models Can Listen and Understand](https://arxiv.org/abs/2507.18452)
*Jiaming Zhou,Hongjie Chen,Shiwan Zhao,Jian Kang,Jie Li,Enzhi Wang,Yujie Guo,Haoqin Sun,Hui Wang,Aobo Kong,Yong Qin,Xuelong Li*

Main category: cs.SD

TL;DR: DIFFA是首个基于扩散的大型音频-语言模型，用于口语理解，结合扩散语言模型和轻量级双适配器架构，在有限数据下表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索扩散模型在音频模态的应用，填补现有研究的空白，提升音频理解的可控性和效率。

Method: 采用两阶段训练：先通过ASR目标对齐语义表示，再通过LLM生成的合成音频-字幕对学习指令跟随能力。

Result: 在MMSU、MMAU和VoiceBench等基准测试中表现优异，超越部分自回归开源基线模型。

Conclusion: 扩散语言模型在高效、可扩展的音频理解方面具有潜力，为语音驱动AI开辟新方向。

Abstract: Recent advances in Large language models (LLMs) have shown remarkable
capabilities across textual and multimodal domains. In parallel,
diffusion-based language models have emerged as a promising alternative to the
autoregressive paradigm, offering improved controllability, bidirectional
context modeling, and robust generation. However, their application to the
audio modality remains underexplored. In this work, we introduce
\textbf{DIFFA}, the first diffusion-based Large Audio-Language Model designed
to perform spoken language understanding. DIFFA integrates a frozen diffusion
language model with a lightweight dual-adapter architecture that bridges speech
understanding and natural language reasoning. We employ a two-stage training
pipeline: first, aligning semantic representations via an ASR objective; then,
learning instruction-following abilities through synthetic audio-caption pairs
automatically generated by prompting LLMs. Despite being trained on only 960
hours of ASR and 127 hours of synthetic instruction data, DIFFA demonstrates
competitive performance on major benchmarks, including MMSU, MMAU, and
VoiceBench, outperforming several autoregressive open-source baselines. Our
results reveal the potential of diffusion-based language models for efficient
and scalable audio understanding, opening a new direction for speech-driven AI.
Our code will be available at https://github.com/NKU-HLT/DIFFA.git.

</details>

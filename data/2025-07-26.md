<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 9]
- [eess.AS](#eess.AS) [Total: 6]
- [cs.SD](#cs.SD) [Total: 5]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Time and Frequency Synchronization for Multiuser OTFS in Uplink](https://arxiv.org/abs/2507.17966)
*Mohsen Bayat,Sanoopkumar P. S.,Arman Farhang*

Main category: eess.SP

TL;DR: 论文提出了高移动场景下上行多用户OTFS系统的时间和频率同步技术，重点解决定时偏移（TO）和载波频率偏移（CFO）的估计与校正问题。


<details>
  <summary>Details</summary>
Motivation: 在高移动场景下，准确估计和校正TO和CFO对于多用户OTFS系统的性能至关重要，尤其是TO估计用于定位用户导频，而CFO估计则提升信道估计精度。

Method: 提出了两种TO估计技术：一种基于单用户启发的PCP导频结构，另一种基于多用户共享导频区域的MU-PCP模式。随后，通过Chebyshev多项式基扩展模型（CPF-BEM）简化CFO估计的多维ML搜索问题。

Result: 提出的技术能够有效分离多用户信号并准确估计TO和CFO，提升了同步性能。

Conclusion: 论文提出的同步技术为高移动场景下的多用户OTFS系统提供了实用的解决方案，显著提升了系统性能。

Abstract: In this paper, we propose time and frequency synchronization techniques for
uplink multiuser OTFS (MU-OTFS) systems in high-mobility scenarios. This work
focuses on accurately estimating and correcting timing offsets (TOs) and
carrier frequency offsets (CFOs). Specifically, TO estimation is essential for
locating users' pilots on the delay-time plane, while CFO estimation enhances
channel estimation accuracy. First, we propose a TO estimation technique for an
existing multiuser pilot structure in MU-OTFS. We replace the impulse pilot
(IMP) in this pilot structure with a more practical pilot with a cyclic prefix
(PCP), referred to as single-user-inspired PCP (SU-PCP). This structure employs
different Zadoff-Chu (ZC) sequences, which enables pilot separation via
correlation at the receiver side. Consequently, we introduce a
correlation-based TO estimation technique for uplink MU-OTFS using this pilot
structure. Next, a spectrally efficient and practical pilot pattern is
proposed, where each user transmits a PCP within a shared pilot region on the
delay-Doppler plane, referred to as MU-PCP. At the receiver, the second TO
estimation technique utilizes a bank of filters to separate different users'
signals and accurately estimate their TOs. Then, we derive a mathematical
threshold range to enhance TO estimation accuracy by finding the first major
peak in the correlation function rather than relying solely on the highest
peak. After locating the received users' pilot signals using one of the
proposed TO estimation techniques, our proposed CFO estimation technique
reduces the multi-dimensional maximum likelihood (ML) search problem into
multiple one-dimensional search problems. In this technique, we apply the
Chebyshev polynomials of the first kind basis expansion model (CPF-BEM) to
effectively handle the time-variations of the channel in obtaining the CFO
estimates for all the users.

</details>


### [2] [Metasurface-based Fluid Antennas: from Electromagnetics to Communications Model](https://arxiv.org/abs/2507.17982)
*Pablo Ramírez-Espinosa,Cleofás Segura-Gómez,Ángel Palomares-Caballero,F. Javier López-Martínez,David Morales-Jiménez*

Main category: eess.SP

TL;DR: 本文提出了一种基于超表面的流体天线系统（FAS）的完整分析模型，利用动态超表面天线（DMA）实现FAS概念，并通过电路理论建模验证其性能。


<details>
  <summary>Details</summary>
Motivation: 由于电子可重构天线在分析建模上的挑战，限制了系统设计的理论指导，因此需要一种更实用的FAS实现方法。

Method: 采用动态超表面天线（DMA）实现FAS，利用电路理论重新建模信号模型，并通过全波仿真验证。

Result: 模型验证显示与仿真结果一致，DMA-based FAS性能接近理想化的位置灵活天线。

Conclusion: 提出的分析模型为FAS设计提供了理论支持，DMA是实现FAS的可行方案。

Abstract: Fluid antenna systems (FASs) have become a popular topic in the wireless
community as an effective yet simple means of exploiting spatial diversity. Due
to the limitations of physically moving radiating elements, electronically
reconfigurable antennas are emerging as practical implementations of FASs,
since changing the radiation pattern is functionally equivalent to physically
moving the device. However, electronically reconfigurable antennas pose a
challenge in terms of analytical modeling, often requiring full-wave
simulations or measurements for their characterization; this severely limits
the extraction of theoretical insights useful for system design. Motivated by
these difficulties and the growing interest in FASs, we propose in this paper a
complete analytical model for metasurface-based embodiments of FASs.
Specifically, we advocate for the implementation of the FAS concept through
dynamic metasurface antennas (DMAs), hitherto proposed as array replacements in
multiple-input multiple-output (MIMO) systems. We leverage circuit theory to
rewrite the conventional signal model of FASs in terms of admittance matrices
accounting for the electromagnetic effects inherent to metasurfaces. The model
is validated with full-wave simulations, showing good agreement. We further
illustrate how to apply the model for standard performance analysis, and
provide closed-form expressions for key metrics, including the resulting signal
covariance matrix. Results confirm that practical DMA-based FASs can achieve
similar performance to that of idealized implementations of position-flexible
antennas.

</details>


### [3] [Multiple Active STAR-RIS-Assisted Secure Integrated Sensing and Communication via Cooperative Beamforming](https://arxiv.org/abs/2507.18035)
*Hyeonho Noh,Hyeonsu Lyu,Hyun Jong Yang*

Main category: eess.SP

TL;DR: 本文研究了由多个主动同时传输和反射的可重构智能表面（STAR-RIS）支持的集成感知与通信（ISAC）网络，通过联合优化基站波束成形和STAR-RIS反射/传输系数，最大化通信总速率，同时满足感知、安全和功率约束。


<details>
  <summary>Details</summary>
Motivation: 探索如何在集成感知与通信网络中利用STAR-RIS提升性能，同时满足严格的感知、安全和功率限制。

Method: 采用交替优化（AO）框架，将问题分解为子问题，分别通过KKT条件和SCA方法优化基站波束成形和STAR-RIS参数。

Result: 仿真结果表明，所提算法在通信总速率上显著优于被动RIS和单STAR-RIS基线，同时满足感知和安全约束。

Conclusion: 主动STAR-RIS在ISAC网络中具有显著性能优势，且优化算法高效可行。

Abstract: This paper explores an integrated sensing and communication (ISAC) network
empowered by multiple active simultaneously transmitting and reflecting
reconfigurable intelligent surfaces (STAR-RISs). A base station (BS) furnishes
downlink communication to multiple users while concurrently interrogating a
sensing target. We jointly optimize the BS transmit beamformer and the
reflection/transmission coefficients of every active STAR-RIS in order to
maximize the aggregate communication sum-rate, subject to (i) a stringent
sensing signal-to-interference-plus-noise ratio (SINR) requirement, (ii) an
upper bound on the leakage of confidential information, and (iii) individual
hardware and total power constraints at both the BS and the STAR-RISs. The
resulting highly non-convex program is tackled with an efficient alternating
optimization (AO) framework. First, the original formulation is reformulated
into an equivalent yet more tractable representation and partitioned into
subproblems. The BS beamformer is updated in closed form via the
Karush-Kuhn-Tucker (KKT) conditions, whereas the STAR-RIS reflection and
transmission vectors are refined through successive convex approximation (SCA),
yielding a semidefinite program that is then solved via semidefinite
relaxation. Comprehensive simulations demonstrate that the proposed algorithm
delivers substantial sum-rate gains over passive-RIS and single STAR-RIS
baselines, all the while rigorously meeting the prescribed sensing and security
constraints.

</details>


### [4] [Geometrical portrait of Multipath error propagation in GNSS Direct Position Estimation](https://arxiv.org/abs/2507.18096)
*Jihong Huang,Rong Yang,Wei Gao,Xingqun Zhan,Zheng Yao*

Main category: eess.SP

TL;DR: 论文提出了一种几何模型（SCMB）来量化多路径误差对DPE的影响，并通过模拟和实验验证了其正确性。结果表明，PVT偏差与卫星仰角相关，为卫星选择提供了几何参考。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对DPE理论中多路径误差的理论描述，需要量化多路径对CAF和PVT解的影响。

Method: 通过几何分析扩展DPE噪声方差的理论框架，引入SCMB模型量化多路径误差，并通过蒙特卡洛模拟和城市峡谷测试验证。

Result: PVT偏差取决于多路径误差的最大值，且随卫星仰角增加而增大。

Conclusion: 研究为从几何角度选择DPE卫星提供了参考，强调高低仰角卫星的平衡组合对优化几何配置的重要性。

Abstract: Direct Position Estimation (DPE) is a method that directly estimate position,
velocity, and time (PVT) information from cross ambiguity function (CAF) of the
GNSS signals, significantly enhancing receiver robustness in urban
environments. However, there is still a lack of theoretical characterization on
multipath errors in the context of DPE theory. Geometric observations highlight
the unique characteristics of DPE errors stemming from multipath and thermal
noise as estimation bias and variance respectively. Expanding upon the
theoretical framework of DPE noise variance through geometric analysis, this
paper focuses on a geometric representation of multipath errors by quantifying
the deviations in CAF and PVT solutions caused by off-centering bias relative
to the azimuth and elevation angles. A satellite circular multipath bias (SCMB)
model is introduced, amalgamating CAF and PVT errors from multiple satellite
channels. The boundaries for maximum or minimum PVT bias are established
through discussions encompassing various multipath conditions. The correctness
of the multipath geometrical portrait is confirmed through both Monte Carlo
simulations and urban canyon tests. The findings indicate that the maximum PVT
bias depends on the largest multipath errors observed across various satellite
channels. Additionally, the PVT bias increases with satellite elevation angles,
influenced by the CAF multipath bias projection. This serves as a reference for
selecting DPE satellites from a geometric standpoint, underscoring the
importance of choosing a balanced combination of high and low elevation angles
to achieve an optimal satellite geometry configuration.

</details>


### [5] [Envelope Control Enabled Probabilistic Shaping for Peak Power Constrained IM DD Systems](https://arxiv.org/abs/2507.18149)
*Dongdong Zou,Wei Wang,Jiawen Yao,Zhongxing Tian,Zeyu Feng,Huan Huang,Fan Li,Gordon Ning Liu,Gangxiang Shen,Yi Cai*

Main category: eess.SP

TL;DR: 提出了一种针对峰值功率受限IM-DD系统的间接概率整形方案，通过动态选择性映射和涡轮均衡器优化性能。


<details>
  <summary>Details</summary>
Motivation: 解决概率整形在IM-DD系统中因记忆效应和非线性等问题难以有效应用的问题。

Method: 采用动态选择性映射（DSLM）和修改的M-BCJR算法涡轮均衡器。

Result: 在56GBaud PAM8系统中实现了1dB接收灵敏度提升。

Conclusion: 该方案为概率整形在IM-DD系统中的应用提供了新思路。

Abstract: Probabilistic shaping (PS) has attracted significant attention in
intensity-modulation and direct-detection (IM-DD) systems. However, due to the
unique system model and inherent constraints, the effective application of the
PS technique is still an open question in IM-DD systems, particularly in
systems with memory effects. In this paper, a novel indirect PS scheme tailored
for peak power constrained (PPC) IM-DD systems is proposed. The key idea lies
in strategically controlling the signal envelope to mitigate memory-induced
impairments, such as nonlinearity, overshoot, peak-to-average power ratio
enhancement, etc. The proposed scheme incorporates a dynamic selective mapping
(DSLM) mechanism at the transmitter, enabling an untypical bit-to-symbol
mapping in which the current symbol is not only determined by the current bits
pattern but also by previously generated symbols within a specified memory
length. At the receiver side, a turbo equalizer with a modified M-BCJR
algorithm is proposed to achieve the recovery of ambiguous bits induced by
DSLM. Experimental verification in a 56GBaud PAM8 system demonstrates that the
proposed scheme exhibits 1dB receiver sensitivity improvement over 2km
single-mode fiber transmission. In addition, the proposed scheme has also been
demonstrated to be compatible with the typical probabilistic amplitude shaping
architecture, enabling a simple and fine-granularity rate adaptation
capability. To the best of our knowledge, this work opens a new sight for the
application of the PS technique in PPC IM-DD systems with memory effects.

</details>


### [6] [GNSS Jammer and Spoofer Mitigation via Multi-Antenna Processing](https://arxiv.org/abs/2507.18166)
*Jonas Elmiger,Gian Marti,Christoph Studer*

Main category: eess.SP

TL;DR: SCHIEBER是一种多天线GNSS接收器方法，无需先验知识即可缓解干扰和欺骗攻击。


<details>
  <summary>Details</summary>
Motivation: GNSS信号易受干扰和欺骗攻击，需要一种无需先验知识的解决方案。

Method: 使用自适应空间滤波技术缓解干扰，通过信号一致性测试识别和拒绝欺骗信号。

Result: 在GPS L1 C/A系统模拟中验证了方法的有效性。

Conclusion: SCHIEBER能有效应对干扰和欺骗攻击，且无需先验信息。

Abstract: Modern positioning relies on radio signals from global navigation satellite
systems (GNSS). Their low receive power renders these radio signals susceptible
to jamming attacks, in which malicious transmitters emit strong interference to
disrupt signal acquisition. Moreover, GNSS are vulnerable to spoofing attacks,
in which malicious transmitters mimic legitimate satellites by transmitting
spurious GNSS signals. We propose SCHIEBER, a novel method for multi-antenna
GNSS receivers that mitigates jammers as well as spoofers without requiring any
prior knowledge of the receiver position or attack type: Jammers are mitigated
during signal acquisition using a recently developed adaptive spatial filtering
technique. Spoofers are identified and rejected after signal acquisition using
a novel approach that tests the consistency of acquired signals by comparing
their respective direction of arrival (DoA) and pseudorange estimates in a test
that is invariant with respect to the unknown receiver position. We demonstrate
the efficacy of our method using extensive simulations of a GPS L1 C/A system
under spoofing and jamming attacks.

</details>


### [7] [ICWLM: A Multi-Task Wireless Large Model via In-Context Learning](https://arxiv.org/abs/2507.18167)
*Yuxuan Wen,Xiaoming Chen,Maojun Zhang,Zhaoyang Zhang*

Main category: eess.SP

TL;DR: 提出了一种新型无线原生基础模型ICWLM，通过多任务学习和上下文学习解决无线通信中的复杂问题，具有优异的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 无线通信技术快速发展带来复杂性和计算需求，传统深度学习方法任务单一且泛化能力不足。

Method: ICWLM直接在混合无线数据集上训练，利用上下文学习和动态权重平均算法实现多任务学习。

Result: ICWLM在多项任务中表现优异，泛化能力强，适用于未见过的系统配置。

Conclusion: ICWLM为未来无线网络提供了统一且自适应的AI模型范式，降低了部署复杂性。

Abstract: The rapid evolution of wireless communication technologies, particularly
massive multiple-input multiple-output (mMIMO) and millimeter-wave (mmWave),
introduces significant network complexity and computational demands.
Significant research efforts have been made to improve physical layer
performance by resorting to deep learning (DL) methods, which, however, are
usually task-specific and struggle with data scarcity and generalization. To
address these challenges, we propose a novel In-Context Wireless Large Model
(ICWLM), a wireless-native foundation model designed for simultaneous
multi-task learning at the physical layer. Unlike conventional methods that
adapt wireless data to pre-trained large language models (LLMs), ICWLM is
trained directly on large-scale, mixed wireless datasets from scratch. It
jointly solves multiple classical physical layer problems, including multi-user
precoding (sum-rate maximization and max-min SINR) and channel prediction. A
key innovation of ICWLM is its utilization of in-context learning (ICL),
enabling the model to adapt to varying system configurations and channel
conditions with minimal demonstration pairs, eliminating the need for extensive
retraining. Furthermore, we employ the Dynamic Weight Averaging (DWA) algorithm
to dynamically balance the individual task losses during multi-task training,
ensuring efficient and stable learning across diverse objectives. Extensive
simulation results demonstrate that ICWLM achieves competitive performance
compared to task-specific methods while exhibiting remarkable generalization
capabilities to unseen system configurations. This work offers a promising
paradigm for developing unified and adaptive AI models for future wireless
networks, potentially reducing deployment complexity and enhancing intelligent
resource management.

</details>


### [8] [Quantized Signal Recovery with Interference via Parametrized Look-Up Tables](https://arxiv.org/abs/2507.18370)
*Morriel Kasher,Michael Tinston,Predrag Spasojevic*

Main category: eess.SP

TL;DR: 论文提出了一种基于查找表（LUT）和参数化模型的高效数字后校正方法，用于低分辨率模数转换器（ADC）。通过优化估计器，显著提升了信号恢复的准确性和抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 低分辨率、非线性或宽带量化器的性能受限，传统线性滤波技术效果不佳，需要更高效的校正方法。

Method: 结合参数化模型和三种分析估计器，优化LUT性能，并提出近似方法以简化估计问题。

Result: 仿真验证了方法的高准确性，能够实时恢复输入信号并抑制谐波失真，性能优于传统线性滤波技术。

Conclusion: 该方法在低分辨率ADC中实现了显著的性能提升，适用于复杂干扰环境。

Abstract: Efficient all-digital post-correction of low-resolution analog-to-digital
converters can be achieved by using Look-Up Tables (LUTs). The performance of a
LUT can be optimized by incorporating a parametric model for the expected input
signal, noise level, and interference signals. We evaluate three analytical
estimators for integration with parametrized LUTs, especially with applications
to low-resolution, non-linear, or wideband quantizers. We also propose several
approximations to improve tractability of the estimation problem for
Phase-Shift Keyed input signals and Linear Frequency Modulated interference
signals. Simulated results validate the ability of our estimator to recover the
instantaneous value of the desired input signal in real-time with a high degree
of accuracy. This includes cancellation of harmonic distortion that aliases
into the desired signal bandwidth from front-end saturation due to high-power
out-of-band interference. Our estimators are shown to achieve a significant
gain over conventional linear-filtering techniques while also being robust to
changes in input parameters, non-linear quantizers, and time-variant
interference sources. For a tone input quantized to 3 bits and estimated with a
fixed 12-tap model order we achieve $>$10 dB improvement in Mean Square Error
and $>$20 dBc improvement in Spurious-Free Dynamic Range.

</details>


### [9] [A Foundation Model for Massive MIMO Precoding with an Adaptive per-User Rate-Power Tradeoff](https://arxiv.org/abs/2507.18587)
*Jérôme Emery,Ali Hasanzadeh Karkan,Jean-François Frigon,François Leduc-Primeau*

Main category: eess.SP

TL;DR: 提出一种基于Transformer的基础模型用于mMIMO预编码，旨在降低发射机能耗并动态适应用户速率需求，在数据稀缺环境下通过数据增强方法提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决mMIMO系统中深度学习预编码模型对高质量本地数据集的依赖问题，同时降低训练复杂度并提升适应性。

Method: 采用Transformer基础模型，结合数据增强方法，通过预训练特征提取器计算余弦相似度生成类似目标分布的样本。

Result: 零样本部署下，模型性能显著优于零强迫法，接近加权最小均方误差性能且复杂度降低8倍。

Conclusion: 该工作通过解决数据可用性和训练复杂度问题，推动了深度学习在mMIMO预编码中的实际应用，并为资源分配算法提供了灵活性。

Abstract: Deep learning (DL) has emerged as a solution for precoding in massive
multiple-input multiple-output (mMIMO) systems due to its capacity to learn the
characteristics of the propagation environment. However, training such a model
requires high-quality, local datasets at the deployment site, which are often
difficult to collect. We propose a transformer-based foundation model for mMIMO
precoding that seeks to minimize the energy consumption of the transmitter
while dynamically adapting to per-user rate requirements. At equal energy
consumption, zero-shot deployment of the proposed foundation model
significantly outperforms zero forcing, and approaches weighted minimum mean
squared error performance with 8x less complexity. To address model adaptation
in data-scarce settings, we introduce a data augmentation method that finds
training samples similar to the target distribution by computing the cosine
similarity between the outputs of the pre-trained feature extractor. Our work
enables the implementation of DL-based solutions in practice by addressing
challenges of data availability and training complexity. Moreover, the ability
to dynamically configure per-user rate requirements can be leveraged by higher
level resource allocation and scheduling algorithms for greater control over
energy efficiency, spectral efficiency and fairness.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [10] [ASR-Guided Speaker-Role Diarization and Diarization-Guided ASR Decoding](https://arxiv.org/abs/2507.17765)
*Arindam Ghosh,Mark Fuhs,Bongjun Kim,Anurag Chowdhury,Monika Woszczyna*

Main category: eess.AS

TL;DR: 本文提出了一种扩展端到端ASR+SD框架的方法，用于角色识别（RD），通过简化训练、分离任务特定预测器以及利用RD后验活动优化ASR解码。


<details>
  <summary>Details</summary>
Motivation: 传统说话人识别（SD）仅提供通用标签，而角色识别（RD）在实际应用中更有价值。本文旨在将现有ASR+SD框架扩展至RD，以提升实用性。

Method: 1. 使用强制对齐和交叉熵损失简化训练；2. 为词预测和角色预测设计独立的任务特定预测器；3. 利用RD后验活动优化ASR解码。

Result: 实验表明，该方法能有效区分角色并减少ASR解码中的小词删除错误。

Conclusion: 本文提出的扩展框架在角色识别任务中表现优越，且能优化ASR性能。

Abstract: From an application standpoint, speaker-role diarization (RD), such as doctor
vs. patient, host vs. guest, etc. is often more useful than traditional speaker
diarization (SD), which assigns generic labels like speaker-1, speaker-2 etc.
In the context of joint automatic speech recognition (ASR) + SD (who spoke
what?), recent end-to-end models employ an auxiliary SD transducer,
synchronized with the ASR transducer, to predict speakers per word. In this
paper, we extend this framework to RD with three key contributions: (1) we
simplify the training via forced alignment and cross-entropy loss instead of
RNNT loss, (2) we show that word prediction and role prediction require
different amounts of predictor's context, leading to separate task-specific
predictors, unlike existing shared-predictor models, and (3) we propose a way
to leverage RD posterior activity to influence ASR decoding and reduce
small-word deletion errors.

</details>


### [11] [A Concept-based approach to Voice Disorder Detection](https://arxiv.org/abs/2507.17799)
*Davide Ghia,Gabriele Ciravegna,Alkis Koudounas,Marco Fantini,Erika Crosetti,Giovanni Succo,Tania Cerquitelli*

Main category: eess.AS

TL;DR: 论文探讨了基于可解释AI（XAI）的方法，如概念瓶颈模型（CBM）和概念嵌入模型（CEM），用于诊断语音障碍，旨在提高模型透明度和临床可信度。


<details>
  <summary>Details</summary>
Motivation: 语音障碍影响广泛，自动化非侵入性诊断技术能显著改善医疗质量。传统深度神经网络（DNNs）虽有效但决策不透明，限制了临床信任。

Method: 研究采用概念瓶颈模型（CBM）和概念嵌入模型（CEM），通过可解释AI提升模型透明度。

Result: 这些概念模型在性能上与传统深度学习方法相当，同时提供更透明的决策框架。

Conclusion: 概念模型为语音障碍诊断提供了高性能且可解释的解决方案，适合临床环境。

Abstract: Voice disorders affect a significant portion of the population, and the
ability to diagnose them using automated, non-invasive techniques would
represent a substantial advancement in healthcare, improving the quality of
life of patients. Recent studies have demonstrated that artificial intelligence
models, particularly Deep Neural Networks (DNNs), can effectively address this
task. However, due to their complexity, the decision-making process of such
models often remain opaque, limiting their trustworthiness in clinical
contexts. This paper investigates an alternative approach based on Explainable
AI (XAI), a field that aims to improve the interpretability of DNNs by
providing different forms of explanations. Specifically, this works focuses on
concept-based models such as Concept Bottleneck Model (CBM) and Concept
Embedding Model (CEM) and how they can achieve performance comparable to
traditional deep learning methods, while offering a more transparent and
interpretable decision framework.

</details>


### [12] [Recent Trends in Distant Conversational Speech Recognition: A Review of CHiME-7 and 8 DASR Challenges](https://arxiv.org/abs/2507.18161)
*Samuele Cornell,Christoph Boeddeker,Taejin Park,He Huang,Desh Raj,Matthew Wiesner,Yoshiki Masuyama,Xuankai Chang,Zhong-Qiu Wang,Stefano Squartini,Paola Garcia,Shinji Watanabe*

Main category: eess.AS

TL;DR: CHiME-7和8挑战赛聚焦多通道、可泛化的联合自动语音识别（ASR）和对话语音的说话人日志任务。分析显示，端到端ASR系统成为主流，但神经语音分离技术仍需改进，说话人日志优化是关键，下游任务评估与转录质量相关性较弱，挑战性环境下的语音识别仍具难度。


<details>
  <summary>Details</summary>
Motivation: 推动多通道、可泛化的联合ASR和说话人日志技术的研究，分析当前技术趋势和挑战。

Method: 设计了挑战赛任务，评估指标和数据集，并分析参与者提交的系统。

Result: 端到端ASR系统成为主流，神经语音分离技术仍需改进，说话人日志优化是关键，下游任务评估与转录质量相关性较弱。

Conclusion: 尽管技术进步，复杂环境下的语音识别仍具挑战性，未来需进一步优化语音分离和说话人日志技术。

Abstract: The CHiME-7 and 8 distant speech recognition (DASR) challenges focus on
multi-channel, generalizable, joint automatic speech recognition (ASR) and
diarization of conversational speech. With participation from 9 teams
submitting 32 diverse systems, these challenges have contributed to
state-of-the-art research in the field. This paper outlines the challenges'
design, evaluation metrics, datasets, and baseline systems while analyzing key
trends from participant submissions. From this analysis it emerges that: 1)
Most participants use end-to-end (e2e) ASR systems, whereas hybrid systems were
prevalent in previous CHiME challenges. This transition is mainly due to the
availability of robust large-scale pre-trained models, which lowers the data
burden for e2e-ASR. 2) Despite recent advances in neural speech separation and
enhancement (SSE), all teams still heavily rely on guided source separation,
suggesting that current neural SSE techniques are still unable to reliably deal
with complex scenarios and different recording setups. 3) All best systems
employ diarization refinement via target-speaker diarization techniques.
Accurate speaker counting in the first diarization pass is thus crucial to
avoid compounding errors and CHiME-8 DASR participants especially focused on
this part. 4) Downstream evaluation via meeting summarization can correlate
weakly with transcription quality due to the remarkable effectiveness of
large-language models in handling errors. On the NOTSOFAR-1 scenario, even
systems with over 50\% time-constrained minimum permutation WER can perform
roughly on par with the most effective ones (around 11\%). 5) Despite recent
progress, accurately transcribing spontaneous speech in challenging acoustic
environments remains difficult, even when using computationally intensive
system ensembles.

</details>


### [13] [SpecASR: Accelerating LLM-based Automatic Speech Recognition via Speculative Decoding](https://arxiv.org/abs/2507.18181)
*Linye Wei,Shuzhang Zhong,Songqiang Xu,Runsheng Wang,Ru Huang,Meng Li*

Main category: eess.AS

TL;DR: SpecASR是一种针对ASR任务优化的推测解码框架，通过动态调整草稿序列长度和回收策略，显著降低解码延迟，同时保持识别精度。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的ASR系统解码延迟高，难以满足实时需求，现有推测解码方法未充分结合ASR任务特性，速度提升有限。

Method: 提出SpecASR框架，包括自适应草稿序列生成、草稿序列回收策略和两阶段稀疏令牌树生成算法。

Result: 实验显示，SpecASR比基线自回归解码和推测解码分别提速3.04x-3.79x和1.25x-1.84x，且识别精度无损失。

Conclusion: SpecASR通过任务专用优化，显著提升ASR解码效率，为实时应用提供可行解决方案。

Abstract: Large language model (LLM)-based automatic speech recognition (ASR) has
recently attracted a lot of attention due to its high recognition accuracy and
enhanced multi-dialect support. However, the high decoding latency of LLMs
challenges the real-time ASR requirements. Although speculative decoding has
been explored for better decoding efficiency, they usually ignore the key
characteristics of the ASR task and achieve limited speedup. To further reduce
the real-time ASR latency, in this paper, we propose a novel speculative
decoding framework specialized for ASR, dubbed SpecASR. SpecASR is developed
based on our core observation that ASR decoding is audio-conditioned, which
results in high output alignment between small and large ASR models, even given
output mismatches in intermediate decoding steps. Therefore, SpecASR features
an adaptive draft sequence generation process that dynamically modifies the
draft sequence length to maximize the token acceptance length. SpecASR further
proposes a draft sequence recycling strategy that reuses the previously
generated draft sequence to reduce the draft ASR model latency. Moreover, a
two-pass sparse token tree generation algorithm is also proposed to balance the
latency of draft and target ASR models. With extensive experimental results, we
demonstrate SpecASR achieves 3.04x-3.79x and 1.25x-1.84x speedup over the
baseline autoregressive decoding and speculative decoding, respectively,
without any loss in recognition accuracy.

</details>


### [14] [Speech Enhancement with Dual-path Multi-Channel Linear Prediction Filter and Multi-norm Beamforming](https://arxiv.org/abs/2507.18350)
*Chengyuan Qin,Wenmeng Xiong,Jing Zhou,Maoshen Jia,Changchun Bao*

Main category: eess.AS

TL;DR: 提出了一种基于双路径多通道线性预测（MCLP）滤波器和多范数波束形成的语音增强方法，在高混响场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决高混响环境下语音增强的挑战，提升语音信号的质量。

Method: 结合双路径MCLP滤波器（时频维度）和多范数波束形成，最小化麦克风阵列输出功率和去噪信号的l1范数，同时保留目标方向信号。

Result: 在高混响场景中优于基线方法。

Conclusion: 该方法在复杂混响环境下具有显著优势，适用于其他MCLP相关应用。

Abstract: In this paper, we propose a speech enhancement method us ing dual-path
Multi-Channel Linear Prediction (MCLP) filters
  and multi-norm beamforming. Specifically, the MCLP part in
  the proposed method is designed with dual-path filters in both
  time and frequency dimensions. For the beamforming part, we
  minimize the power of the microphone array output as well as
  the l1 norm of the denoised signals while preserving source sig nals from the
target directions. An efficient method to select the
  prediction orders in the dual-path filters is also proposed, which
  is robust for signals with different reverberation time (T60) val ues and can
be applied to other MCLP-based methods. Eval uations demonstrate that our
proposed method outperforms the
  baseline methods for speech enhancement, particularly in high
  reverberation scenarios.

</details>


### [15] [Streaming Sortformer: Speaker Cache-Based Online Speaker Diarization with Arrival-Time Ordering](https://arxiv.org/abs/2507.18446)
*Ivan Medennikov,Taejin Park,Weiqing Wang,He Huang,Kunal Dhawan,Jinhan Wang,Jagadeesh Balam,Boris Ginsburg*

Main category: eess.AS

TL;DR: 本文提出了一种流式扩展的Sortformer说话人分割框架，通过动态更新的到达顺序说话人缓存（AOSC）实现高效说话人跟踪。


<details>
  <summary>Details</summary>
Motivation: 解决传统说话人分割框架在流式场景中无法动态跟踪说话人的问题。

Method: 采用AOSC缓存按到达时间顺序存储说话人嵌入，动态更新缓存以提高效率。

Result: 在基准数据集上验证了方法的有效性和灵活性，适用于低延迟场景。

Conclusion: Streaming Sortformer为实时多说话人跟踪提供了稳健解决方案。

Abstract: This paper presents a streaming extension for the Sortformer speaker
diarization framework, whose key property is the arrival-time ordering of
output speakers. The proposed approach employs an Arrival-Order Speaker Cache
(AOSC) to store frame-level acoustic embeddings of previously observed
speakers. Unlike conventional speaker-tracing buffers, AOSC orders embeddings
by speaker index corresponding to their arrival time order, and is dynamically
updated by selecting frames with the highest scores based on the model's past
predictions. Notably, the number of stored embeddings per speaker is determined
dynamically by the update mechanism, ensuring efficient cache utilization and
precise speaker tracking. Experiments on benchmark datasets confirm the
effectiveness and flexibility of our approach, even in low-latency setups.
These results establish Streaming Sortformer as a robust solution for real-time
multi-speaker tracking and a foundation for streaming multi-talker speech
processing.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [16] [Speaker Disentanglement of Speech Pre-trained Model Based on Interpretability](https://arxiv.org/abs/2507.17851)
*Xiaoxu Zhu,Junhua Li*

Main category: cs.SD

TL;DR: 本文提出了一种基于可解释性的语音预训练模型音色解耦方法，通过量化音色残留和改进音色过滤，显著优化了音色与内容的分离效果。


<details>
  <summary>Details</summary>
Motivation: 解决语音预训练模型中音色与内容信息难以解耦的问题，避免音色信息泄露并提升内容相关任务性能。

Method: 提出InterpTRQE-SptME基准和InterpTF-SptME方法，利用梯度SHAP解释器量化音色残留，并通过SHAP噪声和裁剪技术去除音色信息。

Result: 实验显示SHAP噪声方法可将音色残留从18.05%降至接近0%，同时保持内容完整性。

Conclusion: 该方法有效优化了音色解耦，提升了语音处理任务性能并防止音色隐私泄露。

Abstract: Speech pretrained models contain task-specific information across different
layers, but decoupling content and timbre information remains challenging as
removing speaker-specific information often causes content loss. Current
research lacks direct metrics to quantify timbre residual in model encodings,
relying on indirect evaluation through downstream tasks. This paper addresses
these challenges through interpretability-based speaker disentanglement in
speech pretraining models. We quantitatively evaluate timbre residual in model
embeddings and improve speaker disentanglement using interpretive
representations. Our contributions include: (1) InterpTRQE-SptME Benchmark - a
timbre residual recognition framework using interpretability. The benchmark
concatenates content embeddings with timbre embeddings for speaker
classification, then applies Gradient SHAP Explainer to quantify timbre
residual. We evaluate seven speech pretraining model variations. (2)
InterpTF-SptME method - an interpretability-based timbre filtering approach
using SHAP Noise and SHAP Cropping techniques. This model-agnostic method
transforms intermediate encodings to remove timbre while preserving content.
Experiments on VCTK dataset with HuBERT LARGE demonstrate successful content
preservation and significant speaker disentanglement optimization. Results show
the SHAP Noise method can reduce timbre residual from 18.05% to near 0% while
maintaining content integrity, contributing to enhanced performance in
content-related speech processing tasks and preventing timbre privacy leakage.

</details>


### [17] [Bob's Confetti: Phonetic Memorization Attacks in Music and Video Generation](https://arxiv.org/abs/2507.17937)
*Jaechul Roh,Zachary Novack,Yuefeng Peng,Niloofar Mireshghallah,Taylor Berg-Kirkpatrick,Amir Houmansadr*

Main category: cs.SD

TL;DR: 论文研究了歌词到歌曲生成模型（LS2）对训练数据记忆的脆弱性，提出了一种新的攻击方法APT，通过同音替换改变歌词语义但保留声学结构，揭示了模型对训练内容的记忆现象，并发现这种现象在文本到视频模型中同样存在。


<details>
  <summary>Details</summary>
Motivation: 探索歌词到歌曲生成模型对训练数据记忆的脆弱性，揭示其在多模态生成中的潜在风险。

Method: 提出Adversarial PhoneTic Prompting (APT)攻击方法，通过同音替换改变歌词语义但保留声学结构，测试模型对训练内容的记忆能力。

Result: 发现模型（如SUNO和YuE）在音频指标（如CLAP、AudioJudge、CoverID）上表现出对训练内容的高相似性，且这种现象在多语言和流派中普遍存在。此外，文本到视频模型（如Veo 3）在提示中使用同音修改的歌词时，能重建原始音乐视频的视觉元素。

Conclusion: 研究揭示了转录条件多模态生成中的关键漏洞，即仅通过语音提示即可触发记忆的视听内容，引发了关于版权、安全和内容来源的紧迫问题。

Abstract: Lyrics-to-Song (LS2) generation models promise end-to-end music synthesis
from text, yet their vulnerability to training data memorization remains
underexplored. We introduce Adversarial PhoneTic Prompting (APT), a novel
attack where lyrics are semantically altered while preserving their acoustic
structure through homophonic substitutions (e.g., Eminem's famous "mom's
spaghetti" $\rightarrow$ "Bob's confetti"). Despite these distortions, we
uncover a powerful form of sub-lexical memorization: models like SUNO and YuE
regenerate outputs strikingly similar to known training content, achieving high
similarity across audio-domain metrics, including CLAP, AudioJudge, and
CoverID. This vulnerability persists across multiple languages and genres. More
surprisingly, we discover that phoneme-altered lyrics alone can trigger visual
memorization in text-to-video models. When prompted with phonetically modified
lyrics from Lose Yourself, Veo 3 reconstructs visual elements from the original
music video -- including character appearance and scene composition -- despite
no visual cues in the prompt. We term this phenomenon phonetic-to-visual
regurgitation. Together, these findings expose a critical vulnerability in
transcript-conditioned multimodal generation: phonetic prompting alone can
unlock memorized audiovisual content, raising urgent questions about copyright,
safety, and content provenance in modern generative systems. Example
generations are available on our demo page (jrohsc.github.io/music_attack/).

</details>


### [18] [Resnet-conformer network with shared weights and attention mechanism for sound event localization, detection, and distance estimation](https://arxiv.org/abs/2507.17941)
*Quoc Thinh Vo,David Han*

Main category: cs.SD

TL;DR: 该技术报告介绍了DCASE 2024任务3A的音频事件定位与检测（SELD）方法，采用EINV2网络架构，在开发数据集上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: SELD在机器认知任务（如环境推断和导航）中具有重要价值，本次挑战新增距离估计以全面评估模型。

Method: 使用log-mel频谱图和强度向量，结合多种数据增强技术，提出基于EINV2的网络架构。

Result: 测试集上F-score为40.2%，DOA误差17.7度，RDE误差0.32。

Conclusion: 该方法在音频事件定位与检测任务中表现优异，验证了EINV2架构的有效性。

Abstract: This technical report outlines our approach to Task 3A of the Detection and
Classification of Acoustic Scenes and Events (DCASE) 2024, focusing on Sound
Event Localization and Detection (SELD). SELD provides valuable insights by
estimating sound event localization and detection, aiding in various machine
cognition tasks such as environmental inference, navigation, and other sound
localization-related applications. This year's challenge evaluates models using
either audio-only (Track A) or audiovisual (Track B) inputs on annotated
recordings of real sound scenes. A notable change this year is the introduction
of distance estimation, with evaluation metrics adjusted accordingly for a
comprehensive assessment. Our submission is for Task A of the Challenge, which
focuses on the audio-only track. Our approach utilizes log-mel spectrograms,
intensity vectors, and employs multiple data augmentations. We proposed an
EINV2-based [1] network architecture, achieving improved results: an F-score of
40.2%, Angular Error (DOA) of 17.7 degrees, and Relative Distance Error (RDE)
of 0.32 on the test set of the Development Dataset [2 ,3].

</details>


### [19] [The TEA-ASLP System for Multilingual Conversational Speech Recognition and Speech Diarization in MLC-SLM 2025 Challenge](https://arxiv.org/abs/2507.18051)
*Hongfei Xue,Kaixun Huang,Zhikai Zhou,Shen Huang,Shidong Shang*

Main category: cs.SD

TL;DR: TEA-ASLP系统在MLC-SLM 2025挑战赛中，通过改进Ideal-LLM模型和优化说话人日志ASR，分别获得Task I和Task II的第一和第二名。


<details>
  <summary>Details</summary>
Motivation: 解决多语言对话自动语音识别（ASR）和说话人日志ASR的挑战，提升性能。

Method: Task I：集成语言识别和多语言MOE LoRA结构，使用CTC预测标记作为提示；Task II：替换基线说话人日志模型为更适合的英语版本。

Result: Task I的WER降低30.8%，最终WER为9.60%；Task II的时间约束最小排列WER为17.49%。

Conclusion: 系统在多语言ASR和说话人日志任务中表现优异，验证了方法的有效性。

Abstract: This paper presents the TEA-ASLP's system submitted to the MLC-SLM 2025
Challenge, addressing multilingual conversational automatic speech recognition
(ASR) in Task I and speech diarization ASR in Task II. For Task I, we enhance
Ideal-LLM model by integrating known language identification and a multilingual
MOE LoRA structure, along with using CTC-predicted tokens as prompts to improve
autoregressive generation. The model is trained on approximately 180k hours of
multilingual ASR data. In Task II, we replace the baseline English-Chinese
speaker diarization model with a more suitable English-only version. Our
approach achieves a 30.8% reduction in word error rate (WER) compared to the
baseline speech language model, resulting in a final WER of 9.60% in Task I and
a time-constrained minimum-permutation WER of 17.49% in Task II, earning first
and second place in the respective challenge tasks.

</details>


### [20] [DIFFA: Large Language Diffusion Models Can Listen and Understand](https://arxiv.org/abs/2507.18452)
*Jiaming Zhou,Hongjie Chen,Shiwan Zhao,Jian Kang,Jie Li,Enzhi Wang,Yujie Guo,Haoqin Sun,Hui Wang,Aobo Kong,Yong Qin,Xuelong Li*

Main category: cs.SD

TL;DR: DIFFA是首个基于扩散的大型音频语言模型，用于口语理解，通过双适配器架构和两阶段训练，在少量数据下表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索扩散模型在音频模态中的应用，弥补现有自回归模型的不足。

Method: 结合冻结扩散模型与轻量双适配器架构，分两阶段训练：语义对齐和指令学习。

Result: 在MMSU、MMAU和VoiceBench等基准测试中表现优异，超越开源自回归模型。

Conclusion: 扩散模型在音频理解中具有高效和可扩展的潜力，为语音AI开辟新方向。

Abstract: Recent advances in Large language models (LLMs) have shown remarkable
capabilities across textual and multimodal domains. In parallel,
diffusion-based language models have emerged as a promising alternative to the
autoregressive paradigm, offering improved controllability, bidirectional
context modeling, and robust generation. However, their application to the
audio modality remains underexplored. In this work, we introduce
\textbf{DIFFA}, the first diffusion-based Large Audio-Language Model designed
to perform spoken language understanding. DIFFA integrates a frozen diffusion
language model with a lightweight dual-adapter architecture that bridges speech
understanding and natural language reasoning. We employ a two-stage training
pipeline: first, aligning semantic representations via an ASR objective; then,
learning instruction-following abilities through synthetic audio-caption pairs
automatically generated by prompting LLMs. Despite being trained on only 960
hours of ASR and 127 hours of synthetic instruction data, DIFFA demonstrates
competitive performance on major benchmarks, including MMSU, MMAU, and
VoiceBench, outperforming several autoregressive open-source baselines. Our
results reveal the potential of diffusion-based language models for efficient
and scalable audio understanding, opening a new direction for speech-driven AI.
Our code will be available at https://github.com/NKU-HLT/DIFFA.git.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SD](#cs.SD) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Design and Implementation of Parametrized Look-Up Tables for Post-Correction of Oversampling Low-Resolution ADCs](https://arxiv.org/abs/2507.18673)
*Morriel Kasher,Michael Tinston,Predrag Spasojevic*

Main category: eess.SP

TL;DR: 提出了一种用于设计、优化和实现查找表（LUT）的框架，用于恢复噪声、过采样、量化信号，通过全数字解决方案模拟预量化抖动的频谱效果。


<details>
  <summary>Details</summary>
Motivation: 解决量化信号恢复中的频谱纯净度问题，提供一种无需训练的模型驱动方法。

Method: 将LUT设计问题分解为四个阶段，采用三种抖动方法提升频谱纯净度，并提出两种新颖的索引方案以减少内存开销。

Result: 在3位量化信号中，SFDR提升了19 dBc，内存占用仅324字节，且保持3位定点精度。

Conclusion: 该方法适用于低分辨率宽带设备，具有超低延迟特性。

Abstract: We propose a framework for the design, optimization, and implementation of
Look-Up Tables (LUTs) used to recover noisy, oversampled, quantized signals
given a parametric input model. The LUTs emulate the spectral effects of
pre-quantization dithering through an all-digital solution applied after
quantization. This methodology decomposes the intractable LUT design problem
into four distinct stages, each of which is addressed analytically using a
model-driven approach without reliance on training. Three dithering methods are
studied to improve spectral purity metrics. Two novel indexing schemes are
proposed to limit the LUT memory overhead shown to compress the LUT size by
over four orders of magnitude with marginal performance loss. The LUT design is
tested with an oversampled noisy sinusoidal input quantized to 3 bits and shown
to improve its Spurious-Free Dynamic Range (SFDR) by over 19 dBc with only 324
bytes of memory while maintaining the same 3-bit fixed-point precision at the
digital output. This correction can be implemented using two-level
combinational logic ensuring ultra-low latency and, hence, suitable for
low-resolution wideband devices.

</details>


### [2] [Exploiting Movable Antennas in NOMA Networks: Joint Beamforming, Power Allocation and Antenna Position Optimization](https://arxiv.org/abs/2507.18730)
*Yufeng Zhou,Wen Chen,Qingqing Wu,Xusheng Zhu,Zhendong Li,Kunlun Wang,Qiong Wu*

Main category: eess.SP

TL;DR: 该论文研究了基于可移动天线（MA）的下行非正交多址（NOMA）网络，旨在最大化系统吞吐量。通过联合优化基站波束成形、功率分配及天线位置，提出了一种高效的交替优化算法。


<details>
  <summary>Details</summary>
Motivation: 通过利用可移动天线在基站和用户端的自由度，提升非正交多址网络的系统吞吐量。

Method: 采用交替优化框架，将问题分解为三个子问题，并利用SPCA和SCA技术处理非凸约束。

Result: 数值结果表明，所提系统在吞吐量方面显著优于基准方案。

Conclusion: 通过联合优化天线位置和通信参数，可移动天线技术能有效提升NOMA网络的性能。

Abstract: This paper investigates the movable antenna (MA)- assisted downlink
non-orthogonal multiple access (NOMA) network to maximize system throughput. In
the considered scenario, both the base station (BS) and users are equipped with
MA, and a predetermined successive interference cancellation (SIC) decoding
order is adopted. Based on the field-response channel model, we formulate a
complex, non-convex problem to jointly optimize the BS beamforming, power
allocation, and MA positions at both the transmitter and receivers. To address
this, we propose an efficient algorithm based on an alternating optimization
(AO) framework, which decomposes the original problem into three distinct
subproblems. By employing sequential parametric convex approximation (SPCA) and
successive convex approximation (SCA) techniques, the non-convex constraints
within each subproblem are transformed into tractable. This methodology ensures
the algorithm converges to a stable, locally optimal solution. Numerical
results validate that the proposed system, which fully exploits the degrees of
freedom from antenna mobility at both ends, significantly outperforms
benchmarks in terms of throughput.

</details>


### [3] [Max-Min Rate Optimization for Multigroup Multicast MISO Systems Via Novel Transmissive RIS Transceiver](https://arxiv.org/abs/2507.18733)
*Yuan Guo,Wen Chen,Qingqing Wu,Yanze Zhu,Yang Liu,Zhendong Li,Ying Wang*

Main category: eess.SP

TL;DR: 论文研究了基于透射可重构智能表面（RIS）收发器架构的多组多播下行通信系统，提出了三种算法以优化用户最小速率，并比较了它们的性能和复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决在多组多播通信系统中，由于目标函数的不可微性导致的优化问题，同时降低计算复杂度。

Method: 1. 使用逐次凸近似（SCA）和惩罚函数法的迭代解法；2. 基于加权最小均方误差（WMMSE）框架的二阶锥规划（SOCP）方法；3. 结合平滑近似理论和最大化-最小化（MM）方法的低复杂度无求解器算法。

Result: 数值结果表明，SOCP方法在最小速率和计算复杂度上优于惩罚法，而低复杂度设计在性能略有下降的情况下显著降低了复杂度。

Conclusion: 提出的三种算法均有效，SOCP方法性能最优，低复杂度设计适合对性能要求不高的场景。

Abstract: This paper investigates a novel transmissive reconfigurable intelligent
surface (RIS) transceiver architectureenabled multigroup multicast downlink
communication system. Under this setup, an optimization problem is formulated
to maximize the minimum rate of users across all groups, subject to the maximum
available power of each RIS unit. Due to the nondifferentiable nature of the
objective function, the max-min rate problem is challenging to solve. To tackle
this difficult problem, we develop an iterative solution by leveraging the
successive convex approximation (SCA) and the penalty function method. However,
the above approach has high computational complexity and may lead to
compromised performance. To overcome these drawbacks, we design an efficient
second-order cone programming (SOCP)-based method using the weighted minimum
mean squared error (WMMSE) framework to reduce computational complexity.
Furthermore, to further reduce the computational complexity, we also propose a
low-complexity and solver-free algorithm that analytically updates all
variables by combining the smooth approximation theory and the
majorization-minimization (MM) method. Numerical results are provided to verify
the convergence and effectiveness of our proposed three algorithms. It is also
demonstrated that the SOCP-based method outperforms the penalty-based algorithm
in terms of both the achieved min rate and the computational complexity. In
contrast, the lowcomplexity design achieves significantly lower complexity with
only slightly degraded performance.

</details>


### [4] [Max-Min Fairness-Oriented Beamforming Design in HAPS-Enabled ISAC for 6G Networks](https://arxiv.org/abs/2507.18764)
*Parisa Kanani,Mohammad Javad Omidi,Mahmoud Modarres-Hashemi,Halim Yanikomeroglu*

Main category: eess.SP

TL;DR: 论文提出了一种基于高空平台站（HAPS）的集成感知与通信（ISAC）系统，用于6G网络，通过优化资源分配实现公平性和高效性。


<details>
  <summary>Details</summary>
Motivation: 解决6G网络中公平服务分配的需求，同时兼顾通信和感知功能。

Method: 利用HAPS作为超级宏基站，采用波束成形技术，通过非凸优化问题平衡感知波束增益和通信用户的SINR需求。

Result: 仿真结果表明，HAPS-ISAC框架能高效分配资源，提供可靠覆盖并提升感知精度。

Conclusion: HAPS-ISAC是6G网络和集成通信-感知系统的关键推动者。

Abstract: This paper presents a high-altitude platform station (HAPS)-enabled
integrated sensing and communication (ISAC) system designed for
sixth-generation (6G) networks. Positioned in the stratosphere, HAPS serves as
a super-macro base station, leveraging advanced beamforming techniques to
enable communication and sensing simultaneously. This research addresses the
need for equitable service distribution in 6G networks by focusing on fairness
within the HAPS-ISAC system. It tackles a non-convex optimization problem that
balances sensing beampattern gain and signal-to-interference-plus-noise ratio
(SINR) requirements among communication users (CUs) using a max-min fairness
approach while adhering to power constraints. The proposed HAPS-ISAC framework
ensures efficient resource allocation, reliable coverage, and improved sensing
accuracy. Simulation results validate the potential of HAPS-ISAC as a pivotal
enabler for 6G networks and integrated communication-sensing systems.

</details>


### [5] [Flexible Intelligent Metasurfaces in High-Mobility MIMO Integrated Sensing and Communications](https://arxiv.org/abs/2507.18793)
*Kuranage Roche Rayan Ranasinghe,Jiancheng An,Iván Alexander Morales Sandoval,Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu,Chau Yuen,Mérouane Debbah*

Main category: eess.SP

TL;DR: 提出了一种新型的双色散（DD）MIMO信道模型，结合灵活智能超表面（FIM），适用于高移动性场景中的集成感知与通信（ISAC）。


<details>
  <summary>Details</summary>
Motivation: 研究如何在双色散信道环境下优化集成感知与通信的性能，利用FIM技术提升系统表现。

Method: 提出FIM参数化的DD（FPDD）信道模型，并将其应用于OFDM、OTFS和AFDM波形，通过梯度上升算法求解速率最大化问题。

Result: 数值结果表明，FIM技术对可达到的速率有显著影响，且参数化对提升ISAC性能至关重要。

Conclusion: FIM技术结合适当的参数化，可以有效优化双色散信道中的ISAC性能。

Abstract: We propose a novel doubly-dispersive (DD) multiple-input multiple-output
(MIMO) channel model incorporating flexible intelligent metasurfaces (FIMs),
which is suitable for integrated sensing and communications (ISAC) in
high-mobility scenarios. We then discuss how the proposed FIM-parameterized DD
(FPDD) channel model can be applied in a logical manner to ISAC waveforms that
are known to perform well in DD environments, namely, orthogonal frequency
division multiplexing (OFDM), orthogonal time frequency space (OTFS), and
affine frequency division multiplexing (AFDM). Leveraging the proposed model,
we formulate an achievable rate maximization problem with a strong sensing
constraint for all the aforementioned waveforms, which we then solve via a
gradient ascent algorithm with closed-form gradients presented as a bonus. Our
numerical results indicate that the achievable rate is significantly impacted
by the emerging FIM technology with careful parametrization essential in
obtaining strong ISAC performance across all waveforms suitable to mitigating
the effects of DD channels.

</details>


### [6] [A Fingerprint Database Generation Method for RIS-Assisted Indoor Positioning](https://arxiv.org/abs/2507.18927)
*Xin Cheng,Yu He,Menglu Li,Ruoguang Li,Feng Shu,Guangjie Han*

Main category: eess.SP

TL;DR: 提出了一种生成RIS辅助RSS指纹数据库的新方法，解决了现有方法缺乏真实性和空间一致性的问题。


<details>
  <summary>Details</summary>
Motivation: RIS技术虽能提升室内无线通信和感知性能，但缺乏可靠的RSS指纹数据库构建方法。

Method: 通过扩展的基于簇的信道建模和RIS/Tx的物理电磁特性，模拟复杂多径行为，并引入空间一致性。

Result: 仿真验证了方法的有效性，并通过KNN和DNN分析了定位性能。

Conclusion: 该方法为RIS辅助室内定位系统设计提供了有价值的参考。

Abstract: Reconfigurable intelligent surface (RIS) has emerged as a promising
technology to enhance indoor wireless communication and sensing performance.
However, the construction of reliable received signal strength (RSS)-based
fingerprint databases for RIS-assisted indoor positioning remains an open
challenge due to the lack of realistic and spatially consistent channel
modeling methods. In this paper, we propose a novel method with open-source
codes for generating RIS-assisted RSS fingerprint databases. Our method
captures the complex RIS-assisted multipath behaviors by extended cluster-based
channel modeling and the physical and electromagnetic properties of RIS and
transmitter (Tx). And the spatial consistency is incorporated when simulating
the fingerprint data collection across neighboring positions. Furthermore, the
proposed method offers exceptional flexibility in configuring RIS and Tx
parameters. Extensive simulations are conducted to evaluate the fingerprint
database generated by the proposed method. Moreover, the positioning
performance on the database using K-nearest neighbors (KNN) and deep neural
network (DNN) is analyzed, providing valuable insights for the system design.

</details>


### [7] [Assessing the Reliability and Validity of a Balance Mat for Measuring Postural Stability: A Combined Robot-Human Approach](https://arxiv.org/abs/2507.18943)
*Abishek Shrestha,Damith Herath,Angie Fearon,Maryam Ghahramani*

Main category: eess.SP

TL;DR: 研究评估了一种新型低成本便携式平衡垫（BM）的可靠性和有效性，通过机器人实验和人体实验验证其作为力板（FP）替代方案的潜力。


<details>
  <summary>Details</summary>
Motivation: 力板（FP）是实验室条件下评估姿势摇摆的金标准，但缺乏便携性和高专业性限制了其广泛应用。本研究旨在验证BM作为便携替代方案的可行性。

Method: 研究分为两部分：机器人实验使用UR10机械臂生成受控摇摆模式评估BM的可靠性和灵敏度；人体实验让51名健康年轻参与者在BM和FP上完成平衡任务，比较两者的摇摆指标。

Result: 机器人实验显示BM在单腿和双腿站立时可靠性良好（ICC>0.75）。人体实验中，BM与FP的摇摆路径和范围相关性中等至强，但BM倾向于高估指标，需校准改进一致性。

Conclusion: BM在适当校准后表现出可靠的摇摆测量能力，验证了其作为FP便携替代方案的潜力。

Abstract: Postural sway assessment is important for detecting balance problems and
identifying people at risk of falls. Force plates (FP) are considered the gold
standard postural sway assessment method in laboratory conditions, but their
lack of portability and requirement of high-level expertise limit their
widespread usage. This study evaluates the reliability and validity of a novel
Balance Mat (BM) device, a low-cost portable alternative that uses optical
fibre technology. The research includes two studies: a robot study and a human
study. In the robot study, a UR10 robotic arm was used to obtain controlled
sway patterns to assess the reliability and sensitivity of the BM. In the human
study, 51 healthy young participants performed balance tasks on the BM in
combination with an FP to evaluate the BM's validity. Sway metrics such as sway
mean, sway absolute mean, sway root mean square (RMS), sway path, sway range,
and sway velocity were calculated from both BM and FP and compared. Reliability
was evaluated using the intra-class correlation coefficient (ICC), where values
greater than 0.9 were considered excellent and values between 0.75 and 0.9 were
considered good. Results from the robot study demonstrated good to excellent
ICC values in both single and double-leg stances. The human study showed
moderate to strong correlations for sway path and range. Using Bland-Altman
plots for agreement analysis revealed proportional bias between the BM and the
FP where the BM overestimated sway metrics compared to the FP. Calibration was
used to improve the agreement between the devices. The device demonstrated
consistent sway measurement across varied stance conditions, establishing both
reliability and validity following appropriate calibration.

</details>


### [8] [Max-Min Beamforming for Large-Scale Cell-Free Massive MIMO: A Randomized ADMM Algorithm](https://arxiv.org/abs/2507.18980)
*Bin Wang,Jun Fang,Yue Xiao,Martin Haardt*

Main category: eess.SP

TL;DR: 提出了一种随机ADMM算法，用于解决大规模最大-最小波束成形问题，显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有确定性优化方法在问题规模增大时计算效率低下，需要更高效的解决方案。

Method: 将可行性检查问题转化为线性约束优化问题，并开发随机ADMM算法，每次迭代仅需解决少量子问题。

Result: 算法具有O(1/\bar{t})收敛速度，数值结果显示其复杂度显著优于现有方法。

Conclusion: 随机ADMM算法为大规模MMB问题提供了高效解决方案。

Abstract: We consider the problem of max-min beamforming (MMB) for cell-free massive
multi-input multi-output (MIMO) systems, where the objective is to maximize the
minimum achievable rate among all users. Existing MMB methods are mainly based
on deterministic optimization methods, which are computationally inefficient
when the problem size grows large. To address this issue, we, in this paper,
propose a randomized alternating direction method of multiplier (ADMM)
algorithm for large-scale MMB problems. We first propose a novel formulation
that transforms the highly challenging feasibility-checking problem into a
linearly constrained optimization problem. An efficient randomized ADMM is then
developed for solving the linearly constrained problem. Unlike standard ADMM,
randomized ADMM only needs to solve a small number of subproblems at each
iteration to ensure convergence, thus achieving a substantial complexity
reduction. Our theoretical analysis reveals that the proposed algorithm
exhibits an O(1/\bar{t}) convergence rate (\bar{t} represents the number of
iterations), which is on the same order as its deterministic counterpart.
Numerical results show that the proposed algorithm offers a significant
complexity advantage over existing methods in solving the MMB problem.

</details>


### [9] [Machine Learning based Radio Environment Map Estimation for Indoor Visible Light Communication](https://arxiv.org/abs/2507.19149)
*Helena Serpi,Christina,Politi*

Main category: eess.SP

TL;DR: 提出了一种基于机器学习的创新方法，用于光无线通信中的无线电地图估计，取代了传统的仿真技术。


<details>
  <summary>Details</summary>
Motivation: 传统仿真技术耗时且复杂，需要一种更快速、准确且适用于实时估计的方法。

Method: 采用多层感知器（MLP）建模室内可见光通信（VLC）系统，并通过调整MLP参数（如样本量、训练周期和批量大小）优化性能。

Result: 该方法在仿真和性能预测上表现准确、快速，且所需训练样本量较少，适合实时估计。

Conclusion: 通过调整MLP参数，可以在推理精度和训练时间之间取得平衡，优化模型性能以满足实时需求。

Abstract: An innovative method for radio map estimation in optical wireless
communications is proposed that is based on Machine Learning rather than
simulation techniques. Multi-Layer Perceptron (MLP) representation of indoor
Visible Light Communication (VLC) systems is suggested, and signal propagation
is estimated. The simulation and performance predictions are accurate, fast and
require a reduced set of training sample size with respect to other
counterparts, making this solution very suitable for real time estimation of an
indoor VLC system. It is shown that by tweaking MLP parameters, such as sample
size, number of epochs and batch size, one can balance the desired level of
inference accuracy with training time and optimize the model's performance to
meet real-time requirements.

</details>


### [10] [High-Fidelity RF Mapping: Assessing Environmental Modeling in 6G Network Digital Twins](https://arxiv.org/abs/2507.19173)
*Lorenzo Cazzella,Francesco Linsalata,Damiano Badini,Matteo Matteucci,Maurizio Magarini,Umberto Spagnolini*

Main category: eess.SP

TL;DR: 论文提出了两种度量方法（HRT和CRT），用于比较不同环境建模精度下射线追踪模拟的差异，并通过米兰的高保真数字孪生模型验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 评估环境建模精度对数字孪生（DT）模拟的影响，以确定模型特征对高效和准确模拟的重要性。

Method: 提出HRT和CRT两种度量方法，结合NVIDIA Sionna RT和SUMO模拟器，在28 GHz频率下进行网格和车辆射线追踪模拟。

Result: HRT和CRT成功识别了因环境变化导致的模拟差异，车辆模拟揭示了沿真实轨迹的距离模式。

Conclusion: HRT和CRT是评估环境建模精度对DT模拟影响的有效工具。

Abstract: The design of accurate Digital Twins (DTs) of electromagnetic environments
strictly depends on the fidelity of the underlying environmental modeling.
Evaluating the differences among diverse levels of modeling accuracy is key to
determine the relevance of the model features towards both efficient and
accurate DT simulations. In this paper, we propose two metrics, the Hausdorff
ray tracing (HRT) and chamfer ray tracing (CRT) distances, to consistently
compare the temporal, angular and power features between two ray tracing
simulations performed on 3D scenarios featured by environmental changes. To
evaluate the introduced metrics, we considered a high-fidelity digital twin
model of an area of Milan, Italy and we enriched it with two different types of
environmental changes: (i) the inclusion of parked vehicles meshes, and (ii)
the segmentation of the buildings facade faces to separate the windows mesh
components from the rest of the building. We performed grid-based and vehicular
ray tracing simulations at 28 GHz carrier frequency on the obtained scenarios
integrating the NVIDIA Sionna RT ray tracing simulator with the SUMO vehicular
traffic simulator. Both the HRT and CRT metrics highlighted the areas of the
scenarios where the simulated radio propagation features differ owing to the
introduced mesh integrations, while the vehicular ray tracing simulations
allowed to uncover the distance patterns arising along realistic vehicular
trajectories.

</details>


### [11] [Bespoke multiresolution analysis of graph signals](https://arxiv.org/abs/2507.19181)
*Giacomo Elefante,Gianluca Giacchi,Michael Multerer,Jacopo Quizi*

Main category: eess.SP

TL;DR: 提出了一种基于图信号的多分辨率分析框架，利用样本变换（samplet transform）实现高效压缩和分析，优于传统Haar小波方法。


<details>
  <summary>Details</summary>
Motivation: 传统Haar小波方法在图信号分析中存在局限性，需要一种更灵活且高效的框架来扩展可压缩信号的范围。

Method: 将图划分为多个子图，在欧几里得空间中构建样本变换，再映射回图结构，结合重边聚类和Isomap嵌入实现高效计算。

Result: 方法在鲁棒性、可扩展性和稀疏表示方面表现优异，压缩效率和分辨率保真度显著优于Haar小波。

Conclusion: 样本变换框架为图信号分析提供了更高效的工具，适用于平滑流形上的信号处理。

Abstract: We present a novel framework for discrete multiresolution analysis of graph
signals. The main analytical tool is the samplet transform, originally defined
in the Euclidean framework as a discrete wavelet-like construction, tailored to
the analysis of scattered data. The first contribution of this work is defining
samplets on graphs. To this end, we subdivide the graph into a fixed number of
patches, embed each patch into a Euclidean space, where we construct samplets,
and eventually pull the construction back to the graph. This ensures
orthogonality, locality, and the vanishing moments property with respect to
properly defined polynomial spaces on graphs. Compared to classical Haar
wavelets, this framework broadens the class of graph signals that can
efficiently be compressed and analyzed. Along this line, we provide a
definition of a class of signals that can be compressed using our construction.
We support our findings with different examples of signals defined on graphs
whose vertices lie on smooth manifolds. For efficient numerical implementation,
we combine heavy edge clustering, to partition the graph into meaningful
patches, with landmark \texttt{Isomap}, which provides low-dimensional
embeddings for each patch. Our results demonstrate the method's robustness,
scalability, and ability to yield sparse representations with controllable
approximation error, significantly outperforming traditional Haar wavelet
approaches in terms of compression efficiency and multiresolution fidelity.

</details>


### [12] [Real-time rail vehicle localisation using spatially resolved magnetic field measurements](https://arxiv.org/abs/2507.19327)
*Niklas Dieckow,Katharina Ostaszewski,Philip Heinisch,Henriette Struckmann,Hendrik Ranocha*

Main category: eess.SP

TL;DR: 论文提出了两种基于磁场测量的实时铁路车辆定位方法，结合粒子滤波和序列对齐技术，实现了高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为铁路安全关键应用提供准确、稳定的实时车辆定位解决方案。

Method: 1. 粒子滤波通过磁场相似性重加权，使用重尾非高斯核增强稳定性；2. 无状态序列对齐技术将实时信号转换为空间域并与地图匹配。

Result: 粒子滤波在21.6公里范围内实现5米内精度，但低速和冷启动时性能下降；对齐方法在冷启动时表现优异，92%测试中定位误差小于30米。

Conclusion: 混合方法结合两者优势，适合实时应用，硬件要求低，适用于安全关键铁路场景。

Abstract: This work presents two complementary real-time rail vehicle localization
methods based on magnetic field measurements and a pre-recorded magnetic map.
The first uses a particle filter reweighted via magnetic similarity, employing
a heavy-tailed non-Gaussian kernel for enhanced stability. The second is a
stateless sequence alignment technique that transforms real-time magnetic
signals into the spatial domain and matches them to the map using a similarity
measure. Experiments with operational train data show that the particle filter
achieves track-selective, sub-5-meter accuracy over 21.6 km, though its
performance degrades at low speeds and during cold starts. Accuracy tests were
constrained by the GNSS-based reference system. In contrast, the
alignment-based method excels in cold-start scenarios, localizing within 30 m
in 92 % of tests (100 % using top-3 matches). A hybrid approach combines both
methods$\unicode{x2014}$alignment-based initialization followed by particle
filter tracking. Runtime analysis confirms real-time capability on
consumer-grade hardware. The system delivers accurate, robust localization
suitable for safety-critical rail applications.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [13] [FD-Bench: A Full-Duplex Benchmarking Pipeline Designed for Full Duplex Spoken Dialogue Systems](https://arxiv.org/abs/2507.19040)
*Yizhou Peng,Yi-Wen Chao,Dianwen Ng,Yukun Ma,Chongjia Ni,Bin Ma,Eng Siong Chng*

Main category: eess.AS

TL;DR: 本文提出了一个用于评估全双工对话系统（FDSDS）性能的全面基准测试流程，填补了现有评测中缺乏对用户中断场景评估的空白。


<details>
  <summary>Details</summary>
Motivation: 传统的对话系统依赖轮流对话模式，而全双工系统支持实时中断和反馈，但现有评测缺乏相关指标。

Method: 利用LLMs、TTS和ASR技术，设计了一套评估FDSDS处理用户中断、延迟管理和鲁棒性的新指标。

Result: 测试了三个开源FDSDS模型，结果显示它们在频繁中断和噪声环境下仍存在挑战，如无法响应用户中断。

Conclusion: 提出的基准测试为全双工对话系统的性能评估提供了新工具，揭示了现有模型的不足。

Abstract: Full-duplex spoken dialogue systems (FDSDS) enable more natural human-machine
interactions by allowing real-time user interruptions and backchanneling,
compared to traditional SDS that rely on turn-taking. However, existing
benchmarks lack metrics for FD scenes, e.g., evaluating model performance
during user interruptions. In this paper, we present a comprehensive FD
benchmarking pipeline utilizing LLMs, TTS, and ASR to address this gap. It
assesses FDSDS's ability to handle user interruptions, manage delays, and
maintain robustness in challenging scenarios with diverse novel metrics. We
applied our benchmark to three open-source FDSDS (Moshi, Freeze-omni, and
VITA-1.5) using over 40 hours of generated speech, with 293 simulated
conversations and 1,200 interruptions. The results show that all models
continue to face challenges, such as failing to respond to user interruptions,
under frequent disruptions and noisy conditions. Demonstrations, data, and code
will be released.

</details>


### [14] [Assessment of Personality Dimensions Across Situations Using Conversational Speech](https://arxiv.org/abs/2507.19137)
*Alice Zhang,Skanda Muralidhar,Daniel Gatica-Perez,Mathew Magimai-Doss*

Main category: eess.AS

TL;DR: 研究发现，用户偏好与自身性格匹配的辅助技术。自动性格感知（APP）研究通常将性格视为静态特质，但实际性格感知会因情境变化。本研究探讨了两种工作情境下（中性面试和压力客户互动）对话语音与感知性格的关系。


<details>
  <summary>Details</summary>
Motivation: 探索性格感知的动态性，验证情境对性格感知的影响。

Method: 分析中性面试和压力客户互动中的对话语音，提取声学和非语言特征，比较不同情境下的性格感知差异。

Result: 1) 性格感知因情境显著不同；2) 不同情境下声学特征与性格特质相关；3) 手工特征优于说话人嵌入；4) 压力情境更能预测神经质。

Conclusion: 性格感知是动态的，情境对性格感知有显著影响，声学和非语言特征是有效的预测指标。

Abstract: Prior research indicates that users prefer assistive technologies whose
personalities align with their own. This has sparked interest in automatic
personality perception (APP), which aims to predict an individual's perceived
personality traits. Previous studies in APP have treated personalities as
static traits, independent of context. However, perceived personalities can
vary by context and situation as shown in psychological research. In this
study, we investigate the relationship between conversational speech and
perceived personality for participants engaged in two work situations (a
neutral interview and a stressful client interaction). Our key findings are: 1)
perceived personalities differ significantly across interactions, 2) loudness,
sound level, and spectral flux features are indicative of perceived
extraversion, agreeableness, conscientiousness, and openness in neutral
interactions, while neuroticism correlates with these features in stressful
contexts, 3) handcrafted acoustic features and non-verbal features outperform
speaker embeddings in inference of perceived personality, and 4) stressful
interactions are more predictive of neuroticism, aligning with existing
psychological research.

</details>


### [15] [Should Top-Down Clustering Affect Boundaries in Unsupervised Word Discovery?](https://arxiv.org/abs/2507.19204)
*Simon Malan,Benjamin van Niekerk,Herman Kamper*

Main category: eess.AS

TL;DR: 论文研究了如何将未标记的语音分割为类似单词的单元并聚类形成词典。比较了自底向上和自顶向下两种方法，发现两者性能相当，但自底向上方法更快。聚类步骤是性能瓶颈，建议未来研究改进聚类技术和学习更具区分性的表示。


<details>
  <summary>Details</summary>
Motivation: 探索自顶向下信息是否对语音分割改进必要，比较两种方法的效果。

Method: 自底向上方法基于相邻自监督特征的差异预测边界并聚类；自顶向下方法使用ES-KMeans动态规划迭代更新边界。

Result: 两种方法在ZeroSpeech基准测试中性能相当，自底向上方法快五倍。聚类步骤是性能瓶颈。

Conclusion: 自顶向下方法在某些情况下有益，但自底向上方法通常足够。未来应改进聚类技术和表示学习。

Abstract: We investigate the problem of segmenting unlabeled speech into word-like
units and clustering these to create a lexicon. Prior work can be categorized
into two frameworks. Bottom-up methods first determine boundaries and then
cluster the fixed segmented words into a lexicon. In contrast, top-down methods
incorporate information from the clustered words to inform boundary selection.
However, it is unclear whether top-down information is necessary to improve
segmentation. To explore this, we look at two similar approaches that differ in
whether top-down clustering informs boundary selection. Our simple bottom-up
strategy predicts word boundaries using the dissimilarity between adjacent
self-supervised features, then clusters the resulting segments to construct a
lexicon. Our top-down system is an updated version of the ES-KMeans dynamic
programming method that iteratively uses K-means to update its boundaries. On
the five-language ZeroSpeech benchmarks, both approaches achieve comparable
state-of-the-art results, with the bottom-up system being nearly five times
faster. Through detailed analyses, we show that the top-down influence of
ES-KMeans can be beneficial (depending on factors like the candidate
boundaries), but in many cases the simple bottom-up method performs just as
well. For both methods, we show that the clustering step is a limiting factor.
Therefore, we recommend that future work focus on improved clustering
techniques and learning more discriminative word-like representations. Project
code repository: https://github.com/s-malan/prom-seg-clus.

</details>


### [16] [Comparison of Knowledge Distillation Methods for Low-complexity Multi-microphone Speech Enhancement using the FT-JNF Architecture](https://arxiv.org/abs/2507.19208)
*Robert Metzger,Mattes Ohlenbusch,Christian Rollwage,Simon Doclo*

Main category: eess.AS

TL;DR: 多麦克风语音增强的DNN方法近年来进展显著，但资源受限设备难以实现。知识蒸馏（KD）可减小模型尺寸并保持性能。本文评估了五种KD方法，实验表明三种方法显著提升学生模型性能，25%参数的模型在0 dB SNR下PESQ分数接近教师模型。


<details>
  <summary>Details</summary>
Motivation: 解决DNN语音增强算法在资源受限设备上的实现问题，通过知识蒸馏减小模型尺寸并保持性能。

Method: 采用频率-时间联合非线性滤波器（FT-JNF）架构，评估五种知识蒸馏方法，包括直接输出匹配、中间层自相似性和融合多层损失。

Result: 实验表明，三种KD方法显著提升学生模型性能，25%参数的模型在0 dB SNR下PESQ分数接近教师模型，模型尺寸最多可减少96%且PESQ分数下降极小。

Conclusion: 知识蒸馏是减小DNN模型尺寸并保持性能的有效方法，适用于资源受限设备。

Abstract: Multi-microphone speech enhancement using deep neural networks (DNNs) has
significantly progressed in recent years. However, many proposed DNN-based
speech enhancement algorithms cannot be implemented on devices with limited
hardware resources. Only lowering the complexity of such systems by reducing
the number of parameters often results in worse performance. Knowledge
Distillation (KD) is a promising approach for reducing DNN model size while
preserving performance. In this paper, we consider the recently proposed
Frequency-Time Joint Non-linear Filter (FT-JNF) architecture and investigate
several KD methods to train smaller (student) models from a large pre-trained
(teacher) model. Five KD methods are evaluated using direct output matching,
the self-similarity of intermediate layers, and fused multi-layer losses.
Experimental results on a simulated dataset using a compact array with five
microphones show that three KD methods substantially improve the performance of
student models compared to training without KD. A student model with only 25%
of the teacher model's parameters achieves comparable PESQ scores at 0 dB SNR.
Furthermore, a reduction of up to 96% in model size can be achieved with only a
minimal decrease in PESQ scores.

</details>


### [17] [Binaural Target Speaker Extraction using HRTFs and a Complex-Valued Neural Network](https://arxiv.org/abs/2507.19369)
*Yoav Ellinson,Sharon Gannot*

Main category: eess.AS

TL;DR: 提出了一种利用HRTF的双耳目标说话人提取方法，无需说话人嵌入，具有强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 模仿人类在多人同时说话时选择性关注单一说话人的能力。

Method: 使用全复数神经网络直接处理复数STFT，避免传统方法的分量分离处理。

Result: 在无噪声和轻度混响环境下均表现优异，保持目标信号的双耳线索和方向性。

Conclusion: 该方法在多种语言数据集上具有强泛化能力，且能有效减少混响。

Abstract: In this work, we aim to imitate the human ability to selectively attend to a
single speaker, even in the presence of multiple simultaneous talkers. We
propose a novel approach for binaural target speaker extraction that leverages
the listener's Head-Related Transfer Function (HRTF) to isolate the desired
speaker. Notably, our method does not rely on speaker embeddings, making it
speaker-independent and enabling strong generalization across multiple speech
datasets in different languages.
  We employ a fully complex-valued neural network that operates directly on the
complex-valued Short-Time Fourier Transform (STFT) of the mixed audio signals.
This deviates from conventional approaches that use spectrograms or treat the
real and imaginary components of the STFT as separate real-valued inputs.
  We first evaluate the method in an anechoic, noise-free scenario, where it
demonstrates excellent extraction performance while effectively preserving the
binaural cues of the target signal. We then test a modified variant under mild
reverberation conditions. This version remains robust in reverberant
environments, maintaining speech clarity, preserving source directionality, and
simultaneously reducing reverberation.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [18] [SCORE-SET: A dataset of GuitarPro files for Music Phrase Generation and Sequence Learning](https://arxiv.org/abs/2507.18723)
*Vishakh Begari*

Main category: cs.SD

TL;DR: 提供专为吉他音乐生成、序列建模和性能感知学习任务定制的Guitar Pro文件数据集。


<details>
  <summary>Details</summary>
Motivation: 为吉他音乐生成和建模任务提供更贴近真实演奏的数据集，包含丰富的吉他表现技巧。

Method: 从MAESTRO和GiantMIDI的MIDI音符中提取节奏吉他音轨，并添加吉他表现技巧（如弯音、滑音、颤音等）。

Result: 生成了一个包含多种吉他表现技巧的数据集，更真实地模拟吉他演奏。

Conclusion: 该数据集为吉他音乐生成和建模任务提供了更丰富、更真实的数据支持。

Abstract: A curated dataset of Guitar Pro tablature files (.gp5 format), tailored for
tasks involving guitar music generation, sequence modeling, and
performance-aware learning is provided. The dataset is derived from MIDI notes
in MAESTRO and GiantMIDI which have been adapted into rhythm guitar tracks.
These tracks are further processed to include a variety of expression settings
typical of guitar performance, such as bends, slides, vibrato, and palm muting,
to better reflect the nuances of real-world guitar playing.

</details>


### [19] [HH-Codec: High Compression High-fidelity Discrete Neural Codec for Spoken Language Modeling](https://arxiv.org/abs/2507.18897)
*Rongkun Xue,Yazhe Niu,Shuai Hu,Zixin Yin,Yongqiang Yao,Jing Yang*

Main category: cs.SD

TL;DR: HH-Codec是一种神经编解码器，通过单量化器推理实现24 kHz音频的极端压缩（24 tokens/秒），并在0.3 kbps的超低带宽下实现最先进的语音重建性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模语音到语音系统中多量化器并行流复杂性和高时间维度编解码器计算成本的问题。

Method: 设计了优化的向量量化空间，采用不对称编码器-解码器架构（Audio-VQ-Mel-Audio），结合双重监督和渐进训练提升重建稳定性和保真度。

Result: 在0.3 kbps带宽下实现最优语音重建，并在代码本利用率和生成模型适应性方面表现优异。

Conclusion: HH-Codec通过模块化设计和优化，显著提升了压缩效率和语音质量，适用于大规模语音系统。

Abstract: Discrete speech tokenization is a fundamental component in speech codecs.
However, in large-scale speech-to-speech systems, the complexity of parallel
streams from multiple quantizers and the computational cost of
high-time-dimensional codecs pose significant challenges. In this paper, we
introduce HH-Codec, a neural codec that achieves extreme compression at 24
tokens per second for 24 kHz audio while relying on single-quantizer inference.
Our approach involves a carefully designed Vector Quantization space for Spoken
Language Modeling, optimizing compression efficiency while minimizing
information loss. Building on this, we propose an asymmetric encoder-decoder
architecture (Audio-VQ-Mel-Audio) that leverages dual supervision and
progressive training to enhance reconstruction stability and fidelity. HH-Codec
achieves state-of-the-art performance in speech reconstruction with an
ultra-low bandwidth of 0.3 kbps. We further evaluate its effectiveness in
codebook utilization and generative model adaptation, with extensive ablations
validating the necessity of each module. HH-Codec is available at
https://github.com/opendilab/HH-Codec.

</details>


### [20] [MLLM-based Speech Recognition: When and How is Multimodality Beneficial?](https://arxiv.org/abs/2507.19037)
*Yiwen Guan,Viet Anh Trinh,Vivek Voleti,Jacob Whitehill*

Main category: cs.SD

TL;DR: 多模态大语言模型（MLLMs）在噪声环境中提升语音识别（ASR）准确性的条件和架构研究。


<details>
  <summary>Details</summary>
Motivation: 探索多模态输入在噪声环境下如何提升ASR准确性，以弥补单一模态的不足。

Method: 通过合成和真实数据实验，分析不同模态（如语音、文本、图像）对ASR的影响。

Result: 多模态通常提升ASR准确性，但效果依赖于噪声水平；同步与非同步模态在不同噪声水平下效果不同；视觉表征质量对ASR至关重要。

Conclusion: 研究为多模态语音识别提供了实用见解，并深化了对挑战性条件下多模态作用的理解。

Abstract: Recent advances in multi-modal large language models (MLLMs) have opened new
possibilities for unified modeling of speech, text, images, and other
modalities. Building on our prior work, this paper examines the conditions and
model architectures under which multiple input modalities can improve automatic
speech recognition (ASR) accuracy in noisy environments. Through experiments on
synthetic and real-world data, we find that (1) harnessing more modalities
usually improves ASR accuracy, as each modality provides complementary
information, but the improvement depends on the amount of auditory noise. (2)
Synchronized modalities (e.g., lip movements) are more useful at high noise
levels whereas unsynchronized modalities (e.g., image context) are most helpful
at moderate noise levels. (3) Higher-quality visual representations
consistently improve ASR accuracy, highlighting the importance of developing
more powerful visual encoders. (4) Mamba exhibits similar trends regarding the
benefits of multimodality as do Transformers. (5) The input order of modalities
as well as their weights in the loss function can significantly impact
accuracy. These findings both offer practical insights and help to deepen our
understanding of multi-modal speech recognition under challenging conditions.

</details>


### [21] [From Continuous to Discrete: Cross-Domain Collaborative General Speech Enhancement via Hierarchical Language Models](https://arxiv.org/abs/2507.19062)
*Zhaoxi Mu,Rilin Chen,Andong Li,Meng Yu,Xinyu Yang,Dong Yu*

Main category: cs.SD

TL;DR: OmniGSE是一个新颖的通用语音增强框架，通过两阶段架构结合判别式和生成式方法，有效处理多种语音失真。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常只针对单一失真优化，难以应对复杂场景中的多重失真问题。

Method: 采用两阶段架构：第一阶段使用轻量级NAC-RoFormer增强连续特征；第二阶段通过分层语言模型（RootLM和BranchLMs）生成离散标记以重建高质量语音。

Result: 在多个基准测试中表现优异，尤其在复合失真场景下超越现有模型。

Conclusion: OmniGSE展示了在真实场景中实现稳健且多功能语音增强的潜力。

Abstract: This paper introduces OmniGSE, a novel general speech enhancement (GSE)
framework designed to mitigate the diverse distortions that speech signals
encounter in real-world scenarios. These distortions include background noise,
reverberation, bandwidth limitations, signal clipping, and network packet loss.
Existing methods typically focus on optimizing for a single type of distortion,
often struggling to effectively handle the simultaneous presence of multiple
distortions in complex scenarios. OmniGSE bridges this gap by integrating the
strengths of discriminative and generative approaches through a two-stage
architecture that enables cross-domain collaborative optimization. In the first
stage, continuous features are enhanced using a lightweight channel-split
NAC-RoFormer. In the second stage, discrete tokens are generated to reconstruct
high-quality speech through language models. Specifically, we designed a
hierarchical language model structure consisting of a RootLM and multiple
BranchLMs. The RootLM models general acoustic features across codebook layers,
while the BranchLMs explicitly capture the progressive relationships between
different codebook levels. Experimental results demonstrate that OmniGSE
surpasses existing models across multiple benchmarks, particularly excelling in
scenarios involving compound distortions. These findings underscore the
framework's potential for robust and versatile speech enhancement in real-world
applications.

</details>


### [22] [Latent Granular Resynthesis using Neural Audio Codecs](https://arxiv.org/abs/2507.19202)
*Nao Tokui,Tom Baker*

Main category: cs.SD

TL;DR: 提出了一种基于潜在向量粒度的音频重合成技术，通过构建“粒度码本”匹配目标音频的潜在颗粒，实现保留目标时间结构的同时融合源音色特征。


<details>
  <summary>Details</summary>
Motivation: 解决传统拼接合成中的不连续性问题，同时无需模型训练即可适应多样音频材料。

Method: 将源音频编码为潜在向量段构建码本，匹配目标音频的潜在颗粒并解码生成混合音频。

Result: 生成的音频保留了目标的时间结构，同时具有源音色的特征，避免了传统方法的不连续性。

Conclusion: 该技术为音频重合成提供了一种高效且灵活的方法，适用于多种音频材料。

Abstract: We introduce a novel technique for creative audio resynthesis that operates
by reworking the concept of granular synthesis at the latent vector level. Our
approach creates a "granular codebook" by encoding a source audio corpus into
latent vector segments, then matches each latent grain of a target audio signal
to its closest counterpart in the codebook. The resulting hybrid sequence is
decoded to produce audio that preserves the target's temporal structure while
adopting the source's timbral characteristics. This technique requires no model
training, works with diverse audio materials, and naturally avoids the
discontinuities typical of traditional concatenative synthesis through the
codec's implicit interpolation during decoding. We include supplementary
material at https://github.com/naotokui/latentgranular/ , as well as a
proof-of-concept implementation to allow users to experiment with their own
sounds at https://huggingface.co/spaces/naotokui/latentgranular .

</details>


### [23] [Face2VoiceSync: Lightweight Face-Voice Consistency for Text-Driven Talking Face Generation](https://arxiv.org/abs/2507.19225)
*Fang Kang,Yin Cao,Haoyu Chen*

Main category: cs.SD

TL;DR: 论文提出Face2VoiceSync框架，解决语音驱动的人脸动画生成中的固定语音限制问题，实现从人脸图像和文本生成同步的语音和动画。


<details>
  <summary>Details</summary>
Motivation: 现有语音驱动的人脸动画生成方法依赖固定语音，限制了应用（如人脸-语音不匹配）。因此，论文扩展任务至更具挑战性的设置：从人脸图像和文本生成同步的语音和动画。

Method: 提出Face2VoiceSync框架，包括：1) 语音-人脸对齐；2) 多样性与操控；3) 高效训练；4) 新评估指标。

Result: 实验表明，Face2VoiceSync在视觉和音频性能上均达到最先进水平，且仅需单个40GB GPU。

Conclusion: Face2VoiceSync成功解决了语音驱动人脸动画生成的限制，实现了高效且多样化的语音和动画同步生成。

Abstract: Recent studies in speech-driven talking face generation achieve promising
results, but their reliance on fixed-driven speech limits further applications
(e.g., face-voice mismatch). Thus, we extend the task to a more challenging
setting: given a face image and text to speak, generating both talking face
animation and its corresponding speeches. Accordingly, we propose a novel
framework, Face2VoiceSync, with several novel contributions: 1) Voice-Face
Alignment, ensuring generated voices match facial appearance; 2) Diversity \&
Manipulation, enabling generated voice control over paralinguistic features
space; 3) Efficient Training, using a lightweight VAE to bridge visual and
audio large-pretrained models, with significantly fewer trainable parameters
than existing methods; 4) New Evaluation Metric, fairly assessing the diversity
and identity consistency. Experiments show Face2VoiceSync achieves both visual
and audio state-of-the-art performances on a single 40GB GPU.

</details>


### [24] [The Eloquence team submission for task 1 of MLC-SLM challenge](https://arxiv.org/abs/2507.19308)
*Lorenzo Concina,Jordi Luque,Alessio Brutti,Marco Matassoni,Yuchen Zhang*

Main category: cs.SD

TL;DR: 本文研究了多语言对话语音识别任务，通过评估基线、训练自定义多语言线性投影器以及探索对比学习和扩展对话上下文的作用，提出了三种方法。


<details>
  <summary>Details</summary>
Motivation: 随着现实世界对话数据在构建鲁棒口语对话系统中的重要性增加，研究多语言ASR的需求日益突出。

Method: 1. 评估官方基线并训练两种投影器（线性和qformer）；2. 使用SLAM-ASR框架训练自定义多语言线性投影器；3. 研究对比学习和扩展对话上下文的作用。

Result: 通过实验验证了三种方法的有效性，提升了多语言对话语音识别的鲁棒性。

Conclusion: 本文提出的方法为多语言对话语音识别任务提供了新的思路和技术支持。

Abstract: In this paper, we present our studies and experiments carried out for the
task 1 of the Challenge and Workshop on Multilingual Conversational Speech
Language Model (MLC-SLM), which focuses on advancing multilingual
conversational speech recognition through the development of speech language
models architectures. Given the increasing relevance of real-world
conversational data for building robust Spoken Dialogue Systems, we explore
three approaches to multilingual ASR. First, we conduct an evaluation of the
official baseline to better understand its strengths and limitations, by
training two projectors (linear and qformer) with different foundation models.
Second we leverage the SLAM-ASR framework to train a custom multilingual linear
projector. Finally we investigate the role of contrastive learning and the
extended conversational context in enhancing the robustness of recognition.

</details>

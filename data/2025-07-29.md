<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 23]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SD](#cs.SD) [Total: 14]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Multipath Interference Suppression in Indirect Time-of-Flight Imaging via a Novel Compressed Sensing Framework](https://arxiv.org/abs/2507.19546)
*Yansong Du,Yutong Deng,Yuting Zhou,Feiyu Jiao,Bangyao Wang,Zhancong Xu,Zhaoxiang Jiang,Xun Guan*

Main category: eess.SP

TL;DR: 提出一种新型压缩感知方法，提升间接飞行时间（iToF）系统的深度重建精度和多目标分离能力，无需硬件改动。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖硬件修改、复杂调制或繁琐的数据驱动重建，而新方法旨在简化过程并提高性能。

Method: 使用单一调制频率，通过多相位偏移和窄占空比连续波构建感知矩阵，并考虑镜头畸变导致的像素级距离变化。采用K-Means聚类优化稀疏恢复。

Result: 实验表明，该方法在重建精度和鲁棒性上优于传统方法。

Conclusion: 新方法无需硬件改动即可显著提升iToF系统的性能。

Abstract: We propose a novel compressed sensing method to improve the depth
reconstruction accuracy and multi-target separation capability of indirect
Time-of-Flight (iToF) systems. Unlike traditional approaches that rely on
hardware modifications, complex modulation, or cumbersome data-driven
reconstruction, our method operates with a single modulation frequency and
constructs the sensing matrix using multiple phase shifts and narrow-duty-cycle
continuous waves. During matrix construction, we further account for pixel-wise
range variation caused by lens distortion, making the sensing matrix better
aligned with actual modulation response characteristics. To enhance sparse
recovery, we apply K-Means clustering to the distance response dictionary and
constrain atom selection within each cluster during the OMP process, which
effectively reduces the search space and improves solution stability.
Experimental results demonstrate that the proposed method outperforms
traditional approaches in both reconstruction accuracy and robustness, without
requiring any additional hardware changes.

</details>


### [2] [Coverage Probability and Average Rate Analysis of Hybrid Cellular and Cell-free Network](https://arxiv.org/abs/2507.19763)
*Zhuoyin Dai,Jingran Xu,Xiaoli Xu,Ruoguang Li,Yong Zeng,Jiangbin Lyu*

Main category: eess.SP

TL;DR: 本文提出了一种基于随机几何的混合蜂窝和无小区网络模型，分析了信号和干扰的分布及其耦合关系，并推导了覆盖概率和平均可实现速率。


<details>
  <summary>Details</summary>
Motivation: 探索混合蜂窝和无小区网络（HCCNs）的性能极限，以弥合传统蜂窝网络与创新无小区网络之间的差距。

Method: 采用共轭波束成形设计，利用矩匹配分析聚合信号，并通过推导干扰分量的拉普拉斯变换及其高阶导数来表征覆盖概率。

Result: 揭示了信号与干扰的耦合关系，并推导了混合网络在信道衰落下的平均可实现速率。

Conclusion: HCCNs是推进无小区网络发展的实用可行方案，其性能分析为未来网络部署提供了理论支持。

Abstract: Cell-free wireless networks deploy distributed access points (APs) to
simultaneously serve user equipments (UEs) across the service region and are
regarded as one of the most promising network architectural paradigms. Despite
recent advances in the performance analysis and optimization of cellfree
wireless networks, it remains an open question whether large-scale deployment
of APs in existing wireless networks can cost-effectively achieve communication
capacity growth. Besides, the realization of a cell-free network is considered
to be a gradual long-term evolutionary process in which cell-free APs will be
incrementally introduced into existing cellular networks, and form a hybrid
communication network with the existing cellular base stations (BSs). Such a
collaboration will bridge the gap between the established cellular network and
the innovative cellfree network. Therefore, hybrid cellular and cell-free
networks (HCCNs) emerge as a practical and feasible solution for advancing
cell-free network development, and it is worthwhile to further explore its
performance limits. This paper presents a stochastic geometry-based hybrid
cellular and cell-free network model to analyze the distributions of signal and
interference and reveal their mutual coupling. Specifically, in order to
benefit the UEs from both the cellular BSs and the cell-free APs, a conjugate
beamforming design is employed, and the aggregated signal is analyzed using
moment matching. Then, the coverage probability of the hybrid network is
characterized by deriving the Laplace transforms and their higher-order
derivatives of interference components. Furthermore, the average achievable
rate of the hybrid network over channel fading is derived based on the
interference coupling analysis.

</details>


### [3] [Radar and Acoustic Sensor Fusion using a Transformer Encoder for Robust Drone Detection and Classification](https://arxiv.org/abs/2507.19785)
*Gevindu Ganganath,Pasindu Sankalpa,Samal Punsara,Demitha Pasindu,Chamira U. S. Edussooriya,Ranga Rodrigo,Udaya S. K. P. Miriya Thanthrige*

Main category: eess.SP

TL;DR: 提出了一种结合雷达和声学传感的多模态方法，用于无人机的检测与分类，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 无人机应用广泛，但未经授权的入侵引发安全问题，需要高效检测与分类方法。

Method: 结合雷达（远距离、全天候）和原始声学信号（减少参数），使用Transformer编码器融合传感器。

Result: 户外实验验证了该方法优于现有技术。

Conclusion: 多模态方法在无人机检测与分类中表现出色。

Abstract: The use of drones in a wide range of applications is steadily increasing.
However, this has also raised critical security concerns such as unauthorized
drone intrusions into restricted zones. Therefore, robust and accurate drone
detection and classification mechanisms are required despite significant
challenges due to small size of drones, low-altitude flight, and environmental
noise. In this letter, we propose a multi-modal approach combining radar and
acoustic sensing for detecting and classifying drones. We employ radar due to
its long-range capabilities, and robustness to different weather conditions. We
utilize raw acoustic signals without converting them to other domains such as
spectrograms or Mel-frequency cepstral coefficients. This enables us to use
fewer number of parameters compared to the stateof-the-art approaches.
Furthermore, we explore the effectiveness of the transformer encoder
architecture in fusing these sensors. Experimental results obtained in outdoor
settings verify the superior performance of the proposed approach compared to
the state-of-the-art methods.

</details>


### [4] [Channel Estimation in Massive MIMO Systems with Orthogonal Delay-Doppler Division Multiplexing](https://arxiv.org/abs/2507.19812)
*Dezhi Wang,Chongwen Huang,Xiaojun Yuan,Sami Muhaidat,Lei Liu,Xiaoming Chen,Zhaoyang Zhang,Chau Yuen,Mérouane Debbah*

Main category: eess.SP

TL;DR: 提出了一种基于MAMP的低复杂度算法，用于大规模MIMO-ODDM系统中的信道估计，显著提高了估计精度。


<details>
  <summary>Details</summary>
Motivation: 在高移动性环境下，大规模MIMO-ODDM系统的信道估计面临复杂性和准确性的挑战。

Method: 建立有效的信道模型，利用MAMP方法估计多径信道的增益、延迟和多普勒效应，并通过离散傅里叶变换估计信道角度。

Result: 数值结果表明，该算法在无限天线数时接近贝叶斯最优结果，归一化均方误差比现有算法提高约30%。

Conclusion: 提出的算法在高移动性大规模MIMO-ODDM系统中具有高效性和准确性。

Abstract: Orthogonal delay-Doppler division multiplexing~(ODDM) modulation has recently
been regarded as a promising technology to provide reliable communications in
high-mobility situations. Accurate and low-complexity channel estimation is one
of the most critical challenges for massive multiple input multiple
output~(MIMO) ODDM systems, mainly due to the extremely large antenna arrays
and high-mobility environments. To overcome these challenges, this paper
addresses the issue of channel estimation in downlink massive MIMO-ODDM systems
and proposes a low-complexity algorithm based on memory approximate message
passing~(MAMP) to estimate the channel state information~(CSI). Specifically,
we first establish the effective channel model of the massive MIMO-ODDM
systems, where the magnitudes of the elements in the equivalent channel vector
follow a Bernoulli-Gaussian distribution. Further, as the number of antennas
grows, the elements in the equivalent coefficient matrix tend to become
completely random. Leveraging these characteristics, we utilize the MAMP method
to determine the gains, delays, and Doppler effects of the multi-path channel,
while the channel angles are estimated through the discrete Fourier transform
method. Finally, numerical results show that the proposed channel estimation
algorithm approaches the Bayesian optimal results when the number of antennas
tends to infinity and improves the channel estimation accuracy by about 30%
compared with the existing algorithms in terms of the normalized mean square
error.

</details>


### [5] [Feature Engineering for Wireless Communications and Networking: Concepts, Methodologies, and Applications](https://arxiv.org/abs/2507.19837)
*Jiacheng Wang,Changyuan Zhao,Zehui Xiong,Tao Xiang,Dusit Niyato,Xianbin Wang,Shiwen Mao,Dong In Kim*

Main category: eess.SP

TL;DR: 本文全面研究了AI驱动的无线通信中的特征工程技术，重点分析了其基本原理、方法及其在低空ISAC网络中的应用，并提出了一种基于生成AI的框架以应对恶意攻击下的信号特征谱重建。


<details>
  <summary>Details</summary>
Motivation: 随着AI在无线通信中的广泛应用，特征工程技术成为关键，尤其是在低空ISAC网络中，需要有效处理原始数据以支持AI模型。

Method: 论文首先分析了特征工程的基本原理和方法，随后探讨了其在无线通信系统中的应用，并提出了一个生成AI框架用于信号特征谱重建。

Result: 案例研究表明，该框架能有效重建信号谱，平均结构相似性指数提升了4%。

Conclusion: 该研究为AI驱动的无线通信系统提供了有效的特征工程技术，尤其在低空ISAC网络中具有重要应用价值。

Abstract: AI-enabled wireless communications have attracted tremendous research
interest in recent years, particularly with the rise of novel paradigms such as
low-altitude integrated sensing and communication (ISAC) networks. Within these
systems, feature engineering plays a pivotal role by transforming raw wireless
data into structured representations suitable for AI models. Hence, this paper
offers a comprehensive investigation of feature engineering techniques in
AI-driven wireless communications. Specifically, we begin with a detailed
analysis of fundamental principles and methodologies of feature engineering.
Next, we present its applications in wireless communication systems, with
special emphasis on ISAC networks. Finally, we introduce a generative AI-based
framework, which can reconstruct signal feature spectrum under malicious
attacks in low-altitude ISAC networks. The case study shows that it can
effectively reconstruct the signal spectrum, achieving an average structural
similarity index improvement of 4%, thereby supporting downstream sensing and
communication applications.

</details>


### [6] [Toward Dual-Functional LAWN: Control-Aware System Design for Aerodynamics-Aided UAV Formations](https://arxiv.org/abs/2507.19910)
*Jun Wu,Weijie Yuan,Qingqing Cheng,Haijia Jin*

Main category: eess.SP

TL;DR: 本文提出了一种基于ATC扩散LMS算法的分布式节能无人机编队框架，用于双功能低空无线网络中的能量优化和感知任务。


<details>
  <summary>Details</summary>
Motivation: 研究低空无线网络中无人机编队的节能设计，以提升飞行续航能力并同时完成通信与感知任务。

Method: 利用空气动力学上升效应，提出分布式节能编队框架，结合ATC扩散LMS算法和最大LQR最小化问题，并通过SCA和SDR技术求解。

Result: 仿真结果表明，'V'形编队是最节能的配置，且所提设计在控制性能上优于基准方案。

Conclusion: 该研究为双功能低空无线网络中的无人机编队节能设计提供了有效解决方案。

Abstract: Integrated sensing and communication (ISAC) has emerged as a pivotal
technology for advancing low-altitude wireless networks (LAWNs), serving as a
critical enabler for next-generation communication systems. This paper
investigates the system design for energy-saving unmanned aerial vehicle (UAV)
formations in dual-functional LAWNs, where a ground base station (GBS)
simultaneously wirelessly controls multiple UAV formations and performs sensing
tasks. To enhance flight endurance, we exploit the aerodynamic upwash effects
and propose a distributed energy-saving formation framework based on the
adapt-then-combine (ATC) diffusion least mean square (LMS) algorithm.
Specifically, each UAV updates the local position estimate by invoking the LMS
algorithm, followed by refining it through cooperative information exchange
with neighbors. This enables an optimized aerodynamic structure that minimizes
the formation's overall energy consumption. To ensure control stability and
fairness, we formulate a maximum linear quadratic regulator (LQR) minimization
problem, which is subject to both the available power budget and the required
sensing beam pattern gain. To address this non-convex problem, we develop a
two-step approach by first deriving a closed-form expression of LQR as a
function of arbitrary beamformers. Subsequently, an efficient iterative
algorithm that integrates successive convex approximation (SCA) and
semidefinite relaxation (SDR) techniques is proposed to obtain a sub-optimal
dual-functional beamforming solution. Extensive simulation results confirm that
the 'V'-shaped formation is the most energy-efficient configuration and
demonstrate the superiority of our proposed design over benchmark schemes in
improving control performance.

</details>


### [7] [Deep Learning Based Joint Channel Estimation and Positioning for Sparse XL-MIMO OFDM Systems](https://arxiv.org/abs/2507.19936)
*Zhongnian Li,Chao Zheng,Jian Xiao,Ji Wang,Gongpu Wang,Ming Zeng,Octavia A. Dobre*

Main category: eess.SP

TL;DR: 论文提出了一种基于深度学习的两阶段框架（CP-Mamba），用于近场稀疏超大规模MIMO-OFDM系统中的联合信道估计与定位，性能优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 在近场稀疏超大规模MIMO-OFDM系统中，联合信道估计与定位的协同增益尚未充分探索，因此提出一种高效的两阶段框架。

Method: 采用深度学习的两阶段框架：定位阶段预测用户坐标，信道估计阶段利用坐标提升精度；提出CP-Mamba网络，结合Mamba模型和U形卷积网络优势。

Result: 数值仿真表明，CP-Mamba框架在信道估计和定位精度上优于现有方法，稀疏阵列性能显著优于紧凑阵列。

Conclusion: 提出的两阶段框架和CP-Mamba网络有效提升了联合信道估计与定位的性能，稀疏阵列具有显著优势。

Abstract: This paper investigates joint channel estimation and positioning in
near-field sparse extra-large multiple-input multiple-output (XL-MIMO)
orthogonal frequency division multiplexing (OFDM) systems. To achieve
cooperative gains between channel estimation and positioning, we propose a deep
learning-based two-stage framework comprising positioning and channel
estimation. In the positioning stage, the user's coordinates are predicted and
utilized in the channel estimation stage, thereby enhancing the accuracy of
channel estimation. Within this framework, we propose a U-shaped Mamba
architecture for channel estimation and positioning, termed as CP-Mamba. This
network integrates the strengths of the Mamba model with the structural
advantages of U-shaped convolutional networks, enabling effective capture of
local spatial features and long-range temporal dependencies of the channel.
Numerical simulation results demonstrate that the proposed two-stage approach
with CP-Mamba architecture outperforms existing baseline methods. Moreover,
sparse arrays (SA) exhibit significantly superior performance in both channel
estimation and positioning accuracy compared to conventional compact arrays.

</details>


### [8] [Dependability Theory-based Statistical QoS Provisioning of Fluid Antenna Systems](https://arxiv.org/abs/2507.19984)
*Irfan Muhammad,Priyadarshi Mukherjee,Wee Kiat New,Hirley Alves,Ioannis Krikidis,Kai-Kit Wong*

Main category: eess.SP

TL;DR: 提出了一种基于可靠性理论的框架，用于在有限块长度约束下为流体天线系统（FAS）提供统计服务质量（QoS）保障，并定义了新的可靠性指标和能效度量。


<details>
  <summary>Details</summary>
Motivation: 现有研究常忽略信道衰落的时域动态特性及其对关键任务操作的影响，因此需要一种新框架来量化FAS的可靠性。

Method: 推导了N端口FAS在Nakagami-m衰落信道下的闭合表达式，定义了任务可靠性和首次故障平均时间（MTTFF）等指标，并扩展了有效容量（EC）和能效度量（mEEE）。

Result: 通过仿真揭示了端口数量、QoS指数、信噪比和任务持续时间之间的关键权衡，为超可靠、低延迟和高能效的工业物联网（IIoT）系统设计提供了见解。

Conclusion: 提出的框架和指标为FAS在关键任务场景中的可靠性评估和优化提供了有效工具。

Abstract: Fluid antenna systems (FAS) have recently emerged as a promising technology
for next-generation wireless networks, offering real-time spatial
reconfiguration to enhance reliability, throughput, and energy efficiency.
Nevertheless, existing studies often overlook the temporal dynamics of channel
fading and their implications for mission-critical operations. In this paper,
we propose a dependability-theoretic framework for statistical
quality-of-service (QoS) provisioning of FAS under finite blocklength (FBL)
constraints. Specifically, we derive new closed-form expressions for the
level-crossing rate (LCR) and average fade duration (AFD) of an $N$-port FAS
over Nakagami-$m$ fading channels. Leveraging these second-order statistics, we
define two key dependability metrics such as mission reliability and mean
time-to-first-failure (MTTFF), to quantify the probability of uninterrupted
operation over a defined mission duration. We further extend the classical
effective capacity (EC) concept to incorporate mission reliability in the FBL
regime, yielding a mission EC (mEC). To capture energy efficiency under bursty
traffic and latency constraints, we also develop the mission effective energy
efficiency (mEEE) metric and formulate its maximization as a non-convex
fractional optimization problem. This problem is then solved via a modified
Dinkelbach's method with an embedded line search. Extensive simulations uncover
critical trade-offs among port count, QoS exponent, signal-to-noise ratio, and
mission duration, offering insights for the design of ultra-reliable,
low-latency, and energy-efficient industrial internet-of-things (IIoT) systems.

</details>


### [9] [DOA Estimation via Optimal Weighted Low-Rank Matrix Completion](https://arxiv.org/abs/2507.19996)
*Saeed Razavikia,Mohammad Bokaei,Arash Amini,Stefano Rini,Carlo Fischione*

Main category: eess.SP

TL;DR: 提出了一种基于加权提升结构低秩矩阵完成的新方法，用于估计非均匀稀疏线性传感器阵列的到达方向（DOA），仅需单次快照样本。


<details>
  <summary>Details</summary>
Motivation: 传统方法在非均匀稀疏阵列中DOA估计性能受限，需解决样本复杂性和噪声干扰问题。

Method: 通过加权提升结构低秩矩阵恢复框架，分四步完成：样本提升、权重矩阵设计、噪声消除和DOA估计。

Result: 方法在样本复杂性和误差性能上优于非加权方法和原子范数最小化方法，低噪声下归一化均方误差降低约10 dB。

Conclusion: 该方法在非均匀稀疏阵列DOA估计中具有显著优势，样本复杂度接近最优。

Abstract: This paper presents a novel method for estimating the direction of arrival
(DOA) for a non-uniform and sparse linear sensor array using the weighted
lifted structure low-rank matrix completion. The proposed method uses a single
snapshot sample in which a single array of data is observed. The method is
rooted in a weighted lifted-structured low-rank matrix recovery framework. The
method involves four key steps: (i) lifting the antenna samples to form a
low-rank stature, then (ii) designing left and right weight matrices to reflect
the sample informativeness, (iii) estimating a noise-free uniform array output
through completion of the weighted lifted samples, and (iv) obtaining the DOAs
from the restored uniform linear array samples.
  We study the complexity of steps (i) to (iii) above, where we analyze the
required sample for the array interpolation of step (iii) for DOA estimation.
We demonstrate that the proposed choice of weight matrices achieves a
near-optimal sample complexity. This complexity aligns with the problem's
degree of freedom, equivalent to the number of DOAs adjusted for logarithmic
factors. Numerical evaluations show the proposed method's superiority against
the non-weighted counterpart and atomic norm minimization-based methods.
Notably, our proposed method significantly improves, with approximately a 10 dB
reduction in normalized mean-squared error over the non-weighted method at
low-noise conditions.

</details>


### [10] [NeuroCLIP: A Multimodal Contrastive Learning Method for rTMS-treated Methamphetamine Addiction Analysis](https://arxiv.org/abs/2507.20189)
*Chengkai Wang,Di Wu,Yunsheng Liao,Wenyao Zheng,Ziyi Zeng,Xurong Gao,Hemmings Wu,Zhoule Zhu,Jie Yang,Lihua Zhong,Weiwei Cheng,Yun-Hsuan Chen,Mohamad Sawan*

Main category: eess.SP

TL;DR: NeuroCLIP是一种结合EEG和fNIRS数据的深度学习框架，用于提高甲基苯丙胺依赖的诊断和治疗评估的可靠性。


<details>
  <summary>Details</summary>
Motivation: 甲基苯丙胺依赖的评估和治疗（如rTMS）常依赖主观报告，缺乏客观可靠的生物标志物。

Method: 提出NeuroCLIP框架，通过渐进学习策略整合EEG和fNIRS数据。

Result: NeuroCLIP显著提高了甲基苯丙胺依赖者与健康对照的区分能力，并能客观评估rTMS疗效。

Conclusion: NeuroCLIP提供的多模态生物标志物比单模态方法更可靠，对成瘾神经科学研究和临床评估有重要价值。

Abstract: Methamphetamine dependence poses a significant global health challenge, yet
its assessment and the evaluation of treatments like repetitive transcranial
magnetic stimulation (rTMS) frequently depend on subjective self-reports, which
may introduce uncertainties. While objective neuroimaging modalities such as
electroencephalography (EEG) and functional near-infrared spectroscopy (fNIRS)
offer alternatives, their individual limitations and the reliance on
conventional, often hand-crafted, feature extraction can compromise the
reliability of derived biomarkers. To overcome these limitations, we propose
NeuroCLIP, a novel deep learning framework integrating simultaneously recorded
EEG and fNIRS data through a progressive learning strategy. This approach
offers a robust and trustworthy biomarker for methamphetamine addiction.
Validation experiments show that NeuroCLIP significantly improves
discriminative capabilities among the methamphetamine-dependent individuals and
healthy controls compared to models using either EEG or only fNIRS alone.
Furthermore, the proposed framework facilitates objective, brain-based
evaluation of rTMS treatment efficacy, demonstrating measurable shifts in
neural patterns towards healthy control profiles after treatment. Critically,
we establish the trustworthiness of the multimodal data-driven biomarker by
showing its strong correlation with psychometrically validated craving scores.
These findings suggest that biomarker derived from EEG-fNIRS data via NeuroCLIP
offers enhanced robustness and reliability over single-modality approaches,
providing a valuable tool for addiction neuroscience research and potentially
improving clinical assessments.

</details>


### [11] [Information-Preserving CSI Feedback: Invertible Networks with Endogenous Quantization and Channel Error Mitigation](https://arxiv.org/abs/2507.20283)
*Haotian Tian,Lixiang Lian,Jiaqi Cao,Sijie Ji*

Main category: eess.SP

TL;DR: 论文提出了一种基于可逆神经网络（INN）的CSI反馈框架InvCSINet，通过保留信息的压缩和重建解决了传统深度学习方法中的信息丢失问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于深度学习的CSI反馈方法使用深度自编码器压缩CSI，导致不可逆的信息丢失和重建精度下降。

Method: 利用INN的双射特性，设计了一个信息保留的CSI反馈框架，并集成了自适应量化模块、可微分比特信道失真模块和信息补偿模块。

Result: 仿真结果表明，该方案在轻量级架构下表现出优越的CSI恢复性能和鲁棒性。

Conclusion: InvCSINet通过INN和信息补偿模块有效解决了CSI反馈中的信息丢失问题，提升了性能和鲁棒性。

Abstract: Deep learning has emerged as a promising solution for efficient channel state
information (CSI) feedback in frequency division duplex (FDD) massive MIMO
systems. Conventional deep learning-based methods typically rely on a deep
autoencoder to compress the CSI, which leads to irreversible information loss
and degrades reconstruction accuracy. This paper introduces InvCSINet, an
information-preserving CSI feedback framework based on invertible neural
networks (INNs). By leveraging the bijective nature of INNs, the model ensures
information-preserving compression and reconstruction with shared model
parameters. To address practical challenges such as quantization and
channel-induced errors, we endogenously integrate an adaptive quantization
module, a differentiable bit-channel distortion module and an information
compensation module into the INN architecture. This design enables the network
to learn and compensate the information loss during CSI compression,
quantization, and noisy transmission, thereby preserving the CSI integrity
throughout the feedback process. Simulation results validate the effectiveness
of the proposed scheme, demonstrating superior CSI recovery performance and
robustness to practical impairments with a lightweight architecture.

</details>


### [12] [Reliability of Wi-Fi, LTE, and 5G-Based UAV RC Links in ISM Bands: Uplink Interference Asymmetry Analysis and HARQ Design](https://arxiv.org/abs/2507.20392)
*Donggu Lee,Sung Joon Maeng,Ozgur Ozdemir,Mani Bharathi Pandian,Ismail Guvenc*

Main category: eess.SP

TL;DR: 论文研究了无人机（UAV）在ISM频段中遥控（RC）链路的干扰问题，尤其是上行链路（UL）和下行链路（DL）的不对称干扰对吞吐量的影响。


<details>
  <summary>Details</summary>
Motivation: 无人机遥控链路在ISM频段中易受干扰，尤其是上行链路干扰更为严重，导致下行链路吞吐量下降。

Method: 通过测量活动（使用氦气球平台）和评估不同HARQ机制，分析了不对称干扰对吞吐量的影响。

Result: 测量结果显示，高空干扰比地面高16.66 dB，不对称干扰导致上行链路ACK/NACK丢失，影响下行链路吞吐量。

Conclusion: 不对称上行链路干扰显著影响无人机遥控链路的性能，需优化HARQ机制以提升吞吐量。

Abstract: Command and control of uncrewed aerial vehicles (UAVs) is often realized
through air-to-ground (A2G) remote control (RC) links that operate in ISM
bands. While wireless fidelity (Wi-Fi) technology is commonly used for UAV RC
links, ISM-based long-term evolution (LTE) and fifth-generation (5G)
technologies have also been recently considered for the same purpose. A major
problem for UAV RC links in the ISM bands is that other types of interference
sources, such as legacy Wi-Fi and Bluetooth transmissions, may degrade the link
quality. Such interference problems are a higher concern for the UAV in the air
than the RC unit on the ground due to the UAV being in line-of-sight (LoS) with
a larger number of interference sources. To obtain empirical evidence of the
asymmetric interference conditions in downlink (DL) and uplink (UL), we first
conducted a measurement campaign using a helikite platform in urban and rural
areas at NC State University. The results from this measurement campaign show
that the aggregate interference can be up to 16.66 dB at higher altitudes up to
170 m, compared with the interference observed at a ground receiver. As a
result of this asymmetric UL interference, lost hybrid automatic repeat request
(HARQ) indicators (ACK/NACK) in the UL may degrade the DL throughput. To
investigate this, we study various HARQ mechanisms, including HARQ Type-I with
no combining, HARQ Type-I with chase combining, HARQ Type-III with incremental
redundancy, and burst transmission with chase combining. To evaluate the impact
of asymmetric UL interference on throughput performance, we consider three
steps of evaluation process: 1) standalone physical DL shared channel (PDSCH)
throughput evaluation with perfect ACK/NACK assumption; 2) standalone physical
UL control channel (PUCCH) decoding reliability evaluation; and 3) PDSCH DL
throughput evaluation with asymmetric UL ACK/NACK transmission.

</details>


### [13] [A Multi-Stage Hybrid CNN-Transformer Network for Automated Pediatric Lung Sound Classification](https://arxiv.org/abs/2507.20408)
*Samiul Based Shuvo,Taufiq Hasan*

Main category: eess.SP

TL;DR: 提出了一种结合CNN和Transformer的多阶段混合框架，用于儿科呼吸疾病的分类，解决了数据不平衡问题，并在性能上优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 儿科呼吸音分类研究不足，尤其是6岁以下儿童，其肺部发育变化导致声音特性不同，需要专门的方法。

Method: 采用多阶段混合CNN-Transformer框架，结合CNN提取的特征和注意力机制，利用标度图图像进行分类。

Result: 模型在二元事件分类中得分为0.9039，多类事件分类中为0.8448，记录级别分类得分分别为0.720和0.571，性能优于之前最佳模型。

Conclusion: 该方法为资源有限地区的儿科呼吸疾病诊断提供了可扩展的解决方案。

Abstract: Automated analysis of lung sound auscultation is essential for monitoring
respiratory health, especially in regions facing a shortage of skilled
healthcare workers. While respiratory sound classification has been widely
studied in adults, its ap plication in pediatric populations, particularly in
children aged <6 years, remains an underexplored area. The developmental
changes in pediatric lungs considerably alter the acoustic proper ties of
respiratory sounds, necessitating specialized classification approaches
tailored to this age group. To address this, we propose a multistage hybrid
CNN-Transformer framework that combines CNN-extracted features with an
attention-based architecture to classify pediatric respiratory diseases using
scalogram images from both full recordings and individual breath events. Our
model achieved an overall score of 0.9039 in binary event classifi cation and
0.8448 in multiclass event classification by employing class-wise focal loss to
address data imbalance. At the recording level, the model attained scores of
0.720 for ternary and 0.571 for multiclass classification. These scores
outperform the previous best models by 3.81% and 5.94%, respectively. This
approach offers a promising solution for scalable pediatric respiratory disease
diagnosis, especially in resource-limited settings.

</details>


### [14] [Energy-Efficient Secure Communications via Joint Optimization of UAV Trajectory and Movable-Antenna Array Beamforming](https://arxiv.org/abs/2507.20489)
*Sanghyeok Kim,Jinu Gong,Joonhyuk Kang*

Main category: eess.SP

TL;DR: 本文研究无人机搭载可移动天线阵列提升无线通信系统安全的潜力，提出联合优化无人机轨迹和天线波束成形的框架，以提高保密能效。


<details>
  <summary>Details</summary>
Motivation: 利用可移动天线阵列的空间自由度增强物理层安全性，确保合法用户的可靠通信。

Method: 联合优化无人机轨迹和可移动天线阵列的波束成形，最大化保密能效。

Result: 数值结果表明，该方法通过可移动天线架构的空间灵活性显著提高了保密能效。

Conclusion: 可移动天线阵列与无人机轨迹的联合优化能有效提升无线通信系统的安全性。

Abstract: This paper investigates the potential of unmanned aerial vehicles (UAVs)
equipped with movable-antenna (MA) arrays to strengthen security in wireless
communication systems. We propose a novel framework that jointly optimizes the
UAV trajectory and the reconfigurable beamforming of the MA array to maximize
secrecy energy efficiency, while ensuring reliable communication with
legitimate users. By exploiting the spatial degrees of freedom enabled by the
MA array, the system can form highly directional beams and deep nulls, thereby
significantly improving physical layer security. Numerical results demonstrate
that the proposed approach achieves superior secrecy energy efficiency,
attributed to the enhanced spatial flexibility provided by the movable antenna
architecture.

</details>


### [15] [Real-Time Distributed Optical Fiber Vibration Recognition via Extreme Lightweight Model and Cross-Domain Distillation](https://arxiv.org/abs/2507.20587)
*Zhongyao Luo,Hao Wu,Zhao Ge,Ming Tang*

Main category: eess.SP

TL;DR: 论文提出了一种基于FPGA加速的超轻量模型和知识蒸馏框架，解决了分布式光纤振动传感系统在动态条件下识别精度下降和实时处理大数据量的计算瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 分布式光纤振动传感系统在大规模监测和入侵事件识别中具有潜力，但动态条件下的识别精度下降和实时处理大数据量的计算瓶颈限制了其实际部署。

Method: 采用三层深度可分离卷积网络（仅4141参数）和基于物理先验的跨域知识蒸馏框架，嵌入频域知识到时域模型中。

Result: 模型实现了每样本0.019毫秒的处理速度，支持168.68公里光纤的实时处理，识别精度在未知环境下从51.93%提升至95.72%。

Conclusion: 该方法结合了可解释信号处理与深度学习，为实时处理和边缘计算提供了参考架构，弥合了理论能力与实际部署需求之间的差距。

Abstract: Distributed optical fiber vibration sensing (DVS) systems offer a promising
solution for large-scale monitoring and intrusion event recognition. However,
their practical deployment remains hindered by two major challenges:
degradation of recognition accuracy in dynamic conditions, and the
computational bottleneck of real-time processing for mass sensing data. This
paper presents a new solution to these challenges, through a FPGA-accelerated
extreme lightweight model along with a newly proposed knowledge distillation
framework. The proposed three-layer depthwise separable convolution network
contains only 4141 parameters, which is the most compact architecture in this
field to date, and achieves a maximum processing speed of 0.019 ms for each
sample covering a 12.5 m fiber length over 0.256 s. This performance
corresponds to real-time processing capabilities for sensing fibers extending
up to 168.68 km. To improve generalizability under changing environments, the
proposed cross-domain distillation framework guided by physical priors is used
here to embed frequency-domain insights into the time-domain model. This allows
for time-frequency representation learning without increasing complexity and
boosts recognition accuracy from 51.93% to 95.72% under unseen environmental
conditions. The proposed methodology provides key advancements including a
framework combining interpretable signal processing technique with deep
learning and a reference architecture for real-time processing and
edge-computing in DVS systems, and more general distributed optical fiber
sensing (DOFS) area. It mitigates the trade-off between sensing range and
real-time capability, bridging the gap between theoretical capabilities and
practical deployment requirements. Furthermore, this work reveals a new
direction for building more efficient, robust and explainable artificial
intelligence systems for DOFS technologies.

</details>


### [16] [RFI and Jamming Detection in Antenna Arrays with an LSTM Autoencoder](https://arxiv.org/abs/2507.20648)
*Christos Ntemkas,Antonios Argyriou*

Main category: eess.SP

TL;DR: 该论文提出了一种利用天线阵列数据和深度学习检测射频干扰（RFI）和恶意干扰的新方法。


<details>
  <summary>Details</summary>
Motivation: 射频干扰和恶意干扰是无线通信中的主要问题，传统方法依赖于统计检测或基于AI的算法，但需要先验知识或特定数据表示。

Method: 结合傅里叶成像技术进行空间源定位，并使用深度LSTM自编码器检测异常（RFI和干扰）。

Result: 在不同功率水平的RFI/干扰和信号下，检测器表现出高性能，且无需先验知识。

Conclusion: 该方法为RFI和干扰检测提供了一种高效且无需先验知识的解决方案。

Abstract: Radio frequency interference (RFI) and malicious jammers are a significant
problem in our wireless world. Detecting RFI or jamming is typically performed
with model-based statistical detection or AI-empowered algorithms that use an
input baseband data or time-frequency representations like spectrograms. In
this work we depart from the previous approaches and we leverage data in
antenna array systems. We use Fourier imaging to localize spatially the sources
and then deploy a deep LSTM autoencoder that detects RFI and jamming as
anomalies. Our results for different power levels of the RFI/jamming sources,
and the signal of interest, reveal that our detector offers high performance
without needing any pre-existing knowledge regarding the RFI or jamming signal.

</details>


### [17] [Angle-distance decomposition based on deep learning for active sonar detection](https://arxiv.org/abs/2507.20651)
*Jichao Zhang,Xiao-Lei Zhang,Kunde Yang*

Main category: eess.SP

TL;DR: 本文提出了一种基于深度学习的主动声纳目标检测方法，通过分解角度和距离估计任务，结合迁移学习和仿真数据解决水下数据不足问题，实验验证了其有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统信号处理方法在复杂水下环境中因噪声、混响和干扰面临挑战，需要更有效的解决方案。

Method: 将目标检测分解为角度和距离估计任务，利用深度学习模型预测目标位置，并通过迁移学习和仿真数据解决数据不足问题。

Result: 实验结果表明，该方法在复杂条件下表现出有效且鲁棒的性能。

Conclusion: 基于深度学习的方法为水下目标检测提供了有效解决方案，尤其在数据有限的情况下表现优异。

Abstract: Underwater target detection using active sonar constitutes a critical
research area in marine sciences and engineering. However, traditional signal
processing methods face significant challenges in complex underwater
environments due to noise, reverberation, and interference. To address these
issues, this paper presents a deep learning-based active sonar target detection
method that decomposes the detection process into separate angle and distance
estimation tasks. Active sonar target detection employs deep learning models to
predict target distance and angle, with the final target position determined by
integrating these estimates. Limited underwater acoustic data hinders effective
model training, but transfer learning and simulation offer practical solutions
to this challenge. Experimental results verify that the method achieves
effective and robust performance under challenging conditions.

</details>


### [18] [The micro-Doppler Attack Against AI-based Human Activity Classification from Wireless Signals](https://arxiv.org/abs/2507.20657)
*Margarita Loupa,Antonios Argyriou,Yanwei Liu*

Main category: eess.SP

TL;DR: 本文提出了一种针对基于无线OFDM信号的人类活动分类（HAC）系统的微多普勒攻击，通过人为改变信号波形降低HAC的准确性。


<details>
  <summary>Details</summary>
Motivation: 研究HAC系统的安全性，揭示其易受微多普勒攻击的漏洞。

Method: 通过插入人工变化到OFDM波形中，改变其微多普勒特征，并测试两种不同时间尺度的攻击变体。

Result: 使用深度卷积神经网络（CNN）的HAC系统准确性可降至10%以下。

Conclusion: 微多普勒攻击对HAC系统构成严重威胁，需进一步研究防御措施。

Abstract: A subset of Human Activity Classification (HAC) systems are based on AI
algorithms that use passively collected wireless signals. This paper presents
the micro-Doppler attack targeting HAC from wireless orthogonal frequency
division multiplexing (OFDM) signals. The attack is executed by inserting
artificial variations in a transmitted OFDM waveform to alter its micro-Doppler
signature when it reflects off a human target. We investigate two variants of
our scheme that manipulate the waveform at different time scales resulting in
altered receiver spectrograms. HAC accuracy with a deep convolutional neural
network (CNN) can be reduced to less than 10%.

</details>


### [19] [A Nonlinear Spectral Approach for Radar-Based Heartbeat Estimation via Autocorrelation of Higher Harmonics](https://arxiv.org/abs/2507.20664)
*Kohei Shimomura,Chi-Hsuan Lee,Takuya Sakamoto*

Main category: eess.SP

TL;DR: 提出了一种非线性信号处理方法，通过利用心跳信号的高阶谐波周期性，提高了雷达心跳间隔估计的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过选择性频率滤波或跟踪单个谐波，难以有效处理呼吸谐波和噪声，导致估计不准确。

Method: 采用平滑和二阶导数操作抑制噪声并突出高阶谐波，通过局部自相关计算和伪频谱生成，增强全局周期性结构。

Result: 实验表明，该方法将均方根误差降低20%，相关系数提高0.20。

Conclusion: 非线性方法显著提升了心跳间隔估计的鲁棒性和准确性。

Abstract: This study presents a nonlinear signal processing method for accurate
radar-based heartbeat interval estimation by exploiting the periodicity of
higher-order harmonics inherent in heartbeat signals. Unlike conventional
approaches that employ selective frequency filtering or track individual
harmonics, the proposed method enhances the global periodic structure of the
spectrum via nonlinear correlation processing. Specifically, smoothing and
second-derivative operations are first applied to the radar displacement signal
to suppress noise and accentuate higher-order heartbeat harmonics. Rather than
isolating specific frequency components, we compute localized autocorrelations
of the Fourier spectrum around the harmonic frequencies. The incoherent
summation of these autocorrelations yields a pseudo-spectrum in which the
fundamental heartbeat periodicity is distinctly emphasized. This nonlinear
approach mitigates the effects of respiratory harmonics and noise, enabling
robust interbeat interval estimation. Experiments with radar measurements from
five participants demonstrate that the proposed method reduces root-mean-square
error by 20% and improves the correlation coefficient by 0.20 relative to
conventional techniques.

</details>


### [20] [DT-Aided Resource Management in Spectrum Sharing Integrated Satellite-Terrestrial Networks](https://arxiv.org/abs/2507.20789)
*Hung Nguyen-Kha,Vu Nguyen Ha,Ti Ti Nguyen,Eva Lagunas,Symeon Chatzinotas,Joel Grotz*

Main category: eess.SP

TL;DR: 提出了一种基于数字孪生（DT）的框架，用于集成卫星-地面网络（ISTN），通过联合优化带宽分配、流量引导和资源分配来减少拥塞。


<details>
  <summary>Details</summary>
Motivation: 解决卫星与地面网络共存时的频谱共享问题，特别是应对系统间干扰（ISI）和低轨卫星（LSat）移动性带来的挑战。

Method: 采用时间变化的数字孪生（DT）框架，结合3D地图，将问题建模为混合整数非线性规划（MINLP），并通过基于连续凸近似（SCA）和压缩感知的两阶段算法求解。

Result: 数值结果表明，所提方法在队列长度最小化方面优于基准方法。

Conclusion: 该框架有效解决了ISTN中的资源管理问题，为频谱共享提供了高效解决方案。

Abstract: The integrated satellite-terrestrial networks (ISTNs) through spectrum
sharing have emerged as a promising solution to improve spectral efficiency and
meet increasing wireless demand. However, this coexistence introduces
significant challenges, including inter-system interference (ISI) and the low
Earth orbit satellite (LSat) movements. To capture the actual environment for
resource management, we propose a time-varying digital twin (DT)-aided
framework for ISTNs incorporating 3D map that enables joint optimization of
bandwidth (BW) allocation, traffic steering, and resource allocation, and aims
to minimize congestion. The problem is formulated as a mixed-integer nonlinear
programming (MINLP), addressed through a two-phase algorithm based on
successive convex approximation (SCA) and compressed sensing approaches.
Numerical results demonstrate the proposed method's superior performance in
queue length minimization compared to benchmarks.

</details>


### [21] [Chirp-Permuted AFDM: A New Degree of Freedom for Next-Generation Versatile Waveform Design](https://arxiv.org/abs/2507.20825)
*Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu*

Main category: eess.SP

TL;DR: 提出了一种新型多载波波形CP-AFDM，通过引入独特的chirp置换域，增强了AFDM的性能，适用于6G场景。


<details>
  <summary>Details</summary>
Motivation: 提升传统AFDM在双弥散信道中的性能，同时增强多普勒域的分辨率和峰值旁瓣比，以满足6G对可靠性和感知能力的需求。

Method: 在传统AFDM的chirp子载波上引入chirp置换域，并通过数值模拟验证其性能。

Result: CP-AFDM保留了AFDM的核心特性，同时提升了多普勒域的分辨率和峰值旁瓣比，并展示了两种多功能应用。

Conclusion: CP-AFDM是一种适用于6G的高性能波形，兼具可靠性和感知能力，且支持多功能的物理层应用。

Abstract: We present a novel multicarrier waveform, termed chirp-permuted affine
frequency division multiplexing (CP-AFDM), which introduces a unique
chirp-permutation domain on top of the chirp subcarriers of the conventional
AFDM. Rigorous analysis of the signal model and waveform properties, supported
by numerical simulations, demonstrates that the proposed CP-AFDM preserves all
core characteristics of affine frequency division multiplexing (AFDM) -
including robustness to doubly-dispersive channels, peak-to-average power ratio
(PAPR), and full delay-Doppler representation - while further enhancing
ambiguity function resolution and peak-to-sidelobe ratio (PSLR) in the Doppler
domain. These improvements establish CP-AFDM as a highly attractive candidate
for emerging sixth generation (6G) use cases demanding both reliability and
sensing-awareness. Moreover, by exploiting the vast degree of freedom in the
chirp-permutation domain, two exemplary multifunctional applications are
introduced: an index modulation (IM) technique over the permutation domain
which achieves significant spectral efficiency gains, and a physical-layer
security scheme that ensures practically perfect security through
permutation-based keying, without requiring additional transmit energy or
signaling overhead.

</details>


### [22] [Interference Analysis and Successive Interference Cancellation for Multistatic OFDM-based ISAC Systems](https://arxiv.org/abs/2507.20942)
*Taewon Jeong,Lucas Giroto,Umut Utku Erdem,Christian Karle,Jiyeon Choi,Thomas Zwick,Benjamin Nuss*

Main category: eess.SP

TL;DR: 多静态集成感知与通信（ISAC）系统通过分布式收发器提升性能，但存在节点间干扰问题。本文分析了干扰影响并提出低复杂度干扰消除方法，通过仿真和实测验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 多静态ISAC系统因节点共存产生干扰，影响感知和通信性能，需研究干扰分类及消除方法。

Method: 分类干扰类型，提出基于SINR的低复杂度干扰消除方法，并通过仿真和实验验证。

Result: 所提方法降低BER、改善EVM和雷达图像SINR，适用于实际应用。

Conclusion: 低复杂度干扰消除方法在多静态ISAC系统中有效，具有实际应用潜力。

Abstract: Multistatic integrated sensing and communications (ISAC) systems, which use
distributed transmitters and receivers, offer enhanced spatial coverage and
sensing accuracy compared to stand-alone ISAC configurations. However, these
systems face challenges due to interference between co-existing ISAC nodes,
especially during simultaneous operation. In this paper, we analyze the impact
of this mutual interference arising from the co-existence in a multistatic ISAC
scenario, where a mono- and a bistatic ISAC system share the same spectral
resources. We first classify differenct types of interference in the power
domain. Then, we discuss how the interference can affect both sensing and
communications in terms of bit error rate (BER), error vector magnitude (EVM),
and radar image under varied transmit power and RCS configurations through
simulations. Along with interfernce analysis, we propose a low-complexity
successive interference cancellation method that adaptively cancels either the
monostatic reflection or the bistatic line-of-sight signal based on a
monostatic radar image signal-to-interference-plus-noise ratio (SINR). The
proposed framework is evaluated with both simulations and proof-of-concept
measurements using an ISAC testbed with a radar echo generator for object
emulation. The results have shown that the proposed method reduces BER and
improves EVM as well as radar image SINR across a wide range of SINR
conditions. These results demonstrate that accurate component-wise cancellation
can be achieved with low computational overhead, making the method suitable for
practical applications.

</details>


### [23] [Analytical Modeling of Batteryless IoT Sensors Powered by Ambient Energy Harvesting](https://arxiv.org/abs/2507.20952)
*Jimmy Fernandez Landivar,Andrea Zanella,Ihsane Gryech,Sofie Pollin,Hazem Sallouha*

Main category: eess.SP

TL;DR: 提出了一种用于无电池物联网节点的能量动态数学模型，涵盖能量收集与消耗，支持智能电源管理。


<details>
  <summary>Details</summary>
Motivation: 为无电池物联网设备提供精确的能量动态模型，以优化其在多变环境中的性能。

Method: 开发综合数学模型，结合能量收集与消耗，验证于三种光照条件下的原型节点。

Result: 模型与实测超级电容电压曲线高度吻合，验证了其准确性。

Conclusion: 该模型能有效支持无电池物联网设备的智能电源管理设计。

Abstract: This paper presents a comprehensive mathematical model to characterize the
energy dynamics of batteryless IoT sensor nodes powered entirely by ambient
energy harvesting. The model captures both the energy harvesting and
consumption phases, explicitly incorporating power management tasks to enable
precise estimation of device behavior across diverse environmental conditions.
The proposed model is applicable to a wide range of IoT devices and supports
intelligent power management units designed to maximize harvested energy under
fluctuating environmental conditions. We validated our model against a
prototype batteryless IoT node, conducting experiments under three distinct
illumination scenarios. Results show a strong correlation between analytical
and measured supercapacitor voltage profiles, confirming the proposed model's
accuracy.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [24] [Binaural Speech Enhancement Using Complex Convolutional Recurrent Networks](https://arxiv.org/abs/2507.20023)
*Vikas Tokala,Eric Grinstein,Mike Brookes,Simon Doclo,Jesper Jensen,Patrick A. Naylor*

Main category: eess.AS

TL;DR: 提出了一种端到端的双耳语音增强方法，使用复杂的循环卷积网络，结合编码器-解码器架构和复杂的LSTM循环块，显著提升语音清晰度和降噪效果。


<details>
  <summary>Details</summary>
Motivation: 双耳语音增强算法在助听器和增强/虚拟现实设备中广泛应用，但现有方法在保留空间信息方面存在不足。

Method: 采用端到端的复杂循环卷积网络，结合编码器-解码器架构和复杂LSTM块，通过损失函数优化空间信息保留和语音清晰度。

Result: 相比基线算法，该方法显著提升语音清晰度、降低噪声，并有效保留双耳信号的空间信息。

Conclusion: 该方法在单目标说话者和各向同性噪声环境下表现出色，为双耳语音增强提供了有效解决方案。

Abstract: From hearing aids to augmented and virtual reality devices, binaural speech
enhancement algorithms have been established as state-of-the-art techniques to
improve speech intelligibility and listening comfort. In this paper, we present
an end-to-end binaural speech enhancement method using a complex recurrent
convolutional network with an encoder-decoder architecture and a complex LSTM
recurrent block placed between the encoder and decoder. A loss function that
focuses on the preservation of spatial information in addition to speech
intelligibility improvement and noise reduction is introduced. The network
estimates individual complex ratio masks for the left and right-ear channels of
a binaural hearing device in the time-frequency domain. We show that, compared
to other baseline algorithms, the proposed method significantly improves the
estimated speech intelligibility and reduces the noise while preserving the
spatial information of the binaural signals in acoustic situations with a
single target speaker and isotropic noise of various types.

</details>


### [25] [Binaural Localization Model for Speech in Noise](https://arxiv.org/abs/2507.20027)
*Vikas Tokala,Eric Grinstein,Rory Brooks,Mike Brookes,Simon Doclo,Jesper Jensen,Patrick A. Naylor*

Main category: eess.AS

TL;DR: 论文提出了一种轻量级卷积循环网络，用于在噪声和混响条件下定位双耳语音信号，并模拟人耳听力阈值。


<details>
  <summary>Details</summary>
Motivation: 双耳声源定位对人类的空间感知、交流和安全性至关重要。

Method: 使用轻量级卷积循环网络，结合内部耳噪声模拟听力阈值，定位噪声和混响条件下的双耳信号。

Result: 模型性能与转向响应功率算法对比，并用于评估双耳语音增强方法的线索保留效果。

Conclusion: 通过听力测试验证，模型在噪声条件下的定位性能接近人类表现。

Abstract: Binaural acoustic source localization is important to human listeners for
spatial awareness, communication and safety. In this paper, an end-to-end
binaural localization model for speech in noise is presented. A lightweight
convolutional recurrent network that localizes sound in the frontal azimuthal
plane for noisy reverberant binaural signals is introduced. The model
incorporates additive internal ear noise to represent the frequency-dependent
hearing threshold of a typical listener. The localization performance of the
model is compared with the steered response power algorithm, and the use of the
model as a measure of interaural cue preservation for binaural speech
enhancement methods is studied. A listening test was performed to compare the
performance of the model with human localization of speech in noisy conditions.

</details>


### [26] [Binaural Sound Event Localization and Detection based on HRTF Cues for Humanoid Robots](https://arxiv.org/abs/2507.20530)
*Gyeong-Tae Lee,Hyeonuk Nam,Yong-Hwa Park*

Main category: eess.AS

TL;DR: 本文提出了Binaural Sound Event Localization and Detection (BiSELD)任务，结合双耳音频检测和定位声音事件，并提出了Binaural Time-Frequency Feature (BTFF)特征表示和BiSELDnet模型。


<details>
  <summary>Details</summary>
Motivation: 受人类空间听觉机制启发，旨在通过双耳音频联合检测和定位多个声音事件。

Method: 提出了BTFF特征表示，包含八通道信息（如左右mel谱、速度图、SC图、ITD/ILD图），并开发了CRNN模型BiSELDnet。

Result: 在Binaural Set数据集上，BTFF各子特征显著提升性能，最终系统SELD误差为0.110，F-score为87.1%，定位误差4.4°。

Conclusion: 提出的框架有效模拟了人类听觉感知，BTFF和BiSELDnet在声音事件检测与定位中表现出色。

Abstract: This paper introduces Binaural Sound Event Localization and Detection
(BiSELD), a task that aims to jointly detect and localize multiple sound events
using binaural audio, inspired by the spatial hearing mechanism of humans. To
support this task, we present a synthetic benchmark dataset, called the
Binaural Set, which simulates realistic auditory scenes using measured
head-related transfer functions (HRTFs) and diverse sound events. To
effectively address the BiSELD task, we propose a new input feature
representation called the Binaural Time-Frequency Feature (BTFF), which encodes
interaural time difference (ITD), interaural level difference (ILD), and
high-frequency spectral cues (SC) from binaural signals. BTFF is composed of
eight channels, including left and right mel-spectrograms, velocity-maps,
SC-maps, and ITD-/ILD-maps, designed to cover different spatial cues across
frequency bands and spatial axes. A CRNN-based model, BiSELDnet, is then
developed to learn both spectro-temporal patterns and HRTF-based localization
cues from BTFF. Experiments on the Binaural Set show that each BTFF sub-feature
enhances task performance: V-map improves detection, ITD-/ILD-maps enable
accurate horizontal localization, and SC-map captures vertical spatial cues.
The final system achieves a SELD error of 0.110 with 87.1% F-score and
4.4{\deg} localization error, demonstrating the effectiveness of the proposed
framework in mimicking human-like auditory perception.

</details>


### [27] [MIMII-Agent: Leveraging LLMs with Function Calling for Relative Evaluation of Anomalous Sound Detection](https://arxiv.org/abs/2507.20666)
*Harsh Purohit,Tomoya Nishida,Kota Dohi,Takashi Endo,Yohei Kawaguchi*

Main category: eess.AS

TL;DR: 提出了一种利用大语言模型（LLM）生成机器类型特定异常声音的方法，用于评估无监督异常声音检测（UASD）系统的性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于关键词的数据增强方法生成的声音不真实，依赖人工定义的标签，限制了可扩展性；而先进的音频生成模型通常需要异常训练数据，难以应对多样化的异常情况。

Method: 利用LLM解析故障的文本描述，自动选择音频转换函数，将正常机器声音转换为多样且合理的异常声音。

Result: 实验结果表明，合成异常与真实异常在机器类型间的检测难度趋势一致，验证了方法的有效性。

Conclusion: LLM驱动的合成方法为UASD系统的相对评估提供了有效工具。

Abstract: This paper proposes a method for generating machine-type-specific anomalies
to evaluate the relative performance of unsupervised anomalous sound detection
(UASD) systems across different machine types, even in the absence of real
anomaly sound data. Conventional keyword-based data augmentation methods often
produce unrealistic sounds due to their reliance on manually defined labels,
limiting scalability as machine types and anomaly patterns diversify. Advanced
audio generative models, such as MIMII-Gen, show promise but typically depend
on anomalous training data, making them less effective when diverse anomalous
examples are unavailable. To address these limitations, we propose a novel
synthesis approach leveraging large language models (LLMs) to interpret textual
descriptions of faults and automatically select audio transformation functions,
converting normal machine sounds into diverse and plausible anomalous sounds.
We validate this approach by evaluating a UASD system trained only on normal
sounds from five machine types, using both real and synthetic anomaly data.
Experimental results reveal consistent trends in relative detection difficulty
across machine types between synthetic and real anomalies. This finding
supports our hypothesis and highlights the effectiveness of the proposed
LLM-based synthesis approach for relative evaluation of UASD systems.

</details>


### [28] [End-to-End DOA-Guided Speech Extraction in Noisy Multi-Talker Scenarios](https://arxiv.org/abs/2507.20926)
*Kangqi Jing,Wenbin Zhang,Yu Gao*

Main category: eess.AS

TL;DR: 提出一种结合DOA和波束宽度嵌入的端到端目标说话人提取模型，显著提升目标语音质量并抑制干扰。


<details>
  <summary>Details</summary>
Motivation: 在嘈杂和多说话人环境中增强目标语音信号。

Method: 结合方向到达（DOA）和波束宽度嵌入，提取指定空间区域的语音。

Result: 模型显著增强目标语音，有效抑制干扰，并提升下游ASR任务性能。

Conclusion: 该模型适用于实际应用，尤其在复杂场景中表现优异。

Abstract: Target Speaker Extraction (TSE) plays a critical role in enhancing speech
signals in noisy and multi-speaker environments. This paper presents an
end-to-end TSE model that incorporates Direction of Arrival (DOA) and beamwidth
embeddings to extract speech from a specified spatial region centered around
the DOA. Our approach efficiently captures spatial and temporal features,
enabling robust performance in highly complex scenarios with multiple
simultaneous speakers. Experimental results demonstrate that the proposed model
not only significantly enhances the target speech within the defined beamwidth
but also effectively suppresses interference from other directions, producing a
clear and isolated target voice. Furthermore, the model achieves remarkable
improvements in downstream Automatic Speech Recognition (ASR) tasks, making it
particularly suitable for real-world applications.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [29] [Joint Feature and Output Distillation for Low-complexity Acoustic Scene Classification](https://arxiv.org/abs/2507.19557)
*Haowen Li,Ziyi Yang,Mou Wang,Ee-Leng Tan,Junwei Yeow,Santi Peksi,Woon-Seng Gan*

Main category: cs.SD

TL;DR: 提出了一种双层次知识蒸馏框架，结合多教师指导，用于低复杂度的声学场景分类（ASC）。


<details>
  <summary>Details</summary>
Motivation: 解决低复杂度声学场景分类问题，通过知识蒸馏提升学生模型的性能。

Method: 使用预训练的PaSST和CP-ResNet作为教师模型，联合传输软logits和中间特征表示。

Result: 在TAU Urban Acoustic Scenes 2022 Mobile数据集上达到59.30%的准确率。

Conclusion: 双层次知识蒸馏框架有效提升了学生模型的性能。

Abstract: This report presents a dual-level knowledge distillation framework with
multi-teacher guidance for low-complexity acoustic scene classification (ASC)
in DCASE2025 Task 1. We propose a distillation strategy that jointly transfers
both soft logits and intermediate feature representations. Specifically, we
pre-trained PaSST and CP-ResNet models as teacher models. Logits from teachers
are averaged to generate soft targets, while one CP-ResNet is selected for
feature-level distillation. This enables the compact student model (CP-Mobile)
to capture both semantic distribution and structural information from teacher
guidance. Experiments on the TAU Urban Acoustic Scenes 2022 Mobile dataset
(development set) demonstrate that our submitted systems achieve up to 59.30\%
accuracy.

</details>


### [30] [SonicGauss: Position-Aware Physical Sound Synthesis for 3D Gaussian Representations](https://arxiv.org/abs/2507.19835)
*Chunshi Wang,Hongxing Li,Yawei Luo*

Main category: cs.SD

TL;DR: SonicGauss框架利用3D高斯表示（3DGS）的几何和材质特性，结合扩散模型和PointTransformer，实现了基于位置感知的物体碰撞声音合成。


<details>
  <summary>Details</summary>
Motivation: 探索3DGS在捕捉物理属性（如声音）方面的潜力，填补视觉表示与声音合成之间的空白。

Method: 整合扩散模型和PointTransformer，从高斯椭球中推断材质特性和空间-声学相关性。

Result: 在ObjectFolder数据集和真实录音上验证了方法的有效性，生成逼真且位置感知的声音反馈。

Conclusion: SonicGauss展示了3DGS在声音合成中的潜力，为视觉与听觉交互提供了新方向。

Abstract: While 3D Gaussian representations (3DGS) have proven effective for modeling
the geometry and appearance of objects, their potential for capturing other
physical attributes-such as sound-remains largely unexplored. In this paper, we
present a novel framework dubbed SonicGauss for synthesizing impact sounds from
3DGS representations by leveraging their inherent geometric and material
properties. Specifically, we integrate a diffusion-based sound synthesis model
with a PointTransformer-based feature extractor to infer material
characteristics and spatial-acoustic correlations directly from Gaussian
ellipsoids. Our approach supports spatially varying sound responses conditioned
on impact locations and generalizes across a wide range of object categories.
Experiments on the ObjectFolder dataset and real-world recordings demonstrate
that our method produces realistic, position-aware auditory feedback. The
results highlight the framework's robustness and generalization ability,
offering a promising step toward bridging 3D visual representations and
interactive sound synthesis. Project page: https://chunshi.wang/SonicGauss

</details>


### [31] [Efficient Vocal-Conditioned Music Generation via Soft Alignment Attention and Latent Diffusion](https://arxiv.org/abs/2507.19991)
*Hei Shing Cheung,Boya Zhang*

Main category: cs.SD

TL;DR: 提出了一种轻量级潜在扩散模型，用于声乐条件音乐伴奏生成，解决了现有音乐AI系统的关键限制。


<details>
  <summary>Details</summary>
Motivation: 现有音乐AI系统在参数规模和计算效率上存在限制，难以在资源受限环境中实时部署。

Method: 采用新型软对齐注意力机制，结合局部和全局时间依赖性，基于扩散时间步长，在预训练变分自编码器的压缩潜在空间中操作。

Result: 模型参数减少220倍，推理速度提高52倍，仅用15M参数即达到与OpenAI Jukebox竞争的性能，且在制作质量和内容一致性上更优。

Conclusion: 该超轻量架构支持在消费级硬件上实时部署，为交互式应用和资源受限环境提供了AI辅助音乐创作的可行性。

Abstract: We present a lightweight latent diffusion model for vocal-conditioned musical
accompaniment generation that addresses critical limitations in existing music
AI systems. Our approach introduces a novel soft alignment attention mechanism
that adaptively combines local and global temporal dependencies based on
diffusion timesteps, enabling efficient capture of multi-scale musical
structure. Operating in the compressed latent space of a pre-trained
variational autoencoder, the model achieves a 220 times parameter reduction
compared to state-of-the-art systems while delivering 52 times faster
inference. Experimental evaluation demonstrates competitive performance with
only 15M parameters, outperforming OpenAI Jukebox in production quality and
content unity while maintaining reasonable musical coherence. The
ultra-lightweight architecture enables real-time deployment on consumer
hardware, making AI-assisted music creation accessible for interactive
applications and resource-constrained environments.

</details>


### [32] [Improving Audio Classification by Transitioning from Zero- to Few-Shot](https://arxiv.org/abs/2507.20036)
*James Taylor,Wolfgang Mack*

Main category: cs.SD

TL;DR: 论文探讨了通过少样本方法改进音频分类准确性的方法，超越零样本基线。


<details>
  <summary>Details</summary>
Motivation: 零样本音频分类中，文本描述与音频嵌入的对齐存在挑战，尤其是类别包含多种声音时。

Method: 通过将音频嵌入按类别分组并处理，替代噪声较大的文本嵌入。

Result: 少样本分类通常优于零样本基线。

Conclusion: 少样本方法能有效提升音频分类性能。

Abstract: State-of-the-art audio classification often employs a zero-shot approach,
which involves comparing audio embeddings with embeddings from text describing
the respective audio class. These embeddings are usually generated by neural
networks trained through contrastive learning to align audio and text
representations. Identifying the optimal text description for an audio class is
challenging, particularly when the class comprises a wide variety of sounds.
This paper examines few-shot methods designed to improve classification
accuracy beyond the zero-shot approach. Specifically, audio embeddings are
grouped by class and processed to replace the inherently noisy text embeddings.
Our results demonstrate that few-shot classification typically outperforms the
zero-shot baseline.

</details>


### [33] [Improving Deep Learning-based Respiratory Sound Analysis with Frequency Selection and Attention Mechanism](https://arxiv.org/abs/2507.20052)
*Nouhaila Fraihi,Ouassim Karrakchou,Mounir Ghogho*

Main category: cs.SD

TL;DR: 提出了一种结合CNN和轻量级自注意力的CNN-TSA网络，通过频率带选择模块（FBS）提升呼吸音分类的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决CNN在建模全局上下文上的不足以及Transformer模型的高计算需求，提出一种高效且轻量的解决方案。

Method: 结合CNN和轻量级自注意力机制，引入FBS模块抑制噪声和非信息频率区域，并开发年龄特异性模型。

Result: 在SPRSound和ICBHI数据集上达到新基准，计算量减少50%，并在现有Transformer模型上验证FBS的有效性。

Conclusion: CNN-TSA框架适用于资源受限环境，实现了高效、可靠的实时呼吸音分析。

Abstract: Accurate classification of respiratory sounds requires deep learning models
that effectively capture fine-grained acoustic features and long-range temporal
dependencies. Convolutional Neural Networks (CNNs) are well-suited for
extracting local time-frequency patterns but are limited in modeling global
context. In contrast, transformer-based models can capture long-range
dependencies, albeit with higher computational demands. To address these
limitations, we propose a compact CNN-Temporal Self-Attention (CNN-TSA) network
that integrates lightweight self-attention into an efficient CNN backbone.
Central to our approach is a Frequency Band Selection (FBS) module that
suppresses noisy and non-informative frequency regions, substantially improving
accuracy and reducing FLOPs by up to 50%. We also introduce age-specific models
to enhance robustness across diverse patient groups. Evaluated on the
SPRSound-2022/2023 and ICBHI-2017 lung sound datasets, CNN-TSA with FBS sets
new benchmarks on SPRSound and achieves state-of-the-art performance on ICBHI,
all with a significantly smaller computational footprint. Furthermore,
integrating FBS into an existing transformer baseline yields a new record on
ICBHI, confirming FBS as an effective drop-in enhancement. These results
demonstrate that our framework enables reliable, real-time respiratory sound
analysis suitable for deployment in resource-constrained settings.

</details>


### [34] [Diffusion-based Symbolic Music Generation with Structured State Space Models](https://arxiv.org/abs/2507.20128)
*Shenghua Yuan,Xing Tang,Jiatao Chen,Tianming Xie,Jing Wang,Bing Shi*

Main category: cs.SD

TL;DR: 提出了一种基于扩散模型和结构化状态空间模型（SSMs）的符号音乐生成方法SMDIM，解决了传统Transformer架构在长序列生成中的计算效率问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于Transformer的符号音乐生成方法因二次计算复杂度难以扩展至长序列，需要更高效的架构。

Method: 结合SSMs和Mamba-FeedForward-Attention Block（MFA），实现全局上下文高效建模和局部细节精确保留。

Result: 在FolkDB等数据集上，SMDIM在生成质量和计算效率上均优于现有模型，且复杂度接近线性。

Conclusion: SMDIM不仅适用于符号音乐生成，还可推广至其他长序列任务，提供了高效且可扩展的解决方案。

Abstract: Recent advancements in diffusion models have significantly improved symbolic
music generation. However, most approaches rely on transformer-based
architectures with self-attention mechanisms, which are constrained by
quadratic computational complexity, limiting scalability for long sequences. To
address this, we propose Symbolic Music Diffusion with Mamba (SMDIM), a novel
diffusion-based architecture integrating Structured State Space Models (SSMs)
for efficient global context modeling and the Mamba-FeedForward-Attention Block
(MFA) for precise local detail preservation. The MFA Block combines the linear
complexity of Mamba layers, the non-linear refinement of FeedForward layers,
and the fine-grained precision of self-attention mechanisms, achieving a
balance between scalability and musical expressiveness. SMDIM achieves
near-linear complexity, making it highly efficient for long-sequence tasks.
Evaluated on diverse datasets, including FolkDB, a collection of traditional
Chinese folk music that represents an underexplored domain in symbolic music
generation, SMDIM outperforms state-of-the-art models in both generation
quality and computational efficiency. Beyond symbolic music, SMDIM's
architectural design demonstrates adaptability to a broad range of
long-sequence generation tasks, offering a scalable and efficient solution for
coherent sequence modeling.

</details>


### [35] [Do Not Mimic My Voice: Speaker Identity Unlearning for Zero-Shot Text-to-Speech](https://arxiv.org/abs/2507.20140)
*Taesoo Kim,Jinju Kim,Dongchan Kim,Jong Hwan Ko,Gyeong-Moon Park*

Main category: cs.SD

TL;DR: 本文提出了一种针对零样本文本到语音（ZS-TTS）系统的说话人身份遗忘框架（TGU），旨在从预训练模型中移除特定说话人的声音信息，同时保留其他说话人的语音生成能力。


<details>
  <summary>Details</summary>
Motivation: 随着ZS-TTS技术的快速发展，高保真语音合成引发了隐私和伦理问题。目前缺乏从预训练模型中移除特定说话人声音信息的研究。

Method: 提出了教师引导遗忘（TGU）框架，通过引入随机性防止模型复制遗忘说话人的声音，并提出新的评估指标spk-ZRF。

Result: 实验表明，TGU能有效防止模型复制遗忘说话人的声音，同时保持对其他说话人的高质量语音生成。

Conclusion: TGU为解决ZS-TTS系统中的说话人身份遗忘问题提供了有效方法，平衡了隐私保护与语音生成质量。

Abstract: The rapid advancement of Zero-Shot Text-to-Speech (ZS-TTS) technology has
enabled high-fidelity voice synthesis from minimal audio cues, raising
significant privacy and ethical concerns. Despite the threats to voice privacy,
research to selectively remove the knowledge to replicate unwanted individual
voices from pre-trained model parameters has not been explored. In this paper,
we address the new challenge of speaker identity unlearning for ZS-TTS systems.
To meet this goal, we propose the first machine unlearning frameworks for
ZS-TTS, especially Teacher-Guided Unlearning (TGU), designed to ensure the
model forgets designated speaker identities while retaining its ability to
generate accurate speech for other speakers. Our proposed methods incorporate
randomness to prevent consistent replication of forget speakers' voices,
assuring unlearned identities remain untraceable. Additionally, we propose a
new evaluation metric, speaker-Zero Retrain Forgetting (spk-ZRF). This assesses
the model's ability to disregard prompts associated with forgotten speakers,
effectively neutralizing its knowledge of these voices. The experiments
conducted on the state-of-the-art model demonstrate that TGU prevents the model
from replicating forget speakers' voices while maintaining high quality for
other speakers. The demo is available at https://speechunlearn.github.io/

</details>


### [36] [Self-Improvement for Audio Large Language Model using Unlabeled Speech](https://arxiv.org/abs/2507.20169)
*Shaowen Wang,Xinyuan Chen,Yao Xu*

Main category: cs.SD

TL;DR: 提出了一种名为SI-SDA的自改进方法，通过无标签数据增强音频大语言模型在目标领域的性能。


<details>
  <summary>Details</summary>
Motivation: 音频大语言模型在特定目标领域性能下降，需无标签数据提升性能。

Method: 利用大模型解码信息评估伪标签质量，基于强化学习优化进行领域适应。

Result: 在ASR、SQA和S2TT任务中，WER和BLEU指标显著优于基线方法。

Conclusion: SI-SDA方法高效且适用于实际部署。

Abstract: Recent audio LLMs have emerged rapidly, demonstrating strong generalization
across various speech tasks. However, given the inherent complexity of speech
signals, these models inevitably suffer from performance degradation in
specific target domains. To address this, we focus on enhancing audio LLMs in
target domains without any labeled data. We propose a self-improvement method
called SI-SDA, leveraging the information embedded in large-model decoding to
evaluate the quality of generated pseudo labels and then perform domain
adaptation based on reinforcement learning optimization. Experimental results
show that our method consistently and significantly improves audio LLM
performance, outperforming existing baselines in WER and BLEU across multiple
public datasets of automatic speech recognition (ASR), spoken
question-answering (SQA), and speech-to-text translation (S2TT). Furthermore,
our approach exhibits high data efficiency, underscoring its potential for
real-world deployment.

</details>


### [37] [Two Views, One Truth: Spectral and Self-Supervised Features Fusion for Robust Speech Deepfake Detection](https://arxiv.org/abs/2507.20417)
*Yassine El Kheir,Arnab Das,Enes Erdem Erdogan,Fabian Ritter-Guttierez,Tim Polzehl,Sebastian Möller*

Main category: cs.SD

TL;DR: 论文提出了一种结合自监督学习（SSL）和手工谱特征（如MFCC、LFCC、CQCC）的混合融合框架，用于音频深度伪造检测，显著提升了泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有单模态检测方法易受非伪造干扰影响且泛化能力差，需改进。

Method: 研究多种融合策略（如简单拼接、交叉注意力、互交叉注意力、可学习门控机制）结合SSL和谱特征。

Result: 在四个公共基准测试中，所有融合变体均优于SSL基线，交叉注意力策略表现最佳，EER相对降低38%。

Conclusion: 联合建模波形和谱特征能生成鲁棒且领域无关的音频深度伪造检测表示。

Abstract: Recent advances in synthetic speech have made audio deepfakes increasingly
realistic, posing significant security risks. Existing detection methods that
rely on a single modality, either raw waveform embeddings or spectral based
features, are vulnerable to non spoof disturbances and often overfit to known
forgery algorithms, resulting in poor generalization to unseen attacks. To
address these shortcomings, we investigate hybrid fusion frameworks that
integrate self supervised learning (SSL) based representations with handcrafted
spectral descriptors (MFCC , LFCC, CQCC). By aligning and combining
complementary information across modalities, these fusion approaches capture
subtle artifacts that single feature approaches typically overlook. We explore
several fusion strategies, including simple concatenation, cross attention,
mutual cross attention, and a learnable gating mechanism, to optimally blend
SSL features with fine grained spectral cues. We evaluate our approach on four
challenging public benchmarks and report generalization performance. All fusion
variants consistently outperform an SSL only baseline, with the cross attention
strategy achieving the best generalization with a 38% relative reduction in
equal error rate (EER). These results confirm that joint modeling of waveform
and spectral views produces robust, domain agnostic representations for audio
deepfake detection.

</details>


### [38] [Sound Safeguarding for Acoustic Measurement Using Any Sounds: Tools and Applications](https://arxiv.org/abs/2507.20485)
*Hideki Kawahara,Kohei Yatabe,Ken-Ichi Sakakibara*

Main category: cs.SD

TL;DR: 介绍了基于“声音保护”方法开发的工具和应用，支持任何声音用于声学测量，包括准备、交互式实时测量和报告生成工具。


<details>
  <summary>Details</summary>
Motivation: 开发工具以改进声学环境，并鼓励用户使用开源工具。

Method: 基于“声音保护”方法，开发了多种工具，并在实际应用中不断改进。

Result: 成功开发并开源了相关工具，适用于多种实际场景。

Conclusion: 工具的开源和推广有助于改善声学环境，鼓励用户参与使用和改进。

Abstract: We demonstrate tools and applications developed based on the method of "sound
safeguarding," which enables any sound to be used for acoustic measurements. We
developed tools for preparation, interactive and real-time measurement, and
report generation. We extended and modified the method during its development
based on its application in various practical situations. We have open-sourced
these tools and encourage prospective users to use them to improve their
acoustic environments.

</details>


### [39] [Hyperbolic Embeddings for Order-Aware Classification of Audio Effect Chains](https://arxiv.org/abs/2507.20624)
*Aogu Wada,Tomohiko Nakamura,Hiroshi Saruwatari*

Main category: cs.SD

TL;DR: 该论文提出了一种基于神经网络的音频效果链识别方法，利用双曲空间高效建模效果链的非交换性和树状结构，实验表明其优于欧几里得空间方法。


<details>
  <summary>Details</summary>
Motivation: 音频效果链的顺序对最终声音有重要影响，但现有研究多集中于效果类型和参数估计，忽略了顺序问题。

Method: 提出一种神经网络方法，将湿信号嵌入双曲空间并分类效果链，利用双曲空间的指数扩展特性高效建模树状结构。

Result: 实验证明，该方法在吉他声音数据上优于欧几里得空间方法，尤其在效果类型和链长分析中表现突出。

Conclusion: 双曲空间能有效捕捉音频效果链的顺序特性，为音频处理研究提供了新方向。

Abstract: Audio effects (AFXs) are essential tools in music production, frequently
applied in chains to shape timbre and dynamics. The order of AFXs in a chain
plays a crucial role in determining the final sound, particularly when
non-linear (e.g., distortion) or time-variant (e.g., chorus) processors are
involved. Despite its importance, most AFX-related studies have primarily
focused on estimating effect types and their parameters from a wet signal. To
address this gap, we formulate AFX chain recognition as the task of jointly
estimating AFX types and their order from a wet signal. We propose a
neural-network-based method that embeds wet signals into a hyperbolic space and
classifies their AFX chains. Hyperbolic space can represent tree-structured
data more efficiently than Euclidean space due to its exponential expansion
property. Since AFX chains can be represented as trees, with AFXs as nodes and
edges encoding effect order, hyperbolic space is well-suited for modeling the
exponentially growing and non-commutative nature of ordered AFX combinations,
where changes in effect order can result in different final sounds. Experiments
using guitar sounds demonstrate that, with an appropriate curvature, the
proposed method outperforms its Euclidean counterpart. Further analysis based
on AFX type and chain length highlights the effectiveness of the proposed
method in capturing AFX order.

</details>


### [40] [Learning Neural Vocoder from Range-Null Space Decomposition](https://arxiv.org/abs/2507.20731)
*Andong Li,Tong Lei,Zhihang Sun,Rilin Chen,Erwei Yin,Xiaodong Li,Chengshi Zheng*

Main category: cs.SD

TL;DR: 提出了一种基于时频域的新型神经声码器，通过信号范围-零空间分解理论解决传统声码器的建模不透明和参数-性能权衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统神经声码器存在建模不透明和参数-性能权衡的挑战，需要一种更高效的方法。

Method: 结合经典信号范围-零空间分解理论，提出双路径框架，通过线性域转换和可学习网络分别处理范围空间和零空间。

Result: 在LJSpeech和LibriTTS基准测试中，该方法在轻量级参数下实现了最先进的性能。

Conclusion: 该方法通过创新的时频域分解和双路径框架，显著提升了声码器的性能和效率。

Abstract: Despite the rapid development of neural vocoders in recent years, they
usually suffer from some intrinsic challenges like opaque modeling, and
parameter-performance trade-off. In this study, we propose an innovative
time-frequency (T-F) domain-based neural vocoder to resolve the above-mentioned
challenges. To be specific, we bridge the connection between the classical
signal range-null decomposition (RND) theory and vocoder task, and the
reconstruction of target spectrogram can be decomposed into the superimposition
between the range-space and null-space, where the former is enabled by a linear
domain shift from the original mel-scale domain to the target linear-scale
domain, and the latter is instantiated via a learnable network for further
spectral detail generation. Accordingly, we propose a novel dual-path
framework, where the spectrum is hierarchically encoded/decoded, and the cross-
and narrow-band modules are elaborately devised for efficient sub-band and
sequential modeling. Comprehensive experiments are conducted on the LJSpeech
and LibriTTS benchmarks. Quantitative and qualitative results show that while
enjoying lightweight network parameters, the proposed approach yields
state-of-the-art performance among existing advanced methods. Our code and the
pretrained model weights are available at
https://github.com/Andong-Li-speech/RNDVoC.

</details>


### [41] [JAM: A Tiny Flow-based Song Generator with Fine-grained Controllability and Aesthetic Alignment](https://arxiv.org/abs/2507.20880)
*Renhang Liu,Chia-Yu Hung,Navonil Majumder,Taylor Gautreaux,Amir Ali Bagherzadeh,Chuan Li,Dorien Herremans,Soujanya Poria*

Main category: cs.SD

TL;DR: JAM是一种基于流匹配的歌词到歌曲生成模型，首次实现了词级时间和持续时间的控制，并通过直接偏好优化提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有歌词到歌曲生成模型缺乏词级可控性，无法满足音乐工作者的需求。

Method: 采用流匹配技术实现词级控制，并通过直接偏好优化进行美学对齐。

Result: JAM在音乐特定属性上优于现有模型。

Conclusion: JAM为歌词到歌曲生成提供了更精细的控制和更高的质量。

Abstract: Diffusion and flow-matching models have revolutionized automatic
text-to-audio generation in recent times. These models are increasingly capable
of generating high quality and faithful audio outputs capturing to speech and
acoustic events. However, there is still much room for improvement in creative
audio generation that primarily involves music and songs. Recent open
lyrics-to-song models, such as, DiffRhythm, ACE-Step, and LeVo, have set an
acceptable standard in automatic song generation for recreational use. However,
these models lack fine-grained word-level controllability often desired by
musicians in their workflows. To the best of our knowledge, our
flow-matching-based JAM is the first effort toward endowing word-level timing
and duration control in song generation, allowing fine-grained vocal control.
To enhance the quality of generated songs to better align with human
preferences, we implement aesthetic alignment through Direct Preference
Optimization, which iteratively refines the model using a synthetic dataset,
eliminating the need or manual data annotations. Furthermore, we aim to
standardize the evaluation of such lyrics-to-song models through our public
evaluation dataset JAME. We show that JAM outperforms the existing models in
terms of the music-specific attributes.

</details>


### [42] [Music Arena: Live Evaluation for Text-to-Music](https://arxiv.org/abs/2507.20900)
*Yonghyun Kim,Wayne Chi,Anastasios N. Angelopoulos,Wei-Lin Chiang,Koichi Saito,Shinji Watanabe,Yuki Mitsufuji,Chris Donahue*

Main category: cs.SD

TL;DR: Music Arena是一个开放平台，用于通过人类偏好评估文本到音乐（TTM）模型，提供实时评估、标准化协议和音乐特定功能。


<details>
  <summary>Details</summary>
Motivation: 解决TTM领域人类偏好评估的高成本和难以比较的问题，同时为研究提供开放且可更新的偏好数据源。

Method: 通过用户输入文本提示并比较两个TTM系统的输出，收集偏好数据，设计LLM路由系统和详细偏好收集功能。

Result: Music Arena提供了一个标准化评估协议和透明数据访问政策，解决了TTM生态系统的关键挑战。

Conclusion: Music Arena展示了如何针对特定AI领域的独特特性进行实时评估，并为TTM研究提供了实用工具。

Abstract: We present Music Arena, an open platform for scalable human preference
evaluation of text-to-music (TTM) models. Soliciting human preferences via
listening studies is the gold standard for evaluation in TTM, but these studies
are expensive to conduct and difficult to compare, as study protocols may
differ across systems. Moreover, human preferences might help researchers align
their TTM systems or improve automatic evaluation metrics, but an open and
renewable source of preferences does not currently exist. We aim to fill these
gaps by offering *live* evaluation for TTM. In Music Arena, real-world users
input text prompts of their choosing and compare outputs from two TTM systems,
and their preferences are used to compile a leaderboard. While Music Arena
follows recent evaluation trends in other AI domains, we also design it with
key features tailored to music: an LLM-based routing system to navigate the
heterogeneous type signatures of TTM systems, and the collection of *detailed*
preferences including listening data and natural language feedback. We also
propose a rolling data release policy with user privacy guarantees, providing a
renewable source of preference data and increasing platform transparency.
Through its standardized evaluation protocol, transparent data access policies,
and music-specific features, Music Arena not only addresses key challenges in
the TTM ecosystem but also demonstrates how live evaluation can be thoughtfully
adapted to unique characteristics of specific AI domains.
  Music Arena is available at: https://music-arena.org

</details>

{"id": "2507.21202", "categories": ["cs.SD", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.21202", "abs": "https://arxiv.org/abs/2507.21202", "authors": ["Cameron Churchwell", "Minje Kim", "Paris Smaragdis"], "title": "Combolutional Neural Networks", "comment": "4 pages, 3 figures, accepted to WASPAA 2025", "summary": "Selecting appropriate inductive biases is an essential step in the design of\nmachine learning models, especially when working with audio, where even short\nclips may contain millions of samples. To this end, we propose the\ncombolutional layer: a learned-delay IIR comb filter and fused envelope\ndetector, which extracts harmonic features in the time domain. We demonstrate\nthe efficacy of the combolutional layer on three information retrieval tasks,\nevaluate its computational cost relative to other audio frontends, and provide\nefficient implementations for training. We find that the combolutional layer is\nan effective replacement for convolutional layers in audio tasks where precise\nharmonic analysis is important, e.g., piano transcription, speaker\nclassification, and key detection. Additionally, the combolutional layer has\nseveral other key benefits over existing frontends, namely: low parameter\ncount, efficient CPU inference, strictly real-valued computations, and improved\ninterpretability.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3a\u201ccombolutional layer\u201d\u7684\u65b0\u5c42\u7ed3\u6784\uff0c\u7528\u4e8e\u97f3\u9891\u4efb\u52a1\u4e2d\u7684\u8c10\u6ce2\u7279\u5f81\u63d0\u53d6\uff0c\u66ff\u4ee3\u4f20\u7edf\u5377\u79ef\u5c42\uff0c\u5177\u6709\u4f4e\u53c2\u6570\u3001\u9ad8\u6548CPU\u63a8\u7406\u7b49\u4f18\u52bf\u3002", "motivation": "\u5728\u97f3\u9891\u4efb\u52a1\u4e2d\uff0c\u77ed\u7247\u6bb5\u53ef\u80fd\u5305\u542b\u6570\u767e\u4e07\u6837\u672c\uff0c\u9009\u62e9\u5408\u9002\u7684\u5f52\u7eb3\u504f\u7f6e\u5bf9\u673a\u5668\u5b66\u4e60\u6a21\u578b\u8bbe\u8ba1\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51facombolutional\u5c42\uff0c\u7ed3\u5408\u5b66\u4e60\u5ef6\u8fdfIIR\u68b3\u72b6\u6ee4\u6ce2\u5668\u548c\u878d\u5408\u5305\u7edc\u68c0\u6d4b\u5668\uff0c\u5728\u65f6\u57df\u63d0\u53d6\u8c10\u6ce2\u7279\u5f81\u3002", "result": "\u5728\u94a2\u7434\u8f6c\u5f55\u3001\u8bf4\u8bdd\u4eba\u5206\u7c7b\u548c\u97f3\u8c03\u68c0\u6d4b\u7b49\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0c\u8ba1\u7b97\u6210\u672c\u4f4e\u4e14\u5b9e\u73b0\u9ad8\u6548\u3002", "conclusion": "combolutional\u5c42\u5728\u9700\u8981\u7cbe\u786e\u8c10\u6ce2\u5206\u6790\u7684\u97f3\u9891\u4efb\u52a1\u4e2d\u662f\u5377\u79ef\u5c42\u7684\u6709\u6548\u66ff\u4ee3\uff0c\u5177\u6709\u53c2\u6570\u5c11\u3001\u8ba1\u7b97\u9ad8\u6548\u548c\u53ef\u89e3\u91ca\u6027\u5f3a\u7b49\u4f18\u52bf\u3002"}}
{"id": "2507.21426", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.21426", "abs": "https://arxiv.org/abs/2507.21426", "authors": ["Bence Mark Halpern", "Thomas Tienkamp", "Teja Rebernik", "Rob J. J. H. van Son", "Martijn Wieling", "Defne Abur", "Tomoki Toda"], "title": "Relationship between objective and subjective perceptual measures of speech in individuals with head and neck cancer", "comment": "5 pages, 1 figure, 1 table. Accepted at Interspeech 2025", "summary": "Meaningful speech assessment is vital in clinical phonetics and therapy\nmonitoring. This study examined the link between perceptual speech assessments\nand objective acoustic measures in a large head and neck cancer (HNC) dataset.\nTrained listeners provided ratings of intelligibility, articulation, voice\nquality, phonation, speech rate, nasality, and background noise on speech.\nStrong correlations were found between subjective intelligibility,\narticulation, and voice quality, likely due to a shared underlying cause of\nspeech symptoms in our speaker population. Objective measures of\nintelligibility and speech rate aligned with their subjective counterpart. Our\nresults suggest that a single intelligibility measure may be sufficient for the\nclinical monitoring of speakers treated for HNC using concomitant\nchemoradiation.", "AI": {"tldr": "\u7814\u7a76\u63a2\u8ba8\u4e86\u4e3b\u89c2\u8bed\u97f3\u8bc4\u4f30\u4e0e\u5ba2\u89c2\u58f0\u5b66\u6d4b\u91cf\u5728\u5934\u9888\u764c\u60a3\u8005\u4e2d\u7684\u5173\u8054\uff0c\u53d1\u73b0\u4e3b\u89c2\u53ef\u61c2\u5ea6\u3001\u53d1\u97f3\u548c\u97f3\u8d28\u4e0e\u5ba2\u89c2\u6d4b\u91cf\u9ad8\u5ea6\u76f8\u5173\uff0c\u63d0\u793a\u5355\u4e00\u53ef\u61c2\u5ea6\u6d4b\u91cf\u53ef\u80fd\u8db3\u4ee5\u7528\u4e8e\u4e34\u5e8a\u76d1\u6d4b\u3002", "motivation": "\u4e34\u5e8a\u8bed\u97f3\u5b66\u548c\u6cbb\u7597\u76d1\u6d4b\u9700\u8981\u6709\u6548\u7684\u8bed\u97f3\u8bc4\u4f30\u65b9\u6cd5\uff0c\u7814\u7a76\u65e8\u5728\u9a8c\u8bc1\u4e3b\u89c2\u8bc4\u4f30\u4e0e\u5ba2\u89c2\u6d4b\u91cf\u7684\u5173\u8054\u6027\u3002", "method": "\u901a\u8fc7\u8bad\u7ec3\u6709\u7d20\u7684\u542c\u8bc4\u5458\u5bf9\u5934\u9888\u764c\u60a3\u8005\u7684\u8bed\u97f3\u8fdb\u884c\u4e3b\u89c2\u8bc4\u5206\uff0c\u5e76\u4e0e\u5ba2\u89c2\u58f0\u5b66\u6d4b\u91cf\u6570\u636e\u5bf9\u6bd4\u5206\u6790\u3002", "result": "\u4e3b\u89c2\u53ef\u61c2\u5ea6\u3001\u53d1\u97f3\u548c\u97f3\u8d28\u4e0e\u5ba2\u89c2\u6d4b\u91cf\u9ad8\u5ea6\u76f8\u5173\uff0c\u4e14\u53ef\u61c2\u5ea6\u4e0e\u8bed\u901f\u7684\u5ba2\u89c2\u6d4b\u91cf\u4e0e\u4e3b\u89c2\u8bc4\u5206\u4e00\u81f4\u3002", "conclusion": "\u5355\u4e00\u53ef\u61c2\u5ea6\u6d4b\u91cf\u53ef\u80fd\u8db3\u4ee5\u7528\u4e8e\u5934\u9888\u764c\u60a3\u8005\u7684\u4e34\u5e8a\u76d1\u6d4b\uff0c\u7b80\u5316\u8bc4\u4f30\u6d41\u7a0b\u3002"}}
{"id": "2507.21463", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.21463", "abs": "https://arxiv.org/abs/2507.21463", "authors": ["Wen Huang", "Yanmei Gu", "Zhiming Wang", "Huijia Zhu", "Yanmin Qian"], "title": "SpeechFake: A Large-Scale Multilingual Speech Deepfake Dataset Incorporating Cutting-Edge Generation Methods", "comment": "Published in ACL 2025. Dataset available at:\n  https://github.com/YMLLG/SpeechFake", "summary": "As speech generation technology advances, the risk of misuse through deepfake\naudio has become a pressing concern, which underscores the critical need for\nrobust detection systems. However, many existing speech deepfake datasets are\nlimited in scale and diversity, making it challenging to train models that can\ngeneralize well to unseen deepfakes. To address these gaps, we introduce\nSpeechFake, a large-scale dataset designed specifically for speech deepfake\ndetection. SpeechFake includes over 3 million deepfake samples, totaling more\nthan 3,000 hours of audio, generated using 40 different speech synthesis tools.\nThe dataset encompasses a wide range of generation techniques, including\ntext-to-speech, voice conversion, and neural vocoder, incorporating the latest\ncutting-edge methods. It also provides multilingual support, spanning 46\nlanguages. In this paper, we offer a detailed overview of the dataset's\ncreation, composition, and statistics. We also present baseline results by\ntraining detection models on SpeechFake, demonstrating strong performance on\nboth its own test sets and various unseen test sets. Additionally, we conduct\nexperiments to rigorously explore how generation methods, language diversity,\nand speaker variation affect detection performance. We believe SpeechFake will\nbe a valuable resource for advancing speech deepfake detection and developing\nmore robust models for evolving generation techniques.", "AI": {"tldr": "\u8bba\u6587\u4ecb\u7ecd\u4e86SpeechFake\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bed\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\uff0c\u5305\u542b300\u4e07\u6837\u672c\u548c3000\u5c0f\u65f6\u97f3\u9891\uff0c\u8986\u76d640\u79cd\u5408\u6210\u5de5\u5177\u548c46\u79cd\u8bed\u8a00\uff0c\u5e76\u5c55\u793a\u4e86\u68c0\u6d4b\u6a21\u578b\u7684\u57fa\u7ebf\u6027\u80fd\u3002", "motivation": "\u8bed\u97f3\u751f\u6210\u6280\u672f\u7684\u8fdb\u6b65\u5e26\u6765\u4e86\u6df1\u5ea6\u4f2a\u9020\u97f3\u9891\u7684\u6ee5\u7528\u98ce\u9669\uff0c\u73b0\u6709\u6570\u636e\u96c6\u89c4\u6a21\u5c0f\u4e14\u591a\u6837\u6027\u4e0d\u8db3\uff0c\u96be\u4ee5\u8bad\u7ec3\u6cdb\u5316\u80fd\u529b\u5f3a\u7684\u68c0\u6d4b\u6a21\u578b\u3002", "method": "\u6784\u5efa\u4e86\u5927\u89c4\u6a21\u3001\u591a\u6837\u5316\u7684SpeechFake\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u79cd\u751f\u6210\u6280\u672f\u548c\u8bed\u8a00\u652f\u6301\uff0c\u5e76\u8bad\u7ec3\u68c0\u6d4b\u6a21\u578b\u8fdb\u884c\u6027\u80fd\u8bc4\u4f30\u3002", "result": "\u68c0\u6d4b\u6a21\u578b\u5728SpeechFake\u6d4b\u8bd5\u96c6\u548c\u672a\u89c1\u6d4b\u8bd5\u96c6\u4e0a\u8868\u73b0\u826f\u597d\uff0c\u5b9e\u9a8c\u5206\u6790\u4e86\u751f\u6210\u65b9\u6cd5\u3001\u8bed\u8a00\u591a\u6837\u6027\u548c\u8bf4\u8bdd\u4eba\u53d8\u5316\u5bf9\u68c0\u6d4b\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "SpeechFake\u662f\u63a8\u52a8\u8bed\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7814\u7a76\u7684\u5b9d\u8d35\u8d44\u6e90\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u9c81\u68d2\u7684\u6a21\u578b\u5e94\u5bf9\u4e0d\u65ad\u6f14\u53d8\u7684\u751f\u6210\u6280\u672f\u3002"}}
{"id": "2507.21642", "categories": ["cs.SD", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.21642", "abs": "https://arxiv.org/abs/2507.21642", "authors": ["William Ravenscroft", "George Close", "Kit Bower-Morris", "Jamie Stacey", "Dmitry Sityaev", "Kris Y. Hong"], "title": "Whilter: A Whisper-based Data Filter for \"In-the-Wild\" Speech Corpora Using Utterance-level Multi-Task Classification", "comment": "Accepted for Interspeech 2025", "summary": "Large-scale in-the-wild speech datasets have become more prevalent in recent\nyears due to increased interest in models that can learn useful features from\nunlabelled data for tasks such as speech recognition or synthesis. These\ndatasets often contain undesirable features, such as multiple speakers,\nnon-target languages, and music, which may impact model learning. The Whilter\nmodel is proposed as a multitask solution to identify these undesirable\nsamples. Whilter uses a Whisper encoder with an attention-based classifier to\nsolve five diverse classification problems at once. In addition, an annotated\ndataset is published for a subset of two popular in-the-wild corpora. Whilter\nachieves F1 scores above 85% and equal error rates of 6.5% to 7.8% for three of\nfive subtasks, outperforming a state-of-the-art BEATs classifier on\nspeech-specific classes, with a notable decrease in processing time compared to\na combination of single-task alternatives.", "AI": {"tldr": "Whilter\u6a21\u578b\u662f\u4e00\u79cd\u591a\u4efb\u52a1\u89e3\u51b3\u65b9\u6848\uff0c\u7528\u4e8e\u8bc6\u522b\u5927\u89c4\u6a21\u8bed\u97f3\u6570\u636e\u96c6\u4e2d\u7684\u4e0d\u826f\u6837\u672c\uff0c\u5982\u591a\u8bf4\u8bdd\u8005\u3001\u975e\u76ee\u6807\u8bed\u8a00\u548c\u97f3\u4e50\u3002\u5b83\u57fa\u4e8eWhisper\u7f16\u7801\u5668\u548c\u6ce8\u610f\u529b\u5206\u7c7b\u5668\uff0c\u5728\u4e94\u4e2a\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u5f02\uff0cF1\u5206\u6570\u8d85\u8fc785%\uff0c\u5904\u7406\u65f6\u95f4\u663e\u8457\u51cf\u5c11\u3002", "motivation": "\u5927\u89c4\u6a21\u8bed\u97f3\u6570\u636e\u96c6\u4e2d\u5b58\u5728\u4e0d\u826f\u7279\u5f81\uff08\u5982\u591a\u8bf4\u8bdd\u8005\u3001\u975e\u76ee\u6807\u8bed\u8a00\u548c\u97f3\u4e50\uff09\uff0c\u53ef\u80fd\u5f71\u54cd\u6a21\u578b\u5b66\u4e60\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u9ad8\u6548\u7684\u591a\u4efb\u52a1\u89e3\u51b3\u65b9\u6848\u3002", "method": "Whilter\u6a21\u578b\u7ed3\u5408Whisper\u7f16\u7801\u5668\u548c\u6ce8\u610f\u529b\u5206\u7c7b\u5668\uff0c\u540c\u65f6\u89e3\u51b3\u4e94\u4e2a\u5206\u7c7b\u95ee\u9898\uff0c\u5e76\u53d1\u5e03\u4e86\u4e00\u4e2a\u6807\u6ce8\u6570\u636e\u96c6\u3002", "result": "Whilter\u5728\u4e09\u4e2a\u5b50\u4efb\u52a1\u4e2dF1\u5206\u6570\u8d85\u8fc785%\uff0c\u9519\u8bef\u73876.5%-7.8%\uff0c\u4f18\u4e8eBEATs\u5206\u7c7b\u5668\uff0c\u4e14\u5904\u7406\u65f6\u95f4\u66f4\u77ed\u3002", "conclusion": "Whilter\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u591a\u4efb\u52a1\u6a21\u578b\uff0c\u9002\u7528\u4e8e\u8bc6\u522b\u8bed\u97f3\u6570\u636e\u96c6\u4e2d\u7684\u4e0d\u826f\u6837\u672c\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2507.21448", "categories": ["eess.AS", "cs.ET", "cs.LG"], "pdf": "https://arxiv.org/pdf/2507.21448", "abs": "https://arxiv.org/abs/2507.21448", "authors": ["Teng", "Ma", "Sile Yin", "Li-Chia Yang", "Shuo Zhang"], "title": "Real-Time Audio-Visual Speech Enhancement Using Pre-trained Visual Representations", "comment": "Accepted into Interspeech 2025", "summary": "Speech enhancement in audio-only settings remains challenging, particularly\nin the presence of interfering speakers. This paper presents a simple yet\neffective real-time audio-visual speech enhancement (AVSE) system, RAVEN, which\nisolates and enhances the on-screen target speaker while suppressing\ninterfering speakers and background noise. We investigate how visual embeddings\nlearned from audio-visual speech recognition (AVSR) and active speaker\ndetection (ASD) contribute to AVSE across different SNR conditions and numbers\nof interfering speakers. Our results show concatenating embeddings from AVSR\nand ASD models provides the greatest improvement in low-SNR, multi-speaker\nenvironments, while AVSR embeddings alone perform best in noise-only scenarios.\nIn addition, we develop a real-time streaming system that operates on a\ncomputer CPU and we provide a video demonstration and code repository. To our\nknowledge, this is the first open-source implementation of a real-time AVSE\nsystem.", "AI": {"tldr": "RAVEN\u662f\u4e00\u4e2a\u5b9e\u65f6\u97f3\u89c6\u9891\u8bed\u97f3\u589e\u5f3a\u7cfb\u7edf\uff0c\u901a\u8fc7\u7ed3\u5408\u97f3\u9891\u548c\u89c6\u89c9\u4fe1\u606f\uff0c\u6709\u6548\u589e\u5f3a\u76ee\u6807\u8bf4\u8bdd\u4eba\u58f0\u97f3\u5e76\u6291\u5236\u5e72\u6270\u3002", "motivation": "\u89e3\u51b3\u97f3\u9891\u73af\u5883\u4e2d\u5e72\u6270\u8bf4\u8bdd\u4eba\u548c\u80cc\u666f\u566a\u58f0\u5bf9\u8bed\u97f3\u589e\u5f3a\u7684\u6311\u6218\u3002", "method": "\u7ed3\u5408\u97f3\u9891-\u89c6\u89c9\u8bed\u97f3\u8bc6\u522b\uff08AVSR\uff09\u548c\u4e3b\u52a8\u8bf4\u8bdd\u4eba\u68c0\u6d4b\uff08ASD\uff09\u7684\u89c6\u89c9\u5d4c\u5165\uff0c\u5f00\u53d1\u5b9e\u65f6\u6d41\u5f0f\u7cfb\u7edf\u3002", "result": "AVSR\u548cASD\u5d4c\u5165\u7ed3\u5408\u5728\u4f4e\u4fe1\u566a\u6bd4\u591a\u8bf4\u8bdd\u4eba\u73af\u5883\u4e2d\u6548\u679c\u6700\u4f73\uff0cAVSR\u5d4c\u5165\u5728\u7eaf\u566a\u58f0\u573a\u666f\u4e2d\u8868\u73b0\u6700\u597d\u3002", "conclusion": "RAVEN\u662f\u9996\u4e2a\u5f00\u6e90\u7684\u5b9e\u65f6AVSE\u7cfb\u7edf\uff0c\u5c55\u793a\u4e86\u97f3\u89c6\u9891\u7ed3\u5408\u5728\u8bed\u97f3\u589e\u5f3a\u4e2d\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.21347", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.21347", "abs": "https://arxiv.org/abs/2507.21347", "authors": ["Haonan Si", "Zhaolin Wang", "Xiansheng Guo", "Jin Zhang", "Yuanwei Liu"], "title": "DOA Estimation via Continuous Aperture Arrays: MUSIC and CRLB", "comment": "Submit to possible IEEE journal", "summary": "Direction-of-arrival (DOA) estimation using continuous aperture array (CAPA)\nis studied. Compared to the conventional spatially discrete array (SPDA), CAPA\nsignificantly enhances the spatial degrees-of-freedoms (DoFs) for DOA\nestimation, but its infinite-dimensional continuous signals render the\nconventional estimation algorithm non-applicable. To address this challenge, a\nnew multiple signal classification (MUSIC) algorithm is proposed for CAPAs. In\nparticular, an equivalent continuous-discrete transformation is proposed to\nfacilitate the eigendecomposition of continuous operators. Subsequently, the\nMUSIC spectrum is accurately approximated using the Gauss-Legendre quadrature,\neffectively reducing the computational complexity. Furthermore, the\nCram\\'er-Rao lower bounds (CRLBs) for DOA estimation using CAPAs are analyzed\nfor both cases with and without priori knowledge of snapshot signals. It is\ntheoretically proved that CAPAs significantly improve the DOA estimation\naccuracy compared to traditional SPDAs. Numerical results further validate this\ninsight and demonstrate the effectiveness of the proposed MUSIC algorithm for\nCAPA. The proposed method achieves near-optimal estimation performance while\nmaintaining a low computational complexity.", "AI": {"tldr": "\u7814\u7a76\u4e86\u4f7f\u7528\u8fde\u7eed\u5b54\u5f84\u9635\u5217\uff08CAPA\uff09\u8fdb\u884c\u65b9\u5411\u5230\u8fbe\uff08DOA\uff09\u4f30\u8ba1\u7684\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684MUSIC\u7b97\u6cd5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u7b97\u6cd5\u4e0d\u9002\u7528\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u3002", "motivation": "\u4f20\u7edf\u7a7a\u95f4\u79bb\u6563\u9635\u5217\uff08SPDA\uff09\u5728DOA\u4f30\u8ba1\u4e2d\u81ea\u7531\u5ea6\u6709\u9650\uff0c\u800cCAPA\u867d\u7136\u80fd\u663e\u8457\u63d0\u5347\u81ea\u7531\u5ea6\uff0c\u4f46\u5176\u8fde\u7eed\u4fe1\u53f7\u7279\u6027\u4f7f\u5f97\u4f20\u7edf\u4f30\u8ba1\u7b97\u6cd5\u4e0d\u9002\u7528\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684MUSIC\u7b97\u6cd5\uff0c\u901a\u8fc7\u7b49\u6548\u8fde\u7eed-\u79bb\u6563\u53d8\u6362\u5b9e\u73b0\u8fde\u7eed\u7b97\u5b50\u7684\u7279\u5f81\u5206\u89e3\uff0c\u5e76\u5229\u7528\u9ad8\u65af-\u52d2\u8ba9\u5fb7\u79ef\u5206\u8fd1\u4f3cMUSIC\u8c31\u4ee5\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u7406\u8bba\u8bc1\u660eCAPA\u663e\u8457\u63d0\u9ad8\u4e86DOA\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0MUSIC\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u7684\u4f30\u8ba1\u6027\u80fd\u4e14\u8ba1\u7b97\u590d\u6742\u5ea6\u4f4e\u3002", "conclusion": "CAPA\u7ed3\u5408\u65b0MUSIC\u7b97\u6cd5\u5728DOA\u4f30\u8ba1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f18\u4e8e\u4f20\u7edfSPDA\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2507.20624", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.20624", "abs": "https://arxiv.org/abs/2507.20624", "authors": ["Aogu Wada", "Tomohiko Nakamura", "Hiroshi Saruwatari"], "title": "Hyperbolic Embeddings for Order-Aware Classification of Audio Effect Chains", "comment": "7 pages, 3 figures, accepted for the 28th International Conference on\n  Digital Audio Effects (DAFx25)", "summary": "Audio effects (AFXs) are essential tools in music production, frequently\napplied in chains to shape timbre and dynamics. The order of AFXs in a chain\nplays a crucial role in determining the final sound, particularly when\nnon-linear (e.g., distortion) or time-variant (e.g., chorus) processors are\ninvolved. Despite its importance, most AFX-related studies have primarily\nfocused on estimating effect types and their parameters from a wet signal. To\naddress this gap, we formulate AFX chain recognition as the task of jointly\nestimating AFX types and their order from a wet signal. We propose a\nneural-network-based method that embeds wet signals into a hyperbolic space and\nclassifies their AFX chains. Hyperbolic space can represent tree-structured\ndata more efficiently than Euclidean space due to its exponential expansion\nproperty. Since AFX chains can be represented as trees, with AFXs as nodes and\nedges encoding effect order, hyperbolic space is well-suited for modeling the\nexponentially growing and non-commutative nature of ordered AFX combinations,\nwhere changes in effect order can result in different final sounds. Experiments\nusing guitar sounds demonstrate that, with an appropriate curvature, the\nproposed method outperforms its Euclidean counterpart. Further analysis based\non AFX type and chain length highlights the effectiveness of the proposed\nmethod in capturing AFX order.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u6e7f\u4fe1\u53f7\u4e2d\u8054\u5408\u4f30\u8ba1\u97f3\u9891\u6548\u679c\uff08AFX\uff09\u7c7b\u578b\u53ca\u5176\u987a\u5e8f\uff0c\u5229\u7528\u53cc\u66f2\u7a7a\u95f4\u9ad8\u6548\u5efa\u6a21AFX\u94fe\u7684\u6811\u72b6\u7ed3\u6784\u3002", "motivation": "\u97f3\u9891\u6548\u679c\u94fe\u7684\u987a\u5e8f\u5bf9\u6700\u7ec8\u58f0\u97f3\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u6548\u679c\u7c7b\u578b\u548c\u53c2\u6570\u7684\u4f30\u8ba1\uff0c\u5ffd\u7565\u4e86\u987a\u5e8f\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff0c\u5c06\u6e7f\u4fe1\u53f7\u5d4c\u5165\u53cc\u66f2\u7a7a\u95f4\u5e76\u5206\u7c7b\u5176AFX\u94fe\uff0c\u5229\u7528\u53cc\u66f2\u7a7a\u95f4\u7684\u6307\u6570\u6269\u5c55\u7279\u6027\u9ad8\u6548\u8868\u793a\u6811\u72b6\u7ed3\u6784\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5409\u4ed6\u58f0\u97f3\u4e0a\u8868\u73b0\u4f18\u4e8e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u65b9\u6cd5\uff0c\u5c24\u5176\u5728\u6355\u6349AFX\u987a\u5e8f\u65b9\u9762\u6548\u679c\u663e\u8457\u3002", "conclusion": "\u53cc\u66f2\u7a7a\u95f4\u80fd\u6709\u6548\u5efa\u6a21AFX\u94fe\u7684\u975e\u4ea4\u6362\u6027\u548c\u6307\u6570\u589e\u957f\u7279\u6027\uff0c\u4e3a\u97f3\u9891\u6548\u679c\u94fe\u8bc6\u522b\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\u3002"}}
{"id": "2507.21454", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.21454", "abs": "https://arxiv.org/abs/2507.21454", "authors": ["Zhuoran Xiao", "Chenhui Ye", "Yijia Feng", "Yunbo Hu", "Tianyu Jiao", "Liyu Cai", "Guangyi Liu"], "title": "Transmission With Machine Language Tokens: A Paradigm for Task-Oriented Agent Communication", "comment": "Accepted by IEEE Globecom 2025", "summary": "The rapid advancement in large foundation models is propelling the paradigm\nshifts across various industries. One significant change is that agents,\ninstead of traditional machines or humans, will be the primary participants in\nthe future production process, which consequently requires a novel AI-native\ncommunication system tailored for agent communications. Integrating the ability\nof large language models (LLMs) with task-oriented semantic communication is a\npotential approach. However, the output of existing LLM is human language,\nwhich is highly constrained and sub-optimal for agent-type communication. In\nthis paper, we innovatively propose a task-oriented agent communication system.\nSpecifically, we leverage the original LLM to learn a specialized machine\nlanguage represented by token embeddings. Simultaneously, a multi-modal LLM is\ntrained to comprehend the application task and to extract essential implicit\ninformation from multi-modal inputs, subsequently expressing it using machine\nlanguage tokens. This representation is significantly more efficient for\ntransmission over the air interface. Furthermore, to reduce transmission\noverhead, we introduce a joint token and channel coding (JTCC) scheme that\ncompresses the token sequence by exploiting its sparsity while enhancing\nrobustness against channel noise. Extensive experiments demonstrate that our\napproach reduces transmission overhead for downstream tasks while enhancing\naccuracy relative to the SOTA methods.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u5411\u4efb\u52a1\u7684\u667a\u80fd\u4f53\u901a\u4fe1\u7cfb\u7edf\uff0c\u5229\u7528LLM\u5b66\u4e60\u4e13\u7528\u673a\u5668\u8bed\u8a00\uff0c\u7ed3\u5408\u591a\u6a21\u6001LLM\u63d0\u53d6\u4efb\u52a1\u4fe1\u606f\uff0c\u5e76\u901a\u8fc7JTCC\u65b9\u6848\u964d\u4f4e\u4f20\u8f93\u5f00\u9500\u3002", "motivation": "\u968f\u7740\u5927\u578b\u57fa\u7840\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u667a\u80fd\u4f53\u5c06\u6210\u4e3a\u672a\u6765\u751f\u4ea7\u7684\u4e3b\u8981\u53c2\u4e0e\u8005\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u578bAI\u539f\u751f\u901a\u4fe1\u7cfb\u7edf\u3002\u73b0\u6709LLM\u8f93\u51fa\u7684\u4eba\u7c7b\u8bed\u8a00\u5bf9\u667a\u80fd\u4f53\u901a\u4fe1\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u5229\u7528\u539f\u59cbLLM\u5b66\u4e60\u4e13\u7528\u673a\u5668\u8bed\u8a00\uff0c\u8bad\u7ec3\u591a\u6a21\u6001LLM\u63d0\u53d6\u4efb\u52a1\u4fe1\u606f\u5e76\u8868\u8fbe\u4e3a\u673a\u5668\u8bed\u8a00\uff0c\u5f15\u5165JTCC\u65b9\u6848\u538b\u7f29\u4ee4\u724c\u5e8f\u5217\u5e76\u589e\u5f3a\u6297\u566a\u80fd\u529b\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u964d\u4f4e\u4e86\u4f20\u8f93\u5f00\u9500\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u4e0b\u6e38\u4efb\u52a1\u7684\u51c6\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u7cfb\u7edf\u663e\u8457\u63d0\u5347\u4e86\u667a\u80fd\u4f53\u901a\u4fe1\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\uff0c\u4e3a\u672a\u6765AI\u539f\u751f\u901a\u4fe1\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2507.21511", "categories": ["eess.SP", "26A33, 42A38, 94A08, 94A12", "I.4.3; I.6.3; I.5.2; G.1.2"], "pdf": "https://arxiv.org/pdf/2507.21511", "abs": "https://arxiv.org/abs/2507.21511", "authors": ["Daxiang Li", "Zhichao Zhang", "Wei Yao"], "title": "Two-Dimensional Nonseparable Fractional Fourier Transform: Theory and Application", "comment": "26 pages, 11 figures", "summary": "The one-dimensional (1D) fractional Fourier transform (FRFT) generalizes the\n1D Fourier transform, offering significant advantages in time-frequency\nanalysis of non-stationary signals. To extend the benefits of the 1D FRFT to\nhigher-dimensional signals, 2D FRFTs, such as the 2D separable FRFT (SFRFT),\ngyrator transform (GT), and coupled FRFT (CFRFT), have been developed. However,\nexisting 2D FRFTs suffer from several limitations: (1) a lack of theoretical\nuniformity and general applicability, (2) an inability to handle 2D\nnon-stationary signals with nonseparable terms, and (3) failure to maintain a\nconsistent 4D rotational relationship with the 2D Wigner distribution (WD),\nwhich is essential for ensuring geometric consistency and symmetry in\ntime-frequency analysis. These limitations restrict the methods' performance in\npractical applications, such as radar, communication, sonar, and optical\nimaging, in which nonseparable terms frequently arise. To address these\nchallenges, we introduce a more general definition of the 2D FRFT, termed the\n2D nonseparable FRFT (NSFRFT). The 2D NSFRFT has four degrees of freedom,\nincludes the 2D SFRFT, GT, and CFRFT as special cases, and maintains a more\ngeneral 4D rotational relationship with the 2D WD. We derive its properties and\npresent three discrete algorithms, two of which are fast algorithms with\ncomputational complexity $O(N^2 \\log N)$ comparable to that of the 2D SFRFT.\nNumerical simulations and experiments demonstrate the superior performance of\nthe 2D NSFRFT in applications such as image encryption, decryption, filtering,\nand denoising.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u4e8c\u7ef4\u975e\u53ef\u5206\u79bb\u5206\u6570\u5085\u91cc\u53f6\u53d8\u6362\uff08NSFRFT\uff09\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u4e8c\u7ef4FRFT\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u4e8c\u7ef4FRFT\u5b58\u5728\u7406\u8bba\u4e0d\u7edf\u4e00\u3001\u65e0\u6cd5\u5904\u7406\u975e\u53ef\u5206\u79bb\u4fe1\u53f7\u4ee5\u53ca\u7f3a\u4e4f\u4e0e\u4e8c\u7ef4Wigner\u5206\u5e03\u7684\u4e00\u81f4\u6027\u65cb\u8f6c\u5173\u7cfb\u7b49\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u66f4\u901a\u7528\u7684\u4e8c\u7ef4NSFRFT\u5b9a\u4e49\uff0c\u5177\u6709\u56db\u4e2a\u81ea\u7531\u5ea6\uff0c\u5e76\u63a8\u5bfc\u4e86\u5176\u6027\u8d28\uff0c\u540c\u65f6\u63d0\u51fa\u4e86\u4e09\u79cd\u79bb\u6563\u7b97\u6cd5\uff0c\u5176\u4e2d\u4e24\u79cd\u662f\u5feb\u901f\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u6a21\u62df\u548c\u5b9e\u9a8c\u8868\u660e\uff0c2D NSFRFT\u5728\u56fe\u50cf\u52a0\u5bc6\u3001\u89e3\u5bc6\u3001\u6ee4\u6ce2\u548c\u53bb\u566a\u7b49\u5e94\u7528\u4e2d\u8868\u73b0\u4f18\u8d8a\u3002", "conclusion": "2D NSFRFT\u662f\u4e00\u79cd\u66f4\u901a\u7528\u7684\u65b9\u6cd5\uff0c\u80fd\u591f\u514b\u670d\u73b0\u6709\u4e8c\u7ef4FRFT\u7684\u5c40\u9650\u6027\uff0c\u5e76\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5c55\u73b0\u51fa\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2507.21527", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.21527", "abs": "https://arxiv.org/abs/2507.21527", "authors": ["Ziqi Yan", "Zhichao Zhang"], "title": "Trainable Joint Time-Vertex Fractional Fourier Transform", "comment": "35 pages,5 figures", "summary": "To address limitations of the graph fractional Fourier transform (GFRFT)\nWiener filtering and the traditional joint time-vertex fractional Fourier\ntransform (JFRFT) Wiener filtering, this study proposes a filtering method\nbased on the hyper-differential form of the JFRFT. The gradient backpropagation\nmechanism is employed to enable the adaptive selection of transform order pair\nand filter coefficients. First, leveraging the hyper-differential form of the\nGFRFT and the fractional Fourier transform, the hyper-differential form of the\nJFRFT is constructed and its properties are analyzed. Second, time-varying\ngraph signals are divided into dynamic graph sequences of equal span along the\ntemporal dimension. A spatiotemporal joint representation is then established\nthrough vectorized reorganization, followed by the joint time-vertex Wiener\nfiltering. Furthermore, by rigorously proving the differentiability of the\ntransform orders, both the transform orders and filter coefficients are\nembedded as learnable parameters within a neural network architecture. Through\ngradient backpropagation, their synchronized iterative optimization is\nachieved, constructing a parameters-adaptive learning filtering framework. This\nmethod leverages a model-driven approach to learn the optimal transform order\npair and filter coefficients. Experimental results indicate that the proposed\nframework improves the time-varying graph signals denoising performance, while\nreducing the computational burden of the traditional grid search strategy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8d85\u5fae\u5206\u5f62\u5f0f\u7684JFRFT\u6ee4\u6ce2\u65b9\u6cd5\uff0c\u901a\u8fc7\u68af\u5ea6\u53cd\u5411\u4f20\u64ad\u81ea\u9002\u5e94\u9009\u62e9\u53d8\u6362\u9636\u6570\u548c\u6ee4\u6ce2\u5668\u7cfb\u6570\uff0c\u63d0\u5347\u4e86\u65f6\u53d8\u56fe\u4fe1\u53f7\u53bb\u566a\u6027\u80fd\u5e76\u964d\u4f4e\u4e86\u8ba1\u7b97\u8d1f\u62c5\u3002", "motivation": "\u9488\u5bf9GFRFT Wiener\u6ee4\u6ce2\u548c\u4f20\u7edfJFRFT Wiener\u6ee4\u6ce2\u7684\u5c40\u9650\u6027\uff0c\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684\u6ee4\u6ce2\u65b9\u6cd5\u3002", "method": "\u6784\u5efa\u4e86JFRFT\u7684\u8d85\u5fae\u5206\u5f62\u5f0f\uff0c\u901a\u8fc7\u68af\u5ea6\u53cd\u5411\u4f20\u64ad\u5b9e\u73b0\u53d8\u6362\u9636\u6570\u548c\u6ee4\u6ce2\u5668\u7cfb\u6570\u7684\u81ea\u9002\u5e94\u9009\u62e9\uff0c\u5e76\u5d4c\u5165\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u8fdb\u884c\u4f18\u5316\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u63d0\u5347\u4e86\u65f6\u53d8\u56fe\u4fe1\u53f7\u53bb\u566a\u6027\u80fd\uff0c\u540c\u65f6\u964d\u4f4e\u4e86\u4f20\u7edf\u7f51\u683c\u641c\u7d22\u7b56\u7565\u7684\u8ba1\u7b97\u8d1f\u62c5\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u6a21\u578b\u9a71\u52a8\u5b66\u4e60\u6700\u4f18\u53d8\u6362\u9636\u6570\u548c\u6ee4\u6ce2\u5668\u7cfb\u6570\uff0c\u4e3a\u65f6\u53d8\u56fe\u4fe1\u53f7\u5904\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u6ee4\u6ce2\u6846\u67b6\u3002"}}
{"id": "2507.21570", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.21570", "abs": "https://arxiv.org/abs/2507.21570", "authors": ["Joni Shaska", "Urbashi Mitra"], "title": "Causal Link Discovery with Unequal Edge Error Tolerance", "comment": "14 pages, 6 figures, portions presented at International Symposium on\n  Information Theory (ISIT) 2024 and Asilomar 2024", "summary": "This paper proposes a novel framework for causal discovery with asymmetric\nerror control, called Neyman-Pearson causal discovery. Despite the importance\nof applications where different types of edge errors may have different\nimportance, current state-of-the-art causal discovery algorithms do not\ndifferentiate between the types of edge errors, nor provide any finite-sample\nguarantees on the edge errors. Hence, this framework seeks to minimize one type\nof error while keeping the other below a user-specified tolerance level. Using\ntechniques from information theory, fundamental performance limits are found,\ncharacterized by the R\\'enyi divergence, for Neyman-Pearson causal discovery.\nFurthermore, a causal discovery algorithm is introduced for the case of linear\nadditive Gaussian noise models, called epsilon-CUT, that provides finite-sample\nguarantees on the false positive rate, while staying competitive with\nstate-of-the-art methods.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aNeyman-Pearson\u56e0\u679c\u53d1\u73b0\u7684\u65b0\u6846\u67b6\uff0c\u7528\u4e8e\u975e\u5bf9\u79f0\u9519\u8bef\u63a7\u5236\u7684\u56e0\u679c\u53d1\u73b0\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u53d1\u73b0\u7b97\u6cd5\u672a\u533a\u5206\u4e0d\u540c\u7c7b\u578b\u7684\u8fb9\u9519\u8bef\uff0c\u4e14\u7f3a\u4e4f\u6709\u9650\u6837\u672c\u4fdd\u8bc1\uff0c\u8be5\u6846\u67b6\u65e8\u5728\u89e3\u51b3\u8fd9\u4e00\u95ee\u9898\u3002", "method": "\u5229\u7528\u4fe1\u606f\u8bba\u6280\u672f\uff0c\u57fa\u4e8eR\u00e9nyi\u6563\u5ea6\u786e\u5b9a\u6027\u80fd\u6781\u9650\uff0c\u5e76\u9488\u5bf9\u7ebf\u6027\u52a0\u6027\u9ad8\u65af\u566a\u58f0\u6a21\u578b\u63d0\u51faepsilon-CUT\u7b97\u6cd5\u3002", "result": "epsilon-CUT\u7b97\u6cd5\u5728\u63a7\u5236\u5047\u9633\u6027\u7387\u7684\u540c\u65f6\uff0c\u6027\u80fd\u4e0e\u73b0\u6709\u6700\u4f18\u65b9\u6cd5\u76f8\u5f53\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u56e0\u679c\u53d1\u73b0\u63d0\u4f9b\u4e86\u975e\u5bf9\u79f0\u9519\u8bef\u63a7\u5236\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5c55\u793a\u4e86\u5b9e\u9645\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2507.21593", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.21593", "abs": "https://arxiv.org/abs/2507.21593", "authors": ["Erdeng Zhang", "Shuntian Zheng", "Sheng Wu", "Haoge Jia", "Zhe Ji", "Ailing Xiao"], "title": "Affine Invariant Semi-Blind Receiver: Joint Channel Estimation and High-Order Signal Detection for Multiuser Massive MIMO-OFDM Systems", "comment": null, "summary": "Massive multiple input and multiple output (MIMO) systems with orthogonal\nfrequency division multiplexing (OFDM) are foundational for downlink multi-user\n(MU) communication in future wireless networks, for their ability to enhance\nspectral efficiency and support a large number of users simultaneously.\nHowever, high user density intensifies severe inter-user interference (IUI) and\npilot overhead. Consequently, existing blind and semi-blind channel estimation\n(CE) and signal detection (SD) algorithms suffer performance degradation and\nincreased complexity, especially when further challenged by frequency-selective\nchannels and high-order modulation demands. To this end, this paper proposes a\nnovel semi-blind joint channel estimation and signal detection (JCESD) method.\nSpecifically, the proposed approach employs a hybrid precoding architecture to\nsuppress IUI. Furthermore we formulate JCESD as a non-convex constellation\nfitting optimization exploiting constellation affine invariance. Few pilots are\nused to achieve coarse estimation for initialization and ambiguity resolution.\nFor high-order modulations, a data augmentation mechanism utilizes the symmetry\nof quadrature amplitude modulation (QAM) constellations to increase the\neffective number of samples. To address frequency-selective channels, CE\naccuracy is then enhanced via an iterative refinement strategy that leverages\nimproved SD results. Simulation results demonstrate an average throughput gain\nof 11\\% over widely used pilot-based methods in MU scenarios, highlighting the\nproposed method's potential to improve spectral efficiency.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u534a\u76f2\u8054\u5408\u4fe1\u9053\u4f30\u8ba1\u4e0e\u4fe1\u53f7\u68c0\u6d4b\uff08JCESD\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u89e3\u51b3\u5927\u89c4\u6a21MIMO-OFDM\u7cfb\u7edf\u4e2d\u7684\u7528\u6237\u95f4\u5e72\u6270\u548c\u5bfc\u9891\u5f00\u9500\u95ee\u9898\u3002", "motivation": "\u9ad8\u7528\u6237\u5bc6\u5ea6\u5bfc\u81f4\u4e25\u91cd\u7684\u7528\u6237\u95f4\u5e72\u6270\u548c\u5bfc\u9891\u5f00\u9500\u589e\u52a0\uff0c\u73b0\u6709\u76f2\u548c\u534a\u76f2\u4fe1\u9053\u4f30\u8ba1\u4e0e\u4fe1\u53f7\u68c0\u6d4b\u7b97\u6cd5\u6027\u80fd\u4e0b\u964d\u4e14\u590d\u6742\u5ea6\u9ad8\u3002", "method": "\u91c7\u7528\u6df7\u5408\u9884\u7f16\u7801\u67b6\u6784\u6291\u5236\u5e72\u6270\uff0c\u5c06JCESD\u5efa\u6a21\u4e3a\u975e\u51f8\u661f\u5ea7\u62df\u5408\u4f18\u5316\u95ee\u9898\uff0c\u5229\u7528\u5c11\u91cf\u5bfc\u9891\u8fdb\u884c\u521d\u59cb\u5316\u548c\u6a21\u7cca\u6d88\u9664\uff0c\u5e76\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u8fed\u4ee3\u7ec6\u5316\u7b56\u7565\u63d0\u5347\u6027\u80fd\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u5728\u591a\u7528\u6237\u573a\u666f\u4e0b\uff0c\u8be5\u65b9\u6cd5\u6bd4\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u4e8e\u5bfc\u9891\u7684\u65b9\u6cd5\u5e73\u5747\u541e\u5410\u91cf\u63d0\u534711%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u9891\u8c31\u6548\u7387\uff0c\u9002\u7528\u4e8e\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u7684\u9ad8\u5bc6\u5ea6\u7528\u6237\u573a\u666f\u3002"}}
{"id": "2507.21626", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.21626", "abs": "https://arxiv.org/abs/2507.21626", "authors": ["\u00d6zlem Tu\u011ffe Demir", "Muhammed Selman Somuncu", "Ahmet M. Elbir", "Emil Bj\u00f6rnson"], "title": "Comprehensive Analysis of Behavioral Hardware Impairments in Cell-Free Massive MIMO-OFDM Uplink: Centralized Operation", "comment": "4 pages, 2 figures, presented at IEEE Signal Processing and\n  Communications Applications Conference (SIU), 2025", "summary": "Cell-free massive MIMO is a key 6G technology, offering superior spectral and\nenergy efficiency. However, its dense deployment of low-cost access points\n(APs) makes hardware impairments unavoidable. While narrowband impairments are\nwell-studied, their impact in wideband systems remains unexplored. This paper\nprovides the first comprehensive analysis of hardware impairments, such as\nnonlinear distortion in low-noise amplifiers, phase noise, in-phase-quadrature\nimbalance, and low-resolution analog-to-digital converters, on uplink spectral\nefficiency in cell-free massive MIMO. Using an OFDM waveform and centralized\nprocessing, APs share channel state information for joint uplink combining.\nLeveraging Bussgang decomposition, we derive a distortion-aware combining\nvector that optimizes spectral efficiency by modeling distortion as independent\ncolored noise.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u5168\u9762\u5206\u6790\u4e86\u786c\u4ef6\u635f\u4f24\uff08\u5982\u975e\u7ebf\u6027\u5931\u771f\u3001\u76f8\u4f4d\u566a\u58f0\u7b49\uff09\u5bf9\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u4e0a\u884c\u94fe\u8def\u9891\u8c31\u6548\u7387\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u4e8eBussgang\u5206\u89e3\u7684\u4f18\u5316\u65b9\u6cd5\u3002", "motivation": "\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u662f6G\u5173\u952e\u6280\u672f\uff0c\u4f46\u5176\u4f4e\u6210\u672cAP\u5bc6\u96c6\u90e8\u7f72\u5bfc\u81f4\u786c\u4ef6\u635f\u4f24\u4e0d\u53ef\u907f\u514d\uff0c\u800c\u5bbd\u5e26\u7cfb\u7edf\u4e2d\u7684\u5f71\u54cd\u5c1a\u672a\u7814\u7a76\u3002", "method": "\u91c7\u7528OFDM\u6ce2\u5f62\u548c\u96c6\u4e2d\u5f0f\u5904\u7406\uff0cAP\u5171\u4eab\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u8fdb\u884c\u8054\u5408\u4e0a\u884c\u94fe\u8def\u5408\u5e76\uff0c\u5229\u7528Bussgang\u5206\u89e3\u5efa\u6a21\u5931\u771f\u4e3a\u72ec\u7acb\u6709\u8272\u566a\u58f0\uff0c\u4f18\u5316\u9891\u8c31\u6548\u7387\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5931\u771f\u611f\u77e5\u5408\u5e76\u5411\u91cf\uff0c\u901a\u8fc7\u5efa\u6a21\u5931\u771f\u4e3a\u72ec\u7acb\u6709\u8272\u566a\u58f0\uff0c\u4f18\u5316\u4e86\u9891\u8c31\u6548\u7387\u3002", "conclusion": "\u7814\u7a76\u586b\u8865\u4e86\u5bbd\u5e26\u7cfb\u7edf\u4e2d\u786c\u4ef6\u635f\u4f24\u5f71\u54cd\u7684\u7a7a\u767d\uff0c\u4e3a\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u652f\u6301\u3002"}}
{"id": "2507.21635", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.21635", "abs": "https://arxiv.org/abs/2507.21635", "authors": ["\u00d6zlem Tu\u011ffe Demir", "Emil Bj\u00f6rnson"], "title": "Impact of Phase Noise and Power Amplifier Non-Linearities on Downlink Cell-Free Massive MIMO-OFDM Systems", "comment": "6 pages, 3 figures, presented at IEEE SmartNets 2025", "summary": "Cell-free massive MIMO (multiple-input multiple-output) is a key enabler for\nthe sixth generation (6G) of mobile networks, offering significant spectral and\nenergy efficiency gains through user-centric operation of distributed access\npoints (APs). However, its reliance on low-cost APs introduces inevitable\nhardware impairments, whose combined impact on wideband downlink systems\nremains unexplored when analyzed using behavioral models. This paper presents a\ncomprehensive analysis of the downlink spectral efficiency (SE) in cell-free\nmassive MIMO-OFDM systems under practical hardware impairments, including phase\nnoise and third-order power amplifier nonlinearities. Both centralized and\ndistributed precoding strategies are examined. By leveraging the Bussgang\ndecomposition, we derive an SE expression and quantify the relative impact of\nimpairments through simulations. Our results reveal that phase noise causes\nmore severe degradation than power amplifier distortions, especially in\ndistributed operation, highlighting the need for future distortion-aware\nprecoding designs.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5728\u786c\u4ef6\u635f\u4f24\uff08\u5982\u76f8\u4f4d\u566a\u58f0\u548c\u529f\u7387\u653e\u5927\u5668\u975e\u7ebf\u6027\uff09\u4e0b\uff0c\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO-OFDM\u7cfb\u7edf\u7684\u4e0b\u884c\u94fe\u8def\u9891\u8c31\u6548\u7387\uff0c\u53d1\u73b0\u76f8\u4f4d\u566a\u58f0\u5bf9\u5206\u5e03\u5f0f\u64cd\u4f5c\u7684\u6027\u80fd\u5f71\u54cd\u66f4\u5927\u3002", "motivation": "\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u662f6G\u7f51\u7edc\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u5176\u4f9d\u8d56\u4f4e\u6210\u672c\u63a5\u5165\u70b9\uff08AP\uff09\u4f1a\u5f15\u5165\u786c\u4ef6\u635f\u4f24\uff0c\u73b0\u6709\u7814\u7a76\u672a\u5145\u5206\u63a2\u8ba8\u8fd9\u4e9b\u635f\u4f24\u5bf9\u5bbd\u5e26\u4e0b\u884c\u94fe\u8def\u7cfb\u7edf\u7684\u7efc\u5408\u5f71\u54cd\u3002", "method": "\u901a\u8fc7Bussgang\u5206\u89e3\u63a8\u5bfc\u9891\u8c31\u6548\u7387\u8868\u8fbe\u5f0f\uff0c\u5e76\u6a21\u62df\u5206\u6790\u96c6\u4e2d\u5f0f\u548c\u5206\u5e03\u5f0f\u9884\u7f16\u7801\u7b56\u7565\u4e0b\u76f8\u4f4d\u566a\u58f0\u548c\u529f\u7387\u653e\u5927\u5668\u975e\u7ebf\u6027\u7684\u5f71\u54cd\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u76f8\u4f4d\u566a\u58f0\u5bf9\u6027\u80fd\u7684\u635f\u5bb3\u6bd4\u529f\u7387\u653e\u5927\u5668\u975e\u7ebf\u6027\u66f4\u4e25\u91cd\uff0c\u5c24\u5176\u662f\u5728\u5206\u5e03\u5f0f\u64cd\u4f5c\u4e2d\u3002", "conclusion": "\u672a\u6765\u9700\u8981\u8bbe\u8ba1\u9488\u5bf9\u786c\u4ef6\u635f\u4f24\u7684\u9884\u7f16\u7801\u65b9\u6848\uff0c\u4ee5\u4f18\u5316\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u6027\u80fd\u3002"}}
{"id": "2507.21644", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.21644", "abs": "https://arxiv.org/abs/2507.21644", "authors": ["Derya Nurcan-Atceken", "\u00d6zlem Tu\u011ffe Demir", "Aysegul Altin-Kayhan", "Emil Bj\u00f6rnson", "Cicek Cavdar", "Bulent Tavli"], "title": "Energy-Aware Resource Allocation for Multi-Operator Cell-Free Massive MIMO in V-CRAN Architectures", "comment": "6 pages, 2 figures, to be presented at 2025 International Conference\n  on Future Communications and Networks (FCN)", "summary": "Cell-free massive multiple-input multiple-output (MIMO) implemented in\nvirtualized cloud radio access networks (V-CRAN) has emerged as a promising\narchitecture to enhance spectral efficiency (SE), network flexibility, and\nenergy efficiency (EE) in next-generation wireless systems. In this work, we\ndevelop a holistic optimization framework for the efficient deployment of\ncell-free massive MIMO in V-CRAN with multiple mobile network operators (MNOs).\nSpecifically, we formulate a set of mixed-integer programming (MIP) models to\njointly optimize access point (AP) selection, user equipment (UE) association,\ncloud resource allocation, and MNO assignment while minimizing the maximum\ntotal power consumption (TPC) across MNOs. We consider two different scenarios\nbased on whether UEs can be assigned to arbitrary MNOs or not. The numerical\nresults demonstrate the impact of different deployment assumptions on power\nconsumption, highlighting that flexible UE-MNO assignment significantly reduces\nTPC. The findings provide key insights into optimizing resource management in\ncell-free massive MIMO V-CRAN, paving the way for energy-efficient wireless\nnetwork implementations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u865a\u62df\u5316\u4e91\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\u4e2d\u90e8\u7f72\u65e0\u5c0f\u533a\u5927\u89c4\u6a21MIMO\u7684\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316AP\u9009\u62e9\u3001UE\u5173\u8054\u3001\u4e91\u8d44\u6e90\u5206\u914d\u548cMNO\u5206\u914d\uff0c\u6700\u5c0f\u5316\u603b\u529f\u8017\u3002", "motivation": "\u63d0\u5347\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u7684\u9891\u8c31\u6548\u7387\u3001\u7f51\u7edc\u7075\u6d3b\u6027\u548c\u80fd\u6e90\u6548\u7387\u3002", "method": "\u5f00\u53d1\u4e86\u6df7\u5408\u6574\u6570\u89c4\u5212\u6a21\u578b\uff0c\u4f18\u5316AP\u9009\u62e9\u3001UE\u5173\u8054\u3001\u4e91\u8d44\u6e90\u5206\u914d\u548cMNO\u5206\u914d\uff0c\u8003\u8651\u4e24\u79cdUE-MNO\u5206\u914d\u573a\u666f\u3002", "result": "\u7075\u6d3b\u7684UE-MNO\u5206\u914d\u663e\u8457\u964d\u4f4e\u603b\u529f\u8017\uff0c\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u4e0d\u540c\u90e8\u7f72\u5047\u8bbe\u5bf9\u529f\u8017\u7684\u5f71\u54cd\u3002", "conclusion": "\u4e3a\u65e0\u5c0f\u533a\u5927\u89c4\u6a21MIMO V-CRAN\u7684\u8d44\u6e90\u7ba1\u7406\u4f18\u5316\u63d0\u4f9b\u4e86\u5173\u952e\u89c1\u89e3\uff0c\u63a8\u52a8\u80fd\u6e90\u9ad8\u6548\u65e0\u7ebf\u7f51\u7edc\u7684\u5b9e\u73b0\u3002"}}
{"id": "2507.21696", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.21696", "abs": "https://arxiv.org/abs/2507.21696", "authors": ["Abdelaziz Salama", "Zeinab Nezami", "Mohammed M. H. Qazzaz", "Maryam Hafeez", "Syed Ali Raza Zaidi"], "title": "Edge Agentic AI Framework for Autonomous Network Optimisation in O-RAN", "comment": null, "summary": "The deployment of AI agents within legacy Radio Access Network (RAN)\ninfrastructure poses significant safety and reliability challenges for future\n6G networks. This paper presents a novel Edge AI framework for autonomous\nnetwork optimisation in Open RAN environments, addressing these challenges\nthrough three core innovations: (1) a persona-based multi-tools architecture\nenabling distributed, context-aware decision-making; (2) proactive anomaly\ndetection agent powered by traffic predictive tool; and (3) a safety, aligned\nreward mechanism that balances performance with operational stability.\nIntegrated into the RAN Intelligent Controller (RIC), our framework leverages\nmultimodal data fusion, including network KPIs, a traffic prediction model, and\nexternal information sources, to anticipate and respond to dynamic network\nconditions. Extensive evaluation using realistic 5G scenarios demonstrates that\nthe edge framework achieves zero network outages under high-stress conditions,\ncompared to 8.4% for traditional fixed-power networks and 3.3% for large\nlanguage model (LLM) agent-based approaches, while maintaining near real-time\nresponsiveness and consistent QoS. These results establish that, when equipped\nwith the right tools and contextual awareness, AI agents can be safely and\neffectively deployed in critical network infrastructure, laying the framework\nfor intelligent and autonomous 5G and beyond network operations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578bEdge AI\u6846\u67b6\uff0c\u7528\u4e8eOpen RAN\u73af\u5883\u4e2d\u7684\u81ea\u4e3b\u7f51\u7edc\u4f18\u5316\uff0c\u901a\u8fc7\u4e09\u9879\u6838\u5fc3\u521b\u65b0\u89e3\u51b3\u4e866G\u7f51\u7edc\u4e2dAI\u4ee3\u7406\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u6311\u6218\u3002", "motivation": "\u5728\u4f20\u7edfRAN\u57fa\u7840\u8bbe\u65bd\u4e2d\u90e8\u7f72AI\u4ee3\u7406\u5bf96G\u7f51\u7edc\u7684\u5b89\u5168\u6027\u548c\u53ef\u9760\u6027\u63d0\u51fa\u4e86\u91cd\u5927\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6846\u67b6\u5305\u62ec\u57fa\u4e8e\u89d2\u8272\u7684\u591a\u5de5\u5177\u67b6\u6784\u3001\u4e3b\u52a8\u5f02\u5e38\u68c0\u6d4b\u4ee3\u7406\u548c\u5b89\u5168\u5bf9\u9f50\u7684\u5956\u52b1\u673a\u5236\uff0c\u5e76\u5229\u7528\u591a\u6a21\u6001\u6570\u636e\u878d\u5408\u8fdb\u884c\u52a8\u6001\u7f51\u7edc\u54cd\u5e94\u3002", "result": "\u5728\u771f\u5b9e5G\u573a\u666f\u4e2d\uff0c\u8be5\u6846\u67b6\u5b9e\u73b0\u4e86\u96f6\u7f51\u7edc\u4e2d\u65ad\uff0c\u4f18\u4e8e\u4f20\u7edf\u56fa\u5b9a\u529f\u7387\u7f51\u7edc\uff088.4%\uff09\u548c\u57fa\u4e8eLLM\u4ee3\u7406\u7684\u65b9\u6cd5\uff083.3%\uff09\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u914d\u5907\u9002\u5f53\u5de5\u5177\u548c\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u7684AI\u4ee3\u7406\u53ef\u4ee5\u5b89\u5168\u6709\u6548\u5730\u90e8\u7f72\u5728\u5173\u952e\u7f51\u7edc\u57fa\u7840\u8bbe\u65bd\u4e2d\uff0c\u4e3a\u667a\u80fd\u81ea\u4e3b5G\u53ca\u672a\u6765\u7f51\u7edc\u5960\u5b9a\u57fa\u7840\u3002"}}
{"id": "2507.21698", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.21698", "abs": "https://arxiv.org/abs/2507.21698", "authors": ["Abdelaziz Salama", "Mohammed M. H. Qazzaz", "Syed Danial Ali Shah", "Maryam Hafeez", "Syed Ali Zaidi", "Hamed Ahmadi"], "title": "EcoFL: Resource Allocation for Energy-Efficient Federated Learning in Multi-RAT ORAN Networks", "comment": null, "summary": "Federated Learning (FL) enables distributed model training on edge devices\nwhile preserving data privacy. However, FL deployments in wireless networks\nface significant challenges, including communication overhead, unreliable\nconnectivity, and high energy consumption, particularly in dynamic\nenvironments. This paper proposes EcoFL, an integrated FL framework that\nleverages the Open Radio Access Network (ORAN) architecture with multiple Radio\nAccess Technologies (RATs) to enhance communication efficiency and ensure\nrobust FL operations. EcoFL implements a two-stage optimisation approach: an\nRL-based rApp for dynamic RAT selection that balances energy efficiency with\nnetwork performance, and a CNN-based xApp for near real-time resource\nallocation with adaptive policies. This coordinated approach significantly\nenhances communication resilience under fluctuating network conditions.\nExperimental results demonstrate competitive FL model performance with 19\\%\nlower power consumption compared to baseline approaches, highlighting\nsubstantial potential for scalable, energy-efficient collaborative learning\napplications.", "AI": {"tldr": "EcoFL\u662f\u4e00\u4e2a\u96c6\u6210\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528ORAN\u67b6\u6784\u548c\u591aRAT\u6280\u672f\u4f18\u5316\u901a\u4fe1\u6548\u7387\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u80fd\u8017\u5e76\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u65e0\u7ebf\u7f51\u7edc\u4e2d\u8054\u90a6\u5b66\u4e60\u7684\u901a\u4fe1\u5f00\u9500\u3001\u4e0d\u53ef\u9760\u8fde\u63a5\u548c\u9ad8\u80fd\u8017\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u4f18\u5316\uff1a\u57fa\u4e8eRL\u7684rApp\u52a8\u6001\u9009\u62e9RAT\uff0c\u57fa\u4e8eCNN\u7684xApp\u5b9e\u65f6\u5206\u914d\u8d44\u6e90\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u80fd\u8017\u964d\u4f4e19%\uff0c\u6a21\u578b\u6027\u80fd\u4fdd\u6301\u7ade\u4e89\u529b\u3002", "conclusion": "EcoFL\u5728\u52a8\u6001\u7f51\u7edc\u4e2d\u5177\u6709\u9ad8\u6548\u3001\u53ef\u6269\u5c55\u7684\u6f5c\u529b\u3002"}}
{"id": "2507.21704", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.21704", "abs": "https://arxiv.org/abs/2507.21704", "authors": ["Hyeon Seok Rou", "Kuranage Roche Rayan Ranasinghe", "Vincent Savaux", "Giuseppe Thadeu Freitas de Abreu", "David Gonz\u00e1lez G.", "Christos Masouros"], "title": "Affine Frequency Division Multiplexing (AFDM) for 6G: Properties, Features, and Challenges", "comment": null, "summary": "Affine frequency division multiplexing (AFDM) is an emerging waveform\ncandidate for future sixth generation (6G) systems offering a range of\npromising features, such as enhanced robustness in heterogeneous and\nhigh-mobility environments, as well as inherent suitability for integrated\nsensing and communications (ISAC) applications. In addition, unlike other\ncandidates such as orthogonal time-frequency space (OTFS) modulation, AFDM\nprovides several unique advantages that strengthen its relevance to practical\ndeployment and standardization in 6G. Notably, as a natural generalization of\northogonal frequency division multiplexing (OFDM), strong backward\ncompatibility with existing conventional systems is guaranteed, while also\noffering novel possibilities in waveform design, for example to enable\nphysical-layer security through its inherent chirp parametrization. In all,\nthis article provides an overview of AFDM, emphasizing its suitability as a\ncandidate waveform for 6G standardization. First, we provide a concise\nintroduction to the fundamental properties and unique characteristics of AFDM,\nfollowed by highlights of its advantageous features, and finally a discussion\nof its potential and challenges in 6G standardization efforts and\nrepresentative requirements.", "AI": {"tldr": "AFDM\u662f\u4e00\u79cd\u65b0\u5174\u76846G\u6ce2\u5f62\u5019\u9009\u6280\u672f\uff0c\u5177\u6709\u5728\u9ad8\u79fb\u52a8\u6027\u548c\u5f02\u6784\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u4ee5\u53ca\u4e0e\u73b0\u6709\u7cfb\u7edf\u7684\u5411\u540e\u517c\u5bb9\u6027\u3002", "motivation": "\u4e3a6G\u7cfb\u7edf\u5bfb\u627e\u4e00\u79cd\u9002\u5408\u7684\u6ce2\u5f62\u6280\u672f\uff0cAFDM\u56e0\u5176\u72ec\u7279\u4f18\u52bf\u6210\u4e3a\u5019\u9009\u3002", "method": "\u6982\u8ff0AFDM\u7684\u57fa\u672c\u7279\u6027\u3001\u72ec\u7279\u4f18\u52bf\u53ca\u5176\u57286G\u6807\u51c6\u5316\u4e2d\u7684\u6f5c\u529b\u3002", "result": "AFDM\u57286G\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u9002\u5408\u6807\u51c6\u5316\uff0c\u4f46\u4e5f\u9762\u4e34\u6311\u6218\u3002", "conclusion": "AFDM\u662f6G\u6807\u51c6\u5316\u7684\u6709\u529b\u5019\u9009\uff0c\u9700\u8fdb\u4e00\u6b65\u7814\u7a76\u5176\u5b9e\u9645\u5e94\u7528\u548c\u6311\u6218\u3002"}}
{"id": "2507.21879", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.21879", "abs": "https://arxiv.org/abs/2507.21879", "authors": ["Xianxin Song", "Xianghao Yu", "Jie Xu", "Derrick Wing Kwan Ng"], "title": "CRB-Rate Tradeoff for Bistatic ISAC with Gaussian Information and Deterministic Sensing Signals", "comment": "13 pages,6 figures", "summary": "In this paper, we investigate a bistatic integrated sensing and\ncommunications (ISAC) system, consisting of a multi-antenna base station (BS),\na multi-antenna sensing receiver, a single-antenna communication user (CU), and\na point target to be sensed. Specifically, the BS transmits a superposition of\nGaussian information and deterministic sensing signals. The BS aims to deliver\ninformation symbols to the CU, while the sensing receiver aims to estimate the\ntarget's direction-of-arrival (DoA) with respect to the sensing receiver by\nprocessing the echo signals. For the sensing receiver, we assume that only the\nsequences of the deterministic sensing signals and the covariance matrix of the\ninformation signals are perfectly known, whereas the specific realizations of\nthe information signals remain unavailable. Under this setup, we first derive\nthe corresponding Cram\\'er-Rao bounds (CRBs) for DoA estimation and propose\npractical estimators to accurately estimate the target's DoA. Subsequently, we\nformulate the transmit beamforming design as an optimization problem aiming to\nminimize the CRB, subject to a minimum signal-to-interference-plus-noise ratio\n(SINR) requirement at the CU and a maximum transmit power constraint at the BS.\nWhen the BS employs only Gaussian information signals, the resulting\nbeamforming optimization problem is convex, enabling the derivation of an\noptimal solution. In contrast, when both Gaussian information and deterministic\nsensing signals are transmitted, the resulting problem is non-convex and a\nlocally optimal solution is acquired by exploiting successive convex\napproximation (SCA). Finally, numerical results demonstrate that employing\nGaussian information signals leads to a notable performance degradation for\ntarget sensing and the proposed transmit beamforming design achieves a superior\nISAC performance boundary compared with various benchmark schemes.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u4e00\u79cd\u53cc\u57fa\u5730\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\uff0c\u5b9e\u73b0\u901a\u4fe1\u4e0e\u611f\u77e5\u7684\u5e73\u8861\u3002", "motivation": "\u63a2\u7d22\u5728\u53cc\u57fa\u5730ISAC\u7cfb\u7edf\u4e2d\uff0c\u5982\u4f55\u901a\u8fc7\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\uff0c\u540c\u65f6\u6ee1\u8db3\u901a\u4fe1\u7528\u6237\u7684\u4fe1\u606f\u4f20\u8f93\u9700\u6c42\u548c\u611f\u77e5\u63a5\u6536\u5668\u7684\u76ee\u6807\u65b9\u5411\u4f30\u8ba1\u9700\u6c42\u3002", "method": "\u63a8\u5bfc\u4e86\u65b9\u5411\u4f30\u8ba1\u7684Cram\u00e9r-Rao\u754c\uff08CRB\uff09\uff0c\u5e76\u63d0\u51fa\u5b9e\u9645\u4f30\u8ba1\u5668\uff1b\u901a\u8fc7\u51f8\u4f18\u5316\u6216SCA\u65b9\u6cd5\u8bbe\u8ba1\u6ce2\u675f\u6210\u5f62\u3002", "result": "\u4ec5\u4f7f\u7528\u9ad8\u65af\u4fe1\u606f\u4fe1\u53f7\u4f1a\u5bfc\u81f4\u611f\u77e5\u6027\u80fd\u4e0b\u964d\uff1b\u8054\u5408\u8bbe\u8ba1\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u5728ISAC\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u4e86\u901a\u4fe1\u4e0e\u611f\u77e5\u7684\u4f18\u5f02\u6027\u80fd\u8fb9\u754c\u3002"}}
{"id": "2507.21956", "categories": ["eess.SP", "cs.ET"], "pdf": "https://arxiv.org/pdf/2507.21956", "abs": "https://arxiv.org/abs/2507.21956", "authors": ["Atiquzzaman Mondal", "Amira Bendaimi", "Huseyin Arslan"], "title": "A Novel Framework for Near-Field Covert Communications with RIS and RSMA", "comment": "12 pages, 7 figures, IEEE Transactions on Communications", "summary": "This paper explores the near field (NF) covert communication with the aid of\nrate-splitting multiple access (RSMA) and reconfigurable intelligent surfaces\n(RIS). In particular, the RIS operates in the NF of both the legitimate user\nand the passive adversary, enhancing the legitimate users received signal while\nsuppressing the adversarys detection capability. Whereas, the base station (BS)\napplies RSMA to increase the covert communication rate composed of a private\nand a shared rate component. To characterize system covertness, we derive\nclosed form expressions for the detection error probability (DEP), outage\nprobability (OP), and optimal detection threshold for the adversary. We\nformulate a non-convex joint beamforming optimization problem at the BS and RIS\nunder unit-modulus constraints to maximize the covert rate. To tackle this, we\npropose an alternating optimization (AO) algorithm, where the BS beamformer is\ndesigned using a two-stage iterative method based on successive convex\napproximation (SCA). Additionally, two low-complexity techniques are introduced\nto further reduce the adversarys received power. Simulation results demonstrate\nthat the proposed algorithm effectively improves the covert communication rate,\nhighlighting the potential of near field RSMA-RIS integration in covert\ncommunication.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u8fd1\u573a\uff08NF\uff09\u9690\u853d\u901a\u4fe1\uff0c\u7ed3\u5408\u901f\u7387\u5206\u5272\u591a\u5740\uff08RSMA\uff09\u548c\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\uff0c\u901a\u8fc7\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u548c\u7b97\u6cd5\u63d0\u5347\u9690\u853d\u901a\u4fe1\u901f\u7387\u3002", "motivation": "\u63a2\u7d22\u8fd1\u573a\u73af\u5883\u4e0b\u9690\u853d\u901a\u4fe1\u7684\u6f5c\u529b\uff0c\u7ed3\u5408RSMA\u548cRIS\u6280\u672f\uff0c\u4ee5\u589e\u5f3a\u5408\u6cd5\u7528\u6237\u7684\u4fe1\u53f7\u5e76\u6291\u5236\u88ab\u52a8\u5bf9\u624b\u7684\u68c0\u6d4b\u80fd\u529b\u3002", "method": "\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\uff08AO\uff09\u7b97\u6cd5\uff0c\u7ed3\u5408\u4e24\u9636\u6bb5\u8fed\u4ee3\u65b9\u6cd5\u548c\u4f4e\u590d\u6742\u5ea6\u6280\u672f\uff0c\u4f18\u5316BS\u548cRIS\u7684\u6ce2\u675f\u6210\u5f62\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u9690\u853d\u901a\u4fe1\u901f\u7387\uff0c\u9a8c\u8bc1\u4e86\u8fd1\u573aRSMA-RIS\u96c6\u6210\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8fd1\u573aRSMA-RIS\u96c6\u6210\u5728\u9690\u853d\u901a\u4fe1\u4e2d\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u63d0\u4f9b\u4e86\u65b9\u5411\u3002"}}
{"id": "2507.22013", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.22013", "abs": "https://arxiv.org/abs/2507.22013", "authors": ["Alessandro Mirri", "Venkatesh Khammammetti", "Beyza Dabak", "Enrico Paolini", "Krishna Narayanan", "Robert Calderbank"], "title": "Zak-OTFS Based Coded Random Access for Uplink mMTC", "comment": null, "summary": "This paper proposes a grant-free coded random access (CRA) scheme for uplink\nmassive machine-type communications (mMTC), based on Zak-orthogonal time\nfrequency space (Zak-OTFS) modulation in the delay-Doppler domain. The scheme\nis tailored for doubly selective wireless channels, where conventional\northogonal frequency-division multiplexing (OFDM)-based CRA suffers from\nunreliable inter-slot channel prediction due to time-frequency variability. By\nexploiting the predictable nature of Zak-OTFS, the proposed approach enables\naccurate channel estimation across slots, facilitating reliable successive\ninterference cancellation across user packet replicas. A fair comparison with\nan OFDM-based CRA baseline shows that the proposed scheme achieves\nsignificantly lower packet loss rates under high mobility and user density.\nExtensive simulations over the standardized Veh-A channel confirm the\nrobustness and scalability of Zak-OTFS-based CRA, supporting its applicability\nto future mMTC deployments.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eZak-OTFS\u8c03\u5ea6\u7684\u514d\u6388\u6743\u7f16\u7801\u968f\u673a\u63a5\u5165\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u4e0a\u884c\u5927\u89c4\u6a21\u673a\u5668\u7c7b\u901a\u4fe1\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfOFDM\u65b9\u6848\u5728\u9ad8\u79fb\u52a8\u6027\u548c\u7528\u6237\u5bc6\u5ea6\u4e0b\u7684\u4fe1\u9053\u9884\u6d4b\u4e0d\u53ef\u9760\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfOFDM\u65b9\u6848\u5728\u53cc\u9009\u62e9\u6027\u65e0\u7ebf\u4fe1\u9053\u4e2d\u56e0\u65f6\u9891\u53d8\u5316\u5bfc\u81f4\u4fe1\u9053\u9884\u6d4b\u4e0d\u53ef\u9760\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u7a33\u5065\u7684\u65b9\u6848\u3002", "method": "\u5229\u7528Zak-OTFS\u8c03\u5ea6\u7684\u53ef\u9884\u6d4b\u6027\uff0c\u5b9e\u73b0\u8de8\u65f6\u9699\u7684\u51c6\u786e\u4fe1\u9053\u4f30\u8ba1\uff0c\u652f\u6301\u7528\u6237\u6570\u636e\u5305\u590d\u672c\u7684\u53ef\u9760\u5e72\u6270\u6d88\u9664\u3002", "result": "\u4e0eOFDM\u65b9\u6848\u76f8\u6bd4\uff0c\u8be5\u65b9\u6848\u5728\u9ad8\u79fb\u52a8\u6027\u548c\u7528\u6237\u5bc6\u5ea6\u4e0b\u663e\u8457\u964d\u4f4e\u4e86\u6570\u636e\u5305\u4e22\u5931\u7387\u3002", "conclusion": "Zak-OTFS\u65b9\u6848\u5728\u6807\u51c6\u5316Veh-A\u4fe1\u9053\u4e2d\u8868\u73b0\u51fa\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u9002\u7528\u4e8e\u672a\u6765mMTC\u90e8\u7f72\u3002"}}
{"id": "2507.22027", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.22027", "abs": "https://arxiv.org/abs/2507.22027", "authors": ["Mingjun Ying", "Dipankar Shakya", "Peijie Ma", "Guanyue Qian", "Theodore S. Rappaport"], "title": "Site-Specific Location Calibration and Validation of Ray-Tracing Simulator NYURay at Upper Mid-Band Frequencies", "comment": "16 pages, 7 figures", "summary": "Ray-tracing (RT) simulators are essential for wireless digital twins,\nenabling accurate site-specific radio channel prediction for next-generation\nwireless systems. Yet, RT simulation accuracy is often limited by insufficient\nmeasurement data and a lack of systematic validation. This paper presents\nsite-specific location calibration and validation of NYURay, NYU's in-house ray\ntracer, at upper mid-band frequencies (6.75 GHz and 16.95 GHz). We propose a\nlocation calibration algorithm that corrects GPS-induced position errors by\noptimizing transmitter-receiver (TX-RX) locations to align simulated and\nmeasured power delay profiles, improving TX-RX location accuracy by 42.3% for\nline-of-sight (LOS) and 13.5% for non-line-of-sight (NLOS) scenarios.\nValidation across 18 TX-RX locations shows excellent RT accuracy in path loss\nprediction, with path loss exponent (PLE) deviations under 0.14. While RT\nunderestimates delay spread and angular spreads, their cumulative distributions\nremain statistically similar. The validated NYURay advances RT validation and\nprovides reliable channel statistics for 6G deployment.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4d\u7f6e\u6821\u51c6\u7b97\u6cd5\uff0c\u7528\u4e8e\u63d0\u9ad8NYURay\u5c04\u7ebf\u8ffd\u8e2a\u6a21\u62df\u5668\u7684\u51c6\u786e\u6027\uff0c\u901a\u8fc7\u4f18\u5316\u53d1\u5c04-\u63a5\u6536\u4f4d\u7f6e\u4ee5\u51cf\u5c11GPS\u8bef\u5dee\uff0c\u663e\u8457\u63d0\u5347\u4e86LOS\u548cNLOS\u573a\u666f\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u3002\u9a8c\u8bc1\u7ed3\u679c\u663e\u793a\uff0cNYURay\u5728\u8def\u5f84\u635f\u8017\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u5c04\u7ebf\u8ffd\u8e2a\u6a21\u62df\u5668\u7684\u51c6\u786e\u6027\u53d7\u9650\u4e8e\u6d4b\u91cf\u6570\u636e\u4e0d\u8db3\u548c\u7f3a\u4e4f\u7cfb\u7edf\u9a8c\u8bc1\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u65b9\u6cd5\u6765\u6821\u51c6\u548c\u9a8c\u8bc1\u6a21\u62df\u5668\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u4f4d\u7f6e\u6821\u51c6\u7b97\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u53d1\u5c04-\u63a5\u6536\u4f4d\u7f6e\u4ee5\u5bf9\u9f50\u6a21\u62df\u548c\u6d4b\u91cf\u7684\u529f\u7387\u5ef6\u8fdf\u5206\u5e03\uff0c\u4ece\u800c\u51cf\u5c11GPS\u8bef\u5dee\u3002", "result": "\u6821\u51c6\u540e\uff0cLOS\u548cNLOS\u573a\u666f\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u5206\u522b\u63d0\u9ad8\u4e8642.3%\u548c13.5%\u3002\u8def\u5f84\u635f\u8017\u9884\u6d4b\u7684\u504f\u5dee\u5c0f\u4e8e0.14\uff0c\u4f46\u5ef6\u8fdf\u548c\u89d2\u5ea6\u6269\u5c55\u7684\u9884\u6d4b\u7565\u6709\u4f4e\u4f30\u3002", "conclusion": "\u9a8c\u8bc1\u540e\u7684NYURay\u4e3a6G\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u65e0\u7ebf\u4fe1\u9053\u7edf\u8ba1\uff0c\u5e76\u63a8\u52a8\u4e86\u5c04\u7ebf\u8ffd\u8e2a\u9a8c\u8bc1\u7684\u8fdb\u5c55\u3002"}}

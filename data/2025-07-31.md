<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 10]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SD](#cs.SD) [Total: 4]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Efficient handover based on Near-field and Far-field RIS for seamless connectivity](https://arxiv.org/abs/2507.22141)
*Atiquzzaman Mondal,Waheeb Tashan,Ayat Al-Olaimat,Hüseyin Arslan*

Main category: eess.SP

TL;DR: 本文提出了一种基于RIS的高效切换管理方案，通过分析信号强度变化和距离概率密度函数，优化了6G网络中的移动性管理，减少了不必要的切换和信令开销。


<details>
  <summary>Details</summary>
Motivation: RIS技术为6G网络提供了智能操控电磁波的能力，但现有切换管理方案在信令开销和移动性优化方面存在不足，需要改进。

Method: 分析了RIS辅助网络中信号强度的变化，推导了近场区域距离的概率密度函数，并提出了一种结合多种切换类别的算法，以BER为关键参数优化切换。

Result: 数值结果表明，该方法显著降低了切换率和信令负载，提升了频谱效率和能量效率，确保了无缝连接和服务质量。

Conclusion: 提出的RIS辅助切换管理方案有效优化了6G网络的移动性管理，减少了不必要的切换，提升了整体性能。

Abstract: Reconfigurable Intelligent Surfaces (RIS) is becoming a transformative
technology for the upcoming 6G communication networks, providing a way for
smartly maneuvering the electromagnetic waves to enhance coverage and
connectivity. This paper presents an efficient handover (HO) management scheme
leveraging RIS in the Fresnel region i.e., in both the near-field (NF) and
far-field (FF) regions to reduce signaling overhead and optimize mobility
management. For this, we analyzed the signal strength variations in the
considered RIS-aided networks, considering the radiative NF and FF regions, and
derive the probability density function (PDF) of the RIS-UE distance in the NF
region to quantify RIS reflection gains along the user equipment (UE)
trajectory. We propose a new HO algorithm incorporating several HO categories
like hard handover (HHO), soft handover (SHO), RIS-aided cell breathing
(RIS-CB), and RIS-aided ping-pong avoidance (RIS-PP) strategies. The proposed
algorithm uses bit error rate (BER) as a key parameter to predict the
minimization of unnecessary HOs by using RIS-aided pathways to retain
connectivity with the serving base station (BS), which minimizes the
requirement for frequent target BS searching and ultimately optimizes the HO.
By restricting measurement reports and HO requests, the suggested method
improves spectrum efficiency (SE) and energy efficiency (EE), especially in
crowded cellular networks. Numerical results highlight significant reductions
in HO rates and signaling load, ensuring seamless connectivity and improved
quality of service (QoS) in 6G systems.

</details>


### [2] [Deep Learning for Gradient and BCG Artifacts Removal in EEG During Simultaneous fMRI](https://arxiv.org/abs/2507.22263)
*K. A. Shahriar,E. H. Bhuiyan,Q. Luo,M. E. H. Chowdhury,X. J. Zhou*

Main category: eess.SP

TL;DR: 论文提出了一种基于去噪自编码器（DAR）的深度学习方法，用于去除EEG-fMRI同步记录中的磁共振伪影，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: EEG-fMRI同步记录的高时空分辨率受到磁共振伪影（如梯度伪影和心电伪影）的干扰，限制了其应用。

Method: 使用1D卷积自编码器，从噪声信号到清晰信号的直接映射，利用CWL EEG-fMRI数据集进行训练和测试。

Result: DAR的RMSE为0.0218±0.0152，SSIM为0.8885±0.0913，SNR增益为14.63 dB，显著优于传统方法（p<0.001）。

Conclusion: DAR是一种高效且可解释的实时EEG伪影去除方法，适用于EEG-fMRI同步记录。

Abstract: Simultaneous EEG-fMRI recording combines high temporal and spatial resolution
for tracking neural activity. However, its usefulness is greatly limited by
artifacts from magnetic resonance (MR), especially gradient artifacts (GA) and
ballistocardiogram (BCG) artifacts, which interfere with the EEG signal. To
address this issue, we used a denoising autoencoder (DAR), a deep learning
framework designed to reduce MR-related artifacts in EEG recordings. Using
paired data that includes both artifact-contaminated and MR-corrected EEG from
the CWL EEG-fMRI dataset, DAR uses a 1D convolutional autoencoder to learn a
direct mapping from noisy to clear signal segments. Compared to traditional
artifact removal methods like principal component analysis (PCA), independent
component analysis (ICA), average artifact subtraction (AAS), and wavelet
thresholding, DAR shows better performance. It achieves a root-mean-squared
error (RMSE) of 0.0218 $\pm$ 0.0152, a structural similarity index (SSIM) of
0.8885 $\pm$ 0.0913, and a signal-to-noise ratio (SNR) gain of 14.63 dB.
Statistical analysis with paired t-tests confirms that these improvements are
significant (p<0.001; Cohen's d>1.2). A leave-one-subject-out (LOSO)
cross-validation protocol shows that the model generalizes well, yielding an
average RMSE of 0.0635 $\pm$ 0.0110 and an SSIM of 0.6658 $\pm$ 0.0880 across
unseen subjects. Additionally, saliency-based visualizations demonstrate that
DAR highlights areas with dense artifacts, which makes its decisions easier to
interpret. Overall, these results position DAR as a potential and
understandable solution for real-time EEG artifact removal in simultaneous
EEG-fMRI applications.

</details>


### [3] [Robust Filtering and Learning in State-Space Models: Skewness and Heavy Tails Via Asymmetric Laplace Distribution](https://arxiv.org/abs/2507.22343)
*Yifan Yu,Shengjie Xiu,Daniel P. Palomar*

Main category: eess.SP

TL;DR: 本文提出了一种基于非对称拉普拉斯分布的鲁棒状态空间模型扩展，通过高效的变分贝叶斯算法和单循环参数估计策略，显著提升了模型在异常数据下的性能。


<details>
  <summary>Details</summary>
Motivation: 传统状态空间模型在处理非高斯分布（如偏态和厚尾数据）时表现不佳，需要一种更鲁棒的方法。

Method: 采用非对称拉普拉斯分布建模复杂数据特性，并提出高效的变分贝叶斯算法和单循环参数估计策略。

Result: 实验表明，该方法在各种噪声条件下表现稳健，无需手动调整超参数，且计算资源消耗更低。

Conclusion: 该方法在鲁棒控制和金融建模等领域具有实际应用潜力。

Abstract: State-space models are pivotal for dynamic system analysis but often struggle
with outlier data that deviates from Gaussian distributions, frequently
exhibiting skewness and heavy tails. This paper introduces a robust extension
utilizing the asymmetric Laplace distribution, specifically tailored to capture
these complex characteristics. We propose an efficient variational Bayes
algorithm and a novel single-loop parameter estimation strategy, significantly
enhancing the efficiency of the filtering, smoothing, and parameter estimation
processes. Our comprehensive experiments demonstrate that our methods provide
consistently robust performance across various noise settings without the need
for manual hyperparameter adjustments. In stark contrast, existing models
generally rely on specific noise conditions and necessitate extensive manual
tuning. Moreover, our approach uses far fewer computational resources, thereby
validating the model's effectiveness and underscoring its potential for
practical applications in fields such as robust control and financial modeling.

</details>


### [4] [Green One-Bit Quantized Precoding in Cell-Free Massive MIMO](https://arxiv.org/abs/2507.22400)
*Salih Gümüsbuğa,Ozan Alp Topal,Özlem Tuğfe Demir*

Main category: eess.SP

TL;DR: 提出了一种新型量化预编码算法，用于无小区大规模MIMO系统，通过动态关闭不必要的天线提高能效。


<details>
  <summary>Details</summary>
Motivation: 解决大规模MIMO系统中高分辨率射频链导致的高功耗问题，平衡能效与性能。

Method: 动态根据符号向量结构关闭不必要天线，设计量化预编码算法。

Result: 仿真显示算法优于SQUID和RZF，性能更优且功耗更低。

Conclusion: 该算法为无小区大规模MIMO系统提供了一种高效节能的解决方案。

Abstract: Cell-free massive MIMO (multiple-input multiple-output) is expected to be one
of the key technologies in sixth-generation (6G) and beyond wireless
communications, offering enhanced spectral efficiency for cell-edge user
equipments by employing joint transmission and reception with a large number of
antennas distributed throughout the region. However, high-resolution RF chains
associated with these antennas significantly increase power consumption. To
address this issue, the use of low-resolution analog-to-digital and
digital-to-analog converters (ADCs/DACs) has emerged as a promising approach to
balance power efficiency and performance in massive MIMO networks. In this
work, we propose a novel quantized precoding algorithm tailored for cell-free
massive MIMO systems, where the proposed method dynamically deactivates
unnecessary antennas based on the structure of each symbol vector, thereby
enhancing energy efficiency. Simulation results demonstrate that our algorithm
outperforms existing methods such as squared-infinity norm Douglas-Rachford
splitting (SQUID) and regularized zero forcing (RZF), achieving superior
performance while effectively reducing power consumption.

</details>


### [5] [PINN and GNN-based RF Map Construction for Wireless Communication Systems](https://arxiv.org/abs/2507.22513)
*Lizhou Liu,Xiaohui Chen,Zihan Tang,Mengyao Ma,Wenyi Zhang*

Main category: eess.SP

TL;DR: 提出了一种基于物理信息神经网络（PINN）和图神经网络（GNN）的RF地图构建方法，结合物理约束和空间相关性，实现了多径参数的高精度预测。


<details>
  <summary>Details</summary>
Motivation: RF地图能捕捉多径信号传播特性，对无线通信网络的信道建模、覆盖分析和波束成形至关重要。传统方法在稀疏采样条件下性能受限，需结合物理先验和空间相关性以提高精度。

Method: 结合PINN（引入电磁传播规律的物理约束）和GNN（建模接收器位置的空间相关性），将多径信号参数化为接收功率、延迟和到达角（AoA）。

Result: 实验表明，该方法在稀疏采样条件下能高精度构建RF地图，在室内和复杂室外环境中均表现优异，泛化能力和准确性优于基线方法。

Conclusion: 该方法通过融合物理先验和空间相关性，为RF地图构建提供了一种高效且鲁棒的解决方案。

Abstract: Radio frequency (RF) map is a promising technique for capturing the
characteristics of multipath signal propagation, offering critical support for
channel modeling, coverage analysis, and beamforming in wireless communication
networks. This paper proposes a novel RF map construction method based on a
combination of physics-informed neural network (PINN) and graph neural network
(GNN). The PINN incorporates physical constraints derived from electromagnetic
propagation laws to guide the learning process, while the GNN models spatial
correlations among receiver locations. By parameterizing multipath signals into
received power, delay, and angle of arrival (AoA), and integrating both
physical priors and spatial dependencies, the proposed method achieves accurate
prediction of multipath parameters. Experimental results demonstrate that the
method enables high-precision RF map construction under sparse sampling
conditions and delivers robust performance in both indoor and complex outdoor
environments, outperforming baseline methods in terms of generalization and
accuracy.

</details>


### [6] [Exploration of Low-Cost but Accurate Radar-Based Human Motion Direction Determination](https://arxiv.org/abs/2507.22567)
*Weicheng Gao*

Main category: eess.SP

TL;DR: 提出了一种低成本但准确的雷达方法，用于确定人体运动方向，结合特征增强和轻量级混合模型。


<details>
  <summary>Details</summary>
Motivation: 运动方向角影响微多普勒频谱宽度，为步态识别等任务提供重要先验信息，但现有方法在特征增强和运动方向确定方面仍有改进空间。

Method: 首先生成雷达步态DTM，通过特征链接模型增强特征，再使用轻量级Vision Transformer-CNN混合模型实现运动方向确定。

Result: 通过开源数据集验证了方法的有效性。

Conclusion: 该方法低成本且准确，代码已开源。

Abstract: This work is completed on a whim after discussions with my junior colleague.
The motion direction angle affects the micro-Doppler spectrum width, thus
determining the human motion direction can provide important prior information
for downstream tasks such as gait recognition. However, Doppler-Time map
(DTM)-based methods still have room for improvement in achieving feature
augmentation and motion determination simultaneously. In response, a low-cost
but accurate radar-based human motion direction determination (HMDD) method is
explored in this paper. In detail, the radar-based human gait DTMs are first
generated, and then the feature augmentation is achieved using feature linking
model. Subsequently, the HMDD is implemented through a lightweight and fast
Vision Transformer-Convolutional Neural Network hybrid model structure. The
effectiveness of the proposed method is verified through open-source dataset.
The open-source code of this work is released at:
https://github.com/JoeyBGOfficial/Low-Cost-Accurate-Radar-Based-Human-Motion-Direction-Determination.

</details>


### [7] [Fundamental Limits of Rigid Body Localization](https://arxiv.org/abs/2507.22573)
*Niclas Führling,Ivan Alexander Morales Sandoval,Giuseppe Thadeu Freitas de Abreu,Gonzalo Seco-Granados,David González G.,Osvaldo Gonsa*

Main category: eess.SP

TL;DR: 提出了一种新的方法来构建刚体定位问题的Cramér-Rao下界（CRLB），用于评估刚体平移和旋转估计的基本精度限制。


<details>
  <summary>Details</summary>
Motivation: 评估刚体定位问题中平移和旋转估计的基本精度限制，并扩展传统Fisher信息矩阵（FIM）的适用范围。

Method: 采用信息中心的FIM构建方法，捕捉每种测量对FIM的贡献，推导出适用于任何刚体定位场景的通用CRLB框架。

Result: 给出了所有CRLB的闭式表达式，包括对旋转矩阵的正交约束。数值结果表明，这些表达式正确下界了现有最先进估计器的误差。

Conclusion: 提出的CRLB框架揭示了现有刚体定位算法的精度限制，并表明仍有改进空间。

Abstract: We consider a novel approach to formulate the Cram\'er-Rao Lower Bound (CRLB)
for the rigid body localization (RBL) problem, which allows us to assess the
fundamental accuracy limits on the estimation of the translation and rotation
of a rigid body with respect to a known reference. To that end, we adopt an
information-centric construction of the Fisher information matrix (FIM), which
allows to capture the contribution of each measurement towards the FIM, both in
terms of input measurement types, as well as of their error distributions.
Taking advantage of this approach, we derive a generic framework for the CRLB
formulation, which is applicable to any type of rigid body localization
scenario, extending the conventional FIM formulation suitable for point targets
to the case of a rigid body whose location include both translation vector and
the rotation matrix (or alternative the rotation angles), with respect to a
reference. Closed-form expressions for all CRLBs are given, including the bound
incorporating an orthonormality constraint onto the rotation matrix. Numerical
results illustrate that the derived expression correctly lower-bounds the
errors of estimated localization parameters obtained via various related
state-of-the-art (SotA) estimators, revealing their accuracies and suggesting
that SotA RBL algorithms can still be improved.

</details>


### [8] [Measurement and Analysis of the Power Consumption of Hybrid-Amplified SCL-band Links](https://arxiv.org/abs/2507.22616)
*Ronit Sohanpal,Jiaqian Yang,Eric Sillekens,Henrique Buglia,Mingming Tan,Dini Pratiwi,Robert I. Killey,Polina Bayvel*

Main category: eess.SP

TL;DR: 研究了混合放大SCL波段链路的功耗，发现多跨度混合拉曼放大链路比集总放大节省26%的能耗。


<details>
  <summary>Details</summary>
Motivation: 探索混合放大技术在SCL波段链路中的能效表现，以降低通信系统的能耗。

Method: 使用商用台式放大器和拉曼泵浦，对比混合拉曼放大与集总放大的能耗。

Result: 多跨度混合拉曼放大链路比集总放大节省26%的能耗。

Conclusion: 混合拉曼放大技术在SCL波段链路中具有显著的能效优势。

Abstract: We studied the power consumption of hybrid-amplified SCL-band links using
commercial benchtop amplifiers and Raman pumps. We show a reduction in energy
per bit for multi-span hybrid Raman amplified links of up to 26% versus lumped
amplification.

</details>


### [9] [A Multi-Scale Spatial Attention Network for Near-field MIMO Channel Estimation](https://arxiv.org/abs/2507.22656)
*Zhiming Zhu,Shu Xu,Jiexin Zhang,Chunguo Li,Yongming Huang,Luxi Yang*

Main category: eess.SP

TL;DR: 论文提出了一种基于空间注意力的深度学习方法（MsSAN），用于解决极大规模阵列（ELAA）在近场信道估计中的问题，通过多尺度架构和创新的空间注意力机制，显著提升了信道重建性能。


<details>
  <summary>Details</summary>
Motivation: 极大规模阵列（ELAA）虽然提高了频谱效率和空间自由度，但引发了近场信道估计的问题。现有的基于变换域稀疏性的方法对变换矩阵选择和停止标准敏感，因此需要更鲁棒的解决方案。

Method: 论文提出了一种多尺度空间注意力网络（MsSAN），通过分析近场信道的空间天线相关性，利用子信道间的交互来描述相关性，并引入点积和作为空间注意力机制。

Result: 仿真结果表明，MsSAN在近场信道重建中表现出色，显著优于其他方法，尤其是在子信道相关性学习能力方面。

Conclusion: MsSAN通过创新的空间注意力机制和多尺度架构，为近场MIMO信道估计提供了一种高效且鲁棒的解决方案。

Abstract: The deployment of extremely large-scale array (ELAA) brings higher spectral
efficiency and spatial degree of freedom, but triggers issues on near-field
channel estimation.
  Existing near-field channel estimation schemes primarily exploit sparsity in
the transform domain.
  However, these schemes are sensitive to the transform matrix selection and
the stopping criteria.
  Inspired by the success of deep learning (DL) in far-field channel
estimation, this paper proposes a novel spatial-attention-based method for
reconstructing extremely large-scale MIMO (XL-MIMO) channel.
  Initially, the spatial antenna correlations of near-field channels are
analyzed as an expectation over the angle-distance space, which demonstrate
correlation range of an antenna element varies with its position.
  Due to the strong correlation between adjacent antenna elements, interactions
of inter-subchannel are applied to describe inherent correlation of near-field
channels instead of inter-element.
  Subsequently, a multi-scale spatial attention network (MsSAN) with the
inter-subchannel correlation learning capabilities is proposed tailed to
near-field MIMO channel estimation.
  We employ the multi-scale architecture to refine the subchannel size in
MsSAN.
  Specially, we inventively introduce the sum of dot products as spatial
attention (SA) instead of cross-covariance to weight subchannel features at
different scales in the SA module.
  Simulation results are presented to validate the proposed MsSAN achieves
remarkable the inter-subchannel correlation learning capabilities and
outperforms others in terms of near-field channel reconstruction.

</details>


### [10] [Compressive Near-Field Wideband Channel Estimation for THz Extremely Large-scale MIMO Systems](https://arxiv.org/abs/2507.22727)
*Jionghui Wang,Hongwei Wang,Jun Fang,Lingxiang Li,Zhi Chen*

Main category: eess.SP

TL;DR: 论文提出了一种基于频率无关正交字典的宽带近场信道估计方法，利用二维块稀疏结构在压缩感知框架下高效解决问题，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决太赫兹通信系统中宽带近场信道的获取问题，克服路径衰减和波束分裂现象。

Method: 提出频率无关正交字典，引入参数捕捉近场特性，利用二维块稀疏结构和压缩感知框架进行信道估计。

Result: 数值结果表明，所提方法在宽带近场信道估计中优于传统极域方法。

Conclusion: 该方法为太赫兹通信系统的宽带近场信道获取提供了高效解决方案。

Abstract: We consider the channel acquisition problem for a wideband terahertz (THz)
communication system, where an extremely large-scale array is deployed to
mitigate severe path attenuation. In channel modeling, we account for both the
near-field spherical wavefront and the wideband beam-splitting phenomena,
resulting in a wideband near-field channel. We propose a frequency-independent
orthogonal dictionary that generalizes the standard discrete Fourier transform
(DFT) matrix by introducing an additional parameter to capture the near-field
property. This dictionary enables the wideband near-field channel to be
efficiently represented with a two-dimensional (2D) block-sparse structure.
Leveraging this specific sparse structure, the wideband near-field channel
estimation problem can be effectively addressed within a customized compressive
sensing framework. Numerical results demonstrate the significant advantages of
our proposed 2D block-sparsity-aware method over conventional
polar-domain-based approaches for near-field wideband channel estimation.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [11] [Scaling and Distilling Transformer Models for sEMG](https://arxiv.org/abs/2507.22094)
*Nicholas Mehlman,Jean-Christophe Gagnon-Audet,Michael Shvartsman,Kelvin Niu,Alexander H. Miller,Shagun Sodhani*

Main category: eess.AS

TL;DR: 研究表明，基于sEMG信号的Transformer模型可以扩展到110M参数，性能优于传统小模型（<10M参数），并能通过蒸馏技术压缩50倍，保持高性能。


<details>
  <summary>Details</summary>
Motivation: 解决sEMG任务中训练数据不足和计算资源受限的问题，探索大模型在sEMG领域的潜力。

Method: 使用Transformer模型，并研究其参数规模对性能的影响，同时应用模型蒸馏技术压缩模型。

Result: 110M参数的Transformer模型性能优于小模型，且蒸馏后的50x小模型性能损失<1.5%。

Conclusion: 大模型在sEMG任务中表现优异，蒸馏技术可实现高效部署，适用于实时复杂任务。

Abstract: Surface electromyography (sEMG) signals offer a promising avenue for
developing innovative human-computer interfaces by providing insights into
muscular activity. However, the limited volume of training data and
computational constraints during deployment have restricted the investigation
of scaling up the model size for solving sEMG tasks. In this paper, we
demonstrate that vanilla transformer models can be effectively scaled up on
sEMG data and yield improved cross-user performance up to 110M parameters,
surpassing the model size regime investigated in other sEMG research (usually
<10M parameters). We show that >100M-parameter models can be effectively
distilled into models 50x smaller with minimal loss of performance (<1.5%
absolute). This results in efficient and expressive models suitable for complex
real-time sEMG tasks in real-world environments.

</details>


### [12] [Tiny Noise-Robust Voice Activity Detector for Voice Assistants](https://arxiv.org/abs/2507.22157)
*Hamed Jafarzadeh Asl,Mahsa Ghazvini Nejad,Amin Edraki,Masoud Asgharian,Vahid Partovi Nia*

Main category: eess.AS

TL;DR: 提出了一种轻量级且抗噪声的语音活动检测（VAD）方法，通过数据预处理和后处理模块提升噪声环境下的检测准确性，无需更大模型或微调。


<details>
  <summary>Details</summary>
Motivation: 背景噪声严重影响语音活动检测（VAD）的准确性，尤其在AIoT设备等实际应用中，现有模型在低信噪比和多样化声学环境中表现不佳。

Method: 提出一种轻量级VAD，结合数据预处理和后处理模块，以增强噪声环境下的检测能力。

Result: 实验结果表明，该方法在高背景噪声环境下显著优于基线模型，同时提升了干净语音的检测效果。

Conclusion: 该方法为噪声环境下的VAD提供了一种高效且轻量级的解决方案，适用于实际应用场景。

Abstract: Voice Activity Detection (VAD) in the presence of background noise remains a
challenging problem in speech processing. Accurate VAD is essential in
automatic speech recognition, voice-to-text, conversational agents, etc, where
noise can severely degrade the performance. A modern application includes the
voice assistant, specially mounted on Artificial Intelligence of Things (AIoT)
devices such as cell phones, smart glasses, earbuds, etc, where the voice
signal includes background noise. Therefore, VAD modules must remain
light-weight due to their practical on-device limitation. The existing models
often struggle with low signal-to-noise ratios across diverse acoustic
environments. A simple VAD often detects human voice in a clean environment,
but struggles to detect the human voice in noisy conditions. We propose a
noise-robust VAD that comprises a light-weight VAD, with data pre-processing
and post-processing added modules to handle the background noise. This approach
significantly enhances the VAD accuracy in noisy environments and requires
neither a larger model, nor fine-tuning. Experimental results demonstrate that
our approach achieves a notable improvement compared to baselines, particularly
in environments with high background noise interference. This modified VAD
additionally improving clean speech detection.

</details>


### [13] [The Risks and Detection of Overestimated Privacy Protection in Voice Anonymisation](https://arxiv.org/abs/2507.22534)
*Michele Panariello,Sarina Meyer,Pierre Champion,Xiaoxiao Miao,Massimiliano Todisco,Ngoc Thang Vu,Nicholas Evans*

Main category: eess.AS

TL;DR: 论文探讨了语音匿名化性能评估中的潜在风险，指出验证系统训练不足可能导致隐私保护效果被高估，并提出了一种检测方法。


<details>
  <summary>Details</summary>
Motivation: 揭示语音匿名化性能评估中因验证系统不匹配或训练不足导致的隐私保护效果高估问题。

Method: 通过分析文献中的案例，提出一种检测性能评估是否可信的方法，并将其集成到开源工具中。

Result: 研究发现最严重情况下性能被高估74%，提出的检测方法能有效识别所有高估场景。

Conclusion: 论文强调性能评估的可靠性问题，并提供了一种实用工具以改善语音匿名化研究的可信度。

Abstract: Voice anonymisation aims to conceal the voice identity of speakers in speech
recordings. Privacy protection is usually estimated from the difficulty of
using a speaker verification system to re-identify the speaker
post-anonymisation. Performance assessments are therefore dependent on the
verification model as well as the anonymisation system. There is hence
potential for privacy protection to be overestimated when the verification
system is poorly trained, perhaps with mismatched data. In this paper, we
demonstrate the insidious risk of overestimating anonymisation performance and
show examples of exaggerated performance reported in the literature. For the
worst case we identified, performance is overestimated by 74% relative. We then
introduce a means to detect when performance assessment might be untrustworthy
and show that it can identify all overestimation scenarios presented in the
paper. Our solution is openly available as a fork of the 2024 VoicePrivacy
Challenge evaluation toolkit.

</details>


### [14] [Modeling Multi-Level Hearing Loss for Speech Intelligibility Prediction](https://arxiv.org/abs/2507.22599)
*Xiajie Zhou,Candy Olivia Mawalim,Masashi Unoki*

Main category: eess.AS

TL;DR: 提出了一种基于听觉退化的语音清晰度预测方法，通过模拟听力损失对频率和时间分辨率的影响，结合视觉Transformer模型，显著提升了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统临床听力测试无法充分捕捉频率和时间分辨率的缺陷，限制了语音清晰度的准确预测。

Method: 通过加宽耳蜗滤波器和低通调制滤波模拟听力损失，利用STM表示和NCC矩阵提取特征，训练视觉Transformer模型预测清晰度。

Result: 在Clarity Prediction Challenge语料库上，该方法优于HASPI v2，轻度听力损失组误差降低16.5%，中重度组降低6.1%。

Conclusion: 明确模拟听众特定的频率和时间分辨率退化对提升语音清晰度预测的准确性和可解释性至关重要。

Abstract: The diverse perceptual consequences of hearing loss severely impede speech
communication, but standard clinical audiometry, which is focused on
threshold-based frequency sensitivity, does not adequately capture deficits in
frequency and temporal resolution. To address this limitation, we propose a
speech intelligibility prediction method that explicitly simulates auditory
degradations according to hearing loss severity by broadening cochlear filters
and applying low-pass modulation filtering to temporal envelopes. Speech
signals are subsequently analyzed using the spectro-temporal modulation (STM)
representations, which reflect how auditory resolution loss alters the
underlying modulation structure. In addition, normalized cross-correlation
(NCC) matrices quantify the similarity between the STM representations of clean
speech and speech in noise. These auditory-informed features are utilized to
train a Vision Transformer-based regression model that integrates the STM maps
and NCC embeddings to estimate speech intelligibility scores. Evaluations on
the Clarity Prediction Challenge corpus show that the proposed method
outperforms the Hearing-Aid Speech Perception Index v2 (HASPI v2) in both mild
and moderate-to-severe hearing loss groups, with a relative root mean squared
error reduction of 16.5% for the mild group and a 6.1% reduction for the
moderate-to-severe group. These results highlight the importance of explicitly
modeling listener-specific frequency and temporal resolution degradations to
improve speech intelligibility prediction and provide interpretability in
auditory distortions.

</details>


### [15] [A k-space approach to modeling multi-channel parametric array loudspeaker systems](https://arxiv.org/abs/2507.22628)
*Tao Zhuang,Longbiao He,Feng Niu,Jia-Xin Zhong,Jing Lu*

Main category: eess.AS

TL;DR: 提出了一种基于k空间的方法，用于高效准确地预测多通道参数阵列扬声器（MCPAL）系统的声场。


<details>
  <summary>Details</summary>
Motivation: MCPAL系统在现实应用中具有潜力，但其复杂的非线性行为和多通道信号处理使得声场预测成为挑战。

Method: 采用k空间方法，首先用角谱法求解线性超声场，随后在k空间中高效计算准线性音频声场。

Result: 相比直接积分法，该方法在典型配置下实现了超过四个数量级的加速。

Conclusion: 该方法为模拟和设计先进的MCPAL系统提供了高效准确的工具。

Abstract: Multi-channel parametric array loudspeaker (MCPAL) systems offer enhanced
flexibility and promise for generating highly directional audio beams in
real-world applications. However, efficient and accurate prediction of their
generated sound fields remains a major challenge due to the complex nonlinear
behavior and multi-channel signal processing involved. To overcome this
obstacle, we propose a k-space approach for modeling arbitrary MCPAL systems
arranged on a baffled planar surface. In our method, the linear ultrasound
field is first solved using the angular spectrum approach, and the quasilinear
audio sound field is subsequently computed efficiently in k-space. By
leveraging three-dimensional fast Fourier transforms, our approach not only
achieves high computational and memory efficiency but also maintains accuracy
without relying on the paraxial approximation. For typical configurations
studied, the proposed method demonstrates a speed-up of more than four orders
of magnitude compared to the direct integration method. Our proposed approach
paved the way for simulating and designing advanced MCPAL systems.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [16] [Quantum-Inspired Audio Unlearning: Towards Privacy-Preserving Voice Biometrics](https://arxiv.org/abs/2507.22208)
*Shreyansh Pathak,Sonu Shreshtha,Richa Singh,Mayank Vatsa*

Main category: cs.SD

TL;DR: QPAudioEraser是一种量子启发的音频遗忘框架，用于高效删除语音数据中的个体特征，满足隐私法规要求。


<details>
  <summary>Details</summary>
Motivation: 语音认证和生物识别系统的普及增加了隐私风险，现有方法无法有效处理音频信号的高维和时序特性。

Method: 采用量子启发的四阶段方法：权重初始化、标签变换、量子损失函数和权重混合。

Result: 在多种架构和数据集上验证，QPAudioEraser能完全删除目标数据（0%遗忘准确率），且对模型性能影响极小（仅0.05%）。

Conclusion: QPAudioEraser是一种强大的隐私保护解决方案，优于传统方法。

Abstract: The widespread adoption of voice-enabled authentication and audio biometric
systems have significantly increased privacy vulnerabilities associated with
sensitive speech data. Compliance with privacy regulations such as GDPR's right
to be forgotten and India's DPDP Act necessitates targeted and efficient
erasure of individual-specific voice signatures from already-trained biometric
models. Existing unlearning methods designed for visual data inadequately
handle the sequential, temporal, and high-dimensional nature of audio signals,
leading to ineffective or incomplete speaker and accent erasure. To address
this, we introduce QPAudioEraser, a quantum-inspired audio unlearning
framework. Our our-phase approach involves: (1) weight initialization using
destructive interference to nullify target features, (2) superposition-based
label transformations that obscure class identity, (3) an
uncertainty-maximizing quantum loss function, and (4) entanglement-inspired
mixing of correlated weights to retain model knowledge. Comprehensive
evaluations with ResNet18, ViT, and CNN architectures across AudioMNIST, Speech
Commands, LibriSpeech, and Speech Accent Archive datasets validate
QPAudioEraser's superior performance. The framework achieves complete erasure
of target data (0% Forget Accuracy) while incurring minimal impact on model
utility, with a performance degradation on retained data as low as 0.05%.
QPAudioEraser consistently surpasses conventional baselines across
single-class, multi-class, sequential, and accent-level erasure scenarios,
establishing the proposed approach as a robust privacy-preserving solution.

</details>


### [17] [A Two-Step Learning Framework for Enhancing Sound Event Localization and Detection](https://arxiv.org/abs/2507.22322)
*Hogeon Yu*

Main category: cs.SD

TL;DR: 提出了一种两步学习框架，通过轨迹重排序和任务特定特征学习，解决了单分支和双分支SELD方法的局限性，提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有SELD方法中，单分支模型共享SED和DoA表示导致优化冲突，双分支模型分离任务但限制了信息交换，需要一种更好的解决方案。

Method: 1. 引入轨迹重排序格式保持时间一致性；2. 分别训练SED和DoA网络避免干扰；3. 有效融合DoA和SED特征。

Result: 在2023 DCASE挑战赛Task 3数据集上验证，框架克服了单双分支限制，提升了事件分类和定位性能。

Conclusion: 提出的两步学习框架有效解决了SELD中的优化冲突和信息交换问题，显著提升了性能。

Abstract: Sound Event Localization and Detection (SELD) is crucial in spatial audio
processing, enabling systems to detect sound events and estimate their 3D
directions. Existing SELD methods use single- or dual-branch architectures:
single-branch models share SED and DoA representations, causing optimization
conflicts, while dual-branch models separate tasks but limit information
exchange. To address this, we propose a two-step learning framework. First, we
introduce a tracwise reordering format to maintain temporal consistency,
preventing event reassignments across tracks. Next, we train SED and DoA
networks to prevent interference and ensure task-specific feature learning.
Finally, we effectively fuse DoA and SED features to enhance SELD performance
with better spatial and event representation. Experiments on the 2023 DCASE
challenge Task 3 dataset validate our framework, showing its ability to
overcome single- and dual-branch limitations and improve event classification
and localization.

</details>


### [18] [Adaptive Duration Model for Text Speech Alignment](https://arxiv.org/abs/2507.22612)
*Junjie Cao*

Main category: cs.SD

TL;DR: 提出了一种新的音素级时长预测框架，提高了语音到文本对齐的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决自回归TTS模型中注意力机制对齐的脆弱性，以及非自回归TTS模型依赖外部时长的问题。

Method: 提出了一种新的时长预测框架，能够根据给定文本生成音素级时长分布。

Result: 实验表明，该模型在对齐准确率上提升了约11.3%，并增强了零样本TTS模型的鲁棒性。

Conclusion: 提出的时长预测框架显著提升了TTS模型的对齐性能和适应性。

Abstract: Speech-to-text alignment is a critical component of neural text to-speech
(TTS) models. Autoregressive TTS models typically use an attention mechanism to
learn these alignments on-line. However, these alignments tend to be brittle
and often fail to generalize to long utterances and out-of-domain text, leading
to missing or repeating words. Most non-autoregressive end to-end TTS models
rely on durations extracted from external sources, using additional duration
models for alignment. In this paper, we propose a novel duration prediction
framework that can give compromising phoneme-level duration distribution with
given text. In our experiments, the proposed duration model has more precise
prediction and condition adaptation ability compared to previous baseline
models. Numerically, it has roughly a 11.3 percents immprovement on alignment
accuracy, and makes the performance of zero-shot TTS models more robust to the
mismatch between prompt audio and input audio.

</details>


### [19] [Next Tokens Denoising for Speech Synthesis](https://arxiv.org/abs/2507.22746)
*Yanqing Liu,Ruiqing Xue,Chong Zhang,Yufei Liu,Gang Wang,Bohan Li,Yao Qian,Lei He,Shujie Liu,Sheng Zhao*

Main category: cs.SD

TL;DR: Dragon-FM结合自回归和流匹配模型，解决了传统方法的局限性，实现了高效高质量的语音生成。


<details>
  <summary>Details</summary>
Motivation: 自回归模型和扩散模型各有局限性，前者无法利用未来上下文且生成速度慢，后者难以处理KV缓存。

Method: 提出Dragon-FM，统一自回归和流匹配模型，分块处理音频码本标记，实现全局一致性和快速迭代去噪。

Result: 实验表明，该模型能高效生成高质量零样本播客内容。

Conclusion: Dragon-FM在语音生成中表现出色，结合了两种模型的优势。

Abstract: While diffusion and autoregressive (AR) models have significantly advanced
generative modeling, they each present distinct limitations. AR models, which
rely on causal attention, cannot exploit future context and suffer from slow
generation speeds. Conversely, diffusion models struggle with key-value (KV)
caching. To overcome these challenges, we introduce Dragon-FM, a novel
text-to-speech (TTS) design that unifies AR and flow-matching. This model
processes 48 kHz audio codec tokens in chunks at a compact 12.5 tokens per
second rate. This design enables AR modeling across chunks, ensuring global
coherence, while parallel flow-matching within chunks facilitates fast
iterative denoising. Consequently, the proposed model can utilize KV-cache
across chunks and incorporate future context within each chunk. Furthermore, it
bridges continuous and discrete feature modeling, demonstrating that continuous
AR flow-matching can predict discrete tokens with finite scalar quantizers.
This efficient codec and fast chunk-autoregressive architecture also makes the
proposed model particularly effective for generating extended content.
Experiment for demos of our work} on podcast datasets demonstrate its
capability to efficiently generate high-quality zero-shot podcasts.

</details>

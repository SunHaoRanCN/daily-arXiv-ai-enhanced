{"id": "2507.22995", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.22995", "abs": "https://arxiv.org/abs/2507.22995", "authors": ["Julia Wilkins", "Sivan Ding", "Magdalena Fuentes", "Juan Pablo Bello"], "title": "Balancing Information Preservation and Disentanglement in Self-Supervised Music Representation Learning", "comment": "In proceedings of WASPAA 2025. 4 pages, 4 figures, 1 table", "summary": "Recent advances in self-supervised learning (SSL) methods offer a range of\nstrategies for capturing useful representations from music audio without the\nneed for labeled data. While some techniques focus on preserving comprehensive\ndetails through reconstruction, others favor semantic structure via contrastive\nobjectives. Few works examine the interaction between these paradigms in a\nunified SSL framework. In this work, we propose a multi-view SSL framework for\ndisentangling music audio representations that combines contrastive and\nreconstructive objectives. The architecture is designed to promote both\ninformation fidelity and structured semantics of factors in disentangled\nsubspaces. We perform an extensive evaluation on the design choices of\ncontrastive strategies using music audio representations in a controlled\nsetting. We find that while reconstruction and contrastive strategies exhibit\nconsistent trade-offs, when combined effectively, they complement each other;\nthis enables the disentanglement of music attributes without compromising\ninformation integrity."}
{"id": "2507.23365", "categories": ["cs.SD", "cs.AI", "eess.AS", "I.2; J.5"], "pdf": "https://arxiv.org/pdf/2507.23365", "abs": "https://arxiv.org/abs/2507.23365", "authors": ["Bob L. T. Sturm"], "title": "\"I made this (sort of)\": Negotiating authorship, confronting fraudulence, and exploring new musical spaces with prompt-based AI music generation", "comment": null, "summary": "I reflect on my experience creating two music albums centered on\nstate-of-the-art prompt-based AI music generation platforms. The first album\nexplicitly poses the question: What happens when I collide my junk mail with\nthese platforms? The second album is a direct response to the first, and toys\nwith the inability of state-of-the-art prompt-based AI music generation\nplatforms to generate music that is not ``practiced'', ``polished'', and\n``produced''. I seed a large language model (LLM) with information about these\nalbums and have it interview me, which results in the exploration of several\ndeeper questions: To what extent am I the author? Where am I in the resulting\nmusic? How is my musical identity changing as I am faced with machines that are\nin some ways far more talented than I? What new musical spaces does my work\nopen, for me or anyone/thing else? I conclude by reflecting on my reflections,\nas well as LLM-mediated self-reflection as method."}
{"id": "2507.23590", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.23590", "abs": "https://arxiv.org/abs/2507.23590", "authors": ["Jack Collins", "Adrian Buzea", "Chris Collier", "Alejandro Ballesta Rosen", "Julian Maclaren", "Richard F. Lyon", "Simon Carlile"], "title": "Identifying Hearing Difficulty Moments in Conversational Audio", "comment": null, "summary": "Individuals regularly experience Hearing Difficulty Moments in everyday\nconversation. Identifying these moments of hearing difficulty has particular\nsignificance in the field of hearing assistive technology where timely\ninterventions are key for realtime hearing assistance. In this paper, we\npropose and compare machine learning solutions for continuously detecting\nutterances that identify these specific moments in conversational audio. We\nshow that audio language models, through their multimodal reasoning\ncapabilities, excel at this task, significantly outperforming a simple ASR\nhotword heuristic and a more conventional fine-tuning approach with Wav2Vec, an\naudio-only input architecture that is state-of-the-art for automatic speech\nrecognition (ASR)."}
{"id": "2507.22964", "categories": ["eess.AS", "cs.CL", "cs.SD", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.22964", "abs": "https://arxiv.org/abs/2507.22964", "authors": ["Sotheara Leang", "Éric Castelli", "Dominique Vaufreydaz", "Sethserey Sam"], "title": "Exploring Dynamic Parameters for Vietnamese Gender-Independent ASR", "comment": null, "summary": "The dynamic characteristics of speech signal provides temporal information\nand play an important role in enhancing Automatic Speech Recognition (ASR). In\nthis work, we characterized the acoustic transitions in a ratio plane of\nSpectral Subband Centroid Frequencies (SSCFs) using polar parameters to capture\nthe dynamic characteristics of the speech and minimize spectral variation.\nThese dynamic parameters were combined with Mel-Frequency Cepstral Coefficients\n(MFCCs) in Vietnamese ASR to capture more detailed spectral information. The\nSSCF0 was used as a pseudo-feature for the fundamental frequency (F0) to\ndescribe the tonal information robustly. The findings showed that the proposed\nparameters significantly reduce word error rates and exhibit greater gender\nindependence than the baseline MFCCs."}
{"id": "2507.22964", "categories": ["eess.AS", "cs.CL", "cs.SD", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.22964", "abs": "https://arxiv.org/abs/2507.22964", "authors": ["Sotheara Leang", "Éric Castelli", "Dominique Vaufreydaz", "Sethserey Sam"], "title": "Exploring Dynamic Parameters for Vietnamese Gender-Independent ASR", "comment": null, "summary": "The dynamic characteristics of speech signal provides temporal information\nand play an important role in enhancing Automatic Speech Recognition (ASR). In\nthis work, we characterized the acoustic transitions in a ratio plane of\nSpectral Subband Centroid Frequencies (SSCFs) using polar parameters to capture\nthe dynamic characteristics of the speech and minimize spectral variation.\nThese dynamic parameters were combined with Mel-Frequency Cepstral Coefficients\n(MFCCs) in Vietnamese ASR to capture more detailed spectral information. The\nSSCF0 was used as a pseudo-feature for the fundamental frequency (F0) to\ndescribe the tonal information robustly. The findings showed that the proposed\nparameters significantly reduce word error rates and exhibit greater gender\nindependence than the baseline MFCCs."}
{"id": "2507.22906", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.LG", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.22906", "abs": "https://arxiv.org/abs/2507.22906", "authors": ["Bin Deng", "Jiatong Bai", "Feilong Zhao", "Zuming Xie", "Maolin Li", "Yan Wang", "Feng Shu"], "title": "DNN-based Methods of Jointly Sensing Number and Directions of Targets via a Green Massive H2AD MIMO Receiver", "comment": null, "summary": "As a green MIMO structure, the heterogeneous hybrid analog-digital H2AD MIMO\narchitecture has been shown to own a great potential to replace the massive or\nextremely large-scale fully-digital MIMO in the future wireless networks to\naddress the three challenging problems faced by the latter: high energy\nconsumption, high circuit cost, and high complexity. However, how to\nintelligently sense the number and direction of multi-emitters via such a\nstructure is still an open hard problem. To address this, we propose a\ntwo-stage sensing framework that jointly estimates the number and direction\nvalues of multiple targets. Specifically, three target number sensing methods\nare designed: an improved eigen-domain clustering (EDC) framework, an enhanced\ndeep neural network (DNN) based on five key statistical features, and an\nimproved one-dimensional convolutional neural network (1D-CNN) utilizing full\neigenvalues. Subsequently, a low-complexity and high-accuracy DOA estimation is\nachieved via the introduced online micro-clustering (OMC-DOA) method.\nFurthermore, we derive the Cram\\'er-Rao lower bound (CRLB) for the H2AD under\nmultiple-source conditions as a theoretical performance benchmark. Simulation\nresults show that the developed three methods achieve 100\\% number of targets\nsensing at moderate-to-high SNRs, while the improved 1D-CNN exhibits superior\nunder extremely-low SNR conditions. The introduced OMC-DOA outperforms existing\nclustering and fusion-based DOA methods in multi-source environments."}
{"id": "2507.23223", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2507.23223", "abs": "https://arxiv.org/abs/2507.23223", "authors": ["Ryandhimas E. Zezario", "Sabato M. Siniscalchi", "Fei Chen", "Hsin-Min Wang", "Yu Tsao"], "title": "Feature Importance across Domains for Improving Non-Intrusive Speech Intelligibility Prediction in Hearing Aids", "comment": "Accepted to Interspeech 2025", "summary": "Given the critical role of non-intrusive speech intelligibility assessment in\nhearing aids (HA), this paper enhances its performance by introducing Feature\nImportance across Domains (FiDo). We estimate feature importance on spectral\nand time-domain acoustic features as well as latent representations of Whisper.\nImportance weights are calculated per frame, and based on these weights,\nfeatures are projected into new spaces, allowing the model to focus on\nimportant areas early. Next, feature concatenation is performed to combine the\nfeatures before the assessment module processes them. Experimental results show\nthat when FiDo is incorporated into the improved multi-branched speech\nintelligibility model MBI-Net+, RMSE can be reduced by 7.62% (from 26.10 to\n24.11). MBI-Net+ with FiDo also achieves a relative RMSE reduction of 3.98%\ncompared to the best system in the 2023 Clarity Prediction Challenge. These\nresults validate FiDo's effectiveness in enhancing neural speech assessment in\nHA."}
{"id": "2507.23159", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2507.23159", "abs": "https://arxiv.org/abs/2507.23159", "authors": ["Guan-Ting Lin", "Shih-Yun Shan Kuan", "Qirui Wang", "Jiachen Lian", "Tingle Li", "Hung-yi Lee"], "title": "Full-Duplex-Bench v1.5: Evaluating Overlap Handling for Full-Duplex Speech Models", "comment": "Work in Progress", "summary": "While full-duplex speech agents promise natural, low-latency human--machine\ninteraction by concurrently processing input and output speech, overlap\nmanagement remains under-evaluated. We introduce Full-Duplex-Bench v1.5, a\nmodular, fully automated benchmark that simulates four overlap scenarios: user\ninterruption, listener backchannel, side conversation, and ambient speech. Our\nframework supports both open-sourced and commercial models, offering a\ncomprehensive, extensible metric suite -- categorical dialogue behaviors, stop\nand response latency, prosodic adaptation, and perceived speech quality -- that\ncan be tailored to application-specific criteria. Benchmarking five\nstate-of-the-art agents reveals two principal strategies: repair-first rapid\nyielding versus continuity-first sustained flow, and highlights\nscenario-dependent performance trends. The open-sourced design enables seamless\nextension with new audio assets, languages, and deployment contexts, empowering\npractitioners to customize and accelerate the evaluation of robust full-duplex\nspeech systems."}
{"id": "2507.22909", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.22909", "abs": "https://arxiv.org/abs/2507.22909", "authors": ["Yin Zhang", "Jiayi Zhang", "Bokai Xu", "Yuanbin Chen", "Zhilong Liu", "Jiakang Zheng", "Enyu Shi", "Ziheng Liu", "Tierui Gong", "Wei E. I. Sha", "Chau Yuen", "Shi Jin", "Bo Ai"], "title": "Rydberg Atomic Receivers for Wireless Communications: Fundamentals, Potential, Applications, and Challenges", "comment": null, "summary": "Rydberg atomic receivers (RARs) leverage the quantum coherence of highly\nexcited atoms to overcome the intrinsic physical limitations of conventional\nradio frequency receivers (RFRs), particularly in sensitivity, and bandwidth.\nThis innovative technology represents a paradigm shift in wireless\ncommunication systems. This paper systematically explains the fundamental\nsensing mechanisms of RARs, contrasts their differences from RFRs in working\nprinciples and architectures. We explore their advantages in emerging wireless\ncommunication scenarios, such as integrated sensing and communications, quantum\nRydberg radar, and quantum space communications. Practical challenges, such as\nlimited instantaneous bandwidth and nonlinear distortion, are identified. To\naddress these issues, mitigation strategies and future research directions are\nalso outlined, supporting the advancement of RAR-aided wireless systems."}
{"id": "2507.23266", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2507.23266", "abs": "https://arxiv.org/abs/2507.23266", "authors": ["Aemon Yat Fei Chiu", "Jingyu Li", "Yusheng Tian", "Guangyan Zhang", "Tan Lee"], "title": "CUHK-EE Systems for the vTAD Challenge at NCMMSC 2025", "comment": "Under review", "summary": "This paper presents the Voice Timbre Attribute Detection (vTAD) systems\ndeveloped by the Digital Signal Processing & Speech Technology Laboratory\n(DSP&STL) of the Department of Electronic Engineering (EE) at The Chinese\nUniversity of Hong Kong (CUHK) for the 20th National Conference on\nHuman-Computer Speech Communication (NCMMSC 2025) vTAD Challenge. The proposed\nsystems leverage WavLM-Large embeddings with attentive statistical pooling to\nextract robust speaker representations, followed by two variants of Diff-Net,\ni.e., Feed-Forward Neural Network (FFN) and Squeeze-and-Excitation-enhanced\nResidual FFN (SE-ResFFN), to compare timbre attribute intensities between\nutterance pairs. Experimental results demonstrate that the WavLM-Large+FFN\nsystem generalises better to unseen speakers, achieving 77.96% accuracy and\n21.79% EER, while the WavLM-Large+SE-ResFFN model excels in the 'Seen' setting\nwith 94.42% accuracy and 5.49% EER. These findings highlight a trade-off\nbetween model complexity and generalisation, and underscore the importance of\narchitectural choices in fine-grained speaker modelling. Our analysis also\nreveals the impact of speaker identity, annotation subjectivity, and data\nimbalance on system performance, pointing to future directions for improving\nrobustness and fairness in timbre attribute detection."}
{"id": "2507.23223", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2507.23223", "abs": "https://arxiv.org/abs/2507.23223", "authors": ["Ryandhimas E. Zezario", "Sabato M. Siniscalchi", "Fei Chen", "Hsin-Min Wang", "Yu Tsao"], "title": "Feature Importance across Domains for Improving Non-Intrusive Speech Intelligibility Prediction in Hearing Aids", "comment": "Accepted to Interspeech 2025", "summary": "Given the critical role of non-intrusive speech intelligibility assessment in\nhearing aids (HA), this paper enhances its performance by introducing Feature\nImportance across Domains (FiDo). We estimate feature importance on spectral\nand time-domain acoustic features as well as latent representations of Whisper.\nImportance weights are calculated per frame, and based on these weights,\nfeatures are projected into new spaces, allowing the model to focus on\nimportant areas early. Next, feature concatenation is performed to combine the\nfeatures before the assessment module processes them. Experimental results show\nthat when FiDo is incorporated into the improved multi-branched speech\nintelligibility model MBI-Net+, RMSE can be reduced by 7.62% (from 26.10 to\n24.11). MBI-Net+ with FiDo also achieves a relative RMSE reduction of 3.98%\ncompared to the best system in the 2023 Clarity Prediction Challenge. These\nresults validate FiDo's effectiveness in enhancing neural speech assessment in\nHA."}
{"id": "2507.23057", "categories": ["eess.SP", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2507.23057", "abs": "https://arxiv.org/abs/2507.23057", "authors": ["Triet M. Tran", "Sina Khanmohammadi"], "title": "Neural Energy Landscapes Predict Working Memory Decline After Brain Tumor Resection", "comment": null, "summary": "Surgical resection is the primary treatment option for brain tumor patients,\nbut it carries the risk of postoperative cognitive dysfunction. This study\ninvestigates how tumor-induced alterations in presurgical neural dynamics\nrelate to postoperative working memory decline. We analyzed functional magnetic\nresonance imaging (fMRI) of brain tumor patients before surgery and extracted\nenergy landscapes of high-order brain interactions. We then examined the\nrelation between these energy features and postoperative working memory\nperformance using statistical and machine learning (random forest) models.\nPatients with lower postoperative working memory scores exhibited fewer but\nmore extreme transitions between local energy minima and maxima, whereas\npatients with higher scores showed more frequent but less extreme shifts.\nFurthermore, the presurgical high-order energy features were able to accurately\npredict postoperative working memory decline with a mean accuracy of 90\\%, F1\nscore of 87.5\\%, and an AUC of 0.95. Our study suggests that the brain\ntumor-induced disruptions in high-order neural dynamics before surgery are\npredictive of postoperative working memory decline. Our findings pave the path\nfor personalized surgical planning and targeted interventions to mitigate\ncognitive risks associated with brain tumor resection."}
{"id": "2507.23511", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2507.23511", "abs": "https://arxiv.org/abs/2507.23511", "authors": ["Yadong Niu", "Tianzi Wang", "Heinrich Dinkel", "Xingwei Sun", "Jiahao Zhou", "Gang Li", "Jizhong Liu", "Xunying Liu", "Junbo Zhang", "Jian Luan"], "title": "MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks", "comment": "9 main pages, 5 figures, 3 tables, and 14 appendix pages", "summary": "While large audio-language models have advanced open-ended audio\nunderstanding, they still fall short of nuanced human-level comprehension. This\ngap persists largely because current benchmarks, limited by data annotations\nand evaluation metrics, fail to reliably distinguish between generic and highly\ndetailed model outputs. To this end, this work introduces MECAT, a Multi-Expert\nConstructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via\na pipeline that integrates analysis from specialized expert models with\nChain-of-Thought large language model reasoning, MECAT provides\nmulti-perspective, fine-grained captions and open-set question-answering pairs.\nThe benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced\nAudio Text Evaluation). This metric penalizes generic terms and rewards\ndetailed descriptions by combining single-sample semantic similarity with\ncross-sample discriminability. A comprehensive evaluation of state-of-the-art\naudio models is also presented, providing new insights into their current\ncapabilities and limitations. The data and code are available at\nhttps://github.com/xiaomi-research/mecat"}
{"id": "2507.23266", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2507.23266", "abs": "https://arxiv.org/abs/2507.23266", "authors": ["Aemon Yat Fei Chiu", "Jingyu Li", "Yusheng Tian", "Guangyan Zhang", "Tan Lee"], "title": "CUHK-EE Systems for the vTAD Challenge at NCMMSC 2025", "comment": "Under review", "summary": "This paper presents the Voice Timbre Attribute Detection (vTAD) systems\ndeveloped by the Digital Signal Processing & Speech Technology Laboratory\n(DSP&STL) of the Department of Electronic Engineering (EE) at The Chinese\nUniversity of Hong Kong (CUHK) for the 20th National Conference on\nHuman-Computer Speech Communication (NCMMSC 2025) vTAD Challenge. The proposed\nsystems leverage WavLM-Large embeddings with attentive statistical pooling to\nextract robust speaker representations, followed by two variants of Diff-Net,\ni.e., Feed-Forward Neural Network (FFN) and Squeeze-and-Excitation-enhanced\nResidual FFN (SE-ResFFN), to compare timbre attribute intensities between\nutterance pairs. Experimental results demonstrate that the WavLM-Large+FFN\nsystem generalises better to unseen speakers, achieving 77.96% accuracy and\n21.79% EER, while the WavLM-Large+SE-ResFFN model excels in the 'Seen' setting\nwith 94.42% accuracy and 5.49% EER. These findings highlight a trade-off\nbetween model complexity and generalisation, and underscore the importance of\narchitectural choices in fine-grained speaker modelling. Our analysis also\nreveals the impact of speaker identity, annotation subjectivity, and data\nimbalance on system performance, pointing to future directions for improving\nrobustness and fairness in timbre attribute detection."}
{"id": "2507.23235", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23235", "abs": "https://arxiv.org/abs/2507.23235", "authors": ["Mohammad Roueinfar", "Masoud Ardini"], "title": "In-Orbit Cosmo-SkyMed antenna pattern estimation by a narrowband sweeper receiver", "comment": null, "summary": "This paper introduces a novel method for antenna pattern estimation in\nsatellites equipped with Synthetic Aperture Radar (SAR), utilizing a Narrowband\nSweeper Receiver (NSR). By accurately measuring power across individual\nfrequencies within SAR's inherently broadband spectrum, the NSR significantly\nenhances antenna pattern extraction accuracy. Analytical models and practical\nexperiments conducted using the Cosmo-SkyMed satellite validate the receiver's\nperformance, demonstrating superior signal-to-noise ratio (SNR) compared to\nconventional receivers. This research represents a key advancement in SAR\ntechnology, offering a robust framework for future satellite calibration and\nverification methodologies."}
{"id": "2507.23511", "categories": ["eess.AS", "cs.AI", "cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2507.23511", "abs": "https://arxiv.org/abs/2507.23511", "authors": ["Yadong Niu", "Tianzi Wang", "Heinrich Dinkel", "Xingwei Sun", "Jiahao Zhou", "Gang Li", "Jizhong Liu", "Xunying Liu", "Junbo Zhang", "Jian Luan"], "title": "MECAT: A Multi-Experts Constructed Benchmark for Fine-Grained Audio Understanding Tasks", "comment": "9 main pages, 5 figures, 3 tables, and 14 appendix pages", "summary": "While large audio-language models have advanced open-ended audio\nunderstanding, they still fall short of nuanced human-level comprehension. This\ngap persists largely because current benchmarks, limited by data annotations\nand evaluation metrics, fail to reliably distinguish between generic and highly\ndetailed model outputs. To this end, this work introduces MECAT, a Multi-Expert\nConstructed Benchmark for Fine-Grained Audio Understanding Tasks. Generated via\na pipeline that integrates analysis from specialized expert models with\nChain-of-Thought large language model reasoning, MECAT provides\nmulti-perspective, fine-grained captions and open-set question-answering pairs.\nThe benchmark is complemented by a novel metric: DATE (Discriminative-Enhanced\nAudio Text Evaluation). This metric penalizes generic terms and rewards\ndetailed descriptions by combining single-sample semantic similarity with\ncross-sample discriminability. A comprehensive evaluation of state-of-the-art\naudio models is also presented, providing new insights into their current\ncapabilities and limitations. The data and code are available at\nhttps://github.com/xiaomi-research/mecat"}
{"id": "2507.23236", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2507.23236", "abs": "https://arxiv.org/abs/2507.23236", "authors": ["Zhuoyin Dai", "Di Wu", "Yong Zeng", "Xiaoli Xu", "Xinyi Wang", "Zesong Fei"], "title": "BS-1-to-N: Diffusion-Based Environment-Aware Cross-BS Channel Knowledge Map Generation for Cell-Free Networks", "comment": null, "summary": "Channel knowledge map (CKM) inference across base stations (BSs) is the key\nto achieving efficient environmentaware communications. This paper proposes an\nenvironmentaware cross-BS CKM inference method called BS-1-to-N based on the\ngenerative diffusion model. To this end, we first design the BS location\nembedding (BSLE) method tailored for cross-BS CKM inference to embed BS\nlocation information in the feature vector of CKM. Further, we utilize the\ncross- and self-attention mechanism for the proposed BS-1-to-N model to\nrespectively learn the relationships between source and target BSs, as well as\nthat among target BSs. Therefore, given the locations of the source and target\nBSs, together with the source CKMs as control conditions, cross-BS CKM\ninference can be performed for an arbitrary number of source and target BSs.\nSpecifically, in architectures with massive distributed nodes like cell-free\nnetworks, traditional methods of sequentially traversing each BS for CKM\nconstruction are prohibitively costly. By contrast, the proposed BS-1-to-N\nmodel is able to achieve efficient CKM inference for a target BS at any\npotential location based on the CKMs of source BSs. This is achieved by\nexploiting the fact that within a given area, different BSs share the same\nwireless environment that leads to their respective CKMs. Therefore, similar to\nmulti-view synthesis, CKMs of different BSs are representations of the same\nwireless environment from different BS locations. By mining the implicit\ncorrelation between CKM and BS location based on the wireless environment, the\nproposed BS-1-to-N method achieves efficient CKM inference across BSs. We\nprovide extensive comparisons of CKM inference between the proposed BS-1-to-N\ngenerative model versus benchmarking schemes, and provide one use case study to\ndemonstrate its practical application for the optimization of BS deployment."}
{"id": "2507.23365", "categories": ["cs.SD", "cs.AI", "eess.AS", "I.2; J.5"], "pdf": "https://arxiv.org/pdf/2507.23365", "abs": "https://arxiv.org/abs/2507.23365", "authors": ["Bob L. T. Sturm"], "title": "\"I made this (sort of)\": Negotiating authorship, confronting fraudulence, and exploring new musical spaces with prompt-based AI music generation", "comment": null, "summary": "I reflect on my experience creating two music albums centered on\nstate-of-the-art prompt-based AI music generation platforms. The first album\nexplicitly poses the question: What happens when I collide my junk mail with\nthese platforms? The second album is a direct response to the first, and toys\nwith the inability of state-of-the-art prompt-based AI music generation\nplatforms to generate music that is not ``practiced'', ``polished'', and\n``produced''. I seed a large language model (LLM) with information about these\nalbums and have it interview me, which results in the exploration of several\ndeeper questions: To what extent am I the author? Where am I in the resulting\nmusic? How is my musical identity changing as I am faced with machines that are\nin some ways far more talented than I? What new musical spaces does my work\nopen, for me or anyone/thing else? I conclude by reflecting on my reflections,\nas well as LLM-mediated self-reflection as method."}
{"id": "2507.23381", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23381", "abs": "https://arxiv.org/abs/2507.23381", "authors": ["Ziang Liu", "Bruno Clerckx"], "title": "A Secure Full-Duplex Wireless Circulator enabled by Non-Reciprocal Beyond-Diagonal RIS", "comment": "Submitted for IEEE journal", "summary": "Beyond-diagonal reconfigurable intelligent surface (BD-RIS) has arisen as a\npromising technology for enhancing wireless communication systems by enabling\nflexible and intelligent wave manipulation. This is achieved through the\ninterconnections among the ports of the impedance network, enabling wave\nreconfiguration when they flow through the surface. Thus, the output wave at\none port depends on waves impinging on neighboring ports, allowing non-local\ncontrol of both phase and magnitude. Non-reciprocal (NR)-BD-RIS further\nenhances this capability by breaking circuit reciprocity and, consequently,\nchannel reciprocity. This feature potentially benefits communication among\nnon-aligned transceivers. This paper introduces a novel application of\nNR-BD-RIS in full-duplex (FD) wireless circulators, where multiple FD devices\ncommunicate via an NR-BD-RIS. This system is particularly beneficial for secure\ntransmission, as it enforces one-way communication among FD devices, suppresses\nsignal from all other users, and thus prevents eavesdropping. In addition, a\nphysics-compliant system model is considered by incorporating structural\nscattering, also known as specular reflection. By accounting for this effect,\nthe advantages of NR-BD-RIS are further validated. Specifically, we formulate\nan all-user sum-rate maximization problem and propose an iterative optimization\nalgorithm that employs block coordinate descent (BCD) and penalty dual\ndecomposition (PDD) methods. Numerical evaluations illustrate that NR-BD-RIS\nconsistently outperforms reciprocal (R)-BD-RIS and conventional diagonal\n(D)-RIS in terms of sum-rate performance, particularly when more than two\nimpinging and reflection directions need to be supported. By analyzing the\npower of signals from all other users and the beampatterns, we show that secure\ntransmission can be achieved."}
{"id": "2507.23590", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2507.23590", "abs": "https://arxiv.org/abs/2507.23590", "authors": ["Jack Collins", "Adrian Buzea", "Chris Collier", "Alejandro Ballesta Rosen", "Julian Maclaren", "Richard F. Lyon", "Simon Carlile"], "title": "Identifying Hearing Difficulty Moments in Conversational Audio", "comment": null, "summary": "Individuals regularly experience Hearing Difficulty Moments in everyday\nconversation. Identifying these moments of hearing difficulty has particular\nsignificance in the field of hearing assistive technology where timely\ninterventions are key for realtime hearing assistance. In this paper, we\npropose and compare machine learning solutions for continuously detecting\nutterances that identify these specific moments in conversational audio. We\nshow that audio language models, through their multimodal reasoning\ncapabilities, excel at this task, significantly outperforming a simple ASR\nhotword heuristic and a more conventional fine-tuning approach with Wav2Vec, an\naudio-only input architecture that is state-of-the-art for automatic speech\nrecognition (ASR)."}
{"id": "2507.23518", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23518", "abs": "https://arxiv.org/abs/2507.23518", "authors": ["Joel Poncha Lemayian", "Hachem Bensalem", "Ghyslain Gagnon", "Kaiwen Zhang", "Pascal Giard"], "title": "EVMx: An FPGA-Based Smart Contract Processing Unit", "comment": "6 pages", "summary": "Ethereum blockchain uses smart contracts (SCs) to implement decentralized\napplications (dApps). SCs are executed by the Ethereum virtual machine (EVM)\nrunning within an Ethereum client. Moreover, the EVM has been widely adopted by\nother blockchain platforms, including Solana, Cardano, Avalanche, Polkadot, and\nmore. However, the EVM performance is limited by the constraints of the\ngeneral-purpose computer it operates on. This work proposes offloading SC\nexecution onto a dedicated hardware-based EVM. Specifically, EVMx is an\nFPGA-based SC execution engine that benefits from the inherent parallelism and\nhigh-speed processing capabilities of a hardware architecture. Synthesis\nresults demonstrate a reduction in execution time of 61% to 99% for commonly\nused operation codes compared to CPU-based SC execution environments. Moreover,\nthe execution time of Ethereum blocks on EVMx is up to 6x faster compared to\nanalogous works in the literature. These results highlight the potential of the\nproposed architecture to accelerate SC execution and enhance the performance of\nEVM-compatible blockchains."}
{"id": "2507.23526", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.23526", "abs": "https://arxiv.org/abs/2507.23526", "authors": ["Wen-Xuan Long", "Shengyu Ye", "Marco Moretti", "Michele Morelli", "Luca Sanguinetti", "Rui Chen", "Cheng-Xiang Wang"], "title": "Channel Estimation for 6G Near-Field Wireless Communications: A Comprehensive Survey", "comment": null, "summary": "The sixth-generation (6G) wireless systems are expected to adopt extremely\nlarge aperture arrays (ELAAs), novel antenna architectures, and operate in\nextremely high-frequency bands to meet growing data demands. ELAAs\nsignificantly increase the number of antennas, enabling finer spatial\nresolution and improved beamforming. At high frequencies, ELAAs shift\ncommunication from the conventional far-field to near-field regime, where\nspherical wavefronts dominate and the channel response depends on both angle\nand distance, increasing channel dimensionality. Conventional far-field channel\nestimation methods, which rely on angular information, struggle in near-field\nscenarios due to increased pilot overhead and computational complexity. This\npaper presents a comprehensive survey of recent advances in near-field channel\nestimation. It first defines the near- and far-field boundary from an\nelectromagnetic perspective and discusses key propagation differences,\nalongside a brief review of ELAA developments. Then, it introduces mainstream\nnear-field channel models and compares them with far-field models. Major\nestimation techniques are reviewed under different configurations\n(single/multi-user, single/multi-carrier), including both direct estimation and\nRIS-assisted cascaded estimation. These techniques reveal trade-offs among\nestimation accuracy, complexity, and overhead. This survey aims to provide\ninsights and foundations for efficient and scalable near-field channel\nestimation in 6G systems, while identifying key challenges and future research\ndirections."}
{"id": "2507.23570", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23570", "abs": "https://arxiv.org/abs/2507.23570", "authors": ["Manjun Cui", "Zhichao Zhang", "Wei Yao"], "title": "Multiple-Parameter Graph Fractional Fourier Transform: Theory and Applications", "comment": null, "summary": "The graph fractional Fourier transform (GFRFT) applies a single global\nfractional order to all graph frequencies, which restricts its adaptability to\ndiverse signal characteristics across the spectral domain. To address this\nlimitation, in this paper, we propose two types of multiple-parameter GFRFTs\n(MPGFRFTs) and establish their corresponding theoretical frameworks. We design\na spectral compression strategy tailored for ultra-low compression ratios,\neffectively preserving essential information even under extreme dimensionality\nreduction. To enhance flexibility, we introduce a learnable order vector scheme\nthat enables adaptive compression and denoising, demonstrating strong\nperformance on both graph signals and images. We explore the application of\nMPGFRFTs to image encryption and decryption. Experimental results validate the\nversatility and superior performance of the proposed MPGFRFT framework across\nvarious graph signal processing tasks."}
{"id": "2507.23695", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23695", "abs": "https://arxiv.org/abs/2507.23695", "authors": ["Mouli Chakraborty", "Subhash Chandra", "Avishek Nag", "Anshu Mukherjee"], "title": "On the Achievable Rate of Satellite Quantum Communication Channel using Deep Autoencoder Gaussian Mixture Model", "comment": null, "summary": "We present a comparative study of the Gaussian mixture model (GMM) and the\nDeep Autoencoder Gaussian Mixture Model (DAGMM) for estimating satellite\nquantum channel capacity, considering hybrid quantum noise (HQN) and\ntransmission constraints. While GMM is simple and interpretable, DAGMM better\ncaptures non-linear variations and noise distributions. Simulations show that\nDAGMM provides tighter capacity bounds and improved clustering. This introduces\nthe Deep Cluster Gaussian Mixture Model (DCGMM) for high-dimensional quantum\ndata analysis in quantum satellite communication."}
{"id": "2507.23707", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2507.23707", "abs": "https://arxiv.org/abs/2507.23707", "authors": ["Renato Luis Garrido Cavalcante", "Tomasz Piotrowski", "Slawomir Stanczak"], "title": "Cellular, Cell-less, and Everything in Between: A Unified Framework for Utility Region Analysis in Wireless Networks", "comment": null, "summary": "We introduce a unified framework for analyzing utility regions of wireless\nnetworks, with a focus on the signal-to-interference-noise-ratio (SINR) and\nachievable rate regions. The framework provides valuable insights into\ninterference patterns of modern network architectures, such as cell-less and\nextremely large MIMO networks, and it generalizes existing characterizations of\nthe weak Pareto boundary. A central contribution is the derivation of\nsufficient conditions that guarantee convexity of the utility regions.\nConvexity is an important property because it ensures that time sharing (or\nuser grouping) cannot simultaneously increase the utility of all users when the\nnetwork operates on the weak Pareto boundary. These sufficient conditions also\nhave two key implications. First, they identify a family of (weighted) sum-rate\nmaximization problems that are inherently convex without any variable\ntransformations, thus paving the way for the development of efficient, provably\noptimal solvers for this family. Second, they provide a rigorous justification\nfor formulating sum-rate maximization problems directly in terms of achievable\nrates, rather than SINR levels. Our theoretical insights also motivate an\nalternative to the concept of favorable propagation in the massive MIMO\nliterature -- one that explicitly accounts for self-interference and the\nbeamforming strategy."}
{"id": "2507.23746", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2507.23746", "abs": "https://arxiv.org/abs/2507.23746", "authors": ["Hossein Kazemi", "Isaac N. O. Osahon", "Tiankuo Jiao", "David Butler", "Nikolay Ledentsov Jr.", "Ilya Titkov", "Nikolay Ledentsov", "Harald Haas"], "title": "Real-Time Transmission of Uncompressed High-Definition Video Via A VCSEL-Based Optical Wireless Link With Ultra-Low Latency", "comment": "8 pages, 6 figures, 2 tables", "summary": "Real-time transmission of high-resolution video signals in an uncompressed\nand unencrypted format requires an ultra-reliable and low-latency\ncommunications (URLLC) medium with high bandwidth to maintain the quality of\nexperience (QoE) for users. We put forward the design and experimental\ndemonstration of a high-performance laser-based optical wireless communication\n(OWC) system that enables high-definition (HD) video transmission with\nsubmillisecond latencies. The serial digital interface (SDI) output of a camera\nis used to transmit the live video stream over an optical wireless link by\ndirectly modulating the SDI signal on the intensity of a 940 nm vertical cavity\nsurface emitting laser (VCSEL). The proposed SDI over light fidelity (LiFi)\nsystem corroborates error-free transmission of full HD (FHD) and 4K\nultra-high-definition (UHD) resolutions at data rates of 2.97 Gb/s and 5.94\nGb/s, respectively, with a measured end-to-end latency of under 35 ns. Since\nSDI standards support various video formats and VCSELs are high-bandwidth and\nlow-power devices, this presents a scalable and inexpensive solution for\nwireless connectivity between professional broadcast equipment using\noff-the-shelf SDI components."}
{"id": "2507.22964", "categories": ["eess.AS", "cs.CL", "cs.SD", "eess.SP"], "pdf": "https://arxiv.org/pdf/2507.22964", "abs": "https://arxiv.org/abs/2507.22964", "authors": ["Sotheara Leang", "Éric Castelli", "Dominique Vaufreydaz", "Sethserey Sam"], "title": "Exploring Dynamic Parameters for Vietnamese Gender-Independent ASR", "comment": null, "summary": "The dynamic characteristics of speech signal provides temporal information\nand play an important role in enhancing Automatic Speech Recognition (ASR). In\nthis work, we characterized the acoustic transitions in a ratio plane of\nSpectral Subband Centroid Frequencies (SSCFs) using polar parameters to capture\nthe dynamic characteristics of the speech and minimize spectral variation.\nThese dynamic parameters were combined with Mel-Frequency Cepstral Coefficients\n(MFCCs) in Vietnamese ASR to capture more detailed spectral information. The\nSSCF0 was used as a pseudo-feature for the fundamental frequency (F0) to\ndescribe the tonal information robustly. The findings showed that the proposed\nparameters significantly reduce word error rates and exhibit greater gender\nindependence than the baseline MFCCs."}

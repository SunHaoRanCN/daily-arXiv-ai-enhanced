<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 28]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SD](#cs.SD) [Total: 8]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [An AI-driven EDA Algorithm-Empowered VCO and LDO Co-Design Method](https://arxiv.org/abs/2508.02687)
*Yijia Hao,Maarten Strackx,Miguel Gandara,Sandy Cochran,Bo Liu*

Main category: eess.SP

TL;DR: 论文提出了一种AI驱动的EDA算法，用于LDO供电的LC-tank VCO的协同设计，以解决传统方法中高频和低频相位噪声的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统设计方法未能完全解决高频和LDO引起的低频相位噪声之间的权衡问题。

Method: 采用AI驱动的EDA算法进行LDO和LC-tank VCO的协同设计。

Result: 在65 nm CMOS工艺下设计的5.6 GHz LC-tank VCO，相位噪声改善1.2 dB，动态功耗降低28.8%，FoM提升2.4 dBc/Hz。

Conclusion: 协同设计方法显著优于传统顺序设计方法。

Abstract: Traditionally, the output noise and power supply rejection of low-dropout
regulators (LDOs) are optimized to minimize power supply fluctuations, reducing
their impact on the low-frequency noise of target voltage-controlled
oscillators (VCOs). However, this sequential design approach does not fully
address the trade-offs between high-frequency and LDO-induced low-frequency
phase noise. To overcome this limitation, this paper presents a co-design
method for low phase-noise LC-tank VCOs powered by LDOs. It is difficult to
carry out the co-design using traditional manual design techniques. Hence, an
efficient AI-driven EDA algorithm is used. To validate the proposed method, a
5.6 GHz LC-tank VCO with an integrated LDO is designed using a 65 nm CMOS
process. Simulations show that the co-design method improves phase noise by 1.2
dB at a 1 MHz offset and reduces dynamic power consumption by 28.8%, with FoM
increased by 2.4 dBc/Hz compared to the conventional sequential design method.

</details>


### [2] [On Improving PPG-Based Sleep Staging: A Pilot Study](https://arxiv.org/abs/2508.02689)
*Jiawei Wang,Yu Guan,Chen Chen,Ligang Zhou,Laurence T. Yang,Sai Gu*

Main category: eess.SP

TL;DR: 研究通过双流交叉注意力架构结合PPG及其辅助信息，显著提升了基于PPG的睡眠分期性能。


<details>
  <summary>Details</summary>
Motivation: 尽管PPG传感器在消费设备中广泛应用，但仅依赖PPG实现可靠的睡眠分期仍具挑战性。

Method: 比较单流模型与双流交叉注意力策略，利用PPG及其衍生模态（如增强PPG或合成ECG）学习互补信息。

Result: 在MESA数据集上的实验表明，双流架构结合辅助信息可显著提升性能。

Conclusion: 双流交叉注意力架构是提升PPG睡眠分期性能的有效方法。

Abstract: Sleep monitoring through accessible wearable technology is crucial to
improving well-being in ubiquitous computing. Although
photoplethysmography(PPG) sensors are widely adopted in consumer devices,
achieving consistently reliable sleep staging using PPG alone remains a
non-trivial challenge. In this work, we explore multiple strategies to enhance
the performance of PPG-based sleep staging. Specifically, we compare
conventional single-stream model with dual-stream cross-attention strategies,
based on which complementary information can be learned via PPG and PPG-derived
modalities such as augmented PPG or synthetic ECG. To study the effectiveness
of the aforementioned approaches in four-stage sleep monitoring task, we
conducted experiments on the world's largest sleep staging dataset, i.e., the
Multi-Ethnic Study of Atherosclerosis(MESA). We found that substantial
performance gain can be achieved by combining PPG and its auxiliary information
under the dual-stream cross-attention architecture. Source code of this project
can be found at https://github.com/DavyWJW/sleep-staging-models

</details>


### [3] [Federated Learning in Active STARS-Aided Uplink Networks](https://arxiv.org/abs/2508.02693)
*Xinwei Yue,Xinning Guo,Xidong Mu,Jingjing Zhao,Peng Yang,Junsheng Mu,Zhiping Lu*

Main category: eess.SP

TL;DR: ASTARS辅助的联邦学习（FL）上行链路模型传输，通过OTA计算技术减少上传参数数量，提升学习效率和信号传输质量。


<details>
  <summary>Details</summary>
Motivation: 利用ASTARS缓解多径衰落并重塑电磁环境，以提升FL上行链路模型的传输效率和准确性。

Method: 结合OTA计算技术，优化接收波束分配和ASTARS相位调整，以减少模型聚合误差。

Result: ASTARS辅助的FL网络在准确性上优于现有网络，且使用更少的激活单元；高放大功率提升准确性，但过度放大会导致热噪声主导误差。

Conclusion: ASTARS显著提升FL性能，尤其在离散数据集上表现更优，但需平衡放大功率以避免噪声干扰。

Abstract: Active simultaneously transmitting and reflecting surfaces (ASTARS) have
attracted growing research interest due to its ability to alleviate
multiplicative fading and reshape the electromagnetic environment across the
entire space. In this paper, we utilise ASTARS to assist the federated learning
(FL) uplink model transfer and further reduce the number of uploaded parameter
counts through over-the-air (OTA) computing techniques. The impact of model
aggregation errors on ASTARS-aided FL uplink networks is characterized. We
derive an upper bound on the aggregation error of the OTA-FL model and quantify
the training loss due to communication errors. Then, we define the performance
of OTA-FL as a joint optimization problem that encompasses both the assignment
of received beams and the phase shifting of ASTARS, aiming to achieve the
maximum learning efficiency and high-quality signal transmission. Numerical
results demonstrate that: i) The FL accuracy in ASTARS uplink networks are
enhanced compared to that in state-of-the-art networks; ii) The ASTARS enabled
FL system achieves the better learning accuracy using fewer active units than
other baseline, especially when the dataset is more discrete; and iii) FL
accuracy improves with higher amplification power, but excessive amplification
makes thermal noise the dominant source of error.

</details>


### [4] [A Completely Blind Channel Estimation Technique for OFDM Using Constellation Splitting](https://arxiv.org/abs/2508.02698)
*Sameera Bharadwaja H.,D. K. Mehra*

Main category: eess.SP

TL;DR: 提出了一种基于频域线性非冗余预编码和子载波星座分裂的盲信道估计算法，解决了OFDM系统中二阶统计量方法的复标量模糊问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于二阶统计量的盲信道估计算法中存在的复标量模糊问题，避免使用导频或参考符号。

Method: 采用频域线性非冗余预编码和子载波星座分裂技术，设计了一种盲估计算法。

Result: 数值仿真表明，该算法在M进制PAM系统中的性能与半盲方法相当。

Conclusion: 所提算法有效解决了复标量模糊问题，且性能接近半盲方法，适用于盲信道估计。

Abstract: The problem of second-order statistics (SOS)-based blind channel estimation
in OFDM systems is addressed in this paper. Almost all SOS-based methods
proposed so far suffer from a complex-scalar estimation ambiguity, which is
resolved by using pilots or reference symbols. We propose an algorithm to
resolve this ambiguity in blind manner using frequency-domain linear
non-redundant precoding and constellation-splitting among the alternate
subcarriers. The performance of the proposed scheme is evaluated via numerical
simulations in MATLAB environment. Simulation results show that the proposed
approach performs as good as its semi-blind counterpart for M-ary PAM systems.

</details>


### [5] [Measuring Dependencies between Biological Signals with Temporal Self-supervision, and its Limitations](https://arxiv.org/abs/2508.02703)
*Evangelos Sariyanidi,John D. Herrington,Lisa Yankowitz,Pratik Chaudhari,Theodore D. Satterthwaite,Casey J. Zampella,Robert T. Schultz,Russell T. Shinohara,Birkan Tunc*

Main category: eess.SP

TL;DR: 提出了一种名为“concurrence”的自监督方法，用于测量信号间的统计依赖性，无需先验知识，适用于多种信号类型。


<details>
  <summary>Details</summary>
Motivation: 生物系统中复杂的非线性交互难以捕捉，现有方法依赖先验知识。

Method: 基于信号间时间对齐与不对齐段的区分能力，设计自监督方法“concurrence”。

Result: 实验表明，该方法能广泛揭示信号间关系，无需参数调整或先验信息。

Conclusion: concurrence是科学发现的强大工具，但需验证依赖关系是否与研究问题相关。

Abstract: Measuring the statistical dependence between observed signals is a primary
tool for scientific discovery. However, biological systems often exhibit
complex non-linear interactions that currently cannot be captured without a
priori knowledge regarding the nature of dependence. We introduce a
self-supervised approach, concurrence, which is inspired by the observation
that if two signals are dependent, then one should be able to distinguish
between temporally aligned vs. misaligned segments extracted from them.
Experiments with fMRI, physiological and behavioral signals show that, to our
knowledge, concurrence is the first approach that can expose relationships
across such a wide spectrum of signals and extract scientifically relevant
differences without ad-hoc parameter tuning or reliance on a priori
information, providing a potent tool for scientific discoveries across fields.
However, depencencies caused by extraneous factors remain an open problem, thus
researchers should validate that exposed relationships truely pertain to the
question(s) of interest.

</details>


### [6] [Evaluation of Deep Learning Models for LBBB Classification in ECG Signals](https://arxiv.org/abs/2508.02710)
*Beatriz Macas Ordóñez,Diego Vinicio Orellana Villavicencio,José Manuel Ferrández,Paula Bonomini*

Main category: eess.SP

TL;DR: 研究比较不同神经网络架构对ECG信号时空模式的提取能力，用于分类健康、LBBB和sLBBB。


<details>
  <summary>Details</summary>
Motivation: 通过创新技术优化LBBB分类，为心脏再同步治疗（CRT）候选者选择提供支持。

Method: 探索不同神经网络架构，提取ECG信号的时空模式并进行分类。

Result: 未明确提及具体结果。

Conclusion: 研究有助于改进CRT候选者的分类方法。

Abstract: This study explores different neural network architectures to evaluate their
ability to extract spatial and temporal patterns from electrocardiographic
(ECG) signals and classify them into three groups: healthy subjects, Left
Bundle Branch Block (LBBB), and Strict Left Bundle Branch Block (sLBBB).
  Clinical Relevance, Innovative technologies enable the selection of
candidates for Cardiac Resynchronization Therapy (CRT) by optimizing the
classification of subjects with Left Bundle Branch Block (LBBB).

</details>


### [7] [Physics-guided denoiser network for enhanced additive manufacturing data quality](https://arxiv.org/abs/2508.02712)
*Pallock Halder,Satyajit Mojumder*

Main category: eess.SP

TL;DR: 提出了一种基于物理信息的去噪框架，结合能量模型和Fisher分数正则化，用于减少传感器数据噪声并保持物理一致性。


<details>
  <summary>Details</summary>
Motivation: 现代工程系统中的传感器数据常因噪声和难以解释而限制了其控制和诊断的实用性。

Method: 提出了一种物理信息去噪框架，结合能量模型和Fisher分数正则化，并在基准问题和实际LPBF实验数据上验证。

Result: 该方法在多种噪声水平下优于基线神经网络去噪器，能有效减少LPBF工艺中的噪声。

Conclusion: 该物理引导的去噪策略能够实时解释低成本传感器数据，提升增材制造中的预测控制和缺陷缓解。

Abstract: Modern engineering systems are increasingly equipped with sensors for
real-time monitoring and decision-making. However, the data collected by these
sensors is often noisy and difficult to interpret, limiting its utility for
control and diagnostics. In this work, we propose a physics-informed denoising
framework that integrates energy-based model and Fisher score regularization to
jointly reduce data noise and enforce physical consistency with a physics-based
model. The approach is first validated on benchmark problems, including the
simple harmonic oscillator, Burgers' equation, and Laplace's equation, across
varying noise levels. We then apply the denoising framework to real thermal
emission data from laser powder bed fusion (LPBF) additive manufacturing
experiments, using a trained Physics-Informed Neural Network (PINN) surrogate
model of the LPBF process to guide denoising. Results show that the proposed
method outperforms baseline neural network denoisers, effectively reducing
noise under a range of LPBF processing conditions. This physics-guided
denoising strategy enables robust, real-time interpretation of low-cost sensor
data, facilitating predictive control and improved defect mitigation in
additive manufacturing.

</details>


### [8] [Precoder Design for User-Centric Network Massive MIMO: A Symplectic Optimization Approach](https://arxiv.org/abs/2508.02713)
*Pengxu Lin,An-An Lu,Xiqi Gao*

Main category: eess.SP

TL;DR: 论文提出了一种基于辛优化的预编码器设计方法，用于用户中心网络（UCN）大规模MIMO系统，避免了传统线性预编码中的矩阵求逆，提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 在UCN大规模MIMO系统中，传统线性预编码的矩阵求逆计算复杂度高，需要一种更高效的方法来设计预编码器。

Method: 利用辛优化框架，将接收模型转换到实数域，并将加权和速率（WSR）最大化问题重新表述为动力学系统的势能最小化问题，通过离散化连续系统获得迭代方法。

Result: 仿真结果表明，基于辛优化的预编码器设计在UCN大规模MIMO系统中优于加权最小均方误差（WMMSE）预编码器。

Conclusion: 辛优化方法在降低计算复杂度的同时，显著提升了系统性能。

Abstract: In this paper, we utilize symplectic optimization to design a precoder for
user-centric network (UCN) massive multiple-input multiple-output (MIMO)
systems, where a subset of base stations (BSs) serves each user terminal (UT)
instead of using all BSs. In UCN massive MIMO systems, the dimension of the
precoders is reduced compared to conventional network massive MIMO. It
simplifies the implementation of precoders in practical systems. However, the
matrix inversion in traditional linear precoders still requires high
computational complexity. To avoid the matrix inversion, we employ the
symplectic optimization framework, where optimization problems are solved based
on dissipative Hamiltonian dynamical systems. To better fit symplectic
optimization, we transform the received model into the real field and
reformulate the weighted sum-rate (WSR) maximization problem. The objective
function of the optimization problem is viewed as the potential energy of the
dynamical system. Due to energy dissipation, the continuous dynamical system
always converges to a state with minimal potential energy. By discretizing the
continuous system while preserving the symplectic structure, we obtain an
iterative method for the precoder design. The complexity analysis of the
proposed symplectic method is also provided to show its high computational
efficiency. Simulation results demonstrate that the proposed precoder design
based on symplectic optimization outperforms the weighted minimum mean-square
error (WMMSE) precoder in the UCN massive MIMO system.

</details>


### [9] [SleepLiteCNN: Energy-Efficient Sleep Apnea Subtype Classification with 1-Second Resolution Using Single-Lead ECG](https://arxiv.org/abs/2508.02718)
*Zahra Mohammadi,Siamak Mohammadi*

Main category: eess.SP

TL;DR: 提出了一种基于单导联心电图的高效睡眠呼吸暂停亚型分类方法，适用于可穿戴设备。


<details>
  <summary>Details</summary>
Motivation: 睡眠呼吸暂停亚型的准确、高时间分辨率检测对治疗和管理至关重要。

Method: 评估多种机器学习和深度学习算法，提出紧凑且节能的卷积神经网络SleepLiteCNN。

Result: SleepLiteCNN准确率超95%，宏F1分数92%，每次推理仅需1.8微焦耳。

Conclusion: SleepLiteCNN适合能源受限环境中的实时监测，是一种实用有效的解决方案。

Abstract: Apnea is a common sleep disorder characterized by breathing interruptions
lasting at least ten seconds and occurring more than five times per hour.
Accurate, high-temporal-resolution detection of sleep apnea subtypes -
Obstructive, Central, and Mixed - is crucial for effective treatment and
management. This paper presents an energy-efficient method for classifying
these subtypes using a single-lead electrocardiogram (ECG) with high temporal
resolution to address the real-time needs of wearable devices. We evaluate a
wide range of classical machine learning algorithms and deep learning
architectures on 1-second ECG windows, comparing their accuracy, complexity,
and energy consumption. Based on this analysis, we introduce SleepLiteCNN, a
compact and energy-efficient convolutional neural network specifically designed
for wearable platforms. SleepLiteCNN achieves over 95% accuracy and a 92%
macro-F1 score, while requiring just 1.8 microjoules per inference after 8-bit
quantization. Field Programmable Gate Array (FPGA) synthesis further
demonstrates significant reductions in hardware resource usage, confirming its
suitability for continuous, real-time monitoring in energy-constrained
environments. These results establish SleepLiteCNN as a practical and effective
solution for wearable device sleep apnea subtype detection.

</details>


### [10] [Veli: Unsupervised Method and Unified Benchmark for Low-Cost Air Quality Sensor Correction](https://arxiv.org/abs/2508.02724)
*Yahia Dalbah,Marcel Worring,Yen-Chia Hsu*

Main category: eess.SP

TL;DR: Veli是一种无监督贝叶斯模型，通过变分推理校正低成本传感器的读数，无需参考站，解决了部署障碍。


<details>
  <summary>Details</summary>
Motivation: 城市空气污染是重大健康危机，需要准确且可扩展的空气质量监测方法。低成本传感器受漂移、校准误差和环境干扰影响。

Method: Veli利用变分推理构建解耦表示，分离真实污染物读数和传感器噪声。同时引入AQ-SDR作为标准化基准。

Result: Veli在分布内外均表现良好，有效处理传感器漂移和异常行为。AQ-SDR是最大的空气质量传感器基准。

Conclusion: Veli为低成本传感器提供了一种无需参考站的校正方法，解决了部署难题，同时AQ-SDR为研究提供了标准化数据。

Abstract: Urban air pollution is a major health crisis causing millions of premature
deaths annually, underscoring the urgent need for accurate and scalable
monitoring of air quality (AQ). While low-cost sensors (LCS) offer a scalable
alternative to expensive reference-grade stations, their readings are affected
by drift, calibration errors, and environmental interference. To address these
challenges, we introduce Veli (Reference-free Variational Estimation via Latent
Inference), an unsupervised Bayesian model that leverages variational inference
to correct LCS readings without requiring co-location with reference stations,
eliminating a major deployment barrier. Specifically, Veli constructs a
disentangled representation of the LCS readings, effectively separating the
true pollutant reading from the sensor noise. To build our model and address
the lack of standardized benchmarks in AQ monitoring, we also introduce the Air
Quality Sensor Data Repository (AQ-SDR). AQ-SDR is the largest AQ sensor
benchmark to date, with readings from 23,737 LCS and reference stations across
multiple regions. Veli demonstrates strong generalization across both
in-distribution and out-of-distribution settings, effectively handling sensor
drift and erratic sensor behavior. Code for model and dataset will be made
public when this paper is published.

</details>


### [11] [SpectrumFM: A New Paradigm for Spectrum Cognition](https://arxiv.org/abs/2508.02742)
*Chunyu Liu,Hao Zhang,Wei Wu,Fuhui Zhou,Qihui Wu,Derrick Wing Kwan Ng,Chan-Byoung Chae*

Main category: eess.SP

TL;DR: 提出了一种名为SpectrumFM的频谱基础模型，通过创新的频谱编码器和自监督学习任务提升频谱认知的泛化能力和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有频谱认知方法在多样化的频谱环境和任务中泛化能力有限且准确性不足，亟需一种更高效的解决方案。

Method: 结合卷积神经网络和多头自注意力机制的频谱编码器，以及掩码重建和下一时隙信号预测的自监督学习任务，采用LoRA参数高效微调。

Result: 在频谱感知、异常检测和无线技术分类任务中显著优于现有方法，检测概率提升30%，AUC提升10%，准确率提升9.6%。

Conclusion: SpectrumFM为频谱认知提供了高效且泛化能力强的解决方案，适用于多种下游任务。

Abstract: The enhancement of spectrum efficiency and the realization of secure spectrum
utilization are critically dependent on spectrum cognition. However, existing
spectrum cognition methods often exhibit limited generalization and suboptimal
accuracy when deployed across diverse spectrum environments and tasks. To
overcome these challenges, we propose a spectrum foundation model, termed
SpectrumFM, which provides a new paradigm for spectrum cognition. An innovative
spectrum encoder that exploits the convolutional neural networks and the
multi-head self attention mechanisms is proposed to effectively capture both
fine-grained local signal structures and high-level global dependencies in the
spectrum data. To enhance its adaptability, two novel self-supervised learning
tasks, namely masked reconstruction and next-slot signal prediction, are
developed for pre-training SpectrumFM, enabling the model to learn rich and
transferable representations. Furthermore, low-rank adaptation (LoRA)
parameter-efficient fine-tuning is exploited to enable SpectrumFM to seamlessly
adapt to various downstream spectrum cognition tasks, including spectrum
sensing (SS), anomaly detection (AD), and wireless technology classification
(WTC). Extensive experiments demonstrate the superiority of SpectrumFM over
state-of-the-art methods. Specifically, it improves detection probability in
the SS task by 30% at -4 dB signal-to-noise ratio (SNR), boosts the area under
the curve (AUC) in the AD task by over 10%, and enhances WTC accuracy by 9.6%.

</details>


### [12] [Extracting Range-Doppler Information of Moving Targets from Wi-Fi Channel State Information](https://arxiv.org/abs/2508.02799)
*Jessica Sanson,Rahul C. Shah,Maximilian Pinaroc,Valerio Frascolla*

Main category: eess.SP

TL;DR: 提出一种从商用Wi-Fi CSI中提取距离和多普勒信息的方法，解决了硬件异步和天线耦合问题，验证了高精度传感的可行性。


<details>
  <summary>Details</summary>
Motivation: 商用Wi-Fi NIC未设计为全双工操作，硬件异步和天线耦合问题限制了CSI相位在传感中的应用。

Method: 提出时间偏移消除、相位对齐校正和Tx/Rx耦合抑制的信号处理方法。

Result: 在商用Intel Wi-Fi AX211 NIC上实现厘米级精度的距离和多普勒估计，成功检测和跟踪移动目标。

Conclusion: 证明了使用标准Wi-Fi通信和现成硬件实现高精度传感的可行性。

Abstract: This paper presents, for the first time, a method to extract both range and
Doppler information from commercial Wi-Fi Channel State Information (CSI) using
a monostatic (single transceiver) setup. Utilizing the CSI phase in Wi-Fi
sensing from a Network Interface Card (NIC) not designed for full-duplex
operation is challenging due to (1) Hardware asynchronization, which introduces
significant phase errors, and (2) Proximity of transmit (Tx) and receive (Rx)
antennas, which creates strong coupling that overwhelms the motion signal of
interest. We propose a new signal processing approach that addresses both
challenges via three key innovations: Time offset cancellation, Phase alignment
correction, and Tx/Rx coupling mitigation. Our method achieves cm-level
accuracy in range and Doppler estimation for moving targets, validated using a
commercial Intel Wi-Fi AX211 NIC. Our results show successful detection and
tracking of moving objects in realistic environments, establishing the
feasibility of high-precision sensing using standard Wi-Fi packet
communications and off-the-shelf hardware without requiring any modification or
specialized full-duplex capabilities.

</details>


### [13] [Integrating Machine Learning with Multimodal Monitoring System Utilizing Acoustic and Vision Sensing to Evaluate Geometric Variations in Laser Directed Energy Deposition](https://arxiv.org/abs/2508.02847)
*Ke Xu,Chaitanya Krishna Prasad Vallabh,Souran Manoochehri*

Main category: eess.SP

TL;DR: 提出了一种多模态监控框架，结合声发射传感和同轴相机视觉，用于激光定向能量沉积（DED）增材制造中的熔池动态和几何变化评估。


<details>
  <summary>Details</summary>
Motivation: DED增材制造中熔池动态复杂，工艺变化导致零件质量不稳定，但现有研究缺乏对过程监控系统的验证。

Method: 结合声发射传感和同轴相机视觉，提取时域、频域特征和形态特征，使用多种机器学习算法分类几何变化。

Result: 多模态策略分类性能达94.4%，优于单独使用声发射（87.8%）或相机（86.7%）。

Conclusion: 该框架为未来评估零件几何偏差和制造缺陷提供了技术基础。

Abstract: Laser directed energy deposition (DED) additive manufacturing struggles with
consistent part quality due to complex melt pool dynamics and process
variations. While much research targets defect detection, little work has
validated process monitoring systems for evaluating melt pool dynamics and
process quality. This study presents a novel multimodal monitoring framework,
synergistically integrating contact-based acoustic emission (AE) sensing with
coaxial camera vision to enable layer-wise identification and evaluation of
geometric variations in DED parts. The experimental study used three part
configurations: a baseline part without holes, a part with a 3mm diameter
through-hole, and one with a 5mm through-hole to test the system's discerning
capabilities. Raw sensor data was preprocessed: acoustic signals were filtered
for time-domain and frequency-domain feature extraction, while camera data
underwent melt pool segmentation and morphological feature extraction. Multiple
machine learning algorithms (including SVM, random forest, and XGBoost) were
evaluated to find the optimal model for classifying layer-wise geometric
variations. The integrated multimodal strategy achieved a superior
classification performance of 94.4%, compared to 87.8% for AE only and 86.7%
for the camera only. Validation confirmed the integrated system effectively
captures both structural vibration signatures and surface morphological changes
tied to the geometric variations. While this study focuses on specific
geometries, the demonstrated capability to discriminate between features
establishes a technical foundation for future applications in characterizing
part variations like geometric inaccuracies and manufacturing-induced defects.

</details>


### [14] [Secure mmWave Beamforming with Proactive-ISAC Defense Against Beam-Stealing Attacks](https://arxiv.org/abs/2508.02856)
*Seyed Bagher Hashemi Natanzi,Hossein Mohammadi,Bo Tang,Vuk Marojevic*

Main category: eess.SP

TL;DR: 提出了一种基于深度强化学习（DRL）的主动防御框架，用于应对毫米波通信系统中的波束窃取攻击，结合ISAC能力实现智能威胁评估。


<details>
  <summary>Details</summary>
Motivation: 毫米波通信系统面临高级波束窃取攻击的威胁，需要一种主动且自适应的防御方法。

Method: 使用基于PPO算法的DRL代理，结合ISAC能力进行动态探测，并采用课程学习策略优化训练过程。

Result: 框架实现了92.8%的平均攻击检测率和超过13 dB的用户SINR。

Conclusion: 该方法在保证通信性能的同时，显著提升了毫米波系统的安全性。

Abstract: Millimeter-wave (mmWave) communication systems face increasing susceptibility
to advanced beam-stealing attacks, posing a significant physical layer security
threat. This paper introduces a novel framework employing an advanced Deep
Reinforcement Learning (DRL) agent for proactive and adaptive defense against
these sophisticated attacks. A key innovation is leveraging Integrated Sensing
and Communications (ISAC) capabilities for active, intelligent threat
assessment. The DRL agent, built on a Proximal Policy Optimization (PPO)
algorithm, dynamically controls ISAC probing actions to investigate suspicious
activities. We introduce an intensive curriculum learning strategy that
guarantees the agent experiences successful detection during training to
overcome the complex exploration challenges inherent to such a
security-critical task. Consequently, the agent learns a robust and adaptive
policy that intelligently balances security and communication performance.
Numerical results demonstrate that our framework achieves a mean attacker
detection rate of 92.8% while maintaining an average user SINR of over 13 dB.

</details>


### [15] [Zak-OTFS for Faster-Than-Nyquist Signaling in the Presence of Mobility & Delay Spread](https://arxiv.org/abs/2508.02950)
*Sandesh Rao Mattu,Nishant Mehrotra,Robert Calderbank*

Main category: eess.SP

TL;DR: 论文提出了一种基于Zak-OTFS调制的超Nyquist信号传输方法，通过叠加信息符号并利用慢变信道特性提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统正交信号传输（Nyquist）限制了带宽和时间内的信息符号数量，超Nyquist信号传输通过叠加符号突破这一限制。

Method: 利用Zak-OTFS调制在延迟-多普勒域叠加信息符号，构造相互无偏基，并通过预编码器抑制信道干扰。

Result: 数值结果表明，该方法在未编码时性能与Nyquist相当，编码后在高信噪比下优于Nyquist。

Conclusion: 提出的方法通过叠加符号和慢变信道特性，实现了高效的超Nyquist信号传输。

Abstract: Orthogonal signaling limits the number of information symbols transmitted in
bandwidth $B$ and time $T$ to be $BT$. This corresponds to the Nyquist
signaling and is achieved by mounting information symbols on $BT$-dimensional
basis spanning the $BT$-dimensional space spaced $\frac{1}{B}$ and
$\frac{1}{T}$ apart. Faster-than-Nyquist signaling involves transmitting more
than $BT$ informational symbols in a $BT$-dimensional space. This leads to loss
of orthogonality. This is achieved by time and/or bandwidth expansion resulting
from packing more information symbols in the same $BT$-dimensional space
(spacing less than $\frac{1}{B}$ and/or $\frac{1}{T}$). In this paper, we take
a different approach to faster-than-Nyquist signaling. We propose to
superimpose the information symbols on one another maintaining the original
spacing in the Nyquist signaling. We carry this out in the delay-Doppler (DD)
domain using Zak-transform based orthogonal time frequency space (Zak-OTFS)
modulation. In Zak-OTFS, the channel varies slowly. Further Zak-OTFS also
allows construction of mutually unbiased bases the interference between which
appear like Gaussian noise. The proposed scheme leverages the slow variation in
the DD channel to construct a precoder that mitigates the effect of the
doubly-spread channel. Further, in the proposed scheme we mount information
symbols on two mutually unbiased bases which allows superposition of
information symbols. This simplifies receiver processing to detection in
Gaussian noise since each basis appears to the other as Gaussian noise. This
reduction makes it possible to use trellis coded modulation to enhance
bit-error performance. Numerical results demonstrate that the
faster-than-Nyquist signaling scheme achieves similar uncoded performance as
that of Nyquist signaling and with coding the performance is better than
Nyquist signaling at high signal-to-noise ratios.

</details>


### [16] [Generating Light-based Fingerprints for Indoor Localization](https://arxiv.org/abs/2508.03011)
*Hsun-Yu Lee,Jie Lin,Fang-Jing Wu*

Main category: eess.SP

TL;DR: 论文提出了一种基于可见光通信（VLC）的室内定位方法，利用低成本AS7341传感器捕获的光谱特征作为位置指纹，并通过GAN增强数据，显著提升了定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有射频定位技术（如Wi-Fi、RFID）易受多径衰落和干扰影响，而VLC提供了一种互补的解决方案。

Method: 采用两阶段框架：1）用真实光谱数据训练多层感知机（MLP）；2）通过TabGAN生成合成数据以扩充训练集。

Result: 实验表明，数据增强后平均定位误差从62.9cm降至49.3cm（提升20%），仅需额外5%的数据收集成本。

Conclusion: GAN增强有效缓解了数据稀缺问题，提升了模型的泛化能力，适用于复杂室内环境。

Abstract: Accurate indoor localization underpins applications ranging from wayfinding
and emergency response to asset tracking and smart-building services.
Radio-frequency solutions (e.g. Wi-Fi, RFID, UWB) are widely adopted but remain
vulnerable to multipath fading, interference, and uncontrollable coverage
variation. We explore an orthogonal modality -- visible light communication
(VLC) -- and demonstrate that the spectral signatures captured by a low-cost
AS7341 sensor can serve as robust location fingerprints.
  We introduce a two-stage framework that (i) trains a multi-layer perceptron
(MLP) on real spectral measurements and (ii) enlarges the training corpus with
synthetic samples produced by TabGAN. The augmented dataset reduces the mean
localization error from 62.9cm to 49.3cm -- a 20% improvement -- while
requiring only 5% additional data-collection effort. Experimental results
obtained on 42 reference points in a U-shaped laboratory confirm that GAN-based
augmentation mitigates data-scarcity issues and enhances generalization.

</details>


### [17] [Metasurface-Enabled Extremely Large-Scale Antenna Systems: Transceiver Architecture, Physical Modeling, and Channel Estimation](https://arxiv.org/abs/2508.03021)
*Zhengyu Wang,Tiebin Mi,Gui Zhou,Robert C. Qiu*

Main category: eess.SP

TL;DR: 论文提出了一种基于超表面的极大规模天线系统（MELA），通过可重构透射超表面实现高效的射频耦合和相位控制，解决了传统方案中笨重开关矩阵和高成本移相器网络的问题。


<details>
  <summary>Details</summary>
Motivation: 极大规模天线阵列（ELAA）是下一代无线通信系统的关键技术，但其传统实现方式存在体积大、成本高的问题。

Method: 提出MELA架构，开发物理基础模型描述电磁场传播，引入距离相关近似模型，并提出两阶段信道估计框架。

Result: MELA显示出接近最优的空间分辨率，数值实验验证了信道估计算法的高分辨率和电磁模型的准确性。

Conclusion: MELA是一种极具竞争力且前瞻性的ELAA解决方案。

Abstract: Extremely large-scale antenna arrays (ELAAs) have emerged as a pivotal
technology for addressing the unprecedented performance demands of
next-generation wireless communication systems. To enhance their practicality,
we propose metasurface-enabled extremely large-scale antenna (MELA) systems --
novel transceiver architectures that employ reconfigurable transmissive
metasurfaces to facilitate efficient over-the-air RF-to-antenna coupling and
phase control. This architecture eliminates the need for bulky switch matrices
and costly phase-shifter networks typically required in conventional solutions.
Physically grounded models are developed to characterize electromagnetic field
propagation through individual transmissive unit cells, capturing the
fundamental physics of wave transformation and transmission. Additionally,
distance-dependent approximate models are introduced, exhibiting structural
properties conducive to efficient parameter estimation and signal processing.
Based on the channel model, a two stage channel estimation framework is
proposed for the scenarios comprising users in the hybrid near- and far-fields.
In the first stage, a dictionary-driven beamspace filtering technique enables
rapid angular-domain scanning. In the refinement stage, the rotational symmetry
of subarrays is exploited to design super-resolution estimators that jointly
recover angular and range parameters. An analytical expression for the
half-power beamwidth of MELA is derived, revealing its near-optimal spatial
resolution relative to conventional ELAA architectures. Numerical experiments
further validate the high-resolution of the proposed channel estimation
algorithm and the fidelity of the electromagnetic model, positioning the MELA
architecture as a highly competitive and forward-looking solution for practical
ELAA deployment.

</details>


### [18] [Scenario-Agnostic Deep-Learning-Based Localization with Contrastive Self-Supervised Pre-training](https://arxiv.org/abs/2508.03084)
*Lingyan Zhang,Yuanfeng Qiu,Dachuan Li,Shaohua Wu,Tingting Zhang,Qinyu Zhang*

Main category: eess.SP

TL;DR: CSSLoc是一种基于对比自监督预训练的新型框架，用于学习通用表示以实现各种场景下的精确定位，无需位置信息监督。


<details>
  <summary>Details</summary>
Motivation: 无线定位技术在特定场景下精度有所提升，但环境动态脆弱性限制了其实际应用。

Method: 通过对比自监督预训练学习无线电数据的相似性度量，使相似样本在表示空间中紧密聚集，不同样本分离。

Result: CSSLoc在典型室内场景中优于传统和基于DNN的最新定位方案。

Conclusion: CSSLoc将基于深度学习的定位从特定性推向通用性。

Abstract: Wireless localization has become a promising technology for offering
intelligent location-based services. Although its localization accuracy is
improved under specific scenarios, the short of environmental dynamic
vulnerability still hinders this approach from being fully practical
applications. In this paper, we propose CSSLoc, a novel framework on
contrastive self-supervised pre-training to learn generic representations for
accurate localization in various scenarios. Without the location information
supervision, CSSLoc attempts to learn an insightful metric on the similarity
discrimination of radio data, in such a scenario-agnostic manner that the
similar samples are closely clustered together and different samples are
separated in the representation space. Furthermore, the trained feature encoder
can be directly transferred for downstream localization tasks, and the location
predictor is trained to estimate accurate locations with the robustness of
environmental dynamics. With extensive experimental results, CSSLoc can
outperform classical and state-of-the-art DNN-based localization schemes in
typical indoor scenarios, pushing deep-learning-based localization from
specificity to generality.

</details>


### [19] [Can Large Language Models Identify Materials from Radar Signals?](https://arxiv.org/abs/2508.03120)
*Jiangyou Zhu,Hongyu Deng,He Chen*

Main category: eess.SP

TL;DR: LLMaterial首次探索了利用预训练大语言模型（LLM）直接从雷达信号识别材料的方法，通过物理信号处理和检索增强生成策略，实现了开放集材料识别。


<details>
  <summary>Details</summary>
Motivation: 现有雷达材料识别方法局限于封闭集对象且需任务特定数据训练，限制了实际应用。利用LLM的推理能力直接从雷达信号推断材料组成是一个未解决的问题。

Method: 1. 提出物理信号处理流程，将冗余雷达数据压缩为表征材料特性的中间参数；2. 采用检索增强生成（RAG）策略，为LLM提供领域知识以解释中间参数。

Result: 初步结果表明，LLMaterial能有效区分多种常见材料，展示了实际应用的潜力。

Conclusion: LLMaterial结合物理信号处理和LLM推理能力，为开放集材料识别提供了新思路。

Abstract: Accurately identifying the material composition of objects is a critical
capability for AI robots powered by large language models (LLMs) to perform
context-aware manipulation. Radar technologies offer a promising sensing
modality for material recognition task. When combined with deep learning, radar
technologies have demonstrated strong potential in identifying the material of
various objects. However, existing radar-based solutions are often constrained
to closed-set object categories and typically require task-specific data
collection to train deep learning models, largely limiting their practical
applicability. This raises an important question: Can we leverage the powerful
reasoning capabilities of pre-trained LLMs to directly infer material
composition from raw radar signals? Answering this question is non-trivial due
to the inherent redundancy of radar signals and the fact that pre-trained LLMs
have no prior exposure to raw radar data during training. To address this, we
introduce LLMaterial, the first study to investigate the feasibility of using
LLM to identify materials directly from radar signals. First, we introduce a
physics-informed signal processing pipeline that distills high-redundancy radar
raw data into a set of compact intermediate parameters that encapsulate the
material's intrinsic characteristics. Second, we adopt a retrieval-augmented
generation (RAG) strategy to provide the LLM with domain-specific knowledge,
enabling it to interpret and reason over the extracted intermediate parameters.
Leveraging this integration, the LLM is empowered to perform step-by-step
reasoning on the condensed radar features, achieving open-set material
recognition directly from raw radar signals. Preliminary results show that
LLMaterial can effectively distinguish among a variety of common materials,
highlighting its strong potential for real-world material identification
applications.

</details>


### [20] [Model Order Reduction for Large-scale Circuits Using Higher Order Dynamic Mode Decomposition](https://arxiv.org/abs/2508.03131)
*Na Liu,Chengliang Dai,Qiuyue Wu,Qiuqi Li,Guoxiong Cai*

Main category: eess.SP

TL;DR: 本文提出了一种高阶动态模态分解（HODMD）方法，用于提升大规模瞬态电路模拟的计算效率，解决了传统DMD方法在空间分辨率不足时无法重构输出信号的问题。


<details>
  <summary>Details</summary>
Motivation: 传统动态模态分解（DMD）方法在空间分辨率不足时无法重构输出信号，限制了其在大规模电路模拟中的应用。

Method: 本文推导了DMD算法，并提出了结合延迟嵌入技术的高阶动态模态分解（HODMD）方法，适用于一般电路且不对拓扑或元件类型设限。

Result: 通过三个代表性数值测试案例验证了HODMD方法的计算效率和准确性。

Conclusion: HODMD方法显著提升了大规模电路模拟的效率，且具有更广泛的适用性。

Abstract: Model order reduction (MOR) has long been a mainstream strategy to accelerate
large-scale transient circuit simulation. Dynamic Mode Decomposition (DMD)
represents a novel data-driven characterization method, extracting dominant
dynamical modes directly from time-domain simulation data without requiring
explicit system equations. This paper first deduces the DMD algorithm and then
proposes high order dynamic mode decomposition (HODMD) incorporating delayed
embedding technique, specifically targeting computational efficiency in
large-scale circuit simulations. Compared with the DMD method, the HODMD method
overcomes the problem that the output signal cannot be reconstructed when the
spatial resolution is insufficient. The proposed HODMD algorithm is applicable
to general circuits and does not impose any constraints on the topology of the
pertinent circuit or type of the components. Three representative numerical
test cases are presented to systematically validate both the computational
efficiency and accuracy of the proposed HODMD method.

</details>


### [21] [Federated Learning with Feature Reconstruction for Vector Quantization based Semantic Communication](https://arxiv.org/abs/2508.03248)
*Yoon Huh,Bumjun Kim,Wan Choi*

Main category: eess.SP

TL;DR: FedSFR是一种新颖的联邦学习框架，通过语义特征重构（FR）解决VQ图像语义通信系统中的知识库不匹配和模型过时问题，提升训练稳定性和通信效率。


<details>
  <summary>Details</summary>
Motivation: 解决图像语义通信中因知识库不匹配和模型过时导致的语义错误及性能下降问题。

Method: 提出FedSFR框架，结合语义特征重构（FR），允许客户端传输紧凑特征向量而非完整模型更新，并设计针对VQ的损失函数。

Result: 实验证明FedSFR在容量受限场景下优于现有基线，验证了其有效性和鲁棒性。

Conclusion: FedSFR通过FR和联邦学习的结合，显著提升了图像语义通信系统的性能和效率。

Abstract: Recent advancements in semantic communication have primarily focused on image
transmission, where neural network (NN)-based joint source-channel coding
(JSCC) modules play a central role. However, such systems often experience
semantic communication errors due to mismatched knowledge bases between users
and performance degradation from outdated models, necessitating regular model
updates. To address these challenges in vector quantization (VQ)-based image
semantic communication systems, we propose FedSFR, a novel federated learning
(FL) framework that incorporates semantic feature reconstruction (FR). FedSFR
introduces an FR step at the parameter server (PS) and allows a subset of
clients to transmit compact feature vectors in lieu of sending full local model
updates, thereby improving training stability and communication efficiency. To
enable effective FR learning, we design a loss function tailored for VQ-based
image semantic communication and demonstrate its validity as a surrogate for
image reconstruction error. Additionally, we provide a rigorous convergence
analysis and present a differentially private variant of FedSFR, along with
formal privacy analysis. Experimental results on two benchmark datasets
validate the superiority of FedSFR over existing baselines, especially in
capacity-constrained settings, confirming both its effectiveness and
robustness.

</details>


### [22] [Investigating the Cognitive Response of Brake Lights in Initiating Braking Action Using EEG](https://arxiv.org/abs/2508.03274)
*Ramaswamy Palaniappan,Surej Mouli,Howard Bowman,Ian McLoughlin*

Main category: eess.SP

TL;DR: 论文研究了不同刹车灯设计对驾驶员反应时间的影响，发现LED刹车灯比白炽灯刹车灯更能快速引发认知反应。


<details>
  <summary>Details</summary>
Motivation: 研究动机是减少因驾驶员注意力不足或车距不足导致的交通事故，尤其是追尾事故。

Method: 方法包括在模拟驾驶环境中测试多种刹车灯设计，记录22名受试者的脑电图（EEG）数据，分析P3成分以测量反应时间。

Result: 结果显示，白炽灯刹车灯的认知反应时间显著慢于所有LED刹车灯，而不同LED设计之间的差异不显著。

Conclusion: 结论是LED刹车灯在引发驾驶员快速反应方面优于白炽灯刹车灯，但不同LED设计之间的差异需进一步研究。

Abstract: Half of all road accidents result from either lack of driver attention or
from maintaining insufficient separation between vehicles. Collision from the
rear, in particular, has been identified as the most common class of accident
in the UK, and its influencing factors have been widely studied for many years.
Rear-mounted stop lamps, illuminated when braking, are the primary mechanism to
alert following drivers to the need to reduce speed or brake. This paper
develops a novel brain response approach to measuring subject reaction to
different brake light designs. A variety of off-the-shelf brake light
assemblies are tested in a physical simulated driving environment to assess the
cognitive reaction times of 22 subjects. Eight pairs of LED-based and two pairs
of incandescent bulb-based brake light assemblies are used and
electroencephalogram (EEG) data recorded. Channel Pz is utilised to extract the
P3 component evoked during the decision making process that occurs in the brain
when a participant decides to lift their foot from the accelerator and depress
the brake. EEG analysis shows that both incandescent bulb-based lights are
statistically slower to evoke cognitive responses than all tested LED-based
lights. Between the LED designs, differences are evident, but not statistically
significant, attributed to the significant amount of movement artifact in the
EEG signal.

</details>


### [23] [Spiking Neural Networks for Resource Allocation in UAV-Enabled Wireless Networks](https://arxiv.org/abs/2508.03279)
*Vasileios Kouvakis,Stylianos E. Trevlakis,Ioannis Arapakis,Alexandros-Apostolos A. Boulogeorgos*

Main category: eess.SP

TL;DR: 提出了一种基于脉冲神经网络（SNN）的新方法，用于非地面网络（NTN）中的用户设备-基站（UE-BS）关联，比较了集中式和分布式两种优化策略。


<details>
  <summary>Details</summary>
Motivation: 随着无人机（UAV）引入无线网络，系统架构变得异构，需要动态高效的管理以避免拥塞并维持性能。

Method: 采用基于泄漏积分发放神经元的SNN，比较了集中式（全局可见）和分布式（节点独立）两种策略。

Result: 仿真显示分布式模型准确率超过90%，集中式模型为80-100%，两者在部署场景中各具优势。

Conclusion: 两种方法在个体最优解与UE-BS关联可行性之间存在权衡，适用于不同场景。

Abstract: This work presents a new spiking neural network (SNN)-based approach for user
equipment-base station (UE-BS) association in non-terrestrial networks (NTNs).
With the introduction of UAV's in wireless networks, the system architecture
becomes heterogeneous, resulting in the need for dynamic and efficient
management to avoid congestion and sustain overall performance. The presented
framework compares two SNN-based optimization strategies. Specifically, a
top-down centralized approach with complete network visibility and a bottom-up
distributed approach for individual network nodes. The SNN is based on leak
integrate-and-fire neurons with temporal components, which can perform fast and
efficient event-driven inference. Realistic ray-tracing simulations are
conducted, which showcase that the bottom-up model attains over 90\% accuracy,
while the top-down model maintains 80-100\% accuracy. Both approaches reveal a
trade-off between individually optimal solutions and UE-BS association
feasibility, thus revealing the effectiveness of both approaches depending on
deployment scenarios.

</details>


### [24] [Quantum Deep Learning for Massive MIMO User Scheduling](https://arxiv.org/abs/2508.03327)
*Xingyu Huang,Ruining Fan,Mouli Chakraborty,Avishek Nag,Anshu Mukherjee*

Main category: eess.SP

TL;DR: 提出一种混合量子神经网络架构，用于5G/B5G大规模MIMO系统中的高效用户调度，解决传统方法的扩展性问题。


<details>
  <summary>Details</summary>
Motivation: 传统方法在大规模MIMO系统中存在扩展性问题，需要更高效的调度方案。

Method: 结合经典神经网络和变分量子电路内核，利用统计信道状态信息（CSI）减少计算开销。

Result: 模型在噪声信道中表现稳健，优于经典卷积神经网络（CNN），提高了频谱效率。

Conclusion: 量子增强的机器学习在无线调度中具有潜力。

Abstract: We introduce a hybrid Quantum Neural Networks (QNN) architecture for the
efficient user scheduling in 5G/Beyond 5G (B5G) massive Multiple Input Multiple
Output (MIMO) systems, addressing the scalability issues of traditional
methods. By leveraging statistical Channel State Information (CSI), our model
reduces computational overhead and enhances spectral efficiency. It integrates
classical neural networks with a variational quantum circuit kernel,
outperforming classical Convolutional Neural Networks (CNNs) and maintaining
robust performance in noisy channels. This demonstrates the potential of
quantum-enhanced Machine Learning (ML) for wireless scheduling.

</details>


### [25] [Beam-Hopping Pattern Design for Grant-Free Random Access in LEO Satellite Communications](https://arxiv.org/abs/2508.03391)
*Seunghyeon Jeon,Seonjung Kim,Gyeongrae Im,Yo-Seb Jeon*

Main category: eess.SP

TL;DR: 本文研究了低地球轨道（LEO）卫星通信系统中的波束跳跃模式设计，提出了一种动态分配资源的算法，以最大化传输成功概率。


<details>
  <summary>Details</summary>
Motivation: 偏远地区对大规模设备连接的需求增加，推动了LEO卫星通信系统的发展，波束跳跃技术能实现需求感知的资源分配和低延迟接入。

Method: 提出了一种交替优化框架的算法，结合二分法和ADMM方法，优化波束跳跃模式和资源分配。

Result: 仿真结果表明，所提算法在传输成功概率和资源分配效率上优于其他方法，并能有效应对流量需求不均衡。

Conclusion: 本文提出的算法为LEO卫星通信系统提供了一种高效的波束跳跃设计解决方案，具有实际应用潜力。

Abstract: Increasing demand for massive device connectivity in underserved regions
drives the development of advanced low Earth orbit (LEO) satellite
communication systems. Beam-hopping LEO systems without connection
establishment provide a promising solution for achieving both demand-aware
resource allocation and low access latency. This paper investigates
beam-hopping pattern design for the grant-free random access systems to
dynamically allocate satellite resources according to traffic demands across
serving cells. We formulate a binary optimization problem that aims to maximize
the minimum successful transmission probability across cells, given limited
satellite beam generation capacity. To solve this problem, we propose novel
beam-hopping design algorithms that alternately enhance the collision avoidance
rate and decoding success probability within an alternating optimization
framework. Specifically, the algorithms employ a bisection method to optimize
illumination allocation for each cell based on demand, while using the
alternating direction method of multipliers (ADMM) to optimize beam-hopping
patterns for maximizing decoding success probability. Furthermore, we enhance
the ADMM by replacing the strict binary constraint with two equivalent
continuous-valued constraints. Simulation results demonstrate the superiority
of the proposed algorithms compared to other beam-hopping methods and verify
robustness in managing traffic demand imbalance.

</details>


### [26] [How to Proactively Monitor Untrusted Communications with Cell-Free Massive MIMO?](https://arxiv.org/abs/2508.03423)
*Isabella W. G. da Silva,Zahra Mobini,Hien Q. Ngo,Hyundong Shin,Michail Matthaiou*

Main category: eess.SP

TL;DR: 本文研究了无小区大规模多输入多输出（CF-mMIMO）主动监控系统，提出了一种有效的信道状态信息（CSI）获取方案，并通过优化模式和干扰功率控制提升监控性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过多天线监控节点（MNs）对不可信链路进行主动监控，解决CSI获取和监控性能优化问题。

Method: 利用上下行链路中的导频信号，通过最小均方误差（MMSE）估计有效信道，并基于贝叶斯优化框架提出联合模式分配和干扰功率控制优化方法。

Result: 数值结果表明，提出的CF-mMIMO主动监控系统在CSI获取和优化方面显著优于基准方法，监控成功概率（MSP）超过0.8。

Conclusion: 提出的系统和方法在监控性能和鲁棒性方面表现出色，适用于不同天线数量和预编码方案。

Abstract: This paper studies a cell-free massive multiple-input multiple-output
(CF-mMIMO) proactive monitoring system in which multiple multi-antenna
monitoring nodes (MNs) are assigned to either observe the transmissions from an
untrusted transmitter (UT) or to jam the reception at the untrusted receiver
(UR). We propose an effective channel state information (CSI) acquisition
scheme for the monitoring system. In our approach, the MNs leverage the pilot
signals transmitted during the uplink and downlink phases of the untrusted link
and estimate the effective channels corresponding to the UT and UR via a
minimum mean-squared error (MMSE) estimation scheme. We derive new spectral
efficiency (SE) expressions for the untrusted link and the monitoring system.
For the latter, the SE is derived for two CSI availability cases at the central
processing unit (CPU); namely case-1: imperfect CSI knowledge at both MNs and
CPU, case-2: imperfect CSI knowledge at the MNs and no CSI knowledge at the
CPU. To improve the monitoring performance, we propose a novel joint mode
assignment and jamming power control optimization method to maximize the
monitoring success probability (MSP) based on the Bayesian optimization
framework. Numerical results show that (a) our CF-mMIMO proactive monitoring
system relying on the proposed CSI acquisition and optimization approach
significantly outperforms the considered benchmarks; (b) the MSP performance of
our CF-mMIMO proactive monitoring system is greater than 0.8, regardless of the
number of antennas at the untrusted nodes or the precoding scheme for the
untrusted transmission link.

</details>


### [27] [Joint Sensing and Bi-Directional Communication with Dynamic TDD Enabled Cell-Free MIMO](https://arxiv.org/abs/2508.03460)
*Anubhab Chowdhury,Sai Subramanyam Thoota,Erik G. Larsson*

Main category: eess.SP

TL;DR: 本文研究了动态时分双工（DTDD）的无蜂窝（CF）大规模多输入多输出（mMIMO）系统中的集成感知与通信（ISAC）。通过DTDD，系统可同时服务上下行用户，并利用上行AP进行感知与通信。提出了集中式和分布式GLRT检测方法，并量化了其最优性与复杂度的权衡。通信方面，推导了SINR最优组合器，并提出了两种目标预编码器。数值研究验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 研究动态时分双工（DTDD）在无蜂窝大规模MIMO系统中实现集成感知与通信（ISAC）的潜力，以提升系统性能并解决传统系统的局限性。

Method: 1. 提出集中式和分布式GLRT检测方法；2. 量化最优性与复杂度的权衡；3. 推导SINR最优组合器；4. 设计两种目标预编码器（用户中心型和目标中心型）。

Result: 1. GLRT对AP间干扰具有鲁棒性；2. DTDD将上下行频谱效率提升至传统TDD系统的两倍；3. 验证了理论结果的正确性。

Conclusion: DTDD在无蜂窝大规模MIMO系统中实现了高效的集成感知与通信，显著提升了系统性能，同时保持了硬件复杂度。

Abstract: This paper studies integrated sensing and communication (ISAC) with dynamic
time division duplex (DTDD) cell-free (CF) massive multiple-input
multiple-output~(mMIMO) systems. DTDD enables the CF mMIMO system to
concurrently serve both uplink~(UL) and downlink~(DL) users with spatially
separated \emph{half-duplex~(HD)} access points~(APs) using the same
time-frequency resources. Further, to facilitate ISAC, the UL APs are utilized
for both UL data and target echo reception, while the DL APs jointly transmit
the precoded DL data streams and target signal. In this context, we present
centralized and distributed generalized likelihood-ratio tests~(GLRTs) for
target detection treating UL users' signals as sensing interference. We then
quantify the optimality and complexity trade-off between distributed and
centralized GLRTs and benchmark the respective estimators with the Bayesian
Cram\'er-Rao lower bound for target radar-cross section~(RCS). Then, we present
a unified framework for joint UL users' data detection and RCS estimation.
Next, for communication, we derive the signal-to-noise-plus-interference~(SINR)
optimal combiner accounting for the cross-link and radar interference for UL
data processing. In DL, we use regularized zero-forcing for the users and
propose two types of precoders for the target: one ``user-centric" that
nullifies the interference caused by the target signal to the DL users and one
``target-centric" based on the dominant eigenvector of the composite channel
between the target and the APs. Finally, numerical studies corroborate with our
theoretical findings and reveal that the \emph{GLRT is robust to inter-AP
interference, and DTDD doubles the $90\%$-likely sum UL-DL SE compared to
traditional TDD-based CF-mMIMO ISAC systems}; while using HD hardware.

</details>


### [28] [Decoding and Engineering the Phytobiome Communication for Smart Agriculture](https://arxiv.org/abs/2508.03584)
*Fatih Gulec,Hamdan Awan,Nigel Wallbridge,Andrew W. Eckford*

Main category: eess.SP

TL;DR: 论文探讨了如何利用通信工程视角理解植物生物群落（phytobiome）的通信，并将其与智能农业结合，提出多尺度框架和潜在应用。


<details>
  <summary>Details</summary>
Motivation: 解决现代农业面临的食品需求增长、环境污染和水资源短缺等挑战。

Method: 提出多尺度框架建模植物生物群落通信网络，并通过实验验证电生理信号模型。

Result: 展示了智能灌溉和精准农业化学品输送等应用，结合ML/AI和分子通信技术。

Conclusion: 为高效、可持续和环保的农业生产提供了新方向，但需解决实施挑战和研究问题。

Abstract: Smart agriculture applications, integrating technologies like the Internet of
Things and machine learning/artificial intelligence (ML/AI) into agriculture,
hold promise to address modern challenges of rising food demand, environmental
pollution, and water scarcity. Alongside the concept of the phytobiome, which
defines the area including the plant, its environment, and associated
organisms, and the recent emergence of molecular communication (MC), there
exists an important opportunity to advance agricultural science and practice
using communication theory. In this article, we motivate to use the
communication engineering perspective for developing a holistic understanding
of the phytobiome communication and bridge the gap between the phytobiome
communication and smart agriculture. Firstly, an overview of phytobiome
communication via molecular and electrophysiological signals is presented and a
multi-scale framework modeling the phytobiome as a communication network is
conceptualized. Then, how this framework is used to model electrophysiological
signals is demonstrated with plant experiments. Furthermore, possible smart
agriculture applications, such as smart irrigation and targeted delivery of
agrochemicals, through engineering the phytobiome communication are proposed.
These applications merge ML/AI methods with the Internet of Bio-Nano-Things
enabled by MC and pave the way towards more efficient, sustainable, and
eco-friendly agricultural production. Finally, the implementation challenges,
open research issues, and industrial outlook for these applications are
discussed.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [29] [SecoustiCodec: Cross-Modal Aligned Streaming Single-Codecbook Speech Codec](https://arxiv.org/abs/2508.02849)
*Chunyu Qiang,Haoyu Wang,Cheng Gong,Tianrui Wang,Ruibo Fu,Tao Wang,Ruilong Chen,Jiangyan Yi,Zhengqi Wen,Chen Zhang,Longbiao Wang,Jianwu Dang,Jianhua Tao*

Main category: eess.AS

TL;DR: SecoustiCodec是一种低比特率流式语音编解码器，通过跨模态对齐和对比学习分离语义和副语言信息，实现高重建质量和语义完整性。


<details>
  <summary>Details</summary>
Motivation: 现有语音编解码方法在语义编码中存在副语言信息残留、语义不完整、重建能力有限及不支持流式等问题，需要一种新方法解决这些挑战。

Method: 提出基于VAE和FSQ的语义量化方法，结合对比学习分离语义和副语言信息，并采用多阶段优化策略确保收敛稳定性。

Result: 在0.27/1 kbps下，SecoustiCodec达到PESQ 1.77/2.58的SOTA重建质量。

Conclusion: SecoustiCodec在语义编码和重建质量上表现优异，代码和模型将开源。

Abstract: Speech codecs serve as a crucial bridge in unifying speech and text language
models. Existing codec methods face several challenges in semantic encoding,
such as residual paralinguistic information (e.g., timbre, emotion),
insufficient semantic completeness, limited reconstruction capability, and lack
of support for streaming. To address these challenges, we propose
SecoustiCodec, a cross-modal aligned low-bitrate streaming speech codec that
disentangles semantic and paralinguistic information in a single-codebook
space. To ensure semantic completeness and reconstruction fidelity,
paralinguistic encoding is introduced to bridge the information gap between
semantic and acoustic encoding. A semantic-only efficient quantization method
based on VAE (Variational Autoencoder) and FSQ (Finite Scalar Quantization) is
proposed. This approach alleviates the long-tail distribution problem of tokens
while maintaining high codebook utilization. A semantic disentanglement method
based on contrastive learning is proposed, which aligns text and speech in a
joint multimodal frame-level space, effectively removing paralinguistic
information from semantic encoding. An acoustic-constrained multi-stage
optimization strategy is proposed to ensure robust and stable convergence.
Figure~\ref{fig:pesq_kbps_below_2kbps} shows SecoustiCodec achieves SOTA
(state-of-the-art) reconstruction quality (PESQ) of 1.77/2.58 at 0.27/1 kbps.
The code and model weights for SecoustiCodec will be open-sourced upon the
completion of the peer-review process. We've open-sourced SecoustiCodec's demo,
code, and model weights.

</details>


### [30] [Real-time speech enhancement in noise for throat microphone using neural audio codec as foundation model](https://arxiv.org/abs/2508.02974)
*Julien Hauret,Thomas Joubaud,Éric Bavu*

Main category: eess.AS

TL;DR: 实时语音增强演示，使用喉麦克风捕获语音，通过深度学习后处理提升嘈杂环境中的语音质量。


<details>
  <summary>Details</summary>
Motivation: 展示从喉麦克风录音到深度学习后处理的完整流程，解决喉麦克风音频带宽受限的问题。

Method: 基于Kyutai的Mimi神经音频编解码器，在Vibravox数据集上微调，支持实时推理。

Result: 相比现有模型，该方法表现更优，提供交互界面展示增强效果和延迟监控。

Conclusion: 该方法有效提升了喉麦克风在嘈杂环境中的语音质量，具有实时性和交互性。

Abstract: We present a real-time speech enhancement demo using speech captured with a
throat microphone. This demo aims to showcase the complete pipeline, from
recording to deep learning-based post-processing, for speech captured in noisy
environments with a body-conducted microphone. The throat microphone records
skin vibrations, which naturally attenuate external noise, but this robustness
comes at the cost of reduced audio bandwidth. To address this challenge, we
fine-tune Kyutai's Mimi--a neural audio codec supporting real-time
inference--on Vibravox, a dataset containing paired air-conducted and throat
microphone recordings. We compare this enhancement strategy against
state-of-the-art models and demonstrate its superior performance. The inference
runs in an interactive interface that allows users to toggle enhancement,
visualize spectrograms, and monitor processing latency.

</details>


### [31] [Fast Algorithm for Moving Sound Source](https://arxiv.org/abs/2508.03065)
*Dong Yang*

Main category: eess.AS

TL;DR: 提出Yang的运动时空采样重建理论，高效模拟运动引起的连续时变混响，解决语音增强模型在动态场景中训练数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以模拟符合物理规律的运动数据，导致语音增强模型在动态场景中训练数据不足。

Method: 分解运动声源的脉冲响应为线性时不变调制和离散时变分数延迟，建立符合物理的运动声场模型，采用分层采样策略。

Result: 相比开源模型GSound，更准确地恢复动态场景中的振幅和相位变化，解决了运动声源数据模拟的行业难题。

Conclusion: 为语音增强模型提供高质量动态训练数据，提升多通道端到端语音跟踪算法的鲁棒性。

Abstract: Modern neural network-based speech processing systems need reverberation
resistance, relying on large amounts of reverberation data for training.
Existing methods simulate dynamic scenarios by sampling static systems or
supplement with measured data, but struggle to simulate motion data conforming
to physical laws. To address insufficient training data for speech enhancement
models in moving scenarios, this paper proposes Yang's motion spatio-temporal
sampling reconstruction theory, enabling efficient simulation of motion-induced
continuous time-varying reverberation. It breaks through the limitations of
traditional static Image-Source Method (ISM) in time-varying systems by
decomposing the moving image source's impulse response into linear
time-invariant modulation and discrete time-varying fractional delay,
establishing a physics-compliant moving sound field model. Based on the
band-limited nature of motion displacement, a hierarchical sampling strategy is
adopted: high sampling rates for low-order images to retain details, and low
rates for high-order ones to reduce complexity, combined with a fast synthesis
architecture for real-time simulation. Experiments show that compared to
open-source model GSound, the theory more accurately restores amplitude and
phase changes in moving scenarios, solving the industry challenge of motion
sound source data simulation. It provides high-quality dynamic training data
for speech enhancement models and improves the robustness of multi-channel
end-to-end voice tracking algorithms.

</details>


### [32] [Kernel ridge regression based sound field estimation using a rigid spherical microphone array](https://arxiv.org/abs/2508.03087)
*Ryo Matsuda,Juliano G. C. Ribeiro,Hitoshi Akiyama,Jorge Trevino*

Main category: eess.AS

TL;DR: 提出了一种基于核岭回归的声场估计方法，利用刚性球形麦克风阵列，结合物理约束和适应观测声场的核函数，显著提升了估计精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设开放球形麦克风阵列或无散射体，或未考虑散射体的边界条件。本文利用刚性球体的已知边界条件，提出更精确的声场表示方法。

Method: 通过核岭回归框架，结合刚性球体的边界条件，提出新的声场表示方法，并开发了新的球形麦克风阵列进行实验验证。

Result: 数值模拟和实际实验验证了该方法的有效性。

Conclusion: 该方法显著提升了声场估计的精度，尤其在存在刚性散射体的情况下。

Abstract: We propose a sound field estimation method based on kernel ridge regression
using a rigid spherical microphone array. Kernel ridge regression with
physically constrained kernel functions, and further with kernel functions
adapted to observed sound fields, have proven to be powerful tools. However,
such methods generally assume an open-sphere microphone array configuration,
i.e., no scatterers exist within the observation or estimation region.
Alternatively, some approaches assume the presence of scatterers and attempt to
eliminate their influence through a least-squares formulation. Even then, these
methods typically do not incorporate the boundary conditions of the scatterers,
which are not presumed to be known. In contrast, we exploit the fact the
scatterer here is a rigid sphere. Meaning, both the virtual scattering source
locations and the boundary conditions are well-defined. Based on this, we
formulate the scattered sound field within the kernel ridge regression
framework and propose a novel sound field representation incorporating a
boundary constraint. The effectiveness of the proposed method is demonstrated
through numerical simulations and real-world experiments using a newly
developed spherical microphone array.

</details>


### [33] [PatchDSU: Uncertainty Modeling for Out of Distribution Generalization in Keyword Spotting](https://arxiv.org/abs/2508.03190)
*Bronya Roni Chernyak,Yael Segal,Yosi Shrem,Joseph Keshet*

Main category: eess.AS

TL;DR: PatchDSU通过分块处理语音数据，改进了DSU方法，显著提升了语音关键词识别在分布外数据上的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现实语音系统中数据分布常因环境、录音条件和说话人多样性而变化，传统深度学习方法假设训练和测试数据分布一致，难以应对。

Method: 提出PatchDSU方法，将输入分块并独立增强每块，以解决语音数据的时间特性和稀疏性问题。

Result: 在多个数据集和噪声条件下，PatchDSU和DSU表现优于其他方法，且PatchDSU在多种场景中表现更稳定。

Conclusion: PatchDSU通过分块处理有效提升了语音关键词识别的泛化能力，尤其在分布外数据上表现突出。

Abstract: Deep learning models excel at many tasks but rely on the assumption that
training and test data follow the same distribution. This assumption often does
not hold in real-world speech systems, where distribution shifts are common due
to varying environments, recording conditions, and speaker diversity.
  The method of Domain Shifts with Uncertainty (DSU) augments the input of each
neural network layer based on the input feature statistics. It addresses the
problem of out-of-domain generalization by assuming feature statistics follow a
multivariate Gaussian distribution and substitutes the input with sampled
features from this distribution. While effective for computer vision, applying
DSU to speech presents challenges due to the nature of the data. Unlike static
visual data, speech is a temporal signal commonly represented by a spectrogram
- the change of frequency over time. This representation cannot be treated as a
simple image, and the resulting sparsity can lead to skewed feature statistics
when applied to the entire input.
  To tackle out-of-distribution issues in keyword spotting, we propose
PatchDSU, which extends DSU by splitting the input into patches and
independently augmenting each patch. We evaluated PatchDSU and DSU alongside
other methods on the Google Speech Commands, Librispeech, and TED-LIUM.
Additionally, we evaluated performance under white Gaussian and MUSAN music
noise conditions. We also explored out-of-domain generalization by analyzing
model performance on datasets they were not trained on. Overall, in most cases,
both PatchDSU and DSU outperform other methods. Notably, PatchDSU demonstrates
more consistent improvements across the evaluated scenarios compared to other
approaches.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [34] [Adaptive Knowledge Distillation for Device-Directed Speech Detection](https://arxiv.org/abs/2508.02801)
*Hyung Gun Chi,Florian Pesce,Wonil Chang,Oggi Rudovic,Arturo Argueta,Stefan Braun,Vineet Garg,Ahmed Hussen Abdelaziz*

Main category: cs.SD

TL;DR: 提出了一种基于知识蒸馏（KD）的自适应方法，用于提升设备定向语音检测（DDSD）的准确性，并在不同模型架构中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在语音助手中实现更自然的用户体验，需要区分用户查询与背景语音或侧边对话。

Method: 采用自适应知识蒸馏方法，从预训练的大型声学编码器（教师模型）中提取通用表示，并通过任务特定适配器与学生模型联合训练。

Result: 在关键词和非关键词（后续）调用中，自适应KD方法比无蒸馏的学生模型分别提升了26%和19%的等错误率。

Conclusion: 该方法不仅显著提升了DDSD的准确性，还展示了在不同模型架构中的通用性。

Abstract: Device-directed speech detection (DDSD) is a binary classification task that
separates the user's queries to a voice assistant (VA) from background speech
or side conversations. This is important for achieving naturalistic user
experience. To this end, we propose knowledge distillation (KD) to enhance DDSD
accuracy while ensuring efficient deployment. Specifically, we introduce a
novel adaptive KD method that transfers knowledge from general representations
of an ASR large pre-trained acoustic encoder (teacher). We apply task-specific
adapters, on top of the (frozen) teacher encoder, trained jointly with the
student model on DDSD. We demonstrate that the proposed adaptive KD outperforms
the student model without distillation in the keyword and keyword-free
(follow-up) invocations, with an improvement of +26% and +19% in terms of Equal
Error Rate, respectively. We also show that this approach generalizes across
the transformer and conformer-based model architectures.

</details>


### [35] [Neural Speech Extraction with Human Feedback](https://arxiv.org/abs/2508.03041)
*Malek Itani,Ashton Graves,Sefik Emre Eskimez,Shyamnath Gollakota*

Main category: cs.SD

TL;DR: 提出首个利用人类反馈进行迭代优化的神经目标语音提取系统，通过用户标记生成编辑掩码，改进特定片段，同时保留未标记区域。


<details>
  <summary>Details</summary>
Motivation: 解决大规模人类标记数据难以获取的问题，探索人类反馈在语音提取中的有效性。

Method: 生成合成数据集，使用自动掩码功能训练模型，评估不同掩码策略的性能。

Result: 基于噪声功率（dBFS）和概率阈值的掩码表现最佳，用户研究显示优化输出更受青睐。

Conclusion: 人类反馈的迭代优化是提升神经语音提取性能的有效方法。

Abstract: We present the first neural target speech extraction (TSE) system that uses
human feedback for iterative refinement. Our approach allows users to mark
specific segments of the TSE output, generating an edit mask. The refinement
system then improves the marked sections while preserving unmarked regions.
Since large-scale datasets of human-marked errors are difficult to collect, we
generate synthetic datasets using various automated masking functions and train
models on each. Evaluations show that models trained with noise power-based
masking (in dBFS) and probabilistic thresholding perform best, aligning with
human annotations. In a study with 22 participants, users showed a preference
for refined outputs over baseline TSE. Our findings demonstrate that
human-in-the-loop refinement is a promising approach for improving the
performance of neural speech extraction.

</details>


### [36] [TF-MLPNet: Tiny Real-Time Neural Speech Separation](https://arxiv.org/abs/2508.03047)
*Malek Itani,Tuochao Chen,Shyamnath Gollakota*

Main category: cs.SD

TL;DR: TF-MLPNet是一种新型语音分离网络，能在低功耗加速器上实时运行，性能优于现有流式模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有语音分离网络无法在低功耗设备上实时运行的问题。

Method: 采用时频域处理，结合全连接层和卷积层，支持混合精度量化训练。

Result: 在GAP9处理器上实时处理6毫秒音频块，运行时间减少3.5-4倍。

Conclusion: TF-MLPNet为可穿戴设备提供了高效的实时语音分离解决方案。

Abstract: Speech separation on hearable devices can enable transformative augmented and
enhanced hearing capabilities. However, state-of-the-art speech separation
networks cannot run in real-time on tiny, low-power neural accelerators
designed for hearables, due to their limited compute capabilities. We present
TF-MLPNet, the first speech separation network capable of running in real-time
on such low-power accelerators while outperforming existing streaming models
for blind speech separation and target speech extraction. Our network operates
in the time-frequency domain, processing frequency sequences with stacks of
fully connected layers that alternate along the channel and frequency
dimensions, and independently processing the time sequence at each frequency
bin using convolutional layers. Results show that our mixed-precision
quantization-aware trained (QAT) model can process 6 ms audio chunks in
real-time on the GAP9 processor, achieving a 3.5-4x runtime reduction compared
to prior speech separation models.

</details>


### [37] [Fine-Tuning Text-to-Speech Diffusion Models Using Reinforcement Learning with Human Feedback](https://arxiv.org/abs/2508.03123)
*Jingyi Chen,Ju Seung Byun,Micha Elsner,Pichao Wang,Andrew Perrault*

Main category: cs.SD

TL;DR: DLPO是一种结合强化学习的框架，用于优化TTS扩散模型，提升语音质量和效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型生成高质量语音但效率低，难以实时应用，且对音调和节奏建模存在挑战。

Method: 提出DLPO框架，将原始训练损失整合到奖励函数中，利用自然度评分反馈优化模型。

Result: 在WaveGrad 2模型上，DLPO显著提升客观指标（UTMOS 3.65，NISQA 4.02）和主观评价，67%的音频更受青睐。

Conclusion: DLPO展示了在资源有限环境下实现高效、高质量扩散TTS的潜力。

Abstract: Diffusion models produce high-fidelity speech but are inefficient for
real-time use due to long denoising steps and challenges in modeling intonation
and rhythm. To improve this, we propose Diffusion Loss-Guided Policy
Optimization (DLPO), an RLHF framework for TTS diffusion models. DLPO
integrates the original training loss into the reward function, preserving
generative capabilities while reducing inefficiencies. Using naturalness scores
as feedback, DLPO aligns reward optimization with the diffusion model's
structure, improving speech quality. We evaluate DLPO on WaveGrad 2, a
non-autoregressive diffusion-based TTS model. Results show significant
improvements in objective metrics (UTMOS 3.65, NISQA 4.02) and subjective
evaluations, with DLPO audio preferred 67\% of the time. These findings
demonstrate DLPO's potential for efficient, high-quality diffusion TTS in
real-time, resource-limited settings.

</details>


### [38] [MiSTR: Multi-Modal iEEG-to-Speech Synthesis with Transformer-Based Prosody Prediction and Neural Phase Reconstruction](https://arxiv.org/abs/2508.03166)
*Mohammed Salah Al-Radhi,Géza Németh,Branislav Gerazov*

Main category: cs.SD

TL;DR: MiSTR是一种深度学习框架，用于从颅内脑电图（iEEG）信号合成语音，通过小波特征提取、Transformer解码器和神经相位声码器提升语音清晰度和自然度。


<details>
  <summary>Details</summary>
Motivation: 为严重语言障碍患者恢复交流能力，解决现有方法在特征表示、韵律建模和相位重建上的不足。

Method: 结合小波特征提取、Transformer解码器和神经相位声码器，优化iEEG信号的表示和语音合成质量。

Result: 在公开iEEG数据集上，MiSTR的语音清晰度达到最佳水平，Mel频谱图重建的Pearson相关系数为0.91。

Conclusion: MiSTR在iEEG语音合成中表现出色，为语言障碍患者提供了潜在的交流解决方案。

Abstract: Speech synthesis from intracranial EEG (iEEG) signals offers a promising
avenue for restoring communication in individuals with severe speech
impairments. However, achieving intelligible and natural speech remains
challenging due to limitations in feature representation, prosody modeling, and
phase reconstruction. We introduce MiSTR, a deep-learning framework that
integrates: 1) Wavelet-based feature extraction to capture fine-grained
temporal, spectral, and neurophysiological representations of iEEG signals, 2)
A Transformer-based decoder for prosody-aware spectrogram prediction, and 3) A
neural phase vocoder enforcing harmonic consistency via adaptive spectral
correction. Evaluated on a public iEEG dataset, MiSTR achieves state-of-the-art
speech intelligibility, with a mean Pearson correlation of 0.91 between
reconstructed and original Mel spectrograms, improving over existing neural
speech synthesis baselines.

</details>


### [39] [When Good Sounds Go Adversarial: Jailbreaking Audio-Language Models with Benign Inputs](https://arxiv.org/abs/2508.03365)
*Bodam Kim,Hiskias Dingeto,Taeyoun Kwon,Dasol Choi,DongGeon Lee,Haon Park,JaeHoon Lee,Jongho Shin*

Main category: cs.SD

TL;DR: WhisperInject是一种两阶段对抗性音频攻击框架，能够操纵音频语言模型生成有害内容，成功率达86%以上。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型在日常生活中的普及，音频成为人机交互的关键接口，但也带来了新的安全漏洞。研究旨在揭示音频作为攻击面的潜在威胁。

Method: 第一阶段使用基于奖励的优化方法RL-PGD绕过模型安全协议；第二阶段通过PGD将扰动嵌入良性音频载体。

Result: 在多个模型上验证，攻击成功率达86%以上。

Conclusion: WhisperInject展示了音频原生威胁的可行性，为AI行为操纵提供了隐蔽方法。

Abstract: As large language models become increasingly integrated into daily life,
audio has emerged as a key interface for human-AI interaction. However, this
convenience also introduces new vulnerabilities, making audio a potential
attack surface for adversaries. Our research introduces WhisperInject, a
two-stage adversarial audio attack framework that can manipulate
state-of-the-art audio language models to generate harmful content. Our method
uses imperceptible perturbations in audio inputs that remain benign to human
listeners. The first stage uses a novel reward-based optimization method,
Reinforcement Learning with Projected Gradient Descent (RL-PGD), to guide the
target model to circumvent its own safety protocols and generate harmful native
responses. This native harmful response then serves as the target for Stage 2,
Payload Injection, where we use Projected Gradient Descent (PGD) to optimize
subtle perturbations that are embedded into benign audio carriers, such as
weather queries or greeting messages. Validated under the rigorous
StrongREJECT, LlamaGuard, as well as Human Evaluation safety evaluation
framework, our experiments demonstrate a success rate exceeding 86% across
Qwen2.5-Omni-3B, Qwen2.5-Omni-7B, and Phi-4-Multimodal. Our work demonstrates a
new class of practical, audio-native threats, moving beyond theoretical
exploits to reveal a feasible and covert method for manipulating AI behavior.

</details>


### [40] [SonicMaster: Towards Controllable All-in-One Music Restoration and Mastering](https://arxiv.org/abs/2508.03448)
*Jan Melechovsky,Ambuj Mehrish,Dorien Herremans*

Main category: cs.SD

TL;DR: SonicMaster是一个统一的生成模型，用于音乐修复和母带处理，通过文本控制解决多种音频问题。


<details>
  <summary>Details</summary>
Motivation: 解决非专业环境下音乐录音常见的音频质量问题，如混响、失真、削波等，传统方法需要多个工具和手动调整。

Method: 使用基于自然语言指令的生成模型，结合流匹配生成训练范式，利用模拟退化的数据集进行训练。

Result: SonicMaster在所有音频问题类别中显著提升音质，主观测试显示用户偏好其输出。

Conclusion: SonicMaster提供了一个高效统一的解决方案，适用于广泛的音频修复和母带处理任务。

Abstract: Music recordings often suffer from audio quality issues such as excessive
reverberation, distortion, clipping, tonal imbalances, and a narrowed stereo
image, especially when created in non-professional settings without specialized
equipment or expertise. These problems are typically corrected using separate
specialized tools and manual adjustments. In this paper, we introduce
SonicMaster, the first unified generative model for music restoration and
mastering that addresses a broad spectrum of audio artifacts with text-based
control. SonicMaster is conditioned on natural language instructions to apply
targeted enhancements, or can operate in an automatic mode for general
restoration. To train this model, we construct the SonicMaster dataset, a large
dataset of paired degraded and high-quality tracks by simulating common
degradation types with nineteen degradation functions belonging to five
enhancements groups: equalization, dynamics, reverb, amplitude, and stereo. Our
approach leverages a flow-matching generative training paradigm to learn an
audio transformation that maps degraded inputs to their cleaned, mastered
versions guided by text prompts. Objective audio quality metrics demonstrate
that SonicMaster significantly improves sound quality across all artifact
categories. Furthermore, subjective listening tests confirm that listeners
prefer SonicMaster's enhanced outputs over the original degraded audio,
highlighting the effectiveness of our unified approach.

</details>


### [41] [EmoSteer-TTS: Fine-Grained and Training-Free Emotion-Controllable Text-to-Speech via Activation Steering](https://arxiv.org/abs/2508.03543)
*Tianxin Xie,Shan Yang,Chenxing Li,Dong Yu,Li Liu*

Main category: cs.SD

TL;DR: EmoSteer-TTS提出了一种无需训练的细粒度语音情感控制方法，通过激活导向实现情感转换、插值和擦除。


<details>
  <summary>Details</summary>
Motivation: 现有TTS系统情感控制粗糙且依赖高质量数据集，EmoSteer-TTS旨在解决这些问题。

Method: 通过修改流匹配TTS模型的内部激活，结合激活提取、情感标记搜索和推理时导向算法。

Result: 实验表明EmoSteer-TTS在细粒度情感控制上优于现有方法。

Conclusion: EmoSteer-TTS首次实现了无需训练的连续细粒度情感控制。

Abstract: Text-to-speech (TTS) has shown great progress in recent years. However, most
existing TTS systems offer only coarse and rigid emotion control, typically via
discrete emotion labels or a carefully crafted and detailed emotional text
prompt, making fine-grained emotion manipulation either inaccessible or
unstable. These models also require extensive, high-quality datasets for
training. To address these limitations, we propose EmoSteer-TTS, a novel
training-free approach, to achieve fine-grained speech emotion control
(conversion, interpolation, erasure) by activation steering. We first
empirically observe that modifying a subset of the internal activations within
a flow matching-based TTS model can effectively alter the emotional tone of
synthesized speech. Building on this insight, we then develop a training-free
and efficient algorithm, including activation extraction, emotional token
searching, and inference-time steering, which can be seamlessly integrated into
a wide range of pretrained models (e.g., F5-TTS, CosyVoice2, and E2-TTS). In
addition, to derive effective steering vectors, we construct a curated
emotional speech dataset with diverse speakers. Extensive experiments
demonstrate that EmoSteer-TTS enables fine-grained, interpretable, and
continuous control over speech emotion, outperforming the state-of-the-art
(SOTA). To the best of our knowledge, this is the first method that achieves
training-free and continuous fine-grained emotion control in TTS.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 26]
- [eess.AS](#eess.AS) [Total: 19]
- [cs.SD](#cs.SD) [Total: 16]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [A Completely Blind Channel Estimation Technique for OFDM Using Generalized Constellation Splitting and Modified Phase-Directed Algorithm](https://arxiv.org/abs/2508.06508)
*Sameera Bharadwaja H.,D. K. Mehra*

Main category: eess.SP

TL;DR: 论文提出了一种解决SISO-OFDM系统中盲信道估计问题的算法，通过广义星座分裂和改进的相位导向算法解决了传统方法中的复标量估计模糊问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于二阶统计量的盲信道估计方法存在复标量估计模糊问题，需要使用导频符号解决，但这违背了盲方法的初衷。

Method: 提出了一种结合广义星座分裂和改进的相位导向算法的盲方法，无需导频符号即可解决模糊问题。

Result: 通过MATLAB数值仿真验证了所提算法的性能。

Conclusion: 所提算法在保持盲方法优势的同时，有效解决了复标量估计模糊问题。

Abstract: The problem of blind channel estimation for SISO-OFDM systems using
second-order statistics (SOS) is addressed. A comparison of two prominent
SOS-based techniques: subspace-decomposition and precoding-induced
correlation-averaging techniques in terms of MSE performance is presented. The
drawback of these methods is that they suffer from a complex-scalar estimation
ambiguity which is resolved by using pilots or reference symbols. By using
pilots the whole purpose of blind techniques is contradicted. We propose an
algorithm to resolve this ambiguity in blind manner using generalized
constellation-splitting and modified phase-directed algorithm. The performance
of the proposed scheme is evaluated via numerical simulations in MATLAB
environment.

</details>


### [2] [GPU-accelerated Direct Geolocation of GNSS Interference](https://arxiv.org/abs/2508.06672)
*Jacob S. Clements,Zachary L. Clements*

Main category: eess.SP

TL;DR: 论文提出了一种利用GPU加速的直接地理定位方法，以解决低地球轨道卫星中GNSS干扰检测的高计算需求问题。


<details>
  <summary>Details</summary>
Motivation: 近年来，GNSS干扰急剧增加，而现有接收器缺乏有效防御措施，低地球轨道卫星为干扰检测提供了机会，但传统直接地理定位方法计算负担大。

Method: 通过利用位置域相关性在候选点和时间步上的独立性，将计算任务并行化在GPU上实现加速。

Result: GPU加速的直接地理定位方法显著降低了计算负担，性能优于传统CPU处理。

Conclusion: GPU加速的直接地理定位方法为GNSS干扰检测提供了一种高效解决方案，适用于低地球轨道卫星的实时应用。

Abstract: In recent years, there has been a sharp increase in Global Navigation
Satellite Systems (GNSS) interference, which has proven to be problematic in
GNSS-dependent civilian applications. Many currently deployed GNSS receivers
lack the proper countermeasures to defend themselves against interference,
prompting the need for alternative defenses. Satellites in Low Earth Orbit
(LEO) provide an opportunity for GNSS interference detection, classification,
and localization. The direct geolocation approach has been shown to be
well-suited for low SNR regimes and in cases limited to short captures --
exactly what is expected for receivers in LEO. Direct geolocation is a
single-step search over a geographical grid that enables estimation of the
transmitter location directly from correlating raw observed signals. However, a
key limitation to this approach is the computational requirements. This
computational burden is compounded for LEO-based receivers as the geographic
search space is extensive. This paper alleviates the computational burden of
direct geolocation by exploiting the independence of position-domain
correlation across candidate points and time steps: nearly all computation can
be accomplished in parallel on a graphics processing unit (GPU). This paper
presents and evaluates the performance of GPU-accelerated direct geolocation
compared to traditional CPU processing.

</details>


### [3] [Physical Layer Authentication Based on Hierarchical Variational Auto-Encoder for Industrial Internet of Things](https://arxiv.org/abs/2508.06794)
*Rui Meng,Xiaodong Xu,Bizhu Wang,Hao Sun,Shida Xia,Shujun Han,Ping Zhang*

Main category: eess.SP

TL;DR: 提出了一种基于CIR的PLA方案HVAE，用于IIoT环境，无需攻击者先验信道信息即可实现高性能认证。


<details>
  <summary>Details</summary>
Motivation: 现有PLA方案在IIoT中需要攻击者的先验信道信息，导致性能下降，尤其在信号来源未知时。

Method: 结合AE和VAE模块，提取CIR特征并提升表示能力，同时设计新目标函数考虑单峰和双峰高斯分布。

Result: 仿真验证HVAE在静态和移动IIoT场景下优于其他三种PLA方案，即使训练数据较少。

Conclusion: HVAE在复杂环境中无需先验信息即可实现高效认证，适用于IIoT。

Abstract: Recently, Physical Layer Authentication (PLA) has attracted much attention
since it takes advantage of the channel randomness nature of transmission media
to achieve communication confidentiality and authentication. In the complex
environment, such as the Industrial Internet of Things (IIoT), machine learning
(ML) is widely employed with PLA to extract and analyze complex channel
characteristics for identity authentication. However, most PLA schemes for IIoT
require attackers' prior channel information, leading to severe performance
degradation when the source of the received signals is unknown in the training
stage. Thus, a channel impulse response (CIR)-based PLA scheme named
"Hierarchical Variational Auto-Encoder (HVAE)" for IIoT is proposed in this
article, aiming at achieving high authentication performance without knowing
attackers' prior channel information even when trained on a few data in the
complex environment. HVAE consists of an Auto-Encoder (AE) module for CIR
characteristics extraction and a Variational Auto-Encoder (VAE) module for
improving the representation ability of the CIR characteristic and outputting
the authentication results. Besides, a new objective function is constructed in
which both the single-peak and the double-peak Gaussian distribution are taken
into consideration in the VAE module. Moreover, the simulations are conducted
under the static and mobile IIoT scenario, which verify the superiority of the
proposed HVAE over three comparison PLA schemes even with a few training data.

</details>


### [4] [Deep Domain-Adversarial Adaptation for Automatic Modulation Classification under Channel Variability](https://arxiv.org/abs/2508.06829)
*K. A. Shahriar*

Main category: eess.SP

TL;DR: 提出了一种基于域对抗神经网络（DANN）的深度学习框架，用于自动调制分类（AMC），以解决无线信道条件变化带来的分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 在认知和智能无线电系统中，准确的调制识别对自适应通信至关重要，但传统AMC模型在异构无线信道条件下泛化能力不足。

Method: 使用DANN框架，显式缓解源域和目标域之间的信道诱导分布偏移，并在模拟数据集上进行评估。

Result: DANN模型在特定调制情况下比基线模型绝对准确率提升14.93%，验证了其在实际信道变化中的工程可行性。

Conclusion: DANN为自适应频谱智能的未来研究提供了稳健方向。

Abstract: Automatic Modulation Classification (AMC) plays a significant role in modern
cognitive and intelligent radio systems, where accurate identification of
modulation is crucial for adaptive communication. The presence of heterogeneous
wireless channel conditions, such as Rayleigh and Rician fading, poses
significant challenges to the generalization ability of conventional AMC
models. In this work, a domain-adversarial neural network (DANN) based deep
learning framework is proposed that explicitly mitigates channel-induced
distribution shifts between source and target domains. The approach is
evaluated using a comprehensive simulated dataset containing five modulation
schemes (BPSK, QPSK, 16QAM, 64QAM, 256QAM) across Rayleigh and Rician fading
channels at five frequency bands. Comparative experiments demonstrate that the
DANN-based model achieves up to 14.93% absolute accuracy improvement in certain
modulation cases compared to a baseline supervised model trained solely on the
source domain. The findings establish the engineering feasibility of domain
adversarial learning in AMC tasks under real-world channel variability and
offer a robust direction for future research in adaptive spectrum intelligence

</details>


### [5] [Secure Transmission for Cell-Free Symbiotic Radio Communications with Movable Antenna: Continuous and Discrete Positioning Designs](https://arxiv.org/abs/2508.06868)
*Bin Lyu,Jiayu Guan,Meng Hua,Changsheng You,Tianqi Mao,Abbas Jamalipour*

Main category: eess.SP

TL;DR: 论文研究了基于可移动天线（MA）的安全传输方案，用于RIS辅助的无蜂窝共生无线电系统，通过优化MA位置提升主次传输的安全性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决RIS辅助系统中主次传输的安全性和效率问题，特别是通过MA的协同优化抑制窃听风险。

Method: 针对连续和离散MA位置，分别提出基于DEO的两层迭代优化方法和AO迭代框架，降低计算复杂度。

Result: 数值结果验证了所提方案及优化算法的有效性，显著提升了主传输的保密速率。

Conclusion: MA与RIS协同优化能有效提升系统安全性和性能，提出的算法在计算复杂度和性能间取得了平衡。

Abstract: In this paper, we study a movable antenna (MA) empowered secure transmission
scheme for reconfigurable intelligent surface (RIS) aided cell-free symbiotic
radio (SR) system. Specifically, the MAs deployed at distributed access points
(APs) work collaboratively with the RIS to establish high-quality propagation
links for both primary and secondary transmissions, as well as suppressing the
risk of eavesdropping on confidential primary information. We consider both
continuous and discrete MA position cases and maximize the secrecy rate of
primary transmission under the secondary transmission constraints,
respectively. For the continuous position case, we propose a two-layer
iterative optimization method based on differential evolution with one-in-one
representation (DEO), to find a high-quality solution with relatively moderate
computational complexity. For the discrete position case, we first extend the
DEO based iterative framework by introducing the mapping and determination
operations to handle the characteristic of discrete MA positions. To further
reduce the computational complexity, we then design an alternating optimization
(AO) iterative framework to solve all variables within a single layer. In
particular, we develop an efficient strategy to derive the sub-optimal solution
for the discrete MA positions, superseding the DEO-based method. Numerical
results validate the effectiveness of the proposed MA empowered secure
transmission scheme along with its optimization algorithms.

</details>


### [6] [Extremely Large-Scale Dynamic Metasurface Antennas for 6G Near-Field Networks: Opportunities and Challenges](https://arxiv.org/abs/2508.06952)
*Haiyang Zhang,Nir Shlezinger,Giulia Torcolacci,Francesco Guidi,Anna Guerra,Qianyu Yang,Mohammadreza F. Imani,Davide Dardari,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 6G网络需要支持更高数据速率、高精度定位和成像能力，XL-DMAs（超大规模动态超表面天线）因其低功耗和低成本成为理想解决方案。本文探讨了XL-DMAs在6G近场网络中的机遇与挑战，包括基本原理、应用场景及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 6G网络对数据速率、定位和成像的高要求需要新的物理层解决方案，传统架构的高功耗和高成本限制了其应用，XL-DMAs提供了替代方案。

Method: 介绍了XL-DMAs的基本原理和近场模型，并探讨了其在通信、定位和成像中的应用。

Result: XL-DMAs在6G近场网络中展现出巨大潜力，但需解决多个开放性问题。

Conclusion: XL-DMAs是6G近场网络的关键技术，未来研究需进一步优化其性能和应用范围。

Abstract: 6G networks will need to support higher data rates, high-precision
localization, and imaging capabilities. Near-field technologies, enabled by
extremely large-scale (XL)-arrays, are expected to be essential physical-layer
solutions to meet these ambitious requirements. However, implementing XL-array
systems using traditional fully-digital or hybrid analog/digital architectures
poses significant challenges due to high power consumption and implementation
costs. Emerging XL-dynamic metasurface antennas (XL-DMAs) provide a promising
alternative, enabling ultra-low power and cost-efficient solutions, making them
ideal candidates for 6G near-field networks. In this article, we discuss the
opportunities and challenges of XL-DMAs employed in 6G near-field networks. We
first outline the fundamental principles of XL-DMAs and present the specifics
of the near-field model of XL-DMAs. We then highlight several promising
applications that might benefit from XL-DMAs, including near-field
communication, localization, and imaging. Finally, we discuss several open
problems and potential future directions that should be addressed to fully
exploit the capabilities of XL-DMAs in the next 6G near-field networks.

</details>


### [7] [Millimeter-Wave Position Sensing Using Reconfigurable Intelligent Surfaces: Positioning Error Bound and Phase Shift Configuration](https://arxiv.org/abs/2508.06958)
*Xin Cheng,Guangjie Han,Menglu Li,Ruoguang Li,Feng Shu*

Main category: eess.SP

TL;DR: 该论文研究了基于多RIS辅助的3D MISO毫米波定位系统，提出了两种优化方法以降低定位误差，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 毫米波定位是下一代智能系统的关键技术，而RIS的动态环境操控能力为高精度定位提供了新机遇。

Method: 提出了一种结合顺序RIS激活和定向波束成形的测量框架，并针对RIS的连续和离散相位配置分别提出了优化算法。

Result: 数值仿真表明，所提算法能有效降低定位误差，多RIS的引入显著提升了定位精度。

Conclusion: 多RIS辅助的毫米波定位系统具有高精度潜力，所提优化方法为实际应用提供了有效解决方案。

Abstract: Millimeter-wave (mmWave) positioning has emerged as a promising technology
for next-generation intelligent systems. The advent of reconfigurable
intelligent surfaces (RISs) has revolutionized high-precision mmWave
localization by enabling dynamic manipulation of wireless propagation
environments. This paper investigates a three-dimensional (3D) multi-input
single-output (MISO) mmWave positioning system assisted by multiple RISs. We
introduce a measurement framework incorporating sequential RIS activation and
directional beamforming to fully exploit virtual line-of-sight (VLoS) paths.
The theoretical performance limits are rigorously analyzed through derivation
of the Fisher information and subsequent positioning error bound (PEB). To
minimize the PEB, two distinct optimization approaches are proposed for
continuous and discrete phase shift configurations of RISs. For continuous
phase shifts, a Riemannian manifold-based optimization algorithm is proposed.
For discrete phase shifts, a heuristic algorithm incorporating the grey wolf
optimizer is proposed. Extensive numerical simulations demonstrate the
effectiveness of the proposed algorithms in reducing the PEB and validate the
improvement in positioning accuracy achieved by multiple RISs.

</details>


### [8] [Joint Beamforming Optimization for Pinching-Antenna Systems (PASS)-assisted Symbiotic Radio](https://arxiv.org/abs/2508.07002)
*Ze Wang,Guoping Zhang,Hongbo Xu*

Main category: eess.SP

TL;DR: 论文提出了一种基于可调天线系统（PASS）的下行共生无线电（SR）框架，通过优化天线位置和波束成形，提升主次传输性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过可重构天线位置同时优化大尺度路径损耗和信号相位，以增强主次传输的效率。

Method: 提出了两种解决方案：1）基于学习的梯度下降（LGD）算法，通过端到端学习优化问题；2）两阶段优化方法（SCA-PSO），先优化波束成形，再通过粒子群优化（PSO）搜索天线位置。

Result: SCA-PSO算法在性能接近逐元素方法的同时显著降低计算复杂度，并优于LGD方法，避免了局部最优。

Conclusion: PASS框架通过灵活的天线位置调整和优化算法，有效提升了SR系统的传输性能。

Abstract: This paper investigates a novel downlink symbiotic radio (SR) framework
empowered by the pinching antenna system (PASS), aiming to enhance both primary
and secondary transmissions through reconfigurable antenna positioning. PASS
consists of multiple waveguides equipped with numerous low-cost pinching
antennas (PAs), whose positions can be flexibly adjusted to simultaneously
manipulate large-scale path loss and signal phases.We formulate a joint
transmit and pinching beamforming optimization problem to maximize the
achievable sum rate while satisfying the detection error probability constraint
for the IR and the feasible deployment region constraints for the PAs. This
problem is inherently nonconvex and highly coupled. To address it, two solution
strategies are developed. 1) A learning-aided gradient descent (LGD) algorithm
is proposed, where the constrained problem is reformulated into a
differentiable form and solved through end-to-end learning based on the
principle of gradient descent. The PA position matrix is reparameterized to
inherently satisfy minimum spacing constraints, while transmit power and
waveguide length limits are enforced via projection and normalization. 2) A
two-stage optimization-based approach is designed, in which the transmit
beamforming is first optimized via successive convex approximation (SCA),
followed by pinching beamforming optimization using a particle swarm
optimization (PSO) search over candidate PA placements. The SCA-PSO algorithm
achieves performance close to that of the element-wise method while
significantly reducing computational complexity by exploring a randomly
generated effective solution subspace, while further improving upon the LGD
method by avoiding undesirable local optima.

</details>


### [9] [Robust Super-Resolution Compressive Sensing: A Two-timescale Alternating MAP Approach](https://arxiv.org/abs/2508.07013)
*Yufan Zhou,Jingyi Li,Wenkang Xu,An Liu*

Main category: eess.SP

TL;DR: 提出了一种基于双时间尺度交替最大后验（MAP）的鲁棒超分辨率压缩感知框架，解决了现有方法分辨率有限和对超参数敏感的问题。


<details>
  <summary>Details</summary>
Motivation: 现有超分辨率压缩感知方法在网格参数不精确或密集时表现不佳，限制了稀疏信号恢复的准确性。

Method: 采用双时间尺度交替MAP框架，结合双曲正切先验的变分贝叶斯推断（tanh-VBI）和BFGS算法，实现稀疏信号估计和网格参数超分辨率优化。

Result: 仿真结果表明，该方法在信道外推问题中优于基线方案。

Conclusion: 提出的框架在稀疏信号恢复和网格参数超分辨率估计方面具有优越性和低计算成本。

Abstract: The problem of super-resolution compressive sensing (SR-CS) is crucial for
various wireless sensing and communication applications. Existing methods often
suffer from limited resolution capabilities and sensitivity to
hyper-parameters, hindering their ability to accurately recover sparse signals
when the grid parameters do not lie precisely on a fixed grid and are close to
each other. To overcome these limitations, this paper introduces a novel robust
super-resolution compressive sensing algorithmic framework using a
two-timescale alternating maximum a posteriori (MAP) approach. At the slow
timescale, the proposed framework iterates between a sparse signal estimation
module and a grid update module. In the sparse signal estimation module, a
hyperbolic-tangent prior distribution based variational Bayesian inference
(tanh-VBI) algorithm with a strong sparsity promotion capability is adopted to
estimate the posterior probability of the sparse vector and accurately identify
active grid components carrying primary energy under a dense grid.
Subsequently, the grid update module utilizes the BFGS algorithm to refine
these low-dimensional active grid components at a faster timescale to achieve
super-resolution estimation of the grid parameters with a low computational
cost. The proposed scheme is applied to the channel extrapolation problem, and
simulation results demonstrate the superiority of the proposed scheme compared
to baseline schemes.

</details>


### [10] [Pinching-Antenna System Design with LoS Blockage: Does In-Waveguide Attenuation Matter?](https://arxiv.org/abs/2508.07131)
*Yanqing Xu,Zhiguo Ding,Octavia A. Dobre,Tsung-Hui Chang*

Main category: eess.SP

TL;DR: 本文研究了波导内衰减在夹持天线系统中的影响，扩展了分析至更现实的场景，包括任意程度的视距阻塞，并提出了一种动态样本平均近似算法以优化性能。


<details>
  <summary>Details</summary>
Motivation: 现有文献中波导内衰减常被忽略，但其对系统性能的影响尚未充分研究，尤其是在非理想视距条件下。

Method: 从单用户场景出发推导了波导内衰减忽略导致的数据速率损失表达式，并扩展到多用户场景，提出动态样本平均近似算法优化天线位置和波束成形。

Result: 结果表明，即使在大服务区域下，典型视距阻塞条件下速率损失可忽略；动态算法在多用户场景中显著提升了系统性能。

Conclusion: 波导内衰减在典型条件下影响可忽略，动态算法能有效优化夹持天线系统性能，尤其在视距阻塞显著的环境中。

Abstract: In the literature of pinching-antenna systems, in-waveguide attenuation is
often neglected to simplify system design and enable more tractable analysis.
However, its effect on overall system performance has received limited
attention in the existing literature. While a recent study has shown that, in
line-of-sight (LoS)-dominated environments, the data rate loss incurred by
omitting in-waveguide attenuation is negligible when the communication area is
not excessively large, its effect under more general conditions remains
unclear. This work extends the analysis to more realistic scenarios involving
arbitrary levels of LoS blockage. We begin by examining a single-user case and
derive an explicit expression for the average data rate loss caused by
neglecting in-waveguide attenuation. The results demonstrate that, even for
large service areas, the rate loss remains negligible under typical LoS
blockage conditions. We then consider a more general multi-user scenario, where
multiple pinching antennas, each deployed on a separate waveguide, jointly
serve multiple users. The objective is to maximize the average sum rate by
jointly optimize antenna positions and transmit beamformers to maximize the
average sum rate under probabilistic LoS blockage. To solve the resulting
stochastic and nonconvex optimization problem, we propose a dynamic sample
average approximation (SAA) algorithm. At each iteration, this method replaces
the expected objective with an empirical average computed from dynamically
regenerated random channel realizations, ensuring that the optimization
accurately reflects the current antenna configuration. Extensive simulation
results are provided to the proposed algorithm and demonstrate the substantial
performance gains of pinching-antenna systems, particularly in environments
with significant LoS blockage.

</details>


### [11] [Low-Complexity Equalization of Zak-OTFS in the Frequency Domain](https://arxiv.org/abs/2508.07148)
*Sandesh Rao Mattu,Nishant Mehrotra,Saif Khan Mohammed,Venkatesh Khammammetti,Robert Calderbank*

Main category: eess.SP

TL;DR: 本文提出了一种低复杂度的频域（FD）均衡方法用于Zak-OTFS调制，解决了传统OFDM在移动性下性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: OFDM在移动性下因多普勒扩展导致性能下降，而Zak-OTFS对双选择性信道具有鲁棒性，但其均衡复杂度高。

Method: 提出频域均衡方法，推导FD系统模型，证明其与DD模型等价，并利用共轭梯度法降低复杂度。

Result: FD均衡复杂度与帧维度线性相关，性能与DD域均衡相当。

Conclusion: 频域均衡为Zak-OTFS提供了一种低复杂度的解决方案，适用于实际应用。

Abstract: 4G/5G wireless standards use orthogonal frequency division multiplexing
(OFDM) which is robust to frequency selectivity. Equalization is possible with
a single tap filter, and low-complexity equalization makes OFDM an attractive
physical layer. However the performance of OFDM degrades with mobility, since
Doppler spreads introduce inter-carrier interference (ICI) between subcarriers
and they are no longer orthogonal. Zak-transform based orthogonal time
frequency space (Zak-OTFS) modulation has been shown to be robust to doubly
selective channels. Zak-OTFS signals are formed in the delay-Doppler (DD)
domain, converted to time domain (TD) for transmission and reception, then
returned to the DD domain for processing. The received signal is a
superposition of many attenuated copies since the doubly selective channel
introduces delay and Doppler shifts. The received symbols are more difficult to
equalize since they are subject to interference along both delay and Doppler
axes. In this paper, we propose a new low-complexity method of equalizing
Zak-OTFS in the frequency domain (FD). We derive the FD system model and show
that it is unitarily equivalent to the DD system model. We show that the
channel matrix in the FD is banded, making it possible to apply conjugate
gradient methods to reduce the complexity of equalization. We show that
complexity of FD equalization is linear in the dimension of a Zak-OTFS frame.
For comparison the complexity of naive MMSE equalization is cubic in the frame
dimension. Through numerical simulations we show that FD equalization of
Zak-OTFS achieves similar performance as equalization in DD domain.

</details>


### [12] [Vector Orthogonal Chirp Division Multiplexing Over Doubly Selective Channels](https://arxiv.org/abs/2508.07160)
*Deyu Lu,Xiaoli Ma,Yiyin Wang*

Main category: eess.SP

TL;DR: 论文将正交啁啾分频复用（OCDM）扩展为向量OCDM（VOCDM），以提供更多设计自由度应对双选择性信道。通过M个并行的N点离散菲涅尔逆变换实现VOCDM调制，并基于CE-BEM模型推导输入输出关系，分析性能权衡。


<details>
  <summary>Details</summary>
Motivation: 扩展OCDM以应对双选择性信道，提供更多设计自由度。

Method: 通过M个并行的N点离散菲涅尔逆变换实现VOCDM调制，基于CE-BEM模型推导输入输出关系。

Result: 在双选择性信道下，VOCDM表现出优越的分集性能，且PAPR随N减小而降低。

Conclusion: VOCDM在满足特定约束条件下具有优越性能，理论结果通过数值模拟验证。

Abstract: In this letter, we extend orthogonal chirp division multiplexing (OCDM) to
vector OCDM (VOCDM) to provide more design freedom to deal with doubly
selective channels. The VOCDM modulation is implemented by performing M
parallel N-size inverse discrete Fresnel transforms (IDFnT). Based on the
complex exponential basis expansion model (CE-BEM) for doubly selective
channels, we derive the VOCDM input-output relationship, and show performance
tradeoffs of VOCDM with respect to (w.r.t.) its modulation parameters M and N.
Specifically, we investigate the diversity and peak-to-average power ratio
(PAPR) of VOCDM w.r.t. M and N. Under doubly selective channels, VOCDM exhibits
superior diversity performance as long as the parameters M and N are configured
to satisfy some constraints from the delay and the Doppler spreads of the
channel, respectively. Furthermore, the PAPR of VOCDM signals decreases with a
decreasing N. These theoretical findings are verified through numerical
simulations.

</details>


### [13] [Applying the Spectral Method for Modeling Linear Filters: Butterworth, Linkwitz-Riley, and Chebyshev filters](https://arxiv.org/abs/2508.07206)
*Konstantin A. Rybakov,Egor D. Shermatov*

Main category: eess.SP

TL;DR: 提出了一种基于线性系统频谱描述的计算机建模技术，用于连续时间输出信号建模。


<details>
  <summary>Details</summary>
Motivation: 传统线性滤波器建模方法可能无法高效处理连续时间信号，需要一种更灵活的技术。

Method: 通过正交展开表示输入输出信号，并使用二维非平稳传递函数描述滤波器。

Result: 成功应用于Butterworth、Linkwitz-Riley和Chebyshev滤波器，验证了技术的有效性。

Conclusion: 该技术为线性滤波器的连续时间建模提供了新方法，具有广泛的应用潜力。

Abstract: This paper proposes a new technique for computer modeling linear filters
based on the spectral form of mathematical description of linear systems. It
assumes that input and output signals of the filter are represented as
orthogonal expansions, while filters themselves are described by
two-dimensional non-stationary transfer functions. This technique allows one to
model the output signal in continuous time, and it is successfully tested on
the Butterworth, Linkwitz-Riley, and Chebyshev filters with different orders.

</details>


### [14] [Multi-RIS Deployment Optimization for mmWave ISAC Systems in Real-World Environments](https://arxiv.org/abs/2508.07226)
*Yueheng Li,Xueyun Long,Mario Pauli,Suheng Tian,Xiang Wan,Benjamin Nuss,Tiejun Cui,Haixia Zhang,Thomas Zwick*

Main category: eess.SP

TL;DR: 本文研究了可重构智能表面辅助的集成感知与通信系统（RIS-ISAC），通过优化多RIS部署提升毫米波频段的通信覆盖和感知精度。


<details>
  <summary>Details</summary>
Motivation: 未来空地一体化网络中，RIS部署的设计与评估对增强ISAC功能至关重要，本文旨在解决这一问题。

Method: 建立多RIS-ISAC系统模型，提出基于能量效率的优化问题，并设计两步迭代算法求解非凸混合整数问题。

Result: 仿真结果表明，优化后的RIS部署显著提升了通信覆盖和感知精度，同时最小化RIS尺寸。

Conclusion: 本文提出的方法在毫米波频段实现了高效的RIS部署，优于现有方案。

Abstract: Reconfigurable intelligent surface-assisted integrated sensing and
communication (RIS-ISAC) presents a promising system architecture to leverage
the wide bandwidth available at millimeter-wave (mmWave) frequencies, while
mitigating severe signal propagation losses and reducing infrastructure costs.
To enhance ISAC functionalities in the future air-ground integrated network
applications, RIS deployment must be carefully designed and evaluated, which
forms the core motivation of this paper. To ensure practical relevance, a
multi-RIS-ISAC system is established, with its signal model at mmWave
frequencies demonstrated using ray-launching calibrated to real-world
environments. On this basis, an energy-efficiency-driven optimization problem
is formulated to minimize the multi-RIS size-to-coverage sum ratio,
comprehensively considering real-world RIS deployment constraints, positions,
orientations, as well as ISAC beamforming strategies at both the base station
and the RISs. To solve the resulting non-convex mixed-integer problem, a
simplified reformulation based on equivalent gain scaling method is introduced.
A two-step iterative algorithm is then proposed, in which the deployment
parameters are determined under fixed RIS positions in the first step, and the
RIS position set is updated in the second step to progressively approach the
optimum solution. Simulation results based on realistic parameter benchmarks
present that the optimized RISs deployment significantly enhances communication
coverage and sensing accuracy with the minimum RIS sizes, outperforming
existing approaches.

</details>


### [15] [A Scalable Machine Learning Approach Enabled RIS Optimization with Implicit Channel Estimation](https://arxiv.org/abs/2508.07265)
*Bile Peng,Vahid Jamali,Eduard Jorswieck*

Main category: eess.SP

TL;DR: 论文提出了一种基于无监督机器学习的RIS优化方法，通过RISnet神经网络架构直接映射接收信号到RIS配置，无需显式信道估计，显著优于基线方法。


<details>
  <summary>Details</summary>
Motivation: RIS因其被动性和低成本成为下一代移动通信系统的关键，但其可扩展性和信道状态信息需求是主要挑战。

Method: 结合RISnet神经网络架构和隐式信道估计方法，直接学习从接收信号到RIS配置的映射。

Result: 仿真结果表明，所提算法显著优于基线方法。

Conclusion: 无监督机器学习方法为RIS配置提供了一种高效且无需显式信道估计的解决方案。

Abstract: The reconfigurable intelligent surface (RIS) is considered as a key enabler
of the next-generation mobile radio systems. While attracting extensive
interest from academia and industry due to its passive nature and low cost,
scalability of RIS elements and requirement for channel state information (CSI)
are two major difficulties for the RIS to become a reality. In this work, we
introduce an unsupervised machine learning (ML) enabled optimization approach
to configure the RIS. The dedicated neural network (NN) architecture RISnet is
combined with an implicit channel estimation method. The RISnet learns to map
from received pilot signals to RIS configuration directly without explicit
channel estimation. Simulation results show that the proposed algorithm
outperforms baselines significantly.

</details>


### [16] [Channel Charting in Smart Radio Environments](https://arxiv.org/abs/2508.07305)
*Mahdi Maleki,Reza Agahzadeh Ayoubi,Marouan Mizmizi,Umberto Spagnolini*

Main category: eess.SP

TL;DR: 论文提出利用静态电磁表面（EMS）提升设备定位性能，通过优化框架设计EMS相位配置，显著降低了定位误差并提高了可信度和连续性。


<details>
  <summary>Details</summary>
Motivation: 在复杂的城市环境中，非视距（NLoS）条件下的设备定位性能较差，需要一种新方法来提升定位精度和鲁棒性。

Method: 开发了一种基于码本的优化框架，通过设计EMS相位配置来增强信道差异性和空间指纹，利用3D射线追踪模拟验证性能。

Result: 优化后的EMS配置将90%分位数的定位误差从60米以上降至25米以下，同时显著提升了可信度和连续性。

Conclusion: 这是首个利用静态EMS增强信道图表（CC）定位性能的研究，为智能无线电环境（SRE）提供了新思路。

Abstract: This paper introduces the use of static electromagnetic skins (EMSs) to
enable robust device localization via channel charting (CC) in realistic urban
environments. We develop a rigorous optimization framework that leverages EMS
to enhance channel dissimilarity and spatial fingerprinting, formulating EMS
phase profile design as a codebook-based problem targeting the upper quantiles
of key embedding metric, localization error, trustworthiness, and continuity.
Through 3D ray-traced simulations of a representative city scenario, we
demonstrate that optimized EMS configurations, in addition to significant
improvement of the average positioning error, reduce the 90th-percentile
localization error from over 60 m (no EMS) to less than 25 m, while drastically
improving trustworthiness and continuity. To the best of our knowledge, this is
the first work to exploit Smart Radio Environment (SRE) with static EMS for
enhancing CC, achieving substantial gains in localization performance under
challenging None-Line-of-Sight (NLoS) conditions.

</details>


### [17] [Detection and Classification of Internal Leakage in Hydraulic Cylinders](https://arxiv.org/abs/2508.07436)
*Mehrbod Zarifi,Mohamad Amin Jamshidi,Zolfa Anvari,Hamed Ghafarirad,Mohammad Zareinejad*

Main category: eess.SP

TL;DR: 本文提出了一种基于LSTM的液压系统泄漏检测算法，旨在快速准确地识别泄漏类型，减少维护成本并延长系统寿命。


<details>
  <summary>Details</summary>
Motivation: 液压系统中的泄漏问题（尤其是内部泄漏）难以检测，可能导致系统性能下降甚至故障。因此，开发一种高效的泄漏检测方法至关重要。

Method: 通过压力传感器采集液压系统数据，利用LSTM循环神经网络进行复杂数据分析，实现泄漏分类。

Result: 算法在泄漏分类中达到96%的准确率，能够实时在线诊断故障。

Conclusion: 该方法显著提升了泄漏检测效率，降低了维护成本，并延长了液压系统的使用寿命。

Abstract: Hydraulic systems have been one of the most used technologies in many
industries due to their reliance on incompressible fluids that facilitate
energy and power transfer. Within such systems, hydraulic cylinders are prime
devices that convert hydraulic energy into mechanical energy. Some of the
genuine and very common problems related to hydraulic cylinders are leakages.
Leakage in hydraulic systems can cause a drop in pressure, general
inefficiency, and even complete failure of such systems. The various ways
leakage can occur define the major categorization of leakage: internal and
external leakage. External leakage is easily noticeable, while internal
leakage, which involves fluid movement between pressure chambers, can be harder
to detect and may gradually impact system performance without obvious signs.
When leakage surpasses acceptable limits, it is classified as a fault or
failure. In such cases, leakage is divided into three categories: no leakage,
low leakage, and high leakage. It suggests a fault detection algorithm with the
basic responsibility of detecting minimum leakage within the Hydraulic system,
and minimizing detection time is the core idea of this paper. In order to fully
develop this idea, experimental data collection of Hydraulic systems is
required. The collected data uses pressure sensors and other signals that are
single-related. Due to the utilization of Long Short-Term Memory (LSTM)
recurrent neural networks, more complex data analysis was enabled, which the
LSTM-based leakage detection algorithm successfully achieved, providing almost
96% accuracy in classifying leakage types. Results demonstrate that the
proposed method can perform real-time and online fault diagnosis for each
cycle, reducing maintenance costs and prolonging the hydraulic system's
lifespan.

</details>


### [18] [Direction of Arrival Estimation with Virtual Antenna Array Using FMCW Radar Simulated Data](https://arxiv.org/abs/2508.07513)
*Emre Kurtoglu,Mohammad Mahbubur Rahman*

Main category: eess.SP

TL;DR: 该论文研究了77GHz FMCW汽车雷达的角度估计问题，比较了FFT、MUSIC和压缩感知算法的性能，发现FFT速度最快但角度分辨率较差，而MUSIC和压缩感知具有超分辨率能力。


<details>
  <summary>Details</summary>
Motivation: 随着汽车安全功能需求的增加，需要解决两个近距离目标的到达方向（DOA）估计问题，因此研究了77GHz FMCW雷达的角度估计。

Method: 通过模拟数据，比较了FFT、MUSIC和压缩感知算法在角度估计任务中的性能。

Result: FFT速度最快但角度分辨率较差，而MUSIC和压缩感知算法表现出超分辨率能力。

Conclusion: MUSIC和压缩感知算法在角度估计任务中优于FFT，适合高分辨率需求的应用。

Abstract: The FMCW radars are widely used for automotive radar systems. The basic idea
for FMCW radars is to generate a linear frequency ramp as transmit signal. The
difference frequency, (i.e., beat frequency) between the transmitted and
received signal is determined after down conversion. The FFT operation on beat
frequency signal can recognize targets at different range and velocity.
Increasing demand on safety functionality leads to the Direction of Arrival
(DOA) estimation to resolve two closely located targets. Consequently, the
problem of angle estimation for 77GHz FMCW automotive radar simulated data has
been investigated in this term project. In particular, we examined the
performances of FFT, MUSIC and compressed sensing in angle estimation task, and
it was found that although FFT is the fastest algorithm, it has very poor
angular resolution when compared with others which are both super resolution
algorithms. The code for this project report is available at
https://github.com/ekurtgl/FMCW-MIMO-Radar-Simulation.

</details>


### [19] [Pinching-Antenna Systems (PASS): A Tutorial](https://arxiv.org/abs/2508.07572)
*Yuanwei Liu,Hao Jiang,Xiaoxia Xu,Zhaolin Wang,Jia Guo,Chongjun Ouyang,Xidong Mu,Zhiguo Ding,Arumugam Nallanathan,George K. Karagiannidis,Robert Schober*

Main category: eess.SP

TL;DR: PASS（Pinching Antenna Systems）是一种突破性的柔性天线技术，支持大规模天线重构、视距创建和近场优势，将无线通信从“最后一公里”延伸到“最后一米”。本文全面介绍了PASS的基础、性能优势、波束成形设计、多用户通信协议、宽带实现、信道状态信息获取及机器学习应用。


<details>
  <summary>Details</summary>
Motivation: PASS技术通过其独特的柔性天线特性，解决了传统天线技术在可扩展性、灵活性和性能上的限制，为下一代无线通信网络提供了新的可能性。

Method: 论文首先介绍了PASS的基础模型（信号、硬件、功率辐射和激活方法），分析了其信息论容量限制和性能优势。随后研究了波束成形设计、多用户通信协议（波导切换、波导分割和波导复用）以及宽带实现。还探讨了信道状态信息获取和基于机器学习的优化方法。

Result: PASS在单用户和多用户通信中表现出显著优于传统天线的性能，支持灵活的波束成形和高效的功率扩展。机器学习方法进一步提升了PASS的复杂性和性能。

Conclusion: PASS作为一种革命性技术，在下一代无线网络中具有广阔的应用前景，尤其是在高密度通信和近场场景中。

Abstract: Pinching antenna systems (PASS) present a breakthrough among the
flexible-antenna technologies, and distinguish themselves by facilitating
large-scale antenna reconfiguration, line-of-sight creation, scalable
implementation, and near-field benefits, thus bringing wireless communications
from the last mile to the last meter. A comprehensive tutorial is presented in
this paper. First, the fundamentals of PASS are discussed, including PASS
signal models, hardware models, power radiation models, and pinching antenna
activation methods. Building upon this, the information-theoretic capacity
limits achieved by PASS are characterized, and several typical performance
metrics of PASS-based communications are analyzed to demonstrate its
superiority over conventional antenna technologies. Next, the pinching
beamforming design is investigated. The corresponding power scaling law is
first characterized. For the joint transmit and pinching design in the general
multiple-waveguide case, 1) a pair of transmission strategies is proposed for
PASS-based single-user communications to validate the superiority of PASS,
namely sub-connected and fully connected structures; and 2) three practical
protocols are proposed for facilitating PASS-based multi-user communications,
namely waveguide switching, waveguide division, and waveguide multiplexing. A
possible implementation of PASS in wideband communications is further
highlighted. Moreover, the channel state information acquisition in PASS is
elaborated with a pair of promising solutions. To overcome the high complexity
and suboptimality inherent in conventional convex-optimization-based
approaches, machine-learning-based methods for operating PASS are also
explored, focusing on selected deep neural network architectures and training
algorithms. Finally, several promising applications of PASS in next-generation
wireless networks are highlighted.

</details>


### [20] [Remote ID Based UAV Collision Avoidance Optimization for Low-Altitude Airspace Safety](https://arxiv.org/abs/2508.07651)
*Ziye Jia,Yian Zhu,Qihui Wu,Lei Zhang,Sen Yang,Zhu Han*

Main category: eess.SP

TL;DR: 本文研究了基于Remote ID的多无人机碰撞避免框架（DMUCA），通过优化通信延迟提升性能，验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 随着无人机的快速发展，确保其在开放空域的安全高效运行至关重要，Remote ID系统被认为是一种有效的实时监控手段。

Method: 提出DMUCA框架，分析Remote ID消息的平均传输延迟，并设计多智能体深度Q网络算法优化通信配置。

Result: 数值结果表明，DMUCA框架可行，且提出的机制能将平均延迟降低32%。

Conclusion: Remote ID在无人机碰撞避免中具有潜力，优化通信配置可显著提升性能。

Abstract: With the rapid development of unmanned aerial vehicles (UAVs), it is
paramount to ensure safe and efficient operations in open airspaces. The remote
identification (Remote ID) is deemed an effective real-time UAV monitoring
system by the federal aviation administration, which holds potentials for
enabling inter-UAV communications. This paper deeply investigates the
application of Remote ID for UAV collision avoidance while minimizing
communication delays. First, we propose a Remote ID based distributed multi-UAV
collision avoidance (DMUCA) framework to support the collision detection,
avoidance decision-making, and trajectory recovery. Next, the average
transmission delays for Remote ID messages are analyzed, incorporating the
packet reception mechanisms and packet loss due to interference. The
optimization problem is formulated to minimize the long-term average
communication delay, where UAVs can flexibly select the Remote ID protocol to
enhance the collision avoidance performance. To tackle the problem, we design a
multi-agent deep Q-network based adaptive communication configuration
algorithm, allowing UAVs to autonomously learn the optimal protocol
configurations in dynamic environments. Finally, numerical results verify the
feasibility of the proposed DMUCA framework, and the proposed mechanism can
reduce the average delay by 32% compared to the fixed protocol configuration.

</details>


### [21] [Importance-Aware Semantic Communication in MIMO-OFDM Systems Using Vision Transformer](https://arxiv.org/abs/2508.07696)
*Joohyuk Park,Yongjeong Oh,Jihun Park,Yo-Seb Jeon*

Main category: eess.SP

TL;DR: 论文提出了一种基于预训练ViT的IA-QSMPA框架，用于MIMO-OFDM系统中的语义通信，通过联合优化量化、子载波映射和功率分配，显著提升了任务性能和通信效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法在语义通信中资源分配不合理的问题，利用ViT提取的注意力信息优化资源分配。

Method: 采用基于ViT的注意力重要性，联合优化量化、子载波映射和功率分配，并使用块坐标下降算法解决非凸优化问题。

Result: 在MVP-N数据集上的实验表明，IA-QSMPA在理想和有限块长传输场景下均优于传统方法。

Conclusion: IA-QSMPA框架显著提升了语义通信的任务性能和效率，尤其在有限块长传输中表现优异。

Abstract: This paper presents a novel importance-aware quantization, subcarrier
mapping, and power allocation (IA-QSMPA) framework for semantic communication
in multiple-input multiple-output orthogonal frequency division multiplexing
(MIMO-OFDM) systems, empowered by a pretrained Vision Transformer (ViT). The
proposed framework exploits attention-based importance extracted from a
pretrained ViT to jointly optimize quantization levels, subcarrier mapping, and
power allocation. Specifically, IA-QSMPA maps semantically important features
to high-quality subchannels and allocates resources in accordance with their
contribution to task performance and communication latency. To efficiently
solve the resulting nonconvex optimization problem, a block coordinate descent
algorithm is employed. The framework is further extended to operate under
finite blocklength transmission, where communication errors may occur. In this
setting, a segment-wise linear approximation of the channel dispersion penalty
is introduced to enable efficient joint optimization under practical
constraints. Simulation results on a multi-view image classification task using
the MVP-N dataset demonstrate that IA-QSMPA significantly outperforms
conventional methods in both ideal and finite blocklength transmission
scenarios, achieving superior task performance and communication efficiency.

</details>


### [22] [Touch-Augmented Gaussian Splatting for Enhanced 3D Scene Reconstruction](https://arxiv.org/abs/2508.07717)
*Yuchen Gao,Xiao Xu,Eckehard Steinbach,Daniel E. Lucani,Qi Zhang*

Main category: eess.SP

TL;DR: 提出了一种多模态框架，将触觉信号（接触点和表面法线）整合到3D高斯泼溅（3DGS）中，提升场景重建质量，尤其在低光照、有限视角和遮挡等挑战性条件下。


<details>
  <summary>Details</summary>
Motivation: 传统视觉方法在复杂条件下（如低光照、遮挡）表现不佳，因此需要结合触觉信号以提升重建精度。

Method: 采用两阶段采样方案：先探测稀疏区域，再聚焦于高不确定性边界；提出几何损失以确保表面平滑。

Result: 实验显示几何精度显著提升，严重遮挡情况下Chamfer Distance降低15倍以上。

Conclusion: 触觉信号的整合显著提升了3D高斯泼溅的重建效果，适用于视觉退化环境。

Abstract: This paper presents a multimodal framework that integrates touch signals
(contact points and surface normals) into 3D Gaussian Splatting (3DGS). Our
approach enhances scene reconstruction, particularly under challenging
conditions like low lighting, limited camera viewpoints, and occlusions.
Different from the visual-only method, the proposed approach incorporates
spatially selective touch measurements to refine both the geometry and
appearance of the 3D Gaussian representation. To guide the touch exploration,
we introduce a two-stage sampling scheme that initially probes sparse regions
and then concentrates on high-uncertainty boundaries identified from the
reconstructed mesh. A geometric loss is proposed to ensure surface smoothness,
resulting in improved geometry. Experimental results across diverse scenarios
show consistent improvements in geometric accuracy. In the most challenging
case with severe occlusion, the Chamfer Distance is reduced by over 15x,
demonstrating the effectiveness of integrating touch cues into 3D Gaussian
Splatting. Furthermore, our approach maintains a fully online pipeline,
underscoring its feasibility in visually degraded environments.

</details>


### [23] [RIS-Assisted NOMA with Partial CSI and Mutual Coupling: A Machine Learning Approach](https://arxiv.org/abs/2508.07909)
*Bile Peng,Karl-Ludwig Besser,Shanpu Shen,Finn Siegismund-Poschmann,Ramprasad Raghunath,Daniel M. Mittleman,Vahid Jamali,Eduard A. Jorswieck*

Main category: eess.SP

TL;DR: 论文提出了一种结合无监督机器学习和领域知识的神经网络架构RISnet，用于联合优化基站预编码和RIS配置，以提高NOMA性能。


<details>
  <summary>Details</summary>
Motivation: NOMA的性能依赖于无线信道特性，而RIS可以增强信道特性。传统方法难以高效优化大规模RIS配置，因此需要结合领域知识的机器学习方法。

Method: 提出RISnet神经网络架构，结合通信领域知识，自主寻找最优解。该方法联合优化BS预编码和RIS配置，具有高扩展性和低CSI需求。

Result: RISnet能够高效控制超过1000个RIS元素，解决了元素间耦合问题，性能优于现有方法。

Conclusion: 该研究是领域知识驱动机器学习的早期贡献，展示了结合通信系统专业知识设计优于通用ML方法的潜力。

Abstract: Non-orthogonal multiple access (NOMA) is a promising multiple access
technique. Its performance depends strongly on the wireless channel property,
which can be enhanced by reconfigurable intelligent surfaces (RISs). In this
paper, we jointly optimize base station (BS) precoding and RIS configuration
with unsupervised machine learning (ML), which looks for the optimal solution
autonomously. In particular, we propose a dedicated neural network (NN)
architecture RISnet inspired by domain knowledge in communication. Compared to
state-of-the-art, the proposed approach combines analytical optimal BS
precoding and ML-enabled RIS, has a high scalability to control more than 1000
RIS elements, has a low requirement for channel state information (CSI) in
input, and addresses the mutual coupling between RIS elements. Beyond the
considered problem, this work is an early contribution to domain knowledge
enabled ML, which exploit the domain expertise of communication systems to
design better approaches than general ML methods.

</details>


### [24] [Advancing the Control of Low-Altitude Wireless Networks: Architecture, Design Principles, and Future Directions](https://arxiv.org/abs/2508.07967)
*Haijia Jin,Weijie Yuan,Jun Wu,Jiacheng Wang,Dusit Niyato,Xianbin Wang,George K. Karagiannidis,Zhiyun Lin,Yi Gong,Dong In Kim,Athina Petropulu,Maria Sabrina Greco,Abbas Jamalipour,Sumei Sun*

Main category: eess.SP

TL;DR: 本文介绍了一种面向控制的低空无线网络（LAWN），集成了近地通信和内部系统状态的远程估计，支持动态空-地环境中的可靠网络控制。


<details>
  <summary>Details</summary>
Motivation: 动态空-地环境中需要可靠的网络控制，因此提出了一种集成了通信和状态估计的低空无线网络。

Method: 介绍了网络的模块化架构和关键性能指标，讨论了控制、通信和估计层之间的核心设计权衡，并通过案例研究展示了无线约束下的闭环协调。

Result: 展示了LAWN在动态环境中的可行性和性能。

Conclusion: 未来研究方向包括在实时和资源受限场景中实现可扩展和弹性的LAWN部署。

Abstract: This article introduces a control-oriented low-altitude wireless network
(LAWN) that integrates near-ground communications and remote estimation of the
internal system state. This integration supports reliable networked control in
dynamic aerial-ground environments. First, we introduce the network's modular
architecture and key performance metrics. Then, we discuss core design
trade-offs across the control, communication, and estimation layers. A case
study illustrates closed-loop coordination under wireless constraints. Finally,
we outline future directions for scalable, resilient LAWN deployments in
real-time and resource-constrained scenarios.

</details>


### [25] [Robust Design of Beyond-Diagonal Reconfigurable Intelligent Surface Empowered RSMA-SWIPT System Under Channel Estimation Errors](https://arxiv.org/abs/2508.08097)
*Muhammad Asif,Zain Ali,Asim Ihsan,Ali Ranjha,Zhu Shoujin,Manzoor Ahmed,Xingwang Li,Symeon Chatzinotas*

Main category: eess.SP

TL;DR: 论文提出了一种结合RSMA、SWIPT和BD-RIS的优化框架，以提升6G网络的性能，并通过交替优化方法解决了多变量联合优化问题。


<details>
  <summary>Details</summary>
Motivation: 为了提升未来6G通信网络的频谱效率、能量效率、覆盖范围和连接性，研究将RSMA、SWIPT和BD-RIS技术整合，并考虑实际硬件限制和信道不确定性。

Method: 采用交替优化框架，将问题分解为多个块，分别优化发射预编码向量、用户公共速率比例、功率分配比和BD-RIS散射矩阵，并利用SCA和流形优化技术。

Result: 数值仿真表明，所提方案在系统总速率上显著优于现有基准，并在合理迭代次数内快速收敛。

Conclusion: 该研究为6G网络的高效资源分配和鲁棒优化提供了有效解决方案，具有实际应用潜力。

Abstract: This work explores the integration of rate-splitting multiple access (RSMA),
simultaneous wireless information and power transfer (SWIPT), and
beyond-diagonal reconfigurable intelligent surface (BD-RIS) to enhance the
spectral-efficiency, energy-efficiency, coverage, and connectivity of future
sixth-generation (6G) communication networks. Specifically, with a multiuser
BD-RIS-empowered RSMA-SWIPT system, we jointly optimize the transmit precoding
vectors, the common rate proportion of users, the power-splitting ratios, and
scattering matrix of BD-RIS node, under the assumption of imperfect channel
state information (CSI). Additionally, to better capture practical hardware
behavior, we incorporate a nonlinear energy harvesting model under energy
harvesting constraints. We design a robust optimization framework to maximize
the system sum-rate, while explicitly accounting for the worst-case impact of
CSI uncertainties. Further, we introduce an alternating optimization framework
that partitions the problem into several blocks, which are optimized
iteratively. More specifically, the transmit precoding vectors are optimized by
reformulating the problem as a convex semidefinite programming through
successive-convex approximation (SCA), whereas the power-splitting problem is
solved using the MOSEK-enabled CVX toolbox. Subsequently, to optimize the
scattering matrix of the BD-RIS, we first employ SCA to reformulate the problem
into a convex form, and then design a manifold optimization strategy based on
the Conjugate-Gradient method. Finally, numerical simulation results reveal
that the proposed scheme provides significant performance improvements over
existing benchmarks and demonstrates rapid convergence within a reasonable
number of iterations.

</details>


### [26] [Adaptive Learning for IRS-Assisted Wireless Networks: Securing Opportunistic Communications Against Byzantine Eavesdroppers](https://arxiv.org/abs/2508.08206)
*Amirhossein Taherpour,Abbas Taherpour,Tamer Khattab*

Main category: eess.SP

TL;DR: 提出了一种联合学习框架，用于在信道状态信息（CSI）不确定的情况下实现拜占庭容错的频谱感知和安全智能反射面（IRS）辅助的机会接入。


<details>
  <summary>Details</summary>
Motivation: 解决在存在拜占庭用户攻击和CSI不确定性的情况下，如何实现高精度的频谱感知和安全通信的问题。

Method: 采用对数域贝叶斯更新与修剪聚合、注意力加权共识的频谱感知方法，基站采用保守最小规则融合网络信念。在传输阶段，通过优化基站预编码器、IRS相位偏移和用户均衡器，实现最小化均方误差（MSE）。针对不同CSI情况，分别提出基于增广拉格朗日交替算法和约束贝叶斯优化的方法。

Result: 仿真结果显示，在对抗攻击下实现了更高的检测概率和更低的误报率，显著降低了诚实用户的总MSE，并有效抑制了窃听者信号功率。

Conclusion: 该框架为适应CSI可用性的安全机会通信提供了一条实用路径，通过联合学习协调感知和传输。

Abstract: We propose a joint learning framework for Byzantine-resilient spectrum
sensing and secure intelligent reflecting surface (IRS)--assisted opportunistic
access under channel state information (CSI) uncertainty. The sensing stage
performs logit-domain Bayesian updates with trimmed aggregation and
attention-weighted consensus, and the base station (BS) fuses network beliefs
with a conservative minimum rule, preserving detection accuracy under a bounded
number of Byzantine users. Conditioned on the sensing outcome, we pose downlink
design as sum mean-squared error (MSE) minimization under transmit-power and
signal-leakage constraints and jointly optimize the BS precoder, IRS phase
shifts, and user equalizers. With partial (or known) CSI, we develop an
augmented-Lagrangian alternating algorithm with projected updates and provide
provable sublinear convergence, with accelerated rates under mild local
curvature. With unknown CSI, we perform constrained Bayesian optimization (BO)
in a geometry-aware low-dimensional latent space using Gaussian process (GP)
surrogates; we prove regret bounds for a constrained upper confidence bound
(UCB) variant of the BO module, and demonstrate strong empirical performance of
the implemented procedure. Simulations across diverse network conditions show
higher detection probability at fixed false-alarm rate under adversarial
attacks, large reductions in sum MSE for honest users, strong suppression of
eavesdropper signal power, and fast convergence. The framework offers a
practical path to secure opportunistic communication that adapts to CSI
availability while coherently coordinating sensing and transmission through
joint learning.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [27] [Differentiable Grouped Feedback Delay Networks for Learning Coupled Volume Acoustics](https://arxiv.org/abs/2508.06686)
*Orchisama Das,Gloria Dal Santo,Sebastian J. Schlecht,Vesa Valimaki,Zoran Cvetkovic*

Main category: eess.AS

TL;DR: 提出了一种可微分组反馈延迟网络（DiffGFDN），用于高效渲染复杂声学空间中的动态混响，优化参数以匹配多斜率衰减的混响特性，显著降低计算和内存需求。


<details>
  <summary>Details</summary>
Motivation: 在扩展现实（XR）应用中，动态混响渲染对提升沉浸感至关重要，但传统方法成本高且计算量大，难以在可穿戴设备上实现。

Method: 通过可微分的GFDN（DiffGFDN）优化参数以匹配多斜率衰减的混响特性，采用并行处理管道处理每个倍频程带，参数可快速更新。

Result: DiffGFDN在能量衰减误差（EDR）上优于Common Slopes模型，计算需求低一个数量级，但倍频程带能量衰减曲线（EDC）误差稍差。

Conclusion: DiffGFDN为动态混响提供了一种高效、低资源占用的解决方案，适用于XR应用。

Abstract: Rendering dynamic reverberation in a complicated acoustic space for moving
sources and listeners is challenging but crucial for enhancing user immersion
in extended-reality (XR) applications. Capturing spatially varying room impulse
responses (RIRs) is costly and often impractical. Moreover, dynamic convolution
with measured RIRs is computationally expensive with high memory demands,
typically not available on wearable computing devices. Grouped Feedback Delay
Networks (GFDNs), on the other hand, allow efficient rendering of coupled room
acoustics. However, its parameters need to be tuned to match the reverberation
profile of a coupled space. In this work, we propose the concept of
Differentiable GFDNs (DiffGFDNs), which have tunable parameters that are
optimised to match the late reverberation profile of a set of RIRs captured
from a space that exhibits multi-slope decay. Once trained on a finite set of
measurements, the DiffGFDN generalises to unmeasured locations in the space. We
propose a parallel processing pipeline that has multiple DiffGFDNs with
frequency-independent parameters processing each octave band. The parameters of
the DiffGFDN can be updated rapidly during inferencing as sources and listeners
move. We evaluate the proposed architecture against the Common Slopes (CS)
model on a dataset of RIRs for three coupled rooms. The proposed architecture
generates multi-slope late reverberation with low memory and computational
requirements, achieving better energy decay relief (EDR) error and slightly
worse octave-band energy decay curve (EDC) errors compared to the CS model.
Furthermore, DiffGFDN requires an order of magnitude fewer floating-point
operations per sample than the CS renderer.

</details>


### [28] [FlowSE: Flow Matching-based Speech Enhancement](https://arxiv.org/abs/2508.06840)
*Seonggyu Lee,Sein Cheong,Sangwook Han,Jong Won Shin*

Main category: eess.AS

TL;DR: 本文提出了一种基于条件流匹配的语音增强方法，显著降低了计算复杂度，性能与扩散模型相当。


<details>
  <summary>Details</summary>
Motivation: 扩散概率模型在语音增强中表现优异，但推理阶段需要大量计算资源。

Method: 采用条件流匹配方法，训练连续归一化流，模拟从已知分布到未知分布的概率路径。

Result: 在NFE为5时，性能与NFE为60的扩散模型相当，且无需额外微调。

Conclusion: 条件流匹配方法在低计算成本下实现了高性能语音增强。

Abstract: Diffusion probabilistic models have shown impressive performance for speech
enhancement, but they typically require 25 to 60 function evaluations in the
inference phase, resulting in heavy computational complexity. Recently, a
fine-tuning method was proposed to correct the reverse process, which
significantly lowered the number of function evaluations (NFE). Flow matching
is a method to train continuous normalizing flows which model probability paths
from known distributions to unknown distributions including those described by
diffusion processes. In this paper, we propose a speech enhancement based on
conditional flow matching. The proposed method achieved the performance
comparable to those for the diffusion-based speech enhancement with the NFE of
60 when the NFE was 5, and showed similar performance with the diffusion model
correcting the reverse process at the same NFE from 1 to 5 without additional
fine tuning procedure. We also have shown that the corresponding diffusion
model derived from the conditional probability path with a modified optimal
transport conditional vector field demonstrated similar performances with the
NFE of 5 without any fine-tuning procedure.

</details>


### [29] [Speech Enhancement based on cascaded two flow](https://arxiv.org/abs/2508.06842)
*Seonggyu Lee,Sein Cheong,Sangwook Han,Kihyuk Kim,Jong Won Shi*

Main category: eess.AS

TL;DR: 提出了一种基于流匹配的语音增强方法，通过同一模型实现增强和初始点生成，减少了计算需求并保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有扩散概率模型需要高计算量，而流匹配方法虽高效但依赖额外预测模型。本文旨在简化流程并提升效率。

Method: 使用同一流匹配模型进行语音增强和生成初始点，避免额外预测模型，减少计算步骤。

Result: 实验表明，该方法在相同或更少计算量下，性能优于或等同于现有基线。

Conclusion: 提出的方法简化了流程，减少了计算需求，同时保持了高性能。

Abstract: Speech enhancement (SE) based on diffusion probabilistic models has exhibited
impressive performance, while requiring a relatively high number of function
evaluations (NFE). Recently, SE based on flow matching has been proposed, which
showed competitive performance with a small NFE. Early approaches adopted the
noisy speech as the only conditioning variable. There have been other
approaches which utilize speech enhanced with a predictive model as another
conditioning variable and to sample an initial value, but they require a
separate predictive model on top of the generative SE model. In this work, we
propose to employ an identical model based on flow matching for both SE and
generating enhanced speech used as an initial starting point and a conditioning
variable. Experimental results showed that the proposed method required the
same or fewer NFEs even with two cascaded generative methods while achieving
equivalent or better performances to the previous baselines.

</details>


### [30] [Head-steered channel selection method for hearing aid applications using remote microphones](https://arxiv.org/abs/2508.06928)
*Vasudha Sathyapriyan,Michael S. Pedersen,Mike Brookes,Jan Østergaard,Patrick A. Naylor,Jesper Jensen*

Main category: eess.AS

TL;DR: 提出了一种基于头部转向的远程麦克风通道选择方法，用于助听器应用，以在多说话者环境中准确捕捉目标说话者信号。


<details>
  <summary>Details</summary>
Motivation: 在多说话者环境中，助听器用户需要准确捕捉目标说话者的信号，现有方法可能无法满足需求。

Method: 将通道选择任务建模为多假设检验问题，提出最大似然解，选择与头部转向助听器波束形成器输出相关性最高的远程通道。

Result: 仿真实验表明，该方法在多说话者环境中优于现有方法，无需额外传感器即可准确捕捉目标信号。

Conclusion: 该方法有效提升了助听器在多说话者环境中的性能，具有实际应用潜力。

Abstract: We propose a channel selection method for hearing aid applications using
remote microphones, in the presence of multiple competing talkers. The proposed
channel selection method uses the hearing aid user's head-steering direction to
identify the remote channel originating from the frontal direction of the
hearing aid user, which captures the target talker signal. We pose the channel
selection task as a multiple hypothesis testing problem, and derive a maximum
likelihood solution. Under realistic, simplifying assumptions, the solution
selects the remote channel which has the highest weighted squared absolute
correlation coefficient with the output of the head-steered hearing aid
beamformer. We analyze the performance of the proposed channel selection method
using close-talking remote microphones and table microphone arrays. Through
simulations using realistic acoustic scenes, we show that the proposed channel
selection method consistently outperforms existing methods in accurately
finding the remote channel that captures the target talker signal, in the
presence of multiple competing talkers, without the use of any additional
sensors.

</details>


### [31] [TurboBias: Universal ASR Context-Biasing powered by GPU-accelerated Phrase-Boosting Tree](https://arxiv.org/abs/2508.07014)
*Andrei Andrusenko,Vladimir Bataev,Lilit Grigoryan,Vitaly Lavrukhin,Boris Ginsburg*

Main category: eess.AS

TL;DR: 提出了一种通用的ASR上下文偏置框架，支持CTC、Transducers和Attention Encoder-Decoder模型，基于GPU加速的单词提升树，显著提升了准确性和解码速度。


<details>
  <summary>Details</summary>
Motivation: 现有上下文偏置方法需要额外训练模型、解码速度慢或限制ASR系统类型，亟需一种通用且高效的解决方案。

Method: 基于GPU加速的单词提升树，支持浅融合模式，适用于贪婪和束搜索解码，可处理多达20K个关键短语。

Result: 在准确性和解码速度上优于现有开源上下文偏置方法。

Conclusion: 该框架作为NeMo工具包的一部分开源，为ASR上下文偏置提供了一种高效通用的解决方案。

Abstract: Recognizing specific key phrases is an essential task for contextualized
Automatic Speech Recognition (ASR). However, most existing context-biasing
approaches have limitations associated with the necessity of additional model
training, significantly slow down the decoding process, or constrain the choice
of the ASR system type. This paper proposes a universal ASR context-biasing
framework that supports all major types: CTC, Transducers, and Attention
Encoder-Decoder models. The framework is based on a GPU-accelerated word
boosting tree, which enables it to be used in shallow fusion mode for greedy
and beam search decoding without noticeable speed degradation, even with a vast
number of key phrases (up to 20K items). The obtained results showed high
efficiency of the proposed method, surpassing the considered open-source
context-biasing approaches in accuracy and decoding speed. Our context-biasing
framework is open-sourced as a part of the NeMo toolkit.

</details>


### [32] [ParaNoise-SV: Integrated Approach for Noise-Robust Speaker Verification with Parallel Joint Learning of Speech Enhancement and Noise Extraction](https://arxiv.org/abs/2508.07219)
*Minu Kim,Kangwook Jang,Hoirin Kim*

Main category: eess.AS

TL;DR: ParaNoise-SV通过双U-Net结构显式建模噪声和语音增强，相比隐式噪声抑制方法，显著提升了噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖隐式噪声抑制，难以区分噪声与说话人特征，限制了噪声处理效果。

Method: 提出ParaNoise-SV，结合噪声提取（NE）和语音增强（SE）双U-Net，通过并行连接显式建模噪声并优化语音。

Result: 实验表明，ParaNoise-SV的等错误率（EER）比之前联合SE-SV模型低8.4%。

Conclusion: 显式噪声建模和并行结构有效提升了噪声鲁棒性，为说话人验证提供了新思路。

Abstract: Noise-robust speaker verification leverages joint learning of speech
enhancement (SE) and speaker verification (SV) to improve robustness. However,
prevailing approaches rely on implicit noise suppression, which struggles to
separate noise from speaker characteristics as they do not explicitly
distinguish noise from speech during training. Although integrating SE and SV
helps, it remains limited in handling noise effectively. Meanwhile, recent SE
studies suggest that explicitly modeling noise, rather than merely suppressing
it, enhances noise resilience. Reflecting this, we propose ParaNoise-SV, with
dual U-Nets combining a noise extraction (NE) network and a speech enhancement
(SE) network. The NE U-Net explicitly models noise, while the SE U-Net refines
speech with guidance from NE through parallel connections, preserving
speaker-relevant features. Experimental results show that ParaNoise-SV achieves
a relatively 8.4% lower equal error rate (EER) than previous joint SE-SV
models.

</details>


### [33] [Lessons Learnt: Revisit Key Training Strategies for Effective Speech Emotion Recognition in the Wild](https://arxiv.org/abs/2508.07282)
*Jing-Tong Tzeng,Bo-Hao Su,Ya-Tse Wu,Hsing-Hang Chou,Chi-Chun Lee*

Main category: eess.AS

TL;DR: 通过优化训练策略而非加深架构，提升语音情感识别的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 探索常被忽视的训练策略（如平衡策略、激活函数和微调技术），以提升自然条件下的语音情感识别性能。

Method: 采用多模态融合模型，单独微调RoBERTa和WavLM后进行特征融合，并使用焦点损失和优化激活函数。

Result: 模型在情感属性回归任务中取得最佳效价分数（CCC 0.6953）。

Conclusion: 优化核心组件比加深模型更能提升语音情感识别的鲁棒性。

Abstract: In this study, we revisit key training strategies in machine learning often
overlooked in favor of deeper architectures. Specifically, we explore balancing
strategies, activation functions, and fine-tuning techniques to enhance speech
emotion recognition (SER) in naturalistic conditions. Our findings show that
simple modifications improve generalization with minimal architectural changes.
Our multi-modal fusion model, integrating these optimizations, achieves a
valence CCC of 0.6953, the best valence score in Task 2: Emotional Attribute
Regression. Notably, fine-tuning RoBERTa and WavLM separately in a
single-modality setting, followed by feature fusion without training the
backbone extractor, yields the highest valence performance. Additionally, focal
loss and activation functions significantly enhance performance without
increasing complexity. These results suggest that refining core components,
rather than deepening models, leads to more robust SER in-the-wild.

</details>


### [34] [A Survey on Non-Intrusive ASR Refinement: From Output-Level Correction to Full-Model Distillation](https://arxiv.org/abs/2508.07285)
*Mohammad Reza Peyghan,Fatemeh Rajabi,Saman Soleimani Roudi,Saeedreza Zouashkiani,Sajjad Amini,Shahrokh Ghaemmaghami*

Main category: eess.AS

TL;DR: 该论文综述了自动语音识别（ASR）的非侵入式优化方法，分类为融合、重评分、校正、蒸馏和训练调整，并探讨了领域适应、评估数据集及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: ASR系统在口音、方言、环境噪声和领域术语方面存在不足，直接改进模型架构成本高，因此需要非侵入式优化方法。

Method: 系统回顾了五类非侵入式优化方法，分析了各类方法的主要技术、优缺点及适用场景，并探讨了领域适应技术和评估标准。

Result: 提出了方法分类、领域适应技术、评估数据集和标准化指标，为ASR优化提供了清晰框架。

Conclusion: 论文为研究人员和实践者提供了ASR优化的基础，并指出了未来研究方向。

Abstract: Automatic Speech Recognition (ASR) has become an integral component of modern
technology, powering applications such as voice-activated assistants,
transcription services, and accessibility tools. Yet ASR systems continue to
struggle with the inherent variability of human speech, such as accents,
dialects, and speaking styles, as well as environmental interference, including
background noise. Moreover, domain-specific conversations often employ
specialized terminology, which can exacerbate transcription errors. These
shortcomings not only degrade raw ASR accuracy but also propagate mistakes
through subsequent natural language processing pipelines. Because redesigning
an ASR model is costly and time-consuming, non-intrusive refinement techniques
that leave the model's architecture unchanged have become increasingly popular.
In this survey, we systematically review current non-intrusive refinement
approaches and group them into five classes: fusion, re-scoring, correction,
distillation, and training adjustment. For each class, we outline the main
methods, advantages, drawbacks, and ideal application scenarios. Beyond method
classification, this work surveys adaptation techniques aimed at refining ASR
in domain-specific contexts, reviews commonly used evaluation datasets along
with their construction processes, and proposes a standardized set of metrics
to facilitate fair comparisons. Finally, we identify open research gaps and
suggest promising directions for future work. By providing this structured
overview, we aim to equip researchers and practitioners with a clear foundation
for developing more robust, accurate ASR refinement pipelines.

</details>


### [35] [XEmoRAG: Cross-Lingual Emotion Transfer with Controllable Intensity Using Retrieval-Augmented Generation](https://arxiv.org/abs/2508.07302)
*Tianlun Zuo,Jingbin Hu,Yuke Li,Xinfa Zhu,Hai Li,Ying Yan,Junhui Liu,Danming Xie,Lei Xie*

Main category: eess.AS

TL;DR: XEmoRAG框架实现中文到泰语的零样本情感迁移，无需平行情感数据，通过语言无关情感嵌入和检索匹配泰语语音，结合对齐模块提升自然度。


<details>
  <summary>Details</summary>
Motivation: 解决跨语言语音合成中情感迁移的挑战，如缺乏平行数据、口音问题和情感与语言特征的分离困难。

Method: 使用LLM提取中文语音的情感嵌入，检索匹配的泰语语音，结合流匹配对齐模块优化音高和时长，并融合中文音色。

Result: 实验表明XEmoRAG仅需中文参考音频即可生成自然且富有情感的泰语语音，无需显式情感标签。

Conclusion: XEmoRAG实现了低资源跨语言情感迁移，具有灵活性和高效性。

Abstract: Zero-shot emotion transfer in cross-lingual speech synthesis refers to
generating speech in a target language, where the emotion is expressed based on
reference speech from a different source language.However, this task remains
challenging due to the scarcity of parallel multilingual emotional corpora, the
presence of foreign accent artifacts, and the difficulty of separating emotion
from language-specific prosodic features.In this paper, we propose XEmoRAG, a
novel framework to enable zero-shot emotion transfer from Chinese to Thai using
a large language model (LLM)-based model, without relying on parallel emotional
data.XEmoRAG extracts language-agnostic emotional embeddings from Chinese
speech and retrieves emotionally matched Thai utterances from a curated
emotional database, enabling controllable emotion transfer without explicit
emotion labels. Additionally, a flow-matching alignment module minimizes pitch
and duration mismatches, ensuring natural prosody. It also blends Chinese
timbre into the Thai synthesis, enhancing rhythmic accuracy and emotional
expression, while preserving speaker characteristics and emotional
consistency.Experimental results show that XEmoRAG synthesizes expressive and
natural Thai speech using only Chinese reference audio, without requiring
explicit emotion labels.These results highlight XEmoRAG's capability to achieve
flexible and low-resource emotional transfer across languages.Our demo is
available at https://tlzuo-lesley.github.io/Demo-page/.

</details>


### [36] [FlexCTC: GPU-powered CTC Beam Decoding with advanced Contextual Abilities](https://arxiv.org/abs/2508.07315)
*Lilit Grigoryan,Vladimir Bataev,Nikolay Karpov,Andrei Andrusenko,Vitaly Lavrukhin,Boris Ginsburg*

Main category: eess.AS

TL;DR: FlexCTC是一个基于GPU的快速、用户友好的CTC模型解码工具包，支持高级上下文技术，适用于研究和生产。


<details>
  <summary>Details</summary>
Motivation: 传统波束搜索解码速度慢且受限于CPU，无法充分利用现代硬件性能。

Method: 开发了完全基于Python和PyTorch的FlexCTC工具包，采用GPU并行计算，消除CPU-GPU同步，并通过CUDA Graphs减少内核启动开销。

Result: 实现了高性能、完全批处理的GPU解码，支持N-gram语言模型融合和短语级增强。

Conclusion: FlexCTC提供了一种高效、准确的解码方案，适用于研究和生产环境。

Abstract: While beam search improves speech recognition quality over greedy decoding,
standard implementations are slow, often sequential, and CPU-bound. To fully
leverage modern hardware capabilities, we present a novel open-source FlexCTC
toolkit for fully GPU-based beam decoding, designed for Connectionist Temporal
Classification (CTC) models. Developed entirely in Python and PyTorch, it
offers a fast, user-friendly, and extensible alternative to traditional C++,
CUDA, or WFST-based decoders. The toolkit features a high-performance, fully
batched GPU implementation with eliminated CPU-GPU synchronization and
minimized kernel launch overhead via CUDA Graphs. It also supports advanced
contextualization techniques, including GPU-powered N-gram language model
fusion and phrase-level boosting. These features enable accurate and efficient
decoding, making them suitable for both research and production use.

</details>


### [37] [KLASSify to Verify: Audio-Visual Deepfake Detection Using SSL-based Audio and Handcrafted Visual Features](https://arxiv.org/abs/2508.07337)
*Ivan Kukanov,Jun Wah Ng*

Main category: eess.AS

TL;DR: 论文提出了一种多模态方法用于AV-Deepfake1M 2025挑战，结合视觉和音频特征提升深度伪造检测的鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着音频驱动的人脸生成器和TTS模型的快速发展，深度伪造技术日益复杂，现有检测方法计算成本高且难以泛化到新攻击场景。

Method: 视觉模态采用手工特征提升可解释性；音频模态结合自监督学习和图注意力网络捕获丰富音频表示。

Result: 在AV-Deepfake1M++数据集上，多模态系统在深度伪造分类任务中AUC达92.78%，音频模态的时间定位IoU为0.3536。

Conclusion: 该方法在性能和实际部署间取得平衡，注重鲁棒性和可解释性。

Abstract: The rapid development of audio-driven talking head generators and advanced
Text-To-Speech (TTS) models has led to more sophisticated temporal deepfakes.
These advances highlight the need for robust methods capable of detecting and
localizing deepfakes, even under novel, unseen attack scenarios. Current
state-of-the-art deepfake detectors, while accurate, are often computationally
expensive and struggle to generalize to novel manipulation techniques. To
address these challenges, we propose multimodal approaches for the
AV-Deepfake1M 2025 challenge. For the visual modality, we leverage handcrafted
features to improve interpretability and adaptability. For the audio modality,
we adapt a self-supervised learning (SSL) backbone coupled with graph attention
networks to capture rich audio representations, improving detection robustness.
Our approach strikes a balance between performance and real-world deployment,
focusing on resilience and potential interpretability. On the AV-Deepfake1M++
dataset, our multimodal system achieves AUC of 92.78% for deepfake
classification task and IoU of 0.3536 for temporal localization using only the
audio modality.

</details>


### [38] [Scalable Controllable Accented TTS](https://arxiv.org/abs/2508.07426)
*Henry Li Xinyuan,Zexin Cai,Ashi Garg,Kevin Duh,Leibny Paola García-Perera,Sanjeev Khudanpur,Nicholas Andrews,Matthew Wiesner*

Main category: eess.AS

TL;DR: 论文提出了一种扩展带口音TTS系统的方法，通过自动发现口音标签和音色增强技术，显著提升了模型的性能和多样性。


<details>
  <summary>Details</summary>
Motivation: 传统TTS系统在处理带口音语音时面临数据不足和标签缺乏的挑战，需要一种更高效的方法来扩展其能力。

Method: 采用两种策略：1. 通过语音地理定位模型自动发现口音标签；2. 使用kNN语音转换技术增强音色多样性。

Result: 在CommonVoice数据集上验证，新方法优于基于自报口音标签的XTTS-v2和其他现有基准。

Conclusion: 该方法显著提升了带口音TTS系统的性能和适用范围，为未来研究提供了新方向。

Abstract: We tackle the challenge of scaling accented TTS systems, expanding their
capabilities to include much larger amounts of training data and a wider
variety of accent labels, even for accents that are poorly represented or
unlabeled in traditional TTS datasets. To achieve this, we employ two
strategies: 1. Accent label discovery via a speech geolocation model, which
automatically infers accent labels from raw speech data without relying solely
on human annotation; 2. Timbre augmentation through kNN voice conversion to
increase data diversity and model robustness. These strategies are validated on
CommonVoice, where we fine-tune XTTS-v2 for accented TTS with accent labels
discovered or enhanced using geolocation. We demonstrate that the resulting
accented TTS model not only outperforms XTTS-v2 fine-tuned on self-reported
accent labels in CommonVoice, but also existing accented TTS benchmarks.

</details>


### [39] [Real-time CARFAC Cochlea Model Acceleration on FPGA for Underwater Acoustic Sensing Systems](https://arxiv.org/abs/2508.07523)
*Bram Bremer,Matthew Bigelow,Stuart Anstee,Gregory Cohen,Andre van Schaik,Ying Xu*

Main category: eess.AS

TL;DR: 本文提出了一种基于CARFAC模型的实时、节能嵌入式系统，用于水下声音分析，通过硬件加速和优化设计提升了性能和效率。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种实时、高效的水下声音分析系统，解决传统方法在资源利用和速度上的不足。

Method: 系统采用AMD Kria KV260 SoM，结合Rust软件框架和FPGA硬件加速，优化了CARFAC模型的实现。

Result: 实验结果显示，单64通道CARFAC实例硬件利用率13.5%，整板功耗3.11W，实时处理256kHz信号。

Conclusion: 该系统在性能和效率上优于先前工作，适用于实时水下声音分析。

Abstract: This paper presents a real-time, energy-efficient embedded system
implementing an array of Cascade of Asymmetric Resonators with Fast-Acting
Compression (CARFAC) cochlea models for underwater sound analysis. Built on the
AMD Kria KV260 System-on-Module (SoM), the system integrates a Rust-based
software framework on the processor for real-time interfacing and
synchronization with multiple hydrophone inputs, and a hardware-accelerated
implementation of the CARFAC models on a Field-Programmable Gate Array (FPGA)
for real-time sound pre-processing. Compared to prior work, the CARFAC
accelerator achieves improved scalability and processing speed while reducing
resource usage through optimized time-multiplexing, pipelined design, and
elimination of costly division circuits. Experimental results demonstrate 13.5%
hardware utilization for a single 64-channel CARFAC instance and a whole board
power consumption of 3.11 W when processing a 256 kHz input signal in real
time.

</details>


### [40] [UniFlow: Unifying Speech Front-End Tasks via Continuous Generative Modeling](https://arxiv.org/abs/2508.07558)
*Ziqian Wang,Zikai Liu,Yike Zhu,Xingchen Li,Boyi Kang,Jixun Yao,Xianjun Xia,Chuanzeng Huang,Lei Xie*

Main category: eess.AS

TL;DR: UniFlow是一个统一的生成建模框架，用于解决多种语音前端任务，通过共享潜在空间和条件嵌入实现高效扩展。


<details>
  <summary>Details</summary>
Motivation: 当前语音前端任务（如语音增强、目标说话人提取等）通常采用任务特定的解决方案，导致冗余和性能不一致。UniFlow旨在通过统一框架解决这一问题。

Method: UniFlow结合波形变分自编码器（VAE）和扩散变换器（DiT），在潜在空间中进行连续生成建模，并使用任务ID的条件嵌入实现参数共享。

Result: 在多个公开基准测试中，UniFlow表现优于现有方法，展示了其高效性和扩展性。

Conclusion: UniFlow为生成语音处理提供了一个统一且可扩展的基础，未来将开源代码以促进研究。

Abstract: Generative modeling has recently achieved remarkable success across image,
video, and audio domains, demonstrating powerful capabilities for unified
representation learning. Yet speech front-end tasks such as speech enhancement
(SE), target speaker extraction (TSE), acoustic echo cancellation (AEC), and
language-queried source separation (LASS) remain largely tackled by disparate,
task-specific solutions. This fragmentation leads to redundant engineering
effort, inconsistent performance, and limited extensibility. To address this
gap, we introduce UniFlow, a unified framework that employs continuous
generative modeling to tackle diverse speech front-end tasks in a shared latent
space. Specifically, UniFlow utilizes a waveform variational autoencoder (VAE)
to learn a compact latent representation of raw audio, coupled with a Diffusion
Transformer (DiT) that predicts latent updates. To differentiate the speech
processing task during the training, learnable condition embeddings indexed by
a task ID are employed to enable maximal parameter sharing while preserving
task-specific adaptability. To balance model performance and computational
efficiency, we investigate and compare three generative objectives: denoising
diffusion, flow matching, and mean flow within the latent domain. We validate
UniFlow on multiple public benchmarks, demonstrating consistent gains over
state-of-the-art baselines. UniFlow's unified latent formulation and
conditional design make it readily extensible to new tasks, providing an
integrated foundation for building and scaling generative speech processing
pipelines. To foster future research, we will open-source our codebase.

</details>


### [41] [Is GAN Necessary for Mel-Spectrogram-based Neural Vocoder?](https://arxiv.org/abs/2508.07711)
*Hui-Peng Du,Yang Ai,Rui-Chen Zheng,Ye-Xin Lu,Zhen-Hua Ling*

Main category: eess.AS

TL;DR: 本文提出了一种名为FreeGAN的新型神经声码器，旨在探讨GAN在基于mel频谱图的神经声码器中是否必要。FreeGAN通过振幅-相位串行预测框架取代GAN训练，并引入多项技术提升性能。实验表明其语音质量与GAN声码器相当，同时显著提升训练效率和复杂度。


<details>
  <summary>Details</summary>
Motivation: 主流基于mel频谱图的神经声码器依赖GAN实现高保真语音生成，但GAN限制了训练效率和模型复杂度。本文旨在探索GAN是否必要。

Method: FreeGAN采用振幅-相位串行预测框架，无需GAN训练。结合振幅先验输入、SNAKE-ConvNeXt v2骨干网络和频率加权抗缠绕相位损失，弥补无GAN的性能损失。

Result: 实验证明FreeGAN的语音质量与先进GAN声码器相当，同时显著提升训练效率和复杂度。

Conclusion: FreeGAN证明GAN在基于mel频谱图的神经声码器中并非必需，其他显式相位预测声码器也可借鉴其方法。

Abstract: Recently, mainstream mel-spectrogram-based neural vocoders rely on generative
adversarial network (GAN) for high-fidelity speech generation, e.g., HiFi-GAN
and BigVGAN. However, the use of GAN restricts training efficiency and model
complexity. Therefore, this paper proposes a novel FreeGAN vocoder, aiming to
answer the question of whether GAN is necessary for mel-spectrogram-based
neural vocoders. The FreeGAN employs an amplitude-phase serial prediction
framework, eliminating the need for GAN training. It incorporates amplitude
prior input, SNAKE-ConvNeXt v2 backbone and frequency-weighted anti-wrapping
phase loss to compensate for the performance loss caused by the absence of GAN.
Experimental results confirm that the speech quality of FreeGAN is comparable
to that of advanced GAN-based vocoders, while significantly improving training
efficiency and complexity. Other explicit-phase-prediction-based neural
vocoders can also work without GAN, leveraging our proposed methods.

</details>


### [42] [Score-Informed BiLSTM Correction for Refining MIDI Velocity in Automatic Piano Transcription](https://arxiv.org/abs/2508.07757)
*Zhanhong He,Roberto Togneri,Defeng,Huang*

Main category: eess.AS

TL;DR: 论文提出了一种基于BiLSTM的修正模块，用于改进自动音乐转录（AMT）中的MIDI速度估计，尽管未达到最优性能，但在高分辨率钢琴转录（HPT）上取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 现有AMT系统生成的MIDI速度估计往往不准确，需要进一步修正。论文旨在通过修正模块提升AMT估计的准确性。

Method: 采用BiLSTM修正模块对AMT估计的MIDI速度进行优化，而非完全替换AMT估计。

Result: 在HPT系统上验证了方法的有效性，取得了显著改进，但未达到最优性能。

Conclusion: BiLSTM修正模块能够有效改进AMT生成的MIDI速度估计，为未来研究提供了方向。

Abstract: MIDI is a modern standard for storing music, recording how musical notes are
played. Many piano performances have corresponding MIDI scores available
online. Some of these are created by the original performer, recording on an
electric piano alongside the audio, while others are through manual
transcription. In recent years, automatic music transcription (AMT) has rapidly
advanced, enabling machines to transcribe MIDI from audio. However, these
transcriptions often require further correction. Assuming a perfect timing
correction, we focus on the loudness correction in terms of MIDI velocity (a
parameter in MIDI for loudness control). This task can be approached through
score-informed MIDI velocity estimation, which has undergone several
developments. While previous approaches introduced specifically built models to
re-estimate MIDI velocity, thereby replacing AMT estimates, we propose a BiLSTM
correction module to refine AMT-estimated velocity. Although we did not reach
state-of-the-art performance, we validated our method on the well-known AMT
system, the high-resolution piano transcription (HPT), and achieved significant
improvements.

</details>


### [43] [Auditory Intelligence: Understanding the World Through Sound](https://arxiv.org/abs/2508.07829)
*Hyeonuk Nam*

Main category: eess.AS

TL;DR: 论文提出了一种新的听觉智能框架，强调从表面识别转向包含感知、推理和交互的分层过程，并提出了四种认知启发的任务范式。


<details>
  <summary>Details</summary>
Motivation: 当前听觉智能系统仅限于表面识别，缺乏对事件原因、含义和上下文的理解。

Method: 提出了四种任务范式（ASPIRE、SODA、AUX、AUGMENT），分别关注时间-频率模式描述、分层事件/场景描述、因果解释和目标驱动解释。

Result: 这些范式为更通用、可解释且与人类对齐的听觉智能提供了路线图。

Conclusion: 论文旨在推动机器理解声音的更广泛讨论，并促进听觉智能的进一步发展。

Abstract: Recent progress in auditory intelligence has yielded high-performing systems
for sound event detection (SED), acoustic scene classification (ASC), automated
audio captioning (AAC), and audio question answering (AQA). Yet these tasks
remain largely constrained to surface-level recognition-capturing what happened
but not why, what it implies, or how it unfolds in context. I propose a
conceptual reframing of auditory intelligence as a layered, situated process
that encompasses perception, reasoning, and interaction. To instantiate this
view, I introduce four cognitively inspired task paradigms-ASPIRE, SODA, AUX,
and AUGMENT-those structure auditory understanding across time-frequency
pattern captioning, hierarchical event/scene description, causal explanation,
and goal-driven interpretation, respectively. Together, these paradigms provide
a roadmap toward more generalizable, explainable, and human-aligned auditory
intelligence, and are intended to catalyze a broader discussion of what it
means for machines to understand sound.

</details>


### [44] [G-IFT: A Gated Linear Unit adapter with Iterative Fine-Tuning for Low-Resource Children's Speaker Verification](https://arxiv.org/abs/2508.07836)
*Vishwas M. Shetty,Jiusi Zheng,Abeer Alwan*

Main category: eess.AS

TL;DR: 论文提出了一种名为G-IFT的创新框架，通过门控线性单元适配器和迭代微调，提升成人语音到儿童语音的知识迁移效率，显著降低了错误率。


<details>
  <summary>Details</summary>
Motivation: 成人语音训练的说话人验证系统在儿童语音上表现不佳，且儿童语音数据有限，微调效果不理想。

Method: 在预训练说话人嵌入模型和分类器之间插入门控线性单元适配器，并采用迭代方式依次优化分类器、适配器和嵌入模型。

Result: 在ECAPA-TDNN、ResNet和X-vector架构上，G-IFT框架相比基线方法显著降低了等错误率。

Conclusion: G-IFT框架能高效迁移知识，适用于多种说话人验证系统架构，显著提升儿童语音的验证性能。

Abstract: Speaker Verification (SV) systems trained on adults speech often underperform
on children's SV due to the acoustic mismatch, and limited children speech data
makes fine-tuning not very effective. In this paper, we propose an innovative
framework, a Gated Linear Unit adapter with Iterative Fine-Tuning (G-IFT), to
enhance knowledge transfer efficiency between the high-resource adults speech
domain and the low-resource children's speech domain. In this framework, a
Gated Linear Unit adapter is first inserted between the pre-trained speaker
embedding model and the classifier. Then the classifier, adapter, and
pre-trained speaker embedding model are optimized sequentially in an iterative
way. This framework is agnostic to the type of the underlying architecture of
the SV system. Our experiments on ECAPA-TDNN, ResNet, and X-vector
architectures using the OGI and MyST datasets demonstrate that the G-IFT
framework yields consistent reductions in Equal Error Rates compared to
baseline methods.

</details>


### [45] [MSU-Bench: Towards Understanding the Conversational Multi-talker Scenarios](https://arxiv.org/abs/2508.08155)
*Shuai Wang,Zhaokai Sun,Zhennan Lin,Chengyou Wang,Zhou Pan,Lei Xie*

Main category: eess.AS

TL;DR: MSU-Bench是一个针对多说话人对话理解的新基准，通过分层任务设计评估模型性能，发现现有模型在复杂任务中表现显著下降。


<details>
  <summary>Details</summary>
Motivation: 现有语音基准多关注单说话人或孤立任务，忽略了现实场景中多说话人对话的挑战。

Method: 引入MSU-Bench，一个分层框架，覆盖从单说话人到多说话人交互的四个渐进任务层级。

Result: 随着任务复杂度增加，所有模型性能显著下降，开源模型与闭源商业模型在多说话人交互推理上存在能力差距。

Conclusion: MSU-Bench有效评估和推进了现实多说话人环境中的对话理解能力。

Abstract: Spoken Language Understanding (SLU) has progressed from traditional
single-task methods to large audio language model (LALM) solutions. Yet, most
existing speech benchmarks focus on single-speaker or isolated tasks,
overlooking the challenges posed by multi-speaker conversations that are common
in real-world scenarios. We introduce MSU-Bench, a comprehensive benchmark for
evaluating multi-speaker conversational understanding with a speaker-centric
design. Our hierarchical framework covers four progressive tiers:
single-speaker static attribute understanding, single-speaker dynamic attribute
understanding, multi-speaker background understanding, and multi-speaker
interaction understanding. This structure ensures all tasks are grounded in
speaker-centric contexts, from basic perception to complex reasoning across
multiple speakers. By evaluating state-of-the-art models on MSU-Bench, we
demonstrate that as task complexity increases across the benchmark's tiers, all
models exhibit a significant performance decline. We also observe a persistent
capability gap between open-source models and closed-source commercial ones,
particularly in multi-speaker interaction reasoning. These findings validate
the effectiveness of MSU-Bench for assessing and advancing conversational
understanding in realistic multi-speaker environments. Demos can be found in
the supplementary material.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [46] [AutoMashup: Automatic Music Mashups Creation](https://arxiv.org/abs/2508.06516)
*Marine Delabaere,Léa Miqueu,Michael Moreno,Gautier Bigois,Hoang Duong,Ella Fernandez,Flavie Manent,Maria Salgado-Herrera,Bastien Pasdeloup,Nicolas Farrugia,Axel Marmoret*

Main category: cs.SD

TL;DR: AutoMashup系统通过源分离、音乐分析和兼容性评估自动创建混音，发现混音兼容性不对称且通用音频模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 研究混音创作中兼容性评估的挑战，探索通用预训练音频模型在零样本兼容性估计中的适用性。

Method: 使用COCOLA评估分离音轨的兼容性，测试CLAP和MERT模型在零样本兼容性估计中的表现。

Result: 混音兼容性不对称，依赖音轨角色（人声或伴奏），当前音频嵌入无法复现COCOLA测量的感知一致性。

Conclusion: 通用音频表示在混音创作兼容性估计中存在局限性，需进一步改进。

Abstract: We introduce AutoMashup, a system for automatic mashup creation based on
source separation, music analysis, and compatibility estimation. We propose
using COCOLA to assess compatibility between separated stems and investigate
whether general-purpose pretrained audio models (CLAP and MERT) can support
zero-shot estimation of track pair compatibility. Our results show that mashup
compatibility is asymmetric -- it depends on the role assigned to each track
(vocals or accompaniment) -- and that current embeddings fail to reproduce the
perceptual coherence measured by COCOLA. These findings underline the
limitations of general-purpose audio representations for compatibility
estimation in mashup creation.

</details>


### [47] [Maestro-EVC: Controllable Emotional Voice Conversion Guided by References and Explicit Prosody](https://arxiv.org/abs/2508.06890)
*Jinsung Yoon,Wooyeol Jeong,Jio Gim,Young-Joo Suh*

Main category: cs.SD

TL;DR: Maestro-EVC是一种可控的情感语音转换框架，能够独立控制内容、说话人身份和情感，并通过时间情感表示和显式韵律建模捕捉情感动态。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以完全解耦说话人身份和情感风格，且无法建模细粒度情感表达（如时间动态）。

Method: 提出Maestro-EVC框架，通过分离参考解耦各属性，并引入时间情感表示和显式韵律建模。

Result: 实验表明，Maestro-EVC实现了高质量、可控且情感丰富的语音合成。

Conclusion: Maestro-EVC在情感语音转换中表现出色，尤其在解耦属性和捕捉情感动态方面。

Abstract: Emotional voice conversion (EVC) aims to modify the emotional style of speech
while preserving its linguistic content. In practical EVC, controllability, the
ability to independently control speaker identity and emotional style using
distinct references, is crucial. However, existing methods often struggle to
fully disentangle these attributes and lack the ability to model fine-grained
emotional expressions such as temporal dynamics. We propose Maestro-EVC, a
controllable EVC framework that enables independent control of content, speaker
identity, and emotion by effectively disentangling each attribute from separate
references. We further introduce a temporal emotion representation and an
explicit prosody modeling with prosody augmentation to robustly capture and
transfer the temporal dynamics of the target emotion, even under
prosody-mismatched conditions. Experimental results confirm that Maestro-EVC
achieves high-quality, controllable, and emotionally expressive speech
synthesis.

</details>


### [48] [Whisfusion: Parallel ASR Decoding via a Diffusion Transformer](https://arxiv.org/abs/2508.07048)
*Taeyoun Kwon,Junhyuk Ahn,Taegeun Yun,Heeju Jwa,Yoonchae Choi,Siwon Park,Nam-Joon Kim,Jangchan Kim,Hyun Gon Ryu,Hyuk-Jae Lee*

Main category: cs.SD

TL;DR: Whisfusion框架结合Whisper编码器和文本扩散解码器，解决了AR解码器的延迟问题，提升了长音频ASR的效率。


<details>
  <summary>Details</summary>
Motivation: 解决自动语音识别（ASR）中AR解码器的顺序处理导致的延迟问题，尤其是长音频场景。

Method: 提出Whisfusion框架，融合Whisper编码器和文本扩散解码器，通过参数高效微调（PEFT）训练跨注意力适配器，并采用批量并行多步解码策略。

Result: 在LibriSpeech上，Whisfusion的WER低于Whisper-tiny（8.3% vs. 9.7%），长音频处理速度提升2.6倍。

Conclusion: Whisfusion为长音频ASR提供了高效的新解决方案，平衡了准确性和延迟。

Abstract: Fast Automatic Speech Recognition (ASR) is critical for latency-sensitive
applications such as real-time captioning and meeting transcription. However,
truly parallel ASR decoding remains challenging due to the sequential nature of
autoregressive (AR) decoders and the context limitations of non-autoregressive
(NAR) methods. While modern ASR encoders can process up to 30 seconds of audio
at once, AR decoders still generate tokens sequentially, creating a latency
bottleneck. We propose Whisfusion, the first framework to fuse a pre-trained
Whisper encoder with a text diffusion decoder. This NAR architecture resolves
the AR latency bottleneck by processing the entire acoustic context in parallel
at every decoding step. A lightweight cross-attention adapter trained via
parameter-efficient fine-tuning (PEFT) bridges the two modalities. We also
introduce a batch-parallel, multi-step decoding strategy that improves accuracy
by increasing the number of candidates with minimal impact on speed. Fine-tuned
solely on LibriSpeech (960h), Whisfusion achieves a lower WER than Whisper-tiny
(8.3% vs. 9.7%), and offers comparable latency on short audio. For longer
utterances (>20s), it is up to 2.6x faster than the AR baseline, establishing a
new, efficient operating point for long-form ASR. The implementation and
training scripts are available at https://github.com/taeyoun811/Whisfusion.

</details>


### [49] [SEF-MK: Speaker-Embedding-Free Voice Anonymization through Multi-k-means Quantization](https://arxiv.org/abs/2508.07086)
*Beilong Tang,Xiaoxiao Miao,Xin Wang,Ming Li*

Main category: cs.SD

TL;DR: SEF-MK是一种新的语音匿名化框架，通过随机选择多个k-means模型之一来匿名化SSL表示，以保护说话人隐私。


<details>
  <summary>Details</summary>
Motivation: 保护说话人隐私，同时保留语言和副语言内容。

Method: 提出SEF-MK框架，使用多个k-means模型（每个模型基于不同说话人子集训练）随机匿名化SSL表示。

Result: 从用户角度看，SEF-MK更好地保留了语言和情感内容；但从攻击者角度看，多模型增加了隐私攻击的有效性。

Conclusion: SEF-MK为设计语音匿名化系统提供了新思路，需权衡隐私保护与攻击风险。

Abstract: Voice anonymization protects speaker privacy by concealing identity while
preserving linguistic and paralinguistic content. Self-supervised learning
(SSL) representations encode linguistic features but preserve speaker traits.
We propose a novel speaker-embedding-free framework called SEF-MK. Instead of
using a single k-means model trained on the entire dataset, SEF-MK anonymizes
SSL representations for each utterance by randomly selecting one of multiple
k-means models, each trained on a different subset of speakers. We explore this
approach from both attacker and user perspectives. Extensive experiments show
that, compared to a single k-means model, SEF-MK with multiple k-means models
better preserves linguistic and emotional content from the user's viewpoint.
However, from the attacker's perspective, utilizing multiple k-means models
boosts the effectiveness of privacy attacks. These insights can aid users in
designing voice anonymization systems to mitigate attacker threats.

</details>


### [50] [Inversion of Arctic dual-channel sound speed profile based on random airgun signal](https://arxiv.org/abs/2508.07152)
*Jinbao Weng,Yubo Qi,Yanming Yang,Hongtao Wen,Hongtao Zhou,Benqing Chen,Dewei Xu,Ruichao Xue,Caigao Zeng*

Main category: cs.SD

TL;DR: 提出了一种基于折射简正波的双通道声速剖面反演方法，适用于北极加拿大盆地和楚科奇高原的独特双通道声速剖面。该方法通过双参数表示法和色散结构提取方法，结合水平变化反演技术，验证了其高效性和低成本优势。


<details>
  <summary>Details</summary>
Motivation: 针对北极地区独特的双通道声速剖面及其在长距离声传播中的水平变化问题，提出一种高效、低成本的反演方法。

Method: 提出双参数表示法描述双通道声速剖面，结合折射简正波的色散结构提取方法，并扩展至水平变化的反演。

Result: 通过北极低频远程声传播实验验证，该方法反演参数少、速度快，仅需单水听器被动接收随机气枪信号即可实现。

Conclusion: 该方法在双通道声速剖面反演中具有参数少、速度快、低成本等显著优势，解决了水平变化的反演问题。

Abstract: For the unique dual-channel sound speed profiles of the Canadian Basin and
the Chukchi Plateau in the Arctic, based on the propagation characteristics of
refracted normal modes under dual-channel sound speed profiles, an inversion
method using refracted normal modes for dual-channel sound speed profiles is
proposed. This method proposes a dual-parameter representation method for
dual-channel sound speed profiles, tailored to the characteristics of
dual-channel sound speed profiles. A dispersion structure extraction method is
proposed for the dispersion structure characteristics of refracted normal modes
under dual-channel sound speed profiles. Combining the parameter representation
method of sound speed profiles and the dispersion structure extraction method,
an inversion method for dual-channel sound speed profiles is proposed. For the
common horizontal variation of sound speed profiles in long-distance acoustic
propagation, a method for inverting horizontally varying dual-channel sound
speed profiles is proposed. Finally, this article verifies the effectiveness of
the dual-channel sound speed profile inversion method using the Arctic
low-frequency long-range acoustic propagation experiment. Compared with
previous sound speed profile inversion methods, the method proposed in this
article has the advantages of fewer inversion parameters and faster inversion
speed. It can be implemented using only a single hydrophone passively receiving
random air gun signals, and it also solves the inversion problem of horizontal
variation of sound speed profiles. It has significant advantages such as low
cost, easy deployment, and fast computation speed.

</details>


### [51] [Acoustic source depth estimation method based on a single hydrophone in Arctic underwater](https://arxiv.org/abs/2508.07157)
*Jinbao Weng,Yubo Qi,Yanming Yang,Hongtao Wen,Hongtao Zhou,Benqing Chen,Dewei Xu,Ruichao Xue,Caigao Zeng*

Main category: cs.SD

TL;DR: 本文基于简正波和射线理论，探讨了表层声源和接收的特性，提出了基于简正波频率上限和射线到达时间差的深度估计方法，并通过实验数据验证了方法的适用性和局限性。


<details>
  <summary>Details</summary>
Motivation: 研究目的是探索不同环境下声源深度估计的有效方法，特别是在表面折射简正波波导和深海北极区域。

Method: 提出了基于简正波频率上限和振幅信息匹配的深度估计方法，以及通过射线到达时间差匹配的深度估计方法。

Result: 实验数据验证了简正波和射线方法在不同环境下的适用性，并揭示了其局限性。

Conclusion: 简正波和射线方法在特定环境下能有效估计声源深度，但需根据实际条件选择合适方法。

Abstract: Based on the normal mode and ray theory, this article discusses the
characteristics of surface sound source and reception at the surface layer, and
explores depth estimation methods based on normal modes and rays, and proposes
a depth estimation method based on the upper limit of modal frequency. Data
verification is conducted to discuss the applicability and limitations of
different methods. For the surface refracted normal mode waveguide, modes can
be separated through warping transformation. Based on the characteristics of
normal mode amplitude variation with frequency and number, the sound source
depth can be estimated by matching amplitude information. Based on the spatial
variation characteristics of eigenfunctions with frequency, a sound source
depth estimation method matching the cutoff frequency of normal modes is
proposed. For the deep Arctic sea, the sound ray arrival structure at the
receiving end is obtained through the analysis of deep inversion sound ray
trajectories, and the sound source depth can be estimated by matching the time
difference of ray arrivals. Experimental data is used to verify the sound field
patterns and the effectiveness of the sound source depth estimation method.

</details>


### [52] [Noise-Robust Sound Event Detection and Counting via Language-Queried Sound Separation](https://arxiv.org/abs/2508.07176)
*Yuanjian Chen,Yang Xiao,Han Yin,Yadong Guan,Xubo Liu*

Main category: cs.SD

TL;DR: 提出了一种基于事件出现检测（EAD）的多任务学习框架，用于提升噪声环境下的声音事件检测（SED）性能。


<details>
  <summary>Details</summary>
Motivation: 现有SED系统在噪声环境中性能显著下降，且语言查询音频源分离（LASS）模型缺乏对目标事件的明确指导。

Method: 引入EAD计数方法，设计多任务学习框架，通过任务约束提升SED和EAD的预测一致性。

Result: 在DESED和WildDESED数据集上表现优于现有方法，噪声越高优势越明显。

Conclusion: 该框架为LASS模型提供了更可靠的预测，并增强了时间戳检测能力。

Abstract: Most sound event detection (SED) systems perform well on clean datasets but
degrade significantly in noisy environments. Language-queried audio source
separation (LASS) models show promise for robust SED by separating target
events; existing methods require elaborate multi-stage training and lack
explicit guidance for target events. To address these challenges, we introduce
event appearance detection (EAD), a counting-based approach that counts event
occurrences at both the clip and frame levels. Based on EAD, we propose a
co-training-based multi-task learning framework for EAD and SED to enhance
SED's performance in noisy environments. First, SED struggles to learn the same
patterns as EAD. Then, a task-based constraint is designed to improve
prediction consistency between SED and EAD. This framework provides more
reliable clip-level predictions for LASS models and strengthens timestamp
detection capability. Experiments on DESED and WildDESED datasets demonstrate
better performance compared to existing methods, with advantages becoming more
pronounced at higher noise levels.

</details>


### [53] [Keyword Mamba: Spoken Keyword Spotting with State Space Models](https://arxiv.org/abs/2508.07363)
*Hanyu Ding,Wenlong Dong,Qirong Mao*

Main category: cs.SD

TL;DR: 论文提出了一种名为Keyword Mamba的新架构，用于关键词检测（KWS），采用神经状态空间模型（SSM）Mamba，在保持高效的同时解决了长期模式处理问题。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型（如CNN、RNN、Transformer）在KWS任务中表现良好，但难以同时处理长期模式并保持高效。

Method: 提出Keyword Mamba架构，将Mamba应用于时间轴，并探索其替代Transformer中的自注意力机制。

Result: 在Google Speech Commands数据集上测试，Keyword Mamba以更少的参数和更低的计算成本实现了高准确率。

Conclusion: Mamba在语音相关任务中具有强大潜力，这是首次将状态空间模型用于KWS。

Abstract: Keyword spotting (KWS) is an essential task in speech processing. It is
widely used in voice assistants and smart devices. Deep learning models like
CNNs, RNNs, and Transformers have performed well in KWS. However, they often
struggle to handle long-term patterns and stay efficient at the same time. In
this work, we present Keyword Mamba, a new architecture for KWS. It uses a
neural state space model (SSM) called Mamba. We apply Mamba along the time axis
and also explore how it can replace the self-attention part in Transformer
models. We test our model on the Google Speech Commands datasets. The results
show that Keyword Mamba reaches strong accuracy with fewer parameters and lower
computational cost. To our knowledge, this is the first time a state space
model has been used for KWS. These results suggest that Mamba has strong
potential in speech-related tasks.

</details>


### [54] [A Small-footprint Acoustic Echo Cancellation Solution for Mobile Full-Duplex Speech Interactions](https://arxiv.org/abs/2508.07561)
*Yiheng Jiang,Tian Biao*

Main category: cs.SD

TL;DR: 本文提出了一种基于神经网络的声学回声消除（AEC）方法，通过数据增强和渐进学习提升模型鲁棒性，并引入后处理策略优化下游任务（如VAD和ASR），最终实现移动设备上的高效部署。


<details>
  <summary>Details</summary>
Motivation: 在移动场景中，硬件差异、非线性失真和高延迟等问题使得声学回声消除（AEC）具有挑战性，需要一种高效且鲁棒的解决方案。

Method: 结合多样数据增强和渐进学习提升模型鲁棒性，采用小模型和流式推理实现移动部署，并引入后处理策略优化下游任务。

Result: 在回声损失增强（ERLE）和语音质量感知评估（PESQ）上表现优异，同时显著提升了VAD和ASR的效果。

Conclusion: 该方法在移动场景中实现了高效的声学回声消除，并优化了下游任务性能，具有实际应用价值。

Abstract: In full-duplex speech interaction systems, effective Acoustic Echo
Cancellation (AEC) is crucial for recovering echo-contaminated speech. This
paper presents a neural network-based AEC solution to address challenges in
mobile scenarios with varying hardware, nonlinear distortions and long latency.
We first incorporate diverse data augmentation strategies to enhance the
model's robustness across various environments. Moreover, progressive learning
is employed to incrementally improve AEC effectiveness, resulting in a
considerable improvement in speech quality. To further optimize AEC's
downstream applications, we introduce a novel post-processing strategy
employing tailored parameters designed specifically for tasks such as Voice
Activity Detection (VAD) and Automatic Speech Recognition (ASR), thus enhancing
their overall efficacy. Finally, our method employs a small-footprint model
with streaming inference, enabling seamless deployment on mobile devices.
Empirical results demonstrate effectiveness of the proposed method in Echo
Return Loss Enhancement and Perceptual Evaluation of Speech Quality, alongside
significant improvements in both VAD and ASR results.

</details>


### [55] [Exploring Efficient Directional and Distance Cues for Regional Speech Separation](https://arxiv.org/abs/2508.07563)
*Yiheng Jiang,Haoxu Wang,Yafeng Chen,Gang Qiao,Biao Tian*

Main category: cs.SD

TL;DR: 提出了一种基于神经网络的区域语音分离方法，利用麦克风阵列和空间线索，结合改进的延迟求和技术和直达混响比，显著提升了分离效果。


<details>
  <summary>Details</summary>
Motivation: 解决传统语音分离方法在指定方向和距离内提取声源的局限性，提升实际应用中的分离性能。

Method: 采用改进的延迟求和技术获取方向线索，并结合直达混响比作为输入特征，增强模型对距离内外的声源区分能力。

Result: 实验表明，该方法在多个客观指标上显著提升，并在CHiME-8 MMCSG数据集上达到最先进性能。

Conclusion: 该方法在真实对话场景中表现出色，适用于实际语音分离应用。

Abstract: In this paper, we introduce a neural network-based method for regional speech
separation using a microphone array. This approach leverages novel spatial cues
to extract the sound source not only from specified direction but also within
defined distance. Specifically, our method employs an improved delay-and-sum
technique to obtain directional cues, substantially enhancing the signal from
the target direction. We further enhance separation by incorporating the
direct-to-reverberant ratio into the input features, enabling the model to
better discriminate sources within and beyond a specified distance.
Experimental results demonstrate that our proposed method leads to substantial
gains across multiple objective metrics. Furthermore, our method achieves
state-of-the-art performance on the CHiME-8 MMCSG dataset, which was recorded
in real-world conversational scenarios, underscoring its effectiveness for
speech separation in practical applications.

</details>


### [56] [Filling MIDI Velocity using U-Net Image Colorizer](https://arxiv.org/abs/2508.07751)
*Zhanhong He,David Cooper,Defeng Huang,Roberto Togneri*

Main category: cs.SD

TL;DR: 论文提出了一种基于U-Net架构的MIDI速度预测方法，通过将MIDI数据视为图像并采用窗口注意力和自定义损失函数，提升了音乐表现力。


<details>
  <summary>Details</summary>
Motivation: 现代音乐制作中，MIDI文件常缺乏人类演奏的表现力，尤其是速度参数（音符响度）常为默认值。因此，需要一种方法预测并填充MIDI速度以增强音乐表达。

Method: 将MIDI数据视为图像，采用U-Net架构，结合窗口注意力和自定义损失函数，以解决MIDI转换图像的稀疏性问题。实验限于钢琴数据。

Result: 在MAESTRO v3和SMD数据集上，该方法在定量指标和定性听觉测试中均优于先前方法。

Conclusion: 提出的U-Net方法有效提升了MIDI速度预测的性能，为音乐表现力的增强提供了新思路。

Abstract: Modern music producers commonly use MIDI (Musical Instrument Digital
Interface) to store their musical compositions. However, MIDI files created
with digital software may lack the expressive characteristics of human
performances, essentially leaving the velocity parameter - a control for note
loudness - undefined, which defaults to a flat value. The task of filling MIDI
velocity is termed MIDI velocity prediction, which uses regression models to
enhance music expressiveness by adjusting only this parameter. In this paper,
we introduce the U-Net, a widely adopted architecture in image colorization, to
this task. By conceptualizing MIDI data as images, we adopt window attention
and develop a custom loss function to address the sparsity of MIDI-converted
images. Current dataset availability restricts our experiments to piano data.
Evaluated on the MAESTRO v3 and SMD datasets, our proposed method for filling
MIDI velocity outperforms previous approaches in both quantitative metrics and
qualitative listening tests.

</details>


### [57] [SCDF: A Speaker Characteristics DeepFake Speech Dataset for Bias Analysis](https://arxiv.org/abs/2508.07944)
*Vojtěch Staněk,Karel Srna,Anton Firc,Kamil Malinka*

Main category: cs.SD

TL;DR: 论文介绍了SCDF数据集，用于评估深度伪造语音检测中的偏见问题，发现检测性能受说话者特征影响显著。


<details>
  <summary>Details</summary>
Motivation: 当前深度伪造语音检测中对偏见和公平性的研究不足，需填补这一空白。

Method: 构建SCDF数据集，包含多种说话者特征，并评估现有检测器的性能。

Result: 检测性能在性别、语言、年龄和合成器类型上存在显著差异。

Conclusion: 需开发偏见感知的检测系统，符合伦理和监管标准。

Abstract: Despite growing attention to deepfake speech detection, the aspects of bias
and fairness remain underexplored in the speech domain. To address this gap, we
introduce the Speaker Characteristics Deepfake (SCDF) dataset: a novel, richly
annotated resource enabling systematic evaluation of demographic biases in
deepfake speech detection. SCDF contains over 237,000 utterances in a balanced
representation of both male and female speakers spanning five languages and a
wide age range. We evaluate several state-of-the-art detectors and show that
speaker characteristics significantly influence detection performance,
revealing disparities across sex, language, age, and synthesizer type. These
findings highlight the need for bias-aware development and provide a foundation
for building non-discriminatory deepfake detection systems aligned with ethical
and regulatory standards.

</details>


### [58] [Joint Transcription of Acoustic Guitar Strumming Directions and Chords](https://arxiv.org/abs/2508.07973)
*Sebastian Murgul,Johannes Schimper,Michael Heizmann*

Main category: cs.SD

TL;DR: 本文提出了一种基于深度学习的吉他弹奏转录方法，结合真实和合成数据集，显著提升了弹奏方向和和弦分类的准确性。


<details>
  <summary>Details</summary>
Motivation: 吉他弹奏转录在音乐信息检索中是一个具有挑战性且研究不足的任务，现有方法因数据集有限而效果受限。

Method: 采用卷积循环神经网络（CRNN）模型，结合ESP32智能手表运动传感器收集的真实数据集和合成数据集，进行弹奏事件检测、方向分类及和弦识别。

Result: 评估显示，结合合成和真实数据的混合方法在弹奏动作检测与和弦分类上均达到最高准确率。

Conclusion: 该研究展示了深度学习在吉他弹奏转录中的潜力，为自动节奏吉他分析开辟了新途径。

Abstract: Automatic transcription of guitar strumming is an underrepresented and
challenging task in Music Information Retrieval (MIR), particularly for
extracting both strumming directions and chord progressions from audio signals.
While existing methods show promise, their effectiveness is often hindered by
limited datasets. In this work, we extend a multimodal approach to guitar
strumming transcription by introducing a novel dataset and a deep
learning-based transcription model. We collect 90 min of real-world guitar
recordings using an ESP32 smartwatch motion sensor and a structured recording
protocol, complemented by a synthetic dataset of 4h of labeled strumming audio.
A Convolutional Recurrent Neural Network (CRNN) model is trained to detect
strumming events, classify their direction, and identify the corresponding
chords using only microphone audio. Our evaluation demonstrates significant
improvements over baseline onset detection algorithms, with a hybrid method
combining synthetic and real-world data achieving the highest accuracy for both
strumming action detection and chord classification. These results highlight
the potential of deep learning for robust guitar strumming transcription and
open new avenues for automatic rhythm guitar analysis.

</details>


### [59] [Exploring Procedural Data Generation for Automatic Acoustic Guitar Fingerpicking Transcription](https://arxiv.org/abs/2508.07987)
*Sebastian Murgul,Michael Heizmann*

Main category: cs.SD

TL;DR: 论文探讨了通过程序化生成数据训练吉他指弹转录模型，替代稀缺的真实录音数据，取得了合理效果。


<details>
  <summary>Details</summary>
Motivation: 解决吉他指弹转录任务中标记数据稀缺和法律限制的问题。

Method: 采用四阶段程序化数据生成流程：基于知识的指弹谱编写、MIDI演奏渲染、扩展Karplus-Strong算法的物理建模、音频增强（混响和失真）。

Result: 在真实和合成数据集上训练的CRNN模型表现合理，少量真实数据微调后效果更佳。

Conclusion: 程序化生成音频在数据稀缺的音乐信息检索任务中具有潜力。

Abstract: Automatic transcription of acoustic guitar fingerpicking performances remains
a challenging task due to the scarcity of labeled training data and legal
constraints connected with musical recordings. This work investigates a
procedural data generation pipeline as an alternative to real audio recordings
for training transcription models. Our approach synthesizes training data
through four stages: knowledge-based fingerpicking tablature composition, MIDI
performance rendering, physical modeling using an extended Karplus-Strong
algorithm, and audio augmentation including reverb and distortion. We train and
evaluate a CRNN-based note-tracking model on both real and synthetic datasets,
demonstrating that procedural data can be used to achieve reasonable
note-tracking results. Finetuning with a small amount of real data further
enhances transcription accuracy, improving over models trained exclusively on
real recordings. These results highlight the potential of procedurally
generated audio for data-scarce music information retrieval tasks.

</details>


### [60] [Bridging ASR and LLMs for Dysarthric Speech Recognition: Benchmarking Self-Supervised and Generative Approaches](https://arxiv.org/abs/2508.08027)
*Ahmed Aboeitta,Ahmed Sharshar,Youssef Nafea,Shady Shehata*

Main category: cs.SD

TL;DR: 研究比较了自监督ASR模型（如Wav2Vec、HuBERT、Whisper）在构音障碍语音中的表现，并引入LLM增强解码策略（如BART、GPT-2、Vicuna）以提升识别效果。


<details>
  <summary>Details</summary>
Motivation: 现有自监督ASR模型在构音障碍语音中的有效性尚不明确，需系统评估和改进。

Method: 通过CTC、seq2seq和LLM增强解码策略（BART、GPT-2、Vicuna）对模型进行基准测试。

Result: LLM增强解码通过利用语言约束恢复音素和修正语法，显著提升了构音障碍ASR的性能。

Conclusion: LLM增强解码是提升构音障碍语音识别的有效方法，未来可进一步优化跨数据集的泛化能力。

Abstract: Speech Recognition (ASR) due to phoneme distortions and high variability.
While self-supervised ASR models like Wav2Vec, HuBERT, and Whisper have shown
promise, their effectiveness in dysarthric speech remains unclear. This study
systematically benchmarks these models with different decoding strategies,
including CTC, seq2seq, and LLM-enhanced decoding (BART,GPT-2, Vicuna). Our
contributions include (1) benchmarking ASR architectures for dysarthric speech,
(2) introducing LLM-based decoding to improve intelligibility, (3) analyzing
generalization across datasets, and (4) providing insights into recognition
errors across severity levels. Findings highlight that LLM-enhanced decoding
improves dysarthric ASR by leveraging linguistic constraints for phoneme
restoration and grammatical correction.

</details>


### [61] [Audio-Thinker: Guiding Audio Language Model When and How to Think via Reinforcement Learning](https://arxiv.org/abs/2508.08039)
*Shu Wu,Chenxing Li,Wenfu Wang,Hao Zhang,Hualei Wang,Meng Yu,Dong Yu*

Main category: cs.SD

TL;DR: 论文提出Audio-Thinker框架，通过强化学习提升大音频语言模型的推理能力，解决现有模型在音频问答任务中推理不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有大音频语言模型在音频问答任务中推理能力不足，无法达到人类水平，需改进其适应性和一致性。

Method: 提出Audio-Thinker框架，结合自适应思维准确度奖励和外部奖励模型，动态调整推理策略并评估推理质量。

Result: 实验表明，Audio-Thinker在多个基准任务中优于现有推理导向的大音频语言模型，表现出更强的推理和泛化能力。

Conclusion: Audio-Thinker通过强化学习有效提升了大音频语言模型的推理能力，为音频问答任务提供了更优解决方案。

Abstract: Recent advancements in large language models, multimodal large language
models, and large audio language models (LALMs) have significantly improved
their reasoning capabilities through reinforcement learning with rule-based
rewards. However, the explicit reasoning process has yet to show significant
benefits for audio question answering, and effectively leveraging deep
reasoning remains an open challenge, with LALMs still falling short of
human-level auditory-language reasoning. To address these limitations, we
propose Audio-Thinker, a reinforcement learning framework designed to enhance
the reasoning capabilities of LALMs, with a focus on improving adaptability,
consistency, and effectiveness. Our approach introduces an adaptive think
accuracy reward, enabling the model to adjust its reasoning strategies based on
task complexity dynamically. Furthermore, we incorporate an external reward
model to evaluate the overall consistency and quality of the reasoning process,
complemented by think-based rewards that help the model distinguish between
valid and flawed reasoning paths during training. Experimental results
demonstrate that our Audio-Thinker model outperforms existing
reasoning-oriented LALMs across various benchmark tasks, exhibiting superior
reasoning and generalization capabilities.

</details>

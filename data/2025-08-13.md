<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 19]
- [eess.AS](#eess.AS) [Total: 9]
- [cs.SD](#cs.SD) [Total: 10]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Where is the Boundary: Multimodal Sensor Fusion Test Bench for Tissue Boundary Delineation](https://arxiv.org/abs/2508.08257)
*Zacharias Chen,Alexa Cristelle Cahilig,Sarah Dias,Prithu Kolar,Ravi Prakash,Patrick J. Codd*

Main category: eess.SP

TL;DR: 本文提出了一种模块化测试平台，用于评估和整合多模态传感器，以改善机器人辅助神经外科手术中的组织边界识别。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助手术虽提高了精确度，但限制了医生的自然感官反馈，尤其在区分健康与肿瘤组织时。多模态传感技术的研究不足，亟需解决方案。

Method: 开发了一个用户友好的测试平台，结合视觉引导、接触式麦克风和力传感器数据，通过交互式图形界面实现实时数据采集和可视化。

Result: 实验表明，多模态融合显著提高了材料分类的准确性。

Conclusion: 该平台为手术中的传感器融合提供了可扩展的硬件-软件解决方案，展示了多模态方法在实时组织边界识别中的潜力。

Abstract: Robot-assisted neurological surgery is receiving growing interest due to the
improved dexterity, precision, and control of surgical tools, which results in
better patient outcomes. However, such systems often limit surgeons' natural
sensory feedback, which is crucial in identifying tissues -- particularly in
oncological procedures where distinguishing between healthy and tumorous tissue
is vital. While imaging and force sensing have addressed the lack of sensory
feedback, limited research has explored multimodal sensing options for accurate
tissue boundary delineation. We present a user-friendly, modular test bench
designed to evaluate and integrate complementary multimodal sensors for tissue
identification. Our proposed system first uses vision-based guidance to
estimate boundary locations with visual cues, which are then refined using data
acquired by contact microphones and a force sensor. Real-time data acquisition
and visualization are supported via an interactive graphical interface.
Experimental results demonstrate that multimodal fusion significantly improves
material classification accuracy. The platform provides a scalable
hardware-software solution for exploring sensor fusion in surgical applications
and demonstrates the potential of multimodal approaches in real-time tissue
boundary delineation.

</details>


### [2] [Hardware-friendly IR-HARQ for Polar SCL Decoders](https://arxiv.org/abs/2508.08425)
*Marwan Jalaleddine,Jiajie Li,Warren J. Gross*

Main category: eess.SP

TL;DR: 论文提出了一种改进的极坐标码IR-HARQ方案，通过将基于集合的操作转换为二进制向量操作，并引入新的快速节点集成方法，以减少硬件实现中的内存开销和面积开销。


<details>
  <summary>Details</summary>
Motivation: 为了扩展极坐标码在下一代无线通信系统中的应用，需要支持IR-HARQ方案。然而，现有方案存在内存访问模式不规则和硬件实现面积开销大的问题。

Method: 将基于集合的操作转换为二进制向量操作，并引入新的快速节点集成方法，避免增加快速节点数量。

Result: 提出的方案在内存开销上比不支持IR-HARQ的SCL解码仅增加25-27%。

Conclusion: 改进后的方案显著提高了硬件兼容性，减少了内存和面积开销。

Abstract: To extend the applications of polar codes within next-generation wireless
communication systems, it is essential to incorporate support for Incremental
Redundancy (IR) Hybrid Automatic Repeat Request (HARQ) schemes. The baseline
IR-HARQ scheme's reliance on set-based operations leads to irregular memory
access patterns, posing significant challenges for efficient hardware
implementation. Furthermore, the introduction of new bit types increases the
number of fast nodes that are decoded without traversing the sub-tree,
resulting in a substantial area overhead when implemented in hardware. To
address these issues and improve hardware compatibility, we propose
transforming the set-based operations within the polar IR-HARQ scheme into
binary vector operations. Additionally, we introduce a new fast node
integration approach that avoids increasing the number of fast nodes, thereby
minimizing the associated area overhead. Our proposed scheme results in a
memory overhead of 25-27% compared to successive cancellation list (SCL)
decoding without IR-HARQ support.

</details>


### [3] [Tensor-Structured Bayesian Channel Prediction for Upper Mid-Band XL-MIMO Systems](https://arxiv.org/abs/2508.08491)
*Hongwei Hou,Yafei Wang,Xinping Yi,Wenjin Wang,Dirk T. M. Slock,Shi Jin*

Main category: eess.SP

TL;DR: 论文提出了一种新型信道预测方法，针对上中频段XL-MIMO系统中的信道老化和近场传播问题，通过张量结构建模和贝叶斯推断提升性能。


<details>
  <summary>Details</summary>
Motivation: 上中频段XL-MIMO系统在移动性下因信道老化和近场传播特性导致性能下降，需解决信道预测问题。

Method: 提出张量结构的空间-频率-时间和波束-延迟-多普勒域信道模型，结合贝叶斯推断和EM框架的TS-BLI算法。

Result: 数值模拟显示所提算法在信道预测性能上表现优越。

Conclusion: 该方法有效解决了移动性下的信道预测问题，为XL-MIMO系统提供了实用解决方案。

Abstract: The upper mid-band balances coverage and capacity for the future cellular
systems and also embraces XL-MIMO systems, offering enhanced spectral and
energy efficiency. However, these benefits are significantly degraded under
mobility due to channel aging, and further exacerbated by the unique near-field
(NF) and spatial non-stationarity (SnS) propagation in such systems. To address
this challenge, we propose a novel channel prediction approach that
incorporates dedicated channel modeling, probabilistic representations, and
Bayesian inference algorithms for this emerging scenario. Specifically, we
develop tensor-structured channel models in both the spatial-frequency-temporal
(SFT) and beam-delay-Doppler (BDD) domains, which leverage temporal
correlations among multiple pilot symbols for channel prediction. The factor
matrices of multi-linear transformations are parameterized by BDD domain grids
and SnS factors, where beam domain grids are jointly determined by angles and
slopes under spatial-chirp based NF representations. To enable tractable
inference, we replace environment-dependent BDD domain grids with uniformly
sampled ones, and introduce perturbation parameters in each domain to mitigate
grid mismatch. We further propose a hybrid beam domain strategy that integrates
angle-only sampling with slope hyperparameterization to avoid the computational
burden of explicit slope sampling. Based on the probabilistic models, we
develop tensor-structured bi-layer inference (TS-BLI) algorithm under the
expectation-maximization (EM) framework, which reduces computational complexity
via tensor operations by leveraging the bi-layer factor graph for approximate
E-step inference and an alternating strategy with closed-form updates in the
M-step. Numerical simulations based on the near-practical channel simulator
demonstrate the superior channel prediction performance of the proposed
algorithm.

</details>


### [4] [An Analytical and Experimental Study of Distributed Uplink Beamforming in the Presence of Carrier Frequency Offsets](https://arxiv.org/abs/2508.08506)
*Mehdi Zafari,Divyanshu Pandey,Rahman Doost-Mohammady*

Main category: eess.SP

TL;DR: 本文分析了分布式多用户波束成形（D-MUBF）在TDD多用户MIMO系统中的挑战，特别是频率同步误差的影响，并通过实验和理论分析评估其性能。


<details>
  <summary>Details</summary>
Motivation: 解决分布式接入点（APs）间频率同步误差对D-MUBF性能的影响，填补实验研究的空白。

Method: 提供闭式SINR表达式，结合RENEW大规模MIMO测试平台进行实验评估，收集并公开数据集。

Result: 通过实验验证了理论分析的准确性，并提供了频率同步误差下D-MUBF的性能评估。

Conclusion: 研究为未来D-MUBF技术的研究提供了理论和实验基础，并公开数据集以促进进一步研究。

Abstract: Realizing distributed multi-user beamforming (D-MUBF) in time division duplex
(TDD)-based multi-user MIMO (MU-MIMO) systems faces significant challenges. One
of the most fundamental challenges is achieving accurate over-the-air (OTA)
timing and frequency synchronization among distributed access points (APs),
particularly due to residual frequency offsets caused by local oscillator (LO)
drifts. Despite decades of research on synchronization for MU-MIMO, there are
only a few experimental studies that evaluate D-MUBF techniques under imperfect
frequency synchronization among distributed antennas. This paper presents an
analytical and experimental assessment of D-MUBF methods in the presence of
frequency synchronization errors. We provide closed-form expressions for
signal-to-interference-plus-noise ratio (SINR) as a function of channel
characteristics and statistical properties of carrier frequency offset (CFO)
among AP antennas. In addition, through experimental evaluations conducted with
the RENEW massive MIMO testbed, we collected comprehensive datasets across
various experimental scenarios. These datasets comprise uplink pilot samples
for channel and CFO estimation, in addition to uplink multi-user data intended
for analyzing D-MUBF techniques. By examining these datasets, we assess the
performance of D-MUBF in the presence of CFO and compare the analytical
predictions with empirical measurements. Furthermore, we make the datasets
publicly available and provide insights on utilizing them for future research
endeavors.

</details>


### [5] [Learning Zero Constellations for Binary MOCZ in Fading Channels](https://arxiv.org/abs/2508.08571)
*Anthony Joseph Perre,Parker Huggins,Alphan Sahin*

Main category: eess.SP

TL;DR: 论文提出两种设计零星座的方法，用于二进制调制，并通过神经网络解码器实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 研究如何优化二进制调制中的零星座设计，以提高解码性能。

Method: 1. 将星座设计视为多标签分类问题，学习零位置；2. 引入神经网络解码器，联合学习解码器和零星座参数。

Result: 神经网络解码器能泛化到平坦衰落信道，且学习到的零星座性能优于传统Huffman BMOCZ星座。

Conclusion: 提出的方法显著提升性能，但神经网络解码器增加了计算复杂度。

Abstract: In this work, we propose two methods to design zero constellations for binary
modulation on conjugate-reciprocal zeros (BMOCZ). In the first approach, we
treat constellation design as a multi-label binary classification problem and
learn the zero locations for a direct zero-testing (DiZeT) decoder. In the
second approach, we introduce a neural network (NN)-based decoder and jointly
learn the decoder and zero constellation parameters. We show that the NN-based
decoder can directly generalize to flat-fading channels, despite being trained
under additive white Gaussian noise. Furthermore, the results of numerical
simulations demonstrate that learned zero constellations outperform the
canonical, Huffman BMOCZ constellation, with the proposed NN-based decoder
achieving large performance gain at the expense of increased computational
complexity.

</details>


### [6] [Biomedical Signal Processing: EEG and ECG Classification with Discrete Wavelet Transforms, Energy Distribution, and Convolutional Neural Networks](https://arxiv.org/abs/2508.08602)
*Justin London*

Main category: eess.SP

TL;DR: 论文提出了一种多模态深度学习模型，通过离散小波变换预处理信号，结合图像和特征融合技术，显著提高了生物医学信号分析的准确性。


<details>
  <summary>Details</summary>
Motivation: 传统的人工分析生理信号容易因细微异常未被发现而产生错误，因此需要更准确的自动化分析方法。

Method: 使用离散小波变换降噪，将数值信号转换为2D和3D图像（如Gramian角场、递归图和马尔可夫转移场），并应用多模态图像和特征融合框架。

Result: 实验表明，多模态方法结合小波变换能显著提高疾病和障碍分类的准确性。

Conclusion: 多模态深度学习模型在生物医学信号处理中具有更高的准确性和应用潜力。

Abstract: Biomedical signal processing extract meaningful information from
physiological signals like electrocardiograms (ECGs), electroencephalograms
(EEGs), and electromyograms (EMGs) to diagnose, monitor, and treat medical
conditions and diseases such as seizures, cardiomyopathy, and neuromuscular
disorders, respectively. Traditional manual physician analysis of electrical
recordings is prone to human error as subtle anomolies may not be detected.
Recently, advanced deep learning has significantly improved the accuracy of
biomedical signal analysis. A multi-modal deep learning model is proposed that
utilizes discrete wavelet transforms for signal pre-processing to reduce noise.
A multi-modal image fusion and multimodal feature fusion framework is utilized
that converts numeric biomedical signals into 2D and 3D images for image
processing using Gramian angular fields, recurrency plots, and Markov
transition fields. In this paper, deep learning models are applied to ECG, EEG,
and human activity signals using actual medical datasets, brain, and heart
recordings. The results demonstrate that using a multi-modal approach using
wavelet transforms improves the accuracy of disease and disorder
classification.

</details>


### [7] [Agentic Graph Neural Networks for Wireless Communications and Networking Towards Edge General Intelligence: A Survey](https://arxiv.org/abs/2508.08620)
*Yang Lu,Shengli Zhang,Chang Liu,Ruichen Zhang,Bo Ai,Dusit Niyato,Wei Ni,Xianbin Wang,Abbas Jamalipour*

Main category: eess.SP

TL;DR: 该论文探讨了图神经网络（GNNs）在无线通信网络中的应用，提出了一种基于代理人工智能（AI）的主动学习框架，以应对动态环境中多样化的需求。


<details>
  <summary>Details</summary>
Motivation: 通信网络的复杂性和动态性对服务质量提出了更高要求，传统被动学习的GNNs难以满足多样化无线系统的需求。

Method: 论文提出了一种代理AI框架，将GNNs与任务和场景感知结合，并综述了GNNs在无线通信中的最新应用。

Result: 论文总结了GNNs在物理层、MAC层、网络层设计以及新兴技术（如ISAC、RIS和无蜂窝网络）中的应用，并提出了基于大语言模型（LLM）的智能问答框架。

Conclusion: 代理AI框架和GNNs的结合为无线通信网络提供了更灵活和智能的解决方案，未来可进一步探索其通用边缘智能的潜力。

Abstract: The rapid advancement of communication technologies has driven the evolution
of communication networks towards both high-dimensional resource utilization
and multifunctional integration. This evolving complexity poses significant
challenges in designing communication networks to satisfy the growing
quality-of-service and time sensitivity of mobile applications in dynamic
environments. Graph neural networks (GNNs) have emerged as fundamental deep
learning (DL) models for complex communication networks. GNNs not only augment
the extraction of features over network topologies but also enhance scalability
and facilitate distributed computation. However, most existing GNNs follow a
traditional passive learning framework, which may fail to meet the needs of
increasingly diverse wireless systems. This survey proposes the employment of
agentic artificial intelligence (AI) to organize and integrate GNNs, enabling
scenario- and task-aware implementation towards edge general intelligence. To
comprehend the full capability of GNNs, we holistically review recent
applications of GNNs in wireless communications and networking. Specifically,
we focus on the alignment between graph representations and network topologies,
and between neural architectures and wireless tasks. We first provide an
overview of GNNs based on prominent neural architectures, followed by the
concept of agentic GNNs. Then, we summarize and compare GNN applications for
conventional systems and emerging technologies, including physical, MAC, and
network layer designs, integrated sensing and communication (ISAC),
reconfigurable intelligent surface (RIS) and cell-free network architecture. We
further propose a large language model (LLM) framework as an intelligent
question-answering agent, leveraging this survey as a local knowledge base to
enable GNN-related responses tailored to wireless communication research.

</details>


### [8] [Sparse Near-Field Channel Estimation for XL-MIMO via Adaptive Filtering](https://arxiv.org/abs/2508.08663)
*Vidya Bhasker Shukla,Italo Atzeni*

Main category: eess.SP

TL;DR: 论文提出了一种基于自适应滤波的近场稀疏信道估计方法PD-ZALMS，用于XL-MIMO系统，显著提高了估计精度并降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 为了满足下一代无线应用的需求，XL-MIMO系统在近场（NF）环境下的稀疏信道估计成为关键问题。

Method: 采用基于子阵列的架构，开发了一种基于自适应滤波的NF信道估计框架PD-ZALMS。

Result: PD-ZALMS在信道估计精度和计算复杂度上优于现有的极域正交匹配追踪方法，并在低至中等信噪比下优于最小二乘估计器。

Conclusion: PD-ZALMS是一种高效且准确的近场稀疏信道估计方法，适用于XL-MIMO系统。

Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems
operating at sub-THz carrier frequencies represent a promising solution to meet
the demands of next-generation wireless applications. This work focuses on
sparse channel estimation for XL-MIMO systems operating in the near-field (NF)
regime. Assuming a practical subarray-based architecture, we develop a NF
channel estimation framework based on adaptive filtering, referred to as
\textit{polar-domain zero-attracting least mean squares (PD-ZALMS)}. The
proposed method achieves significantly superior channel estimation accuracy and
lower computational complexity compared with the well-established polar-domain
orthogonal matching pursuit. In addition, the proposed PD-ZALMS is shown to
outperform the oracle least-squares channel estimator at low-to-moderate
signal-to-noise ratio.

</details>


### [9] [VQ-VAE Based Digital Semantic Communication with Importance-Aware OFDM Transmission](https://arxiv.org/abs/2508.08686)
*Ming Lyu,Hao Chen,Dan Wang,Chen Qiu,Guangyin Feng,Nan Ma,Xiaodong Xu*

Main category: eess.SP

TL;DR: 本文提出了一种基于VQ-VAE的数字语义通信系统，通过共享离散码本和重要性感知OFDM传输提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习语义通信系统多基于模拟传输，缺乏与数字通信的兼容性。

Method: 使用VQ-VAE生成共享离散码本，结合重要性感知OFDM传输策略保护语义信息。

Result: 实验表明，该方案在低信噪比区域优于传统DeepSC，重建性能更优。

Conclusion: 提出的数字语义通信系统有效提升了传输效率和兼容性。

Abstract: Semantic communication (SemCom) significantly reduces redundant data and
improves transmission efficiency by extracting the latent features of
information. However, most of the conventional deep learning-based SemCom
systems focus on analog transmission and lack in compatibility with practical
digital communications. This paper proposes a vector quantized-variational
autoencoder (VQ-VAE) based digital SemCom system that directly transmits the
semantic features and incorporates the importance-aware orthogonal frequency
division multiplexing (OFDM) transmission to enhance the SemCom performance,
where the VQ-VAE generates a discrete codebook shared between the transmitter
and receiver. At transmitter, the latent semantic features are firstly
extracted by VQ-VAE, and then the shared codebook is adopted to match these
features, which are subsequently transformed into a discrete version to adapt
the digital transmission. To protect the semantic information, an
importance-aware OFDM transmission strategy is proposed to allocate the key
features near the OFDM reference signals, where the feature importance is
derived from the gradient-based method. At the receiver, the features are
rematched with the shared codebook to further correct errors. Finally,
experimental results demonstrate that our proposed scheme outperforms the
conventional DeepSC and achieves better reconstruction performance under low
SNR region.

</details>


### [10] [Evaluating Task Execution Performance Under Energy Measurement Overhead](https://arxiv.org/abs/2508.08757)
*Mateen Ashraf,Shahab Jahanbazi,Onel L. A. López*

Main category: eess.SP

TL;DR: 论文探讨了能量感知（EA）与能量盲（EB）任务决策在能量收集（EH）物联网设备中的性能比较，指出能量测量成本可能抵消其潜在优势，并提出优化测量/执行频率的方法。


<details>
  <summary>Details</summary>
Motivation: 研究能量感知行为对能量收集物联网设备性能的影响，尤其是能量测量成本被忽视的问题。

Method: 比较能量盲（EB）和能量感知（EA）任务决策方法，分析能量测量频率与任务执行频率对任务完成率的影响。

Result: 发现存在最优的测量/执行频率可最大化任务完成率；若参数选择不当，EA可能表现不如EB。

Conclusion: 合理选择能量测量和任务执行频率是优化EH-IoT设备性能的关键。

Abstract: Energy-awareness for adapting task execution behavior can bring several
benefits in terms of performance improvement in energy harvesting (EH) Internet
of Things (IoT) devices. However, the energy measurement cost of acquiring
energy information, which is traditionally ignored, can potentially neutralize
or even reverse the potential benefits. This paper highlights operational
parameters, such as energy measurement frequency and task execution frequency,
which can be tuned to improve the task execution performance of an EH-IoT
device. To this end, we consider energy-blind (EB) and energy-aware (EA) task
decision approaches and compare their task completion rate performance. We show
that, for specific hardware design parameters of an EH-IoT device, there exists
an optimal energy measurement/task execution frequency that can maximize the
task completion rate in both approaches. Moreover, if these parameters are not
chosen appropriately, then energy measurement costs can cause EA scheduling to
underperform compared to EB scheduling.

</details>


### [11] [Wideband Coplanar Waveguide MIMO Antenna for 6G Millimeter-Wave Applications with Defected Ground Structure](https://arxiv.org/abs/2508.08771)
*Atta Ullah,Daniyal Munir,Daniel Lindenschmitt,Hans D. Schotten*

Main category: eess.SP

TL;DR: 提出了一种新型宽带小型天线，适用于6G毫米波频段（25 GHz至33.5 GHz），采用微带贴片结构和缺陷地结构（DGS），单天线和2x2 MIMO天线设计均表现优异。


<details>
  <summary>Details</summary>
Motivation: 为6G无线网络的高频段需求设计一种宽带小型天线，满足毫米波技术的应用需求。

Method: 采用微带贴片结构，通过共面波导（CPW）馈电，并引入缺陷地结构（DGS），设计了单天线和2x2 MIMO天线。

Result: 单天线和2x2 MIMO天线在8.5 GHz宽带范围内表现出优异的回波损耗，适用于6G毫米波技术。

Conclusion: 该天线设计在6G毫米波频段具有广阔的应用前景，性能优异。

Abstract: This research study introduces a novel small antenna with wideband capacity
for the higher frequency range. As a possible contender for 6G wireless
networks, the proposed antenna is designed to target the 6G Millimeter-Wave
(mmWave) operating bands spanning 25 GHz to 33.5 GHz. With a microstrip patch
structure fed by a coplanar waveguide (CPW) with the defected ground structure
(DGS), a single antenna is introduced and then a design of 2 x 2 MIMO antenna
is presented. The single antenna has 2 elements, while the 2 x 2 MIMO antenna
has 8 elements. It achieves remarkably well in terms of return loss of 8.5 GHz
wideband, which is anticipated to be used for several applications in 6G mmWave
technology.

</details>


### [12] [Patient-Adaptive Focused Transmit Beamforming using Cognitive Ultrasound](https://arxiv.org/abs/2508.08782)
*Wessel L. van Nierop,Oisín Nolan,Tristan S. W. Stevens,Ruud J. G. van Sloun*

Main category: eess.SP

TL;DR: 提出了一种患者自适应的聚焦发射方案，通过后验采样和时间扩散模型减少发射次数，提高超声图像质量。


<details>
  <summary>Details</summary>
Motivation: 传统聚焦发射方案帧率低，快速成像方法存在运动去相关和谐波成像能力受限的问题。

Method: 采用后验采样和时间扩散模型，动态选择信息量最大的发射。

Result: 在2D和3D数据集上优于随机和等距子采样，对比噪声比更高，且仅需2%的发射次数即可估计射血分数。

Conclusion: 该方法在实时性和鲁棒性上表现优异，适用于临床超声成像。

Abstract: Focused transmit beamforming is the most commonly used acquisition scheme for
echocardiograms, but suffers from relatively low frame rates, and in 3D, even
lower volume rates. Fast imaging based on unfocused transmits has disadvantages
such as motion decorrelation and limited harmonic imaging capabilities. This
work introduces a patient-adaptive focused transmit scheme that has the ability
to drastically reduce the number of transmits needed to produce a high-quality
ultrasound image. The method relies on posterior sampling with a temporal
diffusion model to perceive and reconstruct the anatomy based on partial
observations, while subsequently taking an action to acquire the most
informative transmits. This active perception modality outperforms random and
equispaced subsampling on the 2D EchoNet-Dynamic dataset and a 3D Philips
dataset, where we actively select focused elevation planes. Furthermore, we
show it achieves better performance in terms of generalized contrast-to-noise
ratio when compared to the same number of diverging waves transmits on three
in-house echocardiograms. Additionally, we can estimate ejection fraction using
only 2% of the total transmits and show that the method is robust to outlier
patients. Finally, our method can be run in real-time on GPU accelerators from
2023. The code is publicly available at https://tue-bmd.github.io/ulsa/

</details>


### [13] [ReQuestNet: A Foundational Learning model for Channel Estimation](https://arxiv.org/abs/2508.08790)
*Kumar Pratik,Pouriya Sadeghi,Gabriele Cesa,Sanaz Barghi,Joseph B. Soriaga,Yuanning Yu,Supratik Bhattacharjee,Arash Behboodi*

Main category: eess.SP

TL;DR: 提出了一种名为ReQuestNet的新型神经网络架构，用于5G及更高版本的通道估计，能够处理多种实际无线通信系统问题，显著简化了通道估计流程。


<details>
  <summary>Details</summary>
Motivation: 解决传统线性MMSE解决方案的局限性，如对其他参考信号的依赖，以及联合处理MIMO层和未知预编码通道的需求。

Method: ReQuestNet由CoarseNet和RefinementNet两个子单元组成，分别进行粗略通道估计和精细化处理，利用跨预编码PRG和跨MIMO空间维度的相关性。

Result: 仿真结果表明，ReQuestNet在多种信道条件下显著优于传统MMSE方法，最高可实现10dB增益，并能有效泛化到未见过的信道配置。

Conclusion: ReQuestNet通过统一模型简化了通道估计流程，并在性能和泛化能力上表现出色。

Abstract: In this paper, we present a novel neural architecture for channel estimation
(CE) in 5G and beyond, the Recurrent Equivariant UERS Estimation Network
(ReQuestNet). It incorporates several practical considerations in wireless
communication systems, such as ability to handle variable number of resource
block (RB), dynamic number of transmit layers, physical resource block groups
(PRGs) bundling size (BS), demodulation reference signal (DMRS) patterns with a
single unified model, thereby, drastically simplifying the CE pipeline. Besides
it addresses several limitations of the legacy linear MMSE solutions, for
example, by being independent of other reference signals and particularly by
jointly processing MIMO layers and differently precoded channels with unknown
precoding at the receiver. ReQuestNet comprises of two sub-units, CoarseNet
followed by RefinementNet. CoarseNet performs per PRG, per transmit-receive
(Tx-Rx) stream channel estimation, while RefinementNet refines the CoarseNet
channel estimate by incorporating correlations across differently precoded
PRGs, and correlation across multiple input multiple output (MIMO) channel
spatial dimensions (cross-MIMO). Simulation results demonstrate that ReQuestNet
significantly outperforms genie minimum mean squared error (MMSE) CE across a
wide range of channel conditions, delay-Doppler profiles, achieving up to 10dB
gain at high SNRs. Notably, ReQuestNet generalizes effectively to unseen
channel profiles, efficiently exploiting inter-PRG and cross-MIMO correlations
under dynamic PRG BS and varying transmit layer allocations.

</details>


### [14] [Iterative Distortion Cancellation Algorithms for Single-Sideband Systems](https://arxiv.org/abs/2508.08796)
*Jun Dong,Tianwai Bo,Zhuo Wang,Haolei Gao,Zhongwei Tan,Yi Dong*

Main category: eess.SP

TL;DR: 提出了一种迭代失真消除算法，用于数字缓解自动偏置控制模块中的双边带抖动信号幅度对Kramers-Kronig接收器的影响，无需修改物理层结构。


<details>
  <summary>Details</summary>
Motivation: 解决自动偏置控制模块中抖动信号对Kramers-Kronig接收器的负面影响，提升接收性能。

Method: 利用KK关系进行初始信号决策，并重建抖动信号引起的失真。

Result: 实验表明，算法将抖动幅度容忍度提升至10% Vπ，80公里光纤传输中接收灵敏度提高超过1 dB。

Conclusion: 该失真消除方法有效提升了Kramers-Kronig接收器的性能。

Abstract: We propose an iterative distortion cancellation algorithm to digitally
mitigate the impact of double-sideband dither signal amplitude from the
automatic bias control module on Kramers-Kronig receivers without modifying
physical layer structures. The algorithm utilizes the KK relation for initial
signal decisions and reconstructs the distortion caused by dither signals.
Experimental tests in back-to-back showed it improved tolerance to dither
amplitudes up to 10% V{\pi}. For 80-km fiber transmission, the algorithm
increased the receiver sensitivity by more than 1 dB, confirming the
effectiveness of the proposed distortion cancellation method.

</details>


### [15] [Trajectory-adaptive Beam Shaping: Towards Beam-Management-Free Near-field Communications](https://arxiv.org/abs/2508.08894)
*Sicong Ye,Yulan Gao,Ming Xiao,Peng Wang,Marios Poulakis,Ulrik Imberg*

Main category: eess.SP

TL;DR: 论文提出了一种名为TABS的新方法，通过预定义用户轨迹来优化毫米波和太赫兹频段的波束成形，减少实时波束管理的需求。


<details>
  <summary>Details</summary>
Motivation: 毫米波和太赫兹频段的高频通信虽然能提升数据吞吐量，但存在严重的路径损耗和波束对准问题，传统方法计算和信令开销大。

Method: 提出轨迹自适应波束成形（TABS），利用自加速光束原理，预定义波束路径以匹配用户运动轨迹，无需实时调整。

Result: 仿真结果表明，TABS在链路性能、开销减少和实现复杂度方面优于传统方法。

Conclusion: TABS为高频无线通信提供了一种高效、低开销的波束成形解决方案。

Abstract: The quest for higher wireless carrier frequencies spanning the
millimeter-wave (mmWave) and Terahertz (THz) bands heralds substantial
enhancements in data throughput and spectral efficiency for next-generation
wireless networks. However, these gains come at the cost of severe path loss
and a heightened risk of beam misalignment due to user mobility, especially
pronounced in near-field communication. Traditional solutions rely on extremely
directional beamforming and frequent beam updates via beam management, but such
techniques impose formidable computational and signaling overhead. In response,
we propose a novel approach termed trajectory-adaptive beam shaping (TABS) that
eliminates the need for real-time beam management by shaping the
electromagnetic wavefront to follow the user's predefined trajectory. Drawing
inspiration from self-accelerating beams in optics, TABS concentrates energy
along pre-defined curved paths corresponding to the user's motion without
requiring real-time beam reconfiguration. We further introduce a dedicated
quantitative metric to characterize performance under the TABS framework.
Comprehensive simulations substantiate the superiority of TABS in terms of link
performance, overhead reduction, and implementation complexity.

</details>


### [16] [Scalable RIS-Aided Beamforming Strategies for Near-Field MU-MISO via Multi-Antenna Feeder](https://arxiv.org/abs/2508.08993)
*Giulia Torcolacci,Malte Schellmann,Davide Dardari*

Main category: eess.SP

TL;DR: 提出了一种基于AT-RIS的模块化波束成形框架，用于近场多用户通信，分析了不同T-RIS架构与预编码方案的性能与权衡。


<details>
  <summary>Details</summary>
Motivation: 研究在近场多用户通信中，如何通过模块化设计实现灵活且高效的波束成形，解决传统RIS在复杂性和性能上的限制。

Method: 提出AT-RIS架构，将AMAF与T-RIS解耦，支持独立配置；分析对角与非对角T-RIS架构，结合聚焦、MMSE和特征模式分解预编码方案。

Result: 非对角方案在UE少且角度可分时性能最优，但公平性和扩展性差；对角方案（如聚焦预编码）在UE密度高时表现稳健且公平。

Conclusion: 对角AT-RIS架构在近场多用户系统中具有实际应用价值，平衡了频谱效率、复杂性和公平性。

Abstract: This paper investigates a modular beamforming framework for reconfigurable
intelligent surface (RIS)-aided multi-user (MU) communications in the
near-field regime, built upon a novel antenna architecture integrating an
active multi-antenna feeder (AMAF) array with a transmissive RIS (T-RIS),
referred to as AT-RIS. This decoupling enables coordinated yet independently
configurable designs in the AMAF and T-RIS domains, supporting flexible
strategies with diverse complexity-performance trade-offs. Several
implementations are analyzed, including diagonal and non-diagonal T-RIS
architectures, paired with precoding schemes based on focusing, minimum mean
square error, and eigenmode decomposition. Simulation results demonstrate that
while non-diagonal schemes maximize sum rate in scenarios with a limited number
of User Equipments (UEs) and high angular separability, they exhibit fairness
and scalability limitations as UE density increases. Conversely, diagonal T-RIS
configurations, particularly the proposed focusing-based scheme with uniform
feeder-side power allocation, offer robust, fair, and scalable performance with
minimal channel state information. The findings emphasize the critical impact
of UEs' angular separability and reveal inherent trade-offs among spectral
efficiency, complexity, and fairness, positioning diagonal AT-RIS architectures
as practical solutions for scalable near-field MU multiple-input single-output
systems.

</details>


### [17] [Improved SINR Approximation for Downlink SDMA-based Networks with Outdated Channel State Information](https://arxiv.org/abs/2508.09020)
*Maria Cecilia Fernández Montefiore,Gustavo González,F. Javier López-Martínez,Fernando Gregorio*

Main category: eess.SP

TL;DR: 本文提出了一种改进的统计模型，用于近似下行MU-MIMO系统中不完美CSIT下的SINR，克服了现有方法的局限性，并在RSMA-enabled MIMO系统中验证了其准确性。


<details>
  <summary>Details</summary>
Motivation: 多用户MIMO系统在不完美CSIT下的性能分析是下一代无线网络的关键挑战，准确的SINR统计建模对性能分析至关重要。

Method: 提出了一种改进的SINR统计近似模型，保留了现有方法的分析简单性，同时解决了SINR方差低估的问题。

Result: 在RSMA-enabled MIMO系统中验证了模型的准确性，适用于不同用户数、天线数和CSIT老化程度。

Conclusion: 该模型为不完美CSIT下的MU-MIMO系统性能分析提供了更准确的工具。

Abstract: Understanding the performance of multi-user multiple-input multiple-output
(MU-MIMO) systems under imperfect channel state information at the transmitter
(CSIT) remains a critical challenge in next-generation wireless networks. In
this context, accurate statistical modeling of the
signal-to-interference-plus-noise ratio (SINR) is essential for enabling
tractable performance analysis of multi-user systems. This paper presents an
improved statistical approximation of the SINR for downlink (DL) MU-MIMO
systems with imperfect CSIT. The proposed model retains the analytical
simplicity of existing approaches (e.g., Gamma-based approximations) while
overcoming their limitations, particularly the underestimation of SINR
variance. We evaluate the proposed approximation in the context of
Rate-Splitting Multiple Access (RSMA)-enabled MIMO DL systems with outdated
CSIT. The results demonstrate excellent accuracy across a wide range of system
configurations, including varying numbers of users, antennas, and degrees of
CSIT staleness.

</details>


### [18] [Chartwin: a Case Study on Channel Charting-aided Localization in Dynamic Digital Network Twins](https://arxiv.org/abs/2508.09055)
*Lorenzo Cazzella,Francesco Linsalata,Mahdi Maleki,Damiano Badini,Matteo Matteucci,Umberto Spagnolini*

Main category: eess.SP

TL;DR: 论文提出Chartwin方法，将定位导向的信道图表与动态数字网络孪生（DNT）结合，展示了半监督信道图表在构建空间一致性地图中的显著性能。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统需要空间一致的信道表示以高效完成通信任务，信道图表是一种有效的无监督学习技术。

Method: 提出Chartwin方法，结合定位导向的信道图表与动态DNT，通过半监督学习构建空间一致性地图。

Result: 静态DNT的定位误差约为4.5米，动态DNT约为6米，验证了DNT辅助信道图表与定位的有效性。

Conclusion: Chartwin方法在构建空间一致性地图和定位方面表现优异，为DNT辅助通信任务提供了新思路。

Abstract: Wireless communication systems can significantly benefit from the
availability of spatially consistent representations of the wireless channel to
efficiently perform a wide range of communication tasks. Towards this purpose,
channel charting has been introduced as an effective unsupervised learning
technique to achieve both locally and globally consistent radio maps. In this
letter, we propose Chartwin, a case study on the integration of
localization-oriented channel charting with dynamic Digital Network Twins
(DNTs). Numerical results showcase the significant performance of
semi-supervised channel charting in constructing a spatially consistent chart
of the considered extended urban environment. The considered method results in
$\approx$ 4.5 m localization error for the static DNT and $\approx$ 6 m in the
dynamic DNT, fostering DNT-aided channel charting and localization.

</details>


### [19] [Spectral Efficiency Considerations for 6G](https://arxiv.org/abs/2508.09117)
*Joseph Boccuzzi*

Main category: eess.SP

TL;DR: 本文提出了一种新的系统指标——无线电资源利用效率（RUE），用于量化未来6G需求中无线电资源的利用效率，并通过比较典型蜂窝和无小区大规模MIMO部署展示了其必要性。


<details>
  <summary>Details</summary>
Motivation: 随着无线连接向6G演进，需要更高效地实现高吞吐量、低延迟和高可靠性，现有指标如频谱效率（SE）和能量效率（EE）不足以全面评估资源利用效率。

Method: 引入RUE指标，分析5G无线电资源、实际限制（如信道矩阵秩不足）和实施损耗（SINR退化）对SE的影响，并通过5G MU-MIMO实测数据进行验证。

Result: 分析显示5G的RUE仅为47%，表明6G有显著改进空间；增加传输带宽（从100MHz到1.6GHz）可带来明显收益。

Conclusion: RUE是评估6G资源利用效率的重要指标，未来RAN架构需支持6G和AI-RAN以实现更高效率。

Abstract: As wireless connectivity continues to evolve towards 6G, there is an
ever-increasing demand to not only deliver higher throughput, lower latency,
and improved reliability, but also do so as efficiently as possible. To this
point, the term efficiency has been quantified through applications to Spectral
Efficiency (SE) and Energy Efficiency (EE). In this paper we introduce a new
system metric called Radio Resource Utilization Efficiency (RUE). This metric
quantifies the efficiency of the available radio resources (Spectrum, Access
Method, Time Slots, Data Symbols, etc.) used to deliver future 6G demands. We
compare the system performance of Typical Cellular and Cell-Free Massive MIMO
deployments as a vehicle to demonstrate the need for this new metric. We begin
by providing a concise treatment of items impacting SE by introducing three
categories: 5G Radio Resources, Practical Limitations (such as channel matrix
rank deficiency) and Implementation Losses (SINR degradation). For the example
Radio Access Technology configuration analyzed, we show 5G yields an RUE of 47%
(revealing significant room for improvement when defining 6G). Practical
limitation assumptions are compared to 5G Multi-User MIMO (MU-MIMO)
measurements conducted in a commercialized deployment. SE losses are
characterized to offer guidance to advanced algorithms employing Machine
Learning (ML) based techniques. We present the benefits of increasing the
transmission Bandwidth (BW) from 100MHz to 1.6GHz. We describe a Next
Generation RAN architecture that can support 6G and AI-RAN.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [20] [Exploring Disentangled Neural Speech Codecs from Self-Supervised Representations](https://arxiv.org/abs/2508.08399)
*Ryo Aihara,Yoshiki Masuyama,Gordon Wichern,François G. Germain,Jonathan Le Roux*

Main category: eess.AS

TL;DR: 论文提出了一种离散神经音频编解码器（NAC），通过结构化解耦实现语音特征的分离，同时保持与传统NAC相当的音频重建性能。


<details>
  <summary>Details</summary>
Motivation: 语音不仅包含语言学内容，还包含丰富的副语言学特征。传统NAC将这些特征纠缠编码，限制了灵活性，例如在语音转换（VC）任务中。因此，需要一种能够解耦这些特征的NAC。

Method: 受VC方法启发，利用k-means量化和自监督特征解耦语音信息，开发了一种支持结构化解耦的离散NAC。

Result: 实验表明，该方法在音频重建性能上与传统NAC相当，同时在语音转换任务中与传统VC技术效果一致。

Conclusion: 提出的离散NAC能够有效解耦语音特征，为下游任务提供更灵活的表示。

Abstract: Neural audio codecs (NACs), which use neural networks to generate compact
audio representations, have garnered interest for their applicability to many
downstream tasks -- especially quantized codecs due to their compatibility with
large language models. However, unlike text, speech conveys not only linguistic
content but also rich paralinguistic features. Encoding these elements in an
entangled fashion may be suboptimal, as it limits flexibility. For instance,
voice conversion (VC) aims to convert speaker characteristics while preserving
the original linguistic content, which requires a disentangled representation.
Inspired by VC methods utilizing $k$-means quantization with self-supervised
features to disentangle phonetic information, we develop a discrete NAC capable
of structured disentanglement. Experimental evaluations show that our approach
achieves reconstruction performance on par with conventional NACs that do not
explicitly perform disentanglement, while also matching the effectiveness of
conventional VC techniques.

</details>


### [21] [Joint decoding method for controllable contextual speech recognition based on Speech LLM](https://arxiv.org/abs/2508.08585)
*Yangui Fang,Jing Peng,Yu Xi,Xu Li,Haoyu Li,Chengwei Zhang,Guohui Zhong,Kai Yu*

Main category: eess.AS

TL;DR: 提出了一种联合解码方法，用于控制上下文信息注入，解决了直接提示注入无法显式控制的问题，并提升了识别性能。


<details>
  <summary>Details</summary>
Motivation: 直接通过提示注入上下文信息的方法依赖模型内部注意力机制，无法显式控制信息注入程度。

Method: 提出了一种联合解码方法，用于显式控制上下文信息的注入。

Result: 实验表明，该方法能显式控制信息注入，提升识别性能，并支持敏感词抑制识别。未预训练长上下文的Speech LLM也能通过该方法获得长上下文能力。

Conclusion: 联合解码方法有效解决了上下文信息注入的控制问题，并扩展了模型能力。

Abstract: Contextual speech recognition refers to the ability to identify preferences
for specific content based on contextual information. Recently, leveraging the
contextual understanding capabilities of Speech LLM to achieve contextual
biasing by injecting contextual information through prompts have emerged as a
research hotspot.However, the direct information injection method via prompts
relies on the internal attention mechanism of the model, making it impossible
to explicitly control the extent of information injection. To address this
limitation, we propose a joint decoding method to control the contextual
information. This approach enables explicit control over the injected
contextual information and achieving superior recognition performance.
Additionally, Our method can also be used for sensitive word suppression
recognition.Furthermore, experimental results show that even Speech LLM not
pre-trained on long contextual data can acquire long contextual capabilities
through our method.

</details>


### [22] [MultiAiTutor: Child-Friendly Educational Multilingual Speech Generation Tutor with LLMs](https://arxiv.org/abs/2508.08715)
*Xiaoxue Gao,Huayun Zhang,Nancy F. Chen*

Main category: eess.AS

TL;DR: MultiAiTutor是一种多语言生成AI教育助手，专为儿童设计，利用LLM架构生成适合教育场景的语音，支持低资源语言。


<details>
  <summary>Details</summary>
Motivation: 现有生成语音模型在儿童教育中潜力大，但低资源语言的儿童友好语音生成仍具挑战性。

Method: 采用LLM架构，结合文化相关图像描述任务，支持新加坡口音普通话、马来语和泰米尔语。

Result: 实验表明MultiAiTutor在客观和主观评估中均优于基线方法。

Conclusion: MultiAiTutor为低资源语言的儿童语言学习提供了高效解决方案。

Abstract: Generative speech models have demonstrated significant potential in
personalizing teacher-student interactions, offering valuable real-world
applications for language learning in children's education. However, achieving
high-quality, child-friendly speech generation remains challenging,
particularly for low-resource languages across diverse languages and cultural
contexts. In this paper, we propose MultiAiTutor, an educational multilingual
generative AI tutor with child-friendly designs, leveraging LLM architecture
for speech generation tailored for educational purposes. We propose to
integrate age-appropriate multilingual speech generation using LLM
architectures, facilitating young children's language learning through
culturally relevant image-description tasks in three low-resource languages:
Singaporean-accent Mandarin, Malay, and Tamil. Experimental results from both
objective metrics and subjective evaluations demonstrate the superior
performance of the proposed MultiAiTutor compared to baseline methods.

</details>


### [23] [Transient Noise Removal via Diffusion-based Speech Inpainting](https://arxiv.org/abs/2508.08890)
*Mordehay Moradi,Sharon Gannot*

Main category: eess.AS

TL;DR: PGDI是一种基于扩散的语音修复框架，能够准确重建长达一秒的缺失或损坏语音片段，同时保留说话者身份、韵律和环境因素。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在说话者变异性或长间隙修复上的不足，提升语音修复的准确性和鲁棒性。

Method: 采用分类器引导（特别是音素级引导）的扩散模型，以说话者无关的方式运行，适用于强瞬态噪声环境。

Result: 实验表明PGDI在多样说话者和间隙长度下表现优异，能处理复杂声学条件，且无需文本输入仍有效。

Conclusion: PGDI在语音修复领域具有显著优势，适用于实际应用场景。

Abstract: In this paper, we present PGDI, a diffusion-based speech inpainting framework
for restoring missing or severely corrupted speech segments. Unlike previous
methods that struggle with speaker variability or long gap lengths, PGDI can
accurately reconstruct gaps of up to one second in length while preserving
speaker identity, prosody, and environmental factors such as reverberation.
Central to this approach is classifier guidance, specifically phoneme-level
guidance, which substantially improves reconstruction fidelity. PGDI operates
in a speaker-independent manner and maintains robustness even when long
segments are completely masked by strong transient noise, making it well-suited
for real-world applications, such as fireworks, door slams, hammer strikes, and
construction noise. Through extensive experiments across diverse speakers and
gap lengths, we demonstrate PGDI's superior inpainting performance and its
ability to handle challenging acoustic conditions. We consider both scenarios,
with and without access to the transcript during inference, showing that while
the availability of text further enhances performance, the model remains
effective even in its absence. For audio samples, visit:
https://mordehaym.github.io/PGDI/

</details>


### [24] [EGGCodec: A Robust Neural Encodec Framework for EGG Reconstruction and F0 Extraction](https://arxiv.org/abs/2508.08924)
*Rui Feng,Yuang Chen,Yu Hu,Jun Du,Jiahong Yuan*

Main category: eess.AS

TL;DR: EGGCodec是一种用于EGG信号重建和F0提取的神经Encodec框架，通过多尺度频域损失和时间域相关性损失提升性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统Encodec模型直接从特征提取F0，而EGGCodec利用重建的EGG信号更准确地对应F0，同时简化训练流程。

Method: 提出多尺度频域损失和时间域相关性损失，移除GAN判别器以简化训练。

Result: EGGCodec将F0提取的MAE从14.14Hz降至13.69Hz，VDE提升38.2%。

Conclusion: EGGCodec在EGG信号处理和F0提取方面表现优异，各组件贡献通过消融实验验证。

Abstract: This letter introduces EGGCodec, a robust neural Encodec framework engineered
for electroglottography (EGG) signal reconstruction and F0 extraction. We
propose a multi-scale frequency-domain loss function to capture the nuanced
relationship between original and reconstructed EGG signals, complemented by a
time-domain correlation loss to improve generalization and accuracy. Unlike
conventional Encodec models that extract F0 directly from features, EGGCodec
leverages reconstructed EGG signals, which more closely correspond to F0. By
removing the conventional GAN discriminator, we streamline EGGCodec's training
process without compromising efficiency, incurring only negligible performance
degradation. Trained on a widely used EGG-inclusive dataset, extensive
evaluations demonstrate that EGGCodec outperforms state-of-the-art F0
extraction schemes, reducing mean absolute error (MAE) from 14.14 Hz to 13.69
Hz, and improving voicing decision error (VDE) by 38.2\%. Moreover, extensive
ablation experiments validate the contribution of each component of EGGCodec.

</details>


### [25] [LPGNet: A Lightweight Network with Parallel Attention and Gated Fusion for Multimodal Emotion Recognition](https://arxiv.org/abs/2508.08925)
*Zhining He,Yang Xiao*

Main category: eess.AS

TL;DR: LPGNet是一种轻量级网络，通过并行注意力和门控融合解决多模态情感识别中的计算成本高和依赖说话者信息的问题。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在多模态情感识别中存在高计算成本和依赖说话者信息的问题，限制了其泛化能力。

Method: 提出LPGNet，采用轻量级并行交互注意力模块（LPIA）和双门控融合方法，去除说话者嵌入。

Result: 在IEMOCAP数据集上，LPGNet在4类情感分类中达到87%以上的准确率和F1分数，优于基线模型。

Conclusion: LPGNet在减少参数和提高泛化能力方面表现出色，适用于真实场景中的多模态情感识别。

Abstract: Emotion recognition in conversations (ERC) aims to predict the emotional
state of each utterance by using multiple input types, such as text and audio.
While Transformer-based models have shown strong performance in this task, they
often face two major issues: high computational cost and heavy dependence on
speaker information. These problems reduce their ability to generalize in
real-world conversations. To solve these challenges, we propose LPGNet, a
Lightweight network with Parallel attention and Gated fusion for multimodal
ERC. The main part of LPGNet is the Lightweight Parallel Interaction Attention
(LPIA) module. This module replaces traditional stacked Transformer layers with
parallel dot-product attention, which can model both within-modality and
between-modality relationships more efficiently. To improve emotional feature
learning, LPGNet also uses a dual-gated fusion method. This method filters and
combines features from different input types in a flexible and dynamic way. In
addition, LPGNet removes speaker embeddings completely, which allows the model
to work independently of speaker identity. Experiments on the IEMOCAP dataset
show that LPGNet reaches over 87% accuracy and F1-score in 4-class emotion
classification. It outperforms strong baseline models while using fewer
parameters and showing better generalization across speakers.

</details>


### [26] [DeCRED: Decoder-Centric Regularization for Encoder-Decoder Based Speech Recognition](https://arxiv.org/abs/2508.08938)
*Alexander Polok,Santosh Kesiraju,Karel Beneš,Bolaji Yusuf,Lukáš Burget,Jan Černocký*

Main category: eess.AS

TL;DR: DeCRED是一种简单有效的正则化方法，通过向解码器添加辅助分类器，提升ASR模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决编码器-解码器ASR模型中解码器内部语言模型的鲁棒性和泛化问题。

Method: 在解码器中添加辅助分类器，通过中间logits预测下一个token。

Result: 在多个测试集上显著降低内部LM的困惑度，并在WER上取得改进。

Conclusion: DeCRED在数据量和参数较少的情况下，仍能实现与先进模型竞争的WER表现。

Abstract: This paper presents a simple yet effective regularization for the internal
language model induced by the decoder in encoder-decoder ASR models, thereby
improving robustness and generalization in both in- and out-of-domain settings.
The proposed method, Decoder-Centric Regularization in Encoder-Decoder
(DeCRED), adds auxiliary classifiers to the decoder, enabling next token
prediction via intermediate logits. Empirically, DeCRED reduces the mean
internal LM BPE perplexity by 36.6% relative to 11 test sets. Furthermore, this
translates into actual WER improvements over the baseline in 5 of 7 in-domain
and 3 of 4 out-of-domain test sets, reducing macro WER from 6.4% to 6.3% and
18.2% to 16.2%, respectively. On TEDLIUM3, DeCRED achieves 7.0% WER, surpassing
the baseline and encoder-centric InterCTC regularization by 0.6% and 0.5%,
respectively. Finally, we compare DeCRED with OWSM v3.1 and Whisper-medium,
showing competitive WERs despite training on much less data with fewer
parameters.

</details>


### [27] [Listen through the Sound: Generative Speech Restoration Leveraging Acoustic Context Representation](https://arxiv.org/abs/2508.08953)
*Soo-Whan Chung,Min-Seok Choi*

Main category: eess.AS

TL;DR: 提出了一种基于上下文相关条件的语音恢复新方法，利用UNIVERSE++扩散模型和CLAP声学嵌入，结合ACX表示提升恢复效果。


<details>
  <summary>Details</summary>
Motivation: 传统语音恢复方法依赖语言和说话者属性，缺乏对上下文环境的考虑，导致恢复效果不稳定。

Method: 采用UNIVERSE++扩散模型，结合CLAP声学嵌入和提出的ACX表示，优化上下文信息处理。

Result: 实验表明，上下文感知条件显著提升了恢复性能和稳定性，减少了内容依赖方法的变异性。

Conclusion: 上下文相关条件策略在语音恢复中具有优势，能更有效区分和减轻失真。

Abstract: This paper introduces a novel approach to speech restoration by integrating a
context-related conditioning strategy. Specifically, we employ the
diffusion-based generative restoration model, UNIVERSE++, as a backbone to
evaluate the effectiveness of contextual representations. We incorporate
acoustic context embeddings extracted from the CLAP model, which capture the
environmental attributes of input audio. Additionally, we propose an Acoustic
Context (ACX) representation that refines CLAP embeddings to better handle
various distortion factors and their intensity in speech signals. Unlike
content-based approaches that rely on linguistic and speaker attributes, ACX
provides contextual information that enables the restoration model to
distinguish and mitigate distortions better. Experimental results indicate that
context-aware conditioning improves both restoration performance and its
stability across diverse distortion conditions, reducing variability compared
to content-based methods.

</details>


### [28] [Selection of Layers from Self-supervised Learning Models for Predicting Mean-Opinion-Score of Speech](https://arxiv.org/abs/2508.08962)
*Xinyu Liang,Fredrik Cumlin,Victor Ungureanu,Chandan K. A. Reddy,Christian Schuldt,Saikat Chatterjee*

Main category: eess.AS

TL;DR: 研究发现，在语音质量评估中，自监督学习模型的早期层特征优于或等同于最后一层特征，显著提升了性能并降低了系统复杂度。


<details>
  <summary>Details</summary>
Motivation: 当前语音质量评估模型主要依赖最后一层特征，而中间层特征未被充分研究，本文旨在系统评估不同层特征对预测平均意见分数（MOS）的效果。

Method: 将自监督学习模型（如Wav2Vec2、HuBERT、WavLM）的各层特征输入轻量级回归网络，评估其对MOS预测的有效性。

Result: 实验表明，早期层特征优于或匹配最后一层特征，显著提升了性能并超越了传统方法和当前最佳MOS预测模型。

Conclusion: 早期层特征选择在语音质量评估中具有优势，可提升性能并降低系统复杂度。

Abstract: Self-supervised learning (SSL) models like Wav2Vec2, HuBERT, and WavLM have
been widely used in speech processing. These transformer-based models consist
of multiple layers, each capturing different levels of representation. While
prior studies explored their layer-wise representations for efficiency and
performance, speech quality assessment (SQA) models predominantly rely on
last-layer features, leaving intermediate layers underexamined. In this work,
we systematically evaluate different layers of multiple SSL models for
predicting mean-opinion-score (MOS). Features from each layer are fed into a
lightweight regression network to assess effectiveness. Our experiments
consistently show early-layers features outperform or match those from the last
layer, leading to significant improvements over conventional approaches and
state-of-the-art MOS prediction models. These findings highlight the advantages
of early-layer selection, offering enhanced performance and reduced system
complexity.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [29] [Audio-Visual Speech Enhancement: Architectural Design and Deployment Strategies](https://arxiv.org/abs/2508.08468)
*Anis Hamadouche,Haifeng Luo,Mathini Sellathurai,Tharm Ratnarajah*

Main category: cs.SD

TL;DR: 本文介绍了一种基于AI的视听语音增强系统（AVSE），并比较了不同部署架构的性能。系统结合CNN和LSTM进行多模态融合，分析了云端、边缘和独立设备的性能。


<details>
  <summary>Details</summary>
Motivation: 研究不同部署架构对AVSE系统性能的影响，以优化实时语音增强应用。

Method: 使用CNN提取频谱特征，LSTM进行时序建模，多模态融合音频和视觉信息，比较云端、边缘和独立设备的性能。

Result: 云端部署质量最高，边缘架构在延迟和清晰度间取得最佳平衡，满足5G和Wi-Fi 6的实时需求。

Conclusion: 研究结果为AVSE系统在不同应用中的部署和优化提供了实用指导。

Abstract: This paper introduces a new AI-based Audio-Visual Speech Enhancement (AVSE)
system and presents a comparative performance analysis of different deployment
architectures. The proposed AVSE system employs convolutional neural networks
(CNNs) for spectral feature extraction and long short-term memory (LSTM)
networks for temporal modeling, enabling robust speech enhancement through
multimodal fusion of audio and visual cues. Multiple deployment scenarios are
investigated, including cloud-based, edge-assisted, and standalone device
implementations. Their performance is evaluated in terms of speech quality
improvement, latency, and computational overhead. Real-world experiments are
conducted across various network conditions, including Ethernet, Wi-Fi, 4G, and
5G, to analyze the trade-offs between processing delay, communication latency,
and perceptual speech quality. The results show that while cloud deployment
achieves the highest enhancement quality, edge-assisted architectures offer the
best balance between latency and intelligibility, meeting real-time
requirements under 5G and Wi-Fi 6 conditions. These findings provide practical
guidelines for selecting and optimizing AVSE deployment architectures in
diverse applications, including assistive hearing devices, telepresence, and
industrial communications.

</details>


### [30] [Fine-grained Video Dubbing Duration Alignment with Segment Supervised Preference Optimization](https://arxiv.org/abs/2508.08550)
*Chaoqun Cui,Liangbin Huang,Shijing Wang,Zhe Tong,Zhaolong Huang,Xiao Zeng,Xiaofeng Liu*

Main category: cs.SD

TL;DR: 提出了一种名为SSPO的方法，用于解决视频配音中源语言和目标语言时长不匹配的问题，通过分段采样和细粒度损失优化时长对齐。


<details>
  <summary>Details</summary>
Motivation: 由于不同语言的信息密度差异，目标语音与源语音时长不匹配会导致音视频同步问题，影响观看体验。

Method: 采用Segment Supervised Preference Optimization (SSPO)方法，结合分段采样策略和细粒度损失函数优化时长对齐。

Result: 实验结果表明，SSPO在时长对齐任务中表现优异。

Conclusion: SSPO方法有效解决了视频配音中的时长对齐问题，提升了音视频同步效果。

Abstract: Video dubbing aims to translate original speech in visual media programs from
the source language to the target language, relying on neural machine
translation and text-to-speech technologies. Due to varying information
densities across languages, target speech often mismatches the source speech
duration, causing audio-video synchronization issues that significantly impact
viewer experience. In this study, we approach duration alignment in LLM-based
video dubbing machine translation as a preference optimization problem. We
propose the Segment Supervised Preference Optimization (SSPO) method, which
employs a segment-wise sampling strategy and fine-grained loss to mitigate
duration mismatches between source and target lines. Experimental results
demonstrate that SSPO achieves superior performance in duration alignment
tasks.

</details>


### [31] [Multi-Target Backdoor Attacks Against Speaker Recognition](https://arxiv.org/abs/2508.08559)
*Alexandrine Fortier,Sonal Joshi,Thomas Thebaud,Jesus Villalba Lopez,Najim Dehak,Patrick Cardinal*

Main category: cs.SD

TL;DR: 提出了一种针对说话人识别的多目标后门攻击方法，使用位置无关的点击声作为触发器，攻击成功率高达95.04%。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击多为单目标，无法满足多目标攻击需求，且缺乏对说话人验证任务的扩展研究。

Method: 采用位置无关的点击声作为触发器，模拟不同信噪比条件，并通过余弦相似度选择目标说话人。

Result: 在多目标攻击中成功率高达95.04%，在说话人验证任务中，目标与注册说话人相似度高时成功率可达90%。

Conclusion: 该方法在多目标攻击和说话人验证任务中均表现出高效性，揭示了攻击效果与目标相似度的关联。

Abstract: In this work, we propose a multi-target backdoor attack against speaker
identification using position-independent clicking sounds as triggers. Unlike
previous single-target approaches, our method targets up to 50 speakers
simultaneously, achieving success rates of up to 95.04%. To simulate more
realistic attack conditions, we vary the signal-to-noise ratio between speech
and trigger, demonstrating a trade-off between stealth and effectiveness. We
further extend the attack to the speaker verification task by selecting the
most similar training speaker - based on cosine similarity - as the target. The
attack is most effective when target and enrolled speaker pairs are highly
similar, reaching success rates of up to 90% in such cases.

</details>


### [32] [SonicRadiation: A Hybrid Numerical Solution for Sound Radiation without Ghost Cells](https://arxiv.org/abs/2508.08775)
*Xutong Jin,Guoping Wang,Sheng Li*

Main category: cs.SD

TL;DR: 提出了一种名为SonicRadiation的混合数值方法，用于解决复杂动态物体边界下的声音辐射模拟问题，结合了TDBEM和FDTD的优势。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法（如基于鬼单元的FDTD）在复杂边界下模拟声音辐射时的误差大和失败问题。

Method: 提出边界网格同步策略，将TDBEM与FDTD无缝结合，利用TDBEM的近场精度和FDTD的远场效率。

Result: 实验结果表明，该方法在复杂场景下的声音辐射模拟中优于现有方法，具有更高的准确性和效率。

Conclusion: SonicRadiation方法有效解决了复杂边界下的声音辐射模拟问题，兼具准确性和效率。

Abstract: Interactive synthesis of physical sound effects is crucial in digital media
production. Sound radiation simulation, a key component of physically based
sound synthesis, has posed challenges in the context of complex object
boundaries. Previous methods, such as ghost cell-based finite-difference
time-domain (FDTD) wave solver, have struggled to address these challenges,
leading to large errors and failures in complex boundaries because of the
limitation of ghost cells. We present SonicRadiation, a hybrid numerical
solution capable of handling complex and dynamic object boundaries in sound
radiation simulation without relying on ghost cells. We derive a consistent
formulation to connect the physical quantities on grid cells in FDTD with the
boundary elements in the time-domain boundary element method (TDBEM). Hereby,
we propose a boundary grid synchronization strategy to seamlessly integrate
TDBEM with FDTD while maintaining high numerical accuracy. Our method holds
both advantages from the accuracy of TDBEM for the near-field and the
efficiency of FDTD for the far-field. Experimental results demonstrate the
superiority of our method in sound radiation simulation over previous
approaches in terms of accuracy and efficiency, particularly in complex scenes,
further validating its effectiveness.

</details>


### [33] [Opening Musical Creativity? Embedded Ideologies in Generative-AI Music Systems](https://arxiv.org/abs/2508.08805)
*Liam Pram,Fabio Morreale*

Main category: cs.SD

TL;DR: 论文探讨了生成式AI音乐系统的市场宣传与实际功能之间的差异，揭示了其背后的个人主义、全球主义和伦理逃避的意识形态。


<details>
  <summary>Details</summary>
Motivation: 研究生成式AI音乐系统如何被宣传为民主化工具，但实际上可能并未真正实现包容性。

Method: 结合自传式民族志和数字民族志，分析四款公开的生成式AI音乐系统（AIVA、Stable Audio、Suno、Udio）的宣传与用户反馈。

Result: 发现开发者和用户共享一种个人主义、全球主义和伦理逃避的意识形态，这种意识形态模糊了个人责任，并重塑了音乐实践的本质。

Conclusion: 生成式AI音乐系统的宣传与实际功能存在脱节，其背后的意识形态可能掩盖了真正的民主化目标。

Abstract: AI systems for music generation are increasingly common and easy to use,
granting people without any musical background the ability to create music.
Because of this, generative-AI has been marketed and celebrated as a means of
democratizing music making. However, inclusivity often functions as marketable
rhetoric rather than a genuine guiding principle in these industry settings. In
this paper, we look at four generative-AI music making systems available to the
public as of mid-2025 (AIVA, Stable Audio, Suno, and Udio) and track how they
are rhetoricized by their developers, and received by users. Our aim is to
investigate ideologies that are driving the early-stage development and
adoption of generative-AI in music making, with a particular focus on
democratization. A combination of autoethnography and digital ethnography is
used to examine patterns and incongruities in rhetoric when positioned against
product functionality. The results are then collated to develop a nuanced,
contextual discussion. The shared ideology we map between producers and
consumers is individualist, globalist, techno-liberal, and ethically evasive.
It is a 'total ideology' which obfuscates individual responsibility, and
through which the nature of music and musical practice is transfigured to suit
generative outcomes.

</details>


### [34] [Sound Signal Synthesis with Auxiliary Classifier GAN, COVID-19 cough as an example](https://arxiv.org/abs/2508.08892)
*Yahya Sherif Solayman Mohamed Saleh,Ahmed Mohammed Dabbous,Lama Alkhaled,Hum Yan Chai,Muhammad Ehsan Rana,Hamam Mokayed*

Main category: cs.SD

TL;DR: 论文探讨了在COVID-19大流行期间，通过合成咳嗽数据提升AI模型检测准确性的方法。


<details>
  <summary>Details</summary>
Motivation: 医疗领域对AI的需求迫切，但数据稀缺问题突出，尤其是在COVID-19期间。合成数据被用于缓解这一问题。

Method: 使用ACGAN生成合成咳嗽的Mel频谱图，用于增强CNN分类器的训练数据。

Result: 通过合成数据增强，CNN分类器的测试准确率从72%提升至75%。

Conclusion: 合成数据在医疗AI中具有潜力，但需注意训练中的不一致性。

Abstract: One of the fastest-growing domains in AI is healthcare. Given its importance,
it has been the interest of many researchers to deploy ML models into the
ever-demanding healthcare domain to aid doctors and increase accessibility.
Delivering reliable models, however, demands a sizable amount of data, and the
recent COVID-19 pandemic served as a reminder of the rampant and scary nature
of healthcare that makes training models difficult. To alleviate such scarcity,
many published works attempted to synthesize radiological cough data to train
better COVID-19 detection models on the respective radiological data. To
accommodate the time sensitivity expected during a pandemic, this work focuses
on detecting COVID-19 through coughs using synthetic data to improve the
accuracy of the classifier. The work begins by training a CNN on a balanced
subset of the Coughvid dataset, establishing a baseline classification test
accuracy of 72%. The paper demonstrates how an Auxiliary Classification GAN
(ACGAN) may be trained to conditionally generate novel synthetic Mel
Spectrograms of both healthy and COVID-19 coughs. These coughs are used to
augment the training dataset of the CNN classifier, allowing it to reach a new
test accuracy of 75%. The work highlights the expected messiness and
inconsistency in training and offers insights into detecting and handling such
shortcomings.

</details>


### [35] [DualSpeechLM: Towards Unified Speech Understanding and Generation via Dual Speech Token Modeling with Large Language Models](https://arxiv.org/abs/2508.08961)
*Yuanyuan Wang,Dongchao Yang,Yiwen Shao,Hangting Chen,Jiankun Zhao,Zhiyong Wu,Helen Meng,Xixin Wu*

Main category: cs.SD

TL;DR: 论文提出了一种统一语音理解和生成的模型，通过理解驱动的语音分词器（USTokenizer）和双令牌建模框架（DualSpeechLM）解决模态差异和任务优化问题。


<details>
  <summary>Details</summary>
Motivation: 解决语音与文本模态差异大、统一模型在理解和生成任务中性能优化困难的问题。

Method: 1. 提出USTokenizer提取高层语义信息；2. 设计DualSpeechLM框架，同时建模语义令牌和声学令牌；3. 引入语义监督损失和Chain-of-Condition策略。

Result: 实验表明，该方法有效促进了理解和生成任务的互补关系。

Conclusion: 统一模型通过双令牌框架和语义监督策略，成功增强了语音理解和生成能力。

Abstract: Extending pre-trained Large Language Models (LLMs)'s speech understanding or
generation abilities by introducing various effective speech tokens has
attracted great attention in the speech community. However, building a unified
speech understanding and generation model still faces the following challenges:
(1) Due to the huge modality gap between speech tokens and text tokens,
extending text LLMs to unified speech LLMs relies on large-scale paired data
for fine-tuning, and (2) Generation and understanding tasks prefer information
at different levels, e.g., generation benefits from detailed acoustic features,
while understanding favors high-level semantics. This divergence leads to
difficult performance optimization in one unified model. To solve these
challenges, in this paper, we present two key insights in speech tokenization
and speech language modeling. Specifically, we first propose an
Understanding-driven Speech Tokenizer (USTokenizer), which extracts high-level
semantic information essential for accomplishing understanding tasks using text
LLMs. In this way, USToken enjoys better modality commonality with text, which
reduces the difficulty of modality alignment in adapting text LLMs to speech
LLMs. Secondly, we present DualSpeechLM, a dual-token modeling framework that
concurrently models USToken as input and acoustic token as output within a
unified, end-to-end framework, seamlessly integrating speech understanding and
generation capabilities. Furthermore, we propose a novel semantic supervision
loss and a Chain-of-Condition (CoC) strategy to stabilize model training and
enhance speech generation performance. Experimental results demonstrate that
our proposed approach effectively fosters a complementary relationship between
understanding and generation tasks, highlighting the promising strategy of
mutually enhancing both tasks in one unified model.

</details>


### [36] [QAMRO: Quality-aware Adaptive Margin Ranking Optimization for Human-aligned Assessment of Audio Generation Systems](https://arxiv.org/abs/2508.08957)
*Chien-Chun Wang,Kuan-Tang Huang,Cheng-Yeh Yang,Hung-Shin Lee,Hsin-Min Wang,Berlin Chen*

Main category: cs.SD

TL;DR: QAMRO框架通过结合回归目标和感知差异优化，提升音频生成系统评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将MOS预测视为回归问题，但忽略了感知判断的相对性，导致评估不准确。

Method: 提出QAMRO框架，结合回归目标和自适应边际排序优化，利用预训练音频-文本模型（如CLAP和Audiobox-Aesthetics）。

Result: 在AudioMOS Challenge 2025数据集上表现优异，显著优于基线模型。

Conclusion: QAMRO框架在音频生成系统评估中表现出更高的准确性和与人类评价的一致性。

Abstract: Evaluating audio generation systems, including text-to-music (TTM),
text-to-speech (TTS), and text-to-audio (TTA), remains challenging due to the
subjective and multi-dimensional nature of human perception. Existing methods
treat mean opinion score (MOS) prediction as a regression problem, but standard
regression losses overlook the relativity of perceptual judgments. To address
this limitation, we introduce QAMRO, a novel Quality-aware Adaptive Margin
Ranking Optimization framework that seamlessly integrates regression objectives
from different perspectives, aiming to highlight perceptual differences and
prioritize accurate ratings. Our framework leverages pre-trained audio-text
models such as CLAP and Audiobox-Aesthetics, and is trained exclusively on the
official AudioMOS Challenge 2025 dataset. It demonstrates superior alignment
with human evaluations across all dimensions, significantly outperforming
robust baseline models.

</details>


### [37] [Neutone SDK: An Open Source Framework for Neural Audio Processing](https://arxiv.org/abs/2508.09126)
*Christopher Mitcheltree,Bogdan Teleaga,Andrew Fyfe,Naotake Masuda,Matthias Schäfer,Alfie Bradic,Nao Tokui*

Main category: cs.SD

TL;DR: Neutone SDK是一个开源框架，简化了基于PyTorch的神经音频模型在实时和离线应用中的部署，解决了插件开发的复杂性和实时推理的挑战。


<details>
  <summary>Details</summary>
Motivation: 将深度学习模型集成到数字音频工作站（DAWs）中面临实时推理和插件开发的复杂性，需要一种简化部署的解决方案。

Method: 通过封装常见挑战（如可变缓冲区大小、采样率转换、延迟补偿和控制参数处理）并提供统一的模型无关接口，实现神经模型与主机插件的无缝互操作。

Result: Neutone SDK展示了在音频效果模拟、音色转换和样本生成等应用中的多功能性，并被研究人员、教育者、公司和艺术家广泛采用。

Conclusion: Neutone SDK为神经音频模型的部署提供了一种高效、灵活的解决方案，推动了深度学习在音频处理中的应用。

Abstract: Neural audio processing has unlocked novel methods of sound transformation
and synthesis, yet integrating deep learning models into digital audio
workstations (DAWs) remains challenging due to real-time / neural network
inference constraints and the complexities of plugin development. In this
paper, we introduce the Neutone SDK: an open source framework that streamlines
the deployment of PyTorch-based neural audio models for both real-time and
offline applications. By encapsulating common challenges such as variable
buffer sizes, sample rate conversion, delay compensation, and control parameter
handling within a unified, model-agnostic interface, our framework enables
seamless interoperability between neural models and host plugins while allowing
users to work entirely in Python. We provide a technical overview of the
interfaces needed to accomplish this, as well as the corresponding SDK
implementations. We also demonstrate the SDK's versatility across applications
such as audio effect emulation, timbre transfer, and sample generation, as well
as its adoption by researchers, educators, companies, and artists alike. The
Neutone SDK is available at https://github.com/Neutone/neutone_sdk

</details>


### [38] [Revealing the Role of Audio Channels in ASR Performance Degradation](https://arxiv.org/abs/2508.08967)
*Kuan-Tang Huang,Li-Wei Chen,Hung-Shin Lee,Berlin Chen,Hsin-Min Wang*

Main category: cs.SD

TL;DR: 提出了一种归一化技术，通过对齐ASR模型内部特征与干净参考通道的特征，减少不同录音通道对ASR性能的影响。


<details>
  <summary>Details</summary>
Motivation: 预训练ASR模型在不同录音通道下的性能下降问题，通常归因于训练与测试数据的不匹配，但本研究认为通道差异本身会损害ASR性能。

Method: 提出一种归一化技术，将ASR模型的内部特征与干净参考通道的特征对齐。

Result: 显著提高了ASR在未见通道和语言上的性能，展示了其跨通道和跨语言的泛化能力。

Conclusion: 该归一化技术有效缓解了通道差异对ASR性能的影响，并具有广泛的适用性。

Abstract: Pre-trained automatic speech recognition (ASR) models have demonstrated
strong performance on a variety of tasks. However, their performance can
degrade substantially when the input audio comes from different recording
channels. While previous studies have demonstrated this phenomenon, it is often
attributed to the mismatch between training and testing corpora. This study
argues that variations in speech characteristics caused by different recording
channels can fundamentally harm ASR performance. To address this limitation, we
propose a normalization technique designed to mitigate the impact of channel
variation by aligning internal feature representations in the ASR model with
those derived from a clean reference channel. This approach significantly
improves ASR performance on previously unseen channels and languages,
highlighting its ability to generalize across channel and language differences.

</details>

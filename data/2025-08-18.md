<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [eess.AS](#eess.AS) [Total: 7]
- [cs.SD](#cs.SD) [Total: 6]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Distributed Integrated Sensing, Localization, and Communications over LEO Satellite Constellations](https://arxiv.org/abs/2508.11029)
*Yuchen Zhang,Francis Soualle,Musa Furkan Keskin,Yuan Liu,Linlong Wu,José A. del Peral-Rosado,Bhavani Shankar M. R.,Gonzalo Seco-Granados,Henk Wymeersch,Tareq Y. Al-Naffouri*

Main category: eess.SP

TL;DR: 本文提出了一种名为DISLAC的分布式集成感知、定位和通信框架，通过LEO卫星间的协作提升性能。


<details>
  <summary>Details</summary>
Motivation: LEO卫星在6G应用中面临功率、天线和处理能力限制，需要新的解决方案。

Method: 采用分布式MIMO架构，通过卫星间链路实现协作，提升吞吐量、定位精度和感知鲁棒性。

Result: 案例研究表明DISLAC能显著改善性能，并分析了同步、天线可重构性等关键问题。

Conclusion: 文章总结了DISLAC的未来研究方向，以推动其在实际非地面网络中的部署。

Abstract: Low Earth orbit (LEO) satellite constellations are rapidly becoming essential
enablers of next-generation wireless systems, offering global broadband access,
high-precision localization, and reliable sensing beyond terrestrial coverage.
However, the inherent limitations of individual LEO satellites, including
restricted power, limited antenna aperture, and constrained onboard processing,
hinder their ability to meet the growing demands of 6G applications. To address
these challenges, this article introduces the concept of distributed integrated
sensing, localization, and communication (DISLAC) over LEO constellations,
inspired by distributed multiple input multiple output architectures. By
enabling inter-satellite cooperation through inter-satellite links, DISLAC can
substantially improve throughput, positioning accuracy, and sensing robustness.
We present illustrative case studies that quantify these benefits and analyze
key system-level considerations, including synchronization, antenna
reconfigurability, and ISL design. The article concludes by outlining open
research directions to advance the practical deployment of DISLAC in future
non-terrestrial networks.

</details>


### [2] [Multi-Satellite Cooperative MIMO Transmission: Statistical CSI-Aware RSMA Precoding Design](https://arxiv.org/abs/2508.11132)
*Sangwon Jo,Seok-Hwan Park*

Main category: eess.SP

TL;DR: 研究了多颗低地球轨道（LEO）卫星间的协作传输，通过MIMO预编码和RSMA技术提升频谱效率，基于统计CSI优化最大最小公平速率。


<details>
  <summary>Details</summary>
Motivation: 解决LEO卫星通信中因延迟和多普勒效应导致瞬时CSI获取困难的问题，提升系统性能。

Method: 设计基于统计CSI的MIMO预编码和RSMA方案，通过闭式上界近似和WMMSE算法求解优化问题。

Result: 仿真表明，基于统计CSI的RSMA方案接近瞬时CSI性能，显著优于传统空间分割多址。

Conclusion: 基于统计CSI的RSMA方案在LEO卫星通信中具有高效性和实用性。

Abstract: We investigate inter-satellite cooperative transmission in a multiple
low-Earth orbit (LEO) satellite communication system to enhance spectral
efficiency. Specifically, we design multiple-input multipleoutput (MIMO)
precoding at LEO satellites for cooperative rate-splitting multiple access
(RSMA). Given the difficulty of acquiring instantaneous channel state
information (iCSI) due to long delays and Doppler effects, we formulate an
ergodic max-min fairness rate (MMFR) maximization problem based on statistical
CSI (sCSI). To address the challenge of ergodic rate evaluation, we approximate
the problem using closed-form upper bounds and develop a weighted minimum mean
squared error-based algorithm to obtain a stationary point. Simulation results
demonstrate that the proposed sCSI-based RSMA scheme approaches iCSI-based
performance and significantly outperforms conventional space-division multiple
access.

</details>


### [3] [Near-Field Variable-Width Beam Coverage and Codebook Design for XL-RIS](https://arxiv.org/abs/2508.11178)
*Yida Zhang,Qiuyan Liu,Qiang Wang,Hongtao Luo,Yuqi Xia*

Main category: eess.SP

TL;DR: 提出一种可变宽度波束生成算法，用于解决XL-RIS波束宽度窄的问题，提升覆盖范围和通信效率。


<details>
  <summary>Details</summary>
Motivation: XL-RIS的高波束增益虽好，但波束宽度较窄，增加了波束对准和广播的复杂性，需改进。

Method: 在近场假设下设计可变宽度波束生成算法，并应用于XL-RIS的近场码本设计。

Result: 仿真显示，该方案能提高频谱效率、降低通信中断概率，并对码本区域变化更具鲁棒性。

Conclusion: 该算法有效解决了XL-RIS的波束宽度问题，提升了系统性能。

Abstract: To mitigate the issue of limited base station coverage caused by severe
high-frequency electromagnetic wave attenuation, Extremely Large Reconfigurable
Intelligent Surface (XL-RIS) has garnered significant attention due to its high
beam gain. However, XL-RIS exhibits a narrower beam width compared to
traditional RIS, which increases the complexity of beam alignment and
broadcast. To address this problem, we propose a variable-width beam generation
algorithm under the near-field assumption and apply it to the near-field
codebook design for XL-RIS. Our algorithm can achieve beam coverage for
arbitrarily shaped codeword regions and generate a joint codebook for the
multi-XL-RIS system. The simulation results demonstrate that our proposed
scheme enables user equipment (UE) to achieve higher spectral efficiency and
lower communication outage probability within the codeword region compared to
existing works. Furthermore, our scheme exhibits better robustness to codeword
region location and area variations.

</details>


### [4] [KAN-HAR: A Human activity recognition based on Kolmogorov-Arnold Network](https://arxiv.org/abs/2508.11186)
*Mohammad Alikhani*

Main category: eess.SP

TL;DR: 论文提出了一种基于Kolmogorov-Arnold Network (KAN)和单三轴加速度计的人体活动识别方法，相比传统深度学习具有更高的可解释性和参数效率。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在人体活动识别中需要大量参数调优且缺乏可解释性，KAN能更好地建模复杂非线性关系。

Method: 使用MotionSense数据集，预处理和归一化加速度计与陀螺仪数据，通过KAN进行特征学习和分类。

Result: KAN在分类性能上与传统深度神经网络相当或更优，同时参数数量显著减少。

Conclusion: KAN架构是一种高效且可解释的替代方案，适用于实际人体活动识别系统。

Abstract: Human Activity Recognition (HAR) plays a critical role in numerous
applications, including healthcare monitoring, fitness tracking, and smart
environments. Traditional deep learning (DL) approaches, while effective, often
require extensive parameter tuning and may lack interpretability. In this work,
we investigate the use of a single three-axis accelerometer and the
Kolmogorov--Arnold Network (KAN) for HAR tasks, leveraging its ability to model
complex nonlinear relationships with improved interpretability and parameter
efficiency. The MotionSense dataset, containing smartphone-based motion sensor
signals across various physical activities, is employed to evaluate the
proposed approach. Our methodology involves preprocessing and normalization of
accelerometer and gyroscope data, followed by KAN-based feature learning and
classification. Experimental results demonstrate that the KAN achieves
competitive or superior classification performance compared to conventional
deep neural networks, while maintaining a significantly reduced parameter
count. This highlights the potential of KAN architectures as an efficient and
interpretable alternative for real-world HAR systems. The open-source
implementation of the proposed framework is available at the Project's GitHub
Repository.

</details>


### [5] [Enabling low-power massive MIMO with ternary ADCs for AIoT sensing](https://arxiv.org/abs/2508.11234)
*Shengheng Liu,Ningning Fu*

Main category: eess.SP

TL;DR: 论文提出了一种使用三元ADC（T-ADC）的低功耗AIoT解决方案，通过联合导频和数据（JPD）方法优化信道估计，验证了其可行性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决AIoT中高分辨率ADC和射频链的高功耗问题。

Method: 采用T-ADC和JPD方案进行信道估计，提出改进的EM和变分推断EM估计器。

Result: JPD方案有效减轻量化效应，仿真验证了其在MSE和SER上的优越性。

Conclusion: T-ADC和JPD方案为绿色AIoT智能感知提供了可行方案。

Abstract: The proliferation of networked devices and the surging demand for ubiquitous
intelligence have given rise to the artificial intelligence of things (AIoT).
However, the utilization of high-resolution analog-to-digital converters (ADCs)
and numerous radio frequency chains significantly raises power consumption.
This paper explores a cost-effective solution using ternary ADCs (T-ADCs) in
massive multiple-input-multiple-output (MIMO) systems for low-power AIoT and
specifically addresses channel sensing challenges. The channel is first
estimated through a pilot-aided scheme and refined using a joint-pilot-and-data
(JPD) approach. To assess the performance limits of this two-threshold ADC
system, the analysis includes its hardware-ideal counterpart, the parallel
one-bit ADCs (PO-ADCs) and a realistic scenario where noise variance is unknown
at the receiver is considered. Analytical findings indicate that the JPD scheme
effectively mitigates performance degradation in channel estimation due to
coarse quantization effects under mild conditions, without necessitating
additional pilot overhead. For deterministic and random channels, we propose
modified expectation maximization (EM) and variational inference EM estimators,
respectively. Extensive simulations validate the theoretical results and
demonstrate the effectiveness of the proposed estimators in terms of mean
square error and symbol error rate, which showcases the feasibility of
implementing T-ADCs and the associated JPD scheme for greener AIoT smart
sensing.

</details>


### [6] [Temporally-Similar Structure-Aware Spatiotemporal Fusion of Satellite Images](https://arxiv.org/abs/2508.11259)
*Ryosuke Isono,Shunsuke Ono*

Main category: eess.SP

TL;DR: 提出了一种名为TSSTF的时空融合框架，通过TGTV和TGEC机制提升噪声鲁棒性和空间结构保留能力。


<details>
  <summary>Details</summary>
Motivation: 解决卫星图像时空分辨率权衡问题，并增强现有方法在噪声环境下的性能。

Method: 引入TGTV和TGEC机制，将任务建模为约束优化问题，采用预条件原始对偶分裂算法求解。

Result: 在无噪声条件下表现与先进方法相当，在噪声条件下更优，并提供了参数推荐。

Conclusion: TSSTF在噪声鲁棒性和结构保留方面优于现有方法，具有实用性和可重复性。

Abstract: This paper proposes a novel spatiotemporal (ST) fusion framework for
satellite images, named Temporally-Similar Structure-Aware ST fusion (TSSTF).
ST fusion is a promising approach to address the trade-off between the spatial
and temporal resolution of satellite images. In real-world scenarios, observed
satellite images are severely degraded by noise due to measurement equipment
and environmental conditions. Consequently, some recent studies have focused on
enhancing the robustness of ST fusion methods against noise. However, existing
noise-robust ST fusion approaches often fail to capture fine spatial structure,
leading to oversmoothing and artifacts. To address this issue, TSSTF introduces
two key mechanisms: Temporally-Guided Total Variation (TGTV) and
Temporally-Guided Edge Constraint (TGEC). TGTV is a novel regularization
function that promotes spatial piecewise smoothness while preserving structural
details, guided by a reference high spatial resolution image acquired on a
nearby date. TGEC enforces consistency in edge locations between two temporally
adjacent images, while allowing for spectral variations. We formulate the ST
fusion task as a constrained optimization problem incorporating TGTV and TGEC,
and develop an efficient algorithm based on a preconditioned primal-dual
splitting method. Experimental results demonstrate that TSSTF performs
comparably to state-of-the-art methods under noise-free conditions and
outperforms them under noisy conditions. Additionally, we provide a
comprehensive set of recommended parameter values that consistently yield high
performance across diverse target regions and noise conditions, aiming to
enhance reproducibility and practical utility.

</details>


### [7] [Beyond Diagonal Reconfigurable Intelligent Surface Enabled Sensing: Cramer-Rao Bound Optimization](https://arxiv.org/abs/2508.11292)
*Xiaoqi Zhang,Liang Liu,Shuowen Zhang,Haijun Zhang*

Main category: eess.SP

TL;DR: 本文研究了非对角可重构智能表面（BD-RIS）在6G感知中的优势，提出了一种基于自适应黎曼最速上升算法的优化方案，显著提升了目标定位性能。


<details>
  <summary>Details</summary>
Motivation: 尽管BD-RIS在通信中的优势已被广泛研究，但其在6G感知中的潜力尚未明确。本文旨在填补这一空白。

Method: 推导了在BD-RIS散射矩阵为酉矩阵约束下的到达角（AOA）估计的Cramer-Rao界（CRB），并提出了基于自适应黎曼最速上升算法的优化方案。

Result: 数值结果表明，所提出的BD-RIS辅助目标定位方法具有优越的感知性能。

Conclusion: BD-RIS在6G感知中具有显著优势，其优化方案能有效提升目标定位精度。

Abstract: Recently, beyond diagonal reconfigurable intelligent surface (BD-RIS) has
emerged as a more flexible solution to engineer the wireless propagation
channels, thanks to its non-diagonal reflecting matrix. Although the gain of
the BD-RIS over the conventional RIS in communication has been revealed in many
works, its gain in 6G sensing is still unknown. This motivates us to study the
BD-RIS assisted sensing in this letter. Specifically, we derive the Cramer-Rao
bound (CRB) for estimating the angle-of-arrival (AOA) from the target to the
BD-RIS under the constraint that the BD-RIS scattering matrix is unitary. To
minimize the CRB, we develop an optimization scheme based on an adaptive
Riemannian steepest ascent algorithm that can satisfy the non-convex unitary
constraint. Numerical results demonstrate that the proposed BD-RIS-assisted
target localization method achieves superior sensing performance.

</details>


### [8] [Optimizing Rate-CRB Performance for Beyond Diagonal Reconfigurable Intelligent Surface Enabled ISAC](https://arxiv.org/abs/2508.11295)
*Xiaoqi Zhang,Liang Liu,Shuowen Zhang,Weifeng Zhu,Haijun Zhang*

Main category: eess.SP

TL;DR: 本文研究了基于超对角可重构智能表面（BD-RIS）的集成感知与通信（ISAC）系统，提出了一种优化方法以最大化用户设备（UE）的总速率，同时满足定位精度约束。


<details>
  <summary>Details</summary>
Motivation: 传统RIS辅助的ISAC系统性能有限，BD-RIS通过更灵活的散射矩阵设计，有望提升系统性能。

Method: 采用基于对数障碍的黎曼最速上升法，优化基站波束成形矩阵和BD-RIS散射矩阵。

Result: 数值结果表明，所提算法有效，且BD-RIS辅助的ISAC系统性能优于传统RIS辅助系统。

Conclusion: BD-RIS在ISAC系统中具有显著性能优势，为未来通信与感知一体化提供了新思路。

Abstract: This letter considers a beyond diagonal reconfigurable intelligent surface
(BD-RIS) aided integrated sensing and communication (ISAC) system, where the
BD-RIS can help a multi-antenna base station (BS) serve multiple user
equipments (UEs) and localize a target simultaneously. We formulate an
optimization problem that designs the BS beamforming matrix and the BD-RIS
scattering matrix to maximize UEs' sum rate subject to a localization
Cramer-Rao bound (CRB) constraint and an additional unitary matrix constraint
for the scattering matrix. Because unitary matrices form a manifold, our
problem belongs to constrained manifold optimization. This letter proposes a
log-barrier based Riemannian steepest ascent method to solve this problem
effectively. Numerical results verify the effectiveness of our algorithm and
the performance gain of the BD-RIS aided ISAC systems over the conventional RIS
aided ISAC systems.

</details>


### [9] [Important Bit Prefix M-ary Quadrature Amplitude Modulation for Semantic Communications](https://arxiv.org/abs/2508.11351)
*Haonan Lu,Rui Meng,Xiaodong Xu,Yiming Liu,Ping Zhang,Dusit Niyato*

Main category: eess.SP

TL;DR: 提出了一种基于MQAM的语义通信调制方案IBP-MQAM，并通过LDA量化语义，验证其性能优于传统MQAM。


<details>
  <summary>Details</summary>
Motivation: 为语义通信（SemCom）设计专用的信道调制技术，以提升性能。

Method: 提出IBP-MQAM方案，推导重要符号错误率（ISER）和非重要符号错误率（USER）的近似表达式，并使用LDA提取和量化文本语义。

Result: IBP-MQAM在语义通信场景中表现优于传统MQAM，并分析了关键系统参数的影响。

Conclusion: IBP-MQAM是一种有效的语义通信调制方案，具有实际应用潜力。

Abstract: M-ary Quadrature Amplitude Modulation (MQAM) is a commonly used channel
modulation technology in wireless communication systems. To achieve dedicated
channel modulation for semantic communication (SemCom), we propose an
Important-Bit-Prefixed MQAM (IBP-MQAM) scheme and derive its approximate
expression of important symbol error rate (ISER) and unimportant symbol error
rate (USER). By extracting and quantifying text semantics using Latent
Dirichlet Allocation (LDA), we verify that IBP-MQAM achieves improved
performance over MQAM in SemCom scenarios and further analyze the effects of
key system parameters.

</details>


### [10] [Importance-Aware Robust Semantic Transmission for LEO Satellite-Ground Communication](https://arxiv.org/abs/2508.11457)
*Hui Cao,Rui Meng,Xiaodong Xu,Shujun Han,Ping Zhang*

Main category: eess.SP

TL;DR: 论文提出了一种重要性感知的鲁棒语义传输框架（IRST），用于解决卫星地面语义通信中的动态SNR波动和带宽限制问题。


<details>
  <summary>Details</summary>
Motivation: 在6G时代，卫星地面语义通信面临动态SNR波动和严格带宽限制的挑战，需要一种高效的任务导向数据传输方法。

Method: IRST框架包括语义分割模型增强算法、任务驱动的语义选择方法以及基于SNR的自适应信道编解码器。

Result: 在不同操作条件下的比较评估中，IRST模型表现出优于现有基准的性能和鲁棒性。

Conclusion: IRST框架为解决卫星地面语义通信中的挑战提供了一种有效的解决方案。

Abstract: Satellite-ground semantic communication is anticipated to serve a critical
role in the forthcoming 6G era. Nonetheless, task-oriented data transmission in
such systems remains a formidable challenge, primarily due to the dynamic
nature of signal-to-noise ratio (SNR) fluctuations and the stringent bandwidth
limitations inherent to low Earth orbit (LEO) satellite channels. In response
to these constraints, we propose an importance-aware robust semantic
transmission (IRST) framework, specifically designed for scenarios
characterized by bandwidth scarcity and channel variability. The IRST scheme
begins by applying a segmentation model enhancement algorithm to improve the
granularity and accuracy of semantic segmentation. Subsequently, a task-driven
semantic selection method is employed to prioritize the transmission of
semantically vital content based on real-time channel state information.
Furthermore, the framework incorporates a stack-based, SNR-aware channel codec
capable of executing adaptive channel coding in alignment with SNR variations.
Comparative evaluations across diverse operating conditions demonstrate the
superior performance and resilience of the IRST model relative to existing
benchmarks.

</details>


### [11] [Efficient Artifacts Removal for Adaptive Deep Brain Stimulation and a Temporal Event Localization Analysis](https://arxiv.org/abs/2508.11459)
*Tzu-Chi Liu,Po-Lin Chen,Yi-Chieh Chen,Po-Hsun Tu,Chih-Hua Yeh,Mun-Chun Yeap,Chiung-Chu Chen,Hau-Tieng Wu*

Main category: eess.SP

TL;DR: SMARTA+是一种高效的后端算法，用于抑制自适应深部脑刺激（aDBS）中的刺激和瞬态直流伪影，支持灵活的算法设计，并在计算效率和性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 刺激引起的信号污染是aDBS临床应用的主要技术障碍，现有方法在伪影抑制和算法灵活性之间存在权衡。

Method: 开发了SMARTA+，作为SMARTA的高效扩展，能够同时抑制刺激和瞬态直流伪影，并支持灵活的算法设计。

Result: SMARTA+在伪影去除效果上与现有方法相当或更优，同时显著减少计算时间，保留了频谱和时间结构，并在不同刺激协议下表现出鲁棒性。

Conclusion: SMARTA+是推动实时闭环aDBS系统的有前景的工具。

Abstract: Adaptive deep brain stimulation (aDBS) leverages symptom-related biomarkers
to deliver personalized neuromodulation therapy, with the potential to improve
treatment efficacy and reduce power consumption compared to conventional DBS.
However, stimulation-induced signal contamination remains a major technical
barrier to advancing its clinical application. Existing artifact removal
strategies, both front-end and back-end, face trade-offs between artifact
suppression and algorithmic flexibility. Among back-end algorithms, Shrinkage
and Manifold-based Artifact Removal using Template Adaptation (SMARTA) has
shown promising performance in mitigating stimulus artifacts with minimal
distortion to local field potentials (LFPs), but its high computational demand
and inability to handle transient direct current (DC) artifacts limit its use
in real-time applications. To address this, we developed SMARTA+, a
computationally efficient extension of SMARTA capable of suppressing both
stimulus and transient DC artifacts while supporting flexible algorithmic
design. We evaluated SMARTA+ using semi-real aDBS data and real data from
Parkinson's disease patients. Compared to SMARTA and other established methods,
SMARTA+ achieved comparable or superior artifact removal while significantly
reducing computation time. It preserved spectral and temporal structures,
ranging from beta band to high-frequency oscillations, and demonstrated
robustness across diverse stimulation protocols. Temporal event localization
analysis further showed improved accuracy in detecting beta bursts. These
findings support SMARTA+ as a promising tool for advancing real-time,
closed-loop aDBS systems.

</details>


### [12] [Reducing AoI and Improving Throughput for NOMA-assisted SGF Systems: A Hierarchical Learning Approach](https://arxiv.org/abs/2508.11473)
*Yuqin Liu,Mona Jaber,Yan Liu,Arumugam Nallanathan*

Main category: eess.SP

TL;DR: 提出了一种基于非正交多址（NOMA）的半免授权（SGF）框架，通过利用授权用户（GBUs）的剩余资源为免授权用户（GFUs）提供信道接入。通过联合波束成形设计和传输调度优化系统吞吐量并降低GFUs的信息时效性（AoI）。采用深度强化学习（DRL）和分层学习算法解决该问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有系统中，免授权用户（GFUs）的信道接入效率低且信息时效性差。通过利用授权用户（GBUs）的剩余资源，可以优化资源分配并提升系统性能。

Method: 1. 将问题建模为马尔可夫决策过程（MDP）；2. 提出基于DRL的传输调度方法，优化传输概率；3. 设计分层学习算法，上层策略优化波束成形，下层策略最大化传输时隙利用率。

Result: 1. DRL调度方法在AoI降低上优于现有基线，平均提前3-5个时隙；2. 分层学习算法实现31.82%的性能增益，同时将GFUs的平均AoI控制在1.5个时隙内；3. 在GFUs数量为GBUs的1-5倍时均有效。

Conclusion: NOMA辅助的SGF框架结合DRL和分层学习算法，显著提升了GFUs的信道接入效率和AoI性能，适用于多种场景。

Abstract: A non-orthogonal multiple access (NOMA) assisted semi-grant-free (SGF)
framework is proposed to enable channel access for grant-free users (GFUs) by
using residual resources from grant-based users. Under this framework, the
problem of joint beamforming design and transmission scheduling is formulated
to improve the system throughput and reduce the age-of-information of GFUs. The
aforementioned problem is transferred into a Markov Decision Process to model
the changing environment with the transmission/ waiting/ retransmission of
GFUs. In an effort to solve the pertinent problem, firstly, a deep
reinforcement learning (DRL) based transmission scheduling approach is proposed
for determining the optimal transmission probability based on the available
transmission slots and transmission status of GFUs. Secondly, a hierarchical
learning algorithm is proposed to analyze the channel state information of GBUs
and the transmission status of GFUs, and to train an upper-level policy based
on this analysis for beamforming to achieve efficient grant-based transmission,
while a lower-level policy adapts to maximize the utilization of transmission
slots allocated by the upper-level agent. The two policies interact to improve
channel access and avoid collisions. Numerical results reveal that 1) The DRL
based transmission scheduling outperforms existing adaptive and state-dependent
baselines in AoI reduction, where an average
three-time-slots-earlier-transmission can be obtained compared to the
state-dependent choice, and five time slots earlier can be achieved when
comparing to the adaptive choice; 2) The hierarchical learning algorithm is
able to achieve approximately a 31.82% gain while maintaining the average AoI
of GFUs within 1.5 time slots. 3) The effectiveness of the hierarchical
learning scheme in NOMA-assisted SGF system is validated across scenarios with
GFUs counts from 1-5 times of GBUs.

</details>


### [13] [Liquid Crystal-Based RIS Loss-Trade-Off Analysis](https://arxiv.org/abs/2508.11489)
*Bowu Wang,Mohamadreza Delbari,Robin Neuder,Alejandro Jiménez-Sáez,Vahid Jamali*

Main category: eess.SP

TL;DR: 研究液晶（LC）技术在毫米波频段可重构智能表面（RIS）中的应用，探讨相位偏移范围与插入损耗之间的权衡。


<details>
  <summary>Details</summary>
Motivation: LC-RIS在毫米波频段具有低功耗、可扩展性和连续可调相位偏移的优势，但其相位偏移范围与插入损耗的权衡尚未被研究。

Method: 通过基站（BS）和RIS的配置，最小化发射功率，同时满足用户的服务质量（QoS）要求。

Result: 仿真结果显示，LC相位偏移范围与总发射功率和可达到的数据速率之间存在基本权衡。

Conclusion: LC-RIS在无线系统中存在相位偏移范围与性能的权衡，需在实际应用中优化设计。

Abstract: Liquid crystal (LC) technology has emerged as a promising solution for large
reconfigurable intelligent surfaces (RISs) at millimeter wave (mmWave) bands,
offering advantages such as low power consumption, scalability, and
continuously tunable phase shifts. For LC-RIS based on the delay-line
architecture, i.e., with dedicated phase shifters, there exists a trade-off
between the maximum achievable phase-shift range and the corresponding
insertion loss, which has not been studied for LC-RIS-assisted wireless systems
yet. In this paper, we investigate this trade-off where a base station (BS) and
an RIS are configured to minimize the transmit power while satisfying a given
quality of service (QoS) for a number of users. Simulation results reveal a
fundamental trade-off between the total transmit power and the achievable data
rate as a function of the LC phase-shift range.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [14] [ASAudio: A Survey of Advanced Spatial Audio Research](https://arxiv.org/abs/2508.10924)
*Zhiyuan Zhu,Yu Zhang,Wenxiang Guo,Changhao Pan,Zhou Zhao*

Main category: eess.AS

TL;DR: 本文对空间音频技术进行了全面综述，系统整理了相关文献，并分类总结了输入输出表示、生成与理解任务，同时回顾了数据集、评估指标和基准。


<details>
  <summary>Details</summary>
Motivation: 随着空间音频技术的快速发展，其在AR、VR等场景中的应用受到广泛关注，但目前缺乏对该领域方法和技术的系统整理与分析。

Method: 按时间顺序梳理现有研究，基于输入输出表示和任务类型进行分类，并总结相关数据集、评估指标和基准。

Result: 提供了空间音频领域的全面概述，系统整理了文献，并总结了研究方向和资源。

Conclusion: 本文填补了空间音频领域综述的空白，为未来研究提供了参考和资源支持。

Abstract: With the rapid development of spatial audio technologies today, applications
in AR, VR, and other scenarios have garnered extensive attention. Unlike
traditional mono sound, spatial audio offers a more realistic and immersive
auditory experience. Despite notable progress in the field, there remains a
lack of comprehensive surveys that systematically organize and analyze these
methods and their underlying technologies. In this paper, we provide a
comprehensive overview of spatial audio and systematically review recent
literature in the area. To address this, we chronologically outlining existing
work related to spatial audio and categorize these studies based on
input-output representations, as well as generation and understanding tasks,
thereby summarizing various research aspects of spatial audio. In addition, we
review related datasets, evaluation metrics, and benchmarks, offering insights
from both training and evaluation perspectives. Related materials are available
at https://github.com/dieKarotte/ASAudio.

</details>


### [15] [CleanCTG: A Deep Learning Model for Multi-Artefact Detection and Reconstruction in Cardiotocography](https://arxiv.org/abs/2508.10928)
*Sheng Wong,Beth Albert,Gabriel Davis Jones*

Main category: eess.AS

TL;DR: CleanCTG是一种双阶段模型，通过多尺度卷积和上下文感知交叉注意力识别多种伪影类型，并通过特定伪影校正分支重建信号，显著提升胎儿心率监测的准确性。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法通常忽略全面的噪声处理，传统方法仅能处理简单问题，无法应对复杂伪影。CleanCTG旨在解决这一问题。

Method: 采用双阶段模型：第一阶段通过多尺度卷积和交叉注意力识别伪影；第二阶段通过特定校正分支重建信号。训练数据为合成的专家验证数据。

Result: 在合成数据上，CleanCTG完美检测伪影（AU-ROC=1.00），MSE显著降低；临床验证中AU-ROC=0.95，决策时间缩短33%。

Conclusion: CleanCTG通过显式伪影去除和信号重建，提高了诊断准确性并缩短监测时间，为可靠CTG解读提供了实用方案。

Abstract: Cardiotocography (CTG) is essential for fetal monitoring but is frequently
compromised by diverse artefacts which obscure true fetal heart rate (FHR)
patterns and can lead to misdiagnosis or delayed intervention. Current
deep-learning approaches typically bypass comprehensive noise handling,
applying minimal preprocessing or focusing solely on downstream classification,
while traditional methods rely on simple interpolation or rule-based filtering
that addresses only missing samples and fail to correct complex artefact types.
We present CleanCTG, an end-to-end dual-stage model that first identifies
multiple artefact types via multi-scale convolution and context-aware
cross-attention, then reconstructs corrupted segments through artefact-specific
correction branches. Training utilised over 800,000 minutes of physiologically
realistic, synthetically corrupted CTGs derived from expert-verified "clean"
recordings. On synthetic data, CleanCTG achieved perfect artefact detection
(AU-ROC = 1.00) and reduced mean squared error (MSE) on corrupted segments to
2.74 x 10^-4 (clean-segment MSE = 2.40 x 10^-6), outperforming the next best
method by more than 60%. External validation on 10,190 minutes of
clinician-annotated segments yielded AU-ROC = 0.95 (sensitivity = 83.44%,
specificity 94.22%), surpassing six comparator classifiers. Finally, when
integrated with the Dawes-Redman system on 933 clinical CTG recordings,
denoised traces increased specificity (from 80.70% to 82.70%) and shortened
median time to decision by 33%. These findings suggest that explicit artefact
removal and signal reconstruction can both maintain diagnostic accuracy and
enable shorter monitoring sessions, offering a practical route to more reliable
CTG interpretation.

</details>


### [16] [Expressive Speech Retrieval using Natural Language Descriptions of Speaking Style](https://arxiv.org/abs/2508.11187)
*Wonjune Kang,Deb Roy*

Main category: eess.AS

TL;DR: 提出了一种基于说话风格的自然语言描述检索语音的任务，通过联合潜在空间嵌入语音和文本描述，实现了高效的跨模态检索。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注语音内容检索，而本文旨在通过说话风格进行检索，填补了这一空白。

Method: 训练语音和文本编码器，将语音和风格描述嵌入联合潜在空间，支持自由文本查询。

Result: 在包含22种说话风格的多数据集上，Recall@k指标表现优异。

Conclusion: 该方法在基于说话风格的语音检索任务中表现出色，具有实际应用潜力。

Abstract: We introduce the task of expressive speech retrieval, where the goal is to
retrieve speech utterances spoken in a given style based on a natural language
description of that style. While prior work has primarily focused on performing
speech retrieval based on what was said in an utterance, we aim to do so based
on how something was said. We train speech and text encoders to embed speech
and text descriptions of speaking styles into a joint latent space, which
enables using free-form text prompts describing emotions or styles as queries
to retrieve matching expressive speech segments. We perform detailed analyses
of various aspects of our proposed framework, including encoder architectures,
training criteria for effective cross-modal alignment, and prompt augmentation
for improved generalization to arbitrary text queries. Experiments on multiple
datasets encompassing 22 speaking styles demonstrate that our approach achieves
strong retrieval performance as measured by Recall@k.

</details>


### [17] [EmoSSLSphere: Multilingual Emotional Speech Synthesis with Spherical Vectors and Discrete Speech Tokens](https://arxiv.org/abs/2508.11273)
*Joonyong Park,Kenichi Nakamura*

Main category: eess.AS

TL;DR: EmoSSLSphere是一种结合球形情感向量与自监督学习（SSL）离散标记特征的多语言情感文本到语音（TTS）合成框架，实现了细粒度情感控制、跨语言情感传递和说话人身份保留。


<details>
  <summary>Details</summary>
Motivation: 解决多语言情感TTS中情感控制的精细化和跨语言传递问题，同时保持说话人身份。

Method: 使用球形坐标空间编码情感，结合SSL的语义和声学建模。

Result: 在英语和日语语料上显著提升了语音清晰度、频谱保真度、韵律一致性和合成质量。主观评估显示自然度和情感表达优于基线模型。

Conclusion: EmoSSLSphere是一种可扩展的多语言情感TTS解决方案。

Abstract: This paper introduces EmoSSLSphere, a novel framework for multilingual
emotional text-to-speech (TTS) synthesis that combines spherical emotion
vectors with discrete token features derived from self-supervised learning
(SSL). By encoding emotions in a continuous spherical coordinate space and
leveraging SSL-based representations for semantic and acoustic modeling,
EmoSSLSphere enables fine-grained emotional control, effective cross-lingual
emotion transfer, and robust preservation of speaker identity. We evaluate
EmoSSLSphere on English and Japanese corpora, demonstrating significant
improvements in speech intelligibility, spectral fidelity, prosodic
consistency, and overall synthesis quality. Subjective evaluations further
confirm that our method outperforms baseline models in terms of naturalness and
emotional expressiveness, underscoring its potential as a scalable solution for
multilingual emotional TTS.

</details>


### [18] [MoE-TTS: Enhancing Out-of-Domain Text Understanding for Description-based TTS via Mixture-of-Experts](https://arxiv.org/abs/2508.11326)
*Heyang Xue,Xuchen Song,Yu Tang,Jianyu Chen,Yanru Chen,Yang Li,Yahui Zhou*

Main category: eess.AS

TL;DR: MoE-TTS是一种基于描述的文本到语音模型，通过混合专家（MoE）方法增强预训练大型语言模型（LLM）对域外文本的理解能力，表现优于现有商业产品。


<details>
  <summary>Details</summary>
Motivation: 解决现有TTS模型在域外文本描述上的理解能力不足问题。

Method: 采用模态混合专家（MoE）方法，在保持预训练LLM冻结的同时，为其添加适应语音模态的专用权重。

Result: 实验表明，MoE-TTS在域外描述测试集上表现优于现有商业产品，生成的语音更准确反映描述。

Conclusion: MoE-TTS通过结合预训练LLM和MoE方法，显著提升了TTS系统对域外文本的理解能力。

Abstract: Description-based text-to-speech (TTS) models exhibit strong performance on
in-domain text descriptions, i.e., those encountered during training. However,
in real-world applications, the diverse range of user-generated descriptions
inevitably introduces numerous out-of-domain inputs that challenge the text
understanding capabilities of these systems. To address this issue, we propose
MoE-TTS, a description-based TTS model designed to enhance the understanding of
out-of-domain text descriptions. MoE-TTS employs a modality-based
mixture-of-experts (MoE) approach to augment a pre-trained textual large
language model (LLM) with a set of specialized weights adapted to the speech
modality while maintaining the original LLM frozen during training. This
approach allows MoE-TTS to effectively leverage the pre-trained knowledge and
text understanding abilities of textual LLMs. Our experimental results indicate
that: first, even the most advanced closed-source commercial products can be
challenged by carefully designed out-of-domain description test sets; second,
MoE-TTS achieves superior performance in generating speech that more accurately
reflects the descriptions. We encourage readers to listen to the demos at
https://welkinyang.github.io/MoE-TTS/.

</details>


### [19] [Enhancing In-the-Wild Speech Emotion Conversion with Resynthesis-based Duration Modeling](https://arxiv.org/abs/2508.11535)
*Navin Raj Prabhu,Danilo de Oliveira,Nale Lehmann-Willenbrock,Timo Gerkmann*

Main category: eess.AS

TL;DR: 论文提出了一种基于重合成的离散内容表示的时长建模框架，用于语音情感转换，以控制语音时长和速率，增强情感表达。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在修改局部声学特性（如基频、频谱包络和能量）方面表现良好，但缺乏对声音时长的控制能力。

Method: 采用基于重合成的离散内容表示方法，通过时长建模框架修改语音时长，反映目标情感，实现可控的语音速率。

Result: 实验表明，该框架显著提升了情感表达，尤其在MSP-Podcast数据集中，低唤醒情感与较长时长和较慢语速相关，高唤醒情感则相反。

Conclusion: 提出的时长建模框架有效解决了语音情感转换中的时长控制问题，提升了情感表达的准确性。

Abstract: Speech Emotion Conversion aims to modify the emotion expressed in input
speech while preserving lexical content and speaker identity. Recently,
generative modeling approaches have shown promising results in changing local
acoustic properties such as fundamental frequency, spectral envelope and
energy, but often lack the ability to control the duration of sounds. To
address this, we propose a duration modeling framework using resynthesis-based
discrete content representations, enabling modification of speech duration to
reflect target emotions and achieve controllable speech rates without using
parallel data. Experimental results reveal that the inclusion of the proposed
duration modeling framework significantly enhances emotional expressiveness, in
the in-the-wild MSP-Podcast dataset. Analyses show that low-arousal emotions
correlate with longer durations and slower speech rates, while high-arousal
emotions produce shorter, faster speech.

</details>


### [20] [Emphasis Sensitivity in Speech Representations](https://arxiv.org/abs/2508.11566)
*Shaun Cassini,Thomas Hain,Anton Ragni*

Main category: eess.AS

TL;DR: 研究现代语音模型是否对韵律重音敏感，提出基于残差的框架分析重音编码方式。


<details>
  <summary>Details</summary>
Motivation: 探讨语音模型如何系统性地编码重音与非重音词汇，弥补现有方法忽略重音关系结构的不足。

Method: 提出残差框架，通过对比中性词与重音词的表示差异定义重音，分析自监督和ASR微调模型。

Result: 残差与时长变化强相关，且在词身份预测中表现差；ASR微调模型的残差空间更紧凑。

Conclusion: 重音以结构化、低维变换方式编码，任务特定学习使其更结构化。

Abstract: This work investigates whether modern speech models are sensitive to prosodic
emphasis - whether they encode emphasized and neutral words in systematically
different ways. Prior work typically relies on isolated acoustic correlates
(e.g., pitch, duration) or label prediction, both of which miss the relational
structure of emphasis. This paper proposes a residual-based framework, defining
emphasis as the difference between paired neutral and emphasized word
representations. Analysis on self-supervised speech models shows that these
residuals correlate strongly with duration changes and perform poorly at word
identity prediction, indicating a structured, relational encoding of prosodic
emphasis. In ASR fine-tuned models, residuals occupy a subspace up to 50% more
compact than in pre-trained models, further suggesting that emphasis is encoded
as a consistent, low-dimensional transformation that becomes more structured
with task-specific learning.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [21] [Perturbed Public Voices (P$^{2}$V): A Dataset for Robust Audio Deepfake Detection](https://arxiv.org/abs/2508.10949)
*Chongyang Gao,Marco Postiglione,Isabel Gortner,Sarit Kraus,V. S. Subrahmanian*

Main category: cs.SD

TL;DR: P$^{2}$V数据集揭示了当前音频深度伪造检测器的脆弱性，并提出了一个更鲁棒的检测基准。


<details>
  <summary>Details</summary>
Motivation: 当前音频深度伪造检测器在真实世界中表现不佳，无法应对恶意伪造的挑战。

Method: 引入P$^{2}$V数据集，包含身份一致文本、环境噪声和先进语音克隆技术。

Result: 现有检测器在P$^{2}$V上性能下降43%，对抗扰动和克隆技术进一步降低检测能力。

Conclusion: P$^{2}$V为鲁棒音频深度伪造检测设立了新基准，并将在未来公开。

Abstract: Current audio deepfake detectors cannot be trusted. While they excel on
controlled benchmarks, they fail when tested in the real world. We introduce
Perturbed Public Voices (P$^{2}$V), an IRB-approved dataset capturing three
critical aspects of malicious deepfakes: (1) identity-consistent transcripts
via LLMs, (2) environmental and adversarial noise, and (3) state-of-the-art
voice cloning (2020-2025). Experiments reveal alarming vulnerabilities of 22
recent audio deepfake detectors: models trained on current datasets lose 43%
performance when tested on P$^{2}$V, with performance measured as the mean of
F1 score on deepfake audio, AUC, and 1-EER. Simple adversarial perturbations
induce up to 16% performance degradation, while advanced cloning techniques
reduce detectability by 20-30%. In contrast, P$^{2}$V-trained models maintain
robustness against these attacks while generalizing to existing datasets,
establishing a new benchmark for robust audio deepfake detection. P$^{2}$V will
be publicly released upon acceptance by a conference/journal.

</details>


### [22] [LD-LAudio-V1: Video-to-Long-Form-Audio Generation Extension with Dual Lightweight Adapters](https://arxiv.org/abs/2508.11074)
*Haomin Zhang,Kristin Qi,Shuxin Yang,Zihao Chen,Chaofan Ding,Xinhan Di*

Main category: cs.SD

TL;DR: 论文提出LD-LAudio-V1模型，通过双轻量适配器实现长视频音频生成，并发布高质量数据集，显著减少拼接伪影和时间不一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法多针对短视频音频生成或依赖噪声数据集，无法满足长视频高质量音频需求。

Method: 扩展现有视频到音频模型，引入双轻量适配器，并发布干净标注数据集。

Result: 模型在多项指标上显著提升，如FD_passt降低27.27%，KL_panns降低16.87%。

Conclusion: LD-Laudio-V1有效解决长视频音频生成问题，数据集推动进一步研究。

Abstract: Generating high-quality and temporally synchronized audio from video content
is essential for video editing and post-production tasks, enabling the creation
of semantically aligned audio for silent videos. However, most existing
approaches focus on short-form audio generation for video segments under 10
seconds or rely on noisy datasets for long-form video-to-audio zsynthesis. To
address these limitations, we introduce LD-LAudio-V1, an extension of
state-of-the-art video-to-audio models and it incorporates dual lightweight
adapters to enable long-form audio generation. In addition, we release a clean
and human-annotated video-to-audio dataset that contains pure sound effects
without noise or artifacts. Our method significantly reduces splicing artifacts
and temporal inconsistencies while maintaining computational efficiency.
Compared to direct fine-tuning with short training videos, LD-LAudio-V1
achieves significant improvements across multiple metrics: $FD_{\text{passt}}$
450.00 $\rightarrow$ 327.29 (+27.27%), $FD_{\text{panns}}$ 34.88 $\rightarrow$
22.68 (+34.98%), $FD_{\text{vgg}}$ 3.75 $\rightarrow$ 1.28 (+65.87%),
$KL_{\text{panns}}$ 2.49 $\rightarrow$ 2.07 (+16.87%), $KL_{\text{passt}}$ 1.78
$\rightarrow$ 1.53 (+14.04%), $IS_{\text{panns}}$ 4.17 $\rightarrow$ 4.30
(+3.12%), $IB_{\text{score}}$ 0.25 $\rightarrow$ 0.28 (+12.00%),
$Energy\Delta10\text{ms}$ 0.3013 $\rightarrow$ 0.1349 (+55.23%),
$Energy\Delta10\text{ms(vs.GT)}$ 0.0531 $\rightarrow$ 0.0288 (+45.76%), and
$Sem.\,Rel.$ 2.73 $\rightarrow$ 3.28 (+20.15%). Our dataset aims to facilitate
further research in long-form video-to-audio generation and is available at
https://github.com/deepreasonings/long-form-video2audio.

</details>


### [23] [Benchmarking Prosody Encoding in Discrete Speech Tokens](https://arxiv.org/abs/2508.11224)
*Kentaro Onda,Satoru Fukayama,Daisuke Saito,Nobuaki Minematsu*

Main category: cs.SD

TL;DR: 研究分析了自监督学习离散令牌在语音语言模型中捕捉韵律信息的能力，并提出设计离散令牌的实用指南。


<details>
  <summary>Details</summary>
Motivation: 离散令牌通常与语言模型或下游任务分开学习，导致离散化选择（如SSL模型或聚类数量）需启发式决定，且缺乏对韵律信息捕捉能力的研究。

Method: 通过分析离散令牌对人工修改韵律的敏感性，综合评估其韵律编码能力。

Result: 研究揭示了离散令牌在捕捉韵律信息方面的表现。

Conclusion: 研究为设计离散令牌提供了实用指南，填补了韵律信息捕捉研究的空白。

Abstract: Recently, discrete tokens derived from self-supervised learning (SSL) models
via k-means clustering have been actively studied as pseudo-text in speech
language models and as efficient intermediate representations for various
tasks. However, these discrete tokens are typically learned in advance,
separately from the training of language models or downstream tasks. As a
result, choices related to discretization, such as the SSL model used or the
number of clusters, must be made heuristically. In particular, speech language
models are expected to understand and generate responses that reflect not only
the semantic content but also prosodic features. Yet, there has been limited
research on the ability of discrete tokens to capture prosodic information. To
address this gap, this study conducts a comprehensive analysis focusing on
prosodic encoding based on their sensitivity to the artificially modified
prosody, aiming to provide practical guidelines for designing discrete tokens.

</details>


### [24] [Mitigating Category Imbalance: Fosafer System for the Multimodal Emotion and Intent Joint Understanding Challenge](https://arxiv.org/abs/2508.11362)
*Honghong Wang,Yankai Wang,Dejun Zhang,Jing Deng,Rong Zheng*

Main category: cs.SD

TL;DR: Fosafer方法通过多模态数据增强、样本加权焦点对比损失和模态丢弃策略，解决了普通话情感与意图联合识别中的类别不平衡问题，并在挑战赛中取得第二名的成绩。


<details>
  <summary>Details</summary>
Motivation: 解决普通话情感与意图联合识别中的类别不平衡问题，并提升对少数类别样本和语义相似样本的识别能力。

Method: 采用多模态数据增强技术、样本加权焦点对比损失、Hubert模型微调、模态丢弃策略和多数投票法进行预测。

Result: 在Track 2 Mandarin挑战赛中取得第二名的成绩。

Conclusion: Fosafer方法在多模态情感与意图联合识别中表现优异，尤其擅长处理类别不平衡问题。

Abstract: This paper presents Fosafer approach to the Track 2 Mandarin in the
Multimodal Emotion and Intent Joint Understandingchallenge, which focuses on
achieving joint recognition of emotion and intent in Mandarin, despite the
issue of category imbalance. To alleviate this issue, we use a variety of data
augmentation techniques across text, video, and audio modalities. Additionally,
we introduce the SampleWeighted Focal Contrastive loss, designed to address the
challenges of recognizing minority class samples and those that are
semantically similar but difficult to distinguish. Moreover, we fine-tune the
Hubert model to adapt the emotion and intent joint recognition. To mitigate
modal competition, we introduce a modal dropout strategy. For the final
predictions, a plurality voting approach is used to determine the results. The
experimental results demonstrate the effectiveness of our method, which
achieves the second-best performance in the Track 2 Mandarin challenge.

</details>


### [25] [Speech Emotion Recognition Using Fine-Tuned DWFormer:A Study on Track 1 of the IERPChallenge 2024](https://arxiv.org/abs/2508.11371)
*Honghong Wang,Xupeng Jia,Jing Deng,Rong Zheng*

Main category: cs.SD

TL;DR: 本文介绍了Fosafer团队在IERP Challenge 2024 Track 1中的工作，通过结合数据增强和分数融合策略，优化了预训练的语音情感识别模型DWFormer，取得了第一名的成绩。


<details>
  <summary>Details</summary>
Motivation: 现有情感识别模型多关注离散情感标签的预测精度，而忽略了人格特质对情感表达的影响。IERP Challenge 2024将人格特质纳入研究，以探索个体差异对情感识别的影响。

Method: 团队在Track 1中仅使用音频特征，通过数据增强和分数融合策略对预训练的语音情感识别模型DWFormer进行微调。

Result: 该方法在比赛中取得了第一名的成绩。

Conclusion: 结合人格特质和音频特征的情感识别方法具有潜力，数据增强和分数融合策略能有效提升模型性能。

Abstract: The field of artificial intelligence has a strong interest in the topic of
emotion recognition. The majority of extant emotion recognition models are
oriented towards enhancing the precision of discrete emotion label prediction.
Given the direct relationship between human personality and emotion, as well as
the significant inter-individual differences in subjective emotional
expression, the IERP Challenge 2024 incorporates personality traits into
emotion recognition research. This paper presents the Fosafer submissions to
the Track 1 of the IERP Challenge 2024. This task primarily concerns the
recognition of emotions in audio, while also providing text and audio features.
In Track 1, we utilized exclusively audio-based features and fine-tuned a
pre-trained speech emotion recognition model, DWFormer, through the integration
of data augmentation and score fusion strategies, thereby achieving the first
place among the participating teams.

</details>


### [26] [Pretrained Conformers for Audio Fingerprinting and Retrieval](https://arxiv.org/abs/2508.11609)
*Kemal Altwlkany,Elmedin Selmanovic,Sead Delalic*

Main category: cs.SD

TL;DR: 论文提出了一种基于自监督对比学习的Conformer编码器，用于生成音频片段的独特嵌入，在音频检索任务中取得了最优结果。


<details>
  <summary>Details</summary>
Motivation: 利用Conformer捕捉局部和全局交互的能力，结合自监督对比学习，提升音频嵌入的泛化性和鲁棒性。

Method: 采用自监督对比学习框架训练Conformer编码器，生成短音频片段的嵌入。

Result: 在音频检索任务中达到最优性能，仅需3秒音频生成嵌入，对时间错位和音频失真（如噪声、混响）具有强鲁棒性。

Conclusion: 该方法在音频处理中表现出色，代码和模型公开，结果易于复现。

Abstract: Conformers have shown great results in speech processing due to their ability
to capture both local and global interactions. In this work, we utilize a
self-supervised contrastive learning framework to train conformer-based
encoders that are capable of generating unique embeddings for small segments of
audio, generalizing well to previously unseen data. We achieve state-of-the-art
results for audio retrieval tasks while using only 3 seconds of audio to
generate embeddings. Our models are almost completely immune to temporal
misalignments and achieve state-of-the-art results in cases of other audio
distortions such as noise, reverb or extreme temporal stretching. Code and
models are made publicly available and the results are easy to reproduce as we
train and test using popular and freely available datasets of different sizes.

</details>

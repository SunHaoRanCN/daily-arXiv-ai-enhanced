<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 44]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.SD](#cs.SD) [Total: 11]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Vibe2Spike: Batteryless Wireless Tags for Vibration Sensing with Event Cameras and Spiking Networks](https://arxiv.org/abs/2508.11640)
*Danny Scott,William LaForest,Hritom Das,Ioannis Polykretis,Catherine D. Schuman,Charles Rizzo,James Plank,Sai Swaminathan*

Main category: eess.SP

TL;DR: Vibe2Spike是一个无电池无线传感框架，利用可见光通信和脉冲神经网络实现振动活动识别，通过压电盘收集振动能量并发射光脉冲，使用事件相机捕获并由优化SNN分类，达到94.9%的平均分类准确率。


<details>
  <summary>Details</summary>
Motivation: 现有传感解决方案在电池维护、无线传输开销和数据处理复杂性方面存在能量、可扩展性和可靠性之间的权衡问题，需要开发更节能、可扩展的传感方案。

Method: 使用仅由压电盘、齐纳二极管和LED组成的超低成本标签，采集振动能量并发射稀疏可见光脉冲；通过事件相机捕获光脉冲，使用EONS框架优化的脉冲神经网络模型进行分类。

Result: 在五类设备上评估，达到94.9%的平均分类适应度，分析了不同时间分箱策略的延迟-准确性权衡。

Conclusion: Vibe2Spike展示了一种可扩展、高能效的无电池方式实现智能环境的方法。

Abstract: The deployment of dense, low-cost sensors is critical for realizing
ubiquitous smart environments. However, existing sensing solutions struggle
with the energy, scalability, and reliability trade-offs imposed by battery
maintenance, wireless transmission overhead, and data processing complexity. In
this work, we present Vibe2Spike, a novel battery-free, wireless sensing
framework that enables vibration-based activity recognition using visible light
communication (VLC) and spiking neural networks (SNNs). Our system uses
ultra-low-cost tags composed only of a piezoelectric disc, a Zener diode, and
an LED, which harvest vibration energy and emit sparse visible light spikes
without requiring batteries or RF radios. These optical spikes are captured by
event cameras and classified using optimized SNN models evolved via the EONS
framework. We evaluate Vibe2Spike across five device classes, achieving 94.9\%
average classification fitness while analyzing the latency-accuracy trade-offs
of different temporal binning strategies. Vibe2Spike demonstrates a scalable,
and energy-efficient approach for enabling intelligent environments in a
batteryless manner.

</details>


### [2] [Data-driven RF Tomography via Cross-modal Sensing and Continual Learning](https://arxiv.org/abs/2508.11654)
*Yang Zhao,Tao Wang,Said Elhadi*

Main category: eess.SP

TL;DR: 基于深度神经网络的数据驱动无线电频成像框架，通过跨模态学习和持续学习技术，在动态环境中实现了高精度的地下植根块获取图像重建


<details>
  <summary>Details</summary>
Motivation: 虽然数据驱动的无线电频成像在地下目标检测方面展现了强大潜力，但在动态环境中实现准确和稳健的性能仍然面临挑战

Method: 设计了无线电频和视觉传感器的跨模态感知系统，采用跨模态学习方法训练RF成像深度神经网络模型，并在环境变化时通过持续学习自动更新模型

Result: 实验结果显示，该方法平均相当直径误差为2.29cm，较现有最优方法提升23.2%的性能收益

Conclusion: 提出的DRIFT框架能够在无线电频信号发生显著变化的情况下，仍然实现了地下植根块根截面图像的准确重建，为动态环境中的地下目标检测提供了有效解决方案

Abstract: Data-driven radio frequency (RF) tomography has demonstrated significant
potential for underground target detection, due to the penetrative nature of RF
signals through soil. However, it is still challenging to achieve accurate and
robust performance in dynamic environments. In this work, we propose a
data-driven radio frequency tomography (DRIFT) framework with the following key
components to reconstruct cross section images of underground root tubers, even
with significant changes in RF signals. First, we design a cross-modal sensing
system with RF and visual sensors, and propose to train an RF tomography deep
neural network (DNN) model following the cross-modal learning approach. Then we
propose to apply continual learning to automatically update the DNN model, once
environment changes are detected in a dynamic environment. Experimental results
show that our approach achieves an average equivalent diameter error of 2.29
cm, 23.2% improvement upon the state-of-the-art approach. Our DRIFT code and
dataset are publicly available on https://github.com/Data-driven-RTI/DRIFT.

</details>


### [3] [Inductive transfer learning from regression to classification in ECG analysis](https://arxiv.org/abs/2508.11656)
*Ridma Jayasundara,Ishan Fernando,Adeepa Fernando,Roshan Ragel,Vajira Thambawita,Isuru Nawinne*

Main category: eess.SP

TL;DR: 这篇论文探索了从回归到分类的转移学习在心电图深度学习中的应用，利用合成心电图数据训练模型并在真实数据上进行评估，结果显示这种方法能够提高分类性能。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是全球首要死因，时早诊断至关重要。心电图是关键诊断工具，但病人数据隐私问题促使研究者寻找合成数据方案。本研究旨在探索如何最大化利用合成数据来提升深度学习模型的性能。

Method: 使用流行的深度学习模型进行四个关键心脏参数的回归预测（心率、PR间期、QT间期、QRS复合波），然后利用这些回归模型进行转移学习，完成5类心电图信号分类任务。实验系统性地验证了从回归到分类的转移学习的可行性。

Result: 研究结果显示，从回归到分类的转移学习能够提高分类性能。这种方法有助于更好地利用各种开放访问和合成心电图数据集。

Conclusion: 转移学习技术在心电图深度学习应用中具有重要潜力，能够最大化数据利用效率并推动该领域的研究进展。

Abstract: Cardiovascular diseases (CVDs) are the leading cause of mortality worldwide,
accounting for over 30% of global deaths according to the World Health
Organization (WHO). Importantly, one-third of these deaths are preventable with
timely and accurate diagnosis. The electrocardiogram (ECG), a non-invasive
method for recording the electrical activity of the heart, is crucial for
diagnosing CVDs. However, privacy concerns surrounding the use of patient ECG
data in research have spurred interest in synthetic data, which preserves the
statistical properties of real data without compromising patient
confidentiality. This study explores the potential of synthetic ECG data for
training deep learning models from regression to classification tasks and
evaluates the feasibility of transfer learning to enhance classification
performance on real ECG data. We experimented with popular deep learning models
to predict four key cardiac parameters, namely, Heart Rate (HR), PR interval,
QT interval, and QRS complex-using separate regression models. Subsequently, we
leveraged these regression models for transfer learning to perform 5-class ECG
signal classification. Our experiments systematically investigate whether
transfer learning from regression to classification is viable, enabling better
utilization of diverse open-access and synthetic ECG datasets. Our findings
demonstrate that transfer learning from regression to classification improves
classification performance, highlighting its potential to maximize the utility
of available data and advance deep learning applications in this domain.

</details>


### [4] [Robust Sparse Bayesian Learning Based on Minimum Error Entropy for Noisy High-Dimensional Brain Activity Decoding](https://arxiv.org/abs/2508.11657)
*Yuanhao Li,Badong Chen,Wenjun Bai,Yasuharu Koike,Okito Yamashita*

Main category: eess.SP

TL;DR: 提出基于最小误差熵(MEE)的稀疏贝叶斯学习框架，用于处理高维脑信号解码中的噪声问题，在回归和分类任务中均优于传统方法


<details>
  <summary>Details</summary>
Motivation: 传统基于高斯和二项分布的稀疏贝叶斯学习假设在处理脑信号噪声时可能不足，需要更鲁棒的方法来处理复杂数据分布

Method: 利用最小误差熵(MEE)准则的鲁棒性，提出基于MEE的似然函数，改进稀疏贝叶斯学习在噪声脑数据集中的准确推断

Result: 在两个高维脑解码任务（回归和分类）中，该方法在解码指标和生理模式方面均优于传统方法和最先进方法

Conclusion: 基于MEE的似然模型使稀疏贝叶斯学习能够同时解决脑解码任务中的噪声和高维挑战，为脑机接口等生物医学工程应用提供了强大工具

Abstract: Objective: Sparse Bayesian learning provides an effective scheme to solve the
high-dimensional problem in brain signal decoding. However, traditional
assumptions regarding data distributions such as Gaussian and binomial are
potentially inadequate to characterize the noisy signals of brain activity.
Hence, this study aims to propose a robust sparse Bayesian learning framework
to address noisy highdimensional brain activity decoding. Methods: Motivated by
the commendable robustness of the minimum error entropy (MEE) criterion for
handling complex data distributions, we proposed an MEE-based likelihood
function to facilitate the accurate inference of sparse Bayesian learning in
analyzing noisy brain datasets. Results: Our proposed approach was evaluated
using two high-dimensional brain decoding tasks in regression and
classification contexts, respectively. The experimental results showed that,
our approach can realize superior decoding metrics and physiological patterns
than the conventional and state-of-the-art methods. Conclusion: Utilizing the
proposed MEE-based likelihood model, sparse Bayesian learning is empowered to
simultaneously address the challenges of noise and high dimensionality in the
brain decoding task. Significance: This work provides a powerful tool to
realize robust brain decoding, advancing biomedical engineering applications
such as brain-computer interface.

</details>


### [5] [CECGSR: Circular ECG Super-Resolution](https://arxiv.org/abs/2508.11658)
*Honggui Li,Zhengyang Zhang,Dingtai Li,Sinan Chen,Nahid Md Lokman Hossain,Xinfeng Xu,Yuting Feng,Hantao Lu,Yinlu Qin,Ruobing Wang,Maria Trocan,Dimitri Galayko,Amara Amara,Mohamad Sawan*

Main category: eess.SP

TL;DR: 闭环循环心电图超分辨方法CECGSR，通过建模退化过程和负反馈机制，在PTB-XL数据集上超越现有开环方法的重建性能。


<details>
  <summary>Details</summary>
Motivation: 传统心电图超分辨方法采用开环架构，而根据自动控制理论，闭环框架具有更优的动态和静态性能。

Method: 提出CECGSR闭环方法，建模从高分辨率到低分辨率心电图的退化过程，通过低分辨率信号差异实现负反馈机制，并使用泰勒级数展开证明稳态误差近零。采用Plug-and-Play策略构建超分辨单元。

Result: 在PTB-XL数据集的无噪声和有噪声子集上进行模拟实验，结果显示CECGSR在心电图信号重建性能方面超过了最先进的开环ECGSR算法。

Conclusion: 闭环CECGSR方法通过循环架构和负反馈机制，显著提升了心电图超分辨的性能，为心电图信号处理提供了更有效的解决方案。

Abstract: The electrocardiogram (ECG) plays a crucial role in the diagnosis and
treatment of various cardiac diseases. ECG signals suffer from low-resolution
(LR) due to the use of convenient acquisition devices, as well as internal and
external noises and artifacts. Classical ECG super-resolution (ECGSR) methods
adopt an open-loop architecture that converts LR ECG signals to
super-resolution (SR) ones. According to the theory of automatic control, a
closed-loop framework exhibits superior dynamic and static performance compared
with its open-loop counterpart. This paper proposes a closed-loop approach,
termed circular ECGSR (CECGSR), which models the degradation process from SR
ECG signals to LR ones. The negative feedback mechanism of the closed-loop
system is based on the differences between the LR ECG signals. A mathematical
loop equation is constructed to characterize the closed-loop infrastructure.
The Taylor series expansion is employed to demonstrate the near-zero
steady-state error of the proposed method. A Plug-and-Play strategy is
considered to establish the SR unit of the proposed architecture, leveraging
any existing advanced open-loop ECGSR methods. Simulation experiments on both
noiseless and noisy subsets of the PTB-XL datasets demonstrate that the
proposed CECGSR outperforms state-of-the-art open-loop ECGSR algorithms in the
reconstruction performance of ECG signals.

</details>


### [6] [Unsupervised Pairwise Learning Optimization Framework for Cross-Corpus EEG-Based Emotion Recognition Based on Prototype Representation](https://arxiv.org/abs/2508.11663)
*Guangli Li,Canbiao Wu,Zhen Liang*

Main category: eess.SP

TL;DR: 提出基于领域对抗迁移学习的McdPL框架，通过双对抗分类器和三阶段对抗训练解决跨语料库情感识别中的决策边界样本对齐问题，在多个公开数据集上取得显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 由于被试生理差异、实验环境和设备变化，跨语料库情感识别面临严重挑战，特别是决策边界附近的样本难以准确分类。

Method: 提出McdPL框架，包含双对抗分类器（Ada和RMS分类器），采用三阶段对抗训练最大化分类差异并最小化特征分布差异，同时引入成对学习将分类问题转化为样本相似性问题。

Result: 在SEED、SEED-IV和SEED-V数据集上的实验表明，McdPL模型优于其他基线模型，平均准确率分别提升4.76%和3.97%。

Conclusion: McdPL框架为跨语料库情感识别提供了有效的解决方案，通过精细的特征对齐和对抗训练机制显著提升了跨域情感识别性能。

Abstract: Affective computing is a rapidly developing interdisciplinary research
direction in the field of brain-computer interface. In recent years, the
introduction of deep learning technology has greatly promoted the development
of the field of emotion recognition. However, due to physiological differences
between subjects, as well as the variations in experimental environments and
equipment, cross-corpus emotion recognition faces serious challenges,
especially for samples near the decision boundary. To solve the above problems,
we propose an optimization method based on domain adversarial transfer learning
to fine-grained alignment of affective features, named Maximum classifier
discrepancy with Pairwise Learning (McdPL) framework. In McdPL, we design a
dual adversarial classifier (Ada classifier and RMS classifier), and apply a
three-stage adversarial training to maximize classification discrepancy and
minimize feature distribution to align controversy samples near the decision
boundary. In the process of domain adversarial training, the two classifiers
also maintain an adversarial relationship, ultimately enabling precise
cross-corpus feature alignment. In addition, the introduction of pairwise
learning transforms the classification problem of samples into a similarity
problem between samples, alleviating the influence of label noise. We conducted
systematic experimental evaluation of the model using publicly available SEED,
SEED-IV and SEED-V databases. The results show that the McdPL model is superior
to other baseline models in the cross-corpus emotion recognition task, and the
average accuracy improvements of 4.76\% and 3.97\%, respectively. Our work
provides a promising solution for emotion recognition cross-corpus. The source
code is available at https://github.com/WuCB-BCI/Mcd_PL.

</details>


### [7] [Energy-Efficient Real-Time 4-Stage Sleep Classification at 10-Second Resolution: A Comprehensive Study](https://arxiv.org/abs/2508.11664)
*Zahra Mohammadi,Parnian Fazel,Siamak Mohammadi*

Main category: eess.SP

TL;DR: 基于单导联电心图的能效睡眠分期分类系统，通过轻量级深度学习模型实现高准确度和低能耗，适合可穿戴式长期监测


<details>
  <summary>Details</summary>
Motivation: 传统多导联睡眠监测方法成本高且不方便家庭长期使用，需要开发从单导联电心图准确分析睡眠阶段的能效解决方案

Method: 提出两种窗口切分策略：5分钟窗口用于机器学习模型，30秒窗口用于深度学习模型。设计了轻量级自定义模型SleepLiteCNN，并应用8位量化技术

Result: MobileNet-v1模型达到92%准确率和91% F1分数，SleepLiteCNN模型在准确率89%、F1分数89%的情况下，每次推理能耗降至5.48微焦耳，FPGA部署证明资源占用低

Conclusion: 该系统为可穿戴电心图基础的连续睡眠监测提供了实用解决方案，在保持高准确性的同时实现了低能耗和实时性能

Abstract: Sleep stage classification is crucial for diagnosing and managing disorders
such as sleep apnea and insomnia. Conventional clinical methods like
polysomnography are costly and impractical for long-term home use. We present
an energy-efficient pipeline that detects four sleep stages (wake, REM, light,
and deep) from a single-lead ECG. Two windowing strategies are introduced: (1)
a 5-minute window with 30-second steps for machine-learning models that use
handcrafted features, and (2) a 30-second window with 10-second steps for
deep-learning models, enabling near-real-time 10-second resolution. Lightweight
networks such as MobileNet-v1 reach 92 percent accuracy and 91 percent F1-score
but still draw significant energy. We therefore design SleepLiteCNN, a custom
model that achieves 89 percent accuracy and 89 percent F1-score while lowering
energy use to 5.48 microjoules per inference at 45 nm. Applying eight-bit
quantization preserves accuracy and further reduces power, and FPGA deployment
confirms low resource usage. The proposed system offers a practical solution
for continuous, wearable ECG-based sleep monitoring.

</details>


### [8] [On the Extension of Differential Beamforming Theory to Arbitrary Planar Arrays of First-Order Elements](https://arxiv.org/abs/2508.12403)
*Federico Miotello,Davide Albertini,Alberto Bernardini*

Main category: eess.SP

TL;DR: 基于模态匹配框架的广义微分堵形技术，解决传感器方向性对广带威嵌塔数组性能的影响


<details>
  <summary>Details</summary>
Motivation: 传统微分堵形技术假设数组元件为全向性，而实际传感器具有频率相关的方向性，这会降低系统性能

Method: 提出一种广义的模态匹配框架，通过圆周调和展开表示期望的堵形图，并与实际元件响应进行拟合，支持任意平面布局和元件方向

Result: 模拟结果证明，在设计阶段考虑传感器方向性能够在不同频率、不同布局和噪声条件下获得准确而稳健的性能

Conclusion: 该方法为小型广带威声数组提供了一种灵活有效的方案，充分考虑了实际传感器的特性，实现了频率独立的空间响应

Abstract: Small-size acoustic arrays exploit spatial diversity to achieve capabilities
beyond those of single-element devices, with applications ranging from
teleconferencing to immersive multimedia. A key requirement for broadband array
processing is a frequency-invariant spatial response, which ensures consistent
directivity across wide bandwidths and prevents spectral coloration.
Differential beamforming offers an inherently frequency-invariant solution by
leveraging pressure differences between closely spaced elements of small-size
arrays. Traditional approaches, however, assume the array elements to be
omnidirectional, whereas real transducers exhibit frequency-dependent
directivity that can degrade performance if not properly modeled. To address
this limitation, we propose a generalized modal matching framework for
frequency-invariant differential beamforming, applicable to unconstrained
planar arrays of first-order directional elements. By representing the desired
beampattern as a truncated circular harmonic expansion and fitting it to the
actual element responses, our method accommodates arbitrary planar geometries
and element orientations. This approach enables the synthesis of beampatterns
of any order and steering direction without imposing rigid layout requirements.
Simulations confirm that accounting for sensor directivity at the design stage
yields accurate and robust performance across varying frequencies, geometries,
and noise conditions.

</details>


### [9] [Explainable Deep Neural Network for Multimodal ECG Signals: Intermediate vs Late Fusion](https://arxiv.org/abs/2508.11666)
*Timothy Oladunni,Ehimen Aneni*

Main category: eess.SP

TL;DR: 这篇论文研究了多模态深度神经网络在ECG心血管疾病分类中的融合策略，发现特征层融合比决策层融合效果更好，达到了97%的最高准确率。


<details>
  <summary>Details</summary>
Motivation: 单模态深度学习模型存在过拟合和沿用性局限的问题，而多模态融合策略在高风险临床应用中的最优方案仍不明确，特别是在ECG心血管疾病分类中。

Method: 采用时域、频域和时频域三种ECG信号域，对比研究中间融合（特征层）和后期融合（决策层）两种策略的效果，并通过显著性地图进行可解释性分析。

Result: 中间融合策略在所有实验中都表现更优，达到峰值准确率97%，相比单模态模型的Cohen's d > 0.8，相比后期融合的Cohen's d = 0.40。显著性地图分析确认了模型与ECG信号的一致性。

Conclusion: 该研究提出的基于ECG域的多模态模型具有更优异的预测能力和更好的可解释性，在医疗AI应用中具有重要价值，超越了现有的最先进模型。

Abstract: The limitations of unimodal deep learning models, particularly their tendency
to overfit and limited generalizability, have renewed interest in multimodal
fusion strategies. Multimodal deep neural networks (MDNN) have the capability
of integrating diverse data domains and offer a promising solution for robust
and accurate predictions. However, the optimal fusion strategy, intermediate
fusion (feature-level) versus late fusion (decision-level) remains
insufficiently examined, especially in high-stakes clinical contexts such as
ECG-based cardiovascular disease (CVD) classification. This study investigates
the comparative effectiveness of intermediate and late fusion strategies using
ECG signals across three domains: time, frequency, and time-frequency. A series
of experiments were conducted to identify the highest-performing fusion
architecture. Results demonstrate that intermediate fusion consistently
outperformed late fusion, achieving a peak accuracy of 97 percent, with Cohen's
d > 0.8 relative to standalone models and d = 0.40 compared to late fusion.
Interpretability analyses using saliency maps reveal that both models align
with the discretized ECG signals. Statistical dependency between the
discretized ECG signals and corresponding saliency maps for each class was
confirmed using Mutual Information (MI). The proposed ECG domain-based
multimodal model offers superior predictive capability and enhanced
explainability, crucial attributes in medical AI applications, surpassing
state-of-the-art models.

</details>


### [10] [Neural Gaussian Radio Fields for Channel Estimation](https://arxiv.org/abs/2508.11668)
*Muhammad Umer,Muhammad Ahmed Mohsin,Ahsan Bilal,John M. Cioffi*

Main category: eess.SP

TL;DR: nGRF是一种基于3D高斯原语的无线信道估计新框架，相比传统方法在精度、速度和数据效率方面有显著提升，解决了移动性环境下的信道状态信息获取瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 传统信道估计技术在移动环境下存在严重性能退化，导频开销大、延迟高、频谱效率低，需要新的解决方案来应对现代无线网络的挑战。

Method: 使用显式3D高斯原语进行直接3D电磁场聚合，每个高斯函数作为局部无线电调制器，避免了基于NeRF的慢速隐式表示或非物理2D投影方法。

Result: 室内场景预测SNR比现有方法高10.9倍，推理延迟从242ms降至1.1ms（220倍加速）；室外场景达到26.2dB SNR；数据收集负担减少18倍，训练时间从小时级降至分钟级（180倍减少）。

Conclusion: nGRF框架在精度、速度和效率方面均显著优于现有方法，能够有效解决移动环境下的信道估计问题，为动态无线网络提供了实用的解决方案。

Abstract: Accurate channel state information (CSI) remains the most critical bottleneck
in modern wireless networks, with pilot overhead consuming up to 11-21% of
transmission bandwidth, increasing latency by 20-40% in massive MIMO systems,
and reducing potential spectral efficiency by over 53%. Traditional estimation
techniques fundamentally fail under mobility, with feedback delays as small as
4 ms causing 50% throughput degradation at even modest speeds (30 km/h). We
present neural Gaussian radio fields (nGRF), a novel framework that leverages
explicit 3D Gaussian primitives to synthesize complex channel matrices
accurately and efficiently. Unlike NeRF-based approaches that rely on slow
implicit representations or existing Gaussian splatting methods that use
non-physical 2D projections, nGRF performs direct 3D electromagnetic field
aggregation, with each Gaussian acting as a localized radio modulator. nGRF
demonstrates superior performance across diverse environments: in indoor
scenarios, it achieves a 10.9$\times$ higher prediction SNR than state of the
art methods while reducing inference latency from 242 ms to just 1.1 ms (a
220$\times$ speedup). For large-scale outdoor environments, where existing
approaches fail to function, nGRF achieves an SNR of 26.2 dB. Moreover, nGRF
requires only 0.011 measurements per cubic foot compared to 0.2-178.1 for
existing methods, thereby reducing data collection burden by 18$\times$.
Training time is similarly reduced from hours to minutes (a 180$\times$
reduction), enabling rapid adaptation to dynamic environments. The code and
datasets are available at: https://github.com/anonym-auth/n-grf

</details>


### [11] [Direction of Arrival Estimation: A Tutorial Survey of Classical and Modern Methods](https://arxiv.org/abs/2508.11675)
*Amgad A. Salama*

Main category: eess.SP

TL;DR: 这是一份关于到达角度估计的综述性教程论文，为初学者和研究人员提供了从经典到现代方法的全面介绍，包括数学推导、Python实现和实践指南。


<details>
  <summary>Details</summary>
Motivation: 到达角度估计是数组信号处理基础问题，应用于雷达、声纳、无线通信等领域。论文旨在为入门者提供全面的学习资源，缩小理论与实践之间的差距。

Method: 重点关注窄带信号处理和均匀线性数组，包含经典波束形成、子空间方法（MUSIC、ESPRIT）、最大似然方法和稀疏信号处理方法。提供步骤性数学推导和几何直观。

Result: 论文提供了开源Python实现代码库，支持可复现研究和实践学习。通过系统性能对比分析，提供了方法选择和参数调整的实践指南。

Conclusion: 该综述性论文成功地为到达角度估计领域提供了全面的入门教程，既适合初学者学习，也可作为领域参考手册。开源代码库为研究人员提供了实践支持。

Abstract: Direction of arrival (DOA) estimation is a fundamental problem in array
signal processing with applications spanning radar, sonar, wireless
communications, and acoustic signal processing. This tutorial survey provides a
comprehensive introduction to classical and modern DOA estimation methods,
specifically designed for students and researchers new to the field. We focus
on narrowband signal processing using uniform linear arrays, presenting
step-by-step mathematical derivations with geometric intuition. The survey
covers classical beamforming methods, subspace-based techniques (MUSIC,
ESPRIT), maximum likelihood approaches, and sparse signal processing methods.
Each method is accompanied by Python implementations available in an
open-source repository, enabling reproducible research and hands-on learning.
Through systematic performance comparisons across various scenarios, we provide
practical guidelines for method selection and parameter tuning. This work aims
to bridge the gap between theoretical foundations and practical implementation,
making DOA estimation accessible to beginners while serving as a comprehensive
reference for the field. See https://github.com/AmgadSalama/DOA for detail
implementation of the methods.

</details>


### [12] [Age-Normalized HRV Features for Non-Invasive Glucose Prediction: A Pilot Sleep-Aware Machine Learning Study](https://arxiv.org/abs/2508.11682)
*Md Basit Azam,Sarangthem Ibotombi Singh*

Main category: eess.SP

TL;DR: 通过年龄正规化的睡眠心率变异性分析，显著提高了无创血糖监测的准确度，为糖尿病管理提供新方法


<details>
  <summary>Details</summary>
Motivation: 非侵入性血糖监测是糖尿病管理的关键挑战，传统的心率变异性分析受到年龄相关自主神经变化的影响，需要找到更准确的预测方法

Method: 对43名受试者进行多模态数据分析，包括睡眠阶段特异心电图、心率变异性特征和临床测量。采用新的年龄正规化技术，将HRV原始值除以年龄缩放因子，使用贝叶斯岭回归和5折交叉验证进行对数血糖预测

Result: 年龄正规化的HRV特征实现了R2 = 0.161 (MAE = 0.182)的预测效果，比非正规化特征提高25.6%。最佳预测特征包括睡眠眼动期平均RR间期、深睡期平均RR间期和舔张压

Conclusion: 年龄正规化的HRV特征显著提高了血糖预测准确性，这种考虑睡眠的方法解决了自主神经功能评估的基本限制，为非侵入性血糖监测应用提供了初步可行性，但需要在更大群体中验证

Abstract: Non-invasive glucose monitoring remains a critical challenge in the
management of diabetes. HRV during sleep shows promise for glucose prediction
however, age-related autonomic changes significantly confound traditional HRV
analyses. We analyzed 43 subjects with multi-modal data including sleep-stage
specific ECG, HRV features, and clinical measurements. A novel
age-normalization technique was applied to the HRV features by, dividing the
raw values by age-scaled factors. BayesianRidge regression with 5-fold
cross-validation was employed for log-glucose prediction. Age-normalized HRV
features achieved R2 = 0.161 (MAE = 0.182) for log-glucose prediction,
representing a 25.6% improvement over non-normalized features (R2 = 0.132). The
top predictive features were hrv rem mean rr age normalized (r = 0.443, p =
0.004), hrv ds mean rr age normalized (r = 0.438, p = 0.005), and diastolic
blood pressure (r = 0.437, p = 0.005). Systematic ablation studies confirmed
age-normalization as the critical component, with sleep-stage specific features
providing additional predictive value. Age-normalized HRV features
significantly enhance glucose prediction accuracy compared with traditional
approaches. This sleep-aware methodology addresses fundamental limitations in
autonomic function assessment and suggests a preliminary feasibility for
non-invasive glucose monitoring applications. However, these results require
validation in larger cohorts before clinical consideration.

</details>


### [13] [A Graph Neural Network based on a Functional Topology Model: Unveiling the Dynamic Mechanisms of Non-Suicidal Self-Injury in Single-Channel EEG](https://arxiv.org/abs/2508.11684)
*BG Tong*

Main category: eess.SP

TL;DR: 这项研究提出了一种新题的功能-能量拓扑模型，利用图神经网络解码单通道EEG数据，揭示了非自杀性自伤行为的神经动力学机制，发现了关键的反馈循环失调现象。


<details>
  <summary>Details</summary>
Motivation: 为了探索非自杀性自伤行为（NSSI）的神经机制，并尝试使用单通道EEG和图神经网络技术在真实环境中解码复杂的心理状态。

Method: 使用智能手机应用和便携式Fp1 EEG头带收集三名青少年NSSI患者的EEG数据，构建了一个理论驱动的七节点图神经网络模型，通过内部分割和交叉验证评估性能，使用GNNExplainer进行可解释性分析。

Result: 模型在内部验证中达到了超过85%的准确率，交叉验证也显示显著超过随机水平的约73.7%性能。可解释性分析发现了关键反馈循环失调和方向逆转的现象。

Conclusion: 这项研究证明了理论导向图神经网络在稀疏单通道EEG中解码复杂心理状态的可行性，所识别的"反馈循环逆转"机制为NSSI提供了新题的动态计算模型，为客观生物标记物和下一代数字疗法开拓了道路。

Abstract: Objective: This study proposes and preliminarily validates a novel
"Functional-Energetic Topology Model" to uncover neurodynamic mechanisms of
Non-Suicidal Self-Injury (NSSI), using Graph Neural Networks (GNNs) to decode
brain network patterns from single-channel EEG in real-world settings.Methods:
EEG data were collected over ~1 month from three adolescents with NSSI using a
smartphone app and a portable Fp1 EEG headband during impulsive and
non-impulsive states. A theory-driven GNN with seven functional nodes was
built. Performance was evaluated via intra-subject (80/20 split) and
leave-one-subject-out cross-validation (LOSOCV). GNNExplainer was used for
interpretability.Results: The model achieved high intra-subject accuracy (>85%)
and significantly above-chance cross-subject performance (approximately73.7%).
Explainability analysis revealed a key finding: during NSSI states, a critical
feedback loop regulating somatic sensation exhibits dysfunction and directional
reversal. Specifically, the brain loses its ability to self-correct via
negative bodily feedback, and the regulatory mechanism enters an "ineffective
idling" state.Conclusion: This work demonstrates the feasibility of applying
theory-guided GNNs to sparse, single-channel EEG for decoding complex mental
states. The identified "feedback loop reversal" offers a novel, dynamic, and
computable model of NSSI mechanisms, paving the way for objective biomarkers
and next-generation Digital Therapeutics (DTx).

</details>


### [14] [Enhancing Corrosion Resistance of Aluminum Alloys Through AI and ML Modeling](https://arxiv.org/abs/2508.11685)
*Farnaz Kaboudvand,Maham Khalid,Nydia Assaf,Vardaan Sahgal,Jon P. Ruffley,Brian J. McDermott*

Main category: eess.SP

TL;DR: 机器学习模型预测铝合金在海洋环境中的腐负速率，高斯过程回归表现最优


<details>
  <summary>Details</summary>
Motivation: 铝合金在海洋环境中面临严重腐负挑战，需要快速预测和优化腐负性能

Method: 使用开源数据集，采用直接和逆向两种方法，比较了随机森林、神经网络和高斯过程回归三种机器学习算法

Result: 高斯过程回归表现最优，尤其是使用混合核函数时，对数变换后的GPR进一步提升了预测精度

Conclusion: 机器学习（特别是GPR）在预测腐负速率和材料性能方面具有高效性

Abstract: Corrosion poses a significant challenge to the performance of aluminum
alloys, particularly in marine environments. This study investigates the
application of machine learning (ML) algorithms to predict and optimize
corrosion resistance, utilizing a comprehensive open-source dataset compiled
from various sources. The dataset encompasses corrosion rate data and
environmental conditions, preprocessed to standardize units and formats. We
explored two different approaches, a direct approach, where the material's
composition and environmental conditions were used as inputs to predict
corrosion rates; and an inverse approach, where corrosion rate served as the
input to identify suitable material compositions as output. We employed and
compared three distinct ML methodologies for forward predictions: Random Forest
regression, optimized via grid search; a feed-forward neural network, utilizing
ReLU activation and Adam optimization; and Gaussian Process Regression (GPR),
implemented with GPyTorch and employing various kernel functions. The Random
Forest and neural network models provided predictive capabilities based on
elemental compositions and environmental conditions. Notably, Gaussian Process
Regression demonstrated superior performance, particularly with hybrid kernel
functions. Log-transformed GPR further refined predictions. This study
highlights the efficacy of ML, particularly GPR, in predicting corrosion rates
and material properties.

</details>


### [15] [The Lost-K and Shorter-J Phenomenon in Non-Standard Ballistocardiography Data](https://arxiv.org/abs/2508.11686)
*Shuai Jiao,Jian Fang,Tianshu Zhou,Jinsong Li,Yanhong Liu,Ye Liu,Ming Ju*

Main category: eess.SP

TL;DR: 这篇论文研究非标准心冲图(BCG)信号中J峰不显著的问题，提出了两种现象和三种信号处理方法，有效提高了J峰检测的性能。


<details>
  <summary>Details</summary>
Motivation: 非标准BCG数据中J峰不显著，影响了心冲图信号的分析和应用。识别和解决J峰不显著的问题对于提高BCG信号处理效果至关重要。

Method: 提出了两种现象：短J现象和失K现象，并提出三种信号变换方法来改善这些现象。在40名受试者的时间对齐ECG-BCG数据集上进行了评估。

Result: 结果显示，基于变换后的信号，简单的J峰基础方法（仅使用局部极大值或极小值检测）在定位J峰和提厼G周期方面显示出更好的性能，尤其是对非标准BCG数据。

Conclusion: 该研究提出的信号变换方法能够有效地改善非标准BCG信号中J峰不显著的问题，为提高BCG信号处理的准确性和可靠性提供了有效的解决方案。

Abstract: Non-standard ballistocardiogram(BCG) data generally do not have prominent J
peaks. This paper introduces two phenomena that reduce the prominence of
Jpeaks: the shorter-J phenomenon and the lost-K phenomenon, both of which are
commonly observed in non-standard BCG signals . This paper also proposes three
signal transformation methods that effectively improve the lost-K and shorter-J
phenomena. The methods were evaluated on a time-aligned ECG-BCG dataset with 40
subjects. The results show that based on the transformed signal, simple
J-peak-based methods using only the detection of local maxima or minima show
better performance in locating J-peaks and extracting BCG cycles, especially
for non-standard BCG data.

</details>


### [16] [Agent-Based Anti-Jamming Techniques for UAV Communications in Adversarial Environments: A Comprehensive Survey](https://arxiv.org/abs/2508.11687)
*Jingpu Yang,Mingxuan Cui,Hang Zhang,Fengxian Ji,Zhengzhao Lai,Yufeng Wang*

Main category: eess.SP

TL;DR: 这篇论文是关于无人机通信中智能抗干扰技术的综述，提出了基于"感知-决策-行动"范式的闭环决策框架，重点讨论了博弈论建模和强化学习算法在抗干扰策略中的应用。


<details>
  <summary>Details</summary>
Motivation: 无人机通信在动态对抗环境中面临日益严重的多源干扰挑战，对通信的可靠性和弹性提出了更高要求，需要发展智能化的自主抗干扰技术。

Method: 建立以"感知-决策-行动"范式为核心的闭环决策框架，系统回顾各阶段关键技术，重点采用博弈论建模无人机与干扰器交互，并整合基于强化学习的智能算法来推导自适应抗干扰策略。

Result: 提出了一个综合性的智能抗干扰代理概念和框架，系统梳理了相关技术方法，为开发更智能和鲁棒的无人机抗干扰通信系统提供了理论基础和技术参考。

Conclusion: 论文讨论了当前方法的潜在局限性，识别了关键工程挑战，并指出了有前景的未来研究方向，旨在为无人机智能抗干扰通信系统的发展提供有价值的参考。

Abstract: Unmanned Aerial Vehicle communications are encountering increasingly severe
multi-source interference challenges in dynamic adversarial environments, which
impose higher demands on their reliability and resilience. To address these
challenges, agent-based autonomous anti-jamming techniques have emerged as a
crucial research direction. This paper presents a comprehensive survey that
first formalizes the concept of intelligent anti-jamming agents for UAV
communications and establishes a closed-loop decision-making framework centered
on the "Perception-Decision-Action" (P-D-A) paradigm. Within this framework, we
systematically review key technologies at each stage, with particular emphasis
on employing game theory to model UAV-jammer interactions and integrating
reinforcement learning-based intelligent algorithms to derive adaptive
anti-jamming strategies. Furthermore, we discuss potential limitations of
current approaches, identify critical engineering challenges, and outline
promising future research directions, aiming to provide valuable references for
developing more intelligent and robust anti-jamming communication systems for
UAVs.

</details>


### [17] [Towards Generalizable Learning Models for EEG-Based Identification of Pain Perception](https://arxiv.org/abs/2508.11691)
*Mathis Rezzouk,Fabrice Gagnon,Alyson Champagne,Mathieu Roy,Philippe Albouy,Michel-Pierre Coll,Cem Subakan*

Main category: eess.SP

TL;DR: 本研究系统评估了多种机器学习模型在跨被试脑电信号疼痛感知识别中的泛化性能，发现深度学习模型相比传统模型在跨被试场景下表现更稳健，图神经网络模型展现出捕获被试不变特征的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前基于EEG的疼痛感知研究面临跨被试泛化的重大挑战，由于EEG信号存在高度个体差异，且现有研究较少关注直接疼痛感知的跨被试识别问题。

Method: 使用108名被试的EEG数据集，系统评估传统分类器和深度神经网络在热痛和厌恶听觉刺激感知识别任务中的性能，包括被试内和跨被试两种评估设置。

Result: 传统模型在跨被试场景下性能下降最显著，深度学习模型表现更稳健，图神经网络模型展现出捕获被试不变EEG信号结构的潜力，尽管性能变异仍然较高。

Conclusion: 深度学习模型特别是图神经网络在跨被试EEG解码中具有优势，研究还提供了预处理数据集作为标准化基准，促进未来算法在相同泛化约束下的评估。

Abstract: EEG-based analysis of pain perception, enhanced by machine learning, reveals
how the brain encodes pain by identifying neural patterns evoked by noxious
stimulation. However, a major challenge that remains is the generalization of
machine learning models across individuals, given the high cross-participant
variability inherent to EEG signals and the limited focus on direct pain
perception identification in current research. In this study, we systematically
evaluate the performance of cross-participant generalization of a wide range of
models, including traditional classifiers and deep neural classifiers for
identifying the sensory modality of thermal pain and aversive auditory
stimulation from EEG recordings. Using a novel dataset of EEG recordings from
108 participants, we benchmark model performance under both within- and
cross-participant evaluation settings. Our findings show that traditional
models suffered the largest drop from within- to cross-participant performance,
while deep learning models proved more resilient, underscoring their potential
for subject-invariant EEG decoding. Even though performance variability
remained high, the strong results of the graph-based model highlight its
potential to capture subject-invariant structure in EEG signals. On the other
hand, we also share the preprocessed dataset used in this study, providing a
standardized benchmark for evaluating future algorithms under the same
generalization constraints.

</details>


### [18] [Scalable, Technology-Agnostic Diagnosis and Predictive Maintenance for Point Machine using Deep Learning](https://arxiv.org/abs/2508.11692)
*Eduardo Di Santi,Ruixiang Ci,Clément Lefebvre,Nenad Mijatovic,Michele Pugnaloni,Jonathan Brown,Victor Martín,Kenza Saiah*

Main category: eess.SP

TL;DR: 这篇论文提出了一种只需单一电源信号输入的深度学习方法，用于预测车辆转向机的故障，达到了极高的准确度和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 车辆转向机作为铁路关键设备，故障会导致服务中断。现有方法需多种输入和特征工程，特定于技术类型和安装环境，可扩展性很差。

Method: 使用深度学习模型直接分析转向机运动过程中的电源功率信号模式，识别健康状态和故障类型，并通过遵循预测提供信心度认证。

Result: 方法达到了>99.99%的精确度，<0.01%的假正率，假阶率可忽略。在真实世界和测试环境中多种电机械转向机类型上验证了可扩展性。

Conclusion: 该方法通过简化数据需求和提供信心度认证，实现了高准确的预测性维护，符合ISO-17359标准，具有强的实际应用价值。

Abstract: The Point Machine (PM) is a critical piece of railway equipment that switches
train routes by diverting tracks through a switchblade. As with any critical
safety equipment, a failure will halt operations leading to service
disruptions; therefore, pre-emptive maintenance may avoid unnecessary
interruptions by detecting anomalies before they become failures. Previous work
relies on several inputs and crafting custom features by segmenting the signal.
This not only adds additional requirements for data collection and processing,
but it is also specific to the PM technology, the installed locations and
operational conditions limiting scalability. Based on the available maintenance
records, the main failure causes for PM are obstacles, friction, power source
issues and misalignment. Those failures affect the energy consumption pattern
of PMs, altering the usual (or healthy) shape of the power signal during the PM
movement. In contrast to the current state-of-the-art, our method requires only
one input. We apply a deep learning model to the power signal pattern to
classify if the PM is nominal or associated with any failure type, achieving
>99.99\% precision, <0.01\% false positives and negligible false negatives. Our
methodology is generic and technology-agnostic, proven to be scalable on
several electromechanical PM types deployed in both real-world and test bench
environments. Finally, by using conformal prediction the maintainer gets a
clear indication of the certainty of the system outputs, adding a confidence
layer to operations and making the method compliant with the ISO-17359
standard.

</details>


### [19] [Track Component Failure Detection Using Data Analytics over existing STDS Track Circuit data](https://arxiv.org/abs/2508.11693)
*Francisco López,Eduardo Di Santi,Clément Lefebvre,Nenad Mijatovic,Michele Pugnaloni,Victor Martín,Kenza Saiah*

Main category: eess.SP

TL;DR: 基于SVM分类器的智能轨道电路故障自动识别方法，能够准确分类15种故障类型，提高维护效率


<details>
  <summary>Details</summary>
Motivation: 传统轨道电路故障检测依靠人工经验，需要自动化方法来准确识别故障组件以改善维护效果

Method: 采用STDS电流数据，使用SVM支持向量机分类器进行故障识别，模型训练分类15种属于3个主要类别的故障

Result: 在10个不同轨道电路的现场数据上进行测试，所有用例都被正确分类，经STDS专家和维护人员验证

Conclusion: 该方法能够有效地自动识别轨道电路故障，为轨道交通安全系统提供了可靠的故障识别解决方案

Abstract: Track Circuits (TC) are the main signalling devices used to detect the
presence of a train on a rail track. It has been used since the 19th century
and nowadays there are many types depending on the technology. As a general
classification, Track Circuits can be divided into 2 main groups, DC (Direct
Current) and AC (Alternating Current) circuits. This work is focused on a
particular AC track circuit, called "Smart Train Detection System" (STDS),
designed with both high and low-frequency bands. This approach uses STDS
current data applied to an SVM (support vector machine) classifier as a type of
failure identifier. The main purpose of this work consists on determine
automatically which is the component of the track that is failing to improve
the maintenance action. Model was trained to classify 15 different failures
that belong to 3 more general categories. The method was tested with field data
from 10 different track circuits and validated by the STDS track circuit expert
and maintainers. All use cases were correctly classified by the method.

</details>


### [20] [Operational machine learning for park-scale irrigation to support urban cooling](https://arxiv.org/abs/2508.11700)
*Mesut Koçyiğit,Bahman Javadi,Russell Thomson,Sebastian Pfautsch,Oliver Obst*

Main category: eess.SP

TL;DR: SIMPaCT是一个智能灌溉系统，通过土壤湿度预测优化公园灌溉来降低城市温度，使用kNN算法和异常检测确保系统可靠性，实现了0.78%的平均绝对误差。


<details>
  <summary>Details</summary>
Motivation: 传统公园灌溉系统主要关注节水而非降温效果，城市热岛效应需要更智能的灌溉管理来缓解局部高温。

Method: 使用202个土壤湿度传感器、50个温湿度节点和13个气象站数据，采用kNN预测算法和滚动窗口训练，配合异常检测和虚拟传感器技术。

Result: 系统平均绝对误差0.78%，优于SARIMA等复杂基线方法，上四分位误差更低(0.71% vs 0.93%)，已实现日常运行。

Conclusion: SIMPaCT提供了一个在城市公园尺度实现稳健、降温导向灌溉的操作方案，有效平衡了节水与降温的双重目标。

Abstract: Urban parks can mitigate local heat, yet irrigation control is usually tuned
for water savings rather than cooling. We report on SIMPaCT (Smart Irrigation
Management for Parks and Cool Towns), a park-scale deployment that links
per-zone soil-moisture forecasts to overnight irrigation set-points in support
of urban cooling. SIMPaCT ingests data from 202 soil-moisture sensors, 50
temperature-relative humidity (TRH) nodes, and 13 weather stations, and trains
a per-sensor k-nearest neighbours (kNN) predictor on short rolling windows
(200-900h). A rule-first anomaly pipeline screens missing and stuck-at signals,
with model-based checks (Isolation Forest and ARIMA). When a device fails, a
mutual-information neighbourhood selects the most informative neighbour and a
small multilayer perceptron supplies a "virtual sensor" until restoration.
Across sensors the mean absolute error was 0.78%, comparable to more complex
baselines; the upper-quartile error (P75) was lower for kNN than SARIMA (0.71%
vs 0.93%). SIMPaCT runs daily and writes proposed set-points to the existing
controller for operator review. This short communication reports an operational
recipe for robust, cooling-oriented irrigation at city-park scale.

</details>


### [21] [Scaling Wideband Massive MIMO Radar via Beamspace Dimension Reduction](https://arxiv.org/abs/2508.11790)
*Oveys Delafrooz Noroozi,Jiyoon Han,Wei Tang,Zhengya Zhang,Upamanyu Madhow*

Main category: eess.SP

TL;DR: 基于束空间变换的窗化MVDR束形成架构，通过空间FFT降低计算复杂度从O(N^3)降至O(NlogN)，在保持检测性能的同时显著减少计算和训练开销


<details>
  <summary>Details</summary>
Motivation: 传统空间处理在大规模数组中计算复杂度过高（MVDR束形成复杂度为O(N^3)），需要寻找更高效的数字束形成方案

Method: 利用束空间能量聚集特性，采用窗化束空间MVDR束形成架构，通过空间FFT进行束空间变换，并在目标咄子带上并行化处理

Result: 在DARPA SOAP程序的宽带雷达数据上评估，该方法达到了与全维度基准相似的检测性能，同时显著减少了计算咄训练开销

Conclusion: 束空间变换为大规模MIMO雷达提供了高效的数字束形成解决方案，通过空间FFT降低复杂度，并需在窗口大小与FFT分辨率之间找到复杂度、检测准确性咄干扰压制的平衡点

Abstract: We present an architecture for scaling digital beamforming for wideband
massive MIMO radar. Conventional spatial processing becomes computationally
prohibitive as array size grows; for example, the computational complexity of
MVDR beamforming scales as O(N^3) for an N-element array. In this paper, we
show that energy concentration in beamspace provides the basis for drastic
complexity reduction, with array scaling governed by the O(NlogN) complexity of
the spatial FFT used for beamspace transformation. Specifically, we propose an
architecture for windowed beamspace MVDR beamforming, parallelized across
targets and subbands, and evaluate its efficacy for beamforming and
interference suppression for government-supplied wideband radar data from the
DARPA SOAP (Scalable On-Array Processing) program. We demonstrate that our
approach achieves detection performance comparable to full-dimensional
benchmarks while significantly reducing computational and training overhead,
and provide insight into tradeoffs between beamspace window size and FFT
resolution in balancing complexity, detection accuracy, and interference
suppression.

</details>


### [22] [Digital Post-Distortion Architectures for Nonlinear Power Amplifiers: Volterra and Kernel Methods](https://arxiv.org/abs/2508.11792)
*Daniel Schäufele,Jochen Fink,Renato L. G. Cavalcante,Sławomir Stańczak*

Main category: eess.SP

TL;DR: 这篇论文探讨在5G终端设备中通过数字后置扩录(DPoD)技术在基站端补偿功放非线性失真的方案，以提高功效和降低终端复杂度。


<details>
  <summary>Details</summary>
Motivation: 5G终端设备中功放(PA)在上行传输时耐耗较大，减少功率后退虽能提高效率但会引入非线性失真。现有数字前置扩录方案需要复杂反馈机制，增加了终端复杂性和耗电。

Method: 研究了在时域、频域和DFT-s域应用DPoD的挑战和优势，提出在时域实施DPoD并配合频域通道均衡的方案。还提出了将复数值非线性补偿问题转换到实希尔伯空间的方法，以及等效内核方法来降低算法复杂度。

Result: 仿真验证显示，所提出的算法能够显著提高性能，效果超过现有最先进算法。时域DPoD配合频域通道均衡能在低计算复杂度和高效非线性补偿之间取得良好平衡。

Conclusion: 在基站端实施DPoD技术是一种有效的解决方案，利用基站优越的计算资源来补偿终端功放的非线性失真，可以在保持信号质量的同时降低终端的复杂性和耗电。

Abstract: In modern 5G user equipments (UEs), the power amplifier (PA) contributes
significantly to power consumption during uplink transmissions, especially in
cell-edge scenarios. While reducing power backoff can enhance PA efficiency, it
introduces nonlinear distortions that degrade signal quality. Existing
solutions, such as digital pre-distortion, require complex feedback mechanisms
for optimal performance, leading to increased UE complexity and power
consumption. Instead, in this study we explore digital post-distortion (DPoD)
techniques, which compensate for these distortions at the base station,
leveraging its superior computational resources. In this study, we conduct an
comprehensive study concerning the challenges and advantages associated with
applying DPoD in time-domain, frequency-domain, and DFT-s-domain. Our findings
suggest that implementing DPoD in the time-domain, complemented by
frequency-domain channel equalization, strikes a good balance between low
computational complexity and efficient nonlinearity compensation. In addition,
we demonstrate that memory has to be taken into account regardless of the
memory of the PA. Subsequently, we show how to pose the complex-valued problem
of nonlinearity compensation in a real Hilbert space, emphasizing the potential
performance enhancements as a result. We then discuss the traditional Volterra
series and show an equivalent kernel method that can reduce algorithmic
complexity. Simulations validate the results of our analysis and show that our
proposed algorithm can significantly improve performance compared to
state-of-the-art algorithms.

</details>


### [23] [Autonomous Driving with RSMA-Enabled Finite Blocklength Transmissions: Ergodic Performance Analysis and Optimization](https://arxiv.org/abs/2508.12012)
*Yi Wang,Yingyang Chen,Li Wang,Donghong Cai,Xiaofan Li,Pingzhi Fan*

Main category: eess.SP

TL;DR: RSMA在FBL传输下的性能分析与优化，通过联合优化功率分配和速率分割，显著提升遍历和速率、降低块长度和误块率，同时保证网络公平性


<details>
  <summary>Details</summary>
Motivation: 针对高移动性自动驾驶场景中URLLC的严格需求，RSMA对不完美CSI具有鲁棒性，但需要解决有限块长度传输的性能评估和优化问题

Method: 推导RSMA遍历和速率的闭式下界，基于梯度下降联合优化全局功率系数、私有功率分配和公共速率分割，根据公共流激活状态采用不同优化策略

Result: 仿真结果表明该RSMA方案显著提升遍历性能，减少块长度和BLER，优于平均私有功率的RSMA和SDMA，同时保证最差信道条件用户的速率

Conclusion: 所提出的RSMA FBL传输方案有效满足URLLC要求，在保证公平性的同时显著提升系统性能，适用于高移动性自动驾驶通信场景

Abstract: Rate-splitting multiple access (RSMA) is a key technology for next-generation
multiple access systems due to its robustness against imperfect channel state
information (CSI). This makes RSMA particularly suitable for high-mobility
autonomous driving, where ultra-reliable and low-latency communication (URLLC)
is essential. To address the stringent requirements, this study enables RSMA
finite blocklength (FBL) transmissions and explicitly evaluates the ergodic
performance. We derive the closed-form lower bound for the ergodic sum-rate of
RSMA, considering vital factors such as the vehicle velocities, vehicle
positions, power allocation of each stream, blocklengths, and block error rates
(BLERs). To further enhance the ergodic sum-rate while complying with quality
of service (QoS) rate constraints, we jointly optimize the global power
coefficient, private power distribution, and common rate splitting. Guided by
gradient descent, we first adjust the global power coefficient based on its
sum-rate solution. This parameter regulates the power state of the common
stream, allowing for dynamic activation or deactivation: if active, we optimize
the private power distribution and adjust the common rate splitting to meet
minimum transmission constraints; if inactive, we use the sequential quadratic
programming for private power distribution optimization. Simulation results
confirm that our RSMA scheme significantly improves the ergodic performance,
reduces blocklength and BLER, surpassing the RSMA counterpart with average
private power and space division multiple access (SDMA). Furthermore, our
approach is validated to guarantee the rates for users with the poorest channel
conditions, thereby enhancing fairness across the network.

</details>


### [24] [A Generalized Multidimensional Chinese Remainder Theorem (MD-CRT) for Multiple Integer Vectors](https://arxiv.org/abs/2508.12099)
*Guangpu Guo,Xiang-Gen Xia*

Main category: eess.SP

TL;DR: 本文研究多维中国剩余定理的普遍化问题，探讨如何从多个矩阵模的向量余数恢复多个整数向量，解决了唯一可确定范围和最大动态范围达到条件两个核心问题。


<details>
  <summary>Details</summary>
Motivation: 多维CRT在加密、编码和信号处理领域应用广泛，但现有普遍化方法面临矩阵不交换和多维唯一确定范围复杂的挑战，需要系统性理论研究。

Method: 首先求解无先验信息情况下的唯一可确定范围，并提出相应算法。重点研究了仅包含两个整数向量的特殊情况，推导达到最大动态范围的新条件。

Result: 得到了无先验信息情况下的唯一可确定范围，以及两向量特殊情况下达到最大动态范围的新条件。当维度降为1时，该条件甚至超过传统普遍化CRT的现有条件。

Conclusion: 本文结果为多维信号处理中的频率检测等应用提供了理论支撑，在多维CRT普遍化理论方面取得了重要进展。

Abstract: Chinese remainder theorem (CRT) is widely applied in cryptography, coding
theory, and signal processing. It has been extended to the multidimensional CRT
(MD-CRT), which reconstructs an integer vector from its vector remainders
modulo multiple integer matrices. This paper investigates a generalized MD-CRT
for multiple integer vectors, where the goal is to determine multiple integer
vectors from multiple vector residue sets modulo multiple integer
matrices.Comparing to the existing generalized CRT for multiple scalar
integers, the challenge is that the moduli in MD-CRT are matrices that do not
commute and the corresponding uniquely determinable range is multidimensional
and the inclusion relationship is much more complicated. In this paper,we
address two fundamental questions regarding the generalized MD-CRT. The first
question concerns the uniquely determinable range of multiple integer vectors
when no prior information about them is available. The second question is about
the conditions under which the maximal possible dynamic range can be
achieved.To answer these two questions, we first derive a uniquely determinable
range without prior information and accordingly propose an algorithm to achieve
it. A special case involving only two integer vectors is investigated for the
second question, leading to a new condition for achieving the maximal possible
dynamic range. Interestingly, this newly obtained condition, when the dimension
is reduced to $1$, is even better than the existing ones for the conventional
generalized CRT for scalar integers.These results may have applications for
frequency detection in multidimensional signal processing.

</details>


### [25] [RFSS: A Comprehensive Multi-Standard RF Signal Source Separation Dataset with Advanced Channel Modeling](https://arxiv.org/abs/2508.12106)
*Hao Chen,Rui Jin,Dayuan Tan*

Main category: eess.SP

TL;DR: RFSS是一个包含52,847个多标准RF信号样本的开源数据集，支持2G/3G/4G/5G信号分离研究，CNN-LSTM架构在信号源分离任务中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统的快速发展导致复杂电磁环境中多种蜂窝标准共存，需要先进的信号源分离技术来处理多标准RF信号。

Method: 开发了包含GSM、UMTS、LTE和5G NR真实基带信号的RFSS开源数据集，采用先进信道建模包括多径衰落、8×8 MIMO处理和真实干扰场景。

Result: CNN-LSTM架构在信号源分离任务中实现了26.7 dB的SINR改善，显著优于传统ICA（15.2 dB）和NMF（18.3 dB）方法。

Conclusion: RFSS数据集为RF信号源分离、认知无线电和机器学习应用提供了可重复研究的基础，并保持完全开源可访问性。

Abstract: The rapid evolution of wireless communication systems has created complex
electromagnetic environments where multiple cellular standards (2G/3G/4G/5G)
coexist, necessitating advanced signal source separation techniques. We present
RFSS (RF Signal Source Separation), a comprehensive open-source dataset
containing 52,847 realistic multi-standard RF signal samples with complete 3GPP
standards compliance. Our framework generates authentic baseband signals for
GSM, UMTS, LTE, and 5G NR with advanced channel modeling including multipath
fading, MIMO processing up to 8 by 8 antennas, and realistic interference
scenarios. Experimental validation demonstrates superior performance of
CNN-LSTM architectures achieving 26.7 dB SINR improvement in source separation
tasks, significantly outperforming traditional ICA (15.2 dB) and NMF (18.3 dB)
approaches. The RFSS dataset enables reproducible research in RF source
separation, cognitive radio, and machine learning applications while
maintaining complete open-source accessibility

</details>


### [26] [Effect of Phase Shift Errors on the Security of UAV-assisted STAR-RIS IoT Networks](https://arxiv.org/abs/2508.12114)
*Mustafa Gusaibat,Mohammed Hnaish,Abdelhamid Salem,Khaled Rabie,Zubair Md Fadlullah,Wali Ullah Khan,Mohamad A. Alawad,Yazeed Alkhrijah*

Main category: eess.SP

TL;DR: 这篇论文研究了UAV搭载STAR-RIS系统中相位偏移错误对网络安全性能的影响，通过建模分析和优化算法提高秘密速率。


<details>
  <summary>Details</summary>
Motivation: 实际UAV系统中的振动和气流等缺陷会影响STAR-RIS的相位偏移，从而容易造成网络安全性能的降级，需要研究这种影响并提出解决方案。

Method: 使用von Mises分布模型化相位估计错误，推导了不完美相位调整下的道常秘密速率分析表达式，并通过线性网格算法优化UAV位置以最大化权重秘密速率和。

Result: 通过Monte Carlo模拟验证了分析推导的正确性，分析了相位估计错误对系统安全性能的具体影响，为实际部署提供了重要见解。

Conclusion: 论文为UAV搭载STAR-RIS系统的安全部署提供了重要的理论基础和实践指南，通过对相位错误的完整分析和优化策略，有效提升了系统的秘密性能。

Abstract: Unmanned aerial vehicles (UAV)-mounted simultaneous transmitting and
reflecting reconfigurable intelligent surface (STAR-RIS) systems can provide
full-dimensional coverage and flexible deployment opportunities in future
6G-enabled IoT networks. However, practical imperfections such as jittering and
airflow of UAV could affect the phase shift of STAR-RIS, and consequently
degrade network security. In this respect, this paper investigates the impact
of phase shift errors on the secrecy performance of UAV-mounted
STAR-RIS-assisted IoT systems. More specifically, we consider a UAV-mounted
STAR-RIS-assisted non-orthogonal multiple access (NOMA) system where IoT
devices are grouped into two groups: one group on each side of the STAR-RIS.
The nodes in each group are considered as potential Malicious nodes for the
ones on the other side. By modeling phase estimation errors using a von Mises
distribution, analytical closed-form expressions for the ergodic secrecy rates
under imperfect phase adjustment are derived. An optimization problem to
maximize the weighted sum secrecy rate (WSSR) by optimizing the UAV placement
is formulated and is then solved using a linear grid-based algorithm. Monte
Carlo simulations are provided to validate the analytical derivations. The
impact of phase estimation errors on system's secrecy performance is analyzed,
providing critical insights for the practical realisation of STAR-RIS
deployments for secure UAV-enabled IoT networks.

</details>


### [27] [ATLAS: AI-Native Receiver Test-and-Measurement by Leveraging AI-Guided Search](https://arxiv.org/abs/2508.12204)
*Mauro Belgiovine,Suyash Pradhan,Johannes Lange,Michael Löhning,Kaushik Chowdhury*

Main category: eess.SP

TL;DR: ATLAS是一种AI引导的测试生成方法，用于发现AI原生无线接收器模型的故障场景，相比传统网格搜索方法效率提高19%


<details>
  <summary>Details</summary>
Motivation: AI原生无线接收器缺乏可解释性，且无法在所有场景下进行穷尽测试，存在网络功能风险

Method: 使用基于梯度的优化方法在线生成高风险故障配置的测试用例，避免穷举所有环境条件

Result: 发现了AI原生DeepRx接收器在特定移动性、信道延迟扩展和噪声组合下的性能问题，测试效率比网格搜索高19%

Conclusion: ATLAS为AI无线接收器提供了一种高效的测试方法，解决了高维测试空间的可扩展性问题

Abstract: Industry adoption of Artificial Intelligence (AI)-native wireless receivers,
or even modular, Machine Learning (ML)-aided wireless signal processing blocks,
has been slow. The main concern is the lack of explainability of these trained
ML models and the significant risks posed to network functionalities in case of
failures, especially since (i) testing on every exhaustive case is infeasible
and (ii) the data used for model training may not be available. This paper
proposes ATLAS, an AI-guided approach that generates a battery of tests for
pre-trained AI-native receiver models and benchmarks the performance against a
classical receiver architecture. Using gradient-based optimization, it avoids
spanning the exhaustive set of all environment and channel conditions; instead,
it generates the next test in an online manner to further probe specific
configurations that offer the highest risk of failure. We implement and
validate our approach by adopting the well-known DeepRx AI-native receiver
model as well as a classical receiver using differentiable tensors in NVIDIA's
Sionna environment. ATLAS uncovers specific combinations of mobility, channel
delay spread, and noise, where fully and partially trained variants of
AI-native DeepRx perform suboptimally compared to the classical receivers. Our
proposed method reduces the number of tests required per failure found by 19%
compared to grid search for a 3-parameters input optimization problem,
demonstrating greater efficiency. In contrast, the computational cost of the
grid-based approach scales exponentially with the number of variables, making
it increasingly impractical for high-dimensional problems.

</details>


### [28] [Weighted Covariance Intersection for Range-based Distributed Cooperative Localization of Multi-Agent Systems](https://arxiv.org/abs/2508.12207)
*Chenxin Tu,Xiaowei Cui,Gang Liu,Mingquan Lu*

Main category: eess.SP

TL;DR: 提出了加权协方差交叉(WCI)方法来改进3D分布式协同定位中的经典CI算法，解决了尺度不平衡和相关性失配问题，显著提升了多智能体系统在恶劣环境下的定位性能。


<details>
  <summary>Details</summary>
Motivation: 3D场景中经典CI优化准则存在尺度不平衡和相关性失配问题，导致分布式协同定位性能严重下降，需要设计专门机制来改进数据融合过程。

Method: 引入加权协方差交叉(WCI)机制，开发了多距离测量的并发融合策略，并基于惯性导航系统误差传播规则设计权重矩阵。

Result: 仿真结果表明，相比经典CI，WCI显著提升了协同定位性能，分布式方法在鲁棒性、可扩展性方面优于集中式方法，更适合大规模集群。

Conclusion: WCI方法有效解决了3D分布式协同定位中的关键挑战，为大规模多智能体系统在恶劣环境下的精确定位提供了更优解决方案。

Abstract: Precise localization of multi-agent systems (MAS) in harsh environments is a
critical challenge for swarm applications, and cooperative localization is
considered a key solution to this issue. Among all solutions, distributed
cooperative localization (DCL) has garnered widespread attention due to its
robustness and scalability. The main challenge of DCL lies in how to fuse
relative measurements between agents under unknown correlations. To address
this, covariance intersection (CI) was introduced to DCL. However, the
classical CI optimization criteria suffer from issues such as scale imbalance
and correlation mismatch during the fusion process. These deficiencies are not
as pronounced in 2D scenarios, where the state space is relatively simple and
the observability of each state component is well. However, in 3D scenarios,
where the state space is more complex and there are significant disparities in
the scale and observability of state components, performance degradation
becomes severe. This necessitates the design of specialized mechanisms to
improve the data fusion process. In this paper, we identify three main
drawbacks of the classical CI optimization criteria in recursive filtering and
introduce a weighting mechanism, namely weighted covariance intersection (WCI),
to improve its performance. We then introduce WCI into range-based distributed
cooperative localization in 3D scenarios, developing a concurrent fusion
strategy for multiple distance measurements and designing a weighting matrix
based on the error propagation rule of the inertial navigation system (INS).
Simulation results demonstrate that the proposed WCI significantly enhances
cooperative localization performance compared to classical CI, while the
distributed approach outperforms the centralized approach in terms of
robustness, scalability, and is more suitable for large-scale swarms.

</details>


### [29] [Towards Generalizable Human Activity Recognition: A Survey](https://arxiv.org/abs/2508.12213)
*Yize Cai,Baoshen Guo,Flora Salim,Zhiqing Hong*

Main category: eess.SP

TL;DR: 这篇综述论文系统回顾了基于IMU的可穿戴AI人体活动识别领域的泛化性问题，涵盖了229篇研究论文和25个公开数据集，从模型中心和数据中心两个角度分类方法，并讨论了持续挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 虽然IMU-based HAR在特定场景下性能有所提升，但其泛化能力仍然是阻碍实际应用的关键障碍。用户、传感器位置或环境变化引起的领域偏移会显著降低实际性能，因此需要系统研究泛化性问题。

Method: 从两个角度分类代表性方法：(i)模型中心方法：包括预训练方法、端到端方法和基于大语言模型的学习方法；(ii)数据中心方法：包括多模态学习和数据增强技术。同时总结了广泛使用的数据集、工具和基准。

Result: 提供了IMU-based泛化HAR领域的全面概述，建立了方法分类框架，识别了当前的研究现状和技术路线，为后续研究提供了系统参考。

Conclusion: 讨论了持续挑战（如数据稀缺、高效训练和可靠评估）并展望了未来方向，包括采用基础和大语言模型、物理信息和上下文感知推理、生成建模以及资源高效的训练和推理。

Abstract: As a critical component of Wearable AI, IMU-based Human Activity Recognition
(HAR) has attracted increasing attention from both academia and industry in
recent years. Although HAR performance has improved considerably in specific
scenarios, its generalization capability remains a key barrier to widespread
real-world adoption. For example, domain shifts caused by variations in users,
sensor positions, or environments can significantly decrease the performance in
practice. As a result, in this survey, we explore the rapidly evolving field of
IMU-based generalizable HAR, reviewing 229 research papers alongside 25
publicly available datasets to provide a broad and insightful overview. We
first present the background and overall framework of IMU-based HAR tasks, as
well as the generalization-oriented training settings. Then, we categorize
representative methodologies from two perspectives: (i) model-centric
approaches, including pre-training method, end-to-end method, and large
language model (LLM)-based learning method; and (ii) data-centric approaches,
including multi-modal learning and data augmentation techniques. In addition,
we summarize widely used datasets in this field, as well as relevant tools and
benchmarks. Building on these methodological advances, the broad applicability
of IMU-based HAR is also reviewed and discussed. Finally, we discuss persistent
challenges (e.g., data scarcity, efficient training, and reliable evaluation)
and also outline future directions for HAR, including the adoption of
foundation and large language models, physics-informed and context-aware
reasoning, generative modeling, and resource-efficient training and inference.
The complete list of this survey is available at
https://github.com/rh20624/Awesome-IMU-Sensing, which will be updated
continuously.

</details>


### [30] [A Novel Symbol Level Precoding based AFDM Transmission Framework: Offloading Equalization Burden to Transmitter Side](https://arxiv.org/abs/2508.12215)
*Shuntian Tang,Zesong Fei,Xinyi Wang,Dongkai Zhou,Zhiqiang Wei,Christos Masouros*

Main category: eess.SP

TL;DR: 提出一种基于符号级预编码的AFDM传输框架，通过将处理负担从用户端转移到基站端，低处理复杂度的同时保持传统性能。


<details>
  <summary>Details</summary>
Motivation: AFDM虽然具有强大的多普勒缓击能力，但其高的接收端计算复杂度仍是实际部署的主要障碍。

Method: 上行链路采用基于稀疏贝叶斯学习的频域通道估计算法，下行链路采用符号级预编码技术设计发射波形，通过二阶锥规划问题求解。

Result: 模拟结果显示，新方法在精度和稳健性方面超过传统OMP算法，且能在显著降低接收端复杂度的同时保持传统性能。

Conclusion: 该方案有效解决了AFDM高接收端复杂度的问题，为实际部署提供了可行的技术路径。

Abstract: Affine Frequency Division Multiplexing (AFDM) has attracted considerable
attention for its robustness to Doppler effects. However, its high
receiver-side computational complexity remains a major barrier to practical
deployment. To address this, we propose a novel symbol-level precoding
(SLP)-based AFDM transmission framework, which shifts the signal processing
burden in downlink communications from user side to the base station (BS),
enabling direct symbol detection without requiring channel estimation or
equalization at the receiver. Specifically, in the uplink phase, we propose a
Sparse Bayesian Learning (SBL) based channel estimation algorithm by exploiting
the inherent sparsity of affine frequency (AF) domain channels. In particular,
the sparse prior is modeled via a hierarchical Laplace distribution, and
parameters are iteratively updated using the Expectation-Maximization (EM)
algorithm. We also derive the Bayesian Cramer-Rao Bound (BCRB) to characterize
the theoretical performance limit. In the downlink phase, the BS employs the
SLP technology to design the transmitted waveform based on the estimated uplink
channel state information (CSI) and channel reciprocity. The resulting
optimization problem is formulated as a second-order cone programming (SOCP)
problem, and its dual problem is investigated by Lagrangian function and
Karush-Kuhn-Tucker conditions. Simulation results demonstrate that the proposed
SBL estimator outperforms traditional orthogonal matching pursuit (OMP) in
accuracy and robustness to off-grid effects, while the SLP-based waveform
design scheme achieves performance comparable to conventional AFDM receivers
while significantly reducing the computational complexity at receiver,
validating the practicality of our approach.

</details>


### [31] [Polarization Reconfigurable Transmit-Receive Beam Alignment with Interpretable Transformer](https://arxiv.org/abs/2508.12298)
*Seungcheol Oh,Han Han,Joongheon Kim,Sean Kwon*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Recent advancement in next generation reconfigurable antenna and fluid
antenna technology has influenced the wireless system with polarization
reconfigurable (PR) channels to attract significant attention for promoting
beneficial channel condition. We exploit the benefit of PR antennas by
integrating such technology into massive multiple-input-multiple-output (MIMO)
system. In particular, we aim to jointly design the polarization and
beamforming vectors on both transceivers for simultaneous channel
reconfiguration and beam alignment, which remarkably enhance the beamforming
gain. However, joint optimization over polarization and beamforming vectors
without channel state information (CSI) is a challenging task, since
depolarization increases the channel dimension; whereas massive MIMO systems
typically have low-dimensional pilot measurement from limited radio frequency
(RF) chain. This leads to pilot overhead because the transceivers can only
observe low-dimensional measurement of the high-dimension channel. This paper
pursues the reduction of the pilot overhead in such systems by proposing to
employ \emph{interpretable transformer}-based deep learning framework on both
transceivers to actively design the polarization and beamforming vectors for
pilot stage and transmission stage based on the sequence of accumulated
received pilots. Numerical experiments demonstrate the significant performance
gain of our proposed framework over the existing non-adaptive and active
data-driven methods. Furthermore, we exploit the interpretability of our
proposed framework to analyze the learning capabilities of the model.

</details>


### [32] [Jamming Identification with Differential Transformer for Low-Altitude Wireless Networks](https://arxiv.org/abs/2508.12320)
*Pengyu Wang,Zhaocheng Wang,Tianqi Mao,Weijie Yuan,Haijun Zhang,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 提出了一种基于差分变换器的无线干扰识别框架，通过差分自注意力机制和随机掩码训练策略来增强对抗样本的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 无人机等低空无线网络易受电磁干扰，而现有的深度学习干扰识别方案容易受到对抗样本攻击，导致鲁棒性下降

Method: 采用差分变换器网络进行干扰信号识别，提出随机掩码训练策略创建并行特征提取分支，并引入双分支正则化的一致性训练框架

Result: 仿真结果表明，所提方法在提升对抗样本鲁棒性方面优于现有方法

Conclusion: 该差分变换器框架通过创新的注意力机制和训练策略，有效提高了无线干扰识别系统对抗对抗攻击的鲁棒性

Abstract: Wireless jamming identification, which detects and classifies electromagnetic
jamming from non-cooperative devices, is crucial for emerging low-altitude
wireless networks consisting of many drone terminals that are highly
susceptible to electromagnetic jamming. However, jamming identification schemes
adopting deep learning (DL) are vulnerable to attacks involving carefully
crafted adversarial samples, resulting in inevitable robustness degradation. To
address this issue, we propose a differential transformer framework for
wireless jamming identification. Firstly, we introduce a differential
transformer network in order to distinguish jamming signals, which overcomes
the attention noise when compared with its traditional counterpart by
performing self-attention operations in a differential manner. Secondly, we
propose a randomized masking training strategy to improve network robustness,
which leverages the patch partitioning mechanism inherent to transformer
architectures in order to create parallel feature extraction branches. Each
branch operates on a distinct, randomly masked subset of patches, which
fundamentally constrains the propagation of adversarial perturbations across
the network. Additionally, the ensemble effect generated by fusing predictions
from these diverse branches demonstrates superior resilience against
adversarial attacks. Finally, we introduce a novel consistent training
framework that significantly enhances adversarial robustness through dualbranch
regularization. Simulation results demonstrate that our proposed methodology is
superior to existing methods in boosting robustness to adversarial samples.

</details>


### [33] [Coherent Compensation-Based Sensing for Long-Range Targets in Integrated Sensing and Communication System](https://arxiv.org/abs/2508.12371)
*Lin Wang,Zhiqing Wei,Xu Chen,Zhiyong Feng*

Main category: eess.SP

TL;DR: 基于MUSIC和最小二乘的空间信号分离方法，解决OFDM信号在超出cyclic prefix时间的干扰问题，提升远程目标检测性能


<details>
  <summary>Details</summary>
Motivation: 解决ISAC系统中OFDM信号在远程目标检测时的问题：循环前缀超时导致的码间干扰和载波干扰，以及近距离目标强回波对远距离目标的媒介干扰

Method: 提出基于MUSIC和最小二乘的空间信号分离方法，分离不同目标的回波信号；采用相干补偿基础的感知信号处理方法，提升SINR来生成更高SINR的距离-多普勒图

Result: 模拟结果显示，在500米远程目标上，方法比传统二维快速弗里叶变换方法提升了10dB的SINR，检测概率也显著提高

Conclusion: 该方法有效解决了ISAC系统中远程目标检测的干扰问题，显著提升了感知性能，为6G集成感知与通信技术提供了有效解决方案

Abstract: Integrated sensing and communication (ISAC) is a promising candidate
technology for 6G due to its improvement in spectral efficiency and energy
efficiency. Orthogonal frequency division multiplexing (OFDM) signal is a
mainstream candidate ISAC waveform. However, there are inter-symbol
interference (ISI) and inter-carrier interference (ICI) when the round-trip
delay exceeds the cyclic prefix (CP) duration for OFDM signals, which limits
the maximum sensing range of ISAC system. When detecting a long-range target,
the wide beam inevitably covers the close-range target, of which the echo's
power is much larger than that of the long-range target. In order to tackle the
above problem, a multiple signal classification (MUSIC) and least squares
(LS)-based spatial signal separation method is proposed to separate the echo
signals reflected from different targets. Moreover, a coherent
compensation-based sensing signal processing method at the receiver is proposed
to enhance the signal to interference plus noise power ratio (SINR) of the OFDM
block for generating the range-Doppler map (RDM) with higher SINR. Simulation
results reveal that the proposed method greatly enhances the SINR of RDM by 10
dB for a target at 500 m compared with two-dimensional fast Fourier transform
(2D-FFT) method. Besides, the detection probability is also significantly
improved compared to the benchmarking method.

</details>


### [34] [Towards SISO Bistatic Sensing for ISAC](https://arxiv.org/abs/2508.12614)
*Zhongqin Wang,J. Andrew Zhang,Kai Wu,Min Xu,Y. Jay Guo*

Main category: eess.SP

TL;DR: WiDFS 3.0是一个轻量级双基地SISO感知框架，通过自参考互相关方法和延迟域波束成形技术，在单天线收发器设置下有效抑制多普勒镜像模糊，实现精确的延迟和多普勒估计。


<details>
  <summary>Details</summary>
Motivation: 下一代无线系统中的集成感知与通信(ISAC)在实际部署中常受限于低成本单天线收发器。在双基地SISO设置中，时钟不同步会在CSI中引入随机相位偏移，传统多天线方法无法解决这一问题。

Method: 提出自参考互相关(SRCC)方法用于SISO随机相位去除，并采用延迟域波束成形技术来解决多普勒模糊问题。使用紧凑神经网络处理无模糊的延迟-多普勒-时间特征。

Result: WiDFS 3.0实现了准确的参数估计，性能与甚至优于先前的多天线方法，特别是在延迟估计方面。在单目标和多目标场景下验证，提取的特征显示出强大的感知精度和泛化能力。

Conclusion: 该框架仅需单天线收发器，适合低复杂度部署，在嵌入式友好的MobileViT-XXS模型上表现优异，持续优于CSI幅度、镜像多普勒和多接收器聚合多普勒等传统特征。

Abstract: Integrated Sensing and Communication (ISAC) is a key enabler for
next-generation wireless systems. However, real-world deployment is often
limited to low-cost, single-antenna transceivers. In such bistatic Single-Input
Single-Output (SISO) setup, clock asynchrony introduces random phase offsets in
Channel State Information (CSI), which cannot be mitigated using conventional
multi-antenna methods. This work proposes WiDFS 3.0, a lightweight bistatic
SISO sensing framework that enables accurate delay and Doppler estimation from
distorted CSI by effectively suppressing Doppler mirroring ambiguity. It
operates with only a single antenna at both the transmitter and receiver,
making it suitable for low-complexity deployments. We propose a
self-referencing cross-correlation (SRCC) method for SISO random phase removal
and employ delay-domain beamforming to resolve Doppler ambiguity. The resulting
unambiguous delay-Doppler-time features enable robust sensing with compact
neural networks. Extensive experiments show that WiDFS 3.0 achieves accurate
parameter estimation, with performance comparable to or even surpassing that of
prior multi-antenna methods, especially in delay estimation. Validated under
single- and multi-target scenarios, the extracted ambiguity-resolved features
show strong sensing accuracy and generalization. For example, when deployed on
the embedded-friendly MobileViT-XXS with only 1.3M parameters, WiDFS 3.0
consistently outperforms conventional features such as CSI amplitude, mirrored
Doppler, and multi-receiver aggregated Doppler.

</details>


### [35] [Factorized Disentangled Representation Learning for Interpretable Radio Frequency Fingerprint](https://arxiv.org/abs/2508.12660)
*Yezhuo Zhang,Zinan Zhou,Guangyu Li,Xuanpeng Li*

Main category: eess.SP

TL;DR: 提出了一种解缠表征学习框架，通过学习明确独立的多因素表征来提高无线设备识别的稳健性和可控性


<details>
  <summary>Details</summary>
Motivation: 应对IoT设备快速增长和安全风险，无线电颜纹识别存在因素混合问题，现有域适配方法缺乏明确因素表征，影响下游任务效果

Method: 设计了解缠表征学习框架，包含因素分类和信号重建专门模块，采用特制损失函数促进解缠和支持下游任务

Result: 在两个公开数据集和自收集数据集上达到优异性能，所有模块都提高了分类准确率，并能够精确控制条件生成信号

Conclusion: 该DRL框架为解释性和明确的无线电颜纹表征提供了潜力，通过因素解缠提升了设备识别的稳健性和可控性

Abstract: In response to the rapid growth of Internet of Things (IoT) devices and
rising security risks, Radio Frequency Fingerprint (RFF) has become key for
device identification and authentication. However, various changing factors -
beyond the RFF itself - can be entangled from signal transmission to reception,
reducing the effectiveness of RFF Identification (RFFI). Existing RFFI methods
mainly rely on domain adaptation techniques, which often lack explicit factor
representations, resulting in less robustness and limited controllability for
downstream tasks. To tackle this problem, we propose a novel Disentangled
Representation Learning (DRL) framework that learns explicit and independent
representations of multiple factors, including the RFF. Our framework
introduces modules for disentanglement, guided by the principles of
explicitness, modularity, and compactness. We design two dedicated modules for
factor classification and signal reconstruction, each with tailored loss
functions that encourage effective disentanglement and enhance support for
downstream tasks. Thus, the framework can extract a set of interpretable
vectors that explicitly represent corresponding factors. We evaluate our
approach on two public benchmark datasets and a self-collected dataset. Our
method achieves impressive performance on multiple DRL metrics. We also analyze
the effectiveness of our method on downstream RFFI task and conditional signal
generation task. All modules of the framework contribute to improved
classification accuracy, and enable precise control over conditional generated
signals. These results highlight the potential of our DRL framework for
interpretable and explicit RFFs.

</details>


### [36] [Multi-Domain Supervised Contrastive Learning for UAV Radio-Frequency Open-Set Recognition](https://arxiv.org/abs/2508.12689)
*Ning Gao,Tianrui Zeng,Bowen Chen,Donghong Cai,Shi Jin,Michail Matthaiou*

Main category: eess.SP

TL;DR: 基于多域监督对比学习和改进生成式OpenMax算法的新题方法Open-RFNet，用于无人机开放集识别，在封闭集和开放集识别中都取得了超过95%的高精度


<details>
  <summary>Details</summary>
Motivation: 解决5G-A低空域感知通信网络中非法无人机飞行带来的安全威胁，需要监控非合作无人机

Method: 结合ResNet和TransformerEncoder融合纹理特征和时频位置特征，采用监督寰比学习优化特征表征，并提出改进生成式OpenMax算法IG-OpenMax构建Open-RFNet模型

Result: 在25种无人机类型下，封闭集识别精度达闸95.12%，开放集识别精度达闸96.08%，超越现有基准方法

Conclusion: Open-RFNet框架能够高效监控非合作无人机，为5G-A低空域感知通信网络提供了可靠的安全保障

Abstract: 5G-Advanced (5G-A) has enabled the vibrant development of low altitude
integrated sensing and communication (LA-ISAC) networks. As a core component of
these networks, unmanned aerial vehicles (UAVs) have witnessed rapid growth in
recent years. However, due to the lag in traditional industry regulatory norms,
unauthorized flight incidents occur frequently, posing a severe security threat
to LA-ISAC networks. To surveil the non-cooperative UAVs, in this paper, we
propose a multi-domain supervised contrastive learning (MD-SupContrast)
framework for UAV radio frequency (RF) open-set recognition. Specifically,
first, the texture features and the time-frequency position features from the
ResNet and the TransformerEncoder are fused, and then the supervised
contrastive learning is applied to optimize the feature representation of the
closed-set samples. Next, to surveil the invasive UAVs that appear in real
life, we propose an improved generative OpenMax (IG-OpenMax) algorithm and
construct an open-set recognition model, namely Open-RFNet. According to the
unknown samples, we first freeze the feature extraction layers and then only
retrain the classification layer, which achieves excellent recognition
performance both in closed-set and open-set recognitions. We analyze the
computational complexity of the proposed model. Experiments are conducted with
a large-scale UAV open dataset. The results show that the proposed Open-RFNet
outperforms the existing benchmark methods in terms of recognition accuracy
between the known and the unknown UAVs, as it achieves 95.12% in closed-set and
96.08% in open-set under 25 UAV types, respectively.

</details>


### [37] [LLM-RIMSA: Large Language Models driven Reconfigurable Intelligent Metasurface Antenna Systems](https://arxiv.org/abs/2508.12728)
*Yunsong Huang,Hui-Ming Wang,Qingli Yan,Zhaowei Wang*

Main category: eess.SP

TL;DR: LLM-RIMSA结合大语言模型与新型可重构智能超表面天线架构，通过LLM的跨模态推理和少样本学习能力动态优化天线配置，在6G网络中实现高性能连接和智能无线电环境。


<details>
  <summary>Details</summary>
Motivation: 解决现有可重构智能表面技术在硬件效率、动态控制和可扩展性方面的关键限制，满足6G网络对超大规模连接和智能无线电环境的需求。

Method: 提出LLM-RIMSA框架，集成大语言模型与新型RIMSA架构（采用并行同轴馈电和2D超表面集成），使每个超材料单元能独立调整幅度和相位，利用LLM的跨模态推理和少样本学习能力进行动态优化。

Result: 仿真显示LLM-RIMSA实现最先进性能，在总速率方面优于传统深度学习方法，同时显著降低训练开销。

Conclusion: 该框架为LLM驱动的智能无线电环境开辟了新途径，解决了传统优化和深度学习方法在高维状态空间和训练成本方面的挑战。

Abstract: The evolution of 6G networks demands ultra-massive connectivity and
intelligent radio environments, yet existing reconfigurable intelligent surface
(RIS) technologies face critical limitations in hardware efficiency, dynamic
control, and scalability. This paper introduces LLM-RIMSA, a transformative
framework that integrates large language models (LLMs) with a novel
reconfigurable intelligent metasurface antenna (RIMSA) architecture to address
these challenges. Unlike conventional RIS designs, RIMSA employs parallel
coaxial feeding and 2D metasurface integration, enabling each individual
metamaterial element to independently adjust both its amplitude and phase.
While traditional optimization and deep learning (DL) methods struggle with
high-dimensional state spaces and prohibitive training costs for RIMSA control,
LLM-RIMSA leverages pre-trained LLMs cross-modal reasoning and few-shot
learning capabilities to dynamically optimize RIMSA configurations. Simulations
demonstrate that LLM-RIMSA achieves state-of-the-art performance, outperforming
conventional DL-based methods in sum rate while reducing training overhead. The
proposed framework pave the way for LLM-driven intelligent radio environments.

</details>


### [38] [Range-Angle Likelihood Maps for Indoor Positioning Using Deep Neural Networks](https://arxiv.org/abs/2508.12746)
*Muhammad Ammad,Paul Schwarzbach,Michael Schultz,Oliver Michler*

Main category: eess.SP

TL;DR: 使用ResNet深度学习模型在模拟机舱环境中实现厘米级精度的室内定位，通过超参数优化获得最佳性能


<details>
  <summary>Details</summary>
Motivation: 室内精确定位在机舱环境中与室外导航同样重要，需要高可靠性和准确性的定位技术来确保导航和监控

Method: 利用模拟机舱环境测量数据，将标签与锚点之间的距离和角度映射为残差网格，转换为似然网格图，使用ResNet模型进行训练和位置预测，并进行超参数优化

Result: 通过超参数优化获得最佳模型参数，实现了厘米级精度的定位准确度

Conclusion: 提出的基于ResNet的深度学习方法能够有效解决机舱环境中的高精度室内定位问题

Abstract: Accurate and high precision of the indoor positioning is as important as
ensuring reliable navigation in outdoor environments. Using the
state-of-the-art deep learning models provides better reliability and accuracy
to navigate and monitor the accurate positions in the aircraft cabin
environment. We utilize the simulated aircraft cabin environment measurements
and propose a residual neural network (ResNet) model to predict the accurate
positions inside the cabin. The measurements include the ranges and angles
between a tag and the anchors points which are then mapped onto a grid as range
and angle residuals. These residual maps are then transformed into the
likelihood grid maps where each cell of the grid shows the likelihood of being
a true location. These grid maps along with the true positions are then passed
as inputs to train the ResNet model. Since any deep learning model involve
numerous parameter settings, hyperparameter optimization is performed to get
the optimal parameters for training the model effectively with the highest
accuracy. Once we get the best hyperparameters settings of the model, it is
then trained to predict the positions which provides a centimeter-level
accuracy of the localization.

</details>


### [39] [A Compute&Memory Efficient Model-Driven Neural 5G Receiver for Edge AI-assisted RAN](https://arxiv.org/abs/2508.12892)
*Mahdi Abdollahpour,Marco Bertuletti,Yichao Zhang,Yawei Li,Luca Benini,Alessandro Vanelli-Coralli*

Main category: eess.SP

TL;DR: 基于模型驱动的低复杂度神经网络接收机，适用于MU-MIMO系统，在保持性能的同时大幅降低计算复杂度和参数数量。


<details>
  <summary>Details</summary>
Motivation: 当前AI基带处理方法计算和内存需求高，限制了在RAN边缘部署和向大带宽多天线系统扩展的可扩展性。

Method: 提出一种模型驱动的神经网络基础接收机，支持多种调制方案、带宽、用户数和基站天线数，仅需单个训练模型即可应用。

Result: 在PUSCH处理模拟中，该方案在TBLER性能上超过现有最佳方法，同时将FLOPs减少66倍，可学参数减少396倍。

Conclusion: 该低复杂度接收机方案为6G系统提供了可扩展的边缘部署解决方案，在保持高性能的同时大幅降低资源消耗。

Abstract: Artificial intelligence approaches for base-band processing for radio
receivers have demonstrated significant performance gains. Most of the proposed
methods are characterized by high compute and memory requirements, hindering
their deployment at the edge of the Radio Access Networks (RAN) and limiting
their scalability to large bandwidths and many antenna 6G systems. In this
paper, we propose a low-complexity, model-driven neural network-based receiver,
designed for multi-user multiple-input multiple-output (MU-MIMO) systems and
suitable for implementation at the RAN edge. The proposed solution is compliant
with the 5G New Radio (5G NR), and supports different modulation schemes,
bandwidths, number of users, and number of base-station antennas with a single
trained model without the need for further training. Numerical simulations of
the Physical Uplink Shared Channel (PUSCH) processing show that the proposed
solution outperforms the state-of-the-art methods in terms of achievable
Transport Block Error Rate (TBLER), while reducing the Floating Point
Operations (FLOPs) by 66$\times$, and the learnable parameters by 396$\times$.

</details>


### [40] [Interference-Asymmetric UAV Remote Control Links: Measurements and Performance Evaluation](https://arxiv.org/abs/2508.12941)
*Donggu Lee,Sung Joon Maeng,Ozgur Ozdemir,Mani Bharathi Pandian,Ismail Guvenc*

Main category: eess.SP

TL;DR: 无人机遥控链路存在上行干扰不对称问题，导致HARQ反馈丢失，严重影响下行吞吐量性能


<details>
  <summary>Details</summary>
Motivation: 无人机遥控链路需要可靠安全的连接，但无人机与地面控制单元之间的干扰不对称问题（无人机暴露在更多干扰源下）会导致上行HARQ反馈丢失，进而影响下行吞吐量

Method: 首先使用helikite平台在NC州立大学主校区进行实地测量，然后使用MATLAB LTE和5G工具箱评估HARQ反馈丢失对吞吐量的影响

Result: 数值结果证实上行干扰不对称确实会因HARQ指示器反馈丢失而显著降低吞吐量性能

Conclusion: 无人机遥控链路的上行干扰不对称是一个严重问题，需要通过相应措施来缓解HARQ反馈丢失对系统性能的影响

Abstract: Reliable and secure connectivity is crucial for remote control (RC) and
uncrewed aerial vehicles (UAVs) links. A major problem for UAV RC links is that
interference sources within the coverage may degrade the link quality. Such
interference problems are a higher concern for the UAV than the RC unit on the
ground due to the UAV being in line of sight (LoS) with a larger number of
interference sources. As a result, lost hybrid automatic repeat request (HARQ)
indicators (ACK/NACK) feedback in the uplink (UL, RC to UAV) may degrade the
downlink (DL, UAV to RC) throughput. To get physical evidence for our
interference asymmetry argument, we first conducted a measurement campaign
using a helikite platform at the Main Campus area of NC State University during
the 2024 Packapalooza festival. Subsequently, we evaluated the throughput
impact of the loss of HARQ indicator feedback caused by UL asymmetry using
MATLAB long-term-evolution (LTE) and fifth-generation (5G) toolboxes. Our
numerical results confirm that UL interference asymmetry substantially degrades
the throughput performance due to the loss of HARQ indicator feedback.

</details>


### [41] [A Novel CNN Based Standalone Detector for Faster-than-Nyquist Signaling](https://arxiv.org/abs/2508.12964)
*Osman Tokluoglu,Enver Cavus,Ebrahim Bedeer,Halim Yanikomeroglu*

Main category: eess.SP

TL;DR: 这篇论文提出了一种新的卷积神经网络检测器，用于更快于奈库斯特信号传输，通过结构化固定内核和域知识掩码来有效减少码间干扰。该方法在保持计算效率的同时实现了接近最优的错误率性能。


<details>
  <summary>Details</summary>
Motivation: 传统的FTN信号检测方法如BCJR算法计算复杂度高，而标准CNN架构使用移动内核时对码间干扰的学习效果不佳。需要一种更高效、更准确的检测方法来处理FTN信号中的复杂ISI问题。

Method: 设计了结构化固定卷积内核层，在预定义位置使用固定内核显式学习不同距离处的ISI模式。采用层次滤波器分配策略，在早期层分配更多滤波器处理强度更大的ISI分量，后期层分配更少滤波器处理弱度ISI。结合域知识掩码来提升特征提取效果。

Result: 在压缩因子τ≥0.7时，该检测器实现了接近BCJR算法的最优BER性能。与M-BCJR相比，在BPSK和QPSK下分别减少86%和84%的计算成本。方法同时兼容高阶调制（至64-QAM），在几乎静止多路雷利衰落频道中保持稳健性，并在LDPC编码FTN传输下保持有效性。

Conclusion: 该研究提出的结构化CNN检测器为FTN信号处理提供了一种高效、准确且实用的解决方案。通过结构化内核设计和层次滤波器分配，方法在显著降低计算复杂度的同时维持了优异的检测性能，并体现了强大的适应性和实用性。

Abstract: This paper presents a novel convolutional neural network (CNN)-based detector
for faster-than-Nyquist (FTN) signaling, introducing structured fixed kernel
layers with domain-informed masking to effectively mitigate intersymbol
interference (ISI). Unlike standard CNN architectures that rely on moving
kernels, the proposed approach employs fixed convolutional kernels at
predefined positions to explicitly learn ISI patterns at varying distances from
the central symbol. To enhance feature extraction, a hierarchical filter
allocation strategy is employed, assigning more filters to earlier layers for
stronger ISI components and fewer to later layers for weaker components. This
structured design improves feature representation, eliminates redundant
computations, and enhances detection accuracy while maintaining computational
efficiency. Simulation results demonstrate that the proposed detector achieves
near-optimal bit error rate (BER) performance, comparable to the BCJR algorithm
for the compression factor $\tau \geq 0.7$, while offering up to $46\%$ and
$84\%$ computational cost reduction over M-BCJR for BPSK and QPSK,
respectively. Additional evaluations confirm the method's adaptability to
high-order modulations (up to 64-QAM), resilience in quasi-static multipath
Rayleigh fading channels, and effectiveness under LDPC-coded FTN transmission,
highlighting its robustness and practicality.

</details>


### [42] [Wavefield Correlation Imaging in Arbitrary Media with Inherent Aberration Correction](https://arxiv.org/abs/2508.13017)
*Scott Schoen Jr,Brian Lause,Marko Jakovljevic,Rimon Tadross,Mike Washburn,Anthony E. Samir*

Main category: eess.SP

TL;DR: 本文提出了一种针对超声成像中形态异质性问题的改进方法——异质性波场相关成像（HWCI），通过在成像过程中直接考虑已知的声速分布，相比传统WCI方法实现了30%以上的分辨率提升和约10%的对比度改善。


<details>
  <summary>Details</summary>
Motivation: 超声成像在形态异质性对象（如超重或肥胖患者）中面临挑战，因为传统成像算法在波束形成过程中未考虑这种变化。虽然了解空间变化可以进行算法修正，但会增加计算复杂度。

Method: 扩展了波场相关成像（WCI）方法，使其能够在成像过程中直接处理任意已知的声速分布，从而适应异质性介质。

Result: 在计算机模拟、体外实验和体内实验中验证了方法的可行性，相比传统WCI成像，分辨率提升超过30%，对比度改善约10%。

Conclusion: 异质性波场相关成像（HWCI）具有很高的转化潜力，能够显著提高超声图像的客观质量和临床实用性。

Abstract: Ultrasound (US) imaging is an indispensable tool for diagnostic imaging,
particularly given its cost, safety, and portability profiles compared to other
modalities. However, US is challenged in subjects with morphological
heterogeneity (e.g., those with overweight or obesity), largely because
conventional imaging algorithms do not account for such variation in the
beamforming process. Specific knowledge of the these spatial variations enables
supplemental corrections of these algorithms, but with added computational
complexity. Wavefield correlation imaging (WCI) enables efficient image
formation in the spatial frequency domain that, in its canonical formulation,
assumes a uniform medium. In this work, we present an extension of WCI to
arbitrary known speed-of-sound distributions directly in the image formation
process, and demonstrate its feasibility in silico, in vitro, and in vivo. We
report resolution improvements of over 30% and contrast improvements of order
10% over conventional WCI imaging. Together our results suggest heterogeneous
WCI (HWCI) may have high translational potential to improve the objective
quality, and thus clinical utility, of ultrasound images.

</details>


### [43] [Low-complexity Leakage Minimization Beamforming for Large-scale Multi-user Cell-Free Massive MIMO](https://arxiv.org/abs/2508.13067)
*Iván Alexander Morales Sandoval,Getuar Rexhepi,Kengo Ando,Giuseppe Thadeu Freitas de Abreu*

Main category: eess.SP

TL;DR: 基于分数规划和凹凸凸规划的低复杂度形成波束设计，在绝密速率与计算复杂度之间取得优异平衡


<details>
  <summary>Details</summary>
Motivation: 解决细胞免大览多用户系统中信息泄漏问题，在保证绝密性的同时降低计算复杂度

Method: 利用分数规划(FP)将绝密速率最大化问题重构为可解的凹凸差形式，采用凹凸凸规划(CCP)算法高效求解

Result: 模拟结果显示该方案能够达到与最先进方法相当的绝密速率，同时显著降低计算复杂度并提高收敛速度

Conclusion: 该方法为细胞免大览MIMO系统提供了一种高效的绝密通信解决方案，在性能和复杂度之间实现优异平衡

Abstract: We propose a low-complexity beamforming (BF) design for information leakage
minimization in multi-user (MU) cell-free massive multiple-input
multiple-output (CF-mMIMO) systems. Our approach leverages fractional
programming (FP) to reformulate the secrecy rate maximization problem into a
tractable difference-of-convex form. To efficiently solve the resulting
non-convex problem, we employ the Concave-Convex Procedure (CCP), enabling fast
convergence to a local optimum. Simulation results demonstrate that the
proposed scheme achieves secrecy rates comparable to state-of-the-art (SotA)
methods, while significantly reducing computational complexity and improving
convergence speed.

</details>


### [44] [BeamSeek: Deep Learning-based DOA Estimation for Low-Complexity mmWave Phased Arrays](https://arxiv.org/abs/2508.13075)
*Arav Sharma,Lei Chi,Ari Gebhardt,Alon S. Levin,Timothy R. Hoerning,Sam Keene*

Main category: eess.SP

TL;DR: BeamSeek结合敏捷波束切换和深度学习，在60GHz毫米波系统中实现了更快更准确的DOA估计，相比传统方法平均误差降低8度，特别适合噪声环境。


<details>
  <summary>Details</summary>
Motivation: 传统DOA方法需要直接访问单个天线单元，不适用于现代毫米波系统中普遍采用的模拟或混合波束成形系统。现有敏捷波束切换技术虽然快速但精度和鲁棒性有待提升。

Method: 采用多层感知机(MLP)和专门的数据增强技术来模拟真实传播条件，结合敏捷波束切换技术，在NSF PAWR COSMOS测试平台上进行60GHz实验验证。

Result: 相比基于相关性的基准方法，BeamSeek在不同信噪比水平下均表现优异，平均估计误差最多降低8度，在噪声信道中优势尤其明显。

Conclusion: 该方法特别适合具有多径干扰和硬件约束的实际毫米波部署环境，为低复杂度硬件实现提供了有效的DOA估计解决方案。

Abstract: A novel approach combining agile beam switching with deep learning to enhance
the speed and accuracy of Direction of Arrival (DOA) estimation for
millimeter-wave (mmWave) phased array systems with low-complexity hardware
implementations is proposed and evaluated. Traditional DOA methods requiring
direct access to individual antenna elements are impractical for analog or
hybrid beamforming systems prevalent in modern mmWave implementations. Recent
agile beam switching techniques have demonstrated rapid DOA estimation, but
their accuracy and robustness can be further improved via deep learning.
BeamSeek addresses these limitations by employing a Multi-Layer Perceptron
(MLP) and specialized data augmentation that emulates real-world propagation
conditions. The proposed approach was experimentally validated at 60 GHz using
the NSF PAWR COSMOS testbed, demonstrating significant improvements over a
correlation-based method across various Signal-to-Noise Ratio (SNR) levels.
Results show that BeamSeek achieves up to an 8 degree reduction in average
estimation error compared to this baseline, with particular advantages in noisy
channels. This makes it especially suitable for practical mmWave deployments in
environments characterized by multipath interference and hardware constraints.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [45] [FNH-TTS: A Fast, Natural, and Human-Like Speech Synthesis System with advanced prosodic modeling based on Mixture of Experts](https://arxiv.org/abs/2508.12001)
*Qingliang Meng,Luogeng Xiong,Wei Liang,Limei Yu,Huizhi Liang,Tian Li*

Main category: eess.AS

TL;DR: FNH-TTS系统通过混合专家时长预测器和双多尺度判别器声码器，显著提升了语音合成的自然度、时长预测准确性和合成速度


<details>
  <summary>Details</summary>
Motivation: 解决语音合成中自然度和推理成本的挑战，特别是韵律建模和非自回归模型的伪影问题

Method: 基于VITS系统，引入混合专家时长预测器和具有双多尺度判别器的新型声码器

Result: 在LJSpeech、VCTK和LibriTTS数据集上表现出优越的合成质量、音素时长预测准确性、声码器效果和合成速度

Conclusion: FNH-TTS系统能够生成更接近人类自然语音的韵律模式，在多个维度上优于现有系统

Abstract: Achieving natural and human-like speech synthesis with low inference costs
remains a major challenge in speech synthesis research. This study focuses on
human prosodic patterns and synthesized spectrum harmony, addressing the
challenges of prosody modeling and artifact issues in non-autoregressive
models. To enhance prosody modeling and synthesis quality, we introduce a new
Duration Predictor based on the Mixture of Experts alongside a new Vocoder with
two advanced multi-scale discriminators. We integrated the these new modules
into the VITS system, forming our FNH-TTS system. Our experiments on LJSpeech,
VCTK, and LibriTTS demonstrate the system's superiority in synthesis quality,
phoneme duration prediction, Vocoder results, and synthesis speed. Our prosody
visualization results show that FNH-TTS produces duration predictions that more
closely align with natural human beings than other systems.

</details>


### [46] [MASSLOC: A Massive Sound Source Localization System based on Direction-of-Arrival Estimation](https://arxiv.org/abs/2508.12024)
*Georg K. J. Fischer,Thomas Schaechtle,Moritz Schabinger,Alexander Richter,Ivo Häring,Fabian Höflinger,Stefan J. Rupitsch*

Main category: eess.AS

TL;DR: MASSLOC系统利用稀疏二维阵列几何结构和Zadoff-Chu序列，实现了多声源的精确定位和识别，在混响环境中表现出色


<details>
  <summary>Details</summary>
Motivation: 声学室内定位相比RF方案硬件要求低，基于角度的定位可减少锚节点数量，需要解决多声源并发定位的挑战

Method: 使用稀疏二维阵列几何结构，采用互补Zadoff-Chu序列进行波束成形源识别，结合Perspective-n-Point校准方法

Result: 在混响时间1.6s的挑战性环境中，实现55.7mm中位定位误差和0.84度角度误差，最多同时识别14个声源

Conclusion: MASSLOC系统具有可扩展性和鲁棒性，即使在恶劣声学条件下也能实现高性能多源定位

Abstract: Acoustic indoor localization offers the potential for highly accurate
position estimation while generally exhibiting low hardware requirements
compared to Radio Frequency (RF)-based solutions. Furthermore, angular-based
localization significantly reduces installation effort by minimizing the number
of required fixed anchor nodes. In this contribution, we propose the so-called
MASSLOC system, which leverages sparse two-dimensional array geometries to
localize and identify a large number of concurrently active sources.
Additionally, the use of complementary Zadoff-Chu sequences is introduced to
enable efficient, beamforming-based source identification. These sequences
provide a trade-off between favorable correlation properties and accurate,
unsynchronized direction-of-arrival estimation by exhibiting a spectrally
balanced waveform. The system is evaluated in both a controlled anechoic
chamber and a highly reverberant lobby environment with a reverberation time of
1.6 s. In a laboratory setting, successful direction-of-arrival estimation and
identification of up to 14 simultaneously emitting sources are demonstrated.
Adopting a Perspective-n-Point (PnP) calibration approach, the system achieves
a median three-dimensional localization error of 55.7 mm and a median angular
error of 0.84 deg with dynamic source movement of up to 1.9 mps in the
challenging reverberant environment. The multi-source capability is also
demonstrated and evaluated in that environment with a total of three tags.
These results indicate the scalability and robustness of the MASSLOC system,
even under challenging acoustic conditions.

</details>


### [47] [Cryfish: On deep audio analysis with Large Language Models](https://arxiv.org/abs/2508.12666)
*Anton Mitrofanov,Sergei Novoselov,Tatiana Prisyach,Vladislav Marchevskiy,Arseniy Karelin,Nikita Khmelev,Dmitry Dutov,Stepan Malykh,Igor Agafonov,Aleksandr Nikitin,Oleg Petrov*

Main category: eess.AS

TL;DR: Cryfish是一个集成听觉能力的大型语言模型，通过WavLM音频编码器和transformer连接器将听觉功能整合到Qwen2模型中，在Dynamic SUPERB Phase-2多任务基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着文本大语言模型的发展，研究者希望扩展其多模态感知能力，特别是听觉能力的集成，以处理复杂的语音和声音任务。

Method: 使用WavLM音频编码器提取特征，通过transformer连接器将音频特征整合到Qwen2语言模型中，采用专门的训练策略适应多种听觉任务。

Result: 在专门为听觉模型设计的Dynamic SUPERB Phase-2多任务基准测试中进行了全面评估，并与现有公开模型进行了详细比较分析。

Conclusion: Cryfish成功实现了听觉能力与语言模型的集成，为多模态大语言模型的发展提供了有效解决方案。

Abstract: The recent revolutionary progress in text-based large language models (LLMs)
has contributed to the growth of interest in extending capabilities of such
models to multimodal perception and understanding tasks. Hearing is an
essential capability that is highly desired to be integrated into LLMs.
However, effective integrating listening capabilities into LLMs is a
significant challenge lying in generalizing complex auditory tasks across
speech and sounds. To address these issues, we introduce Cryfish, our version
of auditory-capable LLM. The model integrates WavLM audio-encoder features into
Qwen2 model using a transformer-based connector. Cryfish is adapted to various
auditory tasks through a specialized training strategy. We evaluate the model
on the new Dynamic SUPERB Phase-2 comprehensive multitask benchmark
specifically designed for auditory-capable models. The paper presents an
in-depth analysis and detailed comparison of Cryfish with the publicly
available models.

</details>


### [48] [Arabic ASR on the SADA Large-Scale Arabic Speech Corpus with Transformer-Based Models](https://arxiv.org/abs/2508.12968)
*Branislav Gerazov,Marcello Politi,Sébastien Bratières*

Main category: eess.AS

TL;DR: 研究多个最新语音识别模型在阿拉伯语语音数据集SADA上的性能表现，包括对精调、语言模型、噪声和去噪效果的分析


<details>
  <summary>Details</summary>
Motivation: 评估现有ASR模型在大规模阿拉伯语语音数据集上的表现，特别是在包含多种方言和噪声环境的挑战性场景中

Method: 使用SADA数据集（668小时沙特电视节目音频）评测多个ASR模型，涉及精调、语言模型集成、噪声处理等实验

Result: MMS 1B模型经过SADA精调并配合4-gram语言模型后表现最佳，在清洁集上达到WER 40.9%和CER 17.6%

Conclusion: 精调和语言模型结合可显著提升ASR模型在阿拉伯语语音识别任务上的性能

Abstract: We explore the performance of several state-of-the-art automatic speech
recognition (ASR) models on a large-scale Arabic speech dataset, the SADA
(Saudi Audio Dataset for Arabic), which contains 668 hours of high-quality
audio from Saudi television shows. The dataset includes multiple dialects and
environments, specifically a noisy subset that makes it particularly
challenging for ASR. We evaluate the performance of the models on the SADA test
set, and we explore the impact of fine-tuning, language models, as well as
noise and denoising on their performance. We find that the best performing
model is the MMS 1B model finetuned on SADA with a 4-gram language model that
achieves a WER of 40.9\% and a CER of 17.6\% on the SADA test clean set.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [49] [Prediction of Spotify Chart Success Using Audio and Streaming Features](https://arxiv.org/abs/2508.11632)
*Ian Jacob Cabansag,Paul Ntegeka*

Main category: cs.SD

TL;DR: 基于Spotify流行榜和音乐特征的分类模型，预测歌曲在榜单上的成功概率，树基模型表现最佳，精度达97%


<details>
  <summary>Details</summary>
Motivation: 理解歌曲在Spotify流行榜上升排的因素，以指导营销策略、投资决策和艺术创作

Method: 使用2024年美国Top 200 Spotify日榜和Spotify Web API构建数据集，对14,639首歌曲进行分析，比较逻辑回归、K近邻、随机森林和XGBoost四种模型

Result: 树基模型表现最佳，随机森林和XGBoost的宏F1分数接近0.95，准确度约97%，即使不包含流量数据，仅靠音频特征也保持预测能力

Conclusion: 音频特征模型在A&R挑选、歌单优化和爆歌预测方面具有强大潜力，可在歌曲达到关键流量前提前预测

Abstract: Spotify's streaming charts offer a real-time lens into music popularity,
driving discovery, playlists, and even revenue potential. Understanding what
influences a song's rise in ranks on these charts-especially early on-can guide
marketing efforts, investment decisions, and even artistic direction. In this
project, we developed a classification pipeline to predict a song's chart
success based on its musical characteristics and early engagement data. Using
all 2024 U.S. Top 200 Spotify Daily Charts and the Spotify Web API, we built a
dataset containing both metadata and audio features for 14,639 unique songs.
  The project was structured in two phases. First, we benchmarked four models:
Logistic Regression, K Nearest Neighbors, Random Forest, and XGBoost-using a
standard train-test split. In the second phase, we incorporated
cross-validation, hyperparameter tuning, and detailed class-level evaluation to
ensure robustness. Tree-based models consistently outperformed the rest, with
Random Forest and XGBoost achieving macro F1-scores near 0.95 and accuracy
around 97%.
  Even when stream count and rank history were excluded, models trained solely
on audio attributes retained predictive power. These findings validate the
potential of audio-based modeling in A&R scouting, playlist optimization, and
hit forecasting-long before a track reaches critical mass.

</details>


### [50] [Audio Flamingo Sound-CoT Technical Report: Improving Chain-of-Thought Reasoning in Sound Understanding](https://arxiv.org/abs/2508.11818)
*Zhifeng Kong,Arushi Goel,Joao Felipe Santos,Sreyan Ghosh,Rafael Valle,Wei Ping,Bryan Catanzaro*

Main category: cs.SD

TL;DR: 本文探索了思维链推理在音频语言模型中的应用，提出了AF-Reasoning-Eval评估基准和AF-CoT-Train训练数据集，通过在Audio Flamingo系列模型上进行微调，显著提升了音频理解能力。


<details>
  <summary>Details</summary>
Motivation: 思维链推理在大型语言模型和视觉语言模型中已显示出显著改进，但在音频语言模型中的潜力尚未被充分探索，本文旨在填补这一空白。

Method: 提出了AF-Reasoning-Eval评估基准用于声音推理评估，开发了自动流水线将现有音频问答和分类数据转换为显式推理链，构建了包含124万个样本的AF-CoT-Train训练数据集，并在Audio Flamingo系列模型上进行微调。

Result: 在多个推理基准测试中观察到显著改进，验证了思维链微调在高级声音理解方面的有效性。

Conclusion: 思维链微调对音频语言模型的推理能力提升具有重要作用，为音频理解领域提供了新的研究方向和实践方法。

Abstract: Chain-of-thought reasoning has demonstrated significant improvements in large
language models and vision language models, yet its potential for audio
language models remains largely unexplored. In this technical report, we take a
preliminary step towards closing this gap. For better assessment of sound
reasoning, we propose AF-Reasoning-Eval, a benchmark targeting common-sense
reasoning and the ability to discriminate among closely related choices. To
prepare training corpus for sound reasoning abilities, we propose automatic
pipelines that transform existing audio question answering and classification
data into explicit reasoning chains, yielding AF-CoT-Train with 1.24M samples.
We study the effect of finetuning Audio Flamingo series on AF-CoT-Train and
observe considerable improvements on several reasoning benchmarks, validating
the effectiveness of chain-of-thought finetuning on advanced sound
understanding.

</details>


### [51] [What Matters for Bioacoustic Encoding](https://arxiv.org/abs/2508.11845)
*Marius Miron,David Robinson,Milad Alizadeh,Ellen Gilsenan-McMahon,Gagan Narula,Olivier Pietquin,Matthieu Geist,Emmanuel Chemla,Maddie Cusimano,Felix Effenberger,Masato Hagiwara,Benjamin Hoffman,Sara Keen,Diane Kim,Jane Lawton,Jen-Yu Liu,Aza Raskin*

Main category: cs.SD

TL;DR: 这是一个大规模生物声学编码器研究，通过自监督预训练和监督式后训练组合，在26个数据集上获得了最佳性能，并将发布模型检查点。


<details>
  <summary>Details</summary>
Motivation: 生物声学研究面临标注数据稀缺问题，需要通用的编码器来提取有用表征。以前的编码器存在范围窄局限性、模型架构单一、评估数据集少等问题。

Method: 进行大规模实验研究，涵盖训练数据多样性和规模、模型架构、训练方法等多个方面。采用自监督预训练经验后监督式后训练的组合方法，使用混合生物声学+通用音频语料库。

Result: 在26个数据集上获得了状态之最佳性能，包括物种分类、检测、个体识别、叫声语料库发现等任务。证明了训练数据多样性在两个训练阶段的重要性。

Conclusion: 研究提供了生物声学编码器训练的关键因素和最佳实践，为未来更多数据或更好架构的扩展研究奠定了基础。将发布模型检查点支持进一步研究和应用。

Abstract: Bioacoustics, the study of sounds produced by living organisms, plays a vital
role in conservation, biodiversity monitoring, and behavioral studies. Many
tasks in this field, such as species, individual, and behavior classification
and detection, are well-suited to machine learning. However, they often suffer
from limited annotated data, highlighting the need for a general-purpose
bioacoustic encoder capable of extracting useful representations for diverse
downstream tasks. Such encoders have been proposed before, but are often
limited in scope due to a focus on a narrow range of species (typically birds),
and a reliance on a single model architecture or training paradigm. Moreover,
they are usually evaluated on a small set of tasks and datasets. In this work,
we present a large-scale empirical study that covers aspects of bioacoustics
that are relevant to research but have previously been scarcely considered:
training data diversity and scale, model architectures and training recipes,
and the breadth of evaluation tasks and datasets. We obtain encoders that are
state-of-the-art on the existing and proposed benchmarks. We also identify what
matters for training these encoders, such that this work can be extended when
more data are available or better architectures are proposed. Specifically,
across 26 datasets with tasks including species classification, detection,
individual ID, and vocal repertoire discovery, we find self-supervised
pre-training followed by supervised post-training on a mixed bioacoustics +
general-audio corpus yields the strongest in- and out-of-distribution
performance. We show the importance of data diversity in both stages. To
support ongoing research and application, we will release the model
checkpoints.

</details>


### [52] [Towards Automatic Evaluation and High-Quality Pseudo-Parallel Dataset Construction for Audio Editing: A Human-in-the-Loop Method](https://arxiv.org/abs/2508.11966)
*Yuhang Jia,Hui Wang,Xin Nie,Yujie Guo,Lianru Gao,Yong Qin*

Main category: cs.SD

TL;DR: 这篇论文提出了一个新的音频编辑评估框架，包括主观评测数据集AuditScore和自动评估模型AuditEval，以解决音频编辑领域缺乏高质量数据集和综合评估指标的挑战。


<details>
  <summary>Details</summary>
Motivation: 音频编辑领域缺乏高质量的标准化数据集和全面的评估指标，这严重限制了音频编辑质量的评估和任务本身的改进。

Method: 1）构建包含6,300个样本的主观评测数据集AuditScore，由专业评测者在质量、相关性和准确性三个维度进行注释 2）基于该数据集训练自动MOS评分模型AuditEval 3）利用AuditEval筛选高质量的伪并行数据集

Result: 实验验证了专家知识导向的筛选策略能够生成更高质量的数据，同时也曝露了仅依靠对象指标的局限性。

Conclusion: 该研究为音频编辑领域提供了一个综合的评估框架，包括主观数据集、自动评估模型和高质量数据构建方法，有助于推动音频编辑技术的发展。

Abstract: Audio editing aims to manipulate audio content based on textual descriptions,
supporting tasks such as adding, removing, or replacing audio events. Despite
recent progress, the lack of high-quality benchmark datasets and comprehensive
evaluation metrics remains a major challenge for both assessing audio editing
quality and improving the task itself. In this work, we propose a novel
approach for audio editing task by incorporating expert knowledge into both the
evaluation and dataset construction processes: 1) First, we establish
AuditScore, the first comprehensive dataset for subjective evaluation of audio
editing, consisting of over 6,300 edited samples generated from 7
representative audio editing frameworks and 23 system configurations. Each
sample is annotated by professional raters on three key aspects of audio
editing quality: overall Quality, Relevance to editing intent, and Faithfulness
to original features. 2) Based on this dataset, we train AuditEval, the first
model designed for automatic MOS-style scoring tailored to audio editing tasks.
AuditEval addresses the critical lack of objective evaluation metrics and the
prohibitive cost of subjective assessment in this field. 3) We further leverage
AuditEval to evaluate and filter a large amount of synthetically mixed editing
pairs, constructing a high-quality pseudo-parallel dataset by selecting the
most plausible samples. Objective experiments validate the effectiveness of our
expert-informed filtering strategy in yielding higher-quality data, while also
revealing the limitations of relying solely on objective metrics. The dataset,
codes and tools can be found at: https://github.com/NKU-HLT/AuditEval.

</details>


### [53] [Optimizing Neural Architectures for Hindi Speech Separation and Enhancement in Noisy Environments](https://arxiv.org/abs/2508.12009)
*Arnav Ramamoorthy*

Main category: cs.SD

TL;DR: 本文提出了一种基于DEMUCS模型的优化方案，用于印度语言语音分离和增强，在极端噪音条件下显著提升语音清晰度和可懂性，并通过量化技术适配边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 解决印度语言语音处理在边缘设备上的挑战，克服传统方法的限制，为印度语境提供高效的语音处理解决方案。

Method: 使用DEMUCS模型练习在40万个印度语语音剪辑的数据集，紧密结合U-Net和LSTM层，并使用ESC-50和MS-SNSD进行多样化音响环境增强。通过量化技术优化计算效率。

Result: 使用PESQ和STOI指标评估，显示在极端噪音条件下达到了超越性能，语音清晰度和可懂性得到显著提升。量化技术有效减少了计算资源需求。

Conclusion: 研究证明了定制化AI算法在印度语境下语音处理的有效性，为边缘设备部署提供了可行方案，并指明了边缘架构优化的未来研究方向。

Abstract: This paper addresses the challenges of Hindi speech separation and
enhancement using advanced neural network architectures, with a focus on edge
devices. We propose a refined approach leveraging the DEMUCS model to overcome
limitations of traditional methods, achieving substantial improvements in
speech clarity and intelligibility. The model is fine-tuned with U-Net and LSTM
layers, trained on a dataset of 400,000 Hindi speech clips augmented with
ESC-50 and MS-SNSD for diverse acoustic environments. Evaluation using PESQ and
STOI metrics shows superior performance, particularly under extreme noise
conditions. To ensure deployment on resource-constrained devices like TWS
earbuds, we explore quantization techniques to reduce computational
requirements. This research highlights the effectiveness of customized AI
algorithms for speech processing in Indian contexts and suggests future
directions for optimizing edge-based architectures.

</details>


### [54] [Exploring Self-Supervised Audio Models for Generalized Anomalous Sound Detection](https://arxiv.org/abs/2508.12230)
*Bing Han,Anbai Jiang,Xinhu Zheng,Wei-Qiang Zhang,Jia Liu,Pingyi Fan,Yanmin Qian*

Main category: cs.SD

TL;DR: 本文提出了一种基于自监督预训练模型的机器异常声音检测方法，通过LoRA简化微调、机器感知组适配器和双层对比学习捐失函数，在多个标准数据集上实现了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 机器异常声音检测的通用性能受限于数据收集困难和声学环境的复杂性，需要利用大规模预训练模型来提升性能。

Method: 利用大规模语音和音频数据集训练的自监督预训练模型，采用Fully-Connected LoRA来避免过拟合，提出机器感知组适配器模块，以及使用向量量化和双层对比学习捐失的新目标函数。

Result: 在DCASE 2020-2024五个ASD挑战赛的所有标准数据集上评估，实验结果显示新方法带来了显著的性能提升。

Conclusion: 预训练对于ASD任务仍然具有重要价值，提出的方法有效提升了机器异常声音检测系统的通用性能。

Abstract: Machine anomalous sound detection (ASD) is a valuable technique across
various applications. However, its generalization performance is often limited
due to challenges in data collection and the complexity of acoustic
environments. Inspired by the success of large pre-trained models in numerous
fields, this paper introduces a robust ASD model that leverages self-supervised
pre-trained models trained on large-scale speech and audio datasets. Although
there are inconsistencies between the pre-training datasets and the ASD task,
our findings indicate that pre-training still provides substantial benefits for
ASD. To mitigate overfitting and retain learned knowledge when fine-tuning with
limited data, we explore Fully-Connected Low-Rank Adaptation (LoRA) as an
alternative to full fine-tuning. Additionally, we propose a Machine-aware Group
Adapter module, which enables the model to capture differences between various
machines within a unified framework, thereby enhancing the generalization
performance of ASD systems. To address the challenge of missing attribute
labels, we design a novel objective function that dynamically clusters
unattributed data using vector quantization and optimizes through a dual-level
contrastive learning loss. The proposed methods are evaluated on all benchmark
datasets, including the DCASE 2020-2024 five ASD challenges, and the
experimental results show significant improvements of our new approach and
demonstrate the effectiveness of our proposed strategies.

</details>


### [55] [HuBERT-VIC: Improving Noise-Robust Automatic Speech Recognition of Speech Foundation Model via Variance-Invariance-Covariance Regularization](https://arxiv.org/abs/2508.12292)
*Hyebin Ahn,Kangwook Jang,Hoirin Kim*

Main category: cs.SD

TL;DR: HuBERT-VIC通过VICReg目标函数调整噪声语音表示统计特性，提升语音基础模型在噪声环境下的鲁棒性，相比基线模型在LibriSpeech测试集上取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: 大多数语音基础模型主要在干净数据上训练，在噪声环境下性能会显著下降，需要解决噪声鲁棒性问题

Method: 提出HuBERT-VIC模型，采用方差、不变性和协方差正则化(VICReg)目标函数来调整噪声语音表示统计特性，捕捉多样化声学特征

Result: 相比在噪声语音上预训练的基线模型，在LibriSpeech test-clean上相对性能提升23.3%，在test-other上提升13.2%

Conclusion: VICReg目标函数能有效提升语音基础模型的噪声鲁棒性和泛化能力，在不同类型噪声下都表现良好

Abstract: Noise robustness in speech foundation models (SFMs) has been a critical
challenge, as most models are primarily trained on clean data and experience
performance degradation when the models are exposed to noisy speech. To address
this issue, we propose HuBERT-VIC, a noise-robust SFM with variance,
in-variance, and covariance regularization (VICReg) objectives. These
objectives adjust the statistics of noisy speech representations, enabling the
model to capture diverse acoustic characteristics and improving the
generalization ability across different types of noise. When applied to HuBERT,
our model shows relative performance improvements of 23.3% on LibriSpeech
test-clean and 13.2% on test-other, compared to the baseline model pre-trained
on noisy speech.

</details>


### [56] [Cross-Modal Knowledge Distillation with Multi-Level Data Augmentation for Low-Resource Audio-Visual Sound Event Localization and Detection](https://arxiv.org/abs/2508.12334)
*Qing Wang,Ya Jiang,Hang Chen,Sabato Marco Siniscalchi,Jun Du,Jianqing Gao*

Main category: cs.SD

TL;DR: 通过跨模态知识萃粉和多层次数据增强技术，在低资源音视频声音事件定位检测任务中实现了显著性能提升，相比基线系统获得22%~36%的相对收益


<details>
  <summary>Details</summary>
Motivation: 解决低资源音视频声音事件定位检测任务中的性能挑战，通过知识萃粉技术将单模态模型的知识传递给多模态模型，以提升整体性能

Method: 采用跨模态知识萃粉框架，以音频单模态SELD模型作为教师模型，向音视频学生模型传递输出响应和中间特征表示。结合多层次数据增强技术，随机混合多个网络层的特征，并使用专门为SELD任务设计的损失函数

Result: 在DCASE 2023和2024 SELD数据集上进行了涉及广泛的实验，方法显著提升了AV SELD性能，在整体指标上获得22%~36%的相对收益。该方法达到了与在更大数据集上训练的教师模型相当或更好的结果，超越了DCASE 2023和2024 SELD任务中的最先进方法

Conclusion: 该研究提出的跨模态知识萃粉结合多层次数据增强的方法，在低资源音视频声音事件定位检测任务中表现出艰固的性能，为跨模态学习和知识萃粉领域提供了有效的解决方案

Abstract: This work presents a cross-modal knowledge distillation (CMKD) framework
combined with multi-level data augmentation for low-resource audio-visual (AV)
sound event localization and detection (SELD). An audio-only SELD model acts as
the teacher, transferring knowledge to an AV student model through both output
responses and intermediate feature representations. To enhance learning, data
augmentation is applied by mixing features randomly selected from multiple
network layers and associated loss functions tailored to the SELD task.
Extensive experiments on the DCASE 2023 and 2024 SELD datasets show that the
proposed method significantly improves AV SELD performance, yielding relative
gains of 22%~36% in the overall metric over the baseline. Notably, our approach
achieves results comparable to or better than teacher models trained on much
larger datasets, surpassing state-of-the-art methods on both DCASE 2023 and
2024 SELD tasks.

</details>


### [57] [Exploring the Feasibility of LLMs for Automated Music Emotion Annotation](https://arxiv.org/abs/2508.12626)
*Meng Yang,Jon McCormack,Maria Teresa Llano,Wanchao Su*

Main category: cs.SD

TL;DR: 这研究评估了GPT-4o在音乐情感注释中的可靠性，寻找人工智能注释的经济高效替代方案


<details>
  <summary>Details</summary>
Motivation: 现有音乐情感注释依赖人工标注，成本高效率低，限制了注释数据的规模

Method: 使用GPT-4o对GiantMIDI-Piano数据集进行四象限激活度-价值观注释，与3名人类专家注释进行对比

Result: GPT注释准确率暂较人类专家差，但其可靠性在专家之间的自然分歧范围内

Conclusion: 虽然GPT目前性能较人类差，但其成本效益和效率使得它成为音乐情感注释的有前景可扩展方案

Abstract: Current approaches to music emotion annotation remain heavily reliant on
manual labelling, a process that imposes significant resource and labour
burdens, severely limiting the scale of available annotated data. This study
examines the feasibility and reliability of employing a large language model
(GPT-4o) for music emotion annotation. In this study, we annotated
GiantMIDI-Piano, a classical MIDI piano music dataset, in a four-quadrant
valence-arousal framework using GPT-4o, and compared against annotations
provided by three human experts. We conducted extensive evaluations to assess
the performance and reliability of GPT-generated music emotion annotations,
including standard accuracy, weighted accuracy that accounts for inter-expert
agreement, inter-annotator agreement metrics, and distributional similarity of
the generated labels.
  While GPT's annotation performance fell short of human experts in overall
accuracy and exhibited less nuance in categorizing specific emotional states,
inter-rater reliability metrics indicate that GPT's variability remains within
the range of natural disagreement among experts. These findings underscore both
the limitations and potential of GPT-based annotation: despite its current
shortcomings relative to human performance, its cost-effectiveness and
efficiency render it a promising scalable alternative for music emotion
annotation.

</details>


### [58] [MATPAC++: Enhanced Masked Latent Prediction for Self-Supervised Audio Representation Learning](https://arxiv.org/abs/2508.12709)
*Aurian Quelennec,Pierre Chouteau,Geoffroy Peeters,Slim Essid*

Main category: cs.SD

TL;DR: 通过集成多重选择学习(MCL)来显式模型预测模糊性，改善MATPAC系统的表征学习性能，在AudioSet和多丫游任务上达到最先进水平


<details>
  <summary>Details</summary>
Motivation: 现有的掩码潜在预测SSL方法对预测器模块的作用关注不够，而音频内容本身存在多重声音源的模糊性，需要更好地处理这种预测不确定性

Method: 在MATPAC系统基础上集成多重选择学习(MCL)，显式模型预测模糊性，改进预测和无监督分类预文任务

Result: 在AudioSet上细调时达到最先进水平，在多丫游任务上获得总体最佳成绩，在音乐数据上训练时达到最先进性能且效率显著提高

Conclusion: 集成MCL能够有效地处理音频预测的模糊性，显著提升表征学习质量，为音频SSL预文任务设计提供了新的视角

Abstract: Masked latent prediction has emerged as a leading paradigm in self-supervised
learning (SSL), especially for general audio and music representation learning.
While recent methods have demonstrated strong performance, the role of the
predictor module used at the output of such SSL systems remains mainly
overlooked, despite being crucial for solving the pretext task at hand. In
particular, this module should be able to deal with the ambiguity inherent in
audio content, especially when it is composed of multiple sound sources. This
work proposes a novel enhancement: integrating Multiple Choice Learning (MCL)
to explicitly model prediction ambiguity and improve representation quality. We
build on top of the recently proposed MATPAC system, improving its prediction
and unsupervised classification pretext tasks with MCL. We extensively evaluate
our method, MATPAC++, through both linear probing across multiple downstream
tasks and fine-tuning on AudioSet, employing a unified protocol that enables
rigorous and fair comparisons with state-of-the-art SSL approaches. Results
show that our proposal achieves state-of-the-art when fine-tuned on AudioSet
and overall state-of-the-art scores on downstream tasks. Additionally, we
examine domain specialisation by training exclusively on music data, where our
model achieves state-of-the-art performance with significantly improved
efficiency.

</details>


### [59] [FoleySpace: Vision-Aligned Binaural Spatial Audio Generation](https://arxiv.org/abs/2508.12918)
*Lei Zhao,Rujin Chen,Chi Zhang,Xiao-Lei Zhang,Xuelong Li*

Main category: cs.SD

TL;DR: FoleySpace是一个视频到双耳音频生成框架，通过视觉信息引导生成沉浸式空间一致的立体声，解决了现有V2A技术缺乏空间感知的问题


<details>
  <summary>Details</summary>
Motivation: 现有视频到音频技术主要关注单声道音频生成，缺乏空间感知能力，而能够提供更强沉浸感的双耳空间音频生成技术研究不足

Method: 开发声音源估计方法确定视频帧中的声源2D坐标和深度，通过坐标映射机制转换为3D轨迹，结合预训练V2A模型生成的单声道音频，作为扩散模型的输入条件来生成空间一致的双耳音频

Result: 实验结果表明该方法在空间感知一致性方面优于现有方法，有效提升了音视频体验的沉浸质量

Conclusion: FoleySpace框架成功实现了视频到双耳音频的生成，为沉浸式音视频体验提供了有效的技术解决方案

Abstract: Recently, with the advancement of AIGC, deep learning-based video-to-audio
(V2A) technology has garnered significant attention. However, existing research
mostly focuses on mono audio generation that lacks spatial perception, while
the exploration of binaural spatial audio generation technologies, which can
provide a stronger sense of immersion, remains insufficient. To solve this
problem, we propose FoleySpace, a framework for video-to-binaural audio
generation that produces immersive and spatially consistent stereo sound guided
by visual information. Specifically, we develop a sound source estimation
method to determine the sound source 2D coordinates and depth in each video
frame, and then employ a coordinate mapping mechanism to convert the 2D source
positions into a 3D trajectory. This 3D trajectory, together with the monaural
audio generated by a pre-trained V2A model, serves as a conditioning input for
a diffusion model to generate spatially consistent binaural audio. To support
the generation of dynamic sound fields, we constructed a training dataset based
on recorded Head-Related Impulse Responses that includes various sound source
movement scenarios. Experimental results demonstrate that the proposed method
outperforms existing approaches in spatial perception consistency, effectively
enhancing the immersive quality of the audio-visual experience.

</details>

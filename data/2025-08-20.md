<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 6]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.SD](#cs.SD) [Total: 4]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [CKM-Assisted Physical-Layer Security for Resilience Against Unknown Eavesdropping Location](https://arxiv.org/abs/2508.13681)
*Ladan Khaloopour,Matthias Hollick,Vahid Jamali*

Main category: eess.SP

TL;DR: 利用信道知识地图(CKM)实现毫米波多波束安全传输，在不假设窃听者位置的情况下最大化绝对保密率


<details>
  <summary>Details</summary>
Motivation: 传统物理层安全方法需要知道窃听者的位置或信道状态信息，这在实际中往往不可得。CKM作为一种新兴的数据驱动工具，能够捕捉对无线信道的认知，为提升物理层安全提供了新途径

Method: 采用高定向性毫米波传输，将保密消息联合编码在多个波束上。利用CKM推导出时间和功率分配算法，在最坏窃听位置场景下优化保密性能

Result: 提出了基于CKM的波束时间和功率分配算法，能够在不知道窃听者具体位置的情况下实现物理层安全

Conclusion: CKM为物理层安全提供了新的解决方案，特别是在毫米波系统中，通过多波束联合编码和智能资源分配，可以有效对抗被动窃听攻击

Abstract: Channel Knowledge Map (CKM) is an emerging data-driven toolbox that captures
our awareness of the wireless channel and enables efficient communication and
resource allocation beyond the state of the art. In this work, we consider CKM
for improving physical-layer security (PLS) in the presence of a passive
eavesdropper (Eve), without making any assumptions about Eve's location or
channel state information (CSI). We employ highly directional mmWave
transmissions, with the confidential message jointly encoded across multiple
beams. By exploiting CKM, we derive an algorithm for time and power allocation
among the beams that maximizes the absolute secrecy rate under the worst-case
scenario for Eve's location.

</details>


### [2] [Airy beams for near-field communications: Fundamentals, potentials, and limitations](https://arxiv.org/abs/2508.13714)
*Donatella Darsena,Francesco Verde,Marco Di Renzo,Vincenzo Galdi*

Main category: eess.SP

TL;DR: 这篇论文研究了近场区域中的Airy光束在下一代无线网络中的应用，对比了Airy光束和Gauss光束在非视线传播情况下的性能优势。


<details>
  <summary>Details</summary>
Motivation: 随着下一代无线网络中大口径天线和高频传输的采用，近场区域扩大，这为使用非平面波前瞲的Airy光束提供了新的机会。Airy光束具有自加速、自恢复和差行免费等优异特性。

Method: 首先分析了连续口径场分布辐射自加速光束的基本原理，然后解决了有限能量和空间截断导致的指数衰减问题，并研究了自由空间传播特性。重点研究了非视线场景下的传播行为，并与Gauss光束进行对比。

Result: 理论和数值结果显示，在某些非视线通道中，如果Airy光束的关键特性（沿抛物线轨迹自加速和差行免费传播）能够大体保持，那么它们可能比Gauss光束更有性能优势。这需要传输口径中有光清视线的部分充分大。

Conclusion: Airy光束在近场区域的非视线传播中显示出潜在的性能优势，特别是在保持其自加速和差行免费特性的情况下。这为下一代无线通信系统的设计提供了新的可能性。

Abstract: In next-generation wireless networks, the combination of electrically large
radiating apertures and high-frequency transmission extends the radiating
near-field region around the transmitter. In this region, unlike in the far
field, the wavefront is nonplanar, which provides additional degrees of freedom
to shape and steer the transmitted beam in a desired manner. In this paper, we
focus on Airy beams, which may exhibit several highly desirable properties in
the near-field region. Ideally, these beams follow self-accelerating (curved)
trajectories, demonstrate resilience to perturbations through self-healing, and
maintain a consistent intensity profile across all planes perpendicular to the
propagation direction, making them effectively diffraction-free. Specifically,
we first present the underlying principles of self-accelerating beams radiated
by continuous aperture field distributions. We then address several challenges
regarding the generation of Airy beams, including their exponential decay due
to finite energy constraints and spatial truncation of the aperture. Moreover,
we examine their free-space propagation characteristics. The second part of the
paper focuses on the propagation behavior of Airy beams in non-line-of-sight
(NLoS) scenarios. A comparison is also presented between Airy beams and
Gaussian beams. Our theoretical and numerical results show that Airy beams may
offer a performance advantage over Gaussian beams in certain NLoS channels,
provided that their key properties are largely preserved, specifically,
self-acceleration along a parabolic trajectory and diffraction-free
propagation. In the presence of an obstacle, this requires that the portion of
the transmit aperture with a clear line-of-sight to the receiver is
sufficiently large.

</details>


### [3] [Joint AP Selection and Power Allocation for Unicast-Multicast Cell-Free Massive MIMO](https://arxiv.org/abs/2508.13771)
*Mustafa S. Abbas,Zahra Mobini,Hien Quoc Ngo,Hyundong Shin,Michail Matthaiou*

Main category: eess.SP

TL;DR: 本文研究了支持单播和多播传输的无蜂窝大规模MIMO系统，推导了频谱效率的闭式表达式，并提出了基于APG的联合AP选择和功率分配优化算法，显著提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 随着物联网等无线系统的发展，联合单播和多播传输变得越来越重要。现有系统需要同时支持这两种传输类型，特别是多播服务多个用户组，这带来了新的技术挑战和优化需求。

Method: 推导了零迫和最大比预编码下频谱效率的精确闭式表达式，构建了加权和频谱效率最大化问题，考虑AP最大发射功率、前传容量限制和服务质量约束，提出了基于加速投影梯度(APG)的算法和基于连续凸近似(SCA)的基准算法。

Result: 仿真结果表明，所提出的联合优化方法在各种系统设置和预编码策略下显著提升了加权和频谱效率。APG算法在保持竞争性能的同时实现了显著的复杂度降低。

Conclusion: 该研究为大规模实际部署提供了高效的解决方案，APG算法特别适合大规模系统，在性能和复杂度之间取得了良好平衡。

Abstract: Joint unicast and multicast transmissions are becoming increasingly important
in practical wireless systems, such as Internet of Things networks. This paper
investigates a cell-free massive multiple-input multiple-output system that
simultaneously supports both transmission types, with multicast serving
multiple groups. Exact closed-form expressions for the achievable downlink
spectral efficiency (SE) of both unicast and multicast users are derived for
zero-forcing and maximum ratio precoding designs. Accordingly, a weighted sum
SE (SSE) maximization problem is formulated to jointly optimize the access
point (AP) selection and power allocation. The optimization framework accounts
for practical constraints, including the maximum transmit power per AP,
fronthaul capacity limitations between APs and the central processing unit, and
quality-of-service requirements for all users. The resulting non-convex
optimization problem is reformulated into a tractable structure, and an
accelerated projected gradient (APG)-based algorithm is developed to
efficiently obtain near-optimal solutions. As a performance benchmark, a
successive convex approximation (SCA)-based algorithm is also implemented.
Simulation results demonstrate that the proposed joint optimization approach
significantly enhances the SSE across various system setups and precoding
strategies. In particular, the APG-based algorithm achieves substantial
complexity reduction while maintaining competitive performance, making it
well-suited for large-scale practical deployments.

</details>


### [4] [Robust Optimization for Movable Antenna-aided Cell-Free ISAC with Time Synchronization Errors](https://arxiv.org/abs/2508.13818)
*Yue Xiu,Yang Zhao,Ran Yang,Wanting Lyu,Dusit Niyato,Dong In Kim,Guangyi Liu,Ning Wei*

Main category: eess.SP

TL;DR: 提出基于可移动天线(MAs)的CF-ISAC架构，通过空间分集增强通信速率、保持感知精度并减少时间同步误差影响，使用流形优化和元强化学习算法解决复杂非凸优化问题。


<details>
  <summary>Details</summary>
Motivation: 无细胞集成感知与通信(CF-ISAC)系统是6G网络的有前景技术，但时间同步(TS)误差严重制约其发展，需要新的架构来克服这一挑战。

Method: 提出MA辅助的CF-ISAC架构，推导最坏情况CRLB下界，设计联合AP波束成形和MA位置优化框架，使用流形优化(MO)和MA元强化学习(MA-MetaRL)算法。

Result: 仿真结果表明，所提鲁棒优化算法显著提高检测精度，对TS误差具有强鲁棒性，相比传统固定天线技术获得更高系统容量。

Conclusion: MA辅助的CF-ISAC架构能有效提升系统性能，验证了其在应对时间同步误差方面的有效性，为6G网络发展提供了有前景的解决方案。

Abstract: The cell-free integrated sensing and communication (CF-ISAC) system, which
effectively mitigates intra-cell interference and provides precise sensing
accuracy, is a promising technology for future 6G networks. However, to fully
capitalize on the potential of CF-ISAC, accurate time synchronization (TS)
between access points (APs) is critical. Due to the limitations of current
synchronization technologies, TS errors have become a significant challenge in
the development of the CF-ISAC system. In this paper, we propose a novel
CF-ISAC architecture based on movable antennas (MAs), which exploits spatial
diversity to enhance communication rates, maintain sensing accuracy, and reduce
the impact of TS errors. We formulate a worst-case sensing accuracy
optimization problem for TS errors to address this challenge, deriving the
worst-case Cram\'er-Rao lower bound (CRLB). Subsequently, we develop a joint
optimization framework for AP beamforming and MA positions to satisfy
communication rate constraints while improving sensing accuracy. A robust
optimization framework is designed for the highly complex and non-convex
problem. Specifically, we employ manifold optimization (MO) to solve the
worst-case sensing accuracy optimization problem. Then, we propose an
MA-enabled meta-reinforcement learning (MA-MetaRL) to design optimization
variables while satisfying constraints on MA positions, communication rate, and
transmit power, thereby improving sensing accuracy. The simulation results
demonstrate that the proposed robust optimization algorithm significantly
improves the accuracy of the detection and is strong against TS errors.
Moreover, compared to conventional fixed position antenna (FPA) technologies,
the proposed MA-aided CF-ISAC architecture achieves higher system capacity,
thus validating its effectiveness.

</details>


### [5] [Distributed Distortion-Aware Robust Optimization for Movable Antenna-aided Cell-Free ISAC Systems](https://arxiv.org/abs/2508.13839)
*Yue Xiu,Yang Zhao,Ran Yang,Zheng Dong,Wanting Lyu,Zeyuan Zhang,Dusit Niyato,Guangyi Liu,Ning Wei*

Main category: eess.SP

TL;DR: 基于可移动天线的无细胞集成感知通信系统，通过分布式夸张感知优化框架和自注意卷积图神经网络算法，有效缓解功放非线性扩展对通信和感知性能的影响


<details>
  <summary>Details</summary>
Motivation: 无细胞集成感知通信架构在实际部署中遇到硬件缺陷问题，特别是功放的非线性扩展造成的性能劣化，需要找到有效的缓解方案

Method: 建立第三阶无记忆多项式模型描述功放非线性，设计分布式夸张感知优化框架，采用逐次凸近似法估计扩展系数，并通过MA-enabled SACGNN算法聚合优化波束成型和天线位置

Result: 模拟实验表明该方法在存在扩展的情况下显著改善了通信-感知交换性能，在稳健性和容量方面都超过了固定位置天线的基准方案

Conclusion: 可移动天线辅助的无细胞集成感知通信系统能够有效应对硬件缺陷带来的挑战，为6G网络提供了更加稳健和高效的解决方案

Abstract: The cell-free integrated sensing and communication (CF-ISAC) architecture is
a promising enabler for 6G, offering spectrum efficiency and ubiquitous
coverage. However, real deployments suffer from hardware impairments,
especially nonlinear distortion from power amplifiers (PAs), which degrades
both communication and sensing. To address this, we propose a movable antenna
(MA)-aided CF-ISAC system that mitigates distortion and enhances robustness.
The PAs nonlinearities are modeled by a third-order memoryless polynomial,
where the third-order distortion coefficients (3RDCs) vary across access points
(APs) due to hardware differences, aging, and environmental conditions. We
design a distributed distortion-aware worst-case robust optimization framework
that explicitly incorporates uncertainty in 3RDCs. First, we analyze the
worst-case impact of PA distortion on both the Cramer-Rao lower bound (CRLB)
and communication rate. Then, to address the resulting non-convexity, we apply
successive convex approximation (SCA) for estimating the 3RDCs. With these, we
jointly optimize beamforming and MA positions under transmit power and sensing
constraints. To efficiently solve this highly non-convex problem, we develop an
MA-enabled self-attention convolutional graph neural network (SACGNN)
algorithm. Simulations demonstrate that our method substantially enhances the
communication-sensing trade-off under distortion and outperforms fixed-position
antenna baselines in terms of robustness and capacity, thereby highlighting the
advantages of MA-aided CF-ISAC systems.

</details>


### [6] [Evaluating Particle Filtering for RSS-Based Target Localization under Varying Noise Levels and Sensor Geometries](https://arxiv.org/abs/2508.13937)
*Halim Lee,Jongmin Park,Kwansik Park*

Main category: eess.SP

TL;DR: 这篇论文系统性分析了基于粒子筛波的RSS目标定位算法，在不同传感器配置和噪声条件下较传统三角测量方法提供更高的定位精度


<details>
  <summary>Details</summary>
Motivation: RSS洞定位价格低廉、耗电低、部署简单，但现有研究缺乏对粒子筛波在不同传感器几何配置和噪声水平下性能的系统分析

Method: 设计和评估了一种用于静止目标定位的粒子筛波算法，并与传统RSS三角测量方法在不同传感器配置和噪声条件下进行比较

Result: 模拟结果显示，粒子筛波比三角测量方法提供更准确的目标定位，尤其在传感器几何配置不利和高RSS噪声场景下

Conclusion: 粒子筛波算法在RSS基础的目标定位中表现优异，特别适用于复杂环境和高噪声情况

Abstract: Target localization is a critical task in various applications, such as
search and rescue, surveillance, and wireless sensor networks. When a target
emits a radio frequency (RF) signal, spatially distributed sensors can collect
signal measurements to estimate the target's location. Among various
measurement modalities, received signal strength (RSS) is particularly
attractive due to its low cost, low power consumption, and ease of deployment.
While particle filtering has previously been applied to RSS-based target
localization, few studies have systematically analyzed its performance under
varying sensor geometries and RSS noise levels. This paper addresses this gap
by designing and evaluating a particle filtering algorithm for localizing a
stationary target. The proposed method is compared with a conventional
RSS-based trilateration approach across different sensor configurations and
noise conditions. Simulation results indicate that particle filtering provides
more accurate target localization than trilateration, particularly in scenarios
with unfavorable sensor geometries and high RSS noise.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [7] [Rapidly Adapting to New Voice Spoofing: Few-Shot Detection of Synthesized Speech Under Distribution Shifts](https://arxiv.org/abs/2508.13320)
*Ashi Garg,Zexin Cai,Henry Li Xinyuan,Leibny Paola García-Perera,Kevin Duh,Sanjeev Khudanpur,Matthew Wiesner,Nicholas Andrews*

Main category: eess.AS

TL;DR: 通过自注意力原型网络实现少样本学习，提升语音合成检测在分布偏移条件下的适应性能


<details>
  <summary>Details</summary>
Motivation: 解决语音合成检测在训练数据与测试数据分布不一致时的性能下降问题

Method: 提出自注意力原型网络，通过少量样本快速适应分布偏移

Result: 在分布偏移条件下，仅需10个样本即可实现32%相对EER提升，在ASVspoof 2021数据集上提升20%

Conclusion: 少样本学习方法能够有效应对语音合成检测中的分布偏移挑战

Abstract: We address the challenge of detecting synthesized speech under distribution
shifts -- arising from unseen synthesis methods, speakers, languages, or audio
conditions -- relative to the training data. Few-shot learning methods are a
promising way to tackle distribution shifts by rapidly adapting on the basis of
a few in-distribution samples. We propose a self-attentive prototypical network
to enable more robust few-shot adaptation. To evaluate our approach, we
systematically compare the performance of traditional zero-shot detectors and
the proposed few-shot detectors, carefully controlling training conditions to
introduce distribution shifts at evaluation time. In conditions where
distribution shifts hamper the zero-shot performance, our proposed few-shot
adaptation technique can quickly adapt using as few as 10 in-distribution
samples -- achieving upto 32% relative EER reduction on deepfakes in Japanese
language and 20% relative reduction on ASVspoof 2021 Deepfake dataset.

</details>


### [8] [End-to-End Audio-Visual Learning for Cochlear Implant Sound Coding in Noisy Environments](https://arxiv.org/abs/2508.13576)
*Meng-Ping Lin,Enoch Hsin-Ho Huang,Shao-Yi Chien,Yu Tsao*

Main category: eess.AS

TL;DR: 提出了一种新型噪声抑制人工耳蜗系统AVSE-ECS，通过音频-视觉语音增强模型作为预处理模块，结合深度学习电极编码策略，在嘈杂环境中显著提升语音理解能力


<details>
  <summary>Details</summary>
Motivation: 尽管人工耳蜗技术已有进步，但在噪声或混响环境中语音理解仍然困难，深度学习技术为提升人工耳蜗声音编码能力提供了新的机会

Method: 采用音频-视觉语音增强(AVSE)模型作为预处理模块，结合基于深度学习的ElectrodeNet-CS(ECS)声音编码策略，使用联合训练方法构建端到端的人工耳蜗系统

Result: 实验结果表明，在噪声条件下，所提方法优于之前的ECS策略，客观语音清晰度得分得到改善

Conclusion: 本研究证明了使用深度学习将AVSE模块集成到端到端人工耳蜗系统的可行性和潜力

Abstract: The cochlear implant (CI) is a remarkable biomedical device that successfully
enables individuals with severe-to-profound hearing loss to perceive sound by
converting speech into electrical stimulation signals. Despite advancements in
the performance of recent CI systems, speech comprehension in noisy or
reverberant conditions remains a challenge. Recent and ongoing developments in
deep learning reveal promising opportunities for enhancing CI sound coding
capabilities, not only through replicating traditional signal processing
methods with neural networks, but also through integrating visual cues as
auxiliary data for multimodal speech processing. Therefore, this paper
introduces a novel noise-suppressing CI system, AVSE-ECS, which utilizes an
audio-visual speech enhancement (AVSE) model as a pre-processing module for the
deep-learning-based ElectrodeNet-CS (ECS) sound coding strategy. Specifically,
a joint training approach is applied to model AVSE-ECS, an end-to-end CI
system. Experimental results indicate that the proposed method outperforms the
previous ECS strategy in noisy conditions, with improved objective speech
intelligibility scores. The methods and findings in this study demonstrate the
feasibility and potential of using deep learning to integrate the AVSE module
into an end-to-end CI system

</details>


### [9] [MMAU-Pro: A Challenging and Comprehensive Benchmark for Holistic Evaluation of Audio General Intelligence](https://arxiv.org/abs/2508.13992)
*Sonal Kumar,Šimon Sedláček,Vaibhavi Lokegaonkar,Fernando López,Wenyi Yu,Nishit Anand,Hyeonggon Ryu,Lichang Chen,Maxim Plička,Miroslav Hlaváček,William Fineas Ellingwood,Sathvik Udupa,Siyuan Hou,Allison Ferner,Sara Barahona,Cecilia Bolaños,Satish Rahi,Laura Herrera-Alarcón,Satvik Dixit,Siddhi Patil,Soham Deshmukh,Lasha Koroshinadze,Yao Liu,Leibny Paola Garcia Perera,Eleni Zanou,Themos Stafylakis,Joon Son Chung,David Harwath,Chao Zhang,Dinesh Manocha,Alicia Lozano-Diez,Santosh Kesiraju,Sreyan Ghosh,Ramani Duraiswami*

Main category: eess.AS

TL;DR: MMAU-Pro是一个全面的音频智能基准测试，包含5,305个音频问答实例，涵盖49种技能，评估22个领先AI模型后发现现有模型在音频理解方面表现接近随机水平。


<details>
  <summary>Details</summary>
Motivation: 音频理解（包括语音、非语音声音和音乐）对于实现人类水平智能至关重要，但现有评估方法不够全面，需要更全面的基准来评估AI系统的音频智能。

Method: 创建MMAU-Pro基准，包含来自真实环境的音频数据和专家生成的问题-答案对，涵盖49种独特技能和多个复杂维度，包括长音频理解、空间音频推理、多音频理解等。

Result: 评估22个领先的多模态AI模型，发现即使是Gemini 2.5 Flash和Audio Flamingo 3等最先进模型也仅达到59.2%和51.7%的准确率，在多个类别中接近随机表现。

Conclusion: 当前AI系统在音频理解方面存在显著局限性，该基准为社区提供了改进AI系统音频通用智能的具体方向和可操作的见解。

Abstract: Audio comprehension-including speech, non-speech sounds, and music-is
essential for achieving human-level intelligence. Consequently, AI agents must
demonstrate holistic audio understanding to qualify as generally intelligent.
However, evaluating auditory intelligence comprehensively remains challenging.
To address this gap, we introduce MMAU-Pro, the most comprehensive and
rigorously curated benchmark for assessing audio intelligence in AI systems.
MMAU-Pro contains 5,305 instances, where each instance has one or more audios
paired with human expert-generated question-answer pairs, spanning speech,
sound, music, and their combinations. Unlike existing benchmarks, MMAU-Pro
evaluates auditory intelligence across 49 unique skills and multiple complex
dimensions, including long-form audio comprehension, spatial audio reasoning,
multi-audio understanding, among others. All questions are meticulously
designed to require deliberate multi-hop reasoning, including both
multiple-choice and open-ended response formats. Importantly, audio data is
sourced directly ``from the wild" rather than from existing datasets with known
distributions. We evaluate 22 leading open-source and proprietary multimodal AI
models, revealing significant limitations: even state-of-the-art models such as
Gemini 2.5 Flash and Audio Flamingo 3 achieve only 59.2% and 51.7% accuracy,
respectively, approaching random performance in multiple categories. Our
extensive analysis highlights specific shortcomings and provides novel
insights, offering actionable perspectives for the community to enhance future
AI systems' progression toward audio general intelligence. The benchmark and
code is available at https://sonalkum.github.io/mmau-pro.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [10] [Is Transfer Learning Necessary for Violin Transcription?](https://arxiv.org/abs/2508.13516)
*Yueh-Po Peng,Ting-Kang Wang,Li Su,Vincent K. M. Cheung*

Main category: cs.SD

TL;DR: 通过在中等规模小提琴数据集上从头训练，可以达到与基于钢琴预训练模型细调相竞争或更优的小提琴自动诗音转换性能


<details>
  <summary>Details</summary>
Motivation: 小提琴自动诗音转换领域因注释数据有限而发展迟缓，常用方法是对其他任务的预训练模型进行细调，但在音色和发音方式存在差异的情况下这种转移效果不明

Method: 采用钢琴诗音转换架构不做任何修改，在MOSA数据集（约30小时对齐小提琴录音）上从头训练

Result: 在URMP和Bach10数据集上的实验显示，从头训练的模型达到了与细调预训练模型相竞争或更优的性能

Conclusion: 强大的小提琴自动诗音转换可以不依赖钢琴预训练表征，强调了专门为某种乐器收集和扩充数据的重要性

Abstract: Automatic music transcription (AMT) has achieved remarkable progress for
instruments such as the piano, largely due to the availability of large-scale,
high-quality datasets. In contrast, violin AMT remains underexplored due to
limited annotated data. A common approach is to fine-tune pretrained models for
other downstream tasks, but the effectiveness of such transfer remains unclear
in the presence of timbral and articulatory differences. In this work, we
investigate whether training from scratch on a medium-scale violin dataset can
match the performance of fine-tuned piano-pretrained models. We adopt a piano
transcription architecture without modification and train it on the MOSA
dataset, which contains about 30 hours of aligned violin recordings. Our
experiments on URMP and Bach10 show that models trained from scratch achieved
competitive or even superior performance compared to fine-tuned counterparts.
These findings suggest that strong violin AMT is possible without relying on
pretrained piano representations, highlighting the importance of
instrument-specific data collection and augmentation strategies.

</details>


### [11] [Leveraging Mamba with Full-Face Vision for Audio-Visual Speech Enhancement](https://arxiv.org/abs/2508.13624)
*Rong Chao,Wenze Ren,You-Jin Li,Kuo-Hsuan Hung,Sung-Feng Huang,Szu-Wei Fu,Wen-Huang Cheng,Yu Tsao*

Main category: cs.SD

TL;DR: AVSEMamba是一个基于Mamba的音频-视觉语音增强模型，通过整合全脸视觉线索来解决多说话人环境中的鸡尾酒会问题，在AVSEC-4挑战赛中取得了单声道排行榜第一名的成绩。


<details>
  <summary>Details</summary>
Motivation: 现有的Mamba模型如SEMamba仅限于单说话人场景，在复杂的多说话人环境（如鸡尾酒会问题）中表现不佳，需要引入视觉信息来提升目标语音提取的准确性。

Method: 提出AVSEMamba模型，将全脸视觉线索与基于Mamba的时间骨干网络相结合，利用时空视觉信息在挑战性条件下实现更准确的目标语音提取。

Result: 在AVSEC-4挑战赛开发和盲测集上，AVSEMamba在语音可懂度（STOI）、感知质量（PESQ）和非侵入式质量（UTMOS）方面均优于其他单声道基线方法，并获得单声道排行榜第一名。

Conclusion: AVSEMamba通过整合音频和视觉信息，成功解决了多说话人环境中的语音增强问题，证明了视觉线索对于提升复杂场景下语音处理性能的重要价值。

Abstract: Recent Mamba-based models have shown promise in speech enhancement by
efficiently modeling long-range temporal dependencies. However, models like
Speech Enhancement Mamba (SEMamba) remain limited to single-speaker scenarios
and struggle in complex multi-speaker environments such as the cocktail party
problem. To overcome this, we introduce AVSEMamba, an audio-visual speech
enhancement model that integrates full-face visual cues with a Mamba-based
temporal backbone. By leveraging spatiotemporal visual information, AVSEMamba
enables more accurate extraction of target speech in challenging conditions.
Evaluated on the AVSEC-4 Challenge development and blind test sets, AVSEMamba
outperforms other monaural baselines in speech intelligibility (STOI),
perceptual quality (PESQ), and non-intrusive quality (UTMOS), and achieves
\textbf{1st place} on the monaural leaderboard.

</details>


### [12] [DegDiT: Controllable Audio Generation with Dynamic Event Graph Guided Diffusion Transformer](https://arxiv.org/abs/2508.13786)
*Yisu Liu,Chenxing Li,Wanqian Zhang,Wenfu Wang,Meng Yu,Ruibo Fu,Zheng Lin,Weiping Wang,Dong Yu*

Main category: cs.SD

TL;DR: DegDiT是一个基于动态事件图引导的扩散变换器框架，用于开放词汇的可控音频生成，通过结构化图表示和共识偏好优化实现精确的时序控制和高质量音频合成


<details>
  <summary>Details</summary>
Motivation: 现有可控文本到音频生成方法在准确时序定位、开放词汇扩展性和实际效率之间存在固有权衡，需要解决这些挑战

Method: 将描述中的事件编码为结构化动态图，节点包含语义特征、时间属性和事件间连接；使用图变换器生成上下文事件嵌入；引入质量平衡数据选择流程和共识偏好优化

Result: 在AudioCondition、DESED和AudioTime数据集上的实验表明，DegDiT在各种主客观评估指标上达到最先进性能

Conclusion: DegDiT框架通过动态事件图表示和共识优化策略，成功解决了可控音频生成中的时序精度、词汇扩展和效率平衡问题

Abstract: Controllable text-to-audio generation aims to synthesize audio from textual
descriptions while satisfying user-specified constraints, including event
types, temporal sequences, and onset and offset timestamps. This enables
precise control over both the content and temporal structure of the generated
audio. Despite recent progress, existing methods still face inherent trade-offs
among accurate temporal localization, open-vocabulary scalability, and
practical efficiency. To address these challenges, we propose DegDiT, a novel
dynamic event graph-guided diffusion transformer framework for open-vocabulary
controllable audio generation. DegDiT encodes the events in the description as
structured dynamic graphs. The nodes in each graph are designed to represent
three aspects: semantic features, temporal attributes, and inter-event
connections. A graph transformer is employed to integrate these nodes and
produce contextualized event embeddings that serve as guidance for the
diffusion model. To ensure high-quality and diverse training data, we introduce
a quality-balanced data selection pipeline that combines hierarchical event
annotation with multi-criteria quality scoring, resulting in a curated dataset
with semantic diversity. Furthermore, we present consensus preference
optimization, facilitating audio generation through consensus among multiple
reward signals. Extensive experiments on AudioCondition, DESED, and AudioTime
datasets demonstrate that DegDiT achieves state-of-the-art performances across
a variety of objective and subjective evaluation metrics.

</details>


### [13] [Evaluating Identity Leakage in Speaker De-Identification Systems](https://arxiv.org/abs/2508.14012)
*Seungmin Seo,Oleg Aulov,Afzal Godil,Kevin Mangold*

Main category: cs.SD

TL;DR: 语者去识别技术存在显著的身份泄漏风险，现有系统在保持语音可识别性的同时无法有效隐藏语者身份


<details>
  <summary>Details</summary>
Motivation: 建立一个量化评估标准，以检测当前语者去识别系统的身份泄漏程度，揭示语音隐私保护技术的实际风险

Method: 使用三种互补的错误率指标：等错误率(EER)、积累匹配特征命中率(CMC hit rate)、以及通过标准相关分析和Procrustes分析测量嵌入空间相似性

Result: 所有现有最优语者去识别系统都存在身份信息泄漏。性能最好的系统仅略强于随机猜测，而性能最差的系统在CMC前50名候选人中达到45%的命中率

Conclusion: 当前语者去识别技术存在持续的隐私风险，需要更有效的方案来真正保护语者身份信息

Abstract: Speaker de-identification aims to conceal a speaker's identity while
preserving intelligibility of the underlying speech. We introduce a benchmark
that quantifies residual identity leakage with three complementary error rates:
equal error rate, cumulative match characteristic hit rate, and embedding-space
similarity measured via canonical correlation analysis and Procrustes analysis.
Evaluation results reveal that all state-of-the-art speaker de-identification
systems leak identity information. The highest performing system in our
evaluation performs only slightly better than random guessing, while the lowest
performing system achieves a 45% hit rate within the top 50 candidates based on
CMC. These findings highlight persistent privacy risks in current speaker
de-identification technologies.

</details>

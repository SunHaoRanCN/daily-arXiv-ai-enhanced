<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 8]
- [eess.AS](#eess.AS) [Total: 8]
- [cs.SD](#cs.SD) [Total: 5]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [InverTwin: Solving Inverse Problems via Differentiable Radio Frequency Digital Twin](https://arxiv.org/abs/2508.14204)
*Xingyu Chen,Jianrong Ding,Kai Zheng,Xinmin Fang,Xinyu Zhang,Chris Xiaoxuan Lu,Zhengxiong Li*

Main category: eess.SP

TL;DR: InverTwin是一个优化驱动的框架，通过虚拟与物理世界的双向交互创建RF数字孪生，解决了RF优化的不可微性挑战，提升了RF传感系统的性能。


<details>
  <summary>Details</summary>
Motivation: 传统RF模拟器的单向性限制了数字孪生在射频传感应用中的潜力，需要开发能够实现虚拟与物理世界双向交互的新方法。

Method: 提出路径空间微分技术处理复杂模拟函数的不连续性，使用雷达替代模型缓解RF信号周期性导致的局部非凸性，实现平滑梯度传播和鲁棒优化。

Result: 实验证明InverTwin在增强数据驱动和模型驱动的RF传感系统进行数字孪生重建方面具有多功能性和有效性。

Conclusion: InverTwin框架成功克服了RF优化问题的根本性可微性挑战，为射频数字孪生的创建提供了有效的双向交互解决方案。

Abstract: Digital twins (DTs), virtual simulated replicas of physical scenes, are
transforming various industries. However, their potential in radio frequency
(RF) sensing applications has been limited by the unidirectional nature of
conventional RF simulators. In this paper, we present InverTwin, an
optimization-driven framework that creates RF digital twins by enabling
bidirectional interaction between virtual and physical realms. InverTwin
overcomes the fundamental differentiability challenges of RF optimization
problems through novel design components, including path-space differentiation
to address discontinuity in complex simulation functions, and a radar surrogate
model to mitigate local non-convexity caused by RF signal periodicity. These
techniques enable smooth gradient propagation and robust optimization of the DT
model. Our implementation and experiments demonstrate InverTwin's versatility
and effectiveness in augmenting both data-driven and model-driven RF sensing
systems for DT reconstruction.

</details>


### [2] [Weakly-Convex Regularization for Magnetic Resonance Image Denoising](https://arxiv.org/abs/2508.14438)
*Akash Prabakar,Abhishek Shreekant Bhandiwad,Abijith Jagannath Kamath,Chandra Sekhar Seelamantula*

Main category: eess.SP

TL;DR: 这篇论文提出了一种构造性方法来设计弱凸正则化函数，用于磁共振成像的去噪，无需偿性深度学习方法的解释性、稳定性成本，但仍能达到领先的去噪性能。


<details>
  <summary>Details</summary>
Motivation: 深度学习在MRI去噪中虽然表现优异，但缺乏解释性、可解释性和稳定性，而这些对磁共振成像至关重要。需要找到既保持高性能又具有良好解释性的方案。

Method: 提出构造性方法设计弱凸正则化函数，应用于液体扭转磁共振图像去噪。该方法还可用于设计弱凸卷积神经网络，具有原型激活函数，使其可解释并且可证收敛。

Result: 在液体扭转磁共振图像去噪任务中，该方法表现与最先进去噪器相当。它还显示出更少的去噪伪影，对脑微结构建模有积极影响。

Conclusion: 该研究提供了一种新的弱凸正则化方法，能够在保持高性能去噪的同时，充分考虑MRI应用中对解释性、稳定性和可证性的需求，为深度学习方法提供了替代方案。

Abstract: Regularization for denoising in magnetic resonance imaging (MRI) is typically
achieved using convex regularization functions. Recently, deep learning
techniques have been shown to provide superior denoising performance. However,
this comes at the price of lack of explainability, interpretability and
stability, which are all crucial to MRI. In this work, we present a
constructive approach for designing weakly-convex regularization functions for
MR image denoising. We show that our technique performs on par with
state-of-the-art denoisers for diffusion-weighted MR image denoising. Our
technique can be applied to design weakly-convex convolutional neural networks
with prototype activation functions that impart interpretability and are
provably convergent. We also show that our technique exhibits fewer denoising
artifacts by demonstrating its effect on brain microstructure modelling.

</details>


### [3] [Pinching-Antenna Systems-Enabled Multi-User Communications: Transmission Structures and Beamforming Optimization](https://arxiv.org/abs/2508.14458)
*Jingjing Zhao,Haowen Song,Xidong Mu,Kaiquan Cai,Yanbo Zhu,Yuanwei Liu*

Main category: eess.SP

TL;DR: 本文提出了三种基于Pinching-antenna系统(PASS)的传输结构(WM、WD、WS)，用于多用户通信。针对多组多播通信系统，设计了联合基带信号处理和pinching波束成形算法，并通过数值结果验证了PASS相比传统固定天线系统的性能优势。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线系统在无线通信中存在局限性，需要创新技术来确保可靠的视距连接和动态天线阵列重构。Pinching-antenna系统(PASS)作为柔性天线技术的创新进展，旨在显著改善无线通信性能。

Method: 提出了三种传输结构：波导复用(WM)、波导分割(WD)和波导切换(WS)。针对多组多播通信系统，设计了基于惩罚对偶分解(PDD)的算法来解决最大最小公平性问题。对于单播情况，提出了低复杂度算法来同时对齐信号相位和最小化大尺度路径损耗。

Result: 数值结果表明：1) PASS相比传统固定位置天线系统显著提高了MMF性能；2) WS和WM分别适用于单播和多播通信；3) 当用户地理位置隔离时，WD和WM之间的性能差距可以显著减小。

Conclusion: PASS系统通过动态天线重构能力，为多用户无线通信提供了有效的解决方案。不同的传输结构适用于不同的通信场景，WM适合多播，WS适合单播，而WD在用户地理隔离时表现良好。所提出的算法能够有效解决复杂的非凸优化问题。

Abstract: Pinching-antenna systems (PASS) represent an innovative advancement in
flexible-antenna technologies, aimed at significantly improving wireless
communications by ensuring reliable line-of-sight connections and dynamic
antenna array reconfigurations. To employ multi-waveguide PASS in multi-user
communications, three practical transmission structures are proposed, namely
waveguide multiplexing (WM), waveguide division (WD), and waveguide switching
(WS). Based on the proposed structures, the joint baseband signal processing
and pinching beamforming design is studied for a general multi-group multicast
communication system, with the unicast communication encompassed as a special
case. A max-min fairness problem is formulated for each proposed transmission
structure, subject to the maximum transmit power constraint. For WM, to solve
the highly-coupled and non-convex MMF problem with complex exponential and
fractional expressions, a penalty dual decomposition (PDD)-based algorithm is
invoked for obtaining locally optimal solutions. Specifically, the augmented
Lagrangian relaxation is first applied to alleviate the stringent coupling
constraints, which is followed by the block decomposition over the resulting
augmented Lagrangian function. Then, the proposed PDD-based algorithm is
extended to solve the MMF problem for both WD and WS. Furthermore, a
low-complexity algorithm is proposed for the unicast case employing the WS
structure, by simultaneously aligning the signal phases and minimizing the
large-scale path loss at each user. Finally, numerical results reveal that: 1)
the MMF performance is significantly improved by employing the PASS compared to
conventional fixed-position antenna systems; 2) WS and WM are suitable for
unicast and multicast communications, respectively; 3) the performance gap
between WD and WM can be significantly alleviated when the users are
geographically isolated.

</details>


### [4] [FPGA Design and Implementation of Fixed-Point Fast Divider Using Goldschmidt Division Algorithm and Mitchell Multiplication Algorithm](https://arxiv.org/abs/2508.14611)
*Jinkun Yang*

Main category: eess.SP

TL;DR: 提出了一种基于Goldschmidt除法算法和Mitchell乘法算法的可变位宽定点快速除法器，在FPGA上实现99%以上计算精度，延迟降低31.7ns，资源利用率显著改善


<details>
  <summary>Details</summary>
Motivation: 针对FPGA系统中需要高性能除法器但资源受限的问题，寻求在计算速度和资源利用率之间更好的平衡

Method: 结合Goldschmidt除法算法和Mitchell乘法算法，使用Verilog HDL设计，在Xilinx XC7Z020-2CLG400I FPGA上实现

Result: 达到99%以上计算精度，最小延迟99.1ns（比现有单精度除法器快31.7ns），相比使用Vedic乘法器的Goldschmidt除法器，Slice寄存器减少46.68%，Slice LUT减少4.93%，Slices减少11.85%，仅增加24.1ns延迟和不到1%的精度损失

Conclusion: 该设计在计算速度和资源利用率之间取得了更好的平衡，特别适合资源受限的高性能FPGA系统

Abstract: This paper presents a variable bit-width fixed-point fast divider using
Goldschmidt division algorithm and Mitchell multiplication algorithm. Described
using Verilog HDL and implemented on a Xilinx XC7Z020-2CLG400I FPGA, the
proposed divider achieves over 99% computational accuracy with a minimum
latency of 99.1 ns, which is 31.7 ns faster than existing single-precision
dividers. Compared with a Goldschmidt divider using a Vedic multiplier, the
proposed design reduces Slice Registers by 46.68%, Slice LUTs by 4.93%, and
Slices by 11.85%, with less than 1% accuracy loss and only 24.1 ns additional
delay. These results demonstrate an improved balance between computational
speed and resource utilization, making the divider well-suited for
high-performance FPGA-based systems with strict resource constraints.

</details>


### [5] [Design of a Gm-C Dynamic Amplifier with High Linearity and High Temperature and Power Supply Voltage Stability](https://arxiv.org/abs/2508.14637)
*Jinkun Yang,Pengbin Xu*

Main category: eess.SP

TL;DR: 高线性度、高温度和电源稳定性的Gm-C动态放大器，采用不对称差分对提升线性度，在-40mV到40mV输入范围内保持持续增益，THD达70.5dB，在广泛的电源和温度变化下显示出良好的性能稳定性。


<details>
  <summary>Details</summary>
Motivation: 设计一种高线性度且具有良好温度和电源电压稳定性的动态放大器，以满足现代集成电路对性能和稳定性的高要求。

Method: 主要采用两个不对称差分对来提高跨导线性度，偏置部分采用常数-gm偏置电路，以改善放大器跨导和增益的温度和供电电压稳定性。

Result: 放大器在-40mV到40mV差分输入范围内保持几乎常数增益，总豪波失真(THD)为70.5dB。在电源电压波动±10%、温度变化从-40°C到120°C的条件下，增益分布的标准偏差为262m，分布范围为15.1到16.3。

Conclusion: 该Gm-C动态放大器设计成功实现了高线性度和良好的温度/电源稳定性，适用于需要高性能和高稳定性的集成电路应用。

Abstract: This paper presents a Gm-C dynamic amplifier with high linearity and high
temperature and power supply voltage stability. The main part of the amplifier
employs two asymmetric differential pairs to enhance transconductance
linearity. The amplifier maintains a nearly constant gain within a differential
input range of -40 mV to 40 mV, and achieves a total harmonic distortion (THD)
of 70.5 dB. The bias part of the amplifier adopts a constant-gm bias circuit,
which improves the temperature and supply voltage stability of the amplifier's
transconductance and gain. When the differential input is 1 mV, the power
supply voltage fluctuates by $\pm$10%, and the temperature varies between
-40$\mathrm{^\circ C}$ and 120$\mathrm{^\circ C}$, the standard deviation of
the gain distribution is 262m, and the distribution range is from 15.1 to 16.3.

</details>


### [6] [Failure Tolerant Phase-Only Indoor Positioning via Deep Learning](https://arxiv.org/abs/2508.14739)
*Fatih Ayten,Mehmet C. Ilter,Akshay Jain,Ossi Kaltiokallio,Jukka Talvitie,Elena Simona Lohan,Henk Wymeersch,Mikko Valkama*

Main category: eess.SP

TL;DR: 提出了一种基于深度学习的稳健相位定位方法，通过双曲线交会原理和抗天线故障机制，在5G-Advanced系统中实现高精度定位


<details>
  <summary>Details</summary>
Motivation: 现有相位定位方法在理想硬件假设下表现良好，但在实际天线故障场景下性能严重下降，需要开发稳健的定位解决方案

Method: 基于双曲线交会原理的深度学习定位方法，设计了抗天线单元故障的处理和学习机制

Result: 所提DL模型在天线受损情况下仍能实现稳健准确的定位，相比现有方法在定位精度上有显著提升

Conclusion: 数据驱动的相位定位机制具有抗干扰能力，为5G-Advanced系统提供了可行的厘米级高精度定位解决方案

Abstract: High-precision localization turns into a crucial added value and asset for
next-generation wireless systems. Carrier phase positioning (CPP) enables
sub-meter to centimeter-level accuracy and is gaining interest in 5G-Advanced
standardization. While CPP typically complements time-of-arrival (ToA)
measurements, recent literature has introduced a phase-only positioning
approach in a distributed antenna/MIMO system context with minimal bandwidth
requirements, using deep learning (DL) when operating under ideal hardware
assumptions. In more practical scenarios, however, antenna failures can largely
degrade the performance. In this paper, we address the challenging phase-only
positioning task, and propose a new DL-based localization approach harnessing
the so-called hyperbola intersection principle, clearly outperforming the
previous methods. Additionally, we consider and propose a processing and
learning mechanism that is robust to antenna element failures. Our results show
that the proposed DL model achieves robust and accurate positioning despite
antenna impairments, demonstrating the viability of data-driven,
impairment-tolerant phase-only positioning mechanisms. Comprehensive set of
numerical results demonstrates large improvements in localization accuracy
against the prior art methods.

</details>


### [7] [Full-Duplex Beamforming Optimization for Near-Field ISAC](https://arxiv.org/abs/2508.14753)
*Ahsan Nazar,Zhambyl Shaikhanov,Sennur Ulukus*

Main category: eess.SP

TL;DR: 本文研究了全双工运行在近场集成感知与通信系统中的性能，通过聚合优化发射和接收波束形成来最小化发射功耗，同时满足多用户通信和多目标感知的需求。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)是未来无线网络的重要技术，能够利用共享资源同时实现通信和感知功能。近场波球波传播带来了独特的波束聚焦能力，但同时也引入了复杂的优化问题。

Method: 提出了聚合优化框架，采用交替优化结合半正定松弛和Rayleigh商数技术来处理非凸性优化问题，实现发射和接收波束形成的聚合设计。

Result: 模拟结果显示，全双工启用的近场ISAC系统在功耗效率方面显著优于半双工和远场对照方案，能够在满足通信要求的同时有效检测相同角度的目标。

Conclusion: 全双工运行在近场ISAC系统中具有显著的性能优势，通过本文提出的聚合优化方法可以实现更高的功耗效率和更好的感知通信性能。

Abstract: Integrated Sensing and Communications (ISAC) is a promising technology for
future wireless networks, enabling simultaneous communication and sensing using
shared resources. This paper investigates the performance of full-duplex (FD)
communication in near-field ISAC systems, where spherical-wave propagation
introduces unique beam-focusing capabilities. We propose a joint optimization
framework for transmit and receive beamforming at the base station to minimize
transmit power while satisfying rate constraints for multi-user downlink
transmission, multi-user uplink reception, and multi-target sensing. Our
approach employs alternating optimization combined with semidefinite relaxation
and Rayleigh quotient techniques to address the non-convexity of the problem.
Simulation results demonstrate that FD-enabled near-field ISAC achieves
superior power efficiency compared to half-duplex and far-field benchmarks,
effectively detecting targets at identical angles while meeting communication
requirements.

</details>


### [8] [Deep Reinforcement Learning Based Routing for Heterogeneous Multi-Hop Wireless Networks](https://arxiv.org/abs/2508.14884)
*Brian Kim,Justin H. Kong,Terrence J. Moore,Fikadu T. Dagefu*

Main category: eess.SP

TL;DR: 提出基于深度Q网络(DQN)的路由框架，用于异构多跳无线网络，通过改进邻居节点选择策略和深度神经网络来提升端到端速率、可扩展性和适应性


<details>
  <summary>Details</summary>
Motivation: 传统Q学习在多跳异构无线网络中面临可扩展性差和泛化能力不足的问题，特别是在动态拓扑和多样化信道特性的网络中管理Q表困难

Method: 使用深度神经网络估计Q值，联合选择下一跳中继和通信技术；提出基于信道增益和速率的邻居节点选择策略，而非简单基于距离的方法；在训练中体验多样化网络拓扑以确保泛化能力

Result: 仿真结果显示，提出的邻居节点选择策略优于简单距离选择；DQN方法在各种基准方案中表现优异，性能接近最优方法

Conclusion: 基于DQN的路由框架通过智能邻居选择和深度学习方法，有效解决了异构多跳无线网络中的路由问题，提升了网络性能和适应性

Abstract: Routing in multi-hop wireless networks is a complex problem, especially in
heterogeneous networks where multiple wireless communication technologies
coexist. Reinforcement learning (RL) methods, such as Q-learning, have been
introduced for decentralized routing by allowing nodes to make decisions based
on local observations. However, Q-learning suffers from scalability issues and
poor generalization due to the difficulty in managing the Q-table in large or
dynamic network topologies, especially in heterogeneous networks (HetNets) with
diverse channel characteristics. Thus, in this paper, we propose a novel deep
Q-network (DQN)-based routing framework for heterogeneous multi-hop wireless
networks to maximize the end-to-end rate of the route by improving scalability
and adaptability, where each node uses a deep neural network (DNN) to estimate
the Q-values and jointly select the next-hop relay and a communication
technology for transmission. To achieve better performance with the DNN,
selecting which nodes to exchange information is critical, as it not only
defines the state and action spaces but also determines the input to the DNN.
To this end, we propose neighbor node selection strategies based on channel
gain and rate between nodes rather than a simple distance-based approach for an
improved set of states and actions for DQN-based routing. During training, the
model experiences diverse network topologies to ensure generalization and
robustness, and simulation results show that the proposed neighbor node
selection outperforms simple distance-based selection. Further, we observe that
the DQN-based approach outperforms various benchmark schemes and performs
comparably to the optimal approach.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [9] [RAG-Boost: Retrieval-Augmented Generation Enhanced LLM-based Speech Recognition](https://arxiv.org/abs/2508.14048)
*Pengcheng Wang,Sheng Li,Takahiro Shinozaki*

Main category: eess.AS

TL;DR: RAG-Boost系统通过在实时ASR识别过程中集成检索增强生成模块，利用音频-文本对和领域术语的向量数据库来修正识别错误，提升语音识别性能


<details>
  <summary>Details</summary>
Motivation: 解决传统ASR系统在实时识别过程中容易出现的错误识别问题，通过检索相关上下文信息来增强识别准确性

Method: 在基线LLM-based ASR系统基础上，为每个部分ASR假设查询音频-文本对和领域术语的向量存储，将检索结果与实时ASR假设融合以修正识别错误，然后将融合后的假设传递给LLM生成改进的响应

Result: 系统能够有效修正ASR识别错误，产生更准确的识别结果

Conclusion: RAG-Boost通过集成检索增强生成技术，显著提升了实时ASR系统的识别准确性和鲁棒性

Abstract: In this paper, we propose RAG-Boost (ST-ShinozakiLab Task I system), which
enhances the baseline LLM-based ASR system of the MLC-SLM Challenge (task I)
with a retrieval-augmented generation (RAG) module on the fly. Each partial ASR
hypothesis queries a vector store of audio-text pairs and domain terms, and the
retrieved results are fused with the live ASR hypotheses to fix recognition
errors. The fused hypotheses are passed to the LLM, yielding improved
responses.

</details>


### [10] [MahaTTS: A Unified Framework for Multilingual Text-to-Speech Synthesis](https://arxiv.org/abs/2508.14049)
*Jaskaran Singh,Amartya Roy Chowdhury,Raghav Prabhakar,Varshul C. W*

Main category: eess.AS

TL;DR: MahaTTS-v2是一个多语言多说话人TTS系统，专门针对印度语言，使用Wav2Vec2.0和条件流模型，在20K小时数据上训练，效果优于现有框架


<details>
  <summary>Details</summary>
Motivation: 当前TTS模型主要关注英语和欧洲语言，限制了信息获取的普及性，特别是对印度语言用户。需要开发专门针对印度语言的高质量多语言TTS系统

Method: 使用Wav2Vec2.0进行语义提取，语言模型进行文本到语义建模，条件流模型(CFM)进行语义到梅尔频谱图生成，在20K小时印度语言数据上训练

Result: 实验结果表明该方法比其他框架更有效，在印度语言上表现出优秀的表达能力

Conclusion: MahaTTS-v2成功填补了印度语言TTS系统的空白，为更多用户提供了信息获取途径，代码已开源

Abstract: Current Text-to-Speech models pose a multilingual challenge, where most of
the models traditionally focus on English and European languages, thereby
hurting the potential to provide access to information to many more people. To
address this gap, we introduce MahaTTS-v2 a Multilingual Multi-speaker
Text-To-Speech (TTS) system that has excellent multilingual expressive
capabilities in Indic languages. The model has been trained on around 20K hours
of data specifically focused on Indian languages. Our approach leverages
Wav2Vec2.0 tokens for semantic extraction, and a Language Model (LM) for
text-to-semantic modeling. Additionally, we have used a Conditional Flow Model
(CFM) for semantics to melspectogram generation. The experimental results
indicate the effectiveness of the proposed approach over other frameworks. Our
code is available at https://github.com/dubverse-ai/MahaTTSv2

</details>


### [11] [Towards Low-Latency Tracking of Multiple Speakers With Short-Context Speaker Embeddings](https://arxiv.org/abs/2508.14115)
*Taous Iatariene,Alexandre Guérin,Romain Serizel*

Main category: eess.AS

TL;DR: 提出基于知识蒸馏的短上下文说话人嵌入提取方法，利用波束成形减少语音重叠，研究块级身份重分配以实现低延迟的说话人跟踪系统


<details>
  <summary>Details</summary>
Motivation: 传统说话人嵌入提取器在短时上下文和重叠语音场景下表现不佳，长时身份重分配会增加跟踪系统错误概率，需要改进短上下文嵌入提取技术

Method: 采用知识蒸馏训练方法，从双说话人混合语音中提取短上下文说话人嵌入，利用波束成形技术基于空间信息减少语音重叠

Result: 蒸馏模型在短上下文嵌入提取方面表现有效，对重叠语音更具鲁棒性，但块级重分配结果显示需要进一步改进以更有效处理同时语音

Conclusion: 知识蒸馏方法能有效提升短上下文说话人嵌入提取性能，但需要继续研究以更好地处理同时说话场景，实现低延迟的说话人跟踪系统

Abstract: Speaker embeddings are promising identity-related features that can enhance
the identity assignment performance of a tracking system by leveraging its
spatial predictions, i.e, by performing identity reassignment. Common speaker
embedding extractors usually struggle with short temporal contexts and
overlapping speech, which imposes long-term identity reassignment to exploit
longer temporal contexts. However, this increases the probability of tracking
system errors, which in turn impacts negatively on identity reassignment. To
address this, we propose a Knowledge Distillation (KD) based training approach
for short context speaker embedding extraction from two speaker mixtures. We
leverage the spatial information of the speaker of interest using beamforming
to reduce overlap. We study the feasibility of performing identity reassignment
over blocks of fixed size, i.e., blockwise identity reassignment, to go towards
a low-latency speaker embedding based tracking system. Results demonstrate that
our distilled models are effective at short-context embedding extraction and
more robust to overlap. Although, blockwise reassignment results indicate that
further work is needed to handle simultaneous speech more effectively.

</details>


### [12] [EmoSLLM: Parameter-Efficient Adaptation of LLMs for Speech Emotion Recognition](https://arxiv.org/abs/2508.14130)
*Hugo Thimonier,Antony Perzo,Renaud Seguier*

Main category: eess.AS

TL;DR: 提出了一种新颖的多模态情感识别方法，通过LoRA高效微调LLM，结合音频特征和文本信息进行语音情感预测，在参数效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 语音情感识别需要同时捕捉语言和副语言线索，现有方法参数量大且效率不高。LLM在多模态任务中展现潜力，但需要更高效的融合机制。

Method: 使用音频特征提取器获取特征，通过可学习接口映射到LLM表示空间。输入包括转换后的音频特征、文本转录和任务描述提示。采用LoRA进行参数高效微调。

Result: 在标准情感识别基准测试中，性能优于除一个之外的所有现有语音-文本LLM方法，同时参数量不到竞争方法的一半。

Conclusion: 该方法有效整合多模态输入进行语音情感理解，在保持显著计算效率的同时实现了优越性能。

Abstract: Emotion recognition from speech is a challenging task that requires capturing
both linguistic and paralinguistic cues, with critical applications in
human-computer interaction and mental health monitoring. Recent works have
highlighted the ability of Large Language Models (LLMs) to perform tasks
outside of the sole natural language area. In particular, recent approaches
have investigated coupling LLMs with other data modalities by using pre-trained
backbones and different fusion mechanisms. This work proposes a novel approach
that fine-tunes an LLM with audio and text representations for emotion
prediction. Our method first extracts audio features using an audio feature
extractor, which are then mapped into the LLM's representation space via a
learnable interfacing module. The LLM takes as input (1) the transformed audio
features, (2) additional features in the form of natural language (e.g., the
transcript), and (3) a textual prompt describing the emotion prediction task.
To efficiently adapt the LLM to this multimodal task, we employ Low-Rank
Adaptation (LoRA), enabling parameter-efficient fine-tuning. Experimental
results on standard emotion recognition benchmarks demonstrate that our model
outperforms all but one existing Speech-Text LLMs in the literature, while
requiring less than half the parameters of competing approaches. This
highlights our approach's effectiveness in integrating multi-modal inputs for
speech-based emotion understanding while maintaining significant computational
efficiency.

</details>


### [13] [A Study of the Scale Invariant Signal to Distortion Ratio in Speech Separation with Noisy References](https://arxiv.org/abs/2508.14623)
*Simon Dahl Jepsen,Mads Græsbøll Christensen,Jesper Rindom Jensen*

Main category: eess.AS

TL;DR: 本文研究了在监督语音分离中使用SI-SDR作为评估和训练目标时，当训练参考包含噪声（如WSJ0-2Mix基准）会导致的问题，并提出了参考增强方法来减少输出噪声。


<details>
  <summary>Details</summary>
Motivation: WSJ0-2Mix等基准数据集的训练参考包含噪声，使用SI-SDR作为目标会导致模型学习噪声参考，限制分离性能并引入不希望的噪声。

Method: 推导了含噪声参考的SI-SDR理论极限，提出参考增强方法和使用WHAM!数据增强来训练避免学习噪声参考的模型。

Result: 增强数据集训练的模型减少了分离语音中的噪声，但参考处理可能引入伪影，限制了整体质量提升。SI-SDR与感知噪声度呈负相关。

Conclusion: 含噪声参考会限制SI-SDR性能并导致输出含噪声，需要谨慎处理训练参考的质量问题。

Abstract: This paper examines the implications of using the Scale-Invariant
Signal-to-Distortion Ratio (SI-SDR) as both evaluation and training objective
in supervised speech separation, when the training references contain noise, as
is the case with the de facto benchmark WSJ0-2Mix. A derivation of the SI-SDR
with noisy references reveals that noise limits the achievable SI-SDR, or leads
to undesired noise in the separated outputs. To address this, a method is
proposed to enhance references and augment the mixtures with WHAM!, aiming to
train models that avoid learning noisy references. Two models trained on these
enhanced datasets are evaluated with the non-intrusive NISQA.v2 metric. Results
show reduced noise in separated speech but suggest that processing references
may introduce artefacts, limiting overall quality gains. Negative correlation
is found between SI-SDR and perceived noisiness across models on the WSJ0-2Mix
and Libri2Mix test sets, underlining the conclusion from the derivation.

</details>


### [14] [Improving Resource-Efficient Speech Enhancement via Neural Differentiable DSP Vocoder Refinement](https://arxiv.org/abs/2508.14709)
*Heitor R. Guimarães,Ke Tan,Juan Azcarreta,Jesus Alvarez,Prabhav Agrawal,Ashutosh Pandey,Buye Xu*

Main category: eess.AS

TL;DR: 一种基于DDSP声码器的高效语音增强框架，通过系统端到端训练在保持计算效率的同时提升语音识别率和质量


<details>
  <summary>Details</summary>
Motivation: 解决可穿戴设备上计算资源有限的问题，在保持计算效率的前提下实现高质量语音增强

Method: 使用简洁神经网络预测增强的声学特征（谱包线、基频、周期性），然后通过DDSP声码器合成清晰波形，采用STFT和对抗损失进行端到端训练

Result: 在不显著增加计算量的情况下，语音识别率提升4%（STOI），质量提升19%（DNSMOS），超过强基线方法

Conclusion: 该方法通过结合神经网络和DDSP声码器的方式，实现了高效的实时语音增强，适合在计算资源有限的可穿戴设备上部署

Abstract: Deploying speech enhancement (SE) systems in wearable devices, such as smart
glasses, is challenging due to the limited computational resources on the
device. Although deep learning methods have achieved high-quality results,
their computational cost limits their feasibility on embedded platforms. This
work presents an efficient end-to-end SE framework that leverages a
Differentiable Digital Signal Processing (DDSP) vocoder for high-quality speech
synthesis. First, a compact neural network predicts enhanced acoustic features
from noisy speech: spectral envelope, fundamental frequency (F0), and
periodicity. These features are fed into the DDSP vocoder to synthesize the
enhanced waveform. The system is trained end-to-end with STFT and adversarial
losses, enabling direct optimization at the feature and waveform levels.
Experimental results show that our method improves intelligibility and quality
by 4% (STOI) and 19% (DNSMOS) over strong baselines without significantly
increasing computation, making it well-suited for real-time applications.

</details>


### [15] [Long-Context Speech Synthesis with Context-Aware Memory](https://arxiv.org/abs/2508.14713)
*Zhipeng Li,Xiaofen Xing,Jingyuan Xing,Hangrui Hu,Heng Lu,Xiangmin Xu*

Main category: eess.AS

TL;DR: 提出基于上下文感知记忆(CAM)的长文本语音合成模型，通过整合长期记忆和局部上下文细节，解决段落级语音合成的连贯性问题。


<details>
  <summary>Details</summary>
Motivation: 当前长文本语音合成方法通常在句子级别进行转换并拼接，忽略了段落的上下文连贯性，导致自然度降低和风格音色不一致。

Method: 使用上下文感知记忆(CAM)块整合检索长期记忆和局部上下文细节，实现动态内存更新和传递；前缀掩码增强上下文学习能力，支持前缀token的双向注意力同时保持单向生成。

Result: 实验结果表明，该方法在韵律表达、连贯性和上下文推理成本方面优于基线和最先进的长上下文方法。

Conclusion: CAM-based TTS模型能有效提升段落级语音合成的自然度和一致性，解决了长文本合成中的上下文连贯性问题。

Abstract: In long-text speech synthesis, current approaches typically convert text to
speech at the sentence-level and concatenate the results to form
pseudo-paragraph-level speech. These methods overlook the contextual coherence
of paragraphs, leading to reduced naturalness and inconsistencies in style and
timbre across the long-form speech. To address these issues, we propose a
Context-Aware Memory (CAM)-based long-context Text-to-Speech (TTS) model. The
CAM block integrates and retrieves both long-term memory and local context
details, enabling dynamic memory updates and transfers within long paragraphs
to guide sentence-level speech synthesis. Furthermore, the prefix mask enhances
the in-context learning ability by enabling bidirectional attention on prefix
tokens while maintaining unidirectional generation. Experimental results
demonstrate that the proposed method outperforms baseline and state-of-the-art
long-context methods in terms of prosody expressiveness, coherence and context
inference cost across paragraph-level speech.

</details>


### [16] [PadAug: Robust Speaker Verification with Simple Waveform-Level Silence Padding](https://arxiv.org/abs/2508.14732)
*Zijun Huang,Chengdong Liang,Jiadi Yao,Xiao-Lei Zhang*

Main category: eess.AS

TL;DR: 这篇论文提出了一种简单的波形数据增帽方法PadAug，通过在语音段后拼接沉默段来提高语音验证系统对沉默段的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 语音中的非语音段导致语音验证性能下降，尤其是语音段之间的短曲沉默段对现有系统构成挑战。

Method: 提出PadAug方法，在波形层面将沉默段与语音段连接起来进行模型训练，增强系统对沉默的适应能力。

Result: 在VoxCeleb数据集上，PadAug使ResNet34相对均误率降低5.0%，并且系统对不同长度和比例的测试沉默段都显示出良好的鲁棒性。

Conclusion: PadAug是一种简单有效的数据增帽方法，可直接集成到现有最先进的语音验证系统中，显著提升了对沉默段的鲁棒性。

Abstract: The presence of non-speech segments in utterances often leads to the
performance degradation of speaker verification. Existing systems usually use
voice activation detection as a preprocessing step to cut off long silence
segments. However, short silence segments, particularly those between speech
segments, still remain a problem for speaker verification. To address this
issue, in this paper, we propose a simple wave-level data augmentation method,
\textit{PadAug}, which aims to enhance the system's robustness to silence
segments. The core idea of \textit{PadAug} is to concatenate silence segments
with speech segments at the waveform level for model training. Due to its
simplicity, it can be directly applied to the current state-of-the art
architectures. Experimental results demonstrate the effectiveness of the
proposed \textit{PadAug}. For example, applying \textit{PadAug} to ResNet34
achieves a relative equal error rate reduction of 5.0\% on the voxceleb
dataset. Moreover, the \textit{PadAug} based systems are robust to different
lengths and proportions of silence segments in the test data.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [17] [Systematic FAIRness Assessment of Open Voice Biomarker Datasets for Mental Health and Neurodegenerative Diseases](https://arxiv.org/abs/2508.14089)
*Ishaan Mahapatra,Nihar R. Mahapatra*

Main category: cs.SD

TL;DR: 本文对27个公开语音生物标志物数据集进行了首次系统性FAIR评估，发现可查找性高但其他方面存在显著差异，提出了改进数据集质量和临床实用性的建议。


<details>
  <summary>Details</summary>
Motivation: 语音生物标志物在心理健康和神经退行性疾病检测中具有潜力，但临床采用受到公开数据集质量不一致和可用性有限的限制。

Method: 使用FAIR数据成熟度模型和结构化优先级加权评分方法，在子原则、原则和综合层面评估27个数据集的FAIR性。

Result: 分析显示可查找性普遍较高，但在可访问性、互操作性和可重用性方面存在显著差异和弱点。心理健康数据集FAIR分数变异性更大，神经退行性数据集稍更一致。存储库选择显著影响FAIR分数。

Conclusion: 建议采用结构化领域特定元数据标准、优先选择FAIR合规存储库，并常规应用结构化FAIR评估框架，以加速语音生物标志物技术的临床转化。

Abstract: Voice biomarkers--human-generated acoustic signals such as speech, coughing,
and breathing--are promising tools for scalable, non-invasive detection and
monitoring of mental health and neurodegenerative diseases. Yet, their clinical
adoption remains constrained by inconsistent quality and limited usability of
publicly available datasets. To address this gap, we present the first
systematic FAIR (Findable, Accessible, Interoperable, Reusable) evaluation of
27 publicly available voice biomarker datasets focused on these disease areas.
Using the FAIR Data Maturity Model and a structured, priority-weighted scoring
method, we assessed FAIRness at subprinciple, principle, and composite levels.
Our analysis revealed consistently high Findability but substantial variability
and weaknesses in Accessibility, Interoperability, and Reusability. Mental
health datasets exhibited greater variability in FAIR scores, while
neurodegenerative datasets were slightly more consistent. Repository choice
also significantly influenced FAIRness scores. To enhance dataset quality and
clinical utility, we recommend adopting structured, domain-specific metadata
standards, prioritizing FAIR-compliant repositories, and routinely applying
structured FAIR evaluation frameworks. These findings provide actionable
guidance to improve dataset interoperability and reuse, thereby accelerating
the clinical translation of voice biomarker technologies.

</details>


### [18] [EffiFusion-GAN: Efficient Fusion Generative Adversarial Network for Speech Enhancement](https://arxiv.org/abs/2508.14525)
*Bin Wen,Tien-Ping Tan*

Main category: cs.SD

TL;DR: EffiFusion-GAN是一个轻量级但强大的语音增强模型，通过深度可分离卷积、增强注意力机制和动态剪枝技术，在保持性能的同时显著减小模型尺寸，适合资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 开发一个既高效又轻量的语音增强模型，使其能够在计算资源有限的环境中部署，同时保持优异的性能表现。

Method: 集成深度可分离卷积的多尺度模块捕捉声学特征，采用双归一化和残差精化的增强注意力机制提高训练稳定性，应用动态剪枝减少模型尺寸。

Result: 在VoiceBank+DEMAND数据集上获得PESQ评分3.45，在相同参数设置下优于现有模型。

Conclusion: EffiFusion-GAN成功实现了轻量化和高性能的平衡，为资源受限环境下的语音增强提供了有效的解决方案。

Abstract: We introduce EffiFusion-GAN (Efficient Fusion Generative Adversarial
Network), a lightweight yet powerful model for speech enhancement. The model
integrates depthwise separable convolutions within a multi-scale block to
capture diverse acoustic features efficiently. An enhanced attention mechanism
with dual normalization and residual refinement further improves training
stability and convergence. Additionally, dynamic pruning is applied to reduce
model size while maintaining performance, making the framework suitable for
resource-constrained environments. Experimental evaluation on the public
VoiceBank+DEMAND dataset shows that EffiFusion-GAN achieves a PESQ score of
3.45, outperforming existing models under the same parameter settings.

</details>


### [19] [Mamba2 Meets Silence: Robust Vocal Source Separation for Sparse Regions](https://arxiv.org/abs/2508.14556)
*Euiyeon Kim,Yong-Hoon Choi*

Main category: cs.SD

TL;DR: 提出基于Mamba2状态空间模型的音乐源分离方法，在语音分离任务中取得当前最佳性能（cSDR 11.03 dB）


<details>
  <summary>Details</summary>
Motivation: Transformer模型在处理间歇性出现的语音时表现不佳，需要更好的长时序依赖建模能力

Method: 结合频带分割策略和双路径架构的Mamba2状态空间模型，有效处理长输入序列

Result: 在语音分离任务中达到11.03 dB的cSDR（当前最佳），uSDR也有显著提升，且在不同输入长度和语音出现模式上表现稳定

Conclusion: Mamba类模型在高分辨率音频处理中具有显著优势，为音频研究开辟了新方向

Abstract: We introduce a new music source separation model tailored for accurate vocal
isolation. Unlike Transformer-based approaches, which often fail to capture
intermittently occurring vocals, our model leverages Mamba2, a recent state
space model, to better capture long-range temporal dependencies. To handle long
input sequences efficiently, we combine a band-splitting strategy with a
dual-path architecture. Experiments show that our approach outperforms recent
state-of-the-art models, achieving a cSDR of 11.03 dB-the best reported to
date-and delivering substantial gains in uSDR. Moreover, the model exhibits
stable and consistent performance across varying input lengths and vocal
occurrence patterns. These results demonstrate the effectiveness of Mamba-based
models for high-resolution audio processing and open up new directions for
broader applications in audio research.

</details>


### [20] [BioSonix: Can Physics-Based Sonification Perceptualize Tissue Deformations From Tool Interactions?](https://arxiv.org/abs/2508.14688)
*Veronica Ruozzi,Sasan Matinfar,Laura Schütz,Benedikt Wiestler,Alberto Redaelli,Emiliano Votta,Nassir Navab*

Main category: cs.SD

TL;DR: BioSonix框架通过物理模拟和声音映射，为混合现实手术环境提供工具-组织交互的听觉反馈，增强医生对软组织操作的直观理解。


<details>
  <summary>Details</summary>
Motivation: 解决手术中工具与可变形结构交互时单模态可视化技术的局限性，如遮挡和深度感知不足，需要通过多感官反馈来提升交互理解。

Method: 开发物理信息设计框架BioSonix，利用生物力学模拟计算组织位移，通过优化方法映射到声音模型，编码组织特性如刚度和密度。

Result: 实验验证声音-位移映射准确性，用户研究显示临床专家任务准确率高，22名生物医学专家在组织区分和定位任务中表现出高辨别精度。

Conclusion: 工具-组织动力学与听觉特征存在强相关性，声音表征有潜力增强对复杂交互的直观理解，提升手术导航效果。

Abstract: Perceptualizing tool interactions with deformable structures in surgical
procedures remains challenging, as unimodal visualization techniques often fail
to capture the complexity of these interactions due to constraints such as
occlusion and limited depth perception. This paper presents a novel approach to
augment tool navigation in mixed reality environments by providing auditory
representations of tool-tissue dynamics, particularly for interactions with
soft tissue. BioSonix, a physics-informed design framework, utilizes tissue
displacements in 3D space to compute excitation forces for a sound model
encoding tissue properties such as stiffness and density. Biomechanical
simulations were employed to model particle displacements resulting from
tool-tissue interactions, establishing a robust foundation for the method. An
optimization approach was used to define configurations for capturing diverse
interaction scenarios with varying tool trajectories. Experiments were
conducted to validate the accuracy of the sound-displacement mappings.
Additionally, two user studies were performed: the first involved two clinical
professionals (a neuroradiologist and a cardiologist), who confirmed the
method's impact and achieved high task accuracy; the second included 22
biomedical experts, who demonstrated high discrimination accuracy in tissue
differentiation and targeting tasks. The results revealed a strong correlation
between tool-tissue dynamics and their corresponding auditory profiles,
highlighting the potential of these sound representations to enhance the
intuitive understanding of complex interactions.

</details>


### [21] [ECHO: Frequency-aware Hierarchical Encoding for Variable-length Signal](https://arxiv.org/abs/2508.14689)
*Yucong Zhang,Juan Liu,Ming Li*

Main category: cs.SD

TL;DR: 提出了一种新的基础模型ECHO，用于通用机器信号处理，整合了先进的频带分割架构和相对频率位置编码，支持任意长度输入，在异常检测和故障识别任务中达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 预训练基础模型在视觉和语言领域取得显著成功，但在机器信号处理（声学、振动等工业传感器数据）方面的潜力尚未充分探索。现有方法存在固定输入长度限制和缺乏显式频率位置编码的问题。

Method: 提出集成先进频带分割架构与相对频率位置嵌入的模型，支持任意长度输入而无需填充或分割，生成保留时间和频谱保真度的简洁嵌入表示。

Result: 在SIREN大规模基准测试中（包含DCASE任务2挑战和工业信号语料库），实验结果显示在异常检测和故障识别任务上取得一致的state-of-the-art性能。

Conclusion: 所提出的模型在机器信号编码方面表现出有效性和泛化能力，已开源ECHO模型供社区使用。

Abstract: Pre-trained foundation models have demonstrated remarkable success in vision
and language, yet their potential for general machine signal modeling-covering
acoustic, vibration, and other industrial sensor data-remains under-explored.
Existing approach using sub-band-based encoders has achieved competitive
results but are limited by fixed input lengths, and the absence of explicit
frequency positional encoding. In this work, we propose a novel foundation
model that integrates an advanced band-split architecture with relative
frequency positional embeddings, enabling precise spectral localization across
arbitrary sampling configurations. The model supports inputs of arbitrary
length without padding or segmentation, producing a concise embedding that
retains both temporal and spectral fidelity. We evaluate our method on SIREN
(https://github.com/yucongzh/SIREN), a newly introduced large-scale benchmark
for machine signal encoding that unifies multiple datasets, including all DCASE
task 2 challenges (2020-2025) and widely-used industrial signal corpora.
Experimental results demonstrate consistent state-of-the-art performance in
anomaly detection and fault identification, confirming the effectiveness and
generalization capability of the proposed model. We open-sourced ECHO on
https://github.com/yucongzh/ECHO.

</details>

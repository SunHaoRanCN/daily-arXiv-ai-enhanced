<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 8]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.SD](#cs.SD) [Total: 9]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [A Refined Alternating Optimization for Sum Rate Maximization in SIM-Aided Multiuser MISO Systems](https://arxiv.org/abs/2508.15257)
*Eduard E. Bahingayi,Shuying Lin,Murat Uysal,Marco Di Renzo,Le-Nam Tran*

Main category: eess.SP

TL;DR: 本文提出了一种改进的交替优化方法，通过先优化SIM相位偏移再优化数字波束成形，以及使用迭代投影梯度方法，显著提升了堆叠智能超表面多用户MISO系统的和速率性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究在优化SIM相位偏移和数字波束成形时通常采用交替优化框架，但当SIM层数增加时性能容易饱和。本文旨在解决这一性能瓶颈问题。

Method: 提出改进的交替优化方法：1）先优化SIM相位偏移再优化数字波束成形；2）使用迭代投影梯度方法而非单步投影梯度来优化相位偏移。

Result: 所提方法相比基准方案实现了高达115.53%的和速率提升，在SIM层数增加时不会出现性能饱和现象。

Conclusion: 优化顺序和投影梯度方法的选择对SIM系统性能至关重要，本文提出的定制化方法能显著提升系统性能。

Abstract: Stacked intelligent metasurfaces (SIMs) have emerged as a disruptive
technology for future wireless networks. To investigate their capabilities, we
study the sum rate maximization problem in an SIM-based multiuser (MU)
multiple-input single-output (MISO) downlink system. A vast majority of pioneer
studies, if not all, address this fundamental problem using the prevailing
alternating optimization (AO) framework, where the digital beamforming (DB) and
SIM phase shifts are optimized alternately. However, many of these approaches
suffer from suboptimal performance, quickly leading to performance saturation,
when the number of SIM layers increases assuming the \emph{fixed SIM
thickness}. In this letter, we demonstrate that significant performance gains
can still be achieved, and such saturation does not occur with the proposed
method in the considered setting. To this end, we provide practical design
guidelines to improve AO-based optimization of digital precoders and SIM phase
shifts. Specifically, we show that (i) optimizing the SIM phase shifts first
yields significant performance improvements, compared to optimizing the DB
first; and (ii) when applying projected gradient (PG) methods, which are
gradually becoming more popular to optimize the phase shifts thanks to their
scalability, we find that using an iterative PG method achieves better
performance than the single PG step, which is commonly used in existing
solutions. Based on these customizations, the proposed method achieves a higher
achievable sum rate (ASR) of up to $\ensuremath{115.53\%}$, compared to
benchmark schemes for the scenarios under consideration.

</details>


### [2] [Performance Analysis of RIS-Aided High-Mobility Wireless Systems](https://arxiv.org/abs/2508.15375)
*Hanwen Hu,Jiancheng An,Lu Gan,Chau Yuen*

Main category: eess.SP

TL;DR: 本文研究RIS辅助的高速列车MISO通信系统，提出BCD算法联合优化RIS相移和发射波束赋形，显著提升系统性能15dB，消除中断概率并改善关键指标。


<details>
  <summary>Details</summary>
Motivation: RIS技术在无线网络中具有巨大潜力，特别是在解决高速移动场景中的多普勒频移和快速衰落等通信挑战方面，因此研究RIS在高速列车通信系统中的应用具有重要意义。

Method: 提出块坐标下降(BCD)算法，联合优化RIS相移和发射波束赋形向量，以最大化信道增益。

Result: 数值结果表明，所提算法显著提升系统性能，平均信道增益比传统方案提高15dB，消除中断概率，并改善可达速率、信道容量和误码率等关键性能指标。

Conclusion: RIS在增强高速列车通信系统性能方面发挥着关键作用，证明了其在高速移动场景中的有效性和重要性。

Abstract: Reconfigurable intelligent surface (RIS) technology holds immense potential
for increasing the performance of wireless networks. Therefore, RIS is also
regarded as one of the solutions to address communication challenges in
high-mobility scenarios, such as Doppler shift and fast fading. This paper
investigates a high-speed train (HST) multiple-input single-output (MISO)
communication system aided by a RIS. We propose a block coordinate descent
(BCD) algorithm to jointly optimize the RIS phase shifts and the transmit
beamforming vectors to maximize the channel gain. Numerical results are
provided to demonstrate that the proposed algorithm significantly enhances the
system performance, achieving an average channel gain improvement of 15 dB
compared to traditional schemes. Additionally, the introduction of RIS
eliminates outage probability and improves key performance metrics such as
achievable rate, channel capacity, and bit error rate (BER). These findings
highlight the critical role of RIS in enhancing HST communication systems.

</details>


### [3] [Lightweight Gradient Descent Optimization for Mitigating Hardware Imperfections in RIS Systems](https://arxiv.org/abs/2508.15544)
*Pedro H. C. de Souza,Luiz A. M. Pereira,Faustino R. Gómez,Elsa M. Materón,Jorge Ricardo Mejía-Salazar*

Main category: eess.SP

TL;DR: 本文提出了一种梯度下降优化方法来缓解RIS辅助宽带通信系统中的硬件缺陷，包括相位偏移噪声和表面变形问题


<details>
  <summary>Details</summary>
Motivation: 随着6G标准化进程推进，可重构智能表面(RIS)技术面临实际部署中的硬件缺陷问题，需要分析并解决这些实际限制

Method: 采用梯度下降优化算法来补偿RIS系统中的硬件缺陷，特别是相位偏移噪声和表面变形

Result: 数值结果表明所提出的优化方法能够有效补偿硬件缺陷，提高系统性能

Conclusion: 该优化方法为RIS技术在实际部署中面临的硬件缺陷问题提供了可行的解决方案，有助于RIS技术的实际应用

Abstract: Ongoing discussions about the future of wireless communications are reaching
a turning point as standardization activities for the sixth generation of
mobile networks (6G) become more mature. New technologies must now face renewed
scrutiny by the industry and academia in order to be ready for deployment in
the near future. Recently, reconfigurable intelligent surfaces (RISs) gained
attention as a promising solution for improving the propagation conditions of
signal transmission in general. The RIS is a planar array of tunable resonant
elements designed to dynamically and precisely manipulate the reflection of
incident electromagnetic waves. However, the physical structure of the RIS and
its components may be subject to practical limitations and imperfections. It is
imperative that the hardware imperfections (HWIs) associated with the RIS be
analyzed, so that it remains a feasible technology from a practical standpoint.
Moreover, solutions for mitigating the HWIs must be considered, as is discussed
in this work. More specifically, we introduce a gradient descent optimization
for mitigating HWIs in RIS-aided wideband communication systems. Numerical
results show that the proposed optimization is able to compensate for HWIs such
as the phase-shift noise (PSN) and RIS surface deformations.

</details>


### [4] [Frequency Selective Reflection of Wideband Signals with Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2508.15581)
*Pedro H. C. de Souza,Luciano Mendes*

Main category: eess.SP

TL;DR: 提出了一种针对可重构智能表面(RIS)的频率选择性信号反射配置方法，解决宽频带信号反射中的带宽限制问题


<details>
  <summary>Details</summary>
Motivation: RIS技术在无线传播环境控制方面具有前景，但经常被忽视的是宽频带信号反射的潜在带宽限制问题，这可能成为下一代通信系统采用RIS的障碍

Method: 提出了一种RIS配置方法，能够为宽频带信号提供频率选择性信号反射

Result: 该方法能够有效处理宽频带信号的反射问题

Conclusion: 所提出的频率选择性反射配置方法有助于克服RIS在宽频带通信系统中的带宽限制障碍

Abstract: Recently, the reconfigurable intelligent surface (RIS) technology has ushered
in the prospect of control over the wireless propagation environment. By
establishing alternative propagation paths for the transmitted signals, and by
reflecting them in a controllable manner, the RIS is able to improve the signal
reception. However, an aspect often overlooked is the potential bandwidth
restrictions on the wideband signal reflected by the RIS. If not carefully
considered, this can become an impediment for the adoption of the RIS in the
next generation of communications systems. Therefore, in this work we propose a
RIS configuration method that provides frequency selective signal reflection
for wideband signals.

</details>


### [5] [On the Compromise Between Performance and Efficiency in RIS-aided Communication Systems](https://arxiv.org/abs/2508.15599)
*P. H. C. de Souza,M. Khazaee,L. L. Mendes*

Main category: eess.SP

TL;DR: 本文探讨了可重构智能表面(RIS)技术在无线通信系统中的应用，重点分析了RIS配置优化、多普勒频移补偿以及STAR-RIS技术的扩展功能。


<details>
  <summary>Details</summary>
Motivation: 传统RIS系统受限于仅反射功能，限制了空间覆盖范围和信号放大潜力，需要开发同时具备透射和反射功能的智能表面技术来突破这些限制。

Method: 采用神经网络(NN)进行RIS元件配置优化，选择最佳相移组合以最大化信道容量；引入同时透射反射可重构智能表面(STAR-RIS)技术实现双向信号处理。

Result: 神经网络方法显著减少了RIS重新配置次数，降低了配置开销；RIS能够以较小性能代价补偿多普勒频移；STAR-RIS技术增强了覆盖范围、能效和延迟减少，同时提高了总速率和物理层安全性。

Conclusion: STAR-RIS技术通过同时透射和反射信号的双重功能，有效解决了传统RIS系统的局限性，为无线通信系统提供了更优越的性能和更广泛的应用前景。

Abstract: The reconfigurable intelligent surface (RIS) technology for metasurfaces is
ushering in a new paradigm for wireless communication systems. It provides an
accessible way for controlling the interaction between electromagnetic waves
with the propagation medium. One particularly important aspect is the
configuration of the RIS elements or reflectors. Simply stated, the objective
of the RIS configuration is to choose the optimum phase-shift combination that
maximizes the channel capacity. Recently, neural networks (NNs) were proposed
for tackling this task and results have shown that the proposed NN promotes far
less reconfigurations of the RIS, consequently reducing the configuration
overhead. Beyond that, the RIS can be repurposed for tackling the Doppler shift
in high-mobility communication systems. Despite not being its usual primary
goal, results have also demonstrated that the RIS can compensate for the
Doppler shift at a small cost in performance. However, the typical
reflection-only constraint for RIS systems limits the spatial coverage and
signal amplification potential achieved by such systems. Therefore, the
simultaneously transmitting and reflecting reconfigurable intelligent surface
(STAR-RIS) can be employed to address these limitations by its dual
functionality of transmitting and reflecting signals concurrently. It can be
shown that the STAR-RIS can augment coverage, energy efficiency, and latency
reduction, while enhancing sum-rate and physical-layer security across several
wireless contexts.

</details>


### [6] [Discrete Radar based on Modulo Arithmetic](https://arxiv.org/abs/2508.15671)
*Nishant Mehrotra,Sandesh Rao Mattu,Saif Khan Mohammed,Ronny Hadani,Robert Calderbank*

Main category: eess.SP

TL;DR: Zak-OTFS调制方案在延迟多普勒域形成信号，可用于雷达感知。通过离散海森堡-外尔群和辛变换方法，将传统雷达信号处理的复杂度从O(B²T²)降低到O(BT log T)，并实现最优雷达波形设计。


<details>
  <summary>Details</summary>
Motivation: 传统连续雷达信号处理复杂度高（O(B²T²)），需要开发更高效的处理方法。Zak-OTFS调制方案在通信领域已有应用，可扩展到雷达感知领域，通过离散化方法降低计算复杂度。

Method: 在延迟多普勒域形成雷达波形，通过匹配滤波和相关处理生成散射环境图像。采用离散海森堡-外尔群替代连续群，通过辛变换规范化离散群，选择最大交换子群的共同特征向量作为雷达波形。

Result: 成功将雷达信号处理复杂度从O(B²T²)显著降低到O(BT log T)，实现了延迟分辨率1/B和多普勒分辨率1/T。通过辛变换能够定义具有低峰均功率比的最优雷达波形库。

Conclusion: Zak-OTFS调制方案可有效应用于雷达感知，离散化方法和辛变换技术大幅降低了计算复杂度，为高效雷达信号处理提供了新的理论框架和实用方法。

Abstract: Zak-OTFS is modulation scheme where signals are formed in the delay-Doppler
(DD) domain, converted to the time domain (DD) for transmission and reception,
then returned to the DD domain for processing. We describe how to use the same
architecture for radar sensing. The intended delay resolution is $\frac{1}{B}$
where $B$ is the radar bandwidth, and the intended Doppler resolution is
$\frac{1}{T}$ where $T$ is the transmission time. We form a radar waveform in
the DD domain, illuminate the scattering environment, match filter the return,
then correlate with delay and Doppler shifts of the transmitted waveform. This
produces an image of the scattering environment, and the radar ambiguity
function expresses the blurriness of this image. The possible delay and Doppler
shifts generate the continuous Heisenberg-Weyl group which has been widely
studied in the theory of radar. We describe how to approach the problem of
waveform design, not from the perspective of this continuous group, but from
the perspective of a discrete group of delay and Doppler shifts, where the
discretization is determined by the intended delay and Doppler resolution of
the radar. We describe how to approach the problem of shaping the ambiguity
surface through symplectic transformations that normalize our discrete
Heisenberg-Weyl group. The complexity of traditional continuous radar signal
processing is $\mathcal{O}\big(B^2T^2\big)$. We describe how to reduce this
complexity to $\mathcal{O}\big(BT\log T\big)$ by choosing the radar waveform to
be a common eigenvector of a maximal commutative subgroup of our discrete
Heisenberg-Weyl group. The theory of symplectic transformations also enables
defining libraries of optimal radar waveforms with small peak-to-average power
ratios.

</details>


### [7] [A Grant-free Coded Random Access Scheme for Near-field Communications](https://arxiv.org/abs/2508.15673)
*Enrico Testi,Giulia Torcolacci,Nicolò Decarli,Davide Dardari,Enrico Paolini*

Main category: eess.SP

TL;DR: 这篇论文提出了一种结合近场空间复用和编码随机访问的创新方案，用于工业物联网的大规模设备通信，提高了可靠性并降低了访问延迟。


<details>
  <summary>Details</summary>
Motivation: 工业物联网需要处理大规模间隔性流量，而无授权随机访问协议是具有扩展性和可靠性的解决方案。同时，新型无线硬件技术使网络运行进入近场传播段，为提高空间复用能力提供了机会。

Method: 该方案结合近场空间复用技术和编码随机访问协议，利用极大强度天线阵列在接入点进行干扰减少。通过这种整合方式来处理IIoT设备的大规模间隔性通信。

Result: 该方法提高了网络连接的可靠性，显著降低了访问延迟，为下一代6G网络中的工业物联网连接提供了稳健的框架。

Conclusion: 结合近场空间复用和编码随机访问的方案能够有效解决工业物联网大规模设备通信的挑战，为6G网络的IIoT应用提供了有效的技术支撑。

Abstract: The industrial Internet of things (IIoT) is revolutionizing industrial
processes by facilitating massive machine-type communications among countless
interconnected devices. To efficiently handle the resulting large-scale and
sporadic traffic, grant-free random access protocols-especially coded random
access (CRA)-have emerged as scalable and reliable solutions. At the same time,
advancements in wireless hardware, including extremely large-scale MIMO arrays
and high-frequency communication (e.g., mmWave, Terahertz), are pushing network
operations into the near-field propagation regime, allowing for dense
connectivity and enhanced spatial multiplexing. This paper proposes an
innovative approach that combines near-field spatial multiplexing with the
interference mitigation capabilities of CRA, utilizing an extremely large
aperture array at the access point. This integration improves reliability and
reduces access latency, offering a robust framework for IIoT connectivity in
next-generation 6G networks.

</details>


### [8] [Estimation-Theoretic Bias Reduction for Oscillometric Blood Pressure Readings](https://arxiv.org/abs/2508.15687)
*Masoud Nateghi,Reza Sameni*

Main category: eess.SP

TL;DR: 本研究分析了示波法血压测量的系统误差来源，提出基于最小二乘和最大似然估计的统计校正框架，可提高非侵入性血压监测的准确性。


<details>
  <summary>Details</summary>
Motivation: 示波法作为标准的无创血压测量方法存在系统误差，可能影响临床准确性。研究旨在分析误差来源（示波法自身局限和呼吸波动），并开发校正方法提高测量精度。

Method: 使用MIMIC数据库的血压波形数据，提出估计理论框架，采用最小二乘(LS)和最大似然(ML)方法校正单次和重复血压测量。LS支持传统多次测量平均协议，ML方法整合测量误差的先验知识。

Result: 示波法倾向于低估收缩压和高估舒张压，呼吸引入周期性变化进一步降低测量精度。统计先验知识在多读数中的应用可以显著提高非侵入性血压监测的准确性。

Conclusion: 基于统计先验的校正框架能有效改善示波法血压测量的系统误差，对提高心血管疾病诊断和治疗具有潜在重要意义。

Abstract: Oscillometry is the standard method for non-invasive, cuff-based blood
pressure (BP) measurement, but it introduces systematic errors that may impact
clinical accuracy. This study investigates the sources of these
errors--primarily the limitations of oscillometry itself and
respiration-induced fluctuations--using BP waveform data from the MIMIC
database. Oscillometry tends to underestimate systolic BP and overestimate
diastolic BP, while respiration introduces cyclical variations that further
degrade measurement precision. To mitigate these effects, we propose an
estimation-theoretic framework employing least squares (LS) and maximum
likelihood (ML) methods for correcting both single and repeated BP
measurements. LS estimation supports conventional multi-measurement averaging
protocols, whereas the ML approach incorporates prior knowledge of measurement
errors, offering improved performance. Our results demonstrate that leveraging
statistical priors across multiple readings can enhance the accuracy of
non-invasive BP monitoring, with potential implications for improving
cardiovascular diagnosis and treatment.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [9] [A Chinese Heart Failure Status Speech Database with Universal and Personalised Classification](https://arxiv.org/abs/2508.14908)
*Yue Pan,Liwei Liu,Changxin Li,Xinyao Wang,Yili Xia,Hanyue Zhang,Ming Chu*

Main category: eess.AS

TL;DR: 首个中文心衰病人语音数据库，证实中文音节含有心衰病检测信息，提出个人化分类方法和适配频率滤波器。


<details>
  <summary>Details</summary>
Motivation: 语音作为一种成本效益高、非侵入性的数据源，可用于心衰病识别，但缺乏关于中文音节是否含有心衰病相关信息的研究。

Method: 建立首个中文心衰病语音数据库，包含入院前后的配对录音；采用标准病人分类和个人化配对分类方法；提出适配频率滤波器(AFF)进行频率重要性分析。

Result: 证实中文语言在心衰病检测中的有效性，统计测试和分类结果显示个体差异是影响准确性的关键因素。

Conclusion: 该研究为中文心衰病语音识别领域提供了重要数据基础，个人化分类方法可作为未来研究的理想基准，适配频率滤波器为频率特征分析提供新方法。

Abstract: Speech is a cost-effective and non-intrusive data source for identifying
acute and chronic heart failure (HF). However, there is a lack of research on
whether Chinese syllables contain HF-related information, as observed in other
well-studied languages. This study presents the first Chinese speech database
of HF patients, featuring paired recordings taken before and after
hospitalisation. The findings confirm the effectiveness of the Chinese language
in HF detection using both standard 'patient-wise' and personalised 'pair-wise'
classification approaches, with the latter serving as an ideal
speaker-decoupled baseline for future research. Statistical tests and
classification results highlight individual differences as key contributors to
inaccuracy. Additionally, an adaptive frequency filter (AFF) is proposed for
frequency importance analysis. The data and demonstrations are published at
https://github.com/panyue1998/Voice_HF.

</details>


### [10] [Transsion Multilingual Speech Recognition System for MLC-SLM 2025 Challenge](https://arxiv.org/abs/2508.14916)
*Xiaoxiao Li,An Zhu,Youhai Jiang,Fengjie Zhu*

Main category: eess.AS

TL;DR: 本文提出了一种基于Whisper和Qwen2.5的多语言语音识别系统，在MLC-SLM 2025挑战赛Track 1中取得第三名，跨11种语言的词错误率为9.83%。


<details>
  <summary>Details</summary>
Motivation: 开发一个高效的多语言自动语音识别系统，通过结合预训练模型和任务特定微调来解决多语言ASR的挑战。

Method: 系统包含三个核心组件：1)冻结的Whisper-large-v3语音编码器；2)可训练的线性-ReLU-线性适配器模块；3)冻结的Qwen2.5-7B-Instruct大语言模型与可训练LoRA结合。

Result: 在评估集的11种语言上实现了9.83%的词/字符错误率(WER/CER)，在全球参赛者中排名第三。

Conclusion: 通过系统性地结合预训练模型和任务特定微调，成功构建了高效的多语言ASR系统，证明了该架构在多语言语音识别任务中的有效性。

Abstract: This paper presents the architecture and performance of a novel Multilingual
Automatic Speech Recognition (ASR) system developed by the Transsion Speech
Team for Track 1 of the MLC-SLM 2025 Challenge. The proposed system comprises
three key components: 1) a frozen Whisper-large-v3 based speech encoder,
leveraging large-scale pretraining to ensure robust acoustic feature
extraction; 2) a trainable adaptor module using Linear-ReLU-Linear
transformation mechanisms to effectively align speech and text representations;
and 3) a frozen Qwen2.5-7B-Instruct large language model (LLM) integrated with
trainable LoRA for optimized contextual linguistic decoding. By systematically
combining pretrained models with task specific fine-tuning, the system achieved
a word/character error rate (WER/CER) of 9.83% across 11 languages in the
evaluation set and ranked third place among global participants.

</details>


### [11] [Mitigating Hallucinations in LM-Based TTS Models via Distribution Alignment Using GFlowNets](https://arxiv.org/abs/2508.15442)
*Chenlin Liu,Minghui Fang,Patrick Zhang,Wei Zhou,Jie Gao,Jiqing Han*

Main category: eess.AS

TL;DR: GOAT是一个后训练框架，通过分布对齐技术减少LM-based TTS系统的语音幻觉问题，无需大量资源或增加推理延迟


<details>
  <summary>Details</summary>
Motivation: 现有的LM-based TTS系统容易产生偏离输入文本的语音幻觉，现有解决方案要么需要过多训练资源，要么引入显著推理延迟

Method: 首先进行不确定性分析，发现幻觉与模型不确定性正相关；将TTS生成重构为轨迹流优化问题，引入增强的子轨迹平衡目标和锐化内部奖励作为目标分布；集成奖励温度衰减和学习率优化

Result: 在挑战性测试案例上减少超过50%的字符错误率，不确定性降低达58%

Conclusion: GOAT框架在减少语音幻觉方面表现出强大的泛化能力和有效性，解决了资源消耗和延迟问题

Abstract: Language Model (LM)-based Text-to-Speech (TTS) systems often generate
hallucinated speech that deviates from input text. Existing mitigation
strategies either demand excessive training resources or introduce significant
inference latency. In this paper, we propose GFlOwNet-guided distribution
AlignmenT (GOAT) for LM-based TTS, a post-training framework that mitigates
hallucinations without relying on massive resources or inference cost.
Specifically, we first conduct an uncertainty analysis, revealing a strong
positive correlation between hallucination and model uncertainty. Based on
this, we reformulate TTS generation as a trajectory flow optimization problem
and introduce an enhanced Subtrajectory Balance objective together with a
sharpened internal reward as target distribution. We further integrate reward
temperature decay and learning rate optimization for stability and performance
balance. Extensive experiments show that GOAT reduce over 50% character error
rates on challenging test cases and lowering uncertainty by up to 58%,
demonstrating its strong generalization ability and effectiveness.

</details>


### [12] [EffortNet: A Deep Learning Framework for Objective Assessment of Speech Enhancement Technologies Using EEG-Based Alpha Oscillations](https://arxiv.org/abs/2508.15473)
*Ching-Chih Sung,Cheng-Hung Hsin,Yu-Anne Shiah,Bo-Jyun Lin,Yi-Xuan Lai,Chia-Ying Lee,Yu-Te Wang,Borchin Su,Yu Tsao*

Main category: eess.AS

TL;DR: EffortNet是一个深度学习框架，通过EEG信号解码个体在语音理解时的听力努力程度，结合自监督学习、增量学习和迁移学习来处理个体差异，在噪声语音处理中达到80.9%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 听力努力是语音听力研究中的重要挑战，特别是在老年人和听力受损人群中。现有方法难以处理EEG信号的个体间变异性，需要开发能够个性化评估听力技术的解决方案。

Method: 收集122名参与者在四种语音条件（清晰、噪声、MMSE增强、Transformer增强）下的64通道EEG数据。使用alpha振荡功率作为生物标志物。EffortNet整合三种学习范式：自监督学习利用未标记数据，增量学习逐步适应个体特征，迁移学习实现向新受试者的高效知识迁移。

Result: alpha振荡在噪声语音处理中功率显著更高。EffortNet仅需新受试者40%的训练数据即可达到80.9%的分类准确率，显著优于传统CNN（62.3%）和STAnet（61.1%）模型。基于概率的度量显示Transformer增强语音的神经响应更接近清晰语音。

Conclusion: EffortNet为个性化听力技术评估提供了实用解决方案，有助于设计认知感知的语音增强系统。研究发现Transformer增强在神经水平上优于MMSE增强，尽管主观可懂度评分相反，但符合客观指标。

Abstract: This paper presents EffortNet, a novel deep learning framework for decoding
individual listening effort from electroencephalography (EEG) during speech
comprehension. Listening effort represents a significant challenge in
speech-hearing research, particularly for aging populations and those with
hearing impairment. We collected 64-channel EEG data from 122 participants
during speech comprehension under four conditions: clean, noisy, MMSE-enhanced,
and Transformer-enhanced speech. Statistical analyses confirmed that alpha
oscillations (8-13 Hz) exhibited significantly higher power during noisy speech
processing compared to clean or enhanced conditions, confirming their validity
as objective biomarkers of listening effort. To address the substantial
inter-individual variability in EEG signals, EffortNet integrates three
complementary learning paradigms: self-supervised learning to leverage
unlabeled data, incremental learning for progressive adaptation to individual
characteristics, and transfer learning for efficient knowledge transfer to new
subjects. Our experimental results demonstrate that Effort- Net achieves 80.9%
classification accuracy with only 40% training data from new subjects,
significantly outperforming conventional CNN (62.3%) and STAnet (61.1%) models.
The probability-based metric derived from our model revealed that
Transformer-enhanced speech elicited neural responses more similar to clean
speech than MMSEenhanced speech. This finding contrasted with subjective
intelligibility ratings but aligned with objective metrics. The proposed
framework provides a practical solution for personalized assessment of hearing
technologies, with implications for designing cognitive-aware speech
enhancement systems.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [13] [Denoising by neural network for muzzle blast detection](https://arxiv.org/abs/2508.14919)
*Hadrien Pujol,Matteo Bevillacqua,Christophe Thirard,Thierry Mazoyer*

Main category: cs.SD

TL;DR: 开发轻量级神经网络用于军事车辆上的枪声检测系统降噪，显著提高枪口冲击波检测率


<details>
  <summary>Details</summary>
Motivation: 军事车辆移动环境中的噪音会降低枪声检测系统的性能，需要开发计算资源需求低的降噪算法

Method: 采用两层隐藏层感知器神经网络结合信号处理技术，替代重型卷积神经网络

Result: 在噪声与枪口冲击波峰值幅度相当时，检测率提高了一倍以上

Conclusion: 轻量级神经网络架构能有效提升移动军事环境中枪声检测系统的性能

Abstract: Acoem develops gunshot detection systems, consisting of a microphone array
and software that detects and locates shooters on the battlefield. The
performance of such systems is obviously affected by the acoustic environment
in which they are operating: in particular, when mounted on a moving military
vehicle, the presence of noise reduces the detection performance of the
software. To limit the influence of the acoustic environment, a neural network
has been developed. Instead of using a heavy convolutional neural network, a
lightweight neural network architecture was chosen to limit the computational
resources required to embed the algorithm on as many hardware platforms as
possible. Thanks to the combination of a two hidden layer perceptron and
appropriate signal processing techniques, the detection rate of impulsive
muzzle blast waveforms (the wave coming from the detonation and indicating the
position of the shooter) is significantly increased. With a rms value of noise
of the same order as the muzzle blast peak amplitude, the detect rate is more
than doubled with this denoising processing.

</details>


### [14] [Human Feedback Driven Dynamic Speech Emotion Recognition](https://arxiv.org/abs/2508.14920)
*Ilya Fedorov,Dmitry Korobchenko*

Main category: cs.SD

TL;DR: 本文提出了一种新的动态语音情感识别方法，采用Dirichlet分布模型化情感混合，通过多阶段训练和人类反馈优化，在3D演员动画数据集上进行评估，结果显示该方法在模型情感混合方面更有效。


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别方法假设每段音频只包含单一情感，而本研究认为音频跟随时间变化的情感序列相关联，特别关注于情感3D虚拟人物的动画应用。

Method: 提出多阶段方法：训练传统语音情感识别模型、合成生成情感序列、基于人类反馈的模型优化。还提出了基于Dirichlet分布的情感混合模型新方法。

Result: 在3D面部动画数据集上进行评估，与滑动窗口方法进行对比。实验结果显示Dirichlet基础方法在模型情感混合方面有效。结合人类反馈进一步提升了模型质量，同时简化了标注流程。

Conclusion: 本研究成功开拓了动态语音情感识别的新领域，Dirichlet模型在处理情感混合问题上表现优异，结合人类反馈的方法为该领域提供了有效的解决方案。

Abstract: This work proposes to explore a new area of dynamic speech emotion
recognition. Unlike traditional methods, we assume that each audio track is
associated with a sequence of emotions active at different moments in time. The
study particularly focuses on the animation of emotional 3D avatars. We propose
a multi-stage method that includes the training of a classical speech emotion
recognition model, synthetic generation of emotional sequences, and further
model improvement based on human feedback. Additionally, we introduce a novel
approach to modeling emotional mixtures based on the Dirichlet distribution.
The models are evaluated based on ground-truth emotions extracted from a
dataset of 3D facial animations. We compare our models against the sliding
window approach. Our experimental results show the effectiveness of
Dirichlet-based approach in modeling emotional mixtures. Incorporating human
feedback further improves the model quality while providing a simplified
annotation procedure.

</details>


### [15] [XAI-Driven Spectral Analysis of Cough Sounds for Respiratory Disease Characterization](https://arxiv.org/abs/2508.14949)
*Patricia Amado-Caballero,Luis Miguel San-José-Revuelta,María Dolores Aguilar-García,José Ramón Garmendia-Leiza,Carlos Alberola-López,Pablo Casaseca-de-la-Higuera*

Main category: cs.SD

TL;DR: 提出基于可解释人工智能(XAI)的方法，通过遮挡图分析咳嗽声谱图来识别呼吸系统疾病的特异性声学特征，提高咳嗽声音分析的诊断能力。


<details>
  <summary>Details</summary>
Motivation: 传统咳嗽声谱图分析缺乏显著差异，需要更可解释的方法来揭示疾病特异性声学特征，提升呼吸系统疾病管理的诊断能力。

Method: 使用卷积神经网络(CNN)处理咳嗽声谱图，生成遮挡图突出相关频谱区域，然后对加权声谱图进行频谱分析，提取多个频谱特征。

Result: 在COPD患者中发现咳嗽模式在识别出的感兴趣频谱区域中更具变异性，而原始声谱图分析未显示显著差异。

Conclusion: XAI技术能够揭示疾病特异性声学签名，通过提供更可解释的结果来增强咳嗽声音分析的诊断能力。

Abstract: This paper proposes an eXplainable Artificial Intelligence (XAI)-driven
methodology to enhance the understanding of cough sound analysis for
respiratory disease management. We employ occlusion maps to highlight relevant
spectral regions in cough spectrograms processed by a Convolutional Neural
Network (CNN). Subsequently, spectral analysis of spectrograms weighted by
these occlusion maps reveals significant differences between disease groups,
particularly in patients with COPD, where cough patterns appear more variable
in the identified spectral regions of interest. This contrasts with the lack of
significant differences observed when analyzing raw spectrograms. The proposed
approach extracts and analyzes several spectral features, demonstrating the
potential of XAI techniques to uncover disease-specific acoustic signatures and
improve the diagnostic capabilities of cough sound analysis by providing more
interpretable results.

</details>


### [16] [Comparative Evaluation of Text and Audio Simplification: A Methodological Replication Study](https://arxiv.org/abs/2508.15088)
*Prosanta Barai,Gondy Leroy,Arif Ahmed*

Main category: cs.SD

TL;DR: 本研究是对Leroy等人(2022)研究的复制，验证了文本简化在音频医疗信息理解中的有效性，发现简化文本能提升感知理解度和实际理解效果。


<details>
  <summary>Details</summary>
Motivation: 随着多媒体环境发展，音频内容在医疗信息传播中日益重要，需要验证文本简化方法在音频内容中的适用性和效果。

Method: 采用44名参与者，使用Leroy等人原始文本和简化文本生成的音频内容，评估参与者对医疗信息的理解程度，并考察教育水平和语言能力的影响。

Result: 文本简化有效提升了感知理解度和实际理解效果，与原始研究结果一致；教育水平和语言能力对医疗信息获取和理解有潜在影响。

Conclusion: 文本简化工具对促进健康素养具有实用价值，医疗领域需要定制化的沟通策略来有效触达多样化受众。

Abstract: This study serves as a methodological replication of Leroy et al. (2022)
research, which investigated the impact of text simplification on healthcare
information comprehension in the evolving multimedia landscape. Building upon
the original studys insights, our replication study evaluates audio content,
recognizing its increasing importance in disseminating healthcare information
in the digital age. Specifically, we explored the influence of text
simplification on perceived and actual difficulty when users engage with audio
content automatically generated from that text. Our replication involved 44
participants for whom we assessed their comprehension of healthcare information
presented as audio created using Leroy et al. (2022) original and simplified
texts. The findings from our study highlight the effectiveness of text
simplification in enhancing perceived understandability and actual
comprehension, aligning with the original studys results. Additionally, we
examined the role of education level and language proficiency, shedding light
on their potential impact on healthcare information access and understanding.
This research underscores the practical value of text simplification tools in
promoting health literacy. It suggests the need for tailored communication
strategies to reach diverse audiences effectively in the healthcare domain.

</details>


### [17] [An Enhanced Audio Feature Tailored for Anomalous Sound Detection Based on Pre-trained Models](https://arxiv.org/abs/2508.15334)
*Guirui Zhong,Qing Wang,Jun Du,Lei Wang,Mingqi Cai,Xin Fang*

Main category: cs.SD

TL;DR: 本文提出了一种新的均匀分布滤波器组音频特征提取方法和无参数特征增强方法，用于提高异常声音检测的性能。


<details>
  <summary>Details</summary>
Motivation: 机器声音中异常位置的不确定性以及噪声等冗余信息阻碍了ASD系统性能的提升，需要更有效的特征提取方法。

Method: 1）提出均匀间隔分布的滤波器组音频特征，确保对所有频段的均等关注 2）基于预训练模型的无参数特征增强方法，去除音频中的冗余信息

Result: 在DCASE 2024挑战赛数据集上的评估结果显示，提出的方法对ASD性能有显著提升

Conclusion: 该方法能够有效地提取机器声音的关键特征，减少冗余信息干扰，为异常声音检测领域提供了有效的解决方案

Abstract: Anomalous Sound Detection (ASD) aims at identifying anomalous sounds from
machines and has gained extensive research interests from both academia and
industry. However, the uncertainty of anomaly location and much redundant
information such as noise in machine sounds hinder the improvement of ASD
system performance. This paper proposes a novel audio feature of filter banks
with evenly distributed intervals, ensuring equal attention to all frequency
ranges in the audio, which enhances the detection of anomalies in machine
sounds. Moreover, based on pre-trained models, this paper presents a
parameter-free feature enhancement approach to remove redundant information in
machine audio. It is believed that this parameter-free strategy facilitates the
effective transfer of universal knowledge from pre-trained tasks to the ASD
task during model fine-tuning. Evaluation results on the Detection and
Classification of Acoustic Scenes and Events (DCASE) 2024 Challenge dataset
demonstrate significant improvements in ASD performance with our proposed
methods.

</details>


### [18] [AudioSet-R: A Refined AudioSet with Multi-Stage LLM Label Reannotation](https://arxiv.org/abs/2508.15429)
*Yulin Sun,Qisheng Xu,Yi Su,Qian Zhu,Yong Dou,Xinwang Liu,Kele Xu*

Main category: cs.SD

TL;DR: 通过三阶段重标注框架利用音频-语言基础模型改喂AudioSet标签质量，构建了高质量的AudioSet-R数据集，在多个音频分类模型上均取得显著性能提升


<details>
  <summary>Details</summary>
Motivation: AudioSet作为音频研究领域的重要基准，存在标签准确性和完整性问题，严重限制了下游应用的性能表现

Method: 提出三阶段重标注框架，采用参考prompt chaining概念的跨模态提示策略，通过音频理解、标签合成和语义对齐三个子任务系统性改喂标签质量

Result: 在AST、PANNs、SSAST、AudioMAE等代表性音频分类模型上进行广泛实验，均实现了显著的性能提升，验证了方法在提高标签可靠性方面的普遍性和有效性

Conclusion: 所提框架能够系统性改喂AudioSet标签质量，构建的AudioSet-R数据集为音频研究领域提供了更可靠的基准资源，具有重要的实践价值

Abstract: AudioSet is a widely used benchmark in the audio research community and has
significantly advanced various audio-related tasks. However, persistent issues
with label accuracy and completeness remain critical bottlenecks that limit
performance in downstream applications.To address the aforementioned
challenges, we propose a three-stage reannotation framework that harnesses
general-purpose audio-language foundation models to systematically improve the
label quality of AudioSet. The framework employs a cross-modal prompting
strategy, inspired by the concept of prompt chaining, wherein prompts are
sequentially composed to execute subtasks (audio comprehension, label
synthesis, and semantic alignment). Leveraging this framework, we construct a
high-quality, structured relabeled version of AudioSet-R. Extensive experiments
conducted on representative audio classification models--including AST, PANNs,
SSAST, and AudioMAE--consistently demonstrate substantial performance
improvements, thereby validating the generalizability and effectiveness of the
proposed approach in enhancing label reliability.The code is publicly available
at: https://github.com/colaudiolab/AudioSet-R.

</details>


### [19] [DualMark: Identifying Model and Training Data Origins in Generated Audio](https://arxiv.org/abs/2508.15521)
*Xuefeng Yang,Jian Guan,Feiyang Xiao,Congyi Fan,Haohe Liu,Qiaoxi Zhu,Dongli Xu,Youtian Lin*

Main category: cs.SD

TL;DR: DualMark是首个双溯源水印框架，能够在音频生成模型中同时嵌入模型身份和数据集来源两种水印，解决了现有方法只能进行模型级溯源而无法追踪训练数据的问题。


<details>
  <summary>Details</summary>
Motivation: 现有音频生成模型水印方法只能识别生成模型的身份，但无法追踪底层训练数据集，这在版权和问责场景中存在重大限制。需要一种能够同时溯源模型和数据的方法。

Method: 提出了DualMark框架，包含双水印嵌入模块（DWE）将双水印嵌入梅尔频谱图表示，以及水印一致性损失（WCL）确保从生成音频中可靠提取两个水印。还建立了首个双溯源基准（DAB）。

Result: 实验验证DualMark达到出色的溯源准确率（模型溯源97.01% F1分数，数据集溯源91.51% AUC），在对抗剪枝、有损压缩、加性噪声和采样攻击等条件下保持卓越鲁棒性。

Conclusion: 该工作为完全可问责的音频生成模型提供了基础性进展，显著增强了版权保护和责任追踪能力。

Abstract: Existing watermarking methods for audio generative models only enable
model-level attribution, allowing the identification of the originating
generation model, but are unable to trace the underlying training dataset. This
significant limitation raises critical provenance questions, particularly in
scenarios involving copyright and accountability concerns. To bridge this
fundamental gap, we introduce DualMark, the first dual-provenance watermarking
framework capable of simultaneously encoding two distinct attribution
signatures, i.e., model identity and dataset origin, into audio generative
models during training. Specifically, we propose a novel Dual Watermark
Embedding (DWE) module to seamlessly embed dual watermarks into Mel-spectrogram
representations, accompanied by a carefully designed Watermark Consistency Loss
(WCL), which ensures reliable extraction of both watermarks from generated
audio signals. Moreover, we establish the Dual Attribution Benchmark (DAB), the
first robustness evaluation benchmark specifically tailored for joint
model-data attribution. Extensive experiments validate that DualMark achieves
outstanding attribution accuracy (97.01% F1-score for model attribution, and
91.51% AUC for dataset attribution), while maintaining exceptional robustness
against aggressive pruning, lossy compression, additive noise, and sampling
attacks, conditions that severely compromise prior methods. Our work thus
provides a foundational step toward fully accountable audio generative models,
significantly enhancing copyright protection and responsibility tracing
capabilities.

</details>


### [20] [Any-to-any Speaker Attribute Perturbation for Asynchronous Voice Anonymization](https://arxiv.org/abs/2508.15565)
*Liping Chen,Chenyang Guo,Rui Wang,Kong Aik Lee,Zhenhua Ling*

Main category: cs.SD

TL;DR: 这篇论文提出了一种任意到任意的训练策略和说话人对抗语音生成模型，通过批次均值损失将多个说话人的语音匿名化到共同的伪说话人，避免使用真实说话人带来隐私风险。


<details>
  <summary>Details</summary>
Motivation: 传统的目标攻击训练策略将语音匿名化到指定的真实说话人，可能侵害该说话人的隐私。需要一种更安全的方法来提高语音匿名化的识别不可链接性。

Method: 提出任意到任意训练策略，通过批次均值损失将训练小批中多个说话人的语音匿名化到共同的伪说话人（小批均值说话人）。构建说话人对抗语音生成模型，结合无目标攻击和任意到任意策略的监督。

Result: 在VoxCeleb数据集上的实验证明了该方法在异步语音匿名化中的有效性。还通过实验探索了说话人对抗语音在语音隐私保护中的潜在限制。

Conclusion: 该研究为语音匿名化提供了一种更安全的方法，避免使用真实说话人带来隐私风险。并为对抗黑盒说话提取器的防御效果和面向自适应攻击的稳健性研究提供了见解。

Abstract: Speaker attribute perturbation offers a feasible approach to asynchronous
voice anonymization by employing adversarially perturbed speech as anonymized
output. In order to enhance the identity unlinkability among anonymized
utterances from the same original speaker, the targeted attack training
strategy is usually applied to anonymize the utterances to a common designated
speaker. However, this strategy may violate the privacy of the designated
speaker who is an actual speaker. To mitigate this risk, this paper proposes an
any-to-any training strategy. It is accomplished by defining a batch mean loss
to anonymize the utterances from various speakers within a training mini-batch
to a common pseudo-speaker, which is approximated as the average speaker in the
mini-batch. Based on this, a speaker-adversarial speech generation model is
proposed, incorporating the supervision from both the untargeted attack and the
any-to-any strategies. The speaker attribute perturbations are generated and
incorporated into the original speech to produce its anonymized version. The
effectiveness of the proposed model was justified in asynchronous voice
anonymization through experiments conducted on the VoxCeleb datasets.
Additional experiments were carried out to explore the potential limitations of
speaker-adversarial speech in voice privacy protection. With them, we aim to
provide insights for future research on its protective efficacy against
black-box speaker extractors \textcolor{black}{and adaptive attacks, as well
as} generalization to out-of-domain datasets \textcolor{black}{and stability}.
Audio samples and open-source code are published in
https://github.com/VoicePrivacy/any-to-any-speaker-attribute-perturbation.

</details>


### [21] [ASCMamba: Multimodal Time-Frequency Mamba for Acoustic Scene Classification](https://arxiv.org/abs/2508.15632)
*Bochao Sun,Dong Wang,Han Yin*

Main category: cs.SD

TL;DR: 本文提出了ASCMamba多模态网络，用于音频场景分类任务，结合音频和文本信息，在APSIPA ASC 2025挑战赛中取得了最佳性能，相比基线提升6.2%。


<details>
  <summary>Details</summary>
Motivation: 传统的音频场景分类系统仅依赖音频输入，而APSIPA ASC 2025挑战赛引入了多模态任务，提供额外的文本信息（录音地点和时间），需要开发能够有效整合多模态信息的系统。

Method: 提出ASCMamba多模态网络：1）使用DenseEncoder从频谱图中提取层次化频谱特征；2）采用双路径Mamba块通过状态空间模型捕获长程时间和频率依赖关系；3）提出两步伪标签机制生成更可靠的伪标签。

Result: 所提出的系统在所有参赛团队中表现最佳，相比基线系统实现了6.2%的性能提升。

Conclusion: ASCMamba通过有效整合音频和文本信息，在多模态音频场景分类任务中取得了显著性能提升，证明了多模态方法在音频场景理解中的有效性。

Abstract: Acoustic Scene Classification (ASC) is a fundamental problem in computational
audition, which seeks to classify environments based on the distinctive
acoustic features. In the ASC task of the APSIPA ASC 2025 Grand Challenge, the
organizers introduce a multimodal ASC task. Unlike traditional ASC systems that
rely solely on audio inputs, this challenge provides additional textual
information as inputs, including the location where the audio is recorded and
the time of recording. In this paper, we present our proposed system for the
ASC task in the APSIPA ASC 2025 Grand Challenge. Specifically, we propose a
multimodal network, \textbf{ASCMamba}, which integrates audio and textual
information for fine-grained acoustic scene understanding and effective
multimodal ASC. The proposed ASCMamba employs a DenseEncoder to extract
hierarchical spectral features from spectrograms, followed by a dual-path Mamba
blocks that capture long-range temporal and frequency dependencies using
Mamba-based state space models. In addition, we present a two-step
pseudo-labeling mechanism to generate more reliable pseudo-labels. Results show
that the proposed system outperforms all the participating teams and achieves a
6.2% improvement over the baseline. Code, model and pre-trained checkpoints are
available at https://github.com/S-Orion/ASCMamba.git.

</details>

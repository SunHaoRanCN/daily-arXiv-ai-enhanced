<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 8]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.SD](#cs.SD) [Total: 9]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [A Refined Alternating Optimization for Sum Rate Maximization in SIM-Aided Multiuser MISO Systems](https://arxiv.org/abs/2508.15257)
*Eduard E. Bahingayi,Shuying Lin,Murat Uysal,Marco Di Renzo,Le-Nam Tran*

Main category: eess.SP

TL;DR: 本文提出了一种改进的交替优化方法，通过先优化SIM相位偏移再优化数字波束成形，以及使用迭代投影梯度方法，显著提升了堆叠智能超表面多用户MISO系统的和速率性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究使用交替优化框架处理SIM多用户系统时，当SIM层数增加但厚度固定时，性能容易达到饱和。本文旨在解决这一性能瓶颈，寻找更有效的优化策略。

Method: 提出定制化的交替优化方法：1) 先优化SIM相位偏移再优化数字波束成形；2) 使用迭代投影梯度方法而非单步投影梯度来优化相位偏移。

Result: 所提方法相比基准方案实现了高达115.53%的和速率提升，有效避免了性能饱和问题。

Conclusion: 优化顺序和投影梯度方法的迭代应用对SIM系统性能有重要影响，本文提出的定制化方法能显著提升系统性能。

Abstract: Stacked intelligent metasurfaces (SIMs) have emerged as a disruptive
technology for future wireless networks. To investigate their capabilities, we
study the sum rate maximization problem in an SIM-based multiuser (MU)
multiple-input single-output (MISO) downlink system. A vast majority of pioneer
studies, if not all, address this fundamental problem using the prevailing
alternating optimization (AO) framework, where the digital beamforming (DB) and
SIM phase shifts are optimized alternately. However, many of these approaches
suffer from suboptimal performance, quickly leading to performance saturation,
when the number of SIM layers increases assuming the \emph{fixed SIM
thickness}. In this letter, we demonstrate that significant performance gains
can still be achieved, and such saturation does not occur with the proposed
method in the considered setting. To this end, we provide practical design
guidelines to improve AO-based optimization of digital precoders and SIM phase
shifts. Specifically, we show that (i) optimizing the SIM phase shifts first
yields significant performance improvements, compared to optimizing the DB
first; and (ii) when applying projected gradient (PG) methods, which are
gradually becoming more popular to optimize the phase shifts thanks to their
scalability, we find that using an iterative PG method achieves better
performance than the single PG step, which is commonly used in existing
solutions. Based on these customizations, the proposed method achieves a higher
achievable sum rate (ASR) of up to $\ensuremath{115.53\%}$, compared to
benchmark schemes for the scenarios under consideration.

</details>


### [2] [Performance Analysis of RIS-Aided High-Mobility Wireless Systems](https://arxiv.org/abs/2508.15375)
*Hanwen Hu,Jiancheng An,Lu Gan,Chau Yuen*

Main category: eess.SP

TL;DR: 本文研究RIS辅助的高速列车MISO通信系统，提出BCD算法联合优化RIS相位偏移和发射波束赋形向量，显著提升系统性能15dB，消除中断概率并改善关键性能指标。


<details>
  <summary>Details</summary>
Motivation: RIS技术具有提升无线网络性能的巨大潜力，被认为是解决高速移动场景中多普勒频移和快速衰落等通信挑战的解决方案之一。

Method: 提出块坐标下降(BCD)算法，联合优化RIS相位偏移和发射波束赋形向量，以最大化信道增益。

Result: 数值结果表明，所提算法显著提升系统性能，平均信道增益比传统方案提高15dB，消除中断概率，改善可达速率、信道容量和误码率等关键性能指标。

Conclusion: 这些发现突显了RIS在增强高速列车通信系统中的关键作用。

Abstract: Reconfigurable intelligent surface (RIS) technology holds immense potential
for increasing the performance of wireless networks. Therefore, RIS is also
regarded as one of the solutions to address communication challenges in
high-mobility scenarios, such as Doppler shift and fast fading. This paper
investigates a high-speed train (HST) multiple-input single-output (MISO)
communication system aided by a RIS. We propose a block coordinate descent
(BCD) algorithm to jointly optimize the RIS phase shifts and the transmit
beamforming vectors to maximize the channel gain. Numerical results are
provided to demonstrate that the proposed algorithm significantly enhances the
system performance, achieving an average channel gain improvement of 15 dB
compared to traditional schemes. Additionally, the introduction of RIS
eliminates outage probability and improves key performance metrics such as
achievable rate, channel capacity, and bit error rate (BER). These findings
highlight the critical role of RIS in enhancing HST communication systems.

</details>


### [3] [Lightweight Gradient Descent Optimization for Mitigating Hardware Imperfections in RIS Systems](https://arxiv.org/abs/2508.15544)
*Pedro H. C. de Souza,Luiz A. M. Pereira,Faustino R. Gómez,Elsa M. Materón,Jorge Ricardo Mejía-Salazar*

Main category: eess.SP

TL;DR: 本文提出了一种梯度下降优化方法来缓解RIS辅助宽带通信系统中的硬件缺陷，包括相位偏移噪声和表面变形问题。


<details>
  <summary>Details</summary>
Motivation: 随着6G标准化进程推进，可重构智能表面(RIS)技术面临实际部署中硬件缺陷的挑战，需要分析并解决这些实际问题以确保技术可行性。

Method: 采用梯度下降优化算法来补偿RIS系统中的硬件缺陷，特别是针对相位偏移噪声和表面变形等具体问题。

Result: 数值结果表明，所提出的优化方法能够有效补偿相位偏移噪声和RIS表面变形等硬件缺陷。

Conclusion: 梯度下降优化是缓解RIS硬件缺陷的有效解决方案，有助于推动RIS技术在6G通信系统中的实际应用。

Abstract: Ongoing discussions about the future of wireless communications are reaching
a turning point as standardization activities for the sixth generation of
mobile networks (6G) become more mature. New technologies must now face renewed
scrutiny by the industry and academia in order to be ready for deployment in
the near future. Recently, reconfigurable intelligent surfaces (RISs) gained
attention as a promising solution for improving the propagation conditions of
signal transmission in general. The RIS is a planar array of tunable resonant
elements designed to dynamically and precisely manipulate the reflection of
incident electromagnetic waves. However, the physical structure of the RIS and
its components may be subject to practical limitations and imperfections. It is
imperative that the hardware imperfections (HWIs) associated with the RIS be
analyzed, so that it remains a feasible technology from a practical standpoint.
Moreover, solutions for mitigating the HWIs must be considered, as is discussed
in this work. More specifically, we introduce a gradient descent optimization
for mitigating HWIs in RIS-aided wideband communication systems. Numerical
results show that the proposed optimization is able to compensate for HWIs such
as the phase-shift noise (PSN) and RIS surface deformations.

</details>


### [4] [Frequency Selective Reflection of Wideband Signals with Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2508.15581)
*Pedro H. C. de Souza,Luciano Mendes*

Main category: eess.SP

TL;DR: 提出一种RIS配置方法，为宽带信号提供频率选择性反射，解决RIS反射中的带宽限制问题


<details>
  <summary>Details</summary>
Motivation: RIS技术虽然能够通过可控反射改善信号接收，但常常忽视了宽带信号反射时的潜在带宽限制问题，这可能成为下一代通信系统采用RIS的障碍

Method: 提出一种RIS配置方法，能够为宽带信号提供频率选择性反射

Result: 该方法能够有效处理宽带信号的反射问题

Conclusion: 所提出的频率选择性RIS配置方法有助于解决宽带通信中的带宽限制问题，促进RIS在下一代通信系统中的应用

Abstract: Recently, the reconfigurable intelligent surface (RIS) technology has ushered
in the prospect of control over the wireless propagation environment. By
establishing alternative propagation paths for the transmitted signals, and by
reflecting them in a controllable manner, the RIS is able to improve the signal
reception. However, an aspect often overlooked is the potential bandwidth
restrictions on the wideband signal reflected by the RIS. If not carefully
considered, this can become an impediment for the adoption of the RIS in the
next generation of communications systems. Therefore, in this work we propose a
RIS configuration method that provides frequency selective signal reflection
for wideband signals.

</details>


### [5] [On the Compromise Between Performance and Efficiency in RIS-aided Communication Systems](https://arxiv.org/abs/2508.15599)
*P. H. C. de Souza,M. Khazaee,L. L. Mendes*

Main category: eess.SP

TL;DR: 本文探讨了可重构智能表面(RIS)技术在无线通信系统中的应用，重点分析了RIS配置优化、多普勒频移补偿以及STAR-RIS技术的扩展功能。


<details>
  <summary>Details</summary>
Motivation: 传统RIS系统存在反射限制，无法充分利用空间覆盖和信号放大潜力，需要开发更先进的智能表面技术来提升无线通信性能。

Method: 采用神经网络优化RIS相位偏移配置，提出同时收发可重构智能表面(STAR-RIS)技术，实现信号的同时传输和反射。

Result: 神经网络方法显著减少了RIS重新配置次数，降低了配置开销；STAR-RIS技术能够增强覆盖范围、提高能效、降低延迟，并在多个无线场景中提升总速率和物理层安全性。

Conclusion: STAR-RIS技术通过同时传输和反射信号的功能，有效解决了传统RIS系统的局限性，为未来无线通信系统提供了更优的性能和灵活性。

Abstract: The reconfigurable intelligent surface (RIS) technology for metasurfaces is
ushering in a new paradigm for wireless communication systems. It provides an
accessible way for controlling the interaction between electromagnetic waves
with the propagation medium. One particularly important aspect is the
configuration of the RIS elements or reflectors. Simply stated, the objective
of the RIS configuration is to choose the optimum phase-shift combination that
maximizes the channel capacity. Recently, neural networks (NNs) were proposed
for tackling this task and results have shown that the proposed NN promotes far
less reconfigurations of the RIS, consequently reducing the configuration
overhead. Beyond that, the RIS can be repurposed for tackling the Doppler shift
in high-mobility communication systems. Despite not being its usual primary
goal, results have also demonstrated that the RIS can compensate for the
Doppler shift at a small cost in performance. However, the typical
reflection-only constraint for RIS systems limits the spatial coverage and
signal amplification potential achieved by such systems. Therefore, the
simultaneously transmitting and reflecting reconfigurable intelligent surface
(STAR-RIS) can be employed to address these limitations by its dual
functionality of transmitting and reflecting signals concurrently. It can be
shown that the STAR-RIS can augment coverage, energy efficiency, and latency
reduction, while enhancing sum-rate and physical-layer security across several
wireless contexts.

</details>


### [6] [Discrete Radar based on Modulo Arithmetic](https://arxiv.org/abs/2508.15671)
*Nishant Mehrotra,Sandesh Rao Mattu,Saif Khan Mohammed,Ronny Hadani,Robert Calderbank*

Main category: eess.SP

TL;DR: Zak-OTFS调制方案用于雷达感知，通过离散海森堡-外尔群和辛变换设计波形，将传统雷达信号处理复杂度从O(B²T²)降低到O(BT log T)。


<details>
  <summary>Details</summary>
Motivation: 传统连续雷达信号处理复杂度高，需要开发更高效的雷达波形设计和处理方案，利用离散群理论来优化雷达性能。

Method: 在延迟-多普勒域形成雷达波形，通过匹配滤波和相关处理生成散射环境图像，利用离散海森堡-外尔群和辛变换进行波形设计和模糊表面整形。

Result: 实现了雷达信号处理复杂度的显著降低，从O(B²T²)降至O(BT log T)，同时能够定义具有低峰均功率比的最优雷达波形库。

Conclusion: 基于离散群理论的Zak-OTFS方法为雷达感知提供了高效的波形设计和处理框架，大幅降低了计算复杂度并改善了雷达性能。

Abstract: Zak-OTFS is modulation scheme where signals are formed in the delay-Doppler
(DD) domain, converted to the time domain (DD) for transmission and reception,
then returned to the DD domain for processing. We describe how to use the same
architecture for radar sensing. The intended delay resolution is $\frac{1}{B}$
where $B$ is the radar bandwidth, and the intended Doppler resolution is
$\frac{1}{T}$ where $T$ is the transmission time. We form a radar waveform in
the DD domain, illuminate the scattering environment, match filter the return,
then correlate with delay and Doppler shifts of the transmitted waveform. This
produces an image of the scattering environment, and the radar ambiguity
function expresses the blurriness of this image. The possible delay and Doppler
shifts generate the continuous Heisenberg-Weyl group which has been widely
studied in the theory of radar. We describe how to approach the problem of
waveform design, not from the perspective of this continuous group, but from
the perspective of a discrete group of delay and Doppler shifts, where the
discretization is determined by the intended delay and Doppler resolution of
the radar. We describe how to approach the problem of shaping the ambiguity
surface through symplectic transformations that normalize our discrete
Heisenberg-Weyl group. The complexity of traditional continuous radar signal
processing is $\mathcal{O}\big(B^2T^2\big)$. We describe how to reduce this
complexity to $\mathcal{O}\big(BT\log T\big)$ by choosing the radar waveform to
be a common eigenvector of a maximal commutative subgroup of our discrete
Heisenberg-Weyl group. The theory of symplectic transformations also enables
defining libraries of optimal radar waveforms with small peak-to-average power
ratios.

</details>


### [7] [A Grant-free Coded Random Access Scheme for Near-field Communications](https://arxiv.org/abs/2508.15673)
*Enrico Testi,Giulia Torcolacci,Nicolò Decarli,Davide Dardari,Enrico Paolini*

Main category: eess.SP

TL;DR: 这篇论文提出了一种结合近场空间复用和编码随机访问的创新方法，为5G网络中的工业物联网提供更高可靠性和更低延迟的连接解决方案。


<details>
  <summary>Details</summary>
Motivation: 工业物联网的大规模设备通信导致了大规模间隔性流量，而无授权随机访问协议是其关键解决方案。同时，无线硬件的进步使网络运行进入近场传播治理，需要新的技术来利用这一特性提升网络性能。

Method: 提出将近场空间复用与编码随机访问协议相结合，利用极大强度的MIMO大维天线阵列在接入点进行处理。这种方法通过空间复用来增强并发连接能力，同时利用编码技术来缓解干扰问题。

Result: 该方法能够显著提高连接的可靠性，同时降低访问延迟。在极大规模天线阵列的支持下，实现了更高的空间复用级和更好的干扰管理效果。

Conclusion: 这种创新的近场空间复用与编码随机访问的集成方案，为下一代6G网络中的工业物联网连接提供了一个健壮的框架，能够满足大规模设备通信的高可靠性和低延迟需求。

Abstract: The industrial Internet of things (IIoT) is revolutionizing industrial
processes by facilitating massive machine-type communications among countless
interconnected devices. To efficiently handle the resulting large-scale and
sporadic traffic, grant-free random access protocols-especially coded random
access (CRA)-have emerged as scalable and reliable solutions. At the same time,
advancements in wireless hardware, including extremely large-scale MIMO arrays
and high-frequency communication (e.g., mmWave, Terahertz), are pushing network
operations into the near-field propagation regime, allowing for dense
connectivity and enhanced spatial multiplexing. This paper proposes an
innovative approach that combines near-field spatial multiplexing with the
interference mitigation capabilities of CRA, utilizing an extremely large
aperture array at the access point. This integration improves reliability and
reduces access latency, offering a robust framework for IIoT connectivity in
next-generation 6G networks.

</details>


### [8] [Estimation-Theoretic Bias Reduction for Oscillometric Blood Pressure Readings](https://arxiv.org/abs/2508.15687)
*Masoud Nateghi,Reza Sameni*

Main category: eess.SP

TL;DR: 本研究分析了示波法血压测量的系统误差来源，提出基于最小二乘和最大似然估计的校正框架，通过多测量统计先验提高非侵入式血压监测精度


<details>
  <summary>Details</summary>
Motivation: 示波法作为标准无创血压测量方法存在系统误差，影响临床准确性。研究旨在识别误差来源（示波法本身限制和呼吸波动），并提出校正方法

Method: 使用MIMIC数据库的血压波形数据，提出估计理论框架，采用最小二乘(LS)支持传统多测量平均协议，最大似然(ML)方法结合测量误差先验知识

Result: 示波法倾向于低估收缩压和高估舒张压，呼吸引入周期性变化进一步降低测量精度。统计先验方法能显著提高多读数测量的准确性

Conclusion: 利用多读数统计先验可以增强非侵入式血压监测的准确性，对改善心血管疾病诊断和治疗具有潜在意义

Abstract: Oscillometry is the standard method for non-invasive, cuff-based blood
pressure (BP) measurement, but it introduces systematic errors that may impact
clinical accuracy. This study investigates the sources of these
errors--primarily the limitations of oscillometry itself and
respiration-induced fluctuations--using BP waveform data from the MIMIC
database. Oscillometry tends to underestimate systolic BP and overestimate
diastolic BP, while respiration introduces cyclical variations that further
degrade measurement precision. To mitigate these effects, we propose an
estimation-theoretic framework employing least squares (LS) and maximum
likelihood (ML) methods for correcting both single and repeated BP
measurements. LS estimation supports conventional multi-measurement averaging
protocols, whereas the ML approach incorporates prior knowledge of measurement
errors, offering improved performance. Our results demonstrate that leveraging
statistical priors across multiple readings can enhance the accuracy of
non-invasive BP monitoring, with potential implications for improving
cardiovascular diagnosis and treatment.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [9] [A Chinese Heart Failure Status Speech Database with Universal and Personalised Classification](https://arxiv.org/abs/2508.14908)
*Yue Pan,Liwei Liu,Changxin Li,Xinyao Wang,Yili Xia,Hanyue Zhang,Ming Chu*

Main category: eess.AS

TL;DR: 首个中文心衰病人语音数据库研究，证实中文音节含有心衰病检测信息，提出个人化分类方法和适配频率滤波器


<details>
  <summary>Details</summary>
Motivation: 语音作为一种成本效益高且非侵入性的数据源，可用于心衰病识别，但缺乏对中文音节是否含有心衰病相关信息的研究

Method: 建立首个中文心衰病语音数据库，包含入院前后的成对录音；采用标准病人分类和个人化成对分类方法；提出适配频率滤波器进行频率重要性分析

Result: 证实中文语言在心衰病检测中的有效性，统计测试和分类结果显示个体差异是准确性的主要影响因素

Conclusion: 研究为中文心衰病语音识别领域提供了重要数据基础，个人化分类方法可作为未来研究的理想基准，数据已开源发布

Abstract: Speech is a cost-effective and non-intrusive data source for identifying
acute and chronic heart failure (HF). However, there is a lack of research on
whether Chinese syllables contain HF-related information, as observed in other
well-studied languages. This study presents the first Chinese speech database
of HF patients, featuring paired recordings taken before and after
hospitalisation. The findings confirm the effectiveness of the Chinese language
in HF detection using both standard 'patient-wise' and personalised 'pair-wise'
classification approaches, with the latter serving as an ideal
speaker-decoupled baseline for future research. Statistical tests and
classification results highlight individual differences as key contributors to
inaccuracy. Additionally, an adaptive frequency filter (AFF) is proposed for
frequency importance analysis. The data and demonstrations are published at
https://github.com/panyue1998/Voice_HF.

</details>


### [10] [Transsion Multilingual Speech Recognition System for MLC-SLM 2025 Challenge](https://arxiv.org/abs/2508.14916)
*Xiaoxiao Li,An Zhu,Youhai Jiang,Fengjie Zhu*

Main category: eess.AS

TL;DR: 本文提出了一种基于Whisper和Qwen2.5-7B的多语言自动语音识别系统，在MLC-SLM 2025挑战赛中取得了9.83%的词/字符错误率，获得第三名


<details>
  <summary>Details</summary>
Motivation: 开发一个高效的多语言自动语音识别系统，通过结合预训练模型和任务特定微调来提升跨语言语音识别性能

Method: 使用冻结的Whisper-large-v3作为语音编码器，可训练的Linear-ReLU-Linear适配器模块对齐语音文本表示，以及冻结的Qwen2.5-7B-Instruct LLM结合LoRA进行上下文语言解码

Result: 在11种语言的评估集上实现了9.83%的词/字符错误率(WER/CER)，在全球参与者中排名第三

Conclusion: 通过系统性地结合预训练模型和任务特定微调，成功构建了高效的多语言ASR系统，证明了该方法在跨语言语音识别任务中的有效性

Abstract: This paper presents the architecture and performance of a novel Multilingual
Automatic Speech Recognition (ASR) system developed by the Transsion Speech
Team for Track 1 of the MLC-SLM 2025 Challenge. The proposed system comprises
three key components: 1) a frozen Whisper-large-v3 based speech encoder,
leveraging large-scale pretraining to ensure robust acoustic feature
extraction; 2) a trainable adaptor module using Linear-ReLU-Linear
transformation mechanisms to effectively align speech and text representations;
and 3) a frozen Qwen2.5-7B-Instruct large language model (LLM) integrated with
trainable LoRA for optimized contextual linguistic decoding. By systematically
combining pretrained models with task specific fine-tuning, the system achieved
a word/character error rate (WER/CER) of 9.83% across 11 languages in the
evaluation set and ranked third place among global participants.

</details>


### [11] [Mitigating Hallucinations in LM-Based TTS Models via Distribution Alignment Using GFlowNets](https://arxiv.org/abs/2508.15442)
*Chenlin Liu,Minghui Fang,Patrick Zhang,Wei Zhou,Jie Gao,Jiqing Han*

Main category: eess.AS

TL;DR: GOAT是一个后训练框架，通过分布对齐方法减少LM-based TTS系统的幻觉问题，无需大量资源或增加推理延迟，能够降低50%以上的字符错误率和58%的不确定性。


<details>
  <summary>Details</summary>
Motivation: 现有的LM-based TTS系统容易产生偏离输入文本的幻觉语音，而现有的缓解策略要么需要大量训练资源，要么会显著增加推理延迟。

Method: 首先进行不确定性分析，发现幻觉与模型不确定性呈强正相关；将TTS生成重新表述为轨迹流优化问题，引入增强的子轨迹平衡目标和锐化的内部奖励作为目标分布；集成奖励温度衰减和学习率优化以确保稳定性和性能平衡。

Result: 在具有挑战性的测试案例上，GOAT减少了50%以上的字符错误率，并将不确定性降低了58%，展示了其强大的泛化能力和有效性。

Conclusion: GOAT是一个有效的后训练框架，能够显著减少LM-based TTS系统的幻觉问题，同时保持资源效率和推理速度。

Abstract: Language Model (LM)-based Text-to-Speech (TTS) systems often generate
hallucinated speech that deviates from input text. Existing mitigation
strategies either demand excessive training resources or introduce significant
inference latency. In this paper, we propose GFlOwNet-guided distribution
AlignmenT (GOAT) for LM-based TTS, a post-training framework that mitigates
hallucinations without relying on massive resources or inference cost.
Specifically, we first conduct an uncertainty analysis, revealing a strong
positive correlation between hallucination and model uncertainty. Based on
this, we reformulate TTS generation as a trajectory flow optimization problem
and introduce an enhanced Subtrajectory Balance objective together with a
sharpened internal reward as target distribution. We further integrate reward
temperature decay and learning rate optimization for stability and performance
balance. Extensive experiments show that GOAT reduce over 50% character error
rates on challenging test cases and lowering uncertainty by up to 58%,
demonstrating its strong generalization ability and effectiveness.

</details>


### [12] [EffortNet: A Deep Learning Framework for Objective Assessment of Speech Enhancement Technologies Using EEG-Based Alpha Oscillations](https://arxiv.org/abs/2508.15473)
*Ching-Chih Sung,Cheng-Hung Hsin,Yu-Anne Shiah,Bo-Jyun Lin,Yi-Xuan Lai,Chia-Ying Lee,Yu-Te Wang,Borchin Su,Yu Tsao*

Main category: eess.AS

TL;DR: EffortNet是一个深度学习框架，通过脑电图(EEG)解码个体在语音理解时的听力努力程度，结合自监督学习、增量学习和迁移学习来处理个体差异，在语音增强技术评估中表现出色。


<details>
  <summary>Details</summary>
Motivation: 听力努力是语音听力研究中的重要挑战，特别是在老年人和听力受损人群中。现有方法难以处理EEG信号的个体间变异性，需要开发能够个性化评估听力技术的解决方案。

Method: 收集122名参与者在四种语音条件下的64通道EEG数据，利用alpha振荡作为生物标志物。EffortNet整合三种学习范式：自监督学习利用未标记数据、增量学习逐步适应个体特征、迁移学习实现高效知识迁移。

Result: EffortNet仅需新受试者40%的训练数据即可达到80.9%的分类准确率，显著优于传统CNN(62.3%)和STAnet(61.1%)。发现Transformer增强的语音比MMSE增强的语音在神经响应上更接近清晰语音。

Conclusion: 该框架为个性化听力技术评估提供了实用解决方案，对设计认知感知的语音增强系统具有重要意义，其客观指标与主观可懂度评分形成对比但更可靠。

Abstract: This paper presents EffortNet, a novel deep learning framework for decoding
individual listening effort from electroencephalography (EEG) during speech
comprehension. Listening effort represents a significant challenge in
speech-hearing research, particularly for aging populations and those with
hearing impairment. We collected 64-channel EEG data from 122 participants
during speech comprehension under four conditions: clean, noisy, MMSE-enhanced,
and Transformer-enhanced speech. Statistical analyses confirmed that alpha
oscillations (8-13 Hz) exhibited significantly higher power during noisy speech
processing compared to clean or enhanced conditions, confirming their validity
as objective biomarkers of listening effort. To address the substantial
inter-individual variability in EEG signals, EffortNet integrates three
complementary learning paradigms: self-supervised learning to leverage
unlabeled data, incremental learning for progressive adaptation to individual
characteristics, and transfer learning for efficient knowledge transfer to new
subjects. Our experimental results demonstrate that Effort- Net achieves 80.9%
classification accuracy with only 40% training data from new subjects,
significantly outperforming conventional CNN (62.3%) and STAnet (61.1%) models.
The probability-based metric derived from our model revealed that
Transformer-enhanced speech elicited neural responses more similar to clean
speech than MMSEenhanced speech. This finding contrasted with subjective
intelligibility ratings but aligned with objective metrics. The proposed
framework provides a practical solution for personalized assessment of hearing
technologies, with implications for designing cognitive-aware speech
enhancement systems.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [13] [Denoising by neural network for muzzle blast detection](https://arxiv.org/abs/2508.14919)
*Hadrien Pujol,Matteo Bevillacqua,Christophe Thirard,Thierry Mazoyer*

Main category: cs.SD

TL;DR: 开发轻量级神经网络用于军事车辆上的枪声检测系统降噪，显著提高枪口冲击波检测率


<details>
  <summary>Details</summary>
Motivation: 军事车辆移动时产生的噪声会降低枪声检测系统的性能，需要开发计算资源需求低的降噪算法以适应多种硬件平台

Method: 采用两层隐藏层的轻量级感知器神经网络，结合适当的信号处理技术，而非使用计算量大的卷积神经网络

Result: 在噪声RMS值与枪口冲击波峰值幅度相当的情况下，检测率提高了两倍以上

Conclusion: 轻量级神经网络架构结合信号处理技术能有效提升移动军事环境中枪声检测系统的性能

Abstract: Acoem develops gunshot detection systems, consisting of a microphone array
and software that detects and locates shooters on the battlefield. The
performance of such systems is obviously affected by the acoustic environment
in which they are operating: in particular, when mounted on a moving military
vehicle, the presence of noise reduces the detection performance of the
software. To limit the influence of the acoustic environment, a neural network
has been developed. Instead of using a heavy convolutional neural network, a
lightweight neural network architecture was chosen to limit the computational
resources required to embed the algorithm on as many hardware platforms as
possible. Thanks to the combination of a two hidden layer perceptron and
appropriate signal processing techniques, the detection rate of impulsive
muzzle blast waveforms (the wave coming from the detonation and indicating the
position of the shooter) is significantly increased. With a rms value of noise
of the same order as the muzzle blast peak amplitude, the detect rate is more
than doubled with this denoising processing.

</details>


### [14] [Human Feedback Driven Dynamic Speech Emotion Recognition](https://arxiv.org/abs/2508.14920)
*Ilya Fedorov,Dmitry Korobchenko*

Main category: cs.SD

TL;DR: 提出动态语音情感识别新方法，使用Dirichlet分布建模情感混合，结合人类反馈改进模型，在3D虚拟人动画情感识别中表现优于滑动窗口方法


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别方法无法处理音频中随时间变化的情感序列，特别是在3D虚拟人动画中需要准确捕捉动态情感变化

Method: 多阶段方法：训练经典语音情感识别模型、合成情感序列生成、基于人类反馈的模型改进，引入基于Dirichlet分布的情感混合建模新方法

Result: 实验结果表明Dirichlet方法在建模情感混合方面有效，结合人类反馈进一步提升了模型质量，同时简化了标注流程

Conclusion: 提出的动态情感识别方法在3D虚拟人动画情感识别任务中优于传统滑动窗口方法，Dirichlet分布为情感混合建模提供了有效解决方案

Abstract: This work proposes to explore a new area of dynamic speech emotion
recognition. Unlike traditional methods, we assume that each audio track is
associated with a sequence of emotions active at different moments in time. The
study particularly focuses on the animation of emotional 3D avatars. We propose
a multi-stage method that includes the training of a classical speech emotion
recognition model, synthetic generation of emotional sequences, and further
model improvement based on human feedback. Additionally, we introduce a novel
approach to modeling emotional mixtures based on the Dirichlet distribution.
The models are evaluated based on ground-truth emotions extracted from a
dataset of 3D facial animations. We compare our models against the sliding
window approach. Our experimental results show the effectiveness of
Dirichlet-based approach in modeling emotional mixtures. Incorporating human
feedback further improves the model quality while providing a simplified
annotation procedure.

</details>


### [15] [XAI-Driven Spectral Analysis of Cough Sounds for Respiratory Disease Characterization](https://arxiv.org/abs/2508.14949)
*Patricia Amado-Caballero,Luis Miguel San-José-Revuelta,María Dolores Aguilar-García,José Ramón Garmendia-Leiza,Carlos Alberola-López,Pablo Casaseca-de-la-Higuera*

Main category: cs.SD

TL;DR: 提出基于可解释人工智能(XAI)的方法，通过遮挡图分析咳嗽声谱图来识别呼吸系统疾病的声学特征，相比原始声谱图能更好地区分疾病组别差异


<details>
  <summary>Details</summary>
Motivation: 增强咳嗽声音分析在呼吸疾病管理中的可解释性，通过XAI技术揭示疾病特异性的声学特征，提高诊断能力

Method: 使用卷积神经网络处理咳嗽声谱图，生成遮挡图突出相关频谱区域，然后对加权声谱图进行频谱分析，提取多个频谱特征

Result: 在COPD患者中识别出咳嗽模式在特定频谱区域更具变异性，而原始声谱图分析未显示显著差异，证明了XAI技术在发现疾病特异性声学特征方面的潜力

Conclusion: XAI驱动的咳嗽声音分析方法能够提供更可解释的结果，揭示疾病特异性声学特征，有望提升咳嗽声音分析的诊断能力

Abstract: This paper proposes an eXplainable Artificial Intelligence (XAI)-driven
methodology to enhance the understanding of cough sound analysis for
respiratory disease management. We employ occlusion maps to highlight relevant
spectral regions in cough spectrograms processed by a Convolutional Neural
Network (CNN). Subsequently, spectral analysis of spectrograms weighted by
these occlusion maps reveals significant differences between disease groups,
particularly in patients with COPD, where cough patterns appear more variable
in the identified spectral regions of interest. This contrasts with the lack of
significant differences observed when analyzing raw spectrograms. The proposed
approach extracts and analyzes several spectral features, demonstrating the
potential of XAI techniques to uncover disease-specific acoustic signatures and
improve the diagnostic capabilities of cough sound analysis by providing more
interpretable results.

</details>


### [16] [Comparative Evaluation of Text and Audio Simplification: A Methodological Replication Study](https://arxiv.org/abs/2508.15088)
*Prosanta Barai,Gondy Leroy,Arif Ahmed*

Main category: cs.SD

TL;DR: 本研究是对Leroy等人(2022)研究的复制，探讨文本简化对音频医疗信息理解的影响，发现简化能提升感知易懂性和实际理解效果。


<details>
  <summary>Details</summary>
Motivation: 随着多媒体环境中音频内容在医疗信息传播中的重要性日益增加，需要验证文本简化策略在音频形式下的有效性。

Method: 采用44名参与者，评估他们对基于原始文本和简化文本生成的音频医疗信息的理解程度，并考察教育水平和语言能力的影响。

Result: 文本简化显著提高了音频内容的感知易懂性和实际理解效果，与原始研究结果一致；教育水平和语言能力对医疗信息获取有重要影响。

Conclusion: 文本简化工具对提升健康素养具有实用价值，医疗领域需要制定定制化的沟通策略来有效触达不同受众群体。

Abstract: This study serves as a methodological replication of Leroy et al. (2022)
research, which investigated the impact of text simplification on healthcare
information comprehension in the evolving multimedia landscape. Building upon
the original studys insights, our replication study evaluates audio content,
recognizing its increasing importance in disseminating healthcare information
in the digital age. Specifically, we explored the influence of text
simplification on perceived and actual difficulty when users engage with audio
content automatically generated from that text. Our replication involved 44
participants for whom we assessed their comprehension of healthcare information
presented as audio created using Leroy et al. (2022) original and simplified
texts. The findings from our study highlight the effectiveness of text
simplification in enhancing perceived understandability and actual
comprehension, aligning with the original studys results. Additionally, we
examined the role of education level and language proficiency, shedding light
on their potential impact on healthcare information access and understanding.
This research underscores the practical value of text simplification tools in
promoting health literacy. It suggests the need for tailored communication
strategies to reach diverse audiences effectively in the healthcare domain.

</details>


### [17] [An Enhanced Audio Feature Tailored for Anomalous Sound Detection Based on Pre-trained Models](https://arxiv.org/abs/2508.15334)
*Guirui Zhong,Qing Wang,Jun Du,Lei Wang,Mingqi Cai,Xin Fang*

Main category: cs.SD

TL;DR: 本文提出了一种新的均匀分布滤波器组音频特征提取方法和无参数特征增强方法，用于提高异常声音检测的性能。


<details>
  <summary>Details</summary>
Motivation: 机器声音中异常位置的不确定性以及噪声等冗余信息阻碍了ASD系统性能的提升，需要更有效的特征提取和处理方法。

Method: 使用均匀间隔分布的滤波器组提取音频特征，确保对所有频段的均等关注；基于预训练模型的无参数特征增强方法，去除冗余信息。

Result: 在DCASE 2024挑战赛数据集上评估，提出的方法在异常声音检测性能上取得了显著提升。

Conclusion: 该方法通过更有效的特征提取和冗余信息清除，能够提高异常声音检测的准确性和可靠性。

Abstract: Anomalous Sound Detection (ASD) aims at identifying anomalous sounds from
machines and has gained extensive research interests from both academia and
industry. However, the uncertainty of anomaly location and much redundant
information such as noise in machine sounds hinder the improvement of ASD
system performance. This paper proposes a novel audio feature of filter banks
with evenly distributed intervals, ensuring equal attention to all frequency
ranges in the audio, which enhances the detection of anomalies in machine
sounds. Moreover, based on pre-trained models, this paper presents a
parameter-free feature enhancement approach to remove redundant information in
machine audio. It is believed that this parameter-free strategy facilitates the
effective transfer of universal knowledge from pre-trained tasks to the ASD
task during model fine-tuning. Evaluation results on the Detection and
Classification of Acoustic Scenes and Events (DCASE) 2024 Challenge dataset
demonstrate significant improvements in ASD performance with our proposed
methods.

</details>


### [18] [AudioSet-R: A Refined AudioSet with Multi-Stage LLM Label Reannotation](https://arxiv.org/abs/2508.15429)
*Yulin Sun,Qisheng Xu,Yi Su,Qian Zhu,Yong Dou,Xinwang Liu,Kele Xu*

Main category: cs.SD

TL;DR: 提出了一个三阶段重新标注框架，利用音频-语言基础模型系统性地改进AudioSet的标签质量，构建了高质量的AudioSet-R数据集，实验证明能显著提升音频分类模型性能


<details>
  <summary>Details</summary>
Motivation: AudioSet作为音频研究领域广泛使用的基准数据集，其标签准确性和完整性问题限制了在下游应用中的性能表现，需要解决这些标签质量问题

Method: 采用三阶段重新标注框架，使用跨模态提示策略（受提示链概念启发），通过顺序组合提示来执行音频理解、标签合成和语义对齐三个子任务

Result: 构建了高质量的AudioSet-R数据集，在AST、PANNs、SSAST和AudioMAE等代表性音频分类模型上均显示出显著的性能提升

Conclusion: 该方法能有效提高标签可靠性，具有很好的泛化性和有效性，为音频数据集标签质量改进提供了系统性的解决方案

Abstract: AudioSet is a widely used benchmark in the audio research community and has
significantly advanced various audio-related tasks. However, persistent issues
with label accuracy and completeness remain critical bottlenecks that limit
performance in downstream applications.To address the aforementioned
challenges, we propose a three-stage reannotation framework that harnesses
general-purpose audio-language foundation models to systematically improve the
label quality of AudioSet. The framework employs a cross-modal prompting
strategy, inspired by the concept of prompt chaining, wherein prompts are
sequentially composed to execute subtasks (audio comprehension, label
synthesis, and semantic alignment). Leveraging this framework, we construct a
high-quality, structured relabeled version of AudioSet-R. Extensive experiments
conducted on representative audio classification models--including AST, PANNs,
SSAST, and AudioMAE--consistently demonstrate substantial performance
improvements, thereby validating the generalizability and effectiveness of the
proposed approach in enhancing label reliability.The code is publicly available
at: https://github.com/colaudiolab/AudioSet-R.

</details>


### [19] [DualMark: Identifying Model and Training Data Origins in Generated Audio](https://arxiv.org/abs/2508.15521)
*Xuefeng Yang,Jian Guan,Feiyang Xiao,Congyi Fan,Haohe Liu,Qiaoxi Zhu,Dongli Xu,Youtian Lin*

Main category: cs.SD

TL;DR: DualMark是首个双重溯源水印框架，能够在音频生成模型中同时嵌入模型身份和数据集来源两种水印，解决了现有方法只能进行模型级溯源而无法追踪训练数据的问题。


<details>
  <summary>Details</summary>
Motivation: 现有音频生成模型水印方法只能识别生成模型的身份，但无法追踪底层训练数据集，这在版权和问责场景中存在重大限制。需要一种能够同时溯源模型和数据的方法来解决这一根本性差距。

Method: 提出了DualMark框架，包含新颖的双重水印嵌入(DWE)模块将双水印嵌入到梅尔频谱图中，并设计了水印一致性损失(WCL)确保从生成音频中可靠提取两个水印。还建立了首个针对联合模型-数据溯源的鲁棒性评估基准DAB。

Result: 实验验证DualMark实现了出色的溯源准确性（模型溯源F1-score 97.01%，数据集溯源AUC 91.51%），在激进剪枝、有损压缩、加性噪声和采样攻击等条件下保持卓越鲁棒性，这些条件严重影响了先前方法。

Conclusion: DualMark为完全可问责的音频生成模型提供了基础性步骤，显著增强了版权保护和责任追踪能力，解决了音频生成模型溯源的关键限制。

Abstract: Existing watermarking methods for audio generative models only enable
model-level attribution, allowing the identification of the originating
generation model, but are unable to trace the underlying training dataset. This
significant limitation raises critical provenance questions, particularly in
scenarios involving copyright and accountability concerns. To bridge this
fundamental gap, we introduce DualMark, the first dual-provenance watermarking
framework capable of simultaneously encoding two distinct attribution
signatures, i.e., model identity and dataset origin, into audio generative
models during training. Specifically, we propose a novel Dual Watermark
Embedding (DWE) module to seamlessly embed dual watermarks into Mel-spectrogram
representations, accompanied by a carefully designed Watermark Consistency Loss
(WCL), which ensures reliable extraction of both watermarks from generated
audio signals. Moreover, we establish the Dual Attribution Benchmark (DAB), the
first robustness evaluation benchmark specifically tailored for joint
model-data attribution. Extensive experiments validate that DualMark achieves
outstanding attribution accuracy (97.01% F1-score for model attribution, and
91.51% AUC for dataset attribution), while maintaining exceptional robustness
against aggressive pruning, lossy compression, additive noise, and sampling
attacks, conditions that severely compromise prior methods. Our work thus
provides a foundational step toward fully accountable audio generative models,
significantly enhancing copyright protection and responsibility tracing
capabilities.

</details>


### [20] [Any-to-any Speaker Attribute Perturbation for Asynchronous Voice Anonymization](https://arxiv.org/abs/2508.15565)
*Liping Chen,Chenyang Guo,Rui Wang,Kong Aik Lee,Zhenhua Ling*

Main category: cs.SD

TL;DR: 这篇论文提出了一种任意到任意的训练策略，通过批处理损失函数将不同说话者的语音匿名化到共享的伪说话者，避免使用真实说话者引发隐私风险。


<details>
  <summary>Details</summary>
Motivation: 传统的指定说话者攻击策略存在涉及真实说话者隐私风险的问题，需要一种更安全的语音匿名化方法。

Method: 提出任意到任意训练策略，使用批处均值损失函数将训练小批中的多个说话者语音匿名化到一个共享的伪说话者（小批均值），并结合非目标攻击监督。

Result: 在VoxCeleb数据集上的实验表明，该方法在异步语音匿名化中有效，同时识别了说话者对抗性语音在隐私保护中的潜在限制。

Conclusion: 该研究为语音匿名化提供了一种更安全的方法，避免了使用真实说话者的风险，并为将来的黑盒说话者提取器和适配攻击的防护效果研究提供了见解。

Abstract: Speaker attribute perturbation offers a feasible approach to asynchronous
voice anonymization by employing adversarially perturbed speech as anonymized
output. In order to enhance the identity unlinkability among anonymized
utterances from the same original speaker, the targeted attack training
strategy is usually applied to anonymize the utterances to a common designated
speaker. However, this strategy may violate the privacy of the designated
speaker who is an actual speaker. To mitigate this risk, this paper proposes an
any-to-any training strategy. It is accomplished by defining a batch mean loss
to anonymize the utterances from various speakers within a training mini-batch
to a common pseudo-speaker, which is approximated as the average speaker in the
mini-batch. Based on this, a speaker-adversarial speech generation model is
proposed, incorporating the supervision from both the untargeted attack and the
any-to-any strategies. The speaker attribute perturbations are generated and
incorporated into the original speech to produce its anonymized version. The
effectiveness of the proposed model was justified in asynchronous voice
anonymization through experiments conducted on the VoxCeleb datasets.
Additional experiments were carried out to explore the potential limitations of
speaker-adversarial speech in voice privacy protection. With them, we aim to
provide insights for future research on its protective efficacy against
black-box speaker extractors \textcolor{black}{and adaptive attacks, as well
as} generalization to out-of-domain datasets \textcolor{black}{and stability}.
Audio samples and open-source code are published in
https://github.com/VoicePrivacy/any-to-any-speaker-attribute-perturbation.

</details>


### [21] [ASCMamba: Multimodal Time-Frequency Mamba for Acoustic Scene Classification](https://arxiv.org/abs/2508.15632)
*Bochao Sun,Dong Wang,Han Yin*

Main category: cs.SD

TL;DR: 本文提出了ASCMamba多模态网络，用于APSIPA ASC 2025挑战赛的声学场景分类任务，通过整合音频和文本信息，在基准系统基础上实现了6.2%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的声学场景分类系统仅依赖音频输入，而APSIPA ASC 2025挑战赛引入了多模态任务，提供额外的文本信息（录音地点和时间），需要开发能够有效整合多模态信息的系统。

Method: 提出ASCMamba多模态网络：使用DenseEncoder从频谱图中提取分层频谱特征，采用双路径Mamba块通过基于状态空间模型的Mamba捕获长程时间和频率依赖关系，并提出两步伪标签机制生成更可靠的伪标签。

Result: 所提出的系统在所有参赛团队中表现最佳，相比基准系统实现了6.2%的性能改进。

Conclusion: ASCMamba通过有效整合音频和文本信息，在多模态声学场景分类任务中取得了优异性能，证明了多模态方法在声学场景理解中的有效性。

Abstract: Acoustic Scene Classification (ASC) is a fundamental problem in computational
audition, which seeks to classify environments based on the distinctive
acoustic features. In the ASC task of the APSIPA ASC 2025 Grand Challenge, the
organizers introduce a multimodal ASC task. Unlike traditional ASC systems that
rely solely on audio inputs, this challenge provides additional textual
information as inputs, including the location where the audio is recorded and
the time of recording. In this paper, we present our proposed system for the
ASC task in the APSIPA ASC 2025 Grand Challenge. Specifically, we propose a
multimodal network, \textbf{ASCMamba}, which integrates audio and textual
information for fine-grained acoustic scene understanding and effective
multimodal ASC. The proposed ASCMamba employs a DenseEncoder to extract
hierarchical spectral features from spectrograms, followed by a dual-path Mamba
blocks that capture long-range temporal and frequency dependencies using
Mamba-based state space models. In addition, we present a two-step
pseudo-labeling mechanism to generate more reliable pseudo-labels. Results show
that the proposed system outperforms all the participating teams and achieves a
6.2% improvement over the baseline. Code, model and pre-trained checkpoints are
available at https://github.com/S-Orion/ASCMamba.git.

</details>

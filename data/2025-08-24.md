<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 8]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.SD](#cs.SD) [Total: 9]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [A Refined Alternating Optimization for Sum Rate Maximization in SIM-Aided Multiuser MISO Systems](https://arxiv.org/abs/2508.15257)
*Eduard E. Bahingayi,Shuying Lin,Murat Uysal,Marco Di Renzo,Le-Nam Tran*

Main category: eess.SP

TL;DR: 本文提出了一种改进的交替优化方法，通过先优化SIM相位偏移再优化数字波束成形，以及使用迭代投影梯度方法，显著提升了堆叠智能超表面多用户MISO系统的和速率性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究使用交替优化框架处理SIM系统的和速率最大化问题时，当SIM层数增加但厚度固定时，性能容易饱和。本文旨在解决这一性能瓶颈，寻求更优的优化策略。

Method: 提出改进的交替优化方法：1）先优化SIM相位偏移再优化数字波束成形；2）使用迭代投影梯度方法而非单步投影梯度来优化相位偏移。

Result: 所提方法相比基准方案实现了高达115.53%的和速率提升，有效避免了性能饱和问题。

Conclusion: 优化顺序和梯度方法的选择对SIM系统性能至关重要，先优化相位偏移并使用迭代投影梯度能显著提升系统性能。

Abstract: Stacked intelligent metasurfaces (SIMs) have emerged as a disruptive
technology for future wireless networks. To investigate their capabilities, we
study the sum rate maximization problem in an SIM-based multiuser (MU)
multiple-input single-output (MISO) downlink system. A vast majority of pioneer
studies, if not all, address this fundamental problem using the prevailing
alternating optimization (AO) framework, where the digital beamforming (DB) and
SIM phase shifts are optimized alternately. However, many of these approaches
suffer from suboptimal performance, quickly leading to performance saturation,
when the number of SIM layers increases assuming the \emph{fixed SIM
thickness}. In this letter, we demonstrate that significant performance gains
can still be achieved, and such saturation does not occur with the proposed
method in the considered setting. To this end, we provide practical design
guidelines to improve AO-based optimization of digital precoders and SIM phase
shifts. Specifically, we show that (i) optimizing the SIM phase shifts first
yields significant performance improvements, compared to optimizing the DB
first; and (ii) when applying projected gradient (PG) methods, which are
gradually becoming more popular to optimize the phase shifts thanks to their
scalability, we find that using an iterative PG method achieves better
performance than the single PG step, which is commonly used in existing
solutions. Based on these customizations, the proposed method achieves a higher
achievable sum rate (ASR) of up to $\ensuremath{115.53\%}$, compared to
benchmark schemes for the scenarios under consideration.

</details>


### [2] [Performance Analysis of RIS-Aided High-Mobility Wireless Systems](https://arxiv.org/abs/2508.15375)
*Hanwen Hu,Jiancheng An,Lu Gan,Chau Yuen*

Main category: eess.SP

TL;DR: 重构智能表面(RIS)助力高速铁路MISO通信系统，通过BCD算法优化相位移和政形，实现15dB通道增益提升，并消除中断概率。


<details>
  <summary>Details</summary>
Motivation: 解决高移动性场景下的多普勒移频和快衰落等通信挑战，探索RIS在高速铁路通信中的应用潜力。

Method: 采用坐标递渝(BCD)算法，联合优化RIS相位移和发射政形向量，最大化通道增益。

Result: 算法显著提升系统性能，平均通道增益提高15dB，消除中断概率，改善可实现速率、通道容量和比特异率等关键指标。

Conclusion: RIS在提升高速铁路通信系统性能方面发挥了关键作用，为高移动性通信提供了有效解决方案。

Abstract: Reconfigurable intelligent surface (RIS) technology holds immense potential
for increasing the performance of wireless networks. Therefore, RIS is also
regarded as one of the solutions to address communication challenges in
high-mobility scenarios, such as Doppler shift and fast fading. This paper
investigates a high-speed train (HST) multiple-input single-output (MISO)
communication system aided by a RIS. We propose a block coordinate descent
(BCD) algorithm to jointly optimize the RIS phase shifts and the transmit
beamforming vectors to maximize the channel gain. Numerical results are
provided to demonstrate that the proposed algorithm significantly enhances the
system performance, achieving an average channel gain improvement of 15 dB
compared to traditional schemes. Additionally, the introduction of RIS
eliminates outage probability and improves key performance metrics such as
achievable rate, channel capacity, and bit error rate (BER). These findings
highlight the critical role of RIS in enhancing HST communication systems.

</details>


### [3] [Lightweight Gradient Descent Optimization for Mitigating Hardware Imperfections in RIS Systems](https://arxiv.org/abs/2508.15544)
*Pedro H. C. de Souza,Luiz A. M. Pereira,Faustino R. Gómez,Elsa M. Materón,Jorge Ricardo Mejía-Salazar*

Main category: eess.SP

TL;DR: 本文提出了一种梯度下降优化方法来减轻RIS辅助宽带通信系统中的硬件缺陷，包括相位偏移噪声和表面变形问题。


<details>
  <summary>Details</summary>
Motivation: 随着6G标准化进程推进，可重构智能表面(RIS)作为改善信号传输环境的有前景技术受到关注，但其物理结构和组件存在实际限制和缺陷，需要分析并解决这些硬件缺陷以确保技术可行性。

Method: 引入梯度下降优化算法来缓解RIS辅助宽带通信系统中的硬件缺陷问题。

Result: 数值结果表明，所提出的优化方法能够有效补偿相位偏移噪声(PSN)和RIS表面变形等硬件缺陷。

Conclusion: 该研究为RIS技术在实际部署中面临的硬件缺陷问题提供了有效的缓解方案，证明了梯度下降优化在补偿相位噪声和表面变形方面的有效性。

Abstract: Ongoing discussions about the future of wireless communications are reaching
a turning point as standardization activities for the sixth generation of
mobile networks (6G) become more mature. New technologies must now face renewed
scrutiny by the industry and academia in order to be ready for deployment in
the near future. Recently, reconfigurable intelligent surfaces (RISs) gained
attention as a promising solution for improving the propagation conditions of
signal transmission in general. The RIS is a planar array of tunable resonant
elements designed to dynamically and precisely manipulate the reflection of
incident electromagnetic waves. However, the physical structure of the RIS and
its components may be subject to practical limitations and imperfections. It is
imperative that the hardware imperfections (HWIs) associated with the RIS be
analyzed, so that it remains a feasible technology from a practical standpoint.
Moreover, solutions for mitigating the HWIs must be considered, as is discussed
in this work. More specifically, we introduce a gradient descent optimization
for mitigating HWIs in RIS-aided wideband communication systems. Numerical
results show that the proposed optimization is able to compensate for HWIs such
as the phase-shift noise (PSN) and RIS surface deformations.

</details>


### [4] [Frequency Selective Reflection of Wideband Signals with Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2508.15581)
*Pedro H. C. de Souza,Luciano Mendes*

Main category: eess.SP

TL;DR: 提出一种针对可重构智能表面(RIS)的频率选择性信号反射配置方法，解决宽频带信号反射中的带宽限制问题


<details>
  <summary>Details</summary>
Motivation: RIS技术在无线传播环境控制方面具有前景，但现有研究往往忽视了宽频带信号反射时的潜在带宽限制问题，这可能成为下一代通信系统采用RIS的障碍

Method: 提出一种RIS配置方法，能够为宽频带信号提供频率选择性信号反射

Result: 该方法能够有效解决RIS在宽频带信号反射中的带宽限制问题

Conclusion: 所提出的频率选择性反射配置方法对于RIS在下一代通信系统中的成功应用至关重要

Abstract: Recently, the reconfigurable intelligent surface (RIS) technology has ushered
in the prospect of control over the wireless propagation environment. By
establishing alternative propagation paths for the transmitted signals, and by
reflecting them in a controllable manner, the RIS is able to improve the signal
reception. However, an aspect often overlooked is the potential bandwidth
restrictions on the wideband signal reflected by the RIS. If not carefully
considered, this can become an impediment for the adoption of the RIS in the
next generation of communications systems. Therefore, in this work we propose a
RIS configuration method that provides frequency selective signal reflection
for wideband signals.

</details>


### [5] [On the Compromise Between Performance and Efficiency in RIS-aided Communication Systems](https://arxiv.org/abs/2508.15599)
*P. H. C. de Souza,M. Khazaee,L. L. Mendes*

Main category: eess.SP

TL;DR: STAR-RIS技术通过同时传输和反射信号，解决了传统RIS系统的空间覆盖和信号放大限制，提升了无线通信系统的性能。


<details>
  <summary>Details</summary>
Motivation: 传统RIS系统受限于仅反射功能，限制了空间覆盖和信号放大潜力。STAR-RIS通过同时传输和反射信号来解决这些限制。

Method: 采用同时传输和反射的可重构智能表面（STAR-RIS）技术，通过双功能操作来增强无线通信系统性能。

Result: STAR-RIS能够扩展覆盖范围、提高能量效率、减少延迟，同时在多个无线场景中增强总速率和物理层安全性。

Conclusion: STAR-RIS技术为无线通信系统提供了新的范式，通过双功能操作显著提升了系统性能，解决了传统RIS的局限性。

Abstract: The reconfigurable intelligent surface (RIS) technology for metasurfaces is
ushering in a new paradigm for wireless communication systems. It provides an
accessible way for controlling the interaction between electromagnetic waves
with the propagation medium. One particularly important aspect is the
configuration of the RIS elements or reflectors. Simply stated, the objective
of the RIS configuration is to choose the optimum phase-shift combination that
maximizes the channel capacity. Recently, neural networks (NNs) were proposed
for tackling this task and results have shown that the proposed NN promotes far
less reconfigurations of the RIS, consequently reducing the configuration
overhead. Beyond that, the RIS can be repurposed for tackling the Doppler shift
in high-mobility communication systems. Despite not being its usual primary
goal, results have also demonstrated that the RIS can compensate for the
Doppler shift at a small cost in performance. However, the typical
reflection-only constraint for RIS systems limits the spatial coverage and
signal amplification potential achieved by such systems. Therefore, the
simultaneously transmitting and reflecting reconfigurable intelligent surface
(STAR-RIS) can be employed to address these limitations by its dual
functionality of transmitting and reflecting signals concurrently. It can be
shown that the STAR-RIS can augment coverage, energy efficiency, and latency
reduction, while enhancing sum-rate and physical-layer security across several
wireless contexts.

</details>


### [6] [Discrete Radar based on Modulo Arithmetic](https://arxiv.org/abs/2508.15671)
*Nishant Mehrotra,Sandesh Rao Mattu,Saif Khan Mohammed,Ronny Hadani,Robert Calderbank*

Main category: eess.SP

TL;DR: Zak-OTFS调制方案用于雷达感知，通过离散海森堡-外尔群和辛变换设计波形，将复杂度从O(B²T²)降低到O(BT log T)，并实现小峰均功率比的优化雷达波形库。


<details>
  <summary>Details</summary>
Motivation: 传统连续雷达信号处理复杂度高（O(B²T²)），需要开发更高效的雷达波形设计和处理方法，利用离散群理论来降低计算复杂度并优化性能。

Method: 在延迟-多普勒域形成雷达波形，通过匹配滤波和相关处理生成散射环境图像，利用离散海森堡-外尔群和辛变换进行波形设计，选择最大交换子群的共同特征向量来降低复杂度。

Result: 成功将雷达信号处理复杂度从O(B²T²)显著降低到O(BT log T)，同时能够定义具有小峰均功率比的优化雷达波形库。

Conclusion: 基于离散海森堡-外尔群和辛变换的Zak-OTFS调制方案为雷达感知提供了高效的计算框架，在保持性能的同时大幅降低了处理复杂度，具有重要的实际应用价值。

Abstract: Zak-OTFS is modulation scheme where signals are formed in the delay-Doppler
(DD) domain, converted to the time domain (DD) for transmission and reception,
then returned to the DD domain for processing. We describe how to use the same
architecture for radar sensing. The intended delay resolution is $\frac{1}{B}$
where $B$ is the radar bandwidth, and the intended Doppler resolution is
$\frac{1}{T}$ where $T$ is the transmission time. We form a radar waveform in
the DD domain, illuminate the scattering environment, match filter the return,
then correlate with delay and Doppler shifts of the transmitted waveform. This
produces an image of the scattering environment, and the radar ambiguity
function expresses the blurriness of this image. The possible delay and Doppler
shifts generate the continuous Heisenberg-Weyl group which has been widely
studied in the theory of radar. We describe how to approach the problem of
waveform design, not from the perspective of this continuous group, but from
the perspective of a discrete group of delay and Doppler shifts, where the
discretization is determined by the intended delay and Doppler resolution of
the radar. We describe how to approach the problem of shaping the ambiguity
surface through symplectic transformations that normalize our discrete
Heisenberg-Weyl group. The complexity of traditional continuous radar signal
processing is $\mathcal{O}\big(B^2T^2\big)$. We describe how to reduce this
complexity to $\mathcal{O}\big(BT\log T\big)$ by choosing the radar waveform to
be a common eigenvector of a maximal commutative subgroup of our discrete
Heisenberg-Weyl group. The theory of symplectic transformations also enables
defining libraries of optimal radar waveforms with small peak-to-average power
ratios.

</details>


### [7] [A Grant-free Coded Random Access Scheme for Near-field Communications](https://arxiv.org/abs/2508.15673)
*Enrico Testi,Giulia Torcolacci,Nicolò Decarli,Davide Dardari,Enrico Paolini*

Main category: eess.SP

TL;DR: 这篇论文提出了一种结合近场空间复用和编码随机访问协议的创新方案，通过极大强度天线阵列提高IIoT连接的可靠性和降低访问延迟，为6G网络提供突破性解决方案。


<details>
  <summary>Details</summary>
Motivation: 工业互联网(IIoT)需要处理大规模间隔性流量，而无授权随机访问协议是具有扩展性和可靠性的解决方案。同时，新型无线硬件技术将网络操作推向近场传播治理，为提高空间复用能力提供了机会。

Method: 结合近场空间复用技术和编码随机访问(CRA)协议，利用极大强度天线阵列在接入点实现干扰减少和空间复用能力提升。

Result: 该方案能够提高IIoT连接的可靠性，显著降低访问延迟，为下一代6G网络提供了突破性的连接框架。

Conclusion: 这种近场空间复用与CRA协议的集成方案为工业互联网提供了一种高效、可靠的连接解决方案，在处理大规模间隔性流量方面表现优异，具有重要的应用价值。

Abstract: The industrial Internet of things (IIoT) is revolutionizing industrial
processes by facilitating massive machine-type communications among countless
interconnected devices. To efficiently handle the resulting large-scale and
sporadic traffic, grant-free random access protocols-especially coded random
access (CRA)-have emerged as scalable and reliable solutions. At the same time,
advancements in wireless hardware, including extremely large-scale MIMO arrays
and high-frequency communication (e.g., mmWave, Terahertz), are pushing network
operations into the near-field propagation regime, allowing for dense
connectivity and enhanced spatial multiplexing. This paper proposes an
innovative approach that combines near-field spatial multiplexing with the
interference mitigation capabilities of CRA, utilizing an extremely large
aperture array at the access point. This integration improves reliability and
reduces access latency, offering a robust framework for IIoT connectivity in
next-generation 6G networks.

</details>


### [8] [Estimation-Theoretic Bias Reduction for Oscillometric Blood Pressure Readings](https://arxiv.org/abs/2508.15687)
*Masoud Nateghi,Reza Sameni*

Main category: eess.SP

TL;DR: 本研究分析了示波法血压测量的系统误差来源，提出基于最小二乘和最大似然估计的统计校正方法，可提高非侵入式血压监测的准确性。


<details>
  <summary>Details</summary>
Motivation: 示波法作为标准的无创袖带血压测量方法存在系统误差，影响临床准确性，需要研究误差来源并开发校正方法。

Method: 使用MIMIC数据库的血压波形数据，分析示波法误差和呼吸波动影响，提出最小二乘(LS)和最大似然(ML)估计框架来校正单次和重复测量。

Result: 示波法倾向于低估收缩压和高估舒张压，呼吸引入周期性变化降低测量精度。统计先验知识可显著提高多读数测量的准确性。

Conclusion: 基于统计先验的估计方法能有效改善非侵入式血压监测的准确性，对心血管疾病诊断和治疗具有潜在重要价值。

Abstract: Oscillometry is the standard method for non-invasive, cuff-based blood
pressure (BP) measurement, but it introduces systematic errors that may impact
clinical accuracy. This study investigates the sources of these
errors--primarily the limitations of oscillometry itself and
respiration-induced fluctuations--using BP waveform data from the MIMIC
database. Oscillometry tends to underestimate systolic BP and overestimate
diastolic BP, while respiration introduces cyclical variations that further
degrade measurement precision. To mitigate these effects, we propose an
estimation-theoretic framework employing least squares (LS) and maximum
likelihood (ML) methods for correcting both single and repeated BP
measurements. LS estimation supports conventional multi-measurement averaging
protocols, whereas the ML approach incorporates prior knowledge of measurement
errors, offering improved performance. Our results demonstrate that leveraging
statistical priors across multiple readings can enhance the accuracy of
non-invasive BP monitoring, with potential implications for improving
cardiovascular diagnosis and treatment.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [9] [A Chinese Heart Failure Status Speech Database with Universal and Personalised Classification](https://arxiv.org/abs/2508.14908)
*Yue Pan,Liwei Liu,Changxin Li,Xinyao Wang,Yili Xia,Hanyue Zhang,Ming Chu*

Main category: eess.AS

TL;DR: 首个中文心衰患者语音数据库研究，证实中文音节包含心衰相关信息，提出个性化配对分类方法和自适应频率滤波器。


<details>
  <summary>Details</summary>
Motivation: 缺乏中文语音在心衰检测中的研究，需要验证中文音节是否包含与其他语言类似的心衰相关信息。

Method: 建立首个中文心衰患者语音数据库，采用标准患者级分类和个性化配对级分类方法，提出自适应频率滤波器进行频率重要性分析。

Result: 中文语音在心衰检测中有效，配对分类方法表现优异，个体差异是准确性的主要影响因素。

Conclusion: 中文语言可用于心衰检测，个性化配对方法为未来研究提供了理想的说话人解耦基线，数据已公开共享。

Abstract: Speech is a cost-effective and non-intrusive data source for identifying
acute and chronic heart failure (HF). However, there is a lack of research on
whether Chinese syllables contain HF-related information, as observed in other
well-studied languages. This study presents the first Chinese speech database
of HF patients, featuring paired recordings taken before and after
hospitalisation. The findings confirm the effectiveness of the Chinese language
in HF detection using both standard 'patient-wise' and personalised 'pair-wise'
classification approaches, with the latter serving as an ideal
speaker-decoupled baseline for future research. Statistical tests and
classification results highlight individual differences as key contributors to
inaccuracy. Additionally, an adaptive frequency filter (AFF) is proposed for
frequency importance analysis. The data and demonstrations are published at
https://github.com/panyue1998/Voice_HF.

</details>


### [10] [Transsion Multilingual Speech Recognition System for MLC-SLM 2025 Challenge](https://arxiv.org/abs/2508.14916)
*Xiaoxiao Li,An Zhu,Youhai Jiang,Fengjie Zhu*

Main category: eess.AS

TL;DR: 本文提出了一种基于Whisper和Qwen2.5-7B的多语言ASR系统，在MLC-SLM 2025挑战赛Track 1中取得了9.83%的词/字符错误率，获得第三名


<details>
  <summary>Details</summary>
Motivation: 开发一个高效的多语言自动语音识别系统，通过结合预训练模型和任务特定微调来提升跨语言语音识别性能

Method: 系统包含三个核心组件：冻结的Whisper-large-v3语音编码器、可训练的线性适配器模块、以及集成了LoRA的冻结Qwen2.5-7B-Instruct语言模型

Result: 在11种语言的评估集上实现了9.83%的词/字符错误率(WER/CER)，在全球参赛者中排名第三

Conclusion: 通过系统性地结合预训练模型和任务特定微调，该多语言ASR系统在跨语言语音识别任务中表现出色，证明了这种架构设计的有效性

Abstract: This paper presents the architecture and performance of a novel Multilingual
Automatic Speech Recognition (ASR) system developed by the Transsion Speech
Team for Track 1 of the MLC-SLM 2025 Challenge. The proposed system comprises
three key components: 1) a frozen Whisper-large-v3 based speech encoder,
leveraging large-scale pretraining to ensure robust acoustic feature
extraction; 2) a trainable adaptor module using Linear-ReLU-Linear
transformation mechanisms to effectively align speech and text representations;
and 3) a frozen Qwen2.5-7B-Instruct large language model (LLM) integrated with
trainable LoRA for optimized contextual linguistic decoding. By systematically
combining pretrained models with task specific fine-tuning, the system achieved
a word/character error rate (WER/CER) of 9.83% across 11 languages in the
evaluation set and ranked third place among global participants.

</details>


### [11] [Mitigating Hallucinations in LM-Based TTS Models via Distribution Alignment Using GFlowNets](https://arxiv.org/abs/2508.15442)
*Chenlin Liu,Minghui Fang,Patrick Zhang,Wei Zhou,Jie Gao,Jiqing Han*

Main category: eess.AS

TL;DR: GOAT是一个针对基于语言模型的TTS系统的后训练框架，通过不确定性分析和轨迹流优化来减少语音幻觉，无需大量资源或增加推理成本。


<details>
  <summary>Details</summary>
Motivation: 现有的基于语言模型的TTS系统容易产生偏离输入文本的幻觉语音，而现有的缓解策略要么需要大量训练资源，要么会显著增加推理延迟。

Method: 首先进行不确定性分析，发现幻觉与模型不确定性呈强正相关；然后将TTS生成重新表述为轨迹流优化问题，引入增强的子轨迹平衡目标和锐化的内部奖励作为目标分布；进一步集成奖励温度衰减和学习率优化以实现稳定性和性能平衡。

Result: 实验表明GOAT在具有挑战性的测试用例上减少了超过50%的字符错误率，并将不确定性降低了高达58%。

Conclusion: GOAT框架展示了强大的泛化能力和有效性，能够有效缓解基于语言模型的TTS系统中的幻觉问题。

Abstract: Language Model (LM)-based Text-to-Speech (TTS) systems often generate
hallucinated speech that deviates from input text. Existing mitigation
strategies either demand excessive training resources or introduce significant
inference latency. In this paper, we propose GFlOwNet-guided distribution
AlignmenT (GOAT) for LM-based TTS, a post-training framework that mitigates
hallucinations without relying on massive resources or inference cost.
Specifically, we first conduct an uncertainty analysis, revealing a strong
positive correlation between hallucination and model uncertainty. Based on
this, we reformulate TTS generation as a trajectory flow optimization problem
and introduce an enhanced Subtrajectory Balance objective together with a
sharpened internal reward as target distribution. We further integrate reward
temperature decay and learning rate optimization for stability and performance
balance. Extensive experiments show that GOAT reduce over 50% character error
rates on challenging test cases and lowering uncertainty by up to 58%,
demonstrating its strong generalization ability and effectiveness.

</details>


### [12] [EffortNet: A Deep Learning Framework for Objective Assessment of Speech Enhancement Technologies Using EEG-Based Alpha Oscillations](https://arxiv.org/abs/2508.15473)
*Ching-Chih Sung,Cheng-Hung Hsin,Yu-Anne Shiah,Bo-Jyun Lin,Yi-Xuan Lai,Chia-Ying Lee,Yu-Te Wang,Borchin Su,Yu Tsao*

Main category: eess.AS

TL;DR: EffortNet是一个深度学习框架，通过脑电图(EEG)解码个体在语音理解时的听力努力程度，特别关注噪声环境下的听力挑战。


<details>
  <summary>Details</summary>
Motivation: 听力努力是语音听力研究中的重要挑战，尤其对老年人和听力受损人群。需要客观的生物标志物来评估听力技术效果。

Method: 收集122名参与者在4种语音条件下的64通道EEG数据，使用自监督学习、增量学习和迁移学习三种互补学习范式来处理个体差异。

Result: EffortNet达到80.9%分类准确率，仅需新受试者40%训练数据，显著优于传统CNN(62.3%)和STAnet(61.1%)模型。发现Transformer增强语音比MMSE增强语音更接近清晰语音的神经响应。

Conclusion: 该框架为个性化听力技术评估提供了实用解决方案，对设计认知感知的语音增强系统具有重要意义。

Abstract: This paper presents EffortNet, a novel deep learning framework for decoding
individual listening effort from electroencephalography (EEG) during speech
comprehension. Listening effort represents a significant challenge in
speech-hearing research, particularly for aging populations and those with
hearing impairment. We collected 64-channel EEG data from 122 participants
during speech comprehension under four conditions: clean, noisy, MMSE-enhanced,
and Transformer-enhanced speech. Statistical analyses confirmed that alpha
oscillations (8-13 Hz) exhibited significantly higher power during noisy speech
processing compared to clean or enhanced conditions, confirming their validity
as objective biomarkers of listening effort. To address the substantial
inter-individual variability in EEG signals, EffortNet integrates three
complementary learning paradigms: self-supervised learning to leverage
unlabeled data, incremental learning for progressive adaptation to individual
characteristics, and transfer learning for efficient knowledge transfer to new
subjects. Our experimental results demonstrate that Effort- Net achieves 80.9%
classification accuracy with only 40% training data from new subjects,
significantly outperforming conventional CNN (62.3%) and STAnet (61.1%) models.
The probability-based metric derived from our model revealed that
Transformer-enhanced speech elicited neural responses more similar to clean
speech than MMSEenhanced speech. This finding contrasted with subjective
intelligibility ratings but aligned with objective metrics. The proposed
framework provides a practical solution for personalized assessment of hearing
technologies, with implications for designing cognitive-aware speech
enhancement systems.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [13] [Denoising by neural network for muzzle blast detection](https://arxiv.org/abs/2508.14919)
*Hadrien Pujol,Matteo Bevillacqua,Christophe Thirard,Thierry Mazoyer*

Main category: cs.SD

TL;DR: 开发轻量级神经网络用于军事车辆上的枪声检测系统降噪，显著提高枪口冲击波检测率


<details>
  <summary>Details</summary>
Motivation: 军事车辆移动时产生的噪声会降低枪声检测系统的性能，需要开发计算资源需求低的降噪算法以适应多种硬件平台

Method: 采用两层隐藏层的轻量级感知器神经网络结合信号处理技术，替代计算量大的卷积神经网络

Result: 在噪声RMS值与枪口冲击波峰值幅度相当时，检测率提高了一倍以上

Conclusion: 轻量级神经网络架构能有效提升移动军事环境中枪声检测系统的性能，且计算资源需求低

Abstract: Acoem develops gunshot detection systems, consisting of a microphone array
and software that detects and locates shooters on the battlefield. The
performance of such systems is obviously affected by the acoustic environment
in which they are operating: in particular, when mounted on a moving military
vehicle, the presence of noise reduces the detection performance of the
software. To limit the influence of the acoustic environment, a neural network
has been developed. Instead of using a heavy convolutional neural network, a
lightweight neural network architecture was chosen to limit the computational
resources required to embed the algorithm on as many hardware platforms as
possible. Thanks to the combination of a two hidden layer perceptron and
appropriate signal processing techniques, the detection rate of impulsive
muzzle blast waveforms (the wave coming from the detonation and indicating the
position of the shooter) is significantly increased. With a rms value of noise
of the same order as the muzzle blast peak amplitude, the detect rate is more
than doubled with this denoising processing.

</details>


### [14] [Human Feedback Driven Dynamic Speech Emotion Recognition](https://arxiv.org/abs/2508.14920)
*Ilya Fedorov,Dmitry Korobchenko*

Main category: cs.SD

TL;DR: 本文提出了一种基于Dirichlet分布建模情感混合的动态语音情感识别新方法，通过多阶段训练结合人类反馈，在3D虚拟人动画情感识别中优于滑动窗口方法


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别方法无法处理音频中随时间变化的情感序列，特别是在3D虚拟人动画场景中需要准确捕捉动态情感变化

Method: 多阶段方法：1）训练经典语音情感识别模型 2）合成生成情感序列 3）基于人类反馈改进模型 4）引入基于Dirichlet分布的情感混合建模新方法

Result: 实验结果表明Dirichlet方法在建模情感混合方面有效，结合人类反馈进一步提升了模型质量并简化了标注过程

Conclusion: 提出的动态语音情感识别方法成功解决了情感序列建模问题，Dirichlet分布和人类反馈的结合为情感识别领域提供了新的有效解决方案

Abstract: This work proposes to explore a new area of dynamic speech emotion
recognition. Unlike traditional methods, we assume that each audio track is
associated with a sequence of emotions active at different moments in time. The
study particularly focuses on the animation of emotional 3D avatars. We propose
a multi-stage method that includes the training of a classical speech emotion
recognition model, synthetic generation of emotional sequences, and further
model improvement based on human feedback. Additionally, we introduce a novel
approach to modeling emotional mixtures based on the Dirichlet distribution.
The models are evaluated based on ground-truth emotions extracted from a
dataset of 3D facial animations. We compare our models against the sliding
window approach. Our experimental results show the effectiveness of
Dirichlet-based approach in modeling emotional mixtures. Incorporating human
feedback further improves the model quality while providing a simplified
annotation procedure.

</details>


### [15] [XAI-Driven Spectral Analysis of Cough Sounds for Respiratory Disease Characterization](https://arxiv.org/abs/2508.14949)
*Patricia Amado-Caballero,Luis Miguel San-José-Revuelta,María Dolores Aguilar-García,José Ramón Garmendia-Leiza,Carlos Alberola-López,Pablo Casaseca-de-la-Higuera*

Main category: cs.SD

TL;DR: 提出基于可解释人工智能(XAI)的方法，通过遮挡映射技术分析咳嗽声谱图，揭示呼吸疾病特有的声学特征，提高咳嗽声音分析的诊断能力。


<details>
  <summary>Details</summary>
Motivation: 传统咳嗽声谱图分析缺乏显著性差异，需要更可解释的方法来识别呼吸疾病特有的声学模式，提升诊断准确性。

Method: 使用卷积神经网络处理咳嗽声谱图，采用遮挡映射技术突出相关频谱区域，然后对加权声谱图进行频谱分析，提取多个频谱特征。

Result: 在COPD患者中，识别出的感兴趣频谱区域显示咳嗽模式变异性更大，而原始声谱图分析未发现显著差异，证明了XAI技术在发现疾病特异性声学特征方面的潜力。

Conclusion: XAI驱动的方法能够提供更可解释的结果，有效揭示呼吸疾病的声学特征，显著提升咳嗽声音分析的诊断能力。

Abstract: This paper proposes an eXplainable Artificial Intelligence (XAI)-driven
methodology to enhance the understanding of cough sound analysis for
respiratory disease management. We employ occlusion maps to highlight relevant
spectral regions in cough spectrograms processed by a Convolutional Neural
Network (CNN). Subsequently, spectral analysis of spectrograms weighted by
these occlusion maps reveals significant differences between disease groups,
particularly in patients with COPD, where cough patterns appear more variable
in the identified spectral regions of interest. This contrasts with the lack of
significant differences observed when analyzing raw spectrograms. The proposed
approach extracts and analyzes several spectral features, demonstrating the
potential of XAI techniques to uncover disease-specific acoustic signatures and
improve the diagnostic capabilities of cough sound analysis by providing more
interpretable results.

</details>


### [16] [Comparative Evaluation of Text and Audio Simplification: A Methodological Replication Study](https://arxiv.org/abs/2508.15088)
*Prosanta Barai,Gondy Leroy,Arif Ahmed*

Main category: cs.SD

TL;DR: 本研究是对Leroy等人(2022)研究的复制，验证了文本简化在音频医疗信息理解中的有效性，发现简化文本能提升感知易懂性和实际理解度。


<details>
  <summary>Details</summary>
Motivation: 基于多媒体环境下医疗信息传播的重要性，特别是音频内容的日益普及，研究文本简化对音频医疗信息理解的影响。

Method: 采用44名参与者，评估他们对基于原始文本和简化文本生成的音频医疗信息的理解程度，同时考察教育水平和语言能力的影响。

Result: 文本简化显著提高了感知易懂性和实际理解度，与原始研究结果一致；教育水平和语言能力对医疗信息获取和理解有潜在影响。

Conclusion: 文本简化工具对提升健康素养具有实用价值，需要制定针对不同受众的定制化沟通策略来有效传播医疗信息。

Abstract: This study serves as a methodological replication of Leroy et al. (2022)
research, which investigated the impact of text simplification on healthcare
information comprehension in the evolving multimedia landscape. Building upon
the original studys insights, our replication study evaluates audio content,
recognizing its increasing importance in disseminating healthcare information
in the digital age. Specifically, we explored the influence of text
simplification on perceived and actual difficulty when users engage with audio
content automatically generated from that text. Our replication involved 44
participants for whom we assessed their comprehension of healthcare information
presented as audio created using Leroy et al. (2022) original and simplified
texts. The findings from our study highlight the effectiveness of text
simplification in enhancing perceived understandability and actual
comprehension, aligning with the original studys results. Additionally, we
examined the role of education level and language proficiency, shedding light
on their potential impact on healthcare information access and understanding.
This research underscores the practical value of text simplification tools in
promoting health literacy. It suggests the need for tailored communication
strategies to reach diverse audiences effectively in the healthcare domain.

</details>


### [17] [An Enhanced Audio Feature Tailored for Anomalous Sound Detection Based on Pre-trained Models](https://arxiv.org/abs/2508.15334)
*Guirui Zhong,Qing Wang,Jun Du,Lei Wang,Mingqi Cai,Xin Fang*

Main category: cs.SD

TL;DR: 本文提出了一种新的均匀分布滤波器组音频特征提取方法和无参数特征增强技术，用于提高异常声音检测系统的性能。


<details>
  <summary>Details</summary>
Motivation: 机器声音中异常位置的不确定性以及噪声等冗余信息阻碍了ASD系统性能的提升，需要更有效的特征提取和处理方法。

Method: 使用均匀分布间隔的滤波器组音频特征，确保对所有频段的均等关注；基于预训练模型的无参数特征增强方法，去除机器音频中的冗余信息。

Result: 在DCASE 2024挑战赛数据集上评估显示，提出的方法在异常声音检测性能上实现了显著提升。

Conclusion: 该新的特征提取和无参数特征增强方法能够有效提高ASD系统的性能，并促进预训练模型知识向ASD任务的有效转移。

Abstract: Anomalous Sound Detection (ASD) aims at identifying anomalous sounds from
machines and has gained extensive research interests from both academia and
industry. However, the uncertainty of anomaly location and much redundant
information such as noise in machine sounds hinder the improvement of ASD
system performance. This paper proposes a novel audio feature of filter banks
with evenly distributed intervals, ensuring equal attention to all frequency
ranges in the audio, which enhances the detection of anomalies in machine
sounds. Moreover, based on pre-trained models, this paper presents a
parameter-free feature enhancement approach to remove redundant information in
machine audio. It is believed that this parameter-free strategy facilitates the
effective transfer of universal knowledge from pre-trained tasks to the ASD
task during model fine-tuning. Evaluation results on the Detection and
Classification of Acoustic Scenes and Events (DCASE) 2024 Challenge dataset
demonstrate significant improvements in ASD performance with our proposed
methods.

</details>


### [18] [AudioSet-R: A Refined AudioSet with Multi-Stage LLM Label Reannotation](https://arxiv.org/abs/2508.15429)
*Yulin Sun,Qisheng Xu,Yi Su,Qian Zhu,Yong Dou,Xinwang Liu,Kele Xu*

Main category: cs.SD

TL;DR: 提出了一个三阶段重标注框架，利用音频-语言基础模型系统性地改进AudioSet的标签质量，构建了高质量的结构化重标注版本AudioSet-R，在多个音频分类模型上验证了显著性能提升


<details>
  <summary>Details</summary>
Motivation: AudioSet作为音频研究社区广泛使用的基准数据集，其标签准确性和完整性问题一直限制着下游应用的性能表现，需要解决这些关键瓶颈

Method: 采用三阶段重标注框架，利用跨模态提示策略（受提示链概念启发），通过顺序组合提示来执行音频理解、标签合成和语义对齐三个子任务

Result: 在代表性音频分类模型（AST、PANNs、SSAST、AudioMAE）上进行的广泛实验一致显示出显著的性能改进，验证了该方法在提高标签可靠性方面的通用性和有效性

Conclusion: 提出的重标注框架能够有效提升AudioSet数据集的标签质量，构建的AudioSet-R版本为音频研究社区提供了更可靠的基准数据集，代码已开源

Abstract: AudioSet is a widely used benchmark in the audio research community and has
significantly advanced various audio-related tasks. However, persistent issues
with label accuracy and completeness remain critical bottlenecks that limit
performance in downstream applications.To address the aforementioned
challenges, we propose a three-stage reannotation framework that harnesses
general-purpose audio-language foundation models to systematically improve the
label quality of AudioSet. The framework employs a cross-modal prompting
strategy, inspired by the concept of prompt chaining, wherein prompts are
sequentially composed to execute subtasks (audio comprehension, label
synthesis, and semantic alignment). Leveraging this framework, we construct a
high-quality, structured relabeled version of AudioSet-R. Extensive experiments
conducted on representative audio classification models--including AST, PANNs,
SSAST, and AudioMAE--consistently demonstrate substantial performance
improvements, thereby validating the generalizability and effectiveness of the
proposed approach in enhancing label reliability.The code is publicly available
at: https://github.com/colaudiolab/AudioSet-R.

</details>


### [19] [DualMark: Identifying Model and Training Data Origins in Generated Audio](https://arxiv.org/abs/2508.15521)
*Xuefeng Yang,Jian Guan,Feiyang Xiao,Congyi Fan,Haohe Liu,Qiaoxi Zhu,Dongli Xu,Youtian Lin*

Main category: cs.SD

TL;DR: DualMark是首个双溯源音频水印框架，能在训练期间同时嵌入模型身份和数据集来源两种水印，解决了现有方法只能进行模型溯源而无法追踪训练数据的问题。


<details>
  <summary>Details</summary>
Motivation: 现有音频生成模型水印方法只能进行模型级溯源，无法追踪底层训练数据集，这在版权和问责场景中存在重大局限性。

Method: 提出Dual Watermark Embedding模块在梅尔频谱表示中嵌入双水印，配合Watermark Consistency Loss确保水印可靠提取，并建立了Dual Attribution Benchmark评估标准。

Result: 实验验证DualMark达到97.01% F1分数的模型溯源准确率和91.51% AUC的数据集溯源准确率，在对抗性攻击下保持优异鲁棒性。

Conclusion: 该工作为实现完全可问责的音频生成模型提供了基础性进展，显著增强了版权保护和责任追踪能力。

Abstract: Existing watermarking methods for audio generative models only enable
model-level attribution, allowing the identification of the originating
generation model, but are unable to trace the underlying training dataset. This
significant limitation raises critical provenance questions, particularly in
scenarios involving copyright and accountability concerns. To bridge this
fundamental gap, we introduce DualMark, the first dual-provenance watermarking
framework capable of simultaneously encoding two distinct attribution
signatures, i.e., model identity and dataset origin, into audio generative
models during training. Specifically, we propose a novel Dual Watermark
Embedding (DWE) module to seamlessly embed dual watermarks into Mel-spectrogram
representations, accompanied by a carefully designed Watermark Consistency Loss
(WCL), which ensures reliable extraction of both watermarks from generated
audio signals. Moreover, we establish the Dual Attribution Benchmark (DAB), the
first robustness evaluation benchmark specifically tailored for joint
model-data attribution. Extensive experiments validate that DualMark achieves
outstanding attribution accuracy (97.01% F1-score for model attribution, and
91.51% AUC for dataset attribution), while maintaining exceptional robustness
against aggressive pruning, lossy compression, additive noise, and sampling
attacks, conditions that severely compromise prior methods. Our work thus
provides a foundational step toward fully accountable audio generative models,
significantly enhancing copyright protection and responsibility tracing
capabilities.

</details>


### [20] [Any-to-any Speaker Attribute Perturbation for Asynchronous Voice Anonymization](https://arxiv.org/abs/2508.15565)
*Liping Chen,Chenyang Guo,Rui Wang,Kong Aik Lee,Zhenhua Ling*

Main category: cs.SD

TL;DR: 这篇论文提出了一种任意到任意的训练策略和说话人对抗语音生成模型，通过批次均值损失将多个说话人的语音匿名化到一个伪说话人，以避免使用真实说话人带来的隐私风险。


<details>
  <summary>Details</summary>
Motivation: 传统的目标攻击训练策略将语音匿名化到指定真实说话人，可能侵害该说话人的隐私。需要一种更安全的方法来提高语音匿名化的身份不可链接性。

Method: 提出任意到任意训练策略，通过批次均值损失将训练小批中的多个说话人语音匿名化到一个共享的伪说话人（小批内说话人的平均）。构建说话人对抗语音生成模型，结合无目标攻击和任意到任意策略的监督。

Result: 在VoxCeleb数据集上进行的异步语音匿名化实验表明了提出模型的有效性。进一步实验探索了说话人对抗语音在语音隐私保护中的潜在限制。

Conclusion: 该方法提供了一种更安全的语音匿名化方案，避免了使用真实说话人带来的隐私风险。为未来研究提供了有价值的见解，特别是在应对黑盒说话提取器、适配性攻击以及领域外数据的通用性方面。

Abstract: Speaker attribute perturbation offers a feasible approach to asynchronous
voice anonymization by employing adversarially perturbed speech as anonymized
output. In order to enhance the identity unlinkability among anonymized
utterances from the same original speaker, the targeted attack training
strategy is usually applied to anonymize the utterances to a common designated
speaker. However, this strategy may violate the privacy of the designated
speaker who is an actual speaker. To mitigate this risk, this paper proposes an
any-to-any training strategy. It is accomplished by defining a batch mean loss
to anonymize the utterances from various speakers within a training mini-batch
to a common pseudo-speaker, which is approximated as the average speaker in the
mini-batch. Based on this, a speaker-adversarial speech generation model is
proposed, incorporating the supervision from both the untargeted attack and the
any-to-any strategies. The speaker attribute perturbations are generated and
incorporated into the original speech to produce its anonymized version. The
effectiveness of the proposed model was justified in asynchronous voice
anonymization through experiments conducted on the VoxCeleb datasets.
Additional experiments were carried out to explore the potential limitations of
speaker-adversarial speech in voice privacy protection. With them, we aim to
provide insights for future research on its protective efficacy against
black-box speaker extractors \textcolor{black}{and adaptive attacks, as well
as} generalization to out-of-domain datasets \textcolor{black}{and stability}.
Audio samples and open-source code are published in
https://github.com/VoicePrivacy/any-to-any-speaker-attribute-perturbation.

</details>


### [21] [ASCMamba: Multimodal Time-Frequency Mamba for Acoustic Scene Classification](https://arxiv.org/abs/2508.15632)
*Bochao Sun,Dong Wang,Han Yin*

Main category: cs.SD

TL;DR: 本文提出了ASCMamba多模态网络，用于APSIPA ASC 2025挑战赛的声学场景分类任务，通过整合音频和文本信息，在基准系统基础上实现了6.2%的性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统的声学场景分类系统仅依赖音频输入，而APSIPA ASC 2025挑战赛引入了多模态任务，提供额外的文本信息（录音地点和时间），需要开发能够有效整合多模态信息的系统。

Method: 提出ASCMamba多模态网络，使用DenseEncoder从频谱图中提取分层频谱特征，采用双路径Mamba块通过基于状态空间模型的Mamba捕获长程时间和频率依赖关系，并引入两步伪标签机制生成更可靠的伪标签。

Result: 所提出的系统在所有参赛团队中表现最佳，相比基准系统实现了6.2%的改进。

Conclusion: ASCMamba通过有效整合音频和文本信息，在多模态声学场景分类任务中取得了显著性能提升，证明了多模态方法在该领域的有效性。

Abstract: Acoustic Scene Classification (ASC) is a fundamental problem in computational
audition, which seeks to classify environments based on the distinctive
acoustic features. In the ASC task of the APSIPA ASC 2025 Grand Challenge, the
organizers introduce a multimodal ASC task. Unlike traditional ASC systems that
rely solely on audio inputs, this challenge provides additional textual
information as inputs, including the location where the audio is recorded and
the time of recording. In this paper, we present our proposed system for the
ASC task in the APSIPA ASC 2025 Grand Challenge. Specifically, we propose a
multimodal network, \textbf{ASCMamba}, which integrates audio and textual
information for fine-grained acoustic scene understanding and effective
multimodal ASC. The proposed ASCMamba employs a DenseEncoder to extract
hierarchical spectral features from spectrograms, followed by a dual-path Mamba
blocks that capture long-range temporal and frequency dependencies using
Mamba-based state space models. In addition, we present a two-step
pseudo-labeling mechanism to generate more reliable pseudo-labels. Results show
that the proposed system outperforms all the participating teams and achieves a
6.2% improvement over the baseline. Code, model and pre-trained checkpoints are
available at https://github.com/S-Orion/ASCMamba.git.

</details>

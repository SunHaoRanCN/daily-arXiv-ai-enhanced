<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 5]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.SD](#cs.SD) [Total: 4]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Secure ISAC Systems Empowered by Compound Reconfigurable Antenna Arrays](https://arxiv.org/abs/2508.16055)
*Mengzhen Liu,Ming Li,Rang Liu,Qian Liu*

Main category: eess.SP

TL;DR: 本文提出了一种基于复合可重配天线(CRA)数组的新题安全ISAC框架，通过联合设计电磁域和基带域预编码器，在保持通信安全的同时实现了远超传统方案的雷达感知性能提升。


<details>
  <summary>Details</summary>
Motivation: 在ISAC系统中，双功能信号在雷达感知过程中容易暴露机密通信信息，尤其当感知目标本身作为侦听者时。传统基带域安全方案受限于空间分辨率不足和空间相关频道的影响。

Method: 提出基于CRA数组的新题安全ISAC框架，建立包含虚拟角域、空间域和去极化效应的综合频道模型，并形成MINLP优化问题。设计了基于FP、MM、SOCP和罚法的迭代分解算法来联合设计电磁域和基带域预编码器。

Result: 模拟结果显示，CRA数组结构与联合设计方案在安全ISAC系统中实现了显著性能提升，雷达感知收益远超传统放射方案达12dB，同时保持了稳健的通信安全性。

Conclusion: 通过联合利用电磁域的额外自由度，本文提出的方案为安全ISAC系统设计带来了重大改进，显著提升了感知性能和通信安全性。

Abstract: In integrated sensing and communication (ISAC) systems, the use of
dual-functional signals inherently exposes confidential communication
information during radar sensing, particularly when the sensing target itself
acts as an eavesdropper. Conventional physical-layer security solutions rely on
directional beamforming or artificial noise injection implemented via signal
processing in the baseband (BB) domain. However, these BB-domain approaches are
constrained by insufficient spatial resolution and the adverse effects of
spatially correlated channels. To overcome these limitations, this paper
proposes a novel secure ISAC framework empowered by compound reconfigurable
antenna (CRA) arrays, which offer simultaneous reconfigurability of radiation
patterns and polarization states in the electromagnetic (EM) domain.
Specifically, we develop a comprehensive channel model incorporating virtual
angular domain, spatial domain, and depolarization effects, and formulate a
mixed-integer nonlinear programming (MINLP) problem to jointly design EM-domain
and BB-domain precoders and combiners. To efficiently solve this complex
optimization problem, we propose an iterative decomposition-based algorithm
leveraging fractional programming (FP), majorization-minimization (MM),
second-order cone programming (SOCP), and penalty methods. Extensive simulation
results demonstrate that the CRA array architecture with proposed joint EM-and
BB-domain design achieves significant performance improvements in secure ISAC
systems. In particular, radar sensing gains of up to 12dB are observed over
conventional beamforming, while robust communication security is maintained.
These results highlight the considerable benefits attainable by jointly
leveraging additional degrees of freedom (DoFs) in the EM domain for secure
ISAC system design.

</details>


### [2] [FM OFDM Unifying High Mobility Communications and Sensing](https://arxiv.org/abs/2508.16107)
*Amir Bouziane,Huseyin Arslan*

Main category: eess.SP

TL;DR: 本文研究了FM-OFDM波形在6G集成感知与通信中的应用，相比传统OFDM具有恒定包络特性，在高移动性环境下表现出更优越的感知性能


<details>
  <summary>Details</summary>
Motivation: 6G系统需要同时支持高速数据传输和精确环境感知，但传统OFDM的高峰均功率比(PAPR)在高频段带来挑战，需要寻找更适合的波形方案

Method: 提出频率调制正交频分复用(FM-OFDM)波形，推导其在时变多径信道中的输入输出关系，分析载波间干扰、多普勒效应和有效信道增益

Result: 仿真显示FM-OFDM在距离和速度估计精度上优于传统CP-OFDM和CE-OFDM，特别是在高信噪比和高移动性条件下

Conclusion: FM-OFDM适合作为6G高频段ISAC应用的统一波形，能够有效应对高移动性双弥散信道条件

Abstract: Integrated Sensing and Communication (ISAC) is foundational to future sixth
generation (6G) systems, demanding waveform co-design that supports both high
throughput data transmission and accurate environmental perception. While
Orthogonal Frequency Division Multiplexing (OFDM) offers flexibility and
backward compatibility, its high Peak to Average Power Ratio (PAPR) poses
significant challenges at higher frequency bands. To address this, we
investigate Frequency Modulated Orthogonal Frequency Division Multiplexing (FM
OFDM) a constant envelope waveform that facilitates robust joint sensing and
communication under highly mobile, doubly dispersive channel conditions. We
derive a comprehensive input output relationship for FM OFDM in time varying
multipath channels, including analytical expressions for Inter Carrier
Interference (ICI), Doppler effects, and effective channel gains. Extensive
simulations comparing FM OFDM with conventional Cyclic Prefix Orthogonal
Frequency Division Multiplexing (CP OFDM) and Constant Envelope Orthogonal
Frequency Division Multiplexing (CE OFDM) demonstrate superior range and
velocity estimation accuracy of FM-OFDM, particularly at high Signal to Noise
Ratios (SNRs) and under high mobility, highlighting its suitability as a
unified waveform for high frequency ISAC applications in 6G.

</details>


### [3] [A Scalable Hybrid Track-Before-Detect Tracking System: Application to Coastal Maritime Radar Surveillance](https://arxiv.org/abs/2508.16169)
*Lukas Herrmann,Ángel F. García-Fernández,Edmund F. Brekke,Egil Eide*

Main category: eess.SP

TL;DR: 提出了一种结合检测前跟踪(TBD)和检测式跟踪的混合框架，用于海岸雷达监视，能够在资源受限条件下实现对强弱目标的鲁棒多目标跟踪


<details>
  <summary>Details</summary>
Motivation: 尽管检测前跟踪方法有理论优势，但由于计算复杂性和可扩展性限制，在实际多目标跟踪应用中很少使用。需要开发可扩展的混合跟踪框架来解决这一问题

Method: 结合IE-PHPMHT TBD模块和传统PMBM点跟踪器。处理原始雷达数据包括地杂波抑制、单元检测和聚类特征提取。高阈值检测用于强目标跟踪，低阈值检测用于TBD模块的自适应新生，实现对弱目标的早期起始和持续跟踪

Result: 使用挪威特隆赫姆峡湾的真实X波段雷达数据进行验证，在资源约束下的大观测区域中展示了鲁棒的多目标跟踪性能

Conclusion: 该方法适用于复杂海上环境中的作战部署，支持海岸监视和自主性需求，证明了在真实场景中的有效性和实用性

Abstract: Despite their theoretical advantages, track-before-detect (TBD) methods
remain largely absent from real-world multi-target tracking applications due to
their computational complexity and limited scalability. This paper presents a
scalable hybrid tracking framework that combines a TBD multi-target tracking
algorithm with a detection-based multi-target tracking algorithm for coastal
radar surveillance. In particular, the approach uses an integrated existence
Poisson histogram-probabilistic multi-hypothesis tracking (IE-PHPMHT)-based TBD
module with a conventional Poisson multi-Bernoulli Mixture (PMBM) point
tracker. The system processes raw radar data through land clutter suppression,
cell-wise detection, and clustering-based feature extraction. High-threshold
detections are used to track strong targets via the point tracker, while
low-threshold detections are employed for adaptive birth in the TBD module,
enabling early initiation and sustained tracking of weak or ambiguous targets.
Validated using real X-band radar data from the Trondheim Fjord, Norway, the
approach demonstrates robust multi-target tracking performance in a full-scale
application with a large observation area under resource constraints,
highlighting its suitability for operational deployment in complex maritime
environments needed for coastal surveillance and to support autonomy.

</details>


### [4] [Hybrid Precoding Revisited: Low-Dimensional Subspace Perspective for MU-MIMO Systems](https://arxiv.org/abs/2508.16218)
*Mintaek Oh,Jinseok Choi*

Main category: eess.SP

TL;DR: 提出基于低维子空间特性的低复杂度混合预编码框架，包括动态子阵列天线分区和统计CSIT利用方法，在显著降低复杂度的同时获得优越性能


<details>
  <summary>Details</summary>
Motivation: 多用户MIMO系统中传统混合预编码方法复杂度高，需要开发低复杂度解决方案来平衡性能和计算效率

Method: 利用低维子空间特性识别无约束最优RF预编码器，采用降复杂度预编码方法优化混合预编码器，扩展动态子阵列天线分区和统计CSIT方法

Result: 仿真验证所提算法在显著降低复杂度的同时，相比现有方法实现了优越的性能表现

Conclusion: 提出的低复杂度混合预编码框架有效解决了多用户MIMO系统的复杂度问题，同时保持了良好的性能

Abstract: This letter presents a low-complexity hybrid precoding framework for
multiuser multiple-input multiple-output (MIMO) systems by leveraging a
low-dimensional subspace property. Under the low-dimensional subspace
perspective, we first identify an unconstrained optimal radio-frequency (RF)
precoder. We then optimize a hybrid precoder via a reduced-complexity precoding
method. We further extend the proposed framework to (i) a dynamic-subarray
antenna partitioning algorithm that adaptively allocates subsets of antennas
associated with RF chains, and (ii) a channel covariance-based approach to
exploit statistical channel state information at a transmitter (CSIT), ensuring
robustness with partial CSIT. Simulations validate that our proposed algorithms
achieve superior performance while significantly reducing complexity compared
to existing methods.

</details>


### [5] [Parameter-Free Logit Distillation via Sorting Mechanism](https://arxiv.org/abs/2508.16544)
*Stephen Ekaputra Limantoro*

Main category: eess.SP

TL;DR: 提出了一种基于排序机制的logit处理方案，通过修正教师模型的错误预测并重新排序分布来改进知识蒸馏效果


<details>
  <summary>Details</summary>
Motivation: 现有知识蒸馏方法通常直接使用教师模型的原始分布，忽略了错误预测的潜在影响，这与通过交叉熵损失进行硬标签学习的动机相矛盾，可能导致某些样本的知识蒸馏效果不佳

Method: 提出了一种新颖的logit处理方案，通过排序机制实现两个目标：1）基于标签修正教师模型的错误预测；2）根据优先级排名自然重新排序分布。该方法可作为即插即用的预处理模块应用于现有的基于logit的知识蒸馏方法

Result: 在CIFAR-100和ImageNet数据集上的大量实验证明了该方法的有效性

Conclusion: 所提出的排序机制是一种有效的logit预处理方法，能够显著提升知识蒸馏的性能，且易于集成到现有方法中

Abstract: Knowledge distillation (KD) aims to distill the knowledge from the teacher
(larger) to the student (smaller) model via soft-label for the efficient neural
network. In general, the performance of a model is determined by accuracy,
which is measured with labels. However, existing KD approaches usually use the
teacher with its original distribution, neglecting the potential of incorrect
prediction. This may contradict the motivation of hard-label learning through
cross-entropy loss, which may lead to sub-optimal knowledge distillation on
certain samples. To address this issue, we propose a novel logit processing
scheme via a sorting mechanism. Specifically, our method has a two-fold goal:
(1) fixing the incorrect prediction of the teacher based on the labels and (2)
reordering the distribution in a natural way according to priority rank at
once. As an easy-to-use, plug-and-play pre-processing, our sort method can be
effectively applied to existing logit-based KD methods. Extensive experiments
on the CIFAR-100 and ImageNet datasets demonstrate the effectiveness of our
method.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [6] [Hybrid Pruning: In-Situ Compression of Self-Supervised Speech Models for Speaker Verification and Anti-Spoofing](https://arxiv.org/abs/2508.16232)
*Junyi Peng,Lin Zhang,Jiangyu Han,Oldřich Plchot,Johan Rohdin,Themos Stafylakis,Shuai Wang,Jan Černocký*

Main category: eess.AS

TL;DR: 提出统一框架将结构化剪枝与下游任务微调整合，单阶段联合优化任务性能和模型稀疏度，实现70%参数压缩且性能损失可忽略


<details>
  <summary>Details</summary>
Motivation: 现有大规模自监督语音模型参数量大难以部署，传统结构化剪枝方法与任务微调分离，无法为不同下游任务创建最优压缩架构

Method: 统一框架将结构化剪枝集成到下游微调过程中，单阶段联合优化任务性能和模型稀疏度，无需复杂多阶段流程和知识蒸馏

Result: 在Vox1数据集上实现70%参数压缩，错误率分别为0.7%、0.8%和1.6%；在低资源场景下泛化能力提升，ASVspoof5上达到3.7% EER的SOTA性能

Conclusion: 该方法能有效压缩模型规模同时保持性能，特别适合资源受限设备部署，在低资源场景表现优异

Abstract: Although large-scale self-supervised learning (SSL) models like WavLM have
achieved state-of-the-art performance in speech processing, their significant
size impedes deployment on resource-constrained devices. While structured
pruning is a key technique for model compression, existing methods typically
separate it from task-specific fine-tuning. This multi-stage approach struggles
to create optimal architectures tailored for diverse downstream tasks. In this
work, we introduce a unified framework that integrates structured pruning into
the downstream fine-tuning process. Our framework unifies these steps, jointly
optimizing for task performance and model sparsity in a single stage. This
allows the model to learn a compressed architecture specifically for the end
task, eliminating the need for complex multi-stage pipelines and knowledge
distillation. Our pruned models achieve up to a 70\% parameter reduction with
negligible performance degradation on large-scale datasets, achieving equal
error rates of 0.7\%, 0.8\%, and 1.6\% on Vox1-O, -E, and -H, respectively.
Furthermore, our approach demonstrates improved generalization in low-resource
scenarios, reducing overfitting and achieving a state-of-the-art 3.7\% EER on
ASVspoof5.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [7] [Beyond Transcription: Mechanistic Interpretability in ASR](https://arxiv.org/abs/2508.15882)
*Neta Glazer,Yael Segal-Feldman,Hilit Segev,Aviv Shamsian,Asaf Buchnick,Gill Hetz,Ethan Fetaya,Joseph Keshet,Aviv Navon*

Main category: cs.SD

TL;DR: 该研究将自然语言处理中的可解释性方法（如logit lens、线性探测和激活修补）系统性地应用于自动语音识别系统，揭示了ASR模型内部的声音-语义信息演化过程，发现了导致重复幻觉和语义偏差的具体编码器-解码器交互机制。


<details>
  <summary>Details</summary>
Motivation: 尽管可解释性方法在大型语言模型中已得到广泛应用，但在自动语音识别领域仍未被充分探索。研究者希望将这些技术应用于ASR系统，以提升系统性能和可解释性，揭示模型内部的信息处理机制。

Method: 研究采用了三种成熟的可解释性方法：logit lens（观察中间层输出）、线性探测（训练分类器分析表示）和激活修补（干预特定激活以分析因果影响），系统地分析ASR系统中各层的声音和语义信息演化。

Result: 实验发现了ASR系统内部以前未知的动态机制，包括导致重复幻觉的具体编码器-解码器交互，以及在深层声音表示中编码的语义偏差。这些发现揭示了ASR模型处理信息的详细过程。

Conclusion: 研究表明将可解释性技术扩展到语音识别领域具有重要价值，为未来提升模型透明度和鲁棒性的研究开辟了有前景的方向，有助于更好地理解和改进ASR系统。

Abstract: Interpretability methods have recently gained significant attention,
particularly in the context of large language models, enabling insights into
linguistic representations, error detection, and model behaviors such as
hallucinations and repetitions. However, these techniques remain underexplored
in automatic speech recognition (ASR), despite their potential to advance both
the performance and interpretability of ASR systems. In this work, we adapt and
systematically apply established interpretability methods such as logit lens,
linear probing, and activation patching, to examine how acoustic and semantic
information evolves across layers in ASR systems. Our experiments reveal
previously unknown internal dynamics, including specific encoder-decoder
interactions responsible for repetition hallucinations and semantic biases
encoded deep within acoustic representations. These insights demonstrate the
benefits of extending and applying interpretability techniques to speech
recognition, opening promising directions for future research on improving
model transparency and robustness.

</details>


### [8] [QvTAD: Differential Relative Attribute Learning for Voice Timbre Attribute Detection](https://arxiv.org/abs/2508.15931)
*Zhiyu Wu,Jingyi Fang,Yufei Tang,Yuanzhong Zheng,Yaoxuan Wang,Haojun Fei*

Main category: cs.SD

TL;DR: QvTAD是一个基于差分注意力的成对比较框架，用于语音音色属性检测，通过图数据增强和相对音色偏移感知注意力模块，在VCTK-RVA数据集上取得了显著性能提升


<details>
  <summary>Details</summary>
Motivation: 语音音色属性检测面临描述词主观性和数据集标签不平衡的挑战，需要新的方法来增强感知音色属性的建模能力

Method: 提出基于有向无环图和并查集技术的图数据增强策略，构建相对音色偏移感知差分注意力模块，使用预训练FACodec的说话人嵌入

Result: 在VCTK-RVA基准测试中，QvTAD在多个音色描述词上取得显著改进，特别是在跨说话人泛化场景中表现突出

Conclusion: QvTAD框架通过差分注意力和数据增强技术有效解决了音色属性检测中的标签不平衡问题，提升了模型的感知建模能力

Abstract: Voice Timbre Attribute Detection (vTAD) plays a pivotal role in fine-grained
timbre modeling for speech generation tasks. However, it remains challenging
due to the inherently subjective nature of timbre descriptors and the severe
label imbalance in existing datasets. In this work, we present QvTAD, a novel
pairwise comparison framework based on differential attention, designed to
enhance the modeling of perceptual timbre attributes. To address the label
imbalance in the VCTK-RVA dataset, we introduce a graph-based data augmentation
strategy that constructs a Directed Acyclic Graph and employs Disjoint-Set
Union techniques to automatically mine unobserved utterance pairs with valid
attribute comparisons. Our framework leverages speaker embeddings from a
pretrained FACodec, and incorporates a Relative Timbre Shift-Aware Differential
Attention module. This module explicitly models attribute-specific contrasts
between paired utterances via differential denoising and contrast amplification
mechanisms. Experimental results on the VCTK-RVA benchmark demonstrate that
QvTAD achieves substantial improvements across multiple timbre descriptors,
with particularly notable gains in cross-speaker generalization scenarios.

</details>


### [9] [Head-Related Transfer Function Individualization Using Anthropometric Features and Spatially Independent Latent Representation](https://arxiv.org/abs/2508.16176)
*Ryan Niu,Shoichi Koyama,Tomohiko Nakamura*

Main category: cs.SD

TL;DR: 提出了一种基于自编码器和人体测量参数的HRTF个性化方法，通过条件化潜在表示解决多数据集融合和参数估计问题，相比现有深度学习方法获得更高精度


<details>
  <summary>Details</summary>
Motivation: 由于HRTF测量成本高昂，包含人体测量参数的数据集稀少，使得基于深度神经网络的HRTF个性化面临数据不足的挑战

Method: 使用基于声源位置条件化的自编码器获取HRTF幅度的潜在表示，从而能够融合不同测量位置的多数据集，并通过减少需要从人体参数估计的参数数量使网络训练可行

Result: 实验评估显示，与当前基于DNN的方法相比，所提方法实现了更高的估计精度

Conclusion: 该方法通过条件化潜在表示有效解决了HRTF个性化中的数据稀缺问题，为多数据集融合提供了可行方案

Abstract: A method for head-related transfer function (HRTF) individualization from the
subject's anthropometric parameters is proposed. Due to the high cost of
measurement, the number of subjects included in many HRTF datasets is limited,
and the number of those that include anthropometric parameters is even smaller.
Therefore, HRTF individualization based on deep neural networks (DNNs) is a
challenging task. We propose a HRTF individualization method using the latent
representation of HRTF magnitude obtained through an autoencoder conditioned on
sound source positions, which makes it possible to combine multiple HRTF
datasets with different measured source positions, and makes the network
training tractable by reducing the number of parameters to be estimated from
anthropometric parameters. Experimental evaluation shows that high estimation
accuracy is achieved by the proposed method, compared to current DNN-based
methods.

</details>


### [10] [Vevo2: Bridging Controllable Speech and Singing Voice Generation via Unified Prosody Learning](https://arxiv.org/abs/2508.16332)
*Xueyao Zhang,Junan Zhang,Yuancheng Wang,Chaoren Wang,Yuanzhe Chen,Dongya Jia,Zhuo Chen,Zhizheng Wu*

Main category: cs.SD

TL;DR: Vevo2是一个统一的语音和歌声生成框架，通过两个音频分词器和两阶段建模实现可控的语音和歌声生成，解决了标注歌唱数据稀缺的问题，并在多种合成任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决可控人声生成（特别是歌唱领域）的挑战，应对标注歌唱数据稀缺的问题，实现语音和歌声的统一建模和灵活控制。

Method: 引入两个音频分词器：无音乐符号的韵律分词器（捕获韵律和旋律）和低帧率内容-风格分词器（编码语言内容、韵律和风格）。采用自回归内容-风格建模阶段和流匹配声学建模阶段，提出显式和隐式韵律学习策略以及多目标后训练任务。

Result: 统一建模为语音和歌声生成带来互惠效益，在广泛的合成、转换和编辑任务中表现出强大的泛化能力和多功能性。

Conclusion: Vevo2框架成功实现了语音和歌声的统一可控生成，通过创新的分词器和建模策略解决了数据稀缺和灵活控制的问题，展现了优异的性能。

Abstract: Controllable human voice generation, particularly for expressive domains like
singing, remains a significant challenge. This paper introduces Vevo2, a
unified framework for controllable speech and singing voice generation. To
tackle issues like the scarcity of annotated singing data and to enable
flexible controllability, Vevo2 introduces two audio tokenizers: (1) a
music-notation-free prosody tokenizer that captures prosody and melody from
speech, singing, and even instrumental sounds, and (2) a low-frame-rate (12.5
Hz) content-style tokenizer that encodes linguistic content, prosody, and style
for both speech and singing, while enabling timbre disentanglement. Vevo2
consists of an auto-regressive (AR) content-style modeling stage, which aims to
enable controllability over text, prosody, and style, as well as a
flow-matching acoustic modeling stage that allows for timbre control.
Particularly, during pre-training of the AR model, we propose both explicit and
implicit prosody learning strategies to bridge speech and singing voice.
Moreover, to further enhance the AR model's ability to follow text and prosody,
we design a multi-objective post-training task that integrates both
intelligibility and prosody similarity alignment. Experimental results show
that the unified modeling in Vevo2 brings mutual benefits to both speech and
singing voice generation. Additionally, Vevo2's effectiveness across a wide
range of synthesis, conversion, and editing tasks for both speech and singing
further demonstrates its strong generalization ability and versatility. Audio
samples are are available at https://versasinger.github.io/.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 18]
- [eess.AS](#eess.AS) [Total: 6]
- [cs.SD](#cs.SD) [Total: 11]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Notes on Deterministic and Stochastic Approaches in Electromagnetic Information Theory](https://arxiv.org/abs/2508.16601)
*Marco Donald Migliore*

Main category: eess.SP

TL;DR: 本文证明了电磁信息理论中确定性模型与空间非相干均匀源的随机模型在自由度数量、特征值和基函数方面完全等价


<details>
  <summary>Details</summary>
Motivation: 研究电磁信息理论中确定性模型和随机源模型之间的关系，探索两者在自由度数量方面的基本联系

Method: 通过理论分析和数学推导，比较确定性模型与具有空间非相干均匀源的随机模型的特征值和基函数

Result: 发现两种模型不仅具有相同的自由度数量，而且具有完全相同的特征值和场表示基函数

Conclusion: 这一等价性解释了确定性方法在电磁信息理论中的有效性，并验证了经典电磁方法在新学科中的适用性

Abstract: This paper investigates the relationship between the Number of Degrees of
Freedom ($N_{\rm DoF}$) of the field in deterministic and stochastic source
models within Electromagnetic Information Theory (EIT). Our findings
demonstrate a fundamental connection between these two approaches.
Specifically, we show that a deterministic model and a stochastic model with a
spatially incoherent and homogeneous source yield not only the same $N_{\rm
DoF}$ but also identical eigenvalues and basis functions for field
representation. This key equivalence not only explains the effectiveness of
deterministic approaches in EIT but also corroborates the use of classical
electromagnetic methods within this new discipline.

</details>


### [2] [A Practical Approach to the Design of an S-Band Image-Rejecting Dual-Conversion Super-Heterodyne RF Chain of a Receiver Considering Spur Signals](https://arxiv.org/abs/2508.16735)
*Seyed Mohammad Amin Shirinbayan,Gholamreza Moradi*

Main category: eess.SP

TL;DR: 本文提出了一种超外差双变频架构雷达接收机RF链路的典型设计，通过两个相互验证的MATLAB代码来抑制杂散信号，优化SFDR性能并降低实现成本。


<details>
  <summary>Details</summary>
Motivation: 在超外差双变频架构中，杂散信号会严重影响RF链路的动态范围，需要找到有效的方法来抑制或消除这些不良影响。

Method: 采用两个相互验证的MATLAB代码来分析杂散信号，结合商用混频器测试，优化滤波器设计（特别是第二和第三滤波器）以降低成本，并使用多种微波软件和全波分析进行详细设计。

Result: 该方法使链路的无杂散动态范围(SFDR)与动态范围的差异最小化，同时优化了其他组件的选择以符合杂散信号考虑，滤波器设计有效降低了实现成本。

Conclusion: 提出的方法能够有效抑制超外差接收机中的杂散信号，优化系统性能并降低实现成本，适用于各种混频器的超外差配置。

Abstract: This paper presents a typical design of the RF section of a radar receiver,
the chain within a superheterodyne dual-conversion architecture. A significant
challenge in this framework is the occurrence of spur signals, which negatively
impact the dynamic range of the RF chain. When addressing this issue, the paper
introduces an innovative approach to mitigate (or even wipe out) these
undesired effects, utilizing two mutually verifying MATLAB codes. These codes
have been tested with two distinct commercial mixers and could be applied to
any superheterodyne configuration with various mixers. The presented method
makes the Spurious-Free Dynamic Range (SFDR) of the chain the least different
from the dynamic range of the chain. Also, the selection of other components
gets optimized to align with spurious signals consideration, with explanations
provided for these choices. Moreover, two filters of the RF chain, the second
and the third, have been designed to reduce implementation costs. Various
Microwave software and full-wave analyses were employed for detailed design and
analysis, with the results compared to evaluate their performance.

</details>


### [3] [Dual Orthogonal Projections-Based Multiuser Interference Cancellation for mmWave Beamforming in XL-MIMO Systems](https://arxiv.org/abs/2508.16888)
*Jiazhe Li,Nicolò Decarli,Francesco Guidi,Anna Guerra,Alessandro Bazzi,Zhuoming Li*

Main category: eess.SP

TL;DR: 这篇论文提出了一种迭代双正交投影算法（DOP），用于极大规模MIMO系统中的毫米波材斗形成的多用户干扰消除，该算法能够按迭代单调提高谱效率并迅速收敛。


<details>
  <summary>Details</summary>
Motivation: 解决极大规模MIMO系统中的多用户干扰问题，提高毫米波材斗形成的谱效率，寻求一种能够接近脏纸编码理论最优性能的线性算法。

Method: 提出迭代双正交投影算法（DOP），通过交替执行两个正交投影：一个用于消除多用户干扰，另一个用于精炼组合器，确保谱效率的单调增长。

Result: 理论分析和模拟结果显示，该算法在每次迭代中都能单调提高用户信号力、降低噪声力，谱效率迅速收敛并接近脏纸编码的理论最优值，性能超过现有的其他线性算法。

Conclusion: 迭代双正交投影算法是一种高效的线性算法，能够在极大规模MIMO系统中有效消除多用户干扰，实现接近理论最优的谱效率性能，为毫米波通信系统提供了有效的干扰消除方案。

Abstract: This paper investigates multiuser interference (MUI) cancellation for
millimeter-wave (mmWave) beamforming in extremely large-scale multiple-input
multiple-output (XL-MIMO) communication systems. We propose a linear algorithm,
termed iterative dual orthogonal projections (DOP), which alternates between
two orthogonal projections: one to eliminate MUI and the other to refine
combiners, ensuring a monotonic increase in spectral efficiency. Theoretical
analysis and simulation results show that, with each iteration, the signal
power for each user increases monotonically, the equivalent noise power after
receive combining decreases monotonically, and the spectral efficiency improves
accordingly and converges rapidly, closely approaching the theoretical optimum
determined by dirty paper coding (DPC), outperforming existing linear
algorithms in spectral efficiency.

</details>


### [4] [Spatially Correlated Blockage Aware Placement of RIS in IIoT Networks](https://arxiv.org/abs/2508.16946)
*Rashmi Kumari,Gourab Ghatak,Abhishek K. Gupta*

Main category: eess.SP

TL;DR: 研究可重构智能表面(RIS)在工业物联网(IIoT)网络中缓解覆盖盲区和提升传输可靠性的影响，分析单遮挡和多遮挡场景下的链路相关性、SNR分布和中断性能，并与网络控制中继进行比较。


<details>
  <summary>Details</summary>
Motivation: 工业物联网环境中存在密集遮挡物，导致通信链路频繁中断，需要研究RIS技术来改善网络覆盖和传输可靠性。

Method: 首先分析单遮挡场景下基站-用户和RIS-用户链路的遮挡事件相关性；然后推导多遮挡场景下SNR分布与数据大小、遮挡密度、RIS数量和部署区域的关系；最后比较RIS辅助系统与网络控制中继的中断性能。

Result: 识别了归一化遮挡半径的阈值，超过该阈值后独立遮挡假设与实际情况出现偏差；发现中继在特定遮挡阈值后提供更高可靠性，但增加RIS数量可以缓解这种影响。

Conclusion: 为在密集遮挡环境中部署RIS辅助的IIoT网络提供了有价值的设计指导原则，RIS技术能够有效改善工业环境中的通信可靠性。

Abstract: We study the impact of deploying reconfigurable intelligent surfaces (RISs)
in mitigating coverage gaps and enhancing transmission reliability in an
industrial internet of things (IIoT) network. First, we consider a single
blockage scenario and characterize the correlation between blocking events of
the base station (BS)-user and the RIS-user links and study its impact on the
probability of establishing a viable reflected link. Then, by considering
multiple blockages, we derive the distribution of the signal to noise ratio
(SNR) as a function of data size, blockage density, the number of RISs, and the
deployment area. We analyze the impact of normalized blockage radius and
identify the threshold beyond which the assumption of independent blockages
deviates from the ground truth of correlated blocking. Finally, we compare the
outage performance of this RIS-assisted system with that operated with network-
controlled relays, and demonstrate that while the relays provide a higher
reliability beyond a certain blockage threshold, increasing the number of RISs
may help mitigate this effect. These insights offer valuable design guidelines
for deploying RIS-aided IIoT networks in dense blockage environments.

</details>


### [5] [Radio Frequency Identification: Decades at a Time](https://arxiv.org/abs/2508.17051)
*Christopher Saetia,Daniel M. Dobkin,Gregory Durgin*

Main category: eess.SP

TL;DR: 这篇文章综述了RFID技术的发展历史和标准，比较了过去的预期与当前实际情况，分析了UHF RFID和HF NFC在不同应用领域的成功案例，并展望了RFID技术的未来发展趋势和挑战。


<details>
  <summary>Details</summary>
Motivation: 回顾RFID技术的发展历程，评估其实际应用效果，并探讨未来发展方向和潜在应用场景。

Method: 采用文献综述方法，通过历史回顾、标准分析、应用案例比较和未来展望的方式，系统性地分析RFID技术的发展状况。

Result: 文章识别了UHF RFID在某些领域取得了巨大成功，而HF NFC在其他领域更受非正式识别或主动无线通信技术占主导地位的应用场景。同时预测了UHF读取功能在手机上普及、更复杂的无线界面、与AI图像处理整合等未来发展趋势。

Conclusion: 论文强调了RFID技术在现代生活中的重要作用，展望了其在智能回收、玩兽管理、数字双生等领域的潜力，但也指出了实现这些发展前景所面临的多重挑战和障碍。

Abstract: In this article, we briefly review the history of the use of radio signals to
identify objects, and of the key Radio Frequency Identification (RFID)
standards for ultra-high-frequency (UHF) and near-field communications that
enabled broad use of these technologies in daily life. We will compare the
vision for the future presented by the Auto-ID Lab in the early 21st century
with the reality we see today, two decades and a little after. We will review
some of the applications in which UHF RFID technology has become hugely
successful, others where High Frequency Near-field Communications (HF NFC) is
preferred, and applications where optical identification or active wireless
communications are dominant.
  We will then examine some possible future paths for RFID technology. We
anticipate that UHF read capability will become widely available for
cellphones, making it as universal as NFC and Bluetooth are today. We will look
at more sophisticated radio interfaces, such as multiple-antenna phased arrays
for readers, and tunnel diode reflection for tags. We will discuss the
integration of information from Artificial Intelligence (AI)-based image
processing, barcodes, NFC and UHF tags, into a digital twin of the real
environment experienced by the human user. We will examine the role of RFID
with sensing in improving the management of perishable goods. The role that
RFID might play in a truly circular economy, with intelligent recycling and
reuse, will be discussed. Finally, we survey the many hazards and obstacles
that obstruct the path to an RF-informed future.

</details>


### [6] [Graphon Signal Processing for Spiking and Biological Neural Networks](https://arxiv.org/abs/2508.17246)
*Takuma Sumi,Georgi S. Medvedev*

Main category: eess.SP

TL;DR: 该论文提出了基于图论的图信号处理方法，通过图论理论扩展了传统图信号处理，为神经网络中的刺激识别问题提供了稳定且计算高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 为了解决计算和生物神经网络中的刺激识别问题（SIP），需要一种能够处理网络数据随机变异性的稳定方法，同时提高大型网络的计算效率。

Method: 使用图论信号处理（GnSP）方法，通过图论理论来表示图和收敛图序列的极限，利用图论谱投影获得试验不变的低维嵌入。

Result: 图论谱投影产生的低维嵌入在刺激分类方面优于主成分分析和离散图信号处理基线方法，在不同网络大小和噪声水平下保持稳定性。

Conclusion: 这是图论信号处理在生物神经网络中的首次应用，为神经科学中基于图论的分析开辟了新途径，提供了对网络随机变异性的鲁棒性。

Abstract: Graph Signal Processing (GSP) extends classical signal processing to signals
defined on graphs, enabling filtering, spectral analysis, and sampling of data
generated by networks of various kinds. Graphon Signal Processing (GnSP)
develops this framework further by employing the theory of graphons. Graphons
are measurable functions on the unit square that represent graphs and limits of
convergent graph sequences. The use of graphons provides stability of GSP
methods to stochastic variability in network data and improves computational
efficiency for very large networks. We use GnSP to address the stimulus
identification problem (SIP) in computational and biological neural networks.
The SIP is an inverse problem that aims to infer the unknown stimulus s from
the observed network output f. We first validate the approach in spiking neural
network simulations and then analyze calcium imaging recordings. Graphon-based
spectral projections yield trial-invariant, lowdimensional embeddings that
improve stimulus classification over Principal Component Analysis and discrete
GSP baselines. The embeddings remain stable under variations in network
stochasticity, providing robustness to different network sizes and noise
levels. To the best of our knowledge, this is the first application of GnSP to
biological neural networks, opening new avenues for graphon-based analysis in
neuroscience.

</details>


### [7] [Toward Multi-Functional LAWNs with ISAC: Opportunities, Challenges, and the Road Ahead](https://arxiv.org/abs/2508.17354)
*Jun Wu,Weijie Yuan,Xiaoqi Zhang,Yaohuan Yu,Yuanhao Cui,Fan Liu,Geng Sun,Jiacheng Wang,Dusit Niyato,Dong In Kim*

Main category: eess.SP

TL;DR: 本文探讨了集成感知与通信(ISAC)在低空无线网络(LAWNs)中的应用，提出了从节点级到网络级的多层次集成框架，并扩展了控制、计算、无线能量传输和LLM智能等新功能。


<details>
  <summary>Details</summary>
Motivation: 随着低空无线网络的发展，需要实现实时环境感知和数据交换的集成解决方案，ISAC技术被视为未来低空网络的基础技术。

Method: 从节点级和网络级两个角度分析ISAC在LAWNs中的作用，提出多层次集成和协作的性能增益，并构建包含控制、计算、无线能量传输和LLM智能的多功能LAWN框架。

Result: 通过层次化集成和协作实现了性能提升，展示了关键设计权衡，并通过案例研究验证了ISAC-enabled LAWNs的优势。

Conclusion: ISAC-enabled LAWNs具有广阔的应用前景，文章最后指出了有前景的研究方向，为未来低空无线网络的发展提供了重要参考。

Abstract: Integrated sensing and communication (ISAC) has been envisioned as a
foundational technology for future low-altitude wireless networks (LAWNs),
enabling real-time environmental perception and data exchange across
aerial-ground systems. In this article, we first explore the roles of ISAC in
LAWNs from both node-level and network-level perspectives. We highlight the
performance gains achieved through hierarchical integration and cooperation,
wherein key design trade-offs are demonstrated. Apart from physical-layer
enhancements, emerging LAWN applications demand broader functionalities. To
this end, we propose a multi-functional LAWN framework that extends ISAC with
capabilities in control, computation, wireless power transfer, and large
language model (LLM)-based intelligence. We further provide a representative
case study to present the benefits of ISAC-enabled LAWNs and the promising
research directions are finally outlined.

</details>


### [8] [Near-Field Integrated Imaging and Communication in Distributed MIMO Networks](https://arxiv.org/abs/2508.17526)
*Kangda Zhi,Tianyu Yang,Shuangyang Li,Yi Song,Amir Rezaei,Giuseppe Caire*

Main category: eess.SP

TL;DR: 本文提出了一个用于分布式MIMO宽带通信系统的无线电成像框架，考虑了多视角非同向性目标和近场传播效应。针对室内小对象高分辨率成像和室外大规模环境重建两种场景，分别提出了RMA基础的算法和SBL基础的算法。


<details>
  <summary>Details</summary>
Motivation: 传统无线电成像技术在处理分布式MIMO系统中的多视角非同向性目标和近场传播效应时遇到挑战，需要一个统一的框架来处理室内高分辨率小对象成像和室外大规模环境重建两种不同的应用需求。

Method: 针对室内场景，提出了基于范围迁移算法(RMA)的方案，采用全数组、边界数组和分布式边界数组三种数组架构。通过建立成像反射率与分布式空间域信号之间的归一化变换关系来实现。针对室外场景，提出了基于稀疏贝叶斯学习(SBL)的算法来解决多重测量向量(MMV)问题，处理不同子载波之间的非同向性反射率。

Result: 数值结果证明了所提出算法的有效性，能够在室内场景中获取高分辨率的小对象成像，并在室外场景中准确地重建大规模三维环境。

Conclusion: 该研究提供了一个全面的框架来处理分布式MIMO宽带系统中的无线电成像问题，通过RMA和SBL算法的组合，有效场景化了室内高分辨率小对象成像和室外大规模环境重建两种不同的应用需求，为无线电成像技术的发展提供了有力支持。

Abstract: In this work, we propose a general framework for wireless imaging in
distributed MIMO wideband communication systems, considering multi-view
non-isotropic targets and near-field propagation effects. For indoor scenarios
where the objective is to image small-scale objects with high resolution, we
propose a range migration algorithm (RMA)-based scheme using three kinds of
array architectures: the full array, boundary array, and distributed boundary
array. With non-isotropic near-field channels, we establish the Fourier
transformation (FT)-based relationship between the imaging reflectivity and the
distributed spatial-domain signals and discuss the corresponding theoretical
properties. Next, for outdoor scenarios where the objective is to reconstruct
the large-scale three-dimensional (3D) environment with coarse resolution, we
propose a sparse Bayesian learning (SBL)-based algorithm to solve the multiple
measurement vector (MMV) problem, which further addresses the non-isotropic
reflectivity across different subcarriers. Numerical results demonstrate the
effectiveness of the proposed algorithms in acquiring high-resolution small
objects and accurately reconstructing large-scale environments.

</details>


### [9] [Steerable Invariant Beamformer Using a Differential Line Array of Omnidirectional and Directional Microphones with Null Constraints](https://arxiv.org/abs/2508.17607)
*Yankai Zhang,Jiafeng Ding,Jingjing Ning,Qiaoxi Zhu*

Main category: eess.SP

TL;DR: 提出基于零点约束的频不变可转向差分波束成形方法，替代需要解析波束模式的Jacobi-Anger展开法，提供更灵活的设计自由度和更好的实际性能


<details>
  <summary>Details</summary>
Motivation: 传统Jacobi-Anger展开法依赖理想波束模式的解析表达式和截断阶数选择，在实际应用中存在局限性，需要更实用的设计方法

Method: 采用多约束优化框架，基于指定零点和期望方向确定参考滤波器和理想波束模式，然后推导白噪声增益约束和波束模式约束，最终通过波束模式、零点和白噪声增益相关约束获得最优滤波器

Result: 仿真和实验表明，该方法在三个关键方面优于Jacobi-Anger展开法：扩展的有效范围、改进的主瓣和零点对齐、更大的麦克风阵列配置和波束模式设计灵活性

Conclusion: 该方法实现了白噪声增益和均方误差之间的平衡，提供了稳健的频不变可转向差分波束成形性能，解决了波束模式灵活性和截断误差的限制

Abstract: Line differential microphone arrays have attracted attention for their
ability to achieve frequency-invariant beampatterns and high directivity.
Recently, the Jacobi-Anger expansion-based approach has enabled the design of
fully steerable-invariant differential beamformers for line arrays combining
omnidirectional and directional microphones. However, this approach relies on
the analytical expression of the ideal beam pattern and the proper selection of
truncation order, which is not always practical. This paper introduces a
null-constraint-based method for designing frequency- and steerable-invariant
differential beamformers using a line array of omnidirectional and directional
microphones. The approach employs a multi-constraint optimisation framework,
where the reference filter and ideal beam pattern are first determined based on
specified nulls and desired direction. Subsequently, the white noise gain
constraint is derived from the reference filter, and the beampattern constraint
is from the ideal beam pattern. The optimal filter is then obtained by
considering constraints related to the beampattern, nulls, and white noise
gain. This method achieves a balance between white noise gain and mean square
error, allowing robust, frequency- and steerableinvariant differential
beamforming performance. It addresses limitations in beam pattern flexibility
and truncation errors, offering greater design freedom and improved practical
applicability. Simulations and experiments demonstrate that this method
outperforms the Jacobi-Anger expansion-based approach in three key aspects: an
extended effective range, improved main lobe and null alignment, and greater
flexibility in microphone array configuration and beam pattern design,
requiring only steering direction and nulls instead of an analytic beam pattern
expression.

</details>


### [10] [Multimodal Radio and Vision Fusion for Robust Localization in Urban V2I Communications](https://arxiv.org/abs/2508.17640)
*Can Zheng,Jiguang He,Chung G. Kang,Guofa Cai,Henk Wymeersch*

Main category: eess.SP

TL;DR: 本文提出了一种多模态对比学习回归定位框架，结合通信频道状态信息和视觉信息，在V2I场景中实现更高的定位精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 基于GPS在城市环境中容易被高楼阻挡导致定位错误的问题，自动驾驶和智慧城市应用需要更可靠精确的定位技术。

Method: 采用多模态对比学习回归方法，融合通信频道状态信息(CSI)和视觉信息，利用无线电和视觉数据的互补优势。

Result: 模拟结果显示，该CSI与视觉融合模型显著超越传统方法和单模态模型，在复杂城市环境中实现了更高的定位精度和精确度。

Conclusion: 该框架为V2I应用提供了一种稳健的定位解决方案，有效克服了传统定位方法的局限性。

Abstract: Accurate localization is critical for vehicle-to-infrastructure (V2I)
communication systems, especially in urban areas where GPS signals are often
obstructed by tall buildings, leading to significant positioning errors,
necessitating alternative or complementary techniques for reliable and precise
positioning in applications like autonomous driving and smart city
infrastructure. This paper proposes a multimodal contrastive learning
regression based localization framework for V2I scenarios that combines channel
state information (CSI) with visual information to achieve improved accuracy
and reliability. The approach leverages the complementary strengths of wireless
and visual data to overcome the limitations of traditional localization
methods, offering a robust solution for V2I applications. Simulation results
demonstrate that the proposed CSI and vision fusion model significantly
outperforms traditional methods and single modal models, achieving superior
localization accuracy and precision in complex urban environments.

</details>


### [11] [Symbol Detection Using an Integrate-and-Fire Time Encoding Receiver](https://arxiv.org/abs/2508.17704)
*Neil Irwin Bernardo*

Main category: eess.SP

TL;DR: 提出了一种基于IF-TEM的事件驱动采样接收器架构，直接从时间编码中估计传输符号，无需波形重建，并分析了符号错误概率性能。


<details>
  <summary>Details</summary>
Motivation: 事件驱动采样在功耗和硬件成本受限系统中具有优势，但传统方法需要从时间编码重建波形再进行符号检测，过程复杂且效率不高。

Method: 设计IF-TEM接收器架构，直接从时间编码估计传输符号，推导符号错误概率的解析近似表达式，并通过蒙特卡洛仿真验证。

Result: 提出的IF-TEM接收器无需波形重建即可实现符号检测，解析近似与仿真结果高度吻合，且发现发射脉冲成形滤波器带宽变窄会降低接收器性能。

Conclusion: 证明了事件驱动采样中波形重建对符号检测的非必要性，揭示了频谱效率与错误恢复能力之间的权衡关系，为低功耗通信系统提供了新思路。

Abstract: Event-driven sampling is a promising alternative to uniform sampling methods,
particularly for systems constrained by power and hardware cost. A notable
example of this sampling approach is the integrate-and-fire time encoding
machine (IF-TEM), which encodes an analog signal into a sequence of time stamps
by generating an event each time the integral of the input signal reaches a
fixed threshold. In this paper, we propose a receiver architecture that
estimates the sequence of transmitted symbols directly from the encoded time
stamps, called time encodings, produced by the IF-TEM sampler on the received
signal. We show that waveform reconstruction from time encodings is not
necessary for symbol detection. We develop an analytical approximation for the
symbol error probability (SEP) of the proposed IF-TEM-based receiver and show
that it closely matches the SEP results obtained through Monte Carlo
simulations. Additionally, we demonstrate that narrowing the 3 dB bandwidth of
the transmit pulse shaping filter degrades the proposed IF-TEM receiver's
performance, highlighting a trade-off between spectral efficiency and error
resilience.

</details>


### [12] [Blind Channel Estimation for RIS-Assisted Millimeter Wave Communication Systems](https://arxiv.org/abs/2508.17710)
*Dianhao Jia,Wenqian Shen,Jianping An,Byonghyo Shim*

Main category: eess.SP

TL;DR: 本文提出了一种基于压缩感知的盲信道估计方法，用于RIS辅助多用户毫米波通信系统，通过块状传输方案和RIS重新配置来减少导频开销，实现高精度的信道估计和信号恢复。


<details>
  <summary>Details</summary>
Motivation: 在RIS辅助通信系统中，信道估计对性能优化至关重要。传统盲信道估计方法在RIS辅助的双跳信道中面临新挑战，需要减少导频开销的同时准确估计信道。

Method: 提出基于压缩感知的盲信道估计方法，采用块状传输方案：在不同数据块传输期间重新配置RIS元件以更好估计级联信道；每个块内将用户数据映射到码字，同时实现发射信号恢复和等效信道估计。

Result: 仿真结果表明，该方法能够实现相当准确的信道估计和发射信号恢复性能。

Conclusion: 该方法首次将压缩感知应用于RIS辅助多用户毫米波系统的盲信道估计，有效解决了双跳信道带来的新挑战，显著降低了导频开销。

Abstract: In the research of RIS-assisted communication systems, channel estimation is
a problem of vital importance for further performance optimization. In order to
reduce the pilot overhead to the greatest extent, blind channel estimation
methods are required, which can estimate the channel and the transmit signals
at the same time without transmitting pilot sequence. Different from existing
researches in traditional MIMO systems, the RIS-assisted two-hop channel brings
new challenges to the blind channel estimation design. Hence, a novel blind
channel estimation method based on compressed sensing for RIS-assisted
multiuser millimeter wave communication systems is proposed for the first time
in this paper. Specifically, for accurately estimating the RIS-assisted two-hop
channel without transmitting pilots, we propose a block-wise transmission
scheme. Among different blocks of data transmission, RIS elements are
reconfigured for better estimating the cascade channel. Inside each block, data
for each user are mapped to a codeword for realizing the transmit signal
recovery and equivalent channel estimation simultaneously. Simulation results
demonstrate that our method can achieve a considerable accuracy of channel
estimation and transmit signal recovery.

</details>


### [13] [EEG-FM-Bench: A Comprehensive Benchmark for the Systematic Evaluation of EEG Foundation Models](https://arxiv.org/abs/2508.17742)
*Wei Xiong,Jiangtong Li,Jie Li,Kun Zhu*

Main category: eess.SP

TL;DR: EEG-FM-Bench是首个用于EEG基础模型标准化评估的综合基准，包含多样下游任务、标准化处理流程和开源框架，旨在解决当前EEG基础模型缺乏统一评估标准的问题。


<details>
  <summary>Details</summary>
Motivation: EEG基础模型的快速发展缺乏标准化评估基准，导致模型比较困难，阻碍了系统性科学进展，需要建立统一的评估平台。

Method: 构建包含多样化下游任务的数据集套件，实施标准化处理和评估协议，在统一开源框架中评估现有最先进的基础模型，并进行定性分析。

Result: 实验发现细粒度时空特征交互、多任务统一训练和神经心理学先验知识有助于提升模型性能和泛化能力。

Conclusion: EEG-FM-Bench为公平比较和可重复研究提供了统一平台，将推动更鲁棒和可泛化的EEG基础模型的发展。

Abstract: Electroencephalography (EEG) foundation models are poised to significantly
advance brain signal analysis by learning robust representations from
large-scale, unlabeled datasets. However, their rapid proliferation has
outpaced the development of standardized evaluation benchmarks, which
complicates direct model comparisons and hinders systematic scientific
progress. This fragmentation fosters scientific inefficiency and obscures
genuine architectural advancements. To address this critical gap, we introduce
EEG-FM-Bench, the first comprehensive benchmark for the systematic and
standardized evaluation of EEG foundation models (EEG-FMs). Our contributions
are threefold: (1) we curate a diverse suite of downstream tasks and datasets
from canonical EEG paradigms, implementing standardized processing and
evaluation protocols within a unified open-source framework; (2) we benchmark
prominent state-of-the-art foundation models to establish comprehensive
baseline results for a clear comparison of the current landscape; (3) we
perform qualitative analyses of the learned representations to provide insights
into model behavior and inform future architectural design. Through extensive
experiments, we find that fine-grained spatio-temporal feature interaction,
multitask unified training and neuropsychological priors would contribute to
enhancing model performance and generalization capabilities. By offering a
unified platform for fair comparison and reproducible research, EEG-FM-Bench
seeks to catalyze progress and guide the community toward the development of
more robust and generalizable EEG-FMs. Code is released at
https://github.com/xw1216/EEG-FM-Bench.

</details>


### [14] [Cross-Domain Lifelong Reinforcement Learning for Wireless Sensor Networks](https://arxiv.org/abs/2508.17852)
*Hossein Mohammadi Firouzjaei,Rafaela Scaciota,Sumudu Samarakoon,Beatriz Lorenzo*

Main category: eess.SP

TL;DR: 提出了跨域终身强化学习框架CD-L2RL，用于动态环境下能量收集无线传感器网络的能效设计，相比传统方法显著提升适应速度和能量收集效率


<details>
  <summary>Details</summary>
Motivation: 6G系统中能量收集无线传感器网络面临动态环境挑战，传统方法假设环境相对稳定，无法有效处理EH条件、网络规模和流量速率随时间变化的问题

Method: 提出跨域终身强化学习(CD-L2RL)框架，利用先验经验加速跨任务和跨领域的适应，通过重用过去任务和领域的知识实现快速策略适应

Result: 在多样化条件下的仿真验证显示，该方法比标准强化学习适应速度快35%，比基于Lyapunov的优化快70%，同时提高了总收集能量

Conclusion: CD-L2RL在动态6G无线传感器网络中具有强大部署潜力，能够确保连续运行和可持续能源使用

Abstract: Wireless sensor networks (WSNs) with energy harvesting (EH) are expected to
play a vital role in intelligent 6G systems, especially in industrial sensing
and control, where continuous operation and sustainable energy use are
critical. Given limited energy resources, WSNs must operate efficiently to
ensure long-term performance. Their deployment, however, is challenged by
dynamic environments where EH conditions, network scale, and traffic rates
change over time. In this work, we address system dynamics that yield different
learning tasks, where decision variables remain fixed but strategies vary, as
well as learning domains, where both decision space and strategies evolve. To
handle such scenarios, we propose a cross-domain lifelong reinforcement
learning (CD-L2RL) framework for energy-efficient WSN design. Our CD-L2RL
algorithm leverages prior experience to accelerate adaptation across tasks and
domains. Unlike conventional approaches based on Markov decision processes or
Lyapunov optimization, which assume relatively stable environments, our
solution achieves rapid policy adaptation by reusing knowledge from past tasks
and domains to ensure continuous operations. We validate the approach through
extensive simulations under diverse conditions. Results show that our method
improves adaptation speed by up to 35% over standard reinforcement learning and
up to 70% over Lyapunov-based optimization, while also increasing total
harvested energy. These findings highlight the strong potential of CD-L2RL for
deployment in dynamic 6G WSNs.

</details>


### [15] [Compressed Learning for Nanosurface Deficiency Recognition Using Angle-resolved Scatterometry Data](https://arxiv.org/abs/2508.17873)
*Mehdi Abdollahpour,Carsten Bockelmann,Tajim Md Hasibur Rahman,Armin Dekorsy,Andreas Fischer*

Main category: eess.SP

TL;DR: 通过缩减采样技术大幅减少角分辨散射测量的数据量，仅采样1%数据即可达到86%的缺陷检测准确率


<details>
  <summary>Details</summary>
Motivation: 角分辨散射测量法虽然适合生产线在线检测，但数据采集时间过长，需要解决数据采集效率问题

Method: 提出基于粗粒度群优化算法的压缩学习框架，为散射图样式采用专门的采样方案，识别最优采样点

Result: 仅采样1%数据时缺陷检测准确率达86%，采样6%数据时提升到94%，在噪声环境中仍保持高准确率

Conclusion: 该压缩学习框架能够在大幅减少数据采集量的同时，保持高准确的缺陷检测性能，有效识别关键采样区域

Abstract: Nanoscale manufacturing requires high-precision surface inspection to
guarantee the quality of the produced nanostructures. For production
environments, angle-resolved scatterometry offers a non- invasive and in-line
compatible alternative to traditional surface inspection methods, such as
scanning electron microscopy. However, angle-resolved scatterometry currently
suffers from long data acquisition time. Our study addresses the issue of slow
data acquisition by proposing a compressed learning framework for the accurate
recognition of nanosurface deficiencies using angle-resolved scatterometry
data. The framework uses the particle swarm optimization algorithm with a
sampling scheme customized for scattering patterns. This combination allows the
identification of optimal sampling points in scatterometry data that maximize
the detection accuracy of five different levels of deficiency in ZnO
nanosurfaces. The proposed method significantly reduces the amount of sampled
data while maintaining a high accuracy in deficiency detection, even in noisy
environments. Notably, by sampling only 1% of the data, the method achieves an
accuracy of over 86%, which further improves to 94% when the sampling rate is
increased to 6%. These results demonstrate a favorable balance between data
reduction and classification performance. The obtained results also show that
the compressed learning framework effectively identifies critical sampling
areas.

</details>


### [16] [Synchrosqueezed X-Ray Wavelet-Chirplet Transform for Accurate Chirp Rate Estimation and Retrieval of Modes from Multicomponent Signals with Crossover Instantaneous Frequencies](https://arxiv.org/abs/2508.17942)
*Qingtang Jiang,Shuixin Li,Jiecheng Chen,Lin Li*

Main category: eess.SP

TL;DR: 本文提出了基于X光变换的小波鹅率变换(XWCT)，解决了传统鹅率估计不准确的问题，并开发了三阶同步压缩变种以获得更清晰的时间-频率-鹅率表示。


<details>
  <summary>Details</summary>
Motivation: 解决传统鹅率变换和小波-鹅率变换在鹅率方向衰减慢导致的鹅率估计不准问题，需要一种新方法来提高变换在鹅率方向的衰减速度。

Method: 提出X光小波-鹅率变换(XWCT)，并开发了小波-鹅率变换和XWCT的三阶同步压缩变种，以获得更清晰的时间-频率-鹅率表示。

Result: 实验结果显示XWCT在鹅率轴方向实现了显著更快的衰减，三阶同步压缩XWCT能够在不需多次同步压缩操作的情况下实现准确的瞬时频率和鹅率估计以及模态恢复。

Conclusion: XWCT提供了一种有效的方法来提高鹅率估计的准确性，三阶同步压缩技术更进一步改善了时间-频率-鹅率表示的分辨率，为多组分信号分析提供了更好的工具。

Abstract: Recent advances in the chirplet transform and wavelet-chirplet transform
(WCT) have enabled the estimation of instantaneous frequencies (IFs) and
chirprates, as well as mode retrieval from multicomponent signals with
crossover IF curves. However, chirprate estimation via these approaches remains
less accurate than IF estimation, primarily due to the slow decay of the
chirplet transform or WCT along the chirprate direction. To address this, the
synchrosqueezed chirplet transform (SCT) and multiple SCT methods were
proposed, achieving moderate improvements in IF and chirprate estimation
accuracy. Nevertheless, a novel approach is still needed to enhance the
transform's decay along the chirprate direction.
  This paper introduces an X-ray transform-based wavelet-chirprate transform,
termed the X-ray wavelet-chirplet transform (XWCT), which exhibits superior
decay along the chirprate direction compared to the WCT. Furthermore,
third-order synchrosqueezed variants of the WCT and XWCT are developed to yield
sharp time-frequency-chirprate representations of signals. Experimental results
demonstrate that the XWCT achieves significantly faster decay along the
chirprate axis, while the third-order synchrosqueezed XWCT enables accurate IF
and chirprate estimation, as well as mode retrieval, without requiring multiple
synchrosqueezing operations.

</details>


### [17] [A Unified Transformer Architecture for Low-Latency and Scalable Wireless Signal Processing](https://arxiv.org/abs/2508.17960)
*Yuto Kawai,Rajeev Koodli*

Main category: eess.SP

TL;DR: 统一变换器架构用于无线电信号处理，集成频道估计、插值和解映射功能，具有低延迟、可动态适配特性。


<details>
  <summary>Details</summary>
Motivation: 以Transformer架构替代传统模块化的无线电接收器处理流水线，提供更高效、更灵活的数据驱动方案。

Method: 设计单一的注意力驱动架构，通过修改最终投影层来动态适配不同输出格式，支持三个核心应用场景。

Result: 在不同用户数量、调制方案和导频配置下都显示出强大的泛化能力，精度、稳健性和计算效率均超过传统基准方法。

Conclusion: 该方案为下一代无线通信系统提供了可部署的数据驱动方案，为智能软件定义信号处理奠定了基础。

Abstract: We propose a unified Transformer-based architecture for wireless signal
processing tasks, offering a low-latency, task-adaptive alternative to
conventional receiver pipelines. Unlike traditional modular designs, our model
integrates channel estimation, interpolation, and demapping into a single,
compact attention-driven architecture designed for real-time deployment. The
model's structure allows dynamic adaptation to diverse output formats by simply
modifying the final projection layer, enabling consistent reuse across receiver
subsystems. Experimental results demonstrate strong generalization to varying
user counts, modulation schemes, and pilot configurations, while satisfying
latency constraints imposed by practical systems. The architecture is evaluated
across three core use cases: (1) an End-to-End Receiver, which replaces the
entire baseband processing pipeline from pilot symbols to bit-level decisions;
(2) Channel Frequency Interpolation, implemented and tested within a
3GPP-compliant OAI+Aerial system; and (3) Channel Estimation, where the model
infers full-band channel responses from sparse pilot observations. In all
cases, our approach outperforms classical baselines in terms of accuracy,
robustness, and computational efficiency. This work presents a deployable,
data-driven alternative to hand-engineered PHY-layer blocks, and lays the
foundation for intelligent, software-defined signal processing in
next-generation wireless communication systems.

</details>


### [18] [Positioning via Probabilistic Graphical Models in RIS-Aided Systems with Channel Estimation Errors](https://arxiv.org/abs/2508.18009)
*Leonardo Tercas,Markku Juntti*

Main category: eess.SP

TL;DR: 提出基于贝叶斯的6D定位框架，利用RIS增强室内移动站的位置和旋转角度估计，通过概率图模型和NUTS采样器处理信道参数误差


<details>
  <summary>Details</summary>
Motivation: 解决室内环境中移动站的精确6D定位问题，特别是在存在信道参数估计误差的情况下，利用RIS技术提升定位精度

Method: 使用概率图模型表示随机变量的联合概率分布，采用No-U-Turn Sampler (NUTS)基于估计的信道参数近似后验分布，推导Cramer-Rao下界(CRLB)评估系统性能

Result: 结果显示RIS能够显著提高定位精度，系统在有RIS辅助的情况下表现出更好的位置误差边界(PEB)和旋转误差边界(REB)性能

Conclusion: 提出的贝叶斯6D定位框架有效解决了室内RIS辅助系统中的移动站定位问题，RIS技术对提升定位精度具有重要作用

Abstract: We propose a 6D Bayesian-based localization framework to estimate the
position and rotation angles of a mobile station (MS) within an indoor
reconfigurable intelligent surface (RIS)-aided system. This framework relies on
a probabilistic graphical model to represent the joint probability distribution
of random variables through their conditional dependencies and employs the
No-U-Turn Sampler (NUTS) to approximate the posterior distribution based on the
estimated channel parameters. Our framework estimates both the position and
rotation of the mobile station (MS), in the presence of channel parameter
estimation errors. We derive the Cramer-Rao lower bound (CRLB) for the proposed
scenario and use it to evaluate the system's position error bound (PEB) and
rotation error bound (REB). We compare the system performances with and without
RIS. The results demonstrate that the RIS can enhance positioning accuracy
significantly.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [19] [Localization using Angle-of-Arrival Triangulation](https://arxiv.org/abs/2508.16908)
*Amod K. Agrawal*

Main category: eess.AS

TL;DR: 提出了一种基于语音信号的被动室内定位系统GCC+，使用分布式智能设备通过改进的广义互相关方法和三角定位技术实现人员定位，无需硬件改造或用户配合。


<details>
  <summary>Details</summary>
Motivation: 随着智能助手设备普及，麦克风设备成为智能环境的关键组件，需要一种基础设施轻量、隐私保护的室内定位方案来支持位置感知应用。

Method: 扩展GCC-PHAT方法估计音频信号的到达角度(AoA)，采用特征空间扩展和子样本插值技术提高TDoA估计精度，使用鲁棒三角定位技术推断说话人二维位置。

Result: 在真实家庭环境中测试，中位数AoA估计误差2.2度，中位数定位误差1.25米，证明了音频定位的可行性。

Conclusion: GCC+系统提供了一种实用、无需校准和用户配合的室内定位解决方案，为环境智能应用提供了上下文感知和隐私保护的能力。

Abstract: Indoor localization is a long-standing challenge in mobile computing, with
significant implications for enabling location-aware and intelligent
applications within smart environments such as homes, offices, and retail
spaces. As AI assistants such as Amazon Alexa and Google Nest become
increasingly pervasive, microphone-equipped devices are emerging as key
components of everyday life and home automation. This paper introduces a
passive, infrastructure-light system for localizing human speakers using speech
signals captured by two or more spatially distributed smart devices. The
proposed approach, GCC+, extends the Generalized Cross-Correlation with Phase
Transform (GCC-PHAT) method to estimate the Angle-of-Arrival (AoA) of audio
signals at each device and applies robust triangulation techniques to infer the
speaker's two-dimensional position. To further improve temporal resolution and
localization accuracy, feature-space expansion and subsample interpolation
techniques are employed for precise Time Difference of Arrival (TDoA)
estimation. The system operates without requiring hardware modifications, prior
calibration, explicit user cooperation, or knowledge of the speaker's signal
content, thereby offering a highly practical solution for real-world
deployment. Experimental evaluation in a real-world home environment yields a
median AoA estimation error of 2.2 degrees and a median localization error of
1.25 m, demonstrating the feasibility and effectiveness of audio-based
localization for enabling context-aware, privacy-preserving ambient
intelligence.

</details>


### [20] [HunyuanVideo-Foley: Multimodal Diffusion with Representation Alignment for High-Fidelity Foley Audio Generation](https://arxiv.org/abs/2508.16930)
*Sizhe Shan,Qiulin Li,Yutao Cui,Miles Yang,Yuehai Wang,Qun Yang,Jin Zhou,Zhao Zhong*

Main category: eess.AS

TL;DR: HunyuanVideo-Foley是一个端到端的文本-视频-音频生成框架，通过创新的数据管道、表示对齐策略和多模态扩散变换器，解决了视频到音频生成中的关键挑战，实现了高保真音频与视觉动态的精确同步。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成技术虽然能产生视觉上真实的内容，但缺乏同步音频严重影响了沉浸感。现有方法面临多模态数据稀缺、模态不平衡和音频质量有限等挑战。

Method: 提出了三个核心创新：(1)可扩展的数据管道，通过自动标注构建10万小时的多模态数据集；(2)使用自监督音频特征进行表示对齐，指导潜在扩散训练；(3)新颖的多模态扩散变换器，通过联合注意力和交叉注意力实现双流音频-视频融合和文本语义注入。

Result: 综合评估表明，HunyuanVideo-Foley在音频保真度、视觉-语义对齐、时间对齐和分布匹配等方面达到了新的最先进性能。

Conclusion: 该框架成功解决了视频到音频生成的关键问题，为多模态内容生成提供了有效的解决方案，显著提升了沉浸式体验。

Abstract: Recent advances in video generation produce visually realistic content, yet
the absence of synchronized audio severely compromises immersion. To address
key challenges in video-to-audio generation, including multimodal data
scarcity, modality imbalance and limited audio quality in existing methods, we
propose HunyuanVideo-Foley, an end-to-end text-video-to-audio framework that
synthesizes high-fidelity audio precisely aligned with visual dynamics and
semantic context. Our approach incorporates three core innovations: (1) a
scalable data pipeline curating 100k-hour multimodal datasets through automated
annotation; (2) a representation alignment strategy using self-supervised audio
features to guide latent diffusion training, efficiently improving audio
quality and generation stability; (3) a novel multimodal diffusion transformer
resolving modal competition, containing dual-stream audio-video fusion through
joint attention, and textual semantic injection via cross-attention.
Comprehensive evaluations demonstrate that HunyuanVideo-Foley achieves new
state-of-the-art performance across audio fidelity, visual-semantic alignment,
temporal alignment and distribution matching. The demo page is available at:
https://szczesnys.github.io/hunyuanvideo-foley/.

</details>


### [21] [Pinhole Effect on Linkability and Dispersion in Speaker Anonymization](https://arxiv.org/abs/2508.17134)
*Kong Aik Lee,Zeyan Liu,Liping Chen,Zhenhua Ling*

Main category: eess.AS

TL;DR: 这篇论文研究语音讽名化中不同伪造讽者映射策略的影响，发现使用独特伪造讽者比共享伪造讽者更能提高隐私保护效果。


<details>
  <summary>Details</summary>
Motivation: 语音讽名化需要隐藏讽者特征，但不同的伪造讽者映射策略对隐私保护效果的影响不明，需要系统性研究。

Method: 通过实验评估，比较两种映射策略：共享伪造讽者和独特伪造讽者，从讽者可连接性、讽者空间分散度和原始身份脱离三个维度分析。

Result: 使用独特伪造讽者能增加讽者分散度、降低可连接性，比共享伪造讽者更能提高隐私保护效果。

Conclusion: 通过提出的"针孔效应"概念框架解释了映射策略与讽名化性能的关系，实验验证了独特伪造讽者策略的优势性。

Abstract: Speaker anonymization aims to conceal speaker-specific attributes in speech
signals, making the anonymized speech unlinkable to the original speaker
identity. Recent approaches achieve this by disentangling speech into content
and speaker components, replacing the latter with pseudo speakers. The
anonymized speech can be mapped either to a common pseudo speaker shared across
utterances or to distinct pseudo speakers unique to each utterance. This paper
investigates the impact of these mapping strategies on three key dimensions:
speaker linkability, dispersion in the anonymized speaker space, and
de-identification from the original identity. Our findings show that using
distinct pseudo speakers increases speaker dispersion and reduces linkability
compared to common pseudo-speaker mapping, thereby enhancing privacy
preservation. These observations are interpreted through the proposed pinhole
effect, a conceptual framework introduced to explain the relationship between
mapping strategies and anonymization performance. The hypothesis is validated
through empirical evaluation.

</details>


### [22] [Optimal Pairwise Comparison Procedures for Subjective Evaluation](https://arxiv.org/abs/2508.17840)
*Jack Webb,Lorenzo Picinali*

Main category: eess.AS

TL;DR: 这篇论文比较了成对比较方法在音频质量评估中的效率，提出了一种新的采样方法来以最少的比较次数近似真实质量分数。


<details>
  <summary>Details</summary>
Motivation: 传统的主观听觉测试存在评分标准不一致问题，而完整的成对比较在大数据集下不可行，需要找到更高效的近似方法。

Method: 提出了一种新的采样程序，并在模拟数据集上对比了该方法与现有最优方法的性能。包括与贝叶斯采样等方法的比较。

Result: 贝叶斯采样在现有方法中产生最稳健的分数估计，而新提出的方法在排名收敛速度上最快，且具有相似的分数准确性。

Conclusion: 成对比较方法可以更高效地评估音频质量，新提出的采样策略在排名收敛方面表现优异，为大规模音频质量评估提供了更实用的解决方案。

Abstract: Audio signal processing algorithms are frequently assessed through subjective
listening tests in which participants directly score degraded signals on a
unidimensional numerical scale. However, this approach is susceptible to
inconsistencies in scale calibration between assessors. Pairwise comparisons
between degraded signals offer a more intuitive alternative, eliciting the
relative scores of candidate signals with lower measurement error and reduced
participant fatigue. Yet, due to the quadratic growth of the number of
necessary comparisons, a complete set of pairwise comparisons becomes
unfeasible for large datasets. This paper compares pairwise comparison
procedures to identify the most efficient methods for approximating true
quality scores with minimal comparisons. A novel sampling procedure is proposed
and benchmarked against state-of-the-art methods on simulated datasets.
Bayesian sampling produces the most robust score estimates among previously
established methods, while the proposed procedure consistently converges
fastest on the underlying ranking with comparable score accuracy.

</details>


### [23] [Objective and Subjective Evaluation of Diffusion-Based Speech Enhancement for Dysarthric Speech](https://arxiv.org/abs/2508.17980)
*Dimme de Groot,Tanvina Patel,Devendra Kayande,Odette Scharenborg,Zhengjun Yue*

Main category: eess.AS

TL;DR: 本研究探索使用扩散模型增强构音障碍语音，通过将构音障碍语音分布向典型语音分布靠近，可能改善语音识别性能。评估了两种扩散模型和一种信号处理方法的增强效果。


<details>
  <summary>Details</summary>
Motivation: 构音障碍语音由于高度变异性和可懂度降低，给自动语音识别系统带来重大挑战。研究假设扩散模型能通过语音增强使构音障碍语音分布更接近典型语音分布。

Method: 使用两种扩散模型和一种信号处理方法对两个英语构音障碍语音库进行增强，评估增强前后的可懂度和语音质量，使用Whisper-Turbo进行ASR性能评估，并对增强语音进行微调。

Result: 研究评估了语音增强算法对构音障碍语音的客观和主观质量影响，以及ASR识别性能的变化，并测试了在增强语音上微调模型的效果。

Conclusion: 扩散模型在构音障碍语音增强方面显示出潜力，可能通过改善语音分布特性来提升语音识别性能，需要进一步验证其实际应用效果。

Abstract: Dysarthric speech poses significant challenges for automatic speech
recognition (ASR) systems due to its high variability and reduced
intelligibility. In this work we explore the use of diffusion models for
dysarthric speech enhancement, which is based on the hypothesis that using
diffusion-based speech enhancement moves the distribution of dysarthric speech
closer to that of typical speech, which could potentially improve dysarthric
speech recognition performance. We assess the effect of two diffusion-based and
one signal-processing-based speech enhancement algorithms on intelligibility
and speech quality of two English dysarthric speech corpora. We applied speech
enhancement to both typical and dysarthric speech and evaluate the ASR
performance using Whisper-Turbo, and the subjective and objective speech
quality of the original and enhanced dysarthric speech. We also fine-tuned
Whisper-Turbo on the enhanced speech to assess its impact on recognition
performance.

</details>


### [24] [Unseen Speaker and Language Adaptation for Lightweight Text-To-Speech with Adapters](https://arxiv.org/abs/2508.18006)
*Alessio Falai,Ziyao Zhang,Akos Gangoly*

Main category: eess.AS

TL;DR: 本文研究通过适配器实现跨语言文本转语音合成，比较未见说话人和语言适应任务，验证适配器在保持原始模型能力的同时学习新语言和说话人特征的有效性。


<details>
  <summary>Details</summary>
Motivation: 探索轻量级TTS系统中使用适配器进行跨语言合成的方法，解决目标语言中目标说话人无录音数据时的合成问题。

Method: 使用适配器技术，比较未见说话人和语言适应任务，提出基于二语学习者发音错误检测的客观评价指标来评估生成语音的口音自然度。

Result: 客观评估结果显示适配器能有效学习语言特定和说话人特定信息，避免原始模型信息的灾难性遗忘，同时验证了适配器位置、配置和说话人数量对性能的影响。

Conclusion: 适配器是跨语言TTS合成的有效方法，能够在不损害原有模型能力的前提下适应新语言和说话人，提出的客观评价指标能有效评估生成语音的口音自然度。

Abstract: In this paper we investigate cross-lingual Text-To-Speech (TTS) synthesis
through the lens of adapters, in the context of lightweight TTS systems. In
particular, we compare the tasks of unseen speaker and language adaptation with
the goal of synthesising a target voice in a target language, in which the
target voice has no recordings therein. Results from objective evaluations
demonstrate the effectiveness of adapters in learning language-specific and
speaker-specific information, allowing pre-trained models to learn unseen
speaker identities or languages, while avoiding catastrophic forgetting of the
original model's speaker or language information. Additionally, to measure how
native the generated voices are in terms of accent, we propose and validate an
objective metric inspired by mispronunciation detection techniques in
second-language (L2) learners. The paper also provides insights into the impact
of adapter placement, configuration and the number of speakers used.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [25] [TaDiCodec: Text-aware Diffusion Speech Tokenizer for Speech Language Modeling](https://arxiv.org/abs/2508.16790)
*Yuancheng Wang,Dekun Chen,Xueyao Zhang,Junan Zhang,Jiaqi Li,Zhizheng Wu*

Main category: cs.SD

TL;DR: TaDiCodec是一种新型语音编码器，通过扩散自编码器和文本引导技术，实现了极低帧率(6.25Hz)和比特率(0.0875kbps)，同时保持优异的语音生成质量，采用单阶段端到端训练，无需预训练模型辅助。


<details>
  <summary>Details</summary>
Motivation: 解决当前语音分词器存在的三个主要问题：依赖多层量化结构或高帧率、需要预训练模型进行语义蒸馏、以及复杂的两阶段训练过程。

Method: 采用文本感知扩散变换器语音编解码器，通过扩散自编码器进行端到端的量化和重建优化，在扩散解码器中集成文本引导以提升重建质量和压缩效率。

Result: 在24kHz语音上实现了6.25Hz的极低帧率和0.0875kbps的比特率，在WER、说话人相似度和语音质量等关键指标上表现优异，重建-生成差距显著减小。

Conclusion: TaDiCodec为语音语言模型提供了高效的基础组件，在零样本文本转语音任务中表现出良好的兼容性和有效性，代码和模型将开源。

Abstract: Speech tokenizers serve as foundational components for speech language
models, yet current designs exhibit several limitations, including: 1)
dependence on multi-layer residual vector quantization structures or high frame
rates, 2) reliance on auxiliary pre-trained models for semantic distillation,
and 3) requirements for complex two-stage training processes. In this work, we
introduce the Text-aware Diffusion Transformer Speech Codec (TaDiCodec), a
novel approach designed to overcome these challenges. TaDiCodec employs
end-to-end optimization for quantization and reconstruction through a diffusion
autoencoder, while integrating text guidance into the diffusion decoder to
enhance reconstruction quality and achieve optimal compression. TaDiCodec
achieves an extremely low frame rate of 6.25 Hz and a corresponding bitrate of
0.0875 kbps with a single-layer codebook for 24 kHz speech, while maintaining
superior performance on critical speech generation evaluation metrics such as
Word Error Rate (WER), speaker similarity (SIM), and speech quality (UTMOS).
Notably, TaDiCodec employs a single-stage, end-to-end training paradigm, and
obviating the need for auxiliary pre-trained models. We also validate the
compatibility of TaDiCodec in language model based zero-shot text-to-speech
with both autoregressive modeling and masked generative modeling, demonstrating
its effectiveness and efficiency for speech language modeling, as well as a
significantly small reconstruction-generation gap. We will open source our code
and model checkpoints. Audio samples are are available at
https:/tadicodec.github.io/. We release code and model checkpoints at
https:/github.com/HeCheng0625/Diffusion-Speech-Tokenizer.

</details>


### [26] [WildSpoof Challenge Evaluation Plan](https://arxiv.org/abs/2508.16858)
*Yihan Wu,Jee-weon Jung,Hye-jin Shim,Xin Cheng,Xin Wang*

Main category: cs.SD

TL;DR: WildSpoof挑战赛旨在推动在真实场景下进行语音合成和反欺骗检测的研究，包含TTS语音生成和SASV欺骗检测两个并行赛道，鼓励使用真实世界数据并促进两个研究社区的跨学科合作。


<details>
  <summary>Details</summary>
Motivation: 传统语音处理研究多使用干净受控的数据集，缺乏对真实世界场景的考虑。挑战赛旨在推动使用真实环境下的数据，并促进语音生成和欺骗检测两个社区的协作，以开发更集成、鲁棒和实用的系统。

Method: 挑战赛设计为两个并行独立的任务赛道：(1)文本到语音合成(TTS)用于生成欺骗语音，(2)欺骗鲁棒的自动说话人验证(SASV)用于检测欺骗语音。组织者统一协调数据协议，参与者分别处理两个任务。

Result: 通过设立双赛道挑战赛形式，为研究人员提供了统一的评估框架和真实世界数据集，促进了两个不同研究方向的交叉融合和技术进步。

Conclusion: WildSpoof挑战赛成功建立了连接语音生成和欺骗检测研究的桥梁，推动了真实场景下语音安全技术的发展，为构建更鲁棒的语音处理系统奠定了基础。

Abstract: The WildSpoof Challenge aims to advance the use of in-the-wild data in two
intertwined speech processing tasks. It consists of two parallel tracks: (1)
Text-to-Speech (TTS) synthesis for generating spoofed speech, and (2)
Spoofing-robust Automatic Speaker Verification (SASV) for detecting spoofed
speech. While the organizers coordinate both tracks and define the data
protocols, participants treat them as separate and independent tasks. The
primary objectives of the challenge are: (i) to promote the use of in-the-wild
data for both TTS and SASV, moving beyond conventional clean and controlled
datasets and considering real-world scenarios; and (ii) to encourage
interdisciplinary collaboration between the spoofing generation (TTS) and
spoofing detection (SASV) communities, thereby fostering the development of
more integrated, robust, and realistic systems.

</details>


### [27] [RephraseTTS: Dynamic Length Text based Speech Insertion with Speaker Style Transfer](https://arxiv.org/abs/2508.17031)
*Neeraj Matiyali,Siddharth Srivastava,Gaurav Sharma*

Main category: cs.SD

TL;DR: 文本条件语音插入方法，通过变长度转换器模型在语音中插入新的语音样本，保持说话者特征和语调特性，在LibriTTS数据集上表现超过现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决在语音样本中根据文本详正插入新语音的需求，如更新文本详正后的语音更新问题。

Method: 使用基于转换器的非自回归方法，支持变长度语音插入，根据文本转写和部分输入的节奏动态决定插入长度。

Result: 在LibriTTS数据集上的实验和用户研究表明，该方法在保持说话者声音特征、语调和谱特性方面超过了基于现有适应性文本转语音方法的基线。

Conclusion: 该方法能够高质量地实现文本条件的语音插入，为语音编辑和更新提供了有效的解决方案。

Abstract: We propose a method for the task of text-conditioned speech insertion, i.e.
inserting a speech sample in an input speech sample, conditioned on the
corresponding complete text transcript. An example use case of the task would
be to update the speech audio when corrections are done on the corresponding
text transcript. The proposed method follows a transformer-based
non-autoregressive approach that allows speech insertions of variable lengths,
which are dynamically determined during inference, based on the text transcript
and tempo of the available partial input. It is capable of maintaining the
speaker's voice characteristics, prosody and other spectral properties of the
available speech input. Results from our experiments and user study on LibriTTS
show that our method outperforms baselines based on an existing adaptive text
to speech method. We also provide numerous qualitative results to appreciate
the quality of the output from the proposed method.

</details>


### [28] [Multi-scale Scanning Network for Machine Anomalous Sound Detection](https://arxiv.org/abs/2508.17194)
*Yucong Zhang,Juan Liu,Ming Li*

Main category: cs.SD

TL;DR: 提出多尺度扫描网络(MSN)来捕捉机器声音在不同尺度上的模式，通过可变大小的卷积核扫描音频频谱图，在DCASE数据集上实现最先进的异常声音检测性能。


<details>
  <summary>Details</summary>
Motivation: 机器声音在频率和时间域上存在一致且重复的模式，这些模式在不同机器类型和尺度上差异显著，但现有研究对跨尺度模式变化的探索不足。

Method: 设计多尺度扫描网络(MSN)，使用不同大小的卷积核盒扫描音频频谱图，并集成轻量级卷积网络和权重共享机制，实现高效可扩展的特征表示。

Result: 在DCASE 2020和DCASE 2023 Task 2数据集上的实验评估表明，MSN实现了最先进的性能。

Conclusion: MSN通过多尺度模式捕捉有效推进了异常声音检测系统的发展，证明了其在处理机器声音跨尺度模式变化方面的有效性。

Abstract: Machine sounds exhibit consistent and repetitive patterns in both the
frequency and time domains, which vary significantly across scales for
different machine types. For instance, rotating machines often show periodic
features in short time intervals, while reciprocating machines exhibit broader
patterns spanning the time domain. While prior studies have leveraged these
patterns to improve Anomalous Sound Detection (ASD), the variation of patterns
across scales remains insufficiently explored. To address this gap, we
introduce a Multi-scale Scanning Network (MSN) designed to capture patterns at
multiple scales. MSN employs kernel boxes of varying sizes to scan audio
spectrograms and integrates a lightweight convolutional network with shared
weights for efficient and scalable feature representation. Experimental
evaluations on the DCASE 2020 and DCASE 2023 Task 2 datasets demonstrate that
MSN achieves state-of-the-art performance, highlighting its effectiveness in
advancing ASD systems.

</details>


### [29] [Multi-Metric Preference Alignment for Generative Speech Restoration](https://arxiv.org/abs/2508.17229)
*Junan Zhang,Xueyao Zhang,Jing Yang,Yuancheng Wang,Fan Fan,Zhizheng Wu*

Main category: cs.SD

TL;DR: 该论文提出了一种基于多指标偏好的后训练对齐方法，用于改善生成式语音修复模型与人类感知偏好的一致性，并在多种生成范式上取得了显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的生成式语音修复模型训练目标与人类感知偏好存在偏差，导致音质不佳。虽然后训练对齐在其他生成领域有效，但在语音修复领域尚未充分探索。

Method: 提出了多指标偏好对齐策略，构建了包含8万对偏好样本的GenSR-Pref数据集，使用Direct Preference Optimization (DPO)方法进行后训练对齐。

Result: 在三种不同生成范式（自回归模型、掩码生成模型、流匹配模型）上均获得一致且显著的性能提升，客观和主观评估都显示改进。

Conclusion: 多指标策略优于单指标方法，能有效避免奖励欺骗，对齐后的模型还能作为高质量数据标注器，在数据稀缺场景中为判别式模型提供监督信号。

Abstract: Recent generative models have significantly advanced speech restoration
tasks, yet their training objectives often misalign with human perceptual
preferences, resulting in suboptimal quality. While post-training alignment has
proven effective in other generative domains like text and image generation,
its application to generative speech restoration remains largely
under-explored. This work investigates the challenges of applying
preference-based post-training to this task, focusing on how to define a robust
preference signal and curate high-quality data to avoid reward hacking. To
address these challenges, we propose a multi-metric preference alignment
strategy. We construct a new dataset, GenSR-Pref, comprising 80K preference
pairs, where each chosen sample is unanimously favored by a complementary suite
of metrics covering perceptual quality, signal fidelity, content consistency,
and timbre preservation. This principled approach ensures a holistic preference
signal. Applying Direct Preference Optimization (DPO) with our dataset, we
observe consistent and significant performance gains across three diverse
generative paradigms: autoregressive models (AR), masked generative models
(MGM), and flow-matching models (FM) on various restoration benchmarks, in both
objective and subjective evaluations. Ablation studies confirm the superiority
of our multi-metric strategy over single-metric approaches in mitigating reward
hacking. Furthermore, we demonstrate that our aligned models can serve as
powerful ''data annotators'', generating high-quality pseudo-labels to serve as
a supervision signal for traditional discriminative models in data-scarce
scenarios like singing voice restoration. Demo
Page:https://gensr-pref.github.io

</details>


### [30] [Modality-Specific Speech Enhancement and Noise-Adaptive Fusion for Acoustic and Body-Conduction Microphone Framework](https://arxiv.org/abs/2508.17336)
*Yunsik Kim,Yoonyoung Chung*

Main category: cs.SD

TL;DR: 提出了一种结合体传导麦克风信号(BMS)和声学麦克风信号(AMS)的多模态框架，通过映射网络增强BMS和掩码网络降噪AMS，采用动态融合机制适应不同噪声环境，在TAPS数据集上验证了优于单模态方案的性能。


<details>
  <summary>Details</summary>
Motivation: 体传导麦克风信号(BMS)具有强抗噪性但会丢失高频信息，需要互补模态来补偿高频信息损失，实现同时的噪声抑制和高频重建。

Method: 使用两个专门网络：基于映射的模型增强BMS信号，基于掩码的模型对AMS信号进行降噪处理，通过动态融合机制根据局部噪声条件自适应整合两种模态的优势。

Result: 在TAPS数据集（使用DNS-2023噪声片段增强）上的客观语音质量评估表明，该方法在多种噪声环境下均优于单模态解决方案。

Conclusion: 提出的多模态框架成功实现了噪声抑制和高频重建的双重目标，动态融合机制确保了在不同噪声条件下都能充分利用各模态的优势。

Abstract: Body\-conduction microphone signals (BMS) bypass airborne sound, providing
strong noise resistance. However, a complementary modality is required to
compensate for the inherent loss of high\-frequency information. In this study,
we propose a novel multi\-modal framework that combines BMS and acoustic
microphone signals (AMS) to achieve both noise suppression and high\-frequency
reconstruction. Unlike conventional multi\-modal approaches that simply merge
features, our method employs two specialized networks\: a mapping-based model
to enhance BMS and a masking-based model to denoise AMS. These networks are
integrated through a dynamic fusion mechanism that adapts to local noise
conditions, ensuring the optimal use of each modality's strengths. We performed
evaluations on the TAPS dataset, augmented with DNS\-2023 noise clips, using
objective speech quality metrics. The results clearly demonstrate that our
approach outperforms single\-modal solutions in a wide range of noisy
environments.

</details>


### [31] [ClearMask: Noise-Free and Naturalness-Preserving Protection Against Voice Deepfake Attacks](https://arxiv.org/abs/2508.17660)
*Yuanda Wang,Bocheng Chen,Hanqing Guo,Guangjing Wang,Weikang Ding,Qiben Yan*

Main category: cs.SD

TL;DR: ClearMask和LiveMask是两种新型的语音深度伪造防御方法，通过选择性频率过滤、音频风格迁移和优化混响技术来保护语音数据，无需注入噪声即可有效防止语音合成模型的攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的语音深度伪造防御方法通常需要注入噪声，这会降低音频质量且需要预先了解攻击方法，无法有效保护实时音频场景。需要开发一种无噪声的通用防御机制。

Method: ClearMask通过选择性过滤mel-spectrogram中的特定频率来诱导可转移的语音特征损失，应用音频风格迁移欺骗语音解码器，并引入优化混响来干扰语音生成模型。LiveMask则通过通用频率滤波器和混响生成器保护实时流媒体语音。

Result: 实验结果表明，ClearMask和LiveMask能有效防止语音深度伪造攻击欺骗说话人验证模型和人类听众，即使面对未见过的语音合成模型和黑盒API服务。ClearMask还对试图从受保护样本中恢复原始音频的自适应攻击者表现出韧性。

Conclusion: 该研究提出了一种创新的无噪声防御框架，通过频率操作和音频处理技术的组合，为语音深度伪造攻击提供了有效的保护方案，特别适用于实时音频场景。

Abstract: Voice deepfake attacks, which artificially impersonate human speech for
malicious purposes, have emerged as a severe threat. Existing defenses
typically inject noise into human speech to compromise voice encoders in speech
synthesis models. However, these methods degrade audio quality and require
prior knowledge of the attack approaches, limiting their effectiveness in
diverse scenarios. Moreover, real-time audios, such as speech in virtual
meetings and voice messages, are still exposed to voice deepfake threats. To
overcome these limitations, we propose ClearMask, a noise-free defense
mechanism against voice deepfake attacks. Unlike traditional approaches,
ClearMask modifies the audio mel-spectrogram by selectively filtering certain
frequencies, inducing a transferable voice feature loss without injecting
noise. We then apply audio style transfer to further deceive voice decoders
while preserving perceived sound quality. Finally, optimized reverberation is
introduced to disrupt the output of voice generation models without affecting
the naturalness of the speech. Additionally, we develop LiveMask to protect
streaming speech in real-time through a universal frequency filter and
reverberation generator. Our experimental results show that ClearMask and
LiveMask effectively prevent voice deepfake attacks from deceiving speaker
verification models and human listeners, even for unseen voice synthesis models
and black-box API services. Furthermore, ClearMask demonstrates resilience
against adaptive attackers who attempt to recover the original audio signal
from the protected speech samples.

</details>


### [32] [FasterVoiceGrad: Faster One-step Diffusion-Based Voice Conversion with Adversarial Diffusion Conversion Distillation](https://arxiv.org/abs/2508.17868)
*Takuhiro Kaneko,Hirokazu Kameoka,Kou Tanaka,Yuto Kondo*

Main category: cs.SD

TL;DR: FasterVoiceGrad是一种基于扩散模型的单步语音转换方法，通过同时蒸馏扩散模型和内容编码器，在保持高质量的同时显著提升转换速度。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散语音转换模型（如VoiceGrad）虽然质量高但转换速度慢，FastVoiceGrad通过蒸馏改进但仍需要计算密集型的内容编码器。

Method: 使用对抗扩散转换蒸馏（ADCD）同时蒸馏扩散模型和内容编码器，在转换过程中进行蒸馏，结合对抗和分数蒸馏训练。

Result: 在单次语音转换实验中，FasterVoiceGrad在GPU上速度提升6.6-6.9倍，CPU上提升1.8倍，同时保持与FastVoiceGrad相当的转换性能。

Conclusion: FasterVoiceGrad成功解决了扩散语音转换模型的速度瓶颈问题，实现了高质量的单步快速语音转换。

Abstract: A diffusion-based voice conversion (VC) model (e.g., VoiceGrad) can achieve
high speech quality and speaker similarity; however, its conversion process is
slow owing to iterative sampling. FastVoiceGrad overcomes this limitation by
distilling VoiceGrad into a one-step diffusion model. However, it still
requires a computationally intensive content encoder to disentangle the
speaker's identity and content, which slows conversion. Therefore, we propose
FasterVoiceGrad, a novel one-step diffusion-based VC model obtained by
simultaneously distilling a diffusion model and content encoder using
adversarial diffusion conversion distillation (ADCD), where distillation is
performed in the conversion process while leveraging adversarial and score
distillation training. Experimental evaluations of one-shot VC demonstrated
that FasterVoiceGrad achieves competitive VC performance compared to
FastVoiceGrad, with 6.6-6.9 and 1.8 times faster speed on a GPU and CPU,
respectively.

</details>


### [33] [Vocoder-Projected Feature Discriminator](https://arxiv.org/abs/2508.17874)
*Takuhiro Kaneko,Hirokazu Kameoka,Kou Tanaka,Yuto Kondo*

Main category: cs.SD

TL;DR: 该文章提出了一种基于声码器特征的别辨器(VPFD)，通过利用预训练的声码器特征进行对抗训练，在保持语音转换性能的同时大幅减少训练时间和内存消耗。


<details>
  <summary>Details</summary>
Motivation: 解决传统波形判别器在TTS和VC中导致的重大时间和内存开销问题，而声码器特征具有更高效的计算特性。

Method: 设计VPFD判别器，利用预训练并冻结的声码器特征提取器，仅需单次上量化步骤，就可以进行对抗性训练。

Result: 在温度基语音转换实验中，VPFD达到了与波形判别器相当的性能，同时训练时间减少9.6倍，内存消耗减少11.4倍。

Conclusion: VPFD方法通过利用声码器特征进行对抗训练，在保持高质量语音生成的前提下，显著提高了训练效率。

Abstract: In text-to-speech (TTS) and voice conversion (VC), acoustic features, such as
mel spectrograms, are typically used as synthesis or conversion targets owing
to their compactness and ease of learning. However, because the ultimate goal
is to generate high-quality waveforms, employing a vocoder to convert these
features into waveforms and applying adversarial training in the time domain is
reasonable. Nevertheless, upsampling the waveform introduces significant time
and memory overheads. To address this issue, we propose a vocoder-projected
feature discriminator (VPFD), which uses vocoder features for adversarial
training. Experiments on diffusion-based VC distillation demonstrated that a
pretrained and frozen vocoder feature extractor with a single upsampling step
is necessary and sufficient to achieve a VC performance comparable to that of
waveform discriminators while reducing the training time and memory consumption
by 9.6 and 11.4 times, respectively.

</details>


### [34] [Enhancing Speech Emotion Recognition with Multi-Task Learning and Dynamic Feature Fusion](https://arxiv.org/abs/2508.17878)
*Honghong Wang,Jing Deng,Fanqin Meng,Rong Zheng*

Main category: cs.SD

TL;DR: 基于多任务学习的自监督导语音情感识别方法，通过共注意力模块和新捐失函数显著提升了情感识别性能


<details>
  <summary>Details</summary>
Motivation: 解决语音情感识别中的类不平衡和语义混淆问题，通过多任务学习提升自监督导模型的表现

Method: 使用多任务学习框架同时处理情感识别、性别识别、语者验证和语音识别四个任务，提出共注意力模块动态抓取任务间交互，并设计SWFC捐失函数处理类不平衡

Result: 在语音情感识别挑战赛的分类情感识别任务中展示了显著的性能提升

Conclusion: 多任务学习结合共注意力模块和适应性捐失函数能够有效提升语音情感识别的性能

Abstract: This study investigates fine-tuning self-supervised learn ing (SSL) models
using multi-task learning (MTL) to enhance
  speech emotion recognition (SER). The framework simultane ously handles four
related tasks: emotion recognition, gender
  recognition, speaker verification, and automatic speech recog nition. An
innovative co-attention module is introduced to dy namically capture the
interactions between features from the
  primary emotion classification task and auxiliary tasks, en abling
context-aware fusion. Moreover, We introduce the Sam ple Weighted Focal
Contrastive (SWFC) loss function to ad dress class imbalance and semantic
confusion by adjusting sam ple weights for difficult and minority samples. The
method is
  validated on the Categorical Emotion Recognition task of the
  Speech Emotion Recognition in Naturalistic Conditions Chal lenge, showing
significant performance improvements.

</details>


### [35] [Dynamic Fusion Multimodal Network for SpeechWellness Detection](https://arxiv.org/abs/2508.18057)
*Wenqiang Sun,Han Yin,Jisheng Bai,Jianfeng Chen*

Main category: cs.SD

TL;DR: 提出了一种轻量级多分支多模态系统，通过动态融合机制整合语音和文本信息，用于自杀风险检测，在减少78%参数的同时提升5%准确率


<details>
  <summary>Details</summary>
Motivation: 青少年自杀是主要死因之一，以往研究多单独使用文本或声学信息，多模态信号整合能更全面理解个体心理状态

Method: 采用轻量级多分支结构，结合时域和时频域声学特征以及语义表征，引入动态融合块自适应整合不同模态信息，使用可学习权重调整各模态贡献度

Result: 相比基线模型，参数量减少78%，准确率提升5%，表现出更优性能

Conclusion: 动态融合多模态信息的方法在自杀风险检测任务中有效，轻量化设计在保持性能的同时显著提升了计算效率

Abstract: Suicide is one of the leading causes of death among adolescents. Previous
suicide risk prediction studies have primarily focused on either textual or
acoustic information in isolation, the integration of multimodal signals, such
as speech and text, offers a more comprehensive understanding of an
individual's mental state. Motivated by this, and in the context of the 1st
SpeechWellness detection challenge, we explore a lightweight multi-branch
multimodal system based on a dynamic fusion mechanism for speechwellness
detection. To address the limitation of prior approaches that rely on
time-domain waveforms for acoustic analysis, our system incorporates both
time-domain and time-frequency (TF) domain acoustic features, as well as
semantic representations. In addition, we introduce a dynamic fusion block to
adaptively integrate information from different modalities. Specifically, it
applies learnable weights to each modality during the fusion process, enabling
the model to adjust the contribution of each modality. To enhance computational
efficiency, we design a lightweight structure by simplifying the original
baseline model. Experimental results demonstrate that the proposed system
exhibits superior performance compared to the challenge baseline, achieving a
78% reduction in model parameters and a 5% improvement in accuracy.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 9]
- [eess.AS](#eess.AS) [Total: 8]
- [cs.SD](#cs.SD) [Total: 4]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [A Synoptic Review of High-Frequency Oscillations as a Biomarker in Neurodegenerative Disease](https://arxiv.org/abs/2508.18712)
*Samin Yaser,Mahad Ali,Laura J. Brattain,Yang Jiang,VP Nguyen,Jing Xiang*

Main category: eess.SP

TL;DR: 这篇综述性评估了公开电脑电图（EEG）数据集在高频振荡（HFOs）研究中的适用性，特别关注阶死病变性疾病如阿尔茫海默病。结果显示数据集存在显著的方法异质性，为跨病毒标记物研究提供了指南。


<details>
  <summary>Details</summary>
Motivation: 高频振荡（HFOs）作为疑疑病组织的特异性标记物，最近证据显示其在阿尔茫海默病中也存在，可能成为早期诊断和病情跟踪的无创伤工具。需要系统评估现有公开EEG数据集的适用性。

Method: 进行了1,222篇文献的文献计量分析，系统评估和比较主要公开数据集的参与者群体、数据采集参数和可访问性，特别关注其在HFO分析中的技术适用性。

Result: 研究发现HFO领域研究喜好明显增长，特别是近十年来。数据集存在显著的方法异质性（如采样频率和记录范式），这给跨研究验证带来挑战，但也为稳健性测试提供了机会。

Conclusion: 该综述通过整合分散信息、清晰术语和提供详细方法论框构，为研究人员利用公开数据推进HFOs作为阿尔茫海默病及相关病疾跨病毒标记物的研究提供了指南。

Abstract: High Frequency Oscillations (HFOs), rapid bursts of brain activity above 80
Hz, have emerged as a highly specific biomarker for epileptogenic tissue.
Recent evidence suggests that HFOs are also present in Alzheimer's Disease
(AD), reflecting underlying network hyperexcitability and offering a promising,
noninvasive tool for early diagnosis and disease tracking. This synoptic review
provides a comprehensive analysis of publicly available electroencephalography
(EEG) datasets relevant to HFO research in neurodegenerative disorders. We
conducted a bibliometric analysis of 1,222 articles, revealing a significant
and growing research interest in HFOs, particularly within the last ten years.
We then systematically profile and compare key public datasets, evaluating
their participant cohorts, data acquisition parameters, and accessibility, with
a specific focus on their technical suitability for HFO analysis. Our
comparative synthesis highlights critical methodological heterogeneity across
datasets, particularly in sampling frequency and recording paradigms, which
poses challenges for cross-study validation, but also offers opportunities for
robustness testing. By consolidating disparate information, clarifying
nomenclature, and providing a detailed methodological framework, this review
serves as a guide for researchers aiming to leverage public data to advance the
role of HFOs as a cross-disease biomarker for AD and related conditions.

</details>


### [2] [SkyTrust: Blockchain-Enhanced UAV Security for NTNs with Dynamic Trust and Energy-Aware Consensus](https://arxiv.org/abs/2508.18735)
*Afan Ali,Irfanullah Khan*

Main category: eess.SP

TL;DR: 提出DTSAM-EAC机制，结合区块链和联邦学习，通过动态信任评分和能量感知共识来增强无人机非地面网络的安全性


<details>
  <summary>Details</summary>
Motivation: 无人机非地面网络因其分布式和动态特性极易受到安全攻击，特别是恶意节点的威胁，需要一种自适应安全机制

Method: 集成Hyperledger Fabric区块链和联邦学习，采用动态信任评分调整机制（结合历史信任、当前行为和能量贡献），以及能量感知共识算法

Result: 实现了94%的信任评分预测准确率和96%的恶意无人机检测率，在隐私保护、能效和可靠性方面优于集中式和静态基准方案

Conclusion: 该框架符合6G分布式智能和可持续性要求，是保障非地面网络安全的能效高、可扩展的解决方案

Abstract: Non-Terrestrial Networks (NTNs) based on Unmanned Aerial Vehicles (UAVs) as
base stations are extremely susceptible to security attacks due to their
distributed and dynamic nature, which makes them vulnerable to rogue nodes. In
this paper, a new Dynamic Trust Score Adjustment Mechanism with Energy-Aware
Consensus (DTSAM-EAC) is proposed to enhance security in UAV-based NTNs. The
proposed framework integrates a permissioned Hyperledger Fabric blockchain with
Federated Learning (FL) to support privacy-preserving trust evaluation. Trust
ratings are updated continuously through weighted aggregation of past trust,
present behavior, and energy contribution, thus making the system adaptive to
changing network conditions. An energy-aware consensus mechanism prioritizes
UAVs with greater available energy for block validation, ensuring efficient use
of resources under resource-constrained environments. FL aggregation with
trust-weighting further increases the resilience of the global trust model.
Simulation results verify the designed framework achieves 94\% trust score
prediction accuracy and 96\% rogue UAV detection rate while outperforming
centralized and static baselines of trust-based solutions on privacy, energy
efficiency, and reliability. It complies with 6G requirements in terms of
distributed intelligence and sustainability and is an energy-efficient and
scalable solution to secure NTNs.

</details>


### [3] [Near-Field Challenges in Ultra-Wideband ISAC: Beamforming Strategies and System Insights](https://arxiv.org/abs/2508.18810)
*Yonghwi Kim,Sang-Hyun Park,Siyun Yang,Kai-Kit Wong,Linglong Dai,Chan-Byoung Chae*

Main category: eess.SP

TL;DR: 本文针对6G网络中集成感知与通信系统的近场超宽带挑战，提出了实用的波束赋形策略，通过码本设计缓解波束倾斜问题，在保持通信吞吐量的同时提升感知性能。


<details>
  <summary>Details</summary>
Motivation: 6G无线网络将集成感知与通信置于核心地位，但大规模天线阵列和超宽带带来的近场传播效应和波束倾斜问题对传统远场设计构成根本性挑战，而真时延单元成本高且硬件复杂，限制了可扩展性。

Method: 探索模拟和数字域的码本设计，缓解波束倾斜，确保可靠用户覆盖并提升感知精度；通过大规模系统级仿真和基于3D地图的评估进行验证。

Result: 精心设计的波束赋形能够在严重近场条件下平衡通信吞吐量与感知性能，实现可靠覆盖和高效资源利用。

Conclusion: 指出了硬件、算法和系统集成方面的开放挑战，为6G就绪的ISAC网络部署指明了研究方向。

Abstract: The shift toward sixth-generation (6G) wireless networks places integrated
sensing and communications (ISAC) at the core of future applications such as
autonomous driving, extended reality, and smart manufacturing. However, the
combination of large antenna arrays and ultra-wide bandwidths brings near-field
propagation effects and beam squint to the forefront, fundamentally challenging
traditional far-field designs. True time delay units (TTDs) offer a potential
solution, but their cost and hardware complexity limit scalability. In this
article, we present practical beamforming strategies for near-field
ultra-wideband ISAC systems. We explore codebook designs across analog and
digital domains that mitigate beam squint, ensure reliable user coverage, and
enhance sensing accuracy. We further validate these approaches through
large-scale system-level simulations, including 3D map-based evaluations that
reflect real-world urban environments. Our results demonstrate how carefully
designed beamforming can balance communication throughput with sensing
performance, achieving reliable coverage and efficient resource use even under
severe near-field conditions. We conclude by highlighting open challenges in
hardware, algorithms, and system integration, pointing toward research
directions that will shape the deployment of 6G-ready ISAC networks.

</details>


### [4] [DIFNet: Decentralized Information Filtering Fusion Neural Network with Unknown Correlation in Sensor Measurement Noises](https://arxiv.org/abs/2508.18854)
*Ruifeng Dong,Ming Wang,Ning Liu,Tong Guo,Jiayi Kang,Xiaojing Shen,Yao Mao*

Main category: eess.SP

TL;DR: 提出DIFNet数据驱动方法，通过神经网络学习测量噪声中的未知相关性，提升去中心化传感器网络的融合性能


<details>
  <summary>Details</summary>
Motivation: 去中心化传感器网络在状态估计中具有鲁棒性和可扩展性优势，但未知噪声相关性会降低融合精度，需要解决这一问题

Method: 使用神经网络学习离散时间非线性状态空间模型中测量噪声的未知相关性，开发DIFNet方法

Result: 数值模拟显示DIFNet相比传统滤波方法具有更优的融合性能，在时变噪声等复杂场景下表现稳健

Conclusion: DIFNet能有效学习未知噪声相关性，提升去中心化传感器网络的估计精度和鲁棒性

Abstract: In recent years, decentralized sensor networks have garnered significant
attention in the field of state estimation owing to enhanced robustness,
scalability, and fault tolerance. Optimal fusion performance can be achieved
under fully connected communication and known noise correlation structures. To
mitigate communication overhead, the global state estimation problem is
decomposed into local subproblems through structured observation model. This
ensures that even when the communication network is not fully connected, each
sensor can achieve locally optimal estimates of its observable state
components. To address the degradation of fusion accuracy induced by unknown
correlations in measurement noise, this paper proposes a data-driven method,
termed Decentralized Information Filter Neural Network (DIFNet), to learn
unknown noise correlations in data for discrete-time nonlinear state space
models with cross-correlated measurement noises. Numerical simulations
demonstrate that DIFNet achieves superior fusion performance compared to
conventional filtering methods and exhibits robust characteristics in more
complex scenarios, such as the presence of time-varying noise. The source code
used in our numerical experiment can be found online at
https://wisdom-estimation.github.io/DIFNet_Demonstrate/.

</details>


### [5] [Beyond-Diagonal RIS: Adversarial Channels and Optimality of Low-Complexity Architectures](https://arxiv.org/abs/2508.19000)
*Atso Iivanainen,Robin Rajamäki,Visa Koivunen*

Main category: eess.SP

TL;DR: 本文分析了两种低复杂度BD-RIS架构（组连接和树连接）在最坏情况下的性能表现，发现了对抗性信道会导致显著的性能损失，并揭示了两种架构之间的新联系。


<details>
  <summary>Details</summary>
Motivation: 现有BD-RIS研究主要关注平均性能和架构复杂度的权衡，但忽略了最坏情况性能分析，特别是在对抗性信道条件下的鲁棒性问题。

Method: 通过理论分析推导出针对组连接和树连接BD-RIS架构的对抗性信道集合，并进行数值验证来评估性能损失。

Result: 研究发现对抗性信道会导致显著的接收信号功率性能损失，并揭示了两种低复杂度BD-RIS架构之间的新联系。

Conclusion: 该研究为设计对对抗性传播条件和恶意攻击具有鲁棒性的高效BD-RIS架构奠定了基础。

Abstract: Beyond-diagonal reconfigurable intelligent surfaces (BD-RISs) have recently
gained attention as an enhancement to conventional RISs. BD-RISs allow
optimizing not only the phase, but also the amplitude responses of their
discrete surface elements by introducing adjustable inter-element couplings.
Various BD-RIS architectures have been proposed to optimally trade off between
average performance and complexity of the architecture. However, little
attention has been paid to worst-case performance. This paper characterizes
novel sets of adversarial channels for which certain low-complexity BD-RIS
architectures have suboptimal performance in terms of received signal power at
an intended communications user. Specifically, we consider two recent BD-RIS
models: the so-called group-connected and tree-connected architecture. The
derived adversarial channel sets reveal new surprising connections between the
two architectures. We validate our analytical results numerically,
demonstrating that adversarial channels can cause a significant performance
loss. Our results pave the way towards efficient BD-RIS designs that are robust
to adversarial propagation conditions and malicious attacks.

</details>


### [6] [mmKey: Channel-Aware Beam Shaping for Reliable Key Generation in mmWave Wireless Networks](https://arxiv.org/abs/2508.19010)
*Poorya Mollahosseini,Yasaman Ghasempour*

Main category: eess.SP

TL;DR: mmKey是一种新颖的毫米波物理层密钥生成框架，利用多天线注入随机性，通过遗传算法优化波束成形，在安全性和鲁棒性之间取得平衡


<details>
  <summary>Details</summary>
Motivation: 毫米波频段的物理层密钥生成面临信道稀疏性、高相位噪声和高路径损耗等挑战，这些因素削弱了密钥生成所需的随机性和互易性

Method: 利用毫米波节点的多天线特性向准静态无线信道注入随机性，采用遗传算法逐步演化初始权重向量种群，抑制LOS分量并考虑信道稀疏性和信噪比条件

Result: mmKey相比随机波束成形平均提升39.4%的安全间隙，相比零陷波束成形提升34.0%，优于传统方案

Conclusion: mmKey框架成功解决了毫米波环境下物理层密钥生成的挑战，在保持安全性的同时实现了鲁棒性，为下一代无线网络安全提供了有效解决方案

Abstract: Physical-layer key generation (PLKG) has emerged as a promising technique to
secure next-generation wireless networks by exploiting the inherent properties
of the wireless channel. However, PLKG faces fundamental challenges in the
millimeter wave (mmWave) regime due to channel sparsity, higher phase noise,
and higher path loss, which undermine both the randomness and reciprocity
required for secure key generation. In this paper, we present mmKey, a novel
PLKG framework that capitalizes on the availability of multiple antennas at
mmWave wireless nodes to inject randomness into an otherwise quasi-static
wireless channel. Different from prior works that sacrifice either the secrecy
of the key generation or the robustness, mmKey balances these two requirements.
In particular, mmKey leverages a genetic algorithm to gradually evolve the
initial weight vector population toward configurations that suppress the LOS
component while taking into account the channel conditions, specifically, the
sparsity and the signal-to-noise ratio (SNR). Extensive simulations show that
mmKey improves the secrecy gap by an average of 39.4% over random beamforming
and 34.0% over null beamforming, outperforming conventional schemes.

</details>


### [7] [Fast Vortex Beam Alignment for OAM Mode Multiplexing in LOS MIMO Networks](https://arxiv.org/abs/2508.19034)
*Poorya Mollahosseini,Yasaman Ghasempour*

Main category: eess.SP

TL;DR: OrthoVortex是一个基于轨道角动量(OAM)的通信系统对准框架，通过估计失准角度并应用相位校正来恢复模态正交性，提高链路容量和信号干扰比。


<details>
  <summary>Details</summary>
Motivation: OAM通信系统在视距场景中提供高容量复用，但对节点失准敏感，会破坏模态正交性并阻碍数据复用增益。现有方法要么依赖不切实际的完全数字阵列，要么需要耗时的波束扫描。

Method: 提出OrthoVortex框架，利用交叉模态相位作为独特特征来识别失准角度。这是一种少样本对准技术，基于OAM传播物理实现角度估计和相位校正。

Result: 在120 GHz使用低成本超表面进行仿真和空中测量，实现快速精确的失准估计（方位角平均绝对误差0.69°，俯仰角2.54°）。可降低模态间干扰，信号干扰比提高12 dB以上，链路容量提升4.5倍以上。

Conclusion: OrthoVortex是首个经过实验验证的OAM波束对准方法，解决了实际部署中的对准挑战，为OAM通信系统的实际应用提供了可行解决方案。

Abstract: Orbital Angular Momentum (OAM)-based communication systems offer
high-capacity multiplexing in line-of-sight (LOS) scenarios; yet, their
performance is sensitive to nodal misalignment, which disrupts modal
orthogonality, hindering the data multiplexing gain. To tackle this challenge,
we present OrthoVortex, a novel framework that estimates the misalignment
angles and applies the appropriate phase correction to restore orthogonality
between modes. Unlike purely theoretical prior efforts that rely on impractical
fully digital arrays or exhaustive beam scans, OrthoVortex introduces and
leverages the cross-modal phase, as a unique signature for identifying the
misalignment angles. OrthoVortex is a few-shot alignment technique, making it
feasible for real-world implementations. Our key contributions include: (i) a
robust angle estimation and phase correction framework based on the physics of
OAM propagation that estimates the misalignment and restores modal
orthogonality, (ii) the first-ever experimental validation of OAM beam
alignment with RF transceivers, and (iii) a comprehensive analysis of practical
constraints, including the impact of antenna count and bandwidth. Simulations
and over-the-air measurements using low-cost, rapidly prototyped metasurfaces
operating at 120 GHz demonstrate that OrthoVortex achieves fast and precise
misalignment estimation (mean absolute error of $0.69^{\circ}$ for azimuth and
$2.54^{\circ}$ for elevation angle). Further, OrthoVortex can mitigate the
inter-modal interference, yielding more than 12 dB increase in
signal-to-interference ratio and more than 4.5-fold improvement in link
capacity.

</details>


### [8] [Space-Time Coded RIS-Assisted Wireless Systems with Practical Reflection Models: Error Rate Analysis and Negative Moment-Based Optimization with Saddle Point Approximation](https://arxiv.org/abs/2508.19129)
*Tayfun Yilmaz,Haci Ilhan,Ibrahim Hokelek*

Main category: eess.SP

TL;DR: 本文提出了一种理论框架，用于分析采用OSTBC的RIS辅助多天线系统的符号错误率(SER)，考虑了实际硬件约束下的幅度依赖和量化相位响应。


<details>
  <summary>Details</summary>
Motivation: 随着RIS辅助通信在具有挑战的环境中提升无线性能的潜力日益受到关注，在实际硬件约束下进行准确的错误分析对未来多天线系统至关重要。

Method: 利用级联通道的Gramian结构，对小规模RIS求解非零特征值的准确矩阵生成函数(MGF)表达式，对大规模RIS部署采用鞋点近似法近似特征值分布。

Result: 推导出统一的SER表达式，适用于任意RIS规模、相位配置以及同构和异构幅度响应，并通过模拟验证了提出表达式的准确性。

Conclusion: 该研究为RIS辅助多天线系统提供了一种统一的理论分析框架，能够在实际硬件约束下进行准确的SER分析，对未来系统设计具有重要意义。

Abstract: RIS-assisted communication has recently attracted significant attention for
enhancing wireless performance in challenging environments, making accurate
error analysis under practical hardware constraints crucial for future
multi-antenna systems. This paper presents a theoretical framework for SER
analysis of RIS-assisted multiple antenna systems employing OSTBC under
practical reflection models with amplitude-dependent and quantized phase
responses. By exploiting the Gramian structure of the cascaded channel f, we
derive exact MGF expressions of the nonzero eigenvalue of f'f for small RIS
sizes. For large-scale RIS deployments, where closed-form analysis becomes
intractable, we employ Saddle Point Approximation to approximate the eigenvalue
distribution. Using these results, we derive unified SER expressions using
exact and SPA-based MGF formulations, applicable to arbitrary RIS sizes, phase
configuration, and both identical and non-identical amplitude responses.
Extensive Monte Carlo simulations confirm the accuracy of the proposed SER
expressions, demonstrating very close agreement for all configurations.

</details>


### [9] [Instantaneous Polarimetry with Zak-OTFS](https://arxiv.org/abs/2508.19185)
*Nishant Mehrotra,Sandesh Rao Mattu,Robert Calderbank*

Main category: eess.SP

TL;DR: 提出了一种基于Zak-OTFS调制的瞬时极化测量方法，通过正交极化同时传输两个互不偏置的载波波形，能够在单帧传输中实现全极化响应估计，计算复杂度低于现有方法。


<details>
  <summary>Details</summary>
Motivation: 极化测量对于提升无线通信和雷达系统性能至关重要，但现有瞬时极化测量方法的计算复杂度较高（时间带宽乘积的二次方），需要更高效的方法。

Method: 使用Zak-OTFS调制，在正交极化上同时传输一个Zak-OTFS载波波形和一个与其互不偏置的扩展载波波形，利用波形的互不偏置特性从单帧接收信号中估计环境的全极化响应。

Result: 数值仿真显示该方法能够实现理想的极化目标检测和参数估计，在性能和计算复杂度方面均优于可比基线方法。

Conclusion: 该方法成功实现了低复杂度的瞬时极化测量，计算复杂度仅为时间带宽乘积的次线性，为无线通信和雷达系统的极化测量提供了高效解决方案。

Abstract: Polarimetry, which is the ability to measure the scattering response of the
environment across orthogonal polarizations, is fundamental to enhancing
wireless communication and radar system performance. In this paper, we utilize
the Zak-OTFS modulation to enable instantaneous polarimetry within a single
transmission frame. We transmit a Zak-OTFS carrier waveform and a spread
carrier waveform mutually unbiased to it simultaneously over orthogonal
polarizations. The mutual unbiasedness of the two waveforms enables the
receiver to estimate the full polarimetric response of the scattering
environment from a single received frame. Unlike existing methods for
instantaneous polarimetry with computational complexity quadratic in the
time-bandwidth product, the proposed method enables instantaneous polarimetry
at complexity that is only sublinear in the time-bandwidth product. Via
numerical simulations, we show ideal polarimetric target detection and
parameter estimation results with the proposed method, with improvements in
performance and computational complexity over comparable baselines.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [10] [Toward Responsible ASR for African American English Speakers: A Scoping Review of Bias and Equity in Speech Technology](https://arxiv.org/abs/2508.18288)
*Jay L. Cunningham,Adinawa Adjagbodjou,Jeffrey Basoah,Jainaba Jawara,Kowe Kadoma,Aaleyah Lewis*

Main category: eess.AS

TL;DR: 本文通过文献综述分析了自动语音识别(ASR)技术对非裔美国英语(AAE)等语言多样化群体的公平性、偏见和公平性问题，发现技术干预虽在增长但缺乏以治理为中心的方法，提出了治理为中心的ASR生命周期框架。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨ASR和相关语音语言技术对AAE说话者及其他语言多样化社区的公平性、偏见和公平性概念化与操作化方式，识别现有研究的不足并提出改进方向。

Method: 采用范围性文献综述方法，分析了44篇来自人机交互、机器学习/自然语言处理和社会语言学领域的同行评审出版物，识别了四个主要研究领域。

Result: 研究发现技术公平性干预措施正在增长，但存在关键差距：缺乏以治理为中心的方法，这些方法应强调社区代理、语言正义和参与式问责。

Conclusion: 提出了以治理为中心的ASR生命周期作为跨学科框架，为研究人员、从业者和政策制定者提供了解决语音AI系统中语言边缘化问题的启示和建议。

Abstract: This scoping literature review examines how fairness, bias, and equity are
conceptualized and operationalized in Automatic Speech Recognition (ASR) and
adjacent speech and language technologies (SLT) for African American English
(AAE) speakers and other linguistically diverse communities. Drawing from 44
peer-reviewed publications across Human-Computer Interaction (HCI), Machine
Learning/Natural Language Processing (ML/NLP), and Sociolinguistics, we
identify four major areas of inquiry: (1) how researchers understand
ASR-related harms; (2) inclusive data practices spanning collection, curation,
annotation, and model training; (3) methodological and theoretical approaches
to linguistic inclusion; and (4) emerging practices and design recommendations
for more equitable systems. While technical fairness interventions are growing,
our review highlights a critical gap in governance-centered approaches that
foreground community agency, linguistic justice, and participatory
accountability. We propose a governance-centered ASR lifecycle as an emergent
interdisciplinary framework for responsible ASR development and offer
implications for researchers, practitioners, and policymakers seeking to
address language marginalization in speech AI systems.

</details>


### [11] [MDD: a Mask Diffusion Detector to Protect Speaker Verification Systems from Adversarial Perturbations](https://arxiv.org/abs/2508.19180)
*Yibo Bai,Sizhou Chen,Michele Panariello,Xiao-Lei Zhang,Massimiliano Todisco,Nicholas Evans*

Main category: eess.AS

TL;DR: 提出了基于文本条件掩码扩散模型的MDD框架，用于检测和净化说话人验证系统中的对抗性扰动，无需对抗样本或大规模预训练，在检测和净化性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 说话人验证系统在安全敏感应用中部署日益增多，但对对抗性扰动高度脆弱，需要有效的检测和净化方法。

Method: 使用文本条件掩码扩散模型，通过对Mel频谱图进行部分掩码和正向扩散过程模拟语音特征退化，然后基于输入文本进行反向重建。

Result: MDD在对抗性检测方面表现强劲，优于现有最先进方法（包括扩散基和神经编解码器基方法），并能有效净化对抗性操纵的语音，使说话人验证性能接近干净条件下的水平。

Conclusion: 基于扩散的掩码策略在构建安全可靠的说话人验证系统方面具有巨大潜力。

Abstract: Speaker verification systems are increasingly deployed in security-sensitive
applications but remain highly vulnerable to adversarial perturbations. In this
work, we propose the Mask Diffusion Detector (MDD), a novel adversarial
detection and purification framework based on a \textit{text-conditioned masked
diffusion model}. During training, MDD applies partial masking to
Mel-spectrograms and progressively adds noise through a forward diffusion
process, simulating the degradation of clean speech features. A reverse process
then reconstructs the clean representation conditioned on the input
transcription. Unlike prior approaches, MDD does not require adversarial
examples or large-scale pretraining. Experimental results show that MDD
achieves strong adversarial detection performance and outperforms prior
state-of-the-art methods, including both diffusion-based and neural codec-based
approaches. Furthermore, MDD effectively purifies adversarially-manipulated
speech, restoring speaker verification performance to levels close to those
observed under clean conditions. These findings demonstrate the potential of
diffusion-based masking strategies for secure and reliable speaker verification
systems.

</details>


### [12] [EAI-Avatar: Emotion-Aware Interactive Talking Head Generation](https://arxiv.org/abs/2508.18337)
*Haijie Yang,Zhenyu Zhang,Hao Tang,Jianjun Qian,Jian Yang*

Main category: eess.AS

TL;DR: 提出EAI-Avatar情感感知对话头像生成框架，通过LLM生成对话内容，结合Transformer头部掩码生成器和交互式对话树结构，实现双向对话中情感自适应的高质量虚拟头像生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多专注于单向肖像动画，少数支持双向对话交互的方法缺乏精确的情感自适应能力，限制了实际应用价值。

Method: 1) 基于Transformer的头部掩码生成器学习潜在掩码空间中的时序一致运动特征；2) 交互式对话树结构表示对话状态转换，通过反向层级遍历提取历史情感线索；3) 利用LLM生成对话内容。

Result: 实验证明该方法在生成时序一致的虚拟头像方面表现优异，能够产生丰富的情感变化并在说话和倾听状态间无缝转换。

Conclusion: EAI-Avatar框架成功解决了双向对话中情感自适应头像生成的挑战，为实际应用提供了有效的解决方案。

Abstract: Generative models have advanced rapidly, enabling impressive talking head
generation that brings AI to life. However, most existing methods focus solely
on one-way portrait animation. Even the few that support bidirectional
conversational interactions lack precise emotion-adaptive capabilities,
significantly limiting their practical applicability. In this paper, we propose
EAI-Avatar, a novel emotion-aware talking head generation framework for dyadic
interactions. Leveraging the dialogue generation capability of large language
models (LLMs, e.g., GPT-4), our method produces temporally consistent virtual
avatars with rich emotional variations that seamlessly transition between
speaking and listening states. Specifically, we design a Transformer-based head
mask generator that learns temporally consistent motion features in a latent
mask space, capable of generating arbitrary-length, temporally consistent mask
sequences to constrain head motions. Furthermore, we introduce an interactive
talking tree structure to represent dialogue state transitions, where each tree
node contains information such as child/parent/sibling nodes and the current
character's emotional state. By performing reverse-level traversal, we extract
rich historical emotional cues from the current node to guide expression
synthesis. Extensive experiments demonstrate the superior performance and
effectiveness of our method.

</details>


### [13] [On the Application of Diffusion Models for Simultaneous Denoising and Dereverberation](https://arxiv.org/abs/2508.18833)
*Adrian Meise,Tobias Cord-Landwehr,Reinhold Haeb-Umbach*

Main category: eess.AS

TL;DR: 扩散模型在语音增强中表现出色，但同时对噪声和混响的处理能力尚未充分研究。本研究比较了级联模型和单一模型在不同失真场景下的表现，发现级联模型需要按主导失真顺序应用，而单一模型的最佳方案是在三种失真数据子集上训练。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在语音去噪和去混响方面已显示出良好效果，但同时对噪声和混响的处理能力在实际应用中最常见却研究不足，需要探索不同方法处理这种复合失真场景。

Method: 研究比较了两种方法：1）级联应用分别针对单一失真训练的模型；2）单一模型，包括仅在噪声混响数据上训练，或在噪声、混响、噪声混响三种数据子集上训练。测试在人工生成和真实录音数据上进行。

Result: 结果显示级联模型只有在按主导失真顺序应用时才能获得满意结果。如果需要一个能处理所有失真场景的单一模型，在三种失真数据子集上训练的模型是最佳折衷方案。

Conclusion: 对于同时处理噪声和混响的语音增强，级联模型需要谨慎选择应用顺序，而单一通用模型的最佳训练策略是使用包含纯净噪声、纯净混响和噪声混响复合数据的多样化训练集。

Abstract: Diffusion models have been shown to achieve natural-sounding enhancement of
speech degraded by noise or reverberation. However, their simultaneous
denoising and dereverberation capability has so far not been studied much,
although this is arguably the most common scenario in a practical application.
In this work, we investigate different approaches to enhance noisy and/or
reverberant speech. We examine the cascaded application of models, each trained
on only one of the distortions, and compare it with a single model, trained
either solely on data that is both noisy and reverberated, or trained on data
comprising subsets of purely noisy, of purely reverberated, and of noisy
reverberant speech. Tests are performed both on artificially generated and real
recordings of noisy and/or reverberant data. The results show that, when using
the cascade of models, satisfactory results are only achieved if they are
applied in the order of the dominating distortion. If only a single model is
desired that can operate on all distortion scenarios, the best compromise
appears to be a model trained on the aforementioned three subsets of degraded
speech data.

</details>


### [14] [A Framework for Robust Speaker Verification in Highly Noisy Environments Leveraging Both Noisy and Enhanced Audio](https://arxiv.org/abs/2508.18913)
*Adam Katav,Yair Moshe,Israel Cohen*

Main category: eess.AS

TL;DR: 这篇论文提出了一种新的神经网络框架，通过合并噪声语音和增强语音的语者嵌入，提高了极端噪声环境下语音验证的稳健性。


<details>
  <summary>Details</summary>
Motivation: 虽然语音增强技术可以提高音频质量，但生成式深度神经网络可能会扭曲语者特征信息，影响验证准确性。需要解决在极端噪声条件下语音验证性能恶化的问题。

Method: 设计了一种轻量级的Siamese网络框架，合并从噪声语音和增强语音中提取的语者嵌入信息。该框架不依赖于具体的语音验证或增强技术，可以直接集成各种先进方案。

Result: 实验结果表明该框架在严重噪声条件下显示出优异的验证性能，能够有效应对增强过程中可能产生的语者特征扭曲问题。

Conclusion: 该研究提供了一种高效的解决方案，通过利用噪声和增强语音的互补信息，显著提升了极端噪声环境下语音验证系统的稳健性和准确性。

Abstract: Recent advancements in speaker verification techniques show promise, but
their performance often deteriorates significantly in challenging acoustic
environments. Although speech enhancement methods can improve perceived audio
quality, they may unintentionally distort speaker-specific information, which
can affect verification accuracy. This problem has become more noticeable with
the increasing use of generative deep neural networks (DNNs) for speech
enhancement. While these networks can produce intelligible speech even in
conditions of very low signal-to-noise ratio (SNR), they may also severely
alter distinctive speaker characteristics. To tackle this issue, we propose a
novel neural network framework that effectively combines speaker embeddings
extracted from both noisy and enhanced speech using a Siamese architecture.
This architecture allows us to leverage complementary information from both
sources, enhancing the robustness of speaker verification under severe noise
conditions. Our framework is lightweight and agnostic to specific speaker
verification and speech enhancement techniques, enabling the use of a wide
range of state-of-the-art solutions without modification. Experimental results
demonstrate the superior performance of our proposed framework.

</details>


### [15] [MOSA: Mixtures of Simple Adapters Outperform Monolithic Approaches in LLM-based Multilingual ASR](https://arxiv.org/abs/2508.18998)
*Junjie Li,Jing Peng,Yangui Fang,Shuai Wang,Kai Yu*

Main category: eess.AS

TL;DR: 提出了MOSA（混合简单适配器）方法，通过混合专家机制结合轻量级适配器来学习共享和语言特定的知识，有效解决了多语言ASR中数据稀缺和跨语言知识共享问题。


<details>
  <summary>Details</summary>
Motivation: 端到端多语言ASR面临多语言数据稀缺的挑战，现有方法主要通过增加数据来提升性能，但缺乏对跨语言知识共享的关注，且单一复杂投影器难以有效捕获共享和语言特定特征。

Method: 采用混合专家机制，结合多个轻量级适配器来分别学习共享知识和语言特定知识，使高资源语言数据能够更好地支持低资源语言。

Result: MOSA-Base相比基线模型平均WER相对降低15.4%，在所有语言上都表现更好，即使仅使用60%参数也能超越基线。MOSA-Large在平均WER和数据处理不平衡鲁棒性方面都优于基线。

Conclusion: 在基于LLM的ASR中，混合简单适配器比单一复杂适配器设计更有效，能够更好地处理个体语言并学习语言特定和共享的语言学知识。

Abstract: End-to-end multilingual ASR aims to transcribe speech from different
languages into corresponding text, but is often limited by scarce multilingual
data. LLM-based ASR aligns speech encoder outputs with LLM input space via a
projector and has achieved notable success. However, prior work mainly improves
performance by increasing data, with little focus on cross-lingual knowledge
sharing. Moreover, a single complex projector struggles to capture both shared
and language-specific features effectively. In this work, we propose MOSA
(Mixture of Simple Adapters), leveraging a Mixture-of-Experts mechanism to
combine lightweight adapters that learn shared and language-specific knowledge.
This enables better utilization of high-resource language data to support
low-resource languages, mitigating data scarcity issues. Experimental results
show that MOSA-Base achieves a 15.4\% relative reduction in average WER
compared to the Baseline-Base and consistently outperforms it across all
languages. Remarkably, MOSA-Base surpasses the Baseline-Base even when trained
with only 60\% of its parameters. Similarly, MOSA-Large outperforms the
Baseline-Large in average WER and demonstrates greater robustness to data
imbalance. Ablation studies further indicate that MOSA is more effective at
handling individual languages and learning both language-specific and shared
linguistic knowledge. These findings support that, in LLM-based ASR, a mixture
of simple adapters is more effective than a single, complex adapter design.

</details>


### [16] [CLEAR: Continuous Latent Autoregressive Modeling for High-quality and Low-latency Speech Synthesis](https://arxiv.org/abs/2508.19098)
*Chun Yat Wu,Jiajun Deng,Guinan Li,Qiuqiang Kong,Simon Lui*

Main category: eess.AS

TL;DR: CLEAR是一种新型零样本文本转语音模型，通过直接建模连续音频表示而非离散token，解决了传统AR模型中的信息压缩损失和延迟问题，实现了高质量低延迟的语音合成。


<details>
  <summary>Details</summary>
Motivation: 传统基于自回归的语言模型在零样本TTS中面临离散音频token化带来的信息损失问题，需要更长的token序列来捕捉相同信息，导致推理延迟增加和建模复杂度提升。

Method: 提出连续潜在自回归模型(CLEAR)，使用增强型变分自编码器将波形映射为紧凑连续潜在表示，采用轻量级MLP整流流头建模连续潜在概率分布，并在单阶段框架中与AR模型联合训练。

Result: CLEAR在LibriSpeech测试集上达到1.88%的词错误率和0.29的实时因子，支持96ms首帧延迟的流式语音合成，在鲁棒性、说话人相似度和自然度方面具有竞争力。

Conclusion: CLEAR通过直接建模连续音频表示，成功解决了传统离散token方法的局限性，实现了高质量、低延迟的零样本TTS合成，为流式语音合成提供了有效解决方案。

Abstract: Autoregressive (AR) language models have emerged as powerful solutions for
zero-shot text-to-speech (TTS) synthesis, capable of generating natural speech
from a few seconds of audio prompts. However, conventional AR-based TTS systems
relying on discrete audio tokens face the challenge of lossy compression during
tokenization, requiring longer discrete token sequences to capture the same
information as continuous ones, which adds inference latency and complicates AR
modeling. To address this challenge, this paper proposes the Continuous Latent
Autoregressive model (CLEAR), a unified zero-shot TTS framework that directly
models continuous audio representations. More specifically, CLEAR introduces an
enhanced variational autoencoder with shortcut connections, which achieves a
high compression ratio to map waveforms into compact continuous latents. A
lightweight MLP-based rectified flow head that operates independently for each
hidden state is presented to model the continuous latent probability
distribution, and trained jointly with the AR model within a single-stage
framework. Experiments show that the proposed zero-shot CLEAR TTS can
synthesize high-quality speech with low latency. Compared to state-of-the-art
(SOTA) TTS models, CLEAR delivers competitive performance in robustness,
speaker similarity and naturalness, while offering a lower real-time factor
(RTF). In particular, CLEAR achieves SOTA results on the LibriSpeech test-clean
dataset, with a word error rate of 1.88\% and an RTF of 0.29. Moreover, CLEAR
facilitates streaming speech synthesis with a first-frame delay of 96ms, while
maintaining high-quality speech synthesis.

</details>


### [17] [Interpolating Speaker Identities in Embedding Space for Data Expansion](https://arxiv.org/abs/2508.19210)
*Tianchi Liu,Ruijie Tao,Qiongqiong Wang,Yidi Jiang,Hardik B. Sailor,Ke Zhang,Jingru Lin,Haizhou Li*

Main category: eess.AS

TL;DR: INSIDE是一种通过插值说话人嵌入来合成新说话人身份的数据扩展方法，可有效提升说话人验证性能


<details>
  <summary>Details</summary>
Motivation: 收集大规模多样化说话人数据成本高、难度大且受隐私限制，需要新的数据扩展方法来提升模型性能

Method: 在预训练的说话人嵌入空间中选择邻近的说话人嵌入对，使用球面线性插值计算中间嵌入，然后通过文本转语音系统生成对应语音波形

Result: 使用INSIDE扩展数据训练的模型相比仅使用真实数据的模型，在说话人验证任务上获得3.06%到5.24%的相对提升，在性别分类任务上获得13.44%的相对提升

Conclusion: INSIDE是一种灵活、可扩展的数据增强方法，可与现有训练流程兼容，有效解决说话人数据稀缺问题

Abstract: The success of deep learning-based speaker verification systems is largely
attributed to access to large-scale and diverse speaker identity data. However,
collecting data from more identities is expensive, challenging, and often
limited by privacy concerns. To address this limitation, we propose INSIDE
(Interpolating Speaker Identities in Embedding Space), a novel data expansion
method that synthesizes new speaker identities by interpolating between
existing speaker embeddings. Specifically, we select pairs of nearby speaker
embeddings from a pretrained speaker embedding space and compute intermediate
embeddings using spherical linear interpolation. These interpolated embeddings
are then fed to a text-to-speech system to generate corresponding speech
waveforms. The resulting data is combined with the original dataset to train
downstream models. Experiments show that models trained with INSIDE-expanded
data outperform those trained only on real data, achieving 3.06\% to 5.24\%
relative improvements. While INSIDE is primarily designed for speaker
verification, we also validate its effectiveness on gender classification,
where it yields a 13.44\% relative improvement. Moreover, INSIDE is compatible
with other augmentation techniques and can serve as a flexible, scalable
addition to existing training pipelines.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [18] [H-PRM: A Pluggable Hotword Pre-Retrieval Module for Various Speech Recognition Systems](https://arxiv.org/abs/2508.18295)
*Huangyu Dai,Lingtao Mao,Ben Chen,Zihan Wang,Zihan Liang,Ying Han,Chenyi Lei,Han Li*

Main category: cs.SD

TL;DR: 一种新的热词定制系统，通过热词预检索模块(H-PRM)提高ASR中大规模热词的识别准确率


<details>
  <summary>Details</summary>
Motivation: 现有ASR模型在处理大规模热词时识别率显著下降，需要提高域特定术语的识别准确性

Method: 使用H-PRM模块，通过测量热词与语音段的音响相似性来识别最相关的热词候选项，支持插入式集成到传统模型和音频大语言模型

Result: H-PRM显著提高了热词后召回率(PRR)，在大规模热词情况下表现超过现有方法

Conclusion: 该系统为ASR热词定制领域展示了新方向，提供了高效的插入式解决方案

Abstract: Hotword customization is crucial in ASR to enhance the accuracy of
domain-specific terms. It has been primarily driven by the advancements in
traditional models and Audio large language models (LLMs). However, existing
models often struggle with large-scale hotwords, as the recognition rate drops
dramatically with the number of hotwords increasing. In this paper, we
introduce a novel hotword customization system that utilizes a hotword
pre-retrieval module (H-PRM) to identify the most relevant hotword candidate by
measuring the acoustic similarity between the hotwords and the speech segment.
This plug-and-play solution can be easily integrated into traditional models
such as SeACo-Paraformer, significantly enhancing hotwords post-recall rate
(PRR). Additionally, we incorporate H-PRM into Audio LLMs through a
prompt-based approach, enabling seamless customization of hotwords. Extensive
testing validates that H-PRM can outperform existing methods, showing a new
direction for hotword customization in ASR.

</details>


### [19] [SwiftF0: Fast and Accurate Monophonic Pitch Detection](https://arxiv.org/abs/2508.18440)
*Lars Nieradzik*

Main category: cs.SD

TL;DR: SwiftF0是一个轻量级神经网络模型，在嘈杂环境下实现实时单音音高估计，性能优于现有方法，计算效率高，适合资源受限设备部署。


<details>
  <summary>Details</summary>
Motivation: 解决在嘈杂环境下资源受限设备上实时单音音高估计的挑战，现有方法在噪声条件下性能下降严重且计算成本高。

Method: 使用多样化语音、音乐和合成数据集进行训练，采用广泛的数据增强技术，并引入SpeechSynth合成语音数据集提供精确的ground-truth音高曲线。

Result: 在10dB SNR下达到91.80%的谐波均值，比CREPE提升12个百分点，仅需95,842参数，CPU运行速度比CREPE快42倍。

Conclusion: SwiftF0在噪声鲁棒性、计算效率和实时部署方面表现出色，为音高估计提供了新的state-of-the-art解决方案，并发布了开源基准测试套件。

Abstract: Accurate and real-time monophonic pitch estimation in noisy conditions,
particularly on resource-constrained devices, remains an open challenge in
audio processing. We present \emph{SwiftF0}, a novel, lightweight neural model
that sets a new state-of-the-art for monophonic pitch estimation. Through
training on diverse speech, music, and synthetic datasets with extensive data
augmentation, SwiftF0 achieves robust generalization across acoustic domains
while maintaining computational efficiency. SwiftF0 achieves a 91.80\% harmonic
mean (HM) at 10 dB SNR, outperforming baselines like CREPE by over 12
percentage points and degrading by only 2.3 points from clean audio. SwiftF0
requires only 95,842 parameters and runs approximately 42x faster than CREPE on
CPU, making it ideal for efficient, real-time deployment. To address the
critical lack of perfectly accurate ground truth pitch in speech corpora (which
typically rely on algorithmic estimators or laryngograph signals), we introduce
\emph{SpeechSynth}. This synthetic speech dataset, generated by a phoneme-level
TTS model, provides exact, on-demand ground-truth pitch curves, enabling more
robust model training and evaluation. Furthermore, we propose a unified metric,
combining six complementary performance measures for comprehensive and reliable
pitch evaluation, and release an open-source pitch benchmark suite. A live demo
of SwiftF0 is available at https://swift-f0.github.io/, the source code at
https://github.com/lars76/swift-f0, and the benchmark framework at
https://github.com/lars76/pitch-benchmark.

</details>


### [20] [Cross-Learning Fine-Tuning Strategy for Dysarthric Speech Recognition Via CDSD database](https://arxiv.org/abs/2508.18732)
*Qing Xiao,Yingshan Peng,PeiPei Zhang*

Main category: cs.SD

TL;DR: 多谎者精细调整比单谎者精细调整更有效，能够提升疾病语音识别的准确性和通用性


<details>
  <summary>Details</summary>
Motivation: 解决疾病语音识别中因病患病患严重程度差异和与正常语音差异导致的挑战，寻找更有效的模型调整策略

Method: 采用多谎者精细调整策略，同时在多个疾病语音谎者数据上进行训练，而非传统的每个病患单独调整

Result: 多谎者精细调整对比单谎者精细调整能够获得较低的词误率（最高降低13.15%），提升了目标谎者的识别准确性

Conclusion: 多谎者精细调整策略通过学习更广泛的病理特征、减轻谎者特定过拟合、降低对单个病患数据的依赖性，显著提升了疾病语音识别的性能

Abstract: Dysarthric speech recognition faces challenges from severity variations and
disparities relative to normal speech. Conventional approaches individually
fine-tune ASR models pre-trained on normal speech per patient to prevent
feature conflicts. Counter-intuitively, experiments reveal that multi-speaker
fine-tuning (simultaneously on multiple dysarthric speakers) improves
recognition of individual speech patterns. This strategy enhances
generalization via broader pathological feature learning, mitigates
speaker-specific overfitting, reduces per-patient data dependence, and improves
target-speaker accuracy - achieving up to 13.15% lower WER versus
single-speaker fine-tuning.

</details>


### [21] [SegReConcat: A Data Augmentation Method for Voice Anonymization Attack](https://arxiv.org/abs/2508.18907)
*Ridwan Arefeen,Xiaoxiao Miao,Rong Tong,Aik Beng Ng,Simon See*

Main category: cs.SD

TL;DR: SegReConcat是一种数据增强方法，通过在单词级别分割匿名化语音并重新排列片段，来增强说话人验证系统的攻击能力，提高去匿名化效果。


<details>
  <summary>Details</summary>
Motivation: 语音匿名化旨在隐藏说话人身份但保留语音效用，但往往仍存在残留的说话人线索，带来隐私风险。需要开发攻击者侧的方法来增强说话人验证系统对这些匿名化语音的识别能力。

Method: 提出SegReConcat方法：1）在单词级别分割匿名化语音；2）使用随机或基于相似性的策略重新排列片段以破坏长期上下文线索；3）将重新排列的片段与原始话语拼接，使攻击者能从多个角度学习源说话人特征。

Result: 在VoicePrivacy Attacker Challenge 2024框架下评估了7个匿名化系统，SegReConcat在5个系统上显著提高了去匿名化性能。

Conclusion: SegReConcat是一种有效的攻击者侧数据增强方法，能够有效破坏语音匿名化系统的保护机制，提高说话人身份识别的成功率。

Abstract: Anonymization of voice seeks to conceal the identity of the speaker while
maintaining the utility of speech data. However, residual speaker cues often
persist, which pose privacy risks. We propose SegReConcat, a data augmentation
method for attacker-side enhancement of automatic speaker verification systems.
SegReConcat segments anonymized speech at the word level, rearranges segments
using random or similarity-based strategies to disrupt long-term contextual
cues, and concatenates them with the original utterance, allowing an attacker
to learn source speaker traits from multiple perspectives. The proposed method
has been evaluated in the VoicePrivacy Attacker Challenge 2024 framework across
seven anonymization systems, SegReConcat improves de-anonymization on five out
of seven systems.

</details>

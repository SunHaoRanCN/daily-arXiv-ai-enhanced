<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 52]
- [eess.AS](#eess.AS) [Total: 16]
- [cs.SD](#cs.SD) [Total: 29]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Exploring the Efficacy of Convolutional Neural Networks in Sleep Apnea Detection from Single Channel EEG](https://arxiv.org/abs/2509.00012)
*Chun Hin Siu,Hossein Miri*

Main category: eess.SP

TL;DR: 使用单通道EEG数据和CNN网络实现睡眠呼吸暂停检测，准确率达85.1%，为家庭自动化诊断提供可行方案


<details>
  <summary>Details</summary>
Motivation: 传统多导睡眠监测(PSG)成本高、操作复杂且影响睡眠质量，需要开发更便捷的家庭自动化检测方法

Method: 采用卷积神经网络(CNN)处理单通道EEG数据，结合IIR巴特沃斯滤波器预处理、数据集构建方法和SMOTETomek处理类别不平衡

Result: 模型准确率达到85.1%，马修斯相关系数(MCC)为0.22，证明了家庭应用的可行性

Conclusion: 该方法成功解决了PSG的局限性，展示了从实验室诊断向家庭自动化解决方案过渡的可行性，能改善患者预后并提高睡眠障碍诊断的可及性

Abstract: Sleep apnea, a prevalent sleep disorder, involves repeated episodes of
breathing interruptions during sleep, leading to various health complications,
including cognitive impairments, high blood pressure, heart disease, stroke,
and even death. One of the main challenges in diagnosing and treating sleep
apnea is identifying individuals at risk. The current gold standard for
diagnosis, Polysomnography (PSG), is costly, labor intensive, and inconvenient,
often resulting in poor quality sleep data. This paper presents a novel
approach to the detection of sleep apnea using a Convolutional Neural Network
(CNN) trained on single channel EEG data. The proposed CNN achieved an accuracy
of 85.1% and a Matthews Correlation Coefficient (MCC) of 0.22, demonstrating a
significant potential for home based applications by addressing the limitations
of PSG in automated sleep apnea detection. Key contributions of this work also
include the development of a comprehensive preprocessing pipeline with an
Infinite Impulse Response (IIR) Butterworth filter, a dataset construction
method providing broader temporal context, and the application of SMOTETomek to
address class imbalance. This research underscores the feasibility of
transitioning from traditional laboratory based diagnostics to more accessible,
automated home based solutions, improving patient outcomes and broadening the
accessibility of sleep disorder diagnostics.

</details>


### [2] [Conditional Generative Adversarial Networks Based Inertial Signal Translation](https://arxiv.org/abs/2509.00016)
*Marcin Kolakowski*

Main category: eess.SP

TL;DR: 使用条件生成对抗网络将手腕传感器惯性信号转换为鞋部传感器信号，实现基于智能手表的日常步态分析


<details>
  <summary>Details</summary>
Motivation: 现有的先进步态分析方法通常需要鞋部安装传感器，限制了日常使用。手腕佩戴的智能手表等设备更便于日常监测，但信号格式不兼容

Method: 采用条件生成对抗网络(Conditional GANs)，包括传统二元交叉熵损失训练的GAN和Wasserstein GAN两种版本，测试了卷积自编码器和卷积U-Net两种生成器架构

Result: 实验结果表明该方法能够准确实现信号转换，使手腕传感器信号可用于高效的日常步态分析

Conclusion: 提出的方法成功解决了手腕与鞋部传感器信号兼容性问题，为基于可穿戴设备的日常步态监测提供了可行方案

Abstract: The paper presents an approach in which inertial signals measured with a
wrist-worn sensor (e.g., a smartwatch) are translated into those that would be
recorded using a shoe-mounted sensor, enabling the use of state-of-the-art gait
analysis methods. In the study, the signals are translated using Conditional
Generative Adversarial Networks (GANs). Two different GAN versions are used for
experimental verification: traditional ones trained using binary cross-entropy
loss and Wasserstein GANs (WGANs). For the generator, two architectures, a
convolutional autoencoder, and a convolutional U-Net, are tested. The
experiment results have shown that the proposed approach allows for an accurate
translation, enabling the use of wrist sensor inertial signals for efficient,
every-day gait analysis.

</details>


### [3] [A Fluid Antenna Enabled Physical Layer Key Generation for Next-G Wireless Networks](https://arxiv.org/abs/2509.00018)
*Jiacheng Guo,Ning Gao,Yiping Zuo,Hao Xu,Shi Jin,Kai Kit Wong*

Main category: eess.SP

TL;DR: 提出了一种基于流体天线的物理层密钥生成系统，通过优化预编码矩阵和天线位置，在恶劣传播环境中显著提升密钥生成率。


<details>
  <summary>Details</summary>
Motivation: 在恶劣传播环境中，无线信道特性变差，传统物理层密钥生成系统的密钥生成率显著下降，需要新的技术来解决这一挑战。

Method: 首先推导流体天线阵列的密钥生成率闭式表达式，然后使用粒子群优化算法联合优化预编码矩阵和天线位置，并开发了交替优化算法来降低计算复杂度。

Result: 仿真结果表明，相比传统固定位置天线阵列和可重构智能表面，流体天线系统在密钥生成率方面表现更优，相比均匀平面天线分别实现了35.42%和67.73%的性能提升。

Conclusion: 流体天线系统通过利用额外的空间自由度，能够有效提升恶劣环境下的物理层密钥生成性能，为无线安全通信提供了新的解决方案。

Abstract: As a promising physical layer security technique, physical layer key
generation (PLKG) enables legitimate users to obtain secret keys from wireless
channel without security infrastructures. However, in harsh propagation
environments, the channel characteristic becomes unsatisfactory, the key
generation rate (KGR) is significantly deteriorated. In this paper, we propose
a novel fluid antenna (FA) enabled PLKG system to address this challenge.
Specifically, we first derive the closed-form expression of the KGR for FA
array, and then jointly optimize the precoding matrix and the antenna positions
via a particle swarm optimization (PSO) algorithm. Next, to further reduce the
computational complexity of the optimization procedure, we develop an
alternating optimization (AO) algorithm, which combines the projected gradient
descent (PGD) and the PSO. Simulation results demonstrate that by exploiting
the additional spatial degree of freedom (DoF), our FA enabled PLKG system is
superior to the benchmarks, such as the conventional fixed-position antenna
(FPA) array and the reconfigurable intelligent surface (RIS). It is worth
highlighting that compared to the conventional uniform planar antenna (UPA),
the FA enabled PLKG achieves a 35.42\% KGR performance improvement under PSO
algorithm and a 67.73\% KGR performance improvement under AO algorithm,
respectively.

</details>


### [4] [A Review of Sensor Insoles](https://arxiv.org/abs/2509.00260)
*Bastian Latsch,Felix Herbst,Mark Suppelt,Julian Seiler,Stephan Schaumann,Sven Suppelt,Alexander A. Altmann,Martin Grimmer,and Mario Kupnik*

Main category: eess.SP

TL;DR: 本文综述了足底压力测量技术（足压测量学）的现状，重点关注传感器技术、数量与布局、参与者群体和参考标准，提出了基于测试设备和仪器化跑步机的金标准，并探讨了鞋垫插入与足底力学的双向相互作用。


<details>
  <summary>Details</summary>
Motivation: 足底压力测量是分析健康人群和患者运动的重要工具，传感器鞋垫作为可穿戴移动解决方案，在糖尿病足监测、康复指导、辅助设备控制和运动表现分析等应用中评估压力分布。

Method: 评估当前最先进技术，涵盖电阻式、电容式、电感式、压电式、摩擦电式和光学传感方法，特别关注具有创新设计的原创工作，并优先选择支持行走实验的研究。

Result: 发现缺乏适当的传感器校准、基于步态的验证和人体研究验证，确定了组织刚度是传感器信号不确定性的关键来源，并提出了传感器尺寸和不显眼鞋垫设计的指南。

Conclusion: 未来方向包括开发多模态传感器以弥补单个模态的局限性，以及捕捉压力分布中剪切分量的多轴传感新兴趋势。

Abstract: Plantar pressure measurement, or pedobarography, is an essential tool for
analyzing human motion in healthy individuals and patients. Across the reviewed
literature, sensor insoles are motivated as wearable, mobile solutions for
assessing pressure distribution in applications including diabetic foot
monitoring, rehabilitation guidance, assistive device control, and sports
performance analysis. This review evaluates the current state of the art with
particular attention to sensor technologies, sensor quantity and placement,
participant cohorts, and reference standards. The focus lies on original works
with innovative designs, preferably supported by ambulation experiments. The
modalities covered include resistive, capacitive, inductive, piezoelectric,
triboelectric, and optical sensing approaches. We identify a lack of proper
sensor calibration, gait-based verification, and human study validation, and
propose a gold standard based on testing machines and instrumented treadmills
to ensure comparability across studies. The bidirectional interaction between
insole insertion and foot-sole mechanics is examined, with tissue stiffness
identified as a key source of uncertainty in sensor signals. Guidelines are
provided for sensor dimensions and unobtrusive insole designs to foster natural
gait. Finally, future directions include the development of multimodal sensors
to compensate for limitations of individual modalities and the emerging trend
of multiaxial sensing for capturing shear components in pressure distributions.

</details>


### [5] [CoMET: A Contrastive-Masked Brain Foundation Model for Universal EEG Representation](https://arxiv.org/abs/2509.00314)
*Ang Li,Zikai Wang,Liuyin Yang,Zhenyu Wang,Tianheng Xu,Honglin Hu,Marc M. Van Hulle*

Main category: eess.SP

TL;DR: CoMET是一个基于掩码自编码器和对比学习的脑电基础模型，通过镜像尺度增强提升全局判别能力，在10个下游数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 传统EEG深度学习模型局限于特定数据集和任务，现有自监督基础模型过度关注局部信号相似性特征而忽略全局判别模式

Method: 采用重新设计分块和嵌入的掩码自编码器作为骨干网络，结合新颖的对比学习框架和镜像尺度增强技术

Result: 在3000多名受试者的100多万个样本上预训练，在10个不同下游数据集上取得SOTA结果

Conclusion: CoMET在提取通用EEG表征方面具有卓越能力，展现出强大的临床潜力

Abstract: Electroencephalography (EEG) is a non-invasive technique for recording brain
activity, widely used in brain-computer interfaces, clinic, and healthcare.
Traditional EEG deep models typically focus on specific dataset and task,
limiting model size and generalization. Recently, self-supervised brain
foundation models have emerged and been applied to various downstream tasks.
Nevertheless, these models still have limitations: current SOTA models
typically rely on masked reconstruction strategy; however, EEG features of
adjacent channels are highly correlated, which causes the pre-training to
overly focus on low-dimensional signal-similarity features in local regions and
neglect the global discriminative patterns vital for downstream tasks. To
address these limitations, we propose a brain foundation model called CoMET.
Specifically, we employ the masked autoencoder with redesigned patching and
embedding for EEG as backbone and devise a novel contrastive learning framework
with mirror-scale augmentation to strengthen the global discrimination ability.
CoMET is pre-trained on mixed EEG datasets over 3000 subjects with over one
million samples. It is evaluated on ten different downstream datasets, and the
SOTA results demonstrate CoMET's superior ability in extracting universal EEG
representations and strong clinical potential.

</details>


### [6] [Gait Analysis using 6DoF Magnetic Tracking](https://arxiv.org/abs/2509.00323)
*R. Abhishek Shankar,Hyungjun Ha,Byunghoo Jung*

Main category: eess.SP

TL;DR: 基于6自由度磁追踪的可穿戴行走分析系统，在人类活动识别任务中达到92%的分类准确率，显著超过传统IMU+磁力计系统


<details>
  <summary>Details</summary>
Motivation: 可穿戴设备虽有便携性优势，但性能不如非可穿戴设备，需要提升可穿戴行走分析的性能

Method: 开发6DoF磁追踪行走分析系统，使用CNN和LSTM深度学习分类器识别四种活动，与IMU+磁力计系统进行性能对比

Result: 磁追踪系统整体分类准确率达92%（IMU系统为86.69%），在区分普通走和负重走路任务上提升约8%

Conclusion: 磁追踪系统可以提供更完整的6DoF跟踪信息，证明了磁追踪技术在行走分析中的可行性和优势

Abstract: Gait analysis using wearable devices has advantages over non-wearable devices
when it comes to portability and accessibility. However, non-wearable devices
have consistently shown superior performance in terms of the gait information
they can provide. This calls for the need to improve the performance of
wearable device based gait analysis. To that end, we developed a 6
Degrees-of-Freedom (6DoF) magnetic tracking based gait analysis system as a
step in this direction. The system is portable, minimally intrusive, wireless
and power efficient. As a proof-of-concept, the system was used for the task of
Human Activity Recognition (HAR) to classify four tasks - walking (W), walking
with weight (WW), jogging (J) and marching on the spot (M). Gait data of 12
participants was collected. The classification performance of two deep learning
(DL) classifiers - Convolutional Neural Networks (CNN) and Long Short Term
Memory (LSTM) - was compared. The performance of the magnetic tracking based
gait analysis system was also compared with an Inertial Measurement Unit (IMU)
+ magnetometer based system. The magnetic tracking based system showed an
overall classification accuracy of 92\% compared to 86.69\% for the IMU +
magnetometer system. Moreover, the magnetic tracking system showed an
improvement of about 8\% in being able to differentiate between W and WW. This
highlights the insufficiency in the information content in the data from IMU +
magnetometer, warranting the need for a complete 6DoF tracking. Our work, thus,
proves the feasibility of using magnetic tracking systems for the purpose of
gait analysis.

</details>


### [7] [AN-Aided Secure Beamforming for ELAA-SWIPT in Mixed Near- and Far-Field](https://arxiv.org/abs/2509.00331)
*Yaqian Yi,Guangchi Zhang,Miao Cui,Changsheng You,Qingqing Wu*

Main category: eess.SP

TL;DR: 本文研究混合近场/远场环境下超大规模天线阵列辅助的SWIPT系统的安全混合波束成形设计，通过联合优化信息传输和人工噪声来最大化加权保密率，同时满足能量收集要求。


<details>
  <summary>Details</summary>
Motivation: 随着6G通信中极大规模天线阵列的应用，系统同时存在近场和远场用户，需要解决在这种混合场域环境下同时进行无线信息和能量传输的安全性问题。

Method: 提出基于连续凸近似的迭代算法，针对Type-I和Type-II两种信息接收器类型分别制定优化问题，联合设计混合波束成形和人工噪声信号。

Result: 仿真结果验证了所提方案的有效性，揭示了混合场域SWIPT系统的安全性能特征，特别是可见区域和角度用户分离对性能的影响。

Conclusion: 该研究为混合近场/远场SWIPT系统的安全传输提供了有效的波束成形设计方案，对6G超大规模天线系统的安全通信具有重要指导意义。

Abstract: This letter investigates secure hybrid beamforming (HB) design for an
extremely large-scale antenna array-aided simultaneous wireless information and
power transfer (SWIPT) system operating in a mixed near-field (NF)/far-field
(FF) environment. A base station (BS) employs HB to transmit information and
artificial noise (AN) signals simultaneously to multiple FF information
receivers (IRs) and NF energy receivers (ERs). The objective is to maximize the
weighted sum secrecy rate for the IRs, considering both Type-I (unable to
cancel AN) and Type-II (capable of canceling AN) IRs, subject to minimum energy
harvesting requirements at the ERs and a BS transmit power constraint. We
formulate optimization problems for both IR types and develop an efficient
iterative algorithm based on successive convex approximation. Simulation
results validate the proposed scheme and provide crucial insights into the
security performance of mixed-field SWIPT systems, highlighting the influence
of visibility regions and angular user separation.

</details>


### [8] [Pilot Allocation and Receiver Design for Cell-Free Massive MIMO ISAC Systems](https://arxiv.org/abs/2509.00478)
*Getuar Rexhepi,Kuranage Roche Rayan Ranasinghe,Kengo Ando,Giuseppe Thadeu Freitas de Abreu,David Gonzalez G*

Main category: eess.SP

TL;DR: 本文提出了一种基于流形优化的导频分配框架和高斯置信传播接收机，用于解决无小区大规模MIMO系统中的导频分配和接收机设计问题，实现了通信性能与最先进算法相当但感知能力更优的效果。


<details>
  <summary>Details</summary>
Motivation: 解决无小区大规模MIMO系统中两个关键挑战：高效的导频分配和实用的接收机设计，以推动集成感知与通信技术的实际部署。

Method: 1) 利用流形优化设计近正交导频序列，在频域施加单模约束；2) 提出基于高斯置信传播的接收机，提供近最优检测性能并显著降低计算复杂度。

Result: 仿真结果表明：提出的导频分配方法在通信性能上与最先进算法相当，但由于单模导频设计而具有更优的感知能力；GaBP接收机相比传统方法具有更稳健的性能和更低的复杂度。

Conclusion: 这些贡献推动了无小区大规模MIMO在集成感知与通信领域的实际部署，为系统提供了高效的导频分配和低复杂度的接收机解决方案。

Abstract: This paper tackles two key challenges in cell-freemassive multiple input
multiple output (CF-mMIMO) systems:efficient pilot allocation and practical
receiver design. To thisend, we introduce a novel pilot allocation framework
leveragingmanifold optimization to maximize the system sum rate, wherepilot
sequences are designed as nearly orthogonal sequences. Theproposed pilot design
enforces unimodularity constraints in thefrequency domain, ensuring pilots are
suitable for both communi-cation and sensing tasks. Additionally, a gaussian
belief propaga-tion (GaBP)-based receiver is introduced, providing
near-optimaldetection performance with substantially reduced
computationalcomplexity. Simulation results demonstrate that the proposedpilot
allocation method achieves communication performancecomparable to
state-of-the-art (SotA) algorithms, while deliveringsuperior sensing
capabilities due to its unimodular pilot design.The GaBP-based receiver
achieves robust performance andlower complexity compared to conventional
approaches. Thesecontributions advance the practical deployment of CF-mMIMOfor
integrated sensing and communications (ISAC).

</details>


### [9] [Distributed Deployment and Dual-Frequency Concepts to Strengthen Sub-THz Wireless Systems](https://arxiv.org/abs/2509.00492)
*Liesbet Van der Perre,Gilles Callebaut,Thomas Eriksson,Muris Sarajlic,Christian Fager,Fredrik Tufvesson,Buon Kiong Lau,Erik G. Larsson*

Main category: eess.SP

TL;DR: 通过聚合物微波纤维传输RF信号，构建链式分布式次太赫网络，结合双频段串联操作提高网络性能和可靠性


<details>
  <summary>Details</summary>
Motivation: 次太赫频段具有庞大带宽潜力，但物理约束和技术限制使得可靠网络部署面临挑战，需要新的覆盖方案

Method: 使用聚合物微波纤维传输RF信号，链式连接低复杂度无线单元，构建分布式网络架构，同时集成次-10GHz系统提供控制信令和备用解决方案

Result: 用户设备可以连接附近的无线单元，减少路径损耗和阻塞，提高网络性能和可靠性

Conclusion: 该方案能够充分发挥次太赫技术潜力，为动态环境中实现成本效益高、能消效高、高性能的实时连接投平道路

Abstract: The vast bandwidth available at sub-THz frequencies holds great promise for
high-speed wireless access, precise localization, and advanced sensing
applications. However, fundamental physical constraints and technological
limitations make the deployment of reliable sub-THz networks challenging. We
propose a new paradigm for sub-THz coverage by transmitting the RF signals over
polymer microwave fibers (PMFs) that interconnect low-complexity radio units
(RUs) in a daisy-chain configuration. The distributed architecture ensures that
user equipments (UEs) connect to RUs in their proximity, reducing path loss and
mitigating blocking. The RUs leverage low-complexity, compact integrated
antenna modules. Additionally, dual-frequency tandem operation is proposed,
integrating the sub-THz system with a sub-10 GHz system that provides control
signalling and a robust fallback solution for the sub-THz system. This proposed
tandem architecture can open up the full potential of sub-THz technology and
paves the way to cost- and energy-efficient, high-performance, real-time
connectivity in dynamic environments.

</details>


### [10] [Robust Resource Allocation for LEO Satellite-Assisted Secure SWIPT via STAR-RIS under CSI Uncertainty](https://arxiv.org/abs/2509.00568)
*Zahra Rostamikafaki,Francois Chan,Claude D'Amours*

Main category: eess.SP

TL;DR: 这篇论文提出了一种稳健的资源分配框架，用于低赨道卫星启用的同时无线信息和能量传输系统，通过地面STAR-RIS辅助来应对直连道阻塞和通道不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 解决直连卫星-地面链路受阻的情况下，通过STAR-RIS辅助实现稳健的同时信息和能量传输，并应对实际通道状态信息错误。

Method: 采用S-procedure处理通道不确定性，提出交替优化(AO)框架来聚合优化主动和被动放大，并结合惩罚策略确保STAR-RIS放大设计。

Result: 模拟结果验证了算法的有效性，并证明STAR-RIS在总收获功率方面显著优于传统RIS和其他基准方案。

Conclusion: 该框架能够在存在通道不确定性和直连道阻塞的情况下，实现高效的稳健资源分配，STAR-RIS架构带来了显著的性能提升。

Abstract: This paper proposes a robust resource allocation framework for a low Earth
orbit (LEO) satellite-enabled simultaneous wireless information and power
transfer (SWIPT) system, assisted by a ground-deployed simultaneously
transmitting and reflecting reconfigurable intelligent surface (STAR-RIS). We
consider a scenario where direct satellite-to-ground links are obstructed, and
the satellite serves multiple single-antenna energy receivers, information
receivers, and eavesdroppers exclusively via the STAR-RIS. A robust
optimization problem is formulated to maximize the total harvested power,
subject to secrecy rate requirements, transmit power limits, and STAR-RIS
coefficient constraints, under a practical bounded channel state information
(CSI) error model. To achieve optimal robust resource allocation, we address
the challenges posed by coupled optimization variables and bounded channel
estimation errors by first applying the S-procedure to handle robustness
against channel uncertainty. An alternating optimization (AO) framework is
subsequently proposed, where the active beamforming at the LEO satellite and
the passive beamforming at the STAR-RIS are jointly optimized, and a
penalty-based strategy is incorporated to enforce the STAR-RIS beamforming
design. Simulation results validate the effectiveness of the proposed algorithm
and demonstrate that the STAR-RIS architecture achieves substantial performance
gains in total harvested power over conventional RIS and other baseline
schemes.

</details>


### [11] [PyNoetic: A modular python framework for no-code development of EEG brain-computer interfaces](https://arxiv.org/abs/2509.00670)
*Gursimran Singh,Aviral Chharia,Rahul Upadhyay,Vinay Kumar,Luca Longo*

Main category: eess.SP

TL;DR: PyNoetic是一个模块化的Python脑机接口框架，提供从刺激呈现到数据可视化的完整BCI设计流程，包含直观的GUI和无代码流程图设计功能


<details>
  <summary>Details</summary>
Motivation: 现有BCI框架存在阶段灵活性不足、学习曲线陡峭、依赖商业软件成本高、功能不完整需要多工具配合等问题，影响了脑机接口研究的效率和效果

Method: 开发了模块化的PyNoetic框架，包含完整的BCI设计流程：刺激呈现、数据采集、通道选择、滤波、特征提取、伪影去除、仿真和可视化。提供无代码流程图配置界面和GUI，支持自定义功能集成

Result: PyNoetic成为少数几个涵盖完整BCI设计流程的Python框架，支持离线和实时BCI开发，降低了研究人员的使用门槛，加速了研究进程

Conclusion: PyNoetic通过其模块化设计、无代码配置功能和完整的工作流程，有效解决了现有BCI框架的局限性，为脑机接口研究提供了强大而灵活的工具平台

Abstract: Electroencephalography (EEG)-based Brain-Computer Interfaces (BCIs) have
emerged as a transformative technology with applications spanning robotics,
virtual reality, medicine, and rehabilitation. However, existing BCI frameworks
face several limitations, including a lack of stage-wise flexibility essential
for experimental research, steep learning curves for researchers without
programming expertise, elevated costs due to reliance on proprietary software,
and a lack of all-inclusive features leading to the use of multiple external
tools affecting research outcomes. To address these challenges, we present
PyNoetic, a modular BCI framework designed to cater to the diverse needs of BCI
research. PyNoetic is one of the very few frameworks in Python that encompasses
the entire BCI design pipeline, from stimulus presentation and data acquisition
to channel selection, filtering, feature extraction, artifact removal, and
finally simulation and visualization. Notably, PyNoetic introduces an intuitive
and end-to-end GUI coupled with a unique pick-and-place configurable flowchart
for no-code BCI design, making it accessible to researchers with minimal
programming experience. For advanced users, it facilitates the seamless
integration of custom functionalities and novel algorithms with minimal coding,
ensuring adaptability at each design stage. PyNoetic also includes a rich array
of analytical tools such as machine learning models, brain-connectivity
indices, systematic testing functionalities via simulation, and evaluation
methods of novel paradigms. PyNoetic's strengths lie in its versatility for
both offline and real-time BCI development, which streamlines the design
process, allowing researchers to focus on more intricate aspects of BCI
development and thus accelerate their research endeavors. Project Website:
https://neurodiag.github.io/PyNoetic

</details>


### [12] [Uninformed-to-Informed Estimation: A Ping-Pong Positioning Method for Multi-user Wideband mmWave Systems](https://arxiv.org/abs/2509.00727)
*Lin Guo,Tiejun Lv,Yashuai Cao,Mugen Peng*

Main category: eess.SP

TL;DR: 提出了一种基于定位误差下界驱动的乒乓定位框架，用于毫米波系统中动态用户设备的精确定位，通过多子载波协作和多路径融合提升定位精度，相比传统方法精度提升16%且资源消耗减少75%。


<details>
  <summary>Details</summary>
Motivation: 为了提升宽带毫米波系统中动态用户设备的定位和跟踪性能，需要解决传统方法在波束配置优化和资源利用效率方面的不足。

Method: 提出了PELB驱动的乒乓定位框架，BS和UE交替传输自适应波束成形信号；开发了多子载波协作定位误差下界(MSCPEB)评估方法；设计了交替优化算法优化混合波束成形器；提出了不依赖路径分辨的多路径协作定位方法。

Result: 数值结果表明，相比未优化波束配置的方案，定位精度提升至少16%，同时仅需约四分之一的时隙资源。

Conclusion: 该框架通过多维度信息融合和优化波束配置，显著提升了毫米波系统的定位性能，为动态用户设备的高精度定位提供了有效解决方案。

Abstract: To enhance the positioning and tracking performance of dynamic user equipment
(UE) in wideband millimeter-wave (mmWave) systems, we propose a novel
positioning error lower bound (PELB)-driven ping-pong positioning framework,
where the base station (BS) and UE alternately transmit and receive adaptive
beamforming signals for positioning. All beam-formers are scheduled based on
the locally evaluated PELB. In this framework, we exploit multi-dimensional
information fusion to assist in positioning. Firstly, a multi-subcarrier
collaborative positioning error lower bound (MSCPEB) is proposed to evaluate
the positioning error limits of wideband mmWave systems, which quantifies the
contribution of all subcarriers to positioning accuracy. Moreover, we prove
that the MSCPEB does not exceed the arithmetic mean of the PELBs of the
individual subcarriers. Subsequently, we develop an alternating optimization
(AO) algorithm to optimize the hybrid beamformers targeted for MSCPEB
minimization. By convexifying this problem, closed-form solutions of
beamformers are derived. Finally, we develop a multipath collaborative
positioning method that quantifies the impact of path reliability on
positioning accuracy, with a closed-form solution for user position derived.
The proposed method does not rely on path resolution and traditional triangular
relationships. Numerical results validate that the proposed method improves
estimation accuracy by at least 16% compared to potential schemes without
optimized beam configurations, while requiring only approximately one-quarter
of the slot resources.

</details>


### [13] [Characterization of Mega-Constellation Links for LEO Missions With Applications to EO and ISS Use Cases](https://arxiv.org/abs/2509.00766)
*G. Maiolini Capez,M. A. Caceres,C. P. Bridges,S. Frey,R. Armellin,R. Garello,P. Bargellini*

Main category: eess.SP

TL;DR: 本文展示了利用OneWeb和Starlink等巨型星座为LEO航天器提供卓越通信连接的新范式，分析了通信链路特性、多系统协同优势，并通过国际空间站和地球观测卫星案例验证了该方案的显著优势。


<details>
  <summary>Details</summary>
Motivation: 随着卫星任务对连接性需求的不断增长，特别是在LEO领域，需要探索利用已部署的巨型星座为太空用户提供通信服务的新途径。

Method: 通过分析空间用户与实际OneWeb和Starlink星座之间的通信链路特性，包括可用性、接入时长、多普勒效应和路径损耗等参数，评估不同用户轨道参数下的性能表现，并研究多系统用户和多轨道系统的协同优势。

Result: 研究结果表明巨型星座能够为LEO航天器提供优异的连接性能，识别了最优用户轨道，多系统协同可进一步提升性能，GEO星座的补充能增强系统能力，实际用例验证了该方案的可行性。

Conclusion: 巨型星座连接解决方案具有众多优势，能够将LEO航天器转变为高度响应的空对空网络节点，为太空通信提供了创新的服务范式。

Abstract: Satellite missions demand ever greater connectivity, especially in the LEO
regime. In this paper, we introduce the new mega-constellation services in
space paradigm: we show that megaconstellations, deployed to offer innovative
services to Earth's users, can provide excellent connectivity to LEO spacecraft
as well. First, we characterise the communication link between space users and
the actual OneWeb and Starlink constellations. A full set of results in terms
of availability, access duration, Doppler, and path losses as a function of
user orbital parameters, identifying optimal user orbits, is provided. The
results achieved by a multi-system user able to communicate with both fleets
are also presented. The potential improvements available if geostationary
constellations are used to complement LEO megaconstellations in a multi-orbit
system are discussed as well. Finally, we focus on two LEO use cases: the
International Space Station and an Earth Observation Sun Synchronous satellite.
All the results demonstrate the numerous advantages of the mega-constellation
connectivity solution, which can transform LEO spacecraft into highly
responsive nodes of a space-to-space network.

</details>


### [14] [Fast Regularized 3D Near-Field MIMO Imaging Using Stochastic Proximal Gradient Method](https://arxiv.org/abs/2509.00774)
*Okyanus Oral*

Main category: eess.SP

TL;DR: 提出基于随机近端梯度方法的快速正则化重建方法，用于三维近场MIMO雷达成像，显著提升计算速度且保持重建质量


<details>
  <summary>Details</summary>
Motivation: 近场MIMO雷达成像因分布式天线的不规则空间采样导致计算负荷高，现有加速方法主要针对直接重建，难以适应不同MIMO几何结构和正则化反演

Method: 基于随机近端梯度方法开发快速正则化重建方法

Result: 实验测量显示运行时间显著改善，重建质量无明显妥协

Conclusion: 该方法有效解决了近场MIMO成像的计算效率问题，为不同几何结构的应用提供了便利

Abstract: Near-field multiple-input multiple-output (MIMO) radar imaging suffers from
high computational load inherently due to irregular spatial sampling with
distributed antennas. Existing acceleration methods for near-field MIMO imaging
typically rely on interpolation or compensation of measurements and are
primarily developed for direct reconstruction. This hinders their ease of
adoption for different MIMO geometries and requires further modification for
regularized inversion. In this study, we address these challenges by developing
a fast regularized reconstruction approach for three-dimensional near-field
MIMO imaging based on the Stochastic Proximal Gradient Method. We demonstrate
the performance of the developed approach through experimental measurements.
The results show a significant improvement in runtime without any notable
compromise in reconstruction quality.

</details>


### [15] [Deep Unfolding with Approximated Computations for Rapid Optimization](https://arxiv.org/abs/2509.00782)
*Dvir Avrahami,Amit Milstein,Caroline Chaux,Tirza Routtenberg,Nir Shlezinger*

Main category: eess.SP

TL;DR: 提出了一种联合优化迭代次数和每次迭代复杂度的学习优化框架，通过展开固定步数、用低复杂度近似计算替换部分迭代，从数据学习超参数来补偿近似，在混合波束成形和鲁棒PCA问题上实现计算复杂度降低3个数量级。


<details>
  <summary>Details</summary>
Motivation: 传统基于优化的求解器在延迟敏感系统中应用受限，因为迭代方法的顺序特性和每次迭代的高计算成本。虽然深度展开可以将迭代算法转换为固定迭代次数的学习模型，但无法解决每次迭代的成本问题。

Method: 展开固定数量的优化步骤，用低复杂度近似计算替换选定的迭代，从数据学习扩展超参数来补偿引入的近似。

Result: 在混合波束成形和鲁棒主成分分析两个代表性问题上，学习近似优化器在达到最先进性能的同时，计算复杂度降低了3个数量级以上。

Conclusion: 该方法有潜力在实时系统中实现快速、可解释和高效的决策，为延迟敏感应用提供了有效的优化解决方案。

Abstract: Optimization-based solvers play a central role in a wide range of signal
processing and communication tasks. However, their applicability in
latency-sensitive systems is limited by the sequential nature of iterative
methods and the high computational cost per iteration. While deep unfolding has
emerged as a powerful paradigm for converting iterative algorithms into learned
models that operate with a fixed number of iterations, it does not inherently
address the cost of each iteration. In this paper, we introduce a learned
optimization framework that jointly tackles iteration count and per-iteration
complexity. Our approach is based on unfolding a fixed number of optimization
steps, replacing selected iterations with low-complexity approximated
computations, and learning extended hyperparameters from data to compensate for
the introduced approximations. We demonstrate the effectiveness of our method
on two representative problems: (i) hybrid beamforming; and (ii) robust
principal component analysis. These fundamental case studies show that our
learned approximated optimizers can achieve state-of-the-art performance while
reducing computational complexity by over three orders of magnitude. Our
results highlight the potential of our approach to enable rapid, interpretable,
and efficient decision-making in real-time systems.

</details>


### [16] [Spectrum Cognition: Semantic Situation for Next-Generation Spectrum Management](https://arxiv.org/abs/2509.00851)
*Hao Zhang,Fuhui Zhou,Qihui Wuand Chau Yuen*

Main category: eess.SP

TL;DR: 该论文全面介绍了谱空认知技术，通过"数据处理-信号分析-语义情况"的创新视角提升无线网络效率和安全性，并提出了具体技术解决方案。


<details>
  <summary>Details</summary>
Motivation: 应对未来无线通信网络的复杂性和需求，优化谱空利用成为关键技术，需要开发更高级别的谱空认知能力。

Method: 采用"数据处理-信号分析-语义情况"的创新框架，对传统和智能谱空认知技术进行综述分析，并提出具体技术解决方案。

Result: 识别了谱空认知的关键挑战，并展示了语义情况在构建下一代无线系统中的转型潜力。

Conclusion: 论文不仅为谱空认知的理论理解做出贡献，还为实际应用提供了实用的见解和指导。

Abstract: In response to the growing complexity and demands of future wireless
communication networks, spectrum cognition has emerged as an essential
technique for optimizing spectrum utilization in next-generation wireless
networks. This article presents a comprehensive overview of spectrum cognition,
underscoring its critical role in enhancing the efficiency and security of
future wireless systems through the innovative perspective of "data processing
to signal analysis to semantic situation". Semantic situation, as the highest
level of spectrum cognition, enables the extraction of meaningful information
from raw spectrum data to provide intelligent support for network decisions. We
formally define spectrum cognition, clearly distinguishing it from traditional
spectrum sensing, and delve into the latest advancements in both traditional
and intelligent spectrum cognition frameworks, addressing key challenges in
spectrum cognition. Furthermore, we propose concrete technical solutions to
address these challenges, highlighting the transformative potential of semantic
situation in shaping next-generation wireless systems. Our findings not only
contribute to the theoretical understanding of spectrum cognition but also
offer practical insights for its implementation in real-world scenarios.

</details>


### [17] [Lightweight Error-Correction Code Encoders in Superconducting Electronic Systems](https://arxiv.org/abs/2509.00962)
*Yerzhan Mustafa,Berker Peköz,Selçuk Köse*

Main category: eess.SP

TL;DR: 本文提出了三种基于SFQ逻辑的轻量级纠错编码器（Hamming(7,4)、Hamming(8,4)和Reed-Muller(1,3)），分析了其在工艺参数变化下的性能，并探讨了理论复杂度与物理尺寸之间的权衡关系。


<details>
  <summary>Details</summary>
Motivation: 超导电子电路（如SFQ逻辑）到室温电子设备的数据传输容易因磁通俘获、制造缺陷和工艺参数变化而产生比特错误，同时4.2K冷却功率预算和芯片面积限制要求编码器尺寸必须紧凑。

Method: 采用SFQ逻辑实现三种轻量级纠错编码器：Hamming(7,4)、Hamming(8,4)和Reed-Muller(1,3)编码器，并在工艺参数变化条件下分析其性能表现。

Result: 研究分析了不同编码器在工艺参数变化环境下的性能表现，识别了编码器理论复杂度与物理实现尺寸之间的权衡关系。

Conclusion: 提出的轻量级纠错编码器方案能够在超导电路的冷却功率和面积约束下有效工作，为超导电子系统的可靠数据传输提供了可行的解决方案。

Abstract: Data transmission from superconducting electronic circuits, such as single
flux quantum (SFQ) logic, to room-temperature electronics is susceptible to bit
errors, which may result from flux trapping, fabrication defects, and process
parameter variations (PPV). Due to the cooling power budget at 4.2 K and
constraints on the chip area, the size of the error-correction code encoders is
limited. In this work, three lightweight error-correction code encoders are
proposed that are based on Hamming(7,4), Hamming(8,4), and Reed-Muller(1,3)
codes and implemented with SFQ logic. The performance of these encoders is
analyzed in the presence of PPV. The trade-offs between the theoretical
complexity and physical size of error-correction code encoders are identified.

</details>


### [18] [Doubly-Dispersive Continuous MIMO Systems: Channel Modeling and Beamforming Design](https://arxiv.org/abs/2509.00964)
*Kuranage Roche Rayan Ranasinghe,Zhaolin Wang,Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu,Emil Björnson*

Main category: eess.SP

TL;DR: 本文针对双色散信道下的MIMO连续孔径阵列系统，提出了全面的信道模型和最优波束成形设计，获得了低复杂度闭式解，在性能和计算复杂度上显著优于传统MIMO系统。


<details>
  <summary>Details</summary>
Motivation: 双色散信道对MIMO系统性能造成挑战，需要开发适用于连续孔径阵列的精确信道模型和高效波束成形方法，以支持集成感知与通信应用。

Method: 推导了双色散连续MIMO信道模型，获得OFDM、OTFS和AFDM波形的输入输出关系，利用变分法设计发射和接收波束成形矩阵，最大化接收功率。

Result: 获得了低复杂度闭式解，仿真结果表明所提出的波束成形设计在双色散信道下相比传统MIMO系统具有显著的性能和计算复杂度优势。

Conclusion: 提出的连续孔径阵列波束成形方法为双色散信道下的MIMO系统提供了有效的解决方案，在集成感知与通信应用中具有重要价值。

Abstract: We address the modeling and optimal beamforming (BF) design for
multiple-input multiple-output (MIMO) continuous aperture array (CAPA) systems
operating over doubly-dispersive (DD) channels. First, a comprehensive DD
continuous MIMO (DDC MIMO) channel model that incorporates CAPAs at both the
transmitter (TX) and receiver (RX) is derived, which is used to obtain explicit
input-output (I/O) relations for various waveforms well suited to integrated
sensing and communications (ISAC) and robust to DD channels, namely orthogonal
frequency division multiplexing (OFDM), orthogonal time frequency space (OTFS),
and affine frequency division multiplexing (AFDM). Then, functional
optimization problems are formulated for the design of TX and RX BF matrices
that maximize received power, in which novel low-complexity, closed-form
solutions are obtained via the calculus of variations (CoV) method, yielding
expressions closely related to the classical matched filter commonly used in
conventional MIMO systems. Simulation results confirm that the proposed TX/RX
BF designs with CAPAs provide significant performance and computational
complexity gains over conventional MIMO systems in DD channels.

</details>


### [19] [Localized Supervised Learning for Cryo-ET Reconstruction](https://arxiv.org/abs/2509.00968)
*Vinith Kishore,Valentin Debarnot,AmirEhsan Khorashadizadeh,Ivan Dokmanić*

Main category: eess.SP

TL;DR: 提出一种基于局部数据训练的轻量级网络方法，用于解决冷冻电子断层扫描中的噪声和缺失楔问题，显著降低计算和内存需求


<details>
  <summary>Details</summary>
Motivation: 冷冻电子断层扫描(Cryo-ET)因电子剂量限制导致测量数据噪声大且不完整，现有自监督学习方法需要为每个体积训练大型3D UNet，计算成本高

Method: 利用前向模型的局部特性，仅使用测量数据中的局部化信息训练轻量级网络，在计算需求和重建精度之间提供灵活平衡

Result: 实验表明该网络在未见数据集上表现良好，尽管只使用了少量测量数据进行训练

Conclusion: 该方法通过局部化训练策略有效解决了Cryo-ET重建中的计算效率问题，同时保持了高精度重建能力

Abstract: Cryo-electron tomography (Cryo-ET) is a powerful tool in structural biology
for 3D visualization of cells and biological systems at resolutions sufficient
to identify individual proteins in situ. The measurements are collected by
tilting the frozen specimen and exposing it to an electron beam of known
dosage. As the biological samples are prone to electron damage, the samples can
be exposed to only a limited dosage of electrons, leading to noisy and
incomplete measurements. Thus, the reconstructions are noisy and incomplete,
leading to the missing wedge problem. Currently, self-supervised learning is
used to compensate for this issue. This typically involves, for each volume to
recover, training a large 3D UNet on the initial noisy reconstruction, leading
to large training time and memory requirements. In this work, we exploit the
local nature of the forward model to train a lightweight network using only
localized data from the measurements. This design provides flexibility in
balancing computational and time requirements while reconstructing the volumes
with high accuracy. We observe experimentally that this network can work well
on unseen datasets, despite using a network trained on a few measurements.

</details>


### [20] [BSNeRF: Broadband Spectral Neural Radiance Fields for Snapshot Multispectral Light-field Imaging](https://arxiv.org/abs/2509.01070)
*Erqi Huang,John Restrepo,Xun Cao,Ivo Ihrke*

Main category: eess.SP

TL;DR: 提出了一种用于快照多光谱光场成像的宽带光谱神经辐射场模型，成功解决了宽带多路复用光谱的解耦问题，提升了多光谱光场图像重建质量


<details>
  <summary>Details</summary>
Motivation: 现有的SMLI方法要么通过降低光通量要么延长成像时间来回避模型解耦的挑战，需要一种能够有效处理宽带光谱解耦的神经辐射场模型

Method: 提出了宽带光谱神经辐射场(BSNeRF)模型，专门针对SMLI系统设计，能够在优化过程中有效处理宽带光谱解耦问题

Result: 实验表明该模型成功解耦了宽带多路复用光谱，提升了多光谱光场图像的重建效果

Conclusion: 该方法推动了全光成像技术的发展，为快照多光谱光场成像提供了有效的宽带光谱解耦解决方案

Abstract: Snapshot Multispectral Light-field Imaging (SMLI) is an emerging
computational imaging technique that captures high-dimensional data (x, y, z,
$\theta$, $\phi$, $\lambda$) in a single shot using a low-dimensional sensor.
The accuracy of high-dimensional data reconstruction depends on representing
the spectrum using neural radiance field models, which requires consideration
of broadband spectral decoupling during optimization. Currently, some SMLI
approaches avoid the challenge of model decoupling by either reducing
light-throughput or prolonging imaging time. In this work, we propose a
broadband spectral neural radiance field (BSNeRF) for SMLI systems. Experiments
show that our model successfully decouples a broadband multiplexed spectrum.
Consequently, this approach enhances multispectral light-field image
reconstruction and further advances plenoptic imaging.

</details>


### [21] [A Bayesian Framework For Cascaded Channel Estimation in RIS-Aided mmWave Systems](https://arxiv.org/abs/2509.01117)
*Gyoseung Lee,Junil Choi*

Main category: eess.SP

TL;DR: 提出基于变分推断的RIS辅助毫米波多用户系统级联信道估计方法，使用复自适应拉普拉斯先验来近似非高斯信道增益分布，相比传统LS和LMMSE估计器性能更优


<details>
  <summary>Details</summary>
Motivation: 由于级联RIS信道的复杂信道增益通常是非高斯的，使用线性最小均方误差(LMMSE)估计器会导致不可避免的性能下降，需要更准确的分布建模方法

Method: 提出变分推断框架，使用复自适应拉普拉斯先验来近似复杂信道增益的概率分布，以可处理的方式有效捕捉其分布特性

Result: 数值结果表明，所提出的估计器在级联信道估计误差方面优于传统的最小二乘(LS)和LMMSE估计器

Conclusion: 基于变分推断和复自适应拉普拉斯先验的估计框架能够有效处理RIS辅助毫米波系统中非高斯信道增益的估计问题，显著提升估计性能

Abstract: In this paper, we investigate cascaded channel estimation for reconfigurable
intelligent surface (RIS)-aided millimeter-wave multi-user communication
systems. Since the complex channel gains of the cascaded RIS channel are
generally non-Gaussian, the use of the linear minimum mean squared error
(LMMSE) estimator leads to inevitable performance degradation. To tackle this
issue, we propose a variational inference-based framework that approximates the
complex channel gains using a complex adaptive Laplace prior, which effectively
captures their probability distributions in a tractable way. Numerical results
demonstrate that the proposed estimator outperforms conventional estimators
including least squares and LMMSE in terms of cascaded channel estimation
error.

</details>


### [22] [Fluid Antenna Port Prediction based on Large Language Models](https://arxiv.org/abs/2509.01121)
*Yali Zhang,Haifan Yin,Weidong Li,Emil Bjornson,Merouane Debbah*

Main category: eess.SP

TL;DR: 使用GPT-2基础的Port-LLM模型，通过大语言模型预测流动天线端口位置，解决用户设备移动性挑战，在中高速移动环境中实现更高的谱效率。


<details>
  <summary>Details</summary>
Motivation: 解决用户设备在移动环境下的天线端口选择挑战，提高通信性能和稳定性。

Method: 基于GPT-2预训练框架构建Port-LLM模型，设计专门的数据预处理、输入嵌入和输出投影模块，完成无线通信数据与LLM数据格式的软仲。

Result: 模型在不同基站天线数量和用户设备速度下都显示出优异的预测性能，具有强大的泛化能力和稳健性，谱效率超过传统方法。

Conclusion: Port-LLM模型成功将大语言模型应用于流动天线端口预测，为移动通信领域提供了新的解决方案。

Abstract: This study seeks to utilize large language models (LLMs) to forecast the
moving ports of fluid antenna (FA). By repositioning the antenna to the
locations identified by our proposed model, we intend to address the mobility
challenges faced by user equipment (UE). To the best of our knowledge, this
paper introduces, for the first time, the application of LLMs in the prediction
of FA ports, presenting a novel model termed Port-LLM. The architecture of our
model is based on the pre-trained GPT-2 framework. We designed specialized data
preprocessing, input embedding, and output projection modules to effectively
bridge the disparities between the wireless communication data and the data
format utilized by the pre-trained LLM. Simulation results demonstrate that our
model exhibits superior predictive performance under different numbers of base
station (BS) antennas and varying UE speeds, indicating strong generalization
and robustness ability. Furthermore, the spectral efficiency (SE) attained by
our model surpasses that achieved by traditional methods in both medium and
high-speed mobile environments.

</details>


### [23] [Enabling 6G Through Multi-Domain Channel Extrapolation: Opportunities and Challenges of Generative Artificial Intelligence](https://arxiv.org/abs/2509.01125)
*Yuan Gao,Zichen Lu,Yifan Wu,Yanliang Jin,Shunqing Zhang,Xiaoli Chu,Shugong Xu,Cheng-Xiang Wang*

Main category: eess.SP

TL;DR: 本文提出了一种基于Transformer编码器的新模型，用于6G网络中的多域通道外推间额外推测问题，该模型在外推准确性和推理速度方面超越了现有基准模型。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要支持复杂场景下的高精度通道状态信息获取，而当前研究主要集中在单域通道外推，缺乏多域通道外推的综合方法。

Method: 提出了一种新的Transformer编码器类模型，移除了位置编码模块，并将原始的多头注意力机制替换为多层感知机(MLP)，以实现多域通道外推。

Result: 模拟结果显示，该模型在外推准确性和推理速度方面超越了现有基准模型。消融研究进一步证明了模块设计的有效性。

Conclusion: 该研究为6G网络的多域通道外推提供了有效解决方案，同时持出了解释性、普遍性和数据集收集等开放问题以促进实际应用。

Abstract: Channel extrapolation has attracted wide attention due to its potential to
acquire channel state information (CSI) with high accuracy and minimal
overhead. This is becoming increasingly crucial as the sixth-generation (6G)
mobile networks aim to support complex scenarios, for example, high-mobility
communications utilizing ultra-massive multiple-input multiple-output (MIMO)
technologies and broad spectrum bands, necessitating multi-domain channel
extrapolation. Current research predominantly addresses channel extrapolation
within a single domain, lacking a comprehensive approach to multi-domain
channel extrapolation. To bridge the gap, we propose the concept of
multi-domain channel extrapolation, detailing the essential performance
requirements for 6G networks. These include precise channel extrapolation,
adaptability to varying scenarios, and manageable computational complexity
during both training and inference stages. In light of these requirements, we
elaborate the potential and challenges of incorporating generative artificial
intelligence (GAI)-based models for effective multi-domain channel
extrapolation. Given the ability of the Transformer to capture long-range
dependencies and hidden patterns, we propose a novel Transformer encoder-like
model by eliminating the positional encoding module and replacing the original
multi-head attention with a multilayer perceptron (MLP) for multi-domain
channel extrapolation. Simulation results indicate that this model surpasses
existing baseline models in terms of extrapolation accuracy and inference
speed. Ablation studies further demonstrate the effectiveness of the module
design of the proposed design. Finally, we pose several open questions for the
development of practical GAI-based multi-domain channel extrapolation models,
including the issues of explainability, generalization, and dataset collection.

</details>


### [24] [A Model-Based Dictionary Approach for Magnetic Nanoparticle Signal Prediction](https://arxiv.org/abs/2509.01127)
*Asli Alpman,Mustafa Utkur,Emine Ulku Saritas*

Main category: eess.SP

TL;DR: 这篇论文提出了一种基于模型字典的迭代算法，能够在未经测试设置下预测磁性纳米粒子的信号响应，并估计非模型动力学的传递函数。


<details>
  <summary>Details</summary>
Motivation: 磁性纳米粒子的磁化响应受多种因素影响，需要一种无需废弃实验的方法来优化驱动场设置和MNP类型选择。

Method: 使用耦合Brown-Néel旋转模型模拟MNP信号构建字典，通过迭代算法聚合估计字典权重和非模型动力学的传递函数。

Result: 在SNR 1和10的合成信号上验证了准确的权重和传递函数估计。在0.89-15.33 mPa.s糖度范围和0.25-2 kHz驱动场频率下，NRMSE低于1.51%和3.5%，NWD值低于0.10和0.07。

Conclusion: 该算法能够准确预测未经测试糖度下的MNP信号，为MPI应用中的驱动场和MNP选择优化提供了有效工具。

Abstract: Magnetic particle imaging (MPI) is a tracer-based medical imaging modality
that enables quantification and spatial mapping of magnetic nanoparticle (MNP)
distribution. The magnetization response of MNPs depends on experimental
conditions such as drive field (DF) settings and medium viscosity, as well as
on magnetic parameters of MNPs such as magnetic core diameter, hydrodynamic
diameter, and magnetic anisotropy constant. A comprehensive understanding of
the magnetization response of MNPs can facilitate the optimization of DF and
MNP type for a given MPI application, without the need for extensive
experimentation. In this work, we propose a calibration-free iterative
algorithm using model-based dictionaries for MNP signal prediction at untested
settings. Dictionaries were constructed with the MNP signals simulated using
the coupled Brown-N\'eel rotation model. Based on the available measurements,
the proposed algorithm jointly estimates the dictionary weights and the
transfer functions due to non-model-based dynamics. These dynamics include the
system response of the measurement setup as well as magnetization dynamics not
accounted for by the employed coupled Brown-N\'eel rotation model. The
algorithm was first validated on synthetic signals at SNR levels of 1 and 10,
and then tested on an in-house MPS setup across six viscosity levels
(0.89-15.33 mPa.s) and DF frequencies of 0.25-2 kHz using two commercial MNPs.
Validation on synthetic signals showed accurate weight and transfer function
estimation even at SNR 1. MPS experiments demonstrated successful prediction of
MNP signals at untested viscosities, with NRMSE below 1.51% and 3.5% for the
two tested MNPs across all DF settings. Predicted signals captured viscosity
dependent trends, and NWD values remained low (<0.10 and <0.07 for the two
tested MNPs), confirming robust weight estimation.

</details>


### [25] [Dynamic State Estimation of Power System Utilizing Cauchy Kernel-Based Maximum Mixture Correntropy UKF over Beluga Whale-Bat Optimization](https://arxiv.org/abs/2509.01163)
*Duc Viet Nguyen,Haiquan Zhao,Jinhui Hu*

Main category: eess.SP

TL;DR: 基于滑石核最大混合相关熵准则的稳健UKF算法，通过鱼鲸-蝙蝠混合优化算法自动调整核函数参数，提高电力系统动态状态估计的稳健性和准确性。


<details>
  <summary>Details</summary>
Motivation: 电力系统中的非高斯噪声、离群倾、负荷突变和坏数据会降低UKF的估计准确性，而传统高斯核函数对带宽参数敏感且容易导致矩阵奇异问题。

Method: 采用两个Cauchy函数混合的滑石核替代高斯核，通过统计线性化技术统一测量误差和状态误差，采用固定点迭代求解最优状态估计值，并用BWB算法优化核函数参数。

Result: 在IEEE 14、30、57节点测试系统中验证了算法的性能，显示出更好的稳健性和准确性。

Conclusion: 所提算法能够有效应对非高斯噪声和异常数据，提高电力系统动态状态估计的可靠性和准确性，为复杂环境下的状态估计提供了有效解决方案。

Abstract: Non-Gaussian noise, outliers, sudden load changes, and bad measurement data
are key factors that diminish the accuracy of dynamic state estimation in power
systems. Additionally, unscented Kalman filters (UKF) based on correntropy
criteria utilize bandwidth-sensitive Gaussian kernels, which may lead to
singular matrices in the Cholesky decomposition. To overcome all the above
problems, in this paper, a robust UKF based on Cauchy kernel maximum mixture
correntropy (CKMMC) criteria over hybrid Beluga Whale-Bat (BWB) optimization
(BWB-CKMMC-UKF) is proposed, in which the kernel is merged of two Cauchy
functions. Specifically, the measurement error and state error are unified in
the cost function by the statistical linearization technique, and the optimal
value of state estimation is obtained by fixed-point iteration. Because of its
insensitive feature to kernel bandwidth and notable thick-tailed feature, the
Cauchy kernel function is utilized instead of the Gaussian kernel in the
optimization criteria. Additionally, to fit the power system model, the shape
coefficients of the kernel in the CKMMC criterion and scale coefficients that
influence the selection of sigma points in the unscented transform are
determined based on the BWB algorithm. Simulation results on IEEE 14, 30, and
57-bus test systems validated the performance of the proposed algorithm.

</details>


### [26] [Beyond Exhaustive Sampling: Efficient Rotational Matching via Ball Harmonics](https://arxiv.org/abs/2509.01180)
*Fabian Kruse,Vinith Kishore,Valentin Debarnot,Ivan Dokmanić*

Main category: eess.SP

TL;DR: 基于球谐函数展开的亚断层图对齐框架，结合频率和梯度优化策略，避免穷举旋转采样，速度比现有方法快一个数量级


<details>
  <summary>Details</summary>
Motivation: 冷冻电子断层扫描技术产生大量数据，需要可扩展、快速且鲁棒的亚断层图对齐方法来处理低信噪比的重建体积

Method: 使用球谐函数展开结合频率和梯度优化策略，避免穷举旋转采样

Result: 实现比当前方法快一个数量级的加速

Conclusion: 提出的框架为处理大规模冷冻电子断层扫描数据提供了高效的对齐解决方案

Abstract: Cryo-ET allows to generate tomograms of biological samples in situ, capturing
complex structures in their native context. Despite low signal-to-noise ratio
in reconstructed volumes, the large number of copies of the same macromolecules
makes it possible to retrieve high-resolution maps by averaging many aligned
subtomograms. To keep up with technical advances in the imaging process and the
resulting huge amounts of data available, there is a need for scalable, fast
and robust procedures to align subtomograms. We propose a subtomogram alignment
framework based on the ball harmonics expansion that combines frequency- and
gradient-based optimization strategies to avoid exhaustive rotation sampling,
enabling a speed-up of an order of magnitude compared to current approaches.

</details>


### [27] [Enhanced Fingerprint-based Positioning With Practical Imperfections: Deep learning-based approaches](https://arxiv.org/abs/2509.01197)
*Shugong Xu,Jun Jiang,Wenjun Yu,Yilin Gao,Guangjin Pan,Shiyi Mu,Zhiqi Ai,Yuan Gao,Peigang Jiang,Cheng-Xiang Wang*

Main category: eess.SP

TL;DR: 本文提出了三种创新的蜂窝网络定位框架，通过半监督一致性、集成学习和解耦映射头方法，解决了实际环境中标签数据稀缺、动态环境和锚点分布不均等挑战，在竞赛中取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的定位算法需要大量标注数据，但在真实蜂窝环境中难以获取，且模型泛化能力不足。为了解决这些问题并推动蜂窝定位技术的发展，作者参加了2024年无线通信算法精英竞赛。

Method: 开发了三种创新定位框架：1）带有一致性的半监督框架，生成高质量伪标签扩大训练数据集；2）基于集成学习的算法，整合不同训练策略模型的定位坐标以应对动态环境；3）基于解耦映射头的算法，使用扇区旋转方案解决锚点分布不均问题。

Result: 仿真结果表明，所提出的定位算法在{90%、80%、67%、50%}百分位数和平均距离误差方面均优于现有基准方法，在竞赛中包揽前三名。

Conclusion: 这些创新框架有效解决了实际蜂窝定位中的关键挑战，包括标签数据稀缺、环境动态变化和锚点分布不均等问题，为高精度蜂窝网络定位提供了有效的解决方案。

Abstract: High-precision positioning is vital for cellular networks to support
innovative applications such as extended reality, unmanned aerial vehicles
(UAVs), and industrial Internet of Things (IoT) systems. Existing positioning
algorithms using deep learning techniques require vast amounts of labeled data,
which are difficult to obtain in real-world cellular environments, and these
models often struggle to generalize effectively. To advance cellular
positioning techniques, the 2024 Wireless Communication Algorithm Elite
Competition as conducted, which provided a dataset from a three-sector outdoor
cellular system, incorporating practical challenges such as limited
labeled-dataset, dynamic wireless environments within the target and
unevenly-spaced anchors, Our team developed three innovative positioning
frameworks that swept the top three awards of this competition, namely the
semi-supervised framework with consistency, ensemble learning-based algorithm
and decoupled mapping heads-based algorithm. Specifically, the semi-supervised
framework with consistency effectively generates high-quality pseudo-labels,
enlarging the labeled-dataset for model training. The ensemble learning-based
algorithm amalgamates the positioning coordinates from models trained under
different strategies, effectively combating the dynamic positioning
environments. The decoupled mapping heads-based algorithm utilized sector
rotation scheme to resolve the uneven-spaced anchor issue. Simulation results
demonstrate the superior performance of our proposed positioning algorithms
compared to existing benchmarks in terms of the {90%, 80%, 67%, 50%} percentile
and mean distance error.

</details>


### [28] [Rigid Body Localization and Tracking for 6G V2X: Algorithms, Applications, and Road to Adoption](https://arxiv.org/abs/2509.01208)
*Niclas Führling,Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu,David González G.,Gonzalo Seco-Granados,Osvaldo Gonsa*

Main category: eess.SP

TL;DR: 本文介绍了刚性体定位(RBL)技术，这是一种能够估计目标位置、速度、3D几何结构和方向的新兴V2X感知技术，在B5G/6G无线系统中具有重要应用前景。


<details>
  <summary>Details</summary>
Motivation: 随着自动驾驶需求的增长和ISAC框架的出现，需要更先进的感知技术来支持车辆与环境的多维交互，RBL技术能够提供比传统定位更丰富的空间信息。

Method: 文章主要介绍了RBL的概念框架，重点讨论了其在集成感知与通信(ISAC)系统中的实现原理和技术特点。

Result: RBL技术能够实现目标位置、速度、3D几何结构和方向的全面估计，为V2X感知提供了更强大的能力。

Conclusion: RBL是V2X感知领域的一个有前景的技术方向，在B5G/6G无线系统中具有重要应用价值，需要进一步研究技术挑战并推动标准化工作。

Abstract: Vehicle-to-everything (V2X) perception refers to a suite of technologies that
empower vehicles to sense their environment and communicate with other
entities, including surrounding vehicles, infrastructure, and cloud/edge
networks. With the growing demands of autonomous driving, V2X perception has
gained significant attention, particularly through the emergence of integrated
sensing and communication (ISAC) frameworks. Within this landscape, rigid body
localization (RBL) has emerged as a promising paradigm, enabling the estimation
of not only the position and velocity of the targets, but also its
three-dimensional (3D) geometric structure and orientation. This article
introduces the concept of RBL, highlights its unique advantages and
applications, identifies key technical challenges, and finally outlines future
research directions. In addition, the potential of RBL in next-generation -
e.g. beyond fifth generation (B5G) and sixth-generation (6G) - wireless systems
applied to V2X perception is also discussed, with a focus on its role in
standardization efforts and its relevance across automotive and industrial
domains.

</details>


### [29] [High-Density MIMO Localization Using a 32x64 Ultrasonic Transducer-Microphone Array with Real-Time Data Streaming](https://arxiv.org/abs/2509.01210)
*Rens Baeyens,Dennis Laurijssen,Jan Steckel,Walter Daems*

Main category: eess.SP

TL;DR: 提出了一种基于大规模MIMO架构的新型超声波阵列系统，使用32个发射器和62个麦克风，通过随机相位多音信号提高信道分离度和空间分辨率。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统超声波定位系统中信道分离度和空间分辨率受限的问题，需要开发能够提供更高精度定位的大规模MIMO超声系统。

Method: 采用32个发射器和62个麦克风组成的大规模MIMO架构，每个发射器使用超声波频段的随机相位多音信号进行激励，以减少信道间相关性并增强多径鲁棒性。

Result: 仿真结果显示，与单发射器配置相比，MIMO处理能够更好地分离反射体，但换能器带宽等实际限制会降低可实现的信道隔离度。

Conclusion: 大规模MIMO超声阵列系统在提高定位精度方面具有潜力，但实际应用中需要考虑换能器带宽等硬件限制对性能的影响。

Abstract: In this work, we present a novel ultrasonic array system designed for
high-precision localization using a large-scale MIMO (Multiple-Input
Multiple-Output) architecture. The system combines 32 transmitters with 62
microphones, creating an extended virtual aperture that improves channel
separability and spatial resolution. Each transmitter is excited by a
random-phase multisine within the ultrasonic band, which reduces inter-channel
correlation and increases robustness against multipath. The feasibility of the
approach is demonstrated through simulations of reflector imaging and analysis
of channel separation under realistic transducer bandwidth constraints. Results
show that MIMO processing enables improved separation of reflectors compared to
single-emitter configurations, although practical limitations such as
transducer bandwidth reduce the achievable channel isolation.

</details>


### [30] [nRTIS: Low-Cost Real-Time 3D Sonar Imaging Circular Array Supporting Beamforming for Industrial Applications](https://arxiv.org/abs/2509.01212)
*Rens Baeyens,Dennis Laurijssen,Jan Steckel,Walter Daems*

Main category: eess.SP

TL;DR: nRTIS是一个基于MEMS麦克风圆形阵列和中央超声波换能器的紧凑型超声传感平台，通过RP2350微控制器实现实时3D成像，解决了传统超声检测系统成本高、体积大的问题


<details>
  <summary>Details</summary>
Motivation: 传统超声检测系统依赖相控阵和高性能计算硬件，导致成本高昂、体积庞大，不适合便携或嵌入式应用，需要开发更紧凑的解决方案

Method: 使用MEMS麦克风圆形阵列和中央超声波换能器构建传感平台，通过RP2350微控制器实现实时采集和高速USB传输，采用点扩散函数模拟和反射器测量进行验证

Result: 点扩散函数模拟显示了波束形成分辨率和旁瓣抑制能力，反射器测量证实了稳健的数据采集性能

Conclusion: nRTIS系统展示了在焊缝检测、管道测绘和机器人导航等工业应用中可扩展的潜力

Abstract: Conventional ultrasonic inspection systems rely on phased arrays and
high-performance computing hardware, making them costly, bulky, and unsuitable
for portable or embedded use. In this work, we present nRTIS (nano Real-Time 3D
Imaging Sonar), a compact ultrasonic sensing platform built around a circular
array of MEMS microphones and a central ultrasonic transducer. The device
achieves real-time acquisition through an RP2350 microcontroller and high-speed
USB transfer. We validate the system using both simulations and controlled
experiments: point spread function (PSF) simulations demonstrate beamforming
resolution and sidelobe suppression, while reflector measurements confirm
robust data acquisition. These results highlight the potential of nRTIS for
scalable industrial applications such as weld inspection, pipe mapping, and
robotic navigation.

</details>


### [31] [Rate Optimization for Downlink URLLC via Pinching Antenna Arrays](https://arxiv.org/abs/2509.01222)
*Tong Lin,Jianyue Zhu,Wei Huang,Meng Hua,Zhizhong Zhang*

Main category: eess.SP

TL;DR: 该研究提出了一种采用夹持天线的uRLLC下行系统，通过优化天线位置和相位对齐策略，在满足服务质量约束下最大化数据速率。


<details>
  <summary>Details</summary>
Motivation: 为满足超可靠低延迟通信(uRLLC)的需求，需要开发紧凑且成本效益高的天线架构，以在有限空间内实现高性能通信。

Method: 提出紧凑的夹持天线架构，建立基于有限块长度的优化模型，推导出天线最优位置闭式解，并集成相位对齐策略实现相干信号叠加。

Result: 仿真结果显示相比传统天线系统有显著速率提升，同时满足uRLLC要求，适用于紧凑和延迟敏感的应用场景。

Conclusion: 所提出的夹持天线设计为未来紧凑型和延迟关键型应用提供了有效的解决方案，在满足服务质量约束的同时实现了数据速率的显著改善。

Abstract: This work studies an ultra-reliable and low-latency communications (uRLLC)
downlink system using pinching antennas which are realized by activating small
dielectric particles along a dielectric waveguide. Our goal is to maximize the
data rate by optimizing the positions of the pinching antennas. By proposing a
compact and cost-efficient antenna architecture and formulating a finite
blocklength-based optimization model, we derive a closed-form solution for the
optimal antenna placement under quality-of-service (QoS) and antenna spacing
constraints. Meanwhile, a phase-alignment strategy is integrated into the
design, enabling coherent signal superposition across the array. Simulation
results confirm significant rate improvements over conventional antenna systems
while satisfying uRLLC requirements, making the proposed design well-suited for
compact and latency-critical future applications.

</details>


### [32] [SMDS-based Rigid Body Localization](https://arxiv.org/abs/2509.01223)
*Niclas Führling,Giuseppe Abreu,David González G.,Osvaldo Gonsa*

Main category: eess.SP

TL;DR: 基于距离和传感器角度测量的创新刚体定位方法，利用超维多维缩放算法的变种，在计算复杂性上有显著优势


<details>
  <summary>Details</summary>
Motivation: 解决仅依靠距离和传感器角度测量进行刚体定位的问题，提高定位精度和减少计算复杂度

Method: 采用超维多维缩放(SMDS)算法的变种，仅使用复杂边缘内核的少部分，基于可用的锐点到锐点和目标到目标信息

Result: 模拟结果显示该方法在估计的均方误差(MSE)方面表现良好，与相应的克拉美-罗下界(CRLB)相比也有竞争力

Conclusion: 该新题刚体定位方法通过优化算法结构，在保持高精度定位的同时有效降低了计算复杂度，为传感器网络定位提供了有效解决方案

Abstract: We consider a novel rigid body localization (RBL) method, based only on a set
of measurements of the distances, as well as the angles between sensors of the
vehicle to the anchor landmark points. A key point of the proposed method is to
use a variation of the super multidimensional scaling (SMDS) algorithm, where
only a minor part of the complex edge kernel is used, based on the available
information, which in the case of RBL is anchor-to-anchor and target-to-target
information. Simulation results illustrate the good performance of the proposed
technique in terms of mean square error (MSE) of the estimates, compared also
to the corresponding Cram\'er-Rao Lower Bound (CRLB).

</details>


### [33] [Comparison between Supervised and Unsupervised Learning in Deep Unfolded Sparse Signal Recovery](https://arxiv.org/abs/2509.01331)
*Koshi Nagahisa,Ryo Hayakawa,Youji Iiguni*

Main category: eess.SP

TL;DR: 本文研究了深度展开技术中损失函数选择对稀疏信号恢复算法的影响，发现损失函数效果取决于优化问题的凸性。对于凸问题，监督学习获得更好恢复精度但无法最小化原目标函数；对于非凸问题，两种方法都能收敛到比传统算法更好的局部极小值。


<details>
  <summary>Details</summary>
Motivation: 深度展开技术将迭代优化算法转换为可训练的轻量级神经网络，但不同应用场景下使用不同的损失函数进行参数学习。需要研究损失函数选择对算法性能的影响，特别是在稀疏信号恢复这一重要应用领域。

Method: 研究深度展开版本的ISTA和IHT算法，比较使用均方误差的监督学习和使用原始优化问题目标函数的无监督学习。通过仿真实验分析不同损失函数在凸和非凸优化问题中的表现。

Result: 对于凸的ℓ1正则化问题，监督ISTA获得更好的最终恢复精度但无法最小化原始目标函数，而无监督ISTA收敛到与传统ISTA几乎相同的解但收敛速度更快。对于非凸的ℓ0正则化问题，监督和无监督IHT都能收敛到比原始IHT更好的局部极小值，性能相似。

Conclusion: 损失函数选择的效果显著依赖于优化问题的凸性，这一发现为设计有效的深度展开网络提供了重要指导，需要根据具体问题的凸性特征来选择合适的损失函数。

Abstract: This paper investigates the impact of loss function selection in deep
unfolding techniques for sparse signal recovery algorithms. Deep unfolding
transforms iterative optimization algorithms into trainable lightweight neural
networks by unfolding their iterations as network layers, with various loss
functions employed for parameter learning depending on application contexts. We
focus on deep unfolded versions of the fundamental iterative shrinkage
thresholding algorithm (ISTA) and the iterative hard thresholding algorithm
(IHT), comparing supervised learning using mean squared error with unsupervised
learning using the objective function of the original optimization problem. Our
simulation results reveal that the effect of the choice of loss function
significantly depends on the convexity of the optimization problem. For convex
$\ell_1$-regularized problems, supervised-ISTA achieves better final recovery
accuracy but fails to minimize the original objective function, whereas we
empirically observe that unsupervised-ISTA converges to a nearly identical
solution as conventional ISTA but with accelerated convergence. Conversely, for
nonconvex $\ell_0$-regularized problems, both supervised-IHT and
unsupervised-IHT converge to better local minima than the original IHT, showing
similar performance regardless of the loss function employed. These findings
provide valuable insights into the design of effective deep unfolded networks
for sparse signal recovery applications.

</details>


### [34] [A James-Stein Estimator based Generalized OMP Algorithm for Robust Signal Recovery using Sparse Representation](https://arxiv.org/abs/2509.01410)
*Debraj Banerjee,Amitava Chatterjee*

Main category: eess.SP

TL;DR: JS-gOMP算法通过整合James-Stein估计器增强gOMP算法，在噪声环境下显著提升稀疏信号处理的鲁棒性和恢复性能


<details>
  <summary>Details</summary>
Motivation: 解决字典中噪声对稀疏表示带来的挑战，优化信号恢复与噪声抑制之间的平衡

Method: 在广义正交匹配追踪(gOMP)算法中引入James-Stein估计器进行改进

Result: JS-gOMP在噪声环境中优于传统gOMP算法，特别是在噪声显著存在的信号和图像处理应用中表现更有效

Conclusion: JS-gOMP算法为噪声环境下的稀疏信号处理提供了更有效的解决方案，具有更好的噪声鲁棒性

Abstract: In this paper, we introduce a novel algorithm named JS-gOMP, which enhances
the generalized Orthogonal Matching Pursuit (gOMP) algorithm for improved noise
robustness in sparse signal processing. The JS-gOMP algorithm uniquely
incorporates the James-Stein estimator, optimizing the trade-off between signal
recovery and noise suppression. This modification addresses the challenges
posed by noise in the dictionary, a common issue in sparse representation
scenarios. Comparative analyses demonstrate that JS-gOMP outperforms
traditional gOMP, especially in noisy environments, offering a more effective
solution for signal and image processing applications where noise presence is
significant.

</details>


### [35] [To Share, or Not to Share: A Study on GEO-LEO Systems for IoT Services with Random Access](https://arxiv.org/abs/2509.01506)
*Marcel Grec,Federico Clazzer,Israel Leyva-Mayorga,Andrea Munari,Gianluigi Liva,Petar Popovski*

Main category: eess.SP

TL;DR: 两个卫星运营商在IoT服务中的谱段共享分析，发现在特定条件下谱段共享可以帮助双方提升吞吐量，但效果受到用户数量和编码率等因素影响


<details>
  <summary>Details</summary>
Motivation: 解决卫星部署增加导致的无线资源稀缺问题，探索卫星运营商之间是否应该共享谱段资源来支持大量爆发式流量的IoT设备

Method: 构建两个运营商服务重叠覆盖区域的通信模型，使用分析近似法并通过蒙特卡洛模拟验证

Result: 谱段共享在某些条件下可以为双方带来显著的吞吐量增益，但增益效果受到服务用户数量相对比例和编码率等系统参数的影响，并非总是双方都能获益

Conclusion: 该模型揭示了上行链路谱段共享的基本批息关系，为未来6G非地面网络的设计和规制提供了可操作的新见解

Abstract: The increasing number of satellite deployments, both in the low and
geostationary Earth orbit exacerbates the already ongoing scarcity of wireless
resources when targeting ubiquitous connectivity. For the aim of supporting a
massive number of IoT devices characterized by bursty traffic and modern
variants of random access, we pose the following question: Should competing
satellite operators share spectrum resources or is an exclusive allocation
preferable? This question is addressed by devising a communication model for
two operators which serve overlapping coverage areas with independent IoT
services. Analytical approximations, validated by Monte Carlo simulations,
reveal that spectrum sharing can yield significant throughput gains for both
operators under certain conditions tied to the relative serviced user
populations and coding rates in use. These gains are sensitive also to the
system parameters and may not always render the spectral coexistence mutually
advantageous. Our model captures basic trade-offs in uplink spectrum sharing
and provides novel actionable insights for the design and regulation of future
6G non-terrestrial networks.

</details>


### [36] [Non-Identical Diffusion Models in MIMO-OFDM Channel Generation](https://arxiv.org/abs/2509.01641)
*Yuzhi Yang,Omar Alhussein,Mérouane Debbah*

Main category: eess.SP

TL;DR: 提出非相同扩散模型用于无线OFDM信道生成，通过元素级时间指示器捕捉局部误差变化，改善初始估计存在偏差时的生成效果


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型使用标量时间索引表示全局噪声水平，无法准确捕捉无线MIMO-OFDM信道矩阵中由于导频方案导致的元素间可靠性不均匀问题

Method: 引入与输入尺寸匹配的矩阵来控制元素级噪声进程，提出维度级时间嵌入策略，遵循类似现有方法的扩散过程

Result: 理论和数值实验证明了非相同扩散方案的正确性和有效性，在MIMO-OFDM信道生成中表现优异

Conclusion: 非相同扩散模型能够更好地表征噪声输入中每个元素的可靠性，特别适用于初始估计存在偏差的无线信道生成场景

Abstract: We propose a novel diffusion model, termed the non-identical diffusion model,
and investigate its application to wireless orthogonal frequency division
multiplexing (OFDM) channel generation. Unlike the standard diffusion model
that uses a scalar-valued time index to represent the global noise level, we
extend this notion to an element-wise time indicator to capture local error
variations more accurately. Non-identical diffusion enables us to characterize
the reliability of each element (e.g., subcarriers in OFDM) within the noisy
input, leading to improved generation results when the initialization is
biased. Specifically, we focus on the recovery of wireless multi-input
multi-output (MIMO) OFDM channel matrices, where the initial channel estimates
exhibit highly uneven reliability across elements due to the pilot scheme.
Conventional time embeddings, which assume uniform noise progression, fail to
capture such variability across pilot schemes and noise levels. We introduce a
matrix that matches the input size to control element-wise noise progression.
Following a similar diffusion procedure to existing methods, we show the
correctness and effectiveness of the proposed non-identical diffusion scheme
both theoretically and numerically. For MIMO-OFDM channel generation, we
propose a dimension-wise time embedding strategy. We also develop and evaluate
multiple training and generation methods and compare them through numerical
experiments.

</details>


### [37] [Predictive Communications for Low-Altitude Networks](https://arxiv.org/abs/2509.01705)
*Junting Chen,Bowen Li,Hao Sun,Shuguang Cui,Nikolaos Pappas*

Main category: eess.SP

TL;DR: 提出了预测性通信新范式，通过融合可预测的任务轨迹和无线电环境模型，实现从被动适应到主动优化的网络管理转变，显著降低跨层干扰


<details>
  <summary>Details</summary>
Motivation: 传统反应式通信范式无法应对低空经济密集任务驱动网络的极端信道动态和严重跨层干扰问题，需要利用网络固有可预测性

Method: 采用分层框架将预测性跨层资源分配分解为战略（路由）、战术（时序）、操作（功率）三层，使决策时间尺度与预测信息精度和范围相匹配

Result: 该前瞻驱动框架实现了跨层干扰的数量级降低，为稳健可扩展的低空通信系统奠定基础

Conclusion: 预测性通信范式通过利用任务可预测性和环境模型，能够有效解决低空网络通信挑战，实现网络管理的根本性转变

Abstract: The emergence of dense, mission-driven aerial networks supporting the
low-altitude economy presents unique communication challenges, including
extreme channel dynamics and severe cross-tier interference. Traditional
reactive communication paradigms are ill-suited to these environments, as they
fail to leverage the network's inherent predictability. This paper introduces
predictive communication, a novel paradigm transforming network management from
reactive adaptation to proactive optimization. The approach is enabled by
fusing predictable mission trajectories with stable, large-scale radio
environment models (e.g., radio maps). Specifically, we present a hierarchical
framework that decomposes the predictive cross-layer resource allocation
problem into three layers: strategic (routing), tactical (timing), and
operational (power). This structure aligns decision-making timescales with the
accuracy levels and ranges of available predictive information. We demonstrate
that this foresight-driven framework achieves an order-of-magnitude reduction
in cross-tier interference, laying the groundwork for robust and scalable
low-altitude communication systems.

</details>


### [38] [Leveraging Orbital Dynamics with RF Signal Features for Satellite Multi-Orbit Proximity Threat Detection](https://arxiv.org/abs/2509.01802)
*Anouar Boumeftah,Gunes Karabulut Kurt*

Main category: eess.SP

TL;DR: 一种融合轨道机动和RF信号分析的模拟框架，通过随机森林分类器实现94.67%的净确度，有效检测占星通信中的近距干扰威胁。


<details>
  <summary>Details</summary>
Motivation: 随着密集多轨道占星组网和敌对机动的增多，近距干扰成为占星通信的新兵胁，需要有效检测和分类可疑接近操作。

Method: 集成轨道机动模型和RF信号降级分析，使用MaDDG库生成标签数据集，融合动力学特征（距离、速度、加速度、TCA）和RF指标（RSSI、通信速率、JSR），加上时间涯量和滚动统计特征。

Result: 随机森林分类器在融合特征集上达到94.67%的净确度和0.9471的宏观F1分数，显著超过仅使用动力学或RF特征的模型。

Conclusion: 该模型特别适用于检测偷播威胁，如监控或间歇性干扰，充分利用了机动和RF数据的优势，提高了占星通信安全性。

Abstract: Proximity-based interference is a growing threat to satellite communications,
driven by dense multi-orbit constellations and increasingly agile adversarial
maneuvers. We propose a hybrid simulation framework that integrates orbital
maneuver modeling with RF signal degradation analysis to detect and classify
suspicious proximity operations. Using the open-source Maneuver Detection Data
Generation (MaDDG) library from MIT Lincoln Laboratory, we generate labeled
datasets combining impulsive maneuver profiles with radio-frequency (RF)
impacts across a range of behavioral intents: routine station-keeping, covert
shadowing, and overt jamming. Our approach fuses kinematic features such as
range, velocity, acceleration, and Time of Closest Approach (TCA), with RF
metrics including Received Signal Strength Indicator (RSSI), throughput, and
Jammer-to-Signal Ratio (JSR). These features are further enhanced with temporal
derivatives and rolling-window statistics to capture subtle or transient
interference patterns. A Random Forest classifier trained on this fused feature
set achieves 94.67% accuracy and a macro F1 score of 0.9471, outperforming
models using only kinematic or RF inputs. The system is particularly effective
in detecting covert threats, such as surveillance or intermittent jamming, that
evade RF-only methods.

</details>


### [39] [Efficient River Water Level Sensing Using Cellular CSI and Joint Space-Time Processing](https://arxiv.org/abs/2509.01905)
*Khawaja Fahad Masood,Kai Wu,Zhongqin Wang,J. Andrew Zhang,Shu-Lin Chen,Y. Jay Guo*

Main category: eess.SP

TL;DR: 利用现有蜂窝通信信号，通过分析信道状态信息变化来被动监测水位变化，无需专用传感器，平均精度达1.5-3.05厘米


<details>
  <summary>Details</summary>
Motivation: 传统水位监测方法依赖专用传感器，成本高、维护难且在洪水中易损坏，需要一种更经济可靠的水位监测方案

Method: 通过分析下行移动信号的CSI变化，使用空时处理框架联合估计到达角和多普勒频移，利用波束成形技术分离和增强水面反射路径，并采用基于波束成形的补偿技术解决收发时钟不同步问题

Result: 河流现场实验表明，该方法能够实现准确可靠的水位估计，在不同接收器配置和部署情况下平均精度达到1.5-3.05厘米

Conclusion: 基于蜂窝信号的被动水位监测方法提供了一种低成本、高精度的替代方案，利用现有通信基础设施即可实现有效的水位监测

Abstract: Accurate and timely water level monitoring is critical for flood prevention,
environmental management, and emerging smart infrastructure systems.
Traditional water sensing methods often rely on dedicated sensors, which can be
costly to deploy and difficult to maintain and are vulnerable to damage during
floods.In this work, we propose a novel cellular signalbased sensing scheme
that passively estimates water level changes using downlink mobile signals from
existing communication infrastructure. By capturing subtle variations in
channel state information (CSI), the proposed method estimates the length
changes of the water-reflected signal path, which correspond to water level
variations. A space-time processing framework is developed to jointly estimate
the angle of arrival and Doppler shift, enabling isolation and enhancement of
the water-reflected path via beamforming, while effectively suppressing
environmental noise. The phase evolution of the beamformed signal is then
extracted to infer water level changes. To address clock asynchronism between
the transmitter and receiver inherent in bistatic systems, we introduce a
beamforming-based compensation technique for removing time-varying random phase
offsets in CSI. Field experiments conducted across a river demonstrate that the
proposed method enables accurate and reliable water level estimation, achieving
a mean accuracy ranging from 1.5 cm to 3.05 cm across different receiver
configurations and deployments.

</details>


### [40] [ECG-Based Stress Prediction with Power Spectral Density Features and Classification Models](https://arxiv.org/abs/2509.01923)
*Md. Mohibbul Haque Chowdhury,Nafisa Anjum,Md. Rokonuzzaman Mim*

Main category: eess.SP

TL;DR: 基于ECG信号的心律变异性分析和机器学习方法用于压力预测，CatBoost达到90%准确率，LSTM模型表现最佳达到94%准确率


<details>
  <summary>Details</summary>
Motivation: 压力已成为全球性健康问题，导致心血管疾病和抑郁症等长期疾病，需要准确可靠的压力监测系统

Method: 使用ECG信号进行功率谱密度分析获取频域特征，应用决策树、随机森林、XGBoost、LightGBM、CatBoost等机器学习模型，以及CNN和LSTM深度学习模型直接处理原始ECG信号

Result: 集成分类器效果显著，CatBoost达到90%准确率，LSTM模型表现最佳，达到94%准确率，且具有平衡的精确率、召回率和F1分数

Conclusion: 频域特征提取与先进学习算法相结合可有效提升压力预测性能，为实时医疗监测解决方案铺平道路

Abstract: Stress has emerged as a critical global health issue, contributing to
cardiovascular disorders, depression, and several other long-term illnesses.
Consequently, accurate and reliable stress monitoring systems are of growing
importance. In this work, we propose a stress prediction framework based on
electrocardiogram (ECG) signals recorded during multiple daily activities such
as sitting, walking, and jogging. Frequency-domain indicators of autonomic
nervous system activity were obtained through Power Spectral Density (PSD)
analysis and utilized as input for machine learning models including Decision
Tree, Random Forest, XGBoost, LightGBM, and CatBoost. In addition, deep
learning approaches, namely Convolutional Neural Networks (CNN) and Long
Short-Term Memory (LSTM) networks, were directly applied to the raw ECG
signals. Our experiments highlight the effectiveness of ensemble-based
classifiers, with CatBoost achieving 90% accuracy. Moreover, the LSTM model
provided superior results, attaining 94% accuracy with balanced precision,
recall, and F1-score, reflecting its strength in modeling temporal dependencies
in ECG data. Overall, the findings suggest that integrating frequency-domain
feature extraction with advanced learning algorithms enhances stress prediction
and paves the way for real-time healthcare monitoring solutions.

</details>


### [41] [On Performance of IoT Networks with Coordinated NOMA Transmission: Covert Monitoring and Information Decoding](https://arxiv.org/abs/2509.01935)
*Thai-Hoc Vu,Anh-Tu Le,Ngo Hoang Tu,Tan N. Nguyen,Miroslav Voznak*

Main category: eess.SP

TL;DR: 该论文研究Rayleigh衰落环境下物联网网络的隐蔽性和安全性能，提出基于NOMA的协调传输策略，推导了检测错误概率和安全中断概率的闭式表达式，并设计了自适应功率分配方案来最大化隐蔽速率或安全速率。


<details>
  <summary>Details</summary>
Motivation: 随着物联网设备的普及，网络隐蔽性和安全性成为关键挑战。传统方法在Rayleigh衰落环境下性能有限，需要新的传输策略来同时应对warden的监测和eavesdropper的窃听。

Method: 采用协调直接和中继传输策略结合非正交多址接入(NOMA)，推导检测错误概率和安全中断概率的闭式表达式，设计自适应功率分配方案来满足隐蔽性约束和服务质量要求。

Result: 数值结果验证了分析框架的准确性，提出的优化策略能有效调整功率分配系数，在满足隐蔽性要求和服务质量的同时，最大化隐蔽速率或安全速率。

Conclusion: 该研究为Rayleigh衰落环境下的物联网网络提供了有效的隐蔽通信和安全传输解决方案，通过NOMA和自适应功率分配实现了性能优化。

Abstract: This work investigates the covertness and security performance of
Internet-of-Things (IoTs) networks under Rayleigh fading environments.
Specifically, a cellular source transmits covert information to cell-edge users
with the assistance of an IoT master node, employing a coordinated direct and
relay transmission strategy combined with non-orthogonal multiple access
(NOMA). This approach not only enhances spectrum utilization but also generates
friendly interference to complicate a warden's surveillance or an
eavesdropper's decoding efforts. From a covertness perspective, we derive exact
closed-form expressions for the detection error probability (DEP) under
arbitrary judgment thresholds. We then identify the optimal judgment threshold
for the worst-case scenario, at which the warden minimizes its DEP performance.
Accordingly, we determine the effective region for user power allocation (PA)
in NOMA transmission that satisfies the DEP constraint. From a security
perspective, we derive analytical expressions for the secrecy outage
probability under two eavesdropping strategies using selection combining and
maximal ratio combining. Based on this analysis, we propose an adaptive PA
scheme that maximizes covert rate while ensuring the quality-of-service (QoS)
requirements of legitimate users, the system's minimum covertness requirements,
and supporting successive interference cancellation (SIC) procedures.
Furthermore, we design an adaptive PA scheme that maximizes the secrecy rate
while ensuring the QoS requirements of legitimate users and SIC conditions.
Numerical results demonstrate the accuracy of the analytical framework, while
the proposed optimization strategies effectively adjust PA coefficients to
maximize either the covert rate or the secrecy rate.

</details>


### [42] [Correlation Analysis Between MF R-Mode Temporal ASF and Meteorological Factors](https://arxiv.org/abs/2509.01958)
*Jongmin Park,Junwoo Song,Taewon Kang,Jaewon Yu,Pyo-Woong Son*

Main category: eess.SP

TL;DR: 分析气象因素与中频R-Mode导航系统中时间性ASF（附加二次因子）的相关性，探索基于气象数据预测ASF时间变化的可行性


<details>
  <summary>Details</summary>
Motivation: 随着GNSS系统脆弱性日益凸显，需要有效的备份导航系统。中频R-Mode系统虽然信号强、成本低，但需要校正受地形影响的ASF传播延迟，而传统参考站校正方法在远离参考站时效果下降

Method: 分析时间性ASF与气象因素之间的相关性，特别关注温度和湿度等气象参数

Result: 温度和湿度与时间性ASF显示出显著相关性，表明这些气象因素在ASF校正中具有潜在应用价值

Conclusion: 基于气象因素预测时间性ASF是可行的，这为改进中频R-Mode导航系统的定位精度提供了新的技术途径

Abstract: As the vulnerabilities of global navigation satellite systems (GNSS) have
become more widely recognized, the need for complementary navigation systems
has grown. Medium frequency ranging mode (MF R-Mode) has gained attention as an
effective backup system during GNSS outages, owing to its strong signal
strength and cost-effective scalability. However, to achieve accurate
positioning, MF R-Mode requires correction for the additional secondary factor
(ASF), a propagation delay affected by terrain. The temporal variation of ASF,
known as temporal ASF, is typically corrected using reference stations;
however, the effectiveness of this method decreases with distance from the
reference station. In this study, we analyzed the correlation between temporal
ASF and meteorological factors to evaluate the feasibility of predicting
temporal ASF based on meteorological factors. Among these factors, temperature
and humidity showed significant correlations with temporal ASF, suggesting
their potential utility in ASF correction.

</details>


### [43] [Dual Target-Mounted RISs-Assisted ISAC Against Eavesdropping and Malicious Interference](https://arxiv.org/abs/2509.02030)
*Zehra Yigit,Sefa Kayraklik,Ertugrul Basar,Ali Gorcin*

Main category: eess.SP

TL;DR: 基站通过双RIS协助ISAC系统，在感知两个UAV目标的同时，利用正当UAV上的RIS进行安全通信，并防范恶意UAV的监听和干扰攻击。通过SDR两阶段优化方案提高秘密速率。


<details>
  <summary>Details</summary>
Motivation: 解决ISAC与RIS融合带来的新型安全挑战，包括恶意UAV目标的监听和通过恶意RIS发起的随机干扰攻击，以保护合法用户的安全传输。

Method: 提出双目标搭载RIS的ISAC方案，构建以秘密速率最大化为目标的非凸优化问题，并采用半正定松粼(SDR)基于两阶段解决方案来优化基站发射材料矩阵和合法RIS的相位移系数。

Result: 通过大量计算机模拟评估了方案在不同系统配置下的稳健性。通信性能以秘密速率评估，感知性能通过信干比和AoD估计的CRB进行评估。

Conclusion: 该研究成功地展示了一种能够同时应对双重安全威胁的RIS协助ISAC系统，通过优化设计显著提高了系统的安全性能和感知性能。

Abstract: The synergy between integrated sensing and communication (ISAC) and
reconfigurable intelligent surfaces (RISs) unlocks novel applications and
advanced services for next-generation wireless networks, yet also introduces
new security challenges. In this study, a novel dual target-mounted
RISs-assisted ISAC scheme is proposed, where a base station with ISAC
capability performs sensing of two unmanned aerial vehicle (UAV) targets, one
of which is legitimate and the other is eavesdropper, while communicating with
the users through an RIS mounted on the legitimate UAV target. The proposed
scheme addresses dual security threats posed by a hostile UAV target:
eavesdropping on legitimate user communications and random interference attacks
launched by a malicious RIS mounted on this eavesdropper UAV target, aiming to
disrupt secure transmissions. A non-convex optimization problem maximizing the
secrecy rate of the users is formulated, and a semi-definite relaxation
(SDR)-based two-stage solution is developed to optimize the transmit
beamforming matrix of the base station and the phase shift coefficients of the
legitimate RIS. Extensive computer simulations are conducted to evaluate the
robustness of the proposed solution under various system configurations. The
proposed system's communication performance is assessed using the secrecy rate
metric, while the sensing performance is evaluated through the
signal-to-interference-plus-noise ratio and the Cramer-Rao bound (CRB) for
angle-of-departure (AoD) estimation of the eavesdropper UAV target.

</details>


### [44] [Synesthesia of Machines (SoM)-Based Task-Driven MIMO System for Image Transmission](https://arxiv.org/abs/2509.02031)
*Sijiang Li,Rongqing Zhang,Xiang Cheng,Jian Tang*

Main category: eess.SP

TL;DR: 提出SoM-MIMO系统，通过结合特征金字塔结构和闭环MIMO信道特性，实现高效鲁棒的图像传输，在保持相同通信开销下显著提升目标检测性能


<details>
  <summary>Details</summary>
Motivation: 现有MIMO JSCC方案在支持网络移动代理复杂协同感知任务时性能有限，需要开发更高效鲁棒的图像传输方案

Method: 基于机器联觉(SoM)框架，利用特征金字塔的结构特性和闭环MIMO系统的信道特性，设计任务驱动的数字MIMO传输系统

Result: 相比两种JSCC基线方案，在所有SNR水平下平均mAP分别提升6.30和10.48，同时保持相同通信开销

Conclusion: SoM-MIMO系统能够为网络移动代理的协同感知提供高效鲁棒的图像传输解决方案

Abstract: To support cooperative perception (CP) of networked mobile agents in dynamic
scenarios, the efficient and robust transmission of sensory data is a critical
challenge. Deep learning-based joint source-channel coding (JSCC) has
demonstrated promising results for image transmission under adverse channel
conditions, outperforming traditional rule-based codecs. While recent works
have explored to combine JSCC with the widely adopted multiple-input
multiple-output (MIMO) technology, these approaches are still limited to the
discrete-time analog transmission (DTAT) model and simple tasks. Given the
limited performance of existing MIMO JSCC schemes in supporting complex CP
tasks for networked mobile agents with digital MIMO communication systems, this
paper presents a Synesthesia of Machines (SoM)-based task-driven MIMO system
for image transmission, referred to as SoM-MIMO. By leveraging the structural
properties of the feature pyramid for perceptual tasks and the channel
properties of the closed-loop MIMO communication system, SoM-MIMO enables
efficient and robust digital MIMO transmission of images. Experimental results
have shown that compared with two JSCC baseline schemes, our approach achieves
average mAP improvements of 6.30 and 10.48 across all SNR levels, while
maintaining identical communication overhead.

</details>


### [45] [Environment-Aware Channel Measurement and Modeling for Terahertz Monostatic Sensing](https://arxiv.org/abs/2509.02088)
*Yejian Lyu,Zhiqiang Yuan,Henk Wymeersch,Chong Han*

Main category: eess.SP

TL;DR: 该研究基于300GHz频段的室内测量数据，提出了一个环境感知的太赫兹集成传感与通信信道建模框架，能够从信道特性中可靠提取物理场景的结构和材料信息。


<details>
  <summary>Details</summary>
Motivation: 太赫兹频段的集成传感与通信系统需要现实且可解释的信道建模来充分发挥其高精度环境感知和超高速无线连接的潜力。

Method: 在三个代表性室内场景的57个收发器位置进行测量，使用高分辨率SAGE算法提取多径参数，采用基于图像处理的CCL聚类方法对多径分量进行分组，建立物理场景属性与信道特性之间的映射关系。

Result: 实验结果表明，所提出的方法能够从观测到的信道特性中可靠地提取物理特征（如结构和材料信息），为先进的太赫兹ISAC信道建模提供了有前景的基础。

Conclusion: 该研究提出的环境感知信道建模框架成功地将物理场景属性与信道域表现联系起来，为太赫兹集成传感与通信系统的实际应用提供了重要的建模基础。

Abstract: Integrated sensing and communication (ISAC) at terahertz (THz) frequencies
holds significant promise for unifying ultra-high-speed wireless connectivity
with fine-grained environmental awareness. Realistic and interpretable channel
modeling is essential to fully realize the potential of such systems. This work
presents a comprehensive investigation of monostatic sensing channels at
300~GHz, based on an extensive measurement campaign conducted at 57 co-located
transceiver (TRx) positions across three representative indoor scenarios.
Multipath component (MPC) parameters, including amplitude, delay, and angle,
are extracted using a high-resolution space-alternating generalized
expectation-maximization (SAGE) algorithm. To cluster the extracted MPCs, an
image-processing-based clustering method, i.e., connected component labeling
(CCL), is applied to group MPCs based on delay-angle consistency. Based on the
measurement data, an environment-aware channel modeling framework is proposed
to establish mappings between physical scenario attributes (e.g., reflector
geometry, surface materials, and roughness) and their corresponding
channel-domain manifestations. The framework incorporates both specular and
diffuse reflections and leverages several channel parameters, e.g., reflection
loss, Lambertian scattering, and intra-cluster dispersion models, to
characterize reflection behavior. Experimental results demonstrate that the
proposed approach can reliably extract physical characteristics, e.g.,
structural and material information, from the observed channel characteristics,
offering a promising foundation for advanced THz ISAC channel modeling.

</details>


### [46] [Affine-Doppler Division Multiplexing for High-Mobility Wireless Communications Systems](https://arxiv.org/abs/2509.02116)
*Yuanfang Ma,Zulin Wang,Peng Yuan,Qin Huang,Yuanhan Ni*

Main category: eess.SP

TL;DR: ADDM是一种新的正交多载波波形，为OTFS和AFDM提供统一框架，兼具两者的优势，在高移动性场景下性能优于OTFS，与AFDM相当。


<details>
  <summary>Details</summary>
Motivation: AFDM和OTFS波形互不兼容，针对OTFS设计的先进方法无法直接应用于AFDM，需要一种通用框架来统一这两种波形。

Method: 提出Affine-Doppler Division Multiplexing (ADDM)，基于二维变换在Affine-Doppler域调制信息符号，实现二维循环移位特性。

Result: ADDM具有优异的无模糊多普勒和多普勒分辨率，与AFDM相当但优于OTFS；数值结果显示在高移动性场景下BER性能与AFDM相当但优于OTFS。

Conclusion: ADDM提供了一个通用框架，能够直接应用针对OTFS和AFDM设计的先进方法，实现了波形技术的统一和性能优化。

Abstract: Affine Frequency Division Multiplexing (AFDM) has been regarded as a
candidate integrated sensing and communications (ISAC) waveform owing to its
superior communication performance, outperforming the Orthogonal Time-Frequency
Space (OTFS) that has been researched for a longer time. However, since the
above two waveforms are incompatible with each other, the state-of-the-art
methods well-designed for OTFS may not be directly applicable to AFDM. This
paper introduces a new orthogonal multicarrier waveform, namely Affine-Doppler
Division Multiplexing (ADDM), which can provide a generic framework and subsume
the existing OTFS and AFDM as a particular case. ADDM modulating information
symbols in the Affine-Doppler (A-D) domain based on a two-dimensional (2D)
transform can enjoy both excellent unambiguous Doppler and Doppler resolution,
which is the same as AFDM but outperforms OTFS. Moreover, benefiting from the
2D transform, the symbols block of ADDM in the A-D domain undergoes a 2D cyclic
shift produced by the delay and the Doppler of the channel, similar to the 2D
cyclic shift in the delay-Doppler domain of cyclic prefix (CP)-OTFS. This
offers a potential to directly apply the state-of-the-art methods well-designed
for OTFS and AFDM to ADDM. Numerical results show that ADDM achieves comparable
BER performance with AFDM but outperforms OTFS in high-mobility scenarios.

</details>


### [47] [High-Resolution Sensing in Communication-Centric ISAC: Deep Learning and Parametric Methods](https://arxiv.org/abs/2509.02137)
*Salmane Naoumi,Ahmad Bazzi,Roberto Bomfin,Marwa Chafii*

Main category: eess.SP

TL;DR: 提出了两种新算法IFFT-C2VNN和PARAMING，用于双站ISAC系统中的超分辨率传感参数估计，利用通信参考符号的CSI信息，在降低计算复杂度的同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 解决通信中心ISAC系统中双站配置下的超分辨率传感参数估计挑战，利用现有的通信信道状态信息实现传感功能，避免额外硬件成本。

Method: IFFT-C2VNN使用复值卷积神经网络估计目标参数，大幅降低计算复杂度；PARAMING采用参数化方法，利用系统模型知识（收发阵列几何结构）精确提取传感参数。

Result: 通过全面的性能分析，证明两种算法在不同信噪比下都具有有效性和鲁棒性，适用于实际ISAC场景。

Conclusion: 两种算法都能有效实现超分辨率传感参数估计，IFFT-C2VNN在计算效率上有优势，PARAMING在模型准确性上表现优异，为ISAC系统提供了实用的解决方案。

Abstract: This paper introduces two novel algorithms designed to address the challenge
of super-resolution sensing parameter estimation in bistatic configurations
within communication-centric integrated sensing and communication (ISAC)
systems. Our approach leverages the estimated channel state information derived
from reference symbols originally intended for communication to achieve
super-resolution sensing parameter estimation. The first algorithm, IFFT-C2VNN,
employs complex-valued convolutional neural networks to estimate the parameters
of different targets, achieving significant reductions in computational
complexity compared to traditional methods. The second algorithm, PARAMING,
utilizes a parametric method that capitalizes on the knowledge of the system
model, including the transmit and receive array geometries, to extract the
sensing parameters accurately. Through a comprehensive performance analysis, we
demonstrate the effectiveness and robustness of both algorithms across a range
of signal-to-noise ratios, underscoring their applicability in realistic ISAC
scenarios.

</details>


### [48] [Beamforming Design for Pinching Antenna Systems with Multiple Receive Antennas](https://arxiv.org/abs/2509.02166)
*Enzhi Zhou,Yue Xiao,Ziyue Liu,Sotiris A. Tegos,Panagiotis D. Diamantoulakis,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 本文提出了一个针对多天线用户的下行链路pinching天线系统(PAS)建模框架，通过两层放置策略优化天线位置，在NLoS条件下显著提升性能


<details>
  <summary>Details</summary>
Motivation: 下一代网络需要智能鲁棒的信道条件来支持超高数据速率和动态环境中的大规模设备部署。现有柔性天线技术重构范围有限且结构刚性，难以有效恢复视距链路

Method: 首先推导接收信噪比与pinching天线位置的解析关系，然后提出两层放置策略：基于大尺度信道特性优化中心辐射点，使用启发式压缩放置算法近似多接收天线的相位对齐并选择空间紧凑的激活元件集

Result: 仿真结果显示相比传统单天线方案有显著性能提升，特别是在短距离场景、密集PA和用户天线间距较大的情况下

Conclusion: PAS系统作为补充解决方案，在挑战性传播环境特别是NLoS条件下提供了增强的灵活性，所提出的建模框架和放置策略有效解决了现有文献中未充分探索的实际场景

Abstract: Next-generation networks require intelligent and robust channel conditions to
support ultra-high data rates, seamless connectivity, and large-scale device
deployments in dynamic environments. While flexible antenna technologies such
as fluid and movable antennas offer some degree of adaptability, their limited
reconfiguration range and structural rigidity reduce their effectiveness in
restoring line-of-sight (LoS) links. As a complementary solution, pinching
antenna systems (PASs) enable fine-grained, hardware-free control of radiation
locations along a waveguide, offering enhanced flexibility in challenging
propagation environments, especially under non-LoS (NLoS) conditions. This
paper introduces a general and novel modeling framework for downlink PASs
targeting users equipped with multiple receive antennas, addressing a practical
yet underexplored scenario in the existing literature. Specifically, we first
derive an analytical relationship between the received signal-to-noise ratio
and the pinching antenna (PA) positions, and based on this, we propose a
two-layer placement strategy. First, we optimize the central radiation point
using large-scale channel characteristics, and then we use a heuristic
compressed placement algorithm to approximate phase alignment across multiple
receive antennas and select a spatially compact set of active elements.
Simulation results demonstrate notable performance gains over conventional
single-antenna schemes, particularly in short-range scenarios with dense PAs
and widely spaced user antennas.

</details>


### [49] [Dual-end Fluid Antennas For Robust Anti-jamming in Low-altitude Air-ground Communications](https://arxiv.org/abs/2509.02260)
*Yifan Guo,Junshan Luo,Fanggang Wang,Haiyang Ding,Shilian Wang,Zhenhai Xu*

Main category: eess.SP

TL;DR: 提出基于流体天线系统的异构双层传输架构，解决低空空地通信中的同频干扰和恶意干扰问题，通过天线位置优化实现信号增强和干扰抑制的动态平衡。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线系统缺乏空间适应性，无法在动态环境中有效平衡信号增强和干扰抑制，特别是在低空空地通信面临同频干扰和恶意干扰的挑战下。

Method: 采用流体天线系统辅助的异构双层传输架构，提出分数规划-块坐标下降算法，交替优化发射预编码器、接收组合器和收发两端的天线位置，使用凸包方法和几何边界方法处理干扰不确定性和天线放置约束。

Result: 仿真验证显示显著性能提升，流体天线系统在同等功率约束下比固定位置天线系统数据率提高高达56%，天线重定位策略有效增强信号质量并抑制干扰。

Conclusion: 流体天线系统通过动态天线位置优化，在复杂干扰环境下实现了鲁棒的性能提升，为空地通信提供了有效的干扰抑制解决方案。

Abstract: This paper addresses the challenge of co-channel interference and intentional
jamming in low-altitude air-ground communications. Since conventional
fixed-position antenna (FPA) systems lack spatial adaptability to dynamically
balance signal enhancement against interference suppression, we propose a
transformative fluid antenna system (FAS)-assisted heterogeneous dual-layer
transmission architecture. Specifically, a terrestrial base station with FPA
serves ground users, while a low altitude-serving base station equipped with
FAS communicates with the aerial user, also equipped with FAS, under the attack
of a malicious jammer. We formulate a worst-case achievable rate maximization
problem for aerial user subject to constraints including quality-of-service for
terrestrial users, imperfect jamming directions, minimum antenna separation,
etc. To address the non-convex problem, we propose a fractional
programming-block coordinate descent algorithm that alternately optimizes the
transmit precoders, receive combiner, and antenna positions at both transceiver
sides. Convex hull-based approach and geometric boundary method are used to
handle the jamming uncertainty and antenna placement constraints in confined
spatial regions, respectively. Extensive simulations validate significant
performance gains. The FAS achieves up to 56\% higher data rates than FPA under
equivalent power constraints. Strategic antenna repositioning demonstrably
enhances signal quality while suppressing interference, maintaining robustness
across diverse jammer channel uncertainties.

</details>


### [50] [Interference Management for Integrated Sensing and Communications: A Multiple Access Perspective](https://arxiv.org/abs/2509.02352)
*Kexin Chen,Yijie Mao,Wonjae Shin,Bruno Clerckx,Christos Masouros*

Main category: eess.SP

TL;DR: 本文是第一篇关于多址接入技术在ISAC网络中应用的全面教程，分析了不同MA技术（OMA、SDMA、NOMA、RSMA）在ISAC系统中的干扰管理和波形设计作用


<details>
  <summary>Details</summary>
Motivation: ISAC技术在6G网络中面临多种干扰挑战，需要借鉴无线通信发展中的多址接入技术来有效管理用户间干扰和功能间干扰

Method: 通过分类ISAC系统中的干扰类型，比较不同多址接入技术辅助的ISAC设计方案，分析各自的优势和局限性

Result: 展示了多址接入技术与ISAC的互利集成关系：ISAC帮助MA技术超越纯通信网络发挥干扰管理能力，而MA技术为ISAC提供有效的干扰管理解决方案

Conclusion: 多址接入技术在ISAC网络中具有重要应用前景，本文为未来研究和新兴应用方向提供了展望和指导

Abstract: The integrated sensing and communication (ISAC) technique has been considered
a key enabler for 6G radio access networks. ISAC fulfills a brand new paradigm
shift in wireless networks via the seamless interplay between communication and
sensing within a unified network. However, the tight integration of these
functionalities inevitably gives rise to various types of interference, posing
significant challenges to existing ISAC waveform designs and rendering
interference management a critical concern. Inspired by the development
trajectory of wireless communications, different multiple access (MA)
techniques, such as orthogonal multiple access (OMA), space-division multiple
access (SDMA), and more recently, non-orthogonal multiple access (NOMA) and
rate-splitting multiple access (RSMA), have been demonstrated to play a pivotal
role in efficiently utilizing limited spectrum resources, designing ISAC
waveforms, as well as managing inter-user interference and inter-functionality
interference in ISAC. Notably, the interplay between MA and ISAC presents
mutually beneficial integration. On the one hand, ISAC helps MA techniques
better exploit their interference management capability beyond the
communication-only networks. On the other hand, different MA techniques serve
as promising solutions for inter-functionality and inter-user interference
management in ISAC. In this paper, we deliver the first comprehensive tutorial
of MA techniques in ISAC networks. Specifically, we illustrate the fundamental
principles of ISAC, classify the diverse types of interference in different
ISAC systems, and compare MA-assisted ISAC designs, highlighting their
respective advantages and limitations. Moreover, we provide an outlook on the
emerging applications and future research directions of different MA-assisted
ISAC.

</details>


### [51] [Know What, Know Why: Semantic Hazard Communication for Intelligent V2X Systems](https://arxiv.org/abs/2509.02442)
*Chen Sun,Wenqi Zhang,Bizhu Wang,Xiaodong Xu,Chau Yuen,Yan Zhang,Ping Zhang*

Main category: eess.SP

TL;DR: 提出语义增强的可解释V2X系统(SEE-V2X)，通过提供上下文警告信息来改善交通效率和减少不必要的减速


<details>
  <summary>Details</summary>
Motivation: 当前V2X系统只播放简短警告消息，缺乏上下文信息，导致司机过度谨慎或驾驶效率低下

Method: 在RSU中配备智能摄像头检测障碍物，传输具有上下文意义的消息，并实现"透视"功能显示障碍物后方的行人

Result: 通过实际演示和模拟对比，SEE-V2X在不同交通条件下显著提高交通效率并减少不必要的减速

Conclusion: 语义增强和可解释的V2X系统能够使驾驶员做出更智能的驾驶决策，提升交通安全性和效率

Abstract: In current vehicle-to-everything (V2X) communication systems, roadside units
(RSUs) broadcast brief warning messages that alert nearby vehicles to avoid
potential hazards. However, these messages lack contextual information on why a
warning is issued, leading to excessive caution or inefficient driving
behaviors. To avoid such a situation, we propose a semantic-enhanced and
explainable V2X (SEE-V2X) system. In the proposed system, RSUs equipped with
smart cameras detect obstructions and transmit context-aware messages to
vehicles. By understanding both what the hazard is and why it occurs, drivers
can make more intelligent decisions based on their specific driving situation.
Furthermore, through a real-field demonstration, we show the new "see-through"
feature in the proposed system, which enables drivers to visualize hidden
pedestrians behind obstacles. We also perform simulations to compare
traditional V2X with SEE-V2X under different traffic conditions. The results
show that SEE-V2X significantly improves traffic efficiency and reduces
unnecessary deceleration.

</details>


### [52] [LLM-Enhanced Space-Air-Ground-Sea Integrated Networks](https://arxiv.org/abs/2509.02540)
*Halvin Yang,Sangarapillai Lambotharan,Mahsa Derakhshani,Lajos Hanzo*

Main category: eess.SP

TL;DR: 使用单一大型语言模型(LLM)作为统一的数据驱动适应层，解决空天地海一体化网络中的CSI快速老化和带宽差异问题，通过长距离信道预测和语义编码实现跨介质通信优化。


<details>
  <summary>Details</summary>
Motivation: 空天地海一体化网络(SAGSIN)面临两个主要挑战：高速移动平台导致的信道状态信息(CSI)快速老化，以及协议栈中从太比特光链路到千比特水声链路的极端数据率差异。

Method: 采用联合训练在无线电、光学和声学轨迹上的单一LLM骨干网络，实现：1）基于LLM的长距离信道预测器，提前预测最强时延-多普勒分量；2）基于LLM的语义编码器，将原始传感器有效载荷转换为面向任务的令牌。

Result: 该方法能够：1）在剧烈信道波动下实现接近容量的接收性能；2）显著降低沿海水下链路高保真图像传输所需的信噪比，通过语义通信规避数据率限制。

Conclusion: 创建了一个跨无线电、光学和声学通道的介质无关适应层，为从实验室原型到现场部署指明了道路，并提出了设备上模型压缩、多模态保真度控制、跨层资源编排和可信操作等有前景的研究方向。

Abstract: The space-air-ground-sea integrated networking (SAGSIN) concept promises
seamless global multimedia connectivity, yet two obstacles still limit its
practical deployment. Firstly, high-velocity satellites, aerial relays and
sea-surface platforms suffer from obsolete channel state information (CSI),
undermining feedback-based adaptation. Secondly, data-rate disparity across the
protocol stack is extreme: terabit optical links in space coexist with kilobit
acoustic under-water links. This article shows that a single large language
model (LLM) backbone, trained jointly on radio, optical and acoustic traces,
can provide a unified, data-driven adaptation layer that addresses both rapid
CSI ageing and severe bandwidth disparity across the SAGSIN protocol stack.
Explicitly, an LLM-based long-range channel predictor forecasts the strongest
delay-Doppler components several coherence intervals ahead, facilitating
near-capacity reception despite violent channel fluctuations. Furthermore, our
LLM-based semantic encoder turns raw sensor payloads into task-oriented tokens.
This substantially reduces the SNR required for high-fidelity image delivery in
a coastal underwater link, circumventing the data rate limitation by semantic
communications. Inclusion of these tools creates a medium-agnostic adaptation
layer that spans radio, optical and acoustic channels. We conclude with
promising open research directions in on-device model compression, multimodal
fidelity control, cross-layer resource orchestration and trustworthy operation,
charting a path from laboratory prototypes to field deployment.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [53] [DeepEmoNet: Building Machine Learning Models for Automatic Emotion Recognition in Human Speeches](https://arxiv.org/abs/2509.00025)
*Tai Vu*

Main category: eess.AS

TL;DR: 使用机器学习方法进行语音情感识别，通过SVM、LSTM、CNN等模型，结合迁移学习和数据增强技术，在较小数据集上取得了良好性能


<details>
  <summary>Details</summary>
Motivation: 语音情感识别是语音处理研究中的挑战性问题，因为人类情感与声音的各种成分（如音调、响度、能量）之间的关系尚不明确

Method: 构建了多种机器学习模型（SVM、LSTM、CNN），采用迁移学习和数据增强技术，在相对较小的数据集上进行高效训练

Result: 最佳模型ResNet34网络达到了66.7%的准确率和0.631的F1分数

Conclusion: 机器学习方法结合迁移学习和数据增强技术可以有效解决语音情感识别问题，即使在数据集较小的情况下也能获得不错的性能

Abstract: Speech emotion recognition (SER) has been a challenging problem in spoken
language processing research, because it is unclear how human emotions are
connected to various components of sounds such as pitch, loudness, and energy.
This paper aims to tackle this problem using machine learning. Particularly, we
built several machine learning models using SVMs, LTSMs, and CNNs to classify
emotions in human speeches. In addition, by leveraging transfer learning and
data augmentation, we efficiently trained our models to attain decent
performances on a relatively small dataset. Our best model was a ResNet34
network, which achieved an accuracy of $66.7\%$ and an F1 score of $0.631$.

</details>


### [54] [Amplifying Emotional Signals: Data-Efficient Deep Learning for Robust Speech Emotion Recognition](https://arxiv.org/abs/2509.00077)
*Tai Vu*

Main category: eess.AS

TL;DR: 该论文通过迁移学习和数据增强技术，在有限数据集上开发了多种机器学习模型用于语音情感识别，其中ResNet34架构在RAVDESS和SAVEE数据集上取得了66.7%的准确率和0.631的F1分数，创下了新的性能基准。


<details>
  <summary>Details</summary>
Motivation: 语音情感识别在人机交互中具有重要意义，但深度学习在有限数据集上实现高性能仍然是一个关键挑战。论文旨在解决数据稀缺问题，开发能够在有限数据集上表现优异的语音情感分类模型。

Method: 开发并评估了多种机器学习模型，包括支持向量机(SVM)、长短期记忆网络(LSTM)和卷积神经网络(CNN)。战略性地采用迁移学习和创新的数据增强技术来克服数据限制。

Result: 最有效的ResNet34架构在RAVDESS和SAVEE组合数据集上取得了66.7%的准确率和0.631的F1分数，建立了新的性能基准。

Conclusion: 研究结果强调了利用预训练模型和数据增强来克服数据稀缺的显著优势，为开发更强大和可泛化的语音情感识别系统铺平了道路。

Abstract: Speech Emotion Recognition (SER) presents a significant yet persistent
challenge in human-computer interaction. While deep learning has advanced
spoken language processing, achieving high performance on limited datasets
remains a critical hurdle. This paper confronts this issue by developing and
evaluating a suite of machine learning models, including Support Vector
Machines (SVMs), Long Short-Term Memory networks (LSTMs), and Convolutional
Neural Networks (CNNs), for automated emotion classification in human speech.
We demonstrate that by strategically employing transfer learning and innovative
data augmentation techniques, our models can achieve impressive performance
despite the constraints of a relatively small dataset. Our most effective
model, a ResNet34 architecture, establishes a new performance benchmark on the
combined RAVDESS and SAVEE datasets, attaining an accuracy of 66.7% and an F1
score of 0.631. These results underscore the substantial benefits of leveraging
pre-trained models and data augmentation to overcome data scarcity, thereby
paving the way for more robust and generalizable SER systems.

</details>


### [55] [ChipChat: Low-Latency Cascaded Conversational Agent in MLX](https://arxiv.org/abs/2509.00078)
*Tatiana Likhomanenko,Luke Carlson,Richard He Bai,Zijin Gu,Han Tran,Zakaria Aldeneh,Yizhe Zhang,Ruixiang Zhang,Huangjie Zheng,Navdeep Jaitly*

Main category: eess.AS

TL;DR: ChipChat是一个创新的低延迟级联语音对话系统，通过架构创新和流式优化在Mac Studio上实现亚秒级响应，完全在设备上处理以保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型改变了语音对话系统，但实时设备端语音代理的最佳架构仍存在问题。端到端方法虽有理论优势，但级联系统在语言理解任务中表现更好，尽管受到顺序处理延迟的限制。

Method: 提出ChipChat系统，集成流式对话语音识别（使用专家混合）、状态-动作增强的LLM、文本到语音合成、神经声码器和说话人建模。使用MLX实现，在无专用GPU的Mac Studio上运行。

Result: 系统实现了亚秒级响应延迟，完全在设备上处理，保护用户隐私。重新设计的级联系统能够克服传统延迟限制。

Conclusion: 战略性重新设计的级联系统可以克服历史延迟限制，为实用的基于语音的AI代理提供了有前景的发展路径。

Abstract: The emergence of large language models (LLMs) has transformed spoken dialog
systems, yet the optimal architecture for real-time on-device voice agents
remains an open question. While end-to-end approaches promise theoretical
advantages, cascaded systems (CSs) continue to outperform them in language
understanding tasks, despite being constrained by sequential processing
latency. In this work, we introduce ChipChat, a novel low-latency CS that
overcomes traditional bottlenecks through architectural innovations and
streaming optimizations. Our system integrates streaming (a) conversational
speech recognition with mixture-of-experts, (b) state-action augmented LLM, (c)
text-to-speech synthesis, (d) neural vocoder, and (e) speaker modeling.
Implemented using MLX, ChipChat achieves sub-second response latency on a Mac
Studio without dedicated GPUs, while preserving user privacy through complete
on-device processing. Our work shows that strategically redesigned CSs can
overcome their historical latency limitations, offering a promising path
forward for practical voice-based AI agents.

</details>


### [56] [Automatic Pronunciation Error Detection and Correction of the Holy Quran's Learners Using Deep Learning](https://arxiv.org/abs/2509.00094)
*Abdullah Abdelfattah,Mahmoud I. Khalil,Hazem Abbas*

Main category: eess.AS

TL;DR: 这篇论文提出了一种自动化管道来生成高质量的可兰置读组数据集，包含850+小时音频和新题ASR方法用于可兰置读声语评估。使用自定义的可兰置音义脚本(QPS)编码音位规则，并开源了代码、数据和模型。


<details>
  <summary>Details</summary>
Motivation: 虽然可兰置读有严格的音位规则(tajweed)便于评估，但高质量注释数据的缺乏仍是重要障碍。需要解决语音评估的挑战和机器学习模型评量难题。

Method: (1)建立98%自动化的高质量数据集生成管道：收集专家读音、使用细调wav2vec2-BERT模型进行停顶分割、转写、Tasmeea算法验证；(2)使用自定义可兰置音义脚本(QPS)编码音位规则；(3)新题多层次CTC模型进行模式建模。

Result: 生成了850+小时音频（约300K注释语句）。新题多层次CTC模型在测试集上达到平均0.16%的音素错误率(PER)。

Conclusion: 该研究为可兰置语音评估提供了高质量的数据集和有效的方法，通过自动化管道和自定义音义脚本成功解决了数据缺乏问题，为令人语音评估提供了有价值的参考。

Abstract: Assessing spoken language is challenging, and quantifying pronunciation
metrics for machine learning models is even harder. However, for the Holy
Quran, this task is simplified by the rigorous recitation rules (tajweed)
established by Muslim scholars, enabling highly effective assessment. Despite
this advantage, the scarcity of high-quality annotated data remains a
significant barrier.
  In this work, we bridge these gaps by introducing: (1) A 98% automated
pipeline to produce high-quality Quranic datasets -- encompassing: Collection
of recitations from expert reciters, Segmentation at pause points (waqf) using
our fine-tuned wav2vec2-BERT model, Transcription of segments, Transcript
verification via our novel Tasmeea algorithm; (2) 850+ hours of audio (~300K
annotated utterances); (3) A novel ASR-based approach for pronunciation error
detection, utilizing our custom Quran Phonetic Script (QPS) to encode Tajweed
rules (unlike the IPA standard for Modern Standard Arabic). QPS uses a
two-level script: (Phoneme level): Encodes Arabic letters with short/long
vowels. (Sifa level): Encodes articulation characteristics of every phoneme. We
further include comprehensive modeling with our novel multi-level CTC Model
which achieved 0.16% average Phoneme Error Rate (PER) on the testset. We
release all code, data, and models as open-source:
https://obadx.github.io/prepare-quran-dataset/

</details>


### [57] [Quantum-Enhanced Analysis and Grading of Vocal Performance](https://arxiv.org/abs/2509.00106)
*Rohan Agarwal*

Main category: eess.AS

TL;DR: QuantumMelody是一种混合量子经典方法，用于客观歌唱评估，通过量子电路处理声乐特征，结合频谱图变换器嵌入，在168个标注样本上达到74.29%的专家评分一致性。


<details>
  <summary>Details</summary>
Motivation: 开发可解释的、客观的歌唱评估方法，应用于音频信号处理领域，解决传统方法在歌唱技术评估方面的局限性。

Method: 将声乐特征（音高稳定性、动态、音色）编码到9量子比特模拟电路中，使用Hadamard门初始化和Rx/Ry/Rz旋转，结合组内和组间纠缠，将量子电路测量概率与频谱图变换器嵌入融合进行评分。

Result: 在168个20秒标注片段上，混合方法达到74.29%的专家评分一致性，相比经典特征基线提升12.86个百分点，在笔记本电脑级Qiskit模拟器上处理时间低于1分钟。

Conclusion: 这是向可解释、客观歌唱评估迈出的可行性步骤，虽然未声称硬件加速优势，但证明了量子经典混合方法在音频处理中的应用潜力。

Abstract: We present QuantumMelody, a hybrid quantum-classical method for objective
singing assessment. Grouped vocal features (pitch stability, dynamics, timbre)
are encoded into a small simulated quantum circuit; all nine qubits are
initialized with a Hadamard on each qubit and then receive Rx, Ry, and Rz
rotations, with intra- and cross-group entanglement. The circuit measurement
probabilities are fused with spectrogram transformer embeddings to estimate a
grade on labels 2-5 and to surface technique-level feedback. On 168 labeled 20
second excerpts, the hybrid reaches 74.29% agreement with expert graders, a
+12.86 point gain over a classical-features baseline. Processing is sub-minute
per recording on a laptop-class Qiskit simulator; we do not claim hardware
speedups. This is a feasibility step toward interpretable, objective singing
assessment in applied audio signal processing.

</details>


### [58] [Deep Learning for Personalized Binaural Audio Reproduction](https://arxiv.org/abs/2509.00400)
*Xikun Lu,Yunda Chen,Zehua Chen,Jie Wang,Mingxing Liu,Hongmei Hu,Chengshi Zheng,Stefan Bleeck,Jinqiu Sang*

Main category: eess.AS

TL;DR: 本文综述了深度学习在个性化双耳音频生成中的最新进展，主要分为显式个性化滤波和端到端渲染两种范式，并总结了相关数据集、评估方法和应用前景。


<details>
  <summary>Details</summary>
Motivation: 个性化双耳音频再现是实现真实空间定位、声音外化和沉浸式聆听的基础，直接影响用户体验和聆听效果。深度学习技术为该领域带来了新的突破机会。

Method: 将方法分为两类：1) 显式个性化滤波 - 从稀疏测量、形态特征或环境线索预测个性化头相关传递函数(HRTFs)；2) 端到端渲染 - 直接将源信号映射到双耳信号，利用视觉、文本或参数化指导，在模型内部学习个性化。

Result: 综述了该领域的主要数据集和评估指标，支持公平和可重复的比较。总结了深度学习技术实现的关键应用。

Conclusion: 讨论了当前技术局限性，并提出了基于深度学习的空间音频系统的潜在研究方向，包括改进个性化效果、提升渲染质量和扩展应用场景。

Abstract: Personalized binaural audio reproduction is the basis of realistic spatial
localization, sound externalization, and immersive listening, directly shaping
user experience and listening effort. This survey reviews recent advances in
deep learning for this task and organizes them by generation mechanism into two
paradigms: explicit personalized filtering and end-to-end rendering. Explicit
methods predict personalized head-related transfer functions (HRTFs) from
sparse measurements, morphological features, or environmental cues, and then
use them in the conventional rendering pipeline. End-to-end methods map source
signals directly to binaural signals, aided by other inputs such as visual,
textual, or parametric guidance, and they learn personalization within the
model. We also summarize the field's main datasets and evaluation metrics to
support fair and repeatable comparison. Finally, we conclude with a discussion
of key applications enabled by these technologies, current technical
limitations, and potential research directions for deep learning-based spatial
audio systems.

</details>


### [59] [Speaker-Conditioned Phrase Break Prediction for Text-to-Speech with Phoneme-Level Pre-trained Language Model](https://arxiv.org/abs/2509.00675)
*Dong Yang,Yuki Saito,Takaaki Saeki,Tomoki Koriyama,Wataru Nakata,Detai Xin,Hiroshi Saruwatari*

Main category: eess.AS

TL;DR: 本文提出了一种改进多说话人TTS系统中短语断句预测的方法，通过集成说话人嵌入特征和应用音素级预训练语言模型，显著提升了断句模型的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的多说话人TTS系统在短语断句预测方面存在不足，需要更好地捕捉说话人特异性特征，并探索预训练模型在该任务中的应用潜力。

Method: 1. 利用说话人嵌入集成说话人特异性特征；2. 通过少样本适应方法探索预训练说话人嵌入对未见说话人的适用性；3. 首次将音素级预训练语言模型应用于TTS前端任务。

Result: 方法经过客观和主观评估验证，证明能够显著提升断句模型的性能，说话人嵌入能够仅从断句任务中捕捉说话人相关特征。

Conclusion: 所提出的方法有效提升了多说话人TTS系统的短语断句预测性能，为TTS前端任务提供了新的技术路径。

Abstract: This paper advances phrase break prediction (also known as phrasing) in
multi-speaker text-to-speech (TTS) systems. We integrate speaker-specific
features by leveraging speaker embeddings to enhance the performance of the
phrasing model. We further demonstrate that these speaker embeddings can
capture speaker-related characteristics solely from the phrasing task. Besides,
we explore the potential of pre-trained speaker embeddings for unseen speakers
through a few-shot adaptation method. Furthermore, we pioneer the application
of phoneme-level pre-trained language models to this TTS front-end task, which
significantly boosts the accuracy of the phrasing model. Our methods are
rigorously assessed through both objective and subjective evaluations,
demonstrating their effectiveness.

</details>


### [60] [MPO: Multidimensional Preference Optimization for Language Model-based Text-to-Speech](https://arxiv.org/abs/2509.00685)
*Kangxiang Xia,Xinfa Zhu,Jixun Yao,Lei Xie*

Main category: eess.AS

TL;DR: 提出了多维偏好优化(MPO)方法，通过构建多维偏好数据集和引入正则化，解决TTS系统中多维度偏好优化和奖励过度自信的问题，在可懂度、说话人相似性和韵律方面显著优于基线系统。


<details>
  <summary>Details</summary>
Motivation: 当前基于大语言模型的TTS系统虽然取得了人声级别的质量，但在利用偏好数据进行多维度优化时面临挑战，且DPO方法存在因奖励过度自信导致的性能下降问题。

Method: 提出多维偏好优化(MPO)框架，包括构建多维偏好数据集来简化多维度偏好优化数据准备，并在训练过程中引入正则化机制来解决DPO方法的性能退化问题。

Result: 实验证明MPO方法在可懂度、说话人相似性和韵律等多个维度上都显著优于基线系统，有效提升了TTS系统的整体性能。

Conclusion: MPO方法成功解决了TTS系统中多维度偏好优化的挑战，通过创新的数据集构建和正则化技术，实现了更好的与人类偏好对齐，为TTS系统的进一步发展提供了有效解决方案。

Abstract: In recent years, text-to-speech (TTS) has seen impressive advancements
through large-scale language models, achieving human-level speech quality.
Integrating human feedback has proven effective for enhancing robustness in
these systems. However, current approaches face challenges in optimizing TTS
with preference data across multiple dimensions and often suffer from
performance degradation due to overconfidence in rewards. We propose
Multidimensional Preference Optimization (MPO) to better align TTS systems with
human preferences. MPO introduces a preference set that streamlines the
construction of data for multidimensional preference optimization, enabling
alignment with multiple dimensions. Additionally, we incorporate regularization
during training to address the typical degradation issues in DPO-based
approaches. Our experiments demonstrate MPO's effectiveness, showing
significant improvements in intelligibility, speaker similarity, and prosody
compared to baseline systems.

</details>


### [61] [Noisy Disentanglement with Tri-stage Training for Noise-Robust Speech Recognition](https://arxiv.org/abs/2509.01087)
*Shuangyuan Chen,Shuang Wei,Dongxing Xu,Yanhua Long*

Main category: eess.AS

TL;DR: NoisyD-CT是一个基于Conformer-Transducer的三阶段训练框架，通过紧凑的噪声解耦模块和一致性损失函数，显著提升噪声环境下的语音识别性能。


<details>
  <summary>Details</summary>
Motivation: 提升端到端语音识别系统在噪声或低信噪比条件下的性能表现，解决噪声环境下ASR鲁棒性问题。

Method: 在Conformer块和Transducer解码器之间集成紧凑的NoisyD模块（仅增加1.71M参数），使用干净表示一致性损失和对齐重构损失进行三阶段训练。

Result: 在LibriSpeech和CHiME-4数据集上，相比基准模型在模拟和真实噪声测试集上分别实现25.7%和10.6%的相对词错误率降低，同时在干净语音测试集上保持或提升性能。

Conclusion: NoisyD-CT框架通过噪声解耦和一致性对齐，有效抑制噪声同时保留关键声学和语言特征，显著提升噪声环境下的ASR性能。

Abstract: To enhance the performance of end-to-end (E2E) speech recognition systems in
noisy or low signal-to-noise ratio (SNR) conditions, this paper introduces
NoisyD-CT, a novel tri-stage training framework built on the
Conformer-Transducer architecture. The core of NoisyD-CT is a especially
designed compact noisy disentanglement (NoisyD) module (adding only 1.71M
parameters), integrated between the Conformer blocks and Transducer Decoder to
perform deep noise suppression and improve ASR robustness in challenging
acoustic noise environments. To fully exploit the noise suppression capability
of the NoisyD-CT, we further propose a clean representation consistency loss to
align high-level representations derived from noisy speech with those obtained
from corresponding clean speech. Together with a noisy reconstruction loss,
this consistency alignment enables the NoisyD module to effectively suppress
noise while preserving essential acoustic and linguistic features consistent
across both clean and noisy conditions, thereby producing cleaner internal
representations that enhance ASR performance. Moreover, our tri-stage training
strategy is designed to fully leverage the functionalities of both the noisy
disentanglement and speech recognition modules throughout the model training
process, ultimately maximizing performance gains under noisy conditions. Our
experiments are performed on the LibriSpeech and CHiME-4 datasets, extensive
results demonstrate that our proposed NoisyD-CT significantly outperforms the
competitive Conformer-Transducer baseline, achieving up to 25.7% and 10.6%
relative word error rate reductions on simulated and real-world noisy test
sets, respectively, while maintaining or even improving performance on clean
speech test sets. The source code, model checkpoint and data simulation scripts
will be available at https://github.com/litchimo/NoisyD-CT.

</details>


### [62] [MixedG2P-T5: G2P-free Speech Synthesis for Mixed-script texts using Speech Self-Supervised Learning and Language Model](https://arxiv.org/abs/2509.01391)
*Joonyong Park,Daisuke Saito,Nobuaki Minematsu*

Main category: eess.AS

TL;DR: 这篇论文提出了一种新题的语音合成方法，用深度学习模型直接从语音生成离散标记，取代传统的字符到音素转换方法。


<details>
  <summary>Details</summary>
Motivation: 传统G2P转换需要人工音标注内，成本高且扩展性差。该研究旨在通过自动化方法减少人工干预，特别是对大规模未注内音频数据集。

Method: 利用预训练语音SSL模型，训练T5编码器从混合脚本文本（如漢字和偊名）生成伪语言标签，直接生成离散标记而不需G2P转换。

Result: 该模型表现与传统G2P基础的语音合成系统相当，能够合成保留自然语言和超语言特征（如口音和语调）的语音。

Conclusion: 该方法成功消除了对人工音标注的需求，降低了成本并提高了扩展性，为大规模语音合成提供了一种更高效的解决方案。

Abstract: This study presents a novel approach to voice synthesis that can substitute
the traditional grapheme-to-phoneme (G2P) conversion by using a deep
learning-based model that generates discrete tokens directly from speech.
Utilizing a pre-trained voice SSL model, we train a T5 encoder to produce
pseudo-language labels from mixed-script texts (e.g., containing Kanji and
Kana). This method eliminates the need for manual phonetic transcription,
reducing costs and enhancing scalability, especially for large non-transcribed
audio datasets. Our model matches the performance of conventional G2P-based
text-to-speech systems and is capable of synthesizing speech that retains
natural linguistic and paralinguistic features, such as accents and
intonations.

</details>


### [63] [Characterization of Speech Similarity Between Australian Aboriginal and High-Resource Languages: A Case Study on Dharawal](https://arxiv.org/abs/2509.01419)
*Ting Dang,Trini Manoj Jeyaseelan,Eliathamby Ambikairajah,Vidhyasaharan Sethu*

Main category: eess.AS

TL;DR: 本文收集并清理了澳大利亚原住民语言Dharawal的语音数据集，通过预训练多语言语音编码器分析了Dharawal与107种高资源语言的语音相似性，发现其与拉丁语、毛利语、韩语、泰语和威尔士语有较强相似性，为低资源语言的语音技术发展提供了重要指导。


<details>
  <summary>Details</summary>
Motivation: 澳大利亚原住民语言具有重要的文化和语言学价值，但在现代语音AI系统中代表性严重不足。现有语音基础模型和自动语音识别系统在高资源语言上表现优异，但难以泛化到缺乏干净标注语音数据的低资源语言。

Method: 1) 收集和清理Dharawal语言的公开可用录音数据集；2) 使用预训练多语言语音编码器分析Dharawal与107种高资源语言的语音相似性；3) 结合误分类率分析和嵌入空间的余弦相似度、Fréchet Inception Distance (FID)进行细粒度相似性测量。

Result: 实验结果显示Dharawal与拉丁语、毛利语、韩语、泰语和威尔士语等语言具有强烈的语音相似性。

Conclusion: 这些发现为未来的迁移学习和模型适应工作提供了实用指导，并强调了数据收集和基于嵌入的分析在支持濒危语言社区语音技术方面的重要性。

Abstract: Australian Aboriginal languages are of significant cultural and linguistic
value but remain severely underrepresented in modern speech AI systems. While
state-of-the-art speech foundation models and automatic speech recognition
excel in high-resource settings, they often struggle to generalize to
low-resource languages, especially those lacking clean, annotated speech data.
In this work, we collect and clean a speech dataset for Dharawal, a
low-resource Australian Aboriginal language, by carefully sourcing and
processing publicly available recordings. Using this dataset, we analyze the
speech similarity between Dharawal and 107 high-resource languages using a
pre-trained multilingual speech encoder. Our approach combines (1)
misclassification rate analysis to assess language confusability, and (2)
fine-grained similarity measurements using cosine similarity and Fr\'echet
Inception Distance (FID) in the embedding space. Experimental results reveal
that Dharawal shares strong speech similarity with languages such as Latin,
M\=aori, Korean, Thai, and Welsh. These findings offer practical guidance for
future transfer learning and model adaptation efforts, and underscore the
importance of data collection and embedding-based analysis in supporting speech
technologies for endangered language communities.

</details>


### [64] [AHAMask: Reliable Task Specification for Large Audio Language Models without Instructions](https://arxiv.org/abs/2509.01787)
*Yiwei Guo,Bohan Li,Hankun Wang,Zhihan Li,Shuai Wang,Xie Chen,Kai Yu*

Main category: eess.AS

TL;DR: AHAMask方法通过掩码LALMs中的特定注意力头来触发音频任务功能，无需指令即可实现可比甚至更好的性能，揭示了LALMs中存在功能特定的注意力通路。


<details>
  <summary>Details</summary>
Motivation: 当前大型音频语言模型虽然扩展了文本LLMs的通用音频理解能力，但存在指令敏感性问题，相同意图的不同指令会导致截然不同的结果。

Method: 提出AHAMask方法，在LALMs的解码器LLM骨干网络中掩码部分注意力头，通过仅训练注意力头数量的参数来触发特定音频任务功能。

Result: 实验表明，应用选择性注意力头掩码在单一或复合任务上都能达到与使用指令相当甚至更好的性能。

Conclusion: 该方法不仅为LALMs提供了可靠的音频任务指定方式，还揭示了LALMs的注意力头中存在特定的"功能通路"。

Abstract: Although current large audio language models (LALMs) extend text large
language models (LLMs) with generic acoustic understanding abilities, they
usually suffer from instruction sensitivity, where different instructions of
the same intention can yield drastically different outcomes. In this work, we
propose AHAMask, where we simply mask some of the attention heads in the
decoder-only LLM backbone of LALMs, to trigger specific acoustic task
functionalities without instructions. These masks are efficiently obtained by
training on an LALM, with the number of trainable parameters equal to the
attention head count in its LLM backbone. We show by experiments that applying
such selective attention head masks achieves comparable or even better
performance than using instructions, either on single or composite tasks.
Besides achieving reliable acoustic task specification for LALMs, this also
reveals that LALMs exhibit certain "functional pathways" in their attention
heads.

</details>


### [65] [From Evaluation to Optimization: Neural Speech Assessment for Downstream Applications](https://arxiv.org/abs/2509.01889)
*Yu Tsao*

Main category: eess.AS

TL;DR: 这篇综述论文探讨了基于神经网络的语音评估模型的发展，重点关注它们作为可微分感知代理在语音增强和合成模型优化中的作用，以及支持下游语音处理的语音特征检测能力。


<details>
  <summary>Details</summary>
Motivation: 传统主观听力测试成本高、耗时长且难以扩展，而传统客观指标与人类感知相关性弱，需要在系统优化和用户体验之间建立更好的感知桥梁。

Method: 回顾和分析近年来开发的神经网络语音评估模型，这些模型能够预测语音质量和可懂度，并作为可微分感知代理集成到下游语音处理任务中。

Result: 基于神经网络的语音评估模型在预测语音质量和可懂度方面取得了有希望的结果，能够有效指导语音增强和合成模型的优化，并支持更精确的下游处理。

Conclusion: 语音评估模型正越来越多地集成到语音处理流程中，但仍存在局限性，需要进一步研究来推进其在语音处理管道中的整合应用。

Abstract: The evaluation of synthetic and processed speech has long been a cornerstone
of audio engineering and speech science. Although subjective listening tests
remain the gold standard for assessing perceptual quality and intelligibility,
their high cost, time requirements, and limited scalability present significant
challenges in the rapid development cycles of modern speech technologies.
Traditional objective metrics, while computationally efficient, often exhibit
weak correlation with human perception, creating a perceptual gap between
system optimization and actual user experience. Bridging this gap requires
speech assessment models that are more closely aligned with human perception.
In recent years, numerous neural network-based speech assessment models have
been developed to predict quality and intelligibility, achieving promising
results. Beyond their role in evaluation, these models are increasingly
integrated into downstream speech processing tasks. This review focuses on
their role in two main areas: (1) serving as differentiable perceptual proxies
that not only assess but also guide the optimization of speech enhancement and
synthesis models; and (2) enabling the detection of salient speech
characteristics to support more precise and efficient downstream processing.
Finally, we discuss current limitations and outline future research directions
to further advance the integration of speech assessment into speech processing
pipelines.

</details>


### [66] [Multilingual Speech Recognition Using Discrete Tokens with a Two-step Training Strategy](https://arxiv.org/abs/2509.01900)
*Zehan Li,Yan Yang,Xueqing Li,Jian Kang,Xiao-Lei Zhang,Jie Li*

Main category: eess.AS

TL;DR: 通过两阶段训练策略提升预训练模型的离散单元表现，在多语言ASR任务中实现CER相对降低44%，超越WavLM模型的26%降低率


<details>
  <summary>Details</summary>
Motivation: 多语言ASR任务中，预训练模型不同层的表征对各语言贡献异质，增加了离散单元建模的复杂性，需要缩小离散表征与连续表征之间的性能差距

Method: 提出两阶段训练策略来改善预训练模型的离散单元性能，基于XLS-R模型按照Interspeech2024离散语音单元挑战赛设置进行验证

Result: 在ML-SUPERB数据集上实现CER相对降低44%，超越WavLM模型的26%降低率，在排行榜上获得所有单系统结果的第一名

Conclusion: 该方法有效提升了预训练模型在多语言ASR任务中离散单元的表现，显著缩小了与连续表征的性能差距，为离散语音表征的应用提供了有效解决方案

Abstract: Pre-trained models, especially self-supervised learning (SSL) models, have
demonstrated impressive results in automatic speech recognition (ASR) task.
While most applications of SSL models focus on leveraging continuous
representations as features for training downstream tasks, the utilization of
discrete units has gained increasing attention in recent years owing to its
lower storage requirements and broader range of applications. In multilingual
ASR tasks, representations at different layers of the model contribute
differently to various languages, complicating the unification of discrete unit
modeling. In this paper, we propose a two-stage training strategy to improve
the discrete token performance of pre-trained models and narrow the gap with
continuous representation performance. We validate our method on the XLS-R
model following the settings of Interspeech2024 Speech Processing Using
Discrete Speech Unit Challenge. Our method demonstrates a significant
improvement on the ML-SUPERB dataset, achieving a 44% relative reduction on CER
for the XLS-R model. This surpasses the previous baseline set by the WavLM
model, which achieves a 26% relative reduction on CER. Furthermore, our method
achieves the first place among all the single-system results on the
leaderboard.

</details>


### [67] [Binaural Unmasking in Practical Use: Perceived Level of Phase-inverted Speech in Environmental Noise](https://arxiv.org/abs/2509.01929)
*Rina Kotani,Chiaki Miyazaki,Shiro Suzuki*

Main category: eess.AS

TL;DR: 通过单耳相位反转技术，在不增加声压或消除环境噪音的情况下，使耳机音响更易听清，最大可提高6dB的声音明显度


<details>
  <summary>Details</summary>
Motivation: 开发一种技术，在不增加声压或消除环境噪音的前提下，提高耳机和耳机声音的可听性

Method: 利用双耳解掩效应现象，通过单耳相位反转进行实验。使用多种讲者的语音声音（包括女性）和日常生活中常见的噪音（城市环境声、喜弓声），在接近实际情况下验证双耳解掩效果

Result: 日语实验结果显示：(i)在噪音环境中，通过单耳相位反转可使语音声觉得明显度提高约6dB；(ii)对本研究中所有讲者和噪音类型都能获得一定效果（可听性提高5dB以上）

Conclusion: 证明了基于耳间相位差的双耳解掩现象在实际应用场景中的有效性，为提升耳机音响识别性能提供了新方法

Abstract: We aim to develop a technology that makes the sound from earphones and
headphones easier to hear without increasing the sound pressure or eliminating
ambient noise. To this end, we focus on harnessing the phenomenon of binaural
unmasking through phase reversal in one ear. Specifically, we conduct
experiments to evaluate the improvement of audibility caused by the phenomenon,
using conditions that approximate practical scenarios. We use speech sounds by
various speakers, including women, and noises that can be encountered in daily
life (urban environmental sounds, cheers) to verify the effects of binaural
unmasking under conditions close to practical situations. The results of
experiments using the Japanese language showed that (i) speech in a noisy
environment is perceived to be up to about 6 dB louder with phase reversal in
one ear, and (ii) a certain effect (improvement of audibility by 5 dB or more)
is obtained for all speakers and noises targeted in this study. These findings
demonstrate the effectiveness of binaural unmasking attributed to interaural
phase differences in practical scenarios.

</details>


### [68] [Group Relative Policy Optimization for Speech Recognition](https://arxiv.org/abs/2509.01939)
*Prashanth Gurunath Shivakumar,Yile Gu,Ankur Gandhe,Ivan Bulyko*

Main category: eess.AS

TL;DR: 本文提出使用Group Relative Policy Optimization (GRPO)方法，通过基于规则的奖励函数进行强化学习，显著改善了语音识别的词错率、幻觉问题和跨域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 虽然大语言模型在语音识别中表现出良好的扩展性和多任务能力，但简单的下一个token预测目标存在性能限制和幻觉问题，需要更好的优化方法。

Method: 采用Group Relative Policy Optimization (GRPO)进行人类反馈强化学习，设计基于规则的奖励函数来指导策略更新。

Result: 词错率相对改善达18.4%，减少了幻觉现象，提高了在域外数据集上的鲁棒性，并证明了在领域适应中的有效性。

Conclusion: GRPO方法通过强化学习有效解决了传统LLM在语音识别中的局限性，显著提升了识别性能和系统鲁棒性。

Abstract: Speech Recognition has seen a dramatic shift towards adopting Large Language
Models (LLMs). This shift is partly driven by good scalability properties
demonstrated by LLMs, ability to leverage large amounts of labelled, unlabelled
speech and text data, streaming capabilities with auto-regressive framework and
multi-tasking with instruction following characteristics of LLMs. However,
simple next-token prediction objective, typically employed with LLMs, have
certain limitations in performance and challenges with hallucinations. In this
paper, we propose application of Group Relative Policy Optimization (GRPO) to
enable reinforcement learning from human feedback for automatic speech
recognition (ASR). We design simple rule based reward functions to guide the
policy updates. We demonstrate significant improvements in word error rate
(upto 18.4% relative), reduction in hallucinations, increased robustness on
out-of-domain datasets and effectiveness in domain adaptation.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [69] [From Sound to Sight: Towards AI-authored Music Videos](https://arxiv.org/abs/2509.00029)
*Leo Vitasovic,Stella Graßhof,Agnes Mercedes Kloft,Ville V. Lehtola,Martin Cunneen,Justyna Starostka,Glenn McGarry,Kun Li,Sami S. Brandt*

Main category: cs.SD

TL;DR: 提出两个基于深度学习模型的自动音乐视频生成管道，通过音频分析提取音乐情感和乐器特征，生成文本场景描述，再用生成模型制作对应视频片段。


<details>
  <summary>Details</summary>
Motivation: 传统音乐可视化系统依赖手工制作的形状和颜色变换，表达能力有限，需要更自动化和富有表现力的音乐视频生成方法。

Method: 使用现成的深度学习模型，通过潜在特征技术分析音频检测音乐品质（情感线索和乐器模式），用语言模型生成文本场景描述，再用生成模型制作视频片段。

Result: 通过初步用户评估显示，生成的视频具有叙事潜力、视觉连贯性和与音乐的情感一致性。

Conclusion: 潜在特征技术和深度生成模型有潜力将音乐可视化扩展到传统方法之外，展示了自动化音乐视频生成的可能性。

Abstract: Conventional music visualisation systems rely on handcrafted ad hoc
transformations of shapes and colours that offer only limited expressiveness.
We propose two novel pipelines for automatically generating music videos from
any user-specified, vocal or instrumental song using off-the-shelf deep
learning models. Inspired by the manual workflows of music video producers, we
experiment on how well latent feature-based techniques can analyse audio to
detect musical qualities, such as emotional cues and instrumental patterns, and
distil them into textual scene descriptions using a language model. Next, we
employ a generative model to produce the corresponding video clips. To assess
the generated videos, we identify several critical aspects and design and
conduct a preliminary user evaluation that demonstrates storytelling potential,
visual coherency and emotional alignment with the music. Our findings
underscore the potential of latent feature techniques and deep generative
models to expand music visualisation beyond traditional approaches.

</details>


### [70] [A Survey on Evaluation Metrics for Music Generation](https://arxiv.org/abs/2509.00051)
*Faria Binte Kader,Santu Karmaker*

Main category: cs.SD

TL;DR: 该论文分析了音乐生成评估方法的现状和问题，提出了评估指标的分类法，并指出了当前评估方法的主要局限性，最后提出了构建全面音乐生成评估框架的未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 尽管音乐生成系统取得了显著进展，但由于音乐本身的复杂性（如结构、连贯性、创造性和情感表达等方面），评估生成音乐的方法并没有相应发展，存在研究空白。

Method: 提出了针对音频和符号音乐表示的评估指标详细分类法，并进行了批判性综述，识别当前评估方法的主要局限性。

Result: 识别出当前评估方法的主要问题包括：客观指标与人类感知相关性差、跨文化偏见、缺乏标准化阻碍跨模型比较等。

Conclusion: 提出了未来研究方向，旨在构建一个全面的音乐生成评估框架，以解决当前评估方法的局限性。

Abstract: Despite significant advancements in music generation systems, the
methodologies for evaluating generated music have not progressed as expected
due to the complex nature of music, with aspects such as structure, coherence,
creativity, and emotional expressiveness. In this paper, we shed light on this
research gap, introducing a detailed taxonomy for evaluation metrics for both
audio and symbolic music representations. We include a critical review
identifying major limitations in current evaluation methodologies which
includes poor correlation between objective metrics and human perception,
cross-cultural bias, and lack of standardization that hinders cross-model
comparisons. Addressing these gaps, we further propose future research
directions towards building a comprehensive evaluation framework for music
generation evaluation.

</details>


### [71] [Algorithms for Collaborative Harmonization](https://arxiv.org/abs/2509.00120)
*Eyal Briman,Eyal Leizerovich,Nimrod Talmon*

Main category: cs.SD

TL;DR: 该论文研究音乐和声领域的文本聚合问题，提出了多种算法来聚合多个代理给出的和声建议，旨在实现集体建议的有效表示和音乐连贯性。


<details>
  <summary>Details</summary>
Motivation: 音乐和声与文本聚合有相似之处，但和声语言比一般文本更具结构性。研究旨在开发能够有效代表集体建议并保持音乐连贯性的和声聚合算法。

Method: 提出了不同的和声聚合算法，包括基于Kemeny和plurality的算法，并分析了这些算法的复杂度。

Result: 结果表明，Kemeny和基于plurality的算法在评估表示效果和保持音乐连贯性方面最为有效。

Conclusion: 在音乐和声聚合任务中，Kemeny和plurality-based算法是平衡集体建议代表性和音乐质量的最佳选择。

Abstract: We consider a specific scenario of text aggregation, in the realm of musical
harmonization. Musical harmonization shares similarities with text aggregation,
however the language of harmony is more structured than general text.
Concretely, given a set of harmonization suggestions for a given musical
melody, our interest lies in devising aggregation algorithms that yield an
harmonization sequence that satisfies the following two key criteria: (1) an
effective representation of the collective suggestions; and (2) an
harmonization that is musically coherent. We present different algorithms for
the aggregation of harmonies given by a group of agents and analyze their
complexities. The results indicate that the Kemeny and plurality-based
algorithms are most effective in assessing representation and maintaining
musical coherence.

</details>


### [72] [CoComposer: LLM Multi-agent Collaborative Music Composition](https://arxiv.org/abs/2509.00132)
*Peiwen Xing,Aske Plaat,Niki van Stein*

Main category: cs.SD

TL;DR: CoComposer是一个多智能体音乐作曲系统，通过五个协作智能体模拟传统作曲流程，在音乐质量和制作复杂性上优于现有多智能体LLM系统，相比非LLM的MusicLM具有更好的可解释性和可编辑性。


<details>
  <summary>Details</summary>
Motivation: 现有AI音乐作曲工具在生成时长、音乐质量和可控性方面存在限制，需要开发更好的多智能体协作系统来提升音乐创作能力。

Method: 采用五个协作智能体系统，每个智能体基于传统音乐作曲工作流程执行特定任务，使用AudioBox-Aesthetics系统进行评估，测试了GPT-4o、DeepSeek-V3-0324和Gemini-2.5-Flash三种LLM。

Result: CoComposer在音乐质量上优于现有多智能体LLM系统，在制作复杂性上优于单智能体系统，相比MusicLM具有更好的可解释性和可编辑性，但MusicLM仍能产生更好的音乐。

Conclusion: 多智能体协作方法在AI音乐作曲中具有优势，特别是在可控性和可编辑性方面，为未来音乐AI系统的发展提供了有价值的参考。

Abstract: Existing AI Music composition tools are limited in generation duration,
musical quality, and controllability. We introduce CoComposer, a multi-agent
system that consists of five collaborating agents, each with a task based on
the traditional music composition workflow. Using the AudioBox-Aesthetics
system, we experimentally evaluate CoComposer on four compositional criteria.
We test with three LLMs (GPT-4o, DeepSeek-V3-0324, Gemini-2.5-Flash), and find
(1) that CoComposer outperforms existing multi-agent LLM-based systems in music
quality, and (2) compared to a single-agent system, in production complexity.
Compared to non- LLM MusicLM, CoComposer has better interpretability and
editability, although MusicLM still produces better music.

</details>


### [73] [Generalizable Audio Spoofing Detection using Non-Semantic Representations](https://arxiv.org/abs/2509.00186)
*Arnab Das,Yassine El Kheir,Carlos Franzreb,Tim Herzig,Tim Polzehl,Sebastian Möller*

Main category: cs.SD

TL;DR: 该研究提出了一种利用非语义通用音频表示的新型深度伪造检测方法，在跨域测试中显著优于现有技术


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展使得合成音频生成变得容易，语音服务面临欺骗攻击威胁，现有深度伪造检测方案缺乏泛化能力，在真实数据上表现不佳

Method: 使用TRILL和TRILLsson模型提取非语义通用音频表示特征，构建可泛化的欺骗检测方法

Result: 在域内测试集上获得可比性能，在域外测试集上显著优于最先进方法，在公共数据上展现出优越的泛化能力

Conclusion: 非语义音频表示特征为深度伪造检测提供了有效的泛化解决方案，超越了基于手工特征、语义嵌入和端到端架构的方法

Abstract: Rapid advancements in generative modeling have made synthetic audio
generation easy, making speech-based services vulnerable to spoofing attacks.
Consequently, there is a dire need for robust countermeasures more than ever.
Existing solutions for deepfake detection are often criticized for lacking
generalizability and fail drastically when applied to real-world data. This
study proposes a novel method for generalizable spoofing detection leveraging
non-semantic universal audio representations. Extensive experiments have been
performed to find suitable non-semantic features using TRILL and TRILLsson
models. The results indicate that the proposed method achieves comparable
performance on the in-domain test set while significantly outperforming
state-of-the-art approaches on out-of-domain test sets. Notably, it
demonstrates superior generalization on public-domain data, surpassing methods
based on hand-crafted features, semantic embeddings, and end-to-end
architectures.

</details>


### [74] [Evaluating the Effectiveness of Transformer Layers in Wav2Vec 2.0, XLS-R, and Whisper for Speaker Identification Tasks](https://arxiv.org/abs/2509.00230)
*Linus Stuhlmann,Michael Alexander Saxer*

Main category: cs.SD

TL;DR: 评估Wav2Vec 2.0、XLS-R和Whisper语音编码器在说话人识别任务中的性能，分析层级表征并确定各模型的最佳转换器层数


<details>
  <summary>Details</summary>
Motivation: 比较不同语音编码模型在说话人识别任务中的表现，以及它们在不同网络层中捐存语者特征的能力

Method: 通过微调模型并使用SVCCA、k-means聚类和t-SNE可视化来分析层级表征

Result: Wav2Vec 2.0和XLS-R在早期层中有效捐存语者特征，微调后性能更稳定；Whisper在更深层表现更好，并确定了各模型的最佳转换器层数

Conclusion: 不同语音编码器在说话人识别中有不同的特性，选择适当的模型和层次对于优化性能至关重要

Abstract: This study evaluates the performance of three advanced speech encoder models,
Wav2Vec 2.0, XLS-R, and Whisper, in speaker identification tasks. By
fine-tuning these models and analyzing their layer-wise representations using
SVCCA, k-means clustering, and t-SNE visualizations, we found that Wav2Vec 2.0
and XLS-R capture speaker-specific features effectively in their early layers,
with fine-tuning improving stability and performance. Whisper showed better
performance in deeper layers. Additionally, we determined the optimal number of
transformer layers for each model when fine-tuned for speaker identification
tasks.

</details>


### [75] [Towards High-Fidelity and Controllable Bioacoustic Generation via Enhanced Diffusion Learning](https://arxiv.org/abs/2509.00318)
*Tianyu Song,Ton Viet Ta*

Main category: cs.SD

TL;DR: BirdDiff是一个生成式框架，通过多尺度自适应鸟叫增强和条件扩散模型，直接从嘈杂的野外录音中合成高保真度的鸟类叫声。


<details>
  <summary>Details</summary>
Motivation: 生成建模为生物声学提供了新机遇，可以合成逼真的动物叫声来支持生物监测工作，并为濒危物种补充稀缺数据。但直接从嘈杂的野外录音生成鸟类叫声波形仍然是一个重大挑战。

Method: 提出BirdDiff框架，包含多尺度自适应鸟叫增强的"零层"阶段，然后是条件扩散生成器，使用梅尔频率倒谱系数、物种标签和文本描述三种模态进行条件生成。增强阶段在最小化频谱失真的同时提高信噪比。

Result: 与DiffWave基线相比，在生成质量指标上取得显著改进：FAD从0.590降至0.213，JSD从0.259降至0.226。使用ResNet50分类器评估，识别准确率从35.9%提升至70.1%，12个物种中有8个超过70%准确率。

Conclusion: BirdDiff能够直接从嘈杂的野外录音中实现高保真、可控的鸟类叫声生成，为生物声学监测和濒危物种保护提供了有效工具。

Abstract: Generative modeling offers new opportunities for bioacoustics, enabling the
synthesis of realistic animal vocalizations that could support biomonitoring
efforts and supplement scarce data for endangered species. However, directly
generating bird call waveforms from noisy field recordings remains a major
challenge.
  We propose BirdDiff, a generative framework designed to synthesize bird calls
from a noisy dataset of 12 wild bird species. The model incorporates a "zeroth
layer" stage for multi-scale adaptive bird-call enhancement, followed by a
diffusion-based generator conditioned on three modalities: Mel-frequency
cepstral coefficients, species labels, and textual descriptions. The
enhancement stage improves signal-to-noise ratio (SNR) while minimizing
spectral distortion, achieving the highest SNR gain (+10.45 dB) and lowest
Itakura-Saito Distance (0.54) compared to three widely used non-training
enhancement methods.
  We evaluate BirdDiff against a baseline generative model, DiffWave. Our
method yields substantial improvements in generative quality metrics: Fr\'echet
Audio Distance (0.590 to 0.213), Jensen-Shannon Divergence (0.259 to 0.226),
and Number of Statistically-Different Bins (7.33 to 5.58). To assess
species-specific detail preservation, we use a ResNet50 classifier trained on
the original dataset to identify generated samples. Classification accuracy
improves from 35.9% (DiffWave) to 70.1% (BirdDiff), with 8 of 12 species
exceeding 70% accuracy.
  These results demonstrate that BirdDiff enables high-fidelity, controllable
bird call generation directly from noisy field recordings.

</details>


### [76] [SaD: A Scenario-Aware Discriminator for Speech Enhancement](https://arxiv.org/abs/2509.00405)
*Xihao Yuan,Siqi Liu,Yan Chen,Hang Zhou,Chang Liu,Hanting Chen,Jie Hu*

Main category: cs.SD

TL;DR: 提出了一种场景感知判别器，通过捕获场景特定特征和频域划分来更准确评估语音增强质量，无需改变生成器结构即可提升性能


<details>
  <summary>Details</summary>
Motivation: 当前GAN语音增强模型的优化策略主要关注生成器架构改进或判别器质量评估指标，忽视了不同场景中丰富的上下文信息

Method: 设计场景感知判别器，捕获场景特定特征并进行频域划分，实现对生成器增强语音的更准确质量评估

Result: 在三个代表性模型和两个公开数据集上的实验表明，该方法能有效适应各种生成器架构，在不同场景下实现进一步的性能提升

Conclusion: 场景感知判别器方法能够在不改变生成器结构的情况下，通过更好的质量评估解锁语音增强的额外性能增益

Abstract: Generative adversarial network-based models have shown remarkable performance
in the field of speech enhancement. However, the current optimization
strategies for these models predominantly focus on refining the architecture of
the generator or enhancing the quality evaluation metrics of the discriminator.
This approach often overlooks the rich contextual information inherent in
diverse scenarios. In this paper, we propose a scenario-aware discriminator
that captures scene-specific features and performs frequency-domain division,
thereby enabling a more accurate quality assessment of the enhanced speech
generated by the generator. We conducted comprehensive experiments on three
representative models using two publicly available datasets. The results
demonstrate that our method can effectively adapt to various generator
architectures without altering their structure, thereby unlocking further
performance gains in speech enhancement across different scenarios.

</details>


### [77] [The Name-Free Gap: Policy-Aware Stylistic Control in Music Generation](https://arxiv.org/abs/2509.00654)
*Ashwin Nagarajan,Hao-Wen Dong*

Main category: cs.SD

TL;DR: 该研究探讨使用大型语言模型生成的人类可读描述符作为艺术家名称的替代方案，用于音乐生成的风格控制，发现描述符能恢复大部分风格效果，但艺术家名称仍是最强的控制信号。


<details>
  <summary>Details</summary>
Motivation: 现有音乐风格化方法通常需要重新训练或专门的条件设置，这限制了可重复性和政策合规性。研究旨在探索轻量级、人类可读的描述符是否能提供政策鲁棒的风格控制替代方案。

Method: 使用MusicGen-small模型，评估Billie Eilish和Ludovico Einaudi两位艺术家的风格控制。通过大型语言模型生成提示词，包括基准提示、艺术家名称提示和五组描述符集。使用VGGish和CLAP嵌入进行评估，包括分布相似性和每片段相似性度量。

Result: 结果显示艺术家名称是最强的控制信号，但无名称描述符能恢复大部分效果。跨艺术家转移会降低对齐性，表明描述符编码了目标风格线索。研究还提供了十位当代艺术家的描述符表。

Conclusion: 研究发现现有 safeguards（如限制艺术家名称）可能无法完全防止风格模仿，定义了"无名称差距"概念，并通过可重复的评估协议展示了提示级别的可控性差异。

Abstract: Text-to-music models capture broad attributes such as instrumentation or
mood, but fine-grained stylistic control remains an open challenge. Existing
stylization methods typically require retraining or specialized conditioning,
which complicates reproducibility and limits policy compliance when artist
names are restricted. We study whether lightweight, human-readable modifiers
sampled from a large language model can provide a policy-robust alternative for
stylistic control. Using MusicGen-small, we evaluate two artists: Billie Eilish
(vocal pop) and Ludovico Einaudi (instrumental piano). For each artist, we use
fifteen reference excerpts and evaluate matched seeds under three conditions:
baseline prompts, artist-name prompts, and five descriptor sets. All prompts
are generated using a large language model. Evaluation uses both VGGish and
CLAP embeddings with distributional and per-clip similarity measures, including
a new min-distance attribution metric. Results show that artist names are the
strongest control signal across both artists, while name-free descriptors
recover much of this effect. This highlights that existing safeguards such as
the restriction of artist names in music generation prompts may not fully
prevent style imitation. Cross-artist transfers reduce alignment, showing that
descriptors encode targeted stylistic cues. We also present a descriptor table
across ten contemporary artists to illustrate the breadth of the tokens.
Together these findings define the name-free gap, the controllability
difference between artist-name prompts and policy-compliant descriptors, shown
through a reproducible evaluation protocol for prompt-level controllability.

</details>


### [78] [PicoAudio2: Temporal Controllable Text-to-Audio Generation with Natural Language Description](https://arxiv.org/abs/2509.00683)
*Zihao Zheng,Zeyu Xie,Xuenan Xu,Wen Wu,Chao Zhang,Mengyue Wu*

Main category: cs.SD

TL;DR: PicoAudio2通过新的数据处理流程和模型架构改进时序可控的文本到音频生成，使用真实和模拟数据结合训练，在时序控制性和音频质量方面表现优异


<details>
  <summary>Details</summary>
Motivation: 现有文本到音频生成方法虽然能基于时间戳实现细粒度控制，但声音事件类别受限且仅使用模拟数据训练，导致生成音频质量和在真实数据上的泛化性能有限

Method: 使用基础模型标注真实音频-文本数据集的事件时间戳来构建时序强化的真实数据，结合现有工作的模拟数据进行训练；采用时间戳矩阵编码时间信息，在粗粒度文本描述基础上提供细粒度时间对齐信息

Result: 实验表明PicoAudio2在时序控制性和音频质量方面表现出优越性能

Conclusion: 提出的数据处理流程和模型架构有效提升了时序可控文本到音频生成的性能，特别是在真实数据上的表现

Abstract: Controllable text-to-audio generation (TTA) has attracted much attention
recently. Although existing works can achieve fine-grained controllability
based on timestamp information, sound event categories are limited to a fixed
set. Moreover, since only simulated data is used for training, the generated
audio quality and generalization performance on real data are limited. To
tackle this issue, we propose PicoAudio2, improving temporal-controllable TTA
via a new data processing pipeline and model architecture. Specifically, we use
a grounding model to annotate event timestamps of real audio-text datasets to
curate temporally-strong real data, in addition to simulation data from
existing works. The model is trained on the combination of real and simulation
data. Moreover, following PicoAudio, we encode timestamp information into a
timestamp matrix to provide extra fine-grained time-aligned information to the
model, on top of the coarse-grained textual description. Experiments show that
PicoAudio2 exhibits superior performance in terms of temporal controllability
and audio quality.

</details>


### [79] [AImoclips: A Benchmark for Evaluating Emotion Conveyance in Text-to-Music Generation](https://arxiv.org/abs/2509.00813)
*Gyehun Go,Satbyul Han,Ahyeon Choi,Eunjin Choi,Juhan Nam,Jeong Mi Park*

Main category: cs.SD

TL;DR: 本文介绍了AImoclips基准测试，用于评估文本到音乐生成系统在情感传达方面的表现，发现商业系统倾向于生成比预期更愉悦的音乐，而开源系统则相反，所有系统都存在情感中性偏差。


<details>
  <summary>Details</summary>
Motivation: 文本到音乐生成系统在情感保真度方面研究不足，需要评估这些系统如何向人类听众传达预期情感。

Method: 创建AImoclips基准，选择12种情感意图覆盖效价-唤醒空间的四个象限，使用6个最先进的TTM系统生成1000多个音乐片段，111名参与者用9点李克特量表评估感知效价和唤醒度。

Result: 商业系统倾向于生成比预期更愉悦的音乐，开源系统则相反；高唤醒条件下所有模型的情感传达更准确；所有系统都存在情感中性偏差。

Conclusion: 该基准测试提供了模型特定情感渲染特征的有价值见解，支持未来开发情感对齐的文本到音乐生成系统。

Abstract: Recent advances in text-to-music (TTM) generation have enabled controllable
and expressive music creation using natural language prompts. However, the
emotional fidelity of TTM systems remains largely underexplored compared to
human preference or text alignment. In this study, we introduce AImoclips, a
benchmark for evaluating how well TTM systems convey intended emotions to human
listeners, covering both open-source and commercial models. We selected 12
emotion intents spanning four quadrants of the valence-arousal space, and used
six state-of-the-art TTM systems to generate over 1,000 music clips. A total of
111 participants rated the perceived valence and arousal of each clip on a
9-point Likert scale. Our results show that commercial systems tend to produce
music perceived as more pleasant than intended, while open-source systems tend
to perform the opposite. Emotions are more accurately conveyed under
high-arousal conditions across all models. Additionally, all systems exhibit a
bias toward emotional neutrality, highlighting a key limitation in affective
controllability. This benchmark offers valuable insights into model-specific
emotion rendering characteristics and supports future development of
emotionally aligned TTM systems.

</details>


### [80] [Adaptive Vehicle Speed Classification via BMCNN with Reinforcement Learning-Enhanced Acoustic Processing](https://arxiv.org/abs/2509.00839)
*Yuli Zhang,Pengfei Fan,Ruiyuan Jiang,Hankang Gu,Dongyao Jia,Xinheng Wang*

Main category: cs.SD

TL;DR: 混合深度学习与强化学习的声音车速分类框架，通过双支深度网络和注意力强化学习实现高精度与高效率的实时交通管理


<details>
  <summary>Details</summary>
Motivation: 基于声音车速分类的智能交通系统对治理城市交通拕塞具有重要意义，需要实现高精度且高效的实时处理方案

Method: 使用双支BMCNN处理MFCC和小波特征捕捉补充频率模式，通过注意力增强DQN自适应选择最小音频帧数量并在达到信心阈值时触发早期决策

Result: 在IDMT-Traffic和SZUR-Acoustic数据集上分别达到95.99%和92.3%的准确率，通过早期终止实现平均1.63倍的处理速度提升，在准确性-效率平衡方面超过A3C、DDDQN、SA2C、PPO和TD3等方法

Conclusion: 该方法提供了优秀的准确性-效率平衡，适合在异构城市环境中部署实时智能交通系统

Abstract: Traffic congestion remains a pressing urban challenge, requiring intelligent
transportation systems for real-time management. We present a hybrid framework
that combines deep learning and reinforcement learning for acoustic vehicle
speed classification. A dual-branch BMCNN processes MFCC and wavelet features
to capture complementary frequency patterns. An attention-enhanced DQN
adaptively selects the minimal number of audio frames and triggers early
decisions once confidence thresholds are reached. Evaluations on IDMT-Traffic
and our SZUR-Acoustic (Suzhou) datasets show 95.99% and 92.3% accuracy, with up
to 1.63x faster average processing via early termination. Compared with A3C,
DDDQN, SA2C, PPO, and TD3, the method provides a superior accuracy-efficiency
trade-off and is suitable for real-time ITS deployment in heterogeneous urban
environments.

</details>


### [81] [Speech Command Recognition Using LogNNet Reservoir Computing for Embedded Systems](https://arxiv.org/abs/2509.00862)
*Yuriy Izotov,Andrei Velichko*

Main category: cs.SD

TL;DR: 这篇论文提出了一种低资源语音命令识别系统，结合能量基声音活动检测、优化MFCC处理流程和LogNNet粘性计算分类器，在Arduino微控制器上实现了高准确度的实时识别。


<details>
  <summary>Details</summary>
Motivation: 解决在内存和计算资源极其有限的IoT设备上实现可靠的语音命令识别问题，适用于电池供电的物联网结点和无手控制界面。

Method: 采用能量基VAD检测声音活动，优化MFCC特征提取流程，使用自适应分桶抄码生成64维特征向量，结合LogNNet粘性计算分类器(64:33:9:4结构)进行分类。

Result: 达到92.04%的语者独立评估准确率，需要参数数量显著少于传统深度学习模型。在Arduino Nano 33 IoT上实现，实时识别准确率约90%，仅占18KB RAM(55%利用率)。

Conclusion: 该完整处理流程(VAD->MFCC->LogNNet)能够在严格的内存和计算限制下实现可靠的设备端语音命令识别，为低功耗IoT应用提供了可行解决方案。

Abstract: This paper presents a low-resource speech-command recognizer combining
energy-based voice activity detection (VAD), an optimized Mel-Frequency
Cepstral Coefficients (MFCC) pipeline, and the LogNNet reservoir-computing
classifier. Using four commands from the Speech Commands da-taset downsampled
to 8 kHz, we evaluate four MFCC aggregation schemes and find that adaptive
binning (64-dimensional feature vector) offers the best accuracy-to-compactness
trade-off. The LogNNet classifier with architecture 64:33:9:4 reaches 92.04%
accuracy under speaker-independent evaluation, while requiring significantly
fewer parameters than conventional deep learn-ing models. Hardware
implementation on Arduino Nano 33 IoT (ARM Cor-tex-M0+, 48 MHz, 32 KB RAM)
validates the practical feasibility, achieving ~90% real-time recognition
accuracy while consuming only 18 KB RAM (55% utilization). The complete
pipeline (VAD -> MFCC -> LogNNet) thus enables reliable on-device
speech-command recognition under strict memory and compute limits, making it
suitable for battery-powered IoT nodes, wire-less sensor networks, and
hands-free control interfaces.

</details>


### [82] [TinyMusician: On-Device Music Generation with Knowledge Distillation and Mixed Precision Quantization](https://arxiv.org/abs/2509.00914)
*Hainan Wang,Mehdi Hosseinzadeh,Reza Rawassizadeh*

Main category: cs.SD

TL;DR: TinyMusician是一个轻量级音乐生成模型，通过知识蒸馏和量化技术，在保持93%性能的同时减少55%模型大小，实现移动端部署


<details>
  <summary>Details</summary>
Motivation: 解决Transformer模型在音乐生成领域计算资源需求大、推理时间长的问题，使其能够在计算资源有限的边缘设备上部署

Method: 1) 阶段混合双向和偏斜KL散度知识蒸馏 2) 自适应混合精度量化技术

Result: 模型保持MusicGen-Small 93%的性能，模型大小减少55%，成为首个可移动部署的音乐生成模型

Conclusion: TinyMusician成功解决了大模型在边缘设备部署的难题，消除了云端依赖，同时保持高音频保真度和资源效率

Abstract: The success of the generative model has gained unprecedented attention in the
music generation area. Transformer-based architectures have set new benchmarks
for model performance. However, their practical adoption is hindered by some
critical challenges: the demand for massive computational resources and
inference time, due to their large number of parameters. These obstacles make
them infeasible to deploy on edge devices, such as smartphones and wearables,
with limited computational resources. In this work, we present TinyMusician, a
lightweight music generation model distilled from MusicGen (a State-of-the-art
music generation model). TinyMusician integrates two innovations: (i)
Stage-mixed Bidirectional and Skewed KL-Divergence and (ii) Adaptive
Mixed-Precision Quantization. The experimental results demonstrate that
TinyMusician retains 93% of the MusicGen-Small performance with 55% less model
size. TinyMusician is the first mobile-deployable music generation model that
eliminates cloud dependency while maintaining high audio fidelity and efficient
resource usage

</details>


### [83] [A Unified Denoising and Adaptation Framework for Self-Supervised Bengali Dialectal ASR](https://arxiv.org/abs/2509.00988)
*Swadhin Biswas,Imran,Tuhin Sheikh*

Main category: cs.SD

TL;DR: 本文提出了一种基于WavLM的新型统一框架，通过多阶段微调策略和针对性数据增强，同时解决孟加拉语ASR中的方言多样性和环境噪声挑战，在多种噪声条件下显著优于现有基线模型。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语作为世界第五大语言，其ASR系统面临两大挑战：巨大的方言多样性和现实环境中的声学噪声。现有SSL模型缺乏明确的噪声处理机制和方言适应策略，严重影响了2.7亿使用者的技术可及性。

Method: 基于具有掩码语音去噪预训练目标的WavLM模型，提出多阶段微调策略：首先适应通用标准孟加拉语建立语言基础，然后通过针对性数据增强专门化用于噪声鲁棒的方言识别。

Result: 在包含多种孟加拉语方言和广泛模拟噪声条件的综合基准测试中，该框架显著优于包括标准微调wav2vec 2.0和大规模多语言Whisper模型在内的强基线，建立了新的最先进水平。

Conclusion: 该工作为开发实用的低资源、高变异语言ASR系统提供了可扩展且有效的蓝图，为解决类似语言的技术可及性问题提供了重要参考。

Abstract: Automatic Speech Recognition (ASR) for Bengali, the world's fifth most spoken
language, remains a significant challenge, critically hindering technological
accessibility for its over 270 million speakers. This challenge is compounded
by two persistent and intertwined factors: the language's vast dialectal
diversity and the prevalence of acoustic noise in real-world environments.
While state-of-the-art self-supervised learning (SSL) models have advanced ASR
for low-resource languages, they often lack explicit mechanisms to handle
environmental noise during pre-training or specialized adaptation strategies
for the complex phonetic and lexical variations across Bengali dialects. This
paper introduces a novel, unified framework designed to address these dual
challenges simultaneously. Our approach is founded on the WavLM model, which is
uniquely pre-trained with a masked speech denoising objective, making it
inherently robust to acoustic distortions. We propose a specialized multi-stage
fine-tuning strategy that first adapts the model to general-domain standard
Bengali to establish a strong linguistic foundation and subsequently
specializes it for noise-robust dialectal recognition through targeted data
augmentation. The framework is rigorously evaluated on a comprehensive
benchmark comprising multiple Bengali dialects under a wide range of simulated
noisy conditions, from clean audio to low Signal-to-Noise Ratio (SNR) levels.
  Experimental results demonstrate that the proposed framework significantly
outperforms strong baselines, including standard fine-tuned wav2vec 2.0 and the
large-scale multilingual Whisper model. This work establishes a new
state-of-the-art for this task and provides a scalable, effective blueprint for
developing practical ASR systems for other low-resource, high-variation
languages globally.

</details>


### [84] [EZhouNet:A framework based on graph neural network and anchor interval for the respiratory sound event detection](https://arxiv.org/abs/2509.01153)
*Yun Chu,Qiuhao Wang,Enze Zhou,Qian Liu,Gang Zheng*

Main category: cs.SD

TL;DR: 提出基于图神经网络和锚点区间的呼吸音事件检测框架，能够处理变长音频并提供更精确的时间定位，结合呼吸位置信息提升异常声音检测性能


<details>
  <summary>Details</summary>
Motivation: 现有呼吸音事件检测方法主要依赖帧级预测和后处理，难以直接学习区间边界，且大多只能处理固定长度音频，限制了在变长呼吸音中的应用。呼吸音位置信息对检测性能的影响也未被充分探索

Method: 基于图神经网络的框架，使用锚点区间来处理变长音频，提供更精确的时间定位。整合呼吸位置信息来增强异常声音的区分能力

Result: 在SPRSound 2024和HF Lung V1数据集上的实验证明了方法的有效性，结合呼吸位置信息能够提升异常声音的判别性能

Conclusion: 该方法提高了呼吸音检测的灵活性和适用性，为呼吸音事件检测提供了新的解决方案

Abstract: Auscultation is a key method for early diagnosis of respiratory and pulmonary
diseases, relying on skilled healthcare professionals. However, the process is
often subjective, with variability between experts. As a result, numerous deep
learning-based automatic classification methods have emerged, most of which
focus on respiratory sound classification. In contrast, research on respiratory
sound event detection remains limited. Existing sound event detection methods
typically rely on frame-level predictions followed by post-processing to
generate event-level outputs, making interval boundaries challenging to learn
directly. Furthermore, many approaches can only handle fixed-length audio, lim-
iting their applicability to variable-length respiratory sounds. Additionally,
the impact of respiratory sound location information on detection performance
has not been extensively explored. To address these issues, we propose a graph
neural network-based framework with anchor intervals, capable of handling
variable-length audio and providing more precise temporal localization for
abnormal respi- ratory sound events. Our method improves both the flexibility
and applicability of respiratory sound detection. Experiments on the SPRSound
2024 and HF Lung V1 datasets demonstrate the effec- tiveness of the proposed
approach, and incorporating respiratory position information enhances the
discrimination between abnormal sounds.

</details>


### [85] [The AudioMOS Challenge 2025](https://arxiv.org/abs/2509.01336)
*Wen-Chin Huang,Hui Wang,Cheng Liu,Yi-Chiao Wu,Andros Tjandra,Wei-Ning Hsu,Erica Cooper,Yong Qin,Tomoki Toda*

Main category: cs.SD

TL;DR: AudioMOS Challenge 2025是首个针对合成音频主观质量预测的挑战赛，包含三个赛道：文本到音乐质量评估、多维度音频美学评估和不同采样率语音质量评估，吸引了24个团队参与并取得了超越基线的进展。


<details>
  <summary>Details</summary>
Motivation: 随着音频生成系统的快速发展，需要建立自动化的主观质量评估方法来替代耗时的人工评估，推动音频生成领域的进步。

Method: 挑战赛设置了三个赛道：1）文本到音乐样本的整体质量和文本对齐评估；2）基于Meta Audiobox美学四个维度的多模态音频评估；3）不同采样率下的合成语音质量评估。

Result: 吸引了来自学术界和工业界的24个独特团队参与，所有团队的表现都超过了基线模型，证明了自动评估方法的有效性。

Conclusion: 该挑战赛的成功举办将为音频生成系统的自动评估领域的发展提供重要推动力，促进该领域的技术进步和标准化建设。

Abstract: This is the summary paper for the AudioMOS Challenge 2025, the very first
challenge for automatic subjective quality prediction for synthetic audio. The
challenge consists of three tracks. The first track aims to assess
text-to-music samples in terms of overall quality and textual alignment. The
second track is based on the four evaluation dimensions of Meta Audiobox
Aesthetics, and the test set consists of text-to-speech, text-to-audio, and
text-to-music samples. The third track focuses on synthetic speech quality
assessment in different sampling rates. The challenge attracted 24 unique teams
from both academia and industry, and improvements over the baselines were
confirmed. The outcome of this challenge is expected to facilitate development
and progress in the field of automatic evaluation for audio generation systems.

</details>


### [86] [CabinSep: IR-Augmented Mask-Based MVDR for Real-Time In-Car Speech Separation with Distributed Heterogeneous Arrays](https://arxiv.org/abs/2509.01399)
*Runduo Han,Yanxin Hu,Yihui Fu,Zihan Zhang,Yukai Jv,Li Chen,Lei Xie*

Main category: cs.SD

TL;DR: CabinSep是一种轻量级神经网络语音分离方法，通过MVDR技术和数据增强，在车载环境中有效分离重叠语音，降低语音识别错误率17.5%


<details>
  <summary>Details</summary>
Motivation: 解决车载环境中多人重叠语音分离问题，提高语音识别系统在复杂声学环境下的性能

Method: 使用通道信息提取空间特征，采用MVDR技术减少语音失真，结合模拟和真实脉冲响应的数据增强方法

Result: 计算复杂度仅0.4 GMACs，在真实数据集上相比DualSep模型实现17.5%的相对语音识别错误率降低

Conclusion: CabinSep提供了一种高效的车载语音分离解决方案，在保持低计算复杂度的同时显著提升语音识别性能

Abstract: Separating overlapping speech from multiple speakers is crucial for effective
human-vehicle interaction. This paper proposes CabinSep, a lightweight neural
mask-based minimum variance distortionless response (MVDR) speech separation
approach, to reduce speech recognition errors in back-end automatic speech
recognition (ASR) models. Our contributions are threefold: First, we utilize
channel information to extract spatial features, which improves the estimation
of speech and noise masks. Second, we employ MVDR during inference, reducing
speech distortion to make it more ASR-friendly. Third, we introduce a data
augmentation method combining simulated and real-recorded impulse responses
(IRs), improving speaker localization at zone boundaries and further reducing
speech recognition errors. With a computational complexity of only 0.4 GMACs,
CabinSep achieves a 17.5% relative reduction in speech recognition error rate
in a real-recorded dataset compared to the state-of-the-art DualSep model.
Demos are available at: https://cabinsep.github.io/cabinsep/.

</details>


### [87] [ArabEmoNet: A Lightweight Hybrid 2D CNN-BiLSTM Model with Attention for Robust Arabic Speech Emotion Recognition](https://arxiv.org/abs/2509.01401)
*Ali Abouzeid,Bilal Elbouardi,Mohamed Maged,Shady Shehata*

Main category: cs.SD

TL;DR: ArabEmoNet是一个轻量级阿拉伯语语音情感识别架构，仅使用100万参数，比主流模型小90倍，但性能更优。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语等低资源语言在语音情感识别方面面临数据有限和研究不足的挑战，需要高效且性能优越的解决方案。

Method: 使用Mel频谱图通过2D卷积处理，替代传统的离散MFCC特征和1D卷积，以保留传统方法中丢失的关键情感线索。

Result: ArabEmoNet在参数规模仅为HuBERT base的1/90和Whisper的1/74的情况下，实现了最先进的性能表现。

Conclusion: 该模型为资源受限环境提供了理想的阿拉伯语语音情感识别解决方案，在性能和可访问性方面都有显著进步。

Abstract: Speech emotion recognition is vital for human-computer interaction,
particularly for low-resource languages like Arabic, which face challenges due
to limited data and research. We introduce ArabEmoNet, a lightweight
architecture designed to overcome these limitations and deliver
state-of-the-art performance. Unlike previous systems relying on discrete MFCC
features and 1D convolutions, which miss nuanced spectro-temporal patterns,
ArabEmoNet uses Mel spectrograms processed through 2D convolutions, preserving
critical emotional cues often lost in traditional methods.
  While recent models favor large-scale architectures with millions of
parameters, ArabEmoNet achieves superior results with just 1 million
parameters, 90 times smaller than HuBERT base and 74 times smaller than
Whisper. This efficiency makes it ideal for resource-constrained environments.
ArabEmoNet advances Arabic speech emotion recognition, offering exceptional
performance and accessibility for real-world applications.

</details>


### [88] [From Discord to Harmony: Decomposed Consonance-based Training for Improved Audio Chord Estimation](https://arxiv.org/abs/2509.01588)
*Andrea Poltronieri,Xavier Serra,Martín Rocamora*

Main category: cs.SD

TL;DR: 本文提出了一种基于协和度感知的和弦估计方法，通过引入协和度距离度量来评估标注一致性，并开发了结合协和度标签平滑的conformer模型来解决和弦估计中的标注主观性和类别不平衡问题。


<details>
  <summary>Details</summary>
Motivation: 音频和弦估计任务面临标注主观性和类别不平衡两大挑战：不同标注者对同一音乐可能有不同的和弦解释，导致标注不一致；数据集中某些和弦类别过度代表，影响模型训练和评估。

Method: 1) 使用超越传统二元度量的指标评估标注者间一致性；2) 提出基于协和度的感知相似性距离度量；3) 开发conformer模型，通过协和度标签平滑整合协和度概念，并分别估计根音、低音和所有音符激活来重建和弦标签。

Result: 分析表明基于协和度的距离度量能更有效地捕捉标注间的音乐意义一致性。提出的模型通过分解输出重建和弦标签，有效解决了类别不平衡问题。

Conclusion: 协和度感知方法为和弦估计提供了更音乐化的评估框架，结合conformer架构的分解方法能够更好地处理标注主观性和数据不平衡问题，推动了音频和弦估计技术的发展。

Abstract: Audio Chord Estimation (ACE) holds a pivotal role in music information
research, having garnered attention for over two decades due to its relevance
for music transcription and analysis. Despite notable advancements, challenges
persist in the task, particularly concerning unique characteristics of harmonic
content, which have resulted in existing systems' performances reaching a glass
ceiling. These challenges include annotator subjectivity, where varying
interpretations among annotators lead to inconsistencies, and class imbalance
within chord datasets, where certain chord classes are over-represented
compared to others, posing difficulties in model training and evaluation. As a
first contribution, this paper presents an evaluation of inter-annotator
agreement in chord annotations, using metrics that extend beyond traditional
binary measures. In addition, we propose a consonance-informed distance metric
that reflects the perceptual similarity between harmonic annotations. Our
analysis suggests that consonance-based distance metrics more effectively
capture musically meaningful agreement between annotations. Expanding on these
findings, we introduce a novel ACE conformer-based model that integrates
consonance concepts into the model through consonance-based label smoothing.
The proposed model also addresses class imbalance by separately estimating
root, bass, and all note activations, enabling the reconstruction of chord
labels from decomposed outputs.

</details>


### [89] [Music Genre Classification Using Machine Learning Techniques](https://arxiv.org/abs/2509.01762)
*Alokit Mishra,Ryyan Akhtar*

Main category: cs.SD

TL;DR: 传统SVM分类器在音乐流派分类任务中表现优于端到端CNN模型，特别是在数据受限的GTZAN数据集上，表明特征工程在中等规模数据集上仍具有重要价值


<details>
  <summary>Details</summary>
Motivation: 比较传统机器学习方法（如SVM和集成方法）与深度学习CNN模型在音乐流派自动分类任务中的性能表现，探讨在数据受限情况下哪种方法更有效

Method: 使用GTZAN数据集，对比基于手工设计音频特征的传统分类器（SVM和集成方法）与基于梅尔频谱图的端到端CNN模型的分类性能

Result: SVM分类器凭借领域特定的特征工程获得了比CNN模型更高的分类准确率，表明在数据受限情况下传统特征提取方法具有优势

Conclusion: 研究强调了传统特征工程在实际音频处理任务中的持久相关性，并对深度学习在中等规模数据集上的普适性提出了批判性视角

Abstract: This paper presents a comparative analysis of machine learning methodologies
for automatic music genre classification. We evaluate the performance of
classical classifiers, including Support Vector Machines (SVM) and ensemble
methods, trained on a comprehensive set of hand-crafted audio features, against
a Convolutional Neural Network (CNN) operating on Mel spectrograms. The study
is conducted on the widely-used GTZAN dataset. Our findings demonstrate a
noteworthy result: the SVM, leveraging domain-specific feature engineering,
achieves superior classification accuracy compared to the end-to-end CNN model.
We attribute this outcome to the data-constrained nature of the benchmark
dataset, where the strong inductive bias of engineered features provides a
regularization effect that mitigates the risk of overfitting inherent in
high-capacity deep learning models. This work underscores the enduring
relevance of traditional feature extraction in practical audio processing tasks
and provides a critical perspective on the universal applicability of deep
learning, especially for moderately sized datasets.

</details>


### [90] [FireRedTTS-2: Towards Long Conversational Speech Generation for Podcast and Chatbot](https://arxiv.org/abs/2509.02020)
*Kun Xie,Feiyu Shen,Junjie Li,Fenglong Xie,Xu Tang,Yao Hu*

Main category: cs.SD

TL;DR: FireRedTTS-2是一个用于多说话人对话生成的长格式流式TTS系统，通过新的12.5Hz流式语音标记器和双变换器架构，实现了稳定的自然语音、可靠的说话人切换和上下文感知的韵律。


<details>
  <summary>Details</summary>
Motivation: 当前对话生成方法需要完整对话文本才能合成，产生包含所有声音的单一不可分割语音，不适合交互式聊天，且存在合成不稳定、说话人转换不准确和韵律不连贯的问题。

Method: 采用新的12.5Hz流式语音标记器加速训练和推理，使用文本-语音交错格式，通过双变换器架构（大型仅解码器变换器预测第一层标记，较小变换器完成后续层）进行建模。

Result: 实验结果表明，FireRedTTS-2能够无缝集成到聊天框架中，通过最小微调产生由隐式上下文线索引导的情感表达语音。在播客生成中，在客观可懂度、说话人轮换可靠性和感知自然度方面超越了现有系统。

Conclusion: FireRedTTS-2系统为多说话人对话生成提供了稳定、自然的流式合成解决方案，在交互性和语音质量方面都有显著提升。

Abstract: Current dialogue generation approaches typically require the complete
dialogue text before synthesis and produce a single, inseparable speech
containing all voices, making them unsuitable for interactive chat; moreover,
they suffer from unstable synthesis, inaccurate speaker transitions, and
incoherent prosody. In this work, we present FireRedTTS-2, a long-form
streaming TTS system for multi-speaker dialogue generation, delivering stable,
natural speech with reliable speaker switching and context-aware prosody. A new
12.5Hz streaming speech tokenizer accelerates training and inference, extends
maximum dialogue length, encodes richer semantics to stabilize text-to-token
modeling and supports high-fidelity streaming generation for real-time
applications. We adopt a text-speech interleaved format, concatenating
speaker-labeled text with aligned speech tokens in chronological order, and
model it with a dual-transformer: a large decoder-only transformer predicts
tokens at the first layer, and a smaller one completes subsequent layers.
Experimental results show that FireRedTTS-2 integrates seamlessly with chat
frameworks and, with minimal fine-tuning, produces emotionally expressive
speech guided by implicit contextual cues. In podcast generation, it surpasses
existing systems including MoonCast, Zipvoice-Dialogue, and MOSS-TTSD in
objective intelligibility, speaker-turn reliability, and perceived naturalness
with context-consistent prosody. Our demos are available at
https://fireredteam.github.io/demos/firered_tts_2.

</details>


### [91] [AudioRWKV: Efficient and Stable Bidirectional RWKV for Audio Pattern Recognition](https://arxiv.org/abs/2509.02167)
*Jiayu Xiong,Jun Xue,Jianlong Kwan,Jing Wang*

Main category: cs.SD

TL;DR: 这篇论文提出了AudioRWKV (A-RWKV)架构，一种高效稳定的音频建模方案，解决了Transformer计算复杂度高和Mamba稳定性差的问题


<details>
  <summary>Details</summary>
Motivation: Transformer架构在音频建模中遇到O(L^2)计算复杂度问题，而Mamba架构在扩展参数和数据时稳定性不足，需要一种更高效稳定的方案

Method: 继承RWKV7的稳定递归形式，将原始1D token-shift操作替换为2D深度分离卷积，并将原始因果WKV内核适配为双向WKV内核(Bi-WKV)，支持全局上下文建模

Result: A-RWKV-S (22M)在相同线性模型体系下达到了与AuM-B (92M)相当的性能，通用能力比AST更稳定，在长音频(~5分28秒)处理中实现了最13.3倍的速度提升

Conclusion: A-RWKV架构通过结合RWKV7的稳定性和高效性，成功解决了音频建模中的长序列处理问题，并体现了良好的扩展性能

Abstract: Recently, Transformers (e.g., Audio Spectrogram Transformers, AST) and
state-space models (e.g., Audio Mamba, AuM) have achieved remarkable progress
in audio modeling. However, the O(L^2) computational complexity of the
Transformer architecture hinders efficient long-sequence processing, while the
Mamba architecture tends to become unstable when scaling parameters and data.
To address these challenges, this paper proposes AudioRWKV (A-RWKV), a highly
efficient and stable architecture for audio modeling. Specifically, we inherit
the stable and efficient recurrent formulation of RWKV7 and replace its 1D
token-shift operation with a 2D depthwise separable convolution to better
capture local spectro-temporal patterns. Furthermore, we adapt the original
causal WKV kernel into a bidirectional WKV kernel (Bi-WKV), enabling global
context modeling over the entire audio sequence while maintaining linear
computational complexity. Benefiting from the inherent stability of the RWKV7
foundation, A-RWKV scales seamlessly to larger model sizes. Experimental
results demonstrate that, under the same linear-model regime, A-RWKV-S (22M)
achieves performance parity with AuM-B (92M) while exhibiting more stable
throughput than AST; for long-form audio (~5 minutes 28 seconds), WKV7 achieves
up to a 13.3X speedup in processing.

</details>


### [92] [Spectrogram Patch Codec: A 2D Block-Quantized VQ-VAE and HiFi-GAN for Neural Speech Coding](https://arxiv.org/abs/2509.02244)
*Luis Felipe Chary,Miguel Arjona Ramirez*

Main category: cs.SD

TL;DR: 提出了一种简化的神经语音编解码器，使用单阶段量化方法替代复杂的残差向量量化(RVQ)，通过4x4频谱图块量化和共享码本实现低延迟流式处理，在7.5kbps码率下达到竞争性音质。


<details>
  <summary>Details</summary>
Motivation: 挑战传统神经语音编解码器中复杂的残差向量量化(RVQ)堆栈的必要性，寻求更简单、低延迟的量化方法。

Method: 将mel频谱图视为2D数据，对非重叠的4x4块进行单阶段量化到共享码本；采用后期对抗微调VQ-VAE，并基于重建频谱图训练HiFi-GAN声码器。

Result: 在16kHz语音约7.5kbits/s码率下，通过STOI、PESQ、MCD、ViSQOL等客观指标评估，显示该简化架构达到了竞争性的感知质量和可懂度。

Conclusion: 验证了简化非残差架构的有效性，为未来低延迟编解码器设计提供了开放基础，证明了复杂RVQ堆栈并非必要。

Abstract: We present a neural speech codec that challenges the need for complex
residual vector quantization (RVQ) stacks by introducing a simpler,
single-stage quantization approach. Our method operates directly on the
mel-spectrogram, treating it as a 2D data and quantizing non-overlapping 4x4
patches into a single, shared codebook. This patchwise design simplifies the
architecture, enables low-latency streaming, and yields a discrete latent grid.
To ensure high-fidelity synthesis, we employ a late-stage adversarial
fine-tuning for the VQ-VAE and train a HiFi-GAN vocoder from scratch on the
codec's reconstructed spectrograms. Operating at approximately 7.5 kbits/s for
16 kHz speech, our system was evaluated against several state-of-the-art neural
codecs using objective metrics such as STOI, PESQ, MCD, and ViSQOL. The results
demonstrate that our simplified, non-residual architecture achieves competitive
perceptual quality and intelligibility, validating it as an effective and open
foundation for future low-latency codec designs.

</details>


### [93] [Speech transformer models for extracting information from baby cries](https://arxiv.org/abs/2509.02259)
*Guillem Bonafos,Jéremy Rouch,Lény Lego,David Reby,Hugues Patural,Nicolas Mathevon,Rémy Emonet*

Main category: cs.SD

TL;DR: 研究表明预训练语音模型的潜在表示能有效分类婴儿哭声，编码了声音源不稳定性和婴儿身份的关键信息，为类似情感检测任务提供了模型设计参考。


<details>
  <summary>Details</summary>
Motivation: 探索预训练语音模型在非语音数据（婴儿哭声）上的适用性，以及这些潜在表示编码的具体声学特性。

Method: 评估5个预训练语音模型在8个婴儿哭声数据集（115小时音频，960个婴儿）上的表现，分析各模型在所有可用分类任务中的潜在表示。

Result: 预训练语音模型的潜在表示能有效分类婴儿哭声，编码了声音源不稳定性和婴儿身份信息。

Conclusion: 研究为针对类似任务（如情感检测）的未来模型设计提供了有价值的架构和训练策略参考。

Abstract: Transfer learning using latent representations from pre-trained speech models
achieves outstanding performance in tasks where labeled data is scarce.
However, their applicability to non-speech data and the specific acoustic
properties encoded in these representations remain largely unexplored. In this
study, we investigate both aspects. We evaluate five pre-trained speech models
on eight baby cries datasets, encompassing 115 hours of audio from 960 babies.
For each dataset, we assess the latent representations of each model across all
available classification tasks. Our results demonstrate that the latent
representations of these models can effectively classify human baby cries and
encode key information related to vocal source instability and identity of the
crying baby. In addition, a comparison of the architectures and training
strategies of these models offers valuable insights for the design of future
models tailored to similar tasks, such as emotion detection.

</details>


### [94] [AudioCodecBench: A Comprehensive Benchmark for Audio Codec Evaluation](https://arxiv.org/abs/2509.02349)
*Lu Wang,Hao Chen,Siyu Wu,Zhiyue Wu,Hao Zhou,Chengfeng Zhang,Ting Wang,Haodi Zhang*

Main category: cs.SD

TL;DR: 本文提出了音频token的语义和声学token的合适定义，并建立了一个系统性评估框架来全面评估不同音频编解码器的能力，包括重建质量、代码本稳定性、困惑度和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在语音和音乐应用中广泛使用音频tokenization，但现有研究对语义token和声学token的定义不恰当，且评估方法局限于特定领域或任务，缺乏公平全面的比较。

Method: 提供了语义token和声学token的合适定义，并引入了一个系统性评估框架，从四个维度评估编解码器能力：音频重建指标、代码本索引稳定性、仅解码器transformer的困惑度、以及下游探测任务性能。

Result: 研究结果验证了所提供合适定义的正确性，并揭示了重建指标、代码本稳定性、下游探测任务和困惑度之间的相关性。

Conclusion: 该研究为音频tokenization提供了更准确的定义和全面的评估框架，有助于促进多模态大语言模型在音频处理领域的发展和应用。

Abstract: Multimodal Large Language Models (MLLMs) have been widely applied in speech
and music. This tendency has led to a focus on audio tokenization for Large
Models (LMs). Unlike semantic-only text tokens, audio tokens must both capture
global semantic content and preserve fine-grained acoustic details. Moreover,
they provide a discrete method for speech and music that can be effectively
integrated into MLLMs. However, existing research is unsuitable in the
definitions of semantic tokens and acoustic tokens. In addition, the evaluation
of different codecs typically concentrates on specific domains or tasks, such
as reconstruction or Automatic Speech Recognition (ASR) task, which prevents
fair and comprehensive comparisons. To address these problems, this paper
provides suitable definitions for semantic and acoustic tokens and introduces a
systematic evaluation framework. This framework allows for a comprehensive
assessment of codecs' capabilities which evaluate across four dimensions: audio
reconstruction metric, codebook index (ID) stability, decoder-only transformer
perplexity, and performance on downstream probe tasks. Our results show the
correctness of the provided suitable definitions and the correlation among
reconstruction metrics, codebook ID stability, downstream probe tasks and
perplexity.

</details>


### [95] [TTA-Bench: A Comprehensive Benchmark for Evaluating Text-to-Audio Models](https://arxiv.org/abs/2509.02398)
*Hui Wang,Cheng Liu,Junyang Chen,Haoze Liu,Yuhang Jia,Shiwan Zhao,Jiaming Zhou,Haoqin Sun,Hui Bu,Yong Qin*

Main category: cs.SD

TL;DR: TTA-Bench是一个全面的文本到音频生成模型评估基准，涵盖7个维度包括准确性、鲁棒性、公平性和毒性等，包含2999个多样化提示词，结合客观指标和超过11.8万个人工标注，对10个最先进模型进行了全面评估。


<details>
  <summary>Details</summary>
Motivation: 当前文本到音频生成模型的评估方法过于狭窄，主要关注感知质量，而忽视了鲁棒性、泛化能力和伦理问题，需要建立一个更全面的评估标准。

Method: 开发了TTA-Bench基准，包含2999个多样化提示词，采用自动和人工方法生成，建立统一的评估协议，结合客观指标和专家与普通用户的118,000多个人工标注。

Result: 对10个最先进的TTA模型进行了基准测试，提供了详细的优劣势分析，建立了TTA系统整体和负责任评估的新标准。

Conclusion: TTA-Bench为文本到音频生成模型的全面评估设立了新标准，数据集和评估工具已开源，促进了该领域更负责任的发展。

Abstract: Text-to-Audio (TTA) generation has made rapid progress, but current
evaluation methods remain narrow, focusing mainly on perceptual quality while
overlooking robustness, generalization, and ethical concerns. We present
TTA-Bench, a comprehensive benchmark for evaluating TTA models across
functional performance, reliability, and social responsibility. It covers seven
dimensions including accuracy, robustness, fairness, and toxicity, and includes
2,999 diverse prompts generated through automated and manual methods. We
introduce a unified evaluation protocol that combines objective metrics with
over 118,000 human annotations from both experts and general users. Ten
state-of-the-art models are benchmarked under this framework, offering detailed
insights into their strengths and limitations. TTA-Bench establishes a new
standard for holistic and responsible evaluation of TTA systems. The dataset
and evaluation tools are open-sourced at https://nku-hlt.github.io/tta-bench/.

</details>


### [96] [ESTM: An Enhanced Dual-Branch Spectral-Temporal Mamba for Anomalous Sound Detection](https://arxiv.org/abs/2509.02471)
*Chengyuan Ma,Peng Jia,Hongyue Guo,Wenming Yang*

Main category: cs.SD

TL;DR: 提出基于双路径Mamba架构的ESTM框架，通过时间-频率解耦建模和选择性状态空间模型来捕捉工业设备异常声音检测中的长程时间模式和跨频带动态耦合特征。


<details>
  <summary>Details</summary>
Motivation: 工业设备异常声音检测的核心挑战在于建模声学特征的时间-频率耦合特性，现有方法受限于局部感受野，难以捕捉长程时间模式和跨频带动态耦合效应。

Method: ESTM框架采用双路径Mamba架构，结合时间-频率解耦建模和选择性状态空间模型(SSM)，融合增强的梅尔频谱图和原始音频特征，并通过TriStat-Gating(TSG)模块提高对异常模式的敏感性。

Result: 在DCASE 2020 Task 2数据集上的实验表明，ESTM提高了异常检测性能，验证了所提方法的有效性。

Conclusion: ESTM框架通过创新的双路径Mamba架构和选择性状态空间建模，有效解决了工业设备异常声音检测中的长程时间-频率耦合特征建模问题，取得了显著的性能提升。

Abstract: The core challenge in industrial equipment anoma lous sound detection (ASD)
lies in modeling the time-frequency coupling characteristics of acoustic
features. Existing modeling methods are limited by local receptive fields,
making it difficult to capture long-range temporal patterns and cross-band
dynamic coupling effects in machine acoustic features. In this paper, we
propose a novel framework, ESTM, which is based on a dual-path Mamba
architecture with time-frequency decoupled modeling and utilizes Selective
State-Space Models (SSM) for long-range sequence modeling. ESTM extracts rich
feature representations from different time segments and frequency bands by
fusing enhanced Mel spectrograms and raw audio features, while further
improving sensitivity to anomalous patterns through the TriStat-Gating (TSG)
module. Our experiments demonstrate that ESTM improves anomalous detection
performance on the DCASE 2020 Task 2 dataset, further validating the
effectiveness of the proposed method.

</details>


### [97] [FLM-Audio: Natural Monologues Improves Native Full-Duplex Chatbots via Dual Training](https://arxiv.org/abs/2509.02521)
*Yiqun Yao,Xiang Li,Xin Jiang,Xuezhi Fang,Naitong Yu,Wenjia Ma,Aixin Sun,Yequan Wang*

Main category: cs.SD

TL;DR: 本文提出了一种新的全双工对话模型FLM-Audio，通过模仿人类认知行为的自然独白训练方式，解决了音频流与文本对齐的挑战，实现了更优的响应速度和对话体验。


<details>
  <summary>Details</summary>
Motivation: 现有全双工对话模型在文本独白与音频流对齐方面遇到挑战：单词级别对齐会降低大型预训练模型的语言能力，且需要高精度的时间戳，导致累积错误和高处理成本。

Method: 提出了"自然"独白方法，将文本独白表示为连续的token序列，模仿人类对话认知。在不同训练阶段交替将自然独白放在音频前面或后面，形成"双重"训练范式。

Result: 构建了FLM-Audio 7B语音对话模型，实验结果证明其在响应速度、全双工能力和聊天体验方面都显示出优异性能。

Conclusion: 该方法有效解决了音频流与文本对齐的问题，不仅保持了大型预训练模型的语言能力，还减少了前期处理成本，为全双工对话模型的发展提供了新的解决方案。

Abstract: Full-duplex dialog models are designed to listen and speak simultaneously
with rapid responses to fast-changing user input. Among existing approaches,
native full-duplex models merges different channels (e.g. listen and speak) in
a single time step, overcoming the high response latency inherent to
time-division multiplexing time-division multiplexing (TDM) alternatives. Yet,
a key challenge remains: aligning textual monologues with audio streams that
operate at different bitrates. The prevailing solution relies on word-level
alignment, but this can degrade the language ability of large pre-trained
models. Moreover, it requires highly accurate timestamps for every token, which
introduces cascading errors and increases pre-processing costs. In this paper,
we propose textual monologues in continuous tokens sequence, namely "natural"
monologues, which mimics humanoid cognitive behavior in dialogs. For temporal
alignment, we alternate the position of the natural monologue - leading or
trailing the audio - across different training stages. This "dual" training
paradigm proves highly effective in building FLM-Audio, our 7B spoken dialog
model that demonstrates superior responsiveness, duplexity, and chatting
experiences, as confirmed by experimental results.

</details>

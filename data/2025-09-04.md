<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 14]
- [eess.AS](#eess.AS) [Total: 7]
- [cs.SD](#cs.SD) [Total: 3]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [EEG-MSAF: An Interpretable Microstate Framework uncovers Default-Mode Decoherence in Early Neurodegeneration](https://arxiv.org/abs/2509.02568)
*Mohammad Mehedi Hasan,Pedro G. Lind,Hernando Ombao,Anis Yazidi,Rabindra Khadka*

Main category: eess.SP

TL;DR: 一个基于EEG微观态分析的端到端框架，通过机器学习和SHAP解释性分析，在疑惑症诊断中实现了高准确率和良好的可推广性


<details>
  <summary>Details</summary>
Motivation: 疑惑症是全球急需解决的健康挑战，需要早期准确诊断。传统EEG方法无法抓取脑电活动的瞬态复杂性，需要更有效的分析方法

Method: 开发了EEG微观态分析框架(EEG-MSAF)，包括三个阶段：自动化微观态特征提取、机器学习分类、SHAP特征排名解释

Result: 在CAUEEG数据集上达到89%准确率(超过深度学习基准模19.3%)，在Thessaloniki数据集上达到95%准确率。SHAP分析发现微观态C和F是关键生物标记

Conclusion: EEG-MSAF框架结合了高准确率、良好可推广性和可解释性，推进了EEG基于疑惑症诊断的发展，为认知过程中的脑动态提供了新视角

Abstract: Dementia (DEM) is a growing global health challenge, underscoring the need
for early and accurate diagnosis. Electroencephalography (EEG) provides a
non-invasive window into brain activity, but conventional methods struggle to
capture its transient complexity. We present the \textbf{EEG Microstate
Analysis Framework (EEG-MSAF)}, an end-to-end pipeline that leverages EEG
microstates discrete, quasi-stable topographies to identify DEM-related
biomarkers and distinguish DEM, mild cognitive impairment (MCI), and normal
cognition (NC). EEG-MSAF comprises three stages: (1) automated microstate
feature extraction, (2) classification with machine learning (ML), and (3)
feature ranking using Shapley Additive Explanations (SHAP) to highlight key
biomarkers. We evaluate on two EEG datasets: the public Chung-Ang University
EEG (CAUEEG) dataset and a clinical cohort from Thessaloniki Hospital. Our
framework demonstrates strong performance and generalizability. On CAUEEG,
EEG-MSAF-SVM achieves \textbf{89\% $\pm$ 0.01 accuracy}, surpassing the deep
learning baseline CEEDNET by \textbf{19.3\%}. On the Thessaloniki dataset, it
reaches \textbf{95\% $\pm$ 0.01 accuracy}, comparable to EEGConvNeXt. SHAP
analysis identifies mean correlation and occurrence as the most informative
metrics: disruption of microstate C (salience/attention network) dominates DEM
prediction, while microstate F, a novel default-mode pattern, emerges as a key
early biomarker for both MCI and DEM. By combining accuracy, generalizability,
and interpretability, EEG-MSAF advances EEG-based dementia diagnosis and sheds
light on brain dynamics across the cognitive spectrum.

</details>


### [2] [Recall Gabor Communication Theory and Joint Time-Frequency Analysis](https://arxiv.org/abs/2509.02724)
*Xiang-Gen Xia*

Main category: eess.SP

TL;DR: 回顾Gabor的通信理论、Gabor变换和展开，及其与联合时频分析的联系


<details>
  <summary>Details</summary>
Motivation: 系统梳理Gabor通信理论及其在时频分析中的应用，建立理论框架

Method: 通过文献回顾和理论分析，阐述Gabor变换的数学基础和与时频分析的关系

Result: 明确了Gabor理论在通信和信号处理中的基础地位，建立了Gabor变换与时频分析的连接

Conclusion: Gabor理论为现代时频分析提供了重要数学工具，在信号处理领域具有基础性意义

Abstract: In this article, we first briefly recall Gabor's communication theory and
then Gabor transform and expansion, and also its connection with joint time
frequency analysis.

</details>


### [3] [minPIC: Towards Optimal Power Allocation in Multi-User Interference Channels](https://arxiv.org/abs/2509.02797)
*Sagnik Bhattacharya,Abhiram Rao Gorle,John M. Cioffi*

Main category: eess.SP

TL;DR: 提出了minPIC框架，用于6G无蜂窝网络中多用户干扰信道的最优功率、子载波和解码顺序分配，消除了传统启发式SIC顺序假设，实现了高斯干扰信道SIC可达速率区域的帕累托边界。


<details>
  <summary>Details</summary>
Motivation: 6G大规模无蜂窝网络需要在不进行集中协调的情况下处理空间嵌套的多址接入和广播信道干扰，现有OMA、NOMA和RSMA方案依赖固定启发式方法，导致速率次优、功率效率低和可扩展性问题。

Method: 引入双变量引导的排序准则来识别全局最优SIC顺序，然后通过带有辅助对数行列式约束的凸优化进行求解，采用二分搜索高效解决。

Result: minPIC能够实现高斯干扰信道SIC可达速率区域的帕累托边界，有望满足沉浸式XR等6G应用的高速率、低功耗要求。

Conclusion: minPIC是首个算法实现高斯干扰信道SIC可达速率区域帕累托边界的方法，为无蜂窝网络的可扩展干扰管理开辟了新途径。

Abstract: 6G envisions massive cell-free networks with spatially nested multiple access
(MAC) and broadcast (BC) channels without centralized coordination. This makes
optimal resource allocation across power, subcarriers, and decoding orders
crucial for interference channels (ICs), where neither transmitters nor
receivers can cooperate. Current orthogonal multiple access (OMA) methods, as
well as non-orthogonal (NOMA) and rate-splitting (RSMA) schemes, rely on fixed
heuristics for interference management, leading to suboptimal rates, power
inefficiency, and scalability issues. This paper proposes a novel minPIC
framework for optimal power, subcarrier, and decoding order allocation in
general multi-user ICs. Unlike existing methods, minPIC eliminates heuristic
SIC order assumptions. Despite the convexity of the IC capacity region, fixing
an SIC order induces non-convexity in resource allocation, traditionally
requiring heuristic approximations. We instead introduce a dual-variable-guided
sorting criterion to identify globally optimal SIC orders, followed by convex
optimization with auxiliary log-det constraints, efficiently solved via binary
search. We also demonstrate that minPIC could potentially meet the stringent
high-rate, low-power targets of immersive XR and other 6G applications. To the
best of our knowledge, minPIC is the first algorithmic realisation of the
Pareto boundary of the SIC-achievable rate region for Gaussian ICs, opening the
door to scalable interference management in cell-free networks.

</details>


### [4] [Protecting Legacy Wireless Systems Against Interference: Precoding and Codebook Approaches Using Massive MIMO and Region Constraints](https://arxiv.org/abs/2509.02819)
*Sameer Mathad,Taejoon Kim,David J. Love*

Main category: eess.SP

TL;DR: 该论文提出了一种基于通信理论的解决方案，通过在MIMO系统设计中加入区域功率约束来保护传统用户免受新频段使用的干扰，而不是采用地理隔离区的方法。


<details>
  <summary>Details</summary>
Motivation: 随着对高速无线通信需求的增长，使用与传统无线系统相邻的新频段会导致对传统用户的干扰。许多传统无线设备用于关键基础设施网络，迫切需要开发保护传统用户免受干扰的方案。

Method: 通过在Massive MIMO系统设计中加入接收功率约束（区域约束），进行单用户Massive MIMO容量分析和多用户Massive MIMO系统和速率分析，提出了一种预编码设计方法。

Result: 该方法允许在保护传统用户的同时利用新频段，通过理论分析和预编码设计实现了干扰的有效控制。

Conclusion: 基于通信理论的区域约束方法比地理隔离区方法更有效地保护传统用户免受新频段使用的干扰，为高速无线通信发展提供了可行的解决方案。

Abstract: The ever-increasing demand for high-speed wireless communication has
generated significant interest in utilizing frequency bands that are adjacent
to those occupied by legacy wireless systems. Since the legacy wireless systems
were designed based on often decades-old assumptions about wireless
interference, utilizing these new bands will result in interference with the
existing legacy users. Many of these legacy wireless devices are used by
critical infrastructure networks upon which society depends. There is an urgent
need to develop schemes that can protect legacy users from such interference.
For many applications, legacy users are located within
geographically-constrained regions. Several studies have proposed mitigating
interference through the implementation of exclusion zones near these
geographically-constrained regions. In contrast to solutions based on
geographic exclusion zones, this paper presents a communication theory-based
solution. By leveraging knowledge of these geographically-constrained regions,
we aim to reduce the interference impact on legacy users. We achieve this by
incorporating received power constraints, termed as region constraints, in our
massive multiple-input multiple-output (MIMO) system design. We perform a
capacity analysis of single-user massive MIMO and a sum-rate analysis of the
multi-user massive MIMO system with transmit power and region constraints. We
present a precoding design method that allows for the utilization of new
frequency bands while protecting legacy users.

</details>


### [5] [Spatially Adaptive SWIPT with Pinching Antenna under Probabilistic LoS Blockage](https://arxiv.org/abs/2509.03038)
*Ruihong Jiang,Ruichen Zhang,Yanqing Xu,Huimin Hu,Yang Lu,Dusit Niyato*

Main category: eess.SP

TL;DR: 这篇论文研究了在概率性视线阻塞环境下，使用可重配制拉拉天线的力量分割基同时无线信息与能量传输系统，通过关键参数优化提升平均信噪比和能量收集性能。


<details>
  <summary>Details</summary>
Motivation: 在动态环境中实现稳健的同时无线信息与能量传输面临挑战，特别是视线阻塞的概率性质影响了系统性能。需要通过天线位置和力量分割比的动态调整来应对这些挑战。

Method: 构建了关于可重配制拉拉天线位置和力量分割比的聚合优化问题，以最大化用户的平均信噪比，并满足平均能量收集和天线部署限制。推导出了闭式的最优解。

Result: 结果显示能量收集要求对最优天线位置及其可行域有确定性影响，需要将天线尽可能靠近用户以最大化平均通道增益。

Conclusion: 空间适配与动态力量分割结合，能够在概率性视线阻塞环境中实现稳健的同时无线信息与能量传输性能。机械可重配性主要通过确保动态环境中的能量可行性来提升系统的可持续性。

Abstract: This paper considers a power-splitting (PS)-based simultaneous wireless
information and power transfer (SWIPT) system employing a reconfigurable
pinching antenna (PA) under probabilistic line-of-sight (LoS) blockage. We
formulate a joint optimization of the PA position and the PS ratio to maximize
the average signal-to-noise ratio (SNR) at a user, subject to its average
energy harvesting (EH) and PA placement limits. We derive a closed-form optimal
solution. Results demonstrate that the EH requirement has a deterministic
impact on the optimal PA position as well as its feasible region, requiring
deployment of the PA as close to the user as possible to maximize average
channel gain. This spatial adaptation, combined with dynamic PS, enables robust
SWIPT performance in the presence of probabilistic LoS blockage, revealing that
mechanical reconfigurability primarily enhances sustainability by ensuring
energy feasibility in dynamic environments.

</details>


### [6] [S2M2ECG: Spatio-temporal bi-directional State Space Model Enabled Multi-branch Mamba for ECG](https://arxiv.org/abs/2509.03066)
*Huaicheng Zhang,Ruoxin Wang,Chenlian Zhou,Jiguang Shi,Yue Ge,Zhoutong Li,Sheng Chang,Hao Wang,Jin He,Qijun Huang*

Main category: eess.SP

TL;DR: S2M2ECG是一个基于状态空间模型(SSM)的新型多导联心电图分析架构，通过三级融合机制实现高性能、低复杂度的CVD诊断


<details>
  <summary>Details</summary>
Motivation: 解决多导联ECG信号分析中性能、计算复杂度和多源特征融合之间的平衡问题，利用SSM模型的高效计算特性和线性复杂度优势

Method: 提出三级融合机制：1)时空双向SSM与分段标记化的低层信号融合；2)导联内双向扫描的时间信息融合；3)跨导联特征交互的空间信息融合。采用多分支设计和导联融合模块

Result: S2M2ECG在节律、形态和临床场景中均取得优异性能，参数量最少，适合高效推理和便捷部署

Conclusion: S2M2ECG在性能、计算复杂度和ECG特性之间实现了优异平衡，为高性能轻量化CVD诊断计算开辟了新途径

Abstract: As one of the most effective methods for cardiovascular disease (CVD)
diagnosis, multi-lead Electrocardiogram (ECG) signals present a characteristic
multi-sensor information fusion challenge that has been continuously researched
in deep learning domains. Despite the numerous algorithms proposed with
different DL architectures, maintaining a balance among performance,
computational complexity, and multi-source ECG feature fusion remains
challenging. Recently, state space models (SSMs), particularly Mamba, have
demonstrated remarkable effectiveness across various fields. Their inherent
design for high-efficiency computation and linear complexity makes them
particularly suitable for low-dimensional data like ECGs. This work proposes
S2M2ECG, an SSM architecture featuring three-level fusion mechanisms: (1)
Spatio-temporal bi-directional SSMs with segment tokenization for low-level
signal fusion, (2) Intra-lead temporal information fusion with bi-directional
scanning to enhance recognition accuracy in both forward and backward
directions, (3) Cross-lead feature interaction modules for spatial information
fusion. To fully leverage the ECG-specific multi-lead mechanisms inherent in
ECG signals, a multi-branch design and lead fusion modules are incorporated,
enabling individual analysis of each lead while ensuring seamless integration
with others. Experimental results reveal that S2M2ECG achieves superior
performance in the rhythmic, morphological, and clinical scenarios. Moreover,
its lightweight architecture ensures it has nearly the fewest parameters among
existing models, making it highly suitable for efficient inference and
convenient deployment. Collectively, S2M2ECG offers a promising alternative
that strikes an excellent balance among performance, computational complexity,
and ECG-specific characteristics, paving the way for high-performance,
lightweight computations in CVD diagnosis.

</details>


### [7] [YOLO-based Bearing Fault Diagnosis With Continuous Wavelet Transform](https://arxiv.org/abs/2509.03070)
*Po-Heng Chou,Wei-Lung Mao,Ru-Ping Lin*

Main category: eess.SP

TL;DR: 基于YOLO的时频谱图轴承故障诊断框架，通过CWT转换振动信号为时频谱图，利用YOLOv9-v11模型进行故障分类和位置检测，在多个数据集上实现了高精度和可视化故障位置。


<details>
  <summary>Details</summary>
Motivation: 传统的轴承故障诊断方法在准确性、通用性和可视化方面存在限制，需要一种能够同时进行故障分类和位置检测的高效方法。

Method: 使用Morlet小波将一维振动信号转换为时频谱图，然后采用YOLOv9、v10、v11模型进行故障分类检测，利用其区域感知机制实现故障位置可视化。

Result: 在CWRU、PU、IMS三个数据集上达到了极高的mAP分数：YOLOv11分别获得99.4%、97.8%、99.5%，显著超越基线MCNN-LSTM模型的准确性和通用性。

Conclusion: 该CWT-YOLO流水线为旋转机械状态监控提供了一种高精度、可视化的实用解决方案，能够同时进行故障类型识别和位置确定。

Abstract: This letter proposes a YOLO-based framework for spatial bearing fault
diagnosis using time-frequency spectrograms derived from continuous wavelet
transform (CWT). One-dimensional vibration signals are first transformed into
time-frequency spectrograms using Morlet wavelets to capture transient fault
signatures. These spectrograms are then processed by YOLOv9, v10, and v11
models to classify fault types. Evaluated on three benchmark datasets,
including Case Western Reserve University (CWRU), Paderborn University (PU),
and Intelligent Maintenance System (IMS), the proposed CWT--YOLO pipeline
achieves significantly higher accuracy and generalizability than the baseline
MCNN--LSTM model. Notably, YOLOv11 reaches mAP scores of 99.4% (CWRU), 97.8%
(PU), and 99.5% (IMS). In addition, its region-aware detection mechanism
enables direct visualization of fault locations in spectrograms, offering a
practical solution for condition monitoring in rotating machinery.

</details>


### [8] [Self-supervised Radio Representation Learning: Can we Learn Multiple Tasks?](https://arxiv.org/abs/2509.03077)
*Ogechukwu Kanu,Ashkan Eshaghbeigi,Hatem Abou-Zeid*

Main category: eess.SP

TL;DR: 提出基于动量对比的自监督学习方案用于无线电信号表示学习，在AoA估计和AMC分类任务上超越监督学习基线


<details>
  <summary>Details</summary>
Motivation: 解决6G AI开发中需要大量标注数据训练监督深度学习模型的问题，利用自监督学习减少对标注数据的依赖

Method: 使用动量对比的对比学习方法，通过精心设计的数据增强和多样化数据提取鲁棒、可迁移的信号表示

Result: 学习到的表示在冻结编码器权重时仍有效，微调后性能进一步提升，超越监督基线，在多个任务上验证有效性

Conclusion: 自监督学习有潜力通过减少标注数据依赖和提升模型泛化能力来变革无线通信AI，为可扩展的6G基础AI模型铺平道路

Abstract: Artificial intelligence (AI) is anticipated to play a pivotal role in 6G.
However, a key challenge in developing AI-powered solutions is the extensive
data collection and labeling efforts required to train supervised deep learning
models. To overcome this, self-supervised learning (SSL) approaches have
recently demonstrated remarkable success across various domains by leveraging
large volumes of unlabeled data to achieve near-supervised performance. In this
paper, we propose an effective SSL scheme for radio signal representation
learning using momentum contrast. By applying contrastive learning, our method
extracts robust, transferable representations from a large real-world dataset.
We assess the generalizability of these learned representations across two
wireless communications tasks: angle of arrival (AoA) estimation and automatic
modulation classification (AMC). Our results show that carefully designed
augmentations and diverse data enable contrastive learning to produce
high-quality, invariant latent representations. These representations are
effective even with frozen encoder weights, and fine-tuning further enhances
performance, surpassing supervised baselines. To the best of our knowledge,
this is the first work to propose and demonstrate the effectiveness of
self-supervised learning for radio signals across multiple tasks. Our findings
highlight the potential of self-supervised learning to transform AI for
wireless communications by reducing dependence on labeled data and improving
model generalization - paving the way for scalable foundational 6G AI models
and solutions.

</details>


### [9] [Handwriting Imagery EEG Classification based on Convolutional Neural Networks](https://arxiv.org/abs/2509.03111)
*Hao Yang,Guang Ouyang*

Main category: eess.SP

TL;DR: 本研究探索使用深度神经网络解码与非侵入式脑电图相关的手写想象，将其转换为英文字母的极限，首次尝试解码与非侵入式脑电图相关的手写想象


<details>
  <summary>Details</summary>
Motivation: 手写想象已成为脑机接口的有前景范式，非侵入式记录比侵入式脑电图记录更实用可行，需要探索其解码极限

Method: 5名参与者想象书写26个英文字母时记录头皮脑电图，测量脑电图相似性分析字母特定模式，训练4个卷积神经网络模型进行脑电图分类

Result: 脑电图数据明显表现出字母特定模式，CNN分类器在3.85%的随机水平下达到约20%的最高准确率

Conclusion: 虽然准确率不足以用于实用的脑到文本脑机接口，但模型性能显著，揭示了将非侵入式记录的脑信号转换为文本输出的潜力，为未来研究建立了基线

Abstract: Handwriting imagery has emerged as a promising paradigm for brain-computer
interfaces (BCIs) aimed at translating brain activity into text output.
Compared with invasively recorded electroencephalography (EEG), non-invasive
recording offers a more practical and feasible approach to capturing brain
signals for BCI. This study explores the limit of decoding non-invasive EEG
associated with handwriting imagery into English letters using deep neural
networks. To this end, five participants were instructed to imagine writing the
26 English letters with their EEG being recorded from the scalp. A measurement
of EEG similarity across letters was conducted to investigate letter-specific
patterns in the dataset. Subsequently, four convolutional neural network (CNN)
models were trained for EEG classification. Descriptively, the EEG data clearly
exhibited letter-specific patterns serving as a proof-of-concept for
EEG-to-text translation. Under the chance level of accuracy at 3.85%, the CNN
classifiers trained on each participant reached the highest limit of around
20%. This study marks the first attempt to decode non-invasive EEG associated
with handwriting imagery. Although the achieved accuracy is not sufficient for
a usable brain-to-text BCI, the model's performance is noteworthy in revealing
the potential for translating non-invasively recorded brain signals into text
outputs and establishing a baseline for future research.

</details>


### [10] [Deep Learning for High Speed Optical Coherence Elastography with a Fiber Scanning Endoscope](https://arxiv.org/abs/2509.03193)
*Maximilian Neidhardt,Sarah Latus,Tim Eixmann,Gereon Hüttmann,Alexander Schlaefer*

Main category: eess.SP

TL;DR: 开发了一种基于深度学习的小型光纤扫描内镜系统，用于实时弹性成像，在幻影和猪织织上展示了更高的测量精度。


<details>
  <summary>Details</summary>
Motivation: 现有的图像基于软织织弹性评估方法在微伤手术中不适用，需要一种能够在介入性操作中进行快速、局部化弹性测量的方法。

Method: 设计了小型化光纤扫描内镜，采用锥形扫描模式（5.05 kHz），并使用空间-时间深度学习网络处理复杂波场图像序列，在多种弹性幻影上进行端到端训练。

Result: 在2D扫描中，方法的平均绝对误差为6.31±5.76 kPa，显著低于传统相位跟踪方法的11.33±12.78 kPa；在3D扫描中，误差降低到4.48±3.63 kPa，远低于传统2D方法的19.75±21.82 kPa，并在离体猪织织上验证了可行性。

Conclusion: 该小型化光纤扫描内镜系统结合深度学习处理能够在微伤手术中实现快速、准确的局部弹性成像，为软织织病理评估提供了新的技术手段。

Abstract: Tissue stiffness is related to soft tissue pathologies and can be assessed
through palpation or via clinical imaging systems, e.g., ultrasound or magnetic
resonance imaging. Typically, the image based approaches are not suitable
during interventions, particularly for minimally invasive surgery. To this end,
we present a miniaturized fiber scanning endoscope for fast and localized
elastography. Moreover, we propose a deep learning based signal processing
pipeline to account for the intricate data and the need for real-time
estimates. Our elasticity estimation approach is based on imaging complex and
diffuse wave fields that encompass multiple wave frequencies and propagate in
various directions. We optimize the probe design to enable different scan
patterns. To maximize temporal sampling while maintaining three-dimensional
information we define a scan pattern in a conical shape with a temporal
frequency of 5.05 kHz. To efficiently process the image sequences of complex
wave fields we consider a spatio-temporal deep learning network. We train the
network in an end-to-end fashion on measurements from phantoms representing
multiple elasticities. The network is used to obtain localized and robust
elasticity estimates, allowing to create elasticity maps in real-time. For 2D
scanning, our approach results in a mean absolute error of 6.31+-5.76 kPa
compared to 11.33+-12.78 kPa for conventional phase tracking. For scanning
without estimating the wave direction, the novel 3D method reduces the error to
4.48+-3.63 kPa compared to 19.75+-21.82 kPa for the conventional 2D method.
Finally, we demonstrate feasibility of elasticity estimates in ex-vivo porcine
tissue.

</details>


### [11] [Crosstalk-Resilient Beamforming for Movable Antenna Enabled Integrated Sensing and Communication](https://arxiv.org/abs/2509.03273)
*Zeyuan Zhang,Yue Xiu,Zheng Dong,Jiacheng Yin,Maurice J. Khabbaz,Chadi Assi,Ning Wei*

Main category: eess.SP

TL;DR: 本文研究了存在天线串扰的可移动天线(MA)集成感知通信(ISAC)系统，提出了基于深度强化学习的抗串扰波束成形算法，显著提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线(FPA)系统的天线串扰模型不适用于可移动天线场景，需要开发新的抗串扰算法来提升ISAC系统性能。

Method: 将天线串扰模型推广到MA场景，采用Twin Delayed Deep Deterministic Policy Gradient (TD3)深度强化学习算法来训练灵活的波束成形代理，解决高度非凸的联合波束成形和天线位置设计问题。

Result: 数值结果表明，所提出的抗串扰(CR)算法相比其他基准方案显著提升了整体ISAC性能。

Conclusion: 基于深度强化学习的抗串扰波束成形算法能有效处理MA-enabled ISAC系统中的天线串扰问题，为未来移动通信系统提供了有前景的解决方案。

Abstract: This paper investigates a movable antenna (MA) enabled integrated sensing and
communication (ISAC) system under the influence of antenna crosstalk. First, it
generalizes the antenna crosstalk model from the conventional fixed-position
antenna (FPA) system to the MA scenario. Then, a Cramer-Rao bound (CRB)
minimization problem driven by joint beamforming and antenna position design is
presented. Specifically, to address this highly non-convex flexible beamforming
problem, we deploy a deep reinforcement learning (DRL) approach to train a
flexible beamforming agent. To ensure stability during training, a Twin Delayed
Deep Deterministic Policy Gradient (TD3) algorithm is adopted to balance
exploration with reward maximization for efficient and reliable learning.
Numerical results demonstrate that the proposed crosstalk-resilient (CR)
algorithm enhances the overall ISAC performance compared to other benchmark
schemes.

</details>


### [12] [Credible Uncertainty Quantification under Noise and System Model Mismatch](https://arxiv.org/abs/2509.03311)
*Penggao Yan,Li-Ta Hsu*

Main category: eess.SP

TL;DR: 这篇论文提出了一种统一的多指标评估框架，用于评估状态估计器的可信度，通过结合传统指标和适当评分规则，能够高精度识别模型缺陷类型。


<details>
  <summary>Details</summary>
Motivation: 状态估计器提供的自我不确定性评估（如协方差矩阵）可能因模型违反而导致误导，下游任务需要可靠的不确定性评估。

Method: 构建了一个紧凑的可信度评估组合，结合传统指标（NEES、NCI）和适当评分规则（NLL、ES），包括一种新题的能量距离基于位置测试和利用NLL与ES不对称敏感性的方法。

Result: 在六个不同可信度场景的蒙特卡洛模拟中，该方法实现了80-100%的高分类准确率，显著超过了单指标基准方法。

Conclusion: 该框架提供了一种将可信度指标模式转化为可操作的模型缺陷诊断的实用工具。

Abstract: State estimators often provide self-assessed uncertainty metrics, such as
covariance matrices, whose reliability is critical for downstream tasks.
However, these self-assessments can be misleading due to underlying modeling
violations like noise or system model mismatch. This letter addresses the
problem of estimator credibility by introducing a unified, multi-metric
evaluation framework. We construct a compact credibility portfolio that
synergistically combines traditional metrics like the Normalized Estimation
Error Squared (NEES) and the Noncredibility Index (NCI) with proper scoring
rules, namely the Negative Log-Likelihood (NLL) and the Energy Score (ES). Our
key contributions are a novel energy distance-based location test to robustly
detect system model misspecification and a method that leverages the asymmetric
sensitivities of NLL and ES to distinguish optimism covariance scaling from
system bias. Monte Carlo simulations across six distinct credibility scenarios
demonstrate that our proposed method achieves high classification accuracy
(80-100%), drastically outperforming single-metric baselines which consistently
fail to provide a complete and correct diagnosis. This framework provides a
practical tool for turning patterns of credibility indicators into actionable
diagnoses of model deficiencies.

</details>


### [13] [Baseband Model, Cutoff Rate Bounds and Constellation Shaping for Mixed Gaussian-Impulsive Noise](https://arxiv.org/abs/2509.03333)
*Tianfu Qi,Jun Wang*

Main category: eess.SP

TL;DR: 该论文针对混合噪声（高斯白噪声+脉冲噪声）问题，通过理论分析截止率来优化传输星座图设计，提出了紧致的CR上下界，并通过投影梯度法优化星座点的几何和概率分布，实现了显著的速率提升。


<details>
  <summary>Details</summary>
Motivation: 混合噪声（高斯白噪声和脉冲噪声）在众多通信场景中出现，会严重降低系统性能，需要找到有效的优化方法来应对这种噪声环境。

Method: 1. 从混合噪声的带通模型推导基带表示 2. 利用基带噪声模型获得截止率的闭式上下界 3. 采用分段线性近似处理积分项 4. 使用投影梯度法优化星座点的几何和概率分布

Result: 数值结果表明，提出的CR界限紧致且具有预期的渐近行为，优化后的星座方案相比基线实现了显著的速率改进。

Conclusion: 通过理论分析截止率并优化星座设计，可以有效应对混合噪声环境，提升通信系统性能，所提出的界限和方法具有实际应用价值。

Abstract: Mixed noise, composed of white Gaussian noise (WGN) and impulsive noise (IN),
appears in numerous communication scenarios and can severely degrade system
performance. In this paper, we address this issue by optimizing the transmitted
constellation under mixed noise based on a theoretical analysis of the cutoff
rate (CR). First, starting from the passband model of the mixed noise, we
derive its corresponding baseband representation. Due to the complexity of the
CR, an exact analytic expression is generally intractable. Therefore, the
baseband noise model is employed to obtain closed-form lower and upper bounds
of the CR. A piecewise linear approximation is applied to derive efficient
bounds by exploiting the algebraic properties of the integral terms. These
bounds are then used as criteria to optimize the transmitted constellation
points in both geometric and probabilistic distributions. The projected
gradient method is employed to solve the optimization problem, and the
convergence and properties of the solutions are analyzed. Numerical results
demonstrate that the proposed CR bounds are tight and exhibit the expected
asymptotic behavior. Furthermore, the optimized constellation scheme achieves a
significant rate improvement compared to baselines.

</details>


### [14] [Efficient DoA Estimation with Hybrid Linear and Rectangular Arrays Using Compact DFT Codebook](https://arxiv.org/abs/2509.03488)
*Miguel Rivas-Costa,Carlos Mosquera*

Main category: eess.SP

TL;DR: 提出了一种采用Butler矩阵的混合模拟数字架构，通过利用波束成形信号的柯西类位移结构，实现了接近CRLB下界的近最优DoA估计精度


<details>
  <summary>Details</summary>
Motivation: 混合模拟数字架构在大规模天线阵列中具有成本效益优势，但由于数字维度有限和波束成形设计受限，准确的波达方向估计仍然具有挑战性

Method: 使用Butler矩阵在均匀线性阵列上合成DFT波束，并利用波束成形信号的柯西类位移结构开发二阶统计量估计算法

Result: 算法实现了接近Cramér-Rao下界的近最优精度，在仿真中优于现有最先进方法

Conclusion: 该方法为混合模拟数字架构提供了有效的DoA估计解决方案，在保持成本效益的同时实现了优异的估计性能

Abstract: Hybrid Analog and Digital (HAD) architectures provide a cost-effective
alternative for large-scale antenna arrays, but accurate Direction-of-Arrival
(DoA) estimation remains challenging due to limited digital dimensionality and
constrained beamforming design. In this work, we propose a HAD architecture
that employs Butler matrices to synthesize DFT beams over a uniform linear
array. By exploiting the Cauchy-like displacement structure of the beamformed
signal, we introduce a second-order statistics estimation algorithm that
achieves near-optimal accuracy, approaching the Cram\'er-Rao Lower Bound (CRLB)
and outperforming state-of-the-art methods in simulation.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [15] [Gaussian Process Regression of Steering Vectors With Physics-Aware Deep Composite Kernels for Augmented Listening](https://arxiv.org/abs/2509.02571)
*Diego Di Carlo,Koyama Shoichi,Nugraha Aditya Arie,Fontaine Mathieu,Bando Yoshiaki,Yoshii Kazuyoshi*

Main category: eess.AS

TL;DR: 本文提出了一种基于神经场和高斯过程的物理感知复合核方法，用于连续表示转向向量，解决传统确定性超分辨率方法的过拟合问题，在数据不足条件下实现优异性能。


<details>
  <summary>Details</summary>
Motivation: 传统转向向量的代数表示无法处理声场散射效应，而现有的确定性超分辨率方法存在非均匀测量空间不确定性导致的过拟合问题。

Method: 将神经场（NF）的表示能力与高斯过程（GP）的概率框架相结合，提出物理感知复合核来建模方向性入射波和后续散射效应。

Result: 在SPEAR挑战赛的模拟数据上进行语音增强和双耳渲染等下游任务，仅用不到十分之一的测量数据就达到了oracle性能水平。

Conclusion: 所提出的方法在数据不足条件下表现出色，为声场感知控制提供了有效的连续转向向量表示解决方案。

Abstract: This paper investigates continuous representations of steering vectors over
frequency and position of microphone and source for augmented listening (e.g.,
spatial filtering and binaural rendering) with precise control of the sound
field perceived by the user. Steering vectors have typically been used for
representing the spatial characteristics of the sound field as a function of
the listening position. The basic algebraic representation of steering vectors
assuming an idealized environment cannot deal with the scattering effect of the
sound field. One may thus collect a discrete set of real steering vectors
measured in dedicated facilities and super-resolve (i.e., upsample) them.
Recently, physics-aware deep learning methods have been effectively used for
this purpose. Such deterministic super-resolution, however, suffers from the
overfitting problem due to the non-uniform uncertainty over the measurement
space. To solve this problem, we integrate an expressive representation based
on the neural field (NF) into the principled probabilistic framework based on
the Gaussian process (GP). Specifically, we propose a physics-aware composite
kernel that model the directional incoming waves and the subsequent scattering
effect. Our comprehensive comparative experiment showed the effectiveness of
the proposed method under data insufficiency conditions. In downstream tasks
such as speech enhancement and binaural rendering using the simulated data of
the SPEAR challenge, the oracle performances were attained with less than ten
times fewer measurements.

</details>


### [16] [IS${}^3$ : Generic Impulsive--Stationary Sound Separation in Acoustic Scenes using Deep Filtering](https://arxiv.org/abs/2509.02622)
*Berger Clémentine,Stamadiatis Paraskevas,Badeau Roland,Essid Slim*

Main category: eess.AS

TL;DR: IS³神经网络用于分离音频中的脉冲声和稳态背景声，通过深度学习过滤方法，在多种音频处理任务中表现优于传统方法


<details>
  <summary>Details</summary>
Motivation: 开发能够区分处理稳态背景和孤立声学事件的音频系统，应用于自适应音频渲染、语音处理、噪声抑制、声学事件分类和生物声学等领域

Method: 使用基于深度过滤方法的IS³神经网络架构，配合精心设计的数据生成流程来训练模型

Result: 该方法在客观分离指标上优于从音乐信号处理改编的谐波-打击乐分离掩蔽方法和小波滤波方法

Conclusion: 基于相对轻量级神经网络架构和精心设计训练数据的学习方法，在这个先前未解决的问题上取得了成功

Abstract: We are interested in audio systems capable of performing a differentiated
processing of stationary backgrounds and isolated acoustic events within an
acoustic scene, whether for applying specific processing methods to each part
or for focusing solely on one while ignoring the other. Such systems have
applications in real-world scenarios, including robust adaptive audio rendering
systems (e.g., EQ or compression), plosive attenuation in voice mixing, noise
suppression or reduction, robust acoustic event classification or even
bioacoustics. To this end, we introduce IS${}^3$, a neural network designed for
Impulsive--Stationary Sound Separation, that isolates impulsive acoustic events
from the stationary background using a deep filtering approach, that can act as
a pre-processing stage for the above-mentioned tasks. To ensure optimal
training, we propose a sophisticated data generation pipeline that curates and
adapts existing datasets for this task. We demonstrate that a learning-based
approach, build on a relatively lightweight neural architecture and trained
with well-designed and varied data, is successful in this previously
unaddressed task, outperforming the Harmonic--Percussive Sound Separation
masking method, adapted from music signal processing research, and wavelet
filtering on objective separation metrics.

</details>


### [17] [Speech Intelligibility Assessment with Uncertainty-Aware Whisper Embeddings and sLSTM](https://arxiv.org/abs/2509.03013)
*Ryandhimas E. Zezario,Dyah A. M. G. Wisnu,Hsin-Min Wang,Yu Tsao*

Main category: eess.AS

TL;DR: 提出了iMTI-Net，一种改进的多目标语音清晰度预测网络，通过结合Whisper嵌入和统计特征（均值、标准差、熵），并采用CNN-sLSTM架构，在多项评估指标上优于原MTI-Net。


<details>
  <summary>Details</summary>
Motivation: 非侵入式语音清晰度预测面临说话人、噪声条件和主观感知的变异性挑战，需要更有效的特征提取和建模方法。

Method: 使用Whisper嵌入结合统计特征（均值、标准差、熵），熵作为不确定性代理；采用标量LSTM捕捉长程依赖；提出iMTI-Net结合CNN和sLSTM的多任务学习框架，联合预测人类清晰度分数和机器WER。

Result: iMTI-Net在多个评估指标上优于原始MTI-Net，证明了不确定性感知特征和CNN-sLSTM架构的有效性。

Conclusion: 提出的不确定性感知特征和CNN-sLSTM多任务学习架构显著提升了语音清晰度预测性能，为鲁棒的语音质量评估提供了有效解决方案。

Abstract: Non-intrusive speech intelligibility prediction remains challenging due to
variability in speakers, noise conditions, and subjective perception. We
propose an uncertainty-aware approach that leverages Whisper embeddings in
combination with statistical features, specifically the mean, standard
deviation, and entropy computed across the embedding dimensions. The entropy,
computed via a softmax over the feature dimension, serves as a proxy for
uncertainty, complementing global information captured by the mean and standard
deviation. To model the sequential structure of speech, we adopt a scalar long
short-term memory (sLSTM) network, which efficiently captures long-range
dependencies. Building on this foundation, we propose iMTI-Net, an improved
multi-target intelligibility prediction network that integrates convolutional
neural network (CNN) and sLSTM components within a multitask learning
framework. It jointly predicts human intelligibility scores and machine-based
word error rates (WER) from Google ASR and Whisper. Experimental results show
that iMTI-Net outperforms the original MTI-Net across multiple evaluation
metrics, demonstrating the effectiveness of incorporating uncertainty-aware
features and the CNN-sLSTM architecture.

</details>


### [18] [Non-Intrusive Intelligibility Prediction for Hearing Aids: Recent Advances, Trends, and Challenges](https://arxiv.org/abs/2509.03017)
*Ryandhimas E. Zezario*

Main category: eess.AS

TL;DR: 这篇论文结合了助听器方面非侵入式语音可慧性预测的最新进展，包括特征提取、听力损失模型和长序列处理方法，并讨论了适配策略和领域泛化挑战。


<details>
  <summary>Details</summary>
Motivation: 提供助听器方向的可靠语音可慧性预测系统的当前趋势、挑战和未来方向视角，以实现实用性和可靠性。

Method: 综述了稳健的音响特征提取、听力损失建模、长序列处理新兴架构、听众特定适配策略和领域泛化方法。

Result: 识别了当前领域的进展和成果，但也指出了如大规模多样性数据集和可靠跨流派泛化等持续挑战。

Conclusion: 该领域在向实用性和可靠性方向发展，需要继续关注大规模数据集、模型适配性和在未见环境中的稳健性挑战。

Abstract: This paper provides an overview of recent progress in non-intrusive speech
intelligibility prediction for hearing aids (HA). We summarize developments in
robust acoustic feature extraction, hearing loss modeling, and the use of
emerging architectures for long-sequence processing. Listener-specific
adaptation strategies and domain generalization approaches that aim to improve
robustness in unseen acoustic environments are also discussed. Remaining
challenges, such as the need for large-scale, diverse datasets and reliable
cross-profile generalization, are acknowledged. Our goal is to offer a
perspective on current trends, ongoing challenges, and possible future
directions toward practical and reliable HA-oriented intelligibility prediction
systems.

</details>


### [19] [A Study on Zero-Shot Non-Intrusive Speech Intelligibility for Hearing Aids Using Large Language Models](https://arxiv.org/abs/2509.03021)
*Ryandhimas E. Zezario,Dyah A. M. G. Wisnu,Hsin-Min Wang,Yu Tsao*

Main category: eess.AS

TL;DR: 基于LLM的零样本非侵入式语音评估模型GPT-Whisper-HA，通过结合耳机模拟和ASR模块，在预测耳机用户语音可懂性方面较GPT-Whisper提升2.59%的RMSE攻过改善


<details>
  <summary>Details</summary>
Motivation: 为了开发一种零样本非侵入式的语音评估方法，专门用于预测耳机用户的主观语音可懂性，充分利用大语言模型的潜力

Method: 扩展GPT-Whisper模型，结合MSBG职听损失和NAL-R模拟处理音频输入，使用两个自动语音识别(ASR)模块进行音频到文本表示，然后使用GPT-4o预测两个对应分数，最终通过分数平均获得估计分数

Result: GPT-Whisper-HA在相对根均方误(RMSE)上比GPT-Whisper提升了2.59%，验证了LLM在耳机零样本语音评估中的潜力

Conclusion: 该研究证明了大语言模型在零样本非侵入式耳机语音评估中的有效性，GPT-Whisper-HA模型能够更准确地预测耳机用户的主观语音可懂性

Abstract: This work focuses on zero-shot non-intrusive speech assessment for hearing
aids (HA) using large language models (LLMs). Specifically, we introduce
GPT-Whisper-HA, an extension of GPT-Whisper, a zero-shot non-intrusive speech
assessment model based on LLMs. GPT-Whisper-HA is designed for speech
assessment for HA, incorporating MSBG hearing loss and NAL-R simulations to
process audio input based on each individual's audiogram, two automatic speech
recognition (ASR) modules for audio-to-text representation, and GPT-4o to
predict two corresponding scores, followed by score averaging for the final
estimated score. Experimental results indicate that GPT-Whisper-HA achieves a
2.59% relative root mean square error (RMSE) improvement over GPT-Whisper,
confirming the potential of LLMs for zero-shot speech assessment in predicting
subjective intelligibility for HA users.

</details>


### [20] [Improving Perceptual Audio Aesthetic Assessment via Triplet Loss and Self-Supervised Embeddings](https://arxiv.org/abs/2509.03292)
*Dyah A. M. G. Wisnu,Ryandhimas E. Zezario,Stefano Rini,Hsin-Min Wang,Yu Tsao*

Main category: eess.AS

TL;DR: 提出基于BEATs预训练模型和多分支LSTM的音频质量评估系统，使用三元组损失和缓冲区采样来解决自然训练数据与合成评估数据之间的域偏移问题。


<details>
  <summary>Details</summary>
Motivation: 解决AudioMOS Challenge 2025中多轴感知质量预测的挑战，特别是自然训练数据与合成评估数据之间的域偏移问题。

Method: 结合BEATs预训练transformer音频表示模型和多分支LSTM预测器，使用三元组损失和缓冲区采样来构建感知相似性的嵌入空间。

Result: 该方法提高了嵌入可区分性和泛化能力，实现了无需合成训练数据的领域鲁棒音频质量评估。

Conclusion: 所提出的系统能够有效处理域偏移问题，在生成音频的多轴质量预测任务中表现出良好的性能。

Abstract: We present a system for automatic multi-axis perceptual quality prediction of
generative audio, developed for Track 2 of the AudioMOS Challenge 2025. The
task is to predict four Audio Aesthetic Scores--Production Quality, Production
Complexity, Content Enjoyment, and Content Usefulness--for audio generated by
text-to-speech (TTS), text-to-audio (TTA), and text-to-music (TTM) systems. A
main challenge is the domain shift between natural training data and synthetic
evaluation data. To address this, we combine BEATs, a pretrained
transformer-based audio representation model, with a multi-branch long
short-term memory (LSTM) predictor and use a triplet loss with buffer-based
sampling to structure the embedding space by perceptual similarity. Our results
show that this improves embedding discriminability and generalization, enabling
domain-robust audio quality assessment without synthetic training data.

</details>


### [21] [An Effective Strategy for Modeling Score Ordinality and Non-uniform Intervals in Automated Speaking Assessment](https://arxiv.org/abs/2509.03372)
*Tien-Hong Lo,Szu-Yu Chen,Yao-Ting Sung,Berlin Chen*

Main category: eess.AS

TL;DR: 这篇论文提出了一种结合自盛盛盛学习表征和手工特征的自动说话评估方法，通过多边降序列损失来模型语言能力级别的顺序性和非均匀间隔。


<details>
  <summary>Details</summary>
Motivation: 解决现有ASA方法的两大问题：语音SSL模型忽视语言内容，文本SSL模型无法编码语调细腻，以及将能力级别简单处理为名义类别而忽视其顺序结构。

Method: 结合自盛盛盛学习表征和手工指标特征，采用新的模型范式，并引入多边降序列损失来联合模型能力级别的顺序性和非均匀间隔。

Result: 在TEEMI语料库上的实验显示，该方法一贯地超过了强基线方法，并能够艾好地演续到未见过的话题上。

Conclusion: 该研究提出的方法有效解决了自动说话评估中的关键挑战，通过结合不同源的特征和考虑能力级别的顺序性，实现了更准确的评估效果。

Abstract: A recent line of research on automated speaking assessment (ASA) has
benefited from self-supervised learning (SSL) representations, which capture
rich acoustic and linguistic patterns in non-native speech without underlying
assumptions of feature curation. However, speech-based SSL models capture
acoustic-related traits but overlook linguistic content, while text-based SSL
models rely on ASR output and fail to encode prosodic nuances. Moreover, most
prior arts treat proficiency levels as nominal classes, ignoring their ordinal
structure and non-uniform intervals between proficiency labels. To address
these limitations, we propose an effective ASA approach combining SSL with
handcrafted indicator features via a novel modeling paradigm. We further
introduce a multi-margin ordinal loss that jointly models both the score
ordinality and non-uniform intervals of proficiency labels. Extensive
experiments on the TEEMI corpus show that our method consistently outperforms
strong baselines and generalizes well to unseen prompts.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [22] [Analysis of Speaker Verification Performance Trade-offs with Neural Audio Codec Transmission](https://arxiv.org/abs/2509.02771)
*Nirmalya Mallick Thakur,Jia Qi Yip,Eng Siong Chng*

Main category: cs.SD

TL;DR: 神经音频编解码器在低比特率（<12kbps）下比传统编解码器Opus性能更好，但在高比特率（≈24kbps）下略差，主要因为其优化目标为感知质量而非说话人特征保留。


<details>
  <summary>Details</summary>
Motivation: 研究神经音频编解码器与传统音频编解码器在不同比特率下对说话人验证性能的影响，评估其在音频处理管道中的适用性。

Method: 在VoxCeleb1数据集上评估三种最先进的说话人验证模型，比较传统和神经音频编解码器在不同比特率下的性能表现。

Result: 所有编解码器和模型在比特率降低时都出现性能下降。神经编解码器在低比特率下比Opus性能好6-8%，在高比特率下EER仅增加0.4-0.7%。

Conclusion: 神经音频编解码器是传统编解码器的可行替代方案，特别是在带宽受限情况下。未来需要开发说话人感知的神经编解码器或重新训练适应说话人验证模型。

Abstract: Neural audio codecs (NACs) have made significant advancements in recent years
and are rapidly being adopted in many audio processing pipelines. However, they
can introduce audio distortions which degrade speaker verification (SV)
performance. This study investigates the impact of both traditional and neural
audio codecs at varying bitrates on three state of-the-art SV models evaluated
on the VoxCeleb1 dataset. Our findings reveal a consistent degradation in SV
performance across all models and codecs as bitrates decrease. Notably, NACs do
not fundamentally break SV performance when compared to traditional codecs.
They outperform Opus by 6-8% at low-bitrates (< 12 kbps) and remain marginally
behind at higher bitrates ($\approx$ 24 kbps), with an EER increase of only
0.4-0.7%. The disparity at higher bitrates is likely due to the primary
optimization of NACs for perceptual quality, which can inadvertently discard
critical speaker-discriminative features, unlike Opus which was designed to
preserve vocal characteristics. Our investigation suggests that NACs are a
feasible alternative to traditional codecs, especially under bandwidth
limitations. To bridge the gap at higher bitrates, future work should focus on
developing speaker-aware NACs or retraining and adapting SV models.

</details>


### [23] [Speech DF Arena: A Leaderboard for Speech DeepFake Detection Models](https://arxiv.org/abs/2509.02859)
*Sandipana Dowerah,Atharva Kulkarni,Ajinkya Kulkarni,Hoan My Tran,Joonas Kalda,Artem Fedorchenko,Benoit Fauve,Damien Lolive,Tanel Alumäe,Matthew Magimai Doss*

Main category: cs.SD

TL;DR: Speech DF Arena是首个全面的音频深度伪造检测基准测试，包含14个数据集、标准化评估指标和协议，以及用于比较检测系统的排行榜。


<details>
  <summary>Details</summary>
Motivation: 随着深度伪造音频生成技术的发展，音频深度伪造检测也取得进展，但缺乏标准化和全面的基准测试。

Method: 开发了包含14个多样化数据集和攻击场景的工具包，采用标准化评估指标和协议，评估了12个开源和3个专有检测系统。

Result: 研究发现许多系统在跨域场景中表现出高EER（等错误率），凸显了广泛跨域评估的必要性。

Conclusion: Speech DF Arena为音频深度伪造检测提供了首个全面基准，强调了跨域评估的重要性，并提供了可复现的工具包和排行榜。

Abstract: Parallel to the development of advanced deepfake audio generation, audio
deepfake detection has also seen significant progress. However, a standardized
and comprehensive benchmark is still missing. To address this, we introduce
Speech DeepFake (DF) Arena, the first comprehensive benchmark for audio
deepfake detection. Speech DF Arena provides a toolkit to uniformly evaluate
detection systems, currently across 14 diverse datasets and attack scenarios,
standardized evaluation metrics and protocols for reproducibility and
transparency. It also includes a leaderboard to compare and rank the systems to
help researchers and developers enhance their reliability and robustness. We
include 14 evaluation sets, 12 state-of-the-art open-source and 3 proprietary
detection systems. Our study presents many systems exhibiting high EER in
out-of-domain scenarios, highlighting the need for extensive cross-domain
evaluation. The leaderboard is hosted on Huggingface1 and a toolkit for
reproducing results across the listed datasets is available on GitHub.

</details>


### [24] [Multi-level SSL Feature Gating for Audio Deepfake Detection](https://arxiv.org/abs/2509.03409)
*Hoan My Tran,Damien Lolive,Aghilas Sini,Arnaud Delhay,Pierre-François Marteau,David Guennec*

Main category: cs.SD

TL;DR: 通过结合XLS-R基础模型的门控机制和多内核卷积分析，提出了一种能够检测多语言深度伪造语音的新方法，在内部和外部数据集上都取得了领先性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI语音合成技术的发展，高质量的合成语音可能被欺诈活动、身份盗用等恶意利用，当前的防伪造检测技术在应对未见攻击和多语言场景时存在不足。

Method: 采用XLS-R语音基础模型作为前端特征提取器，通过门控机制提取关键特征；下游使用多内核门控卷积(MultiConv)捕捉局部和全局语音特征；引入中心内核对齐(CKA)指标确保不同层学习到多样化的特征。

Result: 在内部标准测试集上达到了最优性能，同时在外部数据集(包括多语言语音)上也显示出良好的演化性能，证明方法具有强大的通用性。

Conclusion: 该方法为检测日益发展的语音深度伪造威胁提供了一种灵活有效的解决方案，在保护语音安全方面具有重要价值。

Abstract: Recent advancements in generative AI, particularly in speech synthesis, have
enabled the generation of highly natural-sounding synthetic speech that closely
mimics human voices. While these innovations hold promise for applications like
assistive technologies, they also pose significant risks, including misuse for
fraudulent activities, identity theft, and security threats. Current research
on spoofing detection countermeasures remains limited by generalization to
unseen deepfake attacks and languages. To address this, we propose a gating
mechanism extracting relevant feature from the speech foundation XLS-R model as
a front-end feature extractor. For downstream back-end classifier, we employ
Multi-kernel gated Convolution (MultiConv) to capture both local and global
speech artifacts. Additionally, we introduce Centered Kernel Alignment (CKA) as
a similarity metric to enforce diversity in learned features across different
MultiConv layers. By integrating CKA with our gating mechanism, we hypothesize
that each component helps improving the learning of distinct synthetic speech
patterns. Experimental results demonstrate that our approach achieves
state-of-the-art performance on in-domain benchmarks while generalizing
robustly to out-of-domain datasets, including multilingual speech samples. This
underscores its potential as a versatile solution for detecting evolving speech
deepfake threats.

</details>

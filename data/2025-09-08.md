<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [eess.AS](#eess.AS) [Total: 7]
- [cs.SD](#cs.SD) [Total: 8]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Communication-Efficient Collaborative LLM Inference via Distributed Speculative Decoding](https://arxiv.org/abs/2509.04576)
*Ce Zheng,Tingting Yang*

Main category: eess.SP

TL;DR: 提出TK-SLT方案，通过仅传输top-K概率分布而非完整词汇表来减少分布式推测解码的通信开销，同时保持推理性能。


<details>
  <summary>Details</summary>
Motivation: 在AI-RAN中，分布式推测解码需要从设备向基站传输完整词汇概率分布，导致上行通信开销过大。

Method: Top-K稀疏对数传输方案，只传输top-K token的原始概率和对应索引，并推导最优草稿长度最大化推理吞吐量。

Result: 实验验证了该方法的效率和有效性，显著减少带宽消耗的同时保持推理性能。

Conclusion: TK-SLT方案成功解决了分布式推测解码中的通信瓶颈问题，为AI-RAN中的协作推理提供了实用解决方案。

Abstract: Speculative decoding is an emerging technique that accelerates large language
model (LLM) inference by allowing a smaller draft model to predict multiple
tokens in advance, which are then verified or corrected by a larger target
model. In AI-native radio access networks (AI-RAN), this paradigm is
well-suited for collaborative inference between resource-constrained end
devices and more capable edge servers or base stations (BSs). However, existing
distributed speculative decoding requires transmitting the full vocabulary
probability distribution from the draft model on the device to the target model
at the BS, which leads to prohibitive uplink communication overhead. To address
this issue, we propose a ``Top-K Sparse Logits Transmission (TK-SLT)`` scheme,
where the draft model transmits only the top-K token raw probabilities and the
corresponding token indices instead of the entire distribution. This approach
significantly reduces bandwidth consumption while maintaining inference
performance. We further derive an analytical expression for the optimal draft
length that maximizes inference throughput, and provide a theoretical analysis
of the achievable speedup ratio under TK-SLT. Experimental results validate
both the efficiency and effectiveness of the proposed method.

</details>


### [2] [Tangential Velocity Estimation Using Near-Field Automotive Radar Model](https://arxiv.org/abs/2509.04692)
*Michael Shifrin,Joseph Tabrikian,Igal Bilik*

Main category: eess.SP

TL;DR: 这篇论文研究了汽车雷达系统中切向速度估计问题，通过引入近场雷达模型和利用目标迁移效应来提高估计精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统汽车雷达基于远场模型，只能估计目标的距离、纵向速度和到达方向，无法估计关键的切向速度分量，而这对动态环境的可靠感知至关重要。

Method: 引入近场雷达模型，考虑范围、纵向速度和多普勒沿时间和空间的迁移元素。通过Cramér-Rao界和模糊函数进行可识别性分析，开发了基于分离数组配置和最大似然估计的高效算法来利用目标迁移进行切向速度估计。

Result: 模拟验证了理论研究的可行性，并在单目标和多目标场景中评估了算法性能。提出的方法提高了估计精度和可靠性，同时减轻了范围、纵向速度和多普勒中的似然函数污染问题。

Conclusion: 该研究为汽车雷达系统提供了一种有效的切向速度估计方法，显著提升了高级驾驶辅助系统和自主驾驶车轻的情境感知能力，具有重要的应用价值。

Abstract: This work investigates the problem of tangential velocity estimation in
automotive radar systems, addressing the limitations of conventionally
considered models. Conventional automotive radars are usually based on
far-field models and estimate the target's range, radial velocity, and
direction-of-arrival (DOA) but are not able to estimate the tangential
component of the target 2-D velocity, which is a critical parameter for
reliable perception of dynamic environments. To address this challenge, we
introduce the near-field radar model, which considers various migration
elements in range, radial velocity, and Doppler along time and space.
Conventionally, these migration effects result in smearing of the likelihood
function for estimating the target parameters. However, if the model is
correctly specified, these migration effects are informative for tangential
velocity estimation. We conduct an identifiability analysis for tangential
velocity estimation using the Cram\'er-Rao bound and ambiguity function. The
insights from this study motivate the use of a separated array configuration
and the development of a computationally efficient maximum likelihood based
algorithm designed to utilize target migrations for tangential velocity
estimation, while maintaining practical computational complexity. In addition
to tangential velocity estimation, the proposed algorithm mitigates likelihood
smearing in range, radial velocity, and Doppler. Simulations validate the
theoretical feasibility study, and evaluate the algorithms' performance in both
single- and multi-target scenarios. The proposed approach improves the accuracy
and reliability of automotive radars, enhancing situational awareness for
advanced driver assistance systems and autonomous vehicles.

</details>


### [3] [Environment-Aware IRS Deployment via Channel Knowledge Map: Joint Sensing-Communications Coverage Optimization](https://arxiv.org/abs/2509.04768)
*Yilong Chen,Zixiang Ren,Jie Xu,Rui Zhang*

Main category: eess.SP

TL;DR: 本文研究基于频道知识地图(CKM)的智能反射表面(IRS)部署优化方案，通过关联优化IRS部署、基站发射條形成和IRS反射條形成，在满足感知和通信要求的前提下最小化系统成本。


<details>
  <summary>Details</summary>
Motivation: 为了在IRS启用的感通一化(ISAC)系统中提高感知和通信的覆盖能力，需要在候选位置成略部署多个IRS。CKM提供了频道状态信息，为环境感知的IRS部署设计基础。

Method: 采用混合整数非凸优化问题形式，通过连续凸近似(SCA)的松缝边界法求解。先将二进制部署指标松缝为连续变量，通过SCA找到收敛解，最后将松缝指标四舍五入为二进制值。考虑了实时动态和几何静止两种反射條形成情况。

Result: 数值结果证明了所提出算法的有效性，能够在满足感知和通信要求的同时降低系统成本。

Conclusion: 基于CKM的环境感知IRS部署设计能够有效优化ISAC系统性能，SCA基于的松缝边界法为该混合整数非凸优化问题提供了有效解决方案。

Abstract: This paper studies the intelligent reflecting surface (IRS) deployment
optimization problem for IRS-enabled integrated sensing and communications
(ISAC) systems, in which multiple IRSs are strategically deployed at candidate
locations to assist a base station (BS) to enhance the coverage of both sensing
and communications. We present an environment-aware IRS deployment design via
exploiting the channel knowledge map (CKM), which provides the channel state
information (CSI) between each candidate IRS location and BS or targeted
sensing/communication points. Based on the obtained CSI from CKM, we optimize
the deployment of IRSs, jointly with the BS's transmit beamforming and IRSs'
reflective beamforming during operation, with the objective of minimizing the
system cost, while guaranteeing the minimum illumination power requirements at
sensing areas and the minimum signal-to-noise ratio (SNR) requirements at
communication areas. In particular, we consider two cases when the IRSs'
reflective beamforming optimization can be implemented dynamically in real time
and quasi-stationarily over the whole operation period, respectively. For both
cases, the joint IRS deployment and transmit/reflective beamforming designs are
formulated as mixed-integer non-convex optimization problems, which are solved
via the successive convex approximation (SCA)-based relax-and-bound method.
Specifically, we first relax the binary IRS deployment indicators into
continuous variables, then find converged solutions via SCA, and finally round
relaxed indicators back to binary values. Numerical results demonstrate the
effectiveness of our proposed algorithms in reducing the system cost while
meeting the sensing and communication requirements.

</details>


### [4] [SREC: Encrypted Semantic Super-Resolution Enhanced Communication](https://arxiv.org/abs/2509.04787)
*Zhidi Zhang,Rui Meng,Song Gao,Haixiao Gao,Xiaodong Xu*

Main category: eess.SP

TL;DR: 提出加密语义超分辨率增强通信(SREC)方法，通过模256加密和超分辨率重建技术解决语义通信的安全问题，在低信噪比条件下实现安全且高效的图像传输。


<details>
  <summary>Details</summary>
Motivation: 语义通信(SemCom)作为AI与通信技术深度融合的典型范式，显著提高了通信效率和资源利用率，但其安全问题日益突出。明文传输的语义特征容易被窃听者拦截，需要解决语义通信的安全性问题。

Method: 采用模256加密方法对语义特征进行加密，并利用超分辨率重建方法来提高图像的重建质量。在加性高斯白噪声(AWGN)信道中测试不同调制方法下的性能。

Result: 仿真结果表明，在低信噪比(SNR)条件下，SREC不仅能稳定保证安全性，还能实现更好的传输性能。

Conclusion: SREC方法有效解决了语义通信的安全问题，在保证安全性的同时提升了低信噪比环境下的通信性能，为语义通信的安全应用提供了可行方案。

Abstract: Semantic communication (SemCom), as a typical paradigm of deep integration
between artificial intelligence (AI) and communication technology,
significantly improves communication efficiency and resource utilization
efficiency. However, the security issues of SemCom are becoming increasingly
prominent. Semantic features transmitted in plaintext over physical channels
are easily intercepted by eavesdroppers. To address this issue, this paper
proposes Encrypted Semantic Super-Resolution Enhanced Communication (SREC) to
secure SemCom. SREC uses the modulo-256 encryption method to encrypt semantic
features, and employs super-resolution reconstruction method to improve the
reconstruction quality of images. The simulation results show that in the
additive Gaussian white noise (AWGN) channel, when different modulation methods
are used, SREC can not only stably guarantee security, but also achieve better
transmission performance under low signal-to-noise ratio (SNR) conditions.

</details>


### [5] [KGRAG-SC: Knowledge Graph RAG-Assisted Semantic Communication](https://arxiv.org/abs/2509.04801)
*Dayu Fan,Rui Meng,Song Gao,Xiaodong Xu*

Main category: eess.SP

TL;DR: KGRAG-SC是一个基于知识图谱的语义通信框架，通过检索增强生成技术解决传统语义通信缺乏可解释性和噪声鲁棒性的问题，在低信噪比条件下实现更高的语义保真度和更低的传输开销。


<details>
  <summary>Details</summary>
Motivation: 现有语义通信方案主要依赖端到端深度学习框架，缺乏可解释性，且在噪声条件下语义选择和重建的鲁棒性不足，需要一种更可靠的结构化知识表示方法。

Method: 采用知识图谱辅助的多维框架，包括社区引导的实体链接、GraphRAG处理、最小连通子图构建、紧凑实体索引传输，以及基于结构中心度的重要性感知自适应传输策略。接收端使用大语言模型进行知识驱动的文本重建。

Result: 实验结果表明，KGRAG-SC在低信噪比条件下实现了优越的语义保真度，同时相比传统通信方法显著降低了传输开销。

Conclusion: 将结构化知识表示与生成式语言模型集成到语义通信系统中是有效的，能够提供更好的鲁棒性和效率。

Abstract: The state-of-the-art semantic communication (SC) schemes typically rely on
end-to-end deep learning frameworks that lack interpretability and struggle
with robust semantic selection and reconstruction under noisy conditions. To
address this issue, this paper presents KGRAG-SC, a knowledge graph-assisted SC
framework that leverages retrieval-augmented generation principles. KGRAG-SC
employs a multi-dimensional knowledge graph, enabling efficient semantic
extraction through community-guided entity linking and GraphRAG-assisted
processing. The transmitter constructs minimal connected subgraphs that capture
essential semantic relationships and transmits only compact entity indices
rather than full text or semantic triples. An importance-aware adaptive
transmission strategy provides unequal error protection based on structural
centrality metrics, prioritizing critical semantic elements under adverse
channel conditions. At the receiver, large language models perform
knowledge-driven text reconstruction using the shared knowledge graph as
structured context, ensuring robust semantic recovery even with partial
information loss. Experimental results demonstrate that KGRAG-SC achieves
superior semantic fidelity in low Signal-to-Noise Ratio (SNR) conditions while
significantly reducing transmission overhead compared to traditional
communication methods, highlighting the effectiveness of integrating structured
knowledge representation with generative language models for SC systems.

</details>


### [6] [SemSteDiff: Generative Diffusion Model-based Coverless Semantic Steganography Communication](https://arxiv.org/abs/2509.04803)
*Song Gao,Rui Meng,Xiaodong Xu,Haixiao Gao,Yiming Liu,Chenyuan Feng,Ping Zhang,Tony Q. S. Quek,Dusit Niyato*

Main category: eess.SP

TL;DR: 一种基于生成式涵散模型的无布屏语义隐写通信方案SemSteDiff，通过生成隐密图像来抵御语义截收攻击，使合法接收方能正确解码而截收者失败。


<details>
  <summary>Details</summary>
Motivation: 现有语义隐写通信方案依赖预选择的布屏图像，限制了通用性，需要解决这个限制来提高抵御语义截收的能力。

Method: 使用生成式涵散模型将秘密图像隐藏到生成的隐密图像中，通过语义相关的私钥和公钥实现合法接收方的正确解码。

Result: 在SNR=0dB时，合法接收方的PSNR比截收者高4.14dB，证明了方案在不同JSCC框架下的有效性。

Conclusion: SemSteDiff方案通过生成式方法解决了预选布屏图像的限制，提高了语义隐写通信的通用性和安全性。

Abstract: Semantic communication (SemCom), as a novel paradigm for future communication
systems, has recently attracted much attention due to its superiority in
communication efficiency. However, similar to traditional communication, it
also suffers from eavesdropping threats. Intelligent eavesdroppers could launch
advanced semantic analysis techniques to infer secret semantic information.
Therefore, some researchers have designed Semantic Steganography Communication
(SemSteCom) scheme to confuse semantic eavesdroppers. However, the
state-of-the-art SemSteCom schemes for image transmission rely on the
pre-selected cover image, which limits the universality. To address this issue,
we propose a Generative Diffusion Model-based Coverless Semantic Steganography
Communication (SemSteDiff) scheme to hide secret images into generated stego
images. The semantic related private and public keys enable legitimate receiver
to decode secret images correctly while the eavesdropper without completely
true key-pairs fail to obtain them. Simulation results demonstrate the
effectiveness of the plug-and-play design in different Joint Source-Channel
Coding (JSCC) frameworks. The comparison results under different eavesdroppers'
threats show that, when Signal-to-Noise Ratio (SNR) = 0 dB, the peak
signal-to-noise ratio (PSNR) of the legitimate receiver is 4.14 dB higher than
that of the eavesdropper.

</details>


### [7] [AI-Driven Fronthaul Link Compression in Wireless Communication Systems: Review and Method Design](https://arxiv.org/abs/2509.04805)
*Keqin Zhang*

Main category: eess.SP

TL;DR: 这篇论文探讨了AI驱动的无线系统fronthaul压缩技术，重点分析了CSI反馈压缩和预编码优化等高压缩比方案，并为组织元架构提出了具有高压缩比、可控性能损失、RB级别速率适配和低延迟特性的压缩策略。


<details>
  <summary>Details</summary>
Motivation: 现代无线系统fronthaul链路需要在严格的带宽和延迟约束下传输高维信号，传统压缩方法存在依赖限制性先验知识、高压缩比下性能恶化以及调适困难等问题。

Method: 重点分析了两种代表性高压缩路径：1)基于终端组学习的CSI反馈压缩；2)资源块(RB)粒度预编码优化与压缩的结合。基于这些见解，提出了一种专门为组织元架构设计的fronthaul压缩策略。

Result: 设计目标实现高压缩比下的可控性能损失，支持RB级别的速率适配能力，并支持下一代网络中央化协同传输所需的低延迟推理。

Conclusion: AI驱动的压缩技术能够更好地利用信道状态信息(CSI)、预编码矩阵、I/Q样本和LLR等信号的结构特征，为现代无线系统fronthaul链路提供了更有效的高压缩解决方案，特别是在组织元架构中具有重要应用价值。

Abstract: Modern fronthaul links in wireless systems must transport high-dimensional
signals under stringent bandwidth and latency constraints, which makes
compression indispensable. Traditional strategies such as compressed sensing,
scalar quantization, and fixed-codec pipelines often rely on restrictive
priors, degrade sharply at high compression ratios, and are hard to tune across
channels and deployments. Recent progress in Artificial Intelligence (AI) has
brought end-to-end learned transforms, vector and hierarchical quantization,
and learned entropy models that better exploit the structure of Channel State
Information(CSI), precoding matrices, I/Q samples, and LLRs. This paper first
surveys AI-driven compression techniques and then provides a focused analysis
of two representative high-compression routes: CSI feedback with end-to-end
learning and Resource Block (RB) granularity precoding optimization combined
with compression. Building on these insights, we propose a fronthaul
compression strategy tailored to cell-free architectures. The design targets
high compression with controlled performance loss, supports RB-level rate
adaptation, and enables low-latency inference suitable for centralized
cooperative transmission in next-generation networks.

</details>


### [8] [Plug-and-Play Latent Diffusion for Electromagnetic Inverse Scattering with Application to Brain Imaging](https://arxiv.org/abs/2509.04860)
*Rui Guo,Yi Zhang,Yhonatan Kvich,Tianyao Huang,Maokun Li,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 提出基于潜在扩散的后验采样方法用于电磁脑成像，通过结合物理前向模型和学习的先验分布，实现高精度定量重建。


<details>
  <summary>Details</summary>
Motivation: 现有电磁成像方法难以平衡解释性、失真误差和可靠性，无法有效整合复杂先验分布或提供理论保证，限制了脑卒中成像的准确性。

Method: 使用潜在扩散模型学习介电常数和电导率图的先验分布，然后通过交替采样器执行后验采样，分别强制执行似然和先验分布，最后基于样本进行最小均方误差估计。

Result: 在脑成像实验中，该方法在重建精度和结构相似性方面达到最先进性能，同时保持高测量保真度。

Conclusion: 该方法能够灵活整合先验知识到基于物理的反演中，无需配对测量-标签数据集，为电磁脑成像提供了可靠的后验采样解决方案。

Abstract: Electromagnetic (EM) imaging is an important tool for non-invasive sensing
with low-cost and portable devices. One emerging application is EM stroke
imaging, which enables early diagnosis and continuous monitoring of brain
strokes. Quantitative imaging is achieved by solving an inverse scattering
problem (ISP) that reconstructs permittivity and conductivity maps from
measurements. In general, the reconstruction accuracy is limited by its
inherent nonlinearity and ill-posedness. Existing methods, including
learning-free and learning-based approaches, fail to either incorporate
complicated prior distributions or provide theoretical guarantees, posing
difficulties in balancing interpretability, distortion error, and reliability.
To overcome these limitations, we propose a posterior sampling method based on
latent diffusion for quantitative EM brain imaging, adapted from a generative
plug-and-play (PnP) posterior sampling framework. Our approach allows to
flexibly integrate prior knowledge into physics-based inversion without
requiring paired measurement-label datasets. We first learn the prior
distribution of targets from an unlabeled dataset, and then incorporate the
learned prior into posterior sampling. In particular, we train a latent
diffusion model on permittivity and conductivity maps to capture their prior
distribution. Then, given measurements and the forward model describing EM wave
physics, we perform posterior sampling by alternating between two samplers that
respectively enforce the likelihood and prior distributions. Finally, reliable
reconstruction is obtained through minimum mean squared error (MMSE) estimation
based on the samples. Experimental results on brain imaging demonstrate that
our approach achieves state-of-the-art performance in reconstruction accuracy
and structural similarity while maintaining high measurement fidelity.

</details>


### [9] [Rotatable Antenna Aided Mixed Near-Field and Far-Field Communications in the Upper Mid-Band: Interference Analysis and Joint Optimization](https://arxiv.org/abs/2509.04865)
*Yunpu Zhang,Changsheng You,Hing Cheung So,Dusit Niyato*

Main category: eess.SP

TL;DR: 本文提出利用可旋转天线(RAs)通过天线旋转提供的新空间自由度来抑制复杂的近场干扰和混合场干扰，从而提升混合近场和远场通信系统的性能。


<details>
  <summary>Details</summary>
Motivation: 传统固定天线系统在混合近场和远场通信场景中面临复杂的近场干扰和混合场干扰问题，需要新的技术手段来提升通信性能。

Method: 提出模块化RA使能的混合场下行通信系统，通过联合优化功率分配和子阵列旋转角度来最大化近场用户的和速率。采用双层算法：内层使用SCA技术优化功率分配，外层使用PSO确定旋转角度。

Result: 数值结果表明，RA系统相比传统固定天线系统获得了显著的性能增益，所提出的联合设计方案相比基准方案具有更好的效果。

Conclusion: 天线旋转能有效抑制近场干扰和混合场干扰，显著提升混合场通信性能，为未来通信系统设计提供了新的技术途径。

Abstract: In this paper, we propose to leverage rotatable antennas (RAs) for improving
the communication performance in mixed near-field and far-field communication
systems by exploiting a new spatial degree-of-freedom (DoF) offered by antenna
rotation to mitigate complex near-field interference and mixed-field
interference. Specifically, we investigate a modular RA-enabled mixed-field
downlink communication system, where a base station (BS) consisting of multiple
RA subarrays communicates with multiple near-field users in the presence of
several legacy far-field users. We formulate an optimization problem to
maximize the sum-rate of the near-field users by jointly optimizing the power
allocation and rotation angles of all subarrays at the BS. To gain useful
insights into the effect of RAs on mixed-field communications, we first analyze
a special case where all subarrays share the same rotation angle and obtain
closed-form expressions for the rotation-aware normalized near-field
interference and the rotation-aware normalized mixed-field interference using
the Fresnel integrals. We then analytically reveal that array rotation
effectively suppresses both interference types, thereby significantly enhancing
mixed-field communication performance. For the general case involving
subarray-wise rotation, we propose an efficient double-layer algorithm to
obtain a high-quality solution, where the inner layer optimizes power
allocation using the successive convex approximation (SCA) technique, while the
outer layer determines the rotation angles of all subarrays via particle swarm
optimization (PSO). Finally, numerical results highlight the significant
performance gains achieved by RAs over conventional fixed-antenna systems and
demonstrate the effectiveness of our developed joint design compared to
benchmark schemes.

</details>


### [10] [Movable IRS-Aided ISAC Systems: Joint Beamforming and Position Optimization](https://arxiv.org/abs/2509.04873)
*Yue Geng,Tee Hiang Cheng,Kai Zhong,Kah Chan Teh,Qingqing Wu*

Main category: eess.SP

TL;DR: 该论文研究了可移动智能反射面(MIRS)辅助的集成感知与通信系统，通过联合优化MIRS元素位置、反射系数、发射波束成形和接收滤波器，最小化满足感知和通信服务质量所需的功率。


<details>
  <summary>Details</summary>
Motivation: 传统智能反射面(IRS)位置固定，限制了系统性能。可移动智能反射面(MIRS)结合IRS和可移动天线技术，能够灵活调整反射元素位置，提高系统适应性和性能。

Method: 提出两种MIRS控制方案：元素级控制和阵列级控制；开发基于乘积黎曼流形优化(PRMO)的方法，通过惩罚变换和黎曼BFGS算法在构造的乘积黎曼流形空间并行更新变量。

Result: 仿真结果表明，MIRS在功率最小化方面优于传统IRS。元素级控制方案实现最小功率，阵列级控制方案获得次优解但计算效率更高。

Conclusion: MIRS技术能够显著提升ISAC系统性能，元素级控制提供最优性能，阵列级控制在性能和计算效率之间提供良好平衡。

Abstract: Driven by intelligent reflecting surface (IRS) and movable antenna (MA)
technologies, movable IRS (MIRS) has been proposed to improve the adaptability
and performance of conventional IRS, enabling flexible adjustment of the IRS
reflecting element positions. This paper investigates MIRS-aided integrated
sensing and communication (ISAC) systems. The objective is to minimize the
power required for satisfying the quality-of-service (QoS) of sensing and
communication by jointly optimizing the MIRS element positions, IRS reflection
coefficients, transmit beamforming, and receive filters. To balance the
performance-cost trade-off, we proposed two MIRS schemes: element-wise control
and array-wise control, where the positions of individual reflecting elements
and arrays consisting of multiple elements are controllable, respectively. To
address the joint beamforming and position optimization, a product Riemannian
manifold optimization (PRMO) method is proposed, where the variables are
updated over a constructed product Riemannian manifold space (PRMS) in parallel
via penalty-based transformation and Riemannian
Broyden-Fletcher-Goldfarb-Shanno (RBFGS) algorithm. Simulation results
demonstrate that the proposed MIRS outperforms conventional IRS in power
minimization with both element-wise control and array-wise control.
Specifically, with different system parameters, the minimum power is achieved
by the MIRS with the element-wise control scheme, while suboptimal solution and
higher computational efficiency are achieved by the MIRS with array-wise
control scheme.

</details>


### [11] [Coupled tensor models for probability mass function estimation: Part I, Principles and algorithms](https://arxiv.org/abs/2509.04930)
*Philippe Flores,Konstantin Usevich,David Brie*

Main category: eess.SP

TL;DR: 提出PCTF3D方法，通过部分耦合3D边际张量来估计高维概率质量函数，避免维度灾难问题


<details>
  <summary>Details</summary>
Motivation: 解决高维概率质量函数估计中的维度灾难问题，传统方法在高维情况下计算复杂度急剧增加

Method: 使用部分耦合的3阶张量分解方法(PCTF3D)，通过超图选择3D边际子集进行部分耦合，构建概率质量张量分解

Result: 提出了新的算法框架，能够有效处理高维PMF估计问题，并通过数值实验验证了方法的有效性

Conclusion: PCTF3D为高维概率质量函数估计提供了有效的解决方案，这是两篇系列文章的第一篇，主要关注算法框架

Abstract: In this article, a Probability Mass Function (PMF) estimation method which
tames the curse of dimensionality is proposed. This method, called Partial
Coupled Tensor Factorization of 3D marginals or PCTF3D, has for principle to
partially couple order-3 data projections -- seen as order-3 tensors -- to
obtain a tensor decomposition of the probability mass tensor. The novelty of
PCTF3D relies on partial coupling which consists in choosing a subset of 3D
marginals. The choice of marginals is then formulated with hypergraphs. After
presenting possible coupling strategies, some numerical experiments and an
application of the method are proposed. This article is the first of a two-part
article. While this first article focuses on a new algorithmic framework for
PMF estimation, the second studies uniqueness properties of the model
introduced in this article.

</details>


### [12] [Coupled tensor models for probability mass function estimation: Part II, Uniqueness of the model](https://arxiv.org/abs/2509.04931)
*Philippe Flores,Konstantin Usevich,David Brie*

Main category: eess.SP

TL;DR: 本文研究了PCTF3D方法中耦合张量模型的唯一性特性，分析了不同耦合策略对唯一性的影响，并给出了笛卡尔耦合的可识别性边界。


<details>
  <summary>Details</summary>
Motivation: 张量方法在统计学习中广泛应用，其最大优势是具有强唯一性特性。本文旨在评估PCTF3D方法中约束耦合低秩模型的唯一性特性，特别是耦合策略对唯一性的影响。

Method: 使用雅可比算法提供最大可恢复秩，分析Part I文章中提出的不同耦合策略的唯一性特性，并针对笛卡尔耦合给出可识别性边界。

Result: 研究发现唯一性高度依赖于PCTF3D中使用的耦合方式，在正确处理耦合模型的概率约束条件下，不同耦合策略具有不同的唯一性表现。

Conclusion: PCTF3D方法的唯一性特性与耦合策略密切相关，笛卡尔耦合能够增强文献中充分边界的可识别性，为张量分解方法提供了理论保证。

Abstract: In this paper, uniqueness properties of a coupled tensor model are studied.
This new coupled tensor model is used in a new method called Partial Coupled
Tensor Factorization of 3D marginals or PCTF3D. This method performs estimation
of probability mass functions by coupling 3D marginals, seen as order-3
tensors. The core novelty of PCTF3D's approach (detailed in the part I article)
relies on the partial coupling which consists on the choice of 3D marginals to
be coupled. Tensor methods are ubiquitous in many applications of statistical
learning, with their biggest advantage of having strong uniqueness properties.
In this paper, the uniqueness properties of PCTF3D's constrained coupled
low-rank model is assessed. While probabilistic constraints of the coupled
model are handled properly, it is shown that uniqueness highly depends on the
coupling used in PCTF3D. After proposing a Jacobian algorithm providing maximum
recoverable rank, different coupling strategies presented in the Part I article
are examined with respect to their uniqueness properties. Finally, an
identifiability bound is given for a so-called Cartesian coupling which permits
enhancing sufficient bounds of the literature.

</details>


### [13] [ROPE: A Novel Method for Real-Time Phase Estimation of Complex Biological Rhythms](https://arxiv.org/abs/2509.04962)
*Antonio Spallone,Marco Coraggio,Francesco De Lellis,Mario di Bernardo*

Main category: eess.SP

TL;DR: ROPE是首个能够处理任意维度信号并实时运行的相位估计算法，通过识别信号中的重复模式进行分段，并在先前信号段上进行高效搜索来分配相位值。


<details>
  <summary>Details</summary>
Motivation: 现有相位估计方法通常局限于离线处理和/或一维信号，无法满足实时分析复杂生物节律的需求，特别是在神经科学和机器人学等领域需要实时相位估计的应用。

Method: ROPE算法通过识别信号中的重复模式将信号分割为（伪）周期，并在先前信号段上执行高效、可处理的搜索来分配相位值。

Result: 在多种信号类型（包括混沌动力系统轨迹、人体运动捕捉数据和心电图记录）上的广泛验证表明，ROPE对噪声和信号漂移具有鲁棒性，性能显著优于最先进的相位估计方法。

Conclusion: ROPE算法实现了复杂生物节律的实时分析，为病理节律紊乱的早期诊断和基于节律的治疗干预开辟了新途径。

Abstract: Accurate phase estimation -- the process of assigning phase values between
$0$ and $2\pi$ to repetitive or periodic signals -- is a cornerstone in the
analysis of oscillatory signals across diverse fields, from neuroscience to
robotics, where it is fundamental, e.g., to understanding coordination in
neural networks, cardiorespiratory coupling, and human-robot interaction.
However, existing methods are often limited to offline processing and/or
constrained to one-dimensional signals. In this paper, we introduce ROPE,
which, to the best of our knowledge, is the first phase-estimation algorithm
capable of (i) handling signals of arbitrary dimension and (ii) operating in
real-time, with minimal error. ROPE identifies repetitions within the signal to
segment it into (pseudo-)periods and assigns phase values by performing
efficient, tractable searches over previous signal segments. We extensively
validate the algorithm on a variety of signal types, including trajectories
from chaotic dynamical systems, human motion-capture data, and
electrocardiographic recordings. Our results demonstrate that ROPE is robust
against noise and signal drift, and achieves significantly superior performance
compared to state-of-the-art phase estimation methods. This advancement enables
real-time analysis of complex biological rhythms, opening new pathways, for
example, for early diagnosis of pathological rhythm disruptions and developing
rhythm-based therapeutic interventions in neurological and cardiovascular
disorders.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [14] [On Time Delay Interpolation for Improved Acoustic Reflector Localization](https://arxiv.org/abs/2509.04629)
*Hannes Rosseel,Toon van Waterschoot*

Main category: eess.AS

TL;DR: 这篇论文综述了通过sinc和Whittaker-Shannon插值方法实现次样本精度的时间延迟估计，提高了氧声反射体定位的精度。


<details>
  <summary>Details</summary>
Motivation: 传统时间延迟估计算法只能获得整数倍金石样本周期的延迟，时间分辨率不足，需要通过插值方法实现次样本精度的估计。

Method: 从现有sinc插值方法推导出Whittaker-Shannon插值公式，应用于短时窗TDE方法进行氧声反射体定位。

Result: 模拟实验显示sinc和Whittaker-Shannon插值在关键采样和带限反射情况下在时间延迟误差和位置误差方面超过现有方法；实际测量数据验证了这些方法在不同传感器-声源对和扬声器位置下的稳健性。

Conclusion: sinc和Whittaker-Shannon插值方法能够显著提高氧声反射体定位系统的精度，对房间声学分析、声源定位和声场分析等应用具有重要价值。

Abstract: The localization of acoustic reflectors is a fundamental component in various
applications, including room acoustics analysis, sound source localization, and
acoustic scene analysis. Time Delay Estimation (TDE) is essential for
determining the position of reflectors relative to a sensor array. Traditional
TDE algorithms generally yield time delays that are integer multiples of the
operating sampling period, potentially lacking sufficient time resolution. To
achieve subsample TDE accuracy, various interpolation methods, including
parabolic, Gaussian, frequency, and sinc interpolation, have been proposed.
This paper presents a comprehensive study on time delay interpolation to
achieve subsample accuracy for acoustic reflector localization in reverberant
conditions. We derive the Whittaker-Shannon interpolation formula from the
previously proposed sinc interpolation in the context of short-time windowed
TDE for acoustic reflector localization. Simulations show that sinc and
Whittaker-Shannon interpolation outperform existing methods in terms of time
delay error and positional error for critically sampled and band-limited
reflections. Performance is evaluated on real-world measurements from the
MYRiAD dataset, showing that sinc and Whittaker-Shannon interpolation
consistently provide reliable performance across different sensor-source pairs
and loudspeaker positions. These results can enhance the precision of acoustic
reflector localization systems, vital for applications such as room acoustics
analysis, sound source localization, and acoustic scene analysis.

</details>


### [15] [DarkStream: real-time speech anonymization with low latency](https://arxiv.org/abs/2509.04667)
*Waris Quamer,Ricardo Gutierrez-Osuna*

Main category: eess.AS

TL;DR: DarkStream是一个实时语音合成模型，用于说话人匿名化，通过因果波形编码器、短前瞻缓冲区和Transformer层实现低延迟内容编码，直接生成波形避免频谱转换，使用GAN生成的伪说话人嵌入实现身份匿名化


<details>
  <summary>Details</summary>
Motivation: 为了解决实时语音通信中的隐私保护问题，需要在严格延迟约束下实现有效的说话人匿名化，同时保持语音内容可懂度

Method: 结合因果波形编码器、短前瞻缓冲区和基于Transformer的上下文层进行内容编码；直接通过神经声码器生成波形；注入GAN生成的伪说话人嵌入到语言特征中实现匿名化

Result: 在lazy-informed攻击场景下达到接近50%的说话人验证EER（接近随机性能），同时保持可接受的语言可懂度（WER在9%以内）

Conclusion: DarkStream通过平衡低延迟、强隐私保护和最小可懂度损失，为隐私保护的实时语音通信提供了实用解决方案

Abstract: We propose DarkStream, a streaming speech synthesis model for real-time
speaker anonymization. To improve content encoding under strict latency
constraints, DarkStream combines a causal waveform encoder, a short lookahead
buffer, and transformer-based contextual layers. To further reduce inference
time, the model generates waveforms directly via a neural vocoder, thus
removing intermediate mel-spectrogram conversions. Finally, DarkStream
anonymizes speaker identity by injecting a GAN-generated pseudo-speaker
embedding into linguistic features from the content encoder. Evaluations show
our model achieves strong anonymization, yielding close to 50% speaker
verification EER (near-chance performance) on the lazy-informed attack
scenario, while maintaining acceptable linguistic intelligibility (WER within
9%). By balancing low-latency, robust privacy, and minimal intelligibility
degradation, DarkStream provides a practical solution for privacy-preserving
real-time speech communication.

</details>


### [16] [Say More with Less: Variable-Frame-Rate Speech Tokenization via Adaptive Clustering and Implicit Duration Coding](https://arxiv.org/abs/2509.04685)
*Rui-Chen Zheng,Wenrui Liu,Hui-Peng Du,Qinglin Zhang,Chong Deng,Qian Chen,Wen Wang,Yang Ai,Zhen-Hua Ling*

Main category: eess.AS

TL;DR: VARSTok是一种可变帧率语音分词器，通过自适应分段和隐式时长编码，在减少23%token的同时实现更好的语音重建质量


<details>
  <summary>Details</summary>
Motivation: 现有语音分词器采用固定帧率，无法匹配语音信号中信息密度不均匀的特性，导致token分配效率低下

Method: 提出时间感知密度峰值聚类算法进行自适应分段，以及新颖的隐式时长编码方案，将内容和时间跨度嵌入单个token索引

Result: 显著优于固定帧率基线，重建自然度更好，零样本TTS合成中词错误率更低、自然度更高

Conclusion: 首次证明完全动态的可变帧率语音分词器可以无缝集成到下游语音语言模型中，为语音处理提供了更高效的token化方案

Abstract: Existing speech tokenizers typically assign a fixed number of tokens per
second, regardless of the varying information density or temporal fluctuations
in the speech signal. This uniform token allocation mismatches the intrinsic
structure of speech, where information is distributed unevenly over time. To
address this, we propose VARSTok, a VAriable-frame-Rate Speech Tokenizer that
adapts token allocation based on local feature similarity. VARSTok introduces
two key innovations: (1) a temporal-aware density peak clustering algorithm
that adaptively segments speech into variable-length units, and (2) a novel
implicit duration coding scheme that embeds both content and temporal span into
a single token index, eliminating the need for auxiliary duration predictors.
Extensive experiments show that VARSTok significantly outperforms strong
fixed-rate baselines. Notably, it achieves superior reconstruction naturalness
while using up to 23% fewer tokens than a 40 Hz fixed-frame-rate baseline.
VARSTok further yields lower word error rates and improved naturalness in
zero-shot text-to-speech synthesis. To the best of our knowledge, this is the
first work to demonstrate that a fully dynamic, variable-frame-rate acoustic
speech tokenizer can be seamlessly integrated into downstream speech language
models. Speech samples are available at https://zhengrachel.github.io/VARSTok.

</details>


### [17] [Layer-wise Analysis for Quality of Multilingual Synthesized Speech](https://arxiv.org/abs/2509.04830)
*Erica Cooper,Takuma Okamoto,Yamato Ohtani,Tomoki Toda,Hisashi Kawai*

Main category: eess.AS

TL;DR: 本文通过分层分析多语言预训练语音模型，发现早期SSL层特征与合成语音质量相关，后期ASR层能预测非神经系统的质量和可懂度，并强调了匹配参考数据的重要性。


<details>
  <summary>Details</summary>
Motivation: 监督式语音质量预测器需要领域内标注数据，泛化能力有限。无监督方法虽前景广阔，但对其如何编码语音质量信息了解甚少，特别是在多语言环境下。

Method: 采用基于参考建模的分层分析方法，对多语言预训练语音模型（SSL和ASR模型）进行逐层分析，研究不同层如何编码语音质量信息。

Result: 发现早期SSL层特征与人类对合成语音的评分相关；后期ASR层能预测非神经系统的质量和可懂度；使用良好匹配的参考数据至关重要。

Conclusion: 多语言预训练模型的不同层编码了语音质量的不同方面，为无监督语音质量评估提供了新见解，参考数据匹配是成功的关键因素。

Abstract: While supervised quality predictors for synthesized speech have demonstrated
strong correlations with human ratings, their requirement for in-domain labeled
training data hinders their generalization ability to new domains. Unsupervised
approaches based on pretrained self-supervised learning (SSL) based models and
automatic speech recognition (ASR) models are a promising alternative; however,
little is known about how these models encode information about speech quality.
Towards the goal of better understanding how different aspects of speech
quality are encoded in a multilingual setting, we present a layer-wise analysis
of multilingual pretrained speech models based on reference modeling. We find
that features extracted from early SSL layers show correlations with human
ratings of synthesized speech, and later layers of ASR models can predict
quality of non-neural systems as well as intelligibility. We also demonstrate
the importance of using well-matched reference data.

</details>


### [18] [Lightweight DNN for Full-Band Speech Denoising on Mobile Devices: Exploiting Long and Short Temporal Patterns](https://arxiv.org/abs/2509.05079)
*Konstantinos Drossos,Mikko Heikkinen,Paschalis Tsiaflakis*

Main category: eess.AS

TL;DR: 这篇论文提出了一种优化质量的轻量级深度神经网络方法，用于移动设备上的全带宽语音去噪，具有因果性、低延迟特性。


<details>
  <summary>Details</summary>
Motivation: 目前大多数深度神经网络语音去噪方法没有优化质量并适合移动设备，且少有方法关注全带宽信号和低延迟场景。

Method: 基于修改的UNet架构，采用回顾帧、卷积内核时间范围扩展和递归神经网络来利用短期和长期时间模式，使用STFT幅值作为输入，采用MobileNet反向瓶颈结构和因果实例归一化。

Result: 在现代手机上实时因子低于0.02，在公开数据集上的(SI-)SDR指标超过现有全带宽和低延迟语音去噪方法。

Conclusion: 该方法为移动设备提供了高效、低延迟的全带宽语音去噪解决方案，在保持质量的同时实现了较强的计算效率。

Abstract: Speech denoising (SD) is an important task of many, if not all, modern signal
processing chains used in devices and for everyday-life applications. While
there are many published and powerful deep neural network (DNN)-based methods
for SD, few are optimized for resource-constrained platforms such as mobile
devices. Additionally, most DNN-based methods for SD are not focusing on
full-band (FB) signals, i.e. having 48 kHz sampling rate, and/or low latency
cases. In this paper we present a causal, low latency, and lightweight
DNN-based method for full-band SD, leveraging both short and long temporal
patterns. The method is based on a modified UNet architecture employing
look-back frames, temporal spanning of convolutional kernels, and recurrent
neural networks for exploiting short and long temporal patterns in the signal
and estimated denoising mask. The DNN operates on a causal frame-by-frame basis
taking as an input the STFT magnitude, utilizes inverted bottlenecks inspired
by MobileNet, employs causal instance normalization for channel-wise
normalization, and achieves a real-time factor below 0.02 when deployed on a
modern mobile phone. The proposed method is evaluated using established speech
denoising metrics and publicly available datasets, demonstrating its
effectiveness in achieving an (SI-)SDR value that outperforms existing FB and
low latency SD methods.

</details>


### [19] [Room-acoustic simulations as an alternative to measurements for audio-algorithm evaluation](https://arxiv.org/abs/2509.05175)
*Georg Götz,Daniel Gert Nielsen,Steinar Guðjónsson,Finnur Pind*

Main category: eess.AS

TL;DR: 这篇论文探讨了使用房间声学模拟来评估音频信号处理和音频机器学习算法的可行性，对比了波动数值模拟和几何声学模拟的效果。


<details>
  <summary>Details</summary>
Motivation: 现实中音频算法评估面临数据集限制问题，需要一种成本低、效率高的方法来模拟多样化的应用场景和房间声学条件。

Method: 使用数值波动法模拟器和两种几何声学模拟器生成模拟数据，对三种ASP/AML算法进行评估，并与实际测量结果进行对比分析。

Result: 数值波动法模拟在所有三种算法评估中都产生了与实际测量相似的结果，而几何声学模拟无法像测量结果那样可靠地复现。

Conclusion: 房间声学模拟可以作为音频算法评估的有效工具，特别是数值波动法模拟能够提供与实际测量相似的评估结果。

Abstract: Audio-signal-processing and audio-machine-learning (ASP/AML) algorithms are
ubiquitous in modern technology like smart devices, wearables, and
entertainment systems. Development of such algorithms and models typically
involves a formal evaluation to demonstrate their effectiveness and progress
beyond the state-of-the-art. Ideally, a thorough evaluation should cover many
diverse application scenarios and room-acoustic conditions. However, in
practice, evaluation datasets are often limited in size and diversity because
they rely on costly and time-consuming measurements. This paper explores how
room-acoustic simulations can be used for evaluating ASP/AML algorithms. To
this end, we evaluate three ASP/AML algorithms with room-acoustic measurements
and data from different simulation engines, and assess the match between the
evaluation results obtained from measurements and simulations. The presented
investigation compares a numerical wave-based solver with two geometrical
acoustics simulators. While numerical wave-based simulations yielded similar
evaluation results as measurements for all three evaluated ASP/AML algorithms,
geometrical acoustic simulations could not replicate the measured evaluation
results as reliably.

</details>


### [20] [MEAN-RIR: Multi-Modal Environment-Aware Network for Robust Room Impulse Response Estimation](https://arxiv.org/abs/2509.05205)
*Jiajian Chen,Jiakang Chen,Hang Chen,Qing Wang,Yu Gao,Jun Du*

Main category: eess.AS

TL;DR: MEAN-RIR是一个多模态环境感知网络，通过编码器-解码器框架，结合音频、视觉和文本信息来预测房间脉冲响应，显著提升了RIR估计性能。


<details>
  <summary>Details</summary>
Motivation: 传统的房间脉冲响应估计方法通常依赖单一模态信息，无法充分利用环境的多层次信息。为了更准确地捕捉房间声学特性，需要整合音频、视觉和文本等多种模态的环境信息。

Method: 使用编码器-解码器框架，分别处理混响语音（音频）、全景图像（视觉）和文本描述。通过交叉注意力模块实现多模态间的有效交互。解码器生成两个组件：直接声和早期反射部分，以及用于调制可学习滤波噪声的掩码来合成晚期混响。

Result: MEAN-RIR显著改善了房间脉冲响应的估计效果，在声学参数方面取得了明显的性能提升。

Conclusion: 多模态环境信息的整合能够有效提升房间脉冲响应的预测精度，MEAN-RIR框架为声学环境建模提供了新的有效方法。

Abstract: This paper presents a Multi-Modal Environment-Aware Network (MEAN-RIR), which
uses an encoder-decoder framework to predict room impulse response (RIR) based
on multi-level environmental information from audio, visual, and textual
sources. Specifically, reverberant speech capturing room acoustic properties
serves as the primary input, which is combined with panoramic images and text
descriptions as supplementary inputs. Each input is processed by its respective
encoder, and the outputs are fed into cross-attention modules to enable
effective interaction between different modalities. The MEAN-RIR decoder
generates two distinct components: the first component captures the direct
sound and early reflections, while the second produces masks that modulate
learnable filtered noise to synthesize the late reverberation. These two
components are mixed to reconstruct the final RIR. The results show that
MEAN-RIR significantly improves RIR estimation, with notable gains in acoustic
parameters.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [21] [Ecologically Valid Benchmarking and Adaptive Attention: Scalable Marine Bioacoustic Monitoring](https://arxiv.org/abs/2509.04682)
*Nicholas R. Rasmussen,Rodrigue Rizk,Longwei Wang,KC Santosh*

Main category: cs.SD

TL;DR: 提出了GetNetUPAM评估框架和ARPA-N神经网络架构，用于提升水下被动声学监测的模型稳定性和泛化能力，在生态多样性评估中显著优于基线方法


<details>
  <summary>Details</summary>
Motivation: 水下被动声学监测存在固有噪声和复杂信号依赖性问题，现有方法在处理环境多样性时稳定性不足，需要更鲁棒的架构和评估框架

Method: GetNetUPAM分层嵌套交叉验证框架，按站点-年份分段数据；ARPA-N神经网络采用自适应分辨率池化和空间注意力机制处理不规则频谱图

Result: ARPA-N在平均精度上比DenseNet基线提升14.4%，所有指标的变异性降低一个数量级（log2尺度），在不同站点-年份折叠上实现一致检测

Conclusion: GetNetUPAM框架和ARPA-N架构显著提升了水下生物声学监测的准确性和可扩展性，能够有效应对环境多样性挑战

Abstract: Underwater Passive Acoustic Monitoring (UPAM) provides rich spatiotemporal
data for long-term ecological analysis, but intrinsic noise and complex signal
dependencies hinder model stability and generalization. Multilayered windowing
has improved target sound localization, yet variability from shifting ambient
noise, diverse propagation effects, and mixed biological and anthropogenic
sources demands robust architectures and rigorous evaluation. We introduce
GetNetUPAM, a hierarchical nested cross-validation framework designed to
quantify model stability under ecologically realistic variability. Data are
partitioned into distinct site-year segments, preserving recording
heterogeneity and ensuring each validation fold reflects a unique environmental
subset, reducing overfitting to localized noise and sensor artifacts. Site-year
blocking enforces evaluation against genuine environmental diversity, while
standard cross-validation on random subsets measures generalization across
UPAM's full signal distribution, a dimension absent from current benchmarks.
Using GetNetUPAM as the evaluation backbone, we propose the Adaptive Resolution
Pooling and Attention Network (ARPA-N), a neural architecture for irregular
spectrogram dimensions. Adaptive pooling with spatial attention extends the
receptive field, capturing global context without excessive parameters. Under
GetNetUPAM, ARPA-N achieves a 14.4% gain in average precision over DenseNet
baselines and a log2-scale order-of-magnitude drop in variability across all
metrics, enabling consistent detection across site-year folds and advancing
scalable, accurate bioacoustic monitoring.

</details>


### [22] [A Multiclass Acoustic Dataset and Interactive Tool for Analyzing Drone Signatures in Real-World Environments](https://arxiv.org/abs/2509.04715)
*Mia Y. Wang,Mackenzie Linn,Andrew P. Berg,Qian Zhang*

Main category: cs.SD

TL;DR: 这篇论文提供了一个包含32种不同品牌和模型无人机的音响签名数据集，包括原始音频、谱图和MFCC图谱，并提供了一个交互式网页应用来便于数据集探索和分析。


<details>
  <summary>Details</summary>
Motivation: 无人机的快速普及带来了隐私、安全和噪声污染等挑战，现有的视觉和雷达检测系统在某些条件下存在限制，需要有效的基于声音的检测方法。

Method: 收集了32种不同品牌和模型无人机的音响数据，包括原始音频录音、谱图和Mel频率候偶系数(MFCC)图谱，并开发了一个交互式网页应用。

Result: 构建了一个全面的无人机音响签名数据集，并成功开发了一个用户友好的网页应用，使得用户可以选择特定无人机类型、听取音频并查看对应的谱图和MFCC图谱。

Conclusion: 该数据集和工具有助于推动无人机检测、分类和音响分析的研究，支持技术进步和教育创新，并讨论了未来扩展和增强该项目的潜在应用。

Abstract: The rapid proliferation of drones across various industries has introduced
significant challenges related to privacy, security, and noise pollution.
Current drone detection systems, primarily based on visual and radar
technologies, face limitations under certain conditions, highlighting the need
for effective acoustic-based detection methods. This paper presents a unique
and comprehensive dataset of drone acoustic signatures, encompassing 32
different categories differentiated by brand and model. The dataset includes
raw audio recordings, spectrogram plots, and Mel-frequency cepstral coefficient
(MFCC) plots for each drone. Additionally, we introduce an interactive web
application that allows users to explore this dataset by selecting specific
drone categories, listening to the associated audio, and viewing the
corresponding spectrogram and MFCC plots. This tool aims to facilitate research
in drone detection, classification, and acoustic analysis, supporting both
technological advancements and educational initiatives. The paper details the
dataset creation process, the design and implementation of the web application,
and provides experimental results and user feedback. Finally, we discuss
potential applications and future work to expand and enhance the project.

</details>


### [23] [WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning](https://arxiv.org/abs/2509.04744)
*Gagan Mundada,Yash Vishe,Amit Namburi,Xin Xu,Zachary Novack,Julian McAuley,Junda Wu*

Main category: cs.SD

TL;DR: WildScore是首个多模态符号音乐推理基准，用于评估MLLMs在真实乐谱分析和复杂音乐学查询方面的能力，揭示了当前模型的优势和挑战。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型在视觉-语言任务上表现出色，但在符号音乐领域的推理能力尚未得到充分探索，需要专门的基准来评估这方面的能力。

Method: 构建了基于真实音乐作品和用户生成问题的WildScore数据集，采用系统化的音乐学本体分类，并将复杂音乐推理问题转化为多项选择题形式进行评估。

Result: 对最先进MLLMs的实证评估揭示了它们在视觉-符号推理方面的有趣模式，既显示了有希望的方向，也暴露了在符号音乐推理和分析方面的持续挑战。

Conclusion: WildScore基准为评估MLLMs在符号音乐理解方面的能力提供了重要工具，数据集和代码已公开发布，有助于推动该领域的研究发展。

Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have demonstrated
impressive capabilities across various vision-language tasks. However, their
reasoning abilities in the multimodal symbolic music domain remain largely
unexplored. We introduce WildScore, the first in-the-wild multimodal symbolic
music reasoning and analysis benchmark, designed to evaluate MLLMs' capacity to
interpret real-world music scores and answer complex musicological queries.
Each instance in WildScore is sourced from genuine musical compositions and
accompanied by authentic user-generated questions and discussions, capturing
the intricacies of practical music analysis. To facilitate systematic
evaluation, we propose a systematic taxonomy, comprising both high-level and
fine-grained musicological ontologies. Furthermore, we frame complex music
reasoning as multiple-choice question answering, enabling controlled and
scalable assessment of MLLMs' symbolic music understanding. Empirical
benchmarking of state-of-the-art MLLMs on WildScore reveals intriguing patterns
in their visual-symbolic reasoning, uncovering both promising directions and
persistent challenges for MLLMs in symbolic music reasoning and analysis. We
release the dataset and code.

</details>


### [24] [Quantum Fourier Transform Based Denoising: Unitary Filtering for Enhanced Speech Clarity](https://arxiv.org/abs/2509.04851)
*Rajeshwar Tripathi,Sahil Tomar,Sandeep Kumar,Monika Aggarwal*

Main category: cs.SD

TL;DR: 采用量子受灵的去噪框架，用量子约化变换(QFT)替代传统FFT，在各种SNR条件下实现了较优的去噪效果和减少人工效应


<details>
  <summary>Details</summary>
Motivation: 传统快速富里取变换(FFT)基于的音频增强方法在识别语音和噪声方面有限，需要一种更好的变换方法来提高性能

Method: 将音频增强管道中的FFT替换为量子富里取变换(QFT)，保持相同的超参数设置以便公平比较

Result: 在各种SNR条件下实验显示，QFT基于去噪在SNR方面获得了统计学上显著的收益，最高提高15dB，同时减少了人工效应生成

Conclusion: QFT基于去噪在低SNR和非稳态噪声场景下具有稳健性，而无需额外计算开销，为量子增强语音处理提供了可扩展的途径

Abstract: This paper introduces a quantum-inspired denoising framework that integrates
the Quantum Fourier Transform (QFT) into classical audio enhancement pipelines.
Unlike conventional Fast Fourier Transform (FFT) based methods, QFT provides a
unitary transformation with global phase coherence and energy preservation,
enabling improved discrimination between speech and noise. The proposed
approach replaces FFT in Wiener and spectral subtraction filters with a QFT
operator, ensuring consistent hyperparameter settings for fair comparison.
Experiments on clean speech, synthetic tones, and noisy mixtures across diverse
signal to noise ratio (SNR) conditions, demonstrate statistically significant
gains in SNR, with up to 15 dB improvement and reduced artifact generation.
Results confirm that QFT based denoising offers robustness under low SNR and
nonstationary noise scenarios without additional computational overhead,
highlighting its potential as a scalable pathway toward quantum-enhanced speech
processing.

</details>


### [25] [Learning and composing of classical music using restricted Boltzmann machines](https://arxiv.org/abs/2509.04899)
*Mutsumi Kobayashi,Hiroshi Watanabe*

Main category: cs.SD

TL;DR: 使用受限玻尔兹曼机(RBM)分析巴赫音乐风格特征，相比复杂机器学习模型更易解释内部状态


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的作曲软件模型结构复杂，难以分析其如何理解作曲家音乐特征，需要更简单可解释的模型

Method: 采用受限玻尔兹曼机(RBM)训练J.S.巴赫的音乐数据，利用RBM简单结构便于分析学习后的内部状态

Result: 学习后的RBM能够成功创作音乐作品

Conclusion: RBM作为一种结构简单的模型，既能模仿巴赫音乐风格进行创作，又便于分析其内部学习机制

Abstract: Recently, software has been developed that uses machine learning to mimic the
style of a particular composer, such as J. S. Bach. However, since such
software often adopts machine learning models with complex structures, it is
difficult to analyze how the software understands the characteristics of the
composer's music. In this study, we adopted J. S. Bach's music for training of
a restricted Boltzmann machine (RBM). Since the structure of RBMs is simple, it
allows us to investigate the internal states after learning. We found that the
learned RBM is able to compose music.

</details>


### [26] [MAIA: An Inpainting-Based Approach for Music Adversarial Attacks](https://arxiv.org/abs/2509.04980)
*Yuxuan Liu,Peihong Zhang,Rui Sang,Zhixin Li,Shengchen Li*

Main category: cs.SD

TL;DR: MAIA是一个新的音乐对抗攻击框架，支持白盒和黑盒攻击，通过重要性分析和生成式修复模型创建难以察觉的对抗样本，在多个MIR任务中表现出高攻击成功率和良好音频保真度。


<details>
  <summary>Details</summary>
Motivation: 当前音乐信息检索系统存在安全漏洞，需要研究对抗攻击来揭示这些脆弱性，促进更鲁棒和安全的模型发展。

Method: 首先进行重要性分析识别关键音频段，然后使用生成式修复模型在模型输出指导下重构这些段，生成细微有效的对抗扰动。

Result: 在多个MIR任务中，MAIA在白盒和黑盒设置下都实现了高攻击成功率，同时保持最小感知失真，主观听力测试确认了高音频保真度。

Conclusion: 研究揭示了当前MIR系统的脆弱性，强调了开发更鲁棒和安全模型的必要性，MAIA框架为评估和改进MIR系统安全性提供了有效工具。

Abstract: Music adversarial attacks have garnered significant interest in the field of
Music Information Retrieval (MIR). In this paper, we present Music Adversarial
Inpainting Attack (MAIA), a novel adversarial attack framework that supports
both white-box and black-box attack scenarios. MAIA begins with an importance
analysis to identify critical audio segments, which are then targeted for
modification. Utilizing generative inpainting models, these segments are
reconstructed with guidance from the output of the attacked model, ensuring
subtle and effective adversarial perturbations. We evaluate MAIA on multiple
MIR tasks, demonstrating high attack success rates in both white-box and
black-box settings while maintaining minimal perceptual distortion.
Additionally, subjective listening tests confirm the high audio fidelity of the
adversarial samples. Our findings highlight vulnerabilities in current MIR
systems and emphasize the need for more robust and secure models.

</details>


### [27] [Training a Perceptual Model for Evaluating Auditory Similarity in Music Adversarial Attack](https://arxiv.org/abs/2509.04985)
*Yuxuan Liu,Rui Sang,Peihong Zhang,Zhixin Li,Shengchen Li*

Main category: cs.SD

TL;DR: 提出了PAMT框架，通过心理声学条件化的对比变换器学习与人类听觉感知对齐的音乐表示，显著提高了音乐信息检索系统对抗对抗攻击的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有音乐信息检索系统容易受到人类难以察觉的对抗攻击，主要原因是模型特征空间与人类听觉感知之间的不对齐。现有防御方法和感知指标无法充分捕捉听觉细节，与人类判断相关性低。

Method: 基于冻结的MERT编码器构建心理声学条件化的序列对比变换器投影头，实现架构集成的心理声学条件化，学习感知对齐的音乐表示。

Result: Spearman相关系数达到0.65，优于现有感知指标；在Cover Song Identification和Music Genre Classification等任务上，对抗攻击下的鲁棒准确率平均提高9.15%。

Conclusion: PAMT框架通过心理声学条件化实现了与人类感知更好对齐的音乐表示，显著提升了对抗音乐对抗攻击的鲁棒性，为感知对齐的音乐表示学习开辟了新途径。

Abstract: Music Information Retrieval (MIR) systems are highly vulnerable to
adversarial attacks that are often imperceptible to humans, primarily due to a
misalignment between model feature spaces and human auditory perception.
Existing defenses and perceptual metrics frequently fail to adequately capture
these auditory nuances, a limitation supported by our initial listening tests
showing low correlation between common metrics and human judgments. To bridge
this gap, we introduce Perceptually-Aligned MERT Transformer (PAMT), a novel
framework for learning robust, perceptually-aligned music representations. Our
core innovation lies in the psychoacoustically-conditioned sequential
contrastive transformer, a lightweight projection head built atop a frozen MERT
encoder. PAMT achieves a Spearman correlation coefficient of 0.65 with
subjective scores, outperforming existing perceptual metrics. Our approach also
achieves an average of 9.15\% improvement in robust accuracy on challenging MIR
tasks, including Cover Song Identification and Music Genre Classification,
under diverse perceptual adversarial attacks. This work pioneers
architecturally-integrated psychoacoustic conditioning, yielding
representations significantly more aligned with human perception and robust
against music adversarial attacks.

</details>


### [28] [Recomposer: Event-roll-guided generative audio editing](https://arxiv.org/abs/2509.05256)
*Daniel P. W. Ellis,Eduardo Fonseca,Ron J. Weiss,Kevin Wilson,Scott Wisdom,Hakan Erdogan,John R. Hershey,Aren Jansen,R. Channing Moore,Manoj Plakal*

Main category: cs.SD

TL;DR: 通过文本描述和事件时间图编辑复杂音频场景中的单个音响事件，利用生成模型实现删除、插入和增强功能


<details>
  <summary>Details</summary>
Motivation: 复杂实际音频场景中多个音源时间重叠，编辑单个音响事件困难，需要生成模型来填充缺失或损坏的细节

Method: 使用基于SoundStream表征的编码器-解码器Transformer模型，在合成的（输入，期望输出）音频对上训练，这些对是通过向密集实际背景添加孤立音响事件形成的

Result: 评估显示编辑描述的各个部分（动作、类别、时间）都很重要，系统能够有效处理复杂音频场景的编辑

Conclusion: 重新组合（recomposition）是一个重要且实用的应用领域，该系统为音频场景精细编辑提供了可行的方案

Abstract: Editing complex real-world sound scenes is difficult because individual sound
sources overlap in time. Generative models can fill-in missing or corrupted
details based on their strong prior understanding of the data domain. We
present a system for editing individual sound events within complex scenes able
to delete, insert, and enhance individual sound events based on textual edit
descriptions (e.g., ``enhance Door'') and a graphical representation of the
event timing derived from an ``event roll'' transcription. We present an
encoder-decoder transformer working on SoundStream representations, trained on
synthetic (input, desired output) audio example pairs formed by adding isolated
sound events to dense, real-world backgrounds. Evaluation reveals the
importance of each part of the edit descriptions -- action, class, timing. Our
work demonstrates ``recomposition'' is an important and practical application.

</details>

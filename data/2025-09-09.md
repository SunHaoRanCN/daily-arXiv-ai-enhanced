<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 23]
- [eess.AS](#eess.AS) [Total: 7]
- [cs.SD](#cs.SD) [Total: 9]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Developing a Framework to Simulate Quantitative Ultrasound Flow and Tissue Motion for Ultrafast Doppler Ultrasound](https://arxiv.org/abs/2509.05464)
*Qiang Fu,Changhui Li*

Main category: eess.SP

TL;DR: 一个开源的3D完全量化流体模拟框架，用于在真实血管和组织运动条件下验证超快速功能多普勒成像技术


<details>
  <summary>Details</summary>
Motivation: 目前缺乏能够在真实三维血管流体和组织运动条件下进行量化模拟的工具，以支持超快速功能多普勒成像的研究和临床应用

Method: 开发了3D-FQFlow框架，整合L系统血管生成器、SimVascular CFD流体动力学模拟、组织运动模拟器、优化的PFILED超声模拟器、预计算矩阵重建器和量化分析器

Result: 成功实现了兔子肾脏(SSIM=0.951)、生成血管(SSIM=0.902)和临床肺动脉(SSIM=0.850)的3D成像；GPU加速使得100帧3D-uPDI生成速度提升18.8倍，100万散射体模拟仅需4,117秒

Conclusion: 3D-FQFlow是首个开源框架，为微血管成像研究创造了可复现的量化验证标准，在真实血管和运动条件下支持uPDI技术的研究和临床应用

Abstract: Ultrafast power Doppler imaging (uPDI) has made significant progress and
become an important imaging method for both research and clinical
implementations. While, it lacks simulation tools that can perform
three-dimensional (3D) quantitative flow with tissue motion close to realistic
conditions. In this study, we explore to construct an open-source framework,
named 3D-Fully Quantitative Flow (3D-FQFlow), to provide quantitative modeling
of 3D vascular flow with tissue motion and uPDI imaging. The framework
integrates a L-system-based vascular generator with SimVascular CFD for
hemodynamics, a tissue motion simulator supporting user-defined or
clinical-data-driven condition, an optimized PFILED ultrasound simulator, a
precomputed-matrix-based reconstructor, and a quantitative analyzer
(MSE/PSNR/SSIM). Results demonstrate distinct influences of four motion
patterns on SVD decomposition; successful 3D imaging of rabbit kidney (SSIM =
0.951), generated vasculature (SSIM = 0.902), and clinical pulmonary arteries
(SSIM = 0.850); and GPU acceleration permitting 1-million-scatterer simulation
in 4,117 seconds with 18.8* speedup for 100-frame 3D-uPDI generation. 3D-FQFlow
establishes the first open-source framework for quantitative validation of uPDI
under realistic vascular and motion conditions, creating a reproducible
standard for microvascular imaging research
(https://github.com/FortuneOU/3D-FQFlow).

</details>


### [2] [Time-Modulated Intelligent Reflecting Surfaces for Integrated Sensing, Communication and Security: A Generative AI Design Framework](https://arxiv.org/abs/2509.05565)
*Zhihao Tao,Athina Petropulu,H. Vincent Poor*

Main category: eess.SP

TL;DR: 使用生成流网络(GFlowNet)设计时间调制智能反射表面(TM-IRS)，为集成感知通信系统提供物理层安全保护，在保证合法用户通信质量的同时将其他方向的信号打乱


<details>
  <summary>Details</summary>
Motivation: 解决集成感知通信系统中的安全问题，防止目标作为歇听者获取传输数据，需要一种能够同时优化通信、感知和安全性能的方案

Method: 使用GFlowNet框架学习随机策略，从庞大的离散参数空间中采样高性能TM-IRS配置。通过形成合法通信用户的可实现总速率和目标方向的放大图增益，构建奖励函数来聚合考虑通信和感知性能

Result: 实验结果证明方法能够同时集成感知、通信和安全性能，与穷举组合搜索相比显示出显著的采样效率，并对基于规则的TM-IRS设计方法具有更强的稳健性

Conclusion: GFlowNet基于的TM-IRS设计方法为集成感知通信系统提供了高效的物理层安全解决方案，能够在复杂的参数空间中找到优化配置，实现通信性能与安全性的平衡

Abstract: We propose a novel approach to achieve physical layer security for integrated
sensing and communication (ISAC) systems operating in the presence of targets
that may be eavesdroppers. The system is aided by a time-modulated intelligent
reflecting surface (TM-IRS), which is configured to preserve the integrity of
the transmitted data at one or more legitimate communication users (CUs) while
making them appear scrambled in all other directions. The TM-IRS design
leverages a generative flow network (GFlowNet) framework to learn a stochastic
policy that samples high-performing TM-IRS configurations from a vast discrete
parameter space. Specifically, we begin by formulating the achievable sum rate
for the legitimate CUs and the beampattern gain toward the target direction,
based on which we construct reward functions for GFlowNets that jointly capture
both communication and sensing performance. The TM-IRS design is modeled as a
deterministic Markov decision process (MDP), where each terminal state
corresponds to a complete configuration of TM-IRS parameters. GFlowNets,
parametrized by deep neural networks are employed to learn a stochastic policy
that samples TM-IRS parameter sets with probability proportional to their
associated reward. Experimental results demonstrate the effectiveness of the
proposed GFlowNet-based method in integrating sensing, communication and
security simultaneously, and also exhibit significant sampling efficiency as
compared to the exhaustive combinatorial search and enhanced robustness against
the rule-based TM-IRS design method.

</details>


### [3] [Power-Measurement-Based Channel Estimation for Beyond Diagonal RIS](https://arxiv.org/abs/2509.05639)
*Yijie Liu,Weidong Mei,He Sun,Dong Wang,Peilan Wang*

Main category: eess.SP

TL;DR: 提出基于单层神经网络的BD-RIS信道估计方法，仅使用接收功率测量即可准确获取信道状态信息，无需专用导频信号


<details>
  <summary>Details</summary>
Motivation: 现有BD-RIS信道估计方法依赖专用导频信号，增加系统开销且与现有通信协议不兼容，需要一种更高效的信道估计方案

Method: 利用接收信号功率可表示为类似单层神经网络的形式，通过反向传播算法基于不同训练反射系数下的功率测量来恢复信道状态信息

Result: 数值结果表明该方法能够实现较小的归一化均方误差，特别是在训练反射次数较多时表现更佳

Conclusion: 所提出的神经网络方法为BD-RIS提供了一种低开销、兼容性好的信道估计解决方案，仅需接收功率测量即可实现准确的信道估计

Abstract: Beyond diagonal reconfigurable intelligent surface (BD-RIS), with its
enhanced degrees of freedom compared to conventional RIS, has demonstrated
notable potential for enhancing wireless communication performance. However, a
key challenge in employing BD-RIS lies in accurately acquiring its channel
state information (CSI) with both the base station (BS) and users. Existing
BD-RIS channel estimation methods rely mainly on dedicated pilot signals, which
increase system overhead and may be incompatible with current communication
protocols. To overcome these limitations, this letter proposes a new
single-layer neural network (NN)-enabled channel estimation method utilizing
only the easily accessible received power measurements at user terminals. In
particular, we show that the received signal power can be expressed in a form
similar to a single-layer NN, where the weights represent the BD-RIS's CSI.
This structure enables the recovery of CSI using the backward propagation,
based on power measurements collected under varying training reflection
coefficients. Numerical results show that our proposed method can achieve a
small normalized mean square error (NMSE), particularly when the number of
training reflections is large.

</details>


### [4] [Full-Angle Ray Antenna Array and Omnicell Wireless Communication System](https://arxiv.org/abs/2509.05677)
*Xuancheng Zhu,Zhiwen Zhou,Yong Zeng*

Main category: eess.SP

TL;DR: 全角Ray天线数组构建和全向细胞新通信范式，通过将多个简单均匀线性数组不同方向排列实现全方向覆盖，优于传统ULA/UCA组网方式


<details>
  <summary>Details</summary>
Motivation: 解决传统天线数组硬件成本高、轴向分辨率不均匀、互用户干扰大等问题，提高系统性能和成本效益

Method: 提出全角RAA构建，将RAA方位角扩展到全角域；构建基站中央部署的全向细胞通信系统，取代传统扇区组网

Result: 分析和数值结果显示，该系统在空间分辨率、通信速率等关键性能指标上都显著优于传统ULA/UCA基础的扇区组网系统

Conclusion: 全角RAA和全向细胞通信范式为新一代无线通信系统提供了更高性能、更低成本的解决方案，具有重要的实践价值和应用前景

Abstract: Ray antenna array (RAA) was recently proposed as a novel multi-antenna
architecture that arranges multiple massive cheap antenna elements into simple
uniform linear arrays (sULAs) with different orientations. Compared with
traditional architectures like hybrid analog/digital beamforming with uniform
linear array (ULA) and uniform circular array (UCA), RAA has several promising
advantages such as significantly reduced hardware cost, higher beamforming
gains and the ability of providing uniform angular resolution for all
directions. In this paper, we propose a full-angle RAA architecture and an
innovative omnicell wireless communication paradigm enabled by full-angle RAA.
The proposed full-angle RAA expands RAA's orientation angle to the full angle
domain, such that the RAA's advantages can be exploited to all directions. This
further enables the new concept of omnicell wireless communication system, with
the base station equipped by full-angle RAA and deployed at the center of each
cell. Compared to the conventional cell sectoring wireless communication
system, the proposed omnicell system is expected to not only significantly
reduce the inter-user interference, but also improve the cost efficiency.
Extensive analytical and numerical results are provided to compare those key
performance indicators such as the spatial resolution and the communication
rate of the proposed full-angle RAA based omnicell wireless communication
system against the conventional ULA/UCA-based cell sectoring systems.

</details>


### [5] [Affine Filter Bank Modulation (AFBM): A Novel 6G ISAC Waveform with Low PAPR and OOBE](https://arxiv.org/abs/2509.05683)
*Kuranage Roche Rayan Ranasinghe,Henrique L. Senger,Gustavo P. Gonçalves,Hyeon Seok Rou,Bruno S. Chang,Giuseppe Thadeu Freitas de Abreu,Didier Le Ruyet*

Main category: eess.SP

TL;DR: AFBM波形是一种基于滤波器组多载波调制和啁啾域波形的新型波形，具有低峰均功率比和低带外发射特性，适用于6G集成感知与通信系统。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统AFDM波形在双弥散信道条件下的高PAPR和OOBE问题，同时满足6G系统中集成感知与通信的需求。

Method: 结合经典滤波器组多载波调制理论和啁啾域波形技术，设计AFBM波形；通信方面采用高斯置信传播算法进行符号检测，感知方面使用EM辅助的概率数据关联框架进行目标估计。

Result: AFBM相比传统AFDM波形具有显著更低的PAPR和OOBE，在双弥散信道条件下表现出优异的通信可靠性和感知精度。

Conclusion: AFBM是一种有前景的下一代无线系统波形，通过分析和数值评估验证了其优越性能。

Abstract: We propose the affine filter bank modulation (AFBM) waveform for enhanced
integrated sensing and communications (ISAC) in sixth generation (6G), designed
by drawing on concepts from classical filter bank multicarrier modulation
(FBMC) theory and recent advances in chirp-domain waveforms, particularly
affine frequency division multiplexing (AFDM). Specifically, AFBM exhibits
several desirable properties, with emphasis on its remarkably low
peak-to-average power ratio (PAPR) and reduced out-of-band emission (OOBE) when
benchmarked against the conventional AFDM waveform under doubly-dispersive (DD)
channel conditions. In the communications setting, reliable symbol detection is
achieved using a tailored low-complexity Gaussian belief propagation
(GaBP)-based algorithm, while in the sensing setting, a range and velocity
estimation approach is developed that integrates an expectation maximization
(EM)-assisted probabilistic data association (PDA) framework to accurately
identify surrounding targets. The highlighted performance and benefits of AFBM
are validated through analytical and numerical evaluations, including
conventional metrics such as ambiguity function (AF), bit error rate (BER), and
root mean square error (RMSE), consolidating its position as a promising
waveform for next-generation wireless systems.

</details>


### [6] [Resource Allocation and Beamforming in FIM-Assisted BS and STAR-BD-RIS-Aided NOMA: A Meta-Learning Approach](https://arxiv.org/abs/2509.05692)
*Armin Farhadi,Maryam Cheraghy,Qingqing Wu,Eduard Jorswieck*

Main category: eess.SP

TL;DR: 本研究提出了一种基于柔性智能超表面(FIM)的无线通信系统，集成STAR-BD-RIS和NOMA技术，通过Meta-SAC算法优化系统参数，显著提升能效


<details>
  <summary>Details</summary>
Motivation: 探索将柔性智能超表面与STAR-BD-RIS和NOMA技术相结合的新型无线通信架构，解决传统系统能效低的问题

Method: 采用多天线FIM辅助基站和双扇区BD-RIS，FIM元件可独立发射信号并动态调整垂直位置。使用Meta-SAC算法联合优化波束成形、RIS矩阵、NOMA约束和FIM表面形状

Result: 仿真结果表明Meta-SAC算法优于Meta-DDPG，FIM辅助设计相比基准方案获得显著能效增益

Conclusion: 所提出的FIM-STAR-BD-RIS-NOMA系统架构和Meta-SAC优化算法能有效提升无线通信系统的能量效率

Abstract: This study explores a flexible intelligent metasurface (FIM)-based wireless
communication system that integrates simultaneously transmitting and reflecting
beyond diagonal reconfigurable intelligent surfaces (STAR-BD-RIS) with
non-orthogonal multiple access (NOMA). The system features a multi-antenna
FIM-assisted base station (BS) aided by dual-sector BD-RIS. The FIM consists of
cost-effective radiating elements that can independently emit signals and
dynamically adjust their vertical positions ("morphing"). The goal is to
maximize energy efficiency by jointly optimizing BS beamforming, the
STAR-BD-RIS matrix, NOMA constraints, and the FIM surface shape under power
limits. Due to the problem's non-convexity, a meta-soft actor-critic (Meta-SAC)
algorithm is proposed for adaptive optimization. Simulation results show that
Meta-SAC outperforms the Meta-DDPG algorithm, and FIM-assisted designs yield
substantial energy efficiency gains over benchmark schemes.

</details>


### [7] [Optimal Anchor Deployment and Topology Design for Large-Scale AUV Navigation](https://arxiv.org/abs/2509.05903)
*Wei Huang,Junpeng Lu,Tianhe Xu,Jianxu Shu,Hao Zhang,Kaitao Meng,Yanan Wu*

Main category: eess.SP

TL;DR: 研究海底声学锚点最优部署拓扑，为AUV导航提供高质量定位服务，分析大规模水下导航系统的部署模式，推导锚点集群对导航性能的影响规律，并通过实验验证优化性能。


<details>
  <summary>Details</summary>
Motivation: 海底声学锚点是AUV导航的重要组成部分，但水下锚点部署稀疏且成本高，缺乏卫星覆盖和普遍回传能力，需要研究最优部署拓扑来提供高质量导航定位服务。

Method: 分析大规模水下导航系统的可能部署模式，制定水下锚点部署的拓扑优化方案，推导锚点集群对给定区域内导航性能的影响规律，展示高概率到达目的地的服务区域覆盖条件。

Result: 通过实验结果评估了优化性能，证明了所提出的拓扑优化方法的有效性。

Conclusion: 提出了水下声学锚点最优部署拓扑的优化方法，为AUV导航系统提供了高质量定位服务的部署方案，解决了水下锚点部署稀疏和成本高的问题。

Abstract: Seafloor acoustic anchors are an important component of AUV navigation,
providing absolute updates that correct inertial dead-reckoning. Unlike
terrestrial positioning systems, the deployment of underwater anchor nodes is
usually sparse due to the uneven distribution of underwater users, as well as
the high economic cost and difficult maintenance of underwater equipment. These
anchor nodes lack satellite coverage and cannot form ubiquitous backhaul as
terrestrial nodes do. In this paper, we investigate the optimal anchor
deployment topology to provide high-quality AUV navigation and positioning
services. We first analyze the possible deployment mode in large-scale
underwater navigation system, and formulate a topology optimization for
underwater anchor node deployment. Then, we derive a scaling law about the
influence of anchors in each cluster on the navigation performance within a
given area and demonstrate a service area coverage condition with a high
probability of reaching the destination. Finally, the optimization performance
is evaluated through experimental results.

</details>


### [8] [Active noise cancellation in ultra-low field MRI: distinct strategies for different channels](https://arxiv.org/abs/2509.05955)
*Jiali He,Sheng Shen,Jiamin Wu,Xiaohan Kong,Yamei Dai,Liang Tan,Zheng Xu*

Main category: eess.SP

TL;DR: 这篇论文研究了永磁铁低场核磁共振成像系统中的复合电磁干扰问题，发现鞍形线圈比螺线管线圈更容易受到横向干扰，并提出了前端逆场重构和后端通道自适应器器的双阶段压制策略，实验证明该方法能有效提升干扰抵抗效果和图像质量。


<details>
  <summary>Details</summary>
Motivation: 开放环境中的超低场核磁共振成像系统极易受到复合电磁干扰，不同成像通道因耦合特性异质性而对干扰响应不一，需要研究通道特异性干扰传播路径和有效的压制策略。

Method: 研究永磁铁低场MRI系统中的通道特异性干扰传播路径，分析鞍形线圈和螺线管线圈的干扰效应差异，提出前端空间域逆场重构结合后端通道自适应主动器器的双阶段压制策略。

Result: 实验结果显示，该方法能够压制超过80%的电磁干扰，显著提高通道间信噪比一致性，并将融合图像的信噪比提高24%。

Conclusion: 这些发现深入揭示了电磁干扰耦合的通道依赖性质，为将来阵列线圈超低场MRI系统的噪声压制提供了理论基础和实践指南，建立了针对性的干扰缓解策略。

Abstract: Ultra-low field magnetic resonance imaging(ULF-MRI) systems operating in open
environments are highly susceptible to composite electromagnetic
interference(EMI). Different imaging channels respond non-uniformly to EMI
owing to their distinct coupling characteristics. Here, we investigate
channel-specific interference pathways in a permanent-magnet-based low-field
MRI system and show that saddle coils are intrinsically more vulnerable to
transverse EMI components than solenoidal coils. To mitigate these
heterogeneous coupling effects, we propose a dual-stage suppression strategy
that combines front-end spatial-domain inverse field reconstruction with
back-end channel-adaptive active noise cancellation. Experiments demonstrate
that this approach suppresses EMI by more than 80%, substantially improves
inter-channel signal-to-noise ratio(SNR) consistency, and enhances the
fused-image SNR by 24%. These findings elucidate the channel-dependent nature
of EMI coupling and establish targeted mitigation strategies, providing both a
theoretical basis and practical guidance for noise suppression in future
array-coil ULF-MRI systems.

</details>


### [9] [The Case for a DNANF 1Pb/s Trans-Atlantic Submarine Cable](https://arxiv.org/abs/2509.05959)
*Pierluigi Poggiolini,Francesco Poletti*

Main category: eess.SP

TL;DR: 利用低损耗空芯光纤技术构建跨大西洋海底电缆，实现双向传输1Pb/s容量和200km跨距


<details>
  <summary>Details</summary>
Motivation: 低损耗空芯光纤技术的进步为构建更高容量和更长跨距的海底通信电缆提供了可能性

Method: 利用最新的低损耗空芯光纤技术，通过双向传输方式构建跨大西洋海底电缆系统

Result: 理论上可以实现每方向1Pb/s的传输容量，同时将跨距长度大幅增加到200km

Conclusion: 空芯光纤技术有望显著提升海底通信电缆的性能，实现前所未有的容量和跨距组合

Abstract: The recent progress in low-loss hollow-core fibers allows to speculate on the
possibility of building a transatlantic submarine cable that can achieve the
goal of 1 Pb/s per direction, leveraging bidirectional transmission, and at the
same time drastically increase span length, theoretically to 200km.

</details>


### [10] [DeepStream: Prototyping Deep Joint Source-Channel Coding for Real-Time Multimedia Transmissions](https://arxiv.org/abs/2509.05971)
*Kaiyi Chi,Yinghui He,Qianqian Yang,Zhiping Jiang,Yuanchao Shu,Zhiqin Wang,Jun Luo,Jiming Chen*

Main category: eess.SP

TL;DR: Error


<details>
  <summary>Details</summary>
Motivation: Error

Method: Error

Result: Error

Conclusion: Error

Abstract: Deep learning-based joint source-channel coding (DeepJSCC) has emerged as a
promising technique in 6G for enhancing the efficiency and reliability of data
transmission across diverse modalities, particularly in low signal-to-noise
ratio (SNR) environments. This advantage is realized by leveraging powerful
neural networks to learn an optimal end-to-end mapping from the source data
directly to the transmit symbol sequence, eliminating the need for separate
source coding, channel coding, and modulation. Although numerous efforts have
been made towards efficient DeepJSCC, they have largely stayed at numerical
simulations that can be far from practice, leaving the real-world viability of
DeepJSCC largely unverified. To this end, we prototype DeepStream upon
orthogonal frequency division multiplexing (OFDM) technology to offer efficient
and robust DeepJSCC for multimedia transmission. In conforming to OFDM, we
develop both a feature-to-symbol mapping method and a cross-subcarrier
precoding method to improve the subcarrier independence and reduce
peak-to-average power ratio. To reduce system complexity and enable flexibility
in accommodating varying quality of service requirements, we further propose a
progressive coding strategy that adjusts the compression ratio based on latency
with minimal performance loss. We implement DeepStream for real-time image
transmission and video streaming using software-defined radio. Extensive
evaluations verify that DeepStream outperforms both the standard scheme and the
direct deployment scheme. Particularly, at an SNR of 10 dB, DeepStream achieves
a PSNR of 35 dB for image transmission and an MS-SSIM of 20 dB for video
streaming, whereas the standard scheme fails to recover meaningful information.

</details>


### [11] [3D-Image Reconstruction using MIMO-SAR FMCW Radar](https://arxiv.org/abs/2509.05977)
*Ayush Jha,Dhanireddy Chandrika,Chandra Sekhar Seelamantula,Chetan Singh Thakur*

Main category: eess.SP

TL;DR: 基于虚拟MIMO FMCW雷达与SAR技术的结合，提出了一种高分辨率3D江米波雷达成像的快速时域重建算法


<details>
  <summary>Details</summary>
Motivation: 传统SAR成像算法主要提取2D信息，在3D场景重建方面有限制，需要突破这一限制

Method: 结合虚拟多输入多输出(MIMO)频率调制连续波(FMCW)雷达与综合孔径雷达(SAR)技术，开发快速时域重建算法

Result: 实现了高分辨率3D江米波雷达成像，为充分利用SAR技术的潜力提供了新方案

Conclusion: 该方法为高级雷达成像应用开启了新纪元，在学术研究和工业应用中具有重要意义

Abstract: With the advancement of millimeter-wave radar technology, Synthetic Aperture
Radar (SAR) imaging at millimeter-wave frequencies has gained significant
attention in both academic research and industrial applications. However,
traditional SAR imaging algorithms primarily focus on extracting
two-dimensional information from detected targets, which limits their potential
for 3D scene reconstruction. In this work, we demonstrated a fast time-domain
reconstruction algorithm for achieving high-resolution 3D radar imaging at
millimeter-wave (mmWave) frequencies. This approach leverages a combination of
virtual Multiple Input Multiple Output (MIMO) Frequency Modulated Continuous
Wave (FMCW) radar with the precision of Synthetic Aperture Radar (SAR)
technique, setting the stage for a new era of advanced radar imaging
applications.

</details>


### [12] [Quantum Radar for ISAC: Sum-Rate Optimization](https://arxiv.org/abs/2509.06070)
*Abdulmohsen Alsaui,Neel Kanth Kundu,Hyundong Shin,Octavia A. Dobre*

Main category: eess.SP

TL;DR: 本文提出一种新的集成量子感知与经典通信(IQSCC)框架，通过在基站中嵌入量子照明雷达来同时支持全双工经典通信和量子增强目标检测，解决低信号力高噪声条件下的感知限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统ISAC体系中的经典雷达系统在低信号力高噪声条件下存在基本限制，需要新的技术来提高感知性能。

Method: 通过最大化总速率的优化格式，使用逐次凸近似技术解决发射功率和放大向量的非凸联合优化问题，并在统计检测理论下推导经典和量子雷达协议的性能上限。

Result: 模拟结果显示，提出的IQSCC系统在满足感知要求的同时，通信吞吐量明显高于传统ISAC基准系统。

Conclusion: 量子照明雷达在低信干歧比噪声水平下具有量子优势，IQSCC框架能够实现更高的通信速率和更好的感知性能。

Abstract: Integrated sensing and communication (ISAC) is emerging as a key enabler for
spectrum-efficient and hardware-converged wireless networks. However, classical
radar systems within ISAC architectures face fundamental limitations under low
signal power and high-noise conditions. This paper proposes a novel framework
that embeds quantum illumination radar into a base station to simultaneously
support full-duplex classical communication and quantum-enhanced target
detection. The resulting integrated quantum sensing and classical communication
(IQSCC) system is optimized via a sum-rate maximization formulation subject to
radar sensing constraints. The non-convex joint optimization of transmit power
and beamforming vectors is tackled using the successive convex approximation
technique. Furthermore, we derive performance bounds for classical and quantum
radar protocols under the statistical detection theory, highlighting the
quantum advantage in low signal-to-interference-plus-noise ratio regimes.
Simulation results demonstrate that the proposed IQSCC system achieves a higher
communication throughput than the conventional ISAC baseline while satisfying
the sensing requirement.

</details>


### [13] [Pinching Antenna System (PASS) Enhanced Covert Communications: Against Warden via Sensing](https://arxiv.org/abs/2509.06170)
*Hao Jiang,Zhaolin Wang,Yuanwei Liu,Arumugam Nallanathan,Zhiguo Ding*

Main category: eess.SP

TL;DR: 本文提出了一种基于拉综天线系统(PASS)的感知助力隐蔽通信网络，通过动态重配天线位置和感知跟踪恶意监听者来提升通信隐蔽性能。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置MIMO天线数组在隐蔽通信中存在限制，需要一种能够动态调整天线位置以提升隐蔽性能的新型系统。

Method: 采用扩展卡尔曼滤波器(EKF)进行监听者踪踪，通过子空间方法联合设计波束成形和人工噪声，并使用深度强化学习(DRL)优化拉综天线位置。

Result: 数值结果表明：EKF方法能够以低复杂度准确踪踪监听者CSI，提出的解决方案在性能上超过贪心算法和搜索基准，PASS系统表现优于传统全数字MIMO系统。

Conclusion: 该研究成功开发了一种通过动态天线重配和感知跟踪来提升隐蔽通信性能的有效方法，为未来安全通信系统设计提供了新的设计自由度。

Abstract: A sensing-aided covert communication network empowered by pinching antenna
systems (PASS) is proposed in this work. Unlike conventional fixed-position
MIMO arrays, PASS dynamically reconfigures its pinching antennas (PAs) closer
to the legitimate user, substantially enhancing covertness. To further secure
the adversary's channel state information (CSI), a sensing function is
leveraged to track the malicious warden's movements. In particular, this paper
first proposes an extended Kalman filter (EKF) based approach to fulfilling the
tracking function. Building on this, a covert communication problem is
formulated with a joint design of beamforming, artificial noise (AN) signals,
and the position of PAs. Then, the beamforming and AN design subproblems are
resolved jointly with a subspace approach, while the PA position optimization
subproblem is handled by a deep reinforcement learning (DRL) approach by
treating the evolution of the warden's mobility status as a temporally
corrected process. Numerical results are presented and demonstrate that: i) the
EKF approach can accurately track the warden's CSI with low complexity, ii) the
effectiveness of the proposed solution is verified by its outperformance over
the greedy and searching-based benchmarks, and iii) with new design degrees of
freedom (DoFs), the performance of PASS is superior to the conventional
fully-digital MIMO systems.

</details>


### [14] [Human Body Weight Estimation Through Music-Induced Bed Vibrations](https://arxiv.org/abs/2509.06257)
*Yuyan Wu,Jiale Zhang,Moon Lee,Cherrelle Smith,Xinyi Li,Ankur Senapati,Pei Zhang,Hae Young Noh*

Main category: eess.SP

TL;DR: MelodyBedScale是一种利用音乐诱发床体振动来无创快速估计体重的系统，通过振动传感器捕捉体重对床体振动传递函数的影响，结合物理信息神经网络实现高精度体重估计


<details>
  <summary>Details</summary>
Motivation: 急诊医疗中快速准确的体重估计对治疗决策至关重要，但传统方法对固定患者不实用、不准确或耗时费力

Method: 识别体重敏感频段并创作相应音乐诱发床振动，使用振动传感器采集数据，结合物理理论分析设计物理信息神经网络进行体重回归

Result: 在木质和钢制床上对11名参与者测试，平均绝对误差达到1.55公斤

Conclusion: MelodyBedScale提供了一种非侵入式、快速的床上体重估计解决方案，在急诊医疗中具有重要应用价值

Abstract: Rapid and accurate body weight estimation is critical in emergency medical
care, as it directly influences treatment decisions, such as drug dosing,
defibrillation energy selection, and fluid resuscitation. Traditional methods
such as stand-on scales, length-based tapes, or transfer-based weighing scales
are often impractical for immobilized patients, inaccurate, or labor-intensive
and time-consuming. This paper introduces MelodyBedScale, a non-intrusive and
rapid on-bed weight estimation system that leverages bed vibration induced by
music. The core insight is that body weight affects the vibration transfer
function of the bed-body system, which is captured using vibration sensors
placed on opposite sides of the bed. First, we identify weight-sensitive
frequency bands and compose clinically acceptable soft, natural music with high
signal energy in these frequency bands. This music is then played through a
speaker mounted on the bed to induce bed vibrations. Additionally, to
efficiently capture the complex weight-vibration relationship with limited data
and enhance generalizability to unseen individuals and weights, we
theoretically analyze the weight-vibration relationship and integrate the
results into the activation functions of the neural network for
physics-informed weight regression. We evaluated MelodyBedScale on both wooden
and steel beds across 11 participants, achieving a mean absolute error of up to
1.55 kg.

</details>


### [15] [Optimal Distortion-Aware Multi-User Power Allocation for Massive MIMO Networks](https://arxiv.org/abs/2509.06491)
*Siddarth Marwaha,Pawel Kryszkiewicz,Eduard Jorswieck*

Main category: eess.SP

TL;DR: 本文提出了一种考虑功率放大器非线性失真的最优功率分配策略，在OFDM大规模MIMO系统中显著提升了和速率性能


<details>
  <summary>Details</summary>
Motivation: 现实无线发射机前端存在非线性行为（如功率放大器削波），现有资源分配方案忽略这种失真会导致结果不准确或自由度减少，无法达到全局最优性能

Method: 采用软限幅器PA模型，在瑞利衰落信道下推导宽带信噪失真比(SNDR)，将非凸优化问题解耦为总功率分配和用户间功率分布两个子问题，提出交替优化算法求解最优解

Result: 仿真结果显示相比忽略失真的方案，64天线基站服务60用户时中位数提升4倍，512天线基站时中位数提升50%

Conclusion: 功率放大器引入的失真会导致无需显式发射功率约束的SNDR高效工作点，所提算法能有效处理非线性失真问题，显著提升系统性能

Abstract: Real-world wireless transmitter front-ends exhibit certain nonlinear
behavior, e.g., signal clipping by a Power Amplifier (PA). Although many
resource allocation solutions do not consider this for simplicity, it leads to
inaccurate results or a reduced number of degrees of freedom, not achieving the
global performance. In this work, we propose an optimal PA distortion-aware
power allocation strategy in a downlink orthogonal frequency division multiplex
(OFDM) based massive multiple-input multiple-output (M-MIMO) system. Assuming a
soft-limiter PA model, where the transmission occurs under small-scale
independent and identically distributed (i.i.d) Rayleigh fading channel, we
derive the wideband signal-to-noise-and-distortion ratio (SNDR) and formulate
the power allocation problem. Most interestingly, the distortion introduced by
the PA leads to an SNDR-efficient operating point without explicit transmit
power constraints. While the optimization problem is non-convex, we decouple it
into a non-convex total power allocation problem and a convex power
distribution problem among the users (UEs). We propose an alternating
optimization algorithm to find the optimum solution. Our simulation results
show significant sum-rate gains over existing distortion-neglecting solutions,
e.g., a median 4 times increase and a median 50\% increase for a 64-antenna and
512-antenna base station serving 60 users, respectively.

</details>


### [16] [Synesthesia of Machines (SoM)-Aided LiDAR Point Cloud Transmission for Collaborative Perception](https://arxiv.org/abs/2509.06506)
*Ensong Liu,Rongqing Zhang,Xiang Cheng,Jian Tang*

Main category: eess.SP

TL;DR: 通过密度保持点云压缩和渗透学习技术，提出LPC-FT系统实现高效、稳健的多机器人协作矩阵传输


<details>
  <summary>Details</summary>
Motivation: 解决LiDAR点云大数据量传输延迟问题，提高多机器人协作感知的效率和稳健性

Method: 采用密度保持深度点云压缩编码，设计基于self-attention的通道编码模块和基于cross-attention的特征融合模块，利用非线性激活层和迁移学习对投通道噪声

Result: 在Chamfer Distance上减少30%，PSNR提高1.9dB，超过传统八叉树压缩和现有深度学习压缩技术

Conclusion: LPC-FT系统具有优秀的重建性能和通道逆境耐受性，能够有效支持多机器人协作感知任务

Abstract: Collaborative perception enables more accurate and comprehensive scene
understanding by learning how to share information between agents, with LiDAR
point clouds providing essential precise spatial data. Due to the substantial
data volume generated by LiDAR sensors, efficient point cloud transmission is
essential for low-latency multi-agent collaboration. In this work, we propose
an efficient, robust and applicable LiDAR point cloud transmission system via
the Synesthesia of Machines (SoM), termed LiDAR Point Cloud Feature
Transmission (LPC-FT), to support collaborative perception among multiple
agents. Specifically, we employ a density-preserving deep point cloud
compression method that encodes the complete point cloud into a downsampled
efficient representation. To mitigate the effects of the wireless channel, we
design a channel encoder module based on self-attention to enhance LiDAR point
cloud features and a feature fusion module based on cross-attention to
integrate features from transceivers. Furthermore, we utilize the nonlinear
activation layer and transfer learning to improve the training of deep neural
networks in the presence the digital channel noise. Experimental results
demonstrate that the proposed LPC-FT is more robust and effective than
traditional octree-based compression followed by channel coding, and
outperforms state-of-the-art deep learning-based compression techniques and
existing semantic communication methods, reducing the Chamfer Distance by 30%
and improving the PSNR by 1.9 dB on average. Owing to its superior
reconstruction performance and robustness against channel variations, LPC-FT is
expected to support collaborative perception tasks.

</details>


### [17] [Integrated Detection and Tracking Based on Radar Range-Doppler Feature](https://arxiv.org/abs/2509.06569)
*Chenyu Zhang,Yuanhang Wu,Xiaoxi Ma,Wei Yi*

Main category: eess.SP

TL;DR: 提出基于雷达特征的联合检测跟踪方法InDT，通过神经网络提取RD矩阵特征并自适应更新卡尔曼滤波器，在模拟和公开数据集上验证有效性


<details>
  <summary>Details</summary>
Motivation: 现有联合检测跟踪方法在充分利用雷达信号潜力方面存在挑战，包括CFAR模型信息表示能力有限、复杂场景描述不足以及跟踪器获取信息有限

Method: InDT方法包含雷达信号检测网络架构和检测辅助跟踪器。检测器从RD矩阵提取特征信息，通过特征增强模块和检测头返回目标位置。跟踪器基于检测置信度自适应更新卡尔曼滤波器测量噪声协方差，使用余弦距离测量目标RD特征相似度

Result: 在模拟数据和公开数据集上验证了方法的有效性

Conclusion: 提出的InDT方法能够更好地利用雷达信号特征，提高检测和跟踪性能

Abstract: Detection and tracking are the basic tasks of radar systems. Current joint
detection tracking methods, which focus on dynamically adjusting detection
thresholds from tracking results, still present challenges in fully utilizing
the potential of radar signals. These are mainly reflected in the limited
capacity of the constant false-alarm rate model to accurately represent
information, the insufficient depiction of complex scenes, and the limited
information acquired by the tracker. We introduce the Integrated Detection and
Tracking based on radar feature (InDT) method, which comprises a network
architecture for radar signal detection and a tracker that leverages detection
assistance. The InDT detector extracts feature information from each
Range-Doppler (RD) matrix and then returns the target position through the
feature enhancement module and the detection head. The InDT tracker adaptively
updates the measurement noise covariance of the Kalman filter based on
detection confidence. The similarity of target RD features is measured by
cosine distance, which enhances the data association process by combining
location and feature information. Finally, the efficacy of the proposed method
was validated through testing on both simulated data and publicly available
datasets.

</details>


### [18] [Towards In-Air Ultrasonic QR Codes: Deep Learning for Classification of Passive Reflector Constellations](https://arxiv.org/abs/2509.06615)
*Wouter Jansen,Jan Steckel*

Main category: eess.SP

TL;DR: 本文提出使用多标签CNN从单次3D声纳测量中同时识别多个紧密排列的反射器，通过反射器星座作为编码标签来增加信息容量，验证了复杂声学模式解码的可行性。


<details>
  <summary>Details</summary>
Motivation: 在视觉传感器失效的环境中，空中声纳为自主系统提供了可靠替代方案。虽然先前研究已成功分类单个声学地标，但需要增加信息容量。

Method: 采用多标签卷积神经网络(CNN)同时识别多个紧密排列的反射器，并研究使用自适应波束成形和零陷技术来隔离单个反射器进行单标签分类。

Result: 在小数据集上的初步研究证实了该方法的可行性，验证了解码复杂声学模式的能力。

Conclusion: 为开发具有显著增加信息熵的声学地标系统及其准确鲁棒检测分类提供了关键见解和未来方向。

Abstract: In environments where visual sensors falter, in-air sonar provides a reliable
alternative for autonomous systems. While previous research has successfully
classified individual acoustic landmarks, this paper takes a step towards
increasing information capacity by introducing reflector constellations as
encoded tags. Our primary contribution is a multi-label Convolutional Neural
Network (CNN) designed to simultaneously identify multiple, closely spaced
reflectors from a single in-air 3D sonar measurement. Our initial findings on a
small dataset confirm the feasibility of this approach, validating the ability
to decode these complex acoustic patterns. Secondly, we investigated using
adaptive beamforming with null-steering to isolate individual reflectors for
single-label classification. Finally, we discuss the experimental results and
limitations, offering key insights and future directions for developing
acoustic landmark systems with significantly increased information entropy and
their accurate and robust detection and classification.

</details>


### [19] [Near-Threshold Voltage Massive MIMO Computing](https://arxiv.org/abs/2509.06651)
*Mikael Rinkinen,Mehdi Safarpour,Shahriar Shahabuddin,Olli Silven,Lauri Koskinen*

Main category: eess.SP

TL;DR: 通过算法基础故际耐受技术(ABFT)与近阈值计算(NTC)结合，在大规模MIMO系统中实现了36%的功耗节省，仅付3%计算开销


<details>
  <summary>Details</summary>
Motivation: 解决大规模MIMO系统高功耗问题，应对近阈值计算(NTC)导致的可靠性挑战，提供轻量级错误检测方案

Method: 修改矩阵算术牛顿迭代MIMO算法，无缝集成ABFT技术，通过检查最终结果来检测计算错误

Result: 在可重构硬件平台实现MIMO加速器，大规模问题下实现36%功耗节省，平均3%计算开销

Conclusion: ABFT与近阈值运行结合，为能源效率高、耐用性强的大规模MIMO处理器提供了可行路径

Abstract: Massive MIMO systems have the potential to significantly enhance spectral
efficiency, yet their widespread integration is hindered by the high power
consumption of the underlying computations. This paper explores the
applicability and effectiveness of Algorithm-Based Fault Tolerance (ABFT) for
massive MIMO signal processing to tackle the reliability challenge of Near
Threshold Computing (NTC). We propose modifying matrix arithmetic Newton
iteration MIMO algorithm to seamlessly integrate ABFT to detect any
computational errors by inspecting the final result. The overhead from ABFT
depends largely on the matrix dimensions, which in this context are dictated by
the number of user equipments involved in the computation. NTC is a promising
strategy for reducing the energy consumption in digital circuits by operating
transistors at extremely reduced voltages. However, NTC is highly susceptible
to variations in Process, Voltage, and Temperature (PVT) which can lead to
increased error rates in computations. Traditional techniques for enabling NTC,
such as dynamic voltage and frequency scaling guided by circuit level timing
error detection methods, introduce considerable hardware complexity and are
difficult to implement at high clock frequencies. In this context ABFT has
emerged as a lightweight error detection method tailored for matrix operations
without requiring any modifications on circuit-level and can be implemented
purely in software.A MIMO accelerator was implemented on a reconfigurable
hardware platform. Experimental results demonstrate that for sufficiently large
problem sizes, the proposed method achieves a 36% power saving compared to
baseline, with only an average of 3% computational overhead, at default clock
frequency. These results indicate that combining ABFT with near-threshold
operation provides a viable path toward energy-efficient and robust massive
MIMO processors.

</details>


### [20] [SE and EE Tradeoff in Active STAR-RIS Assisted Systems With Hardware Impairments](https://arxiv.org/abs/2509.06662)
*Ao Huang,Xidong Mu,Li Guo,Guangyu Zhu*

Main category: eess.SP

TL;DR: 本文研究在存在收发器硬件损伤的实际场景下，主动式同时透射反射可重构智能表面(STAR-RIS)辅助通信系统的资源效率最大化问题，通过联合优化基站波束赋形和主动STAR-RIS波束赋形，实现频谱效率和能量效率的最优权衡。


<details>
  <summary>Details</summary>
Motivation: 在存在实际硬件损伤的情况下，如何通过主动STAR-RIS技术实现通信系统频谱效率和能量效率的最优权衡，这是一个具有挑战性的资源优化问题。

Method: 采用二次变换方法简化分数目标函数，然后开发基于交替优化的算法来迭代更新基站和STAR-RIS的波束赋形系数。

Result: 仿真结果表明，在存在硬件损伤的情况下，所提出的方案性能优于其他基线方案，并分析了不同发射功率预算下可实现的SE-EE区域变化。

Conclusion: 该方法能够有效解决硬件损伤下的资源效率优化问题，为主动STAR-RIS辅助通信系统的实际应用提供了有效的解决方案。

Abstract: This paper investigates the problem of resource efficiency maximization in an
active simultaneously transmitting and reflecting reconfigurable intelligent
surface (STAR-RIS) assisted communication system under practical transceiver
hardware impairments (HWIs). We aim to obtain an optimal tradeoff between
system spectral efficiency (SE) and energy efficiency (EE), by jointly
optimizing the base station (BS) transmit beamforming and the active STAR-RIS
beamforming. To tackle the challenges in the fractional objective function, we
begin by applying the quadratic transformation method to simplify it into a
manageable form. An alternating optimization-based algorithm is then developed
to iteratively update the BS and STAR-RIS beamforming coefficients. Simulation
results demonstrate that the proposed scheme performs better than other
baseline schemes in the presence of HWIs. Moreover, the variation of the
achievable SE-EE region with different transmit power budgets is analyzed.

</details>


### [21] [ISAC Imaging by Channel State Information using Ray Tracing for Next Generation 6G](https://arxiv.org/abs/2509.06672)
*Ahmad Bazzi,Mingjun Ying,Ojas Kanhere,Theodore S. Rappaport,Marwa Chafii*

Main category: eess.SP

TL;DR: 基于通信通道状态信息的多跳反射ISAC成像框架，通过两段反射点优化算法实现精确的几何重建


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)是6G的核心技术，需要开发能够利用多路径成分进行环境映射的实时成像方法

Method: 使用港口式NYURay光线追踪器获取通道状态信息，通过两段反射点优化算法独立估计发射端和接收端到等效反射点的路径长度

Result: 实验结果验证了该框架能够准确重建物体表面、边缘和曲线特征，生成密集的三维点云

Conclusion: 该研究首次在6.75GHz频段通过无线电光线追踪实现了多跳ISAC成像，为6G集成感知通信提供了重要技术基础

Abstract: Integrated sensing and communications (ISAC) is emerging as a cornerstone
technology for sixth generation (6G) wireless systems, unifying connectivity
and environmental mapping through shared hardware, spectrum, and waveforms. The
following paper presents an ISAC imaging framework utilizing channel state
information (CSI) per-path components, transmitter (TX) positions, and receiver
(RX) positions obtained from the calibrated NYURay ray tracer at 6.75 GHz in
the upper mid-band. Our work shows how each resolvable multipath component can
be extracted from CSI estimation and cast into an equivalent three-dimensional
reflection point by fusing its angle and delay information, which is useful and
challenging for multi-bounce reflections. The primary contribution of the paper
is the two-segment reflection point optimization algorithm, which independently
estimates the path lengths from the TX position and RX position to an
equivalent reflection point (ERP) on the object surface, thus enabling precise
geometric reconstruction. Subsequently, we aggregate the ERPs derived from
multiple pairs of TX and RX positions, generating dense three dimensional point
clouds representing the objects in the channel. Experimental results validate
that the proposed ISAC imaging framework accurately reconstructs object
surfaces, edges, and curved features. To the best of our knowledge, this paper
provides the first demonstration of multi bounce ISAC imaging using wireless
ray tracing at 6.75 GHz.

</details>


### [22] [RadHARSimulator V1: Model-Based FMCW Radar Human Activity Recognition Simulator](https://arxiv.org/abs/2509.06751)
*Weicheng Gao*

Main category: eess.SP

TL;DR: 开发了一个基于模型的FMCW雷达人体活动识别模拟器，通过13散射点运动学模型模拟12种活动，生成高保真微多普勒特征，为雷达HAR算法提供验证工具


<details>
  <summary>Details</summary>
Motivation: 雷达人体活动识别需要多样化的高保真数据集，但实际数据采集困难，需要开发模拟器来克服这一瓶颈

Method: 使用13散射点运动学模型模拟12种活动，采用FMCW雷达回波模型，包含动态RCS、穿墙传播和校准噪声，通过MTI、多普勒补偿和Savitzky-Golay去噪处理数据，生成RTM和DTM图

Result: 模拟器成功生成了高保真且具有区分度的微多普勒特征，为雷达HAR算法设计和验证提供了宝贵工具

Conclusion: 该模拟器有效解决了雷达HAR数据集获取难题，提供了可靠的算法开发和验证平台，代码已在GitHub开源

Abstract: Radar-based human activity recognition (HAR) is a pivotal research area for
applications requiring non-invasive monitoring. However, the acquisition of
diverse and high-fidelity radar datasets for robust algorithm development
remains a significant challenge. To overcome this bottleneck, a model-based
frequency-modulated continuous wave (FMCW) radar HAR simulator is developed.
The simulator integrates an anthropometrically scaled $13$-scatterer kinematic
model to simulate $12$ distinct activities. The FMCW radar echo model is
employed, which incorporates dynamic radar cross-section (RCS), free-space or
through-the-wall propagation, and a calibrated noise floor to ensure signal
fidelity. The simulated raw data is then processed through a complete pipeline,
including moving target indication (MTI), bulk Doppler compensation, and
Savitzky-Golay denoising, culminating in the generation of high-resolution
range-time map (RTM) and Doppler-time maps (DTMs) via both short-time Fourier
transform (STFT) and Fourier synchrosqueezed transform (FSST). Finally, a novel
neural network method is proposed to validate the effectiveness of the radar
HAR. Numerical experiments demonstrate that the simulator successfully
generates high-fidelity and distinct micro-Doppler signature, which provides a
valuable tool for radar HAR algorithm design and validation. The installer of
this simulator is released at:
\href{https://github.com/JoeyBGOfficial/RadHARSimulatorV1-Model-Based-FMCW-Radar-Human-Activity-Recognition-Simulator}{Github/JoeyBGOfficial/RadHARSimulatorV1}.

</details>


### [23] [Green Learning for STAR-RIS mmWave Systems with Implicit CSI](https://arxiv.org/abs/2509.06820)
*Yu-Hsiang Huang,Po-Heng Chou,Wan-Jen Huang,Walid Saad,C. -C. Jay Kuo*

Main category: eess.SP

TL;DR: 基于绿色学习的STAR-RIS助力毫米波MIMO广播系统预编码框架，无需显式通道估计，较优化方法节省计算开销近4个数量级


<details>
  <summary>Details</summary>
Motivation: 面向6G网络环境可持续性需求，通过广播传输架构提高频谱效率、减少重复传输和功耗

Method: 结合子空间近似与偏置调整(Saab)、相关特征测试(RFT)特征选择和XGBoost决策学习，直接从收到的上行预定信号预测STAR-RIS系数和发射预编码器

Result: 达到与BCD和DL模型相竞争的频谱效率，同时将浮点运算次数(FLOPs)减少超过4个数量级

Conclusion: 该GL方法适合在能源和硬件受限的广播场景中实时部署

Abstract: In this paper, a green learning (GL)-based precoding framework is proposed
for simultaneously transmitting and reflecting reconfigurable intelligent
surface (STAR-RIS)-aided millimeter-wave (mmWave) MIMO broadcasting systems.
Motivated by the growing emphasis on environmental sustainability in future 6G
networks, this work adopts a broadcasting transmission architecture for
scenarios where multiple users share identical information, improving spectral
efficiency and reducing redundant transmissions and power consumption.
Different from conventional optimization methods, such as block coordinate
descent (BCD) that require perfect channel state information (CSI) and
iterative computation, the proposed GL framework operates directly on received
uplink pilot signals without explicit CSI estimation. Unlike deep learning (DL)
approaches that require CSI-based labels for training, the proposed GL approach
also avoids deep neural networks and backpropagation, leading to a more
lightweight design. Although the proposed GL framework is trained with
supervision generated by BCD under full CSI, inference is performed in a fully
CSI-free manner. The proposed GL integrates subspace approximation with
adjusted bias (Saab), relevant feature test (RFT)-based supervised feature
selection, and eXtreme gradient boosting (XGBoost)-based decision learning to
jointly predict the STAR-RIS coefficients and transmit precoder. Simulation
results show that the proposed GL approach achieves competitive spectral
efficiency compared to BCD and DL-based models, while reducing floating-point
operations (FLOPs) by over four orders of magnitude. These advantages make the
proposed GL approach highly suitable for real-time deployment in energy- and
hardware-constrained broadcasting scenarios.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [24] [Graph Connectionist Temporal Classification for Phoneme Recognition](https://arxiv.org/abs/2509.05399)
*Henry Grafé,Hugo Van hamme*

Main category: eess.AS

TL;DR: 通过Graph Temporal Classification (GTC)方法在自动音素识别中整合多重发音变体，比标准CTC损失更有效地利用G2P系统产生的伪音素标注


<details>
  <summary>Details</summary>
Motivation: 标准CTC损失无法处理G2P系统产生的多重可能发音，导致训练过程中不能利用语音变体信息

Method: 将Graph Temporal Classification (GTC)适配到APR设置，允许模型从替代音素序列图中进行训练，考虑每个单词的多种发音为合法监督

Result: 在英语和荷兰数据集上实验显示，与基准CTC相比，通过GTC整合多重发音能持续改喂音素错误率

Conclusion: 将发音变体整合到损失函数中是从噪声G2P监督训练APR系统的有前景策略

Abstract: Automatic Phoneme Recognition (APR) systems are often trained using pseudo
phoneme-level annotations generated from text through Grapheme-to-Phoneme (G2P)
systems. These G2P systems frequently output multiple possible pronunciations
per word, but the standard Connectionist Temporal Classification (CTC) loss
cannot account for such ambiguity during training. In this work, we adapt Graph
Temporal Classification (GTC) to the APR setting. GTC enables training from a
graph of alternative phoneme sequences, allowing the model to consider multiple
pronunciations per word as valid supervision. Our experiments on English and
Dutch data sets show that incorporating multiple pronunciations per word into
the training loss consistently improves phoneme error rates compared to a
baseline trained with CTC. These results suggest that integrating pronunciation
variation into the loss function is a promising strategy for training APR
systems from noisy G2P-based supervision.

</details>


### [25] [On the Contribution of Lexical Features to Speech Emotion Recognition](https://arxiv.org/abs/2509.05634)
*David Combei*

Main category: eess.AS

TL;DR: 这篇论文研究了词汇内容在语音情感识别中的作用，发现仅使用文本特征就能达到与声学模型相当或更好的性能。


<details>
  <summary>Details</summary>
Motivation: 彼比传统观点，识别词汇内容在语音情感识别中的潜在价值，而不仅仅依赖语调等资语言索引。

Method: 使用自监督学习的语音和文本表征，进行层次化的变换器编码器研究，并评估音频去噪的影响。

Result: 在MELD数据集上，仅使用词汇方法获得了51.5%的加权F1分数，超过了参数更多的仅声学模型的49.3%。

Conclusion: 词汇内容在语音情感识别中具有重要作用，在某些情况下甚至能够达到更好的性能，这对传统依赖语调等资语言索引的方法构成了挑战。

Abstract: Although paralinguistic cues are often considered the primary drivers of
speech emotion recognition (SER), we investigate the role of lexical content
extracted from speech and show that it can achieve competitive and in some
cases higher performance compared to acoustic models. On the MELD dataset, our
lexical-based approach obtains a weighted F1-score (WF1) of 51.5%, compared to
49.3% for an acoustic-only pipeline with a larger parameter count. Furthermore,
we analyze different self-supervised (SSL) speech and text representations,
conduct a layer-wise study of transformer-based encoders, and evaluate the
effect of audio denoising.

</details>


### [26] [Time-domain sound field estimation using kernel ridge regression](https://arxiv.org/abs/2509.05720)
*Jesper Brunnström,Martin Bo Møller,Jan Østergaard,Shoichi Koyama,Toon van Waterschoot,Marc Moonen*

Main category: eess.AS

TL;DR: 本文提出了一种基于核岭回归的时域声场估计方法，将传统单频声场估计扩展到离散时域，能够利用时域先验信息提高估计性能。


<details>
  <summary>Details</summary>
Motivation: 传统的核岭回归声场估计方法仅限于单频声场，限制了可用数据类型和先验知识的利用。需要开发能够处理时域声场并利用时域特性的方法。

Method: 将核岭回归方法推广到离散时域声场估计，提出时域数据加权方法，结合方向性加权，利用房间脉冲响应的时空特性先验知识。

Result: 提出的方法能够以闭式解计算时域声场估计，保证物理可实现性，并通过时域数据加权显著提高估计性能。仿真和实测数据验证了方法的有效性。

Conclusion: 该方法扩展了核岭回归在声场估计中的应用范围，能够同时利用时空特性先验知识，为解决更广泛的时域声场估计问题提供了理论框架。

Abstract: Sound field estimation methods based on kernel ridge regression have proven
effective, allowing for strict enforcement of physical properties, in addition
to the inclusion of prior knowledge such as directionality of the sound field.
These methods have been formulated for single-frequency sound fields,
restricting the types of data and prior knowledge that can be used. In this
paper, the kernel ridge regression approach is generalized to consider
discrete-time sound fields. The proposed method provides time-domain sound
field estimates that can be computed in closed form, are guaranteed to be
physically realizable, and for which time-domain properties of the sound fields
can be exploited to improve estimation performance. Exploiting prior
information on the time-domain behaviour of room impulse responses, the
estimation performance of the proposed method is shown to be improved using a
time-domain data weighting, demonstrating the usefulness of the proposed
approach. It is further shown using both simulated and real data that the
time-domain data weighting can be combined with a directional weighting,
exploiting prior knowledge of both spatial and temporal properties of the room
impulse responses. The theoretical framework of the proposed method enables
solving a broader class of sound field estimation problems using kernel ridge
regression where it would be required to consider the time-domain response
rather than the frequency-domain response of each frequency separately.

</details>


### [27] [From perception to production: how acoustic invariance facilitates articulatory learning in a self-supervised vocal imitation model](https://arxiv.org/abs/2509.05849)
*Marvin Lavechin,Thomas Hueber*

Main category: eess.AS

TL;DR: 该研究提出了一个通过自监督学习解决声学-发音映射问题的计算模型，发现预训练的wav2vec 2.0模型的中间层表征在发音学习中表现最佳，显著优于传统MFCC特征。


<details>
  <summary>Details</summary>
Motivation: 解决婴儿如何在没有明确指导的情况下，将高度变化的声学输入映射到相应发音动作这一难题，为理解人类语音习得机制提供计算证据。

Method: 构建包含特征提取器、逆模型和合成器的计算模型，在单人和多人说话者设置下进行实验，比较wav2vec 2.0模型中间层表征与MFCC特征的性能。

Result: wav2vec 2.0中间层表征在发音学习中表现最优，能够学习与人类模式相关的发音轨迹，区分发音部位，并产生可理解的语音。这些表征平衡了音位区分性和说话者不变性。

Conclusion: 研究结果为发展理论提供了计算证据，表明音位类别的感知学习指导发音发展，揭示了婴儿如何克服复杂的映射问题获得语音产生能力。

Abstract: Human infants face a formidable challenge in speech acquisition: mapping
extremely variable acoustic inputs into appropriate articulatory movements
without explicit instruction. We present a computational model that addresses
the acoustic-to-articulatory mapping problem through self-supervised learning.
Our model comprises a feature extractor that transforms speech into latent
representations, an inverse model that maps these representations to
articulatory parameters, and a synthesizer that generates speech outputs.
Experiments conducted in both single- and multi-speaker settings reveal that
intermediate layers of a pre-trained wav2vec 2.0 model provide optimal
representations for articulatory learning, significantly outperforming MFCC
features. These representations enable our model to learn articulatory
trajectories that correlate with human patterns, discriminate between places of
articulation, and produce intelligible speech. Critical to successful
articulatory learning are representations that balance phonetic
discriminability with speaker invariance -- precisely the characteristics of
self-supervised representation learning models. Our findings provide
computational evidence consistent with developmental theories proposing that
perceptual learning of phonetic categories guides articulatory development,
offering insights into how infants might acquire speech production capabilities
despite the complex mapping problem they face.

</details>


### [28] [Beamforming-LLM: What, Where and When Did I Miss?](https://arxiv.org/abs/2509.06221)
*Vishal Choudhari*

Main category: eess.AS

TL;DR: Beamforming-LLM是一个结合空间音频捕获和检索增强生成技术的系统，能够通过自然语言查询帮助用户回忆错过的多人对话内容。


<details>
  <summary>Details</summary>
Motivation: 解决多说话人环境中用户可能错过重要对话内容的问题，为智能听觉记忆系统奠定基础，在辅助技术、会议摘要和空间计算等领域有广泛应用。

Method: 使用麦克风阵列进行空间音频捕获，通过波束成形分离定向音频流，用Whisper进行转录，使用句子编码器嵌入向量数据库，通过RAG技术检索相关片段，用GPT-4o-mini进行摘要生成。

Result: 开发出用户友好的界面，提供对比摘要、空间上下文和时间戳音频回放功能。

Conclusion: 该系统为智能听觉记忆系统提供了技术基础，在多个应用领域具有重要价值。

Abstract: We present Beamforming-LLM, a system that enables users to semantically
recall conversations they may have missed in multi-speaker environments. The
system combines spatial audio capture using a microphone array with
retrieval-augmented generation (RAG) to support natural language queries such
as, "What did I miss when I was following the conversation on dogs?"
Directional audio streams are separated using beamforming, transcribed with
Whisper, and embedded into a vector database using sentence encoders. Upon
receiving a user query, semantically relevant segments are retrieved,
temporally aligned with non-attended segments, and summarized using a
lightweight large language model (GPT-4o-mini). The result is a user-friendly
interface that provides contrastive summaries, spatial context, and timestamped
audio playback. This work lays the foundation for intelligent auditory memory
systems and has broad applications in assistive technology, meeting
summarization, and context-aware personal spatial computing.

</details>


### [29] [Speaker Privacy and Security in the Big Data Era: Protection and Defense against Deepfake](https://arxiv.org/abs/2509.06361)
*Liping Chen,Kong Aik Lee,Zhen-Hua Ling,Xin Wang,Rohan Kumar Das,Tomoki Toda,Haizhou Li*

Main category: eess.AS

TL;DR: 这篇论文简要介绍了防范深度假造语音安全风险的三种技术：声音匿名化、深度假造检测和水印技术，分析了它们的方法、进展和挑战。


<details>
  <summary>Details</summary>
Motivation: 随着大数据时代个性化语音生成技术的进步，深度假造语音的滥用带来了全球性安全风险和社会成本，需要有效的防范技术来应对这些威胁。

Method: 论文通过结合声音匿名化技术（防止声音属性提取）、深度假造检测技术和水印技术（防止深度假造语音滥用）三种方法来综合分析防范深度假造语音安全风险。

Result: 论文对这三种技术进行了简要的概述分析，描述了各自的方法论、技术进展和存在的挑战，为进一步的深入研究奠定了基础。

Conclusion: 这篇论文为防范深度假造语音安全风险提供了一个简洁的技术概览，并告知将在近期发布更全面的讨论版本，以深入探讨这一重要安全领域的技术发展。

Abstract: In the era of big data, remarkable advancements have been achieved in
personalized speech generation techniques that utilize speaker attributes,
including voice and speaking style, to generate deepfake speech. This has also
amplified global security risks from deepfake speech misuse, resulting in
considerable societal costs worldwide. To address the security threats posed by
deepfake speech, techniques have been developed focusing on both the protection
of voice attributes and the defense against deepfake speech. Among them, the
voice anonymization technique has been developed to protect voice attributes
from extraction for deepfake generation, while deepfake detection and
watermarking have been utilized to defend against the misuse of deepfake
speech. This paper provides a short and concise overview of the three
techniques, describing the methodologies, advancements, and challenges. A
comprehensive version, offering additional discussions, will be published in
the near future.

</details>


### [30] [Integrating Spatial and Semantic Embeddings for Stereo Sound Event Localization in Videos](https://arxiv.org/abs/2509.06598)
*Davide Berghi,Philip J. B. Jackson*

Main category: eess.AS

TL;DR: 通过整合CLAP音频和OWL-ViT视觉语言对齐模型，提出交叉模态Conformer方案来解决立体声音事件定位检测任务，在DCASE2025挑战赛中获得第二名


<details>
  <summary>Details</summary>
Motivation: 传统SELD方法依赖多通道输入且缺乏语义信息，无法利用大规模预训练。需要通过语言对齐模型提升语义理解能力

Method: 整合CLAP音频和OWL-ViT视觉语言对齐模型，设计交叉模态Conformer模块进行多模态融合，使用大规模合成数据集预训练

Result: 在DCASE2025 Task3挑战赛中获得第二名，验证了语言对齐模型在立体声音事件检测中的有效性

Conclusion: 语言对齐模型能够显著提升SELD性能，交叉模态Conformer是有效的多模态融合方案，大规模预训练和数据增幅对性能有重要影响

Abstract: In this study, we address the multimodal task of stereo sound event
localization and detection with source distance estimation (3D SELD) in regular
video content. 3D SELD is a complex task that combines temporal event
classification with spatial localization, requiring reasoning across spatial,
temporal, and semantic dimensions. The last is arguably the most challenging to
model. Traditional SELD approaches typically rely on multichannel input,
limiting their capacity to benefit from large-scale pre-training due to data
constraints. To overcome this, we enhance a standard SELD architecture with
semantic information by integrating pre-trained, contrastive language-aligned
models: CLAP for audio and OWL-ViT for visual inputs. These embeddings are
incorporated into a modified Conformer module tailored for multimodal fusion,
which we refer to as the Cross-Modal Conformer. We perform an ablation study on
the development set of the DCASE2025 Task3 Stereo SELD Dataset to assess the
individual contributions of the language-aligned models and benchmark against
the DCASE Task 3 baseline systems. Additionally, we detail the curation process
of large synthetic audio and audio-visual datasets used for model pre-training.
These datasets were further expanded through left-right channel swapping
augmentation. Our approach, combining extensive pre-training, model ensembling,
and visual post-processing, achieved second rank in the DCASE 2025 Challenge
Task 3 (Track B), underscoring the effectiveness of our method. Future work
will explore the modality-specific contributions and architectural refinements.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [31] [TSPC: A Two-Stage Phoneme-Centric Architecture for code-switching Vietnamese-English Speech Recognition](https://arxiv.org/abs/2509.05983)
*Minh N. H. Nguyen,Anh Nguyen Tran,Dung Truong Dinh,Nam Van Vo*

Main category: cs.SD

TL;DR: 提出了一种用于越南语-英语代码转换语音识别的两阶段音素中心模型(TSPC)，通过扩展越南语音素集作为中间表示，显著降低了词错误率至20.8%，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 代码转换对通用ASR系统构成重大挑战，现有方法难以捕捉代码转换中的细微音位变化，特别是越南语-英语这种具有不同音系特征和相似声音识别歧义的语言对。

Method: 采用两阶段音素中心架构，基于扩展的越南语音素集作为中间表示来进行混合语言建模，支持音素适应和语言转换。

Result: TSPC在越南语-英语代码转换ASR中 consistently优于现有基线(包括PhoWhisper-base)，词错误率显著降低至20.8%，且训练资源需求更少。

Conclusion: 基于音素的两阶段架构能够有效提升复杂代码转换场景下的ASR性能，特别是在越南语-英语这种具有挑战性的语言对中表现出色。

Abstract: Code-switching (CS) presents a significant challenge for general Auto-Speech
Recognition (ASR) systems. Existing methods often fail to capture the subtle
phonological shifts inherent in CS scenarios. The challenge is particularly
difficult for language pairs like Vietnamese and English, where both distinct
phonological features and the ambiguity arising from similar sound recognition
are present. In this paper, we propose a novel architecture for
Vietnamese-English CS ASR, a Two-Stage Phoneme-Centric model (TSPC). The TSPC
employs a phoneme-centric approach, built upon an extended Vietnamese phoneme
set as an intermediate representation to facilitate mixed-lingual modeling.
Experimental results demonstrate that TSPC consistently outperforms existing
baselines, including PhoWhisper-base, in Vietnamese-English CS ASR, achieving a
significantly lower word error rate of 20.8\% with reduced training resources.
Furthermore, the phonetic-based two-stage architecture enables phoneme
adaptation and language conversion to enhance ASR performance in complex CS
Vietnamese-English ASR scenarios.

</details>


### [32] [Xi+: Uncertainty Supervision for Robust Speaker Embedding](https://arxiv.org/abs/2509.05993)
*Junjie Li,Kong Aik Lee,Duc-Tuan Truong,Tianchi Liu,Man-Wai Mak*

Main category: cs.SD

TL;DR: 本文提出xi+架构，通过引入时间注意力模块和随机方差损失函数，改进了xi-vector模型在说话人识别中的不确定性估计，在两个数据集上分别实现了约10%和11%的性能提升。


<details>
  <summary>Details</summary>
Motivation: xi-vector模型通过不确定性估计为不同帧分配权重，但其不确定性估计仅通过分类损失隐式训练，未考虑帧间时间关系，导致监督效果不佳。

Method: 提出xi+架构：1）加入时间注意力模块，以上下文感知方式捕捉帧级不确定性；2）引入随机方差损失函数，显式监督不确定性学习。

Result: 在VoxCeleb1-O数据集上性能提升约10%，在NIST SRE 2024评估集上性能提升约11%。

Conclusion: xi+架构通过显式的时间注意力机制和损失函数设计，有效改进了说话人识别系统的不确定性估计，显著提升了识别性能。

Abstract: There are various factors that can influence the performance of speaker
recognition systems, such as emotion, language and other speaker-related or
context-related variations. Since individual speech frames do not contribute
equally to the utterance-level representation, it is essential to estimate the
importance or reliability of each frame. The xi-vector model addresses this by
assigning different weights to frames based on uncertainty estimation. However,
its uncertainty estimation model is implicitly trained through classification
loss alone and does not consider the temporal relationships between frames,
which may lead to suboptimal supervision. In this paper, we propose an improved
architecture, xi+. Compared to xi-vector, xi+ incorporates a temporal attention
module to capture frame-level uncertainty in a context-aware manner. In
addition, we introduce a novel loss function, Stochastic Variance Loss, which
explicitly supervises the learning of uncertainty. Results demonstrate
consistent performance improvements of about 10\% on the VoxCeleb1-O set and
11\% on the NIST SRE 2024 evaluation set.

</details>


### [33] [DreamAudio: Customized Text-to-Audio Generation with Diffusion Models](https://arxiv.org/abs/2509.06027)
*Yi Yuan,Xubo Liu,Haohe Liu,Xiyuan Kang,Zhuo Chen,Yuxuan Wang,Mark D. Plumbley,Wenwu Wang*

Main category: cs.SD

TL;DR: DreamAudio是一个定制化文本到音频生成框架，能够从用户提供的参考音频中学习特定音频事件的特征，生成包含这些个性化事件的新音频样本，同时保持与文本提示的良好对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到音频生成模型主要关注语义对齐，但缺乏对特定声音细粒度声学特征的精确控制，用户难以生成包含特定音频内容的定制化音频片段。

Method: 提出一个新的定制化文本到音频生成框架，通过用户提供的参考音频样本识别听觉信息，能够学习个性化音频事件特征并生成包含这些特定事件的新音频。开发了两种类型的数据集用于训练和测试定制化系统。

Result: 实验表明DreamAudio生成的音频样本与定制化音频特征高度一致，且与输入文本提示对齐良好。在通用文本到音频任务中也表现出可比的性能。

Conclusion: DreamAudio成功解决了定制化音频生成的需求，提供了一个包含真实世界CTTA案例音频事件的人类参与数据集作为定制化生成任务的基准。

Abstract: With the development of large-scale diffusion-based and
language-modeling-based generative models, impressive progress has been
achieved in text-to-audio generation. Despite producing high-quality outputs,
existing text-to-audio models mainly aim to generate semantically aligned sound
and fall short on precisely controlling fine-grained acoustic characteristics
of specific sounds. As a result, users that need specific sound content may
find it challenging to generate the desired audio clips. In this paper, we
present DreamAudio for customized text-to-audio generation (CTTA).
Specifically, we introduce a new framework that is designed to enable the model
to identify auditory information from user-provided reference concepts for
audio generation. Given a few reference audio samples containing personalized
audio events, our system can generate new audio samples that include these
specific events. In addition, two types of datasets are developed for training
and testing the customized systems. The experiments show that the proposed
model, DreamAudio, generates audio samples that are highly consistent with the
customized audio features and aligned well with the input text prompts.
Furthermore, DreamAudio offers comparable performance in general text-to-audio
tasks. We also provide a human-involved dataset containing audio events from
real-world CTTA cases as the benchmark for customized generation tasks.

</details>


### [34] [MeanFlow-Accelerated Multimodal Video-to-Audio Synthesis via One-Step Generation](https://arxiv.org/abs/2509.06389)
*Xiaoran Yang,Jianxuan Yang,Xinyue Guo,Haoyu Wang,Ningning Pan,Gongping Huang*

Main category: cs.SD

TL;DR: 提出MeanFlow加速模型，通过平均速度表征流场实现一步生成，显著提升视频到音频合成的推理速度，同时保持音频质量、语义对齐和时间同步。


<details>
  <summary>Details</summary>
Motivation: 现有音频合成方法在合成质量和推理效率之间存在固有权衡，特别是基于流匹配的模型需要迭代采样过程导致推理速度慢。

Method: 使用平均速度表征流场实现一步生成，采用标量重缩放机制平衡条件和非条件预测以减轻CFG引起的失真，支持多模态条件联合训练。

Result: 实验结果表明，MeanFlow显著提高了推理速度，在VTA和TTA合成任务上均未损害感知质量。

Conclusion: MeanFlow模型有效解决了音频合成中的效率瓶颈，实现了高质量的一步生成，为多模态音频合成提供了高效解决方案。

Abstract: A key challenge in synthesizing audios from silent videos is the inherent
trade-off between synthesis quality and inference efficiency in existing
methods. For instance, flow matching based models rely on modeling
instantaneous velocity, inherently require an iterative sampling process,
leading to slow inference speeds. To address this efficiency bottleneck, we
introduce a MeanFlow-accelerated model that characterizes flow fields using
average velocity, enabling one-step generation and thereby significantly
accelerating multimodal video-to-audio (VTA) synthesis while preserving audio
quality, semantic alignment, and temporal synchronization. Furthermore, a
scalar rescaling mechanism is employed to balance conditional and unconditional
predictions when classifier-free guidance (CFG) is applied, effectively
mitigating CFG-induced distortions in one step generation. Since the audio
synthesis network is jointly trained with multimodal conditions, we further
evaluate it on text-to-audio (TTA) synthesis task. Experimental results
demonstrate that incorporating MeanFlow into the network significantly improves
inference speed without compromising perceptual quality on both VTA and TTA
synthesis tasks.

</details>


### [35] [FireRedChat: A Pluggable, Full-Duplex Voice Interaction System with Cascaded and Semi-Cascaded Implementations](https://arxiv.org/abs/2509.06502)
*Junjie Chen,Yao Hu,Junjie Li,Kangyue Li,Kun Liu,Wenpeng Li,Xu Li,Ziyuan Li,Feiyu Shen,Xu Tang,Manzhen Wei,Yichen Wu,Fenglong Xie,Kaituo Xu,Kun Xie*

Main category: cs.SD

TL;DR: 一个完整的全双工语音交互系统，通过流式个性化VAD和语义转折检测提高了拖入控制精度，并支持异构半双工管道升级到全双工


<details>
  <summary>Details</summary>
Motivation: 现有全双工语音交互解决方案或为结构复杂难以控制的端到端系统，或为依赖非开源组件的模块化管道，限制了整体优化

Method: 构建包含转变控制器、交互模块和对话管理器的完整系统；控制器集成流式个性化VAD和语义转折检测；支持异构半双工管道升级

Result: 实验显示减少了假拖入中断，提高了语义结束检测准确性，延迟接近工业级系统水平，实现了稳健、自然的实时全双工交互

Conclusion: 该系统提供了一个完整可用的全双工语音交互解决方案，通过开源内部模型实现了更好的控制精度和性能，为生动化助手和客服系统提供了基础

Abstract: Full-duplex voice interaction allows users and agents to speak simultaneously
with controllable barge-in, enabling lifelike assistants and customer service.
Existing solutions are either end-to-end, difficult to design and hard to
control, or modular pipelines governed by turn-taking controllers that ease
upgrades and per-module optimization; however, prior modular frameworks depend
on non-open components and external providers, limiting holistic optimization.
In this work, we present a complete, practical full-duplex voice interaction
system comprising a turn-taking controller, an interaction module, and a
dialogue manager. The controller integrates streaming personalized VAD (pVAD)
to suppress false barge-ins from noise and non-primary speakers, precisely
timestamp primary-speaker segments, and explicitly enable primary-speaker
barge-ins; a semantic end-of-turn detector improves stop decisions. It upgrades
heterogeneous half-duplex pipelines, cascaded, semi-cascaded, and
speech-to-speech, to full duplex. Using internal models, we implement cascaded
and semi-cascaded variants; the semi-cascaded one captures emotional and
paralinguistic cues, yields more coherent responses, lowers latency and error
propagation, and improves robustness. A dialogue manager extends capabilities
via tool invocation and context management. We also propose three system-level
metrics, barge-in, end-of-turn detection accuracy, and end-to-end latency, to
assess naturalness, control accuracy, and efficiency. Experiments show fewer
false interruptions, more accurate semantic ends, and lower latency approaching
industrial systems, enabling robust, natural, real-time full-duplex
interaction. Demos: https://fireredteam.github.io/demos/firered_chat.

</details>


### [36] [The First Voice Timbre Attribute Detection Challenge](https://arxiv.org/abs/2509.06635)
*Liping Chen,Jinghao He,Zhengyan Sheng,Kong Aik Lee,Zhen-Hua Ling*

Main category: cs.SD

TL;DR: NCMMSC 2025首届音色属性检测挑战赛，专注于音色可解释性，在VCTK-RVA数据集上比较两个语音在特定音色维度上的强度差异


<details>
  <summary>Details</summary>
Motivation: 推动语音音色的可解释性研究，建立标准化的音色属性检测评估框架

Method: 参赛团队开发系统并提交输出结果，组织方在VCTK-RVA数据集上进行性能评估并提供反馈

Result: 共有6支团队提交结果，其中5支提供了方法描述

Conclusion: 该挑战赛为音色属性检测领域建立了首个基准测试平台，促进了相关技术的发展

Abstract: The first voice timbre attribute detection challenge is featured in a special
session at NCMMSC 2025. It focuses on the explainability of voice timbre and
compares the intensity of two speech utterances in a specified timbre
descriptor dimension. The evaluation was conducted on the VCTK-RVA dataset.
Participants developed their systems and submitted their outputs to the
organizer, who evaluated the performance and sent feedback to them. Six teams
submitted their outputs, with five providing descriptions of their
methodologies.

</details>


### [37] [AnalysisGNN: Unified Music Analysis with Graph Neural Networks](https://arxiv.org/abs/2509.06654)
*Emmanouil Karystinaios,Johannes Hentschel,Markus Neuwirth,Gerhard Widmer*

Main category: cs.SD

TL;DR: AnalysisGNN是一个基于图神经网络的音乐分析框架，通过数据混洗策略、加权多任务损失和分类器logit融合，整合异构标注数据集进行综合乐谱分析，并包含非和弦音预测模块以提高标签一致性。


<details>
  <summary>Details</summary>
Motivation: 当前计算音乐分析方法通常针对特定分析领域定制，缺乏能够整合异构标注数据集进行综合乐谱分析的统一框架。

Method: 使用图神经网络框架，采用数据混洗策略、自定义加权多任务损失函数和任务特定分类器之间的logit融合技术，整合异构标注的符号数据集，并集成非和弦音预测模块来识别和排除经过音和非功能音。

Result: 实验评估显示AnalysisGNN达到与传统静态数据集方法相当的性能，同时在多个异构语料库中表现出对领域转移和标注不一致性的更强韧性。

Conclusion: AnalysisGNN提供了一个有效的框架来整合异构音乐标注数据，实现了跨领域的综合乐谱分析，并提高了对标注不一致性的鲁棒性。

Abstract: Recent years have seen a boom in computational approaches to music analysis,
yet each one is typically tailored to a specific analytical domain. In this
work, we introduce AnalysisGNN, a novel graph neural network framework that
leverages a data-shuffling strategy with a custom weighted multi-task loss and
logit fusion between task-specific classifiers to integrate heterogeneously
annotated symbolic datasets for comprehensive score analysis. We further
integrate a Non-Chord-Tone prediction module, which identifies and excludes
passing and non-functional notes from all tasks, thereby improving the
consistency of label signals. Experimental evaluations demonstrate that
AnalysisGNN achieves performance comparable to traditional static-dataset
approaches, while showing increased resilience to domain shifts and annotation
inconsistencies across multiple heterogeneous corpora.

</details>


### [38] [Continuous Audio Language Models](https://arxiv.org/abs/2509.06926)
*Rouard Simon,Orsini Manu,Roebel Axel,Zeghidour Neil,Défossez Alexandre*

Main category: cs.SD

TL;DR: CALM通过连续音频建模避免了离散token的损失压缩，在更低计算成本下实现更高质量的音频生成


<details>
  <summary>Details</summary>
Motivation: 解决离散音频token因有损压缩和有限比特率导致的质量与计算成本之间的权衡问题

Method: 使用大型Transformer主干网络生成上下文嵌入，通过MLP和一致性建模生成连续音频VAE帧

Result: 在语音和音乐生成任务上，相比最先进的离散音频语言模型，CALM实现了更高的效率和保真度

Conclusion: CALM通过连续表示避免了离散token的局限性，为轻量级高质量音频生成提供了新范式

Abstract: Audio Language Models (ALM) have emerged as the dominant paradigm for speech
and music generation by representing audio as sequences of discrete tokens.
Yet, unlike text tokens, which are invertible, audio tokens are extracted from
lossy codecs with a limited bitrate. As a consequence, increasing audio quality
requires generating more tokens, which imposes a trade-off between fidelity and
computational cost. We address this issue by studying Continuous Audio Language
Models (CALM). These models instantiate a large Transformer backbone that
produces a contextual embedding at every timestep. This sequential information
then conditions an MLP that generates the next continuous frame of an audio VAE
through consistency modeling. By avoiding lossy compression, CALM achieves
higher quality at lower computational cost than their discrete counterpart.
Experiments on speech and music demonstrate improved efficiency and fidelity
over state-of-the-art discrete audio language models, facilitating lightweight,
high-quality audio generation. Samples are available at
https://continuous-audio-language-models.github.io

</details>


### [39] [Benchmarking Music Autotagging with MGPHot Expert Annotations vs. Generic Tag Datasets](https://arxiv.org/abs/2509.06936)
*Pedro Ramoneda,Pablo Alonso-Jiménez,Sergio Oramas,Xavier Serra,Dmitry Bogdanov*

Main category: cs.SD

TL;DR: 基于MGPHot数据集构建音乐自动标签新基准测试集，包含专业音乐学注释、音频数据和标准化评估方案，用于评估七个领先模型并比较专业与通用标签的差异。


<details>
  <summary>Details</summary>
Motivation: 解决音乐自动标签任务中缺乏包含专业音乐学注释的标准化测试集问题，为评估通用音乐表征学习提供更充分的基准框架。

Method: 重新构建MGPHot数据集，添加YouTube音频URL、提供标准训练/验证/测试分割、预计算七个领先模型的表征，并在MGPHot和标准标签数据集上进行评测。

Result: 构建了包含专业音乐学注释的新基准测试集，对七个领先模型进行了评估，并显示了专业标签与通用标签在自动标签任务中的关键差异。

Conclusion: 该研究为音乐理解领域提供了更充分的基准测试框架，通过专业注释数据集提升了自动标签任务的评估质量和可比性。

Abstract: Music autotagging aims to automatically assign descriptive tags, such as
genre, mood, or instrumentation, to audio recordings. Due to its challenges,
diversity of semantic descriptions, and practical value in various
applications, it has become a common downstream task for evaluating the
performance of general-purpose music representations learned from audio data.
We introduce a new benchmarking dataset based on the recently published MGPHot
dataset, which includes expert musicological annotations, allowing for
additional insights and comparisons with results obtained on common generic tag
datasets. While MGPHot annotations have been shown to be useful for
computational musicology, the original dataset neither includes audio nor
provides evaluation setups for its use as a standardized autotagging benchmark.
To address this, we provide a curated set of YouTube URLs with retrievable
audio, and propose a train/val/test split for standardized evaluation, and
precomputed representations for seven state-of-the-art models. Using these
resources, we evaluated these models in MGPHot and standard reference tag
datasets, highlighting key differences between expert and generic tag
annotations. Altogether, our contributions provide a more advanced benchmarking
framework for future research in music understanding.

</details>

{"id": "2509.06966", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.06966", "abs": "https://arxiv.org/abs/2509.06966", "authors": ["Neal G. Ravindra", "Arijit Sehanobish"], "title": "Cross-device Zero-shot Label Transfer via Alignment of Time Series Foundation Model Embeddings", "comment": "5 pages, 3 figures, 1 table. tl;dr: Adversarial alignment of\n  Time-Series Foundation Model (TSFM) embeddings enables transfer of\n  high-quality clinical labels from medical-grade to consumer-grade wearables,\n  enabling zero-shot prediction of gestational age without requiring paired\n  data", "summary": "High-quality, medically validated labels exist for clinical actigraphy data\nbut not for ubiquitous consumer wearables like the Apple Watch. Manually\nlabeling wearables data is expensive and doesn't scale. This paper offers a\nnovel framework that transfers valuable labels from a source domain (e.g.,\nactigraphy) to a target domain (e.g., Apple Watch) without requiring paired\ndata. Instead of working with raw time-series signals, we project both domains\ninto a shared latent embedding space using time-series foundation models\n(TSFMs) and develop a new framework to align the cross-device representations.\nOur method, Adversarial Alignment of TSFM Embeddings forces the distributions\nof source and target embeddings to align within this space, facilitating label\ntransfer across device type.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65e0\u9700\u914d\u5bf9\u6570\u636e\u7684\u8de8\u8bbe\u5907\u6807\u7b7e\u8fc1\u79fb\u6846\u67b6\uff0c\u901a\u8fc7\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\u5c06\u4e0d\u540c\u8bbe\u5907\u6570\u636e\u6620\u5c04\u5230\u5171\u4eab\u5d4c\u5165\u7a7a\u95f4\uff0c\u5e76\u4f7f\u7528\u5bf9\u6297\u5bf9\u9f50\u65b9\u6cd5\u5b9e\u73b0\u6807\u7b7e\u8fc1\u79fb", "motivation": "\u6d88\u8d39\u7ea7\u53ef\u7a7f\u6234\u8bbe\u5907\uff08\u5982Apple Watch\uff09\u7f3a\u4e4f\u533b\u5b66\u9a8c\u8bc1\u7684\u9ad8\u8d28\u91cf\u6807\u7b7e\uff0c\u800c\u624b\u52a8\u6807\u6ce8\u6210\u672c\u9ad8\u6602\u4e14\u96be\u4ee5\u6269\u5c55\u3002\u4e34\u5e8a\u6d3b\u52a8\u8bb0\u5f55\u4eea\u6570\u636e\u867d\u7136\u6709\u9ad8\u8d28\u91cf\u6807\u7b7e\uff0c\u4f46\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u4e8e\u6d88\u8d39\u7ea7\u8bbe\u5907", "method": "\u4f7f\u7528\u65f6\u95f4\u5e8f\u5217\u57fa\u7840\u6a21\u578b\uff08TSFMs\uff09\u5c06\u6e90\u57df\uff08\u5982\u6d3b\u52a8\u8bb0\u5f55\u4eea\uff09\u548c\u76ee\u6807\u57df\uff08\u5982Apple Watch\uff09\u7684\u539f\u59cb\u65f6\u95f4\u5e8f\u5217\u4fe1\u53f7\u6295\u5f71\u5230\u5171\u4eab\u6f5c\u5728\u5d4c\u5165\u7a7a\u95f4\uff0c\u7136\u540e\u901a\u8fc7\u5bf9\u6297\u5bf9\u9f50\u65b9\u6cd5\u5f3a\u5236\u4e24\u4e2a\u57df\u7684\u5d4c\u5165\u5206\u5e03\u5bf9\u9f50", "result": "\u5f00\u53d1\u4e86Adversarial Alignment of TSFM Embeddings\u65b9\u6cd5\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u8de8\u8bbe\u5907\u7c7b\u578b\u7684\u6807\u7b7e\u8fc1\u79fb\uff0c\u65e0\u9700\u914d\u5bf9\u6570\u636e", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u6d88\u8d39\u7ea7\u53ef\u7a7f\u6234\u8bbe\u5907\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6807\u7b7e\u83b7\u53d6\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u533b\u5b66\u9a8c\u8bc1\u6807\u7b7e\u7a00\u7f3a\u7684\u95ee\u9898\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2509.06967", "categories": ["eess.SP", "cs.AI", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2509.06967", "abs": "https://arxiv.org/abs/2509.06967", "authors": ["Tianyu Huo", "Jian Xiong", "Yiyan Wu", "Songjie Yang", "Bo Liu", "Wenjun Zhang"], "title": "Cross-field SNR Analysis and Tensor Channel Estimation for Multi-UAV Near-field Communications", "comment": null, "summary": "Extremely large antenna array (ELAA) is key to enhancing spectral efficiency\nin 6G networks. Leveraging the distributed nature of multi-unmanned aerial\nvehicle (UAV) systems enables the formation of distributed ELAA, which often\noperate in the near-field region with spatial sparsity, rendering the\nconventional far-field plane wave assumption invalid. This paper investigates\nchannel estimation for distributed near-field multi-UAV communication systems.\nWe first derive closed-form signal-to-noise ratio (SNR) expressions under the\nplane wave model (PWM), spherical wave model (SWM), and a hybrid\nspherical-plane wave model (HSPWM), also referred to as the cross-field model,\nwithin a distributed uniform planar array (UPA) scenario. The analysis shows\nthat HSPWM achieves a good balance between modeling accuracy and analytical\ntractability. Based on this, we propose two channel estimation algorithms: the\nspherical-domain orthogonal matching pursuit (SD-OMP) and the tensor-OMP. The\nSD-OMP generalizes the polar domain to jointly consider elevation, azimuth, and\nrange. Under the HSPWM, the channel is naturally formulated as a tensor,\nenabling the use of tensor-OMP. Simulation results demonstrate that tensor-OMP\nachieves normalized mean square error (NMSE) performance comparable to SD-OMP,\nwhile offering reduced computational complexity and improved scalability.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5206\u5e03\u5f0f\u8fd1\u573a\u591a\u65e0\u4eba\u673a\u901a\u4fe1\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8e\u6df7\u5408\u7403\u9762-\u5e73\u9762\u6ce2\u6a21\u578b\u7684\u4e24\u79cd\u7b97\u6cd5\uff1aSD-OMP\u548ctensor-OMP\uff0c\u540e\u8005\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "6G\u7f51\u7edc\u4e2d\u6781\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\u5728\u8fd1\u573a\u533a\u57df\u8fd0\u884c\uff0c\u4f20\u7edf\u8fdc\u573a\u5e73\u9762\u6ce2\u5047\u8bbe\u5931\u6548\uff0c\u9700\u8981\u5f00\u53d1\u9002\u7528\u4e8e\u5206\u5e03\u5f0f\u8fd1\u573a\u591a\u65e0\u4eba\u673a\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u63a8\u5bfc\u4e86\u4e09\u79cd\u6a21\u578b\u7684\u95ed\u5f0fSNR\u8868\u8fbe\u5f0f\uff0c\u63d0\u51faSD-OMP\u7b97\u6cd5\uff08\u5c06\u6781\u5750\u6807\u57df\u63a8\u5e7f\u5230\u8054\u5408\u8003\u8651\u4ef0\u89d2\u3001\u65b9\u4f4d\u89d2\u548c\u8ddd\u79bb\uff09\u548ctensor-OMP\u7b97\u6cd5\uff08\u5229\u7528\u4fe1\u9053\u5f20\u91cf\u7ed3\u6784\uff09\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793atensor-OMP\u5728NMSE\u6027\u80fd\u4e0a\u4e0eSD-OMP\u76f8\u5f53\uff0c\u4f46\u8ba1\u7b97\u590d\u6742\u5ea6\u66f4\u4f4e\uff0c\u53ef\u6269\u5c55\u6027\u66f4\u597d\u3002", "conclusion": "\u6df7\u5408\u7403\u9762-\u5e73\u9762\u6ce2\u6a21\u578b\u5728\u5efa\u6a21\u7cbe\u5ea6\u548c\u5206\u6790\u6613\u5904\u7406\u6027\u4e4b\u95f4\u53d6\u5f97\u826f\u597d\u5e73\u8861\uff0ctensor-OMP\u7b97\u6cd5\u4e3a\u5206\u5e03\u5f0f\u8fd1\u573a\u591a\u65e0\u4eba\u673a\u901a\u4fe1\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u4fe1\u9053\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.06968", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.06968", "abs": "https://arxiv.org/abs/2509.06968", "authors": ["Murat Temiz", "Yongwei Zhang", "Yanwei Fu", "Chi Zhang", "Chenfeng Meng", "Orhan Kaplan", "Christos Masouros"], "title": "Deep Learning-based Techniques for Integrated Sensing and Communication Systems: State-of-the-Art, Challenges, and Opportunities", "comment": "35 Pages, 13 Figures, 11 Tables, corrected version of the published\n  journal article in IEEE Open Journal of the Communications Society", "summary": "This article comprehensively reviews recent developments and research on deep\nlearning-based (DL-based) techniques for integrated sensing and communication\n(ISAC) systems. ISAC, which combines sensing and communication functionalities,\nis regarded as a key enabler for 6G and beyond networks, as many emerging\napplications, such as vehicular networks and industrial robotics, necessitate\nboth sensing and communication capabilities for effective operation. A unified\nplatform that provides both functions can reduce hardware complexity, alleviate\nfrequency spectrum congestion, and improve energy efficiency. However,\nintegrating these functionalities on the same hardware requires highly\noptimized signal processing and system design, introducing significant\ncomputational complexity when relying on conventional iterative or\noptimization-based techniques. As an alternative to conventional techniques,\nDL-based techniques offer efficient and near-optimal solutions with reduced\ncomputational complexity. Hence, such techniques are well-suited for operating\nunder limited computational resources and low latency requirements in real-time\nsystems. DL-based techniques can swiftly and effectively yield near-optimal\nsolutions for a wide range of sophisticated ISAC-related tasks, including\nwaveform design, channel estimation, sensing signal processing, data\ndemodulation, and interference mitigation. Therefore, motivated by these\nadvantages, recent studies have proposed various DL-based approaches for ISAC\nsystem design. After briefly introducing DL architectures and ISAC\nfundamentals, this survey presents a comprehensive and categorized review of\nstate-of-the-art DL-based techniques for ISAC, highlights their key advantages\nand major challenges, and outlines potential directions for future research.", "AI": {"tldr": "\u6df1\u5ea6\u5b66\u4e60\u57fa\u4e8eISAC\u7cfb\u7edf\u7684\u7efc\u8ff0\u7814\u7a76\uff0c\u8ba8\u8bba\u4e86DL\u6280\u672f\u5728\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u4e2d\u7684\u4f18\u52bf\u548c\u5e94\u7528\u573a\u666f", "motivation": "ISAC\u7cfb\u7edf\u4f5c\u4e3a6G\u53ca\u4ee5\u540e\u7f51\u7edc\u7684\u5173\u952e\u6280\u672f\uff0c\u9700\u8981\u89e3\u51b3\u4f20\u7edf\u4f18\u5316\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u80fd\u63d0\u4f9b\u9ad8\u6548\u8fd1\u4f18\u89e3\u51b3\u65b9\u6848", "method": "\u7efc\u8ff0\u6027\u7814\u7a76\u65b9\u6cd5\uff0c\u5148\u4ecb\u7ecd\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\u548cISAC\u57fa\u7840\u77e5\u8bc6\uff0c\u7136\u540e\u5206\u7c7b\u8bc4\u8bba\u73b0\u6709\u7684DL\u57fa\u4e8eISAC\u6280\u672f\uff0c\u5206\u6790\u5176\u4f18\u52bf\u548c\u6311\u6218", "result": "\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u80fd\u591f\u9ad8\u6548\u5904\u7406ISAC\u7cfb\u7edf\u4e2d\u7684\u591a\u79cd\u590d\u6742\u4efb\u52a1\uff0c\u5305\u62ec\u6ce2\u5f62\u8bbe\u8ba1\u3001\u901a\u9053\u4f30\u8ba1\u3001\u611f\u77e5\u4fe1\u53f7\u5904\u7406\u3001\u6570\u636e\u89e3\u8c03\u548c\u5e72\u6270\u51cf\u5c11\uff0c\u9002\u5408\u5b9e\u65f6\u7cfb\u7edf\u7684\u4f4e\u8ba1\u7b97\u8d44\u6e90\u548c\u4f4e\u5ef6\u8fdf\u8981\u6c42", "conclusion": "DL\u57fa\u4e8eISAC\u6280\u672f\u4e3a6G\u7f51\u7edc\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u964d\u4f4e\u786c\u4ef6\u590d\u6742\u5ea6\u3001\u7f13\u89e3\u9891\u8c31\u62e5\u5835\u548c\u63d0\u9ad8\u80fd\u6e90\u6548\u7387\uff0c\u662f\u672a\u6765\u7814\u7a76\u7684\u91cd\u8981\u65b9\u5411"}}
{"id": "2509.07134", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07134", "abs": "https://arxiv.org/abs/2509.07134", "authors": ["Baris Donmez", "Sebastien Loranger", "Gunes Karabulut Kurt"], "title": "Modeling the Doppler Shift in Cislunar Environment with Gaussian Mixture Models", "comment": "6 pages", "summary": "This study investigates the RF-based Doppler shift distribution\ncharacterization of the Lunar South Pole (LSP) based inter-satellite link (ISL)\nin varying inclination. Doppler shift in parts per million (ppm) is determined\nand analyzed, as it provides an independence from the carrier frequency. Due to\nunknown relative velocity states duration, the Gaussian Mixture Model (GMM) is\nfound to be the best fitting distribution for ISLs with $1^\\circ$ inclination\ninterval Doppler shift with respect to a predetermined satellite.\nGoodness-of-fit is investigated and quantified with Kullback-Leibler (KL)\ndivergence and weighted mean relative difference (WMRD) error metrics.\nSimulation results show that ISL Doppler shifts reach up to $\\pm1.89$ ppm as\nthe inclination of the other orbit deviates higher from the reference orbit,\ninclining $80^\\circ$. Regarding the error measurements of GMM fitting, the WMRD\nand KL divergence metrics for ISL take values up to 0.6575 and 2.2963,\nrespectively.", "AI": {"tldr": "Error", "motivation": "Error", "method": "Error", "result": "Error", "conclusion": "Error"}}
{"id": "2509.07195", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2509.07195", "abs": "https://arxiv.org/abs/2509.07195", "authors": ["Mingyue Huo", "Yuheng Zhang", "Yan Tang"], "title": "Identifying and Calibrating Overconfidence in Noisy Speech Recognition", "comment": "Accepted to ASRU2025", "summary": "Modern end-to-end automatic speech recognition (ASR) models like Whisper not\nonly suffer from reduced recognition accuracy in noise, but also exhibit\noverconfidence - assigning high confidence to wrong predictions. We conduct a\nsystematic analysis of Whisper's behavior in additive noise conditions and find\nthat overconfident errors increase dramatically at low signal-to-noise ratios,\nwith 10-20% of tokens incorrectly predicted with confidence above 0.7. To\nmitigate this, we propose a lightweight, post-hoc calibration framework that\ndetects potential overconfidence and applies temperature scaling selectively to\nthose tokens, without altering the underlying ASR model. Evaluations on the\nR-SPIN dataset demonstrate that, in the low signal-to-noise ratio range (-18 to\n-5 dB), our method reduces the expected calibration error (ECE) by 58% and\ntriples the normalized cross entropy (NCE), yielding more reliable confidence\nestimates under severe noise conditions.", "AI": {"tldr": "Whisper\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u5728\u566a\u58f0\u73af\u5883\u4e0b\u5b58\u5728\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\uff0c\u9519\u8bef\u9884\u6d4b\u5374\u7ed9\u51fa\u9ad8\u7f6e\u4fe1\u5ea6\u3002\u672c\u6587\u63d0\u51fa\u8f7b\u91cf\u7ea7\u540e\u5904\u7406\u6821\u51c6\u6846\u67b6\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u6e29\u5ea6\u7f29\u653e\u964d\u4f4e\u6821\u51c6\u8bef\u5dee58%\uff0c\u63d0\u5347\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u7f6e\u4fe1\u5ea6\u53ef\u9760\u6027\u3002", "motivation": "\u73b0\u4ee3\u7aef\u5230\u7aef\u8bed\u97f3\u8bc6\u522b\u6a21\u578b\u5982Whisper\u5728\u566a\u58f0\u73af\u5883\u4e2d\u4e0d\u4ec5\u8bc6\u522b\u51c6\u786e\u7387\u4e0b\u964d\uff0c\u8fd8\u8868\u73b0\u51fa\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\uff0c\u5373\u5bf9\u9519\u8bef\u9884\u6d4b\u8d4b\u4e88\u9ad8\u7f6e\u4fe1\u5ea6\uff0c\u8fd9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u53ef\u80fd\u5e26\u6765\u4e25\u91cd\u540e\u679c\u3002", "method": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u540e\u5904\u7406\u6821\u51c6\u6846\u67b6\uff0c\u68c0\u6d4b\u6f5c\u5728\u7684\u8fc7\u5ea6\u81ea\u4fe1\u9519\u8bef\uff0c\u5e76\u9009\u62e9\u6027\u5e94\u7528\u6e29\u5ea6\u7f29\u653e\u6280\u672f\uff0c\u65e0\u9700\u4fee\u6539\u5e95\u5c42ASR\u6a21\u578b\u3002", "result": "\u5728\u4f4e\u4fe1\u566a\u6bd4\u8303\u56f4(-18\u81f3-5 dB)\u7684R-SPIN\u6570\u636e\u96c6\u8bc4\u4f30\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5c06\u9884\u671f\u6821\u51c6\u8bef\u5dee(ECE)\u964d\u4f4e58%\uff0c\u5f52\u4e00\u5316\u4ea4\u53c9\u71b5(NCE)\u63d0\u5347\u4e09\u500d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3Whisper\u6a21\u578b\u5728\u4e25\u91cd\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u8fc7\u5ea6\u81ea\u4fe1\u95ee\u9898\uff0c\u63d0\u4f9b\u66f4\u53ef\u9760\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\uff0c\u4e14\u5177\u6709\u8f7b\u91cf\u7ea7\u3001\u65e0\u9700\u6a21\u578b\u4fee\u6539\u7684\u4f18\u70b9\u3002"}}
{"id": "2509.06964", "categories": ["cs.SD", "cs.AR", "cs.HC", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.06964", "abs": "https://arxiv.org/abs/2509.06964", "authors": ["Huihong Liang", "Dongxuan Jia", "Youquan Wang", "Longtao Huang", "Shida Zhong", "Luping Xiang", "Lei Huang", "Tao Yuan"], "title": "Prototype: A Keyword Spotting-Based Intelligent Audio SoC for IoT", "comment": null, "summary": "In this demo, we present a compact intelligent audio system-on-chip (SoC)\nintegrated with a keyword spotting accelerator, enabling ultra-low latency,\nlow-power, and low-cost voice interaction in Internet of Things (IoT) devices.\nThrough algorithm-hardware co-design, the system's energy efficiency is\nmaximized. We demonstrate the system's capabilities through a live FPGA-based\nprototype, showcasing stable performance and real-time voice interaction for\nedge intelligence applications.", "AI": {"tldr": "\u4e00\u6b3e\u96c6\u6210\u5173\u952e\u8bcd\u8bc6\u522b\u52a0\u901f\u5668\u7684\u667a\u80fd\u97f3\u9891SoC\u82af\u7247\uff0c\u901a\u8fc7\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u5b9e\u73b0\u4f4e\u5ef6\u8fdf\u3001\u4f4e\u529f\u8017\u3001\u4f4e\u6210\u672c\u8bed\u97f3\u4ea4\u4e92\uff0c\u9002\u7528\u4e8eIoT\u8fb9\u7f18\u8bbe\u5904\u3002", "motivation": "\u4e3a\u4e86\u6ee1\u8db3IoT\u8bbe\u5904\u5bf9\u4f4e\u529f\u8017\u3001\u4f4e\u5ef6\u8fdf\u8bed\u97f3\u4ea4\u4e92\u7684\u9700\u6c42\uff0c\u9700\u8981\u5f00\u53d1\u4e00\u6b3e\u9ad8\u6548\u80fd\u7684\u667a\u80fd\u97f3\u9891\u82af\u7247\u7cfb\u7edf\u3002", "method": "\u91c7\u7528\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u96c6\u6210\u5173\u952e\u8bcd\u8bc6\u522b\u52a0\u901f\u5668\uff0c\u5e76\u901a\u8fc7FPGA\u539f\u578b\u8fdb\u884c\u9a8c\u8bc1\u548c\u5c55\u793a\u3002", "result": "\u5f00\u53d1\u51fa\u4e86\u4e00\u6b3e\u7d27\u51d1\u578b\u667a\u80fd\u97f3\u9891SoC\uff0c\u80fd\u591f\u5b9e\u73b0\u8d85\u4f4e\u5ef6\u8fdf\u3001\u4f4e\u529f\u8017\u7684\u8bed\u97f3\u4ea4\u4e92\uff0c\u5728\u8fb9\u7f18\u667a\u80fd\u5e94\u7528\u4e2d\u5c55\u793a\u4e86\u7a33\u5b9a\u7684\u6027\u80fd\u548c\u5b9e\u65f6\u6027\u3002", "conclusion": "\u8be5\u667a\u80fd\u97f3\u9891SoC\u7cfb\u7edf\u901a\u8fc7\u7b97\u6cd5-\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u6700\u5927\u5316\u4e86\u80fd\u91cf\u6548\u7387\uff0c\u4e3aIoT\u8bbe\u5904\u63d0\u4f9b\u4e86\u4f4e\u6210\u672c\u3001\u9ad8\u6548\u80fd\u7684\u8bed\u97f3\u4ea4\u4e92\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.07172", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07172", "abs": "https://arxiv.org/abs/2509.07172", "authors": ["Paula Isabel Tilleria Lucero", "Bryan Fernando Sarango Rodr\u00edguez", "Fernando Dar\u00edo Almeida Garc\u00eda", "Jos\u00e9 C\u00e2ndido Silveira Santos Filho"], "title": "Impact of Fading Correlation on the High-SNR Regime of Reconfigurable Intelligent Surfaces", "comment": "Accepted for publication in the XLIII Brazilian Symposium on\n  Telecommunications and Signal Processing, 2025", "summary": "This paper addresses three critical limitations in previous analyses of\nRIS-aided wireless systems: propagation environments with fixed diversity gain,\nrestricted spatial correlation profiles, and approximation methods that fail to\ncapture the system behavior in the high signal-to-noise ratio (SNR) regime. To\novercome these challenges, we conduct an exact asymptotic analysis focused on\nthe left tail of the SNR distribution, which plays a critical role in high-SNR\nsystem performance. Additionally, to account for general correlation profiles\nand fading environments with variable diversity and coding gains, we consider\narbitrarily correlated Nakagami-m fading channels. The analytical results show\nthat fading correlation induces a horizontal shift in the asymptotic behavior\n-- represented as a straight line in the log-dB scale -- of the PDF and CDF,\ndisplacing these curves to the left. The asymptotic linear coefficient\nquantifies this shift, while the angular coefficient remains unaffected.\nMoreover, the results reveal that the high sensitivity of the linear\ncoefficient to correlation arises from the aggregated contribution of all\nmarginal asymptotic terms, effectively capturing each channel's correlation\ncharacteristics.", "AI": {"tldr": "\u672c\u6587\u5bf9RIS\u8f85\u52a9\u65e0\u7ebf\u7cfb\u7edf\u8fdb\u884c\u7cbe\u786e\u6e10\u8fd1\u5206\u6790\uff0c\u89e3\u51b3\u4e86\u5148\u524d\u7814\u7a76\u7684\u4e09\u4e2a\u5173\u952e\u9650\u5236\uff1a\u56fa\u5b9a\u5206\u96c6\u589e\u76ca\u7684\u4f20\u64ad\u73af\u5883\u3001\u53d7\u9650\u7a7a\u95f4\u76f8\u5173\u6027\u5256\u9762\uff0c\u4ee5\u53ca\u5728\u9ad8SNR\u533a\u57df\u5931\u6548\u7684\u8fd1\u4f3c\u65b9\u6cd5\u3002", "motivation": "\u514b\u670d\u5148\u524dRIS\u8f85\u52a9\u65e0\u7ebf\u7cfb\u7edf\u5206\u6790\u4e2d\u7684\u4e09\u4e2a\u5173\u952e\u5c40\u9650\u6027\uff1a\u56fa\u5b9a\u5206\u96c6\u589e\u76ca\u73af\u5883\u3001\u53d7\u9650\u76f8\u5173\u6027\u5256\u9762\uff0c\u4ee5\u53ca\u9ad8SNR\u533a\u57df\u4e0d\u51c6\u786e\u7684\u8fd1\u4f3c\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u7cbe\u786e\u6e10\u8fd1\u5206\u6790\u65b9\u6cd5\uff0c\u5173\u6ce8SNR\u5206\u5e03\u7684\u5de6\u5c3e\u90e8\uff0c\u8003\u8651\u4efb\u610f\u76f8\u5173\u7684Nakagami-m\u8870\u843d\u4fe1\u9053\uff0c\u4ee5\u5904\u7406\u4e00\u822c\u76f8\u5173\u6027\u5256\u9762\u548c\u53ef\u53d8\u5206\u96c6/\u7f16\u7801\u589e\u76ca\u7684\u8870\u843d\u73af\u5883\u3002", "result": "\u5206\u6790\u8868\u660e\u8870\u843d\u76f8\u5173\u6027\u5bfc\u81f4PDF\u548cCDF\u6e10\u8fd1\u884c\u4e3a\u53d1\u751f\u6c34\u5e73\u4f4d\u79fb\uff08\u5728\u5bf9\u6570-dB\u5c3a\u5ea6\u4e0a\u8868\u73b0\u4e3a\u76f4\u7ebf\u79fb\u52a8\uff09\uff0c\u7ebf\u6027\u7cfb\u6570\u91cf\u5316\u8fd9\u79cd\u4f4d\u79fb\u800c\u89d2\u5ea6\u7cfb\u6570\u4fdd\u6301\u4e0d\u53d8\u3002\u9ad8\u654f\u611f\u6027\u6e90\u4e8e\u6240\u6709\u8fb9\u9645\u6e10\u8fd1\u9879\u7684\u805a\u5408\u8d21\u732e\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u5bf9RIS\u8f85\u52a9\u7cfb\u7edf\u5728\u9ad8SNR\u533a\u57df\u6027\u80fd\u7684\u7cbe\u786e\u7406\u89e3\uff0c\u63ed\u793a\u4e86\u76f8\u5173\u6027\u5bf9\u7cfb\u7edf\u6e10\u8fd1\u884c\u4e3a\u7684\u5b9a\u91cf\u5f71\u54cd\u673a\u5236\uff0c\u4e3a\u76f8\u5173\u65e0\u7ebf\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u4f9d\u636e\u3002"}}
{"id": "2509.07341", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2509.07341", "abs": "https://arxiv.org/abs/2509.07341", "authors": ["Ye Ni", "Ruiyu Liang", "Xiaoshuai Hao", "Jiaming Cheng", "Qingyun Wang", "Chengwei Huang", "Cairong Zou", "Wei Zhou", "Weiping Ding", "Bj\u00f6rn W. Schuller"], "title": "Affine Modulation-based Audiogram Fusion Network for Joint Noise Reduction and Hearing Loss Compensation", "comment": null, "summary": "Hearing aids (HAs) are widely used to provide personalized speech enhancement\n(PSE) services, improving the quality of life for individuals with hearing\nloss. However, HA performance significantly declines in noisy environments as\nit treats noise reduction (NR) and hearing loss compensation (HLC) as separate\ntasks. This separation leads to a lack of systematic optimization, overlooking\nthe interactions between these two critical tasks, and increases the system\ncomplexity. To address these challenges, we propose a novel audiogram fusion\nnetwork, named AFN-HearNet, which simultaneously tackles the NR and HLC tasks\nby fusing cross-domain audiogram and spectrum features. We propose an\naudiogram-specific encoder that transforms the sparse audiogram profile into a\ndeep representation, addressing the alignment problem of cross-domain features\nprior to fusion. To incorporate the interactions between NR and HLC tasks, we\npropose the affine modulation-based audiogram fusion frequency-temporal\nConformer that adaptively fuses these two features into a unified deep\nrepresentation for speech reconstruction. Furthermore, we introduce a voice\nactivity detection auxiliary training task to embed speech and non-speech\npatterns into the unified deep representation implicitly. We conduct\ncomprehensive experiments across multiple datasets to validate the\neffectiveness of each proposed module. The results indicate that the\nAFN-HearNet significantly outperforms state-of-the-art in-context fusion joint\nmodels regarding key metrics such as HASQI and PESQ, achieving a considerable\ntrade-off between performance and efficiency. The source code and data will be\nreleased at https://github.com/deepnetni/AFN-HearNet.", "AI": {"tldr": "AFN-HearNet\u662f\u4e00\u4e2a\u65b0\u9896\u7684\u542c\u529b\u56fe\u878d\u5408\u7f51\u7edc\uff0c\u901a\u8fc7\u878d\u5408\u8de8\u57df\u542c\u529b\u56fe\u548c\u9891\u8c31\u7279\u5f81\uff0c\u540c\u65f6\u5904\u7406\u566a\u58f0\u6291\u5236\u548c\u542c\u529b\u635f\u5931\u8865\u507f\u4efb\u52a1\uff0c\u663e\u8457\u63d0\u5347\u4e86\u52a9\u542c\u5668\u5728\u5608\u6742\u73af\u5883\u4e2d\u7684\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u52a9\u542c\u5668\u5c06\u566a\u58f0\u6291\u5236\u548c\u542c\u529b\u635f\u5931\u8865\u507f\u4f5c\u4e3a\u72ec\u7acb\u4efb\u52a1\u5904\u7406\uff0c\u7f3a\u4e4f\u7cfb\u7edf\u4f18\u5316\uff0c\u5ffd\u89c6\u4e86\u8fd9\u4e24\u4e2a\u5173\u952e\u4efb\u52a1\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\uff0c\u5bfc\u81f4\u5728\u5608\u6742\u73af\u5883\u4e2d\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "method": "\u63d0\u51fa\u542c\u529b\u56fe\u7279\u5b9a\u7f16\u7801\u5668\u5c06\u7a00\u758f\u542c\u529b\u56fe\u8f6c\u6362\u4e3a\u6df1\u5ea6\u8868\u793a\uff0c\u4f7f\u7528\u57fa\u4e8e\u4eff\u5c04\u8c03\u5236\u7684\u542c\u529b\u56fe\u878d\u5408\u9891\u7387-\u65f6\u95f4Conformer\u81ea\u9002\u5e94\u878d\u5408\u7279\u5f81\uff0c\u5e76\u5f15\u5165\u8bed\u97f3\u6d3b\u52a8\u68c0\u6d4b\u8f85\u52a9\u8bad\u7ec3\u4efb\u52a1\u3002", "result": "AFN-HearNet\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u5728HASQI\u548cPESQ\u7b49\u5173\u952e\u6307\u6807\u4e0a\u663e\u8457\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u4e0a\u4e0b\u6587\u878d\u5408\u8054\u5408\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0e\u6548\u7387\u7684\u826f\u597d\u5e73\u8861\u3002", "conclusion": "AFN-HearNet\u901a\u8fc7\u540c\u65f6\u5904\u7406\u566a\u58f0\u6291\u5236\u548c\u542c\u529b\u635f\u5931\u8865\u507f\u4efb\u52a1\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u4f20\u7edf\u52a9\u542c\u5668\u5728\u5608\u6742\u73af\u5883\u4e2d\u7684\u6027\u80fd\u95ee\u9898\uff0c\u4e3a\u4e2a\u6027\u5316\u8bed\u97f3\u589e\u5f3a\u670d\u52a1\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.07038", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.07038", "abs": "https://arxiv.org/abs/2509.07038", "authors": ["Yerin Ryu", "Inseop Shin", "Chanwoo Kim"], "title": "Controllable Singing Voice Synthesis using Phoneme-Level Energy Sequence", "comment": "Accepted to ASRU 2025", "summary": "Controllable Singing Voice Synthesis (SVS) aims to generate expressive\nsinging voices reflecting user intent. While recent SVS systems achieve high\naudio quality, most rely on probabilistic modeling, limiting precise control\nover attributes such as dynamics. We address this by focusing on dynamic\ncontrol--temporal loudness variation essential for musical expressiveness--and\nexplicitly condition the SVS model on energy sequences extracted from\nground-truth spectrograms, reducing annotation costs and improving\ncontrollability. We also propose a phoneme-level energy sequence for\nuser-friendly control. To the best of our knowledge, this is the first attempt\nenabling user-driven dynamics control in SVS. Experiments show our method\nachieves over 50% reduction in mean absolute error of energy sequences for\nphoneme-level inputs compared to baseline and energy-predictor models, without\ncompromising synthesis quality.", "AI": {"tldr": "\u901a\u8fc7\u663e\u5f0f\u80fd\u91cf\u5e8f\u5217\u6761\u4ef6\u5316\u6a21\u578b\uff0c\u5b9e\u73b0\u4e86\u7c92\u5ea6\u66f4\u7ec6\u7684\u97f3\u7d20\u7ea7\u52a8\u6001\u63a7\u5236\uff0c\u5728\u4fdd\u6301\u5408\u6210\u8d28\u91cf\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u4e86\u80fd\u91cf\u9884\u6d4b\u51c6\u786e\u6027", "motivation": "\u73b0\u6709\u5531\u5531\u8bed\u97f3\u5408\u6210\u7cfb\u7edf\u591a\u4f9d\u8d56\u6982\u7387\u6a21\u578b\uff0c\u5728\u52a8\u6001\u63a7\u5236\u65b9\u9762\u5b58\u5728\u9650\u5236\uff0c\u7279\u522b\u662f\u7f3a\u4e4f\u7528\u6237\u53ef\u9a71\u52a8\u7684\u7cbe\u786e\u52a8\u6001\u63a7\u5236\u80fd\u529b", "method": "\u4f7f\u7528\u4ece\u771f\u5b9e\u8bed\u97f3\u8c31\u63d0\u53d6\u7684\u80fd\u91cf\u5e8f\u5217\u663e\u5f0f\u6761\u4ef6\u5316SVS\u6a21\u578b\uff0c\u5e76\u63d0\u51fa\u97f3\u7d20\u7ea7\u80fd\u91cf\u5e8f\u5217\u63a7\u5236\u65b9\u6848\uff0c\u964d\u4f4e\u6ce8\u91ca\u6210\u672c\u548c\u63d0\u9ad8\u53ef\u63a7\u6027", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u4e0e\u57fa\u7ebf\u6a21\u578b\u548c\u80fd\u91cf\u9884\u6d4b\u5668\u6a21\u578b\u76f8\u6bd4\uff0c\u5728\u97f3\u7d20\u7ea7\u8f93\u5165\u65b9\u5f0f\u4e0b\u80fd\u91cf\u5e8f\u5217\u7684\u5747\u65b9\u5dee\u8bef\u5dee\u51cf\u5c11\u8d85\u8fc750%\uff0c\u4e14\u5408\u6210\u8d28\u91cf\u672a\u53d7\u5f71\u54cd", "conclusion": "\u8be5\u65b9\u6cd5\u9996\u6b21\u5b9e\u73b0\u4e86SVS\u4e2d\u7528\u6237\u53ef\u9a71\u52a8\u7684\u52a8\u6001\u63a7\u5236\uff0c\u901a\u8fc7\u97f3\u7d20\u7ea7\u80fd\u91cf\u5e8f\u5217\u63a7\u5236\u63d0\u4f9b\u4e86\u66f4\u7c92\u5ea6\u5316\u7684\u8868\u8fbe\u529b\u63a7\u5236\u80fd\u529b"}}
{"id": "2509.07229", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07229", "abs": "https://arxiv.org/abs/2509.07229", "authors": ["Navid Reyhanian", "Reza Ghaderi Zefreh", "Parisa Ramezani", "Emil Bj\u00f6rnson"], "title": "Joint Spatial and Spectral Hybrid Precoding for Multi-User MIMO-OFDM Systems", "comment": null, "summary": "The deployment of millimeter wave (mmWave) multiple-input multiple-output\n(MIMO) systems cannot rely solely on digital precoding due to hardware\nconstraints. Instead, hybrid precoding, which combines digital and radio\nfrequency (RF) techniques, has emerged as a potential alternative. This\napproach strikes a balance between performance and cost, addressing the\nlimitations of signal mixers and analog-to-digital converters in mmWave\nsystems. mmWave systems are designed to function in wideband channels with\nfrequency selectivity, necessitating the use of orthogonal frequency-division\nmultiplexing (OFDM) to mitigate dispersive channels. However, OFDM faces\nseveral challenges. First, it suffers from a high peak-to-average power ratio\n(PAPR) due to the linear combination of subcarriers. Second, it suffers from\nout-of-band (OOB) emissions due to the sharp spectral transitions of OFDM\nsubcarriers and windowing-induced spectral leakage. Furthermore, phase shifter\n(PS) impairments at the RF transmitter precoder and the user combiner represent\na limitation in practical mmWave systems, leading to phase errors. This work\naddresses these challenges.\n  We study the problem of robust digital-RF precoding optimization for the\ndownlink sum-rate maximization in hybrid multi-user (MU) MIMO-OFDM systems\nunder maximum transmit power, PAPR, and OOB emission constraints. The\nformulated maximization problem is non-convex and difficult to solve. We\npropose a weighted minimum mean squared error (WMMSE) based block coordinate\ndescent (BCD) method to iteratively optimize digital-RF precoders at the\ntransmitter and digital-RF combiners at the users. Low-cost and scalable\noptimization approaches are proposed to efficiently solve the BCD subproblems.\nExtensive simulation results are conducted to demonstrate the efficiency of the\nproposed approaches and exhibit their superiority relative to well-known\nbenchmarks.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eWMMSE\u7684BCD\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f18\u5316\u6beb\u7c73\u6ce2MU-MIMO-OFDM\u7cfb\u7edf\u4e2d\u7684\u6df7\u5408\u9884\u7f16\u7801\uff0c\u89e3\u51b3\u4e86PAPR\u3001OOB\u53d1\u5c04\u548c\u76f8\u4f4d\u8bef\u5dee\u7b49\u5b9e\u9645\u95ee\u9898\u3002", "motivation": "\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u7531\u4e8e\u786c\u4ef6\u9650\u5236\u65e0\u6cd5\u4ec5\u4f9d\u8d56\u6570\u5b57\u9884\u7f16\u7801\uff0c\u6df7\u5408\u9884\u7f16\u7801\u5728\u6027\u80fd\u548c\u6210\u672c\u95f4\u53d6\u5f97\u5e73\u8861\u3002OFDM\u7cfb\u7edf\u9762\u4e34\u9ad8PAPR\u3001OOB\u53d1\u5c04\u548c\u76f8\u4f4d\u8bef\u5dee\u7b49\u6311\u6218\uff0c\u9700\u8981\u9c81\u68d2\u7684\u4f18\u5316\u65b9\u6848\u3002", "method": "\u91c7\u7528\u52a0\u6743\u6700\u5c0f\u5747\u65b9\u8bef\u5dee(WMMSE)\u548c\u5757\u5750\u6807\u4e0b\u964d(BCD)\u65b9\u6cd5\uff0c\u8fed\u4ee3\u4f18\u5316\u53d1\u5c04\u7aef\u7684\u6570\u5b57-RF\u9884\u7f16\u7801\u5668\u548c\u7528\u6237\u7aef\u7684\u6570\u5b57-RF\u7ec4\u5408\u5668\uff0c\u63d0\u51fa\u4f4e\u6210\u672c\u53ef\u6269\u5c55\u7684\u4f18\u5316\u65b9\u6cd5\u89e3\u51b3BCD\u5b50\u95ee\u9898\u3002", "result": "\u5927\u91cf\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u6548\u7387\u9ad8\uff0c\u76f8\u5bf9\u4e8e\u77e5\u540d\u57fa\u51c6\u65b9\u6cd5\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u6beb\u7c73\u6ce2\u6df7\u5408MIMO-OFDM\u7cfb\u7edf\u4e2d\u7684\u9884\u7f16\u7801\u4f18\u5316\u95ee\u9898\uff0c\u5728\u529f\u7387\u3001PAPR\u548cOOB\u53d1\u5c04\u7ea6\u675f\u4e0b\u5b9e\u73b0\u4e86\u9c81\u68d2\u7684\u6027\u80fd\u3002"}}
{"id": "2509.07586", "categories": ["eess.AS", "cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2509.07586", "abs": "https://arxiv.org/abs/2509.07586", "authors": ["Patricia Hu", "Silvan David Peter", "Jan Schl\u00fcter", "Gerhard Widmer"], "title": "Exploring System Adaptations For Minimum Latency Real-Time Piano Transcription", "comment": "to be published in Proceedings of the 26th International Society for\n  Music Information Retrieval (ISMIR) Conference 2025, Daejeon, South Korea", "summary": "Advances in neural network design and the availability of large-scale labeled\ndatasets have driven major improvements in piano transcription. Existing\napproaches target either offline applications, with no restrictions on\ncomputational demands, or online transcription, with delays of 128-320 ms.\nHowever, most real-time musical applications require latencies below 30 ms. In\nthis work, we investigate whether and how the current state-of-the-art online\ntranscription model can be adapted for real-time piano transcription.\nSpecifically, we eliminate all non-causal processing, and reduce computational\nload through shared computations across core model components and variations in\nmodel size. Additionally, we explore different pre- and postprocessing\nstrategies, and related label encoding schemes, and discuss their suitability\nfor real-time transcription. Evaluating the adaptions on the MAESTRO dataset,\nwe find a drop in transcription accuracy due to strictly causal processing as\nwell as a tradeoff between the preprocessing latency and prediction accuracy.\nWe release our system as a baseline to support researchers in designing models\ntowards minimum latency real-time transcription.", "AI": {"tldr": "\u5c06\u73b0\u6709\u7684\u5728\u7ebf\u94a2\u7434\u8f6c\u8bd1\u6a21\u578b\u9002\u914d\u4e3a\u5b9e\u65f6\u5e94\u7528\uff0c\u5b9e\u73b0\u5ef6\u8fdf\u4f4e\u4e8e30ms\u7684\u8f6c\u8bd1\u80fd\u529b", "motivation": "\u73b0\u6709\u94a2\u7434\u8f6c\u8bd1\u6a21\u578b\u5ef6\u8fdf\u8fc7\u9ad8\uff08128-320ms\uff09\uff0c\u800c\u5927\u591a\u6570\u5b9e\u65f6\u97f3\u4e50\u5e94\u7528\u9700\u8981\u4f4e\u4e8e30ms\u7684\u5ef6\u8fdf", "method": "\u6d88\u9664\u975e\u56e0\u679c\u6027\u5904\u7406\uff0c\u901a\u8fc7\u6838\u5fc3\u6a21\u578b\u7ec4\u4ef6\u5171\u4eab\u8ba1\u7b97\u548c\u6a21\u578b\u5927\u5c0f\u53d8\u5316\u964d\u4f4e\u8ba1\u7b97\u8d1f\u8377\uff0c\u63a2\u7d22\u4e0d\u540c\u7684\u524d\u540e\u5904\u7406\u7b56\u7565\u548c\u6807\u7b7e\u7f16\u7801\u65b9\u6848", "result": "\u5728MAESTRO\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u663e\u793a\uff0c\u4e25\u683c\u56e0\u679c\u6027\u5904\u7406\u5bfc\u81f4\u8f6c\u8bd1\u51c6\u786e\u5ea6\u4e0b\u964d\uff0c\u524d\u5904\u7406\u5ef6\u8fdf\u4e0e\u9884\u6d4b\u51c6\u786e\u6027\u5b58\u5728\u62fc\u6362\u5173\u7cfb", "conclusion": "\u7814\u7a76\u4e3a\u6700\u5c0f\u5ef6\u8fdf\u5b9e\u65f6\u8f6c\u8bd1\u6a21\u578b\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u57fa\u51c6\u7ebf\uff0c\u5e76\u5c55\u793a\u4e86\u5ef6\u8fdf\u4e0e\u6027\u80fd\u4e4b\u95f4\u7684\u62fc\u6362"}}
{"id": "2509.07051", "categories": ["cs.SD", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.07051", "abs": "https://arxiv.org/abs/2509.07051", "authors": ["Pietro Bartoli", "Tommaso Bondini", "Christian Veronesi", "Andrea Giudici", "Niccol\u00f2 Antonello", "Franco Zappa"], "title": "End-to-End Efficiency in Keyword Spotting: A System-Level Approach for Embedded Microcontrollers", "comment": "4 pages, 2 figures, 1 table. Accepted for publication in IEEE Sensors\n  2025. \\c{opyright} 2025 IEEE. Personal use permitted. Permission from IEEE\n  required for all other uses", "summary": "Keyword spotting (KWS) is a key enabling technology for hands-free\ninteraction in embedded and IoT devices, where stringent memory and energy\nconstraints challenge the deployment of AI-enabeld devices. In this work, we\nsystematically evaluate and compare several state-of-the-art lightweight neural\nnetwork architectures, including DS-CNN, LiCoNet, and TENet, alongside our\nproposed Typman-KWS (TKWS) architecture built upon MobileNet, specifically\ndesigned for efficient KWS on microcontroller units (MCUs). Unlike prior\nstudies focused solely on model inference, our analysis encompasses the entire\nprocessing pipeline, from Mel-Frequency Cepstral Coefficient (MFCC) feature\nextraction to neural inference, and is benchmarked across three STM32 platforms\n(N6, H7, and U5). Our results show that TKWS with three residual blocks\nachieves up to 92.4% F1-score with only 14.4k parameters, reducing memory\nfootprint without compromising the accuracy. Moreover, the N6 MCU with\nintegrated neural acceleration achieves the best energy-delay product (EDP),\nenabling efficient, low-latency operation even with high-resolution features.\nOur findings highlight the model accuracy alone does not determine real-world\neffectiveness; rather, optimal keyword spotting deployments require careful\nconsideration of feature extraction parameters and hardware-specific\noptimization.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u7cfb\u7edf\u6027\u8bc4\u4f30\u4e86\u591a\u79cd\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\u5728\u5fae\u63a7\u5236\u5668\u4e0a\u7684\u5173\u952e\u8bcd\u68c0\u6d4b\u6027\u80fd\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eMobileNet\u7684TKWS\u6a21\u578b\uff0c\u5728\u4ec5\u536014.4k\u53c2\u6570\u7684\u60c5\u51b5\u4e0b\u8fbe\u523092.4% F1\u5206\u6570\uff0c\u5e76\u5728STM32\u5e73\u53f0\u4e0a\u8fdb\u884c\u4e86\u4ece\u7279\u5f81\u63d0\u53d6\u5230\u63a8\u7406\u7684\u5168\u6d41\u7a0b\u6027\u80fd\u5206\u6790\u3002", "motivation": "\u5173\u952e\u8bcd\u68c0\u6d4b(KWS)\u662f\u5d4c\u5165\u5f0f\u548cIoT\u8bbe\u5907\u4e2d\u65e0\u624b\u4ea4\u4e92\u7684\u5173\u952e\u6280\u672f\uff0c\u4f46\u5185\u5b58\u548c\u80fd\u6e90\u9650\u5236\u7eb5\u4f7fAI\u8bbe\u5907\u90e8\u7f72\u9762\u4e34\u6311\u6218\u3002\u9700\u8981\u627e\u5230\u65e2\u8f7b\u91cf\u53c8\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7cfb\u7edf\u6027\u8bc4\u4f30\u548c\u6bd4\u8f83\u591a\u79cd\u8f7b\u91cf\u7ea7\u795e\u7ecf\u7f51\u7edc\u67b6\u6784(DS-CNN\u3001LiCoNet\u3001TENet)\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8eMobileNet\u7684Typman-KWS(TKWS)\u67b6\u6784\u3002\u5206\u6790\u6db5\u76d6\u4eceMFCC\u7279\u5f81\u63d0\u53d6\u5230\u795e\u7ecf\u7f51\u7edc\u63a8\u7406\u7684\u5168\u5904\u7406\u6d41\u7a0b\uff0c\u5728\u4e09\u79cdSTM32\u5e73\u53f0(N6\u3001H7\u3001U5)\u4e0a\u8fdb\u884c\u6d4b\u8bd5\u3002", "result": "TKWS\u4f7f\u75283\u4e2a\u6b8a\u5fcd\u5757\u8fbe\u5230\u4e8692.4% F1\u5206\u6570\uff0c\u53c2\u6570\u4ec5\u536014.4k\u3002\u96c6\u6210\u795e\u7ecf\u52a0\u901f\u7684N6 MCU\u5b9e\u73b0\u4e86\u6700\u4f73\u80fd\u6e90-\u5ef6\u8fdf\u4e58\u79ef(EDP)\uff0c\u652f\u6301\u9ad8\u5206\u8fa8\u7387\u7279\u5f81\u7684\u9ad8\u6548\u4f4e\u5ef6\u8fdf\u8fd0\u884c\u3002", "conclusion": "\u6a21\u578b\u51c6\u786e\u6027\u4e0d\u80fd\u5355\u72ec\u51b3\u5b9a\u5b9e\u9645\u6548\u679c\uff0c\u6700\u4f73\u7684\u5173\u952e\u8bcd\u68c0\u6d4b\u90e8\u7f72\u9700\u8981\u7ef4\u5ea6\u8003\u8651\u7279\u5f81\u63d0\u53d6\u53c2\u6570\u548c\u786c\u4ef6\u7279\u5b9a\u4f18\u5316\u3002"}}
{"id": "2509.07293", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07293", "abs": "https://arxiv.org/abs/2509.07293", "authors": ["Miguel Saavedra-Melo", "Benjamin Bradshaw", "Vanessa Yao", "Ender Ayanoglu", "Lee Swindlehurst", "Filippo Capolino"], "title": "Experimental Analysis of Biasing Voltage Generation in Wave-Controlled RIS", "comment": "13 pages, 19 figures, 2 tables", "summary": "Reconfigurable intelligent surfaces (RISs), an emerging technology proposed\nfor inclusion in next generation wireless communication systems, are\nprogrammable surfaces that can adaptively reflect incident electromagnetic\nradiation in different desired directions. To reduce the complexity and\nphysical profile of conventional RIS designs, a novel concept known as\nWave-Controlled RIS has been proposed, in which standing waves along a\ntransmission line are used to generate the required dc bias for reflective\ncontrol. This paper shows the design of such a Wave-Controlled RIS and its\nbiasing transmission line. The effectiveness of this approach in generating the\ncorrect dc bias from a single standing wave frequency is analyzed through both\ntheoretical modeling and experimental validation, which uncovered a dependence\non impedance matching not accounted for by the theory. Additionally, the\npotential for reflective control using only a single standing wave frequency on\nthe biasing transmission line is explored, demonstrating the ability of\nsingle-beam steering toward angles near broadside.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9a7b\u6ce2\u7684\u6ce2\u63a7\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(RIS)\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5355\u9891\u9a7b\u6ce2\u5728\u4f20\u8f93\u7ebf\u4e0a\u4ea7\u751f\u76f4\u6d41\u504f\u7f6e\u6765\u63a7\u5236\u53cd\u5c04\uff0c\u964d\u4f4e\u4e86\u4f20\u7edfRIS\u7684\u590d\u6742\u5ea6\u548c\u7269\u7406\u5c3a\u5bf8\u3002", "motivation": "\u4f20\u7edf\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u8bbe\u8ba1\u590d\u6742\u4e14\u7269\u7406\u5c3a\u5bf8\u8f83\u5927\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u7b80\u5355\u7d27\u51d1\u7684RIS\u5b9e\u73b0\u65b9\u6848\u3002", "method": "\u8bbe\u8ba1\u6ce2\u63a7RIS\u53ca\u5176\u504f\u7f6e\u4f20\u8f93\u7ebf\uff0c\u5229\u7528\u4f20\u8f93\u7ebf\u4e0a\u7684\u5355\u9891\u9a7b\u6ce2\u4ea7\u751f\u6240\u9700\u7684\u76f4\u6d41\u504f\u7f6e\uff0c\u901a\u8fc7\u7406\u8bba\u5efa\u6a21\u548c\u5b9e\u9a8c\u9a8c\u8bc1\u5206\u6790\u5176\u6709\u6548\u6027\u3002", "result": "\u5b9e\u9a8c\u53d1\u73b0\u504f\u7f6e\u751f\u6210\u6548\u679c\u4f9d\u8d56\u4e8e\u963b\u6297\u5339\u914d\uff08\u7406\u8bba\u672a\u8003\u8651\u6b64\u56e0\u7d20\uff09\uff0c\u5e76\u8bc1\u660e\u5355\u9891\u9a7b\u6ce2\u53ef\u5b9e\u73b0\u63a5\u8fd1\u6cd5\u7ebf\u65b9\u5411\u7684\u5355\u6ce2\u675f\u8f6c\u5411\u3002", "conclusion": "\u6ce2\u63a7RIS\u65b9\u6cd5\u80fd\u591f\u7b80\u5316RIS\u8bbe\u8ba1\uff0c\u5355\u9891\u9a7b\u6ce2\u63a7\u5236\u65b9\u6848\u5177\u6709\u53ef\u884c\u6027\uff0c\u4f46\u9700\u8981\u8003\u8651\u963b\u6297\u5339\u914d\u7b49\u5b9e\u9645\u56e0\u7d20\u3002"}}
{"id": "2509.07132", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.07132", "abs": "https://arxiv.org/abs/2509.07132", "authors": ["Kutub Uddin", "Muhammad Umar Farooq", "Awais Khan", "Khalid Mahmood Malik"], "title": "Adversarial Attacks on Audio Deepfake Detection: A Benchmark and Comparative Study", "comment": null, "summary": "The widespread use of generative AI has shown remarkable success in producing\nhighly realistic deepfakes, posing a serious threat to various voice biometric\napplications, including speaker verification, voice biometrics, audio\nconferencing, and criminal investigations. To counteract this, several\nstate-of-the-art (SoTA) audio deepfake detection (ADD) methods have been\nproposed to identify generative AI signatures to distinguish between real and\ndeepfake audio. However, the effectiveness of these methods is severely\nundermined by anti-forensic (AF) attacks that conceal generative signatures.\nThese AF attacks span a wide range of techniques, including statistical\nmodifications (e.g., pitch shifting, filtering, noise addition, and\nquantization) and optimization-based attacks (e.g., FGSM, PGD, C \\& W, and\nDeepFool). In this paper, we investigate the SoTA ADD methods and provide a\ncomparative analysis to highlight their effectiveness in exposing deepfake\nsignatures, as well as their vulnerabilities under adversarial conditions. We\nconducted an extensive evaluation of ADD methods on five deepfake benchmark\ndatasets using two categories: raw and spectrogram-based approaches. This\ncomparative analysis enables a deeper understanding of the strengths and\nlimitations of SoTA ADD methods against diverse AF attacks. It does not only\nhighlight vulnerabilities of ADD methods, but also informs the design of more\nrobust and generalized detectors for real-world voice biometrics. It will\nfurther guide future research in developing adaptive defense strategies that\ncan effectively counter evolving AF techniques.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u5206\u6790\u4e86\u5f53\u524d\u6700\u5148\u8fdb\u7684\u97f3\u9891\u6df1\u5ea6\u5047\u68c0\u6d4b\u65b9\u6cd5\u5728\u53cd\u53f8\u6cd5\u653b\u51fb\u4e0b\u7684\u654f\u611f\u6027\uff0c\u901a\u8fc7\u57285\u4e2a\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u7684\u7efc\u5408\u8bc4\u6d4b\u63ed\u793a\u4e86\u8fd9\u4e9b\u65b9\u6cd5\u7684\u5f3a\u9879\u548c\u5f31\u70b9\u3002", "motivation": "\u968f\u7740\u751f\u6210\u5f0fAI\u4ea7\u751f\u7684\u9ad8\u4fdd\u771f\u5ea6\u6df1\u5ea6\u5047\u97f3\u9891\u5bf9\u8bed\u97f3\u8bc6\u522b\u5e94\u7528\u9020\u6210\u4e25\u91cd\u5a01\u80c1\uff0c\u9700\u8981\u7814\u7a76\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5728\u53cd\u53f8\u6cd5\u653b\u51fb\u4e0b\u7684\u8010\u53d7\u6027\u3002", "method": "\u91c7\u7528\u4e24\u7c7b\u65b9\u6cd5\uff08\u539f\u59cb\u97f3\u9891\u548c\u8c31\u56fe\u57fa\u7840\uff09\uff0c\u57285\u4e2a\u6df1\u5ea6\u5047\u6807\u51c6\u6570\u636e\u96c6\u4e0a\u5bf9\u6700\u5148\u8fdb\u7684\u97f3\u9891\u6df1\u5ea6\u5047\u68c0\u6d4b\u65b9\u6cd5\u8fdb\u884c\u7efc\u5408\u8bc4\u6d4b\uff0c\u6d4b\u8bd5\u5bf9\u7edf\u8ba1\u4fee\u6539\u548c\u4f18\u5316\u57fa\u7840\u653b\u51fb\u7684\u8010\u53d7\u6027\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u73b0\u6709\u68c0\u6d4b\u65b9\u6cd5\u5728\u53cd\u53f8\u6cd5\u653b\u51fb\u4e0b\u654f\u611f\u6027\u9ad8\uff0c\u654f\u611f\u6027\u4e3b\u8981\u6765\u81ea\u7edf\u8ba1\u4fee\u6539\uff08\u5982\u97f3\u9ad8\u53d8\u6362\u3001\u6ee4\u6ce2\u3001\u566a\u58f0\u6dfb\u52a0\u3001\u91cf\u5316\uff09\u548c\u4f18\u5316\u653b\u51fb\uff08\u5982FGSM\u3001PGD\u3001C&W\u3001DeepFool\uff09\u3002", "conclusion": "\u8fd9\u4efd\u5206\u6790\u4e3a\u8bbe\u8ba1\u66f4\u7a33\u5065\u7684\u97f3\u9891\u751f\u7269\u8bc6\u522b\u68c0\u6d4b\u5668\u63d0\u4f9b\u4e86\u6307\u5bfc\uff0c\u5e76\u5c06\u63a8\u52a8\u672a\u6765\u7814\u7a76\u53d1\u5c55\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u6f02\u79fb\u53cd\u53f8\u6cd5\u6280\u672f\u7684\u9002\u5e94\u6027\u9632\u5fa1\u7b56\u7565\u3002"}}
{"id": "2509.07416", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07416", "abs": "https://arxiv.org/abs/2509.07416", "authors": ["Lianming Hu", "Xiaotong Zhang", "Kamal Youcef-Toumi"], "title": "Eye Movement Feature-Guided Signal De-Drifting in Electrooculography Systems", "comment": "This manuscript has been accepted for presentation at the 2025 IEEE\n  21st International Conference on Automation Science and Engineering (CASE)\n  and is currently under publication", "summary": "Electrooculography (EOG) is widely used for gaze tracking in Human-Robot\nCollaboration (HRC). However, baseline drift caused by low-frequency noise\nsignificantly impacts the accuracy of EOG signals, creating challenges for\nfurther sensor fusion. This paper presents an Eye Movement Feature-Guided\nDe-drift (FGD) method for mitigating drift artifacts in EOG signals. The\nproposed approach leverages active eye-movement feature recognition to\nreconstruct the feature-extracted EOG baseline and adaptively correct signal\ndrift while preserving the morphological integrity of the EOG waveform. The FGD\nis evaluated using both simulation data and real-world data, achieving a\nsignificant reduction in mean error. The average error is reduced to\n0.896{\\deg} in simulation, representing a 36.29% decrease, and to 1.033{\\deg}\nin real-world data, corresponding to a 26.53% reduction. Despite additional and\nunpredictable noise in real-world data, the proposed method consistently\noutperforms conventional de-drifting techniques, demonstrating its\neffectiveness in practical applications such as enhancing human performance\naugmentation.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u773c\u52a8\u7279\u5f81\u5f15\u5bfc\u7684\u53bb\u6f02\u79fb\u65b9\u6cd5(FGD)\uff0c\u6709\u6548\u89e3\u51b3EOG\u4fe1\u53f7\u4e2d\u7684\u57fa\u7ebf\u6f02\u79fb\u95ee\u9898\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u773c\u52a8\u8ffd\u8e2a\u7cbe\u5ea6", "motivation": "EOG\u4fe1\u53f7\u4e2d\u7684\u4f4e\u9891\u566a\u58f0\u5bfc\u81f4\u7684\u57fa\u7ebf\u6f02\u79fb\u4e25\u91cd\u5f71\u54cd\u773c\u52a8\u8ffd\u8e2a\u7cbe\u5ea6\uff0c\u7ed9\u4f20\u611f\u5668\u878d\u5408\u5e26\u6765\u6311\u6218\uff0c\u9700\u8981\u6709\u6548\u7684\u53bb\u6f02\u79fb\u65b9\u6cd5", "method": "\u5229\u7528\u4e3b\u52a8\u773c\u52a8\u7279\u5f81\u8bc6\u522b\u6280\u672f\u91cd\u6784\u7279\u5f81\u63d0\u53d6\u7684EOG\u57fa\u7ebf\uff0c\u81ea\u9002\u5e94\u6821\u6b63\u4fe1\u53f7\u6f02\u79fb\uff0c\u540c\u65f6\u4fdd\u6301EOG\u6ce2\u5f62\u5f62\u6001\u5b8c\u6574\u6027", "result": "\u5728\u4eff\u771f\u6570\u636e\u4e2d\u5e73\u5747\u8bef\u5dee\u964d\u81f30.896\u00b0\uff0c\u51cf\u5c1136.29%\uff1b\u5728\u771f\u5b9e\u6570\u636e\u4e2d\u964d\u81f31.033\u00b0\uff0c\u51cf\u5c1126.53%\uff0c\u4f18\u4e8e\u4f20\u7edf\u53bb\u6f02\u79fb\u6280\u672f", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u8868\u73b0\u7a33\u5b9a\uff0c\u80fd\u6709\u6548\u63d0\u5347\u4eba\u673a\u534f\u4f5c\u4e2d\u7684\u4eba\u7c7b\u6027\u80fd\u589e\u5f3a\u5e94\u7528\u6548\u679c"}}
{"id": "2509.07323", "categories": ["cs.SD", "cs.CR"], "pdf": "https://arxiv.org/pdf/2509.07323", "abs": "https://arxiv.org/abs/2509.07323", "authors": ["Bin Hu", "Kunyang Huang", "Daehan Kwak", "Meng Xu", "Kuan Huang"], "title": "When Fine-Tuning is Not Enough: Lessons from HSAD on Hybrid and Adversarial Audio Spoof Detection", "comment": "13 pages, 11 figures.This work has been submitted to the IEEE for\n  possible publication", "summary": "The rapid advancement of AI has enabled highly realistic speech synthesis and\nvoice cloning, posing serious risks to voice authentication, smart assistants,\nand telecom security. While most prior work frames spoof detection as a binary\ntask, real-world attacks often involve hybrid utterances that mix genuine and\nsynthetic speech, making detection substantially more challenging. To address\nthis gap, we introduce the Hybrid Spoofed Audio Dataset (HSAD), a benchmark\ncontaining 1,248 clean and 41,044 degraded utterances across four classes:\nhuman, cloned, zero-shot AI-generated, and hybrid audio. Each sample is\nannotated with spoofing method, speaker identity, and degradation metadata to\nenable fine-grained analysis. We evaluate six transformer-based models,\nincluding spectrogram encoders (MIT-AST, MattyB95-AST) and self-supervised\nwaveform models (Wav2Vec2, HuBERT). Results reveal critical lessons: pretrained\nmodels overgeneralize and collapse under hybrid conditions; spoof-specific\nfine-tuning improves separability but struggles with unseen compositions; and\ndataset-specific adaptation on HSAD yields large performance gains (AST greater\nthan 97 percent and F1 score is approximately 99 percent), though residual\nerrors persist for complex hybrids. These findings demonstrate that fine-tuning\nalone is not sufficient-robust hybrid-aware benchmarks like HSAD are essential\nto expose calibration failures, model biases, and factors affecting spoof\ndetection in adversarial environments. HSAD thus provides both a dataset and an\nanalytic framework for building resilient and trustworthy voice authentication\nsystems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u6df7\u5408\u6b3a\u9a97\u97f3\u9891\u6570\u636e\u96c6(HSAD)\uff0c\u5305\u542b4\u7c7b\u97f3\u9891\u6837\u672c\uff0c\u8bc4\u4f30\u4e866\u79cd\u57fa\u4e8eTransformer\u7684\u6a21\u578b\uff0c\u53d1\u73b0\u5728\u6df7\u5408\u97f3\u9891\u6761\u4ef6\u4e0b\u9884\u8bad\u7ec3\u6a21\u578b\u8868\u73b0\u4e0d\u4f73\uff0c\u800c\u9488\u5bf9\u6027\u7684\u5fae\u8c03\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4f46\u590d\u6742\u6df7\u5408\u97f3\u9891\u4ecd\u5b58\u5728\u68c0\u6d4b\u6311\u6218\u3002", "motivation": "\u968f\u7740AI\u8bed\u97f3\u5408\u6210\u548c\u514b\u9686\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u73b0\u6709\u7684\u4e8c\u8fdb\u5236\u6b3a\u9a97\u68c0\u6d4b\u65b9\u6cd5\u96be\u4ee5\u5e94\u5bf9\u771f\u5b9e\u4e16\u754c\u4e2d\u6df7\u5408\u4e86\u771f\u5b9e\u548c\u5408\u6210\u8bed\u97f3\u7684\u6df7\u5408\u97f3\u9891\u653b\u51fb\uff0c\u9700\u8981\u66f4\u7ec6\u7c92\u5ea6\u7684\u68c0\u6d4b\u57fa\u51c6\u3002", "method": "\u6784\u5efa\u4e86\u5305\u542b41,044\u4e2a\u9000\u5316\u97f3\u9891\u6837\u672c\u7684HSAD\u6570\u636e\u96c6\uff0c\u6db5\u76d6\u4eba\u7c7b\u3001\u514b\u9686\u3001\u96f6\u6837\u672cAI\u751f\u6210\u548c\u6df7\u5408\u97f3\u9891\u56db\u7c7b\uff0c\u5e76\u8bc4\u4f30\u4e86\u5305\u62ec\u9891\u8c31\u56fe\u7f16\u7801\u5668\u548c\u81ea\u76d1\u7763\u6ce2\u5f62\u6a21\u578b\u5728\u5185\u76846\u79cdTransformer\u6a21\u578b\u3002", "result": "\u9884\u8bad\u7ec3\u6a21\u578b\u5728\u6df7\u5408\u6761\u4ef6\u4e0b\u8fc7\u5ea6\u6cdb\u5316\u4e14\u6027\u80fd\u5d29\u6e83\uff1b\u9488\u5bf9\u6b3a\u9a97\u68c0\u6d4b\u7684\u5fae\u8c03\u63d0\u9ad8\u4e86\u53ef\u5206\u6027\u4f46\u5bf9\u672a\u89c1\u7ec4\u5408\u4ecd\u56f0\u96be\uff1b\u5728HSAD\u4e0a\u7684\u6570\u636e\u96c6\u7279\u5b9a\u9002\u914d\u83b7\u5f97\u4e86\u663e\u8457\u6027\u80fd\u63d0\u5347(AST>97%\uff0cF1\u224899%)\uff0c\u4f46\u590d\u6742\u6df7\u5408\u97f3\u9891\u4ecd\u5b58\u5728\u6b8b\u7559\u9519\u8bef\u3002", "conclusion": "\u4ec5\u9760\u5fae\u8c03\u4e0d\u8db3\u591f\uff0c\u9700\u8981\u50cfHSAD\u8fd9\u6837\u7684\u6df7\u5408\u611f\u77e5\u57fa\u51c6\u6765\u66b4\u9732\u6821\u51c6\u5931\u8d25\u548c\u6a21\u578b\u504f\u5dee\uff0cHSAD\u4e3a\u6784\u5efa\u9c81\u68d2\u53ef\u4fe1\u7684\u8bed\u97f3\u8ba4\u8bc1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6570\u636e\u96c6\u548c\u5206\u6790\u6846\u67b6\u3002"}}
{"id": "2509.07422", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07422", "abs": "https://arxiv.org/abs/2509.07422", "authors": ["Lu Bai", "Zengrui Han", "Xuesong Cai", "Xiang Cheng"], "title": "Multi-Modal Intelligent Channel Modeling Framework for 6G-Enabled Networked Intelligent Systems", "comment": null, "summary": "The design and technology development of 6G-enabled networked intelligent\nsystems needs an accurate real-time channel model as the cornerstone. However,\nwith the new requirements of 6G-enabled networked intelligent systems, the\nconventional channel modeling methods face many limitations. Fortunately, the\nmulti-modal sensors equipped on the intelligent agents bring timely\nopportunities, i.e., the intelligent integration and mutually beneficial\nmechanism between communications and multi-modal sensing could be investigated\nbased on the artificial intelligence (AI) technologies. In this case, the\nmapping relationship between physical environment and electromagnetic channel\ncould be explored via Synesthesia of Machines (SoM). This article presents a\nnovel multi-modal intelligent channel modeling (MMICM) framework for 6G-enabled\nnetworked intelligent systems, which establishes a nonlinear model between\nmulti-modal sensing and channel characteristics, including large-scale and\nsmall-scale channel characteristics. The architecture and features of proposed\nintelligent modeling framework are expounded and the key technologies involved\nare also analyzed. Finally, the system-engaged applications and potential\nresearch directions of MMICM framework are outlined.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u9762\u54116G\u7f51\u7edc\u667a\u80fd\u7cfb\u7edf\u7684\u591a\u6a21\u6001\u667a\u80fd\u4fe1\u9053\u5efa\u6a21\u6846\u67b6(MMICM)\uff0c\u901a\u8fc7\u673a\u5668\u8054\u89c9\u6280\u672f\u5efa\u7acb\u591a\u6a21\u6001\u611f\u77e5\u4e0e\u4fe1\u9053\u7279\u6027\u4e4b\u95f4\u7684\u975e\u7ebf\u6027\u6620\u5c04\u5173\u7cfb", "motivation": "6G\u7f51\u7edc\u667a\u80fd\u7cfb\u7edf\u9700\u8981\u7cbe\u786e\u7684\u5b9e\u65f6\u4fe1\u9053\u6a21\u578b\uff0c\u4f46\u4f20\u7edf\u4fe1\u9053\u5efa\u6a21\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\u3002\u667a\u80fd\u4f53\u914d\u5907\u7684\u591a\u6a21\u6001\u4f20\u611f\u5668\u4e3a\u901a\u4fe1\u4e0e\u591a\u6a21\u6001\u611f\u77e5\u7684\u667a\u80fd\u96c6\u6210\u63d0\u4f9b\u4e86\u65b0\u673a\u9047", "method": "\u57fa\u4e8e\u4eba\u5de5\u667a\u80fd\u6280\u672f\uff0c\u901a\u8fc7\u673a\u5668\u8054\u89c9(SoM)\u63a2\u7d22\u7269\u7406\u73af\u5883\u4e0e\u7535\u78c1\u4fe1\u9053\u4e4b\u95f4\u7684\u6620\u5c04\u5173\u7cfb\uff0c\u5efa\u7acb\u591a\u6a21\u6001\u611f\u77e5\u4e0e\u4fe1\u9053\u7279\u6027(\u5927\u5c3a\u5ea6\u548c\u5c0f\u5c3a\u5ea6)\u4e4b\u95f4\u7684\u975e\u7ebf\u6027\u6a21\u578b", "result": "\u63d0\u51fa\u4e86MMICM\u6846\u67b6\u7684\u67b6\u6784\u548c\u7279\u6027\uff0c\u5206\u6790\u4e86\u6d89\u53ca\u7684\u5173\u952e\u6280\u672f", "conclusion": "\u6982\u8ff0\u4e86\u8be5\u6846\u67b6\u7684\u7cfb\u7edf\u5e94\u7528\u548c\u6f5c\u5728\u7814\u7a76\u65b9\u5411\uff0c\u4e3a6G\u7f51\u7edc\u667a\u80fd\u7cfb\u7edf\u63d0\u4f9b\u4e86\u521b\u65b0\u7684\u4fe1\u9053\u5efa\u6a21\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.07635", "categories": ["cs.SD", "cs.LG", "eess.AS", "68T07", "H.5.5; J.5; I.5.4"], "pdf": "https://arxiv.org/pdf/2509.07635", "abs": "https://arxiv.org/abs/2509.07635", "authors": ["Paolo Combes", "Stefan Weinzierl", "Klaus Obermayer"], "title": "Neural Proxies for Sound Synthesizers: Learning Perceptually Informed Preset Representations", "comment": "17 pages, 4 figures, published in the Journal of the Audio\n  Engineering Society", "summary": "Deep learning appears as an appealing solution for Automatic Synthesizer\nProgramming (ASP), which aims to assist musicians and sound designers in\nprogramming sound synthesizers. However, integrating software synthesizers into\ntraining pipelines is challenging due to their potential non-differentiability.\nThis work tackles this challenge by introducing a method to approximate\narbitrary synthesizers. Specifically, we train a neural network to map\nsynthesizer presets onto an audio embedding space derived from a pretrained\nmodel. This facilitates the definition of a neural proxy that produces compact\nyet effective representations, thereby enabling the integration of audio\nembedding loss into neural-based ASP systems for black-box synthesizers. We\nevaluate the representations derived by various pretrained audio models in the\ncontext of neural-based nASP and assess the effectiveness of several neural\nnetwork architectures, including feedforward, recurrent, and transformer-based\nmodels, in defining neural proxies. We evaluate the proposed method using both\nsynthetic and hand-crafted presets from three popular software synthesizers and\nassess its performance in a synthesizer sound matching downstream task. While\nthe benefits of the learned representation are nuanced by resource\nrequirements, encouraging results were obtained for all synthesizers, paving\nthe way for future research into the application of synthesizer proxies for\nneural-based ASP systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3c\u4efb\u610f\u5408\u6210\u5668\u7684\u65b9\u6cd5\uff0c\u5c06\u5408\u6210\u5668\u9884\u8bbe\u6620\u5c04\u5230\u9884\u8bad\u7ec3\u97f3\u9891\u5d4c\u5165\u7a7a\u95f4\uff0c\u4e3a\u9ed1\u76d2\u5408\u6210\u5668\u7684\u81ea\u52a8\u7f16\u7a0b\u63d0\u4f9b\u795e\u7ecf\u4ee3\u7406\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u81ea\u52a8\u5408\u6210\u5668\u7f16\u7a0b\u4e2d\u5f88\u6709\u524d\u666f\uff0c\u4f46\u7531\u4e8e\u8f6f\u4ef6\u5408\u6210\u5668\u7684\u6f5c\u5728\u4e0d\u53ef\u5fae\u5206\u6027\uff0c\u5c06\u5176\u96c6\u6210\u5230\u8bad\u7ec3\u7ba1\u9053\u4e2d\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u5c06\u5408\u6210\u5668\u9884\u8bbe\u6620\u5c04\u5230\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u97f3\u9891\u5d4c\u5165\u7a7a\u95f4\uff0c\u4f7f\u7528\u524d\u9988\u3001\u5faa\u73af\u548c\u57fa\u4e8etransformer\u7684\u67b6\u6784\u5b9a\u4e49\u795e\u7ecf\u4ee3\u7406\u3002", "result": "\u5728\u4e09\u4e2a\u6d41\u884c\u8f6f\u4ef6\u5408\u6210\u5668\u4e0a\u8bc4\u4f30\uff0c\u5728\u5408\u6210\u5668\u58f0\u97f3\u5339\u914d\u4efb\u52a1\u4e2d\u83b7\u5f97\u4ee4\u4eba\u9f13\u821e\u7684\u7ed3\u679c\uff0c\u5c3d\u7ba1\u5b66\u4e60\u8868\u793a\u7684\u597d\u5904\u53d7\u5230\u8d44\u6e90\u9700\u6c42\u7684\u9650\u5236\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u81ea\u52a8\u5408\u6210\u5668\u7f16\u7a0b\u7cfb\u7edf\u7684\u5408\u6210\u5668\u4ee3\u7406\u5e94\u7528\u5f00\u8f9f\u4e86\u672a\u6765\u7814\u7a76\u9053\u8def\u3002"}}
{"id": "2509.07376", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2509.07376", "abs": "https://arxiv.org/abs/2509.07376", "authors": ["Yejin Jeon", "Youngjae Kim", "Jihyun Lee", "Hyounghun Kim", "Gary Geunbae Lee"], "title": "Progressive Facial Granularity Aggregation with Bilateral Attribute-based Enhancement for Face-to-Speech Synthesis", "comment": "EMNLP Findings", "summary": "For individuals who have experienced traumatic events such as strokes, speech\nmay no longer be a viable means of communication. While text-to-speech (TTS)\ncan be used as a communication aid since it generates synthetic speech, it\nfails to preserve the user's own voice. As such, face-to-voice (FTV) synthesis,\nwhich derives corresponding voices from facial images, provides a promising\nalternative. However, existing methods rely on pre-trained visual encoders, and\nfinetune them to align with speech embeddings, which strips fine-grained\ninformation from facial inputs such as gender or ethnicity, despite their known\ncorrelation with vocal traits. Moreover, these pipelines are multi-stage, which\nrequires separate training of multiple components, thus leading to training\ninefficiency. To address these limitations, we utilize fine-grained facial\nattribute modeling by decomposing facial images into non-overlapping segments\nand progressively integrating them into a multi-granular representation. This\nrepresentation is further refined through multi-task learning of speaker\nattributes such as gender and ethnicity at both the visual and acoustic\ndomains. Moreover, to improve alignment robustness, we adopt a multi-view\ntraining strategy by pairing various visual perspectives of a speaker in terms\nof different angles and lighting conditions, with identical speech recordings.\nExtensive subjective and objective evaluations confirm that our approach\nsubstantially enhances face-voice congruence and synthesis stability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u7684\u7ec6\u7c92\u5ea6\u9762\u90e8\u5c5e\u6027\u5efa\u6a21\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u89e3\u9762\u90e8\u56fe\u50cf\u5e76\u9010\u6b65\u6574\u5408\u591a\u7c92\u5ea6\u8868\u793a\uff0c\u7ed3\u5408\u591a\u4efb\u52a1\u5b66\u4e60\u548c\u591a\u89c6\u89d2\u8bad\u7ec3\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4e86\u9762\u90e8\u5230\u8bed\u97f3\u5408\u6210\u7684\u8d28\u91cf\u548c\u7a33\u5b9a\u6027\u3002", "motivation": "\u9488\u5bf9\u4e2d\u98ce\u7b49\u521b\u4f24\u60a3\u8005\u65e0\u6cd5\u6b63\u5e38\u8bf4\u8bdd\u7684\u95ee\u9898\uff0c\u73b0\u6709\u6587\u672c\u8f6c\u8bed\u97f3\u6280\u672f\u65e0\u6cd5\u4fdd\u7559\u7528\u6237\u539f\u58f0\uff0c\u800c\u73b0\u6709\u4eba\u8138\u5230\u8bed\u97f3\u5408\u6210\u65b9\u6cd5\u4f9d\u8d56\u9884\u8bad\u7ec3\u89c6\u89c9\u7f16\u7801\u5668\uff0c\u4e22\u5931\u4e86\u6027\u522b\u3001\u79cd\u65cf\u7b49\u7ec6\u7c92\u5ea6\u4fe1\u606f\uff0c\u4e14\u591a\u9636\u6bb5\u8bad\u7ec3\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u5c06\u9762\u90e8\u56fe\u50cf\u5206\u89e3\u4e3a\u4e0d\u91cd\u53e0\u7247\u6bb5\uff0c\u9010\u6b65\u6574\u5408\u6210\u591a\u7c92\u5ea6\u8868\u793a\uff1b\u901a\u8fc7\u591a\u4efb\u52a1\u5b66\u4e60\u5728\u89c6\u89c9\u548c\u58f0\u5b66\u57df\u540c\u65f6\u5efa\u6a21\u8bf4\u8bdd\u8005\u5c5e\u6027\uff1b\u91c7\u7528\u591a\u89c6\u89d2\u8bad\u7ec3\u7b56\u7565\uff0c\u5c06\u4e0d\u540c\u89d2\u5ea6\u548c\u5149\u7167\u6761\u4ef6\u4e0b\u7684\u9762\u90e8\u56fe\u50cf\u4e0e\u76f8\u540c\u8bed\u97f3\u914d\u5bf9\u3002", "result": "\u7ecf\u8fc7\u5e7f\u6cdb\u7684\u4e3b\u5ba2\u89c2\u8bc4\u4f30\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u589e\u5f3a\u4e86\u9762\u90e8-\u8bed\u97f3\u4e00\u81f4\u6027\u548c\u5408\u6210\u7a33\u5b9a\u6027\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7ec6\u7c92\u5ea6\u9762\u90e8\u5c5e\u6027\u5efa\u6a21\u548c\u591a\u89c6\u89d2\u8bad\u7ec3\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u4eba\u8138\u5230\u8bed\u97f3\u5408\u6210\u6280\u672f\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u65e0\u6cd5\u6b63\u5e38\u8bf4\u8bdd\u7684\u60a3\u8005\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u6c9f\u901a\u8f85\u52a9\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.07432", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07432", "abs": "https://arxiv.org/abs/2509.07432", "authors": ["Senith Jayakody", "Kalana Jayasooriya", "Sashini Liyanage", "Roshan Godaliyadda", "Parakrama Ekanayake", "Chathura Rathnayake"], "title": "Spectrotemporal Feature Extraction in EHG Signals and Tocograms for Enhanced Preterm Birth Prediction", "comment": "12 pages, 4 figures, 5 tables, manuscript under review", "summary": "Preterm birth (PTB), defined as delivery before 37 weeks of gestation, is a\nleading cause of neonatal mortality and long term health complications. Early\ndetection is essential for enabling timely medical interventions.\nElectrohysterography (EHG) and tocography (TOCO) are promising non invasive\ntools for PTB prediction, but prior studies often suffer from class imbalance,\nimproper oversampling, and reliance on features with limited physiological\nrelevance. This work presents a machine learning pipeline incorporating robust\npreprocessing, physiologically grounded feature extraction, and rigorous\nevaluation. Features were extracted from EHG (and TOCO) signals using Mel\nfrequency cepstral coefficients, statistical descriptors of wavelet\ncoefficients, and peaks of the normalized power spectrum. Signal quality was\nenhanced via Karhunen Lo\\`eve Transform (KLT) denoising through eigenvalue\nbased subspace decomposition. Multiple classifiers, including Logistic\nRegression, Support Vector Machines, Random Forest, Gradient Boosting,\nMultilayer Perceptron, and CatBoost, were evaluated on the TPEHGT dataset. The\nCatBoost classifier with KLT denoising achieved the highest performance on\nfixed interval segments of the TPEHGT dataset, reaching 97.28% accuracy and an\nAUC of 0.9988. Ablation studies confirmed the critical role of both KLT\ndenoising and physiologically informed features. Comparative analysis showed\nthat including TOCO signals did not substantially improve prediction over EHG\nalone, highlighting the sufficiency of EHG for PTB detection. These results\ndemonstrate that combining denoising with domain relevant features can yield\nhighly accurate, robust, and clinically interpretable models, supporting the\ndevelopment of cost effective and accessible PTB prediction tools, particularly\nin low resource healthcare settings.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u4e2a\u7ed3\u5408\u4fe1\u53f7\u53bb\u566a\u548c\u751f\u7406\u76f8\u5173\u7279\u5f81\u63d0\u53d6\u7684\u673a\u5668\u5b66\u4e60\u6d41\u7a0b\uff0c\u7528\u4e8e\u65e9\u4ea7\u9884\u6d4b\uff0cCatBoost\u5206\u7c7b\u5668\u5728TPEHGT\u6570\u636e\u96c6\u4e0a\u8fbe\u523097.28%\u51c6\u786e\u7387\u548c0.9988 AUC\u503c\u3002", "motivation": "\u65e9\u4ea7\u662f\u65b0\u751f\u513f\u6b7b\u4ea1\u548c\u957f\u671f\u5065\u5eb7\u5e76\u53d1\u75c7\u7684\u4e3b\u8981\u539f\u56e0\uff0c\u65e9\u671f\u68c0\u6d4b\u5bf9\u53ca\u65f6\u533b\u7597\u5e72\u9884\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7814\u7a76\u5b58\u5728\u7c7b\u522b\u4e0d\u5e73\u8861\u3001\u8fc7\u91c7\u6837\u4e0d\u5f53\u548c\u7279\u5f81\u751f\u7406\u76f8\u5173\u6027\u6709\u9650\u7b49\u95ee\u9898\u3002", "method": "\u4f7f\u7528Karhunen-Lo\u00e8ve\u53d8\u6362\u8fdb\u884c\u4fe1\u53f7\u53bb\u566a\uff0c\u63d0\u53d6Mel\u9891\u7387\u5012\u8c31\u7cfb\u6570\u3001\u5c0f\u6ce2\u7cfb\u6570\u7edf\u8ba1\u63cf\u8ff0\u7b26\u548c\u5f52\u4e00\u5316\u529f\u7387\u8c31\u5cf0\u503c\u7b49\u751f\u7406\u76f8\u5173\u7279\u5f81\uff0c\u8bc4\u4f30\u591a\u79cd\u5206\u7c7b\u5668\u5305\u62ec\u903b\u8f91\u56de\u5f52\u3001SVM\u3001\u968f\u673a\u68ee\u6797\u3001\u68af\u5ea6\u63d0\u5347\u3001\u591a\u5c42\u611f\u77e5\u673a\u548cCatBoost\u3002", "result": "CatBoost\u5206\u7c7b\u5668\u7ed3\u5408KLT\u53bb\u566a\u5728TPEHGT\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u6700\u4f73\u6027\u80fd\uff1a97.28%\u51c6\u786e\u7387\u548c0.9988 AUC\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e86\u53bb\u566a\u548c\u751f\u7406\u7279\u5f81\u7684\u91cd\u8981\u6027\uff0cTOCO\u4fe1\u53f7\u5e76\u672a\u663e\u8457\u63d0\u5347EHG\u5355\u72ec\u9884\u6d4b\u6548\u679c\u3002", "conclusion": "\u7ed3\u5408\u53bb\u566a\u6280\u672f\u548c\u9886\u57df\u76f8\u5173\u7279\u5f81\u53ef\u4ee5\u6784\u5efa\u9ad8\u7cbe\u5ea6\u3001\u9c81\u68d2\u4e14\u4e34\u5e8a\u53ef\u89e3\u91ca\u7684\u65e9\u4ea7\u9884\u6d4b\u6a21\u578b\uff0c\u652f\u6301\u5f00\u53d1\u6210\u672c\u6548\u76ca\u9ad8\u3001\u53ef\u53ca\u6027\u5f3a\u7684\u9884\u6d4b\u5de5\u5177\uff0c\u7279\u522b\u9002\u7528\u4e8e\u8d44\u6e90\u6709\u9650\u7684\u533b\u7597\u73af\u5883\u3002"}}
{"id": "2509.07756", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2509.07756", "abs": "https://arxiv.org/abs/2509.07756", "authors": ["Friedrich Wolf-Monheim"], "title": "Spectral and Rhythm Feature Performance Evaluation for Category and Class Level Audio Classification with Deep Convolutional Neural Networks", "comment": null, "summary": "Next to decision tree and k-nearest neighbours algorithms deep convolutional\nneural networks (CNNs) are widely used to classify audio data in many domains\nlike music, speech or environmental sounds. To train a specific CNN various\nspectral and rhythm features like mel-scaled spectrograms, mel-frequency\ncepstral coefficients (MFCC), cyclic tempograms, short-time Fourier transform\n(STFT) chromagrams, constant-Q transform (CQT) chromagrams and chroma energy\nnormalized statistics (CENS) chromagrams can be used as digital image input\ndata for the neural network. The performance of these spectral and rhythm\nfeatures for audio category level as well as audio class level classification\nis investigated in detail with a deep CNN and the ESC-50 dataset with 2,000\nlabeled environmental audio recordings using an end-to-end deep learning\npipeline. The evaluated metrics accuracy, precision, recall and F1 score for\nmulticlass classification clearly show that the mel-scaled spectrograms and the\nmel-frequency cepstral coefficients (MFCC) perform significantly better then\nthe other spectral and rhythm features investigated in this research for audio\nclassification tasks using deep CNNs.", "AI": {"tldr": "\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5728\u97f3\u9891\u5206\u7c7b\u4e2d\u7684\u8868\u73b0\u7814\u7a76\uff0c\u6bd4\u8f83\u4e86\u591a\u79cd\u8c31\u7279\u5f81\u7684\u6548\u679c\uff0c\u53d1\u73b0mel\u8c31\u56fe\u548cMFCC\u7279\u5f81\u8868\u73b0\u6700\u4f73", "motivation": "\u7814\u7a76\u4e0d\u540c\u8c31\u7279\u5f81\u548c\u8282\u594f\u7279\u5f81\u5728\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u97f3\u9891\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u4ee5\u786e\u5b9a\u6700\u4f18\u7684\u8f93\u5165\u6570\u636e\u8868\u5f81\u65b9\u5f0f", "method": "\u4f7f\u7528ESC-50\u6570\u636e\u96c6\u76842000\u4e2a\u6807\u7b7e\u73af\u5883\u97f3\u9891\u8bb0\u5f55\uff0c\u6784\u5efa\u7aef\u5230\u7aef\u7684\u6df1\u5ea6\u5b66\u4e60\u6d41\u6c34\u7ebf\uff0c\u6bd4\u8f83mel\u8c31\u56fe\u3001MFCC\u3001\u5faa\u73af\u8282\u594f\u56fe\u3001STFT\u97f3\u9636\u56fe\u3001CQT\u97f3\u9636\u56fe\u548cCENS\u97f3\u9636\u56fe\u7b49\u591a\u79cd\u7279\u5f81\u7684\u5206\u7c7b\u6027\u80fd", "result": "\u591a\u7c7b\u5206\u7c7b\u8bc4\u4f30\u6307\u6807\uff08\u51c6\u786e\u7387\u3001\u7cbe\u5ea6\u3001\u53ec\u56de\u7387\u3001F1\u5206\u6570\uff09\u663e\u793amel\u8c31\u56fe\u548cMFCC\u7279\u5f81\u7684\u8868\u73b0\u663e\u8457\u4f18\u4e8e\u5176\u4ed6\u8c31\u7279\u5f81\u548c\u8282\u594f\u7279\u5f81", "conclusion": "\u5bf9\u4e8e\u6df1\u5ea6\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u97f3\u9891\u5206\u7c7b\u4efb\u52a1\uff0cmel\u8c31\u56fe\u548cMFCC\u662f\u6700\u4f18\u7684\u8f93\u5165\u6570\u636e\u8868\u5f81\u65b9\u5f0f\uff0c\u5176\u6027\u80fd\u663e\u8457\u8d85\u8fc7\u5176\u4ed6\u8c31\u7279\u5f81\u548c\u8282\u594f\u7279\u5f81"}}
{"id": "2509.07521", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2509.07521", "abs": "https://arxiv.org/abs/2509.07521", "authors": ["Taihui Wang", "Rilin Chen", "Tong Lei", "Andong Li", "Jinzheng Zhao", "Meng Yu", "Dong Yu"], "title": "Target matching based generative model for speech enhancement", "comment": "12 pages, 5 figures", "summary": "The design of mean and variance schedules for the perturbed signal is a\nfundamental challenge in generative models. While score-based and Schr\\\"odinger\nbridge-based models require careful selection of the stochastic differential\nequation to derive the corresponding schedules, flow-based models address this\nissue via vector field matching. However, this strategy often leads to\nhallucination artifacts and inefficient training and inference processes due to\nthe potential inclusion of stochastic components in the vector field.\nAdditionally, the widely adopted diffusion backbone, NCSN++, suffers from high\ncomputational complexity. To overcome these limitations, we propose a novel\ntarget-based generative framework that enhances both the flexibility of\nmean/variance schedule design and the efficiency of training and inference\nprocesses. Specifically, we eliminate the stochastic components in the training\nloss by reformulating the generative speech enhancement task as a target signal\nestimation problem, which therefore leads to more stable and efficient training\nand inference processes. In addition, we employ a logistic mean schedule and a\nbridge variance schedule, which yield a more favorable signal-to-noise ratio\ntrajectory compared to several widely used schedules and thus leads to a more\nefficient perturbation strategy. Furthermore, we propose a new diffusion\nbackbone for audio, which significantly improves the efficiency over NCSN++ by\nexplicitly modeling long-term frame correlations and cross-band dependencies.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u76ee\u6807\u4fe1\u53f7\u7684\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u6d88\u9664\u8bad\u7ec3\u635f\u5931\u4e2d\u7684\u968f\u673a\u5206\u91cf\uff0c\u91c7\u7528logistic\u5747\u503c\u8c03\u5ea6\u548cbridge\u65b9\u5dee\u8c03\u5ea6\uff0c\u4ee5\u53ca\u65b0\u7684\u97f3\u9891\u6269\u6563\u9aa8\u5e72\u7f51\u7edc\uff0c\u63d0\u9ad8\u751f\u6210\u6a21\u578b\u7684\u7075\u6d3b\u6027\u548c\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u751f\u6210\u6a21\u578b\u5728\u5747\u503c\u65b9\u5dee\u8c03\u5ea6\u8bbe\u8ba1\u4e0a\u5b58\u5728\u6311\u6218\uff0c\u57fa\u4e8e\u5206\u6570\u7684\u6a21\u578b\u9700\u8981\u7cbe\u5fc3\u9009\u62e9SDE\uff0c\u6d41\u6a21\u578b\u5b58\u5728\u5e7b\u89c9\u4f2a\u5f71\u548c\u6548\u7387\u95ee\u9898\uff0cNCSN++\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u3002", "method": "\u5c06\u751f\u6210\u8bed\u97f3\u589e\u5f3a\u4efb\u52a1\u91cd\u65b0\u8868\u8ff0\u4e3a\u76ee\u6807\u4fe1\u53f7\u4f30\u8ba1\u95ee\u9898\uff0c\u6d88\u9664\u8bad\u7ec3\u635f\u5931\u4e2d\u7684\u968f\u673a\u5206\u91cf\uff1b\u91c7\u7528logistic\u5747\u503c\u8c03\u5ea6\u548cbridge\u65b9\u5dee\u8c03\u5ea6\uff1b\u63d0\u51fa\u65b0\u7684\u97f3\u9891\u6269\u6563\u9aa8\u5e72\u7f51\u7edc\uff0c\u663e\u5f0f\u5efa\u6a21\u957f\u65f6\u5e27\u76f8\u5173\u6027\u548c\u8de8\u9891\u5e26\u4f9d\u8d56\u6027\u3002", "result": "\u5b9e\u73b0\u4e86\u66f4\u7a33\u5b9a\u9ad8\u6548\u7684\u8bad\u7ec3\u548c\u63a8\u7406\u8fc7\u7a0b\uff0c\u83b7\u5f97\u4e86\u66f4\u6709\u5229\u7684\u4fe1\u566a\u6bd4\u8f68\u8ff9\uff0c\u663e\u8457\u63d0\u9ad8\u4e86NCSN++\u7684\u6548\u7387\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u76ee\u6807\u57fa\u751f\u6210\u6846\u67b6\u5728\u8c03\u5ea6\u8bbe\u8ba1\u7075\u6d3b\u6027\u548c\u8bad\u7ec3\u63a8\u7406\u6548\u7387\u65b9\u9762\u90fd\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u751f\u6210\u6a21\u578b\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.07436", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07436", "abs": "https://arxiv.org/abs/2509.07436", "authors": ["Feifan Zhang", "Yuyang Du", "Yifan Xiang", "Xiaoyan Liu", "Soung Chang Liew"], "title": "SA-OOSC: A Multimodal LLM-Distilled Semantic Communication Framework for Enhanced Coding Efficiency with Scenario Understanding", "comment": null, "summary": "This paper introduces SA-OOSC, a multimodal large language models\n(MLLM)-distilled semantic communication framework that achieves efficient\nsemantic coding with scenario-aware importance allocations. This approach\naddresses a critical limitation of existing object-oriented semantic\ncommunication (OOSC) systems - assigning static importance values to specific\nclasses of objects regardless of their contextual relevance. Our framework\nutilizes MLLMs to identify the scenario-augmented (SA) semantic importance for\nobjects within the image. Through knowledge distillation with the\nMLLM-annotated data, our vectorization/de-vectorization networks and JSCC\nencoder/decoder learn to dynamically allocate coding resources based on\ncontextual significance, i.e., distinguishing between high-importance objects\nand low-importance according to the SA scenario information of the task. The\nframework features three core innovations: a MLLM-guided knowledge distillation\npipeline, an importance-weighted variable-length JSCC framework, and novel loss\nfunction designs that facilitate the knowledge distillation within the JSCC\nframework. Experimental validation demonstrates our framework's superior coding\nefficiency over conventional semantic communication systems, with open-sourced\nMLLM-annotated and human-verified datasets established as new benchmarks for\nfuture research in semantic communications.", "AI": {"tldr": "SA-OOSC\u662f\u4e00\u4e2a\u57fa\u4e8e\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u84b8\u998f\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u573a\u666f\u611f\u77e5\u7684\u91cd\u8981\u6027\u5206\u914d\u5b9e\u73b0\u9ad8\u6548\u8bed\u4e49\u7f16\u7801\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u5bf9\u8c61\u5bfc\u5411\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u4e2d\u9759\u6001\u91cd\u8981\u6027\u5206\u914d\u7684\u5c40\u9650\u6027\u3002", "motivation": "\u73b0\u6709\u5bf9\u8c61\u5bfc\u5411\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u4e3a\u7279\u5b9a\u7c7b\u522b\u5bf9\u8c61\u5206\u914d\u9759\u6001\u91cd\u8981\u6027\u503c\uff0c\u5ffd\u7565\u4e86\u4e0a\u4e0b\u6587\u76f8\u5173\u6027\uff0c\u5bfc\u81f4\u7f16\u7801\u6548\u7387\u4f4e\u4e0b\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u6839\u636e\u573a\u666f\u4e0a\u4e0b\u6587\u52a8\u6001\u5206\u914d\u7f16\u7801\u8d44\u6e90\u7684\u7cfb\u7edf\u3002", "method": "\u5229\u7528\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u8bc6\u522b\u56fe\u50cf\u4e2d\u5bf9\u8c61\u7684\u573a\u666f\u589e\u5f3a\u8bed\u4e49\u91cd\u8981\u6027\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u8bad\u7ec3\u5411\u91cf\u5316/\u53cd\u5411\u91cf\u5316\u7f51\u7edc\u548cJSCC\u7f16\u7801\u5668/\u89e3\u7801\u5668\uff0c\u5b9e\u73b0\u57fa\u4e8e\u4e0a\u4e0b\u6587\u91cd\u8981\u6027\u7684\u52a8\u6001\u7f16\u7801\u8d44\u6e90\u5206\u914d\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u8868\u660e\u8be5\u6846\u67b6\u5728\u7f16\u7801\u6548\u7387\u4e0a\u4f18\u4e8e\u4f20\u7edf\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\uff0c\u5e76\u5efa\u7acb\u4e86\u5f00\u6e90\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6807\u6ce8\u548c\u4eba\u5de5\u9a8c\u8bc1\u6570\u636e\u96c6\u4f5c\u4e3a\u65b0\u57fa\u51c6\u3002", "conclusion": "SA-OOSC\u6846\u67b6\u901a\u8fc7\u573a\u666f\u611f\u77e5\u7684\u91cd\u8981\u6027\u5206\u914d\u548c\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u7684\u77e5\u8bc6\u84b8\u998f\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8bed\u4e49\u901a\u4fe1\u7684\u7f16\u7801\u6548\u7387\uff0c\u4e3a\u672a\u6765\u8bed\u4e49\u901a\u4fe1\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u57fa\u51c6\u548c\u65b9\u6cd5\u8bba\u3002"}}
{"id": "2509.07526", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2509.07526", "abs": "https://arxiv.org/abs/2509.07526", "authors": ["Gokul Karthik Kumar", "Rishabh Saraf", "Ludovick Lepauloux", "Abdul Muneer", "Billel Mokeddem", "Hakim Hacid"], "title": "Competitive Audio-Language Models with Data-Efficient Single-Stage Training on Public Data", "comment": "Accepted at ASRU 2025", "summary": "Large language models (LLMs) have transformed NLP, yet their integration with\naudio remains underexplored -- despite audio's centrality to human\ncommunication. We introduce Falcon3-Audio, a family of Audio-Language Models\n(ALMs) built on instruction-tuned LLMs and Whisper encoders. Using a remarkably\nsmall amount of public audio data -- less than 30K hours (5K unique) --\nFalcon3-Audio-7B matches the best reported performance among open-weight models\non the MMAU benchmark, with a score of 64.14, matching R1-AQA, while\ndistinguishing itself through superior data and parameter efficiency,\nsingle-stage training, and transparency. Notably, our smallest 1B model remains\ncompetitive with larger open models ranging from 2B to 13B parameters. Through\nextensive ablations, we find that common complexities -- such as curriculum\nlearning, multiple audio encoders, and intricate cross-attention connectors --\nare not required for strong performance, even compared to models trained on\nover 500K hours of data.", "AI": {"tldr": "Falcon3-Audio\u662f\u4e00\u4e2a\u57fa\u4e8e\u6307\u4ee4\u8c03\u4f18LLM\u548cWhisper\u7f16\u7801\u5668\u7684\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u5bb6\u65cf\uff0c\u4ec5\u4f7f\u7528\u5c11\u91cf\u516c\u5f00\u97f3\u9891\u6570\u636e\uff08<30K\u5c0f\u65f6\uff09\u5c31\u5728MMAU\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230\u6700\u4f73\u6027\u80fd\uff0c\u5c55\u73b0\u4e86\u5353\u8d8a\u7684\u6570\u636e\u548c\u53c2\u6570\u6548\u7387\u3002", "motivation": "\u5c3d\u7ba1\u97f3\u9891\u5728\u4eba\u7c7b\u4ea4\u6d41\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5927\u578b\u8bed\u8a00\u6a21\u578b\u4e0e\u97f3\u9891\u7684\u6574\u5408\u4ecd\u672a\u88ab\u5145\u5206\u63a2\u7d22\u3002", "method": "\u57fa\u4e8e\u6307\u4ee4\u8c03\u4f18\u7684LLM\u548cWhisper\u7f16\u7801\u5668\u6784\u5efa\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\uff0c\u91c7\u7528\u5355\u9636\u6bb5\u8bad\u7ec3\uff0c\u907f\u514d\u4e86\u8bfe\u7a0b\u5b66\u4e60\u3001\u591a\u97f3\u9891\u7f16\u7801\u5668\u548c\u590d\u6742\u4ea4\u53c9\u6ce8\u610f\u529b\u8fde\u63a5\u5668\u7b49\u5e38\u89c1\u590d\u6742\u6027\u3002", "result": "7B\u6a21\u578b\u5728MMAU\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u83b7\u5f9764.14\u5206\uff0c\u4e0eR1-AQA\u76f8\u5f53\uff1b1B\u6a21\u578b\u4ecd\u80fd\u4e0e2B-13B\u53c2\u6570\u7684\u5927\u578b\u5f00\u653e\u6a21\u578b\u7ade\u4e89\u3002\u6a21\u578b\u5728\u4ec5\u4f7f\u7528\u4e0d\u523030K\u5c0f\u65f6\u6570\u636e\u7684\u60c5\u51b5\u4e0b\uff0c\u6027\u80fd\u53ef\u4e0e\u4f7f\u7528\u8d85\u8fc7500K\u5c0f\u65f6\u6570\u636e\u7684\u6a21\u578b\u76f8\u5ab2\u7f8e\u3002", "conclusion": "Falcon3-Audio\u8bc1\u660e\u4e86\u901a\u8fc7\u7b80\u6d01\u7684\u67b6\u6784\u8bbe\u8ba1\u548c\u9ad8\u6548\u7684\u6570\u636e\u5229\u7528\uff0c\u53ef\u4ee5\u5728\u97f3\u9891-\u8bed\u8a00\u5efa\u6a21\u9886\u57df\u5b9e\u73b0\u5353\u8d8a\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7684\u97f3\u9891AI\u7814\u7a76\u63d0\u4f9b\u4e86\u65b0\u7684\u65b9\u5411\u3002"}}
{"id": "2509.07441", "categories": ["eess.SP", "94A12", "C.2.1"], "pdf": "https://arxiv.org/pdf/2509.07441", "abs": "https://arxiv.org/abs/2509.07441", "authors": ["Sangjun Hwang", "Chan-Byoung Chae"], "title": "Node Position Estimation in Diffusion-Based Molecular Communications Using Multi-Layer Perceptron", "comment": "2 pages, 2 figures; accepted to ACM NanoCom '25 (short paper). This\n  arXiv version is the author-accepted manuscript", "summary": "This paper proposes a method for accurately estimating the relative position\nbetween two nodes with unknown locations in a diffusion-based molecular\ncommunication environment. A specialized node structure is designed, combining\na central absorbing receiver with multiple transmitters placed at predefined\nspherical coordinates. Pilot molecules are released, and their absorption time\nand concentration are measured. By partitioning the spherical coordinate space,\nthese spatially distinct measurements serve as input to a multilayer perceptron\n(MLP)-based model. The proposed method significantly improves the precision of\ndistance and direction estimation. Simulation results demonstrate localization\naccuracy, confirming the effectiveness of the neural network model in capturing\nthe underlying physical characteristics.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5728\u5206\u5b50\u901a\u4fe1\u73af\u5883\u4e2d\u4f7f\u7528\u795e\u7ecf\u7f51\u7edc\u51c6\u786e\u4f30\u8ba1\u4e24\u4e2a\u672a\u77e5\u4f4d\u7f6e\u8282\u70b9\u95f4\u76f8\u5bf9\u4f4d\u7f6e\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7279\u6b8a\u8282\u70b9\u7ed3\u6784\u548c\u7403\u5f62\u5750\u6807\u6d4b\u91cf\u5b9e\u73b0\u7cbe\u786e\u5b9a\u4f4d", "motivation": "\u5728\u57fa\u4e8e\u6269\u6563\u7684\u5206\u5b50\u901a\u4fe1\u73af\u5883\u4e2d\uff0c\u51c6\u786e\u4f30\u8ba1\u4e24\u4e2a\u672a\u77e5\u4f4d\u7f6e\u8282\u70b9\u4e4b\u95f4\u7684\u76f8\u5bf9\u4f4d\u7f6e\u662f\u4e00\u4e2a\u91cd\u8981\u4f46\u5177\u6709\u6311\u6218\u6027\u7684\u95ee\u9898\uff0c\u9700\u8981\u9ad8\u7cbe\u5ea6\u7684\u8ddd\u79bb\u548c\u65b9\u5411\u4f30\u8ba1\u65b9\u6cd5", "method": "\u8bbe\u8ba1\u4e13\u7528\u8282\u70b9\u7ed3\u6784\uff08\u4e2d\u5fc3\u5438\u6536\u63a5\u6536\u5668+\u591a\u4e2a\u7403\u5f62\u5750\u6807\u53d1\u5c04\u5668\uff09\uff0c\u91ca\u653e\u5bfc\u9891\u5206\u5b50\u5e76\u6d4b\u91cf\u5438\u6536\u65f6\u95f4\u548c\u6d53\u5ea6\uff0c\u901a\u8fc7\u7403\u5f62\u5750\u6807\u7a7a\u95f4\u5206\u533a\uff0c\u5c06\u7a7a\u95f4\u6d4b\u91cf\u6570\u636e\u8f93\u5165\u591a\u5c42\u611f\u77e5\u5668(MLP)\u6a21\u578b", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u8ddd\u79bb\u548c\u65b9\u5411\u4f30\u8ba1\u7684\u7cbe\u5ea6\uff0c\u9a8c\u8bc1\u4e86\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u5728\u6355\u6349\u5e95\u5c42\u7269\u7406\u7279\u6027\u65b9\u9762\u7684\u6709\u6548\u6027", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\u5728\u5206\u5b50\u901a\u4fe1\u73af\u5883\u4e2d\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u7684\u76f8\u5bf9\u4f4d\u7f6e\u4f30\u8ba1\uff0c\u4e3a\u5206\u5b50\u901a\u4fe1\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2509.07442", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07442", "abs": "https://arxiv.org/abs/2509.07442", "authors": ["Ashish Patwari", "Andr\u00e9s Alay\u00f3n Glazunov"], "title": "A Systematic Framework to Test the Resilience of Three-Fold Redundant Sparse Arrays Against Two Sensor Failures and Some Never-Before Findings", "comment": "6 pages, 5 Figures, and 2 Tables", "summary": "As the field of sparse arrays progressed, numerous array designs have been\nintroduced with a focus on larger apertures and higher degrees of freedom\n(DOFs), resulting in maximally economic sparse arrays (MESAs) that operate with\nthe least number of sensors required to provide a given aperture while ensuring\na hole-free difference coarray (DCA). Consequently, MESAs are least robust to\nsensor failures and cannot afford the failure of even a single sensor.\nMultifold redundant sparse arrays (MFRSAs) provide a practical solution to the\nproblem of sensor failures in sparse arrays by making sure that the array\ncontains enough sensor pairs necessary to produce each spatial lag multiple\ntimes. Owing to this property, a \\b{eta}-fold redundant array can withstand\nsimultaneous failure of at least \\b{eta}-1 sensors without losing the hole-free\nDCA property. Nevertheless, MFRSAs are also prone to hidden dependencies that\nprevent them from being fully robust. In this work, we present a systematic\nframework to evaluate the robustness of triple redundant sparse linear arrays\n(TRSLAs) against all possible two-sensor failures. After detailing the proposed\napproach, we present the failure analysis of representative TRSLAs available in\nexisting literature. It is found that existing TRSLAs have some hidden\nvulnerabilities against the failure of some peculiar sensor pairs.\nCorresponding MATLAB programs and numerical simulations are provided for\nevaluation and use by the array processing community. The proposed approach has\na great archival value as it can evaluate the robustness of any present or\nfuture TRSLAs through objective means.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u6846\u67b6\u6765\u8bc4\u4f30\u4e09\u91cd\u5197\u4f59\u7a00\u758f\u7ebf\u6027\u6570\u7ec4\u5bf9\u6240\u6709\u53ef\u80fd\u4e24\u4e2a\u4f20\u611f\u5668\u6545\u969c\u7684\u7a33\u5065\u6027\uff0c\u53d1\u73b0\u73b0\u6709\u8bbe\u8ba1\u5b58\u5728\u9690\u85cf\u7684\u810f\u70b9\u3002", "motivation": "\u867d\u7136\u591a\u91cd\u5197\u4f59\u7a00\u758f\u6570\u7ec4\u80fd\u591f\u627f\u53d7\u591a\u4e2a\u4f20\u611f\u5668\u6545\u969c\uff0c\u4f46\u4ecd\u7136\u5b58\u5728\u9690\u85cf\u7684\u4f9d\u8d56\u5173\u7cfb\u5f71\u54cd\u5176\u5b8c\u5168\u7a33\u5065\u6027\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7cfb\u7edf\u6846\u67b6\uff0c\u901a\u8fc7\u5bf9\u6240\u6709\u53ef\u80fd\u7684\u4e24\u4e2a\u4f20\u611f\u5668\u6545\u969c\u60c5\u51b5\u8fdb\u884c\u5206\u6790\uff0c\u8bc4\u4f30\u4e09\u91cd\u5197\u4f59\u7a00\u758f\u7ebf\u6027\u6570\u7ec4\u7684\u7a33\u5065\u6027\u3002", "result": "\u5bf9\u73b0\u6709\u7684\u4ee3\u8868\u6027\u4e09\u91cd\u5197\u4f59\u6570\u7ec4\u8fdb\u884c\u6545\u969c\u5206\u6790\uff0c\u53d1\u73b0\u5b83\u4eec\u5bf9\u67d0\u4e9b\u7279\u5b9a\u4f20\u611f\u5668\u5bf9\u7684\u6545\u969c\u5b58\u5728\u9690\u85cf\u7684\u810f\u70b9\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5177\u6709\u91cd\u8981\u7684\u6863\u6848\u4ef7\u503c\uff0c\u80fd\u591f\u901a\u8fc7\u5ba2\u89c2\u624b\u6bb5\u8bc4\u4f30\u4efb\u4f55\u73b0\u6709\u6216\u672a\u6765\u7684\u4e09\u91cd\u5197\u4f59\u7a00\u758f\u6570\u7ec4\u7684\u7a33\u5065\u6027\u3002"}}
{"id": "2509.07677", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2509.07677", "abs": "https://arxiv.org/abs/2509.07677", "authors": ["Kamel Kamel", "Hridoy Sankar Dutta", "Keshav Sood", "Sunil Aryal"], "title": "Spectral Masking and Interpolation Attack (SMIA): A Black-box Adversarial Attack against Voice Authentication and Anti-Spoofing Systems", "comment": null, "summary": "Voice Authentication Systems (VAS) use unique vocal characteristics for\nverification. They are increasingly integrated into high-security sectors such\nas banking and healthcare. Despite their improvements using deep learning, they\nface severe vulnerabilities from sophisticated threats like deepfakes and\nadversarial attacks. The emergence of realistic voice cloning complicates\ndetection, as systems struggle to distinguish authentic from synthetic audio.\nWhile anti-spoofing countermeasures (CMs) exist to mitigate these risks, many\nrely on static detection models that can be bypassed by novel adversarial\nmethods, leaving a critical security gap. To demonstrate this vulnerability, we\npropose the Spectral Masking and Interpolation Attack (SMIA), a novel method\nthat strategically manipulates inaudible frequency regions of AI-generated\naudio. By altering the voice in imperceptible zones to the human ear, SMIA\ncreates adversarial samples that sound authentic while deceiving CMs. We\nconducted a comprehensive evaluation of our attack against state-of-the-art\n(SOTA) models across multiple tasks, under simulated real-world conditions.\nSMIA achieved a strong attack success rate (ASR) of at least 82% against\ncombined VAS/CM systems, at least 97.5% against standalone speaker verification\nsystems, and 100% against countermeasures. These findings conclusively\ndemonstrate that current security postures are insufficient against adaptive\nadversarial attacks. This work highlights the urgent need for a paradigm shift\ntoward next-generation defenses that employ dynamic, context-aware frameworks\ncapable of evolving with the threat landscape.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aSMIA\u7684\u65b0\u578b\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\uff0c\u901a\u8fc7\u64cd\u7eb5AI\u751f\u6210\u97f3\u9891\u4e2d\u4eba\u8033\u65e0\u6cd5\u611f\u77e5\u7684\u9891\u7387\u533a\u57df\uff0c\u6210\u529f\u6b3a\u9a97\u8bed\u97f3\u8ba4\u8bc1\u7cfb\u7edf\u548c\u53cd\u6b3a\u9a97\u63aa\u65bd\uff0c\u8bc1\u660e\u4e86\u5f53\u524d\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u7684\u4e0d\u8db3\u3002", "motivation": "\u8bed\u97f3\u8ba4\u8bc1\u7cfb\u7edf\u867d\u7136\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u4e0d\u65ad\u6539\u8fdb\uff0c\u4f46\u4ecd\u9762\u4e34\u6df1\u5ea6\u4f2a\u9020\u548c\u5bf9\u6297\u653b\u51fb\u7b49\u4e25\u91cd\u6f0f\u6d1e\u3002\u73b0\u6709\u7684\u53cd\u6b3a\u9a97\u63aa\u65bd\u591a\u4f9d\u8d56\u9759\u6001\u68c0\u6d4b\u6a21\u578b\uff0c\u5bb9\u6613\u88ab\u65b0\u578b\u5bf9\u6297\u65b9\u6cd5\u7ed5\u8fc7\uff0c\u5b58\u5728\u5173\u952e\u5b89\u5168\u6f0f\u6d1e\u3002", "method": "\u63d0\u51fa\u4e86\u9891\u8c31\u63a9\u853d\u548c\u63d2\u503c\u653b\u51fb(SMIA)\u65b9\u6cd5\uff0c\u7b56\u7565\u6027\u5730\u64cd\u7eb5AI\u751f\u6210\u97f3\u9891\u4e2d\u4eba\u8033\u65e0\u6cd5\u611f\u77e5\u7684\u9891\u7387\u533a\u57df\uff0c\u521b\u5efa\u542c\u8d77\u6765\u771f\u5b9e\u4f46\u80fd\u6b3a\u9a97\u68c0\u6d4b\u7cfb\u7edf\u7684\u5bf9\u6297\u6837\u672c\u3002", "result": "SMIA\u5728\u6a21\u62df\u771f\u5b9e\u4e16\u754c\u6761\u4ef6\u4e0b\u5bf9\u6700\u5148\u8fdb\u6a21\u578b\u8fdb\u884c\u5168\u9762\u8bc4\u4f30\uff1a\u5bf9\u7ec4\u5408VAS/CM\u7cfb\u7edf\u7684\u653b\u51fb\u6210\u529f\u7387\u8fbe82%\u4ee5\u4e0a\uff0c\u5bf9\u72ec\u7acb\u8bf4\u8bdd\u4eba\u9a8c\u8bc1\u7cfb\u7edf\u8fbe97.5%\u4ee5\u4e0a\uff0c\u5bf9\u53cd\u6b3a\u9a97\u63aa\u65bd\u8fbe100%\u3002", "conclusion": "\u5f53\u524d\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u81ea\u9002\u5e94\u5bf9\u6297\u653b\u51fb\uff0c\u8feb\u5207\u9700\u8981\u5411\u4e0b\u4e00\u4ee3\u9632\u5fa1\u8303\u5f0f\u8f6c\u53d8\uff0c\u91c7\u7528\u80fd\u591f\u968f\u5a01\u80c1\u73af\u5883\u6f14\u53d8\u7684\u52a8\u6001\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u6846\u67b6\u3002"}}
{"id": "2509.07482", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07482", "abs": "https://arxiv.org/abs/2509.07482", "authors": ["Joan \u00c7ollaku", "Kuranage Roche Rayan Ranasinghe", "Giuseppe Thadeu Freitas de Abreu", "Takumi Takahashi"], "title": "Integrated Communication and Computing in Time-Varying mmWave Channels", "comment": "Submitted to the IEEE for possible publication", "summary": "We propose a novel framework for integrated communication and computing (ICC)\ntransceiver design in time-varying millimeter-wave (mmWave) channels. In\nparticular, in order to cope with the dynamics of time-varying mmWave channels,\nthe detection of communication symbols and the execution of an over-the-air\ncomputing (AirComp) operation are performed in parallel with channel tracking,\nas opposed to existing state-of-the-art (SotA) on ICC where perfect knowledge\nof the channel at all time instances is typically assumed. For clarity of\nexposition, we consider a single-input multiple-output (SIMO) uplink scenario\nwhere multiple single-antenna user equipment (UE) transmit to a base station\n(BS) equipped with multiple antennas, such that each UE, or edge device (ED),\nprecodes its own transmit signal, while the BS, or access points (APs), also\nperforms receive beamforming. The proposed transceiver framework then estimates\nchannel state information (CSI) and data symbols in parallel, using a bilinear\nGaussian belief propagation (BiGaBP) algorithm for joint channel and data\ndetection (JCDE), aided by a channel prediction (CP) algorithm executed before\neach estimation window at the BS. The AirComp operation is then executed by\nmeans of an optimal combination of the residual signal. Simulation results\ndemonstrate the effectiveness of the proposed scheme in performing ICC in\nchallenging time-varying mmWave channels, with minimal degradation to both\ncommunication and computing performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65b0\u7684\u96c6\u6210\u901a\u4fe1\u8ba1\u7b97(ICC)\u53d1\u6536\u673a\u6846\u67b6\uff0c\u5728\u65f6\u53d8\u6beb\u7c73\u6ce2\u901a\u9053\u4e2d\u5e76\u884c\u8fdb\u884c\u901a\u4fe1\u7b26\u53f7\u68c0\u6d4b\u548c\u7a7a\u4e2d\u8ba1\u7b97\u64cd\u4f5c\uff0c\u5145\u5206\u5229\u7528\u9891\u6e21\u5206\u96c6\u7279\u6027\u63d0\u9ad8\u6027\u80fd\u3002", "motivation": "\u73b0\u6709ICC\u65b9\u6848\u5047\u8bbe\u5b8c\u7f8e\u9891\u9053\u77e5\u8bc6\uff0c\u4f46\u5b9e\u9645\u65f6\u53d8\u6beb\u7c73\u6ce2\u901a\u9053\u5b58\u5728\u52a8\u6001\u53d8\u5316\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5728\u4e0d\u5b8c\u5168\u9891\u9053\u77e5\u8bc6\u4e0b\u4f18\u5316\u901a\u4fe1\u548c\u8ba1\u7b97\u6027\u80fd\u7684\u65b9\u6848\u3002", "method": "\u91c7\u7528SIMO\u4e0a\u884c\u94fe\u8def\u573a\u666f\uff0c\u901a\u8fc7\u53cc\u7ebf\u6027\u9ad8\u65af\u4fe1\u5ff5\u4f20\u64ad(BiGaBP)\u7b97\u6cd5\u8fdb\u884c\u8054\u5408\u9891\u9053\u548c\u6570\u636e\u68c0\u6d4b(JCDE)\uff0c\u5e76\u5728\u6bcf\u4e2a\u4f30\u8ba1\u7a97\u53e3\u524d\u6267\u884c\u9891\u9053\u9884\u6d4b(CP)\u7b97\u6cd5\uff0c\u6700\u540e\u901a\u8fc7\u6b8a\u4f59\u4fe1\u53f7\u7684\u6700\u4f18\u7ec4\u5408\u6765\u6267\u884cAirComp\u64cd\u4f5c\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6848\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u65f6\u53d8\u6beb\u7c73\u6ce2\u901a\u9053\u4e2d\u80fd\u591f\u6709\u6548\u6267\u884cICC\uff0c\u901a\u4fe1\u548c\u8ba1\u7b97\u6027\u80fd\u90fd\u53ea\u6709\u6700\u5c0f\u7a0b\u5ea6\u7684\u6027\u80fd\u964d\u7ea7\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u65f6\u53d8\u6beb\u7c73\u6ce2\u901a\u9053\u4e2d\u7684\u96c6\u6210\u901a\u4fe1\u8ba1\u7b97\u63d0\u4f9b\u4e86\u4e00\u79cd\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5145\u5206\u5229\u7528\u9891\u6e21\u5206\u96c6\u7279\u6027\uff0c\u5728\u4e0d\u5b8c\u5168\u9891\u9053\u77e5\u8bc6\u6761\u4ef6\u4e0b\u4fdd\u6301\u4e86\u826f\u597d\u7684\u901a\u4fe1\u548c\u8ba1\u7b97\u6027\u80fd\u3002"}}
{"id": "2509.07483", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07483", "abs": "https://arxiv.org/abs/2509.07483", "authors": ["Ivan Iudice", "Domenico Pascarella", "Sonia Zappia", "Giovanni Cuciniello", "Hernan M. R. Giannetta", "Marta Albano", "Enrico Cavallini"], "title": "A Methodological Framework for Positioning of Wireless Sensors in New Generation Launchers", "comment": "6 pages, 3 figures, 5 tables, accepted for publication in the\n  proceedings of 2025 IEEE 12th International Workshop on Metrology for\n  AeroSpace (MetroAeroSpace)", "summary": "In wireless sensor networks for reusable launchers, the electromagnetic\ncharacterization and electromagnetic compatibility analyses are relevant due to\nthe reference operational scenario, which implies a complex, and sometimes\ndynamic, electromagnetic environment. This work proposes a methodological\nframework for the design of the network and for the analysis of the related\nelectromagnetic environment within the stages of a given launcher. Based on the\npreliminary positioning of the network nodes, the framework prescribes a\nworkflow and the related toolset for determining the optimal network topology\nfocusing on the weights, the operation of the transceivers, and the overall\nradiated power. The optimal network configuration is simulated by using\ncomputational electromagnetics strategies in order to assess the\nelectromagnetic environment induced by the sensor network itself. The paper\nprovides some results concerning a case study for a specific launcher.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u53ef\u91cd\u590d\u4f7f\u7528\u7b14\u8fd0\u8f7d\u7b52\u7684\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u8bbe\u8ba1\u7684\u65b9\u6cd5\u8bba\u6846\u67b6\uff0c\u91cd\u70b9\u5173\u6ce8\u7535\u78c1\u73af\u5883\u5206\u6790\u548c\u7535\u78c1\u517c\u5bb9\u6027\u95ee\u9898\u3002", "motivation": "\u7535\u78c1\u73af\u5883\u7684\u590d\u6742\u6027\u548c\u52a8\u6001\u6027\u5bfc\u81f4\u9700\u8981\u4e00\u79cd\u7cfb\u7edf\u6027\u65b9\u6cd5\u6765\u8bbe\u8ba1\u4f18\u5316\u7684\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\uff0c\u786e\u4fdd\u4f20\u611f\u5668\u7f51\u7edc\u7684\u6027\u80fd\u548c\u7535\u78c1\u517c\u5bb9\u6027\u3002", "method": "\u57fa\u4e8e\u7f51\u7edc\u8282\u70b9\u7684\u521d\u59cb\u4f4d\u7f6e\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u5de5\u4f5c\u6d41\u7a0b\u548c\u76f8\u5173\u5de5\u5177\u96c6\uff0c\u7528\u4e8e\u786e\u5b9a\u6700\u4f18\u7f51\u7edc\u62d3\u6251\u7ed3\u6784\uff0c\u91cd\u70b9\u8003\u8651\u91cd\u91cf\u3001\u53d1\u5c04\u63a5\u6536\u673a\u64cd\u4f5c\u548c\u603b\u8f90\u5c04\u529f\u7387\u3002\u4f7f\u7528\u8ba1\u7b97\u7535\u78c1\u5b66\u7b56\u7565\u6a21\u62df\u6700\u4f18\u7f51\u7edc\u914d\u7f6e\u3002", "result": "\u8bba\u6587\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5177\u4f53\u7b14\u8fd0\u8f7d\u7b52\u7684\u6848\u4f8b\u7814\u7a76\u7ed3\u679c\uff0c\u8bc1\u660e\u4e86\u8be5\u65b9\u6cd5\u6848\u6848\u5728\u5206\u6790\u4f20\u611f\u5668\u7f51\u7edc\u5f15\u8d77\u7684\u7535\u78c1\u73af\u5883\u65b9\u9762\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bba\u6846\u67b6\u80fd\u591f\u6709\u6548\u5730\u8bbe\u8ba1\u4f18\u5316\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\uff0c\u786e\u4fdd\u5176\u5728\u590d\u6742\u7535\u78c1\u73af\u5883\u4e2d\u7684\u6027\u80fd\u548c\u517c\u5bb9\u6027\uff0c\u4e3a\u53ef\u91cd\u590d\u4f7f\u7528\u7b14\u8fd0\u8f7d\u7b52\u7684\u5b89\u5168\u8fd0\u884c\u63d0\u4f9b\u6280\u672f\u652f\u6491\u3002"}}
{"id": "2509.07511", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07511", "abs": "https://arxiv.org/abs/2509.07511", "authors": ["Jinming Wang", "Lipeng Zhu", "Shuai Han", "He Sun", "Rui Zhang"], "title": "Joint Antenna Positioning and Beamforming for Movable Antenna Array Aided Ground Station in Low-Earth Orbit Satellite Communication", "comment": null, "summary": "This paper proposes a new architecture for the low-earth orbit (LEO)\nsatellite ground station aided by movable antenna (MA) array. Unlike\nconventional fixed-position antenna (FPA), the MA array can flexibly adjust\nantenna positions to reconfigure array geometry, for more effectively\nmitigating interference and improving communication performance in ultra-dense\nLEO satellite networks. To reduce movement overhead, we configure antenna\npositions at the antenna initialization stage, which remain unchanged during\nthe whole communication period of the ground station. To this end, an\noptimization problem is formulated to maximize the average achievable rate of\nthe ground station by jointly optimizing its antenna position vector (APV) and\ntime-varying beamforming weights, i.e., antenna weight vectors (AWVs). To solve\nthe resulting non-convex optimization problem, we adopt the Lagrangian dual\ntransformation and quadratic transformation to reformulate the objective\nfunction into a more tractable form. Then, we develop an efficient block\ncoordinate descent-based iterative algorithm that alternately optimizes the APV\nand AWVs until convergence is reached. Simulation results demonstrate that our\nproposed MA scheme significantly outperforms traditional FPA by increasing the\nachievable rate at ground stations under various system setups, thus providing\nan efficient solution for interference mitigation in future ultra-dense LEO\nsatellite communication networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u53ef\u79fb\u52a8\u5929\u7ebf\u6570\u7ec4\u7684\u4f4e\u8f68\u9053\u536b\u661f\u5730\u9762\u7ad9\u65b0\u67b6\u6784\uff0c\u901a\u8fc7\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\u548c\u6ce2\u675f\u6210\u578b\u6765\u63d0\u9ad8\u901f\u7387\u548c\u51cf\u5c11\u5e72\u6270\u3002", "motivation": "\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\u5728\u8d85\u5bc6\u96c6\u4f4e\u8f68\u9053\u536b\u661f\u7f51\u7edc\u4e2d\u5e72\u6270\u7f13\u89e3\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u5e72\u6270\u51cf\u5c11\u65b9\u6848\u3002", "method": "\u5728\u5929\u7ebf\u521d\u59cb\u5316\u9636\u6bb5\u914d\u7f6e\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\uff0c\u901a\u8fc7\u62c9\u683c\u6717\u65e5\u5bf9\u5076\u53d8\u6362\u548c\u4e8c\u6b21\u53d8\u6362\u91cd\u6784\u76ee\u6807\u51fd\u6570\uff0c\u4f7f\u7528\u5750\u6807\u9012\u6e1d\u6cd5\u4ea4\u66ff\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\u5411\u91cf\u548c\u6ce2\u675f\u6210\u578b\u6743\u91cd\u3002", "result": "\u6a21\u62df\u7ed3\u679c\u663e\u793a\uff0c\u8be5\u53ef\u79fb\u52a8\u5929\u7ebf\u65b9\u6848\u5728\u5404\u79cd\u7cfb\u7edf\u914d\u7f6e\u4e0b\u90fd\u663e\u8457\u8d85\u8fc7\u4f20\u7edf\u56fa\u5b9a\u5929\u7ebf\uff0c\u5927\u5e45\u63d0\u9ad8\u5730\u9762\u7ad9\u7684\u53ef\u5b9e\u73b0\u901f\u7387\u3002", "conclusion": "\u8be5\u65b9\u6848\u4e3a\u672a\u6765\u8d85\u5bc6\u96c6\u4f4e\u8f68\u9053\u536b\u661f\u901a\u4fe1\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u5e72\u6270\u7f13\u89e3\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.07610", "categories": ["eess.SP", "cs.NA", "math.NA"], "pdf": "https://arxiv.org/pdf/2509.07610", "abs": "https://arxiv.org/abs/2509.07610", "authors": ["Ahsan Mehmood", "Ioannis Krikidis", "Ghassan M. Kraidy"], "title": "Asymmetric Modulation Design for Fluid-Antenna SWIPT Systems", "comment": "Accepted for Publication in Globecomm Green Communication Conference", "summary": "In this work, we propose the design of modulation schemes that improve the\nrate-energy region of fluid antenna-assisted simultaneous wireless information\nand power transfer (SWIPT) systems. By considering the nonlinear\ncharacteristics of practical energy harvesting circuits, we formulate a\ndual-objective rate-energy (RE) region optimization problem to jointly maximize\nthe discrete-input mutual information (DIMI) and harvested current. The problem\nis solved using the epsilon-constraint method and optimized constellations are\ndesigned for various energy harvesting thresholds. We then evaluate the\nperformance of the optimized constellations under three different fluid antenna\n(FA) port selection strategies: (i) Best Port, (ii) Fixed Port, and (iii)\nRandom Port. Our simulation results demonstrate significant performance gains\nof optimized constellations over conventional constellations in both\ninformation rate and energy harvesting.", "AI": {"tldr": "\u63d0\u51fa\u6539\u8fdb\u6d41\u4f53\u5929\u7ebf\u8f85\u52a9SWIPT\u7cfb\u7edf\u901f\u7387-\u80fd\u91cf\u533a\u57df\u7684\u8c03\u5236\u65b9\u6848\uff0c\u8003\u8651\u975e\u7ebf\u6027\u80fd\u91cf\u6536\u96c6\u7279\u6027\uff0c\u901a\u8fc7epsilon\u7ea6\u675f\u65b9\u6cd5\u4f18\u5316\u661f\u5ea7\u8bbe\u8ba1\uff0c\u5728\u4e0d\u540c\u5929\u7ebf\u7aef\u53e3\u9009\u62e9\u7b56\u7565\u4e0b\u663e\u8457\u63d0\u5347\u4fe1\u606f\u901f\u7387\u548c\u80fd\u91cf\u6536\u96c6\u6027\u80fd", "motivation": "\u9488\u5bf9\u5b9e\u9645\u80fd\u91cf\u6536\u96c6\u7535\u8def\u7684\u975e\u7ebf\u6027\u7279\u6027\uff0c\u4f18\u5316\u6d41\u4f53\u5929\u7ebf\u8f85\u52a9\u540c\u65f6\u65e0\u7ebf\u4fe1\u606f\u548c\u80fd\u91cf\u4f20\u8f93\u7cfb\u7edf\u7684\u901f\u7387-\u80fd\u91cf\u533a\u57df\uff0c\u63d0\u5347\u4fe1\u606f\u4f20\u8f93\u548c\u80fd\u91cf\u6536\u96c6\u7684\u8054\u5408\u6027\u80fd", "method": "\u91c7\u7528epsilon\u7ea6\u675f\u65b9\u6cd5\u6c42\u89e3\u53cc\u76ee\u6807\u901f\u7387-\u80fd\u91cf\u533a\u57df\u4f18\u5316\u95ee\u9898\uff0c\u6700\u5927\u5316\u79bb\u6563\u8f93\u5165\u4e92\u4fe1\u606f\u548c\u6536\u96c6\u7535\u6d41\uff0c\u4e3a\u4e0d\u540c\u80fd\u91cf\u6536\u96c6\u9608\u503c\u8bbe\u8ba1\u4f18\u5316\u661f\u5ea7\uff0c\u5e76\u8bc4\u4f30\u4e09\u79cd\u6d41\u4f53\u5929\u7ebf\u7aef\u53e3\u9009\u62e9\u7b56\u7565", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u4f18\u5316\u661f\u5ea7\u76f8\u6bd4\u4f20\u7edf\u661f\u5ea7\u5728\u4fe1\u606f\u901f\u7387\u548c\u80fd\u91cf\u6536\u96c6\u65b9\u9762\u5747\u83b7\u5f97\u663e\u8457\u6027\u80fd\u589e\u76ca", "conclusion": "\u6240\u63d0\u51fa\u7684\u4f18\u5316\u8c03\u5236\u65b9\u6848\u80fd\u6709\u6548\u63d0\u5347\u6d41\u4f53\u5929\u7ebfSWIPT\u7cfb\u7edf\u7684\u6574\u4f53\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8bbe\u8ba1\u65b9\u6cd5"}}
{"id": "2509.07754", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07754", "abs": "https://arxiv.org/abs/2509.07754", "authors": ["Felix Artmann", "Daniel Gil Gaviria", "Benedikt Geiger", "Laurent Schmalen"], "title": "Interference Mitigation for OFDM-based Integrated Sensing and Communications with Arbitrary Modulation Formats", "comment": null, "summary": "Integrated sensing and communication will be a key feature of future mobile\nnetworks, enabling highly efficient systems and numerous new applications by\nleveraging communication signals for sensing. In this paper, we analyze the\nimpact of arbitrary modulation alphabets on the sensing performance of\ncommunication-centric OFDM systems as expected in the next-generation 6G\nnetworks. We evaluate existing interference mitigation techniques, such as\ncoherent successive target cancellation, and propose an enhanced version of\nthis algorithm. A systematic performance evaluation in multi-target scenarios,\nincluding the effects of scattering, demonstrates that our proposed\ninterference mitigation methods achieve performance comparable to\nsensing-optimal constant modulus signals while utilizing higher order\nconstellations for more efficient communications.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4e0d\u540c\u8c03\u5236\u5b57\u6bcd\u5bf96G OFDM\u7cfb\u7edf\u611f\u77e5\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u8bc4\u4f30\u5e76\u6539\u8fdb\u4e86\u5e72\u6270\u6d88\u9664\u6280\u672f\uff0c\u5728\u591a\u76ee\u6807\u573a\u666f\u4e2d\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u611f\u77e5\u6027\u80fd\u7684\u540c\u65f6\u4fdd\u6301\u9ad8\u6548\u901a\u4fe1\u3002", "motivation": "\u672a\u6765\u79fb\u52a8\u7f51\u7edc\u9700\u8981\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u529f\u80fd\uff0c\u5229\u7528\u901a\u4fe1\u4fe1\u53f7\u8fdb\u884c\u611f\u77e5\u53ef\u4ee5\u521b\u5efa\u9ad8\u6548\u7cfb\u7edf\u548c\u65b0\u7684\u5e94\u7528\u573a\u666f\u3002\u7814\u7a76\u4e0d\u540c\u8c03\u5236\u65b9\u6848\u5bf9\u611f\u77e5\u6027\u80fd\u7684\u5f71\u54cd\u5bf9\u4e8e6G\u7f51\u7edc\u53d1\u5c55\u81f3\u5173\u91cd\u8981\u3002", "method": "\u8bc4\u4f30\u73b0\u6709\u7684\u76f8\u5e72\u8fde\u7eed\u76ee\u6807\u6d88\u9664\u7b49\u5e72\u6270\u6291\u5236\u6280\u672f\uff0c\u5e76\u63d0\u51fa\u8be5\u7b97\u6cd5\u7684\u589e\u5f3a\u7248\u672c\u3002\u5728\u591a\u76ee\u6807\u573a\u666f\u4e2d\u8fdb\u884c\u7cfb\u7edf\u6027\u6027\u80fd\u8bc4\u4f30\uff0c\u5305\u62ec\u6563\u5c04\u6548\u5e94\u7684\u5f71\u54cd\u3002", "result": "\u63d0\u51fa\u7684\u5e72\u6270\u6291\u5236\u65b9\u6cd5\u5728\u4f7f\u7528\u9ad8\u9636\u661f\u5ea7\u5b9e\u73b0\u66f4\u9ad8\u6548\u901a\u4fe1\u7684\u540c\u65f6\uff0c\u8fbe\u5230\u4e86\u4e0e\u611f\u77e5\u6700\u4f18\u6052\u5b9a\u6a21\u91cf\u4fe1\u53f7\u76f8\u5f53\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u6539\u8fdb\u7684\u5e72\u6270\u6d88\u9664\u6280\u672f\uff0c\u53ef\u4ee5\u5728\u4fdd\u6301\u901a\u4fe1\u6548\u7387\u7684\u540c\u65f6\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u611f\u77e5\u6027\u80fd\uff0c\u4e3a6G\u7f51\u7edc\u4e2d\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u529f\u80fd\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2509.07758", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07758", "abs": "https://arxiv.org/abs/2509.07758", "authors": ["Pietro Savazzi", "Anna Vizziello", "Sherif Badran", "Josep M. Jornet"], "title": "Experimental Evaluation of Joint Clock Recovery and Equalization for Sub-Terahertz Links", "comment": "To be presented at the 13th IEEE INTERNATIONAL CONFERENCE ON WIRELESS\n  FOR SPACE AND EXTREME ENVIRONMENTS WiSEE 2025", "summary": "This paper proposes and experimentally evaluates a joint clock recovery (CR)\nand equalization architecture tailored for high-speed sub-terahertz (sub-THz)\nwireless communication links. Specifically, a Baud-spaced digital receiver\narchitecture is investigated that combines a constant modulus algorithm (CMA)\nequalizer with a blind timing error detector (TED), enabling robust symbol\ntiming synchronization without decision-directed (DD) feedback or pilot\nsymbols. The proposed TED leverages the CMA filter coefficients to estimate\ntiming errors, which are then used to drive a Farrow interpolator operating at\ntwice the symbol rate. The system is validated experimentally using a 140~GHz\nwireless testbed with 16-QAM modulation over a 10~GHz bandwidth. Results show\nthat the proposed TED schemes outperform conventional blind TEDs, such as\nGardner and blind implementations of Mueller \\& M\\\"uller, in terms of bit error\nrate (BER), error vector magnitude (EVM), and intersymbol interference (ISI)\nsuppression. These capabilities are especially relevant to next-generation\nspaceborne communication systems, where wideband sub-THz links are expected to\nplay a key role in enabling ultra-high-data-rate inter-satellite and deep-space\ncommunications under challenging synchronization constraints.", "AI": {"tldr": "\u8fd9\u7bc7\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u9ad8\u901f\u6b21\u592a\u8d6b\u7c92\u5b50\u65e0\u7ebf\u901a\u4fe1\u7684\u8054\u5408\u65f6\u949f\u6062\u590d\u548c\u5747\u8861\u7ed3\u6784\uff0c\u901a\u8fc7\u7ed3\u5408CMA\u5747\u8861\u5668\u548c\u76f2\u65f6\u949f\u9519\u8bef\u68c0\u6d4b\u5668\uff0c\u5728\u65e0\u9700\u51b3\u7b56\u5f15\u5bfc\u6216\u5bfc\u9891\u7b26\u53f7\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u7a33\u5065\u7684\u7b26\u53f7\u540c\u6b65\u3002", "motivation": "\u4e3a\u4e86\u6ee1\u8db3\u4e0b\u4e00\u4ee3\u592a\u7a7a\u901a\u4fe1\u7cfb\u7edf\u5bf9\u5e7f\u5e26\u6b21\u592a\u8d6b\u7c92\u5b50\u94fe\u8def\u7684\u9700\u6c42\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5728\u5177\u6709\u6311\u6218\u6027\u540c\u6b65\u7ea6\u675f\u6761\u4ef6\u4e0b\u5b9e\u73b0\u8d85\u9ad8\u6570\u636e\u901f\u7387\u901a\u4fe1\u7684\u7a33\u5065\u540c\u6b65\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u79cdBaud\u95f4\u9694\u7684\u6570\u5b57\u63a5\u6536\u673a\u67b6\u6784\uff0c\u7ed3\u5408\u5e38\u6a21\u7b97\u6cd5(CMA)\u5747\u8861\u5668\u548c\u76f2\u65f6\u949f\u9519\u8bef\u68c0\u6d4b\u5668(TED)\uff0c\u5229\u7528CMA\u6ee4\u6ce2\u5668\u7cfb\u6570\u4f30\u8ba1\u65f6\u949f\u9519\u8bef\uff0c\u5e76\u9a71\u52a8\u4e8f\u7f57\u63d2\u503c\u5668\u8fd0\u884c\u57282\u500d\u7b26\u53f7\u901f\u7387\u3002", "result": "\u901a\u8fc7140GHz\u65e0\u7ebf\u6d4b\u8bd5\u5e73\u53f0\u9a8c\u8bc1\uff0c\u63d0\u51fa\u7684TED\u65b9\u6848\u5728\u6bd4\u7279\u9519\u8bef\u7387(BER)\u3001\u9519\u8bef\u5411\u91cf\u6a21(EVM)\u548c\u7801\u95f4\u5e72\u6270(ISI)\u538b\u5236\u65b9\u9762\u90fd\u8d85\u8fc7\u4f20\u7edf\u7684Gardner\u548cMueller & M\u00fcller\u76f2TED\u65b9\u6848\u3002", "conclusion": "\u8be5\u65b9\u6848\u4e3a\u4e0b\u4e00\u4ee3\u592a\u7a7a\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u8054\u5408\u65f6\u949f\u6062\u590d\u548c\u5747\u8861\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u6311\u6218\u6027\u540c\u6b65\u6761\u4ef6\u4e0b\u80fd\u591f\u652f\u6301\u8d85\u9ad8\u6570\u636e\u901f\u7387\u7684\u536b\u661f\u95f4\u548c\u6df1\u7a7a\u901a\u4fe1\u3002"}}
{"id": "2509.07775", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07775", "abs": "https://arxiv.org/abs/2509.07775", "authors": ["Yu Ge", "Ossi Kaltiokallio", "Elizaveta Rastorgueva-Foi", "Musa Furkan Keskin", "Hui Chen", "Guillaume Jornod", "Jukka Talvitie", "Mikko Valkama", "Frank Hofmann", "Henk Wymeersch"], "title": "Sensing with Mobile Devices through Radio SLAM: Models, Methods, Opportunities, and Challenges", "comment": null, "summary": "The integration of sensing and communication (ISAC) is a cornerstone of 6G,\nenabling simultaneous environmental awareness and communication. This paper\nexplores radio SLAM (simultaneous localization and mapping) as a key ISAC\napproach, using radio signals for mapping and localization. We analyze radio\nSLAM across different frequency bands, discussing trade-offs in coverage,\nresolution, and hardware requirements. We also highlight opportunities for\nintegration with sensing, positioning, and cooperative networks. The findings\npave the way for standardized solutions in 6G applications such as autonomous\nsystems and industrial robotics.", "AI": {"tldr": "\u672c\u6587\u63a2\u8ba66G\u4e2d\u611f\u77e5\u4e0e\u901a\u4fe1\u96c6\u6210(ISAC)\u7684\u5173\u952e\u6280\u672f\u65e0\u7ebf\u7535SLAM\uff0c\u5206\u6790\u4e86\u4e0d\u540c\u9891\u6bb5\u5e26\u7684\u6027\u80fd\u7279\u5f81\u548c\u5e94\u7528\u524d\u666f", "motivation": "\u65e0\u7ebf\u7535SLAM\u4f5c\u4e3aISAC\u7684\u6838\u5fc3\u6280\u672f\uff0c\u80fd\u591f\u540c\u65f6\u5b9e\u73b0\u73af\u5883\u611f\u77e5\u548c\u901a\u4fe1\u529f\u80fd\uff0c\u4e3a6G\u5e94\u7528\u63d0\u4f9b\u91cd\u8981\u652f\u6491", "method": "\u901a\u8fc7\u5206\u6790\u4e0d\u540c\u9891\u6bb5\u5e26\u4e0b\u65e0\u7ebf\u7535SLAM\u7684\u8986\u76d6\u8303\u56f4\u3001\u5206\u8fa8\u7387\u548c\u786c\u4ef6\u8981\u6c42\u7b49\u6027\u80fd\u7279\u5f81\uff0c\u8ba8\u8bba\u4e86\u4e0e\u611f\u77e5\u3001\u5b9a\u4f4d\u548c\u534f\u540c\u7f51\u7edc\u7684\u96c6\u6210\u673a\u4f1a", "result": "\u7814\u7a76\u63ed\u793a\u4e86\u65e0\u7ebf\u7535SLAM\u5728\u4e0d\u540c\u9891\u6bb5\u5e26\u7684\u6027\u80fd\u504f\u5411\u548c\u5e94\u7528\u6f5c\u529b\uff0c\u4e3a\u6807\u51c6\u5316\u89e3\u51b3\u65b9\u6848\u5960\u5b9a\u57fa\u7840", "conclusion": "\u65e0\u7ebf\u7535SLAM\u6280\u672f\u5c06\u4e3a6G\u81ea\u4e3b\u7cfb\u7edf\u3001\u5de5\u4e1a\u673a\u5668\u4eba\u7b49\u5e94\u7528\u63d0\u4f9b\u5173\u952e\u652f\u6491\uff0c\u662f\u672a\u6765\u667a\u80fd\u5316\u7f51\u7edc\u7684\u91cd\u8981\u6280\u672f\u57fa\u7840"}}
{"id": "2509.07839", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2509.07839", "abs": "https://arxiv.org/abs/2509.07839", "authors": ["Florian Strasser", "Marion B\u00e4ro", "Wolfgang Utschick"], "title": "Enhancements in Score-based Channel Estimation for Real-Time Wireless Systems", "comment": "Presented at 28th International Workshop on Smart Antennas 2025,\n  https://www.wsa2025.fau.de/", "summary": "We propose enhancements to score-based generative modeling techniques for\nlow-latency pilot-based channel estimation in a point-to-point single-carrier\nmultiple-input multiple-output (MIMO) wireless system. Building on recent\nadvances in score-based models, we investigate a specific noise schedule design\nand sampling acceleration by step-skipping to reduce the number of denoising\nsteps during inference. We additionally propose a single-step signal-to-noise\nratio informed denoiser as an extreme case of the step-skipping approach. Our\nmethods achieve significant latency reductions without performance degradation,\nas demonstrated on a synthetic channel dataset representing an urban macrocell\nMIMO communications scenario.", "AI": {"tldr": "\u57fa\u4e8e\u5206\u6570\u751f\u6210\u6a21\u578b\u7684\u4f4e\u5ef6\u8fdfMIMO\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u6539\u8fdb\uff0c\u901a\u8fc7\u566a\u58f0\u8c03\u5ea6\u8bbe\u8ba1\u548c\u8df3\u6b65\u91c7\u6837\u52a0\u901f\u63a8\u7406\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5ef6\u8fdf", "motivation": "\u9488\u5bf9\u70b9\u5bf9\u70b9\u5355\u8f7d\u6ce2MIMO\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u7684\u4f4e\u5ef6\u8fdf\u5bfc\u9891\u4fe1\u9053\u4f30\u8ba1\u9700\u6c42\uff0c\u5229\u7528\u5206\u6570\u751f\u6210\u6a21\u578b\u7684\u6700\u65b0\u8fdb\u5c55\u6765\u63d0\u5347\u4f30\u8ba1\u6548\u7387", "method": "\u63d0\u51fa\u7279\u5b9a\u7684\u566a\u58f0\u8c03\u5ea6\u8bbe\u8ba1\u548c\u8df3\u6b65\u91c7\u6837\u52a0\u901f\u6280\u672f\u51cf\u5c11\u53bb\u566a\u6b65\u9aa4\uff0c\u5e76\u8bbe\u8ba1\u5355\u6b65\u4fe1\u566a\u6bd4\u611f\u77e5\u53bb\u566a\u5668\u4f5c\u4e3a\u8df3\u6b65\u65b9\u6cd5\u7684\u6781\u7aef\u60c5\u51b5", "result": "\u5728\u4ee3\u8868\u57ce\u5e02\u5b8f\u5c0f\u533aMIMO\u901a\u4fe1\u573a\u666f\u7684\u5408\u6210\u4fe1\u9053\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u5ef6\u8fdf\u964d\u4f4e\u4e14\u65e0\u6027\u80fd\u635f\u5931", "conclusion": "\u6240\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u51cf\u5c11\u5206\u6570\u751f\u6210\u6a21\u578b\u5728\u4fe1\u9053\u4f30\u8ba1\u5e94\u7528\u4e2d\u7684\u63a8\u7406\u5ef6\u8fdf\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848"}}

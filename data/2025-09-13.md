<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 14]
- [eess.AS](#eess.AS) [Total: 7]
- [cs.SD](#cs.SD) [Total: 8]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [A Masked Representation Learning to Model Cardiac Functions Using Multiple Physiological Signals](https://arxiv.org/abs/2509.08830)
*Seong-A Park,Jong-Eui Chae,Sungdong Kim,Hyung-Chul Lee,Hyun-Lim Yang*

Main category: eess.SP

TL;DR: SNUPHY-M是一种基于自监督学习的多模态生理信号分析模型，通过同时处理ECG、PPG和ABP三种信号来提取丰富的生理特征，在血流动力学监测任务中显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 临床环境中需要综合分析多种生理信号来监测血流动力学，但现有研究多集中于单一信号分析，缺乏适用于真实临床场景的复杂信号分析方法。

Method: 采用自监督学习框架，通过恢复三种被遮蔽的生理信号（ECG、PPG、ABP）来提取反映心脏周期电学、压力和流体特性的生理特征，利用多种物理特性仅使用无创信号提取更丰富的特征。

Result: 在低血压、每搏输出量、收缩压、舒张压和年龄预测等临床下游任务中，SNUPHY-M显著优于监督学习或自监督学习模型，特别是在使用无创信号的预测任务中表现突出。

Conclusion: SNUPHY-M是首个将多模态自监督学习应用于涉及ECG、PPG和ABP信号的心血管分析的模型，有效支持临床决策，实现精确诊断，为无创血流动力学的早期诊断和管理做出重要贡献。

Abstract: In clinical settings, monitoring hemodynamics is crucial for managing patient
prognosis, necessitating the integrated analysis of multiple physiological
signals. While recent research has analyzed single signals such as
electrocardiography (ECG) or photoplethysmography (PPG), there has yet to be a
proposal for an approach that encompasses the complex signal analysis required
in actual clinical scenarios. In this study, we introduce the SNUPHY-M (Seoul
National University hospital PHYsiological signal Masked representation
learning) model extracts physiological features reflecting the electrical,
pressure, and fluid characteristics of the cardiac cycle in the process of
restoring three masked physiological signals based on self-supervised learning
(SSL): ECG, PPG, and arterial blood pressure (ABP) signals. By employing
multiple physical characteristics, the model can extract more enriched features
only using non-invasive signals. We evaluated the model's performance in
clinical downstream tasks such as hypotension, stroke volume, systolic blood
pressure, diastolic blood pressure, and age prediction. Our results showed that
the SNUPHY-M significantly outperformed supervised or SSL models, especially in
prediction tasks using non-invasive signals. To the best of our knowledge,
SNUPHY-M is the first model to apply multi-modal SSL to cardiovascular analysis
involving ECG, PPG, and ABP signals. This approach effectively supports
clinical decision-making and enables precise diagnostics, contributing
significantly to the early diagnosis and management of hemodynamics without
invasiveness.

</details>


### [2] [Deploying AI for Signal Processing education: Selected challenges and intriguing opportunities](https://arxiv.org/abs/2509.08950)
*Jarvis Haupt,Qin Lu,Yanning Shen,Jia Chen,Yue Dong,Dan McCreary,Mehmet Akçakaya,Georgios B. Giannakis*

Main category: eess.SP

TL;DR: 这篇论文探讨了AI在信号处理教育中的应用，重点关注技术限制和实践应用，以及公平、可靠性等责任使用问题。


<details>
  <summary>Details</summary>
Motivation: 虽然AI技术取得了重大进展，但还面临着如何负责任地使用AI来真正改善全球人类生活的挑战，特别是在教育领域。

Method: 提供了在教育环境中使用AI的核心技术问题入门，包括确保公平性、处理幻觉输出、资源高效利用等，并通过开发沉浸式智能教科书来展示这些考虑。

Result: 论文作为一份资源，为研究人员和教育工作者提供了在工程教育中推进AI应用的实践指南和技术支持。

Conclusion: 人工智能在教育领域具有广阔应用前景，特别是在信号处理教育中，但需要维护公平、包容、透明、可解释性和可信赖性等核心价值观。

Abstract: Powerful artificial intelligence (AI) tools that have emerged in recent years
-- including large language models, automated coding assistants, and advanced
image and speech generation technologies -- are the result of monumental human
achievements. These breakthroughs reflect mastery across multiple technical
disciplines and the resolution of significant technological challenges.
However, some of the most profound challenges may still lie ahead. These
challenges are not purely technical but pertain to the fair and responsible use
of AI in ways that genuinely improve the global human condition. This article
explores one promising application aligned with that vision: the use of AI
tools to facilitate and enhance education, with a specific focus on signal
processing (SP). It presents two interrelated perspectives: identifying and
addressing technical limitations, and applying AI tools in practice to improve
educational experiences. Primers are provided on several core technical issues
that arise when using AI in educational settings, including how to ensure
fairness and inclusivity, handle hallucinated outputs, and achieve efficient
use of resources. These and other considerations -- such as transparency,
explainability, and trustworthiness -- are illustrated through the development
of an immersive, structured, and reliable "smart textbook." The article serves
as a resource for researchers and educators seeking to advance AI's role in
engineering education.

</details>


### [3] [Ultrafast Deep Learning-Based Scatter Estimation in Cone-Beam Computed Tomography](https://arxiv.org/abs/2509.08973)
*Harshit Agrawal,Ari Hietanen,Simo Särkkä*

Main category: eess.SP

TL;DR: 通过不同分辨率层面进行散射估计，在保持性能的同时实现了78倍FLOPs减少和16倍推理速度提升


<details>
  <summary>Details</summary>
Motivation: 解决深度学习散射估计算法在移动CBCT系统和边缘设备上部署时的大内存占用问题

Method: 在不同分辨率下训练状态前沿网络，比较四种插值方法的重建错误，并评估FLOPs、推理时间和GPU内存需求

Result: 输入大小和网络参数减少带来78倍FLOPs减少，MAPE从4.42%降至3.85%，MSE从2.01×10^{-2}降至1.34×10^{-2}，推理时间和GPU内存使用分别减少16倍和12倍

Conclusion: 下采样在深度学习散射估计中具有重要作用，通过大幅减少计算资源需求，使得在资源受限环境中实现散射校正变得可行

Abstract: Purpose: Scatter artifacts drastically degrade the image quality of cone-beam
computed tomography (CBCT) scans. Although deep learning-based methods show
promise in estimating scatter from CBCT measurements, their deployment in
mobile CBCT systems or edge devices is still limited due to the large memory
footprint of the networks. This study addresses the issue by applying networks
at varying resolutions and suggesting an optimal one, based on speed and
accuracy.
  Methods: First, the reconstruction error in down-up sampling of CBCT scatter
signal was examined at six resolutions by comparing four interpolation methods.
Next, a recent state-of-the-art method was trained across five image
resolutions and evaluated for the reductions in floating-point operations
(FLOPs), inference times, and GPU memory requirements.
  Results: Reducing the input size and network parameters achieved a 78-fold
reduction in FLOPs compared to the baseline method, while maintaining comarable
performance in terms of mean-absolute-percentage-error (MAPE) and
mean-square-error (MSE). Specifically, the MAPE decreased to 3.85% compared to
4.42%, and the MSE decreased to 1.34 \times 10^{-2} compared to 2.01 \times
10^{-2}. Inference time and GPU memory usage were reduced by factors of 16 and
12, respectively. Further experiments comparing scatter-corrected
reconstructions on a large, simulated dataset and real CBCT scans from water
and Sedentex CT phantoms clearly demonstrated the robustness of our method.
  Conclusion: This study highlights the underappreciated role of downsampling
in deep learning-based scatter estimation. The substantial reduction in FLOPs
and GPU memory requirements achieved by our method enables scatter correction
in resource-constrained environments, such as mobile CBCT and edge devices.

</details>


### [4] [6G Resilience -- White Paper](https://arxiv.org/abs/2509.09005)
*Hirley Alves,Nurul H. Mahmood,Onel L. A. López,Sumudu Samarakoon,Seppo Yrjölä,Matti Latva-Aho,Markku Juntti,Ari Pouttu,Armin Dekorsy,Arthur Sousa de Sena,Aydin Sezgin,Bho Matthiesen,Chafika Benzaid,Chathuranga Weeraddana,David Hutchison,Dileepa Marasinghe,Doganalp Ergenc,Eduard Jorswieck,Erkki Harjula,Falko Dressler,Harri Saarnisaari,Italo Atzeni,Jaap Van De Beek,Jacek Rak,Konstantin Mikhaylov,Lauri Loven,Madhusanka Liyanage,Marcos Katz,Marja Matinmikko-Blue,Mehdi Rasti,Mika Ylianttila Nhan Nguyen,Pawani Porambage,Petar Popovski,Petri Ahokangas,Premanandana Rajatheva,Robert-Jeron Reifert,Tharaka Hewa,Tommy Svensson*

Main category: eess.SP

TL;DR: 6G网络需要将韧性作为核心设计目标，通过3R框架（可靠性、鲁棒性、韧性）和可衡量的能力来实现对复杂中断的适应和恢复。


<details>
  <summary>Details</summary>
Motivation: 移动网络从效率优先转向可持续性导向，需要设计能够承受、适应和演进于长期复杂中断的6G网络，将韧性作为与可持续性和效率并列的主要设计目标。

Method: 采用3R框架（可靠性、鲁棒性、韧性）形式化韧性概念，转化为可衡量的能力：优雅降级、态势感知、快速重配置、学习驱动的改进和恢复。架构上采用边缘原生和位置感知设计、开放接口、可编程性。

Result: 提出了包括AI原生控制环、硬件根植的零信任安全、关键流量优先的网络技术等关键使能技术，以及9个商业模式组和治理标准化框架。

Conclusion: 本白皮书作为6G韧性研究的起点和催化剂，为研究人员、专业人士、政府官员和公众提供了理解和塑造6G韧性发展的基本组件。

Abstract: 6G must be designed to withstand, adapt to, and evolve amid prolonged,
complex disruptions. Mobile networks' shift from efficiency-first to
sustainability-aware has motivated this white paper to assert that resilience
is a primary design goal, alongside sustainability and efficiency, encompassing
technology, architecture, and economics. We promote resilience by analysing
dependencies between mobile networks and other critical systems, such as
energy, transport, and emergency services, and illustrate how cascading
failures spread through infrastructures. We formalise resilience using the 3R
framework: reliability, robustness, resilience. Subsequently, we translate this
into measurable capabilities: graceful degradation, situational awareness,
rapid reconfiguration, and learning-driven improvement and recovery.
  Architecturally, we promote edge-native and locality-aware designs, open
interfaces, and programmability to enable islanded operations, fallback modes,
and multi-layer diversity (radio, compute, energy, timing). Key enablers
include AI-native control loops with verifiable behaviour, zero-trust security
rooted in hardware and supply-chain integrity, and networking techniques that
prioritise critical traffic, time-sensitive flows, and inter-domain
coordination.
  Resilience also has a techno-economic aspect: open platforms and high-quality
complementors generate ecosystem externalities that enhance resilience while
opening new markets. We identify nine business-model groups and several
patterns aligned with the 3R objectives, and we outline governance and
standardisation. This white paper serves as an initial step and catalyst for 6G
resilience. It aims to inspire researchers, professionals, government
officials, and the public, providing them with the essential components to
understand and shape the development of 6G resilience.

</details>


### [5] [Personalized Sleep Prediction via Deep Adaptive Spatiotemporal Modeling and Sparse Data](https://arxiv.org/abs/2509.09018)
*Xueyi Wang,C. J. C.,Lamoth,Elisabeth Wilhelm*

Main category: eess.SP

TL;DR: 提出了AdaST-Sleep模型，结合卷积层和循环神经网络层来预测睡眠评分，通过域分类器实现跨对象泛化，在多个时间窗口设置下优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 睡眠预测可以帮助个人和医疗提供者预见并主动解决影响良好休息的因素，从而改善身心健康。

Method: 使用卷积层捕捉多特征间的空间交互，循环神经网络层处理长期时间健康数据，集成域分类器实现跨对象泛化。

Result: 在5种输入窗口和5种预测窗口设置下均优于4个基线模型，最低RMSE为0.282（7天输入窗口+1天预测窗口），多天预测仍保持强性能。

Conclusion: 该框架为使用商业可穿戴设备稀疏数据和域适应技术提供了鲁棒且可适应的个性化睡眠预测解决方案。

Abstract: A sleep forecast allows individuals and healthcare providers to anticipate
and proactively address factors influencing restful rest, ultimately improving
mental and physical well-being. This work presents an adaptive spatial and
temporal model (AdaST-Sleep) for predicting sleep scores. Our proposed model
combines convolutional layers to capture spatial feature interactions between
multiple features and recurrent neural network layers to handle longer-term
temporal health-related data. A domain classifier is further integrated to
generalize across different subjects. We conducted several experiments using
five input window sizes (3, 5, 7, 9, 11 days) and five predicting window sizes
(1, 3, 5, 7, 9 days). Our approach consistently outperformed four baseline
models, achieving its lowest RMSE (0.282) with a seven-day input window and a
one-day predicting window. Moreover, the method maintained strong performance
even when forecasting multiple days into the future, demonstrating its
versatility for real-world applications. Visual comparisons reveal that the
model accurately tracks both the overall sleep score level and daily
fluctuations. These findings prove that the proposed framework provides a
robust and adaptable solution for personalized sleep forecasting using sparse
data from commercial wearable devices and domain adaptation techniques.

</details>


### [6] [Improving the Elevational Focusing of Fast Orthogonal Row-Column Electronic Scanning (FORCES) Ultrasound Imaging using Retrospective Transmit Beamforming (RTB)](https://arxiv.org/abs/2509.09056)
*Michael Caulfield,Randy Palamar,Darren Dahunsi,Mohammad Rahim Sobhani,Negar Majidi,Roger Zemp*

Main category: eess.SP

TL;DR: 提出了FORCES成像方案的改进方法，通过应用回顾性发射波束成形(RTB)来改善Row Column Arrays在焦平面外的仰角聚焦性能


<details>
  <summary>Details</summary>
Motivation: 传统FORCES成像方案由于固定的仰角聚焦和大发射孔径，在焦点外的仰角聚焦性能较差，需要改进以提升成像质量

Method: 在FORCES和uFORCES方法中应用回顾性发射波束成形(RTB)技术，在仰角方向进行发射聚焦

Result: 实验显示应用RTB后，在焦点外的仰角聚焦能力得到显著改善，在焦点处性能保持相当或有所提升，通过FWHM和gCNR量化验证

Conclusion: RTB技术有效提升了FORCES成像方案的仰角聚焦性能，为Row Column Arrays的容积成像提供了更好的解决方案

Abstract: Recent developments in Row Column Arrays (RCAs) have presented promising
options for volumetric imaging without the need for the excessive channel
counts of fully wired 2D-arrays. Bias programmable RCAs, also known as Top
Orthogonal to Bottom Electrode (TOBE) Arrays, show further promise in that
imaging schemes, such as Fast Orthogonal Row-Column Electronic Scanning
(FORCES) allow for full transmit and receive focusing everywhere in the image
plane. However, due to its fixed elevational focus and large transmit aperture,
FORCES experiences poor elevational focusing away from the focal point. In this
study we present a modification to the FORCES imaging scheme by applying
Retrospective Transmit Beamforming (RTB) in the elevational direction to allow
for elevational transmit focusing everywhere in the imaging plane. We evaluate
FORCES and uFORCES methods, with and without RTB applied, when imaging both a
cyst and wire phantom. With experiment we show improved elevational focusing
capabilities away from the focal point when RTB is applied to both FORCES and
uFORCES. At the focal point, performance with RTB remains comparable or
improved relative to standard FORCES. This is quantified by the measurement of
Full Width Half Max when imaging the wire phantom, and by the generalized
Contrast to Noise Ratio when imaging the tubular cyst phantom. We also
demonstrate the volumetric imaging capabilities of FORCES RTB with the wire
phantom.

</details>


### [7] [Signed Graph Learning with Hidden Nodes](https://arxiv.org/abs/2509.09120)
*Rong Ye,Xue-Qin Jiang,Hui Feng,Jian Wang,Runhe Qiu*

Main category: eess.SP

TL;DR: 提出了一种针对带隐藏节点的符号图学习方法SGL-HNCS，通过列稀疏正则化约束优化问题来重构符号图拉普拉斯矩阵


<details>
  <summary>Details</summary>
Motivation: 现有符号图学习方法通常假设所有节点可见，但在实际应用中往往只有部分节点可观测，其余节点保持隐藏状态，需要解决这一挑战

Method: 基于符号图上信号平滑的假设，将符号图拓扑推断构建为带列稀疏正则化的约束优化问题，使用定制化的块坐标下降(BCD)方法求解

Result: 在合成数据和真实数据上的实验结果表明了所提SGL-HNCS方法的有效性

Conclusion: 该方法能够有效处理存在隐藏节点的符号图学习问题，为实际应用提供了可行的解决方案

Abstract: Signed graphs, which are characterized by both positive and negative edge
weights, have recently attracted significant attention in the field of graph
signal processing (GSP). Existing works on signed graph learning typically
assume that all graph nodes are available. However, in some specific
applications, only a subset of nodes can be observed while the remaining nodes
stay hidden. To address this challenge, we propose a novel method for
identifying signed graph that accounts for hidden nodes, termed \textit{signed
graph learning with hidden nodes under column-sparsity regularization}
(SGL-HNCS). Our method is based on the assumption that graph signals are smooth
over signed graphs, i.e., signal values of two nodes connected by positive
(negative) edges are similar (dissimilar). Rooted in this prior assumption, the
topology inference of a signed graph is formulated as a constrained
optimization problem with column-sparsity regularization, where the goal is to
reconstruct the signed graph Laplacian matrix without disregarding the
influence of hidden nodes. We solve the constrained optimization problem using
a tailored block coordinate descent (BCD) approach. Experimental results using
synthetic data and real-world data demonstrate the efficiency of the proposed
SGL-HNCS method.

</details>


### [8] [Sequential Spectral Clustering of Data Sequences](https://arxiv.org/abs/2509.09144)
*G Dhinesh Chandran,Kota Srinivas Reddy,Srikrishna Bhashyam*

Main category: eess.SP

TL;DR: 提出了两种序列谱聚类算法(SEQ-SPEC和IA-SEQ-SPEC)，用于数据序列的非参数聚类，在有限样本下实现指数一致性，性能优于固定样本方法和传统序列聚类算法。


<details>
  <summary>Details</summary>
Motivation: 解决数据序列的非参数聚类问题，其中每个序列包含从未知分布生成的i.i.d.样本。传统方法需要固定样本量，而序列框架可以在给定错误概率下通过观察最少样本实现聚类。

Method: 提出了SEQ-SPEC算法和计算效率更高的IA-SEQ-SPEC算法。SEQ-SPEC基于谱聚类算法，在序列框架下工作；IA-SEQ-SPEC是其增量近似版本，计算更高效。

Result: 算法在有限时间内几乎必然停止且具有指数一致性。模拟实验表明，两种算法性能优于固定样本SPEC、SEQ-KMED和SEQ-SLINK算法。IA-SEQ-SPEC在保持计算效率的同时，性能接近SEQ-SPEC。

Conclusion: 这是首个在序列框架下研究数据序列谱聚类的工作，提出的算法在合成和真实数据集上都表现出色，为序列聚类提供了有效的解决方案。

Abstract: We study the problem of nonparametric clustering of data sequences, where
each data sequence comprises i.i.d. samples generated from an unknown
distribution. The true clusters are the clusters obtained using the Spectral
clustering algorithm (SPEC) on the pairwise distance between the true
distributions corresponding to the data sequences. Since the true distributions
are unknown, the objective is to estimate the clusters by observing the minimum
number of samples from the data sequences for a given error probability. To
solve this problem, we propose the Sequential Spectral clustering algorithm
(SEQ-SPEC), and show that it stops in finite time almost surely and is
exponentially consistent. We also propose a computationally more efficient
algorithm called the Incremental Approximate Sequential Spectral clustering
algorithm (IA-SEQ-SPEC). Through simulations, we show that both our proposed
algorithms perform better than the fixed sample size SPEC, the Sequential
$K$-Medoids clustering algorithm (SEQ-KMED) and the Sequential Single Linkage
clustering algorithm (SEQ-SLINK). The IA-SEQ-SPEC, while being computationally
efficient, performs close to SEQ-SPEC on both synthetic and real-world
datasets. To the best of our knowledge, this is the first work on spectral
clustering of data sequences under a sequential framework.

</details>


### [9] [JFRFFNet: A Data-Model Co-Driven Graph Signal Denoising Model with Partial Prior Information](https://arxiv.org/abs/2509.09147)
*Ziqi Yan,Zhichao Zhang*

Main category: eess.SP

TL;DR: 提出JFRFFNet方法，将联合时-顶点分数傅里叶变换域的维纳滤波模型嵌入神经网络，通过数据驱动方式更新变换阶数对和滤波器系数，仅需部分先验信息即可有效去噪。


<details>
  <summary>Details</summary>
Motivation: 传统滤波方法需要完整的图信号先验信息，要么通过网格搜索确定变换阶数对和滤波器系数，要么使用梯度下降策略优化，限制了实际应用。

Method: 将JFRFT域维纳滤波模型嵌入神经网络架构，采用数据-模型协同驱动的方式，通过数据驱动方法更新变换阶数对和滤波器系数。

Result: 实验表明JFRFFNet在输出信噪比方面相比现有最先进方法有显著提升。

Conclusion: JFRFFNet方法能够仅使用部分先验信息实现有效的时变图信号去噪，解决了传统方法对完整先验信息的依赖问题。

Abstract: Wiener filtering in the joint time-vertex fractional Fourier transform
(JFRFT) domain has shown high effectiveness in denoising time-varying graph
signals. Traditional filtering models use grid search to determine the
transform-order pair and compute filter coefficients, while learnable ones
employ gradient-descent strategies to optimize them; both require complete
prior information of graph signals. To overcome this shortcoming, this letter
proposes a data-model co-driven denoising approach, termed neural-network-aided
joint time-vertex fractional Fourier filtering (JFRFFNet), which embeds the
JFRFT-domain Wiener filter model into a neural network and updates the
transform-order pair and filter coefficients through a data-driven approach.
This design enables effective denoising using only partial prior information.
Experiments demonstrate that JFRFFNet achieves significant improvements in
output signal-to-noise ratio compared with some state-of-the-art methods.

</details>


### [10] [On Sampling of Multiple Correlated Stochastic Signals](https://arxiv.org/abs/2509.09225)
*Lin Jin,Hang Sheng,Hui Feng,Bo Hu*

Main category: eess.SP

TL;DR: 提出了一种基于潜在源分解的多通道相关信号高效采样方法，通过建模相关通道为少量不相关潜在源的线性组合，实现了理论最小采样密度下的近无损重建。


<details>
  <summary>Details</summary>
Motivation: 多通道随机信号存在统计相关性，但传统独立采样方法导致数据冗余。为了利用相关性实现高效采样，需要开发能够达到理论最小采样密度的采样方案。

Method: 将相关通道建模为少量不相关宽平稳潜在源的线性组合，通过潜在源的频谱分割，结合空时采样和插值技术，构建多波段采样方案。

Result: 实验证明该方法在合成和真实数据集上都能在理论采样密度下实现近无损重建，验证了其效率。

Conclusion: 提出的多波段采样方案达到了理论最小采样密度，为多通道相关信号的高效采样提供了有效解决方案。

Abstract: Multiple stochastic signals possess inherent statistical correlations, yet
conventional sampling methods that process each channel independently result in
data redundancy. To leverage this correlation for efficient sampling, we model
correlated channels as a linear combination of a smaller set of uncorrelated,
wide-sense stationary latent sources. We establish a theoretical lower bound on
the total sampling density for zero mean-square error reconstruction, proving
it equals the ratio of the joint spectral bandwidth of latent sources to the
number of correlated signal channels. We then develop a constructive multi-band
sampling scheme that attains this bound. The proposed method operates via
spectral partitioning of the latent sources, followed by spatio-temporal
sampling and interpolation. Experiments on synthetic and real datasets confirm
that our scheme achieves near-lossless reconstruction precisely at the
theoretical sampling density, validating its efficiency.

</details>


### [11] [Improved Riemannian potato field: an Automatic Artifact Rejection Method for EEG](https://arxiv.org/abs/2509.09264)
*Davoud Hajhassani,Quentin Barthélemy,Jérémie Mattout,Marco Congedo*

Main category: eess.SP

TL;DR: iRPF是一种快速全自动的EEG伪影去除方法，在多个指标上显著优于现有技术，处理速度快至每epoch 8毫秒


<details>
  <summary>Details</summary>
Motivation: EEG信号清洁是研究领域的关键挑战，现有方法依赖人工参数调优、对异常值敏感且计算成本高，需要自动化解决方案

Method: 改进的黎曼土豆场(iRPF)方法，基于黎曼几何的自动伪影拒绝技术

Result: 在226个EEG记录上测试，iRPF相比其他方法在召回率提升22%，特异性提升102%，精确度提升54%，F1分数提升24%，统计显著(p<0.001)

Conclusion: iRPF为脑机接口和临床神经影像应用提供了强大、数据驱动的伪影拒绝解决方案，适用于大规模EEG数据处理和实时应用

Abstract: Electroencephalography (EEG) signal cleaning has long been a critical
challenge in the research community. The presence of artifacts can
significantly degrade EEG data quality, complicating analysis and potentially
leading to erroneous interpretations. While various artifact rejection methods
have been proposed, the gold standard remains manual visual inspection by human
experts-a process that is time-consuming, subjective, and impractical for
large-scale EEG studies. Existing techniques are often hindered by a strong
reliance on manual hyperparameter tuning, sensitivity to outliers, and high
computational costs. In this paper, we introduce the improved Riemannian Potato
Field (iRPF), a fast and fully automated method for EEG artifact rejection that
addresses key limitations of current approaches. We evaluate iRPF against
several state-of-the-art artifact rejection methods, using two publicly
available EEG databases, labeled for various artifact types, comprising 226 EEG
recordings. Our results demonstrate that iRPF outperforms all competitors
across multiple metrics, with gains of up to 22% in recall, 102% in
specificity, 54% in precision, and 24% in F1-score, compared to Isolation
Forest, Autoreject, Riemannian Potato, and Riemannian Potato Field,
respectively. Statistical analysis confirmed the significance of these
improvements (p < 0.001) with large effect sizes (Cohen's d > 0.8) in most
comparisons. Additionally, on a typical EEG recording iRPF performs artifact
cleaning in under 8 milliseconds per epoch using a standard laptop,
highlighting its efficiency for large-scale EEG data processing and real-time
applications. iRPF offers a robust and data-driven artifact rejection solution
for high-quality EEG pre-processing in brain-computer interfaces and clinical
neuroimaging applications.

</details>


### [12] [On the Relation of Characteristic Modes of Different Conducting Structures](https://arxiv.org/abs/2509.09282)
*Leonardo Mörlein,Dirk Manteuffel*

Main category: eess.SP

TL;DR: 基于另一结构的特征模式分析导体结构散射的形式化方法，定义模态变换矩阵并提供应用示例


<details>
  <summary>Details</summary>
Motivation: 为了使用共同的特征模式基础来分析和比较不同的导体结构，特别是当一个结构的表面是另一结构的超集时

Method: 推导形式化方法，定义模态变换矩阵来描述两个结构之间特征场和权重系数的映射关系，并进行矩阵基准转换

Result: 证明在这种情况下散射矩阵和微氧矩阵不再是对角矩阵，通过两个示例验证和展示了该形式化方法的有效性

Conclusion: 该形式化方法为从基础结构逐步修改天线元件的设计过程提供了有用的分析工具，通过模态变换矩阵实现了不同基准下微氧矩阵的转换

Abstract: A formalism is derived to analyze the scattering of a conducting structure
based on the characteristic modes of another structure whose surface is a
superset of the first structure. This enables the analysis and comparison of
different structures using a common basis of characteristic modes.
Additionally, it is shown that the scattering matrices and perturbation
matrices are no longer diagonal in these cases. Based on this, a modal
transformation matrix is defined to describe the mapping between the
characteristic fields and the weighting coefficients of the two structures.
This matrix enables the conversion of the perturbation matrices in different
bases. Finally, two examples are provided along with a discussion of some
aspects of the theory. The first example aims to validate and illustrate the
formalism. The second example shows how the formalism can be applied in the
design process of an antenna element that is gradually modified, starting from
a base structure.

</details>


### [13] [Channel Estimation and Analog Precoding for Pixel-based Fluid-Antenna-Assisted Multiuser MIMO-OFDM Systems](https://arxiv.org/abs/2509.09373)
*Huayan Guo,Jichen Zhang,Junhui Rao,Ross Murch,Vincent K. N. Lau*

Main category: eess.SP

TL;DR: 基于浓稀通道恢复框架的像素流体天线系统，提出了两种低复杂度通道估计算法和模拟预编码方案，在高信器比环境下显著提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 像素流体天线虽然提供了更好的多工增益和更快的辐射图切换，但引入了状态非可分离通道响应问题，对通道估计和模拟预编码构成挑战。

Method: 提出了一个浓稀通道恢复框架，使用近似可分离通道响应模型和基于DNN的天线辐射函数。设计了两种低复杂度算法：正交匹配追踪法和变分贝叶斯推断法，用于恢复不同散射集群角度的通道响应。

Result: 模拟结果显示，所提方法在高信器比环境下特别是在用户数量较多时，性能显著超过多个基准方法。

Conclusion: 该研究成功解决了像素流体天线系统中的通道估计和预编码挑战，通过浓稀恢复和优化算法实现了高效的系统性能。

Abstract: Pixel-based fluid antennas provide enhanced multiplexing gains and quicker
radiation pattern switching than traditional designs. However, this innovation
introduces challenges for channel estimation and analog precoding due to the
state-non-separable channel response problem. This paper explores a multiuser
MIMO-OFDM system utilizing pixel-based fluid antennas, informed by measurements
from a real-world prototype. We present a sparse channel recovery framework for
uplink channel sounding, employing an approximate separable channel response
model with DNN-based antenna radiation functions. We then propose two
low-complexity channel estimation algorithms that leverage orthogonal matching
pursuit and variational Bayesian inference to accurately recover channel
responses across various scattering cluster angles. These estimations enable
the prediction of composite channels for all fluid antenna states, leading to
an analog precoding scheme that optimally selects switching states for
different antennas. Our simulation results indicate that the proposed approach
significantly outperforms several baseline methods, especially in high
signal-to-noise ratio environments with numerous users.

</details>


### [14] [A Multi-Scale Feature Extraction and Fusion UNet for Pathloss Prediction in UAV-Assisted mmWave Radio Networks](https://arxiv.org/abs/2509.09606)
*Sajjad Hussain*

Main category: eess.SP

TL;DR: 提出基于UNet的深度学习架构，用于无人机毫米波网络路径损耗预测，结合多尺度特征提取和ASPP瓶颈，在准确性和效率上优于现有方法


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在路径损耗预测中泛化能力不足、对噪声输入鲁棒性差以及对无人机高度敏感等问题

Method: 使用UNet架构，结合多尺度特征提取、卷积特征融合和ASPP瓶颈进行上下文聚合，输入包括对数距离、LOS掩码和建筑掩码，并开发了向量化LOS掩码计算算法

Result: 在内部射线追踪数据和RadioMapSeer基准测试中，模型在准确性和效率方面均优于多个最先进的基线方法

Conclusion: 所提出的深度学习架构能够有效预测路径损耗，具有优异的泛化能力和计算效率，所有源代码已公开以支持可重复性和未来研究

Abstract: Accurate pathloss prediction is essential for the design and optimization of
UAV-assisted millimeter-wave (mmWave) networks. While deep learning approaches
have shown strong potential, their generalization across diverse environments,
robustness to noisy inputs, and sensitivity to UAV altitude remain
underexplored. To address these challenges, we propose a UNet-based deep
learning architecture that combines multi-scale feature extraction,
convolution-based feature fusion, and an atrous spatial pyramid pooling (ASPP)
bottleneck for efficient context aggregation. The model predicts pathloss maps
from log-distance, line-of-sight (LOS) mask, and building mask inputs. In
addition, we develop a fully vectorized LOS mask computation algorithm that
significantly accelerates pre-processing and enables large-scale dataset
generation. Extensive evaluations on both in-house ray-tracing data and the
RadioMapSeer benchmark demonstrate that the proposed model outperforms several
state-of-the-art baselines in accuracy and efficiency. All source code is
publicly released to support reproducibility and future research.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [15] [Automotive sound field reproduction using deep optimization with spatial domain constraint](https://arxiv.org/abs/2509.09149)
*Yufan Qian,Tianshu Qu,Xihong Wu*

Main category: eess.AS

TL;DR: SPMnet是一种基于学习的声场重现方法，通过空间功率图约束和深度学习优化，在汽车座舱复杂声学环境中同时提升音质和空间定位精度。


<details>
  <summary>Details</summary>
Motivation: 汽车座舱声学环境复杂，传统方法需要在音质和空间定位精度之间做出权衡，需要一种能够同时改善两者的解决方案。

Method: 提出空间功率图(SPM)约束来表征重现声场的角度能量分布，通过波束成形将能量引导至目标方向；结合多通道均衡框架，使用神经网络进行深度学习优化来解决非凸性问题。

Result: 客观和主观评估均证实该方法在汽车座舱内提升了音质和空间定位能力，并分析了不同音频材料和虚拟声源到达角度的影响因素。

Conclusion: SPMnet方法成功解决了复杂声学环境中音质与空间定位的权衡问题，为汽车音频系统提供了有效的声场重现解决方案。

Abstract: Sound field reproduction with undistorted sound quality and precise spatial
localization is desirable for automotive audio systems. However, the complexity
of automotive cabin acoustic environment often necessitates a trade-off between
sound quality and spatial accuracy. To overcome this limitation, we propose
Spatial Power Map Net (SPMnet), a learning-based sound field reproduction
method that improves both sound quality and spatial localization in complex
environments. We introduce a spatial power map (SPM) constraint, which
characterizes the angular energy distribution of the reproduced field using
beamforming. This constraint guides energy toward the intended direction to
enhance spatial localization, and is integrated into a multi-channel
equalization framework to also improve sound quality under reverberant
conditions. To address the resulting non-convexity, deep optimization that use
neural networks to solve optimization problems is employed for filter design.
Both in situ objective and subjective evaluations confirm that our method
enhances sound quality and improves spatial localization within the automotive
cabin. Furthermore, we analyze the influence of different audio materials and
the arrival angles of the virtual sound source in the reproduced sound field,
investigating the potential underlying factors affecting these results.

</details>


### [16] [MAPSS: Manifold-based Assessment of Perceptual Source Separation](https://arxiv.org/abs/2509.09212)
*Amir Ivry,Samuele Cornell,Shinji Watanabe*

Main category: eess.AS

TL;DR: 这篇论文提出了Perceptual Separation (PS)和Perceptual Match (PM)这对新的度量指标，通过流形多层面学习和马洋距离计算，能够准确评估源分离系统的自我失真和漏泰问题，与主观人类感知相关性达到86-87%。


<details>
  <summary>Details</summary>
Motivation: 目前的源分离系统客观评估方法与主观人类感知存在误差，尤其是在漏泰和自我失真相互作用时。需要一种能够功能性地隔离这两个因素的评估方法。

Method: 使用预训练的自监督学习模型编码波形信号，通过流形多层面技术将表征投影到一个济距离与信号相似性对齐的流形多层面上。PS通过马洋距离测量输出与属于其参考集群的距离，捕获自我失真；PM通过测量输出与属于和最近非属于集群的距离，量化漏泰。

Result: 在英语、西班牙语和音乐混合信号上的实验显示，PS和PM在14种竞争方法中几乎总是获得最高的与人类平均意见分数的线性相关系数，语音达到86.36%，音乐达到87.21%。最差情况下误差半径为1.39%，概率95%信心区间为12.21%。

Conclusion: PS和PM是一对不可微分、粒度细的评估方法，能够准确地隔离和量化源分离系统中的自我失真和漏泰问题，与人类感知有强相关性，为源分离系统提供了更可靠和信息丰富的评估。

Abstract: Objective assessment of source-separation systems still mismatches subjective
human perception, especially when leakage and self-distortion interact. We
introduce the Perceptual Separation (PS) and Perceptual Match (PM), the first
pair of measures that functionally isolate these two factors. Our intrusive
method begins with generating a bank of fundamental distortions for each
reference waveform signal in the mixture. Distortions, references, and their
respective system outputs from all sources are then independently encoded by a
pre-trained self-supervised learning model. These representations are
aggregated and projected onto a manifold via diffusion maps, which aligns
Euclidean distances on the manifold with dissimilarities of the encoded
waveforms. On this manifold, the PM measures the Mahalanobis distance from each
output to its attributed cluster that consists of its reference and distortions
embeddings, capturing self-distortion. The PS accounts for the Mahalanobis
distance of the output to the attributed and to the closest non-attributed
clusters, quantifying leakage. Both measures are differentiable and granular,
operating at a resolution as low as 50 frames per second. We further derive,
for both measures, deterministic error radius and non-asymptotic,
high-probability confidence intervals (CIs). Experiments on English, Spanish,
and music mixtures show that the PS and PM nearly always achieve the highest
linear correlation coefficients with human mean-opinion scores than 14
competitors, reaching as high as 86.36% for speech and 87.21% for music. We
observe, at worst, an error radius of 1.39% and a probabilistic 95% CI of
12.21% for these coefficients, which improves reliable and informed evaluation.
Using mutual information, the measures complement each other most as their
values decrease, suggesting they are jointly more informative as system
performance degrades.

</details>


### [17] [Over-the-Air Adversarial Attack Detection: from Datasets to Defenses](https://arxiv.org/abs/2509.09296)
*Li Wang,Xiaoyan Lei,Haorui He,Lei Wang,Jie Shi,Zhizheng Wu*

Main category: eess.AS

TL;DR: 提出了AdvSV 2.0数据集（628k样本，800小时）用于测试ASV系统对抗攻击的检测方法，包含OTL和OTA攻击场景。提出了基于神经重放模拟器的新型OTA攻击方法和基于对比学习的CODA-OCC防御方法，在数据集上达到11.2% EER和0.95 AUC。


<details>
  <summary>Details</summary>
Motivation: 现有的ASV系统容易受到线上和无线对抗攻击，但缺乏全面的数据集来测试各种检测方法的有效性，需要开发更强大的数据集和防御方法。

Method: 1) 构建AdvSV 2.0大规模数据集；2) 提出基于神经重放模拟器的新型OTA对抗攻击方法；3) 提出CODA-OCC对比学习防御框架（单类分类）。

Result: CODA-OCC在AdvSV 2.0数据集上达到11.2%的等错误率和0.95的AUC，优于现有最先进的检测方法。

Conclusion: AdvSV 2.0数据集为ASV安全研究提供了重要基准，提出的NRS攻击方法增强了OTA攻击威胁，CODA-OCC防御方法在检测对抗攻击方面表现出色。

Abstract: Automatic Speaker Verification (ASV) systems can be used for voice-enabled
applications for identity verification. However, recent studies have exposed
these systems' vulnerabilities to both over-the-line (OTL) and over-the-air
(OTA) adversarial attacks. Although various detection methods have been
proposed to counter these threats, they have not been thoroughly tested due to
the lack of a comprehensive data set. To address this gap, we developed the
AdvSV 2.0 dataset, which contains 628k samples with a total duration of 800
hours. This dataset incorporates classical adversarial attack algorithms, ASV
systems, and encompasses both OTL and OTA scenarios. Furthermore, we introduce
a novel adversarial attack method based on a Neural Replay Simulator (NRS),
which enhances the potency of adversarial OTA attacks, thereby presenting a
greater threat to ASV systems. To defend against these attacks, we propose
CODA-OCC, a contrastive learning approach within the one-class classification
framework. Experimental results show that CODA-OCC achieves an EER of 11.2% and
an AUC of 0.95 on the AdvSV 2.0 dataset, outperforming several state-of-the-art
detection methods.

</details>


### [18] [Listening for "You": Enhancing Speech Image Retrieval via Target Speaker Extraction](https://arxiv.org/abs/2509.09306)
*Wenhao Yang,Jianguo Wei,Wenhuan Lu,Xinyue Song,Xianghu Yue*

Main category: eess.AS

TL;DR: 这篇论文提出了一种新的目标讲话人语音-图像检索框架，通过目标讲话人感知对比学习在多讲话人场景中实现了语音与图像的准确对齐，在2人和3人场景不分别获得36.3%和29.9%的Recall@1指标，显著超过现有方法。


<details>
  <summary>Details</summary>
Motivation: 虽然使用语言线索进行图像检索在多模态感知中展现出很大潜力，但在多讲话人场景中利用语音仍然面临挑战。需要解决如何在存在多个讲话人的情况下准确检索目标讲话人的语音指令并与图像对应的问题。

Method: 提出了一种新的目标讲话人语音-图像检索框架，通过目标讲话人感知对比学习方法，将预训练的自监督音频编码器与视觉模型集成。该方法基于目标讲话人提取和检索模块进行条件化处理，能够从目标讲话人提取语音命令并与对应图像对齐。

Result: 在SpokenCOCO2Mix和SpokenCOCO3Mix数据集上的实验表明，TSRE方法显著超过现有方法，在2人和3人场景不分别达到36.3%和29.9%的Recall@1指标。这是对单讲话人基线模型和最新模型的显著改进。

Conclusion: 该方法在多讲话人语音-图像检索任务中表现出艰强的性能，显示了在辅助机器人和多模态交互系统中实际部署的潜力。该研究为多讲话人环境下的语音驱动图像检索提供了有效的解决方案。

Abstract: Image retrieval using spoken language cues has emerged as a promising
direction in multimodal perception, yet leveraging speech in multi-speaker
scenarios remains challenging. We propose a novel Target Speaker Speech-Image
Retrieval task and a framework that learns the relationship between images and
multi-speaker speech signals in the presence of a target speaker. Our method
integrates pre-trained self-supervised audio encoders with vision models via
target speaker-aware contrastive learning, conditioned on a Target Speaker
Extraction and Retrieval module. This enables the system to extract spoken
commands from the target speaker and align them with corresponding images.
Experiments on SpokenCOCO2Mix and SpokenCOCO3Mix show that TSRE significantly
outperforms existing methods, achieving 36.3% and 29.9% Recall@1 in 2 and 3
speaker scenarios, respectively - substantial improvements over single speaker
baselines and state-of-the-art models. Our approach demonstrates potential for
real-world deployment in assistive robotics and multimodal interaction systems.

</details>


### [19] [Short-term cognitive fatigue of spatial selective attention after face-to-face conversations in virtual noisy environments](https://arxiv.org/abs/2509.09479)
*Ľuboš Hládek,Piotr Majdak,Robert Baumgartner*

Main category: eess.AS

TL;DR: 研究发现，在嘈杂环境中进行对话后，听觉空间选择性注意任务的反应时间反而缩短，准确率无显著变化，与预期相反。


<details>
  <summary>Details</summary>
Motivation: 研究空间选择性注意在鸡尾酒会场景中的重要性，以及短期认知疲劳是否会影响这种注意能力。

Method: 使用虚拟混响房间环境，让正常听力年轻参与者在三种条件下（嘈杂环境对话、被动聆听噪声、安静环境对话）前后执行听觉空间选择性注意任务。

Result: 嘈杂环境对话和被动聆听后，自我报告的努力和疲劳感增加，但注意任务反应时间反而缩短，准确率无系统性变化，且观察到强烈的训练效应。

Conclusion: 短期认知疲劳可能不会损害听觉空间选择性注意，反而可能通过某种机制改善反应时间，同时训练效应在注意任务中表现显著。

Abstract: Spatial selective attention is an important asset for communication in
cocktail party situations but may be compromised by short-term cognitive
fatigue. Here we tested whether an effortful conversation in a highly
ecological setting depletes task performance in an auditory spatial selective
attention task. Young participants with normal hearing performed the task
before and after (1) having a real dyadic face-to-face conversation on a free
topic in a virtual reverberant room with simulated interfering conversations
and background babble noise at 72 dB SPL for 30 minutes, (2) passively
listening to the interfering conversations and babble noise, or (3) having the
conversation in quiet. Self-reported perceived effort and fatigue increased
after conversations in noise and passive listening relative to the reports
after conversations in quiet. In contrast to our expectations, response times
in the attention task decreased, rather than increased, after conversation in
noise and accuracy did not change systematically in any of the conditions on
the group level. Unexpectedly, we observed strong training effects between the
individual sessions in our within-subject design even after one hour of
training on a different day.

</details>


### [20] [Acoustic to Articulatory Speech Inversion for Children with Velopharyngeal Insufficiency](https://arxiv.org/abs/2509.09489)
*Saba Tabatabaee,Suzanne Boyce,Liran Oren,Mark Tiede,Carol Espy-Wilson*

Main category: eess.AS

TL;DR: 通过语音反向技术结合唱音源信息，完善了鼻音性估计模型，并通过学习过渡实现了成人模型向儿童VPI症患者的调适


<details>
  <summary>Details</summary>
Motivation: 传统鼻音性评估方法如鼻内镜检查和鼻量测导致不适感，特别是对儿童而言，需要无侵入性的替代方案

Method: 在基于健康成人鼻音性数据训练的语音反向系统中，增强了来自电唱图的源信息和音频推导的F0、周期性和非周期性能量估计，然后通过学习过渡技术将模型调整到儿童VPI症患者

Result: 模型实现了16.92%相对收益的Pearson相关系数提升，细调后在儿童VPI数据上进一步获得7.90%的相对收益

Conclusion: 这种方法有效地提高了鼻音性估计的准确性，为儿童口腔叙相关疾病的无侵入性评估提供了可行的技术解决方案

Abstract: Traditional clinical approaches for assessing nasality, such as
nasopharyngoscopy and nasometry, involve unpleasant experiences and are
problematic for children. Speech Inversion (SI), a noninvasive technique,
offers a promising alternative for estimating articulatory movement without the
need for physical instrumentation. In this study, an SI system trained on
nasalance data from healthy adults is augmented with source information from
electroglottography and acoustically derived F0, periodic and aperiodic energy
estimates as proxies for glottal control. This model achieves 16.92% relative
improvement in Pearson Product-Moment Correlation (PPMC) compared to a previous
SI system for nasalance estimation. To adapt the SI system for nasalance
estimation in children with Velopharyngeal Insufficiency (VPI), the model
initially trained on adult speech was fine-tuned using children with VPI data,
yielding an 7.90% relative improvement in PPMC compared to its performance
before fine-tuning.

</details>


### [21] [Region-Specific Audio Tagging for Spatial Sound](https://arxiv.org/abs/2509.09526)
*Jinzheng Zhao,Yong Xu,Haohe Liu,Davide Berghi,Xinyuan Qian,Qiuqiang Kong,Junqi Zhao,Mark D. Plumbley,Wenwu Wang*

Main category: eess.AS

TL;DR: 本文提出了区域特定音频标记新任务，通过麦克风阵列标记空间音频中特定区域的声音事件，并扩展了PANNs和AST等先进音频标记系统来解决该任务。


<details>
  <summary>Details</summary>
Motivation: 传统音频标记只能识别声音事件的存在，无法定位其在空间中的具体位置。为了实现对空间音频中特定区域声音事件的精确标记，需要开发新的区域特定音频标记方法。

Method: 研究了频谱、空间和位置特征的不同组合，并扩展了预训练音频神经网络(PANNs)和音频频谱变换器(AST)来处理区域特定音频标记任务。

Result: 在模拟和真实数据集上的实验结果表明，所提出的任务是可行的，所提出的方法是有效的。进一步实验表明，结合方向特征对全向标记有益。

Conclusion: 区域特定音频标记是一个可行的新任务，通过结合空间和方向特征，可以显著提高空间音频中声音事件的定位和标记性能。

Abstract: Audio tagging aims to label sound events appearing in an audio recording. In
this paper, we propose region-specific audio tagging, a new task which labels
sound events in a given region for spatial audio recorded by a microphone
array. The region can be specified as an angular space or a distance from the
microphone. We first study the performance of different combinations of
spectral, spatial, and position features. Then we extend state-of-the-art audio
tagging systems such as pre-trained audio neural networks (PANNs) and audio
spectrogram transformer (AST) to the proposed region-specific audio tagging
task. Experimental results on both the simulated and the real datasets show the
feasibility of the proposed task and the effectiveness of the proposed method.
Further experiments show that incorporating the directional features is
beneficial for omnidirectional tagging.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [22] [In situ estimation of the acoustic surface impedance using simulation-based inference](https://arxiv.org/abs/2509.08873)
*Jonas M. Schmid,Johannes D. Schmid,Martin Eser,Steffen Marburg*

Main category: cs.SD

TL;DR: 这篇论文提出了一种贝叶斯框架，通过神经网络和模拟推理来精确估计室内声学表面阻抗，免除了传统测量方法的限制。


<details>
  <summary>Details</summary>
Motivation: 传统声学边界条件测量技术存在偏差，方法有限制，需要一种更准确、可靠的原地阻抗估计方法来满足实际应用需求。

Method: 采用贝叶斯框架和模拟基于推理，利用现代神经网络结构直接将模拟数据映射到参数后验分布，使用带分数微积分项的阻尼模型来建模阻抗行为。

Result: 在立方体房间有限元模型上验证，并通过阻抗管测量验证，成功估计所有6个单独阻抗，在数值汽车车廊模型中也展现了高预测准确性和可靠的不确定性量化。

Conclusion: 该方法能够在真实环境中进行通用、高效且物理一致的声学边界条件特征化，具有良好的推理检验和覆盖诊断确认。

Abstract: Accurate acoustic simulations of enclosed spaces require precise boundary
conditions, typically expressed through surface impedances for wave-based
methods. Conventional measurement techniques often rely on simplifying
assumptions about the sound field and mounting conditions, limiting their
validity for real-world scenarios. To overcome these limitations, this study
introduces a Bayesian framework for the in situ estimation of
frequency-dependent acoustic surface impedances from sparse interior sound
pressure measurements. The approach employs simulation-based inference, which
leverages the expressiveness of modern neural network architectures to directly
map simulated data to posterior distributions of model parameters, bypassing
conventional sampling-based Bayesian approaches and offering advantages for
high-dimensional inference problems. Impedance behavior is modeled using a
damped oscillator model extended with a fractional calculus term. The framework
is verified on a finite element model of a cuboid room and further tested with
impedance tube measurements used as reference, achieving robust and accurate
estimation of all six individual impedances. Application to a numerical car
cabin model further demonstrates reliable uncertainty quantification and high
predictive accuracy even for complex-shaped geometries. Posterior predictive
checks and coverage diagnostics confirm well-calibrated inference, highlighting
the method's potential for generalizable, efficient, and physically consistent
characterization of acoustic boundary conditions in real-world interior
environments.

</details>


### [23] [MoLEx: Mixture of LoRA Experts in Speech Self-Supervised Models for Audio Deepfake Detection](https://arxiv.org/abs/2509.09175)
*Zihan Pan,Sailor Hardik Bhupendra,Jinyang Wu*

Main category: cs.SD

TL;DR: 通过结合Low-Rank Adaptation和Mixture-of-Experts路由的MoLEx框架，在保持SSL模型领先知识的同时高效小角度完成音频深度伪造检测，达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 解决SSL模型全量微调计算成本高的问题，提高音频深度伪造检测的参数效率

Method: 提出MoLEx框架，结合LoRA和MoE路由器，只微调选择的专家，支持域适应性扩展

Result: 在ASVSpoof 5数据集上达到SOTA性能，EER为5.56%（无增强），路由器能根据攻击类型激活相应专家

Conclusion: MoLEx提供了高效、灵活的参数效率微调方案，在保持性能的同时大幅降低计算成本

Abstract: While self-supervised learning (SSL)-based models have boosted audio deepfake
detection accuracy, fully finetuning them is computationally expensive. To
address this, we propose a parameter-efficient framework that combines Low-Rank
Adaptation with a Mixture-of-Experts router, called Mixture of LoRA Experts
(MoLEx). It preserves pre-trained knowledge of SSL models while efficiently
finetuning only selected experts, reducing training costs while maintaining
robust performance. The observed utility of experts during inference shows the
router reactivates the same experts for similar attacks but switches to other
experts for novel spoofs, confirming MoLEx's domain-aware adaptability. MoLEx
additionally offers flexibility for domain adaptation by allowing extra experts
to be trained without modifying the entire model. We mainly evaluate our
approach on the ASVSpoof 5 dataset and achieve the state-of-the-art (SOTA)
equal error rate (EER) of 5.56% on the evaluation set without augmentation.

</details>


### [24] [DeCodec: Rethinking Audio Codecs as Universal Disentangled Representation Learners](https://arxiv.org/abs/2509.09201)
*Xiaoxue Luo,Jinwei Huang,Runyan Yang,Yingying Gao,Junlan Feng,Chao Deng,Shilei Zhang*

Main category: cs.SD

TL;DR: DeCodec是一个新颖的神经编解码器，通过正交子空间分解实现音频的层次化解耦表示，将音频分离为语音和背景声音，并在语音内部进一步分解为语义和副语言成分，为多种音频应用提供可控的特征选择能力。


<details>
  <summary>Details</summary>
Motivation: 现实世界音频通常包含混合的语音和背景声音，而下游任务需要选择性访问这些组件。现有通用音频编解码器学习纠缠表示，而特定编解码器虽然提供解耦表示但仅限于语音，因此需要开发能够普遍解耦音频表示的编解码器。

Method: 基于编解码器框架，DeCodec引入两个关键技术：子空间正交投影模块将输入分解为两个解耦的正交子空间；表示交换训练过程确保这两个子空间分别对应语音和背景声音。使用并行RVQ独立量化语音和背景声音组件，并通过语义引导实现语音内部的语义和副语言分解。

Result: 实验结果表明DeCodec在保持先进信号重建的同时，实现了新能力：通过表示重组在噪声语音上实现优异的语音增强和有效的一键语音转换；通过干净的语义特征提高ASR鲁棒性；在TTS中实现可控的背景声音保留/抑制。

Conclusion: DeCodec作为一个通用的解耦表示学习器，通过层次化解耦表示实现了灵活的特征选择，使其成为多个音频应用的通用前端，为音频处理任务提供了新的可控能力。

Abstract: Universal audio codecs learn entangled representations across audio types,
whereas some specific codecs offer decoupled representations but are limited to
speech. Real-world audio, however, often contains mixed speech and background
sounds, and downstream tasks require selective access to these components.
Therefore, we rethink the audio codec as a universal disentangled
representation learner to enable controllable feature selection across
different audio tasks. To this end, we introduce DeCodec, a novel neural codec
that learns to decouple audio representations into orthogonal subspaces
dedicated to speech and background sound, and within speech, representations
are further decomposed into semantic and paralinguistic components. This
hierarchical disentanglement allows flexible feature selection, making DeCodec
a universal front-end for multiple audio applications. Technically, built upon
a codec framework, DeCodec incorporates two key innovations: a subspace
orthogonal projection module that factorizes the input into two decoupled
orthogonal subspaces, and a representation swap training procedure that ensures
these two subspaces are correlate to the speech and background sound,
respectively. These allows parallel RVQs to quantize speech and background
sound components independently. Furthermore, we employ semantic guidance to the
speech RVQ to achieve semantic and paralinguistic decomposition. Experimental
results show that DeCodec maintains advanced signal reconstruction while
enabling new capabilities: superior speech enhancement and effective one-shot
voice conversion on noisy speech via representation recombination, improved ASR
robustness through clean semantic features, and controllable background sound
preservation/suppression in TTS. Demo Page: https://luo404.github.io/DeCodecV2/

</details>


### [25] [Bona fide Cross Testing Reveals Weak Spot in Audio Deepfake Detection Systems](https://arxiv.org/abs/2509.09204)
*Chin Yuen Kwok,Jia Qi Yip,Zhen Qiu,Chi Hung Chi,Kwok Yan Lam*

Main category: cs.SD

TL;DR: 语音深度伪造检测模型评估方法改进，提出真实语音交叉测试框架，解决数据集偏差和评估不均衡问题


<details>
  <summary>Details</summary>
Motivation: 传统评估方法存在两大问题：1)多合成器数据集中样本数量不均衡导致EER偏差；2)真实语音类型单一，无法模拟实际场景

Method: 提出真实语音交叉测试框架，整合多样化真实语音数据集，并通过聚合EER进行更均衡的评估

Result: 在9种不同真实语音类型上对超100多个合成器进行基准测试，改善了模型的稳健性和可解释性

Conclusion: 新的评估框架提供了更可靠的语音深度伪造检测评估方法，并释放了新数据集促进进一步研究

Abstract: Audio deepfake detection (ADD) models are commonly evaluated using datasets
that combine multiple synthesizers, with performance reported as a single Equal
Error Rate (EER). However, this approach disproportionately weights
synthesizers with more samples, underrepresenting others and reducing the
overall reliability of EER. Additionally, most ADD datasets lack diversity in
bona fide speech, often featuring a single environment and speech style (e.g.,
clean read speech), limiting their ability to simulate real-world conditions.
To address these challenges, we propose bona fide cross-testing, a novel
evaluation framework that incorporates diverse bona fide datasets and
aggregates EERs for more balanced assessments. Our approach improves robustness
and interpretability compared to traditional evaluation methods. We benchmark
over 150 synthesizers across nine bona fide speech types and release a new
dataset to facilitate further research at
https://github.com/cyaaronk/audio_deepfake_eval.

</details>


### [26] [Adaptive Knowledge Distillation using a Device-Aware Teacher for Low-Complexity Acoustic Scene Classification](https://arxiv.org/abs/2509.09262)
*Seung Gyu Jeong,Seong Eun Kim*

Main category: cs.SD

TL;DR: 基于知识蒸馏的轻量级音频场景分类系统，通过双教师集成和设备感知特征对齐损失，在DCASE 2025挑战赛中取得了57.93%的准确率，显著优于基准模型。


<details>
  <summary>Details</summary>
Motivation: 解决音频场景分类中的双重挑战：严格的复杂度约束和对已知及未知设备的鲁棒泛化能力，同时利用测试时设备标签的新规则。

Method: 使用知识蒸馏框架，高效的CP-MobileNet学生模型从紧凑的双教师集成中学习。教师集成包括标准交叉熵训练的PaSST基准教师和使用新颖设备感知特征对齐(DAFA)损失的泛化专家教师。最后利用测试时设备标签进行设备特定的微调。

Result: 在开发集上达到57.93%的最终准确率，相比官方基准有显著提升，特别是在未知设备上表现优异。

Conclusion: 提出的知识蒸馏框架结合设备感知特征对齐和测试时设备特定微调，有效解决了设备鲁棒性和复杂度约束的双重挑战，为低复杂度设备鲁棒音频场景分类提供了有效解决方案。

Abstract: In this technical report, we describe our submission for Task 1,
Low-Complexity Device-Robust Acoustic Scene Classification, of the DCASE 2025
Challenge. Our work tackles the dual challenges of strict complexity
constraints and robust generalization to both seen and unseen devices, while
also leveraging the new rule allowing the use of device labels at test time.
Our proposed system is based on a knowledge distillation framework where an
efficient CP-MobileNet student learns from a compact, specialized two-teacher
ensemble. This ensemble combines a baseline PaSST teacher, trained with
standard cross-entropy, and a 'generalization expert' teacher. This expert is
trained using our novel Device-Aware Feature Alignment (DAFA) loss, adapted
from prior work, which explicitly structures the feature space for device
robustness. To capitalize on the availability of test-time device labels, the
distilled student model then undergoes a final device-specific fine-tuning
stage. Our proposed system achieves a final accuracy of 57.93\% on the
development set, demonstrating a significant improvement over the official
baseline, particularly on unseen devices.

</details>


### [27] [Efficient Transformer-Based Piano Transcription With Sparse Attention Mechanisms](https://arxiv.org/abs/2509.09318)
*Weixing Wei,Kazuyoshi Yoshii*

Main category: cs.SD

TL;DR: 提出基于稀疏注意力机制的高效Transformer架构，用于钢琴转录，在保持性能的同时显著降低计算成本和内存使用


<details>
  <summary>Details</summary>
Motivation: 传统Transformer模型由于自注意力机制的二次复杂度，无法一次性处理完整音乐片段，需要滑动窗口方式处理，限制了长序列依赖的捕捉

Method: 使用滑动窗口自注意力机制（编码器和解码器）、混合全局-局部交叉注意力机制（根据MIDI标记类型关注不同跨度）、分层池化策略

Result: 在MAESTRO数据集上实验显示，计算成本和内存使用显著降低，推理速度加快，同时转录性能与全注意力基线相当

Conclusion: 稀疏注意力机制可用于构建高效高性能的钢琴转录系统，允许在相同硬件上使用更长音频上下文进行训练

Abstract: This paper investigates automatic piano transcription based on
computationally-efficient yet high-performant variants of the Transformer that
can capture longer-term dependency over the whole musical piece. Recently,
transformer-based sequence-to-sequence models have demonstrated excellent
performance in piano transcription. These models, however, fail to deal with
the whole piece at once due to the quadratic complexity of the self-attention
mechanism, and music signals are thus typically processed in a sliding-window
manner in practice. To overcome this limitation, we propose an efficient
architecture with sparse attention mechanisms. Specifically, we introduce
sliding-window self-attention mechanisms for both the encoder and decoder, and
a hybrid global-local cross-attention mechanism that attends to various spans
according to the MIDI token types. We also use a hierarchical pooling strategy
between the encoder and decoder to further reduce computational load. Our
experiments on the MAESTRO dataset showed that the proposed model achieved a
significant reduction in computational cost and memory usage, accelerating
inference speed, while maintaining transcription performance comparable to the
full-attention baseline. This allows for training with longer audio contexts on
the same hardware, demonstrating the viability of sparse attention for building
efficient and high-performance piano transcription systems. The code is
available at https://github.com/WX-Wei/efficient-seq2seq-piano-trans.

</details>


### [28] [Finite Scalar Quantization Enables Redundant and Transmission-Robust Neural Audio Compression at Low Bit-rates](https://arxiv.org/abs/2509.09550)
*Harry Julia,Rachel Beeson,Lohith Konathala,Johanna Ulin,Jiameng Gao*

Main category: cs.SD

TL;DR: NeuCodec是基于FSQ的神经音频编解码器，相比传统RVQ方法具有更好的抗噪鲁棒性和编码冗余特性


<details>
  <summary>Details</summary>
Motivation: 现有神经音频编解码器主要依赖RVQ，而FSQ作为新兴替代方案能简化训练并支持单码本，但需要验证其在噪声信道传输中的鲁棒性

Method: 提出基于FSQ的NeuCodec编解码器，通过编码器蒸馏实验验证不同编码器能产生不同但等价的编码序列，并比较RVQ和FSQ在模拟噪声信道中的比特级扰动鲁棒性

Result: FSQ编码具有内置冗余特性，不同编码器能学习到不同但重建质量相当的编码序列；FSQ在噪声信道传输中表现出远优于RVQ的比特级扰动鲁棒性

Conclusion: FSQ-based NeuCodec在保持音频重建质量的同时，显著提升了在噪声信道环境下的传输鲁棒性，为实际应用提供了更可靠的音频编码解决方案

Abstract: Neural Audio Codecs (NACs) have become increasingly adopted in speech
processing tasks due to their excellent rate-distortion performance and
compatibility with Large Language Models (LLMs) as discrete feature
representations for audio generation. While most existing codecs rely on
Residual Vector Quantization (RVQ), Finite Scalar Quantization (FSQ) has
recently emerged as a compelling alternative that simplifies training and
natively supports single codebooks. We introduce NeuCodec, an FSQ-based NAC,
and show that FSQ encodes baked-in redundancy which produces an encoding which
is robust when transmitted through noisy channels. First, through an encoder
distillation experiment, we show that two different encoders can learn to
encode identical audio into vastly different code sequences whilst maintaining
comparable reconstruction quality with the same quantizer and decoder. Second,
we demonstrate that FSQ has vastly superior bit-level perturbation robustness
by comparing the performance of RVQ and FSQ codecs when simulating the
transmission of code sequences through a noisy channel.

</details>


### [29] [DiFlow-TTS: Discrete Flow Matching with Factorized Speech Tokens for Low-Latency Zero-Shot Text-To-Speech](https://arxiv.org/abs/2509.09631)
*Ngoc-Son Nguyen,Hieu-Nghia Huynh-Nguyen,Thanh V. T. Tran,Truong-Son Hy,Van Nguyen*

Main category: cs.SD

TL;DR: DiFlow-TTS是首个探索纯离散流匹配的语音合成模型，通过显式建模分解的语音属性，在零样本TTS中实现了高质量语音合成，推理速度比现有基线快25.8倍


<details>
  <summary>Details</summary>
Motivation: 解决现有零样本TTS方法推理速度慢、存在重复伪影的问题，充分利用离散表示的优势，避免将离散token嵌入连续空间带来的效率损失

Method: 采用纯离散流匹配方法，在紧凑统一架构中显式建模分解的语音属性，利用上下文学习条件化文本内容和参考语音的韵律声学属性，使用分解流预测机制分别处理韵律和声学细节

Result: 在自然度、韵律、说话人风格保持和能量控制等关键指标上表现优异，模型紧凑且推理延迟低，生成速度比最新基线快25.8倍

Conclusion: DiFlow-TTS证明了纯离散流匹配在语音合成中的有效性，为高效高质量的零样本TTS提供了新解决方案

Abstract: Zero-shot Text-to-Speech (TTS) aims to synthesize high-quality speech that
mimics the voice of an unseen speaker using only a short reference sample,
requiring not only speaker adaptation but also accurate modeling of prosodic
attributes. Recent approaches based on language models, diffusion, and flow
matching have shown promising results in zero-shot TTS, but still suffer from
slow inference and repetition artifacts. Discrete codec representations have
been widely adopted for speech synthesis, and recent works have begun to
explore diffusion models in purely discrete settings, suggesting the potential
of discrete generative modeling for speech synthesis. However, existing
flow-matching methods typically embed these discrete tokens into a continuous
space and apply continuous flow matching, which may not fully leverage the
advantages of discrete representations. To address these challenges, we
introduce DiFlow-TTS, which, to the best of our knowledge, is the first model
to explore purely Discrete Flow Matching for speech synthesis. DiFlow-TTS
explicitly models factorized speech attributes within a compact and unified
architecture. It leverages in-context learning by conditioning on textual
content, along with prosodic and acoustic attributes extracted from a reference
speech, enabling effective attribute cloning in a zero-shot setting. In
addition, the model employs a factorized flow prediction mechanism with
distinct heads for prosody and acoustic details, allowing it to learn
aspect-specific distributions. Experimental results demonstrate that DiFlow-TTS
achieves promising performance in several key metrics, including naturalness,
prosody, preservation of speaker style, and energy control. It also maintains a
compact model size and achieves low-latency inference, generating speech up to
25.8 times faster than the latest existing baselines.

</details>

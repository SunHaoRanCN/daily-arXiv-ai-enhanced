<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 20]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SD](#cs.SD) [Total: 14]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [FAS-ARIS: Turning Multipath Challenges Into Localization Opportunities](https://arxiv.org/abs/2509.12348)
*Hua Chen,Tao Gong,Tuo Wu,Maged Elkashlan,Baiyang Liu,Chan-Byoung Chae,Kin-Fai Tong,Kai-Kit Wong*

Main category: eess.SP

TL;DR: 提出FAS-ARIS框架，将多径效应从障碍转化为资源，实现无需ToA或频率多样性的鲁棒3D定位


<details>
  <summary>Details</summary>
Motivation: 传统SISO系统在3D定位中面临空间自由度有限和多径传播的不利影响，需要新的解决方案来利用多径效应提升定位精度

Method: 结合ARIS的信号放大能力和FAS的空间分集，设计UE导频序列和ARIS相位配置分离LoS和NLoS信道，采用多阶段估计算法（MUSIC算法估计AoA，最大似然估计恢复级联信道参数），最后通过几何三角定位确定3D位置

Result: 仿真结果表明该框架在丰富多径环境中实现了接近最优的定位精度并保持鲁棒性

Conclusion: FAS-ARIS框架成功将传统定位挑战转化为优势，为3D定位提供了有效的解决方案

Abstract: Traditional single-input single-output (SISO) systems face fundamental
limitations in achieving accurate three-dimensional (3D) localization due to
limited spatial degrees of freedom (DoF) and the adverse impact of multipath
propagation. This paper proposes a novel fluid antenna system (FAS)-active
reconfigurable intelligent surface (ARIS) framework that transforms multipath
effects from a hindrance into a resource for enhanced localization. By
synergistically combining the signal amplification capabilities of ARIS with
the spatial diversity enabled by FAS, the proposed system achieves robust 3D
user equipment (UE) positioning -- without relying on auxiliary information
such as time-of-arrival (ToA) or frequency diversity. The system exploits both
line-of-sight (LoS) and non-line-of-sight (NLoS) components through a tailored
signal decoupling strategy. We design novel UE pilot sequences and ARIS phase
configurations to effectively separate LoS and NLoS channels, enabling
independent parameter estimation. A multi-stage estimation algorithm is then
applied: the multiple signal classification (MUSIC) algorithm estimates
angle-of-arrival (AoA) from the direct path, while maximum likelihood
estimation with interior-point refinement recovers cascaded channel parameters
from the reflected path. Finally, geometric triangulation using least-squares
estimation determines the UE's 3D position based on the extracted AoA
information. Comprehensive performance analysis, including the derivation of
Cram\'{e}r-Rao bounds for both channel and position estimation, establishes
theoretical benchmarks. Simulation results confirm that the proposed FAS-ARIS
framework achieves near-optimal localization accuracy while maintaining
robustness in rich multipath environments -- effectively turning conventional
localization challenges into advantages.

</details>


### [2] [Partial Secrecy Analysis in Wireless Systems: Diversity-Enhanced PLS over Generalized Fading Channels](https://arxiv.org/abs/2509.12359)
*Henry Carvajal Mora,Nathaly Orozco,Fernando Almeida García,José Vega-Sánchez,Felipe Grijalva,Edgar Benitez Olivo*

Main category: eess.SP

TL;DR: 分析多簇波动双射线衰落信道下部分物理层安全性能，推导了保密中断概率、平均分数混淆和信息泄露率等关键指标的精确闭式解，验证了MRC分集对安全性能的提升效果。


<details>
  <summary>Details</summary>
Motivation: 未来移动网络中资源受限设备的信息安全面临挑战，物理层安全利用无线信道随机性提供可行方案。当无法实现完全保密时，部分保密机制成为现实选择，需要研究其在复杂衰落信道下的性能。

Method: 采用广义多簇波动双射线(MFTR)衰落模型，分析包含发射机、合法接收机和窃听者的系统。合法接收机和窃听者均使用最大比合并天线阵列，在非独立同分布衰落条件下，推导保密指标的精确和闭式近似解。

Result: 通过蒙特卡洛仿真验证了推导结果的正确性，所提方法具有与分集阶数无关的恒定复杂度。MFTR模型的灵活性支持全面评估不同衰落条件，结果显示B端更多MRC分支能根据A-E链路特性增强安全性能。

Conclusion: 该研究为部分保密机制在复杂衰落信道下的性能分析提供了有效的数学工具，MFTR模型的通用性使其能够涵盖多种经典衰落情况，为未来移动网络安全设计提供了重要参考。

Abstract: Securing information in future mobile networks is challenging, especially for
devices with limited computational resources. Physical layer security (PLS)
offers a viable solution by leveraging wireless channel randomness. When full
secrecy is unattainable, the partial secrecy regime provides a realistic
alternative. This work analyzes partial secrecy performance under the
generalized multicluster fluctuating two-ray (MFTR) fading model, which
subsumes many classical fading cases. We study a system with a transmitter (A),
legitimate receiver (B), and eavesdropper (E), both B and E using antenna
arrays with maximal ratio combining (MRC), under i.n.i.d. fading. Exact and
closed-form approximations are derived for key secrecy metrics: generalized
secrecy outage probability (GSOP), average fractional equivocation (AFE), and
average information leakage rate (AILR). The results, validated by Monte Carlo
simulations, retain constant complexity regardless of diversity order. The MFTR
model's flexibility enables comprehensive assessment across fading conditions,
showing that more MRC branches at B enhance secrecy performance depending on
the A-E link characteristics.

</details>


### [3] [Self-Supervised and Topological Signal-Quality Assessment for Any PPG Device](https://arxiv.org/abs/2509.12510)
*Wei Shao,Ruoyu Zhang,Zequan Liang,Ehsan Kourkchi,Setareh Rafatirad,Houman Homayoun*

Main category: eess.SP

TL;DR: 首个全无监督的手腕PPG信号质量评估管线，结合自我监督学习咄拓扑学分析，可交叉设备使用


<details>
  <summary>Details</summary>
Motivation: PPG信号容易受到运动、血液流动咄环境光影响，而现有质量评估方法依赖弱烈的经验法则或需要大量标签数据的监督模型

Method: 两阶段方法：第一阶段使用对比学习训练1-D ResNet-18，在276小时未标签数据上训练获得光学发射器咄运动不变的嵌入表示；第二阶段通过持久同调将嵌入转换为拓扑签名，然后使用HDBSCAN进行聚类生成二进制信号质量指数

Result: 方法在10,000个样本窗口上获得了Silhouette 0.72、Davies-Bouldin 0.34、Calinski-Harabasz 6173的评分，表现优异

Conclusion: 该混合自我监督学习-拓扑学分析框架为PPG信号提供了一个可扩展、可交叉设备使用的质量门槽解决方案

Abstract: Wearable photoplethysmography (PPG) is embedded in billions of devices, yet
its optical waveform is easily corrupted by motion, perfusion loss, and ambient
light, jeopardizing downstream cardiometric analytics. Existing signal-quality
assessment (SQA) methods rely either on brittle heuristics or on data-hungry
supervised models. We introduce the first fully unsupervised SQA pipeline for
wrist PPG. Stage 1 trains a contrastive 1-D ResNet-18 on 276 h of raw,
unlabeled data from heterogeneous sources (varying in device and sampling
frequency), yielding optical-emitter- and motion-invariant embeddings (i.e.,
the learned representation is stable across differences in LED wavelength,
drive intensity, and device optics, as well as wrist motion). Stage 2 converts
each 512-D encoder embedding into a 4-D topological signature via persistent
homology (PH) and clusters these signatures with HDBSCAN. To produce a binary
signal-quality index (SQI), the acceptable PPG signals are represented by the
densest cluster while the remaining clusters are assumed to mainly contain
poor-quality PPG signals. Without re-tuning, the SQI attains Silhouette,
Davies-Bouldin, and Calinski-Harabasz scores of 0.72, 0.34, and 6173,
respectively, on a stratified sample of 10,000 windows. In this study, we
propose a hybrid self-supervised-learning--topological-data-analysis (SSL--TDA)
framework that offers a drop-in, scalable, cross-device quality gate for PPG
signals.

</details>


### [4] [Rapid Adaptation of SpO2 Estimation to Wearable Devices via Transfer Learning on Low-Sampling-Rate PPG](https://arxiv.org/abs/2509.12515)
*Zequan Liang,Ruoyu Zhang,Wei Shao,krishna Karthik,Ehsan Kourkchi,Setareh Rafatirad,Houman Homayoun*

Main category: eess.SP

TL;DR: 通过载体学习框架实现低功耗可穿戴设备的血氧饱度监测，使用25Hz PPG采样频率并减少40%功耗，达到了优秀的水氧预测精度


<details>
  <summary>Details</summary>
Motivation: 传统血氧饱度估算方法需要复杂的临床校准，不适合低功耗可穿戴应用，需要一种无需临床校准的准确监测方法

Method: 采用载体学习框架，首先在公共临床数据集上预训练带自注意力机制的双向LSTM模型，然后使用可穿戴设备收集的低采样率(25Hz)双通道PPG数据进行微调

Result: 在公共数据集上达到MAE 2.967%，私有数据集上MAE 2.624%，显著超过传统校准和非载体学习基线。使用25Hz PPG可以比100Hz节省40%功耗，并在瞬时预测中达到MAE 3.284%

Conclusion: 该方法可以在无需临床校准的情况下，实现可穿戴设备上准确、低功耗的血氧饱度监测，有效捕捉快速波动，适用于健康监测应用

Abstract: Blood oxygen saturation (SpO2) is a vital marker for healthcare monitoring.
Traditional SpO2 estimation methods often rely on complex clinical calibration,
making them unsuitable for low-power, wearable applications. In this paper, we
propose a transfer learning-based framework for the rapid adaptation of SpO2
estimation to energy-efficient wearable devices using low-sampling-rate (25Hz)
dual-channel photoplethysmography (PPG). We first pretrain a bidirectional Long
Short-Term Memory (BiLSTM) model with self-attention on a public clinical
dataset, then fine-tune it using data collected from our wearable We-Be band
and an FDA-approved reference pulse oximeter. Experimental results show that
our approach achieves a mean absolute error (MAE) of 2.967% on the public
dataset and 2.624% on the private dataset, significantly outperforming
traditional calibration and non-transferred machine learning baselines.
Moreover, using 25Hz PPG reduces power consumption by 40% compared to 100Hz,
excluding baseline draw. Our method also attains an MAE of 3.284% in
instantaneous SpO2 prediction, effectively capturing rapid fluctuations. These
results demonstrate the rapid adaptation of accurate, low-power SpO2 monitoring
on wearable devices without the need for clinical calibration.

</details>


### [5] [Generalizable Blood Pressure Estimation from Multi-Wavelength PPG Using Curriculum-Adversarial Learning](https://arxiv.org/abs/2509.12518)
*Zequan Liang,Ruoyu Zhang,Wei Shao,Mahdi Pirayesh Shirazi Nejad,Ehsan Kourkchi,Setareh Rafatirad,Houman Homayoun*

Main category: eess.SP

TL;DR: 通过课程-对抗学习策略结合多波长PPG数据，开发了一种准确且可推广的血压估计框架，在主体级分割下实现优异性能


<details>
  <summary>Details</summary>
Motivation: 准确且可推广的血压估计对心血管疾病的早期发现和管理至关重要，需要解决现有方法在主体级分割下的普遍性问题

Method: 采用课程-对抗学习框架，结合从高血压分类过渡到血压回归的课程学习，以及通过混淆主体识别来促进主体不变特征学习的领域对抗训练

Result: 在四波长PPG数据集上，方法在严格主体级分割下达到MAE系统血压14.2mmHg、心舟血压6.4mmHg的强劲性能，多通道融合模型一贵优于单通道模型

Conclusion: 多波长PPG的互补信息与课程-对抗策略结合，为准确和稳健的血压估计提供了有效途径，具有重要的临床应用潜力

Abstract: Accurate and generalizable blood pressure (BP) estimation is vital for the
early detection and management of cardiovascular diseases. In this study, we
enforce subject-level data splitting on a public multi-wavelength
photoplethysmography (PPG) dataset and propose a generalizable BP estimation
framework based on curriculum-adversarial learning. Our approach combines
curriculum learning, which transitions from hypertension classification to BP
regression, with domain-adversarial training that confuses subject identity to
encourage the learning of subject-invariant features. Experiments show that
multi-channel fusion consistently outperforms single-channel models. On the
four-wavelength PPG dataset, our method achieves strong performance under
strict subject-level splitting, with mean absolute errors (MAE) of 14.2mmHg for
systolic blood pressure (SBP) and 6.4mmHg for diastolic blood pressure (DBP).
Additionally, ablation studies validate the effectiveness of both the
curriculum and adversarial components. These results highlight the potential of
leveraging complementary information in multi-wavelength PPG and
curriculum-adversarial strategies for accurate and robust BP estimation.

</details>


### [6] [Kalman Filtering of Stationary Graph Signals](https://arxiv.org/abs/2509.12605)
*Yang Chen,Yeonju Lee,Yao Shi,Qiyu Sun*

Main category: eess.SP

TL;DR: 本文提出了基于对称图位移的平稳图信号新定义，证明了其可通过多项式图通道生成白噪声，并研究了多项式状态观测矩阵系统的卡尔曼滤波，展示了其在保持信号平稳性方面的优势。


<details>
  <summary>Details</summary>
Motivation: 传统信号处理中的平稳性概念在图上缺乏明确定义，需要建立图信号平稳性的理论框架，并开发能够有效处理图信号动态系统和噪声结构的滤波方法。

Method: 提出基于对称图位移的平稳图信号定义，使用多项式图通道生成信号，并应用卡尔曼滤波处理多项式状态观测矩阵的动态系统。

Result: 证明了平稳图信号可通过多项式通道生成且保持平稳性，卡尔曼滤波能有效保持信号平稳性，相比静态逆滤波和零信号策略，提供更准确和自适应的信号估计。

Conclusion: 所提出的平稳图信号定义和卡尔曼滤波方法为图信号处理提供了理论基础和实用工具，展现了在处理动态图系统时的鲁棒性和适应性优势。

Abstract: In this paper, we propose a novel definition of stationary graph signals,
formulated with respect to a symmetric graph shift, such as the graph
Laplacian. We show that stationary graph signals can be generated by
transmitting white noise through polynomial graph channels, and that their
stationarity is preserved under polynomial channel transmission.
  In this paper, we also investigate Kalman filtering to dynamical systems
characterized by polynomial state and observation matrices. We demonstrate that
Kalman filtering maintains the stationarity of graph signals, while effectively
incorporating both system dynamics and noise structure. In comparison to the
static inverse filtering method and naive zero-signal strategy, the Kalman
filtering procedure yields more accurate and adaptive signal estimates,
highlighting its robustness and versatility in graph signal processing.

</details>


### [7] [Data Fusion for BS-UE Cooperative MIMO-OFDM ISAC](https://arxiv.org/abs/2509.12646)
*Yixin Ding,Haoyu Jiang,Xiaoli Xu,Yanan Liang,Yong Zeng*

Main category: eess.SP

TL;DR: 提出了一种新的基站与用户设备协同感知模式，通过融合BS和UE的感知结果来提升无线网络的感知能力


<details>
  <summary>Details</summary>
Motivation: 为了进一步增强无线网络的感知能力，超越3GPP定义的六种基本感知操作模式

Method: 提出BS-UE协同感知模式，UE解码通信数据后处理接收信号提取目标感知信息，并开发了利用BS、UE与目标几何关系的高效数据融合算法

Result: 协同感知数据融合方法有效提高了多目标位置和速度估计精度

Conclusion: 为感知模式的扩展提供了新途径，显著提升了无线网络集成感知与通信的性能

Abstract: Integrated sensing and communication (ISAC) is a promising technique for
expanding the functionalities of wireless networks with enhanced spectral
efficiency. The 3rd Generation Partnership Project (3GPP) has defined six basic
sensing operation modes in wireless networks. To further enhance the sensing
capability of wireless networks, this paper proposes a new sensing operation
mode, i.e., the base station (BS) and user equipment (UE) cooperative sensing.
Specifically, after decoding the communication data, the UE further processes
the received signal to extract the target sensing information. We propose an
efficient algorithm for fusing the sensing results obtained by the BS and UE,
by exploiting the geometric relationship among BS, UE and targets as well as
the expected sensing quality in the BS monostatic and BS-UE bistatic sensing.
The results show that the proposed data fusion method for cooperative sensing
can effectively improve the position and velocity estimation accuracy of
multiple targets, and provide a new approach on the expansion of the sensing
pattern.

</details>


### [8] [Sustainable LSTM-Based Precoding for RIS-Aided mmWave MIMO Systems with Implicit CSI](https://arxiv.org/abs/2509.12658)
*Po-Heng Chou,Jiun-Jia Wu,Wan-Jen Huang,Ronald Y. Chang*

Main category: eess.SP

TL;DR: 基于LSTM的RIS辅助mmWave MIMO系统预编码框架，通过上行导频完成隐式通道学习，减少导频开销和计算复杂度，实现高效能耗比的继续性无线通信方案。


<details>
  <summary>Details</summary>
Motivation: 解决RIS辅助mmWave MIMO系统中显式通道估计导致的高导频开销和计算复杂度问题，提供一种更简单高效的预编码方案。

Method: 使用LSTM网络构建预编码框架，利用上行导频序列进行隐式通道特征学习，考虑RIS元件的相位依赖振幅模型，采用多标签训练策略提高稳健性。

Result: 模拟显示该方法达到了突然搜索90%以上的谱效率，但只需要2.2%的计算时间，能耗降低近两个数量级。方法在分布不匹配情况下仍保持稳健性，并能扩展到更大规模RIS数组。

Conclusion: 该方法为继续性6G无线网络提供了一种实用、能效高的预编码解决方案，在保持高性能的同时大幅降低计算复杂度和能耗。

Abstract: In this paper, we propose a sustainable long short-term memory (LSTM)-based
precoding framework for reconfigurable intelligent surface (RIS)-assisted
millimeter-wave (mmWave) MIMO systems. Instead of explicit channel state
information (CSI) estimation, the framework exploits uplink pilot sequences to
implicitly learn channel characteristics, reducing both pilot overhead and
inference complexity. Practical hardware constraints are addressed by
incorporating the phase-dependent amplitude model of RIS elements, while a
multi-label training strategy improves robustness when multiple near-optimal
codewords yield comparable performance. Simulations show that the proposed
design achieves over 90% of the spectral efficiency of exhaustive search (ES)
with only 2.2% of its computation time, cutting energy consumption by nearly
two orders of magnitude. The method also demonstrates resilience under
distribution mismatch and scalability to larger RIS arrays, making it a
practical and energy-efficient solution for sustainable 6G wireless networks.

</details>


### [9] [Low-Altitude UAV Tracking via Sensing-Assisted Predictive Beamforming](https://arxiv.org/abs/2509.12698)
*Yifan Jiang,Qingqing Wu,Hongxun Hui,Wen Chen,Derrick Wing Kwan Ng*

Main category: eess.SP

TL;DR: 本文研究了感知辅助预测波束成形技术在无人机跟踪中的中断容量最大化问题，提出了基于扩展卡尔曼滤波的跟踪方案和两种高效算法，显著提升了通信可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注频谱效率提升，但感知辅助波束成形技术对通信可靠性的影响尚未充分探索和表征，需要填补这一研究空白。

Method: 提出基于扩展卡尔曼滤波的蜂窝连接无人机跟踪方案，联合优化预测轨迹、感知时长比和目标恒定接收信噪比；开发了基于二分搜索和连续凸逼近的高效算法，以及基于交替优化的低复杂度算法。

Result: 仿真验证了中断概率近似的准确性，证明了所提算法的有效性，相比各种基准方法显著提升了中断容量，同时揭示了路径损耗减小与宽波束覆盖之间的权衡关系。

Conclusion: 该研究为感知辅助预测波束成形技术提供了完整的中断容量表征框架，提出的高效算法能够有效解决非凸优化问题，为未来无人机应用的通信可靠性保障提供了重要技术支撑。

Abstract: Sensing-assisted predictive beamforming, as one of the enabling technologies
for emerging integrated sensing and communication (ISAC) paradigm, shows
significant promise for enhancing various future unmanned aerial vehicle (UAV)
applications. However, current works predominately emphasized on spectral
efficiency enhancement, while the impact of such beamforming techniques on the
communication reliability was largely unexplored and challenging to
characterize. To fill this research gap and tackle this issue, this paper
investigates outage capacity maximization for UAV tracking under the
sensing-assisted predictive beamforming scheme. Specifically, a
cellular-connected UAV tracking scheme is proposed leveraging extended Kalman
filtering (EKF), where the predicted UAV trajectory, sensing duration ratio,
and target constant received signal-to-noise ratio (SNR) are jointly optimized
to maximize the outage capacity at each time slot. To address the implicit
nature of the objective function, closed-form approximations of the outage
probabilities (OPs) at both prediction and measurement stages of each time slot
are proposed based on second-order Taylor expansions, providing an efficient
and full characterization of outage capacity. Subsequently, an efficient
algorithm is proposed based on a combination of bisection search and successive
convex approximation (SCA) to address the non-convex optimization problem with
guaranteed convergence. To further reduce computational complexity, a second
efficient algorithm is developed based on alternating optimization (AO).
Simulation results validate the accuracy of the derived OP approximations, the
effectiveness of the proposed algorithms, and the significant outage capacity
enhancement over various benchmarks, while also indicating a trade-off between
decreasing path loss and enjoying wide beam coverage for outage capacity
maximization.

</details>


### [10] [NEFT: A Unified Transformer Framework for Efficient Near-Field CSI Feedback in XL-MIMO Systems](https://arxiv.org/abs/2509.12748)
*Haiyang Li,Tianqi Mao,Pengyu Wang,Ruiqi Liu,Shunyu Li,Zhaocheng Wang*

Main category: eess.SP

TL;DR: 提出了NEFT系列Transformer模型，用于超大规模MIMO系统的近场CSI反馈，通过轻量化变体在不同硬件平台上实现高效准确的反馈。


<details>
  <summary>Details</summary>
Motivation: 超大规模MIMO系统在近场区域面临CSI反馈的挑战，现有深度学习方法难以捕捉近场CSI的复杂结构且计算开销过大。

Method: 基于分层Vision Transformer架构，开发了NEFT-Compact（多级知识蒸馏）、NEFT-Hybrid（无注意力编码）和NEFT-Edge（知识蒸馏）等轻量化变体。

Result: NEFT相比现有方法在NMSE上提升15-21dB，轻量化变体减少25-36%计算量且精度损失可忽略，NEFT-Hybrid降低编码端复杂度达64%。

Conclusion: NEFT为XL-MIMO系统的近场CSI反馈提供了实用且可扩展的解决方案。

Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) systems,
operating in the near-field region due to their massive antenna arrays, are a
key enabler of next-generation wireless communications but face significant
challenges in channel state information (CSI) feedback. Deep learning has
emerged as a powerful tool by learning compact CSI representations for
feedback. However, existing methods struggle to capture the intricate structure
of near-field CSI while incurring prohibitive computational overhead on
practical mobile devices. To overcome these limitations, we propose the
Near-Field Efficient Feedback Transformer (NEFT) family for accurate and
efficient near-field CSI feedback across diverse hardware platforms. Built on a
hierarchical Vision Transformer backbone, NEFT is extended with lightweight
variants to meet various deployment constraints: NEFT-Compact applies
multi-level knowledge distillation (KD) to reduce complexity while maintaining
accuracy, and NEFT-Hybrid and NEFT-Edge address encoder- and edge-constrained
scenarios via attention-free encoding and KD. Extensive simulations show that
NEFT achieves a 15--21 dB improvement in normalized mean-squared error (NMSE)
over state-of-the-art methods, while NEFT-Compact and NEFT-Edge reduce total
FLOPs by 25--36% with negligible accuracy loss. Moreover, NEFT-Hybrid lowers
encoder-side complexity by up to 64%, enabling deployment in highly asymmetric
device scenarios. These results establish NEFT as a practical and scalable
solution for near-field CSI feedback in XL-MIMO systems.

</details>


### [11] [EMC Limit Level Guidelines for In-System Interference with GPS Receivers](https://arxiv.org/abs/2509.12770)
*Giorgi Tsintsadze,Haran Manoharan,Aaron Harmon,Daniel Commerou,Connor Buneta,Brian Booth,Daryl Beetner*

Main category: eess.SP

TL;DR: 本文提出了一种基于载波-噪声比降级理论模型的指南，用于评估电子设备无意放射对附近GPS接收机的干扰影响，提供比传统发射标准更精细的评估方法。


<details>
  <summary>Details</summary>
Motivation: GPS信号弱小，附近的电子系统和组件容易通过无意放射造成干扰。需要为汽车等应用中需要集成在GPS接收机附近的电子设备制定EMC限值指南。

Method: 建立了预测载波-噪声比(C/N0)在干扰下降级的理论模型，并用实际噪声源进行了验证。基于模型发展了根据噪声频率、带宽和大小来评估对GPS接收机影响的指南。

Result: 提出的模型能够准确预测GPS接收机在干扰下的性能降级，并可用于制定更精细的发射限值指南。

Conclusion: 该方法提供了比传统简单限值线更细致的方法来评估电子设备对GPS接收机的干扰影响，适用于汽车等需要高密集度集成的应用场景。

Abstract: Because GPS signals are weak, electronic systems and components that are
placed near GPS receivers can easily cause disruptive electromagnetic
interference through their unintended radiated emissions. In this paper, EMC
limit level guidelines are presented for electronics that are intended to be
placed near to GPS receivers, as often happens in automotive and other
applications. One of the challenges of defining limit-levels for systems
intended to be integrated with GPS receivers is that the impact of noise at the
input of the receiver may vary substantially depending on the form of the noise
due to the correlator function implemented by GPS receiver. The quality of the
correlated signal is typically represented using the carrier-to-noise ratio ($C
/ N_0$). A theoretical model predicting the degredation of the carrier-to-noise
ratio with radio frequency interference is presented in this paper and is
validated with realistic noise sources. The model is then used to develop
guidelines to assess the impact of unintended emissions from electronic devices
on nearby GPS receivers based on the frequency, bandwidth, and magnitude of the
noise. These guidelines provide a more nuanced method of evaluating emissions
than simple limit lines that are used by many emissions standards.

</details>


### [12] [A Statistical Benchmark for Diffusion Posterior Sampling Algorithms](https://arxiv.org/abs/2509.12821)
*Martin Zach,Youssef Haouchat,Michael Unser*

Main category: eess.SP

TL;DR: 提出了一个用于评估扩散后验采样算法的统计基准框架，基于稀疏Lévy过程先验生成信号，使用吉布斯采样获得金标准后验样本进行比较


<details>
  <summary>Details</summary>
Motivation: 为扩散后验采样算法提供一个可靠的统计评估基准，能够量化算法在贝叶斯线性逆问题中的性能表现

Method: 使用稀疏Lévy过程先验生成信号，通过高效的吉布斯方法获得金标准后验样本，与DPS算法结果进行比较，并分离似然得分近似误差

Result: 建立了包含最小均方误差最优性差距和后验覆盖测试的基准框架，在去噪、反卷积、插补和部分傅里叶测量重建等逆问题上进行了数值实验

Conclusion: 该基准框架为评估扩散后验采样算法提供了标准化工具，代码开源并支持简单插件接口，邀请研究者贡献和报告结果

Abstract: We propose a statistical benchmark for diffusion posterior sampling (DPS)
algorithms for Bayesian linear inverse problems. The benchmark synthesizes
signals from sparse L\'evy-process priors whose posteriors admit efficient
Gibbs methods. These Gibbs methods can be used to obtain gold-standard
posterior samples that can be compared to the samples obtained by the DPS
algorithms. By using the Gibbs methods for the resolution of the denoising
problems in the reverse diffusion, the framework also isolates the error that
arises from the approximations to the likelihood score. We instantiate the
benchmark with the minimum-mean-squared-error optimality gap and posterior
coverage tests and provide numerical experiments for popular DPS algorithms on
the inverse problems of denoising, deconvolution, imputation, and
reconstruction from partial Fourier measurements. We release the benchmark code
at https://github.com/zacmar/dps-benchmark. The repository exposes simple
plug-in interfaces, reference scripts, and config-driven runs so that new
algorithms can be added and evaluated with minimal effort. We invite
researchers to contribute and report results.

</details>


### [13] [Bayesian Signal Separation via Plug-and-Play Diffusion-Within-Gibbs Sampling](https://arxiv.org/abs/2509.12857)
*Yi Zhang,Rui Guo,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 提出了一种结合吉布斯采样和PnP扩散先验的后验采样算法，用于从噪声叠加中估计多个独立源信号，无需重新训练即可灵活组合先验，并在完美扩散模型训练假设下可证明从后验分布采样。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的信号分离方法大多需要联合训练，无法灵活组合单独学习的源先验。需要一种能够将单独学习的先验灵活组合且具有理论保证的方法。

Method: 结合吉布斯采样方法和即插即用(PnP)扩散先验的后验采样算法。源先验可以单独学习，无需重新训练即可灵活组合。

Result: 在心跳信号与合成运动伪影混合的分离任务实验中，该方法表现出优于现有方法的性能。

Conclusion: 提出的算法能够有效解决多源信号分离问题，具有灵活的先验组合能力和理论保证，在心跳提取任务中验证了其优越性。

Abstract: We propose a posterior sampling algorithm for the problem of estimating
multiple independent source signals from their noisy superposition. The
proposed algorithm is a combination of Gibbs sampling method and plug-and-play
(PnP) diffusion priors. Unlike most existing diffusion-model-based approaches
for signal separation, our method allows source priors to be learned separately
and flexibly combined without retraining. Moreover, under the assumption of
perfect diffusion model training, the proposed method provably produces samples
from the posterior distribution. Experiments on the task of heartbeat
extraction from mixtures with synthetic motion artifacts demonstrate the
superior performance of our method over existing approaches.

</details>


### [14] [Towards personalized, precise and survey-free environment recognition: AI-enhanced sensor fusion without pre-deployment](https://arxiv.org/abs/2509.12870)
*Ruichen Wang,Zhikang Ni,Pengzhou Wang,Xiya Cao,Zhi Li,Bao Zhang*

Main category: eess.SP

TL;DR: 一种无需现场调查的个性化室内定位框架，通过多源伤纹数据库和AI增强的动态时间扩张算法，结合云端强化学习循环，实现了网络切换延迟大幅降低


<details>
  <summary>Details</summary>
Motivation: 解决传统指纹定位需要费用昂贵的现场调查且缺乏用户层面适配能力的问题，实现准确且个性化的环境识别以支持无缝室内定位和优化连接性

Method: 构建个人化轻量多源指纹数据库（PDR、WiFi/细胞网、GNSS、交互时间标签），使用AI增强的动态时间扩张模块（AIDTW）进行序列匹配，通过云端强化学习从人类反馈循环（RLHF）优化策略并周期性向设备传递更新

Result: 在室内外场景中，系统将网络过渡延迟（通过切换时间TTS测量）降低了32-65%，无需现场特定的预部署

Conclusion: 该框架成功实现了不依赖于现场调查的高效个性化室内定位方案，通过多源伤纹数据和云端强化学习的结合，显著提升了网络连接性能

Abstract: Accurate and personalized environment recognition is essential for seamless
indoor positioning and optimized connectivity, yet traditional fingerprinting
requires costly site surveys and lacks user-level adaptation. We present a
survey-free, on-device sensor-fusion framework that builds a personalized,
lightweight multi-source fingerprint (FP) database from pedestrian dead
reckoning (PDR), WiFi/cellular, GNSS, and interaction time tags. Matching is
performed by an AI-enhanced dynamic time warping module (AIDTW) that aligns
noisy, asynchronous sequences. To turn perception into continually improving
actions, a cloud-edge online Reinforcement Learning from Human Feedback (RLHF)
loop aggregates desensitized summaries and human feedback in the cloud to
optimize a policy via proximal policy optimization (PPO), and periodically
distills updates to devices. Across indoor/outdoor scenarios, our system
reduces network-transition latency (measured by time-to-switch, TTS) by 32-65%
in daily environments compared with conventional baselines, without
site-specific pre-deployment.

</details>


### [15] [Next-Generation Backscatter Networks for Integrated Communications and RF Sensing](https://arxiv.org/abs/2509.12954)
*Traian E. Abrudan,Kartik Patel,John Kimionis,Tara Esmaeilbeig,Eleftherios Kampianakis,Sahan Damith Liyanaarachchi,Michael Eggleston*

Main category: eess.SP

TL;DR: 该论文为下一代反向散射网络提供了全面的分析和理论基础，将RF定位感知能力与通信功能集成，建立了端到端的系统模型并进行了实验验证。


<details>
  <summary>Details</summary>
Motivation: 为大规模部署的机器类型通信网络建立分布式、非同步反向散射系统的理论基础，实现能量高效的同时集成通信和RF定位感知能力。

Method: 推导了宽带OFDM反向散射系统的端到端系统模型，包括传播信道、接收机链损伤、RF标签操作和非同步网络节点的详细表征，并通过实际硬件进行实验验证。

Result: 理论模型通过实验验证显示准确性，提出了可在非同步节点下工作的实用双基地测距方法，推导了Cramér-Rao下界以展示可实现的性能极限。

Conclusion: 该分析框架和实验验证为未来大规模部署、能量高效的机器类型通信网络中的分布式非同步反向散射系统建立了基本理解。

Abstract: This paper provides a comprehensive analysis and theoretical foundation for
next-generation backscatter networks that move beyond communication and
integrate RF location sensing capabilities. An end-to-end system model for
wideband OFDM backscatter systems is derived, including detailed
characterization of propagation channels, receiver chain impairments, RF tag
operation, and unsynchronized network nodes. The theoretical system model is
validated through experimental evaluation using actual hardware, demonstrating
the detailed model's accuracy. A practical bistatic ranging method that can
operate with unsynchronized nodes is presented, along with the Cram\'er-Rao
Lower Bound (CRLB) derived to show the achievable performance limits. Our
experimental results demonstrate the system performance for communication, RF
sensing, and ranging, while also benchmarking against the derived theoretical
limits. This analytical framework and experimental validation establish
fundamental understanding of distributed, unsynchronized backscatter systems
for future machine-type communication networks that are deployed in massive
scale, while remaining energy-efficient.

</details>


### [16] [Difference-Based Recovery for Modulo Sampling: Tightened Bounds and Robustness Guarantees](https://arxiv.org/abs/2509.12971)
*Wenyi Yan,Zeyuan Li,Lu Gan,Honqing Liu,Guoquan Li*

Main category: eess.SP

TL;DR: 本文提出了改进的基于差分的模数转换恢复方法，显著降低了过采样要求并提高了对采样抖动的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统ADC在信号超过输入范围时会削波，而现有的模数采样恢复方法要么计算复杂，要么需要高采样率，且都无法处理实际中不可避免的采样抖动问题。

Method: 采用基于差分的高阶恢复方法，推导了无噪声和有噪声情况下的采样条件，特别针对二阶差分恢复分析了非均匀采样下的抖动鲁棒性。

Result: 理论证明高阶差分可将过采样因子从2πe降低到π，硬件原型实现了高达108倍的幅度扩展和可靠重建。

Conclusion: 该方法提供了一种简单、鲁棒的高性能无限传感恢复方案，解决了传统模数采样的计算复杂度和采样抖动问题。

Abstract: Conventional analog-to-digital converters (ADCs) clip when signals exceed
their input range. Modulo (unlimited) sampling overcomes this limitation by
folding the signal before digitization, but existing recovery methods are
either computationally intensive or constrained by loose oversampling bounds
that demand high sampling rates. In addition, none account for sampling jitter,
which is unavoidable in practice. This paper revisits difference-based recovery
and establishes new theoretical and practical guarantees. In the noiseless
setting, we prove that arbitrarily high difference order reduces the sufficient
oversampling factor from $2\pi e$ to $\pi$, substantially tightening classical
bounds. For fixed order $N$, we derive a noise-aware sampling condition that
guarantees stable recovery. For second-order difference-based recovery ($N=2$),
we further extend the analysis to non-uniform sampling, proving robustness
under bounded jitter. An FPGA-based hardware prototype demonstrates reliable
reconstruction with amplitude expansion up to $\rho = 108$, confirming the
feasibility of high-performance unlimited sensing with a simple and robust
recovery pipeline.

</details>


### [17] [RF-Powered Batteryless Plant Movement Sensor for Precision Agriculture](https://arxiv.org/abs/2509.13004)
*Jona Cappelle,Jarne Van Mulders,Sarah Goossens,Thomas Reher,Liesbet Van der Perre,Lieven De Strycker,Bram Van de Poel,Gilles Callebaut*

Main category: eess.SP

TL;DR: 这篇论文提出了一种无电池、仅靠无线电能量供电的轻量化植物运动传感器，专门用于控制环境农业中植物生理状态监测


<details>
  <summary>Details</summary>
Motivation: 精准农业需要非侵入性、能源效率高且可持续的植物监测方案，避免电池带来的生态踩边、重量和维护问题

Method: 设计了一种依靠RF能量传输的无电池传感器，采用惯性测量单元(IMU)监测叶片运动，该运动与植物对环境压力的生理响应相关

Result: 实现了从基于使用寿命的能量存储向基于操作的能量存储转变，降低了电路复杂度，支持根据能量可用性和传感器数据进行灵活的适应性读出调度

Conclusion: 该无电池RF能量供电传感器为控制环境农业提供了一种可持续的植物监测方案，未来将探索多天线能量供应和网络化传感器同步

Abstract: Precision agriculture demands non-invasive, energy-efficient, and sustainable
plant monitoring solutions. In this work, we present the design and
implementation of a lightweight, batteryless plant movement sensor powered
solely by RF energy. This sensor targets Controlled Environment Agriculture
(CEA) and utilizes inertial measurements units (IMUs) to monitor leaf motion,
which correlates with plant physiological responses to environmental stress. By
eliminating the battery, we reduce the ecological footprint, weight, and
maintenance requirements, transitioning from lifetime-based to operation-based
energy storage. Our design minimizes circuit complexity while enabling
flexible, adaptive readout scheduling based on energy availability and sensor
data. We detail the energy requirements, RF power transfer considerations,
integration constraints, and outline future directions, including multi-antenna
power delivery and networked sensor synchronization.

</details>


### [18] [Deep Tensor Learning for Reliable Channel Charting from Incomplete and Noisy Measurements](https://arxiv.org/abs/2509.13030)
*Ge Chen,Panqi Chen,Lei Cheng*

Main category: eess.SP

TL;DR: 提出一种基于深度张量学习的方法，用于从噪声和不完整的无线信道数据中提取低维特征（信道图表），解决现有方法在真实基站数据中性能下降的问题。


<details>
  <summary>Details</summary>
Motivation: 现有信道图表方法主要基于仿真或室内测量数据，假设信道数据干净完整，但真实基站收集的信道数据由于频率跳变而不完整，且在小区边缘噪声严重，导致现有方法性能大幅下降。

Method: 采用深度张量学习方法，利用无线信道固有的张量结构，从噪声和不完整的测量数据中有效提取信息丰富且低维的特征（信道图表）。

Result: 实验结果表明，该方法在具有挑战性的场景下表现出可靠性和有效性。

Conclusion: 所提出的深度张量学习方法能够有效处理真实世界中的噪声和不完整信道数据，为信道图表技术在实际应用中的可靠性提供了解决方案。

Abstract: Channel charting has emerged as a powerful tool for user equipment
localization and wireless environment sensing. Its efficacy lies in mapping
high-dimensional channel data into low-dimensional features that preserve the
relative similarities of the original data. However, existing channel charting
methods are largely developed using simulated or indoor measurements, often
assuming clean and complete channel data across all frequency bands. In
contrast, real-world channels collected from base stations are typically
incomplete due to frequency hopping and are significantly noisy, particularly
at cell edges. These challenging conditions greatly degrade the performance of
current methods. To address this, we propose a deep tensor learning method that
leverages the inherent tensor structure of wireless channels to effectively
extract informative while low-dimensional features (i.e., channel charts) from
noisy and incomplete measurements. Experimental results demonstrate the
reliability and effectiveness of the proposed approach in these challenging
scenarios.

</details>


### [19] [Scatterer Localization Using Multi-Bounce Paths](https://arxiv.org/abs/2509.13071)
*Yuan Liu,Linlong Wu,Xuesong Cai,M. R. Bhavani Shankar*

Main category: eess.SP

TL;DR: 本文提出了一种基于图论的GM-SAGE算法，用于处理室内多跳弹近场无线传播渡渡相关的环境感知挑战


<details>
  <summary>Details</summary>
Motivation: 室内感知面临多跳弹效应、球面波前沿和近场效应导致的空间非稳态性挑战，需要有效的方法来模型和处理这些复杂的传播特性

Method: 使用图论模型化近场多跳弹传播，将反射器/散射体模型化为图中顶点，多跳弹路径通过边链接。将空间交替广义期望最大化(SAGE)算法适配为GM-SAGE算法，将距离和离开/到达角的搜索参数转换为图中散射体坐标

Result: 通过测量检验的光线追踪模拟在复杂室内办公室环境中验证，结果表明GM-SAGE算法能够有效处理多跳弹信道

Conclusion: 提出的GM-SAGE算法通过图论模型和参数转换，有效解决了室内近场多跳弹传播的环境感知问题，为复杂室内无线传播环境提供了有效的解决方案

Abstract: Indoor sensing is challenging because of the multi-bounce effect, spherical
wavefront, and spatial nonstationarity (SNS) of the near-field effect. This
paper addresses radio-based environment sensing considering these issues.
Specifically, graph theory (GT) is used to model the multi-bounce propagation
of the near field. In this manner, indoor reflectors/scatterers are modeled as
vertices in a propagation graph, the multi-bounce paths are modeled by the
edges linking the vertices. Besides, the coupled multipath parameters in the
near field, i.e., range and angles, are denoted directly by the coordinates of
vertices. Then, the space-alternating generalized expectation-maximization
(SAGE) algorithm is adapted to the proposed Graph theory-based dictionary-aided
Multi-bounce SAGE (GM-SAGE), where the searching parameters including range and
angle of departure/arrival (AoD/AoA) are transformed to the coordinates of
scatterers in the graph. The proposed algorithm is validated through
measurement-calibrated ray tracing (RT) in a complex indoor office. The results
demonstrate that the proposed GM-SAGE can deal with multi-bounce channels.

</details>


### [20] [Transmitter Subspace-Aware Target Detection in Two-Channel Passive Radars with Inter-Receiver Collaboration](https://arxiv.org/abs/2509.13287)
*Nandan Sriranga,Haodong Yang,Pramod K. Varshney*

Main category: eess.SP

TL;DR: 提出了一种在分布式双通道无源雷达系统中通过协作信号处理和优化权重设计来增强单延迟多普勒单元目标检测性能的方法


<details>
  <summary>Details</summary>
Motivation: 解决在未知机会照射源环境下，分布式无源雷达系统需要高效利用带宽并提升目标检测性能的问题

Method: 将接收信号转换到已知低维子空间进行噪声白化处理，获得互相关测量；接收机协作交换并线性组合互相关输出，仅子集通过多址信道传输到融合中心；基于融合中心测量矩设计协作权重

Result: 通过优化协作权重设计，增强了目标检测性能

Conclusion: 该方法能够有效利用带宽资源，在分布式无源雷达系统中实现高性能的目标检测

Abstract: We address target detection in a single Delay-Doppler cell using spatially
distributed two-channel passive radars. An unknown illuminator of opportunity
(IO) is assumed to emit a waveform lying in a known low-dimensional subspace
(e.g., OFDM). Each receiver transforms its reference and surveillance signals
onto the IO subspace after noise-whitening, to obtain cross-correlation (CC)
measurements. To save bandwidth, receivers collaboratively exchange and
linearly combine the CC output, and only a subset transmits them to a fusion
center (FC) over a multiple-access channel (MAC). Collaboration weights are
designed using the moments of the FC measurement to enhance detection
performance.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [21] [Multi-Modal Embedding-based Target Speaker Enhancement](https://arxiv.org/abs/2509.12583)
*Zhan Jin*

Main category: eess.AS

TL;DR: 这篇论文研究多模态融合策略在目标讲话人提取中的健壮性，采用高模态丢失率训练可显著提升系统在实际应用中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 实际应用中多模态信息常遇到间歇性丢失，需要研究多模态融合策略在模态丢失情况下的健壮性。

Method: 基于现有音视频语音增强系统，集成四种讲话人识别线索：唇部嵌入、声音嵌入、静态面部嵌入和新题动态表情嵌入，在两种训练模式（无丢失和80%丢失率）下进行系统性评估。

Result: 在理想条件下全多模态集成表现最佳，但测试时丢失会导致性能显著下降；而采用80%丢失率训练的模型能够在严重模态缺失时保持优异性能，声音嵌入表现最为稳定，表情嵌入提供了补充信息。

Conclusion: 这项工作强调了考虑实际应用中不完整性的训练策略的重要性，通过高模态丢失率训练可以实现多模态语音增强系统的实际可靠性。

Abstract: Target Speaker Extraction (TSE) is a critical challenge in cocktail party
scenarios. While leveraging multiple modalities, such as voice, lip, face, and
expression embeddings, can enhance performance, real-world applications often
suffer from intermittent modality dropout. This paper presents a comprehensive
study on the interactions and robustness of various multimodal fusion
strategies under varying degrees of modality dropout. We build upon a
state-of-the-art audio-visual speech enhancement system and integrate four
distinct speaker identity cues: lip embeddings for synchronized contextual
information, a voice speaker embedding extracted via cross-attention for
acoustic consistency, a static face embedding for speaker identity, and a novel
dynamic expression embedding for frame-wise emotional features. We
systematically evaluate different combinations of these modalities under two
key training regimes: zero dropout and 80% modality dropout. Extensive
experiments demonstrate that while a full multimodal ensemble achieves optimal
performance under ideal (zero dropout) conditions, its effectiveness diminishes
significantly when test-time dropout occurs without prior exposure during
training. Crucially, we show that training with a high (80%) modality dropout
rate dramatically enhances model robustness, enabling the system to maintain
superior performance even under severe test-time missing modalities. Our
findings highlight that voice embeddings exhibit consistent robustness, while
the proposed expression embedding provides valuable complementary information.
This work underscores the importance of training strategies that account for
real-world imperfection, moving beyond pure performance maximization to achieve
practical reliability in multimodal speech enhancement systems.

</details>


### [22] [Investigating the Potential of Multi-Stage Score Fusion in Spoofing-Aware Speaker Verification](https://arxiv.org/abs/2509.12668)
*Oguzhan Kurnaz,Tomi Kinnunen,Cemal Hanilci*

Main category: eess.AS

TL;DR: 提出了一种多阶段的模块化欺骗感知说话人验证框架，通过集成ASV和CM子系统，相比传统单阶段分数融合方法，在SASV2022挑战赛上实现了1.30%的等错误率，相对基线系统提升了24%。


<details>
  <summary>Details</summary>
Motivation: 尽管自动说话人验证(ASV)技术有所改进，但对欺骗攻击的脆弱性仍然是一个主要问题。需要开发更强大的欺骗感知说话人验证系统来应对这一挑战。

Method: 采用多阶段方法集成ECAPA-TDNN(ASV)和AASIST(CM)子系统，使用支持向量机和逻辑回归分类器实现SASV。在第二阶段将输出与原始分数结合来改进融合后端分类器，并加入RawGAT(CM)的辅助分数来增强框架。

Result: 在SASV2022挑战赛评估数据集上获得了1.30%的等错误率(EER)，相比基线系统实现了24%的相对改进。

Conclusion: 多阶段模块化方法能有效提升欺骗感知说话人验证系统的性能，证明了该方法在对抗欺骗攻击方面的有效性。

Abstract: Despite improvements in automatic speaker verification (ASV), vulnerability
against spoofing attacks remains a major concern. In this study, we investigate
the integration of ASV and countermeasure (CM) subsystems into a modular
spoof-aware speaker verification (SASV) framework. Unlike conventional
single-stage score-level fusion methods, we explore the potential of a
multi-stage approach that utilizes the ASV and CM systems in multiple stages.
By leveraging ECAPA-TDNN (ASV) and AASIST (CM) subsystems, we consider support
vector machine and logistic regression classifiers to achieve SASV. In the
second stage, we integrate their outputs with the original score to revise
fusion back-end classifiers. Additionally, we incorporate another auxiliary
score from RawGAT (CM) to further enhance our SASV framework. Our approach
yields an equal error rate (EER) of 1.30% on the evaluation dataset of the
SASV2022 challenge, representing a 24% relative improvement over the baseline
system.

</details>


### [23] [MSR-Codec: A Low-Bitrate Multi-Stream Residual Codec for High-Fidelity Speech Generation with Information Disentanglement](https://arxiv.org/abs/2509.13068)
*Jingyu Li,Guangyan Zhang,Zhen Ye,Yiwen Guo*

Main category: eess.AS

TL;DR: 一种新的低码率多尺度殊异音频编码器，通过四个流（语义、音色、语调、殊异）实现高保真语音重建和信息解耦，并在TTS和语音转换中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现代语音生成系统需要高效的音频编码器，以实现低码率下的高保真语音处理和信息分离操作。

Method: 设计了一种多尺度殊异音频编码器，将语音编码为四个独立流：语义、音色、语调和殊异分量，并构建了两阶段语言模型用于TTS合成。

Result: 在低码率下实现了竞争性的高保真语音重建，TTS系统达到了最佳词误率（WER）和更好的讲话人相似性，同时在语音转换中实现了音色和语调的独立操控。

Conclusion: 该多流编码器设计不仅能够在低码率下实现高质量语音处理，还具有良好的信息解耦特性，为语音生成和转换应用提供了有效解决方案。

Abstract: Audio codecs are a critical component of modern speech generation systems.
This paper introduces a low-bitrate, multi-scale residual codec that encodes
speech into four distinct streams: semantic, timbre, prosody, and residual.
This architecture achieves high-fidelity speech reconstruction at competitive
low bitrates while demonstrating an inherent ability for information
disentanglement. We construct a two-stage language model for text-to-speech
(TTS) synthesis using this codec, which, despite its lightweight design and
minimal data requirements, achieves a state-of-the-art Word Error Rate (WER)
and superior speaker similarity compared to several larger models. Furthermore,
the codec's design proves highly effective for voice conversion, enabling
independent manipulation of speaker timbre and prosody.

</details>


### [24] [Token-based Attractors and Cross-attention in Spoof Diarization](https://arxiv.org/abs/2509.13085)
*Kyo-Won Koo,Chan-yeong Lim,Jee-weon Jung,Hye-jin Shim,Ha-Jin Yu*

Main category: eess.AS

TL;DR: 本文提出了一种基于可学习令牌的欺骗语音定位方法，通过引入代表真实和欺骗语音声学特征的吸引子来提升检测性能，在PartialSpoof数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有双分支模型结构简单，难以捕捉复杂的欺骗模式，且缺乏明确的参考点来区分真实语音和多种欺骗类型。

Method: 引入可学习令牌作为吸引子，每个令牌代表真实或欺骗语音的声学特征，通过与帧级嵌入交互来提取判别性表征。

Result: 在PartialSpoof数据集上的大量实验表明，该方法在真实语音检测和欺骗方法聚类方面均优于现有方法。

Conclusion: 所提出的基于可学习吸引子的方法有效解决了欺骗语音定位问题，为欺骗语音分析提供了更好的解决方案。

Abstract: Spoof diarization identifies ``what spoofed when" in a given speech by
temporally locating spoofed regions and determining their manipulation
techniques. As a first step toward this task, prior work proposed a two-branch
model for localization and spoof type clustering, which laid the foundation for
spoof diarization. However, its simple structure limits the ability to capture
complex spoofing patterns and lacks explicit reference points for
distinguishing between bona fide and various spoofing types. To address these
limitations, our approach introduces learnable tokens where each token
represents acoustic features of bona fide and spoofed speech. These attractors
interact with frame-level embeddings to extract discriminative representations,
improving separation between genuine and generated speech. Vast experiments on
PartialSpoof dataset consistently demonstrate that our approach outperforms
existing methods in bona fide detection and spoofing method clustering.

</details>


### [25] [Importance-Weighted Domain Adaptation for Sound Source Tracking](https://arxiv.org/abs/2509.13215)
*Bingxiang Zhong,Thomas Dietzen*

Main category: eess.AS

TL;DR: 这篇论文提出了一种新的无监督域适配方法，专门解决声源跟踪任务中的域偏移问题，通过重要性加权对抗训练和固定维庤特征表征来处理变长度序列和方向性多样性不匹配挑战。


<details>
  <summary>Details</summary>
Motivation: 深度学习模型在声源定位中需要大量标签数据，而真实录音标注成本高。综合数据可以作为替代方案，但存在域偏移问题。现有的无监督域适配方法主要聚焦静态声源定位，而声源跟踪任务面临变长度序列和方向性多样性不匹配两大挑战。

Method: 提出了一种专门为声源跟踪设计的无监督域适配方法：1）使用递归神经网络的最后隐藏状态作为固定维庤特征表征来处理变长度序列问题；2）采用重要性加权对抗训练来解决方向性多样性不匹配问题，优先选择与真实域相似的综合样本。

Result: 实验结果表明，该方法成功地将基于综合数据训练的模型适配到真实环境中，显著提高了声源跟踪的性能。

Conclusion: 该研究为声源跟踪任务提供了一种有效的域适配方案，通过重要性加权对抗训练和固定维庤特征表征技术，成功解决了变长度序列和方向性多样性不匹配这两个关键挑战。

Abstract: In recent years, deep learning has significantly advanced sound source
localization (SSL). However, training such models requires large labeled
datasets, and real recordings are costly to annotate in particular if sources
move. While synthetic data using simulated room impulse responses (RIRs) and
noise offers a practical alternative, models trained on synthetic data suffer
from domain shift in real environments. Unsupervised domain adaptation (UDA)
can address this by aligning synthetic and real domains without relying on
labels from the latter. The few existing UDA approaches however focus on static
SSL and do not account for the problem of sound source tracking (SST), which
presents two specific domain adaptation challenges. First, variable-length
input sequences create mismatches in feature dimensionality across domains.
Second, the angular coverages of the synthetic and the real data may not be
well aligned either due to partial domain overlap or due to batch size
constraints, which we refer to as directional diversity mismatch. To address
these, we propose a novel UDA approach tailored for SST based on two key
features. We employ the final hidden state of a recurrent neural network as a
fixed-dimensional feature representation to handle variable-length sequences.
Further, we use importance-weighted adversarial training to tackle directional
diversity mismatch by prioritizing synthetic samples similar to the real
domain. Experimental results demonstrate that our approach successfully adapts
synthetic-trained models to real environments, improving SST performance.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [26] [An Adaptive CMSA for Solving the Longest Filled Common Subsequence Problem with an Application in Audio Querying](https://arxiv.org/abs/2509.12261)
*Marko Djukanovic,Christian Blum,Aleksandar Kartelj,Ana Nikolikj,Guenther Raidl*

Main category: cs.SD

TL;DR: 本文解决长最大填充公共子序列(LFCS)这个NP难问题，提出了适应性CMSA框架，在新大规模数据集上达到最优性能，并探索了在音乐识别中的应用


<details>
  <summary>Details</summary>
Motivation: 现有的LFCS问题解决方法主要在小规模实例上评估，缺乏可扩展性分析。需要更大规模的测试数据集来评估算法在大规模问题上的表现

Method: 使用适应性构建、合并、求解、适应(CMSA)框架，通过迭代生成有前景的子问题，并利用外部黑盒求解器进行精炼

Result: 在1,510个已知最优解的问题实例中，解决了1,486个，达到超199.9%的最优解质量，显示了突出的可扩展性，超迈五种领先方法

Conclusion: 适应性CMSA框架在LFCS问题上实现了独特的性能，为大规模实例提供了高效解决方案，同时开拓了在音频识别等实际应用中的潜力

Abstract: This paper addresses the Longest Filled Common Subsequence (LFCS) problem, a
challenging NP-hard problem with applications in bioinformatics, including gene
mutation prediction and genomic data reconstruction. Existing approaches,
including exact, metaheuristic, and approximation algorithms, have primarily
been evaluated on small-sized instances, which offer limited insights into
their scalability. In this work, we introduce a new benchmark dataset with
significantly larger instances and demonstrate that existing datasets lack the
discriminative power needed to meaningfully assess algorithm performance at
scale. To solve large instances efficiently, we utilize an adaptive Construct,
Merge, Solve, Adapt (CMSA) framework that iteratively generates promising
subproblems via component-based construction and refines them using feedback
from prior iterations. Subproblems are solved using an external black-box
solver. Extensive experiments on both standard and newly introduced benchmarks
show that the proposed adaptive CMSA achieves state-of-the-art performance,
outperforming five leading methods. Notably, on 1,510 problem instances with
known optimal solutions, our approach solves 1,486 of them -- achieving over
99.9% optimal solution quality and demonstrating exceptional scalability. We
additionally propose a novel application of LFCS for song identification from
degraded audio excerpts as an engineering contribution, using real-world
energy-profile instances from popular music. Finally, we conducted an empirical
explainability analysis to identify critical feature combinations influencing
algorithm performance, i.e., the key problem features contributing to success
or failure of the approaches across different instance types are revealed.

</details>


### [27] [A Traditional Approach to Symbolic Piano Continuation](https://arxiv.org/abs/2509.12267)
*Christian Zhou-Zheng,John Backsund,Dun Li Chan,Alex Coventry,Avid Eslami,Jyotin Goel,Xingwen Han,Danysh Soomro,Galen Wei*

Main category: cs.SD

TL;DR: 简单的下一个令牌预测方法在象征钢琴音乐继续任务中超过大型基础模型


<details>
  <summary>Details</summary>
Motivation: 虽然计算音乐生成领域最近主要研究大型基础模型，但简单方法在受限的单乐器任务中仍然更有效

Method: 采用简单的未增强下一个令牌预测目标，对象征化的原始MIDI数据进行模型训练

Result: 通过使用更好的数据和更基础的方法，该方法预计能够超过大型基础模型的性能

Conclusion: 简单的传统方法在特定的音乐生成任务中仍然具有竞争力，方法和代码已开源

Abstract: We present a traditional approach to symbolic piano music continuation for
the MIREX 2025 Symbolic Music Generation challenge. While computational music
generation has recently focused on developing large foundation models with
sophisticated architectural modifications, we argue that simpler approaches
remain more effective for constrained, single-instrument tasks. We thus return
to a simple, unaugmented next-token-prediction objective on tokenized raw MIDI,
aiming to outperform large foundation models by using better data and better
fundamentals. We release model weights and code at
https://github.com/christianazinn/mirex2025.

</details>


### [28] [Omni-CLST: Error-aware Curriculum Learning with guided Selective chain-of-Thought for audio questuin answering](https://arxiv.org/abs/2509.12275)
*Jinghua Zhao,Hang Su,Lichun Fan,Zhenbo Luo,Jian Luan,Hui Wang,Haoqin Sun,Yong Qin*

Main category: cs.SD

TL;DR: Omni-CLST是一个用于音频问答的错误感知课程学习框架，通过难度分级样本和引导思维丢弃机制，在MMAUMini和MMAR数据集上取得了73.80%和64.30%的SOTA准确率。


<details>
  <summary>Details</summary>
Motivation: 为了解决音频问答任务中现有高质量数据集的有效利用问题，提出通过课程学习和选择性思维链来提升模型学习效率。

Method: 采用错误感知课程学习策略按难度组织样本，结合引导思维丢弃机制专注于困难案例，并与GRPO训练集成。

Result: 在MMAUMini数据集上达到73.80%准确率，在MMAR数据集上达到64.30%的SOTA性能，展现了优秀的鲁棒性和泛化能力。

Conclusion: Omni-CLST框架通过有效的课程学习和选择性推理机制，在多模态音频语言理解任务中表现出色，为音频问答提供了新的解决方案。

Abstract: We propose Omni-CLST, an error-aware Curriculum Learning framework with
guided Selective Chain-of-Thought for audio question answering. The framework
efficiently leverages existing high-quality dataset through two key strategies:
an error-aware curriculum that organizes samples by difficulty, and a guided
thought dropout mechanism that focuses reasoning on challenging cases.
Integrated with GRPO training, these strategies enable the model to learn more
effectively from informative samples. Experiments on MMAU-mini and MMAR
demonstrate that Omni-CLST achieves competitive accuracy (73.80% on MMAU-mini)
and establishes a new state of the art (64.30% on MMAR), highlighting its
robustness and generalization capability in multimodal audio-language
understanding.

</details>


### [29] [More Similar than Dissimilar: Modeling Annotators for Cross-Corpus Speech Emotion Recognition](https://arxiv.org/abs/2509.12295)
*James Tavernor,Emily Mower Provost*

Main category: cs.SD

TL;DR: 通过利用注释者间相似性，使用预训练模型找到相似的已见注释者，实现极低成本的语音情感识别个性化适配。


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别模型预测多个注释者的公认值，无法预测个体注释者的标注，而为新注释者重新训练模型成本过高。

Method: 预训练大规模注释者群体的模型，通过限量注册数据找到与新注释者相似的已见注释者，使用相似注释者的模型进行预测。

Result: 该方法显著超过其他开箱即用的适配方法，为轻量级情感适配推广提供了可行途径。

Conclusion: 通过注释者相似性的利用，实现了极低成本的个性化语音情感识别，具有实际部署的应用价值。

Abstract: Speech emotion recognition systems often predict a consensus value generated
from the ratings of multiple annotators. However, these models have limited
ability to predict the annotation of any one person. Alternatively, models can
learn to predict the annotations of all annotators. Adapting such models to new
annotators is difficult as new annotators must individually provide sufficient
labeled training data. We propose to leverage inter-annotator similarity by
using a model pre-trained on a large annotator population to identify a
similar, previously seen annotator. Given a new, previously unseen, annotator
and limited enrollment data, we can make predictions for a similar annotator,
enabling off-the-shelf annotation of unseen data in target datasets, providing
a mechanism for extremely low-cost personalization. We demonstrate our approach
significantly outperforms other off-the-shelf approaches, paving the way for
lightweight emotion adaptation, practical for real-world deployment.

</details>


### [30] [Osu2MIR: Beat Tracking Dataset Derived From Osu! Data](https://arxiv.org/abs/2509.12667)
*Ziyun Liu,Chris Donahue*

Main category: cs.SD

TL;DR: 使用Osu!节奏游戏的社区刻制诗谱作为节拍和强拍注释的替代来源，通过管线提取高质量数据并分析其可靠性


<details>
  <summary>Details</summary>
Motivation: 解决传统节拍注释数据集类型偏少的问题，利用Osu!社区的多样化音乐内容（动漫、Vocaloid、游戏音乐等）来获取可扩展的研究资源

Method: 开发了从Osu!诗谱提取注释的管线，将数据分为有意义子集，并通过手动分析评估不同间隔时间点的可靠性

Result: 发现单一时间点或间隔较大（≥5秒）的诗谱提供可靠注释，而间隔较小（<5秒）的需要额外编辑，同时观察到同一歌曲的多个注释具有高一致性

Conclusion: Osu!数据作为一种可扩展、多样化且社区驱动的资源，在MIR研究中具有很大潜力，并释放了管线和高质量子集osu2beat2025支持进一步研究

Abstract: In this work, we explore the use of Osu!, a community-based rhythm game, as
an alternative source of beat and downbeat annotations. Osu! beatmaps are
created and refined by a large, diverse community and span underrepresented
genres such as anime, Vocaloid, and video game music. We introduce a pipeline
for extracting annotations from Osu! beatmaps and partition them into
meaningful subsets. Through manual analysis, we find that beatmaps with a
single timing point or widely spaced multiple timing points (>=5 seconds apart)
provide reliable annotations, while closely spaced timing points (<5 seconds
apart) often require additional curation. We also observe high consistency
across multiple annotations of the same song. This study demonstrates the
potential of Osu! data as a scalable, diverse, and community-driven resource
for MIR research. We release our pipeline and a high-quality subset
osu2beat2025 to support further exploration:
https://github.com/ziyunliu4444/osu2mir.

</details>


### [31] [Timbre-Adaptive Transcription: A Lightweight Architecture with Associative Memory for Dynamic Instrument Separation](https://arxiv.org/abs/2509.12712)
*Ruigang Li,Yongxu Zhu*

Main category: cs.SD

TL;DR: 轻量级深度聚类模型，通过音色不可知背榜和聚合记忆机制，实现了超越预训练乐器的多音色诗词转换和动态分离


<details>
  <summary>Details</summary>
Motivation: 解决现有多音色转换模型在演绎性和源数限制方面的不足，无法演绎到预训练乐器以外的音色

Method: 采用音色不可知背榜结构（参数量减半）+新题聚合记忆机制，模仿人类听觉认知动态编码未见音色，配合合成数据集方法

Result: 转换模型在公开测试集上超过现有模型，分离模块展现了有前景的音色辨别能力，仅需12.5分钟训练数据

Conclusion: 提供了高效的音色相关音乐转换框架，为通过认知受启发的架构实现音色感知分离开启了新方向

Abstract: Existing multi-timbre transcription models struggle with generalization
beyond pre-trained instruments and rigid source-count constraints. We address
these limitations with a lightweight deep clustering solution featuring: 1) a
timbre-agnostic backbone achieving state-of-the-art performance with only half
the parameters of comparable models, and 2) a novel associative memory
mechanism that mimics human auditory cognition to dynamically encode unseen
timbres via attention-based clustering. Our biologically-inspired framework
enables adaptive polyphonic separation with minimal training data (12.5
minutes), supported by a new synthetic dataset method offering cost-effective,
high-precision multi-timbre generation. Experiments show the timbre-agnostic
transcription model outperforms existing models on public benchmarks, while the
separation module demonstrates promising timbre discrimination. This work
provides an efficient framework for timbre-related music transcription and
explores new directions for timbre-aware separation through cognitive-inspired
architectures.

</details>


### [32] [Beyond Bars: Distribution of Edit Operations in Historical Prints](https://arxiv.org/abs/2509.12786)
*Adrian Nachtwey,Fabian C. Moss,Anna Viktoria Katrin Plaksin*

Main category: cs.SD

TL;DR: 通过采样检验三种方法，找到最代表性的采样方法，减少音乐学研究中耗时的数字化过程


<details>
  <summary>Details</summary>
Motivation: 减少音乐学研究中整体数字化的时间成本，通过采样方法提高研究效率

Method: 提出从音乐源材中采样小节的方法，对比三种不同的采样方法，以贝多芬的小品集Op.33作为案例研究

Result: 找到了在发现差异方面表现最佳的采样方法

Conclusion: 该方法能够支持大规模音乐学分析，为十九世纪编辑实践研究和历史音乐作品学术编辑领域做出贡献

Abstract: In this paper, we present a method for conducting comparative corpus studies
in musicology that reduces the time-consuming digitization process. Instead of
encoding whole corpora of musical sources, we suggest sampling bars from these
sources. We address the challenge of selecting representative samples and
evaluate three different sampling methods. We used Beethoven's Bagatelles Op.
33 as a case study to find the method that works best in finding samples
representative with respect to differences. We believe that this approach
offers significant value to musicological research by enabling large-scale
analyses and thereby statistically sound results. Moreover, we believe our work
to be a valuable step toward understanding nineteenth-century editorial
practices and enriching the field of scholarly editing of historical musical
works.

</details>


### [33] [A Lightweight Pipeline for Noisy Speech Voice Cloning and Accurate Lip Sync Synthesis](https://arxiv.org/abs/2509.12831)
*Javeria Amir,Farwa Attaria,Mah Jabeen,Umara Noor,Zahid Rashid*

Main category: cs.SD

TL;DR: 通过模块化流水线结合Tortoise TTS和轻量GAN网络，实现了在噪声环境中的高保真声音克隆和实时唇部同步


<details>
  <summary>Details</summary>
Motivation: 解决当前声音克隆和说话头生成方法对大规模数据集和清洁工作室记录的依赖问题，适用于噪声或资源稀缺环境

Method: 模块化流求线：1）Tortoise TTS（基于transformer的潜在滿散模型）进行零样本声音克隆；2）轻量GAN网络实现实时唇部同步

Result: 能够在噪声和无约束场景中生成情感丰富的语音和实时唇部同步，减少对大规模预训练的依赖

Conclusion: 该模块化方案为实际系统提供了可扩展的多模态声音调制能力，具有广阔的应用前景

Abstract: Recent developments in voice cloning and talking head generation demonstrate
impressive capabilities in synthesizing natural speech and realistic lip
synchronization. Current methods typically require and are trained on large
scale datasets and computationally intensive processes using clean studio
recorded inputs that is infeasible in noisy or low resource environments. In
this paper, we introduce a new modular pipeline comprising Tortoise text to
speech. It is a transformer based latent diffusion model that can perform high
fidelity zero shot voice cloning given only a few training samples. We use a
lightweight generative adversarial network architecture for robust real time
lip synchronization. The solution will contribute to many essential tasks
concerning less reliance on massive pre training generation of emotionally
expressive speech and lip synchronization in noisy and unconstrained scenarios.
The modular structure of the pipeline allows an easy extension for future multi
modal and text guided voice modulation and it could be used in real world
systems.

</details>


### [34] [Improving Anomalous Sound Detection with Attribute-aware Representation from Domain-adaptive Pre-training](https://arxiv.org/abs/2509.12845)
*Xin Fang,Guirui Zhong,Qing Wang,Fan Chu,Lei Wang,Mengui Qian,Mingqi Cai,Jiangzhao Wu,Jianqing Gao,Jun Du*

Main category: cs.SD

TL;DR: 本文提出了一种聚类分析方法，通过基于领域适配预训练模型的表征分配假属性标签，解决异常音检测中机器属性标签缺失的问题，并在DCASE 2025挑战赛中创造了新的最高性能纪录。


<details>
  <summary>Details</summary>
Motivation: 异常音检测通常需要机器属性标签进行分类，但完整收集这些标签非常耗时且不实际。本文的动机是解决属性标签缺失的挑战。

Method: 提出聚类分析方法，使用领域适配预训练模型生成的表征来分配假属性标签，然后通过有监督精调进行模型适配。

Result: 在DCASE 2025挑战赛数据集上评估，该方法对比之前的顶级系统获得了显著的性能提升，创造了新的最高性能纪录。

Conclusion: 通过假属性标签分配和模型适配的方法，成功地解决了异常音检测中属性标签缺失的问题，为该领域提供了有效的解决方案。

Abstract: Anomalous Sound Detection (ASD) is often formulated as a machine attribute
classification task, a strategy necessitated by the common scenario where only
normal data is available for training. However, the exhaustive collection of
machine attribute labels is laborious and impractical. To address the challenge
of missing attribute labels, this paper proposes an agglomerative hierarchical
clustering method for the assignment of pseudo-attribute labels using
representations derived from a domain-adaptive pre-trained model, which are
expected to capture machine attribute characteristics. We then apply model
adaptation to this pre-trained model through supervised fine-tuning for machine
attribute classification, resulting in a new state-of-the-art performance.
Evaluation on the Detection and Classification of Acoustic Scenes and Events
(DCASE) 2025 Challenge dataset demonstrates that our proposed approach yields
significant performance gains, ultimately outperforming our previous
top-ranking system in the challenge.

</details>


### [35] [The CCF AATC 2025: Speech Restoration Challenge](https://arxiv.org/abs/2509.12974)
*Junan Zhang,Mengyao Zhu,Xin Xu,Hui Bu,Zhenhua Ling,Zhizheng Wu*

Main category: cs.SD

TL;DR: CCF AATC 2025语音修复挑战赛旨在解决现实场景中多种失真同时存在的复杂语音增强问题，包括声学失真、信号链伪影和预处理模型引入的二次伪影。


<details>
  <summary>Details</summary>
Motivation: 现实语音通信中多种失真同时存在且相互作用，现有语音增强算法在单一失真处理上表现良好，但在复杂现实场景中效果有限。

Method: 设计包含三类失真的复合退化任务：复杂声学失真（非平稳噪声和混响）、信号链伪影（如MP3压缩）和其他预处理增强模型引入的二次伪影。创建综合数据集并制定详细评估协议。

Result: 提出了一个全面的语音修复挑战赛框架，包括任务设计、数据集构建方法和评估标准，旨在推动该领域研究发展。

Conclusion: 该挑战赛为处理现实世界中复杂多失真语音增强问题提供了标准化基准，将促进更鲁棒的语音修复算法的发展。

Abstract: Real-world speech communication is often hampered by a variety of distortions
that degrade quality and intelligibility. While many speech enhancement
algorithms target specific degradations like noise or reverberation, they often
fall short in realistic scenarios where multiple distortions co-exist and
interact. To spur research in this area, we introduce the Speech Restoration
Challenge as part of the China Computer Federation (CCF) Advanced Audio
Technology Competition (AATC) 2025. This challenge focuses on restoring speech
signals affected by a composite of three degradation types: (1) complex
acoustic degradations including non-stationary noise and reverberation; (2)
signal-chain artifacts such as those from MP3 compression; and (3) secondary
artifacts introduced by other pre-processing enhancement models. We describe
the challenge's background, the design of the task, the comprehensive dataset
creation methodology, and the detailed evaluation protocol, which assesses both
objective performance and model complexity. Homepage: https://ccf-aatc.org.cn/.

</details>


### [36] [GLAD: Global-Local Aware Dynamic Mixture-of-Experts for Multi-Talker ASR](https://arxiv.org/abs/2509.13093)
*Yujie Guo,Jiaming Zhou,Yuhang Jia,Shiwan Zhao,Yong Qin*

Main category: cs.SD

TL;DR: 提出GLAD混合专家模型，通过全局-局部融合策略动态选择专家，显著提升多说话人语音识别在重叠语音场景下的性能


<details>
  <summary>Details</summary>
Motivation: 端到端多说话人语音识别在重叠语音场景下面临准确率低的挑战，特别是在高重叠条件下

Method: GLAD混合专家模型，动态融合说话人感知的全局信息和细粒度局部特征来指导专家选择，利用全局上下文和局部声学线索实现说话人特定路由

Result: 在LibriSpeechMix数据集上实验表明，GLAD优于现有MTASR方法，特别是在具有挑战性的多说话人场景中

Conclusion: 这是首个将混合专家模型应用于端到端多说话人语音识别的工作，采用全局-局部融合策略，显著提升了重叠语音识别性能

Abstract: End-to-end multi-talker automatic speech recognition (MTASR) faces
significant challenges in accurately transcribing overlapping speech,
especially under high-overlap conditions. To address these challenges, we
proposed Global-Local Aware Dynamic (GLAD) Mixture-of-Experts, which
dynamically fuse speaker-aware global information and fine-grained local
features to guide expert selection. This mechanism enables speaker-specific
routing by leveraging both global context and local acoustic cues. Experiments
on LibriSpeechMix show that GLAD outperforms existing MTASR approaches,
particularly in challenging multi-talker scenarios. To our best knowledge, this
is the first work to apply Mixture-of-Experts (MoE) to end-to-end MTASR with a
global-local fusion strategy. Our code and train dataset can be found at
https://github.com/NKU-HLT/GLAD.

</details>


### [37] [UTI-LLM: A Personalized Articulatory-Speech Therapy Assistance System Based on Multimodal Large Language Model](https://arxiv.org/abs/2509.13145)
*Yudong Yang,Xiaokang Liu,Shaofeng zhao,Rongfeng Su,Nan Yan,Lan Wang*

Main category: cs.SD

TL;DR: 基于多模态大语言模型的语音康复辅助系统，通过超声舌头成像和语音信号的协同融合，实现了精确的反馈和细粒度的语音障碍分析。


<details>
  <summary>Details</summary>
Motivation: 传统语音治疗系统在实时可访问性和语音运动反馈方面有限，而多模态大语言模型在医疗健康领域展现出强大潜力，但在语音治疗中面临着语音信息获取融合不充、语音器官运动轨迹解析不充等挑战。

Method: 构建了高质量的域特定数据集（UTI-speech对话对），并采用超声视频和语音信号的时空融合训练策略，通过微调提升模型的临床适配性。

Result: 实现了细粒度的语音障碍分析，能够生成可执行的反馈，为语音康复提供了精准的交互式语音反馈。

Conclusion: 该系统有效解决了传统语音治疗系统的限制，为语音康复领域提供了一种高效、精确的新方法，展示了多模态大语言模型在医疗健康领域的应用潜力。

Abstract: Speech therapy plays a critical role in training speech disorders caused by
neurological impairments such as stroke. However, traditional manual and
computer-assisted systems are limited in real-time accessibility and
articulatory motion feedback, constraining their practical utility. Recent
advances in multimodal large language models (MLLMs) have demonstrated
significant potential in healthcare, particularly through their ability to
integrate multimodal data for adaptive assessment and therapeutic feedback.
Nevertheless, challenges including insufficient acquisition and fusion of
articulatory information, inadequate parsing of articulatory organ motion
trajectories, and the scarcity of high-quality domain-specific datasets hinder
the application of MLLMs in speech therapy. To address these limitations, we
propose an MLLM-based speech rehabilitation assistance system that
synergistically leverages ultrasound tongue imaging and speech signals to
deliver precise, interactive articulatory feedback. We construct a high-quality
domain-specific dataset comprising UTI-speech dialogue pairs. This dataset
facilitates fine-tuning to enhance the model's clinical adaptability. Building
on this dataset, our methods achieves spatiotemporal fusion training strategy
of ultrasound videos and speech signals, enabling fine-grained articulatory
impairment analysis and ultimately generating actionable feedback.

</details>


### [38] [Can Large Audio Language Models Understand Audio Well? Speech, Scene and Events Understanding Benchmark for LALMs](https://arxiv.org/abs/2509.13148)
*Han Yin,Jung-Woo Choi*

Main category: cs.SD

TL;DR: SSEU-Bench是首个考虑语音与非语音音频能量差异的通用音频理解基准，包含独立和联合理解设置，并通过思维链方法提升大音频语言模型的联合理解性能


<details>
  <summary>Details</summary>
Motivation: 现有音频理解基准未充分考虑真实场景中语音与非语音组件的能量差异，以及语音、场景和事件的联合理解需求

Method: 提出SSEU-Bench基准，包含独立和联合理解设置，并引入思维链(Chain-of-Thought)方法将复杂任务分解为简单推理步骤

Result: 研究发现某些大音频语言模型在联合理解设置下表现不佳，思维链方法有效提升了模型的联合音频理解性能

Conclusion: SSEU-Bench填补了音频理解基准的空白，思维链方法为解决复杂音频联合理解任务提供了有效解决方案

Abstract: Recently, Large Audio Language Models (LALMs) have progressed rapidly,
demonstrating their strong efficacy in universal audio understanding through
cross-modal integration. To evaluate the LALM's audio understanding
performance, researchers have proposed different benchmarks. However, key
aspects for real-world interactions are underexplored in existing benchmarks,
i.e., audio signals typically contain both speech and non-speech components,
and energy levels of these components can vary significantly across different
scenarios. Moreover, most benchmarks do not consider the joint understanding of
speech, scene, and events within the same audio clip. In this work, we
introduce SSEU-Bench, the first versatile audio understanding benchmark that
explicitly accounts for energy differences between speech and non-speech audio,
with both independent and joint understanding settings for speech, scene, and
events. Furthermore, we demonstrate that some LALMs tend to underperform on
certain tasks in a joint understanding setting. To address this issue, we
introduce Chain-of-Thought, which effectively improves the LALM's joint audio
understanding performance by decomposing complex tasks into simpler reasoning
steps

</details>


### [39] [Contrastive timbre representations for musical instrument and synthesizer retrieval](https://arxiv.org/abs/2509.13285)
*Gwendal Le Vaillant,Yannick Molle*

Main category: cs.SD

TL;DR: 提出基于对比学习的乐器检索框架，能够使用单一模型从单乐器或多乐器音频中直接查询乐器数据库，在多乐器检索任务中表现优异


<details>
  <summary>Details</summary>
Motivation: 数字音乐制作中从音频混合中高效检索特定乐器音色存在挑战，现有音频数据增强方法在处理虚拟乐器时存在局限性

Method: 采用对比学习框架，为虚拟乐器（如采样器和合成器）生成真实的正负样本对，使用单一模型处理单乐器和多乐器声音检索

Result: 在3884种乐器数据集上，单乐器检索性能与基于分类预训练的方法相当；多乐器检索中，三乐器混合的top-1准确率达到81.7%，top-5达到95.7%，优于相关工作

Conclusion: 对比学习框架在多乐器检索任务中表现出色，为音乐制作中的乐器检索提供了有效的解决方案

Abstract: Efficiently retrieving specific instrument timbres from audio mixtures
remains a challenge in digital music production. This paper introduces a
contrastive learning framework for musical instrument retrieval, enabling
direct querying of instrument databases using a single model for both single-
and multi-instrument sounds. We propose techniques to generate realistic
positive/negative pairs of sounds for virtual musical instruments, such as
samplers and synthesizers, addressing limitations in common audio data
augmentation methods.
  The first experiment focuses on instrument retrieval from a dataset of 3,884
instruments, using single-instrument audio as input. Contrastive approaches are
competitive with previous works based on classification pre-training. The
second experiment considers multi-instrument retrieval with a mixture of
instruments as audio input. In this case, the proposed contrastive framework
outperforms related works, achieving 81.7\% top-1 and 95.7\% top-5 accuracies
for three-instrument mixtures.

</details>

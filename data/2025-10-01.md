<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 27]
- [eess.AS](#eess.AS) [Total: 7]
- [cs.SD](#cs.SD) [Total: 12]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Experimental Demonstration of Robust Distributed Wireless Clock Synchronization](https://arxiv.org/abs/2509.25277)
*Kumar Sai Bondada,Hiten Kothari,Yibin Liang,Daniel J. Jakubisin,R. Michael Buehrer*

Main category: eess.SP

TL;DR: 提出了一种抗干扰的频率跳变双音波形，用于分布式无线时钟同步，使收发器无需预先知道精确频率即可提取参考信号。


<details>
  <summary>Details</summary>
Motivation: 现有的双音波形时钟同步方法虽然频率精度优于1Hz，但容易受到有意和无意的干扰，需要提高抗干扰能力。

Method: 使用频率跳变的双音波形，通过频率跳变技术使收发器能够在不预先知道精确传输频率的情况下提取参考信号。

Result: 该方法实现了鲁棒的时钟同步，能够有效抵抗干扰，同时保持高精度的频率同步性能。

Conclusion: 频率跳变双音波形为分布式无线时钟同步提供了一种抗干扰的解决方案，提高了系统在干扰环境下的可靠性。

Abstract: Distributed wireless clock synchronization is essential for aligning the
clocks of distributed transceivers in support of joint transmission and
reception techniques. One recently explored method involves synchronizing
distributed transceivers using a two-tone waveform, where the tones are
separated in frequency by a clock (frequency) reference signal. Prior research
has demonstrated frequency accuracy better than 1 Hz; however, this approach
remains vulnerable to both intentional and unintentional interference. In this
demonstration, we present a robust, frequency-hopped two-tone waveform that
enables transceivers to extract the reference signal without prior knowledge of
the exact frequency at which the tones are transmitted.

</details>


### [2] [A Graph-based Hybrid Beamforming Framework for MIMO Cell-Free ISAC Networks](https://arxiv.org/abs/2509.25385)
*Yanan Du,Sai Xu,Jagmohan Chauhan*

Main category: eess.SP

TL;DR: 本文提出了一种基于图神经网络的混合波束成形框架，用于MIMO无蜂窝集成感知与通信网络，通过分布式部署和FPGA加速实现高效通信与感知。


<details>
  <summary>Details</summary>
Motivation: 为了解决MIMO无蜂窝ISAC网络中同时优化通信和感知性能的挑战，同时考虑实际部署中的分布式要求和计算效率问题。

Method: 构建了新型MIMO无蜂窝ISAC网络模型，将多目标优化问题转化为单目标优化，开发基于多图神经网络的图方法实现混合波束成形，并设计FPGA加速器降低推理延迟。

Result: 数值仿真验证了所提优化方法在通信和感知方面的能力，实验评估显示FPGA加速在GNN推理中带来显著性能提升。

Conclusion: 提出的图基混合波束成形框架能有效提升MIMO无蜂窝ISAC网络的通信和感知性能，且通过分布式部署和FPGA加速实现了高效实用的系统实现。

Abstract: This paper develops a graph-based hybrid beamforming framework for
multiple-input multiple-output (MIMO) cell-free integrated sensing and
communication (ISAC) networks. Specifically, we construct a novel MIMO
cell-free ISAC network model. In this model, multiple dual-function base
station (BS) transmitters employ distributed hybrid beamforming to enable
simultaneous communication and sensing, while maintaining physical separation
between the transmitters and the radar receiver. Building on this model, we
formulate a multi-objective optimization problem under a power constraint to
jointly improve communication and sensing performance. To solve it, the problem
is first reformulated as a single-objective optimization problem. Then, a
graph-based method composed of multiple graph neural networks (GNNs) is
developed to realize hybrid beamforming with either perfect or imperfect
channel state information. Once trained, the neural network model can be
deployed distributively across BSs, enabling fast and efficient inference. To
further reduce inference latency, a custom field-programmable gate array
(FPGA)-based accelerator is developed. Numerical simulations validate the
communication and sensing capabilities of the proposed optimization approach,
while experimental evaluations demonstrate remarkable performance gains of
FPGA-based acceleration in GNN inference.

</details>


### [3] [A closed-loop $2\times4$ downlink MIMO Framework for 5G New Radio using OpenAirInterface](https://arxiv.org/abs/2509.25497)
*Duc Tung Bui,Le-Nam Tran*

Main category: eess.SP

TL;DR: 首次实现基于OpenAirInterface的5G O-RAN下行链路2×4 MIMO闭环系统，支持最多两层传输，相比现有2×2 MIMO配置在几乎所有场景下提升了数据速率。


<details>
  <summary>Details</summary>
Motivation: 为新兴O-RAN开发提供基础框架，解决现有OAI中MIMO配置的局限性，实现更高效的5G NR系统。

Method: 使用OpenAirInterface构建完整的5G系统（包括核心网、接入网和用户设备），增强UE的CSI报告流程（RI、PMI、CQI），并通过iperf3在固定信道和Rice1信道下测量下行数据速率。

Result: 相比OAI现有的2×2 MIMO配置，该实现几乎在所有场景下都提高了数据速率，特别是在高信噪比条件下表现更佳。

Conclusion: 成功实现了首个5G O-RAN 2×4 MIMO闭环系统，为O-RAN的进一步发展奠定了重要基础，并显著提升了系统性能。

Abstract: We present the first-of-a-kind closed-loop $2\times4$ MIMO implementation for
the downlink of 5G Open RAN using OpenAirInterface (OAI), which is capable of
transmitting up to two transmission layers. Our implementation is a fully
functional 5G New Radio (5G NR) system, including the 5G Core Network (5G CN),
5G Radio Access Network (5G RAN), as well as 5G NR User Equipment (UEs). This
serves as a foundational framework for further advancements in the context of
emerging Open RAN (O-RAN) development. A key feature of our implementation is
the enhanced Channel State Information (CSI) reporting procedure at the UE,
which includes Rank Indicator (RI), Precoding Matrix Indicator (PMI), and
Channel Quality Indicator (CQI). It is adjusted for the extended configuration
to maximize data rates. To demonstrate the performance of our implementation,
we measure the downlink data rates using $\textit{iperf3}$ in two scenarios:
(i) fixed channels to assess two-layer data transmission and (ii)
$\textit{Rice1}$ channels for general transmission analysis. The obtained
simulation results demonstrate that, compared to the existing $2\times2$ MIMO
configuration in the OAI, our implementation improves the data rates in almost
all scenarios, especially at the high Signal-to-Noise-Ratios (SNRs).

</details>


### [4] [An Implementation of Multi-User MIMO Downlink for O-RAN 5G New Radio using OpenAirInterface](https://arxiv.org/abs/2509.25512)
*Duc Tung Bui,Le-Nam Tran*

Main category: eess.SP

TL;DR: 首个在5G O-RAN上实现MU-MIMO传输方案的实现，基于OpenAirInterface，展示了多用户同时传输的性能提升。


<details>
  <summary>Details</summary>
Motivation: 实现O-RAN兼容的5G NR系统，展示MU-MIMO在5G下行链路的性能优势，同时验证O-RAN的解耦能力。

Method: 构建完整的5G系统架构，包括5G核心网、分离的CU/DU RAN和UE。通过PMI报告进行用户调度，使用iperf评估系统吞吐量。

Result: MU-MIMO方案在高SNR区域显著提升下行链路吞吐量，同时保持两个UE的BLER低于10^-1阈值。

Conclusion: 成功实现了O-RAN兼容的MU-MIMO传输，验证了多用户同时传输的性能增益和O-RAN架构的可行性。

Abstract: We present the first implementation of a Multi-User Multiple-Input
Multiple-Output (MU-MIMO) transmission scheme on the Physical Downlink Shared
Channel (PDSCH) for 5G Open Radio Access Network (O-RAN) based on
OpenAirInterface (OAI). Our implementation features a fully functional
O-RAN-compliant 5G New Radio (5G NR) system, including a 5G Core Network (5G
CN), a refined 5G RAN, which is split into a Centre Unit (CU) and an
Distributed Unit (DU), and 5G NR User Equipment (UEs). This implementation
demonstrates MU-MIMO performance in the downlink while showcasing the
disaggregation capabilities of O-RAN. Specifically, the Base Station (i.e. gNB)
in our setup is capable of serving two UEs simultaneously over the same
downlink Resource Block (RBs). User scheduling is performed based on the
Precoding Matrix Indicators (PMIs) reported by the UEs according to the NR
Channel State Information (CSI) reporting procedure. The system throughput
performance is evaluated using $\textit{iperf}$. The obtained results via
simulation and testbed experiments demonstrate that the MU-MIMO scheme achieves
significant downlink throughput gains, particularly in the high
Signal-to-Noise-Ratio (SNR) regime, while keeping the Block Error Rate (BLER)
below the required threshold of $10^{-1}$ for both UEs.

</details>


### [5] [Joint UE positioning and distributed sensing in the upper mid-band exploiting virtual apertures](https://arxiv.org/abs/2509.25557)
*Soroush Mesforush,Murat Bayraktar,Nuria González-Prelcic*

Main category: eess.SP

TL;DR: 本文提出了一种在FR3频段运行的分布式集成感知与通信(DISAC)系统，通过设计用户设备(UE)侧的信号处理链，实现联合UE定位和目标定位。


<details>
  <summary>Details</summary>
Motivation: 利用FR3频段的大阵列和带宽优势，通过DISAC网络提供增强的定位和感知性能，解决实际系统中存在的定时偏移、扩展目标、密集多径等挑战。

Method: 采用MIMO-OFDM波形，设计包含多径估计、杂波消除、新颖的聚类关联方案以及联合估计器的信号处理链，通过加权最小二乘法联合计算时钟偏移并定位UE和目标。

Result: 数值结果表明，在考虑两个UE和两个目标的情况下，80%的情况下目标定位误差低于32cm，UE定位误差低于44cm。

Conclusion: 所提出的DISAC系统设计能够在FR3频段有效实现联合UE定位和目标定位，具有较高的定位精度。

Abstract: Networks exploiting distributed integrated sensing and communication (DISAC)
nodes can provide enhanced localization and sensing performance, further
emphasized when operating with large arrays and bandwidths available in the
upper mid-band (also known as FR3). In this paper, we consider a DISAC system
operating at FR3 where a single base station (BS) acts as the transmitter and
several vehicular user equipments (UEs) act as the receivers. We tackle the
design of the signal processing chain at the UE side to enable joint UE
positioning and target localization. The system model exploits a
multiple-input-multiple-output orthogonal frequency division multiplexing
(MIMO-OFDM) waveform, and incorporates practical effects such as inter-node
timing offsets (TOs), extended targets, dense multipath, and realistic uniform
planar arrays (UPAs) at both ends. The proposed design includes a multipath
estimation stage at each UE, clutter removal, a novel clustering and
association scheme, and a final joint estimator of UE positions and target
locations. The estimator solves a weighted least squares (WLS) problem to
jointly compute clock offsets and localize UEs and targets. Numerical results
considering two UEs and two targets show that for 80\% of the cases the target
localization error is below 32cm, while the UE positioning error is below 44cm.

</details>


### [6] [Rotatable Antenna-Enabled Spectrum Sharing in Cognitive Radio Systems](https://arxiv.org/abs/2509.25656)
*Yanhua Tan,Beixiong Zheng,Yi Fang,Derrick Wing Kwan Ng,Rui Zhang,Jie Xu*

Main category: eess.SP

TL;DR: 提出了一种基于可旋转天线的认知无线电系统，通过联合优化波束成形和天线方向来最大化次级接收器的信干噪比，同时满足对主用户的干扰约束。


<details>
  <summary>Details</summary>
Motivation: 可旋转天线技术能够通过动态调整天线方向来利用额外的空间自由度，在认知无线电系统中实现更高效的频谱共享和干扰管理。

Method: 使用交替优化和逐次凸逼近技术来解决非凸的联合优化问题，包括波束成形和天线方向设计。

Result: 数值结果表明，所提出的可旋转天线辅助系统在频谱共享认知无线电系统中显著优于传统基准方案。

Conclusion: 可旋转天线技术能够同时提升次级接收器的通信质量并减少对主用户的干扰，验证了其在认知无线电系统中的有效性。

Abstract: Rotatable antenna (RA) technology has recently drawn significant attention in
wireless systems owing to its unique ability to exploit additional spatial
degrees-of-freedom (DoFs) by dynamically adjusting the three-dimensional (3D)
boresight direction of each antenna. In this letter, we propose a new
RA-assisted cognitive radio (CR) system designed to achieve efficient spectrum
sharing while mitigating interference between primary and secondary
communication links. Specifically, we formulate an optimization problem for the
joint design of the transmit beamforming and the boresight directions of RAs at
the secondary transmitter (ST), aimed at maximizing the received
signal-to-interference-plus-noise ratio (SINR) at the secondary receiver (SR),
while satisfying both interference constraint at the primary receiver (PR) and
the maximum transmit power constraint at the ST. Although the formulated
problem is challenging to solve due to its non-convexity and coupled variables,
we develop an efficient algorithm by leveraging alternating optimization (AO)
and successive convex approximation (SCA) techniques to acquire high-quality
solutions. Numerical results demonstrate that the proposed RA-assisted system
substantially outperforms conventional benchmark schemes in spectrum-sharing CR
systems, validating RA's capability to simultaneously enhance the communication
quality at the SR and mitigate interference at the PR.

</details>


### [7] [A Novel Statistical Analysis Method for Radiation Source Classification](https://arxiv.org/abs/2509.25675)
*Haobo Geng,Yaoyao Li,Weiping Tong,Youwei Meng,Houpu Xiao,Yicong Liu*

Main category: eess.SP

TL;DR: 提出了一种结合线性判别分析(LDA)和粗糙邻域集(NRS)的大数据分析方法，用于辐射源分类，并在RadioML 2018数据集上验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 随着电子信息技术的快速发展，未知辐射源的数量和种类显著增加，其中一些辐射源具有共同特征，为解决识别未知辐射源的挑战提供了可能，但目前关于辐射源分类的研究相对有限。

Method: 采用线性判别分析(LDA)与粗糙邻域集(NRS)相结合的大数据分析方法进行辐射源分类。

Result: 在特定约束条件下，所有调制类型可以被分为四个不同的类别。

Conclusion: 该方法为认知干扰信号消除的进一步研究奠定了基础。

Abstract: With the rapid advancement of electronic information technology, the number
and variety of unknown radiation sources have increased significantly. Some of
these sources share common characteristics, which offers the potential to
effectively address the challenge of identifying unknown radiation sources.
However, research on the classification of radiation sources remains relatively
limited. This paper proposes a big data analysis method that combines linear
discriminant analysis (LDA) with a rough neighborhood set (NRS) for radiation
source classification, and its effectiveness is validated on the RadioML 2018
dataset. The results indicate that, under certain constraints, all modulation
types can be categorized into four distinct classes, laying a foundation for
further research on cognitive interference signal cancellation.

</details>


### [8] [Transformer-Based Rate Prediction for Multi-Band Cellular Handsets](https://arxiv.org/abs/2509.25722)
*Ruibin Chen,Haozhe Lei,Hao Guo,Marco Mezzavilla,Hitesh Poddar,Tomoki Yoshimura,Sundeep Rangan*

Main category: eess.SP

TL;DR: 提出基于Transformer的神经网络架构，用于在稀疏历史测量条件下预测多天线阵列和多频段的可达速率，以支持更好的频段选择。


<details>
  <summary>Details</summary>
Motivation: 随着FR3等新频段的扩展，用户设备需要在有限空间内支持多天线多频段。信道质量的快速变化、天线视场角限制以及硬件功率约束导致的测量稀疏性，给可靠的多频段信道跟踪带来挑战。

Method: 采用基于Transformer的神经网络架构，输入异步速率历史数据，输出每个天线阵列的速率预测。

Result: 在密集城市微蜂窝场景下的射线追踪仿真中，该方法在FR1和FR3阵列上表现出优于基线预测器的性能。

Conclusion: 该方法能够在现实的移动性和硬件约束下实现更明智的频段选择。

Abstract: Cellular wireless systems are witnessing the proliferation of frequency bands
over a wide spectrum, particularly with the expansion of new bands in FR3.
These bands must be supported in user equipment (UE) handsets with multiple
antennas in a constrained form factor. Rapid variations in channel quality
across the bands from motion and hand blockage, limited field-of-view of
antennas, and hardware and power-constrained measurement sparsity pose
significant challenges to reliable multi-band channel tracking. This paper
formulates the problem of predicting achievable rates across multiple antenna
arrays and bands with sparse historical measurements. We propose a
transformer-based neural architecture that takes asynchronous rate histories as
input and outputs per-array rate predictions. Evaluated on ray-traced
simulations in a dense urban micro-cellular setting with FR1 and FR3 arrays,
our method demonstrates superior performance over baseline predictors, enabling
more informed band selection under realistic mobility and hardware constraints.

</details>


### [9] [Doppler-Based Multistatic Drone Tracking via Cellular Downlink Signals](https://arxiv.org/abs/2509.25732)
*Chenqing Ji,Qionghui Liu,Jiahong Liu,Chao Yu,Yifei Sun,Rui Wang,Fan Liu*

Main category: eess.SP

TL;DR: 提出了一种利用LTE下行信号的多基地多普勒感知系统来跟踪无人机轨迹，仅通过多普勒频率测量就能实现高精度轨迹重建，无需距离和角度信息。


<details>
  <summary>Details</summary>
Motivation: 利用现有的LTE基站作为信号发射源，通过被动感知接收器检测多普勒频率，实现低成本、高精度的无人机跟踪，避免传统雷达系统的复杂部署。

Method: 部署三个被动感知接收器在不同位置，从接收的LTE下行信号中检测双基地多普勒频率，通过求解最小均方误差问题重建无人机轨迹（包括初始位置和各时隙速度）。

Result: 实验表明，在无人机和接收器距离基站约200米的情况下，复杂轨迹的跟踪误差90%低于90厘米，精度显著高于LTE信号的典型距离分辨率。

Conclusion: 仅通过多普勒检测就能实现高精度无人机轨迹跟踪，前提是接收器部署密度足够高，这为基于现有通信基础设施的感知应用提供了可行性证明。

Abstract: In this paper, a multistatic Doppler sensing system is proposed for the drone
tracking via downlink Long-Term Evolution (LTE) signals. Specifically, the LTE
base stations (BSs) are exploited as signal illuminators, and three passive
sensing receivers are deployed at different locations to detect the bistatic
Doppler frequencies of a target drone from received downlink signals. It is
shown that even without the measurements of BS-drone-receiver range and angle,
the Doppler measurements could provide sufficient information for trajectory
tracking. Particularly, the trajectory of the target drone, consisting of the
initial position and velocities of all the time slots, can be reconstructed by
solving a minimum mean-squared error problem according to the above Doppler
measurements. It is demonstrated by experiment that although the target drone
and all the sensing receivers are around 200 meters away from the illuminating
BSs, the complicated trajectories can be tracked with 90% errors below 90
centimeters. Since this accuracy is notably higher than the typical range
resolution of LTE signals, the demonstration shows that drone trajectory
tracking with a high accuracy could be feasible solely according to Doppler
detection, as long as the deployment density of receivers is sufficiently high.

</details>


### [10] [Digital Twin Aided Massive MIMO CSI Feedback: Exploring the Impact of Twinning Fidelity](https://arxiv.org/abs/2509.25793)
*Hao Luo,Shuaifeng Jiang,Saeed R. Khosravirad,Ahmed Alkhateeb*

Main category: eess.SP

TL;DR: 提出利用站点特定数字孪生来训练基于深度学习的CSI压缩模型，通过电磁3D模型、硬件模型和射线追踪生成合成数据，减少对真实世界测量的依赖，并开发了保真度分析框架和细化策略。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在MIMO系统中压缩CSI时对大量站点特定训练数据的依赖问题，这些数据的收集成本高且限制了跨站点的可扩展性。

Method: 使用数字孪生集成电磁3D模型、硬件模型和射线追踪生成合成CSI数据；开发保真度分析框架评估数字孪生质量；提出结合少量真实数据的细化策略来微调模型。

Result: 在站点特定数字孪生上训练的模型优于通用数据集训练的模型，细化方法能有效利用有限真实数据提升性能；模拟显示数字孪生保真度（特别是3D几何、射线追踪和硬件建模）对CSI重建质量至关重要。

Conclusion: 数字孪生方法为无线通信任务提供了高效的数据生成和模型训练方案，保真度分析框架有助于识别关键因素并优化数字孪生开发策略。

Abstract: Deep learning (DL) techniques have demonstrated strong performance in
compressing and reconstructing channel state information (CSI) while reducing
feedback overhead in massive MIMO systems. A key challenge, however, is their
reliance on extensive site-specific training data, whose real-world collection
incurs significant overhead and limits scalability across deployment sites. To
address this, we propose leveraging site-specific digital twins to assist the
training of DL-based CSI compression models. The digital twin integrates an
electromagnetic (EM) 3D model of the environment, a hardware model, and ray
tracing to produce site-specific synthetic CSI data, allowing DL models to be
trained without the need for extensive real-world measurements. We further
develop a fidelity analysis framework that decomposes digital twin quality into
four key aspects: 3D geometry, material properties, ray tracing, and hardware
modeling. We explore how these factors influence the reliability of the data
and model performance. To enhance the adaptability to real-world environments,
we propose a refinement strategy that incorporates a limited amount of
real-world data to fine-tune the DL model pre-trained on the digital twin
dataset. Evaluation results show that models trained on site-specific digital
twins outperform those trained on generic datasets, with the proposed
refinement method effectively enhancing performance using limited real-world
data. The simulations also highlight the importance of digital twin fidelity,
especially in 3D geometry, ray tracing, and hardware modeling, for improving
CSI reconstruction quality. This analysis framework offers valuable insights
into the critical fidelity aspects, and facilitates more efficient digital twin
development and deployment strategies for various wireless communication tasks.

</details>


### [11] [Delay-Doppler Domain Channel Measurements and Modeling in High-Speed Railways](https://arxiv.org/abs/2509.25854)
*Hao Zhou,Yiyan Ma,Dan Fei,Weirong Liu,Zhengyu Zhang,Mi Yang,Guoyu Ma,Yunlong Lu,Ruisi He,Guoyu Wang,Cheng Li,Zhaohui Song,Bo Ai*

Main category: eess.SP

TL;DR: 本文提出了一种在高速铁路场景下的延迟-多普勒域信道测量与建模方法，通过LTE-R系统验证了DD域信道模型的准确性，并发现DD域信道衰落系数的准不变区间远小于准平稳区间。


<details>
  <summary>Details</summary>
Motivation: 下一代无线通信系统需要在高频段和高移动性场景下运行，DD域多载波调制方案（如OTFS）比OFDM具有更优越的可靠性。然而，传统的信道建模方法主要局限于时域、频域和空域，DD域信道建模原理研究不足。

Method: 1. 基于LTE-R系统设计DD域信道测量方法；2. 研究准平稳区间、多径分量统计功率建模和DD域信道衰落系数的准不变区间；3. 在371 km/h速度下通过LTE-R测量建立不同时变条件下的DD域信道模型；4. 通过OTFS传输的误码率比较验证模型准确性。

Result: 在高速铁路场景下，DD域信道衰落系数的准不变区间为毫秒量级，远小于准平稳区间的100毫秒量级。建立的DD域信道模型通过OTFS传输验证具有良好准确性。

Conclusion: 本研究为高移动性环境中的DD域建模提供了理论指导，支持未来6G及以上的DDMC和集成感知与通信设计。

Abstract: As next-generation wireless communication systems need to be able to operate
in high-frequency bands and high-mobility scenarios, delay-Doppler (DD) domain
multicarrier (DDMC) modulation schemes, such as orthogonal time frequency space
(OTFS), demonstrate superior reliability over orthogonal frequency division
multiplexing (OFDM). Accurate DD domain channel modeling is essential for DDMC
system design. However, since traditional channel modeling approaches are
mainly confined to time, frequency, and space domains, the principles of DD
domain channel modeling remain poorly studied. To address this issue, we
propose a systematic DD domain channel measurement and modeling methodology in
high-speed railway (HSR) scenarios. First, we design a DD domain channel
measurement method based on the long-term evolution for railway (LTE-R) system.
Second, for DD domain channel modeling, we investigate quasi-stationary
interval, statistical power modeling of multipath components, and particularly,
the quasi-invariant intervals of DD domain channel fading coefficients. Third,
via LTE-R measurements at 371 km/h, taking the quasi-stationary interval as the
decision criterion, we establish DD domain channel models under different
channel time-varying conditions in HSR scenarios. Fourth, the accuracy of
proposed DD domain channel models is validated via bit error rate comparison of
OTFS transmission. In addition, simulation verifies that in HSR scenario, the
quasi-invariant interval of DD domain channel fading coefficient is on
millisecond (ms) order of magnitude, which is much smaller than the
quasi-stationary interval length on $100$ ms order of magnitude. This study
could provide theoretical guidance for DD domain modeling in high-mobility
environments, supporting future DDMC and integrated sensing and communication
designs for 6G and beyond.

</details>


### [12] [Closed-Form Least-Squares Design of Fast-Convolution Based Variable-Bandwidth FIR Filters](https://arxiv.org/abs/2509.25931)
*Oksana Moryakova,Håkan Johansson*

Main category: eess.SP

TL;DR: 提出了一种基于快速卷积的可变带宽FIR滤波器的闭式最小二乘设计方法，通过频域采样和重叠保留法实现复杂度显著降低和带宽在线重配置。


<details>
  <summary>Details</summary>
Motivation: 为了解决可变带宽滤波器在实现复杂度和在线带宽重配置方面的挑战，需要一种既能提供闭式设计又能降低复杂度的解决方案。

Method: 采用频域设计和重叠保留法实现，考虑线性周期时变系统的时不变冲激响应集合，并在设计中引入适当的加权函数来减少最大近似误差能量。

Result: 相比现有方案，在给定性能下显著降低了复杂度，且可变带宽范围可以扩展而不增加复杂度，同时通过加权函数有效控制了近似误差。

Conclusion: 该方法为快速卷积可变带宽FIR滤波器提供了一种高效的闭式最小二乘设计框架，在复杂度和性能之间取得了良好平衡。

Abstract: This paper introduces a closed-form least-squares (LS) design approach for
fast-convolution (FC) based variable-bandwidth (VBW) finite-impulse-response
(FIR) filters. The proposed LS design utilizes frequency sampling and the VBW
filter frequency-domain implementation using the overlap-save (OLS) method,
that together offer significant savings in implementation and online bandwidth
reconfiguration complexities. Since combining frequency-domain design and OLS
implementation leads to a linear periodic time-varying (LPTV) behavior of the
VBW filter, a set of the corresponding time-invariant impulse responses is
considered in the proposed design. Through numerical examples, it is
demonstrated that the proposed approach enables not only closed-form design of
FC-based VBW filters with substantial complexity reductions compared to
existing solutions for a given performance, but also allows the variable
bandwidth range to be extended without any increase in complexity. Moreover, a
way of reducing the maximum approximation error energy over the whole set of
the time-invariant filters of the LPTV system is shown by introducing
appropriate weighting functions in the design.

</details>


### [13] [Joint Communications, Sensing, and Positioning in 6G Multi-Functional Satellite Systems: Survey and Open Challenges](https://arxiv.org/abs/2509.25937)
*Chandan Kumar Sheemar,Jorge Querol,Wali Ullah Khan,Prabhu Thiruvasagam,Sourabh Solanki,Idir Edjekouane,Alejandro Gonzalez-Garrido,Mohammed Al-Ansi,Carla E. Garcia,Symeon Chatzinotas*

Main category: eess.SP

TL;DR: 该调查论文提出了多功能卫星系统(MFSS)框架，将通信、感知和定位导航授时(PNT)服务集成到单一载荷中，通过资源共享和功能协同提高频谱效率、降低成本并增强服务多样性。


<details>
  <summary>Details</summary>
Motivation: 当前功能特定的卫星载荷架构在成本、频谱使用和可持续性方面难以满足6G网络对通信、感知和PNT服务的多样化需求。

Method: 提出统一分类法，涵盖联合通信与感知(JCAS)、联合通信与PNT(JCAP)、联合感知与PNT(JSAP)以及完全集成的JCSAP系统；回顾各领域最新进展，分析现有载荷架构，并概述协同、集成和联合设计策略。

Result: 通过将多种卫星能力统一在单一平台中，MFSS能够实现更高的频谱效率、降低发射质量和成本、改善能源使用并增强服务多样性。

Conclusion: MFSS框架有助于开发可持续和智能的非地面网络(NTNs)，为6G及未来空间时代做出贡献。

Abstract: Satellite systems are expected to be a cornerstone of sixth-generation (6G)
networks, providing ubiquitous coverage and supporting a wide range of services
across communications, sensing, and positioning, navigation, and timing (PNT).
Meeting these demands with current function-specific payload architectures is
challenging in terms of cost, spectral use, and sustainability. This survey
introduces the framework of multi-functional satellite systems (MFSS), which
integrate two or more of these core services into a single payload, enabling
resource sharing and functional synergy. A unified taxonomy is proposed,
covering joint communications and sensing (JCAS), joint communications and PNT
(JCAP), joint sensing and PNT (JSAP), and fully integrated joint
communications, sensing, and PNT (JCSAP) systems. The paper reviews the
state-of-the-art in each domain, examines existing payload architectures, and
outlines cooperative, integrated, and joint design strategies. Key challenges,
including waveform co-design, synchronization, interference mitigation, and
resource management, are discussed, along with potential solutions and future
research directions. By unifying diverse satellite capabilities within a single
platform, MFSS can achieve higher spectral efficiency, reduced launch mass and
cost, improved energy use, and enhanced service versatility, contributing to
the development of sustainable and intelligent non-terrestrial networks (NTNs)
for the 6G and beyond space era.

</details>


### [14] [Neural Network State-Space Estimators](https://arxiv.org/abs/2509.25959)
*Minxing Sun,Li Miao,Qingyu Shen,Yao Mao,Qiliang Bao*

Main category: eess.SP

TL;DR: 提出了一种无需目标状态空间模型的统一状态空间结构，将输入层激活和网络权重作为在线估计的隐状态，通过三种经典估计器实现神经网络模拟。


<details>
  <summary>Details</summary>
Motivation: 传统状态估计算法依赖预定义的状态空间模型，模型推导复杂且难以适应系统动态变化；神经网络估计器虽提供数据驱动替代方案，但很少融合经典估计理论且需要大量预计算训练集。

Method: 构建统一状态空间结构，将输入层激活和所有网络权重作为隐状态在线估计，使用扩展卡尔曼估计器、无迹卡尔曼估计器和粒子估计器三种经典估计器实例化非线性模型。

Result: 在三个代表性场景中与七种领先神经网络估计器对比，结果显示该方法不仅保持鲁棒学习能力，而且在精度上匹配或超过经典方法和预训练神经网络方法。

Conclusion: 提出的神经网络状态空间估计器克服了传统方法和现有神经网络估计器的局限性，实现了无需预定义模型和预训练的高性能状态估计。

Abstract: Classical state estimation algorithms rely on predefined target's state-space
model, which complicates model derivation and limits adaptability when system
dynamics change. Neural network based estimators offer a data-driven
alternative, but rarely fuse classical estimation theory into their structure
and demand large, pre-computed training sets. To overcome these limitations, we
propose a unified state-space structure without target's state-space model and
treats both the input-layer activations and all network weights as latent
states to be estimated online. We instantiate this nonlinear model with three
canonical estimators-the extended Kalman estimator, the unscented Kalman
estimator, and the particle estimator to simulate different neural network and
demonstrate its generality. We then benchmark our approach against seven
leading neural network estimators across three representative scenarios.
Results show that our neural network state-space estimators not only retain the
robust learning capability, but also match or exceed the accuracy of both
classical and pre-trained neural network methods. Code, data, and more result:
github.com/ShineMinxing/PaperNNSSE.git

</details>


### [15] [Performance Evaluation of eLoran Spatial ASF Corrections Based on Measured ASF Map](https://arxiv.org/abs/2509.26018)
*Jaewon Yu,Pyo-Woong Son*

Main category: eess.SP

TL;DR: 本文通过实测ASF地图评估了韩国eLoran系统中空间ASF校正方法的有效性，比较了三种校正场景：无校正、本地校正和广域校正。


<details>
  <summary>Details</summary>
Motivation: 分析不同ASF校正方法对eLoran定位性能的影响，为优化系统性能提供依据。

Method: 在相同仿真设置下评估三种校正场景：无校正(S0)、使用真实ASF值的本地校正(S1)、使用单一参考站值的广域校正(S2)。

Result: S1始终获得最低定位误差，S0误差最大且高误差区域广泛，S2仅在参考站附近有有限改进，随着距离和ASF空间梯度增加而性能下降。

Conclusion: 本地ASF校正显著提升eLoran定位性能，而广域校正仅具有局部效益。

Abstract: This paper analyzes the effectiveness of spatial ASF correction methods in
the Korean eLoran system using measured ASF maps. Three correction scenarios
were evaluated under identical simulation settings: no correction (S0), local
correction using true ASF values (S1), and wide-area correction using a single
reference station value (S2). Simulation results show that S1 consistently
achieved the lowest positioning errors, while S0 exhibited the largest errors
with extensive high-error regions. S2 provided limited improvements near the
reference station but degraded with increasing distance and ASF spatial
gradients. The findings highlight that local ASF correction significantly
improves eLoran positioning performance, whereas wide-area correction has only
localized benefits.

</details>


### [16] [Path-Based Correlation Analysis of Meteorological Factors and eLoran Signal Delay Variations](https://arxiv.org/abs/2509.26020)
*Junwoo Song,Pyo-woong Son*

Main category: eess.SP

TL;DR: 分析eLoran信号传播延迟与气象因素的相关性，研究沿信号路径不同点的传播延迟时间变化与气象条件的关系。


<details>
  <summary>Details</summary>
Motivation: eLoran系统具有高场强特性，在GNSS不可用时仍能可靠运行，但其地波传播方式使传播延迟易受地表条件（包括地形和气象变化）影响，需要研究气象因素对传播延迟的影响。

Method: 分析eLoran信号传播路径上多个点的传播延迟时间变化，研究这些变化与气象因素之间的相关性。

Result: 研究发现eLoran信号的传播延迟确实受到气象因素的影响，沿信号路径不同点的延迟变化与气象条件存在相关性。

Conclusion: 气象因素是影响eLoran信号传播延迟的重要变量，需要在eLoran系统应用中考虑气象条件对传播延迟的影响以提高定位精度。

Abstract: Unlike GNSS, which is vulnerable to jamming and spoofing due to its
inherently weak received power, eLoran exhibits robustness owing to its high
field strength. Therefore, the eLoran system can maintain reliable operation
even in scenarios where GNSS becomes unavailable. However, since eLoran signals
propagate through ground waves, the propagation delay is susceptible to changes
in surface conditions, including both terrain and meteorological variations.
This study aims to analyze the correlation between the temporal variations in
eLoran signal propagation delay and meteorological factors at various points
along the signal path.

</details>


### [17] [Enhancing Connectivity for Emergency Vehicles Through UAV Trajectory and Resource Allocation Optimization](https://arxiv.org/abs/2509.26067)
*S. Fatemeh Bozorgi,S. Mohammad Razavizadeh,Mohsen Rezaee*

Main category: eess.SP

TL;DR: 该论文提出了一种无人机辅助的车联网通信系统，通过联合优化无人机轨迹规划和动态带宽分配，在满足应急车辆最低瞬时数据率需求的同时，最大化普通车辆的平均数据率。


<details>
  <summary>Details</summary>
Motivation: 应急车辆（如救护车、消防车）在复杂交通和环境条件下需要可靠的通信支持，而传统车联网系统难以同时满足应急车辆和普通车辆的不同服务质量需求。

Method: 采用联合优化方法，将问题分解为带宽分配和无人机轨迹设计两个子问题，使用迭代优化和连续凸近似(SCA)方法求解非凸优化问题。

Result: 数值结果表明，所提出的解决方案在满足服务需求方面优于基准方法，能够有效平衡应急车辆和普通车辆的通信需求。

Conclusion: 无人机辅助的车联网通信系统通过智能轨迹规划和资源分配，能够为应急车辆提供可靠的通信保障，同时优化普通车辆的通信性能。

Abstract: Effective communication for emergency vehicles - such as ambulances and fire
trucks - is essential to support their operations in various traffic and
environmental conditions. In this context, this paper investigates a vehicular
communication system assisted by an Unmanned Aerial Vehicle (UAV), which
adjusts its trajectory and resource allocation according to communication
needs. The system classifies vehicles into two groups to address their varying
service requirements: emergency vehicles, which require a minimum instantaneous
data rate to access critical information timely, and normal vehicles. To
support both categories effectively, this paper proposes a joint optimization
approach that coordinates UAV trajectory planning and Dynamic Bandwidth
Allocation (DBA). The objective is to maximize the minimum average data rate
for normal vehicles while ensuring that emergency vehicles maintain an
instantaneous rate above a predefined threshold. This approach takes into
account some system constraints, including UAV propulsion power consumption,
mobility limitations, and backhaul capacity. To tackle the resulting non-convex
problem, an iterative optimization method is employed, where the original
problem is decomposed into two subproblems: bandwidth allocation and UAV
trajectory design. In each iteration, the trajectory subproblem is solved using
the Successive Convex Approximation (SCA) method. Numerical results confirm
that the proposed solution achieves superior performance in meeting service
requirements compared to baseline methods.

</details>


### [18] [Secrecy-Driven Beamforming for Multi-User Integrated Sensing and Communication](https://arxiv.org/abs/2509.26249)
*Ali Khandan Boroujeni,Hyeon Seok Rou,Ghazal Bagheri,Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,Stefan Köpsell,Rafael F. Schaefer*

Main category: eess.SP

TL;DR: 提出一个安全的多用户ISAC框架，通过联合优化波束成形和人工噪声来最大化保密率，同时满足感知和通信约束。


<details>
  <summary>Details</summary>
Motivation: 在多用户系统中同时实现安全通信和精确感知，需要解决传统人工噪声策略可能干扰合法用户的问题，并提升系统的整体性能。

Method: 采用基于非齐次复数二次变换的加速分数规划方法，将问题分解为波束成形和人工噪声优化的可处理子问题。

Result: 仿真结果显示在保密率、通信可靠性和感知精度方面均获得显著增益，证明了所提框架的有效性和可扩展性。

Conclusion: 所提出的ISAC框架能够有效平衡安全通信和精确感知的需求，通过创新的优化方法实现了系统性能的全面提升。

Abstract: This paper proposes a secure integrated sensing and communications (ISAC)
framework for multi-user systems with multiple communication users (CUs) and
adversarial targets, where the design problem is formulated to maximize secrecy
rate under joint sensing and communication constraints. An efficient solution
is presented based on an accelerated fractional programming method using a
non-homogeneous complex quadratic transform (QT), which decomposes the problem
into tractable subproblems for beamforming and artificial noise (AN)
optimization. Unlike conventional artificial noise strategies, the proposed
approach also exploits AN to enhance sensing while avoiding interference with
legitimate users. Simulation results show significant gains in secrecy rate,
communication reliability, and sensing accuracy, confirming the effectiveness
and scalability of the proposed framework.

</details>


### [19] [FinGAN: An Interpretable RSS Generation Network for Scalable Fingerprint Localization](https://arxiv.org/abs/2509.26286)
*Jiaming Zhang,Jiajun He,Jie Zhang,Okan Yurduseven*

Main category: eess.SP

TL;DR: FinGAN是一种用于生成RSS指纹数据的生成对抗网络，能够从未测量的参考点直接生成RSS数据，通过最大化生成数据与参考点之间的互信息来学习潜在关系。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型要么依赖已知参考点位置，要么依赖预定义先验，无法有效生成未测量位置的RSS数据。

Method: FinGAN通过最大化生成RSS数据与参考点之间的互信息，端到端地从参考点生成RSS数据，无需预定义先验。

Result: 定量和定性评估显示，FinGAN生成的合成RSS数据与真实数据高度一致，定位性能与完整真实数据集相当，在三个办公环境开源数据集上表现一致。

Conclusion: FinGAN能够准确生成未测量参考点的RSS数据，在不同场景下保持一致的性能，为RSS指纹数据集扩展提供了有效解决方案。

Abstract: This work introduces FinGAN, a robust received signal strength (RSS) data
generator designed to expand RSS fingerprint datasets. Compared to existing
generative adversarial models that either rely on known reference positions
(RPs) or depend on predefined priors, FinGAN learns the latent information
between RPs and RSS values by maximizing the mutual information between the
generated RSS data and the RPs, enabling an end-to-end RSS generation directly
from RPs. This allows us to accurately generate RSS data for previously
unmeasured RPs. Both quantitative and qualitative evaluations demonstrate that
FinGAN produces synthetic RSS data closely aligned with real RSS sample
collected from the on-site experiment, preserving localization performance
comparable to that achieved with complete real-world datasets. To further
validate its generalizability, FinGAN is also trained and evaluated on
open-source datasets from three typical office environments,and the results
demonstrate consistent performance across different scenarios.

</details>


### [20] [Ultra-Reliable Risk-Aggregated Sum Rate Maximization via Model-Aided Deep Learning](https://arxiv.org/abs/2509.26311)
*Hassaan Hashmi,Spyridon Pougkakiotis,Dionysis Kalogerias*

Main category: eess.SP

TL;DR: 提出了一种基于条件风险价值(CVaR)的鲁棒预编码方法，使用展开图神经网络(αRGNN)来最大化MISO下行链路中用户速率的尾部性能，显著降低速率波动并消除深度衰落。


<details>
  <summary>Details</summary>
Motivation: 解决多输入单输出(MISO)下行无线网络中用户速率可靠性的问题，特别是在信道衰落不确定性下的速率可靠性保障。

Method: 引入风险聚合的加权和速率最大化问题，建立WMMSE类等价关系，设计基于展开图神经网络的策略函数逼近(αRGNN)，训练以最大化由不利信道实现导致的尾部(CVaR)速率。

Result: 训练后的αRGNN完全消除了每个用户的深度速率衰落，显著且最优地降低了统计用户速率变异性，同时保持了足够的遍历性能。

Conclusion: 提出的αRGNN方法有效解决了无线网络中用户速率可靠性问题，通过风险感知的预编码策略实现了对不利信道条件的鲁棒性。

Abstract: We consider the problem of maximizing weighted sum rate in a multiple-input
single-output (MISO) downlink wireless network with emphasis on user rate
reliability. We introduce a novel risk-aggregated formulation of the complex
WSR maximization problem, which utilizes the Conditional Value-at-Risk (CVaR)
as a functional for enforcing rate (ultra)-reliability over channel fading
uncertainty/risk. We establish a WMMSE-like equivalence between the proposed
precoding problem and a weighted risk-averse MSE problem, enabling us to design
a tailored unfolded graph neural network (GNN) policy function approximation
(PFA), named {\alpha}-Robust Graph Neural Network ({\alpha}RGNN), trained to
maximize lower-tail (CVaR) rates resulting from adverse wireless channel
realizations (e.g., deep fading, attenuation). We empirically demonstrate that
a trained {\alpha}RGNN fully eliminates per user deep rate fades, and
substantially and optimally reduces statistical user rate variability while
retaining adequate ergodic performance.

</details>


### [21] [Transmitter-Side Beyond-Diagonal RIS-Enabled Integrated Sensing and Communications](https://arxiv.org/abs/2509.26333)
*Kexin Chen,Yijie Mao,Wonjae Shin*

Main category: eess.SP

TL;DR: 本文提出了一种在发射端集成BD-RIS的ISAC框架，通过联合优化主动波束成形和BD-RIS散射矩阵，同时提升感知和通信性能，并显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: BD-RIS相比传统对角RIS能提供更先进的电磁波传播控制，有望提升6G无线网络的性能。本文旨在探索发射端BD-RIS在ISAC中的应用潜力，同时减少对大规模全数字射频链的需求。

Method: 提出一种低复杂度迭代算法，将高度耦合的优化问题分解为主动波束成形和散射矩阵子问题，通过一系列可处理的投影问题及其闭式解来高效求解。

Result: 数值结果表明，发射端BD-RIS辅助的ISAC相比传统对角RIS辅助的ISAC在感知和通信性能上均有显著提升，且所提算法在增强双功能性能的同时大幅降低了计算复杂度。

Conclusion: 发射端BD-RIS为ISAC系统提供了有前景的解决方案，能够同时优化感知和通信性能，并通过高效算法实现实际部署的可行性。

Abstract: Beyond diagonal reconfigurable intelligent surfaces (BD-RIS) have emerged as
a promising technology for 6G wireless networks, offering more advanced control
over electromagnetic wave propagation than conventional diagonal RIS. This
paper proposes a novel integrated sensing and communication (ISAC) framework
that incorporates BD-RIS at the transmitter. This not only opens the door to
enhanced sensing and communication performance, but also alleviates the need
for large-scale fully digital radio frequency (RF) chains at the transmitter.
Based on the proposed system model, we formulate a normalized weighted
optimization problem to jointly design the active beamforming and the BD-RIS
scattering matrix with the aim of jointly minimizing the trace of the
Cram\'er-Rao bound (CRB) for sensing targets and maximizing the sum rate (SR)
for communication users. To address this highly coupled optimization problem,
we propose a novel and low-complexity iterative algorithm that efficiently
solves the active beamforming and scattering matrix subproblems by transforming
each into a series of tractable projection problems with closed-form solutions.
Numerical results show the appealing capability of the transmitter-side
BD-RIS-aided ISAC over conventional diagonal RIS-aided ISAC in enhancing both
sensing and communication performance. Moreover, compared to the classic
iterative algorithm, the proposed algorithm offers enhanced dual-functional
performance while significantly reducing the computational complexity.

</details>


### [22] [A Physics-Informed Multi-Source Domain Adaptation Framework for Label-Free Post-Earthquake Damage Assessment](https://arxiv.org/abs/2509.26356)
*Yifeng Zhang,Xiao Liang*

Main category: eess.SP

TL;DR: 提出了一种基于物理信息的多源域自适应框架，用于无需损伤标签预测目标建筑的地震后结构损伤，通过整合实际损伤数据和数值建模数据来解决标注数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 传统监督学习方法依赖大量标注数据，但受损结构的标注数据难以获取，限制了地震后结构损伤评估的效率和准确性。

Method: 采用三步骤框架：1) 分析各域关键物理相似性形成权重矩阵；2) 提取多源域和目标域特征，使用分类器和判别器分别确保损伤敏感性和域不变性；3) 在对抗训练中应用关键参数矩阵优化各源域特征贡献。

Result: 该框架为标注数据稀缺场景下的结构损伤评估提供了稳健解决方案，显著提升了地震后损伤评估能力。

Conclusion: 提出的物理信息多源域自适应框架有效解决了地震后结构损伤评估中标注数据不足的问题，推动了智能损伤评估技术的发展。

Abstract: Efficient and intelligent assessment of post-earthquake structural damage is
critical for rapid disaster response. While data-driven approaches have shown
promise, traditional supervised learning methods rely on extensive labeled
datasets, which are often impractical to obtain for damaged structures. To
address this limitation, we propose a physics-informed multi-source domain
adaptation framework to predict post-earthquake structural damage for a target
building without requiring damage labels. The multi-source domain integrates
actual damage data and numerical modeling data from buildings similar to the
target structure. The framework operates through three key steps. First, the
similarity of key physics from each domain are analyzed to form a weight
matrix, which enhances domain differentiation. Second, features from the
multi-source and target domains are extracted and fed into a classifier and a
discriminator. The classifier ensures that the features are damage-sensitive
and accurately assign damage states, while the discriminator enforces that the
features remain domain-invariant. Finally, the key parameters matrix is applied
as weights during adversarial training to optimize the contribution of features
from each source domain. The proposed framework provides a robust solution for
assessing structural damage in scenarios where labeled data is scarce,
significantly advancing the capabilities of post-earthquake damage evaluation.

</details>


### [23] [A solution to the mystery of the sub-harmonic series and to the combination tone via a linear mathematical model of the cochlea](https://arxiv.org/abs/2509.26395)
*Ugo Boscain,Xiangyu Ma,Dario Prandi,Giuseppina Turco*

Main category: eess.SP

TL;DR: 该论文通过将耳蜗建模为一组振动弦，研究了听觉信息处理机制，揭示了次谐波序列的出现以及组合音的产生原理。


<details>
  <summary>Details</summary>
Motivation: 研究耳蜗如何将声音信息传递给听觉皮层，探索听觉感知的物理基础，特别是解释小调和弦的协和性以及组合音现象。

Method: 使用简单的线性耳蜗模型，将耳蜗视为一组振动弦，分析所有振荡模式，并考虑能量的非线性特性。

Result: 发现了次谐波序列的出现，这解释了16世纪假设的小调和弦协和性原理；同时展示了能量非线性如何导致组合音（Tartini第三音）的产生。

Conclusion: 该研究为长期争议的听觉现象提供了新的物理解释，表明耳蜗的弦振动模型能够有效解释次谐波感知和组合音产生机制。

Abstract: In this paper, we study a simple linear model of the cochlea as a set of
vibrating strings. We make hypothesis that the information sent to the auditory
cortex is the energy stored in the strings and consider all oscillation modes
of the strings. We show the emergence of the sub-harmonic series whose
existence was hypothesized in the XVI century to explain the consonance of the
minor chord. We additionally show how the nonlinearity of the energy can be
used to study the emergence of the combination tone (Tartini's third sound)
shedding new light on this long debated subject.

</details>


### [24] [Indoor/Outdoor Spectrum Sharing Enabled by GNSS-based Classifiers](https://arxiv.org/abs/2509.26500)
*Hossein Nasiri,Muhammad Iqbal Rochman,Monisha Ghosh*

Main category: eess.SP

TL;DR: 利用GNSS信号进行室内/室外分类，通过阈值方法和机器学习技术，在多种地理位置的扩展数据集上验证，结果显示GNSS方法比仅用Wi-Fi数据更准确，特别是在陌生位置，多模态数据融合能进一步提高分类精度。


<details>
  <summary>Details</summary>
Motivation: 中频段(1-10 GHz)在联邦和商业应用中的需求增长，特别是商业室内用例如工厂自动化，促使频谱共享新方法：联邦户外用户使用的频段可被商业室内用户重用。但缺乏可靠的自动室内/室外分类方法，需要其他机制如强制室内AP集成天线、非电池供电等。

Method: 利用GNSS信号进行室内/室外分类，开发了基于阈值的技术和机器学习方法，并在来自不同地理位置的扩展数据集上进行评估。

Result: GNSS方法单独使用比仅依赖无线(Wi-Fi)数据的方法更准确，特别是在不熟悉的位置。GNSS数据与Wi-Fi信息融合能进一步提高分类精度。

Conclusion: GNSS信号为环境感知提供了强大且区分性强的特征，基于GNSS的室内/室外分类方法能有效解决频谱共享中的挑战，实现自动发射功率调整而不干扰现有用户。

Abstract: The desirability of the mid-band frequency range (1 - 10 GHz) for federal and
commercial applications, combined with the growing applications for commercial
indoor use-cases, such as factory automation, opens up a new approach to
spectrum sharing: the same frequency bands used outdoors by federal incumbents
can be reused by commercial indoor users. A recent example of such sharing,
between commercial systems, is the 6 GHz band (5.925 - 7.125 GHz) where
unlicensed, low-power-indoor (LPI) users share the band with outdoor
incumbents, primarily fixed microwave links. However, to date, there exist no
reliable, automatic means of determining whether a device is indoors or
outdoors, necessitating the use of other mechanisms such as mandating indoor
access points (APs) to have integrated antennas and not be battery powered, and
reducing transmit power of client devices which may be outdoors. An accurate
indoor/outdoor (I/O) classification addresses these challenges, enabling
automatic transmit power adjustments without interfering with incumbents. To
this end, we leverage the Global Navigation Satellite System (GNSS) signals for
I/O classification. GNSS signals, designed inherently for outdoor reception and
highly susceptible to indoor attenuation and blocking, provide a robust and
distinguishing feature for environmental sensing. We develop various
methodologies, including threshold-based techniques and machine learning
approaches and evaluate them using an expanded dataset gathered from diverse
geographical locations. Our results demonstrate that GNSS-based methods alone
can achieve greater accuracy than approaches relying solely on wireless (Wi-Fi)
data, particularly in unfamiliar locations. Furthermore, the integration of
GNSS data with Wi-Fi information leads to improved classification accuracy,
showcasing the significant benefits of multi-modal data fusion.

</details>


### [25] [Neural Network-Based Single-Carrier Joint Communication and Sensing: Loss Design, Constellation Shaping and Precoding](https://arxiv.org/abs/2509.26508)
*Charlotte Muth,Benedikt Geiger,Daniel Gil Gaviria,Laurent Schmalen*

Main category: eess.SP

TL;DR: 该论文研究了高阶调制格式对单载波联合通信感知系统性能的影响，使用神经网络实现各组件，比较几何整形调制与传统QAM，并展示了基于上界的训练方法能提升系统在变化SNR条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 研究高阶调制格式如何影响联合通信感知系统的感知性能，探索神经网络在优化系统组件中的作用，并解决在变化SNR条件下训练神经网络的问题。

Method: 使用神经网络实现波束成形器、调制器、目标检测器、到达角估计器和通信解映射器等组件，采用基于Cramér-Rao界和互信息的上界来解耦损失函数与SNR值及感知快照数的依赖关系。

Result: 神经网络感知在低SNR下优于传统算法，多快照感知显著减小了传统调制与整形调制之间的感知性能差距，系统可扩展到多用户MIMO以提升空间效率。

Conclusion: 基于估计上界的神经网络训练方法对于在变化SNR条件下部署训练解决方案具有重要意义，能够有效提升联合通信感知系统的整体性能。

Abstract: We investigate the impact of higher-order modulation formats on the sensing
performance of single-carrier joint communication and sensing (JCAS) systems.
Several separate components such as a beamformer, a modulator, a target
detector, an angle of arrival (AoA) estimator and a communication demapper are
implemented as trainable neural networks (NNs). We compare geometrically shaped
modulation formats to a classical quadrature amplitude modulation (QAM) scheme.
We assess the influence of multi-snapshot sensing and varying signal-to-noise
ratio (SNR) on the overall performance of the autoencoder-based system. To
improve the training behavior of the system, we decouple the loss functions
from the respective SNR values and the number of sensing snapshots, using upper
bounds of the sensing and communication performance, namely the Cram\'er-Rao
bound for AoA estimation and the mutual information for communication. The
NN-based sensing outperforms classical algorithms, such as a Neyman-Pearson
based power detector for object detection and ESPRIT for AoA estimation for
both the trained constellations and QAM at low SNRs. We show that the gap in
sensing performance between classical and shaped modulation formats can be
significantly reduced through multi-snapshot sensing. Lastly, we demonstrate
system extension to multi-user multiple-input multiple-output to address the
improvement of spatial efficiency when servicing multiple user equipments. Our
contribution emphasizes the importance of estimation bounds for training neural
networks, especially when the trained solutions are deployed in varying SNR
conditions.

</details>


### [26] [Secure ISAC with Fluid Antenna Systems: Joint Precoding and Port Selection](https://arxiv.org/abs/2509.26572)
*Abdelhamid Salem,Hao Xu,Kai-Kit Wong,Chan-Byoung Chae,Yangyang Zhang*

Main category: eess.SP

TL;DR: 提出一种基于流体天线系统的集成感知与通信安全增强框架，通过联合预编码和端口选择策略最大化保密率并保证可靠雷达感知


<details>
  <summary>Details</summary>
Motivation: 在集成感知与通信系统中增强物理层安全性，利用流体天线系统的可重构性来同时优化通信保密性和感知性能

Method: 采用联合预编码和端口选择策略，使用分数规划结合逐次凸逼近的迭代算法，并开发基于迫零预编码的低复杂度方案

Result: 仿真结果显示相比传统基线方法，在保密性能和感知精度方面均有显著提升，适用于多种流体天线端口、用户负载和感知目标场景

Conclusion: 流体天线几何优化对于实现下一代无线网络的安全高效联合通信感知至关重要

Abstract: This paper presents a novel framework for enhancing physical-layer security
in integrated sensing and communication (ISAC) systems by leveraging the
reconfigurability of fluid antenna systems (FAS). We propose a joint precoding
and port selection (JPPS) strategy that maximizes the sum secrecy rate while
simultaneously ensuring reliable radar sensing. The problem is formulated using
fractional programming (FP) and solved through an iterative algorithm that
integrates FP transformations with successive convex approximation (SCA). To
reduce computational complexity, we further develop low-complexity schemes
based on zero-forcing (ZF) precoding, combined with greedy port selection and
trace-inverse minimization. Simulation results demonstrate substantial
improvements in both secrecy performance and sensing accuracy compared to
conventional baselines, across a wide range of FAS ports, user loads, and
sensing targets. These findings highlight the critical importance of FAS
geometry optimization in enabling secure and efficient joint
communication-sensing for next-generation wireless networks.

</details>


### [27] [Statistical Inference Framework for Extended Target Detection in mmWave Automotive Radar](https://arxiv.org/abs/2509.26573)
*Vinay Kulkarni,V. V. Reddy,Neha Maheshwari*

Main category: eess.SP

TL;DR: 提出了一种基于Range-Doppler分割框架的毫米波雷达扩展目标检测方法，通过统计建模和偏度测试统计量来保留目标的空间散射结构，提高了汽车雷达检测精度。


<details>
  <summary>Details</summary>
Motivation: 传统CFAR检测算法将扩展目标的多个散射点视为独立检测，丢弃了目标固有的空间散射结构信息。

Method: 使用Range-Doppler分割框架封装汽车典型散射轮廓，通过MLE和Gibbs MCMC进行统计建模，引入基于偏度的测试统计量进行二元假设分类，并结合IoU和基于峰值响应的分割中心化优化检测流程。

Result: 在仿真和真实数据集上的广泛评估表明，该方法有效提高了检测精度，适用于汽车雷达应用。

Conclusion: 提出的方法能够有效保留扩展目标的空间散射结构，显著改善汽车雷达检测性能。

Abstract: Millimeter wave (mmWave) radar systems, owing to their large bandwidth,
provide fine range resolution that enables the observation of multiple
scatterers originating from a single automotive target commonly referred to as
an extended target. Conventional CFAR-based detection algorithms typically
treat these scatterers as independent detections, thereby discarding the
spatial scattering structure intrinsic to the target. To preserve this
scattering spread, this paper proposes a Range-Doppler (RD) segment framework
designed to encapsulate the typical scattering profile of an automobile. The
statistical characterization of the segment is performed using Maximum
Likelihood Estimation (MLE) and posterior density modeling facilitated through
Gibbs Markov Chain Monte Carlo (MCMC) sampling. A skewness-based test
statistic, derived from the estimated statistical model, is introduced for
binary hypothesis classification of extended targets. Additionally, the paper
presents a detection pipeline that incorporates Intersection over Union (IoU)
and segment centering based on peak response, optimized to work within a single
dwell. Extensive evaluations using both simulated and real-world datasets
demonstrate the effectiveness of the proposed approach, underscoring its
suitability for automotive radar applications through improved detection
accuracy.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [28] [An Analysis of Joint Nonlinear Spatial Filtering for Spatial Aliasing Reduction](https://arxiv.org/abs/2509.25982)
*Alina Mannanova,Jakob Kienegger,Timo Gerkmann*

Main category: eess.AS

TL;DR: 非线性深度神经网络在语音增强中比传统线性空间滤波器更有效处理空间混叠问题，特别是在麦克风间距较大的阵列中。


<details>
  <summary>Details</summary>
Motivation: 传统线性空间滤波器受限于麦克风阵列的物理尺寸和通道数，在大麦克风间距和高频情况下会出现空间混叠，导致非目标方向信号的增强。

Method: 使用非线性深度神经网络进行联合空间-频谱处理，替代传统的线性波束形成器。

Result: 联合空间和时频谱处理比传统单独进行空间处理或时频谱滤波的方法对空间混叠更鲁棒。

Conclusion: 深度非线性网络在多通道语音增强中具有优势，特别是在处理空间混叠、非高斯噪声和多个说话者方面，尤其适用于麦克风间距较大的阵列。

Abstract: The performance of traditional linear spatial filters for speech enhancement
is constrained by the physical size and number of channels of microphone
arrays. For instance, for large microphone distances and high frequencies,
spatial aliasing may occur, leading to unwanted enhancement of signals from
non-target directions. Recently, it has been proposed to replace linear
beamformers by nonlinear deep neural networks for joint spatial-spectral
processing. While it has been shown that such approaches result in higher
performance in terms of instrumental quality metrics, in this work we highlight
their ability to efficiently handle spatial aliasing. In particular, we show
that joint spatial and tempo-spectral processing is more robust to spatial
aliasing than traditional approaches that perform spatial processing alone or
separately with tempo-spectral filtering. The results provide another strong
motivation for using deep nonlinear networks in multichannel speech
enhancement, beyond their known benefits in managing non-Gaussian noise and
multiple speakers, especially when microphone arrays with rather large
microphone distances are used.

</details>


### [29] [Zimtohrli: An Efficient Psychoacoustic Audio Similarity Metric](https://arxiv.org/abs/2509.26133)
*Jyrki Alakuijala,Martin Bruse,Sami Boukortt,Jozef Marus Coldenhoff,Milos Cernak*

Main category: eess.AS

TL;DR: Zimtohrli是一种新型的全参考音频相似度度量方法，结合了耳蜗频率分辨率的伽马通滤波器组和模拟人耳鼓膜响应的非线性谐振器模型，使用改进的DTW和NSIM算法进行感知映射频谱图比较，在性能和计算效率之间取得了良好平衡。


<details>
  <summary>Details</summary>
Motivation: 在深度学习模型计算密集和专有标准主导的时代，需要一种可解释、基于心理声学的度量方法，在性能与实用性之间取得平衡。

Method: 使用128-bin伽马通滤波器组前端模拟耳蜗频率分辨率，结合非线性谐振器模型模拟人耳鼓膜响应，通过改进的DTW和NSIM算法比较感知映射频谱图。

Result: Zimtohrli在性能上优于开源基准ViSQOL，并显著缩小了与最新商业POLQA度量的性能差距。

Conclusion: Zimtohrli在感知相关性和计算效率之间提供了令人信服的平衡，成为现代音频工程应用的有力替代方案。

Abstract: This paper introduces Zimtohrli, a novel, full-reference audio similarity
metric designed for efficient and perceptually accurate quality assessment. In
an era dominated by computationally intensive deep learning models and
proprietary legacy standards, there is a pressing need for an interpretable,
psychoacoustically-grounded metric that balances performance with practicality.
Zimtohrli addresses this gap by combining a 128-bin gammatone filterbank
front-end, which models the frequency resolution of the cochlea, with a unique
non-linear resonator model that mimics the human eardrum's response to acoustic
stimuli. Similarity is computed by comparing perceptually-mapped spectrograms
using modified Dynamic Time Warping (DTW) and Neurogram Similarity Index
Measure (NSIM) algorithms, which incorporate novel non-linearities to better
align with human judgment. Zimtohrli achieves superior performance to the
baseline open-source ViSQOL metric, and significantly narrows the performance
gap with the latest commercial POLQA metric. It offers a compelling balance of
perceptual relevance and computational efficiency, positioning it as a strong
alternative for modern audio engineering applications, from codec development
to the evaluation of generative audio systems.

</details>


### [30] [TAU: A Benchmark for Cultural Sound Understanding Beyond Semantics](https://arxiv.org/abs/2509.26329)
*Yi-Cheng Lin,Yu-Hua Chen,Jia-Kai Dong,Yueh-Hsuan Huang,Szu-Chi Chen,Yu-Chen Chen,Chih-Yao Chen,Yu-Jung Lin,Yu-Ling Chen,Zih-Yu Chen,I-Ning Tsai,Hsiu-Hsuan Wang,Ho-Lam Chung,Ke-Han Lu,Hung-yi Lee*

Main category: eess.AS

TL;DR: TAU是一个针对台湾日常声音的基准测试，揭示了当前音频-语言模型在识别文化特定声音方面的局限性，这些声音本地人能立即识别但外部模型难以理解。


<details>
  <summary>Details</summary>
Motivation: 现有音频-语言模型评估主要关注语音或全球通用声音，忽视了文化独特的声音线索，这引发了对模型能否泛化到本地化、非语义音频的重要问题。

Method: 通过结合精选来源、人工编辑和LLM辅助问题生成的流程，构建了包含702个音频片段和1,794个多项选择题的TAU基准测试，这些题目无法仅通过文字转录解决。

Result: 实验显示，包括Gemini 2.5和Qwen2-Audio在内的最先进音频-语言模型表现远低于本地人类水平。

Conclusion: TAU证明了需要本地化基准测试来揭示文化盲点，指导更公平的多模态评估，并确保模型服务于全球主流之外的社区。

Abstract: Large audio-language models are advancing rapidly, yet most evaluations
emphasize speech or globally sourced sounds, overlooking culturally distinctive
cues. This gap raises a critical question: can current models generalize to
localized, non-semantic audio that communities instantly recognize but
outsiders do not? To address this, we present TAU (Taiwan Audio Understanding),
a benchmark of everyday Taiwanese "soundmarks." TAU is built through a pipeline
combining curated sources, human editing, and LLM-assisted question generation,
producing 702 clips and 1,794 multiple-choice items that cannot be solved by
transcripts alone. Experiments show that state-of-the-art LALMs, including
Gemini 2.5 and Qwen2-Audio, perform far below local humans. TAU demonstrates
the need for localized benchmarks to reveal cultural blind spots, guide more
equitable multimodal evaluation, and ensure models serve communities beyond the
global mainstream.

</details>


### [31] [Game-Time: Evaluating Temporal Dynamics in Spoken Language Models](https://arxiv.org/abs/2509.26388)
*Kai-Wei Chang,En-Pei Hu,Chun-Yi Kuan,Wenze Ren,Wei-Chih Chen,Guan-Ting Lin,Yu Tsao,Shao-Hua Sun,Hung-yi Lee,James Glass*

Main category: eess.AS

TL;DR: 提出了Game-Time基准测试框架，用于评估对话式口语语言模型在时间动态能力（如时间管理、节奏控制和同时说话）方面的表现。


<details>
  <summary>Details</summary>
Motivation: 当前对话式口语语言模型在时间动态能力方面存在关键但未被评估的挑战，这影响了对话的流畅性。

Method: 设计Game-Time基准测试，包含基础指令跟随任务和具有时间约束的高级任务（如节奏遵守和同步响应），对多种SLM架构进行评估。

Result: 最先进模型能较好处理基础任务，但许多当代系统在基础指令跟随方面仍有困难；几乎所有模型在时间约束下性能显著下降，暴露了时间意识和全双工交互方面的持续弱点。

Conclusion: Game-Time基准为引导未来研究开发更具时间意识的对话AI提供了基础。

Abstract: Conversational Spoken Language Models (SLMs) are emerging as a promising
paradigm for real-time speech interaction. However, their capacity of temporal
dynamics, including the ability to manage timing, tempo and simultaneous
speaking, remains a critical and unevaluated challenge for conversational
fluency. To address this gap, we introduce the Game-Time Benchmark, a framework
to systematically assess these temporal capabilities. Inspired by how humans
learn a language through language activities, Game-Time consists of basic
instruction-following tasks and advanced tasks with temporal constraints, such
as tempo adherence and synchronized responses. Our evaluation of diverse SLM
architectures reveals a clear performance disparity: while state-of-the-art
models handle basic tasks well, many contemporary systems still struggle with
fundamental instruction-following. More critically, nearly all models degrade
substantially under temporal constraints, exposing persistent weaknesses in
time awareness and full-duplex interaction. The Game-Time Benchmark provides a
foundation for guiding future research toward more temporally-aware
conversational AI. Demos and datasets are available on our project website
https://ga642381.github.io/Game-Time.

</details>


### [32] [IR-UWB Radar-Based Contactless Silent Speech Recognition with Attention-Enhanced Temporal Convolutional Networks](https://arxiv.org/abs/2509.26409)
*Sunghwa Lee,Jaewon Yu*

Main category: eess.AS

TL;DR: 本文提出了一种基于注意力增强时序卷积网络的非接触式IR-UWB雷达无声语音识别方法，通过端到端学习直接从雷达信号中学习判别性表示，在50词识别任务中达到91.1%的准确率。


<details>
  <summary>Details</summary>
Motivation: 无声语音识别技术旨在从非声学语音相关生物信号中识别语音内容，传统基于手工特征的方法性能有限，需要更有效的深度学习方法直接从原始信号中学习特征。

Method: 采用注意力增强的时序卷积网络架构，结合时序卷积、自注意力机制和压缩激励机制来捕捉发音模式，直接从最小处理的雷达信号中学习判别性表示。

Result: 在50词识别任务上，使用留一会话交叉验证，该方法平均测试准确率达到91.1%，相比传统手工特征方法的74.0%有显著提升。

Conclusion: 端到端学习方法显著提升了无声语音识别性能，注意力增强的时序卷积网络能够有效捕捉发音模式，为基于雷达的无声语音识别提供了有效解决方案。

Abstract: Silent speech recognition (SSR) is a technology that recognizes speech
content from non-acoustic speech-related biosignals. This paper utilizes an
attention-enhanced temporal convolutional network architecture for contactless
IR-UWB radar-based SSR, leveraging deep learning to learn discriminative
representations directly from minimally processed radar signals. The
architecture integrates temporal convolutions with self-attention and
squeeze-and-excitation mechanisms to capture articulatory patterns. Evaluated
on a 50-word recognition task using leave-one-session-out cross-validation, our
approach achieves an average test accuracy of 91.1\% compared to 74.0\% for the
conventional hand-crafted feature method, demonstrating significant improvement
through end-to-end learning.

</details>


### [33] [On Deepfake Voice Detection -- It's All in the Presentation](https://arxiv.org/abs/2509.26471)
*Héctor Delgado,Giorgio Ramondetti,Emanuele Dalmasso,Gennady Karvitsky,Daniele Colibro,Haydar Talib*

Main category: eess.AS

TL;DR: 本文提出了一种新的音频深度伪造检测框架，强调通过改进数据集和研究方法来提高真实场景下的检测效果，而不是单纯依赖更大的模型。


<details>
  <summary>Details</summary>
Motivation: 当前恶意音频深度伪造技术因生成式AI而快速发展，但相应的伪造检测研究却滞后。现有数据集和研究方法导致系统无法泛化到真实应用场景，主要原因是原始伪造音频与经过通信渠道（如电话）传输的伪造音频存在差异。

Method: 提出新的数据创建框架和研究方法，专注于开发在真实场景中更有效的伪造检测对策。通过遵循提出的指导原则，在更稳健和现实的实验设置中改进检测性能。

Result: 在更稳健和现实的实验设置中，深度伪造检测准确率提高了39%；在真实世界基准测试中，准确率提高了57%。研究还表明，改进数据集对检测准确率的影响比选择更大的SOTA模型更大。

Conclusion: 科学界应该更多地投资于全面的数据收集项目，而不是简单地训练计算需求更高的更大模型。改进数据集比模型规模对深度伪造检测准确率有更大的影响。

Abstract: While the technologies empowering malicious audio deepfakes have dramatically
evolved in recent years due to generative AI advances, the same cannot be said
of global research into spoofing (deepfake) countermeasures. This paper
highlights how current deepfake datasets and research methodologies led to
systems that failed to generalize to real world application. The main reason is
due to the difference between raw deepfake audio, and deepfake audio that has
been presented through a communication channel, e.g. by phone. We propose a new
framework for data creation and research methodology, allowing for the
development of spoofing countermeasures that would be more effective in
real-world scenarios. By following the guidelines outlined here we improved
deepfake detection accuracy by 39% in more robust and realistic lab setups, and
by 57% on a real-world benchmark. We also demonstrate how improvement in
datasets would have a bigger impact on deepfake detection accuracy than the
choice of larger SOTA models would over smaller models; that is, it would be
more important for the scientific community to make greater investment on
comprehensive data collection programs than to simply train larger models with
higher computational demands.

</details>


### [34] [Voice Evaluation of Reasoning Ability: Diagnosing the Modality-Induced Performance Gap](https://arxiv.org/abs/2509.26542)
*Yueqian Lin,Zhengmian Hu,Qinsi Wang,Yudong Liu,Hengfan Zhang,Jayakumar Subramanian,Nikos Vlassis,Hai Helen Li,Yiran Chen*

Main category: eess.AS

TL;DR: VERA是一个语音交互系统推理能力评估基准，包含2,931个语音原生测试项，分为数学、网络、科学、长上下文和事实五个赛道，用于评估实时对话约束下的推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前语音系统在推理能力方面与文本系统存在巨大差距，需要专门的评估基准来测量语音交互系统在实时对话约束下的推理性能。

Method: 从现有文本基准改编语音原生测试项，保持推理难度，评估12个当代语音系统和文本基线，进行延迟-准确性分析和诊断实验。

Result: 发现显著的模态差距：在数学竞赛中，领先文本模型准确率74.8%，而语音模型仅6.1%；最佳文本模型平均准确率54.0%，语音模型仅11.3%。

Conclusion: VERA为分离思考与说话的架构提供了可复现测试平台，为开发既流畅又可靠推理的实时语音助手提供了原则性进展测量方法。

Abstract: We present Voice Evaluation of Reasoning Ability (VERA), a benchmark for
evaluating reasoning ability in voice-interactive systems under real-time
conversational constraints. VERA comprises 2,931 voice-native episodes derived
from established text benchmarks and organized into five tracks (Math, Web,
Science, Long-Context, Factual). Each item is adapted for speech interaction
while preserving reasoning difficulty. VERA enables direct text-voice
comparison within model families and supports analysis of how architectural
choices affect reliability. We assess 12 contemporary voice systems alongside
strong text baselines and observe large, consistent modality gaps: on
competition mathematics a leading text model attains 74.8% accuracy while its
voice counterpart reaches 6.1%; macro-averaged across tracks the best text
models achieve 54.0% versus 11.3% for voice. Latency-accuracy analyses reveal a
low-latency plateau, where fast voice systems cluster around ~10% accuracy,
while approaching text performance requires sacrificing real-time interaction.
Diagnostic experiments indicate that common mitigations are insufficient.
Increasing "thinking time" yields negligible gains; a decoupled cascade that
separates reasoning from narration improves accuracy but still falls well short
of text and introduces characteristic grounding/consistency errors. Failure
analyses further show distinct error signatures across native streaming,
end-to-end, and cascade designs. VERA provides a reproducible testbed and
targeted diagnostics for architectures that decouple thinking from speaking,
offering a principled way to measure progress toward real-time voice assistants
that are both fluent and reliably reasoned.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [35] [VoiceBridge: Designing Latent Bridge Models for General Speech Restoration at Scale](https://arxiv.org/abs/2509.25275)
*Chi Zhang,Zehua Chen,Kaiwen Zheng,Jun Zhu*

Main category: cs.SD

TL;DR: VoiceBridge是一个基于潜在桥模型的通用语音恢复系统，能够从各种失真中重建48kHz全频带高质量语音，通过单一潜在到潜在生成过程处理多种低质量到高质量任务。


<details>
  <summary>Details</summary>
Motivation: 现有的桥模型在语音增强任务中通常局限于单一任务或小规模数据集，通用语音恢复能力受限，需要开发能够处理多种失真类型的大规模系统。

Method: 使用能量保持变分自编码器将语音波形压缩为连续潜在表示，通过潜在桥模型进行单一潜在到潜在生成，结合联合神经先验和感知感知微调阶段提高重建质量。

Result: 在领域内和领域外任务及数据集上的广泛验证表明，VoiceBridge在语音恢复方面表现出优越性能，能够改进最近的零样本语音和播客生成结果。

Conclusion: VoiceBridge通过潜在桥模型框架成功实现了通用语音恢复，在保持高质量重建的同时处理多种失真类型，为大规模语音恢复系统提供了有效解决方案。

Abstract: Bridge models have recently been explored for speech enhancement tasks such
as denoising, dereverberation, and super-resolution, while these efforts are
typically confined to a single task or small-scale datasets, with constrained
general speech restoration (GSR) capability at scale. In this work, we
introduce VoiceBridge, a GSR system rooted in latent bridge models (LBMs),
capable of reconstructing high-fidelity speech at full-band (\textit{i.e.,}
48~kHz) from various distortions. By compressing speech waveform into
continuous latent representations, VoiceBridge models the~\textit{diverse
LQ-to-HQ tasks} (namely, low-quality to high-quality) in GSR with~\textit{a
single latent-to-latent generative process} backed by a scalable transformer
architecture. To better inherit the advantages of bridge models from the data
domain to the latent space, we present an energy-preserving variational
autoencoder, enhancing the alignment between the waveform and latent space over
varying energy levels. Furthermore, to address the difficulty of HQ
reconstruction from distinctively different LQ priors, we propose a joint
neural prior, uniformly alleviating the reconstruction burden of LBM. At last,
considering the key requirement of GSR systems, human perceptual quality, a
perceptually aware fine-tuning stage is designed to mitigate the cascading
mismatch in generation while improving perceptual alignment. Extensive
validation across in-domain and out-of-domain tasks and datasets
(\textit{e.g.}, refining recent zero-shot speech and podcast generation
results) demonstrates the superior performance of VoiceBridge. Demo samples can
be visited at: https://VoiceBridge-demo.github.io/.

</details>


### [36] [Learning Relationships Between Separate Audio Tracks for Creative Applications](https://arxiv.org/abs/2509.25296)
*Balthazar Bujard,Jérôme Nika,Fédéric Bevilacqua,Nicolas Obin*

Main category: cs.SD

TL;DR: 该研究提出了一种音乐代理架构，通过训练实现现场音乐输入与实时生成音乐输出之间的期望音乐关系调谐，使用分离音轨数据库进行训练。


<details>
  <summary>Details</summary>
Motivation: 研究目标是通过训练实现现场音乐输入与实时生成音乐输出之间期望音乐关系的调谐，这在音乐代理领域具有重要意义。

Method: 提出集成符号决策模块的架构，使用Transformer作为决策模块，基于Wav2Vec 2.0的感知模块，以及拼接合成作为音频渲染器的离线实现。

Result: 定量评估显示决策模块能够成功复现训练中学到的音乐关系，能够基于配对音轨(A,B)中的引导音轨A预测出连贯的音轨B。

Conclusion: 该研究证明了所提出的决策模块能够有效学习和利用从音乐语料库中提取的音乐关系，为音乐代理系统的开发奠定了基础。

Abstract: This paper presents the first step in a research project situated within the
field of musical agents. The objective is to achieve, through training, the
tuning of the desired musical relationship between a live musical input and a
real-time generated musical output, through the curation of a database of
separated tracks. We propose an architecture integrating a symbolic decision
module capable of learning and exploiting musical relationships from such
musical corpus. We detail an offline implementation of this architecture
employing Transformers as the decision module, associated with a perception
module based on Wav2Vec 2.0, and concatenative synthesis as audio renderer. We
present a quantitative evaluation of the decision module's ability to reproduce
learned relationships extracted during training. We demonstrate that our
decision module can predict a coherent track B when conditioned by its
corresponding ''guide'' track A, based on a corpus of paired tracks (A, B).

</details>


### [37] [EMO-TTA: Improving Test-Time Adaptation of Audio-Language Models for Speech Emotion Recognition](https://arxiv.org/abs/2509.25495)
*Jiacheng Shi,Hongfei Du,Y. Alicia Hong,Ye Gao*

Main category: cs.SD

TL;DR: 提出了Emo-TTA，一种轻量级、无需训练的测试时适应框架，通过期望最大化过程增量更新类条件统计量，用于语音情感识别中的分布偏移问题。


<details>
  <summary>Details</summary>
Motivation: 语音情感识别中的音频-语言模型在测试时容易受到分布偏移的影响，导致性能下降。现有的测试时适应方法通常依赖基于梯度的更新或提示调优，限制了灵活性和实用性。

Method: Emo-TTA通过期望最大化过程增量更新类条件统计量，使用ALM预测作为先验，进行显式的测试时分布估计。该方法在单个测试样本上操作，不修改模型权重。

Result: 在六个域外SER基准测试上的实验显示，Emo-TTA相比先前的TTA基线方法取得了持续的性能提升。

Conclusion: Emo-TTA证明了统计适应在将模型预测与演变的测试分布对齐方面的有效性，为语音情感识别中的测试时适应提供了实用解决方案。

Abstract: Speech emotion recognition (SER) with audio-language models (ALMs) remains
vulnerable to distribution shifts at test time, leading to performance
degradation in out-of-domain scenarios. Test-time adaptation (TTA) provides a
promising solution but often relies on gradient-based updates or prompt tuning,
limiting flexibility and practicality. We propose Emo-TTA, a lightweight,
training-free adaptation framework that incrementally updates class-conditional
statistics via an Expectation-Maximization procedure for explicit test-time
distribution estimation, using ALM predictions as priors. Emo-TTA operates on
individual test samples without modifying model weights. Experiments on six
out-of-domain SER benchmarks show consistent accuracy improvements over prior
TTA baselines, demonstrating the effectiveness of statistical adaptation in
aligning model predictions with evolving test distributions.

</details>


### [38] [LTA-L2S: Lexical Tone-Aware Lip-to-Speech Synthesis for Mandarin with Cross-Lingual Transfer Learning](https://arxiv.org/abs/2509.25670)
*Kang Yang,Yifan Liang,Fangkun Liu,Zhenping Xie,Chengshi Zheng*

Main category: cs.SD

TL;DR: 提出Lexical Tone-Aware Lip-to-Speech (LTA-L2S)方法，通过跨语言迁移学习和流匹配模型解决普通话唇语合成中的音素映射复杂性和声调建模难题。


<details>
  <summary>Details</summary>
Motivation: 普通话唇语合成面临复杂视位-音素映射和声调对可懂度至关重要的挑战，需要专门的方法来处理这些独特问题。

Method: 采用跨语言迁移学习策略，将英语预训练的视听自监督学习模型迁移到普通话领域；使用流匹配模型生成F0轮廓，并通过ASR微调的语音单元指导；采用两阶段训练范式提升语音质量。

Result: 大量实验表明，LTA-L2S在语音可懂度和声调准确性方面显著优于现有方法。

Conclusion: 该方法成功解决了普通话唇语合成的核心挑战，通过创新的迁移学习和声调建模技术实现了优越的性能。

Abstract: Lip-to-speech (L2S) synthesis for Mandarin is a significant challenge,
hindered by complex viseme-to-phoneme mappings and the critical role of lexical
tones in intelligibility. To address this issue, we propose Lexical Tone-Aware
Lip-to-Speech (LTA-L2S). To tackle viseme-to-phoneme complexity, our model
adapts an English pre-trained audio-visual self-supervised learning (SSL) model
via a cross-lingual transfer learning strategy. This strategy not only
transfers universal knowledge learned from extensive English data to the
Mandarin domain but also circumvents the prohibitive cost of training such a
model from scratch. To specifically model lexical tones and enhance
intelligibility, we further employ a flow-matching model to generate the F0
contour. This generation process is guided by ASR-fine-tuned SSL speech units,
which contain crucial suprasegmental information. The overall speech quality is
then elevated through a two-stage training paradigm, where a flow-matching
postnet refines the coarse spectrogram from the first stage. Extensive
experiments demonstrate that LTA-L2S significantly outperforms existing methods
in both speech intelligibility and tonal accuracy.

</details>


### [39] [HNote: Extending YNote with Hexadecimal Encoding for Fine-Tuning LLMs in Music Modeling](https://arxiv.org/abs/2509.25694)
*Hung-Ying Chu,Shao-Yu Wei,Guan-Wei Chen,Tzu-Wei Hung,ChengYang Tsai,Yu-Cheng Lin*

Main category: cs.SD

TL;DR: 提出HNote——一种基于十六进制的符号音乐表示系统，扩展自YNote，在固定32单元小节框架内编码音高和时长，解决了现有格式复杂或不一致的问题，适合LLM架构。


<details>
  <summary>Details</summary>
Motivation: 现有符号音乐格式如MIDI、ABC、MusicXML过于复杂或结构不一致，限制了基于token的学习架构的适用性，需要一种对齐、减少歧义且与LLM架构兼容的新表示系统。

Method: 将YNote生成的12,300首江南风格歌曲转换为HNote格式，使用参数高效的LoRA方法微调LLaMA-3.1(8B)模型。

Result: HNote实现了82.5%的语法正确率，BLEU和ROUGE评估显示在符号和结构相似性方面表现强劲，生成了风格一致的作曲。

Conclusion: HNote是整合LLM与文化音乐建模的有效框架，为符号音乐生成提供了新的解决方案。

Abstract: Recent advances in large language models (LLMs) have created new
opportunities for symbolic music generation. However, existing formats such as
MIDI, ABC, and MusicXML are either overly complex or structurally inconsistent,
limiting their suitability for token-based learning architectures. To address
these challenges, we propose HNote, a novel hexadecimal-based notation system
extended from YNote, which encodes both pitch and duration within a fixed
32-unit measure framework. This design ensures alignment, reduces ambiguity,
and is directly compatible with LLM architectures. We converted 12,300
Jiangnan-style songs generated from traditional folk pieces from YNote into
HNote, and fine-tuned LLaMA-3.1(8B) using parameter-efficient LoRA.
Experimental results show that HNote achieves a syntactic correctness rate of
82.5%, and BLEU and ROUGE evaluations demonstrate strong symbolic and
structural similarity, producing stylistically coherent compositions. This
study establishes HNote as an effective framework for integrating LLMs with
cultural music modeling.

</details>


### [40] [MARS: Audio Generation via Multi-Channel Autoregression on Spectrograms](https://arxiv.org/abs/2509.26007)
*Eleonora Ristori,Luca Bindini,Paolo Frasconi*

Main category: cs.SD

TL;DR: MARS是一个基于多通道频谱图自回归的音频生成框架，通过通道复用技术将频谱图视为多通道图像，使用共享分词器在不同尺度上提供一致的离散表示，实现从粗到细的分辨率高效生成高质量音频。


<details>
  <summary>Details</summary>
Motivation: 音频生成研究正从基于波形的方法转向基于频谱图的方法，后者能更自然地捕捉谐波和时间结构。同时图像合成领域的进展表明，跨尺度的自回归比基于token的自回归能提升连贯性和细节表现。

Method: 将频谱图视为多通道图像，采用通道复用(CMX)技术在不丢失信息的情况下降低高度和宽度。使用共享分词器提供跨尺度的一致离散表示，基于transformer的自回归器从粗到细分辨率高效优化频谱图。

Result: 在大规模数据集上的实验表明，MARS在多个评估指标上表现与最先进基线相当或更好，实现了高效且可扩展的高保真音频生成。

Conclusion: MARS建立了一个高效且可扩展的高保真音频生成范式，通过将频谱图视为多通道图像并采用跨尺度自回归方法，在保持音频质量的同时提高了生成效率。

Abstract: Research on audio generation has progressively shifted from waveform-based
approaches to spectrogram-based methods, which more naturally capture harmonic
and temporal structures. At the same time, advances in image synthesis have
shown that autoregression across scales, rather than tokens, improves coherence
and detail. Building on these ideas, we introduce MARS (Multi-channel
AutoRegression on Spectrograms), a framework that treats spectrograms as
multi-channel images and employs channel multiplexing (CMX), a reshaping
technique that lowers height and width without discarding information. A shared
tokenizer provides consistent discrete representations across scales, enabling
a transformer-based autoregressor to refine spectrograms from coarse to fine
resolutions efficiently. Experiments on a large-scale dataset demonstrate that
MARS performs comparably or better than state-of-the-art baselines across
multiple evaluation metrics, establishing an efficient and scalable paradigm
for high-fidelity audio generation.

</details>


### [41] [OWL: Geometry-Aware Spatial Reasoning for Audio Large Language Models](https://arxiv.org/abs/2509.26140)
*Subrata Biswas,Mohammad Nur Hossain Khan,Bashima Islam*

Main category: cs.SD

TL;DR: 提出了SAGE几何感知音频编码器和OWL音频大语言模型，通过结合双耳音频与全景深度图像，实现了更精确的空间感知和可解释的空间推理。


<details>
  <summary>Details</summary>
Motivation: 当前音频大语言模型主要依赖非结构化双耳线索和单步推理，限制了方向距离估计的准确性和可解释推理能力。现有方法如BAT使用粗粒度分类标签且缺乏几何监督，制约了分辨率和鲁棒性。

Method: 开发了SAGE编码器，在训练时使用全景深度图像和房间脉冲响应将双耳声学特征与3D空间结构对齐；构建了OWL模型，结合SAGE和空间基础思维链进行多步推理；采用从感知问答到多步推理的课程学习策略。

Result: 在BiDepth和SpatialSoundQA两个基准数据集上，OWL通过SAGE将平均DoA误差降低了11度，空间推理问答准确率比BAT提高了25%。

Conclusion: SAGE和OWL通过几何感知编码和空间基础推理，显著提升了音频空间感知和推理的准确性与可解释性，并发布了包含百万级问答对的BiDepth数据集支持大规模训练评估。

Abstract: Spatial reasoning is fundamental to auditory perception, yet current audio
large language models (ALLMs) largely rely on unstructured binaural cues and
single step inference. This limits both perceptual accuracy in direction and
distance estimation and the capacity for interpretable reasoning. Recent work
such as BAT demonstrates spatial QA with binaural audio, but its reliance on
coarse categorical labels (left, right, up, down) and the absence of explicit
geometric supervision constrain resolution and robustness. We introduce the
$\textbf{Spatial-Acoustic Geometry Encoder (SAGE}$), a geometry-aware audio
encoder that aligns binaural acoustic features with 3D spatial structure using
panoramic depth images and room-impulse responses at training time, while
requiring only audio at inference. Building on this representation, we present
$\textbf{OWL}$, an ALLM that integrates $\textbf{SAGE}$ with a spatially
grounded chain-of-thought to rationalize over direction-of-arrivals (DoA) and
distance estimates. Through curriculum learning from perceptual QA to
multi-step reasoning, $\textbf{OWL}$ supports o'clock-level azimuth and DoA
estimation. To enable large-scale training and evaluation, we construct and
release $\textbf{BiDepth}$, a dataset of over one million QA pairs combining
binaural audio with panoramic depth images and room impulse responses across
both in-room and out-of-room scenarios. Across two benchmark datasets, our new
$\textbf{BiDepth}$ and the public SpatialSoundQA, $\textbf{OWL}$ reduces mean
DoA error by $\textbf{11$^{\circ}$}$ through $\textbf{SAGE}$ and improves
spatial reasoning QA accuracy by up to $\textbf{25}$\% over BAT.

</details>


### [42] [Benchmarking Diarization Models](https://arxiv.org/abs/2509.26177)
*Luca A. Lanzendörfer,Florian Grötschla,Cesare Blaser,Roger Wattenhofer*

Main category: cs.SD

TL;DR: 本文评估了五种最先进的说话人日志模型在四种多语言数据集上的表现，发现PyannoteAI性能最佳（11.2% DER），DiariZen是最佳开源替代方案（13.3% DER）。主要错误源于漏检语音段和说话人混淆。


<details>
  <summary>Details</summary>
Motivation: 说话人日志是音频分析中的关键任务，但仍是未解决的问题。其错误会传播到下游系统并导致广泛失败，因此需要深入分析具体失败模式。

Method: 评估五种最先进的说话人日志模型，在四个包含多种语言和声学条件的数据集上进行测试，总计196.6小时多语言音频。

Result: PyannoteAI表现最佳（11.2% DER），DiariZen是最佳开源替代方案（13.3% DER）。主要错误模式是漏检语音段和说话人混淆，特别是在说话人数量多的场景中。

Conclusion: 说话人日志系统的主要挑战在于漏检语音段和说话人混淆，特别是在高说话人数量环境中。PyannoteAI和DiariZen是当前表现最好的解决方案。

Abstract: Speaker diarization is the task of partitioning audio into segments according
to speaker identity, answering the question of "who spoke when" in
multi-speaker conversation recordings. While diarization is an essential task
for many downstream applications, it remains an unsolved problem. Errors in
diarization propagate to downstream systems and cause wide-ranging failures. To
this end, we examine exact failure modes by evaluating five state-of-the-art
diarization models, across four diarization datasets spanning multiple
languages and acoustic conditions. The evaluation datasets consist of 196.6
hours of multilingual audio, including English, Mandarin, German, Japanese, and
Spanish. Overall, we find that PyannoteAI achieves the best performance at
11.2% DER, while DiariZen provides a competitive open-source alternative at
13.3% DER. When analyzing failure cases, we find that the primary cause of
diarization errors stem from missed speech segments followed by speaker
confusion, especially in high-speaker count settings.

</details>


### [43] [The silence of the weights: an investigation of structural pruning strategies for attention-based audio signal architectures](https://arxiv.org/abs/2509.26207)
*Andrea Diecidue,Carlo Alberto Barbano,Piero Fraternali,Mathieu Fontaine,Enzo Tartaglione*

Main category: cs.SD

TL;DR: 提出了一种针对Transformer注意力机制的新型剪枝技术，通过解耦注意力块中四个层的剪枝来减少参数数量，在剪除50%注意力参数时性能下降不到1%。


<details>
  <summary>Details</summary>
Motivation: Transformer模型虽然性能优异，但注意力层需要大量参数和高性能硬件，限制了其应用。

Method: 解耦注意力块中查询、键、值和输出投影矩阵四个层的剪枝，研究沿头部和通道维度的剪枝策略。

Result: 在音频频谱Transformer模型上测试，即使剪除50%的注意力参数，性能下降仍小于1%。

Conclusion: 提出的注意力剪枝技术能显著减少Transformer模型的参数和计算需求，同时保持高性能。

Abstract: Transformer-based models have become the state of the art across multiple
domains, from natural language processing to machine listening, thanks to
attention mechanisms. However, the attention layers require a large number of
parameters and high-end hardware for both training and inference. We propose a
novel pruning technique targeted explicitly at the attention mechanism, where
we decouple the pruning of the four layers in the attention block, namely:
query, keys, values and outputs' projection matrices. We also investigate
pruning strategies to prune along the head and channel dimensions, and compare
the performance of the Audio Spectrogram Transformer (AST) model under
different pruning scenarios. Our results show that even by pruning 50\% of the
attention parameters we incur in performance degradation of less than 1\%

</details>


### [44] [Representation-Based Data Quality Audits for Audio](https://arxiv.org/abs/2509.26291)
*Alvaro Gonzalez-Jimenez,Fabian Gröger,Linda Wermelinger,Andrin Bürli,Iason Kastanis,Simone Lionetti,Marc Pouly*

Main category: cs.SD

TL;DR: 将SelfClean数据审计框架从图像领域适配到音频领域，利用自监督音频表征识别数据质量问题，在单一流程中创建排名列表来发现各种问题。


<details>
  <summary>Details</summary>
Motivation: 音频系统中常见的数据质量问题（如离题样本、近似重复和标签错误）限制了系统性能，需要有效的数据审计方法。

Method: 采用自监督音频表征来识别数据质量问题，通过表示到排名的框架创建审查列表，在ESC-50、GTZAN和工业数据集上进行基准测试。

Result: 该框架实现了最先进的排名性能，通常优于特定问题基线，并能通过高效指导人工审查显著节省标注成本。

Conclusion: SelfClean框架成功从图像领域迁移到音频领域，为音频数据质量审计提供了有效的统一解决方案。

Abstract: Data quality issues such as off-topic samples, near duplicates, and label
errors often limit the performance of audio-based systems. This paper addresses
these issues by adapting SelfClean, a representation-to-rank data auditing
framework, from the image to the audio domain. This approach leverages
self-supervised audio representations to identify common data quality issues,
creating ranked review lists that surface distinct issues within a single,
unified process. The method is benchmarked on the ESC-50, GTZAN, and a
proprietary industrial dataset, using both synthetic and naturally occurring
corruptions. The results demonstrate that this framework achieves
state-of-the-art ranking performance, often outperforming issue-specific
baselines and enabling significant annotation savings by efficiently guiding
human review.

</details>


### [45] [MUSE-Explainer: Counterfactual Explanations for Symbolic Music Graph Classification Models](https://arxiv.org/abs/2509.26521)
*Baptiste Hilaire,Emmanouil Karystinaios,Gerhard Widmer*

Main category: cs.SD

TL;DR: 提出了MUSE-Explainer方法，为符号音乐分析的图神经网络模型提供清晰、人类友好的反事实解释，通过微小但有意义的音乐图修改来改变模型预测，同时保持音乐连贯性。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型在符号音乐分析中缺乏可解释性，大多数研究过于关注模型性能而忽视了解释能力。

Method: 开发MUSE-Explainer方法，通过生成反事实解释，对音乐图进行微小但有意义的修改来改变模型预测，确保结果保持音乐连贯性，并针对音乐数据结构定制解释。

Result: 在音乐分析任务中评估该方法，证明其能提供直观的见解，并可通过标准音乐工具（如Verovio）进行可视化。

Conclusion: MUSE-Explainer为音乐图神经网络模型提供了有效的可解释性工具，能够生成人类友好的解释，避免不现实或混乱的输出。

Abstract: Interpretability is essential for deploying deep learning models in symbolic
music analysis, yet most research emphasizes model performance over
explanation. To address this, we introduce MUSE-Explainer, a new method that
helps reveal how music Graph Neural Network models make decisions by providing
clear, human-friendly explanations. Our approach generates counterfactual
explanations by making small, meaningful changes to musical score graphs that
alter a model's prediction while ensuring the results remain musically
coherent. Unlike existing methods, MUSE-Explainer tailors its explanations to
the structure of musical data and avoids unrealistic or confusing outputs. We
evaluate our method on a music analysis task and show it offers intuitive
insights that can be visualized with standard music tools such as Verovio.

</details>


### [46] [Source Separation for A Cappella Music](https://arxiv.org/abs/2509.26580)
*Luca A. Lanzendörfer,Constantin Pinkl,Florian Grötschla*

Main category: cs.SD

TL;DR: 提出SepACap模型用于无伴奏合唱音乐的多歌手分离，采用幂集数据增强策略和周期性激活，在JaCappella数据集上实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决无伴奏合唱音乐中活跃歌手数量变化的多歌手分离问题，现有数据集有限且歌手数量不固定。

Method: 使用幂集数据增强策略扩展训练样本，基于SepReformer架构构建SepACap模型，引入周期性激活和复合损失函数处理静音音轨。

Result: 在JaCappella数据集上，在完整合唱和子集歌手分离场景中均达到最先进性能，优于基于频谱图的基线方法。

Conclusion: 该方法能有效处理歌手数量变化的现实场景，在无伴奏合唱音乐分离任务中表现优异。

Abstract: In this work, we study the task of multi-singer separation in a cappella
music, where the number of active singers varies across mixtures. To address
this, we use a power set-based data augmentation strategy that expands limited
multi-singer datasets into exponentially more training samples. To separate
singers, we introduce SepACap, an adaptation of SepReformer, a state-of-the-art
speaker separation model architecture. We adapt the model with periodic
activations and a composite loss function that remains effective when stems are
silent, enabling robust detection and separation. Experiments on the JaCappella
dataset demonstrate that our approach achieves state-of-the-art performance in
both full-ensemble and subset singer separation scenarios, outperforming
spectrogram-based baselines while generalizing to realistic mixtures with
varying numbers of singers.

</details>

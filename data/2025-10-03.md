<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 20]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.SD](#cs.SD) [Total: 11]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [JaneEye: A 12-nm 2K-FPS 18.9-$μ$J/Frame Event-based Eye Tracking Accelerator](https://arxiv.org/abs/2510.01213)
*Tao Han,Ang Li,Qinyu Chen,Chang Gao*

Main category: eess.SP

TL;DR: JaneEye是一个专为可穿戴设备设计的基于事件的节能眼动追踪硬件加速器，使用轻量级神经网络架构和硬件优化，在3ET+数据集上达到2.45像素误差，功耗仅为18.9μJ/帧。


<details>
  <summary>Details</summary>
Motivation: 传统基于帧的眼动追踪系统在XR应用中难以满足高精度、低延迟和节能的要求，而事件相机提供了超高时间分辨率和低功耗的替代方案。

Method: 提出超轻量级神经网络架构，包含新颖的ConvJANET层（仅保留遗忘门的简化ConvLSTM），使用自定义线性激活函数近似和定点量化，通过软硬件协同设计实现高效硬件加速。

Result: 在3ET+数据集上达到2.45像素误差，仅使用17.6K参数，支持1250Hz事件帧率，12nm ASIC实现400MHz运行，端到端延迟0.5ms（相当于2000FPS），能效18.9μJ/帧。

Conclusion: JaneEye为下一代XR可穿戴设备设定了低功耗、高性能眼动追踪解决方案的新基准。

Abstract: Eye tracking has become a key technology for gaze-based interactions in
Extended Reality (XR). However, conventional frame-based eye-tracking systems
often fall short of XR's stringent requirements for high accuracy, low latency,
and energy efficiency. Event cameras present a compelling alternative, offering
ultra-high temporal resolution and low power consumption. In this paper, we
present JaneEye, an energy-efficient event-based eye-tracking hardware
accelerator designed specifically for wearable devices, leveraging sparse,
high-temporal-resolution event data. We introduce an ultra-lightweight neural
network architecture featuring a novel ConvJANET layer, which simplifies the
traditional ConvLSTM by retaining only the forget gate, thereby halving
computational complexity without sacrificing temporal modeling capability. Our
proposed model achieves high accuracy with a pixel error of 2.45 on the 3ET+
dataset, using only 17.6K parameters, with up to 1250 Hz event frame rate. To
further enhance hardware efficiency, we employ custom linear approximations of
activation functions (hardsigmoid and hardtanh) and fixed-point quantization.
Through software-hardware co-design, our 12-nm ASIC implementation operates at
400 MHz, delivering an end-to-end latency of 0.5 ms (equivalent to 2000 Frames
Per Second (FPS)) at an energy efficiency of 18.9 $\mu$J/frame. JaneEye sets a
new benchmark in low-power, high-performance eye-tracking solutions suitable
for integration into next-generation XR wearables.

</details>


### [2] [Satellite Assignment Policy Learning for Coexistence in LEO Networks](https://arxiv.org/abs/2510.01408)
*Jeong Min Kong,Ian P. Roberts*

Main category: eess.SP

TL;DR: 该论文提出了一种基于图结构学习的算法，用于推断低地球轨道卫星系统中主系统的卫星分配策略，以帮助次系统避免对主用户造成过度干扰。


<details>
  <summary>Details</summary>
Motivation: 在LEO卫星系统中，次系统需要避免对主用户造成过度干扰，但主系统的卫星分配策略通常不公开。因此需要开发方法来推断这些策略。

Method: 提出了一种端到端的图结构学习算法，利用有限的历史数据来学习基于最高仰角的主卫星分配策略，能够直接将主卫星坐标映射为对主用户的分配决策。

Result: 仿真结果显示，该方法优于最佳基线方法，预测准确率提高了约15%。

Conclusion: 所提出的图结构学习算法能够有效推断主系统的卫星分配策略，为次系统的频谱接入提供了可靠的技术支持。

Abstract: Unlike in terrestrial cellular networks, certain frequency bands for
low-earth orbit (LEO) satellite systems have thus far been allocated on a
non-exclusive basis. In this context, systems that launch their satellites
earlier (referred to as primary systems) are given spectrum access priority
over those that launch later, known as secondary systems. For a secondary
system to function, it is expected to either coordinate with primary systems or
ensure that it does not cause excessive interference to primary ground users.
Reliably meeting this interference constraint requires real-time knowledge of
the receive beams of primary users, which in turn depends on the primary
satellite-to-primary user associations. However, in practice, primary systems
have thus far not publicly disclosed their satellite assignment policies;
therefore, it becomes essential for secondary systems to develop methods to
infer such policies. Assuming there is limited historical data indicating which
primary satellites have served which primary users, we propose an end-to-end
graph structure learning-based algorithm for learning highest elevation primary
satellite assignment policies, that, upon deployment, can directly map the
primary satellite coordinates into assignment decisions for the primary users.
Simulation results show that our method can outperform the best baseline,
achieving approximately a 15% improvement in prediction accuracy.

</details>


### [3] [Delay-Augmented Stacked Intelligent Surfaces: Potential, Challenges, and Opportunities](https://arxiv.org/abs/2510.01411)
*Hibatallah Alwazani,Omran Abbas,Loic Markley,Anas Chaaban*

Main category: eess.SP

TL;DR: 该论文提出了延迟增强堆叠智能表面(DA-SIS)的概念，通过在SIS中集成可调延迟单元实现时空信号处理，并展示了其作为模拟均衡器消除多径干扰的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有堆叠智能表面(SIS)主要进行空间波域信号处理，缺乏时间维度处理能力。为了扩展SIS的功能，需要引入时间处理能力来应对多径干扰等时域问题。

Method: 在SIS中集成战略调谐的符号持续时间级延迟单元，构建延迟增强SIS(DA-SIS)，使其能够同时进行空间和时间信号处理。

Result: DA-SIS作为模拟均衡器可以有效消除多径引起的符号间干扰，通过比特误码率(BER)分析显示其均衡性能，并与数字均衡器进行基准比较验证其潜力。

Conclusion: 延迟增强SIS为全息MIMO和超大规模MIMO技术提供了新的可能性，未来需要进一步研究来实现这一概念的实际应用。

Abstract: Stacked intelligent surfaces (SIS)s have been proposed recently as an
enabling technology for Holographic Multiple Input Multiple Output (HMIMO) and
Ultra-massive MIMO (umMIMO) technologies. Their utility can extend beyond
spatial wave-domain processing of signals if they are enhanced with
strategically-tuned symbol-duration level delays to enable temporal processing
as well. In this work, we introduce the idea of a delay-augmented SIS (DA-SIS).
We shed light on the feasibility of realizing delay units in an SIS. Then, we
discuss the relevance of the proposed DA-SIS and present a use case that
illustrates its potential, wherein the DA-SIS serves as an analog equalizer
that aids in eliminating multi-path-induced inter-symbol-interference (ISI). We
show how the number of elements affect the equalization process using the bit
error rate (BER) as a metric, and demonstrate the potential of the DA-SIS in
equalization via comparing with digital equalizers as a benchmark. Finally, we
present opportunities and future research directions that can be undertaken to
bring this idea to fruition.

</details>


### [4] [A Drone-mounted Magnetometer System for Automatic Interference Removal and Landmine Detection](https://arxiv.org/abs/2510.01417)
*Alex Paul Hoffmann,Matthew G. Finley,Eftyhia Zesta,Mark B. Moldwin,Lauro V. Ojeda*

Main category: eess.SP

TL;DR: 提出了一种使用无人机搭载双磁力计的有效地雷检测方法，通过两步算法消除无人机电子设备干扰并检测地雷信号。


<details>
  <summary>Details</summary>
Motivation: 地雷在冲突地区广泛使用，战后持续威胁平民安全并阻碍恢复工作。无人机磁力计探测面临电子设备干扰的技术挑战。

Method: 使用框架安装的双磁力计载荷，采用WAIC-UP方法消除干扰，然后使用RUDE算法检测地雷信号。

Result: 该方法在蒙特卡洛模拟中验证了高保真度弹药检测，计算成本低，并简化了磁力测量载荷设计。

Conclusion: WAIC-UP/RUDE方法能够有效解决无人机磁力计探测中的干扰问题，实现可靠的地雷检测。

Abstract: Landmines have been extensively used in conflict zones as an indiscriminate
weapon to control military movements, often remaining active long after
hostilities have ended. Their presence poses a persistent danger to civilians,
hindering post-war recovery efforts, causing injuries or death, and restricting
access to essential land for agriculture and infrastructure. Unmanned aerial
vehicles (UAV) equipped with magnetometers are commonly used to detect remnant
hidden landmines but come with significant technical challenges due to magnetic
field interference from UAV electronics such as motors. We propose the use of a
frame-mounted UAV-borne two-magnetometer payload to perform a two-step
automated interference removal and landmine detection analysis. The first step
removes interference via the Wavelet-Adaptive Interference Cancellation for
Underdetermined Platform (WAIC-UP) method designed for spaceflight
magnetometers. The second method uses the Rapid Unsupervised Detection of
Events (RUDE) algorithm to detect landmine signatures. This two-step
WAIC-UP/RUDE approach with multiple magnetometers achieves high-fidelity
ordinance detection at a low computational cost and simplifies the design of
magnetic survey payloads. We validate the method through a Monte Carlo
simulation of randomized landmine placements in a 10 x 10 m square grid and
drone motor interference. Additionally, we assess the efficacy of the algorithm
by varying the drone's altitude, examining its performance at different heights
above the ground.

</details>


### [5] [Meta-Learning-Driven Resource Optimization in Full-Duplex ISAC with Movable Antennas](https://arxiv.org/abs/2510.01437)
*Ali Amhaz,Shreya Khisa,Mohamed Elhattab,Chadi Assi,Sanaa Sharafeddine*

Main category: eess.SP

TL;DR: 本文研究了一种基于可移动天线的全双工ISAC系统，通过联合优化发射/接收波束成形、上行用户功率和天线位置，最大化回波信干噪比，同时满足感知和通信的QoS要求。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)技术需要同时支持通信服务和目标检测功能，而可移动天线(MA)能够通过优化天线位置来提升系统性能，特别是在全双工场景下。

Method: 采用基于梯度的元学习(GML)方法来解决大规模非凸优化问题，联合优化发射波束成形向量、接收波束成形向量、上行用户发射功率以及两个基站的可移动天线位置。

Result: 数值结果表明，所提出的元学习方法能达到最优解的99%性能，且基于MA的方案优于多种基准方法。

Conclusion: 基于可移动天线的全双工ISAC系统在联合优化天线位置和波束成形方面具有显著优势，为实际ISAC应用提供了有效解决方案。

Abstract: This paper investigates a full-duplex (FD) scenario where a base station (BS)
equipped with movable antennas (MAs) simultaneously provides communication
services to a set of downlink (DL) and uplink (UL) users while also enabling
sensing functionalities for target detection, thereby supporting integrated
sensing and communication (ISAC) technology. Additionally, a receiving BS, also
equipped with MAs (denoted as BS R), is responsible for capturing the reflected
echo. To optimize this setup, we formulate an optimization problem aimed at
maximizing the signal-to-noise and interference ratio (SINR) of the captured
echo. This is achieved by jointly optimizing the transmit beamforming vectors
at the FD BS, the receiving beamforming vectors at both the FD BS and BS R, the
UL users' transmit power, and the MAs' positions at both BSs, all while
satisfying the quality-of-service (QoS) requirements for both sensing and
communication. Given the non-convex nature of the problem and the high coupling
between the variables, we employ a gradient-based meta-learning (GML) approach
tailored for large-scale optimization. Numerical results demonstrate the
effectiveness of the proposed meta-learning approach, achieving results within
99% of the optimal solution. Furthermore, the MA-based scheme outperforms
several benchmark approaches, highlighting its advantages in practical ISAC
applications.

</details>


### [6] [The Analysis and Performance of LODC-OFDM Signal in Nonlinear Rydberg Atomic Sensor](https://arxiv.org/abs/2510.01605)
*Hao Wu,Xinyuan Yao,Rui Ni,Chen Gong*

Main category: eess.SP

TL;DR: 本文提出了一种针对里德堡原子传感器的LODC-OFDM方案，解决了传统OFDM在里德堡系统中接收受限的问题，并通过Bussgang定理分析了非线性失真，实验验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 里德堡原子传感器在射频测量中具有高灵敏度，但其光学接口的单极性特性限制了传统OFDM接收，因此需要开发兼容的信号传输方案。

Method: 建立了里德堡原子传感器的AM-AM特性经验近似函数，提出了基于DCO-OFDM框架的LODC-OFDM方案，并采用Bussgang定理分析非线性失真。

Result: 推导了泰勒级数展开和理想预失真情况下的闭式解，实验结果表明理论与实验结果吻合良好。

Conclusion: LODC-OFDM方案有效解决了里德堡系统中的宽带OFDM接收挑战，为里德堡原子传感器在通信接收中的应用提供了可行方案。

Abstract: Rydberg atomic sensors have been seen as novel radio frequency (RF)
measurements and the high sensitivity to a large range of frequencies makes it
attractive for communications reception. However, the signal sensing process in
Rydberg system involves sequential transduction from electromagnetic waves to
optical signals and finally to electrical signals. The unipolar characteristic
of the optical interface inherently restricts conventional OFDM reception.
Therefore, adopting unipolar OFDM schemes, inspired by optical communication
systems, becomes essential for compatible signal transmission. In this work, we
investigate the amplitude modulation-to-amplitude modulation (AM-AM)
characteristics of Rydberg atomic sensors, establishing an empirical
approximation function. Building on the direct current-biased optical
orthogonal frequency division multiplexing (DCO-OFDM) framework, we propose a
novel local oscillator direct current-biased OFDM (LODC-OFDM) scheme
specifically optimized for Rydberg-based sensing, effectively addressing the
broadband OFDM reception challenge. Then, we adopt Bussgang theorem to analyze
the nonlinear distortion of LODC-OFDM signals and the results in closed-form
solutions are derived for AM/AM curves approximated by Taylor series expansion
and for the ideal pre-distortion case. In real experiments, the experimental
and theoretical results fit well.

</details>


### [7] [SEP Analysis of 1-Bit Quantized SIMO Systems with QPSK over Fading Channels](https://arxiv.org/abs/2510.01707)
*Amila Ravinath,Minhua Ding,Bikshapathi Gouda,Italo Atzeni,Antti Tölli*

Main category: eess.SP

TL;DR: 分析了1比特量化SIMO系统在瑞利衰落信道和QPSK调制下的平均符号错误概率，推导了MRC接收的精确SEP表达式，并确定了SIMO-MRC和SIMO-SC系统的分集增益和编码增益。


<details>
  <summary>Details</summary>
Motivation: 先前研究仅部分表征了选择合并(SC)的分集增益，需要更全面的分析来理解1比特量化SIMO系统的性能特性。

Method: 采用新颖的分析方法，推导了1比特量化SIMO系统在QPSK调制和MRC接收下的精确SEP表达式。

Result: 获得了SIMO-MRC系统的精确SEP表达式，并量化了SIMO-MRC和SIMO-SC系统的分集增益和编码增益。

Conclusion: 该研究扩展和补充了先前结果，为1比特量化SIMO系统的性能分析提供了更完整的理论框架。

Abstract: The average symbol error probability (SEP) of a 1-bit quantized single-input
multiple-output (SIMO) system is analyzed under Rayleigh fading channels and
quadrature phase-shift keying (QPSK) modulation. Previous studies have
partially characterized the diversity gain for selection combining (SC). In
this paper, leveraging a novel analytical method, an exact analytical SEP
expression is derived for a 1-bit quantized SIMO system employing QPSK
modulation at the transmitter and maximum ratio combining (MRC) at the
receiver. The corresponding diversity and coding gains of a SIMO-MRC system are
also determined. Furthermore, the diversity and coding gains of a 1-bit
quantized SIMO-SC system are quantified for an arbitrary number of receive
antennas, thereby extending and complementing prior results.

</details>


### [8] [3D 8-Ary Noise Modulation Using Bayesian- and Kurtosis-based Detectors](https://arxiv.org/abs/2510.01748)
*Hadi Zayyani,Felipe A. P. de Figueiredo,Mohammad Salman,Rausley A. A. de Souza*

Main category: eess.SP

TL;DR: 本文提出了一种新颖的三维8元噪声调制方案，通过引入混合高斯分布的概率维度，在传统均值和方差维度基础上增加了第三个维度，使每个传输符号携带3比特信息，数据速率相比现有方案提高了1.5-3倍。


<details>
  <summary>Details</summary>
Motivation: 现有噪声调制方案通常只使用均值和方差两个维度，限制了数据传输速率。为了进一步提高通信系统的数据速率和频谱效率，需要开发新的调制维度。

Method: 采用混合高斯分布的概率作为第三维度，每个符号对应三个子信道比特：均值调制第一比特、方差调制第二比特、MoG概率调制第三比特。检测时分别使用阈值检测器、最大似然检测器、峰度检测器和贝叶斯假设检测器。

Result: 仿真结果显示第三子信道比特的误码率与现有二维方案相当，同时数据速率相比广义二次噪声调制器和经典二元KLJN噪声调制器分别提高了1.5倍和3倍。峰度检测器实现了约0.06的可接受误码率。

Conclusion: 所提出的三维噪声调制方案成功扩展了调制维度，在保持可接受误码率的同时显著提高了数据速率，为噪声调制通信系统提供了一种有效的性能提升方案。

Abstract: This paper presents a novel three-dimensional (3D) 8-ary noise modulation
scheme that introduces a new dimension: the mixture probability of a Mixture of
Gaussian (MoG) distribution. This proposed approach utilizes the dimensions of
mean and variance, in addition to the new probability dimension. Within this
framework, each transmitted symbol carries three bits, each corresponding to a
distinct sub-channel. For detection, a combination of specialized detectors is
employed: a simple threshold based detector for the first sub-channel bit
(modulated by the mean), a Maximum-Likelihood (ML) detector for the second
sub-channel bit (modulated by the variance), a Kurtosis-based, Jarque-Bera (JB)
test, and Bayesian Hypothesis (BHT)-based detectors for the third bit
(modulated by the MoG probability). The Kurtosis- and JB-based detectors
specifically distinguish between Gaussian (or near-Gaussian) and non-Gaussian
MoG distributions by leveraging higher-order statistical measures. The Bit
Error Probabilities (BEPs) are derived for the threshold-, Kurtosis-, and
BHT-based detectors. The optimum threshold for the Kurtosis-based detector is
also derived in a tractable manner. Simulation results demonstrate that a
comparably low BEP is achieved for the third sub-channel bit relative to
existing two-dimensional (2D) schemes. Simultaneously, the proposed scheme
increases the data rate by a factor of 1.5 and 3 compared to the Generalized
Quadratic noise modulator and the classical binary KLJN noise modulator,
respectively. Furthermore, the Kurtosis-based detector offers a low-complexity
solution, achieving an acceptable BEP of approximately 0.06.

</details>


### [9] [Exactly or Approximately Wasserstein Distributionally Robust Estimation According to Wasserstein Radii Being Small or Large](https://arxiv.org/abs/2510.01763)
*Xiao Ding,Enbin Song,Dunbiao Niu,Zhujun Cao,Qingjiang Shi*

Main category: eess.SP

TL;DR: 该论文研究了在Wasserstein距离约束下线性测量模型的鲁棒估计问题，证明了无限维非凸极小极大问题与有限维问题的鞍点存在性等价，给出了鞍点存在的可验证条件，并在无鞍点时提出了鲁棒线性估计器。


<details>
  <summary>Details</summary>
Motivation: 研究在参数和噪声分布受Wasserstein距离约束的线性测量模型中，如何解决无限维非凸极小极大问题的鲁棒估计问题，特别关注鞍点存在性条件。

Method: 将无限维非凸极小极大问题转化为有限维问题进行分析，通过凸问题及其对偶推导鞍点存在的可验证条件，在无鞍点时采用线性估计器方法。

Result: 证明了无限维与有限维问题的鞍点存在性等价，给出了鞍点存在的必要充分条件和简化充分条件，提出了鲁棒线性估计器并提供了数值实验验证。

Conclusion: 该研究为Wasserstein距离约束下的鲁棒估计问题提供了理论分析和实用方法，特别在鞍点存在性判断和鲁棒估计器设计方面取得了进展。

Abstract: This paper primarily considers the robust estimation problem under
Wasserstein distance constraints on the parameter and noise distributions in
the linear measurement model with additive noise, which can be formulated as an
infinite-dimensional nonconvex minimax problem. We prove that the existence of
a saddle point for this problem is equivalent to that for a finite-dimensional
minimax problem, and give a counterexample demonstrating that the saddle point
may not exist. Motivated by this observation, we present a verifiable necessary
and sufficient condition whose parameters can be derived from a convex problem
and its dual. Additionally, we also introduce a simplified sufficient
condition, which intuitively indicates that when the Wasserstein radii are
small enough, the saddle point always exists. In the absence of the saddle
point, we solve an finite-dimensional nonconvex minimax problem, obtained by
restricting the estimator to be linear. Its optimal value establishes an upper
bound on the robust estimation problem, while its optimal solution yields a
robust linear estimator. Numerical experiments are also provided to validate
our theoretical results.

</details>


### [10] [Composite Generalized Quadratic Noise Modulation via Signal Addition: Towards Higher Dimensional Noise Modulations](https://arxiv.org/abs/2510.01776)
*Hadi Zayyani,Mohammad Salman,Felipe A. P. de Figueiredo,Rausley A. A. de Souza*

Main category: eess.SP

TL;DR: 提出通过叠加两个广义二次噪声调制器(GQNM)输出创建16进制噪声调制器，类似经典通信中的QAM调制器，在满足理论可区分性条件下可获得比KLJN和GQNM调制器更好的性能。


<details>
  <summary>Details</summary>
Motivation: 创建更高阶的噪声调制方案，通过叠加多个GQNM调制器输出实现类似QAM的调制效果，提升通信性能。

Method: 将两个GQNM调制器的输出简单相加，创建16进制噪声调制器，在四个不同均值和四个不同方差上调制信息比特。

Result: 仿真验证表明，在满足理论可区分性条件下，该方案相比KLJN和GQNM调制器具有更低的误码概率(BEP)。

Conclusion: 通过增加调制器、发射机和接收机检测器的复杂度，可以实现更好的性能，更高阶调制方案有待未来研究。

Abstract: This letter proposes superposing two Generalized Quadratic Noise Modulators
(GQNM) by simply adding their outputs. It creates a 16-ary noise modulator that
resembles QAM modulators in classical communication. It modulates the
information bits on four different means and four different variances. It could
also be applied to reach higher-order modulations than 16-ary schemes by adding
the outputs of more than two modulators, which is not discussed in detail in
this letter and left for future work. By selecting the parameters necessary for
satisfying the theoretical distinguishability conditions provided in the paper,
we can reach better performances in comparison to the Kirchhoff-Law Johnson
Noise (KLJN) modulator and the GQNM modulator, which is verified by the
simulations. The better result in terms of smaller Bit Error Probability (BEP)
is achieved by increasing the complexity in the modulator, the transmitter, and
the detectors in the receiver.

</details>


### [11] [Closed-form Single UAV-aided Emitter Localization and Trajectory Design Using Doppler and TOA Measurements](https://arxiv.org/abs/2510.01778)
*Samaneh Motie,Hadi Zayyani,Mohammad Salman,Hasan Abu Hilal*

Main category: eess.SP

TL;DR: 提出了一种基于无人机辅助的定位算法，结合多普勒频移和到达时间测量，通过约束最小二乘优化获得闭式解，并提供无人机轨迹设计。


<details>
  <summary>Details</summary>
Motivation: 传统基于多普勒的定位算法使用非凸函数，计算复杂且难以求解。本文旨在通过结合ToA测量，将问题转化为凸优化问题，获得闭式解。

Method: 在多普勒最小二乘代价函数中引入ToA测量，形成二次凸函数，其极小值位于一条直线上。结合ToA测量和极小值线性方程，通过约束LS优化获得发射器位置的闭式解。

Result: 仿真实验表明，所提算法相比文献中其他方法具有更好的性能表现。

Conclusion: 通过结合多普勒和ToA测量，成功将定位问题转化为凸优化问题，获得了闭式解，并提供了无人机轨迹设计的闭式解决方案。

Abstract: In this paper, a single Unmanned-Aerial-Vehicle (UAV)-aided localization
algorithm which uses both Doppler and Time of Arrival (ToA) measurements is
presented. In contrast to Doppler-based localization algorithms which are based
on non-convex functions, exploiting ToA measurements in a Least-Square (LS)
Doppler-based cost function, leads to a quadratic convex function whose
minimizer lies on a line. Utilizing the ToA measurements in addition to the
linear equation of minimizer, a closed form solution is obtained for the
emitter location using a constrained LS optimization. In addition, a trajectory
design of the UAV is provided which has also closed-form solution. Simulation
experiments demonstrate the effectiveness of the proposed algorithm in
comparison to some others in the literature.

</details>


### [12] [Performance Optimization for Movable Antenna Enhanced MISO-OFDM Systems](https://arxiv.org/abs/2510.01789)
*Ruixi Feng,Weidong Mei,Lele Lu,Xin Wei,Zhi Chen,Zhen Gao,Boyu Ning*

Main category: eess.SP

TL;DR: 本文研究了可移动天线在MISO-OFDM系统中的位置优化问题，通过离散化运动区域和分支定界算法，在宽带系统中实现了优于固定天线的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注窄带可移动天线系统，但在宽带OFDM系统中，天线位置需要适应不同子载波的频率平坦特性，这是一个具有挑战性的优化问题。

Method: 将连续位置优化问题转化为离散点选择问题，采用分支定界框架结合图论方法剪枝次优解，在低信噪比下提出简化的图基算法。

Result: 仿真结果表明，所提算法优于传统固定位置天线，且窄带天线位置优化可达到接近最优的性能。

Conclusion: 可移动天线技术通过优化天线位置能有效提升宽带无线系统性能，所提出的离散化方法和高效算法为解决此类问题提供了有效途径。

Abstract: Movable antenna (MA) technology offers a flexible approach to enhancing
wireless channel conditions by adjusting antenna positions within a designated
region. While most existing works focus on narrowband MA systems, this paper
investigates MA position optimization for an MA-enhanced multiple-input
single-output (MISO) orthogonal frequency-division multiplexing (OFDM) system.
This problem appears to be particularly challenging due to the frequency-flat
nature of MA positioning, which should accommodate the channel conditions
across different subcarriers. To overcome this challenge, we discretize the
movement region into a multitude of sampling points, thereby converting the
continuous position optimization problem into a discrete point selection
problem. Although this problem is combinatorial, we develop an efficient
partial enumeration algorithm to find the optimal solution using a
branch-and-bound framework, where a graph-theoretic method is incorporated to
effectively prune suboptimal solutions. In the low signal-to-noise ratio (SNR)
regime, a simplified graph-based algorithm is also proposed to obtain the
optimal MA positions without the need for enumeration. Simulation results
reveal that the proposed algorithm outperforms conventional fixed-position
antennas (FPAs), while narrowband-based antenna position optimization can
achieve near-optimal performance.

</details>


### [13] [NGGAN: Noise Generation GAN Based on the Practical Measurement Dataset for Narrowband Powerline Communications](https://arxiv.org/abs/2510.01850)
*Ying-Ren Chien,Po-Heng Chou,You-Jie Peng,Chun-Yuan Huang,Hen-Wai Tsao,Yu Tsao*

Main category: eess.SP

TL;DR: 提出了一种基于生成对抗网络（NGGAN）的噪声生成方法，用于窄带电力线通信系统中非周期性异步脉冲噪声的数据增强，相比传统数学模型能更好地匹配实际测量噪声的复杂特性。


<details>
  <summary>Details</summary>
Motivation: 现有数学模型只能捕捉部分加性噪声特性，无法全面统计非周期性异步脉冲噪声，这限制了窄带电力线通信收发器的脉冲噪声处理能力提升。

Method: 使用Wasserstein距离作为损失函数的生成对抗网络（NGGAN），通过实际测量的NB-PLC噪声数据集进行训练，设计了适合循环平稳噪声生成的输入信号长度。

Result: 仿真结果表明，基于波形特征训练的NGGAN在生成噪声质量方面更接近实际测量数据集，优于传统的PSCGM和FRESH滤波器模型。

Conclusion: NGGAN能够有效学习实际测量噪声的复杂特性，为窄带电力线通信系统的噪声处理提供了更准确的数据增强方法。

Abstract: Capturing comprehensive statistics of nonperiodic asynchronous impulsive
noise is a critical issue in enhancing impulse noise processing for narrowband
powerline communication (NB-PLC) transceivers. However, existing mathematical
noise generative models capture only some of the characteristics of additive
noise. Therefore, we propose a generative adversarial network (GAN), called the
noise-generation GAN (NGGAN), that learns the complicated characteristics of
practically measured noise samples for data augmentation. To closely match the
statistics of complicated noise in NB-PLC systems, we measured the NB-PLC noise
via the analog coupling and bandpass filtering circuits of a commercial NB-PLC
modem to build a realistic dataset. Specifically, the NGGAN design approaches
based on the practically measured dataset are as follows: (i) we design the
length of input signals that the NGGAN model can fit to facilitate
cyclo-stationary noise generation. (ii) Wasserstein distance is used as a loss
function to enhance the similarity between the generated noise and the training
dataset and ensure that the sample diversity is sufficient for various
applications. (iii) To measure the similarity performance of the GAN-based
models based on mathematical and practically measured datasets, we perform
quantitative and qualitative analyses. The training datasets include (1) a
piecewise spectral cyclo-stationary Gaussian model (PSCGM), (2) a
frequency-shift (FRESH) filter, and (3) practical measurements from NB-PLC
systems. Simulation results demonstrate that the proposed NGGAN trained using
waveform characteristics is closer to the practically measured dataset in terms
of the quality of the generated noise.

</details>


### [14] [Wearable and Ultra-Low-Power Fusion of EMG and A-Mode US for Hand-Wrist Kinematic Tracking](https://arxiv.org/abs/2510.02000)
*Giusy Spacone,Sebastian Frey,Mattia Orlandi,Pierangelo Maria Rapa,Victor Kartsch,Simone Benatti,Luca Benini,Andrea Cossettini*

Main category: eess.SP

TL;DR: 提出了一种超低功耗（低于50mW）系统，融合8通道表面肌电信号和4通道A模式超声信号，用于连续追踪手部和腕部23个自由度，相比单一模态显著提高了精度。


<details>
  <summary>Details</summary>
Motivation: 现有手势识别系统功耗高且仅限于离散手势分类，无法满足多日使用需求，需要开发更节能、能连续追踪手势的系统。

Method: 使用轻量级编码器-解码器架构和多任务学习，同时融合表面肌电和超声信号来估计手部和腕部关节角度，并通过运动捕捉手套获取地面真值标签。

Result: 在传感器重新定位的实际情况中，EMG-US融合的均方根误差为10.6°±2.0°，优于单独的EMG（12.0°±1.0°）和US（13.1°±2.6°），R²得分为0.61±0.1。

Conclusion: EMG-US传感器融合方法在超低功耗下实现了更精确的手势连续追踪，为直观的人机交互提供了可行解决方案。

Abstract: Hand gesture recognition based on biosignals has shown strong potential for
developing intuitive human-machine interaction strategies that closely mimic
natural human behavior. In particular, sensor fusion approaches have gained
attention for combining complementary information and overcoming the
limitations of individual sensing modalities, thereby enabling more robust and
reliable systems. Among them, the fusion of surface electromyography (EMG) and
A-mode ultrasound (US) is very promising. However, prior solutions rely on
power-hungry platforms unsuitable for multi-day use and are limited to discrete
gesture classification. In this work, we present an ultra-low-power (sub-50 mW)
system for concurrent acquisition of 8-channel EMG and 4-channel A-mode US
signals, integrating two state-of-the-art platforms into fully wearable,
dry-contact armbands. We propose a framework for continuous tracking of 23
degrees of freedom (DoFs), 20 for the hand and 3 for the wrist, using a
kinematic glove for ground-truth labeling. Our method employs lightweight
encoder-decoder architectures with multi-task learning to simultaneously
estimate hand and wrist joint angles. Experimental results under realistic
sensor repositioning conditions demonstrate that EMG-US fusion achieves a root
mean squared error of $10.6^\circ\pm2.0^\circ$, compared to
$12.0^\circ\pm1^\circ$ for EMG and $13.1^\circ\pm2.6^\circ$ for US, and a R$^2$
score of $0.61\pm0.1$, with $0.54\pm0.03$ for EMG and $0.38\pm0.20$ for US.

</details>


### [15] [Computing on Dirty Paper: Interference-Free Integrated Communication and Computing](https://arxiv.org/abs/2510.02012)
*Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,David González G.,Carlo Fischione*

Main category: eess.SP

TL;DR: 提出了一种名为"脏纸计算"的新型集成通信与计算方案，通过脏纸编码原理实现通信和计算的同步传输，在SIMO设置下显著优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 受Costa脏纸编码工作的启发，旨在实现离散数据符号传输和函数计算的同步进行，达到渐进无干扰的集成通信与计算。

Method: 采用脏纸编码原理，在发射端预消除计算符号，实现通信和计算的集成传输，在单输入多输出设置下进行评估。

Result: 仿真结果表明，该方法在数据检测和函数计算的均方误差性能方面显著优于现有最先进的集成通信与计算方案。

Conclusion: 脏纸计算方案成功实现了通信与计算的高效集成，验证了脏纸编码原理在集成通信与计算领域的应用价值。

Abstract: Inspired by Costa's pioneering work on dirty paper coding (DPC), this paper
proposes a novel scheme for integrated communication and computing (ICC), named
Computing on Dirty Paper, whereby the transmission of discrete data symbols for
communication, and over-the-air computation (AirComp) of nomographic functions
can be achieved simultaneously over common multiple-access channels. In
particular, the proposed scheme allows for the integration of communication and
computation in a manner that is asymptotically interference-free, by
precanceling the computing symbols at the transmitters (TXs) using DPC
principles. A simulation-based assessment of the proposed ICC scheme under a
single-input multiple-output (SIMO) setup is also offered, including the
evaluation of performance for data detection, and of mean-squared-error (MSE)
performance for function computation, over a block of symbols. The results
validate the proposed method and demonstrate its ability to significantly
outperform state-of-the-art (SotA) ICC schemes in terms of both bit error rate
(BER) and MSE.

</details>


### [16] [Joint Jammer Mitigation and Data Detection](https://arxiv.org/abs/2510.02021)
*Gian Marti,Christoph Studer*

Main category: eess.SP

TL;DR: 提出了一种新的MIMO干扰抑制方法JMD，通过联合估计干扰子空间和检测合法数据，无需专用训练阶段，能有效对抗智能和多天线干扰器。


<details>
  <summary>Details</summary>
Motivation: 现有干扰抑制方法需要专用训练阶段来估计干扰空间特征，这会降低通信速率，且易被智能干扰器规避。

Method: 开发了JMD框架，联合估计干扰子空间和检测合法数据，提出了SANDMAN和MAED两种算法，分别采用不同的信道估计方法。

Result: 广泛仿真验证了JMD在干扰抑制方面的有效性，能够应对动态变化的智能干扰器。

Conclusion: JMD方法消除了专用训练阶段的需求，提高了通信效率，同时能有效对抗智能和多天线干扰器。

Abstract: Multi-antenna (or MIMO) processing is a promising solution to the problem of
jammer mitigation. Existing methods mitigate the jammer based on an estimate of
its spatial signature that is acquired through a dedicated training phase. This
strategy has two main drawbacks: (i) it reduces the communication rate since no
data can be transmitted during the training phase and (ii) it can be evaded by
smart or multi-antenna jammers that do not transmit during the training phase
or that dynamically change their subspace through time-varying beamforming. To
address these drawbacks, we propose Joint jammer Mitigation and data Detection
(JMD), a novel paradigm for MIMO jammer mitigation. The core idea of JMD is to
estimate and remove the jammer interference subspace jointly with detecting the
legitimate transmit data over multiple time slots. Doing so removes the need
for a dedicated and rate-reducing training period while being able to mitigate
smart and dynamic multi-antenna jammers. We provide two JMD-type algorithms,
SANDMAN and MAED, that differ in the way they estimate the channels of the
legitimate transmitters and achieve different complexity-performance tradeoffs.
Extensive simulations demonstrate the efficacy of JMD for jammer mitigation.

</details>


### [17] [A Secure Affine Frequency Division Multiplexing for Wireless Communication Systems](https://arxiv.org/abs/2510.02023)
*Ping Wang,Zulin Wang,Yuanhan Ni,Qu Luo,Yuanfang Ma,Xiaosi Tian,Pei Xiao*

Main category: eess.SP

TL;DR: 提出了一种新型安全仿射频分复用系统，通过动态变化预啁啾参数来增强物理层安全性，采用参数域扩频而非数据域扩频，在保持可靠性和高频谱效率的同时提供额外安全性。


<details>
  <summary>Details</summary>
Motivation: AFDM在高移动性场景中表现出优越性能，但其波形参数提供的自由度尚未充分用于安全增强。现有设计缺乏动态参数变化机制来提升物理层安全性。

Method: 使用长周期伪噪声序列控制的码本动态生成AFDM预啁啾参数，采用参数域扩频方法，并提出了同步框架来解决时变参数在快速时变信道中的可靠快速同步问题。

Result: 理论推导证明未同步的窃听者无法消除时变参数的非线性影响，仿真结果展示了SE-AFDM系统在高移动性场景中的安全优势，硬件原型验证了同步框架的有效性。

Conclusion: SE-AFDM系统通过动态参数变化有效增强了物理层安全性，同时保持了系统性能和频谱效率，为高移动性通信场景提供了可靠的安全解决方案。

Abstract: Affine frequency division multiplexing (AFDM) has garnered significant
attention due to its superior performance in high-mobility scenarios, coupled
with multiple waveform parameters that provide greater degrees of freedom for
system design. This paper introduces a novel secure affine frequency division
multiplexing (SE-AFDM) system, which advances prior designs by dynamically
varying an AFDM pre-chirp parameter to enhance physical-layer security. In the
SE-AFDM system, the pre-chirp parameter is dynamically generated from a
codebook controlled by a long-period pseudo-noise (LPPN) sequence. Instead of
applying spreading in the data domain, our parameter-domain spreading approach
provides additional security while maintaining reliability and high spectrum
efficiency. We also propose a synchronization framework to solve the problem of
reliably and rapidly synchronizing the time-varying parameter in fast
time-varying channels. The theoretical derivations prove that unsynchronized
eavesdroppers cannot eliminate the nonlinear impact of the time-varying
parameter and further provide useful guidance for codebook design. Simulation
results demonstrate the security advantages of the proposed SE-AFDM system in
high-mobility scenarios, while our hardware prototype validates the
effectiveness of the proposed synchronization framework.

</details>


### [18] [Joint DOA and Attitude Sensing Based on Tri-Polarized Continuous Aperture Array](https://arxiv.org/abs/2510.02029)
*Haonan Si,Zhaolin Wang,Xiansheng Guo,Jin Zhang,Yuanwei Liu*

Main category: eess.SP

TL;DR: 提出使用三极化连续孔径阵列进行联合波达方向和姿态感知的方法，通过电磁信息理论和等效连续-离散变换技术实现准确估计，利用三极化信号的协方差构造频谱增强性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用三极化连续孔径阵列同时估计目标的波达方向和姿态信息，解决传统方法在连续孔径阵列中面临的挑战。

Method: 采用电磁信息理论建模三极化连续孔径阵列的接收信号，开发等效连续-离散变换技术进行子空间分解，利用三极化信号的自协方差和互协方差构造频谱，并提出两种姿态估计算法。

Result: 数值结果表明所提框架的可行性和优越性，能够实现准确的波达方向和姿态估计。

Conclusion: 提出的基于三极化连续孔径阵列的联合感知框架有效解决了波达方向和姿态的联合估计问题，理论分析表明姿态信息的可识别性依赖于先验目标快照的可用性。

Abstract: This paper investigates joint direction-of-arrival (DOA) and attitude sensing
using tri-polarized continuous aperture arrays (CAPAs). By employing
electromagnetic (EM) information theory, the spatially continuous received
signals in tri-polarized CAPA are modeled, thereby enabling accurate DOA and
attitude estimation. To facilitate subspace decomposition for continuous
operators, an equivalent continuous-discrete transformation technique is
developed. Moreover, both self- and cross-covariances of tri-polarized signals
are exploited to construct a tri-polarized spectrum, significantly enhancing
DOA estimation performance. Theoretical analyses reveal that the
identifiability of attitude information fundamentally depends on the
availability of prior target snapshots. Accordingly, two attitude estimation
algorithms are proposed: one capable of estimating partial attitude information
without prior knowledge, and the other achieving full attitude estimation when
such knowledge is available. Numerical results demonstrate the feasibility and
superiority of the proposed framework.

</details>


### [19] [Sensing-Secure ISAC: Ambiguity Function Engineering for Impairing Unauthorized Sensing](https://arxiv.org/abs/2510.02103)
*Kawon Han,Kaitao Meng,Christos Masouros*

Main category: eess.SP

TL;DR: 提出了一个感知安全的ISAC框架，通过在ISAC信号的模糊函数中引入人工缺陷，在非法感知接收器的距离剖面中插入人工目标，从而增加其距离估计模糊度，同时合法感知接收器可以通过失配滤波抑制这些伪影。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)的部署给授权感知带来了前所未有的安全漏洞，需要开发安全解决方案来防止非法被动雷达感知窃听者提取感知信息。

Method: 采用OFDM信号，设计结构化子载波功率分配方案来塑造安全自相关函数，插入周期性峰值来误导非法感知的距离估计；引入峰值旁瓣电平和积分旁瓣电平作为感知安全性能指标；通过凸优化问题最大化ISAC性能同时保证特定感知安全水平。

Result: 数值结果验证了所提出的感知安全ISAC信号的有效性，能够降低非法感知的目标估计性能，同时保持合法感知的性能。

Conclusion: 该框架成功实现了感知安全，通过人工模糊函数缺陷有效保护了ISAC系统的感知信息安全，同时分析了通信、合法感知和感知安全之间的三方权衡关系。

Abstract: The deployment of integrated sensing and communication (ISAC) brings along
unprecedented vulnerabilities to authorized sensing, necessitating the
development of secure solutions. Sensing parameters are embedded within the
target-reflected signal leaked to unauthorized passive radar sensing
eavesdroppers (Eve), implying that they can silently extract sensory
information without prior knowledge of the information data. To overcome this
limitation, we propose a sensing-secure ISAC framework that ensures secure
target detection and estimation for the legitimate system, while obfuscating
unauthorized sensing without requiring any prior knowledge of Eve. By
introducing artificial imperfections into the ambiguity function (AF) of ISAC
signals, we introduce artificial targets into Eve's range profile which
increase its range estimation ambiguity. In contrast, the legitimate sensing
receiver (Alice) can suppress these AF artifacts using mismatched filtering,
albeit at the expense of signal-to-noise ratio (SNR) loss. Employing an OFDM
signal, a structured subcarrier power allocation scheme is designed to shape
the secure autocorrelation function (ACF), inserting periodic peaks to mislead
Eve's range estimation and degrade target detection performance. To quantify
the sensing security, we introduce peak sidelobe level (PSL) and integrated
sidelobe level (ISL) as key performance metrics. Then, we analyze the three-way
trade-offs between communication, legitimate sensing, and sensing security,
highlighting the impact of the proposed sensing-secure ISAC signaling on system
performance. We formulate a convex optimization problem to maximize ISAC
performance while guaranteeing a certain sensing security level. Numerical
results validate the effectiveness of the proposed sensing-secure ISAC
signaling, demonstrating its ability to degrade Eve's target estimation while
preserving Alice's performance.

</details>


### [20] [Unlocking Symbol-Level Precoding Efficiency Through Tensor Equivariant Neural Network](https://arxiv.org/abs/2510.02108)
*Jinshuo Zhang,Yafei Wang,Xinping Yi,Wenjin Wang,Shi Jin,Symeon Chatzinotas,Björn Ottersten*

Main category: eess.SP

TL;DR: 提出基于张量等变性的端到端深度学习框架，显著降低符号级预编码的计算复杂度，同时保持性能优势


<details>
  <summary>Details</summary>
Motivation: 符号级预编码虽然能提供性能增益，但其高计算复杂度成为瓶颈，需要开发低复杂度解决方案

Method: 利用最优符号级预编码的闭式解结构及其张量等变性，设计基于注意力的TE模块，实现线性计算复杂度

Result: 所提框架捕获了最优SLP的大部分性能增益，相比传统方法实现约80倍加速，并在用户数和符号块长度上具有强泛化能力

Conclusion: 基于张量等变性的深度学习框架能有效解决符号级预编码的高复杂度问题，在保持性能的同时显著提升计算效率

Abstract: Although symbol-level precoding (SLP) based on constructive interference (CI)
exploitation offers performance gains, its high complexity remains a
bottleneck. This paper addresses this challenge with an end-to-end deep
learning (DL) framework with low inference complexity that leverages the
structure of the optimal SLP solution in the closed-form and its inherent
tensor equivariance (TE), where TE denotes that a permutation of the input
induces the corresponding permutation of the output. Building upon the
computationally efficient model-based formulations, as well as their known
closed-form solutions, we analyze their relationship with linear precoding (LP)
and investigate the corresponding optimality condition. We then construct a
mapping from the problem formulation to the solution and prove its TE, based on
which the designed networks reveal a specific parameter-sharing pattern that
delivers low computational complexity and strong generalization. Leveraging
these, we propose the backbone of the framework with an attention-based TE
module, achieving linear computational complexity. Furthermore, we demonstrate
that such a framework is also applicable to imperfect CSI scenarios, where we
design a TE-based network to map the CSI, statistics, and symbols to auxiliary
variables. Simulation results show that the proposed framework captures
substantial performance gains of optimal SLP, while achieving an approximately
80-times speedup over conventional methods and maintaining strong
generalization across user numbers and symbol block lengths.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [21] [Joint Optimization of Speaker and Spoof Detectors for Spoofing-Robust Automatic Speaker Verification](https://arxiv.org/abs/2510.01818)
*Oğuzhan Kurnaz,Jagabandhu Mishra,Tomi H. Kinnunen,Cemal Hanilçi*

Main category: eess.AS

TL;DR: 该论文研究了抗欺骗的说话人验证系统，通过可训练的后端分类器优化集成说话人和欺骗检测子系统，在ASVspoof 5数据集上实现了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的SASV系统通常独立训练说话人和欺骗检测子系统，然后在嵌入、分数或决策层面进行融合，缺乏对SASV特定性能指标的端到端优化。

Method: 采用模块化设计，将说话人检测（加权余弦评分）和欺骗检测（SSL-AASIST）子系统的输出通过可训练的后端分类器集成，直接优化SASV性能指标（a-DCF）作为训练目标。

Result: 非线性分数融合比线性融合持续改善a-DCF；结合加权余弦评分和SSL-AASIST的方法实现了最先进性能，min a-DCF降至0.196，SPF-EER降至7.6%。

Conclusion: 模块化设计、校准集成和任务对齐优化对于推进鲁棒且可解释的SASV系统至关重要。

Abstract: Spoofing-robust speaker verification (SASV) combines the tasks of speaker and
spoof detection to authenticate speakers under adversarial settings. Many SASV
systems rely on fusion of speaker and spoof cues at embedding, score or
decision levels, based on independently trained subsystems. In this study, we
respect similar modularity of the two subsystems, by integrating their outputs
using trainable back-end classifiers. In particular, we explore various
approaches for directly optimizing the back-end for the recently-proposed SASV
performance metric (a-DCF) as a training objective. Our experiments on the
ASVspoof 5 dataset demonstrate two important findings: (i) nonlinear score
fusion consistently improves a-DCF over linear fusion, and (ii) the combination
of weighted cosine scoring for speaker detection with SSL-AASIST for spoof
detection achieves state-of-the-art performance, reducing min a-DCF to 0.196
and SPF-EER to 7.6%. These contributions highlight the importance of modular
design, calibrated integration, and task-aligned optimization for advancing
robust and interpretable SASV systems.

</details>


### [22] [SLAP: Learning Speaker and Health-Related Representations from Natural Language Supervision](https://arxiv.org/abs/2510.01860)
*Angelika Ando,Auguste Crabeil,Adrien Lesage,Rachid Riad*

Main category: eess.AS

TL;DR: SLAP是首个通过对比学习将语音与说话者和健康元数据的自然语言描述对齐的音频基础模型，在38个二元分类任务上实现零样本评估平均F1得分62.9%，比CLAP提升48%，并在未见过的语言和临床人群中表现出强大的OOD泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前没有音频基础模型支持零样本或OOD泛化到人口统计、音质和健康等副语言信息任务，需要开发能够对齐语音与自然语言描述的模型。

Method: SLAP结合视觉Transformer音频编码器和文本编码器，通过对比学习在9个数据集的3400多小时语音数据上进行训练，使用多样化的说话者标注。

Result: 在14个数据集的38个二元分类任务上，SLAP零样本评估平均F1达62.9%，比CLAP提升48%；线性探测微调后达69.3% F1，在健康任务上达到57.9% F1，超越更大的基础模型。

Conclusion: SLAP证明了通过对比学习对齐语音与自然语言描述的有效性，在零样本和OOD泛化方面表现优异，特别是在健康相关任务上达到最佳性能。

Abstract: Speech encodes paralinguistic information such as demographics, voice
quality, and health. Yet no audio foundation model supports zero-shot or
out-of-distribution (OOD) generalization to these tasks. We introduce SLAP
(Speaker contrastive Language-Audio Pretraining), the first model aligning
speech with natural language descriptions of speaker and health metadata
through contrastive learning. SLAP combines a Vision Transformer audio encoder
with text encoders, trained on more than 3400 hours across 9 datasets with
diverse speaker annotations. We evaluated on 38 binary classification tasks
spanning demographics, voice characteristics, and clinical assessments across
14 datasets in 7 languages. SLAP achieves 62.9% average F1 in zero-shot
evaluation, a 48% relative improvement over CLAP (42.4%), while demonstrating
strong OOD generalization to unseen languages and clinical populations. When
fine-tuned with linear probing, SLAP reaches 69.3% F1 overall and achieves
best-in-class performance on health tasks (57.9% F1), surpassing larger
foundation models.

</details>


### [23] [Clustering of Acoustic Environments with Variational Autoencoders for Hearing Devices](https://arxiv.org/abs/2510.01940)
*Luan Vinícius Fiorio,Ivana Nikoloska,Wim van Houtum,Ronald M. Aarts*

Main category: eess.AS

TL;DR: 提出了一种基于变分自编码器(VAE)的无监督声学环境聚类方法，特别针对助听器场景，使用Gumbel-Softmax重参数化和时间上下文窗口方案。


<details>
  <summary>Details</summary>
Motivation: 传统声学环境分类方法无法提取高维数据的有效表示，监督学习受限于标签可用性，且人工标签不一定反映声学场景的真实结构。

Method: 使用变分自编码器进行无监督聚类，采用Gumbel-Softmax重参数化处理分类潜在变量，并设计时间上下文窗口方案以适应真实助听器场景。

Result: 在语音数字聚类任务中所有变分方法都成功，但在城市声景聚类中，只有提出的分类模型实现了有效的聚类性能。

Conclusion: 提出的分类VAE模型在城市声学场景聚类中表现优异，其分类特性使其更适合处理具有时间和频率重叠的复杂声学环境。

Abstract: Particularly in hearing devices, the environmental context is taken into
account for audio processing, often through classification. Traditional
acoustic environment classification relies on classical algorithms, which are
unable to extract meaningful representations of high-dimensionality data, or on
supervised learning, being limited by the availability of labels. Knowing that
human-imposed labels do not always reflect the true structure of acoustic
scenes, we explore the (unsupervised) clustering of acoustic environments using
variational autoencoders (VAEs), presenting a structured latent space suitable
for the task. We propose a VAE model for categorical latent clustering
employing a Gumbel-Softmax reparameterization with a time-context windowing
scheme, tailored for real-world hearing device scenarios. Additionally, general
adaptations on VAE architectures for audio clustering are also proposed. The
approaches are validated through the clustering of spoken digits, a simpler
task where labels are meaningful, and urban soundscapes, which recordings
present strong overlap in time and frequency. While all variational methods
succeeded when clustering spoken digits, only the proposed model achieved
effective clustering performance on urban acoustic scenes, given its
categorical nature.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [24] [RealClass: A Framework for Classroom Speech Simulation with Public Datasets and Game Engines](https://arxiv.org/abs/2510.01462)
*Ahmed Adel Attia,Jing Liu,Carol Espy Wilson*

Main category: cs.SD

TL;DR: 提出了一种使用游戏引擎合成教室噪声和房间脉冲响应的方法，并创建了RealClass数据集，该数据集结合了合成的教室噪声和从公开语料库编译的教室语音数据。


<details>
  <summary>Details</summary>
Motivation: 大规模教室语音数据的稀缺阻碍了教育领域AI语音模型的发展，现有教室数据集有限且不公开，缺乏专门的教室噪声或RIR语料库限制了标准数据增强技术的使用。

Method: 使用游戏引擎合成教室噪声和RIRs的可扩展方法，构建RealClass数据集，将合成的教室噪声语料库与从公开语料库编译的教室语音数据集相结合。

Result: 实验表明，RealClass在干净和嘈杂语音条件下都能很好地近似真实教室语音。

Conclusion: RealClass在缺乏丰富真实教室语音的情况下是一个有价值的资源，其方法框架可扩展到教室以外的其他领域。

Abstract: The scarcity of large-scale classroom speech data has hindered the
development of AI-driven speech models for education. Classroom datasets remain
limited and not publicly available, and the absence of dedicated classroom
noise or Room Impulse Response (RIR) corpora prevents the use of standard data
augmentation techniques.
  In this paper, we introduce a scalable methodology for synthesizing classroom
noise and RIRs using game engines, a versatile framework that can extend to
other domains beyond the classroom. Building on this methodology, we present
RealClass, a dataset that combines a synthesized classroom noise corpus with a
classroom speech dataset compiled from publicly available corpora. The speech
data pairs a children's speech corpus with instructional speech extracted from
YouTube videos to approximate real classroom interactions in clean conditions.
Experiments on clean and noisy speech show that RealClass closely approximates
real classroom speech, making it a valuable asset in the absence of abundant
real classroom speech.

</details>


### [25] [Emotional Text-To-Speech Based on Mutual-Information-Guided Emotion-Timbre Disentanglement](https://arxiv.org/abs/2510.01722)
*Jianing Yang,Sheng Li,Takahiro Shinozaki,Yuki Saito,Hiroshi Saruwatari*

Main category: cs.SD

TL;DR: 提出了一种新颖的情感文本转语音方法，通过细粒度的音素级情感嵌入预测和风格解耦，能够捕捉参考语音的细微声学细节。


<details>
  <summary>Details</summary>
Motivation: 当前的情感TTS和风格转换方法依赖参考编码器来控制全局风格或情感向量，但无法捕捉参考语音的细微声学细节。

Method: 采用风格解耦方法指导两个特征提取器，减少音色和情感特征之间的互信息，有效分离参考语音中的不同风格成分。

Result: 实验结果表明，该方法在生成自然且情感丰富的语音方面优于基线TTS系统。

Conclusion: 这项工作展示了在情感TTS系统中使用解耦和细粒度表示在提升质量和灵活性方面的潜力。

Abstract: Current emotional Text-To-Speech (TTS) and style transfer methods rely on
reference encoders to control global style or emotion vectors, but do not
capture nuanced acoustic details of the reference speech. To this end, we
propose a novel emotional TTS method that enables fine-grained phoneme-level
emotion embedding prediction while disentangling intrinsic attributes of the
reference speech. The proposed method employs a style disentanglement method to
guide two feature extractors, reducing mutual information between timbre and
emotion features, and effectively separating distinct style components from the
reference speech. Experimental results demonstrate that our method outperforms
baseline TTS systems in generating natural and emotionally rich speech. This
work highlights the potential of disentangled and fine-grained representations
in advancing the quality and flexibility of emotional TTS systems.

</details>


### [26] [SingMOS-Pro: An Comprehensive Benchmark for Singing Quality Assessment](https://arxiv.org/abs/2510.01812)
*Yuxun Tang,Lan Liu,Wenhao Feng,Yiwen Zhao,Jionghao Han,Yifeng Yu,Jiatong Shi,Qin Jin*

Main category: cs.SD

TL;DR: 提出了SingMOS-Pro数据集，用于自动歌唱质量评估，相比之前的SingMOS版本增加了歌词、旋律和整体质量的标注，包含7,981个歌唱片段，由专业标注者评分。


<details>
  <summary>Details</summary>
Motivation: 歌唱声音生成技术快速发展，但评估歌唱质量仍然是一个关键挑战。主观评估成本高且耗时，现有客观指标只能捕捉有限的感知方面。

Method: 构建包含7,981个歌唱片段的数据集，这些片段由41个模型在12个数据集上生成，每个片段至少获得5位专业标注者的评分，涵盖歌词、旋律和整体质量三个维度。

Result: 创建了一个覆盖更广、多样性更强的歌唱质量评估数据集，并基于该数据集对几种广泛使用的评估方法进行了基准测试。

Conclusion: SingMOS-Pro为歌唱质量评估研究提供了可靠的数据基础和实用参考，推动了该领域的发展。

Abstract: Singing voice generation progresses rapidly, yet evaluating singing quality
remains a critical challenge. Human subjective assessment, typically in the
form of listening tests, is costly and time consuming, while existing objective
metrics capture only limited perceptual aspects. In this work, we introduce
SingMOS-Pro, a dataset for automatic singing quality assessment. Building on
our preview version SingMOS, which provides only overall ratings, SingMOS-Pro
expands annotations of the additional part to include lyrics, melody, and
overall quality, offering broader coverage and greater diversity. The dataset
contains 7,981 singing clips generated by 41 models across 12 datasets,
spanning from early systems to recent advances. Each clip receives at least
five ratings from professional annotators, ensuring reliability and
consistency. Furthermore, we explore how to effectively utilize MOS data
annotated under different standards and benchmark several widely used
evaluation methods from related tasks on SingMOS-Pro, establishing strong
baselines and practical references for future research. The dataset can be
accessed at https://huggingface.co/datasets/TangRain/SingMOS-Pro.

</details>


### [27] [HRTFformer: A Spatially-Aware Transformer for Personalized HRTF Upsampling in Immersive Audio Rendering](https://arxiv.org/abs/2510.01891)
*Xuyi Hu,Jian Li,Shaojie Zhang,Stefan Goetz,Lorenzo Picinali,Ozgur B. Akan,Aidan O. T. Hogg*

Main category: cs.SD

TL;DR: 提出了一种基于Transformer的HRTF空间上采样方法，利用注意力机制捕捉HRTF球面的空间相关性，显著提高了从稀疏测量重建高分辨率HRTF的准确性。


<details>
  <summary>Details</summary>
Motivation: 个性化HRTF对于沉浸式音频应用至关重要，但大规模创建个性化HRTF不切实际，因为HRTF测量过程复杂。现有机器学习方法在高上采样因子下存在长距离空间一致性和泛化问题。

Method: 在球谐域中工作，提出基于Transformer的架构，引入邻居差异损失来增强空间一致性，促进幅度平滑性。

Result: 实验表明，该方法在生成真实、高保真HRTF方面大幅超越了领先方法，通过感知定位模型和客观频谱失真指标进行评估。

Conclusion: 所提出的Transformer架构能够有效解决HRTF上采样中的空间一致性问题，为大规模个性化HRTF应用提供了实用解决方案。

Abstract: Personalized Head-Related Transfer Functions (HRTFs) are starting to be
introduced in many commercial immersive audio applications and are crucial for
realistic spatial audio rendering. However, one of the main hesitations
regarding their introduction is that creating personalized HRTFs is impractical
at scale due to the complexities of the HRTF measurement process. To mitigate
this drawback, HRTF spatial upsampling has been proposed with the aim of
reducing measurements required. While prior work has seen success with
different machine learning (ML) approaches, these models often struggle with
long-range spatial consistency and generalization at high upsampling factors.
In this paper, we propose a novel transformer-based architecture for HRTF
upsampling, leveraging the attention mechanism to better capture spatial
correlations across the HRTF sphere. Working in the spherical harmonic (SH)
domain, our model learns to reconstruct high-resolution HRTFs from sparse input
measurements with significantly improved accuracy. To enhance spatial
coherence, we introduce a neighbor dissimilarity loss that promotes magnitude
smoothness, yielding more realistic upsampling. We evaluate our method using
both perceptual localization models and objective spectral distortion metrics.
Experiments show that our model surpasses leading methods by a substantial
margin in generating realistic, high-fidelity HRTFs.

</details>


### [28] [MelCap: A Unified Single-Codebook Neural Codec for High-Fidelity Audio Compression](https://arxiv.org/abs/2510.01903)
*Jingyi Li,Zhiyuan Zhao,Yunfei Liu,Lijian Lin,Ye Zhu,Jiahao Wu,Qiuqiang Kong,Yu Li*

Main category: cs.SD

TL;DR: MelCap是一个统一的神经音频编解码器，使用单一码本处理语音、音乐和通用声音，通过两阶段重构实现高质量音频压缩。


<details>
  <summary>Details</summary>
Motivation: 现有神经音频编解码器要么使用单一量化器仅处理语音，要么使用多个量化器但不适合下游任务，需要一种统一且高效的解决方案。

Method: 将音频重构分为两阶段：第一阶段将音频转换为mel频谱图并用2D标记器压缩量化；第二阶段使用声码器从mel离散标记中恢复波形。应用感知损失减少频谱图重构中的过平滑伪影。

Result: 客观和主观评估表明，MelCap在质量上可与最先进的多码本编解码器相媲美，同时保持了单码本设计的计算简单性。

Conclusion: MelCap提供了一个有效的下游任务表示，在保持计算简单性的同时实现了高质量的音频压缩。

Abstract: Neural audio codecs have recently emerged as powerful tools for high-quality
and low-bitrate audio compression, leveraging deep generative models to learn
latent representations of audio signals. However, existing approaches either
rely on a single quantizer that only processes speech domain, or on multiple
quantizers that are not well suited for downstream tasks. To address this
issue, we propose MelCap, a unified "one-codebook-for-all" neural codec that
effectively handles speech, music, and general sound. By decomposing audio
reconstruction into two stages, our method preserves more acoustic details than
previous single-codebook approaches, while achieving performance comparable to
mainstream multi-codebook methods. In the first stage, audio is transformed
into mel-spectrograms, which are compressed and quantized into compact single
tokens using a 2D tokenizer. A perceptual loss is further applied to mitigate
the over-smoothing artifacts observed in spectrogram reconstruction. In the
second stage, a Vocoder recovers waveforms from the mel discrete tokens in a
single forward pass, enabling real-time decoding. Both objective and subjective
evaluations demonstrate that MelCap achieves quality on comparable to
state-of-the-art multi-codebook codecs, while retaining the computational
simplicity of a single-codebook design, thereby providing an effective
representation for downstream tasks.

</details>


### [29] [Exploring Resolution-Wise Shared Attention in Hybrid Mamba-U-Nets for Improved Cross-Corpus Speech Enhancement](https://arxiv.org/abs/2510.01958)
*Nikolai Lund Kühne,Jesper Jensen,Jan Østergaard,Zheng-Hua Tan*

Main category: cs.SD

TL;DR: RWSA-MambaUNet是一种结合Mamba和多头注意力的U-Net结构语音增强模型，在跨语料库泛化性能上达到最先进水平，同时大幅减少模型参数和计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 受Mamba与注意力机制结合在语音增强中展现出的优异跨语料库泛化性能，以及Mamba在U-Net结构中实现最先进增强性能同时减少模型大小和计算复杂度的启发。

Method: 提出RWSA-MambaUNet混合模型，在U-Net结构中结合Mamba和多头注意力，采用分辨率共享注意力机制，在对应的时间和频率分辨率层间共享注意力。

Result: 在DNS 2020和EARS-WHAM_v2两个域外测试集上取得最先进的泛化性能，最小模型在多个指标上超越所有基线，同时使用不到一半的模型参数和部分FLOPs。

Conclusion: RWSA-MambaUNet证明了结合Mamba和注意力机制的U-Net结构在语音增强任务中的有效性，特别是在跨语料库泛化性能和计算效率方面具有显著优势。

Abstract: Recent advances in speech enhancement have shown that models combining Mamba
and attention mechanisms yield superior cross-corpus generalization
performance. At the same time, integrating Mamba in a U-Net structure has
yielded state-of-the-art enhancement performance, while reducing both model
size and computational complexity. Inspired by these insights, we propose
RWSA-MambaUNet, a novel and efficient hybrid model combining Mamba and
multi-head attention in a U-Net structure for improved cross-corpus
performance. Resolution-wise shared attention (RWSA) refers to layerwise
attention-sharing across corresponding time- and frequency resolutions. Our
best-performing RWSA-MambaUNet model achieves state-of-the-art generalization
performance on two out-of-domain test sets. Notably, our smallest model
surpasses all baselines on the out-of-domain DNS 2020 test set in terms of
PESQ, SSNR, and ESTOI, and on the out-of-domain EARS-WHAM_v2 test set in terms
of SSNR, ESTOI, and SI-SDR, while using less than half the model parameters and
a fraction of the FLOPs.

</details>


### [30] [Bias beyond Borders: Global Inequalities in AI-Generated Music](https://arxiv.org/abs/2510.01963)
*Ahmet Solak,Florian Grötschla,Luca A. Lanzendörfer,Roger Wattenhofer*

Main category: cs.SD

TL;DR: GlobalDISCO数据集揭示了音乐生成模型在地区、语言和文化资源分布上的显著偏见，高资源与低资源地区之间存在音乐质量和参考音乐对齐度的大幅差异。


<details>
  <summary>Details</summary>
Motivation: 解决音乐生成模型在跨国家、语言、文化和音乐流派方面偏见研究不足的问题，以及缺乏捕捉全球音乐多样性的数据集和基准。

Method: 构建GlobalDISCO大规模数据集，包含73k由商业音乐生成模型生成的音乐轨道，配以93k LAION-DISCO-12M中的参考轨道链接，涵盖147种语言和79个国家。

Result: 发现高资源与低资源地区在音乐质量和参考音乐对齐度上存在巨大差异，主流与地理小众流派间模型性能差异显著，某些情况下模型为区域流派生成的音乐更接近主流风格分布。

Conclusion: 音乐生成模型存在明显的资源分布偏见，需要更多关注全球音乐多样性以改善模型公平性。

Abstract: While recent years have seen remarkable progress in music generation models,
research on their biases across countries, languages, cultures, and musical
genres remains underexplored. This gap is compounded by the lack of datasets
and benchmarks that capture the global diversity of music. To address these
challenges, we introduce GlobalDISCO, a large-scale dataset consisting of 73k
music tracks generated by state-of-the-art commercial generative music models,
along with paired links to 93k reference tracks in LAION-DISCO-12M. The dataset
spans 147 languages and includes musical style prompts extracted from
MusicBrainz and Wikipedia. The dataset is globally balanced, representing
musical styles from artists across 79 countries and five continents. Our
evaluation reveals large disparities in music quality and alignment with
reference music between high-resource and low-resource regions. Furthermore, we
find marked differences in model performance between mainstream and
geographically niche genres, including cases where models generate music for
regional genres that more closely align with the distribution of mainstream
styles.

</details>


### [31] [Multi-bit Audio Watermarking](https://arxiv.org/abs/2510.01968)
*Luca A. Lanzendörfer,Kyle Fearne,Florian Grötschla,Roger Wattenhofer*

Main category: cs.SD

TL;DR: Timbru是一种后处理音频水印模型，通过在预训练音频VAE的潜在空间中进行梯度优化来添加不可感知的扰动，无需训练嵌入器-检测器模型，在鲁棒性和不可感知性之间实现了最佳平衡。


<details>
  <summary>Details</summary>
Motivation: 现有音频水印方法在鲁棒性和不可感知性之间存在权衡问题，需要训练复杂的嵌入器-检测器模型。本文旨在开发一种无需训练、数据集无关的高效音频水印方法。

Method: 对44.1kHz立体声音乐片段，在预训练音频VAE的潜在空间中进行逐音频梯度优化，添加不可感知的扰动，使用消息和感知损失的组合作为指导，通过预训练CLAP模型提取水印。

Result: 在MUSDB18-HQ数据集上评估16位水印，相比AudioSeal、WavMark和SilentCipher，在各种攻击下（滤波、噪声、压缩、重采样、裁剪、再生）获得了最佳平均比特错误率，同时保持了感知质量。

Conclusion: Timbru展示了一种高效、数据集无关的路径，实现了不可感知的音频水印，无需训练嵌入器-检测器模型即可达到最先进的鲁棒性和不可感知性权衡。

Abstract: We present Timbru, a post-hoc audio watermarking model that achieves
state-of-the-art robustness and imperceptibility trade-offs without training an
embedder-detector model. Given any 44.1 kHz stereo music snippet, our method
performs per-audio gradient optimization to add imperceptible perturbations in
the latent space of a pretrained audio VAE, guided by a combined message and
perceptual loss. The watermark can then be extracted using a pretrained CLAP
model. We evaluate 16-bit watermarking on MUSDB18-HQ against AudioSeal,
WavMark, and SilentCipher across common filtering, noise, compression,
resampling, cropping, and regeneration attacks. Our approach attains the best
average bit error rates, while preserving perceptual quality, demonstrating an
efficient, dataset-free path to imperceptible audio watermarking.

</details>


### [32] [SoundReactor: Frame-level Online Video-to-Audio Generation](https://arxiv.org/abs/2510.02110)
*Koichi Saito,Julian Tanke,Christian Simon,Masato Ishii,Kazuki Shimada,Zachary Novack,Zhi Zhong,Akio Hayakawa,Takashi Shibuya,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: 提出了首个帧级在线视频到音频生成框架SoundReactor，能够在没有未来视频帧的情况下自回归生成音频，实现低延迟的实时音频生成。


<details>
  <summary>Details</summary>
Motivation: 现有V2A模型需要整个视频序列或帧块作为输入，限制了在直播内容创作和生成世界模型等交互式应用中的使用。

Method: 使用基于解码器的因果变换器处理连续音频潜在表示，通过DINOv2视觉编码器提取网格特征并聚合为每帧单个token，采用扩散预训练和一致性微调加速解码。

Result: 在AAA游戏视频基准测试中成功生成语义和时间对齐的高质量全频段立体声音频，单H100 GPU上实现低延迟（26.3-31.5ms）。

Conclusion: SoundReactor是首个专门为帧级在线V2A生成设计的有效框架，在保持音频质量的同时实现了实时性能。

Abstract: Prevailing Video-to-Audio (V2A) generation models operate offline, assuming
an entire video sequence or chunks of frames are available beforehand. This
critically limits their use in interactive applications such as live content
creation and emerging generative world models. To address this gap, we
introduce the novel task of frame-level online V2A generation, where a model
autoregressively generates audio from video without access to future video
frames. Furthermore, we propose SoundReactor, which, to the best of our
knowledge, is the first simple yet effective framework explicitly tailored for
this task. Our design enforces end-to-end causality and targets low per-frame
latency with audio-visual synchronization. Our model's backbone is a
decoder-only causal transformer over continuous audio latents. For vision
conditioning, it leverages grid (patch) features extracted from the smallest
variant of the DINOv2 vision encoder, which are aggregated into a single token
per frame to maintain end-to-end causality and efficiency. The model is trained
through a diffusion pre-training followed by consistency fine-tuning to
accelerate the diffusion head decoding. On a benchmark of diverse gameplay
videos from AAA titles, our model successfully generates semantically and
temporally aligned, high-quality full-band stereo audio, validated by both
objective and human evaluations. Furthermore, our model achieves low per-frame
waveform-level latency (26.3ms with the head NFE=1, 31.5ms with NFE=4) on
30FPS, 480p videos using a single H100. Demo samples are available at
https://koichi-saito-sony.github.io/soundreactor/.

</details>


### [33] [Go witheFlow: Real-time Emotion Driven Audio Effects Modulation](https://arxiv.org/abs/2510.02171)
*Edmund Dervakos,Spyridon Kantarelis,Vassilis Lyberatos,Jason Liartis,Giorgos Stamou*

Main category: cs.SD

TL;DR: 开发了witheFlow系统，通过生物信号和音频特征实时调制音频效果来增强音乐表演，实现人机协作。


<details>
  <summary>Details</summary>
Motivation: 音乐表演是人类特有的情感表达活动，机器无法真正体验情感，但可以作为协作工具来增强人类表演。

Method: 设计轻量级开源系统，从生物信号和音频中提取特征，实时自动调制音频效果，可在笔记本电脑上本地运行。

Result: 目前处于概念验证阶段，系统能够基于传感器和音频特征实时调整音频效果。

Conclusion: witheFlow系统为探索人机协作音乐表演提供了可行方案，通过技术手段增强表演的情感表达。

Abstract: Music performance is a distinctly human activity, intrinsically linked to the
performer's ability to convey, evoke, or express emotion. Machines cannot
perform music in the human sense; they can produce, reproduce, execute, or
synthesize music, but they lack the capacity for affective or emotional
experience. As such, music performance is an ideal candidate through which to
explore aspects of collaboration between humans and machines. In this paper, we
introduce the witheFlow system, designed to enhance real-time music performance
by automatically modulating audio effects based on features extracted from both
biosignals and the audio itself. The system, currently in a proof-of-concept
phase, is designed to be lightweight, able to run locally on a laptop, and is
open-source given the availability of a compatible Digital Audio Workstation
and sensors.

</details>


### [34] [High-Fidelity Speech Enhancement via Discrete Audio Tokens](https://arxiv.org/abs/2510.02187)
*Luca A. Lanzendörfer,Frédéric Berdoz,Antonis Asonitis,Roger Wattenhofer*

Main category: cs.SD

TL;DR: DAC-SE1是一个基于语言模型的简化语音增强框架，使用离散高分辨率音频表示，在保持语义连贯性的同时保留精细声学细节，超越了现有最先进的自回归语音增强方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归transformer语音增强方法虽然表现良好，但依赖复杂的多阶段流程和低采样率编解码器，限制了它们只能用于特定任务的语音增强。

Method: 引入DAC-SE1框架，利用离散高分辨率音频表示，简化了基于语言模型的语音增强流程。

Result: DAC-SE1在客观感知指标和MUSHRA人类评估中都超越了最先进的自回归语音增强方法。

Conclusion: 该工作为可扩展、统一和高质量的语音增强研究提供了支持，并发布了代码库和模型检查点。

Abstract: Recent autoregressive transformer-based speech enhancement (SE) methods have
shown promising results by leveraging advanced semantic understanding and
contextual modeling of speech. However, these approaches often rely on complex
multi-stage pipelines and low sampling rate codecs, limiting them to narrow and
task-specific speech enhancement. In this work, we introduce DAC-SE1, a
simplified language model-based SE framework leveraging discrete
high-resolution audio representations; DAC-SE1 preserves fine-grained acoustic
details while maintaining semantic coherence. Our experiments show that DAC-SE1
surpasses state-of-the-art autoregressive SE methods on both objective
perceptual metrics and in a MUSHRA human evaluation. We release our codebase
and model checkpoints to support further research in scalable, unified, and
high-quality speech enhancement.

</details>

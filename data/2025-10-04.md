<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 20]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.SD](#cs.SD) [Total: 11]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [JaneEye: A 12-nm 2K-FPS 18.9-$μ$J/Frame Event-based Eye Tracking Accelerator](https://arxiv.org/abs/2510.01213)
*Tao Han,Ang Li,Qinyu Chen,Chang Gao*

Main category: eess.SP

TL;DR: JaneEye是一个基于事件相机的节能眼动追踪硬件加速器，专为可穿戴设备设计，通过新颖的ConvJANET层和硬件优化，在保持高精度的同时显著降低计算复杂度和功耗。


<details>
  <summary>Details</summary>
Motivation: 传统帧式眼动追踪系统在扩展现实(XR)应用中难以满足高精度、低延迟和能效的严格要求，而事件相机提供了超高的时间分辨率和低功耗的替代方案。

Method: 提出超轻量级神经网络架构，采用新颖的ConvJANET层简化传统ConvLSTM，仅保留遗忘门，将计算复杂度减半；使用自定义线性激活函数近似和定点量化；通过软硬件协同设计实现ASIC实现。

Result: 在3ET+数据集上实现2.45像素误差的高精度，仅使用17.6K参数，事件帧率高达1250 Hz；12nm ASIC在400MHz下运行，端到端延迟0.5ms（相当于2000 FPS），能效为18.9 μJ/帧。

Conclusion: JaneEye为下一代XR可穿戴设备设定了低功耗、高性能眼动追踪解决方案的新基准。

Abstract: Eye tracking has become a key technology for gaze-based interactions in
Extended Reality (XR). However, conventional frame-based eye-tracking systems
often fall short of XR's stringent requirements for high accuracy, low latency,
and energy efficiency. Event cameras present a compelling alternative, offering
ultra-high temporal resolution and low power consumption. In this paper, we
present JaneEye, an energy-efficient event-based eye-tracking hardware
accelerator designed specifically for wearable devices, leveraging sparse,
high-temporal-resolution event data. We introduce an ultra-lightweight neural
network architecture featuring a novel ConvJANET layer, which simplifies the
traditional ConvLSTM by retaining only the forget gate, thereby halving
computational complexity without sacrificing temporal modeling capability. Our
proposed model achieves high accuracy with a pixel error of 2.45 on the 3ET+
dataset, using only 17.6K parameters, with up to 1250 Hz event frame rate. To
further enhance hardware efficiency, we employ custom linear approximations of
activation functions (hardsigmoid and hardtanh) and fixed-point quantization.
Through software-hardware co-design, our 12-nm ASIC implementation operates at
400 MHz, delivering an end-to-end latency of 0.5 ms (equivalent to 2000 Frames
Per Second (FPS)) at an energy efficiency of 18.9 $\mu$J/frame. JaneEye sets a
new benchmark in low-power, high-performance eye-tracking solutions suitable
for integration into next-generation XR wearables.

</details>


### [2] [Satellite Assignment Policy Learning for Coexistence in LEO Networks](https://arxiv.org/abs/2510.01408)
*Jeong Min Kong,Ian P. Roberts*

Main category: eess.SP

TL;DR: 该论文提出了一种基于图结构学习的算法，用于推断低地球轨道卫星系统中主系统的卫星分配策略，以帮助次系统避免对主用户造成过度干扰。


<details>
  <summary>Details</summary>
Motivation: 在非独占频段分配的LEO卫星系统中，次系统需要避免对主用户造成干扰，但主系统的卫星分配策略未公开。因此需要开发方法来推断这些策略。

Method: 提出端到端的图结构学习算法，利用有限的历史数据学习最高仰角主卫星分配策略，能够将主卫星坐标直接映射到主用户的分配决策。

Result: 仿真结果显示该方法优于最佳基线，预测准确率提高了约15%。

Conclusion: 该图结构学习方法能有效推断主系统的卫星分配策略，为次系统提供可靠的干扰避免机制。

Abstract: Unlike in terrestrial cellular networks, certain frequency bands for
low-earth orbit (LEO) satellite systems have thus far been allocated on a
non-exclusive basis. In this context, systems that launch their satellites
earlier (referred to as primary systems) are given spectrum access priority
over those that launch later, known as secondary systems. For a secondary
system to function, it is expected to either coordinate with primary systems or
ensure that it does not cause excessive interference to primary ground users.
Reliably meeting this interference constraint requires real-time knowledge of
the receive beams of primary users, which in turn depends on the primary
satellite-to-primary user associations. However, in practice, primary systems
have thus far not publicly disclosed their satellite assignment policies;
therefore, it becomes essential for secondary systems to develop methods to
infer such policies. Assuming there is limited historical data indicating which
primary satellites have served which primary users, we propose an end-to-end
graph structure learning-based algorithm for learning highest elevation primary
satellite assignment policies, that, upon deployment, can directly map the
primary satellite coordinates into assignment decisions for the primary users.
Simulation results show that our method can outperform the best baseline,
achieving approximately a 15% improvement in prediction accuracy.

</details>


### [3] [Delay-Augmented Stacked Intelligent Surfaces: Potential, Challenges, and Opportunities](https://arxiv.org/abs/2510.01411)
*Hibatallah Alwazani,Omran Abbas,Loic Markley,Anas Chaaban*

Main category: eess.SP

TL;DR: 提出了延迟增强堆叠智能表面(DA-SIS)的概念，通过在SIS中集成可调延迟单元，使其能够同时进行空间波域和时域信号处理，并展示了其在消除多径干扰方面的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 现有的堆叠智能表面(SIS)主要用于空间波域信号处理，但缺乏时域处理能力。为了扩展SIS的功能，使其能够同时处理空间和时间维度的信号，需要引入延迟处理能力。

Method: 在SIS中集成战略调谐的符号持续时间级延迟单元，构建延迟增强SIS(DA-SIS)。将其作为模拟均衡器来消除多径引起的符号间干扰(ISI)，并通过误码率(BER)评估性能。

Result: DA-SIS在均衡方面展现出潜力，能够有效消除多径干扰。通过与传统数字均衡器的比较，验证了其性能优势。元素数量对均衡过程有显著影响。

Conclusion: 延迟增强SIS是一个有前景的概念，能够扩展智能表面的功能范围。需要进一步研究来完善这一技术并将其实际应用。

Abstract: Stacked intelligent surfaces (SIS)s have been proposed recently as an
enabling technology for Holographic Multiple Input Multiple Output (HMIMO) and
Ultra-massive MIMO (umMIMO) technologies. Their utility can extend beyond
spatial wave-domain processing of signals if they are enhanced with
strategically-tuned symbol-duration level delays to enable temporal processing
as well. In this work, we introduce the idea of a delay-augmented SIS (DA-SIS).
We shed light on the feasibility of realizing delay units in an SIS. Then, we
discuss the relevance of the proposed DA-SIS and present a use case that
illustrates its potential, wherein the DA-SIS serves as an analog equalizer
that aids in eliminating multi-path-induced inter-symbol-interference (ISI). We
show how the number of elements affect the equalization process using the bit
error rate (BER) as a metric, and demonstrate the potential of the DA-SIS in
equalization via comparing with digital equalizers as a benchmark. Finally, we
present opportunities and future research directions that can be undertaken to
bring this idea to fruition.

</details>


### [4] [A Drone-mounted Magnetometer System for Automatic Interference Removal and Landmine Detection](https://arxiv.org/abs/2510.01417)
*Alex Paul Hoffmann,Matthew G. Finley,Eftyhia Zesta,Mark B. Moldwin,Lauro V. Ojeda*

Main category: eess.SP

TL;DR: 提出了一种基于无人机载双磁力计的两步式自动干扰消除和地雷检测方法，通过WAIC-UP算法消除无人机电子设备干扰，再使用RUDE算法检测地雷信号，实现了高保真度地雷检测。


<details>
  <summary>Details</summary>
Motivation: 地雷在冲突地区广泛使用，对平民构成持续威胁，阻碍战后恢复。无人机载磁力计常用于检测隐藏地雷，但面临无人机电子设备（如电机）磁场干扰的技术挑战。

Method: 使用框架安装的无人机载双磁力计载荷，采用两步法：第一步通过WAIC-UP方法消除干扰，第二步使用RUDE算法检测地雷特征信号。

Result: 该方法在10×10米网格的随机地雷布置和无人机电机干扰的蒙特卡洛模拟中得到验证，并在不同飞行高度下评估了算法效能。

Conclusion: WAIC-UP/RUDE两步法以低计算成本实现了高保真度地雷检测，简化了磁力测量载荷的设计。

Abstract: Landmines have been extensively used in conflict zones as an indiscriminate
weapon to control military movements, often remaining active long after
hostilities have ended. Their presence poses a persistent danger to civilians,
hindering post-war recovery efforts, causing injuries or death, and restricting
access to essential land for agriculture and infrastructure. Unmanned aerial
vehicles (UAV) equipped with magnetometers are commonly used to detect remnant
hidden landmines but come with significant technical challenges due to magnetic
field interference from UAV electronics such as motors. We propose the use of a
frame-mounted UAV-borne two-magnetometer payload to perform a two-step
automated interference removal and landmine detection analysis. The first step
removes interference via the Wavelet-Adaptive Interference Cancellation for
Underdetermined Platform (WAIC-UP) method designed for spaceflight
magnetometers. The second method uses the Rapid Unsupervised Detection of
Events (RUDE) algorithm to detect landmine signatures. This two-step
WAIC-UP/RUDE approach with multiple magnetometers achieves high-fidelity
ordinance detection at a low computational cost and simplifies the design of
magnetic survey payloads. We validate the method through a Monte Carlo
simulation of randomized landmine placements in a 10 x 10 m square grid and
drone motor interference. Additionally, we assess the efficacy of the algorithm
by varying the drone's altitude, examining its performance at different heights
above the ground.

</details>


### [5] [Meta-Learning-Driven Resource Optimization in Full-Duplex ISAC with Movable Antennas](https://arxiv.org/abs/2510.01437)
*Ali Amhaz,Shreya Khisa,Mohamed Elhattab,Chadi Assi,Sanaa Sharafeddine*

Main category: eess.SP

TL;DR: 本文研究了一种基于可移动天线的全双工基站系统，同时为下行和上行用户提供通信服务并实现目标检测的感知功能，支持集成感知与通信技术。通过联合优化波束成形、用户功率和天线位置，最大化回波信干噪比。


<details>
  <summary>Details</summary>
Motivation: 推动集成感知与通信技术的发展，利用可移动天线提升系统性能，解决传统固定天线在感知和通信联合优化中的局限性。

Method: 采用基于梯度的元学习方法，联合优化全双工基站的发射波束成形、接收波束成形、上行用户发射功率以及两个基站的可移动天线位置。

Result: 数值结果表明，所提出的元学习方法能达到最优解的99%性能，且基于可移动天线的方案优于多个基准方法。

Conclusion: 可移动天线方案在集成感知与通信应用中具有显著优势，所提出的元学习方法能有效解决大规模非凸优化问题。

Abstract: This paper investigates a full-duplex (FD) scenario where a base station (BS)
equipped with movable antennas (MAs) simultaneously provides communication
services to a set of downlink (DL) and uplink (UL) users while also enabling
sensing functionalities for target detection, thereby supporting integrated
sensing and communication (ISAC) technology. Additionally, a receiving BS, also
equipped with MAs (denoted as BS R), is responsible for capturing the reflected
echo. To optimize this setup, we formulate an optimization problem aimed at
maximizing the signal-to-noise and interference ratio (SINR) of the captured
echo. This is achieved by jointly optimizing the transmit beamforming vectors
at the FD BS, the receiving beamforming vectors at both the FD BS and BS R, the
UL users' transmit power, and the MAs' positions at both BSs, all while
satisfying the quality-of-service (QoS) requirements for both sensing and
communication. Given the non-convex nature of the problem and the high coupling
between the variables, we employ a gradient-based meta-learning (GML) approach
tailored for large-scale optimization. Numerical results demonstrate the
effectiveness of the proposed meta-learning approach, achieving results within
99% of the optimal solution. Furthermore, the MA-based scheme outperforms
several benchmark approaches, highlighting its advantages in practical ISAC
applications.

</details>


### [6] [The Analysis and Performance of LODC-OFDM Signal in Nonlinear Rydberg Atomic Sensor](https://arxiv.org/abs/2510.01605)
*Hao Wu,Xinyuan Yao,Rui Ni,Chen Gong*

Main category: eess.SP

TL;DR: 本文针对里德堡原子传感器在OFDM接收中的单极性限制问题，提出了专门优化的LODC-OFDM方案，并通过Bussgang定理分析了非线性失真，实验验证了理论结果。


<details>
  <summary>Details</summary>
Motivation: 里德堡原子传感器在射频测量中具有高灵敏度，但其光学接口的单极性特性限制了传统OFDM接收，需要开发兼容的单极性OFDM传输方案。

Method: 建立了里德堡原子传感器的AM-AM特性经验近似函数，基于DCO-OFDM框架提出了LODC-OFDM方案，并采用Bussgang定理分析非线性失真。

Result: 推导了泰勒级数展开和理想预失真情况下的闭合解，实验结果表明理论与实验结果吻合良好。

Conclusion: LODC-OFDM方案有效解决了里德堡传感器宽带OFDM接收的挑战，为兼容信号传输提供了可行方案。

Abstract: Rydberg atomic sensors have been seen as novel radio frequency (RF)
measurements and the high sensitivity to a large range of frequencies makes it
attractive for communications reception. However, the signal sensing process in
Rydberg system involves sequential transduction from electromagnetic waves to
optical signals and finally to electrical signals. The unipolar characteristic
of the optical interface inherently restricts conventional OFDM reception.
Therefore, adopting unipolar OFDM schemes, inspired by optical communication
systems, becomes essential for compatible signal transmission. In this work, we
investigate the amplitude modulation-to-amplitude modulation (AM-AM)
characteristics of Rydberg atomic sensors, establishing an empirical
approximation function. Building on the direct current-biased optical
orthogonal frequency division multiplexing (DCO-OFDM) framework, we propose a
novel local oscillator direct current-biased OFDM (LODC-OFDM) scheme
specifically optimized for Rydberg-based sensing, effectively addressing the
broadband OFDM reception challenge. Then, we adopt Bussgang theorem to analyze
the nonlinear distortion of LODC-OFDM signals and the results in closed-form
solutions are derived for AM/AM curves approximated by Taylor series expansion
and for the ideal pre-distortion case. In real experiments, the experimental
and theoretical results fit well.

</details>


### [7] [SEP Analysis of 1-Bit Quantized SIMO Systems with QPSK over Fading Channels](https://arxiv.org/abs/2510.01707)
*Amila Ravinath,Minhua Ding,Bikshapathi Gouda,Italo Atzeni,Antti Tölli*

Main category: eess.SP

TL;DR: 分析了1比特量化SIMO系统在瑞利衰落信道和QPSK调制下的平均符号错误概率，推导了MRC接收的精确SEP表达式，并确定了SIMO-MRC和SIMO-SC系统的分集增益和编码增益。


<details>
  <summary>Details</summary>
Motivation: 先前研究仅部分描述了选择合并(SC)的分集增益，需要更完整的分析来理解1比特量化SIMO系统的性能特性。

Method: 采用新颖的分析方法，推导了1比特量化SIMO系统在QPSK调制和MRC接收下的精确SEP表达式。

Result: 获得了SIMO-MRC系统的精确SEP表达式，并确定了其分集增益和编码增益；同时量化了SIMO-SC系统在任意接收天线数下的分集和编码增益。

Conclusion: 该研究扩展和补充了先前结果，为1比特量化SIMO系统的性能分析提供了完整的理论框架。

Abstract: The average symbol error probability (SEP) of a 1-bit quantized single-input
multiple-output (SIMO) system is analyzed under Rayleigh fading channels and
quadrature phase-shift keying (QPSK) modulation. Previous studies have
partially characterized the diversity gain for selection combining (SC). In
this paper, leveraging a novel analytical method, an exact analytical SEP
expression is derived for a 1-bit quantized SIMO system employing QPSK
modulation at the transmitter and maximum ratio combining (MRC) at the
receiver. The corresponding diversity and coding gains of a SIMO-MRC system are
also determined. Furthermore, the diversity and coding gains of a 1-bit
quantized SIMO-SC system are quantified for an arbitrary number of receive
antennas, thereby extending and complementing prior results.

</details>


### [8] [3D 8-Ary Noise Modulation Using Bayesian- and Kurtosis-based Detectors](https://arxiv.org/abs/2510.01748)
*Hadi Zayyani,Felipe A. P. de Figueiredo,Mohammad Salman,Rausley A. A. de Souza*

Main category: eess.SP

TL;DR: 提出了一种新颖的三维8元噪声调制方案，通过引入高斯混合分布的概率维度，在均值和方差的基础上增加第三个调制维度，使每个符号携带3比特信息，显著提高了数据传输速率。


<details>
  <summary>Details</summary>
Motivation: 现有的二维噪声调制方案数据速率有限，需要开发更高维度的调制方案来提升通信系统的传输效率。

Method: 使用高斯混合分布的概率作为第三调制维度，结合均值和方差形成三维调制。采用多种检测器组合：阈值检测器用于均值调制的比特，最大似然检测器用于方差调制的比特，峰度和JB测试用于概率调制的比特。

Result: 相比现有的二维方案，该方案将数据速率提高了1.5倍和3倍，同时第三个子信道比特的误码率保持在可接受的低水平（约0.06）。

Conclusion: 提出的三维噪声调制方案成功实现了更高的数据速率和可接受的误码性能，峰度检测器提供了低复杂度的解决方案。

Abstract: This paper presents a novel three-dimensional (3D) 8-ary noise modulation
scheme that introduces a new dimension: the mixture probability of a Mixture of
Gaussian (MoG) distribution. This proposed approach utilizes the dimensions of
mean and variance, in addition to the new probability dimension. Within this
framework, each transmitted symbol carries three bits, each corresponding to a
distinct sub-channel. For detection, a combination of specialized detectors is
employed: a simple threshold based detector for the first sub-channel bit
(modulated by the mean), a Maximum-Likelihood (ML) detector for the second
sub-channel bit (modulated by the variance), a Kurtosis-based, Jarque-Bera (JB)
test, and Bayesian Hypothesis (BHT)-based detectors for the third bit
(modulated by the MoG probability). The Kurtosis- and JB-based detectors
specifically distinguish between Gaussian (or near-Gaussian) and non-Gaussian
MoG distributions by leveraging higher-order statistical measures. The Bit
Error Probabilities (BEPs) are derived for the threshold-, Kurtosis-, and
BHT-based detectors. The optimum threshold for the Kurtosis-based detector is
also derived in a tractable manner. Simulation results demonstrate that a
comparably low BEP is achieved for the third sub-channel bit relative to
existing two-dimensional (2D) schemes. Simultaneously, the proposed scheme
increases the data rate by a factor of 1.5 and 3 compared to the Generalized
Quadratic noise modulator and the classical binary KLJN noise modulator,
respectively. Furthermore, the Kurtosis-based detector offers a low-complexity
solution, achieving an acceptable BEP of approximately 0.06.

</details>


### [9] [Exactly or Approximately Wasserstein Distributionally Robust Estimation According to Wasserstein Radii Being Small or Large](https://arxiv.org/abs/2510.01763)
*Xiao Ding,Enbin Song,Dunbiao Niu,Zhujun Cao,Qingjiang Shi*

Main category: eess.SP

TL;DR: 该论文研究在Wasserstein距离约束下的鲁棒估计问题，证明了无限维极小极大问题与有限维问题的鞍点存在性等价，给出了鞍点存在的充要条件，并在鞍点不存在时提出了鲁棒线性估计器。


<details>
  <summary>Details</summary>
Motivation: 研究在线性测量模型中加入Wasserstein距离约束的鲁棒估计问题，该问题可表述为无限维非凸极小极大问题，需要分析鞍点存在性并提供可验证的条件。

Method: 通过证明无限维与有限维问题的鞍点存在性等价，提出可验证的充要条件，并在鞍点不存在时求解有限维非凸极小极大问题以获得鲁棒线性估计器。

Result: 给出了鞍点存在的充要条件，证明了当Wasserstein半径足够小时鞍点总是存在，并在鞍点不存在时提供了鲁棒线性估计器及其性能上界。

Conclusion: 该研究为Wasserstein距离约束下的鲁棒估计问题提供了理论分析框架和实用算法，通过数值实验验证了理论结果的有效性。

Abstract: This paper primarily considers the robust estimation problem under
Wasserstein distance constraints on the parameter and noise distributions in
the linear measurement model with additive noise, which can be formulated as an
infinite-dimensional nonconvex minimax problem. We prove that the existence of
a saddle point for this problem is equivalent to that for a finite-dimensional
minimax problem, and give a counterexample demonstrating that the saddle point
may not exist. Motivated by this observation, we present a verifiable necessary
and sufficient condition whose parameters can be derived from a convex problem
and its dual. Additionally, we also introduce a simplified sufficient
condition, which intuitively indicates that when the Wasserstein radii are
small enough, the saddle point always exists. In the absence of the saddle
point, we solve an finite-dimensional nonconvex minimax problem, obtained by
restricting the estimator to be linear. Its optimal value establishes an upper
bound on the robust estimation problem, while its optimal solution yields a
robust linear estimator. Numerical experiments are also provided to validate
our theoretical results.

</details>


### [10] [Composite Generalized Quadratic Noise Modulation via Signal Addition: Towards Higher Dimensional Noise Modulations](https://arxiv.org/abs/2510.01776)
*Hadi Zayyani,Mohammad Salman,Felipe A. P. de Figueiredo,Rausley A. A. de Souza*

Main category: eess.SP

TL;DR: 提出通过叠加两个广义二次噪声调制器(GQNM)输出创建16进制噪声调制器，类似经典通信中的QAM调制器，在满足理论可区分性条件下相比KLJN和GQNM调制器性能更好，但增加了系统复杂度。


<details>
  <summary>Details</summary>
Motivation: 创建更高阶的噪声调制方案，通过叠加多个GQNM调制器输出实现类似QAM的调制方式，提升通信性能。

Method: 将两个GQNM调制器的输出简单叠加，创建16进制噪声调制器，通过调制四个不同的均值和四个不同的方差来承载信息比特。

Result: 仿真验证了在满足理论可区分性条件下，该方案相比KLJN和GQNM调制器具有更好的性能，具体表现为更低的比特错误概率(BEP)。

Conclusion: 通过增加调制器、发射机和接收机检测器的复杂度，可以实现更好的通信性能，该方法可扩展至高于16进制的调制方案。

Abstract: This letter proposes superposing two Generalized Quadratic Noise Modulators
(GQNM) by simply adding their outputs. It creates a 16-ary noise modulator that
resembles QAM modulators in classical communication. It modulates the
information bits on four different means and four different variances. It could
also be applied to reach higher-order modulations than 16-ary schemes by adding
the outputs of more than two modulators, which is not discussed in detail in
this letter and left for future work. By selecting the parameters necessary for
satisfying the theoretical distinguishability conditions provided in the paper,
we can reach better performances in comparison to the Kirchhoff-Law Johnson
Noise (KLJN) modulator and the GQNM modulator, which is verified by the
simulations. The better result in terms of smaller Bit Error Probability (BEP)
is achieved by increasing the complexity in the modulator, the transmitter, and
the detectors in the receiver.

</details>


### [11] [Closed-form Single UAV-aided Emitter Localization and Trajectory Design Using Doppler and TOA Measurements](https://arxiv.org/abs/2510.01778)
*Samaneh Motie,Hadi Zayyani,Mohammad Salman,Hasan Abu Hilal*

Main category: eess.SP

TL;DR: 提出了一种使用无人机辅助的定位算法，结合多普勒和到达时间测量，通过约束最小二乘优化获得发射器位置的闭式解。


<details>
  <summary>Details</summary>
Motivation: 现有的基于多普勒的定位算法通常基于非凸函数，计算复杂且难以求解。本文旨在开发一种更高效的定位方法。

Method: 利用到达时间测量改进最小二乘多普勒成本函数，将其转化为二次凸函数，通过约束最小二乘优化获得闭式解，并提供无人机轨迹设计的闭式解。

Result: 仿真实验表明，所提算法相比文献中的其他方法具有更好的性能。

Conclusion: 提出的算法通过结合多普勒和到达时间测量，成功实现了高效且精确的定位，为无人机辅助定位提供了有效的解决方案。

Abstract: In this paper, a single Unmanned-Aerial-Vehicle (UAV)-aided localization
algorithm which uses both Doppler and Time of Arrival (ToA) measurements is
presented. In contrast to Doppler-based localization algorithms which are based
on non-convex functions, exploiting ToA measurements in a Least-Square (LS)
Doppler-based cost function, leads to a quadratic convex function whose
minimizer lies on a line. Utilizing the ToA measurements in addition to the
linear equation of minimizer, a closed form solution is obtained for the
emitter location using a constrained LS optimization. In addition, a trajectory
design of the UAV is provided which has also closed-form solution. Simulation
experiments demonstrate the effectiveness of the proposed algorithm in
comparison to some others in the literature.

</details>


### [12] [Performance Optimization for Movable Antenna Enhanced MISO-OFDM Systems](https://arxiv.org/abs/2510.01789)
*Ruixi Feng,Weidong Mei,Lele Lu,Xin Wei,Zhi Chen,Zhen Gao,Boyu Ning*

Main category: eess.SP

TL;DR: 本文研究了移动天线在多载波OFDM系统中的位置优化问题，通过离散化运动区域和分支定界算法找到最优天线位置，显著提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有移动天线研究主要集中在窄带系统，而多载波OFDM系统中天线位置优化面临挑战，因为天线位置需要适应不同子载波的频率特性。

Method: 将连续位置优化问题离散化为采样点选择问题，采用分支定界算法结合图论方法剪枝次优解，在低信噪比下提出简化的图基算法。

Result: 仿真结果表明，所提算法优于传统固定位置天线，窄带天线位置优化可达到接近最优性能。

Conclusion: 移动天线技术在多载波系统中具有显著性能优势，所提出的离散化和优化算法能有效解决频率平坦特性带来的挑战。

Abstract: Movable antenna (MA) technology offers a flexible approach to enhancing
wireless channel conditions by adjusting antenna positions within a designated
region. While most existing works focus on narrowband MA systems, this paper
investigates MA position optimization for an MA-enhanced multiple-input
single-output (MISO) orthogonal frequency-division multiplexing (OFDM) system.
This problem appears to be particularly challenging due to the frequency-flat
nature of MA positioning, which should accommodate the channel conditions
across different subcarriers. To overcome this challenge, we discretize the
movement region into a multitude of sampling points, thereby converting the
continuous position optimization problem into a discrete point selection
problem. Although this problem is combinatorial, we develop an efficient
partial enumeration algorithm to find the optimal solution using a
branch-and-bound framework, where a graph-theoretic method is incorporated to
effectively prune suboptimal solutions. In the low signal-to-noise ratio (SNR)
regime, a simplified graph-based algorithm is also proposed to obtain the
optimal MA positions without the need for enumeration. Simulation results
reveal that the proposed algorithm outperforms conventional fixed-position
antennas (FPAs), while narrowband-based antenna position optimization can
achieve near-optimal performance.

</details>


### [13] [NGGAN: Noise Generation GAN Based on the Practical Measurement Dataset for Narrowband Powerline Communications](https://arxiv.org/abs/2510.01850)
*Ying-Ren Chien,Po-Heng Chou,You-Jie Peng,Chun-Yuan Huang,Hen-Wai Tsao,Yu Tsao*

Main category: eess.SP

TL;DR: 提出了一种基于生成对抗网络(GAN)的噪声生成模型NGGAN，用于学习窄带电力线通信(NB-PLC)系统中实际测量噪声的复杂特性，以进行数据增强。


<details>
  <summary>Details</summary>
Motivation: 现有数学噪声生成模型只能捕捉加性噪声的部分特性，无法全面统计非周期性异步脉冲噪声，这是提升NB-PLC收发器脉冲噪声处理的关键问题。

Method: 通过商用NB-PLC调制解调器的模拟耦合和带通滤波电路测量NB-PLC噪声构建真实数据集；设计NGGAN模型，使用Wasserstein距离作为损失函数，并优化输入信号长度以促进循环平稳噪声生成。

Result: 仿真结果表明，基于波形特征训练的NGGAN在生成噪声质量方面更接近实际测量数据集。

Conclusion: NGGAN能够有效学习实际NB-PLC噪声的复杂特性，为数据增强提供高质量噪声样本。

Abstract: Capturing comprehensive statistics of nonperiodic asynchronous impulsive
noise is a critical issue in enhancing impulse noise processing for narrowband
powerline communication (NB-PLC) transceivers. However, existing mathematical
noise generative models capture only some of the characteristics of additive
noise. Therefore, we propose a generative adversarial network (GAN), called the
noise-generation GAN (NGGAN), that learns the complicated characteristics of
practically measured noise samples for data augmentation. To closely match the
statistics of complicated noise in NB-PLC systems, we measured the NB-PLC noise
via the analog coupling and bandpass filtering circuits of a commercial NB-PLC
modem to build a realistic dataset. Specifically, the NGGAN design approaches
based on the practically measured dataset are as follows: (i) we design the
length of input signals that the NGGAN model can fit to facilitate
cyclo-stationary noise generation. (ii) Wasserstein distance is used as a loss
function to enhance the similarity between the generated noise and the training
dataset and ensure that the sample diversity is sufficient for various
applications. (iii) To measure the similarity performance of the GAN-based
models based on mathematical and practically measured datasets, we perform
quantitative and qualitative analyses. The training datasets include (1) a
piecewise spectral cyclo-stationary Gaussian model (PSCGM), (2) a
frequency-shift (FRESH) filter, and (3) practical measurements from NB-PLC
systems. Simulation results demonstrate that the proposed NGGAN trained using
waveform characteristics is closer to the practically measured dataset in terms
of the quality of the generated noise.

</details>


### [14] [Wearable and Ultra-Low-Power Fusion of EMG and A-Mode US for Hand-Wrist Kinematic Tracking](https://arxiv.org/abs/2510.02000)
*Giusy Spacone,Sebastian Frey,Mattia Orlandi,Pierangelo Maria Rapa,Victor Kartsch,Simone Benatti,Luca Benini,Andrea Cossettini*

Main category: eess.SP

TL;DR: 提出了一种超低功耗（低于50mW）系统，用于同时采集8通道EMG和4通道A模式超声信号，通过传感器融合实现23个自由度的连续手部姿态跟踪。


<details>
  <summary>Details</summary>
Motivation: 现有手势识别系统功耗高且仅限于离散手势分类，无法满足多日使用需求，需要开发更节能且能连续跟踪手部姿态的系统。

Method: 使用轻量级编码器-解码器架构和多任务学习，结合EMG和超声传感器融合，通过运动学手套进行地面实况标注。

Result: 在传感器重新定位条件下，EMG-US融合的均方根误差为10.6°±2.0°，优于单独使用EMG（12.0°±1°）或US（13.1°±2.6°），R²得分为0.61±0.1。

Conclusion: EMG和超声传感器融合能够显著提高手部姿态跟踪的准确性和鲁棒性，为开发更自然的人机交互系统提供了可行方案。

Abstract: Hand gesture recognition based on biosignals has shown strong potential for
developing intuitive human-machine interaction strategies that closely mimic
natural human behavior. In particular, sensor fusion approaches have gained
attention for combining complementary information and overcoming the
limitations of individual sensing modalities, thereby enabling more robust and
reliable systems. Among them, the fusion of surface electromyography (EMG) and
A-mode ultrasound (US) is very promising. However, prior solutions rely on
power-hungry platforms unsuitable for multi-day use and are limited to discrete
gesture classification. In this work, we present an ultra-low-power (sub-50 mW)
system for concurrent acquisition of 8-channel EMG and 4-channel A-mode US
signals, integrating two state-of-the-art platforms into fully wearable,
dry-contact armbands. We propose a framework for continuous tracking of 23
degrees of freedom (DoFs), 20 for the hand and 3 for the wrist, using a
kinematic glove for ground-truth labeling. Our method employs lightweight
encoder-decoder architectures with multi-task learning to simultaneously
estimate hand and wrist joint angles. Experimental results under realistic
sensor repositioning conditions demonstrate that EMG-US fusion achieves a root
mean squared error of $10.6^\circ\pm2.0^\circ$, compared to
$12.0^\circ\pm1^\circ$ for EMG and $13.1^\circ\pm2.6^\circ$ for US, and a R$^2$
score of $0.61\pm0.1$, with $0.54\pm0.03$ for EMG and $0.38\pm0.20$ for US.

</details>


### [15] [Computing on Dirty Paper: Interference-Free Integrated Communication and Computing](https://arxiv.org/abs/2510.02012)
*Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,David González G.,Carlo Fischione*

Main category: eess.SP

TL;DR: 提出了一种名为"脏纸计算"的集成通信与计算方案，通过脏纸编码原理在发射端预消除计算符号，实现通信和计算的同步进行，在SIMO设置下显著优于现有ICC方案。


<details>
  <summary>Details</summary>
Motivation: 受Costa脏纸编码工作的启发，旨在解决在公共多址信道上同时传输离散数据符号和计算nomographic函数的挑战，实现通信与计算的集成。

Method: 采用脏纸编码原理，在发射端预消除计算符号，实现渐进无干扰的通信与计算集成。在SIMO设置下进行仿真评估，包括数据检测性能和函数计算的均方误差性能。

Result: 验证了所提方法的有效性，在误码率和均方误差方面显著优于现有最先进的ICC方案。

Conclusion: 提出的"脏纸计算"方案成功实现了通信与计算的高效集成，通过脏纸编码原理有效解决了干扰问题，在性能上取得了显著提升。

Abstract: Inspired by Costa's pioneering work on dirty paper coding (DPC), this paper
proposes a novel scheme for integrated communication and computing (ICC), named
Computing on Dirty Paper, whereby the transmission of discrete data symbols for
communication, and over-the-air computation (AirComp) of nomographic functions
can be achieved simultaneously over common multiple-access channels. In
particular, the proposed scheme allows for the integration of communication and
computation in a manner that is asymptotically interference-free, by
precanceling the computing symbols at the transmitters (TXs) using DPC
principles. A simulation-based assessment of the proposed ICC scheme under a
single-input multiple-output (SIMO) setup is also offered, including the
evaluation of performance for data detection, and of mean-squared-error (MSE)
performance for function computation, over a block of symbols. The results
validate the proposed method and demonstrate its ability to significantly
outperform state-of-the-art (SotA) ICC schemes in terms of both bit error rate
(BER) and MSE.

</details>


### [16] [Joint Jammer Mitigation and Data Detection](https://arxiv.org/abs/2510.02021)
*Gian Marti,Christoph Studer*

Main category: eess.SP

TL;DR: 提出了一种联合干扰抑制与数据检测的新方法JMD，无需专用训练阶段即可同时估计干扰子空间和检测合法数据，有效对抗智能多天线干扰器。


<details>
  <summary>Details</summary>
Motivation: 传统干扰抑制方法需要专用训练阶段来估计干扰空间特征，这会降低通信速率，且无法应对智能干扰器在训练阶段不发射或动态改变波束的情况。

Method: 提出了JMD框架，通过联合估计干扰子空间和检测合法传输数据，无需专用训练阶段。开发了SANDMAN和MAED两种算法，分别采用不同的信道估计方法。

Result: 广泛的仿真实验证明了JMD在干扰抑制方面的有效性，能够应对智能和动态多天线干扰器。

Conclusion: JMD方法消除了专用训练阶段的需求，提高了通信效率，同时能够有效对抗各种类型的智能干扰器，为MIMO系统中的干扰抑制提供了新的解决方案。

Abstract: Multi-antenna (or MIMO) processing is a promising solution to the problem of
jammer mitigation. Existing methods mitigate the jammer based on an estimate of
its spatial signature that is acquired through a dedicated training phase. This
strategy has two main drawbacks: (i) it reduces the communication rate since no
data can be transmitted during the training phase and (ii) it can be evaded by
smart or multi-antenna jammers that do not transmit during the training phase
or that dynamically change their subspace through time-varying beamforming. To
address these drawbacks, we propose Joint jammer Mitigation and data Detection
(JMD), a novel paradigm for MIMO jammer mitigation. The core idea of JMD is to
estimate and remove the jammer interference subspace jointly with detecting the
legitimate transmit data over multiple time slots. Doing so removes the need
for a dedicated and rate-reducing training period while being able to mitigate
smart and dynamic multi-antenna jammers. We provide two JMD-type algorithms,
SANDMAN and MAED, that differ in the way they estimate the channels of the
legitimate transmitters and achieve different complexity-performance tradeoffs.
Extensive simulations demonstrate the efficacy of JMD for jammer mitigation.

</details>


### [17] [A Secure Affine Frequency Division Multiplexing for Wireless Communication Systems](https://arxiv.org/abs/2510.02023)
*Ping Wang,Zulin Wang,Yuanhan Ni,Qu Luo,Yuanfang Ma,Xiaosi Tian,Pei Xiao*

Main category: eess.SP

TL;DR: 提出了一种新型安全仿射频分复用(SE-AFDM)系统，通过动态变化AFDM预啁啾参数来增强物理层安全性，采用参数域扩展方法在保持可靠性和高频谱效率的同时提供额外安全性。


<details>
  <summary>Details</summary>
Motivation: AFDM在高移动性场景中表现出优越性能，但现有设计缺乏足够的安全性保障，需要开发能够提供物理层安全性的改进系统。

Method: 使用长周期伪噪声序列控制的码本动态生成AFDM预啁啾参数，采用参数域扩展而非数据域扩展，并提出同步框架解决时变参数在快速时变信道中的可靠快速同步问题。

Result: 理论推导证明未同步的窃听者无法消除时变参数的非线性影响，仿真结果显示SE-AFDM系统在高移动性场景中具有安全优势，硬件原型验证了同步框架的有效性。

Conclusion: SE-AFDM系统通过动态变化的预啁啾参数成功增强了物理层安全性，在保持AFDM原有优势的同时提供了额外的安全保障。

Abstract: Affine frequency division multiplexing (AFDM) has garnered significant
attention due to its superior performance in high-mobility scenarios, coupled
with multiple waveform parameters that provide greater degrees of freedom for
system design. This paper introduces a novel secure affine frequency division
multiplexing (SE-AFDM) system, which advances prior designs by dynamically
varying an AFDM pre-chirp parameter to enhance physical-layer security. In the
SE-AFDM system, the pre-chirp parameter is dynamically generated from a
codebook controlled by a long-period pseudo-noise (LPPN) sequence. Instead of
applying spreading in the data domain, our parameter-domain spreading approach
provides additional security while maintaining reliability and high spectrum
efficiency. We also propose a synchronization framework to solve the problem of
reliably and rapidly synchronizing the time-varying parameter in fast
time-varying channels. The theoretical derivations prove that unsynchronized
eavesdroppers cannot eliminate the nonlinear impact of the time-varying
parameter and further provide useful guidance for codebook design. Simulation
results demonstrate the security advantages of the proposed SE-AFDM system in
high-mobility scenarios, while our hardware prototype validates the
effectiveness of the proposed synchronization framework.

</details>


### [18] [Joint DOA and Attitude Sensing Based on Tri-Polarized Continuous Aperture Array](https://arxiv.org/abs/2510.02029)
*Haonan Si,Zhaolin Wang,Xiansheng Guo,Jin Zhang,Yuanwei Liu*

Main category: eess.SP

TL;DR: 提出基于三极化连续孔径阵列的联合波达方向与姿态感知方法，通过电磁信息理论建模连续信号，开发连续-离散变换技术，利用三极化信号协方差构建增强的DOA估计谱，并基于先验信息提出两种姿态估计算法。


<details>
  <summary>Details</summary>
Motivation: 研究三极化连续孔径阵列在联合波达方向和姿态感知中的应用，旨在通过电磁信息理论解决连续信号建模和姿态信息可辨识性问题。

Method: 采用电磁信息理论建模三极化连续孔径阵列接收信号，开发连续-离散变换技术进行子空间分解，利用三极化信号的自协方差和互协方差构建增强谱，并提出两种姿态估计算法（无先验和基于先验信息）。

Result: 数值结果表明所提框架的可行性和优越性，三极化谱显著提升了DOA估计性能，姿态估计算法在不同先验信息条件下均能有效工作。

Conclusion: 三极化连续孔径阵列能够实现准确的联合波达方向和姿态感知，姿态信息的可辨识性依赖于目标先验快照的可用性，所提方法在理论和实验上均表现出优越性能。

Abstract: This paper investigates joint direction-of-arrival (DOA) and attitude sensing
using tri-polarized continuous aperture arrays (CAPAs). By employing
electromagnetic (EM) information theory, the spatially continuous received
signals in tri-polarized CAPA are modeled, thereby enabling accurate DOA and
attitude estimation. To facilitate subspace decomposition for continuous
operators, an equivalent continuous-discrete transformation technique is
developed. Moreover, both self- and cross-covariances of tri-polarized signals
are exploited to construct a tri-polarized spectrum, significantly enhancing
DOA estimation performance. Theoretical analyses reveal that the
identifiability of attitude information fundamentally depends on the
availability of prior target snapshots. Accordingly, two attitude estimation
algorithms are proposed: one capable of estimating partial attitude information
without prior knowledge, and the other achieving full attitude estimation when
such knowledge is available. Numerical results demonstrate the feasibility and
superiority of the proposed framework.

</details>


### [19] [Sensing-Secure ISAC: Ambiguity Function Engineering for Impairing Unauthorized Sensing](https://arxiv.org/abs/2510.02103)
*Kawon Han,Kaitao Meng,Christos Masouros*

Main category: eess.SP

TL;DR: 提出了一种感知安全的ISAC框架，通过在ISAC信号的模糊函数中引入人工缺陷，在窃听者的距离剖面中插入虚假目标，从而混淆未经授权的感知，同时保证合法系统的安全目标检测和估计。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)的部署带来了前所未有的授权感知漏洞，目标反射信号中的感知参数可能被未经授权的被动雷达窃听者提取，需要开发安全解决方案来保护感知信息。

Method: 采用OFDM信号，设计结构化子载波功率分配方案来塑造安全自相关函数，插入周期性峰值误导窃听者的距离估计；使用失配滤波抑制模糊函数伪影；引入PSL和ISL作为感知安全性能指标；构建凸优化问题最大化ISAC性能同时保证感知安全水平。

Result: 数值结果验证了所提出的感知安全ISAC信号的有效性，能够显著降低窃听者的目标估计性能，同时保持合法系统的性能。

Conclusion: 该研究成功实现了感知安全的ISAC系统设计，通过信号设计在通信、合法感知和感知安全之间实现了有效权衡，为ISAC系统的安全部署提供了重要解决方案。

Abstract: The deployment of integrated sensing and communication (ISAC) brings along
unprecedented vulnerabilities to authorized sensing, necessitating the
development of secure solutions. Sensing parameters are embedded within the
target-reflected signal leaked to unauthorized passive radar sensing
eavesdroppers (Eve), implying that they can silently extract sensory
information without prior knowledge of the information data. To overcome this
limitation, we propose a sensing-secure ISAC framework that ensures secure
target detection and estimation for the legitimate system, while obfuscating
unauthorized sensing without requiring any prior knowledge of Eve. By
introducing artificial imperfections into the ambiguity function (AF) of ISAC
signals, we introduce artificial targets into Eve's range profile which
increase its range estimation ambiguity. In contrast, the legitimate sensing
receiver (Alice) can suppress these AF artifacts using mismatched filtering,
albeit at the expense of signal-to-noise ratio (SNR) loss. Employing an OFDM
signal, a structured subcarrier power allocation scheme is designed to shape
the secure autocorrelation function (ACF), inserting periodic peaks to mislead
Eve's range estimation and degrade target detection performance. To quantify
the sensing security, we introduce peak sidelobe level (PSL) and integrated
sidelobe level (ISL) as key performance metrics. Then, we analyze the three-way
trade-offs between communication, legitimate sensing, and sensing security,
highlighting the impact of the proposed sensing-secure ISAC signaling on system
performance. We formulate a convex optimization problem to maximize ISAC
performance while guaranteeing a certain sensing security level. Numerical
results validate the effectiveness of the proposed sensing-secure ISAC
signaling, demonstrating its ability to degrade Eve's target estimation while
preserving Alice's performance.

</details>


### [20] [Unlocking Symbol-Level Precoding Efficiency Through Tensor Equivariant Neural Network](https://arxiv.org/abs/2510.02108)
*Jinshuo Zhang,Yafei Wang,Xinping Yi,Wenjin Wang,Shi Jin,Symeon Chatzinotas,Björn Ottersten*

Main category: eess.SP

TL;DR: 提出基于张量等变性的端到端深度学习框架，显著降低符号级预编码的计算复杂度，在保持性能优势的同时实现约80倍加速。


<details>
  <summary>Details</summary>
Motivation: 符号级预编码虽然能提供性能增益，但其高计算复杂度限制了实际应用。需要开发低推理复杂度的解决方案。

Method: 利用最优符号级预编码的闭式解结构及其固有的张量等变性，构建从问题表述到解的映射，设计具有特定参数共享模式的网络，并采用基于注意力的TE模块实现线性计算复杂度。

Result: 所提框架捕获了最优符号级预编码的大部分性能增益，相比传统方法实现约80倍加速，并在用户数量和符号块长度方面表现出强泛化能力。

Conclusion: 基于张量等变性的深度学习框架有效解决了符号级预编码的高复杂度问题，在性能和效率之间取得了良好平衡，适用于完美和不完美CSI场景。

Abstract: Although symbol-level precoding (SLP) based on constructive interference (CI)
exploitation offers performance gains, its high complexity remains a
bottleneck. This paper addresses this challenge with an end-to-end deep
learning (DL) framework with low inference complexity that leverages the
structure of the optimal SLP solution in the closed-form and its inherent
tensor equivariance (TE), where TE denotes that a permutation of the input
induces the corresponding permutation of the output. Building upon the
computationally efficient model-based formulations, as well as their known
closed-form solutions, we analyze their relationship with linear precoding (LP)
and investigate the corresponding optimality condition. We then construct a
mapping from the problem formulation to the solution and prove its TE, based on
which the designed networks reveal a specific parameter-sharing pattern that
delivers low computational complexity and strong generalization. Leveraging
these, we propose the backbone of the framework with an attention-based TE
module, achieving linear computational complexity. Furthermore, we demonstrate
that such a framework is also applicable to imperfect CSI scenarios, where we
design a TE-based network to map the CSI, statistics, and symbols to auxiliary
variables. Simulation results show that the proposed framework captures
substantial performance gains of optimal SLP, while achieving an approximately
80-times speedup over conventional methods and maintaining strong
generalization across user numbers and symbol block lengths.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [21] [Joint Optimization of Speaker and Spoof Detectors for Spoofing-Robust Automatic Speaker Verification](https://arxiv.org/abs/2510.01818)
*Oğuzhan Kurnaz,Jagabandhu Mishra,Tomi H. Kinnunen,Cemal Hanilçi*

Main category: eess.AS

TL;DR: 该研究提出了一种可训练后端分类器的模块化方法，用于欺骗鲁棒说话人验证(SASV)，通过直接优化SASV性能指标(a-DCF)来改进说话人和欺骗检测子系统的集成。


<details>
  <summary>Details</summary>
Motivation: 现有的SASV系统通常在嵌入、分数或决策级别独立训练子系统后进行融合，本研究旨在通过可训练后端分类器实现更好的集成，并直接优化SASV性能指标。

Method: 采用模块化设计，分别使用加权余弦评分进行说话人检测和SSL-AASIST进行欺骗检测，然后通过可训练的非线性后端分类器融合两个子系统的输出，并直接优化a-DCF指标。

Result: 在ASVspoof 5数据集上，非线性分数融合相比线性融合持续改进a-DCF性能，最佳组合将min a-DCF降至0.196，SPF-EER降至7.6%，达到最先进水平。

Conclusion: 模块化设计、校准集成和任务对齐优化对于推进鲁棒且可解释的SASV系统至关重要，非线性融合方法显著优于传统线性融合。

Abstract: Spoofing-robust speaker verification (SASV) combines the tasks of speaker and
spoof detection to authenticate speakers under adversarial settings. Many SASV
systems rely on fusion of speaker and spoof cues at embedding, score or
decision levels, based on independently trained subsystems. In this study, we
respect similar modularity of the two subsystems, by integrating their outputs
using trainable back-end classifiers. In particular, we explore various
approaches for directly optimizing the back-end for the recently-proposed SASV
performance metric (a-DCF) as a training objective. Our experiments on the
ASVspoof 5 dataset demonstrate two important findings: (i) nonlinear score
fusion consistently improves a-DCF over linear fusion, and (ii) the combination
of weighted cosine scoring for speaker detection with SSL-AASIST for spoof
detection achieves state-of-the-art performance, reducing min a-DCF to 0.196
and SPF-EER to 7.6%. These contributions highlight the importance of modular
design, calibrated integration, and task-aligned optimization for advancing
robust and interpretable SASV systems.

</details>


### [22] [SLAP: Learning Speaker and Health-Related Representations from Natural Language Supervision](https://arxiv.org/abs/2510.01860)
*Angelika Ando,Auguste Crabeil,Adrien Lesage,Rachid Riad*

Main category: eess.AS

TL;DR: SLAP是首个通过对比学习将语音与说话人和健康元数据的自然语言描述对齐的音频基础模型，在38个二元分类任务上实现62.9%的零样本F1分数，比CLAP提升48%，并在未见语言和临床人群上展现出强大的OOD泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前没有音频基础模型支持说话人特征和健康信息的零样本或分布外泛化任务，需要开发能够对齐语音与自然语言描述的模型。

Method: SLAP结合视觉Transformer音频编码器和文本编码器，在9个数据集3400+小时语音上通过对比学习训练，将语音与说话人和健康元数据的自然语言描述对齐。

Result: 在14个数据集7种语言的38个二元分类任务上，SLAP零样本评估平均F1达62.9%，比CLAP提升48%；线性探测微调后达到69.3% F1，在健康任务上达到57.9% F1，超越更大的基础模型。

Conclusion: SLAP是首个支持说话人特征和健康信息零样本和OOD泛化的音频基础模型，在多种任务上表现出色，特别是在健康相关任务上达到最佳性能。

Abstract: Speech encodes paralinguistic information such as demographics, voice
quality, and health. Yet no audio foundation model supports zero-shot or
out-of-distribution (OOD) generalization to these tasks. We introduce SLAP
(Speaker contrastive Language-Audio Pretraining), the first model aligning
speech with natural language descriptions of speaker and health metadata
through contrastive learning. SLAP combines a Vision Transformer audio encoder
with text encoders, trained on more than 3400 hours across 9 datasets with
diverse speaker annotations. We evaluated on 38 binary classification tasks
spanning demographics, voice characteristics, and clinical assessments across
14 datasets in 7 languages. SLAP achieves 62.9% average F1 in zero-shot
evaluation, a 48% relative improvement over CLAP (42.4%), while demonstrating
strong OOD generalization to unseen languages and clinical populations. When
fine-tuned with linear probing, SLAP reaches 69.3% F1 overall and achieves
best-in-class performance on health tasks (57.9% F1), surpassing larger
foundation models.

</details>


### [23] [Clustering of Acoustic Environments with Variational Autoencoders for Hearing Devices](https://arxiv.org/abs/2510.01940)
*Luan Vinícius Fiorio,Ivana Nikoloska,Wim van Houtum,Ronald M. Aarts*

Main category: eess.AS

TL;DR: 本文提出了一种基于变分自编码器(VAE)的无监督声学环境聚类方法，特别针对助听设备场景，采用Gumbel-Softmax重参数化和时间上下文窗口方案。


<details>
  <summary>Details</summary>
Motivation: 传统声学环境分类方法要么无法提取高维数据的有效表示，要么受限于标签可用性。人工标注的标签并不总能反映声学场景的真实结构，因此探索无监督聚类方法。

Method: 提出使用变分自编码器进行无监督声学环境聚类，采用Gumbel-Softmax重参数化处理分类潜在变量，并结合时间上下文窗口方案以适应真实助听设备场景。

Result: 在语音数字聚类任务中所有变分方法都成功，但在城市声景聚类中，只有提出的分类模型实现了有效的聚类性能，这归因于其分类特性。

Conclusion: 提出的基于VAE的分类聚类模型在复杂声学场景中表现出色，特别适用于具有时间和频率强重叠的城市声景分类任务。

Abstract: Particularly in hearing devices, the environmental context is taken into
account for audio processing, often through classification. Traditional
acoustic environment classification relies on classical algorithms, which are
unable to extract meaningful representations of high-dimensionality data, or on
supervised learning, being limited by the availability of labels. Knowing that
human-imposed labels do not always reflect the true structure of acoustic
scenes, we explore the (unsupervised) clustering of acoustic environments using
variational autoencoders (VAEs), presenting a structured latent space suitable
for the task. We propose a VAE model for categorical latent clustering
employing a Gumbel-Softmax reparameterization with a time-context windowing
scheme, tailored for real-world hearing device scenarios. Additionally, general
adaptations on VAE architectures for audio clustering are also proposed. The
approaches are validated through the clustering of spoken digits, a simpler
task where labels are meaningful, and urban soundscapes, which recordings
present strong overlap in time and frequency. While all variational methods
succeeded when clustering spoken digits, only the proposed model achieved
effective clustering performance on urban acoustic scenes, given its
categorical nature.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [24] [RealClass: A Framework for Classroom Speech Simulation with Public Datasets and Game Engines](https://arxiv.org/abs/2510.01462)
*Ahmed Adel Attia,Jing Liu,Carol Espy Wilson*

Main category: cs.SD

TL;DR: 提出了一种使用游戏引擎合成教室噪声和房间脉冲响应的方法，并构建了RealClass数据集，该数据集结合了合成的教室噪声语料库和从公开语料库编译的教室语音数据集。


<details>
  <summary>Details</summary>
Motivation: 大规模教室语音数据的稀缺阻碍了教育领域AI驱动语音模型的发展，现有教室数据集有限且不公开，缺乏专门的教室噪声或房间脉冲响应语料库，无法使用标准数据增强技术。

Method: 使用游戏引擎合成教室噪声和房间脉冲响应的可扩展方法，构建RealClass数据集，将合成的教室噪声语料库与从公开语料库编译的教室语音数据集相结合。

Result: 在干净和嘈杂语音上的实验表明，RealClass能够很好地近似真实教室语音，在缺乏丰富真实教室语音的情况下成为一个有价值的资源。

Conclusion: 提出的方法可以扩展到教室以外的其他领域，RealClass数据集在缺乏真实教室语音数据的情况下具有重要价值。

Abstract: The scarcity of large-scale classroom speech data has hindered the
development of AI-driven speech models for education. Classroom datasets remain
limited and not publicly available, and the absence of dedicated classroom
noise or Room Impulse Response (RIR) corpora prevents the use of standard data
augmentation techniques.
  In this paper, we introduce a scalable methodology for synthesizing classroom
noise and RIRs using game engines, a versatile framework that can extend to
other domains beyond the classroom. Building on this methodology, we present
RealClass, a dataset that combines a synthesized classroom noise corpus with a
classroom speech dataset compiled from publicly available corpora. The speech
data pairs a children's speech corpus with instructional speech extracted from
YouTube videos to approximate real classroom interactions in clean conditions.
Experiments on clean and noisy speech show that RealClass closely approximates
real classroom speech, making it a valuable asset in the absence of abundant
real classroom speech.

</details>


### [25] [Emotional Text-To-Speech Based on Mutual-Information-Guided Emotion-Timbre Disentanglement](https://arxiv.org/abs/2510.01722)
*Jianing Yang,Sheng Li,Takahiro Shinozaki,Yuki Saito,Hiroshi Saruwatari*

Main category: cs.SD

TL;DR: 提出了一种新颖的情感TTS方法，通过音素级情感嵌入预测和风格解耦技术，能够捕捉参考语音的细微声学细节，生成更自然和情感丰富的声音。


<details>
  <summary>Details</summary>
Motivation: 当前的情感TTS和风格转换方法依赖参考编码器控制全局风格或情感向量，但无法捕捉参考语音的细微声学细节。

Method: 采用风格解耦方法指导两个特征提取器，减少音色和情感特征之间的互信息，有效分离参考语音中的不同风格成分，实现细粒度的音素级情感嵌入预测。

Result: 实验结果表明，该方法在生成自然和情感丰富的语音方面优于基线TTS系统。

Conclusion: 这项工作突出了解耦和细粒度表示在提高情感TTS系统质量和灵活性方面的潜力。

Abstract: Current emotional Text-To-Speech (TTS) and style transfer methods rely on
reference encoders to control global style or emotion vectors, but do not
capture nuanced acoustic details of the reference speech. To this end, we
propose a novel emotional TTS method that enables fine-grained phoneme-level
emotion embedding prediction while disentangling intrinsic attributes of the
reference speech. The proposed method employs a style disentanglement method to
guide two feature extractors, reducing mutual information between timbre and
emotion features, and effectively separating distinct style components from the
reference speech. Experimental results demonstrate that our method outperforms
baseline TTS systems in generating natural and emotionally rich speech. This
work highlights the potential of disentangled and fine-grained representations
in advancing the quality and flexibility of emotional TTS systems.

</details>


### [26] [SingMOS-Pro: An Comprehensive Benchmark for Singing Quality Assessment](https://arxiv.org/abs/2510.01812)
*Yuxun Tang,Lan Liu,Wenhao Feng,Yiwen Zhao,Jionghao Han,Yifeng Yu,Jiatong Shi,Qin Jin*

Main category: cs.SD

TL;DR: 提出了SingMOS-Pro数据集，用于自动歌唱质量评估，包含7,981个歌唱片段，涵盖41个模型和12个数据集，提供歌词、旋律和整体质量的多维度评分。


<details>
  <summary>Details</summary>
Motivation: 歌唱声音生成技术发展迅速，但评估歌唱质量仍面临挑战。主观评估成本高、耗时长，现有客观指标只能捕捉有限的感知方面。

Method: 在SingMOS基础上扩展标注，增加了歌词、旋律和整体质量评分，每个片段至少有5位专业标注者的评分，确保可靠性和一致性。

Result: 构建了包含7,981个歌唱片段的数据集，涵盖从早期系统到最新进展的41个模型，提供了多维度的质量评估基准。

Conclusion: 建立了歌唱质量评估的强基线，为未来研究提供了实用的参考基准，并探索了在不同标准下有效利用MOS数据的方法。

Abstract: Singing voice generation progresses rapidly, yet evaluating singing quality
remains a critical challenge. Human subjective assessment, typically in the
form of listening tests, is costly and time consuming, while existing objective
metrics capture only limited perceptual aspects. In this work, we introduce
SingMOS-Pro, a dataset for automatic singing quality assessment. Building on
our preview version SingMOS, which provides only overall ratings, SingMOS-Pro
expands annotations of the additional part to include lyrics, melody, and
overall quality, offering broader coverage and greater diversity. The dataset
contains 7,981 singing clips generated by 41 models across 12 datasets,
spanning from early systems to recent advances. Each clip receives at least
five ratings from professional annotators, ensuring reliability and
consistency. Furthermore, we explore how to effectively utilize MOS data
annotated under different standards and benchmark several widely used
evaluation methods from related tasks on SingMOS-Pro, establishing strong
baselines and practical references for future research. The dataset can be
accessed at https://huggingface.co/datasets/TangRain/SingMOS-Pro.

</details>


### [27] [HRTFformer: A Spatially-Aware Transformer for Personalized HRTF Upsampling in Immersive Audio Rendering](https://arxiv.org/abs/2510.01891)
*Xuyi Hu,Jian Li,Shaojie Zhang,Stefan Goetz,Lorenzo Picinali,Ozgur B. Akan,Aidan O. T. Hogg*

Main category: cs.SD

TL;DR: 提出基于Transformer的HRTF上采样方法，通过注意力机制捕捉空间相关性，在球谐域中从稀疏测量重建高分辨率HRTF，显著提升精度和空间一致性。


<details>
  <summary>Details</summary>
Motivation: 个性化HRTF测量过程复杂，难以大规模应用。现有机器学习方法在高上采样因子下存在长距离空间一致性和泛化能力不足的问题。

Method: 在球谐域使用基于Transformer的架构，引入注意力机制捕捉空间相关性，并添加邻居差异损失来增强幅度平滑度。

Result: 实验表明，该方法在感知定位模型和客观频谱失真指标上均显著优于现有领先方法，能生成更真实、高保真的HRTF。

Conclusion: 提出的Transformer架构在HRTF上采样任务中表现出色，为大规模个性化HRTF应用提供了可行解决方案。

Abstract: Personalized Head-Related Transfer Functions (HRTFs) are starting to be
introduced in many commercial immersive audio applications and are crucial for
realistic spatial audio rendering. However, one of the main hesitations
regarding their introduction is that creating personalized HRTFs is impractical
at scale due to the complexities of the HRTF measurement process. To mitigate
this drawback, HRTF spatial upsampling has been proposed with the aim of
reducing measurements required. While prior work has seen success with
different machine learning (ML) approaches, these models often struggle with
long-range spatial consistency and generalization at high upsampling factors.
In this paper, we propose a novel transformer-based architecture for HRTF
upsampling, leveraging the attention mechanism to better capture spatial
correlations across the HRTF sphere. Working in the spherical harmonic (SH)
domain, our model learns to reconstruct high-resolution HRTFs from sparse input
measurements with significantly improved accuracy. To enhance spatial
coherence, we introduce a neighbor dissimilarity loss that promotes magnitude
smoothness, yielding more realistic upsampling. We evaluate our method using
both perceptual localization models and objective spectral distortion metrics.
Experiments show that our model surpasses leading methods by a substantial
margin in generating realistic, high-fidelity HRTFs.

</details>


### [28] [MelCap: A Unified Single-Codebook Neural Codec for High-Fidelity Audio Compression](https://arxiv.org/abs/2510.01903)
*Jingyi Li,Zhiyuan Zhao,Yunfei Liu,Lijian Lin,Ye Zhu,Jiahao Wu,Qiuqiang Kong,Yu Li*

Main category: cs.SD

TL;DR: MelCap是一个统一的神经音频编解码器，使用单一码本处理语音、音乐和通用声音，通过两阶段重建实现高质量音频压缩。


<details>
  <summary>Details</summary>
Motivation: 现有神经音频编解码器要么使用单一量化器仅处理语音，要么使用多个量化器但不适合下游任务，需要一种统一且高效的解决方案。

Method: 将音频重建分为两个阶段：第一阶段将音频转换为mel频谱图，使用2D标记器压缩量化为紧凑单标记；第二阶段通过声码器从mel离散标记中恢复波形。

Result: 客观和主观评估表明，MelCap在质量上与最先进的多码本编解码器相当，同时保持了单码本设计的计算简单性。

Conclusion: MelCap提供了一种有效的表示方法，适用于下游任务，在保持高质量的同时简化了计算复杂度。

Abstract: Neural audio codecs have recently emerged as powerful tools for high-quality
and low-bitrate audio compression, leveraging deep generative models to learn
latent representations of audio signals. However, existing approaches either
rely on a single quantizer that only processes speech domain, or on multiple
quantizers that are not well suited for downstream tasks. To address this
issue, we propose MelCap, a unified "one-codebook-for-all" neural codec that
effectively handles speech, music, and general sound. By decomposing audio
reconstruction into two stages, our method preserves more acoustic details than
previous single-codebook approaches, while achieving performance comparable to
mainstream multi-codebook methods. In the first stage, audio is transformed
into mel-spectrograms, which are compressed and quantized into compact single
tokens using a 2D tokenizer. A perceptual loss is further applied to mitigate
the over-smoothing artifacts observed in spectrogram reconstruction. In the
second stage, a Vocoder recovers waveforms from the mel discrete tokens in a
single forward pass, enabling real-time decoding. Both objective and subjective
evaluations demonstrate that MelCap achieves quality on comparable to
state-of-the-art multi-codebook codecs, while retaining the computational
simplicity of a single-codebook design, thereby providing an effective
representation for downstream tasks.

</details>


### [29] [Exploring Resolution-Wise Shared Attention in Hybrid Mamba-U-Nets for Improved Cross-Corpus Speech Enhancement](https://arxiv.org/abs/2510.01958)
*Nikolai Lund Kühne,Jesper Jensen,Jan Østergaard,Zheng-Hua Tan*

Main category: cs.SD

TL;DR: RWSA-MambaUNet是一种结合Mamba和注意力机制的高效语音增强模型，在U-Net结构中采用分辨率共享注意力机制，在跨语料库泛化性能上达到SOTA，同时大幅减少模型参数和计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 受Mamba与注意力机制结合在语音增强中展现的优异跨语料库泛化性能启发，以及Mamba在U-Net结构中实现SOTA增强性能同时减少模型大小和计算复杂度的优势，提出更高效的混合模型。

Method: 提出RWSA-MambaUNet模型，在U-Net结构中结合Mamba和多头注意力机制，采用分辨率共享注意力（RWSA）机制，即在对应时间和频率分辨率之间共享注意力层。

Result: 最佳模型在两个域外测试集上达到SOTA泛化性能。最小模型在DNS 2020测试集的PESQ、SSNR、ESTOI指标上超越所有基线，在EARS-WHAM_v2测试集的SSNR、ESTOI、SI-SDR指标上超越所有基线，同时使用不到一半的模型参数和部分FLOPs。

Conclusion: RWSA-MambaUNet证明了结合Mamba和注意力机制在U-Net结构中的有效性，实现了优异的跨语料库泛化性能，同时显著降低了模型复杂度和计算成本。

Abstract: Recent advances in speech enhancement have shown that models combining Mamba
and attention mechanisms yield superior cross-corpus generalization
performance. At the same time, integrating Mamba in a U-Net structure has
yielded state-of-the-art enhancement performance, while reducing both model
size and computational complexity. Inspired by these insights, we propose
RWSA-MambaUNet, a novel and efficient hybrid model combining Mamba and
multi-head attention in a U-Net structure for improved cross-corpus
performance. Resolution-wise shared attention (RWSA) refers to layerwise
attention-sharing across corresponding time- and frequency resolutions. Our
best-performing RWSA-MambaUNet model achieves state-of-the-art generalization
performance on two out-of-domain test sets. Notably, our smallest model
surpasses all baselines on the out-of-domain DNS 2020 test set in terms of
PESQ, SSNR, and ESTOI, and on the out-of-domain EARS-WHAM_v2 test set in terms
of SSNR, ESTOI, and SI-SDR, while using less than half the model parameters and
a fraction of the FLOPs.

</details>


### [30] [Bias beyond Borders: Global Inequalities in AI-Generated Music](https://arxiv.org/abs/2510.01963)
*Ahmet Solak,Florian Grötschla,Luca A. Lanzendörfer,Roger Wattenhofer*

Main category: cs.SD

TL;DR: 本文介绍了GlobalDISCO数据集，用于评估音乐生成模型在不同国家、语言、文化和音乐流派中的偏见，发现高资源和低资源地区之间存在显著的质量差异。


<details>
  <summary>Details</summary>
Motivation: 当前音乐生成模型研究缺乏对全球多样性的关注，缺少捕捉全球音乐多样性的数据集和基准测试，需要解决模型在不同文化背景下的偏见问题。

Method: 构建了GlobalDISCO大规模数据集，包含73k首由商业音乐生成模型生成的音乐曲目，以及93k首LAION-DISCO-12M中的参考曲目，涵盖147种语言和79个国家的音乐风格。

Result: 评估显示高资源和低资源地区在音乐质量和与参考音乐的对齐度上存在巨大差异，主流与地域性小众流派之间的模型性能也有明显区别。

Conclusion: 音乐生成模型存在显著的地区和文化偏见，需要更多关注全球多样性，GlobalDISCO数据集为评估和解决这些偏见提供了重要工具。

Abstract: While recent years have seen remarkable progress in music generation models,
research on their biases across countries, languages, cultures, and musical
genres remains underexplored. This gap is compounded by the lack of datasets
and benchmarks that capture the global diversity of music. To address these
challenges, we introduce GlobalDISCO, a large-scale dataset consisting of 73k
music tracks generated by state-of-the-art commercial generative music models,
along with paired links to 93k reference tracks in LAION-DISCO-12M. The dataset
spans 147 languages and includes musical style prompts extracted from
MusicBrainz and Wikipedia. The dataset is globally balanced, representing
musical styles from artists across 79 countries and five continents. Our
evaluation reveals large disparities in music quality and alignment with
reference music between high-resource and low-resource regions. Furthermore, we
find marked differences in model performance between mainstream and
geographically niche genres, including cases where models generate music for
regional genres that more closely align with the distribution of mainstream
styles.

</details>


### [31] [Multi-bit Audio Watermarking](https://arxiv.org/abs/2510.01968)
*Luca A. Lanzendörfer,Kyle Fearne,Florian Grötschla,Roger Wattenhofer*

Main category: cs.SD

TL;DR: Timbru是一种后处理音频水印模型，无需训练嵌入器-检测器模型就能实现最先进的鲁棒性和不可感知性平衡。它通过预训练音频VAE的潜在空间添加不可感知扰动，并使用预训练CLAP模型提取水印。


<details>
  <summary>Details</summary>
Motivation: 现有音频水印方法在鲁棒性和不可感知性之间难以平衡，且通常需要训练专门的嵌入器-检测器模型。本文旨在开发一种无需训练、高效且能保持良好感知质量的音频水印方法。

Method: 对任何44.1kHz立体声音乐片段，使用预训练音频VAE的潜在空间进行每音频梯度优化，添加不可感知扰动，通过组合消息和感知损失进行指导，最后使用预训练CLAP模型提取水印。

Result: 在MUSDB18-HQ数据集上评估16位水印，相比AudioSeal、WavMark和SilentCipher，在各种攻击（滤波、噪声、压缩、重采样、裁剪、再生）下获得最佳平均比特错误率，同时保持感知质量。

Conclusion: Timbru展示了一种高效、无需数据集的不可感知音频水印路径，在鲁棒性和不可感知性方面达到最优平衡。

Abstract: We present Timbru, a post-hoc audio watermarking model that achieves
state-of-the-art robustness and imperceptibility trade-offs without training an
embedder-detector model. Given any 44.1 kHz stereo music snippet, our method
performs per-audio gradient optimization to add imperceptible perturbations in
the latent space of a pretrained audio VAE, guided by a combined message and
perceptual loss. The watermark can then be extracted using a pretrained CLAP
model. We evaluate 16-bit watermarking on MUSDB18-HQ against AudioSeal,
WavMark, and SilentCipher across common filtering, noise, compression,
resampling, cropping, and regeneration attacks. Our approach attains the best
average bit error rates, while preserving perceptual quality, demonstrating an
efficient, dataset-free path to imperceptible audio watermarking.

</details>


### [32] [SoundReactor: Frame-level Online Video-to-Audio Generation](https://arxiv.org/abs/2510.02110)
*Koichi Saito,Julian Tanke,Christian Simon,Masato Ishii,Kazuki Shimada,Zachary Novack,Zhi Zhong,Akio Hayakawa,Takashi Shibuya,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: 提出了首个帧级在线视频到音频生成框架SoundReactor，能够实时生成与视频同步的高质量立体声音频，解决了现有离线V2A模型无法用于交互式应用的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有视频到音频生成模型都是离线工作，需要整个视频序列或帧块作为输入，这限制了它们在直播内容创作和生成世界模型等交互式应用中的使用。

Method: 使用基于解码器的因果transformer架构处理连续音频潜在表示，利用DINOv2视觉编码器的网格特征进行视觉条件化，通过扩散预训练和一致性微调来加速解码。

Result: 在AAA游戏视频基准测试中成功生成了语义和时间对齐的高质量全频段立体声音频，在30FPS、480p视频上实现了低延迟（26.3-31.5ms），并通过了客观和人类评估验证。

Conclusion: SoundReactor是首个专门为帧级在线V2A生成设计的有效框架，实现了端到端因果性和低延迟，为交互式音频生成应用开辟了新途径。

Abstract: Prevailing Video-to-Audio (V2A) generation models operate offline, assuming
an entire video sequence or chunks of frames are available beforehand. This
critically limits their use in interactive applications such as live content
creation and emerging generative world models. To address this gap, we
introduce the novel task of frame-level online V2A generation, where a model
autoregressively generates audio from video without access to future video
frames. Furthermore, we propose SoundReactor, which, to the best of our
knowledge, is the first simple yet effective framework explicitly tailored for
this task. Our design enforces end-to-end causality and targets low per-frame
latency with audio-visual synchronization. Our model's backbone is a
decoder-only causal transformer over continuous audio latents. For vision
conditioning, it leverages grid (patch) features extracted from the smallest
variant of the DINOv2 vision encoder, which are aggregated into a single token
per frame to maintain end-to-end causality and efficiency. The model is trained
through a diffusion pre-training followed by consistency fine-tuning to
accelerate the diffusion head decoding. On a benchmark of diverse gameplay
videos from AAA titles, our model successfully generates semantically and
temporally aligned, high-quality full-band stereo audio, validated by both
objective and human evaluations. Furthermore, our model achieves low per-frame
waveform-level latency (26.3ms with the head NFE=1, 31.5ms with NFE=4) on
30FPS, 480p videos using a single H100. Demo samples are available at
https://koichi-saito-sony.github.io/soundreactor/.

</details>


### [33] [Go witheFlow: Real-time Emotion Driven Audio Effects Modulation](https://arxiv.org/abs/2510.02171)
*Edmund Dervakos,Spyridon Kantarelis,Vassilis Lyberatos,Jason Liartis,Giorgos Stamou*

Main category: cs.SD

TL;DR: 开发了witheFlow系统，通过生物信号和音频特征实时调节音频效果，增强音乐表演的人机协作


<details>
  <summary>Details</summary>
Motivation: 音乐表演是人类特有的情感表达活动，机器缺乏情感体验能力，因此探索人机协作在音乐表演中的应用具有重要意义

Method: 设计轻量级的witheFlow系统，从生物信号和音频中提取特征，自动调节音频效果，可在笔记本电脑上本地运行

Result: 系统目前处于概念验证阶段，开源且需要兼容的数字音频工作站和传感器支持

Conclusion: witheFlow系统为探索人机协作音乐表演提供了可行方案，通过生物信号和音频特征的实时处理增强表演效果

Abstract: Music performance is a distinctly human activity, intrinsically linked to the
performer's ability to convey, evoke, or express emotion. Machines cannot
perform music in the human sense; they can produce, reproduce, execute, or
synthesize music, but they lack the capacity for affective or emotional
experience. As such, music performance is an ideal candidate through which to
explore aspects of collaboration between humans and machines. In this paper, we
introduce the witheFlow system, designed to enhance real-time music performance
by automatically modulating audio effects based on features extracted from both
biosignals and the audio itself. The system, currently in a proof-of-concept
phase, is designed to be lightweight, able to run locally on a laptop, and is
open-source given the availability of a compatible Digital Audio Workstation
and sensors.

</details>


### [34] [High-Fidelity Speech Enhancement via Discrete Audio Tokens](https://arxiv.org/abs/2510.02187)
*Luca A. Lanzendörfer,Frédéric Berdoz,Antonis Asonitis,Roger Wattenhofer*

Main category: cs.SD

TL;DR: DAC-SE1是一个基于语言模型的简化语音增强框架，利用离散高分辨率音频表示，在保持语义连贯性的同时保留精细的声学细节，超越了现有的自回归语音增强方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归变换器语音增强方法虽然表现出色，但通常依赖复杂的多阶段流程和低采样率编解码器，限制了其在广泛和任务特定语音增强中的应用。

Method: 引入DAC-SE1框架，利用离散高分辨率音频表示，简化了基于语言模型的语音增强流程，同时保持声学细节和语义连贯性。

Result: 实验表明DAC-SE1在客观感知指标和MUSHRA人类评估中均超越了最先进的自回归语音增强方法。

Conclusion: DAC-SE1为可扩展、统一和高质量的语音增强研究提供了新的解决方案，代码和模型已开源以支持进一步研究。

Abstract: Recent autoregressive transformer-based speech enhancement (SE) methods have
shown promising results by leveraging advanced semantic understanding and
contextual modeling of speech. However, these approaches often rely on complex
multi-stage pipelines and low sampling rate codecs, limiting them to narrow and
task-specific speech enhancement. In this work, we introduce DAC-SE1, a
simplified language model-based SE framework leveraging discrete
high-resolution audio representations; DAC-SE1 preserves fine-grained acoustic
details while maintaining semantic coherence. Our experiments show that DAC-SE1
surpasses state-of-the-art autoregressive SE methods on both objective
perceptual metrics and in a MUSHRA human evaluation. We release our codebase
and model checkpoints to support further research in scalable, unified, and
high-quality speech enhancement.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 20]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.SD](#cs.SD) [Total: 11]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [JaneEye: A 12-nm 2K-FPS 18.9-$μ$J/Frame Event-based Eye Tracking Accelerator](https://arxiv.org/abs/2510.01213)
*Tao Han,Ang Li,Qinyu Chen,Chang Gao*

Main category: eess.SP

TL;DR: JaneEye是一个用于XR设备的基于事件相机的节能眼动追踪硬件加速器，采用轻量级神经网络和硬件优化，实现高精度、低延迟和低功耗的眼动追踪。


<details>
  <summary>Details</summary>
Motivation: 传统帧式眼动追踪系统在XR应用中难以满足高精度、低延迟和低功耗的要求，而事件相机提供了超高的时间分辨率和低功耗的替代方案。

Method: 提出超轻量级神经网络架构，包含新颖的ConvJANET层（仅保留遗忘门的简化ConvLSTM），使用线性激活函数近似和定点量化，通过软硬件协同设计实现高效硬件加速。

Result: 在3ET+数据集上达到2.45像素误差，仅使用17.6K参数，支持1250Hz事件帧率。12nm ASIC实现400MHz运行，端到端延迟0.5ms（相当于2000FPS），能效18.9μJ/帧。

Conclusion: JaneEye为下一代XR可穿戴设备设定了低功耗、高性能眼动追踪解决方案的新基准。

Abstract: Eye tracking has become a key technology for gaze-based interactions in
Extended Reality (XR). However, conventional frame-based eye-tracking systems
often fall short of XR's stringent requirements for high accuracy, low latency,
and energy efficiency. Event cameras present a compelling alternative, offering
ultra-high temporal resolution and low power consumption. In this paper, we
present JaneEye, an energy-efficient event-based eye-tracking hardware
accelerator designed specifically for wearable devices, leveraging sparse,
high-temporal-resolution event data. We introduce an ultra-lightweight neural
network architecture featuring a novel ConvJANET layer, which simplifies the
traditional ConvLSTM by retaining only the forget gate, thereby halving
computational complexity without sacrificing temporal modeling capability. Our
proposed model achieves high accuracy with a pixel error of 2.45 on the 3ET+
dataset, using only 17.6K parameters, with up to 1250 Hz event frame rate. To
further enhance hardware efficiency, we employ custom linear approximations of
activation functions (hardsigmoid and hardtanh) and fixed-point quantization.
Through software-hardware co-design, our 12-nm ASIC implementation operates at
400 MHz, delivering an end-to-end latency of 0.5 ms (equivalent to 2000 Frames
Per Second (FPS)) at an energy efficiency of 18.9 $\mu$J/frame. JaneEye sets a
new benchmark in low-power, high-performance eye-tracking solutions suitable
for integration into next-generation XR wearables.

</details>


### [2] [Satellite Assignment Policy Learning for Coexistence in LEO Networks](https://arxiv.org/abs/2510.01408)
*Jeong Min Kong,Ian P. Roberts*

Main category: eess.SP

TL;DR: 论文提出了一种基于图结构学习的算法，用于推断低地球轨道卫星系统中主系统的卫星分配策略，帮助次系统避免对主用户造成干扰。


<details>
  <summary>Details</summary>
Motivation: 在LEO卫星系统中，次系统需要避免对主用户造成过度干扰，但主系统的卫星分配策略未公开。因此需要开发方法来推断这些策略。

Method: 使用端到端的图结构学习算法，基于有限的历史数据学习最高仰角主卫星分配策略，能够直接将主卫星坐标映射为对主用户的分配决策。

Result: 模拟结果显示，该方法比最佳基线方法提升了约15%的预测准确率。

Conclusion: 提出的图结构学习算法能够有效推断主系统的卫星分配策略，为次系统提供可靠的干扰管理方案。

Abstract: Unlike in terrestrial cellular networks, certain frequency bands for
low-earth orbit (LEO) satellite systems have thus far been allocated on a
non-exclusive basis. In this context, systems that launch their satellites
earlier (referred to as primary systems) are given spectrum access priority
over those that launch later, known as secondary systems. For a secondary
system to function, it is expected to either coordinate with primary systems or
ensure that it does not cause excessive interference to primary ground users.
Reliably meeting this interference constraint requires real-time knowledge of
the receive beams of primary users, which in turn depends on the primary
satellite-to-primary user associations. However, in practice, primary systems
have thus far not publicly disclosed their satellite assignment policies;
therefore, it becomes essential for secondary systems to develop methods to
infer such policies. Assuming there is limited historical data indicating which
primary satellites have served which primary users, we propose an end-to-end
graph structure learning-based algorithm for learning highest elevation primary
satellite assignment policies, that, upon deployment, can directly map the
primary satellite coordinates into assignment decisions for the primary users.
Simulation results show that our method can outperform the best baseline,
achieving approximately a 15% improvement in prediction accuracy.

</details>


### [3] [Delay-Augmented Stacked Intelligent Surfaces: Potential, Challenges, and Opportunities](https://arxiv.org/abs/2510.01411)
*Hibatallah Alwazani,Omran Abbas,Loic Markley,Anas Chaaban*

Main category: eess.SP

TL;DR: 提出了延迟增强堆叠智能表面(DA-SIS)概念，通过在SIS中集成可调延迟单元，使其能够同时进行空间波域和时域信号处理，并展示了其在消除多径干扰方面的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 传统堆叠智能表面(SIS)主要用于空间波域信号处理，但缺乏时域处理能力。为了扩展SIS的功能，使其能够同时处理空间和时间维度，需要引入延迟单元来实现时域处理。

Method: 在SIS中集成可调延迟单元，形成延迟增强SIS(DA-SIS)。通过分析延迟单元的实现可行性，并研究DA-SIS作为模拟均衡器消除多径引起的符号间干扰(ISI)的应用案例。

Result: 研究表明DA-SIS在均衡性能方面具有潜力，通过比特误码率(BER)分析显示单元数量影响均衡效果，与数字均衡器相比表现出竞争力。

Conclusion: DA-SIS为智能表面技术开辟了新方向，能够同时进行空间和时域处理，在消除多径干扰等方面具有应用前景，需要进一步研究来完善这一概念。

Abstract: Stacked intelligent surfaces (SIS)s have been proposed recently as an
enabling technology for Holographic Multiple Input Multiple Output (HMIMO) and
Ultra-massive MIMO (umMIMO) technologies. Their utility can extend beyond
spatial wave-domain processing of signals if they are enhanced with
strategically-tuned symbol-duration level delays to enable temporal processing
as well. In this work, we introduce the idea of a delay-augmented SIS (DA-SIS).
We shed light on the feasibility of realizing delay units in an SIS. Then, we
discuss the relevance of the proposed DA-SIS and present a use case that
illustrates its potential, wherein the DA-SIS serves as an analog equalizer
that aids in eliminating multi-path-induced inter-symbol-interference (ISI). We
show how the number of elements affect the equalization process using the bit
error rate (BER) as a metric, and demonstrate the potential of the DA-SIS in
equalization via comparing with digital equalizers as a benchmark. Finally, we
present opportunities and future research directions that can be undertaken to
bring this idea to fruition.

</details>


### [4] [A Drone-mounted Magnetometer System for Automatic Interference Removal and Landmine Detection](https://arxiv.org/abs/2510.01417)
*Alex Paul Hoffmann,Matthew G. Finley,Eftyhia Zesta,Mark B. Moldwin,Lauro V. Ojeda*

Main category: eess.SP

TL;DR: 提出了一种基于无人机搭载双磁力计的自动化干扰消除和地雷检测方法，通过两步处理实现高精度地雷探测


<details>
  <summary>Details</summary>
Motivation: 地雷在冲突地区广泛使用，对平民构成持续威胁，而现有无人机磁力计探测方法面临电子设备干扰的技术挑战

Method: 采用两步法：第一步使用WAIC-UP方法消除无人机电机干扰，第二步使用RUDE算法检测地雷信号

Result: 该方法在蒙特卡洛模拟中验证了高保真度地雷探测能力，并在不同飞行高度下保持良好性能

Conclusion: WAIC-UP/RUDE方法以低计算成本实现了高精度地雷探测，简化了磁力测量有效载荷设计

Abstract: Landmines have been extensively used in conflict zones as an indiscriminate
weapon to control military movements, often remaining active long after
hostilities have ended. Their presence poses a persistent danger to civilians,
hindering post-war recovery efforts, causing injuries or death, and restricting
access to essential land for agriculture and infrastructure. Unmanned aerial
vehicles (UAV) equipped with magnetometers are commonly used to detect remnant
hidden landmines but come with significant technical challenges due to magnetic
field interference from UAV electronics such as motors. We propose the use of a
frame-mounted UAV-borne two-magnetometer payload to perform a two-step
automated interference removal and landmine detection analysis. The first step
removes interference via the Wavelet-Adaptive Interference Cancellation for
Underdetermined Platform (WAIC-UP) method designed for spaceflight
magnetometers. The second method uses the Rapid Unsupervised Detection of
Events (RUDE) algorithm to detect landmine signatures. This two-step
WAIC-UP/RUDE approach with multiple magnetometers achieves high-fidelity
ordinance detection at a low computational cost and simplifies the design of
magnetic survey payloads. We validate the method through a Monte Carlo
simulation of randomized landmine placements in a 10 x 10 m square grid and
drone motor interference. Additionally, we assess the efficacy of the algorithm
by varying the drone's altitude, examining its performance at different heights
above the ground.

</details>


### [5] [Meta-Learning-Driven Resource Optimization in Full-Duplex ISAC with Movable Antennas](https://arxiv.org/abs/2510.01437)
*Ali Amhaz,Shreya Khisa,Mohamed Elhattab,Chadi Assi,Sanaa Sharafeddine*

Main category: eess.SP

TL;DR: 本文研究了一种基于可移动天线的全双工基站系统，在同时服务上下行用户的同时实现目标检测感知功能，通过联合优化波束成形、用户功率和天线位置来最大化回波信干噪比。


<details>
  <summary>Details</summary>
Motivation: 支持集成感知与通信技术，通过可移动天线优化系统性能，在满足通信服务质量的同时提升感知能力。

Method: 采用梯度元学习方法处理大规模非凸优化问题，联合优化发射/接收波束成形向量、上行用户发射功率和两个基站的可移动天线位置。

Result: 数值结果表明所提元学习方法能达到99%的最优解性能，基于可移动天线的方案优于多个基准方法。

Conclusion: 可移动天线方案在实际ISAC应用中具有显著优势，提出的元学习方法能有效解决复杂优化问题。

Abstract: This paper investigates a full-duplex (FD) scenario where a base station (BS)
equipped with movable antennas (MAs) simultaneously provides communication
services to a set of downlink (DL) and uplink (UL) users while also enabling
sensing functionalities for target detection, thereby supporting integrated
sensing and communication (ISAC) technology. Additionally, a receiving BS, also
equipped with MAs (denoted as BS R), is responsible for capturing the reflected
echo. To optimize this setup, we formulate an optimization problem aimed at
maximizing the signal-to-noise and interference ratio (SINR) of the captured
echo. This is achieved by jointly optimizing the transmit beamforming vectors
at the FD BS, the receiving beamforming vectors at both the FD BS and BS R, the
UL users' transmit power, and the MAs' positions at both BSs, all while
satisfying the quality-of-service (QoS) requirements for both sensing and
communication. Given the non-convex nature of the problem and the high coupling
between the variables, we employ a gradient-based meta-learning (GML) approach
tailored for large-scale optimization. Numerical results demonstrate the
effectiveness of the proposed meta-learning approach, achieving results within
99% of the optimal solution. Furthermore, the MA-based scheme outperforms
several benchmark approaches, highlighting its advantages in practical ISAC
applications.

</details>


### [6] [The Analysis and Performance of LODC-OFDM Signal in Nonlinear Rydberg Atomic Sensor](https://arxiv.org/abs/2510.01605)
*Hao Wu,Xinyuan Yao,Rui Ni,Chen Gong*

Main category: eess.SP

TL;DR: 提出了一种针对里德堡原子传感器的LODC-OFDM方案，解决了宽带OFDM接收挑战，并通过实验验证了理论分析的正确性。


<details>
  <summary>Details</summary>
Motivation: 里德堡原子传感器在射频测量中具有高灵敏度，但其光学接口的单极性特性限制了传统OFDM接收，需要采用单极性OFDM方案。

Method: 建立了里德堡原子传感器的AM-AM特性经验近似函数，基于DCO-OFDM框架提出了LODC-OFDM方案，并采用Bussgang定理分析非线性失真。

Result: 推导了泰勒级数展开和理想预失真情况下的闭式解，实验结果表明理论与实验数据吻合良好。

Conclusion: LODC-OFDM方案有效解决了里德堡原子传感器的宽带OFDM接收问题，为兼容信号传输提供了可行方案。

Abstract: Rydberg atomic sensors have been seen as novel radio frequency (RF)
measurements and the high sensitivity to a large range of frequencies makes it
attractive for communications reception. However, the signal sensing process in
Rydberg system involves sequential transduction from electromagnetic waves to
optical signals and finally to electrical signals. The unipolar characteristic
of the optical interface inherently restricts conventional OFDM reception.
Therefore, adopting unipolar OFDM schemes, inspired by optical communication
systems, becomes essential for compatible signal transmission. In this work, we
investigate the amplitude modulation-to-amplitude modulation (AM-AM)
characteristics of Rydberg atomic sensors, establishing an empirical
approximation function. Building on the direct current-biased optical
orthogonal frequency division multiplexing (DCO-OFDM) framework, we propose a
novel local oscillator direct current-biased OFDM (LODC-OFDM) scheme
specifically optimized for Rydberg-based sensing, effectively addressing the
broadband OFDM reception challenge. Then, we adopt Bussgang theorem to analyze
the nonlinear distortion of LODC-OFDM signals and the results in closed-form
solutions are derived for AM/AM curves approximated by Taylor series expansion
and for the ideal pre-distortion case. In real experiments, the experimental
and theoretical results fit well.

</details>


### [7] [SEP Analysis of 1-Bit Quantized SIMO Systems with QPSK over Fading Channels](https://arxiv.org/abs/2510.01707)
*Amila Ravinath,Minhua Ding,Bikshapathi Gouda,Italo Atzeni,Antti Tölli*

Main category: eess.SP

TL;DR: 分析了1比特量化SIMO系统在瑞利衰落信道和QPSK调制下的平均符号错误概率，推导了MRC接收的精确SEP表达式，并确定了SIMO-MRC和SIMO-SC系统的分集增益和编码增益。


<details>
  <summary>Details</summary>
Motivation: 先前研究仅部分表征了选择合并(SC)的分集增益，需要更全面的分析来理解1比特量化SIMO系统的性能特性。

Method: 采用新颖的分析方法，推导了1比特量化SIMO系统在QPSK调制和MRC接收下的精确SEP表达式。

Result: 获得了SIMO-MRC系统的精确SEP表达式，并量化了SIMO-MRC和SIMO-SC系统的分集增益和编码增益，扩展了先前结果。

Conclusion: 该研究为1比特量化SIMO系统提供了完整的性能分析框架，填补了先前研究的空白，对系统设计具有指导意义。

Abstract: The average symbol error probability (SEP) of a 1-bit quantized single-input
multiple-output (SIMO) system is analyzed under Rayleigh fading channels and
quadrature phase-shift keying (QPSK) modulation. Previous studies have
partially characterized the diversity gain for selection combining (SC). In
this paper, leveraging a novel analytical method, an exact analytical SEP
expression is derived for a 1-bit quantized SIMO system employing QPSK
modulation at the transmitter and maximum ratio combining (MRC) at the
receiver. The corresponding diversity and coding gains of a SIMO-MRC system are
also determined. Furthermore, the diversity and coding gains of a 1-bit
quantized SIMO-SC system are quantified for an arbitrary number of receive
antennas, thereby extending and complementing prior results.

</details>


### [8] [3D 8-Ary Noise Modulation Using Bayesian- and Kurtosis-based Detectors](https://arxiv.org/abs/2510.01748)
*Hadi Zayyani,Felipe A. P. de Figueiredo,Mohammad Salman,Rausley A. A. de Souza*

Main category: eess.SP

TL;DR: 提出了一种新颖的三维8元噪声调制方案，通过引入高斯混合分布的概率维度，在传统均值和方差维度基础上新增第三维度，使每个传输符号携带3比特信息，显著提升数据速率。


<details>
  <summary>Details</summary>
Motivation: 现有二维噪声调制方案数据速率有限，需要开发更高维度的调制方案来提升通信系统的数据传输能力。

Method: 采用三维调制框架：均值调制第一子信道比特（阈值检测）、方差调制第二子信道比特（最大似然检测）、高斯混合概率调制第三子信道比特（峰度、JB检验和贝叶斯假设检测）。

Result: 仿真结果显示，与现有二维方案相比，第三子信道比特实现了较低误码率，数据速率分别比广义二次噪声调制器和经典二元KLJN噪声调制器提高1.5倍和3倍。峰度检测器提供低复杂度解决方案，误码率约为0.06。

Conclusion: 该三维噪声调制方案成功扩展了调制维度，在保持可接受误码率的同时显著提升了数据速率，为噪声调制通信系统提供了新的发展方向。

Abstract: This paper presents a novel three-dimensional (3D) 8-ary noise modulation
scheme that introduces a new dimension: the mixture probability of a Mixture of
Gaussian (MoG) distribution. This proposed approach utilizes the dimensions of
mean and variance, in addition to the new probability dimension. Within this
framework, each transmitted symbol carries three bits, each corresponding to a
distinct sub-channel. For detection, a combination of specialized detectors is
employed: a simple threshold based detector for the first sub-channel bit
(modulated by the mean), a Maximum-Likelihood (ML) detector for the second
sub-channel bit (modulated by the variance), a Kurtosis-based, Jarque-Bera (JB)
test, and Bayesian Hypothesis (BHT)-based detectors for the third bit
(modulated by the MoG probability). The Kurtosis- and JB-based detectors
specifically distinguish between Gaussian (or near-Gaussian) and non-Gaussian
MoG distributions by leveraging higher-order statistical measures. The Bit
Error Probabilities (BEPs) are derived for the threshold-, Kurtosis-, and
BHT-based detectors. The optimum threshold for the Kurtosis-based detector is
also derived in a tractable manner. Simulation results demonstrate that a
comparably low BEP is achieved for the third sub-channel bit relative to
existing two-dimensional (2D) schemes. Simultaneously, the proposed scheme
increases the data rate by a factor of 1.5 and 3 compared to the Generalized
Quadratic noise modulator and the classical binary KLJN noise modulator,
respectively. Furthermore, the Kurtosis-based detector offers a low-complexity
solution, achieving an acceptable BEP of approximately 0.06.

</details>


### [9] [Exactly or Approximately Wasserstein Distributionally Robust Estimation According to Wasserstein Radii Being Small or Large](https://arxiv.org/abs/2510.01763)
*Xiao Ding,Enbin Song,Dunbiao Niu,Zhujun Cao,Qingjiang Shi*

Main category: eess.SP

TL;DR: 该论文研究了在Wasserstein距离约束下的鲁棒估计问题，证明了无限维非凸极小极大问题与有限维问题的等价性，给出了鞍点存在的充要条件，并在鞍点不存在时提出了鲁棒线性估计器。


<details>
  <summary>Details</summary>
Motivation: 研究在参数和噪声分布受Wasserstein距离约束的线性测量模型中，如何解决无限维非凸极小极大问题，特别是鞍点存在性的问题。

Method: 通过证明无限维问题与有限维问题的等价性，提出可验证的充要条件，并在鞍点不存在时求解有限维非凸极小极大问题来获得鲁棒线性估计器。

Result: 给出了鞍点存在的充要条件及其简化形式，证明了当Wasserstein半径足够小时鞍点总是存在，并提出了在鞍点不存在时的鲁棒线性估计方法。

Conclusion: 该研究为Wasserstein距离约束下的鲁棒估计问题提供了理论分析和实用解决方案，包括鞍点存在性条件和鲁棒估计器的构造方法。

Abstract: This paper primarily considers the robust estimation problem under
Wasserstein distance constraints on the parameter and noise distributions in
the linear measurement model with additive noise, which can be formulated as an
infinite-dimensional nonconvex minimax problem. We prove that the existence of
a saddle point for this problem is equivalent to that for a finite-dimensional
minimax problem, and give a counterexample demonstrating that the saddle point
may not exist. Motivated by this observation, we present a verifiable necessary
and sufficient condition whose parameters can be derived from a convex problem
and its dual. Additionally, we also introduce a simplified sufficient
condition, which intuitively indicates that when the Wasserstein radii are
small enough, the saddle point always exists. In the absence of the saddle
point, we solve an finite-dimensional nonconvex minimax problem, obtained by
restricting the estimator to be linear. Its optimal value establishes an upper
bound on the robust estimation problem, while its optimal solution yields a
robust linear estimator. Numerical experiments are also provided to validate
our theoretical results.

</details>


### [10] [Composite Generalized Quadratic Noise Modulation via Signal Addition: Towards Higher Dimensional Noise Modulations](https://arxiv.org/abs/2510.01776)
*Hadi Zayyani,Mohammad Salman,Felipe A. P. de Figueiredo,Rausley A. A. de Souza*

Main category: eess.SP

TL;DR: 本文提出通过叠加两个广义二次噪声调制器(GQNM)的输出，创建了一种类似经典通信中QAM调制器的16进制噪声调制器。该方法通过选择满足理论可区分性条件的参数，相比KLJN和GQNM调制器获得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 为了创建更高阶的噪声调制方案，提高通信系统的性能，特别是在比特错误概率方面获得更好的表现。

Method: 通过简单叠加两个GQNM调制器的输出，创建16进制噪声调制器，将信息比特调制到四个不同的均值和四个不同的方差上。

Result: 仿真验证表明，该方法相比KLJN调制器和GQNM调制器具有更好的性能，实现了更小的比特错误概率。

Conclusion: 通过增加调制器、发射机和接收机检测器的复杂度，可以获得更好的性能表现，并且该方法可以扩展到高于16进制的调制方案。

Abstract: This letter proposes superposing two Generalized Quadratic Noise Modulators
(GQNM) by simply adding their outputs. It creates a 16-ary noise modulator that
resembles QAM modulators in classical communication. It modulates the
information bits on four different means and four different variances. It could
also be applied to reach higher-order modulations than 16-ary schemes by adding
the outputs of more than two modulators, which is not discussed in detail in
this letter and left for future work. By selecting the parameters necessary for
satisfying the theoretical distinguishability conditions provided in the paper,
we can reach better performances in comparison to the Kirchhoff-Law Johnson
Noise (KLJN) modulator and the GQNM modulator, which is verified by the
simulations. The better result in terms of smaller Bit Error Probability (BEP)
is achieved by increasing the complexity in the modulator, the transmitter, and
the detectors in the receiver.

</details>


### [11] [Closed-form Single UAV-aided Emitter Localization and Trajectory Design Using Doppler and TOA Measurements](https://arxiv.org/abs/2510.01778)
*Samaneh Motie,Hadi Zayyani,Mohammad Salman,Hasan Abu Hilal*

Main category: eess.SP

TL;DR: 提出了一种使用无人机辅助的定位算法，结合多普勒和到达时间测量，通过约束最小二乘优化获得闭式解，并提供了无人机轨迹设计的闭式解。


<details>
  <summary>Details</summary>
Motivation: 现有的多普勒定位算法基于非凸函数，计算复杂且难以求解。本文旨在通过结合ToA测量，将问题转化为凸优化问题，获得闭式解。

Method: 在多普勒最小二乘代价函数中引入ToA测量，形成二次凸函数，其极小值位于一条直线上。结合ToA测量和极小值直线方程，通过约束LS优化获得发射器位置的闭式解。

Result: 仿真实验表明，与文献中的其他算法相比，所提算法具有更好的性能。

Conclusion: 提出的算法通过结合多普勒和ToA测量，成功将定位问题转化为凸优化问题，获得了闭式解，同时提供了无人机轨迹设计的闭式解，算法性能优于现有方法。

Abstract: In this paper, a single Unmanned-Aerial-Vehicle (UAV)-aided localization
algorithm which uses both Doppler and Time of Arrival (ToA) measurements is
presented. In contrast to Doppler-based localization algorithms which are based
on non-convex functions, exploiting ToA measurements in a Least-Square (LS)
Doppler-based cost function, leads to a quadratic convex function whose
minimizer lies on a line. Utilizing the ToA measurements in addition to the
linear equation of minimizer, a closed form solution is obtained for the
emitter location using a constrained LS optimization. In addition, a trajectory
design of the UAV is provided which has also closed-form solution. Simulation
experiments demonstrate the effectiveness of the proposed algorithm in
comparison to some others in the literature.

</details>


### [12] [Performance Optimization for Movable Antenna Enhanced MISO-OFDM Systems](https://arxiv.org/abs/2510.01789)
*Ruixi Feng,Weidong Mei,Lele Lu,Xin Wei,Zhi Chen,Zhen Gao,Boyu Ning*

Main category: eess.SP

TL;DR: 本文研究了可移动天线在MISO-OFDM系统中的位置优化问题，提出了一种基于图论的离散化方法来解决频率平坦特性的挑战，在低信噪比下实现了优于固定位置天线的性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注窄带可移动天线系统，而宽带OFDM系统中天线位置优化面临频率平坦特性的挑战，即天线位置需要适应不同子载波的信道条件。

Method: 将连续移动区域离散化为采样点，将位置优化转化为离散点选择问题，开发了基于分支定界框架的部分枚举算法，并引入图论方法剪枝次优解。在低信噪比下提出了简化的图论算法。

Result: 仿真结果表明，所提算法优于传统固定位置天线，而基于窄带的优化方法也能达到接近最优的性能。

Conclusion: 可移动天线技术通过优化天线位置能有效提升宽带OFDM系统的性能，提出的离散化方法和图论算法为解决频率平坦特性挑战提供了有效途径。

Abstract: Movable antenna (MA) technology offers a flexible approach to enhancing
wireless channel conditions by adjusting antenna positions within a designated
region. While most existing works focus on narrowband MA systems, this paper
investigates MA position optimization for an MA-enhanced multiple-input
single-output (MISO) orthogonal frequency-division multiplexing (OFDM) system.
This problem appears to be particularly challenging due to the frequency-flat
nature of MA positioning, which should accommodate the channel conditions
across different subcarriers. To overcome this challenge, we discretize the
movement region into a multitude of sampling points, thereby converting the
continuous position optimization problem into a discrete point selection
problem. Although this problem is combinatorial, we develop an efficient
partial enumeration algorithm to find the optimal solution using a
branch-and-bound framework, where a graph-theoretic method is incorporated to
effectively prune suboptimal solutions. In the low signal-to-noise ratio (SNR)
regime, a simplified graph-based algorithm is also proposed to obtain the
optimal MA positions without the need for enumeration. Simulation results
reveal that the proposed algorithm outperforms conventional fixed-position
antennas (FPAs), while narrowband-based antenna position optimization can
achieve near-optimal performance.

</details>


### [13] [NGGAN: Noise Generation GAN Based on the Practical Measurement Dataset for Narrowband Powerline Communications](https://arxiv.org/abs/2510.01850)
*Ying-Ren Chien,Po-Heng Chou,You-Jie Peng,Chun-Yuan Huang,Hen-Wai Tsao,Yu Tsao*

Main category: eess.SP

TL;DR: 提出了一种基于生成对抗网络(GAN)的噪声生成模型NGGAN，用于学习窄带电力线通信(NB-PLC)系统中实际测量噪声的复杂特性，以进行数据增强。


<details>
  <summary>Details</summary>
Motivation: 现有的数学噪声生成模型只能捕捉加性噪声的部分特性，无法全面统计非周期性异步脉冲噪声，这是增强NB-PLC收发器脉冲噪声处理的关键问题。

Method: 通过商用NB-PLC调制解调器的模拟耦合和带通滤波电路测量NB-PLC噪声构建真实数据集；设计NGGAN模型，使用Wasserstein距离作为损失函数，并设计输入信号长度以促进循环平稳噪声生成。

Result: 仿真结果表明，基于波形特征训练的NGGAN在生成噪声质量方面更接近实际测量数据集。

Conclusion: 提出的NGGAN模型能够更好地学习实际NB-PLC系统中复杂噪声的统计特性，为数据增强提供了有效解决方案。

Abstract: Capturing comprehensive statistics of nonperiodic asynchronous impulsive
noise is a critical issue in enhancing impulse noise processing for narrowband
powerline communication (NB-PLC) transceivers. However, existing mathematical
noise generative models capture only some of the characteristics of additive
noise. Therefore, we propose a generative adversarial network (GAN), called the
noise-generation GAN (NGGAN), that learns the complicated characteristics of
practically measured noise samples for data augmentation. To closely match the
statistics of complicated noise in NB-PLC systems, we measured the NB-PLC noise
via the analog coupling and bandpass filtering circuits of a commercial NB-PLC
modem to build a realistic dataset. Specifically, the NGGAN design approaches
based on the practically measured dataset are as follows: (i) we design the
length of input signals that the NGGAN model can fit to facilitate
cyclo-stationary noise generation. (ii) Wasserstein distance is used as a loss
function to enhance the similarity between the generated noise and the training
dataset and ensure that the sample diversity is sufficient for various
applications. (iii) To measure the similarity performance of the GAN-based
models based on mathematical and practically measured datasets, we perform
quantitative and qualitative analyses. The training datasets include (1) a
piecewise spectral cyclo-stationary Gaussian model (PSCGM), (2) a
frequency-shift (FRESH) filter, and (3) practical measurements from NB-PLC
systems. Simulation results demonstrate that the proposed NGGAN trained using
waveform characteristics is closer to the practically measured dataset in terms
of the quality of the generated noise.

</details>


### [14] [Wearable and Ultra-Low-Power Fusion of EMG and A-Mode US for Hand-Wrist Kinematic Tracking](https://arxiv.org/abs/2510.02000)
*Giusy Spacone,Sebastian Frey,Mattia Orlandi,Pierangelo Maria Rapa,Victor Kartsch,Simone Benatti,Luca Benini,Andrea Cossettini*

Main category: eess.SP

TL;DR: 提出了一种超低功耗系统，融合表面肌电信号和A型超声信号，用于连续跟踪23个手部和腕部自由度，相比单一模态具有更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有手势识别系统功耗高且仅限于离散手势分类，需要开发更节能、能连续跟踪手势的系统。

Method: 使用超低功耗平台同时采集8通道EMG和4通道A型US信号，采用轻量级编码器-解码器架构和多任务学习来同时估计手部和腕部关节角度。

Result: 在传感器重新定位条件下，EMG-US融合的均方根误差为10.6°±2.0°，优于单独的EMG(12.0°±1°)和US(13.1°±2.6°)，R²得分为0.61±0.1。

Conclusion: EMG-US传感器融合方法在连续手势跟踪方面表现优于单一模态，为开发更鲁棒可靠的人机交互系统提供了可行方案。

Abstract: Hand gesture recognition based on biosignals has shown strong potential for
developing intuitive human-machine interaction strategies that closely mimic
natural human behavior. In particular, sensor fusion approaches have gained
attention for combining complementary information and overcoming the
limitations of individual sensing modalities, thereby enabling more robust and
reliable systems. Among them, the fusion of surface electromyography (EMG) and
A-mode ultrasound (US) is very promising. However, prior solutions rely on
power-hungry platforms unsuitable for multi-day use and are limited to discrete
gesture classification. In this work, we present an ultra-low-power (sub-50 mW)
system for concurrent acquisition of 8-channel EMG and 4-channel A-mode US
signals, integrating two state-of-the-art platforms into fully wearable,
dry-contact armbands. We propose a framework for continuous tracking of 23
degrees of freedom (DoFs), 20 for the hand and 3 for the wrist, using a
kinematic glove for ground-truth labeling. Our method employs lightweight
encoder-decoder architectures with multi-task learning to simultaneously
estimate hand and wrist joint angles. Experimental results under realistic
sensor repositioning conditions demonstrate that EMG-US fusion achieves a root
mean squared error of $10.6^\circ\pm2.0^\circ$, compared to
$12.0^\circ\pm1^\circ$ for EMG and $13.1^\circ\pm2.6^\circ$ for US, and a R$^2$
score of $0.61\pm0.1$, with $0.54\pm0.03$ for EMG and $0.38\pm0.20$ for US.

</details>


### [15] [Computing on Dirty Paper: Interference-Free Integrated Communication and Computing](https://arxiv.org/abs/2510.02012)
*Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,David González G.,Carlo Fischione*

Main category: eess.SP

TL;DR: 提出了一种基于脏纸编码的通信与计算集成方案，能够在多址信道中同时传输离散数据符号和计算函数，实现渐进无干扰的通信计算一体化。


<details>
  <summary>Details</summary>
Motivation: 受Costa脏纸编码的启发，旨在解决通信与计算在共享信道中的集成问题，实现数据传输和函数计算的同步进行。

Method: 采用脏纸编码原理，在发射端预消除计算符号，实现通信与计算的渐进无干扰集成，并在单输入多输出系统下进行仿真评估。

Result: 仿真结果表明，该方案在数据检测的误码率和函数计算的均方误差方面均显著优于现有最先进的通信计算集成方案。

Conclusion: 提出的计算脏纸方案验证了通信与计算集成的可行性，为多址信道中的同时数据传输和函数计算提供了有效解决方案。

Abstract: Inspired by Costa's pioneering work on dirty paper coding (DPC), this paper
proposes a novel scheme for integrated communication and computing (ICC), named
Computing on Dirty Paper, whereby the transmission of discrete data symbols for
communication, and over-the-air computation (AirComp) of nomographic functions
can be achieved simultaneously over common multiple-access channels. In
particular, the proposed scheme allows for the integration of communication and
computation in a manner that is asymptotically interference-free, by
precanceling the computing symbols at the transmitters (TXs) using DPC
principles. A simulation-based assessment of the proposed ICC scheme under a
single-input multiple-output (SIMO) setup is also offered, including the
evaluation of performance for data detection, and of mean-squared-error (MSE)
performance for function computation, over a block of symbols. The results
validate the proposed method and demonstrate its ability to significantly
outperform state-of-the-art (SotA) ICC schemes in terms of both bit error rate
(BER) and MSE.

</details>


### [16] [Joint Jammer Mitigation and Data Detection](https://arxiv.org/abs/2510.02021)
*Gian Marti,Christoph Studer*

Main category: eess.SP

TL;DR: 提出了一种联合干扰抑制与数据检测(JMD)的新范式，通过同时估计干扰子空间和检测合法数据来应对智能多天线干扰器，无需专用训练阶段。


<details>
  <summary>Details</summary>
Motivation: 现有干扰抑制方法需要专用训练阶段来估计干扰器空间特征，这会降低通信速率且容易被智能干扰器规避。

Method: 开发了SANDMAN和MAED两种JMD算法，通过联合估计干扰子空间和检测合法数据，无需专用训练阶段。

Result: 广泛仿真验证了JMD在干扰抑制方面的有效性。

Conclusion: JMD范式能够有效应对智能动态多天线干扰器，同时避免专用训练阶段带来的速率损失。

Abstract: Multi-antenna (or MIMO) processing is a promising solution to the problem of
jammer mitigation. Existing methods mitigate the jammer based on an estimate of
its spatial signature that is acquired through a dedicated training phase. This
strategy has two main drawbacks: (i) it reduces the communication rate since no
data can be transmitted during the training phase and (ii) it can be evaded by
smart or multi-antenna jammers that do not transmit during the training phase
or that dynamically change their subspace through time-varying beamforming. To
address these drawbacks, we propose Joint jammer Mitigation and data Detection
(JMD), a novel paradigm for MIMO jammer mitigation. The core idea of JMD is to
estimate and remove the jammer interference subspace jointly with detecting the
legitimate transmit data over multiple time slots. Doing so removes the need
for a dedicated and rate-reducing training period while being able to mitigate
smart and dynamic multi-antenna jammers. We provide two JMD-type algorithms,
SANDMAN and MAED, that differ in the way they estimate the channels of the
legitimate transmitters and achieve different complexity-performance tradeoffs.
Extensive simulations demonstrate the efficacy of JMD for jammer mitigation.

</details>


### [17] [A Secure Affine Frequency Division Multiplexing for Wireless Communication Systems](https://arxiv.org/abs/2510.02023)
*Ping Wang,Zulin Wang,Yuanhan Ni,Qu Luo,Yuanfang Ma,Xiaosi Tian,Pei Xiao*

Main category: eess.SP

TL;DR: 提出了一种新型安全仿射频分复用系统，通过动态变化预啁啾参数来增强物理层安全性，采用参数域扩频方法在保持可靠性和高频谱效率的同时提供额外安全性。


<details>
  <summary>Details</summary>
Motivation: AFDM在高移动性场景中表现出优越性能，但现有系统缺乏有效的物理层安全机制。需要开发能够在保持AFDM优势的同时增强安全性的系统。

Method: 提出SE-AFDM系统，通过长周期伪噪声序列控制的码本动态生成预啁啾参数，采用参数域扩频而非数据域扩频，并设计了同步框架来解决时变参数在快速时变信道中的可靠快速同步问题。

Result: 理论推导证明未同步的窃听者无法消除时变参数的非线性影响，仿真结果表明SE-AFDM系统在高移动性场景中具有安全优势，硬件原型验证了同步框架的有效性。

Conclusion: SE-AFDM系统成功实现了在保持AFDM高性能的同时增强物理层安全性，参数域扩频方法提供了额外的安全保护，同步框架确保了系统的可靠运行。

Abstract: Affine frequency division multiplexing (AFDM) has garnered significant
attention due to its superior performance in high-mobility scenarios, coupled
with multiple waveform parameters that provide greater degrees of freedom for
system design. This paper introduces a novel secure affine frequency division
multiplexing (SE-AFDM) system, which advances prior designs by dynamically
varying an AFDM pre-chirp parameter to enhance physical-layer security. In the
SE-AFDM system, the pre-chirp parameter is dynamically generated from a
codebook controlled by a long-period pseudo-noise (LPPN) sequence. Instead of
applying spreading in the data domain, our parameter-domain spreading approach
provides additional security while maintaining reliability and high spectrum
efficiency. We also propose a synchronization framework to solve the problem of
reliably and rapidly synchronizing the time-varying parameter in fast
time-varying channels. The theoretical derivations prove that unsynchronized
eavesdroppers cannot eliminate the nonlinear impact of the time-varying
parameter and further provide useful guidance for codebook design. Simulation
results demonstrate the security advantages of the proposed SE-AFDM system in
high-mobility scenarios, while our hardware prototype validates the
effectiveness of the proposed synchronization framework.

</details>


### [18] [Joint DOA and Attitude Sensing Based on Tri-Polarized Continuous Aperture Array](https://arxiv.org/abs/2510.02029)
*Haonan Si,Zhaolin Wang,Xiansheng Guo,Jin Zhang,Yuanwei Liu*

Main category: eess.SP

TL;DR: 提出使用三极化连续孔径阵列进行联合波达方向(DOA)和姿态感知的方法，通过电磁信息理论建模连续空间信号，开发连续-离散变换技术，利用三极化信号的协方差构造极化谱，显著提升DOA估计性能。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用三极化连续孔径阵列同时实现波达方向(DOA)和姿态感知，解决传统方法在连续空间信号建模和姿态信息可辨识性方面的挑战。

Method: 采用电磁信息理论建模三极化CAPA的连续空间接收信号；开发等效连续-离散变换技术用于子空间分解；利用三极化信号的自协方差和互协方差构造三极化谱；提出两种姿态估计算法：无先验知识的部分姿态估计和基于先验目标的完整姿态估计。

Result: 数值结果表明所提框架的可行性和优越性，三极化谱显著提升了DOA估计性能，姿态信息的可辨识性依赖于先验目标快照的可用性。

Conclusion: 提出的三极化CAPA框架能够有效实现联合DOA和姿态感知，通过连续空间信号建模和极化信息利用，在无先验和基于先验两种情况下都能实现准确的姿态估计。

Abstract: This paper investigates joint direction-of-arrival (DOA) and attitude sensing
using tri-polarized continuous aperture arrays (CAPAs). By employing
electromagnetic (EM) information theory, the spatially continuous received
signals in tri-polarized CAPA are modeled, thereby enabling accurate DOA and
attitude estimation. To facilitate subspace decomposition for continuous
operators, an equivalent continuous-discrete transformation technique is
developed. Moreover, both self- and cross-covariances of tri-polarized signals
are exploited to construct a tri-polarized spectrum, significantly enhancing
DOA estimation performance. Theoretical analyses reveal that the
identifiability of attitude information fundamentally depends on the
availability of prior target snapshots. Accordingly, two attitude estimation
algorithms are proposed: one capable of estimating partial attitude information
without prior knowledge, and the other achieving full attitude estimation when
such knowledge is available. Numerical results demonstrate the feasibility and
superiority of the proposed framework.

</details>


### [19] [Sensing-Secure ISAC: Ambiguity Function Engineering for Impairing Unauthorized Sensing](https://arxiv.org/abs/2510.02103)
*Kawon Han,Kaitao Meng,Christos Masouros*

Main category: eess.SP

TL;DR: 提出了一种感知安全的ISAC框架，通过在ISAC信号的模糊函数中引入人工缺陷来混淆未经授权的感知，同时保证合法系统的安全目标检测和估计。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)的部署给授权感知带来了前所未有的安全漏洞，未经授权的被动雷达感知窃听者可以从目标反射信号中提取感知信息，需要开发安全解决方案。

Method: 通过向ISAC信号的模糊函数引入人工缺陷，在窃听者的距离剖面中插入人工目标以增加其距离估计模糊度；合法感知接收器使用失配滤波抑制这些伪影；采用OFDM信号设计结构化子载波功率分配方案来塑造安全自相关函数。

Result: 数值结果验证了所提出的感知安全ISAC信号的有效性，能够降低窃听者的目标估计性能，同时保持合法系统的性能。

Conclusion: 提出的感知安全ISAC框架能够在保证合法系统性能的同时，有效混淆未经授权的感知，通过优化问题可以在通信、合法感知和感知安全性之间实现平衡。

Abstract: The deployment of integrated sensing and communication (ISAC) brings along
unprecedented vulnerabilities to authorized sensing, necessitating the
development of secure solutions. Sensing parameters are embedded within the
target-reflected signal leaked to unauthorized passive radar sensing
eavesdroppers (Eve), implying that they can silently extract sensory
information without prior knowledge of the information data. To overcome this
limitation, we propose a sensing-secure ISAC framework that ensures secure
target detection and estimation for the legitimate system, while obfuscating
unauthorized sensing without requiring any prior knowledge of Eve. By
introducing artificial imperfections into the ambiguity function (AF) of ISAC
signals, we introduce artificial targets into Eve's range profile which
increase its range estimation ambiguity. In contrast, the legitimate sensing
receiver (Alice) can suppress these AF artifacts using mismatched filtering,
albeit at the expense of signal-to-noise ratio (SNR) loss. Employing an OFDM
signal, a structured subcarrier power allocation scheme is designed to shape
the secure autocorrelation function (ACF), inserting periodic peaks to mislead
Eve's range estimation and degrade target detection performance. To quantify
the sensing security, we introduce peak sidelobe level (PSL) and integrated
sidelobe level (ISL) as key performance metrics. Then, we analyze the three-way
trade-offs between communication, legitimate sensing, and sensing security,
highlighting the impact of the proposed sensing-secure ISAC signaling on system
performance. We formulate a convex optimization problem to maximize ISAC
performance while guaranteeing a certain sensing security level. Numerical
results validate the effectiveness of the proposed sensing-secure ISAC
signaling, demonstrating its ability to degrade Eve's target estimation while
preserving Alice's performance.

</details>


### [20] [Unlocking Symbol-Level Precoding Efficiency Through Tensor Equivariant Neural Network](https://arxiv.org/abs/2510.02108)
*Jinshuo Zhang,Yafei Wang,Xinping Yi,Wenjin Wang,Shi Jin,Symeon Chatzinotas,Björn Ottersten*

Main category: eess.SP

TL;DR: 提出基于张量等变性的端到端深度学习框架，显著降低符号级预编码的计算复杂度，在保持性能优势的同时实现约80倍加速。


<details>
  <summary>Details</summary>
Motivation: 符号级预编码虽然能提供性能增益，但其高计算复杂度限制了实际应用，需要开发低复杂度的高效解决方案。

Method: 利用最优符号级预编码闭式解的结构特性和张量等变性，构建从问题到解的映射网络，采用基于注意力的TE模块实现线性计算复杂度。

Result: 所提框架在捕获最优SLP性能增益的同时，相比传统方法实现约80倍加速，并在用户数和符号块长度变化时保持强泛化能力。

Conclusion: 基于张量等变性的深度学习框架能有效解决符号级预编码的高复杂度问题，为实际部署提供了可行方案。

Abstract: Although symbol-level precoding (SLP) based on constructive interference (CI)
exploitation offers performance gains, its high complexity remains a
bottleneck. This paper addresses this challenge with an end-to-end deep
learning (DL) framework with low inference complexity that leverages the
structure of the optimal SLP solution in the closed-form and its inherent
tensor equivariance (TE), where TE denotes that a permutation of the input
induces the corresponding permutation of the output. Building upon the
computationally efficient model-based formulations, as well as their known
closed-form solutions, we analyze their relationship with linear precoding (LP)
and investigate the corresponding optimality condition. We then construct a
mapping from the problem formulation to the solution and prove its TE, based on
which the designed networks reveal a specific parameter-sharing pattern that
delivers low computational complexity and strong generalization. Leveraging
these, we propose the backbone of the framework with an attention-based TE
module, achieving linear computational complexity. Furthermore, we demonstrate
that such a framework is also applicable to imperfect CSI scenarios, where we
design a TE-based network to map the CSI, statistics, and symbols to auxiliary
variables. Simulation results show that the proposed framework captures
substantial performance gains of optimal SLP, while achieving an approximately
80-times speedup over conventional methods and maintaining strong
generalization across user numbers and symbol block lengths.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [21] [Joint Optimization of Speaker and Spoof Detectors for Spoofing-Robust Automatic Speaker Verification](https://arxiv.org/abs/2510.01818)
*Oğuzhan Kurnaz,Jagabandhu Mishra,Tomi H. Kinnunen,Cemal Hanilçi*

Main category: eess.AS

TL;DR: 该研究提出了一种抗欺骗的说话人验证系统，通过可训练的后端分类器集成说话人和欺骗检测子系统，直接优化SASV性能指标(a-DCF)，在ASVspoof 5数据集上取得了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有的SASV系统通常在嵌入、分数或决策层面融合独立训练的子系统，本研究旨在通过可训练后端分类器实现模块化集成，并直接优化SASV性能指标。

Method: 采用模块化设计，将说话人检测（加权余弦评分）和欺骗检测（SSL-AASIST）子系统输出通过非线性分数融合，使用可训练后端分类器直接优化a-DCF指标。

Result: 在ASVspoof 5数据集上，非线性分数融合始终优于线性融合，组合加权余弦评分和SSL-AASIST达到最先进性能：min a-DCF为0.196，SPF-EER为7.6%。

Conclusion: 模块化设计、校准集成和任务对齐优化对于推进鲁棒且可解释的SASV系统至关重要。

Abstract: Spoofing-robust speaker verification (SASV) combines the tasks of speaker and
spoof detection to authenticate speakers under adversarial settings. Many SASV
systems rely on fusion of speaker and spoof cues at embedding, score or
decision levels, based on independently trained subsystems. In this study, we
respect similar modularity of the two subsystems, by integrating their outputs
using trainable back-end classifiers. In particular, we explore various
approaches for directly optimizing the back-end for the recently-proposed SASV
performance metric (a-DCF) as a training objective. Our experiments on the
ASVspoof 5 dataset demonstrate two important findings: (i) nonlinear score
fusion consistently improves a-DCF over linear fusion, and (ii) the combination
of weighted cosine scoring for speaker detection with SSL-AASIST for spoof
detection achieves state-of-the-art performance, reducing min a-DCF to 0.196
and SPF-EER to 7.6%. These contributions highlight the importance of modular
design, calibrated integration, and task-aligned optimization for advancing
robust and interpretable SASV systems.

</details>


### [22] [SLAP: Learning Speaker and Health-Related Representations from Natural Language Supervision](https://arxiv.org/abs/2510.01860)
*Angelika Ando,Auguste Crabeil,Adrien Lesage,Rachid Riad*

Main category: eess.AS

TL;DR: SLAP是首个通过对比学习将语音与说话人和健康元数据的自然语言描述对齐的音频基础模型，在38个二元分类任务上实现了62.9%的零样本F1分数，比CLAP提升48%，并在未见过的语言和临床人群中表现出强大的OOD泛化能力。


<details>
  <summary>Details</summary>
Motivation: 目前没有音频基础模型支持说话人特征和健康相关任务的零样本或分布外泛化，而语音编码了人口统计、音质和健康等副语言信息。

Method: SLAP结合视觉Transformer音频编码器和文本编码器，通过对比学习在9个数据集的3400多小时语音数据上训练，将语音与说话人和健康元数据的自然语言描述对齐。

Result: 在14个数据集的38个二元分类任务上，SLAP零样本评估平均F1达62.9%，比CLAP提升48%；线性探测微调后达到69.3% F1，在健康任务上达到57.9% F1，超越更大的基础模型。

Conclusion: SLAP是首个支持说话人和健康相关任务零样本和OOD泛化的音频基础模型，在多种任务上表现出色，特别是在临床应用中具有重要价值。

Abstract: Speech encodes paralinguistic information such as demographics, voice
quality, and health. Yet no audio foundation model supports zero-shot or
out-of-distribution (OOD) generalization to these tasks. We introduce SLAP
(Speaker contrastive Language-Audio Pretraining), the first model aligning
speech with natural language descriptions of speaker and health metadata
through contrastive learning. SLAP combines a Vision Transformer audio encoder
with text encoders, trained on more than 3400 hours across 9 datasets with
diverse speaker annotations. We evaluated on 38 binary classification tasks
spanning demographics, voice characteristics, and clinical assessments across
14 datasets in 7 languages. SLAP achieves 62.9% average F1 in zero-shot
evaluation, a 48% relative improvement over CLAP (42.4%), while demonstrating
strong OOD generalization to unseen languages and clinical populations. When
fine-tuned with linear probing, SLAP reaches 69.3% F1 overall and achieves
best-in-class performance on health tasks (57.9% F1), surpassing larger
foundation models.

</details>


### [23] [Clustering of Acoustic Environments with Variational Autoencoders for Hearing Devices](https://arxiv.org/abs/2510.01940)
*Luan Vinícius Fiorio,Ivana Nikoloska,Wim van Houtum,Ronald M. Aarts*

Main category: eess.AS

TL;DR: 本文提出了一种基于变分自编码器(VAE)的无监督声学环境聚类方法，特别针对助听设备场景，使用Gumbel-Softmax重参数化和时间上下文窗口方案。


<details>
  <summary>Details</summary>
Motivation: 传统声学环境分类方法无法有效处理高维数据，且受限于标签可用性。人类标注的标签并不总能反映声学场景的真实结构，因此探索无监督聚类方法。

Method: 提出基于VAE的分类潜在聚类模型，采用Gumbel-Softmax重参数化和时间上下文窗口方案，并针对音频聚类提出了VAE架构的通用适配。

Result: 所有变分方法在语音数字聚类任务中都取得成功，但只有提出的分类模型在城市场景声学聚类中表现有效，因其分类特性适合处理重叠的时频特征。

Conclusion: 提出的分类VAE模型在无监督声学环境聚类中表现优异，特别适用于具有强时频重叠的真实世界声学场景。

Abstract: Particularly in hearing devices, the environmental context is taken into
account for audio processing, often through classification. Traditional
acoustic environment classification relies on classical algorithms, which are
unable to extract meaningful representations of high-dimensionality data, or on
supervised learning, being limited by the availability of labels. Knowing that
human-imposed labels do not always reflect the true structure of acoustic
scenes, we explore the (unsupervised) clustering of acoustic environments using
variational autoencoders (VAEs), presenting a structured latent space suitable
for the task. We propose a VAE model for categorical latent clustering
employing a Gumbel-Softmax reparameterization with a time-context windowing
scheme, tailored for real-world hearing device scenarios. Additionally, general
adaptations on VAE architectures for audio clustering are also proposed. The
approaches are validated through the clustering of spoken digits, a simpler
task where labels are meaningful, and urban soundscapes, which recordings
present strong overlap in time and frequency. While all variational methods
succeeded when clustering spoken digits, only the proposed model achieved
effective clustering performance on urban acoustic scenes, given its
categorical nature.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [24] [RealClass: A Framework for Classroom Speech Simulation with Public Datasets and Game Engines](https://arxiv.org/abs/2510.01462)
*Ahmed Adel Attia,Jing Liu,Carol Espy Wilson*

Main category: cs.SD

TL;DR: 提出了一种使用游戏引擎合成教室噪声和房间脉冲响应的方法，并创建了RealClass数据集，该数据集结合了合成的教室噪声语料库和从公开语料库编译的教室语音数据集。


<details>
  <summary>Details</summary>
Motivation: 大规模教室语音数据的稀缺阻碍了教育领域AI驱动语音模型的发展，现有教室数据集有限且不公开，缺乏专门的教室噪声或房间脉冲响应语料库，无法使用标准数据增强技术。

Method: 使用游戏引擎合成教室噪声和房间脉冲响应的可扩展方法，创建RealClass数据集，将合成的教室噪声语料库与从公开语料库编译的教室语音数据集相结合。

Result: 在干净和嘈杂语音上的实验表明，RealClass能够很好地近似真实教室语音。

Conclusion: RealClass在缺乏丰富真实教室语音的情况下是一个有价值的资源，该方法可以扩展到教室以外的其他领域。

Abstract: The scarcity of large-scale classroom speech data has hindered the
development of AI-driven speech models for education. Classroom datasets remain
limited and not publicly available, and the absence of dedicated classroom
noise or Room Impulse Response (RIR) corpora prevents the use of standard data
augmentation techniques.
  In this paper, we introduce a scalable methodology for synthesizing classroom
noise and RIRs using game engines, a versatile framework that can extend to
other domains beyond the classroom. Building on this methodology, we present
RealClass, a dataset that combines a synthesized classroom noise corpus with a
classroom speech dataset compiled from publicly available corpora. The speech
data pairs a children's speech corpus with instructional speech extracted from
YouTube videos to approximate real classroom interactions in clean conditions.
Experiments on clean and noisy speech show that RealClass closely approximates
real classroom speech, making it a valuable asset in the absence of abundant
real classroom speech.

</details>


### [25] [Emotional Text-To-Speech Based on Mutual-Information-Guided Emotion-Timbre Disentanglement](https://arxiv.org/abs/2510.01722)
*Jianing Yang,Sheng Li,Takahiro Shinozaki,Yuki Saito,Hiroshi Saruwatari*

Main category: cs.SD

TL;DR: 提出了一种新颖的情感TTS方法，通过细粒度音素级情感嵌入预测和风格解缠技术，解决了现有方法无法捕捉参考语音细微声学细节的问题。


<details>
  <summary>Details</summary>
Motivation: 当前的情感TTS和风格转换方法依赖参考编码器控制全局风格或情感向量，但无法捕捉参考语音的细微声学细节。

Method: 采用风格解缠方法指导两个特征提取器，减少音色和情感特征之间的互信息，有效分离参考语音中的不同风格成分。

Result: 实验结果表明，该方法在生成自然且情感丰富的语音方面优于基线TTS系统。

Conclusion: 这项工作突出了解缠和细粒度表示在提升情感TTS系统质量和灵活性方面的潜力。

Abstract: Current emotional Text-To-Speech (TTS) and style transfer methods rely on
reference encoders to control global style or emotion vectors, but do not
capture nuanced acoustic details of the reference speech. To this end, we
propose a novel emotional TTS method that enables fine-grained phoneme-level
emotion embedding prediction while disentangling intrinsic attributes of the
reference speech. The proposed method employs a style disentanglement method to
guide two feature extractors, reducing mutual information between timbre and
emotion features, and effectively separating distinct style components from the
reference speech. Experimental results demonstrate that our method outperforms
baseline TTS systems in generating natural and emotionally rich speech. This
work highlights the potential of disentangled and fine-grained representations
in advancing the quality and flexibility of emotional TTS systems.

</details>


### [26] [SingMOS-Pro: An Comprehensive Benchmark for Singing Quality Assessment](https://arxiv.org/abs/2510.01812)
*Yuxun Tang,Lan Liu,Wenhao Feng,Yiwen Zhao,Jionghao Han,Yifeng Yu,Jiatong Shi,Qin Jin*

Main category: cs.SD

TL;DR: 提出了SingMOS-Pro数据集，用于自动歌唱质量评估，包含7,981个歌唱片段，提供歌词、旋律和整体质量的多维度标注。


<details>
  <summary>Details</summary>
Motivation: 歌唱生成技术快速发展，但评估歌唱质量仍面临挑战。主观评估成本高、耗时长，现有客观指标只能捕捉有限的感知方面。

Method: 在SingMOS基础上扩展标注，包含歌词、旋律和整体质量三个维度。数据集包含41个模型生成的7,981个歌唱片段，每个片段至少有5位专业标注者的评分。

Result: 建立了包含广泛覆盖和多样性的歌唱质量评估数据集，并基于该数据集对多种评估方法进行了基准测试。

Conclusion: SingMOS-Pro为歌唱质量评估研究提供了可靠的数据基础和实用参考，有助于推动该领域的发展。

Abstract: Singing voice generation progresses rapidly, yet evaluating singing quality
remains a critical challenge. Human subjective assessment, typically in the
form of listening tests, is costly and time consuming, while existing objective
metrics capture only limited perceptual aspects. In this work, we introduce
SingMOS-Pro, a dataset for automatic singing quality assessment. Building on
our preview version SingMOS, which provides only overall ratings, SingMOS-Pro
expands annotations of the additional part to include lyrics, melody, and
overall quality, offering broader coverage and greater diversity. The dataset
contains 7,981 singing clips generated by 41 models across 12 datasets,
spanning from early systems to recent advances. Each clip receives at least
five ratings from professional annotators, ensuring reliability and
consistency. Furthermore, we explore how to effectively utilize MOS data
annotated under different standards and benchmark several widely used
evaluation methods from related tasks on SingMOS-Pro, establishing strong
baselines and practical references for future research. The dataset can be
accessed at https://huggingface.co/datasets/TangRain/SingMOS-Pro.

</details>


### [27] [HRTFformer: A Spatially-Aware Transformer for Personalized HRTF Upsampling in Immersive Audio Rendering](https://arxiv.org/abs/2510.01891)
*Xuyi Hu,Jian Li,Shaojie Zhang,Stefan Goetz,Lorenzo Picinali,Ozgur B. Akan,Aidan O. T. Hogg*

Main category: cs.SD

TL;DR: 提出基于Transformer的HRTF上采样方法，利用注意力机制捕捉空间相关性，在球谐域中从稀疏测量重建高分辨率HRTF，显著提高精度。


<details>
  <summary>Details</summary>
Motivation: 个性化HRTF对沉浸式音频至关重要，但大规模测量不切实际。现有ML方法在高上采样因子下存在长距离空间一致性和泛化问题。

Method: 在球谐域使用基于Transformer的架构，引入邻居差异损失来增强空间一致性，促进幅度平滑。

Result: 通过感知定位模型和频谱失真指标评估，模型在生成真实高保真HRTF方面大幅领先现有方法。

Conclusion: 提出的Transformer架构在HRTF上采样中表现出色，解决了空间一致性问题，为个性化HRTF的大规模应用提供了可行方案。

Abstract: Personalized Head-Related Transfer Functions (HRTFs) are starting to be
introduced in many commercial immersive audio applications and are crucial for
realistic spatial audio rendering. However, one of the main hesitations
regarding their introduction is that creating personalized HRTFs is impractical
at scale due to the complexities of the HRTF measurement process. To mitigate
this drawback, HRTF spatial upsampling has been proposed with the aim of
reducing measurements required. While prior work has seen success with
different machine learning (ML) approaches, these models often struggle with
long-range spatial consistency and generalization at high upsampling factors.
In this paper, we propose a novel transformer-based architecture for HRTF
upsampling, leveraging the attention mechanism to better capture spatial
correlations across the HRTF sphere. Working in the spherical harmonic (SH)
domain, our model learns to reconstruct high-resolution HRTFs from sparse input
measurements with significantly improved accuracy. To enhance spatial
coherence, we introduce a neighbor dissimilarity loss that promotes magnitude
smoothness, yielding more realistic upsampling. We evaluate our method using
both perceptual localization models and objective spectral distortion metrics.
Experiments show that our model surpasses leading methods by a substantial
margin in generating realistic, high-fidelity HRTFs.

</details>


### [28] [MelCap: A Unified Single-Codebook Neural Codec for High-Fidelity Audio Compression](https://arxiv.org/abs/2510.01903)
*Jingyi Li,Zhiyuan Zhao,Yunfei Liu,Lijian Lin,Ye Zhu,Jiahao Wu,Qiuqiang Kong,Yu Li*

Main category: cs.SD

TL;DR: MelCap是一个统一的"一个码本适用所有"神经音频编解码器，能有效处理语音、音乐和一般声音，通过两阶段重建实现高质量音频压缩。


<details>
  <summary>Details</summary>
Motivation: 现有神经音频编解码器要么依赖仅处理语音的单量化器，要么使用不适合下游任务的多量化器，需要一种能统一处理各种音频类型的方法。

Method: 将音频重建分为两阶段：第一阶段将音频转换为mel频谱图，使用2D分词器压缩量化为紧凑单令牌，并应用感知损失减少伪影；第二阶段通过声码器从mel离散令牌中恢复波形。

Result: 客观和主观评估显示，MelCap在质量上与最先进的多码本编解码器相当，同时保持了单码本设计的计算简单性。

Conclusion: MelCap为下游任务提供了有效的表示，在保持高质量的同时简化了计算复杂度。

Abstract: Neural audio codecs have recently emerged as powerful tools for high-quality
and low-bitrate audio compression, leveraging deep generative models to learn
latent representations of audio signals. However, existing approaches either
rely on a single quantizer that only processes speech domain, or on multiple
quantizers that are not well suited for downstream tasks. To address this
issue, we propose MelCap, a unified "one-codebook-for-all" neural codec that
effectively handles speech, music, and general sound. By decomposing audio
reconstruction into two stages, our method preserves more acoustic details than
previous single-codebook approaches, while achieving performance comparable to
mainstream multi-codebook methods. In the first stage, audio is transformed
into mel-spectrograms, which are compressed and quantized into compact single
tokens using a 2D tokenizer. A perceptual loss is further applied to mitigate
the over-smoothing artifacts observed in spectrogram reconstruction. In the
second stage, a Vocoder recovers waveforms from the mel discrete tokens in a
single forward pass, enabling real-time decoding. Both objective and subjective
evaluations demonstrate that MelCap achieves quality on comparable to
state-of-the-art multi-codebook codecs, while retaining the computational
simplicity of a single-codebook design, thereby providing an effective
representation for downstream tasks.

</details>


### [29] [Exploring Resolution-Wise Shared Attention in Hybrid Mamba-U-Nets for Improved Cross-Corpus Speech Enhancement](https://arxiv.org/abs/2510.01958)
*Nikolai Lund Kühne,Jesper Jensen,Jan Østergaard,Zheng-Hua Tan*

Main category: cs.SD

TL;DR: RWSA-MambaUNet是一种结合Mamba和注意力机制的高效混合模型，在U-Net结构中实现跨语料库的语音增强，参数更少但性能优于基线。


<details>
  <summary>Details</summary>
Motivation: 受Mamba与注意力机制结合在语音增强中表现出优异跨语料库泛化性能的启发，以及Mamba在U-Net结构中能减少模型大小和计算复杂度的优势。

Method: 提出RWSA-MambaUNet混合模型，在U-Net结构中结合Mamba和多头注意力机制，采用分辨率共享注意力(RWSA)在对应时间和频率分辨率层间共享注意力。

Result: 在DNS 2020和EARS-WHAM_v2两个域外测试集上取得最先进的泛化性能，最小模型在PESQ、SSNR、ESTOI等指标上超越所有基线，参数不到一半，FLOPs大幅减少。

Conclusion: RWSA-MambaUNet在保持高效性的同时实现了优异的跨语料库语音增强性能，证明了Mamba与注意力机制在U-Net结构中的有效结合。

Abstract: Recent advances in speech enhancement have shown that models combining Mamba
and attention mechanisms yield superior cross-corpus generalization
performance. At the same time, integrating Mamba in a U-Net structure has
yielded state-of-the-art enhancement performance, while reducing both model
size and computational complexity. Inspired by these insights, we propose
RWSA-MambaUNet, a novel and efficient hybrid model combining Mamba and
multi-head attention in a U-Net structure for improved cross-corpus
performance. Resolution-wise shared attention (RWSA) refers to layerwise
attention-sharing across corresponding time- and frequency resolutions. Our
best-performing RWSA-MambaUNet model achieves state-of-the-art generalization
performance on two out-of-domain test sets. Notably, our smallest model
surpasses all baselines on the out-of-domain DNS 2020 test set in terms of
PESQ, SSNR, and ESTOI, and on the out-of-domain EARS-WHAM_v2 test set in terms
of SSNR, ESTOI, and SI-SDR, while using less than half the model parameters and
a fraction of the FLOPs.

</details>


### [30] [Bias beyond Borders: Global Inequalities in AI-Generated Music](https://arxiv.org/abs/2510.01963)
*Ahmet Solak,Florian Grötschla,Luca A. Lanzendörfer,Roger Wattenhofer*

Main category: cs.SD

TL;DR: GlobalDISCO数据集包含73k首由商业音乐生成模型生成的音乐，覆盖147种语言和79个国家，揭示了模型在高资源和低资源地区之间的音乐质量和参考音乐对齐度存在显著差异。


<details>
  <summary>Details</summary>
Motivation: 当前音乐生成模型在跨国家、语言、文化和音乐流派方面的偏见研究不足，且缺乏捕捉全球音乐多样性的数据集和基准。

Method: 构建GlobalDISCO大规模数据集，包含73k生成音乐和93k参考音乐链接，使用MusicBrainz和Wikipedia提取音乐风格提示，实现全球平衡覆盖。

Result: 评估显示高资源和低资源地区在音乐质量和参考音乐对齐度上存在巨大差异，主流与地理小众流派之间模型性能差异显著。

Conclusion: 音乐生成模型存在明显的地区偏见，需要更多关注全球音乐多样性，GlobalDISCO为评估和缓解这些偏见提供了重要资源。

Abstract: While recent years have seen remarkable progress in music generation models,
research on their biases across countries, languages, cultures, and musical
genres remains underexplored. This gap is compounded by the lack of datasets
and benchmarks that capture the global diversity of music. To address these
challenges, we introduce GlobalDISCO, a large-scale dataset consisting of 73k
music tracks generated by state-of-the-art commercial generative music models,
along with paired links to 93k reference tracks in LAION-DISCO-12M. The dataset
spans 147 languages and includes musical style prompts extracted from
MusicBrainz and Wikipedia. The dataset is globally balanced, representing
musical styles from artists across 79 countries and five continents. Our
evaluation reveals large disparities in music quality and alignment with
reference music between high-resource and low-resource regions. Furthermore, we
find marked differences in model performance between mainstream and
geographically niche genres, including cases where models generate music for
regional genres that more closely align with the distribution of mainstream
styles.

</details>


### [31] [Multi-bit Audio Watermarking](https://arxiv.org/abs/2510.01968)
*Luca A. Lanzendörfer,Kyle Fearne,Florian Grötschla,Roger Wattenhofer*

Main category: cs.SD

TL;DR: Timbru是一种后处理音频水印模型，无需训练嵌入器-检测器模型即可实现最先进的鲁棒性和不可感知性平衡。通过在预训练音频VAE的潜在空间中进行梯度优化添加不可感知扰动，使用CLAP模型提取水印。


<details>
  <summary>Details</summary>
Motivation: 开发一种无需训练嵌入器-检测器模型的高效音频水印方法，实现更好的鲁棒性和不可感知性平衡，提供数据集无关的不可感知音频水印解决方案。

Method: 对44.1kHz立体声音乐片段进行每音频梯度优化，在预训练音频VAE的潜在空间添加不可感知扰动，通过消息和感知损失的组合指导优化过程。

Result: 在MUSDB18-HQ数据集上评估16位水印，对抗常见攻击（滤波、噪声、压缩、重采样、裁剪、再生）时获得最佳平均比特错误率，同时保持感知质量。

Conclusion: Timbru展示了无需训练嵌入器-检测器模型即可实现高效、不可感知音频水印的可行性，为音频水印提供了数据集无关的解决方案。

Abstract: We present Timbru, a post-hoc audio watermarking model that achieves
state-of-the-art robustness and imperceptibility trade-offs without training an
embedder-detector model. Given any 44.1 kHz stereo music snippet, our method
performs per-audio gradient optimization to add imperceptible perturbations in
the latent space of a pretrained audio VAE, guided by a combined message and
perceptual loss. The watermark can then be extracted using a pretrained CLAP
model. We evaluate 16-bit watermarking on MUSDB18-HQ against AudioSeal,
WavMark, and SilentCipher across common filtering, noise, compression,
resampling, cropping, and regeneration attacks. Our approach attains the best
average bit error rates, while preserving perceptual quality, demonstrating an
efficient, dataset-free path to imperceptible audio watermarking.

</details>


### [32] [SoundReactor: Frame-level Online Video-to-Audio Generation](https://arxiv.org/abs/2510.02110)
*Koichi Saito,Julian Tanke,Christian Simon,Masato Ishii,Kazuki Shimada,Zachary Novack,Zhi Zhong,Akio Hayakawa,Takashi Shibuya,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: 提出了首个帧级在线视频到音频生成模型SoundReactor，能够在没有未来视频帧的情况下自回归生成音频，实现低延迟和音视频同步。


<details>
  <summary>Details</summary>
Motivation: 现有V2A模型需要完整视频序列，限制了在实时交互应用中的使用，如直播内容创作和生成世界模型。

Method: 使用仅解码器的因果变换器处理连续音频潜在表示，通过DINOv2视觉编码器提取网格特征并聚合为每帧单令牌，采用扩散预训练和一致性微调加速解码。

Result: 在AAA游戏视频基准上生成语义和时间对齐的高质量全频段立体声音频，单帧波形级延迟低至26.3ms（NFE=1）和31.5ms（NFE=4）。

Conclusion: SoundReactor是首个专门为帧级在线V2A生成设计的有效框架，实现了端到端因果性和低延迟，适用于实时应用。

Abstract: Prevailing Video-to-Audio (V2A) generation models operate offline, assuming
an entire video sequence or chunks of frames are available beforehand. This
critically limits their use in interactive applications such as live content
creation and emerging generative world models. To address this gap, we
introduce the novel task of frame-level online V2A generation, where a model
autoregressively generates audio from video without access to future video
frames. Furthermore, we propose SoundReactor, which, to the best of our
knowledge, is the first simple yet effective framework explicitly tailored for
this task. Our design enforces end-to-end causality and targets low per-frame
latency with audio-visual synchronization. Our model's backbone is a
decoder-only causal transformer over continuous audio latents. For vision
conditioning, it leverages grid (patch) features extracted from the smallest
variant of the DINOv2 vision encoder, which are aggregated into a single token
per frame to maintain end-to-end causality and efficiency. The model is trained
through a diffusion pre-training followed by consistency fine-tuning to
accelerate the diffusion head decoding. On a benchmark of diverse gameplay
videos from AAA titles, our model successfully generates semantically and
temporally aligned, high-quality full-band stereo audio, validated by both
objective and human evaluations. Furthermore, our model achieves low per-frame
waveform-level latency (26.3ms with the head NFE=1, 31.5ms with NFE=4) on
30FPS, 480p videos using a single H100. Demo samples are available at
https://koichi-saito-sony.github.io/soundreactor/.

</details>


### [33] [Go witheFlow: Real-time Emotion Driven Audio Effects Modulation](https://arxiv.org/abs/2510.02171)
*Edmund Dervakos,Spyridon Kantarelis,Vassilis Lyberatos,Jason Liartis,Giorgos Stamou*

Main category: cs.SD

TL;DR: 开发了witheFlow系统，通过生物信号和音频特征实时调制音频效果来增强音乐表演，促进人机协作。


<details>
  <summary>Details</summary>
Motivation: 音乐表演是人类特有的情感表达活动，机器无法真正体验情感。通过探索人机协作来增强实时音乐表演。

Method: 设计轻量级开源系统，从生物信号和音频中提取特征，自动调制音频效果，可在笔记本电脑上本地运行。

Result: 系统目前处于概念验证阶段，需要兼容的数字音频工作站和传感器支持。

Conclusion: witheFlow系统为人机协作音乐表演提供了新的可能性，通过生物信号和音频特征的结合来增强表演的情感表达。

Abstract: Music performance is a distinctly human activity, intrinsically linked to the
performer's ability to convey, evoke, or express emotion. Machines cannot
perform music in the human sense; they can produce, reproduce, execute, or
synthesize music, but they lack the capacity for affective or emotional
experience. As such, music performance is an ideal candidate through which to
explore aspects of collaboration between humans and machines. In this paper, we
introduce the witheFlow system, designed to enhance real-time music performance
by automatically modulating audio effects based on features extracted from both
biosignals and the audio itself. The system, currently in a proof-of-concept
phase, is designed to be lightweight, able to run locally on a laptop, and is
open-source given the availability of a compatible Digital Audio Workstation
and sensors.

</details>


### [34] [High-Fidelity Speech Enhancement via Discrete Audio Tokens](https://arxiv.org/abs/2510.02187)
*Luca A. Lanzendörfer,Frédéric Berdoz,Antonis Asonitis,Roger Wattenhofer*

Main category: cs.SD

TL;DR: DAC-SE1是一个基于语言模型的简化语音增强框架，利用离散高分辨率音频表示，在保持语义连贯性的同时保留精细的声学细节，在客观感知指标和人类评估中都超越了现有最先进的自回归语音增强方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归transformer语音增强方法虽然表现出色，但依赖复杂的多阶段流程和低采样率编解码器，限制了它们只能用于狭窄且任务特定的语音增强场景。

Method: 提出DAC-SE1框架，利用离散高分辨率音频表示，简化了语言模型在语音增强中的应用，同时保持声学细节和语义连贯性。

Result: 实验表明DAC-SE1在客观感知指标和MUSHRA人类评估中都超越了现有最先进的自回归语音增强方法。

Conclusion: DAC-SE1为可扩展、统一和高质量的语音增强研究提供了新的方向，作者发布了代码库和模型检查点以支持进一步研究。

Abstract: Recent autoregressive transformer-based speech enhancement (SE) methods have
shown promising results by leveraging advanced semantic understanding and
contextual modeling of speech. However, these approaches often rely on complex
multi-stage pipelines and low sampling rate codecs, limiting them to narrow and
task-specific speech enhancement. In this work, we introduce DAC-SE1, a
simplified language model-based SE framework leveraging discrete
high-resolution audio representations; DAC-SE1 preserves fine-grained acoustic
details while maintaining semantic coherence. Our experiments show that DAC-SE1
surpasses state-of-the-art autoregressive SE methods on both objective
perceptual metrics and in a MUSHRA human evaluation. We release our codebase
and model checkpoints to support further research in scalable, unified, and
high-quality speech enhancement.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 29]
- [eess.AS](#eess.AS) [Total: 13]
- [cs.SD](#cs.SD) [Total: 12]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [COMET: Co-Optimization of a CNN Model using Efficient-Hardware OBC Techniques](https://arxiv.org/abs/2510.03516)
*Boyang Chen,Mohd Tasleem Khan,George Goussetis,Mathini Sellathurai,Yuan Ding,João F. C. Mota*

Main category: eess.SP

TL;DR: COMET框架通过偏移二进制编码技术优化CNN设计，在FPGA上实现性能与资源利用的协同优化，显著降低资源消耗同时保持精度。


<details>
  <summary>Details</summary>
Motivation: 解决CNN在低功耗边缘设备上部署时面临的计算密集和硬件依赖问题，特别是FPGA资源利用效率的挑战。

Method: 采用偏移二进制编码表示输入和权重，利用位宽不对称性；修改移位累加操作；引入四种新颖的查找表技术（并行、共享、拆分、混合）；开发基于OBC的通用矩阵乘法核心。

Result: FPGA评估显示，相比最先进的LeNet-5 CNN设计，显著降低了资源利用率，同时对精度影响最小。

Conclusion: COMET框架通过硬件友好的偏移二进制编码技术，成功实现了CNN在边缘设备上的高效部署，为低功耗应用提供了可行的解决方案。

Abstract: Convolutional Neural Networks (CNNs) are highly effective for computer vision
and pattern recognition tasks; however, their computational intensity and
reliance on hardware such as FPGAs pose challenges for deployment on low-power
edge devices. In this work, we present COMET, a framework of CNN designs that
employ efficient hardware offset-binary coding (OBC) techniques to enable
co-optimization of performance and resource utilization. The approach
formulates CNN inference with OBC representations of inputs (Scheme A) and
weights (Scheme B) separately, enabling exploitation of bit-width asymmetry.
The shift-accumulate operation is modified by incorporating the offset term
with the pre-scaled bias. Leveraging inherent symmetries in Schemes A and B, we
introduce four novel look-up table (LUT) techniques -- parallel, shared, split,
and hybrid -- and analyze them to identify the most efficient options. Building
on this foundation, we develop an OBC-based general matrix multiplication core
using the im2col transformation, enabling efficient acceleration of a
fixed-point modified LeNet-5 model. FPGA evaluations demonstrate that the
proposed co-optimization approach significantly reduces resource utilization
compared to state-of-the-art LeNet-5 based CNN designs, with minimal impact on
accuracy.

</details>


### [2] [Variable Block-Correlation Modeling and Optimization for Secrecy Analysis in Fluid Antenna Systems](https://arxiv.org/abs/2510.03594)
*Tuo Wu,Kwai-Man Luk,Jie Tang,Kai-Kit Wong,Jianchao Zheng,Baiyang Liu,David Morales-Jimenez,Maged Elkashlan,Kin-Fai Tong,Chan-Byoung Chae,Fumiyuki Adachi,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 本文提出将可变块相关模型(VBCM)应用于流体天线系统(FAS)安全分析，开发了优化方法提升分析精度，推导了平均保密容量和保密中断概率的闭式表达式，并设计了两种最大化ASC的算法。


<details>
  <summary>Details</summary>
Motivation: 传统模型如Jakes模型分析困难，而过度简化的恒定相关模型无法准确捕捉FAS端口的空间相关性行为，这给6G无线通信中的FAS安全分析带来了挑战。

Method: 应用可变块相关模型(VBCM)到FAS安全分析，推导平均保密容量(ASC)和保密中断概率(SOP)的闭式表达式，并设计网格搜索和梯度下降两种算法来最大化ASC。

Result: VBCM框架实现了与仿真对齐的精度，相对误差始终低于5%，相比恒定相关模型的10-15%误差有显著提升。在高威胁场景下ASC提升超过120%，紧凑天线配置性能提升18-19%。

Conclusion: VBCM集成到FAS安全分析和优化中具有实际价值，是推进6G通信系统的强大工具。

Abstract: Fluid antenna systems (FAS) are emerging as a transformative enabler for
sixth-generation (6G) wireless communications, providing unprecedented spatial
diversity through dynamic reconfiguration of antenna ports. However, the
inherent spatial correlation among ports poses significant challenges for
accurate analysis. Conventional models such as Jakes are analytically
intractable, while oversimplified constant-correlation models fail to capture
the true behavior. In this work, we address these challenges by applying the
variable block-correlation model (VBCM) -- originally proposed by
Ram\'{i}rez-Espinosa \textit{et al.} in 2024 -- to FAS security analysis, and
by developing comprehensive optimization methods to enhance analytical
accuracy. We derive new closed-form expressions for average secrecy capacity
(ASC) and secrecy outage probability (SOP), demonstrating that the VBCM
framework achieves simulation-aligned accuracy, with relative errors
consistently below $5\%$ (compared to $10$--$15\%$ for constant-correlation
models). To maximize ASC, we further design two algorithms: a grid search (GS)
method and a gradient descent (GD) method. Numerical results reveal that the
VBCM-based approach not only provides reliable insights into FAS security
performance, but also yields substantial gains -- ASC improvements exceeding
$120\%$ in high-threat scenarios and $18$--$19\%$ performance enhancements for
compact antenna configurations. These findings underscore the practical value
of integrating VBCM into FAS security analysis and optimization, establishing
it as a powerful tool for advancing 6G communication systems.

</details>


### [3] [On-Grid Equivalence of Continuous-Time Doubly Selective Channels: A Revisit of Bello's Models](https://arxiv.org/abs/2510.03626)
*Jun Tong*

Main category: eess.SP

TL;DR: 该论文重新审视了双选择性信道的网格模型，研究了具有离网格延迟和多普勒频移的连续时间信道的等效网格表示，扩展了Bello的经典结果以考虑更一般的窗函数。


<details>
  <summary>Details</summary>
Motivation: 实际物理信道通常是离网格的，而现有通信研究主要使用基于传输帧带宽和时长的网格信道模型，这导致实际信道与网格模型之间存在差距。

Method: 研究连续时间双选择性信道在离网格延迟和多普勒频移下的等效网格域表示，考虑收发器端的实际时频域加窗处理，获得适用于有限支撑窗函数的通用模型。

Result: 建立了适用于有限支撑窗函数的通用网格模型，扩展了Bello的经典结果，使其能够处理更一般的窗函数情况。

Conclusion: 提出的等效网格模型能够更准确地描述实际物理信道，为双选择性信道通信提供了更精确的建模框架。

Abstract: Significant studies on communications over doubly selective channels have
utilized on-grid DD channel models, which are previously investigated in
Bello's seminar paper in 1963. The DD grid is typically specified by the
bandwidth and time duration of the transmission frames. However, the physical
channels are determined by the propagation environments and they are typically
off-grid. Hence, there is often a gap between an actual physical channel and
the on-grid model. This paper revisits the on-grid modeling of practical
physical channels. We study the associated on-grid DD-domain representations
for continuous-time, doubly selective channels with off-grid delay and Doppler
shifts, accounting for practical time/frequency-domain windowing at the
transceivers. The universal models obtained are applicable under the mild
assumption that the windows have finite supports, and they extend Bello's
classical results to account for more general windows. We also discuss the
features and implications of the equivalent on-grid models.

</details>


### [4] [Pinching Antenna Systems (PASS) for Cell-Free Communications](https://arxiv.org/abs/2510.03628)
*Haochen Li*

Main category: eess.SP

TL;DR: 提出了一种夹持天线系统辅助的无蜂窝通信系统，通过交替优化算法解决和速率最大化问题，在基站功率预算和夹持天线部署约束下实现性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统蜂窝系统在用户数量增加时会出现平均用户速率下降的问题，需要新的架构来改善系统性能。

Method: 使用交替优化算法，其中数字波束赋形子问题采用加权最小均方误差方法解决，夹持波束赋形子问题通过基于惩罚的方法结合逐元素优化处理。

Result: 仿真结果表明：1）PASS辅助的无蜂窝系统性能优于基准方案；2）增加每个波导的夹持天线数量可提升系统优势；3）无蜂窝架构缓解了用户数增加时的平均用户速率下降问题。

Conclusion: PASS辅助的无蜂窝通信系统能够有效提升系统性能，特别是在用户数量增加时保持稳定的用户速率。

Abstract: A pinching antenna system (PASS) assisted cell-free communication system is
proposed. A sum rate maximization problem under the BS power budget constraint
and PA deployment constraint is formulated. To tackle the proposed non-convex
optimization problem, an alternating optimization (AO) algorithm is developed.
In particular, the digital beamforming sub-problem is solved using the weighted
minimum mean square error (WMMSE) method, whereas the pinching beamforming
sub-problem is handled via a penalty based approach combined with element-wise
optimization. Simulation results demonstrate that: 1) the PASS assisted
cell-free systems achieve superior performance over benchmark schemes; 2)
increasing the number of PAs per waveguides can improve the advantage of PASS
assisted cell-free systems; and 3) the cell-free architecture mitigates the
average user rate degradation as the number of users increases.

</details>


### [5] [Towards Secure ISAC Beamforming: How Many Dedicated Sensing Beams Are Required?](https://arxiv.org/abs/2510.03749)
*Fanghao Xia,Zesong Fei,Xinyi Wang,Nanchi Su,Zhaolin Wang,Yuanwei Liu,Jie Xu*

Main category: eess.SP

TL;DR: 提出了一种用于多用户多窃听器ISAC系统的感知辅助安全通信方案，通过联合传输通信和感知信号，在满足窃听器SINR和感知SCNR约束下最大化系统和速率。


<details>
  <summary>Details</summary>
Motivation: 研究集成感知与通信系统中的安全通信问题，通过感知技术来检测和干扰空中窃听器，提升通信安全性。

Method: 使用基于分数规划的交替优化算法，结合SCA和SDR处理非凸约束；分析最小感知波束数，并将设计扩展到混合模拟数字阵列架构，采用流形优化处理单位模约束。

Result: 仿真结果表明少量感知波束即可有效完成感知和干扰任务，所提设计优于基线方法，并揭示了通信与感知之间的权衡关系。

Conclusion: 该研究为ISAC系统提供了有效的安全通信解决方案，证明了感知辅助方法在对抗空中窃听器方面的有效性。

Abstract: In this paper, sensing-assisted secure communication in a multi-user
multi-eavesdropper integrated sensing and communication (ISAC) system is
investigated. Confidential communication signals and dedicated sensing signals
are jointly transmitted by a base station (BS) to simultaneously serve users
and sense aerial eavesdroppers (AEs). A sum rate maximization problem is
formulated under AEs' Signal-to-Interference-plus-Noise Ratio (SINR) and
sensing Signal-to-Clutter-plus-Noise Ratio (SCNR) constraints. A
fractional-programming-based alternating optimization algorithm is developed to
solve this problem for fully digital arrays, where successive convex
approximation (SCA) and semidefinite relaxation (SDR) are leveraged to handle
non-convex constraints. Furthermore, the minimum number of dedicated sensing
beams is analyzed via a worst-case rank bound, upon which the proposed
beamforming design is further extended to the hybrid analog-digital (HAD) array
architecture, where the unit-modulus constraint is addressed by manifold
optimization. Simulation results demonstrate that only a small number of
sensing beams are sufficient for both sensing and jamming AEs, and the proposed
designs consistently outperform strong baselines while also revealing the
communication-sensing trade-off.

</details>


### [6] [A Benchmark Study of Deep Learning Methods for Multi-Label Pediatric Electrocardiogram-Based Cardiovascular Disease Classification](https://arxiv.org/abs/2510.03780)
*Yiqiao Chen*

Main category: eess.SP

TL;DR: 本研究首次对深度学习在儿科心血管疾病多标签分类方面进行基准测试，使用ZZU-pECG数据集（3716条记录，19种CVD类别），评估了ResNet-1D、BiLSTM、Transformer和Mamba 2四种模型在9导联和12导联配置下的性能。


<details>
  <summary>Details</summary>
Motivation: 心血管疾病是儿科主要健康负担，早期筛查至关重要。心电图作为无创且易获取的工具非常适合此目的，但目前缺乏儿科CVD分类的深度学习基准研究。

Method: 系统评估四种代表性深度学习范式（ResNet-1D、BiLSTM、Transformer、Mamba 2）在9导联和12导联配置下的性能，使用ZZU-pECG数据集进行多标签儿科CVD分类。

Result: 所有模型都取得了强劲结果，汉明损失低至0.0069，大多数设置下F1分数超过85%。ResNet-1D在12导联子集上达到94.67%的宏F1分数，BiLSTM和Transformer也表现出竞争力。对罕见疾病如肥厚型心肌病在9导联子集中存在挑战。

Conclusion: 该基准建立了可复用的基线，突出了不同范式的互补优势，并指出需要更大规模、多中心验证、年龄分层分析和更广泛的疾病覆盖，以支持真实世界的儿科心电图应用。

Abstract: Cardiovascular disease (CVD) is a major pediatric health burden, and early
screening is of critical importance. Electrocardiography (ECG), as a
noninvasive and accessible tool, is well suited for this purpose. This paper
presents the first benchmark study of deep learning for multi-label pediatric
CVD classification on the recently released ZZU-pECG dataset, comprising 3716
recordings with 19 CVD categories. We systematically evaluate four
representative paradigms--ResNet-1D, BiLSTM, Transformer, and Mamba 2--under
both 9-lead and 12-lead configurations. All models achieved strong results,
with Hamming Loss as low as 0.0069 and F1-scores above 85% in most settings.
ResNet-1D reached a macro-F1 of 94.67% on the 12-lead subset, while BiLSTM and
Transformer also showed competitive performance. Per-class analysis indicated
challenges for rare conditions such as hypertrophic cardiomyopathy in the
9-lead subset, reflecting the effect of limited positive samples. This
benchmark establishes reusable baselines and highlights complementary strengths
across paradigms. It further points to the need for larger-scale, multi-center
validation, age-stratified analysis, and broader disease coverage to support
real-world pediatric ECG applications.

</details>


### [7] [Toward Multiband Sensing in FR3: Frequency Anisotropy Characterization and Non-Contiguous Bands Aggregation Algorithms](https://arxiv.org/abs/2510.03787)
*Jacopo Pegoraro,Gianmaria Ventura,Dario Tagliaferri,Marco Mezzavilla,Andrea Bedin,Michele Rossi,Joerg Widmer*

Main category: eess.SP

TL;DR: 本文研究了6G网络中7-24 GHz频段（FR3）的相干多频段集成感知与通信技术，解决了频率各向异性和频谱非连续性问题，提出了新的相位相干性度量和算法来提高感知分辨率。


<details>
  <summary>Details</summary>
Motivation: FR3频段为6G网络提供了前所未有的带宽和频谱多样性，能够实现厘米级精度的多频段相干感知。但现有技术面临频率各向异性和频谱非连续性的挑战，需要新的解决方案。

Method: 实验表征了目标的频率各向异性特性，提出了新的多频段处理相位相干性度量，分析了3GPP非连续FR3频段的影响，并设计了新算法来减轻感知伪影。

Result: 提出的新算法在减轻非连续频段导致的感知伪影方面优于现有技术，为FR3多频段ISAC的完全开发迈出了重要一步。

Conclusion: 本研究为FR3频段的多频段集成感知与通信技术奠定了基础，通过解决频率各向异性和频谱非连续性问题，实现了更精确的感知能力。

Abstract: Frequency Range 3 (FR3) in the 7-24 GHz band will be the new spectrum for 6G
wireless networks. The bandwidth availability and diversity of FR3 offer
unprecedented opportunities for coherent multiband Integrated Sensing and
Communications (ISAC), which aggregates the carrier phase information from
multiple frequency bands to increase the sensing resolution to the cm-level.
However, the frequency anisotropy of sensing targets over GHz-wide bands and
the non-contiguity of the 6G spectrum, pose critical challenges to the
application of existing multiband ISAC techniques. We present the first study
on coherent multiband sensing in FR3. We experimentally characterize the
frequency anisotropy of targets and propose new phase coherence metrics for
multiband processing. Then, we analyze the impact of non-contiguous FR3 bands
considered by 3GPP, and design a new algorithm to mitigate the resulting
sensing artifacts, outperforming existing techniques. Our results represent a
first step toward fully developing multiband ISAC for FR3.

</details>


### [8] [Source PAC Coding for Low-latency Secret Key Generation in Short Blocklength Regime](https://arxiv.org/abs/2510.03818)
*Lulu Song,Di Zhang,Tingting Zhang*

Main category: eess.SP

TL;DR: 提出了一种多级源极化调整卷积(PAC)编码框架，用于解决短块长下密钥生成率和协调可靠性的问题，通过结合极化效应和最大似然解码错误系数，在短块长下实现了优于传统方法的密钥生成率。


<details>
  <summary>Details</summary>
Motivation: 源极化编码是6G物联网中短块长低延迟密钥生成的有前景方案，但现有方法在短块长下存在密钥生成率和协调可靠性的显著下降问题。

Method: 引入了多级源极化调整卷积(PAC)编码框架，并提出了一种新的码构造算法，联合利用极化效应和最大似然解码错误系数。

Result: 仿真表明，所提出的多级源PAC方案在密钥不一致约束下，即使在短块长情况下，也比传统和多级源极化编码方法实现了更优的密钥生成率。

Conclusion: 多级源PAC编码框架结合提出的码构造算法，能够有效提升短块长下的密钥生成性能，为6G物联网应用提供了更好的解决方案。

Abstract: Source polar coding is a potential solution for short blocklength-based
low-latency key generation with limited sources, which is a critical aspect of
six generation (6G) Internet of things. However, existing source coding schemes
still suffer from significant degradation in key generation rate and
reconciliation reliability in short blocklength regime. To address this issue,
we introduce a multilevel source polarization-adjusted convolutional (PAC)
coding framework. Furthermore, we propose a novel code construction algorithm
that jointly leverages polarization effects and the maximum likelihood (ML)
decoding error coefficient. Simulations demonstrate that the multilevel source
PAC scheme with the proposed code construction achieves superior key generation
rate under key disagreement constraints compared to conventional and multilevel
source polar coding methods even in short blocklength regimes.

</details>


### [9] [Multi-Frequency Resonating Based Magnetic Induction Underground Emergency Communications with Diverse Mediums](https://arxiv.org/abs/2510.03848)
*Jianyu Wang,Zhichao Li,Wenchi Cheng,Wei Zhang,Hailin Zhang*

Main category: eess.SP

TL;DR: 提出了一种用于地下应急磁感应通信的统计衰落信道模型，并开发了多频谐振补偿线圈的多频带传输方案来缓解不同介质衰落的影响。


<details>
  <summary>Details</summary>
Motivation: 实际地下应急通信中，由于灾害影响，传播介质通常是随机组成的多种介质，这对磁感应通信的实际应用提出了挑战。

Method: 建立了遵循对数正态分布的统计衰落信道模型，使用多频谐振补偿线圈实现多频带传输，分析了多频带磁感应通信在多种介质衰落下的性能。

Result: 数值结果表明，基于多频谐振补偿的多频带传输方案能有效减少不同介质衰落的影响并提升性能。

Conclusion: 多频谐振补偿的多频带传输是应对地下应急通信中随机介质组成挑战的有效解决方案。

Abstract: Magnetic induction (MI) communication is an effective underground emergency
communication technique after disasters such as landslides, mine collapses, and
earthquakes, due to its advantages in mediums such as soil, concrete, and
metals. However, the propagation mediums in practical MI based underground
emergency communications are usually diverse and composed randomly due to the
impact of disasters, which poses a challenge for MI communication in practical
applications. In this paper, we formulate a statistical fading channel model,
which reflects the random composition of diverse mediums and is shown to follow
a lognormal distribution. To mitigate the impact of diverse medium fading,
Multi-frequency Resonating Compensation (MuReC) based coils are used to achieve
multiband transmission. Then, we analyze the performance of MuReC based
multi-band MI communication with diverse medium fading and derive the
expressions of signal-to-noise ratio (SNR) probability density functions,
ergodic capacities, average bit error rates (BERs), and outage probabilities
for both multiplexing and diversity cases. Numerical results show that MuReC
based multiband transmission schemes can effectively reduce the impact of
diverse medium fading and enhance the performance.

</details>


### [10] [On the Exact Sum PDF and CDF of α-μ Variates](https://arxiv.org/abs/2510.03850)
*Fernando Darío Almeida García,Francisco Raimundo Albuquerque Parente,Michel Daoud Yacoub,Jose Cândido Silveira Santos Filho*

Main category: eess.SP

TL;DR: 本文提出了计算独立同分布α-μ随机变量和的新颖、简单、精确的概率密度函数和累积分布函数公式，其计算复杂度与求和项数量无关，显著提高了计算效率。


<details>
  <summary>Details</summary>
Motivation: 在无线通信中，随机变量和的统计特性对系统性能分析至关重要，但现有方法存在计算复杂度高、稳定性差等问题，特别是当求和项数量增加时。

Method: 推导了独立同分布α-μ随机变量和的精确PDF和CDF表达式，其计算复杂度不随求和项数量增加而增加。

Result: 新公式计算时间大幅减少，是迄今为止最高效和易处理的公式，并成功应用于L分支预检测等增益合并和最大比合并接收机的性能分析。

Conclusion: 提出的新方法解决了传统方法在计算随机变量和统计特性时的局限性，为无线通信系统性能分析提供了高效精确的工具。

Abstract: The sum of random variables (RVs) appears extensively in wireless
communications, at large, both conventional and advanced, and has been subject
of longstanding research. The statistical characterization of the referred sum
is crucial to determine the performance of such communications systems.
Although efforts have been undertaken to unveil these sum statistics, e.g.,
probability density function (PDF) and cumulative distribution function (CDF),
no general efficient nor manageable solutions capable of evaluating the exact
sum PDF and CDF are available to date. The only formulations are given in terms
of either the multi-fold Brennan's integral or the multivariate Fox H-function.
Unfortunately, these methods are only feasible up to a certain number of RVs,
meaning that when the number of RVs in the sum increases, the computation of
the sum PDF and CDF is subject to stability problems, convergence issues, or
inaccurate results. In this paper, we derive new, simple, exact formulations
for the PDF and CDF of the sum of L independent and identically distributed
{\alpha}-{\mu} RVs. Unlike the available solutions, the computational
complexity of our analytical expressions is independent of the number of
summands. Capitalizing on our unprecedented findings, we analyze, in exact and
asymptotic manners, the performance of L-branch pre-detection equal-gain
combining and maximal-ratio combining receivers over {\alpha}-{\mu} fading
environments. The coding and diversity gains of the system for both receivers
are analyzed and quantified. Moreover, numerical simulations show that the
computation time reduces drastically when using our expressions, which are
arguably the most efficient and manageable formulations derived so far.

</details>


### [11] [Robust Beamforming for Magnetic Induction Based Underground Emergency Communications](https://arxiv.org/abs/2510.03852)
*Jianyu Wang,Tianrui Hou,Wenchi Cheng,Hailin Zhang*

Main category: eess.SP

TL;DR: 提出了一种考虑信道估计误差的鲁棒波束成形方案，用于多用户磁感应地下应急通信，旨在最小化功耗同时满足总速率和用户SINR约束。


<details>
  <summary>Details</summary>
Motivation: 在灾后地下通信中，信道估计可能因复杂环境干扰而产生误差，影响磁感应通信性能。需要设计能够应对信道不确定性的鲁棒波束成形方案。

Method: 基于最坏情况优化准则和S-过程，将非凸的波束成形优化问题转化为凸优化问题求解，考虑了信道估计误差的影响。

Result: 数值结果表明，所提出的鲁棒波束成形方案在存在信道估计误差的情况下，能有效提高通信可靠性和有效吞吐量。

Conclusion: 该鲁棒波束成形方案为灾后地下应急通信提供了一种有效的解决方案，能够在信道估计不准确的情况下保证通信性能。

Abstract: Magnetic induction (MI) communication is an effective underground emergency
communication technique after disasters such as landslides, mine collapses, and
earthquakes, due to its advantages in mediums such as soil, concrete, and
metals. Based on channel state information (CSI), magnetic beamforming can
significantly improve the performance of MI communication. However, in
post-disaster underground communication, channel estimation may suffer from
errors due to factors such as complex environmental interferences. Taking
channel estimation error into account, we formulate a beamforming optimization
problem for multi-user MI underground emergency communications, which aims to
minimize the power consumption under the constraints of sum rate and signal to
interference plus noise ratio (SINR) of each user. Based on the worst-case
optimization criterion and the S-procedure, the non-convex optimization problem
is transformed into convex and solved. Numerical results show that the proposed
robust beamforming scheme can effectively enhance communication reliability and
effective throughput in the presence of channel estimation errors.

</details>


### [12] [On the Noise Robustness of Affine Frequency Division Multiplexing: Analysis and Applications](https://arxiv.org/abs/2510.03901)
*Vincent Savaux,Steve Sawadogo,Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu*

Main category: eess.SP

TL;DR: 本文研究AFDM和OTFS调制方案在非白高斯噪声下的鲁棒性，发现AFDM因解调矩阵稀疏度较低而性能最优，在多数场景下比OTFS和OFDM有超过1dB的性能增益。


<details>
  <summary>Details</summary>
Motivation: 研究AFDM和OTFS调制方案对抗非白高斯噪声的鲁棒性，这种噪声可以模拟接收信号的各种加性干扰源。

Method: 分析解调矩阵的白化噪声能力与矩阵稀疏度的关系，比较AFDM、OTFS和OFDM的性能表现，并通过仿真验证。

Result: AFDM性能优于OTFS和OFDM，其解调矩阵通常比其他波形的矩阵稀疏度更低，在非白噪声环境下大多数应用场景中增益超过1dB。

Conclusion: AFDM在非白高斯噪声环境下具有最佳性能，基于此分析提出了若干应用示例和使用场景，如窄带信号中的应用以及与OFDM信号的共存。

Abstract: This paper investigates the robustness of affine frequency division
multiplexing (AFDM) and orthogonal time frequency space (OTFS) modulation
schemes against non-white Gaussian noise, which can model various sources of
additive disturbances to the received signal. The proposed approach
demonstrates that the performance of these waveforms depends on the ability of
the demodulation matrix to whiten the noise-a property that is, in turn,
related to the sparsity of the matrix. AFDM is shown to outperform OTFS and
orthogonal frequency division multiplexing (OFDM), as its demodulation matrix
is generally less sparse than those of the other waveforms. Based on this
analysis, several application examples and use cases are presented, such as the
use of AFDM and OTFS in narrowband signals or in coexistence with OFDM signals.
Finally, simulation results confirm that AFDM achieves better performance than
OTFS and OFDM in the presence of non-white noise, with gains exceeding 1 dB in
most application scenarios.

</details>


### [13] [Closed-form Solutions for Velocity and Acceleration of a Moving Vehicle Using Range, Range Rate, and Derivative of Range Rate](https://arxiv.org/abs/2510.04037)
*Mohammad Salman,Hadi Zayyani,Hasan Abu Hilal,Mostafa Rashdan*

Main category: eess.SP

TL;DR: 提出了一种基于距离测量的移动目标位置、速度和加速度估计新方法，通过使用距离变化率的导数来扩展传统框架，包含加速度估计。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多只关注位置和速度估计，缺乏对加速度的估计，需要扩展框架来更全面地描述移动目标的运动学特性。

Method: 首先使用TOA技术估计位置，然后开发重构的最小二乘和加权最小二乘方法进行速度估计，最后利用距离变化率的导数结合先前的位置和速度估计来计算加速度。

Result: 仿真结果表明，与现有方法相比，所提出的方法在估计移动目标运动学参数方面具有更好的性能。

Conclusion: 该方法成功扩展了传统估计框架，通过引入距离变化率的导数实现了对加速度的有效估计，为移动目标跟踪提供了更全面的运动学信息。

Abstract: This letter presents a novel method for estimating the position, velocity,
and acceleration of a moving target using range-based measurements. Although
most existing studies focus on position and velocity estimation, the framework
of this letter is extended to include acceleration. To achieve this, we propose
using the derivative of the range rate, in addition to the range and range rate
measurements. The proposed method estimates the position at first using
Time-of-Arrival (TOA)-based techniques; then, develops a reformulated least
squares (LS) and weighted least squares (WLS) approaches for velocity
estimation; and finally, employs the derivative of the range rate to estimate
the acceleration using previous position and velocity estimates. On the other
hand, closed-form LS and WLS solutions are derived for both velocity and
acceleration. The simulation results show that the proposed approach provides
improved performance in estimating moving target kinematics compared to
existing methods.

</details>


### [14] [CLEAR: A Closed-Form Minimal-Sensor TDOA/FDOA Estimator for Moving-Source IoT Localization](https://arxiv.org/abs/2510.04160)
*Mohammad Kazzazi,Mohammad Morsali,Rouhollah Amiri*

Main category: eess.SP

TL;DR: CLEAR是一种使用最少传感器（N+1个）的闭式定位估计器，融合TDOA和FDOA测量，通过两阶段方法在计算效率和统计效率间取得平衡。


<details>
  <summary>Details</summary>
Motivation: 解决在资源受限的分布式物联网应用中，使用最少传感器实现高效定位的问题，特别是在无人机跟踪和智能交通等场景。

Method: 两阶段估计器：第一阶段引入辅助参数构建伪线性方程，通过加权最小二乘求解，使用Sylvester结式代数消元得到闭式解；第二阶段进行线性精炼以减少残差偏差。

Result: 在2D和3D场景的蒙特卡洛模拟中，位置和速度估计达到Cramer-Rao下界水平，性能优于代表性两阶段和迭代基线方法。

Conclusion: CLEAR方法在计算效率和统计效率间取得良好平衡，特别适合功率受限的分布式物联网应用，如无人机跟踪和智能交通系统。

Abstract: This paper presents CLEAR -- a closed-form localization estimator with a
reduced sensor network. The proposed method is a computationally efficient,
two-stage estimator that fuses time-difference-of-arrival (TDOA) and
frequency-difference-of-arrival (FDOA) measurements with a minimal number of
sensors. CLEAR localizes a moving source in N-dimensional space using only N+1
sensors, achieving the theoretical minimum sensor count. The first stage
introduces auxiliary range and range-rate parameters to construct a set of
pseudo-linear equations, solved via weighted least squares. An algebraic
elimination using Sylvester's resultant then reduces the problem to a quartic
equation, yielding closed-form estimates for the nuisance variables. A second,
lightweight linear refinement stage is applied to mitigate residual bias. Under
mild Gaussian noise assumptions, the estimator's position and velocity
estimates are statistically efficient, closely approaching the Cramer-Rao lower
bound (CRLB). Extensive Monte Carlo simulations in 2-D and 3-D scenarios
demonstrate CRLB-level accuracy and consistent performance gains over
representative two-stage and iterative baselines, confirming the method's high
suitability for power-constrained, distributed Internet of Things (IoT)
applications such as UAV tracking and smart transportation.

</details>


### [15] [Integrating Phase-Coherent Multistatic Imaging in Downlink D-MIMO Networks](https://arxiv.org/abs/2510.04240)
*Dario Tagliaferri,Silvia Mura,Musa Furkan Keskin,Sauradeep Dey,Henk Wymeersch*

Main category: eess.SP

TL;DR: 提出了一种分布式集成感知与通信系统，在D-MIMO下行链路中叠加专门设计的成像信号，实现多基地相干成像与通信的联合优化。


<details>
  <summary>Details</summary>
Motivation: 解决在相位相干分布式MIMO通信网络中集成多基地相干成像功能的挑战，需要在通信下行链路中同时实现高谱效通信和高质量成像。

Method: 设计AP特定的成像波形满足扩展正交条件，设计空间频率预编码器，提出接收AP的优化选择策略以最大化成像性能。

Result: 广泛的数值结果证明了该方案的可行性和优势，在实际D-MIMO部署中实现了联合多基地成像和通信的潜力。

Conclusion: 提出的D-ISAC系统通过精心设计的信号叠加和接收AP选择策略，成功实现了通信与多基地成像的有效集成，为实际部署提供了可行方案。

Abstract: This paper addresses the challenge of integrating multistatic coherent
imaging functionalities in the downlink (DL) of a phase-coherent distributed
multiple input multiple output (D-MIMO) communication network. During DL, the
D-MIMO access points (APs) jointly precode the transmitted signals to maximize
the spectral efficiency (SE) at the users (UEs) locations. However, imaging
requires that \textit{(i)} a fraction of the APs work as receivers for sensing
and \textit{(ii)} the transmitting APs emit AP-specific and orthogonal signals
to illuminate the area to be imaged and allow multistatic operation. In these
settings, our contribution is twofold. We propose a novel distributed
integrated sensing and communication (D-ISAC) system that superposes a
purposely designed AP-specific signal for imaging to the legacy UE-specific
communication one, with a tunable trade-off factor. We detail both the imaging
waveform design according to the \textit{extended orthogonality condition} and
the space-frequency precoder design. Then, we propose an optimized selection
strategy for the receiving APs, in order to maximize imaging performance under
half-duplex constraints. Extensive numerical results prove the feasibility and
benefits of our proposal, materializing the potential of joint multistatic
imaging and communications in practical D-MIMO deployments.

</details>


### [16] [Terahertz Channel Measurement and Modeling for Short-Range Indoor Environments](https://arxiv.org/abs/2510.04258)
*Ziang Zhao,Weixi Liang,Kai Hu,Qun Zhang,Xiongbin Yu,Qiang Li*

Main category: eess.SP

TL;DR: 提出了一种物理基础的Rician衰落信道模型，用于6G室内太赫兹通信，通过联合处理确定性LOS和随机NLOS分量，结合频率相关衰减和两射线反射框架，显著提高了信道建模精度。


<details>
  <summary>Details</summary>
Motivation: 现有信道模型在太赫兹通信中难以应对严重的频率选择性和多径效应，需要更准确的信道建模来支持6G室内网络的实现。

Method: 采用物理基础的Rician衰落模型，联合处理LOS和NLOS分量，使用优化的alpha和beta参数表征频率相关衰减，集成两射线反射框架捕捉驻波现象，并通过宽带频谱平均减轻频率选择性。

Result: 在208 GHz载波频率、0.1-0.9米距离的实测中，模型RMSE低至2.54 dB，比自由空间路径损耗模型提升14.2%，带宽增加时RMSE降低73.3%。

Conclusion: 该方法为太赫兹系统设计提供了稳健基础，支持可靠的室内WPAN、D2D通信和精确定位等6G应用，强调了带宽在抑制振荡伪影和提高建模精度中的重要性。

Abstract: Accurate channel modeling is essential for realizing the potential of
terahertz (THz) communications in 6G indoor networks, where existing models
struggle with severe frequency selectivity and multipath effects. We propose a
physically grounded Rician fading channel model that jointly incorporates
deterministic line-of-sight (LOS) and stochastic non-line-of-sight (NLOS)
components, enhanced by frequency-dependent attenuation characterized by
optimized exponents alpha and beta. Unlike conventional approaches, our model
integrates a two-ray reflection framework to capture standing wave phenomena
and employs wideband spectral averaging to mitigate frequency selectivity over
bandwidths up to 15 GHz. Empirical measurements at a 208 GHz carrier, spanning
0.1-0.9 m, demonstrate that our model achieves root mean square errors (RMSE)
as low as 2.54 dB, outperforming free-space path loss (FSPL) by up to 14.2% and
reducing RMSE by 73.3% as bandwidth increases. These findings underscore the
importance of bandwidth in suppressing oscillatory artifacts and improving
modeling accuracy. Our approach provides a robust foundation for THz system
design, supporting reliable indoor wireless personal area networks (WPANs),
device-to-device (D2D) communications, and precise localization in future 6G
applications.

</details>


### [17] [Efficient Domain Generalization in Wireless Networks with Scarce Multi-Modal Data](https://arxiv.org/abs/2510.04359)
*Minsu Kim,Walid Saad,Dour Calin*

Main category: eess.SP

TL;DR: 提出一种用于6G无线网络的两阶段学习框架，通过物理知识损失和协作域适应来提高在域偏移下的泛化性能，显著减少所需的多模态数据量。


<details>
  <summary>Details</summary>
Motivation: 解决6G无线网络中多模态ML模型在域偏移下泛化能力差的问题，因为实际无线系统中经常出现信道统计变化、移动障碍物或硬件配置变化等导致的域偏移。

Method: 两阶段学习框架：第一阶段使用基于物理的损失函数让每个基站学习无线环境的物理特性；第二阶段提出协作域适应，通过域相似性感知的模型聚合来利用多个基站的知识。

Result: 基于物理的训练仅需13%的数据样本就能达到不使用物理训练的最先进基线的性能；协作域适应仅需25%的数据样本和20%的FLOPs就能达到收敛。

Conclusion: 该框架在数据稀缺的多模态无线网络环境中实现了鲁棒的泛化性能，显著提高了数据效率和计算效率。

Abstract: In 6G wireless networks, multi-modal ML models can be leveraged to enable
situation-aware network decisions in dynamic environments. However, trained ML
models often fail to generalize under domain shifts when training and test data
distributions are different because they often focus on modality-specific
spurious features. In practical wireless systems, domain shifts occur
frequently due to dynamic channel statistics, moving obstacles, or hardware
configuration. Thus, there is a need for learning frameworks that can achieve
robust generalization under scarce multi-modal data in wireless networks. In
this paper, a novel and data-efficient two-phase learning framework is proposed
to improve generalization performance in unseen and unfamiliar wireless
environments with minimal amount of multi-modal data. In the first stage, a
physics-based loss function is employed to enable each BS to learn the physics
underlying its wireless environment captured by multi-modal data. The
data-efficiency of the physics-based loss function is analytically
investigated. In the second stage, collaborative domain adaptation is proposed
to leverage the wireless environment knowledge of multiple BSs to guide
under-performing BSs under domain shift. Specifically, domain-similarity-aware
model aggregation is proposed to utilize the knowledge of BSs that experienced
similar domains. To validate the proposed framework, a new dataset generation
framework is developed by integrating CARLA and MATLAB-based mmWave channel
modeling to predict mmWave RSS. Simulation results show that the proposed
physics-based training requires only 13% of data samples to achieve the same
performance as a state-of-the-art baseline that does not use physics-based
training. Moreover, the proposed collaborative domain adaptation needs only 25%
of data samples and 20% of FLOPs to achieve the convergence compared to
baselines.

</details>


### [18] [Low-Rank-Based Approximate Computation with Memristors](https://arxiv.org/abs/2510.04402)
*Binyu Lu,Matthias Frey,Stark Draper,Jingge Zhu*

Main category: eess.SP

TL;DR: 提出了一种基于低秩矩阵分解和两步串行向量矩阵乘法的忆阻器交叉阵列方案，通过奇异值分解和逐步平均来减轻随机写入误差，提高计算精度。


<details>
  <summary>Details</summary>
Motivation: 忆阻器交叉阵列虽然能实现向量矩阵乘法且功耗低，但难以精确写入忆阻器电导值，导致计算精度受限。

Method: 使用奇异值分解获得目标矩阵的低秩近似，将其分解为两个较小矩阵，然后执行两步串行向量矩阵乘法，通过逐步平均减轻随机写入误差。

Result: 推导了计算误差的一般表达式，并在规定奇异值分布下进行渐近分析，揭示了误差随矩阵大小和秩的缩放规律。分析和数值结果均证实了所提方案的优越性。

Conclusion: 所提出的基于低秩矩阵分解和两步串行计算的方案能有效提高忆阻器交叉阵列的计算精度，优于基准方案。

Abstract: Memristor crossbars enable vector-matrix multiplication (VMM), and are
promising for low-power applications. However, it can be difficult to write the
memristor conductance values exactly. To improve the accuracy of VMM, we
propose a scheme based on low-rank matrix approximation. Specifically, singular
value decomposition (SVD) is first applied to obtain a low-rank approximation
of the target matrix, which is then factored into a pair of smaller matrices.
Subsequently, a two-step serial VMM is executed, where the stochastic write
errors are mitigated through step-wise averaging. To evaluate the performance
of the proposed scheme, we derive a general expression for the resulting
computation error and provide an asymptotic analysis under a prescribed
singular-value profile, which reveals how the error scales with matrix size and
rank. Both analytical and numerical results confirm the superiority of the
proposed scheme compared with the benchmark scheme.

</details>


### [19] [Effect of nearby Metals on Electro-Quasistatic Human Body Communication](https://arxiv.org/abs/2510.04409)
*Samyadip Sarkar,Arunashish Datta,David Yang,Mayukh Nath,Shovan Maity,Shreyas Sen*

Main category: eess.SP

TL;DR: 本文系统研究了周围金属物体对人体通信信道的影响，发现金属物体可在20cm距离内减少传输损耗约10dB，接地金属连接可使信道增益增加至少20dB。


<details>
  <summary>Details</summary>
Motivation: 虽然先前研究注意到寄生返回路径在电容耦合系统中的作用，但周围金属物体对这些关键路径的影响尚未充分探索，本文填补了这一空白。

Method: 提出理论框架，结合有限元方法仿真和可穿戴设备实验，系统研究各种导电物体（包括非接地金属、接地金属及封闭金属环境）对人体通信信道的影响。

Result: 金属物体在20cm内可减少传输损耗约10dB；设备接地连接到接地金属物体时信道增益增加至少20dB；触摸接地金属时产生接触阻抗相关的高通信道特性；接地金属比浮动金属产生更大影响。

Conclusion: 这些发现增进了对人体中心通信链路的理解，并为医疗保健、消费电子、国防和工业应用的设计提供了指导。

Abstract: In recent decades Human Body Communication has emerged as a promising
alternative to traditional radio wave communication, utilizing the body's
conductive properties for low-power connectivity among wearables. This method
harnesses the human body as an energy-efficient channel for data transmission
within the electro-quasistatic frequency range, enabling advancements in
human-machine interaction. While prior work has noted the role of parasitic
return paths in such capacitively coupled systems, the influence of surrounding
metallic objects on these paths, which are critical for EQS wireless signaling,
has not been fully explored. This paper fills that gap with a structured study
of how various conducting objects, from non-grounded (floating) metals and
grounded metals to enclosed metallic environments such as elevators and cars,
affect the body-communication channel. We present a theoretical framework
supported by finite element method simulations and experiments with wearable
devices. Results show that metallic objects within 20 cm of devices can reduce
transmission loss by about 10 dB. When a device ground connects to a grounded
metallic object, channel gain can increase by at least 20 dB. Contact area
during touch-based interactions with grounded metals produces contact-impedance
dependent high-pass channel characteristics. Proximity to metallic objects
introduces variability within a critical distance, with grounded metals
producing a larger overall effect than floating metals. These findings improve
understanding of body-centric communication links and inform design for
healthcare, consumer electronics, defense, and industrial applications.

</details>


### [20] [The Role of ISAC in 6G Networks: Enabling Next-Generation Wireless Systems](https://arxiv.org/abs/2510.04413)
*Muhammad Umar Farooq Qaisar,Weijie Yuan,Onur Günlü,Taneli Riihonen,Yuanhao Cui,Lin Zhang,Nuria Gonzalez-Prelcic,Marco Di Renzo,Zhu Han*

Main category: eess.SP

TL;DR: 这篇教程论文全面概述了6G网络中集成传感与通信(ISAC)的作用，从5G以来的演进、技术驱动因素到核心原理、系统变体、使能技术，以及当前研究方向、挑战和未来趋势。


<details>
  <summary>Details</summary>
Motivation: 6G无线网络代表了通信与传感技术集成的根本转变，ISAC作为关键概念能够在一个统一框架内支持通信和传感的端到端支持，提高频谱效率、降低延迟，并支持智慧城市、自主系统和感知环境等多样化用例。

Method: 论文采用教程式方法，系统性地介绍了ISAC的演进历程、核心原理、系统变体，深入讨论了促进其实际部署的使能技术，并分析了当前研究方向。

Result: 论文识别了ISAC在6G网络中的关键挑战、开放问题和新兴趋势，并提出了设计见解和建议来支持未来的开发和实施。

Conclusion: ISAC对于6G网络至关重要，它带来了频谱效率提升、延迟降低等创新，并将通过支持多样化应用场景来塑造无线通信的未来。

Abstract: The commencement of the sixth-generation (6G) wireless networks represents a
fundamental shift in the integration of communication and sensing technologies
to support next-generation applications. Integrated sensing and communication
(ISAC) is a key concept in this evolution, enabling end-to-end support for both
communication and sensing within a unified framework. It enhances spectrum
efficiency, reduces latency, and supports diverse use cases, including smart
cities, autonomous systems, and perceptive environments. This tutorial provides
a comprehensive overview of ISAC's role in 6G networks, beginning with its
evolution since 5G and the technical drivers behind its adoption. Core
principles and system variations of ISAC are introduced, followed by an
in-depth discussion of the enabling technologies that facilitate its practical
deployment. The paper further analyzes current research directions to highlight
key challenges, open issues, and emerging trends. Design insights and
recommendations are also presented to support future development and
implementation. This work ultimately try to address three central questions:
Why is ISAC essential for 6G? What innovations does it bring? How will it shape
the future of wireless communication?

</details>


### [21] [Joint Probing and Scheduling for Cache-Aided Hybrid Satellite-Terrestrial Networks](https://arxiv.org/abs/2510.04492)
*Zhou Zhang,Yizhu Wang,Saman Atapattu,Sumei Sun*

Main category: eess.SP

TL;DR: 提出基于最优停止理论的联合探测与调度策略，通过LEO卫星探测卫星-地面链路和协作地面站缓存状态，动态调度用户进行内容分发，显著提升混合卫星-地面网络的系统吞吐量。


<details>
  <summary>Details</summary>
Motivation: 在带宽受限的卫星系统中，缓存对于降低延迟、优化吞吐量和提高数据可用性至关重要，需要战略性的MAC层设计来支持卫星-地面混合网络中的协作缓存。

Method: 采用最优停止理论方法，包含两级不完全信息，实时决策卫星-地面混合链路和缓存探测。基于阈值的策略优化探测和调度，利用协作缓存、卫星-地面链路传输和动态用户请求的时间分集。

Result: 仿真结果验证了所提策略的有效性和实用性，显著提高了平均系统吞吐量。

Conclusion: 提出的联合探测和调度策略通过利用协作缓存、链路传输和时间分集，成功优化了卫星-地面混合网络的吞吐量性能。

Abstract: Caching is crucial in hybrid satellite-terrestrial networks to reduce
latency, optimize throughput, and improve data availability by storing
frequently accessed content closer to users, especially in bandwidth-limited
satellite systems, requiring strategic Medium Access Control (MAC) layer. This
paper addresses throughput optimization in satellite-terrestrial integrated
networks through opportunistic cooperative caching. We propose a joint probing
and scheduling strategy to enhance content retrieval efficiency. The strategy
leverages the LEO satellite to probe satellite-to-ground links and cache states
of multiple cooperative terrestrial stations, enabling dynamic user scheduling
for content delivery. Using an optimal stopping theoretic approach with two
levels of incomplete information, we make real-time decisions on
satellite-terrestrial hybrid links and caching probing. Our threshold-based
strategy optimizes probing and scheduling, significantly improving average
system throughput by exploiting cooperative caching, satellite-terrestrial link
transmission, and time diversity from dynamic user requests. Simulation results
validate the effectiveness and practicality of the proposed strategies.

</details>


### [22] [Performance Analysis for Multi-User Holographic MIMO Downlink with Matched Filter Precoding](https://arxiv.org/abs/2510.04530)
*Gayathri Shekar,Saman Atapattu,Prathapasinghe Dharmawansa,Kandeepan Sithamparanathan*

Main category: eess.SP

TL;DR: 本文首次对多用户全息MIMO下行链路系统进行了分析性能研究，采用匹配滤波器预编码作为低复杂度基准方案，推导了SINR的闭式表达式和吞吐量近似。


<details>
  <summary>Details</summary>
Motivation: 全息MIMO作为未来无线系统的有前景解决方案，虽然已有研究关注电磁建模或仿真性能分析，但缺乏严谨的通信理论框架。

Method: 通过结合多径传播、互耦和元件激励，使用等效随机变量模型推导MF SINR闭式表达式，并利用双变量伽马分布开发了在不同CSI场景下的可处理吞吐量近似。

Result: 数值结果验证了所提框架的准确性，显示MF预编码在低SINR和CSI不确定性下具有强鲁棒性，性能具有竞争力。

Conclusion: 匹配滤波器预编码在全息MIMO系统中表现出良好的性能，特别是在低信噪比和信道状态信息不确定的情况下具有强鲁棒性。

Abstract: Holographic MIMO (HMIMO) has emerged as a promising solution for future
wireless systems by enabling ultra-dense, spatially continuous antenna
deployments. While prior studies have primarily focused on electromagnetic (EM)
modeling or simulation-based performance analysis, a rigorous
communication-theoretic framework remains largely unexplored. This paper
presents the first analytical performance study of a multi-user HMIMO downlink
system with matched filter (MF) precoding - a low-complexity baseline scheme.
By incorporating multipath propagation, mutual coupling, and element
excitation, we derive a novel closed-form expression for the MF
signal-to-interference-plus-noise ratio (SINR) using an equivalent random
variable model. Leveraging bivariate gamma distributions, we then develop
tractable throughput approximations under full, partial, and no channel state
information (CSI) scenarios. Additionally, we formulate a max-min beamforming
problem to benchmark optimal user fairness performance. Numerical results
validate the accuracy of the proposed framework and reveal that MF precoding
achieves competitive performance with strong robustness to low SINR and CSI
uncertainty.

</details>


### [23] [Coordinated Beamforming for Networked Integrated Communication and Multi-TMT Localization](https://arxiv.org/abs/2510.04600)
*Meidong Xia,Zhenyao He,Wei Xu,Yongming Huang,Derrick Wing Kwan Ng,Naofal Al-Dhahir*

Main category: eess.SP

TL;DR: 本文研究了网络化集成感知与通信系统中的协调波束成形设计，重点关注通信和基于到达时间的多目标监测终端定位的联合优化。


<details>
  <summary>Details</summary>
Motivation: 当前网络化ISAC系统中，将感知信号接收委托给专用目标监测终端而非基站，能显著提升感知能力和部署灵活性，但相关的协调波束成形设计尚未充分探索。

Method: 建立了通信和定位的信号模型，首次推导了定位性能的闭式克拉美-罗下界。针对感知中心和通信中心两种优化问题，分别开发了基于半定松弛的全局最优算法和二分搜索算法，并提出了统一的连续凸逼近算法。

Result: 仿真结果表明所提算法有效，揭示了通信与定位之间的内在性能权衡，并发现在网络化ISAC系统中部署更多目标监测终端比部署更多基站更优。

Conclusion: 本文填补了网络化集成通信与定位系统协调波束成形设计的空白，为下一代无线系统提供了有效的优化框架和算法解决方案。

Abstract: Networked integrated sensing and communication (ISAC) has gained significant
attention as a promising technology for enabling next-generation wireless
systems. To further enhance networked ISAC, delegating the reception of sensing
signals to dedicated target monitoring terminals (TMTs) instead of base
stations (BSs) offers significant advantages in terms of sensing capability and
deployment flexibility. Despite its potential, the coordinated beamforming
design for networked integrated communication and time-of-arrival (ToA)-based
multi-TMT localization remains largely unexplored. In this paper, we present a
comprehensive study to fill this gap. Specifically, we first establish signal
models for both communication and localization, and, for the first time, derive
a closed-form Cram\'er-Rao lower bound (CRLB) to characterize the localization
performance. Subsequently, we exploit this CRLB to formulate two optimization
problems, focusing on sensing-centric and communication-centric criteria,
respectively. For the sensing-centric problem, we develop a globally optimal
algorithm based on semidefinite relaxation (SDR) when each BS is equipped with
more antennas than the total number of communication users. While for the
communication-centric problem, we design a globally optimal algorithm for the
single-BS case using bisection search. For the general case of both problems,
we propose a unified successive convex approximation (SCA)-based algorithm,
which is suboptimal yet efficient, and further extend it from single-target
scenarios to more practical multi-target scenarios. Finally, simulation results
demonstrate the effectiveness of our proposed algorithms, reveal the intrinsic
performance trade-offs between communication and localization, and further show
that deploying more TMTs is always preferable to deploying more BSs in
networked ISAC systems.

</details>


### [24] [Dimensionally-Efficient Transmission and Storage of Unitary Matrices](https://arxiv.org/abs/2510.04734)
*Juan Vidal Alegría*

Main category: eess.SP

TL;DR: 提出了一种维度高效参数化方法，用于高效存储和传输酉矩阵，将酉矩阵映射为实数序列，维度减半且序列有界。


<details>
  <summary>Details</summary>
Motivation: 酉矩阵在信号处理中广泛应用，但存储和传输成本高，需要找到更高效的表示方法以降低内存和吞吐量需求。

Method: 显式推导了酉矩阵的维度高效参数化，建立了酉矩阵与实数序列的双向映射关系，并确定了参数的有界区间。

Result: 该方法将酉矩阵的存储维度减半，参数序列有界便于量化，在无线通信应用中展示了良好性能。

Conclusion: 提出的维度高效参数化方法能显著降低酉矩阵的存储和传输成本，在多个应用场景中具有实用价值。

Abstract: Unitary matrices are the basis of a large number of signal processing
applications. In many of these applications, finding ways to efficiently store,
and even transmit these matrices, can significantly reduce memory and
throughput requirements. In this work, we study the problem of efficient
transmission and storage of unitary matrices. Specifically, we explicitly
derive a dimensionally-efficient parametrization (DEP) for unitary matrices
that allows identifying them with sequences of real numbers, where the
dimension coincides with the dimension of the unitary group where they lie. We
also characterize its inverse map that allows retrieving the original unitary
matrices from their DEP. The proposed approach effectively allows halving the
dimension with respect to naively considering all the entries of each unitary
matrix, thus reducing the resources required to store and transmit these
matrices. Furthermore, we show that the sequence of real numbers associated to
the proposed DEP is bounded, and we delimit the interval where these numbers
are contained, facilitating the implementation of quantization approaches with
limited distortion. On the other hand, we outline ways to further reduce the
dimension of the DEP when considering more restrictive constraints for matrices
that show up in certain applications. The numerical results showcase the
potential of the proposed approach in general settings, as well as in three
specific applications of current interest for wireless communications research.

</details>


### [25] [Multilayer Non-Terrestrial Networks with Spectrum Access aided by Beyond-Diagonal RIS](https://arxiv.org/abs/2510.04744)
*Wali Ullah Khan,Chandan Kumar Sheemar,Eva Lagunas,Xingwang Li,Symeon Chatzinotas,Petar Popovski,Zhu Han*

Main category: eess.SP

TL;DR: 本文研究多层非地面网络，其中卫星作为主网络，高空平台站作为认知无线电的次网络。为了降低成本，HAPS配备了透射式BD-RIS天线前端，并联合优化BD-RIS相位响应和功率分配，在严格干扰约束下提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 传统天线阵列成本高、复杂度大、功耗高，需要更高效的天线解决方案来支持多层非地面网络。BD-RIS技术有望降低系统复杂度同时提升性能。

Method: 采用交替优化框架：功率分配子问题通过KKT条件得到闭式水填充解，BD-RIS配置通过黎曼流形优化进行优化。

Result: 仿真结果显示，相比对角RIS辅助基准，在数据速率和干扰抑制方面获得显著增益。

Conclusion: BD-RIS是未来多层非地面网络的有前景的使能技术，能够有效提升系统性能并降低复杂度。

Abstract: In this work, we study a multi-user NTN in which a satellite serves as the
primary network and a high-altitude platform station (HAPS) operates as the
secondary network, acting as a cognitive radio. To reduce the cost, complexity,
and power consumption of conventional antenna arrays, we equip the HAPS with a
transmissive BD-RIS antenna front end. We then formulate a joint optimization
problem for the BD-RIS phase response and the HAPS transmit power allocation
under strict per-user interference temperature constraints. To tackle the
resulting highly nonconvex problem, we propose an alternating-optimization
framework: the power-allocation subproblem admits a closed-form,
water-filling-type solution derived from the Karush-Kuhn-Tucker (KKT)
conditions, while the BD-RIS configuration is refined via Riemannian manifold
optimization. Simulation results show significant gains in data rate and
interference suppression over diagonal RIS-assisted benchmarks, establishing
BD-RIS as a promising enabler for future multilayer NTNs.

</details>


### [26] [Interference Alignment for Multi-cluster Over-the-Air Computation](https://arxiv.org/abs/2510.04745)
*Lucas Sempéré,Yue Bi,Yue Wu,Pengwenlong Gu,Selma Boumerdassi*

Main category: eess.SP

TL;DR: 提出了一种针对上行链路空中计算系统的干扰对齐方案，能够在多簇网络中有效管理干扰，使每个簇能利用一半可用信道而非传统时间共享的1/K。


<details>
  <summary>Details</summary>
Motivation: 物联网网络中大量设备同时通信产生的干扰是主要挑战，特别是在多簇网络中。空中计算虽然是有前景的实时数据聚合解决方案，但在密集干扰受限环境中性能受限。

Method: 开发了专门针对上行链路空中计算系统的干扰对齐方案，支持任意数量K个簇，并针对相邻簇间共享用户的场景设计了专门方案。

Result: 该方法使每个簇能够利用一半可用信道，相比传统时间共享只能利用1/K的信道资源，显著提高了频谱效率。

Conclusion: 所提出的干扰对齐方案为密集物联网网络中的空中计算系统提供了有效的干扰管理解决方案，能够显著提升系统性能。

Abstract: One of the main challenges facing Internet of Things (IoT) networks is
managing interference caused by the large number of devices communicating
simultaneously, particularly in multi-cluster networks where multiple devices
simultaneously transmit to their respective receiver. Over-the-Air Computation
(AirComp) has emerged as a promising solution for efficient real-time data
aggregation, yet its performance suffers in dense, interference-limited
environments. To address this, we propose a novel Interference Alignment (IA)
scheme tailored for up-link AirComp systems. Unlike previous approaches, the
proposed method scales to an arbitrary number $\sf K$ of clusters and enables
each cluster to exploit half of the available channels, instead of only
$\tfrac{1}{\sf K}$ as in time-sharing. In addition, we develop schemes tailored
to scenarios where users are shared between adjacent clusters.

</details>


### [27] [The IEEE Signal Processing Society's Leading Role in Developing Standards for Computational Imaging and Sensing: Part II](https://arxiv.org/abs/2510.04913)
*Andreas Bathelt,Benjamin Deutschmann,Hyeon Seok Rou,Kuranage Roche Rayan Ranasinghe,Giuseppe Thadeu Freitas de Abreu,Peter Vouras*

Main category: eess.SP

TL;DR: 该论文讨论了通过增加自由度来克服硬件限制的技术，重点介绍了IEEE信号处理协会在计算感知技术标准制定中的领导作用，特别是P3383和P3343工作组的标准活动。


<details>
  <summary>Details</summary>
Motivation: 物理硬件在成像和传感应用中存在性能限制，需要通过利用额外自由度来扩展系统性能，这些技术成熟后需要标准化以确保商业成功和互操作性。

Method: 通过同步分布式传感器合成更大孔径，以及通过波形设计和资源管理优化实现通信与感知功能的集成。IEEE信号处理协会通过SASC委员会的工作组制定相关标准。

Result: 论文重点介绍了P3383（集成感知与通信系统性能指标）和P3343（分布式传感器合成孔径时空同步）两个工作组的标准制定活动。

Conclusion: 标准在确保技术商业成功方面发挥关键作用，IEEE信号处理协会通过标准制定工作推动计算感知技术的发展和应用。

Abstract: In every imaging or sensing application, the physical hardware creates
constraints that must be overcome or they limit system performance. Techniques
that leverage additional degrees of freedom can effectively extend performance
beyond the inherent physical capabilities of the hardware. An example includes
synchronizing distributed sensors so as to synthesize a larger aperture for
remote sensing applications. An additional example is integrating the
communication and sensing functions in a wireless system through the clever
design of waveforms and optimized resource management. As these technologies
mature beyond the conceptual and prototype phase they will ultimately
transition to the commercial market. Here, standards play a critical role in
ensuring success. Standards ensure interoperability between systems
manufactured by different vendors and define industry best practices for
vendors and customers alike. The Signal Processing Society of the Institute for
Electrical and Electronics Engineers (IEEE) plays a leading role in developing
high-quality standards for computational sensing technologies through the
working groups of the Synthetic Aperture Standards Committee (SASC). In this
column we highlight the standards activities of the P3383 Performance Metrics
for Integrated Sensing and Communication (ISAC) Systems Working Group and the
P3343 Spatio-Temporal Synchronization of a Synthetic Aperture of Distributed
Sensors Working Group.

</details>


### [28] [Steady-State Spread Bounds for Graph Diffusion via Laplacian Regularisation](https://arxiv.org/abs/2510.04924)
*Ardavan Rahimian*

Main category: eess.SP

TL;DR: 该论文研究了图上的扩散过程在拉普拉斯正则化初始模式下的稳态偏离问题，给出了闭式上界，分离了图最大节点度的影响和正则化强度的影响，并提供了设计规则。


<details>
  <summary>Details</summary>
Motivation: 研究扩散过程在拉普拉斯正则化初始模式下的稳态偏离，特别是在阵列波束成形等应用中，需要量化最终状态与初始设计的差异。

Method: 在无向、非负图的标准稳定性条件下，推导出闭式的、实例特定的上界，分离了图最大节点度的不可约项和正则化强度控制项。

Result: 得到了稳态扩散的相对变化上界，该上界遵循逆平方根规律，并提供了简单的设计规则：给定目标扩散限制，可以闭式选择足够的正则化强度。

Conclusion: 该保证是非渐近的、易于计算的，能够认证稳态偏离的程度，适用于任何先执行拉普拉斯平滑然后通过图上的线性扩散演化的场景。

Abstract: We study how far a diffusion process on a graph can drift from a designed
starting pattern when that pattern is produced using Laplacian regularisation.
Under standard stability conditions for undirected, entrywise nonnegative
graphs, we give a closed-form, instance-specific upper bound on the
steady-state spread, measured as the relative change between the final and
initial profiles. The bound separates two effects: (i) an irreducible term
determined by the graph's maximum node degree, and (ii) a design-controlled
term that shrinks as the regularisation strength increases (following an
inverse square-root law). This leads to a simple design rule: given any target
limit on spread, one can choose a sufficient regularisation strength in closed
form. Although one motivating application is array beamforming, where the
initial pattern is the squared magnitude of the beamformer weights, the result
applies to any scenario that first enforces Laplacian smoothness and then
evolves by linear diffusion on a graph. Overall, the guarantee is
non-asymptotic, easy to compute, and certifies how much steady-state deviation
can occur.

</details>


### [29] [My First Five Years of Faculty Career at the University of Delaware](https://arxiv.org/abs/2510.05000)
*Xiang-Gen Xia*

Main category: eess.SP

TL;DR: 作者总结了自己在美国大学前5年的学术研究成果，认为这是其职业生涯中最优秀且最满意的成果，并希望这些经验能帮助年轻研究者。


<details>
  <summary>Details</summary>
Motivation: 作者希望分享自己在学术生涯初期的研究成果和经验，为年轻研究者提供参考和帮助。

Method: 通过个人总结和回顾的方式，整理和分析了前5年的学术研究成果。

Result: 作者认为这5年的研究成果是其职业生涯中最优秀且最满意的成果。

Conclusion: 作者希望通过分享这些经验，能够对年轻研究者的学术发展有所帮助。

Abstract: In this short article, I would like to briefly summarize my research in the
first 5 years in my university academia life in USA. I think that my research
results obtained in these 5 years are the best in my career, at least which I
like the most by myself. I wish that my experience in my junior academia career
could be of some help to young researchers.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [30] [Scaling Multi-Talker ASR with Speaker-Agnostic Activity Streams](https://arxiv.org/abs/2510.03630)
*Xiluo He,Alexander Polok,Jesús Villalba,Thomas Thebaud,Matthew Maciejewski*

Main category: eess.AS

TL;DR: 提出了一种将说话人活动信号转换为说话人无关流的方法，使多说话人语音识别的推理成本与说话人数量解耦，显著减少运行时间同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多说话人语音识别系统需要为每个说话人运行一次ASR模型，导致推理成本随说话人数量线性增长，限制了实际应用。

Method: 将说话人特定的活动输出转换为两个说话人无关的流，设计新的启发式方法来保持对话连续性并与现有系统兼容。

Result: 在AMI和ICSI会议数据集上，与Diarization-Conditioned Whisper兼容，大幅减少运行时间的同时保持有竞争力的性能。

Conclusion: 该方法成功地将多说话人ASR的推理成本与说话人数量解耦，为实际应用提供了可行的解决方案。

Abstract: An increasingly common training paradigm for multi-talker automatic speech
recognition (ASR) is to use speaker activity signals to adapt single-speaker
ASR models for overlapping speech. Although effective, these systems require
running the ASR model once per speaker, resulting in inference costs that scale
with the number of speakers and limiting their practicality. In this work, we
propose a method that decouples the inference cost of activity-conditioned ASR
systems from the number of speakers by converting speaker-specific activity
outputs into two speaker-agnostic streams. A central challenge is that
na\"ively merging speaker activities into streams significantly degrades
recognition, since pretrained ASR models assume contiguous, single-speaker
inputs. To address this, we design new heuristics aimed at preserving
conversational continuity and maintaining compatibility with existing systems.
We show that our approach is compatible with Diarization-Conditioned Whisper
(DiCoW) to greatly reduce runtimes on the AMI and ICSI meeting datasets while
retaining competitive performance.

</details>


### [31] [Adapting Diarization-Conditioned Whisper for End-to-End Multi-Talker Speech Recognition](https://arxiv.org/abs/2510.03723)
*Martin Kocour,Martin Karafiat,Alexander Polok,Dominik Klement,Lukáš Burget,Jan Černocký*

Main category: eess.AS

TL;DR: 提出一种基于Whisper的说话人归属多说话人语音识别模型，结合目标说话人建模和序列化输出训练，通过联合解码实现重叠语音的带说话人标签和时间的序列化转录。


<details>
  <summary>Details</summary>
Motivation: 解决多说话人重叠语音识别问题，克服传统目标说话人ASR系统需要分别解码每个说话人的限制，实现更高效的联合解码。

Method: 使用Diarization-Conditioned Whisper (DiCoW)编码器提取目标说话人嵌入，将多个说话人表示拼接后输入共享解码器，采用序列化输出训练(SOT)生成带说话人标签和时间的转录流。

Result: 实验表明该模型优于现有的SOT方法，并在多说话人混合语音(如LibriMix)上超越了DiCoW系统。

Conclusion: 提出的说话人归属Whisper模型通过联合解码策略，在多说话人语音识别任务中取得了优越性能，为重叠语音识别提供了有效解决方案。

Abstract: We propose a speaker-attributed (SA) Whisper-based model for multi-talker
speech recognition that combines target-speaker modeling with serialized output
training (SOT). Our approach leverages a Diarization-Conditioned Whisper
(DiCoW) encoder to extract target-speaker embeddings, which are concatenated
into a single representation and passed to a shared decoder. This enables the
model to transcribe overlapping speech as a serialized output stream with
speaker tags and timestamps. In contrast to target-speaker ASR systems such as
DiCoW, which decode each speaker separately, our approach performs joint
decoding, allowing the decoder to condition on the context of all speakers
simultaneously. Experiments show that the model outperforms existing SOT-based
approaches and surpasses DiCoW on multi-talker mixtures (e.g., LibriMix).

</details>


### [32] [A MATLAB toolbox for Computation of Speech Transmission Index (STI)](https://arxiv.org/abs/2510.03825)
*Pavel Rajmic,Jiří Schimmel,Šimon Cieslar*

Main category: eess.AS

TL;DR: 开发了一个符合IEC 60268-16:2020标准的开源Matlab STI实现，包含直接和间接方法以及STIPA协议，通过参考信号测试和商业设备对比验证了准确性。


<details>
  <summary>Details</summary>
Motivation: 当前可靠的STI实现不公开可用，且通常受限于专有测量硬件，需要开发一个公开可用的标准实现。

Method: 基于IEC 60268-16:2020标准，在Matlab中实现了直接和间接STI计算方法，包括缩短的STIPA协议。

Result: 实现满足标准要求，通过参考信号测试验证，并与商业测量设备对比进行了验证测量。

Conclusion: 提供了一个开源、准确的STI计算软件，解决了当前STI实现不公开可用的问题。

Abstract: The speech transmission index (STI) is a popular simple metric for the
prediction of speech intelligibility when speech is passed through a
transmission channel. Computation of STI from acoustic measurements is
described in the IEC 60268-16:2020 standard. Though, reliable implementations
of STI are not publicly accessible and are frequently limited to the use with a
proprietary measurement hardware. We present a Matlab STI implementation of
both the direct and indirect approaches according to the standard, including
the shortened STIPA protocol. The suggested implementation meets prescribed
requirements, as evidenced by tests on reference signals. Additionally, we
conducted a verification measurement in comparison to a commercial measurement
device. Our software comes with open source code.

</details>


### [33] [A Multilingual Framework for Dysarthria: Detection, Severity Classification, Speech-to-Text, and Clean Speech Generation](https://arxiv.org/abs/2510.03986)
*Ananya Raghu,Anisha Raghu,Nithika Vivek,Sofie Budman,Omar Mansour*

Main category: eess.AS

TL;DR: 提出一个统一的多语言AI框架，用于处理构音障碍的六个关键方面：检测、严重程度分类、清晰语音生成、语音转文本、情感检测和声音克隆，在英语、俄语和德语数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 构音障碍是一种运动性言语障碍，导致言语缓慢且难以理解，严重影响社交交流。现有工具缺乏跨语言和严重程度级别的通用性，需要开发更全面的解决方案。

Method: 使用基于频谱图的可视化和声学特征提取来训练模型，采用跨语言迁移学习方法，在英语、俄语和德语数据集上进行训练和评估。

Result: 二元检测模型在三语言上达到97%准确率，严重程度分类模型测试准确率97%，语音翻译管道在俄语和英语上获得低L1损失，语音转文本的词错误率为0.1367。

Conclusion: 该研究的结果和产品可用于诊断构音障碍，并改善不同语言患者的沟通和理解能力，展示了跨语言迁移学习在低资源环境中的潜力。

Abstract: Dysarthria is a motor speech disorder that results in slow and often
incomprehensible speech. Speech intelligibility significantly impacts
communication, leading to barriers in social interactions. Dysarthria is often
a characteristic of neurological diseases including Parkinson's and ALS, yet
current tools lack generalizability across languages and levels of severity. In
this study, we present a unified AI-based multilingual framework that addresses
six key components: (1) binary dysarthria detection, (2) severity
classification, (3) clean speech generation, (4) speech-to-text conversion, (5)
emotion detection, and (6) voice cloning. We analyze datasets in English,
Russian, and German, using spectrogram-based visualizations and acoustic
feature extraction to inform model training. Our binary detection model
achieved 97% accuracy across all three languages, demonstrating strong
generalization across languages. The severity classification model also reached
97% test accuracy, with interpretable results showing model attention focused
on lower harmonics. Our translation pipeline, trained on paired Russian
dysarthric and clean speech, reconstructed intelligible outputs with low
training (0.03) and test (0.06) L1 losses. Given the limited availability of
English dysarthric-clean pairs, we fine-tuned the Russian model on English data
and achieved improved losses of 0.02 (train) and 0.03 (test), highlighting the
promise of cross-lingual transfer learning for low-resource settings. Our
speech-to-text pipeline achieved a Word Error Rate of 0.1367 after three
epochs, indicating accurate transcription on dysarthric speech and enabling
downstream emotion recognition and voice cloning from transcribed speech.
Overall, the results and products of this study can be used to diagnose
dysarthria and improve communication and understanding for patients across
different languages.

</details>


### [34] [MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition](https://arxiv.org/abs/2510.04136)
*Umberto Cappellazzo,Minsu Kim,Pingchuan Ma,Honglie Chen,Xubo Liu,Stavros Petridis,Maja Pantic*

Main category: eess.AS

TL;DR: MoME框架将稀疏专家混合(MoE)集成到套娃表示学习(MRL)中，用于音视频语音识别，实现了动态容量分配和跨粒度一致性，在保持高性能的同时显著减少参数需求。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM在音视频语音识别中计算需求高、token粒度敏感的问题，以及现有token压缩方法缺乏灵活性、MRL方法跨尺度泛化能力有限的问题。

Method: 在冻结的LLM基础上添加top-k路由的共享专家，通过共享路由器实现跨粒度一致激活，使压缩序列能从低压缩表示中受益。

Result: 在LRS2和LRS3数据集上，MoME在AVSR、ASR和VSR任务中达到最先进性能，参数需求显著减少，且在噪声下保持鲁棒性。

Conclusion: MoME统一了MRL的适应性和MoE的效率，为资源感知的语音识别提供了可扩展且可解释的解决方案。

Abstract: Large language models (LLMs) have recently shown strong potential in
audio-visual speech recognition (AVSR), but their high computational demands
and sensitivity to token granularity limit their practicality in
resource-constrained settings. Token compression methods can reduce inference
cost, but they require fixing a compression rate in advance and produce a
single fixed-length output, offering no flexibility to balance information
density and efficiency at inference time. Matryoshka representation learning
(MRL) addresses this by enabling a single model to operate across multiple
token granularities, allowing compression rates to be adjusted dynamically.
However, current MRL-based methods treat each scale independently during
training, limiting cross-scale generalization, robustness at high compression,
and interpretability. To overcome these limitations, we propose MoME (Mixture
of Matryoshka Experts), a novel framework that integrates sparse
Mixture-of-Experts (MoE) into MRL-based LLMs for AVSR. MoME augments a frozen
LLM with top-k routed and shared experts, allowing dynamic capacity allocation
across scales and modalities. A shared router promotes consistent expert
activation across granularities, enabling compressed sequences to benefit from
representations learned at lower compression. Experiments on LRS2 and LRS3
demonstrate that MoME achieves state-of-the-art performance across AVSR, ASR,
and VSR tasks, while requiring significantly fewer parameters and maintaining
robustness under noise. MoME unifies the adaptability of MRL with the
efficiency of MoE, offering a scalable and interpretable solution for
resource-aware speech recognition.

</details>


### [35] [Drax: Speech Recognition with Discrete Flow Matching](https://arxiv.org/abs/2510.04162)
*Aviv Navon,Aviv Shamsian,Neta Glazer,Yael Segal-Feldman,Gill Hetz,Joseph Keshet,Ethan Fetaya*

Main category: eess.AS

TL;DR: Drax是一个用于自动语音识别的离散流匹配框架，通过音频条件概率路径实现高效并行解码，在保持最先进识别精度的同时提供更好的精度-效率权衡。


<details>
  <summary>Details</summary>
Motivation: 扩散和基于流的非自回归模型在大型语言建模中显示出强大潜力，但在自动语音识别领域的应用尚未充分探索。

Method: 构建音频条件概率路径，引导模型通过类似于推理过程中可能出现的中间误差轨迹，而不是直接从随机噪声到目标的转换。

Result: 实证评估表明，该方法在识别精度上与最先进的语音模型相当，同时提供了改进的精度-效率权衡。

Conclusion: 离散流匹配是推进非自回归自动语音识别的一个有前景的方向。

Abstract: Diffusion and flow-based non-autoregressive (NAR) models have shown strong
promise in large language modeling, however, their potential for automatic
speech recognition (ASR) remains largely unexplored. We propose Drax, a
discrete flow matching framework for ASR that enables efficient parallel
decoding. To better align training with inference, we construct an
audio-conditioned probability path that guides the model through trajectories
resembling likely intermediate inference errors, rather than direct random
noise to target transitions. Our theoretical analysis links the generalization
gap to divergences between training and inference occupancies, controlled by
cumulative velocity errors, thereby motivating our design choice. Empirical
evaluation demonstrates that our approach attains recognition accuracy on par
with state-of-the-art speech models while offering improved accuracy-efficiency
trade-offs, highlighting discrete flow matching as a promising direction for
advancing NAR ASR.

</details>


### [36] [Enhancing Speaker Verification with w2v-BERT 2.0 and Knowledge Distillation guided Structured Pruning](https://arxiv.org/abs/2510.04213)
*Ze Li,Ming Cheng,Ming Li*

Main category: eess.AS

TL;DR: 使用600M参数的w2v-BERT 2.0预训练模型进行说话人验证，采用MFA结构和Layer Adapter处理多层特征，结合LoRA高效微调，在Vox1-O和Vox1-H测试集上分别达到0.12%和0.55%的EER，并通过知识蒸馏剪枝将模型大小减少80%而性能仅下降0.04%


<details>
  <summary>Details</summary>
Motivation: 利用大规模自监督预训练模型为说话人验证任务提供丰富的特征表示

Method: 使用w2v-BERT 2.0预训练模型，采用MFA结构和Layer Adapter处理多层特征输出，结合LoRA进行高效微调，并应用知识蒸馏指导的结构化剪枝

Result: 在Vox1-O和Vox1-H测试集上分别达到0.12%和0.55%的EER，剪枝后模型大小减少80%而EER仅增加0.04%

Conclusion: w2v-BERT 2.0在说话人验证任务中表现出色，结合高效微调和剪枝技术可以在保持高性能的同时大幅减小模型规模

Abstract: Large-scale self-supervised Pre-Trained Models (PTMs) have shown significant
improvements in the speaker verification (SV) task by providing rich feature
representations. In this paper, we utilize w2v-BERT 2.0, a model with
approximately 600 million parameters trained on 450 million hours of unlabeled
data across 143 languages, for the SV task. The MFA structure with Layer
Adapter is employed to process the multi-layer feature outputs from the PTM and
extract speaker embeddings. Additionally, we incorporate LoRA for efficient
fine-tuning. Our model achieves state-of-the-art results with 0.12% and 0.55%
EER on the Vox1-O and Vox1-H test sets, respectively. Furthermore, we apply
knowledge distillation guided structured pruning, reducing the model size by
80% while achieving only a 0.04% EER degradation. Source code and models are
released at https://github.com/ZXHY-82/w2v-BERT-2.0_SV.

</details>


### [37] [Probing Whisper for Dysarthric Speech in Detection and Assessment](https://arxiv.org/abs/2510.04219)
*Zhengjun Yue,Devendra Kayande,Zoran Cvetkovic,Erfan Loweimi*

Main category: eess.AS

TL;DR: 该研究分析了Whisper-Medium模型编码器对构音障碍语音的表征，发现中层编码器层（13-15）最具信息性，微调仅带来适度变化，为病理语音分析提供了指导。


<details>
  <summary>Details</summary>
Motivation: 理解构音障碍语音在Whisper模型各层的表征方式，对于构建可靠且可解释的临床评估工具至关重要，但目前对大规模端到端模型在病理语音上的内部行为了解不足。

Method: 使用线性分类器评估Whisper-Medium编码器的逐层嵌入，在单任务和多任务设置下进行分析，辅以轮廓分数和互信息来评估层信息性，并在构音障碍语音识别任务上微调模型后重复分析。

Result: 跨多个指标，中层编码器层（13-15）被证明最具信息性，而微调仅引起适度变化，表明这些层对构音障碍语音的表征相对稳定。

Conclusion: 研究提高了Whisper嵌入的可解释性，并突显了探测分析在指导大规模预训练模型用于病理语音方面的潜力。

Abstract: Large-scale end-to-end models such as Whisper have shown strong performance
on diverse speech tasks, but their internal behavior on pathological speech
remains poorly understood. Understanding how dysarthric speech is represented
across layers is critical for building reliable and explainable clinical
assessment tools. This study probes the Whisper-Medium model encoder for
dysarthric speech for detection and assessment (i.e., severity classification).
We evaluate layer-wise embeddings with a linear classifier under both
single-task and multi-task settings, and complement these results with
Silhouette scores and mutual information to provide perspectives on layer
informativeness. To examine adaptability, we repeat the analysis after
fine-tuning Whisper on a dysarthric speech recognition task. Across metrics,
the mid-level encoder layers (13-15) emerge as most informative, while
fine-tuning induces only modest changes. The findings improve the
interpretability of Whisper's embeddings and highlight the potential of probing
analyses to guide the use of large-scale pretrained models for pathological
speech.

</details>


### [38] [Differentiable physics for sound field reconstruction](https://arxiv.org/abs/2510.04459)
*Samuel A. Verburg,Efren Fernandez-Grande,Peter Gerstoft*

Main category: eess.AS

TL;DR: 提出了一种可微分物理方法用于声场重建，通过神经网络近似波动方程初始条件，使用可微分数值求解器计算微分算子，在严重欠采样条件下仍能有效重建声场。


<details>
  <summary>Details</summary>
Motivation: 传统基于物理的神经网络将物理约束作为损失函数的一部分，而该方法通过可微分数值求解器将物理作为强约束，实现更稳定的网络训练和更好的收敛性。

Method: 使用神经网络近似波动方程初始条件，结合可微分数值求解器计算微分算子，并引入稀疏促进约束来处理严重欠采样问题。

Result: 实验表明该方法在极端数据稀缺条件下能重建声场，相比传统物理信息神经网络具有更高精度和更好收敛性。

Conclusion: 可微分物理方法为声场重建提供了新思路，通过强物理约束和稀疏促进机制，在严重欠采样条件下仍能获得有意义的解。

Abstract: Sound field reconstruction involves estimating sound fields from a limited
number of spatially distributed observations. This work introduces a
differentiable physics approach for sound field reconstruction, where the
initial conditions of the wave equation are approximated with a neural network,
and the differential operator is computed with a differentiable numerical
solver. The use of a numerical solver enables a stable network training while
enforcing the physics as a strong constraint, in contrast to conventional
physics-informed neural networks, which include the physics as a constraint in
the loss function. We introduce an additional sparsity-promoting constraint to
achieve meaningful solutions even under severe undersampling conditions.
Experiments demonstrate that the proposed approach can reconstruct sound fields
under extreme data scarcity, achieving higher accuracy and better convergence
compared to physics-informed neural networks.

</details>


### [39] [UniVoice: Unifying Autoregressive ASR and Flow-Matching based TTS with Large Language Models](https://arxiv.org/abs/2510.04593)
*Wenhao Guan,Zhikang Niu,Ziyue Jiang,Kaidi Wang,Peijie Chen,Qingyang Hong,Lin Li,Xie Chen*

Main category: eess.AS

TL;DR: UniVoice是一个统一的大语言模型框架，通过连续表示将语音识别和语音合成集成在单一模型中，结合自回归建模和流匹配技术，在ASR和零样本TTS任务中达到或超越当前单任务建模方法的性能。


<details>
  <summary>Details</summary>
Motivation: 当前大多数方法将语音识别和语音合成作为独立任务处理，缺乏统一框架。离散语音标记化虽然支持联合建模，但其固有的信息损失限制了识别和生成性能。

Method: 提出UniVoice框架，使用连续表示集成语音识别和合成。结合自回归建模（用于识别）和流匹配（用于高质量生成），设计双重注意力机制在因果掩码和双向注意力掩码间切换，并采用文本前缀条件语音填充方法实现零样本语音克隆。

Result: 实验结果表明，该方法在ASR和零样本TTS任务中能够达到或超越当前单任务建模方法的性能。

Conclusion: 这项工作为端到端语音理解和生成探索了新的可能性，展示了统一模型在语音处理任务中的潜力。

Abstract: Large language models (LLMs) have demonstrated promising performance in both
automatic speech recognition (ASR) and text-to-speech (TTS) systems, gradually
becoming the mainstream approach. However, most current approaches address
these tasks separately rather than through a unified framework. This work aims
to integrate these two tasks into one unified model. Although discrete speech
tokenization enables joint modeling, its inherent information loss limits
performance in both recognition and generation. In this work, we present
UniVoice, a unified LLM framework through continuous representations that
seamlessly integrates speech recognition and synthesis within a single model.
Our approach combines the strengths of autoregressive modeling for speech
recognition with flow matching for high-quality generation. To mitigate the
inherent divergence between autoregressive and flow-matching models, we further
design a dual attention mechanism, which switches between a causal mask for
recognition and a bidirectional attention mask for synthesis. Furthermore, the
proposed text-prefix-conditioned speech infilling method enables high-fidelity
zero-shot voice cloning. Experimental results demonstrate that our method can
achieve or exceed current single-task modeling methods in both ASR and
zero-shot TTS tasks. This work explores new possibilities for end-to-end speech
understanding and generation.

</details>


### [40] [AURA Score: A Metric For Holistic Audio Question Answering Evaluation](https://arxiv.org/abs/2510.04934)
*Satvik Dixit,Soham Deshmukh,Bhiksha Raj*

Main category: eess.AS

TL;DR: 提出了AQEval基准和AURA评分，用于改进音频问答任务的评估方法，解决现有指标与人类判断相关性弱的问题。


<details>
  <summary>Details</summary>
Motivation: 现有音频问答评估指标（如BLEU、METEOR等）主要从NLP和音频字幕领域移植而来，依赖表面相似性，无法考虑问题上下文、推理过程和部分正确性，与人类判断相关性较弱。

Method: 1）创建AQEval基准，包含1万个模型回答的多重人工标注；2）分析现有AQA指标在AQEval上的表现；3）提出新的AURA评分指标来评估开放式回答。

Result: AURA评分在AQEval上达到了与人类评分的最优相关性，显著优于所有基线方法。

Conclusion: 当前AQA评估方法存在局限性，AQEval基准和AURA评分为未来全面AQA评估研究提供了支持。

Abstract: Audio Question Answering (AQA) is a key task for evaluating Audio-Language
Models (ALMs), yet assessing open-ended responses remains challenging. Existing
metrics used for AQA such as BLEU, METEOR and BERTScore, mostly adapted from
NLP and audio captioning, rely on surface similarity and fail to account for
question context, reasoning, and partial correctness. To address the gap in
literature, we make three contributions in this work. First, we introduce
AQEval to enable systematic benchmarking of AQA metrics. It is the first
benchmark of its kind, consisting of 10k model responses annotated by multiple
humans for their correctness and relevance. Second, we conduct a comprehensive
analysis of existing AQA metrics on AQEval, highlighting weak correlation with
human judgment, especially for longer answers. Third, we propose a new metric -
AURA score, to better evaluate open-ended model responses. On AQEval, AURA
achieves state-of-the-art correlation with human ratings, significantly
outperforming all baselines. Through this work, we aim to highlight the
limitations of current AQA evaluation methods and motivate better metrics. We
release both the AQEval benchmark and the AURA metric to support future
research in holistic AQA evaluation.

</details>


### [41] [Perceptual Evaluation of Extrapolated Spatial Room Impulse Responses From a Mono Source](https://arxiv.org/abs/2510.04937)
*Ben Heritage,Fiona Ryder,Michael McLoughlin,Karolina Prawda*

Main category: eess.AS

TL;DR: 本研究通过3AFC听力测试评估了从单声道测量中推断的空间化房间脉冲响应的可信度，结果显示参与者区分人工和真实刺激的准确率为38%，仅比猜测率高5个百分点，表明从单声道测量推断空间RIR是可行的。


<details>
  <summary>Details</summary>
Motivation: 虚拟和增强现实中的沉浸感依赖于真实的空间音频，但传统方法需要大量声学测量，过程耗时且昂贵。

Method: 使用3AFC听力测试，将来自三个空间的RIR与语音、管弦乐和器乐进行卷积，参与者需要从一个人工推断和两个真实刺激中识别出人工刺激。

Result: 20名参与者的总体准确率为38%，仅比33%的猜测率高5个百分点，表明推断的RIR与真实RIR难以区分。

Conclusion: 从单声道测量推断可信的空间RIR是可行的，可以减少声学测量所需的时间和专业设备。

Abstract: Immersion in virtual and augmented reality solutions is reliant on plausible
spatial audio. However, plausibly representing a space for immersive audio
often requires many individual acoustic measurements of source-microphone pairs
with specialist spatial microphones, making the procedure time-consuming and
expensive. In this study, we evaluate the plausibility of extrapolated and
spatialised Room Impulse Responses (RIRs) by using a 3-Alternative Forced
Choice (3AFC) listening test. The stimuli comprised of RIRs from three spaces
convolved with speech, orchestral, and instrumental music. When asked to select
which stimuli was artificial out of one extrapolated and two real stimuli, an
overall accuracy of 38% was achieved from 20 participants (5 percentage points
above the expected guessing rate). Given the listening test result, this study
shows that it is possible to extrapolate plausible spatial RIRs from mono
measurements, decreasing the need for time and specialist equipment in acoustic
measurements.

</details>


### [42] [MuFFIN: Multifaceted Pronunciation Feedback Model with Interactive Hierarchical Neural Modeling](https://arxiv.org/abs/2510.04956)
*Bi-Cheng Yan,Ming-Kang Tsai,Berlin Chen*

Main category: eess.AS

TL;DR: MuFFIN模型通过交互式分层神经网络架构，联合处理发音错误检测与诊断(MDD)和自动发音评估(APA)任务，采用音素对比有序正则化和音素特定扰动训练目标，在Speechocean762数据集上实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 现有CAPT方法通常将MDD和APA作为独立任务处理，忽略了它们之间的互补性，需要统一框架来提供多维度发音反馈。

Method: 提出MuFFIN模型：1)交互式分层神经网络联合处理MDD和APA；2)音素对比有序正则化机制增强音素区分性；3)音素特定扰动训练目标解决数据不平衡问题。

Result: 在Speechocean762基准数据集上的实验表明，该方法在APA和MDD任务上均优于多个前沿基线模型，达到最先进性能。

Conclusion: MuFFIN模型成功统一了MDD和APA任务，通过多维度反馈机制有效提升了计算机辅助发音训练的效果。

Abstract: Computer-assisted pronunciation training (CAPT) manages to facilitate
second-language (L2) learners to practice pronunciation skills by offering
timely and instructive feedback. To examine pronunciation proficiency from
multiple facets, existing methods for CAPT broadly fall into two categories:
mispronunciation detection and diagnosis (MDD) as well as automatic
pronunciation assessment (APA). The former aims to pinpoint phonetic
pronunciation errors and provide diagnostic feedback, while the latter seeks
instead to quantify pronunciation proficiency pertaining to various aspects.
Despite the natural complementarity between MDD and APA, researchers and
practitioners, however, often treat them as independent tasks with disparate
modeling paradigms. In light of this, we in this paper first introduce MuFFIN,
a Multi-Faceted pronunciation Feedback model with an Interactive hierarchical
Neural architecture, to jointly address the tasks of MDD and APA. To better
capture the nuanced distinctions between phonemes in the feature space, a novel
phoneme-contrastive ordinal regularization mechanism is then put forward to
optimize the proposed model to generate more phoneme-discriminative features
while factoring in the ordinality of the aspect scores. In addition, to address
the intricate data imbalance problem in MDD, we design a simple yet effective
training objective, which is specifically tailored to perturb the outputs of a
phoneme classifier with the phoneme-specific variations, so as to better render
the distribution of predicted phonemes meanwhile considering their
mispronunciation characteristics. A series of experiments conducted on the
Speechocean762 benchmark dataset demonstrates the efficacy of our method in
relation to several cutting-edge baselines, showing state-of-the-art
performance on both the APA and MDD tasks.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [43] [Linguistic and Audio Embedding-Based Machine Learning for Alzheimer's Dementia and Mild Cognitive Impairment Detection: Insights from the PROCESS Challenge](https://arxiv.org/abs/2510.03336)
*Adharsha Sam Edwin Sam Devahi,Sohail Singh Sangha,Prachee Priyadarshinee,Jithin Thilakan,Ivan Fu Xing Tan,Christopher Johann Clarke,Sou Ka Lon,Balamurali B T,Yow Wei Quin,Chen Jer-Ming*

Main category: cs.SD

TL;DR: 提出基于语音的机器学习框架，结合音频嵌入和语言特征来检测阿尔茨海默病和轻度认知障碍，在PROCESS挑战中取得良好表现。


<details>
  <summary>Details</summary>
Motivation: 当前阿尔茨海默病和轻度认知障碍的诊断方法资源密集且具有侵入性，而语音作为非侵入性生物标志物具有巨大潜力。

Method: 使用Whisper嵌入提取音频特征，从语音转录中提取语言特征（代词使用、句法复杂性、填充词等），构建分类和回归模型区分健康对照、MCI和AD患者。

Result: 基于语言特征的投票集成模型在分类任务中表现最佳（F1=0.497），基于Whisper嵌入的集成回归器在MMSE预测中误差最低（RMSE=2.843）。

Conclusion: 多模态语音方法在认知评估中具有潜力，整合任务特定的语言和声学标记对痴呆检测很重要。

Abstract: Early detection of Alzheimer's Dementia (AD) and Mild Cognitive Impairment
(MCI) is critical for timely intervention, yet current diagnostic approaches
remain resource-intensive and invasive. Speech, encompassing both acoustic and
linguistic dimensions, offers a promising non-invasive biomarker for cognitive
decline. In this study, we present a machine learning framework for the PROCESS
Challenge, leveraging both audio embeddings and linguistic features derived
from spontaneous speech recordings. Audio representations were extracted using
Whisper embeddings from the Cookie Theft description task, while linguistic
features-spanning pronoun usage, syntactic complexity, filler words, and clause
structure-were obtained from transcriptions across Semantic Fluency, Phonemic
Fluency, and Cookie Theft picture description. Classification models aimed to
distinguish between Healthy Controls (HC), MCI, and AD participants, while
regression models predicted Mini-Mental State Examination (MMSE) scores.
Results demonstrated that voted ensemble models trained on concatenated
linguistic features achieved the best classification performance (F1 = 0.497),
while Whisper embedding-based ensemble regressors yielded the lowest MMSE
prediction error (RMSE = 2.843). Comparative evaluation within the PROCESS
Challenge placed our models among the top submissions in regression task, and
mid-range for classification, highlighting the complementary strengths of
linguistic and audio embeddings. These findings reinforce the potential of
multimodal speech-based approaches for scalable, non-invasive cognitive
assessment and underline the importance of integrating task-specific linguistic
and acoustic markers in dementia detection.

</details>


### [44] [Audio Forensics Evaluation (SAFE) Challenge](https://arxiv.org/abs/2510.03387)
*Kirill Trapeznikov,Paul Cummer,Pranay Pherwani,Jai Aslam,Michael S. Davinroy,Peter Bautista,Laura Cassani,Matthew Stamm,Jill Crisman*

Main category: cs.SD

TL;DR: SAFE挑战赛是一个完全盲测的评估框架，用于在原始合成语音、处理后音频和经过清洗的音频等不同难度场景下，对检测模型进行基准测试。


<details>
  <summary>Details</summary>
Motivation: 随着TTS模型生成的合成语音越来越逼真，加上后处理和清洗技术的应用，给音频取证检测带来了巨大挑战。

Method: 设计了包含90小时音频、21,000个样本的盲测数据集，涵盖21个真实来源和17个TTS模型，设置了3个不同任务。

Result: 提供了对当前方法优势和局限性的初步见解，为推进合成音频检测研究奠定了基础。

Conclusion: SAFE挑战赛为合成音频检测领域提供了一个标准化的评估框架，有助于推动该领域的发展。

Abstract: The increasing realism of synthetic speech generated by advanced
text-to-speech (TTS) models, coupled with post-processing and laundering
techniques, presents a significant challenge for audio forensic detection. In
this paper, we introduce the SAFE (Synthetic Audio Forensics Evaluation)
Challenge, a fully blind evaluation framework designed to benchmark detection
models across progressively harder scenarios: raw synthetic speech, processed
audio (e.g., compression, resampling), and laundered audio intended to evade
forensic analysis. The SAFE challenge consisted of a total of 90 hours of audio
and 21,000 audio samples split across 21 different real sources and 17
different TTS models and 3 tasks. We present the challenge, evaluation design
and tasks, dataset details, and initial insights into the strengths and
limitations of current approaches, offering a foundation for advancing
synthetic audio detection research. More information is available at
\href{https://stresearch.github.io/SAFE/}{https://stresearch.github.io/SAFE/}.

</details>


### [45] [Lightweight and Generalizable Acoustic Scene Representations via Contrastive Fine-Tuning and Distillation](https://arxiv.org/abs/2510.03728)
*Kuang Yuan,Yang Gao,Xilin Li,Xinhao Mei,Syavosh Zadissa,Tarun Pruthi,Saeed Bagheri Sereshki*

Main category: cs.SD

TL;DR: 提出ContrastASC方法，通过对比学习构建结构化的声学场景嵌入空间，使边缘设备上的声学场景分类模型能够适应新类别而无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的声学场景分类模型通常基于固定类别假设，缺乏现实应用中适应新类别或细化类别所需的迁移能力。

Method: 结合监督对比微调预训练模型和对比表示蒸馏，将结构化知识转移到紧凑的学生模型中。

Result: ContrastASC在未见类别上表现出改进的少样本适应能力，同时保持强大的闭集性能。

Conclusion: 该方法通过构建保留场景间语义关系的嵌入空间，实现了对新声学类别的有效适应。

Abstract: Acoustic scene classification (ASC) models on edge devices typically operate
under fixed class assumptions, lacking the transferability needed for
real-world applications that require adaptation to new or refined acoustic
categories. We propose ContrastASC, which learns generalizable acoustic scene
representations by structuring the embedding space to preserve semantic
relationships between scenes, enabling adaptation to unseen categories without
retraining. Our approach combines supervised contrastive fine-tuning of
pre-trained models with contrastive representation distillation to transfer
this structured knowledge to compact student models. Our evaluation shows that
ContrastASC demonstrates improved few-shot adaptation to unseen categories
while maintaining strong closed-set performance.

</details>


### [46] [Soft Disentanglement in Frequency Bands for Neural Audio Codecs](https://arxiv.org/abs/2510.03735)
*Benoit Ginies,Xiaoyu Bie,Olivier Fercoq,Gaël Richard*

Main category: cs.SD

TL;DR: 提出了一种通过谱分解和多分支音频编解码器学习解耦音频特征的新方法，在重建和感知性能上优于现有基线


<details>
  <summary>Details</summary>
Motivation: 现有解耦方法通常依赖于数据特性或特定任务的假设，需要一种更通用的方法来学习解耦的音频特征表示

Method: 使用时域信号的谱分解，然后采用多分支音频编解码器对分解后的组件进行处理

Result: 经验评估显示该方法在重建和感知性能上优于最先进的基线方法，并且在修复任务中具有潜在优势

Conclusion: 该方法提供了一种通用且有效的音频特征解耦学习框架，在多个任务中表现出色

Abstract: In neural-based audio feature extraction, ensuring that representations
capture disentangled information is crucial for model interpretability.
However, existing disentanglement methods often rely on assumptions that are
highly dependent on data characteristics or specific tasks. In this work, we
introduce a generalizable approach for learning disentangled features within a
neural architecture. Our method applies spectral decomposition to time-domain
signals, followed by a multi-branch audio codec that operates on the decomposed
components. Empirical evaluations demonstrate that our approach achieves better
reconstruction and perceptual performance compared to a state-of-the-art
baseline while also offering potential advantages for inpainting tasks.

</details>


### [47] [Désentrelacement Fréquentiel Doux pour les Codecs Audio Neuronaux](https://arxiv.org/abs/2510.03741)
*Benoît Giniès,Xiaoyu Bie,Olivier Fercoq,Gaël Richard*

Main category: cs.SD

TL;DR: 提出了一种基于频谱分解的分离式神经音频编解码器，通过时域信号的频谱分解来增强表示的可解释性，在重建保真度和感知质量方面优于现有基准方法。


<details>
  <summary>Details</summary>
Motivation: 虽然基于神经网络的模型在音频特征提取方面取得了显著进展，但学习到的表示的可解释性仍然是一个关键挑战。现有的分离技术通常对特定数据集或任务形式有强依赖性。

Method: 利用时域信号的频谱分解来构建分离式神经音频编解码器，通过频谱分解增强表示的结构性和可解释性。

Result: 实验评估表明，该方法在重建保真度和感知质量方面都超越了最先进的基准方法。

Conclusion: 提出的基于频谱分解的分离式神经音频编解码器能够有效提升音频表示的可解释性，同时在性能上优于现有方法。

Abstract: While neural-based models have led to significant advancements in audio
feature extraction, the interpretability of the learned representations remains
a critical challenge. To address this, disentanglement techniques have been
integrated into discrete neural audio codecs to impose structure on the
extracted tokens. However, these approaches often exhibit strong dependencies
on specific datasets or task formulations. In this work, we propose a
disentangled neural audio codec that leverages spectral decomposition of
time-domain signals to enhance representation interpretability. Experimental
evaluations demonstrate that our method surpasses a state-of-the-art baseline
in both reconstruction fidelity and perceptual quality.

</details>


### [48] [GDiffuSE: Diffusion-based speech enhancement with noise model guidance](https://arxiv.org/abs/2510.04157)
*Efrayim Yanir,David Burshtein,Sharon Gannot*

Main category: cs.SD

TL;DR: 提出基于去噪扩散概率模型(DDPM)的语音增强方法GDiffuSE，通过轻量级辅助模型估计噪声分布并指导扩散去噪过程，在噪声类型不匹配情况下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统语音增强方法直接将带噪语音映射到干净语音，缺乏对未知噪声类型的鲁棒性。本文旨在利用扩散模型的生成能力，通过噪声估计指导机制提高语音增强的泛化性能。

Method: 使用轻量级辅助模型估计噪声分布，将其作为指导机制融入扩散去噪过程。该方法能够利用为语音生成训练的大规模DDPM模型，实现向语音增强任务的迁移。

Result: 在LibriSpeech语料添加BBC音效库噪声的测试集上，GDiffuSE在不匹配噪声条件下相比最先进基线方法取得了一致的性能提升。

Conclusion: GDiffuSE通过噪声分布估计和指导机制，有效提高了扩散模型在语音增强任务中的鲁棒性和泛化能力，特别是在处理未知噪声类型时表现优异。

Abstract: This paper introduces a novel speech enhancement (SE) approach based on a
denoising diffusion probabilistic model (DDPM), termed Guided diffusion for
speech enhancement (GDiffuSE). In contrast to conventional methods that
directly map noisy speech to clean speech, our method employs a lightweight
helper model to estimate the noise distribution, which is then incorporated
into the diffusion denoising process via a guidance mechanism. This design
improves robustness by enabling seamless adaptation to unseen noise types and
by leveraging large-scale DDPMs originally trained for speech generation in the
context of SE. We evaluate our approach on noisy signals obtained by adding
noise samples from the BBC sound effects database to LibriSpeech utterances,
showing consistent improvements over state-of-the-art baselines under
mismatched noise conditions. Examples are available at our project webpage.

</details>


### [49] [Machine Unlearning in Speech Emotion Recognition via Forget Set Alone](https://arxiv.org/abs/2510.04251)
*Zhao Ren,Rathi Adarshi Rammohan,Kevin Scheck,Tanja Schultz*

Main category: cs.SD

TL;DR: 提出了一种基于对抗攻击的语音情感识别模型遗忘方法，仅使用待遗忘数据就能有效移除模型中的相关知识，同时保持模型性能。


<details>
  <summary>Details</summary>
Motivation: 语音数据包含丰富敏感信息，用户可能因隐私问题要求删除部分数据。现有机器遗忘方法依赖待遗忘样本之外的数据，这在数据重分发受限和大数据场景下面临挑战。

Method: 使用对抗攻击方法，仅基于待遗忘数据对预训练的语音情感识别模型进行微调，实现知识遗忘。

Result: 实验结果表明，该方法能有效移除待遗忘数据的知识，同时在情感识别测试集上保持较高的模型性能。

Conclusion: 提出的对抗攻击方法为语音情感识别中的隐私保护提供了一种有效的机器遗忘解决方案。

Abstract: Speech emotion recognition aims to identify emotional states from speech
signals and has been widely applied in human-computer interaction, education,
healthcare, and many other fields. However, since speech data contain rich
sensitive information, partial data can be required to be deleted by speakers
due to privacy concerns. Current machine unlearning approaches largely depend
on data beyond the samples to be forgotten. However, this reliance poses
challenges when data redistribution is restricted and demands substantial
computational resources in the context of big data. We propose a novel
adversarial-attack-based approach that fine-tunes a pre-trained speech emotion
recognition model using only the data to be forgotten. The experimental results
demonstrate that the proposed approach can effectively remove the knowledge of
the data to be forgotten from the model, while preserving high model
performance on the test set for emotion recognition.

</details>


### [50] [Pitch-Conditioned Instrument Sound Synthesis From an Interactive Timbre Latent Space](https://arxiv.org/abs/2510.04339)
*Christian Limberg,Fares Schulz,Zhe Zhang,Stefan Weinzierl*

Main category: cs.SD

TL;DR: 提出了一种用于神经乐器声音合成的两阶段半监督学习框架，通过解耦的音高-音色2D潜在空间生成音高准确、高质量的音乐样本。


<details>
  <summary>Details</summary>
Motivation: 现有方法虽然能产生足够质量的音乐样本，但依赖高维潜在表示，难以导航且用户体验不直观。

Method: 两阶段训练范式：首先使用变分自编码器训练音高-音色解耦的2D音频表示，然后将该表示作为基于Transformer的生成模型的调节输入。

Result: 实验结果表明，该方法能有效学习解耦的音色空间，在保持高音高准确度的同时捕捉音色的细微变化。

Conclusion: 该方法提供了一个直观的声音导航界面，展示了作为未来直观且富有创造力的音乐制作环境的潜力。

Abstract: This paper presents a novel approach to neural instrument sound synthesis
using a two-stage semi-supervised learning framework capable of generating
pitch-accurate, high-quality music samples from an expressive timbre latent
space. Existing approaches that achieve sufficient quality for music production
often rely on high-dimensional latent representations that are difficult to
navigate and provide unintuitive user experiences. We address this limitation
through a two-stage training paradigm: first, we train a pitch-timbre
disentangled 2D representation of audio samples using a Variational
Autoencoder; second, we use this representation as conditioning input for a
Transformer-based generative model. The learned 2D latent space serves as an
intuitive interface for navigating and exploring the sound landscape. We
demonstrate that the proposed method effectively learns a disentangled timbre
space, enabling expressive and controllable audio generation with reliable
pitch conditioning. Experimental results show the model's ability to capture
subtle variations in timbre while maintaining a high degree of pitch accuracy.
The usability of our method is demonstrated in an interactive web application,
highlighting its potential as a step towards future music production
environments that are both intuitive and creatively empowering:
https://pgesam.faresschulz.com

</details>


### [51] [Evaluating Self-Supervised Speech Models via Text-Based LLMS](https://arxiv.org/abs/2510.04463)
*Takashi Maekaku,Keita Goto,Jinchuan Tian,Yusuke Shinohara,Shinji Watanabe*

Main category: cs.SD

TL;DR: 提出了一种使用大型语言模型评估自监督学习模型性能的新方法，无需额外训练或超参数调优，通过输入离散标记序列和领域线索获得平均对数似然分数。


<details>
  <summary>Details</summary>
Motivation: 自监督学习虽然能降低标注成本，但评估其在下游任务中的性能仍然困难且成本高昂，现有方法也需要额外训练或超参数调优。

Method: 将自监督学习模型生成的离散标记序列和最小领域线索输入大型语言模型，获得平均对数似然作为评估分数，利用上下文学习提高可靠性。

Result: 实验结果显示LLM评分与自动语音识别任务性能相关，且LLM还能为说话人验证任务提供有用的推理时嵌入。

Conclusion: 大型语言模型不仅能作为自监督学习的评估工具，还能提供有用的推理时嵌入，为下游任务带来额外价值。

Abstract: Self-Supervised Learning (SSL) has gained traction for its ability to learn
rich representations with low labeling costs, applicable across diverse
downstream tasks. However, assessing the downstream-task performance remains
challenging due to the cost of extra training and evaluation. Existing methods
for task-agnostic evaluation also require extra training or hyperparameter
tuning. We propose a novel evaluation metric using large language models
(LLMs). By inputting discrete token sequences and minimal domain cues derived
from SSL models into LLMs, we obtain the mean log-likelihood; these cues guide
in-context learning, rendering the score more reliable without extra training
or hyperparameter tuning. Experimental results show a correlation between
LLM-based scores and automatic speech recognition task. Additionally, our
findings reveal that LLMs not only functions as an SSL evaluation tools but
also provides inference-time embeddings that are useful for speaker
verification task.

</details>


### [52] [Language Model Based Text-to-Audio Generation: Anti-Causally Aligned Collaborative Residual Transformers](https://arxiv.org/abs/2510.04577)
*Juncheng Wang,Chao Xu,Cheng Yu,Zhe Hu,Haoyu Xie,Guoqi Yu,Lei Shang,Shujun Wang*

Main category: cs.SD

TL;DR: Siren是一个基于语言模型的文本到音频生成框架，通过多个隔离的Transformer和因果条件化机制，解决了残差向量量化(RVQ)在音频生成中的限制，超越了现有基于语言模型和扩散模型的系统。


<details>
  <summary>Details</summary>
Motivation: 当前基于语言模型和残差向量量化的文本到音频生成系统在音频重建保真度方面仍落后于扩散模型，主要原因是RVQ层数增加会超出传统语言模型的生成能力。

Method: 分析RVQ动态发现两个关键限制：跨层特征正交性和深层RVQ层语义丰富度下降。提出Siren框架，使用多个隔离的Transformer，通过因果条件化和基于强化学习的反因果对齐来解决这些问题。

Result: 大量实验表明，Siren在文本到音频生成任务中超越了现有的基于语言模型和扩散模型的系统，取得了最先进的结果。

Conclusion: 通过将语言模型的表示优势与音频合成的保真度需求相结合，Siren重新定位了语言模型在文本到音频任务中作为扩散模型竞争者的地位，并为统一多模态生成框架提供了有前景的途径。

Abstract: While language models (LMs) paired with residual vector quantization (RVQ)
tokenizers have shown promise in text-to-audio (T2A) generation, they still lag
behind diffusion-based models by a non-trivial margin. We identify a critical
dilemma underpinning this gap: incorporating more RVQ layers improves audio
reconstruction fidelity but exceeds the generation capacity of conventional
LMs. To address this, we first analyze RVQ dynamics and uncover two key
limitations: 1) orthogonality of features across RVQ layers hinders effective
LMs training, and 2) descending semantic richness in tokens from deeper RVQ
layers exacerbates exposure bias during autoregressive decoding. Based on these
insights, we propose Siren, a novel LM-based framework that employs multiple
isolated transformers with causal conditioning and anti-causal alignment via
reinforcement learning. Extensive experiments demonstrate that Siren
outperforms both existing LM-based and diffusion-based T2A systems, achieving
state-of-the-art results. By bridging the representational strengths of LMs
with the fidelity demands of audio synthesis, our approach repositions LMs as
competitive contenders against diffusion models in T2A tasks. Moreover, by
aligning audio representations with linguistic structures, Siren facilitates a
promising pathway toward unified multi-modal generation frameworks.

</details>


### [53] [A Study on the Data Distribution Gap in Music Emotion Recognition](https://arxiv.org/abs/2510.04688)
*Joann Ching,Gerhard Widmer*

Main category: cs.SD

TL;DR: 该论文研究了音乐情感识别中的跨数据集泛化问题，通过分析五个不同音乐风格的数据集，提出结合Jukebox模型嵌入和chroma特征的简单有效框架，显著提升了模型的跨数据集泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有音乐情感识别研究往往局限于特定音乐风格，缺乏对多样化音乐流派（如摇滚和古典）的统一处理框架，且存在数据集偏差和风格主导问题。

Method: 系统分析了五个具有维度情感标注的数据集，研究了多种数据和特征集，提出了结合Jukebox模型嵌入与chroma特征的框架，并采用多个多样化训练集进行模型训练。

Result: 实验揭示了现有数据中的风格-情感关系、潜在风格主导和数据集偏差问题，提出的框架显著提升了模型的跨数据集泛化性能。

Conclusion: 通过结合Jukebox嵌入和chroma特征，并使用多样化训练集，可以构建具有更好跨数据集泛化能力的音乐情感识别模型。

Abstract: Music Emotion Recognition (MER) is a task deeply connected to human
perception, relying heavily on subjective annotations collected from
contributors. Prior studies tend to focus on specific musical styles rather
than incorporating a diverse range of genres, such as rock and classical,
within a single framework. In this paper, we address the task of recognizing
emotion from audio content by investigating five datasets with dimensional
emotion annotations -- EmoMusic, DEAM, PMEmo, WTC, and WCMED -- which span
various musical styles. We demonstrate the problem of out-of-distribution
generalization in a systematic experiment. By closely looking at multiple data
and feature sets, we provide insight into genre-emotion relationships in
existing data and examine potential genre dominance and dataset biases in
certain feature representations. Based on these experiments, we arrive at a
simple yet effective framework that combines embeddings extracted from the
Jukebox model with chroma features and demonstrate how, alongside a combination
of several diverse training sets, this permits us to train models with
substantially improved cross-dataset generalization capabilities.

</details>


### [54] [Speak, Edit, Repeat: High-Fidelity Voice Editing and Zero-Shot TTS with Cross-Attentive Mamba](https://arxiv.org/abs/2510.04738)
*Baher Mohammad,Magauiya Zhussip,Stamatios Lefkimmiatis*

Main category: cs.SD

TL;DR: MAVE是一种基于交叉注意力Mamba架构的自回归语音编辑和合成模型，在语音编辑任务上达到SOTA性能，在零样本TTS上表现优异，同时大幅降低内存需求。


<details>
  <summary>Details</summary>
Motivation: 为了解决语音编辑和合成任务中高保真度、自然度和计算效率的问题，结合Mamba的高效序列建模能力和交叉注意力的精确文本-声学对齐能力。

Method: 采用交叉注意力Mamba架构，集成Mamba进行高效音频序列建模，使用交叉注意力实现精确的文本-声学对齐，支持上下文感知的语音编辑。

Result: 在RealEdit基准测试中，57.2%的听众认为MAVE编辑的语音与原音感知上无差异；在零样本TTS中，MAVE在说话人相似度和自然度上均超过VoiceCraft；内存需求比VoiceCraft减少约6倍。

Conclusion: MAVE通过结构化状态空间建模和跨模态注意力的协同整合，为灵活、高保真度的语音编辑和合成设立了新标准。

Abstract: We introduce MAVE (Mamba with Cross-Attention for Voice Editing and
Synthesis), a novel autoregressive architecture for text-conditioned voice
editing and high-fidelity text-to-speech (TTS) synthesis, built on a
cross-attentive Mamba backbone. MAVE achieves state-of-the-art performance in
speech editing and very competitive results in zero-shot TTS, while not being
explicitly trained on the latter task, outperforming leading autoregressive and
diffusion models on diverse, real-world audio. By integrating Mamba for
efficient audio sequence modeling with cross-attention for precise
text-acoustic alignment, MAVE enables context-aware voice editing with
exceptional naturalness and speaker consistency. In pairwise human evaluations
on a random 40-sample subset of the RealEdit benchmark (400 judgments), 57.2%
of listeners rated MAVE - edited speech as perceptually equal to the original,
while 24.8% prefered the original and 18.0% MAVE - demonstrating that in the
majority of cases edits are indistinguishable from the source. MAVE compares
favorably with VoiceCraft and FluentSpeech both on pairwise comparisons and
standalone mean opinion score (MOS) evaluations. For zero-shot TTS, MAVE
exceeds VoiceCraft in both speaker similarity and naturalness, without
requiring multiple inference runs or post-processing. Remarkably, these quality
gains come with a significantly lower memory cost and approximately the same
latency: MAVE requires ~6x less memory than VoiceCraft during inference on
utterances from the RealEdit database (mean duration: 6.21s, A100, FP16, batch
size 1). Our results demonstrate that MAVE establishes a new standard for
flexible, high-fidelity voice editing and synthesis through the synergistic
integration of structured state-space modeling and cross-modal attention.

</details>

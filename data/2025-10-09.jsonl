{"id": "2510.06429", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.06429", "abs": "https://arxiv.org/abs/2510.06429", "authors": ["Linlin Mao", "Zeping Sui", "Michail Matthaiou", "Hongbin Li"], "title": "Distributed Detection and Bandwidth Allocation with Hybrid Quantized and Full-Precision Observations over Multiplicative Fading Channels", "comment": "6 pages, 4 figures, submitted to IEEE TVT", "summary": "A hybrid detector that fuses both quantized and full-precision observations\nis proposed for weak signal detection under additive and multiplicative\nGaussian noise. We first derive a locally most powerful test (LMPT)--based\nhybrid detector from the composite probability distribution of the compound\nobservations received by the fusion center, and then analyze its asymptotic\ndetection performance. Subsequently, we optimize the sensor-wise quantization\nthresholds to achieve near-optimal asymptotic performance at the local sensor\nlevel. Moreover, we propose a mixed-integer linear programming approach to\nsolve the optimization problem of transmission bandwidth allocation accounting\nfor bandwidth constraints and error-prone channels. Finally, simulation results\ndemonstrate the superiority of the proposed hybrid detector and the bandwidth\nallocation strategy, especially in challenging error-prone channel conditions."}
{"id": "2510.06476", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.06476", "abs": "https://arxiv.org/abs/2510.06476", "authors": ["Nishant Gadde", "Yoshua Alexander", "Sarvesh Parthasarthy", "Arman Allidina"], "title": "Optimized SVR Framework for Electric Load Forecasting", "comment": "10 pages, 11 figures", "summary": "Load forecasting has always been a challenge for grid operators due to the\ngrowing complexity of power systems. The increase in extreme weather and the\nneed for energy from customers has led to load forecasting sometimes failing.\nThis research presents a Support Vector Regression (SVR) framework for electric\nload forecasting that outperforms the industry standard. The SVR model\ndemonstrates better accuracy across all evaluation metrics that are important\nfor power system operations. The model has a 54.2\\% reduction in Mean Squared\nError (31.91 vs. 69.63), a 33.5\\% improvement in Mean Absolute Error, and\nperformance benefits across other metrics. These improvements show significant\nbenefits when integrated with power forecasting tools and show that the\napproach provides an additional tool for accuracy checking for system planning\nand resource allocation in times of need for resource allocation in electric\npower systems."}
{"id": "2510.06654", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.06654", "abs": "https://arxiv.org/abs/2510.06654", "authors": ["Yan Yang", "Zhendong Li", "Jianwei Zhao", "Qingqing Wu", "Zhiqing Wei", "Wen Chen", "Weimin Jia"], "title": "Cooperative Multi-Static ISAC Networks: A Unified Design Framework for Active and Passive Sensing", "comment": "13 pages, 12 figures", "summary": "Multi-static cooperative sensing emerges as a promising technology for\nadvancing integrated sensing and communication (ISAC), enhancing sensing\naccuracy and range. In this paper, we develop a unified design framework for\njoint active and passive sensing (JAPS). In particular, we consider a JAPSbased\ncooperative multi-static ISAC system for coexisting downlink (DL) and uplink\n(UL) communications. An optimization problem is formulated for maximizing the\nsum rate of both the DL and UL transmissions via jointly optimizing\nbeamforming, receive filters and power allocation, while guaranteeing the\nsensing requirements and transmission power constraints. However, the\nformulated problem is a non-convex optimization problem that is challenging to\nsolve directly due to the tight coupling among optimization variables. To\ntackle this complicated issue, we employ an efficient algorithm architecture\nleveraging alternating optimization (AO). Specifically, with the given receive\nfilters and transmission power for UL communication, the transmit beamforming\nsubproblem is addressed by successive convex approximation (SCA)-based and\npenalty-based algorithms. A fractional programming (FP)-based algorithm is\ndeveloped to tackle the receive filters and transmission power for UL\ncommunication optimization subproblem. Extensive numerical results validate the\nperformance improvement of our proposed JAPS scheme and demonstrate the\neffectiveness of our proposed algorithms."}
{"id": "2510.06709", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.06709", "abs": "https://arxiv.org/abs/2510.06709", "authors": ["Zhou Ni", "Sravan Reddy Chintareddy", "Peiyuan Guan", "Morteza Hashemi"], "title": "Personalized Federated Learning-Driven Beamforming Optimization for Integrated Sensing and Communication Systems", "comment": "6 pages, 5 figures, accepted by IEEE Consumer Communications and\n  Networking Conference (CCNC) 2026", "summary": "In this paper, we propose an Expectation-Maximization-based (EM) Personalized\nFederated Learning (PFL) framework for multi-objective optimization (MOO) in\nIntegrated Sensing and Communication (ISAC) systems. In contrast to standard\nfederated learning (FL) methods that handle all clients uniformly, the proposed\napproach enables each base station (BS) to adaptively determine its aggregation\nweight with the EM algorithm. Specifically, an EM posterior is computed at each\nBS to quantify the relative suitability between the global and each local\nmodel, based on the losses of models on their respective datasets. The proposed\nmethod is especially valuable in scenarios with competing communication and\nsensing objectives, as it enables BSs to dynamically adapt to\napplication-specific trade-offs. To assess the effectiveness of the proposed\napproach, we conduct simulation studies under both objective-wise homogeneous\nand heterogeneous conditions. The results demonstrate that our approach\noutperforms existing PFL baselines, such as FedPer and pFedMe, achieving faster\nconvergence and better multi-objective performance."}
{"id": "2510.06785", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.06785", "abs": "https://arxiv.org/abs/2510.06785", "authors": ["Yun-Ning", "Hung", "Igor Pereira", "Filip Korzeniowski"], "title": "Moises-Light: Resource-efficient Band-split U-Net For Music Source Separation", "comment": null, "summary": "In recent years, significant advances have been made in music source\nseparation, with model architectures such as dual-path modeling, band-split\nmodules, or transformer layers achieving comparably good results. However,\nthese models often contain a significant number of parameters, posing\nchallenges to devices with limited computational resources in terms of training\nand practical application. While some lightweight models have been introduced,\nthey generally perform worse compared to their larger counterparts. In this\npaper, we take inspiration from these recent advances to improve a lightweight\nmodel. We demonstrate that with careful design, a lightweight model can achieve\ncomparable SDRs to models with up to 13 times more parameters. Our proposed\nmodel, Moises-Light, achieves competitive results in separating four musical\nstems on the MUSDB-HQ benchmark dataset. The proposed model also demonstrates\ncompetitive scalability when using MoisesDB as additional training data."}
{"id": "2510.06528", "categories": ["cs.SD", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.06528", "abs": "https://arxiv.org/abs/2510.06528", "authors": ["Mingyang Yao", "Ke Chen", "Shlomo Dubnov", "Taylor Berg-Kirkpatrick"], "title": "BACHI: Boundary-Aware Symbolic Chord Recognition Through Masked Iterative Decoding on Pop and Classical Music", "comment": "Under review", "summary": "Automatic chord recognition (ACR) via deep learning models has gradually\nachieved promising recognition accuracy, yet two key challenges remain. First,\nprior work has primarily focused on audio-domain ACR, while symbolic music\n(e.g., score) ACR has received limited attention due to data scarcity. Second,\nexisting methods still overlook strategies that are aligned with human music\nanalytical practices. To address these challenges, we make two contributions:\n(1) we introduce POP909-CL, an enhanced version of POP909 dataset with\ntempo-aligned content and human-corrected labels of chords, beats, keys, and\ntime signatures; and (2) We propose BACHI, a symbolic chord recognition model\nthat decomposes the task into different decision steps, namely boundary\ndetection and iterative ranking of chord root, quality, and bass (inversion).\nThis mechanism mirrors the human ear-training practices. Experiments\ndemonstrate that BACHI achieves state-of-the-art chord recognition performance\non both classical and pop music benchmarks, with ablation studies validating\nthe effectiveness of each module."}
{"id": "2510.06768", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.06768", "abs": "https://arxiv.org/abs/2510.06768", "authors": ["Di Zhang", "Yinglei Yang", "Zhilong Liu", "Shaobo Jia", "Kyungchun Lee", "Zhirong Zhang"], "title": "Low Complexity Weight Flexible Decoding Schemes of Linear Block Code for 6G xURLLC", "comment": null, "summary": "Low complexity error correction code is a key enabler for next generation\nultra-reliable low-latency communications (xURLLC) in six generation (6G).\nAgainst this background, this paper proposes a decoding scheme for linear block\ncode by leveraging certain interesting properties of dual codewords. It is\nfound that dual codewords with flexible weights can provide useful decoding\ninformation for the locations and magnitudes of error bits, which yielding\nhigher reliability performance. In addition, two decoding schemes are proposed,\nin which one directly utilizes intrinsic information for iterative decoding,\nand the other combines prior channel information with intrinsic information for\ndecoding. Both schemes are implemented using vector multiplication and\nreal-number comparisons, making them easy to implement in hardware. Simulation\nresults demonstrate the validness of our study."}
{"id": "2510.06927", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2510.06927", "abs": "https://arxiv.org/abs/2510.06927", "authors": ["Yifan Yang", "Hui Wang", "Bing Han", "Shujie Liu", "Jinyu Li", "Yong Qin", "Xie Chen"], "title": "Towards Responsible Evaluation for Text-to-Speech", "comment": null, "summary": "Recent advances in text-to-speech (TTS) technology have enabled systems to\nproduce human-indistinguishable speech, bringing benefits across accessibility,\ncontent creation, and human-computer interaction. However, current evaluation\npractices are increasingly inadequate for capturing the full range of\ncapabilities, limitations, and societal implications. This position paper\nintroduces the concept of Responsible Evaluation and argues that it is\nessential and urgent for the next phase of TTS development, structured through\nthree progressive levels: (1) ensuring the faithful and accurate reflection of\na model's true capabilities, with more robust, discriminative, and\ncomprehensive objective and subjective scoring methodologies; (2) enabling\ncomparability, standardization, and transferability through standardized\nbenchmarks, transparent reporting, and transferable evaluation metrics; and (3)\nassessing and mitigating ethical risks associated with forgery, misuse, privacy\nviolations, and security vulnerabilities. Through this concept, we critically\nexamine current evaluation practices, identify systemic shortcomings, and\npropose actionable recommendations. We hope this concept of Responsible\nEvaluation will foster more trustworthy and reliable TTS technology and guide\nits development toward ethically sound and societally beneficial applications."}
{"id": "2510.06544", "categories": ["cs.SD", "cs.CR", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.06544", "abs": "https://arxiv.org/abs/2510.06544", "authors": ["Xutao Mao", "Ke Li", "Cameron Baird", "Ezra Xuanru Tao", "Dan Lin"], "title": "Benchmarking Fake Voice Detection in the Fake Voice Generation Arms Race", "comment": null, "summary": "As advances in synthetic voice generation accelerate, an increasing variety\nof fake voice generators have emerged, producing audio that is often\nindistinguishable from real human speech. This evolution poses new and serious\nthreats across sectors where audio recordings serve as critical evidence.\nAlthough fake voice detectors are also advancing, the arms race between fake\nvoice generation and detection has become more intense and complex. In this\nwork, we present the first large-scale, cross-domain evaluation of fake voice\ndetectors, benchmarking 8 state-of-the-art models against datasets synthesized\nby 20 different fake voice generation systems. To the best of our knowledge,\nthis is the most comprehensive cross-domain assessment conducted to date. Our\nstudy reveals substantial security vulnerabilities in current fake voice\ndetection systems, underscoring critical gaps in their real-world robustness.\nTo advance the field, we propose a unified and effective metric that\nconsolidates the diverse and often inconsistent evaluation criteria previously\nused across different studies. This metric enables standardized,\nstraightforward comparisons of the robustness of fake voice detectors. We\nconclude by offering actionable recommendations for building more resilient\nfake voice detection technologies, with the broader goal of reinforcing the\nfoundations of AI security and trustworthiness."}
{"id": "2510.06861", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.06861", "abs": "https://arxiv.org/abs/2510.06861", "authors": ["Abidemi Orimogunje", "Kyeong-Ju Cha", "Hyunwoo Park", "Abdulahi A. Badrudeen", "Sunwoo Kim", "Dejan Vukobratovic"], "title": "Mobility-Aware Localization in mmWave Channel: Adaptive Hybrid Filtering Approach", "comment": "6 pages", "summary": "Precise user localization and tracking enhances energy-efficient and\nultra-reliable low latency applications in the next generation wireless\nnetworks. In addition to computational complexity and data association\nchallenges with Kalman-filter localization techniques, estimation errors tend\nto grow as the user's trajectory speed increases. By exploiting mmWave signals\nfor joint sensing and communication, our approach dispenses with additional\nsensors adopted in most techniques while retaining high resolution spatial\ncues. We present a hybrid mobility-aware adaptive framework that selects the\nExtended Kalman filter at pedestrian speed and the Unscented Kalman filter at\nvehicular speed. The scheme mitigates data-association problem and estimation\nerrors through adaptive noise scaling, chi-square gating, Rauch-Tung-Striebel\nsmoothing. Evaluations using Absolute Trajectory Error, Relative Pose Error,\nNormalized Estimated Error Squared and Root Mean Square Error metrics\ndemonstrate roughly 30-60% improvement in their respective regimes indicating a\nclear advantage over existing approaches tailored to either indoor or static\nsettings."}
{"id": "2510.07299", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.07299", "abs": "https://arxiv.org/abs/2510.07299", "authors": ["Peter Plantinga", "Roozbeh Sattari", "Karine Marcotte", "Carla Di Gironimo", "Madeleine Sharp", "Liziane Bouvier", "Maiya Geddes", "Ingrid Verduyckt", "Étienne de Villers-Sidani", "Mirco Ravanelli", "Denise Klein"], "title": "Comparison of Speech Tasks in Human Expert and Machine Detection of Parkinson's Disease", "comment": "Accepted to SMASH 2025", "summary": "The speech of people with Parkinson's Disease (PD) has been shown to hold\nimportant clues about the presence and progression of the disease. We\ninvestigate the factors based on which humans experts make judgments of the\npresence of disease in speech samples over five different speech tasks:\nphonations, sentence repetition, reading, recall, and picture description. We\nmake comparisons by conducting listening tests to determine clinicians accuracy\nat recognizing signs of PD from audio alone, and we conduct experiments with a\nmachine learning system for detection based on Whisper. Across tasks, Whisper\nperforms on par or better than human experts when only audio is available,\nespecially on challenging but important subgroups of the data: younger\npatients, mild cases, and female patients. Whisper's ability to recognize\nacoustic cues in difficult cases complements the multimodal and contextual\nstrengths of human experts."}
{"id": "2510.06625", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.06625", "abs": "https://arxiv.org/abs/2510.06625", "authors": ["Murat Yasar Baskin"], "title": "Pitch Estimation With Mean Averaging Smoothed Product Spectrum And Musical Consonance Evaluation Using MASP", "comment": null, "summary": "This study introduces Mean Averaging Smoothed Product (MASP) Spectrum, which\nis a modified version of the Harmonic Product Spectrum, designed to enhance\npitch estimation for many algorithm-wise deceptive frequency spectra that still\nlead clear pitches, for both harmonic and inharmonic cases. By introducing a\nglobal mean based smoothing for spectrum, the MASP algorithm diminishes the\nunwanted sensitivity of HPS for spectra with missing partials. The method\nexhibited robust pitch estimations consistent with perceptual expectations.\nMotivated upon the strong correlation between consonance and periodicity, the\nsame algorithm is extended and, with the proposition of a harmonicity measure\n(H), used to evaluate musical consonance for two and three tones; yielding\nconsonance hierarchies that align with perception and practice of music theory.\nThese findings suggest that perception of pitch and consonance may share a\nsimilar underlying mechanism that depend on spectrum."}
{"id": "2510.06884", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2510.06884", "abs": "https://arxiv.org/abs/2510.06884", "authors": ["Rahul Gulia", "Amlan Ganguly", "Michael E. Kuhl", "Ehsan Rashedi", "Clark Hochgraf"], "title": "Memory-Augmented Generative AI for Real-time Wireless Prediction in Dynamic Industrial Environments", "comment": null, "summary": "Accurate and real-time prediction of wireless channel conditions,\nparticularly the Signal-to-Interference-plus-Noise Ratio (SINR), is a\nfoundational requirement for enabling Ultra-Reliable Low-Latency Communication\n(URLLC) in highly dynamic Industry 4.0 environments. Traditional physics-based\nor statistical models fail to cope with the spatio-temporal complexities\nintroduced by mobile obstacles and transient interference inherent to smart\nwarehouses. To address this, we introduce Evo-WISVA (Evolutionary Wireless\nInfrastructure for Smart Warehouse using VAE), a novel synergistic deep\nlearning architecture that functions as a lightweight 2D predictive digital\ntwin of the radio environment. Evo-WISVA integrates a memory-augmented\nVariational Autoencoder (VAE) featuring an Attention-driven Latent Memory\nModule (LMM) for robust, context-aware spatial feature extraction, with a\nConvolutional Long Short-Term Memory (ConvLSTM) network for precise temporal\nforecasting and sequential refinement. The entire pipeline is optimized\nend-to-end via a joint loss function, ensuring optimal feature alignment\nbetween the generative and predictive components. Rigorous experimental\nevaluation conducted on a high-fidelity ns-3-generated industrial warehouse\ndataset demonstrates that Evo-WISVA significantly surpasses state-of-the-art\nbaselines, achieving up to a 47.6\\% reduction in average reconstruction error.\nCrucially, the model exhibits exceptional generalization capacity to unseen\nenvironments with vastly increased dynamic complexity (up to ten simultaneously\nmoving obstacles) while maintaining amortized computational efficiency\nessential for real-time deployment. Evo-WISVA establishes a foundational\ntechnology for proactive wireless resource management, enabling autonomous\noptimization and advancing the realization of predictive digital twins in\nindustrial communication networks."}
{"id": "2510.06528", "categories": ["cs.SD", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.06528", "abs": "https://arxiv.org/abs/2510.06528", "authors": ["Mingyang Yao", "Ke Chen", "Shlomo Dubnov", "Taylor Berg-Kirkpatrick"], "title": "BACHI: Boundary-Aware Symbolic Chord Recognition Through Masked Iterative Decoding on Pop and Classical Music", "comment": "Under review", "summary": "Automatic chord recognition (ACR) via deep learning models has gradually\nachieved promising recognition accuracy, yet two key challenges remain. First,\nprior work has primarily focused on audio-domain ACR, while symbolic music\n(e.g., score) ACR has received limited attention due to data scarcity. Second,\nexisting methods still overlook strategies that are aligned with human music\nanalytical practices. To address these challenges, we make two contributions:\n(1) we introduce POP909-CL, an enhanced version of POP909 dataset with\ntempo-aligned content and human-corrected labels of chords, beats, keys, and\ntime signatures; and (2) We propose BACHI, a symbolic chord recognition model\nthat decomposes the task into different decision steps, namely boundary\ndetection and iterative ranking of chord root, quality, and bass (inversion).\nThis mechanism mirrors the human ear-training practices. Experiments\ndemonstrate that BACHI achieves state-of-the-art chord recognition performance\non both classical and pop music benchmarks, with ablation studies validating\nthe effectiveness of each module."}
{"id": "2510.06706", "categories": ["cs.SD", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.06706", "abs": "https://arxiv.org/abs/2510.06706", "authors": ["Phuong Tuan Dat", "Tran Huy Dat"], "title": "XLSR-Kanformer: A KAN-Intergrated model for Synthetic Speech Detection", "comment": "Accepted to 2025 IEEE International Conference on Advanced Video and\n  Signal-Based Surveillance", "summary": "Recent advancements in speech synthesis technologies have led to increasingly\nsophisticated spoofing attacks, posing significant challenges for automatic\nspeaker verification systems. While systems based on self-supervised learning\n(SSL) models, particularly the XLSR-Conformer architecture, have demonstrated\nremarkable performance in synthetic speech detection, there remains room for\narchitectural improvements. In this paper, we propose a novel approach that\nreplaces the traditional Multi-Layer Perceptron (MLP) in the XLSR-Conformer\nmodel with a Kolmogorov-Arnold Network (KAN), a powerful universal approximator\nbased on the Kolmogorov-Arnold representation theorem. Our experimental results\non ASVspoof2021 demonstrate that the integration of KAN to XLSR-Conformer model\ncan improve the performance by 60.55% relatively in Equal Error Rate (EER) LA\nand DF sets, further achieving 0.70% EER on the 21LA set. Besides, the proposed\nreplacement is also robust to various SSL architectures. These findings suggest\nthat incorporating KAN into SSL-based models is a promising direction for\nadvances in synthetic speech detection."}
{"id": "2510.06936", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.06936", "abs": "https://arxiv.org/abs/2510.06936", "authors": ["Eren Berk Kama", "Murat Babek Salman", "Isaac Skog", "Emil Björnson"], "title": "Sensing Management for Pilot-Free Predictive Beamforming in Cell-Free Massive MIMO Systems", "comment": null, "summary": "This paper introduces a sensing management method for integrated sensing and\ncommunications (ISAC) in cell-free massive multiple-input multiple-output\n(MIMO) systems. Conventional communication systems employ channel estimation\nprocedures that impose significant overhead during data transmission, consuming\nresources that could otherwise be utilized for data. To address this challenge,\nwe propose a state-based approach that leverages sensing capabilities to track\nthe user when there is no communication request. Upon receiving a communication\nrequest, predictive beamforming is employed based on the tracked user position,\nthereby reducing the need for channel estimation. Our framework incorporates an\nextended Kalman filter (EKF) based tracking algorithm with adaptive sensing\nmanagement to perform sensing operations only when necessary to maintain high\ntracking accuracy. The simulation results demonstrate that our proposed sensing\nmanagement approach provides uniform downlink communication rates that are\nhigher than with existing methods by achieving overhead-free predictive\nbeamforming."}
{"id": "2510.06544", "categories": ["cs.SD", "cs.CR", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.06544", "abs": "https://arxiv.org/abs/2510.06544", "authors": ["Xutao Mao", "Ke Li", "Cameron Baird", "Ezra Xuanru Tao", "Dan Lin"], "title": "Benchmarking Fake Voice Detection in the Fake Voice Generation Arms Race", "comment": null, "summary": "As advances in synthetic voice generation accelerate, an increasing variety\nof fake voice generators have emerged, producing audio that is often\nindistinguishable from real human speech. This evolution poses new and serious\nthreats across sectors where audio recordings serve as critical evidence.\nAlthough fake voice detectors are also advancing, the arms race between fake\nvoice generation and detection has become more intense and complex. In this\nwork, we present the first large-scale, cross-domain evaluation of fake voice\ndetectors, benchmarking 8 state-of-the-art models against datasets synthesized\nby 20 different fake voice generation systems. To the best of our knowledge,\nthis is the most comprehensive cross-domain assessment conducted to date. Our\nstudy reveals substantial security vulnerabilities in current fake voice\ndetection systems, underscoring critical gaps in their real-world robustness.\nTo advance the field, we propose a unified and effective metric that\nconsolidates the diverse and often inconsistent evaluation criteria previously\nused across different studies. This metric enables standardized,\nstraightforward comparisons of the robustness of fake voice detectors. We\nconclude by offering actionable recommendations for building more resilient\nfake voice detection technologies, with the broader goal of reinforcing the\nfoundations of AI security and trustworthiness."}
{"id": "2510.07293", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.07293", "abs": "https://arxiv.org/abs/2510.07293", "authors": ["Peize He", "Zichen Wen", "Yubo Wang", "Yuxuan Wang", "Xiaoqian Liu", "Jiajie Huang", "Zehui Lei", "Zhuangcheng Gu", "Xiangqi Jin", "Jiabing Yang", "Kai Li", "Zhifei Liu", "Weijia Li", "Cunxiang Wang", "Conghui He", "Linfeng Zhang"], "title": "AudioMarathon: A Comprehensive Benchmark for Long-Context Audio Understanding and Efficiency in Audio LLMs", "comment": "26 pages, 23 figures, the code is available at\n  \\url{https://github.com/DabDans/AudioMarathon}", "summary": "Processing long-form audio is a major challenge for Large Audio Language\nmodels (LALMs). These models struggle with the quadratic cost of attention\n($O(N^2)$) and with modeling long-range temporal dependencies. Existing audio\nbenchmarks are built mostly from short clips and do not evaluate models in\nrealistic long context settings. To address this gap, we introduce\nAudioMarathon, a benchmark designed to evaluate both understanding and\ninference efficiency on long-form audio. AudioMarathon provides a diverse set\nof tasks built upon three pillars: long-context audio inputs with durations\nranging from 90.0 to 300.0 seconds, which correspond to encoded sequences of\n2,250 to 7,500 audio tokens, respectively, full domain coverage across speech,\nsound, and music, and complex reasoning that requires multi-hop inference. We\nevaluate state-of-the-art LALMs and observe clear performance drops as audio\nlength grows. We also study acceleration techniques and analyze the trade-offs\nof token pruning and KV cache eviction. The results show large gaps across\ncurrent LALMs and highlight the need for better temporal reasoning and\nmemory-efficient architectures. We believe AudioMarathon will drive the audio\nand multimodal research community to develop more advanced audio understanding\nmodels capable of solving complex audio tasks."}
{"id": "2510.06937", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.06937", "abs": "https://arxiv.org/abs/2510.06937", "authors": ["He Huang", "Zilong Liu", "Zeping Sui", "Wei Huang", "Md. Noor-A-Rahim", "Haishi Wang", "Zhiheng Hu"], "title": "Optimal Real-time Communication in 6G Ultra-Massive V2X Mobile Networks", "comment": "6 pages, 5 figures, accepted by IEEE VTC-fall 2025", "summary": "This paper introduces a novel cooperative vehicular communication algorithm\ntailored for future 6G ultra-massive vehicle-to-everything (V2X) networks\nleveraging integrated space-air-ground communication systems. Specifically, we\naddress the challenge of real-time information exchange among rapidly moving\nvehicles. We demonstrate the existence of an upper bound on channel capacity\ngiven a fixed number of relays, and propose a low-complexity relay selection\nheuristic algorithm. Simulation results verify that our proposed algorithm\nachieves superior channel capacities compared to existing cooperative vehicular\ncommunication approaches."}
{"id": "2510.06625", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.06625", "abs": "https://arxiv.org/abs/2510.06625", "authors": ["Murat Yasar Baskin"], "title": "Pitch Estimation With Mean Averaging Smoothed Product Spectrum And Musical Consonance Evaluation Using MASP", "comment": null, "summary": "This study introduces Mean Averaging Smoothed Product (MASP) Spectrum, which\nis a modified version of the Harmonic Product Spectrum, designed to enhance\npitch estimation for many algorithm-wise deceptive frequency spectra that still\nlead clear pitches, for both harmonic and inharmonic cases. By introducing a\nglobal mean based smoothing for spectrum, the MASP algorithm diminishes the\nunwanted sensitivity of HPS for spectra with missing partials. The method\nexhibited robust pitch estimations consistent with perceptual expectations.\nMotivated upon the strong correlation between consonance and periodicity, the\nsame algorithm is extended and, with the proposition of a harmonicity measure\n(H), used to evaluate musical consonance for two and three tones; yielding\nconsonance hierarchies that align with perception and practice of music theory.\nThese findings suggest that perception of pitch and consonance may share a\nsimilar underlying mechanism that depend on spectrum."}
{"id": "2510.06785", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.06785", "abs": "https://arxiv.org/abs/2510.06785", "authors": ["Yun-Ning", "Hung", "Igor Pereira", "Filip Korzeniowski"], "title": "Moises-Light: Resource-efficient Band-split U-Net For Music Source Separation", "comment": null, "summary": "In recent years, significant advances have been made in music source\nseparation, with model architectures such as dual-path modeling, band-split\nmodules, or transformer layers achieving comparably good results. However,\nthese models often contain a significant number of parameters, posing\nchallenges to devices with limited computational resources in terms of training\nand practical application. While some lightweight models have been introduced,\nthey generally perform worse compared to their larger counterparts. In this\npaper, we take inspiration from these recent advances to improve a lightweight\nmodel. We demonstrate that with careful design, a lightweight model can achieve\ncomparable SDRs to models with up to 13 times more parameters. Our proposed\nmodel, Moises-Light, achieves competitive results in separating four musical\nstems on the MUSDB-HQ benchmark dataset. The proposed model also demonstrates\ncompetitive scalability when using MoisesDB as additional training data."}
{"id": "2510.06946", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.06946", "abs": "https://arxiv.org/abs/2510.06946", "authors": ["Ruifeng Gao", "Hao Zhang", "Jue Wang", "Ye Li", "Yingdong Hu", "Qiuming Zhu", "Shu Sun", "Meixia Tao"], "title": "Maritime Communication in Evaporation Duct Environment with Ship Trajectory Optimization", "comment": null, "summary": "In maritime wireless networks, the evaporation duct effect has been known as\na preferable condition for long-range transmissions. However, how to\neffectively utilize the duct effect for efficient communication design is still\nopen for investigation. In this paper, we consider a typical scenario of\nship-to-shore data transmission, where a ship collects data from multiple\noceanographic buoys, sails from one to another, and transmits the collected\ndata back to a terrestrial base station during its voyage. A novel framework,\nwhich exploits priori information of the channel gain map in the presence of\nevaporation duct, is proposed to minimize the data transmission time and the\nsailing time by optimizing the ship's trajectory. To this end, a\nmulti-objective optimization problem is formulated and is further solved by a\ndynamic population PSO-integrated NSGA-II algorithm. Through simulations, it is\ndemonstrated that, compared to the benchmark scheme which ignores useful\ninformation of the evaporation duct, the proposed scheme can effectively reduce\nboth the data transmission time and the sailing time."}
{"id": "2510.06706", "categories": ["cs.SD", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.06706", "abs": "https://arxiv.org/abs/2510.06706", "authors": ["Phuong Tuan Dat", "Tran Huy Dat"], "title": "XLSR-Kanformer: A KAN-Intergrated model for Synthetic Speech Detection", "comment": "Accepted to 2025 IEEE International Conference on Advanced Video and\n  Signal-Based Surveillance", "summary": "Recent advancements in speech synthesis technologies have led to increasingly\nsophisticated spoofing attacks, posing significant challenges for automatic\nspeaker verification systems. While systems based on self-supervised learning\n(SSL) models, particularly the XLSR-Conformer architecture, have demonstrated\nremarkable performance in synthetic speech detection, there remains room for\narchitectural improvements. In this paper, we propose a novel approach that\nreplaces the traditional Multi-Layer Perceptron (MLP) in the XLSR-Conformer\nmodel with a Kolmogorov-Arnold Network (KAN), a powerful universal approximator\nbased on the Kolmogorov-Arnold representation theorem. Our experimental results\non ASVspoof2021 demonstrate that the integration of KAN to XLSR-Conformer model\ncan improve the performance by 60.55% relatively in Equal Error Rate (EER) LA\nand DF sets, further achieving 0.70% EER on the 21LA set. Besides, the proposed\nreplacement is also robust to various SSL architectures. These findings suggest\nthat incorporating KAN into SSL-based models is a promising direction for\nadvances in synthetic speech detection."}
{"id": "2510.07299", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.07299", "abs": "https://arxiv.org/abs/2510.07299", "authors": ["Peter Plantinga", "Roozbeh Sattari", "Karine Marcotte", "Carla Di Gironimo", "Madeleine Sharp", "Liziane Bouvier", "Maiya Geddes", "Ingrid Verduyckt", "Étienne de Villers-Sidani", "Mirco Ravanelli", "Denise Klein"], "title": "Comparison of Speech Tasks in Human Expert and Machine Detection of Parkinson's Disease", "comment": "Accepted to SMASH 2025", "summary": "The speech of people with Parkinson's Disease (PD) has been shown to hold\nimportant clues about the presence and progression of the disease. We\ninvestigate the factors based on which humans experts make judgments of the\npresence of disease in speech samples over five different speech tasks:\nphonations, sentence repetition, reading, recall, and picture description. We\nmake comparisons by conducting listening tests to determine clinicians accuracy\nat recognizing signs of PD from audio alone, and we conduct experiments with a\nmachine learning system for detection based on Whisper. Across tasks, Whisper\nperforms on par or better than human experts when only audio is available,\nespecially on challenging but important subgroups of the data: younger\npatients, mild cases, and female patients. Whisper's ability to recognize\nacoustic cues in difficult cases complements the multimodal and contextual\nstrengths of human experts."}
{"id": "2510.07120", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.07120", "abs": "https://arxiv.org/abs/2510.07120", "authors": ["Yinong Chen", "Wenchi Cheng", "Jingqing Wang", "Xiao Zheng", "Jiangzhou Wang"], "title": "Towards Reliable Emergency Wireless Communications over SAGINs: A Composite Fading and QoS-Centric Perspective", "comment": "13 pages", "summary": "In emergency wireless communications (EWC) scenarios, ensuring reliable,\nflexible, and high-rate transmission while simultaneously maintaining seamless\ncoverage and rapid response capabilities presents a critical technical\nchallenge. To this end, satellite-aerial-ground integrated network (SAGIN) has\nemerged as a promising solution due to its comprehensive three-dimensional\ncoverage and capability to meet stringent, multi-faceted quality-of-service\n(QoS) requirements. Nevertheless, most existing studies either neglected the\ninherent characteristics of the complex channel conditions due to the terrain\nchanges or analyzed the performance in the absence of QoS constraints,\nresulting in a mismatch between theoretical analysis and practical performance.\nTo remedy such deficiencies, in this paper we establish a performance modeling\nframework for SAGIN employing the Fisher-Snedecor $\\mathcal{F}$ composite\nfading model to characterize the air-ground link. In specific, the proposed\n$\\mathcal{F}$ composite fading channel is adopted to accurately describe both\nmultipath fading and shadowing in harsh ground environments. The exact\ndistribution of end-to-end signal-to-noise (SNR) statistics for space-air and\nair-ground links is developed, enabling theoretical analysis of cascaded\nchannels with fixed-gain amplify-and-forward (AF) and decode-and-forward (DF)\nrelaying protocols, respectively. Furthermore, asymptotic expressions of the\nderived results are provided to offer concise representations and demonstrate\nclose alignment with theoretical predictions in the high-SNR regime. Finally,\nthe insightful closed-form and asymptotic expressions of effective capacity\nwith QoS provisioning, outage probability, and $\\epsilon$-outage capacity are\ninvestigated, respectively, followed by both field measurements and Monte Carlo\nsimulations to verify the effectiveness."}
{"id": "2510.07293", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.07293", "abs": "https://arxiv.org/abs/2510.07293", "authors": ["Peize He", "Zichen Wen", "Yubo Wang", "Yuxuan Wang", "Xiaoqian Liu", "Jiajie Huang", "Zehui Lei", "Zhuangcheng Gu", "Xiangqi Jin", "Jiabing Yang", "Kai Li", "Zhifei Liu", "Weijia Li", "Cunxiang Wang", "Conghui He", "Linfeng Zhang"], "title": "AudioMarathon: A Comprehensive Benchmark for Long-Context Audio Understanding and Efficiency in Audio LLMs", "comment": "26 pages, 23 figures, the code is available at\n  \\url{https://github.com/DabDans/AudioMarathon}", "summary": "Processing long-form audio is a major challenge for Large Audio Language\nmodels (LALMs). These models struggle with the quadratic cost of attention\n($O(N^2)$) and with modeling long-range temporal dependencies. Existing audio\nbenchmarks are built mostly from short clips and do not evaluate models in\nrealistic long context settings. To address this gap, we introduce\nAudioMarathon, a benchmark designed to evaluate both understanding and\ninference efficiency on long-form audio. AudioMarathon provides a diverse set\nof tasks built upon three pillars: long-context audio inputs with durations\nranging from 90.0 to 300.0 seconds, which correspond to encoded sequences of\n2,250 to 7,500 audio tokens, respectively, full domain coverage across speech,\nsound, and music, and complex reasoning that requires multi-hop inference. We\nevaluate state-of-the-art LALMs and observe clear performance drops as audio\nlength grows. We also study acceleration techniques and analyze the trade-offs\nof token pruning and KV cache eviction. The results show large gaps across\ncurrent LALMs and highlight the need for better temporal reasoning and\nmemory-efficient architectures. We believe AudioMarathon will drive the audio\nand multimodal research community to develop more advanced audio understanding\nmodels capable of solving complex audio tasks."}
{"id": "2510.07199", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.07199", "abs": "https://arxiv.org/abs/2510.07199", "authors": ["Shirin Shoushtari", "Edward P. Chandler", "Ulugbek S. Kamilov"], "title": "Moments Matter: Posterior Recovery in Poisson Denoising via Log-Networks", "comment": null, "summary": "Poisson denoising plays a central role in photon-limited imaging applications\nsuch as microscopy, astronomy, and medical imaging. It is common to train deep\nlearning models for denoising using the mean-squared error (MSE) loss, which\ncorresponds to computing the posterior mean $\\mathbb{E}[x \\mid y]$. When the\nnoise is Gaussian, Tweedie's formula enables approximation of the posterior\ndistribution through its higher-order moments. However, this connection no\nlonger holds for Poisson denoising: while $ \\mathbb{E}[x \\mid y] $ still\nminimizes MSE, it fails to capture posterior uncertainty. We propose a new\nstrategy for Poisson denoising based on training a log-network. Instead of\npredicting the posterior mean $ \\mathbb{E}[x \\mid y] $, the log-network is\ntrained to learn $\\mathbb{E}[\\log x \\mid y]$, leveraging the logarithm as a\nconvenient parameterization for the Poisson distribution. We provide a\ntheoretical proof that the proposed log-network enables recovery of\nhigher-order posterior moments and thus supports posterior approximation.\nExperiments on simulated data show that our method matches the denoising\nperformance of standard MMSE models while providing access to the posterior."}

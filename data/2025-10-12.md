<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [eess.AS](#eess.AS) [Total: 7]
- [cs.SD](#cs.SD) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Autoencoding Coordinate Sequences from Psychophysiologic Signals](https://arxiv.org/abs/2510.07415)
*Timothy L. Hutcheson,Anil K. Raj*

Main category: eess.SP

TL;DR: 将24通道心理生理时间序列数据（EEG、ECG、EDA、RR）转换为可追踪的3D坐标，用于评估特定任务和认知状态的参与度


<details>
  <summary>Details</summary>
Motivation: 需要一种方法将多通道心理生理数据转换为更直观和可追踪的形式，以便更好地评估个体在特定任务和认知状态中的参与程度

Method: 开发了一种转换方法，将24通道的EEG、ECG、EDA和呼吸率时间序列数据映射为三维坐标

Result: 成功实现了从心理生理时间序列数据到3D坐标的转换，这些坐标足以估计个体在特定任务和认知状态中的参与度

Conclusion: 该方法为心理生理数据的可视化分析和状态评估提供了一种有效的三维表示方式

Abstract: We present a method for converting 24 channels of psychophysiologic time
series data collected from individual participants via electroencephalogram
(EEG), electrocardiogram (ECG), electrodermal activity (EDA), respiration rate
(RR) into trackable three dimensional (3D) coordinates sufficient to estimate
participation in specific task and cognitive states.

</details>


### [2] [Flexible Intelligent Metasurface for Reconfiguring Radio Environments](https://arxiv.org/abs/2510.07466)
*Hanwen Hu,Jiancheng An,Lu Gan,Naofal Al-Dhahir*

Main category: eess.SP

TL;DR: 本文研究了柔性智能超表面(FIM)在SISO和MISO通信系统中的应用，通过联合优化相位偏移矩阵和表面形状来最大化信道增益，相比传统RIS具有显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 柔性智能超表面技术相比传统刚性可重构智能表面具有更大潜力，能够独立调节电磁信号并灵活调整表面形状以获得更好的信道条件，提高无线网络的频谱效率和能量效率。

Method: 在SISO场景中，将高维非凸优化问题分解为多个一维子问题，使用粒子群优化算法和多区间梯度下降法更新FIM表面形状；在MISO场景中，提出高效的交替优化算法联合优化发射波束成形、FIM表面形状和相位偏移矩阵。

Result: 仿真结果表明，FIM相比传统RIS显著提高了信道增益，并且在多径信道中表现出良好的适应性。

Conclusion: 柔性智能超表面技术通过联合优化相位偏移和表面形状，能够有效提升无线通信系统的性能，为未来智能无线网络提供了新的技术路径。

Abstract: Flexible intelligent metasurface (FIM) technology holds immense potential for
increasing the spectral efficiency and energy efficiency of wireless networks.
In contrast to traditional rigid reconfigurable intelligent surfaces (RIS), an
FIM consists of an array of elements, each capable of independently tuning
electromagnetic signals, while flexibly adjusting its position along the
direction perpendicular to the surface. In contrast to traditional rigid
metasurfaces, FIM is capable of morphing its surface shape to attain better
channel conditions. In this paper, we investigate the single-input
single-output (SISO) and multiple-input single-output (MISO) communication
systems aided by a transmissive FIM. In the SISO scenario, we jointly optimize
the FIM phase shift matrix and surface shape to maximize the end-to-end channel
gain. First, we derive the optimal phase-shift matrix for each tentative FIM
surface shape to decompose the high-dimensional non-convex optimization problem
into multiple one-dimensional subproblems. Then, we utilize the particle swarm
optimization (PSO) algorithm and the multi-interval gradient descent (MIGD)
method for updating the FIM's surface shape to maximize the channel gain. In
the MISO scenario, we jointly optimize the transmit beamforming, the FIM
surface shape, and the phase shift matrix to maximize the channel gain. To
tackle this complex problem with multiple highly coupled variables, an
efficient alternating optimization algorithm is proposed. Simulation results
demonstrate that FIM significantly improves channel gain compared to
traditional RIS and exhibits good adaptability to multipath channels.

</details>


### [3] [Time-Frequency Filtering Meets Graph Clustering](https://arxiv.org/abs/2510.07503)
*Marcelo A. Colominas,Stefan Steinerberger,Hau-Tieng Wu*

Main category: eess.SP

TL;DR: 将时频表示中的信号分量识别问题转化为图聚类问题，利用图聚类方法识别信号分量


<details>
  <summary>Details</summary>
Motivation: 传统方法在识别时频表示中的不同信号分量时存在困难，需要寻找新的有效方法

Method: 将信号分量识别问题建模为图聚类问题，利用图论中识别强连接子图且子图间连接较少的方法

Result: 数值实验验证了该方法在识别信号分量方面的有效性

Conclusion: 图聚类方法为信号分量识别提供了新的有效途径

Abstract: We show that the problem of identifying different signal components from a
time-frequency representation can be equivalently phrased as a graph clustering
problem: given a graph $G=(V,E)$ one aims to identify `clusters', subgraphs
that are strongly connected and have relatively few connections between them.
The graph clustering problem is well studied, we show how these ideas can
suggest (many) new ways to identify signal components. Numerical experiments
illustrate the ideas.

</details>


### [4] [Rate Maximization for UAV-assisted ISAC System with Fluid Antennas](https://arxiv.org/abs/2510.07668)
*Xingtao Yang,Zhenghe Guo,Siyun Liang,Zhaohui Yang,Chen Zhu,Zhaoyang Zhang*

Main category: eess.SP

TL;DR: 本文研究了集成感知与通信系统中无人机和基站的联合感知问题，通过建立凸优化模型和交替优化算法，在保证联合系统感知能力的同时最大化通信速率。


<details>
  <summary>Details</summary>
Motivation: 在集成感知与通信系统中，基站通过无人机的感知系统来增强其感知性能，需要解决通信速率最大化与感知能力保障之间的平衡问题。

Method: 建立具有凸优化特性的通信-感知模型，通过问题分解和凸优化逐步求解关键变量，开发基于交替优化方法的迭代算法来寻找最优解。

Result: 仿真结果验证了算法在平衡系统性能方面的有效性，显著降低了求解复杂度。

Conclusion: 所提出的方法能够有效解决无人机与基站联合感知系统中的通信-感知权衡问题，为集成感知与通信系统提供了实用的解决方案。

Abstract: This letter investigates the joint sensing problem between unmanned aerial
vehicles (UAV) and base stations (BS) in integrated sensing and communication
(ISAC) systems with fluid antennas (FA). In this system, the BS enhances its
sensing performance through the UAV's perception system. We aim to maximize the
communication rate between the BS and UAV while guaranteeing the joint system's
sensing capability. By establishing a communication-sensing model with convex
optimization properties, we decompose the problem and apply convex optimization
to progressively solve key variables. An iterative algorithm employing an
alternating optimization approach is subsequently developed to determine the
optimal solution, significantly reducing the solution complexity. Simulation
results validate the algorithm's effectiveness in balancing system performance.

</details>


### [5] [Utilizing Model-Free Reinforcement Learning for Optimizing Secure Multi-Party Computation Protocols](https://arxiv.org/abs/2510.07814)
*Javad Sayyadi,Mahdi Nangir,Mahmood Mohassel Feghhi,Hamid Sayyadi*

Main category: eess.SP

TL;DR: 使用无模型强化学习优化安全多方计算协议，显著降低执行时间和通信成本


<details>
  <summary>Details</summary>
Motivation: 当前安全多方计算协议由于计算和通信复杂性导致效率不佳，需要优化协议性能

Method: 设计强化学习模型，动态学习和适应安全计算的最优策略

Result: 实验结果显示该方法能大幅减少协议执行时间和通信成本

Conclusion: 强化学习在提高安全多方计算协议效率方面具有巨大潜力

Abstract: In this manuscript, we explore the application of model-free reinforcement
learning in optimizing secure multiparty computation (SMPC) protocols. SMPC is
a crucial tool for performing computations on private data without the need to
disclose it, holding significant importance in various domains, including
information security and privacy. However, the efficiency of current protocols
is often suboptimal due to computational and communicational complexities. Our
proposed approach leverages model-free reinforcement learning algorithms to
enhance the performance of these protocols. We have designed a reinforcement
learning model capable of dynamically learning and adapting optimal strategies
for secure computations. Our experimental results demonstrate that employing
this method leads to a substantial reduction in execution time and
communication costs of the protocols. These achievements highlight the high
potential of reinforcement learning in improving the efficiency of secure
multiparty computation protocols, providing an effective solution to the
existing challenges in this field.

</details>


### [6] [Wideband dynamic metasurface antenna performance with practical design characteristics](https://arxiv.org/abs/2510.07827)
*Joseph M. Carlson,Nitish V. Deshpande,Miguel Rodrigo Castellanos,Robert W. Heath Jr*

Main category: eess.SP

TL;DR: 本文研究了动态超表面天线在宽带通信中的应用，分析了波导衰减、元件频率选择性和可调元件有限可重构性对波束成形增益的影响，并提出了一种连续波束成形算法来提升宽带性能。


<details>
  <summary>Details</summary>
Motivation: 动态超表面天线通过可重构辐射槽提供低功耗波束成形，每个槽的可调组件功耗低于传统模拟组件（如移相器），是降低MIMO天线阵列功耗的潜在候选方案。

Method: 开发了考虑波导衰减、元件频率选择性和可调元件有限可重构性的DMA波束成形增益近似模型，并提出了一种简单的连续波束成形算法，通过顺序配置每个DMA元件来改善宽带性能。

Result: 仿真结果显示，在视距宽带系统中，近似模型与模拟DMA模型在频谱效率方面具有良好准确性，且所提出的连续波束成形算法相比基线DMA波束成形方法提高了整体频谱效率。

Conclusion: DMA在宽带通信中具有应用潜力，所开发的近似模型和连续波束成形算法为DMA的宽带性能优化提供了有效工具和关键见解。

Abstract: Dynamic metasurface antennas (DMA) provide low-power beamforming through
reconfigurable radiative slots. Each slot has a tunable component that consumes
low power compared to typical analog components like phase shifters. This makes
DMAs a potential candidate to minimize the power consumption of multiple-input
multiple-output (MIMO) antenna arrays. In this paper, we investigate the use of
DMAs in a wideband communication setting with practical DMA design
characteristics. We develop approximations for the DMA beamforming gain that
account for the effects of waveguide attenuation, element
frequency-selectivity, and limited reconfigurability of the tunable components
as a function of the signal bandwidth. The approximations allow for key
insights into the wideband performance of DMAs in terms of different design
variables. We develop a simple successive beamforming algorithm to improve the
wideband performance of DMAs by sequentially configuring each DMA element.
Simulation results for a line-of-sight (LOS) wideband system show the accuracy
of the approximations with the simulated DMA model in terms of spectral
efficiency. We also find that the proposed successive beamforming algorithm
increases the overall spectral efficiency of the DMA-based wideband system
compared with a baseline DMA beamforming method.

</details>


### [7] [Accelerating vRAN and O-RAN with SIMD: Architectural Perspectives and Performance Evaluation](https://arxiv.org/abs/2510.07843)
*Jaebum Park,Chan-Byoung Chae,Robert W. Heath Jr*

Main category: eess.SP

TL;DR: 本文探讨了如何使用SIMD架构加速无线接入网络(RAN)工作负载，特别是在物理层功能如信道估计、MIMO检测和前向纠错等方面，展示了相比传统CPU处理的吞吐量和能效显著提升。


<details>
  <summary>Details</summary>
Motivation: 随着无线接入网络向虚拟化和开放化演进，在商用现成平台上实现实时且节能的基带处理仍是一个关键挑战。SIMD架构的数据级并行特性与RAN关键工作负载高度匹配。

Method: 提出了实用的设计指南和原型结果，分析了SIMD如何加速关键物理层功能，包括信道估计、MIMO检测和前向纠错等，同时保持可编程性和易集成性。

Result: 相比传统的仅CPU处理，SIMD架构在吞吐量和能效方面实现了显著改进，为灵活、高效的6G就绪RAN提供了技术支持。

Conclusion: SIMD是支持灵活、高效和可持续6G就绪RAN的关键使能技术，尽管在负载均衡和硬件异构性方面仍存在开放挑战。

Abstract: The evolution of radio access networks (RANs) toward virtualization and
openness creates new opportunities for flexible, cost-effective, and
high-performance deployments. Achieving real-time and energy-efficient baseband
processing on commercial off-the-shelf platforms, however, remains a critical
challenge. This article explores how single instruction multiple data (SIMD)
architectures can accelerate RAN workloads. We first outline why key
physical-layer functions, such as channel estimation, multiple-input
multiple-output (MIMO) detection, and forward error correction, are well
aligned with SIMD's data-level parallelism. We then present practical design
guidelines and prototype results, showing significant improvements in
throughput and energy efficiency compared to conventional CPU-only processing,
while retaining programmability and ease of integration. Finally, we discuss
open challenges in workload balancing and hardware heterogeneity, and highlight
the role of SIMD as an enabling technology for flexible, efficient, and
sustainable 6G-ready RANs.

</details>


### [8] [Statistical Analysis of Target Parameter Estimation Using Passive Radar](https://arxiv.org/abs/2510.07948)
*Mats Viberg,Daniele Gerosa,Tomas McKelvey,Thomas Eriksson*

Main category: eess.SP

TL;DR: 分析无源雷达系统中由于不完美了解发射信号波形而产生的目标参数估计误差


<details>
  <summary>Details</summary>
Motivation: 无源雷达系统使用机会照射源进行目标检测和定位，但实际中无法完美了解发射信号波形，这会影响目标参数估计精度

Method: 量化分析由于不了解发射IO波形而产生的额外误差贡献，并给出该误差相对于监视通道中杂波和噪声误差可忽略的充分条件

Result: 建立了目标参数估计误差的量化模型，明确了波形不确定性对系统性能的影响

Conclusion: 提出了一个充分条件，当满足该条件时，波形不确定性引起的误差相对于监视通道中的杂波和噪声误差可以忽略不计

Abstract: A passive radar system uses one or more so-called Illuminators of Opportunity
(IO) to detect and localize targets. In such systems, a reference channel is
often used at each receiving node to capture the transmitted IO signal, while
targets are detected using the main surveillance channel. The purpose of the
present contribution is to analyze a method for estimating the target
parameters in such a system. Specifically, we quantify the additional error
contribution due to not knowing the transmitted IO waveform perfectly. A
sufficient condition for this error to be negligible as compared to errors due
to clutter and noise in the surveillance channel is then given.

</details>


### [9] [Over-The-Air Phase Calibration of Spaceborne Phased Array for LEO Satellite Communications](https://arxiv.org/abs/2510.08011)
*Wei Zhang,Ding Chen,Bin Zhou*

Main category: eess.SP

TL;DR: 本文提出了一种用于低轨卫星通信的星载相控阵空中相位校准方法，通过多次传输导频信号联合估计相控阵相位偏差和未知信道，并推导了克拉美罗界和波束图优化方案。


<details>
  <summary>Details</summary>
Motivation: 为了解决星载相控阵不可预测的相位偏差问题，需要开发有效的空中相位校准方法，特别是在低轨卫星通信场景下。

Method: 使用多次导频传输联合估计相控阵相位偏差和未知信道，推导克拉美罗界，并优化波束图以降低校准的均方根误差。

Result: 仿真结果表明，所提出的空中相位校准算法有效，相位估计的均方根误差接近相应的克拉美罗界，波束图优化方案相比随机生成的波束图可获得超过4dB的信噪比增益。

Conclusion: 该方法能够有效解决星载相控阵的相位校准问题，通过波束图优化显著提升校准性能。

Abstract: To avoid the unpredictable phase deviations of the spaceborne phased array
(SPA), this paper considers the over-the-air (OTA) phase calibration of the SPA
for the low earth orbit (LEO) satellite communications, where the phase
deviations of the SPA and the unknown channel are jointly estimated with
multiple transmissions of the pilots. Moreover, the Cramer Rao Bound (CRB) is
derived, and the optimization of beam patterns is also presented to lower the
root mean squared error (RMSE) of the OTA calibration. The simulation results
verify the effectiveness of the proposed OTA phase calibration algorithm as the
RMSEs of the phase estimates closely approach the corresponding CRB, and the
beam pattern optimization scheme is also validated for more than 4dB gain of
SNR over the randomly generated beam patterns.

</details>


### [10] [Towards Precise Channel Knowledge Map: Exploiting Environmental Information from 2D Visuals to 3D Point Clouds](https://arxiv.org/abs/2510.08140)
*Yancheng Wang,Chuan Huang,Songyang Zhang,Guanying Chen,Wei Guo,Shenglun Lan,Lexi Xu,Xinzhou Cheng,Xiongyan Tang,Shuguang Cui*

Main category: eess.SP

TL;DR: 该论文提出了一种利用3D环境信息构建高精度信道知识地图(CKM)的新框架，通过混合模型和数据驱动方法将3D点云集成到CKM构建中，以解决6G网络中传统导频信道探测带来的通信资源开销问题。


<details>
  <summary>Details</summary>
Motivation: 传统基于导频的信道探测消耗大量通信资源，在6G网络的大规模信道维度、超宽带宽和密集用户部署场景下带来不可持续的负担。信道知识地图(CKM)作为无线电地图的推广，提供了无需详尽测量即可获取位置标记信道信息的新范式。

Method: 提出了一种新颖框架，通过混合模型和数据驱动方法将3D点云集成到CKM构建中。该方法超越了传统的2D视觉表示，充分利用3D环境信息，并在真实场景中进行了广泛的案例研究。

Result: 实验结果表明，基于增强语义理解的3D环境能够构建精确的CKM，并在下一代无线通信中具有应用潜力。同时发布了包含实测信道数据和高分辨率3D环境数据的真实世界数据集。

Conclusion: 该研究强调了利用3D环境信息构建高精度CKM的必要性，展示了3D增强语义理解在精确CKM构建中的潜力，为未来6G网络的可扩展性挑战提供了解决方案。

Abstract: The substantial communication resources consumed by conventional pilot-based
channel sounding impose an unsustainable overhead, presenting a critical
scalability challenge for the future 6G networks characterized by massive
channel dimensions, ultra-wide bandwidth, and dense user deployments. As a
generalization of radio map, channel knowledge map (CKM) offers a paradigm
shift, enabling access to location-tagged channel information without
exhaustive measurements. To fully utilize the power of CKM, this work
highlights the necessity of leveraging three-dimensional (3D) environmental
information, beyond conventional two-dimensional (2D) visual representations,
to construct high-precision CKMs. Specifically, we present a novel framework
that integrates 3D point clouds into CKM construction through a hybrid model-
and data-driven approach, with extensive case studies in real-world scenarios.
The experimental results demonstrate the potential for constructing precise
CKMs based on 3D environments enhanced with semantic understanding, together
with their applications in the next-generation wireless communications. We also
release a real-world dataset of measured channel paired with high-resolution 3D
environmental data to support future research and validation.

</details>


### [11] [Channel Charting based Fast Beam Tracking Design and Implementation](https://arxiv.org/abs/2510.08144)
*Jiawei Zhang,Shihan Wang,Jienan Chen,Fan Wu,Jiyun Tao,Zheqi Gu*

Main category: eess.SP

TL;DR: 提出基于信道图表的低开销波束追踪算法，将波束追踪问题转化为信道图中波束簇的获取问题，显著减少波束扫描次数


<details>
  <summary>Details</summary>
Motivation: 在B5G和6G毫米波通信系统中，波束追踪对于提供可靠通信服务至关重要，但面临提供一致准确追踪性能的挑战

Method: 利用对比学习将高维信道状态信息投影到保持空间邻近性的低维特征空间，采用动态候选波束获取策略

Result: 仿真环境中达到98.27%的准确率，相比现有方法可减少最多55.9%的波束扫描次数，现场测试显示移动过程中通信质量良好

Conclusion: 该算法在保持高预测精度的同时显著降低了扫描复杂度，为毫米波通信系统提供了有效的波束追踪解决方案

Abstract: In the beyond fifth-generation (B5G) and upcoming sixth-generation (6G)
wireless communication systems, millimeter (mmWave) wave technology is a
promising solution for offering additional bandwidth resources and mitigating
spectrum congestion. Beam tracking is an essential procedure for providing
reliable communication services in the mmWave communication system, with the
challenge of providing consistent and accurate tracking performance. In this
study, we introduce a low-overhead beam tracking algorithm based on channel
charting, which significantly reduces beam scanning times during the tracking
process. By projecting the beam information to the channel chart, the beam
tracking problem is transformed into the acquisition of the beam cluster in the
channel chart. Leveraging contrastive learning, the proposed channel chart
projects high-dimensional channel state information into a low-dimensional
feature space that preserves spatial proximities. Using a dynamic candidate
beam acquisition strategy, the complexity of our beam tracking algorithm is
significantly reduced. The proposed algorithm significantly reduces scanning
complexity while maintaining high prediction accuracy, achieving an accuracy of
98.27\% in simulation environments. Compared to existing methods, the proposed
method can reduce beam scanning times by up to 55.9\%. In addition, we also
performed field tests, and the measured results demonstrated excellent
communication quality during mobility.

</details>


### [12] [Attitude and Heading Estimation in Symmetrical Inertial Arrays](https://arxiv.org/abs/2510.08161)
*Yaakov Libero,Itzik Klein*

Main category: eess.SP

TL;DR: 提出了一种新颖的对称多惯性测量单元(MIMU)配置，通过将IMU排列成对称对角对来解耦线性和旋转加速度分量，解决了陀螺仪自由(GF)配置的固有不稳定性和发散率问题。


<details>
  <summary>Details</summary>
Motivation: 陀螺仪自由(GF)配置虽然具有异常值检测和角加速度测量等优势，但存在固有不稳定性和发散率增加的主要缺点，需要解决这些问题以实现可靠的GF导航。

Method: 推导了对称MIMU配置的GF方程理论基础，开发了非线性最小二乘估计过程，并将统计假设检验集成到AHRS误差状态扩展卡尔曼滤波器中。

Result: 在包含85分钟导航数据的真实世界数据集上验证，结果显示姿态估计误差平均减少30%，旋转检测精度提升超过95%，稳定性显著改善。

Conclusion: 该方法能够在陀螺仪不可用、不可靠或能量受限的应用中实现可靠的GF导航，适用于微型平台、计算受限平台和长续航海洋平台。

Abstract: Attitude and heading reference systems (AHRS) play a central role in
autonomous navigation systems on land, air and maritime platforms. AHRS utilize
inertial sensor measurements to estimate platform orientation. In recent years,
there has been increasing interest in multiple inertial measurement units
(MIMU) arrays to improve navigation accuracy and robustness. A particularly
challenging MIMU implementation is the gyro-free (GF) configuration, in which
angular velocity is derived solely from accelerometer measurements. While the
GF configurations have multiple benefits, including outlier detection and in
angular acceleration measurements, their main drawbacks are inherent
instability and an increased divergence rate. To address these shortcomings, we
introduce a novel symmetrical MIMU formulation, in which the IMUs are arranged
in symmetric diagonal pairs to decouple linear and rotational acceleration
components. To this end, we derive the theoretical foundations for the
symmetrical MIMU formulation of the GF equations, develop a nonlinear least
squares estimation process, and integrate statistical hypothesis testing into
an AHRS error-state extended Kalman filter. We validate our approach using
real-world datasets containing 85 minutes of navigation data recorded on both
airborne and land platforms. Our results demonstrated a 30\% average reduction
in attitude estimation errors, rotation detection accuracy exceeding 95\%
improvement, and significantly improved stability compared to a standard GF
implementation. These results enable reliable GF navigation in applications
where gyroscopes are unavailable, unreliable, or energy-constrained. Common
examples include miniature platforms, computational-constraint platforms, and
long-endurance marine platforms.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [13] [SALAD-VAE: Semantic Audio Compression with Language-Audio Distillation](https://arxiv.org/abs/2510.07592)
*Sebastian Braun,Hannes Gamper,Dimitra Emmanouilidou*

Main category: eess.AS

TL;DR: SALAD-VAE是一种紧凑的语义音频变分自编码器，在频率域工作，实现了7.8Hz的低潜在帧率下的最先进压缩，同时保持高音频质量和语义结构。


<details>
  <summary>Details</summary>
Motivation: 现代生成和多模态模型需要平衡语义丰富性和高保真重建的紧凑潜在表示。

Method: 在标准VAE基础上增强语义损失和数据增强，包括对比学习和基于CLAP的嵌入蒸馏，使用计算复杂度较低的架构。

Result: 在重建质量上匹配最先进的VAE，在分类基准上持续优于它们，并提供可用于零样本音频描述和分类的CLAP投影层。

Conclusion: SALAD-VAE实现了高效的音频压缩和语义表示，在多个任务上表现出色，并提供了零样本能力。

Abstract: Modern generative and multimodal models increasingly rely on compact latent
representations that trade and balance semantic richness with high-fidelity
reconstruction. We introduce SALAD-VAE, a continuous and highly compact
semantic Audio Variational Autoencoder, which operates in the frequency domain
and achieves state-of-the-art compression with very low latent frame rate (7.8
Hz) while surfacing semantic structure and producing high audio quality. We
enhance the standard VAE semantic losses and augmentation, specifically
contrastive learning and CLAP-based embedding distillation, enabling it to
generalize across diverse audio domains. With a significantly less
computational complex architecture than comparable state-of-the-art VAEs,
SALAD-VAE matches their reconstruction quality while it consistently
outperforms them on a wide range of classification benchmarks. Furthermore, the
proposed additional loss function provides a trained CLAP projection layer,
which can be used zero-shot audio captioning and classification matching
pretrained CLAP audio-text embeddings.

</details>


### [14] [Full-Duplex-Bench-v2: A Multi-Turn Evaluation Framework for Duplex Dialogue Systems with an Automated Examiner](https://arxiv.org/abs/2510.07838)
*Guan-Ting Lin,Shih-Yun Shan Kuan,Jiatong Shi,Kai-Wei Chang,Siddhant Arora,Shinji Watanabe,Hung-yi Lee*

Main category: eess.AS

TL;DR: FDB-v2是一个用于评估全双工语音代理多轮交互性能的流式框架，包含四种任务类型和两种节奏设置，测试结果显示现有系统在同时说话、纠错处理和实体跟踪方面存在困难。


<details>
  <summary>Details</summary>
Motivation: 全双工语音代理虽然能实现低延迟的自然交互，但其在多轮对话中的一致性和任务表现尚未得到充分研究。

Method: 开发了Full-Duplex-Bench-v2流式框架，集成自动考官系统，在快慢两种节奏下执行阶段性目标，涵盖日常对话、纠错、实体跟踪和安全四种任务类型。

Result: 测试发现全双工系统在用户同时说话时容易混淆，难以流畅处理纠错，有时会丢失对话中的实体跟踪。

Conclusion: FDB-v2通过开源标准化流式协议和任务集，便于扩展新任务类型，帮助社区定制和加速多轮全双工系统的评估。

Abstract: While full-duplex speech agents enable natural, low-latency interaction by
speaking and listening simultaneously, their consistency and task performance
in multi-turn settings remain underexplored. We introduce Full-Duplex-Bench-v2
(FDB-v2), a streaming framework that integrates with an automated examiner that
enforces staged goals under two pacing setups (Fast vs. Slow). FDB-v2 covers
four task families: daily, correction, entity tracking, and safety. We report
turn-taking fluency, multi-turn instruction following, and task-specific
competence. The framework is extensible, supporting both commercial APIs and
open source models. When we test full-duplex systems with FDB-v2, they often
get confused when people talk at the same time, struggle to handle corrections
smoothly, and sometimes lose track of who or what is being talked about.
Through an open-sourced, standardized streaming protocol and a task set, FDB-v2
makes it easy to extend to new task families, allowing the community to tailor
and accelerate evaluation of multi-turn full-duplex systems.

</details>


### [15] [Guitar Tone Morphing by Diffusion-based Model](https://arxiv.org/abs/2510.07908)
*Kuan-Yu Chen,Kuan-Lin Chen,Yu-Chieh Yu,Jian-Jiun Ding*

Main category: eess.AS

TL;DR: 该研究探索了基于学习的吉他音色变形方法，提出了比复杂微调方法更简单的球面插值方法，能生成更平滑自然的音色过渡。


<details>
  <summary>Details</summary>
Motivation: 由于电吉他音色丰富且表达灵活，在音乐信息检索中建模和转换乐器音色受到越来越多关注。音色变形能够在不同吉他声音之间实现平滑过渡，为音乐家提供更大自由度来探索新纹理和个性化表演。

Method: 首先使用LoRA微调来改善模型在有限数据上的性能，然后引入更简单的名为Music2Latent的球面插值方法。

Result: 球面插值方法比复杂的微调方法产生显著更好的结果，实验显示所提出的架构能生成更平滑自然的音色过渡。

Conclusion: 该方法成为音乐制作和实时音频效果处理的实用高效工具。

Abstract: In Music Information Retrieval (MIR), modeling and transforming the tone of
musical instruments, particularly electric guitars, has gained increasing
attention due to the richness of the instrument tone and the flexibility of
expression. Tone morphing enables smooth transitions between different guitar
sounds, giving musicians greater freedom to explore new textures and
personalize their performances. This study explores learning-based approaches
for guitar tone morphing, beginning with LoRA fine-tuning to improve the model
performance on limited data. Moreover, we introduce a simpler method, named
spherical interpolation using Music2Latent. It yields significantly better
results than the more complex fine-tuning approach. Experiments show that the
proposed architecture generates smoother and more natural tone transitions,
making it a practical and efficient tool for music production and real-time
audio effects.

</details>


### [16] [Bloodroot: When Watermarking Turns Poisonous For Stealthy Backdoor](https://arxiv.org/abs/2510.07909)
*Kuan-Yu Chen,Yi-Cheng Lin,Jeng-Lin Li,Jian-Jiun Ding*

Main category: eess.AS

TL;DR: 提出了一种名为Bloodroot的新型音频后门框架，通过将水印作为触发器的概念与对抗性LoRA微调相结合，在保持高感知质量的同时实现了更高的触发成功率和干净样本准确率。


<details>
  <summary>Details</summary>
Motivation: 当前音频后门方法存在感知质量下降的问题，容易被人类察觉。本研究探索音频水印的内在隐蔽性和有效性，旨在开发更隐蔽且有效的音频数据投毒技术。

Method: 提出Watermark-as-Trigger概念，集成到Bloodroot后门框架中，采用对抗性LoRA微调技术，在语音识别和说话人识别数据集上进行实验。

Result: 实验表明基于水印的投毒在声学滤波和模型剪枝下仍保持有效，Bloodroot框架不仅保护了数据到模型的所有权，还揭示了对抗性滥用的风险。

Conclusion: Bloodroot框架成功实现了隐蔽且高效的音频后门攻击，为数据所有权保护提供了新方法，同时也警示了对抗性滥用的潜在风险。

Abstract: Backdoor data poisoning is a crucial technique for ownership protection and
defending against malicious attacks. Embedding hidden triggers in training data
can manipulate model outputs, enabling provenance verification, and deterring
unauthorized use. However, current audio backdoor methods are suboptimal, as
poisoned audio often exhibits degraded perceptual quality, which is noticeable
to human listeners. This work explores the intrinsic stealthiness and
effectiveness of audio watermarking in achieving successful poisoning. We
propose a novel Watermark-as-Trigger concept, integrated into the Bloodroot
backdoor framework via adversarial LoRA fine-tuning, which enhances perceptual
quality while achieving a much higher trigger success rate and clean-sample
accuracy. Experiments on speech recognition (SR) and speaker identification
(SID) datasets show that watermark-based poisoning remains effective under
acoustic filtering and model pruning. The proposed Bloodroot backdoor framework
not only secures data-to-model ownership, but also well reveals the risk of
adversarial misuse.

</details>


### [17] [Pseudo2Real: Task Arithmetic for Pseudo-Label Correction in Automatic Speech Recognition](https://arxiv.org/abs/2510.08047)
*Yi-Cheng Lin,Yu-Hsuan Li Liang,Hsuan Su,Tzu-Quan Lin,Shang-Tse Chen,Yun-Nung Chen,Hung-yi Lee*

Main category: eess.AS

TL;DR: 提出一种参数空间校正方法，通过比较在真实标签和伪标签上微调的ASR模型权重差异来纠正伪标签中的系统性偏差，显著提升跨域ASR性能。


<details>
  <summary>Details</summary>
Motivation: 现实ASR系统面临领域偏移问题，伪标签方法虽然实用但会引入系统性口音特定错误，传统过滤方法无法有效纠正这些偏差。

Method: 从相同初始化训练两个ASR模型：一个使用真实标签，一个使用伪标签，计算它们的权重差异作为校正向量，然后将该向量应用于伪标签目标模型。

Result: 在AfriSpeech-200数据集上，使用Whisper tiny模型对10种非洲口音实现了高达35%的相对词错误率降低。

Conclusion: 参数空间校正方法能有效纠正伪标签中的系统性偏差，显著提升跨域ASR性能，且无需目标域真实标签。

Abstract: Robust ASR under domain shift is crucial because real-world systems encounter
unseen accents and domains with limited labeled data. Although pseudo-labeling
offers a practical workaround, it often introduces systematic, accent-specific
errors that filtering fails to fix. We ask: How can we correct these recurring
biases without target ground truth? We propose a simple parameter-space
correction: in a source domain containing both real and pseudo-labeled data,
two ASR models are fine-tuned from the same initialization, one on ground-truth
labels and the other on pseudo-labels, and their weight difference forms a
correction vector that captures pseudo-label biases. When applied to a
pseudo-labeled target model, this vector enhances recognition, achieving up to
a 35% relative Word Error Rate (WER) reduction on AfriSpeech-200 across ten
African accents with the Whisper tiny model.

</details>


### [18] [DialoSpeech: Dual-Speaker Dialogue Generation with LLM and Flow Matching](https://arxiv.org/abs/2510.08373)
*Hanke Xie,Dake Guo,Chengyou Wang,Yue Li,Wenjie Tian,Xinfa Zhu,Xinsheng Wang,Xiulin Li,Guanqiong Miao,Bo Liu,Lei Xie*

Main category: eess.AS

TL;DR: DialoSpeech是一个结合大语言模型和分块流匹配的双轨架构，用于生成表达力强、类人的对话语音合成，支持中英文及跨语言语音合成。


<details>
  <summary>Details</summary>
Motivation: 当前文本转语音系统在生成类人交互对话语音方面面临挑战，包括双轨数据稀缺以及难以在多轮对话中实现自然性、上下文连贯性和交互动态性（如话轮转换、重叠语音和说话人一致性）。

Method: 提出DialoSpeech双轨架构，结合大语言模型与分块流匹配技术，并引入数据处理管道构建双轨对话数据集，支持可扩展的训练和实验验证。

Result: 实验表明，该模型在基线比较中表现优异，能够生成自然的多轮对话，具有连贯的话轮转换和自然的重叠语音。

Conclusion: DialoSpeech为生成类人口语对话提供了一种解决方案，在表达力和自然性方面取得了显著进展。

Abstract: Recent advances in text-to-speech (TTS) synthesis, particularly those
leveraging large language models (LLMs), have significantly improved
expressiveness and naturalness. However, generating human-like, interactive
dialogue speech remains challenging. Current systems face limitations due to
the scarcity of dual-track data and difficulties in achieving naturalness,
contextual coherence, and interactional dynamics, such as turn-taking,
overlapping speech, and speaker consistency, in multi-turn conversations. To
address these challenges, we propose DialoSpeech, a dual-track architecture
combining a large language model with Chunked Flow Matching for expressive,
human-like dialogue speech synthesis. DialoSpeech generates natural multi-turn
conversations with coherent speaker turns and natural overlaps, supporting both
Chinese and English and cross-lingual speech synthesis. We introduce a data
processing pipeline to construct dual-track dialogue datasets, facilitating
scalable training and experimental validation. Experiments show that our model
outperforms baselines, offering a solution for generating human-like spoken
dialogues. Audio samples are available at
https://tiamojames.github.io/DialoSpeech

</details>


### [19] [MeanVC: Lightweight and Streaming Zero-Shot Voice Conversion via Mean Flows](https://arxiv.org/abs/2510.08392)
*Guobin Ma,Jixun Yao,Ziqian Ning,Yuepeng Jiang,Lingxin Xiong,Lei Xie,Pengcheng Zhu*

Main category: eess.AS

TL;DR: MeanVC是一个轻量级流式零样本语音转换方法，结合了自回归和非自回归框架的优势，使用扩散变换器和分块自回归去噪策略，在单步采样中实现高质量的语音转换。


<details>
  <summary>Details</summary>
Motivation: 现有流式语音转换方法要么需要大量参数才能达到良好性能，要么难以泛化到未见过的说话人，需要同时具备快速、轻量和高保真度的模型。

Method: 引入均值流的扩散变换器，在训练中回归平均速度场，结合分块自回归去噪策略，并采用扩散对抗后训练来减轻过平滑问题。

Result: 实验结果显示MeanVC显著优于现有零样本流式语音转换系统，在更少参数下实现了更高的转换质量和效率。

Conclusion: MeanVC通过结合AR和NAR范式的优势，实现了高效、轻量且高质量的流式零样本语音转换。

Abstract: Zero-shot voice conversion (VC) aims to transfer timbre from a source speaker
to any unseen target speaker while preserving linguistic content. Growing
application scenarios demand models with streaming inference capabilities. This
has created a pressing need for models that are simultaneously fast,
lightweight, and high-fidelity. However, existing streaming methods typically
rely on either autoregressive (AR) or non-autoregressive (NAR) frameworks,
which either require large parameter sizes to achieve strong performance or
struggle to generalize to unseen speakers. In this study, we propose MeanVC, a
lightweight and streaming zero-shot VC approach. MeanVC introduces a diffusion
transformer with a chunk-wise autoregressive denoising strategy, combining the
strengths of both AR and NAR paradigms for efficient streaming processing. By
introducing mean flows, MeanVC regresses the average velocity field during
training, enabling zero-shot VC with superior speech quality and speaker
similarity in a single sampling step by directly mapping from the start to the
endpoint of the flow trajectory. Additionally, we incorporate diffusion
adversarial post-training to mitigate over-smoothing and further enhance speech
quality. Experimental results demonstrate that MeanVC significantly outperforms
existing zero-shot streaming VC systems, achieving superior conversion quality
with higher efficiency and significantly fewer parameters. Audio demos and code
are publicly available at https://aslp-lab.github.io/MeanVC.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [20] [INFER : Learning Implicit Neural Frequency Response Fields for Confined Car Cabin](https://arxiv.org/abs/2510.07442)
*Harshvardhan C. Takawale,Nirupam Roy,Phil Brown*

Main category: cs.SD

TL;DR: INFER：一种用于密闭共振环境（如汽车座舱）的隐式神经频率响应场方法，通过端到端频率域前向模型直接学习3D空间中的频率响应场，显著降低了幅度和相位重构误差。


<details>
  <summary>Details</summary>
Motivation: 当前的空间声学建模方法在密闭共振环境（如汽车座舱）中存在手动调谐、硬件密集、静态建模等问题，无法处理频率选择性行为和乘客存在等动态变化。

Method: 提出INFER框架，包含三个关键创新：1）端到端频率域前向模型直接学习3D空间中的频率响应场；2）感知和硬件感知的频谱监督，强调关键听觉频带；3）基于物理的Kramers-Kronig一致性约束，正则化频率相关衰减和延迟。

Result: 在多个真实汽车座舱数据集上的评估显示，该方法显著优于时域和混合域基线方法，幅度和相位重构误差分别降低了39%和51%。

Conclusion: INFER为汽车空间中的神经声学建模设立了新的最先进水平，能够有效处理密闭共振环境中的复杂声学特性。

Abstract: Accurate modeling of spatial acoustics is critical for immersive and
intelligible audio in confined, resonant environments such as car cabins.
Current tuning methods are manual, hardware-intensive, and static, failing to
account for frequency selective behaviors and dynamic changes like passenger
presence or seat adjustments. To address this issue, we propose INFER: Implicit
Neural Frequency Response fields, a frequency-domain neural framework that is
jointly conditioned on source and receiver positions, orientations to directly
learn complex-valued frequency response fields inside confined, resonant
environments like car cabins. We introduce three key innovations over current
neural acoustic modeling methods: (1) novel end-to-end frequency-domain forward
model that directly learns the frequency response field and frequency-specific
attenuation in 3D space; (2) perceptual and hardware-aware spectral supervision
that emphasizes critical auditory frequency bands and deemphasizes unstable
crossover regions; and (3) a physics-based Kramers-Kronig consistency
constraint that regularizes frequency-dependent attenuation and delay. We
evaluate our method over real-world data collected in multiple car cabins. Our
approach significantly outperforms time- and hybrid-domain baselines on both
simulated and real-world automotive datasets, cutting average magnitude and
phase reconstruction errors by over 39% and 51%, respectively. INFER sets a new
state-of-the-art for neural acoustic modeling in automotive spaces

</details>


### [21] [ACMID: Automatic Curation of Musical Instrument Dataset for 7-Stem Music Source Separation](https://arxiv.org/abs/2510.07840)
*Ji Yu,Yang shuo,Xu Yuetonghui,Liu Mengmei,Ji Qiang,Han Zerui*

Main category: cs.SD

TL;DR: 提出了ACMID数据集，通过网页爬取和自动清理生成音乐源分离数据，将传统4音轨分离扩展到7音轨，显著提升了分离性能。


<details>
  <summary>Details</summary>
Motivation: 当前音乐源分离方法依赖监督学习，受限于训练数据的数量和质量。网页爬取数据存在元数据不匹配问题，阻碍准确获取音频-标签对。

Method: 通过网页爬取获取大量原始数据，使用基于预训练音频编码器的乐器分类器自动清理，过滤和聚合目标乐器的干净片段，生成ACMID-Cleaned数据集。

Result: 使用ACMID-Cleaned训练的模型比使用未清理数据提升了2.39dB的SDR性能；将该数据集加入训练使模型平均性能提升1.16dB。

Conclusion: ACMID数据集通过自动清理有效解决了网页爬取数据的质量问题，扩展了音轨分离的粒度，显著提升了音乐源分离系统的性能。

Abstract: Most current music source separation (MSS) methods rely on supervised
learning, limited by training data quantity and quality. Though web-crawling
can bring abundant data, platform-level track labeling often causes metadata
mismatches, impeding accurate "audio-label" pair acquisition. To address this,
we present ACMID: a dataset for MSS generated through web crawling of extensive
raw data, followed by automatic cleaning via an instrument classifier built on
a pre-trained audio encoder that filters and aggregates clean segments of
target instruments from the crawled tracks, resulting in the refined
ACMID-Cleaned dataset. Leveraging abundant data, we expand the conventional
classification from 4-stem (Vocal/Bass/Drums/Others) to 7-stem
(Piano/Drums/Bass/Acoustic Guitar/Electric Guitar/Strings/Wind-Brass), enabling
high granularity MSS systems. Experiments on SOTA MSS model demonstrates two
key results: (i) MSS model trained with ACMID-Cleaned achieved a 2.39dB
improvement in SDR performance compared to that with ACMID-Uncleaned,
demostrating the effectiveness of our data cleaning procedure; (ii)
incorporating ACMID-Cleaned to training enhances MSS model's average
performance by 1.16dB, confirming the value of our dataset. Our data crawling
code, cleaning model code and weights are available at:
https://github.com/scottishfold0621/ACMID.

</details>


### [22] [IntMeanFlow: Few-step Speech Generation with Integral Velocity Distillation](https://arxiv.org/abs/2510.07979)
*Wei Wang,Rong Cao,Yi Guo,Zhengyang Chen,Kuan Chen,Yuanyuan Huo*

Main category: cs.SD

TL;DR: IntMeanFlow是一种用于少步语音生成的框架，通过积分速度蒸馏消除Jacobian-vector products和自举过程，提高训练稳定性并减少GPU内存使用。


<details>
  <summary>Details</summary>
Motivation: 基于流的生成模型在文本到语音合成中质量优秀，但推理速度受限于迭代采样过程和多次函数评估。MeanFlow模型通过建模平均速度加速生成，但在TTS应用中面临GPU内存开销和训练不稳定的挑战。

Method: 提出IntMeanFlow框架，通过用教师在时间间隔上的瞬时速度近似平均速度，消除JVP和自举需求。同时提出最优步长采样搜索算法(O3S)，识别模型特定的最优采样步长。

Result: IntMeanFlow在token到频谱图任务中实现1-NFE推理，在文本到频谱图任务中实现3-NFE推理，同时保持高质量的语音合成。

Conclusion: IntMeanFlow通过积分速度蒸馏和最优步长采样，显著提高了基于流模型的TTS生成效率，同时保持合成质量。

Abstract: Flow-based generative models have greatly improved text-to-speech (TTS)
synthesis quality, but inference speed remains limited by the iterative
sampling process and multiple function evaluations (NFE). The recent MeanFlow
model accelerates generation by modeling average velocity instead of
instantaneous velocity. However, its direct application to TTS encounters
challenges, including GPU memory overhead from Jacobian-vector products (JVP)
and training instability due to self-bootstrap processes. To address these
issues, we introduce IntMeanFlow, a framework for few-step speech generation
with integral velocity distillation. By approximating average velocity with the
teacher's instantaneous velocity over a temporal interval, IntMeanFlow
eliminates the need for JVPs and self-bootstrap, improving stability and
reducing GPU memory usage. We also propose the Optimal Step Sampling Search
(O3S) algorithm, which identifies the model-specific optimal sampling steps,
improving speech synthesis without additional inference overhead. Experiments
show that IntMeanFlow achieves 1-NFE inference for token-to-spectrogram and
3-NFE for text-to-spectrogram tasks while maintaining high-quality synthesis.
Demo samples are available at https://vvwangvv.github.io/intmeanflow.

</details>


### [23] [Personality-Enhanced Multimodal Depression Detection in the Elderly](https://arxiv.org/abs/2510.08004)
*Honghong Wang,Jing Deng,Rong Zheng*

Main category: cs.SD

TL;DR: 提出了一种融合人格特征的多模态老年人抑郁症检测模型，通过多特征融合和交互模块提升检测性能


<details>
  <summary>Details</summary>
Motivation: 认识到人格特征在抑郁症检测中的关键作用，特别是在老年人群中，需要有效整合多模态信息和人格特质

Method: 使用基于共注意力机制的多特征融合方法整合音频模态的LLDs、MFCCs和Wav2Vec特征；视频模态结合OpenFace、ResNet和DenseNet特征；设计交互模块捕捉人格特质与多模态特征的关系

Result: 在MPDD老年人抑郁症检测赛道上的实验结果表明，该方法显著提升了性能

Conclusion: 该方法为老年人多模态抑郁症检测的后续研究提供了有价值的见解

Abstract: This paper presents our solution to the Multimodal Personality-aware
Depression Detection (MPDD) challenge at ACM MM 2025. We propose a multimodal
depression detection model in the Elderly that incorporates personality
characteristics. We introduce a multi-feature fusion approach based on a
co-attention mechanism to effectively integrate LLDs, MFCCs, and Wav2Vec
features in the audio modality. For the video modality, we combine
representations extracted from OpenFace, ResNet, and DenseNet to construct a
comprehensive visual feature set. Recognizing the critical role of personality
in depression detection, we design an interaction module that captures the
relationships between personality traits and multimodal features. Experimental
results from the MPDD Elderly Depression Detection track demonstrate that our
method significantly enhances performance, providing valuable insights for
future research in multimodal depression detection among elderly populations.

</details>


### [24] [Attribution-by-design: Ensuring Inference-Time Provenance in Generative Music Systems](https://arxiv.org/abs/2510.08062)
*Fabio Morreale,Wiebke Hutiri,Joan Serrà,Alice Xiang,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: 本文提出了一个针对AI生成音乐的补偿框架，通过区分训练集和推理集，采用推理时归因机制实现直接、可验证的艺术家补偿。


<details>
  <summary>Details</summary>
Motivation: AI生成音乐的兴起稀释了版税池，暴露了现有补偿框架的结构性缺陷，需要建立可扩展且技术严谨的解决方案。

Method: 区分训练集和推理集，提出训练时归因和推理时归因两种互补形式，重点采用推理时归因机制，允许在艺术家作品被用于条件生成时提供直接可验证的补偿。

Result: 该框架为艺术家和权利持有人提供了直接归因、透明版税分配和细粒度控制，同时用户也能获得关于归因和使用权限的透明信息。

Conclusion: 该方案为AI生成音乐时代提供了伦理和实用的补偿机制，确保来源和公平性嵌入生成系统的核心。

Abstract: The rise of AI-generated music is diluting royalty pools and revealing
structural flaws in existing remuneration frameworks, challenging the
well-established artist compensation systems in the music industry. Existing
compensation solutions, such as piecemeal licensing agreements, lack
scalability and technical rigour, while current data attribution mechanisms
provide only uncertain estimates and are rarely implemented in practice. This
paper introduces a framework for a generative music infrastructure centred on
direct attribution, transparent royalty distribution, and granular control for
artists and rights' holders. We distinguish ontologically between the training
set and the inference set, which allows us to propose two complementary forms
of attribution: training-time attribution and inference-time attribution. We
here favour inference-time attribution, as it enables direct, verifiable
compensation whenever an artist's catalogue is used to condition a generated
output. Besides, users benefit from the ability to condition generations on
specific songs and receive transparent information about attribution and
permitted usage. Our approach offers an ethical and practical solution to the
pressing need for robust compensation mechanisms in the era of AI-generated
music, ensuring that provenance and fairness are embedded at the core of
generative systems.

</details>


### [25] [Detecting and Mitigating Insertion Hallucination in Video-to-Audio Generation](https://arxiv.org/abs/2510.08078)
*Liyang Chen,Hongkai Chen,Yujun Cai,Sifan Li,Qingwen Ye,Yiwei Wang*

Main category: cs.SD

TL;DR: 本文提出了视频到音频生成中的插入幻觉问题，开发了系统评估框架和两个新指标来量化该问题，并提出了一种无需训练的后验特征校正方法来有效缓解插入幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有视频到音频生成模型的评估指标只关注语义和时间对齐，但忽略了模型经常生成没有对应视觉源的声学事件（特别是语音和音乐）这一关键失败模式，即插入幻觉问题。

Method: 开发了基于多数投票集成多个音频事件检测器的系统评估框架，提出了IH@vid和IH@dur两个新指标，并设计了后验特征校正方法，该方法采用两阶段过程：首先生成初始音频检测幻觉段，然后屏蔽对应时间戳的视频特征重新生成音频。

Result: 实验显示最先进的V2A模型存在严重的插入幻觉问题，而PFC方法平均减少了超过50%的幻觉发生率和持续时间，且不降低甚至改善了传统音频质量和时间同步指标。

Conclusion: 本文首次正式定义、系统测量并有效缓解了插入幻觉问题，为开发更可靠和忠实的视频到音频模型铺平了道路。

Abstract: Video-to-Audio generation has made remarkable strides in automatically
synthesizing sound for video. However, existing evaluation metrics, which focus
on semantic and temporal alignment, overlook a critical failure mode: models
often generate acoustic events, particularly speech and music, that have no
corresponding visual source. We term this phenomenon Insertion Hallucination
and identify it as a systemic risk driven by dataset biases, such as the
prevalence of off-screen sounds, that remains completely undetected by current
metrics. To address this challenge, we first develop a systematic evaluation
framework that employs a majority-voting ensemble of multiple audio event
detectors. We also introduce two novel metrics to quantify the prevalence and
severity of this issue: IH@vid (the fraction of videos with hallucinations) and
IH@dur (the fraction of hallucinated duration). Building on this, we propose
Posterior Feature Correction, a novel training-free inference-time method that
mitigates IH. PFC operates in a two-pass process: it first generates an initial
audio output to detect hallucinated segments, and then regenerates the audio
after masking the corresponding video features at those timestamps. Experiments
on several mainstream V2A benchmarks first reveal that state-of-the-art models
suffer from severe IH. In contrast, our PFC method reduces both the prevalence
and duration of hallucinations by over 50\% on average, without degrading, and
in some cases even improving, conventional metrics for audio quality and
temporal synchronization. Our work is the first to formally define,
systematically measure, and effectively mitigate Insertion Hallucination,
paving the way for more reliable and faithful V2A models.

</details>


### [26] [Leveraging Whisper Embeddings for Audio-based Lyrics Matching](https://arxiv.org/abs/2510.08176)
*Eleonora Mancini,Joan Serrà,Paolo Torroni,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: 提出了WEALY，一个完全可复现的基于Whisper解码器嵌入的歌词匹配流水线，建立了稳健透明的基准，并探索了多模态扩展。


<details>
  <summary>Details</summary>
Motivation: 现有的音频歌词匹配方法存在可复现性有限和基准不一致的问题，需要建立一个可靠且透明的基准系统。

Method: 利用Whisper解码器嵌入构建歌词匹配流水线，探索文本和声学特征的多模态融合，进行消融研究和分析不同语言、损失函数和嵌入策略。

Result: 在标准数据集上的实验表明，WEALY达到了与缺乏可复现性的最先进方法相当的性能。

Conclusion: 这项工作为未来研究提供了可靠的基准，并强调了语音技术在音乐信息检索任务中的潜力。

Abstract: Audio-based lyrics matching can be an appealing alternative to other
content-based retrieval approaches, but existing methods often suffer from
limited reproducibility and inconsistent baselines. In this work, we introduce
WEALY, a fully reproducible pipeline that leverages Whisper decoder embeddings
for lyrics matching tasks. WEALY establishes robust and transparent baselines,
while also exploring multimodal extensions that integrate textual and acoustic
features. Through extensive experiments on standard datasets, we demonstrate
that WEALY achieves a performance comparable to state-of-the-art methods that
lack reproducibility. In addition, we provide ablation studies and analyses on
language robustness, loss functions, and embedding strategies. This work
contributes a reliable benchmark for future research, and underscores the
potential of speech technologies for music information retrieval tasks.

</details>

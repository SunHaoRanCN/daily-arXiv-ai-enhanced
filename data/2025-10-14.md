<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 32]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.SD](#cs.SD) [Total: 23]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Bluetooth Fingerprint Identification Under Domain Shift Through Transient Phase Derivative](https://arxiv.org/abs/2510.09940)
*Haytham Albousayri,Bechir Hamdaoui,Weng-Keen Wong,Nora Basha*

Main category: eess.SP

TL;DR: 提出了一种新颖的低成本域自适应特征提取方法，用于BLE设备的射频指纹识别，显著提高了跨环境和跨接收器的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 基于深度学习的射频指纹识别技术面临域变化的挑战，特别是BLE设备的跳频特性对RFFP的影响尚未被充分研究。

Method: 首次研究了BLE设备跳频效应对RFFP的影响，并提出了一种新颖的低成本域自适应特征提取方法。

Result: 与现有基准相比，该方法在跨环境下的分类准确率提高了58%，在跨接收器下的分类准确率提高了80%。

Conclusion: 该方法有效解决了BLE设备射频指纹识别中的域适应问题，为物理层安全技术提供了重要改进。

Abstract: Deep learning-based radio frequency fingerprinting (RFFP) has become an
enabling physical-layer security technology, allowing device identification and
authentication through received RF signals. This technology, however, faces
significant challenges when it comes to adapting to domain variations, such as
time, location, environment, receiver and channel. For Bluetooth Low Energy
(BLE) devices, addressing these challenges is particularly crucial due to the
BLE protocol's frequency-hopping nature. In this work, and for the first time,
we investigated the frequency hopping effect on RFFP of BLE devices, and
proposed a novel, low-cost, domain-adaptive feature extraction method. Our
approach improves the classification accuracy by up to 58\% across environments
and up to 80\% across receivers compared to existing benchmarks.

</details>


### [2] [Movable Antenna Enhanced Covert Dual-Functional Radar-Communication: Joint Beamforming and Antenna Position Optimization](https://arxiv.org/abs/2510.09949)
*Ran Yang,Zheng Dong,Peng Cheng,Lin Zhang,Wanting Lyu,Yue Xiu,Ning Wei,Chadi Assi*

Main category: eess.SP

TL;DR: 本文研究了基于可移动天线的双功能雷达通信系统，通过联合优化发射波束成形、接收滤波和天线布局，在满足雷达性能和传输隐蔽性约束下最大化通信和速率。


<details>
  <summary>Details</summary>
Motivation: 可移动天线技术能够灵活重构无线信道，为提升双功能雷达通信系统的性能提供了新机遇，特别是在确保通信安全方面具有潜力。

Method: 采用拉格朗日对偶变换将问题重构为更易处理的形式，然后使用块坐标下降算法，结合半定松弛、投影梯度下降和逐次凸逼近技术求解。

Result: 仿真结果表明，所提方法能显著提高隐蔽和速率，并利用可移动天线的灵活性在通信和雷达性能之间实现良好平衡。

Conclusion: 可移动天线技术能有效增强双功能雷达通信系统的性能，特别是在通信安全和系统性能平衡方面具有显著优势。

Abstract: Movable antenna (MA) has emerged as a promising technology to flexibly
reconfigure wireless channels by adjusting antenna placement. In this paper, we
study a dual-functional radar-communication (DFRC) system enhanced with movable
antennas. To ensure communication security, we aim to maximize the achievable
sum rate by jointly optimizing the transmit beamforming vectors, receiving
filter, and antenna placement, subject to radar signal-to-noise ratio (SNR)
performance and transmission covertness constraints. To tackle this challenging
optimization problem, we first employ a Lagrangian dual transformation process
to reformulate it into a more tractable form. Subsequently, the problem is
solved by introducing a block coordinate descent (BCD) algorithm, incorporating
semidefinite relaxation (SDR), projected gradient descent (PGD), and successive
convex approximation (SCA) techniques. Simulation results demonstrate that the
proposed method can significantly improve the covert sum rate, and achieve a
satisfactory balance between the communication and radar performance compared
with existing benchmark schemes by leveraging the flexibility of movable
antennas.

</details>


### [3] [Active IRS Assisted Joint Uplink and Downlink Communications](https://arxiv.org/abs/2510.10045)
*Qiaoyan Peng,Qingqing Wu,Guangji Chen,Wen Chen,Shaodan Ma*

Main category: eess.SP

TL;DR: 本文研究了有源智能反射面(AIRS)辅助的无线通信系统，通过联合优化基站波束成形、AIRS波束成形和AIRS单元分配来最大化上下行链路的加权和速率。


<details>
  <summary>Details</summary>
Motivation: 传统无源智能反射面(PIRS)存在双衰落效应，而有源智能反射面(AIRS)能够放大反射信号，克服这一限制，提升通信性能。

Method: 研究了三种部署方案：分布式AIRS、基站侧AIRS和用户侧AIRS。针对分布式AIRS，推导了最优和近似最优闭式解。对于多用户情况，考虑了用户自适应波束成形和静态波束成形两种方案，并开发了高效的交替优化算法。

Result: 数值结果表明，分布式AIRS相比被动IRS、基站侧AIRS和用户侧AIRS具有实际优势，并突显了动态IRS波束成形的益处。

Conclusion: 分布式有源智能反射面部署方案在无线通信系统中具有显著性能优势，动态波束成形策略能够有效平衡性能与复杂度。

Abstract: In this paper, we investigate an intelligent reflecting surface (IRS) aided
wireless communication system, where active IRSs (AIRSs) are deployed to assist
communication between a base station (BS) and users of both the uplink (UL) and
downlink (DL). We aim to maximize the weighted sum rate (WSR) of UL and DL
communications through joint optimization of BS, AIRS beamforming, and AIRS
element allocation. First, we study three deployment schemes, namely
distributed AIRSs, BS-side AIRS, and user-side AIRS. For distributed AIRSs,
both optimal and near-optimal solutions are derived in closed form. To draw
useful insights, we analytically compare the deployment schemes in terms of the
rate performance under the single-user setup. For the multi-user case, we
consider two beamforming setups at the distributed AIRSs to balance performance
and complexity tradeoffs. Regarding the user-adaptive AIRS beamforming,
different AIRS beamforming vectors are adopted for each user; while for the
static AIRS beamforming, all users share the same beamforming vectors, with
identical phase shifts but different amplitudes for UL and DL. With the
user-adaptive AIRS beamforming, we focus on the optimization of element
allocation for rate maximization. With static AIRS beamforming, we solve the
rate maximization problem by optimizing the BS transmit/receive beamformers,
user beamforming, and AIRS beamforming. Despite its non-convexity, we develop
an efficient alternating optimization (AO) based algorithm that solves each
sub-problem optimally. Numerical results validate the practical advantages of
distributed AIRSs compared to passive IRS (PIRS), BS-side AIRS, and user-side
AIRS, and highlight the benefits of dynamic IRS beamforming.

</details>


### [4] [MIMO Radar Meets Polarization-Reconfigurable Antennas: A BCRB Perspective](https://arxiv.org/abs/2510.10235)
*Jinpeng Xu,Shuowen Zhang*

Main category: eess.SP

TL;DR: 本文提出了一种基于相移极化可重构天线的MIMO雷达系统，通过联合优化发射协方差矩阵和收发相移向量来最小化贝叶斯克拉美罗下界，提高目标角度定位的估计性能。


<details>
  <summary>Details</summary>
Motivation: 传统MIMO雷达系统在目标角度定位估计方面性能有限，极化可重构天线提供了新的设计自由度，可以进一步提升雷达系统的感知性能。

Method: 推导了贝叶斯克拉美罗下界作为性能指标，提出了基于交替优化的联合优化算法，分别优化发射协方差矩阵和收发相移向量。

Result: 数值结果表明所提算法有效，能够显著提升目标角度定位的估计精度。

Conclusion: 基于极化可重构天线的MIMO雷达系统通过联合优化设计，能够充分利用极化自由度，显著改善目标定位性能。

Abstract: In this paper, we investigate a novel multiple-input multiple-output (MIMO)
radar system aided by phase shifter based polarization-reconfigurable antennas
(PRAs). Specifically, a base station (BS) equipped with multiple PRAs at both
the transmitter and the receiver aims to sense the unknown and random angular
location parameter of a point target via sending wireless signals and
processing the received echo signals reflected by the target, where only prior
distribution information about the location parameter is available for
exploitation. Firstly, we characterize the sensing performance of this novel
PRA-based MIMO radar system by deriving the Bayesian Cram\'er-Rao bound (BCRB)
of the mean-squared error (MSE) in estimating the desired location parameter
with prior distribution information. Then, to fully exploit the new design
degrees-of-freedom (DoF) empowered by PRAs, we study the joint optimization of
the transmit sample covariance matrix as well as the transmit and receive phase
shift vectors to minimize the sensing BCRB subject to a transmit power
constraint. This problem is non-convex and difficult to solve due to the
coupling among optimization variables. To resolve this issue, we develop an
alternating optimization (AO) based algorithm which iteratively obtains the
closed-form optimal solution to each variable with the others being fixed at
each time, thus being guaranteed to converge to at least a stationary point of
the joint optimization problem. Numerical results validate the effectiveness of
the proposed algorithm.

</details>


### [5] [Synchrosqueezed windowed linear canonical transform: A method for mode retrieval from multicomponent signals with crossing instantaneous frequencies](https://arxiv.org/abs/2510.10438)
*Shuixin Li,Jiecheng Chen,Qingtang Jiang,Jian Lu*

Main category: eess.SP

TL;DR: 提出了一种新颖的窗口线性正则变换(WLCT)，将二维时频表示提升为三维时频-调频率表示，并开发了相应的三维同步压缩变换，用于多分量非平稳信号的分离。


<details>
  <summary>Details</summary>
Motivation: 自然界中信号通常是多个非平稳信号的叠加，时频域中信号分量的重叠给信号分析带来挑战。需要引入额外的调频率参数来提升信号表示维度。

Method: 基于线性正则变换开发了四种WLCT，使用特殊的X射线变换来锐化时频-调频率表示，并推导了相应的三维同步压缩变换。

Result: WLCT提供了新的三维时频-调频率表示，能够有效处理信号分量在时频域重叠的问题。

Conclusion: WLCT在三维信号分离方面具有巨大潜力，为多分量非平稳信号分析提供了有效的工具。

Abstract: In nature, signals often appear in the form of the superposition of multiple
non-stationary signals. The overlap of signal components in the time-frequency
domain poses a significant challenge for signal analysis. One approach to
addressing this problem is to introduce an additional chirprate parameter and
use the chirplet transform (CT) to elevate the two-dimensional time-frequency
representation to a three-dimensional time-frequency-chirprate representation.
From a certain point of view, the CT of a signal can be regarded as a windowed
special linear canonical transform of that signal, undergoing a shift and a
modulation.
  In this paper, we develop this idea to propose a novel windowed linear
canonical transform (WLCT), which provides a new time-frequency-chirprate
representation. We discuss four types of WLCTs. In addition, we use a special
X-ray transform to further sharpen the time-frequency-chirprate representation.
Furthermore, we derive the corresponding three-dimensional synchrosqueezed
transform, demonstrating that the WLCTs have great potential for
three-dimensional signal separation.

</details>


### [6] [Multi-Carrier Rydberg Atomic Quantum Receivers with Enhanced Bandwidth Feature for Communication and Sensing](https://arxiv.org/abs/2510.10473)
*Huizhi Wang,Tierui Gong,Emil Björnson,Chau Yuen*

Main category: eess.SP

TL;DR: 本文提出了一种五能级多载波里德堡原子量子接收器(MC-RAQR)，通过克服传统RAQR的瞬时带宽限制，实现了14MHz带宽，比传统RAQR提高56倍，显著提升了多载波通信和感知性能。


<details>
  <summary>Details</summary>
Motivation: 传统里德堡原子量子接收器(RAQR)虽然对弱信号具有超高灵敏度，但由于原子能级的离散性和固有瞬时带宽限制，无法准确接收宽带射频信号，这限制了其在多载波通信和感知中的应用。

Method: 提出五能级多载波里德堡原子量子接收器(MC-RAQR)结构，推导其幅度和相位响应，提取基带电信号进行处理，并分析多载波通信的信道容量以及到达角(AoA)和距离参数的感知精度。

Result: MC-RAQR可实现14MHz带宽，比传统RAQR提高56倍。信道容量分别比传统天线和RAQR提高22倍和3倍。AoA估计的MSE仅为传统RAQR的0.16%，距离估计的MSE仅为传统天线CRB的0.01%。

Conclusion: MC-RAQR与OFDM等波形兼容，在多载波信号接收方面具有显著优势，显著提升了多目标感知的分辨率和通信性能。

Abstract: Rydberg atomic quantum receivers (RAQRs) have attracted significant attention
in recent years due to their ultra-high sensitivity. Although capable of
precisely detecting the amplitude and phase of weak signals, conventional RAQRs
face inherent limitations in accurately receiving wideband RF signals, due to
the discrete nature of atomic energy levels and their intrinsic instantaneous
bandwidth constraints. These limitations hinder their direct application to
multi-carrier communication and sensing. To address this issue, this paper
proposes a multi-carrier Rydberg atomic quantum receiver (MC-RAQR) structure
with five energy levels. We derive the amplitude and phase of the MC-RAQR and
extract the baseband electrical signal for signal processing. In terms of
multi-carrier communication and sensing, we analyze the channel capacity and
accuracy of angle of arrival (AoA) and distance parameters, respectively.
Numerical results validate our proposed model, showing that the MC-RAQR can
achieve up to a bandwidth of 14 MHz, which is 56-fold larger than the
conventional RAQRs. As a result, the channel capacity and the resolution for
multi-target sensing are improved significantly. Specifically, the channel
capacity of MC-RAQR is 22-fold and 3-fold larger than the conventional antennas
and RAQRs, respectively. For sensing performance, the MSE of AoA estimation for
MC-RAQR is 0.16% of the conventional RAQR and the MSE of distance estimation is
0.01% of the CRB of conventional antennas, showing the superior performance of
the MC-RAQR. This demonstrates its compatibility with waveforms such as
orthogonal frequency-division multiplexing (OFDM) and its significant
advantages for multi-carrier signal reception.

</details>


### [7] [Graph Signal Wiener Filtering in the Linear Canonical Domain: Theory and Method Design](https://arxiv.org/abs/2510.10512)
*Xiaopeng Cheng,Zhichao Zhang*

Main category: eess.SP

TL;DR: 提出可训练的联合优化框架，将图线性正则变换参数和维纳滤波结合到端到端学习过程中，实现变换域构建与滤波操作的协同优化。


<details>
  <summary>Details</summary>
Motivation: 解决传统GLCT滤波方法中变换参数和滤波器分开优化导致的高计算成本和有限稳定性问题。

Method: 构建端到端学习框架，联合优化GLCT变换参数和维纳滤波器，消除传统网格搜索需求。

Result: 在真实图数据上的实验表明，该方法在去噪任务中优于现有方法，具有更好的去噪性能、更高的鲁棒性和更低的计算复杂度。

Conclusion: 提出的联合优化框架显著提高了滤波系统的灵活性和训练稳定性，在保持高性能的同时降低了计算成本。

Abstract: The graph linear canonical transform (GLCT)-based filtering methods often
optimize transform parameters and filters separately, which results in high
computational costs and limited stability. To address this issue, this paper
proposes a trainable joint optimization framework that combines GLCT parameters
and Wiener filtering into an end-to-end learning process, allowing for
synergistic optimization between transform domain construction and filtering
operations. The proposed method not only eliminates the cumbersome grid search
required by traditional strategies but also significantly enhances the
flexibility and training stability of the filtering system. Experimental
results on real-world graph data show the proposed method outperforms existing
methods in denoising tasks, featuring superior denoising performance, higher
robustness and lower computational complexity.

</details>


### [8] [SVD-based ugmt-gft on directed product graphs](https://arxiv.org/abs/2510.10532)
*Guoyun Xie,Zhichao Zhang*

Main category: eess.SP

TL;DR: 提出基于统一图表示矩阵(UGRM)的广义图傅里叶变换方法，通过SVD分解为有向图和笛卡尔积图提供灵活的频谱分析框架，显著优于传统固定矩阵方法。


<details>
  <summary>Details</summary>
Motivation: 传统有向图信号处理依赖固定表示矩阵，其刚性结构限制了模型适应复杂图拓扑的能力，需要更灵活的表示方法。

Method: 使用参数化UGRM结合SVD分解，定义广义图傅里叶变换，并扩展到笛卡尔积图的两种实现方式：直接对复合矩阵SVD和分别对因子图SVD后组合。

Result: 理论分析确认了方法对参数的单调性，真实数据集实验显示在去噪任务中显著优于传统方法，特别是在信噪比和带宽效率方面。

Conclusion: UGRM-GFT方法为有向图和笛卡尔积图提供了灵活高效的频谱分析工具，突破了传统固定矩阵的限制。

Abstract: Traditional directed graph signal processing generally depends on fixed
representation matrices, whose rigid structures limit the model's ability to
adapt to complex graph topologies. To address this issue, this study employed
the unified graph representation matrix (UGRM) to propose a generalized graph
Fourier transform (UGRM-GFT) method based on singular value decomposition (SVD)
for signal analysis on directed graphs and Cartesian product graphs. We defined
UGRM-GFT for general directed graphs by introducing a parameterized UGRM that
incorporates traditional representations such as the Laplacian matrix and
adjacency matrix. The SVD is used to construct spectral transform pairs with
both left and right singular vectors. We extended this approach to two types of
UGRM-GFTs applied to directed Cartesian product graphs. UGRM-GFT-I performs SVD
directly on the composite UGRM matrix of the two-dimensional graph structure,
suitable for globally coupled graph signals. UGRM-GFT-II separately applies SVD
to the UGRMs of the two-factor graphs and then combines the results,
significantly reducing computational complexity while preserving spectral
expressiveness. Theoretical analysis confirmed the monotonicity of the proposed
method with respect to the parameters alpha and k embedded in the UGRM.
Experimental results on real-world datasets demonstrated that the proposed
method significantly outperforms traditional fixed-matrix approaches in
denoising tasks, with a particular emphasis on signal-to-noise ratio and
bandwidth efficiency.

</details>


### [9] [Data Integration Using Multivariate Mode Decomposition for Physiological Sensing with Multiple Millimeter-Wave Radar Systems](https://arxiv.org/abs/2510.10542)
*Kimitaka Sumi,Takuya Sakamoto*

Main category: eess.SP

TL;DR: 提出了一种多雷达系统，用于任意身体方向下的非接触式生理感知，通过整合不同雷达视角的信号来稳定测量呼吸。


<details>
  <summary>Details</summary>
Motivation: 解决单雷达系统在身体方向变化时呼吸测量不稳定的问题，提高非接触式生理监测的鲁棒性。

Method: 采用多雷达系统，使用多元变分模态分解方法从不同雷达视角提取共同的呼吸成分。

Result: 相比单雷达系统，呼吸间隔的均方根误差降低35.5%，呼吸率的平均绝对误差降低30.8%，准确率提高9.4个百分点。

Conclusion: 多雷达视角结合信号整合能够实现不受身体方向影响的稳定呼吸测量。

Abstract: This study proposes a multi-radar system for non-contact physiological
sensing across arbitrary body orientations. In integrating signals obtained
from different radar viewpoints, we adopt a multivariate variational mode
decomposition method to extract the common respiratory component. Experiments
conducted with six subjects under varying distances and orientations
demonstrate that, compared with a single-radar setup, the proposed system
reduced the root mean square error of the respiratory interval by 35.5%,
decreased the mean absolute error of the respiratory rate by 30.8%, and
improved accuracy by 9.4 percentage points. These results highlight that
combining multiple radar viewpoints with signal integration enables stable
respiratory measurement regardless of body orientation.

</details>


### [10] [Large Language Model-Empowered Channel Prediction and Predictive Beamforming for LEO Satellite Communications](https://arxiv.org/abs/2510.10561)
*Zhixiong Chen,Hyundong Shin,Arumugam Nallanathan,Jonathon Chambers*

Main category: eess.SP

TL;DR: 提出基于大语言模型的LEO卫星通信信道预测框架CPLLM和波束成形框架BFLLM，通过专用编码器将CSI数据映射到文本嵌入空间，利用LLM的泛化能力进行预测，并采用参数高效微调策略。


<details>
  <summary>Details</summary>
Motivation: 现有信道预测和预测性波束成形方法受限于模型泛化能力，难以适应时变无线传播环境。受大语言模型强大泛化和推理能力启发，探索其在LEO卫星通信中的应用。

Method: 设计专用CSI编码器将原始CSI数据映射到文本嵌入空间；引入CSI解码器同时预测多个未来时隙的CSI；采用LoRA参数高效微调策略；扩展框架BFLLM直接生成波束成形策略。

Result: 广泛的仿真结果验证了所提方法在LEO卫星通信信道预测和预测性波束成形方面的有效性。

Conclusion: 基于大语言模型的CPLLM和BFLLM框架能够有效解决LEO卫星通信中的信道预测和波束成形问题，展现了LLM在无线通信领域的应用潜力。

Abstract: Accurate channel prediction and effective beamforming are essential for low
Earth orbit (LEO) satellite communications to enhance system capacity and
enable high-speed connectivity. Most existing channel prediction and predictive
beamforming methods are limited by model generalization capabilities and
struggle to adapt to time-varying wireless propagation environments. Inspired
by the remarkable generalization and reasoning capabilities of large language
models (LLMs), this work proposes an LLM-based channel prediction framework,
namely CPLLM, to forecast future channel state information (CSI) for LEO
satellites based on historical CSI data. In the proposed CPLLM, a dedicated CSI
encoder is designed to map raw CSI data into the textual embedding space,
effectively bridging the modality gap and enabling the LLM to perform reliable
reasoning over CSI data. Additionally, a CSI decoder is introduced to
simultaneously predict CSI for multiple future time slots, substantially
reducing the computational burden and inference latency associated with the
inherent autoregressive decoding process of LLMs. Then, instead of training the
LLM from scratch, we adopt a parameter-efficient fine-tuning strategy, i.e.,
LoRA, for CPLLM, where the pretrained LLM remains frozen and trainable low-rank
matrices are injected into each Transformer decoder layer to enable effective
fine-tuning. Furthermore, we extend CPLLM to directly generate beamforming
strategies for future time slots based on historical CSI data, namely BFLLM.
This extended framework retains the same architecture as CPLLM, while
introducing a dedicated beamforming decoder to output beamforming strategies.
Finally, extensive simulation results validate the effectiveness of the
proposed approaches in channel prediction and predictive beamforming for LEO
satellite communications.

</details>


### [11] [Covert Waveform Design for Integrated Sensing and Communication System in Clutter Environment](https://arxiv.org/abs/2510.10563)
*Xuyang Zhao,Jiangtao Wang,Xinyu Zhang*

Main category: eess.SP

TL;DR: 提出了一种用于复杂杂波环境的ISAC系统隐蔽波形设计方法，通过联合优化发射波形和接收滤波器，在满足隐蔽性要求的同时最大化信杂噪比，实现高效的杂波抑制和协同雷达检测与无线通信。


<details>
  <summary>Details</summary>
Motivation: 在复杂杂波环境中设计既能满足隐蔽性要求，又能有效抑制杂波并实现可靠通信的ISAC系统波形，解决目标多普勒频移不确定性对系统鲁棒性的影响。

Method: 通过联合优化发射波形和接收滤波器，在波形设计中考虑通信信号元素间的相位差约束，以及能量约束、隐蔽约束和峰均比约束，将原始非凸优化问题转化为可处理的凸优化形式。

Result: 仿真结果表明，优化后的波形在复杂杂波环境中不仅满足隐蔽性要求，还实现了优越的目标检测性能，同时确保了可靠的通信，验证了所提方法的有效性。

Conclusion: 该方法成功解决了复杂杂波环境下的ISAC系统波形设计问题，在满足隐蔽性要求的同时实现了高效的杂波抑制和可靠通信，对多普勒频移不确定性的处理显著提升了系统鲁棒性。

Abstract: This paper proposes an integrated sensing and communication (ISAC) system
covert waveform design method for complex clutter environments, with the core
objective of maximizing the signal-to-clutter-plus-noise ratio (SCNR). The
design achieves efficient clutter suppression while meeting the covertness
requirement through joint optimization of the transmit waveform and receive
filter, enabling cooperative radar detection and wireless communication. This
study presents key innovations that explicitly address target Doppler shift
uncertainty, significantly enhancing system robustness against Doppler effects.
To ensure communication reliability, the method incorporates phase difference
constraints between communication signal elements in the waveform design, along
with energy constraint, covert constraint, and peak-to-average power ratio
(PAPR) constraint. The original non-convex optimization problem is transformed
into a tractable convex optimization form through convex optimization
technique. Simulation results demonstrate that the optimized waveform not only
satisfies the covertness requirement in complex clutter environment, but also
achieves superior target detection performance. It also ensures reliable
communication and confirms the effectiveness of propose method.

</details>


### [12] [A Parametric Power Model of Upper Mid-Band (FR3) Base Stations for 6G](https://arxiv.org/abs/2510.10647)
*Emanuele Peschiera,Sangbu Yun,Youngjoo Lee,Liesbet Van der Perre,François Rottenberg*

Main category: eess.SP

TL;DR: 该论文研究了6G网络中FR3频段基站的功耗特性，比较了混合波束成形和全数字波束成形的能效表现。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络研究对FR3频段（7-24 GHz）的关注增加，需要了解大规模天线基站架构的功耗特性及其与数据传输速率的关系。

Method: 建立了FR3基站功耗模型，包括数字和模拟信号处理、功率放大器、供电和冷却等模块在四个工作阶段（数据、信令、微睡眠和空闲）的功耗分析，比较了混合部分连接波束成形与全数字波束成形。

Result: 对于1024天线阵列，在30%负载下，当RF链数量≤64时，功率放大器消耗大部分功率；当RF链数量≥512时，数字和模拟处理功耗占主导。全数字波束成形中数字加模拟处理功耗是功率放大器的2-4倍。混合波束成形在下行链路实现1.3 Gbit/s/用户，能效比全数字波束成形提高1.4倍。

Conclusion: 混合波束成形在FR3频段基站中能够提供高数据速率的同时显著改善能效，是6G网络中有前景的技术方案。

Abstract: Increasing attention is given to the upper mid-band or Frequency Range 3
(FR3), from 7 to 24 GHz, in the research towards sixth-generation (6G)
networks. Promises of offering large data rates at favorable propagation
conditions are leading to novel FR3 base station (BS) architectures, with up to
thousands of antenna elements and radio-frequency (RF) chains. This work
investigates the power consumption of prospective FR3 BSs and its relation to
the delivered data rates. We model the power consumed by digital and analog
signal processing, power amplifiers (PAs), and supply and cooling during four
phases (data, signaling, micro-sleep, and idle) in downlink and uplink. Hybrid
partially-connected beamforming is compared to fully-digital one. Results show
that, for BS arrays with $1024$ antennas at $30\%$ of load, the PA consumes
most of the power when $64$ or less RF chains are utilized, while the digital
and analog processing consumption takes over when the number of RF chains is
$512$ or more. The digital plus analog processing consumes $2\times$ to
$4\times$ more than the PA for fully-digital beamforming. Hybrid beamforming
achieves $1.3$ Gbit/s/user in downlink while improving the energy efficiency by
$1.4\times$ compared to fully-digital beamforming.

</details>


### [13] [HYPERDOA: Robust and Efficient DoA Estimation using Hyperdimensional Computing](https://arxiv.org/abs/2510.10718)
*Rajat Bhattacharjya,Woohyeok Park,Arnab Sarkar,Hyunwoo Oh,Mohsen Imani,Nikil Dutt*

Main category: eess.SP

TL;DR: HYPERDOA是一种基于超维计算(HDC)的新型波达方向(DoA)估计器，在低信噪比条件下比现有方法准确度提高约35.39%，同时能耗降低约93%，适用于边缘设备的任务关键应用。


<details>
  <summary>Details</summary>
Motivation: 传统DoA估计方法在低信噪比条件下精度不足，而现代深度学习方法能耗高且不透明，不适合资源受限的安全关键系统。需要一种既准确又高效的解决方案。

Method: 采用超维计算框架，引入两种特征提取策略（均值空间滞后自相关和空间平滑），将DoA估计重新定义为模式识别问题，利用HDC对噪声的固有鲁棒性和透明代数操作。

Result: 在低信噪比相干源场景下，HYPERDOA比最先进方法准确度提高约35.39%，在嵌入式NVIDIA Jetson Xavier NX平台上比竞争神经基线能耗降低约93%。

Conclusion: HYPERDOA在准确性和效率方面的双重优势，使其成为边缘设备上任务关键应用的稳健可行解决方案。

Abstract: Direction of Arrival (DoA) estimation techniques face a critical trade-off,
as classical methods often lack accuracy in challenging, low signal-to-noise
ratio (SNR) conditions, while modern deep learning approaches are too
energy-intensive and opaque for resource-constrained, safety-critical systems.
We introduce HYPERDOA, a novel estimator leveraging Hyperdimensional Computing
(HDC). The framework introduces two distinct feature extraction strategies --
Mean Spatial-Lag Autocorrelation and Spatial Smoothing -- for its HDC pipeline,
and then reframes DoA estimation as a pattern recognition problem. This
approach leverages HDC's inherent robustness to noise and its transparent
algebraic operations to bypass the expensive matrix decompositions and
``black-box'' nature of classical and deep learning methods, respectively. Our
evaluation demonstrates that HYPERDOA achieves ~35.39% higher accuracy than
state-of-the-art methods in low-SNR, coherent-source scenarios. Crucially, it
also consumes ~93% less energy than competing neural baselines on an embedded
NVIDIA Jetson Xavier NX platform. This dual advantage in accuracy and
efficiency establishes HYPERDOA as a robust and viable solution for
mission-critical applications on edge devices.

</details>


### [14] [Spatially Filtered Sparse Bayesian Learning for Direction-of-Arrival Estimation with Leaky-Wave Antennas](https://arxiv.org/abs/2510.10796)
*R. Maydani,Y. Wang,J. Sarrazin,B. Ma*

Main category: eess.SP

TL;DR: 提出了一种空间滤波稀疏贝叶斯学习框架，用于解决漏波天线在相干源情况下的波达方向估计问题。


<details>
  <summary>Details</summary>
Motivation: 漏波天线提供了一种紧凑且成本效益高的波达方向估计替代方案，但在存在相干源时仍然具有挑战性。

Method: 根据漏波天线的频率波束扫描特性将视场划分为角度扇区，然后在每个扇区内解决贝叶斯逆问题，开发了网格和离网格稀疏贝叶斯学习公式。

Result: 仿真结果表明，该方法即使在相干源情况下也能实现稳健且准确的波达方向估计。

Conclusion: 所提出的空间滤波稀疏贝叶斯学习框架为漏波天线在相干源环境下的波达方向估计提供了有效的解决方案。

Abstract: Direction-of-arrival (DoA) estimation with leaky-wave antennas (LWAs) offers
a compact and cost-effective alternative to conventional antenna arrays but
remains challenging in the presence of coherent sources. To address this issue,
we propose a spatially filtered sparse Bayesian learning (SF-SBL) framework.
Firstly, the field of view (FoV) is divided into angular sectors according to
the frequency beam-scanning property of LWAs, and Bayesian inverse problems are
then solved within each sector to improve efficiency and reduce computational
cost. Both on-grid SBL and off-grid SBL formulations are developed. Simulation
results show that the proposed approach achieves robust and accurate DoA
estimation, even with coherent sources.

</details>


### [15] [Spatial Signal Focusing and Noise Suppression for Direction-of-Arrival Estimation in Large-Aperture 2D Arrays under Demanding Conditions](https://arxiv.org/abs/2510.10923)
*Xuyao Deng,Yong Dou,Kele Xu*

Main category: eess.SP

TL;DR: 提出了一种基于最优空间滤波器概念的空间信号聚焦与噪声抑制(SSFNS)算法，用于解决在低信噪比、单快拍、相干源和未知源数量等苛刻条件下的DOA估计问题。


<details>
  <summary>Details</summary>
Motivation: 传统DOA估计算法在苛刻条件下存在局限性：常规波束形成受旁瓣干扰，自适应方法和子空间算法在有限快拍或相干信号下性能下降，稀疏恢复方法在大阵列中计算复杂度高。

Method: 构建最优空间滤波器概念，将DOA估计问题转化为最优空间滤波器的求解问题，提出SSFNS算法框架来求解最优空间滤波器并获取DOA。

Result: 实验表明，该算法适用于大孔径二维阵列，在少快拍甚至单快拍、低信噪比、相干信号和未知信号数量等场景下，性能优于其他算法。

Conclusion: 基于最优空间滤波器概念的SSFNS算法能够有效解决苛刻条件下的DOA估计问题，特别适合大孔径二维阵列的应用场景。

Abstract: Direction-of-Arrival (DOA) estimation in sensor arrays faces limitations
under demanding conditions, including low signal-to-noise ratio,
single-snapshot scenarios, coherent sources, and unknown source counts.
Conventional beamforming suffers from sidelobe interference, adaptive methods
(e.g., MVDR) and subspace algorithms (e.g., MUSIC) degrade with limited
snapshots or coherent signals, while sparse-recovery approaches (e.g., L1-SVD)
incur high computational complexity for large arrays. In this article, we
construct the concept of the optimal spatial filter to solve the DOA estimation
problem under demanding conditions by utilizing the sparsity of spatial
signals. By utilizing the concept of the optimal spatial filter, we have
transformed the DOA estimation problem into a solution problem for the optimal
spatial filter. We propose the Spatial Signal Focusing and Noise Suppression
(SSFNS) algorithm, which is a novel DOA estimation framework grounded in the
theoretical existence of an optimal spatial filter, to solve for the optimal
spatial filter and obtain DOA. Through experiments, it was found that the
proposed algorithm is suitable for large aperture two-dimensional arrays and
experiments have shown that our proposed algorithm performs better than other
algorithms in scenarios with few snapshots or even a single snapshot, low
signal-to-noise ratio, coherent signals, and unknown signal numbers in
two-dimensional large aperture arrays.

</details>


### [16] [Dual-Waveguide Pinching Antennas for PLS: Parallel Placement or Orthogonal Placement?](https://arxiv.org/abs/2510.11044)
*Yang Lu,Xinke Xie,Yanqing Xu,Bo Ai,Octavia A. Dobre,Dusit Niyato*

Main category: eess.SP

TL;DR: 本文研究了夹持天线在物理层安全中的应用，通过优化天线布局和波束成形来最大化安全速率和能效。


<details>
  <summary>Details</summary>
Motivation: 夹持天线技术能够通过移动天线位置来大规模定制信道条件，利用这一特性来增强合法用户与窃听者之间的信道条件差异，从而提升物理层安全性能。

Method: 提出两阶段算法：第一阶段使用改进的粒子群优化算法（FeaPSO）优化夹持天线布局；第二阶段采用逐次凸近似方法优化波束成形和人工噪声向量。考虑了平行和正交两种波导布局策略。

Result: 数值结果表明所提算法有效，夹持天线能显著提高安全速率和能效，正交波导布局被证明是必要的。

Conclusion: 夹持天线技术能够有效增强物理层安全性能，特别是在双波导场景下，正交布局策略具有明显优势。

Abstract: Pinching antennas (PAs), as an emerging flexible-antenna technology, enables
movable PAs deployed along waveguides to customize channel conditions over a
large scale. This paper investigates an application of PAs to enable
physical-layer security (PLS) by enlarging the channel condition diversity
between legitimate users (LUs) and eavesdroppers (Eves). Particularly, we focus
on the dual-waveguide scenario, where the two waveguides employs multiple PAs
to serve multiple LUs in the presence of an Eve. Specifically, we consider two
waveguide placement strategies, i.e., parallel placement and orthogonal
placement. Meanwhile, we incorporate two channel models, i.e., in-waveguide
phase shifts, and in-waveguide phase shifts and attenuation. We formulate the
secure sum rate (SSR) and secure energy efficiency (SEE) maximization problems,
and propose a two-stage algorithm to solve them. The first stage adopts a
particle swarm optimization (PSO) method with an improved feasibility module,
termed FeaPSO, for PA placement, and the second stage employs the successive
convex approximate (SCA) method to optimize beamforming and artificial noise
vectors. Furthermore, we conduct numerical comparisons between the two
placement strategies in terms of average performance and a special case where
an Eve is positioned in front of LUs. Numerical results validate the
effectiveness of the proposed algorithm and demonstrate that PAs can
significantly improve both SSR and SEE. Additionally, the necessity of
orthogonal waveguide placement is explicitly verified.

</details>


### [17] [The Post-Electromagnetic Era: A Vision for Wireless Communication Beyond 6G](https://arxiv.org/abs/2510.11097)
*Shumaila Javaid,Nasir Saeed*

Main category: eess.SP

TL;DR: 论文提出了一种后6G通信的状态中心框架，通过操纵物理、生物和认知状态而非电磁波来传递信息，旨在超越传统电磁通信的物理和热力学限制。


<details>
  <summary>Details</summary>
Motivation: 电磁通信已接近其物理和热力学极限，频谱优化带来的性能提升越来越不可持续。有限的带宽、高频传播损耗以及能量与信息之间的固有权衡限制了6G及以后系统的可扩展性，这推动了对超越传统电磁传播的信息传输替代机制的研究。

Method: 引入状态中心框架，识别了后电磁时代的十个基础范式，定义了潜在的载体和交互机制，并制定了实现自组织、认知集成网络的研究路线图。

Result: 提出了能够统一物质、生命和智能的能量感知、自适应通信系统新类别，为超越频谱限制的通信范式建立了概念基础。

Conclusion: 这项工作为未来研究提供了基础，旨在实现超越频谱限制系统的通信范式，推动通信系统向能量感知、自适应方向发展，并在单一信息连续体中统一物质、生命和智能。

Abstract: Electromagnetic (EM) communication is nearing its physical and thermodynamic
limits, where further performance gains through spectrum optimization alone
have become increasingly unsustainable. Finite bandwidth, propagation loss at
higher frequencies, and the inherent trade-offs between energy and information
constrain the scalability of 6G and beyond systems. These limitations drive the
search for alternative mechanisms for information transfer beyond conventional
EM propagation. This work introduces a state-centric framework for post-6G
communication, in which information is conveyed by manipulating physical,
biological, and cognitive states rather than EM waves. It identifies ten
foundational paradigms that define potential carriers and interaction
mechanisms for the post-electromagnetic era and outlines a research roadmap
toward self-organizing, cognitively integrated networks. Together, these
developments envision a new class of communication systems that are
energy-aware, adaptive, and capable of uniting matter, life, and intelligence
within a single informational continuum. By establishing the conceptual basis
for this transition, the work provides a foundation for future research aimed
at realizing communication paradigms that transcend the limitations of
spectrum-bound systems.

</details>


### [18] [Navigating the Dual-Use Nature and Security Implications of Reconfigurable Intelligent Surfaces in Next-Generation Wireless Systems](https://arxiv.org/abs/2510.11113)
*Hetong Wang,Tiejun Lv,Yashuai Cao,Weicai Li,Jie Zeng,Pingmu Huang,Muhammad Khurram Khan*

Main category: eess.SP

TL;DR: 可重构智能表面(RIS)技术在增强无线通信系统的同时，其双重用途特性也带来了严重的安全风险。本文调查了RIS在下一代无线网络中的安全影响，揭示了被动-主动混合攻击等新型漏洞，并探讨了RIS在提升安全性和隐私保护方面的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着RIS技术在无线通信系统中的广泛应用，其双重用途特性既能为合法用户提供通信增强，也可能被攻击者利用来危害系统安全。需要全面了解RIS带来的安全风险与防护机会。

Method: 通过系统调查分析，识别RIS的双重用途特性，提出"被动-主动混合攻击"概念，分析各类RIS辅助攻击方式，并探讨AI驱动RIS网络中的对抗性扰动威胁。

Result: 揭示了RIS可被恶意重新配置用于窃听、中间人攻击、重放攻击、反射干扰和旁道攻击等安全威胁，同时发现攻击者可利用无线信道开放性在AI驱动的RIS网络中引入对抗性扰动。

Conclusion: RIS技术既带来安全风险也提供安全增强机会，需要开发强大的安全框架，通过跨层协作、先进对抗防御以及在安全与成本之间取得平衡来应对新兴威胁。

Abstract: Reconfigurable intelligent surface (RIS) technology offers significant
promise in enhancing wireless communication systems, but its dual-use potential
also introduces substantial security risks. This survey explores the security
implications of RIS in next-generation wireless networks. We first highlight
the dual-use nature of RIS, demonstrating how its communication-enhancing
capabilities can be exploited by adversaries to compromise legitimate users. We
identify a new class of security vulnerabilities termed ``passive-active hybrid
attacks,'' where RIS, despite passively handling signals, can be reconfigured
to actively engage in malicious activities, enabling various RIS-assisted
attacks, such as eavesdropping, man-in-the-middle (MITM), replay, reflection
jamming, and side-channel attacks. Furthermore, we reveal how adversaries can
exploit the openness of wireless channels to introduce adversarial
perturbations in artificial intelligence-driven RIS networks, disrupting
communication terminals and causing misclassifications or errors in RIS
reflection predictions. Despite these risks, RIS technology also plays a
critical role in enhancing security and privacy across radio frequency (RF) and
visible light communication (VLC) systems. By synthesizing current insights and
highlighting emerging threats, we provide actionable insights into cross-layer
collaboration, advanced adversarial defenses, and the balance between security
and cost. This survey provides a comprehensive overview of RIS technology's
security landscape and underscores the urgent need for robust security
frameworks in the development of future wireless systems.

</details>


### [19] [WiNPA: Wireless Neural Processing Architecture](https://arxiv.org/abs/2510.11150)
*Sai Xu,Yanan Du*

Main category: eess.SP

TL;DR: 提出无线神经处理架构(WiNPA)，通过无线和计算资源的联合优化来加速深度神经网络(DNN)的边缘推理。


<details>
  <summary>Details</summary>
Motivation: 填补无线通信与边缘智能之间的研究空白，通过无线与计算的细粒度集成来显著提升DNN推理性能。

Method: 探索数学建模、优化算法和统一硬件-软件平台等基础研究问题，并通过案例研究进行仿真验证。

Result: WiNPA能够有效加速DNN推理，展示了其工作流程和有效性。

Conclusion: WiNPA为加速边缘DNN推理提供了新视角，并讨论了关键研究方向以指导未来发展。

Abstract: This article presents a wireless neural processing architecture (WiNPA),
providing a novel perspective for accelerating edge inference of deep neural
network (DNN) workloads via joint optimization of wireless and computing
resources. WiNPA enables fine-grained integration of wireless communication and
edge computing, bridging the research gap between wireless and edge
intelligence and significantly improving DNN inference performance. To fully
realize its potential, we explore a set of fundamental research issues,
including mathematical modeling, optimization, and unified hardware--software
platforms. Additionally, key research directions are discussed to guide future
development and practical implementation. A case study demonstrates WiNPA's
workflow and effectiveness in accelerating DNN inference through simulations.

</details>


### [20] [CSI Prediction Using Diffusion Models](https://arxiv.org/abs/2510.11214)
*Mehdi Sattari,Javad Aliakbari,Alexandre Graell i Amat,Tommy Svensson*

Main category: eess.SP

TL;DR: 提出了一种基于扩散模型的概率性CSI预测框架，通过分解为时间编码器和扩散生成器，支持自回归和序列到序列两种推理方案，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统CSI获取面临高导频开销和信道老化问题，现有深度学习方法只能学习确定性映射，无法捕捉无线信道的随机性和多模态特性。

Method: 将CSI预测分解为时间编码器（提取信道动态）和基于扩散的生成器（生成未来CSI样本），探索了U-Net和Transformer架构，并使用DDIM调度降低复杂度。

Result: 大量仿真表明，基于扩散的模型在性能上显著优于现有最先进的基线方法。

Conclusion: 扩散模型为CSI预测提供了一种灵活的概率框架，能够有效捕捉信道的随机特性，具有优越的预测性能。

Abstract: Acquiring accurate channel state information (CSI) is critical for reliable
and efficient wireless communication, but challenges such as high pilot
overhead and channel aging hinder timely and accurate CSI acquisition. CSI
prediction, which forecasts future CSI from historical observations, offers a
promising solution. Recent deep learning approaches, including recurrent neural
networks and Transformers, have achieved notable success but typically learn
deterministic mappings, limiting their ability to capture the stochastic and
multimodal nature of wireless channels. In this paper, we introduce a novel
probabilistic framework for CSI prediction based on diffusion models, offering
a flexible design that supports integration of diverse prediction schemes. We
decompose the CSI prediction task into two components: a temporal encoder,
which extracts channel dynamics, and a diffusion-based generator, which
produces future CSI samples. We investigate two inference
schemes-autoregressive and sequence-to-sequence- and explore multiple diffusion
backbones, including U-Net and Transformer-based architectures. Furthermore, we
examine a diffusion-based approach without an explicit temporal encoder and
utilize the DDIM scheduling to reduce model complexity. Extensive simulations
demonstrate that our diffusion-based models significantly outperform
state-of-the-art baselines.

</details>


### [21] [Normalized Ambiguity Function Characteristics of OFDM, OTFS, AFDM, and CP-AFDM for ISAC](https://arxiv.org/abs/2510.11216)
*Hyeon Seok Rou,Giuseppe Thadeu Freitas de Abreu*

Main category: eess.SP

TL;DR: 本文对OFDM、OTFS、AFDM和CP-AFDM四种多载波波形的模糊函数特性进行了统一分析，为6G网络中集成感知与通信系统的波形设计提供了基准比较。


<details>
  <summary>Details</summary>
Motivation: 为未来6G网络中集成感知与通信系统提供波形选择的统一分析框架，解决现有波形在延迟-多普勒响应特性比较缺乏标准化方法的问题。

Method: 直接从离散时间定义获取各波形的模糊函数，通过理想分数插值增强，在归一化延迟-多普勒单位下评估3dB主瓣宽度、峰值旁瓣比和积分旁瓣比等指标。

Result: OFDM具有优异的延迟分辨率和旁瓣特性但多普勒响应较差，而先进波形在延迟和多普勒分辨率之间实现了更好的平衡，但旁瓣特性各异。

Conclusion: 建立了波形感知能力比较的一致基准，确认了已知行为模式，为ISAC设计提供了重要参考，并公开仿真代码以促进可重复性和未来研究。

Abstract: This paper presents a unified and system-agnostic analysis of the ambiguity
function (AF) characteristics of four representative multicarrier waveforms,
orthogonal frequency division multiplexing (OFDM), orthogonal time frequency
space (OTFS), affine frequency division multiplexing (AFDM), and chirp-permuted
AFDM (CP-AFDM), which are considered as key candidates for enabling integrated
sensing and communications (ISAC) in future sixth generation (6G) networks. The
AF of each waveform is obtained directly from its discrete-time definition and
enhanced via ideal fractional interpolation, enabling precise characterization
of its continuous-time delay-Doppler response. Two signaling modes are
examined: a communication-oriented case with random information symbols
suitable only for monostatic scenarios, and a sensing-oriented case with fixed
unimodular symbols suitable for general multi-static scenarios. Furthermore,
the AFs and the ambiguity metrics including the 3dB mainlobe width,
peak-to-sidelobe ratio (PSLR), and integrated sidelobe ratio (ISLR), are
evaluated in normalized delay-Doppler units, enabling direct translation to any
physical system configuration defined by bandwidth, sampling frequency, or
symbol duration, while ensuring straightforward and consistent comparison
across waveforms. The results establish a consistent benchmark for comparing
waveform sensing capabilities in ISAC design, consolidating known behaviors:
OFDM exhibits excellent delay resolution and sidelobe behavior but poor Doppler
response, whereas advanced waveforms achieve improved balance between delay and
Doppler resolution with varying sidelobe characteristics. The simulation code
of the smooth AFs, is openly shared to promote reproducibility and support
future ISAC waveform research.

</details>


### [22] [Two-Dimensional Graph Bi-Fractional Fourier Transform](https://arxiv.org/abs/2510.11279)
*Mingzhi Wang,Zhichao Zhang*

Main category: eess.SP

TL;DR: 提出了二维图双分数傅里叶变换(2D-GBFRFT)，为笛卡尔积图的因子图分配独立的分数阶，相比现有方法具有更好的适应性，在多种应用场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的二维图分数傅里叶变换(2D-GFRFT)对两个因子图使用相同的分数阶，限制了其对异构信号的适应性。

Method: 提出2D-GBFRFT，为笛卡尔积图的因子图分配独立分数阶并保持可分离性；建立了可逆性、酉性和指数可加性；开发了两种滤波方案：网格搜索的维纳式设计和联合优化变换阶次与对角谱滤波器的可微框架；还引入了与联合时间-顶点分数傅里叶变换(JFRFT)的混合插值方法。

Result: 在合成笛卡尔积图信号、真实时序图数据集和动态图像去模糊等领域的实验中，2D-GBFRFT始终优于2D-GBFRFT并增强了JFRFT。

Conclusion: 实验证实了2D-GBFRFT在图信号处理滤波中的多功能性和优越性能。

Abstract: Graph signal processing (GSP) advances spectral analysis on irregular
domains. However, existing two-dimensional graph fractional Fourier transform
(2D-GFRFT) employs a single fractional order for both factor graphs, thereby
limiting its adaptability to heterogeneous signals. We proposed the
two-dimensional graph bi-fractional Fourier transform (2D-GBFRFT), which
assigns independent fractional orders to the factor graphs of a Cartesian
product while preserving separability. We established invertibility, unitarity,
and index additivity, and developed two filtering schemes: a Wiener-style
design through grid search and a differentiable framework that jointly
optimizes transform orders and diagonal spectral filters. We further introduced
a hybrid interpolation with the joint time-vertex fractional Fourier transform
(JFRFT), controlled by a tunable parameter that balances the two methods. In
the domains of synthetic Cartesian product graph signals, authentic temporal
graph datasets, and dynamic image deblurring, 2D-GBFRFT consistently surpasses
2D-GFRFT and enhances JFRFT. Experimental results confirmed the versatility and
superior performance of 2D-GBFRFT for filtering in GSP.

</details>


### [23] [Channel-Aware Deep Learning for Superimposed Pilot Power Allocation and Receiver Design](https://arxiv.org/abs/2510.11294)
*Run Gu,Renjie Xie,Wei Xu,Zhaohui Yang,Kaibin Huang*

Main category: eess.SP

TL;DR: 提出了一种名为CaSIP的通道感知学习框架，通过联合优化导频-数据功率分配和接收机网络来消除导频数据干扰，在高速移动和低信噪比条件下显著提升吞吐量和信道估计精度。


<details>
  <summary>Details</summary>
Motivation: 传统叠加导频方案在多用户移动场景中面临导频和数据信号有效叠加与分离的挑战，特别是在信道快速变化的情况下。

Method: 利用信道路径增益信息，开发了用户特定、资源元素级的功率分配因子，并构建了包含显式信道估计和数据检测组件的深度神经网络接收机，通过嵌入生成器将路径增益数据投影到嵌入中并与信道估计网络的中间特征图融合。

Result: 仿真结果表明，CaSIP在总吞吐量和信道估计精度方面有效优于传统导频方案和最先进的叠加导频方案，特别是在高移动性和低信噪比条件下。

Conclusion: CaSIP框架通过联合优化功率分配和接收机设计，成功解决了叠加导频方案中的导频数据干扰问题，为多用户移动通信系统提供了有效的解决方案。

Abstract: Superimposed pilot (SIP) schemes face significant challenges in effectively
superimposing and separating pilot and data signals, especially in multiuser
mobility scenarios with rapidly varying channels. To address these challenges,
we propose a novel channel-aware learning framework for SIP schemes, termed
CaSIP, that jointly optimizes pilot-data power (PDP) allocation and a receiver
network for pilot-data interference (PDI) elimination, by leveraging channel
path gain information, a form of large-scale channel state information (CSI).
The proposed framework identifies user-specific, resource element-wise PDP
factors and develops a deep neural network-based SIP receiver comprising
explicit channel estimation and data detection components. To properly leverage
path gain data, we devise an embedding generator that projects it into
embeddings, which are then fused with intermediate feature maps of the channel
estimation network. Simulation results demonstrate that CaSIP efficiently
outperforms traditional pilot schemes and state-of-the-art SIP schemes in terms
of sum throughput and channel estimation accuracy, particularly under
high-mobility and low signal-to-noise ratio (SNR) conditions.

</details>


### [24] [A Dynamic Watermarking Technique for Matching Communication Addresses with Cars in a Visual Field](https://arxiv.org/abs/2510.11353)
*Woo-Hyun Ko,Jaewon Kim,Tzu-Hsiang Lin,Samin Moosavi,P. R. Kumar*

Main category: eess.SP

TL;DR: 提出了一种使用动态水印技术解决路边单元（RSU）无法将视频中的车辆与IP地址匹配的问题的方法。通过在车辆控制指令中叠加随机激励信号，RSU可以通过视频信号处理验证车辆身份。


<details>
  <summary>Details</summary>
Motivation: 智能路边单元需要向特定车辆发送紧急避让建议，但无法确定视频中的车辆对应哪个IP地址，这是车联网通信中的基础性开放问题。

Method: 采用动态水印技术，要求车辆在转向角或油门/刹车控制指令上叠加小幅度随机激励信号，并将该随机波形与IP地址一起发送给RSU。RSU通过视频流信号处理验证波形匹配，从而关联IP地址与车辆。

Result: 在实验室自动化车辆系统和实际两辆乘用车的现场测试中，动态水印方法使RSU能够成功区分目标车辆与其他附近车辆的通信。

Conclusion: 动态水印技术有效解决了车联网中车辆身份识别问题，为智能交通系统中的精确通信提供了可行方案。

Abstract: We consider a problem faced by an intelligent roadside unit (RSU) monitoring
a roadway by a video camera. Suppose the RSU notices that a particular car in
its visual field needs to execute a specific evasive maneuver to avoid danger.
It would like to send a packet addressed to that particular car with this
suggestion. The problem is that while all the cars are communicating with the
RSU, the RSU does not know which car in the video is associated with what IP
address. So, it does not know which IP address to send the packet to. Indeed,
the problem of matching addresses with cars in the visual field is a
fundamental open problem. We provide an active solution employing dynamic
watermarking that was originally developed for the security of cyber-physical
systems. This technique calls for a car to superpose a small random excitation
onto its actuation commands for steering angle or throttle/brake positions. The
car sends this random waveform to the RSU in a packet containing its IP
address. By signal processing of the video stream of a car at the RSU it can
verify whether it matches with the waveform in the packet and thereby
associates that the IP address of the packet with that car in the visual field.
The RSU thereby determines which IP address is associated with which car in its
visual field. We present two demonstrations of performance. We demonstrate
experimental results on a laboratory transportation automated vehicles, a
vision system, and a network, as well as on the field with two passenger sedans
in practice. The results demonstrate that employing the dynamic watermarking
method enables an RSU to distinguish the communication of a target vehicle from
that of other IP addresses of nearby vehicles.

</details>


### [25] [CIRSense: Rethinking WiFi Sensing with Channel Impulse Response](https://arxiv.org/abs/2510.11374)
*Ruiqi Kong,He Chen*

Main category: eess.SP

TL;DR: CIRSense是一个基于信道冲激响应(CIR)的WiFi感知框架，通过利用CIR在延迟域的优势来提升WiFi感知的性能和可解释性，在呼吸监测和距离估计等任务中表现优于现有基于CSI的方法。


<details>
  <summary>Details</summary>
Motivation: 现有WiFi感知方法直接从CSI估计运动信息，但忽视了CIR在延迟域表示中的优势——能够自然集中运动能量并分离多径分量，从而实现更直观和原理性的运动感知。

Method: 提出了CIRSense框架，基于新的运动模型来表征分数延迟效应，解决了CIR感知中的三个关键技术挑战：硬件失真补偿、高分辨率距离估计以及用于扩展范围感知的子载波聚合。

Result: 在160 MHz信道带宽下，CIRSense通过双模式设计实现了多功能感知能力：呼吸监测平均误差约0.25 bpm，距离估计平均误差0.09 m。在20米挑战性距离下，比现有CSI基线方法准确度提高至少3倍，计算效率提高4.5倍以上。

Conclusion: CIRSense证明了CIR在WiFi感知中的显著优势，通过理论模型和技术创新解决了CIR感知的关键挑战，在多种场景下都展现出优于现有方法的性能。

Abstract: WiFi sensing based on channel state information (CSI) collected from
commodity WiFi devices has shown great potential across a wide range of
applications, including vital sign monitoring and indoor localization. Existing
WiFi sensing approaches typically estimate motion information directly from
CSI. However, they often overlook the inherent advantages of channel impulse
response (CIR), a delay-domain representation that enables more intuitive and
principled motion sensing by naturally concentrating motion energy and
separating multipath components. Motivated by this, we revisit WiFi sensing and
introduce CIRSense, a new framework that enhances the performance and
interpretability of WiFi sensing with CIR. CIRSense is built upon a new motion
model that characterizes fractional delay effects, a fundamental challenge in
CIR-based sensing. This theoretical model underpins technical advances for the
three challenges in WiFi sensing: hardware distortion compensation,
high-resolution distance estimation, and subcarrier aggregation for extended
range sensing. CIRSense, operating with a 160 MHz channel bandwidth,
demonstrates versatile sensing capabilities through its dual-mode design,
achieving a mean error of approximately 0.25 bpm in respiration monitoring and
0.09 m in distance estimation. Comprehensive evaluations across residential
spaces, far-range scenarios, and multi-target settings demonstrate CIRSense's
superior performance over state-of-the-art CSI-based baselines. Notably, at a
challenging sensing distance of 20 m, CIRSense achieves at least 3x higher
average accuracy with more than 4.5x higher computational efficiency.

</details>


### [26] [Uncertainty Propagation in Finite Impulse Response Filters: Evaluating the Gaussian Assumption](https://arxiv.org/abs/2510.11384)
*Jennie Couchman,Phillip Stanley-Marbell*

Main category: eess.SP

TL;DR: 本文分析了FIR滤波器在均匀分布量化噪声下的输出响应，发现输出不确定性不能假设为高斯分布，但高斯估计在某些应用中仍可能有用。


<details>
  <summary>Details</summary>
Motivation: 信号处理中通常假设数据符合高斯分布，但FIR滤波器等线性操作会产生加权和，使得随机变量的分布不再相同。本文旨在研究FIR滤波器在均匀分布量化噪声下的输出不确定性特性。

Method: 通过数学分析表达FIR输出不确定性与其输入量化不确定性和滤波器系数的关系，并进行详细的数值模拟来验证理论分析。

Result: 研究表明FIR滤波器的输出不确定性不能假设为高斯分布，但可以通过其最主要系数来估计输出不确定性分布。

Conclusion: 虽然FIR滤波器的输出噪声不能假设为高斯分布，但在某些应用场景下高斯估计仍然有用，且输出不确定性分布可以通过主导系数进行估计。

Abstract: A common assumption in signal processing is that underlying data numerically
conforms to a Gaussian distribution. It is commonly utilized in signal
processing to describe unknown additive noise in a system and is often
justified by citing the central limit theorem for sums of random variables,
although the central limit theorem applies only to sums of independent
identically distributed random variables. However, many linear operations in
signal processing take the form of weighted sums, which transforms the random
variables such that their distributions are no longer identical. One such
operation is a finite impulse response (FIR) filter. FIR filters are commonly
used in signal processing applications as a pre-processing step. FIR output
noise is generally assumed to be Gaussian. This article examines the FIR output
response in the presence of uniformly distributed quantization noise. We
express the FIR output uncertainty in terms of the input quantization
uncertainty and filter coefficients. We show that the output uncertainty cannot
be assumed to be Gaussian, but depending on the application a Gaussian
estimation may still be useful. Then, we show through detailed numerical
simulations that the output uncertainty distribution of the filter can be
estimated through its most dominant coefficients.

</details>


### [27] [Thermal Analysis of 3D GPU-Memory Architectures with Boron Nitride Interposer](https://arxiv.org/abs/2510.11461)
*Eric Han Wang,Weijia Yan,Ruihong Huang*

Main category: eess.SP

TL;DR: 该研究将电绝缘且导热性好的六方氮化硼(h-BN)中介层集成到AI芯片中，用于3D堆叠设计的有效热管理，相比硅中介层实现了热点温度降低20°C的显著改善。


<details>
  <summary>Details</summary>
Motivation: 随着AI芯片功能增强，传统硅基板的热管理能力在3D堆叠设计中变得不足，需要寻找更有效的热管理解决方案。

Method: 使用COMSOL Multiphysics研究高带宽内存(HBM)分布和热界面材料配置对散热和热点缓解的影响，并集成h-BN中介层。

Result: 使用h-BN中介层相比硅中介层实现了热点温度降低20°C，可使AI芯片的功率泄漏减少22%，显著提升热性能。

Conclusion: h-BN中介层为3D堆叠AI芯片提供了有效的热管理解决方案，能够显著降低热点温度并改善整体热性能。

Abstract: As artificial intelligence (AI) chips become more powerful, the thermal
management capabilities of conventional silicon (Si) substrates become
insufficient for 3D-stacked designs. This work integrates electrically
insulative and thermally conductive hexagonal boron nitride (h-BN) interposers
into AI chips for effective thermal management. Using COMSOL Multiphysics, the
effects of High-Bandwidth Memory (HBM) distributions and thermal interface
material configurations on heat dissipation and hotspot mitigation were
studied. A 20 {\deg}C reduction in hot spots was achieved using h-BN
interposers compared to Si interposers. Such an improvement could reduce AI
chips' power leakage by 22% and significantly enhance their thermal
performance.

</details>


### [28] [Control Requirements for Robust Beamforming in Multi-Satellite Systems](https://arxiv.org/abs/2510.11465)
*Diego Tuzi,Thomas Delamotte,Andreas Knopp*

Main category: eess.SP

TL;DR: 该研究分析了位置和姿态扰动对多卫星系统波束成形性能的影响，发现性能对扰动高度敏感，但通过将位置和姿态信息整合到波束成形过程中可以有效恢复标称性能。


<details>
  <summary>Details</summary>
Motivation: 研究多卫星系统中位置和姿态扰动对波束成形性能的影响，支持开发控制感知的波束成形策略，实现姿态轨道控制系统与信号处理的紧密集成。

Method: 分析由配备直接辐射阵列的小型卫星编队组成的系统，该编队合成大型虚拟天线孔径，研究位置和姿态扰动对波束成形的影响。

Result: 结果表明，波束成形性能对位置和姿态扰动高度敏感，但通过将位置和姿态信息整合到波束成形过程中，可以有效恢复标称性能。

Conclusion: 这些发现支持开发控制感知的波束成形策略，将姿态和轨道控制系统与信号处理紧密集成，以实现鲁棒的波束成形和自主协调。

Abstract: This work investigates the impact of position and attitude perturbations on
the beamforming performance of multi-satellite systems. The system under
analysis is a formation of small satellites equipped with direct radiating
arrays that synthesise a large virtual antenna aperture. The results show that
performance is highly sensitive to the considered perturbations. However, by
incorporating position and attitude information into the beamforming process,
nominal performance can be effectively restored. These findings support the
development of control-aware beamforming strategies that tightly integrate the
attitude and orbit control system with signal processing to enable robust
beamforming and autonomous coordination.

</details>


### [29] [Toward Efficient and Privacy-Aware eHealth Systems: An Integrated Sensing, Computing, and Semantic Communication Approach](https://arxiv.org/abs/2510.11514)
*Yinchao Yang,Yahao Ding,Zhaohui Yang,Chongwen Huang,Zhaoyang Zhang,Dusit Niyato,Mohammad Shikh-Bahaei*

Main category: eess.SP

TL;DR: 提出了一种集成感知、计算和语义通信的框架，用于远程医疗中的实时非接触式生命体征监测，通过语义特征提取提高数据传输效率和隐私保护。


<details>
  <summary>Details</summary>
Motivation: 传统无线通信和感知网络无法满足电子医疗对精确感知、高数据效率和隐私保护的严格要求，特别是在远程和隐私敏感环境中。

Method: 使用服务机器人通过雷达检测患者位置和生命体征，采用语义提取健康特征而非原始生理信息传输，利用IMM滤波器跟踪患者运动实现波束赋形，并联合优化波束赋形矩阵和语义提取比率。

Result: 仿真结果表明，相比传统联合感知通信方法，该框架在感知精度、语义传输效率和隐私保护方面表现更优。

Conclusion: ISCSC框架为现代医疗系统提供了一种高效、隐私保护的远程生命体征监测解决方案。

Abstract: Real-time and contactless monitoring of vital signs, such as respiration and
heartbeat, alongside reliable communication, is essential for modern healthcare
systems, especially in remote and privacy-sensitive environments. Traditional
wireless communication and sensing networks fall short in meeting all the
stringent demands of eHealth, including accurate sensing, high data efficiency,
and privacy preservation. To overcome the challenges, we propose a novel
integrated sensing, computing, and semantic communication (ISCSC) framework. In
the proposed system, a service robot utilises radar to detect patient positions
and monitor their vital signs, while sending updates to the medical devices.
Instead of transmitting raw physiological information, the robot computes and
communicates semantically extracted health features to medical devices. This
semantic processing improves data throughput and preserves the clinical
relevance of the messages, while enhancing data privacy by avoiding the
transmission of sensitive data. Leveraging the estimated patient locations, the
robot employs an interacting multiple model (IMM) filter to actively track
patient motion, thereby enabling robust beam steering for continuous and
reliable monitoring. We then propose a joint optimisation of the beamforming
matrices and the semantic extraction ratio, subject to computing capability and
power budget constraints, with the objective of maximising both the semantic
secrecy rate and sensing accuracy. Simulation results validate that the ISCSC
framework achieves superior sensing accuracy, improved semantic transmission
efficiency, and enhanced privacy preservation compared to conventional joint
sensing and communication methods.

</details>


### [30] [Beyond the Use-and-then-Forget (UatF) Bound: Fixed Point Algorithms for Statistical Max-Min Power Control](https://arxiv.org/abs/2510.11582)
*Renato Luis Garrido Cavalcante,Noor Ul Ain,Lorenzo Miretti,Slawomir Stanczak*

Main category: eess.SP

TL;DR: 提出了用于蜂窝和无蜂窝大规模MIMO系统中最优统计最大最小功率控制的数学工具和定点算法，解决了基于UatF下界的传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于UatF下界的功率控制算法的局限性，包括UatF下界过于保守（在零均值信道中可能产生零速率边界）和缺乏尺度不变性等问题。

Method: 开发了数学工具和定点算法框架，能够处理考虑解码器处完美或不完美CSI的替代边界，而不是依赖UatF下界。

Result: 提出的框架与不遭受上述缺点的信息论边界兼容，通过考虑解码器处瞬时CSI的标准边界解决了最大最小功率控制问题。

Conclusion: 新框架克服了UatF边界的关键限制，为大规模MIMO系统提供了更准确和稳健的功率控制解决方案。

Abstract: We introduce mathematical tools and fixed point algorithms for optimal
statistical max-min power control in cellular and cell-less massive MIMO
systems. Unlike previous studies that rely on the use-and-then-forget (UatF)
lower bound on Shannon achievable (ergodic) rates, our proposed framework can
deal with alternative bounds that explicitly consider perfect or imperfect
channel state information (CSI) at the decoder. In doing so, we address
limitations of UatF-based algorithms, which inherit the shortcomings of the
UatF bound. For example, the UatF bound can be overly conservative: in extreme
cases, under fully statistical (nonadaptive) beamforming in zero-mean channels,
the UatF bound produces trivial (zero) rate bounds. It also lacks scale
invariance: merely scaling the beamformers can change the bound drastically,
especially when simple beamforming strategies are employed. In contrast, our
framework is compatible with information-theoretic bounds that do not suffer
from the above drawbacks. We illustrate the framework by solving a max-min
power control problem considering a standard bound that exploits instantaneous
CSI at the decoder.

</details>


### [31] [Bayesian Self-Calibration and Parametric Channel Estimation for 6G Antenna Arrays](https://arxiv.org/abs/2510.11628)
*Patrick Hödl,Jakob Möderl,Erik Leitinger,Klaus Witrisal*

Main category: eess.SP

TL;DR: 提出将天线单元自校准集成到变分稀疏贝叶斯学习算法中，用于参数化信道估计，以解决相控阵天线在真实环境下的校准失配问题。


<details>
  <summary>Details</summary>
Motivation: 6G无线系统中，精确的信道估计对高速通信和高精度感知至关重要，但相控阵天线在实际条件下的校准失配会严重限制性能。

Method: 将天线增益和相位偏差建模为潜变量，推导显式更新方程，联合推断校准参数和信道参数（模型阶数、复幅值、时延、角度和噪声方差）。

Result: 算法在线运行并实时适应硬件引起的失配，在RMSE和OSPA指标上相比未校准的常规VSBL方法有持续改进。

Conclusion: 将自校准嵌入贝叶斯推断中显著增强了信道估计的鲁棒性。

Abstract: Accurate channel estimation is essential for both high-rate communication and
high-precision sensing in 6G wireless systems. However, a major performance
limitation arises from calibration mismatches when operating phased-array
antennas under real-world conditions. To address this issue, we propose to
integrate antenna element self-calibration into a variational sparse Bayesian
learning (VSBL) algorithm for parametric channel estimation. We model antenna
gain and phase deviations as latent variables and derive explicit update
equations to jointly infer these calibration parameters and the channel
parameters: the model order, complex amplitudes, delays, angles, and the noise
variance. The resulting algorithm operates online and adapts in real time to
hardware-induced mismatches. We assess its performance in terms of the root
mean square error (RMSE) and the optimal subpattern-assignment (OSPA) metric,
demonstrating consistent improvements over conventional VSBL without
calibration. Our results demonstrate that embedding self-calibration within
Bayesian inference significantly enhances the robustness of channel estimation.

</details>


### [32] [Leaky Wave Antennas for Next Generation Wireless Applications in sub-THz Frequencies: Current Status and Research Challenges](https://arxiv.org/abs/2510.11666)
*Natalie Lang,Atsutse K. Kludze,Nir Shlezinger,Yasaman Ghasempour,Tirza Routtenberg,George C. Alexandropoulos,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 本文综述了漏波天线在亚太赫兹通信中的潜力，展示了其通过单一天线元件同时支持多用户高速通信和精确定位的能力，并指出了未来研究的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 未来无线网络对超高数据速率、大规模连接和联合通信感知能力的需求日益增长，亚太赫兹频段虽然频谱资源丰富，但面临严重的传播和硬件设计挑战，需要寻找传统天线阵列之外的替代方案。

Method: 回顾漏波天线技术的基本原理，突出其独特特性，展示其在多用户宽带亚太赫兹无线通信中的潜力，并通过代表性研究进行验证。

Result: 研究表明漏波天线能够仅使用单个天线元件同时支持高速多用户通信和精确定位，具有简单的馈电结构、低制造成本和固有的角度-频率耦合特性。

Conclusion: 漏波天线是下一代无线系统成本效益高且可扩展的使能技术，但在算法设计、信号处理、信息理论、标准化和硬件实现等方面仍存在关键挑战需要解决。

Abstract: The ever-growing demand for ultra-high data rates, massive connectivity, and
joint communication-sensing capabilities in future wireless networks is driving
research into sub-terahertz (sub-THz) communications. While these frequency
bands offer abundant spectrum, they also pose severe propagation and hardware
design challenges, motivating the search for alternative antenna solutions
beyond conventional antenna arrays. Leaky-wave antennas (LWAs) have emerged as
a promising candidate for sub-THz systems due to their simple feed structure,
low fabrication cost, and inherent angle-frequency coupling, which enables
frequency-controlled beamsteering with simple hardware. In this article, we
review the fundamentals of the LWA technology, highlight their unique
properties, and showcase their potential in multi-user wideband sub-THz
wireless communications. We present representative studies demonstrating that
LWAs can simultaneously support high-rate multi-user communications and
accurate localization using only a single antenna element. Finally, several key
open challenges are outlined, spanning algorithm design, signal processing,
information theory, standardization, and hardware implementation, that need to
be addressed to fully harness LWAs as a cost-effective and scalable enabler of
next generations of wireless systems.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [33] [Perceptual Compensation of Ambisonics Recordings for Reproduction in Room](https://arxiv.org/abs/2510.10883)
*Ali Fallah,Shun Nakamura,Steven van de Par*

Main category: eess.AS

TL;DR: 提出了一种基于Ambisonics的录音和渲染方法，通过感知驱动的补偿来减少播放房间混响对音质的影响，相比传统Ambisonics提供更准确的声音场再现。


<details>
  <summary>Details</summary>
Motivation: 传统Ambisonics假设播放房间声学不影响声音场，但实际中播放房间混响会导致音质明显下降，需要补偿方法来保持听觉线索。

Method: 在球谐函数域对录制的直达声和混响声分量进行频谱和空间补偿，保持相关听觉线索，包括直达声到达方向、直达声和混响声的频谱能量以及各听觉频带的双耳相干性。

Result: 听力测试表明，该方法能感知准确地再现原始录音声音场，优于无补偿的传统Ambisonics，甚至优于在模拟消声室中的理想Ambisonics渲染。

Conclusion: 该方法在保持头部旋转和小位移鲁棒性的同时，提供了感知准确的声音场渲染，解决了播放房间混响对Ambisonics音质的影响问题。

Abstract: Ambisonics is a method for capturing and rendering a sound field accurately,
assuming that the acoustics of the playback room does not significantly
influence the sound field. However, in practice, the acoustics of the playback
room may lead to a noticeable degradation in sound quality. We propose a
recording and rendering method based on Ambisonics that utilizes a
perceptually-motivated approach to compensate for the reverberation of the
playback room. The recorded direct and reverberant sound field components in
the spherical harmonics (SHs) domain are spectrally and spatially compensated
to preserve the relevant auditory cues including the direction of arrival of
the direct sound, the spectral energy of the direct and reverberant sound
components, and the Interaural Coherence (IC) across each auditory band. In
contrast to the conventional Ambisonics, a flexible number of Ambisonics
channels can be used for audio rendering. Listening test results show that the
proposed method provides a perceptually accurate rendering of the originally
recorded sound field, outperforming both conventional Ambisonics without
compensation and even ideal Ambisonics rendering in a simulated anechoic room.
Additionally, subjective evaluations of listeners seated at the center of the
loudspeaker array demonstrate that the method remains robust to head rotation
and minor displacements.

</details>


### [34] [Phase Aware Ear-Conditioned Learning for Multi-Channel Binaural Speaker Separation](https://arxiv.org/abs/2510.11366)
*Ruben Johnson Robert Jeremiah,Peyman Goli,Steven van de Par*

Main category: eess.AS

TL;DR: PEASE-8是一个基于八麦克风的相位感知耳条件语音分离网络，在混响环境中有效分离两个竞争语音，同时保持空间线索和分离效率。


<details>
  <summary>Details</summary>
Motivation: 在混响环境中分离竞争语音需要既能保持空间线索又能维持分离效率的模型。

Method: 使用复杂STFT作为输入，直接将原始STFT输入到早期解码器层，绕过整个编码器路径以改进重建。模型端到端训练，采用SI-SDR目标函数，针对直达路径耳目标进行训练，联合执行分离和去混响。

Result: 在混响环境中（T60=0.6s），达到12.37 dB SI-SDR、0.87 STOI和1.86 PESQ，在无混响条件下也保持竞争力。

Conclusion: PEASE-8在混响和噪声条件下为两个固定方位角说话人提供强大的分离和可懂度，无需排列不变训练。

Abstract: Separating competing speech in reverberant environments requires models that
preserve spatial cues while maintaining separation efficiency. We present a
Phase-aware Ear-conditioned speaker Separation network using eight microphones
(PEASE-8) that consumes complex STFTs and directly introduces a raw-STFT input
to the early decoder layer, bypassing the entire encoder pathway to improve
reconstruction. The model is trained end-to-end with an SI-SDR-based objective
against direct-path ear targets, jointly performing separation and
dereverberation for two speakers in a fixed azimuth, eliminating the need for
permutation invariant training. On spatialized two-speaker mixtures spanning
anechoic, reverberant, and noisy conditions, PEASE-8 delivers strong separation
and intelligibility. In reverberant environments, it achieves 12.37 dB SI-SDR,
0.87 STOI, and 1.86 PESQ at T60 = 0.6 s, while remaining competitive under
anechoic conditions.

</details>


### [35] [Dynamically Slimmable Speech Enhancement Network with Metric-Guided Training](https://arxiv.org/abs/2510.11395)
*Haixin Zhao,Kaixuan Yang,Nilesh Madhu*

Main category: eess.AS

TL;DR: 提出了一种基于门控的动态可瘦身网络(DSN)，通过静态和动态组件结合，根据输入信号质量自适应调整计算负载，在保持性能的同时显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 为了进一步降低轻量级语音增强模型的复杂度，需要开发能够根据输入信号质量动态调整计算资源的网络架构。

Method: 设计了包含静态和动态组件的DSN，针对常用组件(分组RNN、多头注意力、卷积和全连接层)引入不同的动态结构，使用策略模块根据输入信号质量在帧级别控制动态部分的使用，并提出了度量引导训练(MGT)来指导策略模块评估语音质量。

Result: DSN在仪器指标上达到了与最先进轻量级基线相当的性能，同时平均只使用了73%的计算负载。动态组件使用率评估表明MGT-DSN能够根据输入信号失真程度适当分配网络资源。

Conclusion: DSN通过动态调整网络结构成功实现了计算效率的提升，在保持语音增强性能的同时显著降低了计算复杂度。

Abstract: To further reduce the complexity of lightweight speech enhancement models, we
introduce a gating-based Dynamically Slimmable Network (DSN). The DSN comprises
static and dynamic components. For architecture-independent applicability, we
introduce distinct dynamic structures targeting the commonly used components,
namely, grouped recurrent neural network units, multi-head attention,
convolutional, and fully connected layers. A policy module adaptively governs
the use of dynamic parts at a frame-wise resolution according to the input
signal quality, controlling computational load. We further propose
Metric-Guided Training (MGT) to explicitly guide the policy module in assessing
input speech quality. Experimental results demonstrate that the DSN achieves
comparable enhancement performance in instrumental metrics to the
state-of-the-art lightweight baseline, while using only 73% of its
computational load on average. Evaluations of dynamic component usage ratios
indicate that the MGT-DSN can appropriately allocate network resources
according to the severity of input signal distortion.

</details>


### [36] [ILD-VIT: A Unified Vision Transformer Architecture for Detection of Interstitial Lung Disease from Respiratory Sounds](https://arxiv.org/abs/2510.11458)
*Soubhagya Ranjan Hota,Arka Roy,Udit Satija*

Main category: eess.AS

TL;DR: 提出了一种基于视觉变换器(VIT)的深度学习框架ILD-VIT，利用呼吸音记录检测间质性肺病(ILD)，在树莓派4微控制器上成功部署，可作为独立的临床筛查系统。


<details>
  <summary>Details</summary>
Motivation: 间质性肺病(ILD)是一组限制性慢性肺部疾病，传统诊断方法包括肺功能测试、高分辨率肺部成像和呼吸音听诊等，需要开发自动化的检测系统。

Method: 提出ILD-VIT框架，包含三个主要阶段：预处理、梅尔频谱图提取，以及使用VIT架构对梅尔频谱图图像块进行分类。

Result: 在BRACETS和KAUH数据库上的实验结果显示，ILD-VIT在独立受试者盲测中达到84.86%准确率、82.67%敏感性和86.91%特异性。

Conclusion: 该框架成功在树莓派4微控制器上部署，表明其具有作为独立临床系统在真实场景中进行ILD筛查的潜力。

Abstract: Interstitial lung disease (ILD) represents a group of restrictive chronic
pulmonary diseases that impair oxygen acquisition by causing irreversible
changes in the lungs such as fibrosis, scarring of parenchyma, etc. ILD
conditions are often diagnosed by various clinical modalities such as
spirometry, high-resolution lung imaging techniques, crackling respiratory
sounds (RSs), etc. In this letter, we develop a novel vision transformer
(VIT)-based deep learning framework namely, ILD-VIT, to detect the ILD
condition using the RS recordings. The proposed framework comprises three major
stages: pre-processing, mel spectrogram extraction, and classification using
the proposed VIT architecture using the mel spectrogram image patches.
Experimental results using the publicly available BRACETS and KAUH databases
show that our proposed ILD-VIT achieves an accuracy, sensitivity, and
specificity of 84.86%, 82.67%, and 86.91%, respectively, for
subject-independent blind testing. The successful onboard implantation of the
proposed framework on a Raspberry-pi-4 microcontroller indicates its potential
as a standalone clinical system for ILD screening in a real clinical scenario.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [37] [Universal Discrete-Domain Speech Enhancement](https://arxiv.org/abs/2510.09974)
*Fei Liu,Yang Ai,Ye-Xin Lu,Rui-Chen Zheng,Hui-Peng Du,Zhen-Hua Ling*

Main category: cs.SD

TL;DR: 提出了一种名为UDSE的通用离散域语音增强模型，将语音增强重新定义为离散域分类任务，通过预测预训练神经语音编解码器的离散标记来重建干净语音，能够处理多种单一或组合失真。


<details>
  <summary>Details</summary>
Motivation: 现实场景中语音信号常受多种干扰同时影响，但现有语音增强方法大多只处理有限类型的失真，缺乏对多种失真同时存在情况的研究，这影响了语音增强方法在真实环境中的泛化能力和实用性。

Method: UDSE首先从退化语音中提取全局特征，然后基于这些特征按照残差向量量化器的规则预测干净的离散标记，每个VQ的预测依赖于前一个VQ的结果，最后将所有VQ预测的干净标记解码重建语音波形。训练时采用教师强制策略和交叉熵损失。

Result: 实验结果表明，UDSE能有效增强受各种常规和非常规失真（如加性噪声、混响、带宽限制、削波、相位失真和压缩失真）及其组合影响的语音，展现了比先进回归方法更好的通用性和实用性。

Conclusion: UDSE模型通过将语音增强重新定义为离散域分类任务，能够有效处理多种单一或组合失真，在真实环境中具有更好的泛化能力和实用性。

Abstract: In real-world scenarios, speech signals are inevitably corrupted by various
types of interference, making speech enhancement (SE) a critical task for
robust speech processing. However, most existing SE methods only handle a
limited range of distortions, such as additive noise, reverberation, or band
limitation, while the study of SE under multiple simultaneous distortions
remains limited. This gap affects the generalization and practical usability of
SE methods in real-world environments.To address this gap, this paper proposes
a novel Universal Discrete-domain SE model called UDSE.Unlike regression-based
SE models that directly predict clean speech waveform or continuous features,
UDSE redefines SE as a discrete-domain classification task, instead predicting
the clean discrete tokens quantized by the residual vector quantizer (RVQ) of a
pre-trained neural speech codec.Specifically, UDSE first extracts global
features from the degraded speech. Guided by these global features, the clean
token prediction for each VQ follows the rules of RVQ, where the prediction of
each VQ relies on the results of the preceding ones. Finally, the predicted
clean tokens from all VQs are decoded to reconstruct the clean speech waveform.
During training, the UDSE model employs a teacher-forcing strategy, and is
optimized with cross-entropy loss. Experimental results confirm that the
proposed UDSE model can effectively enhance speech degraded by various
conventional and unconventional distortions, e.g., additive noise,
reverberation, band limitation, clipping, phase distortion, and compression
distortion, as well as their combinations. These results demonstrate the
superior universality and practicality of UDSE compared to advanced
regression-based SE methods.

</details>


### [38] [Improving Speech Emotion Recognition with Mutual Information Regularized Generative Model](https://arxiv.org/abs/2510.10078)
*Chung-Soo Ahn,Rajib Rana,Sunil Sivadas,Carlos Busso,Jagath C. Rajapakse*

Main category: cs.SD

TL;DR: 提出了一种基于跨模态信息传递和互信息正则化的数据增强框架，用于解决语音情感识别中高质量标注数据不足的问题，并在多个基准数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 语音情感识别研究虽然因深度学习方法而进步，但仍面临高质量标注训练数据获取困难的问题。数据增强方法特别是生成模型被用来缓解这一问题。

Method: 提出了一种数据增强框架，利用跨模态信息传递和互信息正则化。互信息度量可作为生成数据质量的指标，并确保多模态输入之间的依赖性。

Result: 在IEMOCAP、MSP-IMPROV和MSP-Podcast三个基准数据集上测试，该框架提高了情感预测性能，优于现有工作，并且能够在不依赖跨模态信息的情况下生成新输入。

Conclusion: 该数据增强框架通过跨模态信息传递和互信息正则化有效解决了语音情感识别中的数据不足问题，提升了模型性能，并展示了在无跨模态信息情况下的生成能力。

Abstract: Although speech emotion recognition (SER) research has been advanced, thanks
to deep learning methods, it still suffers from obtaining inputs from large
quality-labelled training data. Data augmentation methods have been attempted
to mitigate this issue, generative models have shown success among them
recently. We propose a data augmentation framework that is aided by cross-modal
information transfer and mutual information regularization. Mutual information
based metric can serve as an indicator for the quality. Furthermore, we expand
this data augmentation scope to multimodal inputs, thanks to mutual information
ensureing dependency between modalities. Our framework was tested on three
benchmark datasets: IEMOCAP, MSP-IMPROV and MSP-Podcast. The implementation was
designed to generate input features that are fed into last layer for emotion
classification. Our framework improved the performance of emotion prediction
against existing works. Also, we discovered that our framework is able to
generate new inputs without any cross-modal information.

</details>


### [39] [Matchmaker: An Open-source Library for Real-time Piano Score Following and Systematic Evaluation](https://arxiv.org/abs/2510.10087)
*Jiyun Park,Carlos Cancino-Chacón,Suhit Chiruthapudi,Juhan Nam*

Main category: cs.SD

TL;DR: Matchmaker是一个开源Python库，用于实时音乐对齐（乐谱跟随），提供统一框架比较不同方法，并在大型钢琴音乐数据集上进行系统评估。


<details>
  <summary>Details</summary>
Motivation: 实时音乐对齐是重要的MIR任务，但缺乏统一的开放框架来比较模型，现有实现存在语言/系统依赖性问题，且与现代MIR库兼容性差，难以利用大型数据集进行基准测试。

Method: 开发Matchmaker开源Python库，系统比较音乐表示和对齐方法两个维度，在(n)ASAP、Batik和Vienna4x22数据集上使用综合指标进行评估。

Result: 建立了一个用于乐谱跟随研究的基准框架，同时提供了开发者可轻松集成到应用中的实用工具。

Conclusion: Matchmaker填补了实时音乐对齐领域缺乏统一评估框架的空白，为研究和应用开发提供了重要支持。

Abstract: Real-time music alignment, also known as score following, is a fundamental
MIR task with a long history and is essential for many interactive
applications. Despite its importance, there has not been a unified open
framework for comparing models, largely due to the inherent complexity of
real-time processing and the language- or system-dependent implementations. In
addition, low compatibility with the existing MIR environment has made it
difficult to develop benchmarks using large datasets available in recent years.
While new studies based on established methods (e.g., dynamic programming,
probabilistic models) have emerged, most evaluations compare models only within
the same family or on small sets of test data. This paper introduces
Matchmaker, an open-source Python library for real-time music alignment that is
easy to use and compatible with modern MIR libraries. Using this, we
systematically compare methods along two dimensions: music representations and
alignment methods. We evaluated our approach on a large test set of solo piano
music from the (n)ASAP, Batik, and Vienna4x22 datasets with a comprehensive set
of metrics to ensure robust assessment. Our work aims to establish a benchmark
framework for score-following research while providing a practical tool that
developers can easily integrate into their applications.

</details>


### [40] [Peransformer: Improving Low-informed Expressive Performance Rendering with Score-aware Discriminator](https://arxiv.org/abs/2510.10175)
*Xian He,Wei Zeng,Ye Wang*

Main category: cs.SD

TL;DR: Peransformer是一个基于Transformer的低信息表达性演奏渲染系统，通过引入分数感知判别器和使用对齐的MIDI数据集，在低信息系统中达到最先进性能，并提出了通用EPR评估指标GEM。


<details>
  <summary>Details</summary>
Motivation: 现有高信息EPR系统需要详细乐谱但可用性有限，低信息系统虽然更易用但性能不佳，且现有评估指标不统一难以直接比较不同EPR系统。

Method: 使用Transformer架构，结合分数感知判别器利用基础乐谱MIDI文件，在音符对齐的乐谱-演奏配对MIDI数据集上进行训练。

Result: Peransformer在低信息系统中达到最先进性能，主观评估验证了其有效性。

Conclusion: 提出的Peransformer系统成功缩小了低信息与高信息EPR系统之间的差距，同时GEM指标为EPR系统提供了更直接可靠的比较标准。

Abstract: Highly-informed Expressive Performance Rendering (EPR) systems transform
music scores with rich musical annotations into human-like expressive
performance MIDI files. While these systems have achieved promising results,
the availability of detailed music scores is limited compared to MIDI files and
are less flexible to work with using a digital audio workstation (DAW). Recent
advancements in low-informed EPR systems offer a more accessible alternative by
directly utilizing score-derived MIDI as input, but these systems often exhibit
suboptimal performance. Meanwhile, existing works are evaluated with diverse
automatic metrics and data formats, hindering direct objective comparisons
between EPR systems. In this study, we introduce Peransformer, a
transformer-based low-informed EPR system designed to bridge the gap between
low-informed and highly-informed EPR systems. Our approach incorporates a
score-aware discriminator that leverages the underlying score-derived MIDI
files and is trained on a score-to-performance paired, note-to-note aligned
MIDI dataset. Experimental results demonstrate that Peransformer achieves
state-of-the-art performance among low-informed systems, as validated by
subjective evaluations. Furthermore, we extend existing automatic evaluation
metrics for EPR systems and introduce generalized EPR metrics (GEM), enabling
more direct, accurate, and reliable comparisons across EPR systems.

</details>


### [41] [ProGress: Structured Music Generation via Graph Diffusion and Hierarchical Music Analysis](https://arxiv.org/abs/2510.10249)
*Stephen Ni-Hahn,Chao Péter Yang,Mingchen Ma,Cynthia Rudin,Simon Mak,Yue Jiang*

Main category: cs.SD

TL;DR: 提出了一种结合申克分析理论和扩散模型的新音乐生成框架ProGress，解决了现有AI音乐生成模型缺乏结构连贯性和可解释性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有AI音乐生成模型存在两个主要问题：缺乏和声-旋律结构的连贯性，以及模型是"黑箱"难以进行音乐解释。

Method: 基于DiGress离散扩散模型进行创新性适配，结合申克分析理论提出短语融合方法，并开发了用户可控的生成框架。

Result: 人类实验结果显示，该方法在性能上优于现有的最先进方法。

Conclusion: ProGress框架成功地将音乐理论分析融入AI生成过程，实现了结构连贯且可解释的音乐创作。

Abstract: Artificial Intelligence (AI) for music generation is undergoing rapid
developments, with recent symbolic models leveraging sophisticated deep
learning and diffusion model algorithms. One drawback with existing models is
that they lack structural cohesion, particularly on harmonic-melodic structure.
Furthermore, such existing models are largely "black-box" in nature and are not
musically interpretable. This paper addresses these limitations via a novel
generative music framework that incorporates concepts of Schenkerian analysis
(SchA) in concert with a diffusion modeling framework. This framework, which we
call ProGress (Prolongation-enhanced DiGress), adapts state-of-the-art deep
models for discrete diffusion (in particular, the DiGress model of Vignac et
al., 2023) for interpretable and structured music generation. Concretely, our
contributions include 1) novel adaptations of the DiGress model for music
generation, 2) a novel SchA-inspired phrase fusion methodology, and 3) a
framework allowing users to control various aspects of the generation process
to create coherent musical compositions. Results from human experiments suggest
superior performance to existing state-of-the-art methods.

</details>


### [42] [MRSAudio: A Large-Scale Multimodal Recorded Spatial Audio Dataset with Refined Annotations](https://arxiv.org/abs/2510.10396)
*Wenxiang Guo,Changhao Pan,Zhiyuan Zhu,Xintong Hu,Yu Zhang,Li Tang,Rui Yang,Han Wang,Zongbao Zhang,Yuhan Wang,Yixuan Chen,Hankun Xu,Ke Xu,Pengfei Fan,Zhetao Chen,Yanhao Yu,Qiange Huang,Fei Wu,Zhou Zhao*

Main category: cs.SD

TL;DR: MRSAudio是一个大规模多模态空间音频数据集，包含双耳和环绕声音频、视频、运动轨迹等数据，支持空间音频理解和生成的五个基础任务。


<details>
  <summary>Details</summary>
Motivation: 现有的大多数多模态数据集只提供单声道音频，限制了空间音频生成和理解的发展，而空间音频在VR/AR等沉浸式技术中至关重要。

Method: 构建包含四个组件（MRSLife、MRSSpeech、MRSMusic、MRSSing）的数据集，涵盖多样化现实场景，提供同步的双耳和环绕声音频、视频、运动轨迹及细粒度标注。

Result: MRSAudio支持高质量的空间建模，能够广泛应用于空间音频研究，在五个基础任务上表现出色。

Conclusion: MRSAudio填补了空间音频数据集的空白，为空间音频理解和生成研究提供了重要资源，推动了沉浸式技术的发展。

Abstract: Humans rely on multisensory integration to perceive spatial environments,
where auditory cues enable sound source localization in three-dimensional
space. Despite the critical role of spatial audio in immersive technologies
such as VR/AR, most existing multimodal datasets provide only monaural audio,
which limits the development of spatial audio generation and understanding. To
address these challenges, we introduce MRSAudio, a large-scale multimodal
spatial audio dataset designed to advance research in spatial audio
understanding and generation. MRSAudio spans four distinct components: MRSLife,
MRSSpeech, MRSMusic, and MRSSing, covering diverse real-world scenarios. The
dataset includes synchronized binaural and ambisonic audio, exocentric and
egocentric video, motion trajectories, and fine-grained annotations such as
transcripts, phoneme boundaries, lyrics, scores, and prompts. To demonstrate
the utility and versatility of MRSAudio, we establish five foundational tasks:
audio spatialization, and spatial text to speech, spatial singing voice
synthesis, spatial music generation and sound event localization and detection.
Results show that MRSAudio enables high-quality spatial modeling and supports a
broad range of spatial audio research. Demos and dataset access are available
at https://mrsaudio.github.io.

</details>


### [43] [Knowledge-Decoupled Functionally Invariant Path with Synthetic Personal Data for Personalized ASR](https://arxiv.org/abs/2510.10401)
*Yue Gu,Zhihao Du,Ying Shi,Jiqing Han,Yongjun He*

Main category: cs.SD

TL;DR: 提出KDFIP框架，通过门控参数隔离策略和功能不变路径，解决ASR模型在合成数据增强个性化时平衡合成、个性化和通用知识的挑战


<details>
  <summary>Details</summary>
Motivation: 使用大规模合成个人数据增强ASR模型个性化时面临两个挑战：适应合成个人数据而不遗忘真实知识，以及适应个人数据而不遗忘通用知识

Method: 将门控参数隔离策略集成到FIP中，提出KDFIP框架，将通用和个性化知识存储在独立模块中，并顺序应用FIP。个性化模块适应合成和真实个人数据，通用模块适应通用数据

Result: 使用增强合成数据，KDFIP在目标说话人上实现29.38%相对字符错误率降低，并保持与未适应ASR基线相当的泛化性能

Conclusion: KDFIP框架有效解决了ASR模型个性化中的知识平衡问题，显著提升个性化性能同时保持通用能力

Abstract: Fine-tuning generic ASR models with large-scale synthetic personal data can
enhance the personalization of ASR models, but it introduces challenges in
adapting to synthetic personal data without forgetting real knowledge, and in
adapting to personal data without forgetting generic knowledge. Considering
that the functionally invariant path (FIP) framework enables model adaptation
while preserving prior knowledge, in this letter, we introduce FIP into
synthetic-data-augmented personalized ASR models. However, the model still
struggles to balance the learning of synthetic, personalized, and generic
knowledge when applying FIP to train the model on all three types of data
simultaneously. To decouple this learning process and further address the above
two challenges, we integrate a gated parameter-isolation strategy into FIP and
propose a knowledge-decoupled functionally invariant path (KDFIP) framework,
which stores generic and personalized knowledge in separate modules and applies
FIP to them sequentially. Specifically, KDFIP adapts the personalized module to
synthetic and real personal data and the generic module to generic data. Both
modules are updated along personalization-invariant paths, and their outputs
are dynamically fused through a gating mechanism. With augmented synthetic
data, KDFIP achieves a 29.38% relative character error rate reduction on target
speakers and maintains comparable generalization performance to the unadapted
ASR baseline.

</details>


### [44] [MARS-Sep: Multimodal-Aligned Reinforced Sound Separation](https://arxiv.org/abs/2510.10509)
*Zihan Zhang,Xize Cheng,Zhennan Jiang,Dongjie Fu,Jingyuan Chen,Zhou Zhao,Tao Jin*

Main category: cs.SD

TL;DR: MARS-Sep是一个基于强化学习的通用声音分离框架，通过将分离问题重新定义为决策过程，使用因子化Beta掩码策略和跨模态奖励来提升语义一致性。


<details>
  <summary>Details</summary>
Motivation: 解决传统声音分离模型在信号指标优化与语义质量之间的不匹配问题，传统方法虽然能优化低级信号指标，但会产生语义污染的输出，无法有效抑制声学相似源的感知显著干扰。

Method: 引入强化学习框架，使用因子化Beta掩码策略，通过裁剪信任域代理、熵正则化和组相对优势归一化进行优化。采用冻结旧策略采样掩码、重构波形，使用裁剪重要性比率更新当前策略。利用音频-文本-视觉编码器获得多模态奖励，直接激励与查询提示的语义一致性。

Result: 在多个基准测试中，文本、音频和图像查询分离任务均取得一致提升，在信号指标和语义质量方面都有显著改进。

Conclusion: MARS-Sep通过强化学习重新构建声音分离问题，结合多模态奖励和渐进对齐方案，有效解决了语义污染问题，实现了更稳定和样本高效的学习。

Abstract: Universal sound separation faces a fundamental misalignment: models optimized
for low-level signal metrics often produce semantically contaminated outputs,
failing to suppress perceptually salient interference from acoustically similar
sources. To bridge this gap, we introduce MARS-Sep, a reinforcement learning
framework that reformulates separation as decision making. Instead of simply
regressing ground-truth masks, MARS-Sep learns a factorized Beta mask policy
that is optimized by a clipped trust-region surrogate with entropy
regularization and group-relative advantage normalization. Concretely, we
sample masks from a frozen old policy, reconstruct waveforms, and update the
current policy using clipped importance ratios-yielding substantially more
stable and sample-efficient learning. Multimodal rewards, derived from an
audio-text-vision encoder, directly incentivize semantic consistency with query
prompts. We further propose a progressive alignment scheme to fine-tune this
encoder, boosting its cross-modal discriminability and improving reward
faithfulness. Extensive experiments on multiple benchmarks demonstrate
consistent gains in Text-, Audio-, and Image-Queried separation, with notable
improvements in signal metrics and semantic quality. Our code is available at
https://anonymous.4open.science/r/MARS-Sep. Sound separation samples are
available at https://mars-sep.github.io/.

</details>


### [45] [A Machine Learning Approach for MIDI to Guitar Tablature Conversion](https://arxiv.org/abs/2510.10619)
*Maximos Kaliakatsos-Papakostas,Gregoris Bastas,Dimos Makris,Dorien Herremans,Vassilis Katsouros,Petros Maragos*

Main category: cs.SD

TL;DR: 该论文提出了一种基于机器学习的吉他谱转录方法，能够将MIDI音乐片段转换为可演奏的吉他指法谱，即使原音乐并非为吉他创作。


<details>
  <summary>Details</summary>
Motivation: 吉他谱转录需要找到可演奏的弦-品组合，并保持连续音符之间的简洁运动。传统吉他演奏中形成了特定的和弦指法模式，但现有方法缺乏对吉他特有表达特性的考虑。

Method: 采用机器学习方法，基于手指在指板上的伸展能力假设，仅考虑标准6弦吉他调弦。使用基础方法增强音乐信息，用人工数据训练和测试系统。

Result: 训练增强数据后系统性能得到提升，即使在简单的单音情况下也是如此。结果揭示了系统的弱点，为可能的改进提供了有用结论。

Conclusion: 该方法能够处理非吉他专用音乐，增强数据训练能提高性能，但系统仍存在局限性，为未来改进指明了方向。

Abstract: Guitar tablature transcription consists in deducing the string and the fret
number on which each note should be played to reproduce the actual musical
part. This assignment should lead to playable string-fret combinations
throughout the entire track and, in general, preserve parsimonious motion
between successive combinations. Throughout the history of guitar playing,
specific chord fingerings have been developed across different musical styles
that facilitate common idiomatic voicing combinations and motion between them.
This paper presents a method for assigning guitar tablature notation to a given
MIDI-based musical part (possibly consisting of multiple polyphonic tracks),
i.e. no information about guitar-idiomatic expressional characteristics is
involved (e.g. bending etc.) The current strategy is based on machine learning
and requires a basic assumption about how much fingers can stretch on a
fretboard; only standard 6-string guitar tuning is examined. The proposed
method also examines the transcription of music pieces that was not meant to be
played or could not possibly be played by a guitar (e.g. potentially a
symphonic orchestra part), employing a rudimentary method for augmenting
musical information and training/testing the system with artificial data. The
results present interesting aspects about what the system can achieve when
trained on the initial and augmented dataset, showing that the training with
augmented data improves the performance even in simple, e.g. monophonic, cases.
Results also indicate weaknesses and lead to useful conclusions about possible
improvements.

</details>


### [46] [Unify Variables in Neural Scaling Laws for General Audio Representations via Embedding Effective Rank](https://arxiv.org/abs/2510.10948)
*Xuyao Deng,Yanjie Sun,Yong Dou,Kele Xu*

Main category: cs.SD

TL;DR: 本文系统研究了通用音频表示学习的缩放定律，使用嵌入有效秩(RankMe)作为统一指标来量化不同变量对表示质量的影响，发现RankMe与表示质量之间存在一致的幂律关系。


<details>
  <summary>Details</summary>
Motivation: 缩放定律在计算机视觉和自然语言处理中已得到深入理解，但在通用音频表示学习中的应用仍未被充分探索。主要挑战在于音频表示质量受多个因素共同影响，难以单独分析。

Method: 使用嵌入有效秩(RankMe)作为无标签、信息论的音频嵌入量化指标，在广泛的超参数空间（包括模型大小、训练数据量、计算预算、架构配置等）中检验缩放行为。

Result: 实证发现RankMe与表示质量之间存在一致的幂律关系，表明嵌入有效秩可作为评估和预测音频表示学习模型性能的可靠代理指标。

Conclusion: 这项工作不仅验证了经典缩放原理在通用音频领域的适用性，还为音频基础模型未来的缩放策略提供了理论基础和实证框架。

Abstract: Scaling laws have profoundly shaped our understanding of model performance in
computer vision and natural language processing, yet their application to
general audio representation learning remains underexplored. A key challenge
lies in the multifactorial nature of general audio
representation-representation quality is jointly influenced by variables such
as audio length, embedding dimensionality, model depth, model architecture,
data volume, etc., many of which are difficult to isolate or express
analytically. In this work, we present a systematic study of scaling laws for
general audio representations by utilizing embedding effective rank (RankMe) as
a unifying metric that encapsulates the impact of diverse variables on
representation quality. RankMe enables a label-free, information-theoretic
quantification of audio embeddings, allowing us to examine scaling behaviors
across a wide hyper-parameter space, including model size, training data
volume, computational budget, architectural configurations, etc. Our empirical
findings reveal a consistent power-law relationship between RankMe and
representation quality, suggesting that embedding effective rank serves as a
reliable proxy for assessing and predicting model performance in audio
representation learning. This work not only validates the applicability of
classical scaling principles to the general audio domain but also offers a
theoretically grounded and empirically robust framework for guiding future
model scaling strategies in audio foundation models.

</details>


### [47] [LSZone: A Lightweight Spatial Information Modeling Architecture for Real-time In-car Multi-zone Speech Separation](https://arxiv.org/abs/2510.10687)
*Jun Chen,Shichao Hu,Jiuxin Lin,Wenjie Li,Zihan Zhang,Xingchen Li,JinJiang Liu,Longshuai Xiao,Chao Weng,Lei Xie,Zhiyong Wu*

Main category: cs.SD

TL;DR: LSZone是一种轻量级空间信息建模架构，用于实时车载多区域语音分离，通过空间信息提取压缩模块和Conv-GRU跨带窄带处理模块，在保持性能的同时显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 虽然之前的SpatialNet取得了显著成果，但其高计算成本阻碍了在车辆中的实时应用，因此需要开发轻量级的解决方案。

Method: 设计了空间信息提取压缩(SpaIEC)模块，结合Mel频谱图和耳间相位差(IPD)来减少计算负担；引入极轻量级的Conv-GRU跨带窄带处理(CNP)模块来高效建模空间信息。

Result: LSZone在复杂噪声和多说话人场景下表现出色，计算复杂度为0.56G MACs，实时因子(RTF)为0.37。

Conclusion: LSZone实现了在保持高性能的同时显著降低计算复杂度的目标，适用于车载实时多区域语音分离应用。

Abstract: In-car multi-zone speech separation, which captures voices from different
speech zones, plays a crucial role in human-vehicle interaction. Although
previous SpatialNet has achieved notable results, its high computational cost
still hinders real-time applications in vehicles. To this end, this paper
proposes LSZone, a lightweight spatial information modeling architecture for
real-time in-car multi-zone speech separation. We design a spatial information
extraction-compression (SpaIEC) module that combines Mel spectrogram and
Interaural Phase Difference (IPD) to reduce computational burden while
maintaining performance. Additionally, to efficiently model spatial
information, we introduce an extremely lightweight Conv-GRU
crossband-narrowband processing (CNP) module. Experimental results demonstrate
that LSZone, with a complexity of 0.56G MACs and a real-time factor (RTF) of
0.37, delivers impressive performance in complex noise and multi-speaker
scenarios.

</details>


### [48] [Diffusion-Link: Diffusion Probabilistic Model for Bridging the Audio-Text Modality Gap](https://arxiv.org/abs/2510.11330)
*KiHyun Nam,Jongmin Choi,Hyeongkeun Lee,Jungwoo Heo,Joon Son Chung*

Main category: cs.SD

TL;DR: Diffusion-Link通过扩散模型将音频嵌入映射到文本嵌入分布，减少模态间隙，在自动音频描述任务中实现最先进性能


<details>
  <summary>Details</summary>
Motivation: 现有的对比音频-语言预训练存在模态间隙，限制了多模态编码器与大型语言模型的有效耦合

Method: 提出基于扩散的模态桥接模块，使用轻量级残差MLP网络将音频嵌入映射到文本嵌入分布

Result: 在AudioCaps数据集上，零样本和全监督音频描述任务分别实现52.5%和7.5%的相对提升，达到最先进水平

Conclusion: 弥合模态间隙对于多模态编码器与LLM的有效耦合至关重要，扩散基模态桥接为超越知识检索中心设计提供了有前景的方向

Abstract: Contrastive audio-language pretraining yields powerful joint representations,
yet a persistent audio-text modality gap limits the benefits of coupling
multimodal encoders with large language models (LLMs). We present
Diffusion-Link, a diffusion-based modality-bridging module that generatively
maps audio embeddings into the text-embedding distribution. The module is
trained at the output embedding from the frozen multimodal encoder and
implemented as a lightweight network with three residual MLP blocks. To assess
the effect of Diffusion-Link on multimodal encoder-LLM coupling, we evaluate on
Automatic Audio Captioning (AAC); to our knowledge, this is the first
application of diffusion-based modality bridging to AAC. We report two results.
(1) Modality-gap analysis: on similarity and geometric criteria, Diffusion-Link
reduces the modality gap the most among prior diffusion-based methods and shows
a collective migration of audio embeddings toward the text distribution. (2)
Downstream AAC: attaching Diffusion-Link to the same multimodal LLM baseline
achieves state-of-the-art on AudioCaps in both zero-shot and fully supervised
captioning without external knowledge, with relative gains up to 52.5% and
7.5%, respectively. These findings show that closing the modality gap is
pivotal for effective coupling between multimodal encoders and LLMs, and
diffusion-based modality bridging offers a promising direction beyond
knowledge-retrieval-centric designs. Code will be released upon acceptance
https://github.com/DevKiHyun/Diffusion-Link

</details>


### [49] [SS-DPPN: A self-supervised dual-path foundation model for the generalizable cardiac audio representation](https://arxiv.org/abs/2510.10719)
*Ummy Maria Muna,Md Mehedi Hasan Shawon,Md Jobayer,Sumaiya Akter,Md Rakibul Hasan,Md. Golam Rabiul Alam*

Main category: cs.SD

TL;DR: 提出SS-DPPN自监督双路径原型网络，用于从无标签心音数据中学习表示，在四个心音基准测试中达到最先进性能，具有优异的数据效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 心音图的自动分析对心血管疾病早期诊断至关重要，但监督深度学习常受限于专家标注数据的稀缺性。

Method: 采用双路径对比学习架构，同时处理1D波形和2D频谱图，使用新型混合损失函数；下游任务采用基于原型网络的度量学习方法。

Result: 在四个心音基准测试中达到最先进性能；全监督模型在标记数据减少三倍时仍保持优异表现；学习表示成功泛化到肺音分类和心率估计任务。

Conclusion: SS-DPPN被验证为生理信号的鲁棒、可靠且可扩展的基础模型。

Abstract: The automated analysis of phonocardiograms is vital for the early diagnosis
of cardiovascular disease, yet supervised deep learning is often constrained by
the scarcity of expert-annotated data. In this paper, we propose the
Self-Supervised Dual-Path Prototypical Network (SS-DPPN), a foundation model
for cardiac audio representation and classification from unlabeled data. The
framework introduces a dual-path contrastive learning based architecture that
simultaneously processes 1D waveforms and 2D spectrograms using a novel hybrid
loss. For the downstream task, a metric-learning approach using a Prototypical
Network was used that enhances sensitivity and produces well-calibrated and
trustworthy predictions. SS-DPPN achieves state-of-the-art performance on four
cardiac audio benchmarks. The framework demonstrates exceptional data
efficiency with a fully supervised model on three-fold reduction in labeled
data. Finally, the learned representations generalize successfully across lung
sound classification and heart rate estimation. Our experiments and findings
validate SS-DPPN as a robust, reliable, and scalable foundation model for
physiological signals.

</details>


### [50] [Automatic Music Sample Identification with Multi-Track Contrastive Learning](https://arxiv.org/abs/2510.11507)
*Alain Riou,Joan Serrà,Yuki Mitsufuji*

Main category: cs.SD

TL;DR: 提出了一种基于自监督学习的自动样本识别方法，通过多音轨数据集创建人工混音的正样本对，设计了新颖的对比学习目标，显著优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 采样是现代音乐制作中常见的技术，但自动识别采样内容并追溯其原始材料是一个具有挑战性的任务。

Method: 采用自监督学习方法，利用多音轨数据集创建人工混音的正样本对，并设计新的对比学习目标。

Result: 该方法在不同音乐流派上表现出鲁棒性，在增加参考数据库噪声歌曲数量时具有良好的扩展性，显著优于现有最先进基线方法。

Conclusion: 高质量分离的音轨对于样本识别任务至关重要，所提出的训练流程各组件都对此任务有重要贡献。

Abstract: Sampling, the technique of reusing pieces of existing audio tracks to create
new music content, is a very common practice in modern music production. In
this paper, we tackle the challenging task of automatic sample identification,
that is, detecting such sampled content and retrieving the material from which
it originates. To do so, we adopt a self-supervised learning approach that
leverages a multi-track dataset to create positive pairs of artificial mixes,
and design a novel contrastive learning objective. We show that such method
significantly outperforms previous state-of-the-art baselines, that is robust
to various genres, and that scales well when increasing the number of noise
songs in the reference database. In addition, we extensively analyze the
contribution of the different components of our training pipeline and
highlight, in particular, the need for high-quality separated stems for this
task.

</details>


### [51] [Proficiency-Aware Adaptation and Data Augmentation for Robust L2 ASR](https://arxiv.org/abs/2510.10738)
*Ling Sun,Charlotte Zhu,Shuju Shi*

Main category: cs.SD

TL;DR: 针对非母语学习者等非典型说话人的ASR系统表现不佳，本文提出两种策略来减少识别错误并缩小不同水平学习者之间的性能差距。


<details>
  <summary>Details</summary>
Motivation: 通用ASR系统对非典型说话人（如二语学习者）表现较差，这会加剧偏见并限制在教育与无障碍应用中的使用。

Method: 提出两种方法：(i) 能力感知多任务学习，联合优化ASR和能力分类；(ii) 针对性增强，对低水平语音应用频谱图掩码以应对数据不平衡。

Result: 这些方法将WER相对降低达29.4%，插入/删除错误相对减少达58.6%，并在反映真实世界分布的不平衡数据集上持续缩小能力差距。

Conclusion: 所提出的策略能够推进面向二语学习者的公平ASR系统，在减少总体错误的同时缩小不同水平学习者之间的性能差异。

Abstract: General-purpose ASR underperforms for atypical speakers, such as L2 learners,
reinforcing bias and limiting use in education and accessibility. Using the
CEFR-graded Speak and Improve corpus, we show that naive fine-tuning of Whisper
reduces average WER but simultaneously widens disparities and
disproportionately harms lower-level learners. To address this, we propose two
strategies: (i) proficiency-aware multitask learning, jointly optimizing ASR
with proficiency classification, and (ii) targeted augmentation, applying
spectrogram masking to low-proficiency speech to counter imbalance. These
approaches reduce WER by up to 29.4 percent (relative) and insertion/deletion
errors by as much as 58.6 percent (relative). Crucially, despite the severe
imbalance of the dataset reflecting real-world distributions, both strategies
consistently narrow proficiency gaps, advancing equitable ASR for L2 learners.

</details>


### [52] [Dual Data Scaling for Robust Two-Stage User-Defined Keyword Spotting](https://arxiv.org/abs/2510.10740)
*Zhiqi Ai,Han Cheng,Yuxin Wang,Shiyi Mu,Shugong Xu,Yongjin Zhou*

Main category: cs.SD

TL;DR: DS-KWS是一个两阶段的用户自定义关键词检测框架，结合CTC方法和QbyT方法，通过双数据扩展策略显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的关键词检测方法在处理易混淆词和用户自定义关键词时性能有限，需要更鲁棒的解决方案。

Method: 采用两阶段框架：第一阶段使用CTC方法和流式音素搜索定位候选片段；第二阶段使用QbyT方法和音素匹配器在音素和话语级别进行验证。引入双数据扩展策略：扩展ASR语料库至1460小时，使用15.5万个锚点类别训练音素匹配器。

Result: 在LibriPhrase数据集上，Hard子集达到6.13% EER和97.85% AUC；在Hey-Snips数据集上实现零样本性能，达到99.13%召回率和每小时1次误报。

Conclusion: DS-KWS框架显著优于现有方法，在用户自定义关键词检测任务中表现出色，特别是在处理易混淆词方面。

Abstract: In this paper, we propose DS-KWS, a two-stage framework for robust
user-defined keyword spotting. It combines a CTC-based method with a streaming
phoneme search module to locate candidate segments, followed by a QbyT-based
method with a phoneme matcher module for verification at both the phoneme and
utterance levels. To further improve performance, we introduce a dual data
scaling strategy: (1) expanding the ASR corpus from 460 to 1,460 hours to
strengthen the acoustic model; and (2) leveraging over 155k anchor classes to
train the phoneme matcher, significantly enhancing the distinction of
confusable words. Experiments on LibriPhrase show that DS-KWS significantly
outperforms existing methods, achieving 6.13\% EER and 97.85\% AUC on the Hard
subset. On Hey-Snips, it achieves zero-shot performance comparable to full-shot
trained models, reaching 99.13\% recall at one false alarm per hour.

</details>


### [53] [ParsVoice: A Large-Scale Multi-Speaker Persian Speech Corpus for Text-to-Speech Synthesis](https://arxiv.org/abs/2510.10774)
*Mohammad Javad Ranjbar Kalahroodi,Heshaam Faili,Azadeh Shakery*

Main category: cs.SD

TL;DR: 提出了ParsVoice，这是最大的波斯语语音语料库，专门用于TTS应用，包含1,804小时高质量语音数据，来自470多名说话人。


<details>
  <summary>Details</summary>
Motivation: 波斯语在全球有超过1亿使用者，但在高质量语音语料库中严重不足，特别是用于TTS合成应用，这限制了波斯语语音技术的发展。

Method: 创建了一个自动化流水线，将原始有声读物内容转换为TTS就绪数据，包括基于BERT的句子完成检测器、用于精确音频文本对齐的二分搜索边界优化方法，以及针对波斯语的多维质量评估框架。

Result: 处理了2,000本有声读物，产生了3,526小时的干净语音，进一步筛选为1,804小时的高质量子集，适合TTS使用。

Conclusion: ParsVoice是最大的高质量波斯语语音数据集，具有与主要英语语料库相当的说话人多样性和音频质量，已公开可用以加速波斯语语音技术的发展，并为其他低资源语言提供模板。

Abstract: Persian Language, despite being spoken by over 100 million people worldwide,
remains severely underrepresented in high-quality speech corpora, particularly
for text-to-speech (TTS) synthesis applications. Existing Persian speech
datasets are typically smaller than their English counterparts, which creates a
key limitation for developing Persian speech technologies. We address this gap
by introducing ParsVoice, the largest Persian speech corpus designed
specifically for TTS applications. We created an automated pipeline that
transforms raw audiobook content into TTS-ready data, incorporating components
such as a BERT-based sentence completion detector, a binary search boundary
optimization method for precise audio-text alignment, and multi-dimensional
quality assessment frameworks tailored to Persian. The pipeline processes 2,000
audiobooks, yielding 3,526 hours of clean speech, which was further filtered
into a 1,804-hour high-quality subset suitable for TTS, featuring more than 470
speakers. ParsVoice is the largest high-quality Persian speech dataset,
offering speaker diversity and audio quality comparable to major English
corpora. The complete dataset has been made publicly available to accelerate
the development of Persian speech technologies and to serve as a template for
other low-resource languages. The ParsVoice dataset is publicly available at
ParsVoice (https://huggingface.co/datasets/MohammadJRanjbar/ParsVoice).

</details>


### [54] [FAC-FACodec: Controllable Zero-Shot Foreign Accent Conversion with Factorized Speech Codec](https://arxiv.org/abs/2510.10785)
*Yurii Halychanskyi,Cameron Churchwell,Yutong Wen,Volodymyr Kindratenko*

Main category: cs.SD

TL;DR: 提出了一个可控的口音转换框架，允许用户通过显式参数控制口音修改程度，在保持说话人身份的同时实现发音转换。


<details>
  <summary>Details</summary>
Motivation: 现有口音转换方法缺乏对修改程度的显式控制，而口音修改会影响说话人身份的感知，因此需要在转换强度和身份保持之间取得平衡。

Method: 开发了一个口音转换框架，提供用户可控的显式参数来控制口音修改程度，针对发音进行转换同时保留超音段特征如语调和音素时长。

Result: 性能与近期口音转换系统相当，但能更好地保持说话人身份，并独特地支持可控的口音转换。

Conclusion: 该框架成功实现了可控的口音转换，在保持说话人身份的同时提供用户可调节的转换强度。

Abstract: Previous accent conversion (AC) methods, including foreign accent conversion
(FAC), lack explicit control over the degree of modification. Because accent
modification can alter the perceived speaker identity, balancing conversion
strength and identity preservation is crucial. We present an AC framework that
provides an explicit, user-controllable parameter for accent modification. The
method targets pronunciation while preserving suprasegmental cues such as
intonation and phoneme durations. Results show performance comparable to recent
AC systems, stronger preservation of speaker identity, and unique support for
controllable accent conversion.

</details>


### [55] [MSRBench: A Benchmarking Dataset for Music Source Restoration](https://arxiv.org/abs/2510.10995)
*Yongyi Zang,Jiarui Hai,Wanying Ge,Qiuqiang Kong,Zheqi Dai,Helin Wang,Yuki Mitsufuji,Mark D. Plumbley*

Main category: cs.SD

TL;DR: MSRBench是首个专门为音乐源恢复设计的基准测试，包含专业混音师制作的原始-处理音频对，并添加了12种真实世界退化，用于评估分离准确性和恢复保真度。


<details>
  <summary>Details</summary>
Motivation: 现有基准无法测量恢复保真度：合成数据集使用未处理音轨但混合不真实，而真实制作数据集只提供已处理音轨没有干净参考。

Method: 创建MSRBench基准，包含八种乐器类别的原始音轨-混合对，混合由专业混音师制作，并添加12种真实世界退化（模拟伪影、声学环境、有损编解码器）。

Result: U-Net和BSRNN基线实验分别达到SI-SNR为-37.8 dB和-23.4 dB，感知质量（FAD CLAP）约为0.7-0.8，显示还有很大改进空间。

Conclusion: MSRBench填补了音乐源恢复评估的空白，展示了需要专门针对恢复设计的架构，现有方法仍有显著改进空间。

Abstract: Music Source Restoration (MSR) extends source separation to realistic
settings where signals undergo production effects (equalization, compression,
reverb) and real-world degradations, with the goal of recovering the original
unprocessed sources. Existing benchmarks cannot measure restoration fidelity:
synthetic datasets use unprocessed stems but unrealistic mixtures, while real
production datasets provide only already-processed stems without clean
references. We present MSRBench, the first benchmark explicitly designed for
MSR evaluation. MSRBench contains raw stem-mixture pairs across eight
instrument classes, where mixtures are produced by professional mixing
engineers. These raw-processed pairs enable direct evaluation of both
separation accuracy and restoration fidelity. Beyond controlled studio
conditions, the mixtures are augmented with twelve real-world degradations
spanning analog artifacts, acoustic environments, and lossy codecs. Baseline
experiments with U-Net and BSRNN achieve SI-SNR of -37.8 dB and -23.4 dB
respectively, with perceptual quality (FAD CLAP) around 0.7-0.8, demonstrating
substantial room for improvement and the need for restoration-specific
architectures.

</details>


### [56] [VCB Bench: An Evaluation Benchmark for Audio-Grounded Large Language Model Conversational Agents](https://arxiv.org/abs/2510.11098)
*Jiliang Hu,Wenfu Wang,Zuchao Li,Chenxing Li,Yiyang Zhao,Hanzhao Li,Liqiang Zhang,Meng Yu,Dong Yu*

Main category: cs.SD

TL;DR: VCB Bench是一个高质量的中文语音对话基准测试，完全基于真实人类语音，从指令遵循、知识理解和鲁棒性三个维度评估大型音频语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要局限于英语、依赖合成语音，且缺乏全面的多维度评估，需要构建高质量的中文真实语音基准。

Method: 构建完全基于真实人类语音的中文基准VCB Bench，从指令遵循（包括语音级控制）、知识理解（常识、推理、日常对话）和鲁棒性（内容、环境、说话人特征的扰动）三个互补视角评估模型。

Result: 在代表性LALMs上的实验揭示了显著的性能差距，为改进指明了方向。

Conclusion: VCB Bench提供了一个可复现的细粒度评估框架，为推进中文语音对话模型提供了标准化方法和实践洞见。

Abstract: Recent advances in large audio language models (LALMs) have greatly enhanced
multimodal conversational systems. However, existing benchmarks remain limited
-- they are mainly English-centric, rely on synthetic speech, and lack
comprehensive, discriminative evaluation across multiple dimensions. To address
these gaps, we present Voice Chat Bot Bench (VCB Bench) -- a high-quality
Chinese benchmark built entirely on real human speech. VCB Bench evaluates
LALMs from three complementary perspectives: instruction following (including
speech-level control beyond text commands), knowledge understanding (general
knowledge, reasoning, and daily dialogue), and robustness (stability under
perturbations in content, environment, and speaker traits). Experiments on
representative LALMs reveal notable performance gaps and highlight future
directions for improvement. VCB Bench provides a reproducible and fine-grained
evaluation framework, offering standardized methodology and practical insights
for advancing Chinese voice conversational models.

</details>


### [57] [Perturbation Self-Supervised Representations for Cross-Lingual Emotion TTS: Stage-Wise Modeling of Emotion and Speaker](https://arxiv.org/abs/2510.11124)
*Cheng Gong,Chunyu Qiang,Tianrui Wang,Yu Jiang,Yuheng Lu,Ruihao Jing,Xiaoxiao Miao,Xiaolei Zhang,Longbiao Wang,Jianwu Dang*

Main category: cs.SD

TL;DR: EMM-TTS是一个基于扰动自监督学习表示的两阶段跨语言情感语音合成框架，通过显式和隐式编码韵律线索来捕捉情感表达，同时从扰动表示中恢复音色，实现了对情感、音色和语言的精细控制。


<details>
  <summary>Details</summary>
Motivation: 跨语言情感文本转语音需要在一个语言中生成捕捉另一个语言说话者情感的语音，同时保持目标声音的音色。情感和音色在语音信号中高度纠缠，使得精细控制具有挑战性。

Method: 提出两阶段框架：第一阶段显式和隐式编码韵律线索捕捉情感表达；第二阶段从扰动的SSL表示中恢复音色。引入说话者一致性损失(SCL)和说话者-情感自适应层归一化(SEALN)模块，并探索不同说话者扰动策略。

Result: 综合多指标评估显示，EMM-TTS在跨语言场景下实现了优越的自然度、情感传递性和音色一致性。结合显式声学特征和预训练潜在特征提高了语音克隆性能。

Conclusion: EMM-TTS通过创新的两阶段框架和扰动策略，成功解决了跨语言情感语音合成中情感和音色纠缠的挑战，为多语言情感语音生成提供了有效解决方案。

Abstract: Cross-lingual emotional text-to-speech (TTS) aims to produce speech in one
language that captures the emotion of a speaker from another language while
maintaining the target voice's timbre. This process of cross-lingual emotional
speech synthesis presents a complex challenge, necessitating flexible control
over emotion, timbre, and language. However, emotion and timbre are highly
entangled in speech signals, making fine-grained control challenging. To
address this issue, we propose EMM-TTS, a novel two-stage cross-lingual
emotional speech synthesis framework based on perturbed self-supervised
learning (SSL) representations. In the first stage, the model explicitly and
implicitly encodes prosodic cues to capture emotional expressiveness, while the
second stage restores the timbre from perturbed SSL representations. We further
investigate the effect of different speaker perturbation strategies-formant
shifting and speaker anonymization-on the disentanglement of emotion and
timbre. To strengthen speaker preservation and expressive control, we introduce
Speaker Consistency Loss (SCL) and Speaker-Emotion Adaptive Layer Normalization
(SEALN) modules. Additionally, we find that incorporating explicit acoustic
features (e.g., F0, energy, and duration) alongside pretrained latent features
improves voice cloning performance. Comprehensive multi-metric evaluations,
including both subjective and objective measures, demonstrate that EMM-TTS
achieves superior naturalness, emotion transferability, and timbre consistency
across languages.

</details>


### [58] [Audio-Maestro: Enhancing Large Audio-Language Models with Tool-Augmented Reasoning](https://arxiv.org/abs/2510.11454)
*Kuan-Yi Lee,Tsung-En Lin,Hung-Yi Lee*

Main category: cs.SD

TL;DR: Audio-Maestro是一个工具增强的音频推理框架，让音频语言模型能够自主调用外部工具并将带时间戳的输出整合到推理过程中，从而提升音频理解的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前的大规模多模态模型在音频理解方面主要依赖端到端推理，这限制了需要结构化知识或专门信号分析任务的准确性和可解释性。

Method: 通过让音频语言模型自主调用外部工具，并将工具输出的带时间戳结果整合到推理过程中，使用专门工具来分析、转换和解释音频信号。

Result: 实验显示Audio-Maestro显著提升了通用音频推理性能：Gemini-2.5-flash在MMAU-Test上的平均准确率从67.4%提升到72.1%，DeSTA-2.5从58.3%提升到62.8%，GPT-4o从60.8%提升到63.9%。

Conclusion: Audio-Maestro是首个将结构化工具输出整合到大型音频语言模型推理过程中的框架，有效提升了音频理解的准确性和可解释性。

Abstract: Recent advancements in large multimodal models (LMMs) have shown strong
capabilities in audio understanding. However, most systems rely solely on
end-to-end reasoning, limiting interpretability and accuracy for tasks that
require structured knowledge or specialized signal analysis. In this work, we
present Audio-Maestro -- a tool-augmented audio reasoning framework that
enables audio-language models to autonomously call external tools and integrate
their timestamped outputs into the reasoning process. This design allows the
model to analyze, transform, and interpret audio signals through specialized
tools rather than relying solely on end-to-end inference. Experiments show that
Audio-Maestro consistently improves general audio reasoning performance:
Gemini-2.5-flash's average accuracy on MMAU-Test rises from 67.4% to 72.1%,
DeSTA-2.5 from 58.3% to 62.8%, and GPT-4o from 60.8% to 63.9%. To our
knowledge, Audio-Maestro is the first framework to integrate structured tool
output into the large audio language model reasoning process.

</details>


### [59] [BridgeCode: A Dual Speech Representation Paradigm for Autoregressive Zero-Shot Text-to-Speech Synthesis](https://arxiv.org/abs/2510.11646)
*Jingyuan Xing,Mingru Yang,Zhipeng Li,Xiaofen Xing,Xiangmin Xu*

Main category: cs.SD

TL;DR: BridgeTTS是一个基于双语音表示范式BridgeCode的新型自回归文本转语音框架，通过预测稀疏标记同时重构丰富的连续特征来解决现有AR-TTS系统的速度-质量权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有的基于自回归的零样本TTS系统面临两个关键限制：(i)固有的速度-质量权衡，顺序标记生成要么以表达性为代价降低帧率，要么以效率为代价丰富标记；(ii)文本导向的监督不匹配，交叉熵损失均匀惩罚标记错误而不考虑相邻标记间的细粒度声学相似性。

Method: 提出BridgeTTS框架，基于双语音表示范式BridgeCode，通过预测稀疏标记减少自回归迭代次数，同时重构丰富的连续特征以实现高质量合成。联合优化标记级和特征级目标以进一步增强自然度和可懂度。

Result: 实验表明BridgeTTS在实现竞争性质量和说话人相似度的同时显著加速了合成过程。

Conclusion: BridgeTTS通过双语音表示和联合优化策略有效解决了AR-TTS系统的速度-质量权衡问题，在保持高质量的同时大幅提升了合成效率。

Abstract: Autoregressive (AR) frameworks have recently achieved remarkable progress in
zero-shot text-to-speech (TTS) by leveraging discrete speech tokens and large
language model techniques. Despite their success, existing AR-based zero-shot
TTS systems face two critical limitations: (i) an inherent speed-quality
trade-off, as sequential token generation either reduces frame rates at the
cost of expressiveness or enriches tokens at the cost of efficiency, and (ii) a
text-oriented supervision mismatch, as cross-entropy loss penalizes token
errors uniformly without considering the fine-grained acoustic similarity among
adjacent tokens. To address these challenges, we propose BridgeTTS, a novel
AR-TTS framework built upon the dual speech representation paradigm BridgeCode.
BridgeTTS reduces AR iterations by predicting sparse tokens while
reconstructing rich continuous features for high-quality synthesis. Joint
optimization of token-level and feature-level objectives further enhances
naturalness and intelligibility. Experiments demonstrate that BridgeTTS
achieves competitive quality and speaker similarity while significantly
accelerating synthesis. Speech demos are available at
https://test1562.github.io/demo/.

</details>

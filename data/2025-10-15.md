<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 14]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SD](#cs.SD) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [A Closed-form Expression of the Gaussian Noise Model Supporting O-Band Transmission](https://arxiv.org/abs/2510.11867)
*Zelin Gan,Henrique Buglia,Romulo Aparecido,Mindaugas Jarmolovičius,Eric Sillekens,Jiaqian Yang,Ronit Sohanpal,Robert I. Killey,Polina Bayvel*

Main category: eess.SP

TL;DR: 提出了一种用于O波段低色散传输系统中非线性干扰估计的闭式模型，该模型考虑了四波混频效率项以及多跨距中自相位调制和交叉相位调制的相干贡献。


<details>
  <summary>Details</summary>
Motivation: 传统的闭式高斯噪声模型在低色散O波段传输系统中存在局限性，需要开发更准确的非线性干扰估计方法。

Method: 扩展了闭式模型，纳入四波混频效率项和自相位调制/交叉相位调制的相干贡献，通过分裂步傅里叶方法和数值积分进行验证。

Result: 在41-161个信道、96 GBaud符号率、高达16.1 THz带宽和80-800 km传输距离下，非线性干扰信噪比的均方误差低于0.22 dB。

Conclusion: 该闭式模型为O波段相干传输系统优化提供了高效且准确的工具。

Abstract: We present a novel closed-form model for nonlinear interference (NLI)
estimation in low-dispersion O-band transmission systems. The formulation
incorporates the four-wave mixing (FWM) efficiency term as well as the coherent
contributions of self- and cross-phase modulation (SPM/XPM) across multiple
identical spans. This extension enables accurate evaluation of the NLI in
scenarios where conventional closed-form Gaussian Noise (GN) models are
limited. The proposed model is validated against split-step Fourier method
(SSFM) simulations and numerical integration across 41-161 channels, with a 96
GBaud symbol rate, bandwidths of up to 16.1 THz, and transmission distances
from 80 to 800 km. Results show a mean absolute error of the NLI
signal-to-noise ratio (SNR) below 0.22 dB. The proposed closed-form model
offers an efficient and accurate tool for system optimisation in O-band
coherent transmission.

</details>


### [2] [Based on Deep Neural Networks: A Machine Learning-Assisted Channel Estimation Method for MIMO Systems](https://arxiv.org/abs/2510.11891)
*Haoran He*

Main category: eess.SP

TL;DR: 提出一种基于DNN的大规模MIMO信道估计方法，在5G及未来网络中通过深度学习技术超越传统LS和MMSE方法，显著降低NMSE和BER，并在实际部署中验证了可行性。


<details>
  <summary>Details</summary>
Motivation: 在5G及未来网络中，准确的信道估计对于缓解导频污染和高移动性问题至关重要，传统方法在系统可靠性方面存在局限。

Method: 采用多层感知器DNN架构，包含3个隐藏层（256、128、64个神经元），使用ReLU激活函数、Adam优化器和MSE损失函数，从导频信号学习预测信道矩阵。

Result: 在COST 2100数据集上的仿真表明，DNN方法在中信噪比下比LS和MMSE方法在NMSE指标上提升3-5dB，在高移动性场景下表现稳健，计算复杂度为2.3 GFlOPs，推理时间1.8ms。

Conclusion: 该研究推动了机器学习在无线通信中的集成，为下一代网络的高效资源分配和频谱效率提升提供了可行方案，未来可探索更多真实数据集和混合架构以提升泛化能力。

Abstract: This paper proposes a machine learning-assisted channel estimation approach
for massive MIMO systems, leveraging DNNs to outperform traditional LS and MMSE
methods. In 5G and beyond, accurate channel estimation mitigates pilot
contamination and high mobility issues that harm system reliability. The
proposed DNN architecture includes multi-layer perceptrons with ReLU
activation, 3 hidden layers (256, 128, 64 neurons respectively), uses Adam
optimizer (learning rate 1e-4) and MSE loss function. It learns from pilot
signals to predict channel matrices, achieving lower NMSE and BER across
different SNR levels. Simulations use the COST 2100 public standard dataset (a
well-recognized MIMO channel dataset for 5G, not synthetic datasets) with
10,000 samples of 4x4 MIMO channels under urban macro scenarios. Results show
the DNN outperforms LS and MMSE by 3-5 dB in NMSE at medium SNR, with robust
performance in high-mobility scenarios. The study evaluates metrics like NMSE
vs. SNR, BER vs. SNR, and sensitivity to pilot length, antenna configurations,
and computational complexity. The DNN has 2.3 GFlOPs computational complexity,
15.6k parameters, and 1.8 ms inference time on Raspberry Pi 4, verifying
deployment feasibility. This work advances ML integration in wireless
communications, facilitating efficient resource allocation and improved
spectral efficiency in next-generation networks. Future work may use more
real-world datasets and hybrid architectures for better generalization.

</details>


### [3] [Using STAR-IRS to Secure Indoor Communications Through Symbol-Level Random Phase Modulation](https://arxiv.org/abs/2510.11925)
*Yanan Du,Zeyang Sun,Yilan Zhang,Sai Xu,Beiyuan Liu*

Main category: eess.SP

TL;DR: 提出基于STAR-IRS的安全室内通信方案，使用GNN优化保密率，并通过FPGA加速器降低计算延迟


<details>
  <summary>Details</summary>
Motivation: 解决室内通信中的窃听安全问题，传统反射式IRS无法同时处理透射和反射信号，需要更智能的表面来增强合法用户接收质量并降低窃听者信号质量

Method: 部署STAR-IRS在墙壁或窗户上，将入射电磁波动态分为透射和反射两部分：反射信号增强Bob接收，透射信号添加符号级随机相位偏移以降低Eves信号质量；使用GNN求解保密率最大化问题，并设计FPGA加速器

Result: 仿真显示该策略在保密性能上优于传统方案和仅反射方案；GNN方法在解决优化问题时优于MRT、ZF和MMSE等基准技术；实验验证FPGA加速器实现低推理延迟

Conclusion: STAR-IRS结合GNN优化和FPGA加速的方案能有效提升室内通信的保密性能，为安全通信提供了新思路

Abstract: This paper proposes a secure indoor communication scheme based on
simultaneous transmitting and reflecting intelligent reflecting surface
(STAR-IRS). Specifically, a transmitter (Alice) sends confidential information
to its intended user (Bob) indoors, while several eavesdroppers (Eves) lurk
outside. To safeguard the transmission from eavesdropping, the STAR-IRS is
deployed on walls or windows. Upon impinging on the STAR-IRS, the incoming
electromagnetic wave is dynamically partitioned into two components, enabling
both transmission through and reflection from the surface. The reflected signal
is controlled to enhance reception at Bob, while the transmitted signal is
modulated with symbol-level random phase shifts to degrade the signal quality
at Eves. Based on such a setting, the secrecy rate maximization problem is
formulated. To solve it, a graph neural network (GNN)-based scheme is
developed. Furthermore, a field-programmable gate array (FPGA)-based GNN
accelerator is designed to reduce computational latency. Simulation results
demonstrate that the proposed strategy outperforms both the conventional scheme
and the reflection-only scheme in terms of secrecy performance. Moreover, the
GNN-based approach achieves superior results compared to benchmark techniques
such as maximum ratio transmission (MRT), zero forcing (ZF), and minimum mean
square error (MMSE) in solving the optimization problem. Finally, experimental
evaluations confirm that the FPGA-based accelerator enables low inference
latency.

</details>


### [4] [62.6 GHz ScAlN Solidly Mounted Acoustic Resonators](https://arxiv.org/abs/2510.11994)
*Yinan Wang,Byeongjin Kim,Nishanth Ravi,Kapil Saha,Supratik Dasgupta,Vakhtang Chulukhadze,Eugene Kwon,Lezli Matto,Pietro Simeoni,Omar Barrera,Ian Anderson,Tzu-Hsuan Hsu,Jue Hou,Matteo Rinaldi,Mark S. Goorsky,Ruochen Lu*

Main category: eess.SP

TL;DR: 开发了创纪录的62.6 GHz固态安装声学谐振器，采用67.6 nm钪铝氮化物压电层和40 nm铂底电极，在8.5对SiO2/Ta2O5布拉格反射器上实现第三阶厚度延伸体声波模式。


<details>
  <summary>Details</summary>
Motivation: 为下一代射频前端开发毫米波固态安装声学谐振器，实现更高工作频率的滤波器和谐振器。

Method: 使用67.6 nm Sc0.3Al0.7N压电层和40 nm Pt底电极，在8.5对SiO2/Ta2O5布拉格反射器上设计第三阶厚度延伸体声波模式。

Result: 实现了62.6 GHz工作频率，压电耦合系数0.8%，最大Bode品质因子51，是目前报道的最高频率SMR。

Conclusion: 这些结果为毫米波SMR器件在下一代射频前端中的应用开辟了道路。

Abstract: We demonstrate a record-high 62.6 GHz solidly mounted acoustic resonator
(SMR) incorporating a 67.6 nm scandium aluminum nitride (Sc0.3Al0.7N)
piezoelectric layer on a 40 nm buried platinum (Pt) bottom electrode,
positioned above an acoustic Bragg reflector composed of alternating SiO2 (28.2
nm) and Ta2O5 (24.3 nm) layers in 8.5 pairs. The Bragg reflector and
piezoelectric stack above are designed to confine a third-order
thickness-extensional (TE) bulk acoustic wave (BAW) mode, while efficiently
transducing with thickness-field excitation. The fabricated SMR exhibits an
extracted piezoelectric coupling coefficient (k2) of 0.8% and a maximum Bode
quality factor (Q) of 51 at 63 GHz, representing the highest operating
frequency reported for an SMR to date. These results establish a pathway toward
mmWave SMR devices for filters and resonators in next-generation RF front ends.

</details>


### [5] [A Deep Multi-Task Learning Approach to Impulsive Noise Parameter Estimation](https://arxiv.org/abs/2510.12179)
*Abdullahi Mohammad,Bdah Eya,Bassant Selim*

Main category: eess.SP

TL;DR: 提出基于CNN-LSTM架构的多任务学习框架，结合注意力机制，用于联合估计脉冲噪声参数，通过统一加权损失函数实现多参数同时学习，提高学习效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 脉冲噪声严重影响无线通信系统可靠性，需要准确估计其统计参数以实现有效抑制。

Method: 采用CNN-LSTM架构的多任务学习框架，集成注意力机制，使用统一加权损失函数在共享表示空间中同时学习多个参数。

Result: 实验表明该框架实现稳定收敛、更快训练和增强的可扩展性，相比传统单任务学习模型具有更好的复杂度-性能权衡和显著内存节省。

Conclusion: 多任务学习方法在无线系统实时脉冲噪声参数估计中表现出有效性。

Abstract: Impulsive noise poses a significant challenge to the reliability of wireless
communication systems, necessitating accurate estimation of its statistical
parameters for effective mitigation. This paper introduces a multitask learning
(MTL) framework based on a CNN-LSTM architecture enhanced with an attention
mechanism for the joint estimation of impulsive noise parameters. The proposed
model leverages a unified weighted-loss function to enable simultaneous
learning of multiple parameters within a shared representation space, improving
learning efficiency and generalization across related tasks. Experimental
results show that the proposed MTL framework achieves stable convergence,
faster training, and enhanced scalability with modest computational overhead.
Benchmarking against conventional single-task learning (STL) models confirms
its favorable complexity-performance trade-off and significant memory savings,
indicating the effectiveness of the MTL approach for real-time impulsive noise
parameter estimation in wireless systems.

</details>


### [6] [Probabilistic Constellation Shaping for OFDM ISAC Signals Under Temporal-Frequency Filtering](https://arxiv.org/abs/2510.12204)
*Zhen Du,Jingjing Xu,Yifeng Xiong,Jie Wang,Musa Furkan Keskin,Henk Wymeersch,Fan Liu,Shi Jin*

Main category: eess.SP

TL;DR: 提出了一种统一的概率星座成形框架，通过最大化通信速率同时约束感知CSI的均方误差、功率和概率分布，在6G网络中实现感知与通信的灵活权衡。


<details>
  <summary>Details</summary>
Motivation: 在6G集成感知与通信系统中，使用OFDM通信信号进行感知是一种经济高效的解决方案。但由于QAM等非恒定模量有限字母调制的信号随机性，匹配和非匹配滤波方案的感知性能会显著恶化。如何在保持通信能力的同时提升感知性能是一个挑战性任务。

Method: 提出了统一的概率星座成形框架，兼容匹配和非匹配滤波方案。通过最大化通信速率，同时约束感知信道状态信息的均方误差、功率和概率分布来优化系统性能。

Result: 仿真和现场测量验证了所提PCS方法在实现灵活感知与通信权衡方面的有效性，以及在真实场景中增强6G无线传输的可信度。感知CSI的MSE被证明是比输出SNR和积分旁瓣比更全面的度量指标。

Conclusion: 该概率星座成形框架成功解决了ISAC系统中感知性能与通信能力之间的权衡问题，为6G无线网络的实际部署提供了有效的解决方案。

Abstract: Integrated sensing and communications (ISAC) is considered an innovative
technology in sixth-generation (6G) wireless networks, where utilizing
orthogonal frequency division multiplexing (OFDM) communication signals for
sensing provides a cost-effective solution for implementing ISAC. However, the
sensing performance of matched and mismatched filtering schemes can be
significantly deteriorated due to the signaling randomness induced by
finite-alphabet modulations with nonconstant modulus, such as quadrature
amplitude modulation (QAM) constellations. Therefore, improving sensing
performance without significantly compromising communication capability (i.e.,
maintaining randomness), remains a challenging task. To that end, we propose a
unified probabilistic constellation shaping (PCS) framework that is compatible
with both matched and mismatched filtering schemes, by maximizing the
communication rate while imposing constraints on mean square error (MSE) of
sensing channel state information (CSI), power, and probability distribution.
Specifically, the MSE of sensing CSI is leveraged to optimize sensing
capability, which is illustrated to be a more comprehensive metric compared to
the output SNR after filtering (SNRout) and integrated sidelobes ratio (ISLR).
Additionally, the internal relationships among these three sensing metrics are
explicitly analyzed. Finally, both simulations and field measurements validate
the efficiency of proposed PCS approach in achieving a flexible S&C trade-off,
as well as its credibility in enhancing 6G wireless transmission in real-world
scenarios.

</details>


### [7] [Wireless Channel Modeling for Machine Learning -- A Critical View on Standardized Channel Models](https://arxiv.org/abs/2510.12279)
*Benedikt Böck,Amar Kasibovic,Wolfgang Utschick*

Main category: eess.SP

TL;DR: 论文指出3GPP TDL和CDL等链路级信道模型在评估基于机器学习的物理层方法时存在局限性，会导致分布偏移和近乎高斯特性，使ML模型无法超越经典方法。采用场景级视角可以解决这个问题。


<details>
  <summary>Details</summary>
Motivation: 标准化链路级信道模型在评估ML物理层方法时存在限制性假设，导致分布偏移或需要不切实际的在线训练，且产生近乎高斯特性，使ML模型无法发挥优势。

Method: 论证链路级视角的局限性，展示简单线性方法在信道压缩、估计和建模中的最优性，提出采用场景级视角作为解决方案。

Result: 在链路级信道模型下，ML模型无法超越经典方法，而场景级视角可以解锁ML的相对增益。

Conclusion: 链路级信道模型不适合评估ML模型，应采用场景级视角来充分发挥ML在物理层应用中的潜力。

Abstract: Standardized (link-level) channel models such as the 3GPP TDL and CDL models
are frequently used to evaluate machine learning (ML)-based physical-layer
methods. However, in this work, we argue that a link-level perspective
incorporates limiting assumptions, causing unwanted distributional shifts or
necessitating impractical online training. An additional drawback is that this
perspective leads to (near-)Gaussian channel characteristics. Thus, ML-based
models, trained on link-level channel data, do not outperform classical
approaches for a variety of physical-layer applications. Particularly, we
demonstrate the optimality of simple linear methods for channel compression,
estimation, and modeling, revealing the unsuitability of link-level channel
models for evaluating ML models. On the upside, adopting a scenario-level
perspective offers a solution to this problem and unlocks the relative gains
enabled by ML.

</details>


### [8] [A New Method of Constructing Hadamard Matrices, Circulant Hadamard Matrices, CZCS, GCS, CCC, and CZCSS](https://arxiv.org/abs/2510.12315)
*Piyush Priyanshu,Sudhan Majhi,Subhabrata Paul*

Main category: eess.SP

TL;DR: 本文提出了一种基于循环Hadamard矩阵的新构造方法，使用线性算子和广义布尔函数构建了所有8个4阶循环Hadamard矩阵，并利用这些矩阵递归构造了二进制交叉Z互补集、Golay互补集和Hadamard矩阵，填补了二进制CZCS在所有长度构造上的空白。


<details>
  <summary>Details</summary>
Motivation: 循环Hadamard矩阵在编码理论中具有重要应用，但现有构造方法有限。本文旨在开发一种系统的方法来构造循环Hadamard矩阵及其相关序列集，解决二进制CZCS在所有长度构造上的缺失问题。

Method: 使用线性算子和广义布尔函数构造4阶循环Hadamard矩阵，然后递归应用这些矩阵来构建二进制CZCS、GCS和Hadamard矩阵。还提出了基于循环矩阵的低复杂度替代构造方法。

Result: 成功构造了所有8个4阶循环Hadamard矩阵，实现了二进制CZCS在所有偶数相位长度的覆盖，构建了所有长度的二进制GCS和阶数为2^{n+2}的Hadamard矩阵，并扩展构造了二进制CCC和最优CZCSS。

Conclusion: 所提出的所有构造方法都是新颖的，参数优于现有技术。通过建立Hadamard矩阵与GCS之间的关系，为Hadamard猜想的研究提供了新方向，同时发展了循环矩阵在非周期相关函数方面的性质理论。

Abstract: A Hadamard matrix $H$ is a square matrix of order $n$ with entries $\pm 1$,
such that $HH^\top=nI_{n}$, where $I_n$ is an identity matrix of order $n$. A
circulant Hadamard matrix $H$ is a Hadamard matrix that has rows of entries in
cyclic order. There exist only $8$ circulant Hadamard matrices of order 4, and
here, we provide a novel construction of all such $8$ circulant Hadamard
matrices using a linear operator and generalized Boolean function (GBF). The
constructed circulant Hadamard matrices are used recursively to construct a
binary cross Z-complementary set (CZCS) of all lengths with an even phase, a
binary Golay complementary set (GCS) of all lengths, and Hadamard matrices of
order $2^{n+2}$, where $n\geq1$. The construction of a binary CZCS covering all
lengths was not available before. We also propose an alternative,
lower-complexity construction of binary GCSs of all lengths and Hadamard
matrices of order $2^{a+1}10^b26^c$ using circulant matrices, where $ a,b,c
\geq 0$. The proposed binary GCS covers all lengths with a flexible flock size.
The constructions of GCS are further extended to form binary complete
complementary code (CCC) of the parameter $(2N,2N,2N)-CCC$ where
$N=2^a10^b26^c, a,b,c \geq 0$. The constructed binary CCC provides a flexible
flock size. The construction of CZCS is further extended to form a binary
optimal cross-Z complementary sequence set (CZCSS) of the parameter $(2^{n+2},
2^{n+2}, 2^{n+2}, 2^{n+1})-CZCSS$, where $n\geq1$. Finally, we provide a
relation between Hadamard matrices and GCS, which enables the study of the
Hadamard conjecture in a new direction. We also provided a few properties of
circulant matrices over aperiodic cross-correlation (ACCF) and aperiodic
auto-correlation (AACF), which are used to prove the theorems. All proposed
constructions are novel, and their parameters are compared with the existing
state-of-the-art.

</details>


### [9] [Beyond-Diagonal RIS Architecture Design and Optimization under Physics-Consistent Models](https://arxiv.org/abs/2510.12366)
*Zheyu Wu,Matteo Nerini,Bruno Clerckx*

Main category: eess.SP

TL;DR: 本文研究了基于物理一致性模型的对角线外可重构智能表面(BD-RIS)架构设计与优化，证明了带状连接RIS与全连接RIS具有相同的信道塑造能力，并开发了多种优化算法。


<details>
  <summary>Details</summary>
Motivation: 现有BD-RIS研究大多依赖简化的信道模型，忽略了实际电磁效应如互耦合和阻抗失配。本文旨在解决这一差距，在物理一致性模型下研究BD-RIS。

Method: 基于多端口网络理论建立的物理一致性模型，开发了闭式解(SISO系统)、半定松弛算法(单流MIMO系统)和ADMM算法(多用户MIMO系统)等优化方法。

Result: 证明了带状连接RIS与全连接RIS具有相同的信道塑造能力，通过仿真评估了各种电磁效应和近似对系统性能的影响。

Conclusion: 在物理一致性模型下，BD-RIS架构设计具有实际可行性，所提出的优化算法能有效处理各种电磁效应，为实际系统设计提供了理论支持。

Abstract: Reconfigurable intelligent surface (RIS) is a promising technology for future
wireless communication systems. Conventional RIS is constrained to a diagonal
scattering matrix, which limits its flexibility. Recently, beyond-diagonal RIS
(BD-RIS) has been proposed as a more general RIS architecture class that allows
inter-element connections and shows great potential for performance
improvement. Despite extensive progress on BD-RIS, most existing studies rely
on simplified channel models that ignore practical electromagnetic (EM) effects
such as mutual coupling and impedance mismatching. To address this gap, this
paper investigates the architecture design and optimization of BD-RIS under the
general physics-consistent model derived with multiport network theory in
recent literature. Building on a compact reformulation of this model, we show
that band-connected RIS achieves the same channel-shaping capability as
fully-connected RIS, which extends existing results obtained for conventional
channel models. We then develop optimization methods under the general
physics-consistent model; specifically, we derive closed-form solutions for
single-input single-output (SISO) systems, propose a globally optimal
semidefinite relaxation (SDR)-based algorithm for single-stream multi-input
multi-output (MIMO) systems, and design an efficient alternating direction
method of multipliers (ADMM)-based algorithm for multiuser MIMO systems. Using
the proposed algorithms, we conduct comprehensive simulations to evaluate the
impact of various EM effects and approximations, including mutual coupling
among RIS antennas and the commonly adopted unilateral approximation, on system
performance.

</details>


### [10] [HEAR: An EEG Foundation Model with Heterogeneous Electrode Adaptive Representation](https://arxiv.org/abs/2510.12515)
*Zhige Chen,Chengxuan Qin,Wenlong You,Rui Liu,Congying Chu,Rui Yang,Kay Chen Tan,Jibin Wu*

Main category: eess.SP

TL;DR: HEAR是首个专门支持异构EEG设备的EEG基础模型，通过可学习的基于坐标的空间嵌入将不同电极布局和数量的设备映射到统一表示空间，使用空间引导的transformer捕获时空依赖关系。


<details>
  <summary>Details</summary>
Motivation: 现有EEG基础模型面临EEG设备异构性的挑战，不同设备的电极布局和数量差异阻碍了模型的广泛应用和进一步发展。

Method: 采用可学习的基于坐标的空间嵌入处理不同电极布局和数量，使用空间引导的transformer模型捕获时空依赖关系，构建了包含8782小时数据的大规模EEG数据集。

Result: HEAR在支持异构EEG设备和跨认知任务、跨被试的泛化能力方面显著优于现有EEG基础模型。

Conclusion: HEAR成功解决了EEG设备异构性问题，为EEG基础模型的广泛应用和发展提供了有效解决方案。

Abstract: Electroencephalography (EEG) is an essential technique for neuroscience
research and brain-computer interface (BCI) applications. Recently, large-scale
EEG foundation models have been developed, exhibiting robust generalization
capabilities across diverse tasks and subjects. However, the heterogeneity of
EEG devices not only hinders the widespread adoption of these models but also
poses significant challenges to their further scaling and development. In this
paper, we introduce HEAR, the first EEG foundation model explicitly designed to
support heterogeneous EEG devices, accommodating varying electrode layouts and
electrode counts. HEAR employs a learnable, coordinate-based spatial embedding
to map electrodes with diverse layouts and varying counts into a unified
representational space. This unified spatial representation is then processed
by a novel spatially-guided transformer, which effectively captures
spatiotemporal dependencies across electrodes. To support the development of
HEAR, we construct a large-scale EEG dataset comprising 8,782 hours of data
collected from over 150 distinct electrode layouts with up to 1,132 electrodes.
Experimental results demonstrate that HEAR substantially outperforms existing
EEG foundation models in supporting heterogeneous EEG devices and generalizing
across diverse cognitive tasks and subjects.

</details>


### [11] [A Unified Framework for Adaptive Waveform Processing in Next Generation Wireless Networks](https://arxiv.org/abs/2510.12648)
*Abdelali Arous,Hamza Haif,Arman Farhang,Huseyin Arslan*

Main category: eess.SP

TL;DR: 本文分析多路复用域（如延迟-多普勒域和啁啾域）在复杂传播环境中的优势，提出了一个基于DFT矩阵预/后处理的通用自适应变换域框架，实现不同域间的动态切换。


<details>
  <summary>Details</summary>
Motivation: 传统时频域在复杂传播环境和下一代应用中面临挑战，新兴多路复用域提供了额外的自由度来建模和利用无线信道特性。

Method: 提出基于离散傅里叶变换矩阵预/后处理的通用自适应变换域框架，支持根据信道条件和系统需求在不同域间动态切换。

Result: 建立了跨域波形处理框架，能够适应不同信道条件，并通过代表性用例验证了其在不同场景下的适用性。

Conclusion: 多路复用域为无线通信提供了新的自由度，提出的跨域框架能够有效应对复杂传播环境，但未来仍需解决相关挑战。

Abstract: The emergence of alternative multiplexing domains to the time-frequency
domains, e.g., the delay-Doppler and chirp domains, offers a promising approach
for addressing the challenges posed by complex propagation environments and
next-generation applications. Unlike the time and frequency domains, these
domains offer unique channel representations which provide additional degrees
of freedom (DoF) for modeling, characterizing, and exploiting wireless channel
features. This article provides a comprehensive analysis of channel
characteristics, including delay, Doppler shifts, and channel coefficients
across various domains, with an emphasis on their inter-domain relationships,
shared characteristics, and domain-specific distinctions. We further evaluate
the comparative advantages of each domain under specific channel conditions.
Building on this analysis, we propose a generalized and adaptive transform
domain framework that leverages the pre- and post-processing of the discrete
Fourier transform (DFT) matrix, to enable dynamic transitions between various
domains in response to the channel conditions and system requirements. Finally,
several representative use cases are presented to demonstrate the applicability
of the proposed cross-domain waveform processing framework in diverse
scenarios, along with future directions and challenges.

</details>


### [12] [Moment-based Posterior Sampling for Multi-reference Alignment](https://arxiv.org/abs/2510.12651)
*Axel Janson,Joakim Andén*

Main category: eess.SP

TL;DR: 提出一种基于贝叶斯方法和扩散模型的多参考对齐方法，通过利用样本功率谱作为平移不变统计量，显著减少了所需样本数量，并在模拟实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有频率方法虽然能在低信噪比下准确恢复信号，但需要大量样本。本文旨在开发一种能减少所需样本数量并支持不确定性量化的方法。

Method: 使用扩散模型作为数据驱动的即插即用先验，将其条件化于样本功率谱（平移不变统计量），实现准确的后验采样和不确定性量化。

Result: 模拟实验表明，该方法显著减少了所需样本数量，在性能上优于期望最大化算法和双谱反演等最先进方法。

Conclusion: 该方法为多参考对齐问题提供了一个有前景的框架，并有望应用于其他轨道恢复问题，如冷冻电镜技术。

Abstract: We propose a Bayesian approach to the problem of multi-reference alignment --
the recovery of signals from noisy, randomly shifted observations. While
existing frequentist methods accurately recover the signal at arbitrarily low
signal-to-noise ratios, they require a large number of samples to do so. In
contrast, our proposed method leverages diffusion models as data-driven
plug-and-play priors, conditioning these on the sample power spectrum (a
shift-invariant statistic) enabling both accurate posterior sampling and
uncertainty quantification. The use of an appropriate prior significantly
reduces the required number of samples, as illustrated in simulation
experiments with comparisons to state-of-the-art methods such as
expectation--maximization and bispectrum inversion. These findings establish
our approach as a promising framework for other orbit recovery problems, such
as cryogenic electron microscopy (cryo-EM).

</details>


### [13] [Enhanced Angle-Range Cluster Parameter Estimation in Full-Duplex ISAC Systems](https://arxiv.org/abs/2510.12711)
*Muhammad Talha,Besma Smida,David González G*

Main category: eess.SP

TL;DR: 提出了一种用于角度和距离域扩展目标的集成感知与通信框架，包括截断MUSIC扩展算法和基于DFT的距离估计算法，以及动态发射波束成形算法。


<details>
  <summary>Details</summary>
Motivation: 研究在角度和距离域都扩展的目标的集成感知与通信问题，需要准确估计目标密度函数参数并同时服务多个下行用户。

Method: 使用截断MUSIC扩展算法估计密度函数参数，基于DFT的算法估计距离和距离扩展，开发动态发射波束成形算法。

Result: 仿真结果表明，在低高信噪比和宽角度扩展情况下，所提算法优于基线方案。

Conclusion: 提出的集成感知与通信框架能有效估计扩展目标参数并同时服务多个用户，在各种场景下都表现出优越性能。

Abstract: This work studies an integrated sensing and communication (ISAC) framework
for targets that are spread both in the angle and range domains. We model each
target using a cluster of rays parameterized by a specific density function,
and propose a truncated Multiple Signal Classification (MUSIC) spread (TMS)
algorithm to accurately estimate the parameters of the density function. Unlike
the conventional MUSIC spread (CMS), TMS restricts the signal subspace rank
based on the eigen decomposition of the received-signal autocorrelation. We
also propose a discrete Fourier transform (DFT) based algorithm for estimating
the distance and range spread of each target. Leveraging these estimates, we
then develop a dynamic transmit beamforming algorithm that successfully
illuminates multiple targets while also serving multiple downlink (DL) users.
Simulation results demonstrate the superiority of our proposed algorithms over
baseline schemes in both low and high signal-to-noise ratio (SNR) regimes as
well as under a wide angular spread regime.

</details>


### [14] [Disentangling Neurodegeneration with Brain Age Gap Prediction Models: A Graph Signal Processing Perspective](https://arxiv.org/abs/2510.12763)
*Saurabh Sihag,Gonzalo Mateos,Alejandro Ribeiro*

Main category: eess.SP

TL;DR: 本文介绍了基于图信号处理的脑年龄差距预测框架，使用协方差神经网络从结构MRI中提取解剖协方差矩阵，为神经退行性疾病提供可靠且可解释的生物标志物。


<details>
  <summary>Details</summary>
Motivation: 传统基于皮层厚度或脑体积的神经退行性评估方法缺乏统计复杂性，无法充分捕捉神经退行性在空间上的相关性和异质性。脑年龄差距作为一种有前景的数据驱动生物标志物，但其实际应用受到方法学模糊性和跨临床人群泛化能力有限的限制。

Method: 提出基于图信号处理的脑年龄差距预测框架，引入协方差神经网络，利用从结构MRI导出的解剖协方差矩阵。该方法具有坚实的理论基础和操作可解释性。

Result: VNNs能够稳健地估计脑年龄差距预测，整合了图信号处理、机器学习和网络神经科学的视角。

Conclusion: 该工作为可靠且可解释的脑年龄差距预测模型指明了前进方向，并为个性化医学的未来研究提供了路线图。

Abstract: Neurodegeneration, characterized by the progressive loss of neuronal
structure or function, is commonly assessed in clinical practice through
reductions in cortical thickness or brain volume, as visualized by structural
MRI. While informative, these conventional approaches lack the statistical
sophistication required to fully capture the spatially correlated and
heterogeneous nature of neurodegeneration, which manifests both in healthy
aging and in neurological disorders. To address these limitations, brain age
gap has emerged as a promising data-driven biomarker of brain health. The brain
age gap prediction (BAGP) models estimate the difference between a person's
predicted brain age from neuroimaging data and their chronological age. The
resulting brain age gap serves as a compact biomarker of brain health, with
recent studies demonstrating its predictive utility for disease progression and
severity. However, practical adoption of BAGP models is hindered by their
methodological obscurities and limited generalizability across diverse clinical
populations. This tutorial article provides an overview of BAGP and introduces
a principled framework for this application based on recent advancements in
graph signal processing (GSP). In particular, we focus on graph neural networks
(GNNs) and introduce the coVariance neural network (VNN), which leverages the
anatomical covariance matrices derived from structural MRI. VNNs offer strong
theoretical grounding and operational interpretability, enabling robust
estimation of brain age gap predictions. By integrating perspectives from GSP,
machine learning, and network neuroscience, this work clarifies the path
forward for reliable and interpretable BAGP models and outlines future research
directions in personalized medicine.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [15] [FakeMark: Deepfake Speech Attribution With Watermarked Artifacts](https://arxiv.org/abs/2510.12042)
*Wanying Ge,Xin Wang,Junichi Yamagishi*

Main category: eess.AS

TL;DR: FakeMark是一个新颖的水印框架，通过注入与深度伪造系统相关的伪影相关水印来解决深度伪造语音溯源问题，相比传统方法具有更好的泛化能力和抗干扰性。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造语音溯源解决方案存在局限性：基于分类器的方法对领域偏移样本泛化能力差，基于水印的方法容易受到编解码压缩或恶意移除攻击的影响。

Method: 提出FakeMark框架，注入与深度伪造系统相关的伪影相关水印，而非预分配的比特串消息。检测器可同时利用注入的水印和内在的深度伪造伪影进行系统溯源。

Result: 实验结果显示，FakeMark在基于分类器方法难以处理的跨数据集样本上提高了泛化能力，在各种失真条件下保持高准确率，而传统水印方法在此类情况下会失效。

Conclusion: FakeMark通过结合注入水印和内在伪影的双重线索，有效解决了深度伪造语音溯源中的泛化和鲁棒性问题，即使其中一条线索丢失也能保持有效检测。

Abstract: Deepfake speech attribution remains challenging for existing solutions.
Classifier-based solutions often fail to generalize to domain-shifted samples,
and watermarking-based solutions are easily compromised by distortions like
codec compression or malicious removal attacks. To address these issues, we
propose FakeMark, a novel watermarking framework that injects
artifact-correlated watermarks associated with deepfake systems rather than
pre-assigned bitstring messages. This design allows a detector to attribute the
source system by leveraging both injected watermark and intrinsic deepfake
artifacts, remaining effective even if one of these cues is elusive or removed.
Experimental results show that FakeMark improves generalization to
cross-dataset samples where classifier-based solutions struggle and maintains
high accuracy under various distortions where conventional watermarking-based
solutions fail.

</details>


### [16] [DiSTAR: Diffusion over a Scalable Token Autoregressive Representation for Speech Generation](https://arxiv.org/abs/2510.12210)
*Yakun Song,Xiaobin Zhuang,Jiawei Chen,Zhikang Niu,Guanrou Yang,Chenpeng Du,Zhuo Chen,Yuping Wang,Yuxuan Wang,Xie Chen*

Main category: eess.AS

TL;DR: DISTAR是一个零样本文本到语音框架，在离散残差向量量化代码空间中结合自回归语言模型和掩码扩散模型，实现高质量、可控的长音频合成。


<details>
  <summary>Details</summary>
Motivation: 现有的自回归草图生成器与基于扩散的细化器组合在分布偏移下表现脆弱，且可控性有限。需要开发更鲁棒、可控的零样本TTS系统。

Method: 在离散RVQ代码空间中，使用自回归语言模型生成块级草图，然后用并行掩码扩散模型进行条件填充，完成下一个块。支持分类器自由引导、可变比特率和计算控制。

Result: DISTAR在鲁棒性、自然度和说话人/风格一致性方面超越了最先进的零样本TTS系统，同时保持了丰富的输出多样性。

Conclusion: DISTAR通过离散代码空间中的紧密耦合AR-扩散模型，实现了高质量、可控的零样本TTS，为长音频合成提供了有效的解决方案。

Abstract: Recent attempts to interleave autoregressive (AR) sketchers with
diffusion-based refiners over continuous speech representations have shown
promise, but they remain brittle under distribution shift and offer limited
levers for controllability. We introduce DISTAR, a zero-shot text-to-speech
framework that operates entirely in a discrete residual vector quantization
(RVQ) code space and tightly couples an AR language model with a masked
diffusion model, without forced alignment or a duration predictor. Concretely,
DISTAR drafts block-level RVQ tokens with an AR language model and then
performs parallel masked-diffusion infilling conditioned on the draft to
complete the next block, yielding long-form synthesis with blockwise
parallelism while mitigating classic AR exposure bias. The discrete code space
affords explicit control at inference: DISTAR produces high-quality audio under
both greedy and sample-based decoding using classifier-free guidance, supports
trade-offs between robustness and diversity, and enables variable bit-rate and
controllable computation via RVQ layer pruning at test time. Extensive
experiments and ablations demonstrate that DISTAR surpasses state-of-the-art
zero-shot TTS systems in robustness, naturalness, and speaker/style
consistency, while maintaining rich output diversity. Audio samples are
provided on https://anonymous.4open.science/w/DiSTAR_demo.

</details>


### [17] [DeePAQ: A Perceptual Audio Quality Metric Based On Foundational Models and Weakly Supervised Learning](https://arxiv.org/abs/2510.12326)
*Guanxin Jiang,Andreas Brendel,Pablo M. Delgado,Jürgen Herre*

Main category: eess.AS

TL;DR: DeePAQ是一种基于深度学习的通用音频质量评估指标，利用度量学习和音乐基础模型MERT，通过弱监督标签构建能够捕捉音频失真强度的嵌入空间。


<details>
  <summary>Details</summary>
Motivation: 现有方法在通用音频质量评估领域尚未探索利用弱监督标签和度量学习来微调音乐基础模型的方向，DeePAQ旨在填补这一空白。

Method: 结合度量学习和音乐基础模型MERT，使用弱监督标签指导，采用LoRA（低秩适应）技术微调模型，构建捕捉音频失真强度的嵌入空间。

Result: 在音频编码和源分离的听力测试中，DeePAQ在检测编码伪影方面优于现有最先进的客观音频质量指标，并且对未见过的失真类型（如源分离）具有良好的泛化能力。

Conclusion: DeePAQ展示了在通用音频质量评估中的鲁棒性和多功能性，是首个在该领域结合弱监督标签、度量学习和音乐基础模型微调的方法。

Abstract: This paper presents the Deep learning-based Perceptual Audio Quality metric
(DeePAQ) for evaluating general audio quality. Our approach leverages metric
learning together with the music foundation model MERT, guided by surrogate
labels, to construct an embedding space that captures distortion intensity in
general audio. To the best of our knowledge, DeePAQ is the first in the general
audio quality domain to leverage weakly supervised labels and metric learning
for fine-tuning a music foundation model with Low-Rank Adaptation (LoRA), a
direction not yet explored by other state-of-the-art methods. We benchmark the
proposed model against state-of-the-art objective audio quality metrics across
listening tests spanning audio coding and source separation. Results show that
our method surpasses existing metrics in detecting coding artifacts and
generalizes well to unseen distortions such as source separation, highlighting
its robustness and versatility.

</details>


### [18] [A Phase Synthesizer for Decorrelation to Improve Acoustic Feedback Cancellation](https://arxiv.org/abs/2510.12377)
*Klaus Linhard,Philipp Bulling*

Main category: eess.AS

TL;DR: 提出了一种结合频率偏移和相位调制的统一框架——相位合成器，用于解决通信系统中的声学反馈问题，通过解相关扬声器和麦克风信号来提高系统稳定性和语音质量。


<details>
  <summary>Details</summary>
Motivation: 通信系统（如车载语音通信、扩声系统、助听器）中存在不期望的声学反馈问题，自适应滤波器在消除反馈路径时可能会抑制期望信号，需要解相关处理。

Method: 在DFT滤波器组中实现相位合成器，结合频率偏移和相位调制两种解相关方法，并扩展使用可变延迟线的相位调制技术。

Result: 在车载语音通信示例中，使用自适应频域卡尔曼滤波器，系统稳定性和语音质量（PESQ）得到改善。

Conclusion: 提出的相位合成器框架有效解决了声学反馈问题，提高了通信系统的性能和语音质量。

Abstract: Undesired acoustic feedback is a known issue in communication systems, such
as speech in-car communication, public address systems, or hearing aids.
Without additional precautions, there is a high risk that the adaptive filter -
intended to cancel the feedback path - also suppresses parts of the desired
signal. One solution is to decorrelate the loudspeaker and microphone signals.
In this work, we combine the two decorrelation approaches frequency shifting
and phase modulation in a unified framework: a so-called \textit{phase
synthesizer}, implemented in a discrete Fourier transform (DFT) filter bank.
Furthermore, we extend the phase modulation technique using variable delay
lines, as known from vibrato and chorus effects. We demonstrate the benefits of
the proposed phase synthesizer using an example from speech in-car
communication, employing an adaptive frequency-domain Kalman filter.
Improvements in system stability, speech quality measured by perceptual
evaluation of speech quality (PESQ) are presented.

</details>


### [19] [I-DCCRN-VAE: An Improved Deep Representation Learning Framework for Complex VAE-based Single-channel Speech Enhancement](https://arxiv.org/abs/2510.12485)
*Jiatong Li,Simon Doclo*

Main category: eess.AS

TL;DR: 改进DCCRN-VAE语音增强系统，通过移除预训练VAE的跳跃连接、使用β-VAE平衡重建和正则化、NSVAE同时生成语音和噪声潜在表示，提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有DCCRN-VAE系统在语音增强中存在泛化能力不足的问题，需要改进以在非匹配数据集上获得更好性能。

Method: 1) 移除预训练VAE的跳跃连接以增强潜在表示信息量；2) 使用β-VAE预训练平衡重建和正则化；3) NSVAE同时生成语音和噪声潜在表示；4) 用经典微调替代对抗训练简化流程。

Result: 在匹配DNS3数据集上性能与基线相当，但在非匹配数据集(WSJ0-QUT, Voicebank-DEMEND)上优于基线，显示改进的泛化能力。消融研究表明经典微调可达到相似性能。

Conclusion: 提出的改进方法有效提升了DCCRN-VAE系统的泛化能力，同时通过简化训练流程保持了性能。

Abstract: Recently, a complex variational autoencoder (VAE)-based single-channel speech
enhancement system based on the DCCRN architecture has been proposed. In this
system, a noise suppression VAE (NSVAE) learns to extract clean speech
representations from noisy speech using pretrained clean speech and noise VAEs
with skip connections. In this paper, we improve DCCRN-VAE by incorporating
three key modifications: 1) removing the skip connections in the pretrained
VAEs to encourage more informative speech and noise latent representations; 2)
using $\beta$-VAE in pretraining to better balance reconstruction and latent
space regularization; and 3) a NSVAE generating both speech and noise latent
representations. Experiments show that the proposed system achieves comparable
performance as the DCCRN and DCCRN-VAE baselines on the matched DNS3 dataset
but outperforms the baselines on mismatched datasets (WSJ0-QUT,
Voicebank-DEMEND), demonstrating improved generalization ability. In addition,
an ablation study shows that a similar performance can be achieved with
classical fine-tuning instead of adversarial training, resulting in a simpler
training pipeline.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [20] [Serial-Parallel Dual-Path Architecture for Speaking Style Recognition](https://arxiv.org/abs/2510.11732)
*Guojian Li,Qijie Shao,Zhixian Zhao,Shuiyuan Wang,Zhonghua Fu,Lei Xie*

Main category: cs.SD

TL;DR: 提出了一种新颖的串并行双路径架构用于语音风格识别，通过融合声学和语言双模态信息，显著提升了识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有的语音风格识别方法主要依赖语言信息，对声学信息的整合有限，这限制了识别准确性的提升。声学和语言模态的融合具有显著提升识别性能的潜力。

Method: 采用串并行双路径架构：串行路径遵循ASR+STYLE串行范式，反映顺序时间依赖性；并行路径集成了设计的声学-语言相似性模块(ALSM)，以促进具有时间同步性的跨模态交互。

Result: 与现有SSR基线OSUM模型相比，该方法将参数大小减少了88.4%，并在测试集上对八种风格的SSR准确率提高了30.3%。

Conclusion: 所提出的串并行双路径架构通过有效融合声学和语言双模态信息，在显著减少参数的同时大幅提升了语音风格识别的准确性。

Abstract: Speaking Style Recognition (SSR) identifies a speaker's speaking style
characteristics from speech. Existing style recognition approaches primarily
rely on linguistic information, with limited integration of acoustic
information, which restricts recognition accuracy improvements. The fusion of
acoustic and linguistic modalities offers significant potential to enhance
recognition performance. In this paper, we propose a novel serial-parallel
dual-path architecture for SSR that leverages acoustic-linguistic bimodal
information. The serial path follows the ASR+STYLE serial paradigm, reflecting
a sequential temporal dependency, while the parallel path integrates our
designed Acoustic-Linguistic Similarity Module (ALSM) to facilitate cross-modal
interaction with temporal simultaneity. Compared to the existing SSR baseline
-- the OSUM model, our approach reduces parameter size by 88.4% and achieves a
30.3% improvement in SSR accuracy for eight styles on the test set.

</details>


### [21] [SeeingSounds: Learning Audio-to-Visual Alignment via Text](https://arxiv.org/abs/2510.11738)
*Simone Carnemolla,Matteo Pennisi,Chiara Russo,Simone Palazzo,Daniela Giordano,Concetto Spampinato*

Main category: cs.SD

TL;DR: SeeingSounds是一个轻量级模块化音频到图像生成框架，通过双对齐机制将音频映射到语言语义空间和视觉领域，无需配对音频-视觉数据或视觉生成模型训练。


<details>
  <summary>Details</summary>
Motivation: 受认知神经科学启发，反映人类感知中自然跨模态关联，避免将音频仅视为文本替代品或依赖音频-文本映射。

Method: 使用冻结语言编码器将音频投影到语义语言空间，通过视觉语言模型上下文接地到视觉领域，在冻结扩散骨干上仅训练轻量适配器，支持通过程序化文本提示进行细粒度控制。

Result: 在标准基准测试中，SeeingSounds在零样本和监督设置下均优于现有方法，建立了可控音频到视觉生成的新技术状态。

Conclusion: 该框架实现了高效可扩展的学习，支持通过音频转换生成描述性提示来指导视觉输出，为音频到图像生成提供了新的解决方案。

Abstract: We introduce SeeingSounds, a lightweight and modular framework for
audio-to-image generation that leverages the interplay between audio, language,
and vision-without requiring any paired audio-visual data or training on visual
generative models. Rather than treating audio as a substitute for text or
relying solely on audio-to-text mappings, our method performs dual alignment:
audio is projected into a semantic language space via a frozen language
encoder, and, contextually grounded into the visual domain using a
vision-language model. This approach, inspired by cognitive neuroscience,
reflects the natural cross-modal associations observed in human perception. The
model operates on frozen diffusion backbones and trains only lightweight
adapters, enabling efficient and scalable learning. Moreover, it supports
fine-grained and interpretable control through procedural text prompt
generation, where audio transformations (e.g., volume or pitch shifts)
translate into descriptive prompts (e.g., "a distant thunder") that guide
visual outputs. Extensive experiments across standard benchmarks confirm that
SeeingSounds outperforms existing methods in both zero-shot and supervised
settings, establishing a new state of the art in controllable audio-to-visual
generation.

</details>


### [22] [Audio-Guided Visual Perception for Audio-Visual Navigation](https://arxiv.org/abs/2510.11760)
*Yi Wang,Yinfeng Yu,Fuchun Sun,Liejun Wang,Wendong Zheng*

Main category: cs.SD

TL;DR: AGVP框架通过音频-视觉对齐机制，将声音从策略记忆的声学指纹线索转化为空间引导，提升音频-视觉具身导航在未听过声音和未见环境中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有AVN方法在分布内声源上表现良好，但在遇到未听过声音或未见环境时，导航成功率骤降且搜索路径过长，这源于缺乏听觉信号与对应视觉区域的显式对齐机制。

Method: 提出AGVP框架：通过音频自注意力提取全局听觉上下文，将其作为查询引导视觉特征注意力，在特征层面突出声源相关区域，然后进行时序建模和策略优化。

Result: 实验结果表明AGVP提高了导航效率和鲁棒性，在未听过声音上实现了优越的跨场景泛化能力。

Conclusion: 基于可解释的跨模态对齐和区域重加权设计的AGVP框架，减少了对特定声学指纹的依赖，显著提升了音频-视觉具身导航的泛化性能。

Abstract: Audio-Visual Embodied Navigation aims to enable agents to autonomously
navigate to sound sources in unknown 3D environments using auditory cues. While
current AVN methods excel on in-distribution sound sources, they exhibit poor
cross-source generalization: navigation success rates plummet and search paths
become excessively long when agents encounter unheard sounds or unseen
environments. This limitation stems from the lack of explicit alignment
mechanisms between auditory signals and corresponding visual regions. Policies
tend to memorize spurious \enquote{acoustic fingerprint-scenario} correlations
during training, leading to blind exploration when exposed to novel sound
sources. To address this, we propose the AGVP framework, which transforms sound
from policy-memorable acoustic fingerprint cues into spatial guidance. The
framework first extracts global auditory context via audio self-attention, then
uses this context as queries to guide visual feature attention, highlighting
sound-source-related regions at the feature level. Subsequent temporal modeling
and policy optimization are then performed. This design, centered on
interpretable cross-modal alignment and region reweighting, reduces dependency
on specific acoustic fingerprints. Experimental results demonstrate that AGVP
improves both navigation efficiency and robustness while achieving superior
cross-scenario generalization on previously unheard sounds.

</details>


### [23] [Audio Palette: A Diffusion Transformer with Multi-Signal Conditioning for Controllable Foley Synthesis](https://arxiv.org/abs/2510.12175)
*Junnuo Wang*

Main category: cs.SD

TL;DR: Audio Palette是一个基于扩散变换器的可控音频生成模型，通过引入四种时变控制信号（响度、音高、频谱质心、音色）实现细粒度的音频控制，同时保持高质量的文本对齐和音频质量。


<details>
  <summary>Details</summary>
Motivation: 解决扩散基生成模型在文本到音频合成中细粒度声学控制的挑战，填补开源研究中可控音频生成的"控制空白"。

Method: 基于Stable Audio Open架构，使用扩散变换器，引入四种时变控制信号，采用低秩适应（LoRA）在AudioSet子集上进行高效微调，仅需训练0.85%的参数。

Result: 实现了细粒度、可解释的声音属性控制，在保持高音频质量和强文本语义对齐的同时，在FAD和LAION-CLAP等标准指标上与原始基线模型性能相当。

Conclusion: 为开源环境中的可控声音设计和表演性音频合成建立了坚实基础，实现了更加以艺术家为中心的工作流程。

Abstract: Recent advances in diffusion-based generative models have enabled
high-quality text-to-audio synthesis, but fine-grained acoustic control remains
a significant challenge in open-source research. We present Audio Palette, a
diffusion transformer (DiT) based model that extends the Stable Audio Open
architecture to address this "control gap" in controllable audio generation.
Unlike prior approaches that rely solely on semantic conditioning, Audio
Palette introduces four time-varying control signals: loudness, pitch, spectral
centroid, and timbre, for precise and interpretable manipulation of acoustic
features. The model is efficiently adapted for the nuanced domain of Foley
synthesis using Low-Rank Adaptation (LoRA) on a curated subset of AudioSet,
requiring only 0.85 percent of the original parameters to be trained.
Experiments demonstrate that Audio Palette achieves fine-grained, interpretable
control of sound attributes. Crucially, it accomplishes this novel
controllability while maintaining high audio quality and strong semantic
alignment to text prompts, with performance on standard metrics such as Frechet
Audio Distance (FAD) and LAION-CLAP scores remaining comparable to the original
baseline model. We provide a scalable, modular pipeline for audio research,
emphasizing sequence-based conditioning, memory efficiency, and a three-scale
classifier-free guidance mechanism for nuanced inference-time control. This
work establishes a robust foundation for controllable sound design and
performative audio synthesis in open-source settings, enabling a more
artist-centric workflow.

</details>


### [24] [UALM: Unified Audio Language Model for Understanding, Generation and Reasoning](https://arxiv.org/abs/2510.12000)
*Jinchuan Tian,Sang-gil Lee,Zhifeng Kong,Sreyan Ghosh,Arushi Goel,Chao-Han Huck Yang,Wenliang Dai,Zihan Liu,Hanrong Ye,Shinji Watanabe,Mohammad Shoeybi,Bryan Catanzaro,Rafael Valle,Wei Ping*

Main category: cs.SD

TL;DR: UALM是首个统一音频理解、文本到音频生成和多模态推理的音频语言模型，通过UALM-Gen和UALM-Reason实现了跨模态生成推理。


<details>
  <summary>Details</summary>
Motivation: 当前音频语言建模领域将音频理解和文本到音频生成作为独立任务处理，很少有研究尝试统一这些任务，而这是实现高级多模态推理的关键步骤。

Method: 提出UALM模型，首先开发UALM-Gen文本到音频语言模型直接预测音频token，然后通过数据混合、训练配方和推理技术，使单个模型在多个任务上达到最优性能，并引入UALM-Reason进行多模态推理。

Result: 单个UALM模型在音频理解、文本到音频生成和文本推理方面的质量与最先进的专用模型相当，UALM-Reason在主观评估中证实了跨模态生成推理的有效性。

Conclusion: 这是音频研究中首次展示跨模态生成推理，证明了统一音频语言建模在实现高级多模态推理方面的可行性。

Abstract: Recent advances in the audio language modeling (ALM) domain tackle audio
understanding and text-to-audio generation as separate tasks. Very few studies
attempt to unify these tasks -- an essential step toward advanced multimodal
reasoning. This paper introduces U}nified Audio Language Model (UALM), which
aims to unify audio understanding, text-to-audio generation, and multimodal
reasoning in a single model. To achieve this goal, we first present UALM-Gen, a
text-to-audio language model that directly predicts audio tokens and is
comparable to state-of-the-art diffusion-based models. We then demonstrate,
using proper data blending, training recipes, and inference techniques, that
our single UALM model matches the quality of state-of-the-art specialized
models in audio understanding, text-to-audio generation, and text reasoning.
Furthermore, we present UALM-Reason, a multimodal reasoning model that utilizes
both text and audio in the intermediate thinking steps to facilitate complex
generation tasks. To our knowledge, this is the first demonstration in audio
research of cross-modal generative reasoning, with its effectiveness confirmed
by subjective evaluations.

</details>


### [25] [TFGA-Net: Temporal-Frequency Graph Attention Network for Brain-Controlled Speaker Extraction](https://arxiv.org/abs/2510.12275)
*Youhao Si,Yuan Liao,Qiushi Han,Yuhang Yang,Rui Dai,Liya Huang*

Main category: cs.SD

TL;DR: 提出TFGA-Net模型，利用脑电图信号进行目标说话人提取，通过多尺度时频特征、图卷积网络和自注意力机制有效提取EEG信息，结合MossFormer2作为分离器，在多个数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 基于脑电图的听觉注意解码快速发展，但如何有效利用EEG与语音之间的目标说话人共同信息仍是一个未解决的问题。

Method: 使用多尺度时频特征和皮层拓扑结构提取EEG信息，采用图卷积网络和自注意力机制捕获EEG全局特征，引入MossFormer2结合MossFormer和RNN-Free Recurrent作为分离器。

Result: 在Cocktail Party和KUL数据集上的实验结果表明，TFGA-Net模型在特定客观评估指标上显著优于现有最先进方法。

Conclusion: 提出的TFGA-Net模型能够有效利用EEG信号进行目标说话人提取，在性能上取得了显著提升。

Abstract: The rapid development of auditory attention decoding (AAD) based on
electroencephalography (EEG) signals offers the possibility EEG-driven target
speaker extraction. However, how to effectively utilize the target-speaker
common information between EEG and speech remains an unresolved problem. In
this paper, we propose a model for brain-controlled speaker extraction, which
utilizes the EEG recorded from the listener to extract the target speech. In
order to effectively extract information from EEG signals, we derive
multi-scale time--frequency features and further incorporate cortical
topological structures that are selectively engaged during the task. Moreover,
to effectively exploit the non-Euclidean structure of EEG signals and capture
their global features, the graph convolutional networks and self-attention
mechanism are used in the EEG encoder. In addition, to make full use of the
fused EEG and speech feature and preserve global context and capture speech
rhythm and prosody, we introduce MossFormer2 which combines MossFormer and
RNN-Free Recurrent as separator. Experimental results on both the public
Cocktail Party and KUL dataset in this paper show that our TFGA-Net model
significantly outper-forms the state-of-the-art method in certain objective
evaluation metrics. The source code is available at:
https://github.com/LaoDa-X/TFGA-NET.

</details>


### [26] [Content Anonymization for Privacy in Long-form Audio](https://arxiv.org/abs/2510.12780)
*Cristina Aggazzotti,Ashi Garg,Zexin Cai,Nicholas Andrews*

Main category: cs.SD

TL;DR: 论文提出内容匿名化方法，通过上下文重写文本来消除说话者特定风格，保护长形式音频中的隐私。


<details>
  <summary>Details</summary>
Motivation: 现有语音匿名化技术在短语音中有效，但在长形式音频中，攻击者可以利用说话者的词汇、语法和表达习惯进行重识别，即使声音被完全伪装。

Method: 在ASR-TTS流程中执行上下文重写，通过转述消除说话者特定风格，同时保留语义。

Result: 在长形式电话对话场景中，内容匿名化方法能有效防御基于内容的攻击，同时保持语音实用性。

Conclusion: 转述是防御基于内容攻击的有效方法，建议相关方采用此步骤确保长形式音频的匿名性。

Abstract: Voice anonymization techniques have been found to successfully obscure a
speaker's acoustic identity in short, isolated utterances in benchmarks such as
the VoicePrivacy Challenge. In practice, however, utterances seldom occur in
isolation: long-form audio is commonplace in domains such as interviews, phone
calls, and meetings. In these cases, many utterances from the same speaker are
available, which pose a significantly greater privacy risk: given multiple
utterances from the same speaker, an attacker could exploit an individual's
vocabulary, syntax, and turns of phrase to re-identify them, even when their
voice is completely disguised. To address this risk, we propose new content
anonymization approaches. Our approach performs a contextual rewriting of the
transcripts in an ASR-TTS pipeline to eliminate speaker-specific style while
preserving meaning. We present results in a long-form telephone conversation
setting demonstrating the effectiveness of a content-based attack on
voice-anonymized speech. Then we show how the proposed content-based
anonymization methods can mitigate this risk while preserving speech utility.
Overall, we find that paraphrasing is an effective defense against
content-based attacks and recommend that stakeholders adopt this step to ensure
anonymity in long-form audio.

</details>

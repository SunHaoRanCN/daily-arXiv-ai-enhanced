<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 22]
- [eess.AS](#eess.AS) [Total: 7]
- [cs.SD](#cs.SD) [Total: 5]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Machine Learning-Based Performance Evaluation of a Solar-Powered Hydrogen Fuel Cell Hybrid in a Radio-Controlled Electric Vehicle](https://arxiv.org/abs/2510.17808)
*Amirhesam Aghanouri,Mohamed Sabry,Joshua Cherian Varughese,Cristina Olaverri-Monreal*

Main category: eess.SP

TL;DR: 本文研究了镍氢电池与质子交换膜燃料电池混合动力系统的性能，通过机器学习技术分析运行数据，提高了电压稳定性和系统可靠性。


<details>
  <summary>Details</summary>
Motivation: 研究混合动力系统在小型电动车上的应用潜力，探索可再生能源在交通领域的可行性。

Method: 采用数据驱动分析方法，结合信号处理和机器学习技术（包括时间卷积网络），在不同负载和环境条件下测试混合系统性能。

Result: 混合系统相比纯电池系统显著提高了电气性能和可靠性，机器学习方法能精确识别油门水平并预测电压行为。

Conclusion: 质子交换膜燃料电池与镍氢电池的集成显著改善了小型电动车的性能，为扩展到大型车辆提供了基准。

Abstract: This paper presents an experimental investigation and performance evaluation
of a hybrid electric radio-controlled car powered by a Nickel-Metal Hydride
battery combined with a renewable Proton Exchange Membrane Fuel Cell system.
The study evaluates the performance of the system under various load-carrying
scenarios and varying environmental conditions, simulating real-world operating
conditions including throttle operation. In order to build a predictive model,
gather operational insights, and detect anomalies, data-driven analyses using
signal processing and modern machine learning techniques were employed.
Specifically, machine learning techniques were used to distinguish throttle
levels with high precision based on the operational data. Anomaly and change
point detection methods enhanced voltage stability, resulting in fewer critical
faults in the hybrid system compared to battery-only operation. Temporal
Convolutional Networks were effectively employed to predict voltage behavior,
demonstrating potential for use in planning the locations of fueling or
charging stations. Moreover, integration with a solar-powered electrolyzer
confirmed the system's potential for off-grid, renewable hydrogen use. The
results indicate that integrating a Proton Exchange Membrane Fuel Cell with
Nickel-Metal Hydride batteries significantly improves electrical performance
and reliability for small electric vehicles, and these findings can be a
potential baseline for scaling up to larger vehicles.

</details>


### [2] [In-Process Monitoring of Gear Power Honing Using Vibration Signal Analysis and Machine Learning](https://arxiv.org/abs/2510.17809)
*Massimo Capurso,Luciano Afferrante*

Main category: eess.SP

TL;DR: 提出了一种基于振动信号分析和机器学习的齿轮强力珩磨过程监测框架，使用子空间学习方法提取特征，结合SVM分类器实现齿轮质量分类，在工业环境中达到100%的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 现代齿轮制造对NVH性能要求严格，传统质量控制方法无法实时检测瞬态加工异常，需要开发在线监测系统来确保加工质量。

Method: 通过加速度计连续采集振动数据，使用时频分析，比较三种子空间学习方法（PCA、PCA+LDA、R-UMLDA）进行特征提取，然后用SVM分类器预测四种齿轮质量类别。

Result: 在工业环境中实现了高达100%的分类准确率，提供了可解释的频谱特征，能够与工艺动态相关联。

Conclusion: 该数据驱动框架能够有效监测齿轮强力珩磨过程，为实时监控和预测性维护系统的实际集成提供了可行方案。

Abstract: In modern gear manufacturing, stringent Noise, Vibration, and Harshness (NVH)
requirements demand high-precision finishing operations such as power honing.
Conventional quality control strategies rely on post-process inspections and
Statistical Process Control (SPC), which fail to capture transient machining
anomalies and cannot ensure real-time defect detection. This study proposes a
novel, data-driven framework for in-process monitoring of gear power honing
using vibration signal analysis and machine learning. Our proposed methodology
involves continuous data acquisition via accelerometers, followed by
time-frequency signal analysis. We investigate and compare the efficacy of
three subspace learning methods for features extraction: (1) Principal
Component Analysis (PCA) for dimensionality reduction; (2) a two-stage
framework combining PCA with Linear Discriminant Analysis (LDA) for enhanced
class separation; and (3) Uncorrelated Multilinear Discriminant Analysis with
Regularization (R-UMLDA), adapted for tensor data, which enforces feature
decorrelation and includes regularization for small sample sizes. These
extracted features are then fed into a Support Vector Machine (SVM) classifier
to predict four distinct gear quality categories, established through rigorous
geometrical inspections and test bench results of assembled gearboxes. The
models are trained and validated on an experimental dataset collected in an
industrial context during gear power-honing operations, with gears classified
into four different quality categories. The proposed framework achieves high
classification accuracy (up to 100%) in an industrial setting. The approach
offers interpretable spectral features that correlate with process dynamics,
enabling practical integration into real-time monitoring and predictive
maintenance systems.

</details>


### [3] [Exploring Complexity Changes in Diseased ECG Signals for Enhanced Classification](https://arxiv.org/abs/2510.17810)
*Camilo Quiceno Quintero,Sandip Varkey George*

Main category: eess.SP

TL;DR: 使用非线性时间序列分析研究心电图复杂性如何随心脏病理变化，通过PTB-XL数据集提取非线性指标，发现疾病与健康个体间存在显著差异，并将这些复杂性量化指标整合到机器学习模型中提高了分类准确性。


<details>
  <summary>Details</summary>
Motivation: 心脏的复杂动态反映在其电活动中，通过心电图捕获。本研究旨在理解心电图复杂性如何随心脏病理变化，探索非线性分析在心脏疾病诊断中的应用价值。

Method: 使用PTB-XL数据集，从导联II ECG中提取非线性指标，并使用Spearman相关性和互信息计算跨通道指标（导联II、V2、AVL），然后将这些复杂性量化指标整合到机器学习模型中进行分类。

Result: 在几乎所有指标中，疾病与健康个体之间以及5个诊断超类之间均发现显著差异（p<0.001）。将这些复杂性量化指标整合到机器学习模型中，分类准确率从基线0.86（AUC）提高到0.87（非线性指标）和0.90（包括跨时间序列指标）。

Conclusion: 非线性时间序列分析能够有效捕捉心电图复杂性变化，这些复杂性指标对区分心脏疾病状态具有重要价值，整合到机器学习模型中可显著提高分类性能。

Abstract: The complex dynamics of the heart are reflected in its electrical activity,
captured through electrocardiograms (ECGs). In this study we use nonlinear time
series analysis to understand how ECG complexity varies with cardiac pathology.
Using the large PTB-XL dataset, we extracted nonlinear measures from lead II
ECGs, and cross-channel metrics (leads II, V2, AVL) using Spearman correlations
and mutual information. Significant differences between diseased and healthy
individuals were found in almost all measures between healthy and diseased
classes, and between 5 diagnostic superclasses ($p<.001$). Moreover,
incorporating these complexity quantifiers into machine learning models
substantially improved classification accuracy measured using area under the
ROC curve (AUC) from 0.86 (baseline) to 0.87 (nonlinear measures) and 0.90
(including cross-time series metrics).

</details>


### [4] [Channel Modeling of Satellite-to-Underwater Laser Communication Links: An Analytical-Monte Carlo Hybrid Approach](https://arxiv.org/abs/2510.17811)
*Zhixing Wang,Renzhi Yuan,Haifeng Yao,Chuang Yang,Mugen Peng*

Main category: eess.SP

TL;DR: 本文提出了一种综合的卫星-水下激光通信信道模型，采用解析-蒙特卡洛混合方法，同时考虑粒子和湍流效应，分析了不同环境条件下的通信性能。


<details>
  <summary>Details</summary>
Motivation: 现有的卫星-水下激光通信信道建模要么关注分离的信道，要么忽略了粒子和湍流对激光传播的综合影响，因此需要建立更全面的信道模型。

Method: 采用解析-蒙特卡洛混合方法：基于扩展惠更斯-菲涅尔原理获得激光束通过湍流大气后的强度分布；推导了光子通过气水界面后传播方向的闭式概率密度函数；使用蒙特卡洛方法模拟水下链路并获得接收平面的功率分布。

Result: 数值结果表明，水下粒子浓度对通信性能的影响比大气湍流和水下湍流都更显著；增加气水界面的风速不会显著恶化通信性能。

Conclusion: 提出的综合信道模型能够有效分析卫星-水下激光通信系统的性能，水下粒子浓度是影响通信质量的关键因素。

Abstract: Channel modeling for satellite-to-underwater laser communication (StULC)
links remains challenging due to long distances and the diversity of the
channel constituents. The StULC channel is typically segmented into three
isolated channels: the atmospheric channel, the air-water interface channel,
and the underwater channel. Previous studies involving StULC channel modeling
either focused on separated channels or neglected the combined effects of
particles and turbulence on laser propagation. In this paper, we established a
comprehensive StULC channel model by an analytical-Monte Carlo hybrid approach,
taking into account the effects of both particles and turbulence. We first
obtained the intensity distribution of the transmitted laser beam after passing
through the turbulent atmosphere based on the extended Huygens-Fresnel
principle. Then we derived a closed-form probability density function of the
photon propagating direction after passing through the air-water interface,
which greatly simplified the modeling of StULC links. At last, we employed a
Monte Carlo method to model the underwater links and obtained the power
distribution at the receiving plane. Based on the proposed StULC channel model,
we analyzed the bit error rate and the outage probability under different
environmental conditions. Numerical results demonstrated that, the influence of
underwater particle concentration on the communication performance is much
pronounced than those of both the atmospheric turbulence and the underwater
turbulence. Notably, increasing the wind speed at the air-water interface does
not significantly worsen the communication performance of the StULC links.

</details>


### [5] [Cross-Domain Multi-Person Human Activity Recognition via Near-Field Wi-Fi Sensing](https://arxiv.org/abs/2510.17816)
*Xin Li,Jingzhi Hu,Yinghui He,Hongbo Wang,Jin Gan,Jun Luo*

Main category: eess.SP

TL;DR: WiAnchor是一个用于Wi-Fi多用户活动识别的跨域适应训练框架，通过锚点匹配机制处理不完整活动类别，在缺少某些类别的情况下仍能实现超过90%的跨域准确率。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi活动识别在多用户场景下因空间分辨率粗糙而难以区分不同用户，且跨域适应时某些活动类别不可用，导致传统微调方法效果不佳。

Method: 采用三阶段训练：预训练阶段扩大类间特征边界增强可分性；微调阶段创新锚点匹配机制过滤特定用户干扰；最后基于特征相似性改进识别。

Result: 在构建的全面数据集上评估，WiAnchor在活动类别不完整的情况下实现了超过90%的跨域准确率。

Conclusion: WiAnchor通过锚点匹配机制有效解决了Wi-Fi多用户活动识别中跨域适应时活动类别不完整的问题，显著提升了识别性能。

Abstract: Wi-Fi-based human activity recognition (HAR) provides substantial convenience
and has emerged as a thriving research field, yet the coarse spatial resolution
inherent to Wi-Fi significantly hinders its ability to distinguish multiple
subjects. By exploiting the near-field domination effect, establishing a
dedicated sensing link for each subject through their personal Wi-Fi device
offers a promising solution for multi-person HAR under native traffic. However,
due to the subject-specific characteristics and irregular patterns of
near-field signals, HAR neural network models require fine-tuning (FT) for
cross-domain adaptation, which becomes particularly challenging with certain
categories unavailable. In this paper, we propose WiAnchor, a novel training
framework for efficient cross-domain adaptation in the presence of incomplete
activity categories. This framework processes Wi-Fi signals embedded with
irregular time information in three steps: during pre-training, we enlarge
inter-class feature margins to enhance the separability of activities; in the
FT stage, we innovate an anchor matching mechanism for cross-domain adaptation,
filtering subject-specific interference informed by incomplete activity
categories, rather than attempting to extract complete features from them;
finally, the recognition of input samples is further improved based on their
feature-level similarity with anchors. We construct a comprehensive dataset to
thoroughly evaluate WiAnchor, achieving over 90% cross-domain accuracy with
absent activity categories.

</details>


### [6] [Single-Snapshot Gridless 2D-DoA Estimation for UCAs: A Joint Optimization Approach](https://arxiv.org/abs/2510.17818)
*Salar Nouri*

Main category: eess.SP

TL;DR: 提出了一种用于单快照均匀圆阵的二维无网格DOA估计新框架，通过联合优化流形变换矩阵和源方位-俯仰角对，使用非精确增广拉格朗日方法高效求解，避免了半定规划。


<details>
  <summary>Details</summary>
Motivation: 传统无网格方法在单快照情况下由于计算成本过高或缺乏鲁棒性而失效，需要克服这些限制。

Method: 联合估计流形变换矩阵和源方位-俯仰角对，在一个统一的优化问题中通过非精确增广拉格朗日方法求解，统一了数据保真度和变换鲁棒性目标。

Result: 仿真结果表明，所提出的iALM框架能够提供鲁棒且高分辨率的无网格二维DOA估计。

Conclusion: 该方法特别适用于具有挑战性的单快照情况，为阵列信号处理应用建立了有效性。

Abstract: This paper tackles the challenging problem of gridless two-dimensional (2D)
direction-of-arrival (DOA) estimation for a uniform circular array (UCA) from a
single snapshot of data. Conventional gridless methods often fail in this
scenario due to prohibitive computational costs or a lack of robustness. We
propose a novel framework that overcomes these limitations by jointly
estimating a manifold transformation matrix and the source azimuth-elevation
pairs within a single, unified optimization problem. This problem is solved
efficiently using an inexact Augmented Lagrangian Method (iALM), which
completely circumvents the need for semidefinite programming. By unifying the
objectives of data fidelity and transformation robustness, our approach is
uniquely suited for the demanding single-snapshot case. Simulation results
confirm that the proposed iALM framework provides robust and high-resolution,
gridless 2D-DOA estimates, establishing its efficacy for challenging array
signal processing applications.

</details>


### [7] [CLARAE: Clarity Preserving Reconstruction AutoEncoder for Denoising and Rhythm Classification of Intracardiac Electrograms](https://arxiv.org/abs/2510.17821)
*Long Lin,Pablo Peiro-Corbacho,Pablo Ávila,Alejandro Carta-Bergaz,Ángel Arenal,Gonzalo R. Ríos-Muñoz,Carlos Sevilla-Salcedo*

Main category: eess.SP

TL;DR: CLARAE是一种用于心房内电图的编码器-解码器模型，能够实现高保真重建和紧凑的64维潜在表示，在心律分类和去噪任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 心房内电图常受噪声污染且维度高，限制了实时分析能力，需要开发既能去噪又能生成紧凑表示的方法。

Method: 采用一维编码器-解码器架构，通过池化下采样、混合插值-卷积上采样路径和有界潜在空间三个原则来保持波形形态。

Result: 在495,731个电图段上测试，CLARAE在所有心律类型的分类中F1分数超过0.97，潜在空间显示清晰的心律聚类，去噪性能始终名列前茅。

Conclusion: CLARAE结合了鲁棒的去噪能力和紧凑的判别性表示，为心律鉴别、信号质量评估和实时映射等临床工作流程提供了实用基础。

Abstract: Intracavitary atrial electrograms (EGMs) provide high-resolution insights
into cardiac electrophysiology but are often contaminated by noise and remain
high-dimensional, limiting real-time analysis. We introduce CLARAE
(CLArity-preserving Reconstruction AutoEncoder), a one-dimensional
encoder--decoder designed for atrial EGMs, which achieves both high-fidelity
reconstruction and a compact 64-dimensional latent representation. CLARAE is
designed to preserve waveform morphology, mitigate reconstruction artifacts,
and produce interpretable embeddings through three principles: downsampling
with pooling, a hybrid interpolation--convolution upsampling path, and a
bounded latent space.
  We evaluated CLARAE on 495,731 EGM segments (unipolar and bipolar) from 29
patients across three rhythm types (AF, SR300, SR600). Performance was
benchmarked against six state-of-the-art autoencoders using reconstruction
metrics, rhythm classification, and robustness across signal-to-noise ratios
from -5 to 15 dB. In downstream rhythm classification, CLARAE achieved
F1-scores above 0.97 for all rhythm types, and its latent space showed clear
clustering by rhythm. In denoising tasks, it consistently ranked among the top
performers for both unipolar and bipolar signals.
  In order to promote reproducibility and enhance accessibility, we offer an
interactive web-based application. This platform enables users to explore
pre-trained CLARAE models, visualize the reconstructions, and compute metrics
in real time. Overall, CLARAE combines robust denoising with compact,
discriminative representations, offering a practical foundation for clinical
workflows such as rhythm discrimination, signal quality assessment, and
real-time mapping.

</details>


### [8] [Covariance Matrix Construction with Preprocessing-Based Spatial Sampling for Robust Adaptive Beamforming](https://arxiv.org/abs/2510.17823)
*Saeed Mohammadzadeh,Rodrigo C. de Lamare,Yuriy Zakharov*

Main category: eess.SP

TL;DR: 提出一种高效的鲁棒自适应波束形成技术，通过预处理空间采样重建干扰加噪声协方差矩阵，解决导向矢量估计失配和协方差矩阵重建问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统自适应波束形成中存在的导向矢量估计失配和数据协方差矩阵重建问题，提高波束形成系统的鲁棒性和性能。

Method: 使用到达方向估计干扰源，通过预处理空间采样重建干扰加噪声协方差矩阵，采用功率谱采样策略和功率方法计算期望信号的导向矢量。

Result: 仿真结果表明，相比现有方法，所提方法在性能上表现更优，能够有效处理导向矢量失配问题。

Conclusion: 提出的预处理空间采样方法在计算效率和鲁棒性方面优于现有技术，为自适应波束形成提供了一种有效的解决方案。

Abstract: This work proposes an efficient, robust adaptive beamforming technique to
deal with steering vector (SV) estimation mismatches and data covariance matrix
reconstruction problems. In particular, the direction-of-arrival(DoA) of
interfering sources is estimated with available snapshots in which the angular
sectors of the interfering signals are computed adaptively. Then, we utilize
the well-known general linear combination algorithm to reconstruct the
interference-plus-noise covariance (IPNC) matrix using preprocessing-based
spatial sampling (PPBSS). We demonstrate that the preprocessing matrix can be
replaced by the sample covariance matrix (SCM) in the shrinkage method. A power
spectrum sampling strategy is then devised based on a preprocessing matrix
computed with the estimated angular sectors' information. Moreover, the
covariance matrix for the signal is formed for the angular sector of the
signal-of-interest (SOI), which allows for calculating an SV for the SOI using
the power method. An analysis of the array beampattern in the proposed PPBSS
technique is carried out, and a study of the computational cost of competing
approaches is conducted. Simulation results show the proposed method's
effectiveness compared to existing approaches.

</details>


### [9] [Carbon-Aware Orchestration of Integrated Satellite Aerial Terrestrial Networks via Digital Twin](https://arxiv.org/abs/2510.17825)
*Shumaila Javaid,Nasir Saeed*

Main category: eess.SP

TL;DR: 提出了一种基于数字孪生技术的碳感知编排框架，用于集成卫星-空中-地面网络(ISATNs)，通过多时间尺度的PDCA循环和碳感知控制策略，显著降低碳排放。


<details>
  <summary>Details</summary>
Motivation: ISATNs作为6G关键使能技术，大规模部署面临能源消耗和碳排放的可持续性问题，需要碳感知的编排方案来减少环境影响。

Method: 采用数字孪生技术，构建基于克CO2当量/比特的可持续性指标，实施多时间尺度的PDCA循环，结合日前预测和实时自适应优化，利用碳感知切换、无人机占空比控制和可再生能源感知边缘放置等控制策略。

Result: 使用真实碳强度数据的仿真结果显示，相比仅考虑QoS的编排，gCO2/bit降低高达29%，同时提高了可再生能源利用率和不利事件下的弹性。

Conclusion: 该碳感知编排框架能有效降低ISATNs的碳排放，提升可持续性，同时保持网络性能，为6G网络的绿色部署提供了可行方案。

Abstract: Integrated Satellite Aerial Terrestrial Networks (ISATNs) are envisioned as
key enablers of 6G, providing global connectivity for applications such as
autonomous transportation, Industrial IoT, and disaster response. Their
large-scale deployment, however, risks unsustainable energy use and carbon
emissions. This work advances prior energy-aware studies by proposing a
carbon-aware orchestration framework for ISATNs that leverages Digital Twin
(DT) technology. The framework adopts grams of CO$_2$-equivalent per bit
(gCO$_2$/bit) as a primary sustainability metric and implements a multi
timescale Plan Do Check Act (PDCA) loop that combines day-ahead forecasting
with real-time adaptive optimization. ISATN-specific control knobs, including
carbon-aware handovers, UAV duty cycling, and renewable-aware edge placement,
are exploited to reduce emissions. Simulation results with real carbon
intensity data show up to 29\% lower gCO$_2$/bit than QoS-only orchestration,
while improving renewable utilization and resilience under adverse events.

</details>


### [10] [Synthetic EEG Generation using Diffusion Models for Motor Imagery Tasks](https://arxiv.org/abs/2510.17832)
*Henrique de Lima Alexandre,Clodoaldo Aparecido de Moraes Lima*

Main category: eess.SP

TL;DR: 该研究提出使用扩散概率模型生成运动想象脑电信号的方法，以解决脑电数据采集困难的问题。生成的合成数据在分类任务中达到95%以上准确率，能有效补充数据集。


<details>
  <summary>Details</summary>
Motivation: 脑电信号采集面临传感器成本高、采集时间长和个体间差异大等挑战，导致高质量脑电数据稀缺，限制了脑机接口应用的发展。

Method: 预处理真实脑电数据，训练扩散模型从噪声中重建脑电通道，并通过信号级和任务级指标评估生成信号质量。使用KNN、CNN和U-Net分类器验证合成数据性能。

Result: 生成的合成脑电信号在分类任务中达到95%以上准确率，与真实信号具有低均方误差和高相关性。

Conclusion: 扩散模型生成的合成脑电信号能有效补充数据集，提高脑机接口中的分类性能，解决数据稀缺问题。

Abstract: Electroencephalography (EEG) is a widely used, non-invasive method for
capturing brain activity, and is particularly relevant for applications in
Brain-Computer Interfaces (BCI). However, collecting high-quality EEG data
remains a major challenge due to sensor costs, acquisition time, and
inter-subject variability. To address these limitations, this study proposes a
methodology for generating synthetic EEG signals associated with motor imagery
brain tasks using Diffusion Probabilistic Models (DDPM). The approach involves
preprocessing real EEG data, training a diffusion model to reconstruct EEG
channels from noise, and evaluating the quality of the generated signals
through both signal-level and task-level metrics. For validation, we employed
classifiers such as K-Nearest Neighbors (KNN), Convolutional Neural Networks
(CNN), and U-Net to compare the performance of synthetic data against real data
in classification tasks. The generated data achieved classification accuracies
above 95%, with low mean squared error and high correlation with real signals.
  Our results demonstrate that synthetic EEG signals produced by diffusion
models can effectively complement datasets, improving classification
performance in EEG-based BCIs and addressing data scarcity.

</details>


### [11] [Two Phases Leakage Detection Strategy Supported by DMAs](https://arxiv.org/abs/2510.17836)
*G. Messa,G. Acconciaioco,S. Ripani,L. Bozzelli,A. Simone,O. Giustolisi*

Main category: eess.SP

TL;DR: 提出了一种新颖的两阶段基于模型的泄漏检测策略，包括DMA识别和管道预定位，通过检测异常来识别泄漏，并返回需要检查的管道序列以最小化检查成本。


<details>
  <summary>Details</summary>
Motivation: 为水务公司提供一种能够识别DMA级别异常并以最小检查成本定位泄漏的有效策略，同时考虑DMA配置和压力测量系统的影响。

Method: 采用两阶段方法：首先识别DMA，然后在识别出的DMA中进行管道预定位。使用AMSI指标来限制假阳性，该指标对导致点状泄漏的恶化敏感但对一般恶化不敏感。

Result: 该策略能够有效检测泄漏并返回需要检查的管道序列，通过AMSI指标显著减少了DMA识别阶段的假阳性。

Conclusion: 提出的两阶段策略为水务公司提供了一种实用的泄漏检测和定位方法，能够以最小检查成本有效识别和定位泄漏。

Abstract: The present work proposes a novel two phases model-based strategy for leakage
detection. The two phases are: the identification of the district metering area
(DMA) and the pipe pre-localization into the identified DMA. The strategy is
based on detecting and pre-localizing the punctual leakage as anomaly with
respect to the normal working conditions. A further novelty is the fact that
the pre-localization phase returns the sequence of pipes to inspect, which
makes the strategy attractive for water utilities, whose aim is to identify the
anomaly at DMA level and, successively, to localize it with the minimum
inspection cost. Furthermore, a random database is useful to test the
performance of the strategy with respect to the configuration of DMAs and the
pressure metering system. Consequently, a novel strategy to design the location
of pressure meters is also proposed. It is demonstrated that the entire
strategy limits false positives during the DMA identification phase by using
the recently proposed index named Asset Management Support Indicator (AMSI).
AMSI is invariant with respect to the deterioration, i.e., it is sensitive to
its increase causing punctual leakage. The strategy is studied and discussed
using two real Apulian WDNs managed by Acquedotto Pugliese.

</details>


### [12] [Majority Vote Compressed Sensing](https://arxiv.org/abs/2510.18008)
*Henrik Hellström,Jiwon Jeong,Ayfer Özgür,Viktoria Fodor,Carlo Fischione*

Main category: eess.SP

TL;DR: 提出MVCS方案，利用随机变换和多数投票AirComp，在T=O(kn log(d)/ε²)信道使用次数下估计高维稀疏数据向量的和，误差为ε。


<details>
  <summary>Details</summary>
Motivation: 现有非相干AirComp方案需要超过d次信道使用来计算函数，当数据向量稀疏时，可以利用稀疏性显著降低通信开销。

Method: 使用随机变换传输数据向量的低维投影，通过多数投票AirComp方案估计聚合投影的符号向量，利用1位压缩感知恢复原始高维聚合。

Result: MVCS方案能以ℓ₂范数误差ε估计聚合数据向量∑x_i，所需信道使用次数T=O(kn log(d)/ε²)。

Conclusion: MVCS相比现有技术具有优势，可用于直方图估计和分布式机器学习等应用。

Abstract: We consider the problem of non-coherent over-the-air computation (AirComp),
where $n$ devices carry high-dimensional data vectors
$\mathbf{x}_i\in\mathbb{R}^d$ of sparsity $\lVert\mathbf{x}_i\rVert_0\leq k$
whose sum has to be computed at a receiver. Previous results on non-coherent
AirComp require more than $d$ channel uses to compute functions of
$\mathbf{x}_i$, where the extra redundancy is used to combat non-coherent
signal aggregation. However, if the data vectors are sparse, sparsity can be
exploited to offer significantly cheaper communication. In this paper, we
propose to use random transforms to transmit lower-dimensional projections
$\mathbf{s}_i\in\mathbb{R}^T$ of the data vectors. These projected vectors are
communicated to the receiver using a majority vote (MV)-AirComp scheme, which
estimates the bit-vector corresponding to the signs of the aggregated
projections, i.e., $\mathbf{y} = \text{sign}(\sum_i\mathbf{s}_i)$. By
leveraging 1-bit compressed sensing (1bCS) at the receiver, the real-valued and
high-dimensional aggregate $\sum_i\mathbf{x}_i$ can be recovered from
$\mathbf{y}$. We prove analytically that the proposed MVCS scheme estimates the
aggregated data vector $\sum_i \mathbf{x}_i$ with $\ell_2$-norm error
$\epsilon$ in $T=\mathcal{O}(kn\log(d)/\epsilon^2)$ channel uses. Moreover, we
specify algorithms that leverage MVCS for histogram estimation and distributed
machine learning. Finally, we provide numerical evaluations that reveal the
advantage of MVCS compared to the state-of-the-art.

</details>


### [13] [MCANet: A Coherent Multimodal Collaborative Attention Network for Advanced Modulation Recognition in Adverse Noisy Environments](https://arxiv.org/abs/2510.18336)
*Wangye Jiang,Haoming Yang,Xinyu Lu,Mingyuan Wang,Huimei Sun,Jingya Zhang*

Main category: eess.SP

TL;DR: MCANet是一个多模态深度学习框架，通过精炼特征提取和全局建模来提升自动调制识别在低信噪比条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 传统自动调制识别方法在复杂、嘈杂环境中，特别是在低信噪比条件下表现不佳，需要更鲁棒的解决方案。

Method: 提出MCANet多模态深度学习框架，采用精炼特征提取和全局建模来支持融合策略。

Result: 在多个基准数据集上的实验结果表明，MCANet优于主流AMR模型，在低信噪比条件下具有更好的鲁棒性。

Conclusion: MCANet为自动调制识别提供了一种有效的多模态深度学习方法，特别适用于低信噪比环境。

Abstract: As wireless communication systems evolve, automatic modulation recognition
(AMR) plays a key role in improving spectrum efficiency, especially in
cognitive radio systems. Traditional AMR methods face challenges in complex,
noisy environments, particularly in low signal-to-noise ratio (SNR) conditions.
This paper introduces MCANet (Multimodal Collaborative Attention Network), a
multimodal deep learning framework designed to address these challenges. MCANet
employs refined feature extraction and global modeling to support its fusion
strategy.Experimental results across multiple benchmark datasets show that
MCANet outperforms mainstream AMR models, offering better robustness in low-SNR
conditions.

</details>


### [14] [AWSPNet: Attention-based Dual-Tree Wavelet Scattering Prototypical Network for MIMO Radar Target Recognition and Jamming Suppression](https://arxiv.org/abs/2510.18422)
*Yizhen Jia,Siyao Xiao,Wenkai Jia,Hui Chen,Wen-Qin Wang*

Main category: eess.SP

TL;DR: 提出了一种基于注意力机制的双树小波散射原型网络(AWSPNet)，用于雷达目标识别和干扰抑制，在低信噪比环境下实现90.45%的准确率。


<details>
  <summary>Details</summary>
Motivation: 数字射频存储器电子对抗技术的进步对雷达系统生存能力构成严重威胁，需要能够在低信噪比环境下区分真实目标和复杂干扰信号。

Method: 使用双树复小波变换提取抗噪特征，结合注意力机制和预训练骨干网络进行特征优化，采用监督对比学习和原型网络进行少样本分类。

Result: 在-6 dB信噪比下达到90.45%的准确率，通过t-SNE可视化验证特征可分性，结合时域滑动窗口实现干扰抑制。

Conclusion: AWSPNet在复杂电磁环境中具有实际应用潜力，能够有效识别目标并抑制各种干扰类型。

Abstract: The increasing of digital radio frequency memory based electronic
countermeasures poses a significant threat to the survivability and
effectiveness of radar systems. These jammers can generate a multitude of
deceptive false targets, overwhelming the radar's processing capabilities and
masking targets. Consequently, the ability to robustly discriminate between
true targets and complex jamming signals, especially in low signal-to-noise
ratio (SNR) environments, is of importance. This paper introduces the
attention-based dual-tree wavelet scattering prototypical network (AWSPNet), a
deep learning framework designed for simultaneous radar target recognition and
jamming suppression. The core of AWSPNet is the encoder that leverages the
dual-tree complex wavelet transform to extract features that are inherently
robust to noise and signal translations. These features are further refined by
an attention mechanism and a pre-trained backbone network. To address the
challenge of limited labeled data and enhance generalization, we employ a
supervised contrastive learning strategy during the training phase. The
classification is performed by a prototypical network, which is particularly
effective in few-shot learning scenarios, enabling rapid adaptation to new
signal types. We demonstrate the efficacy of our approach through extensive
experiments. The results show that AWSPNet achieves 90.45\% accuracy at -6 dB
SNR. Furthermore, we provide a physical interpretation of the network's inner
workings through t-SNE visualizations, which analyze the feature separability
at different stages of the model. Finally, by integrating AWSPNet with a
time-domain sliding window approach, we present a complete algorithm capable of
not only identifying but also effectively suppressing various types of jamming,
thereby validating its potential for practical application in complex
electromagnetic environments.

</details>


### [15] [Microsecond Federated SVD on Grassmann Manifold for Real-time IoT Intrusion Detection](https://arxiv.org/abs/2510.18501)
*Tung-Anh Nguyen,Van-Phuc Bui,Shashi Raj Pandey,Kim Hue Ta,Nguyen H. Tran,Petar Popovski*

Main category: eess.SP

TL;DR: FedSVD是一个基于奇异值分解和Grassmann流形优化的无监督联邦学习框架，用于物联网网络的实时异常检测，无需标记数据或集中式数据共享，显著降低通信开销和计算成本。


<details>
  <summary>Details</summary>
Motivation: 物联网网络需要实时异常检测来应对已知和未知入侵，但传统方法依赖标记数据或集中式数据处理，不适合资源受限的物联网设备。

Method: 利用奇异值分解(SVD)和Grassmann流形优化，在低功耗设备上实现无监督联邦学习，避免数据共享并减少通信开销。

Result: FedSVD性能与深度学习基线相当，同时推理延迟降低超过10倍，适合延迟敏感的物联网应用。

Conclusion: FedSVD为物联网网络提供了一种高效、低延迟的无监督异常检测解决方案，特别适用于资源受限的边缘设备。

Abstract: This paper introduces FedSVD, a novel unsupervised federated learning
framework for real-time anomaly detection in IoT networks. By leveraging
Singular Value Decomposition (SVD) and optimization on the Grassmann manifolds,
FedSVD enables accurate detection of both known and unknown intrusions without
relying on labeled data or centralized data sharing. Tailored for deployment on
low-power devices like the NVIDIA Jetson AGX Orin, the proposed method
significantly reduces communication overhead and computational cost.
Experimental results show that FedSVD achieves performance comparable to deep
learning baselines while reducing inference latency by over 10x, making it
suitable for latency-sensitive IoT applications.

</details>


### [16] [Channel-Aware Vector Quantization for Robust Semantic Communication on Discrete Channels](https://arxiv.org/abs/2510.18604)
*Zian Meng,Qiang Li,Wenqian Tang,Mingdie Yan,Xiaohu Ge*

Main category: eess.SP

TL;DR: 提出了一种通道感知向量量化(CAVQ)算法，在联合源信道编码(JSCC)框架下实现离散语义传输，通过集成信道状态信息来提升数字语义通信的鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于深度学习的语义通信主要依赖模拟或半数字传输，与现代数字通信基础设施兼容性差。虽然已有研究使用向量量化实现离散语义传输，但忽略了信道状态信息在码本优化中的作用，导致鲁棒性不足。

Method: 在离散无记忆信道下建立VQJSCC框架，将语义特征离散化并直接映射到调制星座符号。CAVQ算法将信道转移概率集成到量化过程中，使易混淆符号与语义相似的码字对齐。引入多码本对齐机制处理码本顺序与调制顺序不匹配问题。

Result: 实验结果表明VQJSCC有效缓解了数字悬崖效应，在各种调制方案下实现了优越的重建质量，在鲁棒性和效率方面均优于最先进的数字语义通信基线方法。

Conclusion: 所提出的通道感知向量量化方法成功解决了现有数字语义通信中的鲁棒性问题，为与现代数字通信基础设施兼容的语义通信提供了有效解决方案。

Abstract: Deep learning-based semantic communication has largely relied on analog or
semi-digital transmission, which limits compatibility with modern digital
communication infrastructures. Recent studies have employed vector quantization
(VQ) to enable discrete semantic transmission, yet existing methods neglect
channel state information during codebook optimization, leading to suboptimal
robustness. To bridge this gap, we propose a channel-aware vector quantization
(CAVQ) algorithm within a joint source-channel coding (JSCC) framework, termed
VQJSCC, established on a discrete memoryless channel. In this framework,
semantic features are discretized and directly mapped to modulation
constellation symbols, while CAVQ integrates channel transition probabilities
into the quantization process, aligning easily confused symbols with
semantically similar codewords. A multi-codebook alignment mechanism is further
introduced to handle mismatches between codebook order and modulation order by
decomposing the transmission stream into multiple independently optimized
subchannels. Experimental results demonstrate that VQJSCC effectively mitigates
the digital cliff effect, achieves superior reconstruction quality across
various modulation schemes, and outperforms state-of-the-art digital semantic
communication baselines in both robustness and efficiency.

</details>


### [17] [Delay Management Using Packet Fragmentation in Wireless Industrial Automation Systems](https://arxiv.org/abs/2510.18646)
*Anwar Ahmed Khan,Shama Siddiqui,Indrakshi Dey*

Main category: eess.SP

TL;DR: 本文比较了FROG-MAC和FPS-MAC两种MAC协议在工业自动化环境中的性能，发现FROG-MAC在能效和延迟方面优于FPS-MAC。


<details>
  <summary>Details</summary>
Motivation: 工业自动化应用对延迟管理有严格要求，需要高效的MAC协议来保证关键数据的及时传输，特别是在存在异构数据的工业环境中。

Method: 使用Contiki作为仿真平台，采用单跳星型拓扑模拟工业环境，比较FROG-MAC和FPS-MAC两种协议的性能。

Result: FROG-MAC在能效和延迟方面表现优于FPS-MAC，这得益于其能够中断信道中正在进行的低优先级传输的固有特性。

Conclusion: FROG-MAC协议在工业异构无线网络中具有更好的性能潜力，特别是在延迟和能效方面。

Abstract: Managing delay is one of the core requirements of industrial automation
applications due to the high risk associated for equipment and human lives.
Using efficient Media Access Control (MAC) schemes guarantees the timely
transmission of critical data, particularly in the industrial environments
where heterogeneous data is inherently expected. This paper compares the
performance of Fragmentation based MAC (FROG-MAC) against Fuzzy Priority
Scheduling based MAC (FPS-MAC), both of which have been designed to optimize
the performance of heterogenous wireless networks. Contiki has been used as a
simulation platform and a single hop star topology has been assumed to resemble
the industrial environment. It has been shown that FROG-MAC has the potential
to outperform FPS-MAC in terms of energy efficiency and delay both, due to its
inherent feature of interrupting ongoing lower priority transmission on the
channel.

</details>


### [18] [A Comparative Analysis of High-Level vs. Low-Level Simulations for Dynamic MAC Protocols in Wireless Sensor Networks](https://arxiv.org/abs/2510.18662)
*Shama Siddiqui,Anwar Ahmed Khan,Indrakshi Dey*

Main category: eess.SP

TL;DR: 比较了ADP-MAC协议在高级理论模拟和详细实现模拟中的性能差异，发现两种模拟方法在能耗和延迟趋势上存在显著不同。


<details>
  <summary>Details</summary>
Motivation: 评估无线传感器网络中MAC协议性能模拟的质量，比较理论模拟与详细实现结果之间的差异，确保协议在实际部署前的可靠性。

Method: 使用MATLAB进行高级理论模拟，使用TinyOS在Mica2平台上开发详细实现，基于能耗和延迟评估ADP-MAC协议的性能。

Result: 高级模拟中能耗随轮询间隔增加而减少，延迟增加；详细实现中能耗和延迟都随轮询间隔增加而增加。两种模拟的趋势显著不同。

Conclusion: 高级理论模拟缺乏现实假设，导致与详细实现结果存在显著差异，强调了在实际部署前进行详细实现验证的重要性。

Abstract: Simulation studies are conducted at different levels of details for assessing
the performance of Media Access Control (MAC) protocols in Wireless Sensor
Networks (WSN). In the present-day scenario where hundreds of MAC protocols
have been proposed, it is important to assess the quality of performance
evaluation being conducted for each of the proposed protocols. It therefore
becomes crucial to compare the results of high-level theoretical simulations
with the detailed implementation results before any network protocol could be
deployed for a real-world scenario. In this work, we present a comparison of
high-level theoretical and detailed implementation results for Adaptive and
Dynamic Polling-MAC (ADP-MAC). MATLAB has been used for conducting initial
theoretical simulations and TinyOS has been used to develop the detailed
implementation of protocol for Mica2 platform. Performance evaluation of
ADP-MAC using the two levels of simulation has been conducted based on energy
and delay. In the high-level implementation, energy consumption was found to be
decreasing whereas delay was found to be increasing for increasing channel
polling intervals. On the other hand, when detailed implementation was
developed, it was observed that both energy consumption and delay revealed an
increasing trend with the increasing polling intervals. Therefore, it has been
shown that the trends for high- and low-level simulations for ADP-MAC are
significantly different, due to the lack of realistic assumptions in the
higher-level study.

</details>


### [19] [mSQUID: Model-Based Leanred Modulo Recovery at Low Sampling Rates](https://arxiv.org/abs/2510.18729)
*Yhonatan Kvich,Rotem Arie,Hana Hasan,Shaik Basheeruddin Shah,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 提出mSQUID方法，结合压缩感知和深度学习，通过软量化模块处理模数采样的非线性失真，在低采样率和高斯噪声下实现优越的信号重建性能。


<details>
  <summary>Details</summary>
Motivation: 模数采样通过将信号折叠到有限区间避免信号削波，但引入的非线性失真在噪声和量化条件下给信号恢复带来挑战，需要新的恢复方法。

Method: 基于模型的深度展开网络，结合经典压缩感知求解器的可解释性和学习的灵活性，使用软量化模块以可微分方式引导解向折叠范围的离散倍数。

Result: 在低采样率和高斯噪声下实现优越的重建性能，能够同时恢复幅度差异大且频带不重叠的信号，显著减少运行时间。

Conclusion: mSQUID方法有效解决了模数采样中的信号恢复挑战，适用于实时资源受限系统，在避免信号削波的同时保持高重建质量。

Abstract: Modulo sampling enables acquisition of signals with unlimited dynamic range
by folding the input into a bounded interval prior to sampling, thus
eliminating the risk of signal clipping and preserving information without
requiring highresolution ADCs. While this enables low-cost hardware, the
nonlinear distortion introduced by folding presents recovery challenges,
particularly under noise and quantization. We propose a model-based deep
unfolding network tailored to this setting, combining the interpretability of
classical compress sensing (CS) solvers with the flexibility of learning. A key
innovation is a soft-quantization module that encodes the modulo prior by
guiding the solution toward discrete multiples of the folding range in a
differentiable and learnable way. Our method, modulo soft-quantized unfolded
iterative decoder (mSQUID), achieves superior reconstruction performance at low
sampling rates under additive Gaussian noise. We further demonstrate its
utility in a challenging case where signals with vastly different amplitudes
and disjoint frequency bands are acquired simultaneously and quantized. In this
scenario, classical sampling often struggles due to weak signal distortion or
strong signal clipping, while our approach is able to recover the input
signals. Our method also offers significantly reduced runtimes, making it
suitable for real-time, resource-limited systems.

</details>


### [20] [Wireless-Fed Pinching-Antenna Systems (Wi-PASS) for NextG Wireless Networks](https://arxiv.org/abs/2510.18743)
*Kasun R. Wijewardhana,Animesh Yadav,Ming Zeng,Mohamed Elsayed,Octavia A. Dobre,Zhiguo Ding*

Main category: eess.SP

TL;DR: 本文提出无线馈电的夹持天线系统(Wi-PASS)，通过无线方式为波导供电，解决了传统有线馈电PASS系统部署受限的问题，能更灵活地扩展毫米波和太赫兹频段的覆盖范围。


<details>
  <summary>Details</summary>
Motivation: 传统波导夹持天线系统(PASS)依赖有线馈电，限制了部署灵活性，只能部署在基站附近区域，无法经济有效地服务远距离用户。

Method: 采用无线馈电技术为波导供电，开发无线馈电夹持天线系统(Wi-PASS)，通过室内外多种应用场景进行验证。

Result: Wi-PASS相比传统固定天线系统能提供更高的数据速率，在覆盖扩展方面比PASS更具优势，证实了其可行性和优越性能。

Conclusion: Wi-PASS为毫米波和太赫兹频段提供了一种实用且经济高效的覆盖扩展解决方案，未来研究应进一步推进其部署应用。

Abstract: Waveguide-based pinching-antenna systems (PASS) have recently emerged as a
promising solution to mitigate severe propagation losses in millimeter-wave and
terahertz bands by intelligently and flexibly establishing line-of-sight links.
However, their reliance on wire-based feeding confines deployment to areas near
the base station (BS), limiting installation flexibility and making them
cost-ineffective for serving distant users or regions. To overcome this
challenge, this article proposes wireless-fed pinchingantenna systems
(Wi-PASS), which employ wireless feeding to energize waveguides. Wi-PASS offer
a practical and cost-efficient means to extend coverage beyond the BS vicinity.
Several indoor and outdoor use cases demonstrate Wi-PASS advantages over PASS.
Numerical results further show that Wi-PASS deliver higher data rates than
conventional fixed-antenna systems, confirming the superior feasibility and
performance of Wi-PASS. Key future research directions are also discussed to
advance Wi-PASS deployment.

</details>


### [21] [Analyse comparative d'algorithmes de restauration en architecture dépliée pour des signaux chromatographiques parcimonieux](https://arxiv.org/abs/2510.18760)
*Mouna Gharbi,Silvia Villa,Emilie Chouzenoux,Jean-Christophe Pesquet,Laurent Duval*

Main category: eess.SP

TL;DR: 对三种展开式架构在参数化色谱信号数据库上进行比较研究，展示了这些方法在物理化学峰信号表征方面的性能


<details>
  <summary>Details</summary>
Motivation: 从稀疏假设的退化观测中恢复数据是一个活跃的研究领域，传统迭代优化方法现在与深度学习技术互补，展开式方法结合了两者的优势

Method: 在参数化色谱信号数据库上对三种展开式架构进行对比研究，使用适应物理化学峰信号表征的度量指标

Result: 展示了这些方法的性能表现，特别是在采用适应物理化学峰信号表征的度量时

Conclusion: 展开式方法结合了传统优化和深度学习的优势，在色谱信号恢复任务中表现出色

Abstract: Data restoration from degraded observations, of sparsity hypotheses, is an
active field of study. Traditional iterative optimization methods are now
complemented by deep learning techniques. The development of unfolded methods
benefits from both families. We carry out a comparative study of three
architectures on parameterized chromatographic signal databases, highlighting
the performance of these approaches, especially when employing metrics adapted
to physico-chemical peak signal characterization.

</details>


### [22] [SO(3)-invariant PCA with application to molecular data](https://arxiv.org/abs/2510.18827)
*Michael Fraiman,Paulina Hoyos,Tamir Bendory,Joe Kileel,Oscar Mickelin,Nir Sharon,Amit Singer*

Main category: eess.SP

TL;DR: 提出了一种SO(3)不变的主成分分析方法，用于处理具有未知方向的三维体积数据，无需显式数据增强即可隐式考虑所有旋转，显著降低了计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统PCA在处理具有任意方向的三维数据（如结构生物学中常见的数据）时面临挑战，因为需要为每个样本生成大量旋转副本，导致计算成本过高。

Method: 通过利用底层代数结构，开发了一个高效的SO(3)不变PCA框架，仅需计算协方差矩阵条目总数的平方根，从而大幅降低复杂度。

Result: 在真实分子数据集上验证了该方法的有效性，证明其能够有效处理大规模高维重建问题。

Conclusion: 该方法为处理具有未知方向的三维体积数据提供了一种高效且原理性的解决方案，为大规模高维重建问题开辟了新可能性。

Abstract: Principal component analysis (PCA) is a fundamental technique for
dimensionality reduction and denoising; however, its application to
three-dimensional data with arbitrary orientations -- common in structural
biology -- presents significant challenges. A naive approach requires
augmenting the dataset with many rotated copies of each sample, incurring
prohibitive computational costs. In this paper, we extend PCA to 3D volumetric
datasets with unknown orientations by developing an efficient and principled
framework for SO(3)-invariant PCA that implicitly accounts for all rotations
without explicit data augmentation. By exploiting underlying algebraic
structure, we demonstrate that the computation involves only the square root of
the total number of covariance entries, resulting in a substantial reduction in
complexity. We validate the method on real-world molecular datasets,
demonstrating its effectiveness and opening up new possibilities for
large-scale, high-dimensional reconstruction problems.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [23] [Hearing Health in Home Healthcare: Leveraging LLMs for Illness Scoring and ALMs for Vocal Biomarker Extraction](https://arxiv.org/abs/2510.18169)
*Yu-Wen Chen,William Ho,Sasha M. Vergez,Grace Flaherty,Pallavi Gupta,Zhihong Zhang,Maryam Zolnoori,Margaret V. McDonald,Maxim Topaz,Zoran Kostic,Julia Hirschberg*

Main category: eess.AS

TL;DR: 该研究探索利用大型语言模型和音频语言模型从家庭护理录音中自动评估健康状况，通过整合SOAP笔记和生命体征生成疾病评分，并分析声学生物标志物与健康状况的关联。


<details>
  <summary>Details</summary>
Motivation: 家庭医疗保健需求增长，需要能够支持护理服务的工具。研究利用真实世界家庭护理访问数据中的多样化患者信息，探索从语音中自动评估健康状况的方法。

Method: 1. 使用LLM整合来自非结构化音频转录的SOAP笔记和结构化生命体征，生成反映患者整体健康状况的疾病评分；2. 设计多阶段预处理流程从家庭护理录音中提取目标说话者的短语音片段；3. 使用音频语言模型生成声学生物标志物的自然语言描述，并分析其与健康状况的关联。

Result: 实验结果表明，商业和开源LLM在估计疾病评分方面表现良好，与临床结果一致，且SOAP笔记比生命体征信息更丰富。首次证明ALM能够从家庭护理录音中识别与健康相关的声学模式，并以人类可读形式呈现。

Conclusion: LLM和ALM有潜力利用异质性的家庭访问数据进行更好的患者监测和护理，展示了从语音自动评估健康状况的可行性。

Abstract: The growing demand for home healthcare calls for tools that can support care
delivery. In this study, we explore automatic health assessment from voice
using real-world home care visit data, leveraging the diverse patient
information it contains. First, we utilize Large Language Models (LLMs) to
integrate Subjective, Objective, Assessment, and Plan (SOAP) notes derived from
unstructured audio transcripts and structured vital signs into a holistic
illness score that reflects a patient's overall health. This compact
representation facilitates cross-visit health status comparisons and downstream
analysis. Next, we design a multi-stage preprocessing pipeline to extract short
speech segments from target speakers in home care recordings for acoustic
analysis. We then employ an Audio Language Model (ALM) to produce
plain-language descriptions of vocal biomarkers and examine their association
with individuals' health status. Our experimental results benchmark both
commercial and open-source LLMs in estimating illness scores, demonstrating
their alignment with actual clinical outcomes, and revealing that SOAP notes
are substantially more informative than vital signs. Building on the illness
scores, we provide the first evidence that ALMs can identify health-related
acoustic patterns from home care recordings and present them in a
human-readable form. Together, these findings highlight the potential of LLMs
and ALMs to harness heterogeneous in-home visit data for better patient
monitoring and care.

</details>


### [24] [Joint Estimation of Piano Dynamics and Metrical Structure with a Multi-task Multi-Scale Network](https://arxiv.org/abs/2510.18190)
*Zhanhong He,Hanyu Meng,David Huang,Roberto Togneri*

Main category: eess.AS

TL;DR: 提出一个高效的多任务网络，从共享潜在表示中联合预测钢琴动态级别、变化点、节拍和下拍，在MazurkaBL数据集上取得最先进结果。


<details>
  <summary>Details</summary>
Motivation: 从音频录音中估计钢琴动态是计算音乐分析的基本挑战，需要开发高效准确的动态估计方法。

Method: 使用多尺度网络作为主干，以Bark尺度特定响度作为输入特征，构建多任务网络联合预测动态级别、变化点、节拍和下拍。

Result: 模型参数量从14.7M减少到0.5M，支持60秒音频输入，在MazurkaBL数据集上所有任务都达到最先进水平。

Conclusion: 这项工作为钢琴动态估计设定了新基准，提供了一个强大紧凑的工具，为大规模、资源高效的音乐表达分析铺平了道路。

Abstract: Estimating piano dynamic from audio recordings is a fundamental challenge in
computational music analysis. In this paper, we propose an efficient multi-task
network that jointly predicts dynamic levels, change points, beats, and
downbeats from a shared latent representation. These four targets form the
metrical structure of dynamics in the music score. Inspired by recent vocal
dynamic research, we use a multi-scale network as the backbone, which takes
Bark-scale specific loudness as the input feature. Compared to log-Mel as
input, this reduces model size from 14.7 M to 0.5 M, enabling long sequential
input. We use a 60-second audio length in audio segmentation, which doubled the
length of beat tracking commonly used. Evaluated on the public MazurkaBL
dataset, our model achieves state-of-the-art results across all tasks. This
work sets a new benchmark for piano dynamic estimation and delivers a powerful
and compact tool, paving the way for large-scale, resource-efficient analysis
of musical expression.

</details>


### [25] [SAC: Neural Speech Codec with Semantic-Acoustic Dual-Stream Quantization](https://arxiv.org/abs/2510.16841)
*Wenxi Chen,Xinsheng Wang,Ruiqi Yan,Yushen Chen,Zhikang Niu,Ziyang Ma,Xiquan Li,Yuzhe Liang,Hanlin Wen,Shunshun Yin,Ming Tao,Xie Chen*

Main category: eess.AS

TL;DR: 提出SAC神经语音编解码器，采用语义-声学双流量化设计，在重建质量和语义表示方面均优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有语音编解码器难以平衡高质量重建与丰富语义表示，限制了在生成和理解任务中的效果

Method: 语义-声学双流量化，将语义和声学建模解耦为两个专用流，分别优化各自角色

Result: 在不同比特率下实现强重建性能，UTMOS和WER得分高；语义表示大幅优于现有编解码器，接近自监督学习连续嵌入水平

Conclusion: 双流设计有效实现语音解耦，为可控语音应用提供新潜力

Abstract: Speech codecs that convert continuous speech signals into discrete tokens
have become essential for speech language models (SLMs). However, existing
codecs struggle to balance high-quality reconstruction with semantically rich
representations, limiting their effectiveness in both generative and
understanding tasks. In this work, we propose SAC, a neural speech codec with
semantic-acoustic dual-stream quantization. By disentangling semantic and
acoustic modeling into two dedicated streams, SAC enables each to be optimized
for its respective role. Comprehensive evaluations show that SAC achieves
strong reconstruction performance across diverse bitrates under both clean and
noisy conditions, with particularly high scores on UTMOS and WER, demonstrating
superior perceptual quality and intelligibility. Moreover, SAC substantially
outperforms state-of-the-art codecs in semantic representation, achieving a
level comparable to that of self-supervised learning (SSL) continuous
embeddings. Finally, our analysis of speech disentanglement highlights the
effectiveness of the dual-stream design, offering new potential for
controllable speech applications.

</details>


### [26] [Adaptive Per-Channel Energy Normalization Front-end for Robust Audio Signal Processing](https://arxiv.org/abs/2510.18206)
*Hanyu Meng,Vidhyasaharan Sethu,Eliathamby Ambikairajah,Qiquan Zhang,Haizhou Li*

Main category: eess.AS

TL;DR: 提出了一种用于音频前端的新型自适应范式，用闭环神经控制器替代静态参数化，通过动态调整每通道能量归一化实现自适应表示，在多种音频分类任务中优于现有固定和可学习前端。


<details>
  <summary>Details</summary>
Motivation: 当前可学习音频前端虽然在不同任务中表现出色，但其参数在训练后固定不变，缺乏推理时的灵活性，限制了在动态复杂声学环境下的鲁棒性。

Method: 简化了可学习前端LEAF架构，集成神经控制器用于自适应表示，通过动态调整每通道能量归一化实现。神经控制器利用当前和缓冲的过去子带能量，在推理时实现输入相关的自适应。

Result: 在多个音频分类任务的实验结果表明，所提出的自适应前端在干净和复杂声学条件下都持续优于先前的固定和可学习前端。

Conclusion: 神经自适应是下一代音频前端的一个有前景的方向。

Abstract: In audio signal processing, learnable front-ends have shown strong
performance across diverse tasks by optimizing task-specific representation.
However, their parameters remain fixed once trained, lacking flexibility during
inference and limiting robustness under dynamic complex acoustic environments.
In this paper, we introduce a novel adaptive paradigm for audio front-ends that
replaces static parameterization with a closed-loop neural controller.
Specifically, we simplify the learnable front-end LEAF architecture and
integrate a neural controller for adaptive representation via dynamically
tuning Per-Channel Energy Normalization. The neural controller leverages both
the current and the buffered past subband energies to enable input-dependent
adaptation during inference. Experimental results on multiple audio
classification tasks demonstrate that the proposed adaptive front-end
consistently outperforms prior fixed and learnable front-ends under both clean
and complex acoustic conditions. These results highlight neural adaptability as
a promising direction for the next generation of audio front-ends.

</details>


### [27] [MVDR Beamforming for Cyclostationary Processes](https://arxiv.org/abs/2510.18391)
*Giovanni Bologni,Martin Bo Møller,Richard Heusdens,Richard C. Hendriks*

Main category: eess.AS

TL;DR: 该论文提出了循环MVDR（cMVDR）波束形成器，通过利用空间和频谱相关性来改进噪声抑制，特别适用于低信噪比场景中的准周期噪声源。


<details>
  <summary>Details</summary>
Motivation: 传统声学波束形成器假设噪声在短时帧内是平稳的，这限制了它们利用准周期噪声源（如乐器、风扇、发动机）中频率间相关性的能力。这些信号具有周期性变化的统计特性，更适合建模为循环平稳过程。

Method: 基于频率移位（FRESH）滤波方法，通过组合输入的移位版本来衰减或放大跨频率相干的分量。针对非谐波性，提出数据驱动策略，通过周期图分析估计共振频率，并计算其间距的频率偏移。

Result: 分析和实验结果表明，随着频谱相关性的增加，性能得到改善。在实际录音中，cMVDR在尺度不变信噪比（SI-SDR）上比MVDR最多提高5 dB，即使使用单个麦克风也保持有效。

Conclusion: cMVDR波束形成器通过利用循环平稳特性，在准周期噪声抑制方面显著优于传统MVDR方法，特别是在低信噪比条件下。

Abstract: Conventional acoustic beamformers assume that noise is stationary within
short time frames. This assumption prevents them from exploiting correlations
between frequencies in almost-periodic noise sources such as musical
instruments, fans, and engines. These signals exhibit periodically varying
statistics and are better modeled as cyclostationary processes. This paper
introduces the cyclic MVDR (cMVDR) beamformer, an extension of the conventional
MVDR that leverages both spatial and spectral correlations to improve noise
reduction, particularly in low-SNR scenarios. The method builds on
frequency-shifted (FRESH) filtering, where shifted versions of the input are
combined to attenuate or amplify components that are coherent across frequency.
To address inharmonicity, where harmonic partials deviate from exact integer
multiples of the fundamental frequency, we propose a data-driven strategy that
estimates resonant frequencies via periodogram analysis and computes the
frequency shifts from their spacing. Analytical and experimental results
demonstrate that performance improves with increasing spectral correlation. On
real recordings, the cMVDR achieves up to 5 dB gain in scale-invariant
signal-to-distortion ratio (SI-SDR) over the MVDR and remains effective even
with a single microphone. Code is available at
https://github.com/Screeen/cMVDR.

</details>


### [28] [ProLAP: Probabilistic Language-Audio Pre-Training](https://arxiv.org/abs/2510.18423)
*Toranosuke Manabe,Yuchi Ishikawa,Hokuto Munakata,Tatsuya Komatsu*

Main category: eess.AS

TL;DR: ProLAP提出概率性语言-音频预训练方法，通过概率分布建模多对多的语言-音频关系，引入层次包含损失和掩码排斥损失来有效学习层次结构。


<details>
  <summary>Details</summary>
Motivation: 现实世界中语言-音频关系本质上是多对多的，一个音频片段可以有多个描述，反之亦然。现有确定性嵌入方法假设一对一对应，无法处理这种复杂性。

Method: 提出Probabilistic Language-Audio Pre-training (ProLAP)，在联合嵌入空间中用概率分布建模多重性；引入层次包含损失促进语义层次理解，掩码排斥损失提高层次包含损失优化的效率。

Result: ProLAP在音频-文本检索任务上优于现有确定性方法；通过音频遍历任务实验证明模型能捕捉合理的语义层次结构。

Conclusion: ProLAP能够从小数据集中学习数据的层次结构，而先前的概率方法依赖大规模数据集，证明了该方法在建模语言-音频多对多关系方面的有效性。

Abstract: Language-audio joint representation learning frameworks typically depend on
deterministic embeddings, assuming a one-to-one correspondence between audio
and text. In real-world settings, however, the language-audio relationship is
inherently many-to-many: one audio segment can be described by multiple
captions and vice versa. To address this, we propose Probabilistic
Language-Audio Pre-training (ProLAP), which models multiplicity as the spread
of probability distributions in a joint language-audio embedding space. To
train the intra-modal hierarchical relationship effectively, we also introduce
two objectives: (i) hierarchical inclusion loss to promote semantic
hierarchical understanding of inputs and (ii) mask repulsive loss to improve
the efficiency of learning when optimizing the hierarchical inclusion loss.
With this training strategy, our model can learn the hierarchical structure
inherent in the data even from small datasets, in contrast to prior
probabilistic approaches that rely on large-scale datasets. In our experiments,
ProLAP outperforms existing deterministic approaches on audio-text retrieval
tasks. Moreover, through experiments on the audio traversal task introduced in
this paper, we demonstrate that ProLAP captures the plausible semantic
hierarchy.

</details>


### [29] [Diffusion Buffer for Online Generative Speech Enhancement](https://arxiv.org/abs/2510.18744)
*Bunlong Lay,Rostislav Makarov,Simon Welker,Maris Hillemann,Timo Gerkmann*

Main category: eess.AS

TL;DR: 提出了Diffusion Buffer方法，一种基于扩散模型的在线语音增强技术，通过将物理时间与扩散时间步对齐，实现了每帧信号只需一次神经网络调用的高效处理，大幅降低了算法延迟。


<details>
  <summary>Details</summary>
Motivation: 传统生成式语音增强模型需要多次神经网络调用，计算复杂度高，不适合在线应用。本文旨在开发一种只需单次神经网络调用的扩散模型，实现高效的在线语音增强。

Method: 设计了Diffusion Buffer方法，将物理时间与扩散时间步对齐，通过渐进式去噪处理数据流。还开发了专门匹配look-ahead的2D卷积UNet架构，并使用Data Prediction损失函数替代Denoising Score Matching损失。

Result: 将算法延迟从320-960ms大幅降低到32-176ms，同时性能还有所提升。在未见噪声语音数据上，在线Diffusion Buffer超越了预测式方法的表现。

Conclusion: Diffusion Buffer成功实现了基于扩散模型的高效在线语音增强，在保持生成模型优势的同时解决了计算复杂度问题，为在线应用提供了可行的解决方案。

Abstract: Online Speech Enhancement was mainly reserved for predictive models. A key
advantage of these models is that for an incoming signal frame from a stream of
data, the model is called only once for enhancement. In contrast, generative
Speech Enhancement models often require multiple calls, resulting in a
computational complexity that is too high for many online speech enhancement
applications. This work presents the Diffusion Buffer, a generative
diffusion-based Speech Enhancement model which only requires one neural network
call per incoming signal frame from a stream of data and performs enhancement
in an online fashion on a consumer-grade GPU. The key idea of the Diffusion
Buffer is to align physical time with Diffusion time-steps. The approach
progressively denoises frames through physical time, where past frames have
more noise removed. Consequently, an enhanced frame is output to the listener
with a delay defined by the Diffusion Buffer, and the output frame has a
corresponding look-ahead. In this work, we extend upon our previous work by
carefully designing a 2D convolutional UNet architecture that specifically
aligns with the Diffusion Buffer's look-ahead. We observe that the proposed
UNet improves performance, particularly when the algorithmic latency is low.
Moreover, we show that using a Data Prediction loss instead of Denoising Score
Matching loss enables flexible control over the trade-off between algorithmic
latency and quality during inference. The extended Diffusion Buffer equipped
with a novel NN and loss function drastically reduces the algorithmic latency
from 320 - 960 ms to 32 - 176 ms with an even increased performance. While it
has been shown before that offline generative diffusion models outperform
predictive approaches in unseen noisy speech data, we confirm that the online
Diffusion Buffer also outperforms its predictive counterpart on unseen noisy
speech data.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [30] [Transformer Redesign for Late Fusion of Audio-Text Features on Ultra-Low-Power Edge Hardware](https://arxiv.org/abs/2510.18036)
*Stavros Mitsis,Ermos Hadjikyriakos,Humaid Ibrahim,Savvas Neofytou,Shashwat Raman,James Myles,Eiman Kanjo*

Main category: cs.SD

TL;DR: 提出了一种针对Edge TPU优化的硬件感知情感识别系统，结合声学和语言特征，在超约束边缘设备上实现实时多模态情感推理。


<details>
  <summary>Details</summary>
Motivation: 解决在小型、低功耗、私密的边缘设备上部署情感识别系统的挑战，特别是在紧张监测、冲突降级和响应式可穿戴设备等应用中，云端解决方案不切实际。

Method: 采用后期融合架构，结合量化基于transformer的声学模型和DSResNet-SE网络的冻结关键词嵌入，使用MicroFrontend和MLTK确保训练和部署时的频谱图对齐。

Result: 在1.8MB内存预算和21-23ms延迟内实现实时推理，在重新录制、分段的IEMOCAP样本上比单模态基线提高了6.3%的宏F1分数。

Conclusion: 通过任务特定融合和硬件引导的模型设计，在微控制器级边缘平台上实现准确、实时的多模态情感推理是可行的。

Abstract: Deploying emotion recognition systems in real-world environments where
devices must be small, low-power, and private remains a significant challenge.
This is especially relevant for applications such as tension monitoring,
conflict de-escalation, and responsive wearables, where cloud-based solutions
are impractical. Multimodal emotion recognition has advanced through deep
learning, but most systems remain unsuitable for deployment on
ultra-constrained edge devices. Prior work typically relies on powerful
hardware, lacks real-time performance, or uses unimodal input. This paper
addresses that gap by presenting a hardware-aware emotion recognition system
that combines acoustic and linguistic features using a late-fusion architecture
optimised for Edge TPU. The design integrates a quantised transformer-based
acoustic model with frozen keyword embeddings from a DSResNet-SE network,
enabling real-time inference within a 1.8MB memory budget and 21-23ms latency.
The pipeline ensures spectrogram alignment between training and deployment
using MicroFrontend and MLTK. Evaluation on re-recorded, segmented IEMOCAP
samples captured through the Coral Dev Board Micro microphone shows a 6.3%
macro F1 improvement over unimodal baselines. This work demonstrates that
accurate, real-time multimodal emotion inference is achievable on
microcontroller-class edge platforms through task-specific fusion and
hardware-guided model design.

</details>


### [31] [ParaStyleTTS: Toward Efficient and Robust Paralinguistic Style Control for Expressive Text-to-Speech Generation](https://arxiv.org/abs/2510.18308)
*Haowei Lou,Hye-Young Paik,Wen Hu,Lina Yao*

Main category: cs.SD

TL;DR: ParaStyleTTS是一个轻量级、可解释的文本转语音框架，通过文本提示实现表达性风格控制，比基于大语言模型的方法快30倍，参数少8倍，内存需求少2.5倍。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖参考音频存在隐私和可访问性问题，而基于大语言模型的方法计算成本高、缺乏可解释性且对提示措辞敏感，限制了在实际应用中的使用。

Method: 采用新颖的两级风格适应架构，分离韵律和副语言语音风格建模，仅通过文本提示实现细粒度和鲁棒的控制。

Result: 实验结果显示ParaStyleTTS生成高质量语音，性能与最先进的基于大语言模型的系统相当，同时具有更好的鲁棒性和可控性。

Conclusion: ParaStyleTTS为风格可控的文本转语音生成提供了一个实用高效的解决方案，特别适合实时和资源受限环境。

Abstract: Controlling speaking style in text-to-speech (TTS) systems has become a
growing focus in both academia and industry. While many existing approaches
rely on reference audio to guide style generation, such methods are often
impractical due to privacy concerns and limited accessibility. More recently,
large language models (LLMs) have been used to control speaking style through
natural language prompts; however, their high computational cost, lack of
interpretability, and sensitivity to prompt phrasing limit their applicability
in real-time and resource-constrained environments. In this work, we propose
ParaStyleTTS, a lightweight and interpretable TTS framework that enables
expressive style control from text prompts alone. ParaStyleTTS features a novel
two-level style adaptation architecture that separates prosodic and
paralinguistic speech style modeling. It allows fine-grained and robust control
over factors such as emotion, gender, and age. Unlike LLM-based methods,
ParaStyleTTS maintains consistent style realization across varied prompt
formulations and is well-suited for real-world applications, including
on-device and low-resource deployment. Experimental results show that
ParaStyleTTS generates high-quality speech with performance comparable to
state-of-the-art LLM-based systems while being 30x faster, using 8x fewer
parameters, and requiring 2.5x less CUDA memory. Moreover, ParaStyleTTS
exhibits superior robustness and controllability over paralinguistic speaking
styles, providing a practical and efficient solution for style-controllable
text-to-speech generation. Demo can be found at
https://parastyletts.github.io/ParaStyleTTS_Demo/. Code can be found at
https://github.com/haoweilou/ParaStyleTTS.

</details>


### [32] [SegTune: Structured and Fine-Grained Control for Song Generation](https://arxiv.org/abs/2510.18416)
*Pengfei Cai,Joanna Wang,Haorui Zheng,Xu Li,Zihao Ji,Teng Ma,Zhongliang Liu,Chen Zhang,Pengfei Wan*

Main category: cs.SD

TL;DR: SegTune是一个非自回归的歌曲生成框架，通过分段级控制实现结构化可控的歌曲生成，解决了现有系统无法建模歌曲时间变化属性的问题。


<details>
  <summary>Details</summary>
Motivation: 现有歌曲生成系统大多缺乏对时间变化属性的建模能力，限制了在音乐结构和动态方面的细粒度控制。

Method: 提出SegTune框架，允许用户或大语言模型指定与歌曲段落对齐的局部音乐描述；引入基于LLM的时长预测器自动生成带时间戳的歌词；构建大规模数据管道收集高质量对齐数据。

Result: 实验结果表明SegTune在可控性和音乐连贯性方面优于现有基线方法。

Conclusion: SegTune通过分段级控制实现了更精确的歌词-音乐对齐和更好的音乐连贯性，为结构化可控歌曲生成提供了有效解决方案。

Abstract: Recent advancements in song generation have shown promising results in
generating songs from lyrics and/or global text prompts. However, most existing
systems lack the ability to model the temporally varying attributes of songs,
limiting fine-grained control over musical structure and dynamics. In this
paper, we propose SegTune, a non-autoregressive framework for structured and
controllable song generation. SegTune enables segment-level control by allowing
users or large language models to specify local musical descriptions aligned to
song sections.The segmental prompts are injected into the model by temporally
broadcasting them to corresponding time windows, while global prompts influence
the whole song to ensure stylistic coherence. To obtain accurate segment
durations and enable precise lyric-to-music alignment, we introduce an
LLM-based duration predictor that autoregressively generates sentence-level
timestamped lyrics in LRC format. We further construct a large-scale data
pipeline for collecting high-quality songs with aligned lyrics and prompts, and
propose new evaluation metrics to assess segment-level alignment and vocal
attribute consistency. Experimental results show that SegTune achieves superior
controllability and musical coherence compared to existing baselines. See
https://cai525.github.io/SegTune_demo for demos of our work.

</details>


### [33] [A Stage-Wise Learning Strategy with Fixed Anchors for Robust Speaker Verification](https://arxiv.org/abs/2510.18530)
*Bin Gu,Lipeng Dai,Huipeng Du,Haitao Zhao,Jibo Wei*

Main category: cs.SD

TL;DR: 提出基于锚点的分阶段学习策略，用于在噪声条件下学习鲁棒的说话人表示，通过先训练基础模型建立判别边界，然后使用锚点嵌入作为稳定参考来微调噪声输入。


<details>
  <summary>Details</summary>
Motivation: 在噪声条件下学习鲁棒的说话人表示面临挑战，需要同时处理判别性和噪声不变性。传统联合优化方法难以平衡这两个目标。

Method: 采用三阶段策略：1) 训练基础模型建立判别性说话人边界；2) 从基础模型提取锚点嵌入作为稳定参考；3) 在噪声输入上微调模型副本，通过强制接近固定锚点嵌入来保持说话人身份。

Result: 实验结果显示该方法优于传统联合优化，特别是在保持判别性的同时提高噪声鲁棒性。在各种噪声条件下都表现出持续改进。

Conclusion: 该策略通过分别处理边界稳定和变化抑制，有效提升了噪声条件下的说话人表示学习性能。

Abstract: Learning robust speaker representations under noisy conditions presents
significant challenges, which requires careful handling of both discriminative
and noise-invariant properties. In this work, we proposed an anchor-based
stage-wise learning strategy for robust speaker representation learning.
Specifically, our approach begins by training a base model to establish
discriminative speaker boundaries, and then extract anchor embeddings from this
model as stable references. Finally, a copy of the base model is fine-tuned on
noisy inputs, regularized by enforcing proximity to their corresponding fixed
anchor embeddings to preserve speaker identity under distortion. Experimental
results suggest that this strategy offers advantages over conventional joint
optimization, particularly in maintaining discrimination while improving noise
robustness. The proposed method demonstrates consistent improvements across
various noise conditions, potentially due to its ability to handle boundary
stabilization and variation suppression separately.

</details>


### [34] [Noise-Conditioned Mixture-of-Experts Framework for Robust Speaker Verification](https://arxiv.org/abs/2510.18533)
*Bin Gu,Lipeng Dai,Huipeng Du,Haitao Zhao,Jibo Wei*

Main category: cs.SD

TL;DR: 提出了一种噪声条件混合专家框架，通过将特征空间分解为专门的噪声感知子空间来提升噪声条件下的说话人验证性能。


<details>
  <summary>Details</summary>
Motivation: 解决噪声条件下说话人验证的鲁棒性问题，传统方法学习统一的说话人表示空间，而本文通过显式建模噪声依赖特征来提升性能。

Method: 采用噪声条件专家路由机制、基于通用模型的专家专业化策略和SNR衰减课程学习协议，自动根据输入噪声信息路由到针对不同噪声特性的专家网络。

Result: 综合实验表明该方法在多种噪声条件下均优于基线方法，确认了显式噪声依赖特征建模能显著增强鲁棒性而不牺牲验证准确性。

Conclusion: 噪声条件混合专家框架通过专业化子空间分解有效提升了说话人验证在噪声环境下的鲁棒性和泛化能力。

Abstract: Robust speaker verification under noisy conditions remains an open challenge.
Conventional deep learning methods learn a robust unified speaker
representation space against diverse background noise and achieve significant
improvement. In contrast, this paper presents a noise-conditioned
mixture-ofexperts framework that decomposes the feature space into specialized
noise-aware subspaces for speaker verification. Specifically, we propose a
noise-conditioned expert routing mechanism, a universal model based expert
specialization strategy, and an SNR-decaying curriculum learning protocol,
collectively improving model robustness and generalization under diverse noise
conditions. The proposed method can automatically route inputs to expert
networks based on noise information derived from the inputs, where each expert
targets distinct noise characteristics while preserving speaker identity
information. Comprehensive experiments demonstrate consistent superiority over
baselines, confirming that explicit noise-dependent feature modeling
significantly enhances robustness without sacrificing verification accuracy.

</details>

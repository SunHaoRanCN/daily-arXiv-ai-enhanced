{"id": "2510.20210", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2510.20210", "abs": "https://arxiv.org/abs/2510.20210", "authors": ["Hualei Wang", "Na Li", "Chuke Wang", "Shu Wu", "Zhifeng Li", "Dong Yu"], "title": "Vox-Evaluator: Enhancing Stability and Fidelity for Zero-shot TTS with A Multi-Level Evaluator", "comment": "10 pages, 5 figures", "summary": "Recent advances in zero-shot text-to-speech (TTS), driven by language models,\ndiffusion models and masked generation, have achieved impressive naturalness in\nspeech synthesis. Nevertheless, stability and fidelity remain key challenges,\nmanifesting as mispronunciations, audible noise, and quality degradation. To\naddress these issues, we introduce Vox-Evaluator, a multi-level evaluator\ndesigned to guide the correction of erroneous speech segments and preference\nalignment for TTS systems. It is capable of identifying the temporal boundaries\nof erroneous segments and providing a holistic quality assessment of the\ngenerated speech. Specifically, to refine erroneous segments and enhance the\nrobustness of the zero-shot TTS model, we propose to automatically identify\nacoustic errors with the evaluator, mask the erroneous segments, and finally\nregenerate speech conditioning on the correct portions. In addition, the\nfine-gained information obtained from Vox-Evaluator can guide the preference\nalignment for TTS model, thereby reducing the bad cases in speech synthesis.\nDue to the lack of suitable training datasets for the Vox-Evaluator, we also\nconstructed a synthesized text-speech dataset annotated with fine-grained\npronunciation errors or audio quality issues. The experimental results\ndemonstrate the effectiveness of the proposed Vox-Evaluator in enhancing the\nstability and fidelity of TTS systems through the speech correction mechanism\nand preference optimization. The demos are shown.", "AI": {"tldr": "\u63d0\u51fa\u4e86Vox-Evaluator\u591a\u7ea7\u8bc4\u4f30\u5668\uff0c\u901a\u8fc7\u8bc6\u522b\u9519\u8bef\u8bed\u97f3\u7247\u6bb5\u7684\u65f6\u95f4\u8fb9\u754c\u548c\u63d0\u4f9b\u6574\u4f53\u8d28\u91cf\u8bc4\u4f30\uff0c\u6765\u6307\u5bfcTTS\u7cfb\u7edf\u7684\u9519\u8bef\u4fee\u6b63\u548c\u504f\u597d\u5bf9\u9f50\uff0c\u4ece\u800c\u63d0\u9ad8\u96f6\u6837\u672c\u6587\u672c\u5230\u8bed\u97f3\u5408\u6210\u7684\u7a33\u5b9a\u6027\u548c\u4fdd\u771f\u5ea6\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u8bed\u8a00\u6a21\u578b\u3001\u6269\u6563\u6a21\u578b\u548c\u63a9\u7801\u751f\u6210\u7684\u96f6\u6837\u672c\u6587\u672c\u5230\u8bed\u97f3\u7cfb\u7edf\u5728\u81ea\u7136\u5ea6\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\uff0c\u4f46\u5728\u7a33\u5b9a\u6027\u548c\u4fdd\u771f\u5ea6\u65b9\u9762\u4ecd\u9762\u4e34\u6311\u6218\uff0c\u8868\u73b0\u4e3a\u53d1\u97f3\u9519\u8bef\u3001\u53ef\u542c\u566a\u58f0\u548c\u8d28\u91cf\u4e0b\u964d\u3002", "method": "\u63d0\u51faVox-Evaluator\u591a\u7ea7\u8bc4\u4f30\u5668\uff0c\u80fd\u591f\u8bc6\u522b\u9519\u8bef\u8bed\u97f3\u7247\u6bb5\u7684\u65f6\u95f4\u8fb9\u754c\uff1b\u901a\u8fc7\u8bc4\u4f30\u5668\u81ea\u52a8\u8bc6\u522b\u58f0\u5b66\u9519\u8bef\uff0c\u63a9\u7801\u9519\u8bef\u7247\u6bb5\uff0c\u5e76\u57fa\u4e8e\u6b63\u786e\u90e8\u5206\u91cd\u65b0\u751f\u6210\u8bed\u97f3\uff1b\u5229\u7528Vox-Evaluator\u7684\u7ec6\u7c92\u5ea6\u4fe1\u606f\u6307\u5bfcTTS\u6a21\u578b\u7684\u504f\u597d\u5bf9\u9f50\uff1b\u6784\u5efa\u4e86\u5e26\u6709\u7ec6\u7c92\u5ea6\u53d1\u97f3\u9519\u8bef\u6216\u97f3\u9891\u8d28\u91cf\u95ee\u9898\u7684\u5408\u6210\u6587\u672c-\u8bed\u97f3\u6570\u636e\u96c6\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u901a\u8fc7\u8bed\u97f3\u4fee\u6b63\u673a\u5236\u548c\u504f\u597d\u4f18\u5316\uff0cVox-Evaluator\u5728\u63d0\u9ad8TTS\u7cfb\u7edf\u7a33\u5b9a\u6027\u548c\u4fdd\u771f\u5ea6\u65b9\u9762\u5177\u6709\u6709\u6548\u6027\u3002", "conclusion": "Vox-Evaluator\u901a\u8fc7\u9519\u8bef\u4fee\u6b63\u548c\u504f\u597d\u5bf9\u9f50\u673a\u5236\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u96f6\u6837\u672c\u6587\u672c\u5230\u8bed\u97f3\u7cfb\u7edf\u7684\u7a33\u5b9a\u6027\u548c\u4fdd\u771f\u5ea6\uff0c\u89e3\u51b3\u4e86\u5f53\u524dTTS\u7cfb\u7edf\u4e2d\u7684\u53d1\u97f3\u9519\u8bef\u548c\u8d28\u91cf\u4e0b\u964d\u95ee\u9898\u3002"}}
{"id": "2510.20441", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.20441", "abs": "https://arxiv.org/abs/2510.20441", "authors": ["Haoyin Yan", "Chengwei Liu", "Shaofei Xue", "Xiaotao Liang", "Zheng Xue"], "title": "UniSE: A Unified Framework for Decoder-only Autoregressive LM-based Speech Enhancement", "comment": "5 pages, submitted to ICASSP 2026", "summary": "The development of neural audio codecs (NACs) has largely promoted\napplications of language models (LMs) to speech processing and understanding.\nHowever, there lacks the verification on the effectiveness of autoregressive\n(AR) LMbased models in unifying different sub-tasks of speech enhancement (SE).\nIn this work, we propose UniSE, a unified decoder-only LM-based framework to\nhandle different SE tasks including speech restoration, target speaker\nextraction and speech separation. It takes input speech features as conditions\nand generates discrete tokens of the target speech using AR modeling, which\nfacilitates a compatibility between distinct learning patterns of multiple\ntasks. Experiments on several benchmarks indicate the proposed UniSE can\nachieve competitive performance compared to discriminative and generative\nbaselines, showing the capacity of LMs in unifying SE tasks. The demo page is\navailable here: https://github.com/hyyan2k/UniSE.", "AI": {"tldr": "UniSE\u662f\u4e00\u4e2a\u57fa\u4e8e\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u7684\u7edf\u4e00\u8bed\u97f3\u589e\u5f3a\u6846\u67b6\uff0c\u80fd\u591f\u5904\u7406\u8bed\u97f3\u4fee\u590d\u3001\u76ee\u6807\u8bf4\u8bdd\u4eba\u63d0\u53d6\u548c\u8bed\u97f3\u5206\u79bb\u7b49\u591a\u79cd\u4efb\u52a1\u3002", "motivation": "\u9a8c\u8bc1\u81ea\u56de\u5f52\u8bed\u8a00\u6a21\u578b\u5728\u7edf\u4e00\u4e0d\u540c\u8bed\u97f3\u589e\u5f3a\u5b50\u4efb\u52a1\u4e2d\u7684\u6709\u6548\u6027\uff0c\u89e3\u51b3\u76ee\u524d\u7f3a\u4e4f\u76f8\u5173\u9a8c\u8bc1\u7684\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4ec5\u89e3\u7801\u5668\u7684\u8bed\u8a00\u6a21\u578b\u67b6\u6784\uff0c\u4ee5\u8f93\u5165\u8bed\u97f3\u7279\u5f81\u4e3a\u6761\u4ef6\uff0c\u901a\u8fc7\u81ea\u56de\u5f52\u5efa\u6a21\u751f\u6210\u76ee\u6807\u8bed\u97f3\u7684\u79bb\u6563\u6807\u8bb0\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cUniSE\u4e0e\u5224\u522b\u6027\u548c\u751f\u6210\u6027\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0c\u80fd\u591f\u8fbe\u5230\u7ade\u4e89\u6027\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u8bed\u8a00\u6a21\u578b\u5177\u6709\u7edf\u4e00\u8bed\u97f3\u589e\u5f3a\u4efb\u52a1\u7684\u80fd\u529b\uff0c\u4e3a\u591a\u4efb\u52a1\u5b66\u4e60\u63d0\u4f9b\u4e86\u517c\u5bb9\u6027\u3002"}}
{"id": "2510.20504", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2510.20504", "abs": "https://arxiv.org/abs/2510.20504", "authors": ["Xin Zhang", "Lin Li", "Xiangni Lu", "Jianquan Liu", "Kong Aik Lee"], "title": "Speaking Clearly: A Simplified Whisper-Based Codec for Low-Bitrate Speech Coding", "comment": "5 pages, 3 figures, 2 tables", "summary": "Speech codecs serve as bridges between continuous speech signals and large\nlanguage models, yet face an inherent conflict between acoustic fidelity and\nsemantic preservation. To mitigate this conflict, prevailing methods augment\nacoustic codecs with complex semantic supervision. We explore the opposite\ndirection: a semantic-first approach that starts from a semantically-capable\nmodel and adapts it for high-fidelity acoustic reconstruction. Through\nempirical analysis, we discover that targeted architectural simplification can\nunlock the acoustic modeling potential of Whisper, a text-aligned Automatic\nSpeech Recognition (ASR) model. Based on this finding, we propose\nSimWhisper-Codec, a novel codec that balances the semantic and acoustic\npreservation by leveraging a frozen, simplified Whisper encoder without\nrequiring external supervision. Experimental results demonstrate that\nSimWhisper-Codec achieves superior performance in both semantic preservation\nand acoustic quality compared to semantically-supervised codecs such as Mimi\nCodec and SpeechTokenizer at similar bitrates, validating the effectiveness of\nour semantic-first approach. Code is available at\nhttps://github.com/ZhangXinWhut/SimWhisper-Codec.", "AI": {"tldr": "\u63d0\u51faSimWhisper-Codec\uff0c\u4e00\u79cd\u8bed\u4e49\u4f18\u5148\u7684\u8bed\u97f3\u7f16\u89e3\u7801\u5668\uff0c\u901a\u8fc7\u7b80\u5316Whisper\u7f16\u7801\u5668\u67b6\u6784\u5b9e\u73b0\u8bed\u4e49\u548c\u58f0\u5b66\u8d28\u91cf\u7684\u826f\u597d\u5e73\u8861\u3002", "motivation": "\u89e3\u51b3\u4f20\u7edf\u8bed\u97f3\u7f16\u89e3\u7801\u5668\u5728\u58f0\u5b66\u4fdd\u771f\u5ea6\u548c\u8bed\u4e49\u4fdd\u6301\u4e4b\u95f4\u7684\u56fa\u6709\u51b2\u7a81\uff0c\u63a2\u7d22\u4ece\u8bed\u4e49\u80fd\u529b\u5f3a\u7684\u6a21\u578b\u51fa\u53d1\u8fdb\u884c\u58f0\u5b66\u91cd\u5efa\u7684\u65b0\u65b9\u5411\u3002", "method": "\u901a\u8fc7\u76ee\u6807\u67b6\u6784\u7b80\u5316\u89e3\u9501Whisper\u7684\u58f0\u5b66\u5efa\u6a21\u6f5c\u529b\uff0c\u5229\u7528\u51bb\u7ed3\u7684\u7b80\u5316Whisper\u7f16\u7801\u5668\u6784\u5efa\u7f16\u89e3\u7801\u5668\uff0c\u65e0\u9700\u5916\u90e8\u76d1\u7763\u3002", "result": "\u5728\u76f8\u4f3c\u6bd4\u7279\u7387\u4e0b\uff0cSimWhisper-Codec\u5728\u8bed\u4e49\u4fdd\u6301\u548c\u58f0\u5b66\u8d28\u91cf\u65b9\u9762\u5747\u4f18\u4e8e\u8bed\u4e49\u76d1\u7763\u7684\u7f16\u89e3\u7801\u5668\u5982Mimi Codec\u548cSpeechTokenizer\u3002", "conclusion": "\u8bed\u4e49\u4f18\u5148\u7684\u65b9\u6cd5\u5728\u8bed\u97f3\u7f16\u89e3\u7801\u4e2d\u6709\u6548\uff0c\u901a\u8fc7\u7b80\u5316\u8bed\u4e49\u80fd\u529b\u5f3a\u7684\u6a21\u578b\u53ef\u4ee5\u5e73\u8861\u8bed\u4e49\u548c\u58f0\u5b66\u8d28\u91cf\u3002"}}
{"id": "2510.20513", "categories": ["cs.SD", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20513", "abs": "https://arxiv.org/abs/2510.20513", "authors": ["Zhiyu Lin", "Jingwen Yang", "Jiale Zhao", "Meng Liu", "Sunzhu Li", "Benyou Wang"], "title": "Decoding the Ear: A Framework for Objectifying Expressiveness from Human Preference Through Efficient Alignment", "comment": "Submitted to ICASSP 2026. Demos and codes are available at\n  https://github.com/FreedomIntelligence/ExpressiveSpeech", "summary": "Recent speech-to-speech (S2S) models generate intelligible speech but still\nlack natural expressiveness, largely due to the absence of a reliable\nevaluation metric. Existing approaches, such as subjective MOS ratings,\nlow-level acoustic features, and emotion recognition are costly, limited, or\nincomplete. To address this, we present DeEAR (Decoding the Expressive\nPreference of eAR), a framework that converts human preference for speech\nexpressiveness into an objective score. Grounded in phonetics and psychology,\nDeEAR evaluates speech across three dimensions: Emotion, Prosody, and\nSpontaneity, achieving strong alignment with human perception (Spearman's Rank\nCorrelation Coefficient, SRCC = 0.86) using fewer than 500 annotated samples.\nBeyond reliable scoring, DeEAR enables fair benchmarking and targeted data\ncuration. It not only distinguishes expressiveness gaps across S2S models but\nalso selects 14K expressive utterances to form ExpressiveSpeech, which improves\nthe expressive score (from 2.0 to 23.4 on a 100-point scale) of S2S models.\nDemos and codes are available at\nhttps://github.com/FreedomIntelligence/ExpressiveSpeech", "AI": {"tldr": "DeEAR\u662f\u4e00\u4e2a\u8bc4\u4f30\u8bed\u97f3\u8868\u8fbe\u6027\u7684\u6846\u67b6\uff0c\u901a\u8fc7\u5c06\u4eba\u7c7b\u5bf9\u8bed\u97f3\u8868\u8fbe\u6027\u7684\u504f\u597d\u8f6c\u5316\u4e3a\u5ba2\u89c2\u5206\u6570\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u8bc4\u4f30\u65b9\u6cd5\u7684\u4e0d\u8db3\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u97f3\u5230\u8bed\u97f3\u6a21\u578b\u751f\u6210\u7684\u8bed\u97f3\u867d\u7136\u53ef\u7406\u89e3\uff0c\u4f46\u7f3a\u4e4f\u81ea\u7136\u7684\u8868\u8fbe\u6027\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u53ef\u9760\u7684\u8bc4\u4f30\u6307\u6807\u3002\u73b0\u6709\u7684\u4e3b\u89c2MOS\u8bc4\u5206\u3001\u4f4e\u5c42\u58f0\u5b66\u7279\u5f81\u548c\u60c5\u611f\u8bc6\u522b\u65b9\u6cd5\u6210\u672c\u9ad8\u3001\u6709\u9650\u6216\u4e0d\u5b8c\u6574\u3002", "method": "DeEAR\u57fa\u4e8e\u8bed\u97f3\u5b66\u548c\u5fc3\u7406\u5b66\uff0c\u4ece\u60c5\u611f\u3001\u97f5\u5f8b\u548c\u81ea\u53d1\u6027\u4e09\u4e2a\u7ef4\u5ea6\u8bc4\u4f30\u8bed\u97f3\u8868\u8fbe\u6027\uff0c\u4f7f\u7528\u5c11\u4e8e500\u4e2a\u6807\u6ce8\u6837\u672c\u5c31\u80fd\u5b9e\u73b0\u4e0e\u4eba\u7c7b\u611f\u77e5\u7684\u5f3a\u76f8\u5173\u6027\uff08SRCC=0.86\uff09\u3002", "result": "DeEAR\u4e0d\u4ec5\u80fd\u591f\u53ef\u9760\u5730\u8bc4\u5206\uff0c\u8fd8\u80fd\u5b9e\u73b0\u516c\u5e73\u57fa\u51c6\u6d4b\u8bd5\u548c\u9488\u5bf9\u6027\u6570\u636e\u7b5b\u9009\u3002\u5b83\u8bc6\u522b\u4e86\u4e0d\u540cS2S\u6a21\u578b\u4e4b\u95f4\u7684\u8868\u8fbe\u6027\u5dee\u8ddd\uff0c\u5e76\u7b5b\u9009\u4e8614K\u4e2a\u8868\u8fbe\u6027\u8bdd\u8bed\u5f62\u6210ExpressiveSpeech\u6570\u636e\u96c6\uff0c\u5c06S2S\u6a21\u578b\u7684\u8868\u8fbe\u6027\u5206\u6570\u4ece2.0\u63d0\u5347\u523023.4\uff08100\u5206\u5236\uff09\u3002", "conclusion": "DeEAR\u63d0\u4f9b\u4e86\u4e00\u4e2a\u6709\u6548\u7684\u8bed\u97f3\u8868\u8fbe\u6027\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u8bed\u97f3\u5230\u8bed\u97f3\u6a21\u578b\u7684\u8868\u8fbe\u6027\u8d28\u91cf\u3002"}}
{"id": "2510.20253", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2510.20253", "abs": "https://arxiv.org/abs/2510.20253", "authors": ["Weilong Huang", "Srikanth Raj Chetupalli", "Emanu\u00ebl A. P. Habets"], "title": "Neural Directional Filtering with Configurable Directivity Pattern at Inference", "comment": null, "summary": "Spatial filtering with a desired directivity pattern is advantageous for many\naudio applications. In this work, we propose neural directional filtering with\nuser-defined directivity patterns (UNDF), which enables spatial filtering based\non directivity patterns that users can define during inference. To achieve\nthis, we propose a DNN architecture that integrates feature-wise linear\nmodulation (FiLM), allowing user-defined patterns to serve as conditioning\ninputs. Through analysis, we demonstrate that the FiLM-based architecture\nenables the UNDF to generalize to unseen user-defined patterns during\ninterference with higher directivities, scaling variations, and different\nsteering directions. Furthermore, we progressively refine training strategies\nto enhance pattern approximation and enable UNDF to approximate irregular\nshapes. Lastly, experimental comparisons show that UNDF outperforms\nconventional methods.", "AI": {"tldr": "\u63d0\u51fa\u795e\u7ecf\u5b9a\u5411\u6ee4\u6ce2\u65b9\u6cd5UNDF\uff0c\u5141\u8bb8\u7528\u6237\u5728\u63a8\u7406\u65f6\u81ea\u5b9a\u4e49\u6307\u5411\u6027\u6a21\u5f0f\uff0c\u901a\u8fc7FiLM\u67b6\u6784\u5b9e\u73b0\u6a21\u5f0f\u6761\u4ef6\u8f93\u5165\uff0c\u5728\u672a\u89c1\u6a21\u5f0f\u4e0a\u8868\u73b0\u4f18\u5f02", "motivation": "\u5177\u6709\u671f\u671b\u6307\u5411\u6027\u6a21\u5f0f\u7684\u7a7a\u95f4\u6ee4\u6ce2\u5bf9\u8bb8\u591a\u97f3\u9891\u5e94\u7528\u6709\u5229\uff0c\u9700\u8981\u80fd\u591f\u6839\u636e\u7528\u6237\u81ea\u5b9a\u4e49\u6a21\u5f0f\u8fdb\u884c\u7a7a\u95f4\u6ee4\u6ce2\u7684\u65b9\u6cd5", "method": "\u63d0\u51fa\u96c6\u6210\u7279\u5f81\u7ebf\u6027\u8c03\u5236(FiLM)\u7684DNN\u67b6\u6784\uff0c\u5c06\u7528\u6237\u5b9a\u4e49\u6a21\u5f0f\u4f5c\u4e3a\u6761\u4ef6\u8f93\u5165\uff0c\u9010\u6b65\u4f18\u5316\u8bad\u7ec3\u7b56\u7565\u4ee5\u589e\u5f3a\u6a21\u5f0f\u903c\u8fd1\u80fd\u529b", "result": "UNDF\u5728\u672a\u89c1\u7528\u6237\u5b9a\u4e49\u6a21\u5f0f\u4e0a\u5177\u6709\u66f4\u9ad8\u7684\u6307\u5411\u6027\u3001\u5c3a\u5ea6\u53d8\u5316\u548c\u4e0d\u540c\u8f6c\u5411\u65b9\u5411\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u80fd\u591f\u903c\u8fd1\u4e0d\u89c4\u5219\u5f62\u72b6\uff0c\u5b9e\u9a8c\u6bd4\u8f83\u663e\u793a\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5", "conclusion": "\u6240\u63d0\u51fa\u7684UNDF\u65b9\u6cd5\u6709\u6548\u5b9e\u73b0\u4e86\u57fa\u4e8e\u7528\u6237\u81ea\u5b9a\u4e49\u6307\u5411\u6027\u6a21\u5f0f\u7684\u7a7a\u95f4\u6ee4\u6ce2\uff0c\u5728\u6cdb\u5316\u6027\u548c\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5"}}
{"id": "2510.19829", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19829", "abs": "https://arxiv.org/abs/2510.19829", "authors": ["Meghna Roy Chowdhury", "Yi Ding", "Shreyas Sen"], "title": "SSL-SE-EEG: A Framework for Robust Learning from Unlabeled EEG Data with Self-Supervised Learning and Squeeze-Excitation Networks", "comment": "6 figures, 2 tables, 8 pages", "summary": "Electroencephalography (EEG) plays a crucial role in brain-computer\ninterfaces (BCIs) and neurological diagnostics, but its real-world deployment\nfaces challenges due to noise artifacts, missing data, and high annotation\ncosts. We introduce SSL-SE-EEG, a framework that integrates Self-Supervised\nLearning (SSL) with Squeeze-and-Excitation Networks (SE-Nets) to enhance\nfeature extraction, improve noise robustness, and reduce reliance on labeled\ndata. Unlike conventional EEG processing techniques, SSL-SE-EEG} transforms EEG\nsignals into structured 2D image representations, suitable for deep learning.\nExperimental validation on MindBigData, TUH-AB, SEED-IV and BCI-IV datasets\ndemonstrates state-of-the-art accuracy (91% in MindBigData, 85% in TUH-AB),\nmaking it well-suited for real-time BCI applications. By enabling low-power,\nscalable EEG processing, SSL-SE-EEG presents a promising solution for\nbiomedical signal analysis, neural engineering, and next-generation BCIs.", "AI": {"tldr": "SSL-SE-EEG\u6846\u67b6\u7ed3\u5408\u81ea\u76d1\u7763\u5b66\u4e60\u548cSqueeze-and-Excitation\u7f51\u7edc\uff0c\u5c06EEG\u4fe1\u53f7\u8f6c\u6362\u4e3a2D\u56fe\u50cf\u8868\u793a\uff0c\u63d0\u9ad8\u7279\u5f81\u63d0\u53d6\u80fd\u529b\u548c\u566a\u58f0\u9c81\u68d2\u6027\uff0c\u51cf\u5c11\u5bf9\u6807\u6ce8\u6570\u636e\u7684\u4f9d\u8d56\u3002", "motivation": "\u89e3\u51b3EEG\u5728\u8111\u673a\u63a5\u53e3\u548c\u795e\u7ecf\u8bca\u65ad\u4e2d\u9762\u4e34\u7684\u566a\u58f0\u5e72\u6270\u3001\u6570\u636e\u7f3a\u5931\u548c\u6807\u6ce8\u6210\u672c\u9ad8\u7b49\u6311\u6218\uff0c\u63d0\u5347\u771f\u5b9e\u573a\u666f\u4e0b\u7684\u90e8\u7f72\u80fd\u529b\u3002", "method": "\u5c06EEG\u4fe1\u53f7\u8f6c\u6362\u4e3a\u7ed3\u6784\u53162D\u56fe\u50cf\u8868\u793a\uff0c\u7ed3\u5408\u81ea\u76d1\u7763\u5b66\u4e60\u548cSE-Net\u8fdb\u884c\u7279\u5f81\u63d0\u53d6\uff0c\u589e\u5f3a\u566a\u58f0\u9c81\u68d2\u6027\u3002", "result": "\u5728MindBigData\u3001TUH-AB\u3001SEED-IV\u548cBCI-IV\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6700\u5148\u8fdb\u51c6\u786e\u7387\uff08MindBigData 91%\uff0cTUH-AB 85%\uff09\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6BCI\u5e94\u7528\u3002", "conclusion": "SSL-SE-EEG\u4e3a\u751f\u7269\u533b\u5b66\u4fe1\u53f7\u5206\u6790\u3001\u795e\u7ecf\u5de5\u7a0b\u548c\u4e0b\u4e00\u4ee3\u8111\u673a\u63a5\u53e3\u63d0\u4f9b\u4e86\u4f4e\u529f\u8017\u3001\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20602", "categories": ["cs.SD", "cs.AI", "eess.AS", "eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20602", "abs": "https://arxiv.org/abs/2510.20602", "authors": ["Zitong Lan", "Yiduo Hao", "Mingmin Zhao"], "title": "Resounding Acoustic Fields with Reciprocity", "comment": "NeurIPS 2025", "summary": "Achieving immersive auditory experiences in virtual environments requires\nflexible sound modeling that supports dynamic source positions. In this paper,\nwe introduce a task called resounding, which aims to estimate room impulse\nresponses at arbitrary emitter location from a sparse set of measured emitter\npositions, analogous to the relighting problem in vision. We leverage the\nreciprocity property and introduce Versa, a physics-inspired approach to\nfacilitating acoustic field learning. Our method creates physically valid\nsamples with dense virtual emitter positions by exchanging emitter and listener\nposes. We also identify challenges in deploying reciprocity due to\nemitter/listener gain patterns and propose a self-supervised learning approach\nto address them. Results show that Versa substantially improve the performance\nof acoustic field learning on both simulated and real-world datasets across\ndifferent metrics. Perceptual user studies show that Versa can greatly improve\nthe immersive spatial sound experience. Code, dataset and demo videos are\navailable on the project website: https://waves.seas.upenn.edu/projects/versa.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aresounding\u7684\u4efb\u52a1\uff0c\u901a\u8fc7\u7a00\u758f\u6d4b\u91cf\u4f4d\u7f6e\u4f30\u8ba1\u4efb\u610f\u53d1\u5c04\u5668\u4f4d\u7f6e\u7684\u623f\u95f4\u8109\u51b2\u54cd\u5e94\uff0c\u5e76\u5f00\u53d1\u4e86Versa\u65b9\u6cd5\u6765\u6539\u8fdb\u58f0\u573a\u5b66\u4e60\u3002", "motivation": "\u5728\u865a\u62df\u73af\u5883\u4e2d\u5b9e\u73b0\u6c89\u6d78\u5f0f\u542c\u89c9\u4f53\u9a8c\u9700\u8981\u652f\u6301\u52a8\u6001\u58f0\u6e90\u4f4d\u7f6e\u7684\u7075\u6d3b\u58f0\u97f3\u5efa\u6a21\uff0c\u7c7b\u4f3c\u4e8e\u89c6\u89c9\u4e2d\u7684\u91cd\u5149\u7167\u95ee\u9898\u3002", "method": "\u5229\u7528\u58f0\u5b66\u4e92\u6613\u6027\u539f\u7406\uff0c\u901a\u8fc7\u4ea4\u6362\u53d1\u5c04\u5668\u548c\u542c\u8005\u4f4d\u7f6e\u521b\u5efa\u7269\u7406\u6709\u6548\u7684\u5bc6\u96c6\u865a\u62df\u53d1\u5c04\u5668\u4f4d\u7f6e\u6837\u672c\uff0c\u5e76\u63d0\u51fa\u81ea\u76d1\u7763\u5b66\u4e60\u65b9\u6cd5\u89e3\u51b3\u589e\u76ca\u6a21\u5f0f\u6311\u6218\u3002", "result": "Versa\u5728\u6a21\u62df\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u663e\u8457\u63d0\u9ad8\u4e86\u58f0\u573a\u5b66\u4e60\u6027\u80fd\uff0c\u7528\u6237\u611f\u77e5\u7814\u7a76\u8868\u660e\u80fd\u5927\u5e45\u63d0\u5347\u6c89\u6d78\u5f0f\u7a7a\u95f4\u58f0\u97f3\u4f53\u9a8c\u3002", "conclusion": "Versa\u65b9\u6cd5\u901a\u8fc7\u7269\u7406\u542f\u53d1\u7684\u4e92\u6613\u6027\u5229\u7528\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u7a00\u758f\u6d4b\u91cf\u4e0b\u7684\u58f0\u573a\u5b66\u4e60\u95ee\u9898\uff0c\u4e3a\u865a\u62df\u73af\u5883\u4e2d\u7684\u6c89\u6d78\u5f0f\u97f3\u9891\u4f53\u9a8c\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20551", "categories": ["eess.SP", "cs.IT", "eess.AS", "math.IT", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2510.20551", "abs": "https://arxiv.org/abs/2510.20551", "authors": ["Jacob Ayers", "Richard Hahnloser", "Julia Ulrich", "Lothar Sebastian Krapp", "Remo Nitschke", "Sabine Stoll", "Balthasar Bickel", "Reinhard Furrer"], "title": "Time-series Random Process Complexity Ranking Using a Bound on Conditional Differential Entropy", "comment": "7 pages, 4 figures", "summary": "Conditional differential entropy provides an intuitive measure for relatively\nranking time-series complexity by quantifying uncertainty in future\nobservations given past context. However, its direct computation for\nhigh-dimensional processes from unknown distributions is often intractable.\nThis paper builds on the information theoretic prediction error bounds\nestablished by Fang et al. \\cite{fang2019generic}, which demonstrate that the\nconditional differential entropy \\textbf{$h(X_k \\mid X_{k-1},...,X_{k-m})$} is\nupper bounded by a function of the determinant of the covariance matrix of\nnext-step prediction errors for any next step prediction model. We add to this\ntheoretical framework by further increasing this bound by leveraging Hadamard's\ninequality and the positive semi-definite property of covariance matrices.\n  To see if these bounds can be used to rank the complexity of time series, we\nconducted two synthetic experiments: (1) controlled linear autoregressive\nprocesses with additive Gaussian noise, where we compare ordinary least squares\nprediction error entropy proxies to the true entropies of various additive\nnoises, and (2) a complexity ranking task of bio-inspired synthetic audio data\nwith unknown entropy, where neural network prediction errors are used to\nrecover the known complexity ordering.\n  This framework provides a computationally tractable method for time-series\ncomplexity ranking using prediction errors from next-step prediction models,\nthat maintains a theoretical foundation in information theory.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u9884\u6d4b\u8bef\u5dee\u534f\u65b9\u5dee\u77e9\u9635\u7684\u65f6\u95f4\u5e8f\u5217\u590d\u6742\u5ea6\u6392\u5e8f\u65b9\u6cd5\uff0c\u901a\u8fc7\u4fe1\u606f\u8bba\u9884\u6d4b\u8bef\u5dee\u754c\u9650\u7406\u8bba\u6846\u67b6\uff0c\u5229\u7528Hadamard\u4e0d\u7b49\u5f0f\u548c\u534f\u65b9\u5dee\u77e9\u9635\u7684\u534a\u6b63\u5b9a\u6027\u6765\u4e0a\u754c\u6761\u4ef6\u5fae\u5206\u71b5\u3002", "motivation": "\u6761\u4ef6\u5fae\u5206\u71b5\u662f\u8861\u91cf\u65f6\u95f4\u5e8f\u5217\u590d\u6742\u5ea6\u7684\u76f4\u89c2\u6307\u6807\uff0c\u4f46\u5bf9\u4e8e\u672a\u77e5\u5206\u5e03\u7684\u9ad8\u7ef4\u8fc7\u7a0b\u76f4\u63a5\u8ba1\u7b97\u5f80\u5f80\u4e0d\u53ef\u884c\u3002\u672c\u6587\u65e8\u5728\u5efa\u7acb\u8ba1\u7b97\u53ef\u884c\u7684\u590d\u6742\u5ea6\u6392\u5e8f\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8eFang\u7b49\u4eba\u7684\u4fe1\u606f\u8bba\u9884\u6d4b\u8bef\u5dee\u754c\u9650\u7406\u8bba\uff0c\u8fdb\u4e00\u6b65\u5229\u7528Hadamard\u4e0d\u7b49\u5f0f\u548c\u534f\u65b9\u5dee\u77e9\u9635\u7684\u534a\u6b63\u5b9a\u6027\u6765\u589e\u52a0\u4e0a\u754c\u3002\u901a\u8fc7\u5408\u6210\u5b9e\u9a8c\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\uff1a\u63a7\u5236\u7ebf\u6027\u81ea\u56de\u5f52\u8fc7\u7a0b\u548c\u751f\u7269\u542f\u53d1\u5408\u6210\u97f3\u9891\u6570\u636e\u7684\u590d\u6742\u5ea6\u6392\u5e8f\u4efb\u52a1\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u80fd\u591f\u6210\u529f\u6062\u590d\u5df2\u77e5\u7684\u590d\u6742\u5ea6\u6392\u5e8f\uff0c\u5728\u7ebf\u6027\u81ea\u56de\u5f52\u8fc7\u7a0b\u4e2d\u9884\u6d4b\u8bef\u5dee\u71b5\u4ee3\u7406\u4e0e\u771f\u5b9e\u71b5\u4e00\u81f4\uff0c\u5728\u5408\u6210\u97f3\u9891\u6570\u636e\u4e2d\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b\u8bef\u5dee\u80fd\u6062\u590d\u5df2\u77e5\u590d\u6742\u5ea6\u987a\u5e8f\u3002", "conclusion": "\u8be5\u6846\u67b6\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u53ef\u884c\u7684\u65f6\u95f4\u5e8f\u5217\u590d\u6742\u5ea6\u6392\u5e8f\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e0b\u4e00\u6b65\u9884\u6d4b\u6a21\u578b\u7684\u9884\u6d4b\u8bef\u5dee\uff0c\u5e76\u4fdd\u6301\u4e86\u4fe1\u606f\u8bba\u7684\u7406\u8bba\u57fa\u7840\u3002"}}
{"id": "2510.19832", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.19832", "abs": "https://arxiv.org/abs/2510.19832", "authors": ["Ovishake Sen", "Raghav Soni", "Darpan Virmani", "Akshar Parekh", "Patrick Lehman", "Sarthak Jena", "Adithi Katikhaneni", "Adam Khalifa", "Baibhab Chatterjee"], "title": "Low-Latency Neural Inference on an Edge Device for Real-Time Handwriting Recognition from EEG Signals", "comment": "18 pages", "summary": "Brain-computer interfaces (BCIs) offer a pathway to restore communication for\nindividuals with severe motor or speech impairments. Imagined handwriting\nprovides an intuitive paradigm for character-level neural decoding, bridging\nthe gap between human intention and digital communication. While invasive\napproaches such as electrocorticography (ECoG) achieve high accuracy, their\nsurgical risks limit widespread adoption. Non-invasive electroencephalography\n(EEG) offers safer and more scalable alternatives but suffers from low\nsignal-to-noise ratio and spatial resolution, constraining its decoding\nprecision. This work demonstrates that advanced machine learning combined with\ninformative EEG feature extraction can overcome these barriers, enabling\nreal-time, high-accuracy neural decoding on portable edge devices. A 32-channel\nEEG dataset was collected from fifteen participants performing imagined\nhandwriting. Signals were preprocessed with bandpass filtering and artifact\nsubspace reconstruction, followed by extraction of 85 time-, frequency-, and\ngraphical-domain features. A hybrid architecture, EEdGeNet, integrates a\nTemporal Convolutional Network with a multilayer perceptron trained on the\nextracted features. When deployed on an NVIDIA Jetson TX2, the system achieved\n89.83 percent accuracy with 914.18 ms per-character latency. Selecting only ten\nkey features reduced latency by 4.5 times to 202.6 ms with less than 1 percent\nloss in accuracy. These results establish a pathway for accurate, low-latency,\nand fully portable non-invasive BCIs supporting real-time communication.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5f00\u53d1\u4e86\u4e00\u79cd\u57fa\u4e8eEEG\u7684\u8111\u673a\u63a5\u53e3\u7cfb\u7edf\uff0c\u901a\u8fc7\u5148\u8fdb\u7684\u673a\u5668\u5b66\u4e60\u548c\u7279\u5f81\u63d0\u53d6\u6280\u672f\uff0c\u5728\u4fbf\u643a\u8bbe\u5907\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u7684\u5b9e\u65f6\u60f3\u8c61\u624b\u5199\u795e\u7ecf\u89e3\u7801\u3002", "motivation": "\u89e3\u51b3\u975e\u4fb5\u5165\u6027\u8111\u673a\u63a5\u53e3(EEG)\u4fe1\u53f7\u8d28\u91cf\u5dee\u3001\u7a7a\u95f4\u5206\u8fa8\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u4e3a\u8fd0\u52a8\u6216\u8a00\u8bed\u969c\u788d\u60a3\u8005\u63d0\u4f9b\u5b89\u5168\u3001\u53ef\u6269\u5c55\u7684\u901a\u4fe1\u6062\u590d\u65b9\u6848\u3002", "method": "\u6536\u96c615\u540d\u53c2\u4e0e\u8005\u768432\u901a\u9053EEG\u6570\u636e\uff0c\u8fdb\u884c\u5e26\u901a\u6ee4\u6ce2\u548c\u4f2a\u5f71\u5b50\u7a7a\u95f4\u91cd\u5efa\u9884\u5904\u7406\uff0c\u63d0\u53d685\u4e2a\u65f6\u57df\u3001\u9891\u57df\u548c\u56fe\u8bba\u7279\u5f81\uff0c\u4f7f\u7528\u7ed3\u5408\u65f6\u5e8f\u5377\u79ef\u7f51\u7edc\u548c\u591a\u5c42\u611f\u77e5\u5668\u7684EEdGeNet\u6df7\u5408\u67b6\u6784\u3002", "result": "\u5728NVIDIA Jetson TX2\u4e0a\u90e8\u7f72\u65f6\uff0c\u7cfb\u7edf\u8fbe\u523089.83%\u7684\u51c6\u786e\u7387\uff0c\u6bcf\u5b57\u7b26\u5ef6\u8fdf914.18\u6beb\u79d2\uff1b\u4ec5\u4f7f\u752810\u4e2a\u5173\u952e\u7279\u5f81\u53ef\u5c06\u5ef6\u8fdf\u964d\u4f4e4.5\u500d\u81f3202.6\u6beb\u79d2\uff0c\u51c6\u786e\u7387\u635f\u5931\u5c0f\u4e8e1%\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u975e\u4fb5\u5165\u6027\u8111\u673a\u63a5\u53e3\u63d0\u4f9b\u4e86\u51c6\u786e\u3001\u4f4e\u5ef6\u8fdf\u3001\u5b8c\u5168\u4fbf\u643a\u7684\u5b9e\u65f6\u901a\u4fe1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20677", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.20677", "abs": "https://arxiv.org/abs/2510.20677", "authors": ["Junjie Zheng", "Gongyu Chen", "Chaofan Ding", "Zihao Chen"], "title": "R2-SVC: Towards Real-World Robust and Expressive Zero-shot Singing Voice Conversion", "comment": "5 pages, 2 figures", "summary": "In real-world singing voice conversion (SVC) applications, environmental\nnoise and the demand for expressive output pose significant challenges.\nConventional methods, however, are typically designed without accounting for\nreal deployment scenarios, as both training and inference usually rely on clean\ndata. This mismatch hinders practical use, given the inevitable presence of\ndiverse noise sources and artifacts from music separation. To tackle these\nissues, we propose R2-SVC, a robust and expressive SVC framework. First, we\nintroduce simulation-based robustness enhancement through random fundamental\nfrequency ($F_0$) perturbations and music separation artifact simulations\n(e.g., reverberation, echo), substantially improving performance under noisy\nconditions. Second, we enrich speaker representation using domain-specific\nsinging data: alongside clean vocals, we incorporate DNSMOS-filtered separated\nvocals and public singing corpora, enabling the model to preserve speaker\ntimbre while capturing singing style nuances. Third, we integrate the Neural\nSource-Filter (NSF) model to explicitly represent harmonic and noise\ncomponents, enhancing the naturalness and controllability of converted singing.\nR2-SVC achieves state-of-the-art results on multiple SVC benchmarks under both\nclean and noisy conditions.", "AI": {"tldr": "R2-SVC\u662f\u4e00\u4e2a\u9c81\u68d2\u4e14\u5bcc\u6709\u8868\u73b0\u529b\u7684\u6b4c\u58f0\u8f6c\u6362\u6846\u67b6\uff0c\u901a\u8fc7\u6a21\u62df\u566a\u58f0\u589e\u5f3a\u3001\u4e30\u5bcc\u8bf4\u8bdd\u4eba\u8868\u793a\u548c\u96c6\u6210\u795e\u7ecf\u6e90\u6ee4\u6ce2\u5668\u6a21\u578b\uff0c\u5728\u5608\u6742\u73af\u5883\u4e0b\u5b9e\u73b0\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u5b9e\u4e16\u754c\u6b4c\u58f0\u8f6c\u6362\u5e94\u7528\u4e2d\uff0c\u73af\u5883\u566a\u58f0\u548c\u5bf9\u5bcc\u6709\u8868\u73b0\u529b\u8f93\u51fa\u7684\u9700\u6c42\u5e26\u6765\u91cd\u5927\u6311\u6218\u3002\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u57fa\u4e8e\u5e72\u51c0\u6570\u636e\u8bbe\u8ba1\uff0c\u4e0e\u5b9e\u9645\u90e8\u7f72\u573a\u666f\u4e0d\u5339\u914d\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "1. \u901a\u8fc7\u968f\u673a\u57fa\u9891\u6270\u52a8\u548c\u97f3\u4e50\u5206\u79bb\u4f2a\u5f71\u6a21\u62df\u8fdb\u884c\u57fa\u4e8e\u6a21\u62df\u7684\u9c81\u68d2\u6027\u589e\u5f3a\uff1b2. \u4f7f\u7528\u9886\u57df\u7279\u5b9a\u6b4c\u5531\u6570\u636e\u4e30\u5bcc\u8bf4\u8bdd\u4eba\u8868\u793a\uff1b3. \u96c6\u6210\u795e\u7ecf\u6e90\u6ee4\u6ce2\u5668\u6a21\u578b\u6765\u663e\u5f0f\u8868\u793a\u8c10\u6ce2\u548c\u566a\u58f0\u5206\u91cf\u3002", "result": "R2-SVC\u5728\u591a\u4e2a\u6b4c\u58f0\u8f6c\u6362\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u5e72\u51c0\u548c\u5608\u6742\u6761\u4ef6\u4e0b\u5747\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "conclusion": "\u8be5\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u5b9e\u4e16\u754c\u6b4c\u58f0\u8f6c\u6362\u4e2d\u7684\u566a\u58f0\u9c81\u68d2\u6027\u548c\u8868\u8fbe\u6027\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.19985", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.19985", "abs": "https://arxiv.org/abs/2510.19985", "authors": ["M. M. Sadman Shafi", "Tasnia Siddiqua Ahona", "Ashraful Islam Mridha"], "title": "MATLAB-Simulated Dataset for Automatic Modulation Classification in Wireless Fading Channels", "comment": null, "summary": "Accurate modulation classification is a core challenge in cognitive radio,\nadaptive communications, spectrum analysis, and related domains, especially\nunder dynamic channels without transmitter knowledge. To address this need,\nthis article presents a labeled synthetic dataset designed for wireless\nmodulation classification under realistic propagation scenarios. The signals\nwere generated in MATLAB by modulating randomly generated bitstreams using five\ndigital modulation schemes: BPSK, QPSK, 16-QAM, 64-QAM, and 256-QAM. These\nsignals were then transmitted through Rayleigh and Rician fading channels with\nstandardized parameters, along with additional impairments to enhance realism\nand diversity. Each modulated signal contains 1000 symbols. A comprehensive set\nof features was extracted from the signals, encompassing statistical,\ntime-domain, frequency-domain, spectrogram-based, spectral correlation-based,\nand image-processing-based descriptors such as BRISK, MSER, and GLCM. The\ndataset is organized into 10 CSV files covering two channel types (Rayleigh and\nRician) across five sampling frequencies: 1 MHz, 10 MHz, 100 MHz, 500 MHz, and\n1 GHz. To facilitate reproducibility and encourage further experimentation, the\nMATLAB scripts used for signal generation and feature extraction are also\nprovided. This dataset serves as a valuable benchmark for developing and\nevaluating machine learning models in modulation classification, signal\nidentification, and wireless communication research.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8e\u65e0\u7ebf\u8c03\u5236\u5206\u7c7b\u7684\u6807\u8bb0\u5408\u6210\u6570\u636e\u96c6\uff0c\u5305\u542bBPSK\u3001QPSK\u300116-QAM\u300164-QAM\u548c256-QAM\u4e94\u79cd\u8c03\u5236\u65b9\u6848\uff0c\u5728\u745e\u5229\u548c\u83b1\u65af\u8870\u843d\u4fe1\u9053\u4e0b\u751f\u6210\uff0c\u5e76\u63d0\u53d6\u4e86\u591a\u79cd\u7279\u5f81\u7528\u4e8e\u673a\u5668\u5b66\u4e60\u6a21\u578b\u5f00\u53d1\u3002", "motivation": "\u89e3\u51b3\u8ba4\u77e5\u65e0\u7ebf\u7535\u3001\u81ea\u9002\u5e94\u901a\u4fe1\u7b49\u9886\u57df\u4e2d\u52a8\u6001\u4fe1\u9053\u4e0b\u51c6\u786e\u8c03\u5236\u5206\u7c7b\u7684\u6311\u6218\uff0c\u4e3a\u5f00\u53d1\u673a\u5668\u5b66\u4e60\u6a21\u578b\u63d0\u4f9b\u53ef\u9760\u7684\u57fa\u51c6\u6570\u636e\u96c6\u3002", "method": "\u4f7f\u7528MATLAB\u751f\u6210\u968f\u673a\u6bd4\u7279\u6d41\u7684\u4e94\u79cd\u6570\u5b57\u8c03\u5236\u4fe1\u53f7\uff0c\u901a\u8fc7\u745e\u5229\u548c\u83b1\u65af\u8870\u843d\u4fe1\u9053\u4f20\u8f93\uff0c\u5e76\u63d0\u53d6\u7edf\u8ba1\u3001\u65f6\u57df\u3001\u9891\u57df\u3001\u8c31\u56fe\u3001\u8c31\u76f8\u5173\u548c\u56fe\u50cf\u5904\u7406\u7b49\u591a\u79cd\u7279\u5f81\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b10\u4e2aCSV\u6587\u4ef6\u7684\u6570\u636e\u96c6\uff0c\u8986\u76d6\u4e24\u79cd\u4fe1\u9053\u7c7b\u578b\u548c\u4e94\u79cd\u91c7\u6837\u9891\u7387\uff0c\u6bcf\u4e2a\u8c03\u5236\u4fe1\u53f7\u5305\u542b1000\u4e2a\u7b26\u53f7\uff0c\u63d0\u4f9b\u4e86\u5b8c\u6574\u7684\u4fe1\u53f7\u751f\u6210\u548c\u7279\u5f81\u63d0\u53d6\u811a\u672c\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u4e3a\u8c03\u5236\u5206\u7c7b\u3001\u4fe1\u53f7\u8bc6\u522b\u548c\u65e0\u7ebf\u901a\u4fe1\u7814\u7a76\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u51c6\uff0c\u652f\u6301\u53ef\u91cd\u590d\u6027\u548c\u8fdb\u4e00\u6b65\u5b9e\u9a8c\u3002"}}
{"id": "2510.20759", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2510.20759", "abs": "https://arxiv.org/abs/2510.20759", "authors": ["Julia Wilkins", "Jaehun Kim", "Matthew E. P. Davies", "Juan Pablo Bello", "Matthew C. McCallum"], "title": "Controllable Embedding Transformation for Mood-Guided Music Retrieval", "comment": "Preprint; under review", "summary": "Music representations are the backbone of modern recommendation systems,\npowering playlist generation, similarity search, and personalized discovery.\nYet most embeddings offer little control for adjusting a single musical\nattribute, e.g., changing only the mood of a track while preserving its genre\nor instrumentation. In this work, we address the problem of controllable music\nretrieval through embedding-based transformation, where the objective is to\nretrieve songs that remain similar to a seed track but are modified along one\nchosen dimension. We propose a novel framework for mood-guided music embedding\ntransformation, which learns a mapping from a seed audio embedding to a target\nembedding guided by mood labels, while preserving other musical attributes.\nBecause mood cannot be directly altered in the seed audio, we introduce a\nsampling mechanism that retrieves proxy targets to balance diversity with\nsimilarity to the seed. We train a lightweight translation model using this\nsampling strategy and introduce a novel joint objective that encourages\ntransformation and information preservation. Extensive experiments on two\ndatasets show strong mood transformation performance while retaining genre and\ninstrumentation far better than training-free baselines, establishing\ncontrollable embedding transformation as a promising paradigm for personalized\nmusic retrieval.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u60c5\u7eea\u5f15\u5bfc\u97f3\u4e50\u5d4c\u5165\u8f6c\u6362\u7684\u65b0\u6846\u67b6\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u7ffb\u8bd1\u6a21\u578b\u5b9e\u73b0\u53ef\u63a7\u7684\u97f3\u4e50\u68c0\u7d22\uff0c\u80fd\u591f\u5728\u6539\u53d8\u97f3\u4e50\u60c5\u7eea\u7684\u540c\u65f6\u4fdd\u6301\u5176\u4ed6\u97f3\u4e50\u5c5e\u6027\u3002", "motivation": "\u73b0\u6709\u97f3\u4e50\u5d4c\u5165\u8868\u793a\u7f3a\u4e4f\u5bf9\u5355\u4e00\u97f3\u4e50\u5c5e\u6027\uff08\u5982\u60c5\u7eea\uff09\u7684\u7cbe\u786e\u63a7\u5236\u80fd\u529b\uff0c\u65e0\u6cd5\u5728\u6539\u53d8\u7279\u5b9a\u7ef4\u5ea6\uff08\u5982\u60c5\u7eea\uff09\u7684\u540c\u65f6\u4fdd\u6301\u5176\u4ed6\u5c5e\u6027\uff08\u5982\u6d41\u6d3e\u3001\u4e50\u5668\uff09\u4e0d\u53d8\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u91c7\u6837\u7684\u673a\u5236\u83b7\u53d6\u4ee3\u7406\u76ee\u6807\uff0c\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u7ffb\u8bd1\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u8054\u5408\u76ee\u6807\u51fd\u6570\u6765\u5e73\u8861\u8f6c\u6362\u548c\u4fe1\u606f\u4fdd\u7559\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u60c5\u7eea\u8f6c\u6362\u65b9\u9762\u8868\u73b0\u5f3a\u52b2\uff0c\u540c\u65f6\u5728\u4fdd\u6301\u6d41\u6d3e\u548c\u4e50\u5668\u65b9\u9762\u8fdc\u4f18\u4e8e\u65e0\u8bad\u7ec3\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u53ef\u63a7\u5d4c\u5165\u8f6c\u6362\u662f\u4e2a\u6027\u5316\u97f3\u4e50\u68c0\u7d22\u7684\u4e00\u4e2a\u6709\u524d\u666f\u7684\u8303\u5f0f\u3002"}}
{"id": "2510.20038", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20038", "abs": "https://arxiv.org/abs/2510.20038", "authors": ["Cristian Cioflan", "Jose Fonseca", "Xiaying Wang", "Luca Benini"], "title": "NanoHydra: Energy-Efficient Time-Series Classification at the Edge", "comment": "7 pages, 2 figures, 5 tables. Accepted at International Joint\n  Conference on Neural Networks (IJCNN) 2025", "summary": "Time series classification (TSC) on extreme edge devices represents a\nstepping stone towards intelligent sensor nodes that preserve user privacy and\noffer real-time predictions. Resource-constrained devices require efficient\nTinyML algorithms that prolong the device lifetime of battery-operated devices\nwithout compromising the classification accuracy. We introduce NanoHydra, a\nTinyML TSC methodology relying on lightweight binary random convolutional\nkernels to extract meaningful features from data streams. We demonstrate our\nsystem on the ultra-low-power GAP9 microcontroller, exploiting its eight-core\ncluster for the parallel execution of computationally intensive tasks. We\nachieve a classification accuracy of up to 94.47% on ECG5000 dataset,\ncomparable with state-of-the-art works. Our efficient NanoHydra requires only\n0.33 ms to accurately classify a 1-second long ECG signal. With a modest energy\nconsumption of 7.69 uJ per inference, 18x more efficient than the\nstate-of-the-art, NanoHydra is suitable for smart wearable devices, enabling a\ndevice lifetime of over four years.", "AI": {"tldr": "NanoHydra\u662f\u4e00\u79cd\u9762\u5411\u6781\u7aef\u8fb9\u7f18\u8bbe\u5907\u7684\u8f7b\u91cf\u7ea7\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u65b9\u6cd5\uff0c\u4f7f\u7528\u4e8c\u8fdb\u5236\u968f\u673a\u5377\u79ef\u6838\u63d0\u53d6\u7279\u5f81\uff0c\u5728\u8d85\u4f4e\u529f\u8017GAP9\u5fae\u63a7\u5236\u5668\u4e0a\u5b9e\u73b0\u9ad8\u6548\u5206\u7c7b\uff0c\u80fd\u8017\u6bd4\u73b0\u6709\u6280\u672f\u4f4e18\u500d\u3002", "motivation": "\u5f00\u53d1\u9002\u7528\u4e8e\u7535\u6c60\u4f9b\u7535\u8fb9\u7f18\u8bbe\u5907\u7684\u9ad8\u6548TinyML\u7b97\u6cd5\uff0c\u5728\u4fdd\u6301\u5206\u7c7b\u7cbe\u5ea6\u7684\u540c\u65f6\u5ef6\u957f\u8bbe\u5907\u5bff\u547d\uff0c\u5b9e\u73b0\u4fdd\u62a4\u7528\u6237\u9690\u79c1\u7684\u5b9e\u65f6\u9884\u6d4b\u667a\u80fd\u4f20\u611f\u5668\u8282\u70b9\u3002", "method": "\u91c7\u7528\u8f7b\u91cf\u7ea7\u4e8c\u8fdb\u5236\u968f\u673a\u5377\u79ef\u6838\u4ece\u6570\u636e\u6d41\u4e2d\u63d0\u53d6\u7279\u5f81\uff0c\u5229\u7528GAP9\u5fae\u63a7\u5236\u5668\u7684\u516b\u6838\u96c6\u7fa4\u5e76\u884c\u6267\u884c\u8ba1\u7b97\u5bc6\u96c6\u578b\u4efb\u52a1\u3002", "result": "\u5728ECG5000\u6570\u636e\u96c6\u4e0a\u8fbe\u523094.47%\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u4ec5\u97000.33\u6beb\u79d2\u5373\u53ef\u51c6\u786e\u5206\u7c7b1\u79d2\u957f\u7684ECG\u4fe1\u53f7\uff0c\u6bcf\u6b21\u63a8\u7406\u80fd\u8017\u4ec57.69\u5fae\u7126\u8033\u3002", "conclusion": "NanoHydra\u6bd4\u73b0\u6709\u6280\u672f\u80fd\u6548\u9ad818\u500d\uff0c\u9002\u7528\u4e8e\u667a\u80fd\u53ef\u7a7f\u6234\u8bbe\u5907\uff0c\u53ef\u5b9e\u73b0\u8d85\u8fc7\u56db\u5e74\u7684\u8bbe\u5907\u5bff\u547d\uff0c\u662f\u8fb9\u7f18\u8bbe\u5907\u65f6\u95f4\u5e8f\u5217\u5206\u7c7b\u7684\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20067", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20067", "abs": "https://arxiv.org/abs/2510.20067", "authors": ["Maximilian H. V. Tillmann", "Avinash Kankari", "Carsten Bockelmann", "Armin Dekorsy"], "title": "Semantic Communication for Task Execution and Data Reconstruction in Multi-User Scenarios", "comment": null, "summary": "Semantic communication has gained significant attention with the advances in\nmachine learning. Most semantic communication works focus on either task\nexecution or data reconstruction, with some recent works combining the two. In\nthis work, we propose a semantic communication system for concurrent task\nexecution and data reconstruction for a multi-user scenario, which we formulate\nas the maximization of mutual information. To investigate the trade-off between\nthe two objectives, we formulate a joint objective as a convex combination of\ntask execution and data reconstruction. We show that under specific\nassumptions, the \\ac{SSIM} loss can be obtained from the mutual information\nmaximization objective for data reconstruction, which takes human visual\nperception into account. Furthermore, for constant resource use, we show that\nby increasing the weight of the reconstruction objective up to a certain point,\nthe task execution performance can be kept nearly constant, while the data\nreconstruction can be significantly improved.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u591a\u7528\u6237\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\uff0c\u540c\u65f6\u652f\u6301\u4efb\u52a1\u6267\u884c\u548c\u6570\u636e\u91cd\u5efa\uff0c\u901a\u8fc7\u4e92\u4fe1\u606f\u6700\u5927\u5316\u6765\u4f18\u5316\u8fd9\u4e24\u4e2a\u76ee\u6807\u7684\u6743\u8861\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u4e3b\u8981\u4e13\u6ce8\u4e8e\u4efb\u52a1\u6267\u884c\u6216\u6570\u636e\u91cd\u5efa\uff0c\u7f3a\u4e4f\u540c\u65f6\u652f\u6301\u8fd9\u4e24\u4e2a\u76ee\u6807\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u591a\u7528\u6237\u573a\u666f\u4e0b\u3002", "method": "\u5c06\u4efb\u52a1\u6267\u884c\u548c\u6570\u636e\u91cd\u5efa\u7684\u76ee\u6807\u8868\u8ff0\u4e3a\u4e92\u4fe1\u606f\u6700\u5927\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u8054\u5408\u76ee\u6807\u51fd\u6570\u4f5c\u4e3a\u4e24\u8005\u7684\u51f8\u7ec4\u5408\uff0c\u5e76\u63a8\u5bfc\u51faSSIM\u635f\u5931\u4e0e\u4e92\u4fe1\u606f\u6700\u5927\u5316\u76ee\u6807\u7684\u5173\u7cfb\u3002", "result": "\u5728\u56fa\u5b9a\u8d44\u6e90\u4f7f\u7528\u4e0b\uff0c\u9002\u5f53\u589e\u52a0\u91cd\u5efa\u76ee\u6807\u7684\u6743\u91cd\u53ef\u4ee5\u5728\u4fdd\u6301\u4efb\u52a1\u6267\u884c\u6027\u80fd\u57fa\u672c\u4e0d\u53d8\u7684\u540c\u65f6\uff0c\u663e\u8457\u6539\u5584\u6570\u636e\u91cd\u5efa\u8d28\u91cf\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u5e73\u8861\u4efb\u52a1\u6267\u884c\u548c\u6570\u636e\u91cd\u5efa\u4e24\u4e2a\u76ee\u6807\uff0c\u4e3a\u591a\u7528\u6237\u573a\u666f\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20088", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20088", "abs": "https://arxiv.org/abs/2510.20088", "authors": ["Tawfik Osman", "Aditya S. Shekhawat", "Abhradeep Roy", "Georgios C. Trichopoulos", "Ahmed Alkhateeb"], "title": "RIS-Aided mmWave O-RAN: Coverage Extension and User Mobility Handling", "comment": "19 pages, 13 figures", "summary": "Reconfigurable Intelligent Surfaces (RISs) can redirect electromagnetic waves\nto desired directions to enhance signal coverage and/or improve signal-to-noise\nratio (SNR) at the user equipment (UE). We present the design, implementation,\nand evaluation of an RIS-assisted O-RAN 5G system operating in the FR2\nmillimeter wave (mmWave) frequency band. We first introduce the design of 1,024\nelement (32 $\\times$ 32) 1-bit RIS operating at the 28 GHz band, utilizing a\nmodular and scalable tiled architecture. Then we demonstrate how the O-RAN E2\ninterface can be leveraged to dynamically control RIS configurations without\nmodifying standard 5G signaling procedures. To evaluate the RIS-assisted 5G\nsystem, we conducted extensive field trials in both indoor and outdoor\nenvironments. The results of the O-RAN link coverage trials show that the\ndeployed RIS provides substantial received signal power gains, ranging from 9\nto 20 dB and 6 to 18 dB in indoor and outdoors scenarios, respectively.\nHandling UE mobility in RIS-assisted systems is challenging due to the need for\njoint RIS and UE beam management. For that, we develop two UE mobility\nmanagement algorithms and evaluate them in real-time operation using the RIS\nO-RAN testbed. These algorithms leverage the received signal power at the UE to\njointly track and adapt the RIS and UE beams in real time as the UE moves. The\nfindings draw important insights into the practical feasibility of integrating\nRIS into O-RAN systems to enhance coverage, mobility support, and link\nreliability in next-generation cellular networks.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86\u5728O-RAN 5G\u7cfb\u7edf\u4e2d\u96c6\u6210\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(RIS)\u7684\u8bbe\u8ba1\u3001\u5b9e\u73b0\u548c\u8bc4\u4f30\uff0c\u5c55\u793a\u4e86RIS\u5728\u6beb\u7c73\u6ce2\u9891\u6bb5\u663e\u8457\u63d0\u5347\u4fe1\u53f7\u8986\u76d6\u548c\u79fb\u52a8\u6027\u7ba1\u7406\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002", "motivation": "\u5229\u7528RIS\u5c06\u7535\u78c1\u6ce2\u91cd\u5b9a\u5411\u5230\u671f\u671b\u65b9\u5411\uff0c\u4ee5\u589e\u5f3a\u4fe1\u53f7\u8986\u76d6\u548c\u6539\u5584\u7528\u6237\u8bbe\u5907\u7684\u4fe1\u566a\u6bd4\uff0c\u540c\u65f6\u89e3\u51b3RIS\u8f85\u52a9\u7cfb\u7edf\u4e2d\u7528\u6237\u79fb\u52a8\u6027\u7ba1\u7406\u7684\u6311\u6218\u3002", "method": "\u8bbe\u8ba1\u4e861,024\u5143\u4ef6\u76841\u4f4dRIS\uff0c\u91c7\u7528\u6a21\u5757\u5316\u53ef\u6269\u5c55\u7684\u74e6\u7247\u67b6\u6784\uff1b\u5229\u7528O-RAN E2\u63a5\u53e3\u52a8\u6001\u63a7\u5236RIS\u914d\u7f6e\uff1b\u5f00\u53d1\u4e86\u4e24\u79cdUE\u79fb\u52a8\u6027\u7ba1\u7406\u7b97\u6cd5\uff0c\u5229\u7528UE\u63a5\u6536\u4fe1\u53f7\u529f\u7387\u5b9e\u65f6\u8054\u5408\u8ddf\u8e2a\u548c\u8c03\u6574RIS\u4e0eUE\u6ce2\u675f\u3002", "result": "\u5ba4\u5185\u5916\u573a\u6d4b\u8bd5\u663e\u793a\uff0cRIS\u63d0\u4f9b\u4e86\u663e\u8457\u7684\u63a5\u6536\u4fe1\u53f7\u529f\u7387\u589e\u76ca\uff1a\u5ba4\u51859-20 dB\uff0c\u5ba4\u59166-18 dB\uff1b\u5f00\u53d1\u7684\u79fb\u52a8\u6027\u7ba1\u7406\u7b97\u6cd5\u5728\u5b9e\u65f6\u64cd\u4f5c\u4e2d\u6709\u6548\u8ddf\u8e2a\u548c\u9002\u5e94\u79fb\u52a8UE\u7684\u6ce2\u675f\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\u4e86\u5c06RIS\u96c6\u6210\u5230O-RAN\u7cfb\u7edf\u4e2d\u4ee5\u589e\u5f3a\u4e0b\u4e00\u4ee3\u8702\u7a9d\u7f51\u7edc\u8986\u76d6\u3001\u79fb\u52a8\u6027\u652f\u6301\u548c\u94fe\u8def\u53ef\u9760\u6027\u7684\u5b9e\u9645\u53ef\u884c\u6027\u3002"}}
{"id": "2510.20112", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.20112", "abs": "https://arxiv.org/abs/2510.20112", "authors": ["Borui Du", "Yumeng Zhang", "Christos Masouros", "Bruno Clerckx"], "title": "Signal Design for OTFS Dual-Functional Radar and Communications with Imperfect CSI", "comment": null, "summary": "Orthogonal time frequency space (OTFS) offers significant advantages in\nmanaging mobility for both wireless sensing and communication systems, making\nit a promising candidate for dual-functional radar-communication (DFRC).\nHowever, the optimal signal design that fully exploits OTFS's potential in DFRC\nhas not been sufficiently explored. This paper addresses this gap by\nformulating an optimization problem for signal design in DFRC-OTFS,\nincorporating both pilot-symbol design for channel estimation and data-power\nallocation. Specifically, we employ the integrated sidelobe level (ISL) of the\nambiguity function as a radar metric, accounting for the randomness of the data\nsymbols alongside the deterministic pilot symbols. For communication, we derive\na channel capacity lower bound metric that considers channel estimation errors\nin OTFS. We maximize the weighted sum of sensing and communication metrics and\nsolve the optimization problem via an alternating optimization framework.\nSimulations indicate that the proposed signal significantly improves the\nsensing-communication performance region compared with conventional signal\nschemes, achieving at least a 9.44 dB gain in ISL suppression for sensing, and\na 4.82 dB gain in the signal-to-interference-plus-noise ratio (SINR) for\ncommunication.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9OTFS\u53cc\u529f\u80fd\u96f7\u8fbe\u901a\u4fe1\u7cfb\u7edf\u7684\u4fe1\u53f7\u8bbe\u8ba1\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5bfc\u9891\u7b26\u53f7\u8bbe\u8ba1\u548c\u6570\u636e\u529f\u7387\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u4e86\u611f\u77e5\u548c\u901a\u4fe1\u6027\u80fd\u3002", "motivation": "OTFS\u6280\u672f\u5728\u65e0\u7ebf\u611f\u77e5\u548c\u901a\u4fe1\u7cfb\u7edf\u4e2d\u5177\u6709\u5904\u7406\u79fb\u52a8\u6027\u7684\u663e\u8457\u4f18\u52bf\uff0c\u4f46\u5728\u53cc\u529f\u80fd\u96f7\u8fbe\u901a\u4fe1\u4e2d\u7684\u6700\u4f18\u4fe1\u53f7\u8bbe\u8ba1\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u89e3\u51b3\u5bfc\u9891\u7b26\u53f7\u8bbe\u8ba1\u548c\u6570\u636e\u529f\u7387\u5206\u914d\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\u3002", "method": "\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\uff0c\u5c06\u6a21\u7cca\u51fd\u6570\u7684\u7efc\u5408\u65c1\u74e3\u7535\u5e73\u4f5c\u4e3a\u96f7\u8fbe\u6307\u6807\uff0c\u63a8\u5bfc\u8003\u8651\u4fe1\u9053\u4f30\u8ba1\u8bef\u5dee\u7684OTFS\u4fe1\u9053\u5bb9\u91cf\u4e0b\u754c\u4f5c\u4e3a\u901a\u4fe1\u6307\u6807\uff0c\u6700\u5927\u5316\u611f\u77e5\u548c\u901a\u4fe1\u6307\u6807\u7684\u52a0\u6743\u548c\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u4fe1\u53f7\u76f8\u6bd4\u4f20\u7edf\u65b9\u6848\u663e\u8457\u6539\u5584\u4e86\u611f\u77e5-\u901a\u4fe1\u6027\u80fd\u533a\u57df\uff0c\u5728\u611f\u77e5\u65b9\u9762\u83b7\u5f97\u81f3\u5c119.44 dB\u7684ISL\u6291\u5236\u589e\u76ca\uff0c\u5728\u901a\u4fe1\u65b9\u9762\u83b7\u5f974.82 dB\u7684SINR\u589e\u76ca\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86OTFS\u5728\u53cc\u529f\u80fd\u96f7\u8fbe\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u4fe1\u53f7\u8bbe\u8ba1\u4f18\u5316\uff0c\u4e3a\u5145\u5206\u5229\u7528OTFS\u6f5c\u529b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20122", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20122", "abs": "https://arxiv.org/abs/2510.20122", "authors": ["Adnan Abdullah", "David Blow", "Sara Rampazzi", "Md Jahidul Islam"], "title": "Active Localization of Close-range Adversarial Acoustic Sources for Underwater Data Center Surveillance", "comment": "12 pages, V1", "summary": "Underwater data infrastructures offer natural cooling and enhanced physical\nsecurity compared to terrestrial facilities, but are susceptible to acoustic\ninjection attacks that can disrupt data integrity and availability. This work\npresents a comprehensive surveillance framework for localizing and tracking\nclose-range adversarial acoustic sources targeting offshore infrastructures,\nparticularly underwater data centers (UDCs). We propose a heterogeneous\nreceiver configuration comprising a fixed hydrophone mounted on the facility\nand a mobile hydrophone deployed on a dedicated surveillance robot. While using\nenough arrays of static hydrophones covering large infrastructures is not\nfeasible in practice, off-the-shelf approaches based on time difference of\narrival (TDOA) and frequency difference of arrival (FDOA) filtering fail to\ngeneralize for this dynamic configuration. To address this, we formulate a\nLocus-Conditioned Maximum A-Posteriori (LC-MAP) scheme to generate acoustically\ninformed and geometrically consistent priors, ensuring a physically plausible\ninitial state for a joint TDOA-FDOA filtering. We integrate this into an\nunscented Kalman filtering (UKF) pipeline, which provides reliable convergence\nunder nonlinearity and measurement noise. Extensive Monte Carlo analyses,\nGazebo-based physics simulations, and field trials demonstrate that the\nproposed framework can reliably estimate the 3D position and velocity of an\nadversarial acoustic attack source in real time. It achieves sub-meter\nlocalization accuracy and over 90% success rates, with convergence times nearly\nhalved compared to baseline methods. Overall, this study establishes a\ngeometry-aware, real-time approach for acoustic threat localization, advancing\nautonomous surveillance capabilities of underwater infrastructures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u6c34\u4e0b\u6570\u636e\u4e2d\u5fc3\u58f0\u5b66\u653b\u51fb\u6e90\u5b9a\u4f4d\u7684\u5b9e\u65f6\u76d1\u63a7\u6846\u67b6\uff0c\u7ed3\u5408\u56fa\u5b9a\u548c\u79fb\u52a8\u6c34\u542c\u5668\uff0c\u91c7\u7528LC-MAP\u65b9\u6848\u548cUKF\u6ee4\u6ce2\uff0c\u5b9e\u73b0\u4e9a\u7c73\u7ea7\u5b9a\u4f4d\u7cbe\u5ea6\u548c90%\u4ee5\u4e0a\u7684\u6210\u529f\u7387\u3002", "motivation": "\u6c34\u4e0b\u6570\u636e\u4e2d\u5fc3\u867d\u7136\u5177\u6709\u81ea\u7136\u51b7\u5374\u548c\u7269\u7406\u5b89\u5168\u4f18\u52bf\uff0c\u4f46\u6613\u53d7\u58f0\u5b66\u6ce8\u5165\u653b\u51fb\u5a01\u80c1\uff0c\u4f20\u7edfTDOA/FDOA\u65b9\u6cd5\u65e0\u6cd5\u6709\u6548\u5e94\u5bf9\u52a8\u6001\u914d\u7f6e\u7684\u76d1\u63a7\u9700\u6c42\u3002", "method": "\u91c7\u7528\u5f02\u6784\u63a5\u6536\u5668\u914d\u7f6e\uff08\u56fa\u5b9a\u6c34\u542c\u5668+\u79fb\u52a8\u6c34\u542c\u5668\uff09\uff0c\u63d0\u51faLC-MAP\u65b9\u6848\u751f\u6210\u58f0\u5b66\u4fe1\u606f\u548c\u51e0\u4f55\u4e00\u81f4\u7684\u5148\u9a8c\uff0c\u7ed3\u5408UKF\u6ee4\u6ce2\u8fdb\u884c\u8054\u5408TDOA-FDOA\u5904\u7406\u3002", "result": "\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u5206\u6790\u3001Gazebo\u7269\u7406\u4eff\u771f\u548c\u73b0\u573a\u8bd5\u9a8c\u9a8c\u8bc1\uff0c\u80fd\u591f\u5b9e\u65f6\u4f30\u8ba1\u653b\u51fb\u6e90\u76843D\u4f4d\u7f6e\u548c\u901f\u5ea6\uff0c\u5b9a\u4f4d\u7cbe\u5ea6\u8fbe\u5230\u4e9a\u7c73\u7ea7\uff0c\u6210\u529f\u7387\u8d85\u8fc790%\uff0c\u6536\u655b\u65f6\u95f4\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u51cf\u5c11\u8fd1\u4e00\u534a\u3002", "conclusion": "\u8be5\u7814\u7a76\u5efa\u7acb\u4e86\u51e0\u4f55\u611f\u77e5\u7684\u5b9e\u65f6\u58f0\u5b66\u5a01\u80c1\u5b9a\u4f4d\u65b9\u6cd5\uff0c\u63d0\u5347\u4e86\u6c34\u4e0b\u57fa\u7840\u8bbe\u65bd\u7684\u81ea\u4e3b\u76d1\u63a7\u80fd\u529b\u3002"}}
{"id": "2510.20140", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20140", "abs": "https://arxiv.org/abs/2510.20140", "authors": ["Jiangong Chen", "Xia Lei", "Kaitao Meng", "Kawon Han", "Yuchen Zhang", "Christos Masouros", "Athina P. Petropulu"], "title": "Sensing Security in Near-Field ISAC: Exploiting Scatterers for Eavesdropper Deception", "comment": null, "summary": "In this paper, we explore sensing security in near-field (NF) integrated\nsensing and communication (ISAC) scenarios by exploiting known scatterers in\nthe sensing scene. We propose a location deception (LD) scheme where scatterers\nare deliberately illuminated with probing power that is higher than that\ndirected toward targets of interest, with the goal of deceiving potential\neavesdroppers (Eves) with sensing capability into misidentifying scatterers as\ntargets. While the known scatterers can be removed at the legitimate sensing\nreceiver, our LD approach causes Eves to misdetect targets. Notably, this\ndeception is achieved without requiring any prior information about the Eves'\ncharacteristics or locations. To strike a flexible three-way tradeoff among\ncommunication, sensing, and sensing-security performance, the sum rate and\npower allocated to scatterers are weighted and maximized under a legitimate\nradar signal-to-interference-plus-noise ratio (SINR) constraint. We employ the\nfractional programming (FP) framework and semidefinite relaxation (SDR) to\nsolve this problem. To evaluate the security of the proposed LD scheme, the\nCramer-Rao Bound (CRB) and mean squared error (MSE) metrics are employed.\nAdditionally, we introduce the Kullback-Leibler Divergence (KLD) gap between\ntargets and scatterers at Eve to quantify the impact of the proposed LD\nframework on Eve's sensing performance from an information-theoretical\nperspective. Simulation results demonstrate that the proposed LD scheme can\nflexibly adjust the beamforming strategy according to performance requirements,\nthereby achieving the desired three-way tradeoff. In particular, in terms of\nsensing security, the proposed scheme significantly enhances the clutter signal\nstrength at Eve's side, leading to confusion or even missed detection of the\nactual target.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u8fd1\u573aISAC\u573a\u666f\u4e2d\u5229\u7528\u5df2\u77e5\u6563\u5c04\u4f53\u8fdb\u884c\u4f4d\u7f6e\u6b3a\u9a97\u7684\u65b9\u6848\uff0c\u901a\u8fc7\u5411\u6563\u5c04\u4f53\u5206\u914d\u66f4\u9ad8\u63a2\u6d4b\u529f\u7387\u6765\u8bef\u5bfc\u7a83\u542c\u8005\u5c06\u6563\u5c04\u4f53\u8bef\u8ba4\u4e3a\u76ee\u6807\uff0c\u4ece\u800c\u63d0\u5347\u611f\u77e5\u5b89\u5168\u6027\u3002", "motivation": "\u5728\u8fd1\u573a\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u573a\u666f\u4e2d\uff0c\u9700\u8981\u4fdd\u62a4\u611f\u77e5\u76ee\u6807\u4fe1\u606f\u4e0d\u88ab\u6709\u611f\u77e5\u80fd\u529b\u7684\u7a83\u542c\u8005\u83b7\u53d6\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u77e5\u9053\u7a83\u542c\u8005\u7684\u7279\u5f81\u6216\u4f4d\u7f6e\u4fe1\u606f\u3002", "method": "\u91c7\u7528\u4f4d\u7f6e\u6b3a\u9a97\u65b9\u6848\uff0c\u6545\u610f\u5411\u6563\u5c04\u4f53\u5206\u914d\u6bd4\u76ee\u6807\u66f4\u9ad8\u7684\u63a2\u6d4b\u529f\u7387\uff1b\u4f7f\u7528\u5206\u6570\u89c4\u5212\u548c\u534a\u5b9a\u677e\u5f1b\u65b9\u6cd5\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u7b56\u7565\uff1b\u91c7\u7528CRB\u3001MSE\u548cKLD\u5dee\u8ddd\u7b49\u6307\u6807\u8bc4\u4f30\u5b89\u5168\u6027\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6848\u80fd\u7075\u6d3b\u8c03\u6574\u6ce2\u675f\u6210\u5f62\u7b56\u7565\uff0c\u5b9e\u73b0\u901a\u4fe1\u3001\u611f\u77e5\u548c\u611f\u77e5\u5b89\u5168\u6027\u7684\u4e09\u65b9\u6743\u8861\uff0c\u663e\u8457\u589e\u5f3a\u7a83\u542c\u8005\u7aef\u7684\u6742\u6ce2\u4fe1\u53f7\u5f3a\u5ea6\uff0c\u5bfc\u81f4\u5b9e\u9645\u76ee\u6807\u88ab\u6df7\u6dc6\u6216\u6f0f\u68c0\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u4f4d\u7f6e\u6b3a\u9a97\u65b9\u6848\u80fd\u5728\u65e0\u9700\u7a83\u542c\u8005\u5148\u9a8c\u4fe1\u606f\u7684\u60c5\u51b5\u4e0b\u6709\u6548\u63d0\u5347\u611f\u77e5\u5b89\u5168\u6027\uff0c\u5b9e\u73b0\u901a\u4fe1\u3001\u611f\u77e5\u548c\u5b89\u5168\u6027\u7684\u7075\u6d3b\u6743\u8861\u3002"}}
{"id": "2510.20146", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20146", "abs": "https://arxiv.org/abs/2510.20146", "authors": ["Yongning Qi", "Tao Zhou", "Zuowei Xiang", "Liu Liu", "Bo Ai"], "title": "Deep Learning Based Joint Space-Time-Frequency Domain Channel Prediction for Cell-Free Massive MIMO Systems", "comment": "13 pages, 17 figures. This work has been submitted to the IEEE for\n  possible publication", "summary": "The cell-free massive multi-input multi-output (CF-mMIMO) is a promising\ntechnology for the six generation (6G) communication systems. Channel\nprediction will play an important role in obtaining the accurate CSI to improve\nthe performance of CF-mMIMO systems. This paper studies a deep learning (DL)\nbased joint space-time-frequency domain channel prediction for CF-mMIMO.\nFirstly, the prediction problems are formulated, which can output the\nmulti-step prediction results in parallel without error propagation. Then, a\nnovel channel prediction model is proposed, which adds frequency convolution\n(FreqConv) and space convolution (SpaceConv) layers to Transformer-encoder. It\nis able to utilize the space-time-frequency correlations and extract the space\ncorrelation in the irregular AP deployment. Next, simulated datasets with\ndifferent sizes of service areas, UE velocities and scenarios are generated,\nand correlation analysis and cross-validation are used to determine the optimal\nhyper-parameters. According to the optimized hyper-parameters, the prediction\naccuracy and computational complexity are evaluated based on simulated\ndatasets. It is indicated that the prediction accuracy of the proposed model is\nhigher than traditional model, and its computational complexity is lower than\ntraditional Transformer model. After that, the impacts of space-time-frequency\ncorrelations on prediction accuracy are studied. Finally, realistic datasets in\na high-speed train (HST) long-term evolution (LTE) network are collected to\nverify the prediction accuracy. The verification results demonstrate that it\nalso achieves higher prediction accuracy compared with traditional models in\nthe HST LTE network.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u8054\u5408\u7a7a\u65f6\u9891\u57df\u4fe1\u9053\u9884\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u6539\u8fdbTransformer\u67b6\u6784\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u5e76\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u662f6G\u901a\u4fe1\u7cfb\u7edf\u7684\u5173\u952e\u6280\u672f\uff0c\u51c6\u786e\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u83b7\u53d6\u5bf9\u7cfb\u7edf\u6027\u80fd\u81f3\u5173\u91cd\u8981\uff0c\u800c\u4f20\u7edf\u4fe1\u9053\u9884\u6d4b\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u4fe1\u9053\u9884\u6d4b\u6a21\u578b\uff0c\u5728Transformer\u7f16\u7801\u5668\u4e2d\u6dfb\u52a0\u9891\u7387\u5377\u79ef\u548c\u7a7a\u95f4\u5377\u79ef\u5c42\uff0c\u5229\u7528\u7a7a\u65f6\u9891\u76f8\u5173\u6027\u5e76\u63d0\u53d6\u4e0d\u89c4\u5219AP\u90e8\u7f72\u7684\u7a7a\u95f4\u76f8\u5173\u6027\u3002", "result": "\u6240\u63d0\u6a21\u578b\u6bd4\u4f20\u7edf\u6a21\u578b\u5177\u6709\u66f4\u9ad8\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u6bd4\u4f20\u7edfTransformer\u6a21\u578b\u5177\u6709\u66f4\u4f4e\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5728\u9ad8\u901f\u94c1\u8defLTE\u7f51\u7edc\u4e2d\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u8054\u5408\u7a7a\u65f6\u9891\u57df\u4fe1\u9053\u9884\u6d4b\u65b9\u6cd5\u80fd\u6709\u6548\u63d0\u5347\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u4fe1\u9053\u9884\u6d4b\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.20215", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20215", "abs": "https://arxiv.org/abs/2510.20215", "authors": ["Xuesong Wang"], "title": "NOMA for Visible Light Communications: Recent Advances and Future Directions", "comment": "This is a survey article. Sections introducing OFDM variants and NOMA\n  definitions use standard formulations with appropriate citations. We have\n  rewritten and condensed textbook-style passages to minimize overlap", "summary": "Rapidly increasing demand for high speed data is pushing 6G wireless networks\nto support larger link scales, lower latency, and higher spectral efficiency.\nVisible light communications (VLC) is a strong complement to radio frequency\n(RF) systems within 6G. The latest ITU G.9991 and IEEE 802.11bb standards are\nadapted from cable and RF wireless technologies for use in VLC, so they do not\nfully exploit the optical nature of light links. VLC links are often asymmetric\nbetween uplink and downlink, which makes TDMA style protocols inefficient when\nmany users generate bursty and asymmetric traffic. Compared with RF, the strong\ndirectionality and frequent line of sight in VLC can mitigate hidden and\nexposed terminals, yet these effects can still appear under limited field of\nview, blockage, or reflections. CSMA/CA and related methods remain usable in\nVLC and in RF plus VLC networks, but they usually need design tweaks such as\nRTS/CTS or directional sensing to perform well. Although the optical spectrum\nis vast, the bandwidth of practical LEDs and of common PIN or APD receivers is\nlimited, so efficient multiple access can yield large gains. This motivates a\nclean slate design for VLC, especially at the MAC layer. NOMA, first explored\nin 5G RF systems, is also promising for 6G VLC. It lets multiple users share\nthe same time and frequency resources while tolerating controlled interference.\nThis paper reviews progress in VLC and in NOMA based VLC, outlines key\noptimization constraints and objectives, surveys scenarios that fit NOMA in\nVLC, and points to several directions for future work.", "AI": {"tldr": "\u672c\u6587\u56de\u987e\u4e86\u53ef\u89c1\u5149\u901a\u4fe1(VLC)\u548c\u975e\u6b63\u4ea4\u591a\u5740\u63a5\u5165(NOMA)\u57286G\u7f51\u7edc\u4e2d\u7684\u7814\u7a76\u8fdb\u5c55\uff0c\u5206\u6790\u4e86VLC\u94fe\u8def\u7279\u6027\u5bf9MAC\u5c42\u8bbe\u8ba1\u7684\u6311\u6218\uff0c\u5e76\u63a2\u8ba8\u4e86NOMA\u5728VLC\u4e2d\u7684\u5e94\u7528\u524d\u666f\u548c\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "6G\u7f51\u7edc\u5bf9\u9ad8\u901f\u6570\u636e\u4f20\u8f93\u7684\u9700\u6c42\u63a8\u52a8VLC\u4f5c\u4e3a\u5c04\u9891\u7cfb\u7edf\u7684\u8865\u5145\uff0c\u4f46\u73b0\u6709\u6807\u51c6\u672a\u5145\u5206\u5229\u7528\u5149\u94fe\u8def\u7684\u7279\u6027\uff0cVLC\u94fe\u8def\u7684\u4e0d\u5bf9\u79f0\u6027\u548c\u65b9\u5411\u6027\u7279\u70b9\u9700\u8981\u91cd\u65b0\u8bbe\u8ba1MAC\u5c42\u534f\u8bae\uff0cNOMA\u6280\u672f\u6709\u671b\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u65b9\u6cd5\uff0c\u5206\u6790VLC\u94fe\u8def\u7279\u6027\u3001\u73b0\u6709MAC\u534f\u8bae\u7684\u5c40\u9650\u6027\uff0c\u63a2\u8ba8NOMA\u5728VLC\u4e2d\u7684\u5e94\u7528\u573a\u666f\u3001\u4f18\u5316\u7ea6\u675f\u548c\u76ee\u6807\uff0c\u5e76\u6307\u51fa\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "result": "\u7814\u7a76\u53d1\u73b0VLC\u94fe\u8def\u5177\u6709\u4e0d\u5bf9\u79f0\u6027\u3001\u65b9\u5411\u6027\u548c\u5e26\u5bbd\u9650\u5236\u7b49\u7279\u70b9\uff0cCSMA/CA\u7b49\u4f20\u7edf\u534f\u8bae\u9700\u8981\u8c03\u6574\uff0cNOMA\u6280\u672f\u80fd\u591f\u5141\u8bb8\u591a\u7528\u6237\u5171\u4eab\u65f6\u9891\u8d44\u6e90\u5e76\u63a7\u5236\u5e72\u6270\uff0c\u5728VLC\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002", "conclusion": "VLC\u9700\u8981\u5168\u65b0\u7684MAC\u5c42\u8bbe\u8ba1\uff0cNOMA\u6280\u672f\u662f6G VLC\u4e2d\u4e00\u4e2a\u6709\u524d\u666f\u7684\u65b9\u5411\uff0c\u672a\u6765\u9700\u8981\u5728\u4f18\u5316\u7ea6\u675f\u3001\u5e94\u7528\u573a\u666f\u548c\u5b9e\u9645\u90e8\u7f72\u7b49\u65b9\u9762\u8fdb\u884c\u6df1\u5165\u7814\u7a76\u3002"}}
{"id": "2510.20265", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20265", "abs": "https://arxiv.org/abs/2510.20265", "authors": ["Burak Ahmet Ozden", "Erdogan Aydin", "Emir Aslandogan", "Haci Ilhan", "Ertugrul Basar", "Miaowen Wen", "Marco Di Renzo", "Vincent Poor"], "title": "A Survey of OTFS-Based Index Modulation Techniques: Challenges, Benefits, and Future Directions for 6G and Beyond", "comment": "34 pages, 13 figures, 8 Tables", "summary": "Orthogonal time frequency space (OTFS) is a two-dimensional modulation\ntechnique that uses the delay-Doppler (DD) domain and is a candidate for\nproviding robust, high-capacity wireless communications for envisioned 6G and\nbeyond networks. The OTFS technique maps data to the DD domain instead of the\ntraditional time-frequency domain, enabling it to fully utilize channel\ndiversity and transform fast time-varying channels into nearly static channels.\nIndex modulation (IM) is a communication paradigm that conveys information not\nonly through conventional modulation symbols but also by encoding data bits in\nthe indices of the selected communication resources to improve error\nperformance, spectral efficiency, and energy efficiency. In this survey, a\ncomprehensive review of work on OTFS-based wireless communication systems is\npresented. In particular, the existing OTFS-IM schemes are reviewed and\nsystematically categorized according to their system architectures, detection\nmethods, and performance aspects such as capacity, peak-to-average power ratio,\ndiversity, complexity, imperfect channel state information, spectral\nefficiency, and outage probability. Furthermore, the operating principles and\nsystem models of OTFS-IM variants-including OTFS-based space shift keying,\nOTFS-based spatial modulation, OTFS-based quadrature spatial modulation,\nOTFS-based media-based modulation, and OTFS-based code index modulation-are\ndescribed, followed by a comparative performance analysis in terms of\ncomputational complexity, error performance, capacity, energy saving, spectral\nefficiency, and throughput. Finally, the challenges, benefits, and future\ndirections for OTFS-IM systems are discussed, covering key aspects such as\ncomplexity, efficiency, latency, channel estimation, hardware constraints,\nsynchronization, security, and potential integration with other advanced\nwireless communication techniques.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u57fa\u4e8eOTFS\u7684\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\uff0c\u91cd\u70b9\u5206\u6790\u4e86OTFS\u4e0e\u7d22\u5f15\u8c03\u5236(IM)\u7ed3\u5408\u7684\u591a\u79cd\u65b9\u6848\uff0c\u5305\u62ec\u7cfb\u7edf\u67b6\u6784\u3001\u68c0\u6d4b\u65b9\u6cd5\u548c\u6027\u80fd\u8bc4\u4f30\uff0c\u5e76\u8ba8\u8bba\u4e86\u672a\u6765\u7814\u7a76\u65b9\u5411\u3002", "motivation": "OTFS\u6280\u672f\u5229\u7528\u5ef6\u8fdf-\u591a\u666e\u52d2\u57df\u63d0\u4f9b\u5bf9\u65f6\u53d8\u4fe1\u9053\u7684\u9ad8\u9c81\u68d2\u6027\uff0c\u800c\u7d22\u5f15\u8c03\u5236\u901a\u8fc7\u8d44\u6e90\u7d22\u5f15\u7f16\u7801\u63d0\u9ad8\u6027\u80fd\u3002\u5c06\u4e24\u8005\u7ed3\u5408\u53ef\u4ee5\u8fdb\u4e00\u6b65\u63d0\u53476G\u53ca\u672a\u6765\u7f51\u7edc\u7684\u901a\u4fe1\u6027\u80fd\u3002", "method": "\u7cfb\u7edf\u6027\u5730\u5206\u7c7b\u548c\u6bd4\u8f83\u4e86\u591a\u79cdOTFS-IM\u53d8\u4f53\u65b9\u6848\uff0c\u5305\u62ec\u7a7a\u95f4\u79fb\u4f4d\u952e\u63a7\u3001\u7a7a\u95f4\u8c03\u5236\u3001\u6b63\u4ea4\u7a7a\u95f4\u8c03\u5236\u3001\u5a92\u4f53\u8c03\u5236\u548c\u7801\u7d22\u5f15\u8c03\u5236\u7b49\uff0c\u5206\u6790\u4e86\u5b83\u4eec\u7684\u7cfb\u7edf\u6a21\u578b\u548c\u5de5\u4f5c\u539f\u7406\u3002", "result": "\u901a\u8fc7\u6bd4\u8f83\u5206\u6790\u53d1\u73b0\uff0cOTFS-IM\u65b9\u6848\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u3001\u8bef\u7801\u6027\u80fd\u3001\u5bb9\u91cf\u3001\u8282\u80fd\u3001\u9891\u8c31\u6548\u7387\u548c\u541e\u5410\u91cf\u7b49\u65b9\u9762\u5177\u6709\u4e0d\u540c\u4f18\u52bf\uff0c\u4e3a\u4e0d\u540c\u5e94\u7528\u573a\u666f\u63d0\u4f9b\u4e86\u591a\u6837\u5316\u9009\u62e9\u3002", "conclusion": "OTFS-IM\u7cfb\u7edf\u57286G\u7f51\u7edc\u4e2d\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u4f46\u4ecd\u9762\u4e34\u590d\u6742\u5ea6\u3001\u5ef6\u8fdf\u3001\u4fe1\u9053\u4f30\u8ba1\u7b49\u6311\u6218\uff0c\u672a\u6765\u9700\u8981\u4e0e\u5148\u8fdb\u65e0\u7ebf\u6280\u672f\u96c6\u6210\u4ee5\u5145\u5206\u53d1\u6325\u5176\u4f18\u52bf\u3002"}}
{"id": "2510.20274", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20274", "abs": "https://arxiv.org/abs/2510.20274", "authors": ["Kangda Zhi", "Tianyu Yang", "Songyan Xue", "Giuseppe Caire"], "title": "Near-Field 3D Localization and MIMO Channel Estimation with Sub-Connected Planar Arrays", "comment": "Accepted by GLOBECOM 2025", "summary": "This paper investigates the design of channel estimation and 3D localization\nalgorithms in a challenging scenario, where a sub-connected planar extremely\nlarge-scale multiple-input multiple-output (XL-MIMO) communicates with\nmulti-antenna users. In the near field, the uplink MIMO channel is of full\ncolumn rank and therefore can not be estimated effectively by applying existing\ncodebooks that are designed for the far-field case or for the near-field case\nbut limited to single antenna users. To solve this problem, we propose a\nthree-stage algorithm aided by orthogonal matching pursuit (OMP) and sparse\nBayesian learning (SBL). Specifically, we firstly partition the XL-MIMO into\nsubarrays and use OMP to solve the compressed sensing (CS) problem about\nsubarray channel estimation with the Discrete Fourier Transform (DFT)-based\ndictionary matrix. Secondly, exploiting the estimated subarray channels and\nemploying one-dimensional multiple signal classification (MUSIC), we estimate\nthe central location of the user array under the Least Squares (LS) criterion.\nFinally, we utilize the estimated central location to construct a refined\nlocation-aided dictionary matrix and obtain the MIMO channel estimation using\nSBL. Results exhibit the significant superiority of the proposed algorithm\ncompared with several benchmarks, in terms of both the pilot overhead and\nestimation accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u8fd1\u573aXL-MIMO\u7cfb\u7edf\u4e2d\u4fe1\u9053\u4f30\u8ba1\u548c3D\u5b9a\u4f4d\u7684\u4e09\u9636\u6bb5\u7b97\u6cd5\uff0c\u7ed3\u5408OMP\u548cSBL\u6280\u672f\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5bfc\u9891\u5f00\u9500\u5e76\u63d0\u9ad8\u4e86\u4f30\u8ba1\u7cbe\u5ea6", "motivation": "\u5728\u8fd1\u573aXL-MIMO\u7cfb\u7edf\u4e2d\uff0c\u7531\u4e8e\u4fe1\u9053\u77e9\u9635\u6ee1\u5217\u79e9\uff0c\u73b0\u6709\u7684\u8fdc\u573a\u6216\u5355\u5929\u7ebf\u7528\u6237\u8fd1\u573a\u7801\u672c\u65e0\u6cd5\u6709\u6548\u4f30\u8ba1\u4fe1\u9053\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u4e09\u9636\u6bb5\u7b97\u6cd5\uff1a1) \u4f7f\u7528OMP\u548cDFT\u5b57\u5178\u8fdb\u884c\u5b50\u9635\u5217\u4fe1\u9053\u4f30\u8ba1\uff1b2) \u5229\u7528MUSIC\u548cLS\u51c6\u5219\u4f30\u8ba1\u7528\u6237\u9635\u5217\u4e2d\u5fc3\u4f4d\u7f6e\uff1b3) \u6784\u5efa\u4f4d\u7f6e\u8f85\u52a9\u5b57\u5178\u77e9\u9635\uff0c\u4f7f\u7528SBL\u8fdb\u884cMIMO\u4fe1\u9053\u4f30\u8ba1", "result": "\u4e0e\u591a\u4e2a\u57fa\u51c6\u65b9\u6cd5\u76f8\u6bd4\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u5bfc\u9891\u5f00\u9500\u548c\u4f30\u8ba1\u7cbe\u5ea6\u65b9\u9762\u5747\u8868\u73b0\u51fa\u663e\u8457\u4f18\u52bf", "conclusion": "\u8be5\u4e09\u9636\u6bb5\u7b97\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u8fd1\u573aXL-MIMO\u7cfb\u7edf\u4e2d\u591a\u5929\u7ebf\u7528\u6237\u7684\u4fe1\u9053\u4f30\u8ba1\u548c3D\u5b9a\u4f4d\u95ee\u9898\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2510.20354", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20354", "abs": "https://arxiv.org/abs/2510.20354", "authors": ["Huayan Guo", "Junhui Rao", "Alex M. H. Wong", "Ross Murch", "Vincent K. N. Lau"], "title": "Channel Estimation and Passive Beamforming for Pixel-based Reconfigurable Intelligent Surfaces with Non-Separable State Response", "comment": "13 pages, 12 figures", "summary": "Pixel-based reconfigurable intelligent surfaces (RISs) employ a novel design\nto achieve high reflection gain at a lower hardware cost by eliminating the\nphase shifters used in traditional RIS. However, this design presents\nchallenges for channel estimation and passive beamforming due to its\nnon-separable state response, rendering existing solutions ineffective. To\naddress this, we first approximate the non-separable RIS response functions\nusing a kernel-based method and a deep neural network, achieving high accuracy\nwhile reducing computational and memory complexity. Next, we propose a\nsimplified cascaded channel model that focuses on dominated scattering paths\nwith limited unknown parameters, along with customized algorithms to estimate\nshort-term and long-term parameters separately. Finally, we introduce a\nlow-complexity passive beamforming algorithm to configure the discrete RIS\nstate vector, maximizing the achievable rate. Our simulation results\ndemonstrate that the proposed solution significantly outperforms various\nbaselines across a wide SNR range.", "AI": {"tldr": "\u63d0\u51fa\u9488\u5bf9\u50cf\u7d20\u578b\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u7684\u5b8c\u6574\u89e3\u51b3\u65b9\u6848\uff0c\u5305\u62ecRIS\u54cd\u5e94\u51fd\u6570\u8fd1\u4f3c\u3001\u7b80\u5316\u7ea7\u8054\u4fe1\u9053\u6a21\u578b\u548c\u4f4e\u590d\u6742\u5ea6\u6ce2\u675f\u6210\u5f62\u7b97\u6cd5\uff0c\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u50cf\u7d20\u578bRIS\u901a\u8fc7\u6d88\u9664\u79fb\u76f8\u5668\u964d\u4f4e\u4e86\u786c\u4ef6\u6210\u672c\uff0c\u4f46\u5176\u4e0d\u53ef\u5206\u79bb\u72b6\u6001\u54cd\u5e94\u7ed9\u4fe1\u9053\u4f30\u8ba1\u548c\u6ce2\u675f\u6210\u5f62\u5e26\u6765\u6311\u6218\uff0c\u73b0\u6709\u89e3\u51b3\u65b9\u6848\u65e0\u6548\u3002", "method": "1) \u4f7f\u7528\u6838\u65b9\u6cd5\u548c\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u8fd1\u4f3cRIS\u54cd\u5e94\u51fd\u6570\uff1b2) \u63d0\u51fa\u7b80\u5316\u7ea7\u8054\u4fe1\u9053\u6a21\u578b\u805a\u7126\u4e3b\u5bfc\u6563\u5c04\u8def\u5f84\uff1b3) \u8bbe\u8ba1\u5206\u79bb\u4f30\u8ba1\u77ed\u671f\u548c\u957f\u671f\u53c2\u6570\u7684\u7b97\u6cd5\uff1b4) \u5f00\u53d1\u4f4e\u590d\u6742\u5ea6\u88ab\u52a8\u6ce2\u675f\u6210\u5f62\u7b97\u6cd5\u914d\u7f6e\u79bb\u6563RIS\u72b6\u6001\u5411\u91cf\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6848\u5728\u5e7f\u6cdbSNR\u8303\u56f4\u5185\u663e\u8457\u4f18\u4e8e\u5404\u79cd\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u50cf\u7d20\u578bRIS\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4fe1\u9053\u4f30\u8ba1\u548c\u6ce2\u675f\u6210\u5f62\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u4f4e\u6210\u672c\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u3002"}}
{"id": "2510.20363", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.20363", "abs": "https://arxiv.org/abs/2510.20363", "authors": ["Andr\u00e1s R\u00e1cz", "Tam\u00e1s Borsos", "Andr\u00e1s Veres", "Benedek Csala"], "title": "A Transformer Inspired AI-based MIMO receiver", "comment": null, "summary": "We present AttDet, a Transformer-inspired MIMO (Multiple Input Multiple\nOutput) detection method that treats each transmit layer as a token and learns\ninter-stream interference via a lightweight self-attention mechanism. Queries\nand keys are derived directly from the estimated channel matrix, so attention\nscores quantify channel correlation. Values are initialized by matched-filter\noutputs and iteratively refined. The AttDet design combines model-based\ninterpretability with data-driven flexibility. We demonstrate through\nlink-level simulations under realistic 5G channel models and high-order, mixed\nQAM modulation and coding schemes, that AttDet can approach near-optimal\nBER/BLER (Bit Error Rate/Block Error Rate) performance while maintaining\npredictable, polynomial complexity.", "AI": {"tldr": "AttDet\u662f\u4e00\u79cd\u57fa\u4e8eTransformer\u7684MIMO\u68c0\u6d4b\u65b9\u6cd5\uff0c\u5c06\u6bcf\u4e2a\u4f20\u8f93\u5c42\u89c6\u4e3atoken\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5b66\u4e60\u6d41\u95f4\u5e72\u6270\uff0c\u7ed3\u5408\u6a21\u578b\u53ef\u89e3\u91ca\u6027\u548c\u6570\u636e\u9a71\u52a8\u7075\u6d3b\u6027\u3002", "motivation": "\u89e3\u51b3MIMO\u7cfb\u7edf\u4e2d\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u5728\u9ad8\u9636\u8c03\u5236\u548c\u590d\u6742\u4fe1\u9053\u6761\u4ef6\u4e0b\u6027\u80fd\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u590d\u6742\u5ea6\u53ef\u63a7\u3002", "method": "\u5c06\u4f20\u8f93\u5c42\u4f5c\u4e3atoken\uff0c\u76f4\u63a5\u4ece\u4f30\u8ba1\u7684\u4fe1\u9053\u77e9\u9635\u63a8\u5bfc\u67e5\u8be2\u548c\u952e\u5411\u91cf\uff0c\u6ce8\u610f\u529b\u5206\u6570\u91cf\u5316\u4fe1\u9053\u76f8\u5173\u6027\uff0c\u503c\u5411\u91cf\u7531\u5339\u914d\u6ee4\u6ce2\u5668\u8f93\u51fa\u521d\u59cb\u5316\u5e76\u8fed\u4ee3\u4f18\u5316\u3002", "result": "\u5728\u73b0\u5b9e\u76845G\u4fe1\u9053\u6a21\u578b\u548c\u9ad8\u9636\u6df7\u5408QAM\u8c03\u5236\u7f16\u7801\u65b9\u6848\u4e0b\uff0cAttDet\u80fd\u591f\u63a5\u8fd1\u6700\u4f18\u7684BER/BLER\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u591a\u9879\u5f0f\u590d\u6742\u5ea6\u3002", "conclusion": "AttDet\u6210\u529f\u5730\u5c06Transformer\u601d\u60f3\u5e94\u7528\u4e8eMIMO\u68c0\u6d4b\uff0c\u5b9e\u73b0\u4e86\u63a5\u8fd1\u6700\u4f18\u6027\u80fd\u4e0e\u53ef\u63a7\u590d\u6742\u5ea6\u7684\u5e73\u8861\uff0c\u4e3a5G\u53ca\u672a\u6765\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.20380", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20380", "abs": "https://arxiv.org/abs/2510.20380", "authors": ["Anwar Ahmed Khan", "Indrakshi Dey"], "title": "Efficient Medium Access Control for Low-Latency Industrial M2M Communications", "comment": "5th Int. Conference on Computing and Communication Networks.\n  (ICCCNet-2025)", "summary": "Efficient medium access control (MAC) is critical for enabling low-latency\nand reliable communication in industrial Machine-to-Machine (M2M) net-works,\nwhere timely data delivery is essential for seamless operation. The presence of\nmulti-priority data in high-risk industrial environments further adds to the\nchallenges. The development of tens of MAC schemes over the past decade often\nmakes it a tough choice to deploy the most efficient solu-tion. Therefore, a\ncomprehensive cross-comparison of major MAC protocols across a range of\nperformance parameters appears necessary to gain deeper insights into their\nrelative strengths and limitations. This paper presents a comparison of\nContention window-based MAC scheme BoP-MAC with a fragmentation based,\nFROG-MAC; both protocols focus on reducing the delay for higher priority\ntraffic, while taking a diverse approach. BoP-MAC assigns a differentiated\nback-off value to the multi-priority traffic, whereas FROG-MAC enables early\ntransmission of higher-priority packets by fragmenting lower-priority traffic.\nSimulations were performed on Contiki by varying the number of nodes for two\ntraffic priorities. It has been shown that when work-ing with multi-priority\nheterogenous data in the industrial environment, FROG-MAC results better both\nin terms of delay and throughput.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6bd4\u8f83\u4e86\u4e24\u79cd\u5de5\u4e1aM2M\u7f51\u7edcMAC\u534f\u8bae\uff1aBoP-MAC\u548cFROG-MAC\u3002BoP-MAC\u901a\u8fc7\u5dee\u5f02\u5316\u9000\u907f\u503c\u5904\u7406\u591a\u4f18\u5148\u7ea7\u6d41\u91cf\uff0c\u800cFROG-MAC\u901a\u8fc7\u5206\u6bb5\u4f4e\u4f18\u5148\u7ea7\u6d41\u91cf\u5b9e\u73b0\u9ad8\u4f18\u5148\u7ea7\u6570\u636e\u65e9\u671f\u4f20\u8f93\u3002\u4eff\u771f\u663e\u793aFROG-MAC\u5728\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u65b9\u9762\u8868\u73b0\u66f4\u4f18\u3002", "motivation": "\u5de5\u4e1aM2M\u7f51\u7edc\u4e2d\u9700\u8981\u4f4e\u5ef6\u8fdf\u53ef\u9760\u901a\u4fe1\uff0c\u591a\u4f18\u5148\u7ea7\u6570\u636e\u7684\u5b58\u5728\u589e\u52a0\u4e86\u6311\u6218\u3002\u8fc7\u53bb\u5341\u5e74\u5f00\u53d1\u4e86\u4f17\u591aMAC\u65b9\u6848\uff0c\u9700\u8981\u7efc\u5408\u6bd4\u8f83\u4ee5\u4e86\u89e3\u5404\u534f\u8bae\u7684\u76f8\u5bf9\u4f18\u52bf\u548c\u5c40\u9650\u3002", "method": "\u5728Contiki\u5e73\u53f0\u4e0a\u8fdb\u884c\u4eff\u771f\uff0c\u901a\u8fc7\u6539\u53d8\u8282\u70b9\u6570\u91cf\u6765\u6bd4\u8f83BoP-MAC\u548cFROG-MAC\u4e24\u79cd\u534f\u8bae\u7684\u6027\u80fd\u3002BoP-MAC\u91c7\u7528\u5dee\u5f02\u5316\u9000\u907f\u673a\u5236\uff0cFROG-MAC\u91c7\u7528\u6d41\u91cf\u5206\u6bb5\u65b9\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u5728\u5de5\u4e1a\u73af\u5883\u4e2d\u5904\u7406\u591a\u4f18\u5148\u7ea7\u5f02\u6784\u6570\u636e\u65f6\uff0cFROG-MAC\u5728\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u65b9\u9762\u8868\u73b0\u4f18\u4e8eBoP-MAC\u3002", "conclusion": "\u5bf9\u4e8e\u5de5\u4e1a\u73af\u5883\u4e2d\u7684\u591a\u4f18\u5148\u7ea7\u5f02\u6784\u6570\u636e\u4f20\u8f93\uff0cFROG-MAC\u534f\u8bae\u6bd4BoP-MAC\u534f\u8bae\u5728\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u65b9\u9762\u5177\u6709\u66f4\u597d\u7684\u6027\u80fd\u8868\u73b0\u3002"}}
{"id": "2510.20429", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20429", "abs": "https://arxiv.org/abs/2510.20429", "authors": ["Biao Dong", "Bin Cao", "Qinyu Zhang"], "title": "Inference-Optimal ISAC via Task-Oriented Feature Transmission and Power Allocation", "comment": null, "summary": "This work is concerned with the coordination gain in integrated sensing and\ncommunication (ISAC) systems under a compress-and-estimate (CE) framework,\nwherein inference performance is leveraged as the key metric. To enable\ntractable transceiver design and resource optimization, we characterize\ninference performance via an error probability bound as a monotonic function of\nthe discriminant gain (DG). This raises the natural question of whether\nmaximizing DG, rather than minimizing mean squared error (MSE), can yield\nbetter inference performance. Closed-form solutions for DG-optimal and\nMSE-optimal transceiver designs are derived, revealing water-filling-type\nstructures and explicit sensing and communication (S\\&C) tradeoff. Numerical\nexperiments confirm that DG-optimal design achieves more power-efficient\ntransmission, especially in the low signal-to-noise ratio (SNR) regime, by\nselectively allocating power to informative features and thus saving transmit\npower for sensing.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u538b\u7f29\u4f30\u8ba1\u6846\u67b6\u4e0b\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u534f\u8c03\u589e\u76ca\uff0c\u901a\u8fc7\u5224\u522b\u589e\u76ca\u6700\u5927\u5316\u800c\u975e\u5747\u65b9\u8bef\u5dee\u6700\u5c0f\u5316\u6765\u4f18\u5316\u63a8\u7406\u6027\u80fd\uff0c\u63a8\u5bfc\u4e86\u95ed\u5f0f\u89e3\u5e76\u9a8c\u8bc1\u4e86\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u66f4\u8282\u80fd\u7684\u4f20\u8f93\u3002", "motivation": "\u63a2\u7d22\u5728ISAC\u7cfb\u7edf\u4e2d\uff0c\u901a\u8fc7\u6700\u5927\u5316\u5224\u522b\u589e\u76ca\u800c\u975e\u4f20\u7edf\u7684\u6700\u5c0f\u5316\u5747\u65b9\u8bef\u5dee\uff0c\u662f\u5426\u80fd\u83b7\u5f97\u66f4\u597d\u7684\u63a8\u7406\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u5b9e\u73b0\u66f4\u8282\u80fd\u7684\u4f20\u8f93\u3002", "method": "\u91c7\u7528\u538b\u7f29\u4f30\u8ba1\u6846\u67b6\uff0c\u5c06\u63a8\u7406\u6027\u80fd\u8868\u5f81\u4e3a\u5224\u522b\u589e\u76ca\u7684\u5355\u8c03\u51fd\u6570\uff0c\u63a8\u5bfc\u4e86\u5224\u522b\u589e\u76ca\u6700\u4f18\u548c\u5747\u65b9\u8bef\u5dee\u6700\u4f18\u7684\u6536\u53d1\u5668\u95ed\u5f0f\u89e3\uff0c\u5177\u6709\u6ce8\u6c34\u578b\u7ed3\u6784\u548c\u660e\u786e\u7684\u611f\u77e5\u901a\u4fe1\u6743\u8861\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u8bc1\u5b9e\u5224\u522b\u589e\u76ca\u6700\u4f18\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u66f4\u8282\u80fd\u7684\u4f20\u8f93\uff0c\u7279\u522b\u662f\u5728\u4f4e\u4fe1\u566a\u6bd4\u533a\u57df\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u5206\u914d\u529f\u7387\u5230\u4fe1\u606f\u7279\u5f81\u6765\u8282\u7701\u611f\u77e5\u4f20\u8f93\u529f\u7387\u3002", "conclusion": "\u5224\u522b\u589e\u76ca\u6700\u5927\u5316\u65b9\u6cd5\u5728ISAC\u7cfb\u7edf\u4e2d\u4f18\u4e8e\u4f20\u7edf\u5747\u65b9\u8bef\u5dee\u6700\u5c0f\u5316\uff0c\u5c24\u5176\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u80fd\u5b9e\u73b0\u66f4\u6709\u6548\u7684\u529f\u7387\u5206\u914d\u548c\u611f\u77e5\u901a\u4fe1\u6743\u8861\u3002"}}
{"id": "2510.20447", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20447", "abs": "https://arxiv.org/abs/2510.20447", "authors": ["Abdul Jabbar", "Aakash Bansal", "William Whittow"], "title": "Analysis of Frequency-Diverse and Dispersion Effects in Dynamic Metasurface Antenna for Holographic Sensing and Imaging", "comment": "5 pages,6 figurues", "summary": "Dynamic metasurface antennas (DMAs) represent a novel approach to\nprogrammable and affordable electromagnetic wave manipulation for enhanced\nwireless communications, sensing, and imaging applications. Nevertheless,\ncurrent DMA designs and models are usually quasi-narrowband, neglecting the\nversatile frequency-diverse manifestation and its utilization. This work\ndemonstrates the frequency-diversity and dispersion operations of a\nrepresentative DMA structure at the millimeter-wave band. We demonstrate\nflexible dispersion manipulation through dynamic holographic reconfigurability\nof the meta-atoms in a DMA. This effect can create distinct radiation patterns\nacross the operating frequency band, achieving flexible frequency diversity\nwith enhanced scanning range within a compact, reconfigurable platform. It\neliminates the need for wideband systems or complex phase-shifting networks\nwhile offering an alternative to frequency-scanned static beams of traditional\nleaky-wave antennas. The results establish fundamental insights into modelling\nand utilization of dispersive effects of DMAs in next-generation near-field and\nfar-field holographic sensing and computational holographic imaging\napplications.", "AI": {"tldr": "\u672c\u6587\u5c55\u793a\u4e86\u52a8\u6001\u8d85\u8868\u9762\u5929\u7ebf\u5728\u6beb\u7c73\u6ce2\u9891\u6bb5\u7684\u9891\u7387\u591a\u6837\u6027\u548c\u8272\u6563\u64cd\u4f5c\uff0c\u901a\u8fc7\u52a8\u6001\u5168\u606f\u53ef\u91cd\u6784\u6027\u5b9e\u73b0\u7075\u6d3b\u7684\u8272\u6563\u64cd\u63a7\uff0c\u5728\u7d27\u51d1\u53ef\u91cd\u6784\u5e73\u53f0\u4e0a\u5b9e\u73b0\u589e\u5f3a\u7684\u626b\u63cf\u8303\u56f4\u548c\u9891\u7387\u591a\u6837\u6027\u3002", "motivation": "\u5f53\u524dDMA\u8bbe\u8ba1\u548c\u6a21\u578b\u901a\u5e38\u662f\u51c6\u7a84\u5e26\u7684\uff0c\u5ffd\u7565\u4e86\u591a\u529f\u80fd\u7684\u9891\u7387\u591a\u6837\u6027\u8868\u73b0\u53ca\u5176\u5229\u7528\uff0c\u9700\u8981\u63a2\u7d22DMA\u5728\u6beb\u7c73\u6ce2\u9891\u6bb5\u7684\u9891\u7387\u591a\u6837\u6027\u548c\u8272\u6563\u64cd\u4f5c\u3002", "method": "\u901a\u8fc7\u52a8\u6001\u5168\u606f\u53ef\u91cd\u6784\u6027\u64cd\u63a7DMA\u4e2d\u8d85\u539f\u5b50\u7684\u8272\u6563\uff0c\u5728\u64cd\u4f5c\u9891\u5e26\u5185\u521b\u5efa\u4e0d\u540c\u7684\u8f90\u5c04\u6a21\u5f0f\uff0c\u5b9e\u73b0\u7075\u6d3b\u7684\u9891\u7387\u591a\u6837\u6027\u3002", "result": "\u5b9e\u73b0\u4e86\u589e\u5f3a\u7684\u626b\u63cf\u8303\u56f4\u548c\u7075\u6d3b\u7684\u9891\u7387\u591a\u6837\u6027\uff0c\u6d88\u9664\u4e86\u5bf9\u5bbd\u5e26\u7cfb\u7edf\u6216\u590d\u6742\u79fb\u76f8\u7f51\u7edc\u7684\u9700\u6c42\uff0c\u4e3a\u4f20\u7edf\u6f0f\u6ce2\u5929\u7ebf\u7684\u9891\u7387\u626b\u63cf\u9759\u6001\u6ce2\u675f\u63d0\u4f9b\u4e86\u66ff\u4ee3\u65b9\u6848\u3002", "conclusion": "\u7ed3\u679c\u4e3a\u4e0b\u4e00\u4ee3\u8fd1\u573a\u548c\u8fdc\u573a\u5168\u606f\u4f20\u611f\u4ee5\u53ca\u8ba1\u7b97\u5168\u606f\u6210\u50cf\u5e94\u7528\u4e2dDMA\u8272\u6563\u6548\u5e94\u7684\u5efa\u6a21\u548c\u5229\u7528\u5efa\u7acb\u4e86\u57fa\u672c\u89c1\u89e3\u3002"}}
{"id": "2510.20507", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20507", "abs": "https://arxiv.org/abs/2510.20507", "authors": ["Xi Gao", "Akang Wang", "Junkai Zhang", "Qihong Duan", "Jiang Xue"], "title": "An Accelerated Mixed Weighted-Unweighted MMSE Approach for MU-MIMO Beamforming", "comment": null, "summary": "Precoding design based on weighted sum-rate (WSR) maximization is a\nfundamental problem in downlink multi-user multiple-input multiple-output\n(MU-MIMO) systems. While the weighted minimum mean-square error (WMMSE)\nalgorithm is a standard solution, its high computational complexity--cubic in\nthe number of base station antennas due to matrix inversions--hinders its\napplication in latency-sensitive scenarios. To address this limitation, we\npropose a highly parallel algorithm based on a block coordinate descent\nframework. Our key innovation lies in updating the precoding matrix via block\ncoordinate gradient descent, which avoids matrix inversions and relies solely\non matrix multiplications, making it exceptionally amenable to GPU\nacceleration. We prove that the proposed algorithm converges to a stationary\npoint of the WSR maximization problem. Furthermore, we introduce a two-stage\nwarm-start strategy grounded in the sum mean-square error (MSE) minimization\nproblem to accelerate convergence. We refer to our method as the Accelerated\nMixed weighted-unweighted sum-MSE minimization (A-MMMSE) algorithm. Simulation\nresults demonstrate that A-MMMSE matches the WSR performance of both\nconventional WMMSE and its enhanced variant, reduced-WMMSE, while achieving a\nsubstantial reduction in computational time across diverse system\nconfigurations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5757\u5750\u6807\u4e0b\u964d\u6846\u67b6\u7684\u9ad8\u5e76\u884c\u9884\u7f16\u7801\u7b97\u6cd5A-MMMSE\uff0c\u901a\u8fc7\u907f\u514d\u77e9\u9635\u6c42\u9006\u4ec5\u4f7f\u7528\u77e9\u9635\u4e58\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u5e76\u9002\u5408GPU\u52a0\u901f\uff0c\u5728\u4fdd\u6301\u52a0\u6743\u548c\u901f\u7387\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u8ba1\u7b97\u65f6\u95f4\u3002", "motivation": "\u4f20\u7edfWMMSE\u7b97\u6cd5\u7531\u4e8e\u77e9\u9635\u6c42\u9006\u5bfc\u81f4\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff08\u4e0e\u57fa\u7ad9\u5929\u7ebf\u6570\u7acb\u65b9\u76f8\u5173\uff09\uff0c\u96be\u4ee5\u5e94\u7528\u4e8e\u5ef6\u8fdf\u654f\u611f\u573a\u666f\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684\u8ba1\u7b97\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u5757\u5750\u6807\u68af\u5ea6\u4e0b\u964d\u66f4\u65b0\u9884\u7f16\u7801\u77e9\u9635\uff0c\u907f\u514d\u77e9\u9635\u6c42\u9006\u4ec5\u4f7f\u7528\u77e9\u9635\u4e58\u6cd5\uff1b\u5f15\u5165\u57fa\u4e8e\u548c\u5747\u65b9\u8bef\u5dee\u6700\u5c0f\u5316\u95ee\u9898\u7684\u4e24\u9636\u6bb5\u70ed\u542f\u52a8\u7b56\u7565\u52a0\u901f\u6536\u655b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660eA-MMMSE\u5728\u52a0\u6743\u548c\u901f\u7387\u6027\u80fd\u4e0a\u4e0e\u4f20\u7edfWMMSE\u53ca\u5176\u589e\u5f3a\u53d8\u4f53reduced-WMMSE\u76f8\u5f53\uff0c\u4f46\u5728\u5404\u79cd\u7cfb\u7edf\u914d\u7f6e\u4e0b\u8ba1\u7b97\u65f6\u95f4\u663e\u8457\u51cf\u5c11\u3002", "conclusion": "A-MMMSE\u7b97\u6cd5\u901a\u8fc7\u907f\u514d\u77e9\u9635\u6c42\u9006\u548c\u5229\u7528GPU\u5e76\u884c\u6027\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u63d0\u5347\u8ba1\u7b97\u6548\u7387\uff0c\u9002\u7528\u4e8e\u5ef6\u8fdf\u654f\u611f\u7684\u591a\u7528\u6237MIMO\u7cfb\u7edf\u3002"}}
{"id": "2510.20515", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.20515", "abs": "https://arxiv.org/abs/2510.20515", "authors": ["Xu Hu", "Bin Lin", "Xiao Lu", "Ping Wang", "Nan Cheng", "Zhisheng Yin", "Weihua Zhuang"], "title": "Performance Analysis of End-to-End LEO Satellite-Aided Shore-to-Ship Communications: A Stochastic Geometry Approach", "comment": null, "summary": "Low Earth orbit (LEO) satellite networks have shown strategic superiority in\nmaritime communications, assisting in establishing signal transmissions from\nshore to ship through space-based links. Traditional performance modeling based\non multiple circular orbits is challenging to characterize large-scale LEO\nsatellite constellations, thus requiring a tractable approach to accurately\nevaluate the network performance. In this paper, we propose a theoretical\nframework for an LEO satellite-aided shore-to-ship communication network\n(LEO-SSCN), where LEO satellites are distributed as a binomial point process\n(BPP) on a specific spherical surface. The framework aims to obtain the\nend-to-end transmission performance by considering signal transmissions through\neither a marine link or a space link subject to Rician or Shadowed Rician\nfading, respectively. Due to the indeterminate position of the serving\nsatellite, accurately modeling the distance from the serving satellite to the\ndestination ship becomes intractable. To address this issue, we propose a\ndistance approximation approach. Then, by approximation and incorporating a\nthreshold-based communication scheme, we leverage stochastic geometry to derive\nanalytical expressions of end-to-end transmission success probability and\naverage transmission rate capacity. Extensive numerical results verify the\naccuracy of the analysis and demonstrate the effect of key parameters on the\nperformance of LEO-SSCN.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u57fa\u4e8e\u4e8c\u9879\u70b9\u8fc7\u7a0b\u7684LEO\u536b\u661f\u8f85\u52a9\u5cb8\u5230\u8239\u901a\u4fe1\u7f51\u7edc\u7406\u8bba\u6846\u67b6\uff0c\u901a\u8fc7\u8ddd\u79bb\u8fd1\u4f3c\u548c\u968f\u673a\u51e0\u4f55\u65b9\u6cd5\u5206\u6790\u7aef\u5230\u7aef\u4f20\u8f93\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u591a\u5706\u8f68\u9053\u7684\u6027\u80fd\u5efa\u6a21\u96be\u4ee5\u8868\u5f81\u5927\u89c4\u6a21LEO\u536b\u661f\u661f\u5ea7\uff0c\u9700\u8981\u4e00\u79cd\u53ef\u5904\u7406\u7684\u65b9\u6cd5\u6765\u51c6\u786e\u8bc4\u4f30\u7f51\u7edc\u6027\u80fd\u3002", "method": "\u5c06LEO\u536b\u661f\u5efa\u6a21\u4e3a\u7403\u9762\u4e0a\u7684\u4e8c\u9879\u70b9\u8fc7\u7a0b\uff0c\u8003\u8651\u6d77\u6d0b\u94fe\u8def\u548c\u7a7a\u95f4\u94fe\u8def\u7684Rician/Shadowed Rician\u8870\u843d\uff0c\u63d0\u51fa\u8ddd\u79bb\u8fd1\u4f3c\u65b9\u6cd5\u5e76\u7ed3\u5408\u9608\u503c\u901a\u4fe1\u65b9\u6848\uff0c\u4f7f\u7528\u968f\u673a\u51e0\u4f55\u63a8\u5bfc\u7aef\u5230\u7aef\u4f20\u8f93\u6027\u80fd\u3002", "result": "\u63a8\u5bfc\u51fa\u4e86\u7aef\u5230\u7aef\u4f20\u8f93\u6210\u529f\u6982\u7387\u548c\u5e73\u5747\u4f20\u8f93\u901f\u7387\u5bb9\u91cf\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5206\u6790\u7684\u51c6\u786e\u6027\u5e76\u5c55\u793a\u4e86\u5173\u952e\u53c2\u6570\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7406\u8bba\u6846\u67b6\u4e3aLEO\u536b\u661f\u8f85\u52a9\u5cb8\u5230\u8239\u901a\u4fe1\u7f51\u7edc\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6027\u80fd\u8bc4\u4f30\u5de5\u5177\uff0c\u80fd\u591f\u51c6\u786e\u5206\u6790\u5927\u89c4\u6a21\u661f\u5ea7\u7684\u4f20\u8f93\u6027\u80fd\u3002"}}

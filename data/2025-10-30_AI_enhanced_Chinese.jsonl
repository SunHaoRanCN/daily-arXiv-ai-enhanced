{"id": "2510.25048", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2510.25048", "abs": "https://arxiv.org/abs/2510.25048", "authors": ["Ivan Vican", "Hugo De Moraes", "Chongjun Liao", "Nathnael H. Tsegaye", "William O'Gara", "Jasper Inamoto", "Denis G. Pelli"], "title": "EasyEyes: Online hearing research using speakers calibrated by phones", "comment": null, "summary": "Hearing research requires a calibrated sound source, traditionally as lab\nequipment. Online research is quicker and more inclusive, but most participants\nlack calibration equipment and their sound sources are uncalibrated and\ndiverse. This article explains how the open-source EasyEyes.app calibrates\nloudspeakers online. A library of smartphone-microphone profiles allows\nEasyEyes to use the participant's phone to calibrate their computer's\nloudspeaker in three minutes. Participants select their phone model, which is\nverified by screen size. Calibration employs the Novak et al. nonsynchronous\nmaximum-length-sequence (MLS) algorithm. The computer's loudspeaker is\ncorrected by convolving its input with the inverse of its impulse response.\nResearchers can contribute to the open-access library by calibrating phones\nwith a measurement microphone. In the library, each profile is linked back to\nthe profile used to produce it, back to the manufacturer profile of a\nmeasurement microphone. Correction accuracy is such that playing the\nflat-spectrum MLS through the corrected loudspeaker produces a nearly flat\nspectrum, with standard deviation less than 3 dB. A survey shows that a library\nof 94 phone models from major brands will support most participants in the USA\n(87%) and UK (80%). This method facilitates efficient and inclusive online\nhearing research.", "AI": {"tldr": "EasyEyes.app\u5f00\u53d1\u4e86\u4e00\u79cd\u5728\u7ebf\u6821\u51c6\u626c\u58f0\u5668\u7684\u65b9\u6cd5\uff0c\u4f7f\u7528\u667a\u80fd\u624b\u673a\u9ea6\u514b\u98ce\u57283\u5206\u949f\u5185\u6821\u51c6\u8ba1\u7b97\u673a\u626c\u58f0\u5668\uff0c\u652f\u6301\u5728\u7ebf\u542c\u529b\u7814\u7a76\u3002", "motivation": "\u5728\u7ebf\u542c\u529b\u7814\u7a76\u9700\u8981\u6821\u51c6\u7684\u58f0\u6e90\uff0c\u4f46\u5927\u591a\u6570\u53c2\u4e0e\u8005\u7f3a\u4e4f\u4e13\u4e1a\u6821\u51c6\u8bbe\u5907\uff0c\u4e14\u5176\u58f0\u6e90\u672a\u6821\u51c6\u4e14\u591a\u6837\u5316\uff0c\u963b\u788d\u4e86\u9ad8\u6548\u548c\u5305\u5bb9\u6027\u7684\u5728\u7ebf\u7814\u7a76\u3002", "method": "\u5229\u7528\u667a\u80fd\u624b\u673a\u9ea6\u514b\u98ce\u6863\u6848\u5e93\uff0c\u901a\u8fc7Novak\u7b49\u4eba\u7684\u975e\u540c\u6b65\u6700\u5927\u957f\u5ea6\u5e8f\u5217\u7b97\u6cd5\u6821\u51c6\u8ba1\u7b97\u673a\u626c\u58f0\u5668\uff0c\u901a\u8fc7\u5377\u79ef\u8f93\u5165\u4e0e\u8109\u51b2\u54cd\u5e94\u7684\u9006\u6765\u6821\u6b63\u626c\u58f0\u5668\u3002", "result": "\u6821\u6b63\u540e\u7684\u626c\u58f0\u5668\u64ad\u653e\u5e73\u5766\u9891\u8c31MLS\u65f6\u4ea7\u751f\u8fd1\u4e4e\u5e73\u5766\u7684\u9891\u8c31\uff0c\u6807\u51c6\u504f\u5dee\u5c0f\u4e8e3 dB\u300294\u4e2a\u624b\u673a\u578b\u53f7\u7684\u6863\u6848\u5e93\u53ef\u652f\u6301\u7f8e\u56fd87%\u548c\u82f1\u56fd80%\u7684\u53c2\u4e0e\u8005\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u6548\u548c\u5305\u5bb9\u7684\u5728\u7ebf\u542c\u529b\u7814\u7a76\uff0c\u4f7f\u7f3a\u4e4f\u4e13\u4e1a\u8bbe\u5907\u7684\u53c2\u4e0e\u8005\u4e5f\u80fd\u53c2\u4e0e\u6821\u51c6\u7684\u542c\u529b\u5b9e\u9a8c\u3002"}}
{"id": "2510.25182", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.25182", "abs": "https://arxiv.org/abs/2510.25182", "authors": ["Phurich Saengthong", "Tomoya Nishida", "Kota Dohi", "Natsuo Yamashita", "Yohei Kawaguchi"], "title": "Retaining Mixture Representations for Domain Generalized Anomalous Sound Detection", "comment": "Submitted to ICASSP 2026", "summary": "Anomalous sound detection (ASD) in the wild requires robustness to\ndistribution shifts such as unseen low-SNR input mixtures of machine and noise\ntypes. State-of-the-art systems extract embeddings from an adapted audio\nencoder and detect anomalies via nearest-neighbor search, but fine tuning on\nnoisy machine sounds often acts like a denoising objective, suppressing noise\nand reducing generalization under mismatched mixtures or inconsistent labeling.\nTraining-free systems with frozen self-supervised learning (SSL) encoders avoid\nthis issue and show strong first-shot generalization, yet their performance\ndrops when mixture embeddings deviate from clean-source embeddings. We propose\nto improve SSL backbones with a retain-not-denoise strategy that better\npreserves information from mixed sound sources. The approach combines a\nmulti-label audio tagging loss with a mixture alignment loss that aligns\nstudent mixture embeddings to convex teacher embeddings of clean and noise\ninputs. Controlled experiments on stationary, non-stationary, and mismatched\nnoise subsets demonstrate improved robustness under distribution shifts,\nnarrowing the gap toward oracle mixture representations.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\"\u4fdd\u7559\u800c\u975e\u53bb\u566a\"\u7b56\u7565\u6765\u6539\u8fdb\u81ea\u76d1\u7763\u5b66\u4e60\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u591a\u6807\u7b7e\u97f3\u9891\u5206\u7c7b\u635f\u5931\u548c\u6df7\u5408\u5bf9\u9f50\u635f\u5931\uff0c\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u63d0\u9ad8\u5f02\u5e38\u58f0\u97f3\u68c0\u6d4b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u566a\u58f0\u73af\u5883\u4e0b\u8bad\u7ec3\u65f6\u5f80\u5f80\u50cf\u53bb\u566a\u4efb\u52a1\uff0c\u6291\u5236\u566a\u58f0\u4fe1\u606f\u5bfc\u81f4\u6cdb\u5316\u80fd\u529b\u4e0b\u964d\uff1b\u800c\u51bb\u7ed3\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u7f16\u7801\u5668\u867d\u7136\u907f\u514d\u6b64\u95ee\u9898\uff0c\u4f46\u5728\u6df7\u5408\u58f0\u97f3\u5d4c\u5165\u504f\u79bb\u5e72\u51c0\u6e90\u5d4c\u5165\u65f6\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u91c7\u7528\u4fdd\u7559\u800c\u975e\u53bb\u566a\u7b56\u7565\uff0c\u7ed3\u5408\u591a\u6807\u7b7e\u97f3\u9891\u5206\u7c7b\u635f\u5931\u548c\u6df7\u5408\u5bf9\u9f50\u635f\u5931\uff0c\u5c06\u5b66\u751f\u6df7\u5408\u5d4c\u5165\u4e0e\u5e72\u51c0\u548c\u566a\u58f0\u8f93\u5165\u7684\u6559\u5e08\u5d4c\u5165\u51f8\u7ec4\u5408\u5bf9\u9f50\u3002", "result": "\u5728\u9759\u6001\u3001\u975e\u9759\u6001\u548c\u4e0d\u5339\u914d\u566a\u58f0\u5b50\u96c6\u4e0a\u7684\u63a7\u5236\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u5206\u5e03\u504f\u79fb\u4e0b\u63d0\u9ad8\u4e86\u9c81\u68d2\u6027\uff0c\u7f29\u5c0f\u4e86\u4e0e\u7406\u60f3\u6df7\u5408\u8868\u793a\u7684\u5dee\u8ddd\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b56\u7565\u80fd\u66f4\u597d\u5730\u4fdd\u7559\u6df7\u5408\u58f0\u6e90\u4fe1\u606f\uff0c\u5728\u5f02\u5e38\u58f0\u97f3\u68c0\u6d4b\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u6539\u8fdb\u7684\u5206\u5e03\u504f\u79fb\u9c81\u68d2\u6027\u3002"}}
{"id": "2510.25235", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.25235", "abs": "https://arxiv.org/abs/2510.25235", "authors": ["Toshio Irino", "Ayako Yamamoto", "Fuki Miyazaki"], "title": "Separating peripheral and higher-level effects on speech intelligibility using a hearing loss simulator and an objective intelligibility measure", "comment": "This is a manuscript that was submitted to Trends in Hearing on\n  October 29, 2025", "summary": "This paper presents a new method for separating the effects of peripheral\nhearing loss (HL) and higher-level processes on speech intelligibility (SI). In\na previous study, we conducted an SI experiment with 14 older adult (OA)\nlisteners, using speech-in-noise sounds that were either processed with an\nideal ratio mask (IRM) enhancement technique or left unprocessed. The current\nstudy involved an SI experiment with 15 young, normal-hearing (YNH) listeners.\nThis experiment used simulated HL sounds processed with the WHIS simulator that\nreflected the hearing level of a specific OA from the previous study. The\nresults showed that the target OA's SI scores were higher than the average YNH\nscores. This implies that the target OA's higher-level processes may be more\neffective than those of the average YNH. To understand the characteristics of\nother OAs, we used the GESI objective intelligibility measure to predict SI.\nFirst, we confirmed that GESI could fairly accurately predict the SI scores for\nboth the YNH and OA listeners. Next, we predicted the SI scores of the 14 OA\nlisteners using the parameters estimated in the YNH experiment. The results\nshowed that some OAs had higher SI scores than the average YNH, while one OA\nhad lower scores. These differences in SI scores may reflect variations in the\nefficiency of higher-level processes.These results imply that WHIS and GESI\ncould facilitate contrastive experiments between YNH and OA listeners,\nregardless of hearing level. This would allow us to study the effects of\nhigher-level processes in OA listeners individually.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u79bb\u5916\u5468\u542c\u529b\u635f\u5931\u548c\u9ad8\u7ea7\u5904\u7406\u8fc7\u7a0b\u5bf9\u8a00\u8bed\u53ef\u61c2\u5ea6\u5f71\u54cd\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5e74\u8f7b\u6b63\u5e38\u542c\u529b\u8005\u548c\u8001\u5e74\u542c\u529b\u635f\u5931\u8005\u7684\u5b9e\u9a8c\u7ed3\u679c\uff0c\u53d1\u73b0WHIS\u6a21\u62df\u5668\u548cGESI\u5ba2\u89c2\u6d4b\u91cf\u5de5\u5177\u53ef\u4ee5\u6709\u6548\u7814\u7a76\u4e2a\u4f53\u5dee\u5f02\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u533a\u5206\u5916\u5468\u542c\u529b\u635f\u5931\u548c\u9ad8\u7ea7\u8ba4\u77e5\u5904\u7406\u5bf9\u8001\u5e74\u4eba\u8a00\u8bed\u53ef\u61c2\u5ea6\u7684\u76f8\u5bf9\u8d21\u732e\uff0c\u8fd9\u5bf9\u4e8e\u7406\u89e3\u8001\u5e74\u4eba\u542c\u529b\u969c\u788d\u7684\u672c\u8d28\u548c\u6539\u8fdb\u52a9\u542c\u6280\u672f\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002", "method": "\u91c7\u7528\u5bf9\u6bd4\u5b9e\u9a8c\u65b9\u6cd5\uff1a\u5bf9\u5e74\u8f7b\u6b63\u5e38\u542c\u529b\u8005\u4f7f\u7528WHIS\u6a21\u62df\u5668\u6a21\u62df\u8001\u5e74\u542c\u529b\u635f\u5931\uff0c\u5bf9\u8001\u5e74\u542c\u529b\u635f\u5931\u8005\u8fdb\u884c\u5b9e\u9645\u6d4b\u8bd5\uff0c\u5e76\u4f7f\u7528GESI\u5ba2\u89c2\u6d4b\u91cf\u5de5\u5177\u9884\u6d4b\u8a00\u8bed\u53ef\u61c2\u5ea6\u5f97\u5206\u3002", "result": "\u7ed3\u679c\u663e\u793a\u90e8\u5206\u8001\u5e74\u542c\u529b\u635f\u5931\u8005\u7684\u8a00\u8bed\u53ef\u61c2\u5ea6\u5f97\u5206\u9ad8\u4e8e\u5e74\u8f7b\u6b63\u5e38\u542c\u529b\u8005\u5e73\u5747\u503c\uff0c\u8868\u660e\u5176\u9ad8\u7ea7\u5904\u7406\u8fc7\u7a0b\u53ef\u80fd\u66f4\u6709\u6548\uff1bGESI\u80fd\u591f\u8f83\u51c6\u786e\u5730\u9884\u6d4b\u4e24\u7ec4\u4eba\u7fa4\u7684\u5f97\u5206\u3002", "conclusion": "WHIS\u548cGESI\u5de5\u5177\u80fd\u591f\u4fc3\u8fdb\u4e0d\u540c\u542c\u529b\u6c34\u5e73\u4eba\u7fa4\u7684\u5bf9\u6bd4\u5b9e\u9a8c\uff0c\u6709\u52a9\u4e8e\u5355\u72ec\u7814\u7a76\u8001\u5e74\u542c\u529b\u635f\u5931\u8005\u9ad8\u7ea7\u5904\u7406\u8fc7\u7a0b\u7684\u5f71\u54cd\uff0c\u4e3a\u4e2a\u6027\u5316\u542c\u529b\u5eb7\u590d\u63d0\u4f9b\u652f\u6301\u3002"}}
{"id": "2510.25566", "categories": ["eess.AS", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25566", "abs": "https://arxiv.org/abs/2510.25566", "authors": ["Diego Torres", "Axel Roebel", "Nicolas Obin"], "title": "PitchFlower: A flow-based neural audio codec with pitch controllability", "comment": "5 pages, 5 figures", "summary": "We present PitchFlower, a flow-based neural audio codec with explicit pitch\ncontrollability. Our approach enforces disentanglement through a simple\nperturbation: during training, F0 contours are flattened and randomly shifted,\nwhile the true F0 is provided as conditioning. A vector-quantization bottleneck\nprevents pitch recovery, and a flow-based decoder generates high quality audio.\nExperiments show that PitchFlower achieves more accurate pitch control than\nWORLD at much higher audio quality, and outperforms SiFiGAN in controllability\nwhile maintaining comparable quality. Beyond pitch, this framework provides a\nsimple and extensible path toward disentangling other speech attributes.", "AI": {"tldr": "PitchFlower\u662f\u4e00\u4e2a\u57fa\u4e8e\u6d41\u7684\u795e\u7ecf\u97f3\u9891\u7f16\u89e3\u7801\u5668\uff0c\u5177\u6709\u660e\u786e\u7684\u97f3\u9ad8\u53ef\u63a7\u6027\uff0c\u901a\u8fc7F0\u8f6e\u5ed3\u5e73\u5766\u5316\u548c\u968f\u673a\u504f\u79fb\u6765\u5b9e\u73b0\u97f3\u9ad8\u89e3\u8026\uff0c\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u97f3\u9891\u7684\u540c\u65f6\u5b9e\u73b0\u6bd4WORLD\u66f4\u51c6\u786e\u7684\u97f3\u9ad8\u63a7\u5236\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u660e\u786e\u63a7\u5236\u97f3\u9ad8\u540c\u65f6\u4fdd\u6301\u9ad8\u8d28\u91cf\u97f3\u9891\u7684\u795e\u7ecf\u97f3\u9891\u7f16\u89e3\u7801\u5668\uff0c\u4e3a\u89e3\u8026\u5176\u4ed6\u8bed\u97f3\u5c5e\u6027\u63d0\u4f9b\u7b80\u5355\u53ef\u6269\u5c55\u7684\u6846\u67b6\u3002", "method": "\u5728\u8bad\u7ec3\u671f\u95f4\u5bf9F0\u8f6e\u5ed3\u8fdb\u884c\u5e73\u5766\u5316\u548c\u968f\u673a\u504f\u79fb\uff0c\u540c\u65f6\u5c06\u771f\u5b9eF0\u4f5c\u4e3a\u6761\u4ef6\u8f93\u5165\uff1b\u4f7f\u7528\u5411\u91cf\u91cf\u5316\u74f6\u9888\u9632\u6b62\u97f3\u9ad8\u6062\u590d\uff1b\u91c7\u7528\u57fa\u4e8e\u6d41\u7684\u89e3\u7801\u5668\u751f\u6210\u9ad8\u8d28\u91cf\u97f3\u9891\u3002", "result": "PitchFlower\u5728\u97f3\u9ad8\u63a7\u5236\u51c6\u786e\u6027\u4e0a\u4f18\u4e8eWORLD\uff0c\u97f3\u9891\u8d28\u91cf\u66f4\u9ad8\uff1b\u5728\u53ef\u63a7\u6027\u4e0a\u4f18\u4e8eSiFiGAN\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u97f3\u9891\u8d28\u91cf\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e0d\u4ec5\u5b9e\u73b0\u4e86\u97f3\u9ad8\u7684\u6709\u6548\u89e3\u8026\u548c\u63a7\u5236\uff0c\u8fd8\u4e3a\u89e3\u8026\u5176\u4ed6\u8bed\u97f3\u5c5e\u6027\u63d0\u4f9b\u4e86\u7b80\u5355\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2510.24722", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24722", "abs": "https://arxiv.org/abs/2510.24722", "authors": ["Narges Rashvand", "Kenneth Witham", "Gabriel Maldonado", "Vinit Katariya", "Aly Sultan", "Gunar Schirner", "Hamed Tabkhi"], "title": "Distributed learning for automatic modulation recognition in bandwidth-limited networks", "comment": null, "summary": "Automatic Modulation Recognition (AMR) is critical in identifying various\nmodulation types in wireless communication systems. Recent advancements in deep\nlearning have facilitated the integration of algorithms into AMR techniques.\nHowever, this integration typically follows a centralized approach that\nnecessitates collecting and processing all training data on high-powered\ncomputing devices, which may prove impractical for bandwidth-limited wireless\nnetworks. In response to this challenge, this study introduces two methods for\ndistributed learning-based AMR on the collaboration of multiple receivers to\nperform AMR tasks. The TeMuRAMRD 2023 dataset is employed to support this\ninvestigation, uniquely suited for multi-receiver AMR tasks. Within this\ndistributed sensing environment, multiple receivers collaborate in identifying\nmodulation types from the same RF signal, each possessing a partial perspective\nof the overall environment. Experimental results demonstrate that the\ncentralized-based AMR, with six receivers, attains an impressive accuracy rate\nof 91%, while individual receivers exhibit a notably lower accuracy, at around\n41%. Nonetheless, the two proposed decentralized learning-based AMR methods\nexhibit noteworthy enhancements. Based on consensus voting among six receivers,\nthe initial method achieves a marginally lower accuracy. It achieves this while\nsubstantially reducing the bandwidth demands to a 1/256th of the centralized\nmodel. With the second distributed method, each receiver shares its feature\nmap, subsequently aggregated by a central node. This approach also accompanies\na substantial bandwidth reduction of 1/8 compared to the centralized approach.\nThese findings highlight the capacity of distributed AMR to significantly\nenhance accuracy while effectively addressing the constraints of\nbandwidth-limited wireless networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e24\u79cd\u57fa\u4e8e\u5206\u5e03\u5f0f\u5b66\u4e60\u7684\u81ea\u52a8\u8c03\u5236\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u63a5\u6536\u5668\u534f\u4f5c\u5728\u5e26\u5bbd\u53d7\u9650\u7684\u65e0\u7ebf\u7f51\u7edc\u4e2d\u5b9e\u73b0\u9ad8\u6548\u8c03\u5236\u8bc6\u522b\u3002", "motivation": "\u4f20\u7edf\u96c6\u4e2d\u5f0fAMR\u65b9\u6cd5\u9700\u8981\u5c06\u6240\u6709\u8bad\u7ec3\u6570\u636e\u6536\u96c6\u5230\u9ad8\u6027\u80fd\u8ba1\u7b97\u8bbe\u5907\u4e0a\u5904\u7406\uff0c\u8fd9\u5728\u5e26\u5bbd\u53d7\u9650\u7684\u65e0\u7ebf\u7f51\u7edc\u4e2d\u4e0d\u5b9e\u7528\u3002", "method": "1. \u57fa\u4e8e\u5171\u8bc6\u6295\u7968\u7684\u5206\u5e03\u5f0f\u65b9\u6cd5\uff1a\u516d\u4e2a\u63a5\u6536\u5668\u6295\u7968\u51b3\u5b9a\u8c03\u5236\u7c7b\u578b\uff0c\u5e26\u5bbd\u9700\u6c42\u964d\u81f3\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u76841/256\uff1b2. \u7279\u5f81\u56fe\u5171\u4eab\u65b9\u6cd5\uff1a\u5404\u63a5\u6536\u5668\u5171\u4eab\u7279\u5f81\u56fe\uff0c\u7531\u4e2d\u5fc3\u8282\u70b9\u805a\u5408\uff0c\u5e26\u5bbd\u9700\u6c42\u964d\u81f3\u96c6\u4e2d\u5f0f\u65b9\u6cd5\u76841/8\u3002", "result": "\u96c6\u4e2d\u5f0fAMR\uff086\u4e2a\u63a5\u6536\u5668\uff09\u51c6\u786e\u7387\u8fbe91%\uff0c\u5355\u4e2a\u63a5\u6536\u5668\u51c6\u786e\u7387\u4ec541%\u3002\u4e24\u79cd\u5206\u5e03\u5f0f\u65b9\u6cd5\u5728\u663e\u8457\u964d\u4f4e\u5e26\u5bbd\u9700\u6c42\u7684\u540c\u65f6\u63d0\u5347\u4e86\u51c6\u786e\u7387\u3002", "conclusion": "\u5206\u5e03\u5f0fAMR\u65b9\u6cd5\u80fd\u591f\u5728\u6709\u6548\u5e94\u5bf9\u5e26\u5bbd\u53d7\u9650\u65e0\u7ebf\u7f51\u7edc\u7ea6\u675f\u7684\u540c\u65f6\uff0c\u663e\u8457\u63d0\u5347\u8c03\u5236\u8bc6\u522b\u51c6\u786e\u7387\u3002"}}
{"id": "2510.24852", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2510.24852", "abs": "https://arxiv.org/abs/2510.24852", "authors": ["Yassine El Kheir", "Fabian Ritter-Guttierez", "Arnab Das", "Tim Polzehl", "Sebastian M\u00f6ller"], "title": "A Parameter-Efficient Multi-Scale Convolutional Adapter for Synthetic Speech Detection", "comment": "6 pages", "summary": "Recent synthetic speech detection models typically adapt a pre-trained SSL\nmodel via finetuning, which is computationally demanding. Parameter-Efficient\nFine-Tuning (PEFT) offers an alternative. However, existing methods lack the\nspecific inductive biases required to model the multi-scale temporal artifacts\ncharacteristic of spoofed audio. This paper introduces the Multi-Scale\nConvolutional Adapter (MultiConvAdapter), a parameter-efficient architecture\ndesigned to address this limitation. MultiConvAdapter integrates parallel\nconvolutional modules within the SSL encoder, facilitating the simultaneous\nlearning of discriminative features across multiple temporal resolutions,\ncapturing both short-term artifacts and long-term distortions. With only\n$3.17$M trainable parameters ($1\\%$ of the SSL backbone), MultiConvAdapter\nsubstantially reduces the computational burden of adaptation. Evaluations on\nfive public datasets, demonstrate that MultiConvAdapter achieves superior\nperformance compared to full fine-tuning and established PEFT methods.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aMultiConvAdapter\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u67b6\u6784\uff0c\u7528\u4e8e\u5408\u6210\u8bed\u97f3\u68c0\u6d4b\uff0c\u901a\u8fc7\u96c6\u6210\u5e76\u884c\u5377\u79ef\u6a21\u5757\u6765\u540c\u65f6\u5b66\u4e60\u591a\u65f6\u95f4\u5206\u8fa8\u7387\u7684\u7279\u5f81\uff0c\u4ec5\u97001%\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u5c31\u80fd\u8fbe\u5230\u4f18\u4e8e\u5b8c\u5168\u5fae\u8c03\u548c\u5176\u4ed6PEFT\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u4f2a\u9020\u97f3\u9891\u4e2d\u591a\u5c3a\u5ea6\u65f6\u95f4\u4f2a\u5f71\u5efa\u6a21\u6240\u9700\u7684\u7279\u5b9a\u5f52\u7eb3\u504f\u7f6e\uff0c\u800c\u5b8c\u5168\u5fae\u8c03\u9884\u8bad\u7ec3SSL\u6a21\u578b\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u63d0\u51faMultiConvAdapter\u67b6\u6784\uff0c\u5728SSL\u7f16\u7801\u5668\u4e2d\u96c6\u6210\u5e76\u884c\u5377\u79ef\u6a21\u5757\uff0c\u652f\u6301\u8de8\u591a\u4e2a\u65f6\u95f4\u5206\u8fa8\u7387\u540c\u65f6\u5b66\u4e60\u5224\u522b\u6027\u7279\u5f81\uff0c\u80fd\u591f\u6355\u83b7\u77ed\u671f\u4f2a\u5f71\u548c\u957f\u671f\u5931\u771f\u3002", "result": "\u4ec5\u4f7f\u7528317\u4e07\u4e2a\u53ef\u8bad\u7ec3\u53c2\u6570\uff08SSL\u9aa8\u5e72\u7f51\u7edc\u76841%\uff09\uff0cMultiConvAdapter\u663e\u8457\u964d\u4f4e\u4e86\u9002\u5e94\u8ba1\u7b97\u8d1f\u62c5\uff0c\u5728\u4e94\u4e2a\u516c\u5171\u6570\u636e\u96c6\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\u5176\u6027\u80fd\u4f18\u4e8e\u5b8c\u5168\u5fae\u8c03\u548c\u73b0\u6709PEFT\u65b9\u6cd5\u3002", "conclusion": "MultiConvAdapter\u662f\u4e00\u79cd\u6709\u6548\u7684\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u4ee5\u6781\u5c11\u7684\u53ef\u8bad\u7ec3\u53c2\u6570\u5b9e\u73b0\u4f18\u5f02\u7684\u5408\u6210\u8bed\u97f3\u68c0\u6d4b\u6027\u80fd\u3002"}}
{"id": "2510.25577", "categories": ["eess.AS", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2510.25577", "abs": "https://arxiv.org/abs/2510.25577", "authors": ["Harm Lameris", "Shree Harsha Bokkahalli Satish", "Joakim Gustafson", "\u00c9va Sz\u00e9kely"], "title": "Lost in Phonation: Voice Quality Variation as an Evaluation Dimension for Speech Foundation Models", "comment": "8 pages, 3 figures, 4 tables, submitted to LREC 2026", "summary": "Recent advances in speech foundation models (SFMs) have enabled the direct\nprocessing of spoken language from raw audio, bypassing intermediate textual\nrepresentations. This capability allows SFMs to be exposed to, and potentially\nrespond to, rich paralinguistic variations embedded in the input speech signal.\nOne under-explored dimension of paralinguistic variation is voice quality,\nencompassing phonation types such as creaky and breathy voice. These phonation\ntypes are known to influence how listeners infer affective state, stance and\nsocial meaning in speech. Existing benchmarks for speech understanding largely\nrely on multiple-choice question answering (MCQA) formats, which are prone to\nfailure and therefore unreliable in capturing the nuanced ways paralinguistic\nfeatures influence model behaviour. In this paper, we probe SFMs through\nopen-ended generation tasks and speech emotion recognition, evaluating whether\nmodel behaviours are consistent across different phonation inputs. We introduce\na new parallel dataset featuring synthesized modifications to voice quality,\ndesigned to evaluate SFM responses to creaky and breathy voice. Our work\nprovides the first examination of SFM sensitivity to these particular\nnon-lexical aspects of speech perception.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u8bed\u97f3\u57fa\u7840\u6a21\u578b\u5bf9\u8bed\u97f3\u8d28\u91cf\uff08\u5982\u560e\u5431\u58f0\u548c\u547c\u5438\u58f0\uff09\u7684\u654f\u611f\u6027\uff0c\u901a\u8fc7\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\u548c\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u6765\u8bc4\u4f30\u6a21\u578b\u884c\u4e3a\u5728\u4e0d\u540c\u53d1\u58f0\u8f93\u5165\u4e0b\u7684\u4e00\u81f4\u6027\u3002", "motivation": "\u73b0\u6709\u8bed\u97f3\u7406\u89e3\u57fa\u51c6\u4e3b\u8981\u4f9d\u8d56\u591a\u9879\u9009\u62e9\u9898\u56de\u7b54\u683c\u5f0f\uff0c\u65e0\u6cd5\u53ef\u9760\u6355\u6349\u526f\u8bed\u8a00\u7279\u5f81\u5bf9\u6a21\u578b\u884c\u4e3a\u7684\u7ec6\u5fae\u5f71\u54cd\uff0c\u56e0\u6b64\u9700\u8981\u63a2\u7d22\u8bed\u97f3\u57fa\u7840\u6a21\u578b\u5bf9\u8bed\u97f3\u8d28\u91cf\u7b49\u526f\u8bed\u8a00\u53d8\u5316\u7684\u654f\u611f\u6027\u3002", "method": "\u901a\u8fc7\u5f00\u653e\u5f0f\u751f\u6210\u4efb\u52a1\u548c\u8bed\u97f3\u60c5\u611f\u8bc6\u522b\u6765\u63a2\u6d4b\u8bed\u97f3\u57fa\u7840\u6a21\u578b\uff0c\u5e76\u5f15\u5165\u4e00\u4e2a\u5305\u542b\u5408\u6210\u8bed\u97f3\u8d28\u91cf\u4fee\u6539\u7684\u5e73\u884c\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bc4\u4f30\u6a21\u578b\u5bf9\u560e\u5431\u58f0\u548c\u547c\u5438\u58f0\u7684\u54cd\u5e94\u3002", "result": "\u7814\u7a76\u9996\u6b21\u68c0\u9a8c\u4e86\u8bed\u97f3\u57fa\u7840\u6a21\u578b\u5bf9\u8fd9\u4e9b\u7279\u5b9a\u975e\u8bcd\u6c47\u6027\u8bed\u97f3\u611f\u77e5\u65b9\u9762\u7684\u654f\u611f\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u7406\u89e3\u8bed\u97f3\u57fa\u7840\u6a21\u578b\u5982\u4f55\u5904\u7406\u8bed\u97f3\u4e2d\u7684\u526f\u8bed\u8a00\u7279\u5f81\u63d0\u4f9b\u4e86\u65b0\u7684\u8bc4\u4f30\u65b9\u6cd5\u548c\u6570\u636e\u96c6\u3002"}}
{"id": "2510.24725", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24725", "abs": "https://arxiv.org/abs/2510.24725", "authors": ["Masoud Kaveh", "Farshad Rostami Ghadi", "Riku Jantti", "Kai-Kit Wong", "F. Javier Lopez-Martinez"], "title": "Ambient Backscatter Communication Assisted by Fluid Reconfigurable Intelligent Surfaces", "comment": null, "summary": "This paper investigates the integration of a fluid reconfigurable intelligent\nsurface (FRIS) into ambient backscatter communication (AmBC) systems. Unlike\nconventional reconfigurable intelligent surfaces (RISs) with fixed position\nelements, FRIS employs fluidic elements that can dynamically adjust their\npositions, offering enhanced spatial adaptability. We develop a system model\nwhere an AmBC tag communicates with a reader through an FRIS, which is\nparticularly beneficial in scenarios where the direct tag-to-reader link is\nweak or blocked by obstacles. The achievable backscatter rate is analyzed, and\nthe optimization of FRIS element positions is formulated as a non-convex\nproblem. To address this, we employ particle swarm optimization (PSO) to obtain\nnear-optimal configurations of the fluid elements. Simulation results\ndemonstrate that FRIS-aided AmBC significantly outperforms conventional\nRIS-based AmBC systems in terms of achievable throughput.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5c06\u6d41\u4f53\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(FRIS)\u96c6\u6210\u5230\u73af\u5883\u53cd\u5411\u6563\u5c04\u901a\u4fe1(AmBC)\u7cfb\u7edf\u4e2d\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u6d41\u4f53\u5143\u4ef6\u4f4d\u7f6e\u6765\u589e\u5f3a\u7a7a\u95f4\u9002\u5e94\u6027\uff0c\u5e76\u4f7f\u7528\u7c92\u5b50\u7fa4\u4f18\u5316\u7b97\u6cd5\u4f18\u5316\u914d\u7f6e\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u541e\u5410\u91cf\u3002", "motivation": "\u4f20\u7edfRIS\u5177\u6709\u56fa\u5b9a\u4f4d\u7f6e\u7684\u5143\u4ef6\uff0c\u5728\u76f4\u63a5\u94fe\u8def\u5f31\u6216\u88ab\u969c\u788d\u7269\u963b\u6321\u7684\u573a\u666f\u4e2d\u6027\u80fd\u53d7\u9650\u3002FRIS\u901a\u8fc7\u6d41\u4f53\u5143\u4ef6\u7684\u52a8\u6001\u4f4d\u7f6e\u8c03\u6574\u63d0\u4f9b\u66f4\u597d\u7684\u7a7a\u95f4\u9002\u5e94\u6027\uff0c\u6539\u5584AmBC\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u5f00\u53d1\u4e86FRIS\u8f85\u52a9\u7684AmBC\u7cfb\u7edf\u6a21\u578b\uff0c\u5c06FRIS\u5143\u4ef6\u4f4d\u7f6e\u4f18\u5316\u5efa\u6a21\u4e3a\u975e\u51f8\u95ee\u9898\uff0c\u91c7\u7528\u7c92\u5b50\u7fa4\u4f18\u5316(PSO)\u7b97\u6cd5\u6765\u83b7\u5f97\u8fd1\u6700\u4f18\u7684\u6d41\u4f53\u5143\u4ef6\u914d\u7f6e\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cFRIS\u8f85\u52a9\u7684AmBC\u7cfb\u7edf\u5728\u53ef\u5b9e\u73b0\u541e\u5410\u91cf\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u7684RIS\u57faAmBC\u7cfb\u7edf\u3002", "conclusion": "FRIS\u901a\u8fc7\u52a8\u6001\u4f4d\u7f6e\u8c03\u6574\u589e\u5f3a\u4e86AmBC\u7cfb\u7edf\u7684\u7a7a\u95f4\u9002\u5e94\u6027\uff0c\u5728\u5f31\u76f4\u63a5\u94fe\u8def\u573a\u666f\u4e0b\u63d0\u4f9b\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff0c\u8bc1\u660e\u4e86\u6d41\u4f53\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u5728\u73af\u5883\u53cd\u5411\u6563\u5c04\u901a\u4fe1\u4e2d\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2510.25075", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.25075", "abs": "https://arxiv.org/abs/2510.25075", "authors": ["Keisuke Imoto"], "title": "Joint Analysis of Acoustic Scenes and Sound Events Based on Semi-Supervised Training of Sound Events With Partial Labels", "comment": "Accepted to APSIPA Transactions on Signal and Information Processing", "summary": "Annotating time boundaries of sound events is labor-intensive, limiting the\nscalability of strongly supervised learning in audio detection. To reduce\nannotation costs, weakly-supervised learning with only clip-level labels has\nbeen widely adopted. As an alternative, partial label learning offers a\ncost-effective approach, where a set of possible labels is provided instead of\nexact weak annotations. However, partial label learning for audio analysis\nremains largely unexplored. Motivated by the observation that acoustic scenes\nprovide contextual information for constructing a set of possible sound events,\nwe utilize acoustic scene information to construct partial labels of sound\nevents. On the basis of this idea, in this paper, we propose a multitask\nlearning framework that jointly performs acoustic scene classification and\nsound event detection with partial labels of sound events. While reducing\nannotation costs, weakly-supervised and partial label learning often suffer\nfrom decreased detection performance due to lacking the precise event set and\ntheir temporal annotations. To better balance between annotation cost and\ndetection performance, we also explore a semi-supervised framework that\nleverages both strong and partial labels. Moreover, to refine partial labels\nand achieve better model training, we propose a label refinement method based\non self-distillation for the proposed approach with partial labels.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u58f0\u5b66\u573a\u666f\u4fe1\u606f\u6784\u5efa\u58f0\u97f3\u4e8b\u4ef6\u90e8\u5206\u6807\u7b7e\u7684\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u8054\u5408\u58f0\u5b66\u573a\u666f\u5206\u7c7b\u548c\u58f0\u97f3\u4e8b\u4ef6\u68c0\u6d4b\u6765\u964d\u4f4e\u6807\u6ce8\u6210\u672c\uff0c\u5e76\u5f15\u5165\u57fa\u4e8e\u81ea\u84b8\u998f\u7684\u6807\u7b7e\u7cbe\u70bc\u65b9\u6cd5\u63d0\u5347\u6a21\u578b\u6027\u80fd\u3002", "motivation": "\u58f0\u97f3\u4e8b\u4ef6\u65f6\u95f4\u8fb9\u754c\u6807\u6ce8\u6210\u672c\u9ad8\u6602\uff0c\u9650\u5236\u4e86\u5f3a\u76d1\u7763\u5b66\u4e60\u7684\u53ef\u6269\u5c55\u6027\u3002\u4e3a\u4e86\u964d\u4f4e\u6807\u6ce8\u6210\u672c\uff0c\u53ef\u4ee5\u5229\u7528\u58f0\u5b66\u573a\u666f\u63d0\u4f9b\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u6765\u6784\u5efa\u58f0\u97f3\u4e8b\u4ef6\u7684\u90e8\u5206\u6807\u7b7e\u96c6\u3002", "method": "\u63d0\u51fa\u591a\u4efb\u52a1\u5b66\u4e60\u6846\u67b6\uff0c\u8054\u5408\u6267\u884c\u58f0\u5b66\u573a\u666f\u5206\u7c7b\u548c\u57fa\u4e8e\u90e8\u5206\u6807\u7b7e\u7684\u58f0\u97f3\u4e8b\u4ef6\u68c0\u6d4b\uff1b\u63a2\u7d22\u534a\u76d1\u7763\u6846\u67b6\u7ed3\u5408\u5f3a\u6807\u7b7e\u548c\u90e8\u5206\u6807\u7b7e\uff1b\u5f15\u5165\u57fa\u4e8e\u81ea\u84b8\u998f\u7684\u6807\u7b7e\u7cbe\u70bc\u65b9\u6cd5\u3002", "result": "\u901a\u8fc7\u5229\u7528\u58f0\u5b66\u573a\u666f\u4fe1\u606f\u6784\u5efa\u90e8\u5206\u6807\u7b7e\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u6807\u6ce8\u6210\u672c\uff0c\u540c\u65f6\u901a\u8fc7\u6807\u7b7e\u7cbe\u70bc\u65b9\u6cd5\u63d0\u5347\u4e86\u68c0\u6d4b\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u964d\u4f4e\u6807\u6ce8\u6210\u672c\u548c\u4fdd\u6301\u68c0\u6d4b\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u97f3\u9891\u5206\u6790\u4e2d\u7684\u90e8\u5206\u6807\u7b7e\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.24726", "categories": ["eess.SP", "cs.CY", "stat.AP", "62C (Primary), 91B06 (Secondary)", "J.4; H.4"], "pdf": "https://arxiv.org/pdf/2510.24726", "abs": "https://arxiv.org/abs/2510.24726", "authors": ["Maximiliano Rosadio Z.", "Angel Jimenez-Molina", "Basti\u00e1n Henr\u00edquez", "Paulina Leiva", "Ricardo Hurtubia", "Ricardo De La Paz Guala", "Leandro Gayozo", "C. Angelo Guevara"], "title": "Modelling Real-Life Cycling Decisions in Real Urban Settings Through Psychophysiology and LLM-Derived Contextual Data", "comment": "31 pages, 10 figures", "summary": "Measuring emotional states in transportation contexts is an emerging field.\nMethods based on self-reported emotions are limited by their low granularity\nand their susceptibility to memory bias. In contrast, methods based on\nphysiological indicators provide continuous data, enabling researchers to\nmeasure changes in emotional states with high detail and accuracy. Not only are\nemotions important in the analysis, but understanding what triggers emotional\nchanges is equally important. Uncontrolled variables such as traffic\nconditions, pedestrian interactions, and infrastructure remain a significant\nchallenge, as they can have a great impact on emotional states. Explaining the\nreasons behind these emotional states requires gathering sufficient and proper\ncontextual data, which can be extremely difficult in real-world environments.\nThis paper addresses these challenges by applying an innovative approach,\nextracting contextual data (expert annotator level) from recorded multimedia\nusing large language models (LLMs). In this paper, data are collected from an\nurban cycling case study of the City of Santiago, Chile. The applied models\nfocus on understanding how different environments and traffic situations affect\nthe emotional states and behaviors of the participants using physiological\ndata. Sequences of images, extracted from the recorded videos, are processed by\nLLMs to obtain semantic descriptions of the environment. These discrete,\nalthough dense and detailed, contextual data are integrated into a hybrid\nmodel, where fatigue and arousal serve as latent variables influencing observed\ncycling behaviors (inferred from GPS data) like waiting, accelerating, braking,\netc. The study confirms that cycling decisions are influenced by stress-related\nemotions and highlights the strong impact of urban characteristics and traffic\nconditions on cyclist behavior.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u521b\u65b0\u65b9\u6cd5\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u4ece\u591a\u5a92\u4f53\u8bb0\u5f55\u4e2d\u63d0\u53d6\u4e0a\u4e0b\u6587\u6570\u636e\uff0c\u7ed3\u5408\u751f\u7406\u6570\u636e\u7814\u7a76\u57ce\u5e02\u9a91\u884c\u73af\u5883\u4e2d\u60c5\u7eea\u72b6\u6001\u548c\u884c\u4e3a\u7684\u5173\u7cfb\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u81ea\u6211\u62a5\u544a\u7684\u60c5\u7eea\u6d4b\u91cf\u65b9\u6cd5\u5b58\u5728\u7c92\u5ea6\u4f4e\u548c\u8bb0\u5fc6\u504f\u5dee\u95ee\u9898\uff0c\u800c\u751f\u7406\u6307\u6807\u80fd\u63d0\u4f9b\u8fde\u7eed\u6570\u636e\u3002\u7406\u89e3\u60c5\u7eea\u53d8\u5316\u89e6\u53d1\u56e0\u7d20\u540c\u6837\u91cd\u8981\uff0c\u4f46\u73b0\u5b9e\u73af\u5883\u4e2d\u83b7\u53d6\u8db3\u591f\u4e0a\u4e0b\u6587\u6570\u636e\u6781\u5177\u6311\u6218\u3002", "method": "\u4ece\u667a\u5229\u5723\u5730\u4e9a\u54e5\u57ce\u5e02\u9a91\u884c\u6848\u4f8b\u4e2d\u6536\u96c6\u6570\u636e\uff0c\u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5904\u7406\u89c6\u9891\u4e2d\u63d0\u53d6\u7684\u56fe\u50cf\u5e8f\u5217\u83b7\u5f97\u73af\u5883\u8bed\u4e49\u63cf\u8ff0\uff0c\u5c06\u8fd9\u4e9b\u4e0a\u4e0b\u6587\u6570\u636e\u6574\u5408\u5230\u6df7\u5408\u6a21\u578b\u4e2d\uff0c\u5176\u4e2d\u75b2\u52b3\u548c\u5524\u9192\u5ea6\u4f5c\u4e3a\u5f71\u54cd\u9a91\u884c\u884c\u4e3a\u7684\u6f5c\u5728\u53d8\u91cf\u3002", "result": "\u7814\u7a76\u8bc1\u5b9e\u9a91\u884c\u51b3\u7b56\u53d7\u538b\u529b\u76f8\u5173\u60c5\u7eea\u5f71\u54cd\uff0c\u5e76\u7a81\u663e\u57ce\u5e02\u7279\u5f81\u548c\u4ea4\u901a\u6761\u4ef6\u5bf9\u9a91\u884c\u8005\u884c\u4e3a\u7684\u5f3a\u70c8\u5f71\u54cd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u5728\u73b0\u5b9e\u73af\u5883\u4e2d\u83b7\u53d6\u8db3\u591f\u4e0a\u4e0b\u6587\u6570\u636e\u7684\u6311\u6218\uff0c\u4e3a\u7406\u89e3\u60c5\u7eea\u72b6\u6001\u4e0e\u884c\u4e3a\u5173\u7cfb\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84\u3002"}}
{"id": "2510.25178", "categories": ["cs.SD", "cs.AI", "eess.AS", "I.2.7; H.5.5"], "pdf": "https://arxiv.org/pdf/2510.25178", "abs": "https://arxiv.org/abs/2510.25178", "authors": ["Dharma Teja Donepudi"], "title": "SFMS-ALR: Script-First Multilingual Speech Synthesis with Adaptive Locale Resolution", "comment": "10 pages, 2 figures, 1 table. Demonstration prototype available at\n  https://sfml-tts-proxy-253495793487.us-central1.run.app", "summary": "Intra-sentence multilingual speech synthesis (code-switching TTS) remains a\nmajor challenge due to abrupt language shifts, varied scripts, and mismatched\nprosody between languages. Conventional TTS systems are typically monolingual\nand fail to produce natural, intelligible speech in mixed-language contexts. We\nintroduce Script-First Multilingual Synthesis with Adaptive Locale Resolution\n(SFMS-ALR), an engine-agnostic framework for fluent, real-time code-switched\nspeech generation. SFMS-ALR segments input text by Unicode script, applies\nadaptive language identification to determine each segment's language and\nlocale, and normalizes prosody using sentiment-aware adjustments to preserve\nexpressive continuity across languages. The algorithm generates a unified SSML\nrepresentation with appropriate \"lang\" or \"voice\" spans and synthesizes the\nutterance in a single TTS request. Unlike end-to-end multilingual models,\nSFMS-ALR requires no retraining and integrates seamlessly with existing voices\nfrom Google, Apple, Amazon, and other providers. Comparative analysis with\ndata-driven pipelines such as Unicom and Mask LID demonstrates SFMS-ALR's\nflexibility, interpretability, and immediate deployability. The framework\nestablishes a modular baseline for high-quality, engine-independent\nmultilingual TTS and outlines evaluation strategies for intelligibility,\nnaturalness, and user preference.", "AI": {"tldr": "SFMS-ALR\u662f\u4e00\u4e2a\u5f15\u64ce\u65e0\u5173\u7684\u591a\u8bed\u8a00\u8bed\u97f3\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7Unicode\u811a\u672c\u5206\u5272\u3001\u81ea\u9002\u5e94\u8bed\u8a00\u8bc6\u522b\u548c\u60c5\u611f\u611f\u77e5\u97f5\u5f8b\u8c03\u6574\uff0c\u5b9e\u73b0\u6d41\u7545\u7684\u5b9e\u65f6\u4ee3\u7801\u5207\u6362\u8bed\u97f3\u751f\u6210\u3002", "motivation": "\u4f20\u7edf\u5355\u8bed\u8a00TTS\u7cfb\u7edf\u5728\u591a\u8bed\u8a00\u6df7\u5408\u573a\u666f\u4e0b\u65e0\u6cd5\u4ea7\u751f\u81ea\u7136\u3001\u6e05\u6670\u7684\u8bed\u97f3\uff0c\u5b58\u5728\u8bed\u8a00\u5207\u6362\u7a81\u5140\u3001\u811a\u672c\u5dee\u5f02\u548c\u97f5\u5f8b\u4e0d\u5339\u914d\u7b49\u95ee\u9898\u3002", "method": "\u57fa\u4e8eUnicode\u811a\u672c\u5206\u5272\u8f93\u5165\u6587\u672c\uff0c\u5e94\u7528\u81ea\u9002\u5e94\u8bed\u8a00\u8bc6\u522b\u786e\u5b9a\u6bcf\u4e2a\u7247\u6bb5\u7684\u8bed\u8a00\u548c\u533a\u57df\u8bbe\u7f6e\uff0c\u4f7f\u7528\u60c5\u611f\u611f\u77e5\u8c03\u6574\u8fdb\u884c\u97f5\u5f8b\u5f52\u4e00\u5316\uff0c\u751f\u6210\u7edf\u4e00\u7684SSML\u8868\u793a\u3002", "result": "SFMS-ALR\u65e0\u9700\u91cd\u65b0\u8bad\u7ec3\u5373\u53ef\u4e0e\u73b0\u6709TTS\u63d0\u4f9b\u5546\u96c6\u6210\uff0c\u76f8\u6bd4Unicom\u548cMask LID\u7b49\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\uff0c\u5c55\u73b0\u51fa\u66f4\u597d\u7684\u7075\u6d3b\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u5373\u65f6\u90e8\u7f72\u80fd\u529b\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u9ad8\u8d28\u91cf\u3001\u5f15\u64ce\u65e0\u5173\u7684\u591a\u8bed\u8a00TTS\u5efa\u7acb\u4e86\u6a21\u5757\u5316\u57fa\u51c6\uff0c\u5e76\u63d0\u51fa\u4e86\u53ef\u61c2\u5ea6\u3001\u81ea\u7136\u5ea6\u548c\u7528\u6237\u504f\u597d\u7684\u8bc4\u4f30\u7b56\u7565\u3002"}}
{"id": "2510.24731", "categories": ["eess.SP", "cs.IT", "math.IT"], "pdf": "https://arxiv.org/pdf/2510.24731", "abs": "https://arxiv.org/abs/2510.24731", "authors": ["Bin Li", "Dongdong Yang", "Lei Liu", "Dusit Niyato"], "title": "Aerial RIS-Enhanced Communications: Joint UAV Trajectory, Altitude Control, and Phase Shift Design", "comment": "15 pages, 12 figures", "summary": "Reconfigurable intelligent surface (RIS) has emerged as a pivotal technology\nfor enhancing wireless networks. Compared to terrestrial RIS deployed on\nbuilding facades, aerial RIS (ARIS) mounted on quadrotor unmanned aerial\nvehicle (UAV) offers superior flexibility and extended coverage. However, the\ninevitable tilt and altitude variations of a quadrotor UAV during flight may\nlead to severe beam misalignment, significantly degrading ARIS's performance.\nTo address this challenge, we propose a Euler angles-based ARIS control scheme\nthat jointly optimizes the altitude and trajectory of the ARIS by leveraging\nthe UAV's dynamic model. Considering the constraints on ARIS flight energy\nconsumption, flight safety, and the transmission power of a base station (BS),\nwe jointly design the ARIS's altitude, trajectory, phase shifts, and BS\nbeamforming to maximize the system sum-rate. Due to the continuous control\nnature of ARIS flight and the strong coupling among variables, we formulate the\nproblem as a Markov decision process and adopt a soft actor-critic algorithm\nwith prioritized experience replay to learn efficient ARIS control policies.\nBased on the optimized ARIS configuration, we further employ the water-filling\nand bisection method to efficiently determine the optimal BS beamforming.\nNumerical results demonstrate that the proposed algorithm significantly\noutperforms benchmarks in both convergence and communication performance,\nachieving approximately 14.4\\% improvement in sum-rate. Moreover, in comparison\nto the fixed-horizontal ARIS scheme, the proposed scheme yields more adaptive\ntrajectories and significantly mitigates performance degradation caused by ARIS\ntilting, demonstrating strong potential for practical ARIS deployment.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6b27\u62c9\u89d2\u5ea6\u7684\u7a7a\u4e2d\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u63a7\u5236\u65b9\u6848\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316ARIS\u7684\u9ad8\u5ea6\u548c\u8f68\u8ff9\u6765\u7f13\u89e3\u65e0\u4eba\u673a\u98de\u884c\u4e2d\u7684\u503e\u659c\u548c\u9ad8\u5ea6\u53d8\u5316\u5bfc\u81f4\u7684\u6ce2\u675f\u5931\u51c6\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u603b\u901f\u7387\u3002", "motivation": "\u7a7a\u4e2dRIS\u76f8\u6bd4\u5730\u9762RIS\u5177\u6709\u66f4\u597d\u7684\u7075\u6d3b\u6027\u548c\u8986\u76d6\u8303\u56f4\uff0c\u4f46\u56db\u65cb\u7ffc\u65e0\u4eba\u673a\u98de\u884c\u4e2d\u7684\u503e\u659c\u548c\u9ad8\u5ea6\u53d8\u5316\u4f1a\u5bfc\u81f4\u4e25\u91cd\u7684\u6ce2\u675f\u5931\u51c6\uff0c\u663e\u8457\u964d\u4f4eARIS\u6027\u80fd\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u6311\u6218\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u91c7\u7528\u5e26\u4f18\u5148\u7ea7\u7ecf\u9a8c\u56de\u653e\u7684\u8f6f\u6f14\u5458-\u8bc4\u8bba\u5bb6\u7b97\u6cd5\u5b66\u4e60ARIS\u63a7\u5236\u7b56\u7565\uff0c\u5e76\u57fa\u4e8e\u4f18\u5316\u914d\u7f6e\u4f7f\u7528\u6ce8\u6c34\u6cd5\u548c\u4e8c\u5206\u6cd5\u786e\u5b9a\u57fa\u7ad9\u6ce2\u675f\u6210\u5f62\u3002", "result": "\u6240\u63d0\u7b97\u6cd5\u5728\u6536\u655b\u6027\u548c\u901a\u4fe1\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\uff0c\u7cfb\u7edf\u603b\u901f\u7387\u63d0\u5347\u7ea614.4%\uff0c\u76f8\u6bd4\u56fa\u5b9a\u6c34\u5e73ARIS\u65b9\u6848\u4ea7\u751f\u66f4\u81ea\u9002\u5e94\u7684\u8f68\u8ff9\uff0c\u663e\u8457\u51cf\u8f7b\u4e86ARIS\u503e\u659c\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u8be5\u65b9\u6848\u5c55\u793a\u4e86\u5b9e\u9645ARIS\u90e8\u7f72\u7684\u5f3a\u5927\u6f5c\u529b\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u65e0\u4eba\u673a\u98de\u884c\u4e2d\u7684\u52a8\u6001\u53d8\u5316\uff0c\u63d0\u5347\u65e0\u7ebf\u7f51\u7edc\u6027\u80fd\u3002"}}
{"id": "2510.25228", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25228", "abs": "https://arxiv.org/abs/2510.25228", "authors": ["Chihiro Nagashima", "Akira Takahashi", "Zhi Zhong", "Shusuke Takahashi", "Yuki Mitsufuji"], "title": "Studies for : A Human-AI Co-Creative Sound Artwork Using a Real-time Multi-channel Sound Generation Model", "comment": "Accepted at NeurIPS Creative AI Track 2025, 9 pages, 6 figures, 1\n  table, Demo page: https://sony.github.io/studies-for/", "summary": "This paper explores the integration of AI technologies into the artistic\nworkflow through the creation of Studies for, a generative sound installation\ndeveloped in collaboration with sound artist Evala\n(https://www.ntticc.or.jp/en/archive/works/studies-for/). The installation\nemploys SpecMaskGIT, a lightweight yet high-quality sound generation AI model,\nto generate and playback eight-channel sound in real-time, creating an\nimmersive auditory experience over the course of a three-month exhibition. The\nwork is grounded in the concept of a \"new form of archive,\" which aims to\npreserve the artistic style of an artist while expanding beyond artists' past\nartworks by continued generation of new sound elements. This speculative\napproach to archival preservation is facilitated by training the AI model on a\ndataset consisting of over 200 hours of Evala's past sound artworks.\n  By addressing key requirements in the co-creation of art using AI, this study\nhighlights the value of the following aspects: (1) the necessity of integrating\nartist feedback, (2) datasets derived from an artist's past works, and (3)\nensuring the inclusion of unexpected, novel outputs. In Studies for, the model\nwas designed to reflect the artist's artistic identity while generating new,\npreviously unheard sounds, making it a fitting realization of the concept of \"a\nnew form of archive.\" We propose a Human-AI co-creation framework for\neffectively incorporating sound generation AI models into the sound art\ncreation process and suggest new possibilities for creating and archiving sound\nart that extend an artist's work beyond their physical existence. Demo page:\nhttps://sony.github.io/studies-for/", "AI": {"tldr": "\u8be5\u8bba\u6587\u901a\u8fc7\u5f00\u53d1\"Studies for\"\u58f0\u97f3\u88c5\u7f6e\uff0c\u63a2\u7d22\u4e86AI\u6280\u672f\u5728\u827a\u672f\u5de5\u4f5c\u6d41\u4e2d\u7684\u96c6\u6210\uff0c\u4f7f\u7528SpecMaskGIT\u6a21\u578b\u5b9e\u65f6\u751f\u6210\u516b\u58f0\u9053\u58f0\u97f3\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u827a\u672f\u5bb6\u8fc7\u53bb\u4f5c\u54c1\u8bad\u7ec3AI\u7684\"\u65b0\u578b\u6863\u6848\"\u6982\u5ff5\u3002", "motivation": "\u63a2\u7d22AI\u4e0e\u827a\u672f\u521b\u4f5c\u7684\u878d\u5408\uff0c\u901a\u8fc7\u8bad\u7ec3AI\u6a21\u578b\u6765\u4fdd\u5b58\u827a\u672f\u5bb6\u7684\u98ce\u683c\u7279\u5f81\uff0c\u540c\u65f6\u751f\u6210\u65b0\u7684\u58f0\u97f3\u5143\u7d20\uff0c\u5b9e\u73b0\u4e00\u79cd\u8d85\u8d8a\u827a\u672f\u5bb6\u7269\u7406\u5b58\u5728\u7684\u827a\u672f\u5ef6\u7eed\u548c\u6863\u6848\u4fdd\u5b58\u65b9\u5f0f\u3002", "method": "\u4f7f\u7528SpecMaskGIT\u8f7b\u91cf\u7ea7\u9ad8\u8d28\u91cf\u58f0\u97f3\u751f\u6210AI\u6a21\u578b\uff0c\u5728Evala\u827a\u672f\u5bb6\u8d85\u8fc7200\u5c0f\u65f6\u8fc7\u53bb\u4f5c\u54c1\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u5f00\u53d1\u5b9e\u65f6\u516b\u58f0\u9053\u58f0\u97f3\u751f\u6210\u88c5\u7f6e\uff0c\u5e76\u6574\u5408\u827a\u672f\u5bb6\u53cd\u9988\u673a\u5236\u3002", "result": "\u6210\u529f\u521b\u5efa\u4e86\"Studies for\"\u58f0\u97f3\u88c5\u7f6e\uff0c\u5728\u4e09\u4e2a\u6708\u5c55\u89c8\u671f\u95f4\u63d0\u4f9b\u6c89\u6d78\u5f0f\u542c\u89c9\u4f53\u9a8c\uff0cAI\u6a21\u578b\u80fd\u591f\u53cd\u6620\u827a\u672f\u5bb6\u8eab\u4efd\u540c\u65f6\u751f\u6210\u65b0\u9896\u58f0\u97f3\uff0c\u5b9e\u73b0\u4e86\"\u65b0\u578b\u6863\u6848\"\u6982\u5ff5\u3002", "conclusion": "\u63d0\u51fa\u4e86\u6709\u6548\u6574\u5408\u58f0\u97f3\u751f\u6210AI\u6a21\u578b\u7684\u4eba\u7c7b-AI\u534f\u540c\u521b\u4f5c\u6846\u67b6\uff0c\u4e3a\u58f0\u97f3\u827a\u672f\u7684\u521b\u4f5c\u548c\u6863\u6848\u4fdd\u5b58\u5f00\u8f9f\u4e86\u65b0\u53ef\u80fd\u6027\uff0c\u4f7f\u827a\u672f\u5bb6\u7684\u4f5c\u54c1\u80fd\u591f\u8d85\u8d8a\u5176\u7269\u7406\u5b58\u5728\u800c\u5ef6\u7eed\u53d1\u5c55\u3002"}}
{"id": "2510.25560", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2510.25560", "abs": "https://arxiv.org/abs/2510.25560", "authors": ["Antonin Gagnere", "Slim Essid", "Geoffroy Peeters"], "title": "Controlling Contrastive Self-Supervised Learning with Knowledge-Driven Multiple Hypothesis: Application to Beat Tracking", "comment": null, "summary": "Ambiguities in data and problem constraints can lead to diverse, equally\nplausible outcomes for a machine learning task. In beat and downbeat tracking,\nfor instance, different listeners may adopt various rhythmic interpretations,\nnone of which would necessarily be incorrect. To address this, we propose a\ncontrastive self-supervised pre-training approach that leverages multiple\nhypotheses about possible positive samples in the data. Our model is trained to\nlearn representations compatible with different such hypotheses, which are\nselected with a knowledge-based scoring function to retain the most plausible\nones. When fine-tuned on labeled data, our model outperforms existing methods\non standard benchmarks, showcasing the advantages of integrating domain\nknowledge with multi-hypothesis selection in music representation learning in\nparticular.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5bf9\u6bd4\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5229\u7528\u6570\u636e\u4e2d\u591a\u4e2a\u53ef\u80fd\u7684\u6b63\u6837\u672c\u5047\u8bbe\u6765\u5904\u7406\u97f3\u4e50\u8282\u62cd\u8ddf\u8e2a\u4e2d\u7684\u6b67\u4e49\u95ee\u9898\uff0c\u901a\u8fc7\u57fa\u4e8e\u77e5\u8bc6\u7684\u8bc4\u5206\u51fd\u6570\u9009\u62e9\u6700\u5408\u7406\u7684\u5047\u8bbe\uff0c\u5728\u5fae\u8c03\u540e\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u6570\u636e\u548c\u95ee\u9898\u7ea6\u675f\u4e2d\u7684\u6b67\u4e49\u53ef\u80fd\u5bfc\u81f4\u673a\u5668\u5b66\u4e60\u4efb\u52a1\u4ea7\u751f\u591a\u4e2a\u540c\u6837\u5408\u7406\u7684\u7ed3\u679c\uff0c\u4f8b\u5982\u5728\u8282\u62cd\u8ddf\u8e2a\u4e2d\u4e0d\u540c\u542c\u4f17\u53ef\u80fd\u6709\u4e0d\u540c\u7684\u8282\u594f\u89e3\u91ca\uff0c\u8fd9\u4e9b\u89e3\u91ca\u90fd\u4e0d\u4e00\u5b9a\u662f\u9519\u8bef\u7684\u3002", "method": "\u91c7\u7528\u5bf9\u6bd4\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5b66\u4e60\u4e0e\u4e0d\u540c\u5047\u8bbe\u517c\u5bb9\u7684\u8868\u793a\uff0c\u4f7f\u7528\u57fa\u4e8e\u77e5\u8bc6\u7684\u8bc4\u5206\u51fd\u6570\u9009\u62e9\u6700\u5408\u7406\u7684\u5047\u8bbe\u3002", "result": "\u5728\u6807\u51c6\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5fae\u8c03\u540e\u7684\u6a21\u578b\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u5c06\u9886\u57df\u77e5\u8bc6\u4e0e\u591a\u5047\u8bbe\u9009\u62e9\u76f8\u7ed3\u5408\u5728\u97f3\u4e50\u8868\u793a\u5b66\u4e60\u4e2d\u5177\u6709\u4f18\u52bf\u3002"}}
{"id": "2510.24733", "categories": ["eess.SP", "cs.LG", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2510.24733", "abs": "https://arxiv.org/abs/2510.24733", "authors": ["Richard Csaky"], "title": "Decoding non-invasive brain activity with novel deep-learning approaches", "comment": "PhD thesis, 342 pages", "summary": "This thesis delves into the world of non-invasive electrophysiological brain\nsignals like electroencephalography (EEG) and magnetoencephalography (MEG),\nfocusing on modelling and decoding such data. The research aims to investigate\nwhat happens in the brain when we perceive visual stimuli or engage in covert\nspeech (inner speech) and enhance the decoding performance of such stimuli. The\nthesis is divided into two main sections, methodological and experimental work.\nA central concern in both sections is the large variability present in\nelectrophysiological recordings, whether it be within-subject or\nbetween-subject variability, and to a certain extent between-dataset\nvariability. In the methodological sections, we explore the potential of deep\nlearning for brain decoding. We present advancements in decoding visual stimuli\nusing linear models at the individual subject level. We then explore how deep\nlearning techniques can be employed for group decoding, introducing new methods\nto deal with between-subject variability. Finally, we also explores novel\nforecasting models of MEG data based on convolutional and Transformer-based\narchitectures. In particular, Transformer-based models demonstrate superior\ncapabilities in generating signals that closely match real brain data, thereby\nenhancing the accuracy and reliability of modelling the brain's\nelectrophysiology. In the experimental section, we present a unique dataset\ncontaining high-trial inner speech EEG, MEG, and preliminary optically pumped\nmagnetometer (OPM) data. Our aim is to investigate different types of inner\nspeech and push decoding performance by collecting a high number of trials and\nsessions from a few participants. However, the decoding results are found to be\nmostly negative, underscoring the difficulty of decoding inner speech.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u975e\u4fb5\u5165\u6027\u8111\u7535\u4fe1\u53f7\uff08EEG\u548cMEG\uff09\u7684\u5efa\u6a21\u548c\u89e3\u7801\uff0c\u91cd\u70b9\u5173\u6ce8\u89c6\u89c9\u611f\u77e5\u548c\u5185\u90e8\u8a00\u8bed\u7684\u8111\u6d3b\u52a8\u89e3\u7801\uff0c\u5e76\u63d0\u51fa\u5904\u7406\u4e2a\u4f53\u95f4\u53d8\u5f02\u6027\u7684\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u3002", "motivation": "\u7814\u7a76\u5927\u8111\u5728\u611f\u77e5\u89c6\u89c9\u523a\u6fc0\u6216\u8fdb\u884c\u5185\u90e8\u8a00\u8bed\u65f6\u7684\u6d3b\u52a8\uff0c\u5e76\u63d0\u5347\u8fd9\u7c7b\u523a\u6fc0\u7684\u89e3\u7801\u6027\u80fd\uff0c\u540c\u65f6\u89e3\u51b3\u8111\u7535\u8bb0\u5f55\u4e2d\u5b58\u5728\u7684\u4e2a\u4f53\u5185\u3001\u4e2a\u4f53\u95f4\u548c\u6570\u636e\u96c6\u95f4\u7684\u53d8\u5f02\u6027\u95ee\u9898\u3002", "method": "\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u8fdb\u884c\u8111\u89e3\u7801\uff0c\u5305\u62ec\u4e2a\u4f53\u5c42\u9762\u7684\u7ebf\u6027\u6a21\u578b\u3001\u5904\u7406\u4e2a\u4f53\u95f4\u53d8\u5f02\u6027\u7684\u7fa4\u4f53\u89e3\u7801\u65b9\u6cd5\uff0c\u4ee5\u53ca\u57fa\u4e8e\u5377\u79ef\u548cTransformer\u67b6\u6784\u7684MEG\u6570\u636e\u9884\u6d4b\u6a21\u578b\u3002", "result": "\u5728\u65b9\u6cd5\u5b66\u90e8\u5206\uff0cTransformer\u6a21\u578b\u5728\u751f\u6210\u63a5\u8fd1\u771f\u5b9e\u8111\u6570\u636e\u7684\u4fe1\u53f7\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff1b\u5728\u5b9e\u9a8c\u90e8\u5206\uff0c\u5185\u90e8\u8a00\u8bed\u89e3\u7801\u7ed3\u679c\u5927\u591a\u4e3a\u9634\u6027\uff0c\u8868\u660e\u5185\u90e8\u8a00\u8bed\u89e3\u7801\u5177\u6709\u6311\u6218\u6027\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u7279\u522b\u662fTransformer\u67b6\u6784\u5728\u8111\u7535\u4fe1\u53f7\u5efa\u6a21\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u5185\u90e8\u8a00\u8bed\u7684\u89e3\u7801\u4ecd\u7136\u9762\u4e34\u5de8\u5927\u56f0\u96be\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u3002"}}
{"id": "2510.24737", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24737", "abs": "https://arxiv.org/abs/2510.24737", "authors": ["Koustav Mallick", "Neel Singh", "Mohammedreza Hajiarbabi"], "title": "Cardi-GPT: An Expert ECG-Record Processing Chatbot", "comment": null, "summary": "Interpreting and communicating electrocardiogram (ECG) findings are crucial\nyet challenging tasks in cardiovascular diagnosis, traditionally requiring\nsignificant expertise and precise clinical communication. This paper introduces\nCardi-GPT, an advanced expert system designed to streamline ECG interpretation\nand enhance clinical communication through deep learning and natural language\ninteraction. Cardi-GPT employs a 16-residual-block convolutional neural network\n(CNN) to process 12-lead ECG data, achieving a weighted accuracy of 0.6194\nacross 24 cardiac conditions. A novel fuzzification layer converts complex\nnumerical outputs into clinically meaningful linguistic categories, while an\nintegrated chatbot interface facilitates intuitive exploration of diagnostic\ninsights and seamless communication between healthcare providers.\n  The system was evaluated on a diverse dataset spanning six hospitals across\nfour countries, demonstrating superior performance compared to baseline models.\nAdditionally, Cardi-GPT achieved an impressive overall response quality score\nof 73\\%, assessed using a comprehensive evaluation framework that measures\ncoverage, grounding, and coherence. By bridging the gap between intricate ECG\ndata interpretation and actionable clinical insights, Cardi-GPT represents a\ntransformative innovation in cardiovascular healthcare, promising to improve\ndiagnostic accuracy, clinical workflows, and patient outcomes across diverse\nmedical settings.", "AI": {"tldr": "Cardi-GPT\u662f\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u4e13\u5bb6\u7cfb\u7edf\uff0c\u901a\u8fc716\u5c42\u6b8b\u5dee\u5757CNN\u5904\u740612\u5bfc\u8054\u5fc3\u7535\u56fe\u6570\u636e\uff0c\u7ed3\u5408\u6a21\u7cca\u5316\u5c42\u548c\u804a\u5929\u673a\u5668\u4eba\u754c\u9762\uff0c\u63d0\u5347ECG\u89e3\u8bfb\u548c\u4e34\u5e8a\u6c9f\u901a\u6548\u7387\u3002", "motivation": "\u4f20\u7edfECG\u89e3\u8bfb\u9700\u8981\u5927\u91cf\u4e13\u4e1a\u77e5\u8bc6\u4e14\u4e34\u5e8a\u6c9f\u901a\u56f0\u96be\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u7b80\u5316ECG\u89e3\u91ca\u548c\u589e\u5f3a\u4e34\u5e8a\u6c9f\u901a\u7684\u667a\u80fd\u7cfb\u7edf\u3002", "method": "\u4f7f\u752816\u6b8b\u5dee\u5757CNN\u5904\u740612\u5bfc\u8054ECG\u6570\u636e\uff0c\u91c7\u7528\u6a21\u7cca\u5316\u5c42\u5c06\u6570\u503c\u8f93\u51fa\u8f6c\u6362\u4e3a\u4e34\u5e8a\u8bed\u8a00\u7c7b\u522b\uff0c\u96c6\u6210\u804a\u5929\u673a\u5668\u4eba\u754c\u9762\u8fdb\u884c\u8bca\u65ad\u63a2\u7d22\u548c\u6c9f\u901a\u3002", "result": "\u572824\u79cd\u5fc3\u810f\u75be\u75c5\u4e0a\u8fbe\u52300.6194\u52a0\u6743\u51c6\u786e\u7387\uff0c\u57286\u5bb6\u533b\u9662\u6570\u636e\u96c6\u4e0a\u8868\u73b0\u4f18\u4e8e\u57fa\u7ebf\u6a21\u578b\uff0c\u6574\u4f53\u54cd\u5e94\u8d28\u91cf\u5f97\u520673%\u3002", "conclusion": "Cardi-GPT\u901a\u8fc7\u5f25\u5408\u590d\u6742ECG\u6570\u636e\u89e3\u8bfb\u4e0e\u4e34\u5e8a\u6d1e\u5bdf\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4ee3\u8868\u4e86\u5fc3\u8840\u7ba1\u533b\u7597\u7684\u53d8\u9769\u6027\u521b\u65b0\uff0c\u6709\u671b\u63d0\u9ad8\u8bca\u65ad\u51c6\u786e\u6027\u3001\u4f18\u5316\u4e34\u5e8a\u5de5\u4f5c\u6d41\u7a0b\u548c\u6539\u5584\u60a3\u8005\u9884\u540e\u3002"}}
{"id": "2510.25714", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2510.25714", "abs": "https://arxiv.org/abs/2510.25714", "authors": ["Dan Barry", "Davoud Shariat Panah", "Alessandro Ragano", "Jan Skoglund", "Andrew Hines"], "title": "Binaspect -- A Python Library for Binaural Audio Analysis, Visualization & Feature Generation", "comment": null, "summary": "We present Binaspect, an open-source Python library for binaural audio\nanalysis, visualization, and feature generation. Binaspect generates\ninterpretable \"azimuth maps\" by calculating modified interaural time and level\ndifference spectrograms, and clustering those time-frequency (TF) bins into\nstable time-azimuth histogram representations. This allows multiple active\nsources to appear as distinct azimuthal clusters, while degradations manifest\nas broadened, diffused, or shifted distributions. Crucially, Binaspect operates\nblindly on audio, requiring no prior knowledge of head models. These\nvisualizations enable researchers and engineers to observe how binaural cues\nare degraded by codec and renderer design choices, among other downstream\nprocesses. We demonstrate the tool on bitrate ladders, ambisonic rendering, and\nVBAP source positioning, where degradations are clearly revealed. In addition\nto their diagnostic value, the proposed representations can be exported as\nstructured features suitable for training machine learning models in quality\nprediction, spatial audio classification, and other binaural tasks. Binaspect\nis released under an open-source license with full reproducibility scripts at\nhttps://github.com/QxLabIreland/Binaspect.", "AI": {"tldr": "Binaspect\u662f\u4e00\u4e2a\u5f00\u6e90\u7684Python\u5e93\uff0c\u7528\u4e8e\u53cc\u8033\u97f3\u9891\u5206\u6790\u3001\u53ef\u89c6\u5316\u548c\u7279\u5f81\u751f\u6210\uff0c\u901a\u8fc7\u751f\u6210\u53ef\u89e3\u91ca\u7684\u65b9\u4f4d\u56fe\u6765\u663e\u793a\u53cc\u8033\u7ebf\u7d22\u7684\u9000\u5316\u60c5\u51b5\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u65e0\u9700\u5148\u9a8c\u5934\u90e8\u6a21\u578b\u77e5\u8bc6\u7684\u5de5\u5177\uff0c\u4f7f\u7814\u7a76\u4eba\u5458\u548c\u5de5\u7a0b\u5e08\u80fd\u591f\u89c2\u5bdf\u53cc\u8033\u7ebf\u7d22\u5982\u4f55\u88ab\u7f16\u89e3\u7801\u5668\u548c\u6e32\u67d3\u5668\u8bbe\u8ba1\u9009\u62e9\u7b49\u4e0b\u6e38\u8fc7\u7a0b\u6240\u9000\u5316\u3002", "method": "\u901a\u8fc7\u8ba1\u7b97\u4fee\u6539\u7684\u8033\u95f4\u65f6\u95f4\u548c\u7535\u5e73\u5dee\u9891\u8c31\u56fe\uff0c\u5e76\u5c06\u65f6\u9891(TF)\u7bb1\u805a\u7c7b\u4e3a\u7a33\u5b9a\u7684\u65f6-\u65b9\u4f4d\u76f4\u65b9\u56fe\u8868\u793a\uff0c\u751f\u6210\u53ef\u89e3\u91ca\u7684\u65b9\u4f4d\u56fe\u3002", "result": "\u8be5\u5de5\u5177\u5728\u6bd4\u7279\u7387\u9636\u68af\u3001Ambisonic\u6e32\u67d3\u548cVBAP\u6e90\u5b9a\u4f4d\u7b49\u573a\u666f\u4e2d\u6e05\u6670\u663e\u793a\u4e86\u9000\u5316\u60c5\u51b5\uff0c\u591a\u4e2a\u6d3b\u52a8\u6e90\u8868\u73b0\u4e3a\u4e0d\u540c\u7684\u65b9\u4f4d\u805a\u7c7b\uff0c\u800c\u9000\u5316\u8868\u73b0\u4e3a\u5206\u5e03\u53d8\u5bbd\u3001\u6269\u6563\u6216\u504f\u79fb\u3002", "conclusion": "Binaspect\u4e0d\u4ec5\u5177\u6709\u8bca\u65ad\u4ef7\u503c\uff0c\u5176\u8868\u793a\u8fd8\u53ef\u4ee5\u5bfc\u51fa\u4e3a\u7ed3\u6784\u5316\u7279\u5f81\uff0c\u9002\u7528\u4e8e\u8d28\u91cf\u9884\u6d4b\u3001\u7a7a\u95f4\u97f3\u9891\u5206\u7c7b\u7b49\u673a\u5668\u5b66\u4e60\u6a21\u578b\u7684\u8bad\u7ec3\uff0c\u5e76\u4ee5\u5f00\u6e90\u8bb8\u53ef\u8bc1\u53d1\u5e03\u3002"}}
{"id": "2510.24738", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24738", "abs": "https://arxiv.org/abs/2510.24738", "authors": ["Tianheng Ling", "Chao Qian", "Peter Zdankin", "Torben Weis", "Gregor Schiele"], "title": "StrikeWatch: Wrist-worn Gait Recognition with Compact Time-series Models on Low-power FPGAs", "comment": "9 pages, 6 figures, 3 tables, accepted by IEEE Annual Congress on\n  Artificial Intelligence of Things (IEEE AIoT), 3-5 Dec 2025, Osaka Japan", "summary": "Running offers substantial health benefits, but improper gait patterns can\nlead to injuries, particularly without expert feedback. While prior gait\nanalysis systems based on cameras, insoles, or body-mounted sensors have\ndemonstrated effectiveness, they are often bulky and limited to offline,\npost-run analysis. Wrist-worn wearables offer a more practical and\nnon-intrusive alternative, yet enabling real-time gait recognition on such\ndevices remains challenging due to noisy Inertial Measurement Unit (IMU)\nsignals, limited computing resources, and dependence on cloud connectivity.\nThis paper introduces StrikeWatch, a compact wrist-worn system that performs\nentirely on-device, real-time gait recognition using IMU signals. As a case\nstudy, we target the detection of heel versus forefoot strikes to enable\nrunners to self-correct harmful gait patterns through visual and auditory\nfeedback during running. We propose four compact DL architectures (1D-CNN,\n1D-SepCNN, LSTM, and Transformer) and optimize them for energy-efficient\ninference on two representative embedded Field-Programmable Gate Arrays\n(FPGAs): the AMD Spartan-7 XC7S15 and the Lattice iCE40UP5K. Using our\ncustom-built hardware prototype, we collect a labeled dataset from outdoor\nrunning sessions and evaluate all models via a fully automated deployment\npipeline. Our results reveal clear trade-offs between model complexity and\nhardware efficiency. Evaluated across 12 participants, 6-bit quantized\n1D-SepCNN achieves the highest average F1 score of 0.847 while consuming just\n0.350 {\\mu}J per inference with a latency of 0.140 ms on the iCE40UP5K running\nat 20 MHz. This configuration supports up to 13.6 days of continuous inference\non a 320 mAh battery. All datasets and code are available in the GitHub\nrepository https://github.com/tianheng-ling/StrikeWatch.", "AI": {"tldr": "StrikeWatch\u662f\u4e00\u4e2a\u7d27\u51d1\u578b\u8155\u6234\u7cfb\u7edf\uff0c\u901a\u8fc7IMU\u4fe1\u53f7\u5728\u8bbe\u5907\u4e0a\u5b9e\u65f6\u8fdb\u884c\u6b65\u6001\u8bc6\u522b\uff0c\u4e13\u95e8\u68c0\u6d4b\u811a\u8ddf\u4e0e\u811a\u524d\u638c\u7740\u5730\u6a21\u5f0f\uff0c\u4e3a\u8dd1\u6b65\u8005\u63d0\u4f9b\u89c6\u89c9\u548c\u542c\u89c9\u53cd\u9988\u4ee5\u7ea0\u6b63\u6709\u5bb3\u6b65\u6001\u3002", "motivation": "\u8dd1\u6b65\u6709\u76ca\u5065\u5eb7\u4f46\u4e0d\u6b63\u786e\u7684\u6b65\u6001\u6a21\u5f0f\u53ef\u80fd\u5bfc\u81f4\u53d7\u4f24\uff0c\u73b0\u6709\u6b65\u6001\u5206\u6790\u7cfb\u7edf\u7b28\u91cd\u4e14\u4ec5\u9650\u4e8e\u79bb\u7ebf\u5206\u6790\u3002\u8155\u6234\u8bbe\u5907\u66f4\u5b9e\u7528\u4f46\u5b9e\u65f6\u6b65\u6001\u8bc6\u522b\u9762\u4e34IMU\u4fe1\u53f7\u566a\u58f0\u3001\u8ba1\u7b97\u8d44\u6e90\u6709\u9650\u548c\u4f9d\u8d56\u4e91\u8fde\u63a5\u7684\u6311\u6218\u3002", "method": "\u63d0\u51fa\u56db\u79cd\u7d27\u51d1\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff081D-CNN\u30011D-SepCNN\u3001LSTM\u548cTransformer\uff09\uff0c\u5728\u4e24\u4e2a\u5d4c\u5165\u5f0fFPGA\u4e0a\u4f18\u5316\u80fd\u6548\u63a8\u7406\uff0c\u4f7f\u7528\u5b9a\u5236\u786c\u4ef6\u539f\u578b\u6536\u96c6\u6237\u5916\u8dd1\u6b65\u6570\u636e\u96c6\uff0c\u901a\u8fc7\u81ea\u52a8\u5316\u90e8\u7f72\u7ba1\u9053\u8bc4\u4f30\u6240\u6709\u6a21\u578b\u3002", "result": "6\u4f4d\u91cf\u5316\u76841D-SepCNN\u5728iCE40UP5K\u4e0a\u5b9e\u73b0\u6700\u9ad8\u5e73\u5747F1\u5206\u65700.847\uff0c\u6bcf\u6b21\u63a8\u7406\u4ec5\u6d88\u80170.350\u03bcJ\uff0c\u5ef6\u8fdf0.140ms\uff0c\u652f\u6301320mAh\u7535\u6c60\u8fde\u7eed\u63a8\u740613.6\u5929\u3002", "conclusion": "\u7814\u7a76\u63ed\u793a\u4e86\u6a21\u578b\u590d\u6742\u5ea6\u548c\u786c\u4ef6\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u7d27\u51d1\u76841D-SepCNN\u67b6\u6784\u5728\u8d44\u6e90\u53d7\u9650\u7684\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u5b9e\u65f6\u6b65\u6001\u8bc6\u522b\u3002"}}
{"id": "2510.25745", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2510.25745", "abs": "https://arxiv.org/abs/2510.25745", "authors": ["Christodoulos Benetatos", "Yongyi Zang", "Randal Leistikow"], "title": "Efficient Vocal Source Separation Through Windowed Sink Attention", "comment": null, "summary": "State-of-the-art vocal separation models like Mel-Band-Roformer rely on full\ntemporal self-attention mechanisms, where each temporal frame interacts with\nevery other frames. This incurs heavy computational costs that scales\nquadratically with input audio length, motivating chunking and windowing\napproaches. Through analysis of a pre-trained vocal separation model, we\ndiscovered that temporal attention patterns are highly localized. Building on\nthis insight, we replaced full attention with windowed sink attention (WSA)\nwith small temporal attention window and attention sinks. We show empirically\nthat fine-tuning from the original checkpoint recovers 92% of the original SDR\nperformance while reducing FLOPs by 44.5x. We release our code and checkpoints\nunder MIT license at https://github.com/smulelabs/windowed-roformer.", "AI": {"tldr": "\u901a\u8fc7\u7528\u7a97\u53e3\u5316\u6ce8\u610f\u529b\u673a\u5236\u66ff\u4ee3\u5168\u65f6\u57df\u6ce8\u610f\u529b\uff0c\u5728\u4fdd\u630192%\u539f\u59cb\u6027\u80fd\u7684\u540c\u65f6\u5c06\u8ba1\u7b97\u91cf\u51cf\u5c1144.5\u500d", "motivation": "\u73b0\u6709\u8bed\u97f3\u5206\u79bb\u6a21\u578b\u4f7f\u7528\u5168\u65f6\u57df\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8ba1\u7b97\u6210\u672c\u968f\u97f3\u9891\u957f\u5ea6\u5448\u4e8c\u6b21\u65b9\u589e\u957f\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6ce8\u610f\u529b\u673a\u5236", "method": "\u5206\u6790\u9884\u8bad\u7ec3\u6a21\u578b\u53d1\u73b0\u6ce8\u610f\u529b\u6a21\u5f0f\u9ad8\u5ea6\u5c40\u90e8\u5316\uff0c\u4f7f\u7528\u7a97\u53e3\u5316\u6ce8\u610f\u529b\u914d\u5408\u6ce8\u610f\u529bsink\u673a\u5236\u66ff\u4ee3\u5168\u6ce8\u610f\u529b", "result": "\u4ece\u539f\u59cb\u68c0\u67e5\u70b9\u5fae\u8c03\u540e\u6062\u590d92%\u7684\u539f\u59cbSDR\u6027\u80fd\uff0c\u540c\u65f6FLOPs\u51cf\u5c1144.5\u500d", "conclusion": "\u7a97\u53e3\u5316\u6ce8\u610f\u529b\u673a\u5236\u80fd\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\u800c\u4fdd\u6301\u6027\u80fd\uff0c\u4e3a\u957f\u97f3\u9891\u5904\u7406\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2510.24740", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24740", "abs": "https://arxiv.org/abs/2510.24740", "authors": ["Nader Nemati"], "title": "Comparative Analysis of Data Augmentation for Clinical ECG Classification with STAR", "comment": "19 pages, 11 figures", "summary": "Clinical 12-lead ECG classification remains difficult because of diverse\nrecording conditions, overlapping pathologies, and pronounced label imbalance\nhinder generalization, while unconstrained augmentations risk distorting\ndiagnostically critical morphology. In this study, Sinusoidal Time--Amplitude\nResampling (STAR) is introduced as a beat-wise augmentation that operates\nstrictly between successive R-peaks to apply controlled time warping and\namplitude scaling to each R--R segment, preserving the canonical P--QRS--T\norder and leaving the head and tail of the trace unchanged. STAR is designed\nfor practical pipelines and offers: (i) morphology-faithful variability that\nbroadens training diversity without corrupting peaks or intervals; (ii)\nsource-resilient training, improving stability across devices, sites, and\ncohorts without dataset-specific tuning; (iii) model-agnostic integration with\ncommon 1D SE--ResNet-style ECG encoders backbone; and (iv) better learning on\nrare classes via beat-level augmentation, reducing overfitting by resampling\ninformative beats instead of duplicating whole records. In contrast to global\ncrops, large shifts, or additive noise, STAR avoids transformations that\nsuppress or misalign clinical landmarks. A complete Python implementation and a\ntransparent training workflow are released, aligned with a source-aware,\nstratified five-fold protocol over a multi-institutional 12-lead corpus,\nthereby facilitating inspection and reuse. Taken together, STAR provides a\nsimple and controllable augmentation for clinical ECG classification where\ntrustworthy morphology, operational simplicity, and cross-source durability are\nessential.", "AI": {"tldr": "STAR\u662f\u4e00\u79cd\u9488\u5bf912\u5bfc\u8054\u5fc3\u7535\u56fe\u7684\u8282\u62cd\u7ea7\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728R-R\u95f4\u671f\u8fdb\u884c\u53d7\u63a7\u65f6\u95f4\u626d\u66f2\u548c\u5e45\u5ea6\u7f29\u653e\uff0c\u4fdd\u6301P-QRS-T\u987a\u5e8f\u4e0d\u53d8\uff0c\u63d0\u5347\u6a21\u578b\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4e34\u5e8a12\u5bfc\u8054\u5fc3\u7535\u56fe\u5206\u7c7b\u9762\u4e34\u8bb0\u5f55\u6761\u4ef6\u591a\u6837\u3001\u75c5\u7406\u91cd\u53e0\u548c\u6807\u7b7e\u4e0d\u5e73\u8861\u7b49\u6311\u6218\uff0c\u4f20\u7edf\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\u53ef\u80fd\u626d\u66f2\u8bca\u65ad\u5173\u952e\u5f62\u6001\u3002", "method": "STAR\u5728\u8fde\u7eedR\u5cf0\u4e4b\u95f4\u8fdb\u884c\u64cd\u4f5c\uff0c\u5bf9\u6bcf\u4e2aR-R\u6bb5\u5e94\u7528\u65f6\u95f4\u626d\u66f2\u548c\u5e45\u5ea6\u7f29\u653e\uff0c\u4fdd\u6301\u5fc3\u7535\u56fe\u5f62\u6001\u5b8c\u6574\u6027\uff0c\u53ef\u4e0e\u5e38\u89c11D SE-ResNet\u98ce\u683c\u7f16\u7801\u5668\u96c6\u6210\u3002", "result": "STAR\u63d0\u4f9b\u5f62\u6001\u4fdd\u771f\u53d8\u5f02\u6027\uff0c\u63d0\u5347\u8de8\u8bbe\u5907\u3001\u7ad9\u70b9\u548c\u961f\u5217\u7684\u7a33\u5b9a\u6027\uff0c\u6539\u5584\u7f55\u89c1\u7c7b\u522b\u5b66\u4e60\u6548\u679c\uff0c\u907f\u514d\u4e34\u5e8a\u6807\u5fd7\u70b9\u9519\u4f4d\u3002", "conclusion": "STAR\u4e3a\u4e34\u5e8a\u5fc3\u7535\u56fe\u5206\u7c7b\u63d0\u4f9b\u7b80\u5355\u53ef\u63a7\u7684\u6570\u636e\u589e\u5f3a\u65b9\u6cd5\uff0c\u5728\u5f62\u6001\u53ef\u4fe1\u5ea6\u3001\u64cd\u4f5c\u7b80\u4fbf\u6027\u548c\u8de8\u6e90\u8010\u4e45\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2510.24744", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.24744", "abs": "https://arxiv.org/abs/2510.24744", "authors": ["Pranay Kocheta", "Nayan Sanjay Bhatia", "Katia Obraczka"], "title": "PulseFi: A Low Cost Robust Machine Learning System for Accurate Cardiopulmonary and Apnea Monitoring Using Channel State Information", "comment": "12 pages, 10 figures", "summary": "Non-intrusive monitoring of vital signs has become increasingly important in\na variety of healthcare settings. In this paper, we present PulseFi, a novel\nlow-cost non-intrusive system that uses Wi-Fi sensing and artificial\nintelligence to accurately and continuously monitor heart rate and breathing\nrate, as well as detect apnea events. PulseFi operates using low-cost commodity\ndevices, making it more accessible and cost-effective. It uses a signal\nprocessing pipeline to process Wi-Fi telemetry data, specifically Channel State\nInformation (CSI), that is fed into a custom low-compute Long Short-Term Memory\n(LSTM) neural network model. We evaluate PulseFi using two datasets: one that\nwe collected locally using ESP32 devices and another that contains recordings\nof 118 participants collected using the Raspberry Pi 4B, making the latter the\nmost comprehensive data set of its kind. Our results show that PulseFi can\neffectively estimate heart rate and breathing rate in a seemless non-intrusive\nway with comparable or better accuracy than multiple antenna systems that can\nbe expensive and less accessible.", "AI": {"tldr": "PulseFi\u662f\u4e00\u4e2a\u57fa\u4e8eWi-Fi\u611f\u77e5\u548c\u4eba\u5de5\u667a\u80fd\u7684\u4f4e\u6210\u672c\u975e\u4fb5\u5165\u5f0f\u7cfb\u7edf\uff0c\u7528\u4e8e\u51c6\u786e\u8fde\u7eed\u76d1\u6d4b\u5fc3\u7387\u548c\u547c\u5438\u7387\uff0c\u5e76\u68c0\u6d4b\u547c\u5438\u6682\u505c\u4e8b\u4ef6\u3002", "motivation": "\u975e\u4fb5\u5165\u5f0f\u751f\u547d\u4f53\u5f81\u76d1\u6d4b\u5728\u533b\u7597\u4fdd\u5065\u73af\u5883\u4e2d\u53d8\u5f97\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u9700\u8981\u66f4\u6613\u83b7\u53d6\u4e14\u6210\u672c\u6548\u76ca\u9ad8\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528Wi-Fi\u9065\u6d4b\u6570\u636e\uff08\u7279\u522b\u662f\u4fe1\u9053\u72b6\u6001\u4fe1\u606fCSI\uff09\uff0c\u901a\u8fc7\u4fe1\u53f7\u5904\u7406\u6d41\u7a0b\uff0c\u8f93\u5165\u5230\u5b9a\u5236\u7684\u4f4e\u8ba1\u7b97\u91cfLSTM\u795e\u7ecf\u7f51\u7edc\u6a21\u578b\u4e2d\u3002", "result": "\u5728\u4e24\u4e2a\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\u663e\u793a\uff0cPulseFi\u80fd\u591f\u6709\u6548\u4f30\u8ba1\u5fc3\u7387\u548c\u547c\u5438\u7387\uff0c\u51c6\u786e\u5ea6\u4e0e\u6602\u8d35\u591a\u5929\u7ebf\u7cfb\u7edf\u76f8\u5f53\u6216\u66f4\u597d\u3002", "conclusion": "PulseFi\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u7f1d\u975e\u4fb5\u5165\u5f0f\u7684\u751f\u547d\u4f53\u5f81\u76d1\u6d4b\u65b9\u6cd5\uff0c\u4f7f\u7528\u4f4e\u6210\u672c\u5546\u7528\u8bbe\u5907\uff0c\u6bd4\u6602\u8d35\u7cfb\u7edf\u66f4\u6613\u83b7\u53d6\u3002"}}
{"id": "2510.25193", "categories": ["eess.SP", "cs.SD"], "pdf": "https://arxiv.org/pdf/2510.25193", "abs": "https://arxiv.org/abs/2510.25193", "authors": ["Qi You", "Qinghua Huang", "Yi-Cheng Lin"], "title": "State Space and Self-Attention Collaborative Network with Feature Aggregation for DOA Estimation", "comment": null, "summary": "Accurate direction-of-arrival (DOA) estimation for sound sources is\nchallenging due to the continuous changes in acoustic characteristics across\ntime and frequency. In such scenarios, accurate localization relies on the\nability to aggregate relevant features and model temporal dependencies\neffectively. In time series modeling, achieving a balance between model\nperformance and computational efficiency remains a significant challenge. To\naddress this, we propose FA-Stateformer, a state space and self-attention\ncollaborative network with feature aggregation. The proposed network first\nemploys a feature aggregation module to enhance informative features across\nboth temporal and spectral dimensions. This is followed by a lightweight\nConformer architecture inspired by the squeeze-and-excitation mechanism, where\nthe feedforward layers are compressed to reduce redundancy and parameter\noverhead. Additionally, a temporal shift mechanism is incorporated to expand\nthe receptive field of convolutional layers while maintaining a compact kernel\nsize. To further enhance sequence modeling capabilities, a bidirectional Mamba\nmodule is introduced, enabling efficient state-space-based representation of\ntemporal dependencies in both forward and backward directions. The remaining\nself-attention layers are combined with the Mamba blocks, forming a\ncollaborative modeling framework that achieves a balance between representation\ncapacity and computational efficiency. Extensive experiments demonstrate that\nFA-Stateformer achieves superior performance and efficiency compared to\nconventional architectures.", "AI": {"tldr": "FA-Stateformer\u662f\u4e00\u4e2a\u7ed3\u5408\u72b6\u6001\u7a7a\u95f4\u548c\u81ea\u6ce8\u610f\u529b\u673a\u5236\u7684\u58f0\u97f3\u6e90\u5230\u8fbe\u65b9\u5411\u4f30\u8ba1\u7f51\u7edc\uff0c\u901a\u8fc7\u7279\u5f81\u805a\u5408\u3001\u8f7b\u91cf\u5316Conformer\u67b6\u6784\u3001\u65f6\u95f4\u79fb\u4f4d\u673a\u5236\u548c\u53cc\u5411Mamba\u6a21\u5757\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u58f0\u97f3\u6e90\u5230\u8fbe\u65b9\u5411\u4f30\u8ba1\u9762\u4e34\u58f0\u5b66\u7279\u5f81\u968f\u65f6\u95f4\u9891\u7387\u8fde\u7eed\u53d8\u5316\u7684\u6311\u6218\uff0c\u9700\u8981\u6709\u6548\u805a\u5408\u76f8\u5173\u7279\u5f81\u5e76\u5efa\u6a21\u65f6\u95f4\u4f9d\u8d56\u6027\uff0c\u540c\u65f6\u5e73\u8861\u6a21\u578b\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u63d0\u51faFA-Stateformer\u7f51\u7edc\uff1a1) \u7279\u5f81\u805a\u5408\u6a21\u5757\u589e\u5f3a\u65f6\u9891\u7ef4\u5ea6\u4fe1\u606f\u7279\u5f81\uff1b2) \u8f7b\u91cf\u5316Conformer\u67b6\u6784\u538b\u7f29\u524d\u9988\u5c42\u51cf\u5c11\u5197\u4f59\uff1b3) \u65f6\u95f4\u79fb\u4f4d\u673a\u5236\u6269\u5c55\u5377\u79ef\u611f\u53d7\u91ce\uff1b4) \u53cc\u5411Mamba\u6a21\u5757\u9ad8\u6548\u5efa\u6a21\u53cc\u5411\u65f6\u95f4\u4f9d\u8d56\uff1b5) \u81ea\u6ce8\u610f\u529b\u5c42\u4e0eMamba\u5757\u534f\u540c\u5efa\u6a21\u3002", "result": "\u5927\u91cf\u5b9e\u9a8c\u8868\u660eFA-Stateformer\u76f8\u6bd4\u4f20\u7edf\u67b6\u6784\u5b9e\u73b0\u4e86\u66f4\u4f18\u8d8a\u7684\u6027\u80fd\u548c\u6548\u7387\u3002", "conclusion": "FA-Stateformer\u901a\u8fc7\u72b6\u6001\u7a7a\u95f4\u548c\u81ea\u6ce8\u610f\u529b\u7684\u534f\u540c\u5efa\u6a21\u6846\u67b6\uff0c\u5728\u58f0\u97f3\u6e90\u5230\u8fbe\u65b9\u5411\u4f30\u8ba1\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u8868\u793a\u80fd\u529b\u548c\u8ba1\u7b97\u6548\u7387\u7684\u826f\u597d\u5e73\u8861\u3002"}}
{"id": "2510.24748", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.24748", "abs": "https://arxiv.org/abs/2510.24748", "authors": ["Dong-Hyeon Kang", "Ju-Hyeon Nam", "Sang-Chul Lee"], "title": "EcoScaleNet: A Lightweight Multi Kernel Network for Long Sequence 12 lead ECG Classification", "comment": "MICCAI Workshop on Efficient Medical AI (EMA)", "summary": "Accurate interpretation of 12 lead electrocardiograms (ECGs) is critical for\nearly detection of cardiac abnormalities, yet manual reading is error prone and\nexisting CNN based classifiers struggle to choose receptive field sizes that\ngeneralize to the long sequences typical of ECGs. Omni Scale CNN (OS CNN)\naddresses this by enumerating prime sized kernels inspired by Goldbach\nconjecture to cover every scale, but its exhaustive design explodes\ncomputational cost and blocks deeper, wider models. We present Efficient\nConvolutional Omni Scale Network (EcoScale-Net), a hierarchical variant that\nretains full receptive field coverage while eliminating redundancy. At each\nstage, the maximum kernel length is capped to the scale still required after\ndown sampling, and bottleneck convolutions inserted before and after every Omni\nScale block curtail channel growth and fuse multi scale features. On the large\nscale CODE 15% ECG dataset, EcoScaleNet reduces parameters by 90% and FLOPs by\n99% compared with OS CNN, while raising macro averaged F1 score by 2.4%. These\nresults demonstrate that EcoScaleNet delivers SOTA accuracy for long sequence\nECG classification at a fraction of the computational cost, enabling real time\ndeployment on commodity hardware. Our EcoScaleNet code is available in GitHub\nLink.", "AI": {"tldr": "EcoScaleNet\u662f\u4e00\u79cd\u9ad8\u6548\u7684\u5377\u79ef\u5168\u5c3a\u5ea6\u7f51\u7edc\uff0c\u901a\u8fc7\u5206\u5c42\u8bbe\u8ba1\u548c\u74f6\u9888\u5377\u79ef\uff0c\u5728\u4fdd\u6301\u5168\u611f\u53d7\u91ce\u8986\u76d6\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u5728ECG\u5206\u7c7b\u4efb\u52a1\u4e2d\u5b9e\u73b0SOTA\u7cbe\u5ea6\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709CNN\u5728ECG\u957f\u5e8f\u5217\u5206\u7c7b\u4e2d\u611f\u53d7\u91ce\u9009\u62e9\u56f0\u96be\u7684\u95ee\u9898\uff0c\u540c\u65f6\u514b\u670dOmni Scale CNN\u8ba1\u7b97\u6210\u672c\u8fc7\u9ad8\u3001\u963b\u788d\u66f4\u6df1\u66f4\u5bbd\u6a21\u578b\u7684\u7f3a\u9677\u3002", "method": "\u91c7\u7528\u5206\u5c42\u53d8\u4f53\u8bbe\u8ba1\uff0c\u6bcf\u9636\u6bb5\u9650\u5236\u6700\u5927\u6838\u957f\u5ea6\u4ee5\u51cf\u5c11\u5197\u4f59\uff1b\u5728Omni Scale\u5757\u524d\u540e\u63d2\u5165\u74f6\u9888\u5377\u79ef\u6765\u63a7\u5236\u901a\u9053\u589e\u957f\u548c\u878d\u5408\u591a\u5c3a\u5ea6\u7279\u5f81\u3002", "result": "\u5728CODE 15% ECG\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4OS CNN\u51cf\u5c1190%\u53c2\u6570\u548c99%FLOPs\uff0c\u540c\u65f6\u5c06\u5b8f\u5e73\u5747F1\u5206\u6570\u63d0\u53472.4%\u3002", "conclusion": "EcoScaleNet\u4ee5\u6781\u4f4e\u8ba1\u7b97\u6210\u672c\u5b9e\u73b0\u4e86\u957f\u5e8f\u5217ECG\u5206\u7c7b\u7684SOTA\u7cbe\u5ea6\uff0c\u53ef\u5728\u666e\u901a\u786c\u4ef6\u4e0a\u5b9e\u65f6\u90e8\u7f72\u3002"}}
{"id": "2510.24750", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24750", "abs": "https://arxiv.org/abs/2510.24750", "authors": ["Shun Huang", "Deyun Zhang", "Sumei Fan", "Shijia Geng", "Yujie Xiao", "Rui Zhang", "Zhaoji Fu", "Shenda Hong"], "title": "Opportunistic Screening of Wolff-Parkinson-White Syndrome using Single-Lead AI-ECG Mobile System: A Real-World Study of over 3.5 million ECG Recordings in China", "comment": null, "summary": "Wolff-Parkinson-White (WPW) syndrome is a congenital cardiac condition\nassociated with sudden cardiac death, with a prevalence of 0.1-0.3%.\nConventional screening relies on electrophysiological testing or 12-lead\nelectrocardiography interpreted by cardiologists, which limits large-scale and\ncost-effective screening. Building on our previous work developing a\nsingle-lead AI-ECG mobile system for atrial fibrillation screening, this study\nevaluates its efficiency and effectiveness for opportunistic detection of WPW\nsyndrome in real-world settings. This retrospective analysis included 3,566,626\nsingle-lead ECG recordings from 87,836 individuals in China, collected using\nthe NMPA-approved portable ECG device WenXinWuYang. The AI system performance\nwas validated using cardiologist annotations and random sampling. We quantified\nAI-assisted workload reduction and compared review efficiency across\nAI-positive and user-initiated workflows. The AI system achieved 45.5%\nsensitivity and 95.9% specificity. A positive AI result indicated about 210\ntimes higher risk of confirmed WPW. Focusing on AI-selected positives reduced\nphysician workload by 99.5%, requiring only 12 reviews to confirm one WPW case,\ncompared with 909 and 875 in population-wide and user-driven approaches. In\nconclusion, this large-scale real-world study demonstrates that a single-lead\nAI-ECG system enables efficient and practical opportunistic screening for WPW\nsyndrome, significantly reducing physician workload and supporting\npopulation-based cardiovascular prevention.", "AI": {"tldr": "\u672c\u7814\u7a76\u8bc4\u4f30\u4e86\u5355\u5bfc\u8054AI-ECG\u79fb\u52a8\u7cfb\u7edf\u5728\u771f\u5b9e\u4e16\u754c\u73af\u5883\u4e2d\u5bf9WPW\u7efc\u5408\u5f81\u7684\u673a\u4f1a\u6027\u68c0\u6d4b\u6548\u7387\uff0c\u7ed3\u679c\u663e\u793aAI\u7cfb\u7edf\u80fd\u663e\u8457\u51cf\u5c11\u533b\u751f\u5de5\u4f5c\u91cf99.5%\uff0c\u4ec5\u970012\u6b21\u5ba1\u67e5\u5373\u53ef\u786e\u8ba4\u4e00\u4f8bWPW\u75c5\u4f8b\u3002", "motivation": "WPW\u7efc\u5408\u5f81\u662f\u4e00\u79cd\u4e0e\u5fc3\u6e90\u6027\u731d\u6b7b\u76f8\u5173\u7684\u5148\u5929\u6027\u5fc3\u810f\u75c5\uff0c\u4f20\u7edf\u7b5b\u67e5\u65b9\u6cd5\u4f9d\u8d56\u5fc3\u7535\u56fe\u89e3\u8bfb\uff0c\u9650\u5236\u4e86\u5927\u89c4\u6a21\u548c\u6210\u672c\u6548\u76ca\u7684\u7b5b\u67e5\u3002", "method": "\u56de\u987e\u6027\u5206\u6790\u5305\u542b\u6765\u81ea87,836\u540d\u4e2d\u56fd\u4e2a\u4f53\u76843,566,626\u4efd\u5355\u5bfc\u8054ECG\u8bb0\u5f55\uff0c\u4f7f\u7528NMPA\u6279\u51c6\u7684\u4fbf\u643a\u5f0fECG\u8bbe\u5907\uff0c\u901a\u8fc7AI\u7cfb\u7edf\u6027\u80fd\u9a8c\u8bc1\u548c\u968f\u673a\u62bd\u6837\u8bc4\u4f30\u3002", "result": "AI\u7cfb\u7edf\u8fbe\u523045.5%\u7684\u654f\u611f\u6027\u548c95.9%\u7684\u7279\u5f02\u6027\uff0cAI\u9633\u6027\u7ed3\u679c\u4f7f\u786e\u8ba4WPW\u7684\u98ce\u9669\u589e\u52a0\u7ea6210\u500d\uff0cAI\u9009\u62e9\u9633\u6027\u53ef\u5c06\u533b\u751f\u5de5\u4f5c\u91cf\u51cf\u5c1199.5%\u3002", "conclusion": "\u5355\u5bfc\u8054AI-ECG\u7cfb\u7edf\u80fd\u591f\u5b9e\u73b0\u9ad8\u6548\u5b9e\u7528\u7684WPW\u7efc\u5408\u5f81\u673a\u4f1a\u6027\u7b5b\u67e5\uff0c\u663e\u8457\u51cf\u5c11\u533b\u751f\u5de5\u4f5c\u91cf\uff0c\u652f\u6301\u57fa\u4e8e\u4eba\u7fa4\u7684\u5fc3\u8840\u7ba1\u9884\u9632\u3002"}}
{"id": "2510.24890", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24890", "abs": "https://arxiv.org/abs/2510.24890", "authors": ["Dilara Aktas", "Ozgur B. Akan"], "title": "A Cylindrical Nanowire Array-Based Flexure-FET Receiver for Molecular Communication", "comment": null, "summary": "Molecular communication (MC) enables biocompatible and energy-efficient\ninformation transfer through chemical signaling, forming a foundational\nparadigm for emerging applications in the Internet of Nano Things (IoNT) and\nintrabody healthcare systems. The realization of this vision critically depends\non developing advanced receiver architectures that merge nanoscale\ncommunication and networking techniques with bio-cyber interfaces, ensuring\nenergy-efficient, reliable, and low-complexity modulation and detection while\nmaintaining biocompatibility. To address these challenges, the Flexure-FET MC\nreceiver was introduced as a mechanically transducing design capable of\ndetecting both charged and neutral molecular species. In this study, we present\na cylindrical nanowire array-based Flexure-FET MC receiver that enhances design\nversatility and scalability through distributed electromechanical coupling in a\nsuspended-gate configuration. The proposed array architecture offers additional\ngeometric degrees of freedom, including nanowire radius, length, spacing, and\narray size, providing a flexible framework that can be tailored to advanced MC\nscenarios. An analytical end-to-end model is developed to characterize the\nsystem's electromechanical response, noise behavior, and information-theoretic\nperformance, including signal-to-noise ratio (SNR) and channel capacity. The\nresults reveal the strong interdependence between geometry, electromechanical\ndynamics, and molecular binding processes, enabling tunable control over\nsensitivity, noise characteristics, and communication capacity. The enhanced\nstructural tunability and array configuration of the proposed design provide a\nflexible foundation for future mixture-based and spatially modulated MC\nsystems, paving the way toward scalable and multifunctional receiver\narchitectures within the IoNT framework.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5706\u67f1\u5f62\u7eb3\u7c73\u7ebf\u9635\u5217\u7684Flexure-FET\u5206\u5b50\u901a\u4fe1\u63a5\u6536\u5668\uff0c\u901a\u8fc7\u5206\u5e03\u5f0f\u673a\u7535\u8026\u5408\u589e\u5f3a\u8bbe\u8ba1\u7075\u6d3b\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3aIoNT\u63d0\u4f9b\u53ef\u8c03\u8c10\u7684\u63a5\u6536\u5668\u67b6\u6784\u3002", "motivation": "\u5206\u5b50\u901a\u4fe1\u662f\u7269\u8054\u7f51\u7eb3\u7c73\u6280\u672f\u548c\u4f53\u5185\u533b\u7597\u7cfb\u7edf\u7684\u5173\u952e\u8303\u5f0f\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u540c\u65f6\u68c0\u6d4b\u5e26\u7535\u548c\u4e2d\u6027\u5206\u5b50\u3001\u5177\u6709\u751f\u7269\u76f8\u5bb9\u6027\u4e14\u80fd\u6548\u9ad8\u7684\u5148\u8fdb\u63a5\u6536\u5668\u67b6\u6784\u3002", "method": "\u91c7\u7528\u60ac\u6d6e\u6805\u914d\u7f6e\u7684\u5706\u67f1\u5f62\u7eb3\u7c73\u7ebf\u9635\u5217\u7ed3\u6784\uff0c\u5f00\u53d1\u5206\u6790\u6027\u7aef\u5230\u7aef\u6a21\u578b\u6765\u8868\u5f81\u7cfb\u7edf\u7684\u673a\u7535\u54cd\u5e94\u3001\u566a\u58f0\u884c\u4e3a\u548c\u4fe1\u606f\u7406\u8bba\u6027\u80fd\u3002", "result": "\u7ed3\u679c\u663e\u793a\u51e0\u4f55\u5f62\u72b6\u3001\u673a\u7535\u52a8\u529b\u5b66\u548c\u5206\u5b50\u7ed3\u5408\u8fc7\u7a0b\u4e4b\u95f4\u5b58\u5728\u5f3a\u76f8\u4e92\u4f9d\u8d56\u6027\uff0c\u80fd\u591f\u5b9e\u73b0\u5bf9\u7075\u654f\u5ea6\u3001\u566a\u58f0\u7279\u6027\u548c\u901a\u4fe1\u5bb9\u91cf\u7684\u53ef\u8c03\u63a7\u5236\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u7684\u589e\u5f3a\u7ed3\u6784\u53ef\u8c03\u6027\u548c\u9635\u5217\u914d\u7f6e\u4e3a\u672a\u6765\u57fa\u4e8e\u6df7\u5408\u548c\u7a7a\u95f4\u8c03\u5236\u7684\u5206\u5b50\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7075\u6d3b\u57fa\u7840\uff0c\u63a8\u52a8\u4e86IoNT\u6846\u67b6\u5185\u53ef\u6269\u5c55\u591a\u529f\u80fd\u63a5\u6536\u5668\u67b6\u6784\u7684\u53d1\u5c55\u3002"}}
{"id": "2510.24928", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24928", "abs": "https://arxiv.org/abs/2510.24928", "authors": ["Anwar Ahmed Khan", "Farid Nait-Abdesselam", "Indrakshi Dey"], "title": "Next-Generation MAC Technique for Priority Handling in Industrial Cyber-Physical Systems", "comment": "Int. Conference on Computer, Information and Telecommunication\n  Systems (CITS 2025), Colmar, France", "summary": "Next Generation Media Access Control (NGMA) techniques have been designed to\nsupport diverse applications with heterogeneous priorities. In industrial\ncyber-physical systems (CPS), the number of connected devices and systems is\nexpected to grow significantly, demanding dependable and prompt network\nservices. In this work, we present a novel scheme, Dynamic Fragmentation-MAC\n(DyFrag-MAC) that offers dynamic, differentiated channel access to the traffic\nof various priorities. DyFrag-MAC works on fragmenting the data of normal\npriority in order to support early delivery of urgent priority data. In prior\nwork, urgent priority data either had to wait for the complete transmission of\nlower-priority packets or relied on multi-channel protocols to gain access. We\ncompared the proposed fragmentation scheme with FROG-MAC and industrial\nDeterministic and Synchronous Multi-channel Extension (i-DSME). FROG-MAC\nfragmented the lower priority packets, but did not adjust the fragment size\ndynamically, whereas i-DSME utilized multiple channels and adaptive contention\nmechanisms; both protocols lack the ability to preempt ongoing lower-priority\ntransmissions. Hence, the performance evaluation in terms of average delay and\nthroughput reveals better performance of DyFRAG-MAC for the heterogeneous\ntraffic.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u540d\u4e3aDyFrag-MAC\u7684\u52a8\u6001\u5206\u7247MAC\u65b9\u6848\uff0c\u4e3a\u4e0d\u540c\u4f18\u5148\u7ea7\u7684\u6d41\u91cf\u63d0\u4f9b\u5dee\u5f02\u5316\u4fe1\u9053\u63a5\u5165\uff0c\u901a\u8fc7\u52a8\u6001\u5206\u7247\u666e\u901a\u4f18\u5148\u7ea7\u6570\u636e\u6765\u652f\u6301\u7d27\u6025\u4f18\u5148\u7ea7\u6570\u636e\u7684\u65e9\u671f\u4f20\u8f93\u3002", "motivation": "\u5de5\u4e1a\u4fe1\u606f\u7269\u7406\u7cfb\u7edf\u4e2d\u8fde\u63a5\u8bbe\u5907\u6570\u91cf\u6fc0\u589e\uff0c\u9700\u8981\u53ef\u9760\u548c\u53ca\u65f6\u7684\u7f51\u7edc\u670d\u52a1\uff0c\u73b0\u6709\u534f\u8bae\u65e0\u6cd5\u52a8\u6001\u8c03\u6574\u5206\u7247\u5927\u5c0f\u6216\u62a2\u5360\u4f4e\u4f18\u5148\u7ea7\u4f20\u8f93\u3002", "method": "DyFrag-MAC\u901a\u8fc7\u52a8\u6001\u5206\u7247\u666e\u901a\u4f18\u5148\u7ea7\u6570\u636e\uff0c\u5141\u8bb8\u7d27\u6025\u4f18\u5148\u7ea7\u6570\u636e\u5728\u4f4e\u4f18\u5148\u7ea7\u6570\u636e\u4f20\u8f93\u8fc7\u7a0b\u4e2d\u83b7\u5f97\u4fe1\u9053\u63a5\u5165\u673a\u4f1a\u3002", "result": "\u4e0eFROG-MAC\u548ci-DSME\u76f8\u6bd4\uff0cDyFrag-MAC\u5728\u5f02\u6784\u6d41\u91cf\u4e0b\u7684\u5e73\u5747\u5ef6\u8fdf\u548c\u541e\u5410\u91cf\u6027\u80fd\u8868\u73b0\u66f4\u4f18\u3002", "conclusion": "DyFrag-MAC\u65b9\u6848\u80fd\u591f\u6709\u6548\u652f\u6301\u5de5\u4e1aCPS\u4e2d\u5f02\u6784\u4f18\u5148\u7ea7\u6d41\u91cf\u7684\u5dee\u5f02\u5316\u670d\u52a1\u9700\u6c42\uff0c\u63d0\u4f9b\u66f4\u597d\u7684\u7f51\u7edc\u6027\u80fd\u3002"}}
{"id": "2510.24931", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.24931", "abs": "https://arxiv.org/abs/2510.24931", "authors": ["Shama Sidiqui", "Indrakshi Dey"], "title": "Optimizing Next Generation Wireless BAN with Prioritized Access for Heterogeneous Traffic", "comment": "Int. Conference on Computer, Information and Telecommunication\n  Systems (CITS 2025), Colmar, France", "summary": "Efficient management of heterogeneous traffic with varying priorities is\ncritical in Wireless Body Area Networks (WBANs). The priority mechanisms\nembedded in Media Access Control (MAC) schemes largely govern the performance\nof WBAN in terms of reliability, delay and energy efficiency. Minimizing the\ndelay between packet generation and reception is critical for enhancing WBAN\nperformance and associated health outcomes; however, delay optimization must be\ntailored to each traffic priority. In this work, we proposed a novel\npriority-based MAC protocol, Adaptive and Dynamic Polling MAC for Prioritized\nTraffic (ADP2-MAC), designed to support heterogeneous traffic in WBANs. The\nprotocol utilizes a probabilistic approach to dynamically determine channel\npolling/listening intervals. ADP2-MAC not only identifies traffic arrival\npatterns to determine optimal polling intervals but also interrupts the\ntransmission of lower-priority data when urgent packets are expected. The\nperformance of ADP2-MAC has been compared with the MAC protocol for Variable\nData Rates (MVDR) which supports heterogeneous traffic by assigning different\ndata rates based on traffic priority. ADP2-MAC outperforms MVDR due to its use\nof probabilistic polling intervals and an interruption mechanism designed to\nefficiently handle urgent-priority data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u57fa\u4e8e\u4f18\u5148\u7ea7\u7684MAC\u534f\u8baeADP2-MAC\uff0c\u7528\u4e8e\u65e0\u7ebf\u4f53\u57df\u7f51\u4e2d\u5f02\u6784\u6d41\u91cf\u7684\u9ad8\u6548\u7ba1\u7406\uff0c\u901a\u8fc7\u6982\u7387\u6027\u65b9\u6cd5\u52a8\u6001\u786e\u5b9a\u4fe1\u9053\u8f6e\u8be2\u95f4\u9694\uff0c\u5e76\u5728\u9884\u671f\u7d27\u6025\u6570\u636e\u5305\u65f6\u4e2d\u65ad\u4f4e\u4f18\u5148\u7ea7\u4f20\u8f93\u3002", "motivation": "\u65e0\u7ebf\u4f53\u57df\u7f51\u4e2d\u5f02\u6784\u6d41\u91cf\u5177\u6709\u4e0d\u540c\u4f18\u5148\u7ea7\uff0c\u9700\u8981\u9ad8\u6548\u7ba1\u7406\u4ee5\u4f18\u5316\u53ef\u9760\u6027\u3001\u5ef6\u8fdf\u548c\u80fd\u6548\u3002\u6700\u5c0f\u5316\u6570\u636e\u5305\u751f\u6210\u5230\u63a5\u6536\u7684\u5ef6\u8fdf\u5bf9\u63d0\u5347WBAN\u6027\u80fd\u548c\u5065\u5eb7\u7ed3\u679c\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u5ef6\u8fdf\u4f18\u5316\u9700\u8981\u9488\u5bf9\u4e0d\u540c\u6d41\u91cf\u4f18\u5148\u7ea7\u8fdb\u884c\u5b9a\u5236\u3002", "method": "ADP2-MAC\u534f\u8bae\u91c7\u7528\u6982\u7387\u6027\u65b9\u6cd5\u52a8\u6001\u786e\u5b9a\u4fe1\u9053\u8f6e\u8be2/\u76d1\u542c\u95f4\u9694\uff0c\u8bc6\u522b\u6d41\u91cf\u5230\u8fbe\u6a21\u5f0f\u4ee5\u786e\u5b9a\u6700\u4f18\u8f6e\u8be2\u95f4\u9694\uff0c\u5e76\u5728\u9884\u671f\u7d27\u6025\u6570\u636e\u5305\u65f6\u4e2d\u65ad\u4f4e\u4f18\u5148\u7ea7\u6570\u636e\u7684\u4f20\u8f93\u3002", "result": "\u4e0e\u652f\u6301\u5f02\u6784\u6d41\u91cf\u7684MVDR\u534f\u8bae\u76f8\u6bd4\uff0cADP2-MAC\u8868\u73b0\u66f4\u4f18\uff0c\u8fd9\u5f97\u76ca\u4e8e\u5176\u6982\u7387\u6027\u8f6e\u8be2\u95f4\u9694\u548c\u65e8\u5728\u9ad8\u6548\u5904\u7406\u7d27\u6025\u4f18\u5148\u7ea7\u6570\u636e\u7684\u4e2d\u65ad\u673a\u5236\u3002", "conclusion": "ADP2-MAC\u534f\u8bae\u901a\u8fc7\u52a8\u6001\u8f6e\u8be2\u95f4\u9694\u548c\u4f18\u5148\u7ea7\u4e2d\u65ad\u673a\u5236\uff0c\u80fd\u591f\u6709\u6548\u652f\u6301\u65e0\u7ebf\u4f53\u57df\u7f51\u4e2d\u7684\u5f02\u6784\u6d41\u91cf\u7ba1\u7406\uff0c\u5728\u5ef6\u8fdf\u4f18\u5316\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u534f\u8bae\u3002"}}
{"id": "2510.25020", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25020", "abs": "https://arxiv.org/abs/2510.25020", "authors": ["Minti Liu", "Qinghua Guo", "Cao Zeng", "Yanguang Yu", "Jun Li", "Ming Jin"], "title": "Hybrid Liquid Neural Network-Random Finite Set Filtering for Robust Maneuvering Object Tracking", "comment": "This manuscript has been submitted to the IEEE Transactions on\n  Aerospace and Electronic Systems (TAES) Correspondence", "summary": "This work addresses the problem of tracking maneuvering objects with complex\nmotion patterns, a task in which conventional methods often struggle due to\ntheir reliance on predefined motion models. We integrate a data-driven liquid\nneural network (LNN) into the random finite set (RFS) framework, leading to two\nLNN-RFS filters. By learning continuous-time dynamics directly from data, the\nLNN enables the filters to adapt to complex, nonlinear motion and achieve\naccurate tracking of highly maneuvering objects in clutter. This hybrid\napproach preserves the inherent multi-object tracking strengths of the RFS\nframework while improving flexibility and robustness. Simulation results on\nchallenging maneuvering scenarios demonstrate substantial gains of the proposed\nhybrid approach in tracking accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408\u6db2\u4f53\u795e\u7ecf\u7f51\u7edc\u548c\u968f\u673a\u6709\u9650\u96c6\u6846\u67b6\u7684\u6df7\u5408\u65b9\u6cd5\uff0c\u7528\u4e8e\u8ddf\u8e2a\u5177\u6709\u590d\u6742\u8fd0\u52a8\u6a21\u5f0f\u7684\u673a\u52a8\u76ee\u6807\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5728\u8ddf\u8e2a\u7cbe\u5ea6\u4e0a\u6709\u663e\u8457\u63d0\u5347\u3002", "motivation": "\u4f20\u7edf\u8ddf\u8e2a\u65b9\u6cd5\u4f9d\u8d56\u9884\u5b9a\u4e49\u8fd0\u52a8\u6a21\u578b\uff0c\u5728\u5904\u7406\u590d\u6742\u673a\u52a8\u76ee\u6807\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u6765\u9002\u5e94\u975e\u7ebf\u6027\u8fd0\u52a8\u6a21\u5f0f\u3002", "method": "\u5c06\u6570\u636e\u9a71\u52a8\u7684\u6db2\u4f53\u795e\u7ecf\u7f51\u7edc\u96c6\u6210\u5230\u968f\u673a\u6709\u9650\u96c6\u6846\u67b6\u4e2d\uff0c\u5f00\u53d1\u4e86\u4e24\u79cdLNN-RFS\u6ee4\u6ce2\u5668\uff0c\u76f4\u63a5\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u8fde\u7eed\u65f6\u95f4\u52a8\u529b\u5b66\u3002", "result": "\u5728\u5177\u6709\u6311\u6218\u6027\u7684\u673a\u52a8\u573a\u666f\u4eff\u771f\u4e2d\uff0c\u6240\u63d0\u51fa\u7684\u6df7\u5408\u65b9\u6cd5\u5728\u8ddf\u8e2a\u7cbe\u5ea6\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u63d0\u5347\uff0c\u80fd\u591f\u51c6\u786e\u8ddf\u8e2a\u9ad8\u673a\u52a8\u76ee\u6807\u3002", "conclusion": "\u8fd9\u79cd\u6df7\u5408\u65b9\u6cd5\u4fdd\u6301\u4e86RFS\u6846\u67b6\u56fa\u6709\u7684\u591a\u76ee\u6807\u8ddf\u8e2a\u4f18\u52bf\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u7075\u6d3b\u6027\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u590d\u6742\u673a\u52a8\u76ee\u6807\u8ddf\u8e2a\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25192", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25192", "abs": "https://arxiv.org/abs/2510.25192", "authors": ["Zihao Zhou", "Zhaolin Wang", "Yuanwei Liu"], "title": "Spectral and Energy Efficiency Tradeoff for Pinching-Antenna Systems", "comment": null, "summary": "The joint transmit and pinching beamforming design for spectral efficiency\n(SE) and energy efficiency (EE) tradeoff in pinching-antenna systems (PASS) is\nproposed. Both PASS-enabled single- and multi-user communications are\nconsidered. In the single-user scenario, it is proved that the optimal pinching\nantenna (PA) positions are independent of the transmit beamforming. Based on\nthis insight, a two-stage joint beamforming design is proposed. Specifically,\nin the first stage, an iterative closed-form refinement (ICR) scheme is\nproposed to align the phases of the received signals, based on which a PA\nplacement framework is proposed. In the second stage, the closed-form solution\nfor the optimal transmit beamformer is derived given the optimal PA positions.\nIn the multi-user scenario, an alternating optimization (AO)-based joint\nbeamforming design is proposed to balance the SE-EE performance while taking\nthe quality-of-service (QoS) requirements into account. It is proved that the\nproposed AO-based algorithm is guaranteed to converge when no constraints are\nviolated in PA placement subproblem. Numerical results demonstrate that: 1) the\nproposed algorithms significantly improve joint SE-EE performance with fast\nconvergence speed; 2) the SE-EE tradeoff regime gap between PASS and\nconventional multi-antenna system widens as the number of PAs and service\ncoverage increase.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7528\u4e8e\u5939\u6301\u5929\u7ebf\u7cfb\u7edf(PASS)\u4e2d\u9891\u8c31\u6548\u7387(SE)\u548c\u80fd\u91cf\u6548\u7387(EE)\u6743\u8861\u7684\u8054\u5408\u53d1\u5c04\u548c\u5939\u6301\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\uff0c\u5305\u62ec\u5355\u7528\u6237\u548c\u591a\u7528\u6237\u573a\u666f\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bbe\u8ba1\u548c\u4ea4\u66ff\u4f18\u5316\u65b9\u6cd5\u663e\u8457\u63d0\u5347SE-EE\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u591a\u5929\u7ebf\u7cfb\u7edf\u5728\u9891\u8c31\u6548\u7387\u548c\u80fd\u91cf\u6548\u7387\u4e4b\u95f4\u5b58\u5728\u6743\u8861\u95ee\u9898\uff0c\u5939\u6301\u5929\u7ebf\u7cfb\u7edf(PASS)\u901a\u8fc7\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\u548c\u6ce2\u675f\u6210\u5f62\uff0c\u65e8\u5728\u5b9e\u73b0\u66f4\u597d\u7684SE-EE\u8054\u5408\u6027\u80fd\u3002", "method": "\u5355\u7528\u6237\u573a\u666f\uff1a\u63d0\u51fa\u4e24\u9636\u6bb5\u8054\u5408\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\uff0c\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u8fed\u4ee3\u95ed\u5f0f\u4f18\u5316\u65b9\u6848\u5bf9\u9f50\u63a5\u6536\u4fe1\u53f7\u76f8\u4f4d\u5e76\u786e\u5b9aPA\u4f4d\u7f6e\uff0c\u7b2c\u4e8c\u9636\u6bb5\u63a8\u5bfc\u6700\u4f18\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\u5668\uff1b\u591a\u7528\u6237\u573a\u666f\uff1a\u63d0\u51fa\u57fa\u4e8e\u4ea4\u66ff\u4f18\u5316\u7684\u8054\u5408\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\uff0c\u8003\u8651\u670d\u52a1\u8d28\u91cf\u8981\u6c42\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff1a1)\u6240\u63d0\u7b97\u6cd5\u663e\u8457\u63d0\u5347\u8054\u5408SE-EE\u6027\u80fd\u4e14\u6536\u655b\u901f\u5ea6\u5feb\uff1b2)\u968f\u7740PA\u6570\u91cf\u548c\u670d\u52a1\u8986\u76d6\u8303\u56f4\u589e\u52a0\uff0cPASS\u4e0e\u4f20\u7edf\u591a\u5929\u7ebf\u7cfb\u7edf\u4e4b\u95f4\u7684SE-EE\u6743\u8861\u5dee\u8ddd\u6269\u5927\u3002", "conclusion": "PASS\u7cfb\u7edf\u901a\u8fc7\u4f18\u5316PA\u4f4d\u7f6e\u548c\u6ce2\u675f\u6210\u5f62\uff0c\u80fd\u591f\u6709\u6548\u5e73\u8861\u9891\u8c31\u6548\u7387\u548c\u80fd\u91cf\u6548\u7387\uff0c\u5728\u5355\u7528\u6237\u548c\u591a\u7528\u6237\u901a\u4fe1\u4e2d\u5747\u8868\u73b0\u51fa\u4f18\u8d8a\u7684SE-EE\u8054\u5408\u6027\u80fd\u3002"}}
{"id": "2510.25246", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25246", "abs": "https://arxiv.org/abs/2510.25246", "authors": ["Yuan Guo", "Wen Chen", "Qingqing Wu", "Yang Liu", "Qiong Wu"], "title": "Cram\u00e9r-Rao Bound Optimization for Movable Antenna-Empowered Integrated Sensing and Uplink Communication System", "comment": null, "summary": "Integrated sensing and communication (ISAC) is a promising solution for the\nfuture sixth-generation (6G) system. However, classical fixed-position antenna\n(FPA) ISAC systems fail to fully utilize spatial degrees of freedom (DoFs),\nresulting in limited gains for both radar sensing and communication\nfunctionalities. This challenge can be addressed by the emerging novel movable\nantenna (MA) technology, which can pursue better channel conditions and improve\nsensing and communication performances. In this paper, we aim to minimize the\nCram\\'er-Rao bound (CRB) for estimating the target's angle while guaranteeing\ncommunication performance. This involves jointly optimizing active beamforming,\npower allocation, receiving filters, and MA position configurations, which is a\nhighly non-convex problem. To tackle this difficulty, we propose an efficient\niterative solution that analytically optimizes all variables without relying on\nnumerical solvers, i.e., CVX. Specifically, by leveraging cutting-edge\nmajorization-minimization (MM) and penalty-dual-decomposition (PDD) methods, we\ndevelop a low-complexity algorithm to solve the beamformer configuration\nproblem containing the fractional and quartic terms. Numerical simulation\nresults demonstrate the effectiveness and efficiency of our proposed algorithm,\nhighlighting significant performance improvements achieved by employing MA in\nthe ISAC system.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u79fb\u52a8\u5929\u7ebf\u6280\u672f\u7684ISAC\u7cfb\u7edf\u4f18\u5316\u65b9\u6848\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u3001\u529f\u7387\u5206\u914d\u3001\u63a5\u6536\u6ee4\u6ce2\u5668\u548c\u5929\u7ebf\u4f4d\u7f6e\u914d\u7f6e\uff0c\u5728\u4fdd\u8bc1\u901a\u4fe1\u6027\u80fd\u7684\u540c\u65f6\u6700\u5c0f\u5316\u76ee\u6807\u89d2\u5ea6\u4f30\u8ba1\u7684\u514b\u62c9\u7f8e-\u7f57\u4e0b\u754c\u3002", "motivation": "\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebfISAC\u7cfb\u7edf\u65e0\u6cd5\u5145\u5206\u5229\u7528\u7a7a\u95f4\u81ea\u7531\u5ea6\uff0c\u5bfc\u81f4\u96f7\u8fbe\u611f\u77e5\u548c\u901a\u4fe1\u6027\u80fd\u53d7\u9650\u3002\u53ef\u79fb\u52a8\u5929\u7ebf\u6280\u672f\u80fd\u591f\u901a\u8fc7\u4f18\u5316\u5929\u7ebf\u4f4d\u7f6e\u6765\u6539\u5584\u4fe1\u9053\u6761\u4ef6\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u91c7\u7528\u4e3b\u4f18\u5316-\u6700\u5c0f\u5316\u548c\u60e9\u7f5a-\u5bf9\u5076\u5206\u89e3\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\u6765\u89e3\u51b3\u5305\u542b\u5206\u6570\u9879\u548c\u56db\u6b21\u9879\u7684\u6ce2\u675f\u6210\u5f62\u914d\u7f6e\u95ee\u9898\uff0c\u65e0\u9700\u4f9d\u8d56\u6570\u503c\u6c42\u89e3\u5668\u3002", "result": "\u6570\u503c\u4eff\u771f\u7ed3\u679c\u8868\u660e\u6240\u63d0\u7b97\u6cd5\u5177\u6709\u6709\u6548\u6027\u548c\u9ad8\u6548\u6027\uff0c\u91c7\u7528\u53ef\u79fb\u52a8\u5929\u7ebf\u7684ISAC\u7cfb\u7edf\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\u3002", "conclusion": "\u53ef\u79fb\u52a8\u5929\u7ebf\u6280\u672f\u80fd\u591f\u663e\u8457\u63d0\u5347ISAC\u7cfb\u7edf\u7684\u611f\u77e5\u548c\u901a\u4fe1\u6027\u80fd\uff0c\u6240\u63d0\u51fa\u7684\u4f18\u5316\u7b97\u6cd5\u4e3a\u89e3\u51b3\u76f8\u5173\u975e\u51f8\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25290", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25290", "abs": "https://arxiv.org/abs/2510.25290", "authors": ["Yuan Guo", "Wen Chen", "Qingqing Wu", "Zhendong Li", "Kunlun Wang", "Hongying Tang", "Jun Li"], "title": "Fair Rate Maximization for Multi-user Multi-cell MISO Communication Systems via Novel Transmissive RIS Transceiver", "comment": null, "summary": "This paper explores a multi-cell multiple-input single-output (MISO) downlink\ncommunication system enabled by a unique transmissive reconfigurable\nintelligent surface (RIS) transceiver (TRTC) configuration. Within this system\nframework, we formulate an optimization problem for the purpose of maximizing\nthe minimum rate of users for each cell via designing the transmit beamforming\nof the TRTC, subject to the power constraints of each TRTC unit. Since the\nobjective function is non-differentiable, the max-min rate problem is difficult\nto solve. In order to tackle this challenging optimization problem, an\nefficient low-complexity optimization algorithm is developed. Specifically, the\nlog-form rate function is transformed into a tractable form by employing the\nfractional programming (FP) methodology. Next, the max-min objective function\ncan be approximated using a differentiable function derived from smooth\napproximation theory. Moreover, by applying the majorization-minimization (MM)\ntechnique and examining the optimality conditions, a solution is proposed that\nupdates all variables analytically without relying on any numerical solvers.\nNumerical results are presented to demonstrate the convergence and\neffectiveness of the proposed low-complexity algorithm. Additionally, the\nalgorithm can significantly reduce the computational complexity without\nperformance loss. Furthermore, the simulation results illustrate the clear\nsuperiority of the deployment of the TRTC over the benchmark schemes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u900f\u5c04\u5f0f\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u6536\u53d1\u5668(TRTC)\u7684\u591a\u5c0f\u533aMISO\u4e0b\u884c\u901a\u4fe1\u7cfb\u7edf\uff0c\u5f00\u53d1\u4e86\u9ad8\u6548\u4f4e\u590d\u6742\u5ea6\u7684\u4f18\u5316\u7b97\u6cd5\u6765\u6700\u5927\u5316\u7528\u6237\u6700\u5c0f\u901f\u7387\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u4e14\u65e0\u6027\u80fd\u635f\u5931\u3002", "motivation": "\u5728\u591a\u5c0f\u533aMISO\u4e0b\u884c\u901a\u4fe1\u7cfb\u7edf\u4e2d\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u89e3\u51b3\u975e\u53ef\u5fae\u7684\u6700\u5927\u6700\u5c0f\u901f\u7387\u4f18\u5316\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u4f4e\u590d\u6742\u5ea6\u7684\u9ad8\u6548\u7b97\u6cd5\u6765\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u91c7\u7528\u5206\u6570\u89c4\u5212(FP)\u65b9\u6cd5\u5c06\u901f\u7387\u51fd\u6570\u8f6c\u5316\u4e3a\u53ef\u5904\u7406\u5f62\u5f0f\uff0c\u5229\u7528\u5e73\u6ed1\u903c\u8fd1\u7406\u8bba\u8fd1\u4f3c\u6700\u5927\u6700\u5c0f\u76ee\u6807\u51fd\u6570\uff0c\u7ed3\u5408\u4e3b\u6700\u5c0f\u5316(MM)\u6280\u672f\u548c\u6700\u4f18\u6027\u6761\u4ef6\u5206\u6790\uff0c\u63d0\u51fa\u65e0\u9700\u6570\u503c\u6c42\u89e3\u5668\u7684\u89e3\u6790\u66f4\u65b0\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u7b97\u6cd5\u5177\u6709\u826f\u597d\u6536\u655b\u6027\u548c\u6709\u6548\u6027\uff0c\u80fd\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u4e14\u65e0\u6027\u80fd\u635f\u5931\uff0cTRTC\u90e8\u7f72\u65b9\u6848\u660e\u663e\u4f18\u4e8e\u57fa\u51c6\u65b9\u6848\u3002", "conclusion": "\u63d0\u51fa\u7684\u4f4e\u590d\u6742\u5ea6\u4f18\u5316\u7b97\u6cd5\u6210\u529f\u89e3\u51b3\u4e86TRTC\u7cfb\u7edf\u4e2d\u7684\u6700\u5927\u6700\u5c0f\u901f\u7387\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u591a\u5c0f\u533a\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25293", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25293", "abs": "https://arxiv.org/abs/2510.25293", "authors": ["Marina Murakami", "Ryoko Iwase", "Chiemi Iba", "Daisuke Ogura", "Takuya Sakamoto"], "title": "Millimeter-Wave Radar Sensing of Wombat Respiration", "comment": "5 pages, 5 figures, 1 table. This work is going to be submitted to\n  the IEEE for possible publication", "summary": "This study demonstrates the feasibility of radar-based non-contact\nrespiratory monitoring for wombats. Two measurement experiments were conducted\nin June and December 2024 using 79-GHz millimeter-wave radar systems to monitor\nthe respiration of two wombats. To estimate the respiratory interval, we used a\nmethod based on summing harmonic components in the autocorrelation function,\ncapturing the quasi-periodic displacement of the body surface caused by\nrespiration. Estimation accuracy was evaluated through simultaneous\nmeasurements from different angles using two radar units. The respiratory\ninterval and respiratory rate were measured with errors of 47.4 ms (2.44%) and\n0.81 bpm (2.21%), respectively. We also discuss the differences in respiratory\nrates between the two wombats, as well as seasonal variations between June and\nDecember. The results support the potential application of this method to\nnon-contact health monitoring of wombats.", "AI": {"tldr": "\u4f7f\u752879GHz\u6beb\u7c73\u6ce2\u96f7\u8fbe\u7cfb\u7edf\u5bf9\u888b\u718a\u8fdb\u884c\u975e\u63a5\u89e6\u5f0f\u547c\u5438\u76d1\u6d4b\uff0c\u901a\u8fc7\u81ea\u76f8\u5173\u51fd\u6570\u8c10\u6ce2\u5206\u91cf\u6c42\u548c\u7684\u65b9\u6cd5\u4f30\u8ba1\u547c\u5438\u95f4\u9694\uff0c\u6d4b\u91cf\u7cbe\u5ea6\u8fbe\u523047.4ms\u8bef\u5dee(2.44%)\u548c0.81bpm\u8bef\u5dee(2.21%)\u3002", "motivation": "\u5f00\u53d1\u975e\u63a5\u89e6\u5f0f\u547c\u5438\u76d1\u6d4b\u65b9\u6cd5\u7528\u4e8e\u888b\u718a\u7684\u5065\u5eb7\u76d1\u6d4b\uff0c\u907f\u514d\u4f20\u7edf\u63a5\u89e6\u5f0f\u76d1\u6d4b\u5bf9\u52a8\u7269\u7684\u5e72\u6270\u3002", "method": "\u4f7f\u752879GHz\u6beb\u7c73\u6ce2\u96f7\u8fbe\u7cfb\u7edf\uff0c\u901a\u8fc7\u81ea\u76f8\u5173\u51fd\u6570\u8c10\u6ce2\u5206\u91cf\u6c42\u548c\u7684\u65b9\u6cd5\u6765\u4f30\u8ba1\u7531\u547c\u5438\u5f15\u8d77\u7684\u4f53\u8868\u51c6\u5468\u671f\u4f4d\u79fb\u3002", "result": "\u547c\u5438\u95f4\u9694\u6d4b\u91cf\u8bef\u5dee47.4ms(2.44%)\uff0c\u547c\u5438\u7387\u6d4b\u91cf\u8bef\u5dee0.81bpm(2.21%)\uff0c\u5e76\u89c2\u5bdf\u5230\u4e24\u53ea\u888b\u718a\u4e4b\u95f4\u4ee5\u53ca6\u6708\u4e0e12\u6708\u4e4b\u95f4\u7684\u547c\u5438\u7387\u5dee\u5f02\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u888b\u718a\u975e\u63a5\u89e6\u5065\u5eb7\u76d1\u6d4b\u65b9\u9762\u5177\u6709\u5e94\u7528\u6f5c\u529b\uff0c\u80fd\u591f\u51c6\u786e\u6d4b\u91cf\u547c\u5438\u53c2\u6570\u5e76\u68c0\u6d4b\u5b63\u8282\u6027\u53d8\u5316\u3002"}}
{"id": "2510.25390", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25390", "abs": "https://arxiv.org/abs/2510.25390", "authors": ["Syed Luqman Shah", "Nurul Huda Mahmood", "Italo Atzeni"], "title": "Low-Overhead CSI Prediction via Gaussian Process Regression -- Part~I: Data-Driven Spatial Interpolation", "comment": "Submitted to IEEE Wireless Communications Letters", "summary": "Accurate channel state information (CSI) is critical for current and\nnext-generation multi-antenna systems. Yet conventional pilot-based estimators\nincur prohibitive overhead as antenna counts grow. In this paper, we address\nthis challenge by developing a novel framework based on Gaussian process\nregression (GPR) that predicts full CSI from only a few observed entries,\nthereby reducing pilot overhead. The correlation between data points in GPR is\ndefined by the covariance function, known as kernels. In the proposed GPR-based\nCSI estimation framework, we incorporate three kernels, i.e., radial basis\nfunction, Mat\\'ern, and rational quadratic, to model smooth and multi-scale\nspatial correlations derived from the antenna array geometry. The proposed\napproach is evaluated across Kronecker and Weichselberger channel models with\nthree distinct pilot probing schemes. Results show that the proposed GPR with\n50% pilot saving achieves the lowest prediction error, the highest empirical\n95% credible-interval coverage, and the best preservation of mutual information\nrelative to benchmarks. This enables up to 50% pilot reduction while preserving\nover 92% of the link capacity.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u7684CSI\u4f30\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5c11\u91cf\u89c2\u6d4b\u70b9\u9884\u6d4b\u5b8c\u6574\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff0c\u51cf\u5c1150%\u5bfc\u9891\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u630192%\u4ee5\u4e0a\u7684\u94fe\u8def\u5bb9\u91cf\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5bfc\u9891\u7684\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u5728\u5929\u7ebf\u6570\u91cf\u589e\u52a0\u65f6\u4f1a\u4ea7\u751f\u8fc7\u9ad8\u5f00\u9500\uff0c\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u7684CSI\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u9ad8\u65af\u8fc7\u7a0b\u56de\u5f52\u6846\u67b6\uff0c\u7ed3\u5408\u5f84\u5411\u57fa\u51fd\u6570\u3001Mat\u00e9rn\u548c\u6709\u7406\u4e8c\u6b21\u6838\u51fd\u6570\u6765\u5efa\u6a21\u5929\u7ebf\u9635\u5217\u51e0\u4f55\u4ea7\u751f\u7684\u7a7a\u95f4\u76f8\u5173\u6027\u3002", "result": "\u5728Kronecker\u548cWeichselberger\u4fe1\u9053\u6a21\u578b\u4e0b\uff0c\u6240\u63d0\u65b9\u6cd5\u572850%\u5bfc\u9891\u8282\u7701\u4e0b\u83b7\u5f97\u6700\u4f4e\u9884\u6d4b\u8bef\u5dee\u3001\u6700\u9ad895%\u53ef\u4fe1\u533a\u95f4\u8986\u76d6\u7387\u548c\u6700\u4f73\u4e92\u4fe1\u606f\u4fdd\u6301\u6027\u80fd\u3002", "conclusion": "\u8be5GPR\u6846\u67b6\u80fd\u591f\u663e\u8457\u51cf\u5c11\u5bfc\u9891\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u4fe1\u9053\u5bb9\u91cf\uff0c\u4e3a\u5927\u89c4\u6a21\u5929\u7ebf\u7cfb\u7edf\u63d0\u4f9b\u9ad8\u6548\u7684CSI\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2510.25393", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25393", "abs": "https://arxiv.org/abs/2510.25393", "authors": ["Alea Schr\u00f6der", "Steffen Gracla", "Carsten Bockelmann", "Dirk W\u00fcbben", "Armin Dekorsy"], "title": "Model-Free Robust Beamforming in Satellite Downlink using Reinforcement Learning", "comment": null, "summary": "Satellite-based communications are expected to be a substantial future market\nin 6G networks. As satellite constellations grow denser and transmission\nresources remain limited, frequency reuse plays an increasingly important role\nin managing inter-user interference. In the multi-user downlink, precoding\nenables the reuse of frequencies across spatially separated users, greatly\nimproving spectral efficiency. The analytical calculation of suitable\nprecodings for perfect channel information is well studied, however, their\nperformance can quickly deteriorate when faced with, e.g., outdated channel\nstate information or, as is particularly relevant for satellite channels, when\nposition estimates are erroneous. Deriving robust precoders under imperfect\nchannel state information is not only analytically intractable in general but\noften requires substantial relaxations of the optimization problem or heuristic\nconstraints to obtain feasible solutions. Instead, in this paper we flexibly\nderive robust precoding algorithms from given data using reinforcement\nlearning. We describe how we adapt the applied Soft Actor-Critic learning\nalgorithm to the problem of downlink satellite beamforming and show numerically\nthat the resulting precoding algorithm adjusts to all investigated scenarios.\nThe considered scenarios cover both single satellite and cooperative\nmulti-satellite beamforming, using either global or local channel state\ninformation, and two error models that represent increasing levels of\nuncertainty. We show that the learned algorithms match or markedly outperform\ntwo analytical baselines in sum rate performance, adapting to the required\nlevel of robustness. We also analyze the mechanisms that the learned algorithms\nleverage to achieve robustness. The implementation is publicly available for\nuse and reproduction of the results.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u4e3a\u536b\u661f\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u9c81\u68d2\u9884\u7f16\u7801\u7b97\u6cd5\uff0c\u4ee5\u5e94\u5bf9\u4e0d\u5b8c\u7f8e\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff0c\u5728\u591a\u79cd\u573a\u666f\u4e0b\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u5206\u6790\u65b9\u6cd5\u3002", "motivation": "\u536b\u661f\u901a\u4fe1\u4e2d\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u4e0d\u5b8c\u7f8e\uff08\u5982\u4f4d\u7f6e\u4f30\u8ba1\u9519\u8bef\uff09\u4f1a\u5bfc\u81f4\u4f20\u7edf\u9884\u7f16\u7801\u7b97\u6cd5\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u800c\u63a8\u5bfc\u9c81\u68d2\u9884\u7f16\u7801\u5728\u5206\u6790\u4e0a\u901a\u5e38\u4e0d\u53ef\u884c\u6216\u9700\u8981\u5927\u91cf\u7b80\u5316\u3002", "method": "\u91c7\u7528Soft Actor-Critic\u5f3a\u5316\u5b66\u4e60\u7b97\u6cd5\uff0c\u5c06\u5176\u9002\u914d\u5230\u536b\u661f\u4e0b\u884c\u6ce2\u675f\u6210\u5f62\u95ee\u9898\uff0c\u901a\u8fc7\u6570\u636e\u9a71\u52a8\u65b9\u5f0f\u7075\u6d3b\u5b66\u4e60\u9c81\u68d2\u9884\u7f16\u7801\u7b56\u7565\u3002", "result": "\u5b66\u4e60\u5230\u7684\u9884\u7f16\u7801\u7b97\u6cd5\u5728\u6240\u6709\u7814\u7a76\u573a\u666f\u4e2d\u90fd\u80fd\u9002\u5e94\uff0c\u5728\u603b\u901f\u7387\u6027\u80fd\u4e0a\u5339\u914d\u6216\u663e\u8457\u4f18\u4e8e\u4e24\u79cd\u5206\u6790\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e76\u80fd\u9002\u5e94\u6240\u9700\u7684\u9c81\u68d2\u6027\u6c34\u5e73\u3002", "conclusion": "\u5f3a\u5316\u5b66\u4e60\u4e3a\u536b\u661f\u901a\u4fe1\u4e2d\u7684\u9c81\u68d2\u9884\u7f16\u7801\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7075\u6d3b\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5e94\u5bf9\u4fe1\u9053\u4e0d\u786e\u5b9a\u6027\u5e76\u5b9e\u73b0\u9ad8\u6027\u80fd\u6ce2\u675f\u6210\u5f62\u3002"}}
{"id": "2510.25416", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2510.25416", "abs": "https://arxiv.org/abs/2510.25416", "authors": ["Jiaming Cheng", "Wei Chen", "Bo Ai"], "title": "Adaptive End-to-End Transceiver Design for NextG Pilot-Free and CP-Free Wireless Systems", "comment": "Submitted to IEEE for possible publication", "summary": "The advent of artificial intelligence (AI)-native wireless communication is\nfundamentally reshaping the design paradigm of next-generation (NextG) systems,\nwhere intelligent air interfaces are expected to operate adaptively and\nefficiently in highly dynamic environments. Conventional orthogonal frequency\ndivision multiplexing (OFDM) systems rely heavily on pilots and the cyclic\nprefix (CP), resulting in significant overhead and reduced spectral efficiency.\nTo address these limitations, we propose an adaptive end-to-end (E2E)\ntransceiver architecture tailored for pilot-free and CP-free wireless systems.\nThe architecture combines AI-driven constellation shaping and a neural receiver\nthrough joint training. To enhance robustness against mismatched or\ntime-varying channel conditions, we introduce a lightweight channel adapter\n(CA) module, which enables rapid adaptation with minimal computational overhead\nby updating only the CA parameters. Additionally, we present a framework that\nis scalable to multiple modulation orders within a unified model, significantly\nreducing model storage requirements. Moreover, to tackle the high\npeak-to-average power ratio (PAPR) inherent to OFDM, we incorporate constrained\nE2E training, achieving compliance with PAPR targets without additional\ntransmission overhead. Extensive simulations demonstrate that the proposed\nframework delivers superior bit error rate (BER), throughput, and resilience\nacross diverse channel scenarios, highlighting its potential for AI-native\nNextG.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u65e0\u5bfc\u9891\u548c\u65e0\u5faa\u73af\u524d\u7f00\u65e0\u7ebf\u7cfb\u7edf\u7684\u81ea\u9002\u5e94\u7aef\u5230\u7aef\u6536\u53d1\u5668\u67b6\u6784\uff0c\u7ed3\u5408AI\u9a71\u52a8\u7684\u661f\u5ea7\u6574\u5f62\u548c\u795e\u7ecf\u7f51\u7edc\u63a5\u6536\u5668\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u4fe1\u9053\u9002\u914d\u5668\u5b9e\u73b0\u5feb\u901f\u9002\u5e94\uff0c\u652f\u6301\u591a\u8c03\u5236\u9636\u6570\u7edf\u4e00\u6a21\u578b\uff0c\u5e76\u89e3\u51b3\u4e86OFDM\u7684\u9ad8\u5cf0\u5747\u529f\u7387\u6bd4\u95ee\u9898\u3002", "motivation": "\u4f20\u7edfOFDM\u7cfb\u7edf\u4e25\u91cd\u4f9d\u8d56\u5bfc\u9891\u548c\u5faa\u73af\u524d\u7f00\uff0c\u5bfc\u81f4\u663e\u8457\u5f00\u9500\u548c\u9891\u8c31\u6548\u7387\u964d\u4f4e\u3002AI\u539f\u751f\u65e0\u7ebf\u901a\u4fe1\u9700\u8981\u667a\u80fd\u7a7a\u53e3\u5728\u9ad8\u5ea6\u52a8\u6001\u73af\u5883\u4e2d\u81ea\u9002\u5e94\u9ad8\u6548\u8fd0\u884c\u3002", "method": "\u7aef\u5230\u7aef\u6536\u53d1\u5668\u67b6\u6784\uff0c\u7ed3\u5408AI\u9a71\u52a8\u7684\u661f\u5ea7\u6574\u5f62\u548c\u795e\u7ecf\u7f51\u7edc\u63a5\u6536\u5668\u8054\u5408\u8bad\u7ec3\uff1b\u5f15\u5165\u8f7b\u91cf\u7ea7\u4fe1\u9053\u9002\u914d\u5668\u6a21\u5757\u5b9e\u73b0\u5feb\u901f\u9002\u5e94\uff1b\u652f\u6301\u591a\u8c03\u5236\u9636\u6570\u7684\u7edf\u4e00\u6a21\u578b\uff1b\u91c7\u7528\u7ea6\u675f\u7aef\u5230\u7aef\u8bad\u7ec3\u89e3\u51b3\u9ad8\u5cf0\u5747\u529f\u7387\u6bd4\u95ee\u9898\u3002", "result": "\u5e7f\u6cdb\u4eff\u771f\u8868\u660e\uff0c\u8be5\u6846\u67b6\u5728\u4e0d\u540c\u4fe1\u9053\u573a\u666f\u4e0b\u63d0\u4f9b\u4f18\u8d8a\u7684\u8bef\u7801\u7387\u3001\u541e\u5410\u91cf\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u5c55\u793a\u4e86AI\u539f\u751f\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u7684\u6f5c\u529b\uff0c\u80fd\u591f\u663e\u8457\u63d0\u9ad8\u9891\u8c31\u6548\u7387\u5e76\u964d\u4f4e\u5f00\u9500\u3002"}}
{"id": "2510.25433", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25433", "abs": "https://arxiv.org/abs/2510.25433", "authors": ["Caihao Weng", "Yuqing Guo", "Bowen Zhao", "Ying Wang", "Wen Chen", "Zhendong Li"], "title": "Learning-Based Blockage-Resilient Beam Training in Near-Field Terahertz Communications", "comment": "13 pages, 11 figures", "summary": "Terahertz (THz) band is considered a promising candidate to meet the\nhigh-throughput requirement for future sixth-generation (6G) wireless\ncommunications due to its ultrawide bandwidth. However, due to the high\npenetration loss at high-frequencies, blockage becomes a serious problem in THz\ncommunications, especially in near-field indoor communications with numerous\nobstacles. To address this issue, this paper investigates blockage-resilient\nnear-field beam training based on self-accelerating Airy beam, which can\npropagate along a curved trajectory to circumvent obstacles. Specifically, we\nfirst analyze the trajectory of the Airy beam and the beam pattern at the\nreceiver using a discrete Fourier transform (DFT) codebook in the presence of\nobstacles. Interestingly, we reveal that the beam pattern not only captures the\nreceiver's location information but also implicitly encodes the spatial\nrelationship between the receiver and obstacle, which facilitates identifying\nthe optimal Airy beam configuration. Based on this insight, we formulate the\nblockage-resilient beam training task as a multitask learning problem and\npropose a lightweight attention-based multi-parameter beam training network\n(AMPBT-Net) to jointly predict the angle, distance, and curvature parameters of\nthe optimal Airy beam based on the beam pattern. Finally, simulation results\ndemonstrate that the Airy beam effectively mitigates blockage effects and the\nproposed scheme achieves comparable performance to exhaustive beam sweeping\nwhile significantly reducing training overhead.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u81ea\u52a0\u901f\u827e\u91cc\u5149\u675f\u7684\u906e\u6321\u5f39\u6027\u8fd1\u573a\u6ce2\u675f\u8bad\u7ec3\u65b9\u6848\uff0c\u5229\u7528\u827e\u91cc\u5149\u675f\u7684\u5f2f\u66f2\u4f20\u64ad\u7279\u6027\u7ed5\u8fc7\u969c\u788d\u7269\uff0c\u5e76\u901a\u8fc7\u8f7b\u91cf\u7ea7\u6ce8\u610f\u529b\u7f51\u7edc\u8054\u5408\u9884\u6d4b\u6700\u4f18\u6ce2\u675f\u53c2\u6570\u3002", "motivation": "\u592a\u8d6b\u5179\u901a\u4fe1\u4e2d\u9ad8\u9891\u6bb5\u7684\u9ad8\u7a7f\u900f\u635f\u8017\u5bfc\u81f4\u906e\u6321\u95ee\u9898\u4e25\u91cd\uff0c\u7279\u522b\u662f\u5728\u8fd1\u573a\u5ba4\u5185\u901a\u4fe1\u73af\u5883\u4e2d\u5b58\u5728\u4f17\u591a\u969c\u788d\u7269\uff0c\u9700\u8981\u89e3\u51b3\u906e\u6321\u5f39\u6027\u95ee\u9898\u3002", "method": "\u5206\u6790\u827e\u91cc\u5149\u675f\u8f68\u8ff9\u548c\u6ce2\u675f\u6a21\u5f0f\uff0c\u63d0\u51fa\u57fa\u4e8e\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u8f7b\u91cf\u7ea7\u6ce8\u610f\u529b\u7f51\u7edcAMPBT-Net\uff0c\u8054\u5408\u9884\u6d4b\u6700\u4f18\u827e\u91cc\u5149\u675f\u7684\u89d2\u5ea6\u3001\u8ddd\u79bb\u548c\u66f2\u7387\u53c2\u6570\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u827e\u91cc\u5149\u675f\u6709\u6548\u7f13\u89e3\u906e\u6321\u6548\u5e94\uff0c\u6240\u63d0\u65b9\u6848\u5728\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u5f00\u9500\u7684\u540c\u65f6\u8fbe\u5230\u4e0e\u7a77\u4e3e\u6ce2\u675f\u626b\u63cf\u76f8\u5f53\u7684\u6027\u80fd\u3002", "conclusion": "\u57fa\u4e8e\u827e\u91cc\u5149\u675f\u7684\u906e\u6321\u5f39\u6027\u6ce2\u675f\u8bad\u7ec3\u65b9\u6848\u4e3a\u592a\u8d6b\u5179\u8fd1\u573a\u901a\u4fe1\u4e2d\u7684\u906e\u6321\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2510.25464", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25464", "abs": "https://arxiv.org/abs/2510.25464", "authors": ["Amirhossein Azarbahram", "Onel L. A. L\u00f3pez"], "title": "Echo-Conditioned Denoising Diffusion Probabilistic Models for Multi-Target Tracking in RF Sensing", "comment": null, "summary": "In this paper, we consider a dynamic radio frequency sensing system aiming to\nspatially track multiple targets over time. We develop a conditional denoising\ndiffusion probabilistic model (C-DDPM)-assisted framework that learns the\ntemporal evolution of target parameters by leveraging the noisy echo\nobservations as conditioning features. The proposed framework integrates a\nvariational autoencoder (VAE) for echo compression and utilizes classifier-free\nguidance to enhance conditional denoising. In each transmission block, VAE\nencodes the received echo into a latent representation that conditions DDPM to\npredict future target states, which are then used for codebook beam selection.\nSimulation results show that the proposed approach outperforms classical signal\nprocessing, filtering, and deep learning benchmarks. The C-DDPM-assisted\nframework achieves significantly lower estimation errors in both angle and\ndistance tracking, demonstrating the potential of generative models for\nintegrated sensing and communications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6761\u4ef6\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b(C-DDPM)\u7684\u52a8\u6001\u5c04\u9891\u611f\u77e5\u7cfb\u7edf\uff0c\u7528\u4e8e\u591a\u76ee\u6807\u7a7a\u95f4\u8ddf\u8e2a\uff0c\u901a\u8fc7\u53d8\u5206\u81ea\u7f16\u7801\u5668\u538b\u7f29\u56de\u6ce2\u5e76\u5229\u7528\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\u589e\u5f3a\u6761\u4ef6\u53bb\u566a\u3002", "motivation": "\u5f00\u53d1\u80fd\u591f\u5b66\u4e60\u76ee\u6807\u53c2\u6570\u65f6\u95f4\u6f14\u53d8\u7684\u52a8\u6001\u5c04\u9891\u611f\u77e5\u7cfb\u7edf\uff0c\u5229\u7528\u566a\u58f0\u56de\u6ce2\u89c2\u6d4b\u4f5c\u4e3a\u6761\u4ef6\u7279\u5f81\u6765\u6539\u5584\u591a\u76ee\u6807\u8ddf\u8e2a\u6027\u80fd\u3002", "method": "\u96c6\u6210\u53d8\u5206\u81ea\u7f16\u7801\u5668(VAE)\u8fdb\u884c\u56de\u6ce2\u538b\u7f29\uff0c\u4f7f\u7528\u6761\u4ef6\u53bb\u566a\u6269\u6563\u6982\u7387\u6a21\u578b(C-DDPM)\u9884\u6d4b\u672a\u6765\u76ee\u6807\u72b6\u6001\uff0c\u5e76\u91c7\u7528\u5206\u7c7b\u5668\u81ea\u7531\u5f15\u5bfc\u589e\u5f3a\u6761\u4ef6\u53bb\u566a\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u89d2\u5ea6\u548c\u8ddd\u79bb\u8ddf\u8e2a\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u4fe1\u53f7\u5904\u7406\u3001\u6ee4\u6ce2\u548c\u6df1\u5ea6\u5b66\u4e60\u57fa\u51c6\u65b9\u6cd5\uff0c\u4f30\u8ba1\u8bef\u5dee\u663e\u8457\u964d\u4f4e\u3002", "conclusion": "\u8bc1\u660e\u4e86\u751f\u6210\u6a21\u578b\u5728\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u4e2d\u7684\u6f5c\u529b\uff0cC-DDPM\u8f85\u52a9\u6846\u67b6\u5728\u591a\u76ee\u6807\u8ddf\u8e2a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2510.25467", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25467", "abs": "https://arxiv.org/abs/2510.25467", "authors": ["Muhammad Khalil", "Ke Wang", "Jinho Choi"], "title": "Adaptive Channel Estimation and Quantized Feedback for RIS Assisted Optical Wireless Communication Systems", "comment": null, "summary": "This paper presents a unified modeling, estimation, and feedback framework\nfor reconfigurable intelligent surface RIS-assisted optical wireless links. The\nkey modeling element is a long-exposure pixel gain that extends the classical\ndiffraction-limited response by statistically averaging angular jitter and\nmispointing; it admits an exact real-integral form and captures boresight\nattenuation and progressive sidelobe filling. The end-to-end system couples\nfree-space path loss, Beer--Lambert atmospheric extinction, pixel-level\ndiffraction, and optical efficiency with a unitary-pilot least-squares channel\nestimator and quantized phase feedback. Analysis closely matches Monte Carlo\nsimulations and yields concrete design rules: with a surface of N=64 pixels,\npilot length $M=2N$, and pilot SNR=20 dB, the normalized mean-squared error\nis0.005, implying an effective-SNR loss of about 0.5 and a capacity penalty of\n0.007bits-s. Six-bit phase quantization introduces no measurable additional\npenalty at these operating points, setting a practical benchmark for feedback\nresolution. Training overhead scales strongly with pixel geometry: halving\npixel width (quartering pixel area) increases the pilot length required to\nmaintain the same NMSE by roughly fourfold. The framework reconciles\nphysical-optics modeling with estimation-and-feedback design and provides a\nprincipled basis for scalable link budgeting in RIS-assisted optical networks.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7528\u4e8eRIS\u8f85\u52a9\u5149\u65e0\u7ebf\u94fe\u8def\u7684\u7edf\u4e00\u5efa\u6a21\u3001\u4f30\u8ba1\u548c\u53cd\u9988\u6846\u67b6\uff0c\u901a\u8fc7\u957f\u66dd\u5149\u50cf\u7d20\u589e\u76ca\u6269\u5c55\u7ecf\u5178\u884d\u5c04\u9650\u5236\u54cd\u5e94\uff0c\u7ed3\u5408\u4fe1\u9053\u4f30\u8ba1\u548c\u91cf\u5316\u76f8\u4f4d\u53cd\u9988\uff0c\u4e3aRIS\u8f85\u52a9\u5149\u7f51\u7edc\u63d0\u4f9b\u53ef\u6269\u5c55\u7684\u94fe\u8def\u9884\u7b97\u57fa\u7840\u3002", "motivation": "\u4e3a\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(RIS)\u8f85\u52a9\u7684\u5149\u65e0\u7ebf\u94fe\u8def\u5f00\u53d1\u4e00\u4e2a\u7edf\u4e00\u7684\u7269\u7406\u5149\u5b66\u5efa\u6a21\u4e0e\u4f30\u8ba1\u53cd\u9988\u8bbe\u8ba1\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edf\u884d\u5c04\u9650\u5236\u54cd\u5e94\u65e0\u6cd5\u7edf\u8ba1\u5e73\u5747\u89d2\u5ea6\u6296\u52a8\u548c\u6307\u5411\u8bef\u5dee\u7684\u95ee\u9898\u3002", "method": "\u4f7f\u7528\u957f\u66dd\u5149\u50cf\u7d20\u589e\u76ca\u6a21\u578b\u6269\u5c55\u7ecf\u5178\u884d\u5c04\u9650\u5236\u54cd\u5e94\uff0c\u7ed3\u5408\u81ea\u7531\u7a7a\u95f4\u8def\u5f84\u635f\u8017\u3001\u5927\u6c14\u6d88\u5149\u3001\u50cf\u7d20\u7ea7\u884d\u5c04\u548c\u5149\u5b66\u6548\u7387\uff0c\u91c7\u7528\u5355\u4f4d\u5bfc\u9891\u6700\u5c0f\u4e8c\u4e58\u4fe1\u9053\u4f30\u8ba1\u5668\u548c\u91cf\u5316\u76f8\u4f4d\u53cd\u9988\u3002", "result": "\u5728N=64\u50cf\u7d20\u8868\u9762\u3001\u5bfc\u9891\u957f\u5ea6M=2N\u3001\u5bfc\u9891SNR=20dB\u6761\u4ef6\u4e0b\uff0c\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\u4e3a0.005\uff0c\u6709\u6548SNR\u635f\u5931\u7ea60.5dB\uff0c\u5bb9\u91cf\u635f\u59310.007bits/s\u30026\u4f4d\u76f8\u4f4d\u91cf\u5316\u5728\u8fd9\u4e9b\u5de5\u4f5c\u70b9\u4e0b\u65e0\u989d\u5916\u6027\u80fd\u635f\u5931\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u8c03\u548c\u4e86\u7269\u7406\u5149\u5b66\u5efa\u6a21\u4e0e\u4f30\u8ba1\u53cd\u9988\u8bbe\u8ba1\uff0c\u4e3aRIS\u8f85\u52a9\u5149\u7f51\u7edc\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u94fe\u8def\u9884\u7b97\u539f\u5219\uff0c\u50cf\u7d20\u51e0\u4f55\u5f62\u72b6\u5bf9\u8bad\u7ec3\u5f00\u9500\u6709\u663e\u8457\u5f71\u54cd\u3002"}}
{"id": "2510.25496", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25496", "abs": "https://arxiv.org/abs/2510.25496", "authors": ["Duc Nguyen Dao", "Andr\u00e9 B. J. Kokkeler", "Haibin Zhang", "Yang Miao"], "title": "Dynamic Beamforming and Power Allocation in ISAC via Deep Reinforcement Learning", "comment": "7 pages, 7 figures", "summary": "Integrated Sensing and Communication (ISAC) is a key enabler in 6G networks,\nwhere sensing and communication capabilities are designed to complement and\nenhance each other. One of the main challenges in ISAC lies in resource\nallocation, which becomes computationally demanding in dynamic environments\nrequiring real-time adaptation. In this paper, we propose a Deep Reinforcement\nLearning (DRL)-based approach for dynamic beamforming and power allocation in\nISAC systems. The DRL agent interacts with the environment and learns optimal\nstrategies through trial and error, guided by predefined rewards. Simulation\nresults show that the DRL-based solution converges within 2000 episodes and\nachieves up to 80\\% of the spectral efficiency of a semidefinite relaxation\n(SDR) benchmark. More importantly, it offers a significant improvement in\nruntime performance, achieving decision times of around 20 ms compared to 4500\nms for the SDR method. Furthermore, compared with a Deep Q-Network (DQN)\nbenchmark employing discrete beamforming, the proposed approach achieves\napproximately 30\\% higher sum-rate with comparable runtime. These results\nhighlight the potential of DRL for enabling real-time, high-performance ISAC in\ndynamic scenarios.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684ISAC\u7cfb\u7edf\u52a8\u6001\u6ce2\u675f\u6210\u5f62\u548c\u529f\u7387\u5206\u914d\u65b9\u6cd5\uff0c\u57282000\u6b21\u8bad\u7ec3\u540e\u6536\u655b\uff0c\u8fbe\u5230SDR\u57fa\u51c680%\u7684\u9891\u8c31\u6548\u7387\uff0c\u4f46\u51b3\u7b56\u65f6\u95f4\u4ece4500ms\u5927\u5e45\u964d\u81f320ms\uff0c\u76f8\u6bd4DQN\u57fa\u51c6\u63d0\u9ad830%\u603b\u901f\u7387\u3002", "motivation": "6G\u7f51\u7edc\u4e2d\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u9762\u4e34\u52a8\u6001\u73af\u5883\u4e0b\u5b9e\u65f6\u8d44\u6e90\u5206\u914d\u7684\u8ba1\u7b97\u6311\u6218\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u5b9e\u65f6\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u4ee3\u7406\u4e0e\u73af\u5883\u4ea4\u4e92\uff0c\u901a\u8fc7\u8bd5\u9519\u5b66\u4e60\u6700\u4f18\u7b56\u7565\uff0c\u4ee5\u9884\u5b9a\u4e49\u5956\u52b1\u4e3a\u6307\u5bfc\u8fdb\u884c\u52a8\u6001\u6ce2\u675f\u6210\u5f62\u548c\u529f\u7387\u5206\u914d\u3002", "result": "DRL\u65b9\u6cd5\u57282000\u6b21\u8bad\u7ec3\u540e\u6536\u655b\uff0c\u8fbe\u5230SDR\u57fa\u51c680%\u7684\u9891\u8c31\u6548\u7387\uff0c\u51b3\u7b56\u65f6\u95f4\u4ece4500ms\u964d\u81f320ms\uff0c\u76f8\u6bd4DQN\u57fa\u51c6\u63d0\u9ad830%\u603b\u901f\u7387\u3002", "conclusion": "\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u5728\u52a8\u6001\u573a\u666f\u4e2d\u5177\u6709\u5b9e\u73b0\u5b9e\u65f6\u9ad8\u6027\u80fdISAC\u7684\u6f5c\u529b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u8fd0\u884c\u65f6\u6027\u80fd\u3002"}}
{"id": "2510.25604", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25604", "abs": "https://arxiv.org/abs/2510.25604", "authors": ["Krishna Chaythanya KV", "Saqib Abbas Baba", "Anurag Kumar", "Arpan Chattopadhyay", "Rajesh Sundaresan"], "title": "Quickest Change Point Detection with Measurements over a Lossy Link", "comment": "17 pages, 6 Figures", "summary": "Motivated by Industry 4.0 applications, we consider quickest change detection\n(QCD) of an abrupt change in a process when its measurements are transmitted by\na sensor over a lossy wireless link to a decision maker (DM). The sensor node\nsamples measurements using a Bernoulli sampling process, and places the\nmeasurement samples in the transmit queue of its transmitter. The transmitter\nuses a retransmit-until-success transmission strategy to deliver packets to the\nDM over the lossy link, in which the packet losses are modeled as a Bernoulli\nprocess, with different loss probabilities before and after the change. We pose\nthe QCD problem in the non-Bayesian setting under Lorden's framework, and\npropose a CUSUM algorithm. By defining a suitable Markov process, involving the\nDM measurements and the queue length process, we show that the problem reduces\nto QCD in a Markov process. Characterizing the information measure per\nmeasurement sample at the DM, we establish the asymptotic optimality of our\nalgorithm when the false alarm rate tends to zero. Further, when the DM\nreceives incomplete data due to channel loss, we present asymptotically optimal\nQCD algorithms by suitably modifying the CUSUM algorithm. We then explore the\nlast-come-first-served (LCFS) queuing discipline at the sensor transmit queue\nto lower detection delay in the non-asymptotic case. Next, we consider the case\nof multiple sensors, each with its own wireless transmitter queue, and show\nthat our analysis extends to the case of multiple homogeneous sensors. When the\nsensors are heterogeneous, we present a sensor scheduling algorithm that\nminimizes detection delay by balancing the trade-off between the age of the\nobservations and their information content. Numerical analysis demonstrate\ntrade-offs that can be used to optimize system design parameters in the\nnon-asymptotic regime.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5de5\u4e1a4.0\u5e94\u7528\u7684\u5feb\u901f\u53d8\u5316\u68c0\u6d4b\u65b9\u6cd5\uff0c\u8003\u8651\u65e0\u7ebf\u94fe\u8def\u4e22\u5305\u548c\u4f20\u611f\u5668\u961f\u5217\u7684\u5f71\u54cd\uff0c\u5f00\u53d1\u4e86\u57fa\u4e8eCUSUM\u7684\u6e10\u8fd1\u6700\u4f18\u7b97\u6cd5\uff0c\u5e76\u6269\u5c55\u5230\u591a\u4f20\u611f\u5668\u573a\u666f\u3002", "motivation": "\u5de5\u4e1a4.0\u5e94\u7528\u9700\u8981\u68c0\u6d4b\u8fc7\u7a0b\u4e2d\u7684\u7a81\u7136\u53d8\u5316\uff0c\u4f46\u6d4b\u91cf\u6570\u636e\u901a\u8fc7\u6709\u635f\u65e0\u7ebf\u94fe\u8def\u4f20\u8f93\uff0c\u5b58\u5728\u4e22\u5305\u548c\u961f\u5217\u5ef6\u8fdf\u95ee\u9898\uff0c\u9700\u8981\u8bbe\u8ba1\u6709\u6548\u7684\u5feb\u901f\u53d8\u5316\u68c0\u6d4b\u7b97\u6cd5\u3002", "method": "\u4f7f\u7528\u4f2f\u52aa\u5229\u91c7\u6837\u8fc7\u7a0b\uff0c\u91c7\u7528\u91cd\u4f20\u81f3\u6210\u529f\u7684\u4f20\u8f93\u7b56\u7565\uff0c\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u8fc7\u7a0b\uff0c\u63d0\u51faCUSUM\u7b97\u6cd5\uff0c\u5e76\u8003\u8651LCFS\u961f\u5217\u7b56\u7565\u548c\u591a\u4f20\u611f\u5668\u8c03\u5ea6\u3002", "result": "\u8bc1\u660e\u4e86\u7b97\u6cd5\u5728\u8bef\u62a5\u7387\u8d8b\u4e8e\u96f6\u65f6\u7684\u6e10\u8fd1\u6700\u4f18\u6027\uff0c\u6570\u503c\u5206\u6790\u5c55\u793a\u4e86\u975e\u6e10\u8fd1\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u6743\u8861\uff0c\u53ef\u7528\u4e8e\u4f18\u5316\u7cfb\u7edf\u8bbe\u8ba1\u53c2\u6570\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684CUSUM\u7b97\u6cd5\u5728\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u53d8\u5316\u68c0\u6d4b\u4e2d\u5177\u6709\u6e10\u8fd1\u6700\u4f18\u6027\u80fd\uff0c\u961f\u5217\u7ba1\u7406\u548c\u4f20\u611f\u5668\u8c03\u5ea6\u7b56\u7565\u80fd\u6709\u6548\u964d\u4f4e\u68c0\u6d4b\u5ef6\u8fdf\u3002"}}
{"id": "2510.25648", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2510.25648", "abs": "https://arxiv.org/abs/2510.25648", "authors": ["Ishfaq Aziz", "Mohamad Alipour"], "title": "Continuous subsurface property retrieval from sparse radar observations using physics informed neural networks", "comment": "22 pages, 9 main text figures + 2 supplementary figures", "summary": "Estimating subsurface dielectric properties is essential for applications\nranging from environmental surveys of soils to nondestructive evaluation of\nconcrete in infrastructure. Conventional wave inversion methods typically\nassume few discrete homogeneous layers and require dense measurements or strong\nprior knowledge of material boundaries, limiting scalability and accuracy in\nrealistic settings where properties vary continuously. We present a physics\ninformed machine learning framework that reconstructs subsurface permittivity\nas a fully neural, continuous function of depth, trained to satisfy both\nmeasurement data and Maxwells equations. We validate the framework with both\nsimulations and custom built radar experiments on multilayered natural\nmaterials. Results show close agreement with in-situ permittivity measurements\n(R^2=0.93), with sensitivity to even subtle variations (Delta eps_r=2).\nParametric analysis reveals that accurate profiles can be recovered with as few\nas three strategically placed sensors in two layer systems. This approach\nreframes subsurface inversion from boundary-driven to continuous property\nestimation, enabling accurate characterization of smooth permittivity\nvariations and advancing electromagnetic imaging using low cost radar systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u5c06\u5730\u4e0b\u4ecb\u7535\u5e38\u6570\u91cd\u5efa\u4e3a\u6df1\u5ea6\u7684\u8fde\u7eed\u795e\u7ecf\u7f51\u7edc\u51fd\u6570\uff0c\u901a\u8fc7\u6a21\u62df\u548c\u96f7\u8fbe\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5176\u5728\u591a\u5c42\u5929\u7136\u6750\u6599\u4e2d\u7684\u6709\u6548\u6027\u3002", "motivation": "\u4f20\u7edf\u6ce2\u53cd\u6f14\u65b9\u6cd5\u901a\u5e38\u5047\u8bbe\u5c11\u6570\u79bb\u6563\u5747\u5300\u5c42\uff0c\u9700\u8981\u5bc6\u96c6\u6d4b\u91cf\u6216\u5bf9\u6750\u6599\u8fb9\u754c\u7684\u5f3a\u5148\u9a8c\u77e5\u8bc6\uff0c\u8fd9\u5728\u7279\u6027\u8fde\u7eed\u53d8\u5316\u7684\u5b9e\u9645\u73af\u5883\u4e2d\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\u548c\u51c6\u786e\u6027\u3002", "method": "\u4f7f\u7528\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u8bad\u7ec3\u795e\u7ecf\u7f51\u7edc\u6ee1\u8db3\u6d4b\u91cf\u6570\u636e\u548c\u9ea6\u514b\u65af\u97e6\u65b9\u7a0b\uff0c\u5c06\u5730\u4e0b\u4ecb\u7535\u5e38\u6570\u91cd\u5efa\u4e3a\u6df1\u5ea6\u7684\u8fde\u7eed\u51fd\u6570\u3002", "result": "\u4e0e\u73b0\u573a\u4ecb\u7535\u5e38\u6570\u6d4b\u91cf\u7ed3\u679c\u9ad8\u5ea6\u4e00\u81f4\uff08R^2=0.93\uff09\uff0c\u5bf9\u7ec6\u5fae\u53d8\u5316\u654f\u611f\uff08\u0394\u03b5_r=2\uff09\uff0c\u5728\u4e24\u5c42\u7cfb\u7edf\u4e2d\u4ec5\u9700\u4e09\u4e2a\u6218\u7565\u6027\u653e\u7f6e\u7684\u4f20\u611f\u5668\u5373\u53ef\u6062\u590d\u51c6\u786e\u5256\u9762\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5c06\u5730\u4e0b\u53cd\u6f14\u4ece\u8fb9\u754c\u9a71\u52a8\u91cd\u6784\u4e3a\u8fde\u7eed\u7279\u6027\u4f30\u8ba1\uff0c\u80fd\u591f\u51c6\u786e\u8868\u5f81\u5e73\u6ed1\u4ecb\u7535\u5e38\u6570\u53d8\u5316\uff0c\u63a8\u52a8\u4e86\u4f7f\u7528\u4f4e\u6210\u672c\u96f7\u8fbe\u7cfb\u7edf\u7684\u7535\u78c1\u6210\u50cf\u6280\u672f\u53d1\u5c55\u3002"}}
{"id": "2510.25693", "categories": ["eess.SP", "cs.LG", "60-04", "G.3"], "pdf": "https://arxiv.org/pdf/2510.25693", "abs": "https://arxiv.org/abs/2510.25693", "authors": ["John-Joseph Brady", "Benjamin Cox", "V\u00edctor Elvira", "Yunpeng Li"], "title": "PyDPF: A Python Package for Differentiable Particle Filtering", "comment": "42 pages, 0 figures, under review at the Journal of Statistical\n  Software, the python package can be found at https://pypi.org/project/pydpf/\n  , the full documentation at\n  https://python-dpf.readthedocs.io/en/latest/#documentation-index , and the\n  source code including experiments and replication material at\n  https://github.com/John-JoB/pydpf", "summary": "State-space models (SSMs) are a widely used tool in time series analysis. In\nthe complex systems that arise from real-world data, it is common to employ\nparticle filtering (PF), an efficient Monte Carlo method for estimating the\nhidden state corresponding to a sequence of observations. Applying particle\nfiltering requires specifying both the parametric form and the parameters of\nthe system, which are often unknown and must be estimated. Gradient-based\noptimisation techniques cannot be applied directly to standard particle\nfilters, as the filters themselves are not differentiable. However, several\nrecently proposed methods modify the resampling step to make particle filtering\ndifferentiable. In this paper, we present an implementation of several such\ndifferentiable particle filters (DPFs) with a unified API built on the popular\nPyTorch framework. Our implementation makes these algorithms easily accessible\nto a broader research community and facilitates straightforward comparison\nbetween them. We validate our framework by reproducing experiments from several\nexisting studies and demonstrate how DPFs can be applied to address several\ncommon challenges with state space modelling.", "AI": {"tldr": "\u672c\u6587\u5b9e\u73b0\u4e86\u4e00\u4e2a\u57fa\u4e8ePyTorch\u7684\u7edf\u4e00API\uff0c\u7528\u4e8e\u51e0\u79cd\u53ef\u5fae\u5206\u7c92\u5b50\u6ee4\u6ce2\u5668(DPFs)\uff0c\u4f7f\u8fd9\u4e9b\u7b97\u6cd5\u66f4\u6613\u8bbf\u95ee\u5e76\u4fbf\u4e8e\u6bd4\u8f83\u3002", "motivation": "\u7c92\u5b50\u6ee4\u6ce2\u5668\u5728\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u4e2d\u5f88\u5e38\u7528\uff0c\u4f46\u6807\u51c6\u7c92\u5b50\u6ee4\u6ce2\u5668\u4e0d\u53ef\u5fae\u5206\uff0c\u65e0\u6cd5\u76f4\u63a5\u5e94\u7528\u68af\u5ea6\u4f18\u5316\u3002\u6700\u8fd1\u63d0\u51fa\u7684\u53ef\u5fae\u5206\u7c92\u5b50\u6ee4\u6ce2\u5668\u89e3\u51b3\u4e86\u8fd9\u4e2a\u95ee\u9898\uff0c\u4f46\u7f3a\u4e4f\u7edf\u4e00\u7684\u5b9e\u73b0\u6846\u67b6\u3002", "method": "\u5728PyTorch\u6846\u67b6\u4e0a\u6784\u5efa\u7edf\u4e00API\uff0c\u5b9e\u73b0\u591a\u79cd\u53ef\u5fae\u5206\u7c92\u5b50\u6ee4\u6ce2\u5668\uff0c\u901a\u8fc7\u4fee\u6539\u91cd\u91c7\u6837\u6b65\u9aa4\u4f7f\u7c92\u5b50\u6ee4\u6ce2\u53ef\u5fae\u5206\u3002", "result": "\u6210\u529f\u590d\u73b0\u4e86\u591a\u4e2a\u73b0\u6709\u7814\u7a76\u7684\u5b9e\u9a8c\uff0c\u5c55\u793a\u4e86DPFs\u5982\u4f55\u89e3\u51b3\u72b6\u6001\u7a7a\u95f4\u5efa\u6a21\u4e2d\u7684\u5e38\u89c1\u6311\u6218\u3002", "conclusion": "\u8be5\u5b9e\u73b0\u4f7f\u53ef\u5fae\u5206\u7c92\u5b50\u6ee4\u6ce2\u5668\u66f4\u6613\u4e8e\u8bbf\u95ee\uff0c\u4fc3\u8fdb\u4e86\u7b97\u6cd5\u6bd4\u8f83\u548c\u5e94\u7528\u7814\u7a76\u3002"}}
{"id": "2510.25751", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2510.25751", "abs": "https://arxiv.org/abs/2510.25751", "authors": ["Diego Cuevas", "Mikel Guti\u00e9rrez", "Jes\u00fas Ib\u00e1\u00f1ez", "Ignacio Santamaria"], "title": "Low Probability of Detection Communication Using Noncoherent Grassmannian Signaling", "comment": "5 pages, 6 figures, conference", "summary": "This paper proposes a noncoherent low probability of detection (LPD)\ncommunication system based on direct sequence spread spectrum (DSSS) and\nGrassmannian signaling. Grassmannian constellations enhance covertness because\nthey tend to follow a noise-like distribution. Simulations showed that\nGrassmannian signaling provides competitive bit error rates (BER) at low\nsignal-to-noise ratio (SNR) regimes with low probability of detection at the\nunintended receiver compared to coherent schemes that use QPSK or QAM\nmodulation formats and need pilots to perform channel estimation. The results\nsuggest the practicality and security benefits of noncoherent Grassmannian\nsignaling for LPD communications due to their improved covertness and\nperformance.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u76f4\u63a5\u5e8f\u5217\u6269\u9891\u548cGrassmannian\u4fe1\u53f7\u7684\u975e\u76f8\u5e72\u4f4e\u68c0\u6d4b\u6982\u7387\u901a\u4fe1\u7cfb\u7edf\uff0c\u901a\u8fc7\u566a\u58f0\u5206\u5e03\u7279\u6027\u589e\u5f3a\u9690\u853d\u6027\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u63d0\u4f9b\u7ade\u4e89\u6027\u8bef\u7801\u7387\u6027\u80fd\u3002", "motivation": "\u4f20\u7edf\u76f8\u5e72\u65b9\u6848\u9700\u8981\u5bfc\u9891\u8fdb\u884c\u4fe1\u9053\u4f30\u8ba1\uff0c\u5b58\u5728\u68c0\u6d4b\u98ce\u9669\u3002Grassmannian\u4fe1\u53f7\u5177\u6709\u566a\u58f0\u5206\u5e03\u7279\u6027\uff0c\u53ef\u589e\u5f3a\u901a\u4fe1\u9690\u853d\u6027\uff0c\u9002\u7528\u4e8e\u4f4e\u68c0\u6d4b\u6982\u7387\u901a\u4fe1\u573a\u666f\u3002", "method": "\u7ed3\u5408\u76f4\u63a5\u5e8f\u5217\u6269\u9891\u6280\u672f\u548cGrassmannian\u4fe1\u53f7\u8bbe\u8ba1\u975e\u76f8\u5e72\u901a\u4fe1\u7cfb\u7edf\uff0c\u5229\u7528Grassmannian\u661f\u5ea7\u7684\u566a\u58f0\u5206\u5e03\u7279\u6027\u63d0\u9ad8\u9690\u853d\u6027\u3002", "result": "\u4eff\u771f\u663e\u793aGrassmannian\u4fe1\u53f7\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u63d0\u4f9b\u7ade\u4e89\u6027\u8bef\u7801\u7387\u6027\u80fd\uff0c\u76f8\u6bd4\u4f7f\u7528QPSK\u6216QAM\u8c03\u5236\u7684\u76f8\u5e72\u65b9\u6848\uff0c\u5728\u975e\u76ee\u6807\u63a5\u6536\u5668\u5904\u5177\u6709\u66f4\u4f4e\u7684\u68c0\u6d4b\u6982\u7387\u3002", "conclusion": "\u975e\u76f8\u5e72Grassmannian\u4fe1\u53f7\u5728\u4f4e\u68c0\u6d4b\u6982\u7387\u901a\u4fe1\u4e2d\u5177\u6709\u5b9e\u7528\u6027\u548c\u5b89\u5168\u6027\u4f18\u52bf\uff0c\u56e0\u5176\u6539\u8fdb\u7684\u9690\u853d\u6027\u548c\u6027\u80fd\u8868\u73b0\u3002"}}

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 24]
- [eess.AS](#eess.AS) [Total: 6]
- [cs.SD](#cs.SD) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [AI-Enhanced Wi-Fi Sensing Through Single Transceiver Pair](https://arxiv.org/abs/2511.02845)
*Yuxuan Liu,Chiya Zhang,Yifeng Yuan,Chunlong He,Weizheng Zhang,Gaojie Chen*

Main category: eess.SP

TL;DR: AI驱动的Wi-Fi感知系统在硬件受限条件下，通过先验信息和时间相关性突破传统雷达理论的分辨率限制，实现高精度人体姿态估计和室内定位。


<details>
  <summary>Details</summary>
Motivation: 研究AI驱动的Wi-Fi感知系统如何突破传统雷达理论的分辨率限制，特别是在硬件受限条件下（如最小带宽和天线数量），探索其性能提升的理论基础。

Method: 开发基于AI的Wi-Fi感知系统，使用单个收发器对，通过人体姿态估计和室内定位实验验证理论假设，重点分析先验信息和时间相关性对感知性能的影响。

Result: 实验证实时间相关性和先验信息确实带来了性能提升，验证了AI在Wi-Fi感知系统中突破传统分辨率限制的理论机制。

Conclusion: 在硬件受限的Wi-Fi感知系统中，AI的性能提升主要来源于先验信息（基于模糊输入生成合理细节）和时间相关性（降低感知误差上限），这为下一代Wi-Fi技术的大规模部署提供了理论基础。

Abstract: The advancement of next-generation Wi-Fi technology heavily relies on sensing
capabilities, which play a pivotal role in enabling sophisticated applications.
In response to the growing demand for large-scale deployments, contemporary
Wi-Fi sensing systems strive to achieve high-precision perception while
maintaining minimal bandwidth consumption and antenna count requirements.
Remarkably, various AI-driven perception technologies have demonstrated the
ability to surpass the traditional resolution limitations imposed by radar
theory. However, the theoretical underpinnings of this phenomenon have not been
thoroughly investigated in existing research. In this study, we found that
under hardware-constrained conditions, the performance gains brought by AI to
Wi-Fi sensing systems primarily originate from two aspects: prior information
and temporal correlation. Prior information enables the AI to generate
plausible details based on vague input, while temporal correlation helps reduce
the upper bound of sensing error. We developed an AI-based Wi-Fi sensing system
using a single transceiver pair and designed experiments focusing on human pose
estimation and indoor localization to validate the theoretical claims. The
results confirm the performance gains contributed by temporal correlation and
prior information.

</details>


### [2] [Spatio-Temporal Attention Network for Epileptic Seizure Prediction](https://arxiv.org/abs/2511.02846)
*Zan Li,Kyongmin Yeo,Wesley Gifford,Lara Marcuse,Madeline Fields,Bülent Yener*

Main category: eess.SP

TL;DR: 提出了一种基于时空注意力网络(STAN)的深度学习框架，通过建模EEG信号的复杂时空相关性来准确预测癫痫发作，无需特征工程或固定预发作持续时间假设。


<details>
  <summary>Details</summary>
Motivation: 现有癫痫预测方法依赖特征工程和/或假设固定的预发作持续时间，无法有效建模EEG信号的复杂时空相关性。

Method: 使用时空注意力网络(STAN)同时建模时空相关性，并采用对抗判别器区分预发作和发作间期的注意力模式，实现患者特异性学习。

Result: 在CHB-MIT数据集上达到96.6%的敏感性和0.011/h的误检率，在MSSM数据集上达到94.2%的敏感性和0.063/h的误检率，显著优于现有方法。

Conclusion: 该框架能可靠地至少在发作前15分钟检测到预发作状态，患者特异性窗口可延长至45分钟，为临床应用提供了足够的干预时间。

Abstract: In this study, we present a deep learning framework that learns complex
spatio-temporal correlation structures of EEG signals through a Spatio-Temporal
Attention Network (STAN) for accurate predictions of onset of seizures for
Epilepsy patients. Unlike existing methods, which rely on feature engineering
and/or assume fixed preictal durations, our approach simultaneously models
spatio-temporal correlations through STAN and employs an adversarial
discriminator to distinguish preictal from interictal attention patterns,
enabling patient-specific learning. Evaluation on CHB-MIT and MSSM datasets
demonstrates 96.6\% sensitivity with 0.011/h false detection rate on CHB-MIT,
and 94.2% sensitivity with 0.063/h FDR on MSSM, significantly outperforming
state-of-the-art methods. The framework reliably detects preictal states at
least 15 minutes before an onset, with patient-specific windows extending to 45
minutes, providing sufficient intervention time for clinical applications.

</details>


### [3] [EEGReXferNet: A Lightweight Gen-AI Framework for EEG Subspace Reconstruction via Cross-Subject Transfer Learning and Channel-Aware Embedding](https://arxiv.org/abs/2511.02848)
*Shantanu Sarkar,Piotr Nabrzyski,Saurabh Prasad,Jose Luis Contreras-Vidal*

Main category: eess.SP

TL;DR: EEGReXferNet是一个轻量级生成式AI框架，通过跨被试迁移学习进行EEG子空间重建，解决了传统EEG去噪方法的问题，提高了时空频谱分辨率并减少了计算负担。


<details>
  <summary>Details</summary>
Motivation: 传统EEG信号去噪方法需要人工干预或在滤波/重建过程中可能抑制关键神经特征，而现有的生成模型方法缺乏集成的时空频谱敏感性且计算量大，不适合脑机接口等实时应用。

Method: EEGReXferNet采用模块化架构，利用相邻通道的容积传导、频带特定卷积编码和滑动窗口的动态潜在特征提取，通过基于参考的缩放确保窗口间的连续性，并实现跨被试的有效泛化。

Result: 该框架提高了时空频谱分辨率（平均PSD相关性≥0.95；平均频谱图RV系数≥0.85），总权重减少约45%以减轻过拟合，并保持了计算效率。

Conclusion: EEGReXferNet为神经生理学和脑机接口应用提供了稳健、实时的EEG预处理解决方案，通过轻量级设计和跨被试迁移学习解决了现有方法的局限性。

Abstract: Electroencephalography (EEG) is a widely used non-invasive technique for
monitoring brain activity, but low signal-to-noise ratios (SNR) due to various
artifacts often compromise its utility. Conventional artifact removal methods
require manual intervention or risk suppressing critical neural features during
filtering/reconstruction. Recent advances in generative models, including
Variational Autoencoders (VAEs) and Generative Adversarial Networks (GANs),
have shown promise for EEG reconstruction; however, these approaches often lack
integrated temporal-spectral-spatial sensitivity and are computationally
intensive, limiting their suitability for real-time applications like
brain-computer interfaces (BCIs). To overcome these challenges, we introduce
EEGReXferNet, a lightweight Gen-AI framework for EEG subspace reconstruction
via cross-subject transfer learning - developed using Keras TensorFlow
(v2.15.1). EEGReXferNet employs a modular architecture that leverages volume
conduction across neighboring channels, band-specific convolution encoding, and
dynamic latent feature extraction through sliding windows. By integrating
reference-based scaling, the framework ensures continuity across successive
windows and generalizes effectively across subjects. This design improves
spatial-temporal-spectral resolution (mean PSD correlation >= 0.95; mean
spectrogram RV-Coefficient >= 0.85), reduces total weights by ~45% to mitigate
overfitting, and maintains computational efficiency for robust, real-time EEG
preprocessing in neurophysiological and BCI applications.

</details>


### [4] [Benchmarking ResNet for Short-Term Hypoglycemia Classification with DiaData](https://arxiv.org/abs/2511.02849)
*Beyza Cinar,Maria Maleshkova*

Main category: eess.SP

TL;DR: 本研究改进了DiaData数据集的质量，通过异常值处理、缺失值插补等方法提升T1D数据分析的可靠性，并展示了质量提升对低血糖分类模型性能的积极影响。


<details>
  <summary>Details</summary>
Motivation: T1D个体化治疗需要高质量数据支持，但现有数据存在异常值、噪声和小样本问题，影响分析的可靠性。

Method: 使用IQR方法识别异常值并用缺失值替换；小间隙（≤25分钟）用线性插值，大间隙（30-120分钟）用Stineman插值；分析血糖与心率相关性；使用ResNet模型进行低血糖分类。

Result: Stineman插值比线性插值提供更现实的血糖估计；血糖与心率在低血糖前15-60分钟有中等相关性；使用更多数据训练提升性能7%，使用质量优化数据比原始数据提升2-3%。

Conclusion: 数据质量改进显著提升了T1D数据分析的可靠性，为个体化治疗提供了更好的数据基础。

Abstract: Individualized therapy is driven forward by medical data analysis, which
provides insight into the patient's context. In particular, for Type 1 Diabetes
(T1D), which is an autoimmune disease, relationships between demographics,
sensor data, and context can be analyzed. However, outliers, noisy data, and
small data volumes cannot provide a reliable analysis. Hence, the research
domain requires large volumes of high-quality data. Moreover, missing values
can lead to information loss. To address this limitation, this study improves
the data quality of DiaData, an integration of 15 separate datasets containing
glucose values from 2510 subjects with T1D. Notably, we make the following
contributions: 1) Outliers are identified with the interquartile range (IQR)
approach and treated by replacing them with missing values. 2) Small gaps
($\le$ 25 min) are imputed with linear interpolation and larger gaps ($\ge$ 30
and $<$ 120 min) with Stineman interpolation. Based on a visual comparison,
Stineman interpolation provides more realistic glucose estimates than linear
interpolation for larger gaps. 3) After data cleaning, the correlation between
glucose and heart rate is analyzed, yielding a moderate relation between 15 and
60 minutes before hypoglycemia ($\le$ 70 mg/dL). 4) Finally, a benchmark for
hypoglycemia classification is provided with a state-of-the-art ResNet model.
The model is trained with the Maindatabase and Subdatabase II of DiaData to
classify hypoglycemia onset up to 2 hours in advance. Training with more data
improves performance by 7% while using quality-refined data yields a 2-3% gain
compared to raw data.

</details>


### [5] [ECGXtract: Deep Learning-based ECG Feature Extraction for Automated CVD Diagnosis](https://arxiv.org/abs/2511.02850)
*Youssif Abuzied,Hassan AbdEltawab,Abdelrhman Gaber,Tamer ElBatt*

Main category: eess.SP

TL;DR: ECGXtract是一种基于深度学习的可解释ECG特征提取方法，通过卷积神经网络提取与临床验证真值强相关的时域和形态特征，在多个实验设置下表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统信号处理和黑盒机器学习方法在ECG特征提取中的局限性，开发可解释且精确的特征提取方法。

Method: 使用卷积神经网络模型，每个模型训练提取单个特征以确保精确性和可解释性，实验评估包括全局与导联特定特征、不同采样频率，并与ECGdeli等方法比较。

Result: ECGXtract在全局特征上平均相关性得分为0.80，导联II表现最佳；导联特定特征平均相关性得分为0.822；在90%的特征上优于ECGdeli。语义分组对全局特征有效，但大规模分组和导联特定多输出模型性能下降。

Conclusion: 结构化分组策略可在计算效率和模型准确性之间取得平衡，为资源受限环境下开发可扩展且临床可解释的ECG特征提取系统铺平道路。

Abstract: This paper presents ECGXtract, a deep learning-based approach for
interpretable ECG feature extraction, addressing the limitations of traditional
signal processing and black-box machine learning methods. In particular, we
develop convolutional neural network models capable of extracting both temporal
and morphological features with strong correlations to a clinically validated
ground truth. Initially, each model is trained to extract a single feature,
ensuring precise and interpretable outputs. A series of experiments is then
carried out to evaluate the proposed method across multiple setups, including
global versus lead-specific features, different sampling frequencies, and
comparisons with other approaches such as ECGdeli. Our findings show that
ECGXtract achieves robust performance across most features with a mean
correlation score of 0.80 with the ground truth for global features, with lead
II consistently providing the best results. For lead-specific features,
ECGXtract achieves a mean correlation score of 0.822. Moreover, ECGXtract
achieves superior results to the state-of-the-art open source ECGdeli as it got
a higher correlation score with the ground truth in 90% of the features.
Furthermore, we explore the feasibility of extracting multiple features
simultaneously utilizing a single model. Semantic grouping is proved to be
effective for global features, while large-scale grouping and lead-specific
multi-output models show notable performance drops. These results highlight the
potential of structured grouping strategies to balance the computational
efficiency vs. model accuracy, paving the way for more scalable and clinically
interpretable ECG feature extraction systems in limited resource settings.

</details>


### [6] [Approaching Low-Cost Cardiac Intelligence with Semi-Supervised Knowledge Distillation](https://arxiv.org/abs/2511.02851)
*Rushuang Zhou,Yuan-Ting Zhang,M. Jamal Deen,Yining Dong*

Main category: eess.SP

TL;DR: LiteHeart是一个半监督知识蒸馏框架，通过区域感知蒸馏和跨层互信息模块，显著缩小了低成本心脏智能系统与高成本系统之间的诊断性能差距。


<details>
  <summary>Details</summary>
Motivation: 先进的心脏AI在日常监测中面临医疗数据需求大、计算资源高的问题，而低成本心脏智能系统虽然使用可穿戴设备数据，但与高成本系统存在显著的诊断性能差距。

Method: 提出LiteHeart框架，包含区域感知蒸馏模块（模拟心脏病专家关注诊断相关ECG区域）和跨层互信息模块（对齐LCCI和HCCI系统的决策过程），采用半监督训练策略提高模型鲁棒性。

Result: 在涵盖38种心血管疾病的5个数据集上评估，LiteHeart将LCCI与HCCI之间的性能差距显著缩小，在宏观F1分数上比现有方法提升4.27%至7.10%。

Conclusion: LiteHeart显著增强了低成本心脏智能系统的诊断能力，为使用可穿戴技术实现可扩展、经济实惠且准确的日常心脏保健铺平了道路。

Abstract: Deploying advanced cardiac artificial intelligence for daily cardiac
monitoring is hindered by its reliance on extensive medical data and high
computational resources. Low-cost cardiac intelligence (LCCI) offers a
promising alternative by using wearable device data, such as 1-lead
electrocardiogram (ECG), but it suffers from a significant diagnostic
performance gap compared to high-cost cardiac intelligence (HCCI). To bridge
this gap, we propose LiteHeart, a semi-supervised knowledge distillation
framework. LiteHeart introduces a region-aware distillation module to mimic how
cardiologists focus on diagnostically relevant ECG regions and a cross-layer
mutual information module to align the decision processes of LCCI and HCCI
systems. Using a semi-supervised training strategy, LiteHeart further improves
model robustness under limited supervision. Evaluated on five datasets covering
over 38 cardiovascular diseases, LiteHeart substantially reduces the
performance gap between LCCI and HCCI, outperforming existing methods by 4.27%
to 7.10% in macro F1 score. These results demonstrate that LiteHeart
significantly enhances the diagnostic capabilities of low-cost cardiac
intelligence systems, paving the way for scalable, affordable, and accurate
daily cardiac healthcare using wearable technologies.

</details>


### [7] [Real-Time Interactive Hybrid Ocean: Spectrum-Consistent Wave Particle-FFT Coupling](https://arxiv.org/abs/2511.02852)
*Shengze Xue,Yu Ren,Jiacheng Hong,Run Ni,Shuangjiu Xiao,Deli Dong*

Main category: eess.SP

TL;DR: 提出了一种实时交互式混合海洋模型，将全局FFT背景与局部波粒子区域相结合，在统一频谱参数下实现大规模光谱真实性和细粒度交互性。


<details>
  <summary>Details</summary>
Motivation: 传统FFT海洋模型假设全局平稳性和空间均匀性，难以表示非均匀海洋和近场交互；而波粒子方法虽然能捕捉局部波浪，但大规模维护成本高且难以匹配全局光谱统计。

Method: 采用混合海洋表示：全局FFT背景与局部波粒子区域在统一频谱下耦合；基于频率分桶的粒子采样和GPU并行合成方案，保持光谱能量一致性。

Result: 实现了大规模光谱一致性的同时支持局部波浪和涟漪，在实时交互性能下提供统一框架。

Conclusion: 该混合方法成功结合了FFT海洋的大尺度真实性和波粒子的局部交互能力，为实时海洋模拟提供了有效解决方案。

Abstract: Fast Fourier Transform-based (FFT) spectral oceans are widely adopted for
their efficiency and large-scale realism, but they assume global stationarity
and spatial homogeneity, making it difficult to represent non-uniform seas and
near-field interactions (e.g., ships and floaters). In contrast, wave particles
capture local wakes and ripples, yet are costly to maintain at scale and hard
to match global spectral statistics.We present a real-time interactive hybrid
ocean: a global FFT background coupled with local wave-particle (WP) patch
regions around interactive objects, jointly driven under a unified set of
spectral parameters and dispersion. At patch boundaries, particles are injected
according to the same directional spectrum as the FFT, aligning the local
frequency-direction distribution with the background and matching energy
density, without disturbing the far field.Our approach introduces two main
innovations: (1) Hybrid ocean representation. We couple a global FFT background
with local WP patches under a unified spectrum, achieving large-scale spectral
consistency while supporting localized wakes and ripples.(2) Frequency-bucketed
implementation. We design a particle sampling and GPU-parallel synthesis scheme
based on frequency buckets, which preserves spectral energy consistency and
sustains real-time interactive performance.Together, these innovations enable a
unified framework that delivers both large-scale spectral realism and
fine-grained interactivity in real time.

</details>


### [8] [Consciousness-ECG Transformer for Conscious State Estimation System with Real-Time Monitoring](https://arxiv.org/abs/2511.02853)
*Young-Seok Kweon,Gi-Hwan Shin,Ji-Yong Kim,Bokyeong Ryu,Seong-Whan Lee*

Main category: eess.SP

TL;DR: 提出基于心电图的意识状态估计系统，使用解耦查询注意力transformer模型，在睡眠分期和麻醉监测任务中优于基线方法，为临床环境提供可靠替代方案。


<details>
  <summary>Details</summary>
Motivation: 传统意识状态监测主要依赖脑电图，但存在噪声敏感、环境要求高等问题，需要开发更可靠、非侵入的替代方法。

Method: 使用心电图信号，构建consciousness-ECG transformer模型，采用解耦查询注意力机制捕捉心率变异性特征来区分意识状态。

Result: 在睡眠分期任务中准确率达0.877，麻醉监测准确率达0.880，AUC值分别为0.786和0.895，均优于基线模型。

Conclusion: 基于心电图的意识监测系统为临床环境提供了实用且鲁棒的替代方案，有望提升患者安全并促进对意识状态的理解。

Abstract: Conscious state estimation is important in various medical settings,
including sleep staging and anesthesia management, to ensure patient safety and
optimize health outcomes. Traditional methods predominantly utilize
electroencephalography (EEG), which faces challenges such as high sensitivity
to noise and the requirement for controlled environments. In this study, we
propose the consciousness-ECG transformer that leverages electrocardiography
(ECG) signals for non-invasive and reliable conscious state estimation. Our
approach employs a transformer with decoupled query attention to effectively
capture heart rate variability features that distinguish between conscious and
unconscious states. We implemented the conscious state estimation system with
real-time monitoring and validated our system on datasets involving sleep
staging and anesthesia level monitoring during surgeries. Experimental results
demonstrate that our model outperforms baseline models, achieving accuracies of
0.877 on sleep staging and 0.880 on anesthesia level monitoring. Moreover, our
model achieves the highest area under curve values of 0.786 and 0.895 on sleep
staging and anesthesia level monitoring, respectively. The proposed system
offers a practical and robust alternative to EEG-based methods, particularly
suited for dynamic clinical environments. Our results highlight the potential
of ECG-based consciousness monitoring to enhance patient safety and advance our
understanding of conscious states.

</details>


### [9] [NEF-NET+: Adapting Electrocardio panorama in the wild](https://arxiv.org/abs/2511.02880)
*Zehui Zhan,Yaojun Hu,Jiajing Zhan,Wanchen Lian,Wanqing Wu,Jintai Chen*

Main category: eess.SP

TL;DR: NEF-NET+是一个增强的心电图全景合成框架，能够从任意视角生成任意长度的心电信号，克服了传统多导联心电图系统的固定视角限制。


<details>
  <summary>Details</summary>
Motivation: 传统多导联心电图系统只能从固定的解剖视角捕捉心脏信号，而某些心脏疾病需要非标准视角才能显示诊断关键模式。现有的Nef-Net方法在现实应用中面临长时程建模、设备特异性伪影和电极放置偏差等挑战。

Method: 设计了一个新的模型架构，执行直接视角变换，包含离线预训练、设备校准调优步骤以及用于患者特定适应的实时校准步骤。

Result: 实验结果显示，NEF-NET+相比Nef-Net在真实世界设置中PSNR提高了约6 dB，构建了包含5367个记录、每个受试者48个视角的新基准Panobench。

Conclusion: NEF-NET+显著提升了全景心电图合成的性能，能够更好地适应现实世界应用场景，为心脏电活动空间变异性研究提供了有力工具。

Abstract: Conventional multi-lead electrocardiogram (ECG) systems capture cardiac
signals from a fixed set of anatomical viewpoints defined by lead placement.
However, certain cardiac conditions (e.g., Brugada syndrome) require
additional, non-standard viewpoints to reveal diagnostically critical patterns
that may be absent in standard leads. To systematically overcome this
limitation, Nef-Net was recently introduced to reconstruct a continuous
electrocardiac field, enabling virtual observation of ECG signals from
arbitrary views (termed Electrocardio Panorama). Despite its promise, Nef-Net
operates under idealized assumptions and faces in-the-wild challenges, such as
long-duration ECG modeling, robustness to device-specific signal artifacts, and
suboptimal lead placement calibration. This paper presents NEF-NET+, an
enhanced framework for realistic panoramic ECG synthesis that supports
arbitrary-length signal synthesis from any desired view, generalizes across ECG
devices, and compensates for operator-induced deviations in electrode
placement. These capabilities are enabled by a newly designed model
architecture that performs direct view transformation, incorporating a workflow
comprising offline pretraining, device calibration tuning steps as well as an
on-the-fly calibration step for patient-specific adaptation. To rigorously
evaluate panoramic ECG synthesis, we construct a new Electrocardio Panorama
benchmark, called Panobench, comprising 5367 recordings with 48-view per
subject, capturing the full spatial variability of cardiac electrical activity.
Experimental results show that NEF-NET+ delivers substantial improvements over
Nef-Net, yielding an increase of around 6 dB in PSNR in real-world setting. The
code and Panobench will be released in a subsequent publication.

</details>


### [10] [Adaptive Internal Calibration for Temperature-Robust mmWave FMCW Radars](https://arxiv.org/abs/2511.02884)
*Dariush Salami,Nima Bahmani,Hüseyin Yiğitler,Stephan Sigg*

Main category: eess.SP

TL;DR: 提出了一种用于毫米波FMCW雷达的内部校准框架，通过温度补偿模型减少温度漂移对测量精度的影响，在密集无线网络中实现稳健性能。


<details>
  <summary>Details</summary>
Motivation: 解决毫米波FMCW雷达在内部温度变化下性能不稳定的问题，特别是在密集无线网络部署中确保测量可靠性。

Method: 利用内部传感器数据和信号处理技术构建温度补偿模型，减少温度引起的硬件漂移。

Result: 实验结果显示，该方法将中频信号幅度与内部温度漂移的皮尔逊相关性降低了84%，显著减轻了温度漂移影响，且计算开销小。

Conclusion: 该框架在保持测量精度的同时，通过内部校准机制增强了雷达在温度变化环境下的鲁棒性，适用于密集网络部署。

Abstract: We present a novel internal calibration framework for Millimeter- Wave
(mmWave) Frequency-Modulated Continuous-Wave (FMCW) radars to ensure robust
performance under internal temperature variations, tailored for deployment in
dense wireless networks. Our approach mitigates the impact of
temperature-induced drifts in radar hardware, enhancing reliability. We propose
a temperature compensation model that leverages internal sensor data and signal
processing techniques to maintain measurement accuracy. Experimental results
demonstrate improved robustness across a range of internal temperature
conditions, with minimal computational overhead, ensuring scalability in dense
network environments. The framework also incorporates ethical design
principles, avoiding reliance on sensitive external data. The proposed scheme
reduces the Pearson correlation between the amplitude of the Intermediate
Frequency (IF) signal and internal temperature drift up to 84%, significantly
mitigating the temperature drift.

</details>


### [11] [From Narrow to Wide: Autoencoding Transformers for Ultrasound Bandwidth Recovery](https://arxiv.org/abs/2511.02938)
*Sepideh KhakzadGharamaleki,Hassan Rivaz,Brandon Helfield*

Main category: eess.SP

TL;DR: 提出一种基于ViT自编码器的数据驱动方法，将窄带超声RF信号映射为宽带频谱图，显著提升图像质量而不牺牲帧率或相位信息。


<details>
  <summary>Details</summary>
Motivation: 传统脉冲回波超声在低成本窄带探头下性能受限，脉冲延长导致高频细节丢失，限制了资源受限环境中的高分辨率超声应用。

Method: 使用改进的Tiny ViT自编码器在仿真数据上训练，采用课程加权损失函数，学习从窄带到宽带RF频谱图的映射。

Result: 在异质斑块-囊肿体模上，图像域MSE降低90%，PSNR提升6.7 dB，SSIM达到0.965；在未见过的分辨率体模中也能锐化点目标，表现出强大的分布外泛化能力。

Conclusion: 纯软件升级可使现有窄带探头获得类似宽带的性能，有望在资源受限环境中推广高分辨率超声应用。

Abstract: Conventional pulse-echo ultrasound suffers when low-cost probes deliver only
narrow fractional bandwidths, elongating pulses and erasing high-frequency
detail. We address this limitation by learning a data-driven mapping from
band-limited to broadband spectrogram of radio-frequency (RF) lines. To this
end, a variation of Tiny Vision Transform (ViT) auto-encoder is trained on
simulation data using a curriculum-weighted loss. On heterogeneous speckle-cyst
phantoms, the network reduces image-domain MSE by 90 percent, boosts PSNR by
6.7 dB, and raises SSIM to 0.965 compared with the narrow-band input. It also
sharpens point-target rows in a completely unseen resolution phantom,
demonstrating strong out-of-distribution generalisation without sacrificing
frame rate or phase information. These results indicate that a purely software
upgrade can endow installed narrow-band probes with broadband-like performance,
potentially widening access to high-resolution ultrasound in
resource-constrained settings.

</details>


### [12] [Consensus Tracking of an Underwater Vehicle Using Weighted Harmonic Mean Density](https://arxiv.org/abs/2511.03130)
*Ved Prakash Dubey,Shovan Bhaumik*

Main category: eess.SP

TL;DR: 提出一种基于加权调和均值密度的水下目标跟踪方法，通过最小化K-L散度分配最优权重，在分布式跟踪中优于现有融合方法


<details>
  <summary>Details</summary>
Motivation: 解决水下目标跟踪问题，其中大量声纳浮标传感器部署在监视区域，需要实现多个跟踪器之间的共识融合

Method: 使用加权调和均值密度进行跟踪，通过最小化K-L散度来分配最优权重，提供高斯密度融合解决方案

Result: 仿真结果显示，优化的HMD融合方法在均方根误差、轨迹发散百分比和归一化估计误差平方等指标上优于现有融合方法

Conclusion: 提出的加权调和均值密度融合方法在分布式跟踪中表现出优越性能，能够有效实现跟踪器间的共识

Abstract: This paper addresses an underwater target tracking problem in which a large
number of sonobuoy sensors are deployed on a surveillance region. The region is
divided into several sub-regions, where a single tracker, capable of generating
track is installed. Each sonobuoy can measure the direction of arrival of
acoustic signals (known as bearing angles) and communicate the measurements
with the local tracker. Further, each local tracker can communicate with all
other trackers, where each of them can exchange their estimate and finally a
consensus is reached. We propose a weighted harmonic mean density (HMD) based
tracking to reach a consensus and provide a solution for the fusion of Gaussian
densities. In this approach, optimal weights are assigned by minimizing the
Kullback-Leibler divergence measure. Performance of the proposed method is
measured using root mean square error, percentage of track divergence, and
normalized estimation error squared. Simulation results demonstrate that the
optimized HMD-based fusion outperforms existing fusion methods during a
distributed tracking.

</details>


### [13] [Analysis and Algorithm for Multi IRS Collaborative Localization via Hybrid Time Angle Estimation](https://arxiv.org/abs/2511.03133)
*Ziheng Zhang,Wen Chen,Qingqing Wu,Haoran Qin,Zhendong Li,Qiong Wu*

Main category: eess.SP

TL;DR: 提出了一种基于多智能反射面协作的混合定位系统，通过联合时延和角度估计实现目标定位，并设计了接近克拉美罗界的估计算法。


<details>
  <summary>Details</summary>
Motivation: 传统定位系统在低信噪比条件下性能受限，需要开发更精确的定位方法来满足现代通信和感知需求。

Method: 使用多IRS协作，通过联合时延和角度估计，采用原子范数最小化和ADMM算法进行角度估计，以及三阶段定位算法处理误差。

Result: 数值仿真验证了系统在协作、混合定位和分布式部署方面的优势，特别是在低信噪比条件下算法精度显著。

Conclusion: 所提出的多IRS协作混合定位系统能够有效提高定位精度，特别是在恶劣信道条件下表现出优越性能。

Abstract: This paper proposes a novel multiple intelligent reflecting surfaces (IRSs)
collaborative hybrid localization system, which involves deploying multiple
IRSs near the target area and achieving target localization through joint time
delay and angle estimation. Specifically, echo signals from all reflective
elements are received by each sensor and jointly processed to estimate the time
delay and angle parameters. Based on the above model, we derive the Fisher
Information Matrix (FIM) for cascaded delay, Angle of Arrival (AOA), and Angle
of Departure (AOD) estimation in semi passive passive models, along with the
corresponding Cramer Rao Bound (CRB). To achieve precise estimation close to
the CRB, we design efficient algorithms for angle and location estimation. For
angle estimation, reflective signals are categorized into three cases based on
their rank, with different signal preprocessing. By constructing an atomic norm
set and minimizing the atomic norm, the joint angle estimation problem is
transformed into a convex optimization problem, and low-complexity estimation
of multiple AOA and AOD pairs is achieved using the Alternating Direction
Method of Multipliers (ADMM). For location estimation, we propose a three-stage
localization algorithm that combines weighted least squares, total least
squares, and quadratic correction to handle errors in the coefficient matrix
and observation vector, thus improving accuracy. Numerical simulations validate
the superiority of the proposed system, demonstrating that the system's
collaboration, hybrid localization, and distributed deployment provide
substantial benefits, as well as the accuracy of the proposed estimation
algorithms, particularly in low signal to noise ratio (SNR) condition.

</details>


### [14] [Multimodal-Wireless: A Large-Scale Dataset for Sensing and Communication](https://arxiv.org/abs/2511.03220)
*Tianhao Mao,Le Liang,Jie Yang,Hao Ye,Shi Jin,Geoffrey Ye Li*

Main category: eess.SP

TL;DR: Multimodal-Wireless是一个用于无线通信研究的开源多模态感知数据集，包含约16万帧数据，涵盖通信信道、激光雷达、RGB和深度相机、惯性测量单元和雷达等多种传感模态。


<details>
  <summary>Details</summary>
Motivation: 为无线通信研究提供高质量的多模态感知数据集，支持通信和协同感知等研究方向。

Method: 基于CARLA模拟器和Sionna框架构建集成可定制数据管道，在四个虚拟城镇、十六个通信场景和三种天气条件下收集数据。

Result: 成功创建包含约16万帧多模态数据的开放数据集，并展示了使用多模态大语言模型进行波束预测的应用示例。

Conclusion: 该数据集为无线通信研究提供了宝贵的资源，支持多模态感知和通信技术的融合发展。

Abstract: This paper presents Multimodal-Wireless, an open-source multimodal sensing
dataset designed for wireless communication research. The dataset is generated
through an integrated and customizable data pipeline built upon the CARLA
simulator and Sionna framework. It contains approximately 160,000 frames
collected across four virtual towns, sixteen communication scenarios, and three
weather conditions, encompassing multiple sensing modalities--communication
channel, light detection and ranging, RGB and depth cameras, inertial
measurement unit, and radar. This paper provides a comprehensive overview of
the dataset, outlining its key features, overall framework, and technical
implementation details. In addition, it explores potential research
applications concerning communication and collaborative perception, exemplified
by beam prediction using a multimodal large language model. The dataset is open
in https://le-liang.github.io/mmw/.

</details>


### [15] [Integrated Sensing and Communication with UAV Swarms via Decentralized Consensus ADMM](https://arxiv.org/abs/2511.03283)
*Zhiyuan Zhai,Wei Ni,Xin Wang,Dusit Niyato,Ekram Hossain*

Main category: eess.SP

TL;DR: 提出了一种去中心化的无人机群优化框架，通过共识ADMM算法让无人机并行决策位置，达成全局最优的ISAC几何构型。


<details>
  <summary>Details</summary>
Motivation: 无人机群形成虚拟天线阵列可增强集成感知与通信性能，但由于分布式特性和缺乏全局视角，位置优化具有挑战性。

Method: 使用共识交替方向乘子法(ADMM)，将全局目标分解为局部投影更新、代理辅助的共识协调和轻量级对偶更新。

Result: 算法收敛快速且扩展性强，无人机群在通信和感知性能上显著优于固定阵列基线。

Conclusion: 所提出的去中心化共识ADMM框架能有效解决无人机群ISAC位置优化问题，实现全局最优性能。

Abstract: UAV swarms can form virtual antenna arrays to exploit additional spatial
degrees of freedom and enhance integrated sensing and communication (ISAC). The
optimization of UAV positions is challenging due to the distributed nature of
swarms and the lack of a global view at individual UAVs.
  This paper presents a new decentralized optimization framework that allows
UAVs to decide their locations in parallel and reach consensus on a globally
optimal swarm geometry for ISAC.
  Specifically, we derive the achievable uplink rate and Cram\'er-Rao Bound
(CRB) as tractable metrics for communication and sensing, respectively.
  The UAV positions are optimized to balance maximizing the communication rate
and minimizing the CRB.
  To solve this non-convex problem with coupled variables, we develop a
decentralized consensus alternating direction method of multipliers (ADMM)
algorithm, which enables the UAVs to iteratively align their local updates and
reach consensus.
  The algorithm decomposes the global objective into local projection updates,
proxy-assisted consensus coordination, and lightweight dual updates, ensuring
scalability and consistency throughout the swarm.
  Simulations demonstrate that the proposed consensus ADMM algorithm converges
rapidly with strong scalability, and that the UAV swarm significantly
outperforms fixed-array baselines in both communication and sensing
performance.

</details>


### [16] [Decentralized Federated Learning with Distributed Aggregation Weight Optimization](https://arxiv.org/abs/2511.03284)
*Zhiyuan Zhai,Xiaojun Yuan,Xin Wang,Geoffrey Ye Li*

Main category: eess.SP

TL;DR: 提出了一种分布式聚合权重优化算法，用于去中心化联邦学习，通过本地D2D通信优化聚合权重来最小化收敛边界。


<details>
  <summary>Details</summary>
Motivation: 传统去中心化联邦学习依赖中心实体收集信息并优化权重，这与去中心化特性不符，需要开发真正分布式的权重优化方法。

Method: 将聚合权重优化问题转化为特征值优化问题，提出基于次梯度的分布式算法，仅需本地信息和D2D通信即可获得最优权重。

Result: 数值结果表明该算法在实际DFL部署中具有优越性能。

Conclusion: 实现了真正分布式的DFL系统，优化、通信和学习过程均可分布式进行。

Abstract: Decentralized federated learning (DFL) is an emerging paradigm to enable edge
devices collaboratively training a learning model using a device-to-device
(D2D) communication manner without the coordination of a parameter server (PS).
Aggregation weights, also known as mixing weights, are crucial in DFL process,
and impact the learning efficiency and accuracy. Conventional design relies on
a so-called central entity to collect all local information and conduct system
optimization to obtain appropriate weights. In this paper, we develop a
distributed aggregation weight optimization algorithm to align with the
decentralized nature of DFL. We analyze convergence by quantitatively capturing
the impact of the aggregation weights over decentralized communication
networks. Based on the analysis, we then formulate a learning performance
optimization problem by designing the aggregation weights to minimize the
derived convergence bound. The optimization problem is further transformed as
an eigenvalue optimization problem and solved by our proposed subgradient-based
algorithm in a distributed fashion. In our algorithm, edge devices only need
local information to obtain the optimal aggregation weights through local (D2D)
communications, just like the learning itself. Therefore, the optimization,
communication, and learning process can be all conducted in a distributed
fashion, which leads to a genuinely distributed DFL system. Numerical results
demonstrate the superiority of the proposed algorithm in practical DFL
deployment.

</details>


### [17] [Diffusion-Driven Terahertz Air-Ground Communications under Dynamic Atmospheric Turbulence](https://arxiv.org/abs/2511.03290)
*Jinhao Yi,Weijun Gao,Chong Han*

Main category: eess.SP

TL;DR: 提出了一种AI赋能的太赫兹空-地通信框架，通过流体动力学建模飞机湍流引起的衰减，并采用扩散算法联合优化发射功率和飞机姿态，显著提升链路容量。


<details>
  <summary>Details</summary>
Motivation: 现有研究往往忽略飞机高速移动引起的强烈湍流对太赫兹通信的额外传播损耗，需要建立精确的湍流衰减模型并优化通信性能。

Method: 建立基于流体动力学的湍流衰减模型，构建联合功率-姿态优化问题，使用扩散算法学习飞行配置与湍流衰减的非线性关系进行高效求解。

Result: 湍流引起的衰减在-10度到10度攻击角、0.7马赫条件下达到18-28dB；所提框架平均容量达11.241bps/Hz，比现有策略提升22.8%和66.5%，接近理论容量极限的98%。

Conclusion: 飞机诱导湍流对太赫兹传播有显著影响，所提出的AI赋能框架能有效缓解湍流衰减，大幅提升空-地太赫兹通信性能。

Abstract: The ever-increasing demand for ultra-high data rates in space-air-ground
integrated networks (SAGINs) has rendered terahertz THz communications a
promising technology owing to its exceptionally broad and continuous spectrum
resources. Nevertheless, in air-ground (AG) scenarios, the high mobility of
aircraft induces intense and rapidly fluctuating turbulence, leading to
additional propagation loss that is often overlooked in existing studies. To
bridge this gap, this paper presents an AI-empowered THz AG communication
framework that explicitly models turbulence-induced attenuation through fluid
dynamics and integrates it into an adaptive optimization paradigm for
communication performance enhancement. Specifically, a fluid-dynamics-informed
attenuation model is established to characterize aircraft-generated turbulence
and quantify its impact on THz signal propagation. Building upon this model, a
joint power-attitude optimization problem is formulated to adaptively allocate
transmit power and adjust aircraft attitude for maximizing link capacity. The
optimization problem is efficiently solved using a diffusion-based algorithm
that learns the nonlinear relationship between flight configuration and
turbulence-induced attenuation. Comprehensive numerical evaluations demonstrate
that the turbulence-induced attenuation ranges from 18 to 28 dB under attacking
angles between -10 degree and 10 degree at 0.7 Mach, verifying the pronounced
impact of aircraft-induced turbulence on THz propagation. Furthermore, the
proposed framework attains an average capacity of 11.241 bps/Hz, substantially
outperforming existing strategies by 22.8% and 66.5%, and approaching
approximately 98% of the theoretical capacity limit.

</details>


### [18] [Spectral-Convergent Decentralized Machine Learning: Theory and Application in Space Networks](https://arxiv.org/abs/2511.03291)
*Zhiyuan Zhai,Shuyan Hu,Wei Ni,Xiaojun Yuan,Xin Wang*

Main category: eess.SP

TL;DR: 本文研究了去中心化机器学习在随机拓扑网络中的收敛性问题，建立了混合过程谱特性与全局性能的直接联系，并提出了一种谱优化方法来提升在概率性链路故障下的收敛效率。


<details>
  <summary>Details</summary>
Motivation: 去中心化机器学习在大规模网络中支持无中心服务器的协作训练，但对设备间通信质量敏感，容易出现时变和随机拓扑。需要研究不可靠通信对DML收敛的影响。

Method: 提出了一个谱优化问题，最小化期望二阶混合矩阵的谱半径以提升收敛速率。设计了基于次梯度的分布式算法，结合切比雪夫加速特征向量估计与本地更新和聚合权重调整，确保对称性和随机性约束。

Result: 在低地球轨道卫星星座上的实验表明，该方法相比现有基线显著提高了分类准确性和收敛效率，验证了在卫星和其他去中心化系统中的适用性。

Conclusion: 提出的谱优化方法能有效提升去中心化机器学习在不可靠通信环境下的性能，为卫星网络等实际应用提供了可行的解决方案。

Abstract: Decentralized machine learning (DML) supports collaborative training in
large-scale networks with no central server. It is sensitive to the quality and
reliability of inter-device communications that result in time-varying and
stochastic topologies. This paper studies the impact of unreliable
communication on the convergence of DML and establishes a direct connection
between the spectral properties of the mixing process and the global
performance. We provide rigorous convergence guarantees under random topologies
and derive bounds that characterize the impact of the expected mixing matrix's
spectral properties on learning. We formulate a spectral optimization problem
that minimizes the spectral radius of the expected second-order mixing matrix
to enhance the convergence rate under probabilistic link failures. To solve
this non-smooth spectral problem in a fully decentralized manner, we design an
efficient subgradient-based algorithm that integrates Chebyshev-accelerated
eigenvector estimation with local update and aggregation weight adjustment,
while ensuring symmetry and stochasticity constraints without central
coordination. Experiments on a realistic low Earth orbit (LEO) satellite
constellation with time-varying inter-satellite link models and real-world
remote sensing data demonstrate the feasibility and effectiveness of the
proposed method. The method significantly improves classification accuracy and
convergence efficiency compared to existing baselines, validating its
applicability in satellite and other decentralized systems.

</details>


### [19] [UAV SAR Imaging with 5G NR OFDM Signals in NLOS Environments](https://arxiv.org/abs/2511.03292)
*Qiuyuan Yang,Cunhua Pan,Ruidong Li,Zhenkun Zhang,Hong Ren,Changhong Wang,Jiangzhou Wang*

Main category: eess.SP

TL;DR: 提出了一种基于OFDM通信信号的协作式感知与通信一体化SAR成像框架，采用两阶段压缩感知-空间交替广义期望最大化方案，在非视距环境下实现高精度散射体定位。


<details>
  <summary>Details</summary>
Motivation: 解决在非视距环境下合成孔径雷达成像性能严重退化的问题，利用ISAC技术实现高效的频谱利用和新型应用场景。

Method: 采用两阶段CS-SAGE方案：第一阶段使用正交匹配追踪进行粗估计，识别主要散射体的大致位置；第二阶段使用SAGE算法进行精细估计，准确提取散射体参数。

Result: 仿真结果验证了所提协作ISAC框架的有效性，为实际系统设计提供了有价值的见解。

Conclusion: 所提出的协作ISAC框架在非视距环境下能够有效提升SAR成像性能，为未来无线系统提供了可行的技术方案。

Abstract: The integration of sensing and communication (ISAC) has significant potential
for future wireless systems, enabling efficient spectrum utilization and novel
application scenarios. In this paper, we propose a cooperative ISAC framework
for synthetic aperture radar (SAR) imaging by leveraging orthogonal frequency
division multiplexing (OFDM) communication signals. We address the challenge of
severe imaging degradation in non-line-of-sight (NLOS) environments under the
QUAsi Deterministic RadIo channel GenerAtor (QuaDRiGa). To detect weak signals
and eliminate false points, we develop a two-stage compressed sensing-space
alternating generalized expectation maximization (CS-SAGE) scheme for
high-precision scatterer localization. In stage I, orthogonal matching pursuit
(OMP) is employed for coarse estimation to identify the approximate locations
of dominant scatterers. Then, the SAGE algorithm in stage II performs fine
estimation to accurately extract scatterer parameters. Simulation results
validate the effectiveness of the proposed cooperative ISAC framework, and
provide valuable insights for practical system design.

</details>


### [20] [C-RAN Advanced: From a Network Cooperation Perspective](https://arxiv.org/abs/2511.03302)
*Xiaoyun Wang,Yutong Zhang,Sen Wang,Sun Qi,Hanning Wang,Qixing Wang,Jing Jin,Jiwei He,Nan Li*

Main category: eess.SP

TL;DR: 提出了一种新型的CIS-RAN架构，将协作通信扩展到协作感知和协作AI，通过全流程网络协作提升6G网络性能。


<details>
  <summary>Details</summary>
Motivation: 6G网络需要从传统通信服务向综合信息服务转变，推动RAN架构向增强协作、智能化和服务导向演进。

Method: 基于C-RAN概念，提出CIS-RAN架构，整合协作通信、协作感知和协作AI，在采集、传输和处理全过程中增强网络协作。

Result: 通过网络协作MIMO案例研究，数值结果显示相比传统架构具有优越性能。

Conclusion: CIS-RAN架构在6G网络中具有重要应用前景，未来研究方向应继续探索和推进网络协作的增强。

Abstract: Future mobile networks in the sixth generation (6G) are poised for a paradigm
shift from conventional communication services toward comprehensive information
services, driving the evolution of radio access network (RAN) architectures
toward enhanced cooperation, intelligence, and service orientation. Building
upon the concept of centralized, collaborative, cloud, and clean RAN (C-RAN),
this article proposes a novel cooperative, intelligent, and service-based RAN
(CIS-RAN) architecture. Focusing on cooperation, CIS-RAN extends the
traditional cooperative communication paradigm by further integrating
cooperative sensing and cooperative artificial intelligence (AI). To improve
both performance and effectiveness across diverse application scenarios,
CIS-RAN enhances network cooperation throughout the entire process of
acquisition, transmission, and processing, thereby enabling efficient
information acquisition, diverse cooperative interactions, and intelligent
fusion decision-making. Key technologies are discussed, with network
cooperative multiple-input multiple-output (MIMO) examined as a case study,
demonstrating superior performance over traditional architectures, as
demonstrated by numerical results. Future research directions are outlined,
emphasizing the continued exploration and advancement of the CIS-RAN
architecture, particularly in enhancing network cooperation.

</details>


### [21] [Performance Analysis of Wireless-Powered Pinching Antenna Systems](https://arxiv.org/abs/2511.03401)
*Kunrui Cao,Jingyu Chen,Panagiotis D. Diamantoulakis,Lei Zhou,Xingwang Li,Yuanwei Liu,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 本文提出了无线供电的夹持天线系统(PAS)，通过灵活调整夹持天线位置建立强视距链路来降低自由空间路径损耗。研究了无线供电PAS的可靠性，推导了损耗和无损耗波导情况下的中断概率和遍历速率的闭式表达式，分析了波导和用户的最优部署策略。


<details>
  <summary>Details</summary>
Motivation: 探索夹持天线在改善无线供电通信系统性能方面的优势，通过建立强视距链路来减少自由空间路径损耗，提高系统可靠性。

Method: 引入无线供电PAS概念，推导了损耗和无损耗波导情况下的中断概率和遍历速率的闭式表达式，分析了波导和用户的最优部署策略，包括时间分配因子和功率站与接入点间最优距离的优化。

Result: 吸收系数和用户区域尺寸的增加会导致更高的波导内和自由空间传播损耗，从而提高中断概率并降低遍历速率。在高吸收系数和长波导条件下，无线供电PAS的中断概率比传统WPC系统更差，但遍历速率更好。系统存在最优时间分配因子和PS-AP间最优距离来最小化中断概率或最大化遍历速率。

Conclusion: 无线供电PAS在PS和AP分离部署于最优距离时的系统性能优于PS和AP集成到混合接入点的方案。系统性能受吸收系数和波导长度严重影响，需要优化部署策略来充分发挥PAS的优势。

Abstract: Pinching antenna system (PAS) serves as a groundbreaking paradigm that
enhances wireless communications by flexibly adjusting the position of pinching
antenna (PA) and establishing a strong line-of-sight (LoS) link, thereby
reducing the free-space path loss. This paper introduces the concept of
wireless-powered PAS, and investigates the reliability of wireless-powered PAS
to explore the advantages of PA in improving the performance of
wireless-powered communication (WPC) system. In addition, we derive the
closed-form expressions of outage probability and ergodic rate for the
practical lossy waveguide case and ideal lossless waveguide case, respectively,
and analyze the optimal deployment of waveguides and user to provide valuable
insights for guiding their deployments. The results show that an increase in
the absorption coefficient and in the dimensions of the user area leads to
higher in-waveguide and free-space propagation losses, respectively, which in
turn increase the outage probability and reduce the ergodic rate of the
wireless-powered PAS. However, the performance of wireless-powered PAS is
severely affected by the absorption coefficient and the waveguide length, e.g.,
under conditions of high absorption coefficient and long waveguide, the outage
probability of wireless-powered PAS is even worse than that of traditional WPC
system. While the ergodic rate of wireless-powered PAS is better than that of
traditional WPC system under conditions of high absorption coefficient and long
waveguide. Interestingly, the wireless-powered PAS has the optimal time
allocation factor and optimal distance between power station (PS) and access
point (AP) to minimize the outage probability or maximize the ergodic rate.
Moreover, the system performance of PS and AP separated at the optimal distance
between PS and AP is superior to that of PS and AP integrated into a hybrid
access point.

</details>


### [22] [A Modified Pulse and Design Framework to Halve the Complexity of OFDM Spectral Shaping Techniques](https://arxiv.org/abs/2511.03465)
*Javier Giménez,José A. Cortés,Francisco Javier Cañete,Eduardo Martos-Naya,Luis Díez*

Main category: eess.SP

TL;DR: 提出一种改进的OFDM波形，可降低频谱整形技术的优化和实现成本，最多减少50%的系数和乘积运算


<details>
  <summary>Details</summary>
Motivation: OFDM调制存在高带外发射问题，现有频谱整形技术虽然有效但涉及复杂的优化过程和实时实现成本

Method: 对传统OFDM波形进行修改，为频谱整形技术提供框架支持，减少优化系数和实现乘积运算

Result: 该方法可将优化涉及的系数数量和实现所需的乘积运算数量减少高达50%

Conclusion: 该改进方法显著降低了频谱整形技术的成本，为未来研究提供了成本降低的框架

Abstract: Orthogonal frequency division multiplexing (OFDM) is a widespread modulation
but suffers from high out-of-band emissions (OOBE). Spectral shaping strategies
such as precoding, active interference cancellation (AIC) and time-domain
methods are effective at reducing the OOBE but entail optimization procedures
and real-time implementation costs which might be considerable. This letter
proposes a modification of the conventional OFDM waveform aimed at reducing the
cost associated to many of the state-of-theart spectral shaping techniques and
sets a framework for future works that want to benefit from the same reduction.
This approach may reduce both the number of coefficients involved in the
optimization and the number of products of its implementation by up to 50%.

</details>


### [23] [A Novel Multi-Reference-Point Modeling Framework for Monostatic Background Channel: Toward 3GPP ISAC Standardization](https://arxiv.org/abs/2511.03487)
*Yameng Liu,Jianhua Zhang,Yuxiang Zhang,Zhiqiang Yuan,Chuangxin Jiang,Junchen Liu,Wei Hong,Yingyang Li,Yan Li,Guangyi Liu*

Main category: eess.SP

TL;DR: 本文提出了一种用于6G集成感知与通信(ISAC)单静态背景信道的新型随机模型，通过将信道建模为单静态收发器与多个参考点之间的子信道叠加，解决了3GPP标准兼容的ISAC信道建模关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有通信标准主要针对分离的收发器建模，而ISAC单静态模式（收发器共址）的背景信道建模仍是一个紧迫挑战，这对评估复杂环境中的感知性能至关重要。

Method: 首先在28GHz频段进行室内ISAC单静态背景信道测量，提取实际信道参数；然后提出将ISAC单静态背景信道建模为单静态收发器与多个通信接收器样参考点之间子信道的叠加；最后使用遗传算法优化多参考点的数量和位置。

Result: 测量结果显示信道具有明显的单跳传播和离散多径分布特性；验证结果表明所提模型能有效捕捉单静态背景信道特性，解决了ISAC信道建模的关键空白。

Conclusion: 该模型与标准化兼容，提出的3GPP扩展实现框架支持6G标准化，为ISAC系统设计提供了现实且标准兼容的信道模型。

Abstract: Integrated Sensing and Communication (ISAC) has been identified as a key 6G
application by ITU and 3GPP. A realistic, standard-compatible channel model is
essential for ISAC system design. To characterize the impact of Sensing Targets
(STs), 3GPP defines ISAC channel as a combination of target and background
channels, comprising multipath components related to STs and those originating
solely from the environment, respectively. Although the background channel does
not carry direct ST information, its accurate modeling is critical for
evaluating sensing performance, especially in complex environments. Existing
communication standards characterize propagation between separated transmitter
(Tx) and receiver (Rx). However, modeling background channels in the ISAC
monostatic mode, where the Tx and Rx are co-located, remains a pressing
challenge. In this paper, we firstly conduct ISAC monostatic background channel
measurements for an indoor scenario at 28 GHz. Realistic channel parameters are
extracted, revealing pronounced single-hop propagation and discrete multipath
distribution. Inspired by these properties, a novel stochastic model is
proposed to characterizing the ISAC monostatic background channel as the
superposition of sub-channels between the monostatic Tx&Rx and multiple
communication Rx-like Reference Points (RPs). This model is compatible with
standardizations, and a 3GPP-extended implementation framework is introduced.
Finally, a genetic algorithm-based method is proposed to extract the optimal
number and placement of multi-RPs. The optimization approach and modeling
framework are validated by comparing measured and simulated channel parameters.
Results demonstrate that the proposed model effectively captures monostatic
background channel characteristics, addresses a critical gap in ISAC channel
modeling, and supports 6G standardization.

</details>


### [24] [3D Cooperative User Tracking for Distributed Integrated Sensing and Communication](https://arxiv.org/abs/2511.03612)
*Yingjie Xu,Xuesong Cai,Michiel Sandra,Sara Willhammar,Fredrik Tufvesson*

Main category: eess.SP

TL;DR: 提出了一个分布式ISAC系统中协同用户跟踪的完整框架，通过全局PHD滤波器和视场感知AP管理策略，实现了厘米级精度的用户轨迹跟踪，并优化了AP调度效率。


<details>
  <summary>Details</summary>
Motivation: 随着ISAC成为6G网络的重要组成部分，分布式ISAC有望通过其去中心化架构提升感知和通信性能，需要解决协同用户跟踪的挑战。

Method: 采用全局概率假设密度(PHD)滤波器和视场感知的接入点(AP)管理策略，结合分布式MIMO信道测量来评估框架有效性。

Result: 实现了厘米级的均方根轨迹误差，并证明无需始终保持所有AP活跃即可维持高跟踪精度。

Conclusion: 研究结果为分布式ISAC系统中协同用户跟踪技术的实际部署和进一步发展提供了重要见解，强调了稳健高效的AP管理的必要性。

Abstract: As integrated sensing and communication (ISAC) becomes an integral part of 6G
networks, distributed ISAC (DISAC) is expected to enhance both sensing and
communication performance through its decentralized architecture. This paper
presents a complete framework to address the challenge of cooperative user
tracking in DISAC systems. By incorporating a global probability hypothesis
density (PHD) filter and a field-of-view-aware access point (AP) management
strategy, the framework enables accurate user tracking using radio signals
while optimizing AP scheduling. In addition, a real-world distributed MIMO
channel measurement campaign is performed to evaluate the effectiveness of the
framework. The results demonstrate that a centimeter-level root mean-square
trajectory error can be achieved. Furthermore, the results show that it is not
necessary to keep APs active at all times to maintain high tracking accuracy,
indicating the need for robust and efficient AP management. These findings
provide valuable insight into practical deployments and further development of
cooperative user tracking techniques in DISAC systems.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [25] [Quantifying Articulatory Coordination as a Biomarker for Schizophrenia](https://arxiv.org/abs/2511.03084)
*Gowtham Premananth,Carol Espy-Wilson*

Main category: eess.AS

TL;DR: 提出了一种基于语音特征的可解释框架，通过特征谱差异图和加权指数衰减和来量化声带协调性，为精神分裂症提供透明、严重程度敏感的语音生物标志物。


<details>
  <summary>Details</summary>
Motivation: 尽管AI和深度学习在医疗诊断中有所进展，但有限的可解释性阻碍了临床采用。精神分裂症作为复杂疾病，需要能够捕捉症状严重程度并提供临床意义洞察的工具，而不仅仅是二元诊断。

Method: 利用发音语音特征，通过特征谱差异图和加权指数衰减和（WSED）来量化声带协调性。特征谱图有效区分复杂与简单协调模式，WSED分数可靠分离这些组别。

Result: WSED分数不仅与总体BPRS严重程度相关，还与阳性和阴性症状的平衡相关，反映了阳性症状明显患者更复杂的协调模式，而阴性症状明显患者则呈现相反趋势。

Conclusion: 该方法为精神分裂症提供了透明、严重程度敏感的语音生物标志物，推进了临床可解释的语音评估工具的潜力。

Abstract: Advances in artificial intelligence (AI) and deep learning have improved
diagnostic capabilities in healthcare, yet limited interpretability continues
to hinder clinical adoption. Schizophrenia, a complex disorder with diverse
symptoms including disorganized speech and social withdrawal, demands tools
that capture symptom severity and provide clinically meaningful insights beyond
binary diagnosis. Here, we present an interpretable framework that leverages
articulatory speech features through eigenspectra difference plots and a
weighted sum with exponential decay (WSED) to quantify vocal tract
coordination. Eigenspectra plots effectively distinguished complex from simpler
coordination patterns, and WSED scores reliably separated these groups, with
ambiguity confined to a narrow range near zero. Importantly, WSED scores
correlated not only with overall BPRS severity but also with the balance
between positive and negative symptoms, reflecting more complex coordination in
subjects with pronounced positive symptoms and the opposite trend for stronger
negative symptoms. This approach offers a transparent, severity-sensitive
biomarker for schizophrenia, advancing the potential for clinically
interpretable speech-based assessment tools.

</details>


### [26] [Speech-Based Prioritization for Schizophrenia Intervention](https://arxiv.org/abs/2511.03086)
*Gowtham Premananth,Philip Resnik,Sonia Bansal,Deanna L. Kelly,Carol Espy-Wilson*

Main category: eess.AS

TL;DR: 提出基于语音的成对比较模型，用于评估精神分裂症症状严重程度，通过Bradley-Terry模型生成严重程度排名，在资源受限环境下实现更好的临床分诊效果。


<details>
  <summary>Details</summary>
Motivation: 解决精神健康资源有限导致的诊断延迟问题，传统评估方法劳动密集且依赖主观自报，需要可扩展的自动化症状严重程度评估方法。

Method: 利用发音和声学特征构建语音模型，进行症状严重程度的成对比较，通过Bradley-Terry模型生成严重程度排名。

Result: 在基于排名的指标上优于之前的回归模型，为临床分诊和优先级排序提供更有效的解决方案。

Conclusion: 语音AI方法能够实现自动化、连续和远程监测，在资源受限环境中为精神分裂症症状严重程度评估提供可扩展的替代方案。

Abstract: Millions of people suffer from mental health conditions, yet many remain
undiagnosed or receive delayed care due to limited clinical resources and
labor-intensive assessment methods. While most machine-assisted approaches
focus on diagnostic classification, estimating symptom severity is essential
for prioritizing care, particularly in resource-constrained settings.
Speech-based AI provides a scalable alternative by enabling automated,
continuous, and remote monitoring, reducing reliance on subjective self-reports
and time-consuming evaluations. In this paper, we introduce a speech-based
model for pairwise comparison of schizophrenia symptom severity, leveraging
articulatory and acoustic features. These comparisons are used to generate
severity rankings via the Bradley-Terry model. Our approach outperforms
previous regression-based models on ranking-based metrics, offering a more
effective solution for clinical triage and prioritization.

</details>


### [27] [TASU: Text-Only Alignment for Speech Understanding](https://arxiv.org/abs/2511.03310)
*Jing Peng,Yi Yang,Xu Li,Yu Xi,Quanwei Tang,Yangui Fang,Junjie Li,Kai Yu*

Main category: eess.AS

TL;DR: TASU是一种新的语音大语言模型对齐范式，仅使用非配对的文本数据来实现跨模态对齐，在零样本语音识别和多种语音理解任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前语音大语言模型的对齐方法依赖大规模音频-文本配对数据和计算密集型训练，但在未见领域或任务上的泛化能力有限。

Method: 提出TASU范式，仅利用非配对文本数据指导跨模态对齐，可作为课程学习的预训练阶段来增强领域泛化。

Result: TASU在零样本语音识别中表现优异，在MMSU基准测试中显著优于GLM-4-Voice和Step-Audio等主流语音大语言模型。

Conclusion: TASU是一种高效且可扩展的语音大语言模型对齐范式，能够扩展到广泛的语音理解任务中。

Abstract: Recent advances in Speech Large Language Models (Speech LLMs) have paved the
way for unified architectures across diverse speech understanding tasks.
However, prevailing alignment paradigms rely heavily on large-scale audio-text
paired data and computationally intensive training, yet often exhibit limited
generalization to unseen domains or tasks. To address these limitations, we
propose TASU (Text-only Alignment for Speech Understanding), a novel alignment
paradigm that can leverage only unpaired text data to guide cross-modal
alignment. Experiments show that TASU achieves competitive zero-shot speech
recognition. Leveraging this property, it can further function as a
pre-training stage in curriculum learning, enhancing domain generalization in
speech recognition. Ultimately, TASU can extend its zero-shot generalization to
a wide range of speech understanding tasks and notably outperforms prominent
Speech LLMs including GLM-4-Voice and Step-Audio on the MMSU benchmark,
establishing TASU as an efficient and scalable alignment paradigm for Speech
LLMs.

</details>


### [28] [audio2chart: End to End Audio Transcription into playable Guitar Hero charts](https://arxiv.org/abs/2511.03337)
*Riccardo Tripodi*

Main category: eess.AS

TL;DR: 音频2图表框架：从原始音频自动生成吉他英雄风格图表，通过序列预测方法生成与音频对齐的离散图表标记


<details>
  <summary>Details</summary>
Motivation: 开发能够直接从音频自动生成吉他英雄风格图表的系统，解决手动制作图表耗时耗力的问题

Method: 将任务形式化为序列预测问题，训练模型在离散时间步上生成与音频对齐的图表标记，包括无条件基线和音频条件化模型

Result: 无条件基线表现出强大的预测性能，音频条件化在所有基于准确度的指标上带来一致改进

Conclusion: 音频条件化对于自动图表生成中的音符预测既可行又有效，代码和预训练模型已开源支持可重复研究

Abstract: This work introduces audio2chart, a framework for the automatic generation of
Guitar Hero style charts directly from raw audio. The task is formalized as a
sequence prediction problem, where models are trained to generate discrete
chart tokens aligned with the audio on discrete time steps. An unconditional
baseline demonstrates strong predictive performance, while the addition of
audio conditioning yields consistent improvements across accuracy based
metrics. This work demonstrates that incorporating audio conditioning is both
feasible and effective for improving note prediction in automatic chart
generation. The complete codebase for training and inference is publicly
available on GitHub supporting reproducible research on neural chart
generation. A family of pretrained models is released on Hugging Face.

</details>


### [29] [Open Source State-Of-the-Art Solution for Romanian Speech Recognition](https://arxiv.org/abs/2511.03361)
*Gabriel Pirlogeanu,Alexandru-Lucian Georgescu,Horia Cucu*

Main category: eess.AS

TL;DR: 提出了基于NVIDIA FastConformer架构的罗马尼亚语自动语音识别系统，在2600小时语音数据上训练，使用CTC和TDT混合解码器，在多个评估基准上实现了27%的相对WER降低。


<details>
  <summary>Details</summary>
Motivation: 为罗马尼亚语开发最先进的自动语音识别系统，首次在该语言中探索FastConformer架构，解决现有系统性能不足的问题。

Method: 使用FastConformer架构，在2600小时弱监督转录语音数据上训练，采用CTC和Token-Duration Transducer混合解码器，评估多种解码策略包括贪婪解码、ALSD和CTC波束搜索结合6-gram语言模型。

Result: 在所有罗马尼亚语评估基准（包括朗读、自发和领域特定语音）上达到最先进性能，相比之前最佳系统实现高达27%的相对WER降低，同时具备实用的解码效率。

Conclusion: 该系统不仅显著提高了转录准确性，还具备低延迟ASR应用所需的解码效率，适合研究和实际部署。

Abstract: In this work, we present a new state-of-the-art Romanian Automatic Speech
Recognition (ASR) system based on NVIDIA's FastConformer architecture--explored
here for the first time in the context of Romanian. We train our model on a
large corpus of, mostly, weakly supervised transcriptions, totaling over 2,600
hours of speech. Leveraging a hybrid decoder with both Connectionist Temporal
Classification (CTC) and Token-Duration Transducer (TDT) branches, we evaluate
a range of decoding strategies including greedy, ALSD, and CTC beam search with
a 6-gram token-level language model. Our system achieves state-of-the-art
performance across all Romanian evaluation benchmarks, including read,
spontaneous, and domain-specific speech, with up to 27% relative WER reduction
compared to previous best-performing systems. In addition to improved
transcription accuracy, our approach demonstrates practical decoding
efficiency, making it suitable for both research and deployment in low-latency
ASR applications.

</details>


### [30] [Seeing What You Say: Expressive Image Generation from Speech](https://arxiv.org/abs/2511.03423)
*Jiyoung Lee,Song Park,Sanghyuk Chun,Soo-Whan Chung*

Main category: eess.AS

TL;DR: VoxStudio是首个统一的端到端语音到图像生成模型，通过联合对齐语言和副语言信息，直接从语音描述生成富有表现力的图像。核心是语音信息瓶颈模块，将原始语音压缩为紧凑的语义标记，保留韵律和情感细节。


<details>
  <summary>Details</summary>
Motivation: 现有的语音到图像系统通常需要额外的语音转文本模块，这会忽略文本之外的隐藏细节（如语调或情感）。VoxStudio旨在直接从语音生成图像，保留语音中的情感和韵律信息。

Method: 提出语音信息瓶颈模块压缩原始语音为语义标记，直接在这些标记上操作，无需语音转文本系统。同时发布了VoxEmoset数据集，通过先进的TTS引擎生成富有表现力的语音-图像对。

Result: 在SpokenCOCO、Flickr8kAudio和VoxEmoset基准测试上的综合实验证明了该方法的可行性，并突出了情感一致性和语言歧义等关键挑战。

Conclusion: VoxStudio为直接从语音生成富有表现力图像提供了可行方案，并为未来研究铺平了道路，特别是在处理情感一致性和语言歧义方面。

Abstract: This paper proposes VoxStudio, the first unified and end-to-end
speech-to-image model that generates expressive images directly from spoken
descriptions by jointly aligning linguistic and paralinguistic information. At
its core is a speech information bottleneck (SIB) module, which compresses raw
speech into compact semantic tokens, preserving prosody and emotional nuance.
By operating directly on these tokens, VoxStudio eliminates the need for an
additional speech-to-text system, which often ignores the hidden details beyond
text, e.g., tone or emotion. We also release VoxEmoset, a large-scale paired
emotional speech-image dataset built via an advanced TTS engine to affordably
generate richly expressive utterances. Comprehensive experiments on the
SpokenCOCO, Flickr8kAudio, and VoxEmoset benchmarks demonstrate the feasibility
of our method and highlight key challenges, including emotional consistency and
linguistic ambiguity, paving the way for future research.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [31] [Why Not Put a Microphone Near the Loudspeaker? A New Paradigm for Acoustic Echo Cancellation](https://arxiv.org/abs/2511.03244)
*Fei Zhao,Zhong-Qiu Wang*

Main category: cs.SD

TL;DR: 提出了一种双麦克风配置的声学回声消除方法，通过辅助参考麦克风捕获非线性失真信号，结合维纳滤波预处理和深度神经网络，有效处理现实环境中的非线性失真问题。


<details>
  <summary>Details</summary>
Motivation: 现实环境中由于低成本扬声器和复杂房间声学导致的非线性失真使得声学回声消除具有挑战性，需要更有效的解决方案。

Method: 使用双麦克风配置，辅助麦克风靠近扬声器捕获失真信号；通过维纳滤波预处理估计压缩时频掩码抑制近端语音；线性AEC阶段后，用深度神经网络进行联合残余回声和噪声抑制。

Result: 在匹配测试集上优于基线方法；在不匹配数据集上对强非线性失真表现出显著性能提升，证明其在未知非线性失真场景下的有效性。

Conclusion: 该方法通过双麦克风配置和深度学习技术，有效解决了现实环境中非线性失真带来的声学回声消除挑战，具有实际应用价值。

Abstract: Acoustic echo cancellation (AEC) remains challenging in real-world
environments due to nonlinear distortions caused by low-cost loudspeakers and
complex room acoustics. To mitigate these issues, we introduce a
dual-microphone configuration, where an auxiliary reference microphone is
placed near the loudspeaker to capture the nonlinearly distorted far-end
signal. Although this reference signal is contaminated by near-end speech, we
propose a preprocessing module based on Wiener filtering to estimate a
compressed time-frequency mask to suppress near-end components. This purified
reference signal enables a more effective linear AEC stage, whose residual
error signal is then fed to a deep neural network for joint residual echo and
noise suppression. Evaluation results show that our method outperforms baseline
approaches on matched test sets. To evaluate its robustness under strong
nonlinearities, we further test it on a mismatched dataset and observe that it
achieves substantial performance gains. These results demonstrate its
effectiveness in practical scenarios where the nonlinear distortions are
typically unknown.

</details>


### [32] [SyMuPe: Affective and Controllable Symbolic Music Performance](https://arxiv.org/abs/2511.03425)
*Ilya Borovik,Dmitrii Gavrilev,Vladimir Viro*

Main category: cs.SD

TL;DR: 提出SyMuPe框架和PianoFlow模型，用于开发情感可控的符号钢琴演奏模型，通过条件流匹配支持无条件生成和音乐特征填充，在情感控制方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 机器学习模型在音乐演奏渲染中难以实现类人表达和情感，需要开发能够控制情感表达的符号钢琴演奏模型。

Method: 使用条件流匹配训练PianoFlow模型，解决多掩码演奏修复任务；集成钢琴演奏情感分类器，使用情感加权的Flan-T5文本嵌入作为条件输入。

Result: 客观和主观评估显示PianoFlow优于基于Transformer的基线模型，性能质量可与人类录制和转录的MIDI样本相媲美。

Conclusion: 该模型可集成到交互应用中，有助于创建更易访问和引人入胜的音乐演奏系统。

Abstract: Emotions are fundamental to the creation and perception of music
performances. However, achieving human-like expression and emotion through
machine learning models for performance rendering remains a challenging task.
In this work, we present SyMuPe, a novel framework for developing and training
affective and controllable symbolic piano performance models. Our flagship
model, PianoFlow, uses conditional flow matching trained to solve diverse
multi-mask performance inpainting tasks. By design, it supports both
unconditional generation and infilling of music performance features. For
training, we use a curated, cleaned dataset of 2,968 hours of aligned musical
scores and expressive MIDI performances. For text and emotion control, we
integrate a piano performance emotion classifier and tune PianoFlow with the
emotion-weighted Flan-T5 text embeddings provided as conditional inputs.
Objective and subjective evaluations against transformer-based baselines and
existing models show that PianoFlow not only outperforms other approaches, but
also achieves performance quality comparable to that of human-recorded and
transcribed MIDI samples. For emotion control, we present and analyze samples
generated under different text conditioning scenarios. The developed model can
be integrated into interactive applications, contributing to the creation of
more accessible and engaging music performance systems.

</details>

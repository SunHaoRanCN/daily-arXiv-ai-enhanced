{"id": "2511.08720", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.08720", "abs": "https://arxiv.org/abs/2511.08720", "authors": ["Saba Asaad", "Chongjun Ouyang", "Ali Bereyhi", "Zhiguo Ding"], "title": "Dynamic and Static Energy Efficient Design of Pinching Antenna Systems", "comment": "6 pages, 4 figures, 2 algorithms", "summary": "We study the energy efficiency of pinching-antenna systems (PASSs) by developing a consistent formulation for power distribution in these systems. The per-antenna power distribution in PASSs is not controlled explicitly by a power allocation policy, but rather implicitly through tuning of pinching couplings and locations. Both these factors are tunable: (i) pinching locations are tuned using movable elements, and (ii) couplings can be tuned by varying the effective coupling length of the pinching elements. While the former is feasible to be addressed dynamically in settings with low user mobility, the latter cannot be addressed at a high rate. We thus develop a class of hybrid dynamic-static algorithms, which maximize the energy efficiency by updating the system parameters at different rates. Our experimental results depict that dynamic tuning of pinching locations can significantly boost energy efficiency of PASSs.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u634f\u5408\u5929\u7ebf\u7cfb\u7edf\u7684\u80fd\u91cf\u6548\u7387\uff0c\u5f00\u53d1\u4e86\u529f\u7387\u5206\u5e03\u7684\u4e00\u81f4\u6027\u516c\u5f0f\uff0c\u5e76\u63d0\u51fa\u4e86\u6df7\u5408\u52a8\u6001-\u9759\u6001\u7b97\u6cd5\u6765\u6700\u5927\u5316\u80fd\u91cf\u6548\u7387\u3002", "motivation": "\u7814\u7a76\u634f\u5408\u5929\u7ebf\u7cfb\u7edf\u7684\u80fd\u91cf\u6548\u7387\uff0c\u56e0\u4e3a\u8fd9\u7c7b\u7cfb\u7edf\u4e2d\u7684\u6bcf\u5929\u7ebf\u529f\u7387\u5206\u5e03\u4e0d\u662f\u901a\u8fc7\u529f\u7387\u5206\u914d\u7b56\u7565\u663e\u5f0f\u63a7\u5236\uff0c\u800c\u662f\u901a\u8fc7\u8c03\u6574\u634f\u5408\u8026\u5408\u548c\u4f4d\u7f6e\u9690\u5f0f\u63a7\u5236\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u7c7b\u6df7\u5408\u52a8\u6001-\u9759\u6001\u7b97\u6cd5\uff0c\u901a\u8fc7\u4ee5\u4e0d\u540c\u901f\u7387\u66f4\u65b0\u7cfb\u7edf\u53c2\u6570\u6765\u6700\u5927\u5316\u80fd\u91cf\u6548\u7387\u3002\u5176\u4e2d\u634f\u5408\u4f4d\u7f6e\u53ef\u4ee5\u901a\u8fc7\u53ef\u79fb\u52a8\u5143\u4ef6\u52a8\u6001\u8c03\u6574\uff0c\u800c\u8026\u5408\u5219\u901a\u8fc7\u6539\u53d8\u634f\u5408\u5143\u4ef6\u7684\u6709\u6548\u8026\u5408\u957f\u5ea6\u6765\u8c03\u6574\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u52a8\u6001\u8c03\u6574\u634f\u5408\u4f4d\u7f6e\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u634f\u5408\u5929\u7ebf\u7cfb\u7edf\u7684\u80fd\u91cf\u6548\u7387\u3002", "conclusion": "\u634f\u5408\u5929\u7ebf\u7cfb\u7edf\u7684\u80fd\u91cf\u6548\u7387\u53ef\u4ee5\u901a\u8fc7\u6df7\u5408\u52a8\u6001-\u9759\u6001\u7b97\u6cd5\u5f97\u5230\u663e\u8457\u63d0\u5347\uff0c\u7279\u522b\u662f\u5728\u4f4e\u7528\u6237\u79fb\u52a8\u6027\u573a\u666f\u4e0b\u52a8\u6001\u8c03\u6574\u634f\u5408\u4f4d\u7f6e\u6548\u679c\u660e\u663e\u3002"}}
{"id": "2511.08769", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.08769", "abs": "https://arxiv.org/abs/2511.08769", "authors": ["Anuab Sen", "Mir Sayeed Mohammad", "Saibal Mukhopadhyay"], "title": "SSMRadNet : A Sample-wise State-Space Framework for Efficient and Ultra-Light Radar Segmentation and Object Detection", "comment": null, "summary": "We introduce SSMRadNet, the first multi-scale State Space Model (SSM) based detector for Frequency Modulated Continuous Wave (FMCW) radar that sequentially processes raw ADC samples through two SSMs. One SSM learns a chirp-wise feature by sequentially processing samples from all receiver channels within one chirp, and a second SSM learns a representation of a frame by sequentially processing chirp-wise features. The latent representations of a radar frame are decoded to perform segmentation and detection tasks. Comprehensive evaluations on the RADIal dataset show SSMRadNet has 10-33x fewer parameters and 60-88x less computation (GFLOPs) while being 3.7x faster than state-of-the-art transformer and convolution-based radar detectors at competitive performance for segmentation tasks.", "AI": {"tldr": "SSMRadNet\u662f\u9996\u4e2a\u57fa\u4e8e\u591a\u5c3a\u5ea6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684FMCW\u96f7\u8fbe\u68c0\u6d4b\u5668\uff0c\u901a\u8fc7\u4e24\u4e2aSSM\u987a\u5e8f\u5904\u7406\u539f\u59cbADC\u6837\u672c\uff0c\u5728RADIal\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e86\u6bd4\u73b0\u6709\u65b9\u6cd5\u66f4\u5c11\u7684\u53c2\u6570\u548c\u8ba1\u7b97\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u7ade\u4e89\u6027\u6027\u80fd\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u9ad8\u6548\u7684\u96f7\u8fbe\u68c0\u6d4b\u5668\uff0c\u51cf\u5c11\u53c2\u6570\u6570\u91cf\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u96f7\u8fbe\u5206\u5272\u548c\u68c0\u6d4b\u4efb\u52a1\u7684\u6027\u80fd\u3002", "method": "\u4f7f\u7528\u4e24\u4e2a\u72b6\u6001\u7a7a\u95f4\u6a21\u578b(SSM)\uff1a\u4e00\u4e2a\u5728\u5355\u4e2achirp\u5185\u987a\u5e8f\u5904\u7406\u6240\u6709\u63a5\u6536\u901a\u9053\u7684\u6837\u672c\u5b66\u4e60chirp\u7ea7\u7279\u5f81\uff0c\u53e6\u4e00\u4e2a\u987a\u5e8f\u5904\u7406chirp\u7ea7\u7279\u5f81\u5b66\u4e60\u5e27\u7ea7\u8868\u793a\uff0c\u6700\u540e\u89e3\u7801\u8fdb\u884c\u5206\u5272\u548c\u68c0\u6d4b\u3002", "result": "\u5728RADIal\u6570\u636e\u96c6\u4e0a\uff0cSSMRadNet\u6bd4\u6700\u5148\u8fdb\u7684transformer\u548c\u5377\u79ef\u96f7\u8fbe\u68c0\u6d4b\u5668\u53c2\u6570\u51cf\u5c1110-33\u500d\uff0c\u8ba1\u7b97\u91cf\u51cf\u5c1160-88\u500d\uff0c\u901f\u5ea6\u5feb3.7\u500d\uff0c\u5728\u5206\u5272\u4efb\u52a1\u4e0a\u4fdd\u6301\u7ade\u4e89\u6027\u6027\u80fd\u3002", "conclusion": "SSMRadNet\u8bc1\u660e\u4e86\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u5728\u96f7\u8fbe\u5904\u7406\u4e2d\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u663e\u8457\u51cf\u5c11\u8ba1\u7b97\u8d44\u6e90\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u68c0\u6d4b\u6027\u80fd\uff0c\u4e3a\u9ad8\u6548\u96f7\u8fbe\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.08775", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.08775", "abs": "https://arxiv.org/abs/2511.08775", "authors": ["Sergi Liesegang", "Stefano Buzzi"], "title": "Power Control Design for ISAC Optimization in User-Target-Centric Cell-Free mMIMO Networks", "comment": "This work has been accepted for publication in 2025 IEEE 26th International Workshop on Signal Processing and Artificial Intelligence for Wireless Communications (SPAWC). The final published version will be available via IEEE Xplore", "summary": "This paper addresses the power control design for a cell-free massive MIMO (CF-mMIMO) system that performs integrated sensing and communications (ISAC). Specifically, the case where many access points are deployed to simultaneously communicate with mobile users and monitor the surrounding environment at the same time-frequency slot is considered. On top of the user-centric architecture used for the data services, a target-centric approach is introduced for the detection tasks. As a valuable performance metric, we derive the receive sensing signal-to-noise (SNR) ratio under generalized likelihood ratio test processing. Based on that, we formulate a quality-of-service (QoS) scheme that maximizes the two figures of merit: achievable data rate and effective sensing SNR. Simulations demonstrate that our proposal surpasses orthogonal resource algorithms, underscoring the potential of ISAC-enabled CF-mMIMO networks.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u652f\u6301\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7684\u8702\u7a9d\u81ea\u7531\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u529f\u7387\u63a7\u5236\u8bbe\u8ba1\uff0c\u5728\u7528\u6237\u4e2d\u5fc3\u67b6\u6784\u57fa\u7840\u4e0a\u5f15\u5165\u76ee\u6807\u4e2d\u5fc3\u65b9\u6cd5\u8fdb\u884c\u68c0\u6d4b\u4efb\u52a1\uff0c\u901a\u8fc7\u6700\u5927\u5316\u6570\u636e\u901f\u7387\u548c\u611f\u77e5SNR\u6765\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u5728\u76f8\u540c\u65f6\u95f4-\u9891\u7387\u8d44\u6e90\u4e0a\u540c\u65f6\u8fdb\u884c\u79fb\u52a8\u7528\u6237\u901a\u4fe1\u548c\u73af\u5883\u76d1\u6d4b\u7684\u529f\u7387\u63a7\u5236\u95ee\u9898\uff0c\u5229\u7528\u8702\u7a9d\u81ea\u7531\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u4f18\u52bf\u5b9e\u73b0\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u529f\u80fd\u3002", "method": "\u5728\u7528\u6237\u4e2d\u5fc3\u6570\u636e\u670d\u52a1\u67b6\u6784\u4e0a\u5f15\u5165\u76ee\u6807\u4e2d\u5fc3\u68c0\u6d4b\u65b9\u6cd5\uff0c\u63a8\u5bfc\u63a5\u6536\u611f\u77e5\u4fe1\u566a\u6bd4\uff0c\u6784\u5efa\u670d\u52a1\u8d28\u91cf\u65b9\u6848\u6765\u6700\u5927\u5316\u6570\u636e\u901f\u7387\u548c\u6709\u6548\u611f\u77e5SNR\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6848\u4f18\u4e8e\u6b63\u4ea4\u8d44\u6e90\u5206\u914d\u7b97\u6cd5\uff0c\u8bc1\u660e\u4e86ISAC-enabled CF-mMIMO\u7f51\u7edc\u7684\u6f5c\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u529f\u7387\u63a7\u5236\u8bbe\u8ba1\u6709\u6548\u63d0\u5347\u4e86\u8702\u7a9d\u81ea\u7531\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7684\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u7f51\u7edc\u53d1\u5c55\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.08852", "categories": ["eess.SP", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2511.08852", "abs": "https://arxiv.org/abs/2511.08852", "authors": ["Po-Heng Chou", "Chiapin Wang", "Kuan-Hao Chen", "Wei-Chen Hsiao"], "title": "DRL-Based Beam Positioning for LEO Satellite Constellations with Weighted Least Squares", "comment": "6 pages, 2 figures, 1 table, and submitted to IEEE ICC 2026", "summary": "In this paper, we propose a reinforcement learning based beam weighting framework that couples a policy network with an augmented weighted least squares (WLS) estimator for accurate and low-complexity positioning in multi-beam LEO constellations. Unlike conventional geometry or CSI-dependent approaches, the policy learns directly from uplink pilot responses and geometry features, enabling robust localization without explicit CSI estimation. An augmented WLS jointly estimates position and receiver clock bias, improving numerical stability under dynamic beam geometry. Across representative scenarios, the proposed method reduces the mean positioning error by 99.3% compared with the geometry-based baseline, achieving 0.395 m RMSE with near real-time inference.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u6ce2\u675f\u6743\u91cd\u6846\u67b6\uff0c\u7ed3\u5408\u7b56\u7565\u7f51\u7edc\u548c\u589e\u5f3a\u52a0\u6743\u6700\u5c0f\u4e8c\u4e58\u4f30\u8ba1\u5668\uff0c\u7528\u4e8e\u591a\u6ce2\u675fLEO\u661f\u5ea7\u4e2d\u7684\u7cbe\u786e\u4f4e\u590d\u6742\u5ea6\u5b9a\u4f4d", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u51e0\u4f55\u6216CSI\u7684\u65b9\u6cd5\u9700\u8981\u663e\u5f0fCSI\u4f30\u8ba1\uff0c\u4e14\u5728\u591a\u6ce2\u675fLEO\u661f\u5ea7\u4e2d\u9762\u4e34\u6570\u503c\u7a33\u5b9a\u6027\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u548c\u9ad8\u6548\u7684\u5b9a\u4f4d\u65b9\u6cd5", "method": "\u4f7f\u7528\u5f3a\u5316\u5b66\u4e60\u7b56\u7565\u7f51\u7edc\u76f4\u63a5\u4ece\u4e0a\u884c\u94fe\u8def\u5bfc\u9891\u54cd\u5e94\u548c\u51e0\u4f55\u7279\u5f81\u5b66\u4e60\uff0c\u7ed3\u5408\u589e\u5f3aWLS\u8054\u5408\u4f30\u8ba1\u4f4d\u7f6e\u548c\u63a5\u6536\u673a\u65f6\u949f\u504f\u5dee", "result": "\u76f8\u6bd4\u51e0\u4f55\u57fa\u7ebf\u65b9\u6cd5\uff0c\u5e73\u5747\u5b9a\u4f4d\u8bef\u5dee\u51cf\u5c1199.3%\uff0c\u8fbe\u52300.395\u7c73RMSE\uff0c\u4e14\u5177\u6709\u8fd1\u5b9e\u65f6\u63a8\u7406\u80fd\u529b", "conclusion": "\u8be5\u65b9\u6cd5\u65e0\u9700\u663e\u5f0fCSI\u4f30\u8ba1\uff0c\u5728\u52a8\u6001\u6ce2\u675f\u51e0\u4f55\u4e0b\u5177\u6709\u66f4\u597d\u7684\u6570\u503c\u7a33\u5b9a\u6027\uff0c\u5b9e\u73b0\u4e86\u9ad8\u7cbe\u5ea6\u4f4e\u590d\u6742\u5ea6\u7684\u5b9a\u4f4d\u6027\u80fd"}}
{"id": "2511.08723", "categories": ["eess.AS", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.08723", "abs": "https://arxiv.org/abs/2511.08723", "authors": ["Shu-wen Yang", "Ming Tu", "Andy T. Liu", "Xinghua Qu", "Hung-yi Lee", "Lu Lu", "Yuxuan Wang", "Yonghui Wu"], "title": "ParaS2S: Benchmarking and Aligning Spoken Language Models for Paralinguistic-aware Speech-to-Speech Interaction", "comment": null, "summary": "Speech-to-Speech (S2S) models have shown promising dialogue capabilities, but their ability to handle paralinguistic cues--such as emotion, tone, and speaker attributes--and to respond appropriately in both content and style remains underexplored. Progress is further hindered by the scarcity of high-quality and expressive demonstrations. To address this, we introduce a novel reinforcement learning (RL) framework for paralinguistic-aware S2S, ParaS2S, which evaluates and optimizes both content and speaking style directly at the waveform level. We first construct ParaS2SBench, a benchmark comprehensively evaluates S2S models' output for content and style appropriateness from diverse and challenging input queries. It scores the fitness of input-output pairs and aligns well with human judgments, serving as an automatic judge for model outputs. With this scalable scoring feedback, we enable the model to explore and learn from diverse unlabeled speech via Group Relative Policy Optimization (GRPO). Experiments show that existing S2S models fail to respond appropriately to paralinguistic attributes, performing no better than pipeline-based baselines. Our RL approach achieves a 11% relative improvement in response content and style's appropriateness on ParaS2SBench over supervised fine-tuning (SFT), surpassing all prior models while requiring substantially fewer warm-up annotations than pure SFT.", "AI": {"tldr": "\u63d0\u51fa\u4e86ParaS2S\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5316\u5b66\u4e60\u5728\u6ce2\u5f62\u7ea7\u522b\u4f18\u5316\u8bed\u97f3\u5230\u8bed\u97f3\u6a21\u578b\u7684\u526f\u8bed\u8a00\u80fd\u529b\uff0c\u5305\u62ec\u60c5\u611f\u3001\u8bed\u8c03\u548c\u8bf4\u8bdd\u4eba\u5c5e\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5185\u5bb9\u548c\u8bf4\u8bdd\u98ce\u683c\u7684\u9002\u5f53\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u8bed\u97f3\u5230\u8bed\u97f3\u6a21\u578b\u5728\u5904\u7406\u526f\u8bed\u8a00\u7ebf\u7d22\uff08\u5982\u60c5\u611f\u3001\u8bed\u8c03\u548c\u8bf4\u8bdd\u4eba\u5c5e\u6027\uff09\u65b9\u9762\u80fd\u529b\u4e0d\u8db3\uff0c\u4e14\u7f3a\u4e4f\u9ad8\u8d28\u91cf\u7684\u8868\u8fbe\u6027\u6f14\u793a\u6570\u636e\u3002", "method": "\u6784\u5efaParaS2SBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u4f7f\u7528Group Relative Policy Optimization\uff08GRPO\uff09\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5728\u6ce2\u5f62\u7ea7\u522b\u8bc4\u4f30\u548c\u4f18\u5316\u5185\u5bb9\u548c\u8bf4\u8bdd\u98ce\u683c\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u73b0\u6709S2S\u6a21\u578b\u5728\u526f\u8bed\u8a00\u5c5e\u6027\u54cd\u5e94\u65b9\u9762\u8868\u73b0\u4e0d\u4f73\uff0c\u800cRL\u65b9\u6cd5\u5728ParaS2SBench\u4e0a\u6bd4\u76d1\u7763\u5fae\u8c03\u63d0\u5347\u4e8611%\u7684\u76f8\u5bf9\u6539\u8fdb\uff0c\u8d85\u8d8a\u4e86\u6240\u6709\u5148\u524d\u6a21\u578b\u3002", "conclusion": "ParaS2S\u6846\u67b6\u6709\u6548\u63d0\u5347\u4e86\u8bed\u97f3\u5230\u8bed\u97f3\u6a21\u578b\u7684\u526f\u8bed\u8a00\u5904\u7406\u80fd\u529b\uff0c\u4e14\u6bd4\u7eaf\u76d1\u7763\u5fae\u8c03\u9700\u8981\u66f4\u5c11\u7684\u6807\u6ce8\u6570\u636e\u3002"}}
{"id": "2511.08755", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2511.08755", "abs": "https://arxiv.org/abs/2511.08755", "authors": ["Alexandra C Salem", "Mohammad Shokri", "Johanna Devaney"], "title": "Chord-conditioned Melody and Bass Generation", "comment": "To appear at NeurIPS 2025 Workshop on AI for Music (AI4Music)", "summary": "We evaluate five Transformer-based strategies for chord-conditioned melody and bass generation using a set of music theory-motivated metrics capturing pitch content, pitch interval size, and chord tone usage. The evaluated models include (1) no chord conditioning, (2) independent line chord-conditioned generation, (3) bass-first chord-conditioned generation, (4) melody-first chord-conditioned generation, and (5) chord-conditioned co-generation. We show that chord-conditioning improves the replication of stylistic pitch content and chord tone usage characteristics, particularly for the bass-first model.", "AI": {"tldr": "\u8bc4\u4f30\u4e86\u4e94\u79cd\u57fa\u4e8eTransformer\u7684\u548c\u5f26\u6761\u4ef6\u5316\u65cb\u5f8b\u4e0e\u8d1d\u65af\u751f\u6210\u7b56\u7565\uff0c\u4f7f\u7528\u97f3\u4e50\u7406\u8bba\u9a71\u52a8\u7684\u6307\u6807\u6765\u8861\u91cf\u97f3\u9ad8\u5185\u5bb9\u3001\u97f3\u7a0b\u5927\u5c0f\u548c\u548c\u5f26\u97f3\u4f7f\u7528\u3002", "motivation": "\u7814\u7a76\u4e0d\u540c\u548c\u5f26\u6761\u4ef6\u5316\u7b56\u7565\u5bf9\u65cb\u5f8b\u548c\u8d1d\u65af\u751f\u6210\u8d28\u91cf\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5982\u4f55\u66f4\u597d\u5730\u590d\u5236\u97f3\u4e50\u98ce\u683c\u7279\u5f81\u3002", "method": "\u6bd4\u8f83\u4e86\u4e94\u79cd\u6a21\u578b\uff1a(1)\u65e0\u548c\u5f26\u6761\u4ef6\u5316\u3001(2)\u72ec\u7acb\u7ebf\u548c\u5f26\u6761\u4ef6\u5316\u751f\u6210\u3001(3)\u8d1d\u65af\u4f18\u5148\u548c\u5f26\u6761\u4ef6\u5316\u751f\u6210\u3001(4)\u65cb\u5f8b\u4f18\u5148\u548c\u5f26\u6761\u4ef6\u5316\u751f\u6210\u3001(5)\u548c\u5f26\u6761\u4ef6\u5316\u534f\u540c\u751f\u6210\u3002", "result": "\u548c\u5f26\u6761\u4ef6\u5316\u6539\u5584\u4e86\u98ce\u683c\u5316\u97f3\u9ad8\u5185\u5bb9\u548c\u548c\u5f26\u97f3\u4f7f\u7528\u7279\u5f81\u7684\u590d\u5236\uff0c\u7279\u522b\u662f\u8d1d\u65af\u4f18\u5148\u6a21\u578b\u8868\u73b0\u6700\u4f73\u3002", "conclusion": "\u548c\u5f26\u6761\u4ef6\u5316\u5bf9\u97f3\u4e50\u751f\u6210\u8d28\u91cf\u6709\u79ef\u6781\u5f71\u54cd\uff0c\u8d1d\u65af\u4f18\u5148\u7684\u751f\u6210\u7b56\u7565\u5728\u590d\u5236\u97f3\u4e50\u98ce\u683c\u7279\u5f81\u65b9\u9762\u6548\u679c\u6700\u597d\u3002"}}
{"id": "2511.08910", "categories": ["eess.SP", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.08910", "abs": "https://arxiv.org/abs/2511.08910", "authors": ["Jiuqi Yan", "Chendong Xu", "Dongyu Liu"], "title": "OG-PCL: Efficient Sparse Point Cloud Processing for Human Activity Recognition", "comment": null, "summary": "Human activity recognition (HAR) with millimeter-wave (mmWave) radar offers a privacy-preserving and robust alternative to camera- and wearable-based approaches. In this work, we propose the Occupancy-Gated Parallel-CNN Bi-LSTM (OG-PCL) network to process sparse 3D radar point clouds produced by mmWave sensing. Designed for lightweight deployment, the parameter size of the proposed OG-PCL is only 0.83M and achieves 91.75 accuracy on the RadHAR dataset, outperforming those existing baselines such as 2D CNN, PointNet, and 3D CNN methods. We validate the advantages of the tri-view parallel structure in preserving spatial information across three dimensions while maintaining efficiency through ablation studies. We further introduce the Occupancy-Gated Convolution (OGConv) block and demonstrate the necessity of its occupancy compensation mechanism for handling sparse point clouds. The proposed OG-PCL thus offers a compact yet accurate framework for real-time radar-based HAR on lightweight platforms.", "AI": {"tldr": "\u63d0\u51faOG-PCL\u7f51\u7edc\u5904\u7406\u6beb\u7c73\u6ce2\u96f7\u8fbe\u7a00\u758f3D\u70b9\u4e91\uff0c\u53c2\u6570\u4ec50.83M\uff0c\u5728RadHAR\u6570\u636e\u96c6\u4e0a\u8fbe\u523091.75%\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "\u6beb\u7c73\u6ce2\u96f7\u8fbeHAR\u63d0\u4f9b\u9690\u79c1\u4fdd\u62a4\u548c\u9c81\u68d2\u6027\uff0c\u662f\u76f8\u673a\u548c\u53ef\u7a7f\u6234\u8bbe\u5907\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u4f7f\u7528Occupancy-Gated Parallel-CNN Bi-LSTM\u7f51\u7edc\u5904\u7406\u7a00\u758f3D\u96f7\u8fbe\u70b9\u4e91\uff0c\u5305\u542b\u4e09\u89c6\u56fe\u5e76\u884c\u7ed3\u6784\u548cOGConv\u5757\u3002", "result": "\u5728RadHAR\u6570\u636e\u96c6\u4e0a\u8fbe\u523091.75%\u51c6\u786e\u7387\uff0c\u53c2\u6570\u5927\u5c0f\u4ec50.83M\uff0c\u4f18\u4e8e2D CNN\u3001PointNet\u548c3D CNN\u7b49\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "OG-PCL\u4e3a\u8f7b\u91cf\u7ea7\u5e73\u53f0\u4e0a\u7684\u5b9e\u65f6\u96f7\u8fbeHAR\u63d0\u4f9b\u4e86\u7d27\u51d1\u800c\u51c6\u786e\u7684\u6846\u67b6\u3002"}}
{"id": "2511.09084", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2511.09084", "abs": "https://arxiv.org/abs/2511.09084", "authors": ["Tianzi Wang", "Xurong Xie", "Zengrui Jin", "Mengzhe Geng", "Jiajun Deng", "Zhaoqing Li", "Shoukang Hu", "Shujie Hu", "Guinan Li", "Mingyu Cui", "Helen Meng", "Xunying Liu"], "title": "Towards Effective and Efficient Non-autoregressive decoders for Conformer and LLM-based ASR using Block-based Attention Mask", "comment": "Accepted by regular paper in the IEEE Transactions on Audio, Speech and Language Processing (TASLP)", "summary": "Automatic speech recognition (ASR) systems often rely on autoregressive (AR) Transformer decoder architectures, which limit efficient inference parallelization due to their sequential nature. To this end, non-autoregressive (NAR) approaches aim primarily to achieve significant decoding speedup while the maintaining recognition accuracy that is comparable to AR baselines. This paper proposes a novel NAR block-based attention mask decoder (AMD) that effectively improves decoding efficiency while maintaining ASR accuracy, and also offering flexibility in balancing the performance-efficiency trade-off on both Conformer and large language model (LLM)-based ASR systems. The proposed AMD performs parallel inference within contiguous blocks of output labels while maintaining monotonic left-to-right prediction between blocks. A one-pass beam search algorithm is designed to dynamically fuse Connectionist Temporal Classification (CTC), AR decoder, and AMD probabilities. Experiments are conducted on normal speech LS960 and DBank elderly speech across: a) The Conformer encoder-decoder ASR system with filterbank input features; b) its integration with WavLM features; and c) further advancement by integrating an LLM-based decoder. On the LS960 task, the proposed AMD empowered tripartite decoder achieves decoding speedup ratios of up to 1.44x, 1.55x, and 2.31x under the three model configurations over the CTC + AR baselines, without statistically significant WER increases. When operating with real-time factors (RTFs) comparable to the baselines, the tripartite decoder produces statistically significant WER reductions of 0.19%, 0.62% and 0.13% absolute (4.3%, 16.3%, and 3.8% relative). Similar improvements are also obtained on the DBank task.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u975e\u81ea\u56de\u5f52\u5757\u6ce8\u610f\u529b\u63a9\u7801\u89e3\u7801\u5668(AMD)\uff0c\u5728\u4fdd\u6301ASR\u7cbe\u5ea6\u7684\u540c\u65f6\u63d0\u9ad8\u89e3\u7801\u6548\u7387\uff0c\u5e76\u5728Conformer\u548cLLM-based ASR\u7cfb\u7edf\u4e2d\u63d0\u4f9b\u6027\u80fd-\u6548\u7387\u6743\u8861\u7684\u7075\u6d3b\u6027\u3002", "motivation": "\u81ea\u56de\u5f52Transformer\u89e3\u7801\u5668\u67b6\u6784\u7531\u4e8e\u987a\u5e8f\u6027\u8d28\u9650\u5236\u4e86\u63a8\u7406\u5e76\u884c\u5316\u6548\u7387\uff0c\u975e\u81ea\u56de\u5f52\u65b9\u6cd5\u65e8\u5728\u5b9e\u73b0\u663e\u8457\u89e3\u7801\u52a0\u901f\u540c\u65f6\u4fdd\u6301\u4e0e\u81ea\u56de\u5f52\u57fa\u7ebf\u76f8\u5f53\u7684\u8bc6\u522b\u7cbe\u5ea6\u3002", "method": "AMD\u5728\u8f93\u51fa\u6807\u7b7e\u7684\u8fde\u7eed\u5757\u5185\u6267\u884c\u5e76\u884c\u63a8\u7406\uff0c\u540c\u65f6\u5728\u5757\u4e4b\u95f4\u4fdd\u6301\u5355\u8c03\u4ece\u5de6\u5230\u53f3\u9884\u6d4b\u3002\u8bbe\u8ba1\u4e86\u4e00\u6b21\u6027\u675f\u641c\u7d22\u7b97\u6cd5\u52a8\u6001\u878d\u5408CTC\u3001AR\u89e3\u7801\u5668\u548cAMD\u6982\u7387\u3002", "result": "\u5728LS960\u4efb\u52a1\u4e2d\uff0cAMD\u589e\u5f3a\u7684\u4e09\u65b9\u89e3\u7801\u5668\u5728\u4e09\u79cd\u6a21\u578b\u914d\u7f6e\u4e0b\u76f8\u6bd4CTC+AR\u57fa\u7ebf\u5b9e\u73b0\u4e861.44x\u30011.55x\u548c2.31x\u7684\u89e3\u7801\u52a0\u901f\u6bd4\uff0c\u65e0\u7edf\u8ba1\u663e\u8457\u7684WER\u589e\u52a0\u3002\u5728\u76f8\u540cRTF\u4e0b\uff0cWER\u5206\u522b\u7edd\u5bf9\u964d\u4f4e0.19%\u30010.62%\u548c0.13%\u3002", "conclusion": "AMD\u65b9\u6cd5\u5728Conformer\u548cLLM-based ASR\u7cfb\u7edf\u4e2d\u6709\u6548\u5e73\u8861\u4e86\u6027\u80fd\u4e0e\u6548\u7387\uff0c\u5728\u4fdd\u6301\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u89e3\u7801\u901f\u5ea6\uff0c\u5728DBank\u4efb\u52a1\u4e2d\u4e5f\u83b7\u5f97\u4e86\u7c7b\u4f3c\u6539\u8fdb\u3002"}}
{"id": "2511.09029", "categories": ["cs.SD", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2511.09029", "abs": "https://arxiv.org/abs/2511.09029", "authors": ["Leonie B\u00f6hlke", "Tim Ziemer", "Rolf Bader"], "title": "Non-verbal Perception of Room Acoustics using Multi Dimensional Scaling Metho", "comment": null, "summary": "Subjective room acoustics impressions play an important role for the performance and reception of music in concert venues and auralizations. Therefore, room acoustics since the 20th century dealt with the relationship between objective, acoustic parameters and subjective impressions of room acoustics. One common approach is to correlate acoustic measures with experts' subjective ratings of rooms as recalled from their long-term memory, and explain them using acoustical measures. Another approach is to let listeners rate auralized room acoustics on bipolar scales and find objective correlates. In this study, we present an alternative approach to characterizing the subjective impressions of room acoustics. We concolve music with binaural room impulse response measurements and utilize Multi Dimensional Scaling (MDS) to identify the perceptual dimensions of room acoustics. Results show that the perception of room acoustics has $5$ dimensions that can be explained by the (psycho-)acoustical measures echo density, fractal correlation dimension, roughness, loudness, and early decay time.", "AI": {"tldr": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u901a\u8fc7\u591a\u7ef4\u7f29\u653e(MDS)\u5206\u6790\u623f\u95f4\u58f0\u5b66\u611f\u77e5\u7ef4\u5ea6\u7684\u65b0\u65b9\u6cd5\uff0c\u8bc6\u522b\u51fa5\u4e2a\u4e3b\u8981\u611f\u77e5\u7ef4\u5ea6\uff0c\u5e76\u627e\u5230\u4e86\u5bf9\u5e94\u7684\u5fc3\u7406\u58f0\u5b66\u6d4b\u91cf\u6307\u6807\u3002", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u4e13\u5bb6\u4e3b\u89c2\u8bb0\u5fc6\u8bc4\u5206\u6216\u53cc\u6781\u91cf\u8868\u8bc4\u7ea7\u6765\u5173\u8054\u5ba2\u89c2\u58f0\u5b66\u53c2\u6570\u4e0e\u4e3b\u89c2\u5370\u8c61\uff0c\u672c\u7814\u7a76\u65e8\u5728\u63d0\u4f9b\u4e00\u79cd\u66ff\u4ee3\u65b9\u6cd5\u6765\u66f4\u51c6\u786e\u5730\u8868\u5f81\u623f\u95f4\u58f0\u5b66\u7684\u4e3b\u89c2\u611f\u77e5\u3002", "method": "\u5c06\u97f3\u4e50\u4e0e\u53cc\u8033\u623f\u95f4\u8109\u51b2\u54cd\u5e94\u6d4b\u91cf\u8fdb\u884c\u5377\u79ef\u5904\u7406\uff0c\u7136\u540e\u4f7f\u7528\u591a\u7ef4\u7f29\u653e(MDS)\u6280\u672f\u6765\u5206\u6790\u623f\u95f4\u58f0\u5b66\u7684\u611f\u77e5\u7ef4\u5ea6\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u623f\u95f4\u58f0\u5b66\u611f\u77e5\u5177\u67095\u4e2a\u7ef4\u5ea6\uff0c\u5206\u522b\u53ef\u7531\u56de\u58f0\u5bc6\u5ea6\u3001\u5206\u5f62\u76f8\u5173\u7ef4\u5ea6\u3001\u7c97\u7cd9\u5ea6\u3001\u54cd\u5ea6\u548c\u65e9\u671f\u8870\u51cf\u65f6\u95f4\u8fd9\u4e9b\u5fc3\u7406\u58f0\u5b66\u6d4b\u91cf\u6307\u6807\u6765\u89e3\u91ca\u3002", "conclusion": "\u591a\u7ef4\u7f29\u653e\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u8bc6\u522b\u623f\u95f4\u58f0\u5b66\u7684\u611f\u77e5\u7ef4\u5ea6\uff0c\u5e76\u4e3a\u7406\u89e3\u4e3b\u89c2\u58f0\u5b66\u5370\u8c61\u4e0e\u5ba2\u89c2\u58f0\u5b66\u53c2\u6570\u4e4b\u95f4\u7684\u5173\u7cfb\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\u3002"}}
{"id": "2511.09007", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09007", "abs": "https://arxiv.org/abs/2511.09007", "authors": ["Anshu Arora", "Kaluguri Yashaswini", "Satish Mulleti"], "title": "Linear-Bias Time Encoding for Low-Rate Quantized Representation of Bandlimited Signals", "comment": "5 pages", "summary": "Integrate-and-fire time encoding machines (IF-TEMs) provide an efficient framework for asynchronous sampling of bandlimited signals through discrete firing times. However, conventional IF-TEMs often exhibit excessive oversampling, leading to inefficient encoding for signals with smoothly distributed information. This letter introduces a linear-bias IF-TEM (LB-IF-TEM), where the bias dynamically tracks the input signal to maintain a nearly constant integrator input, thereby localizing the firing intervals. The resulting concentrated distribution enables effective non-uniform quantization with reduced distortion. Theoretical analysis establishes explicit bounds on the achievable oversampling range, while experimental results demonstrate that the proposed method attains comparable reconstruction accuracy at significantly lower bitrate than existing IF-TEM variants. The LB-IF-TEM thus provides a low-power, communication-efficient, and analytically tractable framework for time-based signal encoding and reconstruction.", "AI": {"tldr": "\u63d0\u51fa\u7ebf\u6027\u504f\u7f6eIF-TEM\uff08LB-IF-TEM\uff09\uff0c\u901a\u8fc7\u52a8\u6001\u8ddf\u8e2a\u8f93\u5165\u4fe1\u53f7\u6765\u51cf\u5c11\u8fc7\u91c7\u6837\uff0c\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u57fa\u4e8e\u65f6\u95f4\u7684\u4fe1\u53f7\u7f16\u7801\u3002", "motivation": "\u4f20\u7edfIF-TEM\u5b58\u5728\u8fc7\u5ea6\u8fc7\u91c7\u6837\u95ee\u9898\uff0c\u5bfc\u81f4\u5bf9\u4fe1\u606f\u5206\u5e03\u5e73\u6ed1\u7684\u4fe1\u53f7\u7f16\u7801\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u5f15\u5165\u7ebf\u6027\u504f\u7f6eIF-TEM\uff0c\u4f7f\u504f\u7f6e\u52a8\u6001\u8ddf\u8e2a\u8f93\u5165\u4fe1\u53f7\uff0c\u4fdd\u6301\u79ef\u5206\u5668\u8f93\u5165\u8fd1\u4f3c\u6052\u5b9a\uff0c\u4ece\u800c\u96c6\u4e2d\u89e6\u53d1\u95f4\u9694\u3002", "result": "\u7406\u8bba\u5206\u6790\u5efa\u7acb\u4e86\u53ef\u5b9e\u73b0\u7684\u8fc7\u91c7\u6837\u8303\u56f4\u754c\u9650\uff0c\u5b9e\u9a8c\u8868\u660e\u5728\u663e\u8457\u964d\u4f4e\u6bd4\u7279\u7387\u7684\u540c\u65f6\u83b7\u5f97\u53ef\u6bd4\u8f83\u7684\u91cd\u5efa\u7cbe\u5ea6\u3002", "conclusion": "LB-IF-TEM\u63d0\u4f9b\u4e86\u4e00\u4e2a\u4f4e\u529f\u8017\u3001\u901a\u4fe1\u9ad8\u6548\u4e14\u5206\u6790\u53ef\u5904\u7406\u7684\u57fa\u4e8e\u65f6\u95f4\u7684\u4fe1\u53f7\u7f16\u7801\u548c\u91cd\u5efa\u6846\u67b6\u3002"}}
{"id": "2511.09090", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.09090", "abs": "https://arxiv.org/abs/2511.09090", "authors": ["Shulei Ji", "Zihao Wang", "Jiaxing Yu", "Xiangyuan Yang", "Shuyu Li", "Songruoyao Wu", "Kejun Zhang"], "title": "Diff-V2M: A Hierarchical Conditional Diffusion Model with Explicit Rhythmic Modeling for Video-to-Music Generation", "comment": "AAAI 2026", "summary": "Video-to-music (V2M) generation aims to create music that aligns with visual content. However, two main challenges persist in existing methods: (1) the lack of explicit rhythm modeling hinders audiovisual temporal alignments; (2) effectively integrating various visual features to condition music generation remains non-trivial. To address these issues, we propose Diff-V2M, a general V2M framework based on a hierarchical conditional diffusion model, comprising two core components: visual feature extraction and conditional music generation. For rhythm modeling, we begin by evaluating several rhythmic representations, including low-resolution mel-spectrograms, tempograms, and onset detection functions (ODF), and devise a rhythmic predictor to infer them directly from videos. To ensure contextual and affective coherence, we also extract semantic and emotional features. All features are incorporated into the generator via a hierarchical cross-attention mechanism, where emotional features shape the affective tone via the first layer, while semantic and rhythmic features are fused in the second cross-attention layer. To enhance feature integration, we introduce timestep-aware fusion strategies, including feature-wise linear modulation (FiLM) and weighted fusion, allowing the model to adaptively balance semantic and rhythmic cues throughout the diffusion process. Extensive experiments identify low-resolution ODF as a more effective signal for modeling musical rhythm and demonstrate that Diff-V2M outperforms existing models on both in-domain and out-of-domain datasets, achieving state-of-the-art performance in terms of objective metrics and subjective comparisons. Demo and code are available at https://Tayjsl97.github.io/Diff-V2M-Demo/.", "AI": {"tldr": "Diff-V2M\u662f\u4e00\u4e2a\u57fa\u4e8e\u5206\u5c42\u6761\u4ef6\u6269\u6563\u6a21\u578b\u7684\u89c6\u9891\u5230\u97f3\u4e50\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u89c6\u89c9\u7279\u5f81\u63d0\u53d6\u548c\u6761\u4ef6\u97f3\u4e50\u751f\u6210\u89e3\u51b3\u8282\u594f\u5efa\u6a21\u548c\u7279\u5f81\u878d\u5408\u95ee\u9898\uff0c\u5728\u5ba2\u89c2\u6307\u6807\u548c\u4e3b\u89c2\u6bd4\u8f83\u4e2d\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u89c6\u9891\u5230\u97f3\u4e50\u751f\u6210\u65b9\u6cd5\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a(1)\u7f3a\u4e4f\u660e\u786e\u7684\u8282\u594f\u5efa\u6a21\u963b\u788d\u4e86\u89c6\u542c\u65f6\u95f4\u5bf9\u9f50\uff1b(2)\u6709\u6548\u6574\u5408\u5404\u79cd\u89c6\u89c9\u7279\u5f81\u6765\u6761\u4ef6\u5316\u97f3\u4e50\u751f\u6210\u4ecd\u7136\u56f0\u96be\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u6761\u4ef6\u6269\u6563\u6a21\u578b\u6846\u67b6\uff0c\u5305\u542b\u89c6\u89c9\u7279\u5f81\u63d0\u53d6\u548c\u6761\u4ef6\u97f3\u4e50\u751f\u6210\u3002\u4f7f\u7528\u8282\u594f\u9884\u6d4b\u5668\u4ece\u89c6\u9891\u63a8\u65ad\u8282\u594f\u8868\u793a\uff0c\u63d0\u53d6\u8bed\u4e49\u548c\u60c5\u611f\u7279\u5f81\uff0c\u901a\u8fc7\u5206\u5c42\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u548c\u65f6\u5e8f\u611f\u77e5\u878d\u5408\u7b56\u7565\u6574\u5408\u7279\u5f81\u3002", "result": "\u5e7f\u6cdb\u5b9e\u9a8c\u8868\u660e\u4f4e\u5206\u8fa8\u7387\u8d77\u59cb\u68c0\u6d4b\u51fd\u6570(ODF)\u662f\u5efa\u6a21\u97f3\u4e50\u8282\u594f\u7684\u66f4\u6709\u6548\u4fe1\u53f7\uff0cDiff-V2M\u5728\u9886\u57df\u5185\u548c\u9886\u57df\u5916\u6570\u636e\u96c6\u4e0a\u5747\u4f18\u4e8e\u73b0\u6709\u6a21\u578b\u3002", "conclusion": "Diff-V2M\u901a\u8fc7\u660e\u786e\u7684\u8282\u594f\u5efa\u6a21\u548c\u6709\u6548\u7684\u7279\u5f81\u878d\u5408\uff0c\u5728\u89c6\u9891\u5230\u97f3\u4e50\u751f\u6210\u4efb\u52a1\u4e2d\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002"}}
{"id": "2511.09037", "categories": ["cs.SD", "nlin.AO"], "pdf": "https://arxiv.org/pdf/2511.09037", "abs": "https://arxiv.org/abs/2511.09037", "authors": ["Rolf Bader", "Niko Plath", "Patrick Kontopidis"], "title": "Sound impact of simple viscoelastic damping changes due to aging and the role of the double bentside on soundboard tension in a 1755 Dulcken harpsichord", "comment": null, "summary": "The sound perception of wood aging is investigated on a Dulcken harpsichord of 1755 from the Museum of Applied Arts in Hamburg, Germany using a Finite-Difference Time Domain (FDTD) model of the harpsichords soundboard. The soundboard thickness was measured on the instrument at 497 positions during strings being deattached and used in the model. Impulse responses were taken on the instrument to estimate the present internal damping by calculating the T60 decay time and used as a model input. By varying the internal damping from this measured damping as a logarithmic decrement, impulse responses were simulated at 52 string positions on both, the 8' and 4' bridge. To estimate the changed sound brightness due to changed internal damping, spectral centroids were calculated from the simulated impulse responses. A dependency of brightness change due to aging on string position was found, where the lower strings have higher brightness, as expected, while the higher strings have decreased brightness. This counterintuitive finding is caused by the frequency-dependent filter effect of changed damping. Future studies need to incorporate viscoelasticity to differentiate this effect further. Furthermore, the attachment of the 8' string to the outer instead of the inner wall, a characteristic feature of Dulcken harpsichords, is investigated using a 3D Finite-Element Method (FEM) model simulation of the whole instrument. No considerable changes on the soundboard tension were found compared to an attachment of the 8' strings to the inner wall, pointing to another reason for this special construction.", "AI": {"tldr": "\u7814\u7a76\u4f7f\u7528FDTD\u6a21\u578b\u5206\u67901755\u5e74\u675c\u5c14\u80af\u5927\u952e\u7434\u6728\u6750\u8001\u5316\u7684\u58f0\u97f3\u611f\u77e5\uff0c\u53d1\u73b0\u4e0d\u540c\u97f3\u533a\u5f26\u7684\u4eae\u5ea6\u53d8\u5316\u5b58\u5728\u53cd\u76f4\u89c9\u73b0\u8c61\uff0c\u5e76\u901a\u8fc7FEM\u6a21\u578b\u7814\u7a76\u4e868'\u5f26\u7279\u6b8a\u56fa\u5b9a\u65b9\u5f0f\u7684\u5f71\u54cd\u3002", "motivation": "\u7814\u7a76\u6728\u6750\u8001\u5316\u5bf9\u5927\u952e\u7434\u58f0\u97f3\u7279\u6027\u7684\u5f71\u54cd\uff0c\u7279\u522b\u662f\u5185\u90e8\u963b\u5c3c\u53d8\u5316\u5bf9\u4e0d\u540c\u97f3\u533a\u5f26\u58f0\u97f3\u4eae\u5ea6\u7684\u4f5c\u7528\uff0c\u4ee5\u53ca\u675c\u5c14\u80af\u5927\u952e\u7434\u7279\u6709\u76848'\u5f26\u56fa\u5b9a\u65b9\u5f0f\u5bf9\u97f3\u677f\u5f20\u529b\u7684\u5f71\u54cd\u3002", "method": "\u4f7f\u7528\u6709\u9650\u5dee\u5206\u65f6\u57df(FDTD)\u6a21\u578b\u6a21\u62df\u97f3\u677f\uff0c\u5728497\u4e2a\u4f4d\u7f6e\u6d4b\u91cf\u97f3\u677f\u539a\u5ea6\uff0c\u901a\u8fc7\u8109\u51b2\u54cd\u5e94\u4f30\u8ba1\u5185\u90e8\u963b\u5c3c\uff0c\u8ba1\u7b97T60\u8870\u51cf\u65f6\u95f4\uff0c\u6a21\u62df52\u4e2a\u5f26\u4f4d\u7f6e\u7684\u8109\u51b2\u54cd\u5e94\uff0c\u5e76\u901a\u8fc7\u8c31\u8d28\u5fc3\u5206\u6790\u4eae\u5ea6\u53d8\u5316\u3002\u540c\u65f6\u4f7f\u75283D\u6709\u9650\u5143\u6cd5(FEM)\u6a21\u578b\u7814\u7a768'\u5f26\u56fa\u5b9a\u65b9\u5f0f\u3002", "result": "\u53d1\u73b0\u4f4e\u97f3\u5f26\u4eae\u5ea6\u589e\u52a0\uff08\u7b26\u5408\u9884\u671f\uff09\uff0c\u4f46\u9ad8\u97f3\u5f26\u4eae\u5ea6\u964d\u4f4e\u7684\u53cd\u76f4\u89c9\u73b0\u8c61\uff0c\u8fd9\u662f\u7531\u4e8e\u963b\u5c3c\u53d8\u5316\u7684\u9891\u7387\u4f9d\u8d56\u6027\u6ee4\u6ce2\u6548\u5e94\u30028'\u5f26\u56fa\u5b9a\u5728\u5916\u58c1\u800c\u975e\u5185\u58c1\u5bf9\u97f3\u677f\u5f20\u529b\u6ca1\u6709\u663e\u8457\u5f71\u54cd\u3002", "conclusion": "\u6728\u6750\u8001\u5316\u5f15\u8d77\u7684\u963b\u5c3c\u53d8\u5316\u5bf9\u4e0d\u540c\u97f3\u533a\u5f26\u7684\u4eae\u5ea6\u5f71\u54cd\u4e0d\u540c\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u7c98\u5f39\u6027\u6548\u5e94\u6765\u533a\u5206\u8fd9\u79cd\u5f71\u54cd\u3002\u675c\u5c14\u80af\u5927\u952e\u7434\u7684\u7279\u6b8a\u6784\u9020\u53ef\u80fd\u6709\u5176\u4ed6\u539f\u56e0\u3002"}}
{"id": "2511.09022", "categories": ["eess.SP", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.09022", "abs": "https://arxiv.org/abs/2511.09022", "authors": ["Weicheng Gao"], "title": "RadHARSimulator V2: Video to Doppler Generator", "comment": "19 pages, 16 figures, 8 tables", "summary": "Radar-based human activity recognition (HAR) still lacks a comprehensive simulation method. Existing software is developed based on models or motion-captured data, resulting in limited flexibility. To address this issue, a simulator that directly generates Doppler spectra from recorded video footage (RadHARSimulator V2) is presented in this paper. Both computer vision and radar modules are included in the simulator. In computer vision module, the real-time model for object detection with global nearest neighbor is first used to detect and track human targets in the video. Then, the high-resolution network is used to estimate two-dimensional poses of the detected human targets. Next, the three-dimensional poses of the detected human targets are obtained by nearest matching method. Finally, smooth temporal three-dimensional pose estimation is achieved through Kalman filtering. In radar module, pose interpolation and smoothing are first achieved through the Savitzky-Golay method. Second, the delay model and the mirror method are used to simulate echoes in both free-space and through-the-wall scenarios. Then, range-time map is generated using pulse compression, moving target indication, and DnCNN. Next, Doppler-time map (DTM) is generated using short-time Fourier transform and DnCNN again. Finally, the ridge features on the DTM are extracted using the maximum local energy method. In addition, a hybrid parallel-serial neural network architecture is proposed for radar-based HAR. Numerical experiments are conducted and analyzed to demonstrate the effectiveness of the designed simulator and the proposed network model. The open-source code of this work can be found in: https://github.com/JoeyBGOfficial/RadHARSimulatorV2-Video-to-Doppler-Generator.", "AI": {"tldr": "\u63d0\u51fa\u4e86RadHARSimulator V2\uff0c\u8fd9\u662f\u4e00\u4e2a\u76f4\u63a5\u4ece\u89c6\u9891\u751f\u6210\u591a\u666e\u52d2\u9891\u8c31\u7684\u96f7\u8fbe\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u6a21\u62df\u5668\uff0c\u5305\u542b\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u96f7\u8fbe\u6a21\u5757\uff0c\u5e76\u63d0\u51fa\u4e86\u6df7\u5408\u5e76\u884c-\u4e32\u884c\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u3002", "motivation": "\u73b0\u6709\u7684\u96f7\u8fbe\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u65b9\u6cd5\u57fa\u4e8e\u6a21\u578b\u6216\u8fd0\u52a8\u6355\u6349\u6570\u636e\uff0c\u7075\u6d3b\u6027\u6709\u9650\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u6a21\u62df\u65b9\u6cd5\u3002", "method": "\u8ba1\u7b97\u673a\u89c6\u89c9\u6a21\u5757\uff1a\u4f7f\u7528\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b\u548c\u8ddf\u8e2a\u30012D\u59ff\u6001\u4f30\u8ba1\u30013D\u59ff\u6001\u91cd\u5efa\u3001\u5361\u5c14\u66fc\u6ee4\u6ce2\uff1b\u96f7\u8fbe\u6a21\u5757\uff1a\u4f7f\u7528Savitzky-Golay\u5e73\u6ed1\u3001\u5ef6\u8fdf\u6a21\u578b\u548c\u955c\u50cf\u65b9\u6cd5\u6a21\u62df\u56de\u6ce2\u3001\u8109\u51b2\u538b\u7f29\u548cSTFT\u751f\u6210\u65f6\u9891\u56fe\u3001\u6700\u5927\u5c40\u90e8\u80fd\u91cf\u6cd5\u63d0\u53d6\u7279\u5f81\uff1b\u5e76\u63d0\u51fa\u6df7\u5408\u5e76\u884c-\u4e32\u884c\u795e\u7ecf\u7f51\u7edc\u3002", "result": "\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6a21\u62df\u5668\u548c\u7f51\u7edc\u6a21\u578b\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u6a21\u62df\u5668\u80fd\u591f\u76f4\u63a5\u4ece\u89c6\u9891\u751f\u6210\u591a\u666e\u52d2\u9891\u8c31\uff0c\u4e3a\u96f7\u8fbe\u4eba\u7c7b\u6d3b\u52a8\u8bc6\u522b\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09060", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.09060", "abs": "https://arxiv.org/abs/2511.09060", "authors": ["Itsuki Yazawa", "Akira Furui"], "title": "VAE-Based Synthetic EMG Generation with Mix-Consistency Loss for Recognizing Unseen Motion Combinations", "comment": "6 pages, 5 figures, accepted at IEEE SII 2026", "summary": "Electromyogram (EMG)-based motion classification using machine learning has been widely employed in applications such as prosthesis control. While previous studies have explored generating synthetic patterns of combined motions to reduce training data requirements, these methods assume that combined motions can be represented as linear combinations of basic motions. However, this assumption often fails due to complex neuromuscular phenomena such as muscle co-contraction, resulting in low-fidelity synthetic signals and degraded classification performance. To address this limitation, we propose a novel method that learns to synthesize combined motion patterns in a structured latent space. Specifically, we employ a variational autoencoder (VAE) to encode EMG signals into a low-dimensional representation and introduce a mixconsistency loss that structures the latent space such that combined motions are embedded between their constituent basic motions. Synthetic patterns are then generated within this structured latent space and used to train classifiers for recognizing unseen combined motions. We validated our approach through upper-limb motion classification experiments with eight healthy participants. The results demonstrate that our method outperforms input-space synthesis approaches, achieving approximately 30% improvement in accuracy.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5728\u7ed3\u6784\u5316\u6f5c\u5728\u7a7a\u95f4\u4e2d\u5408\u6210\u808c\u7535\u4fe1\u53f7\u7ec4\u5408\u8fd0\u52a8\u6a21\u5f0f\u7684\u65b0\u65b9\u6cd5\uff0c\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u548c\u6df7\u5408\u4e00\u81f4\u6027\u635f\u5931\uff0c\u663e\u8457\u63d0\u9ad8\u7ec4\u5408\u8fd0\u52a8\u5206\u7c7b\u51c6\u786e\u7387\u7ea630%\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5047\u8bbe\u7ec4\u5408\u8fd0\u52a8\u662f\u57fa\u672c\u8fd0\u52a8\u7684\u7ebf\u6027\u7ec4\u5408\uff0c\u4f46\u7531\u4e8e\u808c\u8089\u534f\u540c\u6536\u7f29\u7b49\u590d\u6742\u795e\u7ecf\u808c\u8089\u73b0\u8c61\uff0c\u8fd9\u79cd\u5047\u8bbe\u5f80\u5f80\u4e0d\u6210\u7acb\uff0c\u5bfc\u81f4\u5408\u6210\u4fe1\u53f7\u4fdd\u771f\u5ea6\u4f4e\u548c\u5206\u7c7b\u6027\u80fd\u4e0b\u964d\u3002", "method": "\u4f7f\u7528\u53d8\u5206\u81ea\u7f16\u7801\u5668\u5c06\u808c\u7535\u4fe1\u53f7\u7f16\u7801\u5230\u4f4e\u7ef4\u8868\u793a\u7a7a\u95f4\uff0c\u5f15\u5165\u6df7\u5408\u4e00\u81f4\u6027\u635f\u5931\u6765\u7ed3\u6784\u5316\u6f5c\u5728\u7a7a\u95f4\uff0c\u4f7f\u7ec4\u5408\u8fd0\u52a8\u5d4c\u5165\u5728\u6784\u6210\u57fa\u672c\u8fd0\u52a8\u4e4b\u95f4\uff0c\u7136\u540e\u5728\u8be5\u7ed3\u6784\u5316\u6f5c\u5728\u7a7a\u95f4\u4e2d\u751f\u6210\u5408\u6210\u6a21\u5f0f\u7528\u4e8e\u8bad\u7ec3\u5206\u7c7b\u5668\u3002", "result": "\u5728\u516b\u540d\u5065\u5eb7\u53c2\u4e0e\u8005\u7684\u4e0a\u80a2\u8fd0\u52a8\u5206\u7c7b\u5b9e\u9a8c\u4e2d\uff0c\u8be5\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u8f93\u5165\u7a7a\u95f4\u5408\u6210\u65b9\u6cd5\uff0c\u51c6\u786e\u7387\u63d0\u9ad8\u7ea630%\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u7ed3\u6784\u5316\u6f5c\u5728\u7a7a\u95f4\u5408\u6210\u65b9\u6cd5\u80fd\u6709\u6548\u89e3\u51b3\u7ec4\u5408\u8fd0\u52a8\u6a21\u5f0f\u5408\u6210\u95ee\u9898\uff0c\u4e3a\u808c\u7535\u4fe1\u53f7\u5206\u7c7b\u63d0\u4f9b\u4e86\u66f4\u51c6\u786e\u7684\u5408\u6210\u6570\u636e\u751f\u6210\u65b9\u6848\u3002"}}
{"id": "2511.09282", "categories": ["cs.SD", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.09282", "abs": "https://arxiv.org/abs/2511.09282", "authors": ["Jiliang Hu", "Zuchao Li", "Baoyuan Qi", "Liu Guoming", "Ping Wang"], "title": "End-to-end Contrastive Language-Speech Pretraining Model For Long-form Spoken Question Answering", "comment": "12 pages, 7 figures, accepted by AAAI 2026", "summary": "Significant progress has been made in spoken question answering (SQA) in recent years. However, many existing methods, including large audio language models, struggle with processing long audio. Follow the success of retrieval augmented generation, a speech-related retriever shows promising in help preprocessing long-form speech. But the performance of existing speech-related retrievers is lacking. To address this challenge, we propose CLSR, an end-to-end contrastive language-speech retriever that efficiently extracts question-relevant segments from long audio recordings for downstream SQA task. Unlike conventional speech-text contrastive models, CLSR incorporates an intermediate step that converts acoustic features into text-like representations prior to alignment, thereby more effectively bridging the gap between modalities. Experimental results across four cross-modal retrieval datasets demonstrate that CLSR surpasses both end-to-end speech related retrievers and pipeline approaches combining speech recognition with text retrieval, providing a robust foundation for advancing practical long-form SQA applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86CLSR\uff0c\u4e00\u79cd\u7aef\u5230\u7aef\u7684\u5bf9\u6bd4\u8bed\u8a00-\u8bed\u97f3\u68c0\u7d22\u5668\uff0c\u80fd\u591f\u4ece\u957f\u97f3\u9891\u4e2d\u9ad8\u6548\u63d0\u53d6\u4e0e\u95ee\u9898\u76f8\u5173\u7684\u7247\u6bb5\uff0c\u7528\u4e8e\u4e0b\u6e38\u53e3\u8bed\u95ee\u7b54\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u7684\u53e3\u8bed\u95ee\u7b54\u65b9\u6cd5\u5728\u5904\u7406\u957f\u97f3\u9891\u65f6\u8868\u73b0\u4e0d\u4f73\uff0c\u73b0\u6709\u7684\u8bed\u97f3\u76f8\u5173\u68c0\u7d22\u5668\u6027\u80fd\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u597d\u7684\u65b9\u6cd5\u6765\u9884\u5904\u7406\u957f\u683c\u5f0f\u8bed\u97f3\u3002", "method": "CLSR\u91c7\u7528\u7aef\u5230\u7aef\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u6a21\u6001\u5bf9\u9f50\u524d\u5f15\u5165\u4e2d\u95f4\u6b65\u9aa4\u5c06\u58f0\u5b66\u7279\u5f81\u8f6c\u6362\u4e3a\u7c7b\u4f3c\u6587\u672c\u7684\u8868\u793a\uff0c\u4ece\u800c\u66f4\u6709\u6548\u5730\u5f25\u5408\u6a21\u6001\u5dee\u8ddd\u3002", "result": "\u5728\u56db\u4e2a\u8de8\u6a21\u6001\u68c0\u7d22\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cCLSR\u8d85\u8d8a\u4e86\u7aef\u5230\u7aef\u8bed\u97f3\u76f8\u5173\u68c0\u7d22\u5668\u548c\u7ed3\u5408\u8bed\u97f3\u8bc6\u522b\u4e0e\u6587\u672c\u68c0\u7d22\u7684\u6d41\u6c34\u7ebf\u65b9\u6cd5\u3002", "conclusion": "CLSR\u4e3a\u63a8\u8fdb\u5b9e\u7528\u7684\u957f\u683c\u5f0f\u53e3\u8bed\u95ee\u7b54\u5e94\u7528\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u57fa\u7840\u3002"}}
{"id": "2511.09137", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09137", "abs": "https://arxiv.org/abs/2511.09137", "authors": ["Georgios Kokkinis", "Alexandros Iosifidis", "Qi Zhang"], "title": "xHAP: Cross-Modal Attention for Haptic Feedback Estimation in the Tactile Internet", "comment": "12 pages, 13 figures, 3 tables, 2 algorithms", "summary": "The Tactile Internet requires ultra-low latency and high-fidelity haptic feedback to enable immersive teleoperation. A key challenge is to ensure ultra-reliable and low-latency transmission of haptic packets under channel variations and potential network outages. To address these issues, one approach relies on local estimation of haptic feedback at the operator side. However, designing an accurate estimator that can faithfully reproduce the true haptic forces remains a significant challenge. In this paper, we propose a novel deep learning architecture, xHAP, based on cross-modal attention to estimate haptic feedback. xHAP fuses information from two distinct data streams: the teleoperator's historical force feedback and the operator's control action sequence. We employ modality-specific encoders to learn temporal representations, followed by a cross-attention layer where the teleoperator haptic data attend to the operator input. This fusion allows the model to selectively focus on the most relevant operator sensory data when predicting the teleoperator's haptic feedback. The proposed architecture reduces the mean-squared error by more than two orders of magnitude compared to existing methods and lowers the SNR requirement for reliable transmission by $10~\\mathrm{dB}$ at an error threshold of $0.1$ in a 3GPP UMa scenario. Additionally, it increases coverage by $138\\%$ and supports $59.6\\%$ more haptic users even under 10 dB lower SNR compared to the baseline.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u7684\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784xHAP\uff0c\u7528\u4e8e\u5728\u89e6\u89c9\u4e92\u8054\u7f51\u4e2d\u4f30\u8ba1\u89e6\u89c9\u53cd\u9988\uff0c\u663e\u8457\u63d0\u5347\u4f20\u8f93\u53ef\u9760\u6027\u548c\u8986\u76d6\u8303\u56f4", "motivation": "\u89e6\u89c9\u4e92\u8054\u7f51\u9700\u8981\u8d85\u4f4e\u5ef6\u8fdf\u548c\u9ad8\u4fdd\u771f\u89e6\u89c9\u53cd\u9988\uff0c\u4f46\u9762\u4e34\u4fe1\u9053\u53d8\u5316\u548c\u7f51\u7edc\u4e2d\u65ad\u4e0b\u89e6\u89c9\u6570\u636e\u5305\u8d85\u53ef\u9760\u4f4e\u5ef6\u8fdf\u4f20\u8f93\u7684\u6311\u6218", "method": "\u4f7f\u7528\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u67b6\u6784\uff0c\u878d\u5408\u64cd\u4f5c\u8005\u5386\u53f2\u529b\u53cd\u9988\u548c\u63a7\u5236\u52a8\u4f5c\u5e8f\u5217\u4e24\u4e2a\u6570\u636e\u6d41\uff0c\u901a\u8fc7\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\u548c\u4ea4\u53c9\u6ce8\u610f\u529b\u5c42\u8fdb\u884c\u9009\u62e9\u6027\u4fe1\u606f\u878d\u5408", "result": "\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\uff0c\u5747\u65b9\u8bef\u5dee\u964d\u4f4e\u4e24\u4e2a\u6570\u91cf\u7ea7\uff0c\u57283GPP UMa\u573a\u666f\u4e0b\u4fe1\u566a\u6bd4\u8981\u6c42\u964d\u4f4e10dB\uff0c\u8986\u76d6\u8303\u56f4\u63d0\u5347138%\uff0c\u652f\u6301\u7528\u6237\u6570\u589e\u52a059.6%", "conclusion": "xHAP\u67b6\u6784\u901a\u8fc7\u8de8\u6a21\u6001\u6ce8\u610f\u529b\u6709\u6548\u4f30\u8ba1\u89e6\u89c9\u53cd\u9988\uff0c\u663e\u8457\u63d0\u5347\u89e6\u89c9\u4e92\u8054\u7f51\u7684\u4f20\u8f93\u53ef\u9760\u6027\u548c\u6027\u80fd"}}
{"id": "2511.09140", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09140", "abs": "https://arxiv.org/abs/2511.09140", "authors": ["Xuyao Yu", "Zijun Gong", "Zhilu Lai"], "title": "LMMSE-Optimal Pilot Pattern Design Based on Covariance Matrix Approximation for OFDM Channel Estimation in Doubly Dispersive Channel", "comment": "This manuscript was submitted to IEEE International Conference on Communications (ICC) 2026", "summary": "This paper investigates the optimal pilot pattern design, in the linear minimum mean square error (LMMSE) estimator sense, for OFDM systems in doubly dispersive channels. To enable analytical tractability, the channel covariance matrix is decomposed into the Kronecker product of two Hermitian Toeplitz matrices corresponding to the delay and Doppler domains. By invoking the Szeg\u00f6 limit theorem, these matrices are shown to be approximately diagonalizable by discrete Fourier transform (DFT) matrices. Based on this structure, the LMMSE channel estimation error is reformulated into a compact analytical form, from which a closed-form lower bound is derived. Furthermore, we establish the condition under which this bound is achieved by a lattice-based pilot pattern. Numerical results verify that the proposed matrix approximation introduces negligible error and examples of the proposed lattice design are given.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u5728\u53cc\u5f25\u6563\u4fe1\u9053\u4e2dOFDM\u7cfb\u7edf\u7684\u6700\u4f18\u5bfc\u9891\u6a21\u5f0f\u8bbe\u8ba1\uff0c\u4eceLMMSE\u4f30\u8ba1\u5668\u89d2\u5ea6\u51fa\u53d1\u3002\u901a\u8fc7\u5c06\u4fe1\u9053\u534f\u65b9\u5dee\u77e9\u9635\u5206\u89e3\u4e3a\u5ef6\u8fdf\u57df\u548c\u591a\u666e\u52d2\u57df\u7684Kronecker\u79ef\uff0c\u5229\u7528Szeg\u00f6\u6781\u9650\u5b9a\u7406\u8fd1\u4f3c\u5bf9\u89d2\u5316\uff0c\u63a8\u5bfc\u51faLMMSE\u4fe1\u9053\u4f30\u8ba1\u8bef\u5dee\u7684\u7d27\u51d1\u89e3\u6790\u5f62\u5f0f\u548c\u95ed\u5f0f\u4e0b\u754c\uff0c\u5e76\u5efa\u7acb\u4e86\u683c\u5b50\u5bfc\u9891\u6a21\u5f0f\u8fbe\u5230\u8be5\u4e0b\u754c\u7684\u6761\u4ef6\u3002", "motivation": "\u5728\u53cc\u5f25\u6563\u4fe1\u9053\u4e2d\uff0cOFDM\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u6027\u80fd\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u51b3\u4e8e\u5bfc\u9891\u6a21\u5f0f\u7684\u8bbe\u8ba1\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u6700\u4f18\u5bfc\u9891\u6a21\u5f0f\u7684\u7cfb\u7edf\u5206\u6790\uff0c\u7279\u522b\u662f\u5728LMMSE\u4f30\u8ba1\u5668\u6846\u67b6\u4e0b\u3002", "method": "\u5c06\u4fe1\u9053\u534f\u65b9\u5dee\u77e9\u9635\u5206\u89e3\u4e3a\u5ef6\u8fdf\u57df\u548c\u591a\u666e\u52d2\u57df\u7684Kronecker\u79ef\uff0c\u5229\u7528Szeg\u00f6\u6781\u9650\u5b9a\u7406\u8fd1\u4f3c\u5bf9\u89d2\u5316\uff0c\u63a8\u5bfcLMMSE\u4fe1\u9053\u4f30\u8ba1\u8bef\u5dee\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\u548c\u95ed\u5f0f\u4e0b\u754c\uff0c\u5e76\u8bbe\u8ba1\u683c\u5b50\u5bfc\u9891\u6a21\u5f0f\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u51fa\u7684\u77e9\u9635\u8fd1\u4f3c\u5f15\u5165\u7684\u8bef\u5dee\u53ef\u5ffd\u7565\u4e0d\u8ba1\uff0c\u5e76\u7ed9\u51fa\u4e86\u6240\u63d0\u683c\u5b50\u8bbe\u8ba1\u7684\u5b9e\u4f8b\uff0c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u672c\u6587\u63d0\u4f9b\u4e86\u4e00\u79cd\u7cfb\u7edf\u7684\u65b9\u6cd5\u6765\u8bbe\u8ba1\u53cc\u5f25\u6563\u4fe1\u9053\u4e2dOFDM\u7cfb\u7edf\u7684\u6700\u4f18\u5bfc\u9891\u6a21\u5f0f\uff0c\u901a\u8fc7\u77e9\u9635\u5206\u89e3\u548c\u8fd1\u4f3c\u5bf9\u89d2\u5316\u6280\u672f\uff0c\u63a8\u5bfc\u51fa\u4e86LMMSE\u4f30\u8ba1\u8bef\u5dee\u7684\u4e0b\u754c\uff0c\u5e76\u8bc1\u660e\u4e86\u683c\u5b50\u5bfc\u9891\u6a21\u5f0f\u5728\u7279\u5b9a\u6761\u4ef6\u4e0b\u53ef\u4ee5\u8fbe\u5230\u8be5\u4e0b\u754c\u3002"}}
{"id": "2511.09150", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09150", "abs": "https://arxiv.org/abs/2511.09150", "authors": ["Yulin Fu", "Jiancun Fan", "Shiyu Zhai", "Zhibo Duan", "Jie Luo"], "title": "Mip-NeWRF: Enhanced Wireless Radiance Field with Hybrid Encoding for Channel Prediction", "comment": "13 pages, 12 figures", "summary": "Recent work on wireless radiance fields represents a promising deep learning approach for channel prediction, however, in complex environments these methods still exhibit limited robustness, slow convergence, and modest accuracy due to insufficiently refined modeling. To address this issue, we propose Mip-NeWRF, a physics-informed neural framework for accurate indoor channel prediction based on sparse channel measurements. The framework operates in a ray-based pipeline with coarse-to-fine importance sampling: frustum samples are encoded, processed by a shared multilayer perceptron (MLP), and the outputs are synthesized into the channel frequency response (CFR). Prior to MLP input, Mip-NeWRF performs conical-frustum sampling and applies a scale-consistent hybrid positional encoding to each frustum. The scale-consistent normalization aligns positional encodings across scene scales, while the hybrid encoding supplies both scale-robust, low-frequency stability to accelerate convergence and fine spatial detail to improve accuracy. During training, a curriculum learning schedule is applied to stabilize and accelerate convergence of the shared MLP. During channel synthesis, the MLP outputs, including predicted virtual transmitter presence probabilities and amplitudes, are combined with modeled pathloss and surface interaction attenuation to enhance physical fidelity and further improve accuracy. Simulation results demonstrate the effectiveness of the proposed approach: in typical scenarios, the normalized mean square error (NMSE) is reduced by 14.3 dB versus state-of-the-art baselines.", "AI": {"tldr": "Mip-NeWRF\u662f\u4e00\u4e2a\u57fa\u4e8e\u7269\u7406\u4fe1\u606f\u7684\u795e\u7ecf\u6846\u67b6\uff0c\u7528\u4e8e\u5ba4\u5185\u4fe1\u9053\u9884\u6d4b\uff0c\u901a\u8fc7\u5706\u9525\u622a\u5934\u4f53\u91c7\u6837\u3001\u5c3a\u5ea6\u4e00\u81f4\u6df7\u5408\u4f4d\u7f6e\u7f16\u7801\u548c\u8bfe\u7a0b\u5b66\u4e60\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fe1\u9053\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u65e0\u7ebf\u8f90\u5c04\u573a\u65b9\u6cd5\u5728\u590d\u6742\u73af\u5883\u4e2d\u5b58\u5728\u9c81\u68d2\u6027\u4e0d\u8db3\u3001\u6536\u655b\u6162\u548c\u7cbe\u5ea6\u6709\u9650\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u7cbe\u7ec6\u7684\u5efa\u6a21\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u5c04\u7ebf\u7684\u7ba1\u9053\uff0c\u5305\u542b\u7c97\u5230\u7ec6\u91cd\u8981\u6027\u91c7\u6837\u3001\u5706\u9525\u622a\u5934\u4f53\u91c7\u6837\u3001\u5c3a\u5ea6\u4e00\u81f4\u6df7\u5408\u4f4d\u7f6e\u7f16\u7801\u3001\u5171\u4eab\u591a\u5c42\u611f\u77e5\u673a\u5904\u7406\uff0c\u5e76\u7ed3\u5408\u8def\u5f84\u635f\u8017\u548c\u8868\u9762\u4ea4\u4e92\u8870\u51cf\u8fdb\u884c\u7269\u7406\u589e\u5f3a\u3002", "result": "\u5728\u5178\u578b\u573a\u666f\u4e2d\uff0c\u4e0e\u6700\u5148\u8fdb\u57fa\u7ebf\u76f8\u6bd4\uff0c\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\u964d\u4f4e\u4e8614.3 dB\u3002", "conclusion": "Mip-NeWRF\u901a\u8fc7\u6539\u8fdb\u7684\u4f4d\u7f6e\u7f16\u7801\u548c\u7269\u7406\u5efa\u6a21\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5ba4\u5185\u4fe1\u9053\u9884\u6d4b\u7684\u51c6\u786e\u6027\u548c\u6536\u655b\u6027\u80fd\u3002"}}
{"id": "2511.09163", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09163", "abs": "https://arxiv.org/abs/2511.09163", "authors": ["Xuyao Yu", "Zijun Gong", "Zhilu Lai"], "title": "Characterizing ISCI in Multi-carrier ISAC Systems over Doubly Dispersive Channel: Joint Sensing and Communication Performance Analysis", "comment": "This manuscript has been submitted to IEEE International Conference on Communications (ICC) 2026", "summary": "This paper presents a systematic analysis of inter-symbol and inter-carrier interference (ISCI) modeling in doubly dispersive channels for integrated sensing and communication (ISAC) systems. We propose a generalized OFDM (Weyl-Heisenberg) framework to evaluate four ISCI treatment approaches: (1) explicit estimation and compensation, (2) complete ignorance, (3) uncorrelated colored noise approximation, and (4) correlated colored noise modeling. Through continuous delay-Doppler channel characterization, we derive LMMSE channel estimators and corresponding estimation errors (as sensing metrics) for both pilot-assisted and fully-known symbol scenarios. The communication performance is quantified via ergodic capacity bounds under imperfect CSI. Our theoretical analysis and numerical results reveal fundamental performance-complexity trade-offs, providing insights for practical ISAC waveform and receiver design in doubly dispersive channels.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u5206\u6790\u4e86\u53cc\u5f25\u6563\u4fe1\u9053\u4e2d\u7b26\u53f7\u95f4\u548c\u8f7d\u6ce2\u95f4\u5e72\u6270\u5efa\u6a21\uff0c\u63d0\u51fa\u4e86\u5e7f\u4e49OFDM\u6846\u67b6\u8bc4\u4f30\u56db\u79cdISCI\u5904\u7406\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u6027\u80fd-\u590d\u6742\u5ea6\u6743\u8861\u3002", "motivation": "\u4e3a\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u5728\u53cc\u5f25\u6563\u4fe1\u9053\u4e2d\u63d0\u4f9b\u5b9e\u7528\u7684\u6ce2\u5f62\u548c\u63a5\u6536\u673a\u8bbe\u8ba1\u6307\u5bfc\uff0c\u89e3\u51b3ISCI\u5efa\u6a21\u7684\u5173\u952e\u95ee\u9898\u3002", "method": "\u91c7\u7528\u5e7f\u4e49OFDM\u6846\u67b6\uff0c\u901a\u8fc7\u8fde\u7eed\u65f6\u5ef6-\u591a\u666e\u52d2\u4fe1\u9053\u8868\u5f81\uff0c\u63a8\u5bfcLMMSE\u4fe1\u9053\u4f30\u8ba1\u5668\u548c\u76f8\u5e94\u4f30\u8ba1\u8bef\u5dee\uff0c\u91cf\u5316\u901a\u4fe1\u6027\u80fd\u7684\u904d\u5386\u5bb9\u91cf\u754c\u9650\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u7ed3\u679c\u63ed\u793a\u4e86\u56db\u79cdISCI\u5904\u7406\u65b9\u6cd5\u7684\u57fa\u672c\u6027\u80fd-\u590d\u6742\u5ea6\u6743\u8861\uff0c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\u3002", "conclusion": "\u5728\u53cc\u5f25\u6563\u4fe1\u9053\u4e2d\uff0cISCI\u5904\u7406\u65b9\u6cd5\u7684\u9009\u62e9\u9700\u8981\u5728\u6027\u80fd\u548c\u590d\u6742\u5ea6\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\uff0c\u4e3aISAC\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2511.09165", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09165", "abs": "https://arxiv.org/abs/2511.09165", "authors": ["Wouter Jansen", "Walter Daems", "Jan Steckel"], "title": "Delay-Multiply-And-Sum Beamforming for Real-Time In-Air Acoustic Imaging", "comment": null, "summary": "In-air acoustic imaging systems demand beamforming techniques that offer a high dynamic range and spatial resolution while also remaining robust. Conventional Delay-and-Sum (DAS) beamforming fails to meet these quality demands due to high sidelobes, a wide main lobe and the resulting low contrast, whereas advanced adaptive methods are typically precluded by the computational cost and the single-snapshot constraint of real-time field operation. To overcome this trade-off, we propose and detail the implementation of higher-order non-linear beamforming methods using the Delay-Multiply-and-Sum technique, coupled with Coherence Factor weighting, specifically adapted for ultrasonic in-air microphone arrays. Our efficient implementation allows for enabling GPU-accelerated, real-time performance on embedded computing platforms. Through validation against the DAS baseline using simulated and real-world acoustic data, we demonstrate that the proposed method provides significant improvements in image contrast, establishing higher-order non-linear beamforming as a practical, high-performance solution for in-air acoustic imaging.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u5b9e\u73b0\u4e86\u57fa\u4e8e\u5ef6\u8fdf\u4e58\u548c(DMAS)\u6280\u672f\u548c\u76f8\u5e72\u56e0\u5b50\u52a0\u6743\u7684\u975e\u7ebf\u6027\u6ce2\u675f\u6210\u5f62\u65b9\u6cd5\uff0c\u7528\u4e8e\u7a7a\u6c14\u58f0\u5b66\u6210\u50cf\u7cfb\u7edf\uff0c\u5728\u5d4c\u5165\u5f0f\u5e73\u53f0\u4e0a\u5b9e\u73b0GPU\u52a0\u901f\u7684\u5b9e\u65f6\u6027\u80fd\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u56fe\u50cf\u5bf9\u6bd4\u5ea6\u3002", "motivation": "\u4f20\u7edf\u5ef6\u8fdf\u6c42\u548c(DAS)\u6ce2\u675f\u6210\u5f62\u65b9\u6cd5\u5b58\u5728\u9ad8\u65c1\u74e3\u3001\u5bbd\u4e3b\u74e3\u548c\u4f4e\u5bf9\u6bd4\u5ea6\u7684\u95ee\u9898\uff0c\u800c\u81ea\u9002\u5e94\u65b9\u6cd5\u7531\u4e8e\u8ba1\u7b97\u6210\u672c\u548c\u5b9e\u65f6\u64cd\u4f5c\u7684\u5355\u5feb\u7167\u7ea6\u675f\u800c\u96be\u4ee5\u5e94\u7528\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u63d0\u4f9b\u9ad8\u52a8\u6001\u8303\u56f4\u548c\u7a7a\u95f4\u5206\u8fa8\u7387\u53c8\u4fdd\u6301\u9c81\u68d2\u6027\u7684\u6298\u4e2d\u65b9\u6848\u3002", "method": "\u91c7\u7528\u5ef6\u8fdf\u4e58\u548c(DMAS)\u6280\u672f\u7ed3\u5408\u76f8\u5e72\u56e0\u5b50\u52a0\u6743\u7684\u975e\u7ebf\u6027\u6ce2\u675f\u6210\u5f62\u65b9\u6cd5\uff0c\u4e13\u95e8\u9488\u5bf9\u7a7a\u6c14\u8d85\u58f0\u9ea6\u514b\u98ce\u9635\u5217\u8fdb\u884c\u9002\u914d\uff0c\u5e76\u901a\u8fc7GPU\u52a0\u901f\u5b9e\u73b0\u5728\u5d4c\u5165\u5f0f\u8ba1\u7b97\u5e73\u53f0\u4e0a\u7684\u5b9e\u65f6\u6027\u80fd\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u548c\u771f\u5b9e\u58f0\u5b66\u6570\u636e\u9a8c\u8bc1\uff0c\u76f8\u6bd4DAS\u57fa\u7ebf\u65b9\u6cd5\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u56fe\u50cf\u5bf9\u6bd4\u5ea6\u65b9\u9762\u6709\u663e\u8457\u63d0\u5347\u3002", "conclusion": "\u9ad8\u9636\u975e\u7ebf\u6027\u6ce2\u675f\u6210\u5f62\u662f\u7a7a\u6c14\u58f0\u5b66\u6210\u50cf\u7684\u4e00\u79cd\u5b9e\u7528\u9ad8\u6027\u80fd\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09207", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09207", "abs": "https://arxiv.org/abs/2511.09207", "authors": ["Yuan Zhong", "Yue Xiao", "Yijia Li", "Hao Chen", "Xianfu Lei", "Pingzhi Fan"], "title": "Two-Dimensional Pinching-Antenna Systems: Modeling and Beamforming Design", "comment": "32 pages, 10 figures, 2 tables, pinching-antenna system (PASS)", "summary": "Recently, the pinching-antenna system (PASS) has emerged as a promising architecture owing to its ability to reconfigure large-scale path loss and signal phase by activating radiation points along a dielectric waveguide. However, existing studies mainly focus on line-shaped PASS architectures, whose limited spatial flexibility constrains their applicability in multiuser and indoor scenarios. In this paper, we propose a novel two-dimensional (2D) pinching-antenna system (2D-PASS) that extends the conventional line-shaped structure into a continuous dielectric waveguide plane, thereby forming a reconfigurable radiating plane capable of dynamic beam adaptation across a 2D spatial domain. An optimization framework is developed to maximize the minimum received signal-to-noise ratio (SNR) among user equipments (UEs) by adaptively adjusting the spatial configuration of pinching antennas (PAs), serving as an analog beamforming mechanism for dynamic spatial control. For the continuous-position scenario, a particle swarm optimization (PSO)-based algorithm is proposed to efficiently explore the nonconvex search space, while a discrete variant is introduced to accommodate practical hardware constraints with limited PA placement resolution. Simulation results demonstrate that the proposed 2D-PASS substantially improves the minimum SNR compared with conventional line-shaped PASS and fixed-position antenna (FPA) benchmarks, while maintaining robustness under varying user distributions and distances.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u4e8c\u7ef4\u5939\u6301\u5929\u7ebf\u7cfb\u7edf\uff082D-PASS\uff09\uff0c\u5c06\u4f20\u7edf\u7684\u7ebf\u5f62\u7ed3\u6784\u6269\u5c55\u4e3a\u8fde\u7eed\u4ecb\u8d28\u6ce2\u5bfc\u5e73\u9762\uff0c\u5f62\u6210\u53ef\u91cd\u6784\u8f90\u5c04\u5e73\u9762\uff0c\u80fd\u591f\u5728\u4e8c\u7ef4\u7a7a\u95f4\u57df\u5b9e\u73b0\u52a8\u6001\u6ce2\u675f\u9002\u5e94\u3002", "motivation": "\u73b0\u6709\u7684\u5939\u6301\u5929\u7ebf\u7cfb\u7edf\u4e3b\u8981\u91c7\u7528\u7ebf\u5f62\u67b6\u6784\uff0c\u5176\u6709\u9650\u7684\u7a7a\u95f4\u7075\u6d3b\u6027\u9650\u5236\u4e86\u5728\u591a\u7528\u6237\u548c\u5ba4\u5185\u573a\u666f\u4e2d\u7684\u9002\u7528\u6027\u3002", "method": "\u5f00\u53d1\u4e86\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u5939\u6301\u5929\u7ebf\u7684\u7a7a\u95f4\u914d\u7f6e\u6765\u6700\u5927\u5316\u7528\u6237\u8bbe\u5907\u7684\u6700\u5c0f\u63a5\u6536\u4fe1\u566a\u6bd4\u3002\u9488\u5bf9\u8fde\u7eed\u4f4d\u7f6e\u573a\u666f\u63d0\u51fa\u4e86\u57fa\u4e8e\u7c92\u5b50\u7fa4\u4f18\u5316\u7684\u7b97\u6cd5\uff0c\u5e76\u4e3a\u5b9e\u9645\u786c\u4ef6\u7ea6\u675f\u5f15\u5165\u4e86\u79bb\u6563\u53d8\u4f53\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u4f20\u7edf\u7684\u7ebf\u5f62PASS\u548c\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\u57fa\u51c6\u76f8\u6bd4\uff0c\u6240\u63d0\u51fa\u76842D-PASS\u663e\u8457\u63d0\u9ad8\u4e86\u6700\u5c0fSNR\uff0c\u540c\u65f6\u5728\u53d8\u5316\u7684\u7528\u6237\u5206\u5e03\u548c\u8ddd\u79bb\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027\u3002", "conclusion": "2D-PASS\u901a\u8fc7\u6269\u5c55\u4e3a\u4e8c\u7ef4\u7ed3\u6784\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7a7a\u95f4\u7075\u6d3b\u6027\u548c\u6027\u80fd\uff0c\u4e3a\u591a\u7528\u6237\u901a\u4fe1\u573a\u666f\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09227", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09227", "abs": "https://arxiv.org/abs/2511.09227", "authors": ["Jos\u00e9 Miguel Mateos-Ramos", "Frederik Zumegen", "Henk Wymeersch", "Christian H\u00e4ger", "Christoph Studer"], "title": "Positioning via Digital-Twin-Aided Channel Charting with Large-Scale CSI Features", "comment": "12 pages, 4 figures. Submitted to an IEEE journal", "summary": "Channel charting (CC) is a self-supervised positioning technique whose main limitation is that the estimated positions lie in an arbitrary coordinate system that is not aligned with true spatial coordinates. In this work, we propose a novel method to produce CC locations in true spatial coordinates with the aid of a digital twin (DT). Our main contribution is a new framework that (i) extracts large-scale channel-state information (CSI) features from estimated CSI and the DT and (ii) matches these features with a cosine-similarity loss function. The DT-aided loss function is then combined with a conventional CC loss to learn a positioning function that provides true spatial coordinates without relying on labeled data. Our results for a simulated indoor scenario demonstrate that the proposed framework reduces the relative mean distance error by 29% compared to the state of the art. We also show that the proposed approach is robust to DT modeling mismatches and a distribution shift in the testing data.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u6570\u5b57\u5b6a\u751f\u5c06\u4fe1\u9053\u56fe\u5b9a\u4f4d\u6280\u672f\u4ece\u4efb\u610f\u5750\u6807\u7cfb\u8f6c\u6362\u5230\u771f\u5b9e\u7a7a\u95f4\u5750\u6807\u7cfb\u7684\u65b0\u65b9\u6cd5\uff0c\u901a\u8fc7\u63d0\u53d6\u5927\u89c4\u6a21\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u7279\u5f81\u5e76\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u635f\u5931\u51fd\u6570\u8fdb\u884c\u5339\u914d\uff0c\u5728\u6a21\u62df\u5ba4\u5185\u573a\u666f\u4e2d\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u5c06\u76f8\u5bf9\u5e73\u5747\u8ddd\u79bb\u8bef\u5dee\u964d\u4f4e\u4e8629%\u3002", "motivation": "\u4f20\u7edf\u4fe1\u9053\u56fe\u5b9a\u4f4d\u6280\u672f\u4f30\u8ba1\u7684\u4f4d\u7f6e\u4f4d\u4e8e\u4efb\u610f\u5750\u6807\u7cfb\u4e2d\uff0c\u65e0\u6cd5\u4e0e\u771f\u5b9e\u7a7a\u95f4\u5750\u6807\u5bf9\u9f50\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "method": "\u63d0\u51fa\u65b0\u6846\u67b6\uff1a(i)\u4ece\u4f30\u8ba1\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u548c\u6570\u5b57\u5b6a\u751f\u4e2d\u63d0\u53d6\u5927\u89c4\u6a21CSI\u7279\u5f81\uff1b(ii)\u4f7f\u7528\u4f59\u5f26\u76f8\u4f3c\u5ea6\u635f\u5931\u51fd\u6570\u5339\u914d\u8fd9\u4e9b\u7279\u5f81\uff0c\u5e76\u5c06\u8be5\u635f\u5931\u51fd\u6570\u4e0e\u4f20\u7edf\u7684\u4fe1\u9053\u56fe\u635f\u5931\u7ed3\u5408\uff0c\u5b66\u4e60\u63d0\u4f9b\u771f\u5b9e\u7a7a\u95f4\u5750\u6807\u7684\u5b9a\u4f4d\u51fd\u6570\u3002", "result": "\u5728\u6a21\u62df\u5ba4\u5185\u573a\u666f\u4e2d\uff0c\u6240\u63d0\u6846\u67b6\u76f8\u6bd4\u73b0\u6709\u6280\u672f\u5c06\u76f8\u5bf9\u5e73\u5747\u8ddd\u79bb\u8bef\u5dee\u964d\u4f4e\u4e8629%\uff0c\u4e14\u5bf9\u6570\u5b57\u5b6a\u751f\u5efa\u6a21\u4e0d\u5339\u914d\u548c\u6d4b\u8bd5\u6570\u636e\u5206\u5e03\u504f\u79fb\u5177\u6709\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u4e0d\u4f9d\u8d56\u6807\u8bb0\u6570\u636e\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u771f\u5b9e\u7a7a\u95f4\u5750\u6807\uff0c\u663e\u8457\u63d0\u5347\u4e86\u4fe1\u9053\u56fe\u5b9a\u4f4d\u6280\u672f\u7684\u5b9e\u7528\u6027\u548c\u51c6\u786e\u6027\u3002"}}
{"id": "2511.09234", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09234", "abs": "https://arxiv.org/abs/2511.09234", "authors": ["Thrassos K. Oikonomou", "Dimitrios Tyrovolas", "Sotiris A. Tegos", "Panagiotis D. Diamantoulakis", "Panagiotis Sarigiannidis", "George K. Karagiannidis"], "title": "Constellation Design and Detection under Generalized Hardware Impairments", "comment": null, "summary": "This paper presents a maximum-likelihood detection framework that jointly mitigates hardware (HW) impairments in both amplitude and phase. By modeling transceiver distortions as residual amplitude and phase noise, we introduce the approximate phase-and-amplitude distortion detector (PAD-D), which operates in the polar domain and effectively mitigates both distortion components through distortion-aware weighting. The proposed detector performs reliable detection under generalized HW impairment conditions, achieving substantial performance gains over the conventional Euclidean detector (EUC-D) and the Gaussian-assumption phase noise detector (GAP-D), which is primarily designed to address phase distortions. In addition, we derive a closed-form high-SNR symbol error probability (SEP) approximation, which offers a generic analytical expression applicable to arbitrary constellations. Simulation results demonstrate that the PAD-D achieves up to an order-of-magnitude reduction in the error floor relative to EUC-D and GAP-D for both high-order quadrature amplitude modulation (QAM) and super amplitude phase-shift keying (SAPSK) constellations, establishing a unified and practical framework for detection under realistic transceiver impairments. Building on this framework, we further develop optimized constellations tailored to PAD-D, where the symbol positions are optimized in the complex plane to minimize SEP. The optimality of these constellations is confirmed through extensive simulations, which also verify the accuracy of the proposed analytical SEP approximation, even for the optimized designs.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8054\u5408\u6291\u5236\u5e45\u5ea6\u548c\u76f8\u4f4d\u786c\u4ef6\u635f\u4f24\u7684\u6700\u5927\u4f3c\u7136\u68c0\u6d4b\u6846\u67b6PAD-D\uff0c\u5728\u6781\u5750\u6807\u57df\u901a\u8fc7\u5931\u771f\u611f\u77e5\u52a0\u6743\u6709\u6548\u7f13\u89e3\u4e24\u79cd\u5931\u771f\uff0c\u76f8\u6bd4\u4f20\u7edf\u68c0\u6d4b\u5668\u663e\u8457\u964d\u4f4e\u8bef\u7801\u7387\u5e73\u53f0\u3002", "motivation": "\u73b0\u6709\u68c0\u6d4b\u5668\u4e3b\u8981\u5173\u6ce8\u76f8\u4f4d\u5931\u771f\uff0c\u7f3a\u4e4f\u5bf9\u5e45\u5ea6\u548c\u76f8\u4f4d\u786c\u4ef6\u635f\u4f24\u7684\u8054\u5408\u5904\u7406\uff0c\u9700\u8981\u5f00\u53d1\u7edf\u4e00\u6846\u67b6\u6765\u5e94\u5bf9\u5b9e\u9645\u6536\u53d1\u5668\u635f\u4f24\u3002", "method": "\u5c06\u6536\u53d1\u5668\u5931\u771f\u5efa\u6a21\u4e3a\u6b8b\u4f59\u5e45\u5ea6\u548c\u76f8\u4f4d\u566a\u58f0\uff0c\u5728\u6781\u5750\u6807\u57df\u8bbe\u8ba1\u8fd1\u4f3c\u76f8\u4f4d\u5e45\u5ea6\u5931\u771f\u68c0\u6d4b\u5668\uff0c\u91c7\u7528\u5931\u771f\u611f\u77e5\u52a0\u6743\u7b56\u7565\u3002", "result": "PAD-D\u76f8\u6bd4\u4f20\u7edf\u6b27\u51e0\u91cc\u5f97\u68c0\u6d4b\u5668\u548c\u57fa\u4e8e\u9ad8\u65af\u5047\u8bbe\u7684\u76f8\u4f4d\u566a\u58f0\u68c0\u6d4b\u5668\uff0c\u5bf9\u9ad8\u9636QAM\u548cSAPSK\u661f\u5ea7\u53ef\u5b9e\u73b0\u9ad8\u8fbe\u4e00\u4e2a\u6570\u91cf\u7ea7\u7684\u8bef\u7801\u7387\u5e73\u53f0\u964d\u4f4e\u3002", "conclusion": "\u5efa\u7acb\u4e86\u5728\u73b0\u5b9e\u6536\u53d1\u5668\u635f\u4f24\u4e0b\u68c0\u6d4b\u7684\u7edf\u4e00\u5b9e\u7528\u6846\u67b6\uff0c\u5e76\u57fa\u4e8e\u6b64\u5f00\u53d1\u4e86\u9488\u5bf9PAD-D\u4f18\u5316\u7684\u661f\u5ea7\u8bbe\u8ba1\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u5206\u6790\u8fd1\u4f3c\u7684\u51c6\u786e\u6027\u3002"}}
{"id": "2511.09244", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09244", "abs": "https://arxiv.org/abs/2511.09244", "authors": ["Kuranage Roche Rayan Ranasinghe", "Zhaolin Wang", "Giuseppe Thadeu Freitas de Abreu", "Emil Bj\u00f6rnson"], "title": "Flexible Continuous Aperture Arrays", "comment": "Submitted to an IEEE journal", "summary": "A novel electromagnetic (EM) structure termed flexible continuous aperture array (FCAPA) is proposed, which incorporates inherent surface flexibility into typical continuous aperture array (CAPA) systems, thereby enhancing the degrees-of-freedom (DoF) of multiple-input multiple-output (MIMO) systems equipped with this technology. By formulating and solving a downlink multi-user beamforming optimization problem to maximize the weighted sum rate (WSR) of the multiple users with FCAPA, it is shown that the proposed structure outperforms typical CAPA systems by a wide margin, with performance increasing with increasing morphability.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u67d4\u6027\u8fde\u7eed\u5b54\u5f84\u9635\u5217(FCAPA)\uff0c\u901a\u8fc7\u5728\u5178\u578b\u8fde\u7eed\u5b54\u5f84\u9635\u5217\u4e2d\u5f15\u5165\u8868\u9762\u67d4\u6027\uff0c\u589e\u5f3a\u4e86MIMO\u7cfb\u7edf\u7684\u81ea\u7531\u5ea6\uff0c\u5728\u591a\u7528\u6237\u6ce2\u675f\u6210\u5f62\u4f18\u5316\u4e2d\u663e\u8457\u4f18\u4e8e\u4f20\u7edfCAPA\u7cfb\u7edf\u3002", "motivation": "\u4f20\u7edf\u8fde\u7eed\u5b54\u5f84\u9635\u5217(CAPA)\u7cfb\u7edf\u7f3a\u4e4f\u7075\u6d3b\u6027\uff0c\u9650\u5236\u4e86MIMO\u7cfb\u7edf\u7684\u81ea\u7531\u5ea6\u3002\u901a\u8fc7\u5f15\u5165\u8868\u9762\u67d4\u6027\u6765\u589e\u5f3a\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u67d4\u6027\u8fde\u7eed\u5b54\u5f84\u9635\u5217(FCAPA)\u7ed3\u6784\uff0c\u901a\u8fc7\u6570\u5b66\u5efa\u6a21\u548c\u6c42\u89e3\u4e0b\u884c\u591a\u7528\u6237\u6ce2\u675f\u6210\u5f62\u4f18\u5316\u95ee\u9898\uff0c\u6700\u5927\u5316\u591a\u7528\u6237\u7684\u52a0\u6743\u548c\u901f\u7387\u3002", "result": "FCAPA\u7ed3\u6784\u5728\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u4f20\u7edfCAPA\u7cfb\u7edf\uff0c\u4e14\u6027\u80fd\u968f\u7740\u53ef\u53d8\u5f62\u80fd\u529b\u7684\u589e\u52a0\u800c\u63d0\u5347\u3002", "conclusion": "\u67d4\u6027\u8fde\u7eed\u5b54\u5f84\u9635\u5217\u901a\u8fc7\u5f15\u5165\u8868\u9762\u67d4\u6027\u6709\u6548\u589e\u5f3a\u4e86MIMO\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u8bbe\u8ba1\u601d\u8def\u3002"}}
{"id": "2511.09254", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09254", "abs": "https://arxiv.org/abs/2511.09254", "authors": ["Ioannis Gavras", "Panagiotis Gavriilidis", "George C. Alexandropoulos"], "title": "2D Waveguide-Fed Metasurface Antenna Arrays: Modeling and Optimization for Bistatic Sensing", "comment": "5 pages, 1 figure", "summary": "This paper presents a physics-consistent framework for bistatic sensing incorporating a 2-Dimensional (2D) waveguide-fed metasurface antenna array capable of realizing eXtremely-Large Multiple-Input Multiple-Output (XL MIMO) apertures. A coupled-dipole model is presented that captures the array's mutual coupling due to both waveguide and free-space interactions, and a novel passivity constraint on the corresponding magnetic polarizabilities is proposed. Focusing on a bistatic sensing setup, we leverage a Neumann-series approximation of the array response model and derive the Cramer-Rao bound for multi-target parameter estimation, which is then incorporated into a sensing optimization formulation with respect to the metasurface's per-element resonance strength configuration. Simulation results on the position error bound in the radiative near field with the proposed design quantify the critical role of metamaterial placement in strongly coupled metasurface-based XL MIMO bistatic sensing systems.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u53cc\u57fa\u5730\u611f\u77e5\u7684\u7269\u7406\u4e00\u81f4\u6027\u6846\u67b6\uff0c\u91c7\u75282D\u6ce2\u5bfc\u9988\u7535\u8d85\u8868\u9762\u5929\u7ebf\u9635\u5217\u5b9e\u73b0\u8d85\u5927\u89c4\u6a21MIMO\u5b54\u5f84\u3002\u901a\u8fc7\u8026\u5408\u5076\u6781\u5b50\u6a21\u578b\u6355\u83b7\u9635\u5217\u4e92\u8026\u6548\u5e94\uff0c\u5e76\u63d0\u51fa\u4e86\u78c1\u6781\u5316\u7387\u7684\u65e0\u6e90\u6027\u7ea6\u675f\u3002", "motivation": "\u89e3\u51b3\u8d85\u5927\u89c4\u6a21MIMO\u53cc\u57fa\u5730\u611f\u77e5\u7cfb\u7edf\u4e2d\u8d85\u8868\u9762\u9635\u5217\u7684\u4e92\u8026\u6548\u5e94\u548c\u4f18\u5316\u914d\u7f6e\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u8f90\u5c04\u8fd1\u573a\u73af\u5883\u4e0b\u7684\u591a\u76ee\u6807\u53c2\u6570\u4f30\u8ba1\u7cbe\u5ea6\u3002", "method": "\u4f7f\u7528\u8026\u5408\u5076\u6781\u5b50\u6a21\u578b\u63cf\u8ff0\u6ce2\u5bfc\u548c\u81ea\u7531\u7a7a\u95f4\u4e92\u8026\uff0c\u63d0\u51fa\u78c1\u6781\u5316\u7387\u65e0\u6e90\u6027\u7ea6\u675f\uff0c\u91c7\u7528Neumann\u7ea7\u6570\u8fd1\u4f3c\u9635\u5217\u54cd\u5e94\u6a21\u578b\uff0c\u63a8\u5bfc\u591a\u76ee\u6807\u53c2\u6570\u4f30\u8ba1\u7684Cramer-Rao\u754c\uff0c\u5e76\u57fa\u4e8e\u6b64\u4f18\u5316\u8d85\u8868\u9762\u5171\u632f\u5f3a\u5ea6\u914d\u7f6e\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u5728\u8f90\u5c04\u8fd1\u573a\u4e2d\u63d0\u51fa\u7684\u8bbe\u8ba1\u80fd\u591f\u91cf\u5316\u4f4d\u7f6e\u8bef\u5dee\u754c\u9650\uff0c\u63ed\u793a\u4e86\u8d85\u6750\u6599\u4f4d\u7f6e\u5728\u5f3a\u8026\u5408\u8d85\u8868\u9762XL MIMO\u53cc\u57fa\u5730\u611f\u77e5\u7cfb\u7edf\u4e2d\u7684\u5173\u952e\u4f5c\u7528\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u8d85\u5927\u89c4\u6a21MIMO\u53cc\u57fa\u5730\u611f\u77e5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7269\u7406\u4e00\u81f4\u7684\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5f3a\u8c03\u4e86\u8d85\u6750\u6599\u5e03\u5c40\u5bf9\u7cfb\u7edf\u6027\u80fd\u7684\u91cd\u8981\u6027\uff0c\u7279\u522b\u662f\u5728\u5f3a\u8026\u5408\u73af\u5883\u4e0b\u7684\u4f18\u5316\u914d\u7f6e\u3002"}}
{"id": "2511.09341", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09341", "abs": "https://arxiv.org/abs/2511.09341", "authors": ["Weiran Yang", "Yiqi Cai", "Handi Deng", "Cheng Ma"], "title": "End-to-End Hardware Modeling and Sensitivity Optimization of Photoacoustic Signal Readout Chains", "comment": "10 pages, 9 figures, 1 table", "summary": "The sensitivity of the acoustic detection subsystem in photoacoustic imaging (PAI) critically affects image quality. However, previous studies often focused only on front-end acoustic components or back-end electronic components, overlooking end-to-end coupling among the transducer, cable, and receiver. This work develops a complete analytical model for system-level sensitivity optimization based on the Krimholtz, Leedom, and Matthaei (KLM) model. The KLM model is rederived from first principles of linear piezoelectric constitutive equations, 1D wave equations and transmission line theory to clarify its physical basis and applicable conditions. By encapsulating the acoustic components into a controlled voltage source and extending the model to include lumped-parameter representations of cable and receiver, an end-to-end equivalent circuit is established. Analytical expressions for the system transfer functions are derived, revealing the coupling effects among key parameters such as transducer element area (EA), cable length (CL), and receiver impedance (RI). Experimental results validate the model with an average error below 5%. Additionally, a low-frequency tailing phenomenon arising from exceeding the 1D vibration assumption is identified and analyzed, illustrating the importance of understanding the model's applicable conditions and providing a potential pathway for artifact suppression. This work offers a comprehensive framework for optimizing detection sensitivity and improving image fidelity in PAI systems.", "AI": {"tldr": "\u5f00\u53d1\u4e86\u57fa\u4e8eKLM\u6a21\u578b\u7684\u5b8c\u6574\u5149\u58f0\u6210\u50cf\u7cfb\u7edf\u7075\u654f\u5ea6\u5206\u6790\u6a21\u578b\uff0c\u901a\u8fc7\u7aef\u5230\u7aef\u7b49\u6548\u7535\u8def\u63ed\u793a\u4e86\u6362\u80fd\u5668\u3001\u7535\u7f06\u548c\u63a5\u6536\u5668\u4e4b\u95f4\u7684\u8026\u5408\u6548\u5e94\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u8bef\u5dee\u4f4e\u4e8e5%\u3002", "motivation": "\u4ee5\u5f80\u7814\u7a76\u4ec5\u5173\u6ce8\u524d\u7aef\u58f0\u5b66\u7ec4\u4ef6\u6216\u540e\u7aef\u7535\u5b50\u7ec4\u4ef6\uff0c\u5ffd\u89c6\u4e86\u6362\u80fd\u5668\u3001\u7535\u7f06\u548c\u63a5\u6536\u5668\u4e4b\u95f4\u7684\u7aef\u5230\u7aef\u8026\u5408\u6548\u5e94\uff0c\u8fd9\u9650\u5236\u4e86\u5149\u58f0\u6210\u50cf\u7cfb\u7edf\u7075\u654f\u5ea6\u7684\u4f18\u5316\u3002", "method": "\u4ece\u7ebf\u6027\u538b\u7535\u672c\u6784\u65b9\u7a0b\u3001\u4e00\u7ef4\u6ce2\u52a8\u65b9\u7a0b\u548c\u4f20\u8f93\u7ebf\u7406\u8bba\u91cd\u65b0\u63a8\u5bfcKLM\u6a21\u578b\uff0c\u5efa\u7acb\u5305\u542b\u7535\u7f06\u548c\u63a5\u6536\u5668\u7684\u7aef\u5230\u7aef\u7b49\u6548\u7535\u8def\uff0c\u63a8\u5bfc\u7cfb\u7edf\u4f20\u9012\u51fd\u6570\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u6a21\u578b\u5e73\u5747\u8bef\u5dee\u4f4e\u4e8e5%\uff0c\u8bc6\u522b\u5e76\u5206\u6790\u4e86\u8d85\u51fa1D\u632f\u52a8\u5047\u8bbe\u5bfc\u81f4\u7684\u4f4e\u9891\u62d6\u5c3e\u73b0\u8c61\uff0c\u63ed\u793a\u4e86\u5173\u952e\u53c2\u6570\u95f4\u7684\u8026\u5408\u6548\u5e94\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u4f18\u5316\u5149\u58f0\u6210\u50cf\u7cfb\u7edf\u68c0\u6d4b\u7075\u654f\u5ea6\u548c\u6539\u5584\u56fe\u50cf\u4fdd\u771f\u5ea6\u63d0\u4f9b\u4e86\u5168\u9762\u6846\u67b6\uff0c\u5e76\u6307\u51fa\u4e86\u6a21\u578b\u9002\u7528\u6761\u4ef6\u548c\u4f2a\u5f71\u6291\u5236\u7684\u6f5c\u5728\u9014\u5f84\u3002"}}
{"id": "2511.09342", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09342", "abs": "https://arxiv.org/abs/2511.09342", "authors": ["Junyi Duan", "Jiageng Chen", "Zuyuan He"], "title": "A cross-modal pre-training framework with video data for improving performance and generalization of distributed acoustic sensing", "comment": null, "summary": "Fiber-optic distributed acoustic sensing (DAS) has emerged as a critical Internet-of-Things (IoT) sensing technology with broad industrial applications. However, the two-dimensional spatial-temporal morphology of DAS signals presents analytical challenges where conventional methods prove suboptimal, while being well-suited for deep learning approaches. Although our previous work, DAS Masked Autoencoder (DAS-MAE), established state-of-the-art performance and generalization without labels, it is not satisfactory in frequency analysis in temporal-dominated DAS data. Moreover, the limitation of effective training data fails to address the substantial data requirements inherent to Transformer architectures in DAS-MAE. To overcome these limitations, we present an enhanced framework incorporating short-time Fourier transform (STFT) for explicit temporal-frequency feature extraction and pioneering video-to-DAS cross-modal pre-training to mitigate data constraints. This approach learns high-level representations (e.g., event classification) through label-free reconstruction tasks. Experimental results demonstrate transformative improvements: 0.1% error rate in few-shot classification (90.9% relative improvement over DAS-MAE) and 4.7% recognition error in external damage prevention applications (75.4% improvement over from-scratch training). As the first work to pioneer video-to-DAS cross-modal pre-training, available training resources are expanded by bridging computer vision and distributed sensing areas. The enhanced performance and generalization facilitate DAS deployment across diverse industrial scenarios while advancing cross-modal representation learning for industrial IoT sensing.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684DAS\u6846\u67b6\uff0c\u7ed3\u5408\u77ed\u65f6\u5085\u91cc\u53f6\u53d8\u6362\u8fdb\u884c\u65f6\u9891\u7279\u5f81\u63d0\u53d6\uff0c\u5e76\u9996\u521b\u89c6\u9891\u5230DAS\u7684\u8de8\u6a21\u6001\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u663e\u8457\u63d0\u5347\u4e86DAS\u4fe1\u53f7\u5206\u6790\u7684\u6027\u80fd\u548c\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u4f20\u7edfDAS\u4fe1\u53f7\u5206\u6790\u65b9\u6cd5\u5728\u4e8c\u7ef4\u65f6\u7a7a\u5f62\u6001\u5206\u6790\u4e0a\u6548\u679c\u4e0d\u4f73\uff0c\u800c\u4e4b\u524d\u7684DAS-MAE\u65b9\u6cd5\u5728\u65f6\u57df\u4e3b\u5bfc\u7684DAS\u6570\u636e\u9891\u7387\u5206\u6790\u65b9\u9762\u8868\u73b0\u4e0d\u7406\u60f3\uff0c\u4e14Transformer\u67b6\u6784\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u3002", "method": "\u91c7\u7528\u77ed\u65f6\u5085\u91cc\u53f6\u53d8\u6362(STFT)\u8fdb\u884c\u663e\u5f0f\u65f6\u9891\u7279\u5f81\u63d0\u53d6\uff0c\u5e76\u5f15\u5165\u89c6\u9891\u5230DAS\u7684\u8de8\u6a21\u6001\u9884\u8bad\u7ec3\u65b9\u6cd5\uff0c\u901a\u8fc7\u65e0\u6807\u7b7e\u91cd\u5efa\u4efb\u52a1\u5b66\u4e60\u9ad8\u7ea7\u8868\u793a\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\u5c0f\u6837\u672c\u5206\u7c7b\u9519\u8bef\u7387\u964d\u81f30.1%\uff08\u76f8\u5bf9DAS-MAE\u63d0\u534790.9%\uff09\uff0c\u5916\u90e8\u635f\u4f24\u9884\u9632\u5e94\u7528\u8bc6\u522b\u9519\u8bef\u7387\u4e3a4.7%\uff08\u76f8\u6bd4\u4ece\u5934\u8bad\u7ec3\u63d0\u534775.4%\uff09\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u662f\u9996\u4e2a\u5b9e\u73b0\u89c6\u9891\u5230DAS\u8de8\u6a21\u6001\u9884\u8bad\u7ec3\u7684\u7814\u7a76\uff0c\u901a\u8fc7\u8fde\u63a5\u8ba1\u7b97\u673a\u89c6\u89c9\u548c\u5206\u5e03\u5f0f\u4f20\u611f\u9886\u57df\uff0c\u6269\u5c55\u4e86\u53ef\u7528\u8bad\u7ec3\u8d44\u6e90\uff0c\u63a8\u52a8\u4e86\u5de5\u4e1a\u7269\u8054\u7f51\u611f\u77e5\u4e2d\u7684\u8de8\u6a21\u6001\u8868\u793a\u5b66\u4e60\u3002"}}
{"id": "2511.09370", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09370", "abs": "https://arxiv.org/abs/2511.09370", "authors": ["Corentin Presv\u00f4ts", "Michel Kieffer", "Thibault Prevost"], "title": "Reduced-Complexity Model Selection and Rate Allocation for Multiple-Model Electrical Signal Compression", "comment": "This paper has been submitted for review to the IEEE Transactions on Power Delivery", "summary": "This paper adapts a Multiple-Model Coding (MMC) approach for sampled electrical signal waveforms to satisfy reconstructed signal quality constraints. The baseline MMC approach consists of two stages processing vectors of Voltage and Current Signal (VCS) of constant size and producing bitstreams of constant rate but varying quality. In the proposed approach, the parametric model and the rate allocated to the first stage, as well as the residual compression method of the second stage and its associated rate, are jointly optimized to achieve a target distortion of the reconstructed signal. Three approaches are proposed. An exhaustive search serves as a baseline for comparison. Then, an approach involving a Golden Section search is exploited to determine the rate of the first stage with reduced complexity. Finally, rate-distortion models of the compression efficiency for each model in the first stage are employed to obtain a subset of promising models in the first stage and reduced-size search intervals for the rate selection in both stages. Simulation results demonstrate that the proposed reduced-complexity MMC approach reduces the rate for a given distortion constraint compared to state-of-the-art solutions for VCS with equivalent complexity.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u591a\u6a21\u578b\u7f16\u7801\u7684\u91c7\u6837\u7535\u4fe1\u53f7\u6ce2\u5f62\u538b\u7f29\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u7b2c\u4e00\u9636\u6bb5\u7684\u53c2\u6570\u6a21\u578b\u548c\u6bd4\u7279\u7387\u5206\u914d\u4ee5\u53ca\u7b2c\u4e8c\u9636\u6bb5\u7684\u6b8b\u5dee\u538b\u7f29\u65b9\u6cd5\uff0c\u5728\u6ee1\u8db3\u91cd\u6784\u4fe1\u53f7\u8d28\u91cf\u7ea6\u675f\u7684\u540c\u65f6\u964d\u4f4e\u590d\u6742\u5ea6\u3002", "motivation": "\u4f20\u7edf\u7684\u591a\u6a21\u578b\u7f16\u7801\u65b9\u6cd5\u867d\u7136\u80fd\u5904\u7406\u6052\u5b9a\u5927\u5c0f\u7684\u7535\u538b\u7535\u6d41\u4fe1\u53f7\u5411\u91cf\u5e76\u4ea7\u751f\u6052\u5b9a\u6bd4\u7279\u7387\u7684\u7801\u6d41\uff0c\u4f46\u8d28\u91cf\u4f1a\u53d8\u5316\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5728\u7ed9\u5b9a\u5931\u771f\u7ea6\u675f\u4e0b\u4f18\u5316\u6bd4\u7279\u7387\u5206\u914d\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u65b9\u6cd5\uff1a1\uff09\u7a77\u4e3e\u641c\u7d22\u4f5c\u4e3a\u57fa\u7ebf\uff1b2\uff09\u4f7f\u7528\u9ec4\u91d1\u5206\u5272\u641c\u7d22\u786e\u5b9a\u7b2c\u4e00\u9636\u6bb5\u6bd4\u7279\u7387\u4ee5\u964d\u4f4e\u590d\u6742\u5ea6\uff1b3\uff09\u5229\u7528\u7b2c\u4e00\u9636\u6bb5\u5404\u6a21\u578b\u7684\u7387\u5931\u771f\u6a21\u578b\u6765\u7f29\u5c0f\u641c\u7d22\u7a7a\u95f4\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u4f4e\u590d\u6742\u5ea6MMC\u65b9\u6cd5\u5728\u76f8\u540c\u590d\u6742\u5ea6\u4e0b\uff0c\u76f8\u6bd4\u73b0\u6709VCS\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u7ed9\u5b9a\u5931\u771f\u7ea6\u675f\u4e0b\u80fd\u591f\u964d\u4f4e\u6bd4\u7279\u7387\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u8054\u5408\u4f18\u5316\u6a21\u578b\u9009\u62e9\u548c\u6bd4\u7279\u7387\u5206\u914d\uff0c\u5728\u4fdd\u6301\u91cd\u6784\u8d28\u91cf\u7684\u540c\u65f6\u6709\u6548\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4e3a\u7535\u4fe1\u53f7\u538b\u7f29\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09372", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09372", "abs": "https://arxiv.org/abs/2511.09372", "authors": ["Navid Amani", "Filiberto Bilotti", "Davide Dardari", "Raffaele D Errico", "Riku Jantti", "Gianni Pasolini", "Dinh-Thuy Phan-Huy", "Davide Ramaccia", "Olivier Rance", "Henk Wymeersch"], "title": "Generation-Agnostic Zero-Energy Devices for Sustainable Connectivity, Sensing, and Localization", "comment": null, "summary": "The massive scale of Internet of Things (IoT) connectivity expected in 6G networks raises unprecedented challenges in energy use, battery waste, and lifecycle sustainability. Current cellular IoT solutions remain bound to the lifetime of underlying network generations and rely on billions of disposable batteries, creating unsustainable economic and environmental costs. This article proposes generation-agnostic zero-energy devices (XG-ZEDs), a new class of backscatter based IoT devices that are battery-less, spectrum-agnostic, and future-proof across successive network generations. XG-ZEDs exploit existing ambient wireless signals for communication, sensing, and localization, transforming infrastructure and user devices into universal enablers of ultra-low-power connectivity. We review architectural classifications, communication protocols, network integration, and representative applications such as sensing, localization, and radio-SLAM, while outlining the challenges ahead.", "AI": {"tldr": "\u63d0\u51faXG-ZEDs\u2014\u2014\u4e00\u79cd\u65e0\u7535\u6c60\u3001\u9891\u8c31\u65e0\u5173\u3001\u8de8\u4ee3\u517c\u5bb9\u7684\u65b0\u578b\u53cd\u5411\u6563\u5c04\u7269\u8054\u7f51\u8bbe\u5907\uff0c\u5229\u7528\u73b0\u6709\u73af\u5883\u65e0\u7ebf\u4fe1\u53f7\u5b9e\u73b0\u901a\u4fe1\u3001\u611f\u77e5\u548c\u5b9a\u4f4d\uff0c\u89e3\u51b36G\u7269\u8054\u7f51\u7684\u80fd\u6e90\u548c\u53ef\u6301\u7eed\u6027\u6311\u6218\u3002", "motivation": "6G\u7f51\u7edc\u4e2d\u7269\u8054\u7f51\u8fde\u63a5\u89c4\u6a21\u5de8\u5927\uff0c\u5e26\u6765\u524d\u6240\u672a\u6709\u7684\u80fd\u6e90\u4f7f\u7528\u3001\u7535\u6c60\u6d6a\u8d39\u548c\u751f\u547d\u5468\u671f\u53ef\u6301\u7eed\u6027\u6311\u6218\u3002\u73b0\u6709\u8702\u7a9d\u7269\u8054\u7f51\u89e3\u51b3\u65b9\u6848\u53d7\u9650\u4e8e\u7f51\u7edc\u4ee3\u9645\u5bff\u547d\uff0c\u4f9d\u8d56\u6570\u5341\u4ebf\u4e00\u6b21\u6027\u7535\u6c60\uff0c\u4ea7\u751f\u4e0d\u53ef\u6301\u7eed\u7684\u7ecf\u6d4e\u548c\u73af\u5883\u6210\u672c\u3002", "method": "\u63d0\u51faXG-ZEDs\uff08\u8de8\u4ee3\u96f6\u80fd\u8017\u8bbe\u5907\uff09\uff0c\u8fd9\u662f\u4e00\u79cd\u57fa\u4e8e\u53cd\u5411\u6563\u5c04\u7684\u65e0\u7535\u6c60\u7269\u8054\u7f51\u8bbe\u5907\uff0c\u80fd\u591f\u5229\u7528\u73b0\u6709\u73af\u5883\u65e0\u7ebf\u4fe1\u53f7\u8fdb\u884c\u901a\u4fe1\u3001\u611f\u77e5\u548c\u5b9a\u4f4d\uff0c\u5c06\u57fa\u7840\u8bbe\u65bd\u548c\u7528\u6237\u8bbe\u5907\u8f6c\u53d8\u4e3a\u8d85\u4f4e\u529f\u8017\u8fde\u63a5\u7684\u901a\u7528\u4f7f\u80fd\u5668\u3002", "result": "\u56de\u987e\u4e86\u67b6\u6784\u5206\u7c7b\u3001\u901a\u4fe1\u534f\u8bae\u3001\u7f51\u7edc\u96c6\u6210\u4ee5\u53ca\u4ee3\u8868\u6027\u5e94\u7528\uff08\u5982\u611f\u77e5\u3001\u5b9a\u4f4d\u548c\u65e0\u7ebf\u7535SLAM\uff09\uff0c\u4e3a\u672a\u6765\u96f6\u80fd\u8017\u7269\u8054\u7f51\u53d1\u5c55\u63d0\u4f9b\u4e86\u6846\u67b6\u3002", "conclusion": "XG-ZEDs\u4ee3\u8868\u4e86\u89e3\u51b3\u7269\u8054\u7f51\u53ef\u6301\u7eed\u6027\u6311\u6218\u7684\u7a81\u7834\u6027\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528\u73af\u5883\u65e0\u7ebf\u4fe1\u53f7\u5b9e\u73b0\u65e0\u7535\u6c60\u64cd\u4f5c\uff0c\u4e3a\u8de8\u4ee3\u517c\u5bb9\u7684\u7eff\u8272\u7269\u8054\u7f51\u8fde\u63a5\u94fa\u5e73\u9053\u8def\u3002"}}
{"id": "2511.09418", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.09418", "abs": "https://arxiv.org/abs/2511.09418", "authors": ["Nishant Mehrotra", "Sandesh Rao Mattu", "Robert Calderbank"], "title": "Equivalence of Several 6G Modulation Schemes for Doubly-Selective Channels", "comment": "6 pages, 2 figures, to be submitted to IEEE for possible publication", "summary": "There is significant recent interest in designing new modulation schemes for doubly-selective channels with large delay and Doppler spreads, where legacy modulation schemes based on time-frequency signal representations do not perform well. In this paper, we develop a framework for analyzing such modulations using two characteristics -- non-selectivity and predictability -- which directly relate to the diversity and spectral efficiency that the modulations achieve. We show that modulations in the delay-Doppler, chirp and time-sequency domains are non-selective, predictable and equivalent to one another, whereas time-frequency modulations are selective and non-predictable.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u5206\u6790\u53cc\u9009\u62e9\u6027\u4fe1\u9053\u8c03\u5236\u65b9\u6848\u7684\u6846\u67b6\uff0c\u57fa\u4e8e\u975e\u9009\u62e9\u6027\u548c\u53ef\u9884\u6d4b\u6027\u4e24\u4e2a\u7279\u6027\uff0c\u63ed\u793a\u4e86\u5ef6\u8fdf-\u591a\u666e\u52d2\u3001\u5541\u557e\u548c\u65f6\u95f4\u5e8f\u5217\u8c03\u5236\u4e0e\u65f6\u95f4-\u9891\u7387\u8c03\u5236\u7684\u672c\u8d28\u5dee\u5f02\u3002", "motivation": "\u9488\u5bf9\u5177\u6709\u5927\u5ef6\u8fdf\u548c\u591a\u666e\u52d2\u6269\u5c55\u7684\u53cc\u9009\u62e9\u6027\u4fe1\u9053\uff0c\u4f20\u7edf\u57fa\u4e8e\u65f6\u95f4-\u9891\u7387\u4fe1\u53f7\u8868\u793a\u7684\u8c03\u5236\u65b9\u6848\u6027\u80fd\u4e0d\u4f73\uff0c\u9700\u8981\u8bbe\u8ba1\u65b0\u7684\u8c03\u5236\u65b9\u6848\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5206\u6790\u6846\u67b6\uff0c\u4f7f\u7528\u975e\u9009\u62e9\u6027\u548c\u53ef\u9884\u6d4b\u6027\u4e24\u4e2a\u7279\u6027\u6765\u5206\u6790\u4e0d\u540c\u8c03\u5236\u65b9\u6848\uff0c\u8fd9\u4e9b\u7279\u6027\u76f4\u63a5\u5173\u7cfb\u5230\u8c03\u5236\u65b9\u6848\u5b9e\u73b0\u7684\u591a\u6837\u6027\u548c\u9891\u8c31\u6548\u7387\u3002", "result": "\u53d1\u73b0\u5ef6\u8fdf-\u591a\u666e\u52d2\u3001\u5541\u557e\u548c\u65f6\u95f4\u5e8f\u5217\u57df\u8c03\u5236\u662f\u975e\u9009\u62e9\u6027\u3001\u53ef\u9884\u6d4b\u4e14\u5f7c\u6b64\u7b49\u4ef7\u7684\uff0c\u800c\u65f6\u95f4-\u9891\u7387\u8c03\u5236\u662f\u9009\u62e9\u6027\u548c\u4e0d\u53ef\u9884\u6d4b\u7684\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53cc\u9009\u62e9\u6027\u4fe1\u9053\u8c03\u5236\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u63ed\u793a\u4e86\u4e0d\u540c\u8c03\u5236\u57df\u7684\u672c\u8d28\u7279\u6027\u5dee\u5f02\u3002"}}
{"id": "2511.09453", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09453", "abs": "https://arxiv.org/abs/2511.09453", "authors": ["Deqiao Gan", "Xiaoxia Xu", "Xiaohu Ge", "Yuanwei Liu"], "title": "LLM Enabled Beam Training for Pinching Antenna Systems (PASS)", "comment": "submitted to IEEE journal", "summary": "To enable intelligent beam training, a large language model (LLM)-enabled beam training framework is proposed for the pinching antenna system (PASS) in downlink multi-user multiple-input multiple-output (MIMO) communications. A novel LLM-based beam training supervised learning mechanism is developed, allowing context-aware and environment-adaptive probing for PASS to reduce overheads. Both single-user and multi-user cases are considered. 1) For single-user case, the LLM-based pinching beamforming codebook generation problem is formulated to maximize the beamforming gain. Then, the optimal transmit beamforming is obtained by maximum ratio transmission (MRT). 2) For multi-user case, a joint codebook generation and beam selection problem is formulated based on the system sum rate under the minimum mean square error (MMSE) transmit beamforming. The training labels for pinching beamforming are constructed by selecting the beam combination that maximizes system performance from each user's Top-S candidate beams. Based on pretrained Generative Pre-trained Transformers (GPTs), the LLM is trained in an end-to-end fashion to minimize the cross-entropy loss. Simulation results demonstrate that: i) For single-user case, the proposed LLM-enabled PASS attains over 95% Top-1 accuracy in beam selection and achieves 51.92% improvements in beamforming gains compared to conventional method. ii) For multi-user case, the proposed LLM-enabled PASS framework significantly outperforms both the LLM-based massive MIMO and conventional PASS beam training, achieving up to 57.14% and 33.33% improvements in sum rate, respectively.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u6ce2\u675f\u8bad\u7ec3\u6846\u67b6\uff0c\u7528\u4e8e\u591a\u7528\u6237MIMO\u901a\u4fe1\u4e2d\u7684pinching\u5929\u7ebf\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u73af\u5883\u81ea\u9002\u5e94\u7684\u63a2\u6d4b\u6765\u51cf\u5c11\u5f00\u9500\uff0c\u5728\u5355\u7528\u6237\u548c\u591a\u7528\u6237\u573a\u666f\u4e0b\u5747\u663e\u8457\u63d0\u5347\u4e86\u6027\u80fd\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u4f20\u7edf\u6ce2\u675f\u8bad\u7ec3\u5f00\u9500\u5927\u7684\u95ee\u9898\uff0c\u5229\u7528\u5927\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u667a\u80fd\u5316\u7684\u6ce2\u675f\u8bad\u7ec3\uff0c\u4f7fpinching\u5929\u7ebf\u7cfb\u7edf\u80fd\u591f\u8fdb\u884c\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u73af\u5883\u81ea\u9002\u5e94\u7684\u63a2\u6d4b\u3002", "method": "\u5f00\u53d1\u4e86\u57fa\u4e8eLLM\u7684\u6ce2\u675f\u8bad\u7ec3\u76d1\u7763\u5b66\u4e60\u673a\u5236\uff1a\u5355\u7528\u6237\u573a\u666f\u4e0b\u91c7\u7528\u6700\u5927\u6bd4\u4f20\u8f93\u6ce2\u675f\u6210\u5f62\uff1b\u591a\u7528\u6237\u573a\u666f\u4e0b\u57fa\u4e8eMMSE\u6ce2\u675f\u6210\u5f62\u8054\u5408\u4f18\u5316\u7801\u672c\u751f\u6210\u548c\u6ce2\u675f\u9009\u62e9\uff0c\u4f7f\u7528\u9884\u8bad\u7ec3\u7684GPT\u6a21\u578b\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3\u3002", "result": "\u5355\u7528\u6237\u573a\u666f\u4e0b\uff1aTop-1\u51c6\u786e\u7387\u8d85\u8fc795%\uff0c\u6ce2\u675f\u6210\u5f62\u589e\u76ca\u6bd4\u4f20\u7edf\u65b9\u6cd5\u63d0\u534751.92%\uff1b\u591a\u7528\u6237\u573a\u666f\u4e0b\uff1a\u7cfb\u7edf\u603b\u901f\u7387\u6bd4\u57fa\u4e8eLLM\u7684\u5927\u89c4\u6a21MIMO\u548c\u4f20\u7edfPASS\u5206\u522b\u63d0\u534757.14%\u548c33.33%\u3002", "conclusion": "LLM\u4f7f\u80fd\u7684PASS\u6846\u67b6\u5728\u6ce2\u675f\u8bad\u7ec3\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6ce2\u675f\u9009\u62e9\u51c6\u786e\u6027\u548c\u7cfb\u7edf\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86LLM\u5728\u901a\u4fe1\u7cfb\u7edf\u4e2d\u5e94\u7528\u7684\u6f5c\u529b\u3002"}}
{"id": "2511.09464", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09464", "abs": "https://arxiv.org/abs/2511.09464", "authors": ["Ali Rasteh", "Amirreza Kiani", "Marco Mezzavilla", "Sundeep Rangan"], "title": "Scalable Long-Term Beamforming for Massive Multi-User MIMO", "comment": "6 pages, submitted to the IEEE International Conference on Communications (ICC) 2026", "summary": "Fully digital massive MIMO systems with large numbers (1000+) of antennas offer dramatically increased capacity gains from spatial multiplexing and beamforming. Designing digital receivers that can scale to these array dimensions presents significant challenges regarding both channel estimation overhead and digital computation. This paper presents a computationally efficient and low-overhead receiver design based on long-term beamforming. The method combines finding a low-rank projection from the spatial covariance estimate with a fast polynomial matrix inverse. Ray tracing simulations show minimal loss relative to complete instantaneous beamforming while offering significant overhead and computational gains.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u957f\u671f\u6ce2\u675f\u6210\u5f62\u7684\u8ba1\u7b97\u9ad8\u6548\u3001\u5f00\u9500\u4f4e\u7684\u5927\u89c4\u6a21MIMO\u63a5\u6536\u673a\u8bbe\u8ba1\u65b9\u6cd5", "motivation": "\u5168\u6570\u5b57\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\uff081000+\u5929\u7ebf\uff09\u867d\u7136\u80fd\u63d0\u4f9b\u663e\u8457\u7684\u7a7a\u95f4\u590d\u7528\u548c\u6ce2\u675f\u6210\u5f62\u589e\u76ca\uff0c\u4f46\u5728\u4fe1\u9053\u4f30\u8ba1\u5f00\u9500\u548c\u6570\u5b57\u8ba1\u7b97\u65b9\u9762\u9762\u4e34\u91cd\u5927\u6311\u6218", "method": "\u7ed3\u5408\u4ece\u7a7a\u95f4\u534f\u65b9\u5dee\u4f30\u8ba1\u4e2d\u5bfb\u627e\u4f4e\u79e9\u6295\u5f71\u4e0e\u5feb\u901f\u591a\u9879\u5f0f\u77e9\u9635\u6c42\u9006\u7684\u65b9\u6cd5", "result": "\u5c04\u7ebf\u8ffd\u8e2a\u4eff\u771f\u663e\u793a\u76f8\u5bf9\u4e8e\u5b8c\u6574\u7684\u77ac\u65f6\u6ce2\u675f\u6210\u5f62\u65b9\u6cd5\uff0c\u6027\u80fd\u635f\u5931\u6781\u5c0f\uff0c\u540c\u65f6\u63d0\u4f9b\u4e86\u663e\u8457\u7684\u5f00\u9500\u548c\u8ba1\u7b97\u589e\u76ca", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u591f\u4ee5\u6700\u5c0f\u7684\u6027\u80fd\u635f\u5931\u5b9e\u73b0\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u9ad8\u6548\u63a5\u6536\u673a\u8bbe\u8ba1"}}
{"id": "2511.09474", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09474", "abs": "https://arxiv.org/abs/2511.09474", "authors": ["Tummi Ganesh", "Soumya P. Dash", "Italo Atzeni"], "title": "Outage Probability Analysis of MRC-Based Fluid Antenna Systems under Rician Fading", "comment": "5 pages, 3 figures", "summary": "This paper investigates a fluid antenna system (FAS) where a single-antenna transmitter communicates with a receiver equipped with a fluid antenna (FA) over a Rician fading channel. Considering that multiple ports among the M available FA ports can be activated, the receiver selects the best K with the highest instantaneous signal-to-noise ratio (SNR) and combines the received signals at the selected ports using maximum ratio combining. The statistics of the post-combining SNR are derived using a Laplace transform-based approach, which allows to analyze the outage probability (OP) of the FAS. Additional closed-form expressions for a lower bound on the OP and the asymptotic OP at high SNR are presented. Numerical results validate the analytical framework and demonstrate the interplay of key system parameters on the performance of the considered MRC-based FAS.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u6700\u5927\u6bd4\u5408\u5e76\u7684\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u5728Rician\u8870\u843d\u4fe1\u9053\u4e0b\u7684\u6027\u80fd\uff0c\u63a8\u5bfc\u4e86\u4e2d\u65ad\u6982\u7387\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u5e76\u7ed9\u51fa\u4e86\u95ed\u5f0f\u8868\u8fbe\u5f0f\u548c\u6e10\u8fd1\u5206\u6790\u3002", "motivation": "\u7814\u7a76\u591a\u7aef\u53e3\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u4e2d\u901a\u8fc7\u9009\u62e9\u6700\u4f73\u7aef\u53e3\u5e76\u91c7\u7528\u6700\u5927\u6bd4\u5408\u5e76\u6280\u672f\u6765\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728Rician\u8870\u843d\u4fe1\u9053\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u8868\u73b0\u3002", "method": "\u4f7f\u7528\u62c9\u666e\u62c9\u65af\u53d8\u6362\u65b9\u6cd5\u63a8\u5bfc\u540e\u5408\u5e76\u4fe1\u566a\u6bd4\u7684\u7edf\u8ba1\u7279\u6027\uff0c\u5206\u6790\u4e2d\u65ad\u6982\u7387\uff0c\u5e76\u7ed9\u51fa\u4e0b\u754c\u548c\u6e10\u8fd1\u8868\u8fbe\u5f0f\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u5206\u6790\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5173\u952e\u7cfb\u7edf\u53c2\u6570\u5bf9\u57fa\u4e8eMRC\u7684\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002", "conclusion": "\u57fa\u4e8eMRC\u7684\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u80fd\u591f\u6709\u6548\u63d0\u5347\u901a\u4fe1\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u591a\u7aef\u53e3\u9009\u62e9\u548c\u5408\u5e76\u7b56\u7565\u4e0b\uff0c\u7cfb\u7edf\u53c2\u6570\u5bf9\u6027\u80fd\u6709\u663e\u8457\u5f71\u54cd\u3002"}}

{"id": "2511.09995", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2511.09995", "abs": "https://arxiv.org/abs/2511.09995", "authors": ["Haoyu Li", "Mingyang Han", "Yu Xi", "Dongxiao Wang", "Hankun Wang", "Haoxiang Shi", "Boyu Li", "Jun Song", "Bo Zheng", "Shuai Wang"], "title": "Time-Layer Adaptive Alignment for Speaker Similarity in Flow-Matching Based Zero-Shot TTS", "comment": "Submitted to ICASSP 2026", "summary": "Flow-Matching (FM)-based zero-shot text-to-speech (TTS) systems exhibit high-quality speech synthesis and robust generalization capabilities. However, the speaker representation ability of such systems remains underexplored, primarily due to the lack of explicit speaker-specific supervision in the FM framework. To this end, we conduct an empirical analysis of speaker information distribution and reveal its non-uniform allocation across time steps and network layers, underscoring the need for adaptive speaker alignment. Accordingly, we propose Time-Layer Adaptive Speaker Alignment (TLA-SA), a loss that enhances speaker consistency by jointly leveraging temporal and hierarchical variations in speaker information. Experimental results show that TLA-SA significantly improves speaker similarity compared to baseline systems on both research- and industrial-scale datasets and generalizes effectively across diverse model architectures, including decoder-only language models (LM) and FM-based TTS systems free of LM.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u65f6\u95f4-\u5c42\u81ea\u9002\u5e94\u8bf4\u8bdd\u4eba\u5bf9\u9f50(TLA-SA)\u635f\u5931\u51fd\u6570\uff0c\u901a\u8fc7\u5229\u7528\u8bf4\u8bdd\u4eba\u4fe1\u606f\u5728\u65f6\u95f4\u6b65\u548c\u7f51\u7edc\u5c42\u4e2d\u7684\u975e\u5747\u5300\u5206\u5e03\u7279\u6027\uff0c\u663e\u8457\u63d0\u5347\u4e86\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u96f6\u6837\u672c\u6587\u672c\u5230\u8bed\u97f3\u7cfb\u7edf\u7684\u8bf4\u8bdd\u4eba\u76f8\u4f3c\u5ea6\u3002", "motivation": "\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u96f6\u6837\u672c\u6587\u672c\u5230\u8bed\u97f3\u7cfb\u7edf\u867d\u7136\u5177\u6709\u9ad8\u8d28\u91cf\u7684\u8bed\u97f3\u5408\u6210\u548c\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u4f46\u7531\u4e8e\u7f3a\u4e4f\u660e\u786e\u7684\u8bf4\u8bdd\u4eba\u7279\u5b9a\u76d1\u7763\uff0c\u5176\u8bf4\u8bdd\u4eba\u8868\u793a\u80fd\u529b\u4ecd\u6709\u5f85\u63a2\u7d22\u3002", "method": "\u901a\u8fc7\u7ecf\u9a8c\u5206\u6790\u63ed\u793a\u4e86\u8bf4\u8bdd\u4eba\u4fe1\u606f\u5728\u65f6\u95f4\u6b65\u548c\u7f51\u7edc\u5c42\u4e2d\u7684\u975e\u5747\u5300\u5206\u914d\u7279\u6027\uff0c\u636e\u6b64\u63d0\u51fa\u4e86\u65f6\u95f4-\u5c42\u81ea\u9002\u5e94\u8bf4\u8bdd\u4eba\u5bf9\u9f50(TLA-SA)\u635f\u5931\u51fd\u6570\uff0c\u8be5\u635f\u5931\u51fd\u6570\u8054\u5408\u5229\u7528\u8bf4\u8bdd\u4eba\u4fe1\u606f\u7684\u65f6\u95f4\u53d8\u5316\u548c\u5c42\u6b21\u53d8\u5316\u6765\u589e\u5f3a\u8bf4\u8bdd\u4eba\u4e00\u81f4\u6027\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cTLA-SA\u5728\u7814\u7a76\u548c\u5de5\u4e1a\u89c4\u6a21\u6570\u636e\u96c6\u4e0a\u5747\u663e\u8457\u63d0\u9ad8\u4e86\u8bf4\u8bdd\u4eba\u76f8\u4f3c\u5ea6\uff0c\u5e76\u4e14\u80fd\u591f\u6709\u6548\u6cdb\u5316\u5230\u4e0d\u540c\u7684\u6a21\u578b\u67b6\u6784\uff0c\u5305\u62ec\u4ec5\u89e3\u7801\u5668\u8bed\u8a00\u6a21\u578b\u548c\u65e0\u8bed\u8a00\u6a21\u578b\u7684\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u6587\u672c\u5230\u8bed\u97f3\u7cfb\u7edf\u3002", "conclusion": "TLA-SA\u901a\u8fc7\u81ea\u9002\u5e94\u5730\u5bf9\u9f50\u8bf4\u8bdd\u4eba\u4fe1\u606f\uff0c\u6709\u6548\u63d0\u5347\u4e86\u57fa\u4e8e\u6d41\u5339\u914d\u7684\u96f6\u6837\u672c\u6587\u672c\u5230\u8bed\u97f3\u7cfb\u7edf\u7684\u8bf4\u8bdd\u4eba\u8868\u793a\u80fd\u529b\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u9002\u7528\u6027\u3002"}}
{"id": "2511.10168", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2511.10168", "abs": "https://arxiv.org/abs/2511.10168", "authors": ["Ilai Zaidel", "Sharon Gannot"], "title": "A Study of Binaural Deep Beamforming With Interpretable Beampatterns Guided by Time-Varying RTF", "comment": "5 pages, 6 figures", "summary": "In this work, a deep beamforming framework for speech enhancement in dynamic acoustic environments is studied. The time-varying beamformer weights are estimated from the noisy multichannel signals by minimizing an SI-SDR loss. The estimation is guided by the continuously tracked relative transfer functions (RTFs) of the moving target speaker. The spatial behavior of the network is evaluated through both narrowband and wideband beampatterns under three settings: (i) oracle guidance using true RTFs, (ii) estimated RTFs obtained by a subspace tracking method, and (iii) without the RTF guidance. Results show that RTF-guided models produce smoother, spatially consistent beampatterns that accurately track the target's direction of arrival. In contrast, the model fails to maintain a clear spatial focus when guidance is absent. Using the estimated RTFs as guidance closely matches the oracle RTF behavior, confirming the effectiveness of the tracking scheme. The model also outputs a binaural signal to preserve the speaker's spatial cues, which promotes hearing aid and hearables applications.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u52a8\u6001\u58f0\u5b66\u73af\u5883\u4e2d\u8bed\u97f3\u589e\u5f3a\u7684\u6df1\u5ea6\u6ce2\u675f\u5f62\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u6700\u5c0f\u5316SI-SDR\u635f\u5931\u4ece\u591a\u901a\u9053\u566a\u58f0\u4fe1\u53f7\u4e2d\u4f30\u8ba1\u65f6\u53d8\u6ce2\u675f\u5f62\u6210\u5668\u6743\u91cd\uff0c\u5e76\u4f7f\u7528\u76ee\u6807\u8bf4\u8bdd\u4eba\u7684\u76f8\u5bf9\u4f20\u9012\u51fd\u6570\u8fdb\u884c\u5f15\u5bfc\u3002", "motivation": "\u5728\u52a8\u6001\u58f0\u5b66\u73af\u5883\u4e2d\u5b9e\u73b0\u6709\u6548\u7684\u8bed\u97f3\u589e\u5f3a\uff0c\u7279\u522b\u662f\u5728\u76ee\u6807\u8bf4\u8bdd\u4eba\u79fb\u52a8\u7684\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u80fd\u591f\u51c6\u786e\u8ddf\u8e2a\u8bf4\u8bdd\u4eba\u65b9\u5411\u5e76\u4fdd\u6301\u7a7a\u95f4\u4e00\u81f4\u6027\u7684\u6ce2\u675f\u5f62\u6210\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\u4f30\u8ba1\u65f6\u53d8\u6ce2\u675f\u5f62\u6210\u5668\u6743\u91cd\uff0c\u901a\u8fc7\u6700\u5c0f\u5316SI-SDR\u635f\u5931\u8fdb\u884c\u4f18\u5316\uff0c\u5e76\u5229\u7528\u76ee\u6807\u8bf4\u8bdd\u4eba\u7684\u76f8\u5bf9\u4f20\u9012\u51fd\u6570\u8fdb\u884c\u5f15\u5bfc\u3002\u8bc4\u4f30\u4e86\u4e09\u79cd\u8bbe\u7f6e\uff1a\u4f7f\u7528\u771f\u5b9eRTF\u3001\u4f30\u8ba1RTF\u548c\u65e0RTF\u5f15\u5bfc\u3002", "result": "RTF\u5f15\u5bfc\u7684\u6a21\u578b\u4ea7\u751f\u66f4\u5e73\u6ed1\u3001\u7a7a\u95f4\u4e00\u81f4\u7684\u6ce2\u675f\u6a21\u5f0f\uff0c\u80fd\u51c6\u786e\u8ddf\u8e2a\u76ee\u6807\u5230\u8fbe\u65b9\u5411\u3002\u65e0\u5f15\u5bfc\u65f6\u6a21\u578b\u65e0\u6cd5\u4fdd\u6301\u6e05\u6670\u7684\u7a7a\u95f4\u805a\u7126\u3002\u4f7f\u7528\u4f30\u8ba1RTF\u4e0e\u4f7f\u7528\u771f\u5b9eRTF\u6548\u679c\u63a5\u8fd1\u3002", "conclusion": "RTF\u5f15\u5bfc\u5bf9\u4e8e\u5728\u52a8\u6001\u73af\u5883\u4e2d\u7ef4\u6301\u6709\u6548\u7684\u7a7a\u95f4\u805a\u7126\u81f3\u5173\u91cd\u8981\uff0c\u6240\u63d0\u51fa\u7684\u8ddf\u8e2a\u65b9\u6848\u6709\u6548\uff0c\u4e14\u6a21\u578b\u8f93\u51fa\u7684\u53cc\u8033\u4fe1\u53f7\u6709\u52a9\u4e8e\u52a9\u542c\u5668\u548c\u53ef\u7a7f\u6234\u8bbe\u5907\u5e94\u7528\u3002"}}
{"id": "2511.10289", "categories": ["eess.AS", "cs.CL"], "pdf": "https://arxiv.org/pdf/2511.10289", "abs": "https://arxiv.org/abs/2511.10289", "authors": ["Sreyan Ghosh", "Arushi Goel", "Lasha Koroshinadze", "Sang-gil Lee", "Zhifeng Kong", "Joao Felipe Santos", "Ramani Duraiswami", "Dinesh Manocha", "Wei Ping", "Mohammad Shoeybi", "Bryan Catanzaro"], "title": "Music Flamingo: Scaling Music Understanding in Audio Language Models", "comment": "Project Page: https://research.nvidia.com/labs/adlr/MF/", "summary": "We introduce Music Flamingo, a novel large audio-language model designed to advance music (including song) understanding in foundational audio models. While audio-language research has progressed rapidly, music remains challenging due to its dynamic, layered, and information-dense nature. Progress has been further limited by the difficulty of scaling open audio understanding models, primarily because of the scarcity of high-quality music data and annotations. As a result, prior models are restricted to producing short, high-level captions, answering only surface-level questions, and showing limited generalization across diverse musical cultures. To address these challenges, we curate MF-Skills, a large-scale dataset labeled through a multi-stage pipeline that yields rich captions and question-answer pairs covering harmony, structure, timbre, lyrics, and cultural context. We fine-tune an enhanced Audio Flamingo 3 backbone on MF-Skills and further strengthen multiple skills relevant to music understanding. To improve the model's reasoning abilities, we introduce a post-training recipe: we first cold-start with MF-Think, a novel chain-of-thought dataset grounded in music theory, followed by GRPO-based reinforcement learning with custom rewards. Music Flamingo achieves state-of-the-art results across 10+ benchmarks for music understanding and reasoning, establishing itself as a generalist and musically intelligent audio-language model. Beyond strong empirical results, Music Flamingo sets a new standard for advanced music understanding by demonstrating how models can move from surface-level recognition toward layered, human-like perception of songs. We believe this work provides both a benchmark and a foundation for the community to build the next generation of models that engage with music as meaningfully as humans do.", "AI": {"tldr": "Music Flamingo\u662f\u4e00\u4e2a\u4e13\u4e3a\u97f3\u4e50\u7406\u89e3\u8bbe\u8ba1\u7684\u5927\u578b\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u6784\u5efa\u5927\u89c4\u6a21\u6570\u636e\u96c6MF-Skills\u548c\u589e\u5f3a\u63a8\u7406\u80fd\u529b\u7684\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5728\u97f3\u4e50\u7406\u89e3\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\u3002", "motivation": "\u5f53\u524d\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u5728\u97f3\u4e50\u7406\u89e3\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u4e3b\u8981\u7531\u4e8e\u97f3\u4e50\u5177\u6709\u52a8\u6001\u3001\u5206\u5c42\u548c\u4fe1\u606f\u5bc6\u96c6\u7684\u7279\u6027\uff0c\u4e14\u9ad8\u8d28\u91cf\u97f3\u4e50\u6570\u636e\u548c\u6807\u6ce8\u7a00\u7f3a\uff0c\u5bfc\u81f4\u73b0\u6709\u6a21\u578b\u53ea\u80fd\u751f\u6210\u7b80\u77ed\u63cf\u8ff0\u3001\u56de\u7b54\u6d45\u5c42\u95ee\u9898\uff0c\u8de8\u6587\u5316\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002", "method": "\u6784\u5efaMF-Skills\u5927\u89c4\u6a21\u6570\u636e\u96c6\uff0c\u5305\u542b\u4e30\u5bcc\u6807\u6ce8\u548c\u95ee\u7b54\u5bf9\uff1b\u5728\u589e\u5f3a\u7684Audio Flamingo 3\u9aa8\u5e72\u7f51\u7edc\u4e0a\u5fae\u8c03\uff1b\u5f15\u5165\u540e\u8bad\u7ec3\u65b9\u6cd5\uff1a\u5148\u7528\u57fa\u4e8e\u97f3\u4e50\u7406\u8bba\u7684MF-Think\u6570\u636e\u96c6\u8fdb\u884c\u51b7\u542f\u52a8\u601d\u7ef4\u94fe\u8bad\u7ec3\uff0c\u518d\u4f7f\u7528GRPO\u5f3a\u5316\u5b66\u4e60\u548c\u5b9a\u5236\u5956\u52b1\u3002", "result": "\u572810\u591a\u4e2a\u97f3\u4e50\u7406\u89e3\u548c\u63a8\u7406\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6700\u5148\u8fdb\u7684\u7ed3\u679c\uff0c\u5c55\u73b0\u4e86\u4f5c\u4e3a\u901a\u7528\u97f3\u4e50\u667a\u80fd\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u7684\u5f3a\u5927\u80fd\u529b\u3002", "conclusion": "Music Flamingo\u4e3a\u97f3\u4e50\u7406\u89e3\u8bbe\u5b9a\u4e86\u65b0\u6807\u51c6\uff0c\u5c55\u793a\u4e86\u6a21\u578b\u5982\u4f55\u4ece\u8868\u5c42\u8bc6\u522b\u8f6c\u5411\u5206\u5c42\u3001\u7c7b\u4eba\u7684\u97f3\u4e50\u611f\u77e5\uff0c\u4e3a\u6784\u5efa\u80fd\u4e0e\u97f3\u4e50\u8fdb\u884c\u6709\u610f\u4e49\u4ea4\u4e92\u7684\u4e0b\u4e00\u4ee3\u6a21\u578b\u63d0\u4f9b\u4e86\u57fa\u51c6\u548c\u57fa\u7840\u3002"}}
{"id": "2511.10639", "categories": ["eess.AS", "math.OC"], "pdf": "https://arxiv.org/pdf/2511.10639", "abs": "https://arxiv.org/abs/2511.10639", "authors": ["Vitor Gelsleichter Probst Curtarelli"], "title": "Direction-of-Arrival and Noise Covariance Matrix joint estimation for beamforming", "comment": null, "summary": "We propose a joint estimation method for the Direction-of-Arrival (DoA) and the Noise Covariance Matrix (NCM) tailored for beamforming applications. Building upon an existing NCM framework, our approach simplifies the estimation procedure by deriving an quasi-linear solution, instead of the traditional exhaustive search. Additionally, we introduce a novel DoA estimation technique that operates across all frequency bins, improving robustness in reverberant environments. Simulation results demonstrate that our method outperforms classical techniques, such as MUSIC, in mid- to high-angle scenarios, achieving lower angular errors and superior signal enhancement through beamforming. The proposed framework was also fared against other techniques for signal enhancement, having better noise rejection and interference canceling capabilities. These improvements are validated using both theoretical and empirical performance metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8054\u5408\u4f30\u8ba1\u6ce2\u8fbe\u65b9\u5411(DoA)\u548c\u566a\u58f0\u534f\u65b9\u5dee\u77e9\u9635(NCM)\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u6ce2\u675f\u6210\u5f62\u5e94\u7528\uff0c\u901a\u8fc7\u51c6\u7ebf\u6027\u89e3\u7b80\u5316\u4f30\u8ba1\u8fc7\u7a0b\uff0c\u5e76\u5728\u6df7\u54cd\u73af\u5883\u4e2d\u63d0\u9ad8\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edfDoA\u548cNCM\u4f30\u8ba1\u65b9\u6cd5\u901a\u5e38\u4f7f\u7528\u7a77\u4e3e\u641c\u7d22\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u4e14\u5728\u6df7\u54cd\u73af\u5883\u4e2d\u6027\u80fd\u53d7\u9650\u3002\u9700\u8981\u5f00\u53d1\u66f4\u9ad8\u6548\u3001\u9c81\u68d2\u7684\u65b9\u6cd5\u6765\u63d0\u5347\u6ce2\u675f\u6210\u5f62\u6027\u80fd\u3002", "method": "\u57fa\u4e8e\u73b0\u6709NCM\u6846\u67b6\uff0c\u63a8\u5bfc\u51c6\u7ebf\u6027\u89e3\u66ff\u4ee3\u4f20\u7edf\u7a77\u4e3e\u641c\u7d22\uff1b\u63d0\u51fa\u8de8\u6240\u6709\u9891\u7387\u7bb1\u7684DoA\u4f30\u8ba1\u6280\u672f\uff1b\u8054\u5408\u4f30\u8ba1DoA\u548cNCM\u7528\u4e8e\u6ce2\u675f\u6210\u5f62\u3002", "result": "\u5728\u4e2d\u9ad8\u89d2\u5ea6\u573a\u666f\u4e0b\u4f18\u4e8eMUSIC\u7b49\u7ecf\u5178\u65b9\u6cd5\uff0c\u89d2\u5ea6\u8bef\u5dee\u66f4\u4f4e\uff0c\u4fe1\u53f7\u589e\u5f3a\u6548\u679c\u66f4\u597d\uff1b\u5728\u566a\u58f0\u6291\u5236\u548c\u5e72\u6270\u6d88\u9664\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u6240\u63d0\u65b9\u6cd5\u5728\u7406\u8bba\u548c\u5b9e\u8bc1\u6027\u80fd\u6307\u6807\u4e0a\u5747\u9a8c\u8bc1\u4e86\u5176\u4f18\u8d8a\u6027\uff0c\u4e3a\u6ce2\u675f\u6210\u5f62\u5e94\u7528\u63d0\u4f9b\u4e86\u66f4\u6709\u6548\u7684DoA\u548cNCM\u8054\u5408\u4f30\u8ba1\u65b9\u6848\u3002"}}
{"id": "2511.09562", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2511.09562", "abs": "https://arxiv.org/abs/2511.09562", "authors": ["Hannah Park", "Dasaem Jeong"], "title": "WaveRoll: JavaScript Library for Comparative MIDI Piano-Roll Visualization", "comment": "Late-breaking/demo (LBD) at ISMIR 2025. https://ismir2025program.ismir.net/lbd_459.html", "summary": "WaveRoll is an interactive JavaScript library that enables comparative visualization and synchronized playback of multiple MIDI piano rolls on a browser. It addresses a specific evaluation need in Automatic Music Transcription (AMT), contrasting multiple MIDI outputs produced from the same input. The library displays multiple MIDI tracks on a single, time-aligned grid with synchronized audio, allowing users to compare pitch and timing, identify missed or extra notes, and observe onset and offset differences, as well as section-level patterns. We expect that such comparisons would assist in model evaluation and error analysis, and help readers to understand the model behavior better. The open-source library is available at https://github.com/crescent-stdio/wave-roll", "AI": {"tldr": "WaveRoll\u662f\u4e00\u4e2a\u4ea4\u4e92\u5f0fJavaScript\u5e93\uff0c\u7528\u4e8e\u5728\u6d4f\u89c8\u5668\u4e2d\u6bd4\u8f83\u53ef\u89c6\u5316\u548c\u540c\u6b65\u64ad\u653e\u591a\u4e2aMIDI\u94a2\u7434\u5377\u5e18\uff0c\u4e13\u95e8\u7528\u4e8e\u81ea\u52a8\u97f3\u4e50\u8f6c\u5f55(AMT)\u7684\u8bc4\u4f30\u9700\u6c42\u3002", "motivation": "\u89e3\u51b3\u81ea\u52a8\u97f3\u4e50\u8f6c\u5f55(AMT)\u4e2d\u5bf9\u6bd4\u540c\u4e00\u8f93\u5165\u4ea7\u751f\u7684\u591a\u4e2aMIDI\u8f93\u51fa\u7684\u7279\u5b9a\u8bc4\u4f30\u9700\u6c42\uff0c\u5e2e\u52a9\u6a21\u578b\u8bc4\u4f30\u548c\u9519\u8bef\u5206\u6790\u3002", "method": "\u5728\u5355\u4e2a\u65f6\u95f4\u5bf9\u9f50\u7684\u7f51\u683c\u4e0a\u663e\u793a\u591a\u4e2aMIDI\u97f3\u8f68\uff0c\u652f\u6301\u540c\u6b65\u97f3\u9891\u64ad\u653e\uff0c\u5141\u8bb8\u7528\u6237\u6bd4\u8f83\u97f3\u9ad8\u548c\u65f6\u5e8f\uff0c\u8bc6\u522b\u9057\u6f0f\u6216\u591a\u4f59\u97f3\u7b26\uff0c\u89c2\u5bdf\u8d77\u59cb\u548c\u7ed3\u675f\u65f6\u95f4\u5dee\u5f02\u4ee5\u53ca\u6bb5\u843d\u7ea7\u6a21\u5f0f\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u5f00\u6e90JavaScript\u5e93\uff0c\u53ef\u5728\u6d4f\u89c8\u5668\u4e2d\u5b9e\u73b0\u591aMIDI\u94a2\u7434\u5377\u5e18\u7684\u5bf9\u6bd4\u53ef\u89c6\u5316\u548c\u540c\u6b65\u64ad\u653e\u529f\u80fd\u3002", "conclusion": "\u8fd9\u79cd\u6bd4\u8f83\u65b9\u6cd5\u6709\u52a9\u4e8e\u6a21\u578b\u8bc4\u4f30\u3001\u9519\u8bef\u5206\u6790\uff0c\u5e76\u5e2e\u52a9\u8bfb\u8005\u66f4\u597d\u5730\u7406\u89e3\u6a21\u578b\u884c\u4e3a\u3002"}}
{"id": "2511.09802", "categories": ["eess.SP", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.09802", "abs": "https://arxiv.org/abs/2511.09802", "authors": ["Parinaz Binandeh Dehaghani", "Danilo Pena", "A. Pedro Aguiar"], "title": "Investigation of Feature Selection and Pooling Methods for Environmental Sound Classification", "comment": "6 pages, 7 figures (including subfigures)", "summary": "This paper explores the impact of dimensionality reduction and pooling methods for Environmental Sound Classification (ESC) using lightweight CNNs. We evaluate Sparse Salient Region Pooling (SSRP) and its variants, SSRP-Basic (SSRP-B) and SSRP-Top-K (SSRP-T), under various hyperparameter settings and compare them with Principal Component Analysis (PCA). Experiments on the ESC-50 dataset demonstrate that SSRP-T achieves up to 80.69 % accuracy, significantly outperforming both the baseline CNN (66.75 %) and the PCA-reduced model (37.60 %). Our findings confirm that a well-tuned sparse pooling strategy provides a robust, efficient, and high-performing solution for ESC tasks, particularly in resource-constrained scenarios where balancing accuracy and computational cost is crucial.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u73af\u5883\u58f0\u97f3\u5206\u7c7b\u4e2d\u7ef4\u5ea6\u7f29\u51cf\u548c\u6c60\u5316\u65b9\u6cd5\u7684\u5f71\u54cd\uff0c\u53d1\u73b0SSRP-T\u7a00\u758f\u6c60\u5316\u7b56\u7565\u5728ESC-50\u6570\u636e\u96c6\u4e0a\u8fbe\u523080.69%\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebfCNN\u548cPCA\u65b9\u6cd5\u3002", "motivation": "\u63a2\u7d22\u5728\u8d44\u6e90\u53d7\u9650\u573a\u666f\u4e0b\u5e73\u8861\u51c6\u786e\u6027\u548c\u8ba1\u7b97\u6210\u672c\u7684\u8f7b\u91cf\u7ea7\u73af\u5883\u58f0\u97f3\u5206\u7c7b\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u8bc4\u4f30\u7a00\u758f\u663e\u8457\u533a\u57df\u6c60\u5316(SSRP)\u53ca\u5176\u53d8\u4f53SSRP-B\u548cSSRP-T\uff0c\u4e0e\u4e3b\u6210\u5206\u5206\u6790(PCA)\u8fdb\u884c\u5bf9\u6bd4\uff0c\u5e76\u5728ESC-50\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "SSRP-T\u8fbe\u523080.69%\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebfCNN(66.75%)\u548cPCA\u6a21\u578b(37.60%)\u3002", "conclusion": "\u7cbe\u5fc3\u8c03\u4f18\u7684\u7a00\u758f\u6c60\u5316\u7b56\u7565\u4e3a\u73af\u5883\u58f0\u97f3\u5206\u7c7b\u4efb\u52a1\u63d0\u4f9b\u4e86\u9c81\u68d2\u3001\u9ad8\u6548\u4e14\u9ad8\u6027\u80fd\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2511.09585", "categories": ["cs.SD", "cs.MM"], "pdf": "https://arxiv.org/pdf/2511.09585", "abs": "https://arxiv.org/abs/2511.09585", "authors": ["Xinyi Tong", "Yiran Zh", "Jishang Chen", "Chunru Zhan", "Tianle Wang", "Sirui Zhang", "Nian Liu", "Tiezheng Ge", "Duo Xu", "Xin Jin", "Feng Yu", "Song-Chun Zhu"], "title": "Video Echoed in Music: Semantic, Temporal, and Rhythmic Alignment for Video-to-Music Generation", "comment": null, "summary": "Video-to-Music generation seeks to generate musically appropriate background music that enhances audiovisual immersion for videos. However, current approaches suffer from two critical limitations: 1) incomplete representation of video details, leading to weak alignment, and 2) inadequate temporal and rhythmic correspondence, particularly in achieving precise beat synchronization. To address the challenges, we propose Video Echoed in Music (VeM), a latent music diffusion that generates high-quality soundtracks with semantic, temporal, and rhythmic alignment for input videos. To capture video details comprehensively, VeM employs a hierarchical video parsing that acts as a music conductor, orchestrating multi-level information across modalities. Modality-specific encoders, coupled with a storyboard-guided cross-attention mechanism (SG-CAtt), integrate semantic cues while maintaining temporal coherence through position and duration encoding. For rhythmic precision, the frame-level transition-beat aligner and adapter (TB-As) dynamically synchronize visual scene transitions with music beats. We further contribute a novel video-music paired dataset sourced from e-commerce advertisements and video-sharing platforms, which imposes stricter transition-beat synchronization requirements. Meanwhile, we introduce novel metrics tailored to the task. Experimental results demonstrate superiority, particularly in semantic relevance and rhythmic precision.", "AI": {"tldr": "\u63d0\u51fa\u4e86Video Echoed in Music (VeM)\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u89c6\u9891\u89e3\u6790\u548c\u8282\u62cd\u5bf9\u9f50\u6280\u672f\u751f\u6210\u4e0e\u89c6\u9891\u8bed\u4e49\u3001\u65f6\u95f4\u548c\u8282\u594f\u5bf9\u9f50\u7684\u9ad8\u8d28\u91cf\u80cc\u666f\u97f3\u4e50\u3002", "motivation": "\u89e3\u51b3\u73b0\u6709\u89c6\u9891\u914d\u4e50\u751f\u6210\u65b9\u6cd5\u5728\u89c6\u9891\u7ec6\u8282\u8868\u793a\u4e0d\u5b8c\u6574\u548c\u5bf9\u9f50\u6027\u5f31\uff0c\u4ee5\u53ca\u65f6\u95f4\u8282\u594f\u5bf9\u5e94\u4e0d\u8db3\u7684\u95ee\u9898\uff0c\u7279\u522b\u662f\u7cbe\u786e\u8282\u62cd\u540c\u6b65\u7684\u6311\u6218\u3002", "method": "\u4f7f\u7528\u5206\u5c42\u89c6\u9891\u89e3\u6790\u4f5c\u4e3a\u97f3\u4e50\u6307\u6325\uff0c\u7ed3\u5408\u6a21\u6001\u7279\u5b9a\u7f16\u7801\u5668\u548c\u6545\u4e8b\u677f\u5f15\u5bfc\u7684\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\uff0c\u901a\u8fc7\u5e27\u7ea7\u8fc7\u6e21-\u8282\u62cd\u5bf9\u9f50\u5668\u52a8\u6001\u540c\u6b65\u89c6\u89c9\u573a\u666f\u8f6c\u6362\u4e0e\u97f3\u4e50\u8282\u62cd\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u5728\u8bed\u4e49\u76f8\u5173\u6027\u548c\u8282\u594f\u7cbe\u786e\u6027\u65b9\u9762\u8868\u73b0\u4f18\u8d8a\uff0c\u7279\u522b\u662f\u5728\u65b0\u6784\u5efa\u7684\u89c6\u9891-\u97f3\u4e50\u914d\u5bf9\u6570\u636e\u96c6\u4e0a\u3002", "conclusion": "VeM\u65b9\u6cd5\u80fd\u591f\u751f\u6210\u4e0e\u89c6\u9891\u5728\u8bed\u4e49\u3001\u65f6\u95f4\u548c\u8282\u594f\u4e0a\u9ad8\u5ea6\u5bf9\u9f50\u7684\u9ad8\u8d28\u91cf\u80cc\u666f\u97f3\u4e50\uff0c\u663e\u8457\u63d0\u5347\u4e86\u89c6\u542c\u6c89\u6d78\u4f53\u9a8c\u3002"}}
{"id": "2511.09826", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.09826", "abs": "https://arxiv.org/abs/2511.09826", "authors": ["Yu Zhao", "Li You", "Jinke Tang", "Mengyu Qian", "Bin Jiang", "Xiang-Gen Xia", "Xiqi Gao"], "title": "Massive MIMO-OFDM Channel Acquisition with Multi-group Adjustable Phase Shift Pilots", "comment": "to appear on IEEE Transactions on Communications", "summary": "Massive multiple-input multiple-output - orthogonal frequency division multiplexing (MIMO-OFDM) systems face the challenge of high channel acquisition overhead while providing significant spectral efficiency (SE). Adjustable phase shift pilots (APSPs) are an effective technique to acquire channels with low overhead by exploiting channel sparsity. In this paper, we extend it to multiple groups and propose multi-group adjustable phase shift pilots (MAPSPs) to improve SE further. We first introduce a massive MIMO-OFDM system model and transform the conventional channel model in the space-frequency domain to the angle-delay domain, obtaining a sparse channel matrix. Then, we propose a method of generating MAPSPs through multiple basic sequences and investigate channel estimation processes. By analyzing the components of pilot interference, we elucidate the underlying mechanism by which interference affects MMSE estimation. Building upon this foundation, we demonstrate the benefit of phase scheduling in MAPSP channel estimation and establish the optimal design condition tailored for scheduling. Furthermore, we propose an implementation scheme based on Zadoff-Chu sequences that includes received signal pre-processing and pilot scheduling methods to mitigate pilot interference. Simulation results indicate that the MAPSP method achieves a lower mean square error (MSE) of estimation than APSP and significantly enhances SE in mobility scenarios.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u591a\u7ec4\u53ef\u8c03\u76f8\u79fb\u5bfc\u9891(MAPSPs)\u65b9\u6cd5\uff0c\u901a\u8fc7\u591a\u7ec4\u57fa\u672c\u5e8f\u5217\u751f\u6210\u5bfc\u9891\uff0c\u5728\u89d2\u5ea6-\u65f6\u5ef6\u57df\u5229\u7528\u4fe1\u9053\u7a00\u758f\u6027\uff0c\u964d\u4f4e\u5927\u89c4\u6a21MIMO-OFDM\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u5f00\u9500\u5e76\u63d0\u9ad8\u9891\u8c31\u6548\u7387\u3002", "motivation": "\u5927\u89c4\u6a21MIMO-OFDM\u7cfb\u7edf\u9762\u4e34\u9ad8\u4fe1\u9053\u83b7\u53d6\u5f00\u9500\u7684\u6311\u6218\uff0c\u800c\u53ef\u8c03\u76f8\u79fb\u5bfc\u9891(APSPs)\u867d\u7136\u80fd\u5229\u7528\u4fe1\u9053\u7a00\u758f\u6027\u964d\u4f4e\u5f00\u9500\uff0c\u4f46\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\u3002\u672c\u6587\u65e8\u5728\u901a\u8fc7\u6269\u5c55\u4e3a\u591a\u7ec4\u5bfc\u9891\u8fdb\u4e00\u6b65\u63d0\u5347\u9891\u8c31\u6548\u7387\u3002", "method": "\u5c06\u4f20\u7edf\u7a7a\u95f4-\u9891\u7387\u57df\u4fe1\u9053\u6a21\u578b\u8f6c\u6362\u5230\u89d2\u5ea6-\u65f6\u5ef6\u57df\u83b7\u5f97\u7a00\u758f\u4fe1\u9053\u77e9\u9635\uff1b\u63d0\u51fa\u57fa\u4e8e\u591a\u7ec4\u57fa\u672c\u5e8f\u5217\u7684MAPSPs\u751f\u6210\u65b9\u6cd5\uff1b\u5206\u6790\u5bfc\u9891\u5e72\u6270\u5bf9MMSE\u4f30\u8ba1\u7684\u5f71\u54cd\u673a\u5236\uff1b\u63d0\u51fa\u57fa\u4e8eZadoff-Chu\u5e8f\u5217\u7684\u5b9e\u73b0\u65b9\u6848\uff0c\u5305\u62ec\u63a5\u6536\u4fe1\u53f7\u9884\u5904\u7406\u548c\u5bfc\u9891\u8c03\u5ea6\u65b9\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cMAPSP\u65b9\u6cd5\u76f8\u6bd4APSP\u5b9e\u73b0\u4e86\u66f4\u4f4e\u7684\u4f30\u8ba1\u5747\u65b9\u8bef\u5dee(MSE)\uff0c\u5e76\u5728\u79fb\u52a8\u573a\u666f\u4e2d\u663e\u8457\u63d0\u5347\u4e86\u9891\u8c31\u6548\u7387\u3002", "conclusion": "MAPSP\u65b9\u6cd5\u901a\u8fc7\u591a\u7ec4\u5bfc\u9891\u548c\u76f8\u4f4d\u8c03\u5ea6\u4f18\u5316\uff0c\u6709\u6548\u964d\u4f4e\u4e86\u4fe1\u9053\u4f30\u8ba1\u8bef\u5dee\u5e76\u63d0\u9ad8\u4e86\u5927\u89c4\u6a21MIMO-OFDM\u7cfb\u7edf\u7684\u9891\u8c31\u6548\u7387\uff0c\u7279\u522b\u662f\u5728\u79fb\u52a8\u573a\u666f\u4e2d\u8868\u73b0\u4f18\u5f02\u3002"}}
{"id": "2511.10112", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2511.10112", "abs": "https://arxiv.org/abs/2511.10112", "authors": ["Wenyu Wang", "Zhetao Hu", "Yiquan Zhou", "Jiacheng Xu", "Zhiyu Wu", "Chen Li", "Shihao Li"], "title": "FabasedVC: Enhancing Voice Conversion with Text Modality Fusion and Phoneme-Level SSL Features", "comment": "Accepted by ACMMM-Asia 2025", "summary": "In voice conversion (VC), it is crucial to preserve complete semantic information while accurately modeling the target speaker's timbre and prosody. This paper proposes FabasedVC to achieve VC with enhanced similarity in timbre, prosody, and duration to the target speaker, as well as improved content integrity. It is an end-to-end VITS-based VC system that integrates relevant textual modality information, phoneme-level self-supervised learning (SSL) features, and a duration predictor. Specifically, we employ a text feature encoder to encode attributes such as text, phonemes, tones and BERT features. We then process the frame-level SSL features into phoneme-level features using two methods: average pooling and attention mechanism based on each phoneme's duration. Moreover, a duration predictor is incorporated to better align the speech rate and prosody of the target speaker. Experimental results demonstrate that our method outperforms competing systems in terms of naturalness, similarity, and content integrity.", "AI": {"tldr": "FabasedVC\u662f\u4e00\u4e2a\u57fa\u4e8eVITS\u7684\u7aef\u5230\u7aef\u8bed\u97f3\u8f6c\u6362\u7cfb\u7edf\uff0c\u901a\u8fc7\u6574\u5408\u6587\u672c\u6a21\u6001\u4fe1\u606f\u3001\u97f3\u7d20\u7ea7\u81ea\u76d1\u7763\u5b66\u4e60\u7279\u5f81\u548c\u65f6\u957f\u9884\u6d4b\u5668\uff0c\u5728\u97f3\u8272\u3001\u97f5\u5f8b\u548c\u65f6\u957f\u65b9\u9762\u5b9e\u73b0\u4e0e\u76ee\u6807\u8bf4\u8bdd\u4eba\u66f4\u597d\u7684\u76f8\u4f3c\u6027\uff0c\u540c\u65f6\u4fdd\u6301\u5185\u5bb9\u5b8c\u6574\u6027\u3002", "motivation": "\u5728\u8bed\u97f3\u8f6c\u6362\u4e2d\uff0c\u9700\u8981\u540c\u65f6\u4fdd\u6301\u5b8c\u6574\u7684\u8bed\u4e49\u4fe1\u606f\u5e76\u51c6\u786e\u5efa\u6a21\u76ee\u6807\u8bf4\u8bdd\u4eba\u7684\u97f3\u8272\u548c\u97f5\u5f8b\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u8fd9\u4e9b\u65b9\u9762\u7684\u8868\u73b0\u4ecd\u6709\u63d0\u5347\u7a7a\u95f4\u3002", "method": "\u4f7f\u7528\u6587\u672c\u7279\u5f81\u7f16\u7801\u5668\u7f16\u7801\u6587\u672c\u3001\u97f3\u7d20\u3001\u97f3\u8c03\u548cBERT\u7279\u5f81\uff1b\u901a\u8fc7\u5e73\u5747\u6c60\u5316\u548c\u6ce8\u610f\u529b\u673a\u5236\u5c06\u5e27\u7ea7SSL\u7279\u5f81\u5904\u7406\u4e3a\u97f3\u7d20\u7ea7\u7279\u5f81\uff1b\u52a0\u5165\u65f6\u957f\u9884\u6d4b\u5668\u6765\u5bf9\u9f50\u76ee\u6807\u8bf4\u8bdd\u4eba\u7684\u8bed\u901f\u548c\u97f5\u5f8b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u81ea\u7136\u5ea6\u3001\u76f8\u4f3c\u5ea6\u548c\u5185\u5bb9\u5b8c\u6574\u6027\u65b9\u9762\u4f18\u4e8e\u7ade\u4e89\u7cfb\u7edf\u3002", "conclusion": "FabasedVC\u901a\u8fc7\u6574\u5408\u591a\u6a21\u6001\u4fe1\u606f\u548c\u65f6\u957f\u9884\u6d4b\uff0c\u6709\u6548\u63d0\u5347\u4e86\u8bed\u97f3\u8f6c\u6362\u5728\u97f3\u8272\u3001\u97f5\u5f8b\u548c\u5185\u5bb9\u4fdd\u6301\u65b9\u9762\u7684\u6027\u80fd\u3002"}}
{"id": "2511.09992", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.09992", "abs": "https://arxiv.org/abs/2511.09992", "authors": ["Mehdi Zafari", "A. Lee Swindlehurst"], "title": "ASSENT: Learning-Based Association Optimization for Distributed Cell-Free ISAC", "comment": "Preprint. 6 pages, 2 figures, 2 tables. Under review. Code and datasets: https://github.com/LS-Wireless/ASSENT-CellFree-ISAC", "summary": "Integrated Sensing and Communication (ISAC) is a key emerging 6G technology. Despite progress, ISAC still lacks scalable methods for joint AP clustering and user/target scheduling in distributed deployments under fronthaul limits. Moreover, existing ISAC solutions largely rely on centralized processing and full channel state information, limiting scalability. This paper addresses joint access point (AP) clustering, user and target scheduling, and AP mode selection in distributed cell-free ISAC systems operating with constrained fronthaul capacity. We formulate the problem as a mixed-integer linear program (MILP) that jointly captures interference coupling, RF-chain limits, and sensing requirements, providing optimal but computationally demanding solutions. To enable real-time and scalable operation, we propose ASSENT (ASSociation and ENTity selection), a graph neural network (GNN) framework trained on MILP solutions to efficiently learn association and mode-selection policies directly from lightweight link statistics. Simulations show that ASSENT achieves near-optimal utility while accurately learning the underlying associations. Additionally, its single forward pass inference reduces decision latency compared to optimization-based methods. An open-source Python/PyTorch implementation with full datasets is provided to facilitate reproducible and extensible research in cell-free ISAC.", "AI": {"tldr": "\u63d0\u51faASSENT\u6846\u67b6\uff0c\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u89e3\u51b3\u5206\u5e03\u5f0f\u65e0\u8702\u7a9dISAC\u7cfb\u7edf\u4e2d\u7684AP\u805a\u7c7b\u3001\u7528\u6237/\u76ee\u6807\u8c03\u5ea6\u548cAP\u6a21\u5f0f\u9009\u62e9\u95ee\u9898\uff0c\u5728\u6709\u9650\u524d\u4f20\u5bb9\u91cf\u4e0b\u5b9e\u73b0\u8fd1\u6700\u4f18\u6027\u80fd\u3002", "motivation": "\u73b0\u6709ISAC\u89e3\u51b3\u65b9\u6848\u4e3b\u8981\u4f9d\u8d56\u96c6\u4e2d\u5f0f\u5904\u7406\u548c\u5b8c\u6574\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff0c\u9650\u5236\u4e86\u53ef\u6269\u5c55\u6027\uff0c\u4e14\u7f3a\u4e4f\u5728\u524d\u4f20\u9650\u5236\u4e0b\u8054\u5408AP\u805a\u7c7b\u548c\u7528\u6237/\u76ee\u6807\u8c03\u5ea6\u7684\u53ef\u6269\u5c55\u65b9\u6cd5\u3002", "method": "\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u6df7\u5408\u6574\u6570\u7ebf\u6027\u89c4\u5212\uff0c\u5e76\u63d0\u51faASSENT\u6846\u67b6\u2014\u2014\u57fa\u4e8eMILP\u89e3\u8bad\u7ec3\u7684\u56fe\u795e\u7ecf\u7f51\u7edc\uff0c\u76f4\u63a5\u4ece\u8f7b\u91cf\u7ea7\u94fe\u8def\u7edf\u8ba1\u4e2d\u5b66\u4e60\u5173\u8054\u548c\u6a21\u5f0f\u9009\u62e9\u7b56\u7565\u3002", "result": "\u4eff\u771f\u663e\u793aASSENT\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684\u6548\u7528\uff0c\u51c6\u786e\u5b66\u4e60\u5e95\u5c42\u5173\u8054\uff0c\u5355\u6b21\u524d\u5411\u4f20\u64ad\u63a8\u7406\u76f8\u6bd4\u57fa\u4e8e\u4f18\u5316\u7684\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u51b3\u7b56\u5ef6\u8fdf\u3002", "conclusion": "ASSENT\u4e3a\u65e0\u8702\u7a9dISAC\u63d0\u4f9b\u5b9e\u65f6\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5f00\u6e90\u5b9e\u73b0\u4fc3\u8fdb\u53ef\u590d\u73b0\u548c\u53ef\u6269\u5c55\u7814\u7a76\u3002"}}
{"id": "2511.10222", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.10222", "abs": "https://arxiv.org/abs/2511.10222", "authors": ["Yudong Yang", "Xuezhen Zhang", "Zhifeng Han", "Siyin Wang", "Jimin Zhuang", "Zengrui Jin", "Jing Shao", "Guangzhi Sun", "Chao Zhang"], "title": "Speech-Audio Compositional Attacks on Multimodal LLMs and Their Mitigation with SALMONN-Guard", "comment": null, "summary": "Recent progress in large language models (LLMs) has enabled understanding of both speech and non-speech audio, but exposing new safety risks emerging from complex audio inputs that are inadequately handled by current safeguards. We introduce SACRED-Bench (Speech-Audio Composition for RED-teaming) to evaluate the robustness of LLMs under complex audio-based attacks. Unlike existing perturbation-based methods that rely on noise optimization or white-box access, SACRED-Bench exploits speech-audio composition mechanisms. SACRED-Bench adopts three mechanisms: (a) speech overlap and multi-speaker dialogue, which embeds harmful prompts beneath or alongside benign speech; (b) speech-audio mixture, which imply unsafe intent via non-speech audio alongside benign speech or audio; and (c) diverse spoken instruction formats (open-ended QA, yes/no) that evade text-only filters. Experiments show that, even Gemini 2.5 Pro, the state-of-the-art proprietary LLM, still exhibits 66% attack success rate in SACRED-Bench test set, exposing vulnerabilities under cross-modal, speech-audio composition attacks. To bridge this gap, we propose SALMONN-Guard, a safeguard LLM that jointly inspects speech, audio, and text for safety judgments, reducing attack success down to 20%. Our results highlight the need for audio-aware defenses for the safety of multimodal LLMs. The benchmark and SALMONN-Guard checkpoints can be found at https://huggingface.co/datasets/tsinghua-ee/SACRED-Bench. Warning: this paper includes examples that may be offensive or harmful.", "AI": {"tldr": "SACRED-Bench\u662f\u4e00\u4e2a\u8bc4\u4f30\u5927\u8bed\u8a00\u6a21\u578b\u5728\u590d\u6742\u97f3\u9891\u653b\u51fb\u4e0b\u9c81\u68d2\u6027\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u8bed\u97f3-\u97f3\u9891\u7ec4\u5408\u673a\u5236\uff08\u8bed\u97f3\u91cd\u53e0\u3001\u8bed\u97f3-\u97f3\u9891\u6df7\u5408\u3001\u591a\u6837\u5316\u53e3\u8bed\u6307\u4ee4\uff09\u8fdb\u884c\u7ea2\u961f\u6d4b\u8bd5\uff0c\u53d1\u73b0\u5373\u4f7f\u6700\u5148\u8fdb\u7684Gemini 2.5 Pro\u4ecd\u670966%\u653b\u51fb\u6210\u529f\u7387\uff0c\u5e76\u63d0\u51fa\u4e86SALMONN-Guard\u9632\u62a4\u6a21\u578b\u5c06\u653b\u51fb\u6210\u529f\u7387\u964d\u81f320%\u3002", "motivation": "\u5f53\u524d\u5927\u8bed\u8a00\u6a21\u578b\u5728\u8bed\u97f3\u548c\u975e\u8bed\u97f3\u97f3\u9891\u7406\u89e3\u65b9\u9762\u53d6\u5f97\u8fdb\u5c55\uff0c\u4f46\u73b0\u6709\u5b89\u5168\u9632\u62a4\u63aa\u65bd\u65e0\u6cd5\u6709\u6548\u5904\u7406\u590d\u6742\u7684\u97f3\u9891\u8f93\u5165\u5e26\u6765\u7684\u65b0\u5174\u5b89\u5168\u98ce\u9669\uff0c\u9700\u8981\u8bc4\u4f30\u548c\u6539\u8fdb\u591a\u6a21\u6001LLM\u5728\u97f3\u9891\u653b\u51fb\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u91c7\u7528\u4e09\u79cd\u8bed\u97f3-\u97f3\u9891\u7ec4\u5408\u673a\u5236\uff1a1\uff09\u8bed\u97f3\u91cd\u53e0\u548c\u591a\u8bf4\u8bdd\u4eba\u5bf9\u8bdd\uff0c\u5c06\u6709\u5bb3\u63d0\u793a\u5d4c\u5165\u826f\u6027\u8bed\u97f3\u4e0b\u65b9\u6216\u65c1\u8fb9\uff1b2\uff09\u8bed\u97f3-\u97f3\u9891\u6df7\u5408\uff0c\u901a\u8fc7\u975e\u8bed\u97f3\u97f3\u9891\u6697\u793a\u4e0d\u5b89\u5168\u610f\u56fe\uff1b3\uff09\u591a\u6837\u5316\u53e3\u8bed\u6307\u4ee4\u683c\u5f0f\uff08\u5f00\u653e\u5f0f\u95ee\u7b54\u3001\u662f/\u5426\u95ee\u9898\uff09\u89c4\u907f\u7eaf\u6587\u672c\u8fc7\u6ee4\u5668\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u5373\u4f7f\u662f\u5f53\u524d\u6700\u5148\u8fdb\u7684\u4e13\u6709LLM Gemini 2.5 Pro\uff0c\u5728SACRED-Bench\u6d4b\u8bd5\u96c6\u4e0a\u4ecd\u8868\u73b0\u51fa66%\u7684\u653b\u51fb\u6210\u529f\u7387\uff0c\u66b4\u9732\u4e86\u5728\u8de8\u6a21\u6001\u8bed\u97f3-\u97f3\u9891\u7ec4\u5408\u653b\u51fb\u4e0b\u7684\u8106\u5f31\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u5f3a\u8c03\u4e86\u4e3a\u591a\u6a21\u6001LLM\u5b89\u5168\u5f00\u53d1\u97f3\u9891\u611f\u77e5\u9632\u5fa1\u7684\u5fc5\u8981\u6027\uff0c\u63d0\u51fa\u7684SALMONN-Guard\u9632\u62a4\u6a21\u578b\u80fd\u6709\u6548\u964d\u4f4e\u653b\u51fb\u6210\u529f\u7387\uff0c\u9700\u8981\u52a0\u5f3a\u97f3\u9891\u8f93\u5165\u7684\u5b89\u5168\u9632\u62a4\u673a\u5236\u3002"}}
{"id": "2511.10006", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10006", "abs": "https://arxiv.org/abs/2511.10006", "authors": ["Qiaoyan Peng", "Qingqing Wu", "Guangji Chen", "Wen Chen", "Shaodan Ma", "Shanpu Shen", "Rui Zhang"], "title": "Rotatable IRS Aided Wireless Communication", "comment": null, "summary": "Rotatable intelligent reflecting surface (IRS) introduces a new spatial degree of freedom (DoF) by dynamically adjusting orientations without the need of changing its elements' positions in real time. To unleash the full potential of rotatable IRSs for wireless communications, this paper investigates the joint optimization of IRS rotation angles to maximize the minimum expected signal-to-noise ratio (SNR) over all locations within a given target area. We first propose an angle-dependent channel model that accurately characterizes the reception and reflection of each IRS element. Different from the conventional cosine-law assumption, the proposed model captures the practical electromagnetic characteristics of the IRS, including the effective reception area and reflection efficiency. For the single target location case, a particle swarm optimization (PSO)-based algorithm is developed to solve the SNR maximization problem, and a closed-form expression for a near-optimal solution is derived to provide useful insights. For the general area coverage enhancement case, the optimal rotation is obtained through a two-loop PSO-based iterative algorithm with null-point detection. In this algorithm, the outer loop updates the global rotation angles to maximize the minimum SNR over the target area, whereas the inner loop evaluates the SNR distribution within the area to identify the location corresponding to the minimum SNR through null-point detection. Numerical results demonstrate significant SNR improvement achieved by the proposed rotatable IRS design over various benchmark schemes under different system setups.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u53ef\u65cb\u8f6c\u667a\u80fd\u53cd\u5c04\u9762(IRS)\u7684\u8054\u5408\u4f18\u5316\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574IRS\u7684\u65cb\u8f6c\u89d2\u5ea6\u6765\u6700\u5927\u5316\u76ee\u6807\u533a\u57df\u5185\u6240\u6709\u4f4d\u7f6e\u7684\u6700\u5c0f\u671f\u671b\u4fe1\u566a\u6bd4(SNR)\u3002", "motivation": "\u53ef\u65cb\u8f6cIRS\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u65b9\u5411\u5f15\u5165\u65b0\u7684\u7a7a\u95f4\u81ea\u7531\u5ea6\uff0c\u65e0\u9700\u5b9e\u65f6\u6539\u53d8\u5143\u4ef6\u4f4d\u7f6e\u3002\u4e3a\u4e86\u5145\u5206\u53d1\u6325\u53ef\u65cb\u8f6cIRS\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\u7684\u6f5c\u529b\uff0c\u9700\u8981\u4f18\u5316\u5176\u65cb\u8f6c\u89d2\u5ea6\u4ee5\u589e\u5f3a\u533a\u57df\u8986\u76d6\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e86\u89d2\u5ea6\u4f9d\u8d56\u7684\u4fe1\u9053\u6a21\u578b\uff0c\u51c6\u786e\u63cf\u8ff0IRS\u5143\u4ef6\u7684\u63a5\u6536\u548c\u53cd\u5c04\u7279\u6027\uff1b\u9488\u5bf9\u5355\u76ee\u6807\u4f4d\u7f6e\u60c5\u51b5\u5f00\u53d1\u4e86\u57fa\u4e8e\u7c92\u5b50\u7fa4\u4f18\u5316(PSO)\u7684\u7b97\u6cd5\uff1b\u9488\u5bf9\u533a\u57df\u8986\u76d6\u589e\u5f3a\u60c5\u51b5\uff0c\u8bbe\u8ba1\u4e86\u5177\u6709\u96f6\u70b9\u68c0\u6d4b\u7684\u4e24\u5c42PSO\u8fed\u4ee3\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u53ef\u65cb\u8f6cIRS\u8bbe\u8ba1\u5728\u4e0d\u540c\u7cfb\u7edf\u8bbe\u7f6e\u4e0b\u76f8\u6bd4\u5404\u79cd\u57fa\u51c6\u65b9\u6848\u5b9e\u73b0\u4e86\u663e\u8457\u7684SNR\u63d0\u5347\u3002", "conclusion": "\u53ef\u65cb\u8f6cIRS\u901a\u8fc7\u4f18\u5316\u65cb\u8f6c\u89d2\u5ea6\u80fd\u591f\u6709\u6548\u589e\u5f3a\u65e0\u7ebf\u901a\u4fe1\u7684\u533a\u57df\u8986\u76d6\u6027\u80fd\uff0c\u6240\u63d0\u51fa\u7684\u7b97\u6cd5\u548c\u6a21\u578b\u4e3a\u5b9e\u9645\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u7528\u6307\u5bfc\u3002"}}
{"id": "2511.10073", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10073", "abs": "https://arxiv.org/abs/2511.10073", "authors": ["Yuhao Ren", "Yiting Liu", "Yanfei Zhou", "Zhiyu Zheng", "Li Shang", "Fan Yang", "Zhiang Wang"], "title": "Bridging the Initialization Gap: A Co-Optimization Framework for Mixed-Size Global Placement", "comment": null, "summary": "Global placement is a critical step with high computational complexity in VLSI physical design. Modern analytical placers formulate the placement problem as a nonlinear optimization, where initialization strongly affects both convergence behavior and final placement quality. However, existing initialization methods exhibit a trade-off: area-aware initializers account for cell areas but are computationally expensive and can dominate total runtime, while fast point-based initializers ignore cell area, leading to a modeling gap that impairs convergence and solution quality. We propose a lightweight co-optimization framework that bridges this initialization gap through two strategies. First, an area-hint refinement initializer incorporates heuristic cell area information into a signed graph signal by augmenting the netlist graph with virtual nodes and negative-weight edges, yielding an area-aware and spectrally smooth placement initialization. Second, a macro-schedule placement procedure progressively restores area constraints, enabling a smooth transition from the refined initializer to the full area-aware objective and producing high-quality placement results. We evaluate the framework on macro-heavy ISPD2005 academic benchmarks and two real-world industrial designs across two technology nodes (12 cases in total). Experimental results show that our method consistently improves half-perimeter wirelength (HPWL) over point-based initializers in 11 out of 12 cases, achieving up to 2.2% HPWL reduction, while running approximately 100 times faster than the state-of-the-art area-aware initializer.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u7ea7\u534f\u540c\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u533a\u57df\u63d0\u793a\u7cbe\u5316\u521d\u59cb\u5316\u5668\u548c\u5b8f\u8c03\u5ea6\u5e03\u5c40\u7a0b\u5e8f\uff0c\u89e3\u51b3VLSI\u5168\u5c40\u5e03\u5c40\u4e2d\u521d\u59cb\u5316\u65b9\u6cd5\u5728\u8ba1\u7b97\u6548\u7387\u548c\u5e03\u5c40\u8d28\u91cf\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u521d\u59cb\u5316\u65b9\u6cd5\u5b58\u5728\u6743\u8861\uff1a\u533a\u57df\u611f\u77e5\u521d\u59cb\u5316\u5668\u8ba1\u7b97\u6602\u8d35\uff0c\u800c\u5feb\u901f\u70b9\u57fa\u521d\u59cb\u5316\u5668\u5ffd\u7565\u5355\u5143\u9762\u79ef\uff0c\u5bfc\u81f4\u5efa\u6a21\u5dee\u8ddd\u5f71\u54cd\u6536\u655b\u548c\u89e3\u51b3\u65b9\u6848\u8d28\u91cf\u3002", "method": "1. \u533a\u57df\u63d0\u793a\u7cbe\u5316\u521d\u59cb\u5316\u5668\uff1a\u901a\u8fc7\u865a\u62df\u8282\u70b9\u548c\u8d1f\u6743\u91cd\u8fb9\u5c06\u542f\u53d1\u5f0f\u5355\u5143\u9762\u79ef\u4fe1\u606f\u6574\u5408\u5230\u6709\u7b26\u53f7\u56fe\u4fe1\u53f7\u4e2d\uff1b2. \u5b8f\u8c03\u5ea6\u5e03\u5c40\u7a0b\u5e8f\uff1a\u9010\u6b65\u6062\u590d\u533a\u57df\u7ea6\u675f\uff0c\u5b9e\u73b0\u4ece\u7cbe\u5316\u521d\u59cb\u5316\u5668\u5230\u5b8c\u6574\u533a\u57df\u611f\u77e5\u76ee\u6807\u7684\u5e73\u6ed1\u8fc7\u6e21\u3002", "result": "\u572812\u4e2a\u6d4b\u8bd5\u6848\u4f8b\u4e2d\uff0c11\u4e2a\u6848\u4f8b\u7684HPWL\u76f8\u6bd4\u70b9\u57fa\u521d\u59cb\u5316\u5668\u6709\u6240\u6539\u5584\uff0c\u6700\u9ad8\u51cf\u5c112.2%\uff0c\u540c\u65f6\u8fd0\u884c\u901f\u5ea6\u6bd4\u6700\u5148\u8fdb\u7684\u533a\u57df\u611f\u77e5\u521d\u59cb\u5316\u5668\u5feb\u7ea6100\u500d\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5f25\u5408\u4e86\u521d\u59cb\u5316\u5dee\u8ddd\uff0c\u5728\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u5e03\u5c40\u8d28\u91cf\u3002"}}
{"id": "2511.10178", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10178", "abs": "https://arxiv.org/abs/2511.10178", "authors": ["Chandrima Thakur", "Priyanka Ghosh", "Rashmita Badhai", "Sumit Kundu"], "title": "NOMA-Enabled Dual-IRS Relay Network Integrated with Ambient Backscatter Communication", "comment": null, "summary": "This paper analyzes a NOMA-enabled dual-Intelligent Reflecting Surface (IRS) relay network integrated with Ambient Backscatter (BS) communication. The system comprises a source, an energy-constrained relay with energy harvesting (EH) and BS capabilities, two NOMA users, and a BS node. The relay adopts a time-switching relaying (TSR) protocol to harvest energy and forward information ,while simultaneously enabling BS-based communication. Two IRS are deployed to enhance the S to R and R to (D1, D2) links under blockage conditions. Closed-form expressions for the Outage Probability (OP) and Throughput of both the main communication links and the BS-assisted secondary links are derived. Furthermore, throughput is analyzed under varying system parameters, including power allocation factors, reflection efficiency, IRS elements, and transmission rate. Monte Carlo simulations validate the analytical results. numerical findings reveal critical trade-offs between the main and RS links. The proposed framework provides useful insights for designing reliable and energy-efficient NOMA-IRS-aided BS networks for future IoT applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408NOMA\u3001\u53cc\u667a\u80fd\u53cd\u5c04\u8868\u9762(IRS)\u548c\u4e2d\u7ee7\u7684Ambient Backscatter\u901a\u4fe1\u7f51\u7edc\u6846\u67b6\uff0c\u901a\u8fc7\u80fd\u91cf\u6536\u96c6\u548c\u65f6\u95f4\u5207\u6362\u4e2d\u7ee7\u534f\u8bae\u5b9e\u73b0\u80fd\u91cf\u53d7\u9650\u4e2d\u7ee7\u7684\u901a\u4fe1\uff0c\u5e76\u5206\u6790\u4e86\u7cfb\u7edf\u6027\u80fd\u53c2\u6570\u3002", "motivation": "\u4e3a\u4e86\u89e3\u51b3\u672a\u6765\u7269\u8054\u7f51\u5e94\u7528\u4e2d\u80fd\u91cf\u53d7\u9650\u8bbe\u5907\u7684\u53ef\u9760\u901a\u4fe1\u95ee\u9898\uff0c\u540c\u65f6\u5229\u7528\u73af\u5883\u53cd\u5411\u6563\u5c04\u901a\u4fe1\u6280\u672f\u63d0\u9ad8\u9891\u8c31\u548c\u80fd\u91cf\u6548\u7387\uff0c\u9700\u8981\u8bbe\u8ba1\u4e00\u79cd\u7ed3\u5408NOMA\u3001IRS\u548c\u4e2d\u7ee7\u7684\u9ad8\u6548\u901a\u4fe1\u6846\u67b6\u3002", "method": "\u91c7\u7528\u53ccIRS\u589e\u5f3a\u94fe\u8def\u8d28\u91cf\uff0c\u4e2d\u7ee7\u4f7f\u7528\u65f6\u95f4\u5207\u6362\u534f\u8bae\u8fdb\u884c\u80fd\u91cf\u6536\u96c6\u548c\u4fe1\u606f\u8f6c\u53d1\uff0c\u540c\u65f6\u652f\u6301\u53cd\u5411\u6563\u5c04\u901a\u4fe1\uff0c\u63a8\u5bfc\u4e86\u4e2d\u65ad\u6982\u7387\u548c\u541e\u5410\u91cf\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u4eff\u771f\u9a8c\u8bc1\u5206\u6790\u7ed3\u679c\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\u4e3b\u901a\u4fe1\u94fe\u8def\u548c\u53cd\u5411\u6563\u5c04\u8f85\u52a9\u94fe\u8def\u4e4b\u95f4\u5b58\u5728\u5173\u952e\u6743\u8861\u5173\u7cfb\uff0c\u7cfb\u7edf\u6027\u80fd\u53d7\u529f\u7387\u5206\u914d\u56e0\u5b50\u3001\u53cd\u5c04\u6548\u7387\u3001IRS\u5143\u7d20\u6570\u91cf\u548c\u4f20\u8f93\u901f\u7387\u7b49\u53c2\u6570\u5f71\u54cd\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u8bbe\u8ba1\u53ef\u9760\u4e14\u80fd\u91cf\u9ad8\u6548\u7684NOMA-IRS\u8f85\u52a9\u53cd\u5411\u6563\u5c04\u7f51\u7edc\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u9002\u7528\u4e8e\u672a\u6765\u7269\u8054\u7f51\u5e94\u7528\u3002"}}
{"id": "2511.10205", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10205", "abs": "https://arxiv.org/abs/2511.10205", "authors": ["Martin J. W. Schubert"], "title": "High Order Delta-Sigma Modulation with Positive Integer Coefficients", "comment": "4 pages, 11 figures. This paper was rejected by the 2025 IEEE SiPS Workshop, mainly because the idea was not sufficiently developed, e.g. regarding stability limits. Presumably for this reason, the German Federal Office for Economic Affairs and Export Control that monitors issues of signal processing, has approved the publication", "summary": "This document proposes binomial integer parameters for the cascaded Delta-Sigma-modulator structure with distributed feedback and distributed feedforward input and multi-bit output. It is demonstrated that high orders can be achieved with these coefficients. Accuracy requirements concerning the coefficients are discussed.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u7528\u4e8e\u7ea7\u8054Delta-Sigma\u8c03\u5236\u5668\u7ed3\u6784\u7684\u4e8c\u9879\u5f0f\u6574\u6570\u53c2\u6570\uff0c\u8be5\u7ed3\u6784\u5177\u6709\u5206\u5e03\u5f0f\u53cd\u9988\u548c\u524d\u9988\u8f93\u5165\u4ee5\u53ca\u591a\u6bd4\u7279\u8f93\u51fa\u3002", "motivation": "\u5b9e\u73b0\u9ad8\u9636Delta-Sigma\u8c03\u5236\u5668\u7ed3\u6784\uff0c\u540c\u65f6\u4f7f\u7528\u6574\u6570\u53c2\u6570\u7b80\u5316\u5b9e\u73b0\u590d\u6742\u5ea6\u3002", "method": "\u91c7\u7528\u7ea7\u8054Delta-Sigma\u8c03\u5236\u5668\u7ed3\u6784\uff0c\u7ed3\u5408\u5206\u5e03\u5f0f\u53cd\u9988\u548c\u524d\u9988\u8f93\u5165\uff0c\u4f7f\u7528\u4e8c\u9879\u5f0f\u6574\u6570\u4f5c\u4e3a\u7cfb\u6570\uff0c\u5b9e\u73b0\u591a\u6bd4\u7279\u8f93\u51fa\u3002", "result": "\u8bc1\u660e\u4e86\u4f7f\u7528\u8fd9\u4e9b\u7cfb\u6570\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u9636\u8c03\u5236\u5668\uff0c\u5e76\u8ba8\u8bba\u4e86\u7cfb\u6570\u7684\u7cbe\u5ea6\u8981\u6c42\u3002", "conclusion": "\u4e8c\u9879\u5f0f\u6574\u6570\u53c2\u6570\u4e3a\u7ea7\u8054Delta-Sigma\u8c03\u5236\u5668\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u5b9e\u73b0\u65b9\u6cd5\uff0c\u80fd\u591f\u8fbe\u5230\u9ad8\u9636\u6027\u80fd\uff0c\u540c\u65f6\u8003\u8651\u4e86\u7cfb\u6570\u7684\u7cbe\u5ea6\u7ea6\u675f\u3002"}}
{"id": "2511.10302", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10302", "abs": "https://arxiv.org/abs/2511.10302", "authors": ["Karim Nasreddine", "Christo Kurisummoottil Thomas", "Walid Saad"], "title": "Semantic Communication with Hopfield Memories", "comment": "6 pages", "summary": "Traditional joint source-channel coding employs static learned semantic representations that cannot dynamically adapt to evolving source distributions. Shared semantic memories between transmitter and receiver can potentially enable bandwidth savings by reusing previously transmitted concepts as context to reconstruct data, but require effective mechanisms to determine when current content is similar enough to stored patterns. However, existing hard quantization approaches based on variational autoencoders are limited by frequent memory updates even under small changes in data dynamics, which leads to inefficient usage of bandwidth.To address this challenge, in this paper, a memory-augmented semantic communication framework is proposed where both transmitter and receiver maintain a shared memory of semantic concepts using modern Hopfield networks (MHNs). The proposed framework employs soft attention-based retrieval that smoothly adjusts stored semantic prototype weights as data evolves that enables stable matching decisions under gradual data dynamics. A joint optimization of encoder, decoder, and memory retrieval\n  mechanism is performed with the objective of maximizing a reasoning capacity metric that quantifies semantic efficiency as the product of memory reuse rate and compression ratio. Theoretical analysis establishes the fundamental rate-distortion-reuse tradeoff and proves that soft retrieval reduces unnecessary transmissions compared to hard quantization under bounded semantic drift. Extensive simulations over diverse video scenarios demonstrate that the proposed MHN-based approach achieves substantial bit reductions around 14% on average and up to 70% in scenarios with gradual content changes compared to baseline.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u73b0\u4ee3Hopfield\u7f51\u7edc(MHN)\u7684\u8bb0\u5fc6\u589e\u5f3a\u8bed\u4e49\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u8f6f\u6ce8\u610f\u529b\u68c0\u7d22\u673a\u5236\u52a8\u6001\u8c03\u6574\u5b58\u50a8\u7684\u8bed\u4e49\u539f\u578b\u6743\u91cd\uff0c\u5728\u6570\u636e\u52a8\u6001\u53d8\u5316\u65f6\u5b9e\u73b0\u7a33\u5b9a\u5339\u914d\uff0c\u663e\u8457\u51cf\u5c11\u4f20\u8f93\u6bd4\u7279\u6570\u3002", "motivation": "\u4f20\u7edf\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\u4f7f\u7528\u9759\u6001\u8bed\u4e49\u8868\u793a\uff0c\u65e0\u6cd5\u9002\u5e94\u52a8\u6001\u53d8\u5316\u7684\u6e90\u5206\u5e03\u3002\u73b0\u6709\u57fa\u4e8e\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7684\u786c\u91cf\u5316\u65b9\u6cd5\u5728\u6570\u636e\u52a8\u6001\u53d8\u5316\u65f6\u9891\u7e41\u66f4\u65b0\u8bb0\u5fc6\uff0c\u5bfc\u81f4\u5e26\u5bbd\u4f7f\u7528\u6548\u7387\u4f4e\u4e0b\u3002", "method": "\u4f7f\u7528\u73b0\u4ee3Hopfield\u7f51\u7edc\u6784\u5efa\u5171\u4eab\u8bed\u4e49\u8bb0\u5fc6\uff0c\u91c7\u7528\u8f6f\u6ce8\u610f\u529b\u68c0\u7d22\u673a\u5236\u5e73\u6ed1\u8c03\u6574\u8bed\u4e49\u539f\u578b\u6743\u91cd\uff0c\u8054\u5408\u4f18\u5316\u7f16\u7801\u5668\u3001\u89e3\u7801\u5668\u548c\u8bb0\u5fc6\u68c0\u7d22\u673a\u5236\uff0c\u6700\u5927\u5316\u63a8\u7406\u80fd\u529b\u6307\u6807\u3002", "result": "\u5728\u591a\u6837\u5316\u89c6\u9891\u573a\u666f\u4e2d\uff0c\u6240\u63d0MHN\u65b9\u6cd5\u5e73\u5747\u51cf\u5c11\u7ea614%\u7684\u6bd4\u7279\u6570\uff0c\u5728\u6e10\u8fdb\u5185\u5bb9\u53d8\u5316\u573a\u666f\u4e2d\u6700\u591a\u53ef\u51cf\u5c1170%\u7684\u6bd4\u7279\u6570\u3002", "conclusion": "\u57fa\u4e8e\u73b0\u4ee3Hopfield\u7f51\u7edc\u7684\u8f6f\u68c0\u7d22\u673a\u5236\u6bd4\u786c\u91cf\u5316\u65b9\u6cd5\u80fd\u66f4\u6709\u6548\u5730\u51cf\u5c11\u4e0d\u5fc5\u8981\u4f20\u8f93\uff0c\u5728\u8bed\u4e49\u6f02\u79fb\u6709\u754c\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u66f4\u597d\u7684\u7387-\u5931\u771f-\u91cd\u7528\u6743\u8861\u3002"}}
{"id": "2511.10526", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.10526", "abs": "https://arxiv.org/abs/2511.10526", "authors": ["Andrea Jung", "Paul Schwarzbach", "Oliver Michler"], "title": "Evaluation of Grid-based Uncertainty Propagation for Collaborative Self-Calibration in Indoor Positioning Systems", "comment": null, "summary": "Radio-based localization systems conventionally require stationary reference points (e.g. anchors) with precisely surveyed positions, making deployment time-consuming and costly. This paper presents an empirical evaluation of collaborative self-calibration for Ultra-Wideband (UWB) networks, extending a discrete Bayesian approach based on grid-based uncertainty propagation. The enhanced algorithm reduces measurement availability requirements while maintaining positioning accuracy through probabilistic state estimation. We validate the approach using real-world data from controlled indoor UWB network experiments with 12 nodes in a static environment. Experimental evaluation demonstrates 0.28~m mean ranging error under line-of-sight conditions and 1.11~m overall ranging error across mixed propagation scenarios, achieving sub-meter positioning accuracy. Results demonstrate the algorithm's robustness to measurement noise and partial connectivity scenarios typical in industrial deployments. The findings contribute to automated UWB network initialization for indoor positioning applications, reducing infrastructure dependency compared to manual anchor calibration procedures.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u79bb\u6563\u8d1d\u53f6\u65af\u65b9\u6cd5\u7684\u534f\u4f5c\u81ea\u6821\u51c6UWB\u7f51\u7edc\u7b97\u6cd5\uff0c\u901a\u8fc7\u6982\u7387\u72b6\u6001\u4f30\u8ba1\u5728\u51cf\u5c11\u6d4b\u91cf\u9700\u6c42\u7684\u540c\u65f6\u4fdd\u6301\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u7b97\u6cd5\u5728\u5de5\u4e1a\u90e8\u7f72\u4e2d\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u65e0\u7ebf\u7535\u7684\u5b9a\u4f4d\u7cfb\u7edf\u9700\u8981\u7cbe\u786e\u6d4b\u91cf\u4f4d\u7f6e\u7684\u56fa\u5b9a\u53c2\u8003\u70b9\uff0c\u90e8\u7f72\u8017\u65f6\u4e14\u6210\u672c\u9ad8\uff0c\u9700\u8981\u51cf\u5c11\u5bf9\u57fa\u7840\u8bbe\u65bd\u7684\u4f9d\u8d56\u5e76\u5b9e\u73b0\u81ea\u52a8\u5316\u7f51\u7edc\u521d\u59cb\u5316\u3002", "method": "\u6269\u5c55\u4e86\u57fa\u4e8e\u7f51\u683c\u4e0d\u786e\u5b9a\u6027\u4f20\u64ad\u7684\u79bb\u6563\u8d1d\u53f6\u65af\u65b9\u6cd5\uff0c\u91c7\u7528\u534f\u4f5c\u81ea\u6821\u51c6\u6280\u672f\uff0c\u901a\u8fc7\u6982\u7387\u72b6\u6001\u4f30\u8ba1\u6765\u51cf\u5c11\u6d4b\u91cf\u53ef\u7528\u6027\u8981\u6c42\u3002", "result": "\u5728\u53d7\u63a7\u5ba4\u5185UWB\u7f51\u7edc\u5b9e\u9a8c\u4e2d\uff0c\u89c6\u8ddd\u6761\u4ef6\u4e0b\u5e73\u5747\u6d4b\u8ddd\u8bef\u5dee\u4e3a0.28\u7c73\uff0c\u6df7\u5408\u4f20\u64ad\u573a\u666f\u4e0b\u603b\u4f53\u6d4b\u8ddd\u8bef\u5dee\u4e3a1.11\u7c73\uff0c\u5b9e\u73b0\u4e86\u4e9a\u7c73\u7ea7\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u57fa\u7840\u8bbe\u65bd\u4f9d\u8d56\u6027\uff0c\u4e3a\u5ba4\u5185\u5b9a\u4f4d\u5e94\u7528\u63d0\u4f9b\u4e86\u81ea\u52a8\u5316\u7684UWB\u7f51\u7edc\u521d\u59cb\u5316\u89e3\u51b3\u65b9\u6848\uff0c\u76f8\u6bd4\u624b\u52a8\u951a\u70b9\u6821\u51c6\u7a0b\u5e8f\u5177\u6709\u660e\u663e\u4f18\u52bf\u3002"}}

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 23]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SD](#cs.SD) [Total: 6]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Inverted C-Shaped Slots Loaded Exponential Tapered Triple Band Notched Ultra Wideband (UWB) Antenna](https://arxiv.org/abs/2511.11844)
*Olaoluwa A. Adegboye,Kufre M. Udofia,Akaninyene Obot*

Main category: eess.SP

TL;DR: 提出一种指数锥形三陷波超宽带天线设计策略，通过在辐射贴片上切割两个倒C形槽和在馈线上蚀刻U形槽，实现Wi-MAX、WLAN和X波段的频率抑制。


<details>
  <summary>Details</summary>
Motivation: 设计能够抑制特定频段干扰的超宽带天线，满足Wi-MAX、WLAN和X波段卫星下行链路的频率抑制需求。

Method: 采用指数锥形变换器匹配微带线馈电和辐射贴片，在辐射贴片上切割两个倒C形槽抑制Wi-MAX和WLAN频段，在馈线上蚀刻U形槽抑制X波段，并最小化交叉耦合。

Result: 天线成功抑制了3.5GHz(Wi-MAX)、5.5GHz(WLAN)和7.5GHz(X波段)三个频段，测量结果验证了设计的可靠性，满足超宽带设计要求。

Conclusion: 所提出的三陷波超宽带天线设计策略有效，能够可靠地抑制特定频段干扰，满足超宽带应用需求。

Abstract: This research presents a simple strategy for designing an exponentially tapered, triple-notched ultrawideband antenna. The antenna's microstrip line feed and radiating patch are matched using an exponential tapered transformer. This method inserts antenna notch elements, by cutting two inverted C-shaped slots in the radiating patch; frequency rejection can be achieved for WI-MAX and wireless LAN. The X-band is rejected by etching a U-shaped slot in the feedline. When embedding the notch elements, cross-coupling was minimized. The desired antenna was designed, simulated, and measured. The measured results and graphs show that our proposed design is reliable. This band notched antenna rejects 3.5 GHz (Wi-MAX band, 3.3 to 3.7 GHz), 5.5 GHz (WLAN 2 band, 5.15 to 5.825 GHz), and 7.5 GHz (for satellite downlink X - band-7.25 GHz to 7.75 GHz). The proposed antenna meets UWB design requirements.

</details>


### [2] [AI-Open-RAN for Non-Terrestrial Networks](https://arxiv.org/abs/2511.11947)
*Tri Nhu Do*

Main category: eess.SP

TL;DR: 提出AIO-RAN-NTN概念，这是一种基于开放架构和AI功能的全合一无线接入网络，用于非地面网络，通过AI驱动的KPI预测来缓解移动性影响。


<details>
  <summary>Details</summary>
Motivation: 推进下一代电信网络的互操作性、灵活性和智能化，特别是在非地面网络环境中。

Method: 基于Open-RAN和AI-RAN架构，提出集成蓝图，使用OpenAirInterface平台实现5G独立组网系统测试，并训练AI模型预测关键性能指标。

Result: 实验表明AIO-RAN架构对移动性敏感，即使在低速下也会受影响，但通过AI驱动的KPI预测可以有效缓解这一限制。

Conclusion: AIO-RAN-NTN架构为下一代非地面网络提供了可行的解决方案，AI技术能够有效应对移动性带来的挑战。

Abstract: In this paper, we propose the concept of AIO-RAN-NTN, a unified all-in-one Radio Access Network (RAN) for Non-Terrestrial Networks (NTNs), built on an open architecture that leverages open interfaces and artificial intelligence (AI)-based functionalities. This approach advances interoperability, flexibility, and intelligence in next-generation telecommunications. First, we provide a concise overview of the state-of-the-art architectures for Open-RAN and AI-RAN, highlighting key network functions and infrastructure elements. Next, we introduce our integrated AIO-RAN-NTN blueprint, emphasizing how internal and air interfaces from AIO-RAN and the 3rd Generation Partnership Project (3GPP) can be applied to emerging environments such as NTNs. To examine the impact of mobility on AIO-RAN, we implement a testbed transmission using the OpenAirInterface platform for a standalone (SA) New Radio (NR) 5G system. We then train an AI model on realistic data to forecast key performance indicators (KPIs). Our experiments demonstrate that the AIO-based SA architecture is sensitive to mobility, even at low speeds, but this limitation can be mitigated through AI-driven KPI forecasting.

</details>


### [3] [Temporal Micro-Doppler Spectrogram-based ViT Multiclass Target Classification](https://arxiv.org/abs/2511.11951)
*Nghia Thinh Nguyen,Tri Nhu Do*

Main category: eess.SP

TL;DR: 提出了一种基于Transformer的T-MDS-ViT架构，用于毫米波FMCW雷达微多普勒谱图的多类目标分类，通过跨轴注意力机制处理时空张量，在目标重叠和部分遮挡情况下保持可分离性。


<details>
  <summary>Details</summary>
Motivation: 现有基于CNN的方法在处理毫米波雷达微多普勒谱图时存在局限性，特别是在目标重叠和遮挡情况下分类性能下降，需要更有效的时空建模方法。

Method: 设计Transformer架构处理堆叠的RVA时空张量，使用补丁嵌入和跨轴注意力机制显式建模MDS数据的序列特性，并利用移动感知约束保持注意力层对应关系。

Result: 所提框架在分类精度上优于现有CNN方法，同时实现了更好的数据效率和实时部署能力。

Conclusion: T-MDS-ViT通过Transformer架构和注意力机制有效提升了毫米波雷达目标分类性能，特别是在复杂场景下具有优势。

Abstract: In this paper, we propose a new Temporal MDS-Vision Transformer (T-MDS-ViT) for multiclass target classification using millimeter-wave FMCW radar micro-Doppler spectrograms. Specifically, we design a transformer-based architecture that processes stacked range-velocity-angle (RVA) spatiotemporal tensors via patch embeddings and cross-axis attention mechanisms to explicitly model the sequential nature of MDS data across multiple frames. The T-MDS-ViT exploits mobility-aware constraints in its attention layer correspondences to maintain separability under target overlaps and partial occlusions. Next, we apply an explainable mechanism to examine how the attention layers focus on characteristic high-energy regions of the MDS representations and their effect on class-specific kinematic features. We also demonstrate that our proposed framework is superior to existing CNN-based methods in terms of classification accuracy while achieving better data efficiency and real-time deployability.

</details>


### [4] [Resource Allocation for Transmissive RIS Transceiver Enabled SWIPT Systems](https://arxiv.org/abs/2511.11980)
*Yuan Guo,Wen Chen,Xudong Bai,Chong He,Qiong Wu*

Main category: eess.SP

TL;DR: 提出了一种基于透射式可重构智能表面(TRIS)收发器的SWIPT框架，通过优化TRIS波束成形来最大化信息解码用户的和速率，同时满足能量收集用户的质量要求和每天线功率约束。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统SWIPT系统中信息传输和能量收集之间的权衡问题，利用TRIS技术实现更高效的无线信息与能量同时传输。

Method: 将原始非凸问题重构为半定规划问题，采用逐次凸逼近与基于惩罚的方法相结合的优化算法。

Result: 数值结果表明所提算法具有有效性。

Conclusion: TRIS收发器赋能的SWIPT框架能够有效提升信息解码用户的和速率，同时保证能量收集用户的质量要求。

Abstract: A novel transmissive reconfigurable intelligent surface (TRIS) transceiver-empowered simultaneous wireless information and power transfer (SWIPT) framework is proposed. The sum-rate of the information decoding (ID) users is maximized by optimizing the TRIS transceiver's beamforming, subject to the energy harvesting (EH) users' quality-of-harvest and the per-antenna power constraints. To solve this non-convex problem, we develop an efficient optimization algorithm. First, the original problem is reformulated as a semi-definite programming (SDP) problem. The resulting SDP problem is then addressed using successive convex approximation (SCA) combined with a penalty-based method. Numerical results demonstrate the effectiveness of the algorithm.

</details>


### [5] [Beamforming for Transmissive RIS Transmitter Enabled Simultaneous Wireless Information and Power Transfer Systems](https://arxiv.org/abs/2511.11985)
*Yuan Guo,Wen Chen,Yanze Zhu,Zhendong Li,Qiong Wu,Kunlun Wang*

Main category: eess.SP

TL;DR: 本文研究了基于透射式可重构智能表面(TRIS)收发器的无线信息和能量同时传输(SWIPT)系统，提出了在满足能量收集用户需求和天线功率约束下最大化信息解码用户总速率的优化算法。


<details>
  <summary>Details</summary>
Motivation: 传统SWIPT系统面临信息传输和能量收集之间的权衡挑战，TRIS技术能够灵活调控电磁波，为提升SWIPT系统性能提供了新途径。

Method: 采用加权最小均方误差(WMMSE)框架和主优化-最小化(MM)方法，提出基于二阶锥规划(SOCP)的算法，并应用交替方向乘子法(ADMM)处理天线功率约束问题。

Result: 数值结果表明所提算法具有良好的收敛性和有效性，低复杂度算法在保持性能的同时显著降低了计算复杂度。

Conclusion: 提出的TRIS收发器赋能SWIPT系统能够有效提升信息传输速率，同时满足能量收集需求，为未来无线通信系统提供了有前景的解决方案。

Abstract: This paper investigates a novel transmissive reconfigurable intelligent surface (TRIS) transceiver-empowered simultaneous wireless information and power transfer (SWIPT) system with multiple information decoding (ID) and energy harvesting (EH) users. Under the considered system model, we formulate an optimization problem that maximizes the sum-rate of all ID users via the design of the TRIS transceiver's active beamforming. The design is constrained by per-antenna power limits at the TRIS transceiver and by the minimum harvested energy demand of all EH users. Due to the non-convexity of the objective function and the energy harvesting constraint, the sum-rate problem is difficult to tackle. To solve this challenging optimization problem, by leveraging the weighted minimum mean squared error (WMMSE) framework and the majorization-minimization (MM) method, we propose a second-order cone programming (SOCP)-based algorithm. Per-element power constraints introduce a large number of constraints, making the problem considerably more difficult. By applying the alternating direction method of multipliers (ADMM) method, we successfully develop an analytical, computationally efficient, and highly parallelizable algorithm to address this challenge. Numerical results are provided to validate the convergence and effectiveness of the proposed algorithms. Furthermore, the low-complexity algorithm significantly reduces computational complexity without performance degradation.

</details>


### [6] [MUSTEM: A Dual-Modality System for Vibrotactile and Visual Translation of Music as an Assistive Technology](https://arxiv.org/abs/2511.12045)
*Paloma Sette,Maria Werneck,William Barbosa,Ana Loubacker*

Main category: eess.SP

TL;DR: MUSTEM系统将音乐转化为多感官体验，通过振动触觉和视觉界面让听障人士感受音乐的结构和情感


<details>
  <summary>Details</summary>
Motivation: 解决听障群体在音乐情感和结构体验方面的可访问性挑战，提供科学基础的多感官音乐体验

Method: 双模态方法：低成本便携硬件原型（实时音频分析+四通道振动触觉系统）+高保真软件模拟（视觉翻译辅助仪表板）

Result: 初步用户反馈显示空间振动触觉映射可感知且引人入胜，系统提供了结构化和情感共鸣的视觉触觉语言

Conclusion: MUSTEM为听障社区提供了可行的音乐体验途径，不仅是振动，更是结构化和情感共鸣的多感官体验

Abstract: The emotional and structural experience of music remains a significant accessibility challenge for the deaf and hard of hearing community. This paper introduces MUSTEM (Multisensorial Emotional Translation), a novel system designed to translate music into a rich, coherent, and scientifically-grounded sensory experience. We present a dual-modality approach addressing this challenge through two interconnected components. First, a low-cost, portable hardware prototype that performs real-time audio analysis, mapping distinct frequency bands (sub-bass, bass, mid-range, treble) to a four-channel vibrotactile system, allowing users to feel the music's rhythmic and foundational structure. Second, to overcome the processing limitations of embedded hardware, we developed a high-fidelity software simulation that demonstrates the full potential of the visual translation. This assistive dashboard decodes musical components - such as rhythm, harmony, and frequency spectrum - into an intuitive and educational visual interface. MUSTEM offers a comprehensive framework for sensory substitution, presenting a viable and accessible pathway for the deaf community to experience music not just as vibration, but as a structured, substantiated and emotionally resonant visual and tactile language. Preliminary feedback from seven deaf users suggests the system's spatial vibrotactile mapping is perceptible and engaging. All source code and hardware designs are released as open-source. Video demonstrations and open-source code are available on the project's official channel.

</details>


### [7] [Near-Real-Time InSAR Phase Estimation for Large-Scale Surface Displacement Monitoring](https://arxiv.org/abs/2511.12051)
*Scott Staniewicz,Sara Mirzaee,Heresh Fattahi,Talib Oliver-Cabrera,Emre Havazli,Geoffrey Gunter,Se-Yeon Jeon,Mary Grace Bato,Jinwoo Kim,Simran S. Sangha,Bruce Chapman,Alexander L. Handwerger,Marin Govorcin,Piyush Agram,David Bekaert*

Main category: eess.SP

TL;DR: 提出了一种用于近实时InSAR监测的序列相位连接方法，能够在数小时内处理新获取的数据，无需重新处理历史档案。


<details>
  <summary>Details</summary>
Motivation: 实现地球表面形变的近实时监测需要能够高效整合新获取数据的处理算法，避免重新处理历史数据。

Method: 使用压缩单视复图像，采用小堆栈参考方案保持相位一致性，引入在线方法识别持久和分布式散射体，结合多种像素质量指标和L1范数网络反演。

Result: 成功生成了北美大陆尺度的表面位移产品，与GPS测量结果在毫米级别一致，成功检测到基拉韦厄火山喷发期间米级位移和三姐妹火山的细微抬升。

Conclusion: 该方法为在云环境中处理大型InSAR数据集提供了重要进展，所有软件已作为开源库提供。

Abstract: Operational near-real-time monitoring of Earth's surface deformation using Interferometric Synthetic Aperture Radar (InSAR) requires processing algorithms that efficiently incorporate new acquisitions without reprocessing historical archives. We present sequential phase linking approach using compressed single-look-complex images (SLCs) capable of producing surface displacement estimates within hours of the time of a new acquisition. Our key algorithmic contribution is a mini-stack reference scheme that maintains phase consistency across processing batches without adjusting or re-estimating previous time steps, enabling straightforward operational deployment. We introduce online methods for persistent and distributed scatterer identification that adapt to temporal changes in surface properties through incremental amplitude statistics updates. The processing chain incorporates multiple complementary metrics for pixel quality that are reliable for small SLC stack sizes, and an L1-norm network inversion to limit propagation of unwrapping errors across the time series. We use our algorithm to produce OPERA Surface Displacement from Sentinel-1 product, the first continental-scale surface displacement product over North America. Validation against GPS measurements and InSAR residual analysis demonstrates millimeter-level agreement in velocity estimates in varying environmental conditions. We demonstrate our algorithm's capabilities with a successful recovery of meter-scale co-eruptive displacement at Kilauea volcano during the 2018 eruption, as well as detection of subtle uplift at Three Sisters volcano, Oregon- a challenging environment for C-band InSAR due to dense vegetation and seasonal snow. We have made all software available as open source libraries, providing a significant advancement to the open scientific community's ability to process large InSAR data sets in a cloud environment.

</details>


### [8] [Informed Bootstrap Augmentation Improves EEG Decoding](https://arxiv.org/abs/2511.12073)
*Woojae Jeong,Wenhui Cui,Kleanthis Avramidis,Takfarinas Medani,Shrikanth Narayanan,Richard Leahy*

Main category: eess.SP

TL;DR: 提出了一种基于可靠性的加权自助法来增强EEG数据表示，通过优先选择信息量更大的试验样本来提高解码性能。


<details>
  <summary>Details</summary>
Motivation: 传统均匀平均方法忽略了试验样本的信息量差异，可能降低表示质量，需要一种能优先考虑可靠试验的数据增强方法。

Method: 使用加权自助法，基于相对ERP差异计算权重，在概率采样和平均过程中优先选择更可靠的试验样本。

Result: 在句子评估范式中，加权自助法将解码准确率从68.35%提升至71.25%，表明强调可靠试验能增强表示质量。

Conclusion: 基于可靠性的数据增强方法能产生更鲁棒和更具区分度的EEG表示，代码已公开。

Abstract: Electroencephalography (EEG) offers detailed access to neural dynamics but remains constrained by noise and trial-by-trial variability, limiting decoding performance in data-restricted or complex paradigms. Data augmentation is often employed to enhance feature representations, yet conventional uniform averaging overlooks differences in trial informativeness and can degrade representational quality. We introduce a weighted bootstrapping approach that prioritizes more reliable trials to generate higher-quality augmented samples. In a Sentence Evaluation paradigm, weights were computed from relative ERP differences and applied during probabilistic sampling and averaging. Across conditions, weighted bootstrapping improved decoding accuracy relative to unweighted (from 68.35% to 71.25% at best), demonstrating that emphasizing reliable trials strengthens representational quality. The results demonstrate that reliability-based augmentation yields more robust and discriminative EEG representations. The code is publicly available at https://github.com/lyricists/NeuroBootstrap.

</details>


### [9] [Bayesian Learning Aided Simultaneous Sparse Estimation of Dual-Wideband THz Channels in Multi-User Hybrid MIMO Systems](https://arxiv.org/abs/2511.12102)
*Abhisha Garg,Akash Kumar,Suraj Srivastava,Nimish Yadav,Aditya K. Jagannatham,Lajos Hanzo*

Main category: eess.SP

TL;DR: 提出贝叶斯群稀疏回归方法用于太赫兹混合MIMO系统中的双宽带信道估计，结合低分辨率ADC和贝叶斯克拉美罗界分析。


<details>
  <summary>Details</summary>
Motivation: 太赫兹大规模MIMO系统需要解决高采样率和大天线数量带来的功耗和硬件复杂度问题，同时需要准确估计空间和频率双宽带信道。

Method: 开发实用的双宽带太赫兹信道模型，采用低分辨率ADC，使用Bussgang分解线性化量化模型，提出贝叶斯群稀疏回归框架进行信道学习。

Result: 通过广泛仿真验证，所提出的BGSR方法在归一化均方误差和误码率方面相比其他稀疏估计技术有显著性能提升。

Conclusion: BGSR方法能有效解决太赫兹大规模MIMO系统中的双宽带信道估计问题，为低功耗高精度系统设计提供了可行方案。

Abstract: This work conceives the Bayesian Group-Sparse Regression (BGSR) for the estimation of a spatial and frequency wideband, i.e., a dual wideband channel in Multi-User (MU) THz hybrid MIMO scenarios. We develop a practical dual wideband THz channel model that incorporates absorption losses, reflection losses, diffused ray modeling and angles of arrival/departure (AoAs/AoDs) using a Gaussian Mixture Model (GMM). Furthermore, a low-resolution analog-to-digital converter (ADC) is employed at each RF chain, which is crucial for wideband THz massive MIMO systems to reduce power consumption and hardware complexity, given the high sampling rates and large number of antennas involved. The quantized MU THz MIMO model is linearized using the popular Bussgang decomposition followed by BGSR based channel learning framework that results in sparsity across different subcarriers, where each subcarrier has its unique dictionary matrix. Next, the Bayesian Cramér Rao Bound (BCRB) is devised for bounding the normalized mean square error (NMSE) performance. Extensive simulations were performed to assess the performance improvements achieved by the proposed BGSR method compared to other sparse estimation techniques. The metrics considered for quantifying the performance improvements include the NMSE and bit error rate (BER).

</details>


### [10] [A 24-GHz CMOS Transformer-Based Three-Tline Series Doherty Power Amplifier Achieving 39% PAE](https://arxiv.org/abs/2511.12137)
*Zheng Wang,Yifu Li,Yuchao Mei,Xinyu Sui,Qingbin Li,Xu Luo,Rui Wang,Dongxin Ni,Jian Pang*

Main category: eess.SP

TL;DR: 基于变压器的三传输线级联Doherty功率放大器，在65nm CMOS工艺中实现，针对K/Ka波段宽带应用，通过阻抗缩放网络实现有效负载调制和降低阻抗变换比。


<details>
  <summary>Details</summary>
Motivation: 针对下一代无线系统中毫米波相控阵发射机的高效率需求，开发宽带K/Ka波段Doherty功率放大器。

Method: 在输出匹配结构中集成阻抗缩放网络，采用堆叠共源共栅晶体管，实现有效负载调制和降低功率回退时的阻抗变换比。

Result: -3dB小信号增益带宽22-32.5GHz，饱和输出功率21.6dBm，峰值功率附加效率39%，6dB回退时效率仍高于24%。

Conclusion: 该设计验证了其在下一代无线系统中毫米波相控阵发射机的高效率适用性。

Abstract: This paper presents a transformer-based three- transmission-line (Tline) series Doherty power amplifier (PA) implemented in 65-nm CMOS, targeting broadband K/Ka-band applications. By integrating an impedance-scaling network into the output matching structure, the design enables effective load modulation and reduced impedance transformation ratio (ITR) at power back-off when employing stacked cascode transistors. The PA demonstrates a -3-dB small-signal gain bandwidth from 22 to 32.5 GHz, a saturated output power (Psat) of 21.6 dBm, and a peak power-added efficiency (PAE) of 39%. At 6dB back-off, the PAE remains above 24%, validating its suitability for high- efficiency mm-wave phased-array transmitters in next-generation wireless systems.

</details>


### [11] [A Linear Implementation of an Analog Resonate-and-Fire Neuron](https://arxiv.org/abs/2511.12297)
*Angqi Liu,Filippo Moro,Sebastian Billaudelle,Melika Payvand*

Main category: eess.SP

TL;DR: 提出了一种基于22nm FD-SOI技术的共振-发放神经元，该神经元与状态空间模型原理一致，同时保持了基于脉冲通信的效率，在关键词检测任务中表现出良好的性能和能效。


<details>
  <summary>Details</summary>
Motivation: 振荡动力学在机器学习中很有效，特别是通过状态空间模型进行长程时间处理。共振-发放神经元在脉冲框架中捕获这种振荡行为，提供强表达能力和稀疏事件通信。

Method: 在22nm全耗尽绝缘体上硅技术中构建共振-发放神经元，分析其动力学、线性度以及对工艺、电压和温度变化的鲁棒性，评估功率、性能和面积权衡。

Result: 电路的非理想性不会影响性能，在系统级模拟中用于关键词检测任务表现良好。共振-发放神经元被证明是神经形态硬件的稳健、高能效计算原语。

Conclusion: 共振-发放神经元是稳健、能量高效的计算原语，适合神经形态硬件应用。

Abstract: Oscillatory dynamics have recently proven highly effective in machine learning (ML), particularly through State-Space-Models (SSM) that leverage structured linear recurrences for long-range temporal processing. Resonate-and-Fire neurons capture such oscillatory behavior in a spiking framework, offering strong expressivity with sparse event-based communication. While early analog RAF circuits employed nonlinear coupling and suffered from process sensitivity, modern ML practice favors linear recurrence. In this work, we introduce a resonate-and-fire (RAF) neuron, built in 22nm Fully-Depleted Silicon-on-Insulator technology, that aligns with SSM principles while retaining the efficiency of spike-based communication. We analyze its dynamics, linearity, and resilience to Process, Voltage, and Temperature variations, and evaluate its power, performance, and area trade-offs. We map the characteristics of our circuit into a system-level simulation where our RAF neuron is utilized in a keyword-spotting task, showing that its non-idealities do not hinder performance. Our results establish RAF neurons as robust, energy-efficient computational primitives for neuromorphic hardware.

</details>


### [12] [ISAC with Affine Frequency Division Multiplexing: An FMCW-Based Signal Processing Perspective](https://arxiv.org/abs/2511.12308)
*Jiajun Zhu,Yanqun Tang,Cong Yi,Haoran Yin,Yuanhan Ni,Fan Liu,Zhiqiang Wei,Huseyin Arslan*

Main category: eess.SP

TL;DR: 本文从雷达波形角度研究了AFDM在高移动性ISAC中的感知潜力，提出了参数选择准则将AFDM子载波与FMCW等价，开发了DD-DAFT域输入输出模型，并设计了两种匹配滤波感知算法。


<details>
  <summary>Details</summary>
Motivation: 研究AFDM在高速移动集成感知与通信中的感知能力，探索其作为雷达波形的潜力，解决传统方法在高速移动场景下的性能限制。

Method: 提出参数选择准则建立AFDM子载波与FMCW的数学等价性，开发DD-DAFT域输入输出模型揭示啁啾-信道交互产生的DD耦合效应，设计两种匹配滤波感知算法（时频域和DD-DAFT域）。

Result: 仿真显示算法实现了有效的无导频感知，在大多数场景下优于经典AFDM和其他变体，揭示了感知性能、通信开销和计算复杂度之间的基本权衡关系。

Conclusion: AFDM在高移动性ISAC中具有优秀的感知潜力，提出的方法为AFDM感知提供了清晰的物理解释和有效的实现方案。

Abstract: This paper investigates the sensing potential of affine frequency division multiplexing (AFDM) in high-mobility integrated sensing and communication (ISAC) from the perspective of radar waveforms. We introduce an innovative parameter selection criterion that establishes a precise mathematical equivalence between AFDM subcarriers and Nyquist-sampled frequency-modulated continuous-wave (FMCW). This connection not only provides a clear physical insight into AFDM's sensing mechanism but also enables a direct mapping from the DAFT index to delay-Doppler (DD) parameters of wireless channels. Building on this, we develop a novel input-output model in a DD-parameterized DAFT (DD-DAFT) domain for AFDM, which explicitly reveals the inherent DD coupling effect arising from the chirp-channel interaction. Subsequently, we design two matched-filtering sensing algorithms. The first is performed in the time-frequency domain with low complexity, while the second is operated in the DD-DAFT domain to precisely resolve the DD coupling. Simulations show that our algorithms achieve effective pilot-free sensing and demonstrate a fundamental trade-off between sensing performance, communication overhead, and computational complexity. The proposed AFDM outperforms classical AFDM and other variants in most scenarios.

</details>


### [13] [Toward ISAC-empowered subnetworks: Cooperative localization and iterative node selection](https://arxiv.org/abs/2511.12348)
*Mostafa Nozari,Israel Leyva-Mayorga,Fabio Saggese,Gilberto Berardinelli*

Main category: eess.SP

TL;DR: 提出一种低复杂度迭代节点选择算法，用于ISAC子网络中的单站目标定位，在资源受限条件下最大化定位精度，在AWGN信道中实现亚7厘米精度


<details>
  <summary>Details</summary>
Motivation: 解决集成感知与通信(ISAC)赋能子网络中感知与通信的权衡问题，特别是在单站目标定位场景下，如何在严格资源约束下优化定位性能

Method: 利用子网络部署的空间多样性，提出低复杂度迭代节点选择算法，动态优化感知子网络集合

Result: 在AWGN信道中仅需3次迭代即可实现亚7厘米定位精度，相比最佳基准方法在相同感知预算下提升超过97%；增加空间多样性（更多天线和子网络）可增强感知鲁棒性，特别是在衰落信道中

Conclusion: 量化了感知-通信权衡：减少感知迭代次数和感知子网络数量可提高吞吐量，但会降低定位精度

Abstract: This paper tackles the sensing-communication trade-off in integrated sensing and communication (ISAC)-empowered subnetworks for mono-static target localization. We propose a low-complexity iterative node selection algorithm that exploits the spatial diversity of subnetwork deployments and dynamically refines the set of sensing subnetworks to maximize localization accuracy under tight resource constraints. Simulation results show that our method achieves sub-7 cm accuracy in additive white Gaussian noise (AWGN) channels within only three iterations, yielding over 97% improvement compared to the best-performing benchmark under the same sensing budget. We further demonstrate that increasing spatial diversity through additional antennas and subnetworks enhances sensing robustness, especially in fading channels. Finally, we quantify the sensing-communication trade-off, showing that reducing sensing iterations and the number of sensing subnetworks improves throughput at the cost of reduced localization precision.

</details>


### [14] [Cross-Layer Design for Near-Field mmWave Beam Management and Scheduling under Delay-Sensitive Traffic](https://arxiv.org/abs/2511.12470)
*Zijun Wang,Anjali Omer,Jacob Chakareski,Nicholas Mastronarde,Rui Zhang*

Main category: eess.SP

TL;DR: 论文提出了一种跨层控制方法，将物理层波束管理与MAC层服务相结合，通过深度强化学习优化近场波束训练策略，在保证服务质量的同时显著降低能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络使用毫米波/太赫兹频谱和极大规模天线阵列，使系统工作在近场区域，传统远场波束管理性能下降，波束训练成本增加且需要更频繁进行。波束训练与数据传输存在能耗和时隙分配的权衡。

Method: 将问题建模为部分可观测马尔可夫决策过程，使用深度强化学习求解。控制器决策何时重新训练、训练强度（导频数量和稀疏度），同时分配发射功率，平衡导频开销、数据速率和能耗。

Result: 在真实近场信道和不同移动性、流量负载的仿真中，学习到的策略在可比能耗下优于5G-NR基准方法：吞吐量比DFT扫描提高85.5%，溢出率降低78%。

Conclusion: 该方法为开销感知、流量自适应的近场波束管理提供了实用路径，对数字孪生、空间计算和沉浸式通信等新兴低延迟、高速率应用具有重要意义。

Abstract: Next-generation wireless networks will rely on mmWave/sub-THz spectrum and extremely large antenna arrays (ELAAs). This will push their operation into the near field where far-field beam management degrades and beam training becomes more costly and must be done more frequently. Because ELAA training and data transmission consume energy and training trades off with service time, we pose a cross-layer control problem that couples PHY-layer beam management with MAC-layer service under delay-sensitive traffic. The controller decides when to retrain and how aggressively to train (pilot count and sparsity) while allocating transmit power, explicitly balancing pilot overhead, data-phase rate, and energy to reduce the queueing delay of MAC-layer frames/packets to be transmitted. We model the problem as a partially observable Markov decision process and solve it with deep reinforcement learning. In simulations with a realistic near-field channel and varying mobility and traffic load, the learned policy outperforms strong 5G-NR--style baselines at a comparable energy: it achieves 85.5% higher throughput than DFT sweeping and reduces the overflow rate by 78%. These results indicate a practical path to overhead-aware, traffic-adaptive near-field beam management with implications for emerging low-latency, high-rate next-generation applications such as digital twin, spatial computing, and immersive communication.

</details>


### [15] [Lightweight Deep Autoencoder for ECG Denoising with Morphology Preservation and Near Real-Time Hardware Deployment](https://arxiv.org/abs/2511.12478)
*Mahdi Pirayesh Shirazi Nejad,David Hicks,Matt Valentine,Ki H. Chon*

Main category: eess.SP

TL;DR: 提出了一种轻量级深度学习去噪框架，采用紧凑自编码器架构，在-5 dB强噪声条件下训练，在多种噪声配置和SNR水平下均表现稳定，能有效抑制噪声同时保持心电图形态完整性，并在树莓派4上验证了边缘设备部署可行性。


<details>
  <summary>Details</summary>
Motivation: 心电图信号常受基线漂移、运动伪影和肌电干扰等多种噪声影响，这在临床环境中构成重大挑战，需要开发能有效去噪同时保持诊断关键形态特征的解决方案。

Method: 构建轻量级深度学习去噪框架，采用紧凑自编码器架构，在-5 dB强噪声条件下训练，使用严格划分的数据集避免数据泄露，确保模型泛化能力。

Result: 在七种噪声配置和三个SNR水平（-5 dB、0 dB、+5 dB）下均表现一致的去噪性能，形态失真最小；对心室心动过速和心室颤动等关键心律测试证实能有效抑制噪声而不改变心律失常特征；树莓派4上部署显示每14秒ECG段推理延迟仅1.41秒。

Conclusion: 该研究提供了一种轻量级、硬件验证且形态可靠的ECG去噪解决方案，适合集成到便携或可穿戴医疗系统中，具有近实时边缘设备应用的可行性。

Abstract: Electrocardiogram (ECG) signals are often degraded by various noise sources such as baseline wander, motion artifacts, and electromyographic interference, posing a major challenge in clinical settings. This paper presents a lightweight deep learning-based denoising framework, forming a compact autoencoder architecture. The model was trained under severe noise conditions (-5 dB signal-to-noise ratio (SNR)) using a rigorously partitioned dataset to ensure no data leakage and robust generalization. Extensive evaluations were conducted across seven noise configurations and three SNR levels (-5 dB, 0 dB, and +5 dB), showing consistent denoising performance with minimal morphological distortion, critical for maintaining diagnostic integrity. In particular, tests on clinically vital rhythms such as ventricular tachycardia (VT) and ventricular fibrillation (VF) confirm that the proposed model effectively suppresses noise without altering arrhythmic features essential for diagnosis. Visual and quantitative assessments, including SNR improvement, RMSE, and correlation metrics, validate the model's efficacy in preserving waveform fidelity. To demonstrate real-world applicability, the model was deployed on a Raspberry Pi 4 using TensorFlow Lite with float16 precision. Inference latency was measured at just 1.41 seconds per 14-second ECG segment, indicating feasibility for near-real-time use in edge devices. Overall, this study introduces a lightweight, hardware-validated, and morphologically reliable ECG denoising solution suitable for integration into portable or wearable healthcare systems.

</details>


### [16] [Robust Radar HRRP Recognition under Non-uniform Jamming Based on Complex-valued Frequency Attention Network](https://arxiv.org/abs/2511.12508)
*Yanhao Wang,Lei Wang,Jie Wang,Yimin Liu*

Main category: eess.SP

TL;DR: 提出一种端到端训练的雷达目标识别网络，通过CFA模块在复数频谱上生成自适应滤波器，抑制强干扰频带并保留干净频带的目标信息，在严重干扰环境下比传统方法识别准确率提高近9%。


<details>
  <summary>Details</summary>
Motivation: 复杂电磁环境中多干扰源导致频谱功率不均匀，严重扭曲目标高分辨率距离像(HRRP)，影响传统HRRP目标识别方法的性能和可靠性。

Method: 开发CFA模块直接在接收回波的复数频谱上操作，学习生成自适应频域滤波器，对强干扰频带赋予较低权重，同时保留干净频带中的关键目标信息，然后将滤波后的频谱输入分类器进行识别。

Result: 在模拟HRRP数据上的实验结果表明，该方法在严重干扰条件下比传统基于模型的方法识别准确率提高近9%，且计算开销可忽略不计。

Conclusion: 该方法在挑战性干扰环境中展现出卓越的性能和鲁棒性，为解决复杂电磁环境下的雷达目标识别问题提供了有效方案。

Abstract: Complex electromagnetic environments, often containing multiple jammers with different jamming patterns, produce non-uniform jamming power across the frequency spectrum. This spectral non-uniformity directly induces severe distortion in the target's HRRP, consequently compromising the performance and reliability of conventional HRRP-based target recognition methods. This paper proposes a novel, end-to-end trained network for robust radar target recognition. The core of our model is a CFA module that operates directly on the complex spectrum of the received echo. The CFA module learns to generate an adaptive frequency-domain filter, assigning lower weights to bands corrupted by strong jamming while preserving critical target information in cleaner bands. The filtered spectrum is then fed into a classifier backbone for recognition. Experimental results on simulated HRRP data with various jamming combinations demonstrate our method's superiority. Notably, under severe jamming conditions, our model achieves a recognition accuracy nearly 9% higher than traditional model-based approaches, all while introducing negligible computational overhead. This highlights its exceptional performance and robustness in challenging jamming environments.

</details>


### [17] [A mixed-signal analogue front-end for brain-implantable neural interfaces using a digital fixed-point IIR filter and bulk offset cancellation](https://arxiv.org/abs/2511.12540)
*Dimitris Antoniadis,Timothy G. Constandinou*

Main category: eess.SP

TL;DR: 本文提出了一种用于记录细胞外动作电位和局部场电位的混合信号模拟前端，集成了低噪声放大器和SAR ADC，通过IIR滤波器抑制亚毫赫兹分量，实现了高增益、低功耗的神经信号监测。


<details>
  <summary>Details</summary>
Motivation: 随着微型植入式神经电子学的发展，需要设计能够同时记录EAPs和LFPs的高性能模拟前端，以支持治疗性脑机接口在运动障碍、癫痫等神经系统疾病中的临床应用。

Method: 采用混合信号设计，前向路径集成LNA和SAR ADC，反馈路径使用定点IIR切比雪夫II型低通滤波器，通过R-2R伪电阻DACs进行LNA输入差分对的体电压控制，抑制亚毫赫兹分量。

Result: AFE实现了41.42dB增益，每通道功耗2.178μA，面积0.198mm²，支持0.1Hz至10kHz的神经信号监测，输入参考集成噪声为3.59μVrms。

Conclusion: 该模拟前端设计成功实现了高性能的神经信号记录能力，为植入式脑机接口系统提供了有效的信号采集解决方案。

Abstract: Advances in miniaturised implantable neural electronics have paved the way for therapeutic brain-computer interfaces with clinical potential for movement disorders, epilepsy, and broader neurological applications. This paper presents a mixed-signal analogue front end (AFE) designed to record both extracellular action potentials (EAPs) and local field potentials (LFPs). The feedforward path integrates a low-noise amplifier (LNA) and a successive-approximation-register (SAR) analogue-to-digital converter (ADC), while the feedback path employs a fixed-point infinite-impulse-response (IIR) Chebyshev Type II low-pass filter to suppress sub-mHz components via bulk-voltage control of the LNA input differential pair using two R-2R pseudo-resistor digital-to-analogue converters (DACs). The proposed AFE achieves up to 41.42dB gain, consumes 2.178uA per channel, occupies 0.198mm2 per channel, and supports neural signal monitoring from 0.1Hz to 10kHz with 3.59uVrms input-referred integrated noise.

</details>


### [18] [Near Field Tapering with Slepian Window: Balancing the Range Angle Sidelobe Trade off](https://arxiv.org/abs/2511.12733)
*Ahmed Hussain,Ahmed Sultan,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil*

Main category: eess.SP

TL;DR: 提出了一种基于Slepian的幅度锥削方法，用于近场波束成形，能同时在轴向和横向维度显著降低旁瓣水平。


<details>
  <summary>Details</summary>
Motivation: 传统幅度锥削技术设计用于远场场景，无法同时抑制近场中的轴向和横向旁瓣，而旁瓣升高会增加干扰敏感性并降低检测性能。

Method: 采用Slepian基的幅度锥削方法，最大化主瓣能量集中度。

Result: 数值结果显示，与传统均匀窗口相比，所提出的锥削方法在横向域将峰值旁瓣抑制提高了约24 dB，在轴向域提高了约10 dB。

Conclusion: Slepian基幅度锥削方法能有效同时抑制近场波束成形中的轴向和横向旁瓣，显著提升检测性能。

Abstract: Near-field beamforming enables target discrimination in both range (axial) and angle (lateral) dimensions. Elevated sidelobes along either dimension, however, increase susceptibility to interference and degrade detection performance. Conventional amplitude tapering techniques, designed for far-field scenarios, cannot simultaneously suppress axial and lateral sidelobes in near-field. In this letter, we propose a Slepian-based amplitude tapering approach that maximizes mainlobe energy concentration, achieving significant sidelobe reduction in both dimensions. Numerical results show that the proposed taper improves peak sidelobe suppression by approximately 24 dB in the lateral domain and 10 dB in the axial domain compared to a conventional uniform window.

</details>


### [19] [Uniform Circular Arrays in Near-Field: Omnidirectional Coverage with Limited Capacity](https://arxiv.org/abs/2511.12750)
*Ahmed Hussain,Asmaa Abdallah,Abdulkadir Celik,Ahmed M. Eltawil*

Main category: eess.SP

TL;DR: 本文研究了均匀圆形阵列(UCA)与均匀线性阵列(ULA)在近场空间复用性能方面的比较，引入了有效波束聚焦瑞利距离(EBRD)来更准确界定有效近场区域。


<details>
  <summary>Details</summary>
Motivation: 近期研究表明UCA可以扩展辐射近场区域的角覆盖范围，本文旨在探究这种增强的角覆盖是否能转化为比ULA更好的空间复用性能。

Method: 推导了UCA的波束深度和EBRD的闭式表达式，通过理论分析和仿真比较了在固定天线数量和固定孔径长度两种约束条件下UCA和ULA的性能。

Result: 在固定天线数量条件下，ULA实现更窄的波束深度和更长的EBRD；在固定孔径长度条件下，UCA提供稍窄的波束深度和稍长的EBRD。仿真结果显示ULA在固定元素约束下获得更高和速率，而UCA在固定孔径约束下仅有边际性能增益。

Conclusion: UCA在扩展角覆盖方面的优势并不直接转化为显著的空间复用性能提升，阵列几何形状的选择应基于具体应用约束条件。

Abstract: Recent studies suggest that uniform circular arrays (UCAs) can extend the angular coverage of the radiative near field region. This work investigates whether such enhanced angular coverage translates into improved spatial multiplexing performance when compared to uniform linear arrays (ULAs). To more accurately delineate the effective near field region, we introduce the effective beamfocusing Rayleigh distance (EBRD), an angle dependent metric that bounds the spatial region where beamfocusing remains effective. Closed form expressions for both beamdepth and EBRD are derived for UCAs. Our analysis shows that, under a fixed antenna element count, ULAs achieve narrower beamdepth and a longer EBRD than UCAs. Conversely, under a fixed aperture length, UCAs provide slightly narrower beamdepth and a marginally longer EBRD. Simulation results further confirm that ULAs achieve higher sum rate under the fixed element constraint, while UCAs offer marginal performance gain under the fixed aperture constraint.

</details>


### [20] [Distributed Multisensor ISAC](https://arxiv.org/abs/2511.13104)
*Reiner Thomä,Michael Döbereiner,Reza Faramarzahangari,Jonas Gedschold. Marc Francisco Colaco Miranda,Saw James Myint,Steffen Schieler,Christian Schneider,Sebastian Semper,Carsten Smeenk,Gerd Sommerkorn,Zhixiang Zhao*

Main category: eess.SP

TL;DR: 本文提出了多传感器集成感知与通信(MS-ISAC)的基本原理和架构，将多用户MIMO通信与分布式MIMO雷达相结合，探讨了多链路接入、协调、预编码等关键技术，以及基于模型的延迟/多普勒估计和分布式数据融合问题。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)将成为未来移动通信网络的重要服务，能够利用移动网络和无线接入资源实现被动对象和环境的检测识别，构建分布式、无处不在的感知网络。

Method: 开发了MS-ISAC的基本架构原则，提出通用MS-ISAC架构，涵盖多链路接入、协调、预编码和链路自适应方案，采用基于模型的稀疏OFDMA/TDMA帧延迟/多普勒估计和跟踪，强调协作被动相干定位用于双基地相关和同步。

Result: 建立了将多用户MIMO通信与分布式MIMO雷达相结合的MS-ISAC理论框架，解决了多传感器节点同步和分布式数据融合等关键问题。

Conclusion: MS-ISAC为实现分布式、自适应的无线感知网络提供了理论基础和技术路径，能够支持多种无线感知任务和服务。

Abstract: Integrated Sensing and Communications (ISAC) will become a service in future mobile communication networks. It enables the detection and recognition of passive objects and environments using radar-like sensing. The ultimate advantage is the reuse of the mobile network and radio access resources for scene illumination, sensing, data transportation, computation, and fusion. It enables building a distributed, ubiquitous sensing network that can be adapted for a variety of radio sensing tasks and services.
  In this article, we develop the principles of multi-sensor ISAC (MS-ISAC). MS-ISAC corresponds to multi-user MIMO communication, which in radar terminology is known as distributed MIMO radar. \ First, we develop basic architectural principles for MS-ISAC and link them to example use cases. We then propose a generic MS-ISAC architecture. After a brief reference to multipath propagation and multistatic target reflectivity issues, we outline multilink access, coordination, precoding and link adaptation schemes for MS-ISAC. Moreover, we review model-based estimation and tracking of delay~/~Doppler from sparse OFDMA~/~TDMA frames. We emphasize Cooperative Passive Coherent Location (CPCL) for bistatic correlation and synchronization. Finally, issues of multisensor node synchronization and distributed data fusion are addressed.

</details>


### [21] [Autonomous Sensing UAV for Accurate Multi-User Identification and Localization in Cellular Networks](https://arxiv.org/abs/2511.13171)
*Niccolò Paglierani,Francesco Linsalata,Vineeth Teeda,Davide Scazzoli,Maurizio Magarini*

Main category: eess.SP

TL;DR: 提出了一种基于无人机的自主感知框架，利用5G网络的上行探测参考信号来识别和定位多个用户，无需与网络基础设施协调，实现了基础设施独立的感知能力。


<details>
  <summary>Details</summary>
Motivation: 传统空中服务节点需要与网络基础设施协调，而本文旨在开发一种完全被动、仅用于感知的无人机系统，支持在紧急情况或连接受限环境中的快速部署和态势感知。

Method: 开发了完整的信号处理链，包括同步、用户识别和定位，所有处理都在无人机飞行期间机载执行。系统自主规划和调整任务工作流程，将飞行控制与实时感知集成。

Result: 通过广泛仿真和全尺度低空实验验证，在农村实地测试中定位误差低于3米，在城市仿真场景中低于8米，同时可靠识别每个用户。

Conclusion: 结果证实了基础设施独立感知无人机作为新兴低空经济核心元素的可行性，支持在紧急或连接受限环境中的态势感知和快速部署。

Abstract: This paper presents an autonomous sensing frame- work for identifying and localizing multiple users in Fifth Generation (5G) networks using an Unmanned Aerial Vehicle (UAV) that is not part of the serving access network. Unlike conventional aerial serving nodes, the proposed UAV operates passively and is dedicated solely to sensing. It captures Uplink (UL) Sounding Reference Signals (SRS), and requires virtually no coordination with the network infrastructure. A complete signal processing chain is proposed and developed, encompassing synchronization, user identification, and localization, all executed onboard UAV during flight. The system autonomously plans and adapts its mission workflow to estimate multiple user positions within a single deployment, integrating flight control with real-time sensing. Extensive simulations and a full-scale low- altitude experimental campaign validate the approach, showing localization errors below 3 m in rural field tests and below 8 m in urban simulation scenarios, while reliably identifying each user. The results confirm the feasibility of infrastructure-independent sensing UAVs as a core element of the emerging Low Altitude Economy (LAE), supporting situational awareness and rapid deployment in emergency or connectivity-limited environments.

</details>


### [22] [Pinching-Antenna-Enabled Cognitive Radio Networks](https://arxiv.org/abs/2511.13272)
*Zeyang Sun,Xidong Mu,Shuai Han,Sai Xu,Michail Matthaiou*

Main category: eess.SP

TL;DR: 本文研究了基于夹持天线的认知无线电网络，通过联合优化主次用户的夹持波束成形和功率控制，实现了显著频谱效率提升和有效干扰抑制。


<details>
  <summary>Details</summary>
Motivation: 传统固定位置天线在认知无线电网络中频谱效率有限，需要开发新的天线技术来改善同时频谱共享性能。

Method: 提出三阶段优化算法：首先在波导级确定PA粗位置，然后在波长级进行精细调整实现信号建设性组合，最后推导ST功率控制的闭式解。

Result: 仿真结果表明：PA相比传统天线显著提升频谱效率；所提波束成形设计有效抑制干扰；三阶段算法使主次网络传输近乎正交。

Conclusion: 夹持天线技术结合所提优化算法能够有效提升认知无线电网络的频谱效率，实现主次用户间的有效共存。

Abstract: This paper investigates a pinching-antenna (PA)-enabled cognitive radio network, where both the primary transmitter (PT) and secondary transmitter (ST) are equipped with a single waveguide and multiple PAs to facilitate simultaneous spectrum sharing. Under a general Ricean fading channel model, a closed-form analytical expression for the average spectral efficiency (SE) achieved by PAs is first derived. Based on this, a sum-SE maximization problem is formulated to jointly optimize the primary and secondary pinching beamforming, subject to system constraints on the transmission power budgets, minimum antenna separation requirements, and feasible PA deployment regions. To address this non-convex problem, a three-stage optimization algorithm is developed to sequentially optimize both the PT and ST pinching beamforming, and the ST power control. For the PT and ST pinching beamforming optimization, the coarse positions of PA are first determined at the waveguide-level. Then, wavelength-level refinements achieve constructive signal combination at the intended user and destructive superposition at the unintended user. For the ST power control, a closed-form solution is derived. Simulation results demonstrate that i) PAs can achieve significant SE improvements over conventional fixed-position antennas; ii) the proposed pinching beamforming design achieves effective interference suppression and superior performance for both even and odd numbers of PAs; and iii) the developed three-stage optimization algorithm enables nearly orthogonal transmission between the primary and secondary networks.

</details>


### [23] [Sensing-enabled Secure Rotatable Array System Enhanced by Multi-Layer Transmitting RIS](https://arxiv.org/abs/2511.13336)
*Maolin Li,Feng Shu,Minghao Chen,Cunhua Pan,Fuhui Zhou,Yongpeng Wu,Liang Yang*

Main category: eess.SP

TL;DR: 本文研究了可旋转阵列系统的安全性，采用双基站架构协同执行窃听者感知和通信任务，提出了在线和离线算法来优化阵列姿态、天线分布和波束成形，相比传统方案实现了约22%的保密率提升。


<details>
  <summary>Details</summary>
Motivation: 可编程超表面和可调天线是前景技术，但传统方案在窃听者位于主通信链路上时存在安全挑战，需要研究如何通过阵列姿态调整来增强通信安全性。

Method: 采用双基站架构协同执行感知和通信任务，提出基于广义瑞利商的在线两阶段算法和基于多智能体深度确定性策略梯度的离线算法，联合优化阵列姿态、天线分布、RIS相位矩阵和波束成形矩阵。

Result: 仿真结果表明所提算法有效，相比无阵列姿态调整的传统方案，保密率提升约22%，且阵列旋转比位置变化提供更高的性能增益。

Conclusion: 通过阵列姿态调整可以有效提升通信系统的安全性，旋转阵列比位置调整具有更好的性能增益，所提算法为解决复杂非凸优化问题提供了有效解决方案。

Abstract: Programmable metasurfaces and adjustable antennas are promising technologies. The security of a rotatable array system is investigated in this paper. A dual-base-station (BS) architecture is adopted, in which the BSs collaboratively perform integrated sensing of the eavesdropper (the target) and communication tasks. To address the security challenge when the sensing target is located on the main communication link, the problem of maximizing the secrecy rate (SR) under sensing signal-to-interference-plus-noise ratio requirements and discrete constraints is formulated. This problem involves the joint optimization of the array pose, the antenna distribution on the array surface, the multi-layer transmitting RIS phase matrices, and the beamforming matrices, which is non-convex. To solve this challenge, an two-stage online algorithm based on the generalized Rayleigh quotient and an offline algorithm based on the Multi-Agent Deep Deterministic Policy Gradient are proposed. Simulation results validate the effectiveness of the proposed algorithms. Compared to conventional schemes without array pose adjustment, the proposed approach achieves approximately 22\% improvement in SR. Furthermore, array rotation provides higher performance gains than position changes.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [24] [How Far Do SSL Speech Models Listen for Tone? Temporal Focus of Tone Representation under Low-resource Transfer](https://arxiv.org/abs/2511.12285)
*Minu Kim,Ji Sub Um,Hoirin Kim*

Main category: eess.AS

TL;DR: 研究自监督学习语音模型在四种复杂声调语言（缅甸语、泰语、老挝语、越南语）中的声调感知能力，发现下游任务对声调转移的时域关注范围有显著影响。


<details>
  <summary>Details</summary>
Motivation: 声调在许多语言中至关重要，但在自监督学习语音模型中研究不足，特别是在普通话以外的语言中。需要探索这类模型如何感知声调以及在低资源条件下的转移机制。

Method: 首先估计了四种语言中声调线索的时间跨度基线（缅甸语和泰语约100毫秒，老挝语和越南语约180毫秒），然后通过探针和梯度分析研究了微调后的SSL模型。

Result: 声调转移因下游任务而异：自动语音识别微调使模型关注范围与语言特定的声调线索对齐，而韵律和语音相关任务则使模型偏向过长的关注跨度。

Conclusion: 下游任务塑造了声调转移过程，强调了任务效应对声调建模中时域关注的影响。

Abstract: Lexical tone is central to many languages but remains underexplored in self-supervised learning (SSL) speech models, especially beyond Mandarin. We study four languages with complex and diverse tone systems: Burmese, Thai, Lao, and Vietnamese, to examine how far such models listen for tone and how transfer operates in low-resource conditions. As a baseline reference, we estimate the temporal span of tone cues to be about 100 ms in Burmese and Thai, and about 180 ms in Lao and Vietnamese. Probes and gradient analyses on fine-tuned SSL models reveal that tone transfer varies by downstream task: automatic speech recognition fine-tuning aligns spans with language-specific tone cues, while prosody- and voice-related tasks bias the model toward overly long spans. These findings indicate that tone transfer is shaped by downstream task, highlighting task effects on temporal focus in tone modeling.

</details>


### [25] [VoiceCraft-X: Unifying Multilingual, Voice-Cloning Speech Synthesis and Speech Editing](https://arxiv.org/abs/2511.12347)
*Zhisheng Zheng,Puyuan Peng,Anuj Diwan,Cong Phuoc Huynh,Xiaohang Sun,Zhu Liu,Vimal Bhat,David Harwath*

Main category: eess.AS

TL;DR: VoiceCraft-X是一个自回归神经编解码语言模型，统一了11种语言的语音编辑和零样本文本到语音合成任务。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的框架来处理多语言语音编辑和TTS合成，克服传统方法需要单独处理不同语言和任务的限制。

Method: 使用Qwen3大语言模型进行无音素跨语言文本处理，并采用新颖的令牌重排序机制，将时间对齐的文本和语音令牌作为单一序列生成问题处理。

Result: 模型能够生成高质量、自然的声音，在一个框架内无缝创建新音频或编辑现有录音，在多样语言环境中表现出稳健性能。

Conclusion: 统一的自回归方法在推进复杂、现实世界的多语言语音应用方面具有强大潜力，即使在每种语言数据有限的情况下也能有效工作。

Abstract: We introduce VoiceCraft-X, an autoregressive neural codec language model which unifies multilingual speech editing and zero-shot Text-to-Speech (TTS) synthesis across 11 languages: English, Mandarin, Korean, Japanese, Spanish, French, German, Dutch, Italian, Portuguese, and Polish. VoiceCraft-X utilizes the Qwen3 large language model for phoneme-free cross-lingual text processing and a novel token reordering mechanism with time-aligned text and speech tokens to handle both tasks as a single sequence generation problem. The model generates high-quality, natural-sounding speech, seamlessly creating new audio or editing existing recordings within one framework. VoiceCraft-X shows robust performance in diverse linguistic settings, even with limited per-language data, underscoring the power of unified autoregressive approaches for advancing complex, real-world multilingual speech applications. Audio samples are available at https://zhishengzheng.com/voicecraft-x/.

</details>


### [26] [Eardrum sound pressure prediction from ear canal reflectance based on the inverse solution of Webster's horn equation](https://arxiv.org/abs/2511.12552)
*Reinhild Roden,Tobias Sankowsky-Rothe,Nick Wulbusch,Alexey Chernov,Matthias Blau*

Main category: eess.AS

TL;DR: 该研究改进了通过Webster喇叭方程反演计算耳道面积函数的方法，通过优化空间分辨率终止条件和调整截止频率，提高了耳道模型在个体化听力系统均衡算法中的准确性。


<details>
  <summary>Details</summary>
Motivation: 为个体化耳内听力系统均衡算法开发准确的耳道传输函数，需要建立个体化的耳道模型，这要求准确估计耳道的面积函数。

Method: 采用Webster喇叭方程的一维有限差分近似方法，通过时间域反射率反演计算耳道面积函数，优化了空间分辨率终止条件，并调整了截止频率以适应频带受限的输入阻抗。

Result: 与几何参考相比，通过将模拟输入阻抗外推至3.5MHz频率（对应0.1mm空间分辨率），获得了更精确的面积函数，并建立了稳健的耳道长度终止标准。

Conclusion: 验证了一维电声模型结合改进的面积函数计算方法，能够很好地复现三维模拟和测量的耳道传输阻抗，为个体化听力系统提供了可靠的基础。

Abstract: To derive ear canal transfer functions for individualized equalization algorithms of in-ear hearing systems, individual ear canal models are needed. In a one-dimensional approach, this requires the estimation of the individual area function of the ear canal. The area function can be effectively and reproducibly calculated as the inverse solution of Webster's horn equation by finite difference approximation of the time domain reflectance. Building upon previous research, the present study further investigates the termination of the approximation at an optimal spatial resolution, addressing the absence of higher frequencies in typical ear canal measurements and enhancing the accuracy of the inverse solution. Compared to the geometric reference, more precise area functions were achieved by extrapolating simulated input impedances of ear canal geometries up to a frequency of 3.5 MHz, corresponding to 0.1 mm spatial resolution. The low pass of the previous work was adopted but adjusted for its cut-off frequency depending on the highest frequency of the band-limited input impedance. Robust criteria for terminating the area function at the approximated ear canal length were found. Finally, three-dimensional simulated and measured ear canal transfer impedances were replicated well employing the previously introduced and herein validated one-dimensional electro-acoustic model fed by the area functions.

</details>


### [27] [PASE: Leveraging the Phonological Prior of WavLM for Low-Hallucination Generative Speech Enhancement](https://arxiv.org/abs/2511.13300)
*Xiaobin Rong,Qinwen Hu,Mansur Yesilbursa,Kamil Wojcicki,Jing Lu*

Main category: eess.AS

TL;DR: PASE是一个生成式语音增强框架，利用预训练WavLM模型的鲁棒音韵先验来减轻幻觉问题，在感知质量上超越判别式模型，同时显著降低语言和声学幻觉。


<details>
  <summary>Details</summary>
Motivation: 现有生成式语音增强方法在严重噪声下容易产生语言幻觉（错误语音内容）和声学幻觉（不一致的说话人特征），特别是语言幻觉源于模型未能约束有效的音韵结构，这是更根本的挑战。

Method: 1. 通过表示蒸馏将WavLM适配为去噪专家，清理其最终层特征；2. 使用双流表示训练声码器：高层音韵表示提供干净语言内容，低层声学表示保留说话人身份和韵律。

Result: PASE不仅在感知质量上超越了最先进的判别式模型，还显著优于先前的生成式模型，语言和声学幻觉大幅降低。

Conclusion: 通过利用预训练模型的音韵先验和双流表示策略，PASE有效解决了生成式语音增强中的幻觉问题，实现了更好的语音增强效果。

Abstract: Generative models have shown remarkable performance in speech enhancement (SE), achieving superior perceptual quality over traditional discriminative approaches. However, existing generative SE approaches often overlook the risk of hallucination under severe noise, leading to incorrect spoken content or inconsistent speaker characteristics, which we term linguistic and acoustic hallucinations, respectively. We argue that linguistic hallucination stems from models' failure to constrain valid phonological structures and it is a more fundamental challenge. While language models (LMs) are well-suited for capturing the underlying speech structure through modeling the distribution of discrete tokens, existing approaches are limited in learning from noise-corrupted representations, which can lead to contaminated priors and hallucinations. To overcome these limitations, we propose the Phonologically Anchored Speech Enhancer (PASE), a generative SE framework that leverages the robust phonological prior embedded in the pre-trained WavLM model to mitigate hallucinations. First, we adapt WavLM into a denoising expert via representation distillation to clean its final-layer features. Guided by the model's intrinsic phonological prior, this process enables robust denoising while minimizing linguistic hallucinations. To further reduce acoustic hallucinations, we train the vocoder with a dual-stream representation: the high-level phonetic representation provides clean linguistic content, while a low-level acoustic representation retains speaker identity and prosody. Experimental results demonstrate that PASE not only surpasses state-of-the-art discriminative models in perceptual quality, but also significantly outperforms prior generative models with substantially lower linguistic and acoustic hallucinations.

</details>


### [28] [Systematic evaluation of time-frequency features for binaural sound source localization](https://arxiv.org/abs/2511.13487)
*Davoud Shariat Panah,Alessandro Ragano,Dan Barry,Jan Skoglund,Andrew Hines*

Main category: eess.AS

TL;DR: 本文系统评估了双耳声源定位中的时频特征设计，发现精心选择的特征组合通常优于增加模型复杂度。ILD+IPD双特征组合足以用于域内定位，而泛化到多样化内容需要结合通道谱图、ILD和IPD的更丰富输入。


<details>
  <summary>Details</summary>
Motivation: 研究特征选择如何影响双耳声源定位模型在不同条件下的性能，探索振幅特征和相位特征的最佳组合方式。

Method: 使用卷积神经网络模型，评估不同振幅特征（幅度谱图、ILD）和相位特征（相位谱图、IPD）组合的性能，在域内和域外数据上进行测试。

Result: 精心选择的特征组合往往优于增加模型复杂度。低复杂度CNN模型使用最优特征集能达到竞争性性能。

Conclusion: 特征设计在双耳声源定位中至关重要，为特定领域和通用定位提供了实用指导。

Abstract: This study presents a systematic evaluation of time-frequency feature design for binaural sound source localization (SSL), focusing on how feature selection influences model performance across diverse conditions. We investigate the performance of a convolutional neural network (CNN) model using various combinations of amplitude-based features (magnitude spectrogram, interaural level difference - ILD) and phase-based features (phase spectrogram, interaural phase difference - IPD). Evaluations on in-domain and out-of-domain data with mismatched head-related transfer functions (HRTFs) reveal that carefully chosen feature combinations often outperform increases in model complexity. While two-feature sets such as ILD + IPD are sufficient for in-domain SSL, generalization to diverse content requires richer inputs combining channel spectrograms with both ILD and IPD. Using the optimal feature sets, our low-complexity CNN model achieves competitive performance. Our findings underscore the importance of feature design in binaural SSL and provide practical guidance for both domain-specific and general-purpose localization.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [29] [Lightweight Hopfield Neural Networks for Bioacoustic Detection and Call Monitoring of Captive Primates](https://arxiv.org/abs/2511.11615)
*Wendy Lomas,Andrew Gascoyne,Colin Dubreuil,Stefano Vaglio,Liam Naughton*

Main category: cs.SD

TL;DR: 提出一种轻量级的Hopfield神经网络模型，用于自动监测濒危黑白领狐猴的叫声，替代资源密集的卷积神经网络方法。


<details>
  <summary>Details</summary>
Motivation: 被动声学监测产生大量数据集但处理积压，现有卷积神经网络方法资源密集、需要大量预标记数据且缺乏灵活性。

Method: 使用Hopfield神经网络架构的关联记忆AI模型，存储感兴趣的狐猴社交叫声和运动信号，在大规模声学数据集中检测其他叫声实例。

Result: 模型整体准确率达到0.94，每秒可进行340次分类，每分钟处理超过5.5小时音频数据，在标准笔记本电脑上训练仅需毫秒级时间。

Conclusion: 这种轻量级解决方案显著减少了数据到洞察的周转时间，能够加速圈养和野外环境中的决策制定，具有广泛适用性。

Abstract: Passive acoustic monitoring is a sustainable method of monitoring wildlife and environments that leads to the generation of large datasets and, currently, a processing backlog. Academic research into automating this process is focused on the application of resource intensive convolutional neural networks which require large pre-labelled datasets for training and lack flexibility in application. We present a viable alternative relevant in both wild and captive settings; a transparent, lightweight and fast-to-train associative memory AI model with Hopfield neural network (HNN) architecture. Adapted from a model developed to detect bat echolocation calls, this model monitors captive endangered black-and-white ruffed lemur Varecia variegata vocalisations. Lemur social calls of interest when monitoring welfare are stored in the HNN in order to detect other call instances across the larger acoustic dataset. We make significant model improvements by storing an additional signal caused by movement and achieve an overall accuracy of 0.94. The model can perform $340$ classifications per second, processing over 5.5 hours of audio data per minute, on a standard laptop running other applications. It has broad applicability and trains in milliseconds. Our lightweight solution reduces data-to-insight turnaround times and can accelerate decision making in both captive and wild settings.

</details>


### [30] [Real-Time Speech Enhancement via a Hybrid ViT: A Dual-Input Acoustic-Image Feature Fusion](https://arxiv.org/abs/2511.11825)
*Behnaz Bahmei,Siamak Arzanpour,Elina Birmingham*

Main category: cs.SD

TL;DR: 提出基于Transformer的轻量级实时噪声抑制框架，通过双输入声学图像特征融合有效处理非平稳噪声，在嵌入式设备上实现接近干净参考的语音质量提升。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在平稳噪声中表现良好，但在真实环境中面对非平稳噪声（如狗叫、婴儿哭声）时性能下降，需要开发适用于真实环境的实时噪声抑制方案。

Method: 采用混合ViT框架的双输入声学图像特征融合方法，有效建模噪声信号中的时间和频谱依赖关系，设计轻量级架构适合嵌入式设备部署。

Result: 在Librispeech、UrbanSound8K和Google Audioset数据集上的实验表明，该方法在PESQ、STOI、Seg SNR和LLR四个标准指标上显著提升噪声抑制、语音清晰度和感知质量，性能接近干净参考信号。

Conclusion: 所提出的Transformer框架在真实噪声环境中表现出色，为嵌入式设备上的实时语音增强提供了有效解决方案。

Abstract: Speech quality and intelligibility are significantly degraded in noisy environments. This paper presents a novel transformer-based learning framework to address the single-channel noise suppression problem for real-time applications. Although existing deep learning networks have shown remarkable improvements in handling stationary noise, their performance often diminishes in real-world environments characterized by non-stationary noise (e.g., dog barking, baby crying). The proposed dual-input acoustic-image feature fusion using a hybrid ViT framework effectively models both temporal and spectral dependencies in noisy signals. Designed for real-world audio environments, the proposed framework is computationally lightweight and suitable for implementation on embedded devices. To evaluate its effectiveness, four standard and commonly used quality measurements, namely PESQ, STOI, Seg SNR, and LLR, are utilized. Experimental results obtained using the Librispeech dataset as the clean speech source and the UrbanSound8K and Google Audioset datasets as the noise sources, demonstrate that the proposed method significantly improves noise reduction, speech intelligibility, and perceptual quality compared to the noisy input signal, achieving performance close to the clean reference.

</details>


### [31] [MF-Speech: Achieving Fine-Grained and Compositional Control in Speech Generation via Factor Disentanglement](https://arxiv.org/abs/2511.12074)
*Xinyue Yu,Youqing Fang,Pingyu Wu,Guoyang Ye,Wenbo Zhou,Weiming Zhang,Song Xiao*

Main category: cs.SD

TL;DR: MF-Speech是一个解决语音生成中因素纠缠和粗粒度控制问题的框架，包含因素纯化编码器和生成器，在多因素组合语音生成任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决语音生成中两个基本挑战：语音因素的深度纠缠和现有控制机制的粗粒度问题，实现更精确、可组合的语音控制。

Method: 使用MF-SpeechEncoder进行因素纯化，通过多目标优化将语音分解为内容、音色和情感的独立表示；使用MF-SpeechGenerator通过动态融合和层次风格自适应归一化实现精细控制。

Result: 在多因素组合语音生成任务中显著优于现有方法：词错误率4.67%，风格控制指标SECS=0.5685、Corr=0.68，主观评分nMOS=3.96、sMOS_emotion=3.86、sMOS_style=3.78。

Conclusion: MF-Speech框架成功解决了语音因素纠缠问题，实现了精细粒度的语音控制，学习到的离散因素具有强迁移性，有望成为通用语音表示。

Abstract: Generating expressive and controllable human speech is one of the core goals of generative artificial intelligence, but its progress has long been constrained by two fundamental challenges: the deep entanglement of speech factors and the coarse granularity of existing control mechanisms. To overcome these challenges, we have proposed a novel framework called MF-Speech, which consists of two core components: MF-SpeechEncoder and MF-SpeechGenerator. MF-SpeechEncoder acts as a factor purifier, adopting a multi-objective optimization strategy to decompose the original speech signal into highly pure and independent representations of content, timbre, and emotion. Subsequently, MF-SpeechGenerator functions as a conductor, achieving precise, composable and fine-grained control over these factors through dynamic fusion and Hierarchical Style Adaptive Normalization (HSAN). Experiments demonstrate that in the highly challenging multi-factor compositional speech generation task, MF-Speech significantly outperforms current state-of-the-art methods, achieving a lower word error rate (WER=4.67%), superior style control (SECS=0.5685, Corr=0.68), and the highest subjective evaluation scores(nMOS=3.96, sMOS_emotion=3.86, sMOS_style=3.78). Furthermore, the learned discrete factors exhibit strong transferability, demonstrating their significant potential as a general-purpose speech representation.

</details>


### [32] [Towards Practical Real-Time Low-Latency Music Source Separation](https://arxiv.org/abs/2511.13146)
*Junyu Wu,Jie Liu,Tianrui Pan,Jie Tang,Gangshan Wu*

Main category: cs.SD

TL;DR: 提出RT-STT轻量级实时低延迟音乐分离模型，基于单路径架构和通道扩展特征融合，参数更少、推理时间更短


<details>
  <summary>Details</summary>
Motivation: 现有深度学习音乐分离方法缺乏对实时低延迟应用的关注，且模型趋向大型化限制了实际应用场景

Method: 基于DTTNet的单路径TFC-TDF UNET架构，采用通道扩展特征融合技术，并研究量化方法减少推理时间

Result: RT-STT在参数数量和推理时间方面显著优于最先进模型，同时保持优越性能

Conclusion: 单路径建模在实时模型中优于双路径建模，RT-STT为实时音乐分离应用提供了高效解决方案

Abstract: In recent years, significant progress has been made in the field of deep learning for music demixing. However, there has been limited attention on real-time, low-latency music demixing, which holds potential for various applications, such as hearing aids, audio stream remixing, and live performances. Additionally, a notable tendency has emerged towards the development of larger models, limiting their applicability in certain scenarios. In this paper, we introduce a lightweight real-time low-latency model called Real-Time Single-Path TFC-TDF UNET (RT-STT), which is based on the Dual-Path TFC-TDF UNET (DTTNet). In RT-STT, we propose a feature fusion technique based on channel expansion. We also demonstrate the superiority of single-path modeling over dual-path modeling in real-time models. Moreover, we investigate the method of quantization to further reduce inference time. RT-STT exhibits superior performance with significantly fewer parameters and shorter inference times compared to state-of-the-art models.

</details>


### [33] [FoleyBench: A Benchmark For Video-to-Audio Models](https://arxiv.org/abs/2511.13219)
*Satvik Dixit,Koichi Saito,Zhi Zhong,Yuki Mitsufuji,Chris Donahue*

Main category: cs.SD

TL;DR: 提出了FoleyBench，这是第一个专门为Foley风格视频到音频生成评估设计的大规模基准数据集，包含5000个视频-音频-文本三元组，解决了现有数据集在音频-视觉对应性和Foley声音类别覆盖方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有视频到音频生成评估数据集存在两个主要问题：74%的视频音频-视觉对应性差，且主要被语音和音乐主导，不适合Foley声音效果评估。需要专门针对Foley应用场景的基准数据集。

Method: 通过自动化、可扩展的流程从YouTube和Vimeo等互联网视频构建数据集，包含5000个视频-音频-文本三元组，每个视频都包含可见声源且音频与屏幕事件因果相关。

Result: 与过去数据集相比，FoleyBench在专门为Foley声音设计的分类法中具有更强的声音类别覆盖。每个片段都标注了源复杂性、UCS/AudioSet类别和视频长度等元数据。

Conclusion: FoleyBench填补了Foley风格视频到音频生成评估的空白，为模型性能分析和失败模式识别提供了细粒度分析能力，并评估了多个最先进的V2A模型在音频质量、音频-视频对齐、时间同步和音频-文本一致性等方面的表现。

Abstract: Video-to-audio generation (V2A) is of increasing importance in domains such as film post-production, AR/VR, and sound design, particularly for the creation of Foley sound effects synchronized with on-screen actions. Foley requires generating audio that is both semantically aligned with visible events and temporally aligned with their timing. Yet, there is a mismatch between evaluation and downstream applications due to the absence of a benchmark tailored to Foley-style scenarios. We find that 74% of videos from past evaluation datasets have poor audio-visual correspondence. Moreover, they are dominated by speech and music, domains that lie outside the use case for Foley. To address this gap, we introduce FoleyBench, the first large-scale benchmark explicitly designed for Foley-style V2A evaluation. FoleyBench contains 5,000 (video, ground-truth audio, text caption) triplets, each featuring visible sound sources with audio causally tied to on-screen events. The dataset is built using an automated, scalable pipeline applied to in-the-wild internet videos from YouTube-based and Vimeo-based sources. Compared to past datasets, we show that videos from FoleyBench have stronger coverage of sound categories from a taxonomy specifically designed for Foley sound. Each clip is further labeled with metadata capturing source complexity, UCS/AudioSet category, and video length, enabling fine-grained analysis of model performance and failure modes. We benchmark several state-of-the-art V2A models, evaluating them on audio quality, audio-video alignment, temporal synchronization, and audio-text consistency. Samples are available at: https://gclef-cmu.org/foleybench

</details>


### [34] [Spatial Blind Spot: Auditory Motion Perception Deficits in Audio LLMs](https://arxiv.org/abs/2511.13273)
*Zhe Sun,Yujun Cai,Jiayu Yao,Yiwei Wang*

Main category: cs.SD

TL;DR: 当前音频语言模型存在系统性的运动感知缺陷，无法可靠识别声音源的运动方向和轨迹，准确率低于50%。


<details>
  <summary>Details</summary>
Motivation: 研究大型音频语言模型是否能够感知声音源的空间动态和运动特性，填补现有模型在听觉空间推理方面的空白。

Method: 引入AMPBench基准测试，通过双耳音频的问答任务评估模型对移动声音源方向和轨迹的推理能力。

Result: 当前模型在运动感知方面表现不佳，无法可靠识别运动线索或区分方向模式，平均准确率低于50%。

Conclusion: 揭示了人类与模型在听觉空间推理方面的根本差距，为未来音频语言模型的空间认知增强提供了诊断工具和新见解。

Abstract: Large Audio-Language Models (LALMs) have recently shown impressive progress in speech recognition, audio captioning, and auditory question answering. Yet, whether these models can perceive spatial dynamics, particularly the motion of sound sources, remains unclear. In this work, we uncover a systematic motion perception deficit in current ALLMs. To investigate this issue, we introduce AMPBench, the first benchmark explicitly designed to evaluate auditory motion understanding. AMPBench introduces a controlled question-answering benchmark designed to evaluate whether Audio-Language Models (LALMs) can infer the direction and trajectory of moving sound sources from binaural audio. Comprehensive quantitative and qualitative analyses reveal that current models struggle to reliably recognize motion cues or distinguish directional patterns. The average accuracy remains below 50%, underscoring a fundamental limitation in auditory spatial reasoning. Our study highlights a fundamental gap between human and model auditory spatial reasoning, providing both a diagnostic tool and new insight for enhancing spatial cognition in future Audio-Language Models.

</details>

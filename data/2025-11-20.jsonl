{"id": "2511.14969", "categories": ["eess.AS", "cs.AI", "cs.LG", "eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.14969", "abs": "https://arxiv.org/abs/2511.14969", "authors": ["Zanxu Wang", "Homayoon Beigi"], "title": "Quality-Controlled Multimodal Emotion Recognition in Conversations with Identity-Based Transfer Learning and MAMBA Fusion", "comment": "8 pages, 14 images, 3 tables, Recognition Technologies, Inc. Technical Report RTI-20251118-01", "summary": "This paper addresses data quality issues in multimodal emotion recognition in conversation (MERC) through systematic quality control and multi-stage transfer learning. We implement a quality control pipeline for MELD and IEMOCAP datasets that validates speaker identity, audio-text alignment, and face detection. We leverage transfer learning from speaker and face recognition, assuming that identity-discriminative embeddings capture not only stable acoustic and Facial traits but also person-specific patterns of emotional expression. We employ RecoMadeEasy(R) engines for extracting 512-dimensional speaker and face embeddings, fine-tune MPNet-v2 for emotion-aware text representations, and adapt these features through emotion-specific MLPs trained on unimodal datasets. MAMBA-based trimodal fusion achieves 64.8% accuracy on MELD and 74.3% on IEMOCAP. These results show that combining identity-based audio and visual embeddings with emotion-tuned text representations on a quality-controlled subset of data yields consistent competitive performance for multimodal emotion recognition in conversation and provides a basis for further improvement on challenging, low-frequency emotion classes."}
{"id": "2511.14793", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.14793", "abs": "https://arxiv.org/abs/2511.14793", "authors": ["Muntahi Safwan Mahfi", "Md. Manzurul Hasan", "Gahangir Hossain"], "title": "OBHS: An Optimized Block Huffman Scheme for Real-Time Audio Compression", "comment": "3 page, 2 figures, 2 tables", "summary": "In this paper, we introduce OBHS (Optimized Block Huffman Scheme), a novel lossless audio compression algorithm tailored for real-time streaming applications. OBHS leverages block-wise Huffman coding with canonical code representation and intelligent fallback mechanisms to achieve high compression ratios while maintaining low computational complexity. Our algorithm partitions audio data into fixed-size blocks, constructs optimal Huffman trees for each block, and employs canonical codes for efficient storage and transmission. Experimental results demonstrate that OBHS attains compression ratios of up to 93.6% for silence-rich audio and maintains competitive performance across various audio types, including pink noise, tones, and real-world recordings. With a linear time complexity of O(n) for n audio samples, OBHS effectively balances compression efficiency and computational demands, making it highly suitable for resource-constrained real-time audio streaming scenarios."}
{"id": "2511.15131", "categories": ["eess.AS", "cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.15131", "abs": "https://arxiv.org/abs/2511.15131", "authors": ["Hokuto Munakata", "Takehiro Imamura", "Taichi Nishimura", "Tatsuya Komatsu"], "title": "CASTELLA: Long Audio Dataset with Captions and Temporal Boundaries", "comment": null, "summary": "We introduce CASTELLA, a human-annotated audio benchmark for the task of audio moment retrieval (AMR). Although AMR has various useful potential applications, there is still no established benchmark with real-world data. The early study of AMR trained the model with solely synthetic datasets. Moreover, the evaluation is based on annotated dataset of fewer than 100 samples. This resulted in less reliable reported performance. To ensure performance for applications in real-world environments, we present CASTELLA, a large-scale manually annotated AMR dataset. CASTELLA consists of 1,009, 213, and 640 audio recordings for train, valid, and test split, respectively, which is 24 times larger than the previous dataset. We also establish a baseline model for AMR using CASTELLA. Our experiments demonstrate that a model fine-tuned on CASTELLA after pre-training on the synthetic data outperformed a model trained solely on the synthetic data by 10.4 points in Recall1@0.7. CASTELLA is publicly available in https://h-munakata.github.io/CASTELLA-demo/."}
{"id": "2511.14801", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2511.14801", "abs": "https://arxiv.org/abs/2511.14801", "authors": ["Jonas Länzlinger", "Katharina Müller", "Bruno Rodrigues"], "title": "IHearYou: Linking Acoustic Features to DSM-5 Depressive Behavior Indicators", "comment": null, "summary": "Depression affects over millions people worldwide, yet diagnosis still relies on subjective self-reports and interviews that may not capture authentic behavior. We present IHearYou, an approach to automated depression detection focused on speech acoustics. Using passive sensing in household environments, IHearYou extracts voice features and links them to DSM-5 (Diagnostic and Statistical Manual of Mental Disorders) indicators through a structured Linkage Framework instantiated for Major Depressive Disorder. The system runs locally to preserve privacy and includes a persistence schema and dashboard, presenting real-time throughput on a commodity laptop. To ensure reproducibility, we define a configuration-driven protocol with False Discovery Rate (FDR) correction and gender-stratified testing. Applied to the DAIC-WOZ dataset, this protocol reveals directionally consistent feature-indicator associations, while a TESS-based audio streaming experiment validates end-to-end feasibility. Our results show how passive voice sensing can be turned into explainable DSM-5 indicator scores, bridging the gap between black-box detection and clinically interpretable, on-device analysis."}
{"id": "2511.15145", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.15145", "abs": "https://arxiv.org/abs/2511.15145", "authors": ["Mingyue Huo", "Wei-Cheng Tseng", "Yiwen Shao", "Hao Zhang", "Dong Yu"], "title": "Auden-Voice: General-Purpose Voice Encoder for Speech and Language Understanding", "comment": "Submitted to ICASSP2026", "summary": "Human voice encodes both identity and paralinguistic cues, yet encoders in large audio-language models (LALMs) rarely balance both aspects. In this work, we present a study toward building a general-purpose voice encoder that captures nuanced voice cues. Through a comprehensive evaluation, we find that multi-task training yields the most balanced representations, whereas contrastive language-audio pretraining (CLAP) primarily improves retrieval without enhancing paralinguistic understanding. Our final encoder, Auden-Voice, also demonstrates strong performance when integrated with LLMs. The code and training recipes will be released with the audio understanding toolkit Auden."}
{"id": "2511.14824", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.14824", "abs": "https://arxiv.org/abs/2511.14824", "authors": ["Nam-Gyu Kim"], "title": "Voiced-Aware Style Extraction and Style Direction Adjustment for Expressive Text-to-Speech", "comment": "Master's thesis, Korea University, 2025", "summary": "Recent advances in expressive text-to-speech (TTS) have introduced diverse methods based on style embedding extracted from reference speech. However, synthesizing high-quality expressive speech remains challenging. We propose SpotlightTTS, which exclusively emphasizes style via voiced-aware style extraction and style direction adjustment. Voiced-aware style extraction focuses on voiced regions highly related to style while maintaining continuity across different speech regions to improve expressiveness. We adjust the direction of the extracted style for optimal integration into the TTS model, which improves speech quality. Experimental results demonstrate that Spotlight-TTS achieves superior performance compared to baseline models in terms of expressiveness, overall speech quality, and style transfer capability."}
{"id": "2511.14793", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.14793", "abs": "https://arxiv.org/abs/2511.14793", "authors": ["Muntahi Safwan Mahfi", "Md. Manzurul Hasan", "Gahangir Hossain"], "title": "OBHS: An Optimized Block Huffman Scheme for Real-Time Audio Compression", "comment": "3 page, 2 figures, 2 tables", "summary": "In this paper, we introduce OBHS (Optimized Block Huffman Scheme), a novel lossless audio compression algorithm tailored for real-time streaming applications. OBHS leverages block-wise Huffman coding with canonical code representation and intelligent fallback mechanisms to achieve high compression ratios while maintaining low computational complexity. Our algorithm partitions audio data into fixed-size blocks, constructs optimal Huffman trees for each block, and employs canonical codes for efficient storage and transmission. Experimental results demonstrate that OBHS attains compression ratios of up to 93.6% for silence-rich audio and maintains competitive performance across various audio types, including pink noise, tones, and real-world recordings. With a linear time complexity of O(n) for n audio samples, OBHS effectively balances compression efficiency and computational demands, making it highly suitable for resource-constrained real-time audio streaming scenarios."}
{"id": "2511.14939", "categories": ["cs.SD", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.14939", "abs": "https://arxiv.org/abs/2511.14939", "authors": ["Daniel Oliveira de Brito", "Letícia Gabriella de Souza", "Marcelo Matheus Gauy", "Marcelo Finger", "Arnaldo Candido Junior"], "title": "Fine-tuning Pre-trained Audio Models for COVID-19 Detection: A Technical Report", "comment": "11 pages", "summary": "This technical report investigates the performance of pre-trained audio models on COVID-19 detection tasks using established benchmark datasets. We fine-tuned Audio-MAE and three PANN architectures (CNN6, CNN10, CNN14) on the Coswara and COUGHVID datasets, evaluating both intra-dataset and cross-dataset generalization. We implemented a strict demographic stratification by age and gender to prevent models from exploiting spurious correlations between demographic characteristics and COVID-19 status. Intra-dataset results showed moderate performance, with Audio-MAE achieving the strongest result on Coswara (0.82 AUC, 0.76 F1-score), while all models demonstrated limited performance on Coughvid (AUC 0.58-0.63). Cross-dataset evaluation revealed severe generalization failure across all models (AUC 0.43-0.68), with Audio-MAE showing strong performance degradation (F1-score 0.00-0.08). Our experiments demonstrate that demographic balancing, while reducing apparent model performance, provides more realistic assessment of COVID-19 detection capabilities by eliminating demographic leakage - a confounding factor that inflate performance metrics. Additionally, the limited dataset sizes after balancing (1,219-2,160 samples) proved insufficient for deep learning models that typically require substantially larger training sets. These findings highlight fundamental challenges in developing generalizable audio-based COVID-19 detection systems and underscore the importance of rigorous demographic controls for clinically robust model evaluation."}
{"id": "2511.14890", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.14890", "abs": "https://arxiv.org/abs/2511.14890", "authors": ["Helmut Repp"], "title": "Ein Fenster zur gleichzeitigen Messung der Uebertragungsfunktion eines realen Systems und des Leistungsdichtespektrums des ueberlagerten Rauschens am Systemausgang (Teil 1)", "comment": "256 pages, in German, MATLAB and SCILAB programs for calculating a window in a ZIP folder attached as ancillary file", "summary": "There is already a method known from the literature with which it is possible to measure both the transfer function and the noise power spectral density of the superimposed noise at the output of a disturbed, time-invariant, real system with nonlinearities in one measurement. By using a suitable window, the frequency selectivity of the measurement of the power spectral density of the superimposed noise can be noticeably improved without significantly increasing the computational complexity of the method. The unbiasedness and consistency of the measurement method with a suitable window are proven. The measurement of the power spectral density of a zero-mean, stationary process without measuring the transfer function is investigated as a special case for both real-valued and complex-valued signals. It is derived which requirements a suitable window should meet and how it can be calculated with high numerical accuracy.\n  --\n  Es gibt bereits eine aus der Literatur bekannte Methode mit der es moeglich ist in einer Messung sowohl die Uebertragungsfunktion als auch das Rauschleistungsdichtespektrum des ueberlagerten Rauschens am Ausgang eines gestoerten, zeitinvarianten, realen Systems mit Nichtlinearitaeten zu messen. Durch den Einsatz eines geeigneten Fensters kann die Frequenzselektivitaet der Messung des Leistungsdichtespektrums der Stoerung deutlich verbessert werden, ohne den Aufwand der Berechnungen des Verfahrens nennenswert zu erhoehen. Die Erwartungstreue und die Konsistenz des Messverfahren mit Fensterung wird gezeigt. Die Messung des Leistungsdichtespektrums eines mittelwertfreien, stationaeren Prozesses ohne Messung der Uebertragungsfunktion wird als Sonderfall sowohl fuer reellwertige, als auch fuer komplexwertige Signale untersucht. Es wird hergeleitet, welche Forderungen ein geeignetes Fenster erfuellen sollte und wie es sich numerisch hochgenau berechnen laesst."}
{"id": "2511.14939", "categories": ["cs.SD", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.14939", "abs": "https://arxiv.org/abs/2511.14939", "authors": ["Daniel Oliveira de Brito", "Letícia Gabriella de Souza", "Marcelo Matheus Gauy", "Marcelo Finger", "Arnaldo Candido Junior"], "title": "Fine-tuning Pre-trained Audio Models for COVID-19 Detection: A Technical Report", "comment": "11 pages", "summary": "This technical report investigates the performance of pre-trained audio models on COVID-19 detection tasks using established benchmark datasets. We fine-tuned Audio-MAE and three PANN architectures (CNN6, CNN10, CNN14) on the Coswara and COUGHVID datasets, evaluating both intra-dataset and cross-dataset generalization. We implemented a strict demographic stratification by age and gender to prevent models from exploiting spurious correlations between demographic characteristics and COVID-19 status. Intra-dataset results showed moderate performance, with Audio-MAE achieving the strongest result on Coswara (0.82 AUC, 0.76 F1-score), while all models demonstrated limited performance on Coughvid (AUC 0.58-0.63). Cross-dataset evaluation revealed severe generalization failure across all models (AUC 0.43-0.68), with Audio-MAE showing strong performance degradation (F1-score 0.00-0.08). Our experiments demonstrate that demographic balancing, while reducing apparent model performance, provides more realistic assessment of COVID-19 detection capabilities by eliminating demographic leakage - a confounding factor that inflate performance metrics. Additionally, the limited dataset sizes after balancing (1,219-2,160 samples) proved insufficient for deep learning models that typically require substantially larger training sets. These findings highlight fundamental challenges in developing generalizable audio-based COVID-19 detection systems and underscore the importance of rigorous demographic controls for clinically robust model evaluation."}
{"id": "2511.15038", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.15038", "abs": "https://arxiv.org/abs/2511.15038", "authors": ["Dorien Herremans", "Abhinaba Roy"], "title": "Aligning Generative Music AI with Human Preferences: Methods and Challenges", "comment": "Accepted at the AAAI-2026 Senior Member Track", "summary": "Recent advances in generative AI for music have achieved remarkable fidelity and stylistic diversity, yet these systems often fail to align with nuanced human preferences due to the specific loss functions they use. This paper advocates for the systematic application of preference alignment techniques to music generation, addressing the fundamental gap between computational optimization and human musical appreciation. Drawing on recent breakthroughs including MusicRL's large-scale preference learning, multi-preference alignment frameworks like diffusion-based preference optimization in DiffRhythm+, and inference-time optimization techniques like Text2midi-InferAlign, we discuss how these techniques can address music's unique challenges: temporal coherence, harmonic consistency, and subjective quality assessment. We identify key research challenges including scalability to long-form compositions, reliability amongst others in preference modelling. Looking forward, we envision preference-aligned music generation enabling transformative applications in interactive composition tools and personalized music services. This work calls for sustained interdisciplinary research combining advances in machine learning, music-theory to create music AI systems that truly serve human creative and experiential needs."}
{"id": "2511.14895", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.14895", "abs": "https://arxiv.org/abs/2511.14895", "authors": ["Mohammad Cheraghinia", "Eli De Poorter", "Jaron Fontaine", "Kwang Soon Kim", "Merouane Debbah", "Adnan Shahid"], "title": "Lightweight Foundation Model for Wireless Time Series Downstream Tasks on Edge Devices", "comment": "6 pages, 4 figures, 5 tables. Accepted to a workshop in the IEEE GLOBECOM 2025", "summary": "While machine learning is widely used to optimize wireless networks, training a separate model for each task in communication and localization is becoming increasingly unsustainable due to the significant costs associated with training and deployment. Foundation models offer a more scalable alternative by enabling a single model to be adapted across multiple tasks through fine-tuning with limited samples. However, current foundation models mostly rely on large-scale Transformer architectures, resulting in computationally intensive models unsuitable for deployment on typical edge devices. This paper presents a lightweight foundation model based on simple Multi-Layer-Perceptron (MLP) encoders that independently process input patches. Our model supports 4 types of downstream tasks (long-range technology recognition, short-range technology recognition, modulation recognition and line-of-sight-detection) from multiple input types (IQ and CIR) and different sampling rates. We show that, unlike Transformers, which can exhibit performance drops as downstream tasks are added, our MLP model maintains robust generalization performance, achieving over 97% accurate fine-tuning results for previously unseen data classes. These results are achieved despite having only 21K trainable parameters, allowing an inference time of 0.33 ms on common edge devices, making the model suitable for constrained real-time deployments."}
{"id": "2511.15038", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2511.15038", "abs": "https://arxiv.org/abs/2511.15038", "authors": ["Dorien Herremans", "Abhinaba Roy"], "title": "Aligning Generative Music AI with Human Preferences: Methods and Challenges", "comment": "Accepted at the AAAI-2026 Senior Member Track", "summary": "Recent advances in generative AI for music have achieved remarkable fidelity and stylistic diversity, yet these systems often fail to align with nuanced human preferences due to the specific loss functions they use. This paper advocates for the systematic application of preference alignment techniques to music generation, addressing the fundamental gap between computational optimization and human musical appreciation. Drawing on recent breakthroughs including MusicRL's large-scale preference learning, multi-preference alignment frameworks like diffusion-based preference optimization in DiffRhythm+, and inference-time optimization techniques like Text2midi-InferAlign, we discuss how these techniques can address music's unique challenges: temporal coherence, harmonic consistency, and subjective quality assessment. We identify key research challenges including scalability to long-form compositions, reliability amongst others in preference modelling. Looking forward, we envision preference-aligned music generation enabling transformative applications in interactive composition tools and personalized music services. This work calls for sustained interdisciplinary research combining advances in machine learning, music-theory to create music AI systems that truly serve human creative and experiential needs."}
{"id": "2511.15270", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2511.15270", "abs": "https://arxiv.org/abs/2511.15270", "authors": ["Chih-Pin Tan", "Hsuan-Kai Kao", "Li Su", "Yi-Hsuan Yang"], "title": "LargeSHS: A large-scale dataset of music adaptation", "comment": "submitted as an ISMIR 2025 late-breaking demo paper", "summary": "Recent advances in AI-based music generation have focused heavily on text-conditioned models, with less attention given to reference-based generation such as song adaptation. To support this line of research, we introduce LargeSHS, a large-scale dataset derived from SecondHandSongs, containing over 1.7 million metadata entries and approximately 900k publicly accessible audio links. Unlike existing datasets, LargeSHS includes structured adaptation relationships between musical works, enabling the construction of adaptation trees and performance clusters that represent cover song families. We provide comprehensive statistics and comparisons with existing datasets, highlighting the unique scale and richness of LargeSHS. This dataset paves the way for new research in cover song generation, reference-based music generation, and adaptation-aware MIR tasks."}
{"id": "2511.14957", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.14957", "abs": "https://arxiv.org/abs/2511.14957", "authors": ["Helmut Repp"], "title": "Ein Fenster zur gleichzeitigen Messung der Uebertragungsfunktion eines realen Systems und des Leistungsdichtespektrums des ueberlagerten Rauschens am Systemausgang (Teil 2)", "comment": "288 pages, in German", "summary": "The method described in the first part for frequency-selectively measuring the transfer function and the noise power spectral density of the superimposed noise at the output of a disturbed, real system with nonlinearities using windowing was limited to time-invariant systems with stationary and zero-mean processes. Here, we investigate how this measurement method can be extended so that all correlations existing between the input and output signals can also be measured using windowing for a periodically time-varying system disturbed by a cyclostationary noise process. An extended version of the window construction algorithm presented in the first part is introduced, in which some degrees of freedom not used there can be used to appropriately influence the properties of the window sequence depending on the application.\n  --\n  Das im ersten Teil beschriebene Verfahren die Uebertragungsfunktion und das Rauschleistungsdichtespektrum des ueberlagerten Rauschens am Ausgang eines gestoerten, realen Systems mit Nichtlinearitaeten mit Hilfe der Fensterung frequenzselektiv zu vermessen beschraenkte sich auf zeitinvariante Systeme mit stationaeren und mittelwertfreien Prozessen. Hier wird untersucht, wie dieses Messverfahren zu erweitern ist, so dass man damit auch alle Korrelationen, die zwischen Ein- und Ausgangssignal bestehen, bei einem periodisch zeitvarianten System, das von einem zyklostationaeren Rauschprozess gestoert wird, mit einer Fensterung messen kann. Es wird eine erweiterte Variante des im ersten Teil vorgestellten Algorithmus zur Konstruktion des Fensters angegeben, bei der einige dort nicht genutzte Freiheitsgrade dazu verwendet werden koennen, die Eigenschaften der Fensterfolge je nach Applikation geeignet zu beeinflussen."}
{"id": "2511.15485", "categories": ["cs.SD", "cs.CV"], "pdf": "https://arxiv.org/pdf/2511.15485", "abs": "https://arxiv.org/abs/2511.15485", "authors": ["Abishek Karthik", "Pandiyaraju V", "Dominic Savio M", "Rohit Swaminathan S"], "title": "A Novel CustNetGC Boosted Model with Spectral Features for Parkinson's Disease Prediction", "comment": null, "summary": "Parkinson's disease is a neurodegenerative disorder that can be very tricky to diagnose and treat. Such early symptoms can include tremors, wheezy breathing, and changes in voice quality as critical indicators of neural damage. Notably, there has been growing interest in utilizing changes in vocal attributes as markers for the detection of PD early on. Based on this understanding, the present paper was designed to focus on the acoustic feature analysis based on voice recordings of patients diagnosed with PD and healthy controls (HC). In this paper, we introduce a novel classification and visualization model known as CustNetGC, combining a Convolutional Neural Network (CNN) with Custom Network Grad-CAM and CatBoost to enhance the efficiency of PD diagnosis. We use a publicly available dataset from Figshare, including voice recordings of 81 participants: 40 patients with PD and 41 healthy controls. From these recordings, we extracted the key spectral features: L-mHP and Spectral Slopes. The L-mHP feature combines three spectrogram representations: Log-Mel spectrogram, harmonic spectrogram, and percussive spectrogram, which are derived using Harmonic-Percussive Source Separation (HPSS). Grad-CAM was used to highlight the important regions in the data, thus making the PD predictions interpretable and effective. Our proposed CustNetGC model achieved an accuracy of 99.06% and precision of 95.83%, with the area under the ROC curve (AUC) recorded at 0.90 for the PD class and 0.89 for the HC class. Additionally, the combination of CatBoost, a gradient boosting algorithm, enhanced the robustness and the prediction performance by properly classifying PD and non-PD samples. Therefore, the results provide the potential improvement in the CustNetGC system in enhancing diagnostic accuracy and the interpretability of the Parkinson's Disease prediction model."}
{"id": "2511.15026", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15026", "abs": "https://arxiv.org/abs/2511.15026", "authors": ["Zengrui Han", "Lu Bai", "Xuesong Cai", "Xiang Cheng"], "title": "WiCo-MG: Wireless Channel Foundation Model for Multipath Generation via Synesthesia of Machines", "comment": null, "summary": "Precise modeling of channel multipath is essential for understanding wireless propagation environments and optimizing communication systems. In particular, sixth-generation (6G) artificial intelligence (AI)-native communication systems demand massive and high-quality multipath channel data to enable intelligent model training and performance optimization. In this paper, we propose a wireless channel foundation model (WiCo) for multipath generation (WiCo-MG) via Synesthesia of Machines (SoM). To provide a solid training foundation for WiCo-MG, a new synthetic intelligent sensing-communication dataset for uncrewed aerial vehicle (UAV)-to-ground (U2G) communications is constructed. To overcome the challenges of cross-modal alignment and mapping, a two-stage training framework is proposed. In the first stage, sensing images are embedded into discrete-continuous SoM feature spaces, and multipath maps are embedded into a sensing-initialized discrete SoM space to align the representations. In the second stage, a mixture of shared and routed experts (S-R MoE) Transformer with frequency-aware expert routing learns the mapping from sensing to channel SoM feature spaces, enabling decoupled and adaptive multipath generation. Experimental results demonstrate that WiCo-MG achieves state-of-the-art in-distribution generation performance and superior out-of-distribution generalization, reducing NMSE by more than 2.59 dB over baselines, while exhibiting strong scalability in model and dataset growth and extensibility to new multipath parameters and tasks. Owing to higher accuracy, stronger generalization, and better scalability, WiCo-MG is expected to enable massive and high-fidelity channel data generation for the development of 6G AI-native communication systems."}
{"id": "2511.15131", "categories": ["eess.AS", "cs.CL", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.15131", "abs": "https://arxiv.org/abs/2511.15131", "authors": ["Hokuto Munakata", "Takehiro Imamura", "Taichi Nishimura", "Tatsuya Komatsu"], "title": "CASTELLA: Long Audio Dataset with Captions and Temporal Boundaries", "comment": null, "summary": "We introduce CASTELLA, a human-annotated audio benchmark for the task of audio moment retrieval (AMR). Although AMR has various useful potential applications, there is still no established benchmark with real-world data. The early study of AMR trained the model with solely synthetic datasets. Moreover, the evaluation is based on annotated dataset of fewer than 100 samples. This resulted in less reliable reported performance. To ensure performance for applications in real-world environments, we present CASTELLA, a large-scale manually annotated AMR dataset. CASTELLA consists of 1,009, 213, and 640 audio recordings for train, valid, and test split, respectively, which is 24 times larger than the previous dataset. We also establish a baseline model for AMR using CASTELLA. Our experiments demonstrate that a model fine-tuned on CASTELLA after pre-training on the synthetic data outperformed a model trained solely on the synthetic data by 10.4 points in Recall1@0.7. CASTELLA is publicly available in https://h-munakata.github.io/CASTELLA-demo/."}
{"id": "2511.15030", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15030", "abs": "https://arxiv.org/abs/2511.15030", "authors": ["Mingran Sun", "Lu Bai", "Ziwei Huang", "Xuesong Cai", "Xiang Cheng", "Jianjun Wu"], "title": "WiCo-PG: Wireless Channel Foundation Model for Pathloss Map Generation via Synesthesia of Machines", "comment": null, "summary": "A wireless channel foundation model for pathloss map generation (WiCo-PG) via Synesthesia of Machines (SoM) is developed for the first time. Considering sixth-generation (6G) uncrewed aerial vehicle (UAV)-to-ground (U2G) scenarios, a new multi-modal sensing-communication dataset is constructed for WiCo-PG pre-training, including multiple U2G scenarios, diverse flight altitudes, and diverse frequency bands. Based on the constructed dataset, the proposed WiCo-PG enables cross-modal pathloss map generation by leveraging RGB images from different scenarios and flight altitudes. In WiCo-PG, a novel network architecture designed for cross-modal pathloss map generation based on dual vector quantized generative adversarial networks (VQGANs) and Transformer is proposed. Furthermore, a novel frequency-guided shared-routed mixture of experts (S-R MoE) architecture is designed for cross-modal pathloss map generation. Simulation results demonstrate that the proposed WiCo-PG achieves improved pathloss map generation accuracy through pre-training with a normalized mean squared error (NMSE) of 0.012, outperforming the large language model (LLM)-based scheme, i.e., LLM4PG, and the conventional deep learning-based scheme by more than 6.98 dB. The enhanced generality of the proposed WiCo-PG can further outperform the LLM4PG by at least 1.37 dB using 2.7% samples in few-shot generalization."}
{"id": "2511.15145", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2511.15145", "abs": "https://arxiv.org/abs/2511.15145", "authors": ["Mingyue Huo", "Wei-Cheng Tseng", "Yiwen Shao", "Hao Zhang", "Dong Yu"], "title": "Auden-Voice: General-Purpose Voice Encoder for Speech and Language Understanding", "comment": "Submitted to ICASSP2026", "summary": "Human voice encodes both identity and paralinguistic cues, yet encoders in large audio-language models (LALMs) rarely balance both aspects. In this work, we present a study toward building a general-purpose voice encoder that captures nuanced voice cues. Through a comprehensive evaluation, we find that multi-task training yields the most balanced representations, whereas contrastive language-audio pretraining (CLAP) primarily improves retrieval without enhancing paralinguistic understanding. Our final encoder, Auden-Voice, also demonstrates strong performance when integrated with LLMs. The code and training recipes will be released with the audio understanding toolkit Auden."}
{"id": "2511.15064", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15064", "abs": "https://arxiv.org/abs/2511.15064", "authors": ["Eros Kuikel", "Sidrah Javed", "Baha Eddine Youcef Belmekki", "Yunfei Chen", "Ning Wang", "Mohamed-Slim Alouini"], "title": "The Triple-C Paradigm: Cooperative, Complementary, and Competitive Modes for TBS-HAPS-LEO Integration", "comment": null, "summary": "The growing demands of ubiquitous and resilient global coverage have pushed existing networks to their operational limits, making it increasingly difficult to meet all requirements on their own. Integrating \\emph{Terrestrial Base Stations (TBS), High Altitude Platform Stations (HAPS)} and \\emph{Low-Earth-Orbit (LEO)} satellites is envisioned as a promising solution, yet the coordination across these heterogeneous platforms remains an open challenge. This paper proposes a novel unifying \\emph{Triple-C framework: Cooperation, Complementarity, and Competition}, that systematically defines the TBS-HAPS-LEO interaction to deliver seamless resilient and scalable connectivity. For each C, we detail the architectural methodology, required pre-requisites, and measurable deliverables that govern when and how the three layers should collaborate, complement each other, or contend. We further identify the enabling technologies across physical, logical, and cognitive layers to operationalize the proposed 3C paradigm. A rich portfolio of use cases and targeted applications demonstrates how this technological leap will make such integration both feasible and impactful. Comprehensive performance analysis and emulation results quantify the trade-offs of such integrated networks. In addition, we examine the economical, environmental, safety, privacy, standardization, and regulatory implications that shape the real-world implementation of the proposed framework. eventually, we provide the gap analysis, outline key technical/non-technical challenges, and a road-map of future research directions needed to unlock the full potential of Cooperation, Complementarity, and Competition operations in TBS-HAPS-LEO integrated networks."}
{"id": "2511.15093", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15093", "abs": "https://arxiv.org/abs/2511.15093", "authors": ["Weijie Xiong", "Jingran Lin", "Cunhua Pan", "Yilong Zeng", "Qiang Li"], "title": "Enhancing Physical Layer Security in MIMO Systems Assisted by Beyond-Diagonal Reconfigurable Intelligent Surfaces", "comment": null, "summary": "Reconfigurable intelligent surfaces (RISs) hold significant promise for enhancing physical layer security (PLS). However, conventional RISs are typically modeled using diagonal scattering matrices, capturing only independent reflections from each reflecting element, which limits their flexibility in channel manipulation. In contrast, beyond-diagonal RISs (BD-RISs) employ non-diagonal scattering matrices enabled by active and tunable inter-element connections through a shared impedance network. This architecture significantly enhances channel shaping capabilities, creating new opportunities for advanced PLS techniques. This paper investigates PLS in a multiple-input multiple-output (MIMO) system assisted by BD-RISs, where a multi-antenna transmitter sends confidential information to a multi-antenna legitimate user while a multi-antenna eavesdropper attempts interception. To maximize the secrecy rate (SR), we formulate it as a non-convex optimization problem by jointly optimizing the transmit beamforming and BD-RIS REs under power and structural constraints. To solve this problem, we first introduce an auxiliary variable to decouple BD-RIS constraints. We then propose a low-complexity penalty product Riemannian conjugate gradient descent (P-PRCGD) method, which combines the augmented Lagrangian (AL) approach with the product manifold gradient descent (PMGD) method to obtain a Karush-Kuhn-Tucker (KKT) solution. Simulation results confirm that BD-RIS-assisted systems significantly outperform conventional RIS-assisted systems in PLS performance."}
{"id": "2511.15095", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15095", "abs": "https://arxiv.org/abs/2511.15095", "authors": ["Weijie Xiong", "Jingran Lin", "Zhiling Xiao", "Qiang Li"], "title": "Constant-Modulus Secure Analog Beamforming for an IRS-Assisted Communication System with Large-Scale Antenna Array", "comment": null, "summary": "Physical layer security (PLS) is an important technology in wireless communication systems to safeguard communication privacy and security between transmitters and legitimate users. The integration of large-scale antenna arrays (LSAA) and intelligent reflecting surfaces (IRS) has emerged as a promising approach to enhance PLS. However, LSAA requires a dedicated radio frequency (RF) chain for each antenna element, and IRS comprises hundreds of reflecting micro-antennas, leading to increased hardware costs and power consumption. To address this, cost-effective solutions like constant modulus analog beamforming (CMAB) have gained attention. This paper investigates PLS in IRS-assisted communication systems with a focus on jointly designing the CMAB at the transmitter and phase shifts at the IRS to maximize the secrecy rate. The resulting secrecy rate maximization (SRM) problem is non-convex. To solve the problem efficiently, we propose two algorithms: (1) the time-efficient Dinkelbach-BSUM algorithm, which reformulates the fractional problem into a series of quadratic programs using the Dinkelbach method and solves them via block successive upper-bound minimization (BSUM), and (2) the product manifold conjugate gradient descent (PMCGD) algorithm, which provides a better solution at the cost of slightly higher computational time by transforming the problem into an unconstrained optimization on a Riemannian product manifold and solving it using the conjugate gradient descent (CGD) algorithm. Simulation results validate the effectiveness of the proposed algorithms and highlight their distinct advantages."}
{"id": "2511.15096", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15096", "abs": "https://arxiv.org/abs/2511.15096", "authors": ["Weijie Xiong", "Kai Zhong", "Zhiling Xiao", "Jingran Lin", "Qiang Li"], "title": "Joint Analog Beamforming and Antenna Position Design for Secure Communication systems With Movable Antennas", "comment": null, "summary": "Movable antennas (MA) are a novel technology that allows for the flexible adjustment of antenna positions within a specified region, thereby enhancing the performance of wireless communication systems. In this paper, we explore the use of MA to improve physical layer security in an analog beamforming (AB) communication system. Our goal is to maximize the secrecy rate by jointly optimizing the transmit AB and MA position, subject to constant modulus (CM) constraints on the AB and position constraints for the MA. The resulting problem is non-convex, and we propose a penalty product manifold (PPM) method to solve it efficiently. Specifically, we convert the inequality constraints related to MA position into a penalty function using smoothing techniques, thereby reformulating the problem as an unconstrained optimization on the product manifold space (PMS). We then derive a parallel conjugate gradient descent (PCGD) algorithm to update both the AB and MA position on the PMS. This method is efficient, providing an analytical solution at each step and ensuring convergence to a KKT point. Simulation results show that the MA system achieves a higher secrecy rate than systems with fixed-position antennas."}
{"id": "2511.15108", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15108", "abs": "https://arxiv.org/abs/2511.15108", "authors": ["Liujia Yao", "Changsheng You", "Chao Zhou", "Beixiong Zheng", "Weidong Mei"], "title": "Position Optimization for Two-layer Movable Antenna Systems", "comment": null, "summary": "Movable antenna (MA) is a promising technology for improving the performance of wireless communication systems by providing new degrees-of-freedom (DoFs) in antenna position optimization. However, existing works on MA systems have mostly considered element-wise single-layer MA (SL-MA) arrays, where all the MAs move within the given movable region, hence inevitably incurring high control complexity and hardware cost in practice. To address this issue, we propose in this letter a new two-layer MA array (TL-MA), where the positions of MAs are jointly determined by the large-scale movement of multiple subarrays and the small-scale fine-tuning of per-subarray MAs. In particular, an optimization problem is formulated to maximize the sum-rate of the TL-MA-aided communication system by jointly optimizing the subarray-positions, per-subarray (relative) MA positions, and receive beamforming. To solve this non-convex problem, we propose an alternating optimization (AO)-based particle swarm optimization (PSO) algorithm, which alternately optimizes the positions of subarrays and per-subarray MAs, given the optimal receive beamforming. Numerical results verify that the proposed TL-MA significantly reduces the sum-displacement of MA motors (i.e., the total moving distances of all motors) of element-wise SL-MA, while achieving comparable rate performance."}
{"id": "2511.15162", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15162", "abs": "https://arxiv.org/abs/2511.15162", "authors": ["Ahmed Aboulfotouh", "Hatem Abou-Zeid"], "title": "Multimodal Wireless Foundation Models", "comment": null, "summary": "Wireless foundation models (WFMs) have recently demonstrated promising capabilities, jointly performing multiple wireless functions and adapting effectively to new environments. However, while current WFMs process only one modality, depending on the task and operating conditions, the most informative modality changes and no single modality is best for all tasks. WFMs should therefore be designed to accept multiple modalities to enable a broader and more diverse range of tasks and scenarios. In this work, we propose and build the first multimodal wireless foundation model capable of processing both raw IQ streams and image-like wireless modalities (e.g., spectrograms and CSI) and performing multiple tasks across both. We introduce masked wireless modeling for the multimodal setting, a self-supervised objective and pretraining recipe that learns a joint representation from IQ streams and image-like wireless modalities. We evaluate the model on five tasks across both modality families: image-based (human activity sensing, RF signal classification, 5G NR positioning) and IQ-based (RF device fingerprinting, interference detection/classification). The multimodal WFM is competitive with single-modality WFMs, and in several cases surpasses their performance. Our results demonstrates the strong potential of developing multimodal WFMs that support diverse wireless tasks across different modalities. We believe this provides a concrete step toward both AI-native 6G and the vision of joint sensing, communication, and localization."}
{"id": "2511.15184", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15184", "abs": "https://arxiv.org/abs/2511.15184", "authors": ["Akram Shafie", "Jun Tong", "Jinhong Yuan", "Taka Sakurai", "Paul Fitzpatrick", "Yuting Fang", "Yixuan Xie"], "title": "Spectrum and Orthogonality of Orthogonal Delay-Doppler Division Multiplexing Modulation Waveforms", "comment": "This paper has been accepted for publication in an IEEE Journal", "summary": "Orthogonal delay-Doppler (DD) division multiplexing (ODDM) modulation has recently emerged as a promising paradigm for ensuring reliable communications in doubly-selective channels. This work investigates the spectra and orthogonality characteristics of analog (direct) and approximate digital implementations of ODDM systems. We first determine the time and frequency domain representations of the basis functions for waveform in analog and approximate digital ODDM systems. Thereafter, we derive their power spectral densities and show that while the spectrum of analog ODDM waveforms exhibits a step-wise behavior in its transition regions, the spectrum of approximate digital ODDM waveforms is confined to that of the ODDM sub-pulse. Next, we prove the orthogonality characteristics of approximate digital ODDM waveforms and show that, unlike analog ODDM waveforms, the approximate digital ODDM waveforms satisfy orthogonality without the need of additional time domain resources. Additionally, we examine the similarities and differences that implementations of approximate digital ODDM share with the other variants of DD modulations, focusing on the domain changes the symbols undergo, the type of pulse shaping and windowing used, and the domains and the sequence in which they are performed. Finally, we present numerical results to validate our findings and draw further insights."}
{"id": "2511.15187", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15187", "abs": "https://arxiv.org/abs/2511.15187", "authors": ["Evan Frenklak", "Yamin Arefeen", "Jonathan I Tamir"], "title": "Theoretical Bounds on Parallel Imaging Implicit Data Crimes in an MRI Reproducing Kernel Hilbert Space", "comment": null, "summary": "Magnetic Resonance Imaging (MRI) diagnoses and manages a wide range of diseases, yet long scan times drive high costs and limit accessibility. AI methods have demonstrated substantial potential for reducing scan times, but despite rapid progress, clinical translation of AI often fails. One particular class of failure modes, referred to as implicit data crimes, are a result of hidden biases introduced when MRI datasets incompletely model the MRI physics of the acquisition. Previous work identified data crimes resulting from algorithmic completion of k-space with parallel imaging and drew on simulation to demonstrate the resulting downstream biases. This work proposes a mathematical framework to re-characterize the problem as one of error reduction during interpolation between sets of evaluation coordinates. We establish a generalized matrix-based definition of the reconstruction error upper bound as a function of the input sampling pattern. Experiments on relevant sampling pattern structures demonstrate the relevance of the framework and suggest future directions for analysis of data crimes."}
{"id": "2511.15198", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15198", "abs": "https://arxiv.org/abs/2511.15198", "authors": ["Henglin Pu", "Xuefeng Wang", "Lu Su", "Husheng Li"], "title": "Space-Time-Frequency Synthetic Integrated Sensing and Communication Networks", "comment": null, "summary": "Integrated sensing and communication (ISAC) promises high spectral and power efficiencies by sharing waveforms, spectrum, and hardware across sensing and data links. Yet commercial cellular networks struggle to deliver fine angular, range, and Doppler resolution due to limited aperture, bandwidth, and coherent observation time. In this paper, we propose a space-time-frequency synthetic ISAC architecture that fuses observations from distributed transmitters and receivers across time intervals and frequency bands. We develop a unified signal model for multistatic and monostatic configurations, derive Cramer-Rao lower bounds (CRLBs) for the estimations of position and velocity. The analysis shows how spatial diversity, multiband operation, and observation scheduling impact the Fisher information. We also compare the estimation performance between a concentrated maximum likelihood estimator (MLE) and a two stage information fusion (TSIF) method that first estimates per-path delay and radial speed and then fuses them by solving a weighted nonlinear least-squares problem via the Gauss-Newton algorithm. Numerical results show that MLE approaches the CRLB in the high signal-to-noise ratio (SNR) regime, while the two stage method remains competitive at moderate to high SNR but degrades at low SNR. A central finding is that fully synthesized network processing is essential, as estimations by individual base stations (BSs) followed by fusion are consistently inferior and unstable at low SNR. This framework offers a practical guidance for upgrading existing communication infrastructure into dense sensing networks."}
{"id": "2511.15221", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15221", "abs": "https://arxiv.org/abs/2511.15221", "authors": ["Yongchao He", "Taihao Zhang", "Cunhua Pan", "Hong Ren", "Xianzhe Chen", "Tian Qiu", "Bingchang Hua", "Jiangzhou Wang"], "title": "Theoretical and Empirical Study of Spatial Power Focusing Effect for Sparse Arrays at Terahertz Band", "comment": "5 pages, 7 figures", "summary": "This work investigates the spatial power focusing effect for large-scale sparse arrays at terahertz (THz) band, combining theoretical analysis with experimental validation. Specifically, based on a Green's function channel model, we analyze the power distribution along the $z$-axis, deriving a closed-form expression to characterize the focusing effect. Furthermore, the factors influencing the focusing effect, including phase noise and positional deviations, are theoretically analyzed and numerically simulated. Finally, a 300 GHz measurement platform based on a vector network analyzer (VNA) is constructed for experimental validation. The measurement results demonstrate close consistence with theoretical simulation results, confirming the spatial power focusing effect for sparse arrays."}
{"id": "2511.15412", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2511.15412", "abs": "https://arxiv.org/abs/2511.15412", "authors": ["Evgenii Vinogradov", "Aymen Fakhreddine", "Abdul Saboor", "Sergi Abadal", "Sofie Pollin"], "title": "Spatially Consistent Air-to-Ground Channel Modeling and Simulation via 3D Shadow Projections", "comment": "International Conference on Computing, Networking and Communications (ICNC 2026)", "summary": "We present an approach for spatially-consistent semi-deterministic Air-to-Ground (A2G) channel modeling in Unmanned Aerial Vehicle-assisted networks. We use efficient 3D building shadow projections to determine Line-of-Sight (LOS) regions, enabling fast generation of LOS maps. By integrating LOS-aware deterministic path loss with stochastic shadow fading, the approach produces spatially consistent A2G radio maps suitable for environment- and mobility-aware channel evaluation and performance prediction. Simulation results in ITU-compliant Manhattan grid environments demonstrate the model's ability to reflect key urban propagation characteristics, such as LOS blockage patterns and outage behavior. The proposed approach provides an efficient alternative to ray tracing or fully stochastic models, with particular relevance for user mobility, link planning, and radio map generation in 6G non-terrestrial networks."}
{"id": "2511.15416", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15416", "abs": "https://arxiv.org/abs/2511.15416", "authors": ["Davide Tornielli Bellini", "Dario Tagliaferri", "Pietro Grassi", "Davide Scazzoli", "Stefano Tebaldini", "Umberto Spagnolini"], "title": "Enabling NLOS Imaging Capabilities at the Initial Access of 6G Base Stations", "comment": "15 pages (including supplementary material)", "summary": "Sensing in non-line-of-sight (NLOS) is one of the major challenges for integrated sensing and communication systems. Existing countermeasures for NLOS either use prior knowledge on the environment to characterize all the multiple bounces or deploy anomalous reflectors in the environment to enable communication infrastructure to ''\\textit{see behind the corner}''. This work addresses the integration of monostatic NLOS imaging functionalities into the initial access (IA) procedure of a next generation base station (BS), by means of a non-reconfigurable modular reflector. During standard-compliant IA, the BS sweeps a narrow beam using a pre-defined dedicated codebook to achieve the beam alignment with users. We introduce the imaging functionality by enhancing such codebook with imaging-specific entries that are jointly designed with the angular configuration of the modular reflector to enable high-resolution imaging of a region in NLOS by \\textit{coherently} processing all the echoes at the BS. We derive closed-form expressions for the near-field (NF) spatial resolution, as well as for the \\textit{effective aperture} (i.e., the portion of the reflector that actively contributes to improve image resolution). The problem of imaging of moving targets in NLOS is also addressed, and we propose a maximum-likelihood estimation for target's velocity in NF and related theoretical bound. Further, we discuss and quantify the inherent communication-imaging performance trade-offs and related system design challenges through numerical simulations. Finally, the proposed imaging method employing modular reflectors is validated both numerically and experimentally, showing the effectiveness of our concept."}
{"id": "2511.15444", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15444", "abs": "https://arxiv.org/abs/2511.15444", "authors": ["Jiajun He", "Xidong Mu", "Hien Quoc Ngo", "Michail Matthaiou"], "title": "Pinching-Antenna System-Assisted Localization: A Stochastic Geometry Perspective", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "This paper proposes a novel localization framework underpinned by a pinching-antenna (PA) system, in which the target location is estimated using received signal strength (RSS) measurements obtained from downlink signals transmitted by the PAs. To develop a comprehensive analytical framework, we employ stochastic geometry to model the spatial distribution of the PAs, enabling tractable and insightful network-level performance analysis. Closed-form expressions for target localizability and the Cramer-Rao lower bound (CRLB) distribution are analytically derived, enabling the evaluation of the fundamental limits of PA-assisted localization systems without extensive simulations. Furthermore, the proposed framework provides practical guidance for selecting the optimal waveguide number to maximize localization performance. Numerical results also highlight the superiority of the PA-assisted approach over conventional fixed-antenna systems in terms of the CRLB."}
{"id": "2511.15458", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15458", "abs": "https://arxiv.org/abs/2511.15458", "authors": ["Xuan Yang", "Dongming Li", "Dong Wei", "Meng Zhang"], "title": "Division-based Receiver-agnostic RFF Identification in WiFi Systems", "comment": null, "summary": "In physical-layer security schemes, radio frequency fingerprint (RFF) identification of WiFi devices is susceptible to receiver differences, which can significantly degrade classification performance when a model is trained on one receiver but tested on another. In this paper, we propose a division-based receiver-agnostic RFF extraction method for WiFi systems, which removes the receivers' effects by dividing different preambles in the frequency domain. The proposed method requires only a single receiver for training and does not rely on additional calibration or stacking processes. First, for flat fading channel scenarios, the legacy short training field (L-STF) and legacy long training field (L-LTF) of the unknown device are divided by those of the reference device in the frequency domain. The receiver-dependent effects can be eliminated with the requirement of only a single receiver for training, and the higher-dimensional RFF features can be extracted. Second, for frequency-selective fading channel scenarios, the high-throughput long training field (HT-LTF) is divided by the L-LTF in the frequency domain. Only a single receiver is required for training and the higher-dimensional RFF features that are both channel-invariant and receiver-agnostic are extracted. Finally, simulation and experimental results demonstrate that the proposed method effectively mitigate the impacts of channel variations and receiver differences. The classification results show that, even when training on a single receiver and testing on a different one, the proposed method achieves classification accuracy improvements of 15.5% and 28.45% over the state-of-the-art approach in flat fading and frequency-selective fading channel scenarios, respectively."}
{"id": "2511.15490", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15490", "abs": "https://arxiv.org/abs/2511.15490", "authors": ["Mohamed Siala", "Noura Sellami"], "title": "Collision Resolution in RFID Systems Using Antenna Arrays and Mix Source Separation", "comment": "4 pages, 3 figures", "summary": "In this letter, we propose an efficient mix source separation algorithm for collision resolution in radio frequency identification (RFID) systems equipped with an antenna array at the reader. We first introduce an approach that exploits the zero constant modulus (ZCM) criterion to separate colliding tags through gradient descent, without using pilot symbols. We show that the ZCM characteristic, considered alone, in the design of the objective function can lead to significant ambiguities in the determination of the beamformers used in the recovery of tag messages. To address this limitation, we propose a more sophisticated approach, relying on a hybrid objective function, incorporating a new ambiguity-raising criterion in addition to the ZCM criterion."}
{"id": "2511.15497", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15497", "abs": "https://arxiv.org/abs/2511.15497", "authors": ["Yu Sha", "Ningtao Liu", "Haofeng Liu", "Junqi Tao", "Zhenxing Niu", "Guojun Huang", "Yao Yao", "Jiaqi Liang", "Moxian Qian", "Horst Stoecker", "Domagoj Vnucec", "Andreas Widl", "Kai Zhou"], "title": "A Review of Machine Learning for Cavitation Intensity Recognition in Complex Industrial Systems", "comment": "43 pages", "summary": "Cavitation intensity recognition (CIR) is a critical technology for detecting and evaluating cavitation phenomena in hydraulic machinery, with significant implications for operational safety, performance optimization, and maintenance cost reduction in complex industrial systems. Despite substantial research progress, a comprehensive review that systematically traces the development trajectory and provides explicit guidance for future research is still lacking. To bridge this gap, this paper presents a thorough review and analysis of hundreds of publications on intelligent CIR across various types of mechanical equipment from 2002 to 2025, summarizing its technological evolution and offering insights for future development. The early stages are dominated by traditional machine learning approaches that relied on manually engineered features under the guidance of domain expert knowledge. The advent of deep learning has driven the development of end-to-end models capable of automatically extracting features from multi-source signals, thereby significantly improving recognition performance and robustness. Recently, physical informed diagnostic models have been proposed to embed domain knowledge into deep learning models, which can enhance interpretability and cross-condition generalization. In the future, transfer learning, multi-modal fusion, lightweight network architectures, and the deployment of industrial agents are expected to propel CIR technology into a new stage, addressing challenges in multi-source data acquisition, standardized evaluation, and industrial implementation. The paper aims to systematically outline the evolution of CIR technology and highlight the emerging trend of integrating deep learning with physical knowledge. This provides a significant reference for researchers and practitioners in the field of intelligent cavitation diagnosis in complex industrial systems."}
{"id": "2511.15523", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2511.15523", "abs": "https://arxiv.org/abs/2511.15523", "authors": ["Noura Sellami", "Mohamed Siala"], "title": "Randomized Power Transmission with Optimized Level Selection Probabilities in Uncoordinated Uplink NOMA", "comment": "5 pages, 7 figures", "summary": "We consider uncoordinated random uplink non-orthogonal multiple access (NOMA) systems using a set of predetermined power levels. We propose to optimize the probabilities of selection of power levels in order to minimize performance metrics as block error probability (BLEP) or bit error probability (BEP). When the multiuser detection algorithm at the BS treats at most two colliding users' packets, our optimization problem is a quadratic programming problem. For more colliding users' packets, we solve the problem iteratively. Our solution is original because it applies to any multiuser detection algorithm and any set of power levels."}
{"id": "2511.15545", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2511.15545", "abs": "https://arxiv.org/abs/2511.15545", "authors": ["Noura Sellami", "Mohamed Siala"], "title": "Uncoordinated Cooperative OFDM Multi-Hop UAV Relay Networks Using Virtual Channels Based on All-Pass Filters", "comment": "14 pages, 5 figures", "summary": "In this paper, we propose an efficient transmission scheme for autonomous cooperative Orthogonal Frequency Division Multiplexing (OFDM) based multi-hop Unmanned Aerial Vehicle (UAV) relay networks. These systems often suffer from destructive interference at the destination node due to uncoordinated transmissions of common packets by cooperating UAVs. To address this issue, we introduce the concept of virtual transmit channels at each UAV, implemented using truncated all-pass filters (APFs). This approach ensures that all subcarriers benefit from comparable transmit powers, guaranteeing excellent performance when a single UAV is transmitting. In scenarios where multiple UAVs cooperate without coordination, the inherent randomness of the generated virtual channels facilitates cooperative diversity, effectively mitigating destructive interference. We further integrate this method with the distributed randomized space-time block coding (STBC) scheme to enhance transmission reliability. Additionally, we propose efficient algorithms for estimating the composite channels that combine both the true propagation channels and the virtual channels. Simulation results demonstrate that our proposed scheme significantly outperforms the classical phase dithering scheme across various scenarios."}
{"id": "2511.15632", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2511.15632", "abs": "https://arxiv.org/abs/2511.15632", "authors": ["Petrus E. O. G. B. Abreu", "Gabriela M. M. Paixão", "Jiawei Li", "Paulo R. Gomes", "Peter W. Macfarlane", "Ana C. S. Oliveira", "Vinicius T. Carvalho", "Thomas B. Schön", "Antonio Luiz P. Ribeiro", "Antônio H. Ribeiro"], "title": "CODE-II: A large-scale dataset for artificial intelligence in ECG analysis", "comment": null, "summary": "Data-driven methods for electrocardiogram (ECG) interpretation are rapidly progressing. Large datasets have enabled advances in artificial intelligence (AI) based ECG analysis, yet limitations in annotation quality, size, and scope remain major challenges. Here we present CODE-II, a large-scale real-world dataset of 2,735,269 12-lead ECGs from 2,093,807 adult patients collected by the Telehealth Network of Minas Gerais (TNMG), Brazil. Each exam was annotated using standardized diagnostic criteria and reviewed by cardiologists. A defining feature of CODE-II is a set of 66 clinically meaningful diagnostic classes, developed with cardiologist input and routinely used in telehealth practice. We additionally provide an open available subset: CODE-II-open, a public subset of 15,000 patients, and the CODE-II-test, a non-overlapping set of 8,475 exams reviewed by multiple cardiologists for blinded evaluation. A neural network pre-trained on CODE-II achieved superior transfer performance on external benchmarks (PTB-XL and CPSC 2018) and outperformed alternatives trained on larger datasets."}
{"id": "2511.15699", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2511.15699", "abs": "https://arxiv.org/abs/2511.15699", "authors": ["Jingkai Ying", "Zhijin Qin", "Yulong Feng", "Liejun Wang", "Xiaoming Tao"], "title": "Joint Semantic-Channel Coding and Modulation for Token Communications", "comment": "14 pages, 14 figures, 2 tables", "summary": "In recent years, the Transformer architecture has achieved outstanding performance across a wide range of tasks and modalities. Token is the unified input and output representation in Transformer-based models, which has become a fundamental information unit. In this work, we consider the problem of token communication, studying how to transmit tokens efficiently and reliably. Point cloud, a prevailing three-dimensional format which exhibits a more complex spatial structure compared to image or video, is chosen to be the information source. We utilize the set abstraction method to obtain point tokens. Subsequently, to get a more informative and transmission-friendly representation based on tokens, we propose a joint semantic-channel and modulation (JSCCM) scheme for the token encoder, mapping point tokens to standard digital constellation points (modulated tokens). Specifically, the JSCCM consists of two parallel Point Transformer-based encoders and a differential modulator which combines the Gumel-softmax and soft quantization methods. Besides, the rate allocator and channel adapter are developed, facilitating adaptive generation of high-quality modulated tokens conditioned on both semantic information and channel conditions. Extensive simulations demonstrate that the proposed method outperforms both joint semantic-channel coding and traditional separate coding, achieving over 1dB gain in reconstruction and more than 6x compression ratio in modulated symbols."}
{"id": "2511.14969", "categories": ["eess.AS", "cs.AI", "cs.LG", "eess.IV", "eess.SP"], "pdf": "https://arxiv.org/pdf/2511.14969", "abs": "https://arxiv.org/abs/2511.14969", "authors": ["Zanxu Wang", "Homayoon Beigi"], "title": "Quality-Controlled Multimodal Emotion Recognition in Conversations with Identity-Based Transfer Learning and MAMBA Fusion", "comment": "8 pages, 14 images, 3 tables, Recognition Technologies, Inc. Technical Report RTI-20251118-01", "summary": "This paper addresses data quality issues in multimodal emotion recognition in conversation (MERC) through systematic quality control and multi-stage transfer learning. We implement a quality control pipeline for MELD and IEMOCAP datasets that validates speaker identity, audio-text alignment, and face detection. We leverage transfer learning from speaker and face recognition, assuming that identity-discriminative embeddings capture not only stable acoustic and Facial traits but also person-specific patterns of emotional expression. We employ RecoMadeEasy(R) engines for extracting 512-dimensional speaker and face embeddings, fine-tune MPNet-v2 for emotion-aware text representations, and adapt these features through emotion-specific MLPs trained on unimodal datasets. MAMBA-based trimodal fusion achieves 64.8% accuracy on MELD and 74.3% on IEMOCAP. These results show that combining identity-based audio and visual embeddings with emotion-tuned text representations on a quality-controlled subset of data yields consistent competitive performance for multimodal emotion recognition in conversation and provides a basis for further improvement on challenging, low-frequency emotion classes."}

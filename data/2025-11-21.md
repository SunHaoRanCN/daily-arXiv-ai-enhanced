<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.SD](#cs.SD) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Rapid and Accurate Changepoint Detection of Power System Forced Oscillations](https://arxiv.org/abs/2511.15812)
*Luke Dosiek,Akaash Karn,Frank Liu*

Main category: eess.SP

TL;DR: 提出了一种使用变点检测(CPD)来估计电力系统数据中强制振荡起止时间的新方法，通过手动设置PELT算法的惩罚参数，大幅减少计算时间而不损失精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用PELT算法自动调整惩罚参数，计算成本高。需要一种更高效的方法来准确检测强制振荡的起止时间。

Method: 采用PELT算法进行变点检测，但手动提供惩罚参数而非自动调整，同时减少输入参数数量，提供数据驱动的方法设置最小FO段长度。

Result: 在minniWECC模型测试中，计算时间减少98%，同时保持高估计精度。

Conclusion: 该方法显著提高了强制振荡检测的计算效率，同时保持了准确性，为电力系统振荡监测提供了更实用的解决方案。

Abstract: This paper describes a new approach for using changepoint detection (CPD) to estimate the starting and stopping times of a forced oscillation (FO) in measured power system data. As with a previous application of CPD to this problem, the pruned exact linear time (PELT) algorithm is used. However, instead of allowing PELT to automatically tune its penalty parameter, a method of manually providing it is presented that dramatically reduces computation time without sacrificing accuracy. Additionally, the new algorithm requires fewer input parameters and provides a formal, data-driven approach to setting the minimum FO segment length to consider as troublesome for an electromechanical mode meter. A low-order ARMAX representation of the minniWECC model is used to test the approach, where a 98\% reduction in computation time is enjoyed with high estimation accuracy.

</details>


### [2] [EEG Emotion Recognition Through Deep Learning](https://arxiv.org/abs/2511.15902)
*Roman Dolgopolyi,Antonis Chatzipanagiotou*

Main category: eess.SP

TL;DR: 开发了基于CNN-Transformer架构的EEG情绪分类模型，使用5个电极实现91%准确率，支持低成本家用EEG设备部署。


<details>
  <summary>Details</summary>
Motivation: 解决传统情绪识别方法在面部表情或声音线索受限场景下的不足，为医疗健康平台提供连续被动情绪监测方案。

Method: 融合SEED、SEED-FRA和SEED-GER数据集，构建1455个样本的多样化数据集，采用CNN-Transformer混合架构进行情绪分类。

Result: 测试准确率达91%，优于SVM、DNN和逻辑回归等传统模型，仅需5个电极即可实现高性能识别。

Conclusion: 该技术为媒体内容引发的情绪变化研究奠定基础，有望变革心理健康诊断和干预方式，特别适用于临床和护理场景。

Abstract: An advanced emotion classification model was developed using a CNN-Transformer architecture for emotion recognition from EEG brain wave signals, effectively distinguishing among three emotional states, positive, neutral and negative. The model achieved a testing accuracy of 91%, outperforming traditional models such as SVM, DNN, and Logistic Regression. Training was conducted on a custom dataset created by merging data from SEED, SEED-FRA, and SEED-GER repositories, comprising 1,455 samples with EEG recordings labeled according to emotional states. The combined dataset represents one of the largest and most culturally diverse collections available. Additionally, the model allows for the reduction of the requirements of the EEG apparatus, by leveraging only 5 electrodes of the 62. This reduction demonstrates the feasibility of deploying a more affordable consumer-grade EEG headset, thereby enabling accessible, at-home use, while also requiring less computational power. This advancement sets the groundwork for future exploration into mood changes induced by media content consumption, an area that remains underresearched. Integration into medical, wellness, and home-health platforms could enable continuous, passive emotional monitoring, particularly beneficial in clinical or caregiving settings where traditional behavioral cues, such as facial expressions or vocal tone, are diminished, restricted, or difficult to interpret, thus potentially transforming mental health diagnostics and interventions...

</details>


### [3] [Integrated Coexistence for Satellite and Terrestrial Networks with Multistatic ISAC](https://arxiv.org/abs/2511.15947)
*Jeongju Jee,Jeffrey G. Andrews*

Main category: eess.SP

TL;DR: 提出了一种卫星与地面网络共存合作框架，通过预优化和细化阶段利用卫星CSI的可预测性，结合波束成形和功率分配优化，实现频谱共享下的性能提升。


<details>
  <summary>Details</summary>
Motivation: 6G时代LEO卫星通信与地面ISAC的紧密集成需要频谱共享，但这可能导致严重干扰，需要解决实际CSI获取不理想的问题。

Method: 采用预优化和细化两阶段结构，利用卫星CSI可预测性，提出地面波束成形与卫星功率分配的协同设计，以及多静态ISAC的目标-雷达关联方法。

Result: 仿真结果显示该方法显著提升集成网络性能，随着波束数量和雷达接收器增加，整体性能接近无干扰基准。

Conclusion: 证明了卫星与地面网络频谱共存的可行性，为6G集成网络提供了实用解决方案。

Abstract: Tightly integrated low earth orbit (LEO) satellite communications and terrestrial integrated sensing and communication (ISAC) are expected to be key novel aspects of the 6G era. Spectrum sharing between satellite and terrestrial cellular networks may, however, cause severe interference. This paper introduces a cooperation framework for integrated coexistence between satellite and terrestrial networks where the terrestrial network also deploys multistatic ISAC. Unlike prior works that assume ideal channel state information (CSI) acquisition, the proposed approach develops a practical structure consisting of pre-optimization and refinement stages that leverages the predictability of satellite CSI. In addition, a co-design of terrestrial beamforming and satellite power allocation utilizing a weighted minimum mean-squared error algorithm is proposed, and a target-radar association method designed for multistatic ISAC is presented. Simulation results show that the proposed approach significantly enhances the performance of these integrated networks. Furthermore, it is confirmed that the overall performance approaches the interference-free benchmark as the number of spot beams and radar receivers increases, demonstrating the feasibility of spectral coexistence between the two networks.

</details>


### [4] [Joint Admission Control and Power Minimization in IRS-assisted Networks](https://arxiv.org/abs/2511.16000)
*Weijie Xiong,Jingran Lin,Zhiling Xiao,Qiang Li,Yuhan Zhang*

Main category: eess.SP

TL;DR: 提出了一种基于sigmoid函数近似l0范数的联合准入控制和功率最小化方法，使用惩罚对偶分解算法优化波束成形和准入控制，降低了计算复杂度并提高了性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖l1范数近似和交替优化技术，存在计算复杂度高、缺乏鲁棒收敛保证的问题。

Method: 使用sigmoid函数近似l0范数准入控制指示器，引入惩罚对偶分解算法联合优化波束成形和准入控制。

Result: 相比现有方法，实现了更低的功耗、容纳更多用户、减少计算时间，并支持分布式实现。

Conclusion: 该方法在智能反射表面辅助网络中有效解决了联合准入控制和功率最小化问题，具有更好的性能和收敛保证。

Abstract: Joint admission control and power minimization are critical challenges in intelligent reflecting surface (IRS)-assisted networks. Traditional methods often rely on \( l_1 \)-norm approximations and alternating optimization (AO) techniques, which suffer from high computational complexity and lack robust convergence guarantees. To address these limitations, we propose a sigmoid-based approximation of the \( l_0 \)-norm AC indicator, enabling a more efficient and tractable reformulation of the problem. Additionally, we introduce a penalty dual decomposition (PDD) algorithm to jointly optimize beamforming and admission control, ensuring convergence to a stationary solution. This approach reduces computational complexity and supports distributed implementation. Moreover, it outperforms existing methods by achieving lower power consumption, accommodating more users, and reducing computational time.

</details>


### [5] [UT-OSANet: A Multimodal Deep Learning model for Evaluating and Classifying Obstructive Sleep Apnea](https://arxiv.org/abs/2511.16169)
*Zijian Wang,Xiaoyu Bao,Chenhao Zhao,Jihui Zhang,Sizhi Ai,Yuanqing Li*

Main category: eess.SP

TL;DR: UT OSANet是一个基于深度学习的阻塞性睡眠呼吸暂停(OSA)事件级多场景诊断工具，能够高精度识别呼吸暂停、低通气、血氧下降和觉醒等事件，支持灵活输入模态组合。


<details>
  <summary>Details</summary>
Motivation: 现有OSA诊断方法只能粗略分类严重程度或检测孤立呼吸事件，缺乏高分辨率的事件级诊断精度和全面性。

Method: 采用随机掩码模态组合训练策略，利用EEG、气流和SpO2等可调输入模态，理解跨模态关系并在不同模态条件下保持稳定性能。基于9,021个多导睡眠图记录进行训练和评估。

Result: 在家庭、临床和研究三种场景下，灵敏度最高达0.93，宏F1分数分别为0.84和0.85，表现优异。

Conclusion: 该模型可作为OSA实际应用的事件级多场景诊断工具，同时有助于深入理解睡眠障碍中呼吸过程的机制及其广泛健康影响。

Abstract: Obstructive sleep apnea (OSA) is a highly prevalent sleep disorder that is associated with increased risks of cardiovascular morbidity and all-cause mortality. While existing diagnostic approaches can roughly classify OSA severity or detect isolated respiratory events, they lack the precision and comprehensiveness required for high resolution, event level diagnosis. Here, we present UT OSANet, a deep learning based model designed as a event level, multi scenario diagnostic tool for OSA. This model facilitates detailed identification of events associated with OSA, including apnea, hypopnea, oxygen desaturation, and arousal. Moreover, the model employs flexibly adjustable input modalities such as electroencephalography (EEG), airflow, and SpO 2. It utilizes a random masked modality combination training strategy, allowing it to comprehend cross-modal relationships while sustaining consistent performance across varying modality conditions. This model was trained and evaluated utilizing 9,021 polysomnography (PSG) recordings from five independent datasets. achieving sensitivities up to 0.93 and macro F1 scores of 0.84, 0.85 across home, clinical, and research scenarios. This model serves as an event-level, multi-scenario diagnostic instrument for real-world applications of OSA, while also establishing itself as a means to deepen the mechanistic comprehension of respiratory processes in sleep disorders and their extensive health implications.

</details>


### [6] [Low-Complexity Rydberg Array Reuse: Modeling and Receiver Design for Sparse Channels](https://arxiv.org/abs/2511.16260)
*Hao Wu,Shanchi Wu,Xinyuan Yao,Rui Ni,Chen Gong*

Main category: eess.SP

TL;DR: 本文提出了一种低复杂度的多路复用里德堡阵列设计，通过混合模拟-数字波束成形架构来解决传统里德堡阵列因多个激光装置导致系统笨重的问题。


<details>
  <summary>Details</summary>
Motivation: 当前里德堡阵列天线主要依赖多个单天线单元的简单堆叠，由于原子传感器的特殊要求（特别是需要多个空间分离的激光装置），导致系统笨重，难以在实际应用中实现和制造。

Method: 借鉴传统射频阵列天线中的混合模拟-数字波束成形方法，系统研究了低复杂度的多路复用里德堡阵列的设计原理、等效建模和预编码策略。

Result: 该方法显著降低了与全数字波束成形相关的硬件复杂性，同时性能接近全数字波束成形。

Conclusion: 多路复用里德堡传感器阵列架构对于实现实用且可扩展的量子增强通信系统至关重要。

Abstract: Rydberg atomic quantum receivers have been seen as novel radio frequency measurements and the high sensitivity to a large range of frequencies makes it attractive for communications reception. However, current implementations of Rydberg array antennas predominantly rely on simple stacking of multiple single-antenna units. While conceptually straightforward, this approach leads to substantial system bulkiness due to the unique requirements of atomic sensors, particularly the need for multiple spatially separated laser setups, rendering such designs both impractical for real-world applications and challenging to fabricate. This limitation underscores the critical need for developing multiplexed Rydberg sensor array architectures. In the domain of conventional RF array antennas, hybrid analog-digital beamforming has emerged as a pivotal architecture for large-scale millimeter-wave (mmWave) multiple-input multiple-output (MIMO) systems, as it substantially reduces the hardware complexity associated with fully-digital beamforming while closely approaching its performance. Drawing inspiration from this methodology, we conduct a systematic study in this work on the design principles, equivalent modeling, and precoding strategies for low-complexity multiplexed Rydberg array, an endeavor crucial to enabling practical and scalable quantum-enhanced communication systems.

</details>


### [7] [Dynamic Multiple-Parameter Joint Time-Vertex Fractional Fourier Transform and its Intelligent Filtering Methods](https://arxiv.org/abs/2511.16277)
*Manjun Cui,Ziqi Yan,Yangfan He,Zhichao Zhang*

Main category: eess.SP

TL;DR: 提出了一种动态多参数联合时-顶点分数傅里叶变换框架，通过引入时变分数参数来建模动态图信号的复杂演化过程。


<details>
  <summary>Details</summary>
Motivation: 现有的联合时-顶点变换只能为空间域和时间域分别分配一个固定分数阶，无法有效建模图信号的复杂动态变化。

Method: 提出了DMPJFRFT框架，为每个时间步分配不同的分数阶，实现自适应谱建模；开发了基于梯度下降和神经网络的两类滤波方法用于动态信号恢复。

Result: 在动态图和视频数据集上的实验表明，该框架能有效捕捉时间拓扑变化，在去噪和去模糊任务中优于现有图变换方法和神经网络。

Conclusion: DMPJFRFT框架通过时变分数参数提供了更灵活的动态图信号表示，在动态信号处理任务中表现出优越性能。

Abstract: Dynamic graph signal processing provides a principled framework for analyzing time-varying data defined on irregular graph domains. However, existing joint time-vertex transforms such as the joint time-vertex fractional Fourier transform assign only one fractional order to the spatial domain and another one to the temporal domain, thereby restricting their capacity to model the complex and continuously varying dynamics of graph signals. To address this limitation, we propose a novel dynamic multiple-parameter joint time-vertex fractional Fourier transform (DMPJFRFT) framework, which introduces time-varying fractional parameters to achieve adaptive spectral modeling of dynamic graph structures. By assigning distinct fractional orders to each time step, the proposed transform enables dynamic and flexible representation of spatio-temporal signal evolution in the joint time-vertex spectral domain. Theoretical properties of the DMPJFRFT are systematically analyzed, and two filtering approaches: a gradient descent-based method and a neural network-based method, are developed for dynamic signal restoration. Experimental results on dynamic graph and video datasets demonstrate that the proposed framework effectively captures temporal topology variations and achieves superior performance in denoising and deblurring tasks compared with some state-of-the-art graph-based transforms and neural networks.

</details>


### [8] [Revealing computation-communication trade-off in Segmented Pinching Antenna System (PASS)](https://arxiv.org/abs/2511.16327)
*Deqiao Gan,Xiaoxia Xu,Xiaohu Ge,Yuanwei Liu*

Main category: eess.SP

TL;DR: 提出了一种使用分段夹持天线系统的联合通信与计算框架，通过分段设计改善上行传输性能，分别针对计算导向和通信导向场景开发了AO-MMSE和AO-WMMSE算法，显著降低了MSE并提高了加权和速率。


<details>
  <summary>Details</summary>
Motivation: 传统通信系统难以同时高效处理通信比特流和计算数据的传输，需要开发能够同时优化通信和计算性能的联合框架，以应对大规模路径损耗和波导内损耗的挑战。

Method: 采用分段夹持天线系统设计，提出三种操作协议（段选择、段聚合、段复用），针对计算导向场景开发AO-MMSE算法，针对通信导向场景开发AO-WMMSE算法，通过交替优化求解收发波束成形问题。

Result: 仿真结果显示：与传统的MIMO和PASS相比，所提框架在MSE方面分别降低了70.65%和45.32%，在加权和速率方面分别提高了87.70%和51.35%。

Conclusion: 分段JCC-PASS框架在联合通信与计算性能方面显著优于传统方法，为未来无线通信系统提供了有效的解决方案。

Abstract: A joint communication and computation (JCC) framework using segmented pinching antenna system (PASS) is proposed, where both the communication bit streams and computation data are simultaneously transmitted via uplink communications. The segmented PASS design is used to yield the tractable uplink transmission, and to mitigate large-scale path loss and in-waveguide loss. Based on three operating protocols, namely segment selection (SS), segment aggregation (SA), and segment multiplexing (SM), the joint transmit and receive beamforming problem is formulated: 1) The mean square error (MSE) minimization problem is formulated for computation-oriented cases. To address this problem, a low-complexity alternating optimization-minimum mean square error (AO-MMSE) algorithm is developed. This problem is decomposed into receiver-side and transmitter-side MSE subproblems that are iteratively optimized by MMSE receivers to obtain the closed-form solutions. It is mathematically proved that the segmented JCC-PASS framework significantly outperforms the conventional PASS for the average in-waveguide propagation gain. 2) The weighted sum rate (WSR) maximization problem is formulated for communication-oriented cases. To solve the decomposed receiver-side and transmitter-side MSE subproblems, the AO-weighted minimum mean square error (AO-WMMSE) algorithm is further developed. An auxiliary weight variable is introduced to linearize the WSR function and is alternatively optimized based on WMMSE to derive the closed-form solutions. Simulation results demonstrate that: i) The proposed JCC-PASS framework achieves up to 70.65% and 45.32% reductions in MSE compared with conventional MIMO and conventional PASS, and ii) it reaches 87.70% and 51.35% improvements in WSR compared with conventional MIMO and conventional PASS, respectively.

</details>


### [9] [VersaPants: A Loose-Fitting Textile Capacitive Sensing System for Lower-Body Motion Capture](https://arxiv.org/abs/2511.16346)
*Deniz Kasap,Taraneh Aminosharieh Najafi,Jérôme Paul Rémy Thevenot,Jonathan Dan,Stefano Albini,David Atienza*

Main category: eess.SP

TL;DR: VersaPants是首个基于纺织品的电容传感系统，用于下肢运动捕捉，通过集成导电纺织贴片和紧凑采集单元到裤子中，在不影响舒适度的情况下重建下肢姿态。


<details>
  <summary>Details</summary>
Motivation: 现有IMU系统需要用户特定拟合，基于摄像头的方法会损害隐私。VersaPants无需拟合调整且保护用户隐私，旨在提供舒适、可扩展的运动捕捉解决方案。

Method: 使用6个电容通道每腿，采用轻量级Transformer深度学习模型将电容信号映射到关节角度，可在边缘平台上嵌入式实现。

Result: 在11名参与者约3.7小时运动数据上测试，平均关节位置误差11.96cm，平均关节角度误差12.3度，模型能够泛化到未见过的用户和动作。

Conclusion: VersaPants在竞争性重建性能下，参数减少22倍，FLOPs减少18倍，在商用智能手表上实现42FPS实时推理，为健身、医疗和健康应用提供了有前景的嵌入式运动捕捉解决方案。

Abstract: We present VersaPants, the first loose-fitting, textile-based capacitive sensing system for lower-body motion capture, built on the open-hardware VersaSens platform. By integrating conductive textile patches and a compact acquisition unit into a pair of pants, the system reconstructs lower-body pose without compromising comfort. Unlike IMU-based systems that require user-specific fitting or camera-based methods that compromise privacy, our approach operates without fitting adjustments and preserves user privacy. VersaPants is a custom-designed smart garment featuring 6 capacitive channels per leg. We employ a lightweight Transformer-based deep learning model that maps capacitance signals to joint angles, enabling embedded implementation on edge platforms. To test our system, we collected approximately 3.7 hours of motion data from 11 participants performing 16 daily and exercise-based movements. The model achieves a mean per-joint position error (MPJPE) of 11.96 cm and a mean per-joint angle error (MPJAE) of 12.3 degrees across the hip, knee, and ankle joints, indicating the model's ability to generalize to unseen users and movements. A comparative analysis of existing textile-based deep learning architectures reveals that our model achieves competitive reconstruction performance with up to 22 times fewer parameters and 18 times fewer FLOPs, enabling real-time inference at 42 FPS on a commercial smartwatch without quantization. These results position VersaPants as a promising step toward scalable, comfortable, and embedded motion-capture solutions for fitness, healthcare, and wellbeing applications.

</details>


### [10] [Neural Positioning Without External Reference](https://arxiv.org/abs/2511.16352)
*Till-Yannic Müller,Frederik Zumegen,Reinhard Wiesmayr,Emre Gönültaş,Christoph Studer*

Main category: eess.SP

TL;DR: 提出了一种无需外部参考定位系统的神经网络定位方法，仅使用采集的CSI数据和商用机器人平台的相对位移命令来训练定位网络，在Wi-Fi和5G系统中实现了接近最先进方法的定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于CSI的神经网络定位方法需要从外部参考定位系统获取地面真实位置标签，这需要昂贵的硬件且在大面积区域中标签获取困难。

Method: 提出新的神经网络定位流程，仅使用离设备采集的CSI数据和商用机器人平台执行的相对位移命令来训练定位网络，无需外部参考定位系统。

Result: 在三个真实场景（从小型视距区域到大型非视距环境）中评估，使用IEEE 802.11 Wi-Fi和5G NR系统的CSI测量，实现了接近需要外部高精度地面真实位置标签训练的最先进方法的定位精度。

Conclusion: 该方法能够在大面积区域上以低成本训练准确的神经网络定位功能，避免了对外部参考定位系统的依赖。

Abstract: Channel state information (CSI)-based user equipment (UE) positioning with neural networks -- referred to as neural positioning -- is a promising approach for accurate off-device UE localization. Most existing methods train their neural networks with ground-truth position labels obtained from external reference positioning systems, which requires costly hardware and renders label acquisition difficult in large areas. In this work, we propose a novel neural positioning pipeline that avoids the need for any external reference positioning system. Our approach trains the positioning network only using CSI acquired off-device and relative displacement commands executed on commercial off-the-shelf (COTS) robot platforms, such as robotic vacuum cleaners -- such an approach enables inexpensive training of accurate neural positioning functions over large areas. We evaluate our method in three real-world scenarios, ranging from small line-of-sight (LoS) areas to larger non-line-of-sight (NLoS) environments, using CSI measurements acquired in IEEE 802.11 Wi-Fi and 5G New Radio (NR) systems. Our experiments demonstrate that the proposed neural positioning pipeline achieves UE localization accuracies close to state-of-the-art methods that require externally acquired high-precision ground-truth position labels for training.

</details>


### [11] [Reasoning Meets Representation: Envisioning Neuro-Symbolic Wireless Foundation Models](https://arxiv.org/abs/2511.16369)
*Jaron Fontaine,Mohammad Cheraghinia,John Strassner,Adnan Shahid,Eli De Poorter*

Main category: eess.SP

TL;DR: 提出神经符号范式，将数据驱动的神经网络与基于规则的符号推理相结合，以解决无线物理层基础模型在可解释性、鲁棒性和合规性方面的局限性。


<details>
  <summary>Details</summary>
Motivation: 无线物理层基础模型存在可解释性、鲁棒性、适应性和物理/监管约束合规性等关键限制，而6G网络需要深度嵌入且可信的智能系统。

Method: 设计神经符号框架，将通用RF嵌入与符号知识图谱和可微分逻辑层集成，实现从大数据学习与显式领域知识推理的结合。

Result: 该混合方法能够实现可信、可泛化且高效的无线AI，满足未来网络需求。

Conclusion: 神经符号范式对于弥合当前无线AI能力与6G网络需求之间的差距至关重要。

Abstract: Recent advances in Wireless Physical Layer Foundation Models (WPFMs) promise a new paradigm of universal Radio Frequency (RF) representations. However, these models inherit critical limitations found in deep learning such as the lack of explainability, robustness, adaptability, and verifiable compliance with physical and regulatory constraints. In addition, the vision for an AI-native 6G network demands a level of intelligence that is deeply embedded into the systems and is trustworthy. In this vision paper, we argue that the neuro-symbolic paradigm, which integrates data-driven neural networks with rule- and logic-based symbolic reasoning, is essential for bridging this gap. We envision a novel Neuro-Symbolic framework that integrates universal RF embeddings with symbolic knowledge graphs and differentiable logic layers. This hybrid approach enables models to learn from large datasets while reasoning over explicit domain knowledge, enabling trustworthy, generalizable, and efficient wireless AI that can meet the demands of future networks.

</details>


### [12] [3-20 GHz Wideband Tightly-Coupled Dual-Polarized Vivaldi Antenna Array](https://arxiv.org/abs/2511.16472)
*Niko Lindvall,Mikko Heino,Mikko Valkama*

Main category: eess.SP

TL;DR: 提出了一种新型紧密耦合双极化对跖维瓦尔第天线，通过重叠天线叶片实现紧密耦合，将低频边缘从3.75GHz扩展到3GHz和2.75GHz，带宽提升20-25%。


<details>
  <summary>Details</summary>
Motivation: 定位、传感、频谱监测和现代扩频系统需要超宽带孔径，维瓦尔第天线因其天然宽带特性成为理想选择，但现有紧密耦合阵列研究多集中于偶极子单元而非双极化维瓦尔第天线。

Method: 设计紧密耦合双极化对跖维瓦尔第天线，通过重叠维瓦尔第天线叶片实现单元间的强互耦合。

Result: 实现了3-20GHz的-6dB阻抗带宽，相比孤立对跖维瓦尔第单元，低频边缘从3.75GHz扩展到3GHz和2.75GHz，带宽提升20-25%。

Conclusion: 紧密耦合技术可有效扩展双极化维瓦尔第天线的低频性能，为超宽带系统提供紧凑阵列解决方案。

Abstract: Very wideband apertures are needed in positioning, sensing, spectrum monitoring, and modern spread spectrum, e.g., frequency hopping systems. Vivaldi antennas are one of the prominent choices for the aforementioned systems due to their natural wideband characteristics. Furthermore, tightly-coupled antenna arrays have been researched in the recent years to extend the lower band edge of compact arrays by taking advantage of the strong mutual coupling between the elements especially with dipole elements, but not with dual-polarized Vivaldi antennas. This paper presents a novel tightly-coupled dual-polarized antipodal Vivaldi antenna (TC-AVA) with -6 dB impedance bandwidth of 3 to 20 GHz. The tight coupling by overlapping the Vivaldi leaves is shown to extend the lower band edge from 3.75 to 3 GHz and 2.75 GHz, an improvement of 20% to 25% for both polarizations, compared with an isolated antipodal Vivaldi element.

</details>


### [13] [TFCDiff: Robust ECG Denoising via Time-Frequency Complementary Diffusion](https://arxiv.org/abs/2511.16627)
*Pengxin Li,Yimin Zhou,Jie Min,Yirong Wang,Wei Liang,Wang Li*

Main category: eess.SP

TL;DR: TFCDiff是一种在DCT域操作的新型ECG去噪方法，使用时间-频率互补扩散模型和时域特征增强机制，在合成数据集和SimEMG数据库上实现最先进性能。


<details>
  <summary>Details</summary>
Motivation: 动态心电图容易受到多种噪声干扰（基线漂移、肌肉伪影、电极运动伪影），影响诊断准确性。多拍ECG段的去噪研究不足且技术挑战大。

Method: 在离散余弦变换域操作，使用噪声信号的DCT系数作为条件输入，结合时间-频率互补扩散模型和时域特征增强机制来强化时域表示并保留关键生理信息。

Result: 在合成数据集上五个评估指标均达到最先进性能，在未见过的SimEMG数据库上表现出优越的泛化能力，优于所有基准模型。

Conclusion: TFCDiff能够处理原始10秒序列并在灵活随机混合噪声下保持鲁棒性，可在可穿戴ECG监测器中即插即用部署，适用于高运动场景。

Abstract: Ambulatory electrocardiogram (ECG) readings are prone to mixed noise from physical activities, including baseline wander (BW), muscle artifact (MA), and electrode motion artifact (EM). Developing a method to remove such complex noise and reconstruct high-fidelity signals is clinically valuable for diagnostic accuracy. However, denoising of multi-beat ECG segments remains understudied and poses technical challenges. To address this, we propose Time-Frequency Complementary Diffusion (TFCDiff), a novel approach that operates in the Discrete Cosine Transform (DCT) domain and uses the DCT coefficients of noisy signals as conditioning input. To refine waveform details, we incorporate Temporal Feature Enhancement Mechanism (TFEM) to reinforce temporal representations and preserve key physiological information. Comparative experiments on a synthesized dataset demonstrate that TFCDiff achieves state-of-the-art performance across five evaluation metrics. Furthermore, TFCDiff shows superior generalization on the unseen SimEMG Database, outperforming all benchmark models. Notably, TFCDiff processes raw 10-second sequences and maintains robustness under flexible random mixed noise (fRMN), enabling plug-and-play deployment in wearable ECG monitors for high-motion scenarios. Source code is available at https://github.com/Miroircivil/TFCDiff.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [14] [A Generalized Weighted Overlap-Add (WOLA) Filter Bank for Improved Subband System Identification](https://arxiv.org/abs/2511.15766)
*Mohit Sharma,Robbe Van Rompaey,Wouter Lanneer,Marc Moonen*

Main category: eess.AS

TL;DR: 本文提出了一种广义WOLA滤波器组，通过将子带滤波器重新定位到降采样操作之前，消除了传统WOLA滤波器组对子带滤波器的约束，显著提升了子带系统识别的性能，并提出了计算复杂度与常规WOLA相当的PT-WOLA实现。


<details>
  <summary>Details</summary>
Motivation: 传统STFT域子带自适应滤波主要关注在降采样率下使用WOLA滤波器组的设置，但这种方法在转换为全速率表示时对子带滤波器施加了约束，限制了系统识别性能。

Method: 1. 引入广义WOLA滤波器组，重新定位子带滤波器位置；2. 分析广义WOLA在系统识别中的MSE性能；3. 提出低复杂度PT-WOLA实现。

Result: 分析和实验证明，广义WOLA滤波器组显著提升了子带系统识别的性能，PT-WOLA在保持性能的同时将计算复杂度降至与常规WOLA相当的水平。

Conclusion: 广义WOLA滤波器组通过消除传统约束改善了子带系统识别，而PT-WOLA提供了实用的低复杂度实现方案。

Abstract: This paper addresses the challenges in short-time Fourier transform (STFT) domain subband adaptive filtering, in particular, subband system identification. Previous studies in this area have primarily focused on setups with subband filtering at a downsampled rate, implemented using the weighted overlap-add (WOLA) filter bank, popular in audio and speech-processing for its reduced complexity. However, this traditional approach imposes constraints on the subband filters when transformed to their full-rate representation. This paper makes three key contributions. First, it introduces a generalized WOLA filter bank that repositions subband filters before the downsampling operation, eliminating the constraints on subband filters inherent in the conventional WOLA filter bank. Second, it investigates the mean square error (MSE) performance of the generalized WOLA filter bank for full-band system identification, establishing analytical ties between the order of subband filters, the full-band system impulse response length, the decimation factor, and the prototype filters. Third, to address the increased computational complexity of the generalized WOLA, the paper proposes a low-complexity implementation termed per-tone weighted overlap-add (PT-WOLA), which maintains computational complexity on par with conventional WOLA. Analytical and empirical evidence demonstrates that the proposed generalized WOLA filter bank significantly enhances the performance of subband system identification.

</details>


### [15] [Train Short, Infer Long: Speech-LLM Enables Zero-Shot Streamable Joint ASR and Diarization on Long Audio](https://arxiv.org/abs/2511.16046)
*Mohan Shi,Xiong Xiao,Ruchao Fan,Shaoshi Ling,Jinyu Li*

Main category: eess.AS

TL;DR: 提出了一个端到端的语音大语言模型JEDIS-LLM，用于联合流式说话人日志和语音识别，仅需在短音频上训练即可实现长音频的零样本流式推理。


<details>
  <summary>Details</summary>
Motivation: 解决多说话人场景下'谁说了什么'的问题，传统方法需要分别进行语音识别和说话人日志，且难以实现流式处理。

Method: 引入说话人提示缓存（SPC）机制，在分块流式推理时进行动态更新，并融入预注册说话人档案；在训练时加入词级说话人监督。

Result: 在短音频上超越Sortformer和Meta-Cat，在长音频上优于DiarizationLM，实现了最先进的性能。

Conclusion: 这是首个仅用短音频训练就能实现长音频零样本流式联合ASR和说话人日志的Speech-LLM工作。

Abstract: Joint automatic speech recognition (ASR) and speaker diarization aim to answer the question "who spoke what" in multi-speaker scenarios. In this paper, we present an end-to-end speech large language model (Speech-LLM) for Joint strEamable DIarization and aSr (JEDIS-LLM). The model is trained only on short audio under 20s but is capable of streamable inference on long-form audio without additional training. This is achieved by introducing a Speaker Prompt Cache (SPC) with an on-the-fly update mechanism during chunk-wise streaming inference, inspired by the autoregressive nature of LLMs. The SPC also allows the seamless use of pre-enrolled speaker profiles which is common in many scenarios like meeting transcription. To further enhance diarization capability, we incorporate word-level speaker supervision into the speech encoder during training. Experimental results demonstrate that our system outperforms strong baselines, including Sortformer and Meta-Cat in the local setting on audio up to 20s, and DiarizationLM on long-form audio, despite being fully end-to-end and streamable while DiarizationLM follows a cascaded offline pipeline. To the best of our knowledge, this is the first work enabling zero-shot streamable joint ASR and diarization on long audio using a Speech-LLM trained only on short audio, achieving state-of-the-art performance.

</details>


### [16] [SUNAC: Source-aware Unified Neural Audio Codec](https://arxiv.org/abs/2511.16126)
*Ryo Aihara,Yoshiki Masuyama,Francesco Paissan,François G. Germain,Gordon Wichern,Jonathan Le Roux*

Main category: eess.AS

TL;DR: 提出了一种源感知音频编解码器，能够直接从混合音频中编码单个声源，并通过源类型提示进行条件控制，实现用户驱动的声源选择。


<details>
  <summary>Details</summary>
Motivation: 传统神经音频编解码器对多个声源的混合进行纠缠编码，这在需要访问特定声源子集的下游应用中效率低下。

Method: 开发了源感知编解码器，通过源类型提示直接从混合音频中编码单个声源，支持用户选择要编码的声源，包括相同类型的多个声源。

Result: 实验表明，该模型在重合成和分离质量上与传统源分离后接常规编解码器的级联方法相当，但计算成本更低。

Conclusion: 源感知编解码器提供了一种高效的方法来编码混合音频中的特定声源，为下游应用提供了更好的灵活性和效率。

Abstract: Neural audio codecs (NACs) provide compact representations that can be leveraged in many downstream applications, in particular large language models. Yet most NACs encode mixtures of multiple sources in an entangled manner, which may impede efficient downstream processing in applications that need access to only a subset of the sources (e.g., analysis of a particular type of sound, transcription of a given speaker, etc). To address this, we propose a source-aware codec that encodes individual sources directly from mixtures, conditioned on source type prompts. This enables user-driven selection of which source(s) to encode, including separately encoding multiple sources of the same type (e.g., multiple speech signals). Experiments show that our model achieves competitive resynthesis and separation quality relative to a cascade of source separation followed by a conventional NAC, with lower computational cost.

</details>


### [17] [Codec2Vec: Self-Supervised Speech Representation Learning Using Neural Speech Codecs](https://arxiv.org/abs/2511.16639)
*Wei-Cheng Tseng,David Harwath*

Main category: eess.AS

TL;DR: Codec2Vec是首个基于离散音频编解码单元的语音表示学习框架，在SUPERB基准测试中表现优异，同时大幅降低存储需求和训练时间。


<details>
  <summary>Details</summary>
Motivation: 探索神经音频编解码器作为通用声学特征提取器的潜力，为更广泛的语音处理任务提供高效解决方案。

Method: 使用离散音频编解码单元构建语音表示学习框架，探索多种训练目标推导策略的掩码预测方法。

Result: 在SUPERB基准测试中达到与连续输入模型相当的性能，同时存储需求降低16.5倍，训练时间减少2.3倍。

Conclusion: Codec2Vec展示了离散音频编解码单元在语音表示学习中的有效性，具有出色的可扩展性和效率优势。

Abstract: Recent advancements in neural audio codecs have not only enabled superior audio compression but also enhanced speech synthesis techniques. Researchers are now exploring their potential as universal acoustic feature extractors for a broader range of speech processing tasks. Building on this trend, we introduce Codec2Vec, the first speech representation learning framework that relies exclusively on discrete audio codec units. This approach offers several advantages, including improved data storage and transmission efficiency, faster training, and enhanced data privacy. We explore masked prediction with various training target derivation strategies to thoroughly understand the effectiveness of this framework. Evaluated on the SUPERB benchmark, Codec2Vec achieves competitive performance compared to continuous-input models while reducing storage requirements by up to 16.5x and training time by 2.3x, showcasing its scalability and efficiency.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [18] [SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise](https://arxiv.org/abs/2511.16114)
*Rui Sang,Yuxuan Liu*

Main category: cs.SD

TL;DR: SceneGuard是一种训练时语音保护方法，通过在语音录音中添加场景一致的背景噪音来防止未经授权的语音克隆攻击。


<details>
  <summary>Details</summary>
Motivation: 现有的基于不可感知对抗扰动的语音保护方法容易受到音频预处理（如降噪和压缩）的影响，需要更鲁棒的防御方案。

Method: 利用自然发生的声学场景（如机场、街道、公园）创建上下文适当的保护性噪音，而不是使用不可感知的扰动。

Result: 在文本转语音训练攻击中，SceneGuard使说话人相似度降低5.5%（统计显著性极高，p < 10^{-15}，Cohen's d = 2.18），同时保持98.6%的语音可懂度。在五种常见对抗措施下仍能保持或增强保护效果。

Conclusion: 可听且场景一致的噪音为训练时语音保护提供了比不可感知扰动更鲁棒的替代方案。

Abstract: Voice cloning technology poses significant privacy threats by enabling unauthorized speech synthesis from limited audio samples. Existing defenses based on imperceptible adversarial perturbations are vulnerable to common audio preprocessing such as denoising and compression. We propose SceneGuard, a training-time voice protection method that applies scene-consistent audible background noise to speech recordings. Unlike imperceptible perturbations, SceneGuard leverages naturally occurring acoustic scenes (e.g., airport, street, park) to create protective noise that is contextually appropriate and robust to countermeasures. We evaluate SceneGuard on text-to-speech training attacks, demonstrating 5.5% speaker similarity degradation with extremely high statistical significance (p < 10^{-15}, Cohen's d = 2.18) while preserving 98.6% speech intelligibility (STOI = 0.986). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures including MP3 compression, spectral subtraction, lowpass filtering, and downsampling. Our results suggest that audible, scene-consistent noise provides a more robust alternative to imperceptible perturbations for training-time voice protection. The source code are available at: https://github.com/richael-sang/SceneGuard.

</details>


### [19] [Difficulty-Controlled Simplification of Piano Scores with Synthetic Data for Inclusive Music Education](https://arxiv.org/abs/2511.16228)
*Pedro Ramoneda,Emilia Parada-Cabaleiro,Dasaem Jeong,Xavier Serra*

Main category: cs.SD

TL;DR: 提出了一种基于Transformer的MusicXML钢琴谱难度调整方法，使用合成数据集而非标注数据，并开源所有资源以促进音乐教育的民主化。


<details>
  <summary>Details</summary>
Motivation: 当前AI音乐教育受限于专有系统，阻碍了技术民主化。特别是音乐难度调整技术有巨大潜力，但现有方法依赖专有数据集和MIDI格式，限制了可重复性和实用性。

Method: 使用Transformer架构调整MusicXML钢琴谱难度，创建合成数据集（包含按难度排序的钢琴谱对），利用预训练模型评估难度和风格以确保配对质量。

Result: 实验结果表明该方法能准确控制可演奏性和目标难度，定性和定量评估都验证了方法的有效性。

Conclusion: 与以往工作不同，该方法开源所有资源（代码、数据集和模型），确保可重复性并促进开源创新，帮助弥合数字鸿沟。

Abstract: Despite its potential, AI advances in music education are hindered by proprietary systems that limit the democratization of technology in this domain. In particular, AI-driven music difficulty adjustment is especially promising, as simplifying complex pieces can make music education more inclusive and accessible to learners of all ages and contexts. Nevertheless, recent efforts have relied on proprietary datasets, which prevents the research community from reproducing, comparing, or extending the current state of the art. In addition, while these generative methods offer great potential, most of them use the MIDI format, which, unlike others, such as MusicXML, lacks readability and layout information, thereby limiting their practical use for human performers. This work introduces a transformer-based method for adjusting the difficulty of MusicXML piano scores. Unlike previous methods, which rely on annotated datasets, we propose a synthetic dataset composed of pairs of piano scores ordered by estimated difficulty, with each pair comprising a more challenging and easier arrangement of the same piece. We generate these pairs by creating variations conditioned on the same melody and harmony and leverage pretrained models to assess difficulty and style, ensuring appropriate pairing. The experimental results illustrate the validity of the proposed approach, showing accurate control of playability and target difficulty, as highlighted through qualitative and quantitative evaluations. In contrast to previous work, we openly release all resources (code, dataset, and models), ensuring reproducibility while fostering open-source innovation to help bridge the digital divide.

</details>

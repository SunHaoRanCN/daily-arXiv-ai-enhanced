<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.SD](#cs.SD) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Rapid and Accurate Changepoint Detection of Power System Forced Oscillations](https://arxiv.org/abs/2511.15812)
*Luke Dosiek,Akaash Karn,Frank Liu*

Main category: eess.SP

TL;DR: 本文提出了一种使用变点检测(CPD)来估计电力系统数据中强迫振荡(FO)起止时间的新方法，通过手动设置惩罚参数显著减少计算时间，同时保持高精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法使用PELT算法自动调整惩罚参数导致计算时间较长，需要开发更高效的方法来准确检测强迫振荡的起止时间。

Method: 采用PELT算法但手动提供惩罚参数，减少输入参数数量，提供数据驱动的方法设置最小FO段长度，使用minniWECC模型的低阶ARMAX表示进行测试。

Result: 计算时间减少了98%，同时保持了高估计精度。

Conclusion: 该方法在显著减少计算时间的同时保持了检测精度，为电力系统强迫振荡检测提供了更高效的解决方案。

Abstract: This paper describes a new approach for using changepoint detection (CPD) to estimate the starting and stopping times of a forced oscillation (FO) in measured power system data. As with a previous application of CPD to this problem, the pruned exact linear time (PELT) algorithm is used. However, instead of allowing PELT to automatically tune its penalty parameter, a method of manually providing it is presented that dramatically reduces computation time without sacrificing accuracy. Additionally, the new algorithm requires fewer input parameters and provides a formal, data-driven approach to setting the minimum FO segment length to consider as troublesome for an electromechanical mode meter. A low-order ARMAX representation of the minniWECC model is used to test the approach, where a 98\% reduction in computation time is enjoyed with high estimation accuracy.

</details>


### [2] [EEG Emotion Recognition Through Deep Learning](https://arxiv.org/abs/2511.15902)
*Roman Dolgopolyi,Antonis Chatzipanagiotou*

Main category: eess.SP

TL;DR: 开发了基于CNN-Transformer架构的EEG情绪分类模型，使用5个电极实现91%准确率，支持低成本家用EEG设备部署


<details>
  <summary>Details</summary>
Motivation: 解决传统情绪识别方法在面部表情或语音线索受限场景下的不足，推动可负担的家庭情绪监测技术发展

Method: 融合SEED、SEED-FRA和SEED-GER数据集，构建1455个样本的多样化数据集，采用CNN-Transformer混合架构进行情绪分类

Result: 测试准确率达到91%，优于SVM、DNN和逻辑回归等传统模型，仅需5个电极即可实现高性能

Conclusion: 该模型为媒体内容诱导情绪变化研究和家庭心理健康监测提供了可行技术基础，有望改变心理健康诊断和干预方式

Abstract: An advanced emotion classification model was developed using a CNN-Transformer architecture for emotion recognition from EEG brain wave signals, effectively distinguishing among three emotional states, positive, neutral and negative. The model achieved a testing accuracy of 91%, outperforming traditional models such as SVM, DNN, and Logistic Regression. Training was conducted on a custom dataset created by merging data from SEED, SEED-FRA, and SEED-GER repositories, comprising 1,455 samples with EEG recordings labeled according to emotional states. The combined dataset represents one of the largest and most culturally diverse collections available. Additionally, the model allows for the reduction of the requirements of the EEG apparatus, by leveraging only 5 electrodes of the 62. This reduction demonstrates the feasibility of deploying a more affordable consumer-grade EEG headset, thereby enabling accessible, at-home use, while also requiring less computational power. This advancement sets the groundwork for future exploration into mood changes induced by media content consumption, an area that remains underresearched. Integration into medical, wellness, and home-health platforms could enable continuous, passive emotional monitoring, particularly beneficial in clinical or caregiving settings where traditional behavioral cues, such as facial expressions or vocal tone, are diminished, restricted, or difficult to interpret, thus potentially transforming mental health diagnostics and interventions...

</details>


### [3] [Integrated Coexistence for Satellite and Terrestrial Networks with Multistatic ISAC](https://arxiv.org/abs/2511.15947)
*Jeongju Jee,Jeffrey G. Andrews*

Main category: eess.SP

TL;DR: 本文提出了一个卫星与地面网络集成共存的合作框架，通过预优化和精细化阶段利用卫星CSI的可预测性，设计了地面波束成形和卫星功率分配的协同方案，以及多静态ISAC的目标-雷达关联方法。


<details>
  <summary>Details</summary>
Motivation: 6G时代LEO卫星通信与地面ISAC的紧密集成需要频谱共享，但这可能导致严重干扰，因此需要开发实用的共存合作框架。

Method: 采用预优化和精细化两阶段结构，利用卫星CSI的可预测性；提出基于加权最小均方误差算法的地面波束成形和卫星功率分配协同设计；开发多静态ISAC的目标-雷达关联方法。

Result: 仿真结果显示所提方法显著提升了集成网络性能，随着波束数量和雷达接收器增加，整体性能接近无干扰基准，证明了两个网络频谱共存的可行性。

Conclusion: 提出的合作框架有效解决了卫星与地面网络频谱共享的干扰问题，为实现6G时代卫星-地面集成网络提供了可行的技术方案。

Abstract: Tightly integrated low earth orbit (LEO) satellite communications and terrestrial integrated sensing and communication (ISAC) are expected to be key novel aspects of the 6G era. Spectrum sharing between satellite and terrestrial cellular networks may, however, cause severe interference. This paper introduces a cooperation framework for integrated coexistence between satellite and terrestrial networks where the terrestrial network also deploys multistatic ISAC. Unlike prior works that assume ideal channel state information (CSI) acquisition, the proposed approach develops a practical structure consisting of pre-optimization and refinement stages that leverages the predictability of satellite CSI. In addition, a co-design of terrestrial beamforming and satellite power allocation utilizing a weighted minimum mean-squared error algorithm is proposed, and a target-radar association method designed for multistatic ISAC is presented. Simulation results show that the proposed approach significantly enhances the performance of these integrated networks. Furthermore, it is confirmed that the overall performance approaches the interference-free benchmark as the number of spot beams and radar receivers increases, demonstrating the feasibility of spectral coexistence between the two networks.

</details>


### [4] [Joint Admission Control and Power Minimization in IRS-assisted Networks](https://arxiv.org/abs/2511.16000)
*Weijie Xiong,Jingran Lin,Zhiling Xiao,Qiang Li,Yuhan Zhang*

Main category: eess.SP

TL;DR: 提出了一种基于sigmoid函数近似l0范数的联合准入控制和功率最小化方法，使用惩罚对偶分解算法优化波束成形和准入控制，降低了计算复杂度并提高了性能。


<details>
  <summary>Details</summary>
Motivation: 传统IRS辅助网络中的联合准入控制和功率最小化方法依赖l1范数近似和交替优化技术，存在计算复杂度高、收敛性保证不足的问题。

Method: 使用sigmoid函数近似l0范数准入控制指标，提出惩罚对偶分解算法联合优化波束成形和准入控制，支持分布式实现。

Result: 相比现有方法，实现了更低的功耗、容纳更多用户、减少计算时间，并确保收敛到平稳解。

Conclusion: 所提出的方法在IRS辅助网络中有效解决了联合准入控制和功率最小化问题，具有更好的性能和实用性。

Abstract: Joint admission control and power minimization are critical challenges in intelligent reflecting surface (IRS)-assisted networks. Traditional methods often rely on \( l_1 \)-norm approximations and alternating optimization (AO) techniques, which suffer from high computational complexity and lack robust convergence guarantees. To address these limitations, we propose a sigmoid-based approximation of the \( l_0 \)-norm AC indicator, enabling a more efficient and tractable reformulation of the problem. Additionally, we introduce a penalty dual decomposition (PDD) algorithm to jointly optimize beamforming and admission control, ensuring convergence to a stationary solution. This approach reduces computational complexity and supports distributed implementation. Moreover, it outperforms existing methods by achieving lower power consumption, accommodating more users, and reducing computational time.

</details>


### [5] [UT-OSANet: A Multimodal Deep Learning model for Evaluating and Classifying Obstructive Sleep Apnea](https://arxiv.org/abs/2511.16169)
*Zijian Wang,Xiaoyu Bao,Chenhao Zhao,Jihui Zhang,Sizhi Ai,Yuanqing Li*

Main category: eess.SP

TL;DR: UT OSANet是一个基于深度学习的阻塞性睡眠呼吸暂停(OSA)事件级多场景诊断工具，能够识别呼吸暂停、低通气、血氧下降和觉醒等事件，支持灵活输入模态组合，在家庭、临床和研究场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有OSA诊断方法只能粗略分类严重程度或检测孤立呼吸事件，缺乏高分辨率的事件级诊断精度和全面性。

Method: 开发深度学习模型UT OSANet，采用随机掩码模态组合训练策略，支持EEG、气流和SpO2等灵活输入模态，理解跨模态关系并在不同模态条件下保持稳定性能。

Result: 使用5个独立数据集的9,021个多导睡眠图记录进行训练和评估，灵敏度达0.93，宏F1分数在家庭、临床和研究场景中分别为0.84和0.85。

Conclusion: 该模型可作为OSA实际应用的事件级多场景诊断工具，同时为深入理解睡眠障碍中呼吸过程的机制及其广泛健康影响提供了手段。

Abstract: Obstructive sleep apnea (OSA) is a highly prevalent sleep disorder that is associated with increased risks of cardiovascular morbidity and all-cause mortality. While existing diagnostic approaches can roughly classify OSA severity or detect isolated respiratory events, they lack the precision and comprehensiveness required for high resolution, event level diagnosis. Here, we present UT OSANet, a deep learning based model designed as a event level, multi scenario diagnostic tool for OSA. This model facilitates detailed identification of events associated with OSA, including apnea, hypopnea, oxygen desaturation, and arousal. Moreover, the model employs flexibly adjustable input modalities such as electroencephalography (EEG), airflow, and SpO 2. It utilizes a random masked modality combination training strategy, allowing it to comprehend cross-modal relationships while sustaining consistent performance across varying modality conditions. This model was trained and evaluated utilizing 9,021 polysomnography (PSG) recordings from five independent datasets. achieving sensitivities up to 0.93 and macro F1 scores of 0.84, 0.85 across home, clinical, and research scenarios. This model serves as an event-level, multi-scenario diagnostic instrument for real-world applications of OSA, while also establishing itself as a means to deepen the mechanistic comprehension of respiratory processes in sleep disorders and their extensive health implications.

</details>


### [6] [Low-Complexity Rydberg Array Reuse: Modeling and Receiver Design for Sparse Channels](https://arxiv.org/abs/2511.16260)
*Hao Wu,Shanchi Wu,Xinyuan Yao,Rui Ni,Chen Gong*

Main category: eess.SP

TL;DR: 本文提出了一种低复杂度的多路复用里德堡阵列设计，通过混合模拟-数字波束成形架构解决传统里德堡阵列因激光设置需求导致的系统庞大问题。


<details>
  <summary>Details</summary>
Motivation: 当前里德堡阵列天线主要依赖简单堆叠单天线单元，导致系统庞大且不实用，因此需要开发多路复用的里德堡传感器阵列架构。

Method: 借鉴传统射频阵列中的混合模拟-数字波束成形方法，系统研究了多路复用里德堡阵列的设计原理、等效建模和预编码策略。

Result: 该方法显著降低了硬件复杂度，同时接近全数字波束成形的性能，为实现实用化和可扩展的量子增强通信系统奠定了基础。

Conclusion: 混合模拟-数字波束成形架构是解决里德堡阵列系统庞大问题的关键，对实现实用量子通信系统具有重要意义。

Abstract: Rydberg atomic quantum receivers have been seen as novel radio frequency measurements and the high sensitivity to a large range of frequencies makes it attractive for communications reception. However, current implementations of Rydberg array antennas predominantly rely on simple stacking of multiple single-antenna units. While conceptually straightforward, this approach leads to substantial system bulkiness due to the unique requirements of atomic sensors, particularly the need for multiple spatially separated laser setups, rendering such designs both impractical for real-world applications and challenging to fabricate. This limitation underscores the critical need for developing multiplexed Rydberg sensor array architectures. In the domain of conventional RF array antennas, hybrid analog-digital beamforming has emerged as a pivotal architecture for large-scale millimeter-wave (mmWave) multiple-input multiple-output (MIMO) systems, as it substantially reduces the hardware complexity associated with fully-digital beamforming while closely approaching its performance. Drawing inspiration from this methodology, we conduct a systematic study in this work on the design principles, equivalent modeling, and precoding strategies for low-complexity multiplexed Rydberg array, an endeavor crucial to enabling practical and scalable quantum-enhanced communication systems.

</details>


### [7] [Dynamic Multiple-Parameter Joint Time-Vertex Fractional Fourier Transform and its Intelligent Filtering Methods](https://arxiv.org/abs/2511.16277)
*Manjun Cui,Ziqi Yan,Yangfan He,Zhichao Zhang*

Main category: eess.SP

TL;DR: 提出动态多参数联合时间-顶点分数傅里叶变换框架，通过引入时变分数参数实现动态图结构的自适应谱建模，在去噪和去模糊任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有联合时间-顶点变换仅能为空间域和时间域各分配一个分数阶，限制了建模图信号复杂动态变化的能力。

Method: 提出DMPJFRFT框架，为每个时间步分配不同的分数阶，实现动态灵活的时空信号表示；开发了基于梯度下降和神经网络两种滤波方法。

Result: 在动态图和视频数据集上的实验表明，该框架能有效捕捉时间拓扑变化，在去噪和去模糊任务中优于现有图变换和神经网络方法。

Conclusion: DMPJFRFT通过时变分数参数实现了动态图信号的自适应谱建模，为动态图信号处理提供了更灵活的表示能力。

Abstract: Dynamic graph signal processing provides a principled framework for analyzing time-varying data defined on irregular graph domains. However, existing joint time-vertex transforms such as the joint time-vertex fractional Fourier transform assign only one fractional order to the spatial domain and another one to the temporal domain, thereby restricting their capacity to model the complex and continuously varying dynamics of graph signals. To address this limitation, we propose a novel dynamic multiple-parameter joint time-vertex fractional Fourier transform (DMPJFRFT) framework, which introduces time-varying fractional parameters to achieve adaptive spectral modeling of dynamic graph structures. By assigning distinct fractional orders to each time step, the proposed transform enables dynamic and flexible representation of spatio-temporal signal evolution in the joint time-vertex spectral domain. Theoretical properties of the DMPJFRFT are systematically analyzed, and two filtering approaches: a gradient descent-based method and a neural network-based method, are developed for dynamic signal restoration. Experimental results on dynamic graph and video datasets demonstrate that the proposed framework effectively captures temporal topology variations and achieves superior performance in denoising and deblurring tasks compared with some state-of-the-art graph-based transforms and neural networks.

</details>


### [8] [Revealing computation-communication trade-off in Segmented Pinching Antenna System (PASS)](https://arxiv.org/abs/2511.16327)
*Deqiao Gan,Xiaoxia Xu,Xiaohu Ge,Yuanwei Liu*

Main category: eess.SP

TL;DR: 提出了一种基于分段夹持天线系统的联合通信与计算框架，通过分段PASS设计实现可处理的上行传输，并减少大规模路径损耗和波导内损耗。针对计算导向和通信导向场景分别开发了AO-MMSE和AO-WMMSE算法，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 传统通信系统难以同时高效处理通信比特流和计算数据，需要开发联合通信与计算框架来克服大规模路径损耗和波导内损耗问题。

Method: 采用分段PASS设计，提出三种操作协议（SS、SA、SM），针对计算导向场景开发AO-MMSE算法，针对通信导向场景开发AO-WMMSE算法，通过交替优化求解波束成形问题。

Result: 仿真结果显示：与传统的MIMO和PASS相比，所提框架在MSE方面分别减少了70.65%和45.32%，在WSR方面分别提升了87.70%和51.35%。

Conclusion: 所提出的JCC-PASS框架在联合通信与计算方面显著优于传统方法，为同时传输通信和计算数据提供了有效解决方案。

Abstract: A joint communication and computation (JCC) framework using segmented pinching antenna system (PASS) is proposed, where both the communication bit streams and computation data are simultaneously transmitted via uplink communications. The segmented PASS design is used to yield the tractable uplink transmission, and to mitigate large-scale path loss and in-waveguide loss. Based on three operating protocols, namely segment selection (SS), segment aggregation (SA), and segment multiplexing (SM), the joint transmit and receive beamforming problem is formulated: 1) The mean square error (MSE) minimization problem is formulated for computation-oriented cases. To address this problem, a low-complexity alternating optimization-minimum mean square error (AO-MMSE) algorithm is developed. This problem is decomposed into receiver-side and transmitter-side MSE subproblems that are iteratively optimized by MMSE receivers to obtain the closed-form solutions. It is mathematically proved that the segmented JCC-PASS framework significantly outperforms the conventional PASS for the average in-waveguide propagation gain. 2) The weighted sum rate (WSR) maximization problem is formulated for communication-oriented cases. To solve the decomposed receiver-side and transmitter-side MSE subproblems, the AO-weighted minimum mean square error (AO-WMMSE) algorithm is further developed. An auxiliary weight variable is introduced to linearize the WSR function and is alternatively optimized based on WMMSE to derive the closed-form solutions. Simulation results demonstrate that: i) The proposed JCC-PASS framework achieves up to 70.65% and 45.32% reductions in MSE compared with conventional MIMO and conventional PASS, and ii) it reaches 87.70% and 51.35% improvements in WSR compared with conventional MIMO and conventional PASS, respectively.

</details>


### [9] [VersaPants: A Loose-Fitting Textile Capacitive Sensing System for Lower-Body Motion Capture](https://arxiv.org/abs/2511.16346)
*Deniz Kasap,Taraneh Aminosharieh Najafi,Jérôme Paul Rémy Thevenot,Jonathan Dan,Stefano Albini,David Atienza*

Main category: eess.SP

TL;DR: VersaPants是一种基于纺织品的电容传感系统，用于下半身运动捕捉，通过集成导电纺织补丁和紧凑采集单元到裤子中，无需特定用户适配即可重建下半身姿态。


<details>
  <summary>Details</summary>
Motivation: 现有IMU系统需要用户特定适配，基于摄像头的方法会侵犯隐私，需要一种既舒适又能保护隐私的运动捕捉解决方案。

Method: 使用6个电容通道每腿，采用轻量级Transformer深度学习模型将电容信号映射到关节角度，可在边缘平台上嵌入式实现。

Result: 在11名参与者3.7小时运动数据上测试，平均关节位置误差11.96厘米，平均关节角度误差12.3度，模型参数减少22倍，FLOPs减少18倍，在商用智能手表上实现42 FPS实时推理。

Conclusion: VersaPants为健身、医疗和健康应用提供了可扩展、舒适且可嵌入的运动捕捉解决方案。

Abstract: We present VersaPants, the first loose-fitting, textile-based capacitive sensing system for lower-body motion capture, built on the open-hardware VersaSens platform. By integrating conductive textile patches and a compact acquisition unit into a pair of pants, the system reconstructs lower-body pose without compromising comfort. Unlike IMU-based systems that require user-specific fitting or camera-based methods that compromise privacy, our approach operates without fitting adjustments and preserves user privacy. VersaPants is a custom-designed smart garment featuring 6 capacitive channels per leg. We employ a lightweight Transformer-based deep learning model that maps capacitance signals to joint angles, enabling embedded implementation on edge platforms. To test our system, we collected approximately 3.7 hours of motion data from 11 participants performing 16 daily and exercise-based movements. The model achieves a mean per-joint position error (MPJPE) of 11.96 cm and a mean per-joint angle error (MPJAE) of 12.3 degrees across the hip, knee, and ankle joints, indicating the model's ability to generalize to unseen users and movements. A comparative analysis of existing textile-based deep learning architectures reveals that our model achieves competitive reconstruction performance with up to 22 times fewer parameters and 18 times fewer FLOPs, enabling real-time inference at 42 FPS on a commercial smartwatch without quantization. These results position VersaPants as a promising step toward scalable, comfortable, and embedded motion-capture solutions for fitness, healthcare, and wellbeing applications.

</details>


### [10] [Neural Positioning Without External Reference](https://arxiv.org/abs/2511.16352)
*Till-Yannic Müller,Frederik Zumegen,Reinhard Wiesmayr,Emre Gönültaş,Christoph Studer*

Main category: eess.SP

TL;DR: 提出了一种无需外部参考定位系统的神经网络定位方法，仅使用信道状态信息和机器人相对位移命令来训练定位网络，在大范围环境中实现低成本、高精度的用户设备定位。


<details>
  <summary>Details</summary>
Motivation: 现有基于CSI的神经网络定位方法需要依赖外部参考定位系统获取地面真实位置标签，这需要昂贵的硬件设备且在大范围区域中难以实现。

Method: 使用商用机器人平台（如扫地机器人）执行相对位移命令，仅利用采集的信道状态信息和相对位移信息来训练定位神经网络，无需外部高精度位置标签。

Result: 在三个真实场景（从小范围视距区域到大范围非视距环境）中评估，使用IEEE 802.11 Wi-Fi和5G NR系统的CSI测量，实现了接近需要外部高精度地面真实标签的最先进方法的定位精度。

Conclusion: 该方法证明了仅使用相对位移信息和CSI数据即可训练出准确的神经网络定位功能，为大规模低成本定位系统提供了可行方案。

Abstract: Channel state information (CSI)-based user equipment (UE) positioning with neural networks -- referred to as neural positioning -- is a promising approach for accurate off-device UE localization. Most existing methods train their neural networks with ground-truth position labels obtained from external reference positioning systems, which requires costly hardware and renders label acquisition difficult in large areas. In this work, we propose a novel neural positioning pipeline that avoids the need for any external reference positioning system. Our approach trains the positioning network only using CSI acquired off-device and relative displacement commands executed on commercial off-the-shelf (COTS) robot platforms, such as robotic vacuum cleaners -- such an approach enables inexpensive training of accurate neural positioning functions over large areas. We evaluate our method in three real-world scenarios, ranging from small line-of-sight (LoS) areas to larger non-line-of-sight (NLoS) environments, using CSI measurements acquired in IEEE 802.11 Wi-Fi and 5G New Radio (NR) systems. Our experiments demonstrate that the proposed neural positioning pipeline achieves UE localization accuracies close to state-of-the-art methods that require externally acquired high-precision ground-truth position labels for training.

</details>


### [11] [Reasoning Meets Representation: Envisioning Neuro-Symbolic Wireless Foundation Models](https://arxiv.org/abs/2511.16369)
*Jaron Fontaine,Mohammad Cheraghinia,John Strassner,Adnan Shahid,Eli De Poorter*

Main category: eess.SP

TL;DR: 本文提出神经符号范式作为解决无线物理层基础模型局限性的关键方法，通过整合数据驱动的神经网络与基于规则的符号推理，构建可信赖的无线AI系统。


<details>
  <summary>Details</summary>
Motivation: 现有无线物理层基础模型存在可解释性、鲁棒性、适应性不足以及难以验证物理和监管约束等关键局限，而6G网络需要深度嵌入且可信赖的智能系统。

Method: 提出神经符号框架，整合通用RF嵌入与符号知识图谱及可微分逻辑层，实现从大数据学习与显式领域知识推理的结合。

Result: 该混合方法使模型能够从大规模数据集中学习，同时基于显式领域知识进行推理。

Conclusion: 神经符号范式对于构建满足未来网络需求的可信赖、可泛化且高效的无线AI至关重要。

Abstract: Recent advances in Wireless Physical Layer Foundation Models (WPFMs) promise a new paradigm of universal Radio Frequency (RF) representations. However, these models inherit critical limitations found in deep learning such as the lack of explainability, robustness, adaptability, and verifiable compliance with physical and regulatory constraints. In addition, the vision for an AI-native 6G network demands a level of intelligence that is deeply embedded into the systems and is trustworthy. In this vision paper, we argue that the neuro-symbolic paradigm, which integrates data-driven neural networks with rule- and logic-based symbolic reasoning, is essential for bridging this gap. We envision a novel Neuro-Symbolic framework that integrates universal RF embeddings with symbolic knowledge graphs and differentiable logic layers. This hybrid approach enables models to learn from large datasets while reasoning over explicit domain knowledge, enabling trustworthy, generalizable, and efficient wireless AI that can meet the demands of future networks.

</details>


### [12] [3-20 GHz Wideband Tightly-Coupled Dual-Polarized Vivaldi Antenna Array](https://arxiv.org/abs/2511.16472)
*Niko Lindvall,Mikko Heino,Mikko Valkama*

Main category: eess.SP

TL;DR: 提出了一种新型紧耦合双极化对跖维瓦尔第天线，通过叶片重叠实现紧耦合，将低频边缘从3.75GHz扩展到3GHz和2.75GHz，阻抗带宽达到3-20GHz。


<details>
  <summary>Details</summary>
Motivation: 定位、传感、频谱监测和现代扩频系统需要超宽带天线孔径。维瓦尔第天线因其天然宽带特性成为理想选择，但双极化维瓦尔第天线的紧耦合设计尚未得到充分研究。

Method: 设计紧耦合双极化对跖维瓦尔第天线，通过重叠维瓦尔第叶片实现单元间的强互耦合，利用这种紧耦合效应扩展低频性能。

Result: 实现了-6dB阻抗带宽3-20GHz，相比孤立对跖维瓦尔第单元，低频边缘从3.75GHz分别扩展到3GHz和2.75GHz，两个极化方向的性能分别提升了20%和25%。

Conclusion: 通过紧耦合设计成功扩展了双极化维瓦尔第天线的低频带宽，为超宽带天线系统提供了有效的解决方案。

Abstract: Very wideband apertures are needed in positioning, sensing, spectrum monitoring, and modern spread spectrum, e.g., frequency hopping systems. Vivaldi antennas are one of the prominent choices for the aforementioned systems due to their natural wideband characteristics. Furthermore, tightly-coupled antenna arrays have been researched in the recent years to extend the lower band edge of compact arrays by taking advantage of the strong mutual coupling between the elements especially with dipole elements, but not with dual-polarized Vivaldi antennas. This paper presents a novel tightly-coupled dual-polarized antipodal Vivaldi antenna (TC-AVA) with -6 dB impedance bandwidth of 3 to 20 GHz. The tight coupling by overlapping the Vivaldi leaves is shown to extend the lower band edge from 3.75 to 3 GHz and 2.75 GHz, an improvement of 20% to 25% for both polarizations, compared with an isolated antipodal Vivaldi element.

</details>


### [13] [TFCDiff: Robust ECG Denoising via Time-Frequency Complementary Diffusion](https://arxiv.org/abs/2511.16627)
*Pengxin Li,Yimin Zhou,Jie Min,Yirong Wang,Wei Liang,Wang Li*

Main category: eess.SP

TL;DR: TFCDiff是一种基于离散余弦变换的扩散模型，用于去除动态心电图中复杂的混合噪声，在多个评估指标上达到最先进性能，并具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 动态心电图容易受到基线漂移、肌肉伪影和电极运动伪影等复杂噪声的干扰，影响诊断准确性。目前多拍心电图段的去噪研究较少且存在技术挑战。

Method: 提出TFCDiff方法，在DCT域操作，使用噪声信号的DCT系数作为条件输入，并引入时间特征增强机制来强化时间表示和保留关键生理信息。

Result: 在合成数据集上的比较实验显示，TFCDiff在五个评估指标上达到最先进性能，在未见过的SimEMG数据库上表现出优越的泛化能力，优于所有基准模型。

Conclusion: TFCDiff能够处理原始10秒序列，在灵活随机混合噪声下保持鲁棒性，可在可穿戴心电图监测器中即插即用部署，适用于高运动场景。

Abstract: Ambulatory electrocardiogram (ECG) readings are prone to mixed noise from physical activities, including baseline wander (BW), muscle artifact (MA), and electrode motion artifact (EM). Developing a method to remove such complex noise and reconstruct high-fidelity signals is clinically valuable for diagnostic accuracy. However, denoising of multi-beat ECG segments remains understudied and poses technical challenges. To address this, we propose Time-Frequency Complementary Diffusion (TFCDiff), a novel approach that operates in the Discrete Cosine Transform (DCT) domain and uses the DCT coefficients of noisy signals as conditioning input. To refine waveform details, we incorporate Temporal Feature Enhancement Mechanism (TFEM) to reinforce temporal representations and preserve key physiological information. Comparative experiments on a synthesized dataset demonstrate that TFCDiff achieves state-of-the-art performance across five evaluation metrics. Furthermore, TFCDiff shows superior generalization on the unseen SimEMG Database, outperforming all benchmark models. Notably, TFCDiff processes raw 10-second sequences and maintains robustness under flexible random mixed noise (fRMN), enabling plug-and-play deployment in wearable ECG monitors for high-motion scenarios. Source code is available at https://github.com/Miroircivil/TFCDiff.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [14] [A Generalized Weighted Overlap-Add (WOLA) Filter Bank for Improved Subband System Identification](https://arxiv.org/abs/2511.15766)
*Mohit Sharma,Robbe Van Rompaey,Wouter Lanneer,Marc Moonen*

Main category: eess.AS

TL;DR: 提出了广义WOLA滤波器组，将子带滤波器重新定位到降采样操作之前，消除了传统WOLA滤波器组对子带滤波器的约束，并通过PT-WOLA实现低复杂度实现。


<details>
  <summary>Details</summary>
Motivation: 传统STFT域子带自适应滤波主要关注降采样率下的子带滤波，使用WOLA滤波器组，但这种方法在转换为全速率表示时对子带滤波器施加了约束。

Method: 1. 引入广义WOLA滤波器组重新定位子带滤波器位置；2. 分析MSE性能；3. 提出PT-WOLA低复杂度实现。

Result: 广义WOLA滤波器组显著提升了子带系统辨识性能，PT-WOLA保持与传统WOLA相当的计算复杂度。

Conclusion: 广义WOLA滤波器组有效解决了传统方法的约束问题，在保持计算效率的同时提升了系统辨识性能。

Abstract: This paper addresses the challenges in short-time Fourier transform (STFT) domain subband adaptive filtering, in particular, subband system identification. Previous studies in this area have primarily focused on setups with subband filtering at a downsampled rate, implemented using the weighted overlap-add (WOLA) filter bank, popular in audio and speech-processing for its reduced complexity. However, this traditional approach imposes constraints on the subband filters when transformed to their full-rate representation. This paper makes three key contributions. First, it introduces a generalized WOLA filter bank that repositions subband filters before the downsampling operation, eliminating the constraints on subband filters inherent in the conventional WOLA filter bank. Second, it investigates the mean square error (MSE) performance of the generalized WOLA filter bank for full-band system identification, establishing analytical ties between the order of subband filters, the full-band system impulse response length, the decimation factor, and the prototype filters. Third, to address the increased computational complexity of the generalized WOLA, the paper proposes a low-complexity implementation termed per-tone weighted overlap-add (PT-WOLA), which maintains computational complexity on par with conventional WOLA. Analytical and empirical evidence demonstrates that the proposed generalized WOLA filter bank significantly enhances the performance of subband system identification.

</details>


### [15] [Train Short, Infer Long: Speech-LLM Enables Zero-Shot Streamable Joint ASR and Diarization on Long Audio](https://arxiv.org/abs/2511.16046)
*Mohan Shi,Xiong Xiao,Ruchao Fan,Shaoshi Ling,Jinyu Li*

Main category: eess.AS

TL;DR: 提出JEDIS-LLM，一种端到端的语音大语言模型，用于联合流式说话人日志和语音识别，仅需在短音频上训练即可实现长音频的零样本流式推理。


<details>
  <summary>Details</summary>
Motivation: 解决多说话人场景下"谁说了什么"的问题，实现端到端的联合语音识别和说话人日志，并支持流式处理和预注册说话人信息。

Method: 引入说话人提示缓存(SPC)机制，在分块流式推理时进行在线更新；在语音编码器中加入词级说话人监督；仅需在20秒以内的短音频上训练。

Result: 在短音频上超越Sortformer和Meta-Cat，在长音频上优于DiarizationLM，实现了最先进的性能。

Conclusion: 这是首个使用仅短音频训练的语音大语言模型实现长音频零样本流式联合ASR和说话人日志的工作，性能达到最优。

Abstract: Joint automatic speech recognition (ASR) and speaker diarization aim to answer the question "who spoke what" in multi-speaker scenarios. In this paper, we present an end-to-end speech large language model (Speech-LLM) for Joint strEamable DIarization and aSr (JEDIS-LLM). The model is trained only on short audio under 20s but is capable of streamable inference on long-form audio without additional training. This is achieved by introducing a Speaker Prompt Cache (SPC) with an on-the-fly update mechanism during chunk-wise streaming inference, inspired by the autoregressive nature of LLMs. The SPC also allows the seamless use of pre-enrolled speaker profiles which is common in many scenarios like meeting transcription. To further enhance diarization capability, we incorporate word-level speaker supervision into the speech encoder during training. Experimental results demonstrate that our system outperforms strong baselines, including Sortformer and Meta-Cat in the local setting on audio up to 20s, and DiarizationLM on long-form audio, despite being fully end-to-end and streamable while DiarizationLM follows a cascaded offline pipeline. To the best of our knowledge, this is the first work enabling zero-shot streamable joint ASR and diarization on long audio using a Speech-LLM trained only on short audio, achieving state-of-the-art performance.

</details>


### [16] [SUNAC: Source-aware Unified Neural Audio Codec](https://arxiv.org/abs/2511.16126)
*Ryo Aihara,Yoshiki Masuyama,Francesco Paissan,François G. Germain,Gordon Wichern,Jonathan Le Roux*

Main category: eess.AS

TL;DR: 提出了一种源感知音频编解码器，能够直接从混合音频中编码单个声源，通过源类型提示实现用户驱动的声源选择。


<details>
  <summary>Details</summary>
Motivation: 传统神经音频编解码器对多个声源的混合进行纠缠编码，不利于需要访问特定声源子集的下游应用。

Method: 使用源类型提示作为条件，直接从混合音频中编码单个声源，支持相同类型的多个声源分别编码。

Result: 实验显示该模型在重合成和分离质量上与传统分离+编解码级联方法相当，但计算成本更低。

Conclusion: 源感知编解码器为需要选择性访问特定声源的下游应用提供了更高效的解决方案。

Abstract: Neural audio codecs (NACs) provide compact representations that can be leveraged in many downstream applications, in particular large language models. Yet most NACs encode mixtures of multiple sources in an entangled manner, which may impede efficient downstream processing in applications that need access to only a subset of the sources (e.g., analysis of a particular type of sound, transcription of a given speaker, etc). To address this, we propose a source-aware codec that encodes individual sources directly from mixtures, conditioned on source type prompts. This enables user-driven selection of which source(s) to encode, including separately encoding multiple sources of the same type (e.g., multiple speech signals). Experiments show that our model achieves competitive resynthesis and separation quality relative to a cascade of source separation followed by a conventional NAC, with lower computational cost.

</details>


### [17] [Codec2Vec: Self-Supervised Speech Representation Learning Using Neural Speech Codecs](https://arxiv.org/abs/2511.16639)
*Wei-Cheng Tseng,David Harwath*

Main category: eess.AS

TL;DR: Codec2Vec是首个基于离散音频编解码单元的语音表示学习框架，在SUPERB基准测试中表现优异，同时显著降低了存储需求和训练时间。


<details>
  <summary>Details</summary>
Motivation: 探索神经音频编解码器作为通用声学特征提取器的潜力，利用离散音频编解码单元的优势来改进语音处理任务。

Method: 采用基于离散音频编解码单元的表示学习框架，探索了多种训练目标推导策略的掩码预测方法。

Result: 在SUPERB基准测试中达到与连续输入模型竞争的性能，同时存储需求降低16.5倍，训练时间减少2.3倍。

Conclusion: Codec2Vec展示了离散音频编解码单元作为高效语音表示学习方法的可行性和优势，具有更好的可扩展性和效率。

Abstract: Recent advancements in neural audio codecs have not only enabled superior audio compression but also enhanced speech synthesis techniques. Researchers are now exploring their potential as universal acoustic feature extractors for a broader range of speech processing tasks. Building on this trend, we introduce Codec2Vec, the first speech representation learning framework that relies exclusively on discrete audio codec units. This approach offers several advantages, including improved data storage and transmission efficiency, faster training, and enhanced data privacy. We explore masked prediction with various training target derivation strategies to thoroughly understand the effectiveness of this framework. Evaluated on the SUPERB benchmark, Codec2Vec achieves competitive performance compared to continuous-input models while reducing storage requirements by up to 16.5x and training time by 2.3x, showcasing its scalability and efficiency.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [18] [SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise](https://arxiv.org/abs/2511.16114)
*Rui Sang,Yuxuan Liu*

Main category: cs.SD

TL;DR: SceneGuard是一种训练时语音保护方法，通过添加场景一致的可听背景噪声来防止语音克隆攻击，相比不可感知的对抗扰动更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有的基于不可感知对抗扰动的语音保护方法容易受到音频预处理（如去噪和压缩）的攻击，需要更鲁棒的防御方案。

Method: 在语音录制时添加场景一致的可听背景噪声（如机场、街道、公园等自然声学场景），使保护噪声在上下文中合理且难以被移除。

Result: 在文本转语音训练攻击中，SceneGuard将说话人相似度降低5.5%（p < 10^{-15}, Cohen's d = 2.18），同时保持98.6%的语音可懂度（STOI = 0.986），在五种常见对抗措施下仍保持或增强保护效果。

Conclusion: 可听且场景一致的噪声为训练时语音保护提供了比不可感知扰动更鲁棒的替代方案。

Abstract: Voice cloning technology poses significant privacy threats by enabling unauthorized speech synthesis from limited audio samples. Existing defenses based on imperceptible adversarial perturbations are vulnerable to common audio preprocessing such as denoising and compression. We propose SceneGuard, a training-time voice protection method that applies scene-consistent audible background noise to speech recordings. Unlike imperceptible perturbations, SceneGuard leverages naturally occurring acoustic scenes (e.g., airport, street, park) to create protective noise that is contextually appropriate and robust to countermeasures. We evaluate SceneGuard on text-to-speech training attacks, demonstrating 5.5% speaker similarity degradation with extremely high statistical significance (p < 10^{-15}, Cohen's d = 2.18) while preserving 98.6% speech intelligibility (STOI = 0.986). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures including MP3 compression, spectral subtraction, lowpass filtering, and downsampling. Our results suggest that audible, scene-consistent noise provides a more robust alternative to imperceptible perturbations for training-time voice protection. The source code are available at: https://github.com/richael-sang/SceneGuard.

</details>


### [19] [Difficulty-Controlled Simplification of Piano Scores with Synthetic Data for Inclusive Music Education](https://arxiv.org/abs/2511.16228)
*Pedro Ramoneda,Emilia Parada-Cabaleiro,Dasaem Jeong,Xavier Serra*

Main category: cs.SD

TL;DR: 本文提出了一种基于Transformer的方法，用于调整MusicXML钢琴乐谱的难度，通过合成数据集和预训练模型实现难度评估和配对，所有资源开源发布。


<details>
  <summary>Details</summary>
Motivation: AI在音乐教育中的潜力受到专有系统的限制，特别是难度调整技术可以提升音乐教育的包容性，但现有方法依赖专有数据集和MIDI格式，缺乏可读性和可复现性。

Method: 使用Transformer架构处理MusicXML钢琴乐谱，创建合成数据集包含按难度排序的乐谱对，利用预训练模型评估难度和风格以确保配对质量。

Result: 实验结果表明该方法能准确控制可演奏性和目标难度，定性和定量评估均验证了方法的有效性。

Conclusion: 与先前工作不同，本研究开源所有资源（代码、数据集和模型），确保可复现性并促进开源创新，帮助缩小数字鸿沟。

Abstract: Despite its potential, AI advances in music education are hindered by proprietary systems that limit the democratization of technology in this domain. In particular, AI-driven music difficulty adjustment is especially promising, as simplifying complex pieces can make music education more inclusive and accessible to learners of all ages and contexts. Nevertheless, recent efforts have relied on proprietary datasets, which prevents the research community from reproducing, comparing, or extending the current state of the art. In addition, while these generative methods offer great potential, most of them use the MIDI format, which, unlike others, such as MusicXML, lacks readability and layout information, thereby limiting their practical use for human performers. This work introduces a transformer-based method for adjusting the difficulty of MusicXML piano scores. Unlike previous methods, which rely on annotated datasets, we propose a synthetic dataset composed of pairs of piano scores ordered by estimated difficulty, with each pair comprising a more challenging and easier arrangement of the same piece. We generate these pairs by creating variations conditioned on the same melody and harmony and leverage pretrained models to assess difficulty and style, ensuring appropriate pairing. The experimental results illustrate the validity of the proposed approach, showing accurate control of playability and target difficulty, as highlighted through qualitative and quantitative evaluations. In contrast to previous work, we openly release all resources (code, dataset, and models), ensuring reproducibility while fostering open-source innovation to help bridge the digital divide.

</details>

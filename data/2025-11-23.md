<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.SD](#cs.SD) [Total: 2]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Rapid and Accurate Changepoint Detection of Power System Forced Oscillations](https://arxiv.org/abs/2511.15812)
*Luke Dosiek,Akaash Karn,Frank Liu*

Main category: eess.SP

TL;DR: 提出了一种使用变点检测(CPD)估计电力系统数据中强迫振荡起止时间的新方法，通过手动设置PELT算法的惩罚参数，大幅减少计算时间而不损失精度。


<details>
  <summary>Details</summary>
Motivation: 改进现有变点检测方法在电力系统强迫振荡检测中的应用，解决自动调参带来的高计算成本问题，提供更高效且准确的检测方案。

Method: 使用PELT算法，但手动提供惩罚参数而非自动调参；采用低阶ARMAX模型表示minniWECC系统进行测试；提供数据驱动的最小FO段长度设置方法。

Result: 计算时间减少98%，同时保持高估计精度；算法需要更少的输入参数。

Conclusion: 该方法显著提高了强迫振荡检测的计算效率，为机电模式表提供了更实用的数据驱动解决方案。

Abstract: This paper describes a new approach for using changepoint detection (CPD) to estimate the starting and stopping times of a forced oscillation (FO) in measured power system data. As with a previous application of CPD to this problem, the pruned exact linear time (PELT) algorithm is used. However, instead of allowing PELT to automatically tune its penalty parameter, a method of manually providing it is presented that dramatically reduces computation time without sacrificing accuracy. Additionally, the new algorithm requires fewer input parameters and provides a formal, data-driven approach to setting the minimum FO segment length to consider as troublesome for an electromechanical mode meter. A low-order ARMAX representation of the minniWECC model is used to test the approach, where a 98\% reduction in computation time is enjoyed with high estimation accuracy.

</details>


### [2] [EEG Emotion Recognition Through Deep Learning](https://arxiv.org/abs/2511.15902)
*Roman Dolgopolyi,Antonis Chatzipanagiotou*

Main category: eess.SP

TL;DR: 开发了基于CNN-Transformer架构的EEG情绪分类模型，使用5个电极实现91%准确率，支持低成本家用EEG设备部署


<details>
  <summary>Details</summary>
Motivation: 解决传统情绪识别方法在面部表情或声音受限场景下的不足，推动可负担的家庭情绪监测技术发展

Method: 使用CNN-Transformer混合架构处理EEG信号，在合并SEED、SEED-FRA、SEED-GER数据集（1455个样本）上训练，仅需5个电极

Result: 测试准确率达到91%，优于SVM、DNN和逻辑回归等传统模型，电极需求从62个减少到5个

Conclusion: 该模型为媒体内容引发的情绪变化研究奠定基础，可在医疗、健康监测等场景实现持续被动情绪监控

Abstract: An advanced emotion classification model was developed using a CNN-Transformer architecture for emotion recognition from EEG brain wave signals, effectively distinguishing among three emotional states, positive, neutral and negative. The model achieved a testing accuracy of 91%, outperforming traditional models such as SVM, DNN, and Logistic Regression. Training was conducted on a custom dataset created by merging data from SEED, SEED-FRA, and SEED-GER repositories, comprising 1,455 samples with EEG recordings labeled according to emotional states. The combined dataset represents one of the largest and most culturally diverse collections available. Additionally, the model allows for the reduction of the requirements of the EEG apparatus, by leveraging only 5 electrodes of the 62. This reduction demonstrates the feasibility of deploying a more affordable consumer-grade EEG headset, thereby enabling accessible, at-home use, while also requiring less computational power. This advancement sets the groundwork for future exploration into mood changes induced by media content consumption, an area that remains underresearched. Integration into medical, wellness, and home-health platforms could enable continuous, passive emotional monitoring, particularly beneficial in clinical or caregiving settings where traditional behavioral cues, such as facial expressions or vocal tone, are diminished, restricted, or difficult to interpret, thus potentially transforming mental health diagnostics and interventions...

</details>


### [3] [Integrated Coexistence for Satellite and Terrestrial Networks with Multistatic ISAC](https://arxiv.org/abs/2511.15947)
*Jeongju Jee,Jeffrey G. Andrews*

Main category: eess.SP

TL;DR: 提出了一种卫星与地面网络共存合作框架，通过预优化和精细化两阶段处理卫星CSI的可预测性，结合波束成形和功率分配优化，显著提升集成网络性能。


<details>
  <summary>Details</summary>
Motivation: 6G时代LEO卫星通信与地面ISAC的紧密集成需要频谱共享，但可能造成严重干扰，需要解决实际CSI获取问题。

Method: 采用预优化和精细化两阶段结构，利用卫星CSI可预测性，提出波束成形与功率分配协同设计，以及多站ISAC的目标-雷达关联方法。

Result: 仿真结果显示该方法显著提升集成网络性能，随着波束和雷达接收器数量增加，性能接近无干扰基准。

Conclusion: 证明了卫星与地面网络频谱共存的可行性，为6G集成网络提供了实用解决方案。

Abstract: Tightly integrated low earth orbit (LEO) satellite communications and terrestrial integrated sensing and communication (ISAC) are expected to be key novel aspects of the 6G era. Spectrum sharing between satellite and terrestrial cellular networks may, however, cause severe interference. This paper introduces a cooperation framework for integrated coexistence between satellite and terrestrial networks where the terrestrial network also deploys multistatic ISAC. Unlike prior works that assume ideal channel state information (CSI) acquisition, the proposed approach develops a practical structure consisting of pre-optimization and refinement stages that leverages the predictability of satellite CSI. In addition, a co-design of terrestrial beamforming and satellite power allocation utilizing a weighted minimum mean-squared error algorithm is proposed, and a target-radar association method designed for multistatic ISAC is presented. Simulation results show that the proposed approach significantly enhances the performance of these integrated networks. Furthermore, it is confirmed that the overall performance approaches the interference-free benchmark as the number of spot beams and radar receivers increases, demonstrating the feasibility of spectral coexistence between the two networks.

</details>


### [4] [Joint Admission Control and Power Minimization in IRS-assisted Networks](https://arxiv.org/abs/2511.16000)
*Weijie Xiong,Jingran Lin,Zhiling Xiao,Qiang Li,Yuhan Zhang*

Main category: eess.SP

TL;DR: 提出了一种基于sigmoid函数近似l0范数的智能反射面网络联合准入控制和功率最小化方法，使用惩罚对偶分解算法进行联合优化，相比传统方法具有更低功耗、更高用户容量和更短计算时间。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖l1范数近似和交替优化技术，存在计算复杂度高、收敛保证不足的问题，需要更高效可靠的解决方案。

Method: 使用sigmoid函数近似l0范数准入控制指标，提出惩罚对偶分解算法联合优化波束成形和准入控制，支持分布式实现。

Result: 相比现有方法，实现了更低的功耗、更高的用户容纳能力和更短的计算时间。

Conclusion: 所提出的方法在计算复杂度和性能方面均优于传统方法，为IRS辅助网络提供了更高效的联合优化解决方案。

Abstract: Joint admission control and power minimization are critical challenges in intelligent reflecting surface (IRS)-assisted networks. Traditional methods often rely on \( l_1 \)-norm approximations and alternating optimization (AO) techniques, which suffer from high computational complexity and lack robust convergence guarantees. To address these limitations, we propose a sigmoid-based approximation of the \( l_0 \)-norm AC indicator, enabling a more efficient and tractable reformulation of the problem. Additionally, we introduce a penalty dual decomposition (PDD) algorithm to jointly optimize beamforming and admission control, ensuring convergence to a stationary solution. This approach reduces computational complexity and supports distributed implementation. Moreover, it outperforms existing methods by achieving lower power consumption, accommodating more users, and reducing computational time.

</details>


### [5] [UT-OSANet: A Multimodal Deep Learning model for Evaluating and Classifying Obstructive Sleep Apnea](https://arxiv.org/abs/2511.16169)
*Zijian Wang,Xiaoyu Bao,Chenhao Zhao,Jihui Zhang,Sizhi Ai,Yuanqing Li*

Main category: eess.SP

TL;DR: UT OSANet是一个基于深度学习的阻塞性睡眠呼吸暂停(OSA)事件级诊断工具，能够识别呼吸暂停、低通气、血氧下降和觉醒等事件，支持多种输入模态，在家庭、临床和研究场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有OSA诊断方法只能粗略分类严重程度或检测孤立呼吸事件，缺乏高分辨率的事件级诊断精度和全面性。

Method: 开发UT OSANet深度学习模型，采用随机掩码模态组合训练策略，支持EEG、气流和SpO2等灵活输入模态，理解跨模态关系并在不同模态条件下保持稳定性能。

Result: 使用5个独立数据集的9,021个多导睡眠图记录进行训练和评估，在家庭、临床和研究场景中灵敏度高达0.93，宏观F1分数分别为0.84和0.85。

Conclusion: 该模型可作为OSA实际应用的事件级、多场景诊断工具，同时为深入理解睡眠障碍中呼吸过程的机制及其广泛健康影响提供了手段。

Abstract: Obstructive sleep apnea (OSA) is a highly prevalent sleep disorder that is associated with increased risks of cardiovascular morbidity and all-cause mortality. While existing diagnostic approaches can roughly classify OSA severity or detect isolated respiratory events, they lack the precision and comprehensiveness required for high resolution, event level diagnosis. Here, we present UT OSANet, a deep learning based model designed as a event level, multi scenario diagnostic tool for OSA. This model facilitates detailed identification of events associated with OSA, including apnea, hypopnea, oxygen desaturation, and arousal. Moreover, the model employs flexibly adjustable input modalities such as electroencephalography (EEG), airflow, and SpO 2. It utilizes a random masked modality combination training strategy, allowing it to comprehend cross-modal relationships while sustaining consistent performance across varying modality conditions. This model was trained and evaluated utilizing 9,021 polysomnography (PSG) recordings from five independent datasets. achieving sensitivities up to 0.93 and macro F1 scores of 0.84, 0.85 across home, clinical, and research scenarios. This model serves as an event-level, multi-scenario diagnostic instrument for real-world applications of OSA, while also establishing itself as a means to deepen the mechanistic comprehension of respiratory processes in sleep disorders and their extensive health implications.

</details>


### [6] [Low-Complexity Rydberg Array Reuse: Modeling and Receiver Design for Sparse Channels](https://arxiv.org/abs/2511.16260)
*Hao Wu,Shanchi Wu,Xinyuan Yao,Rui Ni,Chen Gong*

Main category: eess.SP

TL;DR: 本文提出了一种低复杂度的多路复用里德堡阵列设计，通过混合模拟-数字波束成形技术解决当前里德堡原子量子接收器阵列因需要多个激光设置而导致的系统庞大问题。


<details>
  <summary>Details</summary>
Motivation: 当前里德堡阵列天线主要依赖简单堆叠多个单天线单元，由于原子传感器的特殊需求（特别是需要多个空间分离的激光设置），导致系统庞大、不实用且制造困难，迫切需要开发多路复用里德堡传感器阵列架构。

Method: 借鉴传统射频阵列天线中的混合模拟-数字波束成形方法，系统研究了低复杂度多路复用里德堡阵列的设计原理、等效建模和预编码策略。

Result: 该方法显著降低了与全数字波束成形相关的硬件复杂性，同时接近其性能表现。

Conclusion: 这项工作对于实现实用且可扩展的量子增强通信系统至关重要，为里德堡阵列提供了可行的低复杂度解决方案。

Abstract: Rydberg atomic quantum receivers have been seen as novel radio frequency measurements and the high sensitivity to a large range of frequencies makes it attractive for communications reception. However, current implementations of Rydberg array antennas predominantly rely on simple stacking of multiple single-antenna units. While conceptually straightforward, this approach leads to substantial system bulkiness due to the unique requirements of atomic sensors, particularly the need for multiple spatially separated laser setups, rendering such designs both impractical for real-world applications and challenging to fabricate. This limitation underscores the critical need for developing multiplexed Rydberg sensor array architectures. In the domain of conventional RF array antennas, hybrid analog-digital beamforming has emerged as a pivotal architecture for large-scale millimeter-wave (mmWave) multiple-input multiple-output (MIMO) systems, as it substantially reduces the hardware complexity associated with fully-digital beamforming while closely approaching its performance. Drawing inspiration from this methodology, we conduct a systematic study in this work on the design principles, equivalent modeling, and precoding strategies for low-complexity multiplexed Rydberg array, an endeavor crucial to enabling practical and scalable quantum-enhanced communication systems.

</details>


### [7] [Dynamic Multiple-Parameter Joint Time-Vertex Fractional Fourier Transform and its Intelligent Filtering Methods](https://arxiv.org/abs/2511.16277)
*Manjun Cui,Ziqi Yan,Yangfan He,Zhichao Zhang*

Main category: eess.SP

TL;DR: 提出了一种动态多参数联合时-顶点分数傅里叶变换(DMPJFRFT)框架，通过引入时变分数参数来实现动态图结构的自适应谱建模，在动态图信号去噪和去模糊任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有联合时-顶点变换仅能为空间域和时间域分别分配一个分数阶，限制了其建模图信号复杂动态变化的能力。

Method: 提出了DMPJFRFT框架，为每个时间步分配不同的分数阶，实现动态灵活的时空信号表示；开发了基于梯度下降和神经网络两种滤波方法用于动态信号恢复。

Result: 在动态图和视频数据集上的实验表明，该框架能有效捕捉时间拓扑变化，在去噪和去模糊任务中优于现有图基变换和神经网络方法。

Conclusion: DMPJFRFT通过时变分数参数实现了对动态图结构的自适应谱建模，为动态图信号处理提供了更灵活有效的工具。

Abstract: Dynamic graph signal processing provides a principled framework for analyzing time-varying data defined on irregular graph domains. However, existing joint time-vertex transforms such as the joint time-vertex fractional Fourier transform assign only one fractional order to the spatial domain and another one to the temporal domain, thereby restricting their capacity to model the complex and continuously varying dynamics of graph signals. To address this limitation, we propose a novel dynamic multiple-parameter joint time-vertex fractional Fourier transform (DMPJFRFT) framework, which introduces time-varying fractional parameters to achieve adaptive spectral modeling of dynamic graph structures. By assigning distinct fractional orders to each time step, the proposed transform enables dynamic and flexible representation of spatio-temporal signal evolution in the joint time-vertex spectral domain. Theoretical properties of the DMPJFRFT are systematically analyzed, and two filtering approaches: a gradient descent-based method and a neural network-based method, are developed for dynamic signal restoration. Experimental results on dynamic graph and video datasets demonstrate that the proposed framework effectively captures temporal topology variations and achieves superior performance in denoising and deblurring tasks compared with some state-of-the-art graph-based transforms and neural networks.

</details>


### [8] [Revealing computation-communication trade-off in Segmented Pinching Antenna System (PASS)](https://arxiv.org/abs/2511.16327)
*Deqiao Gan,Xiaoxia Xu,Xiaohu Ge,Yuanwei Liu*

Main category: eess.SP

TL;DR: 提出了基于分段夹捏天线系统的联合通信与计算框架，通过三种操作协议实现通信比特流和计算数据的同步上行传输，显著降低了均方误差并提高了加权和速率。


<details>
  <summary>Details</summary>
Motivation: 传统通信系统在处理联合通信与计算任务时存在性能限制，需要开发能够同时传输通信数据和计算数据的高效框架，以应对大规模路径损耗和波导内损耗。

Method: 采用分段夹捏天线系统设计，提出三种操作协议：段选择、段聚合和段复用。针对计算导向场景开发AO-MMSE算法，针对通信导向场景开发AO-WMMSE算法，通过交替优化求解收发波束成形问题。

Result: 仿真结果显示：与传统的MIMO和PASS相比，提出的JCC-PASS框架在均方误差上分别降低了70.65%和45.32%，在加权和速率上分别提高了87.70%和51.35%。

Conclusion: 所提出的分段JCC-PASS框架在联合通信与计算性能上显著优于传统方法，为未来无线通信系统提供了有效的解决方案。

Abstract: A joint communication and computation (JCC) framework using segmented pinching antenna system (PASS) is proposed, where both the communication bit streams and computation data are simultaneously transmitted via uplink communications. The segmented PASS design is used to yield the tractable uplink transmission, and to mitigate large-scale path loss and in-waveguide loss. Based on three operating protocols, namely segment selection (SS), segment aggregation (SA), and segment multiplexing (SM), the joint transmit and receive beamforming problem is formulated: 1) The mean square error (MSE) minimization problem is formulated for computation-oriented cases. To address this problem, a low-complexity alternating optimization-minimum mean square error (AO-MMSE) algorithm is developed. This problem is decomposed into receiver-side and transmitter-side MSE subproblems that are iteratively optimized by MMSE receivers to obtain the closed-form solutions. It is mathematically proved that the segmented JCC-PASS framework significantly outperforms the conventional PASS for the average in-waveguide propagation gain. 2) The weighted sum rate (WSR) maximization problem is formulated for communication-oriented cases. To solve the decomposed receiver-side and transmitter-side MSE subproblems, the AO-weighted minimum mean square error (AO-WMMSE) algorithm is further developed. An auxiliary weight variable is introduced to linearize the WSR function and is alternatively optimized based on WMMSE to derive the closed-form solutions. Simulation results demonstrate that: i) The proposed JCC-PASS framework achieves up to 70.65% and 45.32% reductions in MSE compared with conventional MIMO and conventional PASS, and ii) it reaches 87.70% and 51.35% improvements in WSR compared with conventional MIMO and conventional PASS, respectively.

</details>


### [9] [VersaPants: A Loose-Fitting Textile Capacitive Sensing System for Lower-Body Motion Capture](https://arxiv.org/abs/2511.16346)
*Deniz Kasap,Taraneh Aminosharieh Najafi,Jérôme Paul Rémy Thevenot,Jonathan Dan,Stefano Albini,David Atienza*

Main category: eess.SP

TL;DR: VersaPants是首个基于纺织品的电容传感系统，用于捕捉下半身运动，无需用户特定校准，保护隐私，并能在边缘设备上实时运行。


<details>
  <summary>Details</summary>
Motivation: 现有IMU系统需要用户特定校准，摄像头方法侵犯隐私，需要一种既舒适又保护隐私的运动捕捉解决方案。

Method: 在裤子中集成导电纺织贴片和紧凑采集单元，使用轻量级Transformer深度学习模型将电容信号映射到关节角度。

Result: 在11名参与者的测试中，平均关节位置误差11.96厘米，平均关节角度误差12.3度，模型能在智能手表上以42FPS实时运行。

Conclusion: VersaPants为健身、医疗和健康应用提供了可扩展、舒适且可嵌入的运动捕捉解决方案。

Abstract: We present VersaPants, the first loose-fitting, textile-based capacitive sensing system for lower-body motion capture, built on the open-hardware VersaSens platform. By integrating conductive textile patches and a compact acquisition unit into a pair of pants, the system reconstructs lower-body pose without compromising comfort. Unlike IMU-based systems that require user-specific fitting or camera-based methods that compromise privacy, our approach operates without fitting adjustments and preserves user privacy. VersaPants is a custom-designed smart garment featuring 6 capacitive channels per leg. We employ a lightweight Transformer-based deep learning model that maps capacitance signals to joint angles, enabling embedded implementation on edge platforms. To test our system, we collected approximately 3.7 hours of motion data from 11 participants performing 16 daily and exercise-based movements. The model achieves a mean per-joint position error (MPJPE) of 11.96 cm and a mean per-joint angle error (MPJAE) of 12.3 degrees across the hip, knee, and ankle joints, indicating the model's ability to generalize to unseen users and movements. A comparative analysis of existing textile-based deep learning architectures reveals that our model achieves competitive reconstruction performance with up to 22 times fewer parameters and 18 times fewer FLOPs, enabling real-time inference at 42 FPS on a commercial smartwatch without quantization. These results position VersaPants as a promising step toward scalable, comfortable, and embedded motion-capture solutions for fitness, healthcare, and wellbeing applications.

</details>


### [10] [Neural Positioning Without External Reference](https://arxiv.org/abs/2511.16352)
*Till-Yannic Müller,Frederik Zumegen,Reinhard Wiesmayr,Emre Gönültaş,Christoph Studer*

Main category: eess.SP

TL;DR: 提出了一种无需外部定位系统的神经网络定位方法，仅使用信道状态信息和机器人相对位移命令进行训练，在Wi-Fi和5G系统中实现了接近最先进方法的定位精度。


<details>
  <summary>Details</summary>
Motivation: 现有基于CSI的神经网络定位方法需要外部参考定位系统提供地面真实位置标签，硬件成本高且在大面积区域难以获取标签。

Method: 使用商用机器人平台（如扫地机器人）的相对位移命令和获取的CSI数据进行神经网络训练，无需外部参考定位系统。

Result: 在三个真实场景（从小的视距区域到较大的非视距环境）中评估，使用IEEE 802.11 Wi-Fi和5G NR系统的CSI测量，实现了接近需要外部高精度标签的最先进方法的定位精度。

Conclusion: 该方法能够在大面积区域以低成本训练准确的神经网络定位功能，避免了对外部参考定位系统的依赖。

Abstract: Channel state information (CSI)-based user equipment (UE) positioning with neural networks -- referred to as neural positioning -- is a promising approach for accurate off-device UE localization. Most existing methods train their neural networks with ground-truth position labels obtained from external reference positioning systems, which requires costly hardware and renders label acquisition difficult in large areas. In this work, we propose a novel neural positioning pipeline that avoids the need for any external reference positioning system. Our approach trains the positioning network only using CSI acquired off-device and relative displacement commands executed on commercial off-the-shelf (COTS) robot platforms, such as robotic vacuum cleaners -- such an approach enables inexpensive training of accurate neural positioning functions over large areas. We evaluate our method in three real-world scenarios, ranging from small line-of-sight (LoS) areas to larger non-line-of-sight (NLoS) environments, using CSI measurements acquired in IEEE 802.11 Wi-Fi and 5G New Radio (NR) systems. Our experiments demonstrate that the proposed neural positioning pipeline achieves UE localization accuracies close to state-of-the-art methods that require externally acquired high-precision ground-truth position labels for training.

</details>


### [11] [Reasoning Meets Representation: Envisioning Neuro-Symbolic Wireless Foundation Models](https://arxiv.org/abs/2511.16369)
*Jaron Fontaine,Mohammad Cheraghinia,John Strassner,Adnan Shahid,Eli De Poorter*

Main category: eess.SP

TL;DR: 本文提出神经符号范式来解决无线物理层基础模型在可解释性、鲁棒性、适应性等方面的局限性，通过整合神经网络的表示学习与符号推理来构建可信赖的无线AI系统。


<details>
  <summary>Details</summary>
Motivation: 现有无线物理层基础模型继承了深度学习的局限性，缺乏可解释性、鲁棒性和对物理约束的合规性验证。6G网络需要深度嵌入且可信赖的智能系统。

Method: 提出神经符号框架，整合通用RF嵌入、符号知识图谱和可微分逻辑层，实现数据驱动学习与领域知识推理的融合。

Result: 该混合方法能够从大数据中学习，同时基于显式领域知识进行推理，为未来网络需求提供可信赖、可泛化且高效的无线AI。

Conclusion: 神经符号范式对于弥合当前无线AI局限性与6G网络可信智能需求之间的差距至关重要，是实现下一代无线AI系统的关键路径。

Abstract: Recent advances in Wireless Physical Layer Foundation Models (WPFMs) promise a new paradigm of universal Radio Frequency (RF) representations. However, these models inherit critical limitations found in deep learning such as the lack of explainability, robustness, adaptability, and verifiable compliance with physical and regulatory constraints. In addition, the vision for an AI-native 6G network demands a level of intelligence that is deeply embedded into the systems and is trustworthy. In this vision paper, we argue that the neuro-symbolic paradigm, which integrates data-driven neural networks with rule- and logic-based symbolic reasoning, is essential for bridging this gap. We envision a novel Neuro-Symbolic framework that integrates universal RF embeddings with symbolic knowledge graphs and differentiable logic layers. This hybrid approach enables models to learn from large datasets while reasoning over explicit domain knowledge, enabling trustworthy, generalizable, and efficient wireless AI that can meet the demands of future networks.

</details>


### [12] [3-20 GHz Wideband Tightly-Coupled Dual-Polarized Vivaldi Antenna Array](https://arxiv.org/abs/2511.16472)
*Niko Lindvall,Mikko Heino,Mikko Valkama*

Main category: eess.SP

TL;DR: 提出了一种新型紧密耦合双极化对跖维瓦尔第天线，通过重叠天线叶片实现紧密耦合，将工作频带从3.75GHz扩展到3GHz和2.75GHz，带宽提升20-25%。


<details>
  <summary>Details</summary>
Motivation: 定位、传感、频谱监测和现代扩频系统需要超宽带天线孔径。维瓦尔第天线因其天然宽带特性成为理想选择，但传统设计在紧凑阵列中的低频性能有限。

Method: 采用紧密耦合双极化对跖维瓦尔第天线设计，通过重叠维瓦尔第天线叶片实现元件间的强互耦，从而扩展低频工作范围。

Result: 实现了3-20GHz的-6dB阻抗带宽，相比孤立天线元件，低频边缘从3.75GHz扩展到3GHz和2.75GHz，性能提升20-25%。

Conclusion: 紧密耦合技术成功扩展了双极化维瓦尔第天线的低频工作范围，为超宽带系统提供了更紧凑的解决方案。

Abstract: Very wideband apertures are needed in positioning, sensing, spectrum monitoring, and modern spread spectrum, e.g., frequency hopping systems. Vivaldi antennas are one of the prominent choices for the aforementioned systems due to their natural wideband characteristics. Furthermore, tightly-coupled antenna arrays have been researched in the recent years to extend the lower band edge of compact arrays by taking advantage of the strong mutual coupling between the elements especially with dipole elements, but not with dual-polarized Vivaldi antennas. This paper presents a novel tightly-coupled dual-polarized antipodal Vivaldi antenna (TC-AVA) with -6 dB impedance bandwidth of 3 to 20 GHz. The tight coupling by overlapping the Vivaldi leaves is shown to extend the lower band edge from 3.75 to 3 GHz and 2.75 GHz, an improvement of 20% to 25% for both polarizations, compared with an isolated antipodal Vivaldi element.

</details>


### [13] [TFCDiff: Robust ECG Denoising via Time-Frequency Complementary Diffusion](https://arxiv.org/abs/2511.16627)
*Pengxin Li,Yimin Zhou,Jie Min,Yirong Wang,Wei Liang,Wang Li*

Main category: eess.SP

TL;DR: TFCDiff是一种基于离散余弦变换的扩散模型，用于去除动态心电图中的混合噪声，在多个评估指标上达到最先进性能，并具有良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 动态心电图容易受到基线漂移、肌肉伪影和电极运动伪影等混合噪声干扰，影响诊断准确性，而多拍心电信号段的去噪研究仍不足且技术挑战大。

Method: 提出TFCDiff方法，在DCT域操作，使用噪声信号的DCT系数作为条件输入，并引入时间特征增强机制来强化时间表征并保留关键生理信息。

Result: 在合成数据集上的比较实验显示TFCDiff在五个评估指标上达到最先进性能，在未见过的SimEMG数据库上表现出优越的泛化能力，优于所有基准模型。

Conclusion: TFCDiff能够处理原始10秒序列并在灵活随机混合噪声下保持鲁棒性，可在可穿戴心电图监测器中即插即用部署，适用于高运动场景。

Abstract: Ambulatory electrocardiogram (ECG) readings are prone to mixed noise from physical activities, including baseline wander (BW), muscle artifact (MA), and electrode motion artifact (EM). Developing a method to remove such complex noise and reconstruct high-fidelity signals is clinically valuable for diagnostic accuracy. However, denoising of multi-beat ECG segments remains understudied and poses technical challenges. To address this, we propose Time-Frequency Complementary Diffusion (TFCDiff), a novel approach that operates in the Discrete Cosine Transform (DCT) domain and uses the DCT coefficients of noisy signals as conditioning input. To refine waveform details, we incorporate Temporal Feature Enhancement Mechanism (TFEM) to reinforce temporal representations and preserve key physiological information. Comparative experiments on a synthesized dataset demonstrate that TFCDiff achieves state-of-the-art performance across five evaluation metrics. Furthermore, TFCDiff shows superior generalization on the unseen SimEMG Database, outperforming all benchmark models. Notably, TFCDiff processes raw 10-second sequences and maintains robustness under flexible random mixed noise (fRMN), enabling plug-and-play deployment in wearable ECG monitors for high-motion scenarios. Source code is available at https://github.com/Miroircivil/TFCDiff.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [14] [A Generalized Weighted Overlap-Add (WOLA) Filter Bank for Improved Subband System Identification](https://arxiv.org/abs/2511.15766)
*Mohit Sharma,Robbe Van Rompaey,Wouter Lanneer,Marc Moonen*

Main category: eess.AS

TL;DR: 提出了一种广义WOLA滤波器组，将子带滤波器重新定位到降采样操作之前，消除了传统WOLA滤波器组中子带滤波器的约束，并通过PT-WOLA实现保持计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统STFT域子带自适应滤波主要关注降采样率下的子带滤波，使用WOLA滤波器组，但这种方法在转换为全速率表示时对子带滤波器施加了约束。

Method: 1. 引入广义WOLA滤波器组重新定位子带滤波器位置；2. 分析MSE性能与各参数关系；3. 提出PT-WOLA低复杂度实现。

Result: 分析和实验证据表明，广义WOLA滤波器组显著提升了子带系统识别的性能。

Conclusion: 广义WOLA滤波器组解决了传统方法的约束问题，同时通过PT-WOLA保持了计算效率，为子带系统识别提供了更好的解决方案。

Abstract: This paper addresses the challenges in short-time Fourier transform (STFT) domain subband adaptive filtering, in particular, subband system identification. Previous studies in this area have primarily focused on setups with subband filtering at a downsampled rate, implemented using the weighted overlap-add (WOLA) filter bank, popular in audio and speech-processing for its reduced complexity. However, this traditional approach imposes constraints on the subband filters when transformed to their full-rate representation. This paper makes three key contributions. First, it introduces a generalized WOLA filter bank that repositions subband filters before the downsampling operation, eliminating the constraints on subband filters inherent in the conventional WOLA filter bank. Second, it investigates the mean square error (MSE) performance of the generalized WOLA filter bank for full-band system identification, establishing analytical ties between the order of subband filters, the full-band system impulse response length, the decimation factor, and the prototype filters. Third, to address the increased computational complexity of the generalized WOLA, the paper proposes a low-complexity implementation termed per-tone weighted overlap-add (PT-WOLA), which maintains computational complexity on par with conventional WOLA. Analytical and empirical evidence demonstrates that the proposed generalized WOLA filter bank significantly enhances the performance of subband system identification.

</details>


### [15] [Train Short, Infer Long: Speech-LLM Enables Zero-Shot Streamable Joint ASR and Diarization on Long Audio](https://arxiv.org/abs/2511.16046)
*Mohan Shi,Xiong Xiao,Ruchao Fan,Shaoshi Ling,Jinyu Li*

Main category: eess.AS

TL;DR: 提出了JEDIS-LLM，一种端到端的语音大语言模型，用于联合流式说话人日志和语音识别，仅需在短音频上训练即可实现长音频的零样本流式推理。


<details>
  <summary>Details</summary>
Motivation: 解决多说话人场景下"谁说了什么"的问题，实现联合ASR和说话人日志的端到端流式处理，避免传统级联方法的复杂性。

Method: 引入说话人提示缓存(SPC)机制，在分块流式推理时进行动态更新；在语音编码器中加入词级说话人监督；支持预注册说话人配置。

Result: 在20秒音频上超越Sortformer和Meta-Cat，在长音频上优于DiarizationLM，且完全端到端和流式处理。

Conclusion: 这是首个仅用短音频训练就能在长音频上实现零样本流式联合ASR和说话人日志的Speech-LLM，达到了最先进的性能。

Abstract: Joint automatic speech recognition (ASR) and speaker diarization aim to answer the question "who spoke what" in multi-speaker scenarios. In this paper, we present an end-to-end speech large language model (Speech-LLM) for Joint strEamable DIarization and aSr (JEDIS-LLM). The model is trained only on short audio under 20s but is capable of streamable inference on long-form audio without additional training. This is achieved by introducing a Speaker Prompt Cache (SPC) with an on-the-fly update mechanism during chunk-wise streaming inference, inspired by the autoregressive nature of LLMs. The SPC also allows the seamless use of pre-enrolled speaker profiles which is common in many scenarios like meeting transcription. To further enhance diarization capability, we incorporate word-level speaker supervision into the speech encoder during training. Experimental results demonstrate that our system outperforms strong baselines, including Sortformer and Meta-Cat in the local setting on audio up to 20s, and DiarizationLM on long-form audio, despite being fully end-to-end and streamable while DiarizationLM follows a cascaded offline pipeline. To the best of our knowledge, this is the first work enabling zero-shot streamable joint ASR and diarization on long audio using a Speech-LLM trained only on short audio, achieving state-of-the-art performance.

</details>


### [16] [SUNAC: Source-aware Unified Neural Audio Codec](https://arxiv.org/abs/2511.16126)
*Ryo Aihara,Yoshiki Masuyama,Francesco Paissan,François G. Germain,Gordon Wichern,Jonathan Le Roux*

Main category: eess.AS

TL;DR: 提出了一种源感知音频编解码器，能够直接从混合音频中编码单个声源，通过源类型提示实现用户驱动的声源选择。


<details>
  <summary>Details</summary>
Motivation: 传统神经音频编解码器对多个声源的混合进行纠缠编码，这在需要访问特定声源子集的下游应用中效率低下。

Method: 开发源感知编解码器，通过源类型提示条件化，直接从混合音频中编码单个声源，支持用户选择要编码的声源。

Result: 实验表明该模型在重合成和分离质量上与源分离+传统编解码器级联方法相当，但计算成本更低。

Conclusion: 源感知编解码器为下游应用提供了更灵活高效的声源编码方案，特别适用于需要访问特定声源的场景。

Abstract: Neural audio codecs (NACs) provide compact representations that can be leveraged in many downstream applications, in particular large language models. Yet most NACs encode mixtures of multiple sources in an entangled manner, which may impede efficient downstream processing in applications that need access to only a subset of the sources (e.g., analysis of a particular type of sound, transcription of a given speaker, etc). To address this, we propose a source-aware codec that encodes individual sources directly from mixtures, conditioned on source type prompts. This enables user-driven selection of which source(s) to encode, including separately encoding multiple sources of the same type (e.g., multiple speech signals). Experiments show that our model achieves competitive resynthesis and separation quality relative to a cascade of source separation followed by a conventional NAC, with lower computational cost.

</details>


### [17] [Codec2Vec: Self-Supervised Speech Representation Learning Using Neural Speech Codecs](https://arxiv.org/abs/2511.16639)
*Wei-Cheng Tseng,David Harwath*

Main category: eess.AS

TL;DR: Codec2Vec是首个基于离散音频编解码单元的语音表示学习框架，在SUPERB基准测试中表现优异，同时显著降低了存储需求和训练时间。


<details>
  <summary>Details</summary>
Motivation: 探索神经音频编解码器作为通用声学特征提取器的潜力，利用离散音频编解码单元的优势来改进语音处理任务。

Method: 采用基于离散音频编解码单元的表示学习框架，使用掩码预测和多种训练目标推导策略。

Result: 在SUPERB基准测试中达到与连续输入模型竞争的性能，同时存储需求减少16.5倍，训练时间减少2.3倍。

Conclusion: Codec2Vec展示了离散音频编解码单元在语音表示学习中的有效性，具有更好的可扩展性和效率。

Abstract: Recent advancements in neural audio codecs have not only enabled superior audio compression but also enhanced speech synthesis techniques. Researchers are now exploring their potential as universal acoustic feature extractors for a broader range of speech processing tasks. Building on this trend, we introduce Codec2Vec, the first speech representation learning framework that relies exclusively on discrete audio codec units. This approach offers several advantages, including improved data storage and transmission efficiency, faster training, and enhanced data privacy. We explore masked prediction with various training target derivation strategies to thoroughly understand the effectiveness of this framework. Evaluated on the SUPERB benchmark, Codec2Vec achieves competitive performance compared to continuous-input models while reducing storage requirements by up to 16.5x and training time by 2.3x, showcasing its scalability and efficiency.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [18] [SceneGuard: Training-Time Voice Protection with Scene-Consistent Audible Background Noise](https://arxiv.org/abs/2511.16114)
*Rui Sang,Yuxuan Liu*

Main category: cs.SD

TL;DR: SceneGuard是一种训练时语音保护方法，通过添加场景一致的可听背景噪声来防止语音克隆攻击，相比不可感知的对抗扰动更鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有基于不可感知对抗扰动的语音保护方法容易受到音频预处理（如去噪和压缩）的攻击，需要更鲁棒的防御方案。

Method: 在语音录制时应用场景一致的可听背景噪声，利用自然声学场景（如机场、街道、公园）创建上下文适当的保护性噪声。

Result: 在文本转语音训练攻击中，SceneGuard使说话人相似度降低5.5%（p < 10^{-15}，Cohen's d = 2.18），同时保持98.6%的语音可懂度（STOI = 0.986），在五种常见对抗措施下保持或增强保护效果。

Conclusion: 可听且场景一致的噪声为训练时语音保护提供了比不可感知扰动更鲁棒的替代方案。

Abstract: Voice cloning technology poses significant privacy threats by enabling unauthorized speech synthesis from limited audio samples. Existing defenses based on imperceptible adversarial perturbations are vulnerable to common audio preprocessing such as denoising and compression. We propose SceneGuard, a training-time voice protection method that applies scene-consistent audible background noise to speech recordings. Unlike imperceptible perturbations, SceneGuard leverages naturally occurring acoustic scenes (e.g., airport, street, park) to create protective noise that is contextually appropriate and robust to countermeasures. We evaluate SceneGuard on text-to-speech training attacks, demonstrating 5.5% speaker similarity degradation with extremely high statistical significance (p < 10^{-15}, Cohen's d = 2.18) while preserving 98.6% speech intelligibility (STOI = 0.986). Robustness evaluation shows that SceneGuard maintains or enhances protection under five common countermeasures including MP3 compression, spectral subtraction, lowpass filtering, and downsampling. Our results suggest that audible, scene-consistent noise provides a more robust alternative to imperceptible perturbations for training-time voice protection. The source code are available at: https://github.com/richael-sang/SceneGuard.

</details>


### [19] [Difficulty-Controlled Simplification of Piano Scores with Synthetic Data for Inclusive Music Education](https://arxiv.org/abs/2511.16228)
*Pedro Ramoneda,Emilia Parada-Cabaleiro,Dasaem Jeong,Xavier Serra*

Main category: cs.SD

TL;DR: 本文提出了一种基于Transformer的MusicXML钢琴谱难度调整方法，通过合成数据集和预训练模型来评估难度和风格，确保准确控制可演奏性和目标难度。


<details>
  <summary>Details</summary>
Motivation: AI在音乐教育中的潜力受到专有系统的限制，特别是难度调整技术可以促进音乐教育的包容性和可及性。现有方法依赖专有数据集和MIDI格式，缺乏可读性和布局信息，限制了实际应用。

Method: 使用基于Transformer的方法调整MusicXML钢琴谱难度，创建合成数据集包含按估计难度排序的钢琴谱对，每个对包含同一曲目的更难和更简单版本。利用预训练模型评估难度和风格以确保配对适当。

Result: 实验结果表明该方法有效，通过定性和定量评估显示能够准确控制可演奏性和目标难度。

Conclusion: 与先前工作不同，本文公开所有资源（代码、数据集和模型），确保可重现性，同时促进开源创新以帮助弥合数字鸿沟。

Abstract: Despite its potential, AI advances in music education are hindered by proprietary systems that limit the democratization of technology in this domain. In particular, AI-driven music difficulty adjustment is especially promising, as simplifying complex pieces can make music education more inclusive and accessible to learners of all ages and contexts. Nevertheless, recent efforts have relied on proprietary datasets, which prevents the research community from reproducing, comparing, or extending the current state of the art. In addition, while these generative methods offer great potential, most of them use the MIDI format, which, unlike others, such as MusicXML, lacks readability and layout information, thereby limiting their practical use for human performers. This work introduces a transformer-based method for adjusting the difficulty of MusicXML piano scores. Unlike previous methods, which rely on annotated datasets, we propose a synthetic dataset composed of pairs of piano scores ordered by estimated difficulty, with each pair comprising a more challenging and easier arrangement of the same piece. We generate these pairs by creating variations conditioned on the same melody and harmony and leverage pretrained models to assess difficulty and style, ensuring appropriate pairing. The experimental results illustrate the validity of the proposed approach, showing accurate control of playability and target difficulty, as highlighted through qualitative and quantitative evaluations. In contrast to previous work, we openly release all resources (code, dataset, and models), ensuring reproducibility while fostering open-source innovation to help bridge the digital divide.

</details>

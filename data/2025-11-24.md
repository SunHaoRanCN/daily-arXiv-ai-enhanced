<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 9]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.SD](#cs.SD) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Line-of-Sight Probability in Macrocells: Framework, Statistical Models, and Parametrization from Massive Real World Datasets in the USA](https://arxiv.org/abs/2511.16827)
*Bassel Abou Ali Modad,Xin Yu,Yao-Yi Chiang,Andreas F. Molisch*

Main category: eess.SP

TL;DR: 提出了一个基于地理空间数据的高精度LOS概率建模框架，应用于美国全国范围的宏蜂窝网络，创建了优于3GPP模型的新参数化模型，并展示了基于单小区建模和随机变量处理的改进方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LOS概率模型基于有限数据集，需要更准确的信道描述和覆盖规划模型。

Method: 建立从地理空间数据生成高精度LOS模型的框架，使用美国13000多个宏蜂窝位置数据，创建完全参数化模型，并采用基于单小区建模和随机变量处理的方法。

Result: 开发的新模型比3GPP模型更好地描述了美国宏蜂窝部署，基于单小区的随机变量模型能更准确地预测小区边缘的干扰。

Conclusion: LOS概率应在单小区基础上建模，模型参数应作为随机变量处理，这种方法能提供更准确的干扰预测性能。

Abstract: Accurate modeling of line-of-sight (LOS) probability is crucial for wireless channel description and coverage planning. The presence of a LOS impacts other channel characteristics such as pathloss, fading depth, delay- and angular spread, etc.. Existing models, although useful, are based on very limited datasets. In this paper, we establish a framework to produce high accuracy LOS models from geospatial data in different environments, and apply it to create a LOS model for macrocells, using datasets of the United States (US) on a nationalscale, using more than 13, 000 locations of real-world macrocells. Based on this we create a new, fully parameterized model that better describes macrocell deployments in the US than the 3GPP model. We furthermore demonstrate that for improved accuracy the LOS probability should be modeled on a per cell basis, and the model parameters treated as random variables; we provide a full description and parameterization of this novel approach and by simulations show that it better predicts the inter-cell interference at the cell-edge than an average-based model.

</details>


### [2] [State-of-charge estimation of lithium-ion batteries using a tree seed and genetic algorithm-optimized generalized mixture minimum error entropy-based square root cubature Kalman filter](https://arxiv.org/abs/2511.16888)
*Haiquan Zhao,Xiong Yin,Jinhui Hu*

Main category: eess.SP

TL;DR: 提出了一种基于广义混合最小误差熵的平方根容积卡尔曼滤波器（GMMEE-SRCKF），通过TSGA算法优化核参数，在复杂噪声环境下实现高精度的SOC估计，RMSE低于0.5%。


<details>
  <summary>Details</summary>
Motivation: 现有的基于最小误差熵的容积卡尔曼滤波器（MEE-CKF）在复杂噪声环境下鲁棒性有限，需要更灵活的算法来适应非高斯噪声。

Method: 结合平方根算法确保数值稳定性，使用具有两个灵活核的GMMEE准则适应非高斯噪声，并引入混合树种子遗传算法（TSGA）自动优化核参数。

Result: 实验结果表明，TSGA优化的GMMEE-SRCKF优于现有鲁棒滤波器，均方根误差（RMSE）低于0.5%。

Conclusion: GMMEE-SRCKF算法在复杂噪声环境下具有优越的鲁棒性和估计精度，为SOC估计提供了有效的解决方案。

Abstract: The cubature Kalman filter based on minimum error entropy (MEE-CKF) offers accurate and robust performance in state of charge (SOC) estimation. However, due to the inflexibility of the minimum error entropy (MEE), this algorithm demonstrates limited robustness when confronted with more complex noise environments. To address these limitations, this paper proposes a generalized mixture minimum error entropy-based (GMMEE) square-root cubature Kalman filter (GMMEE-SRCKF). The square-root algorithm ensures improved numerical stability and avoids covariance degeneration, while the GMMEE criterion with two flexible kernels adapts effectively to non-Gaussian noise. Moreover, a hybrid tree seed and genetic algorithm (TSGA) is introduced to optimize the kernel parameters automatically. Experimental results confirm that the TSGA-optimized GMMEE-SRCKF outperforms existing robust filters, achieving the root mean square error (RMSE) of less than 0.5%.

</details>


### [3] [Generative MIMO Beam Map Construction for Location Recovery and Beam Tracking](https://arxiv.org/abs/2511.17007)
*Wangqian Chen,Junting Chen,Shuguang Cui*

Main category: eess.SP

TL;DR: 提出了一种从稀疏CSI测量序列中恢复位置标签的生成框架，无需显式位置标签即可构建无线电地图，通过双尺度特征提取和混合循环-卷积编码器学习移动模式，使用基于扩散的生成解码器重建完整CSI。


<details>
  <summary>Details</summary>
Motivation: 现有基于机器学习的方法依赖大量带位置标签的数据集，这些数据获取困难且成本高昂，因此需要一种无需显式位置标签的方法来构建无线电地图。

Method: 设计双尺度特征提取方案联合利用角度空间和相邻样本相关性；开发混合循环-卷积编码器学习移动模式；嵌入可学习无线电地图捕捉位置信息；使用基于扩散的生成解码器重建CSI。

Result: 相比基于模型的卡尔曼滤波方法，在非视距场景下定位精度提高30%以上，容量增益达到20%。

Conclusion: 该生成框架能够有效从稀疏CSI测量中恢复位置信息，显著提升无线通信系统的定位性能和容量增益。

Abstract: Machine learning (ML) has greatly advanced data-driven channel modeling and resource optimization in wireless communication systems. However, most existing ML-based methods rely on large, accurately labeled datasets with location information, which are often difficult and costly to obtain. This paper proposes a generative framework to recover location labels directly from sequences of sparse channel state information (CSI) measurements, without explicit location labels for radio map construction. Instead of directly storing raw CSI, we learn a compact low-dimensional radio map embedding and leverage a generative model to reconstruct the high-dimensional CSI. Specifically, to address the uncertainty of sparse CSI, a dual-scale feature extraction scheme is designed to enhance feature representation by jointly exploiting correlations from angular space and across neighboring samples. We develop a hybrid recurrent-convolutional encoder to learn mobility patterns, which combines a truncation strategy and multi-scale convolutions in the recurrent neural network (RNN) to ensure feature robustness against short-term fluctuations. Unlike conventional Gaussian priors in latent space, we embed a learnable radio map to capture the location information by encoding high-level positional features from CSI measurements. Finally, a diffusion-based generative decoder reconstructs the full CSI with high fidelity by conditioning on the positional features in the radio map. Numerical experiments demonstrate that the proposed model can improve localization accuracy by over 30% and achieve a 20% capacity gain in non-line-of-sight (NLOS) scenarios compared with model-based Kalman filter approaches.

</details>


### [4] [Movable Intelligent Surface-Enabled Wireless Communications: Static Phase Shifts with Mechanical Reconfigurability](https://arxiv.org/abs/2511.17058)
*Ziyuan Zheng,Qingqing Wu,Wen Chen,Weiren Zhu,Ying Gao*

Main category: eess.SP

TL;DR: 提出了一种新型可移动智能表面(MIS)架构，通过机械滑动预相位次级超表面层来切换波束模式，填补了动态可重构智能表面和静态表面之间的实用空白。


<details>
  <summary>Details</summary>
Motivation: 现有智能表面设计存在两个极端：动态RIS提供精细波束控制但成本高昂，而低成本静态表面只能提供单一波束模式。在准静态环境中，这两种方案都不够经济或灵活。

Method: 开发了MIS信号模型，通过二进制选择矩阵描述静态相位元素与动态几何之间的相互作用。提出了基于惩罚方法、块坐标下降和黎曼流形优化的高效算法来解决混合整数非凸优化问题。

Result: 仿真结果表明，所提出的MIS架构显著缩小了单层静态表面和动态RIS之间的性能差距。

Conclusion: MIS为准静态无线应用提供了一种实用且灵活的解决方案。

Abstract: Intelligent surfaces that reshape electromagnetic waves are regarded as disruptive technologies for wireless networks. However, existing designs sit at two costly extremes: dynamic reconfigurable intelligent surfaces (RISs) offer fine beam control but require dense cabling, continuous power consumption, and substantial signaling overhead, whereas low-cost static surfaces require no control lines or electronics but are limited to a single beam pattern. This disparity leaves a practical gap for quasi-static environments, such as industrial Internet-of-things and smart agriculture scenarios, where channels are stable with user demands changing only occasionally or periodically, and neither extreme is sufficiently economical or flexible. To bridge this gap, we propose a novel movable intelligent surface (MIS) architecture, whose beam patterns are switched not by electronic phase tuning but by mechanically sliding a small, pre-phased secondary metasurface layer across a larger, likewise static primary layer. We develop an MIS signal model that characterizes the interaction between static phase elements with dynamic geometry via binary selection matrices. Based on this model, we formulate a new type of optimization problems that jointly design static phase shifts and the overlapping position selection of MS2 (equal to beam pattern scheduling). Efficient algorithms based on the penalty method, block coordinate descent, and Riemannian manifold optimization are proposed to tackle these mixed-integer non-convex problems. Simulation results demonstrate that the proposed MIS architecture substantially narrows the performance gap between single-layer static surfaces and dynamic RISs, providing a practical and flexible solution for quasi-static wireless applications.

</details>


### [5] [Super-Resolution ISAC Receivers: An MCMC-Based Gridless Sparse Bayesian Learning Approach](https://arxiv.org/abs/2511.17062)
*Keying Zhu,Xingyu Zhou,Jie Yang,Le Liang,Shi Jin*

Main category: eess.SP

TL;DR: 提出了一种新颖的无网格稀疏贝叶斯学习框架，用于联合超分辨率多目标检测和高精度参数估计，解决了传统方法在精度和复杂度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 低空无线网络中的集成感知与通信需要高精度感知，但传统方法在精度和复杂度之间存在权衡。为了解决这个问题，需要开发一种能够在强杂波环境下实现超分辨率多目标检测和高精度参数估计的方法。

Method: 采用无网格稀疏贝叶斯学习框架，将目标参数视为连续变量以避免传统方法的网格限制。开发了增强的基于梯度的马尔可夫链蒙特卡洛算法，集成了小批量采样和Adam优化器以确保计算效率和快速收敛。

Result: 仿真结果显示出色的超分辨率能力，成功分辨出距离、速度和角度分别仅为瑞利极限50%、17%和52%的多个目标。在20dB信噪比下，多目标检测概率超过90%，同时实现超高精度：距离、速度和角度的均方根误差分别为0.07m、0.024m/s和0.015度。

Conclusion: 该框架在强杂波环境下表现出稳健性能，展示了其在实用ISAC-LAWNs应用中的适用性，为低空无线网络中的集成感知与通信提供了有效的解决方案。

Abstract: Integrated sensing and communication (ISAC) is crucial for low-altitude wireless networks (LAWNs), where the safety-critical demand for high-accuracy sensing creates a trade-off between precision and complexity for conventional methods. To address this, we propose a novel gridless sparse Bayesian learning (SBL) framework for joint super-resolution multi-target detection and high-accuracy parameter estimation with manageable computational cost. Our model treats target parameters as continuous variables to bypass the grid limitations of conventional approaches. This SBL formulation, however, transforms the estimation task into a challenging high-dimensional inference problem, which we address by developing an enhanced gradient-based Markov chain Monte Carlo algorithm. Our method integrates mini-batch sampling and the Adam optimizer to ensure computational efficiency and rapid convergence. Finally, we validate the framework's robustness in strong clutter and provide a theoretical benchmark by deriving the corresponding Bayesian Cramer-Rao bound. Simulation results demonstrate remarkable super-resolution capabilities, successfully resolving multiple targets separated by merely 50% of the Rayleigh limit in range, 17% in velocity, and 52% in angle. At a signal-to-noise ratio of 20 dB, the algorithm achieves a multi-target detection probability exceeding 90% while concurrently delivering ultra-high accuracy, with root mean square error of 0.07 m, 0.024 m/s, and 0.015 degree for range, velocity, and angle, respectively. This robust performance, demonstrated against strong clutter, showcases its suitability for practical ISAC-LAWNs applications.

</details>


### [6] [Distributed Cubature Kalman Filter based on MEEF with Adaptive Cauchy Kernel for State Estimation](https://arxiv.org/abs/2511.17066)
*Duc Viet Nguyen,Haiquan Zhao,Jinhui Hu*

Main category: eess.SP

TL;DR: 提出基于自适应最小误差熵与基准点的分布式容积卡尔曼滤波器(AMEEF-DCKF)，解决非高斯噪声、异常数据和通信负担问题。


<details>
  <summary>Details</summary>
Motivation: 多传感器网络中，分布式容积卡尔曼滤波器面临非高斯噪声、异常数据和通信负担的挑战，需要改进现有方案。

Method: 设计AMEEF优化准则使用自适应带宽的柯西核处理非高斯噪声和异常数据；构建领导者-跟随者平均一致性(LFAC)算法降低通信负担；提供收敛性证明和计算复杂度分析。

Result: 通过10节点传感器网络验证，在电力系统状态估计和复杂环境陆地车辆导航中表现出有效性。

Conclusion: AMEEF-DCKF算法能有效处理非高斯噪声、异常数据，并降低通信负担，在多传感器状态估计中具有良好性能。

Abstract: Nowadays, with the development of multi-sensor networks, the distributed cubature Kalman filter is one of the well-known existing schemes for state estimation, for which the influence of the non-Gaussian noise, abnormal data, and communication burden are urgent challenges. In this paper, a distributed cubature Kalman filter based on adaptive minimum error entropy with fiducial points (AMEEF) criterion (AMEEF-DCKF) is proposed to overcome the above limitations. Specifically, firstly, in order to solve the influence of various types of non-Gaussian noise and abnormal data, the AMEEF optimization criterion is designed, in which the kernels used are Cauchy kernels with adaptive bandwidth. At the same time, the designed optimization criterion has enhanced the numerical stability and optimized the kernel bandwidth value. Next, in order to address the communication burden problem in multi-sensor networks, where a leader and a follower are distinguished, a distributed algorithm is constructed to achieve an average consensus among these sensors, called leader-follower average consensus (LFAC). Additionally, the convergence proof of the average consensus algorithm and the computational complexity analysis of the AMEEF-DCKF algorithm are also presented. Finally, through a 10-node sensor network, the effectiveness of the proposed algorithm is demonstrated in estimating the state of the power system and navigating land vehicles in complex environments.

</details>


### [7] [Unleashing Sensor-Aided Environment Awareness for Beam Management in Beyond-5G Networks: An OpenAirInterface Experimental Platform](https://arxiv.org/abs/2511.17122)
*Aron Schott,Berk Acikgöz,Omar Massoud,Marina Petrova,Ljiljana Simić*

Main category: eess.SP

TL;DR: 提出了一个基于SDR的完整实验平台，集成低成本天线阵列收发器、波束扫描能力和模块化传感器框架，用于实时真实场景下的波束管理实验和数据集收集。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏用于训练机器学习波束管理技术的开放平台和数据集，特别是在真实场景和端到端网络中评估新方法。

Method: 基于OpenAirInterface开发SDR实验平台，集成低成本天线阵列收发器、波束扫描功能和模块化传感器框架。

Result: 成功构建了首个集成这些功能的完整实验平台，支持实时真实场景下的波束管理实验。

Conclusion: 该平台为开发基于机器学习的波束管理协议提供了必要的实验环境和数据集收集能力，能够利用传感器模态实现环境感知。

Abstract: Large antenna arrays and beamforming techniques are key components for exploiting the spectrum-rich FR2 bands in next-generation mobile communication networks. Given the site-specific spatio-temporal variations of the mm-wave channel, non-RF sensor inputs and environment awareness can be leveraged to greatly enhance beam management decisions, e.g. via machine learning (ML) techniques. However, the current literature lacks open platforms to gather datasets for the training of such ML techniques and to evaluate novel beam management approaches in real-time, real-world scenarios and full-stack endto-end networks. In this work, we present our SDR-based experimental platform based on OpenAirInterface and are the first to integrate popular low-cost antenna array transceivers, beam sweeping capabilities, and a highly-modular sensor framework and associated interfaces into such a full-stack experimental platform. This enables beam management experimentation in real-world, real-time scenarios and facilitates gathering datasets necessary for developing ML-based beam management protocols that incorporate environment awareness via sensor modalities.

</details>


### [8] [Teager-Kaiser Energy Methods For EEG Feature Extraction In Biomedical Applications](https://arxiv.org/abs/2511.17164)
*Ioanna Chourdaki,Kleanthis Avramidis,Christos Garoufis,Athanasia Zlatintsi,Petros Maragos*

Main category: eess.SP

TL;DR: 本文研究了Teager-Kaiser能量算子(TKEO)在EEG信号分析中的应用，通过Gabor滤波器组和能量分离算法提取能量描述符，在运动想象和癫痫检测任务中优于传统能量特征。


<details>
  <summary>Details</summary>
Motivation: EEG信号具有非线性、非平稳性和易受噪声影响的特点，提取判别性特征一直是个挑战。本文旨在探索TKEO算子对EEG信号能量动态建模的有效性。

Method: 使用Gabor滤波器组分离标准频带，应用能量分离算法将TKEO输出分解为幅度包络和瞬时频率分量，然后基于此解调推导出一组能量描述符。

Result: TKEO特征在运动想象和癫痫检测任务中优于基线方法，在情绪识别任务中表现相当。

Conclusion: 提出的基于TKEO的流程为提取EEG信号动态提供了一个直观的框架。

Abstract: Electroencephalography (EEG) signals are inherently non-linear, non-stationary, and vulnerable to noise sources, making the extraction of discriminative features a long-standing challenge. In this work, we investigate the non-linear Teager-Kaiser Energy Operator (TKEO) for modeling the underlying energy dynamics of EEG in three representative tasks: motor imagery, emotion recognition, and epilepsy detection. To accommodate the narrowband nature of the operator, we employ Gabor filterbanks to isolate canonical frequency bands, followed by the Energy Separation Algorithm to decompose the TKEO output into amplitude envelope and instantaneous frequency components. We then derive a set of energy descriptors based on this demodulation and compare their classification performance against established signal energy and power spectrum features. TKEO features outperform the respective baselines in motor imagery and epilepsy detection, whereas they perform on par in emotion recognition. Our findings suggest that the proposed TKEO-based pipeline provides an intuitive framework for extracting EEG signal dynamics.

</details>


### [9] [Incorporating Bayesian Transfer Learning into Particle Filter for Dual-Tracking System with Asymmetric Noise Intensities](https://arxiv.org/abs/2511.17440)
*Omar A. Alotaibi,Brian L. Mark,Mohammad Reza Fasihi*

Main category: eess.SP

TL;DR: 提出了一种基于贝叶斯迁移学习的粒子滤波方法，用于处理双传感器系统中测量噪声强度不对称的非线性动态模型跟踪问题。


<details>
  <summary>Details</summary>
Motivation: 在双传感器跟踪系统中，主传感器通常面临比源传感器更高的噪声强度，需要改进跟踪性能。

Method: 使用加权粒子之和来近似贝叶斯迁移学习的密度，提高主传感器的跟踪性能。

Result: 仿真结果表明，该方法比孤立粒子滤波以及应用于无迹卡尔曼滤波和容积卡尔曼滤波的迁移学习更有效。增加粒子数量能更显著提升性能，但会增加计算时间。

Conclusion: 贝叶斯迁移学习的性能增益与双传感器系统中噪声强度绝对差值近似线性相关。

Abstract: Using Bayesian transfer learning, we develop a particle filter approach for tracking a nonlinear dynamical model in a dual-tracking system where intensities of measurement noise for both sensors are asymmetric. The densities for Bayesian transfer learning are approximated with the sum of weighted particles to improve the tracking performance of the primary sensor, which experiences a higher noise intensity compared to the source sensor. We present simulation results that validate the effectiveness of the proposed approach compared to an isolated particle filter and transfer learning applied to the unscented Kalman filter and the cubature Kalman filter. Furthermore, increasing the number of particles shows an improvement in the performance of transfer learning applied to the particle filter with a higher rate compared to the isolated particle filter. However, increasing the number of particles raises computational time per step. Moreover, the performance gain from incorporating Bayesian transfer learning is approximately linearly proportional to the absolute difference value between the noise intensities of the sensors in the dual-tracking system.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [10] [Revisiting Audio-language Pretraining for Learning General-purpose Audio Representation](https://arxiv.org/abs/2511.16757)
*Wei-Cheng Tseng,Xuanru Zhou,Mingyue Huo,Yiwen Shao,Hao Zhang,Dong Yu*

Main category: eess.AS

TL;DR: 该论文提出了CaptionStew数据集（1070万条音频-文本对），系统评估了对比学习和描述生成两种预训练目标在音频表示学习中的表现，发现对比学习在小规模数据上更高效，而描述生成在语言相关的音频理解任务上更具扩展性。


<details>
  <summary>Details</summary>
Motivation: 音频-语言预训练在通用音频理解方面具有潜力，但与视觉-语言模型相比仍未被充分探索。现有音频-语言模型主要擅长检索任务，作为通用编码器的应用有限，主要障碍包括：大规模音频-文本语料库有限、字幕多样性不足、缺乏系统探索和评估。

Method: 构建CaptionStew数据集（聚合多个领域的开源音频-文本语料库），系统比较对比学习和描述生成两种预训练目标在语音、音乐和环境声音任务中的表现，进行数据规模扩展实验。

Result: 音频-语言预训练产生具有竞争力的可迁移表示；对比学习在小规模时数据效率更高，描述生成在语言相关的音频理解任务上扩展性更好；常见的监督初始化方法在大规模时收益递减。

Conclusion: 音频-语言预训练是实现通用音频表示的可行途径，为未来研究提供指导。作者发布了数据准备方法、训练协议和预训练模型，推动通用音频理解的发展。

Abstract: Audio-language pretraining holds promise for general-purpose audio understanding, yet remains underexplored compared to its vision counterpart. While vision-language models like CLIP serve as widely adopted foundations, existing audio-language models primarily excel at retrieval tasks with limited adoption as general-purpose encoders. We identify three key barriers: limited large-scale audio-text corpora, insufficient caption diversity, and lack of systematic exploration and evaluation. To this end, we introduce CaptionStew, a 10.7M caption dataset aggregating diverse open-source audio-text corpora across multiple domains and captioning styles. Using this resource, we conduct the first comprehensive evaluation comparing contrastive and captioning objectives for audio representation learning across speech, music, and environmental sound tasks. Our results demonstrate that audio-language pretraining yields competitive, transferable representations. Through systematic data-scaling experiments, we reveal complementary objective strengths: contrastive learning achieves superior data efficiency at smaller scales, while captioning demonstrates better scalability on language-involved audio understanding tasks. We also find that common supervised initialization practices provide diminishing returns at scale, challenging current approaches. These findings establish audio-language pretraining as a viable pathway toward general-purpose audio representations, guiding future research. To accelerate progress, we release data preparation recipes, training protocols, and pretrained models, paving the way toward universal audio understanding.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [11] [Device-Guided Music Transfer](https://arxiv.org/abs/2511.17136)
*Manh Pham Hung,Changshuo Hu,Ting Dang,Dong Ma*

Main category: cs.SD

TL;DR: DeMT是一种设备引导的音乐传输方法，通过处理扬声器频率响应曲线来提取设备嵌入，实现跨设备的音乐播放适配和风格迁移。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注音色、节奏、和声或乐器编排来模仿流派或艺术家，但忽略了播放设备（扬声器）的多样化硬件特性。

Method: 使用视觉语言模型处理扬声器频率响应曲线作为线图来提取设备嵌入，然后通过特征线性调制将这些嵌入条件化到混合变压器中。

Result: 在自收集数据集上微调后，DeMT能够实现有效的扬声器风格迁移和对未见设备的鲁棒少样本适配。

Conclusion: DeMT支持设备风格增强和质量提升等应用，为跨设备音乐传输提供了新的解决方案。

Abstract: Device-guided music transfer adapts playback across unseen devices for users who lack them. Existing methods mainly focus on modifying the timbre, rhythm, harmony, or instrumentation to mimic genres or artists, overlooking the diverse hardware properties of the playback device (i.e., speaker). Therefore, we propose DeMT, which processes a speaker's frequency response curve as a line graph using a vision-language model to extract device embeddings. These embeddings then condition a hybrid transformer via feature-wise linear modulation. Fine-tuned on a self-collected dataset, DeMT enables effective speaker-style transfer and robust few-shot adaptation for unseen devices, supporting applications like device-style augmentation and quality enhancement.

</details>


### [12] [The Artist is Present: Traces of Artists Resigind and Spawning in Text-to-Audio AI](https://arxiv.org/abs/2511.17404)
*Guilherme Coelho*

Main category: cs.SD

TL;DR: 该论文通过元标签提示工程方法，系统性地定位和生成特定艺术家风格的音频内容，揭示了文本到音频系统如何利用艺术家作品作为训练数据生成新内容，引发关于版权、授权和算法创作伦理的问题。


<details>
  <summary>Details</summary>
Motivation: 研究文本到音频系统如何通过提示工程访问特定艺术家的独特声音特征，验证这些艺术家作品是否被纳入训练数据集，并探索算法创作中的伦理和版权问题。

Method: 使用元标签提示工程技术，基于公共音乐分类法构建描述符星座，系统探索艺术家风格的可诱导性，通过战略提示设计实现艺术家风格内容的生成。

Result: 成功实现了对Bon Iver、Philip Glass、Panda Bear和William Basinski等艺术家风格的稳定复现，证明了文本-音频对应关系的存在，能够在不明说艺术家名字的情况下精确遍历风格微位置。

Conclusion: 文本到音频系统利用艺术家的创作作品作为基础材料生成新内容，通常未经明确同意或署名，这引发了关于归属权、同意和披露标准的治理问题，以及创作实践中所有权、复制、模仿和算法创作伦理的复杂边界问题。

Abstract: Text-to-audio (TTA) systems are rapidly transforming music creation and distribution, with platforms like Udio and Suno generating thousands of tracks daily and integrating into mainstream music platforms and ecosystems. These systems, trained on vast and largely undisclosed datasets, are fundamentally reshaping how music is produced, reproduced and consumed. This paper presents empirical evidence that artist-conditioned regions can be systematically microlocated through metatag-based prompt design, effectively enabling the spawning of artist-like content through strategic prompt engineering. Through systematic exploration of metatag-based prompt engineering techniques this research reveals how users can access the distinctive sonic signatures of specific artists, evidencing their inclusion in training datasets. Using descriptor constellations drawn from public music taxonomies, the paper demonstrates reproducible proximity to artists such as Bon Iver, Philip Glass, Panda Bear and William Basinski. The results indicate stable text-audio correspondences consistent with artist-specific training signals, enabling precise traversal of stylistic microlocations without explicitly naming artists. This capacity to summon artist-specific outputs shows that artists' creative works fuction as foundational material from which these systems generate new content, often without explicit consent or attribuition. Conceptually, the work clarifies how textual descriptors act as navigational cues in high-dimensional representation spaces; methodologically, it provides a replicable protocol for auditing stylistic inducibility. The findings raise immediate queestions for governance-attribution, consent and disclosure standards-and for creative practice, where induced stylistic proximity complicates boundaries between ownership, reproduction, imitation, creative agency and the ethics of algorithmic creation.

</details>


### [13] [MusicAIR: A Multimodal AI Music Generation Framework Powered by an Algorithm-Driven Core](https://arxiv.org/abs/2511.17323)
*Callie C. Liao,Duoduo Liao,Ellie L. Zhang*

Main category: cs.SD

TL;DR: MusicAIR是一个创新的多模态AI音乐生成框架，使用算法驱动的符号音乐核心，从歌词自动生成完整的旋律乐谱，有效降低版权侵权风险。


<details>
  <summary>Details</summary>
Motivation: 解决现有神经模型依赖大型数据集导致的版权侵权和高性能成本问题，开发一种更安全、高效的AI音乐生成方法。

Method: 采用算法驱动的符号音乐核心，连接歌词和节奏信息自动推导音乐特征，支持从歌词、文本和图像生成音乐。

Result: 系统平均调性置信度达85%，优于人类作曲家的79%，生成的音乐符合音乐理论标准，能够创作多样化、类人化的作品。

Conclusion: MusicAIR作为协同创作工具，可成为可靠的音乐创作助手和教育导师，降低音乐创作门槛，对AI音乐生成领域有重要贡献。

Abstract: Recent advances in generative AI have made music generation a prominent research focus. However, many neural-based models rely on large datasets, raising concerns about copyright infringement and high-performance costs. In contrast, we propose MusicAIR, an innovative multimodal AI music generation framework powered by a novel algorithm-driven symbolic music core, effectively mitigating copyright infringement risks. The music core algorithms connect critical lyrical and rhythmic information to automatically derive musical features, creating a complete, coherent melodic score solely from the lyrics. The MusicAIR framework facilitates music generation from lyrics, text, and images. The generated score adheres to established principles of music theory, lyrical structure, and rhythmic conventions. We developed Generate AI Music (GenAIM), a web tool using MusicAIR for lyric-to-song, text-to-music, and image-to-music generation. In our experiments, we evaluated AI-generated music scores produced by the system using both standard music metrics and innovative analysis that compares these compositions with original works. The system achieves an average key confidence of 85%, outperforming human composers at 79%, and aligns closely with established music theory standards, demonstrating its ability to generate diverse, human-like compositions. As a co-pilot tool, GenAIM can serve as a reliable music composition assistant and a possible educational composition tutor while simultaneously lowering the entry barrier for all aspiring musicians, which is innovative and significantly contributes to AI for music generation.

</details>


### [14] [AI in Music and Sound: Pedagogical Reflections, Post-Structuralist Approaches and Creative Outcomes in Seminar Practice](https://arxiv.org/abs/2511.17425)
*Guilherme Coelho*

Main category: cs.SD

TL;DR: 该论文介绍了一门AI音乐与声音课程的课程设计，采用配对练习的教学方法，让学生通过正常使用和故意误用AI工具来理解其表征限制和替代行为，培养学生的技术流畅性、媒介意识和批判素养。


<details>
  <summary>Details</summary>
Motivation: 旨在通过结合理论反思和实践实验的教学方法，帮助学生理解AI作为跨模态导管的特性，培养学生在AI音乐创作中的技术能力、媒介意识和批判性思维。

Method: 采用配对练习设计：每个AI模态先通过其预期功能学习，然后通过故意重构或误用的练习来揭示表征限制；课程涵盖符号作曲、语音合成、音色转换、神经音频合成和文本转音频等AI模态。

Result: 学生作品和反思显示学生在技术流畅性、媒介意识和批判素养方面有所成长，同时培养了实验方法和过程导向的聆听能力；提炼出一套AI音乐教学的设计模式。

Conclusion: 提出了整合创造性实践、媒介意识和AI技术文化认识论分析的教学建议，帮助学生参与AI在创意社区中的理解、开发和部署过程。

Abstract: This paper presents a pedagogical and conceptual account of the course AI in Music and Sound: Modalities, Tools and Creative Applications, offered within the Music Informatics and Media Art module of an M.Sc. in Audio Communication. The course engaged students with a range of AI modalities such as symbolic composition, voice synthesis, timbre transfer, neural audio synthesis, and text-to-audio systems, combining theoretical reflection with practice-based experimentation. Its central pedagogical move is a paired-études design: each modality is approached first through its intended affordances and then through a deliberately reframed or "misused" exercise that surfaces representational limits and alternative behaviours. Framed by medium theory and post-structuralist inquiry, we treated AI as a transmodal conduit-a system that translates and perturbs musical signs across textual, symbolic, timbral and audio domains. Evidence from student work and reflection indicates growth in technical fluency, medium awareness, and critical literacy, alongside the cultivation of experimental method and process-oriented listening. The paper outlines the course architecture, assessment design, and representative projects, and distils a set of design patterns for AI-music pedagogy (eg., prompt-conditioned interplays and semantic destabilisation in text-to-audio; latent space materialism in timbre transfer). It concludes with pedagogical recommendations that integrate creative practice with medium awareness and with cultural-epistemic analysis of AI technologies, preparing students to participate in how AI is understood, developed, and deployed with creative communities.

</details>


### [15] [Is Phase Really Needed for Weakly-Supervised Dereverberation ?](https://arxiv.org/abs/2511.17346)
*Marius Rodrigues,Louis Bahrman,Roland Badeau,Gaël Richard*

Main category: cs.SD

TL;DR: 基于统计波场理论，研究发现混响语音的相位在时频域中携带的有用信息有限，因此在弱监督语音去混响中可排除混响相位信息来提升性能。


<details>
  <summary>Details</summary>
Motivation: 在无监督或弱监督语音去混响方法中，目标干净信号在训练时未知，因此需要评估仅从混响语音中能恢复多少信息，特别是混响相位的作用。

Method: 基于统计波场理论分析混响相位特性，并在弱监督框架下训练去混响模型，从损失函数中排除混响相位。

Result: 研究表明后期混响会使相位分量受到白噪声扰动，混响相位携带的有用信息有限，排除混响相位可显著提升去混响性能。

Conclusion: 混响相位在弱监督去混响中不是必需的，排除相位信息可以改善模型性能。

Abstract: In unsupervised or weakly-supervised approaches for speech dereverberation, the target clean (dry) signals are considered to be unknown during training. In that context, evaluating to what extent information can be retrieved from the sole knowledge of reverberant (wet) speech becomes critical. This work investigates the role of the reverberant (wet) phase in the time-frequency domain. Based on Statistical Wave Field Theory, we show that late reverberation perturbs phase components with white, uniformly distributed noise, except at low frequencies. Consequently, the wet phase carries limited useful information and is not essential for weakly supervised dereverberation. To validate this finding, we train dereverberation models under a recent weak supervision framework and demonstrate that performance can be significantly improved by excluding the reverberant phase from the loss function.

</details>


### [16] [Semantic and Semiotic Interplays in Text-to-Audio AI: Exploring Cognitive Dynamics and Musical Interactions](https://arxiv.org/abs/2511.17429)
*Guilherme Coelho*

Main category: cs.SD

TL;DR: 本文研究文本到音频AI范式对音乐创作、诠释和认知的变革性影响，探讨语言提示与声音对象之间的语义符号互动，以及AI系统如何重构音乐意义过程和认知框架。


<details>
  <summary>Details</summary>
Motivation: 探索文本到音频AI系统在音乐创作和认知中的新兴作用，理解这些系统如何改变音乐的意义生成过程和认知模式。

Method: 采用结构主义和后结构主义视角，结合认知理论中的图式动态和元认知概念，以Udio为主要案例研究，分析AI介导的音乐活动中的认知动态。

Result: 文本到音频AI模型作为音乐意义的准对象，既稳定又颠覆传统形式，促进新的聆听模式和审美反思，鼓励批判性和结构感知的聆听方式。

Conclusion: 文本到音频AI模型具有作为认知工具和准对象的潜力，能够促进音乐互动的重大转变，帮助用户更细致地理解音乐的认知和文化基础。

Abstract: This paper investigates the emerging text-to-audio paradigm in artificial intelligence (AI), examining its transformative implications for musical creation, interpretation, and cognition. I explore the complex semantic and semiotic interplays that occur when descriptive natural language prompts are translated into nuanced sound objects across the text-to-audio modality. Drawing from structuralist and post-structuralist perspectives, as well as cognitive theories of schema dynamics and metacognition, the paper explores how these AI systems reconfigure musical signification processes and navigate established cognitive frameworks. The research analyzes some of the cognitive dynamics at play in AI-mediated musicking, including processes of schema assimilation and accommodation, metacognitive reflection, and constructive perception. The paper argues that text-to-audio AI models function as quasi-objects of musical signification, simultaneously stabilizing and destabilizing conventional forms while fostering new modes of listening and aesthetic reflexivity.Using Udio as a primary case study, this study explores how these models navigate the liminal spaces between linguistic prompts and sonic outputs. This process not only generates novel musical expressions but also prompts listeners to engage in forms of critical and "structurally-aware listening.", encouraging a deeper understanding of music's structures, semiotic nuances, and the socio-cultural contexts that shape our musical cognition. The paper concludes by reflecting on the potential of text-to-audio AI models to serve as epistemic tools and quasi-objects, facilitating a significant shift in musical interactions and inviting users to develop a more nuanced comprehension of the cognitive and cultural foundations of music.

</details>


### [17] [Enhancing Quranic Learning: A Multimodal Deep Learning Approach for Arabic Phoneme Recognition](https://arxiv.org/abs/2511.17477)
*Ayhan Kucukmanisa,Derya Gelmez,Sukru Selim Calik,Zeynep Hilal Kilimci*

Main category: cs.SD

TL;DR: 提出基于Transformer的多模态框架，结合声学和文本表示来检测阿拉伯语音素发音错误，特别针对古兰经诵读场景。


<details>
  <summary>Details</summary>
Motivation: 阿拉伯语特别是古兰经诵读中的准确发音检测具有挑战性，细微的语音差异可能改变含义，需要更高精度和鲁棒性的检测方法。

Method: 集成UniSpeech声学嵌入和基于BERT的文本嵌入（来自Whisper转录），采用早期、中期和晚期融合策略，在两个包含29个阿拉伯语音素的数据集上进行评估。

Result: 实验结果显示UniSpeech-BERT多模态配置表现良好，基于融合的Transformer架构在音素级发音错误检测中有效。

Conclusion: 该研究为开发智能、说话人无关的多模态计算机辅助语言学习系统做出贡献，为技术支持的古兰经发音训练和更广泛的语音教育应用提供了实用步骤。

Abstract: Recent advances in multimodal deep learning have greatly enhanced the capability of systems for speech analysis and pronunciation assessment. Accurate pronunciation detection remains a key challenge in Arabic, particularly in the context of Quranic recitation, where subtle phonetic differences can alter meaning. Addressing this challenge, the present study proposes a transformer-based multimodal framework for Arabic phoneme mispronunciation detection that combines acoustic and textual representations to achieve higher precision and robustness. The framework integrates UniSpeech-derived acoustic embeddings with BERT-based textual embeddings extracted from Whisper transcriptions, creating a unified representation that captures both phonetic detail and linguistic context. To determine the most effective integration strategy, early, intermediate, and late fusion methods were implemented and evaluated on two datasets containing 29 Arabic phonemes, including eight hafiz sounds, articulated by 11 native speakers. Additional speech samples collected from publicly available YouTube recordings were incorporated to enhance data diversity and generalization. Model performance was assessed using standard evaluation metrics: accuracy, precision, recall, and F1-score, allowing a detailed comparison of the fusion strategies. Experimental findings show that the UniSpeech-BERT multimodal configuration provides strong results and that fusion-based transformer architectures are effective for phoneme-level mispronunciation detection. The study contributes to the development of intelligent, speaker-independent, and multimodal Computer-Aided Language Learning (CALL) systems, offering a practical step toward technology-supported Quranic pronunciation training and broader speech-based educational applications.

</details>

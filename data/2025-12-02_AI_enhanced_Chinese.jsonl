{"id": "2512.00482", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2512.00482", "abs": "https://arxiv.org/abs/2512.00482", "authors": ["Yair Amar", "Amir Ivry", "Israel Cohen"], "title": "Beyond Performance: Probing Representation Dynamics In Speech Enhancement Models", "comment": null, "summary": "We probe internal representations of a speech enhancement (SE) model across noise conditions. Using MUSE, a transformer-convolutional model trained on VoiceBank DEMAND, we analyze activations in encoder, latent, decoder, and refinement blocks while sweeping input signal-to-noise-ratios (SNRs) from -10 to 30 dB. We use Centered Kernel Alignment (CKA) to measure point-wise representation similarity and diffusion distance to capture distributional shifts across SNRs. Results show that the encoder CKA between noisy and clean inputs remains stable and latent and decoder CKA drop sharply as SNR decreases. Linear fits of CKA versus SNR reveal a depth-dependent robustness-sensitivity trade-off. The diffusion distance varies incrementally with SNR within each layer but differs strongly across layers, especially at low SNRs. Together, these findings indicate that noise levels differentially activate model regions and induce distinct inter-layer dynamics, motivating SNR-aware conditioning and refinement strategies for SE.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5206\u6790\u4e86\u8bed\u97f3\u589e\u5f3a\u6a21\u578b\u5728\u4e0d\u540c\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u7684\u5185\u90e8\u8868\u5f81\uff0c\u53d1\u73b0\u7f16\u7801\u5668\u5bf9\u566a\u58f0\u5177\u6709\u9c81\u68d2\u6027\uff0c\u800c\u6f5c\u5728\u5c42\u548c\u89e3\u7801\u5668\u5bf9\u566a\u58f0\u654f\u611f\uff0c\u63ed\u793a\u4e86\u6df1\u5ea6\u4f9d\u8d56\u7684\u9c81\u68d2\u6027-\u654f\u611f\u6027\u6743\u8861\u3002", "motivation": "\u7814\u7a76\u8bed\u97f3\u589e\u5f3a\u6a21\u578b\u5728\u4e0d\u540c\u566a\u58f0\u6761\u4ef6\u4e0b\u5185\u90e8\u8868\u5f81\u7684\u53d8\u5316\uff0c\u4e86\u89e3\u6a21\u578b\u5982\u4f55\u5e94\u5bf9\u4e0d\u540c\u4fe1\u566a\u6bd4\u7684\u8f93\u5165\uff0c\u4e3a\u8bbe\u8ba1\u4fe1\u566a\u6bd4\u611f\u77e5\u7684\u8bed\u97f3\u589e\u5f3a\u7b56\u7565\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "method": "\u4f7f\u7528MUSE\u6a21\u578b\uff08\u57fa\u4e8eVoiceBank DEMAND\u8bad\u7ec3\u7684transformer-convolutional\u6a21\u578b\uff09\uff0c\u5728-10\u523030 dB\u7684\u4fe1\u566a\u6bd4\u8303\u56f4\u5185\u5206\u6790\u7f16\u7801\u5668\u3001\u6f5c\u5728\u5c42\u3001\u89e3\u7801\u5668\u548c\u7ec6\u5316\u5757\u7684\u6fc0\u6d3b\u3002\u91c7\u7528\u4e2d\u5fc3\u6838\u5bf9\u9f50\uff08CKA\uff09\u6d4b\u91cf\u70b9\u8868\u793a\u76f8\u4f3c\u6027\uff0c\u6269\u6563\u8ddd\u79bb\u6355\u6349\u8de8\u4fe1\u566a\u6bd4\u7684\u5206\u5e03\u53d8\u5316\u3002", "result": "\u7f16\u7801\u5668\u7684CKA\u5728\u566a\u58f0\u548c\u5e72\u51c0\u8f93\u5165\u4e4b\u95f4\u4fdd\u6301\u7a33\u5b9a\uff0c\u800c\u6f5c\u5728\u5c42\u548c\u89e3\u7801\u5668\u7684CKA\u968f\u4fe1\u566a\u6bd4\u964d\u4f4e\u800c\u6025\u5267\u4e0b\u964d\u3002CKA\u4e0e\u4fe1\u566a\u6bd4\u7684\u7ebf\u6027\u62df\u5408\u63ed\u793a\u4e86\u6df1\u5ea6\u4f9d\u8d56\u7684\u9c81\u68d2\u6027-\u654f\u611f\u6027\u6743\u8861\u3002\u6269\u6563\u8ddd\u79bb\u5728\u5404\u5c42\u5185\u968f\u4fe1\u566a\u6bd4\u9010\u6e10\u53d8\u5316\uff0c\u4f46\u5728\u5c42\u95f4\u5dee\u5f02\u663e\u8457\uff0c\u5c24\u5176\u5728\u4f4e\u4fe1\u566a\u6bd4\u65f6\u3002", "conclusion": "\u566a\u58f0\u6c34\u5e73\u4f1a\u5dee\u5f02\u6027\u5730\u6fc0\u6d3b\u6a21\u578b\u7684\u4e0d\u540c\u533a\u57df\u5e76\u5f15\u53d1\u4e0d\u540c\u7684\u5c42\u95f4\u52a8\u6001\uff0c\u8fd9\u4e3a\u8bbe\u8ba1\u4fe1\u566a\u6bd4\u611f\u77e5\u7684\u6761\u4ef6\u548c\u7ec6\u5316\u7b56\u7565\u63d0\u4f9b\u4e86\u52a8\u673a\uff0c\u6709\u52a9\u4e8e\u6539\u8fdb\u8bed\u97f3\u589e\u5f3a\u6a21\u578b\u7684\u6027\u80fd\u3002"}}
{"id": "2512.00511", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2512.00511", "abs": "https://arxiv.org/abs/2512.00511", "authors": ["Ellison Murray", "Morriel Kasher", "Predrag Spasojevic"], "title": "A Low-Complexity Speech Codec Using Parametric Dithering for ASR", "comment": "10 pages, 8 figures, Accepted 2026 Data Compression Conference", "summary": "Dithering is a technique commonly used to improve the perceptual quality of lossy data compression. In this work, we analytically and experimentally justify the use of dithering for ASR input compression. We formalize an understanding of optimal ASR performance under lossy input compression and leverage this to propose a parametric dithering technique for a low-complexity speech compression pipeline. The method performs well at 1-bit resolution, showing a 25\\% relative CER improvement, while also demonstrating improvements of 32.4\\% and 33.5\\% at 2- and 3-bit resolution, respectively, with our second dither choice yielding a reduced data rate. The proposed codec is adaptable to meet performance targets or stay within entropy constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8eASR\u8f93\u5165\u538b\u7f29\u7684\u6296\u52a8\u6280\u672f\uff0c\u57281\u6bd4\u7279\u5206\u8fa8\u7387\u4e0b\u5b9e\u73b025%\u76f8\u5bf9CER\u6539\u8fdb\uff0c\u57282-3\u6bd4\u7279\u5206\u8fa8\u7387\u4e0b\u6539\u8fdb32-33%\uff0c\u540c\u65f6\u964d\u4f4e\u6570\u636e\u7387", "motivation": "\u6296\u52a8\u6280\u672f\u901a\u5e38\u7528\u4e8e\u6539\u5584\u6709\u635f\u6570\u636e\u538b\u7f29\u7684\u611f\u77e5\u8d28\u91cf\uff0c\u4f46\u9700\u8981\u5206\u6790\u5176\u5728ASR\u8f93\u5165\u538b\u7f29\u4e2d\u7684\u5e94\u7528\u4ef7\u503c\uff0c\u4ee5\u4f18\u5316ASR\u6027\u80fd\u5e76\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6", "method": "\u5f62\u5f0f\u5316\u7406\u89e3\u6709\u635f\u8f93\u5165\u538b\u7f29\u4e0b\u7684\u6700\u4f18ASR\u6027\u80fd\uff0c\u63d0\u51fa\u53c2\u6570\u5316\u6296\u52a8\u6280\u672f\u7528\u4e8e\u4f4e\u590d\u6742\u5ea6\u8bed\u97f3\u538b\u7f29\u6d41\u6c34\u7ebf\uff0c\u53ef\u9002\u5e94\u6027\u80fd\u76ee\u6807\u6216\u71b5\u7ea6\u675f", "result": "\u57281\u6bd4\u7279\u5206\u8fa8\u7387\u4e0b\u5b9e\u73b025%\u76f8\u5bf9CER\u6539\u8fdb\uff0c2\u6bd4\u7279\u548c3\u6bd4\u7279\u5206\u8fa8\u7387\u4e0b\u5206\u522b\u6539\u8fdb32.4%\u548c33.5%\uff0c\u7b2c\u4e8c\u79cd\u6296\u52a8\u9009\u62e9\u53ef\u964d\u4f4e\u6570\u636e\u7387", "conclusion": "\u6296\u52a8\u6280\u672f\u80fd\u6709\u6548\u63d0\u5347ASR\u8f93\u5165\u538b\u7f29\u6027\u80fd\uff0c\u63d0\u51fa\u7684\u7f16\u89e3\u7801\u5668\u5177\u6709\u9002\u5e94\u6027\uff0c\u53ef\u5728\u6027\u80fd\u76ee\u6807\u548c\u71b5\u7ea6\u675f\u4e4b\u95f4\u5e73\u8861"}}
{"id": "2512.00937", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2512.00937", "abs": "https://arxiv.org/abs/2512.00937", "authors": ["Lars Nippert"], "title": "Arabic TTS with FastPitch: Reproducible Baselines, Adversarial Training, and Oversmoothing Analysis", "comment": null, "summary": "Arabic text-to-speech (TTS) remains challenging due to limited resources and complex phonological patterns. We present reproducible baselines for Arabic TTS built on the FastPitch architecture and introduce cepstral-domain metrics for analyzing oversmoothing in mel-spectrogram prediction. While traditional Lp reconstruction losses yield smooth but over-averaged outputs, the proposed metrics reveal their temporal and spectral effects throughout training. To address this, we incorporate a lightweight adversarial spectrogram loss, which trains stably and substantially reduces oversmoothing. We further explore multi-speaker Arabic TTS by augmenting FastPitch with synthetic voices generated using XTTSv2, resulting in improved prosodic diversity without loss of stability. The code, pretrained models, and training recipes are publicly available at: https://github.com/nipponjo/tts-arabic-pytorch.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eFastPitch\u7684\u963f\u62c9\u4f2f\u8bedTTS\u53ef\u590d\u73b0\u57fa\u7ebf\uff0c\u5f15\u5165\u5012\u8c31\u57df\u6307\u6807\u5206\u6790\u6885\u5c14\u9891\u8c31\u56fe\u9884\u6d4b\u4e2d\u7684\u8fc7\u5e73\u6ed1\u95ee\u9898\uff0c\u5e76\u91c7\u7528\u8f7b\u91cf\u5bf9\u6297\u9891\u8c31\u635f\u5931\u548c\u591a\u8bf4\u8bdd\u4eba\u5408\u6210\u6765\u6539\u5584\u8f93\u51fa\u8d28\u91cf\u3002", "motivation": "\u963f\u62c9\u4f2f\u8bedTTS\u9762\u4e34\u8d44\u6e90\u6709\u9650\u548c\u590d\u6742\u8bed\u97f3\u6a21\u5f0f\u7684\u6311\u6218\uff0c\u9700\u8981\u5efa\u7acb\u53ef\u590d\u73b0\u7684\u57fa\u7ebf\u7cfb\u7edf\u5e76\u89e3\u51b3\u6885\u5c14\u9891\u8c31\u56fe\u9884\u6d4b\u4e2d\u7684\u8fc7\u5e73\u6ed1\u95ee\u9898\u3002", "method": "1) \u57fa\u4e8eFastPitch\u67b6\u6784\u6784\u5efa\u963f\u62c9\u4f2f\u8bedTTS\u57fa\u7ebf\uff1b2) \u5f15\u5165\u5012\u8c31\u57df\u6307\u6807\u5206\u6790\u8fc7\u5e73\u6ed1\u73b0\u8c61\uff1b3) \u91c7\u7528\u8f7b\u91cf\u5bf9\u6297\u9891\u8c31\u635f\u5931\u51cf\u5c11\u8fc7\u5e73\u6ed1\uff1b4) \u4f7f\u7528XTTSv2\u751f\u6210\u5408\u6210\u8bed\u97f3\u589e\u5f3a\u591a\u8bf4\u8bdd\u4eba\u7cfb\u7edf\u3002", "result": "\u63d0\u51fa\u7684\u5012\u8c31\u57df\u6307\u6807\u80fd\u6709\u6548\u63ed\u793a\u4f20\u7edfLp\u91cd\u5efa\u635f\u5931\u7684\u65f6\u57df\u548c\u9891\u57df\u5f71\u54cd\uff1b\u5bf9\u6297\u635f\u5931\u8bad\u7ec3\u7a33\u5b9a\u4e14\u663e\u8457\u51cf\u5c11\u8fc7\u5e73\u6ed1\uff1b\u591a\u8bf4\u8bdd\u4eba\u7cfb\u7edf\u5728\u4fdd\u6301\u7a33\u5b9a\u6027\u7684\u540c\u65f6\u63d0\u5347\u4e86\u97f5\u5f8b\u591a\u6837\u6027\u3002", "conclusion": "\u6210\u529f\u5efa\u7acb\u4e86\u963f\u62c9\u4f2f\u8bedTTS\u7684\u53ef\u590d\u73b0\u57fa\u7ebf\uff0c\u63d0\u51fa\u7684\u5012\u8c31\u57df\u6307\u6807\u548c\u5bf9\u6297\u635f\u5931\u6709\u6548\u89e3\u51b3\u4e86\u8fc7\u5e73\u6ed1\u95ee\u9898\uff0c\u591a\u8bf4\u8bdd\u4eba\u6269\u5c55\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\uff0c\u6240\u6709\u4ee3\u7801\u548c\u6a21\u578b\u5df2\u5f00\u6e90\u3002"}}
{"id": "2512.01466", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2512.01466", "abs": "https://arxiv.org/abs/2512.01466", "authors": ["Arnout Roebben", "Toon van Waterschoot", "Jan Wouters", "Marc Moonen"], "title": "Identifiability Conditions for Acoustic Feedback Cancellation with the Two-Channel Adaptive Feedback Canceller Algorithm", "comment": "Accepted for publication in IEEE Open Journal of Signal Processing (OJSP)", "summary": "In audio signal processing applications with a microphone and a loudspeaker within the same acoustic environment, the loudspeaker signals can feed back into the microphone, thereby creating a closed-loop system that potentially leads to system instability. To remove this acoustic coupling, prediction error method (PEM) feedback cancellation algorithms aim to identify the feedback path between the loudspeaker and the microphone by assuming that the input signal can be modelled by means of an autoregressive (AR) model. It has previously been shown that this PEM framework and resulting algorithms can identify the feedback path correctly in cases where the forward path from microphone to loudspeaker is sufficiently time-varying or non-linear, or when the forward path delay equals or exceeds the order of the AR model. In this paper, it is shown that this delay-based condition can be generalised for one particular PEM-based algorithm, the so-called two-channel adaptive feedback canceller (2ch-AFC), to an invertibility-based condition, for which it is shown that identifiability can be achieved when the order of the forward path feedforward filter exceeds the order of the AR model. Additionally, the condition number of inversion of the correlation matrix as used in the 2ch-AFC algorithm can serve as a measure for monitoring the identifiability.", "AI": {"tldr": "\u672c\u6587\u6269\u5c55\u4e86\u57fa\u4e8e\u9884\u6d4b\u8bef\u5dee\u65b9\u6cd5\uff08PEM\uff09\u7684\u53cd\u9988\u6d88\u9664\u7b97\u6cd5\u53ef\u8bc6\u522b\u6027\u6761\u4ef6\uff0c\u4ece\u539f\u6709\u7684\u5ef6\u8fdf\u6761\u4ef6\u63a8\u5e7f\u5230\u53ef\u9006\u6027\u6761\u4ef6\uff0c\u5e76\u63d0\u51fa\u4e86\u4f7f\u7528\u76f8\u5173\u77e9\u9635\u6761\u4ef6\u6570\u4f5c\u4e3a\u53ef\u8bc6\u522b\u6027\u76d1\u6d4b\u6307\u6807\u3002", "motivation": "\u5728\u9ea6\u514b\u98ce\u548c\u626c\u58f0\u5668\u5171\u5904\u540c\u4e00\u58f0\u5b66\u73af\u5883\u7684\u97f3\u9891\u4fe1\u53f7\u5904\u7406\u5e94\u7528\u4e2d\uff0c\u626c\u58f0\u5668\u4fe1\u53f7\u4f1a\u53cd\u9988\u5230\u9ea6\u514b\u98ce\u5f62\u6210\u95ed\u73af\u7cfb\u7edf\uff0c\u53ef\u80fd\u5bfc\u81f4\u7cfb\u7edf\u4e0d\u7a33\u5b9a\u3002\u73b0\u6709\u7684PEM\u53cd\u9988\u6d88\u9664\u7b97\u6cd5\u5728\u67d0\u4e9b\u6761\u4ef6\u4e0b\u80fd\u6b63\u786e\u8bc6\u522b\u53cd\u9988\u8def\u5f84\uff0c\u4f46\u6761\u4ef6\u9650\u5236\u8f83\u591a\uff0c\u9700\u8981\u6269\u5c55\u53ef\u8bc6\u522b\u6027\u6761\u4ef6\u3002", "method": "\u9488\u5bf9\u7279\u5b9a\u7684PEM\u7b97\u6cd5\u2014\u2014\u53cc\u901a\u9053\u81ea\u9002\u5e94\u53cd\u9988\u6d88\u9664\u5668\uff082ch-AFC\uff09\uff0c\u5c06\u539f\u6709\u7684\u5ef6\u8fdf\u6761\u4ef6\u63a8\u5e7f\u5230\u66f4\u4e00\u822c\u7684\u53ef\u9006\u6027\u6761\u4ef6\u3002\u5206\u6790\u8868\u660e\uff0c\u5f53\u524d\u5411\u8def\u5f84\u524d\u9988\u6ee4\u6ce2\u5668\u7684\u9636\u6570\u8d85\u8fc7AR\u6a21\u578b\u9636\u6570\u65f6\uff0c\u53ef\u5b9e\u73b0\u53ef\u8bc6\u522b\u6027\u3002\u540c\u65f6\u63d0\u51fa\u4f7f\u75282ch-AFC\u7b97\u6cd5\u4e2d\u76f8\u5173\u77e9\u9635\u7684\u6761\u4ef6\u6570\u4f5c\u4e3a\u53ef\u8bc6\u522b\u6027\u76d1\u6d4b\u6307\u6807\u3002", "result": "\u6210\u529f\u5c06\u53cd\u9988\u8def\u5f84\u53ef\u8bc6\u522b\u6027\u6761\u4ef6\u4ece\u5ef6\u8fdf\u6761\u4ef6\u63a8\u5e7f\u5230\u53ef\u9006\u6027\u6761\u4ef6\uff0c\u4e3a2ch-AFC\u7b97\u6cd5\u63d0\u4f9b\u4e86\u66f4\u4e00\u822c\u7684\u53ef\u8bc6\u522b\u6027\u7406\u8bba\u6846\u67b6\u3002\u76f8\u5173\u77e9\u9635\u6761\u4ef6\u6570\u53ef\u4f5c\u4e3a\u6709\u6548\u7684\u53ef\u8bc6\u522b\u6027\u76d1\u6d4b\u5de5\u5177\u3002", "conclusion": "\u672c\u6587\u6269\u5c55\u4e86PEM\u53cd\u9988\u6d88\u9664\u7b97\u6cd5\u7684\u7406\u8bba\u6846\u67b6\uff0c\u4e3a\u53cc\u901a\u9053\u81ea\u9002\u5e94\u53cd\u9988\u6d88\u9664\u5668\u63d0\u4f9b\u4e86\u66f4\u901a\u7528\u7684\u53ef\u8bc6\u522b\u6027\u6761\u4ef6\uff0c\u5e76\u63d0\u51fa\u4e86\u5b9e\u7528\u7684\u53ef\u8bc6\u522b\u6027\u76d1\u6d4b\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u63d0\u9ad8\u97f3\u9891\u7cfb\u7edf\u4e2d\u53cd\u9988\u6d88\u9664\u7684\u7a33\u5b9a\u6027\u548c\u6027\u80fd\u3002"}}
{"id": "2512.00115", "categories": ["cs.SD", "cs.CV", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.00115", "abs": "https://arxiv.org/abs/2512.00115", "authors": ["Kyeongha Rho", "Hyeongkeun Lee", "Jae Won Cho", "Joon Son Chung"], "title": "MoLT: Mixture of Layer-Wise Tokens for Efficient Audio-Visual Learning", "comment": "10 pages, 5 figures", "summary": "In this paper, we propose Mixture of Layer-Wise Tokens (MoLT), a parameter- and memory-efficient adaptation framework for audio-visual learning. The key idea of MoLT is to replace conventional, computationally heavy sequential adaptation at every transformer layer with a parallel, lightweight scheme that extracts and fuses layer-wise tokens only from the late layers. We adopt two types of adapters to distill modality-specific information and cross-modal interaction into compact latent tokens in a layer-wise manner. A token fusion module then dynamically fuses these layer-wise tokens by taking into account their relative significance. To prevent the redundancy of latent tokens, we apply an orthogonality regularization between latent tokens during training. Through the systematic analysis of the position of adaptation in the pre-trained transformers, we extract latent tokens only from the late layers of the transformers. This strategic adaptation approach avoids error propagation from the volatile early-layer features, thereby maximizing the adaptation performance while maintaining parameter and memory efficiency. Through extensive experiments, we demonstrate that MoLT outperforms existing methods on diverse audio-visual benchmarks, including Audio-Visual Question Answering, Audio-Visual Segmentation, and Audio-Visual Event Localization.", "AI": {"tldr": "MoLT\u662f\u4e00\u79cd\u53c2\u6570\u548c\u5185\u5b58\u9ad8\u6548\u7684\u97f3\u89c6\u9891\u5b66\u4e60\u9002\u914d\u6846\u67b6\uff0c\u901a\u8fc7\u4ece\u9884\u8bad\u7ec3\u6a21\u578b\u7684\u540e\u671f\u5c42\u63d0\u53d6\u5c42\u95f4\u4ee4\u724c\u8fdb\u884c\u5e76\u884c\u8f7b\u91cf\u9002\u914d\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u4f20\u7edf\u97f3\u89c6\u9891\u5b66\u4e60\u65b9\u6cd5\u5728\u6bcf\u4e2aTransformer\u5c42\u8fdb\u884c\u987a\u5e8f\u9002\u914d\u8ba1\u7b97\u91cf\u5927\u4e14\u5185\u5b58\u6548\u7387\u4f4e\uff0c\u9700\u8981\u66f4\u8f7b\u91cf\u9ad8\u6548\u7684\u9002\u914d\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u4e24\u79cd\u9002\u914d\u5668\u4ece\u540e\u671f\u5c42\u63d0\u53d6\u6a21\u6001\u7279\u5b9a\u4fe1\u606f\u548c\u8de8\u6a21\u6001\u4ea4\u4e92\u7684\u7d27\u51d1\u6f5c\u5728\u4ee4\u724c\uff0c\u901a\u8fc7\u4ee4\u724c\u878d\u5408\u6a21\u5757\u52a8\u6001\u878d\u5408\uff0c\u5e76\u5e94\u7528\u6b63\u4ea4\u6b63\u5219\u5316\u9632\u6b62\u5197\u4f59\u3002", "result": "\u5728\u97f3\u9891-\u89c6\u89c9\u95ee\u7b54\u3001\u97f3\u9891-\u89c6\u89c9\u5206\u5272\u548c\u97f3\u9891-\u89c6\u89c9\u4e8b\u4ef6\u5b9a\u4f4d\u7b49\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "MoLT\u901a\u8fc7\u540e\u671f\u5c42\u5e76\u884c\u9002\u914d\u907f\u514d\u4e86\u65e9\u671f\u5c42\u7279\u5f81\u7684\u4e0d\u7a33\u5b9a\u6027\uff0c\u5728\u4fdd\u6301\u53c2\u6570\u548c\u5185\u5b58\u6548\u7387\u7684\u540c\u65f6\u6700\u5927\u5316\u9002\u914d\u6027\u80fd\u3002"}}
{"id": "2512.00171", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.00171", "abs": "https://arxiv.org/abs/2512.00171", "authors": ["Cagatay Candan"], "title": "Polynomial Order Selection for Savitzky-Golay Smoothers via N-fold Cross-Validation (extended version)", "comment": "MATLAB source code is available at codeocean, see https://doi.org/10.24433/CO.1732394.v2", "summary": "Savitzky-Golay (SG) smoothers are noise suppressing filters operating on the principle of projecting noisy input onto the subspace of polynomials. A poorly selected polynomial order results in over- or under-smoothing which shows as either bias or excessive noise at the output. In this study, we apply the N-fold cross-validation technique (also known as leave-one-out cross-validation) for model order selection and show that the inherent analytical structure of the SG filtering problem, mainly its minimum norm formulation, enables an efficient and effective order selection solution. More specifically, a novel connection between the total prediction error and SG-projection spaces is developed to reduce the implementation complexity of cross-validation method. The suggested solution compares favorably with the state-of-the-art Bayesian Information Criterion (BIC) rule in non-asymptotic signal-to-noise ratio (SNR) and sample size regimes. MATLAB codes reproducing the numerical results are provided.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7559\u4e00\u4ea4\u53c9\u9a8c\u8bc1\u7684Savitzky-Golay\u5e73\u6ed1\u5668\u591a\u9879\u5f0f\u9636\u6570\u9009\u62e9\u65b9\u6cd5\uff0c\u901a\u8fc7\u5229\u7528SG\u6ee4\u6ce2\u7684\u6700\u5c0f\u8303\u6570\u7279\u6027\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u5728\u975e\u6e10\u8fd1SNR\u548c\u6837\u672c\u91cf\u6761\u4ef6\u4e0b\u4f18\u4e8eBIC\u51c6\u5219\u3002", "motivation": "Savitzky-Golay\u5e73\u6ed1\u5668\u7684\u591a\u9879\u5f0f\u9636\u6570\u9009\u62e9\u4e0d\u5f53\u4f1a\u5bfc\u81f4\u8fc7\u5e73\u6ed1\uff08\u504f\u5dee\uff09\u6216\u6b20\u5e73\u6ed1\uff08\u566a\u58f0\u6b8b\u7559\uff09\uff0c\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u9636\u6570\u9009\u62e9\u65b9\u6cd5\u3002", "method": "\u91c7\u7528N\u6298\u4ea4\u53c9\u9a8c\u8bc1\uff08\u7559\u4e00\u6cd5\uff09\u8fdb\u884c\u6a21\u578b\u9636\u6570\u9009\u62e9\uff0c\u5229\u7528SG\u6ee4\u6ce2\u95ee\u9898\u7684\u6700\u5c0f\u8303\u6570\u7279\u6027\uff0c\u5efa\u7acb\u4e86\u603b\u9884\u6d4b\u8bef\u5dee\u4e0eSG\u6295\u5f71\u7a7a\u95f4\u4e4b\u95f4\u7684\u65b0\u8054\u7cfb\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u4ea4\u53c9\u9a8c\u8bc1\u7684\u5b9e\u73b0\u590d\u6742\u5ea6\u3002", "result": "\u5728\u975e\u6e10\u8fd1\u4fe1\u566a\u6bd4\u548c\u6837\u672c\u91cf\u6761\u4ef6\u4e0b\uff0c\u6240\u63d0\u65b9\u6cd5\u4f18\u4e8e\u5f53\u524d\u6700\u5148\u8fdb\u7684\u8d1d\u53f6\u65af\u4fe1\u606f\u51c6\u5219\uff08BIC\uff09\uff0c\u5e76\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u6570\u503c\u7ed3\u679c\u7684MATLAB\u4ee3\u7801\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528SG\u6ee4\u6ce2\u7684\u5185\u5728\u5206\u6790\u7ed3\u6784\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u9ad8\u6548\u6709\u6548\u7684\u591a\u9879\u5f0f\u9636\u6570\u9009\u62e9\u65b9\u6cd5\uff0c\u4e3aSG\u5e73\u6ed1\u5668\u7684\u53c2\u6570\u9009\u62e9\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00120", "categories": ["cs.SD", "cs.AI", "cs.CV", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.00120", "abs": "https://arxiv.org/abs/2512.00120", "authors": ["Jiaying Hong", "Ting Zhu", "Thanet Markchom", "Huizhi Liang"], "title": "Art2Music: Generating Music for Art Images with Multi-modal Feeling Alignment", "comment": null, "summary": "With the rise of AI-generated content (AIGC), generating perceptually natural and feeling-aligned music from multimodal inputs has become a central challenge. Existing approaches often rely on explicit emotion labels that require costly annotation, underscoring the need for more flexible feeling-aligned methods. To support multimodal music generation, we construct ArtiCaps, a pseudo feeling-aligned image-music-text dataset created by semantically matching descriptions from ArtEmis and MusicCaps. We further propose Art2Music, a lightweight cross-modal framework that synthesizes music from artistic images and user comments. In the first stage, images and text are encoded with OpenCLIP and fused using a gated residual module; the fused representation is decoded by a bidirectional LSTM into Mel-spectrograms with a frequency-weighted L1 loss to enhance high-frequency fidelity. In the second stage, a fine-tuned HiFi-GAN vocoder reconstructs high-quality audio waveforms. Experiments on ArtiCaps show clear improvements in Mel-Cepstral Distortion, Frechet Audio Distance, Log-Spectral Distance, and cosine similarity. A small LLM-based rating study further verifies consistent cross-modal feeling alignment and offers interpretable explanations of matches and mismatches across modalities. These results demonstrate improved perceptual naturalness, spectral fidelity, and semantic consistency. Art2Music also maintains robust performance with only 50k training samples, providing a scalable solution for feeling-aligned creative audio generation in interactive art, personalized soundscapes, and digital art exhibitions.", "AI": {"tldr": "Art2Music\uff1a\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u8de8\u6a21\u6001\u6846\u67b6\uff0c\u901a\u8fc7\u827a\u672f\u56fe\u50cf\u548c\u7528\u6237\u8bc4\u8bba\u751f\u6210\u611f\u77e5\u81ea\u7136\u3001\u60c5\u611f\u5bf9\u9f50\u7684\u97f3\u4e50\uff0c\u4f7f\u7528\u4f2a\u60c5\u611f\u5bf9\u9f50\u6570\u636e\u96c6ArtiCaps\uff0c\u5728\u9891\u8c31\u4fdd\u771f\u5ea6\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "motivation": "\u968f\u7740AI\u751f\u6210\u5185\u5bb9\u5174\u8d77\uff0c\u4ece\u591a\u6a21\u6001\u8f93\u5165\u751f\u6210\u611f\u77e5\u81ea\u7136\u4e14\u60c5\u611f\u5bf9\u9f50\u7684\u97f3\u4e50\u6210\u4e3a\u6838\u5fc3\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u9700\u8981\u6602\u8d35\u6807\u6ce8\u7684\u663e\u5f0f\u60c5\u611f\u6807\u7b7e\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u7684\u60c5\u611f\u5bf9\u9f50\u65b9\u6cd5\u3002", "method": "\u6784\u5efaArtiCaps\u4f2a\u60c5\u611f\u5bf9\u9f50\u56fe\u50cf-\u97f3\u4e50-\u6587\u672c\u6570\u636e\u96c6\uff1b\u63d0\u51faArt2Music\u4e24\u9636\u6bb5\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528OpenCLIP\u7f16\u7801\u56fe\u50cf\u548c\u6587\u672c\uff0c\u901a\u8fc7\u95e8\u63a7\u6b8b\u5dee\u6a21\u5757\u878d\u5408\uff0c\u53cc\u5411LSTM\u89e3\u7801\u4e3a\u6885\u5c14\u9891\u8c31\u56fe\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u5fae\u8c03\u7684HiFi-GAN\u58f0\u7801\u5668\u91cd\u5efa\u9ad8\u8d28\u91cf\u97f3\u9891\u6ce2\u5f62\u3002", "result": "\u5728ArtiCaps\u6570\u636e\u96c6\u4e0a\uff0cMel-Cepstral Distortion\u3001Frechet Audio Distance\u3001Log-Spectral Distance\u548c\u4f59\u5f26\u76f8\u4f3c\u5ea6\u5747\u6709\u660e\u663e\u6539\u5584\uff1b\u57fa\u4e8eLLM\u7684\u5c0f\u578b\u8bc4\u5206\u7814\u7a76\u9a8c\u8bc1\u4e86\u8de8\u6a21\u6001\u60c5\u611f\u5bf9\u9f50\u4e00\u81f4\u6027\uff0c\u5e76\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u5339\u914d\u4e0e\u4e0d\u5339\u914d\u5206\u6790\u3002", "conclusion": "Art2Music\u5728\u611f\u77e5\u81ea\u7136\u6027\u3001\u9891\u8c31\u4fdd\u771f\u5ea6\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u4ec5\u97005\u4e07\u8bad\u7ec3\u6837\u672c\u5373\u53ef\u4fdd\u6301\u7a33\u5065\u6027\u80fd\uff0c\u4e3a\u4ea4\u4e92\u827a\u672f\u3001\u4e2a\u6027\u5316\u97f3\u666f\u548c\u6570\u5b57\u827a\u672f\u5c55\u89c8\u4e2d\u7684\u60c5\u611f\u5bf9\u9f50\u521b\u610f\u97f3\u9891\u751f\u6210\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00205", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00205", "abs": "https://arxiv.org/abs/2512.00205", "authors": ["Dimitris Kompostiotis", "Dimitris Vordonis", "Konstantinos D. Katsanos", "Florin-Catalin Grec", "Vassilis Paliouras", "George C. Alexandropoulos"], "title": "RIS-Aided Localization and Sensing", "comment": "Book chapter to appear", "summary": "High-precision localization and environmental sensing are essential for a new wave of applications, ranging from industrial automation and autonomous systems to augmented reality and remote healthcare. Conventional wireless methods, however, often face limitations in accuracy, reliability, and coverage, especially in complex non-line-of-sight (NLoS) environments. Reconfigurable Intelligent Surfaces (RISs) have emerged as a key enabling technology, offering dynamic control over the radio propagation environment to overcome these challenges. This chapter provides a comprehensive overview of RIS-aided localization and sensing, bridging fundamental theory with practical implementation. The core principles of the RIS technology are first described detailing how programmable metasurfaces can intelligently combat blockages, enhance signal diversity, and create virtual line-of-sight (LoS) links. The chapter then reviews a range of application scenarios where RISs can offer significant improvements. A significant portion of the chapter is dedicated to algorithmic methodologies, covering beam sweeping protocols, codebook-based techniques, and advanced optimization and machine learning strategies for both localization and sensing. To validate the theoretical concepts in real-world conditions, recent experimental results using an RIS prototype are detailed, showcasing the technology's efficacy and illustrating key performance trade-offs.", "AI": {"tldr": "\u672c\u7ae0\u5168\u9762\u7efc\u8ff0\u4e86RIS\u8f85\u52a9\u7684\u5b9a\u4f4d\u4e0e\u611f\u77e5\u6280\u672f\uff0c\u6db5\u76d6\u57fa\u672c\u539f\u7406\u3001\u5e94\u7528\u573a\u666f\u3001\u7b97\u6cd5\u65b9\u6cd5\u53ca\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u5c55\u793a\u4e86RIS\u5728\u590d\u6742NLoS\u73af\u5883\u4e2d\u63d0\u5347\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u611f\u77e5\u80fd\u529b\u7684\u6f5c\u529b\u3002", "motivation": "\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u548c\u73af\u5883\u611f\u77e5\u5bf9\u5de5\u4e1a\u81ea\u52a8\u5316\u3001\u81ea\u4e3b\u7cfb\u7edf\u3001\u589e\u5f3a\u73b0\u5b9e\u548c\u8fdc\u7a0b\u533b\u7597\u7b49\u65b0\u5174\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u65e0\u7ebf\u65b9\u6cd5\u5728\u590d\u6742\u975e\u89c6\u8ddd\u73af\u5883\u4e2d\u9762\u4e34\u7cbe\u5ea6\u3001\u53ef\u9760\u6027\u548c\u8986\u76d6\u8303\u56f4\u7684\u9650\u5236\uff0c\u9700\u8981\u65b0\u6280\u672f\u6765\u514b\u670d\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u9996\u5148\u4ecb\u7ecdRIS\u6280\u672f\u6838\u5fc3\u539f\u7406\uff0c\u5305\u62ec\u53ef\u7f16\u7a0b\u8d85\u8868\u9762\u5982\u4f55\u667a\u80fd\u5bf9\u6297\u963b\u585e\u3001\u589e\u5f3a\u4fe1\u53f7\u591a\u6837\u6027\u548c\u521b\u5efa\u865a\u62df\u89c6\u8ddd\u94fe\u8def\u3002\u7136\u540e\u7efc\u8ff0RIS\u7684\u5e94\u7528\u573a\u666f\uff0c\u91cd\u70b9\u8ba8\u8bba\u7b97\u6cd5\u65b9\u6cd5\u5b66\uff0c\u6db5\u76d6\u6ce2\u675f\u626b\u63cf\u534f\u8bae\u3001\u57fa\u4e8e\u7801\u672c\u7684\u6280\u672f\uff0c\u4ee5\u53ca\u7528\u4e8e\u5b9a\u4f4d\u548c\u611f\u77e5\u7684\u5148\u8fdb\u4f18\u5316\u548c\u673a\u5668\u5b66\u4e60\u7b56\u7565\u3002\u6700\u540e\u901a\u8fc7RIS\u539f\u578b\u5b9e\u9a8c\u9a8c\u8bc1\u7406\u8bba\u6982\u5ff5\u3002", "result": "\u901a\u8fc7RIS\u539f\u578b\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u8be5\u6280\u672f\u7684\u6709\u6548\u6027\uff0c\u5c55\u793a\u4e86\u5173\u952e\u6027\u80fd\u6743\u8861\uff0c\u8bc1\u660e\u4e86RIS\u5728\u590d\u6742NLoS\u73af\u5883\u4e2d\u80fd\u591f\u663e\u8457\u63d0\u5347\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u611f\u77e5\u80fd\u529b\u3002", "conclusion": "RIS\u4f5c\u4e3a\u5173\u952e\u4f7f\u80fd\u6280\u672f\uff0c\u901a\u8fc7\u52a8\u6001\u63a7\u5236\u65e0\u7ebf\u7535\u4f20\u64ad\u73af\u5883\uff0c\u80fd\u591f\u514b\u670d\u4f20\u7edf\u65e0\u7ebf\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u548c\u73af\u5883\u611f\u77e5\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u591a\u79cd\u5e94\u7528\u573a\u666f\u4e2d\u5177\u6709\u663e\u8457\u6539\u8fdb\u6f5c\u529b\u3002"}}
{"id": "2512.00451", "categories": ["cs.SD", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.00451", "abs": "https://arxiv.org/abs/2512.00451", "authors": ["Siyu Wang", "Haitao Li"], "title": "STCTS: Generative Semantic Compression for Ultra-Low Bitrate Speech via Explicit Text-Prosody-Timbre Decomposition", "comment": "The complete source code and online speech reconstruction demo is publicly available at https://github.com/dywsy21/STCTS", "summary": "Voice communication in bandwidth-constrained environments--maritime, satellite, and tactical networks--remains prohibitively expensive. Traditional codecs struggle below 1 kbps, while existing semantic approaches (STT-TTS) sacrifice prosody and speaker identity. We present STCTS, a generative semantic compression framework enabling natural voice communication at approximately 80 bps. STCTS explicitly decomposes speech into linguistic content, prosodic expression, and speaker timbre, applying tailored compression: context-aware text encoding (approximately 70 bps), sparse prosody transmission via TTS interpolation (less than 14 bps at 0.1-1 Hz), and amortized speaker embedding.\n  Evaluations on LibriSpeech demonstrate a 75x bitrate reduction versus Opus (6 kbps) and 12x versus EnCodec (1 kbps), while maintaining perceptual quality (NISQA MOS greater than 4.26). We also discover a bimodal quality distribution with prosody sampling rate: sparse and dense updates both achieve high quality, while mid-range rates degrade due to perceptual discontinuities--guiding optimal configuration design. Beyond efficiency, our modular architecture supports privacy-preserving encryption, human-interpretable transmission, and flexible deployment on edge devices, offering a robust solution for ultra-low bandwidth scenarios.", "AI": {"tldr": "STCTS\u662f\u4e00\u4e2a\u751f\u6210\u5f0f\u8bed\u4e49\u538b\u7f29\u6846\u67b6\uff0c\u80fd\u5728\u7ea680bps\u7684\u8d85\u4f4e\u6bd4\u7279\u7387\u4e0b\u5b9e\u73b0\u81ea\u7136\u8bed\u97f3\u901a\u4fe1\uff0c\u76f8\u6bd4\u4f20\u7edf\u7f16\u89e3\u7801\u5668\u5b9e\u73b075-12\u500d\u7684\u538b\u7f29\u6bd4\u63d0\u5347\u3002", "motivation": "\u5728\u5e26\u5bbd\u53d7\u9650\u73af\u5883\uff08\u6d77\u4e8b\u3001\u536b\u661f\u3001\u6218\u672f\u7f51\u7edc\uff09\u4e2d\uff0c\u8bed\u97f3\u901a\u4fe1\u6210\u672c\u8fc7\u9ad8\u3002\u4f20\u7edf\u7f16\u89e3\u7801\u5668\u57281kbps\u4ee5\u4e0b\u6027\u80fd\u4e0d\u4f73\uff0c\u800c\u73b0\u6709\u8bed\u4e49\u65b9\u6cd5\uff08STT-TTS\uff09\u4f1a\u727a\u7272\u97f5\u5f8b\u548c\u8bf4\u8bdd\u4eba\u8eab\u4efd\u7279\u5f81\u3002", "method": "STCTS\u5c06\u8bed\u97f3\u663e\u5f0f\u5206\u89e3\u4e3a\u8bed\u8a00\u5185\u5bb9\u3001\u97f5\u5f8b\u8868\u8fbe\u548c\u8bf4\u8bdd\u4eba\u97f3\u8272\u4e09\u4e2a\u90e8\u5206\uff0c\u5206\u522b\u91c7\u7528\u5b9a\u5236\u5316\u538b\u7f29\uff1a\u4e0a\u4e0b\u6587\u611f\u77e5\u6587\u672c\u7f16\u7801\uff08\u7ea670bps\uff09\u3001\u901a\u8fc7TTS\u63d2\u503c\u7684\u7a00\u758f\u97f5\u5f8b\u4f20\u8f93\uff08\u5c0f\u4e8e14bps\uff0c0.1-1Hz\uff09\u548c\u644a\u9500\u7684\u8bf4\u8bdd\u4eba\u5d4c\u5165\u3002", "result": "\u5728LibriSpeech\u4e0a\u7684\u8bc4\u4f30\u663e\u793a\uff0c\u76f8\u6bd4Opus\uff086kbps\uff09\u5b9e\u73b075\u500d\u6bd4\u7279\u7387\u964d\u4f4e\uff0c\u76f8\u6bd4EnCodec\uff081kbps\uff09\u5b9e\u73b012\u500d\u964d\u4f4e\uff0c\u540c\u65f6\u4fdd\u6301\u611f\u77e5\u8d28\u91cf\uff08NISQA MOS\u5927\u4e8e4.26\uff09\u3002\u53d1\u73b0\u97f5\u5f8b\u91c7\u6837\u7387\u7684\u53cc\u5cf0\u8d28\u91cf\u5206\u5e03\u73b0\u8c61\u3002", "conclusion": "STCTS\u4e3a\u8d85\u4f4e\u5e26\u5bbd\u573a\u666f\u63d0\u4f9b\u4e86\u9c81\u68d2\u89e3\u51b3\u65b9\u6848\uff0c\u5176\u6a21\u5757\u5316\u67b6\u6784\u652f\u6301\u9690\u79c1\u4fdd\u62a4\u52a0\u5bc6\u3001\u4eba\u7c7b\u53ef\u89e3\u91ca\u4f20\u8f93\u548c\u8fb9\u7f18\u8bbe\u5907\u7075\u6d3b\u90e8\u7f72\uff0c\u8d85\u8d8a\u4e86\u5355\u7eaf\u7684\u6548\u7387\u63d0\u5347\u3002"}}
{"id": "2512.00302", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00302", "abs": "https://arxiv.org/abs/2512.00302", "authors": ["Jinyuan Liu", "Yong Liang Guan", "Tuo Wu", "Kai-Kit Wong", "Bruno Clerckx"], "title": "FAS-RSMA: Can Fluid Antennas Elevate RSMA Performance?", "comment": null, "summary": "As 6G networks demand massive connectivity and stronger interference control, rate-splitting multiple access (RSMA) is attractive because it superposes a common stream and user-private streams and remains effective under imperfect CSIT and heterogeneous traffic. In practical multiuser deployments, two considerations arise: the common stream decoding constraint imposed by the weakest user, and residual inter-user interference can remain non-negligible, particularly in single-input single-output (SISO) broadcast settings and under an imperfect CSIT scenario. Motivated by prior advances of RSMA research, we investigate a complementary mechanism-fluid antenna systems (FAS), with dynamic port reconfiguration supplies adaptive spatial selectivity without altering the RSMA signaling structure. Can FAS help alleviate these considerations and enhance RSMA performance? We develop a tractable correlation-aware analytical framework based on block-correlation models, including constant block correlation (CBC) and variable block correlation (VBC), to capture realistic spatial dependence among ports. Closed-form expressions are derived for outage probability (OP) and average capacity (AC), revealing how port reconfiguration strengthens the weakest effective channel and improves SINR through higher channel gains and lower relative noise impact. Monte Carlo simulations verify the analysis and show that VBC matches simulations more tightly than CBC across all port configurations. Finally, FAS-RSMA provides clear gains over conventional antenna systems and NOMA, achieving lower OP and higher AC by combining RSMA interference management with FAS spatial diversity.", "AI": {"tldr": "FAS-RSMA\u7ed3\u5408\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u4e0e\u901f\u7387\u5206\u5272\u591a\u5740\u63a5\u5165\uff0c\u901a\u8fc7\u7aef\u53e3\u91cd\u914d\u7f6e\u589e\u5f3a\u7a7a\u95f4\u9009\u62e9\u6027\uff0c\u6539\u5584\u6700\u5f31\u7528\u6237\u4fe1\u9053\u5e76\u63d0\u5347SINR\uff0c\u57286G\u7f51\u7edc\u4e2d\u5b9e\u73b0\u66f4\u597d\u7684\u4e2d\u65ad\u6982\u7387\u548c\u5e73\u5747\u5bb9\u91cf\u6027\u80fd\u3002", "motivation": "6G\u7f51\u7edc\u9700\u8981\u5927\u89c4\u6a21\u8fde\u63a5\u548c\u66f4\u5f3a\u7684\u5e72\u6270\u63a7\u5236\uff0cRSMA\u867d\u7136\u6709\u6548\u4f46\u9762\u4e34\u6700\u5f31\u7528\u6237\u89e3\u7801\u7ea6\u675f\u548c\u6b8b\u7559\u5e72\u6270\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728SISO\u5e7f\u64ad\u548c\u4e0d\u5b8c\u7f8eCSIT\u573a\u666f\u4e0b\u3002\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\uff08FAS\uff09\u7684\u52a8\u6001\u7aef\u53e3\u91cd\u914d\u7f6e\u53ef\u4ee5\u63d0\u4f9b\u81ea\u9002\u5e94\u7a7a\u95f4\u9009\u62e9\u6027\uff0c\u6709\u671b\u589e\u5f3aRSMA\u6027\u80fd\u3002", "method": "\u63d0\u51faFAS-RSMA\u6846\u67b6\uff0c\u7ed3\u5408\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u7684\u7aef\u53e3\u91cd\u914d\u7f6e\u80fd\u529b\u4e0eRSMA\u7684\u5e72\u6270\u7ba1\u7406\u3002\u5efa\u7acb\u57fa\u4e8e\u5757\u76f8\u5173\u6a21\u578b\uff08\u5305\u62ec\u6052\u5b9a\u5757\u76f8\u5173CBC\u548c\u53ef\u53d8\u5757\u76f8\u5173VBC\uff09\u7684\u53ef\u5904\u7406\u5206\u6790\u6846\u67b6\uff0c\u6355\u83b7\u7aef\u53e3\u95f4\u7684\u7a7a\u95f4\u4f9d\u8d56\u6027\u3002\u63a8\u5bfc\u4e2d\u65ad\u6982\u7387\u548c\u5e73\u5747\u5bb9\u91cf\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002", "result": "\u5206\u6790\u8868\u660e\u7aef\u53e3\u91cd\u914d\u7f6e\u80fd\u589e\u5f3a\u6700\u5f31\u6709\u6548\u4fe1\u9053\uff0c\u901a\u8fc7\u66f4\u9ad8\u4fe1\u9053\u589e\u76ca\u548c\u66f4\u4f4e\u76f8\u5bf9\u566a\u58f0\u5f71\u54cd\u6539\u5584SINR\u3002\u8499\u7279\u5361\u6d1b\u4eff\u771f\u9a8c\u8bc1\u4e86\u5206\u6790\uff0cVBC\u6a21\u578b\u6bd4CBC\u6a21\u578b\u5728\u6240\u6709\u7aef\u53e3\u914d\u7f6e\u4e0b\u66f4\u8d34\u5408\u4eff\u771f\u7ed3\u679c\u3002FAS-RSMA\u76f8\u6bd4\u4f20\u7edf\u5929\u7ebf\u7cfb\u7edf\u548cNOMA\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u5b9e\u73b0\u4e86\u66f4\u4f4e\u4e2d\u65ad\u6982\u7387\u548c\u66f4\u9ad8\u5e73\u5747\u5bb9\u91cf\u3002", "conclusion": "FAS-RSMA\u901a\u8fc7\u7ed3\u5408RSMA\u7684\u5e72\u6270\u7ba1\u7406\u548cFAS\u7684\u7a7a\u95f4\u5206\u96c6\uff0c\u6709\u6548\u89e3\u51b3\u4e86RSMA\u4e2d\u7684\u6700\u5f31\u7528\u6237\u89e3\u7801\u7ea6\u675f\u548c\u6b8b\u7559\u5e72\u6270\u95ee\u9898\uff0c\u4e3a6G\u7f51\u7edc\u4e2d\u7684\u5927\u89c4\u6a21\u8fde\u63a5\u548c\u5e72\u6270\u63a7\u5236\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00563", "categories": ["cs.SD", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.00563", "abs": "https://arxiv.org/abs/2512.00563", "authors": ["S M Asiful Islam Saky", "Md Rashidul Islam", "Md Saiful Arefin", "Shahaba Alam"], "title": "Explainable Multi-Modal Deep Learning for Automatic Detection of Lung Diseases from Respiratory Audio Signals", "comment": null, "summary": "Respiratory diseases remain major global health challenges, and traditional auscultation is often limited by subjectivity, environmental noise, and inter-clinician variability. This study presents an explainable multimodal deep learning framework for automatic lung-disease detection using respiratory audio signals. The proposed system integrates two complementary representations: a spectral-temporal encoder based on a CNN-BiLSTM Attention architecture, and a handcrafted acoustic-feature encoder capturing physiologically meaningful descriptors such as MFCCs, spectral centroid, spectral bandwidth, and zero-crossing rate. These branches are combined through late-stage fusion to leverage both data-driven learning and domain-informed acoustic cues. The model is trained and evaluated on the Asthma Detection Dataset Version 2 using rigorous preprocessing, including resampling, normalization, noise filtering, data augmentation, and patient-level stratified partitioning. The study achieved strong generalization with 91.21% accuracy, 0.899 macro F1-score, and 0.9866 macro ROC-AUC, outperforming all ablated variants. An ablation study confirms the importance of temporal modeling, attention mechanisms, and multimodal fusion. The framework incorporates Grad-CAM, Integrated Gradients, and SHAP, generating interpretable spectral, temporal, and feature-level explanations aligned with known acoustic biomarkers to build clinical transparency. The findings demonstrate the framework's potential for telemedicine, point-of-care diagnostics, and real-world respiratory screening.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u53ef\u89e3\u91ca\u7684\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u7ed3\u5408CNN-BiLSTM\u6ce8\u610f\u529b\u67b6\u6784\u548c\u624b\u5de5\u58f0\u5b66\u7279\u5f81\uff0c\u7528\u4e8e\u57fa\u4e8e\u547c\u5438\u97f3\u9891\u4fe1\u53f7\u7684\u80ba\u90e8\u75be\u75c5\u81ea\u52a8\u68c0\u6d4b\uff0c\u5728\u54ee\u5598\u68c0\u6d4b\u6570\u636e\u96c6\u4e0a\u53d6\u5f9791.21%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edf\u542c\u8bca\u65b9\u6cd5\u5b58\u5728\u4e3b\u89c2\u6027\u3001\u73af\u5883\u566a\u58f0\u548c\u4e34\u5e8a\u533b\u751f\u95f4\u5dee\u5f02\u7b49\u9650\u5236\uff0c\u9700\u8981\u5f00\u53d1\u5ba2\u89c2\u3001\u51c6\u786e\u7684\u81ea\u52a8\u80ba\u90e8\u75be\u75c5\u68c0\u6d4b\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u4e92\u8865\u5206\u652f\uff1a1\uff09\u57fa\u4e8eCNN-BiLSTM\u6ce8\u610f\u529b\u67b6\u6784\u7684\u8c31\u65f6\u7f16\u7801\u5668\uff1b2\uff09\u6355\u83b7MFCCs\u3001\u8c31\u8d28\u5fc3\u3001\u8c31\u5e26\u5bbd\u3001\u8fc7\u96f6\u7387\u7b49\u751f\u7406\u610f\u4e49\u58f0\u5b66\u7279\u5f81\u7684\u624b\u5de5\u7279\u5f81\u7f16\u7801\u5668\u3002\u901a\u8fc7\u540e\u671f\u878d\u5408\u7ed3\u5408\u4e24\u79cd\u8868\u793a\uff0c\u5e76\u91c7\u7528\u4e25\u683c\u7684\u9884\u5904\u7406\uff08\u91cd\u91c7\u6837\u3001\u5f52\u4e00\u5316\u3001\u566a\u58f0\u6ee4\u6ce2\u3001\u6570\u636e\u589e\u5f3a\u3001\u60a3\u8005\u7ea7\u5206\u5c42\u5212\u5206\uff09\u3002", "result": "\u5728\u54ee\u5598\u68c0\u6d4b\u6570\u636e\u96c6V2\u4e0a\u53d6\u5f9791.21%\u51c6\u786e\u7387\u30010.899\u5b8fF1\u5206\u6570\u548c0.9866\u5b8fROC-AUC\uff0c\u4f18\u4e8e\u6240\u6709\u6d88\u878d\u53d8\u4f53\u3002\u6d88\u878d\u7814\u7a76\u8bc1\u5b9e\u4e86\u65f6\u5e8f\u5efa\u6a21\u3001\u6ce8\u610f\u529b\u673a\u5236\u548c\u591a\u6a21\u6001\u878d\u5408\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u901a\u8fc7Grad-CAM\u3001Integrated Gradients\u548cSHAP\u63d0\u4f9b\u53ef\u89e3\u91ca\u7684\u8c31\u3001\u65f6\u548c\u7279\u5f81\u7ea7\u89e3\u91ca\uff0c\u4e0e\u5df2\u77e5\u58f0\u5b66\u751f\u7269\u6807\u5fd7\u7269\u4e00\u81f4\uff0c\u589e\u5f3a\u4e86\u4e34\u5e8a\u900f\u660e\u5ea6\uff0c\u5c55\u793a\u4e86\u5728\u8fdc\u7a0b\u533b\u7597\u3001\u5e8a\u65c1\u8bca\u65ad\u548c\u73b0\u5b9e\u4e16\u754c\u547c\u5438\u7b5b\u67e5\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2512.00309", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00309", "abs": "https://arxiv.org/abs/2512.00309", "authors": ["Biao Dong", "Bin Cao", "Guan Gui", "Qinyu Zhang"], "title": "Distributed Integrated Sensing and Edge AI Exploiting Prior Information", "comment": null, "summary": "This paper investigates a distributed ISEA system under a Bayesian framework, focusing on incorporating task-relevant priors to maximize inference performance. At the sensing level, an RWB estimator with a GM prior is designed. By weighting class-conditional posterior means with responsibilities, RWB effectively denoises features and outperforms ML at low SNR. At the communication level, two theoretical proxies are introduced: the computation-optimal and decision-optimal proxies. Optimal transceiver designs in terms of closed-form power allocation are derived for both TDM and FDM settings, revealing threshold-based and dual-decomposition structures. Results show that the discriminant-aware allocation yields additional inference gains.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u8d1d\u53f6\u65af\u6846\u67b6\u4e0b\u7684\u5206\u5e03\u5f0fISEA\u7cfb\u7edf\uff0c\u901a\u8fc7\u4efb\u52a1\u76f8\u5173\u5148\u9a8c\u4f18\u5316\u63a8\u7406\u6027\u80fd\uff0c\u8bbe\u8ba1\u4e86RWB\u4f30\u8ba1\u5668\u548c\u4e24\u79cd\u7406\u8bba\u4ee3\u7406\uff0c\u5728\u901a\u4fe1\u5c42\u63a8\u5bfc\u4e86\u6700\u4f18\u6536\u53d1\u5668\u8bbe\u8ba1", "motivation": "\u5728\u5206\u5e03\u5f0f\u667a\u80fd\u4f20\u611f\u3001\u8fb9\u7f18\u5206\u6790\u548c\u63a8\u7406\u7cfb\u7edf\u4e2d\uff0c\u5982\u4f55\u6709\u6548\u6574\u5408\u4efb\u52a1\u76f8\u5173\u5148\u9a8c\u77e5\u8bc6\u6765\u6700\u5927\u5316\u63a8\u7406\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u63d0\u5347\u7279\u5f81\u53bb\u566a\u548c\u51b3\u7b56\u51c6\u786e\u6027", "method": "1) \u611f\u77e5\u5c42\uff1a\u8bbe\u8ba1\u57fa\u4e8e\u9ad8\u65af\u6df7\u5408\u5148\u9a8c\u7684RWB\u4f30\u8ba1\u5668\uff0c\u901a\u8fc7\u8d23\u4efb\u52a0\u6743\u7c7b\u6761\u4ef6\u540e\u9a8c\u5747\u503c\u8fdb\u884c\u7279\u5f81\u53bb\u566a\uff1b2) \u901a\u4fe1\u5c42\uff1a\u5f15\u5165\u8ba1\u7b97\u6700\u4f18\u548c\u51b3\u7b56\u6700\u4f18\u4e24\u79cd\u7406\u8bba\u4ee3\u7406\uff0c\u63a8\u5bfcTDM\u548cFDM\u573a\u666f\u4e0b\u7684\u95ed\u5f0f\u529f\u7387\u5206\u914d\u6700\u4f18\u6536\u53d1\u5668\u8bbe\u8ba1\uff0c\u91c7\u7528\u9608\u503c\u548c\u53cc\u5206\u89e3\u7ed3\u6784", "result": "RWB\u4f30\u8ba1\u5668\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u4f18\u4e8eML\u4f30\u8ba1\uff1b\u5224\u522b\u611f\u77e5\u7684\u529f\u7387\u5206\u914d\u5e26\u6765\u989d\u5916\u7684\u63a8\u7406\u6027\u80fd\u589e\u76ca\uff1b\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u6700\u4f18\u8bbe\u8ba1\u7684\u7ed3\u6784\u7279\u6027", "conclusion": "\u901a\u8fc7\u8d1d\u53f6\u65af\u6846\u67b6\u6574\u5408\u4efb\u52a1\u5148\u9a8c\u80fd\u663e\u8457\u63d0\u5347\u5206\u5e03\u5f0fISEA\u7cfb\u7edf\u7684\u63a8\u7406\u6027\u80fd\uff0cRWB\u4f30\u8ba1\u5668\u548c\u5224\u522b\u611f\u77e5\u901a\u4fe1\u8bbe\u8ba1\u4e3a\u7cfb\u7edf\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u9014\u5f84"}}
{"id": "2512.00621", "categories": ["cs.SD", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.00621", "abs": "https://arxiv.org/abs/2512.00621", "authors": ["Arnesh Batra", "Dev Sharma", "Krish Thukral", "Ruhani Bhatia", "Naman Batra", "Aditya Gautam"], "title": "Melody or Machine: Detecting Synthetic Music with Dual-Stream Contrastive Learning", "comment": "Accepted at Transactions on Machine Learning Research (TMLR)", "summary": "The rapid evolution of end-to-end AI music generation poses an escalating threat to artistic authenticity and copyright, demanding detection methods that can keep pace. While foundational, existing models like SpecTTTra falter when faced with the diverse and rapidly advancing ecosystem of new generators, exhibiting significant performance drops on out-of-distribution (OOD) content. This generalization failure highlights a critical gap: the need for more challenging benchmarks and more robust detection architectures. To address this, we first introduce Melody or Machine (MoM), a new large-scale benchmark of over 130,000 songs (6,665 hours). MoM is the most diverse dataset to date, built with a mix of open and closed-source models and a curated OOD test set designed specifically to foster the development of truly generalizable detectors. Alongside this benchmark, we introduce CLAM, a novel dual-stream detection architecture. We hypothesize that subtle, machine-induced inconsistencies between vocal and instrumental elements, often imperceptible in a mixed signal, offer a powerful tell-tale sign of synthesis. CLAM is designed to test this hypothesis by employing two distinct pre-trained audio encoders (MERT and Wave2Vec2) to create parallel representations of the audio. These representations are fused by a learnable cross-aggregation module that models their inter-dependencies. The model is trained with a dual-loss objective: a standard binary cross-entropy loss for classification, complemented by a contrastive triplet loss which trains the model to distinguish between coherent and artificially mismatched stream pairings, enhancing its sensitivity to synthetic artifacts without presuming a simple feature alignment. CLAM establishes a new state-of-the-art in synthetic music forensics. It achieves an F1 score of 0.925 on our challenging MoM benchmark.", "AI": {"tldr": "\u63d0\u51faMoM\u5927\u89c4\u6a21\u57fa\u51c6\u6570\u636e\u96c6\u548cCLAM\u53cc\u6d41\u68c0\u6d4b\u67b6\u6784\uff0c\u7528\u4e8e\u68c0\u6d4bAI\u751f\u6210\u7684\u97f3\u4e50\uff0c\u89e3\u51b3\u73b0\u6709\u6a21\u578b\u5728\u5206\u5e03\u5916\u5185\u5bb9\u4e0a\u6cdb\u5316\u80fd\u529b\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u7aef\u5230\u7aefAI\u97f3\u4e50\u751f\u6210\u7684\u5feb\u901f\u53d1\u5c55\u5bf9\u827a\u672f\u771f\u5b9e\u6027\u548c\u7248\u6743\u6784\u6210\u5a01\u80c1\uff0c\u73b0\u6709\u68c0\u6d4b\u6a21\u578b\u5728\u65b0\u578b\u751f\u6210\u5668\u4ea7\u751f\u7684\u5206\u5e03\u5916\u5185\u5bb9\u4e0a\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u9700\u8981\u66f4\u5177\u6311\u6218\u6027\u7684\u57fa\u51c6\u548c\u66f4\u9c81\u68d2\u7684\u68c0\u6d4b\u67b6\u6784\u3002", "method": "1) \u6784\u5efaMoM\u57fa\u51c6\u6570\u636e\u96c6\uff1a\u5305\u542b\u8d85\u8fc713\u4e07\u9996\u6b4c\u66f2\uff086,665\u5c0f\u65f6\uff09\uff0c\u4f7f\u7528\u5f00\u6e90\u548c\u95ed\u6e90\u6a21\u578b\u6df7\u5408\u6784\u5efa\uff0c\u5e76\u4e13\u95e8\u8bbe\u8ba1\u5206\u5e03\u5916\u6d4b\u8bd5\u96c6\uff1b2) \u63d0\u51faCLAM\u53cc\u6d41\u68c0\u6d4b\u67b6\u6784\uff1a\u4f7f\u7528MERT\u548cWave2Vec2\u4e24\u4e2a\u9884\u8bad\u7ec3\u97f3\u9891\u7f16\u7801\u5668\u521b\u5efa\u5e76\u884c\u8868\u793a\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u4ea4\u53c9\u805a\u5408\u6a21\u5757\u878d\u5408\uff0c\u91c7\u7528\u4e8c\u5143\u4ea4\u53c9\u71b5\u635f\u5931\u548c\u5bf9\u6bd4\u4e09\u5143\u7ec4\u635f\u5931\u7684\u53cc\u635f\u5931\u76ee\u6807\u8bad\u7ec3\u3002", "result": "CLAM\u5728MoM\u57fa\u51c6\u4e0a\u53d6\u5f97\u4e860.925\u7684F1\u5206\u6570\uff0c\u5efa\u7acb\u4e86\u5408\u6210\u97f3\u4e50\u53d6\u8bc1\u7684\u65b0\u6700\u5148\u8fdb\u6c34\u5e73\u3002", "conclusion": "MoM\u57fa\u51c6\u548cCLAM\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86AI\u751f\u6210\u97f3\u4e50\u68c0\u6d4b\u4e2d\u7684\u6cdb\u5316\u95ee\u9898\uff0c\u4e3a\u5f00\u53d1\u771f\u6b63\u53ef\u6cdb\u5316\u7684\u68c0\u6d4b\u5668\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\uff0c\u5728\u5408\u6210\u97f3\u4e50\u53d6\u8bc1\u9886\u57df\u5b9e\u73b0\u4e86\u7a81\u7834\u6027\u8fdb\u5c55\u3002"}}
{"id": "2512.00374", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00374", "abs": "https://arxiv.org/abs/2512.00374", "authors": ["Arkadiusz Czuba"], "title": "Vision Transformer for Classification of UAV and Helicopters Using Micro-Doppler Spectrograms in Surveillance Radar", "comment": "Accepted to IEEE ICCI*CC 2023 (pre-publication version)", "summary": "Machine learning researchers strive to develop better and better algorithms to solve computer vision problems, such as image classification. In recent years, the classification of micro-Doppler spectrograms has also benefited from these findings. Convolutional neural networks (CNNs) became the gold standard for these tasks. Unfortunately, CNNs can work on fixed-resolution images, or they need to resize mismatched images to fit input dimensions. It can become a problem when micro-Doppler spectrograms are generated with e.g. different integration times. The goal of this work was to classify the UAV and helicopters micro-Doppler spectrograms with different duration times, using the Vision Transformer (ViT) architecture. Before that, spectrograms signal-to-noise-ratio and micro-Doppler features visibility were improved by denoising algorithm based on modified Dual Tree Complex Wavelet Transform. The experiments were conducted on real data collected using surveillance, short range, military radar. As a result, it has been shown that the ViT model achieved 97.76\\% accuracy for this task. To further interpret the network performance, the raw self-attention maps were analyzed.", "AI": {"tldr": "\u4f7f\u7528Vision Transformer (ViT) \u67b6\u6784\u5bf9\u65e0\u4eba\u673a\u548c\u76f4\u5347\u673a\u5fae\u591a\u666e\u52d2\u8c31\u56fe\u8fdb\u884c\u5206\u7c7b\uff0c\u5904\u7406\u4e0d\u540c\u6301\u7eed\u65f6\u95f4\u7684\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u6539\u8fdb\u7684\u4fe1\u566a\u6bd4\u548c\u53bb\u566a\u7b97\u6cd5\u5b9e\u73b097.76%\u7684\u51c6\u786e\u7387\u3002", "motivation": "\u4f20\u7edfCNN\u5728\u5904\u7406\u5fae\u591a\u666e\u52d2\u8c31\u56fe\u65f6\u5b58\u5728\u5c40\u9650\u6027\uff0c\u7279\u522b\u662f\u5f53\u8c31\u56fe\u56e0\u4e0d\u540c\u79ef\u5206\u65f6\u95f4\u800c\u4ea7\u751f\u4e0d\u540c\u5206\u8fa8\u7387\u65f6\uff0cCNN\u9700\u8981\u56fa\u5b9a\u5206\u8fa8\u7387\u6216\u91cd\u65b0\u8c03\u6574\u56fe\u50cf\u5c3a\u5bf8\u3002\u5fae\u591a\u666e\u52d2\u8c31\u56fe\u5206\u7c7b\u5728\u96f7\u8fbe\u76ee\u6807\u8bc6\u522b\u4e2d\u5f88\u91cd\u8981\uff0c\u9700\u8981\u80fd\u5904\u7406\u4e0d\u540c\u6301\u7eed\u65f6\u95f4\u8c31\u56fe\u7684\u66f4\u7075\u6d3b\u65b9\u6cd5\u3002", "method": "1. \u4f7f\u7528\u6539\u8fdb\u7684\u53cc\u6811\u590d\u5c0f\u6ce2\u53d8\u6362\u53bb\u566a\u7b97\u6cd5\u63d0\u9ad8\u8c31\u56fe\u7684\u4fe1\u566a\u6bd4\u548c\u5fae\u591a\u666e\u52d2\u7279\u5f81\u53ef\u89c1\u6027\uff1b2. \u91c7\u7528Vision Transformer (ViT) \u67b6\u6784\u5bf9\u65e0\u4eba\u673a\u548c\u76f4\u5347\u673a\u7684\u5fae\u591a\u666e\u52d2\u8c31\u56fe\u8fdb\u884c\u5206\u7c7b\uff0cViT\u80fd\u5904\u7406\u4e0d\u540c\u6301\u7eed\u65f6\u95f4\u7684\u8c31\u56fe\uff1b3. \u5728\u771f\u5b9e\u519b\u7528\u96f7\u8fbe\u6570\u636e\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff1b4. \u5206\u6790\u539f\u59cb\u81ea\u6ce8\u610f\u529b\u56fe\u4ee5\u89e3\u91ca\u7f51\u7edc\u6027\u80fd\u3002", "result": "ViT\u6a21\u578b\u5728\u8be5\u4efb\u52a1\u4e0a\u8fbe\u5230\u4e8697.76%\u7684\u51c6\u786e\u7387\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u4e0d\u540c\u6301\u7eed\u65f6\u95f4\u5fae\u591a\u666e\u52d2\u8c31\u56fe\u7684\u5206\u7c7b\u95ee\u9898\u3002\u901a\u8fc7\u81ea\u6ce8\u610f\u529b\u56fe\u5206\u6790\u8fdb\u4e00\u6b65\u89e3\u91ca\u4e86\u7f51\u7edc\u6027\u80fd\u3002", "conclusion": "Vision Transformer\u67b6\u6784\u5728\u5fae\u591a\u666e\u52d2\u8c31\u56fe\u5206\u7c7b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u80fd\u591f\u6709\u6548\u5904\u7406\u4e0d\u540c\u6301\u7eed\u65f6\u95f4\u7684\u8c31\u56fe\uff0c\u4e3a\u96f7\u8fbe\u76ee\u6807\u8bc6\u522b\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edfCNN\u66f4\u7075\u6d3b\u7684\u89e3\u51b3\u65b9\u6848\u3002\u53bb\u566a\u9884\u5904\u7406\u5bf9\u63d0\u9ad8\u5206\u7c7b\u6027\u80fd\u4e5f\u5f88\u91cd\u8981\u3002"}}
{"id": "2512.01537", "categories": ["cs.SD", "cs.AI", "cs.IT", "cs.LG", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.01537", "abs": "https://arxiv.org/abs/2512.01537", "authors": ["Tal Shuster", "Eliya Nachmani"], "title": "Q2D2: A Geometry-Aware Audio Codec Leveraging Two-Dimensional Quantization", "comment": null, "summary": "Recent neural audio codecs have achieved impressive reconstruction quality, typically relying on quantization methods such as Residual Vector Quantization (RVQ), Vector Quantization (VQ) and Finite Scalar Quantization (FSQ). However, these quantization techniques limit the geometric structure of the latent space, make it harder to capture correlations between features leading to inefficiency in representation learning, codebook utilization and token rate. In this paper we introduce Two Dimensional Quantization (Q2D2), a quantization scheme in which feature pairs are projected onto structured 2D grids such as hexagonal, rhombic, or rectangular tiling and quantized to the nearest grid values, yielding an implicit codebook defined by the product of grid levels, with codebook sizes comparable to conventional methods. Despite its simple geometric formulation, Q2D2 improves audio compression efficiency, with low token rates and high codebook utilization while maintaining state of the art reconstruction quality. Specifically, Q2D2 achieves competitive to superior performance in various objective and subjective reconstruction metrics, across extensive experiments in speech domain compared to state of the art models. Comprehensive ablation studies further confirm the effectiveness of our design choices.", "AI": {"tldr": "\u63d0\u51faQ2D2\u4e8c\u7ef4\u91cf\u5316\u65b9\u6cd5\uff0c\u5c06\u7279\u5f81\u5bf9\u6295\u5f71\u5230\u7ed3\u6784\u5316\u7f51\u683c\u8fdb\u884c\u91cf\u5316\uff0c\u5728\u97f3\u9891\u538b\u7f29\u4e2d\u5b9e\u73b0\u9ad8\u6548\u8868\u793a\u5b66\u4e60\u3001\u9ad8\u7801\u672c\u5229\u7528\u7387\u548c\u4f4etoken\u7387\uff0c\u540c\u65f6\u4fdd\u6301SOTA\u91cd\u5efa\u8d28\u91cf\u3002", "motivation": "\u73b0\u6709\u795e\u7ecf\u97f3\u9891\u7f16\u89e3\u7801\u5668\u4f7f\u7528\u7684\u91cf\u5316\u65b9\u6cd5\uff08\u5982RVQ\u3001VQ\u3001FSQ\uff09\u9650\u5236\u4e86\u6f5c\u5728\u7a7a\u95f4\u7684\u51e0\u4f55\u7ed3\u6784\uff0c\u96be\u4ee5\u6355\u6349\u7279\u5f81\u95f4\u76f8\u5173\u6027\uff0c\u5bfc\u81f4\u8868\u793a\u5b66\u4e60\u6548\u7387\u4f4e\u4e0b\u3001\u7801\u672c\u5229\u7528\u7387\u4f4e\u548ctoken\u7387\u9ad8\u3002", "method": "\u63d0\u51fa\u4e8c\u7ef4\u91cf\u5316(Q2D2)\u65b9\u6848\uff1a\u5c06\u7279\u5f81\u5bf9\u6295\u5f71\u5230\u7ed3\u6784\u5316\u4e8c\u7ef4\u7f51\u683c\uff08\u5982\u516d\u8fb9\u5f62\u3001\u83f1\u5f62\u6216\u77e9\u5f62\u5e73\u94fa\uff09\uff0c\u91cf\u5316\u5230\u6700\u8fd1\u7684\u7f51\u683c\u503c\uff0c\u901a\u8fc7\u7f51\u683c\u7ea7\u522b\u7684\u4e58\u79ef\u5b9a\u4e49\u9690\u5f0f\u7801\u672c\uff0c\u7801\u672c\u5927\u5c0f\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u5f53\u3002", "result": "Q2D2\u5728\u8bed\u97f3\u9886\u57df\u7684\u5e7f\u6cdb\u5b9e\u9a8c\u4e2d\uff0c\u5728\u5404\u79cd\u5ba2\u89c2\u548c\u4e3b\u89c2\u91cd\u5efa\u6307\u6807\u4e0a\u8fbe\u5230\u7ade\u4e89\u6027\u751a\u81f3\u4f18\u4e8eSOTA\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5b9e\u73b0\u4f4etoken\u7387\u548c\u9ad8\u7801\u672c\u5229\u7528\u7387\u3002", "conclusion": "Q2D2\u901a\u8fc7\u7b80\u5355\u7684\u51e0\u4f55\u516c\u5f0f\u5316\u6539\u8fdb\u4e86\u97f3\u9891\u538b\u7f29\u6548\u7387\uff0c\u5728\u4fdd\u6301SOTA\u91cd\u5efa\u8d28\u91cf\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u8868\u793a\u5b66\u4e60\u3001\u66f4\u597d\u7684\u7801\u672c\u5229\u7528\u7387\u548c\u66f4\u4f4e\u7684token\u7387\u3002"}}
{"id": "2512.00435", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00435", "abs": "https://arxiv.org/abs/2512.00435", "authors": ["Jinbing Jiang", "Feng Shu", "Bin Deng", "Maolin Li", "Jiatong Bai", "Yan Wang", "Cunhua Pan", "Jiangzhou Wang"], "title": "Rotatable Antenna-array-enhanced Direction-sensing for Low-altitude Communication Network: Method and Performance", "comment": "10 pages, 16 figures", "summary": "In a practical multi-antenna receiver, each element of the receive antenna array has a directive antenna pattern, which is still not fully explored and investigated in academia and industry until now. When the emitter is deviated greatly from the normal direction of antenna element or is close to the null-point direction, the sensing energy by array will be seriously attenuated such that the direction-sensing performance is degraded significantly. To address such an issue, a rotatable array system is established with the directive antenna pattern of each element taken into account, where each element has the same antenna pattern. Then, the corresponding the Cramer-Rao lower bound (CRLB) is derived. Finally, a recursive rotation Root-MUSIC (RR-Root-MUSIC) direction-sensing method is proposed and its mean-square-error (MSE) performance is evaluated by the derived CRLB. Simulation results show that the proposed rotation method converges rapidly with about ten iterations, and make a significant enhancement on the direction-sensing accuracy in terms of MSE when the target direction departs seriously far away from the normal vector of array. Compared with conventional Root-MUSIC, the sensing performance of the proposed RR-Root-MUSIC method is much closer to the CRLB.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u8003\u8651\u5929\u7ebf\u5355\u5143\u65b9\u5411\u6027\u6a21\u5f0f\u7684\u65cb\u8f6c\u9635\u5217\u7cfb\u7edf\uff0c\u901a\u8fc7\u9012\u5f52\u65cb\u8f6cRoot-MUSIC\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u4e86\u76ee\u6807\u65b9\u5411\u504f\u79bb\u9635\u5217\u6cd5\u7ebf\u65b9\u5411\u65f6\u7684\u6d4b\u5411\u7cbe\u5ea6\u3002", "motivation": "\u5b9e\u9645\u591a\u5929\u7ebf\u63a5\u6536\u7cfb\u7edf\u4e2d\uff0c\u6bcf\u4e2a\u5929\u7ebf\u5355\u5143\u90fd\u5177\u6709\u65b9\u5411\u6027\u5929\u7ebf\u6a21\u5f0f\uff0c\u5f53\u53d1\u5c04\u6e90\u4e25\u91cd\u504f\u79bb\u5929\u7ebf\u5355\u5143\u6cd5\u7ebf\u65b9\u5411\u6216\u63a5\u8fd1\u96f6\u70b9\u65b9\u5411\u65f6\uff0c\u9635\u5217\u7684\u611f\u77e5\u80fd\u91cf\u4f1a\u4e25\u91cd\u8870\u51cf\uff0c\u5bfc\u81f4\u6d4b\u5411\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002\u8fd9\u4e00\u95ee\u9898\u5728\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\u3002", "method": "\u5efa\u7acb\u8003\u8651\u5929\u7ebf\u5355\u5143\u65b9\u5411\u6027\u6a21\u5f0f\u7684\u65cb\u8f6c\u9635\u5217\u7cfb\u7edf\uff0c\u63a8\u5bfc\u76f8\u5e94\u7684\u514b\u62c9\u7f8e\u7f57\u4e0b\u754c(CRLB)\uff0c\u5e76\u63d0\u51fa\u9012\u5f52\u65cb\u8f6cRoot-MUSIC(RR-Root-MUSIC)\u6d4b\u5411\u65b9\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65cb\u8f6c\u65b9\u6cd5\u5728\u5927\u7ea610\u6b21\u8fed\u4ee3\u540e\u5feb\u901f\u6536\u655b\uff0c\u5f53\u76ee\u6807\u65b9\u5411\u4e25\u91cd\u504f\u79bb\u9635\u5217\u6cd5\u7ebf\u65b9\u5411\u65f6\uff0c\u5728\u5747\u65b9\u8bef\u5dee\u65b9\u9762\u663e\u8457\u63d0\u9ad8\u4e86\u6d4b\u5411\u7cbe\u5ea6\u3002\u4e0e\u4f20\u7edfRoot-MUSIC\u76f8\u6bd4\uff0cRR-Root-MUSIC\u65b9\u6cd5\u7684\u611f\u77e5\u6027\u80fd\u66f4\u63a5\u8fd1CRLB\u3002", "conclusion": "\u8003\u8651\u5929\u7ebf\u5355\u5143\u65b9\u5411\u6027\u6a21\u5f0f\u7684\u65cb\u8f6c\u9635\u5217\u7cfb\u7edf\u80fd\u6709\u6548\u89e3\u51b3\u76ee\u6807\u65b9\u5411\u504f\u79bb\u9635\u5217\u6cd5\u7ebf\u65f6\u7684\u6d4b\u5411\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u63d0\u51fa\u7684RR-Root-MUSIC\u65b9\u6cd5\u5177\u6709\u5feb\u901f\u6536\u655b\u548c\u63a5\u8fd1\u7406\u8bba\u6781\u9650\u7684\u4f18\u5f02\u6027\u80fd\u3002"}}
{"id": "2512.01559", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.01559", "abs": "https://arxiv.org/abs/2512.01559", "authors": ["Seungheon Doh", "Junghyun Koo", "Marco A. Mart\u00ednez-Ram\u00edrez", "Woosung Choi", "Wei-Hsiang Liao", "Qiyu Wu", "Juhan Nam", "Yuki Mitsufuji"], "title": "LLM2Fx-Tools: Tool Calling For Music Post-Production", "comment": null, "summary": "This paper introduces LLM2Fx-Tools, a multimodal tool-calling framework that generates executable sequences of audio effects (Fx-chain) for music post-production. LLM2Fx-Tools uses a large language model (LLM) to understand audio inputs, select audio effects types, determine their order, and estimate parameters, guided by chain-of-thought (CoT) planning. We also present LP-Fx, a new instruction-following dataset with structured CoT annotations and tool calls for audio effects modules. Experiments show that LLM2Fx-Tools can infer an Fx-chain and its parameters from pairs of unprocessed and processed audio, enabled by autoregressive sequence modeling, tool calling, and CoT reasoning. We further validate the system in a style transfer setting, where audio effects information is transferred from a reference source and applied to new content. Finally, LLM-as-a-judge evaluation demonstrates that our approach generates appropriate CoT reasoning and responses for music production queries. To our knowledge, this is the first work to apply LLM-based tool calling to audio effects modules, enabling interpretable and controllable music production.", "AI": {"tldr": "LLM2Fx-Tools\uff1a\u9996\u4e2a\u57fa\u4e8eLLM\u5de5\u5177\u8c03\u7528\u7684\u97f3\u9891\u6548\u679c\u94fe\u751f\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u601d\u7ef4\u94fe\u89c4\u5212\u5b9e\u73b0\u97f3\u4e50\u540e\u671f\u5236\u4f5c\u7684\u53ef\u89e3\u91ca\u63a7\u5236", "motivation": "\u97f3\u4e50\u540e\u671f\u5236\u4f5c\u4e2d\u97f3\u9891\u6548\u679c\u94fe\u7684\u521b\u5efa\u9700\u8981\u4e13\u4e1a\u77e5\u8bc6\u548c\u7ecf\u9a8c\uff0c\u4f20\u7edf\u65b9\u6cd5\u7f3a\u4e4f\u53ef\u89e3\u91ca\u6027\u548c\u81ea\u52a8\u5316\u3002\u9700\u8981\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u7406\u89e3\u97f3\u9891\u8f93\u5165\u3001\u9009\u62e9\u6548\u679c\u7c7b\u578b\u3001\u786e\u5b9a\u987a\u5e8f\u548c\u4f30\u8ba1\u53c2\u6570\u7684\u667a\u80fd\u7cfb\u7edf\u3002", "method": "1. \u4f7f\u7528\u5927\u8bed\u8a00\u6a21\u578b\u7406\u89e3\u97f3\u9891\u8f93\u5165\uff0c\u901a\u8fc7\u601d\u7ef4\u94fe\u89c4\u5212\u6307\u5bfc\u97f3\u9891\u6548\u679c\u9009\u62e9\uff1b2. \u63d0\u51faLP-Fx\u6570\u636e\u96c6\uff0c\u5305\u542b\u7ed3\u6784\u5316\u601d\u7ef4\u94fe\u6807\u6ce8\u548c\u5de5\u5177\u8c03\u7528\uff1b3. \u7ed3\u5408\u81ea\u56de\u5f52\u5e8f\u5217\u5efa\u6a21\u3001\u5de5\u5177\u8c03\u7528\u548c\u601d\u7ef4\u94fe\u63a8\u7406\uff1b4. \u652f\u6301\u98ce\u683c\u8fc1\u79fb\u5e94\u7528\u3002", "result": "1. \u80fd\u591f\u4ece\u672a\u5904\u7406/\u5df2\u5904\u7406\u97f3\u9891\u5bf9\u4e2d\u63a8\u65ad\u6548\u679c\u94fe\u548c\u53c2\u6570\uff1b2. \u5728\u98ce\u683c\u8fc1\u79fb\u4efb\u52a1\u4e2d\u6709\u6548\u4f20\u9012\u97f3\u9891\u6548\u679c\u4fe1\u606f\uff1b3. LLM-as-a-judge\u8bc4\u4f30\u663e\u793a\u7cfb\u7edf\u80fd\u751f\u6210\u5408\u9002\u7684\u601d\u7ef4\u94fe\u63a8\u7406\u548c\u54cd\u5e94\uff1b4. \u9996\u6b21\u5c06LLM\u5de5\u5177\u8c03\u7528\u5e94\u7528\u4e8e\u97f3\u9891\u6548\u679c\u6a21\u5757\u3002", "conclusion": "LLM2Fx-Tools\u662f\u9996\u4e2a\u5c06LLM\u5de5\u5177\u8c03\u7528\u5e94\u7528\u4e8e\u97f3\u9891\u6548\u679c\u6a21\u5757\u7684\u5de5\u4f5c\uff0c\u5b9e\u73b0\u4e86\u53ef\u89e3\u91ca\u548c\u53ef\u63a7\u7684\u97f3\u4e50\u5236\u4f5c\uff0c\u4e3a\u97f3\u4e50\u540e\u671f\u5236\u4f5c\u81ea\u52a8\u5316\u5f00\u8f9f\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2512.00443", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00443", "abs": "https://arxiv.org/abs/2512.00443", "authors": ["Harshith Reddy", "Pankaj Arora"], "title": "A 40 GHz Low-Power Variable-Gain Low Noise Amplifier in 28-nm CMOS Process", "comment": "6 pages, 11 figures, accepted at IEEE IEMECON 2025", "summary": "A Low-Power Variable Gain (VG) mm-Wave Low Noise Amplifier (LNA) is designed and simulated in a 28-nm CMOS process. The LNA utilizes a simple, yet novel, technique presented in this paper to vary the small-signal output resistance to provide gain control. The amplifier also utilizes forward body biasing to reduce the supply voltage to 0.7 V and enhance power efficiency. A simultaneous noise and input matching (SNIM) technique is used to provide robust input matching and noise performance during gain adjustment. The proposed VG-LNA achieves a peak gain of 21 dB at 40.5 GHz with a noise figure of 2.8 dB and consumes only 4.5 mW. At the highest gain configuration, an input-referred 1-dB compression of -21 dBm and IP3 of -7.8 dBm are achieved, which increase to -14.8 dBm and 1.2 dBm, respectively, at the lowest gain configuration. Regardless of the gain control voltage, the LNA attains a very good FoM as compared to the state-of-the-art.", "AI": {"tldr": "\u8bbe\u8ba1\u4e86\u4e00\u79cd\u91c7\u752828nm CMOS\u5de5\u827a\u7684\u4f4e\u529f\u8017\u53ef\u53d8\u589e\u76ca\u6beb\u7c73\u6ce2\u4f4e\u566a\u58f0\u653e\u5927\u5668\uff0c\u901a\u8fc7\u65b0\u9896\u7684\u8f93\u51fa\u7535\u963b\u8c03\u8282\u6280\u672f\u5b9e\u73b0\u589e\u76ca\u63a7\u5236\uff0c\u91c7\u7528\u524d\u5411\u4f53\u504f\u7f6e\u964d\u4f4e\u4f9b\u7535\u7535\u538b\u81f30.7V\uff0c\u572840.5GHz\u9891\u7387\u4e0b\u5b9e\u73b021dB\u5cf0\u503c\u589e\u76ca\u548c2.8dB\u566a\u58f0\u7cfb\u6570\uff0c\u529f\u8017\u4ec54.5mW\u3002", "motivation": "\u6beb\u7c73\u6ce2\u901a\u4fe1\u7cfb\u7edf\u9700\u8981\u9ad8\u6027\u80fd\u3001\u4f4e\u529f\u8017\u7684\u53ef\u53d8\u589e\u76ca\u4f4e\u566a\u58f0\u653e\u5927\u5668\uff0c\u4f20\u7edf\u8bbe\u8ba1\u5728\u589e\u76ca\u8c03\u8282\u65f6\u96be\u4ee5\u540c\u65f6\u4fdd\u6301\u566a\u58f0\u6027\u80fd\u548c\u8f93\u5165\u5339\u914d\uff0c\u4e14\u529f\u8017\u8f83\u9ad8\u3002\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u80fd\u5728\u589e\u76ca\u53d8\u5316\u65f6\u4fdd\u6301\u826f\u597d\u566a\u58f0\u548c\u5339\u914d\u6027\u80fd\u7684\u4f4e\u529f\u8017\u89e3\u51b3\u65b9\u6848\u3002", "method": "1. \u91c7\u7528\u65b0\u9896\u7684\u5c0f\u4fe1\u53f7\u8f93\u51fa\u7535\u963b\u8c03\u8282\u6280\u672f\u5b9e\u73b0\u589e\u76ca\u63a7\u5236\uff1b2. \u4f7f\u7528\u524d\u5411\u4f53\u504f\u7f6e\u6280\u672f\u5c06\u4f9b\u7535\u7535\u538b\u964d\u81f30.7V\u4ee5\u63d0\u9ad8\u529f\u7387\u6548\u7387\uff1b3. \u5e94\u7528\u540c\u65f6\u566a\u58f0\u548c\u8f93\u5165\u5339\u914d\u6280\u672f\uff0c\u5728\u589e\u76ca\u8c03\u8282\u8fc7\u7a0b\u4e2d\u4fdd\u6301\u7a33\u5b9a\u7684\u8f93\u5165\u5339\u914d\u548c\u566a\u58f0\u6027\u80fd\u3002", "result": "\u572840.5GHz\u9891\u7387\u4e0b\u5b9e\u73b021dB\u5cf0\u503c\u589e\u76ca\uff0c\u566a\u58f0\u7cfb\u65702.8dB\uff0c\u529f\u8017\u4ec54.5mW\u3002\u6700\u9ad8\u589e\u76ca\u914d\u7f6e\u4e0b\u8f93\u51651dB\u538b\u7f29\u70b9\u4e3a-21dBm\uff0cIP3\u4e3a-7.8dBm\uff1b\u6700\u4f4e\u589e\u76ca\u914d\u7f6e\u4e0b\u5206\u522b\u4e3a-14.8dBm\u548c1.2dBm\u3002\u5728\u6240\u6709\u589e\u76ca\u63a7\u5236\u7535\u538b\u4e0b\u5747\u83b7\u5f97\u4f18\u4e8e\u73b0\u6709\u6280\u672f\u7684\u4f18\u503c\u7cfb\u6570\u3002", "conclusion": "\u8be5\u8bbe\u8ba1\u6210\u529f\u5b9e\u73b0\u4e86\u4f4e\u529f\u8017\u3001\u9ad8\u6027\u80fd\u7684\u53ef\u53d8\u589e\u76ca\u6beb\u7c73\u6ce2\u4f4e\u566a\u58f0\u653e\u5927\u5668\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u8f93\u51fa\u7535\u963b\u8c03\u8282\u548c\u524d\u5411\u4f53\u504f\u7f6e\u6280\u672f\uff0c\u5728\u4fdd\u6301\u826f\u597d\u566a\u58f0\u548c\u5339\u914d\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u529f\u8017\uff0c\u4e3a\u6beb\u7c73\u6ce2\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.01626", "categories": ["cs.SD", "cs.NE"], "pdf": "https://arxiv.org/pdf/2512.01626", "abs": "https://arxiv.org/abs/2512.01626", "authors": ["Pengfei Sun", "Wenyu Jiang", "Paul Devos", "Dick Botteldooren"], "title": "Parallel Delayed Memory Units for Enhanced Temporal Modeling in Biomedical and Bioacoustic Signal Analysis", "comment": "Accepted for publication in IEEE Transactions on Audio, Speech and Language Processing, 2025", "summary": "Advanced deep learning architectures, particularly recurrent neural networks (RNNs), have been widely applied in audio, bioacoustic, and biomedical signal analysis, especially in data-scarce environments. While gated RNNs remain effective, they can be relatively over-parameterised and less training-efficient in some regimes, while linear RNNs tend to fall short in capturing the complexity inherent in bio-signals. To address these challenges, we propose the Parallel Delayed Memory Unit (PDMU), a {delay-gated state-space module for short-term temporal credit assignment} targeting audio and bioacoustic signals, which enhances short-term temporal state interactions and memory efficiency via a gated delay-line mechanism. Unlike previous Delayed Memory Units (DMU) that embed temporal dynamics into the delay-line architecture, the PDMU further compresses temporal information into vector representations using Legendre Memory Units (LMU). This design serves as a form of causal attention, allowing the model to dynamically adjust its reliance on past states and improve real-time learning performance. Notably, in low-information scenarios, the gating mechanism behaves similarly to skip connections by bypassing state decay and preserving early representations, thereby facilitating long-term memory retention. The PDMU is modular, supporting parallel training and sequential inference, and can be easily integrated into existing linear RNN frameworks. Furthermore, we introduce bidirectional, efficient, and spiking variants of the architecture, each offering additional gains in performance or energy efficiency. Experimental results on diverse audio and biomedical benchmarks demonstrate that the PDMU significantly enhances both memory capacity and overall model performance.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u884c\u5ef6\u8fdf\u8bb0\u5fc6\u5355\u5143\uff08PDMU\uff09\uff0c\u4e00\u79cd\u7528\u4e8e\u97f3\u9891\u548c\u751f\u7269\u58f0\u5b66\u4fe1\u53f7\u5904\u7406\u7684\u5ef6\u8fdf\u95e8\u63a7\u72b6\u6001\u7a7a\u95f4\u6a21\u5757\uff0c\u901a\u8fc7\u95e8\u63a7\u5ef6\u8fdf\u7ebf\u673a\u5236\u589e\u5f3a\u77ed\u671f\u65f6\u95f4\u72b6\u6001\u4ea4\u4e92\u548c\u8bb0\u5fc6\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u95e8\u63a7RNN\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u53c2\u6570\u8fc7\u591a\u3001\u8bad\u7ec3\u6548\u7387\u4f4e\uff0c\u800c\u7ebf\u6027RNN\u96be\u4ee5\u6355\u6349\u751f\u7269\u4fe1\u53f7\u7684\u590d\u6742\u6027\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u9ad8\u6548\u5904\u7406\u77ed\u671f\u65f6\u95f4\u4f9d\u8d56\uff0c\u53c8\u80fd\u4fdd\u6301\u957f\u671f\u8bb0\u5fc6\u7684\u67b6\u6784\u3002", "method": "\u63d0\u51faPDMU\u67b6\u6784\uff0c\u5c06\u65f6\u95f4\u4fe1\u606f\u538b\u7f29\u5230\u5411\u91cf\u8868\u793a\u4e2d\uff08\u4f7f\u7528Legendre Memory Units\uff09\uff0c\u4f5c\u4e3a\u56e0\u679c\u6ce8\u610f\u529b\u673a\u5236\uff0c\u8ba9\u6a21\u578b\u52a8\u6001\u8c03\u6574\u5bf9\u8fc7\u53bb\u72b6\u6001\u7684\u4f9d\u8d56\u3002\u652f\u6301\u5e76\u884c\u8bad\u7ec3\u548c\u987a\u5e8f\u63a8\u7406\uff0c\u53ef\u96c6\u6210\u5230\u73b0\u6709\u7ebf\u6027RNN\u6846\u67b6\u4e2d\u3002", "result": "\u5728\u591a\u79cd\u97f3\u9891\u548c\u751f\u7269\u533b\u5b66\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0cPDMU\u663e\u8457\u63d0\u5347\u4e86\u8bb0\u5fc6\u5bb9\u91cf\u548c\u6574\u4f53\u6a21\u578b\u6027\u80fd\u3002\u8fd8\u5f00\u53d1\u4e86\u53cc\u5411\u3001\u9ad8\u6548\u548c\u8109\u51b2\u53d8\u4f53\uff0c\u5206\u522b\u63d0\u4f9b\u989d\u5916\u6027\u80fd\u6216\u80fd\u6548\u4f18\u52bf\u3002", "conclusion": "PDMU\u901a\u8fc7\u95e8\u63a7\u5ef6\u8fdf\u7ebf\u673a\u5236\u6709\u6548\u89e3\u51b3\u4e86\u97f3\u9891\u548c\u751f\u7269\u58f0\u5b66\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u77ed\u671f\u65f6\u95f4\u4fe1\u7528\u5206\u914d\u95ee\u9898\uff0c\u5728\u6570\u636e\u7a00\u7f3a\u73af\u5883\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4e3a\u5b9e\u65f6\u5b66\u4e60\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00468", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00468", "abs": "https://arxiv.org/abs/2512.00468", "authors": ["Tongjia Zhang", "Shu Sun", "Meixia Tao", "Qiuming Zhu", "Ruifeng Gao"], "title": "Diffuse scattering measurements and mechanism analysis at 8, 12, and 28 GHz for typical building surfaces", "comment": null, "summary": "This study investigates the fundamental diffuse scattering mechanisms from three typical building wall surfaces, conducting measurements and model parameterization at 28 GHz and two key FR3 frequencies (8 GHz and 12 GHz). A novel three-dimensional (3D) measurement procedure is proposed to capture comprehensive spatial characteristics, and its effectiveness in improving parameterization accuracy was verified using 28 GHz data. For parameterization, we developed a new method utilizing two dimensions of the high-bandwidth power delay profile-received power and delay spread-thereby fully leveraging the rich information provided by such measurements. Furthermore, we introduce the ER-BK hybrid model, which integrates the Beckmann-Kirchhoff (BK) model's high accuracy and cross-frequency adaptability with the Effective Roughness (ER) model's simplicity, applying it to the building surfaces. Our results show that diffuse scattering at 8 GHz and 12 GHz is highly similar, distinct from that at 28 GHz. A comparison revealed that the BK model provides a better fit for our FR3 measurement data. Crucially, we validated the angular generalization of the parameterized BK model using data from a different incident angle than the one used for fitting. The feasibility of the ER-BK hybrid model was also verified through simulation of the parameterized marble surface.", "AI": {"tldr": "\u8be5\u7814\u7a76\u572828GHz\u548cFR3\u9891\u6bb5\uff088GHz\u300112GHz\uff09\u6d4b\u91cf\u4e86\u4e09\u79cd\u5178\u578b\u5efa\u7b51\u5899\u9762\u7684\u6f2b\u6563\u5c04\u7279\u6027\uff0c\u63d0\u51fa\u4e86\u4e09\u7ef4\u6d4b\u91cf\u65b9\u6cd5\u548cER-BK\u6df7\u5408\u6a21\u578b\uff0c\u9a8c\u8bc1\u4e86BK\u6a21\u578b\u5728FR3\u9891\u6bb5\u7684\u4f18\u8d8a\u62df\u5408\u6027\u80fd\u3002", "motivation": "\u7814\u7a76FR3\u9891\u6bb5\uff088GHz\u548c12GHz\uff09\u5efa\u7b51\u5899\u9762\u6f2b\u6563\u5c04\u7279\u6027\uff0c\u4e3a\u672a\u6765\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u51c6\u786e\u7684\u4fe1\u9053\u6a21\u578b\u53c2\u6570\uff0c\u89e3\u51b3\u9ad8\u9891\u6bb5\u6563\u5c04\u673a\u5236\u4e0d\u660e\u786e\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u4e09\u7ef4\u6d4b\u91cf\u65b9\u6cd5\u6355\u83b7\u7a7a\u95f4\u7279\u6027\uff1b\u5229\u7528\u9ad8\u5e26\u5bbd\u529f\u7387\u5ef6\u8fdf\u5256\u9762\u7684\u63a5\u6536\u529f\u7387\u548c\u65f6\u5ef6\u6269\u5c55\u8fdb\u884c\u53c2\u6570\u5316\uff1b\u5f00\u53d1ER-BK\u6df7\u5408\u6a21\u578b\u7ed3\u5408BK\u6a21\u578b\u7cbe\u5ea6\u548cER\u6a21\u578b\u7b80\u6d01\u6027\u3002", "result": "8GHz\u548c12GHz\u7684\u6f2b\u6563\u5c04\u7279\u6027\u9ad8\u5ea6\u76f8\u4f3c\u4f46\u4e0e28GHz\u660e\u663e\u4e0d\u540c\uff1bBK\u6a21\u578b\u5bf9FR3\u6d4b\u91cf\u6570\u636e\u62df\u5408\u66f4\u597d\uff1b\u9a8c\u8bc1\u4e86\u53c2\u6570\u5316BK\u6a21\u578b\u7684\u89d2\u5411\u6cdb\u5316\u80fd\u529b\uff1bER-BK\u6df7\u5408\u6a21\u578b\u5728\u6a21\u62df\u5927\u7406\u77f3\u8868\u9762\u65f6\u53ef\u884c\u3002", "conclusion": "\u4e09\u7ef4\u6d4b\u91cf\u65b9\u6cd5\u6709\u6548\u63d0\u9ad8\u53c2\u6570\u5316\u7cbe\u5ea6\uff0cBK\u6a21\u578b\u66f4\u9002\u5408FR3\u9891\u6bb5\u5efa\u7b51\u5899\u9762\u6563\u5c04\u5efa\u6a21\uff0cER-BK\u6df7\u5408\u6a21\u578b\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u7cbe\u5ea6\u4e0e\u590d\u6742\u5ea6\u7684\u5e73\u8861\u65b9\u6848\u3002"}}
{"id": "2512.01428", "categories": ["eess.SP", "cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2512.01428", "abs": "https://arxiv.org/abs/2512.01428", "authors": ["Oguz Bedir", "Nurullah Sevim", "Mostafa Ibrahim", "Sabit Ekin"], "title": "Masked Symbol Modeling for Demodulation of Oversampled Baseband Communication Signals in Impulsive Noise-Dominated Channels", "comment": "Accepted to the 39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop on AI and ML for Next-Generation Wireless Communications and Networking (AI4NextG), non-archival", "summary": "Recent breakthroughs in natural language processing show that attention mechanism in Transformer networks, trained via masked-token prediction, enables models to capture the semantic context of the tokens and internalize the grammar of language. While the application of Transformers to communication systems is a burgeoning field, the notion of context within physical waveforms remains under-explored. This paper addresses that gap by re-examining inter-symbol contribution (ISC) caused by pulse-shaping overlap. Rather than treating ISC as a nuisance, we view it as a deterministic source of contextual information embedded in oversampled complex baseband signals. We propose Masked Symbol Modeling (MSM), a framework for the physical (PHY) layer inspired by Bidirectional Encoder Representations from Transformers methodology. In MSM, a subset of symbol aligned samples is randomly masked, and a Transformer predicts the missing symbol identifiers using the surrounding \"in-between\" samples. Through this objective, the model learns the latent syntax of complex baseband waveforms. We illustrate MSM's potential by applying it to the task of demodulating signals corrupted by impulsive noise, where the model infers corrupted segments by leveraging the learned context. Our results suggest a path toward receivers that interpret, rather than merely detect communication signals, opening new avenues for context-aware PHY layer design.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMasked Symbol Modeling (MSM)\u6846\u67b6\uff0c\u5c06Transformer\u7684\u63a9\u7801\u8bed\u8a00\u5efa\u6a21\u601d\u60f3\u5e94\u7528\u4e8e\u7269\u7406\u5c42\u901a\u4fe1\u4fe1\u53f7\u5904\u7406\uff0c\u901a\u8fc7\u9884\u6d4b\u88ab\u63a9\u7801\u7684\u7b26\u53f7\u6765\u5b66\u4e60\u590d\u6742\u57fa\u5e26\u6ce2\u5f62\u7684\u4e0a\u4e0b\u6587\u8bed\u6cd5\u3002", "motivation": "\u867d\u7136Transformer\u5728\u81ea\u7136\u8bed\u8a00\u5904\u7406\u4e2d\u5df2\u6210\u529f\u5229\u7528\u6ce8\u610f\u529b\u673a\u5236\u6355\u6349\u8bed\u4e49\u4e0a\u4e0b\u6587\uff0c\u4f46\u5728\u901a\u4fe1\u7cfb\u7edf\u4e2d\uff0c\u7269\u7406\u6ce2\u5f62\u4e2d\u7684\u4e0a\u4e0b\u6587\u6982\u5ff5\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u8bba\u6587\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u91cd\u65b0\u5ba1\u89c6\u8109\u51b2\u6574\u5f62\u91cd\u53e0\u5f15\u8d77\u7684\u7b26\u53f7\u95f4\u5e72\u6270(ISC)\uff0c\u5c06\u5176\u89c6\u4e3a\u786e\u5b9a\u6027\u4e0a\u4e0b\u6587\u4fe1\u606f\u800c\u975e\u5e72\u6270\u3002", "method": "\u63d0\u51faMasked Symbol Modeling (MSM)\u6846\u67b6\uff0c\u53d7BERT\u65b9\u6cd5\u542f\u53d1\uff0c\u5e94\u7528\u4e8e\u7269\u7406\u5c42\u3002\u968f\u673a\u63a9\u7801\u7b26\u53f7\u5bf9\u9f50\u6837\u672c\u7684\u5b50\u96c6\uff0c\u4f7f\u7528Transformer\u901a\u8fc7\u5468\u56f4\u7684\"\u4e2d\u95f4\"\u6837\u672c\u9884\u6d4b\u7f3a\u5931\u7684\u7b26\u53f7\u6807\u8bc6\u3002\u6a21\u578b\u901a\u8fc7\u8fd9\u4e00\u76ee\u6807\u5b66\u4e60\u590d\u6742\u57fa\u5e26\u6ce2\u5f62\u7684\u6f5c\u5728\u8bed\u6cd5\u3002", "result": "\u5c06MSM\u5e94\u7528\u4e8e\u53d7\u8109\u51b2\u566a\u58f0\u5e72\u6270\u7684\u4fe1\u53f7\u89e3\u8c03\u4efb\u52a1\uff0c\u6a21\u578b\u80fd\u591f\u5229\u7528\u5b66\u4e60\u5230\u7684\u4e0a\u4e0b\u6587\u63a8\u65ad\u53d7\u635f\u6bb5\u3002\u7ed3\u679c\u8868\u660e\u8be5\u65b9\u6cd5\u4e3a\u8bbe\u8ba1\u80fd\u591f\u89e3\u91ca\u800c\u975e\u4ec5\u4ec5\u68c0\u6d4b\u901a\u4fe1\u4fe1\u53f7\u7684\u63a5\u6536\u5668\u63d0\u4f9b\u4e86\u65b0\u8def\u5f84\u3002", "conclusion": "MSM\u6846\u67b6\u4e3a\u7269\u7406\u5c42\u8bbe\u8ba1\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u4f7f\u63a5\u6536\u5668\u80fd\u591f\u89e3\u91ca\u901a\u4fe1\u4fe1\u53f7\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u68c0\u6d4b\u4fe1\u53f7\uff0c\u63a8\u52a8\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u7684\u7269\u7406\u5c42\u8bbe\u8ba1\u53d1\u5c55\u3002"}}
{"id": "2512.00510", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00510", "abs": "https://arxiv.org/abs/2512.00510", "authors": ["H. Nazim Bicer"], "title": "Data-Driven Multi-Emitter Localization Using Spatially Distributed Power Measurements", "comment": "This is a report submitted for 1st year PhD Qualifier. Not Submitted to a conference", "summary": "With more devices competing for limited spectrum, dynamic spectrum sharing is increasingly vulnerable to interference from unauthorized emitters. This motivates fast detection and localization of these emitters using low-cost, distributed sensors that do not require precise time synchronization. This paper presents two convolutional neural network (CNN) approaches for multi-emitter detection and localization from sparsely sampled power maps. The first method performs single-stage prediction of existence probabilities and positions. The alternative two-stage method first estimates an occupancy map as an interpretable intermediate representation and then localizes emitters. A unified training objective combines binary cross entropy with coordinate regression loss and can handle an unknown emitter count. Small footprint networks, on the order of 70\\,k parameters, are trained and evaluated on simulated free-space and urban scenes. Experiments demonstrate that both approaches localize multiple emitters from sparse measurements across diverse environments, with the logits based two-stage variant remaining competitive, and in some cases superior, under extreme sensor sparsity. The findings indicate that small CNNs with a unified objective can be deployed for spectrum monitoring and localization.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e24\u79cd\u57fa\u4e8e\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u7684\u4f4e\u529f\u8017\u5206\u5e03\u5f0f\u4f20\u611f\u5668\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u7a00\u758f\u91c7\u6837\u7684\u529f\u7387\u56fe\u4e2d\u68c0\u6d4b\u548c\u5b9a\u4f4d\u591a\u4e2a\u672a\u6388\u6743\u53d1\u5c04\u6e90\uff0c\u65e0\u9700\u7cbe\u786e\u65f6\u95f4\u540c\u6b65\u3002", "motivation": "\u968f\u7740\u66f4\u591a\u8bbe\u5907\u7ade\u4e89\u6709\u9650\u7684\u9891\u8c31\u8d44\u6e90\uff0c\u52a8\u6001\u9891\u8c31\u5171\u4eab\u8d8a\u6765\u8d8a\u5bb9\u6613\u53d7\u5230\u672a\u6388\u6743\u53d1\u5c04\u6e90\u7684\u5e72\u6270\u3002\u8fd9\u4fc3\u4f7f\u9700\u8981\u5feb\u901f\u68c0\u6d4b\u548c\u5b9a\u4f4d\u8fd9\u4e9b\u53d1\u5c04\u6e90\uff0c\u4f7f\u7528\u4f4e\u6210\u672c\u3001\u5206\u5e03\u5f0f\u4e14\u65e0\u9700\u7cbe\u786e\u65f6\u95f4\u540c\u6b65\u7684\u4f20\u611f\u5668\u3002", "method": "\u63d0\u51fa\u4e86\u4e24\u79cd\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\uff1a1\uff09\u5355\u9636\u6bb5\u65b9\u6cd5\u76f4\u63a5\u9884\u6d4b\u5b58\u5728\u6982\u7387\u548c\u4f4d\u7f6e\uff1b2\uff09\u4e24\u9636\u6bb5\u65b9\u6cd5\u5148\u4f30\u8ba1\u53ef\u89e3\u91ca\u7684\u5360\u7528\u56fe\u4f5c\u4e3a\u4e2d\u95f4\u8868\u793a\uff0c\u518d\u5b9a\u4f4d\u53d1\u5c04\u6e90\u3002\u4f7f\u7528\u7edf\u4e00\u7684\u8bad\u7ec3\u76ee\u6807\u7ed3\u5408\u4e8c\u5143\u4ea4\u53c9\u71b5\u548c\u5750\u6807\u56de\u5f52\u635f\u5931\uff0c\u53ef\u5904\u7406\u672a\u77e5\u6570\u91cf\u7684\u53d1\u5c04\u6e90\u3002\u7f51\u7edc\u53c2\u6570\u7ea670k\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\u4e24\u79cd\u65b9\u6cd5\u90fd\u80fd\u5728\u7a00\u758f\u6d4b\u91cf\u4e0b\u5b9a\u4f4d\u591a\u4e2a\u53d1\u5c04\u6e90\uff0c\u5728\u81ea\u7531\u7a7a\u95f4\u548c\u57ce\u5e02\u573a\u666f\u4e2d\u8868\u73b0\u826f\u597d\u3002\u4e24\u9636\u6bb5\u65b9\u6cd5\u5728\u6781\u7aef\u4f20\u611f\u5668\u7a00\u758f\u60c5\u51b5\u4e0b\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u66f4\u4f18\u3002", "conclusion": "\u7814\u7a76\u8868\u660e\uff0c\u5177\u6709\u7edf\u4e00\u8bad\u7ec3\u76ee\u6807\u7684\u5c0f\u578bCNN\u53ef\u4ee5\u90e8\u7f72\u7528\u4e8e\u9891\u8c31\u76d1\u6d4b\u548c\u5b9a\u4f4d\uff0c\u4e3a\u52a8\u6001\u9891\u8c31\u5171\u4eab\u63d0\u4f9b\u6709\u6548\u7684\u5e72\u6270\u68c0\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00574", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.00574", "abs": "https://arxiv.org/abs/2512.00574", "authors": ["Yiqiao Chen", "Zijian Huang", "Juchi He", "Fazheng Xu", "Zhenghui Feng"], "title": "GCMCG: A Clustering-Aware Graph Attention and Expert Fusion Network for Multi-Paradigm, Multi-task, and Cross-Subject EEG Decoding", "comment": "46 pages, 11 figures", "summary": "Brain-Computer Interfaces (BCIs) based on Motor Execution (ME) and Motor Imagery (MI) electroencephalogram (EEG) signals offer a direct pathway for human-machine interaction. However, developing robust decoding models remains challenging due to the complex spatio-temporal dynamics of EEG, its low signal-to-noise ratio, and the limited generalizability of many existing approaches across subjects and paradigms. To address these issues, this paper proposes Graph-guided Clustering Mixture-of-Experts CNN-GRU (GCMCG), a novel unified framework for MI-ME EEG decoding. Our approach integrates a robust preprocessing stage using Independent Component Analysis and Wavelet Transform (ICA-WT) for effective denoising. We further introduce a pre-trainable graph tokenization module that dynamically models electrode relationships via a Graph Attention Network (GAT), followed by unsupervised spectral clustering to decompose signals into interpretable functional brain regions. Each region is processed by a dedicated CNN-GRU expert network, and a gated fusion mechanism with L1 regularization adaptively combines these local features with a global expert. This Mixture-of-Experts (MoE) design enables deep spatio-temporal fusion and enhances representational capacity. A three-stage training strategy incorporating focal loss and progressive sampling is employed to improve cross-subject generalization and handle class imbalance. Evaluated on three public datasets of varying complexity (EEGmmidb-BCI2000, BCI-IV 2a, and M3CV), GCMCG achieves overall accuracies of 86.60%, 98.57%, and 99.61%, respectively, which demonstrates its superior effectiveness and strong generalization capability for practical BCI applications.", "AI": {"tldr": "\u63d0\u51faGCMCG\u6846\u67b6\uff0c\u6574\u5408ICA-WT\u53bb\u566a\u3001\u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u5efa\u6a21\u7535\u6781\u5173\u7cfb\u3001\u65e0\u76d1\u7763\u8c31\u805a\u7c7b\u5206\u89e3\u8111\u533a\u3001CNN-GRU\u4e13\u5bb6\u7f51\u7edc\u5904\u7406\u5404\u533a\u57df\uff0c\u901a\u8fc7\u95e8\u63a7\u878d\u5408\u673a\u5236\u548cL1\u6b63\u5219\u5316\u5b9e\u73b0\u65f6\u7a7a\u7279\u5f81\u878d\u5408\uff0c\u5728\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u4e0b\u663e\u8457\u63d0\u5347MI-ME EEG\u89e3\u7801\u6027\u80fd\u3002", "motivation": "\u57fa\u4e8e\u8fd0\u52a8\u6267\u884c\u548c\u8fd0\u52a8\u60f3\u8c61EEG\u4fe1\u53f7\u7684\u8111\u673a\u63a5\u53e3\u9762\u4e34\u6311\u6218\uff1aEEG\u4fe1\u53f7\u65f6\u7a7a\u52a8\u6001\u590d\u6742\u3001\u4fe1\u566a\u6bd4\u4f4e\uff0c\u73b0\u6709\u65b9\u6cd5\u8de8\u88ab\u8bd5\u548c\u8de8\u8303\u5f0f\u7684\u6cdb\u5316\u80fd\u529b\u6709\u9650\u3002", "method": "\u63d0\u51faGCMCG\u7edf\u4e00\u6846\u67b6\uff1a1) ICA-WT\u9884\u5904\u7406\u53bb\u566a\uff1b2) \u56fe\u6ce8\u610f\u529b\u7f51\u7edc\u5efa\u6a21\u7535\u6781\u5173\u7cfb\uff0c\u65e0\u76d1\u7763\u8c31\u805a\u7c7b\u5206\u89e3\u529f\u80fd\u8111\u533a\uff1b3) \u5404\u8111\u533a\u7531\u4e13\u7528CNN-GRU\u4e13\u5bb6\u7f51\u7edc\u5904\u7406\uff1b4) \u95e8\u63a7\u878d\u5408\u673a\u5236\u7ed3\u5408L1\u6b63\u5219\u5316\u81ea\u9002\u5e94\u878d\u5408\u5c40\u90e8\u4e0e\u5168\u5c40\u7279\u5f81\uff1b5) \u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff08\u7126\u70b9\u635f\u5931\u3001\u6e10\u8fdb\u91c7\u6837\uff09\u63d0\u5347\u6cdb\u5316\u80fd\u529b\u3002", "result": "\u5728\u4e09\u4e2a\u516c\u5f00\u6570\u636e\u96c6\uff08EEGmmidb-BCI2000\u3001BCI-IV 2a\u3001M3CV\uff09\u4e0a\u5206\u522b\u8fbe\u523086.60%\u300198.57%\u300199.61%\u7684\u603b\u4f53\u51c6\u786e\u7387\uff0c\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u548c\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "GCMCG\u6846\u67b6\u901a\u8fc7\u521b\u65b0\u7684\u56fe\u5f15\u5bfc\u805a\u7c7b\u548c\u6df7\u5408\u4e13\u5bb6\u8bbe\u8ba1\uff0c\u6709\u6548\u89e3\u51b3\u4e86EEG\u89e3\u7801\u4e2d\u7684\u65f6\u7a7a\u52a8\u6001\u5efa\u6a21\u548c\u8de8\u88ab\u8bd5\u6cdb\u5316\u95ee\u9898\uff0c\u4e3a\u5b9e\u9645BCI\u5e94\u7528\u63d0\u4f9b\u4e86\u5f3a\u5927\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.00608", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00608", "abs": "https://arxiv.org/abs/2512.00608", "authors": ["Jacqueline Malayter", "Yingyao Zhou", "Natasha Devroye", "Chih-Chun Wang", "Christopher Brinton", "David J. Love"], "title": "Deep Broadcast Feedback Codes", "comment": null, "summary": "Recent advances in deep learning for wireless communications have renewed interest in channel output feedback codes. In the additive white Gaussian broadcast channel with feedback (AWGN-BC-F), feedback can expand the channel capacity region beyond that of the no-feedback case, but linear analytical codes perform poorly with even small amounts of feedback noise. Deep learning enables the design of nonlinear feedback codes that are more resilient to feedback noise. We extend single-user learned feedback codes for the AWGN channel to the broadcast setting, and compare their performance with existing analytical codes, as well as a newly proposed analytical scheme inspired by the learned schemes. Our results show that, for a fixed code rate, learned codes outperform analytical codes at the same blocklength by using power-efficient nonlinear structures and are more robust to feedback noise. Analytical codes scale more easily to larger blocklengths with perfect feedback and surpass learned codes at higher SNRs.", "AI": {"tldr": "\u6df1\u5ea6\u5b66\u4e60\u53cd\u9988\u7801\u5728AWGN\u5e7f\u64ad\u4fe1\u9053\u4e2d\u6bd4\u4f20\u7edf\u89e3\u6790\u7801\u66f4\u6297\u53cd\u9988\u566a\u58f0\uff0c\u4f46\u89e3\u6790\u7801\u5728\u5b8c\u7f8e\u53cd\u9988\u548c\u5927\u5757\u957f\u65f6\u8868\u73b0\u66f4\u597d", "motivation": "\u65e0\u7ebf\u901a\u4fe1\u4e2d\u7684\u6df1\u5ea6\u5b66\u4e60\u8fdb\u5c55\u91cd\u65b0\u6fc0\u53d1\u4e86\u4fe1\u9053\u8f93\u51fa\u53cd\u9988\u7801\u7684\u7814\u7a76\u5174\u8da3\u3002\u5728AWGN\u5e7f\u64ad\u53cd\u9988\u4fe1\u9053\u4e2d\uff0c\u53cd\u9988\u53ef\u4ee5\u6269\u5c55\u4fe1\u9053\u5bb9\u91cf\u533a\u57df\uff0c\u4f46\u4f20\u7edf\u7ebf\u6027\u89e3\u6790\u7801\u5bf9\u53cd\u9988\u566a\u58f0\u654f\u611f\uff0c\u6027\u80fd\u8f83\u5dee\u3002\u6df1\u5ea6\u5b66\u4e60\u53ef\u4ee5\u8bbe\u8ba1\u66f4\u6297\u53cd\u9988\u566a\u58f0\u7684\u975e\u7ebf\u6027\u53cd\u9988\u7801\u3002", "method": "\u5c06\u5355\u7528\u6237\u5b66\u4e60\u53cd\u9988\u7801\u6269\u5c55\u5230\u5e7f\u64ad\u573a\u666f\uff0c\u5e76\u4e0e\u73b0\u6709\u89e3\u6790\u7801\u4ee5\u53ca\u53d7\u5b66\u4e60\u65b9\u6848\u542f\u53d1\u7684\u65b0\u89e3\u6790\u65b9\u6848\u8fdb\u884c\u6bd4\u8f83\u3002\u5b66\u4e60\u7801\u4f7f\u7528\u529f\u7387\u9ad8\u6548\u7684\u975e\u7ebf\u6027\u7ed3\u6784\u3002", "result": "\u5728\u56fa\u5b9a\u7801\u7387\u4e0b\uff0c\u5b66\u4e60\u7801\u5728\u76f8\u540c\u5757\u957f\u4e0b\u4f18\u4e8e\u89e3\u6790\u7801\uff0c\u5bf9\u53cd\u9988\u566a\u58f0\u66f4\u9c81\u68d2\u3002\u89e3\u6790\u7801\u5728\u5b8c\u7f8e\u53cd\u9988\u4e0b\u66f4\u5bb9\u6613\u6269\u5c55\u5230\u66f4\u5927\u5757\u957f\uff0c\u5728\u9ad8SNR\u4e0b\u8d85\u8d8a\u5b66\u4e60\u7801\u3002", "conclusion": "\u6df1\u5ea6\u5b66\u4e60\u53cd\u9988\u7801\u5728\u5e7f\u64ad\u4fe1\u9053\u4e2d\u8868\u73b0\u51fa\u5bf9\u53cd\u9988\u566a\u58f0\u7684\u66f4\u597d\u9c81\u68d2\u6027\uff0c\u800c\u4f20\u7edf\u89e3\u6790\u7801\u5728\u7406\u60f3\u6761\u4ef6\u4e0b\u4ecd\u6709\u6269\u5c55\u4f18\u52bf\uff0c\u4e24\u8005\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u5404\u6709\u4f18\u52bf\u3002"}}
{"id": "2512.00609", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00609", "abs": "https://arxiv.org/abs/2512.00609", "authors": ["Fernando D. Almeida Garc\u00eda", "Maria C. Luna Alvarado", "Lenin P. Jim\u00e9nez Jim\u00e9nez", "Gustavo Fraidenraich", "Michel D. Yacoub", "Nathaly V. Orozco Garz\u00f3n", "Jos\u00e9 D. Vega-S\u00e1nchez", "Henry R. Carvajal Mora"], "title": "Outage Analysis of TAS-NOMA Systems With Multi-Antenna Users Over \u03b1-\u03bc Fading", "comment": null, "summary": "This paper analyzes the outage performance of downlink NOMA systems with transmit antenna selection (TAS) and multi-antenna users over \u03b1-\u03bc fading. Maximal-ratio combining (MRC) and equal-gain combining (EGC) are considered, with imperfect successive interference cancellation (ipSIC) explicitly modeled. Exact closed-form outage probability (OP) expressions and asymptotic results are derived, offering insights into diversity and coding gains. Simulations validate the analysis, showing that TAS improves the far user's performance and that MRC outperforms EGC. The results also quantify the loss from ipSIC, and highlight the impact of power allocation on joint OP. The proposed framework serves as a unified tool for evaluating TAS-NOMA systems under generalized fading, providing design insights for B5G/6G networks.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u5728\u03b1-\u03bc\u8870\u843d\u4fe1\u9053\u4e0b\uff0c\u91c7\u7528\u53d1\u5c04\u5929\u7ebf\u9009\u62e9(TAS)\u548c\u591a\u5929\u7ebf\u7528\u6237\u7684\u4e0b\u884cNOMA\u7cfb\u7edf\u4e2d\u65ad\u6027\u80fd\uff0c\u8003\u8651\u4e86MRC\u548cEGC\u63a5\u6536\u4ee5\u53ca\u4e0d\u5b8c\u7f8e\u5e72\u6270\u6d88\u9664\uff0c\u63a8\u5bfc\u4e86\u7cbe\u786e\u95ed\u5f0f\u4e2d\u65ad\u6982\u7387\u8868\u8fbe\u5f0f\u548c\u6e10\u8fd1\u7ed3\u679c\u3002", "motivation": "\u4e3aB5G/6G\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u7edf\u4e00\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u5206\u6790TAS-NOMA\u7cfb\u7edf\u5728\u5e7f\u4e49\u8870\u843d\u4fe1\u9053\u4e0b\u7684\u6027\u80fd\uff0c\u91cf\u5316\u4e0d\u5b8c\u7f8e\u5e72\u6270\u6d88\u9664\u7684\u5f71\u54cd\uff0c\u5e76\u7814\u7a76\u529f\u7387\u5206\u914d\u5bf9\u8054\u5408\u4e2d\u65ad\u6982\u7387\u7684\u5f71\u54cd\u3002", "method": "\u91c7\u7528\u53d1\u5c04\u5929\u7ebf\u9009\u62e9(TAS)\u7ed3\u5408\u591a\u5929\u7ebf\u7528\u6237\uff0c\u8003\u8651\u6700\u5927\u6bd4\u5408\u5e76(MRC)\u548c\u7b49\u589e\u76ca\u5408\u5e76(EGC)\u63a5\u6536\u65b9\u6848\uff0c\u663e\u5f0f\u5efa\u6a21\u4e0d\u5b8c\u7f8e\u8fde\u7eed\u5e72\u6270\u6d88\u9664(ipSIC)\uff0c\u63a8\u5bfc\u7cbe\u786e\u95ed\u5f0f\u4e2d\u65ad\u6982\u7387\u8868\u8fbe\u5f0f\u548c\u6e10\u8fd1\u5206\u6790\u3002", "result": "TAS\u6539\u5584\u4e86\u8fdc\u7528\u6237\u6027\u80fd\uff0cMRC\u4f18\u4e8eEGC\uff0c\u91cf\u5316\u4e86ipSIC\u5e26\u6765\u7684\u6027\u80fd\u635f\u5931\uff0c\u529f\u7387\u5206\u914d\u5bf9\u8054\u5408\u4e2d\u65ad\u6982\u7387\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4eff\u771f\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u7684\u6b63\u786e\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u6846\u67b6\u4e3a\u8bc4\u4f30\u5e7f\u4e49\u8870\u843d\u4fe1\u9053\u4e0b\u7684TAS-NOMA\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7edf\u4e00\u5de5\u5177\uff0c\u4e3aB5G/6G\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u89c1\u89e3\uff0c\u7279\u522b\u662f\u5728\u5929\u7ebf\u9009\u62e9\u548c\u63a5\u6536\u5408\u5e76\u7b56\u7565\u65b9\u9762\u3002"}}
{"id": "2512.00653", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.00653", "abs": "https://arxiv.org/abs/2512.00653", "authors": ["Shengchun Yang", "Amit Sravan Bora", "Emil Matus", "Gerhard Fettweis"], "title": "Box Decoding with Low-Complexity Sort-free Candidate Pruning for MIMO Detection", "comment": null, "summary": "Box Decoding is a sort-free tree-search MIMO detector whose complexity does not scale with the QAM order, achieved by searching a fixed candidate \"box\" around a zero-forcing (ZF) estimate. Prior work primarily reports small dimensions (e.g. 2x2), since the search visits an exponentially growing number of nodes as the MIMO order increases when no pruning is applied. This letter introduces three deterministic pruning rules that exploit QAM-grid symmetry and relative displacement between the ZF estimate and the nearby QAM points to eliminate unlikely branches, avoiding metric sorting and reducing full metric distance calculations. Simulations show large complexity savings with only a small impact on error performance. The resulting detector preserves QAM-order independence, scales to larger MIMO sizes, and maps naturally to parallel hardware implementation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6539\u8fdb\u7684Box Decoding MIMO\u68c0\u6d4b\u5668\uff0c\u901a\u8fc7\u4e09\u79cd\u786e\u5b9a\u6027\u526a\u679d\u89c4\u5219\u51cf\u5c11\u641c\u7d22\u590d\u6742\u5ea6\uff0c\u4fdd\u6301QAM\u9636\u6570\u72ec\u7acb\u6027\uff0c\u5e76\u80fd\u6269\u5c55\u5230\u66f4\u5927\u7684MIMO\u7cfb\u7edf\u3002", "motivation": "\u4f20\u7edfBox Decoding\u68c0\u6d4b\u5668\u5728MIMO\u9636\u6570\u589e\u52a0\u65f6\uff0c\u7531\u4e8e\u641c\u7d22\u8282\u70b9\u6570\u6307\u6570\u589e\u957f\uff0c\u4e3b\u8981\u9002\u7528\u4e8e\u5c0f\u7ef4\u5ea6\u7cfb\u7edf\uff08\u59822x2\uff09\u3002\u9700\u8981\u5f00\u53d1\u6709\u6548\u7684\u526a\u679d\u65b9\u6cd5\u6765\u51cf\u5c11\u590d\u6742\u5ea6\uff0c\u4f7f\u5176\u80fd\u6269\u5c55\u5230\u66f4\u5927\u7684MIMO\u7cfb\u7edf\u3002", "method": "\u63d0\u51fa\u4e86\u4e09\u79cd\u786e\u5b9a\u6027\u526a\u679d\u89c4\u5219\uff1a1) \u5229\u7528QAM\u7f51\u683c\u5bf9\u79f0\u6027\uff1b2) \u5229\u7528ZF\u4f30\u8ba1\u4e0e\u9644\u8fd1QAM\u70b9\u4e4b\u95f4\u7684\u76f8\u5bf9\u4f4d\u79fb\uff1b3) \u907f\u514d\u5ea6\u91cf\u6392\u5e8f\u5e76\u51cf\u5c11\u5b8c\u6574\u5ea6\u91cf\u8ddd\u79bb\u8ba1\u7b97\u3002\u8fd9\u4e9b\u89c4\u5219\u6d88\u9664\u4e86\u4e0d\u592a\u53ef\u80fd\u7684\u5206\u652f\u3002", "result": "\u4eff\u771f\u663e\u793a\uff0c\u8be5\u65b9\u6cd5\u5728\u8bef\u5dee\u6027\u80fd\u5f71\u54cd\u5f88\u5c0f\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u4e86\u5927\u5e45\u590d\u6742\u5ea6\u8282\u7701\u3002\u6539\u8fdb\u540e\u7684\u68c0\u6d4b\u5668\u4fdd\u6301\u4e86QAM\u9636\u6570\u72ec\u7acb\u6027\uff0c\u80fd\u6269\u5c55\u5230\u66f4\u5927\u7684MIMO\u5c3a\u5bf8\uff0c\u5e76\u81ea\u7136\u5730\u6620\u5c04\u5230\u5e76\u884c\u786c\u4ef6\u5b9e\u73b0\u3002", "conclusion": "\u63d0\u51fa\u7684\u786e\u5b9a\u6027\u526a\u679d\u89c4\u5219\u6709\u6548\u89e3\u51b3\u4e86Box Decoding\u5728MIMO\u9636\u6570\u589e\u52a0\u65f6\u7684\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u4f7f\u5176\u6210\u4e3a\u9002\u7528\u4e8e\u66f4\u5927MIMO\u7cfb\u7edf\u7684\u5b9e\u7528\u68c0\u6d4b\u5668\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u786c\u4ef6\u53cb\u597d\u7684\u7279\u6027\u3002"}}
{"id": "2512.00655", "categories": ["eess.SP", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.00655", "abs": "https://arxiv.org/abs/2512.00655", "authors": ["Panagiotis Gavriilidis", "George C. Alexandropoulos"], "title": "Sensing-Aided Near-Field Beam Tracking", "comment": "33 pages, 8 figures, 1 table, book chapter to appear", "summary": "The interplay between large antenna apertures and high carrier frequencies in future wireless systems gives rise to near-field communications, where the curvature of spherical wavefronts renders traditional far-field beamforming models inadequate. This chapter addresses the following fundamental questions on near-field operation: (i) What is the maximum distance where far-field approximations remain effective for path gain prediction and beam design? (ii) What level of position resolution is needed for accurate near-field beam focusing? (iii) How frequently must channel state information be updated to maintain highly directive bweamforming in dynamic scenarios? We develop an analytical framework for assessing near-field beamforming gain degradation due to mismatches between the focusing point and the coordinates of a user. Closed-form expressions for beam correlation, beam sensitivity to user movement, and the direction of fastest beamforming gain degradation are derived. A dynamic polar coordinate grid is also proposed for low complexity and adaptive near-field beam search. Furthermore, we introduce the novel concept of beam coherence time, quantifying the temporal robustness of focused beams and enabling proactive sensing-aided beam tracking strategies. The effect of microstrip losses on the preceding derivations is also analyzed. Finally, extensive simulation results validate the presented theoretical analysis and beam tracking method over randomly generated user trajectories.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u8fd1\u573a\u901a\u4fe1\u4e2d\u7684\u5173\u952e\u95ee\u9898\uff1a\u8fdc\u573a\u8fd1\u4f3c\u6709\u6548\u8ddd\u79bb\u3001\u4f4d\u7f6e\u5206\u8fa8\u7387\u9700\u6c42\u3001\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u66f4\u65b0\u9891\u7387\uff0c\u63d0\u51fa\u4e86\u8fd1\u573a\u6ce2\u675f\u6210\u5f62\u589e\u76ca\u5206\u6790\u6846\u67b6\u548c\u52a8\u6001\u6ce2\u675f\u8ddf\u8e2a\u65b9\u6cd5\u3002", "motivation": "\u672a\u6765\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u5927\u5929\u7ebf\u5b54\u5f84\u548c\u9ad8\u8f7d\u9891\u7684\u7ed3\u5408\u5bfc\u81f4\u8fd1\u573a\u901a\u4fe1\u6210\u4e3a\u5fc5\u8981\uff0c\u4f20\u7edf\u7684\u8fdc\u573a\u6ce2\u675f\u6210\u5f62\u6a21\u578b\u5728\u7403\u9762\u6ce2\u524d\u66f2\u7387\u4e0b\u4e0d\u518d\u9002\u7528\u3002\u9700\u8981\u89e3\u51b3\u8fd1\u573a\u64cd\u4f5c\u4e2d\u7684\u4e09\u4e2a\u57fa\u672c\u95ee\u9898\uff1a\u8fdc\u573a\u8fd1\u4f3c\u6709\u6548\u8ddd\u79bb\u3001\u4f4d\u7f6e\u5206\u8fa8\u7387\u9700\u6c42\u3001\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u66f4\u65b0\u9891\u7387\u3002", "method": "\u5f00\u53d1\u4e86\u5206\u6790\u6846\u67b6\u8bc4\u4f30\u8fd1\u573a\u6ce2\u675f\u6210\u5f62\u589e\u76ca\u9000\u5316\uff0c\u63a8\u5bfc\u4e86\u6ce2\u675f\u76f8\u5173\u6027\u3001\u6ce2\u675f\u5bf9\u7528\u6237\u79fb\u52a8\u654f\u611f\u5ea6\u3001\u6700\u5feb\u6ce2\u675f\u6210\u5f62\u589e\u76ca\u9000\u5316\u65b9\u5411\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002\u63d0\u51fa\u4e86\u52a8\u6001\u6781\u5750\u6807\u7f51\u683c\u7528\u4e8e\u4f4e\u590d\u6742\u5ea6\u81ea\u9002\u5e94\u8fd1\u573a\u6ce2\u675f\u641c\u7d22\uff0c\u5f15\u5165\u4e86\u6ce2\u675f\u76f8\u5e72\u65f6\u95f4\u6982\u5ff5\u91cf\u5316\u805a\u7126\u6ce2\u675f\u7684\u65f6\u95f4\u9c81\u68d2\u6027\u3002", "result": "\u901a\u8fc7\u5e7f\u6cdb\u4eff\u771f\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u548c\u6ce2\u675f\u8ddf\u8e2a\u65b9\u6cd5\u5728\u968f\u673a\u751f\u6210\u7528\u6237\u8f68\u8ff9\u4e0a\u7684\u6709\u6548\u6027\u3002\u5206\u6790\u4e86\u5fae\u5e26\u635f\u8017\u5bf9\u63a8\u5bfc\u7ed3\u679c\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u4e3b\u52a8\u611f\u77e5\u8f85\u52a9\u7684\u6ce2\u675f\u8ddf\u8e2a\u7b56\u7565\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u8fd1\u573a\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u7528\u65b9\u6cd5\uff0c\u89e3\u51b3\u4e86\u8fd1\u573a\u6ce2\u675f\u6210\u5f62\u4e2d\u7684\u5173\u952e\u6311\u6218\uff0c\u5305\u62ec\u589e\u76ca\u9000\u5316\u5206\u6790\u3001\u4f4e\u590d\u6742\u5ea6\u6ce2\u675f\u641c\u7d22\u548c\u52a8\u6001\u6ce2\u675f\u8ddf\u8e2a\uff0c\u5bf9\u672a\u6765\u65e0\u7ebf\u7cfb\u7edf\u53d1\u5c55\u5177\u6709\u91cd\u8981\u610f\u4e49\u3002"}}
{"id": "2512.00658", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00658", "abs": "https://arxiv.org/abs/2512.00658", "authors": ["Ahmed A. Al-habob", "Octavia A. Dobre", "Yindi Jing"], "title": "Energy-Efficient Aerial Network Slicing for Computation Offloading, Data Gathering, and Content Delivery", "comment": null, "summary": "This paper introduces an unmanned aerial vehicle (UAV)-enabled network slicing problem to provide content delivery, sensing data gathering, and mobile edge computing (MEC) services. Three tenants provide services to their clients by sharing a common infrastructure of a set of UAVs. The content delivery tenant needs to guarantee that each of its clients (users) receives the required content, the sensing tenant aims to gather an adequate amount of uncorrelated data, and the MEC tenant provides computing service to its clients. An energy consumption minimization framework is considered to meet the tenants' requirements by optimizing the number of deployed UAVs, the deployment location of each UAV, the transmit power of each deployed UAV, the user-UAV association, and the transmission power as well as the computing resources of each UAV. Taking into account the spatial correlation among the sensing users, a subset of these users is activated to gather the required sensing information. A solution approach technique inherited from graph theory is presented, in which the Lagrange approach derives the transmission power and computing resource allocation expressions. Simulation results illustrate that the proposed framework significantly reduces the total energy consumption.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u4eba\u673a\u7f51\u7edc\u5207\u7247\u6846\u67b6\uff0c\u4e3a\u5185\u5bb9\u4ea4\u4ed8\u3001\u4f20\u611f\u6570\u636e\u6536\u96c6\u548c\u79fb\u52a8\u8fb9\u7f18\u8ba1\u7b97\u670d\u52a1\u4f18\u5316\u80fd\u91cf\u6d88\u8017", "motivation": "\u968f\u7740\u65e0\u4eba\u673a\u5728\u591a\u79cd\u670d\u52a1\u4e2d\u7684\u5e94\u7528\u589e\u52a0\uff0c\u9700\u8981\u9ad8\u6548\u7684\u591a\u79df\u6237\u7f51\u7edc\u5207\u7247\u65b9\u6848\u6765\u540c\u65f6\u6ee1\u8db3\u5185\u5bb9\u4ea4\u4ed8\u3001\u6570\u636e\u6536\u96c6\u548c\u8fb9\u7f18\u8ba1\u7b97\u9700\u6c42\uff0c\u540c\u65f6\u6700\u5c0f\u5316\u80fd\u91cf\u6d88\u8017", "method": "\u91c7\u7528\u57fa\u4e8e\u56fe\u8bba\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4f18\u5316\u65e0\u4eba\u673a\u90e8\u7f72\u6570\u91cf\u3001\u4f4d\u7f6e\u3001\u53d1\u5c04\u529f\u7387\u3001\u7528\u6237\u5173\u8054\u3001\u4f20\u8f93\u529f\u7387\u548c\u8ba1\u7b97\u8d44\u6e90\u5206\u914d\uff0c\u8003\u8651\u4f20\u611f\u7528\u6237\u7a7a\u95f4\u76f8\u5173\u6027\u9009\u62e9\u6fc0\u6d3b\u5b50\u96c6", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u6846\u67b6\u663e\u8457\u964d\u4f4e\u4e86\u603b\u80fd\u91cf\u6d88\u8017", "conclusion": "\u63d0\u51fa\u7684\u65e0\u4eba\u673a\u7f51\u7edc\u5207\u7247\u6846\u67b6\u80fd\u591f\u6709\u6548\u534f\u8c03\u591a\u79df\u6237\u670d\u52a1\u9700\u6c42\uff0c\u901a\u8fc7\u4f18\u5316\u8d44\u6e90\u5206\u914d\u663e\u8457\u964d\u4f4e\u7cfb\u7edf\u80fd\u91cf\u6d88\u8017"}}
{"id": "2512.00707", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00707", "abs": "https://arxiv.org/abs/2512.00707", "authors": ["Inocent Calist", "Minseok Kim"], "title": "Bridging FR1 to FR3: Frequency-Continuous Urban Macro/Microcellular Channel Parameterization Anchored at 4.85 GHz", "comment": null, "summary": "The transition from 5G to 6G requires radio channel models that are frequency-continuous across the entire FR1--FR3 span, particularly in the under-explored 4--8 GHz region targeted by WRC-27. Existing 3GPP-style models are often specified at discrete frequencies, introducing discontinuities in large-scale parameters (LSPs) at the 7.125 GHz boundary. To address this, we develop a unified framework anchored by rigorous double-directional measurements at 4.85 GHz in three representative UMa/UMi layouts. We derive route-specific statistics for path loss, delay and angular spreads, K-factor, and spatial consistency using robust distance-binning and bootstrap processing. Subsequently, we construct a log-log frequency-continuous LSP model spanning 4.85 to 28 GHz by anchoring these local statistics to complementary high-frequency datasets. The resulting models ensure smoothness across 7.125 GHz and systematically deviate from 3GPP trends, capturing weaker dispersion in urban macrocells (UMa) and stronger frequency-dependent compaction in urban microcells (UMi). The proposed parameter set fills the measurement gap around 4.85 GHz and provides a practical, implementation-ready basis for wideband 5G/6G simulations, mobility evaluation, and spectrum-planning activities across the FR1--FR3 interface.", "AI": {"tldr": "\u63d0\u51fa\u9891\u7387\u8fde\u7eed\u7684\u7edf\u4e00\u4fe1\u9053\u5efa\u6a21\u6846\u67b6\uff0c\u89e3\u51b35G\u54116G\u8fc7\u6e21\u4e2dFR1-FR3\u9891\u6bb5\uff08\u7279\u522b\u662f4-8GHz\uff09\u7684\u6a21\u578b\u4e0d\u8fde\u7eed\u95ee\u9898\uff0c\u586b\u88654.85GHz\u6d4b\u91cf\u7a7a\u767d\u3002", "motivation": "5G\u54116G\u8fc7\u6e21\u9700\u8981\u8de8FR1-FR3\u9891\u6bb5\u7684\u9891\u7387\u8fde\u7eed\u4fe1\u9053\u6a21\u578b\uff0c\u73b0\u67093GPP\u6a21\u578b\u5728\u79bb\u6563\u9891\u7387\u6307\u5b9a\uff0c\u57287.125GHz\u8fb9\u754c\u5904\u5b58\u5728\u5927\u5c3a\u5ea6\u53c2\u6570\u4e0d\u8fde\u7eed\u95ee\u9898\uff0c\u4e144-8GHz\u533a\u57df\u7f3a\u4e4f\u5145\u5206\u7814\u7a76\u3002", "method": "\u5728\u4e09\u79cd\u5178\u578bUMa/UMi\u573a\u666f\u8fdb\u884c4.85GHz\u53cc\u5b9a\u5411\u6d4b\u91cf\uff0c\u901a\u8fc7\u8ddd\u79bb\u5206\u7bb1\u548cbootstrap\u5904\u7406\u83b7\u53d6\u8def\u5f84\u635f\u8017\u3001\u65f6\u5ef6/\u89d2\u5ea6\u6269\u5c55\u3001K\u56e0\u5b50\u7b49\u7edf\u8ba1\u7279\u6027\uff0c\u7136\u540e\u7ed3\u5408\u9ad8\u9891\u6570\u636e\u96c6\u6784\u5efa4.85-28GHz\u5bf9\u6570-\u5bf9\u6570\u9891\u7387\u8fde\u7eed\u6a21\u578b\u3002", "result": "\u6a21\u578b\u786e\u4fdd\u8de87.125GHz\u7684\u5e73\u6ed1\u6027\uff0c\u4e0e3GPP\u8d8b\u52bf\u5b58\u5728\u7cfb\u7edf\u6027\u504f\u5dee\uff1a\u57ce\u5e02\u5b8f\u5c0f\u533a\uff08UMa\uff09\u8868\u73b0\u51fa\u66f4\u5f31\u7684\u8272\u6563\uff0c\u57ce\u5e02\u5fae\u5c0f\u533a\uff08UMi\uff09\u5448\u73b0\u66f4\u5f3a\u7684\u9891\u7387\u4f9d\u8d56\u6027\u538b\u7f29\u3002\u586b\u8865\u4e864.85GHz\u6d4b\u91cf\u7a7a\u767d\u3002", "conclusion": "\u63d0\u51fa\u7684\u53c2\u6570\u96c6\u4e3a\u5bbd\u5e265G/6G\u4eff\u771f\u3001\u79fb\u52a8\u6027\u8bc4\u4f30\u548c\u9891\u8c31\u89c4\u5212\u63d0\u4f9b\u4e86\u5b9e\u7528\u3001\u53ef\u5b9e\u65bd\u7684\u9891\u7387\u8fde\u7eed\u4fe1\u9053\u5efa\u6a21\u57fa\u7840\uff0c\u652f\u6301WRC-27\u76ee\u6807\u9891\u6bb5\u7684\u7cfb\u7edf\u8bbe\u8ba1\u3002"}}
{"id": "2512.00847", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.00847", "abs": "https://arxiv.org/abs/2512.00847", "authors": ["Xiaokun Teng", "Yanqing Ren", "Weicong Chen", "Wankai Tang", "Xiao Li", "Shi Jin"], "title": "Planar Diffractive Neural Networks Empowered Communications: A Spatial Modulation Scheme", "comment": "submitted to IEEE journals for possible publication", "summary": "Diffractive neural networks, where signal processing is embedded into wave propagation, promise light-speed and energy-efficient computation. However, existing three-dimensional structures, such as stacked intelligent metasurfaces (SIMs), face critical challenges in implementation and integration. In contrast, this work pioneers planar diffractive neural networks (PDNNs) empowered communications, a novel architecture that performs signal processing as signals propagate through artificially designed planar circuits. To demonstrate the capability of PDNN, we propose a PDNN-based space-shift-keying (PDNN-SSK) communication system with a single radio-frequency (RF) chain and a maximum power detector. In this system, PDNNs are deployed at both the transmitter and receiver to jointly execute modulation, beamforming, and detection. We conduct theoretical analyses to provide the maximization condition of correct detection probability and derive the closed-form expression of the symbol error rate (SER) for the proposed system. To approach these theoretical benchmarks, the phase shift parameters of PDNNs are optimized using a surrogate model-based training approach, which effectively navigates the high-dimensional, non-convex optimization landscape. Extensive simulations verify the theoretical analysis framework and uncover fundamental design principles for the PDNN architecture, highlighting its potential to revolutionize RF front-ends by replacing conventional digital baseband modules with this integrable RF computing platform.", "AI": {"tldr": "\u63d0\u51fa\u5e73\u9762\u884d\u5c04\u795e\u7ecf\u7f51\u7edc\u901a\u4fe1\u7cfb\u7edf\uff0c\u7528\u5e73\u9762\u7535\u8def\u5b9e\u73b0\u4fe1\u53f7\u5904\u7406\uff0c\u66ff\u4ee3\u4f20\u7edf\u6570\u5b57\u57fa\u5e26\u6a21\u5757", "motivation": "\u73b0\u6709\u4e09\u7ef4\u884d\u5c04\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\u5b9e\u73b0\u56f0\u96be\uff0c\u9700\u8981\u66f4\u6613\u96c6\u6210\u7684\u65b0\u578b\u67b6\u6784\u6765\u53d1\u6325\u5149\u901f\u3001\u9ad8\u6548\u8ba1\u7b97\u4f18\u52bf", "method": "\u8bbe\u8ba1PDNN-SSK\u901a\u4fe1\u7cfb\u7edf\uff0c\u5728\u6536\u53d1\u7aef\u90e8\u7f72\u5e73\u9762\u884d\u5c04\u795e\u7ecf\u7f51\u7edc\u8054\u5408\u6267\u884c\u8c03\u5236\u3001\u6ce2\u675f\u6210\u5f62\u548c\u68c0\u6d4b\uff0c\u91c7\u7528\u4ee3\u7406\u6a21\u578b\u8bad\u7ec3\u4f18\u5316\u76f8\u4f4d\u53c2\u6570", "result": "\u7406\u8bba\u5206\u6790\u5f97\u5230\u6b63\u786e\u68c0\u6d4b\u6982\u7387\u6700\u5927\u5316\u6761\u4ef6\u548c\u8bef\u7801\u7387\u95ed\u5f0f\u89e3\uff0c\u4eff\u771f\u9a8c\u8bc1\u7406\u8bba\u6846\u67b6\u5e76\u63ed\u793aPDNN\u67b6\u6784\u8bbe\u8ba1\u539f\u5219", "conclusion": "\u5e73\u9762\u884d\u5c04\u795e\u7ecf\u7f51\u7edc\u6709\u6f5c\u529b\u901a\u8fc7\u53ef\u96c6\u6210\u5c04\u9891\u8ba1\u7b97\u5e73\u53f0\u66ff\u4ee3\u4f20\u7edf\u6570\u5b57\u57fa\u5e26\u6a21\u5757\uff0c\u9769\u65b0\u5c04\u9891\u524d\u7aef\u8bbe\u8ba1"}}
{"id": "2512.00898", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.00898", "abs": "https://arxiv.org/abs/2512.00898", "authors": ["R\u0131fat Volkan \u015eenyuva"], "title": "Covariance-Guided DFT Beam Selection for Beamspace ESPRIT in Hybrid mmWave MIMO Receivers", "comment": "22 pages, 7 figures, 1 table", "summary": "We consider direction-of-arrival estimation in hybrid analog/digital mmWave MIMO receivers that employ DFT beamspace processing with a limited number of RF chains. Building on beamspace ESPRIT, we develop a covariance-guided beam selection framework that reconstructs a virtual fully digital subarray, fits a structured signal-plus-noise covariance model, and uses the resulting denoised covariance to select, for each coarse sector, a small contiguous block of DFT beams under a beam-budget constraint. The selected beams feed a sparse beamspace Unitary ESPRIT stage, so that the overall complexity is dominated by a single low-dimensional ESPRIT call while retaining a large effective aperture. Monte Carlo simulations for a 32-element uniform linear array with three paths show that, relative to a standard sectorization-based beam selector built on the same DFT codebook and ESPRIT estimator, the proposed method attains near Cram\u00e9r--Rao bound accuracy at moderate array signal-to-noise ratios, substantially reduces the gap to the bound and the failure rate, and offers favorable accuracy--runtime trade-offs under dynamic RF budgets and sector-edge stress tests.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u534f\u65b9\u5dee\u5f15\u5bfc\u7684\u6ce2\u675f\u9009\u62e9\u6846\u67b6\uff0c\u7528\u4e8e\u6df7\u5408\u6a21\u62df/\u6570\u5b57\u6beb\u7c73\u6ce2MIMO\u63a5\u6536\u673a\u4e2d\u7684DOA\u4f30\u8ba1\uff0c\u901a\u8fc7\u91cd\u6784\u865a\u62df\u5168\u6570\u5b57\u5b50\u9635\u5217\u548c\u7ed3\u6784\u5316\u534f\u65b9\u5dee\u5efa\u6a21\uff0c\u5728\u6ce2\u675f\u9884\u7b97\u7ea6\u675f\u4e0b\u9009\u62e9\u8fde\u7eedDFT\u6ce2\u675f\u5757\uff0c\u5b9e\u73b0\u63a5\u8fd1CRB\u7684\u7cbe\u5ea6\u548c\u826f\u597d\u7684\u7cbe\u5ea6-\u8fd0\u884c\u65f6\u6743\u8861\u3002", "motivation": "\u9488\u5bf9\u6df7\u5408\u6a21\u62df/\u6570\u5b57\u6beb\u7c73\u6ce2MIMO\u63a5\u6536\u673a\u4e2dDFT\u6ce2\u675f\u7a7a\u95f4\u5904\u7406\u65f6RF\u94fe\u6570\u91cf\u6709\u9650\u7684\u95ee\u9898\uff0c\u9700\u8981\u5f00\u53d1\u9ad8\u6548\u7684\u6ce2\u675f\u9009\u62e9\u65b9\u6cd5\u4ee5\u5728\u4fdd\u6301\u5927\u6709\u6548\u5b54\u5f84\u7684\u540c\u65f6\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "method": "\u57fa\u4e8e\u6ce2\u675f\u7a7a\u95f4ESPRIT\uff0c\u5f00\u53d1\u534f\u65b9\u5dee\u5f15\u5bfc\u7684\u6ce2\u675f\u9009\u62e9\u6846\u67b6\uff1a1)\u91cd\u6784\u865a\u62df\u5168\u6570\u5b57\u5b50\u9635\u5217\uff1b2)\u62df\u5408\u7ed3\u6784\u5316\u4fe1\u53f7\u52a0\u566a\u58f0\u534f\u65b9\u5dee\u6a21\u578b\uff1b3)\u4f7f\u7528\u53bb\u566a\u540e\u7684\u534f\u65b9\u5dee\u5728\u6bcf\u4e2a\u7c97\u6247\u533a\u9009\u62e9\u5c0f\u7684\u8fde\u7eedDFT\u6ce2\u675f\u5757\uff08\u53d7\u6ce2\u675f\u9884\u7b97\u7ea6\u675f\uff09\uff1b4)\u5c06\u9009\u4e2d\u7684\u6ce2\u675f\u8f93\u5165\u7a00\u758f\u6ce2\u675f\u7a7a\u95f4Unitary ESPRIT\u9636\u6bb5\u3002", "result": "\u572832\u5143\u7d20\u5747\u5300\u7ebf\u6027\u9635\u5217\u4e09\u8def\u5f84\u7684\u8499\u7279\u5361\u6d1b\u4eff\u771f\u4e2d\uff0c\u76f8\u6bd4\u57fa\u4e8e\u76f8\u540cDFT\u7801\u672c\u548cESPRIT\u4f30\u8ba1\u5668\u7684\u6807\u51c6\u6247\u533a\u5316\u6ce2\u675f\u9009\u62e9\u5668\uff0c\u8be5\u65b9\u6cd5\u5728\u4e2d\u7b49\u9635\u5217\u4fe1\u566a\u6bd4\u4e0b\u8fbe\u5230\u63a5\u8fd1CRB\u7684\u7cbe\u5ea6\uff0c\u663e\u8457\u51cf\u5c0f\u4e0eCRB\u7684\u5dee\u8ddd\u548c\u5931\u8d25\u7387\uff0c\u5728\u52a8\u6001RF\u9884\u7b97\u548c\u6247\u533a\u8fb9\u7f18\u538b\u529b\u6d4b\u8bd5\u4e0b\u63d0\u4f9b\u6709\u5229\u7684\u7cbe\u5ea6-\u8fd0\u884c\u65f6\u6743\u8861\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u534f\u65b9\u5dee\u5f15\u5bfc\u6ce2\u675f\u9009\u62e9\u6846\u67b6\u80fd\u591f\u5728\u6709\u9650RF\u94fe\u7ea6\u675f\u4e0b\uff0c\u901a\u8fc7\u667a\u80fd\u6ce2\u675f\u9009\u62e9\u5b9e\u73b0\u63a5\u8fd1\u6700\u4f18\u7684DOA\u4f30\u8ba1\u6027\u80fd\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u590d\u6742\u5ea6\u4e3b\u8981\u7531\u5355\u4e2a\u4f4e\u7ef4ESPRIT\u8c03\u7528\u4e3b\u5bfc\uff0c\u4e3a\u6df7\u5408\u6a21\u62df/\u6570\u5b57\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.01096", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.01096", "abs": "https://arxiv.org/abs/2512.01096", "authors": ["Fatih Merdan", "Ozgur B. Akan"], "title": "An Acoustic Communication Model in Plants", "comment": "12 pages, 13 figures", "summary": "Molecular communication (MC) studies biological signals that are found in nature. Most MC literature focuses on particle properties, even though many natural phenomena exhibit wave-like behavior. One such signal is sound waves. Understanding how sound waves are used in nature can help us better utilize this signal in our interactions with our environment. To take a step in this direction, in this paper, we examine how plants process incoming sound waves and take informed actions. Indeed, plants respond to sound, yet no quantitative communication-theoretic model currently explains this behavior. This study develops the first end-to-end acoustic communication framework for plants. The model is formed following the biological steps of the incoming signal, and a mathematical description is constructed at each step following basic biological models. The resulting end-to-end communication-theoretic model is analyzed using MATLAB. Simulations show that a $200$ $Hz$, $20$ $mu Pa$ stimulus elevates cytosolic $Ca^{2+}$ from $150$ $nM$ to $230 \\pm 10$ $nM$ within $50$ seconds which can cause root bending in plants in the long run. This work establishes quantitative phytoacoustics, enabling bio-inspired acoustic connections for precision agriculture and plant signaling research.", "AI": {"tldr": "\u8be5\u8bba\u6587\u9996\u6b21\u5efa\u7acb\u4e86\u690d\u7269\u58f0\u5b66\u901a\u4fe1\u7684\u7aef\u5230\u7aef\u5b9a\u91cf\u6a21\u578b\uff0c\u5c55\u793a\u4e86\u690d\u7269\u5982\u4f55\u901a\u8fc7\u58f0\u6ce2\u4fe1\u53f7\u5904\u7406\u5b9e\u73b0\u7ec6\u80de\u54cd\u5e94\uff0c\u4e3a\u7cbe\u51c6\u519c\u4e1a\u548c\u690d\u7269\u4fe1\u53f7\u7814\u7a76\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u3002", "motivation": "\u5206\u5b50\u901a\u4fe1\u7814\u7a76\u901a\u5e38\u5173\u6ce8\u7c92\u5b50\u7279\u6027\uff0c\u4f46\u81ea\u7136\u754c\u4e2d\u8bb8\u591a\u73b0\u8c61\uff08\u5982\u58f0\u6ce2\uff09\u8868\u73b0\u51fa\u6ce2\u52a8\u6027\u3002\u690d\u7269\u5bf9\u58f0\u97f3\u6709\u54cd\u5e94\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u5b9a\u91cf\u901a\u4fe1\u7406\u8bba\u6a21\u578b\u6765\u89e3\u91ca\u8fd9\u4e00\u884c\u4e3a\u3002\u7406\u89e3\u690d\u7269\u5982\u4f55\u5229\u7528\u58f0\u6ce2\u4fe1\u53f7\u6709\u52a9\u4e8e\u6211\u4eec\u66f4\u597d\u5730\u4e0e\u73af\u5883\u4e92\u52a8\u3002", "method": "\u5f00\u53d1\u4e86\u9996\u4e2a\u690d\u7269\u58f0\u5b66\u901a\u4fe1\u7684\u7aef\u5230\u7aef\u6846\u67b6\uff0c\u6309\u7167\u751f\u7269\u4fe1\u53f7\u5904\u7406\u6b65\u9aa4\u6784\u5efa\u6a21\u578b\uff0c\u6bcf\u4e2a\u6b65\u9aa4\u90fd\u57fa\u4e8e\u57fa\u672c\u751f\u7269\u6a21\u578b\u5efa\u7acb\u6570\u5b66\u63cf\u8ff0\uff0c\u5e76\u4f7f\u7528MATLAB\u8fdb\u884c\u5206\u6790\u548c\u4eff\u771f\u3002", "result": "\u4eff\u771f\u663e\u793a\uff0c200 Hz\u300120 \u03bcPa\u7684\u58f0\u523a\u6fc0\u572850\u79d2\u5185\u5c06\u80de\u8d28Ca\u00b2\u207a\u6d53\u5ea6\u4ece150 nM\u63d0\u5347\u5230230\u00b110 nM\uff0c\u957f\u671f\u6765\u770b\u53ef\u5bfc\u81f4\u690d\u7269\u6839\u7cfb\u5f2f\u66f2\u3002\u8fd9\u9a8c\u8bc1\u4e86\u690d\u7269\u58f0\u5b66\u901a\u4fe1\u7684\u53ef\u884c\u6027\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u5efa\u7acb\u4e86\u5b9a\u91cf\u690d\u7269\u58f0\u5b66\uff0c\u4e3a\u7cbe\u51c6\u519c\u4e1a\u548c\u690d\u7269\u4fe1\u53f7\u7814\u7a76\u63d0\u4f9b\u4e86\u751f\u7269\u542f\u53d1\u7684\u58f0\u5b66\u8fde\u63a5\u57fa\u7840\uff0c\u5f00\u542f\u4e86\u690d\u7269\u58f0\u6ce2\u901a\u4fe1\u7684\u5b9a\u91cf\u7814\u7a76\u65b0\u65b9\u5411\u3002"}}
{"id": "2512.01245", "categories": ["eess.SP", "cs.GT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01245", "abs": "https://arxiv.org/abs/2512.01245", "authors": ["Yunchuan Zhang", "Jiechen Chen", "Junshuo Liu", "Robert C. Qiu"], "title": "Bayesian Optimization for Non-Cooperative Game-Based Radio Resource Management", "comment": "6 pages, 4 figures, this paper is accepted to 2025 IEEE Global Communications Conference (Globecom)", "summary": "Radio resource management in modern cellular networks often calls for the optimization of complex utility functions that are potentially conflicting between different base stations (BSs). Coordinating the resource allocation strategies efficiently across BSs to ensure stable network service poses significant challenges, especially when each utility is accessible only via costly, black-box evaluations. This paper considers formulating the resource allocation among spectrum sharing BSs as a non-cooperative game, with the goal of aligning their allocation incentives toward a stable outcome. To address this challenge, we propose PPR-UCB, a novel Bayesian optimization (BO) strategy that learns from sequential decision-evaluation pairs to approximate pure Nash equilibrium (PNE) solutions. PPR-UCB applies martingale techniques to Gaussian process (GP) surrogates and constructs high probability confidence bounds for utilities uncertainty quantification. Experiments on downlink transmission power allocation in a multi-cell multi-antenna system demonstrate the efficiency of PPR-UCB in identifying effective equilibrium solutions within a few data samples.", "AI": {"tldr": "\u63d0\u51faPPR-UCB\u7b97\u6cd5\uff0c\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u9785\u6280\u672f\u89e3\u51b3\u8702\u7a9d\u7f51\u7edc\u4e2d\u57fa\u7ad9\u8d44\u6e90\u5206\u914d\u7684\u975e\u5408\u4f5c\u535a\u5f08\u95ee\u9898\uff0c\u5feb\u901f\u627e\u5230\u7eaf\u7eb3\u4ec0\u5747\u8861\u89e3\u3002", "motivation": "\u73b0\u4ee3\u8702\u7a9d\u7f51\u7edc\u4e2d\u57fa\u7ad9\u95f4\u7684\u8d44\u6e90\u5206\u914d\u9700\u8981\u4f18\u5316\u590d\u6742\u7684\u6548\u7528\u51fd\u6570\uff0c\u8fd9\u4e9b\u51fd\u6570\u53ef\u80fd\u5b58\u5728\u51b2\u7a81\u3002\u7531\u4e8e\u6548\u7528\u51fd\u6570\u53ea\u80fd\u901a\u8fc7\u6602\u8d35\u7684\u9ed1\u76d2\u8bc4\u4f30\u83b7\u5f97\uff0c\u4e14\u9700\u8981\u534f\u8c03\u4e0d\u540c\u57fa\u7ad9\u7684\u5206\u914d\u7b56\u7565\u4ee5\u786e\u4fdd\u7f51\u7edc\u670d\u52a1\u7a33\u5b9a\uff0c\u8fd9\u5e26\u6765\u4e86\u91cd\u5927\u6311\u6218\u3002", "method": "\u5c06\u57fa\u7ad9\u95f4\u7684\u9891\u8c31\u5171\u4eab\u8d44\u6e90\u5206\u914d\u5efa\u6a21\u4e3a\u975e\u5408\u4f5c\u535a\u5f08\uff0c\u63d0\u51faPPR-UCB\u7b97\u6cd5\uff1a1\uff09\u4f7f\u7528\u8d1d\u53f6\u65af\u4f18\u5316\u4ece\u987a\u5e8f\u51b3\u7b56-\u8bc4\u4f30\u5bf9\u4e2d\u5b66\u4e60\uff1b2\uff09\u5e94\u7528\u9785\u6280\u672f\u5230\u9ad8\u65af\u8fc7\u7a0b\u4ee3\u7406\u6a21\u578b\uff1b3\uff09\u6784\u5efa\u9ad8\u6982\u7387\u7f6e\u4fe1\u754c\u8fdb\u884c\u6548\u7528\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u4ee5\u8fd1\u4f3c\u7eaf\u7eb3\u4ec0\u5747\u8861\u89e3\u3002", "result": "\u5728\u591a\u5c0f\u533a\u591a\u5929\u7ebf\u7cfb\u7edf\u7684\u4e0b\u884c\u4f20\u8f93\u529f\u7387\u5206\u914d\u5b9e\u9a8c\u4e2d\uff0cPPR-UCB\u80fd\u591f\u5728\u5c11\u91cf\u6570\u636e\u6837\u672c\u5185\u6709\u6548\u8bc6\u522b\u5747\u8861\u89e3\uff0c\u8bc1\u660e\u4e86\u5176\u9ad8\u6548\u6027\u3002", "conclusion": "PPR-UCB\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u8702\u7a9d\u7f51\u7edc\u4e2d\u57fa\u7ad9\u8d44\u6e90\u5206\u914d\u7684\u975e\u5408\u4f5c\u535a\u5f08\u95ee\u9898\uff0c\u901a\u8fc7\u8d1d\u53f6\u65af\u4f18\u5316\u548c\u9785\u6280\u672f\u5feb\u901f\u627e\u5230\u7a33\u5b9a\u7684\u5747\u8861\u89e3\uff0c\u4e3a\u590d\u6742\u7f51\u7edc\u8d44\u6e90\u7ba1\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.01275", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.01275", "abs": "https://arxiv.org/abs/2512.01275", "authors": ["Tiantian Chu", "Chen Chen", "Jia Ye", "Xin Xiong", "Sihua Shao", "Zhihong Zeng", "Dengke Wang", "Fengli Yang", "Guanjun Xu", "Harald Haas"], "title": "Retroreflective Optical ISAC for 6G: Technologies, Applications and Future Directions", "comment": null, "summary": "Integrated sensing and communication (ISAC) has emerged as a key technological paradigm for sixth generation (6G) mobile networks, aiming to unify sensing and communication in a spectrally efficient and hardware lightweight manner. Radio frequency ISAC (RF-ISAC) is constrained by spectrum crowding, limited sensing resolution, and susceptibility to electromagnetic interference. In contrast, optical ISAC (O-ISAC) leverages the large bandwidth and short wavelength of optical carriers and is regarded as an important complement to RF-ISAC. However, conventional O-ISAC relies on natural optical reflections from target surfaces, which generate weak echoes that are highly dependent on surface materials, thereby limiting the achievable sensing range and sensing accuracy. This article introduces retroreflective optical ISAC (RO-ISAC), which alleviates these limitations by equipping targets with compact retroreflective modules. These modules return incident light approximately back to the source over a useful range of incidence angles, forming a well controlled double pass optical path with strong and stable echoes, and thereby further unlocking the application potential of O-ISAC. The conceptual architecture of RO-ISAC is presented together with the underlying retroreflection mechanism. Key enabling technologies for RO-ISAC systems are discussed, including channel modeling, waveform design, bidirectional transmission, and multi-target sensing and communication, with representative details and experimental validation. The suitability of RO-ISAC is analyzed in indoor, aerial, underwater, and satellite scenarios, and challenges and research directions related to mobility, cooperative networking, intelligent operation, and sustainable deployment are outlined, pointing toward robust and scalable RO-ISAC deployment in future 6G networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u65b0\u578b\u7684\u9006\u5411\u53cd\u5c04\u5149\u5b66\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\uff08RO-ISAC\uff09\u7cfb\u7edf\uff0c\u901a\u8fc7\u5728\u76ee\u6807\u4e0a\u5b89\u88c5\u7d27\u51d1\u7684\u9006\u5411\u53cd\u5c04\u6a21\u5757\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5149\u5b66ISAC\u4f9d\u8d56\u81ea\u7136\u53cd\u5c04\u5bfc\u81f4\u4fe1\u53f7\u5f31\u4e14\u4e0d\u7a33\u5b9a\u7684\u95ee\u9898\uff0c\u4e3a6G\u7f51\u7edc\u63d0\u4f9b\u4e86\u66f4\u5f3a\u5927\u7684\u611f\u77e5\u80fd\u529b\u3002", "motivation": "\u4f20\u7edf\u5c04\u9891ISAC\u9762\u4e34\u9891\u8c31\u62e5\u6324\u3001\u611f\u77e5\u5206\u8fa8\u7387\u6709\u9650\u548c\u6613\u53d7\u7535\u78c1\u5e72\u6270\u7684\u9650\u5236\uff0c\u800c\u5149\u5b66ISAC\u867d\u7136\u5e26\u5bbd\u5927\u3001\u6ce2\u957f\u77ed\uff0c\u4f46\u4f9d\u8d56\u76ee\u6807\u8868\u9762\u7684\u81ea\u7136\u5149\u5b66\u53cd\u5c04\uff0c\u5bfc\u81f4\u56de\u6ce2\u4fe1\u53f7\u5f31\u4e14\u53d7\u8868\u9762\u6750\u6599\u5f71\u54cd\u5927\uff0c\u9650\u5236\u4e86\u611f\u77e5\u8303\u56f4\u548c\u7cbe\u5ea6\u3002", "method": "\u63d0\u51faRO-ISAC\u67b6\u6784\uff0c\u5728\u76ee\u6807\u4e0a\u5b89\u88c5\u7d27\u51d1\u7684\u9006\u5411\u53cd\u5c04\u6a21\u5757\uff0c\u8fd9\u4e9b\u6a21\u5757\u80fd\u5c06\u5165\u5c04\u5149\u8fd1\u4f3c\u539f\u8def\u8fd4\u56de\uff0c\u5f62\u6210\u53d7\u63a7\u7684\u53cc\u7a0b\u5149\u8def\uff0c\u4ea7\u751f\u5f3a\u800c\u7a33\u5b9a\u7684\u56de\u6ce2\u4fe1\u53f7\u3002\u8ba8\u8bba\u4e86\u4fe1\u9053\u5efa\u6a21\u3001\u6ce2\u5f62\u8bbe\u8ba1\u3001\u53cc\u5411\u4f20\u8f93\u548c\u591a\u76ee\u6807\u611f\u77e5\u901a\u4fe1\u7b49\u5173\u952e\u6280\u672f\u3002", "result": "RO-ISAC\u7cfb\u7edf\u80fd\u591f\u4ea7\u751f\u5f3a\u800c\u7a33\u5b9a\u7684\u56de\u6ce2\u4fe1\u53f7\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5149\u5b66ISAC\u7684\u611f\u77e5\u8303\u56f4\u548c\u7cbe\u5ea6\u3002\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u53ef\u884c\u6027\uff0c\u5e76\u5206\u6790\u4e86\u5728\u5ba4\u5185\u3001\u7a7a\u4e2d\u3001\u6c34\u4e0b\u548c\u536b\u661f\u7b49\u591a\u79cd\u573a\u666f\u7684\u9002\u7528\u6027\u3002", "conclusion": "RO-ISAC\u901a\u8fc7\u9006\u5411\u53cd\u5c04\u673a\u5236\u89e3\u51b3\u4e86\u4f20\u7edf\u5149\u5b66ISAC\u7684\u5173\u952e\u9650\u5236\uff0c\u4e3a6G\u7f51\u7edc\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u611f\u77e5\u80fd\u529b\u3002\u672a\u6765\u9700\u8981\u5728\u79fb\u52a8\u6027\u3001\u534f\u4f5c\u7ec4\u7f51\u3001\u667a\u80fd\u64cd\u4f5c\u548c\u53ef\u6301\u7eed\u90e8\u7f72\u7b49\u65b9\u9762\u8fdb\u4e00\u6b65\u7814\u7a76\uff0c\u4ee5\u5b9e\u73b0\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684RO-ISAC\u90e8\u7f72\u3002"}}
{"id": "2512.01294", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01294", "abs": "https://arxiv.org/abs/2512.01294", "authors": ["Song Zhang", "Ruohan Guo", "Xiaohua Ge", "Perter Mahon", "Weixiang Shen"], "title": "Experimental Methods, Health Indicators, and Diagnostic Strategies for Retired Lithium-ion Batteries: A Comprehensive Review", "comment": "Review article; 46 pages, 3 figures, 2 tables", "summary": "Reliable health assessment of retired lithium-ion batteries is essential for safe and economically viable second-life deployment, yet remains difficult due to sparse measurements, incomplete historical records, heterogeneous chemistries, and limited or noisy battery health labels. Conventional laboratory diagnostics, such as full charge-discharge cycling, pulse tests, Electrochemical Impedance Spectroscopy (EIS) measurements, and thermal characterization, provide accurate degradation information but are too time-consuming, equipment-intensive, or condition-sensitive to be applied at scale during retirement-stage sorting, leaving real-world datasets fragmented and inconsistent. This review synthesizes recent advances that address these constraints through physical health indicators, experiment testing methods, data-generation and augmentation techniques, and a spectrum of learning-based modeling routes spanning supervised, semi-supervised, weakly supervised, and unsupervised paradigms. We highlight how minimal-test features, synthetic data, domain-invariant representations, and uncertainty-aware prediction enable robust inference under limited or approximate labels and across mixed chemistries and operating histories. A comparative evaluation further reveals trade-offs in accuracy, interpretability, scalability, and computational burden. Looking forward, progress toward physically constrained generative models, cross-chemistry generalization, calibrated uncertainty estimation, and standardized benchmarks will be crucial for building reliable, scalable, and deployment-ready health prediction tools tailored to the realities of retired-battery applications.", "AI": {"tldr": "\u8be5\u7efc\u8ff0\u603b\u7ed3\u4e86\u9000\u5f79\u9502\u7535\u6c60\u5065\u5eb7\u8bc4\u4f30\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u5305\u62ec\u7269\u7406\u5065\u5eb7\u6307\u6807\u3001\u5b9e\u9a8c\u6d4b\u8bd5\u65b9\u6cd5\u3001\u6570\u636e\u751f\u6210\u589e\u5f3a\u6280\u672f\uff0c\u4ee5\u53ca\u4ece\u76d1\u7763\u5230\u65e0\u76d1\u7763\u7684\u5404\u79cd\u5b66\u4e60\u5efa\u6a21\u65b9\u6cd5\uff0c\u65e8\u5728\u89e3\u51b3\u9000\u5f79\u7535\u6c60\u8bc4\u4f30\u4e2d\u7684\u6d4b\u91cf\u7a00\u758f\u3001\u5386\u53f2\u8bb0\u5f55\u4e0d\u5168\u3001\u5316\u5b66\u4f53\u7cfb\u5f02\u8d28\u7b49\u6311\u6218\u3002", "motivation": "\u9000\u5f79\u9502\u7535\u6c60\u7684\u5065\u5eb7\u8bc4\u4f30\u5bf9\u4e8e\u5b89\u5168\u548c\u7ecf\u6d4e\u53ef\u884c\u7684\u4e8c\u6b21\u5229\u7528\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u6d4b\u91cf\u6570\u636e\u7a00\u758f\u3001\u5386\u53f2\u8bb0\u5f55\u4e0d\u5b8c\u6574\u3001\u5316\u5b66\u4f53\u7cfb\u5f02\u8d28\u6027\u3001\u5065\u5eb7\u6807\u7b7e\u6709\u9650\u6216\u566a\u58f0\u5927\u7b49\u6311\u6218\u3002\u4f20\u7edf\u5b9e\u9a8c\u5ba4\u8bca\u65ad\u65b9\u6cd5\u867d\u7136\u51c6\u786e\u4f46\u8017\u65f6\u8017\u8bbe\u5907\uff0c\u96be\u4ee5\u5728\u9000\u5f79\u9636\u6bb5\u5927\u89c4\u6a21\u5e94\u7528\uff0c\u5bfc\u81f4\u73b0\u5b9e\u6570\u636e\u96c6\u788e\u7247\u5316\u4e14\u4e0d\u4e00\u81f4\u3002", "method": "\u7efc\u8ff0\u4e86\u7269\u7406\u5065\u5eb7\u6307\u6807\u3001\u5b9e\u9a8c\u6d4b\u8bd5\u65b9\u6cd5\u3001\u6570\u636e\u751f\u6210\u4e0e\u589e\u5f3a\u6280\u672f\uff0c\u4ee5\u53ca\u6db5\u76d6\u76d1\u7763\u5b66\u4e60\u3001\u534a\u76d1\u7763\u5b66\u4e60\u3001\u5f31\u76d1\u7763\u5b66\u4e60\u548c\u65e0\u76d1\u7763\u5b66\u4e60\u7b49\u591a\u79cd\u5b66\u4e60\u5efa\u6a21\u65b9\u6cd5\u3002\u7279\u522b\u5173\u6ce8\u6700\u5c0f\u5316\u6d4b\u8bd5\u7279\u5f81\u3001\u5408\u6210\u6570\u636e\u3001\u9886\u57df\u4e0d\u53d8\u8868\u793a\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u9884\u6d4b\u7b49\u6280\u672f\u3002", "result": "\u901a\u8fc7\u6bd4\u8f83\u8bc4\u4f30\u63ed\u793a\u4e86\u4e0d\u540c\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u3001\u53ef\u89e3\u91ca\u6027\u3001\u53ef\u6269\u5c55\u6027\u548c\u8ba1\u7b97\u8d1f\u62c5\u65b9\u9762\u7684\u6743\u8861\u3002\u6700\u5c0f\u5316\u6d4b\u8bd5\u7279\u5f81\u3001\u5408\u6210\u6570\u636e\u3001\u9886\u57df\u4e0d\u53d8\u8868\u793a\u548c\u4e0d\u786e\u5b9a\u6027\u611f\u77e5\u9884\u6d4b\u80fd\u591f\u5728\u6709\u9650\u6216\u8fd1\u4f3c\u6807\u7b7e\u4e0b\u5b9e\u73b0\u9c81\u68d2\u63a8\u7406\uff0c\u5e76\u8de8\u8d8a\u4e0d\u540c\u5316\u5b66\u4f53\u7cfb\u548c\u8fd0\u884c\u5386\u53f2\u3002", "conclusion": "\u672a\u6765\u9700\u8981\u53d1\u5c55\u7269\u7406\u7ea6\u675f\u751f\u6210\u6a21\u578b\u3001\u8de8\u5316\u5b66\u4f53\u7cfb\u6cdb\u5316\u80fd\u529b\u3001\u6821\u51c6\u7684\u4e0d\u786e\u5b9a\u6027\u4f30\u8ba1\u548c\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u8fd9\u5bf9\u4e8e\u6784\u5efa\u53ef\u9760\u3001\u53ef\u6269\u5c55\u4e14\u9002\u5408\u9000\u5f79\u7535\u6c60\u5e94\u7528\u73b0\u5b9e\u7684\u5065\u5eb7\u9884\u6d4b\u5de5\u5177\u81f3\u5173\u91cd\u8981\u3002"}}
{"id": "2512.01386", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.01386", "abs": "https://arxiv.org/abs/2512.01386", "authors": ["Bowen Li", "Haotian Zhang", "Mu Jia", "Junting Chen", "Nikolaos Pappas"], "title": "Joint CFO-Channel Estimation over CFO-Coherent SS Burst Sets for Low-Altitude Radio Mapping", "comment": null, "summary": "Extending terrestrial networks into low-altitude airspace is a practical way to support aerial services, and accurate low-altitude radio maps are essential for characterizing terrestrial base station (BS) coverage and guiding system design. This work targets per-cell per-beam radio mapping from 5G new radio (NR) synchronization signal (SS) burst sets. Conventional processing treats interference as noise and focuses on the strongest link, which is insufficient to comprehensive awareness of the radio environment and ineffective in dense multi-cell low-altitude scenarios. We propose a successive waveform reconstruction and cancellation framework that iteratively estimates, reconstructs, and subtracts the SSs of stronger BSs, thereby enabling reliable detection and estimation of ultra-weak signals. To support this, we introduce the notion of a carrier frequency offset (CFO)-coherent block within which a common-CFO/per-synchronization signal block (SSB)-channel model holds and design a joint CFO-channel estimator that coherently aggregates multiple SSBs within each CFO-coherent block. We further derive closed-form scaling laws that relate estimation accuracy to unmanned aerial vehicle (UAV) speed, motion geometry, burst periodicity, and the length of the CFO-coherent block. Simulations show that the proposed framework can detect and estimate SSs at signal-to-interference-and-noise ratio (SINR) levels down to -30 dB. Field tests at 150 m altitude demonstrate per-beam coverage maps for more than ten overlapping BSs and reveal that, despite strong received power, the measured SINR rarely exceeds 10 dB, underscoring the need for careful interference management in low-altitude airspace.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e5G NR\u540c\u6b65\u4fe1\u53f7\u7684\u8fde\u7eed\u6ce2\u5f62\u91cd\u6784\u4e0e\u6d88\u9664\u6846\u67b6\uff0c\u7528\u4e8e\u4f4e\u7a7a\u591a\u57fa\u7ad9\u5bc6\u96c6\u573a\u666f\u4e0b\u7684\u8d85\u5f31\u4fe1\u53f7\u68c0\u6d4b\u4e0e\u4f30\u8ba1\uff0c\u80fd\u5b9e\u73b0-30dB SINR\u7ea7\u522b\u7684\u4fe1\u53f7\u68c0\u6d4b\u3002", "motivation": "\u5c06\u5730\u9762\u7f51\u7edc\u6269\u5c55\u5230\u4f4e\u7a7a\u7a7a\u57df\u662f\u652f\u6301\u7a7a\u4e2d\u670d\u52a1\u7684\u5b9e\u7528\u65b9\u6cd5\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5c06\u5e72\u6270\u89c6\u4e3a\u566a\u58f0\u5e76\u53ea\u5173\u6ce8\u6700\u5f3a\u94fe\u8def\uff0c\u5728\u5bc6\u96c6\u591a\u57fa\u7ad9\u4f4e\u7a7a\u573a\u666f\u4e2d\u6548\u679c\u4e0d\u4f73\uff0c\u65e0\u6cd5\u5168\u9762\u611f\u77e5\u65e0\u7ebf\u7535\u73af\u5883\u3002", "method": "\u63d0\u51fa\u8fde\u7eed\u6ce2\u5f62\u91cd\u6784\u4e0e\u6d88\u9664\u6846\u67b6\uff0c\u8fed\u4ee3\u4f30\u8ba1\u3001\u91cd\u6784\u5e76\u51cf\u53bb\u8f83\u5f3a\u57fa\u7ad9\u7684\u540c\u6b65\u4fe1\u53f7\uff0c\u4ece\u800c\u5b9e\u73b0\u5bf9\u8d85\u5f31\u4fe1\u53f7\u7684\u53ef\u9760\u68c0\u6d4b\u3002\u5f15\u5165CFO\u76f8\u5e72\u5757\u6982\u5ff5\uff0c\u8bbe\u8ba1\u8054\u5408CFO-\u4fe1\u9053\u4f30\u8ba1\u5668\uff0c\u5e76\u63a8\u5bfc\u4e86\u4f30\u8ba1\u7cbe\u5ea6\u4e0e\u65e0\u4eba\u673a\u901f\u5ea6\u3001\u8fd0\u52a8\u51e0\u4f55\u3001\u7a81\u53d1\u5468\u671f\u6027\u548cCFO\u76f8\u5e72\u5757\u957f\u5ea6\u7684\u95ed\u5f0f\u7f29\u653e\u5b9a\u5f8b\u3002", "result": "\u4eff\u771f\u663e\u793a\u8be5\u6846\u67b6\u80fd\u5728SINR\u4f4e\u81f3-30dB\u65f6\u68c0\u6d4b\u548c\u4f30\u8ba1\u540c\u6b65\u4fe1\u53f7\u3002150\u7c73\u9ad8\u5ea6\u7684\u73b0\u573a\u6d4b\u8bd5\u5c55\u793a\u4e86\u5341\u591a\u4e2a\u91cd\u53e0\u57fa\u7ad9\u7684\u6bcf\u6ce2\u675f\u8986\u76d6\u56fe\uff0c\u5e76\u63ed\u793a\u5c3d\u7ba1\u63a5\u6536\u529f\u7387\u5f3a\uff0c\u4f46\u5b9e\u6d4bSINR\u5f88\u5c11\u8d85\u8fc710dB\uff0c\u7a81\u663e\u4e86\u4f4e\u7a7a\u7a7a\u57df\u9700\u8981\u4ed4\u7ec6\u7684\u5e72\u6270\u7ba1\u7406\u3002", "conclusion": "\u8be5\u8fde\u7eed\u6ce2\u5f62\u91cd\u6784\u4e0e\u6d88\u9664\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u4f4e\u7a7a\u5bc6\u96c6\u591a\u57fa\u7ad9\u573a\u666f\u4e2d\u7684\u5e72\u6270\u95ee\u9898\uff0c\u5b9e\u73b0\u5bf9\u8d85\u5f31\u4fe1\u53f7\u7684\u53ef\u9760\u68c0\u6d4b\uff0c\u4e3a\u4f4e\u7a7a\u65e0\u7ebf\u7535\u73af\u5883\u611f\u77e5\u548c\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u5de5\u5177\u3002"}}
{"id": "2512.01433", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.01433", "abs": "https://arxiv.org/abs/2512.01433", "authors": ["Tristan S. W. Stevens", "Wessel L. van Nierop", "Ben Luijten", "Vincent van de Schaft", "Ois\u00edn Nolan", "Beatrice Federici", "Louis D. van Harten", "Simon W. Penninga", "Noortje I. P. Schueler", "Ruud J. G. van Sloun"], "title": "zea: A Toolbox for Cognitive Ultrasound Imaging", "comment": "10 pages, 3 figures, preprint", "summary": "We present zea (pronounced ze-yah), a Python package for cognitive ultrasound imaging that offers a flexible, modular, and differentiable pipeline for ultrasound data processing. Additionally, it includes a collection of pre-defined models for ultrasound image and signal processing. The toolbox is designed to be easy to use, with a high-level interface that enables users to define custom ultrasound reconstruction pipelines and integrate deep learning models seamlessly. Built on top of Keras 3, it supports all three major deep learning backends: TensorFlow, PyTorch, and JAX, making it straightforward to incorporate custom ultrasound processing pipelines into machine learning workflows. Documentation is available at https://zea.readthedocs.io/.", "AI": {"tldr": "zea\u662f\u4e00\u4e2a\u7528\u4e8e\u8ba4\u77e5\u8d85\u58f0\u6210\u50cf\u7684Python\u5305\uff0c\u63d0\u4f9b\u7075\u6d3b\u3001\u6a21\u5757\u5316\u3001\u53ef\u5fae\u5206\u7684\u8d85\u58f0\u6570\u636e\u5904\u7406\u6d41\u7a0b\uff0c\u5305\u542b\u9884\u5b9a\u4e49\u6a21\u578b\uff0c\u652f\u6301TensorFlow\u3001PyTorch\u548cJAX\u4e09\u5927\u6df1\u5ea6\u5b66\u4e60\u540e\u7aef\u3002", "motivation": "\u4e3a\u8d85\u58f0\u56fe\u50cf\u548c\u4fe1\u53f7\u5904\u7406\u63d0\u4f9b\u4e00\u4e2a\u7075\u6d3b\u3001\u6a21\u5757\u5316\u4e14\u53ef\u5fae\u5206\u7684\u5de5\u5177\u7bb1\uff0c\u7b80\u5316\u8d85\u58f0\u91cd\u5efa\u6d41\u7a0b\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u96c6\u6210\uff0c\u652f\u6301\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u3002", "method": "\u57fa\u4e8eKeras 3\u6784\u5efa\uff0c\u63d0\u4f9b\u9ad8\u7ea7\u63a5\u53e3\u8ba9\u7528\u6237\u5b9a\u4e49\u81ea\u5b9a\u4e49\u8d85\u58f0\u91cd\u5efa\u6d41\u7a0b\uff0c\u5305\u542b\u9884\u5b9a\u4e49\u7684\u8d85\u58f0\u56fe\u50cf\u548c\u4fe1\u53f7\u5904\u7406\u6a21\u578b\uff0c\u652f\u6301TensorFlow\u3001PyTorch\u548cJAX\u4e09\u5927\u540e\u7aef\u3002", "result": "\u5f00\u53d1\u4e86zea Python\u5305\uff0c\u5177\u5907\u7075\u6d3b\u3001\u6a21\u5757\u5316\u3001\u53ef\u5fae\u5206\u7684\u8d85\u58f0\u6570\u636e\u5904\u7406\u80fd\u529b\uff0c\u652f\u6301\u591a\u79cd\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u6587\u6863\u9f50\u5168\uff0c\u6613\u4e8e\u96c6\u6210\u5230\u673a\u5668\u5b66\u4e60\u5de5\u4f5c\u6d41\u4e2d\u3002", "conclusion": "zea\u662f\u4e00\u4e2a\u529f\u80fd\u5f3a\u5927\u7684\u8d85\u58f0\u6210\u50cf\u5de5\u5177\u7bb1\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u591a\u6846\u67b6\u652f\u6301\uff0c\u663e\u8457\u7b80\u5316\u4e86\u8d85\u58f0\u6570\u636e\u5904\u7406\u4e0e\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u7684\u96c6\u6210\uff0c\u4e3a\u8ba4\u77e5\u8d85\u58f0\u6210\u50cf\u7814\u7a76\u63d0\u4f9b\u4e86\u4fbf\u5229\u5de5\u5177\u3002"}}
{"id": "2512.01451", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.01451", "abs": "https://arxiv.org/abs/2512.01451", "authors": ["Zeyao Sun", "Bohao Fan", "Qingyu Liu", "Shuhang Zhang", "Lingyang Song"], "title": "RadioPiT: Radio Map Generation with Pixel Transformer Driven by Ultra-Sparse Real-World Data", "comment": "Accepted by the 30th Asia Pacific Conference on Communications(APCC)", "summary": "As wireless communication networks rapidly evolve, spectrum resources are increasingly scarce, making effective spectrum management critically important. Radio map is a spatial representation of signal characteristics across different locations in a given area, which serves as a key tool for enabling precise spectrum management. To generate accurate radio maps, extensive research efforts have been made. However, most existing studies are conducted on simulation data, which differs significantly from real-world data and cannot accurately reflect the spectrum characteristics of practical environments. To tackle this problem, we construct a dataset of real-world radio map with a self-developed measurement system. Due to the limited volume of real-world data and the distributional discrepancies between simulation and real-world data, we propose a Pixel Transformer (PiT)- based model enhanced with the test-time adaptation (TTA) strategy, named RadioPiT, for real-world radio map generation. Experimental results demonstrate that our proposed RadioPiT significantly outperforms baseline methods in real-world scenarios, yielding a 21.9% decrement in the root mean square error (RMSE) compared to RadioUNet.", "AI": {"tldr": "\u63d0\u51faRadioPiT\u6a21\u578b\uff0c\u7ed3\u5408Pixel Transformer\u548c\u6d4b\u8bd5\u65f6\u9002\u5e94\u7b56\u7565\uff0c\u7528\u4e8e\u751f\u6210\u771f\u5b9e\u4e16\u754c\u65e0\u7ebf\u7535\u5730\u56fe\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u65e0\u7ebf\u901a\u4fe1\u7f51\u7edc\u5feb\u901f\u53d1\u5c55\u5bfc\u81f4\u9891\u8c31\u8d44\u6e90\u65e5\u76ca\u7a00\u7f3a\uff0c\u9700\u8981\u7cbe\u786e\u7684\u9891\u8c31\u7ba1\u7406\u3002\u65e0\u7ebf\u7535\u5730\u56fe\u4f5c\u4e3a\u9891\u8c31\u7ba1\u7406\u7684\u5173\u952e\u5de5\u5177\uff0c\u73b0\u6709\u7814\u7a76\u5927\u591a\u57fa\u4e8e\u4eff\u771f\u6570\u636e\uff0c\u4e0e\u771f\u5b9e\u73af\u5883\u5b58\u5728\u663e\u8457\u5dee\u5f02\uff0c\u65e0\u6cd5\u51c6\u786e\u53cd\u6620\u5b9e\u9645\u9891\u8c31\u7279\u6027\u3002", "method": "\u6784\u5efa\u771f\u5b9e\u4e16\u754c\u65e0\u7ebf\u7535\u5730\u56fe\u6570\u636e\u96c6\uff0c\u63d0\u51fa\u57fa\u4e8ePixel Transformer\u7684RadioPiT\u6a21\u578b\uff0c\u7ed3\u5408\u6d4b\u8bd5\u65f6\u9002\u5e94\u7b56\u7565\u6765\u5904\u7406\u771f\u5b9e\u6570\u636e\u91cf\u6709\u9650\u4ee5\u53ca\u4eff\u771f\u4e0e\u771f\u5b9e\u6570\u636e\u5206\u5e03\u5dee\u5f02\u7684\u95ee\u9898\u3002", "result": "RadioPiT\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u76f8\u6bd4RadioUNet\u5728\u5747\u65b9\u6839\u8bef\u5dee\u4e0a\u964d\u4f4e\u4e8621.9%\u3002", "conclusion": "\u63d0\u51fa\u7684RadioPiT\u6a21\u578b\u80fd\u591f\u6709\u6548\u751f\u6210\u771f\u5b9e\u4e16\u754c\u7684\u65e0\u7ebf\u7535\u5730\u56fe\uff0c\u89e3\u51b3\u4e86\u4eff\u771f\u6570\u636e\u4e0e\u771f\u5b9e\u6570\u636e\u5dee\u5f02\u7684\u95ee\u9898\uff0c\u4e3a\u7cbe\u786e\u9891\u8c31\u7ba1\u7406\u63d0\u4f9b\u4e86\u5b9e\u7528\u5de5\u5177\u3002"}}
{"id": "2512.01542", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.01542", "abs": "https://arxiv.org/abs/2512.01542", "authors": ["Mohammad Soleymani", "Alessio Zappone", "Eduard Jorswieck", "Marco Di Renzo", "Ignacio Santamaria"], "title": "Spectral-Energy Efficiency Tradeoff of Nearly-Passive RIS in MIMO URLLC Downlink: Diagonal vs. Beyond Diagonal", "comment": "Accepted at IEEE Wireless Communications Letters", "summary": "This paper investigates the spectral and energy efficiency (EE) tradeoff of nearly-passive (NP), both locally and globally NP (GNP), reconfigurable intelligent surface (RIS), considering diagonal and beyond-diagonal (BD) implementations in multi-user multiple-input multiple-output (MU-MIMO) broadcast channels designed for ultra-reliable low-latency communication (URLLC). We demonstrate that while all RIS architectures enhance the spectral efficiency, GNP BD-RIS achieves the highest gains. However, its EE is highly sensitive to the static circuit power consumption since BD-RIS has many more circuit elements than diagonal architectures. Furthermore, we demonstrate that the benefits of BD-RIS over diagonal RIS diminish as the number of data streams per user increases due to enhanced channel diversity in MIMO systems.", "AI": {"tldr": "\u7814\u7a76\u8fd1\u65e0\u6e90RIS\u5728MU-MIMO\u5e7f\u64ad\u4fe1\u9053\u4e2d\u7684\u9891\u8c31\u6548\u7387\u548c\u80fd\u91cf\u6548\u7387\u6743\u8861\uff0c\u6bd4\u8f83\u5bf9\u89d2\u548c\u8d85\u5bf9\u89d2\u67b6\u6784\uff0c\u53d1\u73b0GNP BD-RIS\u9891\u8c31\u6548\u7387\u6700\u9ad8\u4f46\u80fd\u91cf\u6548\u7387\u5bf9\u9759\u6001\u529f\u8017\u654f\u611f\uff0c\u4e14\u968f\u7740\u7528\u6237\u6570\u636e\u6d41\u589e\u52a0\u4f18\u52bf\u51cf\u5f31", "motivation": "\u7814\u7a76\u8fd1\u65e0\u6e90\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u5728URLLC\u591a\u7528\u6237MIMO\u5e7f\u64ad\u4fe1\u9053\u4e2d\u7684\u6027\u80fd\uff0c\u7279\u522b\u5173\u6ce8\u4e0d\u540cRIS\u67b6\u6784\uff08\u5bf9\u89d2\u548c\u8d85\u5bf9\u89d2\uff09\u5728\u9891\u8c31\u6548\u7387\u548c\u80fd\u91cf\u6548\u7387\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb", "method": "\u5206\u6790\u8fd1\u65e0\u6e90RIS\uff08\u5305\u62ec\u5c40\u90e8\u548c\u5168\u5c40\u8fd1\u65e0\u6e90\uff09\u5728MU-MIMO\u5e7f\u64ad\u4fe1\u9053\u4e2d\u7684\u6027\u80fd\uff0c\u6bd4\u8f83\u5bf9\u89d2\u548c\u8d85\u5bf9\u89d2RIS\u67b6\u6784\uff0c\u8003\u8651URLLC\u5e94\u7528\u573a\u666f\u4e0b\u7684\u9891\u8c31\u6548\u7387\u548c\u80fd\u91cf\u6548\u7387\u8bc4\u4f30", "result": "\u6240\u6709RIS\u67b6\u6784\u90fd\u80fd\u63d0\u5347\u9891\u8c31\u6548\u7387\uff0c\u5176\u4e2dGNP BD-RIS\u589e\u76ca\u6700\u9ad8\uff1b\u4f46BD-RIS\u7684\u80fd\u91cf\u6548\u7387\u5bf9\u9759\u6001\u7535\u8def\u529f\u8017\u9ad8\u5ea6\u654f\u611f\uff1b\u968f\u7740\u6bcf\u4e2a\u7528\u6237\u6570\u636e\u6d41\u6570\u91cf\u589e\u52a0\uff0cBD-RIS\u76f8\u5bf9\u4e8e\u5bf9\u89d2RIS\u7684\u4f18\u52bf\u51cf\u5f31", "conclusion": "\u8d85\u5bf9\u89d2RIS\u5728\u9891\u8c31\u6548\u7387\u65b9\u9762\u8868\u73b0\u6700\u4f73\uff0c\u4f46\u80fd\u91cf\u6548\u7387\u53d7\u7535\u8def\u529f\u8017\u5f71\u54cd\u8f83\u5927\uff0c\u4e14\u5728MIMO\u7cfb\u7edf\u4fe1\u9053\u591a\u6837\u6027\u589e\u5f3a\u65f6\u4f18\u52bf\u51cf\u5c0f\uff0c\u9700\u8981\u5728\u5177\u4f53\u5e94\u7528\u573a\u666f\u4e2d\u6743\u8861\u9009\u62e9"}}
{"id": "2512.01567", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2512.01567", "abs": "https://arxiv.org/abs/2512.01567", "authors": ["Meng Hua", "Wenjing Zhang", "Chenghong Bian", "Deniz Gunduz"], "title": "In-Context Learning for Deep Joint Source-Channel Coding Over MIMO Channels", "comment": null, "summary": "Large language models have demonstrated the ability to perform \\textit{in-context learning} (ICL), whereby the model performs predictions by directly mapping the query and a few examples from the given task to the output variable. In this paper, we study ICL for deep joint source-channel coding (DeepJSCC) in image transmission over multiple-input multiple-output (MIMO) systems, where an ICL denoiser is employed for MIMO symbol estimation. We first study the transceiver without any hardware impairments and explore the integration of transformer-based ICL with DeepJSCC in both open-loop and closed-loop MIMO systems, depending on the availability of channel state information (CSI) at the transceiver. For both open-loop and closed-loop scenarios, we propose two MIMO transceiver architectures that leverage context information, i.e., pilot sequences and their outputs, as additional inputs, enabling the DeepJSCC encoder, DeepJSCC decoder, and the ICL denoiser to jointly learn encoding, decoding, and estimation strategies tailored to each channel realization. Next, we extend our study to a more challenging scenario where the transceiver suffers from in-phase and quadrature (IQ) imbalance, resulting in nonlinear MIMO estimation. In this case, the context information is also exploited, facilitating joint learning across the DeepJSCC encoder, decoder, and the ICL denoiser under hardware impairments and varying channel conditions. Numerical results demonstrate that the ICL denoiser for MIMO estimation significantly outperforms the conventional least-squares method, with even greater advantages under IQ imbalance. Moreover, the proposed transformer-based ICL framework, integrated with contextual information, achieves significant improvements in end-to-end image reconstruction quality under transceiver IQ imbalance.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u4e0a\u4e0b\u6587\u5b66\u4e60\u7684\u6df1\u5ea6\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\u5728MIMO\u56fe\u50cf\u4f20\u8f93\u4e2d\u7684\u5e94\u7528\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Transformer ICL\u7684MIMO\u6536\u53d1\u5668\u67b6\u6784\uff0c\u5728\u6709\u65e0\u786c\u4ef6\u635f\u4f24\u7684\u60c5\u51b5\u4e0b\u90fd\u80fd\u663e\u8457\u63d0\u5347\u56fe\u50cf\u91cd\u5efa\u8d28\u91cf\u3002", "motivation": "\u5927\u8bed\u8a00\u6a21\u578b\u5c55\u793a\u7684\u4e0a\u4e0b\u6587\u5b66\u4e60\u80fd\u529b\u53ef\u4ee5\u5e94\u7528\u4e8e\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u5c06\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e0e\u6df1\u5ea6\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\u7ed3\u5408\uff0c\u7528\u4e8eMIMO\u7cfb\u7edf\u4e2d\u7684\u56fe\u50cf\u4f20\u8f93\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u786c\u4ef6\u635f\u4f24\uff08\u5982IQ\u4e0d\u5e73\u8861\uff09\u7684\u6311\u6218\u6027\u573a\u666f\u4e0b\u3002", "method": "\u63d0\u51fa\u4e24\u79cdMIMO\u6536\u53d1\u5668\u67b6\u6784\uff1a1\uff09\u5728\u5f00\u73af\u548c\u95ed\u73afMIMO\u7cfb\u7edf\u4e2d\u96c6\u6210Transformer-based ICL\u4e0eDeepJSCC\uff1b2\uff09\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\uff08\u5bfc\u9891\u5e8f\u5217\u53ca\u5176\u8f93\u51fa\uff09\u4f5c\u4e3a\u989d\u5916\u8f93\u5165\uff0c\u4f7fDeepJSCC\u7f16\u7801\u5668\u3001\u89e3\u7801\u5668\u548cICL\u53bb\u566a\u5668\u80fd\u591f\u9488\u5bf9\u6bcf\u4e2a\u4fe1\u9053\u5b9e\u73b0\u8054\u5408\u5b66\u4e60\u7f16\u7801\u3001\u89e3\u7801\u548c\u4f30\u8ba1\u7b56\u7565\uff1b3\uff09\u6269\u5c55\u5230\u5b58\u5728IQ\u4e0d\u5e73\u8861\u7684\u975e\u7ebf\u6027MIMO\u4f30\u8ba1\u573a\u666f\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff1a1\uff09\u7528\u4e8eMIMO\u4f30\u8ba1\u7684ICL\u53bb\u566a\u5668\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u6700\u5c0f\u4e8c\u4e58\u6cd5\uff1b2\uff09\u5728IQ\u4e0d\u5e73\u8861\u60c5\u51b5\u4e0b\u4f18\u52bf\u66f4\u52a0\u660e\u663e\uff1b3\uff09\u63d0\u51fa\u7684\u57fa\u4e8eTransformer\u7684ICL\u6846\u67b6\u7ed3\u5408\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u5728\u6536\u53d1\u5668IQ\u4e0d\u5e73\u8861\u60c5\u51b5\u4e0b\u663e\u8457\u63d0\u5347\u4e86\u7aef\u5230\u7aef\u56fe\u50cf\u91cd\u5efa\u8d28\u91cf\u3002", "conclusion": "\u4e0a\u4e0b\u6587\u5b66\u4e60\u4e0e\u6df1\u5ea6\u8054\u5408\u6e90\u4fe1\u9053\u7f16\u7801\u7684\u7ed3\u5408\u4e3aMIMO\u56fe\u50cf\u4f20\u8f93\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u786c\u4ef6\u635f\u4f24\u7684\u6311\u6218\u6027\u573a\u666f\u4e0b\u3002\u63d0\u51fa\u7684\u6846\u67b6\u901a\u8fc7\u5229\u7528\u4e0a\u4e0b\u6587\u4fe1\u606f\u5b9e\u73b0\u4e86\u7f16\u7801\u3001\u89e3\u7801\u548c\u4f30\u8ba1\u7b56\u7565\u7684\u8054\u5408\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u4e86\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2512.01653", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01653", "abs": "https://arxiv.org/abs/2512.01653", "authors": ["Yiqiao Chen", "Fazheng Xu", "Zijian Huang", "Juchi He", "Zhenghui Feng"], "title": "Cuffless Blood Pressure Estimation from Six Wearable Sensor Modalities in Multi-Motion-State Scenarios", "comment": "13 pages, 7 figures", "summary": "Cardiovascular disease (CVD) is a leading cause of morbidity and mortality worldwide, and sustained hypertension is an often silent risk factor, making cuffless continuous blood pressure (BP) monitoring with wearable devices important for early screening and long-term management. Most existing cuffless BP estimation methods use only photoplethysmography (PPG) and electrocardiography (ECG) signals, alone or in combination. These models are typically developed under resting or quasi-static conditions and struggle to maintain robust accuracy in multi-motion-state scenarios. In this study, we propose a six-modal BP estimation framework that jointly leverages ECG, multi-channel PPG, attachment pressure, sensor temperature, and triaxial acceleration and angular velocity. Each modality is processed by a lightweight branch encoder, contrastive learning enforces cross-modal semantic alignment, and a mixture-of-experts (MoE) regression head adaptively maps the fused features to BP across motion states. Comprehensive experiments on the public Pulse Transit Time PPG Dataset, which includes running, walking, and sitting data from 22 subjects, show that the proposed method achieves mean absolute errors (MAE) of 3.60 mmHg for systolic BP (SBP) and 3.01 mmHg for diastolic BP (DBP). From a clinical perspective, it attains Grade A for SBP, DBP, and mean arterial pressure (MAP) according to the British Hypertension Society (BHS) protocol and meets the numerical criteria of the Association for the Advancement of Medical Instrumentation (AAMI) standard for mean error (ME) and standard deviation of error (SDE).", "AI": {"tldr": "\u63d0\u51fa\u516d\u6a21\u6001\u8840\u538b\u4f30\u8ba1\u6846\u67b6\uff0c\u7ed3\u5408ECG\u3001\u591a\u901a\u9053PPG\u3001\u9644\u7740\u538b\u529b\u3001\u4f20\u611f\u5668\u6e29\u5ea6\u3001\u4e09\u8f74\u52a0\u901f\u5ea6\u548c\u89d2\u901f\u5ea6\uff0c\u5728\u8fd0\u52a8\u72b6\u6001\u4e0b\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u8fde\u7eed\u8840\u538b\u76d1\u6d4b\u3002", "motivation": "\u5fc3\u8840\u7ba1\u75be\u75c5\u662f\u5168\u7403\u4e3b\u8981\u6b7b\u56e0\uff0c\u9ad8\u8840\u538b\u662f\u91cd\u8981\u98ce\u9669\u56e0\u7d20\u3002\u73b0\u6709\u57fa\u4e8ePPG\u548cECG\u7684\u8840\u538b\u76d1\u6d4b\u65b9\u6cd5\u5728\u9759\u6001\u6761\u4ef6\u4e0b\u6709\u6548\uff0c\u4f46\u5728\u591a\u8fd0\u52a8\u72b6\u6001\u4e0b\u7cbe\u5ea6\u4e0d\u8db3\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u516d\u6a21\u6001\u8f93\u5165\uff08ECG\u3001\u591a\u901a\u9053PPG\u3001\u9644\u7740\u538b\u529b\u3001\u4f20\u611f\u5668\u6e29\u5ea6\u3001\u4e09\u8f74\u52a0\u901f\u5ea6\u548c\u89d2\u901f\u5ea6\uff09\uff0c\u6bcf\u4e2a\u6a21\u6001\u901a\u8fc7\u8f7b\u91cf\u7ea7\u5206\u652f\u7f16\u7801\u5668\u5904\u7406\uff0c\u91c7\u7528\u5bf9\u6bd4\u5b66\u4e60\u5b9e\u73b0\u8de8\u6a21\u6001\u8bed\u4e49\u5bf9\u9f50\uff0c\u4f7f\u7528\u6df7\u5408\u4e13\u5bb6\u56de\u5f52\u5934\u81ea\u9002\u5e94\u6620\u5c04\u878d\u5408\u7279\u5f81\u5230\u8840\u538b\u503c\u3002", "result": "\u5728\u5305\u542b22\u540d\u53d7\u8bd5\u8005\u8dd1\u6b65\u3001\u884c\u8d70\u548c\u5750\u59ff\u6570\u636e\u7684\u516c\u5f00\u6570\u636e\u96c6\u4e0a\uff0c\u6536\u7f29\u538bMAE\u4e3a3.60 mmHg\uff0c\u8212\u5f20\u538bMAE\u4e3a3.01 mmHg\u3002\u6839\u636eBHS\u534f\u8bae\u83b7\u5f97SBP\u3001DBP\u548cMAP\u7684A\u7ea7\u8bc4\u7ea7\uff0c\u5e76\u6ee1\u8db3AAMI\u6807\u51c6\u7684\u6570\u503c\u6807\u51c6\u3002", "conclusion": "\u63d0\u51fa\u7684\u516d\u6a21\u6001\u6846\u67b6\u5728\u591a\u8fd0\u52a8\u72b6\u6001\u4e0b\u5b9e\u73b0\u4e86\u4e34\u5e8a\u53ef\u63a5\u53d7\u7684\u8840\u538b\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u4e3a\u53ef\u7a7f\u6234\u8bbe\u5907\u5b9e\u73b0\u65e0\u8896\u5e26\u8fde\u7eed\u8840\u538b\u76d1\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.01750", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.01750", "abs": "https://arxiv.org/abs/2512.01750", "authors": ["Kai Zhang", "Wentao Yu", "Hengtao He", "Shenghui Song", "Jun Zhang", "Khaled B. Letaief"], "title": "Multimodal Mixture-of-Experts for ISAC in Low-Altitude Wireless Networks", "comment": null, "summary": "Integrated sensing and communication (ISAC) is a key enabler for low-altitude wireless networks (LAWNs), providing simultaneous environmental perception and data transmission in complex aerial scenarios. By combining heterogeneous sensing modalities such as visual, radar, lidar, and positional information, multimodal ISAC can improve both situational awareness and robustness of LAWNs. However, most existing multimodal fusion approaches use static fusion strategies that treat all modalities equally and cannot adapt to channel heterogeneity or time-varying modality reliability in dynamic low-altitude environments. To address this fundamental limitation, we propose a mixture-of-experts (MoE) framework for multimodal ISAC in LAWNs. Each modality is processed by a dedicated expert network, and a lightweight gating module adaptively assigns fusion weights according to the instantaneous informativeness and reliability of each modality. To improve scalability under the stringent energy constraints of aerial platforms, we further develop a sparse MoE variant that selectively activates only a subset of experts, thereby reducing computation overhead while preserving the benefits of adaptive fusion. Comprehensive simulations on three typical ISAC tasks in LAWNs demonstrate that the proposed frameworks consistently outperform conventional multimodal fusion baselines in terms of learning performance and training sample efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u4e13\u5bb6\u6df7\u5408\u6846\u67b6\u7684\u591a\u6a21\u6001ISAC\u878d\u5408\u65b9\u6cd5\uff0c\u901a\u8fc7\u8f7b\u91cf\u7ea7\u95e8\u63a7\u6a21\u5757\u81ea\u9002\u5e94\u5206\u914d\u878d\u5408\u6743\u91cd\uff0c\u5e76\u5f00\u53d1\u7a00\u758f\u53d8\u4f53\u4ee5\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\uff0c\u5728LAWNs\u4e2d\u4f18\u4e8e\u4f20\u7edf\u878d\u5408\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u7684\u591a\u6a21\u6001\u878d\u5408\u65b9\u6cd5\u91c7\u7528\u9759\u6001\u878d\u5408\u7b56\u7565\uff0c\u65e0\u6cd5\u9002\u5e94\u4f4e\u7a7a\u52a8\u6001\u73af\u5883\u4e2d\u4fe1\u9053\u5f02\u8d28\u6027\u548c\u6a21\u6001\u53ef\u9760\u6027\u968f\u65f6\u95f4\u53d8\u5316\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86LAWNs\u4e2dISAC\u7cfb\u7edf\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e13\u5bb6\u6df7\u5408\u6846\u67b6\uff1a\u6bcf\u4e2a\u6a21\u6001\u7531\u4e13\u7528\u4e13\u5bb6\u7f51\u7edc\u5904\u7406\uff0c\u8f7b\u91cf\u7ea7\u95e8\u63a7\u6a21\u5757\u6839\u636e\u6a21\u6001\u5373\u65f6\u4fe1\u606f\u91cf\u548c\u53ef\u9760\u6027\u81ea\u9002\u5e94\u5206\u914d\u878d\u5408\u6743\u91cd\u3002\u4e3a\u6ee1\u8db3\u7a7a\u4e2d\u5e73\u53f0\u4e25\u683c\u80fd\u91cf\u7ea6\u675f\uff0c\u5f00\u53d1\u7a00\u758fMoE\u53d8\u4f53\uff0c\u9009\u62e9\u6027\u6fc0\u6d3b\u4e13\u5bb6\u5b50\u96c6\u4ee5\u964d\u4f4e\u8ba1\u7b97\u5f00\u9500\u3002", "result": "\u5728LAWNs\u4e2d\u4e09\u4e2a\u5178\u578bISAC\u4efb\u52a1\u7684\u7efc\u5408\u4eff\u771f\u8868\u660e\uff0c\u6240\u63d0\u6846\u67b6\u5728\u5b66\u4e60\u6027\u80fd\u548c\u8bad\u7ec3\u6837\u672c\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u591a\u6a21\u6001\u878d\u5408\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u81ea\u9002\u5e94\u591a\u6a21\u6001\u878d\u5408\u6846\u67b6\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u4f4e\u7a7a\u52a8\u6001\u73af\u5883\u4e2d\u7684\u4fe1\u9053\u5f02\u8d28\u6027\u548c\u6a21\u6001\u53ef\u9760\u6027\u53d8\u5316\u95ee\u9898\uff0c\u4e3aLAWNs\u4e2d\u7684ISAC\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u4f18\u7684\u6027\u80fd\u548c\u6548\u7387\u3002"}}
{"id": "2512.01778", "categories": ["eess.SP", "cs.IT", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.01778", "abs": "https://arxiv.org/abs/2512.01778", "authors": ["David Nordlund", "Luis Ma\u00dfny", "Antonia Wachter-Zeh", "Erik G. Larsson", "Zheng Chen"], "title": "Secure Over-the-Air Computation Against Multiple Eavesdroppers using Correlated Artificial Noise", "comment": "13 pages, 9 figures, submitted for possible journal publication", "summary": "In the era of the Internet of Things and massive connectivity, many engineering applications, such as sensor fusion and federated edge learning, rely on efficient data aggregation from geographically distributed users over wireless networks. Over-the-air computation shows promising potential for enhancing resource efficiency and scalability in such scenarios by leveraging the superposition property of wireless channels. However, due to the use of uncoded transmission with linear mapping, it also suffers from security vulnerabilities that must be dealt with to allow widespread adoption. In this work, we consider a scenario where multiple cooperating eavesdroppers attempt to infer information about the aggregation result. We derive the optimal joint estimator for the eavesdroppers and provide bounds on the achievable estimation accuracy for both the eavesdroppers and the intended receiver. We show that significant inherent security exists against individual eavesdroppers due to channel misalignment. However, the security level is greatly compromised when the eavesdroppers can cooperate, motivating the need for deliberate security measures. A common measure is to add carefully calibrated perturbation signals (artificial noise) prior to data transmission to improve the security level. To this end, we propose a zero-forced artificial noise design that achieves a high level of security against cooperative eavesdroppers without compromising the aggregation accuracy.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u65e0\u7ebf\u7a7a\u4e2d\u8ba1\u7b97\u7684\u5b89\u5168\u6027\u95ee\u9898\uff0c\u9488\u5bf9\u534f\u4f5c\u7a83\u542c\u8005\u63d0\u51fa\u96f6\u8feb\u4eba\u5de5\u566a\u58f0\u65b9\u6848\uff0c\u5728\u4fdd\u8bc1\u805a\u5408\u7cbe\u5ea6\u7684\u540c\u65f6\u63d0\u5347\u5b89\u5168\u6027\u3002", "motivation": "\u7269\u8054\u7f51\u548c\u5927\u89c4\u6a21\u8fde\u63a5\u65f6\u4ee3\uff0c\u4f20\u611f\u5668\u878d\u5408\u3001\u8054\u90a6\u8fb9\u7f18\u5b66\u4e60\u7b49\u5e94\u7528\u9700\u8981\u4ece\u5730\u7406\u5206\u5e03\u7528\u6237\u9ad8\u6548\u805a\u5408\u6570\u636e\u3002\u7a7a\u4e2d\u8ba1\u7b97\u5229\u7528\u65e0\u7ebf\u4fe1\u9053\u53e0\u52a0\u7279\u6027\u63d0\u9ad8\u8d44\u6e90\u6548\u7387\uff0c\u4f46\u91c7\u7528\u672a\u7f16\u7801\u7ebf\u6027\u6620\u5c04\u4f20\u8f93\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u9700\u8981\u89e3\u51b3\u4ee5\u4fc3\u8fdb\u5e7f\u6cdb\u5e94\u7528\u3002", "method": "\u8003\u8651\u591a\u4e2a\u534f\u4f5c\u7a83\u542c\u8005\u8bd5\u56fe\u63a8\u65ad\u805a\u5408\u7ed3\u679c\u4fe1\u606f\u7684\u573a\u666f\u3002\u63a8\u5bfc\u7a83\u542c\u8005\u7684\u6700\u4f18\u8054\u5408\u4f30\u8ba1\u5668\uff0c\u5206\u6790\u7a83\u542c\u8005\u548c\u9884\u671f\u63a5\u6536\u5668\u7684\u4f30\u8ba1\u7cbe\u5ea6\u754c\u9650\u3002\u9488\u5bf9\u534f\u4f5c\u7a83\u542c\u5a01\u80c1\uff0c\u63d0\u51fa\u96f6\u8feb\u4eba\u5de5\u566a\u58f0\u8bbe\u8ba1\uff0c\u5728\u4e0d\u5f71\u54cd\u805a\u5408\u7cbe\u5ea6\u7684\u524d\u63d0\u4e0b\u63d0\u5347\u5b89\u5168\u6c34\u5e73\u3002", "result": "\u5206\u6790\u8868\u660e\uff0c\u7531\u4e8e\u4fe1\u9053\u5931\u914d\uff0c\u5355\u4e2a\u7a83\u542c\u8005\u9762\u4e34\u663e\u8457\u56fa\u6709\u5b89\u5168\u9650\u5236\u3002\u4f46\u7a83\u542c\u8005\u534f\u4f5c\u4f1a\u4e25\u91cd\u524a\u5f31\u5b89\u5168\u6c34\u5e73\uff0c\u9700\u8981\u4e13\u95e8\u7684\u5b89\u5168\u63aa\u65bd\u3002\u63d0\u51fa\u7684\u96f6\u8feb\u4eba\u5de5\u566a\u58f0\u65b9\u6848\u80fd\u6709\u6548\u5bf9\u6297\u534f\u4f5c\u7a83\u542c\u8005\uff0c\u5b9e\u73b0\u9ad8\u6c34\u5e73\u5b89\u5168\u3002", "conclusion": "\u7a7a\u4e2d\u8ba1\u7b97\u5b58\u5728\u5b89\u5168\u6f0f\u6d1e\uff0c\u7279\u522b\u662f\u9762\u5bf9\u534f\u4f5c\u7a83\u542c\u8005\u65f6\u3002\u63d0\u51fa\u7684\u96f6\u8feb\u4eba\u5de5\u566a\u58f0\u65b9\u6848\u662f\u6709\u6548\u7684\u5b89\u5168\u589e\u5f3a\u63aa\u65bd\uff0c\u80fd\u5728\u4fdd\u6301\u805a\u5408\u7cbe\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u5b89\u5168\u6027\uff0c\u4fc3\u8fdb\u7a7a\u4e2d\u8ba1\u7b97\u5728\u5b89\u5168\u654f\u611f\u5e94\u7528\u4e2d\u7684\u91c7\u7528\u3002"}}
{"id": "2512.01806", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.01806", "abs": "https://arxiv.org/abs/2512.01806", "authors": ["Lise Aabel", "Giuseppe Durisi", "Frida Olofsson", "Erik B\u00f6rjeson", "Mikael Coldrey", "Christian Fager"], "title": "Insights on the Uplink Operation of a 1-bit Radio-Over-Fiber Architecture in Multi-User D-MIMO Communication", "comment": null, "summary": "We consider a distributed multiple-input multiple-output (D-MIMO) testbed in which, to enable coherent-phase transmission without over-the-air synchronization, the remote radio heads (RRHs) are connected to a central unit via a 1-bit radio-over-fiber fronthaul. Specifically, 1-bit samples of the radio-frequency signal are exchanged over the fronthaul. We investigate via both measurements and simulations based on an accurate model of the testbed hardware, the capability of the proposed architecture to provide uniform quality of services over the coverage area--one of the promises of D-MIMO. Our results are encouraging: for the case in which two user equipments (UEs) communicate over the same 75MHz signal bandwidth, the measured error-vector magnitude meets the 3GPP New Radio specification of 12.5\\% for 16QAM across all tested DMIMO scenarios. We also determine that uplink transmission is a potential bottleneck, due to the limited dynamic range of the automatic gain controller, which prevents the 1-bit quantizer to benefit from dithering. We show that this issue can be mitigated via UE power control.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u57fa\u4e8e1\u6bd4\u7279\u5c04\u9891\u4fe1\u53f7\u91c7\u6837\u7684\u5206\u5e03\u5f0fMIMO\u6d4b\u8bd5\u5e73\u53f0\uff0c\u9a8c\u8bc1\u4e86\u8be5\u67b6\u6784\u5728\u65e0\u7a7a\u4e2d\u540c\u6b65\u60c5\u51b5\u4e0b\u5b9e\u73b0\u76f8\u5e72\u76f8\u4f4d\u4f20\u8f93\u7684\u80fd\u529b\uff0c\u6ee1\u8db33GPP NR\u89c4\u8303\u8981\u6c42\uff0c\u5e76\u8bc6\u522b\u4e86\u4e0a\u884c\u94fe\u8def\u52a8\u6001\u8303\u56f4\u9650\u5236\u95ee\u9898\u53ca\u529f\u7387\u63a7\u5236\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u7814\u7a76\u5206\u5e03\u5f0fMIMO\u7cfb\u7edf\u4e2d\uff0c\u901a\u8fc71\u6bd4\u7279\u5c04\u9891\u4fe1\u53f7\u91c7\u6837\u5b9e\u73b0\u65e0\u7a7a\u4e2d\u540c\u6b65\u7684\u76f8\u5e72\u76f8\u4f4d\u4f20\u8f93\uff0c\u9a8c\u8bc1\u8be5\u67b6\u6784\u80fd\u5426\u63d0\u4f9b\u8986\u76d6\u533a\u57df\u5185\u5747\u5300\u7684\u670d\u52a1\u8d28\u91cf\uff0c\u8fd9\u662fD-MIMO\u7684\u6838\u5fc3\u627f\u8bfa\u4e4b\u4e00\u3002", "method": "\u91c7\u7528\u57fa\u4e8e\u6d4b\u8bd5\u5e73\u53f0\u786c\u4ef6\u7684\u7cbe\u786e\u6a21\u578b\u8fdb\u884c\u6d4b\u91cf\u548c\u4eff\u771f\uff0c\u7814\u7a761\u6bd4\u7279\u5c04\u9891\u4fe1\u53f7\u91c7\u6837\u7684\u5206\u5e03\u5f0fMIMO\u67b6\u6784\uff0c\u5206\u6790\u5176\u5728\u65e0\u7a7a\u4e2d\u540c\u6b65\u60c5\u51b5\u4e0b\u5b9e\u73b0\u76f8\u5e72\u76f8\u4f4d\u4f20\u8f93\u7684\u80fd\u529b\u3002", "result": "\u6d4b\u8bd5\u7ed3\u679c\u4ee4\u4eba\u9f13\u821e\uff1a\u5728\u4e24\u4e2a\u7528\u6237\u8bbe\u5907\u5171\u4eab75MHz\u4fe1\u53f7\u5e26\u5bbd\u7684\u60c5\u51b5\u4e0b\uff0c\u6d4b\u91cf\u7684\u8bef\u5dee\u77e2\u91cf\u5e45\u5ea6\u6ee1\u8db33GPP NR\u89c4\u8303\u5bf916QAM\u768412.5%\u8981\u6c42\u3002\u540c\u65f6\u53d1\u73b0\u4e0a\u884c\u94fe\u8def\u56e0\u81ea\u52a8\u589e\u76ca\u63a7\u5236\u5668\u52a8\u6001\u8303\u56f4\u6709\u9650\u800c\u6210\u4e3a\u6f5c\u5728\u74f6\u9888\uff0c\u4f46\u53ef\u901a\u8fc7\u7528\u6237\u8bbe\u5907\u529f\u7387\u63a7\u5236\u7f13\u89e3\u3002", "conclusion": "\u57fa\u4e8e1\u6bd4\u7279\u5c04\u9891\u4fe1\u53f7\u91c7\u6837\u7684\u5206\u5e03\u5f0fMIMO\u67b6\u6784\u80fd\u591f\u5b9e\u73b0\u65e0\u7a7a\u4e2d\u540c\u6b65\u7684\u76f8\u5e72\u76f8\u4f4d\u4f20\u8f93\uff0c\u6ee1\u8db33GPP\u89c4\u8303\u8981\u6c42\uff0c\u4f46\u9700\u8981\u89e3\u51b3\u4e0a\u884c\u94fe\u8def\u52a8\u6001\u8303\u56f4\u9650\u5236\u95ee\u9898\uff0c\u7528\u6237\u8bbe\u5907\u529f\u7387\u63a7\u5236\u662f\u6709\u6548\u7684\u7f13\u89e3\u65b9\u6848\u3002"}}
{"id": "2512.01902", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.01902", "abs": "https://arxiv.org/abs/2512.01902", "authors": ["Hao Luo", "Ahmed Alkhateeb"], "title": "Digital Twin Aided Millimeter Wave MIMO: Site-Specific Beam Codebook Learning", "comment": "6 pages, 6 figures", "summary": "Learning site-specific beams that adapt to the deployment environment, interference sources, and hardware imperfections can lead to noticeable performance gains in coverage, data rate, and power saving, among other interesting advantages. This learning process, however, typically requires a large number of active interactions/iterations, which limits its practical feasibility and leads to excessive overhead. To address these challenges, we propose a digital twin aided codebook learning framework, where a site-specific digital twin is leveraged to generate synthetic channel data for codebook learning. We also propose to learn separate codebooks for line-of-sight and non-line-of-sight users, leveraging the geometric information provided by the digital twin. Simulation results demonstrate that the codebook learned from the digital twin can adapt to the environment geometry and user distribution, leading to high received signal-to-noise ratio performance. Moreover, we identify the ray-tracing accuracy as the most critical factor in digital twin fidelity that impacts the learned codebook performance.", "AI": {"tldr": "\u63d0\u51fa\u6570\u5b57\u5b6a\u751f\u8f85\u52a9\u7684\u7801\u672c\u5b66\u4e60\u6846\u67b6\uff0c\u5229\u7528\u7ad9\u70b9\u7279\u5b9a\u7684\u6570\u5b57\u5b6a\u751f\u751f\u6210\u5408\u6210\u4fe1\u9053\u6570\u636e\u6765\u5b66\u4e60\u81ea\u9002\u5e94\u6ce2\u675f\u8d4b\u5f62\u7801\u672c\uff0c\u51cf\u5c11\u5b9e\u9645\u4ea4\u4e92\u5f00\u9500", "motivation": "\u4f20\u7edf\u7ad9\u70b9\u81ea\u9002\u5e94\u6ce2\u675f\u5b66\u4e60\u9700\u8981\u5927\u91cf\u5b9e\u9645\u4ea4\u4e92\u8fed\u4ee3\uff0c\u5bfc\u81f4\u5f00\u9500\u8fc7\u5927\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u53ef\u884c\u6027", "method": "1) \u5229\u7528\u7ad9\u70b9\u7279\u5b9a\u6570\u5b57\u5b6a\u751f\u751f\u6210\u5408\u6210\u4fe1\u9053\u6570\u636e\u7528\u4e8e\u7801\u672c\u5b66\u4e60\uff1b2) \u57fa\u4e8e\u6570\u5b57\u5b6a\u751f\u63d0\u4f9b\u7684\u51e0\u4f55\u4fe1\u606f\uff0c\u4e3a\u89c6\u8ddd\u548c\u975e\u89c6\u8ddd\u7528\u6237\u5206\u522b\u5b66\u4e60\u7801\u672c", "result": "\u4eff\u771f\u8868\u660e\uff0c\u4ece\u6570\u5b57\u5b6a\u751f\u5b66\u4e60\u7684\u7801\u672c\u80fd\u9002\u5e94\u73af\u5883\u51e0\u4f55\u548c\u7528\u6237\u5206\u5e03\uff0c\u83b7\u5f97\u9ad8\u63a5\u6536\u4fe1\u566a\u6bd4\u6027\u80fd\uff1b\u5149\u7ebf\u8ffd\u8e2a\u7cbe\u5ea6\u662f\u5f71\u54cd\u7801\u672c\u6027\u80fd\u7684\u6700\u5173\u952e\u6570\u5b57\u5b6a\u751f\u4fdd\u771f\u5ea6\u56e0\u7d20", "conclusion": "\u6570\u5b57\u5b6a\u751f\u8f85\u52a9\u7684\u7801\u672c\u5b66\u4e60\u6846\u67b6\u80fd\u6709\u6548\u51cf\u5c11\u5b9e\u9645\u4ea4\u4e92\u5f00\u9500\uff0c\u5b9e\u73b0\u7ad9\u70b9\u81ea\u9002\u5e94\u7684\u6ce2\u675f\u8d4b\u5f62\uff0c\u5149\u7ebf\u8ffd\u8e2a\u7cbe\u5ea6\u5bf9\u6027\u80fd\u81f3\u5173\u91cd\u8981"}}
{"id": "2512.01974", "categories": ["eess.SP", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.01974", "abs": "https://arxiv.org/abs/2512.01974", "authors": ["Keshab K. Parhi"], "title": "The Equivalence of Fast Algorithms for Convolution, Parallel FIR Filters, Polynomial Modular Multiplication, and Pointwise Multiplication in DFT/NTT Domain", "comment": "Proc. 2025 Asilomar conference on Signals, Systems, and Computers", "summary": "Fast time-domain algorithms have been developed in signal processing applications to reduce the multiplication complexity. For example, fast convolution structures using Cook-Toom and Winograd algorithms are well understood. Short length fast convolutions can be iterated to obtain fast convolution structures for long lengths. In this paper, we show that well known fast convolution structures form the basis for design of fast algorithms in four other problem domains: fast parallel filters, fast polynomial modular multiplication, and fast pointwise multiplication in the DFT and NTT domains. Fast polynomial modular multiplication and fast pointwise multiplication problems are important for cryptosystem applications such as post-quantum cryptography and homomorphic encryption. By establishing the equivalence of these problems, we show that a fast structure from one domain can be used to design a fast structure for another domain. This understanding is important as there are many well known solutions for fast convolution that can be used in other signal processing and cryptosystem applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c55\u793a\u4e86\u5feb\u901f\u5377\u79ef\u7ed3\u6784\u53ef\u4f5c\u4e3a\u57fa\u7840\uff0c\u7528\u4e8e\u8bbe\u8ba1\u5176\u4ed6\u56db\u4e2a\u95ee\u9898\u57df\u7684\u5feb\u901f\u7b97\u6cd5\uff1a\u5feb\u901f\u5e76\u884c\u6ee4\u6ce2\u5668\u3001\u5feb\u901f\u591a\u9879\u5f0f\u6a21\u4e58\u3001\u4ee5\u53caDFT\u548cNTT\u57df\u4e2d\u7684\u5feb\u901f\u9010\u70b9\u4e58\u6cd5\u3002", "motivation": "\u5feb\u901f\u5377\u79ef\u7b97\u6cd5\uff08\u5982Cook-Toom\u548cWinograd\u7b97\u6cd5\uff09\u5728\u4fe1\u53f7\u5904\u7406\u4e2d\u5df2\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u4f5c\u8005\u53d1\u73b0\u8fd9\u4e9b\u7ed3\u6784\u53ef\u6269\u5c55\u5230\u5176\u4ed6\u91cd\u8981\u9886\u57df\uff0c\u7279\u522b\u662f\u5bc6\u7801\u5b66\u5e94\u7528\uff08\u5982\u540e\u91cf\u5b50\u5bc6\u7801\u5b66\u548c\u540c\u6001\u52a0\u5bc6\uff09\u4e2d\u7684\u591a\u9879\u5f0f\u6a21\u4e58\u548c\u9010\u70b9\u4e58\u6cd5\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u5efa\u7acb\u5feb\u901f\u5377\u79ef\u4e0e\u5176\u4ed6\u56db\u4e2a\u95ee\u9898\u57df\uff08\u5feb\u901f\u5e76\u884c\u6ee4\u6ce2\u5668\u3001\u5feb\u901f\u591a\u9879\u5f0f\u6a21\u4e58\u3001DFT\u57df\u5feb\u901f\u9010\u70b9\u4e58\u6cd5\u3001NTT\u57df\u5feb\u901f\u9010\u70b9\u4e58\u6cd5\uff09\u4e4b\u95f4\u7684\u7b49\u4ef7\u6027\uff0c\u8bc1\u660e\u4e00\u4e2a\u9886\u57df\u7684\u5feb\u901f\u7ed3\u6784\u53ef\u7528\u4e8e\u8bbe\u8ba1\u53e6\u4e00\u4e2a\u9886\u57df\u7684\u5feb\u901f\u7ed3\u6784\u3002", "result": "\u5c55\u793a\u4e86\u5df2\u77e5\u7684\u5feb\u901f\u5377\u79ef\u89e3\u51b3\u65b9\u6848\u53ef\u5e94\u7528\u4e8e\u4fe1\u53f7\u5904\u7406\u548c\u5bc6\u7801\u7cfb\u7edf\u5e94\u7528\u4e2d\u7684\u5176\u4ed6\u95ee\u9898\u57df\uff0c\u4e3a\u8fd9\u4e9b\u9886\u57df\u63d0\u4f9b\u4e86\u65b0\u7684\u5feb\u901f\u7b97\u6cd5\u8bbe\u8ba1\u65b9\u6cd5\u3002", "conclusion": "\u5feb\u901f\u5377\u79ef\u7ed3\u6784\u4e3a\u591a\u4e2a\u95ee\u9898\u57df\u63d0\u4f9b\u4e86\u7edf\u4e00\u7684\u7b97\u6cd5\u8bbe\u8ba1\u57fa\u7840\uff0c\u8fd9\u4e00\u7406\u89e3\u5177\u6709\u91cd\u8981\u610f\u4e49\uff0c\u56e0\u4e3a\u8bb8\u591a\u5df2\u77e5\u7684\u5feb\u901f\u5377\u79ef\u89e3\u51b3\u65b9\u6848\u53ef\u7528\u4e8e\u5176\u4ed6\u4fe1\u53f7\u5904\u7406\u548c\u5bc6\u7801\u7cfb\u7edf\u5e94\u7528\u3002"}}

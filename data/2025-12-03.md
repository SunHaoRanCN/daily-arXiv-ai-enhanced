<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 16]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.SD](#cs.SD) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [DySTAN: Joint Modeling of Sedentary Activity and Social Context from Smartphone Sensors](https://arxiv.org/abs/2512.02025)
*Aditya Sneh,Nilesh Kumar Sahu,Snehil Gupta,Haroon R. Lone*

Main category: eess.SP

TL;DR: LogMe应用收集智能手机传感器数据和用户自我报告，DySTAN多任务学习框架联合分类久坐活动和社会情境，显著提升识别准确率。


<details>
  <summary>Details</summary>
Motivation: 现有移动感知研究在识别久坐活动（如学习、听课、放松、进食）时面临挑战，这些活动具有高度相似的惯性模式。此外，社会情境对理解用户行为至关重要，但在移动感知研究中常被忽视。

Method: 开发LogMe移动感知应用，被动收集智能手机传感器数据（加速度计、陀螺仪、磁力计、旋转矢量），并每小时提示用户自我报告久坐活动和社会情境。提出DySTAN（动态交叉缝合任务注意力网络），这是一个多任务学习框架，通过任务特定层和跨任务注意力机制，从共享传感器输入中联合分类两个情境维度。

Result: DySTAN将久坐活动的宏观F1分数比单任务CNN-BiLSTM-GRU模型提高了21.8%，比最强的多任务基线Sluice Network提高了8.2%。

Conclusion: 建模多个共现的情境维度对于提高移动情境识别的准确性和鲁棒性至关重要。DySTAN框架有效解决了久坐活动识别和社会情境建模的挑战。

Abstract: Accurately recognizing human context from smartphone sensor data remains a significant challenge, especially in sedentary settings where activities such as studying, attending lectures, relaxing, and eating exhibit highly similar inertial patterns. Furthermore, social context plays a critical role in understanding user behavior, yet is often overlooked in mobile sensing research. To address these gaps, we introduce LogMe, a mobile sensing application that passively collects smartphone sensor data (accelerometer, gyroscope, magnetometer, and rotation vector) and prompts users for hourly self-reports capturing both sedentary activity and social context. Using this dual-label dataset, we propose DySTAN (Dynamic Cross-Stitch with Task Attention Network), a multi-task learning framework that jointly classifies both context dimensions from shared sensor inputs. It integrates task-specific layers with cross-task attention to model subtle distinctions effectively. DySTAN improves sedentary activity macro F1 scores by 21.8% over a single-task CNN-BiLSTM-GRU (CBG) model and by 8.2% over the strongest multi-task baseline, Sluice Network (SN). These results demonstrate the importance of modeling multiple, co-occurring context dimensions to improve the accuracy and robustness of mobile context recognition.

</details>


### [2] [Towards Sustainable Precision: Machine Learning for Laser Micromachining Optimization](https://arxiv.org/abs/2512.02026)
*Luis Correas-Naranjo,Miguel Camacho-Sánchez,Laëtitia Launet,Milena Zuric,Valery Naranjo*

Main category: eess.SP

TL;DR: 提出一个机器学习框架，用于超短脉冲激光微加工的表面质量评估，通过优化计算需求实现实时监测


<details>
  <summary>Details</summary>
Motivation: 超短脉冲激光微加工在可持续制造中具有潜力，但需要优化的监测系统来早期检测缺陷工件。现有机器学习方法虽然能预测工艺质量特征，但监测数据复杂，需要减少模型大小和数据维度以实现实时分析。

Method: 引入一个机器学习框架，旨在优化机器学习模型的计算需求，以促进实时激光加工监测。

Result: 实验结果表明，所提出的模型不仅在不同预处理技术上的泛化能力优于先前工作，而且显著减少了训练的计算需求。

Conclusion: 通过这些进展，旨在为更可持续的制造过程建立基准。

Abstract: In the pursuit of sustainable manufacturing, ultra-short pulse laser micromachining stands out as a promising solution while also offering high-precision and qualitative laser processing. However, unlocking the full potential of ultra-short pulse lasers requires an optimized monitoring system capable of early detection of defective workpieces, regardless of the preprocessing technique employed. While advances in machine learning can help predict process quality features, the complexity of monitoring data necessitates reducing both model size and data dimensionality to enable real-time analysis. To address these challenges, this paper introduces a machine learning framework designed to enhance surface quality assessment across diverse preprocessing techniques. To facilitate real-time laser processing monitoring, our solution aims to optimize the computational requirements of the machine learning model. Experimental results show that the proposed model not only outperforms the generalizability achieved by previous works across diverse preprocessing techniques but also significantly reduces the computational requirements for training. Through these advancements, we aim to establish the baseline for a more sustainable manufacturing process.

</details>


### [3] [Seizure-NGCLNet: Representation Learning of SEEG Spatial Pathological Patterns for Epileptic Seizure Detection via Node-Graph Dual Contrastive Learning](https://arxiv.org/abs/2512.02028)
*Yiping Wang,Peiren Wang,Zhenye Li,Fang Liu,Jinguo Huang*

Main category: eess.SP

TL;DR: 提出Seizure-NGCLNet，一种节点-图双重对比学习框架，用于从立体脑电图(SEEG)中学习癫痫发作相关的大脑网络模式，提高耐药性癫痫发作检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 耐药性癫痫(DRE)的复杂空间连接模式（如发作间期抑制和发作期传播）使得使用传统机器学习方法进行癫痫发作检测变得困难。主要挑战包括：1）功能连接估计的信噪比低，难以学习发作相关交互；2）专家标注的空间病理连接模式难以获取，且缺乏这些模式的表示来改善发作检测。

Method: 提出节点-图双重对比学习框架Seizure-NGCLNet：1）基于中心性度量的自适应图增强策略生成癫痫相关大脑网络；2）集成双重对比学习方法，结合全局图级对比和局部节点-图对比，编码空间结构和语义致痫特征；3）通过top-k局部图注意力网络微调预训练嵌入进行最终分类。

Result: 在33名DRE患者的大规模公共SEEG数据集上，Seizure-NGCLNet达到最先进性能：平均准确率95.93%，灵敏度96.25%，特异性94.12%。可视化显示学习到的嵌入能清晰区分发作期和发作间期状态，反映了与临床机制对应的抑制和传播模式。

Conclusion: Seizure-NGCLNet能够学习可解释的空间病理模式，不仅提高了癫痫发作检测性能，还有助于癫痫发作起始区的定位，为耐药性癫痫的精准诊断提供了有效工具。

Abstract: Complex spatial connectivity patterns, such as interictal suppression and ictal propagation, complicate accurate drug-resistant epilepsy (DRE) seizure detection using stereotactic electroencephalography (SEEG) and traditional machine learning methods. Two critical challenges remain:(1)a low signal-to-noise ratio in functional connectivity estimates, making it difficult to learn seizure-related interactions; and (2)expert labels for spatial pathological connectivity patterns are difficult to obtain, meanwhile lacking the patterns' representation to improve seizure detection. To address these issues, we propose a novel node-graph dual contrastive learning framework, Seizure-NGCLNet, to learn SEEG interictal suppression and ictal propagation patterns for detecting DRE seizures with high precision. First, an adaptive graph augmentation strategy guided by centrality metrics is developed to generate seizure-related brain networks. Second, a dual-contrastive learning approach is integrated, combining global graph-level contrast with local node-graph contrast, to encode both spatial structural and semantic epileptogenic features. Third, the pretrained embeddings are fine-tuned via a top-k localized graph attention network to perform the final classification. Extensive experiments on a large-scale public SEEG dataset from 33 DRE patients demonstrate that Seizure-NGCLNet achieves state-of-the-art performance, with an average accuracy of 95.93%, sensitivity of 96.25%, and specificity of 94.12%. Visualizations confirm that the learned embeddings clearly separate ictal from interictal states, reflecting suppression and propagation patterns that correspond to the clinical mechanisms. These results highlight Seizure-NGCLNet's ability to learn interpretable spatial pathological patterns, enhancing both seizure detection and seizure onset zone localization.

</details>


### [4] [Hardware Distortion Aware Precoding for ISAC Systems](https://arxiv.org/abs/2512.02153)
*Murat Babek Salman,Emil Björnson,Özlem Tugfe Demir*

Main category: eess.SP

TL;DR: 本文分析了硬件损伤对集成感知与通信系统在杂波环境中的影响，提出了两种方法来减轻硬件损伤和杂波对感知性能的恶化。


<details>
  <summary>Details</summary>
Motivation: 硬件损伤对通信系统频谱效率的影响已有充分研究，但其对感知性能的影响尚未探索。本文旨在分析硬件损伤在杂波环境中对集成感知与通信系统的影响。

Method: 推导了感知信号与杂波加噪声比，分析了硬件失真如何增强杂波噪声并掩盖目标回波。提出了两种方法：1）失真和杂波感知的预编码策略，在最小化与通信优化预编码器偏差的同时提高感知鲁棒性；2）基于功率分配的替代方法以降低计算复杂度。

Result: 数值结果证实了所提方法在克服硬件和杂波引起的限制方面的有效性，相比不考虑失真的设计显示出显著的性能提升。

Conclusion: 硬件失真显著恶化感知性能，特别是通过增强杂波噪声。提出的失真和杂波感知方法能有效改善集成感知与通信系统在硬件损伤和杂波环境下的性能。

Abstract: The impact of hardware impairments on the spectral efficiency of communication systems is well studied, but their effect on sensing performance remains unexplored. In this paper, we analyze the influence of hardware impairments on integrated sensing and communication (ISAC) systems in cluttered environments. We derive the sensing signal-to-clutter-plus-noise ratio (SCNR) and show that hardware distortions significantly degrade sensing performance by enhancing clutter-induced noise, which masks target echoes. The isotropic nature of transmit distortion due to multiple stream transmission further complicates clutter suppression. To address this, we propose a distortion- and clutter-aware precoding strategy that minimizes the deviation from the communication-optimized precoder while improving sensing robustness. We also propose an alternative power allocation-based approach that reduces computational complexity. Numerical results confirm the effectiveness of the proposed approaches in overcoming hardware- and clutter-induced limitations, demonstrating significant performance gains over distortion-unaware designs.

</details>


### [5] [Wavenumber-Division Multiplexing in Holographic MIMO with NLoS Channels](https://arxiv.org/abs/2512.02245)
*Ashutosh Prajapati,Prathapasinghe Dharmawansa,Marco Di Renzo,Italo Atzeni*

Main category: eess.SP

TL;DR: 论文将波数分复用技术从视距传播扩展到非视距传播的全息MIMO系统，分析了角度域表征、各向同性散射下的闭式解，并评估了自由度和遍历容量。


<details>
  <summary>Details</summary>
Motivation: 波数分复用技术最初是为视距传播的全息MIMO系统设计的，但实际通信场景中非视距传播更为常见。因此需要将WDM技术扩展到非视距传播的全息MIMO信道中，以更好地理解和利用空间频率域的特性。

Method: 将WDM技术应用于非视距信道，得到对应的角度域表征，通过功率谱因子和功率谱密度进行特征分析。针对各向同性散射情况，推导出闭式解，恢复Jakes的各向同性模型。通过数值结果评估各向同性和非各向同性散射下的自由度和遍历容量。

Result: 成功将WDM扩展到非视距传播的全息MIMO信道，获得了角度域表征的数学描述。在各向同性散射情况下得到了闭式解，与Jakes模型一致。数值分析表明该方法能有效评估信道自由度并计算遍历容量。

Conclusion: WDM技术可以成功扩展到非视距传播的全息MIMO系统，为空间频率域的信道分析提供了理论框架，特别是在各向同性散射条件下能够获得简洁的闭式解，为实际系统设计提供了有价值的理论指导。

Abstract: Wavenumber-division multiplexing (WDM) was introduced as a counterpart of orthogonal frequency-division multiplexing in the spatial-frequency domain for line-of-sight holographic multiple-input multiple-output (MIMO) systems. In this paper, we extend WDM to holographic MIMO channels with non-line-of-sight (NLoS) propagation. We show that applying WDM to the NLoS channel yields the corresponding angular-domain representation, which we characterize through the power spectral factor and power spectral density. We further obtain a closed-form characterization for the case of isotropic scattering, recovering Jakes' isotropic model. The analysis is complemented by numerical results evaluating the degrees of freedom and ergodic capacity under both isotropic and non-isotropic scattering.

</details>


### [6] [Bayesian Probability Fusion for Multi-AP Collaborative Sensing in Mobile Networks](https://arxiv.org/abs/2512.02462)
*Shengheng Liu,Xingkang Li,Yongming Huang,Yuan Fang,Qingji Jiang,Dazhuan Xu,Ziguo Zhong,Dongming Wang,Xiaohu You*

Main category: eess.SP

TL;DR: 提出一种用于多AP协作感知的贝叶斯概率融合框架，采用PCGA算法进行参数估计，在降低传输开销的同时提升估计精度


<details>
  <summary>Details</summary>
Motivation: 多接入点协作感知相比单站感知能提供更广泛、更准确、更鲁棒的感知能力，对下一代移动网络中的位置服务至关重要。现有方法在传输开销和估计精度之间存在权衡问题。

Method: 提出贝叶斯概率融合框架，将多AP接收信号建模为概率分布以捕获信道噪声和散射系数的随机性。采用先验约束梯度上升算法解决高维优化问题，并推导了最优融合权重、收敛性和Cramer-Rao下界。

Result: 相比信号融合减少90%传输开销，相比参数融合降低41%估计误差。实际毫米波AP覆盖范围内，50%概率达到亚米级精度。发布了公开数据集。

Conclusion: 该框架在实际多AP感知部署中实现了通信效率和估计精度之间的良好平衡，为下一代移动网络的集成感知与通信提供了有效解决方案。

Abstract: Integrated sensing and communication is widely acknowledged as a foundational technology for next-generation mobile networks. Compared with monostatic sensing, multi-access point (AP) collaborative sensing endows mobile networks with broader, more accurate, and resilient sensing capabilities, which are critical for diverse location-based sectors. This paper focuses on collaborative sensing in multi-AP networks and proposes a Bayesian probability fusion framework for target parameter estimation using orthogonal frequency-division multiplexing waveform. The framework models multi-AP received signals as probability distributions to capture stochastic observations from channel noise and scattering coefficients. Prior information is then incorporated into the joint probability density function to cast the problem as a constrained maximum a posteriori estimation. To address the high-dimensional optimization, we develop a prior-constrained gradient ascent (PCGA) algorithm that decouples correlated parameters and performs efficient gradient updates guided by the target prior. Theoretical analysis covers optimal fusion weights for global signal-to-noise ratio maximization, PCGA convergence, and the Cramer-Rao lower bound of the estimator, with insights applicable to broader fusion schemes. Extensive numerical simulations and real-world experiments with commercial devices show the framework reduces transmission overhead by 90% versus signal fusion and lowers estimation error by 41% relative to parameter fusion. Notably, field tests achieve submeter accuracy with 50% probability in typical coverage of mmWave APs. These improvements highlight a favorable balance between communication efficiency and estimation accuracy for practical multi-AP sensing deployment.
  The dataset is released for research purposes and is publicly available at: http://pmldatanet.com.cn/dataapp/multimodal

</details>


### [7] [Channel Knowledge Map Enabled Low-Altitude ISAC Networks: Joint Air Corridor Planning and Base Station Deployment](https://arxiv.org/abs/2512.02464)
*Jiaxuan Li,Yilong Chen,Fan Liu,Jie Xu*

Main category: eess.SP

TL;DR: 该论文提出了一种用于低空ISAC网络的联合空中走廊规划和基站部署方法，通过分层粗到细网格分解算法最小化系统成本，确保传感和通信覆盖。


<details>
  <summary>Details</summary>
Motivation: 在低空集成传感与通信网络中，需要同时规划无人机空中走廊和部署基站，确保整个走廊的传感和通信覆盖，同时最小化部署成本。

Method: 利用信道知识图（CKM）在部署前表征候选基站站点的无线信道，提出分层粗到细网格分解算法来解决大规模非凸整数规划问题。

Result: 仿真结果表明，所提出的联合设计能够在确保低空ISAC网络覆盖的同时，有效降低整体部署成本。

Conclusion: 该研究为低空ISAC网络提供了一种高效的联合空中走廊规划和基站部署方案，通过离线规划优化系统成本，确保网络性能。

Abstract: This letter addresses the joint air corridor planning and base station (BS) deployment problem for low-altitude integrated sensing and communication (ISAC) networks. In the considered system, unmanned aerial vehicles (UAVs) operate within a structured air corridor composed of connected cubic segments, and multiple BSs need to be selectively deployed at a set of candidate locations to ensure both sensing and communication coverage throughout the corridor. In particular, we leverage the channel knowledge map (CKM) to characterize wireless channels for candidate BS sites prior to deployment, thereby facilitating the offline planning. Under this setup, we minimize the system cost in terms of the weighted sum of the air corridor length and the number of deployed BSs, subject to the constraints on both sensing and communication performance across the corridor. To solve the formulated large-scale nonconvex integer programming problem, we develop a hierarchical coarse-to-fine grid decomposition algorithm. Simulation results demonstrate the benefit of the proposed joint design in reducing the overall deployment cost while ensuring the coverage of the low-altitude ISAC networks.

</details>


### [8] [Cell-free versus Conventional Massive MIMO : An Analysis of Channel Capacity based on Channel Measurement in the FR3 Band](https://arxiv.org/abs/2512.02501)
*Qi Zhen,Pan Tang,Haiyang Miao,Enrui Liu,Ximan Liu,Zihang Ding,Jianhua Zhang*

Main category: eess.SP

TL;DR: 本文首次在FR3频段（6-24 GHz）对无蜂窝大规模MIMO进行广泛信道测量，比较了CF-mMIMO与传统mMIMO在LOS和NLOS条件下的信道容量，发现64天线配置在测量环境中能带来最大容量增益。


<details>
  <summary>Details</summary>
Motivation: 无蜂窝大规模MIMO结合了分布式天线系统和传统MIMO技术的优势，是下一代无线系统的关键技术。然而在FR3中频段（6-24 GHz）缺乏实际信道测量数据，需要了解其实际性能表现。

Method: 使用包含512个天线的虚拟分布式天线阵列，在城区宏蜂窝环境中进行信道测量。基于测量数据，比较CF-mMIMO与传统mMIMO在不同SNR、LOS/NLOS条件下的信道容量，并从全阵列和子阵列角度分析容量随接收位置的变化。

Result: 测量结果显示，在考虑的测量环境中，64天线配置为CF-mMIMO带来最大信道容量增益：LOS条件下增益14.02%，NLOS条件下增益24.61%。

Conclusion: FR3频段CF-mMIMO信道容量的深入分析为优化下一代无线网络中的无蜂窝大规模MIMO系统提供了关键见解，64天线配置在测量环境中表现出最佳性能。

Abstract: Cell-free massive MIMO (CF-mMIMO) has emerged as a promising technology for next generation wireless systems, combining the benefits of distributed antenna systems (DAS) and traditional MIMO technology. In this work, we present the first extensive channel measurements for CF-mMIMO in the mid-band (FR3, 6-24 GHz), using a virtual widely distributed antenna array comprising 512 elements in the urban Macrocell (UMa) environment. Based on the measurement data, this paper compares the channel capacity of CF-mMIMO and Conventional mMIMO under both line-of-sight (LOS) and non-line-of-sight (NLOS) conditions across a range of signal-to-noise ratios (SNRs). We then analyze how channel capacity varies with Rx positions from the perspectives of the full array and of individual subarrays. Finally, we conclude that the 64-element array configuration yields the greatest advantage in channel capacity for CF-mMIMO in the measurement environment considered, with gains of 14.02\% under LOS and 24.61\% under NLOS conditions. This in-depth analysis of channel capacity in the FR3 band provides critical insights for optimizing CF-mMIMO systems in next generation wireless networks.

</details>


### [9] [Deep Learning-Based Joint Uplink-Downlink CSI Acquisition for Next-Generation Upper Mid-Band Systems](https://arxiv.org/abs/2512.02557)
*Xuan He,Hongwei Hou,Yafei Wang,Wenjin Wang,Shi Jin,Symeon Chatzinotas,Björn Ottersten*

Main category: eess.SP

TL;DR: 提出一个用于FR3频段大规模MIMO系统的CSI获取框架，整合CSI反馈、上下行信道估计和信道预测，通过联合估计网络、Transformer-MLP反馈网络和Mamba预测网络提升性能。


<details>
  <summary>Details</summary>
Motivation: 下一代无线通信系统中的FR3频段面临CSI获取挑战：天线数量增加和传输带宽扩大导致传统估计方法训练开销过大，而更高载频导致信道时变更快，需要新的解决方案。

Method: 1) 提出JUDCEN联合上下行信道估计网络，融合SRS和CSI-RS的不完整观测；2) 设计TMCFN Transformer-MLP CSI反馈网络，联合利用角度域和时延域特征；3) 开发MCPN Mamba信道预测网络，利用选择性状态空间模型捕捉时域动态。

Result: 仿真结果表明，所提框架在CSI获取精度和传输频谱效率方面均优于基准方法，同时具有更低的计算复杂度。

Conclusion: 该框架有效解决了FR3频段大规模MIMO系统的CSI获取挑战，通过整合反馈、估计和预测，实现了高性能、低复杂度的CSI获取方案。

Abstract: In next-generation wireless communication systems, the newly designated upper mid-band has attracted considerable attention, also called frequency range 3 (FR3), highlighting the need for downlink (DL) transmission design, which fundamentally relies on accurate CSI. However, CSI acquisition in FR3 systems faces significant challenges: the increased number of antennas and wider transmission bandwidth introduces prohibitive training overhead with traditional estimation approaches, as each probing captures only incomplete spatial-frequency observation, while higher carrier frequencies lead to faster temporal channel variation. To address these challenges, we propose a novel CSI acquisition framework that integrates CSI feedback, uplink (UL) and DL channel estimation, as well as channel prediction in the FR3 TDD massive MIMO systems. Specifically, we first develop the Joint UL and DL Channel Estimation Network (JUDCEN) to fuse incomplete observations based on the SRSs and CSI-RSs. By exploiting the complementary characteristics of preliminary UL and DL estimation features, obtained through initial UL estimation and quantized-feedback-assisted DL estimation, it enables full CSI reconstruction in the spatial domain. To mitigate the performance degradation in the feedback process, we propose the Transformer-MLP CSI Feedback Network (TMCFN), employing an MLP-based module to jointly exploit angle- and delay-domain features. Building upon the reconstructed full CSI, we further develop the Mamba-based Channel Prediction Network (MCPN), which exploits selective state-space model (SSM) mechanism to capture long-range temporal dynamics in the angle-delay domain for future CSI prediction. Simulation results demonstrate that the proposed framework consistently outperforms benchmarks in both CSI acquisition accuracy and transmission spectral efficiency with lower computational complexity.

</details>


### [10] [Predictive Beamforming in Low-Altitude Wireless Networks: A Cross-Attention Approach](https://arxiv.org/abs/2512.02563)
*Xiaotong Zhao,Yuanhao Cui,Weijie Yuan,Ziye Jia,Heng Liu,Chengwen Xing*

Main category: eess.SP

TL;DR: 提出基于跨注意力融合的多模态预测波束赋形方法，利用视觉和传感器数据，在动态低空无线网络中实现准确波束预测


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉异构感知模态间的深层相关性，限制了在复杂三维环境中的适应性，需要更有效的波束预测方法

Method: 使用CNN学习视觉图像的多尺度空间特征，Transformer编码器捕捉传感器数据的跨维度依赖，通过跨注意力融合模块整合两种模态的互补信息

Result: 在真实数据集上达到79.7%的Top-1准确率和99.3%的Top-3准确率，比3D ResNet-Transformer基线在Top-1到Top-5指标上提升4.4%-23.2%

Conclusion: 多模态跨注意力融合对动态低空无线网络中的智能波束选择是有效的，能够生成统一且具有区分性的表示

Abstract: Accurate beam prediction is essential for maintaining reliable links and high spectral efficiency in dynamic low-altitude wireless networks. However, existing approaches often fail to capture the deep correlations across heterogeneous sensing modalities, limiting their adaptability in complex three-dimensional environments. To overcome these challenges, we propose a multi-modal predictive beamforming method based on a cross-attention fusion mechanism that jointly leverages visual and structured sensor data. The proposed model utilizes a Convolutional Neural Network (CNN) to learn multi-scale spatial feature hierarchies from visual images and a Transformer encoder to capture cross-dimensional dependencies within sensor data. Then, a cross-attention fusion module is introduced to integrate complementary information between the two modalities, generating a unified and discriminative representation for accurate beam prediction. Through experimental evaluations conducted on a real-world dataset, our method reaches 79.7% Top-1 accuracy and 99.3% Top-3 accuracy, surpassing the 3D ResNet-Transformer baseline by 4.4%-23.2% across Top-1 to Top-5 metrics. These results verify that multi-modal cross-attention fusion is effective for intelligent beam selection in dynamic low-altitude wireless networks.

</details>


### [11] [Zero-Forcing MU-MIMO Precoding under Power Amplifier Non-Linearities](https://arxiv.org/abs/2512.02573)
*Juan Vidal Alegría,Ashkan Sheikhi,Ove Edfors*

Main category: eess.SP

TL;DR: 论文提出了一种非线性感知的迫零预编码方案，用于解决多用户MIMO系统中功率放大器非线性导致的干扰消除性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 在多用户MIMO系统中，功率放大器的非线性行为会降低线性预编码方案（如迫零预编码）的性能，导致用户间干扰消除效果变差。虽然可以使用数字预失真模块来线性化功率放大器，但完美实现成本高且功耗大。因此需要寻找替代方案来在非线性环境下实现完美干扰消除。

Method: 提出非线性感知迫零预编码方案，通过利用功率放大器非线性响应的知识，在非线性环境下实现完美干扰消除。针对基站天线数为偶数、每个天线连接具有三阶无记忆非线性功率放大器的两用户下行MU-MIMO场景，提供了初始迭代解决方案。

Result: 所提出的方法能够在存在显著残余干扰的场景中获得性能增益，通过可调节容差实现非线性感知迫零预编码。

Conclusion: 非线性感知迫零预编码方案为多用户MIMO系统中功率放大器非线性问题提供了一种有效的替代方案，避免了数字预失真模块的高成本和功耗问题，在残余干扰显著的情况下能够获得性能提升。

Abstract: In multi-user multiple-input multiple-output (MU-MIMO) systems, the non-linear behavior of the power amplifiers (PAs) may cause degradation of the linear precoding schemes dealing with interference between user equipments (UEs), e.g., the zero-forcing (ZF) precoder. One way to minimize this effect is to use digital-pre-distortion (DPD) modules to linearize the PAs. However, using perfect DPD modules is costly and it may incur significant power consumption. As an alternative, we consider the problem of characterizing non-linearity-aware ZF (NLA-ZF) precoding schemes, hereby defined as linear precoders that achieve perfect interference cancellation in the presence of PA non-linearity by exploiting knowledge of this non-linear response. We provide initial iterative solutions that allow achieving NLA-ZF (up to adjustable tolerance) in a two-UE downlink MU-MIMO scenario where the base station (BS) has an even number of antennas, and each antenna is connected to a PA exhibiting third-order memory-less non-linear behavior. The proposed approach allows for performance gains in scenarios with significant residual interference.

</details>


### [12] [Joint Beamforming and Matching for Ultra-Dense Massive Antenna Arrays](https://arxiv.org/abs/2512.02628)
*Carolina Nolasco-Ferencikova,Georg Schwan,Raphael Rolny,Alexander Stutz-Tirri,Christoph Studer*

Main category: eess.SP

TL;DR: 本文通过电磁建模分析开关式波束赋形架构，证明其能以低成本接近全数字方案的性能


<details>
  <summary>Details</summary>
Motivation: 传统全数字和混合波束赋形架构在扩展到大规模天线阵列时成本过高、功耗过大，需要寻找更经济的替代方案

Method: 采用物理一致的电磁建模框架，分析使用RF开关网络进行联合波束赋形和匹配的超密集贴片天线阵列架构

Result: 简单的开关式波束赋形架构能以显著更低的成本和复杂度接近全数字解决方案的天线增益

Conclusion: 开关式波束赋形架构是解决大规模MIMO系统成本和功耗问题的有前景的替代方案

Abstract: Massive multiple-input multiple-output (MIMO) offers substantial spectral-efficiency gains, but scaling to very large antenna arrays with conventional all-digital and hybrid beamforming architectures quickly results in excessively high costs and power consumption. Low-cost, switch-based architectures have recently emerged as a potential alternative. However, prior studies rely on simplified models that ignore (among others) antenna coupling, radiation patterns, and matching losses, resulting in inaccurate performance predictions. In this paper, we use a physically consistent electromagnetic modeling framework to analyze an ultra-dense patch-antenna array architecture that performs joint beamforming and matching using networks of inexpensive RF switches. Our results demonstrate that simple, switch-based beamforming architectures can approach the antenna-gain of all-digital solutions at significantly lower cost and complexity.

</details>


### [13] [G-PIFNN: A Generalizable Physics-informed Fourier Neural Network Framework for Electrical Circuits](https://arxiv.org/abs/2512.02712)
*Ibrahim Shahbaz,Mohammad J. Abdel-Rahman,Eman Hammad*

Main category: eess.SP

TL;DR: G-PIFNN框架通过物理激活函数、自动物理损失函数生成和迁移学习策略，显著提升了PINNs在电路分析中的性能、可解释性和泛化能力，同时减少了可训练参数数量。


<details>
  <summary>Details</summary>
Motivation: 虽然物理信息神经网络在动态物理系统的微分方程求解方面取得了进展，但在可解释性、可扩展性和架构复杂性方面仍存在挑战，特别是在电路分析应用中。

Method: 提出G-PIFNN框架，包含三个关键创新：1) 物理激活函数和轻量级PIFNN架构；2) 基于键合图的自动物理损失函数生成；3) 电路内和跨电路类迁移学习策略。

Result: 数值模拟表明，G-PIFNN在多种电路类别中实现了显著更好的预测性能和泛化能力，同时相比标准PINNs大幅减少了可训练参数数量。

Conclusion: G-PIFNN框架为电路分析提供了一种高效、可解释且可泛化的物理信息神经网络解决方案，解决了传统PINNs在可解释性、可扩展性和架构复杂性方面的局限性。

Abstract: Physics-Informed Neural Networks (PINNs) have advanced the data-driven solution of differential equations (DEs) in dynamic physical systems, yet challenges remain in explainability, scalability, and architectural complexity. This paper presents a Generalizable Physics-Informed Fourier Neural Network (G-PIFNN) framework that enhances PINN architectures for efficient and interpretable electrical circuit analysis. The proposed G-PIFNN introduces three key advancements: (1) improved performance and interpretability via a physics activation function (PAF) and a lightweight Physics-Informed Fourier Neural Network (PIFNN) architecture; (2) automated, bond graph (BG) based formulation of physics-informed loss functions for systematic differential equation generation; and (3) integration of intra-circuit and cross-circuit class transfer learning (TL) strategies, enabling unsupervised fine-tuning for rapid adaptation to varying circuit topologies. Numerical simulations demonstrate that G-PIFNN achieves significantly better predictive performance and generalization across diverse circuit classes, while significantly reducing the number of trainable parameters compared to standard PINNs.

</details>


### [14] [Channel Knowledge Map Construction via Physics-Inspired Diffusion Model Without Prior Observations](https://arxiv.org/abs/2512.02757)
*Yunzhe Zhu,Xuewen Liao,Zhenzhen Gao,Yong Zeng*

Main category: eess.SP

TL;DR: 本文提出了一种基于物理约束的扩散模型，用于构建6G无线系统中更准确、物理一致的信道知识图（CKM），相比现有计算机视觉方法能更好地捕捉无线传播的物理特性。


<details>
  <summary>Details</summary>
Motivation: 现有CKM构建方法大多将任务视为图像超分辨率或生成问题，采用计算机视觉模型，导致生成的CKM无法捕捉无线传播的物理特性。本文旨在构建能准确表征大规模衰落场景物理特征的CKM。

Method: 针对大规模衰落场景，设计了三个基于物理的约束项来表征大规模衰落的空间分布模式。将这些物理约束与具有卓越生成能力的先进扩散模型相结合，提出了物理启发的CKM构建扩散模型，推导了增强物理约束的损失函数，并设计了训练和生成框架。

Result: 大量实验表明，该方法在构建精度方面优于所有现有方法。所提出的模型提供了一个统一有效的框架，具有生成多样化、准确且物理一致的CKM的强大潜力。

Conclusion: 通过将物理约束融入扩散模型，本文提出的方法能够生成更准确、物理一致的信道知识图，为6G无线系统的环境感知提供了更可靠的解决方案。

Abstract: The ability to construct Channel Knowledge Map (CKM) with high precision is essential for environment awareness in 6G wireless systems. However, most existing CKM construction methods formulate the task as an image super-resolution or generation problem, thereby employing models originally developed for computer vision. As a result, the generated CKMs often fail to capture the underlying physical characteristics of wireless propagation. In this paper, we focus on the construction of CKM for large-scale fading scenarios and design three physics-based constraint terms to characterize the spatial distribution patterns of large-scale fading. By integrating these physical constraints with a state-of-the-art diffusion model that possesses superior generative capability, a physics-inspired diffusion model for CKM construction is proposed. Following this motivation, we derive the loss function of the diffusion model augmented with physics-based constraint terms and further design the training and generation framework for the proposed physics-inspired CKM generation diffusion model. Extensive experiments show that our approach outperforms all existing methods in terms of construction accuracy. Moreover, the proposed model provides a unified and effective framework with strong potential for generating diverse, accurate, and physically consistent CKM.

</details>


### [15] [Effects of disease duration and antipsychotics on brain age in schizophrenia](https://arxiv.org/abs/2512.02765)
*Alejandro Roig-Herrero,Luis M. San-José-Revuelta,Rafael Navarro-González,Rodrigo de Luis-García,Vicente Molina*

Main category: eess.SP

TL;DR: 精神分裂症患者存在加速脑老化现象，但抗精神病药物可能不是主要原因，需要纵向研究进一步验证


<details>
  <summary>Details</summary>
Motivation: 研究精神分裂症患者加速脑老化的进展性特征，并探究抗精神病药物在这一现象中的作用

Method: 使用脑年龄范式，比较首发精神病患者与健康对照的脑年龄差距；采用两种模型：基于FastSurfer提取的脑体积特征的Transformer模型和预训练的深度学习模型；通过Mann-Whitney U检验比较接受与未接受抗精神病药物治疗的双相情感障碍患者

Result: 两种模型均显示接受抗精神病药物治疗的双相情感障碍患者并未表现出显著更大的脑年龄差距，表明加速脑老化不太可能仅由抗精神病药物解释

Conclusion: 加速脑老化现象在精神分裂症中确实存在，但抗精神病药物可能不是主要原因，需要纵向研究来阐明脑老化的时间动态

Abstract: Accelerated brain aging has been consistently reported in patients with schizophrenia. Over the past decade, these findings have been replicated using the Brain Age paradigm, which applies machine learning techniques to estimate brain age from neuroimaging data. This approach yields a single index, the Brain Age Gap, defined as the difference between predicted and chronological age. Nevertheless, both the progressive nature of this phenomenon and the potential role of antipsychotic medication remain unclear. To investigate its progression, we compared the Brain Age Gap between individuals experiencing a first episode of psychosis and healthy controls using ANCOVA, adjusting for age, sex, body mass index, and estimated total intracranial volume. To enhance the robustness of our findings, we employed two distinct models: a transformer-inspired model based on harmonized volumetric brain features extracted with FastSurfer, and a previously trained deep learning model. To assess the potential effect of medication, we further compared bipolar patients who received antipsychotic treatment with those who did not. Mann-Whitney U test consistently showed that medicated bipolar patients did not exhibit a significantly larger Brain Age Gap. Both models converge on the conclusion that accelerated brain aging is unlikely to be explained by antipsychotic medication alone. Longitudinal studies are therefore required to clarify the temporal dynamics of brain aging in schizophrenia.

</details>


### [16] [Diffusion-Prior Split Gibbs Sampling for Synthetic Aperture Radar Imaging under Incomplete Measurements](https://arxiv.org/abs/2512.02768)
*Hefei Gao,Tianyao Huang,Letian Guo,Jie He,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 提出一种基于扩散模型和分裂吉布斯采样的SAR图像重建框架，通过交替进行似然驱动和先验驱动的更新，显著提升了SAR图像重建质量。


<details>
  <summary>Details</summary>
Motivation: 传统SAR重建方法（如匹配滤波和压缩感知）难以捕捉复杂场景结构，存在伪影、高旁瓣和细节丢失问题。现有基于扩散模型的方法由于采样过程中的似然近似过于简化，导致重建质量下降。

Method: 提出扩散驱动的分裂吉布斯采样框架，通过交替执行似然驱动更新（基于测量保真度）和先验驱动更新（基于学习到的扩散先验），使用近端采样确保逐步收敛到真实后验分布。

Result: 在仿真数据上获得超过7dB的平均PSNR提升，旁瓣抑制显著（MPLSR +2.96 dB，MISLR +11.5 dB）。在真实Sentinel-1A数据上获得1.6dB的平均PSNR提升，有效减少伪影并保留山脊、边缘和纹理等细节。

Conclusion: 该框架通过严谨整合测量保真度和学习到的扩散先验，为高保真SAR成像提供了一个鲁棒且可泛化的解决方案，在各种传感场景中展现出强大潜力。

Abstract: Synthetic aperture radar (SAR) imaging plays a critical role in all-weather, day-and-night remote sensing, yet reconstruction is often challenged by noise, undersampling, and complex scattering scenarios. Conventional methods, including matched filtering and sparsity-based compressed sensing, are limited in capturing intricate scene structures and frequently suffer from artifacts, elevated sidelobes, and loss of fine details. Recent diffusion models have demonstrated superior capability in representing high-order priors; however, existing diffusion-based SAR methods still yield degraded reconstructions due to oversimplified likelihood approximations in guided sampling. In this work, we propose a diffusion-driven split Gibbs sampling framework for SAR reconstruction, rigorously integrating measurement fidelity with learned diffusion priors. By alternately performing likelihood- and prior-driven updates via proximal sampling, this method ensures progressive convergence toward the true posterior while fully leveraging the expressive power of diffusion priors. Extensive experiments on simulated and Sentinel-1A datasets demonstrate substantial performance improvements: over 7 dB average PSNR gain in simulations, along with significant sidelobe suppression (MPLSR +2.96 dB, MISLR +11.5 dB) with respect to the best baseline result. On real-world Sentinel-1A data, the method achieves an average PSNR gain of 1.6 dB while effectively reducing artifacts and preserving scene details, including ridges, edges, and fine textures. These results underscore the potential of the adapted framework as a robust and generalizable solution for high-fidelity SAR imaging across diverse sensing scenarios.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [17] [On the Difficulty of Token-Level Modeling of Dysfluency and Fluency Shaping Artifacts](https://arxiv.org/abs/2512.02027)
*Kashaf Gulzar,Dominik Wagner,Sebastian P. Bayerl,Florian Hönig,Tobias Bocklet,Korbinian Riedhammer*

Main category: eess.AS

TL;DR: 提出参数高效的自适应方法，将口吃语音中的不流畅和流畅度修饰作为特殊标记解码，在英语和德语数据集上评估，揭示了端到端ASR系统的多语言局限性


<details>
  <summary>Details</summary>
Motivation: 现代端到端ASR系统在口吃语音转录方面仍面临挑战，往往忽略不流畅和流畅度修饰，导致转录结果缺乏临床和研究价值

Method: 提出参数高效的自适应方法，将口吃语音中的不流畅和流畅度修饰解码为特殊标记；采用多步微调策略和语言自适应预训练；在模拟（LibriStutter，英语）和自然（KSoF，德语）口吃语音数据集上评估

Result: 轻量级自适应技术对不流畅感知ASR有效，但标记化分析揭示了标记器的英语中心偏见，这对提升德语数据性能构成挑战

Conclusion: 展示了轻量级自适应技术在不流畅感知ASR中的有效性，同时暴露了端到端多语言系统的关键局限性，特别是标记器的英语中心偏见问题

Abstract: Automatic transcription of stuttered speech remains a challenge, even for modern end-to-end (E2E) automatic speech recognition (ASR) frameworks. Dysfluencies and fluency-shaping artifacts are often overlooked, resulting in non-verbatim transcriptions with limited clinical and research value. We propose a parameter-efficient adaptation method to decode dysfluencies and fluency modifications as special tokens within transcriptions, evaluated on simulated (LibriStutter, English) and natural (KSoF, German) stuttered speech datasets. To mitigate ASR performance disparities and bias towards English, we introduce a multi-step fine-tuning strategy with language-adaptive pretraining. Tokenization analysis further highlights the tokenizer's English-centric bias, which poses challenges for improving performance on German data. Our findings demonstrate the effectiveness of lightweight adaptation techniques for dysfluency-aware ASR while exposing key limitations in multilingual E2E systems.

</details>


### [18] [Towards Language-Independent Face-Voice Association with Multimodal Foundation Models](https://arxiv.org/abs/2512.02759)
*Aref Farhadipour,Teodora Vukovic,Volker Dellwo*

Main category: eess.AS

TL;DR: UZH-CL系统参加FAME2026挑战赛，采用ImageBind-LoRA方法，仅用阿拉伯语音频微调就在英语和德语评估集上取得24.73% EER，获得第二名


<details>
  <summary>Details</summary>
Motivation: 解决FAME2026挑战赛中跨模态验证在多语言条件下的问题，特别是未见和未听过的语言，应对数据稀缺和语言限制的挑战

Method: 研究两种架构：1）从头训练的基线双编码器系统，使用对比损失和正交投影损失；2）基于ImageBind结合LoRA的基础模型方法。从VoxBlink收集外部阿拉伯语数据集解决数据稀缺问题

Result: 最佳系统ImageBind-LoRA表现出卓越的跨语言泛化能力：仅用阿拉伯语音频微调，在英语和德语评估集上达到24.73% EER，在比赛中获得第二名

Conclusion: ImageBind-LoRA方法在跨语言跨模态验证任务中表现出色，即使训练数据有限且语言不匹配，也能实现有效的泛化，为多语言音频-文本验证提供了有前景的解决方案

Abstract: This paper describes the UZH-CL system submitted to the FAME2026 Challenge. The challenge focuses on cross-modal verification under unique multilingual conditions, specifically unseen and unheard languages. Our approach investigates two distinct architectures, consisting of a baseline dual-encoder system trained from scratch using contrastive and orthogonal projection losses, and a foundation model approach leveraging ImageBind with LoRA. To address the data scarcity and language constraints of the challenge, we curated an external Arabic dataset from VoxBlink. Our best-performing system, ImageBind-LoRA, demonstrates remarkable cross-lingual generalization: despite being fine-tuned exclusively on Arabic audio, it achieved an EER of 24.73% on the evaluation set (English and German), securing 2nd place in the competition.

</details>


### [19] [Perceptual evaluation of Acoustic Level of Detail in Virtual Acoustic Environments](https://arxiv.org/abs/2512.02891)
*Stefan Fichna,Steven van de Par,Bernhard U. Seeber,Stephan D. Ewert*

Main category: eess.AS

TL;DR: 研究探讨了虚拟声学环境中声学细节水平(ALOD)对感知的影响，发现即使大幅降低ALOD仍能保持与真实录音相似的感知质量，前提是适当表现扩散后期混响。


<details>
  <summary>Details</summary>
Motivation: 虚拟声学环境对听力研究和听力学至关重要，但实时应用需要简化房间声学模拟。目前尚不清楚需要多少声学细节水平(ALOD)才能捕捉所有感知相关效果。

Method: 研究在三个真实环境（客厅+厨房、酒吧、地铁站）中变化ALOD：通过生成不同数量的镜像源来改变早期反射，或排除特定几何细节。使用耳机与真实环境中的假人头双耳录音进行比较评估，或使用扬声器。评估内容包括脉冲刺激、电贝斯和语音片段的整体差异感知，以及合理性、语音清晰度和外部化感知。

Result: 结果表明，即使大幅降低ALOD，仍能保持与假人头录音相似的合理性、语音清晰度和外部化感知。早期反射的数量和准确性似乎不那么重要，前提是扩散后期混响得到适当表现。

Conclusion: 虚拟声学环境模拟可以在保持良好感知质量的同时大幅简化，关键在于适当表现扩散后期混响而非精确的早期反射细节。

Abstract: Virtual acoustic environments enable the creation and simulation of realistic and eco-logically valid daily-life situations vital for hearing research and audiology. Reverberant indoor environments are particularly important. For real-time applications, room acous-tics simulation requires simplifications, however, the necessary acoustic level of detail (ALOD) remains unclear in order to capture all perceptually relevant effects. This study examines the impact of varying ALOD in simulations of three real environments: a living room with a coupled kitchen, a pub, and an underground station. ALOD was varied by generating different numbers of image sources for early reflections, or by excluding geo-metrical room details specific for each environment. Simulations were perceptually eval-uated using headphones in comparison to binaural room impulse responses measured with a dummy head in the corresponding real environments, or by using loudspeakers. The study assessed the perceived overall difference for a pulse stimulus, a played electric bass and a speech token. Additionally, plausibility, speech intelligibility, and externaliza-tion were evaluated. Results indicate that a strong reduction in ALOD is feasible while maintaining similar plausibility, speech intelligibility, and externalization as with dummy head recordings. The number and accuracy of early reflections appear less relevant, pro-vided diffuse late reverberation is appropriately represented.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [20] [Story2MIDI: Emotionally Aligned Music Generation from Text](https://arxiv.org/abs/2512.02192)
*Mohammad Shokri,Alexandra C. Salem,Gabriel Levine,Johanna Devaney,Sarah Ita Levitan*

Main category: cs.SD

TL;DR: Story2MIDI：基于Transformer的序列到序列模型，可从文本生成情感对齐的音乐


<details>
  <summary>Details</summary>
Motivation: 开发能够根据文本内容生成相应情感音乐的AI系统，实现跨模态情感表达

Method: 构建Story2MIDI数据集（合并文本情感分析和音乐情感分类数据集），使用序列到序列Transformer模型，在小数据集和有限计算资源下训练

Result: 模型能有效学习音乐中的情感相关特征，生成具有多样情感响应的音乐样本，客观音乐指标和人类听音测试均证实其捕捉情感线索的能力

Conclusion: Story2MIDI模型成功实现了从文本到情感对齐音乐的生成，即使在资源有限条件下也能有效学习情感特征

Abstract: In this paper, we introduce Story2MIDI, a sequence-to-sequence Transformer-based model for generating emotion-aligned music from a given piece of text. To develop this model, we construct the Story2MIDI dataset by merging existing datasets for sentiment analysis from text and emotion classification in music. The resulting dataset contains pairs of text blurbs and music pieces that evoke the same emotions in the reader or listener. Despite the small scale of our dataset and limited computational resources, our results indicate that our model effectively learns emotion-relevant features in music and incorporates them into its generation process, producing samples with diverse emotional responses. We evaluate the generated outputs using objective musical metrics and a human listening study, confirming the model's ability to capture intended emotional cues.

</details>


### [21] [Continual Learning for Singing Voice Separation with Human in the Loop Adaptation](https://arxiv.org/abs/2512.02432)
*Ankur Gupta,Anshul Rai,Archit Bansal,Vipul Arora*

Main category: cs.SD

TL;DR: 提出基于深度学习的交互式持续学习框架，用于歌唱人声分离，允许用户通过标记误报区域来微调模型，适应新歌曲。


<details>
  <summary>Details</summary>
Motivation: 现有歌唱人声分离模型缺乏用户交互能力，无法适应实际场景中音乐风格和乐器的变化，需要用户参与来提升模型在新数据上的表现。

Method: 使用U-Net架构作为基础模型生成频谱图掩码，引入人机交互环节让用户标记误报区域（本应是静音的人声区域），提出两种持续学习算法来整合用户反馈。

Result: 实验证明提出的算法在数据集内和跨数据集设置中，相比基础模型显著提升了歌唱人声分离性能。

Conclusion: 交互式持续学习框架有效提升了歌唱人声分离模型在实际部署中的适应性和性能，通过用户反馈使模型能更好地处理与训练数据不同的新歌曲。

Abstract: Deep learning-based works for singing voice separation have performed exceptionally well in the recent past. However, most of these works do not focus on allowing users to interact with the model to improve performance. This can be crucial when deploying the model in real-world scenarios where music tracks can vary from the original training data in both genre and instruments. In this paper, we present a deep learning-based interactive continual learning framework for singing voice separation that allows users to fine-tune the vocal separation model to conform it to new target songs. We use a U-Net-based base model architecture that produces a mask for separating vocals from the spectrogram, followed by a human-in-the-loop task where the user provides feedback by marking a few false positives, i.e., regions in the extracted vocals that should have been silence. We propose two continual learning algorithms. Experiments substantiate the improvement in singing voice separation performance by the proposed algorithms over the base model in intra-dataset and inter-dataset settings.

</details>


### [22] [VibOmni: Towards Scalable Bone-conduction Speech Enhancement on Earables](https://arxiv.org/abs/2512.02515)
*Lixing He,Yunqi Guo,Haozheng Hou,Zhenyu Yan*

Main category: cs.SD

TL;DR: VibOmni：一种轻量级端到端多模态语音增强系统，利用IMU采集的骨传导振动来提升耳戴设备在嘈杂环境中的语音质量


<details>
  <summary>Details</summary>
Motivation: 耳戴设备（如TWS耳机和VR/AR头显）在嘈杂环境中语音应用效果不佳，现有仅依赖全向麦克风的系统难以处理环境噪声和竞争说话者干扰

Method: 提出VibOmni系统，采用双分支编码器-解码器深度神经网络融合音频和振动特征；引入BCF建模的数据增强技术生成合成振动数据；使用多模态SNR估计器实现持续学习和自适应推理

Result: 在32名志愿者的真实数据集上，VibOmni在PESQ上提升21%，SNR提升26%，WER降低约40%，移动设备延迟更低；35名参与者的用户研究显示87%偏好VibOmni

Conclusion: VibOmni通过有效融合骨传导振动信息，显著提升了耳戴设备在嘈杂环境中的语音增强性能，具有实际部署价值

Abstract: Earables, such as True Wireless Stereo earphones and VR/AR headsets, are increasingly popular, yet their compact design poses challenges for robust voice-related applications like telecommunication and voice assistant interactions in noisy environments. Existing speech enhancement systems, reliant solely on omnidirectional microphones, struggle with ambient noise like competing speakers. To address these issues, we propose VibOmni, a lightweight, end-to-end multi-modal speech enhancement system for earables that leverages bone-conducted vibrations captured by widely available Inertial Measurement Units (IMUs). VibOmni integrates a two-branch encoder-decoder deep neural network to fuse audio and vibration features. To overcome the scarcity of paired audio-vibration datasets, we introduce a novel data augmentation technique that models Bone Conduction Functions (BCFs) from limited recordings, enabling synthetic vibration data generation with only 4.5% spectrogram similarity error. Additionally, a multi-modal SNR estimator facilitates continual learning and adaptive inference, optimizing performance in dynamic, noisy settings without on-device back-propagation. Evaluated on real-world datasets from 32 volunteers with different devices, VibOmni achieves up to 21% improvement in Perceptual Evaluation of Speech Quality (PESQ), 26% in Signal-to-Noise Ratio (SNR), and about 40% WER reduction with much less latency on mobile devices. A user study with 35 participants showed 87% preferred VibOmni over baselines, demonstrating its effectiveness for deployment in diverse acoustic environments.

</details>


### [23] [Generative Multi-modal Feedback for Singing Voice Synthesis Evaluation](https://arxiv.org/abs/2512.02523)
*Xueyan Li,Yuxin Wang,Mengjie Jiang,Qingzi Zhu,Jiang Zhang,Zoey Kim,Yazhe Niu*

Main category: cs.SD

TL;DR: 提出VocalCritic框架，使用音频-语言模型为歌唱合成提供多维语言和音频反馈，解决传统奖励模型依赖单一分数、难以捕捉表达维度的问题。


<details>
  <summary>Details</summary>
Motivation: 当前歌唱合成评估方法依赖单一数值评分，难以捕捉音色、表达等多维度特征，且需要昂贵的人工标注，限制了可解释性和泛化能力。

Method: 提出生成式反馈框架，使用音频-语言模型生成文本和音频形式的批评反馈，涵盖旋律、内容、听觉质量等方面。通过混合人类音乐反应和MLLMs生成的合成批评数据进行微调。

Result: 定量实验验证了数据集和训练策略的有效性，框架能够产生音乐准确且可解释的评估，适合指导生成模型的改进。

Conclusion: VocalCritic框架为歌唱合成提供了多维、可解释的评估方法，解决了传统奖励模型的局限性，有助于提升生成模型的质量。

Abstract: Singing voice synthesis (SVS) has advanced significantly, enabling models to generate vocals with accurate pitch and consistent style. As these capabilities improve, the need for reliable evaluation and optimization becomes increasingly critical. However, current methods like reward systems often rely on single numerical scores, struggle to capture various dimensions such as phrasing or expressiveness, and require costly annotations, limiting interpretability and generalization. To address these issues, we propose a generative feedback (i.e., reward model) framework that provides multi-dimensional language and audio feedback for SVS assessment. Our approach leverages an audio-language model to generate text and audio critiques-covering aspects such as melody, content, and auditory quality. The model is fine-tuned on a hybrid dataset combining human music reactions and synthetic critiques from a MLLMs, enhancing diversity and linguistic richness. Quantitative experiments validate the effectiveness of the proposed dataset and training strategy, demonstrating that the framework produces musically accurate and interpretable evaluations suitable for guiding generative model improvement. The code is at [https://github.com/opendilab/VocalCritic](https://github.com/opendilab/VocalCritic)

</details>


### [24] [Pianist Transformer: Towards Expressive Piano Performance Rendering via Scalable Self-Supervised Pre-Training](https://arxiv.org/abs/2512.02652)
*Hong-Jie You,Jie-Jing Shao,Xiao-Wen Yang,Lin-Han Jia,Lan-Zhe Guo,Yu-Feng Li*

Main category: cs.SD

TL;DR: Pianist Transformer：首个基于自监督预训练的大规模音乐表现力渲染模型，使用统一MIDI表示和高效非对称架构，在10B token上训练135M参数模型，实现人类水平的音乐表现力合成。


<details>
  <summary>Details</summary>
Motivation: 现有音乐表现力渲染方法依赖小规模标注数据集，限制了数据和模型规模的扩展，尽管存在大量未标注音乐数据。需要解决这一扩展瓶颈以实现更高质量的音乐表现力合成。

Method: 1) 统一的MIDI数据表示，无需显式标注即可学习音乐结构和表现力的共享原则；2) 高效的非对称架构，支持更长上下文和更快推理；3) 自监督预训练流程，使用10B token训练135M参数模型；4) 最先进的性能模型。

Result: 模型在客观指标和主观评分上均达到人类水平，建立了音乐表现力合成的可扩展路径，实现了数据规模和模型规模的双重突破。

Conclusion: Pianist Transformer为音乐领域的人类水平表现力合成建立了可扩展的路径，解决了现有方法在数据和模型规模扩展上的限制，为音乐AI的发展提供了新方向。

Abstract: Existing methods for expressive music performance rendering rely on supervised learning over small labeled datasets, which limits scaling of both data volume and model size, despite the availability of vast unlabeled music, as in vision and language. To address this gap, we introduce Pianist Transformer, with four key contributions: 1) a unified Musical Instrument Digital Interface (MIDI) data representation for learning the shared principles of musical structure and expression without explicit annotation; 2) an efficient asymmetric architecture, enabling longer contexts and faster inference without sacrificing rendering quality; 3) a self-supervised pre-training pipeline with 10B tokens and 135M-parameter model, unlocking data and model scaling advantages for expressive performance rendering; 4) a state-of-the-art performance model, which achieves strong objective metrics and human-level subjective ratings. Overall, Pianist Transformer establishes a scalable path toward human-like performance synthesis in the music domain.

</details>


### [25] [SAND Challenge: Four Approaches for Dysartria Severity Classification](https://arxiv.org/abs/2512.02669)
*Gauri Deshpande,Harish Battula,Ashish Panda,Sunil Kumar Kopparapu*

Main category: cs.SD

TL;DR: 本文对SAND挑战赛中四种不同的构音障碍严重程度分类建模方法进行了统一研究，比较了基于视觉Transformer的ViT-OF、1D-CNN、BiLSTM-OF和分层XGBoost集成四种方法在相同数据集上的性能。


<details>
  <summary>Details</summary>
Motivation: 研究动机是系统比较不同建模方法在构音障碍严重程度分类任务上的表现，探索特征工程方法与深度学习方法的优劣，为神经退行性疾病语音分析提供参考。

Method: 使用四种不同方法：1）基于谱图图像的Vision Transformer（ViT-OF）；2）使用八个1D-CNN并进行多数投票融合；3）使用九个BiLSTM模型并进行多数投票融合；4）采用两阶段学习框架结合声门和共振峰特征的分层XGBoost集成。

Result: 在53名说话者的验证集上，特征工程的XGBoost集成方法获得最高的macro-F1分数（0.86），而深度学习方法（ViT、CNN、BiLSTM）获得约0.70的F1分数，表现出竞争性但略逊于特征工程方法。

Conclusion: 特征工程的XGBoost集成方法在构音障碍严重程度分类任务上表现最佳，但深度学习方法也展现出竞争性性能，并为问题提供了互补的视角，表明不同方法各有优势。

Abstract: This paper presents a unified study of four distinct modeling approaches for classifying dysarthria severity in the Speech Analysis for Neurodegenerative Diseases (SAND) challenge. All models tackle the same five class classification task using a common dataset of speech recordings. We investigate: (1) a ViT-OF method leveraging a Vision Transformer on spectrogram images, (2) a 1D-CNN approach using eight 1-D CNN's with majority-vote fusion, (3) a BiLSTM-OF approach using nine BiLSTM models with majority vote fusion, and (4) a Hierarchical XGBoost ensemble that combines glottal and formant features through a two stage learning framework. Each method is described, and their performances on a validation set of 53 speakers are compared. Results show that while the feature-engineered XGBoost ensemble achieves the highest macro-F1 (0.86), the deep learning models (ViT, CNN, BiLSTM) attain competitive F1-scores (0.70) and offer complementary insights into the problem.

</details>


### [26] [Exploring Definitions of Quality and Diversity in Sonic Measurement Spaces](https://arxiv.org/abs/2512.02783)
*Björn Þór Jónsson,Çağrı Erdem,Stefano Fasciani,Kyrre Glette*

Main category: cs.SD

TL;DR: 该研究探索了使用无监督降维方法（PCA和自编码器）自动定义和动态重构声学行为空间，以提升质量多样性进化算法在数字声音合成中的探索能力。


<details>
  <summary>Details</summary>
Motivation: 数字声音合成具有巨大的参数空间，质量多样性进化算法是探索这一潜力的有前景方法，但现有方法主要依赖手工特征描述符或有监督分类器，可能引入探索偏见并限制发现范围。

Method: 采用无监督降维方法（主成分分析和自编码器）将高维音频特征投影到结构化网格上，用于MAP-Elites算法，并通过定期重新训练模型实现动态重构。

Result: 自动方法比手工行为空间实现了显著更大的多样性，避免了专家引入的偏见；动态行为空间重构保持了进化压力并防止停滞，其中PCA在降维技术中表现最有效。

Conclusion: 无监督降维方法能够创建自动化的声音发现系统，无需人工干预或有监督训练约束即可探索巨大的参数空间，为数字声音合成提供了更有效的探索框架。

Abstract: Digital sound synthesis presents the opportunity to explore vast parameter spaces containing millions of configurations. Quality diversity (QD) evolutionary algorithms offer a promising approach to harness this potential, yet their success hinges on appropriate sonic feature representations. Existing QD methods predominantly employ handcrafted descriptors or supervised classifiers, potentially introducing unintended exploration biases and constraining discovery to familiar sonic regions. This work investigates unsupervised dimensionality reduction methods for automatically defining and dynamically reconfiguring sonic behaviour spaces during QD search. We apply Principal Component Analysis (PCA) and autoencoders to project high-dimensional audio features onto structured grids for MAP-Elites, implementing dynamic reconfiguration through model retraining at regular intervals. Comparison across two experimental scenarios shows that automatic approaches achieve significantly greater diversity than handcrafted behaviour spaces while avoiding expert-imposed biases. Dynamic behaviour-space reconfiguration maintains evolutionary pressure and prevents stagnation, with PCA proving most effective among the dimensionality reduction techniques. These results contribute to automated sonic discovery systems capable of exploring vast parameter spaces without manual intervention or supervised training constraints.

</details>

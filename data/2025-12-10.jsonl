{"id": "2512.08313", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2512.08313", "abs": "https://arxiv.org/abs/2512.08313", "authors": ["Gabriele Ravizza", "Julián Villegas", "Christer P. Volk", "Tore Stegenborg-Andersen", "Yan Pei"], "title": "An Adaptive Method for Target Curve Selection", "comment": "8 pages,6 figures. Accepted for presentation at the Audio Engineering Society (AES) International Conference on Headphone Technology, 2025", "summary": "In this paper, we introduce an adaptation of the \"Interactive Differential Evolution\" (IDE) algorithm to the audio domain for the task of identifying the preferred over-the-ear headphone frequency response target among consumers. The method is based on data collection using an adaptive paired rating listening test paradigm (paired comparison with a scale). The IDE algorithm and its parameters are explained in detail. Additionally, data collected from three listening experiments with more than 20 consumers is presented, and the algorithm's performance in this untested domain is investigated on the basis of two convergence measures. The results indicate that this method can converge and may ease the task of 'extracting' frequency response preference from untrained consumers."}
{"id": "2512.08319", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2512.08319", "abs": "https://arxiv.org/abs/2512.08319", "authors": ["Junyi Peng", "Lin Zhang", "Jin Li", "Oldrich Plchot", "Jan Cernocky"], "title": "BUT Systems for Environmental Sound Deepfake Detection in the ESDD 2026 Challenge", "comment": null, "summary": "This paper describes the BUT submission to the ESDD 2026 Challenge, specifically focusing on Track 1: Environmental Sound Deepfake Detection with Unseen Generators. To address the critical challenge of generalizing to audio generated by unseen synthesis algorithms, we propose a robust ensemble framework leveraging diverse Self-Supervised Learning (SSL) models. We conduct a comprehensive analysis of general audio SSL models (including BEATs, EAT, and Dasheng) and speech-specific SSLs. These front-ends are coupled with a lightweight Multi-Head Factorized Attention (MHFA) back-end to capture discriminative representations. Furthermore, we introduce a feature domain augmentation strategy based on distribution uncertainty modeling to enhance model robustness against unseen spectral distortions. All models are trained exclusively on the official EnvSDD data, without using any external resources. Experimental results demonstrate the effectiveness of our approach: our best single system achieved Equal Error Rates (EER) of 0.00\\%, 4.60\\%, and 4.80\\% on the Development, Progress (Track 1), and Final Evaluation sets, respectively. The fusion system further improved generalization, yielding EERs of 0.00\\%, 3.52\\%, and 4.38\\% across the same partitions."}
{"id": "2512.07845", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2512.07845", "abs": "https://arxiv.org/abs/2512.07845", "authors": ["Shuaihang Yuan", "Congcong Wen", "Muhammad Shafique", "Anthony Tzes", "Yi Fang"], "title": "AudioScene: Integrating Object-Event Audio into 3D Scenes", "comment": null, "summary": "The rapid advances in audio analysis underscore its vast potential for humancomputer interaction, environmental monitoring, and public safety; yet, existing audioonly datasets often lack spatial context. To address this gap, we present two novel audiospatial scene datasets, AudioScanNet and AudioRoboTHOR, designed to explore audioconditioned tasks within 3D environments. By integrating audio clips with spatially aligned 3D scenes, our datasets enable research on how audio signals interact with spatial context. To associate audio events with corresponding spatial information, we leverage the common sense reasoning ability of large language models and supplement them with rigorous human verification, This approach offers greater scalability compared to purely manual annotation while maintaining high standards of accuracy, completeness, and diversity, quantified through inter annotator agreement and performance on two benchmark tasks audio based 3D visual grounding and audio based robotic zeroshot navigation. The results highlight the limitations of current audiocentric methods and underscore the practical challenges and significance of our datasets in advancing audio guided spatial learning."}
{"id": "2512.07872", "categories": ["cs.SD", "eess.AS", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.07872", "abs": "https://arxiv.org/abs/2512.07872", "authors": ["Ishaan Kunwar", "Henry Cantor", "Tyler Rizzo", "Ayaan Qayyum"], "title": "LocaGen: Sub-Sample Time-Delay Learning for Beam Localization", "comment": "7 pages", "summary": "The goal of LocaGen is to improve the localization performance of audio signals in the 2-D beam localization problem. LocaGen reduces sampling quantization errors through machine learning models trained on realistic synthetic data generated by a simulation. The system increases the accuracy of both direction-of-arrival (DOA) and precise location estimation of an audio beam from an array of three microphones. We demonstrate LocaGen's efficacy on a low-powered embedded system with an increased localization accuracy with a minimal increase in real-time resource usage. LocaGen was demonstrated to reduce DOA error by approximately 67% even with a microphone array of only 10 kHz in audio processing."}
{"id": "2512.07845", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2512.07845", "abs": "https://arxiv.org/abs/2512.07845", "authors": ["Shuaihang Yuan", "Congcong Wen", "Muhammad Shafique", "Anthony Tzes", "Yi Fang"], "title": "AudioScene: Integrating Object-Event Audio into 3D Scenes", "comment": null, "summary": "The rapid advances in audio analysis underscore its vast potential for humancomputer interaction, environmental monitoring, and public safety; yet, existing audioonly datasets often lack spatial context. To address this gap, we present two novel audiospatial scene datasets, AudioScanNet and AudioRoboTHOR, designed to explore audioconditioned tasks within 3D environments. By integrating audio clips with spatially aligned 3D scenes, our datasets enable research on how audio signals interact with spatial context. To associate audio events with corresponding spatial information, we leverage the common sense reasoning ability of large language models and supplement them with rigorous human verification, This approach offers greater scalability compared to purely manual annotation while maintaining high standards of accuracy, completeness, and diversity, quantified through inter annotator agreement and performance on two benchmark tasks audio based 3D visual grounding and audio based robotic zeroshot navigation. The results highlight the limitations of current audiocentric methods and underscore the practical challenges and significance of our datasets in advancing audio guided spatial learning."}
{"id": "2512.07851", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.07851", "abs": "https://arxiv.org/abs/2512.07851", "authors": ["Sansrit Paudel"], "title": "Signal and Noise Classification in Bio-Signals via unsupervised Machine Learning", "comment": null, "summary": "Real-world biosignal data is frequently corrupted by various types of noise, such as motion artifacts, and baseline wander. Although digital signal processing techniques exist to process such signals; however, heavily degraded signals cannot be recovered. In this study, we aim to classify two things: first, a binary classification of noisy and clean biosignals, and next, to categorize various kinds of noise such as motion artifacts, sensor failure, etc. We implemented K-means clustering, and our results indicate that the algorithm can most reliably group clean segments from noisy ones, particularly strong performance in identifying clean data compared to various categories of noise. This approach enables the selection of only high-quality bio-signal segments and provides accurate results for feature engineering that may enhance the precision of machine learning models trained on biosignals."}
{"id": "2512.08006", "categories": ["cs.SD", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2512.08006", "abs": "https://arxiv.org/abs/2512.08006", "authors": ["Mahta Fetrat", "Donya Navabi", "Zahra Dehghanian", "Morteza Abolghasemi", "Hamid R. Rabiee"], "title": "Beyond Unified Models: A Service-Oriented Approach to Low Latency, Context Aware Phonemization for Real Time TTS", "comment": null, "summary": "Lightweight, real-time text-to-speech systems are crucial for accessibility. However, the most efficient TTS models often rely on lightweight phonemizers that struggle with context-dependent challenges. In contrast, more advanced phonemizers with a deeper linguistic understanding typically incur high computational costs, which prevents real-time performance.\n  This paper examines the trade-off between phonemization quality and inference speed in G2P-aided TTS systems, introducing a practical framework to bridge this gap. We propose lightweight strategies for context-aware phonemization and a service-oriented TTS architecture that executes these modules as independent services. This design decouples heavy context-aware components from the core TTS engine, effectively breaking the latency barrier and enabling real-time use of high-quality phonemization models. Experimental results confirm that the proposed system improves pronunciation soundness and linguistic accuracy while maintaining real-time responsiveness, making it well-suited for offline and end-device TTS applications."}
{"id": "2512.07872", "categories": ["cs.SD", "eess.AS", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.07872", "abs": "https://arxiv.org/abs/2512.07872", "authors": ["Ishaan Kunwar", "Henry Cantor", "Tyler Rizzo", "Ayaan Qayyum"], "title": "LocaGen: Sub-Sample Time-Delay Learning for Beam Localization", "comment": "7 pages", "summary": "The goal of LocaGen is to improve the localization performance of audio signals in the 2-D beam localization problem. LocaGen reduces sampling quantization errors through machine learning models trained on realistic synthetic data generated by a simulation. The system increases the accuracy of both direction-of-arrival (DOA) and precise location estimation of an audio beam from an array of three microphones. We demonstrate LocaGen's efficacy on a low-powered embedded system with an increased localization accuracy with a minimal increase in real-time resource usage. LocaGen was demonstrated to reduce DOA error by approximately 67% even with a microphone array of only 10 kHz in audio processing."}
{"id": "2512.08069", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08069", "abs": "https://arxiv.org/abs/2512.08069", "authors": ["Florian Muralter", "Fabian Muralter", "Hugo Landaluce", "Asier Perallos"], "title": "Polarization-Diversity-Based Rotation Sensing Methodology Using COTS UHF RFID Tags", "comment": null, "summary": "Phase-based sensing using ultra-high frequency (UHF) radio-frequency identification (RFID) has, in recent years, yielded numerous additions to the Internet of Things (IoT). This work presents a polarization diversity-based rotation sensing methodology using common-off-the-shelf (COTS) UHF RFID tags identified with a software-defined radio (SDR) UHF RFID reader. The proposed methodology uses the tag-to-reader message after fully coherent demodulation to calculate a difference signal of the backscatter load modulation states. This sequence is then used to compute the rotation speed by evaluating its phase change over time. Experimental results are used to validate the theoretical model and to evaluate the performance and limitations of the proposed system."}
{"id": "2512.08006", "categories": ["cs.SD", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2512.08006", "abs": "https://arxiv.org/abs/2512.08006", "authors": ["Mahta Fetrat", "Donya Navabi", "Zahra Dehghanian", "Morteza Abolghasemi", "Hamid R. Rabiee"], "title": "Beyond Unified Models: A Service-Oriented Approach to Low Latency, Context Aware Phonemization for Real Time TTS", "comment": null, "summary": "Lightweight, real-time text-to-speech systems are crucial for accessibility. However, the most efficient TTS models often rely on lightweight phonemizers that struggle with context-dependent challenges. In contrast, more advanced phonemizers with a deeper linguistic understanding typically incur high computational costs, which prevents real-time performance.\n  This paper examines the trade-off between phonemization quality and inference speed in G2P-aided TTS systems, introducing a practical framework to bridge this gap. We propose lightweight strategies for context-aware phonemization and a service-oriented TTS architecture that executes these modules as independent services. This design decouples heavy context-aware components from the core TTS engine, effectively breaking the latency barrier and enabling real-time use of high-quality phonemization models. Experimental results confirm that the proposed system improves pronunciation soundness and linguistic accuracy while maintaining real-time responsiveness, making it well-suited for offline and end-device TTS applications."}
{"id": "2512.08162", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08162", "abs": "https://arxiv.org/abs/2512.08162", "authors": ["Benjamin W. Domae", "Ibrahim Pehlivan", "Danijela Cabric"], "title": "Millimeter-Wave True-Time Delay Array Beamforming with Robustness to Mobility", "comment": "Presented at the 2025 Asilomar Conference on Signals, Systems, and Computers; 6 pages, 9 figures", "summary": "Ultra-reliable and low-latency connectivity is required for real-time and latency-sensitive applications, like wireless augmented and virtual reality streaming. Millimeter-wave (mmW) networks have enabled extremely high data rates through large available bandwidths but struggle to maintain continuous connectivity with mobile users. Achieving the required beamforming gain from large antenna arrays with minimal disruption is particularly challenging with fast-moving users and practical analog mmW array architectures. In this work, we propose frequency-dependent slanted beams from true-time delay (TTD) analog arrays to achieve robust beamforming in wideband, multi-user downlink scenarios. Novel beams with linear angle-frequency relationships for different users and sub-bands provide a trade-off between instantaneous capacity and angular coverage. Compared to alternative analog array beamforming designs, slanted beams provide higher reliability to angle offsets and greater adaptability to varied user movement statistics."}
{"id": "2512.08203", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.08203", "abs": "https://arxiv.org/abs/2512.08203", "authors": ["Zhuohang Han", "Jincheng Dai", "Shengshi Yao", "Junyi Wang", "Yanlong Li", "Kai Niu", "Wenjun Xu", "Ping Zhang"], "title": "Error-Resilient Semantic Communication for Speech Transmission over Packet-Loss Networks", "comment": "submitted to IEEE in Nov. 2025", "summary": "Real-time speech communication over wireless networks remains challenging, as conventional channel protection mechanisms cannot effectively counter packet loss under stringent bandwidth and latency constraints. Semantic communication has emerged as a promising paradigm for enhancing the robustness of speech transmission by means of joint source-channel coding (JSCC). However, its cross-layer design hinders practical deployment due to the incompatibility with existing digital communication systems. In this case, the robustness of speech communication is consequently evaluated primarily by the error-resilience to packet loss over wireless networks. To address these challenges, we propose \\emph{Glaris}, a generative latent-prior-based resilient speech semantic communication framework that performs resilient speech coding in the generative latent space. Generative latent priors enable high-quality packet loss concealment (PLC) at the receiver side, well-balancing semantic consistency and reconstruction fidelity. Additionally, an integrated error resilience mechanism is designed to mitigate the error propagation and improve the effectiveness of PLC. Compared with traditional packet-level forward error correction (FEC) strategies, our new method achieves enhanced robustness over dynamic wireless networks while reducing redundancy overhead significantly. Experimental results on the LibriSpeech dataset demonstrate that \\emph{Glaris} consistently outperforms existing error-resilient codecs, achieving JSCC-level robustness while maintaining seamless compatibility with existing systems, and it also strikes a favorable balance between transmission efficiency and speech reconstruction quality."}
{"id": "2512.08208", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08208", "abs": "https://arxiv.org/abs/2512.08208", "authors": ["Mingyi Li", "Jiawen Xu", "Hanting Zhao", "Xu Zhao", "Yan Jin Chen", "Tie Jun Cui", "Vincenzo Galdi", "Lianlin Li"], "title": "Metasurfaces Enable Active-Like Passive Radar", "comment": null, "summary": "Passive radars (PRs) provide a low-cost and energy-efficient approach to object detection by reusing existing wireless transmissions instead of emitting dedicated probing signals. Yet, conventional passive systems require prior knowledge of non-cooperative source waveforms, are vulnerable to strong interference, and rely on Doppler signatures, limiting their ability to detect subtle or slow-moving targets. Here, we introduce a metasurface-enabled PR (MEPR) concept that integrates a space-time-coding programmable metasurface to imprint distinct spatiotemporal tags onto ambient wireless wavefields. This mechanism transforms a PR into an active-like sensing platform without the need for source control, enabling interference suppression, signal enhancement, and accurate target localization and tracking in cluttered environments. A proof-of-concept implementation operating at 5.48 GHz confirms real-time imaging and tracking of unmanned aerial vehicles under interference-rich conditions, with performance comparable to active radar systems. These results establish MEPR as a solid foundation for scalable, adaptive, and energy-efficient next-generation integrated sensing and communication systems."}
{"id": "2512.08238", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08238", "abs": "https://arxiv.org/abs/2512.08238", "authors": ["Mahathir Monjur", "Shahriar Nirjon"], "title": "SpeechQualityLLM: LLM-Based Multimodal Assessment of Speech Quality", "comment": "9 pages, 5 figures, 8 tables", "summary": "Objective speech quality assessment is central to telephony, VoIP, and streaming systems, where large volumes of degraded audio must be monitored and optimized at scale. Classical metrics such as PESQ and POLQA approximate human mean opinion scores (MOS) but require carefully controlled conditions and expensive listening tests, while learning-based models such as NISQA regress MOS and multiple perceptual dimensions from waveforms or spectrograms, achieving high correlation with subjective ratings yet remaining rigid: they do not support interactive, natural-language queries and do not natively provide textual rationales. In this work, we introduce SpeechQualityLLM, a multimodal speech quality question-answering (QA) system that couples an audio encoder with a language model and is trained on the NISQA corpus using template-based question-answer pairs covering overall MOS and four perceptual dimensions (noisiness, coloration, discontinuity, and loudness) in both single-ended (degraded only) and double-ended (degraded plus clean reference) setups. Instead of directly regressing scores, our system is supervised to generate textual answers from which numeric predictions are parsed and evaluated with standard regression and ranking metrics; on held-out NISQA clips, the double-ended model attains a MOS mean absolute error (MAE) of 0.41 with Pearson correlation of 0.86, with competitive performance on dimension-wise tasks. Beyond these quantitative gains, it offers a flexible natural-language interface in which the language model acts as an audio quality expert: practitioners can query arbitrary aspects of degradations, prompt the model to emulate different listener profiles to capture human variability and produce diverse but plausible judgments rather than a single deterministic score, and thereby reduce reliance on large-scale crowdsourced tests and their monetary cost."}
{"id": "2512.08244", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08244", "abs": "https://arxiv.org/abs/2512.08244", "authors": ["Ye Ke", "Zhengnan Fu", "Junyi Yang", "Hongyang Shang", "Arindam Basu"], "title": "1024-Channel 0.8V 23.9-nW/Channel Event-based Compute In-memory Neural Spike Detector", "comment": null, "summary": "The increasing data rate has become a major issue confronting next-generation intracortical brain-machine interfaces (iBMIs). The scaling number of recording sites requires complex analog wiring and lead to huge digitization power consumption. Compressive event-based neural frontends have been used in high-density neural implants to support the simultaneous recording of more channels. Event-based frontends (EBF) convert recorded signals into asynchronous digital events via delta modulation and can inherently achieve considerable compression. But EBFs are prone to false events that do not correspond to neural spikes. Spike detection (SPD) is a key process in the iBMI pipeline to detect neural spikes and further reduce the data rate. However, conventional digital SPD suffers from the increasing buffer size and frequent memory access power, and conventional spike emphasizers are not compatible with EBFs. In this work we introduced an event-based spike detection (Ev-SPD) algorithm for scalable compressive EBFs. To implement the algorithm effectively, we proposed a novel low-power 10-T eDRAM-SRAM hybrid random-access memory in-memory computing bitcell for event processing. We fabricated the proposed 1024-channel IMC SPD macro in a 65nm process and tested the macro with both synthetic dataset and Neuropixel recordings. The proposed macro achieved a high spike detection accuracy of 96.06% on a synthetic dataset and 95.08% similarity and 0.05 firing pattern MAE on Neuropixel recordings. Our event-based IMC SPD macro achieved a high per channel spike detection energy efficiency of 23.9 nW per channel and an area efficiency of 375 um^2 per channel. Our work presented a SPD scheme compatible with compressive EBFs for high-density iBMIs, achieving ultra-low power consumption with an IMC architecture while maintaining considerable accuracy."}
{"id": "2512.08403", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.08403", "abs": "https://arxiv.org/abs/2512.08403", "authors": ["Yupei Li", "Li Wang", "Yuxiang Wang", "Lei Wang", "Rizhao Cai", "Jie Shi", "Björn W. Schuller", "Zhizheng Wu"], "title": "DFALLM: Achieving Generalizable Multitask Deepfake Detection by Optimizing Audio LLM Components", "comment": null, "summary": "Audio deepfake detection has recently garnered public concern due to its implications for security and reliability. Traditional deep learning methods have been widely applied to this task but often lack generalisability when confronted with newly emerging spoofing techniques and more tasks such as spoof attribution recognition rather than simple binary classification. In principle, Large Language Models (LLMs) are considered to possess the needed generalisation capabilities. However, previous research on Audio LLMs (ALLMs) indicates a generalization bottleneck in audio deepfake detection performance, even when sufficient data is available. Consequently, this study investigates the model architecture and examines the effects of the primary components of ALLMs, namely the audio encoder and the text-based LLM. Our experiments demonstrate that the careful selection and combination of audio encoders and text-based LLMs are crucial for unlocking the deepfake detection potential of ALLMs. We further propose an ALLM structure capable of generalizing deepfake detection abilities to out-of-domain spoofing tests and other deepfake tasks, such as spoof positioning and spoof attribution recognition. Our proposed model architecture achieves state-of-the-art (SOTA) performance across multiple datasets, including ASVSpoof2019, InTheWild, and Demopage, with accuracy reaching up to 95.76% on average, and exhibits competitive capabilities in other deepfake detection tasks such as attribution, and localisation compared to SOTA audio understanding models. Data and codes are provided in supplementary materials."}
{"id": "2512.08263", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08263", "abs": "https://arxiv.org/abs/2512.08263", "authors": ["Jijia Tian", "Wangqian Chen", "Junting Chen", "Pooi-Yuen Kam"], "title": "Geometry-Aligned Differential Privacy for Location-Safe Federated Radio Map Construction", "comment": null, "summary": "Radio maps that describe spatial variations in wireless signal strength are widely used to optimize networks and support aerial platforms. Their construction requires location-labeled signal measurements from distributed users, raising fundamental concerns about location privacy. Even when raw data are kept local, the shared model updates can reveal user locations through their spatial structure, while naive noise injection either fails to hide this leakage or degrades model accuracy. This work analyzes how location leakage arises from gradients in a virtual-environment radio map model and proposes a geometry-aligned differential privacy mechanism with heterogeneous noise tailored to both confuse localization and cover gradient spatial patterns. The approach is theoretically supported with a convergence guarantee linking privacy strength to learning accuracy. Numerical experiments show the approach increases attacker localization error from 30 m to over 180 m, with only 0.2 dB increase in radio map construction error compared to a uniform-noise baseline."}
{"id": "2512.08812", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.08812", "abs": "https://arxiv.org/abs/2512.08812", "authors": ["Anna Jordanous"], "title": "Emovectors: assessing emotional content in jazz improvisations for creativity evaluation", "comment": "Presented at IEEE Big Data 2025 3rd Workshop on AI Music Generation (AIMG 2025). https://www.intellisky.org/workshops/AIMG2025/workshop_AIMG2025.html", "summary": "Music improvisation is fascinating to study, being essentially a live demonstration of a creative process. In jazz, musicians often improvise across predefined chord progressions (leadsheets). How do we assess the creativity of jazz improvisations? And can we capture this in automated metrics for creativity for current LLM-based generative systems? Demonstration of emotional involvement is closely linked with creativity in improvisation. Analysing musical audio, can we detect emotional involvement? This study hypothesises that if an improvisation contains more evidence of emotion-laden content, it is more likely to be recognised as creative. An embeddings-based method is proposed for capturing the emotional content in musical improvisations, using a psychologically-grounded classification of musical characteristics associated with emotions. Resulting 'emovectors' are analysed to test the above hypothesis, comparing across multiple improvisations. Capturing emotional content in this quantifiable way can contribute towards new metrics for creativity evaluation that can be applied at scale."}
{"id": "2512.08386", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08386", "abs": "https://arxiv.org/abs/2512.08386", "authors": ["Yixuan Guo", "Mingliang Xiong", "Qingwen Liu"], "title": "Self-Alignment Resonant Beam Empowers Beamforming without Estimation and Control for 6G IoT", "comment": null, "summary": "The integration of communication, sensing, and wireless power transfer (WPT) is a cornerstone of 6G intelligent IoT. However, relying on traditional beamforming imposes prohibitive overheads due to complex channel state information (CSI) estimation and active beam scanning, particularly in dynamic environments. This paper presents a comprehensive review of the radio frequency resonant beam system (RF-RBS), a native physical-layer paradigm that circumvents these limitations. By deploying retro-directive antenna arrays (RAA) at transceivers, RF-RBS establishes a self-sustaining cyclic electromagnetic loop. This mechanism inherently enables self-aligning, high-gain beamforming through positive feedback, eliminating the reliance on digital CSI processing. We analyze the system's architecture and its capability to support high-efficiency WPT, robust communication, and millimeter-level passive positioning. Finally, we evaluate the implementation challenges and strategic value of RF-RBS in latency-sensitive 6G scenarios, including unmanned systems and industrial automation."}
{"id": "2512.08419", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08419", "abs": "https://arxiv.org/abs/2512.08419", "authors": ["F. Philibert Andriniriniaimalaza", "Nour Mohammad Murad", "George Balan", "Habachi Bilal", "Nirilalaina Randriatefison", "Abdel Khoodaruth", "Charles Bernard Andrianirina", "Blaise Ravelo"], "title": "Hybrid Fuzzy Logic and Shading-Aware Particle Swarm Optimization for Dynamic Photovoltaic Shading Faults Mitigation", "comment": null, "summary": "Shading faults remain one of the most critical challenges affecting photovoltaic (PV) system efficiency, as they not only reduce power generation but also disturb maximum power point tracking (MPPT). To address this issue, this study introduces a hybrid optimization framework that combines Fuzzy Logic Control (FLC) with a Shading-Aware Particle Swarm Optimization (SA-PSO) method. The proposed scheme is designed to adapt dynamically to both partial shading (20%-80%) and complete shading events, ensuring reliable global maximum power point (GMPP) detection. In this approach, the fuzzy controller provides rapid decision support based on shading patterns, while SA-PSO accelerates the search process and prevents the system from becoming trapped in local minima. A comparative performance assessment with the conventional Perturb and Observe (P\\&O) algorithm highlights the advantages of the hybrid model, showing up to an 11.8% improvement in power output and a 62% reduction in tracking time. These results indicate that integrating intelligent control with shading-aware optimization can significantly enhance the resilience and energy yield of PV systems operating under complex real-world conditions."}
{"id": "2512.08469", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08469", "abs": "https://arxiv.org/abs/2512.08469", "authors": ["Gilles Monnoyer", "Jérôme Louveaux", "Laurence Defraigne", "Baptiste Sambon", "Luc vandendorpe"], "title": "Aliasing in Near-Field Array Ambiguity Functions: a Spatial Frequency-Domain Framework", "comment": "17 pages, 14 figures", "summary": "Next-generation communication and localization systems increasingly rely on extremely large-scale arrays (XL-arrays), which promise unprecedented spatial resolution and new functionalities. These gains arise from their inherent operation in the near field (NF) regime, where the spherical nature of the wavefront can no longer be ignored; consequently, characterizing the ambiguity function -- which amounts to the matched beam pattern -- is considerably more challenging. Implementing very wide apertures with half-wavelength element spacing is costly and complex. This motivates thinning the array (removing elements), which introduces intricate aliasing structures, i.e., grating lobes. Whereas prior work has addressed this challenge using approximations tailored to specific array geometries, this paper develops a general framework that reveals the fundamental origins and geometric behavior of grating lobes in near-field ambiguity functions. Using a local spatial-frequency analysis of steering signals, we derive a systematic methodology to model NF grating lobes as aliasing artifacts, quantifying their structure on the AF, and providing design guidelines for XL-arrays that operate within aliasing-safe regions. We further connect our framework to established far-field principles. Finally, we demonstrate the practical value of the approach by deriving closed-form expressions for aliasing-free regions in canonical uniform linear arrays and uniform circular arrays."}
{"id": "2512.08509", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08509", "abs": "https://arxiv.org/abs/2512.08509", "authors": ["Ashutosh Prajapati", "Prathapasinghe Dharmawansa", "Marco Di Renzo", "Italo Atzeni"], "title": "LoS+NLoS Holographic MIMO: Analysis and Application of Wavenumber-Division Multiplexing", "comment": "Submitted to IEEE Transactions on Wireless Communications", "summary": "Holographic multiple-input multiple-output (MIMO) enables electrically large continuous apertures, overcoming the physical scaling limits of conventional MIMO architectures with half-wavelength spacing. Their near-field operating regime requires channel models that jointly capture line-of-sight (LoS) and non-line-of-sight (NLoS) components in a physically consistent manner. Existing studies typically treat these components separately or rely on environment-specific multipath models. In this work, we develop a unified LoS+NLoS channel representation for holographic lines that integrates spatial-sampling-based and expansion-based formulations. Building on this model, we extend the wavenumber-division multiplexing (WDM) framework, originally introduced for purely LoS channels, to the LoS+NLoS scenario. Applying WDM to the NLoS component yields its angular-domain representation, enabling direct characterization through the power spectral factor and power spectral density. We further derive closed-form characterizations for isotropic and non-isotropic scattering, with the former recovering Jakes' isotropic model. Lastly, we evaluate the resulting degrees of freedom and ergodic capacity, showing that incorporating the NLoS component substantially improves the performance relative to the purely LoS case."}
{"id": "2512.08516", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08516", "abs": "https://arxiv.org/abs/2512.08516", "authors": ["Ainna Yue Moreno-Locubiche", "Josep Vidal"], "title": "Beyond Diagonal RIS-assisted MIMO Transmission: Beamforming Gain and Capacity Optimization", "comment": "6 pages, 7 figures", "summary": "Reconfigurable Intelligent Surfaces (RIS) have emerged as a transformative technology in wireless communications, offering unprecedented control over signal propagation. This study focuses on passive beyond diagonal reconfigurable intelligent surface (BD-RIS), which has been proposed to generalize conventional diagonal RIS, in Multiple-Input Multiple-Output (MIMO) downlink (DL) communication systems. We compare the performance of transmit beamforming (TxBF) and MIMO capacity transmission with waterfilling power allocation in the millimeter wave (mmWave) band, where propagation primarily occurs under line-of-sight (LOS) conditions. In the lack of closed-form expressions for the optimal RIS elements in either case, our approach adopts a gradient-based optimization approach requiring lower complexity than the solution in arXiv:2406.02170. Numerical results reveal that BD-RIS significantly outperforms traditional diagonal RIS in terms of spectral efficiency and coverage"}
{"id": "2512.08556", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08556", "abs": "https://arxiv.org/abs/2512.08556", "authors": ["Ainna Yue Moreno-Locubiche", "Josep Vidal", "Olga Muñoz-Medina", "Margarita Cabrera-Bean"], "title": "Contextual Bandits and Reconfigurable Intelligent Surfaces for Predictive LTM Handover Decisions", "comment": "6 pages, 3 figures", "summary": "This article addresses the challenge of optimizing handover (HO) in next-generation wireless networks by integrating Reconfigurable Intelligent Surfaces (RIS), predicting received signal power, and utilizing learning-based decision-making. A conventional reactive HO mechanism, such as lower-layer triggered mobility (LTM), is enhanced through linear prediction to anticipate link degradation. Additionally, the use of RIS helps to mitigate signal blockage and extend coverage. An online trained non-linear Contextual Multi-Armed Bandit (CMAB) agent selects target gNBs based on context features, which reduces unnecessary HO and signaling overhead. Extensive simulations evaluate eight combinations of these techniques under realistic mobility and channel conditions. Results show that CMAB and RSRP prediction consistently reduce the number of HO, ping-pong rate and cell preparations, while RIS improves link reliability."}
{"id": "2512.08717", "categories": ["eess.SP", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.08717", "abs": "https://arxiv.org/abs/2512.08717", "authors": ["Oscar Romero", "Néstor Thome"], "title": "Applications of Singular Entropy to Signals and Singular Smoothness to Images", "comment": "13 pages, 6 figures", "summary": "This paper explores signal and image analysis by using the Singular Value Decomposition (SVD) and its extension, the Generalized Singular Value Decomposition (GSVD). A key strength of SVD lies in its ability to separate information into orthogonal subspaces. While SVD is a well-established tool in ECG analysis, particularly for source separation, this work proposes a refined method for selecting a threshold to distinguish between maternal and fetal components more effectively. In the first part of the paper, the focus is onmedical signal analysis,where the concepts of Energy Gap Variation (EGV) and Singular Energy are introduced to isolate fetal and maternal ECG signals, improving the known ones. Furthermore, the approach is significantly enhanced by the application of GSVD, which provides additional discriminative power for more accurate signal separation. The second part introduces a novel technique called Singular Smoothness, developed for image analysis. This method incorporates Singular Entropy and the Frobenius normto evaluate information density, and is applied to the detection of natural anomalies such asmountain fractures and burned forest regions. Numerical experiments are presented to demonstrate the effectiveness of the proposed approaches."}
{"id": "2512.08746", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08746", "abs": "https://arxiv.org/abs/2512.08746", "authors": ["Federica Fieramosca", "Vittorio Rampa", "Michele D'Amico", "Stefano Savazzi"], "title": "RF sensing with dense IoT network graphs: An EM-informed analysis", "comment": "accepted to IEEE Internet of Things Journal", "summary": "Radio Frequency (RF) sensing is attracting interest in research, standardization, and industry, especially for its potential in Internet of Things (IoT) applications. By leveraging the properties of the ElectroMagnetic (EM) waves used in wireless networks, RF sensing captures environmental information such as the presence and movement of people and objects, enabling passive localization and vision applications. This paper investigates the theoretical bounds on accuracy and resolution for RF sensing systems within dense networks. It employs an EM model to predict the effects of body blockage in various scenarios. To detect human movements, the paper proposes a deep graph neural network, trained on Received Signal Strength (RSS) samples generated from the EM model. These samples are structured as dense graphs, with nodes representing antennas and edges as radio links. Focusing on the problem of identifying the number of human subjects co-present in a monitored area over time, the paper analyzes the theoretical limits on the number of distinguishable subjects, exploring how these limits depend on factors such as the number of radio links, the size of the monitored area and the subjects physical dimensions. These bounds enable the prediction of the system performance during network pre-deployment stages. The paper also presents the results of an indoor case study, which demonstrate the effectiveness of the approach and confirm the model's predictive potential in the network design stages."}
{"id": "2512.08779", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08779", "abs": "https://arxiv.org/abs/2512.08779", "authors": ["Emre Havazli", "Shadi Oveisgharan", "Michael Denbina", "Brian Hawkins"], "title": "Evaluating the Deformation Measurement Accuracy Using Low-SNR Radars for Future InSAR Missions", "comment": null, "summary": "Interferometric Synthetic Aperture Radar (InSAR) is a powerful tool for monitoring surface deformation with high precision. However, low Signal-to-Noise Ratio (SNR) conditions, common in regions with low backscatter, can degrade phase coherence and compromise displacement accuracy. In this study, we quantify the impact of low-SNR conditions on InSAR-derived displacement using L-band UAVSAR data collected over the San Andreas Fault and Greenland ice sheet. We simulate low-SNR conditions by degrading the Noise-Equivalent Sigma Zero (NESZ) to $-15~\\mathrm{dB}$ and assess the resulting effects on interferometric coherence, phase unwrapping, and time series inversion. The displacement accuracy of 4mm in single interferogram can be achieved by taking looks for the signal decorrelation of 0.6 and SNR between -9dB to -10dB. Our findings indicate that even under low-SNR conditions, a velocity precision of $0.5~\\mathrm{cm/yr}$ can be achieved in comparison to high-SNR conditions. By applying multilooking with an 8x8 window, we significantly improve coherence and eliminate this bias, demonstrating that low-SNR systems can achieve comparable precision to high-SNR systems at the expense of spatial resolution. These results have important implications for the design of future cost-effective SAR missions, such as Surface Deformation and Change (SDC), and the optimization of InSAR processing techniques in challenging environments."}
{"id": "2512.08799", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.08799", "abs": "https://arxiv.org/abs/2512.08799", "authors": ["Boxuan Wen", "Junyu Luo"], "title": "Delay-Oriented Distributed Scheduling with TransGNN", "comment": "10 pages, 3 figures", "summary": "Minimizing transmission delay in wireless multi-hop networks is a fundamental yet challenging task due to the complex coupling among interference, queue dynamics, and distributed control. Traditional scheduling algorithms, such as max-weight or queue-length-based policies, primarily aim to optimize throughput but often suffer from high latency, especially in heterogeneous or dynamically changing topologies. Recent learning-based approaches, particularly those employing Graph Neural Networks (GNNs), have shown promise in capturing spatial interference structures. However, conventional Graph Convolutional Networks (GCNs) remain limited by their local aggregation mechanism and their inability to model long-range dependencies within the conflict graph. To address these challenges, this paper proposes a delay-oriented distributed scheduling framework based on Transformer GNN. The proposed model employs an attention-based graph encoder to generate adaptive per-link utility scores that reflect both queue backlog and interference intensity. A Local Greedy Solver (LGS) then utilizes these utilities to construct a feasible independent set of links for transmission, ensuring distributed and conflict-free scheduling."}
{"id": "2512.08887", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08887", "abs": "https://arxiv.org/abs/2512.08887", "authors": ["Nakul Singh", "Coleman DeLude", "Mark Davenport", "Justin Romberg"], "title": "A Fast Broadband Beamspace Transformation", "comment": null, "summary": "We present a new computationally efficient method for multi-beamforming in the broadband setting. Our \"fast beamspace transformation\" forms $B$ beams from $M$ sensor outputs using a number of operations per sample that scales linearly (to within logarithmic factors) with $M$ when $B\\sim M$. While the narrowband version of this transformation can be performed efficiently with a spatial fast Fourier transform, the broadband setting requires coherent processing of multiple array snapshots simultaneously. Our algorithm works by taking $N$ samples off of each of $M$ sensors and encoding the sensor outputs into a set of coefficients using a special non-uniform spaced Fourier transform. From these coefficients, each beam is formed by solving a small system of equations that has Toeplitz structure. The total runtime complexity is $\\mathcal{O}(M\\log N+B\\log N)$ operations per sample, exhibiting essentially the same scaling as in the narrowband case and vastly outperforming broadband beamformers based on delay and sum whose computations scale as $\\mathcal{O}(MB)$. Alongside a careful mathematical formulation and analysis of our fast broadband beamspace transform, we provide a host of numerical experiments demonstrating the algorithm's favorable computational scaling and high accuracy. Finally, we demonstrate how tasks such as interpolating to ``off-grid\" angles and nulling an interferer are more computationally efficient when performed directly in beamspace."}
{"id": "2512.08903", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08903", "abs": "https://arxiv.org/abs/2512.08903", "authors": ["Ramin Babaee", "Shahab Oveis Gharan", "Martin Bouchard"], "title": "Timing-Error Optimized Architecture for Current-Steering DACs", "comment": null, "summary": "We propose a novel digital-to-analog converter (DAC) weighting architecture that statistically minimizes the distortion caused by random timing mismatches among current sources. To decode the DAC input codewords into corresponding DAC switches, we present three algorithms with varying computational complexities. We perform high-level Matlab simulations to illustrate the dynamic performance improvement over the segmented structure."}
{"id": "2512.08909", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08909", "abs": "https://arxiv.org/abs/2512.08909", "authors": ["Ramin Babaee", "Shahab Oveis Gharan", "Martin Bouchard"], "title": "Architecture Design for Rise/Fall Asymmetry Glitch Minimization in Current-Steering DACs", "comment": null, "summary": "Current-steering digital-to-analog converter (DAC) is a prominent architecture that is commonly used in high-speed applications such as optical communications. One of the shortcomings of this architecture is the output glitches that are input dependent and degrade the dynamic performance of the DAC. We investigate DAC glitches that arise from asymmetry in the fall/rise response of DAC switches. We formulate a glitch metric that defines the overall DAC performance, which is then used to find a novel DAC weighting scheme. Numerical simulations show that the proposed architecture can potentially provide a significant performance advantage compared to the segmented structure."}
{"id": "2512.07872", "categories": ["cs.SD", "eess.AS", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.07872", "abs": "https://arxiv.org/abs/2512.07872", "authors": ["Ishaan Kunwar", "Henry Cantor", "Tyler Rizzo", "Ayaan Qayyum"], "title": "LocaGen: Sub-Sample Time-Delay Learning for Beam Localization", "comment": "7 pages", "summary": "The goal of LocaGen is to improve the localization performance of audio signals in the 2-D beam localization problem. LocaGen reduces sampling quantization errors through machine learning models trained on realistic synthetic data generated by a simulation. The system increases the accuracy of both direction-of-arrival (DOA) and precise location estimation of an audio beam from an array of three microphones. We demonstrate LocaGen's efficacy on a low-powered embedded system with an increased localization accuracy with a minimal increase in real-time resource usage. LocaGen was demonstrated to reduce DOA error by approximately 67% even with a microphone array of only 10 kHz in audio processing."}

{"id": "2512.08973", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2512.08973", "abs": "https://arxiv.org/abs/2512.08973", "authors": ["Karamvir Singh"], "title": "Enhancing Automatic Speech Recognition Through Integrated Noise Detection Architecture", "comment": "5 figures", "summary": "This research presents a novel approach to enhancing automatic speech recognition systems by integrating noise detection capabilities directly into the recognition architecture. Building upon the wav2vec2 framework, the proposed method incorporates a dedicated noise identification module that operates concurrently with speech transcription. Experimental validation using publicly available speech and environmental audio datasets demonstrates substantial improvements in transcription quality and noise discrimination. The enhanced system achieves superior performance in word error rate, character error rate, and noise detection accuracy compared to conventional architectures. Results indicate that joint optimization of transcription and noise classification objectives yields more reliable speech recognition in challenging acoustic conditions."}
{"id": "2512.09066", "categories": ["cs.SD", "cs.AI", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.09066", "abs": "https://arxiv.org/abs/2512.09066", "authors": ["Šimon Sedláček", "Sara Barahona", "Bolaji Yusuf", "Laura Herrera-Alarcón", "Santosh Kesiraju", "Cecilia Bolaños", "Alicia Lozano-Diez", "Sathvik Udupa", "Fernando López", "Allison Ferner", "Ramani Duraiswami", "Jan Černocký"], "title": "ORCA: Open-ended Response Correctness Assessment for Audio Question Answering", "comment": null, "summary": "Evaluating open-ended responses from large audio language models (LALMs) is challenging because human annotators often genuinely disagree on answer correctness due to multiple valid interpretations, partial correctness, and subjective judgment. Traditional metrics reporting only mean scores fail to capture this uncertainty. We present ORCA (Open-ended Response Correctness Assessment), a framework that models the variability in human judgments using Beta distributions to predict both expected correctness and uncertainty. Our three-stage annotation framework combines human judgment with structured feedback and iterative refinement to simultaneously curate training data and improve benchmark quality. We collected 11,721 annotations across 3,580 question-answer pairs from 15 LALMs on two audio QA benchmarks, achieving inter-annotator agreement of 0.82 (Krippendorff's alpha). ORCA achieves 0.91 Spearman correlation with mean human judgments, matching or outperforming LLM-judge baselines while providing uncertainty estimates and requiring significantly less compute. We release our models, code, and curated dataset."}
{"id": "2512.09285", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.09285", "abs": "https://arxiv.org/abs/2512.09285", "authors": ["Shaoying Wang", "Hansong Zhou", "Yukun Yuan", "Xiaonan Zhang"], "title": "Who Speaks What from Afar: Eavesdropping In-Person Conversations via mmWave Sensing", "comment": null, "summary": "Multi-participant meetings occur across various domains, such as business negotiations and medical consultations, during which sensitive information like trade secrets, business strategies, and patient conditions is often discussed. Previous research has demonstrated that attackers with mmWave radars outside the room can overhear meeting content by detecting minute speech-induced vibrations on objects. However, these eavesdropping attacks cannot differentiate which speech content comes from which person in a multi-participant meeting, leading to potential misunderstandings and poor decision-making. In this paper, we answer the question ``who speaks what''. By leveraging the spatial diversity introduced by ubiquitous objects, we propose an attack system that enables attackers to remotely eavesdrop on in-person conversations without requiring prior knowledge, such as identities, the number of participants, or seating arrangements. Since participants in in-person meetings are typically seated at different locations, their speech induces distinct vibration patterns on nearby objects. To exploit this, we design a noise-robust unsupervised approach for distinguishing participants by detecting speech-induced vibration differences in the frequency domain. Meanwhile, a deep learning-based framework is explored to combine signals from objects for speech quality enhancement. We validate the proof-of-concept attack on speech classification and signal enhancement through extensive experiments. The experimental results show that our attack can achieve the speech classification accuracy of up to $0.99$ with several participants in a meeting room. Meanwhile, our attack demonstrates consistent speech quality enhancement across all real-world scenarios, including different distances between the radar and the objects."}
{"id": "2512.09504", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.09504", "abs": "https://arxiv.org/abs/2512.09504", "authors": ["Kang Yin", "Chunyu Qiang", "Sirui Zhao", "Xiaopeng Wang", "Yuzhe Liang", "Pengfei Cai", "Tong Xu", "Chen Zhang", "Enhong Chen"], "title": "DMP-TTS: Disentangled multi-modal Prompting for Controllable Text-to-Speech with Chained Guidance", "comment": null, "summary": "Controllable text-to-speech (TTS) systems face significant challenges in achieving independent manipulation of speaker timbre and speaking style, often suffering from entanglement between these attributes. We present DMP-TTS, a latent Diffusion Transformer (DiT) framework with explicit disentanglement and multi-modal prompting. A CLAP-based style encoder (Style-CLAP) aligns cues from reference audio and descriptive text in a shared space and is trained with contrastive learning plus multi-task supervision on style attributes. For fine-grained control during inference, we introduce chained classifier-free guidance (cCFG) trained with hierarchical condition dropout, enabling independent adjustment of content, timbre, and style guidance strengths. Additionally, we employ Representation Alignment (REPA) to distill acoustic-semantic features from a pretrained Whisper model into intermediate DiT representations, stabilizing training and accelerating convergence. Experiments show that DMP-TTS delivers stronger style controllability than open-source baselines while maintaining competitive intelligibility and naturalness. Code and demos will be available at https://y61329697.github.io/DMP-TTS/."}
{"id": "2512.09000", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2512.09000", "abs": "https://arxiv.org/abs/2512.09000", "authors": ["Jinyoung Park", "Won Jang", "Jiwoong Park"], "title": "LG Uplus System with Multi-Speaker IDs and Discriminator-based Sub-Judges for the WildSpoof Challenge", "comment": "3 pages, 2 figures, 2 tables", "summary": "This paper describes our submission to the WildSpoof Challenge Track 2, which focuses on spoof-aware speaker verification (SASV) in the presence of high-quality text-to-speech (TTS) attacks. We adopt a ResNet-221 back-bone and study two speaker-labeling strategies, namelyDual-Speaker IDs and Multi-Speaker IDs, to explicitly enlarge the margin between bona fide and generated speech in the embedding space. In addition, we propose discriminator-based sub-judge systems that reuse internal features from HiFi-GAN and BigVGAN discriminators, aggregated via multi-query multi-head attentive statistics pooling(MQMHA). Experimental results on the SpoofCeleb corpus show that our system design is effective in improving agnostic detection cost function (a-DCF)."}
{"id": "2512.08947", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.08947", "abs": "https://arxiv.org/abs/2512.08947", "authors": ["Demerson N. Gonçalves", "João T. Dias"], "title": "New Algorithm for Structured OFDM Channel Estimation using Subgroup Duality", "comment": "17 pages, 4 figures", "summary": "This paper presents a group-theoretic framework for structured channel estimation in Orthogonal Frequency Division Multiplexing (OFDM). By modeling subcarriers as the cyclic group \\(\\mathbb{Z}_N\\), we show that nulling a subgroup \\(H \\subseteq \\mathbb{Z}_N\\) constrains the channel impulse response to its annihilator \\(H^\\perp\\) in the dual domain. A low-complexity estimator is proposed that detects such structure by evaluating energy concentration across candidate annihilators. Simulations demonstrate consistent gains in mean squared error, bit error rate, and throughput compared with least-squares and linear minimum mean square error baselines, achieving competitive performance with substantially lower complexity and preserved interpretability."}
{"id": "2512.09221", "categories": ["eess.AS", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.09221", "abs": "https://arxiv.org/abs/2512.09221", "authors": ["Eugenia San Segundo", "Aurora López-Jareño", "Xin Wang", "Junichi Yamagishi"], "title": "Human perception of audio deepfakes: the role of language and speaking style", "comment": "Submitted to Speech Communication", "summary": "Audio deepfakes have reached a level of realism that makes it increasingly difficult to distinguish between human and artificial voices, which poses risks such as identity theft or spread of disinformation. Despite these concerns, research on humans' ability to identify deepfakes is limited, with most studies focusing on English and very few exploring the reasons behind listeners' perceptual decisions. This study addresses this gap through a perceptual experiment in which 54 listeners (28 native Spanish speakers and 26 native Japanese speakers) classified voices as natural or synthetic, and justified their choices. The experiment included 80 stimuli (50% artificial), organized according to three variables: language (Spanish/Japanese), speech style (audiobooks/interviews), and familiarity with the voice (familiar/unfamiliar). The goal was to examine how these variables influence detection and to analyze qualitatively the reasoning behind listeners' perceptual decisions. Results indicate an average accuracy of 59.11%, with higher performance on authentic samples. Judgments of vocal naturalness rely on a combination of linguistic and non-linguistic cues. Comparing Japanese and Spanish listeners, our qualitative analysis further reveals both shared cues and notable cross-linguistic differences in how listeners conceptualize the \"humanness\" of speech. Overall, participants relied primarily on suprasegmental and higher-level or extralinguistic characteristics - such as intonation, rhythm, fluency, pauses, speed, breathing, and laughter - over segmental features. These findings underscore the complexity of human perceptual strategies in distinguishing natural from artificial speech and align partly with prior research emphasizing the importance of prosody and phenomena typical of spontaneous speech, such as disfluencies."}
{"id": "2512.09098", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.09098", "abs": "https://arxiv.org/abs/2512.09098", "authors": ["Shixiong Wang", "Wei Dai", "Geoffrey Ye Li"], "title": "A New Particle Filter for Target Tracking in MIMO OFDM Integrated Sensing and Communications", "comment": null, "summary": "Particle filtering for target tracking using multi-input multi-output (MIMO) pulse-Doppler radars faces three long-standing obstacles: a) the absence of reliable likelihood models for raw radar data; b) the computational and statistical complications that arise when nuisance parameters (e.g., complex path gains) are augmented into state vectors; and c) the prohibitive computational burden of extracting noisy measurements of range, Doppler, and angles from snapshots. Motivated by an optimization-centric interpretation of Bayes' rule, this article addresses these challenges by proposing a new particle filtering framework that evaluates each hypothesized state using a tailored cost function, rather than relying on an explicit likelihood relation. The framework yields substantial reductions in both running time and tracking error compared to existing schemes. In addition, we examine the implementation of the proposed particle filter in MIMO orthogonal frequency-division multiplexing (OFDM) systems, aiming to equip modern communication infrastructure with integrated sensing and communications (ISAC) capabilities. Experiments suggest that MIMO-OFDM with pulse-Doppler processing holds considerable promise for ISAC, particularly when wide bandwidth, extended on-target time, and large antenna aperture are utilized."}
{"id": "2512.09713", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2512.09713", "abs": "https://arxiv.org/abs/2512.09713", "authors": ["Philipp Grundhuber", "Mhd Modar Halimeh", "Martin Strauß", "Emanuël A. P. Habets"], "title": "Robust Speech Activity Detection in the Presence of Singing Voice", "comment": "This paper has been published in: 2025 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)", "summary": "Speech Activity Detection (SAD) systems often misclassify singing as speech, leading to degraded performance in applications such as dialogue enhancement and automatic speech recognition. We introduce Singing-Robust Speech Activity Detection ( SR-SAD ), a neural network designed to robustly detect speech in the presence of singing. Our key contributions are: i) a training strategy using controlled ratios of speech and singing samples to improve discrimination, ii) a computationally efficient model that maintains robust performance while reducing inference runtime, and iii) a new evaluation metric tailored to assess SAD robustness in mixed speech-singing scenarios. Experiments on a challenging dataset spanning multiple musical genres show that SR-SAD maintains high speech detection accuracy (AUC = 0.919) while rejecting singing. By explicitly learning to distinguish between speech and singing, SR-SAD enables more reliable SAD in mixed speech-singing scenarios."}
{"id": "2512.09155", "categories": ["eess.SP", "cs.AR", "cs.MS"], "pdf": "https://arxiv.org/pdf/2512.09155", "abs": "https://arxiv.org/abs/2512.09155", "authors": ["Mostafa Darvishi"], "title": "A Hybrid Residue Floating Numerical Architecture for High Precision Arithmetic on FPGAs", "comment": null, "summary": "Floating point arithmetic remains expensive on FPGA platforms due to wide datapaths and normalization logic, motivating alternative representations that preserve dynamic range at lower cost. This work introduces the Hybrid Residue Floating Numerical Architecture (HRFNA), a unified arithmetic system that combines carry free residue channels with a lightweight floating point scaling factor. We develop the full mathematical framework, derive bounded error normalization rules, and present FPGA optimized microarchitectures for modular multiplication, exponent management, and hybrid reconstruction. HRFNA is implemented on a Xilinx ZCU104, with Vitis simulation, RTL synthesis, and on chip ILA traces confirming cycle accurate correctness. The architecture achieves over 2.1 times throughput improvement and 38-52 percent LUT reduction compared to IEEE 754 single precision baselines while maintaining numerical stability across long iterative sequences. These results demonstrate that HRFNA offers an efficient and scalable alternative to floating point computation on modern FPGA devices."}
{"id": "2512.08973", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2512.08973", "abs": "https://arxiv.org/abs/2512.08973", "authors": ["Karamvir Singh"], "title": "Enhancing Automatic Speech Recognition Through Integrated Noise Detection Architecture", "comment": "5 figures", "summary": "This research presents a novel approach to enhancing automatic speech recognition systems by integrating noise detection capabilities directly into the recognition architecture. Building upon the wav2vec2 framework, the proposed method incorporates a dedicated noise identification module that operates concurrently with speech transcription. Experimental validation using publicly available speech and environmental audio datasets demonstrates substantial improvements in transcription quality and noise discrimination. The enhanced system achieves superior performance in word error rate, character error rate, and noise detection accuracy compared to conventional architectures. Results indicate that joint optimization of transcription and noise classification objectives yields more reliable speech recognition in challenging acoustic conditions."}
{"id": "2512.09194", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.09194", "abs": "https://arxiv.org/abs/2512.09194", "authors": ["Anton Schlegel", "Jason M/ Merlo", "Samuel Wagner", "John B. Lancaster", "Jeffrey A. Nanzer"], "title": "Secure Wireless Communication Using Distributed Coherent Transmission and Spatial Signal Decomposition", "comment": null, "summary": "We present a new approach to secure wireless communications using coherent distributed transmission of signals that are spatially decomposed between a two-element distributed antenna array. High-accuracy distributed coordination of microwave wireless systems supports the ability to transmit different parts of a signal from separate transmitters such that they combine coherently at a designated destination. In this paper we explore this concept using a two-element coherent distributed phased array where each of the two transmitters sends a separate component of a communication signal where each symbol is decomposed into a sum of two pseudo-random signal vectors, the coherent summation of which yields the intended symbol. By directing the transmission to an intended receiver using distributed beamforming, the summation of the two vector components is largely confined to a spatial region at the destination receiver. We implement the technique in a 50 wavelength array operating at 3 GHz. We evaluate the symbol error ratio. (SER) in two-dimensional space through simulation and measurement, showing the approach yields a spatially confined secure region where the information is recoverable(i.e., the received signal has low SER), and outside of which the information is unrecoverable (high SER). The proposed system is also compared against a traditional beamforming system where each node sends the same data. We validate experimentally that our approach achieves a low SER of 0.0082 at broadside and a SER above 0.25 at all other locations compared to a traditional beamforming approach that achieves a SER of 0 at all locations measured."}
{"id": "2512.09432", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.09432", "abs": "https://arxiv.org/abs/2512.09432", "authors": ["Min Liu", "Yue Xiao", "Shuaixin Yang", "Gang Wu", "Xianfu Lei", "Wei Xiang"], "title": "Joint Channel Estimation and Localization in Pinching-Antenna OFDM Systems: The Blessing of Multipath", "comment": null, "summary": "Pinching-antenna systems (PASS) have recently attracted considerable attention owing to their capability of flexibly reconfiguring large-scale wireless channels. Motivated by this potential, we investigate the issue of joint localization and channel estimation for the uplink PASS in the presence of multipath dispersion. To this end, a comprehensive multi-user orthogonal frequency division multiplexing (OFDM) uplink PASS model is first established, where the use of a cyclic prefix (CP) enables the multipath-induced time-domain dispersion to be transformed into a set of superimposed sinusoids in the frequency domain. Building upon this model, we propose a hybrid inference framework capable of accurately estimating both channel parameters and user locations. Specifically, expectation propagation is first employed to mitigate multi-user interference, while the path delays are then extracted from noisy channel state information using an orthogonal matching pursuit (OMP) based approach, or a hybrid belief propagation-variational inference (BP-VI) algorithm. Then the estimated delays are subsequently refined through the embedded geometric information via an iterative localization procedure, wherein the estimated channel matrices are recursively fed back to EP. Furthermore, the Cramer-Rao lower bound (CRLB) is derived to characterize the fundamental estimation limits. Finally, simulation results validate that our proposed framework closely approaches the CRLB, with performance comparable to cooperative multi-base station localization, with significantly fewer RF chains and reduced hardware complexity."}
{"id": "2512.09515", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.09515", "abs": "https://arxiv.org/abs/2512.09515", "authors": ["Soumendu Das", "Nagendra Kumar", "Dharmendra Dixit"], "title": "Analytical and DNN-Aided Performance Evaluation of IRS-Assisted THz Communication Systems", "comment": null, "summary": "This paper investigates the performance of an intelligent reflecting surface (IRS)-assisted terahertz (THz) communication system, where the IRS facilitates connectivity between the source and destination nodes in the absence of a direct transmission path. The source-IRS and IRS-destination links are subject to various challenges, including atmospheric attenuation, asymmetric $α$-$μ$ distributed small-scale fading, and beam misalignment-induced pointing errors. The IRS link is characterized using the Laguerre series expansion (LSE) approximation, while both the source-IRS and IRS-destination channels are modeled as independent and identically distributed (i.i.d.) $α$-$μ$ fading channels. Furthermore, closed-form analytical expressions are derived for the outage probability (OP), average channel capacity (ACC), and average symbol error rate (ASER) for rectangular QAM (RQAM) and hexagonal QAM (HQAM) schemes over the end-to-end (e2e) link. The impact of random co-phasing and phase quantization errors are also examined. In addition to the theoretical analysis, deep neural network-based frameworks are developed to predict key performance metrics, facilitating fast and accurate system evaluation without computationally intensive analytical computations. Moreover, the asymptotic analysis in the high-signal-to-noise ratio (SNR) regime yields closed-form expressions for coding gain and diversity order, providing further insights into performance trends. Finally, Monte Carlo simulations validate the theoretical formulations and present a comprehensive assessment of system behavior under practical conditions."}
{"id": "2512.09560", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.09560", "abs": "https://arxiv.org/abs/2512.09560", "authors": ["Zihan Xu", "Zhiwen Zhou", "Di Wu", "Xiaoli Xu", "Yong Zeng"], "title": "CKM-Enabled Joint Spatial-Doppler Domain Clutter Suppression for Low-Altitude UAV ISAC", "comment": "This work has been submitted to IEEE for possible publication", "summary": "The rapid development of low-altitude economy has placed higher demands on the sensing of small-sized unmanned aerial vehicle (UAV) targets. However, the complex and dynamic low-altitude environment, like the urban and mountainous areas, makes clutter a significant factor affecting the sensing performance. Traditional clutter suppression methods based on Doppler difference or signal strength are inadequate for scenarios with dynamic clutter and slow-moving targets like low-altitude UAVs. In this paper, motivated by the concept of channel knowledge map (CKM), we propose a novel clutter suppression technique for orthogonal frequency division multiplexing (OFDM) integrated sensing and communication (ISAC) system, by leveraging a new type of CKM named clutter angle map (CLAM). CLAM is a site-specific database, containing location-specific primary clutter angles for the coverage area of the ISAC base station (BS). With CLAM, the sensing signal components corresponding to the clutter environment can be effectively removed before target detection and parameter estimation, which greatly enhances the sensing performance. Besides, to take into account the scenarios when the targets and clutters are in close directions so that pure CLAM-based spatial domain clutter suppression is no longer effective, we further propose a two-step CLAM-enabled joint spatial-Doppler domain clutter suppression algorithm. Simulation results demonstrate that the proposed technique effectively suppresses clutter and enhances target sensing performance, achieving accurate parameter estimation for sensing slow-moving low-altitude UAV targets."}
{"id": "2512.09589", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.09589", "abs": "https://arxiv.org/abs/2512.09589", "authors": ["Anup Mishra", "João Henrique Inacio de Souza", "Petar Popovski"], "title": "Temporal Windows of Integration for Multisensory Wireless Systems as Enablers of Physical AI", "comment": null, "summary": "Physical artificial intelligence (AI) refers to the AI that interacts with the physical world in real time. Similar to multisensory perception, Physical AI makes decisions based on multimodal updates from sensors and devices. Physical AI thus operates with a finite spatial footprint of its sensory tributaries. The multimodal updates traverse heterogeneous and unreliable paths, involving wireless links. Throughput or latency guarantees do not ensure correct decision-making, as misaligned, misordered, or stale inputs still yield wrong inferences. Preserving decision-time coherence hinges on three timing primitives at the network-application interface: (i) simultaneity, a short coincidence window that groups measurements as co-temporal, (ii) causality, path-wise delivery that never lets a consequence precede its precursor, and (iii) usefulness, a validity horizon that drops information too stale to influence the current action. In this work, we focus on usefulness and adopt temporal window of integration (TWI)-Causality: the TWI enforces decision-time usefulness by assuming path-wise causal consistency and cross-path simultaneity are handled upstream. We model end-to-end path delay as the sum of sensing/propagation, computation, and access/transmission latencies, and formulate network design as minimizing the validity horizon under a delivery reliability constraint. In effect, this calibrates delay-reliability budgets for a timing-aware system operating over sensors within a finite spatial footprint. The joint choice of horizon and per-path reliability is cast as a convex optimization problem, solved to global optimality to obtain the minimal horizon and per-path allocation of reliability. This is compared favourably to a benchmark based on uniform-after-threshold allocation. Overall, this study contributes to timing-aware Physical AI in next-generation networks."}
{"id": "2512.09714", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.09714", "abs": "https://arxiv.org/abs/2512.09714", "authors": ["Chong Huang", "Gaojie Chen", "Zhuoao Xu", "Jing Zhu", "Taisong Pan", "Rahim Tafazolli", "Wei Huang"], "title": "Flexible Reconfigurable Intelligent Surface-Aided Covert Communications in UAV Networks", "comment": "Accepted for publication in IEEE Journal on Selected Areas in Communications", "summary": "In recent years, unmanned aerial vehicles (UAVs) have become a key role in wireless communication networks due to their flexibility and dynamic adaptability. However, the openness of UAV-based communications leads to security and privacy concerns in wireless transmissions. This paper investigates a framework of UAV covert communications which introduces flexible reconfigurable intelligent surfaces (F-RIS) in UAV networks. Unlike traditional RIS, F-RIS provides advanced deployment flexibility by conforming to curved surfaces and dynamically reconfiguring its electromagnetic properties to enhance the covert communication performance. We establish an electromagnetic model for F-RIS and further develop a fitted model that describes the relationship between F-RIS reflection amplitude, reflection phase, and incident angle. To maximize the covert transmission rate among UAVs while meeting the covert constraint and public transmission constraint, we introduce a strategy of jointly optimizing UAV trajectories, F-RIS reflection vectors, F-RIS incident angles, and non-orthogonal multiple access (NOMA) power allocation. Considering this is a complicated non-convex optimization problem, we propose a deep reinforcement learning (DRL) algorithm-based optimization solution. Simulation results demonstrate that our proposed framework and optimization method significantly outperform traditional benchmarks, and highlight the advantages of F-RIS in enhancing covert communication performance within UAV networks."}
{"id": "2512.09803", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.09803", "abs": "https://arxiv.org/abs/2512.09803", "authors": ["Eya Gourar", "Yahia Medjahdi", "Laurent Clavier", "Abdul Karim Gizzini", "Patrick Sondi"], "title": "On the Ambiguity Function of OFDM-based ISAC Signals Under Non-Ideal Power Amplifiers", "comment": "This article has been submitted to the IEEE Transactions on Vehicular Technology", "summary": "Integrated Sensing and Communications (ISAC) has garnered significant attention as a promising technology for next-generation wireless and vehicular communications. Among candidate waveforms, Orthogonal Frequency Division Multiplexing (OFDM) has been extensively investigated over the past decade for its robustness against frequency-selective fading and its favorable ranging performance. However, the waveform's sensing and communication (S&C) performance depends strongly on the modulation scheme; while variable-amplitude constellations such as quadrature amplitude (QAM) are more efficient for communication, constant-modulus modulations such as phase shift keying (PSK) are more suitable for sensing. Yet, it remains unclear whether these findings persist under power amplifier (PA) nonlinearity. Because OFDM signals exhibit a high peak-to-average power ratio (PAPR), they require highly linear PAs to avoid distortion, which conflicts with radar requirements, where high transmit power is always beneficial for sensing. In this work, we analyze the effect of PA-induced distortions on the sensing task for PSK and QAM constellations. By introducing the Signal-to-Distortion Ratio (SDR), we examine the extent of the distortion limitation on the ranging task. We complement simulation results with a theoretical characterization of the ambiguity function (AF), thereby explicitly demonstrating how distortion artifacts manifest in the zero-Doppler sidelobes (i.e, ranging sidelobes) and the zero-delay sidelobes. Simulations show that PA distortions impose a palpable performance ceiling for both constellations, reshape the AF, and reduce detection probability, diminishing the theoretical advantage of unimodular signaling and further compromising the OFDM sensing performance with non-uniform envelope signals."}
{"id": "2512.09827", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.09827", "abs": "https://arxiv.org/abs/2512.09827", "authors": ["Hamid Reza Hashempour", "Mostafa Nozari", "Gilberto Berardinelli", "Yanjiao Li", "Jie Zhang", "Hien Quoc Ngo", "Shashi Raj Pandey"], "title": "Energy-Efficient Federated Learning with Relay-Assisted Aggregation in IIoT Networks", "comment": null, "summary": "This paper presents an energy-efficient transmission framework for federated learning (FL) in industrial Internet of Things (IIoT) environments with strict latency and energy constraints. Machinery subnetworks (SNs) collaboratively train a global model by uploading local updates to an edge server (ES), either directly or via neighboring SNs acting as decode-and-forward relays. To enhance communication efficiency, relays perform partial aggregation before forwarding the models to the ES, significantly reducing overhead and training latency. We analyze the convergence behavior of this relay-assisted FL scheme. To address the inherent energy efficiency (EE) challenges, we decompose the original non-convex optimization problem into sub-problems addressing computation and communication energy separately. An SN grouping algorithm categorizes devices into single-hop and two-hop transmitters based on latency minimization, followed by a relay selection mechanism. To improve FL reliability, we further maximize the number of SNs that meet the roundwise delay constraint, promoting broader participation and improved convergence stability under practical IIoT data distributions. Transmit power levels are then optimized to maximize EE, and a sequential parametric convex approximation (SPCA) method is proposed for joint configuration of system parameters. We further extend the EE formulation to the imperfect channel state information (ICSI). Simulation results demonstrate that the proposed framework significantly enhances convergence speed, reduces outage probability from 10-2 in single-hop to 10-6 and achieves substantial energy savings, with the SPCA approach reducing energy consumption by at least 2x compared to unaggregated cooperation and up to 6x over single-hop transmission."}
{"id": "2512.09893", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.09893", "abs": "https://arxiv.org/abs/2512.09893", "authors": ["Nian-Cin Wang", "Rajeev Sahay"], "title": "A Speculative GLRT-Backed Approach for Adversarial Resilience on Deep Learning-Based Array Processing", "comment": "12 pages, 3 figures, 2 tables", "summary": "Classical array processing methods such as the generalized likelihood ratio test (GLRT) provide statistically grounded solutions for signal detection and direction-of-arrival (DoA) estimation, but their high computational cost limits their use in low-latency settings. Deep learning (DL) has recently emerged as an efficient alternative, offering fast inference for array processing tasks. However, DL models lack statistical guarantees and, moreover, are highly susceptible to adversarial perturbations, raising fundamental concerns about their reliability in adversarial wireless environments. To address these challenges, we propose an adversarially resilient speculative array processing framework that consists of a low-latency DL classifier backed by a theoretically-grounded GLRT validator, where DL is used for fast speculative inference and later confirmed with the GLRT. We show that second order statistics of the received array, which the GLRT operates on, are spatially invariant to L-p bounded adversarial perturbations, providing adversarial robustness and theoretically-grounded validation of DL predictions. Empirical evaluations under multiple L-p bounds, perturbation designs, and perturbation magnitudes corroborate our theoretical findings, demonstrating the superior performance of our proposed framework in comparison to multiple state-of-the-art baselines."}
{"id": "2512.09221", "categories": ["eess.AS", "eess.SP"], "pdf": "https://arxiv.org/pdf/2512.09221", "abs": "https://arxiv.org/abs/2512.09221", "authors": ["Eugenia San Segundo", "Aurora López-Jareño", "Xin Wang", "Junichi Yamagishi"], "title": "Human perception of audio deepfakes: the role of language and speaking style", "comment": "Submitted to Speech Communication", "summary": "Audio deepfakes have reached a level of realism that makes it increasingly difficult to distinguish between human and artificial voices, which poses risks such as identity theft or spread of disinformation. Despite these concerns, research on humans' ability to identify deepfakes is limited, with most studies focusing on English and very few exploring the reasons behind listeners' perceptual decisions. This study addresses this gap through a perceptual experiment in which 54 listeners (28 native Spanish speakers and 26 native Japanese speakers) classified voices as natural or synthetic, and justified their choices. The experiment included 80 stimuli (50% artificial), organized according to three variables: language (Spanish/Japanese), speech style (audiobooks/interviews), and familiarity with the voice (familiar/unfamiliar). The goal was to examine how these variables influence detection and to analyze qualitatively the reasoning behind listeners' perceptual decisions. Results indicate an average accuracy of 59.11%, with higher performance on authentic samples. Judgments of vocal naturalness rely on a combination of linguistic and non-linguistic cues. Comparing Japanese and Spanish listeners, our qualitative analysis further reveals both shared cues and notable cross-linguistic differences in how listeners conceptualize the \"humanness\" of speech. Overall, participants relied primarily on suprasegmental and higher-level or extralinguistic characteristics - such as intonation, rhythm, fluency, pauses, speed, breathing, and laughter - over segmental features. These findings underscore the complexity of human perceptual strategies in distinguishing natural from artificial speech and align partly with prior research emphasizing the importance of prosody and phenomena typical of spontaneous speech, such as disfluencies."}

{"id": "2512.10689", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2512.10689", "abs": "https://arxiv.org/abs/2512.10689", "authors": ["Pablo M. Delgado", "Sascha Dick", "Christoph Thompson", "Chih-Wei Wu", "Phillip A. Williams"], "title": "Exploring Perceptual Audio Quality Measurement on Stereo Processing Using the Open Dataset of Audio Quality", "comment": "Presented at the 159 Audio Engineering Society Convention. Paper Number:366. https://aes2.org/publications/elibrary-page/?id=23040", "summary": "ODAQ (Open Dataset of Audio Quality) provides a comprehensive framework for exploring both monaural and binaural audio quality degradations across a range of distortion classes and signals, accompanied by subjective quality ratings. A recent update of ODAQ, focusing on the impact of stereo processing methods such as Mid/Side (MS) and Left/Right (LR), provides test signals and subjective ratings for the in-depth investigation of state-of-the-art objective audio quality metrics. Our evaluation results suggest that, while timbre-focused metrics often yield robust results under simpler conditions, their prediction performance tends to suffer under the conditions with a more complex presentation context. Our findings underscore the importance of modeling the interplay of bottom-up psychoacoustic processes and top-down contextual factors, guiding future research toward models that more effectively integrate both timbral and spatial dimensions of perceived audio quality.", "AI": {"tldr": "ODAQ\u6570\u636e\u96c6\u66f4\u65b0\uff0c\u4e13\u6ce8\u4e8e\u7acb\u4f53\u58f0\u5904\u7406\uff08MS/LR\uff09\u5bf9\u97f3\u9891\u8d28\u91cf\u8bc4\u4f30\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u73b0\u6709\u6307\u6807\u5728\u590d\u6742\u573a\u666f\u4e0b\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u7ed3\u5408\u97f3\u8272\u548c\u7a7a\u95f4\u7ef4\u5ea6\u5efa\u6a21\u3002", "motivation": "\u73b0\u6709\u97f3\u9891\u8d28\u91cf\u8bc4\u4f30\u6307\u6807\u4e3b\u8981\u5173\u6ce8\u5355\u58f0\u9053\u97f3\u8272\u8d28\u91cf\uff0c\u7f3a\u4e4f\u5bf9\u7acb\u4f53\u58f0\u5904\u7406\u548c\u7a7a\u95f4\u7ef4\u5ea6\u5f71\u54cd\u7684\u7cfb\u7edf\u7814\u7a76\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u6307\u5bfc\u672a\u6765\u6a21\u578b\u53d1\u5c55\u3002", "method": "\u66f4\u65b0ODAQ\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u79cd\u7acb\u4f53\u58f0\u5904\u7406\uff08Mid/Side\u548cLeft/Right\uff09\u7684\u6d4b\u8bd5\u4fe1\u53f7\u548c\u4e3b\u89c2\u8d28\u91cf\u8bc4\u5206\uff0c\u7528\u4e8e\u6df1\u5165\u8bc4\u4f30\u73b0\u6709\u5ba2\u89c2\u97f3\u9891\u8d28\u91cf\u6307\u6807\u7684\u6027\u80fd\u3002", "result": "\u97f3\u8272\u5bfc\u5411\u7684\u6307\u6807\u5728\u7b80\u5355\u6761\u4ef6\u4e0b\u8868\u73b0\u7a33\u5065\uff0c\u4f46\u5728\u590d\u6742\u5448\u73b0\u73af\u5883\u4e0b\u9884\u6d4b\u6027\u80fd\u4e0b\u964d\uff1b\u7acb\u4f53\u58f0\u5904\u7406\u5bf9\u8d28\u91cf\u611f\u77e5\u6709\u663e\u8457\u5f71\u54cd\uff0c\u73b0\u6709\u6307\u6807\u672a\u80fd\u5145\u5206\u6355\u6349\u7a7a\u95f4\u7ef4\u5ea6\u3002", "conclusion": "\u672a\u6765\u97f3\u9891\u8d28\u91cf\u6a21\u578b\u9700\u8981\u6574\u5408\u81ea\u4e0b\u800c\u4e0a\u7684\u5fc3\u7406\u58f0\u5b66\u8fc7\u7a0b\u548c\u81ea\u4e0a\u800c\u4e0b\u7684\u4e0a\u4e0b\u6587\u56e0\u7d20\uff0c\u540c\u65f6\u8003\u8651\u97f3\u8272\u548c\u7a7a\u95f4\u7ef4\u5ea6\uff0c\u624d\u80fd\u66f4\u51c6\u786e\u5730\u9884\u6d4b\u590d\u6742\u573a\u666f\u4e0b\u7684\u611f\u77e5\u8d28\u91cf\u3002"}}
{"id": "2512.10778", "categories": ["cs.SD", "cs.MM", "eess.AS"], "pdf": "https://arxiv.org/pdf/2512.10778", "abs": "https://arxiv.org/abs/2512.10778", "authors": ["Zitong Lan", "Yiwei Tang", "Yuhan Wang", "Haowen Lai", "Yiduo Hao", "Mingmin Zhao"], "title": "Building Audio-Visual Digital Twins with Smartphones", "comment": "Under Mobisys 2026 review, single blind", "summary": "Digital twins today are almost entirely visual, overlooking acoustics-a core component of spatial realism and interaction. We introduce AV-Twin, the first practical system that constructs editable audio-visual digital twins using only commodity smartphones. AV-Twin combines mobile RIR capture and a visual-assisted acoustic field model to efficiently reconstruct room acoustics. It further recovers per-surface material properties through differentiable acoustic rendering, enabling users to modify materials, geometry, and layout while automatically updating both audio and visuals. Together, these capabilities establish a practical path toward fully modifiable audio-visual digital twins for real-world environments.", "AI": {"tldr": "AV-Twin\uff1a\u9996\u4e2a\u4f7f\u7528\u666e\u901a\u667a\u80fd\u624b\u673a\u6784\u5efa\u53ef\u7f16\u8f91\u89c6\u542c\u6570\u5b57\u5b6a\u751f\u7684\u5b9e\u7528\u7cfb\u7edf\uff0c\u7ed3\u5408\u79fb\u52a8RIR\u91c7\u96c6\u548c\u89c6\u89c9\u8f85\u52a9\u58f0\u573a\u5efa\u6a21\uff0c\u5b9e\u73b0\u623f\u95f4\u58f0\u5b66\u91cd\u5efa\u548c\u8868\u9762\u6750\u8d28\u6062\u590d", "motivation": "\u5f53\u524d\u6570\u5b57\u5b6a\u751f\u4e3b\u8981\u5173\u6ce8\u89c6\u89c9\u5c42\u9762\uff0c\u5ffd\u7565\u4e86\u58f0\u5b66\u8fd9\u4e00\u7a7a\u95f4\u771f\u5b9e\u611f\u548c\u4ea4\u4e92\u7684\u6838\u5fc3\u7ec4\u6210\u90e8\u5206\u3002\u9700\u8981\u6784\u5efa\u65e2\u80fd\u7f16\u8f91\u89c6\u89c9\u53c8\u80fd\u7f16\u8f91\u97f3\u9891\u7684\u5b8c\u6574\u6570\u5b57\u5b6a\u751f\u7cfb\u7edf", "method": "1. \u4f7f\u7528\u666e\u901a\u667a\u80fd\u624b\u673a\u8fdb\u884c\u79fb\u52a8\u623f\u95f4\u8109\u51b2\u54cd\u5e94\uff08RIR\uff09\u91c7\u96c6\uff1b2. \u7ed3\u5408\u89c6\u89c9\u8f85\u52a9\u58f0\u573a\u6a21\u578b\u9ad8\u6548\u91cd\u5efa\u623f\u95f4\u58f0\u5b66\uff1b3. \u901a\u8fc7\u53ef\u5fae\u5206\u58f0\u5b66\u6e32\u67d3\u6062\u590d\u6bcf\u4e2a\u8868\u9762\u7684\u6750\u8d28\u5c5e\u6027\uff1b4. \u652f\u6301\u7528\u6237\u4fee\u6539\u6750\u8d28\u3001\u51e0\u4f55\u5f62\u72b6\u548c\u5e03\u5c40\uff0c\u540c\u65f6\u81ea\u52a8\u66f4\u65b0\u97f3\u9891\u548c\u89c6\u89c9", "result": "\u5efa\u7acb\u4e86\u9996\u4e2a\u5b9e\u7528\u7684\u53ef\u7f16\u8f91\u89c6\u542c\u6570\u5b57\u5b6a\u751f\u7cfb\u7edfAV-Twin\uff0c\u80fd\u591f\u4ece\u771f\u5b9e\u73af\u5883\u6784\u5efa\u5b8c\u6574\u7684\u97f3\u9891-\u89c6\u89c9\u6570\u5b57\u8868\u793a\uff0c\u5e76\u652f\u6301\u5b9e\u65f6\u4fee\u6539\u548c\u66f4\u65b0", "conclusion": "AV-Twin\u4e3a\u6784\u5efa\u771f\u5b9e\u4e16\u754c\u73af\u5883\u7684\u5b8c\u5168\u53ef\u4fee\u6539\u89c6\u542c\u6570\u5b57\u5b6a\u751f\u5f00\u8f9f\u4e86\u5b9e\u7528\u8def\u5f84\uff0c\u586b\u8865\u4e86\u5f53\u524d\u6570\u5b57\u5b6a\u751f\u4e2d\u58f0\u5b66\u5efa\u6a21\u7684\u7a7a\u767d"}}
{"id": "2512.10120", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10120", "abs": "https://arxiv.org/abs/2512.10120", "authors": ["Maris Basha", "Anja Zai", "Sabine Stoll", "Richard Hahnloser"], "title": "VocSim: A Training-free Benchmark for Zero-shot Content Identity in Single-source Audio", "comment": null, "summary": "General-purpose audio representations aim to map acoustically variable instances of the same event to nearby points, resolving content identity in a zero-shot setting. Unlike supervised classification benchmarks that measure adaptability via parameter updates, we introduce VocSim, a training-free benchmark probing the intrinsic geometric alignment of frozen embeddings. VocSim aggregates 125k single-source clips from 19 corpora spanning human speech, animal vocalizations, and environmental sounds. By restricting to single-source audio, we isolate content representation from the confound of source separation. We evaluate embeddings using Precision@k for local purity and the Global Separation Rate (GSR) for point-wise class separation. To calibrate GSR, we report lift over an empirical permutation baseline. Across diverse foundation models, a simple pipeline, frozen Whisper encoder features, time-frequency pooling, and label-free PCA, yields strong zero-shot performance. However, VocSim also uncovers a consistent generalization gap. On blind, low-resource speech, local retrieval drops sharply. While performance remains statistically distinguishable from chance, the absolute geometric structure collapses, indicating a failure to generalize to unseen phonotactics. As external validation, our top embeddings predict avian perceptual similarity, improve bioacoustic classification, and achieve state-of-the-art results on the HEAR benchmark. We posit that the intrinsic geometric quality measured here proxies utility in unlisted downstream applications. We release data, code, and a public leaderboard to standardize the evaluation of intrinsic audio geometry.", "AI": {"tldr": "VocSim\u662f\u4e00\u4e2a\u65e0\u9700\u8bad\u7ec3\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u51bb\u7ed3\u97f3\u9891\u5d4c\u5165\u7684\u5185\u5728\u51e0\u4f55\u5bf9\u9f50\u8d28\u91cf\uff0c\u6db5\u76d6\u8bed\u97f3\u3001\u52a8\u7269\u53eb\u58f0\u548c\u73af\u5883\u58f0\u97f3\uff0c\u63ed\u793a\u6a21\u578b\u5728\u672a\u89c1\u4f4e\u8d44\u6e90\u8bed\u97f3\u4e0a\u7684\u6cdb\u5316\u5dee\u8ddd\u3002", "motivation": "\u73b0\u6709\u76d1\u7763\u5206\u7c7b\u57fa\u51c6\u901a\u8fc7\u53c2\u6570\u66f4\u65b0\u8861\u91cf\u9002\u5e94\u6027\uff0c\u4f46\u7f3a\u4e4f\u5bf9\u51bb\u7ed3\u5d4c\u5165\u5185\u5728\u51e0\u4f55\u7ed3\u6784\u7684\u8bc4\u4f30\u3002\u9700\u8981\u4e00\u79cd\u8bad\u7ec3\u65e0\u5173\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u97f3\u9891\u8868\u793a\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u7684\u5185\u5bb9\u8bc6\u522b\u80fd\u529b\uff0c\u540c\u65f6\u6392\u9664\u58f0\u6e90\u5206\u79bb\u7684\u5e72\u6270\u3002", "method": "\u6536\u96c6125k\u5355\u6e90\u97f3\u9891\u7247\u6bb5\uff0c\u6765\u81ea19\u4e2a\u8bed\u6599\u5e93\uff0c\u6db5\u76d6\u4eba\u7c7b\u8bed\u97f3\u3001\u52a8\u7269\u53eb\u58f0\u548c\u73af\u5883\u58f0\u97f3\u3002\u4f7f\u7528Precision@k\u8bc4\u4f30\u5c40\u90e8\u7eaf\u5ea6\uff0cGlobal Separation Rate\u8bc4\u4f30\u70b9\u7ea7\u7c7b\u522b\u5206\u79bb\uff0c\u5e76\u901a\u8fc7\u7ecf\u9a8c\u6392\u5217\u57fa\u7ebf\u6821\u51c6\u3002\u91c7\u7528\u7b80\u5355\u6d41\u7a0b\uff1a\u51bb\u7ed3Whisper\u7f16\u7801\u5668\u7279\u5f81\u3001\u65f6\u9891\u6c60\u5316\u548c\u65e0\u6807\u7b7ePCA\u3002", "result": "\u8be5\u6d41\u7a0b\u5728\u96f6\u6837\u672c\u8bbe\u7f6e\u4e0b\u8868\u73b0\u5f3a\u52b2\uff0c\u4f46VocSim\u63ed\u793a\u4e86\u6301\u7eed\u7684\u6cdb\u5316\u5dee\u8ddd\uff1a\u5728\u672a\u89c1\u4f4e\u8d44\u6e90\u8bed\u97f3\u4e0a\uff0c\u5c40\u90e8\u68c0\u7d22\u6027\u80fd\u6025\u5267\u4e0b\u964d\uff0c\u51e0\u4f55\u7ed3\u6784\u5d29\u6e83\u3002\u540c\u65f6\uff0c\u6700\u4f73\u5d4c\u5165\u80fd\u9884\u6d4b\u9e1f\u7c7b\u611f\u77e5\u76f8\u4f3c\u6027\uff0c\u6539\u8fdb\u751f\u7269\u58f0\u5b66\u5206\u7c7b\uff0c\u5e76\u5728HEAR\u57fa\u51c6\u4e0a\u8fbe\u5230SOTA\u3002", "conclusion": "VocSim\u57fa\u51c6\u63ed\u793a\u4e86\u97f3\u9891\u5d4c\u5165\u7684\u5185\u5728\u51e0\u4f55\u8d28\u91cf\uff0c\u53ef\u4f5c\u4e3a\u672a\u5217\u51fa\u4e0b\u6e38\u5e94\u7528\u6548\u7528\u7684\u4ee3\u7406\u6307\u6807\u3002\u7814\u7a76\u53d1\u5e03\u4e86\u6570\u636e\u3001\u4ee3\u7801\u548c\u516c\u5171\u6392\u884c\u699c\uff0c\u4ee5\u6807\u51c6\u5316\u5185\u5728\u97f3\u9891\u51e0\u4f55\u7684\u8bc4\u4f30\u3002"}}
{"id": "2512.10036", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10036", "abs": "https://arxiv.org/abs/2512.10036", "authors": ["Nimesha Gunasekara", "Ebrahim Bedeer"], "title": "Analysis and Compensation of Receiver IQ Imbalance and Residual CFO Error for AFDM", "comment": null, "summary": "Affine frequency division multiplexing (AFDM) is a promising waveform for future wireless communication systems. In this paper, we analyze the impact of receiver in-phase and quadrature (IQ) imbalance and residual carrier frequency offset (CFO) error on AFDM signals. Our analysis shows that the receiver IQ imbalance may not preserve the sparsity of the AFDM effective channel matrix because of the complex-conjugate operator of the discrete affine Fourier transform (DAFT). Moreover, the residual CFO error causes energy leakage in the effective channel matrix in the affine domain. To mitigate these effects, we extend the linear minimum mean-square error (LMMSE) detector to handle the improper Gaussian noise arising from the receiver IQ imbalance. Simulation results demonstrate that the proposed LMMSE detector effectively compensates for the receiver hardware impairments.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u63a5\u6536\u673aIQ\u4e0d\u5e73\u8861\u548c\u6b8b\u4f59\u8f7d\u6ce2\u9891\u7387\u504f\u79fb\u5bf9AFDM\u4fe1\u53f7\u7684\u5f71\u54cd\uff0c\u5e76\u63d0\u51fa\u4e86\u6269\u5c55\u7684LMMSE\u68c0\u6d4b\u5668\u6765\u8865\u507f\u8fd9\u4e9b\u786c\u4ef6\u635f\u4f24\u3002", "motivation": "AFDM\u662f\u672a\u6765\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u4e2d\u6709\u524d\u666f\u7684\u6ce2\u5f62\u6280\u672f\uff0c\u4f46\u63a5\u6536\u673a\u786c\u4ef6\u635f\u4f24\uff08IQ\u4e0d\u5e73\u8861\u548c\u6b8b\u4f59CFO\uff09\u4f1a\u5f71\u54cd\u5176\u6027\u80fd\u3002\u73b0\u6709\u7814\u7a76\u5bf9\u8fd9\u4e9b\u635f\u4f24\u5bf9AFDM\u4fe1\u53f7\u7684\u5f71\u54cd\u5206\u6790\u4e0d\u8db3\uff0c\u9700\u8981\u7814\u7a76\u6709\u6548\u7684\u8865\u507f\u65b9\u6cd5\u3002", "method": "\u5206\u6790\u4e86\u63a5\u6536\u673aIQ\u4e0d\u5e73\u8861\u548c\u6b8b\u4f59CFO\u5bf9AFDM\u6709\u6548\u4fe1\u9053\u77e9\u9635\u7684\u5f71\u54cd\uff0c\u53d1\u73b0IQ\u4e0d\u5e73\u8861\u4f1a\u7834\u574f\u4fe1\u9053\u77e9\u9635\u7684\u7a00\u758f\u6027\uff0c\u6b8b\u4f59CFO\u4f1a\u5bfc\u81f4\u80fd\u91cf\u6cc4\u6f0f\u3002\u4e3a\u6b64\uff0c\u5c06LMMSE\u68c0\u6d4b\u5668\u6269\u5c55\u5230\u5904\u7406IQ\u4e0d\u5e73\u8861\u5f15\u8d77\u7684\u4e0d\u9002\u5f53\u9ad8\u65af\u566a\u58f0\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684LMMSE\u68c0\u6d4b\u5668\u80fd\u6709\u6548\u8865\u507f\u63a5\u6536\u673a\u786c\u4ef6\u635f\u4f24\uff0c\u63d0\u5347AFDM\u7cfb\u7edf\u5728\u5b58\u5728IQ\u4e0d\u5e73\u8861\u548c\u6b8b\u4f59CFO\u60c5\u51b5\u4e0b\u7684\u6027\u80fd\u3002", "conclusion": "\u63a5\u6536\u673aIQ\u4e0d\u5e73\u8861\u548c\u6b8b\u4f59CFO\u5bf9AFDM\u4fe1\u53f7\u6709\u663e\u8457\u5f71\u54cd\uff0c\u4f46\u901a\u8fc7\u6269\u5c55\u7684LMMSE\u68c0\u6d4b\u5668\u53ef\u4ee5\u6709\u6548\u8865\u507f\u8fd9\u4e9b\u786c\u4ef6\u635f\u4f24\uff0c\u4e3aAFDM\u5728\u5b9e\u9645\u7cfb\u7edf\u4e2d\u7684\u90e8\u7f72\u63d0\u4f9b\u4e86\u91cd\u8981\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.10170", "categories": ["cs.SD", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.10170", "abs": "https://arxiv.org/abs/2512.10170", "authors": ["Lucas Dunker", "Sai Akshay Menta", "Snigdha Mohana Addepalli", "Venkata Krishna Rayalu Garapati"], "title": "Semantic-Aware Confidence Calibration for Automated Audio Captioning", "comment": "5 pages, 2 figures", "summary": "Automated audio captioning models frequently produce overconfident predictions regardless of semantic accuracy, limiting their reliability in deployment. This deficiency stems from two factors: evaluation metrics based on n-gram overlap that fail to capture semantic correctness, and the absence of calibrated confidence estimation. We present a framework that addresses both limitations by integrating confidence prediction into audio captioning and redefining correctness through semantic similarity. Our approach augments a Whisper-based audio captioning model with a learned confidence prediction head that estimates uncertainty from decoder hidden states. We employ CLAP audio-text embeddings and sentence transformer similarities (FENSE) to define semantic correctness, enabling Expected Calibration Error (ECE) computation that reflects true caption quality rather than surface-level text overlap. Experiments on Clotho v2 demonstrate that confidence-guided beam search with semantic evaluation achieves dramatically improved calibration (CLAP-based ECE of 0.071) compared to greedy decoding baselines (ECE of 0.488), while simultaneously improving caption quality across standard metrics. Our results establish that semantic similarity provides a more meaningful foundation for confidence calibration in audio captioning than traditional n-gram metrics.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7ed3\u5408\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u548c\u8bed\u4e49\u76f8\u4f3c\u5ea6\u7684\u97f3\u9891\u5b57\u5e55\u6821\u51c6\u6846\u67b6\uff0c\u89e3\u51b3\u4f20\u7edf\u65b9\u6cd5\u8fc7\u5ea6\u81ea\u4fe1\u548c\u8bc4\u4f30\u6307\u6807\u4e0d\u51c6\u786e\u7684\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u97f3\u9891\u5b57\u5e55\u6a21\u578b\u7ecf\u5e38\u4ea7\u751f\u8fc7\u5ea6\u81ea\u4fe1\u7684\u9884\u6d4b\uff0c\u65e0\u8bba\u8bed\u4e49\u51c6\u786e\u6027\u5982\u4f55\uff0c\u8fd9\u9650\u5236\u4e86\u5176\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u53ef\u9760\u6027\u3002\u95ee\u9898\u6e90\u4e8e\u4e24\u4e2a\u56e0\u7d20\uff1a\u57fa\u4e8en-gram\u91cd\u53e0\u7684\u8bc4\u4f30\u6307\u6807\u65e0\u6cd5\u6355\u6349\u8bed\u4e49\u6b63\u786e\u6027\uff0c\u4ee5\u53ca\u7f3a\u4e4f\u6821\u51c6\u7684\u7f6e\u4fe1\u5ea6\u4f30\u8ba1\u3002", "method": "\u5728\u57fa\u4e8eWhisper\u7684\u97f3\u9891\u5b57\u5e55\u6a21\u578b\u4e0a\u589e\u52a0\u5b66\u4e60\u578b\u7f6e\u4fe1\u5ea6\u9884\u6d4b\u5934\uff0c\u4ece\u89e3\u7801\u5668\u9690\u85cf\u72b6\u6001\u4f30\u8ba1\u4e0d\u786e\u5b9a\u6027\u3002\u4f7f\u7528CLAP\u97f3\u9891-\u6587\u672c\u5d4c\u5165\u548c\u53e5\u5b50\u53d8\u6362\u5668\u76f8\u4f3c\u5ea6(FENSE)\u5b9a\u4e49\u8bed\u4e49\u6b63\u786e\u6027\uff0c\u4ece\u800c\u8ba1\u7b97\u53cd\u6620\u771f\u5b9e\u5b57\u5e55\u8d28\u91cf\u800c\u975e\u8868\u9762\u6587\u672c\u91cd\u53e0\u7684\u671f\u671b\u6821\u51c6\u8bef\u5dee(ECE)\u3002", "result": "\u5728Clotho v2\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u7f6e\u4fe1\u5ea6\u5f15\u5bfc\u7684\u675f\u641c\u7d22\u4e0e\u8bed\u4e49\u8bc4\u4f30\u76f8\u7ed3\u5408\uff0c\u76f8\u6bd4\u8d2a\u5a6a\u89e3\u7801\u57fa\u7ebf(ECE\u4e3a0.488)\uff0c\u5b9e\u73b0\u4e86\u663e\u8457\u6539\u5584\u7684\u6821\u51c6(\u57fa\u4e8eCLAP\u7684ECE\u4e3a0.071)\uff0c\u540c\u65f6\u63d0\u9ad8\u4e86\u6807\u51c6\u6307\u6807\u4e0b\u7684\u5b57\u5e55\u8d28\u91cf\u3002", "conclusion": "\u8bed\u4e49\u76f8\u4f3c\u5ea6\u4e3a\u97f3\u9891\u5b57\u5e55\u4e2d\u7684\u7f6e\u4fe1\u5ea6\u6821\u51c6\u63d0\u4f9b\u4e86\u6bd4\u4f20\u7edfn-gram\u6307\u6807\u66f4\u6709\u610f\u4e49\u7684\u57fa\u7840\uff0c\u5efa\u7acb\u4e86\u66f4\u53ef\u9760\u7684\u97f3\u9891\u5b57\u5e55\u7cfb\u7edf\u3002"}}
{"id": "2512.10074", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10074", "abs": "https://arxiv.org/abs/2512.10074", "authors": ["Peyman Moeini", "Mark Coates"], "title": "Cost and Complexity as Barriers to RTLS Adoption in SMEs: A Survey and Analysis", "comment": "18 pages, 11 figures, 1 table. Survey of RTLS adoption barriers for small and medium-sized manufacturing enterprises", "summary": "Real-time location systems (RTLSs) are central to Industry 4.0 and emerging Industry 5.0, providing the spatiotemporal data required for asset tracking, workflow optimization, safety, and integration with WMS, MES, and digital twins. While large enterprises increasingly deploy RTLSs, adoption among small and medium-sized enterprises (SMEs) remains limited. This paper examines whether cost and installation complexity are primary barriers to SME adoption. We position RTLSs within the broader Industry 4.0 and Logistics 4.0 landscape and summarize their operational value. We then synthesize evidence from the literature on technical, financial, and organizational constraints, with emphasis on infrastructure requirements, calibration effort, integration with legacy systems, and human factors. To complement this analysis, we report results from an online survey of sixteen manufacturing and technology professionals in Canada and the United States. Respondents report strong perceived value for real-time tracking but identify upfront cost, installation effort, integration difficulty, and reliance on multiple anchor nodes as dominant obstacles. Most indicate acceptable upfront investments below $10,000 and express a clear preference for low-infrastructure deployments with minimized anchor counts. Building on these findings, we outline design directions for SME-focused RTLSs, including wireless and modular architectures, cloud-managed and self-calibrating systems, standardized integration interfaces, and anchor-minimizing or anchor-free localization methods. Overall, the results show that limited SME adoption stems less from insufficient perceived value than from misalignment between current RTLS deployment models and SME resource constraints.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u53d1\u73b0\uff0c\u4e2d\u5c0f\u4f01\u4e1a\u91c7\u7528\u5b9e\u65f6\u5b9a\u4f4d\u7cfb\u7edf\u7684\u4e3b\u8981\u969c\u788d\u4e0d\u662f\u4ef7\u503c\u8ba4\u77e5\u4e0d\u8db3\uff0c\u800c\u662f\u73b0\u6709RTLS\u90e8\u7f72\u6a21\u5f0f\u4e0e\u4e2d\u5c0f\u4f01\u4e1a\u8d44\u6e90\u9650\u5236\u4e0d\u5339\u914d\uff0c\u5305\u62ec\u9ad8\u6210\u672c\u3001\u590d\u6742\u5b89\u88c5\u548c\u96c6\u6210\u56f0\u96be\u7b49\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u4e2d\u5c0f\u4f01\u4e1a\u91c7\u7528\u5b9e\u65f6\u5b9a\u4f4d\u7cfb\u7edf\uff08RTLS\uff09\u7684\u4e3b\u8981\u969c\u788d\uff0c\u7279\u522b\u662f\u5728\u5de5\u4e1a4.0\u548c\u7269\u6d414.0\u80cc\u666f\u4e0b\uff0c\u867d\u7136\u5927\u578b\u4f01\u4e1a\u8d8a\u6765\u8d8a\u591a\u5730\u90e8\u7f72RTLS\uff0c\u4f46\u4e2d\u5c0f\u4f01\u4e1a\u91c7\u7528\u7387\u4ecd\u7136\u6709\u9650\u3002", "method": "\u901a\u8fc7\u6587\u732e\u7efc\u8ff0\u5206\u6790\u6280\u672f\u3001\u8d22\u52a1\u548c\u7ec4\u7ec7\u7ea6\u675f\uff0c\u5e76\u901a\u8fc7\u5bf9\u52a0\u62ff\u5927\u548c\u7f8e\u56fd16\u4f4d\u5236\u9020\u548c\u6280\u672f\u4e13\u4e1a\u4eba\u5458\u7684\u5728\u7ebf\u8c03\u67e5\u6536\u96c6\u5b9e\u8bc1\u6570\u636e\u3002", "result": "\u8c03\u67e5\u663e\u793a\u4e2d\u5c0f\u4f01\u4e1a\u8ba4\u53ef\u5b9e\u65f6\u8ddf\u8e2a\u7684\u4ef7\u503c\uff0c\u4f46\u8ba4\u4e3a\u524d\u671f\u6210\u672c\u3001\u5b89\u88c5\u5de5\u4f5c\u91cf\u3001\u96c6\u6210\u96be\u5ea6\u548c\u5bf9\u591a\u4e2a\u951a\u8282\u70b9\u7684\u4f9d\u8d56\u662f\u4e3b\u8981\u969c\u788d\u3002\u5927\u591a\u6570\u53d7\u8bbf\u8005\u63a5\u53d7\u4f4e\u4e8e1\u4e07\u7f8e\u5143\u7684\u524d\u671f\u6295\u8d44\uff0c\u5e76\u504f\u597d\u4f4e\u57fa\u7840\u8bbe\u65bd\u90e8\u7f72\u548c\u6700\u5c0f\u5316\u951a\u8282\u70b9\u6570\u91cf\u3002", "conclusion": "\u4e2d\u5c0f\u4f01\u4e1aRTLS\u91c7\u7528\u53d7\u9650\u4e3b\u8981\u6e90\u4e8e\u5f53\u524d\u90e8\u7f72\u6a21\u5f0f\u4e0e\u4e2d\u5c0f\u4f01\u4e1a\u8d44\u6e90\u9650\u5236\u4e0d\u5339\u914d\uff0c\u800c\u975e\u4ef7\u503c\u8ba4\u77e5\u4e0d\u8db3\u3002\u9700\u8981\u5f00\u53d1\u9762\u5411\u4e2d\u5c0f\u4f01\u4e1a\u7684RTLS\u8bbe\u8ba1\uff0c\u5305\u62ec\u65e0\u7ebf\u6a21\u5757\u5316\u67b6\u6784\u3001\u4e91\u7ba1\u7406\u81ea\u6821\u51c6\u7cfb\u7edf\u3001\u6807\u51c6\u5316\u96c6\u6210\u63a5\u53e3\u548c\u951a\u8282\u70b9\u6700\u5c0f\u5316\u6216\u65e0\u951a\u5b9a\u4f4d\u65b9\u6cd5\u3002"}}
{"id": "2512.10264", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.10264", "abs": "https://arxiv.org/abs/2512.10264", "authors": ["Alon Ziv", "Sanyuan Chen", "Andros Tjandra", "Yossi Adi", "Wei-Ning Hsu", "Bowen Shi"], "title": "MR-FlowDPO: Multi-Reward Direct Preference Optimization for Flow-Matching Text-to-Music Generation", "comment": null, "summary": "A key challenge in music generation models is their lack of direct alignment with human preferences, as music evaluation is inherently subjective and varies widely across individuals. We introduce MR-FlowDPO, a novel approach that enhances flow-matching-based music generation models - a major class of modern music generative models, using Direct Preference Optimization (DPO) with multiple musical rewards. The rewards are crafted to assess music quality across three key dimensions: text alignment, audio production quality, and semantic consistency, utilizing scalable off-the-shelf models for each reward prediction. We employ these rewards in two ways: (i) By constructing preference data for DPO and (ii) by integrating the rewards into text prompting. To address the ambiguity in musicality evaluation, we propose a novel scoring mechanism leveraging semantic self-supervised representations, which significantly improves the rhythmic stability of generated music. We conduct an extensive evaluation using a variety of music-specific objective metrics as well as a human study. Results show that MR-FlowDPO significantly enhances overall music generation quality and is consistently preferred over highly competitive baselines in terms of audio quality, text alignment, and musicality. Our code is publicly available at https://github.com/lonzi/mrflow_dpo; Samples are provided in our demo page at https://lonzi.github.io/mr_flowdpo_demopage/.", "AI": {"tldr": "MR-FlowDPO\uff1a\u901a\u8fc7\u591a\u5956\u52b1DPO\u589e\u5f3a\u6d41\u5339\u914d\u97f3\u4e50\u751f\u6210\u6a21\u578b\uff0c\u5728\u6587\u672c\u5bf9\u9f50\u3001\u97f3\u9891\u8d28\u91cf\u548c\u8bed\u4e49\u4e00\u81f4\u6027\u65b9\u9762\u663e\u8457\u63d0\u5347\u97f3\u4e50\u751f\u6210\u8d28\u91cf", "motivation": "\u97f3\u4e50\u751f\u6210\u6a21\u578b\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\u662f\u7f3a\u4e4f\u4e0e\u4eba\u7c7b\u504f\u597d\u7684\u76f4\u63a5\u5bf9\u9f50\uff0c\u56e0\u4e3a\u97f3\u4e50\u8bc4\u4ef7\u5177\u6709\u4e3b\u89c2\u6027\u4e14\u4e2a\u4f53\u5dee\u5f02\u5927\u3002\u73b0\u6709\u6a21\u578b\u96be\u4ee5\u76f4\u63a5\u4f18\u5316\u4eba\u7c7b\u504f\u597d\u3002", "method": "\u63d0\u51faMR-FlowDPO\u65b9\u6cd5\uff1a1\uff09\u4f7f\u7528\u4e09\u4e2a\u53ef\u6269\u5c55\u7684\u73b0\u6210\u6a21\u578b\u6784\u5efa\u591a\u5956\u52b1\u7cfb\u7edf\uff0c\u8bc4\u4f30\u6587\u672c\u5bf9\u9f50\u3001\u97f3\u9891\u5236\u4f5c\u8d28\u91cf\u548c\u8bed\u4e49\u4e00\u81f4\u6027\uff1b2\uff09\u901a\u8fc7\u4e24\u79cd\u65b9\u5f0f\u4f7f\u7528\u8fd9\u4e9b\u5956\u52b1\uff1a\u6784\u5efaDPO\u504f\u597d\u6570\u636e\uff0c\u4ee5\u53ca\u5c06\u5956\u52b1\u96c6\u6210\u5230\u6587\u672c\u63d0\u793a\u4e2d\uff1b3\uff09\u63d0\u51fa\u57fa\u4e8e\u8bed\u4e49\u81ea\u76d1\u7763\u8868\u793a\u7684\u65b0\u8bc4\u5206\u673a\u5236\uff0c\u6539\u5584\u8282\u594f\u7a33\u5b9a\u6027\u3002", "result": "\u901a\u8fc7\u591a\u79cd\u97f3\u4e50\u7279\u5b9a\u5ba2\u89c2\u6307\u6807\u548c\u4eba\u7c7b\u7814\u7a76\u8bc4\u4f30\uff0c\u7ed3\u679c\u663e\u793aMR-FlowDPO\u663e\u8457\u63d0\u5347\u4e86\u6574\u4f53\u97f3\u4e50\u751f\u6210\u8d28\u91cf\uff0c\u5728\u97f3\u9891\u8d28\u91cf\u3001\u6587\u672c\u5bf9\u9f50\u548c\u97f3\u4e50\u6027\u65b9\u9762\u59cb\u7ec8\u4f18\u4e8e\u5f3a\u57fa\u7ebf\u6a21\u578b\u3002", "conclusion": "MR-FlowDPO\u901a\u8fc7\u591a\u5956\u52b1DPO\u6709\u6548\u589e\u5f3a\u4e86\u6d41\u5339\u914d\u97f3\u4e50\u751f\u6210\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u97f3\u4e50\u8bc4\u4ef7\u7684\u4e3b\u89c2\u6027\u95ee\u9898\uff0c\u663e\u8457\u63d0\u5347\u4e86\u751f\u6210\u97f3\u4e50\u7684\u8d28\u91cf\u548c\u4eba\u7c7b\u504f\u597d\u5bf9\u9f50\u3002"}}
{"id": "2512.10183", "categories": ["eess.SP", "cs.SI", "stat.ME", "stat.ML"], "pdf": "https://arxiv.org/pdf/2512.10183", "abs": "https://arxiv.org/abs/2512.10183", "authors": ["Gonzalo Mateos", "Yanning Shen", "Georgios B. Giannakis", "Ananthram Swami"], "title": "Topology Identification and Inference over Graphs", "comment": "Contributed chapter to appear in Handbook of Statistics Volume 54: Multidimensional Signal Processing, K. V. Mishra, G. R. Arce, and A. S. R. S. Rao, Editors, Amsterdam, Netherlands, Elsevier, 2026", "summary": "Topology identification and inference of processes evolving over graphs arise in timely applications involving brain, transportation, financial, power, as well as social and information networks. This chapter provides an overview of graph topology identification and statistical inference methods for multidimensional relational data. Approaches for undirected links connecting graph nodes are outlined, going all the way from correlation metrics to covariance selection, and revealing ties with smooth signal priors. To account for directional (possibly causal) relations among nodal variables and address the limitations of linear time-invariant models in handling dynamic as well as nonlinear dependencies, a principled framework is surveyed to capture these complexities through judiciously selected kernels from a prescribed dictionary. Generalizations are also described via structural equations and vector autoregressions that can exploit attributes such as low rank, sparsity, acyclicity, and smoothness to model dynamic processes over possibly time-evolving topologies. It is argued that this approach supports both batch and online learning algorithms with convergence rate guarantees, is amenable to tensor (that is, multi-way array) formulations as well as decompositions that are well-suited for multidimensional network data, and can seamlessly leverage high-order statistical information.", "AI": {"tldr": "\u8be5\u7ae0\u8282\u7efc\u8ff0\u4e86\u56fe\u62d3\u6251\u8bc6\u522b\u548c\u7edf\u8ba1\u63a8\u65ad\u65b9\u6cd5\uff0c\u6db5\u76d6\u4ece\u76f8\u5173\u6027\u5ea6\u91cf\u5230\u534f\u65b9\u5dee\u9009\u62e9\u7684\u65e0\u5411\u94fe\u63a5\u65b9\u6cd5\uff0c\u4ee5\u53ca\u901a\u8fc7\u6838\u51fd\u6570\u3001\u7ed3\u6784\u65b9\u7a0b\u548c\u5411\u91cf\u81ea\u56de\u5f52\u5904\u7406\u52a8\u6001\u975e\u7ebf\u6027\u4f9d\u8d56\u5173\u7cfb\u7684\u6846\u67b6\u3002", "motivation": "\u5728\u5927\u8111\u3001\u4ea4\u901a\u3001\u91d1\u878d\u3001\u7535\u529b\u4ee5\u53ca\u793e\u4ea4\u548c\u4fe1\u606f\u7f51\u7edc\u7b49\u5e94\u7528\u4e2d\uff0c\u9700\u8981\u8bc6\u522b\u56fe\u62d3\u6251\u7ed3\u6784\u5e76\u5bf9\u56fe\u4e0a\u6f14\u5316\u7684\u8fc7\u7a0b\u8fdb\u884c\u7edf\u8ba1\u63a8\u65ad\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u52a8\u6001\u548c\u975e\u7ebf\u6027\u4f9d\u8d56\u5173\u7cfb\u65b9\u9762\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "1. \u65e0\u5411\u94fe\u63a5\u65b9\u6cd5\uff1a\u4ece\u76f8\u5173\u6027\u5ea6\u91cf\u5230\u534f\u65b9\u5dee\u9009\u62e9\uff0c\u4e0e\u5e73\u6ed1\u4fe1\u53f7\u5148\u9a8c\u76f8\u5173\u8054\uff1b2. \u6709\u5411\u5173\u7cfb\u6846\u67b6\uff1a\u901a\u8fc7\u4ece\u9884\u5b9a\u5b57\u5178\u4e2d\u9009\u62e9\u6838\u51fd\u6570\u5904\u7406\u52a8\u6001\u548c\u975e\u7ebf\u6027\u4f9d\u8d56\uff1b3. \u63a8\u5e7f\u65b9\u6cd5\uff1a\u7ed3\u6784\u65b9\u7a0b\u548c\u5411\u91cf\u81ea\u56de\u5f52\uff0c\u5229\u7528\u4f4e\u79e9\u3001\u7a00\u758f\u6027\u3001\u65e0\u73af\u6027\u548c\u5e73\u6ed1\u6027\u7b49\u5c5e\u6027\u5efa\u6a21\u52a8\u6001\u8fc7\u7a0b\u3002", "result": "\u8be5\u6846\u67b6\u652f\u6301\u6279\u5904\u7406\u548c\u5728\u7ebf\u5b66\u4e60\u7b97\u6cd5\uff0c\u5177\u6709\u6536\u655b\u901f\u7387\u4fdd\u8bc1\uff0c\u9002\u7528\u4e8e\u5f20\u91cf\uff08\u591a\u7ef4\u6570\u7ec4\uff09\u516c\u5f0f\u548c\u5206\u89e3\uff0c\u80fd\u65e0\u7f1d\u5229\u7528\u9ad8\u9636\u7edf\u8ba1\u4fe1\u606f\uff0c\u9002\u5408\u591a\u7ef4\u7f51\u7edc\u6570\u636e\u5206\u6790\u3002", "conclusion": "\u8be5\u7ae0\u8282\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u56fe\u62d3\u6251\u8bc6\u522b\u548c\u7edf\u8ba1\u63a8\u65ad\u65b9\u6cd5\u7efc\u8ff0\uff0c\u5c55\u793a\u4e86\u5982\u4f55\u901a\u8fc7\u6838\u51fd\u6570\u3001\u7ed3\u6784\u65b9\u7a0b\u548c\u5411\u91cf\u81ea\u56de\u5f52\u7b49\u5148\u8fdb\u6280\u672f\u5904\u7406\u590d\u6742\u52a8\u6001\u5173\u7cfb\uff0c\u4e3a\u591a\u7ef4\u7f51\u7edc\u6570\u636e\u5206\u6790\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u7406\u8bba\u6846\u67b6\u3002"}}
{"id": "2512.10375", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.10375", "abs": "https://arxiv.org/abs/2512.10375", "authors": ["Wenye Zhu", "Jun Tang", "Xiaofei Li"], "title": "Neural personal sound zones with flexible bright zone control", "comment": null, "summary": "Personal sound zone (PSZ) reproduction system, which attempts to create distinct virtual acoustic scenes for different listeners at their respective positions within the same spatial area using one loudspeaker array, is a fundamental technology in the application of virtual reality. For practical applications, the reconstruction targets must be measured on the same fixed receiver array used to record the local room impulse responses (RIRs) from the loudspeaker array to the control points in each PSZ, which makes the system inconvenient and costly for real-world use. In this paper, a 3D convolutional neural network (CNN) designed for PSZ reproduction with flexible control microphone grid and alternative reproduction target is presented, utilizing the virtual target scene as inputs and the PSZ pre-filters as output. Experimental results of the proposed method are compared with the traditional method, demonstrating that the proposed method is able to handle varied reproduction targets on flexible control point grid using only one training session. Furthermore, the proposed method also demonstrates the capability to learn global spatial information from sparse sampling points distributed in PSZs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e3D CNN\u7684PSZ\u7cfb\u7edf\uff0c\u53ef\u5904\u7406\u7075\u6d3b\u7684\u63a7\u5236\u70b9\u7f51\u683c\u548c\u66ff\u4ee3\u518d\u73b0\u76ee\u6807\uff0c\u4ec5\u9700\u4e00\u6b21\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u4e0d\u540c\u573a\u666f", "motivation": "\u4f20\u7edfPSZ\u7cfb\u7edf\u9700\u8981\u5728\u5b9e\u9645\u63a7\u5236\u70b9\u4f4d\u7f6e\u6d4b\u91cf\u91cd\u5efa\u76ee\u6807\uff0c\u8fd9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u65e2\u4e0d\u65b9\u4fbf\u53c8\u6210\u672c\u9ad8\u6602\uff0c\u9650\u5236\u4e86\u7cfb\u7edf\u7684\u5b9e\u7528\u6027", "method": "\u8bbe\u8ba13D\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u4ee5\u865a\u62df\u76ee\u6807\u573a\u666f\u4e3a\u8f93\u5165\uff0cPSZ\u9884\u6ee4\u6ce2\u5668\u4e3a\u8f93\u51fa\uff0c\u652f\u6301\u7075\u6d3b\u7684\u63a7\u5236\u9ea6\u514b\u98ce\u7f51\u683c\u548c\u66ff\u4ee3\u518d\u73b0\u76ee\u6807", "result": "\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u4ec5\u9700\u4e00\u6b21\u8bad\u7ec3\u5373\u53ef\u5904\u7406\u4e0d\u540c\u518d\u73b0\u76ee\u6807\u548c\u7075\u6d3b\u63a7\u5236\u70b9\u7f51\u683c\uff0c\u5e76\u80fd\u4ece\u7a00\u758f\u91c7\u6837\u70b9\u5b66\u4e60\u5168\u5c40\u7a7a\u95f4\u4fe1\u606f", "conclusion": "\u63d0\u51fa\u76843D CNN\u65b9\u6cd5\u4e3aPSZ\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u7075\u6d3b\u3001\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u964d\u4f4e\u4e86\u5b9e\u9645\u5e94\u7528\u7684\u6210\u672c\u548c\u590d\u6742\u6027"}}
{"id": "2512.10246", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10246", "abs": "https://arxiv.org/abs/2512.10246", "authors": ["Hongyu Li", "Shanpu Shen"], "title": "Antenna Coding Design for Multi-User Transmissions Using Pixel Antennas", "comment": "12 pages, 9 figures, submitted to IEEE journal for possible publication", "summary": "This work investigates exploiting the potential of pixel antennas, which are a reconfigurable antenna technology that can flexibly adjust the antenna characteristics through antenna coding, in multi-user transmissions. To that end, we propose a multi-user multi-input single-output (MISO) pixel antenna system, which deploys the pixel antenna at users, and develop the system model including pixel antenna with antenna coding and multi-user beamspace channels. Aiming at maximizing the sum rate performance, we first propose an algorithm to alternatively design the precoding at the transmitter and the antenna coding at users, which explores the performance boundary for the proposed multi-user MISO pixel antenna system. To reduce the computational complexity, we propose a codebook-based antenna coding design algorithm, where the antenna coder is online optimized from an offline codebook. To further enhance the computation efficiency, we propose a hierarchical codebook-based antenna coding design that uses a multi-layer hierarchical search to achieve a better performance-complexity trade-off. Simulation results show that, adopting the proposed algorithms, the multi-user MISO pixel antenna system can always outperform conventional multi-user MISO systems with fixed antennas. More importantly, results validate that the proposed (hierarchical) codebook-based algorithms can significantly reduce the computational complexity while maintaining a satisfactory sum rate performance.", "AI": {"tldr": "\u63d0\u51fa\u591a\u7528\u6237MISO\u50cf\u7d20\u5929\u7ebf\u7cfb\u7edf\uff0c\u901a\u8fc7\u5929\u7ebf\u7f16\u7801\u548c\u9884\u7f16\u7801\u8054\u5408\u8bbe\u8ba1\u63d0\u5347\u548c\u901f\u7387\uff0c\u5e76\u5f00\u53d1\u57fa\u4e8e\u7801\u672c\u7684\u5206\u5c42\u641c\u7d22\u7b97\u6cd5\u964d\u4f4e\u590d\u6742\u5ea6\u3002", "motivation": "\u63a2\u7d22\u50cf\u7d20\u5929\u7ebf\u5728\u591a\u7528\u6237\u4f20\u8f93\u4e2d\u7684\u6f5c\u529b\uff0c\u50cf\u7d20\u5929\u7ebf\u4f5c\u4e3a\u53ef\u91cd\u6784\u5929\u7ebf\u6280\u672f\uff0c\u80fd\u591f\u901a\u8fc7\u5929\u7ebf\u7f16\u7801\u7075\u6d3b\u8c03\u6574\u5929\u7ebf\u7279\u6027\uff0c\u4f46\u5982\u4f55\u5c06\u5176\u6709\u6548\u5e94\u7528\u4e8e\u591a\u7528\u6237\u7cfb\u7edf\u5e76\u7ba1\u7406\u8ba1\u7b97\u590d\u6742\u5ea6\u662f\u9700\u8981\u89e3\u51b3\u7684\u95ee\u9898\u3002", "method": "1) \u63d0\u51fa\u591a\u7528\u6237MISO\u50cf\u7d20\u5929\u7ebf\u7cfb\u7edf\u6a21\u578b\uff0c\u5305\u542b\u5929\u7ebf\u7f16\u7801\u548c\u591a\u7528\u6237\u6ce2\u675f\u7a7a\u95f4\u4fe1\u9053\uff1b2) \u5f00\u53d1\u4ea4\u66ff\u8bbe\u8ba1\u53d1\u5c04\u7aef\u9884\u7f16\u7801\u548c\u7528\u6237\u7aef\u5929\u7ebf\u7f16\u7801\u7684\u7b97\u6cd5\uff1b3) \u63d0\u51fa\u57fa\u4e8e\u7801\u672c\u7684\u5929\u7ebf\u7f16\u7801\u8bbe\u8ba1\u7b97\u6cd5\uff0c\u4ece\u79bb\u7ebf\u7801\u672c\u5728\u7ebf\u4f18\u5316\u5929\u7ebf\u7f16\u7801\u5668\uff1b4) \u8fdb\u4e00\u6b65\u63d0\u51fa\u5206\u5c42\u7801\u672c\u5929\u7ebf\u7f16\u7801\u8bbe\u8ba1\uff0c\u4f7f\u7528\u591a\u5c42\u5206\u5c42\u641c\u7d22\u5b9e\u73b0\u66f4\u597d\u7684\u6027\u80fd-\u590d\u6742\u5ea6\u6743\u8861\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u91c7\u7528\u6240\u63d0\u7b97\u6cd5\u7684\u591a\u7528\u6237MISO\u50cf\u7d20\u5929\u7ebf\u7cfb\u7edf\u59cb\u7ec8\u4f18\u4e8e\u91c7\u7528\u56fa\u5b9a\u5929\u7ebf\u7684\u4f20\u7edf\u591a\u7528\u6237MISO\u7cfb\u7edf\u3002\u66f4\u91cd\u8981\u7684\u662f\uff0c\u6240\u63d0\u51fa\u7684\uff08\u5206\u5c42\uff09\u7801\u672c\u7b97\u6cd5\u80fd\u591f\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u4ee4\u4eba\u6ee1\u610f\u7684\u548c\u901f\u7387\u6027\u80fd\u3002", "conclusion": "\u50cf\u7d20\u5929\u7ebf\u6280\u672f\u5728\u591a\u7528\u6237MISO\u7cfb\u7edf\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u901a\u8fc7\u6709\u6548\u7684\u5929\u7ebf\u7f16\u7801\u8bbe\u8ba1\u548c\u590d\u6742\u5ea6\u7ba1\u7406\u7b97\u6cd5\uff0c\u53ef\u4ee5\u5b9e\u73b0\u6027\u80fd\u63d0\u5347\u4e0e\u8ba1\u7b97\u6548\u7387\u7684\u826f\u597d\u5e73\u8861\uff0c\u4e3a\u672a\u6765\u53ef\u91cd\u6784\u5929\u7ebf\u5728\u591a\u7528\u6237\u901a\u4fe1\u4e2d\u7684\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.10382", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.10382", "abs": "https://arxiv.org/abs/2512.10382", "authors": ["Liusha Yang", "Ziru Ge", "Gui Zhang", "Junan Zhang", "Zhizheng Wu"], "title": "Investigating training objective for flow matching-based speech enhancement", "comment": null, "summary": "Speech enhancement(SE) aims to recover clean speech from noisy recordings. Although generative approaches such as score matching and Schrodinger bridge have shown strong effectiveness, they are often computationally expensive. Flow matching offers a more efficient alternative by directly learning a velocity field that maps noise to data. In this work, we present a systematic study of flow matching for SE under three training objectives: velocity prediction, $x_1$ prediction, and preconditioned $x_1$ prediction. We analyze their impact on training dynamics and overall performance. Moreover, by introducing perceptual(PESQ) and signal-based(SI-SDR) objectives, we further enhance convergence efficiency and speech quality, yielding substantial improvements across evaluation metrics.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u6d41\u5339\u914d\u5728\u8bed\u97f3\u589e\u5f3a\u4e2d\u7684\u5e94\u7528\uff0c\u6bd4\u8f83\u4e86\u4e09\u79cd\u8bad\u7ec3\u76ee\u6807\uff0c\u5e76\u5f15\u5165\u611f\u77e5\u548c\u4fe1\u53f7\u76ee\u6807\u6765\u63d0\u5347\u6536\u655b\u6548\u7387\u548c\u8bed\u97f3\u8d28\u91cf\u3002", "motivation": "\u867d\u7136\u751f\u6210\u5f0f\u65b9\u6cd5\u5982\u5206\u6570\u5339\u914d\u548c\u859b\u5b9a\u8c14\u6865\u5728\u8bed\u97f3\u589e\u5f3a\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002\u6d41\u5339\u914d\u901a\u8fc7\u76f4\u63a5\u5b66\u4e60\u4ece\u566a\u58f0\u5230\u6570\u636e\u7684\u901f\u5ea6\u573a\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u6d41\u5339\u914d\u5728\u8bed\u97f3\u589e\u5f3a\u4e2d\u7684\u5e94\u7528\uff0c\u6bd4\u8f83\u4e09\u79cd\u8bad\u7ec3\u76ee\u6807\uff1a\u901f\u5ea6\u9884\u6d4b\u3001x\u2081\u9884\u6d4b\u548c\u9884\u6761\u4ef6x\u2081\u9884\u6d4b\u3002\u5206\u6790\u5b83\u4eec\u5bf9\u8bad\u7ec3\u52a8\u6001\u548c\u6574\u4f53\u6027\u80fd\u7684\u5f71\u54cd\u3002\u5f15\u5165\u611f\u77e5\u76ee\u6807(PESQ)\u548c\u4fe1\u53f7\u76ee\u6807(SI-SDR)\u6765\u8fdb\u4e00\u6b65\u63d0\u5347\u6536\u655b\u6548\u7387\u548c\u8bed\u97f3\u8d28\u91cf\u3002", "result": "\u901a\u8fc7\u5f15\u5165\u611f\u77e5\u548c\u4fe1\u53f7\u76ee\u6807\uff0c\u663e\u8457\u63d0\u5347\u4e86\u6536\u655b\u6548\u7387\u548c\u8bed\u97f3\u8d28\u91cf\uff0c\u5728\u5404\u9879\u8bc4\u4f30\u6307\u6807\u4e0a\u90fd\u53d6\u5f97\u4e86\u5b9e\u8d28\u6027\u6539\u8fdb\u3002", "conclusion": "\u6d41\u5339\u914d\u4e3a\u8bed\u97f3\u589e\u5f3a\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u7cfb\u7edf\u7814\u7a76\u4e0d\u540c\u8bad\u7ec3\u76ee\u6807\u5e76\u5f15\u5165\u611f\u77e5\u548c\u4fe1\u53f7\u76ee\u6807\uff0c\u53ef\u4ee5\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4e3a\u751f\u6210\u5f0f\u8bed\u97f3\u589e\u5f3a\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.10447", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10447", "abs": "https://arxiv.org/abs/2512.10447", "authors": ["Kaisei Higeta", "Masakatsu Ogawa", "Tomoki Murakami", "Kazuya Ohara", "Shinya Otsuki"], "title": "Outdoor Crowd Flow Estimation Using RSRP from Commercial LTE Base Station: A Field Study", "comment": "6 pages, 15 figures, Accepted for presentation at the International Conference on Information Networking (ICOIN) 2026", "summary": "With the advent of the 6G era, Integrated Sensing and Communications (ISAC) has attracted increasing attention. One representative of use cases is crowd flow estimation on outdoor streets. However, most existing studies have focused on indoor environments or vehicles, and demonstrations of outdoor crowd flow estimation using commercial LTE base station remain limited. This study addresses this use case and proposes an analysis of a crowd flow estimation method using Reference Signal Received Power (RSRP) obtained from a commercial LTE base station. Specifically, pedestrian counts derived from a camera-based object recognition algorithm were associated with the variance of RSRP. The features obtained from the variance were quantitatively evaluated by combining a CatBoost regression model with SHapley Additive exPlanations (SHAP) analysis. Through this investigation, we clarified that an optimal variance window size for RSRP is 0.1 to 0.2 seconds and that enlarging the counting area increased the features obtained from the variance of RSRP, for machine learning. Consequently, this study is the first to quantitatively demonstrate the effectiveness of outdoor crowd flow estimation using commercial LTE, while also revealing the characteristic behavior of variance window size and counting area size in feature design.", "AI": {"tldr": "\u8be5\u7814\u7a76\u9996\u6b21\u5b9a\u91cf\u8bc1\u660e\u4e86\u4f7f\u7528\u5546\u7528LTE\u57fa\u7ad9\u8fdb\u884c\u5ba4\u5916\u4eba\u7fa4\u6d41\u91cf\u4f30\u8ba1\u7684\u6709\u6548\u6027\uff0c\u786e\u5b9a\u4e86RSRP\u65b9\u5dee\u7684\u6700\u4f73\u7a97\u53e3\u5927\u5c0f\u4e3a0.1-0.2\u79d2\uff0c\u5e76\u53d1\u73b0\u6269\u5927\u8ba1\u6570\u533a\u57df\u80fd\u589e\u52a0\u673a\u5668\u5b66\u4e60\u7279\u5f81\u3002", "motivation": "\u968f\u77406G\u65f6\u4ee3\u7684\u5230\u6765\uff0c\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u53d7\u5230\u8d8a\u6765\u8d8a\u591a\u7684\u5173\u6ce8\u3002\u5ba4\u5916\u8857\u9053\u4eba\u7fa4\u6d41\u91cf\u4f30\u8ba1\u662f\u4ee3\u8868\u6027\u5e94\u7528\u573a\u666f\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u591a\u96c6\u4e2d\u4e8e\u5ba4\u5185\u73af\u5883\u6216\u8f66\u8f86\uff0c\u4f7f\u7528\u5546\u7528LTE\u57fa\u7ad9\u8fdb\u884c\u5ba4\u5916\u4eba\u7fa4\u6d41\u91cf\u4f30\u8ba1\u7684\u6f14\u793a\u4ecd\u7136\u6709\u9650\u3002", "method": "\u7814\u7a76\u63d0\u51fa\u4f7f\u7528\u5546\u7528LTE\u57fa\u7ad9\u83b7\u53d6\u7684\u53c2\u8003\u4fe1\u53f7\u63a5\u6536\u529f\u7387\uff08RSRP\uff09\u8fdb\u884c\u4eba\u7fa4\u6d41\u91cf\u4f30\u8ba1\u7684\u65b9\u6cd5\u3002\u5c06\u57fa\u4e8e\u6444\u50cf\u5934\u7684\u7269\u4f53\u8bc6\u522b\u7b97\u6cd5\u5f97\u5230\u7684\u884c\u4eba\u6570\u91cf\u4e0eRSRP\u65b9\u5dee\u76f8\u5173\u8054\uff0c\u901a\u8fc7CatBoost\u56de\u5f52\u6a21\u578b\u7ed3\u5408SHAP\u5206\u6790\u5bf9\u4ece\u65b9\u5dee\u4e2d\u63d0\u53d6\u7684\u7279\u5f81\u8fdb\u884c\u5b9a\u91cf\u8bc4\u4f30\u3002", "result": "\u7814\u7a76\u53d1\u73b0RSRP\u65b9\u5dee\u7684\u6700\u4f73\u7a97\u53e3\u5927\u5c0f\u4e3a0.1\u52300.2\u79d2\uff0c\u6269\u5927\u8ba1\u6570\u533a\u57df\u80fd\u589e\u52a0\u4eceRSRP\u65b9\u5dee\u4e2d\u83b7\u5f97\u7684\u673a\u5668\u5b66\u4e60\u7279\u5f81\u3002\u8fd9\u662f\u9996\u6b21\u5b9a\u91cf\u8bc1\u660e\u4f7f\u7528\u5546\u7528LTE\u8fdb\u884c\u5ba4\u5916\u4eba\u7fa4\u6d41\u91cf\u4f30\u8ba1\u7684\u6709\u6548\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u63ed\u793a\u4e86RSRP\u65b9\u5dee\u7a97\u53e3\u5927\u5c0f\u548c\u8ba1\u6570\u533a\u57df\u5927\u5c0f\u5728\u7279\u5f81\u8bbe\u8ba1\u4e2d\u7684\u7279\u6027\u884c\u4e3a\uff0c\u4e3a\u4f7f\u7528\u5546\u7528LTE\u57fa\u7ad9\u8fdb\u884c\u5ba4\u5916\u4eba\u7fa4\u6d41\u91cf\u4f30\u8ba1\u63d0\u4f9b\u4e86\u5b9a\u91cf\u9a8c\u8bc1\u548c\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2512.10403", "categories": ["cs.SD", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.10403", "abs": "https://arxiv.org/abs/2512.10403", "authors": ["Tianyu Guo", "Hongyu Chen", "Hao Liang", "Meiyi Qiang", "Bohan Zeng", "Linzhuang Sun", "Bin Cui", "Wentao Zhang"], "title": "BRACE: A Benchmark for Robust Audio Caption Quality Evaluation", "comment": null, "summary": "Automatic audio captioning is essential for audio understanding, enabling applications such as accessibility and content indexing. However, evaluating the quality of audio captions remains a major challenge, especially in reference-free settings where high-quality ground-truth captions are unavailable. While CLAPScore is currently the most widely used reference-free Audio Caption Evaluation Metric(ACEM), its robustness under diverse conditions has not been systematically validated.\n  To address this gap, we introduce BRACE, a new benchmark designed to evaluate audio caption alignment quality in a reference-free setting. BRACE is primarily designed for assessing ACEMs, and can also be extended to measure the modality alignment abilities of Large Audio Language Model(LALM). BRACE consists of two sub-benchmarks: BRACE-Main for fine-grained caption comparison and BRACE-Hallucination for detecting subtle hallucinated content. We construct these datasets through high-quality filtering, LLM-based corruption, and human annotation.\n  Given the widespread adoption of CLAPScore as a reference-free ACEM and the increasing application of LALMs in audio-language tasks, we evaluate both approaches using the BRACE benchmark, testing CLAPScore across various CLAP model variants and assessing multiple LALMs.\n  Notably, even the best-performing CLAP-based ACEM achieves only a 70.01 F1-score on the BRACE-Main benchmark, while the best LALM reaches just 63.19.\n  By revealing the limitations of CLAP models and LALMs, our BRACE benchmark offers valuable insights into the direction of future research.", "AI": {"tldr": "BRACE\u662f\u4e00\u4e2a\u65b0\u7684\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u5728\u65e0\u53c2\u8003\u8bbe\u7f6e\u4e0b\u8bc4\u4f30\u97f3\u9891\u5b57\u5e55\u5bf9\u9f50\u8d28\u91cf\uff0c\u5305\u62ec\u4e24\u4e2a\u5b50\u57fa\u51c6\uff1aBRACE-Main\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5b57\u5e55\u6bd4\u8f83\uff0cBRACE-Hallucination\u7528\u4e8e\u68c0\u6d4b\u7ec6\u5fae\u7684\u5e7b\u89c9\u5185\u5bb9\u3002", "motivation": "\u81ea\u52a8\u97f3\u9891\u5b57\u5e55\u5bf9\u4e8e\u97f3\u9891\u7406\u89e3\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u8bc4\u4f30\u97f3\u9891\u5b57\u5e55\u8d28\u91cf\u4ecd\u7136\u662f\u4e00\u4e2a\u4e3b\u8981\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u65e0\u53c2\u8003\u8bbe\u7f6e\u4e0b\u3002\u867d\u7136CLAPScore\u662f\u76ee\u524d\u6700\u5e7f\u6cdb\u4f7f\u7528\u7684\u65e0\u53c2\u8003\u97f3\u9891\u5b57\u5e55\u8bc4\u4f30\u6307\u6807\uff0c\u4f46\u5176\u5728\u4e0d\u540c\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u5c1a\u672a\u5f97\u5230\u7cfb\u7edf\u9a8c\u8bc1\u3002", "method": "\u5f15\u5165BRACE\u57fa\u51c6\u6d4b\u8bd5\uff0c\u901a\u8fc7\u9ad8\u8d28\u91cf\u8fc7\u6ee4\u3001\u57fa\u4e8eLLM\u7684\u7834\u574f\u548c\u4eba\u5de5\u6807\u6ce8\u6784\u5efa\u6570\u636e\u96c6\u3002\u8be5\u57fa\u51c6\u5305\u62ec\u4e24\u4e2a\u5b50\u57fa\u51c6\uff1aBRACE-Main\u7528\u4e8e\u7ec6\u7c92\u5ea6\u5b57\u5e55\u6bd4\u8f83\uff0cBRACE-Hallucination\u7528\u4e8e\u68c0\u6d4b\u5e7b\u89c9\u5185\u5bb9\u3002", "result": "\u5373\u4f7f\u8868\u73b0\u6700\u597d\u7684\u57fa\u4e8eCLAP\u7684ACEM\u5728BRACE-Main\u57fa\u51c6\u4e0a\u4ec5\u8fbe\u523070.01 F1\u5206\u6570\uff0c\u800c\u6700\u597d\u7684LALM\u4ec5\u8fbe\u523063.19\u3002\u8fd9\u63ed\u793a\u4e86CLAP\u6a21\u578b\u548cLALMs\u7684\u5c40\u9650\u6027\u3002", "conclusion": "BRACE\u57fa\u51c6\u901a\u8fc7\u63ed\u793aCLAP\u6a21\u578b\u548cLALMs\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u672a\u6765\u7814\u7a76\u65b9\u5411\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\uff0c\u8868\u660e\u5f53\u524d\u97f3\u9891\u5b57\u5e55\u8bc4\u4f30\u548c\u6a21\u6001\u5bf9\u9f50\u80fd\u529b\u4ecd\u6709\u5f88\u5927\u6539\u8fdb\u7a7a\u95f4\u3002"}}
{"id": "2512.10478", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10478", "abs": "https://arxiv.org/abs/2512.10478", "authors": ["Yumeng Zhang", "Huayan Guo", "Vincent Lau"], "title": "A Novel Pilot Scheme for Uplink Channel Estimation for Sub-array Structured ELAA in XL-MIMO systems", "comment": null, "summary": "This paper proposes a novel pilot scheme for multi-user uplink channel estimation in extra-large-scale massive MIMO (XL-MIMO) systems with extremely large aperture arrays (ELAA). The large aperture of ELAA introduces spatial non-stationarity, where far-apart users have significantly distinct visibility at the antennas, thereby reducing inter-user interference. This insight motivates our novel pilot scheme to group users with distinct visibility regions to share the same frequency subcarriers for channel estimation, so that more users can be served with reduced pilot overhead. Specifically, the proposed pilot scheme employs frequency-division multiplexing for inter-group channel estimation, while intra-group users -- benefiting from strong spatial orthogonality -- are distinguished by shifted cyclic codes, similar to code-division multiplexing. Additionally, we introduce a sub-array structured ELAA, where each sub-array is a traditional MIMO array and treated as spatial stationary, while the distances between sub-arrays can be significantly larger to achieve an expanded aperture. The channel support for sub-arrays features clustered sparsity in the antenna-delay domain and is modeled by a 2-dimensional (2-D) Markov random field (MRF). Based on this, we propose a low-complexity channel estimation algorithm within a turbo Bayesian inference framework that incorporates the 2-D MRF prior model. Simulations show that the proposed scheme and algorithm allow the XL-MIMO system to support more users, and deliver superior channel estimation performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u8d85\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u65b0\u578b\u5bfc\u9891\u65b9\u6848\uff0c\u901a\u8fc7\u5229\u7528\u7a7a\u95f4\u975e\u5e73\u7a33\u6027\u8ba9\u5177\u6709\u4e0d\u540c\u53ef\u89c1\u533a\u57df\u7684\u7528\u6237\u5171\u4eab\u5b50\u8f7d\u6ce2\uff0c\u51cf\u5c11\u5bfc\u9891\u5f00\u9500\u5e76\u652f\u6301\u66f4\u591a\u7528\u6237\u3002", "motivation": "\u8d85\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\uff0c\u6781\u5927\u5b54\u5f84\u9635\u5217\u5f15\u5165\u7a7a\u95f4\u975e\u5e73\u7a33\u6027\uff0c\u8fdc\u8ddd\u79bb\u7528\u6237\u5728\u5929\u7ebf\u5904\u5177\u6709\u663e\u8457\u4e0d\u540c\u7684\u53ef\u89c1\u6027\uff0c\u8fd9\u51cf\u5c11\u4e86\u7528\u6237\u95f4\u5e72\u6270\u3002\u8fd9\u4e00\u6d1e\u5bdf\u4fc3\u4f7f\u8bbe\u8ba1\u65b0\u7684\u5bfc\u9891\u65b9\u6848\uff0c\u8ba9\u5177\u6709\u4e0d\u540c\u53ef\u89c1\u533a\u57df\u7684\u7528\u6237\u5171\u4eab\u76f8\u540c\u9891\u7387\u5b50\u8f7d\u6ce2\u8fdb\u884c\u4fe1\u9053\u4f30\u8ba1\uff0c\u4ece\u800c\u4ee5\u66f4\u5c11\u7684\u5bfc\u9891\u5f00\u9500\u670d\u52a1\u66f4\u591a\u7528\u6237\u3002", "method": "1) \u63d0\u51fa\u65b0\u578b\u5bfc\u9891\u65b9\u6848\uff1a\u91c7\u7528\u9891\u5206\u590d\u7528\u8fdb\u884c\u7ec4\u95f4\u4fe1\u9053\u4f30\u8ba1\uff0c\u7ec4\u5185\u7528\u6237\u5229\u7528\u5f3a\u7a7a\u95f4\u6b63\u4ea4\u6027\u901a\u8fc7\u79fb\u4f4d\u5faa\u73af\u7801\u533a\u5206\uff08\u7c7b\u4f3c\u7801\u5206\u590d\u7528\uff09\uff1b2) \u5f15\u5165\u5b50\u9635\u5217\u7ed3\u6784ELAA\uff1a\u6bcf\u4e2a\u5b50\u9635\u5217\u4f5c\u4e3a\u4f20\u7edfMIMO\u9635\u5217\u5904\u7406\uff0c\u5b50\u9635\u5217\u95f4\u8ddd\u8f83\u5927\u4ee5\u6269\u5c55\u5b54\u5f84\uff1b3) \u5efa\u7acb\u4fe1\u9053\u6a21\u578b\uff1a\u5b50\u9635\u5217\u4fe1\u9053\u652f\u6301\u5728\u5929\u7ebf-\u5ef6\u8fdf\u57df\u5177\u6709\u805a\u7c7b\u7a00\u758f\u6027\uff0c\u91c7\u7528\u4e8c\u7ef4\u9a6c\u5c14\u53ef\u592b\u968f\u673a\u573a\u5efa\u6a21\uff1b4) \u63d0\u51fa\u4f4e\u590d\u6742\u5ea6\u4fe1\u9053\u4f30\u8ba1\u7b97\u6cd5\uff1a\u5728Turbo\u8d1d\u53f6\u65af\u63a8\u7406\u6846\u67b6\u4e2d\u878d\u5165\u4e8c\u7ef4MRF\u5148\u9a8c\u6a21\u578b\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u65b9\u6848\u548c\u7b97\u6cd5\u4f7fXL-MIMO\u7cfb\u7edf\u80fd\u591f\u652f\u6301\u66f4\u591a\u7528\u6237\uff0c\u5e76\u63d0\u4f9b\u4f18\u8d8a\u7684\u4fe1\u9053\u4f30\u8ba1\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u5229\u7528ELAA\u7684\u7a7a\u95f4\u975e\u5e73\u7a33\u6027\u548c\u8bbe\u8ba1\u521b\u65b0\u7684\u5bfc\u9891\u65b9\u6848\u4e0e\u4fe1\u9053\u4f30\u8ba1\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u5728\u51cf\u5c11\u5bfc\u9891\u5f00\u9500\u7684\u540c\u65f6\u652f\u6301\u66f4\u591a\u7528\u6237\uff0c\u4e3a\u8d85\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.10496", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10496", "abs": "https://arxiv.org/abs/2512.10496", "authors": ["Shilian Zheng", "Xiaoxiang Wu", "Luxin Zhang", "Keqiang Yue", "Peihan Qi", "Zhijin Zhao"], "title": "T-ADD: Enhancing DOA Estimation Robustness Against Adversarial Attacks", "comment": null, "summary": "Deep learning has achieved remarkable success in direction-of-arrival (DOA) estimation. However, recent studies have shown that adversarial perturbations can severely compromise the performance of such models. To address this vulnerability, we propose Transformer-based Adversarial Defense for DOA estimation (T-ADD), a transformer-based defense method designed to counter adversarial attacks. To achieve a balance between robustness and estimation accuracy, we formulate the adversarial defense as a joint reconstruction task and introduce a tailored joint loss function. Experimental results demonstrate that, compared with three state-of-the-art adversarial defense methods, the proposed T-ADD significantly mitigates the adverse effects of widely used adversarial attacks, leading to notable improvements in the adversarial robustness of the DOA model.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eTransformer\u7684\u5bf9\u6297\u9632\u5fa1\u65b9\u6cd5T-ADD\uff0c\u7528\u4e8e\u4fdd\u62a4DOA\u4f30\u8ba1\u6a21\u578b\u514d\u53d7\u5bf9\u6297\u653b\u51fb\u5f71\u54cd\uff0c\u901a\u8fc7\u8054\u5408\u91cd\u6784\u4efb\u52a1\u548c\u5b9a\u5236\u635f\u5931\u51fd\u6570\u5e73\u8861\u9c81\u68d2\u6027\u548c\u4f30\u8ba1\u7cbe\u5ea6\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728DOA\u4f30\u8ba1\u4e2d\u53d6\u5f97\u4e86\u663e\u8457\u6210\u529f\uff0c\u4f46\u7814\u7a76\u8868\u660e\u5bf9\u6297\u6270\u52a8\u4f1a\u4e25\u91cd\u635f\u5bb3\u6a21\u578b\u6027\u80fd\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u79cd\u8106\u5f31\u6027\u95ee\u9898\u3002", "method": "\u63d0\u51faTransformer-based Adversarial Defense for DOA estimation (T-ADD)\uff0c\u5c06\u5bf9\u6297\u9632\u5fa1\u5efa\u6a21\u4e3a\u8054\u5408\u91cd\u6784\u4efb\u52a1\uff0c\u5e76\u5f15\u5165\u5b9a\u5236\u7684\u8054\u5408\u635f\u5931\u51fd\u6570\u6765\u5e73\u8861\u9c81\u68d2\u6027\u548c\u4f30\u8ba1\u7cbe\u5ea6\u3002", "result": "\u4e0e\u4e09\u79cd\u6700\u5148\u8fdb\u7684\u5bf9\u6297\u9632\u5fa1\u65b9\u6cd5\u76f8\u6bd4\uff0cT-ADD\u663e\u8457\u51cf\u8f7b\u4e86\u5e7f\u6cdb\u4f7f\u7528\u7684\u5bf9\u6297\u653b\u51fb\u7684\u8d1f\u9762\u5f71\u54cd\uff0c\u663e\u8457\u63d0\u9ad8\u4e86DOA\u6a21\u578b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\u3002", "conclusion": "T-ADD\u65b9\u6cd5\u6709\u6548\u63d0\u5347\u4e86DOA\u4f30\u8ba1\u6a21\u578b\u7684\u5bf9\u6297\u9c81\u68d2\u6027\uff0c\u5728\u9632\u5fa1\u5bf9\u6297\u653b\u51fb\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2512.10731", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10731", "abs": "https://arxiv.org/abs/2512.10731", "authors": ["Yundi Zhang", "Yanshi Sun", "Li Chen"], "title": "NN-Based Frequency Domain DPD for OFDM Massive MIMO Transmitters With Multiple States", "comment": null, "summary": "Frequency domain (FD)-digital predistortion (DPD) is a low-complexity DPD solution for massive multiple-inputmultiple-output (MIMO) transmitters (TXs). In this letter, we extend FD-DPD to scenarios with multiple signal states (e.g., bandwidths and power levels). First, we propose a new neural network (NN)-based FD-DPD model, whose main idea is to use a hypernetwork (HN) to generate parameters for the output layer of the main NN based on the signal states. Then, we introduce how to effectively train the model with the help of time-domain (TD)-DPD. Experimental results show that the proposed model can achieve excellent performance, without requiring additional online training when signal states change.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8d85\u7f51\u7edc\u7684\u9891\u57df\u6570\u5b57\u9884\u5931\u771f\u6a21\u578b\uff0c\u7528\u4e8e\u591a\u4fe1\u53f7\u72b6\u6001\uff08\u5e26\u5bbd\u3001\u529f\u7387\uff09\u573a\u666f\uff0c\u65e0\u9700\u5728\u7ebf\u91cd\u8bad\u7ec3\u5373\u53ef\u9002\u5e94\u72b6\u6001\u53d8\u5316", "motivation": "\u9891\u57df\u6570\u5b57\u9884\u5931\u771f\uff08FD-DPD\uff09\u662f\u6d77\u91cfMIMO\u53d1\u5c04\u673a\u7684\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u89e3\u51b3\u65b9\u6848\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5904\u7406\u591a\u4fe1\u53f7\u72b6\u6001\uff08\u5982\u4e0d\u540c\u5e26\u5bbd\u548c\u529f\u7387\u6c34\u5e73\uff09\u573a\u666f", "method": "\u63d0\u51fa\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684FD-DPD\u6a21\u578b\uff0c\u4f7f\u7528\u8d85\u7f51\u7edc\u6839\u636e\u4fe1\u53f7\u72b6\u6001\u751f\u6210\u4e3b\u795e\u7ecf\u7f51\u7edc\u8f93\u51fa\u5c42\u53c2\u6570\uff0c\u5e76\u501f\u52a9\u65f6\u57dfDPD\u8fdb\u884c\u6709\u6548\u8bad\u7ec3", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u6a21\u578b\u80fd\u5b9e\u73b0\u4f18\u5f02\u6027\u80fd\uff0c\u5728\u4fe1\u53f7\u72b6\u6001\u53d8\u5316\u65f6\u65e0\u9700\u989d\u5916\u5728\u7ebf\u8bad\u7ec3", "conclusion": "\u57fa\u4e8e\u8d85\u7f51\u7edc\u7684FD-DPD\u6a21\u578b\u80fd\u6709\u6548\u9002\u5e94\u591a\u4fe1\u53f7\u72b6\u6001\u573a\u666f\uff0c\u63d0\u4f9b\u7075\u6d3b\u4e14\u9ad8\u6027\u80fd\u7684\u9884\u5931\u771f\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.10752", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10752", "abs": "https://arxiv.org/abs/2512.10752", "authors": ["Yufei Wang", "Qiang Li", "Hongli Liu", "Ying Zhang", "Jingran Lin"], "title": "Symbol-Level Precoding for Integrated Sensing and Covert Communication", "comment": "IEEE Journal on Selected Areas in Communications", "summary": "Integrated sensing and communication (ISAC) systems have emerged as a promising solution to improve spectrum efficiency and enable functional convergence. However, ensuring secure information transmission while maintaining high-quality sensing performance remains a significant challenge. In this paper, we investigate an integrated sensing and covert communication (ISCC) system, in which a base station (BS) simultaneously serves multiple downlink users and senses malicious targets that may act as both potential eavesdroppers (Eves) and wardens. We propose a novel symbol-level precoding (SLP)-based waveform design for ISCC that achieves covert communication intrinsically, without requiring additional transmission resources such as artificial noise. The proposed design integrates symbol shaping to enhance reliability for legitimate users and noise shaping to obscure transmission activities from the targets. For imperfect channel state information (CSI), the framework incorporates bounded uncertainty models for user channels and target angles, yielding a more robust design. The resulting ISCC waveform optimization problem is non-convex; to address this, we develop a low-complexity proximal distance algorithm (PDA) with closed-form updates under both PSK and QAM modulations. Simulation results demonstrate that the proposed method achieves superior covertness and sensing-communication performance with negligible degradation compared to traditional beamforming and conventional SLP approaches without noise-shaping mechanisms.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u7b26\u53f7\u7ea7\u9884\u7f16\u7801\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u9690\u853d\u901a\u4fe1\u7cfb\u7edf\u6ce2\u5f62\u8bbe\u8ba1\uff0c\u901a\u8fc7\u7b26\u53f7\u6574\u5f62\u548c\u566a\u58f0\u6574\u5f62\u5b9e\u73b0\u5185\u5728\u9690\u853d\u901a\u4fe1\uff0c\u65e0\u9700\u989d\u5916\u4eba\u5de5\u566a\u58f0\u8d44\u6e90\u3002", "motivation": "\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u5728\u63d0\u9ad8\u9891\u8c31\u6548\u7387\u548c\u529f\u80fd\u878d\u5408\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u4f46\u5982\u4f55\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u611f\u77e5\u6027\u80fd\u7684\u540c\u65f6\u786e\u4fdd\u4fe1\u606f\u5b89\u5168\u4f20\u8f93\u4ecd\u9762\u4e34\u6311\u6218\u3002\u6076\u610f\u76ee\u6807\u53ef\u80fd\u540c\u65f6\u5145\u5f53\u7a83\u542c\u8005\u548c\u76d1\u89c6\u8005\uff0c\u9700\u8981\u89e3\u51b3\u9690\u853d\u901a\u4fe1\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u7b26\u53f7\u7ea7\u9884\u7f16\u7801\u6ce2\u5f62\u8bbe\u8ba1\uff0c\u96c6\u6210\u7b26\u53f7\u6574\u5f62\u589e\u5f3a\u5408\u6cd5\u7528\u6237\u53ef\u9760\u6027\uff0c\u566a\u58f0\u6574\u5f62\u9690\u85cf\u4f20\u8f93\u6d3b\u52a8\u3002\u9488\u5bf9\u4e0d\u5b8c\u7f8e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff0c\u91c7\u7528\u6709\u754c\u4e0d\u786e\u5b9a\u6027\u6a21\u578b\u3002\u5f00\u53d1\u4f4e\u590d\u6742\u5ea6\u8fd1\u7aef\u8ddd\u79bb\u7b97\u6cd5\u6c42\u89e3\u975e\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u652f\u6301PSK\u548cQAM\u8c03\u5236\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u9690\u853d\u6027\u548c\u611f\u77e5-\u901a\u4fe1\u6027\u80fd\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u6ce2\u675f\u8d4b\u5f62\u548c\u4f20\u7edf\u7b26\u53f7\u7ea7\u9884\u7f16\u7801\u65b9\u6cd5\uff0c\u4e14\u6027\u80fd\u4e0b\u964d\u53ef\u5ffd\u7565\u4e0d\u8ba1\u3002", "conclusion": "\u63d0\u51fa\u7684\u7b26\u53f7\u7ea7\u9884\u7f16\u7801\u6ce2\u5f62\u8bbe\u8ba1\u4e3a\u96c6\u6210\u611f\u77e5\u4e0e\u9690\u853d\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5728\u4e0d\u589e\u52a0\u989d\u5916\u4f20\u8f93\u8d44\u6e90\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u5185\u5728\u9690\u853d\u901a\u4fe1\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.10809", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.10809", "abs": "https://arxiv.org/abs/2512.10809", "authors": ["Reinhard Wiesmayr", "Frederik Zumegen", "Sueda Taner", "Chris Dick", "Christoph Studer"], "title": "CSI-Based User Positioning, Channel Charting, and Device Classification with an NVIDIA 5G Testbed", "comment": "This work has been presented at the 59th Asilomar Conference on Signals, Systems, and Computers 2025", "summary": "Channel-state information (CSI)-based sensing will play a key role in future cellular systems. However, no CSI dataset has been published from a real-world 5G NR system that facilitates the development and validation of suitable sensing algorithms. To close this gap, we publish three real-world wideband multi-antenna multi-open RAN radio unit (O-RU) CSI datasets from the 5G NR uplink channel: an indoor lab/office room dataset, an outdoor campus courtyard dataset, and a device classification dataset with six commercial-off-the-shelf (COTS) user equipments (UEs). These datasets have been recorded using a software-defined 5G NR testbed based on NVIDIA Aerial RAN CoLab Over-the-Air (ARC-OTA) with COTS hardware, which we have deployed at ETH Zurich. We demonstrate the utility of these datasets for three CSI-based sensing tasks: neural UE positioning, channel charting in real-world coordinates, and closed-set device classification. For all these tasks, our results show high accuracy: neural UE positioning achieves 0.6cm (indoor) and 5.7cm (outdoor) mean absolute error, channel charting in real-world coordinates achieves 73cm mean absolute error (outdoor), and device classification achieves 99% (same day) and 95% (next day) accuracy. The CSI datasets, ground-truth UE position labels, CSI features, and simulation code are publicly available at https://caez.ethz.ch", "AI": {"tldr": "\u8be5\u8bba\u6587\u53d1\u5e03\u4e86\u9996\u4e2a\u6765\u81ea\u771f\u5b9e5G NR\u7cfb\u7edf\u7684CSI\u6570\u636e\u96c6\uff0c\u5305\u542b\u5ba4\u5185\u5916\u73af\u5883\u548c\u8bbe\u5907\u5206\u7c7b\u6570\u636e\uff0c\u5e76\u5c55\u793a\u4e86\u5728UE\u5b9a\u4f4d\u3001\u4fe1\u9053\u5236\u56fe\u548c\u8bbe\u5907\u5206\u7c7b\u7b49\u611f\u77e5\u4efb\u52a1\u4e2d\u7684\u9ad8\u7cbe\u5ea6\u5e94\u7528\u3002", "motivation": "\u867d\u7136\u57fa\u4e8eCSI\u7684\u611f\u77e5\u5728\u672a\u6765\u8702\u7a9d\u7cfb\u7edf\u4e2d\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u76ee\u524d\u7f3a\u4e4f\u6765\u81ea\u771f\u5b9e5G NR\u7cfb\u7edf\u7684\u516c\u5f00CSI\u6570\u636e\u96c6\u6765\u5f00\u53d1\u548c\u9a8c\u8bc1\u5408\u9002\u7684\u611f\u77e5\u7b97\u6cd5\uff0c\u8fd9\u963b\u788d\u4e86\u76f8\u5173\u7814\u7a76\u8fdb\u5c55\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eNVIDIA Aerial RAN CoLab OTA\u7684\u8f6f\u4ef6\u5b9a\u4e495G NR\u6d4b\u8bd5\u5e73\u53f0\uff0c\u5728ETH Zurich\u90e8\u7f72\u5e76\u91c7\u96c6\u4e86\u4e09\u4e2a\u771f\u5b9e\u4e16\u754c\u7684\u5bbd\u5e26\u591a\u5929\u7ebf\u591aO-RU CSI\u6570\u636e\u96c6\uff1a\u5ba4\u5185\u5b9e\u9a8c\u5ba4/\u529e\u516c\u5ba4\u3001\u5ba4\u5916\u6821\u56ed\u5ead\u9662\u4ee5\u53ca\u5305\u542b6\u79cd\u5546\u7528UE\u8bbe\u5907\u7684\u5206\u7c7b\u6570\u636e\u96c6\u3002", "result": "\u5728\u4e09\u4e2aCSI\u611f\u77e5\u4efb\u52a1\u4e2d\u5747\u53d6\u5f97\u9ad8\u7cbe\u5ea6\uff1a\u795e\u7ecfUE\u5b9a\u4f4d\u8fbe\u52300.6cm\uff08\u5ba4\u5185\uff09\u548c5.7cm\uff08\u5ba4\u5916\uff09\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff1b\u771f\u5b9e\u4e16\u754c\u5750\u6807\u4fe1\u9053\u5236\u56fe\u8fbe\u523073cm\u5e73\u5747\u7edd\u5bf9\u8bef\u5dee\uff08\u5ba4\u5916\uff09\uff1b\u8bbe\u5907\u5206\u7c7b\u8fbe\u523099%\uff08\u540c\u4e00\u5929\uff09\u548c95%\uff08\u7b2c\u4e8c\u5929\uff09\u51c6\u786e\u7387\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u771f\u5b9e5G NR\u7cfb\u7edfCSI\u6570\u636e\u96c6\u7684\u7a7a\u767d\uff0c\u4e3aCSI\u611f\u77e5\u7b97\u6cd5\u5f00\u53d1\u63d0\u4f9b\u4e86\u5b9d\u8d35\u8d44\u6e90\uff0c\u5e76\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u6570\u636e\u96c6\u5728\u591a\u79cd\u611f\u77e5\u4efb\u52a1\u4e2d\u7684\u5b9e\u7528\u6027\u548c\u9ad8\u7cbe\u5ea6\u6f5c\u529b\u3002"}}
{"id": "2512.10829", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10829", "abs": "https://arxiv.org/abs/2512.10829", "authors": ["Vitor G. P. Curtarelli"], "title": "Comparative analysis of WNG-DF compromising beamformers", "comment": null, "summary": "This work studies beamformers designed to achieve multiple characteristics simultaneously, specifically those compromising white-noise gain and directivity factor. We compare methods explicitly designed for these joint features against those obtained by combining specific single-task beamformers. Through simulations, we demonstrate that the robust superdirective and the tunable beamformers yield the best results among those studied. Notably, these two methods produced nearly identical outputs across all evaluated metrics. These two are also more practical, continuously compromising between the two objectives.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6bd4\u8f83\u4e86\u540c\u65f6\u4f18\u5316\u767d\u566a\u58f0\u589e\u76ca\u548c\u6307\u5411\u6027\u56e0\u5b50\u7684\u591a\u7279\u6027\u6ce2\u675f\u5f62\u6210\u5668\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u53d1\u73b0\u9c81\u68d2\u8d85\u6307\u5411\u548c\u53ef\u8c03\u6ce2\u675f\u5f62\u6210\u5668\u6027\u80fd\u6700\u4f73\u4e14\u51e0\u4e4e\u76f8\u540c\uff0c\u80fd\u5b9e\u73b0\u4e24\u4e2a\u76ee\u6807\u7684\u8fde\u7eed\u6298\u8877\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u662f\u8bbe\u8ba1\u80fd\u591f\u540c\u65f6\u5b9e\u73b0\u591a\u4e2a\u7279\u6027\uff08\u7279\u522b\u662f\u767d\u566a\u58f0\u589e\u76ca\u548c\u6307\u5411\u6027\u56e0\u5b50\u6298\u8877\uff09\u7684\u6ce2\u675f\u5f62\u6210\u5668\uff0c\u6bd4\u8f83\u4e13\u95e8\u8bbe\u8ba1\u7684\u8054\u5408\u4f18\u5316\u65b9\u6cd5\u4e0e\u7ec4\u5408\u5355\u4efb\u52a1\u6ce2\u675f\u5f62\u6210\u5668\u7684\u6548\u679c\u3002", "method": "\u901a\u8fc7\u4eff\u771f\u6bd4\u8f83\u4e24\u79cd\u65b9\u6cd5\uff1a1\uff09\u4e13\u95e8\u4e3a\u8054\u5408\u7279\u6027\u8bbe\u8ba1\u7684\u6ce2\u675f\u5f62\u6210\u5668\uff1b2\uff09\u7ec4\u5408\u7279\u5b9a\u5355\u4efb\u52a1\u6ce2\u675f\u5f62\u6210\u5668\u7684\u65b9\u6cd5\u3002\u91cd\u70b9\u8bc4\u4f30\u9c81\u68d2\u8d85\u6307\u5411\u548c\u53ef\u8c03\u6ce2\u675f\u5f62\u6210\u5668\u7684\u6027\u80fd\u3002", "result": "\u9c81\u68d2\u8d85\u6307\u5411\u548c\u53ef\u8c03\u6ce2\u675f\u5f62\u6210\u5668\u5728\u6240\u6709\u8bc4\u4f30\u6307\u6807\u4e2d\u8868\u73b0\u6700\u4f73\uff0c\u4e14\u4e24\u79cd\u65b9\u6cd5\u4ea7\u751f\u51e0\u4e4e\u76f8\u540c\u7684\u8f93\u51fa\u7ed3\u679c\u3002\u8fd9\u4e24\u79cd\u65b9\u6cd5\u66f4\u5177\u5b9e\u7528\u6027\uff0c\u80fd\u591f\u5b9e\u73b0\u4e24\u4e2a\u76ee\u6807\u4e4b\u95f4\u7684\u8fde\u7eed\u6298\u8877\u3002", "conclusion": "\u5bf9\u4e8e\u540c\u65f6\u4f18\u5316\u767d\u566a\u58f0\u589e\u76ca\u548c\u6307\u5411\u6027\u56e0\u5b50\u7684\u6ce2\u675f\u5f62\u6210\u5668\u8bbe\u8ba1\uff0c\u9c81\u68d2\u8d85\u6307\u5411\u548c\u53ef\u8c03\u6ce2\u675f\u5f62\u6210\u5668\u662f\u6700\u4f18\u9009\u62e9\uff0c\u5b83\u4eec\u6027\u80fd\u76f8\u5f53\u4e14\u80fd\u63d0\u4f9b\u7075\u6d3b\u7684\u76ee\u6807\u6298\u8877\u65b9\u6848\u3002"}}
{"id": "2512.10832", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10832", "abs": "https://arxiv.org/abs/2512.10832", "authors": ["Karel P\u00e4rlin", "Aaron Byman", "Tommi Meril\u00e4inen", "Taneli Riihonen"], "title": "A Variable Step Sizes Frequency Offsets-Compensated Least Mean Squares Algorithm", "comment": "Submitted to an IEEE journal", "summary": "Frequency offsets-compensated least mean squares (FO-LMS) algorithm is a generic method for estimating a wireless channel under carrier and sampling frequency offsets when the transmitted signal is beforehand known to the receiver. The algorithm iteratively and explicitly adjusts its estimates of the channel and frequency offsets using stochastic gradient descent-based rules and the step sizes of these rules determine the learning rate and stability of the algorithm. Within the stability conditions, the choice of step sizes reflects a trade-off between the algorithm's ability to react to changes in the channel and the ability to minimize misadjustments caused by noise. This paper provides theoretical expressions to predict and optimize the tracking and misadjusment errors of FO-LMS when estimating channels and frequency offsets with known time-varying characteristics. This work also proposes a method to adjust the FO-LMS's step sizes based on the algorithm's performance when the time-varying characteristics are not known, which is more often the case in practice. Accuracy of the expressions and performance of the proposed variable step sizes algorithm are studied through simulations.", "AI": {"tldr": "FO-LMS\u7b97\u6cd5\u7528\u4e8e\u65e0\u7ebf\u4fe1\u9053\u4f30\u8ba1\uff0c\u672c\u6587\u63d0\u51fa\u7406\u8bba\u8868\u8fbe\u5f0f\u9884\u6d4b\u548c\u4f18\u5316\u5176\u8ddf\u8e2a\u8bef\u5dee\u4e0e\u5931\u8c03\u8bef\u5dee\uff0c\u5e76\u63d0\u51fa\u81ea\u9002\u5e94\u6b65\u957f\u8c03\u6574\u65b9\u6cd5", "motivation": "FO-LMS\u7b97\u6cd5\u5728\u5b58\u5728\u8f7d\u6ce2\u548c\u91c7\u6837\u9891\u7387\u504f\u79fb\u65f6\u4f30\u8ba1\u65e0\u7ebf\u4fe1\u9053\uff0c\u4f46\u6b65\u957f\u9009\u62e9\u9700\u8981\u5728\u4fe1\u9053\u53d8\u5316\u54cd\u5e94\u80fd\u529b\u548c\u566a\u58f0\u5f15\u8d77\u7684\u5931\u8c03\u4e4b\u95f4\u6743\u8861\u3002\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u65f6\u53d8\u7279\u6027\u7684\u7406\u8bba\u5206\u6790\u548c\u81ea\u9002\u5e94\u6b65\u957f\u8c03\u6574\u673a\u5236\u3002", "method": "1) \u63a8\u5bfc\u7406\u8bba\u8868\u8fbe\u5f0f\u9884\u6d4bFO-LMS\u5728\u5df2\u77e5\u65f6\u53d8\u7279\u6027\u4e0b\u7684\u8ddf\u8e2a\u8bef\u5dee\u548c\u5931\u8c03\u8bef\u5dee\uff1b2) \u63d0\u51fa\u57fa\u4e8e\u7b97\u6cd5\u6027\u80fd\u7684\u81ea\u9002\u5e94\u6b65\u957f\u8c03\u6574\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u65f6\u53d8\u7279\u6027\u672a\u77e5\u7684\u5b9e\u9645\u60c5\u51b5", "result": "\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u7406\u8bba\u8868\u8fbe\u5f0f\u7684\u51c6\u786e\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u6240\u63d0\u81ea\u9002\u5e94\u6b65\u957f\u7b97\u6cd5\u5728\u5b9e\u9645\u672a\u77e5\u65f6\u53d8\u7279\u6027\u4e0b\u7684\u6027\u80fd\u8868\u73b0", "conclusion": "\u672c\u6587\u4e3aFO-LMS\u7b97\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u6846\u67b6\u548c\u5b9e\u7528\u7684\u81ea\u9002\u5e94\u6b65\u957f\u8c03\u6574\u65b9\u6cd5\uff0c\u63d0\u9ad8\u4e86\u5728\u65f6\u53d8\u4fe1\u9053\u548c\u9891\u7387\u504f\u79fb\u6761\u4ef6\u4e0b\u7684\u4f30\u8ba1\u6027\u80fd"}}
{"id": "2512.10833", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10833", "abs": "https://arxiv.org/abs/2512.10833", "authors": ["Karel P\u00e4rlin", "Aaron Byman", "Tommi Meril\u00e4inen", "Taneli Riihonen"], "title": "Decision Feedback-Aided Known-Interference Cancellation", "comment": "Submitted to an IEEE journal", "summary": "Known-interference cancellation (KIC) in combination with cooperative jamming can be used to provide covertness and security to wireless communications at the physical layer. However, since the signal of interest (SI) of a wireless communication system acts as estimation noise, i.e., interference, to KIC, the SI limits the extent to which the known interference (KI) can be canceled and that in turn limits the throughput of the wireless communication system that is being hidden or secured. In this letter, we analyze a decision feedback-aided known-interference cancellation (DF-KIC) structure in which both the KI and SI are canceled iteratively and successively. Measurement results demonstrate that introducing decision feedback to KIC improves its KI cancellation capability and hence increases the wireless communication system's useful throughput, albeit at the expense of a higher computational load.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u51b3\u7b56\u53cd\u9988\u7684\u5df2\u77e5\u5e72\u6270\u6d88\u9664(DF-KIC)\u7ed3\u6784\uff0c\u901a\u8fc7\u8fed\u4ee3\u8fde\u7eed\u6d88\u9664\u5df2\u77e5\u5e72\u6270\u548c\u4fe1\u53f7\u5e72\u6270\uff0c\u63d0\u9ad8\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684\u9690\u853d\u6027\u548c\u5b89\u5168\u6027", "motivation": "\u4f20\u7edf\u5df2\u77e5\u5e72\u6270\u6d88\u9664(KIC)\u7ed3\u5408\u534f\u4f5c\u5e72\u6270\u53ef\u4e3a\u65e0\u7ebf\u901a\u4fe1\u63d0\u4f9b\u7269\u7406\u5c42\u9690\u853d\u6027\u548c\u5b89\u5168\u6027\uff0c\u4f46\u4fe1\u53f7\u5e72\u6270\u4f1a\u9650\u5236\u5df2\u77e5\u5e72\u6270\u7684\u6d88\u9664\u7a0b\u5ea6\uff0c\u4ece\u800c\u9650\u5236\u88ab\u9690\u85cf\u6216\u4fdd\u62a4\u7684\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684\u541e\u5410\u91cf", "method": "\u63d0\u51fa\u51b3\u7b56\u53cd\u9988\u8f85\u52a9\u7684\u5df2\u77e5\u5e72\u6270\u6d88\u9664(DF-KIC)\u7ed3\u6784\uff0c\u901a\u8fc7\u8fed\u4ee3\u548c\u8fde\u7eed\u7684\u65b9\u5f0f\u540c\u65f6\u6d88\u9664\u5df2\u77e5\u5e72\u6270\u548c\u4fe1\u53f7\u5e72\u6270", "result": "\u6d4b\u91cf\u7ed3\u679c\u8868\u660e\uff0c\u5728KIC\u4e2d\u5f15\u5165\u51b3\u7b56\u53cd\u9988\u63d0\u9ad8\u4e86\u5176\u5df2\u77e5\u5e72\u6270\u6d88\u9664\u80fd\u529b\uff0c\u4ece\u800c\u589e\u52a0\u4e86\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684\u6709\u6548\u541e\u5410\u91cf\uff0c\u4f46\u4ee3\u4ef7\u662f\u66f4\u9ad8\u7684\u8ba1\u7b97\u8d1f\u8f7d", "conclusion": "DF-KIC\u7ed3\u6784\u901a\u8fc7\u6539\u8fdb\u5e72\u6270\u6d88\u9664\u80fd\u529b\uff0c\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u589e\u52a0\u7684\u60c5\u51b5\u4e0b\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684\u9690\u853d\u901a\u4fe1\u541e\u5410\u91cf"}}
{"id": "2512.10879", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.10879", "abs": "https://arxiv.org/abs/2512.10879", "authors": ["Sauradeep Dey", "Musa Furkan Keskin", "Dario Tagliaferri", "Gonzalo Seco-Granados", "Mikko Valkama", "Henk Wymeersch"], "title": "POLO: Phase-Only Localization in Uplink Distributed MIMO Systems", "comment": null, "summary": "We propose a low-complexity localization framework for uplink distributed MIMO (D-MIMO) systems, targeting the challenge of minimizing the highly spiky maximum-likelihood (ML) cost function that arises in sparsely deployed phasecoherent access points (APs) with narrowband transmission. In such systems, ML-based localization typically relies on dense grid search, incurring prohibitive computational complexity. To address this, we introduce phase-only localization (POLO), an approach that leverages differential carrier-phase measurements from selected APs to generate a compact set of candidate user positions. The ML cost function is then evaluated only at these candidates, reducing complexity significantly. A key challenge is to devise an AP selection mechanism that reduces the number of candidate points while maintaining reliable coverage. We propose two variants: POLO-I, which selects three APs to provide closed-form candidate positions with low computational cost, and POLO-II, which selects four APs using an alternative strategy that enhances coverage at marginally higher runtime. Comprehensive analytical and simulation results show that POLO achieves a favorable coverage-complexity trade-off, reducing cost by orders of magnitude relative to exhaustive grid search with only marginal loss in coverage. By characterizing this tradeoff under diverse AP configurations, we also provide practical guidelines for selecting between POLO-I and POLO-II depending on latency and coverage requirements.", "AI": {"tldr": "\u63d0\u51faPOLO\u4f4e\u590d\u6742\u5ea6\u5b9a\u4f4d\u6846\u67b6\uff0c\u5229\u7528\u5dee\u5206\u8f7d\u6ce2\u76f8\u4f4d\u6d4b\u91cf\u751f\u6210\u5019\u9009\u4f4d\u7f6e\uff0c\u5927\u5e45\u964d\u4f4e\u5206\u5e03\u5f0fMIMO\u7cfb\u7edfML\u5b9a\u4f4d\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u5206\u5e03\u5f0fMIMO\u7cfb\u7edf\u4e2d\uff0c\u57fa\u4e8e\u6700\u5927\u4f3c\u7136\u7684\u5b9a\u4f4d\u901a\u5e38\u9700\u8981\u5bc6\u96c6\u7f51\u683c\u641c\u7d22\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u6781\u9ad8\u3002\u7279\u522b\u662f\u5728\u7a00\u758f\u90e8\u7f72\u7684\u76f8\u4f4d\u76f8\u5e72\u63a5\u5165\u70b9\u3001\u7a84\u5e26\u4f20\u8f93\u573a\u666f\u4e0b\uff0cML\u4ee3\u4ef7\u51fd\u6570\u9ad8\u5ea6\u5c16\u5cf0\uff0c\u9700\u8981\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faPOLO\uff08\u76f8\u4f4d\u5b9a\u4f4d\uff09\u6846\u67b6\uff1a1\uff09\u5229\u7528\u9009\u5b9aAP\u7684\u5dee\u5206\u8f7d\u6ce2\u76f8\u4f4d\u6d4b\u91cf\u751f\u6210\u7d27\u51d1\u7684\u5019\u9009\u7528\u6237\u4f4d\u7f6e\u96c6\u5408\uff1b2\uff09\u4ec5\u5728\u5019\u9009\u70b9\u4e0a\u8bc4\u4f30ML\u4ee3\u4ef7\u51fd\u6570\u3002\u63d0\u51fa\u4e24\u79cd\u53d8\u4f53\uff1aPOLO-I\u9009\u62e93\u4e2aAP\u63d0\u4f9b\u95ed\u5f0f\u5019\u9009\u4f4d\u7f6e\uff08\u4f4e\u8ba1\u7b97\u6210\u672c\uff09\uff0cPOLO-II\u9009\u62e94\u4e2aAP\uff08\u589e\u5f3a\u8986\u76d6\uff0c\u7a0d\u9ad8\u8fd0\u884c\u65f6\uff09\u3002", "result": "POLO\u5728\u8986\u76d6-\u590d\u6742\u5ea6\u6743\u8861\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u76f8\u6bd4\u7a77\u4e3e\u7f51\u683c\u641c\u7d22\u5c06\u6210\u672c\u964d\u4f4e\u6570\u4e2a\u6570\u91cf\u7ea7\uff0c\u4ec5\u5e26\u6765\u8fb9\u9645\u8986\u76d6\u635f\u5931\u3002\u5728\u4e0d\u540cAP\u914d\u7f6e\u4e0b\u8868\u5f81\u4e86\u8fd9\u79cd\u6743\u8861\uff0c\u4e3a\u6839\u636e\u5ef6\u8fdf\u548c\u8986\u76d6\u9700\u6c42\u9009\u62e9POLO-I\u6216POLO-II\u63d0\u4f9b\u5b9e\u7528\u6307\u5357\u3002", "conclusion": "POLO\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u5206\u5e03\u5f0fMIMO\u7cfb\u7edfML\u5b9a\u4f4d\u7684\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u901a\u8fc7\u76f8\u4f4d\u6d4b\u91cf\u548c\u667a\u80fdAP\u9009\u62e9\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u590d\u6742\u5ea6\u964d\u4f4e\uff0c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u5b9a\u4f4d\u89e3\u51b3\u65b9\u6848\u3002"}}

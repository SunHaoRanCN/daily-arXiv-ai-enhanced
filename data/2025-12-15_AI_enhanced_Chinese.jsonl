{"id": "2512.11543", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2512.11543", "abs": "https://arxiv.org/abs/2512.11543", "authors": ["Takafumi Moriya", "Masato Mimura", "Tomohiro Tanaka", "Hiroshi Sato", "Ryo Masumura", "Atsunori Ogawa"], "title": "All-in-One ASR: Unifying Encoder-Decoder Models of CTC, Attention, and Transducer in Dual-Mode ASR", "comment": "Accepted to ASRU 2025", "summary": "This paper proposes a unified framework, All-in-One ASR, that allows a single model to support multiple automatic speech recognition (ASR) paradigms, including connectionist temporal classification (CTC), attention-based encoder-decoder (AED), and Transducer, in both offline and streaming modes. While each ASR architecture offers distinct advantages and trade-offs depending on the application, maintaining separate models for each scenario incurs substantial development and deployment costs. To address this issue, we introduce a multi-mode joiner that enables seamless integration of various ASR modes within a single unified model. Experiments show that All-in-One ASR significantly reduces the total model footprint while matching or even surpassing the recognition performance of individually optimized ASR models. Furthermore, joint decoding leverages the complementary strengths of different ASR modes, yielding additional improvements in recognition accuracy.", "AI": {"tldr": "\u63d0\u51faAll-in-One ASR\u7edf\u4e00\u6846\u67b6\uff0c\u5355\u4e2a\u6a21\u578b\u652f\u6301CTC\u3001AED\u3001Transducer\u7b49\u591a\u79cdASR\u8303\u5f0f\uff0c\u517c\u987e\u79bb\u7ebf\u548c\u6d41\u5f0f\u6a21\u5f0f\uff0c\u51cf\u5c11\u6a21\u578b\u90e8\u7f72\u6210\u672c", "motivation": "\u4e0d\u540cASR\u67b6\u6784\u5404\u6709\u4f18\u52bf\uff0c\u4f46\u4e3a\u6bcf\u79cd\u573a\u666f\u7ef4\u62a4\u72ec\u7acb\u6a21\u578b\u5e26\u6765\u9ad8\u6602\u5f00\u53d1\u548c\u90e8\u7f72\u6210\u672c\uff0c\u9700\u8981\u7edf\u4e00\u89e3\u51b3\u65b9\u6848", "method": "\u5f15\u5165\u591a\u6a21\u5f0f\u8fde\u63a5\u5668\uff0c\u5728\u5355\u4e2a\u7edf\u4e00\u6a21\u578b\u4e2d\u65e0\u7f1d\u96c6\u6210\u591a\u79cdASR\u6a21\u5f0f\uff0c\u652f\u6301\u8054\u5408\u89e3\u7801", "result": "\u663e\u8457\u51cf\u5c11\u6a21\u578b\u603b\u5360\u7528\u7a7a\u95f4\uff0c\u8bc6\u522b\u6027\u80fd\u5339\u914d\u751a\u81f3\u8d85\u8d8a\u72ec\u7acb\u4f18\u5316\u7684ASR\u6a21\u578b\uff0c\u8054\u5408\u89e3\u7801\u8fdb\u4e00\u6b65\u63d0\u5347\u51c6\u786e\u7387", "conclusion": "All-in-One ASR\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u591aASR\u8303\u5f0f\u7edf\u4e00\u95ee\u9898\uff0c\u964d\u4f4e\u90e8\u7f72\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u6216\u63d0\u5347\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u7528\u4ef7\u503c"}}
{"id": "2512.11231", "categories": ["eess.SP", "eess.AS"], "pdf": "https://arxiv.org/pdf/2512.11231", "abs": "https://arxiv.org/abs/2512.11231", "authors": ["Siyuan Cang", "Cong Liu", "Xueli Sheng", "Xiaoming Cui", "Chao Li", "Changxin Fa", "Jiantong Chen", "Chaoran Yang", "Huayong Yang"], "title": "Robust Detection of Underwater Target Against Non-Uniform Noise With Optical Fiber DAS Array", "comment": "17 pages, 29 figures. The IEEE Transactions on Instrumentation and Measurement has accepted this research for publication, and it is currently accessible in its early access version", "summary": "The detection of underwater targets is severely affected by the non-uniform spatial characteristics of marine environmental noise. Additionally, the presence of both natural and anthropogenic acoustic sources, including shipping traffic, marine life, and geological activity, further complicates the underwater acoustic landscape. Addressing these challenges requires advanced underwater sensors and robust signal processing techniques. In this paper, we present a novel approach that leverages an optical fiber distributed acoustic sensing (DAS) system combined with a broadband generalized sparse covariance-fitting framework for underwater target direction sensing, particularly focusing on robustness against non-uniform noise. The DAS system incorporates a newly developed spiral-sensitized optical cable, which significantly improves sensitivity compared to conventional submarine cables. This innovative design enables the system to capture acoustic signals with greater precision. Notably, the sensitivity of the spiral-wound sensitized cable is around -145.69 dB re: 1 rad / (uPa*m), as measured inside the standing-wave tube. Employing simulations, we assess the performance of the algorithm across diverse noise levels and target configurations, consistently revealing higher accuracy and reduced background noise compared to conventional beamforming techniques and other sparse techniques. In a controlled pool experiment, the correlation coefficient between waveforms acquired by the DAS system and a standard hydrophone reached 0.973, indicating high fidelity in signal capture.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u5149\u7ea4\u5206\u5e03\u5f0f\u58f0\u5b66\u4f20\u611f\u7cfb\u7edf\u4e0e\u5bbd\u5e26\u5e7f\u4e49\u7a00\u758f\u534f\u65b9\u5dee\u62df\u5408\u6846\u67b6\u7684\u6c34\u4e0b\u76ee\u6807\u65b9\u5411\u611f\u77e5\u65b0\u65b9\u6cd5\uff0c\u9488\u5bf9\u975e\u5747\u5300\u6d77\u6d0b\u566a\u58f0\u73af\u5883\uff0c\u901a\u8fc7\u65b0\u578b\u87ba\u65cb\u654f\u611f\u5149\u7f06\u63d0\u5347\u7075\u654f\u5ea6\uff0c\u5728\u4eff\u771f\u548c\u6c60\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u4e86\u4f18\u4e8e\u4f20\u7edf\u6ce2\u675f\u5f62\u6210\u548c\u5176\u4ed6\u7a00\u758f\u6280\u672f\u7684\u6027\u80fd\u3002", "motivation": "\u6d77\u6d0b\u73af\u5883\u566a\u58f0\u7684\u975e\u5747\u5300\u7a7a\u95f4\u7279\u6027\u4e25\u91cd\u5f71\u54cd\u6c34\u4e0b\u76ee\u6807\u68c0\u6d4b\uff0c\u52a0\u4e0a\u822a\u8fd0\u3001\u6d77\u6d0b\u751f\u7269\u3001\u5730\u8d28\u6d3b\u52a8\u7b49\u81ea\u7136\u548c\u4eba\u4e3a\u58f0\u6e90\u4f7f\u6c34\u4e0b\u58f0\u5b66\u73af\u5883\u590d\u6742\u5316\uff0c\u9700\u8981\u5148\u8fdb\u7684\u6c34\u4e0b\u4f20\u611f\u5668\u548c\u9c81\u68d2\u4fe1\u53f7\u5904\u7406\u6280\u672f\u6765\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u91c7\u7528\u5149\u7ea4\u5206\u5e03\u5f0f\u58f0\u5b66\u4f20\u611f\u7cfb\u7edf\u7ed3\u5408\u5bbd\u5e26\u5e7f\u4e49\u7a00\u758f\u534f\u65b9\u5dee\u62df\u5408\u6846\u67b6\uff0c\u7cfb\u7edf\u5305\u542b\u65b0\u5f00\u53d1\u7684\u87ba\u65cb\u654f\u611f\u5149\u7f06\uff0c\u7075\u654f\u5ea6\u8fbe-145.69 dB re: 1 rad/(uPa*m)\uff0c\u76f8\u6bd4\u4f20\u7edf\u6d77\u5e95\u7535\u7f06\u663e\u8457\u63d0\u5347\u7075\u654f\u5ea6\uff0c\u901a\u8fc7\u4eff\u771f\u8bc4\u4f30\u7b97\u6cd5\u5728\u4e0d\u540c\u566a\u58f0\u6c34\u5e73\u548c\u76ee\u6807\u914d\u7f6e\u4e0b\u7684\u6027\u80fd\u3002", "result": "\u4eff\u771f\u663e\u793a\u8be5\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u80cc\u666f\u566a\u58f0\u6291\u5236\u65b9\u9762\u4f18\u4e8e\u4f20\u7edf\u6ce2\u675f\u5f62\u6210\u6280\u672f\u548c\u5176\u4ed6\u7a00\u758f\u6280\u672f\uff1b\u6c60\u5b9e\u9a8c\u4e2dDAS\u7cfb\u7edf\u4e0e\u6807\u51c6\u6c34\u542c\u5668\u83b7\u53d6\u6ce2\u5f62\u7684\u76f8\u5173\u7cfb\u6570\u8fbe0.973\uff0c\u8868\u660e\u4fe1\u53f7\u6355\u83b7\u4fdd\u771f\u5ea6\u9ad8\u3002", "conclusion": "\u63d0\u51fa\u7684\u5149\u7ea4DAS\u7cfb\u7edf\u4e0e\u7a00\u758f\u534f\u65b9\u5dee\u62df\u5408\u6846\u67b6\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u5e94\u5bf9\u975e\u5747\u5300\u6d77\u6d0b\u566a\u58f0\u73af\u5883\uff0c\u65b0\u578b\u87ba\u65cb\u654f\u611f\u5149\u7f06\u8bbe\u8ba1\u63d0\u5347\u4e86\u7cfb\u7edf\u7075\u654f\u5ea6\uff0c\u4e3a\u6c34\u4e0b\u76ee\u6807\u65b9\u5411\u611f\u77e5\u63d0\u4f9b\u4e86\u9ad8\u7cbe\u5ea6\u3001\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.10965", "categories": ["eess.SP", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.10965", "abs": "https://arxiv.org/abs/2512.10965", "authors": ["Qiming Zhang", "Xiucheng Wang", "Nan Cheng", "Zhisheng Yin", "Xiang Li"], "title": "RMSup: Physics-Informed Radio Map Super-Resolution for Compute-Enhanced Integrated Sensing and Communications", "comment": null, "summary": "Radio maps (RMs) provide a spatially continuous description of wireless propagation, enabling cross-layer optimization and unifying communication and sensing for integrated sensing and communications (ISAC). However, constructing high-fidelity RMs at operational scales is difficult, since physics-based solvers are time-consuming and require precise scene models, while learning methods degrade under incomplete priors and sparse measurements, often smoothing away critical discontinuities. We present RMSup, a physics-informed super-resolution framework that functions with uniform sparse sampling and imperfect environment priors. RMSup extracts Helmholtz equation-informed boundary and singularity prompts from the measurements, fuses them with base-station side information and coarse scene descriptors as conditional inputs, and employs a boundary-aware dual-head network to reconstruct a high-fidelity RM and recover environmental contours jointly. Experimental results show the proposed RMsup achieves state-of-the-art performance both in RM construction and ISAC-related environment sensing.", "AI": {"tldr": "RMSup\uff1a\u4e00\u79cd\u7269\u7406\u4fe1\u606f\u9a71\u52a8\u7684\u8d85\u5206\u8fa8\u7387\u6846\u67b6\uff0c\u7528\u4e8e\u5728\u7a00\u758f\u91c7\u6837\u548c\u4e0d\u5b8c\u7f8e\u73af\u5883\u5148\u9a8c\u4e0b\u6784\u5efa\u9ad8\u4fdd\u771f\u65e0\u7ebf\u5730\u56fe\uff0c\u540c\u65f6\u6062\u590d\u73af\u5883\u8f6e\u5ed3", "motivation": "\u65e0\u7ebf\u5730\u56fe\uff08RMs\uff09\u5bf9\u4e8e\u8de8\u5c42\u4f18\u5316\u548c\u901a\u4fe1\u611f\u77e5\u4e00\u4f53\u5316\uff08ISAC\uff09\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u64cd\u4f5c\u89c4\u6a21\u4e0a\u6784\u5efa\u9ad8\u4fdd\u771f\u5730\u56fe\u3002\u57fa\u4e8e\u7269\u7406\u7684\u6c42\u89e3\u5668\u8017\u65f6\u4e14\u9700\u8981\u7cbe\u786e\u573a\u666f\u6a21\u578b\uff0c\u800c\u5b66\u4e60\u65b9\u6cd5\u5728\u7a00\u758f\u6d4b\u91cf\u548c\u4e0d\u5b8c\u6574\u5148\u9a8c\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u901a\u5e38\u4f1a\u5e73\u6ed1\u6389\u5173\u952e\u7684\u7269\u7406\u4e0d\u8fde\u7eed\u6027\u3002", "method": "\u63d0\u51faRMSup\u6846\u67b6\uff1a1\uff09\u4ece\u6d4b\u91cf\u4e2d\u63d0\u53d6\u4ea5\u59c6\u970d\u5179\u65b9\u7a0b\u4fe1\u606f\u7684\u8fb9\u754c\u548c\u5947\u70b9\u63d0\u793a\uff1b2\uff09\u5c06\u8fd9\u4e9b\u63d0\u793a\u4e0e\u57fa\u7ad9\u4fa7\u4fe1\u606f\u548c\u7c97\u7cd9\u573a\u666f\u63cf\u8ff0\u7b26\u878d\u5408\u4f5c\u4e3a\u6761\u4ef6\u8f93\u5165\uff1b3\uff09\u4f7f\u7528\u8fb9\u754c\u611f\u77e5\u7684\u53cc\u5934\u7f51\u7edc\u8054\u5408\u91cd\u5efa\u9ad8\u4fdd\u771f\u65e0\u7ebf\u5730\u56fe\u5e76\u6062\u590d\u73af\u5883\u8f6e\u5ed3\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cRMSup\u5728\u65e0\u7ebf\u5730\u56fe\u6784\u5efa\u548cISAC\u76f8\u5173\u73af\u5883\u611f\u77e5\u65b9\u9762\u5747\u5b9e\u73b0\u4e86\u6700\u5148\u8fdb\u7684\u6027\u80fd\u3002", "conclusion": "RMSup\u80fd\u591f\u5728\u5747\u5300\u7a00\u758f\u91c7\u6837\u548c\u4e0d\u5b8c\u7f8e\u73af\u5883\u5148\u9a8c\u6761\u4ef6\u4e0b\u6709\u6548\u6784\u5efa\u9ad8\u4fdd\u771f\u65e0\u7ebf\u5730\u56fe\uff0c\u540c\u65f6\u6062\u590d\u73af\u5883\u8f6e\u5ed3\uff0c\u4e3aISAC\u5e94\u7528\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.11009", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.11009", "abs": "https://arxiv.org/abs/2512.11009", "authors": ["Nikhil Raghav", "Arnab Banerjee", "Janojit Chakraborty", "Avisek Gupta", "Swami Punyeshwarananda", "Md Sahidullah"], "title": "The TCG CREST -- RKMVERI Submission for the NCIIPC Startup India AI Grand Challenge", "comment": "6 pages, 3 tables, 3 figures, report submission for the NCIIPC Startup India AI Grand Challenge, Problem Statement 06", "summary": "In this report, we summarize the integrated multilingual audio processing pipeline developed by our team for the inaugural NCIIPC Startup India AI GRAND CHALLENGE, addressing Problem Statement 06: Language-Agnostic Speaker Identification and Diarisation, and subsequent Transcription and Translation System. Our primary focus was on advancing speaker diarization, a critical component for multilingual and code-mixed scenarios. The main intent of this work was to study the real-world applicability of our in-house speaker diarization (SD) systems. To this end, we investigated a robust voice activity detection (VAD) technique and fine-tuned speaker embedding models for improved speaker identification in low-resource settings. We leveraged our own recently proposed multi-kernel consensus spectral clustering framework, which substantially improved the diarization performance across all recordings in the training corpus provided by the organizers. Complementary modules for speaker and language identification, automatic speech recognition (ASR), and neural machine translation were integrated in the pipeline. Post-processing refinements further improved system robustness.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e3aNCIIPC Startup India AI GRAND CHALLENGE\u5f00\u53d1\u7684\u96c6\u6210\u591a\u8bed\u8a00\u97f3\u9891\u5904\u7406\u7ba1\u9053\uff0c\u91cd\u70b9\u6539\u8fdb\u4e86\u8bf4\u8bdd\u4eba\u65e5\u5fd7\u5316\u6280\u672f\uff0c\u7279\u522b\u662f\u5728\u591a\u8bed\u8a00\u548c\u4ee3\u7801\u6df7\u5408\u573a\u666f\u4e0b\u7684\u5e94\u7528\u3002", "motivation": "\u7814\u7a76\u56e2\u961f\u65e8\u5728\u89e3\u51b3\u8bed\u8a00\u65e0\u5173\u7684\u8bf4\u8bdd\u4eba\u8bc6\u522b\u4e0e\u65e5\u5fd7\u5316\u3001\u8f6c\u5f55\u548c\u7ffb\u8bd1\u7cfb\u7edf\u95ee\u9898\uff0c\u4e3b\u8981\u5173\u6ce8\u591a\u8bed\u8a00\u548c\u4ee3\u7801\u6df7\u5408\u573a\u666f\u4e0b\u8bf4\u8bdd\u4eba\u65e5\u5fd7\u5316\u7684\u5b9e\u9645\u5e94\u7528\u6027\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e2d\u7684\u6027\u80fd\u63d0\u5347\u3002", "method": "\u5f00\u53d1\u4e86\u96c6\u6210\u591a\u8bed\u8a00\u97f3\u9891\u5904\u7406\u7ba1\u9053\uff0c\u91c7\u7528\u9c81\u68d2\u7684\u8bed\u97f3\u6d3b\u52a8\u68c0\u6d4b\u6280\u672f\uff0c\u5fae\u8c03\u8bf4\u8bdd\u4eba\u5d4c\u5165\u6a21\u578b\u7528\u4e8e\u4f4e\u8d44\u6e90\u73af\u5883\uff0c\u4f7f\u7528\u81ea\u7814\u7684\u591a\u6838\u5171\u8bc6\u8c31\u805a\u7c7b\u6846\u67b6\uff0c\u5e76\u6574\u5408\u4e86\u8bf4\u8bdd\u4eba\u8bc6\u522b\u3001\u8bed\u8a00\u8bc6\u522b\u3001\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u548c\u795e\u7ecf\u673a\u5668\u7ffb\u8bd1\u7b49\u6a21\u5757\u3002", "result": "\u591a\u6838\u5171\u8bc6\u8c31\u805a\u7c7b\u6846\u67b6\u663e\u8457\u63d0\u9ad8\u4e86\u8bad\u7ec3\u8bed\u6599\u5e93\u4e2d\u6240\u6709\u5f55\u97f3\u7684\u65e5\u5fd7\u5316\u6027\u80fd\uff0c\u540e\u5904\u7406\u4f18\u5316\u8fdb\u4e00\u6b65\u589e\u5f3a\u4e86\u7cfb\u7edf\u9c81\u68d2\u6027\uff0c\u6574\u4f53\u7cfb\u7edf\u5728\u6311\u6218\u8d5b\u4e2d\u8868\u73b0\u51fa\u8272\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5f00\u53d1\u4e86\u4e00\u4e2a\u9002\u7528\u4e8e\u591a\u8bed\u8a00\u548c\u4ee3\u7801\u6df7\u5408\u573a\u666f\u7684\u96c6\u6210\u97f3\u9891\u5904\u7406\u7cfb\u7edf\uff0c\u9a8c\u8bc1\u4e86\u81ea\u7814\u8bf4\u8bdd\u4eba\u65e5\u5fd7\u5316\u7cfb\u7edf\u5728\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u7684\u6709\u6548\u6027\uff0c\u7279\u522b\u662f\u5728\u4f4e\u8d44\u6e90\u73af\u5883\u4e0b\u7684\u6539\u8fdb\u65b9\u6cd5\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.10970", "categories": ["eess.SP", "cs.IT", "math.NA"], "pdf": "https://arxiv.org/pdf/2512.10970", "abs": "https://arxiv.org/abs/2512.10970", "authors": ["Yulei Wang", "Yalin Liu", "Yaru Fu", "Yuanwei Liu"], "title": "Uplink Rate Maximization for Pinching Antenna- Assisted Covert Backscatter Communication", "comment": null, "summary": "The emerging pinching antenna (PA) technology enables flexible antenna positioning for creating line-of-sight (LoS) links, thus offering substantial potential to facilitate ambient signal-based backscatter communication (BSC). This paper investigates PA-assisted BSC for enhanced communication and covertness in the presence of a randomly distributed eavesdropper. An optimization problem is formulated to maximize the uplink covert transmission rate by jointly optimizing the transmit power and antenna positions while satisfying both communication reliability and covertness constraints. An alternative optimization (AO)-based framework is proposed to solve this problem. Numerical results demonstrate that the proposed PA-BSC effectively mitigates the double near-far problem, where energy harvesting and backscatter transmission degrade simultaneously due to distance disparities, thereby improving downlink energy harvesting and uplink data transmission while maintaining covertness performance under practical deployment scenarios.", "AI": {"tldr": "PA-BSC\u6280\u672f\u901a\u8fc7\u53ef\u8c03\u5929\u7ebf\u4f4d\u7f6e\u4f18\u5316\uff0c\u5728\u7a83\u542c\u8005\u5b58\u5728\u4e0b\u63d0\u5347\u9690\u853d\u901a\u4fe1\u901f\u7387\uff0c\u89e3\u51b3\u53cc\u8fdc\u8fd1\u95ee\u9898", "motivation": "\u5939\u6301\u5929\u7ebf\u6280\u672f\u53ef\u5b9e\u73b0\u7075\u6d3b\u5929\u7ebf\u5b9a\u4f4d\uff0c\u521b\u5efa\u89c6\u8ddd\u94fe\u8def\uff0c\u4e3a\u73af\u5883\u4fe1\u53f7\u53cd\u5411\u6563\u5c04\u901a\u4fe1\u63d0\u4f9b\u6f5c\u529b\u3002\u4f46\u5728\u968f\u673a\u5206\u5e03\u7684\u7a83\u542c\u8005\u5b58\u5728\u4e0b\uff0c\u9700\u8981\u540c\u65f6\u6ee1\u8db3\u901a\u4fe1\u53ef\u9760\u6027\u548c\u9690\u853d\u6027\u7ea6\u675f", "method": "\u63d0\u51faPA\u8f85\u52a9\u7684BSC\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u53d1\u5c04\u529f\u7387\u548c\u5929\u7ebf\u4f4d\u7f6e\u6765\u6700\u5927\u5316\u4e0a\u884c\u9690\u853d\u4f20\u8f93\u901f\u7387\u3002\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\u89e3\u51b3\u8fd9\u4e2a\u4f18\u5316\u95ee\u9898", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0cPA-BSC\u80fd\u6709\u6548\u7f13\u89e3\u53cc\u8fdc\u8fd1\u95ee\u9898\uff08\u80fd\u91cf\u6536\u96c6\u548c\u53cd\u5411\u6563\u5c04\u4f20\u8f93\u56e0\u8ddd\u79bb\u5dee\u5f02\u540c\u65f6\u9000\u5316\uff09\uff0c\u6539\u5584\u4e0b\u884c\u80fd\u91cf\u6536\u96c6\u548c\u4e0a\u884c\u6570\u636e\u4f20\u8f93\uff0c\u540c\u65f6\u5728\u5b9e\u7528\u90e8\u7f72\u573a\u666f\u4e0b\u4fdd\u6301\u9690\u853d\u6027\u80fd", "conclusion": "PA-BSC\u7cfb\u7edf\u901a\u8fc7\u5929\u7ebf\u4f4d\u7f6e\u548c\u529f\u7387\u7684\u8054\u5408\u4f18\u5316\uff0c\u5728\u7a83\u542c\u8005\u5b58\u5728\u4e0b\u5b9e\u73b0\u4e86\u589e\u5f3a\u7684\u901a\u4fe1\u6027\u80fd\u548c\u9690\u853d\u6027\uff0c\u4e3a\u89e3\u51b3\u53cd\u5411\u6563\u5c04\u901a\u4fe1\u4e2d\u7684\u53cc\u8fdc\u8fd1\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848"}}
{"id": "2512.11165", "categories": ["cs.SD", "cs.CE"], "pdf": "https://arxiv.org/pdf/2512.11165", "abs": "https://arxiv.org/abs/2512.11165", "authors": ["Lucas C. F. Domingos", "Russell S. A. Brinkworth", "Paulo E. Santos", "Karl Sammut"], "title": "Mitigation of multi-path propagation artefacts in acoustic targets with cepstral adaptive filtering", "comment": null, "summary": "Passive acoustic sensing is a cost-effective solution for monitoring moving targets such as vessels and aircraft, but its performance is hindered by complex propagation effects like multi-path reflections and motion-induced artefacts. Existing filtering techniques do not properly incorporate the characteristics of the environment or account for variability in medium properties, limiting their effectiveness in separating source and reflection components. This paper proposes a method for separating target signals from their reflections in a spectrogram. Temporal filtering is applied to cepstral coefficients using an adaptive band-stop filter, which dynamically adjusts its bandwidth based on the relative intensity of the quefrency components. The method improved the signal-to-noise ratio (SNR), log-spectral distance (LSD), and Itakura-Saito (IS) distance across velocities ranging from 10 to 100 metres per second in aircraft noise with simulated motion. It also enhanced the performance of ship-type classification in underwater tasks by 2.28 and 2.62 Matthews Correlation Coefficient percentage points for the DeepShip and VTUAD v2 datasets, respectively. These results demonstrate the potential of the proposed pipeline to improve acoustic target classification and time-delay estimation in multi-path environments, with future work aimed at amplitude preservation and multi-sensor applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5012\u8c31\u7cfb\u6570\u81ea\u9002\u5e94\u5e26\u963b\u6ee4\u6ce2\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u4ece\u6df7\u54cd\u73af\u5883\u4e2d\u5206\u79bb\u76ee\u6807\u4fe1\u53f7\u4e0e\u53cd\u5c04\u5206\u91cf\uff0c\u63d0\u5347\u58f0\u5b66\u76ee\u6807\u76d1\u6d4b\u6027\u80fd\u3002", "motivation": "\u88ab\u52a8\u58f0\u5b66\u4f20\u611f\u662f\u76d1\u6d4b\u79fb\u52a8\u76ee\u6807\u7684\u7ecf\u6d4e\u65b9\u6848\uff0c\u4f46\u590d\u6742\u4f20\u64ad\u6548\u5e94\uff08\u591a\u5f84\u53cd\u5c04\u3001\u8fd0\u52a8\u4f2a\u5f71\uff09\u9650\u5236\u4e86\u5176\u6027\u80fd\u3002\u73b0\u6709\u6ee4\u6ce2\u6280\u672f\u672a\u80fd\u5145\u5206\u8003\u8651\u73af\u5883\u7279\u6027\u548c\u4ecb\u8d28\u5c5e\u6027\u53d8\u5316\uff0c\u96be\u4ee5\u6709\u6548\u5206\u79bb\u6e90\u4fe1\u53f7\u4e0e\u53cd\u5c04\u5206\u91cf\u3002", "method": "\u5728\u58f0\u8c31\u56fe\u4e0a\u5206\u79bb\u76ee\u6807\u4fe1\u53f7\u4e0e\u53cd\u5c04\u5206\u91cf\uff1a\u5bf9\u5012\u8c31\u7cfb\u6570\u5e94\u7528\u65f6\u57df\u6ee4\u6ce2\uff0c\u91c7\u7528\u81ea\u9002\u5e94\u5e26\u963b\u6ee4\u6ce2\u5668\uff0c\u6839\u636e\u5012\u9891\u7387\u5206\u91cf\u7684\u76f8\u5bf9\u5f3a\u5ea6\u52a8\u6001\u8c03\u6574\u5e26\u5bbd\u3002", "result": "\u572810-100\u7c73/\u79d2\u901f\u5ea6\u8303\u56f4\u7684\u6a21\u62df\u8fd0\u52a8\u98de\u673a\u566a\u58f0\u4e2d\uff0c\u663e\u8457\u6539\u5584\u4e86\u4fe1\u566a\u6bd4\u3001\u5bf9\u6570\u8c31\u8ddd\u79bb\u548cItakura-Saito\u8ddd\u79bb\u3002\u5728\u6c34\u4e0b\u4efb\u52a1\u4e2d\uff0c\u5c06DeepShip\u548cVTUAD v2\u6570\u636e\u96c6\u7684\u8239\u8236\u7c7b\u578b\u5206\u7c7b\u6027\u80fd\u5206\u522b\u63d0\u5347\u4e862.28\u548c2.62\u4e2a\u9a6c\u4fee\u65af\u76f8\u5173\u7cfb\u6570\u767e\u5206\u70b9\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u591a\u5f84\u73af\u5883\u4e2d\u63d0\u5347\u58f0\u5b66\u76ee\u6807\u5206\u7c7b\u548c\u65f6\u5ef6\u4f30\u8ba1\u65b9\u9762\u5177\u6709\u6f5c\u529b\uff0c\u672a\u6765\u5de5\u4f5c\u5c06\u805a\u7126\u4e8e\u5e45\u5ea6\u4fdd\u6301\u548c\u591a\u4f20\u611f\u5668\u5e94\u7528\u3002"}}
{"id": "2512.11170", "categories": ["eess.SP", "eess.IV"], "pdf": "https://arxiv.org/pdf/2512.11170", "abs": "https://arxiv.org/abs/2512.11170", "authors": ["Nicholas Bampton", "Tian J. Ma", "Minh N. Do"], "title": "A Unified Theory of Dynamic Programming Algorithms in Small Target Detection", "comment": "11 pages, 6 figures", "summary": "Small target detection is inherently challenging due to the minimal size, lack of distinctive features, and the presence of complex backgrounds. Heavy noise further complicates the task by both obscuring and imitating the target appearance. Weak target signals require integrating target trajectories over multiple frames, an approach that can be computationally intensive. Dynamic programming offers an efficient solution by decomposing the problem into iterative maximization. This, however, has limited the analytical tools available for their study. In this paper, we present a robust framework for this class of algorithms and establish rigorous convergence results for error rates under mild assumptions. We depart from standard analysis by modeling error probabilities as a function of distance from the target, allowing us to construct a relationship between uncertainty in location and uncertainty in existence. From this framework, we introduce a novel algorithm, Normalized Path Integration (NPI), that utilizes the similarity between sequential observations, enabling target detection with unknown or time varying features.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7528\u4e8e\u5c0f\u76ee\u6807\u68c0\u6d4b\u7684\u9c81\u68d2\u6846\u67b6\uff0c\u5efa\u7acb\u6536\u655b\u6027\u7406\u8bba\uff0c\u5e76\u5f15\u5165\u65b0\u7b97\u6cd5NPI\u6765\u5904\u7406\u672a\u77e5\u6216\u65f6\u53d8\u7279\u5f81\u7684\u76ee\u6807\u68c0\u6d4b", "motivation": "\u5c0f\u76ee\u6807\u68c0\u6d4b\u9762\u4e34\u5c3a\u5bf8\u5c0f\u3001\u7279\u5f81\u4e0d\u660e\u663e\u3001\u80cc\u666f\u590d\u6742\u7b49\u6311\u6218\uff0c\u566a\u58f0\u5e72\u6270\u4f7f\u5f97\u76ee\u6807\u5916\u89c2\u6a21\u7cca\u6216\u88ab\u6a21\u4eff\u3002\u73b0\u6709\u65b9\u6cd5\u5982\u52a8\u6001\u89c4\u5212\u867d\u7136\u9ad8\u6548\u4f46\u5206\u6790\u5de5\u5177\u6709\u9650\uff0c\u9700\u8981\u5efa\u7acb\u66f4\u4e25\u8c28\u7684\u7406\u8bba\u6846\u67b6", "method": "\u63d0\u51fa\u4e00\u4e2a\u9c81\u68d2\u5206\u6790\u6846\u67b6\uff0c\u5c06\u9519\u8bef\u6982\u7387\u5efa\u6a21\u4e3a\u4e0e\u76ee\u6807\u8ddd\u79bb\u7684\u51fd\u6570\uff0c\u5efa\u7acb\u4f4d\u7f6e\u4e0d\u786e\u5b9a\u6027\u4e0e\u5b58\u5728\u4e0d\u786e\u5b9a\u6027\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u57fa\u4e8e\u6b64\u6846\u67b6\u5f15\u5165\u65b0\u7b97\u6cd5NPI\uff0c\u5229\u7528\u5e8f\u5217\u89c2\u6d4b\u95f4\u7684\u76f8\u4f3c\u6027\u8fdb\u884c\u76ee\u6807\u68c0\u6d4b", "result": "\u5728\u6e29\u548c\u5047\u8bbe\u4e0b\u5efa\u7acb\u4e86\u4e25\u683c\u7684\u6536\u655b\u7ed3\u679c\u548c\u9519\u8bef\u7387\u5206\u6790\uff0c\u63d0\u51fa\u7684NPI\u7b97\u6cd5\u80fd\u591f\u5904\u7406\u672a\u77e5\u6216\u65f6\u53d8\u7279\u5f81\u7684\u76ee\u6807\u68c0\u6d4b\u95ee\u9898", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u5c0f\u76ee\u6807\u68c0\u6d4b\u7b97\u6cd5\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u6846\u67b6\uff0c\u63d0\u51fa\u7684NPI\u7b97\u6cd5\u5728\u590d\u6742\u566a\u58f0\u548c\u7279\u5f81\u53d8\u5316\u6761\u4ef6\u4e0b\u5177\u6709\u9c81\u68d2\u6027\uff0c\u4e3a\u52a8\u6001\u89c4\u5212\u7c7b\u7b97\u6cd5\u63d0\u4f9b\u4e86\u66f4\u4e25\u8c28\u7684\u5206\u6790\u5de5\u5177"}}
{"id": "2512.11241", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.11241", "abs": "https://arxiv.org/abs/2512.11241", "authors": ["Yupei Li", "Chenyang Lyu", "Longyue Wang", "Weihua Luo", "Kaifu Zhang", "Bj\u00f6rn W. Schuller"], "title": "The Affective Bridge: Unifying Feature Representations for Speech Deepfake Detection", "comment": null, "summary": "Speech deepfake detection has been widely explored using low-level acoustic descriptors. However, each study tends to select different feature sets, making it difficult to establish a unified representation for the task. Moreover, such features are not intuitive for humans to perceive, as the distinction between bona fide and synthesized speech becomes increasingly subtle with the advancement of deepfake generation techniques. Emotion, on the other hand, remains a unique human attribute that current deepfake generator struggles to fully replicate, reflecting the gap toward true artificial general intelligence. Interestingly, many existing acoustic and semantic features have implicit correlations with emotion. For instance, speech features recognized by automatic speech recognition systems often varies naturally with emotional expression. Based on this insight, we propose a novel training framework that leverages emotion as a bridge between conventional deepfake features and emotion-oriented representations. Experiments on the widely used FakeOrReal and In-the-Wild datasets demonstrate consistent and substantial improvements in accuracy, up to approximately 6% and 2% increases, respectively, and in equal error rate (EER), showing reductions of up to about 4% and 1%, respectively, while achieving comparable results on ASVspoof2019. This approach provides a unified training strategy for all features and interpretable feature direction for deepfake detection while improving model performance through emotion-informed learning.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u60c5\u611f\u6865\u63a5\u7684\u8bed\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u6846\u67b6\uff0c\u5229\u7528\u60c5\u611f\u4f5c\u4e3a\u4f20\u7edf\u6df1\u5ea6\u4f2a\u9020\u7279\u5f81\u4e0e\u60c5\u611f\u5bfc\u5411\u8868\u793a\u4e4b\u95f4\u7684\u6865\u6881\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u6027\u80fd\u63d0\u5347", "motivation": "\u73b0\u6709\u8bed\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7814\u7a76\u4f7f\u7528\u4e0d\u540c\u7684\u4f4e\u7ea7\u58f0\u5b66\u63cf\u8ff0\u7b26\uff0c\u7f3a\u4e4f\u7edf\u4e00\u8868\u793a\uff1b\u540c\u65f6\u8fd9\u4e9b\u7279\u5f81\u5bf9\u4eba\u7c7b\u4e0d\u76f4\u89c2\uff0c\u4e14\u968f\u7740\u6df1\u5ea6\u4f2a\u9020\u6280\u672f\u8fdb\u6b65\uff0c\u771f\u5047\u8bed\u97f3\u5dee\u5f02\u8d8a\u6765\u8d8a\u7ec6\u5fae\u3002\u60c5\u611f\u4f5c\u4e3a\u4eba\u7c7b\u72ec\u7279\u5c5e\u6027\uff0c\u5f53\u524d\u6df1\u5ea6\u4f2a\u9020\u751f\u6210\u5668\u96be\u4ee5\u5b8c\u5168\u590d\u5236\uff0c\u800c\u8bb8\u591a\u73b0\u6709\u58f0\u5b66\u548c\u8bed\u4e49\u7279\u5f81\u4e0e\u60c5\u611f\u5b58\u5728\u9690\u542b\u5173\u8054", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u8bad\u7ec3\u6846\u67b6\uff0c\u5229\u7528\u60c5\u611f\u4f5c\u4e3a\u4f20\u7edf\u6df1\u5ea6\u4f2a\u9020\u7279\u5f81\u4e0e\u60c5\u611f\u5bfc\u5411\u8868\u793a\u4e4b\u95f4\u7684\u6865\u6881\u3002\u901a\u8fc7\u60c5\u611f\u4fe1\u606f\u5b66\u4e60\uff0c\u4e3a\u6240\u6709\u7279\u5f81\u63d0\u4f9b\u7edf\u4e00\u7684\u8bad\u7ec3\u7b56\u7565\u548c\u53ef\u89e3\u91ca\u7684\u7279\u5f81\u65b9\u5411", "result": "\u5728FakeOrReal\u548cIn-the-Wild\u6570\u636e\u96c6\u4e0a\u5b9e\u73b0\u4e00\u81f4\u4e14\u663e\u8457\u7684\u6027\u80fd\u63d0\u5347\uff1a\u51c6\u786e\u7387\u5206\u522b\u63d0\u9ad8\u7ea66%\u548c2%\uff0c\u7b49\u9519\u8bef\u7387\u5206\u522b\u964d\u4f4e\u7ea64%\u548c1%\uff1b\u5728ASVspoof2019\u6570\u636e\u96c6\u4e0a\u83b7\u5f97\u53ef\u6bd4\u7ed3\u679c", "conclusion": "\u8be5\u65b9\u6cd5\u901a\u8fc7\u60c5\u611f\u6865\u63a5\u63d0\u4f9b\u7edf\u4e00\u7684\u8bad\u7ec3\u7b56\u7565\u548c\u53ef\u89e3\u91ca\u7684\u7279\u5f81\u65b9\u5411\uff0c\u540c\u65f6\u901a\u8fc7\u60c5\u611f\u4fe1\u606f\u5b66\u4e60\u63d0\u9ad8\u6a21\u578b\u6027\u80fd\uff0c\u4e3a\u89e3\u51b3\u8bed\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u4e2d\u7684\u7279\u5f81\u4e0d\u7edf\u4e00\u548c\u53ef\u89e3\u91ca\u6027\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u601d\u8def"}}
{"id": "2512.11348", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.11348", "abs": "https://arxiv.org/abs/2512.11348", "authors": ["Longshen Ou", "Ye Wang"], "title": "PhraseVAE and PhraseLDM: Latent Diffusion for Full-Song Multitrack Symbolic Music Generation", "comment": null, "summary": "This technical report presents a new paradigm for full-song symbolic music generation. Existing symbolic models operate on note-attribute tokens and suffer from extremely long sequences, limited context length, and weak support for long-range structure. We address these issues by introducing PhraseVAE and PhraseLDM, the first latent diffusion framework designed for full-song multitrack symbolic music. PhraseVAE compresses variable-length polyphonic note sequences into compact 64-dimensional phrase-level representations with high reconstruction fidelity, allowing efficient training and a well-structured latent space. Built on this latent space, PhraseLDM generates an entire multi-track song in a single pass without any autoregressive components. The system eliminates bar-wise sequential modeling, supports up to 128 bars of music (8 minutes in 64 bpm), and produces complete songs with coherent local texture, idiomatic instrument patterns, and clear global structure. With only 45M parameters, our framework generates a full song within seconds while maintaining competitive musical quality and generation diversity. Together, these results show that phrase-level latent diffusion provides an effective and scalable solution to long-sequence modeling in symbolic music generation. We hope this work encourages future symbolic music research to move beyond note-attribute tokens and to consider phrase-level units as a more effective and musically meaningful modeling target.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u9762\u5411\u5168\u6b4c\u66f2\u591a\u8f68\u7b26\u53f7\u97f3\u4e50\u7684\u6f5c\u5728\u6269\u6563\u6846\u67b6\uff0c\u901a\u8fc7\u77ed\u8bed\u7ea7\u8868\u793a\u89e3\u51b3\u957f\u5e8f\u5217\u5efa\u6a21\u95ee\u9898\uff0c\u5b9e\u73b0\u79d2\u7ea7\u751f\u6210\u5b8c\u6574\u6b4c\u66f2", "motivation": "\u73b0\u6709\u7b26\u53f7\u97f3\u4e50\u6a21\u578b\u57fa\u4e8e\u97f3\u7b26\u5c5e\u6027token\uff0c\u5b58\u5728\u5e8f\u5217\u8fc7\u957f\u3001\u4e0a\u4e0b\u6587\u957f\u5ea6\u6709\u9650\u3001\u957f\u7a0b\u7ed3\u6784\u652f\u6301\u5f31\u7b49\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u5efa\u6a21\u8303\u5f0f", "method": "\u63d0\u51faPhraseVAE\u5c06\u53d8\u957f\u590d\u8c03\u97f3\u7b26\u5e8f\u5217\u538b\u7f29\u4e3a64\u7ef4\u77ed\u8bed\u7ea7\u8868\u793a\uff0c\u518d\u57fa\u4e8e\u6b64\u6784\u5efaPhraseLDM\u6f5c\u5728\u6269\u6563\u6a21\u578b\uff0c\u5355\u6b21\u751f\u6210\u5b8c\u6574\u591a\u8f68\u6b4c\u66f2", "result": "\u7cfb\u7edf\u652f\u6301128\u5c0f\u8282\u97f3\u4e50\uff0864bpm\u4e0b8\u5206\u949f\uff09\uff0c\u4ec54500\u4e07\u53c2\u6570\u5373\u53ef\u79d2\u7ea7\u751f\u6210\u5177\u6709\u8fde\u8d2f\u5c40\u90e8\u7eb9\u7406\u3001\u5730\u9053\u4e50\u5668\u6a21\u5f0f\u548c\u6e05\u6670\u5168\u5c40\u7ed3\u6784\u7684\u5b8c\u6574\u6b4c\u66f2", "conclusion": "\u77ed\u8bed\u7ea7\u6f5c\u5728\u6269\u6563\u4e3a\u7b26\u53f7\u97f3\u4e50\u751f\u6210\u4e2d\u7684\u957f\u5e8f\u5217\u5efa\u6a21\u63d0\u4f9b\u4e86\u6709\u6548\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u9f13\u52b1\u672a\u6765\u7814\u7a76\u8d85\u8d8a\u97f3\u7b26\u5c5e\u6027token\uff0c\u91c7\u7528\u66f4\u6709\u6548\u7684\u77ed\u8bed\u7ea7\u5355\u5143"}}
{"id": "2512.11420", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.11420", "abs": "https://arxiv.org/abs/2512.11420", "authors": ["Fuhai Wang", "Tiebin Mi", "Chun Wang", "Rujing Xiong", "Zhengyu Wang", "Robert Caiming Qiu"], "title": "Source Localization and Power Estimation through RISs: Performance Analysis and Prototype Validations", "comment": null, "summary": "This paper investigates the capabilities and effectiveness of backward localization centered on reconfigurable intelligent surfaces (RISs). In the backward sensing paradigm, the region of interest (RoI) is illuminated using a set of diverse radiation patterns. These patterns encode spatial information into a sequence of measurements, which are subsequently processed to reconstruct the RoI. We show that a single RIS can estimate the direction of arrival of incident waves by leveraging configurational diversity, and that the spatial diversity provided by multiple RISs further improves the accuracy of source localization and power estimation. The underlying structure of the sensing operator in the multi-snapshot measurement process is clarified. For single-RIS localization, the sensing operator is decomposed into a product of structured matrices, each corresponding to a specific physical process: wave propagation to and from the RIS, the relative phase offsets of elements with respect to the reference point, and the applied phase configuration of each element. A unified framework for identifying key performance indicators is established by analyzing the conditioning of the sensing operators. In the multi-RIS setting, we derive--via rank analysis--the governing law among the RoI size, the number of elements, and the number of measurements. Upper bounds on the relative error of the least squares reconstruction algorithm are derived. These bounds clarify how key performance indicators affect estimation error and provide valuable guidance for system-level optimization. Numerical experiments confirm that the trend of the relative error is consistent with the theoretical bounds.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u57fa\u4e8e\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u7684\u540e\u5411\u5b9a\u4f4d\u80fd\u529b\uff0c\u901a\u8fc7\u914d\u7f6e\u591a\u6837\u6027\u5b9e\u73b0\u5355RIS\u7684\u6ce2\u8fbe\u65b9\u5411\u4f30\u8ba1\uff0c\u591aRIS\u8fdb\u4e00\u6b65\u63d0\u5347\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u5e76\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u6027\u80fd\u5206\u6790\u6846\u67b6\u3002", "motivation": "\u7814\u7a76RIS\u5728\u53cd\u5411\u611f\u77e5\u8303\u5f0f\u4e2d\u7684\u80fd\u529b\uff0c\u63a2\u7d22\u5982\u4f55\u5229\u7528RIS\u7684\u914d\u7f6e\u591a\u6837\u6027\u548c\u7a7a\u95f4\u591a\u6837\u6027\u6765\u6539\u5584\u76ee\u6807\u533a\u57df\u7684\u5b9a\u4f4d\u548c\u529f\u7387\u4f30\u8ba1\u6027\u80fd\uff0c\u4e3a\u7cfb\u7edf\u7ea7\u4f18\u5316\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u540e\u5411\u611f\u77e5\u8303\u5f0f\uff0c\u901a\u8fc7\u591a\u6837\u5316\u7684\u8f90\u5c04\u6a21\u5f0f\u7167\u5c04\u611f\u5174\u8da3\u533a\u57df\uff0c\u5c06\u7a7a\u95f4\u4fe1\u606f\u7f16\u7801\u5230\u6d4b\u91cf\u5e8f\u5217\u4e2d\u3002\u5206\u6790\u5355RIS\u548c\u591aRIS\u8bbe\u7f6e\u4e0b\u7684\u611f\u77e5\u7b97\u5b50\u7ed3\u6784\uff0c\u901a\u8fc7\u77e9\u9635\u5206\u89e3\u548c\u79e9\u5206\u6790\u5efa\u7acb\u6027\u80fd\u6307\u6807\u6846\u67b6\uff0c\u63a8\u5bfc\u6700\u5c0f\u4e8c\u4e58\u91cd\u5efa\u7b97\u6cd5\u7684\u8bef\u5dee\u4e0a\u754c\u3002", "result": "\u5355RIS\u80fd\u591f\u5229\u7528\u914d\u7f6e\u591a\u6837\u6027\u4f30\u8ba1\u5165\u5c04\u6ce2\u7684\u6ce2\u8fbe\u65b9\u5411\uff0c\u591aRIS\u901a\u8fc7\u7a7a\u95f4\u591a\u6837\u6027\u8fdb\u4e00\u6b65\u63d0\u9ad8\u6e90\u5b9a\u4f4d\u548c\u529f\u7387\u4f30\u8ba1\u7684\u51c6\u786e\u6027\u3002\u7406\u8bba\u5206\u6790\u63ed\u793a\u4e86\u611f\u77e5\u7b97\u5b50\u7684\u7ed3\u6784\u7279\u6027\uff0c\u63a8\u5bfc\u4e86\u8bef\u5dee\u4e0a\u754c\u4e0e\u5173\u952e\u6027\u80fd\u6307\u6807\u7684\u5173\u7cfb\uff0c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7406\u8bba\u8d8b\u52bf\u3002", "conclusion": "RIS\u5728\u53cd\u5411\u5b9a\u4f4d\u4e2d\u5177\u6709\u663e\u8457\u6f5c\u529b\uff0c\u914d\u7f6e\u591a\u6837\u6027\u548c\u7a7a\u95f4\u591a\u6837\u6027\u662f\u63d0\u5347\u6027\u80fd\u7684\u5173\u952e\u56e0\u7d20\u3002\u5efa\u7acb\u7684\u7edf\u4e00\u5206\u6790\u6846\u67b6\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\uff0c\u8bef\u5dee\u4e0a\u754c\u5206\u6790\u4e3a\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u9884\u6d4b\u548c\u4f18\u5316\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002"}}
{"id": "2512.11545", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.11545", "abs": "https://arxiv.org/abs/2512.11545", "authors": ["Sheng Feng", "Shuqing Ma", "Xiaoqian Zhu"], "title": "Graph Embedding with Mel-spectrograms for Underwater Acoustic Target Recognition", "comment": null, "summary": "Underwater acoustic target recognition (UATR) is extremely challenging due to the complexity of ship-radiated noise and the variability of ocean environments. Although deep learning (DL) approaches have achieved promising results, most existing models implicitly assume that underwater acoustic data lie in a Euclidean space. This assumption, however, is unsuitable for the inherently complex topology of underwater acoustic signals, which exhibit non-stationary, non-Gaussian, and nonlinear characteristics. To overcome this limitation, this paper proposes the UATR-GTransformer, a non-Euclidean DL model that integrates Transformer architectures with graph neural networks (GNNs). The model comprises three key components: a Mel patchify block, a GTransformer block, and a classification head. The Mel patchify block partitions the Mel-spectrogram into overlapping patches, while the GTransformer block employs a Transformer Encoder to capture mutual information between split patches to generate Mel-graph embeddings. Subsequently, a GNN enhances these embeddings by modeling local neighborhood relationships, and a feed-forward network (FFN) further performs feature transformation. Experiments results based on two widely used benchmark datasets demonstrate that the UATR-GTransformer achieves performance competitive with state-of-the-art methods. In addition, interpretability analysis reveals that the proposed model effectively extracts rich frequency-domain information, highlighting its potential for applications in ocean engineering.", "AI": {"tldr": "\u63d0\u51faUATR-GTransformer\u6a21\u578b\uff0c\u7ed3\u5408Transformer\u548cGNN\u5904\u7406\u6c34\u4e0b\u58f0\u5b66\u76ee\u6807\u8bc6\u522b\uff0c\u5728\u975e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u5efa\u6a21\u590d\u6742\u58f0\u5b66\u4fe1\u53f7\u62d3\u6251\u7ed3\u6784", "motivation": "\u6c34\u4e0b\u58f0\u5b66\u76ee\u6807\u8bc6\u522b\u9762\u4e34\u4fe1\u53f7\u590d\u6742\u548c\u73af\u5883\u591a\u53d8\u7684\u6311\u6218\uff0c\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u5927\u591a\u5047\u8bbe\u6570\u636e\u4f4d\u4e8e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\uff0c\u4f46\u6c34\u4e0b\u58f0\u5b66\u4fe1\u53f7\u5177\u6709\u975e\u5e73\u7a33\u3001\u975e\u9ad8\u65af\u3001\u975e\u7ebf\u6027\u7279\u5f81\uff0c\u5176\u590d\u6742\u62d3\u6251\u7ed3\u6784\u66f4\u9002\u5408\u5728\u975e\u6b27\u51e0\u91cc\u5f97\u7a7a\u95f4\u4e2d\u5efa\u6a21", "method": "\u63d0\u51faUATR-GTransformer\u6a21\u578b\uff0c\u5305\u542b\u4e09\u4e2a\u5173\u952e\u7ec4\u4ef6\uff1a1) Mel patchify\u5757\u5c06\u6885\u5c14\u9891\u8c31\u56fe\u5206\u5272\u4e3a\u91cd\u53e0\u5757\uff1b2) GTransformer\u5757\u4f7f\u7528Transformer\u7f16\u7801\u5668\u6355\u83b7\u5757\u95f4\u4e92\u4fe1\u606f\u751f\u6210\u6885\u5c14\u56fe\u5d4c\u5165\uff0c\u518d\u7528GNN\u5efa\u6a21\u5c40\u90e8\u90bb\u57df\u5173\u7cfb\uff1b3) \u5206\u7c7b\u5934\u8fdb\u884c\u7279\u5f81\u53d8\u6362\u548c\u5206\u7c7b", "result": "\u5728\u4e24\u4e2a\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\uff0cUATR-GTransformer\u53d6\u5f97\u4e86\u4e0e\u6700\u5148\u8fdb\u65b9\u6cd5\u76f8\u7ade\u4e89\u7684\u6027\u80fd\uff0c\u53ef\u89e3\u91ca\u6027\u5206\u6790\u8868\u660e\u6a21\u578b\u80fd\u6709\u6548\u63d0\u53d6\u4e30\u5bcc\u7684\u9891\u57df\u4fe1\u606f", "conclusion": "\u63d0\u51fa\u7684\u975e\u6b27\u51e0\u91cc\u5f97\u6df1\u5ea6\u5b66\u4e60\u6a21\u578bUATR-GTransformer\u80fd\u6709\u6548\u5904\u7406\u6c34\u4e0b\u58f0\u5b66\u4fe1\u53f7\u7684\u590d\u6742\u62d3\u6251\u7ed3\u6784\uff0c\u5728\u6d77\u6d0b\u5de5\u7a0b\u5e94\u7528\u4e2d\u5177\u6709\u6f5c\u529b"}}
{"id": "2512.11444", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.11444", "abs": "https://arxiv.org/abs/2512.11444", "authors": ["Baptiste Sambon", "Gilles Monnoyer", "Claude Oestges", "Luc Vandendorpe"], "title": "Point Target Near-Field Bistatic Imaging: Chirp-Based Aliasing Analysis", "comment": "Accepted to 2025 IEEE International Workshop on Computational Advances in Multi-Sensor Adaptive Processing (CAMSAP)", "summary": "This paper presents a chirp-based framework for characterising aliasing in a bistatic Near-Field (NF) imaging system equipped with multidimensional antenna arrays. Extending monostatic formulations, we derive closed-form expressions for the maximum spatial frequency, enabling the analytical derivations of the conditions for aliasing-free image reconstruction. The framework also provides a geometric interpretation of aliasing based on the antenna array geometry, target position, and antenna element spacing. Numerical results corroborate theoretical findings and show that the aliasing-free region enlarges with smaller antenna spacing, greater target range, lower array dimensionality, and smaller arrays. These results enable more effective design of bistatic NF imaging systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5541\u557e\u4fe1\u53f7\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u5206\u6790\u914d\u5907\u591a\u7ef4\u5929\u7ebf\u9635\u5217\u7684\u53cc\u57fa\u5730\u8fd1\u573a\u6210\u50cf\u7cfb\u7edf\u4e2d\u7684\u6df7\u53e0\u73b0\u8c61\uff0c\u63a8\u5bfc\u4e86\u65e0\u6df7\u53e0\u56fe\u50cf\u91cd\u5efa\u7684\u6761\u4ef6\u3002", "motivation": "\u53cc\u57fa\u5730\u8fd1\u573a\u6210\u50cf\u7cfb\u7edf\u4f7f\u7528\u591a\u7ef4\u5929\u7ebf\u9635\u5217\u65f6\u5b58\u5728\u6df7\u53e0\u95ee\u9898\uff0c\u9700\u8981\u7406\u8bba\u6846\u67b6\u6765\u5206\u6790\u548c\u907f\u514d\u6df7\u53e0\uff0c\u4ee5\u4f18\u5316\u7cfb\u7edf\u8bbe\u8ba1\u3002", "method": "\u6269\u5c55\u5355\u57fa\u5730\u516c\u5f0f\uff0c\u63a8\u5bfc\u6700\u5927\u7a7a\u95f4\u9891\u7387\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u57fa\u4e8e\u5929\u7ebf\u9635\u5217\u51e0\u4f55\u3001\u76ee\u6807\u4f4d\u7f6e\u548c\u5929\u7ebf\u95f4\u8ddd\u63d0\u4f9b\u6df7\u53e0\u7684\u51e0\u4f55\u89e3\u91ca\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u7406\u8bba\uff1a\u5929\u7ebf\u95f4\u8ddd\u8d8a\u5c0f\u3001\u76ee\u6807\u8ddd\u79bb\u8d8a\u8fdc\u3001\u9635\u5217\u7ef4\u5ea6\u8d8a\u4f4e\u3001\u9635\u5217\u5c3a\u5bf8\u8d8a\u5c0f\uff0c\u65e0\u6df7\u53e0\u533a\u57df\u8d8a\u5927\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u53cc\u57fa\u5730\u8fd1\u573a\u6210\u50cf\u7cfb\u7edf\u7684\u6709\u6548\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\uff0c\u80fd\u591f\u4f18\u5316\u7cfb\u7edf\u53c2\u6570\u4ee5\u907f\u514d\u6df7\u53e0\u3002"}}
{"id": "2512.11461", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.11461", "abs": "https://arxiv.org/abs/2512.11461", "authors": ["Taissir Y. Elganimi", "Mahmoud Aldababsa", "Ali A. Nasir", "Khaled M. Rabie"], "title": "STAR-RIS-Aided Secure Communications:Analytical Insights and Performance Comparison", "comment": "15 pages", "summary": "Simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RISs) have emerged as a promising technology for enabling full-space signal manipulation and enhancing wireless network coverage and capacity. In this article, we present a comprehensive analytical comparison of STAR-RIS-assisted systems with single-input single-output (SISO), conventional RISs, and decode-and-forward (DF) relaying schemes, including both half-duplex (HD) and full-duplex (FD) modes. Closed-form expressions are derived for the achievable secrecy rates of STAR-RIS-aided communications under both the absence and presence of eavesdroppers. Unlike most existing works, the direct source destination link is incorporated in all considered schemes, and optimal transmit power allocation is investigated for HD and FD-DF relaying. Furthermore, we provide the conditions under which STAR-RIS outperforms HD- and FD-DF relaying and quantify the minimum number of STAR-RIS elements required to achieve superior rates. The impacts of key system parameters including transmit power, number of elements, reflection-to-transmission power ratio, element-splitting factor, and deployment positions on both achievable and secrecy performance are investigated. The results reveal that STAR-RIS systems can achieve superior rates and secrecy rates compared to all benchmark schemes.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5bf9STAR-RIS\u8f85\u52a9\u901a\u4fe1\u7cfb\u7edf\u8fdb\u884c\u4e86\u5168\u9762\u7684\u5206\u6790\u6bd4\u8f83\uff0c\u63a8\u5bfc\u4e86\u4fdd\u5bc6\u901f\u7387\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u786e\u5b9a\u4e86STAR-RIS\u4f18\u4e8e\u4f20\u7edf\u4e2d\u7ee7\u65b9\u6848\u7684\u6761\u4ef6\u548c\u6240\u9700\u6700\u5c0f\u5355\u5143\u6570\u3002", "motivation": "STAR-RIS\u4f5c\u4e3a\u65b0\u5174\u6280\u672f\u80fd\u591f\u5b9e\u73b0\u5168\u7a7a\u95f4\u4fe1\u53f7\u64cd\u63a7\uff0c\u589e\u5f3a\u65e0\u7ebf\u7f51\u7edc\u8986\u76d6\u548c\u5bb9\u91cf\u3002\u9700\u8981\u7cfb\u7edf\u5206\u6790\u5176\u4e0eSISO\u3001\u4f20\u7edfRIS\u4ee5\u53caHD/FD-DF\u4e2d\u7ee7\u65b9\u6848\u7684\u6027\u80fd\u5dee\u5f02\uff0c\u7279\u522b\u662f\u5728\u5b58\u5728\u7a83\u542c\u8005\u60c5\u51b5\u4e0b\u7684\u4fdd\u5bc6\u6027\u80fd\u3002", "method": "\u63a8\u5bfc\u4e86STAR-RIS\u8f85\u52a9\u901a\u4fe1\u5728\u6709\u65e0\u7a83\u542c\u8005\u60c5\u51b5\u4e0b\u7684\u53ef\u8fbe\u4fdd\u5bc6\u901f\u7387\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff1b\u8003\u8651\u4e86\u76f4\u63a5\u6e90-\u76ee\u7684\u94fe\u8def\uff1b\u7814\u7a76\u4e86HD\u548cFD-DF\u4e2d\u7ee7\u7684\u6700\u4f18\u529f\u7387\u5206\u914d\uff1b\u786e\u5b9a\u4e86STAR-RIS\u4f18\u4e8e\u4e2d\u7ee7\u65b9\u6848\u7684\u6761\u4ef6\u548c\u6240\u9700\u6700\u5c0f\u5355\u5143\u6570\uff1b\u5206\u6790\u4e86\u5173\u952e\u7cfb\u7edf\u53c2\u6570\u7684\u5f71\u54cd\u3002", "result": "STAR-RIS\u7cfb\u7edf\u5728\u6240\u6709\u57fa\u51c6\u65b9\u6848\u4e2d\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u901f\u7387\u548c\u4fdd\u5bc6\u901f\u7387\uff1b\u786e\u5b9a\u4e86STAR-RIS\u4f18\u4e8eHD-\u548cFD-DF\u4e2d\u7ee7\u7684\u6761\u4ef6\uff1b\u91cf\u5316\u4e86\u5b9e\u73b0\u66f4\u4f18\u901f\u7387\u6240\u9700\u7684\u6700\u5c0fSTAR-RIS\u5355\u5143\u6570\uff1b\u5206\u6790\u4e86\u529f\u7387\u3001\u5355\u5143\u6570\u3001\u53cd\u5c04-\u4f20\u8f93\u529f\u7387\u6bd4\u3001\u5355\u5143\u5206\u88c2\u56e0\u5b50\u548c\u90e8\u7f72\u4f4d\u7f6e\u7b49\u53c2\u6570\u7684\u5f71\u54cd\u3002", "conclusion": "STAR-RIS\u6280\u672f\u76f8\u6bd4\u4f20\u7edf\u65b9\u6848\u5177\u6709\u663e\u8457\u6027\u80fd\u4f18\u52bf\uff0c\u7279\u522b\u662f\u5728\u4fdd\u5bc6\u901a\u4fe1\u573a\u666f\u4e0b\u3002\u7814\u7a76\u4e3aSTAR-RIS\u7cfb\u7edf\u8bbe\u8ba1\u548c\u90e8\u7f72\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u548c\u6027\u80fd\u57fa\u51c6\u3002"}}
{"id": "2512.11537", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.11537", "abs": "https://arxiv.org/abs/2512.11537", "authors": ["Stefan H\u00e4gele", "Adam Misik", "Eckehard Steinbach"], "title": "RadarFuseNet: Complex-Valued Attention-Based Fusion of IQ Time- and Frequency-Domain Radar Features for Classification Tasks", "comment": "5 pages, 4 figures", "summary": "Millimeter-wave (mmWave) radar has emerged as a compact and powerful sensing modality for advanced perception tasks that leverage machine learning techniques. It is particularly effective in scenarios where vision-based sensors fail to capture reliable information, such as detecting occluded objects or distinguishing between different surface materials in indoor environments. Due to the non-linear characteristics of mmWave radar signals, deep learning-based methods are well suited for extracting relevant information from in-phase and quadrature (IQ) data. However, the current state of the art in IQ signal-based occluded-object and material classification still offers substantial potential for further improvement. In this paper, we propose a bidirectional cross-attention fusion network that combines IQ-signal and FFT-transformed radar features obtained by distinct complex-valued convolutional neural networks (CNNs). The proposed method achieves improved performance and robustness compared to standalone complex-valued CNNs. We achieve a near-perfect material classification accuracy of 99.92% on samples collected at same sensor-to-surface distances used during training, and an improved accuracy of 67.38% on samples measured at previously unseen distances, demonstrating improved generalization ability across varying measurement conditions. Furthermore, the accuracy for occluded object classification improves from 91.99% using standalone complex-valued CNNs to 94.20% using our proposed approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53cc\u5411\u4ea4\u53c9\u6ce8\u610f\u529b\u878d\u5408\u7f51\u7edc\uff0c\u7ed3\u5408IQ\u4fe1\u53f7\u548cFFT\u53d8\u6362\u7684\u96f7\u8fbe\u7279\u5f81\uff0c\u901a\u8fc7\u590d\u6570CNN\u5904\u7406\uff0c\u63d0\u5347\u906e\u6321\u7269\u4f53\u548c\u6750\u6599\u5206\u7c7b\u7684\u6027\u80fd\u4e0e\u9c81\u68d2\u6027\u3002", "motivation": "\u6beb\u7c73\u6ce2\u96f7\u8fbe\u5728\u89c6\u89c9\u4f20\u611f\u5668\u5931\u6548\u7684\u573a\u666f\uff08\u5982\u906e\u6321\u7269\u4f53\u68c0\u6d4b\u3001\u5ba4\u5185\u6750\u6599\u533a\u5206\uff09\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u73b0\u6709\u57fa\u4e8eIQ\u4fe1\u53f7\u7684\u906e\u6321\u7269\u4f53\u548c\u6750\u6599\u5206\u7c7b\u65b9\u6cd5\u4ecd\u6709\u8f83\u5927\u6539\u8fdb\u7a7a\u95f4\u3002", "method": "\u63d0\u51fa\u53cc\u5411\u4ea4\u53c9\u6ce8\u610f\u529b\u878d\u5408\u7f51\u7edc\uff0c\u7ed3\u5408IQ\u4fe1\u53f7\u548cFFT\u53d8\u6362\u7684\u96f7\u8fbe\u7279\u5f81\uff0c\u4f7f\u7528\u4e0d\u540c\u7684\u590d\u6570\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5206\u522b\u63d0\u53d6\u7279\u5f81\uff0c\u901a\u8fc7\u4ea4\u53c9\u6ce8\u610f\u529b\u673a\u5236\u8fdb\u884c\u7279\u5f81\u878d\u5408\u3002", "result": "\u5728\u76f8\u540c\u8ddd\u79bb\u8bad\u7ec3\u6837\u672c\u4e0a\u5b9e\u73b099.92%\u7684\u6750\u6599\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u5728\u672a\u89c1\u8ddd\u79bb\u6837\u672c\u4e0a\u8fbe\u523067.38%\u7684\u51c6\u786e\u7387\uff1b\u906e\u6321\u7269\u4f53\u5206\u7c7b\u51c6\u786e\u7387\u4ece91.99%\u63d0\u5347\u523094.20%\uff0c\u663e\u793a\u51fa\u66f4\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u63d0\u51fa\u7684\u53cc\u5411\u4ea4\u53c9\u6ce8\u610f\u529b\u878d\u5408\u7f51\u7edc\u663e\u8457\u63d0\u5347\u4e86\u6beb\u7c73\u6ce2\u96f7\u8fbe\u5728\u906e\u6321\u7269\u4f53\u548c\u6750\u6599\u5206\u7c7b\u4efb\u52a1\u4e0a\u7684\u6027\u80fd\u4e0e\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u6d4b\u91cf\u6761\u4ef6\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2512.11556", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.11556", "abs": "https://arxiv.org/abs/2512.11556", "authors": ["Stefan H\u00e4gele", "Adam Misik", "Constantin Patsch", "Eckehard Steinbach"], "title": "ACCOR: Attention-Enhanced Complex-Valued Contrastive Learning for Occluded Object Classification Using mmWave Radar IQ Signals", "comment": "7 pages, 6 figures", "summary": "Millimeter-wave (mmWave) radar has emerged as a robust sensing modality for several areas, offering reliable operation under adverse environmental conditions. Its ability to penetrate lightweight materials such as packaging or thin walls enables non-visual sensing in industrial and automated environments and can provide robotic platforms with enhanced environmental perception when used alongside optical sensors. Recent work with MIMO mmWave radar has demonstrated its ability to penetrate cardboard packaging for occluded object classification. However, existing models leave room for improvement and warrant a more thorough evaluation across different sensing frequencies. In this paper, we propose ACCOR, an attention-enhanced complex-valued contrastive learning approach for radar, enabling robust occluded object classification. We process complex-valued IQ radar signals using a complex-valued CNN backbone, followed by a multi-head attention layer and a hybrid loss. Our proposed loss combines a weighted cross-entropy term with a supervised contrastive term. We further extend an existing 64 GHz dataset with a 67 GHz subset of the occluded objects and evaluate our model using both center frequencies. Performance evaluation demonstrates that our approach outperforms prior radar-specific models and image classification models with adapted input, achieving classification accuracies of 96.60% at 64 GHz and 93.59% at 67 GHz for ten different objects. These results demonstrate the benefits of complex-valued deep learning with attention and contrastive learning for mmWave radar-based occluded object classification in industrial and automated environments.", "AI": {"tldr": "ACCOR\uff1a\u4e00\u79cd\u7528\u4e8e\u6beb\u7c73\u6ce2\u96f7\u8fbe\u7684\u6ce8\u610f\u529b\u589e\u5f3a\u590d\u6570\u503c\u5bf9\u6bd4\u5b66\u4e60\u65b9\u6cd5\uff0c\u7528\u4e8e\u906e\u6321\u7269\u4f53\u5206\u7c7b\uff0c\u572864GHz\u548c67GHz\u9891\u7387\u4e0b\u5206\u522b\u8fbe\u523096.60%\u548c93.59%\u7684\u5206\u7c7b\u51c6\u786e\u7387\u3002", "motivation": "\u6beb\u7c73\u6ce2\u96f7\u8fbe\u5728\u6076\u52a3\u73af\u5883\u4e0b\u5177\u6709\u9c81\u68d2\u6027\uff0c\u80fd\u7a7f\u900f\u8f7b\u8d28\u6750\u6599\u8fdb\u884c\u975e\u89c6\u89c9\u611f\u77e5\u3002\u73b0\u6709MIMO\u6beb\u7c73\u6ce2\u96f7\u8fbe\u6a21\u578b\u5728\u906e\u6321\u7269\u4f53\u5206\u7c7b\u65b9\u9762\u4ecd\u6709\u6539\u8fdb\u7a7a\u95f4\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u9891\u7387\u8bc4\u4f30\u3002", "method": "\u63d0\u51faACCOR\u65b9\u6cd5\uff1a\u4f7f\u7528\u590d\u6570\u503cCNN\u9aa8\u5e72\u7f51\u7edc\u5904\u7406IQ\u96f7\u8fbe\u4fe1\u53f7\uff0c\u540e\u63a5\u591a\u5934\u6ce8\u610f\u529b\u5c42\u548c\u6df7\u5408\u635f\u5931\u51fd\u6570\uff08\u52a0\u6743\u4ea4\u53c9\u71b5+\u76d1\u7763\u5bf9\u6bd4\u635f\u5931\uff09\u3002\u6269\u5c55\u4e86\u73b0\u670964GHz\u6570\u636e\u96c6\uff0c\u589e\u52a0\u4e8667GHz\u5b50\u96c6\u3002", "result": "\u572810\u79cd\u4e0d\u540c\u7269\u4f53\u7684\u5206\u7c7b\u4efb\u52a1\u4e2d\uff0cACCOR\u572864GHz\u8fbe\u523096.60%\u51c6\u786e\u7387\uff0c\u572867GHz\u8fbe\u523093.59%\u51c6\u786e\u7387\uff0c\u4f18\u4e8e\u73b0\u6709\u96f7\u8fbe\u4e13\u7528\u6a21\u578b\u548c\u56fe\u50cf\u5206\u7c7b\u6a21\u578b\u3002", "conclusion": "\u590d\u6570\u503c\u6df1\u5ea6\u5b66\u4e60\u7ed3\u5408\u6ce8\u610f\u529b\u548c\u5bf9\u6bd4\u5b66\u4e60\u5bf9\u6beb\u7c73\u6ce2\u96f7\u8fbe\u906e\u6321\u7269\u4f53\u5206\u7c7b\u6709\u76ca\uff0c\u9002\u7528\u4e8e\u5de5\u4e1a\u548c\u81ea\u52a8\u5316\u73af\u5883\u3002"}}
{"id": "2512.11629", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.11629", "abs": "https://arxiv.org/abs/2512.11629", "authors": ["Anish Nair", "Austin O' Connell", "Shalomi Arulpragasam", "Noah Kim"], "title": "PaddleSat Optical Charging Station in Space", "comment": null, "summary": "This work investigates the feasibility and design trade-offs for a companion spacecraft, or PaddleSat, to charge a host spacecraft by wirelessly transmitting power using a directional laser system. The primary goal of the PaddleSat is to supplement power on a host spacecraft to reduce the requirements for onboard power systems of the host spacecraft or extend mission lifetimes. System performance estimates, link budget calculations, optical transmission hardware and link analysis, design tradeoffs between beam divergence, optical efficiency, and relative orbital control requirements are examined.", "AI": {"tldr": "\u7814\u7a76\u4e00\u79cd\u540d\u4e3aPaddleSat\u7684\u4f34\u98de\u822a\u5929\u5668\uff0c\u901a\u8fc7\u5b9a\u5411\u6fc0\u5149\u7cfb\u7edf\u4e3a\u5bbf\u4e3b\u822a\u5929\u5668\u65e0\u7ebf\u5145\u7535\u7684\u53ef\u884c\u6027\u548c\u8bbe\u8ba1\u6743\u8861", "motivation": "\u8865\u5145\u5bbf\u4e3b\u822a\u5929\u5668\u7684\u7535\u529b\u4f9b\u5e94\uff0c\u51cf\u5c11\u5bbf\u4e3b\u822a\u5929\u5668\u673a\u8f7d\u7535\u529b\u7cfb\u7edf\u7684\u9700\u6c42\u6216\u5ef6\u957f\u4efb\u52a1\u5bff\u547d", "method": "\u8fdb\u884c\u7cfb\u7edf\u6027\u80fd\u8bc4\u4f30\u3001\u94fe\u8def\u9884\u7b97\u8ba1\u7b97\u3001\u5149\u5b66\u4f20\u8f93\u786c\u4ef6\u548c\u94fe\u8def\u5206\u6790\uff0c\u7814\u7a76\u5149\u675f\u53d1\u6563\u3001\u5149\u5b66\u6548\u7387\u548c\u76f8\u5bf9\u8f68\u9053\u63a7\u5236\u8981\u6c42\u4e4b\u95f4\u7684\u8bbe\u8ba1\u6743\u8861", "result": "\u8bba\u6587\u63a2\u8ba8\u4e86\u65e0\u7ebf\u5145\u7535\u7cfb\u7edf\u7684\u53ef\u884c\u6027\u548c\u8bbe\u8ba1\u6743\u8861\uff0c\u4f46\u6ca1\u6709\u63d0\u4f9b\u5177\u4f53\u7684\u5b9e\u9a8c\u7ed3\u679c\u6570\u636e", "conclusion": "PaddleSat\u6982\u5ff5\u5728\u6280\u672f\u4e0a\u662f\u53ef\u884c\u7684\uff0c\u4f46\u9700\u8981\u5728\u5149\u675f\u63a7\u5236\u3001\u5149\u5b66\u6548\u7387\u548c\u8f68\u9053\u4fdd\u6301\u4e4b\u95f4\u8fdb\u884c\u4ed4\u7ec6\u7684\u6743\u8861\u8bbe\u8ba1"}}

{"id": "2512.13744", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.13744", "abs": "https://arxiv.org/abs/2512.13744", "authors": ["Udayon Sen", "Alka Luqman", "Anupam Chattopadhyay"], "title": "Toward Noise-Aware Audio Deepfake Detection: Survey, SNR-Benchmarks, and Practical Recipes", "comment": "6 pages", "summary": "Deepfake audio detection has progressed rapidly with strong pre-trained encoders (e.g., WavLM, Wav2Vec2, MMS). However, performance in realistic capture conditions - background noise (domestic/office/transport), room reverberation, and consumer channels - often lags clean-lab results. We survey and evaluate robustness for state-of-the-art audio deepfake detection models and present a reproducible framework that mixes MS-SNSD noises with ASVspoof 2021 DF utterances to evaluate under controlled signal-to-noise ratios (SNRs). SNR is a measured proxy for noise severity used widely in speech; it lets us sweep from near-clean (35 dB) to very noisy (-5 dB) to quantify graceful degradation. We study multi-condition training and fixed-SNR testing for pretrained encoders (WavLM, Wav2Vec2, MMS), reporting accuracy, ROC-AUC, and EER on binary and four-class (authenticity x corruption) tasks. In our experiments, finetuning reduces EER by 10-15 percentage points at 10-0 dB SNR across backbones.", "AI": {"tldr": "\u8bba\u6587\u8bc4\u4f30\u4e86\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u6a21\u578b\u5728\u771f\u5b9e\u566a\u58f0\u73af\u5883\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u566a\u58f0\u6d4b\u8bd5\u6846\u67b6\uff0c\u53d1\u73b0\u5fae\u8c03\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u3002", "motivation": "\u5f53\u524d\u57fa\u4e8e\u9884\u8bad\u7ec3\u7f16\u7801\u5668\u7684\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u5728\u5b9e\u9a8c\u5ba4\u5e72\u51c0\u73af\u5883\u4e0b\u8868\u73b0\u826f\u597d\uff0c\u4f46\u5728\u771f\u5b9e\u573a\u666f\u4e2d\uff08\u5305\u542b\u80cc\u666f\u566a\u58f0\u3001\u623f\u95f4\u6df7\u54cd\u3001\u6d88\u8d39\u7ea7\u8bbe\u5907\u901a\u9053\uff09\u6027\u80fd\u4f1a\u663e\u8457\u4e0b\u964d\u3002\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u6a21\u578b\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u8bc4\u4f30\u6846\u67b6\uff1a\u5c06MS-SNSD\u566a\u58f0\u4e0eASVspoof 2021 DF\u8bed\u97f3\u6df7\u5408\uff0c\u5728\u53ef\u63a7\u7684\u4fe1\u566a\u6bd4\uff08SNR\uff09\u4e0b\u6d4b\u8bd5\u3002\u7814\u7a76\u4e86\u591a\u6761\u4ef6\u8bad\u7ec3\u548c\u56fa\u5b9aSNR\u6d4b\u8bd5\u7b56\u7565\uff0c\u8bc4\u4f30\u4e86WavLM\u3001Wav2Vec2\u3001MMS\u7b49\u9884\u8bad\u7ec3\u7f16\u7801\u5668\uff0c\u4f7f\u7528\u51c6\u786e\u7387\u3001ROC-AUC\u548cEER\u6307\u6807\uff0c\u5728\u4e8c\u5143\u548c\u56db\u5206\u7c7b\u4efb\u52a1\u4e0a\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u8868\u660e\uff0c\u572810-0 dB SNR\u7684\u566a\u58f0\u6761\u4ef6\u4e0b\uff0c\u5fae\u8c03\u80fd\u5c06EER\u964d\u4f4e10-15\u4e2a\u767e\u5206\u70b9\u3002\u6a21\u578b\u5728\u4ece\u8fd1\u5e72\u51c0\uff0835 dB\uff09\u5230\u6781\u5608\u6742\uff08-5 dB\uff09\u7684SNR\u8303\u56f4\u5185\u8868\u73b0\u51fa\u6e10\u8fdb\u6027\u6027\u80fd\u4e0b\u964d\u3002", "conclusion": "\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u6a21\u578b\u5728\u566a\u58f0\u73af\u5883\u4e2d\u7684\u9c81\u68d2\u6027\u9700\u8981\u7279\u522b\u5173\u6ce8\uff0c\u5fae\u8c03\u80fd\u663e\u8457\u63d0\u5347\u6a21\u578b\u5728\u771f\u5b9e\u566a\u58f0\u6761\u4ef6\u4e0b\u7684\u6027\u80fd\u3002\u63d0\u51fa\u7684\u8bc4\u4f30\u6846\u67b6\u4e3a\u7cfb\u7edf\u7814\u7a76\u6a21\u578b\u9c81\u68d2\u6027\u63d0\u4f9b\u4e86\u53ef\u590d\u73b0\u7684\u65b9\u6cd5\u3002"}}
{"id": "2512.13905", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.13905", "abs": "https://arxiv.org/abs/2512.13905", "authors": ["Hossein Sharify", "Behnam Raoufi", "Mahdy Ramezani", "Khosrow Hajsadeghi", "Saeed Bagheri Shouraki"], "title": "Ensemble-Guided Distillation for Compact and Robust Acoustic Scene Classification on Edge Devices", "comment": null, "summary": "We present a compact, quantization-ready acoustic scene classification (ASC) framework that couples an efficient student network with a learned teacher ensemble and knowledge distillation. The student backbone uses stacked depthwise-separable \"expand-depthwise-project\" blocks with global response normalization to stabilize training and improve robustness to device and noise variability, while a global pooling head yields class logits for efficient edge inference. To inject richer inductive bias, we assemble a diverse set of teacher models and learn two complementary fusion heads: z1, which predicts per-teacher mixture weights using a student-style backbone, and z2, a lightweight MLP that performs per-class logit fusion. The student is distilled from the ensemble via temperature-scaled soft targets combined with hard labels, enabling it to approximate the ensemble's decision geometry with a single compact model. Evaluated on the TAU Urban Acoustic Scenes 2022 Mobile benchmark, our approach achieves state-of-the-art (SOTA) results on the TAU dataset under matched edge-deployment constraints, demonstrating strong performance and practicality for mobile ASC.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7d27\u51d1\u3001\u91cf\u5316\u5c31\u7eea\u7684\u58f0\u5b66\u573a\u666f\u5206\u7c7b\u6846\u67b6\uff0c\u7ed3\u5408\u9ad8\u6548\u5b66\u751f\u7f51\u7edc\u4e0e\u5b66\u4e60\u578b\u6559\u5e08\u96c6\u6210\u548c\u77e5\u8bc6\u84b8\u998f\uff0c\u5728TAU\u6570\u636e\u96c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u89e3\u51b3\u79fb\u52a8\u8bbe\u5907\u4e0a\u58f0\u5b66\u573a\u666f\u5206\u7c7b\u9700\u8981\u7d27\u51d1\u3001\u9ad8\u6548\u6a21\u578b\u7684\u9700\u6c42\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u6027\u80fd\u548c\u9c81\u68d2\u6027\uff0c\u5e94\u5bf9\u8bbe\u5907\u5dee\u5f02\u548c\u566a\u58f0\u53d8\u5316\u3002", "method": "\u4f7f\u7528\u5806\u53e0\u6df1\u5ea6\u53ef\u5206\u79bb\"\u6269\u5c55-\u6df1\u5ea6-\u6295\u5f71\"\u5757\u6784\u5efa\u5b66\u751f\u7f51\u7edc\uff0c\u7ed3\u5408\u5168\u5c40\u54cd\u5e94\u5f52\u4e00\u5316\uff1b\u6784\u5efa\u591a\u6837\u5316\u6559\u5e08\u6a21\u578b\u96c6\u6210\uff0c\u5b66\u4e60\u4e24\u4e2a\u4e92\u8865\u7684\u878d\u5408\u5934\uff08z1\u9884\u6d4b\u6559\u5e08\u6df7\u5408\u6743\u91cd\uff0cz2\u8fdb\u884c\u7c7b\u522blogit\u878d\u5408\uff09\uff1b\u901a\u8fc7\u6e29\u5ea6\u7f29\u653e\u8f6f\u76ee\u6807\u4e0e\u786c\u6807\u7b7e\u7ed3\u5408\u8fdb\u884c\u77e5\u8bc6\u84b8\u998f\u3002", "result": "\u5728TAU Urban Acoustic Scenes 2022 Mobile\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u5728\u5339\u914d\u7684\u8fb9\u7f18\u90e8\u7f72\u7ea6\u675f\u4e0b\u8fbe\u5230\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u5c55\u793a\u4e86\u79fb\u52a8ASC\u7684\u5f3a\u5927\u6027\u80fd\u548c\u5b9e\u7528\u6027\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u5b9e\u73b0\u4e86\u7d27\u51d1\u3001\u91cf\u5316\u5c31\u7eea\u7684\u58f0\u5b66\u573a\u666f\u5206\u7c7b\uff0c\u901a\u8fc7\u77e5\u8bc6\u84b8\u998f\u4f7f\u5355\u4e2a\u7d27\u51d1\u6a21\u578b\u80fd\u591f\u8fd1\u4f3c\u96c6\u6210\u6a21\u578b\u7684\u51b3\u7b56\u51e0\u4f55\uff0c\u5728\u79fb\u52a8\u8bbe\u5907\u4e0a\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.13998", "categories": ["cs.SD", "cs.AI", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.13998", "abs": "https://arxiv.org/abs/2512.13998", "authors": ["Qilin Li", "C. L. Philip Chen", "TongZhang"], "title": "Memo2496: Expert-Annotated Dataset and Dual-View Adaptive Framework for Music Emotion Recognition", "comment": null, "summary": "Music Emotion Recogniser (MER) research faces challenges due to limited high-quality annotated datasets and difficulties in addressing cross-track feature drift. This work presents two primary contributions to address these issues. Memo2496, a large-scale dataset, offers 2496 instrumental music tracks with continuous valence arousal labels, annotated by 30 certified music specialists. Annotation quality is ensured through calibration with extreme emotion exemplars and a consistency threshold of 0.25, measured by Euclidean distance in the valence arousal space. Furthermore, the Dual-view Adaptive Music Emotion Recogniser (DAMER) is introduced. DAMER integrates three synergistic modules: Dual Stream Attention Fusion (DSAF) facilitates token-level bidirectional interaction between Mel spectrograms and cochleagrams via cross attention mechanisms; Progressive Confidence Labelling (PCL) generates reliable pseudo labels employing curriculum-based temperature scheduling and consistency quantification using Jensen Shannon divergence; and Style Anchored Memory Learning (SAML) maintains a contrastive memory queue to mitigate cross-track feature drift. Extensive experiments on the Memo2496, 1000songs, and PMEmo datasets demonstrate DAMER's state-of-the-art performance, improving arousal dimension accuracy by 3.43%, 2.25%, and 0.17%, respectively. Ablation studies and visualisation analyses validate each module's contribution. Both the dataset and source code are publicly available.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51faMemo2496\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548cDAMER\u6a21\u578b\uff0c\u89e3\u51b3\u97f3\u4e50\u60c5\u611f\u8bc6\u522b\u4e2d\u6570\u636e\u8d28\u91cf\u5dee\u548c\u8de8\u66f2\u76ee\u7279\u5f81\u6f02\u79fb\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230SOTA\u6027\u80fd\u3002", "motivation": "\u97f3\u4e50\u60c5\u611f\u8bc6\u522b\u7814\u7a76\u9762\u4e34\u9ad8\u8d28\u91cf\u6807\u6ce8\u6570\u636e\u96c6\u6709\u9650\u548c\u8de8\u66f2\u76ee\u7279\u5f81\u6f02\u79fb\u7684\u6311\u6218\uff0c\u9700\u8981\u66f4\u597d\u7684\u6570\u636e\u96c6\u548c\u6a21\u578b\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "1) \u521b\u5efaMemo2496\u6570\u636e\u96c6\uff1a2496\u9996\u5668\u4e50\u4f5c\u54c1\uff0c30\u4f4d\u4e13\u4e1a\u97f3\u4e50\u4e13\u5bb6\u6807\u6ce8\u8fde\u7eed\u6548\u4ef7-\u5524\u9192\u5ea6\u6807\u7b7e\uff0c\u901a\u8fc7\u6781\u7aef\u60c5\u611f\u6837\u672c\u6821\u51c6\u548c0.25\u4e00\u81f4\u6027\u9608\u503c\u4fdd\u8bc1\u8d28\u91cf\u30022) \u63d0\u51faDAMER\u6a21\u578b\uff1a\u5305\u542b\u4e09\u4e2a\u534f\u540c\u6a21\u5757\uff1a\u53cc\u6d41\u6ce8\u610f\u529b\u878d\u5408(DSAF)\u5b9e\u73b0\u6885\u5c14\u8c31\u56fe\u548c\u8033\u8717\u56fe\u7684\u53cc\u5411\u4ea4\u4e92\uff1b\u6e10\u8fdb\u7f6e\u4fe1\u5ea6\u6807\u6ce8(PCL)\u751f\u6210\u53ef\u9760\u4f2a\u6807\u7b7e\uff1b\u98ce\u683c\u951a\u5b9a\u8bb0\u5fc6\u5b66\u4e60(SAML)\u7ef4\u62a4\u5bf9\u6bd4\u8bb0\u5fc6\u961f\u5217\u7f13\u89e3\u7279\u5f81\u6f02\u79fb\u3002", "result": "\u5728Memo2496\u30011000songs\u548cPMEmo\u6570\u636e\u96c6\u4e0a\uff0cDAMER\u8fbe\u5230\u6700\u5148\u8fdb\u6027\u80fd\uff0c\u5524\u9192\u5ea6\u7ef4\u5ea6\u51c6\u786e\u7387\u5206\u522b\u63d0\u53473.43%\u30012.25%\u548c0.17%\u3002\u6d88\u878d\u7814\u7a76\u548c\u53ef\u89c6\u5316\u5206\u6790\u9a8c\u8bc1\u4e86\u5404\u6a21\u5757\u7684\u6709\u6548\u6027\u3002", "conclusion": "Memo2496\u6570\u636e\u96c6\u548cDAMER\u6a21\u578b\u6709\u6548\u89e3\u51b3\u4e86\u97f3\u4e50\u60c5\u611f\u8bc6\u522b\u4e2d\u7684\u6570\u636e\u8d28\u91cf\u548c\u7279\u5f81\u6f02\u79fb\u95ee\u9898\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u8d44\u6e90\u548c\u5148\u8fdb\u65b9\u6cd5\u3002\u6570\u636e\u96c6\u548c\u6e90\u4ee3\u7801\u5df2\u516c\u5f00\u3002"}}
{"id": "2512.14115", "categories": ["cs.SD", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14115", "abs": "https://arxiv.org/abs/2512.14115", "authors": ["Ramesh Gundluru", "Shubham Gupta", "Sri Rama Murty K"], "title": "Joint Multimodal Contrastive Learning for Robust Spoken Term Detection and Keyword Spotting", "comment": null, "summary": "Acoustic Word Embeddings (AWEs) improve the efficiency of speech retrieval tasks such as Spoken Term Detection (STD) and Keyword Spotting (KWS). However, existing approaches suffer from limitations, including unimodal supervision, disjoint optimization of audio-audio and audio-text alignment, and the need for task-specific models. To address these shortcomings, we propose a joint multimodal contrastive learning framework that unifies both acoustic and cross-modal supervision in a shared embedding space. Our approach simultaneously optimizes: (i) audio-text contrastive learning, inspired by the CLAP loss, to align audio and text representations and (ii) audio-audio contrastive learning, via Deep Word Discrimination (DWD) loss, to enhance intra-class compactness and inter-class separation. The proposed method outperforms existing AWE baselines on word discrimination task while flexibly supporting both STD and KWS. To our knowledge, this is the first comprehensive approach of its kind.", "AI": {"tldr": "\u63d0\u51fa\u8054\u5408\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff0c\u7edf\u4e00\u58f0\u5b66\u548c\u8de8\u6a21\u6001\u76d1\u7763\uff0c\u540c\u65f6\u4f18\u5316\u97f3\u9891-\u6587\u672c\u548c\u97f3\u9891-\u97f3\u9891\u5bf9\u9f50\uff0c\u5728\u8bcd\u533a\u5206\u4efb\u52a1\u4e0a\u8d85\u8d8a\u73b0\u6709\u57fa\u7ebf\uff0c\u7075\u6d3b\u652f\u6301STD\u548cKWS\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u58f0\u5b66\u8bcd\u5d4c\u5165\u65b9\u6cd5\u5b58\u5728\u5355\u6a21\u6001\u76d1\u7763\u3001\u97f3\u9891-\u97f3\u9891\u548c\u97f3\u9891-\u6587\u672c\u5bf9\u9f50\u5206\u79bb\u4f18\u5316\u3001\u9700\u8981\u4efb\u52a1\u7279\u5b9a\u6a21\u578b\u7b49\u5c40\u9650\u6027\uff0c\u9700\u8981\u66f4\u7edf\u4e00\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u8054\u5408\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\uff1a1) \u97f3\u9891-\u6587\u672c\u5bf9\u6bd4\u5b66\u4e60\uff08\u53d7CLAP\u635f\u5931\u542f\u53d1\uff09\u5bf9\u9f50\u97f3\u9891\u548c\u6587\u672c\u8868\u793a\uff1b2) \u97f3\u9891-\u97f3\u9891\u5bf9\u6bd4\u5b66\u4e60\uff08\u901a\u8fc7\u6df1\u5ea6\u8bcd\u533a\u5206\u635f\u5931\uff09\u589e\u5f3a\u7c7b\u5185\u7d27\u51d1\u6027\u548c\u7c7b\u95f4\u5206\u79bb\u6027\u3002", "result": "\u5728\u8bcd\u533a\u5206\u4efb\u52a1\u4e0a\u8d85\u8d8a\u73b0\u6709\u58f0\u5b66\u8bcd\u5d4c\u5165\u57fa\u7ebf\uff0c\u540c\u65f6\u7075\u6d3b\u652f\u6301\u53e3\u8bed\u8bcd\u68c0\u6d4b\u548c\u5173\u952e\u8bcd\u53d1\u73b0\u4e24\u79cd\u4efb\u52a1\uff0c\u662f\u9996\u4e2a\u6b64\u7c7b\u7efc\u5408\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u8054\u5408\u591a\u6a21\u6001\u5bf9\u6bd4\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u7edf\u4e00\u58f0\u5b66\u548c\u8de8\u6a21\u6001\u76d1\u7763\uff0c\u5728\u4fdd\u6301\u4efb\u52a1\u7075\u6d3b\u6027\u7684\u540c\u65f6\u63d0\u5347\u4e86\u6027\u80fd\u3002"}}
{"id": "2512.14083", "categories": ["eess.AS", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14083", "abs": "https://arxiv.org/abs/2512.14083", "authors": ["Sungnyun Kim"], "title": "Scalable Frameworks for Real-World Audio-Visual Speech Recognition", "comment": "PhD Dissertation", "summary": "The practical deployment of Audio-Visual Speech Recognition (AVSR) systems is fundamentally challenged by significant performance degradation in real-world environments, characterized by unpredictable acoustic noise and visual interference. This dissertation posits that a systematic, hierarchical approach is essential to overcome these challenges, achieving the robust scalability at the representation, architecture, and system levels. At the representation level, we investigate methods for building a unified model that learns audio-visual features inherently robust to diverse real-world corruptions, thereby enabling generalization to new environments without specialized modules. To address architectural scalability, we explore how to efficiently expand model capacity while ensuring the adaptive and reliable use of multimodal inputs, developing a framework that intelligently allocates computational resources based on the input characteristics. Finally, at the system level, we present methods to expand the system's functionality through modular integration with large-scale foundation models, leveraging their powerful cognitive and generative capabilities to maximize final recognition accuracy. By systematically providing solutions at each of these three levels, this dissertation aims to build a next-generation, robust, and scalable AVSR system with high reliability in real-world applications.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5206\u5c42\u7cfb\u7edf\u65b9\u6cd5\uff0c\u901a\u8fc7\u5728\u8868\u793a\u3001\u67b6\u6784\u548c\u7cfb\u7edf\u4e09\u4e2a\u5c42\u9762\u89e3\u51b3\u9c81\u68d2\u6027\u548c\u53ef\u6269\u5c55\u6027\u95ee\u9898\uff0c\u6784\u5efa\u4e0b\u4e00\u4ee3\u9c81\u68d2\u53ef\u6269\u5c55\u7684\u89c6\u542c\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u3002", "motivation": "\u5b9e\u9645\u90e8\u7f72\u7684\u89c6\u542c\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u9762\u4e34\u4e25\u91cd\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u5305\u62ec\u4e0d\u53ef\u9884\u6d4b\u7684\u58f0\u5b66\u566a\u58f0\u548c\u89c6\u89c9\u5e72\u6270\uff0c\u9700\u8981\u7cfb\u7edf\u6027\u7684\u89e3\u51b3\u65b9\u6848\u6765\u5e94\u5bf9\u8fd9\u4e9b\u6311\u6218\u3002", "method": "\u91c7\u7528\u5206\u5c42\u65b9\u6cd5\uff1a1) \u8868\u793a\u5c42\u9762\uff1a\u6784\u5efa\u7edf\u4e00\u6a21\u578b\u5b66\u4e60\u5bf9\u591a\u6837\u5316\u771f\u5b9e\u4e16\u754c\u5e72\u6270\u5177\u6709\u5185\u5728\u9c81\u68d2\u6027\u7684\u89c6\u542c\u7279\u5f81\uff1b2) \u67b6\u6784\u5c42\u9762\uff1a\u5f00\u53d1\u9ad8\u6548\u6269\u5c55\u6a21\u578b\u5bb9\u91cf\u7684\u6846\u67b6\uff0c\u57fa\u4e8e\u8f93\u5165\u7279\u5f81\u667a\u80fd\u5206\u914d\u8ba1\u7b97\u8d44\u6e90\uff1b3) \u7cfb\u7edf\u5c42\u9762\uff1a\u901a\u8fc7\u6a21\u5757\u5316\u96c6\u6210\u5927\u89c4\u6a21\u57fa\u7840\u6a21\u578b\uff0c\u5229\u7528\u5176\u5f3a\u5927\u7684\u8ba4\u77e5\u548c\u751f\u6210\u80fd\u529b\u3002", "result": "\u8bba\u6587\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u5728\u8868\u793a\u3001\u67b6\u6784\u548c\u7cfb\u7edf\u4e09\u4e2a\u5c42\u9762\u90fd\u5177\u6709\u9c81\u68d2\u53ef\u6269\u5c55\u6027\u7684\u4e0b\u4e00\u4ee3AVSR\u7cfb\u7edf\uff0c\u80fd\u591f\u5728\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u5b9e\u73b0\u9ad8\u53ef\u9760\u6027\u3002", "conclusion": "\u901a\u8fc7\u7cfb\u7edf\u6027\u5730\u5728\u4e09\u4e2a\u5c42\u6b21\u63d0\u4f9b\u89e3\u51b3\u65b9\u6848\uff0c\u8be5\u7814\u7a76\u65e8\u5728\u6784\u5efa\u4e00\u4e2a\u5728\u771f\u5b9e\u4e16\u754c\u5e94\u7528\u4e2d\u5177\u6709\u9ad8\u53ef\u9760\u6027\u7684\u4e0b\u4e00\u4ee3\u9c81\u68d2\u53ef\u6269\u5c55AVSR\u7cfb\u7edf\u3002"}}
{"id": "2512.13844", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.13844", "abs": "https://arxiv.org/abs/2512.13844", "authors": ["Hiten Prakash Kothari", "R. Michael Buehrer"], "title": "Interference Mitigation using U-Net Autoencoder based system", "comment": null, "summary": "This paper proposes a U-Net-based autoencoder framework for mitigating interference in communication signals corrupted by noise and diverse interference sources. The approach targets scenarios involving both signal-plus-noise and signal-plus-interference-plus-noise mixtures, including sinusoidal interferers, LFM chirps, QPSK interferers with different sampling rates, and modulated interference such as QAM. The U-Net architecture leverages multiscale feature extraction and skip connections to preserve fine-grained temporal structure while suppressing interference components. Performance is evaluated using bit error rate and compared against conventional cancellation methods. Results show that the proposed method consistently outperforms traditional techniques in low- and mid-SIR regimes, while remaining competitive at high SIRs. Additional experiments examine the autoencoder's behavior under model mismatch conditions such as carrier offset and colored noise. The study demonstrates that multiscale neural architectures provide a flexible and effective platform for interference mitigation across a wide range of interference types.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eU-Net\u7684\u81ea\u7f16\u7801\u5668\u6846\u67b6\uff0c\u7528\u4e8e\u6291\u5236\u901a\u4fe1\u4fe1\u53f7\u4e2d\u7684\u566a\u58f0\u548c\u591a\u79cd\u5e72\u6270\u6e90\uff0c\u5728\u4f4e\u4e2dSIR\u4e0b\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5", "motivation": "\u901a\u4fe1\u4fe1\u53f7\u5e38\u53d7\u566a\u58f0\u548c\u5404\u79cd\u5e72\u6270\u6e90\u5f71\u54cd\uff0c\u4f20\u7edf\u5e72\u6270\u6291\u5236\u65b9\u6cd5\u5728\u590d\u6742\u5e72\u6270\u73af\u5883\u4e0b\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u66f4\u7075\u6d3b\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u91c7\u7528U-Net\u67b6\u6784\u7684\u81ea\u7f16\u7801\u5668\u6846\u67b6\uff0c\u5229\u7528\u591a\u5c3a\u5ea6\u7279\u5f81\u63d0\u53d6\u548c\u8df3\u8dc3\u8fde\u63a5\uff0c\u5728\u4fdd\u7559\u4fe1\u53f7\u7cbe\u7ec6\u65f6\u95f4\u7ed3\u6784\u7684\u540c\u65f6\u6291\u5236\u5e72\u6270\u6210\u5206", "result": "\u5728\u4f4e\u4e2dSIR\u4e0b\u6301\u7eed\u4f18\u4e8e\u4f20\u7edf\u5e72\u6270\u6d88\u9664\u65b9\u6cd5\uff0c\u5728\u9ad8SIR\u4e0b\u4fdd\u6301\u7ade\u4e89\u529b\uff1b\u5728\u8f7d\u6ce2\u504f\u79fb\u548c\u6709\u8272\u566a\u58f0\u7b49\u6a21\u578b\u5931\u914d\u6761\u4ef6\u4e0b\u8868\u73b0\u826f\u597d", "conclusion": "\u591a\u5c3a\u5ea6\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\u4e3a\u5404\u79cd\u5e72\u6270\u7c7b\u578b\u63d0\u4f9b\u4e86\u7075\u6d3b\u6709\u6548\u7684\u5e72\u6270\u6291\u5236\u5e73\u53f0\uff0c\u5c55\u793a\u4e86\u6df1\u5ea6\u5b66\u4e60\u5728\u901a\u4fe1\u4fe1\u53f7\u5904\u7406\u4e2d\u7684\u6f5c\u529b"}}
{"id": "2512.14291", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.14291", "abs": "https://arxiv.org/abs/2512.14291", "authors": ["Jiayan Cui", "Zhihan Yang", "Naihan Li", "Jiankun Tian", "Xingyu Ma", "Yi Zhang", "Guangyu Chen", "Runxuan Yang", "Yuqing Cheng", "Yizhi Zhou", "Guochen Yu", "Xiaotao Gu", "Jie Tang"], "title": "GLM-TTS Technical Report", "comment": null, "summary": "This work proposes GLM-TTS, a production-level TTS system designed for efficiency, controllability, and high-fidelity speech generation. GLM-TTS follows a two-stage architecture, consisting of a text-to-token autoregressive model and a token-to-waveform diffusion model. With only 100k hours of training data, GLM-TTS achieves state-of-the-art performance on multiple open-source benchmarks. To meet production requirements, GLM-TTS improves speech quality through an optimized speech tokenizer with fundamental frequency constraints and a GRPO-based multi-reward reinforcement learning framework that jointly optimizes pronunciation, speaker similarity, and expressive prosody. In parallel, the system enables efficient and controllable deployment via parameter-efficient LoRA-based voice customization and a hybrid phoneme-text input scheme that provides precise pronunciation control. Our code is available at https://github.com/zai-org/GLM-TTS. Real-time speech synthesis demos are provided via Z.ai (audio.z.ai), the Zhipu Qingyan app/web (chatglm.cn).", "AI": {"tldr": "GLM-TTS\u662f\u4e00\u4e2a\u751f\u4ea7\u7ea7\u6587\u672c\u8f6c\u8bed\u97f3\u7cfb\u7edf\uff0c\u91c7\u7528\u4e24\u9636\u6bb5\u67b6\u6784\uff08\u6587\u672c\u5230token\u81ea\u56de\u5f52\u6a21\u578b\u548ctoken\u5230\u6ce2\u5f62\u6269\u6563\u6a21\u578b\uff09\uff0c\u5728\u4ec5100k\u5c0f\u65f6\u8bad\u7ec3\u6570\u636e\u4e0b\u5b9e\u73b0SOTA\u6027\u80fd\uff0c\u901a\u8fc7\u4f18\u5316\u8bed\u97f3\u5206\u8bcd\u5668\u548c\u591a\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u63d0\u5347\u8d28\u91cf\uff0c\u652f\u6301\u9ad8\u6548\u8bed\u97f3\u5b9a\u5236\u548c\u7cbe\u786e\u53d1\u97f3\u63a7\u5236\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u6ee1\u8db3\u751f\u4ea7\u9700\u6c42\u7684TTS\u7cfb\u7edf\uff0c\u9700\u8981\u517c\u987e\u6548\u7387\u3001\u53ef\u63a7\u6027\u548c\u9ad8\u4fdd\u771f\u8bed\u97f3\u751f\u6210\uff0c\u540c\u65f6\u8981\u5728\u6709\u9650\u8bad\u7ec3\u6570\u636e\u4e0b\u5b9e\u73b0\u6700\u4f18\u6027\u80fd\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5\u67b6\u6784\uff1a1\uff09\u6587\u672c\u5230token\u7684\u81ea\u56de\u5f52\u6a21\u578b\uff1b2\uff09token\u5230\u6ce2\u5f62\u7684\u6269\u6563\u6a21\u578b\u3002\u901a\u8fc7\u4f18\u5316\u8bed\u97f3\u5206\u8bcd\u5668\uff08\u52a0\u5165\u57fa\u9891\u7ea6\u675f\uff09\u548cGRPO\u591a\u5956\u52b1\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff08\u8054\u5408\u4f18\u5316\u53d1\u97f3\u3001\u8bf4\u8bdd\u4eba\u76f8\u4f3c\u6027\u548c\u8868\u8fbe\u6027\u97f5\u5f8b\uff09\u63d0\u5347\u8d28\u91cf\u3002\u652f\u6301LoRA\u53c2\u6570\u9ad8\u6548\u8bed\u97f3\u5b9a\u5236\u548c\u6df7\u5408\u97f3\u7d20-\u6587\u672c\u8f93\u5165\u65b9\u6848\u5b9e\u73b0\u7cbe\u786e\u63a7\u5236\u3002", "result": "\u5728\u4ec5100k\u5c0f\u65f6\u8bad\u7ec3\u6570\u636e\u4e0b\uff0c\u5728\u591a\u4e2a\u5f00\u6e90\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8fbe\u5230state-of-the-art\u6027\u80fd\uff0c\u5b9e\u73b0\u4e86\u751f\u4ea7\u7ea7\u7684\u8bed\u97f3\u5408\u6210\u8d28\u91cf\u3002", "conclusion": "GLM-TTS\u662f\u4e00\u4e2a\u9ad8\u6548\u3001\u53ef\u63a7\u4e14\u9ad8\u8d28\u91cf\u7684TTS\u7cfb\u7edf\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u4e24\u9636\u6bb5\u67b6\u6784\u548c\u4f18\u5316\u6280\u672f\uff0c\u5728\u6709\u9650\u6570\u636e\u4e0b\u5b9e\u73b0\u4e86SOTA\u6027\u80fd\uff0c\u9002\u5408\u751f\u4ea7\u73af\u5883\u90e8\u7f72\u3002"}}
{"id": "2512.14259", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2512.14259", "abs": "https://arxiv.org/abs/2512.14259", "authors": ["Sascha Dick", "Christoph Thompson", "Chih-Wei Wu", "Pablo Delgado", "Phillip A. Williams", "Matteo Torcoli"], "title": "Investigating the impact of stereo processing -- a study for extending the Open Dataset of Audio Quality (ODAQ)", "comment": "Presented at the Audio Engineering Society (AES) 159th Convention, October 2025, Paper number 365, see https://aes2.org/publications/elibrary-page/?id=23039", "summary": "In this paper, we present an initial study for extending Open Dataset of Audio Quality (ODAQ) towards the impact of stereo processing. Monaural artifacts from ODAQ were adapted in combinations with left-right (LR) and mid-side (MS) stereo processing, across stimuli including solo instruments, typical wide stereo mixes and and hard-panned mixes. Listening tests in different presentation context -- with and without direct comparison of MS and LR conditions -- were conducted to collect subjective data beyond monaural artifacts while also scrutinizing the listening test methodology. The ODAQ dataset is extended with new material along with subjective scores from 16 expert listeners. The listening test results show substantial influences of the stimuli's spatial characteristics as well as the presentation context. Notably, several significant disparities between LR and MS only occur when presented in direct comparison. The findings suggest that listeners primarily assess timbral impairments when spatial characteristics are consistent and focus on stereo image only when timbral quality is similar. The rating of an additional mono anchor was overall consistent across different stereo characteristics, averaging at 65 on the MUSHRA scale, further corroborating that listeners prioritize timbral over spatial impressions.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6269\u5c55\u4e86ODAQ\u97f3\u9891\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u63a2\u7d22\u7acb\u4f53\u58f0\u5904\u7406\uff08\u5de6\u53f3LR\u548c\u4e2d\u4fa7MS\uff09\u5bf9\u97f3\u9891\u8d28\u91cf\u611f\u77e5\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u542c\u4f17\u4e3b\u8981\u5173\u6ce8\u97f3\u8272\u635f\u4f24\u800c\u975e\u7a7a\u95f4\u5370\u8c61\u3002", "motivation": "\u73b0\u6709ODAQ\u6570\u636e\u96c6\u4e3b\u8981\u5173\u6ce8\u5355\u58f0\u9053\u97f3\u9891\u8d28\u91cf\uff0c\u9700\u8981\u6269\u5c55\u5230\u7acb\u4f53\u58f0\u5904\u7406\u9886\u57df\uff0c\u7814\u7a76\u4e0d\u540c\u7acb\u4f53\u58f0\u5904\u7406\u65b9\u5f0f\uff08LR\u548cMS\uff09\u5bf9\u97f3\u9891\u8d28\u91cf\u611f\u77e5\u7684\u5f71\u54cd\uff0c\u5e76\u9a8c\u8bc1\u542c\u529b\u6d4b\u8bd5\u65b9\u6cd5\u3002", "method": "\u5c06ODAQ\u7684\u5355\u58f0\u9053\u4f2a\u5f71\u9002\u5e94\u5230LR\u548cMS\u7acb\u4f53\u58f0\u5904\u7406\u4e2d\uff0c\u4f7f\u7528\u72ec\u594f\u4e50\u5668\u3001\u5178\u578b\u5bbd\u7acb\u4f53\u58f0\u6df7\u97f3\u548c\u786c\u58f0\u50cf\u6df7\u97f3\u7b49\u523a\u6fc0\u6750\u6599\uff0c\u901a\u8fc716\u540d\u4e13\u5bb6\u542c\u4f17\u8fdb\u884c\u542c\u529b\u6d4b\u8bd5\uff0c\u6bd4\u8f83\u4e0d\u540c\u5448\u73b0\u4e0a\u4e0b\u6587\uff08\u6709\u65e0\u76f4\u63a5\u6bd4\u8f83\uff09\u3002", "result": "\u523a\u6fc0\u6750\u6599\u7684\u7a7a\u95f4\u7279\u6027\u548c\u5448\u73b0\u4e0a\u4e0b\u6587\u5bf9\u4e3b\u89c2\u8bc4\u5206\u6709\u663e\u8457\u5f71\u54cd\uff1bLR\u548cMS\u4e4b\u95f4\u7684\u663e\u8457\u5dee\u5f02\u4ec5\u5728\u76f4\u63a5\u6bd4\u8f83\u65f6\u51fa\u73b0\uff1b\u542c\u4f17\u5728\u7a7a\u95f4\u7279\u6027\u4e00\u81f4\u65f6\u4e3b\u8981\u8bc4\u4f30\u97f3\u8272\u635f\u4f24\uff0c\u5728\u97f3\u8272\u8d28\u91cf\u76f8\u4f3c\u65f6\u624d\u5173\u6ce8\u7acb\u4f53\u58f0\u50cf\uff1b\u5355\u58f0\u9053\u951a\u70b9\u8bc4\u5206\u5728\u4e0d\u540c\u7acb\u4f53\u58f0\u7279\u6027\u4e0b\u4fdd\u6301\u7a33\u5b9a\uff08\u5e73\u574765\u5206MUSHRA\uff09\u3002", "conclusion": "\u542c\u4f17\u5728\u8bc4\u4f30\u97f3\u9891\u8d28\u91cf\u65f6\u4f18\u5148\u8003\u8651\u97f3\u8272\u635f\u4f24\u800c\u975e\u7a7a\u95f4\u5370\u8c61\uff1b\u542c\u529b\u6d4b\u8bd5\u7684\u5448\u73b0\u4e0a\u4e0b\u6587\uff08\u662f\u5426\u76f4\u63a5\u6bd4\u8f83\uff09\u5bf9\u7ed3\u679c\u6709\u91cd\u8981\u5f71\u54cd\uff1b\u6269\u5c55\u7684ODAQ\u6570\u636e\u96c6\u4e3a\u7acb\u4f53\u58f0\u5904\u7406\u8d28\u91cf\u8bc4\u4f30\u63d0\u4f9b\u4e86\u65b0\u8d44\u6e90\u3002"}}
{"id": "2512.13866", "categories": ["eess.SP", "cs.AR"], "pdf": "https://arxiv.org/pdf/2512.13866", "abs": "https://arxiv.org/abs/2512.13866", "authors": ["Mostafa Darvishi"], "title": "Pipeline Stage Resolved Timing Characterization of FPGA and ASIC Implementations of a RISC V Processor", "comment": "11 pages, 7 figures, 1 table, submitted to IEEE Transactions on Circuits and Systems (TCAS). Identification # TCAS-I-03260-2025", "summary": "This paper presents a pipeline stage resolved timing characterization of a 32-bit RISC V processor implemented on a 20 nm FPGA and a 7 nm FinFET ASIC platform. A unified analysis framework is introduced that decomposes timing paths into logic, routing, and clocking components and maps them to well-defined pipeline stage transitions. This approach enables systematic comparison of timing behavior across heterogeneous implementation technologies at a microarchitectural level. Using static timing analysis and statistical characterization, the study shows that although both implementations exhibit dominant critical paths in the EX to MEM pipeline transition, their underlying timing mechanisms differ fundamentally. FPGA timing is dominated by routing parasitics and placement dependent variability, resulting in wide slack distributions and sensitivity to routing topology. In contrast, ASIC timing is governed primarily by combinational logic depth and predictable parametric variation across process, voltage, and temperature corners, yielding narrow and stable timing distributions. The results provide quantitative insight into the structural origins of timing divergence between programmable and custom fabrics and demonstrate the effectiveness of pipeline stage resolved analysis for identifying platform specific bottlenecks. Based on these findings, the paper derives design implications for achieving predictable timing closure in processor architectures targeting both FPGA and ASIC implementations.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf932\u4f4dRISC-V\u5904\u7406\u5668\u572820nm FPGA\u548c7nm FinFET ASIC\u5e73\u53f0\u4e0a\u7684\u6d41\u6c34\u7ebf\u7ea7\u65f6\u5e8f\u5206\u6790\u65b9\u6cd5\uff0c\u63ed\u793a\u4e86\u4e24\u79cd\u5b9e\u73b0\u6280\u672f\u4e4b\u95f4\u6839\u672c\u4e0d\u540c\u7684\u65f6\u5e8f\u673a\u5236\u3002", "motivation": "\u7814\u7a76\u52a8\u673a\u5728\u4e8e\u7406\u89e3\u5f02\u6784\u5b9e\u73b0\u6280\u672f\uff08FPGA vs ASIC\uff09\u5728\u5fae\u67b6\u6784\u5c42\u9762\u7684\u65f6\u5e8f\u884c\u4e3a\u5dee\u5f02\uff0c\u4e3a\u5904\u7406\u5668\u8bbe\u8ba1\u63d0\u4f9b\u8de8\u5e73\u53f0\u65f6\u5e8f\u6536\u655b\u7684\u6307\u5bfc\u3002", "method": "\u5f15\u5165\u7edf\u4e00\u5206\u6790\u6846\u67b6\uff0c\u5c06\u65f6\u5e8f\u8def\u5f84\u5206\u89e3\u4e3a\u903b\u8f91\u3001\u5e03\u7ebf\u548c\u65f6\u949f\u7ec4\u4ef6\uff0c\u5e76\u6620\u5c04\u5230\u660e\u786e\u5b9a\u4e49\u7684\u6d41\u6c34\u7ebf\u7ea7\u8f6c\u6362\u3002\u4f7f\u7528\u9759\u6001\u65f6\u5e8f\u5206\u6790\u548c\u7edf\u8ba1\u7279\u6027\u5206\u6790\u3002", "result": "\u867d\u7136\u4e24\u79cd\u5b9e\u73b0\u7684\u5173\u952e\u8def\u5f84\u90fd\u96c6\u4e2d\u5728EX\u5230MEM\u6d41\u6c34\u7ebf\u8f6c\u6362\uff0c\u4f46FPGA\u65f6\u5e8f\u53d7\u5e03\u7ebf\u5bc4\u751f\u548c\u5e03\u5c40\u76f8\u5173\u53d8\u5f02\u4e3b\u5bfc\uff0c\u800cASIC\u65f6\u5e8f\u4e3b\u8981\u7531\u7ec4\u5408\u903b\u8f91\u6df1\u5ea6\u548c\u53ef\u9884\u6d4b\u7684PVT\u53d8\u5316\u51b3\u5b9a\u3002", "conclusion": "\u6d41\u6c34\u7ebf\u7ea7\u65f6\u5e8f\u5206\u6790\u80fd\u6709\u6548\u8bc6\u522b\u5e73\u53f0\u7279\u5b9a\u74f6\u9888\uff0c\u7814\u7a76\u7ed3\u679c\u4e3aFPGA\u548cASIC\u5b9e\u73b0\u4e2d\u7684\u53ef\u9884\u6d4b\u65f6\u5e8f\u6536\u655b\u63d0\u4f9b\u4e86\u8bbe\u8ba1\u542f\u793a\u3002"}}
{"id": "2512.14602", "categories": ["cs.SD", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14602", "abs": "https://arxiv.org/abs/2512.14602", "authors": ["Luk\u00e1\u0161 Samuel Mart\u00e1k", "Patricia Hu", "Gerhard Widmer"], "title": "Sound and Music Biases in Deep Music Transcription Models: A Systematic Analysis", "comment": "pre-print of the upcoming EURASIP JASM journal article", "summary": "Automatic Music Transcription (AMT) -- the task of converting music audio into note representations -- has seen rapid progress, driven largely by deep learning systems. Due to the limited availability of richly annotated music datasets, much of the progress in AMT has been concentrated on classical piano music, and even a few very specific datasets. Whether these systems can generalize effectively to other musical contexts remains an open question. Complementing recent studies on distribution shifts in sound (e.g., recording conditions), in this work we investigate the musical dimension -- specifically, variations in genre, dynamics, and polyphony levels. To this end, we introduce the MDS corpus, comprising three distinct subsets -- (1) Genre, (2) Random, and (3) MAEtest -- to emulate different axes of distribution shift. We evaluate the performance of several state-of-the-art AMT systems on the MDS corpus using both traditional information-retrieval and musically-informed performance metrics. Our extensive evaluation isolates and exposes varying degrees of performance degradation under specific distribution shifts. In particular, we measure a note-level F1 performance drop of 20 percentage points due to sound, and 14 due to genre. Generally, we find that dynamics estimation proves more vulnerable to musical variation than onset prediction. Musically informed evaluation metrics, particularly those capturing harmonic structure, help identify potential contributing factors. Furthermore, experiments with randomly generated, non-musical sequences reveal clear limitations in system performance under extreme musical distribution shifts. Altogether, these findings offer new evidence of the persistent impact of the Corpus Bias problem in deep AMT systems.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u6784\u5efaMDS\u8bed\u6599\u5e93\uff0c\u8bc4\u4f30\u4e86\u81ea\u52a8\u97f3\u4e50\u8f6c\u5f55\u7cfb\u7edf\u5728\u4e0d\u540c\u97f3\u4e50\u5206\u5e03\u504f\u79fb\uff08\u5982\u6d41\u6d3e\u3001\u52a8\u6001\u3001\u590d\u8c03\uff09\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\uff0c\u53d1\u73b0\u7cfb\u7edf\u6027\u80fd\u663e\u8457\u4e0b\u964d\uff0c\u63ed\u793a\u4e86\u6df1\u5ea6\u5b66\u4e60AMT\u7cfb\u7edf\u5b58\u5728\u7684\u8bed\u6599\u5e93\u504f\u5dee\u95ee\u9898\u3002", "motivation": "\u5f53\u524d\u81ea\u52a8\u97f3\u4e50\u8f6c\u5f55\u7814\u7a76\u4e3b\u8981\u96c6\u4e2d\u4e8e\u53e4\u5178\u94a2\u7434\u97f3\u4e50\u548c\u7279\u5b9a\u6570\u636e\u96c6\uff0c\u7cfb\u7edf\u5728\u5176\u4ed6\u97f3\u4e50\u4e0a\u4e0b\u6587\u4e2d\u7684\u6cdb\u5316\u80fd\u529b\u5c1a\u4e0d\u660e\u786e\u3002\u7814\u7a76\u65e8\u5728\u63a2\u7a76\u97f3\u4e50\u7ef4\u5ea6\uff08\u6d41\u6d3e\u3001\u52a8\u6001\u3001\u590d\u8c03\u6c34\u5e73\uff09\u7684\u5206\u5e03\u504f\u79fb\u5bf9AMT\u7cfb\u7edf\u6027\u80fd\u7684\u5f71\u54cd\u3002", "method": "\u6784\u5efaMDS\u8bed\u6599\u5e93\uff0c\u5305\u542b\u4e09\u4e2a\u5b50\u96c6\uff1aGenre\uff08\u6d41\u6d3e\uff09\u3001Random\uff08\u968f\u673a\uff09\u548cMAEtest\uff0c\u6a21\u62df\u4e0d\u540c\u5206\u5e03\u504f\u79fb\u8f74\u3002\u4f7f\u7528\u4f20\u7edf\u4fe1\u606f\u68c0\u7d22\u548c\u97f3\u4e50\u611f\u77e5\u6027\u80fd\u6307\u6807\u8bc4\u4f30\u591a\u4e2a\u6700\u5148\u8fdb\u7684AMT\u7cfb\u7edf\u3002", "result": "\u7814\u7a76\u53d1\u73b0\u7cfb\u7edf\u6027\u80fd\u5728\u4e0d\u540c\u5206\u5e03\u504f\u79fb\u4e0b\u51fa\u73b0\u4e0d\u540c\u7a0b\u5ea6\u4e0b\u964d\uff1a\u58f0\u97f3\u56e0\u7d20\u5bfc\u81f4\u97f3\u7b26\u7ea7F1\u6027\u80fd\u4e0b\u964d20\u4e2a\u767e\u5206\u70b9\uff0c\u6d41\u6d3e\u56e0\u7d20\u5bfc\u81f4\u4e0b\u964d14\u4e2a\u767e\u5206\u70b9\u3002\u52a8\u6001\u4f30\u8ba1\u6bd4\u8d77\u59cb\u70b9\u9884\u6d4b\u66f4\u5bb9\u6613\u53d7\u97f3\u4e50\u53d8\u5316\u5f71\u54cd\u3002\u968f\u673a\u751f\u6210\u7684\u975e\u97f3\u4e50\u5e8f\u5217\u5b9e\u9a8c\u663e\u793a\u7cfb\u7edf\u5728\u6781\u7aef\u97f3\u4e50\u5206\u5e03\u504f\u79fb\u4e0b\u5b58\u5728\u660e\u663e\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u8bc1\u5b9e\u4e86\u6df1\u5ea6\u5b66\u4e60AMT\u7cfb\u7edf\u4e2d\u6301\u7eed\u5b58\u5728\u7684\u8bed\u6599\u5e93\u504f\u5dee\u95ee\u9898\uff0c\u97f3\u4e50\u611f\u77e5\u8bc4\u4f30\u6307\u6807\uff08\u7279\u522b\u662f\u6355\u6349\u548c\u58f0\u7ed3\u6784\u7684\u6307\u6807\uff09\u6709\u52a9\u4e8e\u8bc6\u522b\u6f5c\u5728\u5f71\u54cd\u56e0\u7d20\uff0c\u4e3a\u672a\u6765AMT\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u6539\u8fdb\u63d0\u4f9b\u4e86\u65b0\u8bc1\u636e\u3002"}}
{"id": "2512.14652", "categories": ["eess.AS", "cs.CL"], "pdf": "https://arxiv.org/pdf/2512.14652", "abs": "https://arxiv.org/abs/2512.14652", "authors": ["Pawel Swietojanski", "Xinwei Li", "Mingbin Xu", "Takaaki Hori", "Dogan Can", "Xiaodan Zhuang"], "title": "Segmental Attention Decoding With Long Form Acoustic Encodings", "comment": "5 pages, 1 fig", "summary": "We address the fundamental incompatibility of attention-based encoder-decoder (AED) models with long-form acoustic encodings. AED models trained on segmented utterances learn to encode absolute frame positions by exploiting limited acoustic context beyond segment boundaries, but fail to generalize when decoding long-form segments where these cues vanish. The model loses ability to order acoustic encodings due to permutation invariance of keys and values in cross-attention. We propose four modifications: (1) injecting explicit absolute positional encodings into cross-attention for each decoded segment, (2) long-form training with extended acoustic context to eliminate implicit absolute position encoding, (3) segment concatenation to cover diverse segmentations needed during training, and (4) semantic segmentation to align AED-decoded segments with training segments. We show these modifications close the accuracy gap between continuous and segmented acoustic encodings, enabling auto-regressive use of the attention decoder.", "AI": {"tldr": "\u8bba\u6587\u89e3\u51b3\u4e86\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\u4e0e\u957f\u97f3\u9891\u7f16\u7801\u4e0d\u517c\u5bb9\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u56db\u79cd\u6539\u8fdb\u65b9\u6cd5\u6d88\u9664\u4e86\u5206\u6bb5\u8bad\u7ec3\u5bfc\u81f4\u7684\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\u4f9d\u8d56\uff0c\u4f7f\u6a21\u578b\u80fd\u5904\u7406\u957f\u97f3\u9891\u8f93\u5165\u3002", "motivation": "\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u7f16\u7801\u5668-\u89e3\u7801\u5668\u6a21\u578b\u5728\u5206\u6bb5\u8bad\u7ec3\u65f6\u5b66\u4f1a\u4e86\u5229\u7528\u6709\u9650\u97f3\u9891\u4e0a\u4e0b\u6587\u7f16\u7801\u7edd\u5bf9\u5e27\u4f4d\u7f6e\uff0c\u4f46\u5728\u5904\u7406\u957f\u97f3\u9891\u65f6\u8fd9\u4e9b\u7ebf\u7d22\u6d88\u5931\uff0c\u5bfc\u81f4\u6a21\u578b\u65e0\u6cd5\u6b63\u786e\u6392\u5e8f\u97f3\u9891\u7f16\u7801\uff0c\u56e0\u4e3a\u4ea4\u53c9\u6ce8\u610f\u529b\u4e2d\u7684\u952e\u503c\u5177\u6709\u7f6e\u6362\u4e0d\u53d8\u6027\u3002", "method": "\u63d0\u51fa\u56db\u79cd\u6539\u8fdb\uff1a1) \u5728\u6bcf\u4e2a\u89e3\u7801\u6bb5\u4e2d\u5411\u4ea4\u53c9\u6ce8\u610f\u529b\u6ce8\u5165\u663e\u5f0f\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff1b2) \u4f7f\u7528\u6269\u5c55\u97f3\u9891\u4e0a\u4e0b\u6587\u8fdb\u884c\u957f\u5f62\u5f0f\u8bad\u7ec3\u4ee5\u6d88\u9664\u9690\u5f0f\u7edd\u5bf9\u4f4d\u7f6e\u7f16\u7801\uff1b3) \u6bb5\u8fde\u63a5\u4ee5\u8986\u76d6\u8bad\u7ec3\u6240\u9700\u7684\u5404\u79cd\u5206\u6bb5\uff1b4) \u8bed\u4e49\u5206\u6bb5\u4f7fAED\u89e3\u7801\u6bb5\u4e0e\u8bad\u7ec3\u6bb5\u5bf9\u9f50\u3002", "result": "\u8fd9\u4e9b\u6539\u8fdb\u6d88\u9664\u4e86\u8fde\u7eed\u97f3\u9891\u7f16\u7801\u548c\u5206\u6bb5\u97f3\u9891\u7f16\u7801\u4e4b\u95f4\u7684\u51c6\u786e\u5ea6\u5dee\u8ddd\uff0c\u4f7f\u6ce8\u610f\u529b\u89e3\u7801\u5668\u80fd\u591f\u81ea\u56de\u5f52\u5730\u4f7f\u7528\u3002", "conclusion": "\u901a\u8fc7\u663e\u5f0f\u4f4d\u7f6e\u7f16\u7801\u3001\u957f\u5f62\u5f0f\u8bad\u7ec3\u3001\u6bb5\u8fde\u63a5\u548c\u8bed\u4e49\u5206\u6bb5\u56db\u79cd\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86AED\u6a21\u578b\u4e0e\u957f\u97f3\u9891\u7f16\u7801\u4e0d\u517c\u5bb9\u7684\u95ee\u9898\uff0c\u4f7f\u6a21\u578b\u80fd\u591f\u6709\u6548\u5904\u7406\u957f\u97f3\u9891\u8f93\u5165\u3002"}}
{"id": "2512.13870", "categories": ["eess.SP", "cs.LG", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.13870", "abs": "https://arxiv.org/abs/2512.13870", "authors": ["Ricardo Gon\u00e7alves Molinari", "Leonardo Abdala Elias"], "title": "Simultaneous and Proportional Finger Motion Decoding Using Spatial Features from High-Density Surface Electromyography", "comment": "39 pages, 13 figures, 2 tables", "summary": "Restoring natural and intuitive hand function requires simultaneous and proportional control (SPC) of multiple degrees of freedom (DoFs). This study systematically evaluated the multichannel linear descriptors-based block field method (MLD-BFM) for continuous decoding of five finger-joint DoFs by leveraging the rich spatial information of high-density surface electromyography (HD sEMG). Twenty-one healthy participants performed dynamic sinusoidal finger movements while HD sEMG signals were recorded from the \\textit{extensor digitorum communis} (EDC) and \\textit{flexor digitorum superficialis} (FDS) muscles. MLD-BFM extracted region-specific spatial features, including effective field strength ($\u03a3$), field-strength variation rate ($\u03a6$), and spatial complexity ($\u03a9$). Model performance was optimized (block size: $2 \\times 2$; window: 0.15 s) and compared with conventional time-domain features and dimensionality reduction approaches when applied to multi-output regression models. MLD-BFM consistently achieved the highest $\\mathrm{R}^2_{\\mathrm{vw}}$ values across all models. The multilayer perceptron (MLP) combined with MLD-BFM yielded the best performance ($\\mathrm{R}^2_{\\mathrm{vw}} = 86.68\\% \\pm 0.33$). Time-domain features also showed strong predictive capability and were statistically comparable to MLD-BFM in some models, whereas dimensionality reduction techniques exhibited lower accuracy. Decoding accuracy was higher for the middle and ring fingers than for the thumb. Overall, MLD-BFM improved continuous finger movement decoding accuracy, underscoring the importance of taking advantage of the spatial richness of HD sEMG. These findings suggest that spatially structured features enhance SPC and provide practical guidance for designing robust, real-time, and responsive myoelectric interfaces.", "AI": {"tldr": "MLD-BFM\u65b9\u6cd5\u5229\u7528\u9ad8\u5bc6\u5ea6\u8868\u9762\u808c\u7535\u4fe1\u53f7\u7684\u7a7a\u95f4\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u8fde\u7eed\u624b\u6307\u8fd0\u52a8\u89e3\u7801\u7684\u51c6\u786e\u6027\uff0c\u4e3a\u8bbe\u8ba1\u9c81\u68d2\u7684\u5b9e\u65f6\u808c\u7535\u63a5\u53e3\u63d0\u4f9b\u4e86\u6307\u5bfc\u3002", "motivation": "\u6062\u590d\u81ea\u7136\u76f4\u89c2\u7684\u624b\u90e8\u529f\u80fd\u9700\u8981\u540c\u65f6\u6bd4\u4f8b\u63a7\u5236\u591a\u4e2a\u81ea\u7531\u5ea6\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u5229\u7528\u9ad8\u5bc6\u5ea6\u8868\u9762\u808c\u7535\u4fe1\u53f7\u7684\u7a7a\u95f4\u4fe1\u606f\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\u3002", "method": "\u63d0\u51fa\u591a\u901a\u9053\u7ebf\u6027\u63cf\u8ff0\u7b26\u5757\u573a\u65b9\u6cd5\uff08MLD-BFM\uff09\uff0c\u4eceEDC\u548cFDS\u808c\u8089\u8bb0\u5f55HD sEMG\u4fe1\u53f7\uff0c\u63d0\u53d6\u533a\u57df\u7279\u5f02\u6027\u7a7a\u95f4\u7279\u5f81\uff08\u03a3\u3001\u03a6\u3001\u03a9\uff09\uff0c\u5e76\u4e0e\u4f20\u7edf\u65f6\u57df\u7279\u5f81\u548c\u964d\u7ef4\u65b9\u6cd5\u6bd4\u8f83\u3002", "result": "MLD-BFM\u5728\u6240\u6709\u6a21\u578b\u4e2d\u5747\u83b7\u5f97\u6700\u9ad8\u7684R\u00b2_vw\u503c\uff0cMLP+MLD-BFM\u7ec4\u5408\u6027\u80fd\u6700\u4f73\uff0886.68%\u00b10.33\uff09\uff0c\u4e2d\u6307\u548c\u65e0\u540d\u6307\u89e3\u7801\u7cbe\u5ea6\u9ad8\u4e8e\u62c7\u6307\u3002", "conclusion": "MLD-BFM\u63d0\u9ad8\u4e86\u8fde\u7eed\u624b\u6307\u8fd0\u52a8\u89e3\u7801\u7cbe\u5ea6\uff0c\u5f3a\u8c03\u4e86\u5229\u7528HD sEMG\u7a7a\u95f4\u4e30\u5bcc\u6027\u7684\u91cd\u8981\u6027\uff0c\u4e3a\u8bbe\u8ba1\u9c81\u68d2\u3001\u5b9e\u65f6\u3001\u54cd\u5e94\u6027\u808c\u7535\u63a5\u53e3\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\u3002"}}
{"id": "2512.14629", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.14629", "abs": "https://arxiv.org/abs/2512.14629", "authors": ["Yash Vishe", "Eric Xue", "Xunyi Jiang", "Zachary Novack", "Junda Wu", "Julian McAuley", "Xin Xu"], "title": "MuseCPBench: an Empirical Study of Music Editing Methods through Music Context Preservation", "comment": null, "summary": "Music editing plays a vital role in modern music production, with applications in film, broadcasting, and game development. Recent advances in music generation models have enabled diverse editing tasks such as timbre transfer, instrument substitution, and genre transformation. However, many existing works overlook the evaluation of their ability to preserve musical facets that should remain unchanged during editing a property we define as Music Context Preservation (MCP). While some studies do consider MCP, they adopt inconsistent evaluation protocols and metrics, leading to unreliable and unfair comparisons. To address this gap, we introduce the first MCP evaluation benchmark, MuseCPBench, which covers four categories of musical facets and enables comprehensive comparisons across five representative music editing baselines. Through systematic analysis along musical facets, methods, and models, we identify consistent preservation gaps in current music editing methods and provide insightful explanations. We hope our findings offer practical guidance for developing more effective and reliable music editing strategies with strong MCP capability", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u9996\u4e2a\u97f3\u4e50\u4e0a\u4e0b\u6587\u4fdd\u6301(MCP)\u8bc4\u4f30\u57fa\u51c6MuseCPBench\uff0c\u7528\u4e8e\u7cfb\u7edf\u8bc4\u4f30\u97f3\u4e50\u7f16\u8f91\u65b9\u6cd5\u5728\u4fdd\u6301\u97f3\u4e50\u539f\u59cb\u8981\u7d20\u65b9\u9762\u7684\u80fd\u529b\uff0c\u53d1\u73b0\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u4e00\u81f4\u7684\u4fdd\u6301\u7f3a\u9677\u3002", "motivation": "\u5f53\u524d\u97f3\u4e50\u7f16\u8f91\u7814\u7a76\u5ffd\u89c6\u4e86\u8bc4\u4f30\u7f16\u8f91\u8fc7\u7a0b\u4e2d\u5e94\u4fdd\u6301\u4e0d\u53d8\u7684\u97f3\u4e50\u8981\u7d20\u4fdd\u6301\u80fd\u529b(MCP)\uff0c\u4e14\u73b0\u6709\u8bc4\u4f30\u534f\u8bae\u548c\u6307\u6807\u4e0d\u4e00\u81f4\uff0c\u5bfc\u81f4\u4e0d\u53ef\u9760\u548c\u4e0d\u516c\u5e73\u7684\u6bd4\u8f83\u3002", "method": "\u5f15\u5165\u9996\u4e2aMCP\u8bc4\u4f30\u57fa\u51c6MuseCPBench\uff0c\u6db5\u76d6\u56db\u7c7b\u97f3\u4e50\u8981\u7d20\uff0c\u5bf9\u4e94\u79cd\u4ee3\u8868\u6027\u97f3\u4e50\u7f16\u8f91\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u7cfb\u7edf\u5206\u6790\uff0c\u4ece\u97f3\u4e50\u8981\u7d20\u3001\u65b9\u6cd5\u548c\u6a21\u578b\u4e09\u4e2a\u7ef4\u5ea6\u8fdb\u884c\u8bc4\u4f30\u3002", "result": "\u901a\u8fc7\u7cfb\u7edf\u5206\u6790\u53d1\u73b0\u5f53\u524d\u97f3\u4e50\u7f16\u8f91\u65b9\u6cd5\u5b58\u5728\u4e00\u81f4\u7684\u4fdd\u6301\u7f3a\u9677\uff0c\u5e76\u63d0\u4f9b\u4e86\u6df1\u5165\u7684\u89e3\u91ca\uff0c\u63ed\u793a\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u97f3\u4e50\u4e0a\u4e0b\u6587\u4fdd\u6301\u65b9\u9762\u7684\u5c40\u9650\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u5f00\u53d1\u5177\u6709\u66f4\u5f3aMCP\u80fd\u529b\u7684\u6709\u6548\u53ef\u9760\u97f3\u4e50\u7f16\u8f91\u7b56\u7565\u63d0\u4f9b\u4e86\u5b9e\u7528\u6307\u5bfc\uff0c\u586b\u8865\u4e86\u97f3\u4e50\u7f16\u8f91\u8bc4\u4f30\u9886\u57df\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.13941", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.13941", "abs": "https://arxiv.org/abs/2512.13941", "authors": ["Abdelhamid Salem", "Kai-Kit Wong", "Hyundong Shin", "Yangyang Zhang"], "title": "Fundamental Limits of Localization with Fluid Antenna Systems: A Fisher Information Analysis", "comment": null, "summary": "In this letter, we investigate the fundamental limits of localization in fluid antenna systems (FAS) utilizing a Fisher-information-theoretic framework. We develop a unified model to quantify the localization information extractable from time-of-arrival (ToA) and angle-of-arrival (AoA) measurements, explicitly capturing the synthetic aperture effects induced by FAS. Closed-form expressions are derived for the equivalent Fisher information matrix (EFIM) and the corresponding positioning error bound (PEB) in both user-side and base-station (BS)-side FAS configurations. Also, we propose optimal port-selection strategies based on greedy algorithms and convex relaxation to maximize the information gain under a constrained number of activated ports. Numerical results demonstrate that the proposed port-selection schemes can substantially tighten the PEB compared with random activation, thereby confirming the strong potential of FAS to enable high-precision localization. These results offer analytical insights and practical design guidelines for FAS-aided positioning in future-generation wireless networks", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf(FAS)\u4e2d\u5b9a\u4f4d\u7684\u57fa\u672c\u6781\u9650\uff0c\u4f7f\u7528\u8d39\u96ea\u4fe1\u606f\u7406\u8bba\u6846\u67b6\uff0c\u63a8\u5bfc\u4e86\u65f6\u5ef6\u548c\u89d2\u5ea6\u6d4b\u91cf\u7684\u5b9a\u4f4d\u4fe1\u606f\u754c\u9650\uff0c\u5e76\u63d0\u51fa\u4e86\u6700\u4f18\u7aef\u53e3\u9009\u62e9\u7b56\u7565\u6765\u63d0\u5347\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "motivation": "\u7814\u7a76\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf(FAS)\u5728\u5b9a\u4f4d\u5e94\u7528\u4e2d\u7684\u57fa\u672c\u6027\u80fd\u6781\u9650\uff0c\u4e3a\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u63d0\u4f9b\u7406\u8bba\u57fa\u7840\u548c\u8bbe\u8ba1\u6307\u5bfc\u3002", "method": "\u91c7\u7528\u8d39\u96ea\u4fe1\u606f\u7406\u8bba\u6846\u67b6\uff0c\u5efa\u7acb\u7edf\u4e00\u6a21\u578b\u91cf\u5316\u65f6\u5ef6(ToA)\u548c\u89d2\u5ea6(AoA)\u6d4b\u91cf\u7684\u5b9a\u4f4d\u4fe1\u606f\uff0c\u63a8\u5bfc\u7b49\u6548\u8d39\u96ea\u4fe1\u606f\u77e9\u9635(EFIM)\u548c\u5b9a\u4f4d\u8bef\u5dee\u754c(PEB)\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u63d0\u51fa\u57fa\u4e8e\u8d2a\u5fc3\u7b97\u6cd5\u548c\u51f8\u677e\u5f1b\u7684\u6700\u4f18\u7aef\u53e3\u9009\u62e9\u7b56\u7565\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u7aef\u53e3\u9009\u62e9\u65b9\u6848\u76f8\u6bd4\u968f\u673a\u6fc0\u6d3b\u80fd\u663e\u8457\u6536\u7d27\u5b9a\u4f4d\u8bef\u5dee\u754c(PEB)\uff0c\u8bc1\u5b9e\u4e86FAS\u5728\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u65b9\u9762\u7684\u5f3a\u5927\u6f5c\u529b\u3002", "conclusion": "FAS\u80fd\u591f\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\uff0c\u7814\u7a76\u7ed3\u679c\u4e3a\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u4e2dFAS\u8f85\u52a9\u7684\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u7406\u8bba\u5206\u6790\u548c\u5b9e\u9645\u8bbe\u8ba1\u6307\u5bfc\u3002"}}
{"id": "2512.14653", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.14653", "abs": "https://arxiv.org/abs/2512.14653", "authors": ["Yiwen Zhao", "Jiatong Shi", "Yuxun Tang", "William Chen", "Shinji Watanabe"], "title": "Robust Training of Singing Voice Synthesis Using Prior and Posterior Uncertainty", "comment": "Accepted by ASRU 2025", "summary": "Singing voice synthesis (SVS) has seen remarkable advancements in recent years. However, compared to speech and general audio data, publicly available singing datasets remain limited. In practice, this data scarcity often leads to performance degradation in long-tail scenarios, such as imbalanced pitch distributions or rare singing styles. To mitigate these challenges, we propose uncertainty-based optimization to improve the training process of end-to-end SVS models. First, we introduce differentiable data augmentation in the adversarial training, which operates in a sample-wise manner to increase the prior uncertainty. Second, we incorporate a frame-level uncertainty prediction module that estimates the posterior uncertainty, enabling the model to allocate more learning capacity to low-confidence segments. Empirical results on the Opencpop and Ofuton-P, across Chinese and Japanese, demonstrate that our approach improves performance in various perspectives.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u4f18\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5fae\u5206\u6570\u636e\u589e\u5f3a\u548c\u5e27\u7ea7\u4e0d\u786e\u5b9a\u6027\u9884\u6d4b\u6a21\u5757\uff0c\u6539\u5584\u7aef\u5230\u7aef\u6b4c\u58f0\u5408\u6210\u6a21\u578b\u5728\u6570\u636e\u7a00\u7f3a\u573a\u666f\u4e0b\u7684\u6027\u80fd", "motivation": "\u516c\u5f00\u53ef\u7528\u7684\u6b4c\u58f0\u6570\u636e\u96c6\u6709\u9650\uff0c\u5bfc\u81f4\u5728\u957f\u5c3e\u573a\u666f\uff08\u5982\u4e0d\u5e73\u8861\u97f3\u9ad8\u5206\u5e03\u6216\u7f55\u89c1\u6f14\u5531\u98ce\u683c\uff09\u4e2d\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u89e3\u51b3\u6570\u636e\u7a00\u7f3a\u95ee\u9898", "method": "1. \u5728\u5bf9\u6297\u8bad\u7ec3\u4e2d\u5f15\u5165\u53ef\u5fae\u5206\u6570\u636e\u589e\u5f3a\uff0c\u4ee5\u6837\u672c\u65b9\u5f0f\u589e\u52a0\u5148\u9a8c\u4e0d\u786e\u5b9a\u6027\uff1b2. \u52a0\u5165\u5e27\u7ea7\u4e0d\u786e\u5b9a\u6027\u9884\u6d4b\u6a21\u5757\uff0c\u4f30\u8ba1\u540e\u9a8c\u4e0d\u786e\u5b9a\u6027\uff0c\u4f7f\u6a21\u578b\u80fd\u4e3a\u4f4e\u7f6e\u4fe1\u5ea6\u7247\u6bb5\u5206\u914d\u66f4\u591a\u5b66\u4e60\u80fd\u529b", "result": "\u5728Opencpop\u548cOfuton-P\u6570\u636e\u96c6\uff08\u4e2d\u6587\u548c\u65e5\u6587\uff09\u4e0a\u7684\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u591a\u4e2a\u65b9\u9762\u63d0\u5347\u4e86\u6027\u80fd", "conclusion": "\u57fa\u4e8e\u4e0d\u786e\u5b9a\u6027\u7684\u4f18\u5316\u65b9\u6cd5\u80fd\u6709\u6548\u7f13\u89e3\u6b4c\u58f0\u5408\u6210\u4e2d\u7684\u6570\u636e\u7a00\u7f3a\u95ee\u9898\uff0c\u63d0\u5347\u6a21\u578b\u5728\u957f\u5c3e\u573a\u666f\u4e0b\u7684\u8868\u73b0"}}
{"id": "2512.14013", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.14013", "abs": "https://arxiv.org/abs/2512.14013", "authors": ["Nadia Abdolkhani", "Walaa Hamouda"], "title": "Hierarchical Deep Reinforcement Learning for Robust Access in Cognitive IoT Networks under Smart Jamming Attacks", "comment": "Accepted at IEEE Global Communications Conference (GlobeCom 2025). This is the authors' accepted manuscript version", "summary": "In this paper, we address the challenge of dynamic spectrum access in a cognitive Internet of Things (CIoT) network where a secondary user (SU) operates under both energy constraints and adversarial interference from a smart jammer. The SU coexists with primary users (PUs) and must ensure that its transmissions do not exceed a predefined interference threshold on licensed channels. At each time slot, the SU must jointly determine whether to transmit or harvest energy, which channel to access, and the appropriate transmit power while satisfying energy and interference constraints. Meanwhile, a smart jammer actively selects a channel to disrupt, aiming to degrade the SU's communication performance. This setting presents a significant challenge due to its multi-level decision structure and hybrid action space, which combines both discrete and continuous decisions. To tackle this, we propose a novel Hierarchical Deep Deterministic Policy Gradient (H-DDPG) framework that decomposes the decision-making process into three levels: the high-level policy determines the mode (transmit or harvest), the mid-level policy selects the channel, and the low-level actor outputs a continuous power level. Concurrently, the jammer is modeled as a reinforcement learning agent that learns an adaptive channel jamming strategy using a discrete variant of DDPG. Simulation results show that our H-DDPG approach outperforms conventional flat reinforcement learning baselines.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08H-DDPG\uff09\u6846\u67b6\uff0c\u89e3\u51b3\u8ba4\u77e5\u7269\u8054\u7f51\u7f51\u7edc\u4e2d\u6b21\u7ea7\u7528\u6237\u5728\u80fd\u91cf\u7ea6\u675f\u548c\u667a\u80fd\u5e72\u6270\u4e0b\u7684\u52a8\u6001\u9891\u8c31\u63a5\u5165\u95ee\u9898\uff0c\u901a\u8fc7\u4e09\u5c42\u51b3\u7b56\u7ed3\u6784\u4f18\u5316\u4f20\u8f93/\u80fd\u91cf\u6536\u96c6\u3001\u4fe1\u9053\u9009\u62e9\u548c\u529f\u7387\u63a7\u5236\u3002", "motivation": "\u8ba4\u77e5\u7269\u8054\u7f51\u7f51\u7edc\u4e2d\uff0c\u6b21\u7ea7\u7528\u6237\u9762\u4e34\u80fd\u91cf\u7ea6\u675f\u548c\u667a\u80fd\u5e72\u6270\u5668\u7684\u5bf9\u6297\u6027\u5e72\u6270\uff0c\u9700\u8981\u5728\u6ee1\u8db3\u4e3b\u7528\u6237\u5e72\u6270\u9608\u503c\u7684\u524d\u63d0\u4e0b\uff0c\u540c\u65f6\u51b3\u7b56\u4f20\u8f93/\u80fd\u91cf\u6536\u96c6\u3001\u4fe1\u9053\u9009\u62e9\u548c\u529f\u7387\u63a7\u5236\uff0c\u8fd9\u79cd\u591a\u5c42\u7ea7\u51b3\u7b56\u7ed3\u6784\u548c\u6df7\u5408\u52a8\u4f5c\u7a7a\u95f4\u5e26\u6765\u4e86\u663e\u8457\u6311\u6218\u3002", "method": "\u63d0\u51fa\u5206\u5c42\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08H-DDPG\uff09\u6846\u67b6\uff0c\u5c06\u51b3\u7b56\u8fc7\u7a0b\u5206\u89e3\u4e3a\u4e09\u5c42\uff1a\u9ad8\u5c42\u7b56\u7565\u51b3\u5b9a\u4f20\u8f93\u6216\u80fd\u91cf\u6536\u96c6\u6a21\u5f0f\uff0c\u4e2d\u5c42\u7b56\u7565\u9009\u62e9\u4fe1\u9053\uff0c\u4f4e\u5c42\u6267\u884c\u5668\u8f93\u51fa\u8fde\u7eed\u529f\u7387\u6c34\u5e73\u3002\u5e72\u6270\u5668\u5219\u5efa\u6a21\u4e3a\u4f7f\u7528\u79bb\u6563DDPG\u53d8\u4f53\u5b66\u4e60\u81ea\u9002\u5e94\u4fe1\u9053\u5e72\u6270\u7b56\u7565\u7684\u5f3a\u5316\u5b66\u4e60\u667a\u80fd\u4f53\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684H-DDPG\u65b9\u6cd5\u4f18\u4e8e\u4f20\u7edf\u7684\u6241\u5e73\u5f3a\u5316\u5b66\u4e60\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "H-DDPG\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u8ba4\u77e5\u7269\u8054\u7f51\u7f51\u7edc\u4e2d\u6b21\u7ea7\u7528\u6237\u9762\u4e34\u7684\u590d\u6742\u591a\u5c42\u7ea7\u51b3\u7b56\u95ee\u9898\uff0c\u5728\u80fd\u91cf\u7ea6\u675f\u548c\u667a\u80fd\u5e72\u6270\u73af\u5883\u4e0b\u5b9e\u73b0\u4f18\u5316\u7684\u52a8\u6001\u9891\u8c31\u63a5\u5165\u3002"}}
{"id": "2512.14657", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.14657", "abs": "https://arxiv.org/abs/2512.14657", "authors": ["Yiwen Zhao", "Jiatong Shi", "Jinchuan Tian", "Yuxun Tang", "Jiarui Hai", "Jionghao Han", "Shinji Watanabe"], "title": "Adapting Speech Language Model to Singing Voice Synthesis", "comment": "Accepted by NeurIPS 2025 workshop AI for Music", "summary": "Speech Language Models (SLMs) have recently emerged as a unified paradigm for addressing a wide range of speech-related tasks, including text-to-speech (TTS), speech enhancement (SE), and automatic speech recognition (ASR). However, the generalization capability of large-scale pre-trained SLMs remains underexplored. In this work, we adapt a 1.7B parameter TTS pretrained SLM for singing voice synthesis (SVS), using only a 135-hour synthetic singing corpus, ACE-Opencpop. Building upon the ESPNet-SpeechLM, our recipe involves the following procedure: (1) tokenization of music score conditions and singing waveforms, (2) multi-stream language model token prediction, (3) conditional flow matching-based mel-spectrogram generation. (4) a mel-to-wave vocoder. Experimental results demonstrate that our adapted SLM generalizes well to SVS and achieves performance comparable to leading discrete token-based SVS models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5c06\u9884\u8bad\u7ec3\u76841.7B\u53c2\u6570\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\uff08SLM\uff09\u9002\u914d\u5230\u6b4c\u58f0\u5408\u6210\u4efb\u52a1\uff0c\u4ec5\u4f7f\u7528135\u5c0f\u65f6\u5408\u6210\u6b4c\u58f0\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u4e0e\u4e3b\u6d41\u79bb\u6563token\u6a21\u578b\u76f8\u5f53\u7684\u6027\u80fd\u3002", "motivation": "\u867d\u7136\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\uff08SLMs\uff09\u5df2\u6210\u4e3a\u5904\u7406\u591a\u79cd\u8bed\u97f3\u4efb\u52a1\u7684\u7edf\u4e00\u8303\u5f0f\uff0c\u4f46\u5176\u5728\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u540e\u7684\u6cdb\u5316\u80fd\u529b\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u9884\u8bad\u7ec3SLM\u5728\u6b4c\u58f0\u5408\u6210\uff08SVS\uff09\u4efb\u52a1\u4e0a\u7684\u6cdb\u5316\u80fd\u529b\u3002", "method": "\u57fa\u4e8eESPNet-SpeechLM\uff0c\u91c7\u7528\u56db\u6b65\u6d41\u7a0b\uff1a1\uff09\u4e50\u8c31\u6761\u4ef6\u548c\u6b4c\u58f0\u6ce2\u5f62\u7684token\u5316\uff1b2\uff09\u591a\u6d41\u8bed\u8a00\u6a21\u578btoken\u9884\u6d4b\uff1b3\uff09\u57fa\u4e8e\u6761\u4ef6\u6d41\u5339\u914d\u7684\u6885\u5c14\u9891\u8c31\u751f\u6210\uff1b4\uff09\u6885\u5c14\u5230\u6ce2\u5f62\u7684\u58f0\u7801\u5668\u8f6c\u6362\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u9002\u914d\u540e\u7684SLM\u5728\u6b4c\u58f0\u5408\u6210\u4efb\u52a1\u4e0a\u6cdb\u5316\u826f\u597d\uff0c\u6027\u80fd\u4e0e\u9886\u5148\u7684\u57fa\u4e8e\u79bb\u6563token\u7684SVS\u6a21\u578b\u76f8\u5f53\u3002", "conclusion": "\u9884\u8bad\u7ec3\u7684\u5927\u89c4\u6a21\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u80fd\u591f\u6709\u6548\u6cdb\u5316\u5230\u6b4c\u58f0\u5408\u6210\u4efb\u52a1\uff0c\u4ec5\u9700\u76f8\u5bf9\u5c11\u91cf\u7684\u9886\u57df\u7279\u5b9a\u6570\u636e\u5373\u53ef\u8fbe\u5230\u7ade\u4e89\u6027\u6027\u80fd\uff0c\u8bc1\u660e\u4e86SLM\u7684\u8de8\u4efb\u52a1\u6cdb\u5316\u6f5c\u529b\u3002"}}
{"id": "2512.14029", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.14029", "abs": "https://arxiv.org/abs/2512.14029", "authors": ["Nadia Abdolkhani", "Walaa Hamouda"], "title": "Cooperative Caching Towards Efficient Spectrum Utilization in Cognitive-IoT Networks", "comment": "Published in Proc. IEEE ICC 2025. This is the authors' accepted manuscript version", "summary": "In cognitive Internet of Things (CIoT) networks, efficient spectrum sharing is essential to address increasing wireless demands. This paper presents a novel deep reinforcement learning (DRL)-based approach for joint cooperative caching and spectrum access coordination in CIoT networks, enabling the CIoT agents to collaborate with primary users (PUs) by caching PU content and serving their requests, fostering mutual benefits. The proposed DRL framework jointly optimizes caching policy and spectrum access under challenging conditions. Unlike traditional cognitive radio (CR) methods, where CIoT agents vacate the spectrum for PUs, or relaying techniques, which merely support spectrum sharing, caching brings data closer to the edge, reducing latency by minimizing retrieval distance. Simulations demonstrate that our approach outperforms others in lowering latency, increasing CIoT and PU cache hit rates, and enhancing network throughput. This approach redefines spectrum sharing, offering a fresh perspective on CIoT network design and illustrating the potential of DRL-guided caching to highlight the benefits of collaboration over dynamic spectrum access scenarios, elevating CIoT performance under constrained resources.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u8ba4\u77e5\u7269\u8054\u7f51\u8054\u5408\u534f\u4f5c\u7f13\u5b58\u4e0e\u9891\u8c31\u63a5\u5165\u534f\u8c03\u65b9\u6cd5\uff0c\u901a\u8fc7\u7f13\u5b58\u4e3b\u7528\u6237\u5185\u5bb9\u5b9e\u73b0\u4e92\u5229\u5408\u4f5c\uff0c\u63d0\u5347\u7f51\u7edc\u6027\u80fd", "motivation": "\u8ba4\u77e5\u7269\u8054\u7f51\u7f51\u7edc\u4e2d\u9891\u8c31\u5171\u4eab\u6548\u7387\u5bf9\u6ee1\u8db3\u65e5\u76ca\u589e\u957f\u7684\u65e0\u7ebf\u9700\u6c42\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u8ba4\u77e5\u65e0\u7ebf\u7535\u65b9\u6cd5\u4e2dCIoT\u4ee3\u7406\u9700\u4e3a\u4e3b\u7528\u6237\u817e\u51fa\u9891\u8c31\uff0c\u6216\u4ec5\u652f\u6301\u9891\u8c31\u5171\u4eab\u7684\u4e2d\u7ee7\u6280\u672f\uff0c\u65e0\u6cd5\u5145\u5206\u5229\u7528\u8fb9\u7f18\u8d44\u6e90\u964d\u4f4e\u5ef6\u8fdf", "method": "\u63d0\u51fa\u65b0\u9896\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u8054\u5408\u4f18\u5316\u7f13\u5b58\u7b56\u7565\u548c\u9891\u8c31\u63a5\u5165\u534f\u8c03\u3002CIoT\u4ee3\u7406\u901a\u8fc7\u7f13\u5b58\u4e3b\u7528\u6237\u5185\u5bb9\u5e76\u4e0e\u4e3b\u7528\u6237\u534f\u4f5c\uff0c\u5c06\u6570\u636e\u63a8\u5411\u7f51\u7edc\u8fb9\u7f18\uff0c\u51cf\u5c11\u68c0\u7d22\u8ddd\u79bb", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u964d\u4f4e\u5ef6\u8fdf\u3001\u63d0\u9ad8CIoT\u548c\u4e3b\u7528\u6237\u7f13\u5b58\u547d\u4e2d\u7387\u3001\u589e\u5f3a\u7f51\u7edc\u541e\u5410\u91cf\u65b9\u9762\u4f18\u4e8e\u5176\u4ed6\u65b9\u6cd5", "conclusion": "\u8be5\u65b9\u6cd5\u91cd\u65b0\u5b9a\u4e49\u4e86\u9891\u8c31\u5171\u4eab\u8303\u5f0f\uff0c\u4e3aCIoT\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u89c6\u89d2\uff0c\u5c55\u793a\u4e86DRL\u5f15\u5bfc\u7684\u7f13\u5b58\u5728\u52a8\u6001\u9891\u8c31\u63a5\u5165\u573a\u666f\u4e2d\u7684\u534f\u4f5c\u4f18\u52bf\uff0c\u63d0\u5347\u4e86\u8d44\u6e90\u53d7\u9650\u6761\u4ef6\u4e0b\u7684CIoT\u6027\u80fd"}}
{"id": "2512.14037", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14037", "abs": "https://arxiv.org/abs/2512.14037", "authors": ["Qiaoyan Peng", "Qingqing Wu", "Guangji Chen", "Wen Chen", "Shanpu Shen", "Shaodan Ma"], "title": "Cooperative Rotatable IRSs for Wireless Communications: Joint Beamforming and Orientation Optimization", "comment": null, "summary": "Rotatable intelligent reflecting surfaces (IRSs) introduce a new degree of freedom (DoF) for shaping wireless propagation by adaptively adjusting the orientation of IRSs. This paper considers an angle-dependent reflection model in a wireless communication system aided by two rotatable IRSs. Specifically, we study the joint design of the base station transmit beamforming, as well as the cooperative passive beamforming and orientation of the two IRSs, to maximize the received signal-to-noise ratio (SNR). Under the light-of-sight (LoS) channels, we first develop a particle swarm optimization (PSO) based method to determine the IRS rotation and derive an optimal rotation in a closed-form expression for a two-dimensional IRS deployment. Then, we extend the design to the general Rician fading channels by proposing an efficient alternating optimization and PSO (AO-PSO) algorithm. Numerical results validate the substantial gains achieved by the IRS rotation over fixed-IRS schemes and also demonstrate the superior performance of the double rotatable IRSs over a single rotatable IRS given a sufficient total number of IRS elements.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u4e86\u53cc\u53ef\u65cb\u8f6c\u667a\u80fd\u53cd\u5c04\u9762\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u57fa\u7ad9\u6ce2\u675f\u6210\u5f62\u3001IRS\u88ab\u52a8\u6ce2\u675f\u6210\u5f62\u548c\u65cb\u8f6c\u89d2\u5ea6\uff0c\u6700\u5927\u5316\u63a5\u6536\u4fe1\u566a\u6bd4\uff0c\u76f8\u6bd4\u56fa\u5b9aIRS\u65b9\u6848\u83b7\u5f97\u663e\u8457\u6027\u80fd\u589e\u76ca\u3002", "motivation": "\u4f20\u7edf\u56fa\u5b9aIRS\u65b9\u6848\u9650\u5236\u4e86\u65e0\u7ebf\u4f20\u64ad\u7684\u8c03\u63a7\u81ea\u7531\u5ea6\uff0c\u53ef\u65cb\u8f6cIRS\u901a\u8fc7\u81ea\u9002\u5e94\u8c03\u6574\u65b9\u5411\u5f15\u5165\u65b0\u7684\u81ea\u7531\u5ea6\uff0c\u80fd\u591f\u66f4\u597d\u5730\u5851\u9020\u65e0\u7ebf\u4fe1\u9053\uff0c\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u5728\u89c6\u8ddd\u4fe1\u9053\u4e0b\uff0c\u63d0\u51fa\u57fa\u4e8e\u7c92\u5b50\u7fa4\u4f18\u5316\u7684IRS\u65cb\u8f6c\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u63a8\u5bfc\u51fa\u4e8c\u7ef4\u90e8\u7f72\u4e0b\u7684\u95ed\u5f0f\u6700\u4f18\u65cb\u8f6c\u89e3\uff1b\u5728\u4e00\u822c\u83b1\u65af\u8870\u843d\u4fe1\u9053\u4e0b\uff0c\u63d0\u51fa\u9ad8\u6548\u7684\u4ea4\u66ff\u4f18\u5316\u548c\u7c92\u5b50\u7fa4\u4f18\u5316\u6df7\u5408\u7b97\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u53ef\u65cb\u8f6cIRS\u76f8\u6bd4\u56fa\u5b9aIRS\u65b9\u6848\u83b7\u5f97\u663e\u8457\u6027\u80fd\u589e\u76ca\uff0c\u4e14\u5f53IRS\u603b\u5355\u5143\u6570\u8db3\u591f\u65f6\uff0c\u53cc\u53ef\u65cb\u8f6cIRS\u4f18\u4e8e\u5355\u53ef\u65cb\u8f6cIRS\u3002", "conclusion": "\u53ef\u65cb\u8f6cIRS\u4e3a\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u7684\u8c03\u63a7\u7ef4\u5ea6\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u65cb\u8f6c\u89d2\u5ea6\u548c\u6ce2\u675f\u6210\u5f62\u80fd\u591f\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u591aIRS\u534f\u4f5c\u573a\u666f\u4e0b\u4f18\u52bf\u66f4\u660e\u663e\u3002"}}
{"id": "2512.14116", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14116", "abs": "https://arxiv.org/abs/2512.14116", "authors": ["Ruohai Yang", "Shuangyang Li", "Han Yu", "Zhiqiang Wei", "Kai Wan", "Giuseppe Caire"], "title": "Hybrid Iterative Detection for OTFS: Interplay between Local L-MMSE and Global Message Passing", "comment": null, "summary": "Orthogonal time frequency space (OTFS) modulation has emerged as a robust solution for high-mobility wireless communications. However, conventional detection algorithms, such as linear equalizers and message passing (MP) methods, either suffer from noise enhancement or fail under complex doubly-selective channels, especially in the presence of fractional delay and Doppler shifts. In this paper, we propose a hybrid low-complexity iterative detection framework that combines linear minimum mean square error (L-MMSE) estimation with MP-based probabilistic inference. The key idea is to apply a new delay-Doppler (DD) commutation precoder (DDCP) to the DD domain signal vector, such that the resulting effective channel matrix exhibits a structured form with several locally dense blocks that are sparsely inter-connected. This precoding structure enables a hybrid iterative detection strategy, where a low-dimensional L-MMSE estimation is applied to the dense blocks, while MP is utilized to exploit the sparse inter-block connections. Furthermore, we provide a detailed complexity analysis, which shows that the proposed scheme incurs lower computational cost compared to the full-size L-MMSE detection. The simulation results of convergence performance confirm that the proposed hybrid MP detection achieves fast and reliable convergence with controlled complexity. In terms of error performance, simulation results demonstrate that our scheme achieves significantly better bit error rate (BER) under various channel conditions. Particularly in multipath scenarios, the BER performance of the proposed method closely approaches the matched filter bound (MFB), indicating its near-optimal error performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408L-MMSE\u548c\u6d88\u606f\u4f20\u9012\u7684\u6df7\u5408\u4f4e\u590d\u6742\u5ea6OTFS\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7DD\u57df\u9884\u7f16\u7801\u4f7f\u4fe1\u9053\u77e9\u9635\u5448\u73b0\u5c40\u90e8\u7a20\u5bc6\u5757\u7a00\u758f\u8fde\u63a5\u7ed3\u6784\uff0c\u5b9e\u73b0\u5feb\u901f\u6536\u655b\u548c\u8fd1\u6700\u4f18\u8bef\u7801\u6027\u80fd\u3002", "motivation": "\u4f20\u7edfOTFS\u68c0\u6d4b\u7b97\u6cd5\uff08\u7ebf\u6027\u5747\u8861\u5668\u548c\u6d88\u606f\u4f20\u9012\u65b9\u6cd5\uff09\u5728\u9ad8\u79fb\u52a8\u6027\u65e0\u7ebf\u901a\u4fe1\u4e2d\u9762\u4e34\u6311\u6218\uff1a\u7ebf\u6027\u5747\u8861\u5668\u5b58\u5728\u566a\u58f0\u589e\u5f3a\u95ee\u9898\uff0c\u800c\u6d88\u606f\u4f20\u9012\u65b9\u6cd5\u5728\u590d\u6742\u7684\u53cc\u9009\u62e9\u6027\u4fe1\u9053\uff08\u7279\u522b\u662f\u5b58\u5728\u5206\u6570\u5ef6\u8fdf\u548c\u591a\u666e\u52d2\u9891\u79fb\u65f6\uff09\u5bb9\u6613\u5931\u6548\u3002", "method": "\u63d0\u51fa\u6df7\u5408\u4f4e\u590d\u6742\u5ea6\u8fed\u4ee3\u68c0\u6d4b\u6846\u67b6\uff1a1\uff09\u91c7\u7528\u65b0\u7684\u5ef6\u8fdf-\u591a\u666e\u52d2\u57df\u9884\u7f16\u7801\u5668\uff08DDCP\uff09\uff0c\u4f7f\u6709\u6548\u4fe1\u9053\u77e9\u9635\u5448\u73b0\u5c40\u90e8\u7a20\u5bc6\u5757\u7a00\u758f\u8fde\u63a5\u7684\u7ed3\u6784\uff1b2\uff09\u7ed3\u5408L-MMSE\u4f30\u8ba1\u548c\u6d88\u606f\u4f20\u9012\u7684\u6df7\u5408\u7b56\u7565\uff0c\u5bf9\u7a20\u5bc6\u5757\u5e94\u7528\u4f4e\u7ef4L-MMSE\u4f30\u8ba1\uff0c\u5229\u7528\u6d88\u606f\u4f20\u9012\u5904\u7406\u7a00\u758f\u5757\u95f4\u8fde\u63a5\u3002", "result": "1\uff09\u590d\u6742\u5ea6\u5206\u6790\u663e\u793a\u6bd4\u5168\u5c3a\u5bf8L-MMSE\u68c0\u6d4b\u8ba1\u7b97\u6210\u672c\u66f4\u4f4e\uff1b2\uff09\u6536\u655b\u6027\u80fd\u4eff\u771f\u8868\u660e\u6df7\u5408\u6d88\u606f\u4f20\u9012\u68c0\u6d4b\u5b9e\u73b0\u5feb\u901f\u53ef\u9760\u6536\u655b\uff1b3\uff09\u8bef\u7801\u6027\u80fd\u5728\u5404\u79cd\u4fe1\u9053\u6761\u4ef6\u4e0b\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5728\u591a\u5f84\u573a\u666f\u4e0b\u63a5\u8fd1\u5339\u914d\u6ee4\u6ce2\u5668\u754c\uff08MFB\uff09\uff0c\u8868\u73b0\u8fd1\u6700\u4f18\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u68c0\u6d4b\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86OTFS\u7cfb\u7edf\u4e2d\u4f20\u7edf\u68c0\u6d4b\u65b9\u6cd5\u7684\u5c40\u9650\u6027\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u9884\u7f16\u7801\u7ed3\u6784\u548c\u6df7\u5408\u68c0\u6d4b\u7b56\u7565\uff0c\u5728\u63a7\u5236\u590d\u6742\u5ea6\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u5feb\u901f\u6536\u655b\u548c\u8fd1\u6700\u4f18\u8bef\u7801\u6027\u80fd\uff0c\u4e3a\u9ad8\u79fb\u52a8\u6027\u65e0\u7ebf\u901a\u4fe1\u63d0\u4f9b\u4e86\u9c81\u68d2\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.14135", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14135", "abs": "https://arxiv.org/abs/2512.14135", "authors": ["Yijun Chen", "Shanpu Shen", "Tianrui Qiao", "Hongyu Li", "Jun Qian", "Ross Murch"], "title": "Antenna Coding Optimization Based on Pixel Antennas for MIMO Wireless Power Transfer with DC Combining", "comment": null, "summary": "This paper investigates antenna coding based on pixel antennas as a new degree of freedom for enhancing multiple-input multiple-output (MIMO) wireless power transfer (WPT) systems. Antenna coding is closely related to the Fluid Antenna System (FAS) concept and further generalizes the radiation pattern reconfigurability. We first introduce a beamspace channel model to demonstrate reconfigurable radiation patterns enabled by antenna coders. By jointly optimizing the antenna coding and transmit beamforming with perfect channel state information (CSI), we exploit gains from antenna coding, transmit beamforming, and rectenna nonlinearity to maximize the output DC power. We adopt an alternating optimization approach with the quasi-Newton method and Successive Exhaustive Boolean Optimization (SEBO) method with warm-start to handle the transmit beamforming design and antenna coding design respectively. Finally, simulation results show that the proposed MIMO WPT system with pixel antennas achieves up to 15 dB gain in average output DC power compared with a conventional system with fixed antenna configuration, highlighting the potential of pixel antennas for boosting the WPT efficiency.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u57fa\u4e8e\u50cf\u7d20\u5929\u7ebf\u7684\u5929\u7ebf\u7f16\u7801\u6280\u672f\uff0c\u5c06\u5176\u4f5c\u4e3a\u589e\u5f3aMIMO\u65e0\u7ebf\u529f\u7387\u4f20\u8f93\u7cfb\u7edf\u7684\u65b0\u81ea\u7531\u5ea6\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5929\u7ebf\u7f16\u7801\u548c\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\uff0c\u5b9e\u73b0\u4e86\u6bd4\u4f20\u7edf\u56fa\u5b9a\u5929\u7ebf\u914d\u7f6e\u9ad8\u8fbe15dB\u7684DC\u8f93\u51fa\u529f\u7387\u589e\u76ca\u3002", "motivation": "\u4f20\u7edfMIMO\u65e0\u7ebf\u529f\u7387\u4f20\u8f93\u7cfb\u7edf\u4f7f\u7528\u56fa\u5b9a\u5929\u7ebf\u914d\u7f6e\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u5929\u7ebf\u7f16\u7801\u4f5c\u4e3a\u65b0\u81ea\u7531\u5ea6\uff0c\u901a\u8fc7\u50cf\u7d20\u5929\u7ebf\u5b9e\u73b0\u8f90\u5c04\u6a21\u5f0f\u53ef\u91cd\u6784\uff0c\u4ece\u800c\u63d0\u5347\u65e0\u7ebf\u529f\u7387\u4f20\u8f93\u6548\u7387\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u50cf\u7d20\u5929\u7ebf\u7684\u5929\u7ebf\u7f16\u7801\u6280\u672f\uff0c\u5efa\u7acb\u6ce2\u675f\u7a7a\u95f4\u4fe1\u9053\u6a21\u578b\u3002\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u65b9\u6cd5\uff1a\u4f7f\u7528\u62df\u725b\u987f\u6cd5\u4f18\u5316\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\uff0c\u4f7f\u7528\u5e26\u70ed\u542f\u52a8\u7684\u8fde\u7eed\u7a77\u4e3e\u5e03\u5c14\u4f18\u5316(SEBO)\u65b9\u6cd5\u4f18\u5316\u5929\u7ebf\u7f16\u7801\u8bbe\u8ba1\uff0c\u8054\u5408\u5229\u7528\u5929\u7ebf\u7f16\u7801\u3001\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\u548c\u6574\u6d41\u5668\u975e\u7ebf\u6027\u7279\u6027\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u63d0\u51fa\u7684\u57fa\u4e8e\u50cf\u7d20\u5929\u7ebf\u7684MIMO\u65e0\u7ebf\u529f\u7387\u4f20\u8f93\u7cfb\u7edf\u76f8\u6bd4\u4f20\u7edf\u56fa\u5b9a\u5929\u7ebf\u914d\u7f6e\u7cfb\u7edf\uff0c\u5e73\u5747\u8f93\u51faDC\u529f\u7387\u589e\u76ca\u6700\u9ad8\u53ef\u8fbe15dB\uff0c\u663e\u8457\u63d0\u5347\u4e86\u65e0\u7ebf\u529f\u7387\u4f20\u8f93\u6548\u7387\u3002", "conclusion": "\u5929\u7ebf\u7f16\u7801\u4f5c\u4e3aMIMO\u65e0\u7ebf\u529f\u7387\u4f20\u8f93\u7cfb\u7edf\u7684\u65b0\u81ea\u7531\u5ea6\u5177\u6709\u5de8\u5927\u6f5c\u529b\uff0c\u50cf\u7d20\u5929\u7ebf\u6280\u672f\u80fd\u591f\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u672a\u6765\u65e0\u7ebf\u529f\u7387\u4f20\u8f93\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2512.14205", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14205", "abs": "https://arxiv.org/abs/2512.14205", "authors": ["Hadi M. Daniali", "Martin v. Mohrenschildt"], "title": "Rethinking Gaussian-Windowed Wavelets for Damping Identification", "comment": null, "summary": "In modal analysis, the prevalent use of Gaussian-based wavelets (such as Morlet and Gabor) for damping estimation is rarely questioned. In this study, we challenge this conventional approach by systematically exploring envelope-based damping estimators and proposing a data-driven framework that optimizes the shape and parameters of the envelope utilizing synthetic impulse responses with known ground-truth envelopes. The performance of the resulting estimators is benchmarked across a range of scenarios and compared against frequency-domain damping estimation methods, including Least Squares Rational Function (LSRF), poly-reference Least Squares Complex Frequency-Domain (pLSCF), peak picking (PP), and the Yoshida method. Our findings indicate that Triangle and Welch windows consistently outperform or are on par with Gaussian wavelet methods in contexts of moderate to high signal-to-noise ratios (SNR). In contrast, Blackman filtering demonstrates superior robustness under low SNR conditions and scenarios involving closely spaced modes. Among the frequency-domain methods assessed, LSRF shows the most reliability at very low SNR; however, the non-Gaussian optimized envelope estimators perform exceptionally well as the SNR improves.", "AI": {"tldr": "\u8be5\u7814\u7a76\u6311\u6218\u4e86\u6a21\u6001\u5206\u6790\u4e2d\u57fa\u4e8e\u9ad8\u65af\u5c0f\u6ce2\uff08\u5982Morlet\u548cGabor\uff09\u7684\u963b\u5c3c\u4f30\u8ba1\u4f20\u7edf\u65b9\u6cd5\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u6570\u636e\u9a71\u52a8\u7684\u5305\u7edc\u4f18\u5316\u6846\u67b6\uff0c\u53d1\u73b0\u975e\u9ad8\u65af\u5305\u7edc\u4f30\u8ba1\u5668\u5728\u4e2d\u7b49\u81f3\u9ad8\u4fe1\u566a\u6bd4\u4e0b\u8868\u73b0\u4f18\u4e8e\u6216\u7b49\u540c\u4e8e\u9ad8\u65af\u65b9\u6cd5\u3002", "motivation": "\u6a21\u6001\u5206\u6790\u4e2d\u666e\u904d\u4f7f\u7528\u57fa\u4e8e\u9ad8\u65af\u7684\u5c0f\u6ce2\uff08\u5982Morlet\u548cGabor\uff09\u8fdb\u884c\u963b\u5c3c\u4f30\u8ba1\uff0c\u4f46\u8fd9\u79cd\u4f20\u7edf\u65b9\u6cd5\u5f88\u5c11\u53d7\u5230\u8d28\u7591\u3002\u672c\u7814\u7a76\u65e8\u5728\u6311\u6218\u8fd9\u4e00\u5e38\u89c4\u505a\u6cd5\uff0c\u7cfb\u7edf\u63a2\u7d22\u57fa\u4e8e\u5305\u7edc\u7684\u963b\u5c3c\u4f30\u8ba1\u5668\u3002", "method": "\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u6846\u67b6\uff0c\u5229\u7528\u5df2\u77e5\u771f\u5b9e\u5305\u7edc\u7684\u5408\u6210\u8109\u51b2\u54cd\u5e94\u4f18\u5316\u5305\u7edc\u5f62\u72b6\u548c\u53c2\u6570\u3002\u5c06\u6240\u5f97\u4f30\u8ba1\u5668\u5728\u5404\u79cd\u573a\u666f\u4e0b\u8fdb\u884c\u57fa\u51c6\u6d4b\u8bd5\uff0c\u5e76\u4e0e\u9891\u57df\u963b\u5c3c\u4f30\u8ba1\u65b9\u6cd5\uff08\u5305\u62ecLSRF\u3001pLSCF\u3001\u5cf0\u503c\u62fe\u53d6\u6cd5\u548cYoshida\u65b9\u6cd5\uff09\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "Triangle\u548cWelch\u7a97\u5728\u4e2d\u7b49\u81f3\u9ad8\u4fe1\u566a\u6bd4\u4e0b\u59cb\u7ec8\u4f18\u4e8e\u6216\u7b49\u540c\u4e8e\u9ad8\u65af\u5c0f\u6ce2\u65b9\u6cd5\u3002Blackman\u6ee4\u6ce2\u5728\u4f4e\u4fe1\u566a\u6bd4\u548c\u5bc6\u96c6\u6a21\u6001\u573a\u666f\u4e0b\u8868\u73b0\u51fa\u66f4\u5f3a\u7684\u9c81\u68d2\u6027\u3002\u5728\u9891\u57df\u65b9\u6cd5\u4e2d\uff0cLSRF\u5728\u6781\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u6700\u53ef\u9760\uff0c\u4f46\u968f\u7740\u4fe1\u566a\u6bd4\u63d0\u9ad8\uff0c\u975e\u9ad8\u65af\u4f18\u5316\u5305\u7edc\u4f30\u8ba1\u5668\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u4f20\u7edf\u7684\u9ad8\u65af\u5c0f\u6ce2\u65b9\u6cd5\u5e76\u975e\u603b\u662f\u6700\u4f73\u9009\u62e9\uff0c\u6570\u636e\u9a71\u52a8\u7684\u5305\u7edc\u4f18\u5316\u6846\u67b6\u53ef\u4ee5\u4ea7\u751f\u66f4\u6709\u6548\u7684\u963b\u5c3c\u4f30\u8ba1\u5668\uff0c\u7279\u522b\u662f\u5728\u4e0d\u540c\u4fe1\u566a\u6bd4\u548c\u6a21\u6001\u5bc6\u5ea6\u6761\u4ef6\u4e0b\uff0c\u975e\u9ad8\u65af\u5305\u7edc\u4f30\u8ba1\u5668\u5c55\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2512.14213", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14213", "abs": "https://arxiv.org/abs/2512.14213", "authors": ["Hayate Kojima", "Hiroshi Higashi", "Yuichi Tanaka"], "title": "Graph Signal Denoising Using Regularization by Denoising and Its Parameter Estimation", "comment": "Submitted to APSIPA Transactions on Signal and Information Processing", "summary": "In this paper, we propose an interpretable denoising method for graph signals using regularization by denoising (RED). RED is a technique developed for image restoration that uses an efficient (and sometimes black-box) denoiser in the regularization term of the optimization problem. By using RED, optimization problems can be designed with the explicit use of the denoiser, and the gradient of the regularization term can be easily computed under mild conditions. We adapt RED for denoising of graph signals beyond image processing. We show that many graph signal denoisers, including graph neural networks, theoretically or practically satisfy the conditions for RED. We also study the effectiveness of RED from a graph filter perspective. Furthermore, we propose supervised and unsupervised parameter estimation methods based on deep algorithm unrolling. These methods aim to enhance the algorithm applicability, particularly in the unsupervised setting. Denoising experiments for synthetic and real-world datasets show that our proposed method improves signal denoising accuracy in mean squared error compared to existing graph signal denoising methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6b63\u5219\u5316\u53bb\u566a(RED)\u7684\u53ef\u89e3\u91ca\u56fe\u4fe1\u53f7\u53bb\u566a\u65b9\u6cd5\uff0c\u901a\u8fc7\u6df1\u5ea6\u7b97\u6cd5\u5c55\u5f00\u5b9e\u73b0\u76d1\u7763\u548c\u65e0\u76d1\u7763\u53c2\u6570\u4f30\u8ba1\uff0c\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5c06\u56fe\u50cf\u5904\u7406\u4e2d\u7684RED\u6280\u672f\u6269\u5c55\u5230\u56fe\u4fe1\u53f7\u53bb\u566a\u9886\u57df\uff0c\u5229\u7528RED\u7684\u4f18\u52bf\u8bbe\u8ba1\u53ef\u89e3\u91ca\u7684\u4f18\u5316\u95ee\u9898\uff0c\u5e76\u89e3\u51b3\u56fe\u4fe1\u53f7\u53bb\u566a\u4e2d\u53c2\u6570\u4f30\u8ba1\u7684\u6311\u6218\u3002", "method": "\u5c06RED\u6280\u672f\u9002\u914d\u5230\u56fe\u4fe1\u53f7\u53bb\u566a\uff0c\u8bc1\u660e\u591a\u79cd\u56fe\u4fe1\u53f7\u53bb\u566a\u5668\u6ee1\u8db3RED\u6761\u4ef6\uff0c\u4ece\u56fe\u6ee4\u6ce2\u5668\u89d2\u5ea6\u5206\u6790RED\u6709\u6548\u6027\uff0c\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u7b97\u6cd5\u5c55\u5f00\u7684\u76d1\u7763\u548c\u65e0\u76d1\u7763\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\u3002", "result": "\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\u7684\u53bb\u566a\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u5747\u65b9\u8bef\u5dee\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u56fe\u4fe1\u53f7\u53bb\u566a\u65b9\u6cd5\uff0c\u7279\u522b\u662f\u5728\u65e0\u76d1\u7763\u8bbe\u7f6e\u4e0b\u589e\u5f3a\u4e86\u7b97\u6cd5\u9002\u7528\u6027\u3002", "conclusion": "\u6210\u529f\u5c06RED\u6280\u672f\u6269\u5c55\u5230\u56fe\u4fe1\u53f7\u53bb\u566a\u9886\u57df\uff0c\u63d0\u51fa\u7684\u53ef\u89e3\u91ca\u65b9\u6cd5\u5728\u51c6\u786e\u6027\u548c\u9002\u7528\u6027\u65b9\u9762\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e3a\u56fe\u4fe1\u53f7\u5904\u7406\u63d0\u4f9b\u4e86\u65b0\u7684\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2512.14287", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14287", "abs": "https://arxiv.org/abs/2512.14287", "authors": ["Yunnuo Xu", "Yumeng Zhang", "Yijie Mao", "Bruno Clerck", "Yun Hee Kim", "Yujun Li"], "title": "Robust Design for Multi-Antenna LEO Satellite Communications with Fractional Delay and Doppler Shifts: An RSMA-OTFS Approach", "comment": null, "summary": "Low-Earth-orbit (LEO) satellite communication systems face challenges due to high satellite mobility, which hinders the reliable acquisition of instantaneous channel state information at the transmitter (CSIT) and subsequently degrades multi-user transmission performance. This paper investigates a downlink multi-user multi-antenna system, and tackles the above challenges by introducing orthogonal time frequency space (OTFS) modulation and rate-splitting multiple access (RSMA) transmission. Specifically, OTFS enables stable characterization of time-varying channels by representing them in the delay-Doppler domain. However, realistic propagation introduces various inter-symbol and inter-user interference due to non-orthogonal yet practical rectangular pulse shaping, fractional delays, Doppler shifts, and imperfect (statistical) CSIT. In this context, RSMA offers promising robustness for interference mitigation and CSIT imperfections, and hence is integrated with OTFS to provide a comprehensive solution. A compact cross-domain input-output relationship for RSMA-OTFS is established, and an ergodic sum-rate maximization problem is formulated and solved using a weighted minimum mean-square-error based alternating optimization algorithm that does not depend on channel sparsity. Simulation results reveal that the considered practical propagation effects significantly degrade performance if unaddressed. Furthermore, the RSMA-OTFS scheme demonstrates improved ergodic sum-rate and robustness against CSIT uncertainty across various user deployments and CSIT qualities.", "AI": {"tldr": "RSMA-OTFS\u65b9\u6848\u7ed3\u5408\u6b63\u4ea4\u65f6\u9891\u7a7a\u95f4\u8c03\u5236\u548c\u901f\u7387\u5206\u5272\u591a\u5740\u63a5\u5165\uff0c\u89e3\u51b3\u4e86LEO\u536b\u661f\u901a\u4fe1\u4e2d\u9ad8\u901f\u79fb\u52a8\u5bfc\u81f4\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u83b7\u53d6\u56f0\u96be\u548c\u591a\u7528\u6237\u4f20\u8f93\u6027\u80fd\u4e0b\u964d\u95ee\u9898\u3002", "motivation": "\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u901a\u4fe1\u7cfb\u7edf\u9762\u4e34\u9ad8\u536b\u661f\u79fb\u52a8\u6027\u5e26\u6765\u7684\u6311\u6218\uff0c\u8fd9\u963b\u788d\u4e86\u53d1\u5c04\u7aef\u77ac\u65f6\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u7684\u53ef\u9760\u83b7\u53d6\uff0c\u4ece\u800c\u964d\u4f4e\u4e86\u591a\u7528\u6237\u4f20\u8f93\u6027\u80fd\u3002\u5b9e\u9645\u4f20\u64ad\u4e2d\u8fd8\u5b58\u5728\u5404\u79cd\u7b26\u53f7\u95f4\u548c\u7528\u6237\u95f4\u5e72\u6270\u3002", "method": "\u5f15\u5165OTFS\u8c03\u5236\u548cRSMA\u4f20\u8f93\uff0c\u5efa\u7acbRSMA-OTFS\u7684\u7d27\u51d1\u8de8\u57df\u8f93\u5165\u8f93\u51fa\u5173\u7cfb\uff0c\u6784\u5efa\u904d\u5386\u548c\u901f\u7387\u6700\u5927\u5316\u95ee\u9898\uff0c\u4f7f\u7528\u57fa\u4e8e\u52a0\u6743\u6700\u5c0f\u5747\u65b9\u8bef\u5dee\u7684\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u6c42\u89e3\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u672a\u5904\u7406\u7684\u5b9e\u7528\u4f20\u64ad\u6548\u5e94\u4f1a\u663e\u8457\u964d\u4f4e\u6027\u80fd\u3002RSMA-OTFS\u65b9\u6848\u5728\u5404\u79cd\u7528\u6237\u90e8\u7f72\u548cCSIT\u8d28\u91cf\u4e0b\u90fd\u8868\u73b0\u51fa\u6539\u8fdb\u7684\u904d\u5386\u548c\u901f\u7387\u4ee5\u53ca\u5bf9CSIT\u4e0d\u786e\u5b9a\u6027\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "RSMA-OTFS\u4e3aLEO\u536b\u661f\u901a\u4fe1\u4e2d\u7684\u591a\u7528\u6237\u591a\u5929\u7ebf\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5168\u9762\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u4fe1\u9053\u65f6\u53d8\u6027\u548cCSIT\u4e0d\u5b8c\u7f8e\u6027\uff0c\u63d0\u9ad8\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2512.14351", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14351", "abs": "https://arxiv.org/abs/2512.14351", "authors": ["Xiaoxia Xu", "Xidong Mu", "Yuanwei Liu", "Hong Xing", "Arumugam Nallanathan"], "title": "User Localization and Channel Estimation for Pinching-Antenna Systems (PASS)", "comment": "5 Pages, 3 figures", "summary": "This letter proposes a novel user localization and channel estimation framework for pinching-antenna systems (PASS), where pinching antennas are grouped into subarrays on each waveguide to cooperatively estimate user/scatterer locations, thus reconstructing channels. Both single-waveguide (SW) and multi-waveguide (MW) structures are considered. SW consists of multiple alternatingly activated subarrays, while MW deploys one subarray on each waveguide to enable concurrent subarray measurements. For the 2D scenarios with a fixed user/scatter height, an orthogonal matching pursuit-based geometry-consistent localization (OMP-GCL) algorithm is proposed, which leverages inter-subarray geometric relationships and compressed sensing for precise estimation. Theoretical analysis on Cram\u00e9r-Rao lower bound (CRLB) demonstrates that: 1) The estimation accuracy can be improved by increasing the geometric diversity through multi-subarray deployment; and 2) SW provides a limited geometric diversity within a $180^\\circ$ half space and leads to angle ambiguity, while MW enables full-space observations and reduces overheads. The OMP-GCL algorithm is further extended to 3D scenarios, where user and scatter heights are also estimated. Numerical results validate the theoretical analysis, and verify that MW achieves centimeter- and decimeter-level localization accuracy in 2D and 3D scenarios with only three waveguides.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5939\u6301\u5929\u7ebf\u7cfb\u7edf(PASS)\u7684\u65b0\u578b\u7528\u6237\u5b9a\u4f4d\u548c\u4fe1\u9053\u4f30\u8ba1\u6846\u67b6\uff0c\u901a\u8fc7\u5206\u7ec4\u5b50\u9635\u5217\u534f\u540c\u4f30\u8ba1\u7528\u6237/\u6563\u5c04\u4f53\u4f4d\u7f6e\u6765\u91cd\u5efa\u4fe1\u9053\uff0c\u8003\u8651\u4e86\u5355\u6ce2\u5bfc\u548c\u591a\u6ce2\u5bfc\u7ed3\u6784\uff0c\u5e76\u5f00\u53d1\u4e86\u57fa\u4e8e\u51e0\u4f55\u4e00\u81f4\u6027\u7684\u5b9a\u4f4d\u7b97\u6cd5\u3002", "motivation": "\u5939\u6301\u5929\u7ebf\u7cfb\u7edf\u9700\u8981\u6709\u6548\u7684\u7528\u6237\u5b9a\u4f4d\u548c\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\uff0c\u73b0\u6709\u65b9\u6cd5\u5728\u51e0\u4f55\u591a\u6837\u6027\u548c\u89d2\u5ea6\u6a21\u7cca\u6027\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u5229\u7528\u591a\u5b50\u9635\u5217\u51e0\u4f55\u5173\u7cfb\u5b9e\u73b0\u7cbe\u786e\u4f30\u8ba1\u7684\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u5355\u6ce2\u5bfc(SW)\u548c\u591a\u6ce2\u5bfc(MW)\u4e24\u79cd\u7ed3\u6784\uff1aSW\u4f7f\u7528\u4ea4\u66ff\u6fc0\u6d3b\u7684\u591a\u4e2a\u5b50\u9635\u5217\uff0cMW\u5728\u6bcf\u4e2a\u6ce2\u5bfc\u4e0a\u90e8\u7f72\u4e00\u4e2a\u5b50\u9635\u5217\u5b9e\u73b0\u5e76\u53d1\u6d4b\u91cf\u3002\u5f00\u53d1\u4e86\u57fa\u4e8e\u6b63\u4ea4\u5339\u914d\u8ffd\u8e2a\u7684\u51e0\u4f55\u4e00\u81f4\u6027\u5b9a\u4f4d(OMP-GCL)\u7b97\u6cd5\uff0c\u5229\u7528\u5b50\u9635\u5217\u95f4\u51e0\u4f55\u5173\u7cfb\u548c\u538b\u7f29\u611f\u77e5\u8fdb\u884c\u7cbe\u786e\u4f30\u8ba1\u3002\u7b97\u6cd5\u4ece2D\u573a\u666f\u6269\u5c55\u52303D\u573a\u666f\u4ee5\u4f30\u8ba1\u9ad8\u5ea6\u4fe1\u606f\u3002", "result": "\u7406\u8bba\u5206\u6790\u8868\u660e\uff1a1)\u901a\u8fc7\u591a\u5b50\u9635\u5217\u90e8\u7f72\u589e\u52a0\u51e0\u4f55\u591a\u6837\u6027\u53ef\u4ee5\u63d0\u9ad8\u4f30\u8ba1\u7cbe\u5ea6\uff1b2)SW\u5728180\u00b0\u534a\u7a7a\u95f4\u5185\u63d0\u4f9b\u6709\u9650\u7684\u51e0\u4f55\u591a\u6837\u6027\u5e76\u5bfc\u81f4\u89d2\u5ea6\u6a21\u7cca\uff0c\u800cMW\u652f\u6301\u5168\u7a7a\u95f4\u89c2\u6d4b\u5e76\u51cf\u5c11\u5f00\u9500\u3002\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\uff0cMW\u4ec5\u7528\u4e09\u4e2a\u6ce2\u5bfc\u5c31\u57282D\u548c3D\u573a\u666f\u4e2d\u5206\u522b\u5b9e\u73b0\u4e86\u5398\u7c73\u7ea7\u548c\u5206\u7c73\u7ea7\u7684\u5b9a\u4f4d\u7cbe\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684PASS\u6846\u67b6\u548cOMP-GCL\u7b97\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u7528\u6237\u5b9a\u4f4d\u548c\u4fe1\u9053\u4f30\u8ba1\u95ee\u9898\uff0c\u591a\u6ce2\u5bfc\u7ed3\u6784\u76f8\u6bd4\u5355\u6ce2\u5bfc\u7ed3\u6784\u5177\u6709\u66f4\u597d\u7684\u51e0\u4f55\u591a\u6837\u6027\u3001\u5168\u7a7a\u95f4\u89c2\u6d4b\u80fd\u529b\u548c\u66f4\u4f4e\u7684\u5f00\u9500\uff0c\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002"}}
{"id": "2512.14357", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14357", "abs": "https://arxiv.org/abs/2512.14357", "authors": ["Navid Amani", "Priyanka Maity", "Musa Furkan Keskin", "Henk Wymeersch"], "title": "Sparse OFDM Design for Interference and Ambiguity Mitigation in Multi-Static ISAC", "comment": null, "summary": "The sixth-generation (6G) wireless networks promises the integration of radar-like sensing capabilities into communication infrastructure. In this paper, we investigate a multi-static sensing framework where half-duplex base stations (BSs) are assigned as either transmitter or sensing receiver nodes. We propose a randomized sparse resource allocation scheme based on orthogonal frequency division multiplexing (OFDM) waveform design tailored for the multi-static scenario to simultaneously mitigate inter-BS interference (IBI) and sensing ambiguities. The waveform design also ensures robustness against inter-symbol interference (ISI) and intercarrier interference (ICI) via a judicious choice of subcarrier spacing according to the deployment of BSs. The potential ambiguity caused by sparse signaling is addressed through controlled irregularity in both time and frequency domains, with a negligible noise floor elevation. Simulation results demonstrate the effectiveness and resilience of the proposed design in the presence of multiple targets and clutter.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eOFDM\u6ce2\u5f62\u8bbe\u8ba1\u7684\u968f\u673a\u7a00\u758f\u8d44\u6e90\u5206\u914d\u65b9\u6848\uff0c\u7528\u4e8e6G\u591a\u57fa\u7ad9\u611f\u77e5\u7cfb\u7edf\uff0c\u4ee5\u540c\u65f6\u51cf\u8f7b\u57fa\u7ad9\u95f4\u5e72\u6270\u548c\u611f\u77e5\u6a21\u7cca\u6027\u3002", "motivation": "6G\u65e0\u7ebf\u7f51\u7edc\u9700\u8981\u5c06\u96f7\u8fbe\u5f0f\u611f\u77e5\u80fd\u529b\u96c6\u6210\u5230\u901a\u4fe1\u57fa\u7840\u8bbe\u65bd\u4e2d\uff0c\u591a\u57fa\u7ad9\u611f\u77e5\u6846\u67b6\u9762\u4e34\u57fa\u7ad9\u95f4\u5e72\u6270\u548c\u611f\u77e5\u6a21\u7cca\u6027\u7684\u6311\u6218\uff0c\u9700\u8981\u8bbe\u8ba1\u6709\u6548\u7684\u8d44\u6e90\u5206\u914d\u65b9\u6848\u6765\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u968f\u673a\u7a00\u758f\u8d44\u6e90\u5206\u914d\u65b9\u6848\uff0c\u57fa\u4e8eOFDM\u6ce2\u5f62\u8bbe\u8ba1\uff0c\u901a\u8fc7\u5b50\u8f7d\u6ce2\u95f4\u9694\u7684\u5408\u7406\u9009\u62e9\u6765\u62b5\u6297\u7b26\u53f7\u95f4\u5e72\u6270\u548c\u8f7d\u6ce2\u95f4\u5e72\u6270\uff0c\u5728\u65f6\u57df\u548c\u9891\u57df\u5f15\u5165\u53d7\u63a7\u7684\u4e0d\u89c4\u5219\u6027\u6765\u89e3\u51b3\u7a00\u758f\u4fe1\u53f7\u5f15\u8d77\u7684\u6a21\u7cca\u6027\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u8bbe\u8ba1\u5728\u5b58\u5728\u591a\u4e2a\u76ee\u6807\u548c\u6742\u6ce2\u7684\u60c5\u51b5\u4e0b\u5177\u6709\u6709\u6548\u6027\u548c\u9c81\u68d2\u6027\uff0c\u80fd\u591f\u4ee5\u53ef\u5ffd\u7565\u7684\u566a\u58f0\u57fa\u5e95\u5347\u9ad8\u4e3a\u4ee3\u4ef7\u89e3\u51b3\u611f\u77e5\u6a21\u7cca\u6027\u95ee\u9898\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a6G\u591a\u57fa\u7ad9\u611f\u77e5\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u6ce2\u5f62\u8bbe\u8ba1\u548c\u8d44\u6e90\u5206\u914d\u65b9\u6848\uff0c\u80fd\u591f\u540c\u65f6\u89e3\u51b3\u5e72\u6270\u548c\u611f\u77e5\u6a21\u7cca\u6027\u95ee\u9898\uff0c\u4e3a\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u76846G\u7f51\u7edc\u5960\u5b9a\u4e86\u57fa\u7840\u3002"}}
{"id": "2512.14368", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14368", "abs": "https://arxiv.org/abs/2512.14368", "authors": ["Xavier Artiga", "M\u00e0rius Caus", "Ana P\u00e9rez-Neira"], "title": "Pragmatic Earth-Fixed Beam Management for 3GPP NTN Common Signaling in LEO Satellites", "comment": "14 pages, 18 figures", "summary": "This work proposes a pragmatic method for the design of beam footprint layouts and beam hopping illumination patterns to efficiently broadcast 3GPP NTN common signaling to large coverage areas using EIRP-limited LEO satellites. This method minimizes the time resources required to sweep over the whole coverage while ensuring that the signal-to-interference-plus-noise ratio received by users is above a given threshold. It discusses the design of: (i) an Earth-fixed grid of beam layouts; (ii) beamforming vectors and beam power allocation; (iii) beam hopping patterns and (iv) space, time and frequency resource allocation of 3GPP common signaling. Two main beam layout solutions are proposed to significantly reduce the number of beams required to illuminate the coverage area: one based on phased array beams with low beam crossover levels and the other on widened beams. A numerical evaluation using practical system parameters showed that both solutions perform similarly, but that the best result is obtained with phased arrays beams with optimized beam cross over levels. Indeed, for the system evaluated, they allowed reducing the total number of beams from 1723 to 451, which combined with a proper beam hopping pattern and scheduling scheme allowed obtaining a coverage ratio of 100% and a common signaling efficiency (i.e. number of slots carrying common signaling over total number of slots) up to 80.6% for the most stringent common signaling periodicity of 20 ms considered by 3GPP.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8bbe\u8ba1\u6ce2\u675f\u8986\u76d6\u5e03\u5c40\u548c\u6ce2\u675f\u8df3\u53d8\u7167\u660e\u6a21\u5f0f\u7684\u65b9\u6cd5\uff0c\u7528\u4e8eLEO\u536b\u661f\u9ad8\u6548\u5e7f\u64ad3GPP NTN\u516c\u5171\u4fe1\u4ee4\uff0c\u5728EIRP\u9650\u5236\u4e0b\u6700\u5c0f\u5316\u8986\u76d6\u6574\u4e2a\u533a\u57df\u6240\u9700\u7684\u65f6\u95f4\u8d44\u6e90\uff0c\u540c\u65f6\u4fdd\u8bc1\u7528\u6237\u63a5\u6536\u4fe1\u53f7\u8d28\u91cf\u3002", "motivation": "LEO\u536b\u661f\u5728EIRP\u529f\u7387\u9650\u5236\u4e0b\u9700\u8981\u9ad8\u6548\u5e7f\u64ad3GPP NTN\u516c\u5171\u4fe1\u4ee4\u7ed9\u5927\u8986\u76d6\u533a\u57df\u3002\u4f20\u7edf\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6ce2\u675f\u8986\u76d6\u6574\u4e2a\u533a\u57df\uff0c\u5bfc\u81f4\u65f6\u95f4\u8d44\u6e90\u6548\u7387\u4f4e\u4e0b\u3002\u9700\u8981\u8bbe\u8ba1\u4f18\u5316\u7684\u6ce2\u675f\u5e03\u5c40\u548c\u8df3\u53d8\u6a21\u5f0f\u6765\u51cf\u5c11\u6240\u9700\u6ce2\u675f\u6570\u91cf\uff0c\u63d0\u9ad8\u516c\u5171\u4fe1\u4ee4\u4f20\u8f93\u6548\u7387\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u7efc\u5408\u6027\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5305\u62ec\uff1a(1) \u8bbe\u8ba1\u5730\u7403\u56fa\u5b9a\u7f51\u683c\u6ce2\u675f\u5e03\u5c40\uff1b(2) \u6ce2\u675f\u8d4b\u5f62\u5411\u91cf\u548c\u529f\u7387\u5206\u914d\uff1b(3) \u6ce2\u675f\u8df3\u53d8\u6a21\u5f0f\uff1b(4) 3GPP\u516c\u5171\u4fe1\u4ee4\u7684\u65f6\u9891\u8d44\u6e90\u5206\u914d\u3002\u63d0\u51fa\u4e24\u79cd\u4e3b\u8981\u6ce2\u675f\u5e03\u5c40\u65b9\u6848\uff1a\u57fa\u4e8e\u4f4e\u4ea4\u53c9\u6c34\u5e73\u7684\u76f8\u63a7\u9635\u6ce2\u675f\u65b9\u6848\u548c\u52a0\u5bbd\u6ce2\u675f\u65b9\u6848\uff0c\u4ee5\u663e\u8457\u51cf\u5c11\u8986\u76d6\u533a\u57df\u6240\u9700\u6ce2\u675f\u6570\u91cf\u3002", "result": "\u6570\u503c\u8bc4\u4f30\u663e\u793a\u4e24\u79cd\u65b9\u6848\u6027\u80fd\u76f8\u4f3c\uff0c\u4f46\u4f18\u5316\u4ea4\u53c9\u6c34\u5e73\u7684\u76f8\u63a7\u9635\u6ce2\u675f\u65b9\u6848\u6548\u679c\u6700\u4f73\u3002\u5bf9\u4e8e\u8bc4\u4f30\u7684\u7cfb\u7edf\uff0c\u6240\u9700\u6ce2\u675f\u6570\u91cf\u4ece1723\u4e2a\u51cf\u5c11\u5230451\u4e2a\uff0c\u7ed3\u5408\u9002\u5f53\u7684\u6ce2\u675f\u8df3\u53d8\u6a21\u5f0f\u548c\u8c03\u5ea6\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86100%\u7684\u8986\u76d6\u7387\uff0c\u5728\u6700\u4e25\u683c\u768420ms\u516c\u5171\u4fe1\u4ee4\u5468\u671f\u4e0b\uff0c\u516c\u5171\u4fe1\u4ee4\u6548\u7387\u8fbe\u523080.6%\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u5c11LEO\u536b\u661f\u5e7f\u64ad3GPP NTN\u516c\u5171\u4fe1\u4ee4\u6240\u9700\u7684\u6ce2\u675f\u6570\u91cf\uff0c\u663e\u8457\u63d0\u9ad8\u65f6\u95f4\u8d44\u6e90\u6548\u7387\u3002\u4f18\u5316\u4ea4\u53c9\u6c34\u5e73\u7684\u76f8\u63a7\u9635\u6ce2\u675f\u65b9\u6848\u5728\u4fdd\u6301100%\u8986\u76d6\u7387\u7684\u540c\u65f6\uff0c\u5c06\u516c\u5171\u4fe1\u4ee4\u6548\u7387\u63d0\u5347\u81f380.6%\uff0c\u4e3aEIRP\u53d7\u9650\u7684LEO\u536b\u661f\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u7684\u8bbe\u8ba1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.14394", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14394", "abs": "https://arxiv.org/abs/2512.14394", "authors": ["Ben Chen", "Zhangdui Zhong", "Ke Guan", "Danping He", "Yiran Wang", "Jianwen Ding", "Qi Luo"], "title": "Terahertz Signal Coverage Enhancement in Hall Scenarios Based on Single-Hop and Dual-Hop Reconfigurable Intelligent Surfaces", "comment": "5 pages, 5 figures. This paper has been accepted for the 2026 20th European Conference on Antennas and Propagation (EuCAP) International Conference on December 13, 2025", "summary": "Terahertz (THz) communication offers ultra-high data rates and has emerged as a promising technology for future wireless networks. However, the inherently high free-space path loss of THz waves significantly limits the coverage range of THz communication systems. Therefore, extending the effective coverage area is a key challenge for the practical deployment of THz networks. Reconfigurable intelligent surfaces (RIS), which can dynamically manipulate electromagnetic wave propagation, provide a solution to enhance THz coverage. To investigate multi-RIS deployment scenarios, this work integrates an antenna array-based RIS model into the ray-tracing simulation platform. Using an indoor hall as a representative case study, the enhancement effects of single-hop and dual-hop RIS configurations on indoor signal coverage are evaluated under various deployment schemes. The developed framework offers valuable insights and design references for optimizing RIS-assisted indoor THz communication and coverage estimation.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5929\u7ebf\u9635\u5217RIS\u6a21\u578b\u7684\u5c04\u7ebf\u8ffd\u8e2a\u4eff\u771f\u5e73\u53f0\uff0c\u7528\u4e8e\u8bc4\u4f30RIS\u5728\u5ba4\u5185\u592a\u8d6b\u5179\u901a\u4fe1\u4e2d\u7684\u8986\u76d6\u589e\u5f3a\u6548\u679c\uff0c\u901a\u8fc7\u5355\u8df3\u548c\u53cc\u8df3RIS\u914d\u7f6e\u4f18\u5316\u5ba4\u5185\u4fe1\u53f7\u8986\u76d6\u3002", "motivation": "\u592a\u8d6b\u5179\u901a\u4fe1\u867d\u7136\u80fd\u63d0\u4f9b\u8d85\u9ad8\u6570\u636e\u901f\u7387\uff0c\u4f46\u5176\u56fa\u6709\u7684\u9ad8\u81ea\u7531\u7a7a\u95f4\u8def\u5f84\u635f\u8017\u4e25\u91cd\u9650\u5236\u4e86\u8986\u76d6\u8303\u56f4\uff0c\u56e0\u6b64\u6269\u5c55\u6709\u6548\u8986\u76d6\u533a\u57df\u662f\u592a\u8d6b\u5179\u7f51\u7edc\u5b9e\u9645\u90e8\u7f72\u7684\u5173\u952e\u6311\u6218\u3002\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u80fd\u591f\u52a8\u6001\u64cd\u7eb5\u7535\u78c1\u6ce2\u4f20\u64ad\uff0c\u4e3a\u589e\u5f3a\u592a\u8d6b\u5179\u8986\u76d6\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u57fa\u4e8e\u5929\u7ebf\u9635\u5217\u7684RIS\u6a21\u578b\u96c6\u6210\u5230\u5c04\u7ebf\u8ffd\u8e2a\u4eff\u771f\u5e73\u53f0\u4e2d\uff0c\u4ee5\u5ba4\u5185\u5927\u5385\u4e3a\u4ee3\u8868\u6027\u6848\u4f8b\u7814\u7a76\uff0c\u8bc4\u4f30\u5355\u8df3\u548c\u53cc\u8df3RIS\u914d\u7f6e\u5728\u5404\u79cd\u90e8\u7f72\u65b9\u6848\u4e0b\u5bf9\u5ba4\u5185\u4fe1\u53f7\u8986\u76d6\u7684\u589e\u5f3a\u6548\u679c\u3002", "result": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6846\u67b6\uff0c\u4e3a\u4f18\u5316RIS\u8f85\u52a9\u7684\u5ba4\u5185\u592a\u8d6b\u5179\u901a\u4fe1\u548c\u8986\u76d6\u4f30\u8ba1\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u89c1\u89e3\u548c\u8bbe\u8ba1\u53c2\u8003\uff0c\u8bc4\u4f30\u4e86\u4e0d\u540cRIS\u914d\u7f6e\u5bf9\u4fe1\u53f7\u8986\u76d6\u7684\u589e\u5f3a\u6548\u679c\u3002", "conclusion": "RIS\u6280\u672f\u80fd\u591f\u6709\u6548\u589e\u5f3a\u592a\u8d6b\u5179\u901a\u4fe1\u7684\u5ba4\u5185\u8986\u76d6\uff0c\u901a\u8fc7\u5408\u7406\u7684\u90e8\u7f72\u65b9\u6848\u53ef\u4ee5\u663e\u8457\u6539\u5584\u4fe1\u53f7\u8986\u76d6\u8d28\u91cf\uff0c\u4e3a\u592a\u8d6b\u5179\u7f51\u7edc\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u3002"}}
{"id": "2512.14426", "categories": ["eess.SP", "cs.RO"], "pdf": "https://arxiv.org/pdf/2512.14426", "abs": "https://arxiv.org/abs/2512.14426", "authors": ["Simon Steuernagel", "Marcus Baum"], "title": "Quadratic Kalman Filter for Elliptical Extended Object Tracking based on Decoupling State Components", "comment": "13 pages, 8 figures, submitted to IEEE Transactions on Aerospace and Electronic Systems", "summary": "Extended object tracking involves estimating both the physical extent and kinematic parameters of a target object, where typically multiple measurements are observed per time step. In this article, we propose a deterministic closed-form elliptical extended object tracker, based on decoupling of the kinematics, orientation, and axis lengths. By disregarding potential correlations between these state components, fewer approximations are required for the individual estimators than for an overall joint solution. The resulting algorithm outperforms existing algorithms, reaching the accuracy of sampling-based procedures. Additionally, a batch-based variant is introduced, yielding highly efficient computation while outperforming all comparable state-of-the-art algorithms. This is validated both by a simulation study using common models from literature, as well as an extensive quantitative evaluation on real automotive radar data.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u786e\u5b9a\u6027\u95ed\u5f0f\u692d\u5706\u6269\u5c55\u76ee\u6807\u8ddf\u8e2a\u5668\uff0c\u901a\u8fc7\u89e3\u8026\u8fd0\u52a8\u5b66\u3001\u65b9\u5411\u548c\u8f74\u957f\uff0c\u51cf\u5c11\u8fd1\u4f3c\u9700\u6c42\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\uff0c\u8fbe\u5230\u91c7\u6837\u65b9\u6cd5\u7cbe\u5ea6\uff0c\u5e76\u5f15\u5165\u6279\u5904\u7406\u53d8\u4f53\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002", "motivation": "\u6269\u5c55\u76ee\u6807\u8ddf\u8e2a\u9700\u8981\u540c\u65f6\u4f30\u8ba1\u76ee\u6807\u7684\u7269\u7406\u8303\u56f4\u548c\u8fd0\u52a8\u53c2\u6570\uff0c\u901a\u5e38\u6bcf\u4e2a\u65f6\u95f4\u6b65\u6709\u591a\u4e2a\u6d4b\u91cf\u503c\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u8fd9\u4e9b\u53c2\u6570\u4e4b\u95f4\u7684\u76f8\u5173\u6027\u65f6\u9700\u8981\u8f83\u591a\u8fd1\u4f3c\uff0c\u5f71\u54cd\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u3002", "method": "\u63d0\u51fa\u786e\u5b9a\u6027\u95ed\u5f0f\u692d\u5706\u6269\u5c55\u76ee\u6807\u8ddf\u8e2a\u5668\uff0c\u5c06\u8fd0\u52a8\u5b66\u3001\u65b9\u5411\u548c\u8f74\u957f\u4e09\u4e2a\u72b6\u6001\u5206\u91cf\u89e3\u8026\u5904\u7406\uff0c\u5ffd\u7565\u5b83\u4eec\u4e4b\u95f4\u7684\u6f5c\u5728\u76f8\u5173\u6027\u3002\u8fd9\u6837\u6bcf\u4e2a\u5206\u91cf\u4f30\u8ba1\u5668\u6240\u9700\u7684\u8fd1\u4f3c\u6bd4\u6574\u4f53\u8054\u5408\u89e3\u51b3\u65b9\u6848\u66f4\u5c11\u3002\u8fd8\u5f15\u5165\u4e86\u6279\u5904\u7406\u53d8\u4f53\u4ee5\u63d0\u9ad8\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u7b97\u6cd5\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u7b97\u6cd5\uff0c\u8fbe\u5230\u91c7\u6837\u65b9\u6cd5\u7684\u7cbe\u5ea6\u6c34\u5e73\u3002\u6279\u5904\u7406\u53d8\u4f53\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u9ad8\u6548\u8ba1\u7b97\u3002\u901a\u8fc7\u6587\u732e\u5e38\u7528\u6a21\u578b\u7684\u4eff\u771f\u7814\u7a76\u548c\u771f\u5b9e\u6c7d\u8f66\u96f7\u8fbe\u6570\u636e\u7684\u5e7f\u6cdb\u5b9a\u91cf\u8bc4\u4f30\u9a8c\u8bc1\u4e86\u8fd9\u4e9b\u4f18\u52bf\u3002", "conclusion": "\u901a\u8fc7\u89e3\u8026\u72b6\u6001\u5206\u91cf\u7684\u65b9\u6cd5\uff0c\u5f00\u53d1\u4e86\u4e00\u79cd\u9ad8\u6027\u80fd\u7684\u692d\u5706\u6269\u5c55\u76ee\u6807\u8ddf\u8e2a\u5668\uff0c\u5728\u7cbe\u5ea6\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u90fd\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u7b97\u6cd5\uff0c\u9002\u7528\u4e8e\u5b9e\u9645\u5e94\u7528\u5982\u6c7d\u8f66\u96f7\u8fbe\u6570\u636e\u5904\u7406\u3002"}}
{"id": "2512.14432", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14432", "abs": "https://arxiv.org/abs/2512.14432", "authors": ["Zhuoran Li", "Zhen Gao", "Sheng Chen", "Dusit Niyato", "Zhaocheng Wan", "George K. Karagiannidis"], "title": "Chirp Delay-Doppler Domain Modulation Based Joint Communication and Radar for Autonomous Vehicles", "comment": "This paper has been accepted by IEEE TWC, and simulation codes are provided to reproduce the results in this paper: https://github.com/LiZhuoRan0/2026-IEEE-TWC-ChirpDelayDopplerModulationISAC", "summary": "This paper introduces a sensing-centric joint communication and millimeter-wave radar paradigm to facilitate collaboration among intelligent vehicles.\n  We first propose a chirp waveform-based delay-Doppler quadrature amplitude modulation (DD-QAM) that modulates data across delay, Doppler, and amplitude dimensions.\n  Building upon this modulation scheme, we derive its achievable rate to quantify the communication performance.\n  We then introduce an extended Kalman filter-based scheme for four-dimensional (4D) parameter estimation in dynamic environments, enabling the active vehicles to accurately estimate orientation and tangential-velocity beyond traditional 4D radar systems.\n  Furthermore, in terms of communication, we propose a dual-compensation-based demodulation and tracking scheme that allows the passive vehicles to effectively demodulate data without compromising their sensing functions.\n  Simulation results underscore the feasibility and superior performance of our proposed methods, marking a significant advancement in the field of autonomous vehicles.\n  Simulation codes are provided to reproduce the results in this paper: \\href{https://github.com/LiZhuoRan0/2026-IEEE-TWC-ChirpDelayDopplerModulationISAC}{https://github.com/LiZhuoRan0}.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5541\u557e\u6ce2\u5f62\u7684\u5ef6\u8fdf-\u591a\u666e\u52d2QAM\u8c03\u5236\u65b9\u6848\uff0c\u7528\u4e8e\u667a\u80fd\u8f66\u8f86\u95f4\u7684\u901a\u4fe1\u4e0e\u6beb\u7c73\u6ce2\u96f7\u8fbe\u534f\u540c\uff0c\u5b9e\u73b0\u901a\u4fe1\u901f\u7387\u63d0\u5347\u548c4D\u53c2\u6570\u4f30\u8ba1", "motivation": "\u4e3a\u4fc3\u8fdb\u667a\u80fd\u8f66\u8f86\u95f4\u7684\u534f\u4f5c\uff0c\u9700\u8981\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u901a\u4fe1\u548c\u7cbe\u786e\u611f\u77e5\u3002\u4f20\u7edf\u7cfb\u7edf\u96be\u4ee5\u517c\u987e\u901a\u4fe1\u4e0e\u96f7\u8fbe\u529f\u80fd\uff0c\u56e0\u6b64\u9700\u8981\u4e00\u79cd\u96c6\u6210\u65b9\u6848\u6765\u63d0\u5347\u8f66\u8f86\u534f\u540c\u80fd\u529b", "method": "1. \u63d0\u51fa\u57fa\u4e8e\u5541\u557e\u6ce2\u5f62\u7684\u5ef6\u8fdf-\u591a\u666e\u52d2\u6b63\u4ea4\u5e45\u5ea6\u8c03\u5236(DD-QAM)\uff0c\u5728\u5ef6\u8fdf\u3001\u591a\u666e\u52d2\u548c\u5e45\u5ea6\u4e09\u4e2a\u7ef4\u5ea6\u8c03\u5236\u6570\u636e\n2. \u63a8\u5bfc\u8be5\u8c03\u5236\u65b9\u6848\u7684\u53ef\u8fbe\u901f\u7387\u4ee5\u91cf\u5316\u901a\u4fe1\u6027\u80fd\n3. \u63d0\u51fa\u57fa\u4e8e\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u76844D\u53c2\u6570\u4f30\u8ba1\u65b9\u6848\uff0c\u7528\u4e8e\u52a8\u6001\u73af\u5883\u4e2d\u7684\u65b9\u5411\u89d2\u548c\u5207\u5411\u901f\u5ea6\u4f30\u8ba1\n4. \u63d0\u51fa\u57fa\u4e8e\u53cc\u8865\u507f\u7684\u89e3\u8c03\u4e0e\u8ddf\u8e2a\u65b9\u6848\uff0c\u4f7f\u88ab\u52a8\u8f66\u8f86\u80fd\u6709\u6548\u89e3\u8c03\u6570\u636e\u800c\u4e0d\u5f71\u54cd\u5176\u611f\u77e5\u529f\u80fd", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u5177\u6709\u53ef\u884c\u6027\u4e14\u6027\u80fd\u4f18\u8d8a\uff0c\u5728\u901a\u4fe1\u901f\u7387\u548c\u611f\u77e5\u7cbe\u5ea6\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u63a8\u52a8\u4e86\u81ea\u52a8\u9a7e\u9a76\u9886\u57df\u7684\u53d1\u5c55", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u79cd\u611f\u77e5\u4e2d\u5fc3\u7684\u8054\u5408\u901a\u4fe1\u4e0e\u6beb\u7c73\u6ce2\u96f7\u8fbe\u8303\u5f0f\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u8c03\u5236\u548c\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5b9e\u73b0\u4e86\u667a\u80fd\u8f66\u8f86\u95f4\u901a\u4fe1\u4e0e\u611f\u77e5\u7684\u6709\u6548\u534f\u540c\uff0c\u4e3a\u81ea\u52a8\u9a7e\u9a76\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u6280\u672f\u652f\u6491"}}
{"id": "2512.14436", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14436", "abs": "https://arxiv.org/abs/2512.14436", "authors": ["Jiahui Liang", "Wenlihan Lu", "Tianyi Liu", "Kang Kang", "Guixin Pan", "Liuqing Yang", "Xinhu Zheng", "Shijian Gao"], "title": "Relaying Signal When Monitoring Traffic: Double Use of Aerial Vehicles Towards Intelligent Low-Altitude Networking", "comment": null, "summary": "In intelligent low-altitude networks, integrating monitoring tasks into communication unmanned aerial vehicles (UAVs) can consume resources and increase handoff latency for communication links. To address this challenge, we propose a strategy that enables a \"double use\" of UAVs, unifying the monitoring and relay handoff functions into a single, efficient process. Our scheme, guided by an integrated sensing and communication framework, coordinates these multi-role UAVs through a proactive handoff network that fuses multi-view sensory data from aerial and ground vehicles. A lightweight vehicle inspection module and a two-stage training procedure are developed to ensure monitoring accuracy and collaborative efficiency. Simulation results demonstrate the effectiveness of this integrated approach: it reduces communication outage probability by nearly 10% at a 200 Mbps requirement without compromising monitoring performance and maintains high resilience (86% achievable rate) even in the absence of multiple UAVs, outperforming traditional ground-based handoff schemes. Our code is available at the https://github.com/Jiahui-L/UAP.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u4eba\u673a\u53cc\u91cd\u7528\u9014\u7b56\u7565\uff0c\u5c06\u76d1\u63a7\u548c\u4e2d\u7ee7\u5207\u6362\u529f\u80fd\u7edf\u4e00\u5230\u5355\u4e2a\u9ad8\u6548\u6d41\u7a0b\u4e2d\uff0c\u964d\u4f4e\u901a\u4fe1\u4e2d\u65ad\u6982\u7387\u540c\u65f6\u4fdd\u6301\u76d1\u63a7\u6027\u80fd", "motivation": "\u5728\u667a\u80fd\u4f4e\u7a7a\u7f51\u7edc\u4e2d\uff0c\u5c06\u76d1\u63a7\u4efb\u52a1\u96c6\u6210\u5230\u901a\u4fe1\u65e0\u4eba\u673a\u4e2d\u4f1a\u6d88\u8017\u8d44\u6e90\u5e76\u589e\u52a0\u901a\u4fe1\u94fe\u8def\u5207\u6362\u5ef6\u8fdf\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u6311\u6218", "method": "\u57fa\u4e8e\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u4e3b\u52a8\u5207\u6362\u7f51\u7edc\u534f\u8c03\u591a\u89d2\u8272\u65e0\u4eba\u673a\uff0c\u878d\u5408\u7a7a\u4e2d\u548c\u5730\u9762\u8f66\u8f86\u7684\u591a\u89c6\u89d2\u4f20\u611f\u6570\u636e\uff0c\u5f00\u53d1\u8f7b\u91cf\u7ea7\u8f66\u8f86\u68c0\u6d4b\u6a21\u5757\u548c\u4e24\u9636\u6bb5\u8bad\u7ec3\u7a0b\u5e8f", "result": "\u5728200Mbps\u8981\u6c42\u4e0b\uff0c\u901a\u4fe1\u4e2d\u65ad\u6982\u7387\u964d\u4f4e\u8fd110%\u800c\u4e0d\u5f71\u54cd\u76d1\u63a7\u6027\u80fd\uff0c\u5373\u4f7f\u7f3a\u5c11\u591a\u4e2a\u65e0\u4eba\u673a\u4ecd\u4fdd\u6301\u9ad8\u5f39\u6027\uff0886%\u53ef\u8fbe\u901f\u7387\uff09\uff0c\u4f18\u4e8e\u4f20\u7edf\u5730\u9762\u5207\u6362\u65b9\u6848", "conclusion": "\u96c6\u6210\u65b9\u6cd5\u6709\u6548\u7edf\u4e00\u4e86\u76d1\u63a7\u548c\u4e2d\u7ee7\u5207\u6362\u529f\u80fd\uff0c\u63d0\u9ad8\u4e86\u4f4e\u7a7a\u7f51\u7edc\u7684\u6548\u7387\u548c\u5f39\u6027\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90"}}
{"id": "2512.14488", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.14488", "abs": "https://arxiv.org/abs/2512.14488", "authors": ["Nadia Abdolkhani", "Walaa Hamouda"], "title": "Hybrid Cognitive IoT with Cooperative Caching and SWIPT-EH: A Hierarchical Reinforcement Learning Framework", "comment": "Published in IEEE Internet of Things Journal (Early Access), 2025. This arXiv version is the authors' accepted manuscript", "summary": "This paper proposes a hierarchical deep reinforcement learning (DRL) framework based on the soft actor-critic (SAC) algorithm for hybrid underlay-overlay cognitive Internet of Things (CIoT) networks with simultaneous wireless information and power transfer (SWIPT)-energy harvesting (EH) and cooperative caching. Unlike prior hierarchical DRL approaches that focus primarily on spectrum access or power control, our work jointly optimizes EH, hybrid access coordination, power allocation, and caching in a unified framework. The joint optimization problem is formulated as a weighted-sum multi-objective task, designed to maximize throughput and cache hit ratio while simultaneously minimizing transmission delay. In the proposed model, CIoT agents jointly optimize EH and data transmission using a learnable time switching (TS) factor. They also coordinate spectrum access under hybrid overlay-underlay paradigms and make power control and cache placement decisions while considering energy, interference, and storage constraints. Specifically, in this work, cooperative caching is used to enable overlay access, while power control is used for underlay access. A novel three-level hierarchical SAC (H-SAC) agent decomposes the mixed discrete-continuous action space into modular subproblems, improving scalability and convergence over flat DRL methods. The high-level policy adjusts the TS factor, the mid-level policy manages spectrum access coordination and cache sharing, and the low-level policy decides transmit power and caching actions for both the CIoT agent and PU content. Simulation results show that the proposed hierarchical SAC approach significantly outperforms benchmark and greedy strategies. It achieves better performance in terms of average sum rate, delay, cache hit ratio, and energy efficiency, even under channel fading and uncertain conditions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eSAC\u7b97\u6cd5\u7684\u5206\u5c42\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u4f18\u5316\u5177\u6709SWIPT\u80fd\u91cf\u6536\u96c6\u548c\u534f\u4f5c\u7f13\u5b58\u7684\u6df7\u5408\u8ba4\u77e5\u7269\u8054\u7f51\u7f51\u7edc\uff0c\u8054\u5408\u4f18\u5316\u80fd\u91cf\u6536\u96c6\u3001\u9891\u8c31\u63a5\u5165\u3001\u529f\u7387\u5206\u914d\u548c\u7f13\u5b58\u51b3\u7b56\u3002", "motivation": "\u73b0\u6709\u5206\u5c42DRL\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u9891\u8c31\u63a5\u5165\u6216\u529f\u7387\u63a7\u5236\uff0c\u7f3a\u4e4f\u5bf9\u80fd\u91cf\u6536\u96c6\u3001\u6df7\u5408\u63a5\u5165\u534f\u8c03\u3001\u529f\u7387\u5206\u914d\u548c\u7f13\u5b58\u7684\u8054\u5408\u4f18\u5316\u3002\u8ba4\u77e5\u7269\u8054\u7f51\u7f51\u7edc\u9700\u8981\u540c\u65f6\u5904\u7406\u65e0\u7ebf\u4fe1\u606f\u548c\u80fd\u91cf\u4f20\u8f93\u3001\u534f\u4f5c\u7f13\u5b58\u7b49\u591a\u91cd\u6311\u6218\u3002", "method": "\u63d0\u51fa\u4e09\u5c42\u5206\u5c42SAC\uff08H-SAC\uff09\u4ee3\u7406\u6846\u67b6\uff1a\u9ad8\u5c42\u7b56\u7565\u8c03\u6574\u65f6\u95f4\u5207\u6362\u56e0\u5b50\uff0c\u4e2d\u5c42\u7b56\u7565\u7ba1\u7406\u9891\u8c31\u63a5\u5165\u534f\u8c03\u548c\u7f13\u5b58\u5171\u4eab\uff0c\u4f4e\u5c42\u7b56\u7565\u51b3\u5b9a\u53d1\u5c04\u529f\u7387\u548c\u7f13\u5b58\u52a8\u4f5c\u3002\u5c06\u6df7\u5408\u79bb\u6563-\u8fde\u7eed\u52a8\u4f5c\u7a7a\u95f4\u5206\u89e3\u4e3a\u6a21\u5757\u5316\u5b50\u95ee\u9898\uff0c\u4f7f\u7528\u534f\u4f5c\u7f13\u5b58\u5b9e\u73b0\u8986\u76d6\u63a5\u5165\uff0c\u529f\u7387\u63a7\u5236\u5b9e\u73b0\u5e95\u5c42\u63a5\u5165\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u5206\u5c42SAC\u65b9\u6cd5\u663e\u8457\u4f18\u4e8e\u57fa\u51c6\u548c\u8d2a\u5a6a\u7b56\u7565\uff0c\u5728\u5e73\u5747\u603b\u901f\u7387\u3001\u5ef6\u8fdf\u3001\u7f13\u5b58\u547d\u4e2d\u7387\u548c\u80fd\u91cf\u6548\u7387\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u5373\u4f7f\u5728\u4fe1\u9053\u8870\u843d\u548c\u4e0d\u786e\u5b9a\u6761\u4ef6\u4e0b\u4e5f\u4fdd\u6301\u826f\u597d\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u5206\u5c42SAC\u6846\u67b6\u80fd\u591f\u6709\u6548\u8054\u5408\u4f18\u5316\u8ba4\u77e5\u7269\u8054\u7f51\u7f51\u7edc\u4e2d\u7684\u80fd\u91cf\u6536\u96c6\u3001\u6df7\u5408\u63a5\u5165\u534f\u8c03\u3001\u529f\u7387\u5206\u914d\u548c\u7f13\u5b58\u51b3\u7b56\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5177\u6709\u66f4\u597d\u7684\u53ef\u6269\u5c55\u6027\u548c\u6536\u655b\u6027\uff0c\u4e3a\u590d\u6742\u7f51\u7edc\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.14608", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14608", "abs": "https://arxiv.org/abs/2512.14608", "authors": ["Cole Dickerson", "Sean Kearney", "Sultan Manjur", "Ismail Guvenc", "Sevgi Gurbuz", "Ali Gurbuz", "Ozgur Ozdemir", "Mihail Sichitiu"], "title": "Fusion of Cellular ISAC and Passive RF Sensing for UAV Detection and Tracking", "comment": "Accepted for publication at the 2025 IEEE Asilomar Conference on Signals, Systems, and Computers, Session: UAV Intrusion Detection Using Mobile Communications Networks", "summary": "The rapid growth of unmanned aerial vehicles (UAVs) in civilian and critical-infrastructure airspace has created a need for reliable detection and tracking systems that operate under diverse environmental and sensing conditions. This paper presents a UAV detection and tracking system that fuses measurements from a network of passive Keysight N6841A RF sensors and a Ku-band Fortem TrueView R20 radar operating in the FR3 spectrum (16.3 GHz) as an ISAC proxy. Real-world experiments at the NSF AERPAW testbed demonstrate that radar and RF sensing provide complementary strengths under varying geometric, range, and line-of-sight conditions. A Kalman filter using a constant-velocity motion model integrates the asynchronous 2D RF and 3D radar observations, suppressing large standalone errors, improving accuracy over individual modalities, and increasing tracking coverage without degrading performance. These results demonstrate the effectiveness of multi-modal, ISAC-oriented sensing for robust UAV tracking in outdoor environments.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u878d\u5408\u88ab\u52a8RF\u4f20\u611f\u5668\u548cKu\u6ce2\u6bb5\u96f7\u8fbe\u7684\u591a\u6a21\u6001\u65e0\u4eba\u673a\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\u7cfb\u7edf\uff0c\u901a\u8fc7\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u6574\u5408\u5f02\u6b652D RF\u548c3D\u96f7\u8fbe\u89c2\u6d4b\uff0c\u5728\u771f\u5b9e\u73af\u5883\u4e2d\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u7684\u6709\u6548\u6027\u3002", "motivation": "\u968f\u7740\u65e0\u4eba\u673a\u5728\u6c11\u7528\u548c\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7a7a\u57df\u7684\u5feb\u901f\u589e\u957f\uff0c\u9700\u8981\u80fd\u591f\u5728\u591a\u6837\u5316\u73af\u5883\u548c\u611f\u77e5\u6761\u4ef6\u4e0b\u53ef\u9760\u8fd0\u884c\u7684\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\u7cfb\u7edf\u3002\u73b0\u6709\u5355\u4e00\u4f20\u611f\u5668\u7cfb\u7edf\u5728\u51e0\u4f55\u3001\u8ddd\u79bb\u548c\u89c6\u7ebf\u6761\u4ef6\u53d8\u5316\u65f6\u5b58\u5728\u5c40\u9650\u6027\u3002", "method": "\u7cfb\u7edf\u878d\u5408\u4e86Keysight N6841A RF\u88ab\u52a8\u4f20\u611f\u5668\u7f51\u7edc\u548cKu\u6ce2\u6bb5Fortem TrueView R20\u96f7\u8fbe\uff08FR3\u9891\u8c3116.3 GHz\uff09\u7684\u6d4b\u91cf\u6570\u636e\u3002\u4f7f\u7528\u6052\u5b9a\u901f\u5ea6\u8fd0\u52a8\u6a21\u578b\u7684\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u6574\u5408\u5f02\u6b65\u76842D RF\u548c3D\u96f7\u8fbe\u89c2\u6d4b\u3002", "result": "\u5728NSF AERPAW\u6d4b\u8bd5\u5e8a\u7684\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\u4e2d\uff0c\u96f7\u8fbe\u548cRF\u4f20\u611f\u5728\u4e0d\u540c\u51e0\u4f55\u3001\u8ddd\u79bb\u548c\u89c6\u7ebf\u6761\u4ef6\u4e0b\u8868\u73b0\u51fa\u4e92\u8865\u4f18\u52bf\u3002\u878d\u5408\u7cfb\u7edf\u6291\u5236\u4e86\u5355\u72ec\u4f20\u611f\u5668\u7684\u8f83\u5927\u8bef\u5dee\uff0c\u63d0\u9ad8\u4e86\u7cbe\u5ea6\uff0c\u589e\u52a0\u4e86\u8ddf\u8e2a\u8986\u76d6\u8303\u56f4\u4e14\u4e0d\u964d\u4f4e\u6027\u80fd\u3002", "conclusion": "\u591a\u6a21\u6001\u3001\u9762\u5411ISAC\uff08\u96c6\u6210\u4f20\u611f\u4e0e\u901a\u4fe1\uff09\u7684\u4f20\u611f\u65b9\u6cd5\u5728\u5ba4\u5916\u73af\u5883\u4e2d\u5bf9\u65e0\u4eba\u673a\u8fdb\u884c\u9c81\u68d2\u8ddf\u8e2a\u662f\u6709\u6548\u7684\uff0c\u4e3a\u65e0\u4eba\u673a\u68c0\u6d4b\u4e0e\u8ddf\u8e2a\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.14637", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.14637", "abs": "https://arxiv.org/abs/2512.14637", "authors": ["Bruno Felipe Costa", "Anup Mishra", "Israel Leyva-Mayorga", "Taufik Abr\u00e3o", "Petar Popovski"], "title": "Tunable Gaussian Pulse for Delay-Doppler ISAC", "comment": null, "summary": "Integrated sensing and communication (ISAC) for next-generation networks targets robust operation under high mobility and high Doppler spread, leading to severe inter-carrier interference (ICI) in systems based on orthogonal frequency-division multiplexing (OFDM) waveforms. Delay--Doppler (DD)-domain ISAC offers a more robust foundation under high mobility, but it requires a suitable DD-domain pulse-shaping filter. The prevailing DD pulse designs are either communication-centric or static, which limits adaptation to non-stationary channels and diverse application demands. To address this limitation, this paper introduces the tunable Gaussian pulse (TGP), a DD-native, analytically tunable pulse shape parameterized by its aspect ratio \\( \u03b3\\), chirp rate \\( \u03b1_c \\), and phase coupling \\( \u03b2_c \\). On the sensing side, we derive closed-form Cram\u00e9r--Rao lower bounds (CRLBs) that map \\( (\u03b3,\u03b1_c,\u03b2_c) \\) to fundamental delay and Doppler precision. On the communications side, we show that \\( \u03b1_c \\) and \\( \u03b2_c \\) reshape off-diagonal covariance, and thus inter-symbol interference (ISI), without changing received power, isolating capacity effects to interference structure rather than power loss. A comprehensive trade-off analysis demonstrates that the TGP spans a flexible operational region from the high capacity of the Sinc pulse to the high precision of the root raised cosine (RRC) pulse. Notably, TGP attains near-RRC sensing precision while retaining over \\( 90\\% \\) of Sinc's maximum capacity, achieving a balanced operating region that is not attainable by conventional static pulse designs.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u53ef\u8c03\u9ad8\u65af\u8109\u51b2(TGP)\u7528\u4e8e\u5ef6\u8fdf-\u591a\u666e\u52d2\u57dfISAC\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e09\u4e2a\u53c2\u6570(\u03b3,\u03b1c,\u03b2c)\u5b9e\u73b0\u611f\u77e5\u7cbe\u5ea6\u4e0e\u901a\u4fe1\u5bb9\u91cf\u7684\u7075\u6d3b\u6743\u8861\uff0c\u5728\u4fdd\u630190%\u6700\u5927\u5bb9\u91cf\u7684\u540c\u65f6\u8fbe\u5230\u63a5\u8fd1RRC\u8109\u51b2\u7684\u611f\u77e5\u7cbe\u5ea6\u3002", "motivation": "\u73b0\u6709\u5ef6\u8fdf-\u591a\u666e\u52d2\u57df\u8109\u51b2\u8bbe\u8ba1\u8981\u4e48\u662f\u901a\u4fe1\u4e2d\u5fc3\u578b\u7684\uff0c\u8981\u4e48\u662f\u9759\u6001\u7684\uff0c\u65e0\u6cd5\u9002\u5e94\u975e\u5e73\u7a33\u4fe1\u9053\u548c\u591a\u6837\u5316\u5e94\u7528\u9700\u6c42\u3002\u5728\u9ad8\u79fb\u52a8\u6027\u548c\u5927\u591a\u666e\u52d2\u6269\u5c55\u4e0b\uff0cOFDM\u7cfb\u7edf\u9762\u4e34\u4e25\u91cd\u7684\u8f7d\u6ce2\u95f4\u5e72\u6270\uff0c\u9700\u8981\u66f4\u7a33\u5065\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u53ef\u8c03\u9ad8\u65af\u8109\u51b2(TGP)\uff0c\u8fd9\u662f\u4e00\u79cd\u5ef6\u8fdf-\u591a\u666e\u52d2\u57df\u539f\u751f\u3001\u53ef\u89e3\u6790\u8c03\u5236\u7684\u8109\u51b2\u5f62\u72b6\uff0c\u901a\u8fc7\u4e09\u4e2a\u53c2\u6570\u63a7\u5236\uff1a\u7eb5\u6a2a\u6bd4\u03b3\u3001\u5541\u557e\u7387\u03b1c\u548c\u76f8\u4f4d\u8026\u5408\u03b2c\u3002\u5728\u611f\u77e5\u4fa7\u63a8\u5bfc\u4e86\u95ed\u5f0fCRLB\uff0c\u5c06\u53c2\u6570\u6620\u5c04\u5230\u57fa\u672c\u5ef6\u8fdf\u548c\u591a\u666e\u52d2\u7cbe\u5ea6\uff1b\u5728\u901a\u4fe1\u4fa7\u5206\u6790\u4e86\u53c2\u6570\u5982\u4f55\u91cd\u5851\u79bb\u5bf9\u89d2\u7ebf\u534f\u65b9\u5dee\u548c\u7b26\u53f7\u95f4\u5e72\u6270\u3002", "result": "TGP\u5b9e\u73b0\u4e86\u4eceSinc\u8109\u51b2\u7684\u9ad8\u5bb9\u91cf\u5230\u6839\u5347\u4f59\u5f26(RRC)\u8109\u51b2\u7684\u9ad8\u7cbe\u5ea6\u4e4b\u95f4\u7684\u7075\u6d3b\u64cd\u4f5c\u533a\u57df\u3002\u7279\u522b\u5730\uff0cTGP\u5728\u4fdd\u6301\u8d85\u8fc790% Sinc\u6700\u5927\u5bb9\u91cf\u7684\u540c\u65f6\uff0c\u8fbe\u5230\u4e86\u63a5\u8fd1RRC\u7684\u611f\u77e5\u7cbe\u5ea6\uff0c\u5b9e\u73b0\u4e86\u4f20\u7edf\u9759\u6001\u8109\u51b2\u8bbe\u8ba1\u65e0\u6cd5\u8fbe\u5230\u7684\u5e73\u8861\u64cd\u4f5c\u533a\u57df\u3002", "conclusion": "\u53ef\u8c03\u9ad8\u65af\u8109\u51b2\u4e3a\u5ef6\u8fdf-\u591a\u666e\u52d2\u57dfISAC\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53c2\u6570\u5316\u8109\u51b2\u8bbe\u8ba1\u6846\u67b6\uff0c\u80fd\u591f\u6839\u636e\u5e94\u7528\u9700\u6c42\u5728\u611f\u77e5\u7cbe\u5ea6\u548c\u901a\u4fe1\u5bb9\u91cf\u4e4b\u95f4\u8fdb\u884c\u7075\u6d3b\u6743\u8861\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u9759\u6001\u8109\u51b2\u8bbe\u8ba1\u7684\u5c40\u9650\u6027\u3002"}}

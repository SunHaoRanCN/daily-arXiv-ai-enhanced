<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 14]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.SD](#cs.SD) [Total: 5]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Compensation of Coarse Quantization Effects on Channel Estimation and BER in Massive MIMO](https://arxiv.org/abs/2512.14893)
*Reza Mohammadkhani,Azad Azizzadeh,Seyed Vahab Al-Din Makki,John Thompson,Maziar Nekovee*

Main category: eess.SP

TL;DR: 该论文分析了大规模MIMO系统中低分辨率量化对信道估计和数据传输的影响，提出了基于LMMSE信道估计的BER近似方法，并开发了联合优化量化分辨率、发射功率和导频长度的补偿策略框架。


<details>
  <summary>Details</summary>
Motivation: 5G/6G大规模MIMO系统中，低分辨率量化对于降低实现成本和功耗至关重要。现有研究大多假设完美信道状态信息，但实际系统中量化噪声会影响信道估计和数据传输性能，需要更现实的系统性能评估。

Method: 基于线性最小均方误差(LMMSE)信道估计，开发了零迫检测下未编码M-QAM的误码率(BER)紧密近似方法。该框架联合优化量化分辨率、发射功率和导频长度，考虑不完美CSI条件下的实际量化约束。

Result: 提出的分析框架能够快速准确地评估系统性能，替代蒙特卡洛仿真。在16-QAM系统中，通过将导频序列延长2.5倍并降低发射功率0.5dB，3位量化系统可以达到全分辨率情况下的BER性能。

Conclusion: 该框架为实际量化约束下的系统优化提供了快速准确的替代方案，能够有效优化系统参数并提高能量效率，特别适用于大规模MIMO系统的实际部署场景。

Abstract: Low-resolution quantization is essential to reduce implementation cost and power consumption in massive multiple-input multiple-output (MIMO) systems for 5G and 6G. While most existing studies assume perfect channel state information (CSI), we model the impact of coarse quantization noise on both channel estimation and data transmission, yielding a more realistic assessment of system performance under imperfect CSI conditions in the uplink. We develop a tight approximation for the bit-error ratio (BER) of uncoded M-QAM with zero-forcing detection, based on the linear minimum mean-square error (LMMSE) channel estimate. These analytical results enable compensation strategies that jointly optimize quantization resolution, transmit power, and pilot length across different numbers of users and base station antennas. We further demonstrate the applicability of the proposed framework through several design scenarios that highlight its effectiveness in optimizing system parameters and improving energy efficiency under quantization constraints. For example, in a 16-QAM system, extending the pilot sequence by 2.5 times and lowering transmit power by 0.5 dB enables a 3-bit quantized system to match the BER of the full-resolution case. The proposed framework offers a fast and accurate alternative to Monte Carlo simulations, enabling practical system optimization under realistic quantization constraints.

</details>


### [2] [Janus Metasurface Breaking Polarization Symmetry: Surface-Modulated Electromagnetic Wave Radiation with Coexistent Linear and Circular Polarization](https://arxiv.org/abs/2512.15045)
*Aparna Parameswaran,Hoyoung Kim,Sangkil Kim*

Main category: eess.SP

TL;DR: 提出一种基于Janus超表面的张量阻抗全息天线，能够从单个孔径、单馈源同时辐射线极化和圆极化波束，具有宽带工作特性和低交叉极化


<details>
  <summary>Details</summary>
Motivation: 为了开发能够同时辐射线极化和圆极化波束的先进宽带通信天线，从单个孔径实现多功能辐射，减少交叉极化并提高圆极化纯度

Method: 提出改进的张量阻抗方程来显著降低高辐射角度的交叉极化，使用孔径场积分理论验证设计方法，确保阻抗分布产生所需的远场辐射方向图

Result: 实现了0.5 GHz的宽带工作带宽，同时保持高圆极化纯度，制造了三种变体的全息天线原型，验证了天线性能

Conclusion: 该天线具有优越的辐射特性，是先进宽带通信应用的有吸引力的选择

Abstract: In this work, a Janus metasurface based tensor impedance holographic antenna (JHA) is proposed that simultaneously radiates linearly polarized (LP) and circularly polarized (CP) beams from a single aperture excited by a single feed. The proposed design introduces modified tensor impedance equations to significantly reduce cross-polarization at higher radiation angles. It demonstrates broadband operation bandwidth of 0.5 GHz while maintaining high circular polarization purity. The design methodology is verified using aperture field integration theory, ensuring that the impedance distribution produces the desired far-field radiation patterns. Prototypes of three variations of the holographic antenna are fabricated, validating its performance. The radiation characteristics of the proposed antenna make it an attractive choice for advanced broadband communication applications.

</details>


### [3] [Deep Reinforcement Learning for Joint Time and Power Management in SWIPT-EH CIoT](https://arxiv.org/abs/2512.15062)
*Nadia Abdolkhani,Nada Abdel Khalek,Walaa Hamouda,Iyad Dayoub*

Main category: eess.SP

TL;DR: 提出一种基于深度强化学习的认知物联网系统联合时间分配与功率控制方法，通过可学习的时间切换因子优化能量收集和传输，提升吞吐量和系统寿命。


<details>
  <summary>Details</summary>
Motivation: 认知物联网系统需要同时进行无线信息与能量传输，但传统方法难以在动态信道条件和能量收集约束下实现联合优化。需要一种能够自主管理能量收集与传输的智能方法。

Method: 将联合优化问题建模为马尔可夫决策过程，考虑小尺度衰落、实际能量收集和干扰约束。开发了基于上置信界增强的双深度Q网络（DDQN）方法，通过可学习的时间切换因子自主管理能量收集和传输。

Result: 仿真结果表明，该方法在性能上优于现有的深度强化学习方法，在吞吐量和系统寿命方面表现优异。

Conclusion: 提出的深度强化学习方法能够有效解决认知物联网系统中联合时间分配与功率控制的复杂优化问题，为智能能量管理与传输优化提供了有效解决方案。

Abstract: This letter presents a novel deep reinforcement learning (DRL) approach for joint time allocation and power control in a cognitive Internet of Things (CIoT) system with simultaneous wireless information and power transfer (SWIPT). The CIoT transmitter autonomously manages energy harvesting (EH) and transmissions using a learnable time switching factor while optimizing power to enhance throughput and lifetime. The joint optimization is modeled as a Markov decision process under small-scale fading, realistic EH, and interference constraints. We develop a double deep Q-network (DDQN) enhanced with an upper confidence bound. Simulations benchmark our approach, showing superior performance over existing DRL methods.

</details>


### [4] [CF-Net: A Cross-Feature Reconstruction Network for High-Accuracy 1-Bit Target Classification](https://arxiv.org/abs/2512.15105)
*Jundong Qi,Weize Sun,Shaowu Chen,Lei Huang,Qiuchen Liu*

Main category: eess.SP

TL;DR: 提出CF-Net两阶段深度学习框架，从1-bit雷达数据直接实现高精度目标分类，无需过采样即可达到与16-bit方法相当的精度


<details>
  <summary>Details</summary>
Motivation: 1-bit量化雷达信号具有直接高频采样和简化系统的优势，但极端量化导致信息严重损失。传统过采样补偿方法在高频场景下不实用，需要开发能在相同采样率下从1-bit数据直接实现高精度分类的方法

Method: 提出CF-Net两阶段框架：1）自监督预训练阶段，使用双分支U-Net架构通过跨特征重建任务学习从1-bit图像恢复16-bit图像；2）迁移学习阶段，将预训练的1-bit编码器重新用于下游多类目标分类任务并进行微调

Result: 在两个雷达目标数据集上的实验表明，CF-Net能有效从1-bit图像中提取判别性特征，在不进行过采样的条件下，达到与某些16-bit方法相当甚至更优的分类精度

Conclusion: CF-Net框架成功解决了1-bit雷达数据分类的挑战，通过自监督预训练学习鲁棒特征，实现了在相同采样率下从极端量化数据中直接获得高精度分类性能

Abstract: Target classification is a fundamental task in radar systems, and its performance critically depends on the quantization precision of the signal. While high-precision quantization (e.g. 16-bit) is well established, 1-bit quantization offers distinct advantages by enabling direct sampling at high frequencies and eliminating complex intermediate stages. However, its extreme quantization leads to significant information loss. Although higher sampling rates can compensate for this loss, such oversampling is impractical at the high frequencies targeted for direct sampling. To achieve high-accuracy classification directly from 1-bit radar data under the same sampling rate, this paper proposes a novel two-stage deep learning framework, CF-Net. First, we introduce a self-supervised pre-training strategy based on a dual-branch U-Net architecture. This network learns to restore high-fidelity 16-bit images from their 1-bit counterparts via a cross-feature reconstruction task, forcing the 1-bit encoder to learn robust features despite extreme quantization. Subsequently, this pre-trained encoder is repurposed and fine-tuned for the downstream multi-class target classification task. Experiments on two radar target datasets demonstrate that CF-Net can effectively extract discriminative features from 1-bit imagery, achieving comparable and even superior accuracy to some 16-bit methods without oversampling.

</details>


### [5] [Large Model Enabled Embodied Intelligence for 6G Integrated Perception, Communication, and Computation Network](https://arxiv.org/abs/2512.15109)
*Zhuoran Li,Zhen Gao,Xinhua Liu,Zheng Wang,Xiaotian Zhou,Lei Liu,Yongpeng Wu,Wei Feng,Yongming Huang*

Main category: eess.SP

TL;DR: 本文提出将大型人工智能模型（LAMs）赋能基站，使其成为智能基站代理（IBSAs），实现感知、通信和计算的融合，为6G系统提供安全关键的基础设施。


<details>
  <summary>Details</summary>
Motivation: 6G时代需要将智能置于无线架构的核心，融合感知、通信和计算。传统基站功能单一，无法满足未来智能系统的需求，需要将其升级为具备感知、推理和行动能力的智能代理。

Method: 提出IBSA架构，结合感知-认知-执行流水线与云-边-端协作，采用参数高效适配。研究两个代表性场景：自动驾驶的车路协同感知和无人机安全监控。分析LAM设计训练、高效边缘云推理、多模态感知执行等关键技术。

Result: 建立了IBSA的完整架构框架，提出了涵盖通信性能、感知精度、决策可靠性、安全性和能效的评估框架，为6G安全关键系统提供了可行的技术路径。

Conclusion: LAM赋能的IBSA是实现6G原生感知-通信-计算融合系统的实用路径，但仍需解决基准测试、持续适配、可信决策和标准化等开放挑战。

Abstract: The advent of sixth-generation (6G) places intelligence at the core of wireless architecture, fusing perception, communication, and computation into a single closed-loop. This paper argues that large artificial intelligence models (LAMs) can endow base stations with perception, reasoning, and acting capabilities, thus transforming them into intelligent base station agents (IBSAs). We first review the historical evolution of BSs from single-functional analog infrastructure to distributed, software-defined, and finally LAM-empowered IBSA, highlighting the accompanying changes in architecture, hardware platforms, and deployment. We then present an IBSA architecture that couples a perception-cognition-execution pipeline with cloud-edge-end collaboration and parameter-efficient adaptation. Subsequently,we study two representative scenarios: (i) cooperative vehicle-road perception for autonomous driving, and (ii) ubiquitous base station support for low-altitude uncrewed aerial vehicle safety monitoring and response against unauthorized drones. On this basis, we analyze key enabling technologies spanning LAM design and training, efficient edge-cloud inference, multi-modal perception and actuation, as well as trustworthy security and governance. We further propose a holistic evaluation framework and benchmark considerations that jointly cover communication performance, perception accuracy, decision-making reliability, safety, and energy efficiency. Finally, we distill open challenges on benchmarks, continual adaptation, trustworthy decision-making, and standardization. Together, this work positions LAM-enabled IBSAs as a practical path toward integrated perception, communication, and computation native, safety-critical 6G systems.

</details>


### [6] [QoS-Aware Hierarchical Reinforcement Learning for Joint Link Selection and Trajectory Optimization in SAGIN-Supported UAV Mobility Management](https://arxiv.org/abs/2512.15119)
*Jiayang Wan,Ke He,Yafei Wang,Fan Liu,Wenjin Wang,Shi Jin*

Main category: eess.SP

TL;DR: 提出一种基于分层深度强化学习的无人机空天地一体化网络移动管理框架，通过DDQN和约束SAC算法分别处理离散链路选择和连续轨迹优化，显著提升吞吐量和服务质量


<details>
  <summary>Details</summary>
Motivation: 无人机在三维空间中移动时，单一网络难以保证连续可靠的覆盖，而空天地一体化网络(SAGIN)中异构网络的覆盖范围和信号特性差异显著，需要有效的移动管理方案

Method: 提出两级多智能体分层深度强化学习框架：顶层使用双深度Q网络(DDQN)处理离散链路选择；底层采用基于拉格朗日的约束软演员-评论家(CSAC)算法处理连续轨迹优化并满足服务质量约束；支持多无人机场景下的集中训练分散执行

Result: 仿真结果表明，所提方案在吞吐量、链路切换频率和服务质量满意度方面显著优于现有基准方法

Conclusion: 该分层深度强化学习框架有效解决了空天地一体化网络中无人机移动管理的多目标联合优化问题，实现了离散链路选择和连续轨迹优化的协同优化

Abstract: Due to the significant variations in unmanned aerial vehicle (UAV) altitude and horizontal mobility, it becomes difficult for any single network to ensure continuous and reliable threedimensional coverage. Towards that end, the space-air-ground integrated network (SAGIN) has emerged as an essential architecture for enabling ubiquitous UAV connectivity. To address the pronounced disparities in coverage and signal characteristics across heterogeneous networks, this paper formulates UAV mobility management in SAGIN as a constrained multi-objective joint optimization problem. The formulation couples discrete link selection with continuous trajectory optimization. Building on this, we propose a two-level multi-agent hierarchical deep reinforcement learning (HDRL) framework that decomposes the problem into two alternately solvable subproblems. To map complex link selection decisions into a compact discrete action space, we conceive a double deep Q-network (DDQN) algorithm in the top-level, which achieves stable and high-quality policy learning through double Q-value estimation. To handle the continuous trajectory action space while satisfying quality of service (QoS) constraints, we integrate the maximum-entropy mechanism of the soft actor-critic (SAC) and employ a Lagrangian-based constrained SAC (CSAC) algorithm in the lower-level that dynamically adjusts the Lagrange multipliers to balance constraint satisfaction and policy optimization. Moreover, the proposed algorithm can be extended to multi-UAV scenarios under the centralized training and decentralized execution (CTDE) paradigm, which enables more generalizable policies. Simulation results demonstrate that the proposed scheme substantially outperforms existing benchmarks in throughput, link switching frequency and QoS satisfaction.

</details>


### [7] [Enhancing Alzheimer's Detection through Late Fusion of Multi-Modal EEG Features](https://arxiv.org/abs/2512.15246)
*Nguyen Thanh Vinh,Manoj Vishwanath,Thinh Nguyen-Quang,Nguyen Viet Ha,Bui Thanh Tung,Huy-Dung Han,Nguyen Quang Linh,Nguyen Hai Linh,Hung Cao*

Main category: eess.SP

TL;DR: 提出一种基于EEG信号的深度学习框架，通过多特征提取和晚期融合策略实现阿尔茨海默病的早期诊断，准确率达87.23%


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病早期检测对及时干预至关重要，传统诊断方法耗时且需要专家解读，需要自动化方法

Method: 使用EEG信号，集成alpha波分析、离散小波变换和马尔可夫转移场等多特征提取技术，采用晚期融合策略结合不同神经网络预测

Result: 在公开数据集上获得87.23%准确率、87.95%精确率、86.91%召回率和87.42% F1分数

Conclusion: 该深度学习框架展示了可靠、可扩展的早期AD筛查潜力，有望为医生提供高效便捷的诊断工具

Abstract: Alzheimer s disease (AD) is a progressive neurodegenerative disorder characterized by cognitive decline, where early detection is essential for timely intervention and improved patient outcomes. Traditional diagnostic methods are time-consuming and require expert interpretation, thus, automated approaches are highly desirable. This study presents a novel deep learning framework for AD diagnosis using Electroencephalograph (EEG) signals, integrating multiple feature extraction techniques including alpha-wave analysis, Discrete Wavelet Transform (DWT), and Markov Transition Fields (MTF). A late-fusion strategy is employed to combine predictions from separate neural networks trained on these diverse representations, capturing both temporal and frequency-domain patterns in the EEG data. The proposed model attains a classification accuracy of 87.23%, with a precision of 87.95%, a recall of 86.91%, and an F1 score of 87.42% when evaluated on a publicly available dataset, demonstrating its potential for reliable, scalable, and early AD screening. Rigorous preprocessing and targeted frequency band selection, particularly in the alpha range due to its cognitive relevance, further enhance performance. This work highlights the promise of deep learning in supporting physicians with efficient and accessible tools for early AD diagnosis.

</details>


### [8] [Dataset and UAV Propagation Channel Modeling for LoRa in the 860 MHz ISM Band](https://arxiv.org/abs/2512.15268)
*Joachim Tapparel,Andreas Burg*

Main category: eess.SP

TL;DR: 本文通过SDR测试平台收集并发布了校园环境中的LoRa帧数据集，利用该数据推导了无人机视距、无人机非视距和行人非视距三种场景下的经验传播信道模型，并提供了同步信息用于接收机算法评估。


<details>
  <summary>Details</summary>
Motivation: 随着物联网网络快速密集化，需要针对LoRa传输特性（长距离、小带宽）建立专门的信道模型来评估网络性能，而现有蜂窝技术的信道模型不适用于LoRa。

Method: 使用基于SDR的测试平台收集校园环境中LoRa帧的IQ样本数据集，包含多个接收位置的帧数据，利用这些数据推导三种场景（无人机视距、无人机非视距、行人非视距）的经验传播信道模型。

Result: 发布了包含高时间分辨率信道变化的LoRa帧数据集，建立了包含接收器距离相关性的经验传播信道模型，数据集还包含同步信息可用于接收机算法评估。

Conclusion: 该工作为LoRa网络性能评估提供了专门的信道模型和实验数据集，填补了LoRa特定信道建模的空白，支持未来LoRa网络优化和接收机算法开发。

Abstract: LoRa is one of the most widely used low-power wide-area network technology for the Internet of Things. To achieve long-range communication with low power consumption at a low cost, LoRa uses a chirp spread spectrum modulation and transmits in the sub-GHz unlicensed industrial, scientific, and medical (ISM) frequency bands. Due to the rapid densification of IoT networks, it is crucial to obtain tailored channel models to evaluate the performance of LoRa networks. While channel models for cellular technologies have been investigated extensively, specific characteristics of LoRa transmissions operating at long range with a rather small (~ 250kHz) bandwidth require dedicated measurement campaigns and modeling efforts. In this work, we leverage an SDR-based testbed to gather and publish a dataset of LoRa frames transmitted in a campus environment. The dataset includes IQ samples of the received frames at multiple locations and allows for the evaluation of channel variations with high time resolution. Using the gathered data, we derive empirical propagation channel models for LoRa that include receiver correlation over distance for three scenarios: unmanned aerial vehicle (UAV) line-of-sight (LoS), UAV non-LoS, and pedestrian non-LoS. Furthermore, the dataset is annotated with synchronization information, enabling the evaluation of receiver algorithms using experimental data.

</details>


### [9] [Learning-Based Phase Shift Optimization of Liquid Crystal RIS in Dynamic mmWave Networks](https://arxiv.org/abs/2512.15279)
*Le Hao,Robin Neuder,Mohamadreza Delbari,Alejandro Jiménez-Sáez,Vahid Jamali,Arash Asadi,Andrea Ortiz*

Main category: eess.SP

TL;DR: 提出基于强化学习的LC-RIS相位优化框架，解决液晶可重构智能表面在动态场景中重配置时间过长的问题，通过DDPG算法自适应控制相位以最大化移动用户数据速率。


<details>
  <summary>Details</summary>
Motivation: 毫米波通信中，传统半导体RIS存在功耗高、扩展性差的问题，而液晶RIS(LC-RIS)虽然能效高、成本低，但重配置时间长达数十毫秒，限制了其在动态场景中的应用。现有研究多关注硬件设计或静态场景，缺乏针对动态环境的优化解决方案。

Method: 提出基于强化学习的优化框架，采用深度确定性策略梯度(DDPG)算法动态控制LC-RIS相位偏移。该算法不需要完美信道状态信息，能够平衡信噪比(SNR)与配置时间之间的权衡。

Result: 通过高保真射线追踪仿真验证方法有效性，利用LC-RIS原型测量数据进行评估。结果表明该解决方案能够为动态LC-RIS辅助毫米波系统带来自适应控制能力。

Conclusion: 本文填补了LC-RIS在动态场景优化方面的研究空白，提出的强化学习框架能够有效解决液晶RIS重配置时间长的限制，为动态毫米波通信系统提供了可行的自适应控制方案。

Abstract: To enhance coverage and signal quality in millimeter-wave (mmWave) frequencies, reconfigurable intelligent surfaces (RISs) have emerged as a game-changing solution to manipulate the wireless environment. Traditional semiconductor-based RISs face scalability issues due to high power consumption. Meanwhile, liquid crystal-based RISs (LC-RISs) offer energy-efficient and cost-effective operation even for large arrays. However, this promise has a caveat. LC-RISs suffer from long reconfiguration times, on the order of tens of milliseconds, which limits their applicability in dynamic scenarios. To date, prior works have focused on hardware design aspects or static scenarios to address this limitation, but little attention has been paid to optimization solutions for dynamic settings. Our paper fills this gap by proposing a reinforcement learning-based optimization framework to dynamically control the phase shifts of LC-RISs and maximize the data rate of a moving user. Specifically, we propose a Deep Deterministic Policy Gradient (DDPG) algorithm that adapts the LC-RIS phase shifts without requiring perfect channel state information and balances the tradeoff between signal-to-noise ratio (SNR) and configuration time. We validate our approach through high-fidelity ray tracing simulations, leveraging measurement data from an LC-RIS prototype. Our results demonstrate the potential of our solution to bring adaptive control to dynamic LC-RIS-assisted mmWave systems.

</details>


### [10] [Moment-Matching Array Processing Technique for diffuse source estimation](https://arxiv.org/abs/2512.15283)
*Colin Cros,Laurent Ferro-Famil*

Main category: eess.SP

TL;DR: MoMET是一种低复杂度方法，用于估计窄带扩散源的平均DOA、扩展和功率，无需源分布的先验知识。


<details>
  <summary>Details</summary>
Motivation: 传统DOA估计方法通常基于对源角度分布的特定函数假设，当这些假设不正确时会导致显著的估计偏差。需要一种不依赖先验分布假设的鲁棒估计方法。

Method: 通过矩匹配估计技术，将未知源密度用其平均DOA和前几个中心矩来表征，通过协方差匹配技术将测量值的经验协方差与矩建模的协方差进行拟合。

Result: MoMET参数化对错误模型假设具有鲁棒性，数值计算高效。推导了估计器的渐近偏差和协方差，并通过仿真验证了其性能。

Conclusion: MoMET提供了一种无需先验分布知识的低复杂度DOA估计方法，对扩散源的平均DOA、扩展和功率估计具有鲁棒性和有效性。

Abstract: Direction of Arrival (DOA) estimation is a fundamental problem in signal processing. Diffuse sources, whose power density cannot be represented with a single angular coordinate, are usually characterized based on prior assumptions, which associate the source angular density with a specific set of functions. However, these assumptions can lead to significant estimation biases when they are incorrect. This paper introduces the Moment-Matching Estimation Technique (MoMET), a low-complexity method for estimating the mean DOA, spread, and power of a narrow diffuse source without requiring prior knowledge on the source distribution. The unknown source density is characterized by its mean DOA and its first central moments, which are estimated through covariance matching techniques which fit the empirical covariance of the measurements to that modeled from the moments. The MoMET parameterization is robust to incorrect model assumptions, and numerically efficient. The asymptotic bias and covariance of the new estimator are derived and its performance is demonstrated through simulations.

</details>


### [11] [On the Asymptotic Performance of Diagonally Loaded Detectors for Large Arrays: To Achieve CFAR and Optimality](https://arxiv.org/abs/2512.15290)
*Jie Zhou,Junhao Xie*

Main category: eess.SP

TL;DR: 本文解决了对角加载自适应匹配滤波器（DL-AMF）的两个关键限制：缺乏对任意协方差矩阵的CFAR特性，以及从最大化检测概率角度缺乏最优加载因子选择标准。通过大维渐近分析，提出了两种CFAR DL检测器，并推导了渐近最优加载因子。


<details>
  <summary>Details</summary>
Motivation: 传统DL-AMF检测器存在两个主要问题：1）对于任意协方差矩阵不具备恒虚警率（CFAR）特性；2）缺乏从最大化检测概率角度选择最优加载因子的标准。这些问题限制了DL-AMF在实际应用中的性能。

Method: 采用大维渐近分析框架，其中维度N和样本量K趋于无穷大，其比值收敛于常数c∈(0,1)。通过理论分析证明，任何通过确定性量或几乎必然收敛于确定性量的随机变量归一化构造的DL检测器在大维渐近下具有等效性能。基于此，提出了两种CFAR DL检测器：CFAR-DL-SCMF和CFAR-DL-AMF，并推导了渐近最优加载因子λ_opt。

Result: 理论分析和仿真表明，提出的CFAR-DL-SCMF和CFAR-DL-AMF对协方差矩阵、目标导向向量和加载因子均具有CFAR特性。推导出的渐近最优加载因子λ_opt能最大化检测概率。基于λ_opt及其一致估计，建立了最优CFAR检测器opt-CFAR-DL-SCMF和opt-CFAR-DL-AMF。

Conclusion: 本文成功解决了DL-AMF的两个关键限制，提出了具有CFAR特性的DL检测器，并提供了最优加载因子的理论推导和实用估计方法。数值实验表明，提出的最优CFAR检测器在满秩和低秩杂波加噪声环境中均优于现有方法。

Abstract: This paper addresses two critical limitations in diagonally loaded (DL) adaptive matched filter (AMF) detector: (1) the lack of CFAR property with respect to arbitrary covariance matrices, and (2) the absence of selection criteria for optimal loading factor from the perspective of maximizing the detection probability (Pd). We provide solutions to both challenges through a comprehensive analysis for the asymptotic performance of DL-AMF under large dimensional regime (LDR) where the dimension N and sample size K tend to infinity whereas their ratio N/K converges to a constant c\in(0,1). The analytical results show that any DL detectors constructed by normalizing the random variable |a|2=|sH(R+λIN)-1y0|2 with a deterministic quantity or a random variable that converges almost surely to a deterministic value will exhibit equivalent performance under LDR. Following this idea, we derive two CFAR DL detectors: CFAR DL semi-clairvoyant matched filter (CFAR-DL-SCMF) detector and CFAR DL adaptive matched filter (CFAR-DL-AMF) detector, by normalizing |a|2 with an appropriate deterministic quantity and its consistent estimate, respectively. The theoretical analysis and simulations show that both CFAR-DL-SCMF and CFAR-DL-AMF achieve CFAR with respect to covariance matrix, target steering vector and loading factor. Furthermore, we derive the asymptotically optimal loading factor λ_opt by maximizing the explicit expression of asymptotic Pd. For practical implementation, we provide a consistent estimator for λ_opt under LDR. Based on λ_opt and its consistent estimate, we establish the optimal CFAR-DL-SCMF (opt-CFAR-DL-SCMF) and the optimal CFAR-DL-AMF (opt-CFAR-DL-AMF). Numerical examples demonstrate that the proposed opt-CFAR-DL-SCMF and opt-CFAR-DL-AMF consistently outperform EL-AMF and persymmetric AMF in both full-rank and low-rank clutter plus noise environments.

</details>


### [12] [Semi-Blind Joint Channel and Symbol Estimation for Beyond Diagonal Reconfigurable Surfaces](https://arxiv.org/abs/2512.15441)
*Gilderlan Tavares de Araújo,André L. F. de Almeida Buno Sokal,Gabor Fodor,Paulo R. B. Gomes*

Main category: eess.SP

TL;DR: 本文提出了一种基于张量分解的半盲信道估计方法，用于BD-RIS系统，无需训练序列，通过数据符号直接进行联合信道和符号估计。


<details>
  <summary>Details</summary>
Motivation: BD-RIS（超对角可重构智能表面）通过散射单元互连增强了波束控制自由度，但复杂的连接和更多系数使得信道估计比传统RIS更具挑战性。现有方法依赖导频辅助估计，本文旨在消除训练序列需求。

Method: 提出两种半盲接收器：1）两阶段方法，将四阶PARATUCK模型转换为三阶PARAFAC模型；2）单阶段迭代方法，基于四阶TUCKER分解。两种方法都从张量分解角度重构接收信号，考虑时变用户终端-RIS信道。

Result: 推导了可靠联合恢复的可识别性条件，数值结果表明所提方案在性能上优于现有解决方案，并展示了不同方案间的权衡。

Conclusion: 提出的半盲张量方法有效解决了BD-RIS系统的信道估计挑战，无需训练序列，在移动性场景下实现了联合信道和符号估计，为实际部署提供了可行方案。

Abstract: The beyond-diagonal reconfigurable intelligent surface (BD-RIS) is a recent architecture in which scattering elements are interconnected to enhance the degrees of freedom for wave control, yielding performance gains over traditional single-connected RISs. For BD-RIS, channel estimation - well-studied for conventional RIS - becomes more challenging due to the complex connections and a larger number of coefficients. Prior works rely on pilot-assisted estimation followed by data decoding. This paper introduces a semi-blind tensor-based approach for joint channel and symbol estimation that eliminates the need for training sequences by leveraging data symbols directly. A practical scenario with time-varying user terminal-RIS channels under mobility is considered. By reformulating the received signal from a tensor decomposition perspective, we develop two semi-blind receivers: a two-stage method transforming the fourth-order PARATUCK model into a third-order PARAFAC model, and a single-stage iterative process based on fourth-order TUCKER decomposition. Identifiability conditions for reliable joint recovery are derived, and numerical results demonstrate the performance advantages and trade-offs of the proposed schemes over existing solutions.

</details>


### [13] [Optimum Discrete Beamforming via Minkowski Sum of Polygons](https://arxiv.org/abs/2512.15546)
*Heedong Do,Angel Lozano*

Main category: eess.SP

TL;DR: 该论文将最优离散波束成形问题转化为凸多边形Minkowski和的计算，证明该问题可高效求解。


<details>
  <summary>Details</summary>
Motivation: 传统离散波束成形优化问题计算复杂度高，需要寻找更高效直观的解决方案。

Method: 将离散波束成形问题重新表述为凸多边形的Minkowski和计算问题，利用凸多边形Minkowski和的性质（结果仍为凸多边形且顶点数有界）实现高效计算。

Result: 证明最优波束成形解可以通过计算凸多边形的Minkowski和高效获得，该Minkowski和本身也是凸多边形，其顶点数最多为原始多边形顶点数之和。

Conclusion: 通过将离散波束成形问题转化为凸多边形Minkowski和计算，提供了一种原始且直观的表述，证实了最优波束成形解可以高效找到。

Abstract: This letter casts the problem of optimum discrete beamforming as the computation of the Minkowski sum of convex polygons, which is itself a convex polygon. The number of vertices of the latter is at most the sum of the number of vertices of the original polygons, enabling its efficient computation. This original and intuitive formulation confirms that the optimum beamforming solution can be found efficiently.

</details>


### [14] [Deep Reinforcement Learning for EH-Enabled Cognitive-IoT Under Jamming Attacks](https://arxiv.org/abs/2512.15558)
*Nadia Abdolkhani,Nada Abdel Khalek,Walaa Hamouda*

Main category: eess.SP

TL;DR: 提出基于深度强化学习的认知物联网抗干扰方案，通过DDQN和UCB-IA算法优化吞吐量和网络寿命


<details>
  <summary>Details</summary>
Motivation: 认知物联网面临频谱稀缺和无线电干扰攻击的挑战，需要智能的抗干扰和能量管理方案

Method: 采用深度强化学习框架，将问题建模为无模型马尔可夫决策过程，开发DDQN算法和UCB-IA变体，实现自主能量收集、数据传输和功率控制

Result: 仿真表明提出的DRL算法优于现有基准，实现了更自适应、节能和安全的频谱共享

Conclusion: 提出的DRL框架能有效应对认知物联网中的干扰攻击，优化系统性能，为安全频谱共享提供新方案

Abstract: In the evolving landscape of the Internet of Things (IoT), integrating cognitive radio (CR) has become a practical solution to address the challenge of spectrum scarcity, leading to the development of cognitive IoT (CIoT). However, the vulnerability of radio communications makes radio jamming attacks a key concern in CIoT networks. In this paper, we introduce a novel deep reinforcement learning (DRL) approach designed to optimize throughput and extend network lifetime of an energy-constrained CIoT system under jamming attacks. This DRL framework equips a CIoT device with the autonomy to manage energy harvesting (EH) and data transmission, while also regulating its transmit power to respect spectrum-sharing constraints. We formulate the optimization problem under various constraints, and we model the CIoT device's interactions within the channel as a model-free Markov decision process (MDP). The MDP serves as a foundation to develop a double deep Q-network (DDQN), designed to help the CIoT agent learn the optimal communication policy to navigate challenges such as dynamic channel occupancy, jamming attacks, and channel fading while achieving its goal. Additionally, we introduce a variant of the upper confidence bound (UCB) algorithm, named UCB-IA, which enhances the CIoT network's ability to efficiently navigate jamming attacks within the channel. The proposed DRL algorithm does not rely on prior knowledge and uses locally observable information such as channel occupancy, jamming activity, channel gain, and energy arrival to make decisions. Extensive simulations prove that our proposed DRL algorithm that utilizes the UCB-IA strategy surpasses existing benchmarks, allowing for a more adaptive, energy-efficient, and secure spectrum sharing in CIoT networks.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [15] [On the Use of Self-Supervised Representation Learning for Speaker Diarization and Separation](https://arxiv.org/abs/2512.15224)
*Séverin Baroudi,Hervé Bredin,Joseph Razik,Ricard Marxer*

Main category: eess.AS

TL;DR: 评估自监督语音模型在说话人分离和语音分离任务上的表现，发现现有基准存在多样性不足的问题


<details>
  <summary>Details</summary>
Motivation: 尽管自监督语音模型（如wav2vec2.0和WavLM）在许多下游任务中表现出色，但在说话人分离和语音分离任务上的评估仍然有限，需要更全面的评估

Method: 调查最近的自监督语音表示在这两个说话人身份相关任务上的质量，分析现有基准的局限性

Result: 发现当前文献存在空白，主要源于现有基准的限制，特别是评估数据集缺乏多样性和下游系统种类不足

Conclusion: 需要更全面、多样化的评估基准来准确评估自监督语音模型在说话人分离和语音分离任务上的表现

Abstract: Self-supervised speech models such as wav2vec2.0 and WavLM have been shown to significantly improve the performance of many downstream speech tasks, especially in low-resource settings, over the past few years. Despite this, evaluations on tasks such as Speaker Diarization and Speech Separation remain limited. This paper investigates the quality of recent self-supervised speech representations on these two speaker identity-related tasks, highlighting gaps in the current literature that stem from limitations in the existing benchmarks, particularly the lack of diversity in evaluation datasets and variety in downstream systems associated to both diarization and separation.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [16] [Audio MultiChallenge: A Multi-Turn Evaluation of Spoken Dialogue Systems on Natural Human Interaction](https://arxiv.org/abs/2512.14865)
*Advait Gosai,Tyler Vuong,Utkarsh Tyagi,Steven Li,Wenjia You,Miheer Bavare,Arda Uçar,Zhongwang Fang,Brian Jang,Bing Liu,Yunzhong He*

Main category: cs.SD

TL;DR: Audio MultiChallenge：首个评估端到端语音对话系统在多轮自然对话中能力的开源基准，包含4个评估维度，揭示前沿模型在真实语音交互中仍存在显著挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估合成语音和单轮任务，缺乏对真实多轮对话能力的评估。端到端语音对话系统直接处理原始音频，需要更全面的评估框架来测试其在自然多轮交互中的表现。

Method: 基于文本MultiChallenge框架，引入新的Voice Editing维度，并将所有维度扩展到音频模态（如Audio-Cue挑战）。通过混合音频原生代理和人工参与流程，从47位说话者中收集452个对话，包含1,712个实例特定评分标准。

Result: 评估显示前沿模型在基准上表现不佳，最佳模型Gemini 3 Pro Preview（Thinking）通过率仅为54.65%。错误分析表明模型在新维度和长音频上下文的自洽性方面失败最多，反映出在跟踪编辑、音频线索和长范围上下文方面的困难。

Conclusion: Audio MultiChallenge提供了一个可复现的测试平台，能够量化端到端语音对话系统在自然多轮交互中的能力缺陷，推动音频原生多轮交互能力的改进。

Abstract: End-to-end (E2E) spoken dialogue systems are increasingly replacing cascaded pipelines for voice-based human-AI interaction, processing raw audio directly without intermediate transcription. Existing benchmarks primarily evaluate these models on synthetic speech and single-turn tasks, leaving realistic multi-turn conversational ability underexplored. We introduce Audio MultiChallenge, an open-source benchmark to evaluate E2E spoken dialogue systems under natural multi-turn interaction patterns. Building on the text-based MultiChallenge framework, which evaluates Inference Memory, Instruction Retention, and Self Coherence, we introduce a new axis Voice Editing that tests robustness to mid-utterance speech repairs and backtracking. We further augment each axis to the audio modality, such as introducing Audio-Cue challenges for Inference Memory that require recalling ambient sounds and paralinguistic signals beyond semantic content. We curate 452 conversations from 47 speakers with 1,712 instance-specific rubrics through a hybrid audio-native agentic and human-in-the-loop pipeline that exposes model failures at scale while preserving natural disfluencies found in unscripted human speech. Our evaluation of proprietary and open-source models reveals that even frontier models struggle on our benchmark, with Gemini 3 Pro Preview (Thinking), our highest-performing model achieving a 54.65% pass rate. Error analysis shows that models fail most often on our new axes and that Self Coherence degrades with longer audio context. These failures reflect difficulty of tracking edits, audio cues, and long-range context in natural spoken dialogue. Audio MultiChallenge provides a reproducible testbed to quantify them and drive improvements in audio-native multi-turn interaction capability.

</details>


### [17] [A Conditioned UNet for Music Source Separation](https://arxiv.org/abs/2512.15532)
*Ken O'Hanlon,Basil Woods,Lin Wang,Mark Sandler*

Main category: cs.SD

TL;DR: 提出QSCNet，一种用于音乐源分离的条件化UNet架构，在性能上优于现有方法Banquet，参数量更少


<details>
  <summary>Details</summary>
Motivation: 传统音乐源分离方法需要预定义乐器词汇表，而条件化方法通过音频查询可以更灵活地分离任意音源。现有研究认为UNet不适合条件化音乐源分离，本文旨在反驳这一观点

Method: 提出QSCNet，一种新颖的条件化UNet架构，将网络条件化元素集成到用于音乐源分离的稀疏压缩网络中

Result: QSCNet在多个音乐源分离任务上比Banquet方法高出超过1dB SNR，同时使用不到一半的参数数量

Conclusion: UNet架构确实适用于条件化音乐源分离任务，QSCNet证明了其在性能和效率上的优势，为更灵活的音乐源分离提供了有效解决方案

Abstract: In this paper we propose a conditioned UNet for Music Source Separation (MSS). MSS is generally performed by multi-output neural networks, typically UNets, with each output representing a particular stem from a predefined instrument vocabulary. In contrast, conditioned MSS networks accept an audio query related to a stem of interest alongside the signal from which that stem is to be extracted. Thus, a strict vocabulary is not required and this enables more realistic tasks in MSS. The potential of conditioned approaches for such tasks has been somewhat hidden due to a lack of suitable data, an issue recently addressed with the MoisesDb dataset. A recent method, Banquet, employs this dataset with promising results seen on larger vocabularies. Banquet uses Bandsplit RNN rather than a UNet and the authors state that UNets should not be suitable for conditioned MSS. We counter this argument and propose QSCNet, a novel conditioned UNet for MSS that integrates network conditioning elements in the Sparse Compressed Network for MSS. We find QSCNet to outperform Banquet by over 1dB SNR on a couple of MSS tasks, while using less than half the number of parameters.

</details>


### [18] [Synaspot: A Lightweight, Streaming Multi-modal Framework for Keyword Spotting with Audio-Text Synergy](https://arxiv.org/abs/2512.15124)
*Kewei Li,Yinan Zhong,Xiaotao Liang,Tianchi Dai,Shaofei Xue*

Main category: cs.SD

TL;DR: 提出轻量级流式多模态关键词检测框架，通过减少语音注册中的说话人信息、有效融合语音文本特征，以及仅需编码器提取特征的流式解码，实现更好性能且参数更少。


<details>
  <summary>Details</summary>
Motivation: 连续语音流中的开放词汇关键词检测具有重要实用价值，但现有多模态方法存在参数成本高和端到端部署限制的问题，限制了实际应用。

Method: 1. 关注多模态注册特征，减少语音注册中的说话人特定信息以提取说话人不相关特征；2. 有效融合语音和文本特征；3. 引入流式解码框架，仅需编码器提取特征，然后通过三种模态表示进行数学解码。

Result: 在LibriPhase和WenetPrase数据集上的实验表明，相比现有流式方法，该方法以显著更少的参数实现了更好的性能。

Conclusion: 提出的轻量级流式多模态框架解决了多模态关键词检测中的参数成本和部署限制问题，在保持高性能的同时大幅减少了模型参数，具有更好的实际应用价值。

Abstract: Open-vocabulary keyword spotting (KWS) in continuous speech streams holds significant practical value across a wide range of real-world applications. While increasing attention has been paid to the role of different modalities in KWS, their effectiveness has been acknowledged. However, the increased parameter cost from multimodal integration and the constraints of end-to-end deployment have limited the practical applicability of such models. To address these challenges, we propose a lightweight, streaming multi-modal framework. First, we focus on multimodal enrollment features and reduce speaker-specific (voiceprint) information in the speech enrollment to extract speaker-irrelevant characteristics. Second, we effectively fuse speech and text features. Finally, we introduce a streaming decoding framework that only requires the encoder to extract features, which are then mathematically decoded with our three modal representations. Experiments on LibriPhase and WenetPrase demonstrate the performance of our model. Compared to existing streaming approaches, our method achieves better performance with significantly fewer parameters.

</details>


### [19] [BEAT2AASIST model with layer fusion for ESDD 2026 Challenge](https://arxiv.org/abs/2512.15180)
*Sanghyeok Chung,Eujin Kim,Donggun Kim,Gaeun Heo,Jeongbin You,Nahyun Lee,Sunmook Choi,Soyul Han,Seungsang Oh,Il-Youp Kwak*

Main category: cs.SD

TL;DR: BEAT2AASIST模型通过双分支处理和特征融合策略，在环境声音深度伪造检测挑战中取得竞争性表现


<details>
  <summary>Details</summary>
Motivation: 音频生成技术的进步增加了环境声音被恶意操纵的风险，需要建立大规模的环境声音深度伪造检测基准

Method: 扩展BEATs-AASIST模型，将BEATs特征沿频率或通道维度分割，用双AASIST分支处理；采用top-k transformer层融合策略（拼接、CNN门控、SE门控）；使用声码器数据增强提升鲁棒性

Result: 在官方测试集上，所提方法在挑战赛各赛道中取得了竞争性的性能表现

Conclusion: BEAT2AASIST模型通过多分支架构和特征融合策略，为环境声音深度伪造检测提供了有效的解决方案

Abstract: Recent advances in audio generation have increased the risk of realistic environmental sound manipulation, motivating the ESDD 2026 Challenge as the first large-scale benchmark for Environmental Sound Deepfake Detection (ESDD). We propose BEAT2AASIST which extends BEATs-AASIST by splitting BEATs-derived representations along frequency or channel dimension and processing them with dual AASIST branches. To enrich feature representations, we incorporate top-k transformer layer fusion using concatenation, CNN-gated, and SE-gated strategies. In addition, vocoder-based data augmentation is applied to improve robustness against unseen spoofing methods. Experimental results on the official test sets demonstrate that the proposed approach achieves competitive performance across the challenge tracks.

</details>


### [20] [Time-Varying Audio Effect Modeling by End-to-End Adversarial Training](https://arxiv.org/abs/2512.15313)
*Yann Bourdin,Pierrick Legrand,Fanny Roche*

Main category: cs.SD

TL;DR: 提出基于GAN的框架，仅使用输入-输出音频录音来建模时变音频效果，无需调制信号提取


<details>
  <summary>Details</summary>
Motivation: 传统黑盒建模方法对时变音频效果存在问题，需要录制或提取控制信号以确保时间对齐，这在实际应用中很困难

Method: 采用卷积-循环架构，通过两阶段训练策略：1) 对抗训练阶段学习调制行为分布；2) 监督微调阶段使用状态预测网络估计初始内部状态以实现同步

Result: 实验建模老式硬件移相器效果，证明该方法能够在完全黑盒环境下准确捕捉时变动态特性

Conclusion: 该方法成功解决了时变音频效果的黑盒建模问题，无需调制信号提取，为音频效果建模提供了更实用的解决方案

Abstract: Deep learning has become a standard approach for the modeling of audio effects, yet strictly black-box modeling remains problematic for time-varying systems. Unlike time-invariant effects, training models on devices with internal modulation typically requires the recording or extraction of control signals to ensure the time-alignment required by standard loss functions. This paper introduces a Generative Adversarial Network (GAN) framework to model such effects using only input-output audio recordings, removing the need for modulation signal extraction. We propose a convolutional-recurrent architecture trained via a two-stage strategy: an initial adversarial phase allows the model to learn the distribution of the modulation behavior without strict phase constraints, followed by a supervised fine-tuning phase where a State Prediction Network (SPN) estimates the initial internal states required to synchronize the model with the target. Additionally, a new objective metric based on chirp-train signals is developed to quantify modulation accuracy. Experiments modeling a vintage hardware phaser demonstrate the method's ability to capture time-varying dynamics in a fully black-box context.

</details>

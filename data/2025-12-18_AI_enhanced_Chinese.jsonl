{"id": "2512.14893", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.14893", "abs": "https://arxiv.org/abs/2512.14893", "authors": ["Reza Mohammadkhani", "Azad Azizzadeh", "Seyed Vahab Al-Din Makki", "John Thompson", "Maziar Nekovee"], "title": "Compensation of Coarse Quantization Effects on Channel Estimation and BER in Massive MIMO", "comment": "12 pages, submitted to IEEE Transactions", "summary": "Low-resolution quantization is essential to reduce implementation cost and power consumption in massive multiple-input multiple-output (MIMO) systems for 5G and 6G. While most existing studies assume perfect channel state information (CSI), we model the impact of coarse quantization noise on both channel estimation and data transmission, yielding a more realistic assessment of system performance under imperfect CSI conditions in the uplink. We develop a tight approximation for the bit-error ratio (BER) of uncoded M-QAM with zero-forcing detection, based on the linear minimum mean-square error (LMMSE) channel estimate. These analytical results enable compensation strategies that jointly optimize quantization resolution, transmit power, and pilot length across different numbers of users and base station antennas. We further demonstrate the applicability of the proposed framework through several design scenarios that highlight its effectiveness in optimizing system parameters and improving energy efficiency under quantization constraints. For example, in a 16-QAM system, extending the pilot sequence by 2.5 times and lowering transmit power by 0.5 dB enables a 3-bit quantized system to match the BER of the full-resolution case. The proposed framework offers a fast and accurate alternative to Monte Carlo simulations, enabling practical system optimization under realistic quantization constraints.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5206\u6790\u4e86\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u4f4e\u5206\u8fa8\u7387\u91cf\u5316\u5bf9\u4fe1\u9053\u4f30\u8ba1\u548c\u6570\u636e\u4f20\u8f93\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4e86\u57fa\u4e8eLMMSE\u4fe1\u9053\u4f30\u8ba1\u7684BER\u8fd1\u4f3c\u65b9\u6cd5\uff0c\u5e76\u5f00\u53d1\u4e86\u8054\u5408\u4f18\u5316\u91cf\u5316\u5206\u8fa8\u7387\u3001\u53d1\u5c04\u529f\u7387\u548c\u5bfc\u9891\u957f\u5ea6\u7684\u8865\u507f\u7b56\u7565\u6846\u67b6\u3002", "motivation": "5G/6G\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\uff0c\u4f4e\u5206\u8fa8\u7387\u91cf\u5316\u5bf9\u4e8e\u964d\u4f4e\u5b9e\u73b0\u6210\u672c\u548c\u529f\u8017\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u7814\u7a76\u5927\u591a\u5047\u8bbe\u5b8c\u7f8e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff0c\u4f46\u5b9e\u9645\u7cfb\u7edf\u4e2d\u91cf\u5316\u566a\u58f0\u4f1a\u5f71\u54cd\u4fe1\u9053\u4f30\u8ba1\u548c\u6570\u636e\u4f20\u8f93\u6027\u80fd\uff0c\u9700\u8981\u66f4\u73b0\u5b9e\u7684\u7cfb\u7edf\u6027\u80fd\u8bc4\u4f30\u3002", "method": "\u57fa\u4e8e\u7ebf\u6027\u6700\u5c0f\u5747\u65b9\u8bef\u5dee(LMMSE)\u4fe1\u9053\u4f30\u8ba1\uff0c\u5f00\u53d1\u4e86\u96f6\u8feb\u68c0\u6d4b\u4e0b\u672a\u7f16\u7801M-QAM\u7684\u8bef\u7801\u7387(BER)\u7d27\u5bc6\u8fd1\u4f3c\u65b9\u6cd5\u3002\u8be5\u6846\u67b6\u8054\u5408\u4f18\u5316\u91cf\u5316\u5206\u8fa8\u7387\u3001\u53d1\u5c04\u529f\u7387\u548c\u5bfc\u9891\u957f\u5ea6\uff0c\u8003\u8651\u4e0d\u5b8c\u7f8eCSI\u6761\u4ef6\u4e0b\u7684\u5b9e\u9645\u91cf\u5316\u7ea6\u675f\u3002", "result": "\u63d0\u51fa\u7684\u5206\u6790\u6846\u67b6\u80fd\u591f\u5feb\u901f\u51c6\u786e\u5730\u8bc4\u4f30\u7cfb\u7edf\u6027\u80fd\uff0c\u66ff\u4ee3\u8499\u7279\u5361\u6d1b\u4eff\u771f\u3002\u572816-QAM\u7cfb\u7edf\u4e2d\uff0c\u901a\u8fc7\u5c06\u5bfc\u9891\u5e8f\u5217\u5ef6\u957f2.5\u500d\u5e76\u964d\u4f4e\u53d1\u5c04\u529f\u73870.5dB\uff0c3\u4f4d\u91cf\u5316\u7cfb\u7edf\u53ef\u4ee5\u8fbe\u5230\u5168\u5206\u8fa8\u7387\u60c5\u51b5\u4e0b\u7684BER\u6027\u80fd\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u5b9e\u9645\u91cf\u5316\u7ea6\u675f\u4e0b\u7684\u7cfb\u7edf\u4f18\u5316\u63d0\u4f9b\u4e86\u5feb\u901f\u51c6\u786e\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u6709\u6548\u4f18\u5316\u7cfb\u7edf\u53c2\u6570\u5e76\u63d0\u9ad8\u80fd\u91cf\u6548\u7387\uff0c\u7279\u522b\u9002\u7528\u4e8e\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u5b9e\u9645\u90e8\u7f72\u573a\u666f\u3002"}}
{"id": "2512.15045", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15045", "abs": "https://arxiv.org/abs/2512.15045", "authors": ["Aparna Parameswaran", "Hoyoung Kim", "Sangkil Kim"], "title": "Janus Metasurface Breaking Polarization Symmetry: Surface-Modulated Electromagnetic Wave Radiation with Coexistent Linear and Circular Polarization", "comment": null, "summary": "In this work, a Janus metasurface based tensor impedance holographic antenna (JHA) is proposed that simultaneously radiates linearly polarized (LP) and circularly polarized (CP) beams from a single aperture excited by a single feed. The proposed design introduces modified tensor impedance equations to significantly reduce cross-polarization at higher radiation angles. It demonstrates broadband operation bandwidth of 0.5 GHz while maintaining high circular polarization purity. The design methodology is verified using aperture field integration theory, ensuring that the impedance distribution produces the desired far-field radiation patterns. Prototypes of three variations of the holographic antenna are fabricated, validating its performance. The radiation characteristics of the proposed antenna make it an attractive choice for advanced broadband communication applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eJanus\u8d85\u8868\u9762\u7684\u5f20\u91cf\u963b\u6297\u5168\u606f\u5929\u7ebf\uff0c\u80fd\u591f\u4ece\u5355\u4e2a\u5b54\u5f84\u3001\u5355\u9988\u6e90\u540c\u65f6\u8f90\u5c04\u7ebf\u6781\u5316\u548c\u5706\u6781\u5316\u6ce2\u675f\uff0c\u5177\u6709\u5bbd\u5e26\u5de5\u4f5c\u7279\u6027\u548c\u4f4e\u4ea4\u53c9\u6781\u5316", "motivation": "\u4e3a\u4e86\u5f00\u53d1\u80fd\u591f\u540c\u65f6\u8f90\u5c04\u7ebf\u6781\u5316\u548c\u5706\u6781\u5316\u6ce2\u675f\u7684\u5148\u8fdb\u5bbd\u5e26\u901a\u4fe1\u5929\u7ebf\uff0c\u4ece\u5355\u4e2a\u5b54\u5f84\u5b9e\u73b0\u591a\u529f\u80fd\u8f90\u5c04\uff0c\u51cf\u5c11\u4ea4\u53c9\u6781\u5316\u5e76\u63d0\u9ad8\u5706\u6781\u5316\u7eaf\u5ea6", "method": "\u63d0\u51fa\u6539\u8fdb\u7684\u5f20\u91cf\u963b\u6297\u65b9\u7a0b\u6765\u663e\u8457\u964d\u4f4e\u9ad8\u8f90\u5c04\u89d2\u5ea6\u7684\u4ea4\u53c9\u6781\u5316\uff0c\u4f7f\u7528\u5b54\u5f84\u573a\u79ef\u5206\u7406\u8bba\u9a8c\u8bc1\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u786e\u4fdd\u963b\u6297\u5206\u5e03\u4ea7\u751f\u6240\u9700\u7684\u8fdc\u573a\u8f90\u5c04\u65b9\u5411\u56fe", "result": "\u5b9e\u73b0\u4e860.5 GHz\u7684\u5bbd\u5e26\u5de5\u4f5c\u5e26\u5bbd\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u5706\u6781\u5316\u7eaf\u5ea6\uff0c\u5236\u9020\u4e86\u4e09\u79cd\u53d8\u4f53\u7684\u5168\u606f\u5929\u7ebf\u539f\u578b\uff0c\u9a8c\u8bc1\u4e86\u5929\u7ebf\u6027\u80fd", "conclusion": "\u8be5\u5929\u7ebf\u5177\u6709\u4f18\u8d8a\u7684\u8f90\u5c04\u7279\u6027\uff0c\u662f\u5148\u8fdb\u5bbd\u5e26\u901a\u4fe1\u5e94\u7528\u7684\u6709\u5438\u5f15\u529b\u7684\u9009\u62e9"}}
{"id": "2512.15062", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.15062", "abs": "https://arxiv.org/abs/2512.15062", "authors": ["Nadia Abdolkhani", "Nada Abdel Khalek", "Walaa Hamouda", "Iyad Dayoub"], "title": "Deep Reinforcement Learning for Joint Time and Power Management in SWIPT-EH CIoT", "comment": "Published in IEEE Communications Letters, 2025. This arXiv version is the authors' accepted manuscript", "summary": "This letter presents a novel deep reinforcement learning (DRL) approach for joint time allocation and power control in a cognitive Internet of Things (CIoT) system with simultaneous wireless information and power transfer (SWIPT). The CIoT transmitter autonomously manages energy harvesting (EH) and transmissions using a learnable time switching factor while optimizing power to enhance throughput and lifetime. The joint optimization is modeled as a Markov decision process under small-scale fading, realistic EH, and interference constraints. We develop a double deep Q-network (DDQN) enhanced with an upper confidence bound. Simulations benchmark our approach, showing superior performance over existing DRL methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u8ba4\u77e5\u7269\u8054\u7f51\u7cfb\u7edf\u8054\u5408\u65f6\u95f4\u5206\u914d\u4e0e\u529f\u7387\u63a7\u5236\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u65f6\u95f4\u5207\u6362\u56e0\u5b50\u4f18\u5316\u80fd\u91cf\u6536\u96c6\u548c\u4f20\u8f93\uff0c\u63d0\u5347\u541e\u5410\u91cf\u548c\u7cfb\u7edf\u5bff\u547d\u3002", "motivation": "\u8ba4\u77e5\u7269\u8054\u7f51\u7cfb\u7edf\u9700\u8981\u540c\u65f6\u8fdb\u884c\u65e0\u7ebf\u4fe1\u606f\u4e0e\u80fd\u91cf\u4f20\u8f93\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5728\u52a8\u6001\u4fe1\u9053\u6761\u4ef6\u548c\u80fd\u91cf\u6536\u96c6\u7ea6\u675f\u4e0b\u5b9e\u73b0\u8054\u5408\u4f18\u5316\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u81ea\u4e3b\u7ba1\u7406\u80fd\u91cf\u6536\u96c6\u4e0e\u4f20\u8f93\u7684\u667a\u80fd\u65b9\u6cd5\u3002", "method": "\u5c06\u8054\u5408\u4f18\u5316\u95ee\u9898\u5efa\u6a21\u4e3a\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u8003\u8651\u5c0f\u5c3a\u5ea6\u8870\u843d\u3001\u5b9e\u9645\u80fd\u91cf\u6536\u96c6\u548c\u5e72\u6270\u7ea6\u675f\u3002\u5f00\u53d1\u4e86\u57fa\u4e8e\u4e0a\u7f6e\u4fe1\u754c\u589e\u5f3a\u7684\u53cc\u6df1\u5ea6Q\u7f51\u7edc\uff08DDQN\uff09\u65b9\u6cd5\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u65f6\u95f4\u5207\u6362\u56e0\u5b50\u81ea\u4e3b\u7ba1\u7406\u80fd\u91cf\u6536\u96c6\u548c\u4f20\u8f93\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u5728\u541e\u5410\u91cf\u548c\u7cfb\u7edf\u5bff\u547d\u65b9\u9762\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u89e3\u51b3\u8ba4\u77e5\u7269\u8054\u7f51\u7cfb\u7edf\u4e2d\u8054\u5408\u65f6\u95f4\u5206\u914d\u4e0e\u529f\u7387\u63a7\u5236\u7684\u590d\u6742\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u667a\u80fd\u80fd\u91cf\u7ba1\u7406\u4e0e\u4f20\u8f93\u4f18\u5316\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.15105", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15105", "abs": "https://arxiv.org/abs/2512.15105", "authors": ["Jundong Qi", "Weize Sun", "Shaowu Chen", "Lei Huang", "Qiuchen Liu"], "title": "CF-Net: A Cross-Feature Reconstruction Network for High-Accuracy 1-Bit Target Classification", "comment": "14 pages, 10 figures. Submitted to IEEE Transactions on Geoscience and Remote Sensing", "summary": "Target classification is a fundamental task in radar systems, and its performance critically depends on the quantization precision of the signal. While high-precision quantization (e.g. 16-bit) is well established, 1-bit quantization offers distinct advantages by enabling direct sampling at high frequencies and eliminating complex intermediate stages. However, its extreme quantization leads to significant information loss. Although higher sampling rates can compensate for this loss, such oversampling is impractical at the high frequencies targeted for direct sampling. To achieve high-accuracy classification directly from 1-bit radar data under the same sampling rate, this paper proposes a novel two-stage deep learning framework, CF-Net. First, we introduce a self-supervised pre-training strategy based on a dual-branch U-Net architecture. This network learns to restore high-fidelity 16-bit images from their 1-bit counterparts via a cross-feature reconstruction task, forcing the 1-bit encoder to learn robust features despite extreme quantization. Subsequently, this pre-trained encoder is repurposed and fine-tuned for the downstream multi-class target classification task. Experiments on two radar target datasets demonstrate that CF-Net can effectively extract discriminative features from 1-bit imagery, achieving comparable and even superior accuracy to some 16-bit methods without oversampling.", "AI": {"tldr": "\u63d0\u51faCF-Net\u4e24\u9636\u6bb5\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u4ece1-bit\u96f7\u8fbe\u6570\u636e\u76f4\u63a5\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u76ee\u6807\u5206\u7c7b\uff0c\u65e0\u9700\u8fc7\u91c7\u6837\u5373\u53ef\u8fbe\u5230\u4e0e16-bit\u65b9\u6cd5\u76f8\u5f53\u7684\u7cbe\u5ea6", "motivation": "1-bit\u91cf\u5316\u96f7\u8fbe\u4fe1\u53f7\u5177\u6709\u76f4\u63a5\u9ad8\u9891\u91c7\u6837\u548c\u7b80\u5316\u7cfb\u7edf\u7684\u4f18\u52bf\uff0c\u4f46\u6781\u7aef\u91cf\u5316\u5bfc\u81f4\u4fe1\u606f\u4e25\u91cd\u635f\u5931\u3002\u4f20\u7edf\u8fc7\u91c7\u6837\u8865\u507f\u65b9\u6cd5\u5728\u9ad8\u9891\u573a\u666f\u4e0b\u4e0d\u5b9e\u7528\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u5728\u76f8\u540c\u91c7\u6837\u7387\u4e0b\u4ece1-bit\u6570\u636e\u76f4\u63a5\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5206\u7c7b\u7684\u65b9\u6cd5", "method": "\u63d0\u51faCF-Net\u4e24\u9636\u6bb5\u6846\u67b6\uff1a1\uff09\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u9636\u6bb5\uff0c\u4f7f\u7528\u53cc\u5206\u652fU-Net\u67b6\u6784\u901a\u8fc7\u8de8\u7279\u5f81\u91cd\u5efa\u4efb\u52a1\u5b66\u4e60\u4ece1-bit\u56fe\u50cf\u6062\u590d16-bit\u56fe\u50cf\uff1b2\uff09\u8fc1\u79fb\u5b66\u4e60\u9636\u6bb5\uff0c\u5c06\u9884\u8bad\u7ec3\u76841-bit\u7f16\u7801\u5668\u91cd\u65b0\u7528\u4e8e\u4e0b\u6e38\u591a\u7c7b\u76ee\u6807\u5206\u7c7b\u4efb\u52a1\u5e76\u8fdb\u884c\u5fae\u8c03", "result": "\u5728\u4e24\u4e2a\u96f7\u8fbe\u76ee\u6807\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cCF-Net\u80fd\u6709\u6548\u4ece1-bit\u56fe\u50cf\u4e2d\u63d0\u53d6\u5224\u522b\u6027\u7279\u5f81\uff0c\u5728\u4e0d\u8fdb\u884c\u8fc7\u91c7\u6837\u7684\u6761\u4ef6\u4e0b\uff0c\u8fbe\u5230\u4e0e\u67d0\u4e9b16-bit\u65b9\u6cd5\u76f8\u5f53\u751a\u81f3\u66f4\u4f18\u7684\u5206\u7c7b\u7cbe\u5ea6", "conclusion": "CF-Net\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e861-bit\u96f7\u8fbe\u6570\u636e\u5206\u7c7b\u7684\u6311\u6218\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u5b66\u4e60\u9c81\u68d2\u7279\u5f81\uff0c\u5b9e\u73b0\u4e86\u5728\u76f8\u540c\u91c7\u6837\u7387\u4e0b\u4ece\u6781\u7aef\u91cf\u5316\u6570\u636e\u4e2d\u76f4\u63a5\u83b7\u5f97\u9ad8\u7cbe\u5ea6\u5206\u7c7b\u6027\u80fd"}}
{"id": "2512.15224", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2512.15224", "abs": "https://arxiv.org/abs/2512.15224", "authors": ["S\u00e9verin Baroudi", "Herv\u00e9 Bredin", "Joseph Razik", "Ricard Marxer"], "title": "On the Use of Self-Supervised Representation Learning for Speaker Diarization and Separation", "comment": "accepted at ASRU25", "summary": "Self-supervised speech models such as wav2vec2.0 and WavLM have been shown to significantly improve the performance of many downstream speech tasks, especially in low-resource settings, over the past few years. Despite this, evaluations on tasks such as Speaker Diarization and Speech Separation remain limited. This paper investigates the quality of recent self-supervised speech representations on these two speaker identity-related tasks, highlighting gaps in the current literature that stem from limitations in the existing benchmarks, particularly the lack of diversity in evaluation datasets and variety in downstream systems associated to both diarization and separation.", "AI": {"tldr": "\u8bc4\u4f30\u81ea\u76d1\u7763\u8bed\u97f3\u6a21\u578b\u5728\u8bf4\u8bdd\u4eba\u5206\u79bb\u548c\u8bed\u97f3\u5206\u79bb\u4efb\u52a1\u4e0a\u7684\u8868\u73b0\uff0c\u53d1\u73b0\u73b0\u6709\u57fa\u51c6\u5b58\u5728\u591a\u6837\u6027\u4e0d\u8db3\u7684\u95ee\u9898", "motivation": "\u5c3d\u7ba1\u81ea\u76d1\u7763\u8bed\u97f3\u6a21\u578b\uff08\u5982wav2vec2.0\u548cWavLM\uff09\u5728\u8bb8\u591a\u4e0b\u6e38\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u8bf4\u8bdd\u4eba\u5206\u79bb\u548c\u8bed\u97f3\u5206\u79bb\u4efb\u52a1\u4e0a\u7684\u8bc4\u4f30\u4ecd\u7136\u6709\u9650\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30", "method": "\u8c03\u67e5\u6700\u8fd1\u7684\u81ea\u76d1\u7763\u8bed\u97f3\u8868\u793a\u5728\u8fd9\u4e24\u4e2a\u8bf4\u8bdd\u4eba\u8eab\u4efd\u76f8\u5173\u4efb\u52a1\u4e0a\u7684\u8d28\u91cf\uff0c\u5206\u6790\u73b0\u6709\u57fa\u51c6\u7684\u5c40\u9650\u6027", "result": "\u53d1\u73b0\u5f53\u524d\u6587\u732e\u5b58\u5728\u7a7a\u767d\uff0c\u4e3b\u8981\u6e90\u4e8e\u73b0\u6709\u57fa\u51c6\u7684\u9650\u5236\uff0c\u7279\u522b\u662f\u8bc4\u4f30\u6570\u636e\u96c6\u7f3a\u4e4f\u591a\u6837\u6027\u548c\u4e0b\u6e38\u7cfb\u7edf\u79cd\u7c7b\u4e0d\u8db3", "conclusion": "\u9700\u8981\u66f4\u5168\u9762\u3001\u591a\u6837\u5316\u7684\u8bc4\u4f30\u57fa\u51c6\u6765\u51c6\u786e\u8bc4\u4f30\u81ea\u76d1\u7763\u8bed\u97f3\u6a21\u578b\u5728\u8bf4\u8bdd\u4eba\u5206\u79bb\u548c\u8bed\u97f3\u5206\u79bb\u4efb\u52a1\u4e0a\u7684\u8868\u73b0"}}
{"id": "2512.14865", "categories": ["cs.SD", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.14865", "abs": "https://arxiv.org/abs/2512.14865", "authors": ["Advait Gosai", "Tyler Vuong", "Utkarsh Tyagi", "Steven Li", "Wenjia You", "Miheer Bavare", "Arda U\u00e7ar", "Zhongwang Fang", "Brian Jang", "Bing Liu", "Yunzhong He"], "title": "Audio MultiChallenge: A Multi-Turn Evaluation of Spoken Dialogue Systems on Natural Human Interaction", "comment": null, "summary": "End-to-end (E2E) spoken dialogue systems are increasingly replacing cascaded pipelines for voice-based human-AI interaction, processing raw audio directly without intermediate transcription. Existing benchmarks primarily evaluate these models on synthetic speech and single-turn tasks, leaving realistic multi-turn conversational ability underexplored. We introduce Audio MultiChallenge, an open-source benchmark to evaluate E2E spoken dialogue systems under natural multi-turn interaction patterns. Building on the text-based MultiChallenge framework, which evaluates Inference Memory, Instruction Retention, and Self Coherence, we introduce a new axis Voice Editing that tests robustness to mid-utterance speech repairs and backtracking. We further augment each axis to the audio modality, such as introducing Audio-Cue challenges for Inference Memory that require recalling ambient sounds and paralinguistic signals beyond semantic content. We curate 452 conversations from 47 speakers with 1,712 instance-specific rubrics through a hybrid audio-native agentic and human-in-the-loop pipeline that exposes model failures at scale while preserving natural disfluencies found in unscripted human speech. Our evaluation of proprietary and open-source models reveals that even frontier models struggle on our benchmark, with Gemini 3 Pro Preview (Thinking), our highest-performing model achieving a 54.65% pass rate. Error analysis shows that models fail most often on our new axes and that Self Coherence degrades with longer audio context. These failures reflect difficulty of tracking edits, audio cues, and long-range context in natural spoken dialogue. Audio MultiChallenge provides a reproducible testbed to quantify them and drive improvements in audio-native multi-turn interaction capability.", "AI": {"tldr": "Audio MultiChallenge\uff1a\u9996\u4e2a\u8bc4\u4f30\u7aef\u5230\u7aef\u8bed\u97f3\u5bf9\u8bdd\u7cfb\u7edf\u5728\u591a\u8f6e\u81ea\u7136\u5bf9\u8bdd\u4e2d\u80fd\u529b\u7684\u5f00\u6e90\u57fa\u51c6\uff0c\u5305\u542b4\u4e2a\u8bc4\u4f30\u7ef4\u5ea6\uff0c\u63ed\u793a\u524d\u6cbf\u6a21\u578b\u5728\u771f\u5b9e\u8bed\u97f3\u4ea4\u4e92\u4e2d\u4ecd\u5b58\u5728\u663e\u8457\u6311\u6218\u3002", "motivation": "\u73b0\u6709\u57fa\u51c6\u4e3b\u8981\u8bc4\u4f30\u5408\u6210\u8bed\u97f3\u548c\u5355\u8f6e\u4efb\u52a1\uff0c\u7f3a\u4e4f\u5bf9\u771f\u5b9e\u591a\u8f6e\u5bf9\u8bdd\u80fd\u529b\u7684\u8bc4\u4f30\u3002\u7aef\u5230\u7aef\u8bed\u97f3\u5bf9\u8bdd\u7cfb\u7edf\u76f4\u63a5\u5904\u7406\u539f\u59cb\u97f3\u9891\uff0c\u9700\u8981\u66f4\u5168\u9762\u7684\u8bc4\u4f30\u6846\u67b6\u6765\u6d4b\u8bd5\u5176\u5728\u81ea\u7136\u591a\u8f6e\u4ea4\u4e92\u4e2d\u7684\u8868\u73b0\u3002", "method": "\u57fa\u4e8e\u6587\u672cMultiChallenge\u6846\u67b6\uff0c\u5f15\u5165\u65b0\u7684Voice Editing\u7ef4\u5ea6\uff0c\u5e76\u5c06\u6240\u6709\u7ef4\u5ea6\u6269\u5c55\u5230\u97f3\u9891\u6a21\u6001\uff08\u5982Audio-Cue\u6311\u6218\uff09\u3002\u901a\u8fc7\u6df7\u5408\u97f3\u9891\u539f\u751f\u4ee3\u7406\u548c\u4eba\u5de5\u53c2\u4e0e\u6d41\u7a0b\uff0c\u4ece47\u4f4d\u8bf4\u8bdd\u8005\u4e2d\u6536\u96c6452\u4e2a\u5bf9\u8bdd\uff0c\u5305\u542b1,712\u4e2a\u5b9e\u4f8b\u7279\u5b9a\u8bc4\u5206\u6807\u51c6\u3002", "result": "\u8bc4\u4f30\u663e\u793a\u524d\u6cbf\u6a21\u578b\u5728\u57fa\u51c6\u4e0a\u8868\u73b0\u4e0d\u4f73\uff0c\u6700\u4f73\u6a21\u578bGemini 3 Pro Preview\uff08Thinking\uff09\u901a\u8fc7\u7387\u4ec5\u4e3a54.65%\u3002\u9519\u8bef\u5206\u6790\u8868\u660e\u6a21\u578b\u5728\u65b0\u7ef4\u5ea6\u548c\u957f\u97f3\u9891\u4e0a\u4e0b\u6587\u7684\u81ea\u6d3d\u6027\u65b9\u9762\u5931\u8d25\u6700\u591a\uff0c\u53cd\u6620\u51fa\u5728\u8ddf\u8e2a\u7f16\u8f91\u3001\u97f3\u9891\u7ebf\u7d22\u548c\u957f\u8303\u56f4\u4e0a\u4e0b\u6587\u65b9\u9762\u7684\u56f0\u96be\u3002", "conclusion": "Audio MultiChallenge\u63d0\u4f9b\u4e86\u4e00\u4e2a\u53ef\u590d\u73b0\u7684\u6d4b\u8bd5\u5e73\u53f0\uff0c\u80fd\u591f\u91cf\u5316\u7aef\u5230\u7aef\u8bed\u97f3\u5bf9\u8bdd\u7cfb\u7edf\u5728\u81ea\u7136\u591a\u8f6e\u4ea4\u4e92\u4e2d\u7684\u80fd\u529b\u7f3a\u9677\uff0c\u63a8\u52a8\u97f3\u9891\u539f\u751f\u591a\u8f6e\u4ea4\u4e92\u80fd\u529b\u7684\u6539\u8fdb\u3002"}}
{"id": "2512.15109", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15109", "abs": "https://arxiv.org/abs/2512.15109", "authors": ["Zhuoran Li", "Zhen Gao", "Xinhua Liu", "Zheng Wang", "Xiaotian Zhou", "Lei Liu", "Yongpeng Wu", "Wei Feng", "Yongming Huang"], "title": "Large Model Enabled Embodied Intelligence for 6G Integrated Perception, Communication, and Computation Network", "comment": null, "summary": "The advent of sixth-generation (6G) places intelligence at the core of wireless architecture, fusing perception, communication, and computation into a single closed-loop. This paper argues that large artificial intelligence models (LAMs) can endow base stations with perception, reasoning, and acting capabilities, thus transforming them into intelligent base station agents (IBSAs). We first review the historical evolution of BSs from single-functional analog infrastructure to distributed, software-defined, and finally LAM-empowered IBSA, highlighting the accompanying changes in architecture, hardware platforms, and deployment. We then present an IBSA architecture that couples a perception-cognition-execution pipeline with cloud-edge-end collaboration and parameter-efficient adaptation. Subsequently,we study two representative scenarios: (i) cooperative vehicle-road perception for autonomous driving, and (ii) ubiquitous base station support for low-altitude uncrewed aerial vehicle safety monitoring and response against unauthorized drones. On this basis, we analyze key enabling technologies spanning LAM design and training, efficient edge-cloud inference, multi-modal perception and actuation, as well as trustworthy security and governance. We further propose a holistic evaluation framework and benchmark considerations that jointly cover communication performance, perception accuracy, decision-making reliability, safety, and energy efficiency. Finally, we distill open challenges on benchmarks, continual adaptation, trustworthy decision-making, and standardization. Together, this work positions LAM-enabled IBSAs as a practical path toward integrated perception, communication, and computation native, safety-critical 6G systems.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u5c06\u5927\u578b\u4eba\u5de5\u667a\u80fd\u6a21\u578b\uff08LAMs\uff09\u8d4b\u80fd\u57fa\u7ad9\uff0c\u4f7f\u5176\u6210\u4e3a\u667a\u80fd\u57fa\u7ad9\u4ee3\u7406\uff08IBSAs\uff09\uff0c\u5b9e\u73b0\u611f\u77e5\u3001\u901a\u4fe1\u548c\u8ba1\u7b97\u7684\u878d\u5408\uff0c\u4e3a6G\u7cfb\u7edf\u63d0\u4f9b\u5b89\u5168\u5173\u952e\u7684\u57fa\u7840\u8bbe\u65bd\u3002", "motivation": "6G\u65f6\u4ee3\u9700\u8981\u5c06\u667a\u80fd\u7f6e\u4e8e\u65e0\u7ebf\u67b6\u6784\u7684\u6838\u5fc3\uff0c\u878d\u5408\u611f\u77e5\u3001\u901a\u4fe1\u548c\u8ba1\u7b97\u3002\u4f20\u7edf\u57fa\u7ad9\u529f\u80fd\u5355\u4e00\uff0c\u65e0\u6cd5\u6ee1\u8db3\u672a\u6765\u667a\u80fd\u7cfb\u7edf\u7684\u9700\u6c42\uff0c\u9700\u8981\u5c06\u5176\u5347\u7ea7\u4e3a\u5177\u5907\u611f\u77e5\u3001\u63a8\u7406\u548c\u884c\u52a8\u80fd\u529b\u7684\u667a\u80fd\u4ee3\u7406\u3002", "method": "\u63d0\u51faIBSA\u67b6\u6784\uff0c\u7ed3\u5408\u611f\u77e5-\u8ba4\u77e5-\u6267\u884c\u6d41\u6c34\u7ebf\u4e0e\u4e91-\u8fb9-\u7aef\u534f\u4f5c\uff0c\u91c7\u7528\u53c2\u6570\u9ad8\u6548\u9002\u914d\u3002\u7814\u7a76\u4e24\u4e2a\u4ee3\u8868\u6027\u573a\u666f\uff1a\u81ea\u52a8\u9a7e\u9a76\u7684\u8f66\u8def\u534f\u540c\u611f\u77e5\u548c\u65e0\u4eba\u673a\u5b89\u5168\u76d1\u63a7\u3002\u5206\u6790LAM\u8bbe\u8ba1\u8bad\u7ec3\u3001\u9ad8\u6548\u8fb9\u7f18\u4e91\u63a8\u7406\u3001\u591a\u6a21\u6001\u611f\u77e5\u6267\u884c\u7b49\u5173\u952e\u6280\u672f\u3002", "result": "\u5efa\u7acb\u4e86IBSA\u7684\u5b8c\u6574\u67b6\u6784\u6846\u67b6\uff0c\u63d0\u51fa\u4e86\u6db5\u76d6\u901a\u4fe1\u6027\u80fd\u3001\u611f\u77e5\u7cbe\u5ea6\u3001\u51b3\u7b56\u53ef\u9760\u6027\u3001\u5b89\u5168\u6027\u548c\u80fd\u6548\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u4e3a6G\u5b89\u5168\u5173\u952e\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u6280\u672f\u8def\u5f84\u3002", "conclusion": "LAM\u8d4b\u80fd\u7684IBSA\u662f\u5b9e\u73b06G\u539f\u751f\u611f\u77e5-\u901a\u4fe1-\u8ba1\u7b97\u878d\u5408\u7cfb\u7edf\u7684\u5b9e\u7528\u8def\u5f84\uff0c\u4f46\u4ecd\u9700\u89e3\u51b3\u57fa\u51c6\u6d4b\u8bd5\u3001\u6301\u7eed\u9002\u914d\u3001\u53ef\u4fe1\u51b3\u7b56\u548c\u6807\u51c6\u5316\u7b49\u5f00\u653e\u6311\u6218\u3002"}}
{"id": "2512.15532", "categories": ["cs.SD", "cs.AI", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2512.15532", "abs": "https://arxiv.org/abs/2512.15532", "authors": ["Ken O'Hanlon", "Basil Woods", "Lin Wang", "Mark Sandler"], "title": "A Conditioned UNet for Music Source Separation", "comment": null, "summary": "In this paper we propose a conditioned UNet for Music Source Separation (MSS). MSS is generally performed by multi-output neural networks, typically UNets, with each output representing a particular stem from a predefined instrument vocabulary. In contrast, conditioned MSS networks accept an audio query related to a stem of interest alongside the signal from which that stem is to be extracted. Thus, a strict vocabulary is not required and this enables more realistic tasks in MSS. The potential of conditioned approaches for such tasks has been somewhat hidden due to a lack of suitable data, an issue recently addressed with the MoisesDb dataset. A recent method, Banquet, employs this dataset with promising results seen on larger vocabularies. Banquet uses Bandsplit RNN rather than a UNet and the authors state that UNets should not be suitable for conditioned MSS. We counter this argument and propose QSCNet, a novel conditioned UNet for MSS that integrates network conditioning elements in the Sparse Compressed Network for MSS. We find QSCNet to outperform Banquet by over 1dB SNR on a couple of MSS tasks, while using less than half the number of parameters.", "AI": {"tldr": "\u63d0\u51faQSCNet\uff0c\u4e00\u79cd\u7528\u4e8e\u97f3\u4e50\u6e90\u5206\u79bb\u7684\u6761\u4ef6\u5316UNet\u67b6\u6784\uff0c\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5Banquet\uff0c\u53c2\u6570\u91cf\u66f4\u5c11", "motivation": "\u4f20\u7edf\u97f3\u4e50\u6e90\u5206\u79bb\u65b9\u6cd5\u9700\u8981\u9884\u5b9a\u4e49\u4e50\u5668\u8bcd\u6c47\u8868\uff0c\u800c\u6761\u4ef6\u5316\u65b9\u6cd5\u901a\u8fc7\u97f3\u9891\u67e5\u8be2\u53ef\u4ee5\u66f4\u7075\u6d3b\u5730\u5206\u79bb\u4efb\u610f\u97f3\u6e90\u3002\u73b0\u6709\u7814\u7a76\u8ba4\u4e3aUNet\u4e0d\u9002\u5408\u6761\u4ef6\u5316\u97f3\u4e50\u6e90\u5206\u79bb\uff0c\u672c\u6587\u65e8\u5728\u53cd\u9a73\u8fd9\u4e00\u89c2\u70b9", "method": "\u63d0\u51faQSCNet\uff0c\u4e00\u79cd\u65b0\u9896\u7684\u6761\u4ef6\u5316UNet\u67b6\u6784\uff0c\u5c06\u7f51\u7edc\u6761\u4ef6\u5316\u5143\u7d20\u96c6\u6210\u5230\u7528\u4e8e\u97f3\u4e50\u6e90\u5206\u79bb\u7684\u7a00\u758f\u538b\u7f29\u7f51\u7edc\u4e2d", "result": "QSCNet\u5728\u591a\u4e2a\u97f3\u4e50\u6e90\u5206\u79bb\u4efb\u52a1\u4e0a\u6bd4Banquet\u65b9\u6cd5\u9ad8\u51fa\u8d85\u8fc71dB SNR\uff0c\u540c\u65f6\u4f7f\u7528\u4e0d\u5230\u4e00\u534a\u7684\u53c2\u6570\u6570\u91cf", "conclusion": "UNet\u67b6\u6784\u786e\u5b9e\u9002\u7528\u4e8e\u6761\u4ef6\u5316\u97f3\u4e50\u6e90\u5206\u79bb\u4efb\u52a1\uff0cQSCNet\u8bc1\u660e\u4e86\u5176\u5728\u6027\u80fd\u548c\u6548\u7387\u4e0a\u7684\u4f18\u52bf\uff0c\u4e3a\u66f4\u7075\u6d3b\u7684\u97f3\u4e50\u6e90\u5206\u79bb\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.15124", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.15124", "abs": "https://arxiv.org/abs/2512.15124", "authors": ["Kewei Li", "Yinan Zhong", "Xiaotao Liang", "Tianchi Dai", "Shaofei Xue"], "title": "Synaspot: A Lightweight, Streaming Multi-modal Framework for Keyword Spotting with Audio-Text Synergy", "comment": null, "summary": "Open-vocabulary keyword spotting (KWS) in continuous speech streams holds significant practical value across a wide range of real-world applications. While increasing attention has been paid to the role of different modalities in KWS, their effectiveness has been acknowledged. However, the increased parameter cost from multimodal integration and the constraints of end-to-end deployment have limited the practical applicability of such models. To address these challenges, we propose a lightweight, streaming multi-modal framework. First, we focus on multimodal enrollment features and reduce speaker-specific (voiceprint) information in the speech enrollment to extract speaker-irrelevant characteristics. Second, we effectively fuse speech and text features. Finally, we introduce a streaming decoding framework that only requires the encoder to extract features, which are then mathematically decoded with our three modal representations. Experiments on LibriPhase and WenetPrase demonstrate the performance of our model. Compared to existing streaming approaches, our method achieves better performance with significantly fewer parameters.", "AI": {"tldr": "\u63d0\u51fa\u8f7b\u91cf\u7ea7\u6d41\u5f0f\u591a\u6a21\u6001\u5173\u952e\u8bcd\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u51cf\u5c11\u8bed\u97f3\u6ce8\u518c\u4e2d\u7684\u8bf4\u8bdd\u4eba\u4fe1\u606f\u3001\u6709\u6548\u878d\u5408\u8bed\u97f3\u6587\u672c\u7279\u5f81\uff0c\u4ee5\u53ca\u4ec5\u9700\u7f16\u7801\u5668\u63d0\u53d6\u7279\u5f81\u7684\u6d41\u5f0f\u89e3\u7801\uff0c\u5b9e\u73b0\u66f4\u597d\u6027\u80fd\u4e14\u53c2\u6570\u66f4\u5c11\u3002", "motivation": "\u8fde\u7eed\u8bed\u97f3\u6d41\u4e2d\u7684\u5f00\u653e\u8bcd\u6c47\u5173\u952e\u8bcd\u68c0\u6d4b\u5177\u6709\u91cd\u8981\u5b9e\u7528\u4ef7\u503c\uff0c\u4f46\u73b0\u6709\u591a\u6a21\u6001\u65b9\u6cd5\u5b58\u5728\u53c2\u6570\u6210\u672c\u9ad8\u548c\u7aef\u5230\u7aef\u90e8\u7f72\u9650\u5236\u7684\u95ee\u9898\uff0c\u9650\u5236\u4e86\u5b9e\u9645\u5e94\u7528\u3002", "method": "1. \u5173\u6ce8\u591a\u6a21\u6001\u6ce8\u518c\u7279\u5f81\uff0c\u51cf\u5c11\u8bed\u97f3\u6ce8\u518c\u4e2d\u7684\u8bf4\u8bdd\u4eba\u7279\u5b9a\u4fe1\u606f\u4ee5\u63d0\u53d6\u8bf4\u8bdd\u4eba\u4e0d\u76f8\u5173\u7279\u5f81\uff1b2. \u6709\u6548\u878d\u5408\u8bed\u97f3\u548c\u6587\u672c\u7279\u5f81\uff1b3. \u5f15\u5165\u6d41\u5f0f\u89e3\u7801\u6846\u67b6\uff0c\u4ec5\u9700\u7f16\u7801\u5668\u63d0\u53d6\u7279\u5f81\uff0c\u7136\u540e\u901a\u8fc7\u4e09\u79cd\u6a21\u6001\u8868\u793a\u8fdb\u884c\u6570\u5b66\u89e3\u7801\u3002", "result": "\u5728LibriPhase\u548cWenetPrase\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u76f8\u6bd4\u73b0\u6709\u6d41\u5f0f\u65b9\u6cd5\uff0c\u8be5\u65b9\u6cd5\u4ee5\u663e\u8457\u66f4\u5c11\u7684\u53c2\u6570\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "\u63d0\u51fa\u7684\u8f7b\u91cf\u7ea7\u6d41\u5f0f\u591a\u6a21\u6001\u6846\u67b6\u89e3\u51b3\u4e86\u591a\u6a21\u6001\u5173\u952e\u8bcd\u68c0\u6d4b\u4e2d\u7684\u53c2\u6570\u6210\u672c\u548c\u90e8\u7f72\u9650\u5236\u95ee\u9898\uff0c\u5728\u4fdd\u6301\u9ad8\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u51cf\u5c11\u4e86\u6a21\u578b\u53c2\u6570\uff0c\u5177\u6709\u66f4\u597d\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2512.15119", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.15119", "abs": "https://arxiv.org/abs/2512.15119", "authors": ["Jiayang Wan", "Ke He", "Yafei Wang", "Fan Liu", "Wenjin Wang", "Shi Jin"], "title": "QoS-Aware Hierarchical Reinforcement Learning for Joint Link Selection and Trajectory Optimization in SAGIN-Supported UAV Mobility Management", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Due to the significant variations in unmanned aerial vehicle (UAV) altitude and horizontal mobility, it becomes difficult for any single network to ensure continuous and reliable threedimensional coverage. Towards that end, the space-air-ground integrated network (SAGIN) has emerged as an essential architecture for enabling ubiquitous UAV connectivity. To address the pronounced disparities in coverage and signal characteristics across heterogeneous networks, this paper formulates UAV mobility management in SAGIN as a constrained multi-objective joint optimization problem. The formulation couples discrete link selection with continuous trajectory optimization. Building on this, we propose a two-level multi-agent hierarchical deep reinforcement learning (HDRL) framework that decomposes the problem into two alternately solvable subproblems. To map complex link selection decisions into a compact discrete action space, we conceive a double deep Q-network (DDQN) algorithm in the top-level, which achieves stable and high-quality policy learning through double Q-value estimation. To handle the continuous trajectory action space while satisfying quality of service (QoS) constraints, we integrate the maximum-entropy mechanism of the soft actor-critic (SAC) and employ a Lagrangian-based constrained SAC (CSAC) algorithm in the lower-level that dynamically adjusts the Lagrange multipliers to balance constraint satisfaction and policy optimization. Moreover, the proposed algorithm can be extended to multi-UAV scenarios under the centralized training and decentralized execution (CTDE) paradigm, which enables more generalizable policies. Simulation results demonstrate that the proposed scheme substantially outperforms existing benchmarks in throughput, link switching frequency and QoS satisfaction.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5206\u5c42\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u65e0\u4eba\u673a\u7a7a\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u79fb\u52a8\u7ba1\u7406\u6846\u67b6\uff0c\u901a\u8fc7DDQN\u548c\u7ea6\u675fSAC\u7b97\u6cd5\u5206\u522b\u5904\u7406\u79bb\u6563\u94fe\u8def\u9009\u62e9\u548c\u8fde\u7eed\u8f68\u8ff9\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\u548c\u670d\u52a1\u8d28\u91cf", "motivation": "\u65e0\u4eba\u673a\u5728\u4e09\u7ef4\u7a7a\u95f4\u4e2d\u79fb\u52a8\u65f6\uff0c\u5355\u4e00\u7f51\u7edc\u96be\u4ee5\u4fdd\u8bc1\u8fde\u7eed\u53ef\u9760\u7684\u8986\u76d6\uff0c\u800c\u7a7a\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc(SAGIN)\u4e2d\u5f02\u6784\u7f51\u7edc\u7684\u8986\u76d6\u8303\u56f4\u548c\u4fe1\u53f7\u7279\u6027\u5dee\u5f02\u663e\u8457\uff0c\u9700\u8981\u6709\u6548\u7684\u79fb\u52a8\u7ba1\u7406\u65b9\u6848", "method": "\u63d0\u51fa\u4e24\u7ea7\u591a\u667a\u80fd\u4f53\u5206\u5c42\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff1a\u9876\u5c42\u4f7f\u7528\u53cc\u6df1\u5ea6Q\u7f51\u7edc(DDQN)\u5904\u7406\u79bb\u6563\u94fe\u8def\u9009\u62e9\uff1b\u5e95\u5c42\u91c7\u7528\u57fa\u4e8e\u62c9\u683c\u6717\u65e5\u7684\u7ea6\u675f\u8f6f\u6f14\u5458-\u8bc4\u8bba\u5bb6(CSAC)\u7b97\u6cd5\u5904\u7406\u8fde\u7eed\u8f68\u8ff9\u4f18\u5316\u5e76\u6ee1\u8db3\u670d\u52a1\u8d28\u91cf\u7ea6\u675f\uff1b\u652f\u6301\u591a\u65e0\u4eba\u673a\u573a\u666f\u4e0b\u7684\u96c6\u4e2d\u8bad\u7ec3\u5206\u6563\u6267\u884c", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6848\u5728\u541e\u5410\u91cf\u3001\u94fe\u8def\u5207\u6362\u9891\u7387\u548c\u670d\u52a1\u8d28\u91cf\u6ee1\u610f\u5ea6\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\u65b9\u6cd5", "conclusion": "\u8be5\u5206\u5c42\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u7a7a\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u4e2d\u65e0\u4eba\u673a\u79fb\u52a8\u7ba1\u7406\u7684\u591a\u76ee\u6807\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u79bb\u6563\u94fe\u8def\u9009\u62e9\u548c\u8fde\u7eed\u8f68\u8ff9\u4f18\u5316\u7684\u534f\u540c\u4f18\u5316"}}
{"id": "2512.15180", "categories": ["cs.SD", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15180", "abs": "https://arxiv.org/abs/2512.15180", "authors": ["Sanghyeok Chung", "Eujin Kim", "Donggun Kim", "Gaeun Heo", "Jeongbin You", "Nahyun Lee", "Sunmook Choi", "Soyul Han", "Seungsang Oh", "Il-Youp Kwak"], "title": "BEAT2AASIST model with layer fusion for ESDD 2026 Challenge", "comment": "3 pages, 1 figure, challenge paper", "summary": "Recent advances in audio generation have increased the risk of realistic environmental sound manipulation, motivating the ESDD 2026 Challenge as the first large-scale benchmark for Environmental Sound Deepfake Detection (ESDD). We propose BEAT2AASIST which extends BEATs-AASIST by splitting BEATs-derived representations along frequency or channel dimension and processing them with dual AASIST branches. To enrich feature representations, we incorporate top-k transformer layer fusion using concatenation, CNN-gated, and SE-gated strategies. In addition, vocoder-based data augmentation is applied to improve robustness against unseen spoofing methods. Experimental results on the official test sets demonstrate that the proposed approach achieves competitive performance across the challenge tracks.", "AI": {"tldr": "BEAT2AASIST\u6a21\u578b\u901a\u8fc7\u53cc\u5206\u652f\u5904\u7406\u548c\u7279\u5f81\u878d\u5408\u7b56\u7565\uff0c\u5728\u73af\u5883\u58f0\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u6311\u6218\u4e2d\u53d6\u5f97\u7ade\u4e89\u6027\u8868\u73b0", "motivation": "\u97f3\u9891\u751f\u6210\u6280\u672f\u7684\u8fdb\u6b65\u589e\u52a0\u4e86\u73af\u5883\u58f0\u97f3\u88ab\u6076\u610f\u64cd\u7eb5\u7684\u98ce\u9669\uff0c\u9700\u8981\u5efa\u7acb\u5927\u89c4\u6a21\u7684\u73af\u5883\u58f0\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u57fa\u51c6", "method": "\u6269\u5c55BEATs-AASIST\u6a21\u578b\uff0c\u5c06BEATs\u7279\u5f81\u6cbf\u9891\u7387\u6216\u901a\u9053\u7ef4\u5ea6\u5206\u5272\uff0c\u7528\u53ccAASIST\u5206\u652f\u5904\u7406\uff1b\u91c7\u7528top-k transformer\u5c42\u878d\u5408\u7b56\u7565\uff08\u62fc\u63a5\u3001CNN\u95e8\u63a7\u3001SE\u95e8\u63a7\uff09\uff1b\u4f7f\u7528\u58f0\u7801\u5668\u6570\u636e\u589e\u5f3a\u63d0\u5347\u9c81\u68d2\u6027", "result": "\u5728\u5b98\u65b9\u6d4b\u8bd5\u96c6\u4e0a\uff0c\u6240\u63d0\u65b9\u6cd5\u5728\u6311\u6218\u8d5b\u5404\u8d5b\u9053\u4e2d\u53d6\u5f97\u4e86\u7ade\u4e89\u6027\u7684\u6027\u80fd\u8868\u73b0", "conclusion": "BEAT2AASIST\u6a21\u578b\u901a\u8fc7\u591a\u5206\u652f\u67b6\u6784\u548c\u7279\u5f81\u878d\u5408\u7b56\u7565\uff0c\u4e3a\u73af\u5883\u58f0\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.15246", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15246", "abs": "https://arxiv.org/abs/2512.15246", "authors": ["Nguyen Thanh Vinh", "Manoj Vishwanath", "Thinh Nguyen-Quang", "Nguyen Viet Ha", "Bui Thanh Tung", "Huy-Dung Han", "Nguyen Quang Linh", "Nguyen Hai Linh", "Hung Cao"], "title": "Enhancing Alzheimer's Detection through Late Fusion of Multi-Modal EEG Features", "comment": null, "summary": "Alzheimer s disease (AD) is a progressive neurodegenerative disorder characterized by cognitive decline, where early detection is essential for timely intervention and improved patient outcomes. Traditional diagnostic methods are time-consuming and require expert interpretation, thus, automated approaches are highly desirable. This study presents a novel deep learning framework for AD diagnosis using Electroencephalograph (EEG) signals, integrating multiple feature extraction techniques including alpha-wave analysis, Discrete Wavelet Transform (DWT), and Markov Transition Fields (MTF). A late-fusion strategy is employed to combine predictions from separate neural networks trained on these diverse representations, capturing both temporal and frequency-domain patterns in the EEG data. The proposed model attains a classification accuracy of 87.23%, with a precision of 87.95%, a recall of 86.91%, and an F1 score of 87.42% when evaluated on a publicly available dataset, demonstrating its potential for reliable, scalable, and early AD screening. Rigorous preprocessing and targeted frequency band selection, particularly in the alpha range due to its cognitive relevance, further enhance performance. This work highlights the promise of deep learning in supporting physicians with efficient and accessible tools for early AD diagnosis.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8eEEG\u4fe1\u53f7\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u7279\u5f81\u63d0\u53d6\u548c\u665a\u671f\u878d\u5408\u7b56\u7565\u5b9e\u73b0\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7684\u65e9\u671f\u8bca\u65ad\uff0c\u51c6\u786e\u7387\u8fbe87.23%", "motivation": "\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u65e9\u671f\u68c0\u6d4b\u5bf9\u53ca\u65f6\u5e72\u9884\u81f3\u5173\u91cd\u8981\uff0c\u4f20\u7edf\u8bca\u65ad\u65b9\u6cd5\u8017\u65f6\u4e14\u9700\u8981\u4e13\u5bb6\u89e3\u8bfb\uff0c\u9700\u8981\u81ea\u52a8\u5316\u65b9\u6cd5", "method": "\u4f7f\u7528EEG\u4fe1\u53f7\uff0c\u96c6\u6210alpha\u6ce2\u5206\u6790\u3001\u79bb\u6563\u5c0f\u6ce2\u53d8\u6362\u548c\u9a6c\u5c14\u53ef\u592b\u8f6c\u79fb\u573a\u7b49\u591a\u7279\u5f81\u63d0\u53d6\u6280\u672f\uff0c\u91c7\u7528\u665a\u671f\u878d\u5408\u7b56\u7565\u7ed3\u5408\u4e0d\u540c\u795e\u7ecf\u7f51\u7edc\u9884\u6d4b", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u83b7\u5f9787.23%\u51c6\u786e\u7387\u300187.95%\u7cbe\u786e\u7387\u300186.91%\u53ec\u56de\u7387\u548c87.42% F1\u5206\u6570", "conclusion": "\u8be5\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u5c55\u793a\u4e86\u53ef\u9760\u3001\u53ef\u6269\u5c55\u7684\u65e9\u671fAD\u7b5b\u67e5\u6f5c\u529b\uff0c\u6709\u671b\u4e3a\u533b\u751f\u63d0\u4f9b\u9ad8\u6548\u4fbf\u6377\u7684\u8bca\u65ad\u5de5\u5177"}}
{"id": "2512.15313", "categories": ["cs.SD", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15313", "abs": "https://arxiv.org/abs/2512.15313", "authors": ["Yann Bourdin", "Pierrick Legrand", "Fanny Roche"], "title": "Time-Varying Audio Effect Modeling by End-to-End Adversarial Training", "comment": "Submitted for review to the Journal of the Audio Engineering Society (JAES). Accompanying website: https://ybourdin.github.io/sptvmod", "summary": "Deep learning has become a standard approach for the modeling of audio effects, yet strictly black-box modeling remains problematic for time-varying systems. Unlike time-invariant effects, training models on devices with internal modulation typically requires the recording or extraction of control signals to ensure the time-alignment required by standard loss functions. This paper introduces a Generative Adversarial Network (GAN) framework to model such effects using only input-output audio recordings, removing the need for modulation signal extraction. We propose a convolutional-recurrent architecture trained via a two-stage strategy: an initial adversarial phase allows the model to learn the distribution of the modulation behavior without strict phase constraints, followed by a supervised fine-tuning phase where a State Prediction Network (SPN) estimates the initial internal states required to synchronize the model with the target. Additionally, a new objective metric based on chirp-train signals is developed to quantify modulation accuracy. Experiments modeling a vintage hardware phaser demonstrate the method's ability to capture time-varying dynamics in a fully black-box context.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eGAN\u7684\u6846\u67b6\uff0c\u4ec5\u4f7f\u7528\u8f93\u5165-\u8f93\u51fa\u97f3\u9891\u5f55\u97f3\u6765\u5efa\u6a21\u65f6\u53d8\u97f3\u9891\u6548\u679c\uff0c\u65e0\u9700\u8c03\u5236\u4fe1\u53f7\u63d0\u53d6", "motivation": "\u4f20\u7edf\u9ed1\u76d2\u5efa\u6a21\u65b9\u6cd5\u5bf9\u65f6\u53d8\u97f3\u9891\u6548\u679c\u5b58\u5728\u95ee\u9898\uff0c\u9700\u8981\u5f55\u5236\u6216\u63d0\u53d6\u63a7\u5236\u4fe1\u53f7\u4ee5\u786e\u4fdd\u65f6\u95f4\u5bf9\u9f50\uff0c\u8fd9\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u5f88\u56f0\u96be", "method": "\u91c7\u7528\u5377\u79ef-\u5faa\u73af\u67b6\u6784\uff0c\u901a\u8fc7\u4e24\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff1a1) \u5bf9\u6297\u8bad\u7ec3\u9636\u6bb5\u5b66\u4e60\u8c03\u5236\u884c\u4e3a\u5206\u5e03\uff1b2) \u76d1\u7763\u5fae\u8c03\u9636\u6bb5\u4f7f\u7528\u72b6\u6001\u9884\u6d4b\u7f51\u7edc\u4f30\u8ba1\u521d\u59cb\u5185\u90e8\u72b6\u6001\u4ee5\u5b9e\u73b0\u540c\u6b65", "result": "\u5b9e\u9a8c\u5efa\u6a21\u8001\u5f0f\u786c\u4ef6\u79fb\u76f8\u5668\u6548\u679c\uff0c\u8bc1\u660e\u8be5\u65b9\u6cd5\u80fd\u591f\u5728\u5b8c\u5168\u9ed1\u76d2\u73af\u5883\u4e0b\u51c6\u786e\u6355\u6349\u65f6\u53d8\u52a8\u6001\u7279\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u89e3\u51b3\u4e86\u65f6\u53d8\u97f3\u9891\u6548\u679c\u7684\u9ed1\u76d2\u5efa\u6a21\u95ee\u9898\uff0c\u65e0\u9700\u8c03\u5236\u4fe1\u53f7\u63d0\u53d6\uff0c\u4e3a\u97f3\u9891\u6548\u679c\u5efa\u6a21\u63d0\u4f9b\u4e86\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2512.15268", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15268", "abs": "https://arxiv.org/abs/2512.15268", "authors": ["Joachim Tapparel", "Andreas Burg"], "title": "Dataset and UAV Propagation Channel Modeling for LoRa in the 860 MHz ISM Band", "comment": "Accepted for publication in ACSSC", "summary": "LoRa is one of the most widely used low-power wide-area network technology for the Internet of Things. To achieve long-range communication with low power consumption at a low cost, LoRa uses a chirp spread spectrum modulation and transmits in the sub-GHz unlicensed industrial, scientific, and medical (ISM) frequency bands. Due to the rapid densification of IoT networks, it is crucial to obtain tailored channel models to evaluate the performance of LoRa networks. While channel models for cellular technologies have been investigated extensively, specific characteristics of LoRa transmissions operating at long range with a rather small (~ 250kHz) bandwidth require dedicated measurement campaigns and modeling efforts. In this work, we leverage an SDR-based testbed to gather and publish a dataset of LoRa frames transmitted in a campus environment. The dataset includes IQ samples of the received frames at multiple locations and allows for the evaluation of channel variations with high time resolution. Using the gathered data, we derive empirical propagation channel models for LoRa that include receiver correlation over distance for three scenarios: unmanned aerial vehicle (UAV) line-of-sight (LoS), UAV non-LoS, and pedestrian non-LoS. Furthermore, the dataset is annotated with synchronization information, enabling the evaluation of receiver algorithms using experimental data.", "AI": {"tldr": "\u672c\u6587\u901a\u8fc7SDR\u6d4b\u8bd5\u5e73\u53f0\u6536\u96c6\u5e76\u53d1\u5e03\u4e86\u6821\u56ed\u73af\u5883\u4e2d\u7684LoRa\u5e27\u6570\u636e\u96c6\uff0c\u5229\u7528\u8be5\u6570\u636e\u63a8\u5bfc\u4e86\u65e0\u4eba\u673a\u89c6\u8ddd\u3001\u65e0\u4eba\u673a\u975e\u89c6\u8ddd\u548c\u884c\u4eba\u975e\u89c6\u8ddd\u4e09\u79cd\u573a\u666f\u4e0b\u7684\u7ecf\u9a8c\u4f20\u64ad\u4fe1\u9053\u6a21\u578b\uff0c\u5e76\u63d0\u4f9b\u4e86\u540c\u6b65\u4fe1\u606f\u7528\u4e8e\u63a5\u6536\u673a\u7b97\u6cd5\u8bc4\u4f30\u3002", "motivation": "\u968f\u7740\u7269\u8054\u7f51\u7f51\u7edc\u5feb\u901f\u5bc6\u96c6\u5316\uff0c\u9700\u8981\u9488\u5bf9LoRa\u4f20\u8f93\u7279\u6027\uff08\u957f\u8ddd\u79bb\u3001\u5c0f\u5e26\u5bbd\uff09\u5efa\u7acb\u4e13\u95e8\u7684\u4fe1\u9053\u6a21\u578b\u6765\u8bc4\u4f30\u7f51\u7edc\u6027\u80fd\uff0c\u800c\u73b0\u6709\u8702\u7a9d\u6280\u672f\u7684\u4fe1\u9053\u6a21\u578b\u4e0d\u9002\u7528\u4e8eLoRa\u3002", "method": "\u4f7f\u7528\u57fa\u4e8eSDR\u7684\u6d4b\u8bd5\u5e73\u53f0\u6536\u96c6\u6821\u56ed\u73af\u5883\u4e2dLoRa\u5e27\u7684IQ\u6837\u672c\u6570\u636e\u96c6\uff0c\u5305\u542b\u591a\u4e2a\u63a5\u6536\u4f4d\u7f6e\u7684\u5e27\u6570\u636e\uff0c\u5229\u7528\u8fd9\u4e9b\u6570\u636e\u63a8\u5bfc\u4e09\u79cd\u573a\u666f\uff08\u65e0\u4eba\u673a\u89c6\u8ddd\u3001\u65e0\u4eba\u673a\u975e\u89c6\u8ddd\u3001\u884c\u4eba\u975e\u89c6\u8ddd\uff09\u7684\u7ecf\u9a8c\u4f20\u64ad\u4fe1\u9053\u6a21\u578b\u3002", "result": "\u53d1\u5e03\u4e86\u5305\u542b\u9ad8\u65f6\u95f4\u5206\u8fa8\u7387\u4fe1\u9053\u53d8\u5316\u7684LoRa\u5e27\u6570\u636e\u96c6\uff0c\u5efa\u7acb\u4e86\u5305\u542b\u63a5\u6536\u5668\u8ddd\u79bb\u76f8\u5173\u6027\u7684\u7ecf\u9a8c\u4f20\u64ad\u4fe1\u9053\u6a21\u578b\uff0c\u6570\u636e\u96c6\u8fd8\u5305\u542b\u540c\u6b65\u4fe1\u606f\u53ef\u7528\u4e8e\u63a5\u6536\u673a\u7b97\u6cd5\u8bc4\u4f30\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3aLoRa\u7f51\u7edc\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u4e13\u95e8\u7684\u4fe1\u9053\u6a21\u578b\u548c\u5b9e\u9a8c\u6570\u636e\u96c6\uff0c\u586b\u8865\u4e86LoRa\u7279\u5b9a\u4fe1\u9053\u5efa\u6a21\u7684\u7a7a\u767d\uff0c\u652f\u6301\u672a\u6765LoRa\u7f51\u7edc\u4f18\u5316\u548c\u63a5\u6536\u673a\u7b97\u6cd5\u5f00\u53d1\u3002"}}
{"id": "2512.15279", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15279", "abs": "https://arxiv.org/abs/2512.15279", "authors": ["Le Hao", "Robin Neuder", "Mohamadreza Delbari", "Alejandro Jim\u00e9nez-S\u00e1ez", "Vahid Jamali", "Arash Asadi", "Andrea Ortiz"], "title": "Learning-Based Phase Shift Optimization of Liquid Crystal RIS in Dynamic mmWave Networks", "comment": null, "summary": "To enhance coverage and signal quality in millimeter-wave (mmWave) frequencies, reconfigurable intelligent surfaces (RISs) have emerged as a game-changing solution to manipulate the wireless environment. Traditional semiconductor-based RISs face scalability issues due to high power consumption. Meanwhile, liquid crystal-based RISs (LC-RISs) offer energy-efficient and cost-effective operation even for large arrays. However, this promise has a caveat. LC-RISs suffer from long reconfiguration times, on the order of tens of milliseconds, which limits their applicability in dynamic scenarios. To date, prior works have focused on hardware design aspects or static scenarios to address this limitation, but little attention has been paid to optimization solutions for dynamic settings. Our paper fills this gap by proposing a reinforcement learning-based optimization framework to dynamically control the phase shifts of LC-RISs and maximize the data rate of a moving user. Specifically, we propose a Deep Deterministic Policy Gradient (DDPG) algorithm that adapts the LC-RIS phase shifts without requiring perfect channel state information and balances the tradeoff between signal-to-noise ratio (SNR) and configuration time. We validate our approach through high-fidelity ray tracing simulations, leveraging measurement data from an LC-RIS prototype. Our results demonstrate the potential of our solution to bring adaptive control to dynamic LC-RIS-assisted mmWave systems.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684LC-RIS\u76f8\u4f4d\u4f18\u5316\u6846\u67b6\uff0c\u89e3\u51b3\u6db2\u6676\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u5728\u52a8\u6001\u573a\u666f\u4e2d\u91cd\u914d\u7f6e\u65f6\u95f4\u8fc7\u957f\u7684\u95ee\u9898\uff0c\u901a\u8fc7DDPG\u7b97\u6cd5\u81ea\u9002\u5e94\u63a7\u5236\u76f8\u4f4d\u4ee5\u6700\u5927\u5316\u79fb\u52a8\u7528\u6237\u6570\u636e\u901f\u7387\u3002", "motivation": "\u6beb\u7c73\u6ce2\u901a\u4fe1\u4e2d\uff0c\u4f20\u7edf\u534a\u5bfc\u4f53RIS\u5b58\u5728\u529f\u8017\u9ad8\u3001\u6269\u5c55\u6027\u5dee\u7684\u95ee\u9898\uff0c\u800c\u6db2\u6676RIS(LC-RIS)\u867d\u7136\u80fd\u6548\u9ad8\u3001\u6210\u672c\u4f4e\uff0c\u4f46\u91cd\u914d\u7f6e\u65f6\u95f4\u957f\u8fbe\u6570\u5341\u6beb\u79d2\uff0c\u9650\u5236\u4e86\u5176\u5728\u52a8\u6001\u573a\u666f\u4e2d\u7684\u5e94\u7528\u3002\u73b0\u6709\u7814\u7a76\u591a\u5173\u6ce8\u786c\u4ef6\u8bbe\u8ba1\u6216\u9759\u6001\u573a\u666f\uff0c\u7f3a\u4e4f\u9488\u5bf9\u52a8\u6001\u73af\u5883\u7684\u4f18\u5316\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u4f18\u5316\u6846\u67b6\uff0c\u91c7\u7528\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6(DDPG)\u7b97\u6cd5\u52a8\u6001\u63a7\u5236LC-RIS\u76f8\u4f4d\u504f\u79fb\u3002\u8be5\u7b97\u6cd5\u4e0d\u9700\u8981\u5b8c\u7f8e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff0c\u80fd\u591f\u5e73\u8861\u4fe1\u566a\u6bd4(SNR)\u4e0e\u914d\u7f6e\u65f6\u95f4\u4e4b\u95f4\u7684\u6743\u8861\u3002", "result": "\u901a\u8fc7\u9ad8\u4fdd\u771f\u5c04\u7ebf\u8ffd\u8e2a\u4eff\u771f\u9a8c\u8bc1\u65b9\u6cd5\u6709\u6548\u6027\uff0c\u5229\u7528LC-RIS\u539f\u578b\u6d4b\u91cf\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\u3002\u7ed3\u679c\u8868\u660e\u8be5\u89e3\u51b3\u65b9\u6848\u80fd\u591f\u4e3a\u52a8\u6001LC-RIS\u8f85\u52a9\u6beb\u7c73\u6ce2\u7cfb\u7edf\u5e26\u6765\u81ea\u9002\u5e94\u63a7\u5236\u80fd\u529b\u3002", "conclusion": "\u672c\u6587\u586b\u8865\u4e86LC-RIS\u5728\u52a8\u6001\u573a\u666f\u4f18\u5316\u65b9\u9762\u7684\u7814\u7a76\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\u80fd\u591f\u6709\u6548\u89e3\u51b3\u6db2\u6676RIS\u91cd\u914d\u7f6e\u65f6\u95f4\u957f\u7684\u9650\u5236\uff0c\u4e3a\u52a8\u6001\u6beb\u7c73\u6ce2\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u81ea\u9002\u5e94\u63a7\u5236\u65b9\u6848\u3002"}}
{"id": "2512.15283", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15283", "abs": "https://arxiv.org/abs/2512.15283", "authors": ["Colin Cros", "Laurent Ferro-Famil"], "title": "Moment-Matching Array Processing Technique for diffuse source estimation", "comment": null, "summary": "Direction of Arrival (DOA) estimation is a fundamental problem in signal processing. Diffuse sources, whose power density cannot be represented with a single angular coordinate, are usually characterized based on prior assumptions, which associate the source angular density with a specific set of functions. However, these assumptions can lead to significant estimation biases when they are incorrect. This paper introduces the Moment-Matching Estimation Technique (MoMET), a low-complexity method for estimating the mean DOA, spread, and power of a narrow diffuse source without requiring prior knowledge on the source distribution. The unknown source density is characterized by its mean DOA and its first central moments, which are estimated through covariance matching techniques which fit the empirical covariance of the measurements to that modeled from the moments. The MoMET parameterization is robust to incorrect model assumptions, and numerically efficient. The asymptotic bias and covariance of the new estimator are derived and its performance is demonstrated through simulations.", "AI": {"tldr": "MoMET\u662f\u4e00\u79cd\u4f4e\u590d\u6742\u5ea6\u65b9\u6cd5\uff0c\u7528\u4e8e\u4f30\u8ba1\u7a84\u5e26\u6269\u6563\u6e90\u7684\u5e73\u5747DOA\u3001\u6269\u5c55\u548c\u529f\u7387\uff0c\u65e0\u9700\u6e90\u5206\u5e03\u7684\u5148\u9a8c\u77e5\u8bc6\u3002", "motivation": "\u4f20\u7edfDOA\u4f30\u8ba1\u65b9\u6cd5\u901a\u5e38\u57fa\u4e8e\u5bf9\u6e90\u89d2\u5ea6\u5206\u5e03\u7684\u7279\u5b9a\u51fd\u6570\u5047\u8bbe\uff0c\u5f53\u8fd9\u4e9b\u5047\u8bbe\u4e0d\u6b63\u786e\u65f6\u4f1a\u5bfc\u81f4\u663e\u8457\u7684\u4f30\u8ba1\u504f\u5dee\u3002\u9700\u8981\u4e00\u79cd\u4e0d\u4f9d\u8d56\u5148\u9a8c\u5206\u5e03\u5047\u8bbe\u7684\u9c81\u68d2\u4f30\u8ba1\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u77e9\u5339\u914d\u4f30\u8ba1\u6280\u672f\uff0c\u5c06\u672a\u77e5\u6e90\u5bc6\u5ea6\u7528\u5176\u5e73\u5747DOA\u548c\u524d\u51e0\u4e2a\u4e2d\u5fc3\u77e9\u6765\u8868\u5f81\uff0c\u901a\u8fc7\u534f\u65b9\u5dee\u5339\u914d\u6280\u672f\u5c06\u6d4b\u91cf\u503c\u7684\u7ecf\u9a8c\u534f\u65b9\u5dee\u4e0e\u77e9\u5efa\u6a21\u7684\u534f\u65b9\u5dee\u8fdb\u884c\u62df\u5408\u3002", "result": "MoMET\u53c2\u6570\u5316\u5bf9\u9519\u8bef\u6a21\u578b\u5047\u8bbe\u5177\u6709\u9c81\u68d2\u6027\uff0c\u6570\u503c\u8ba1\u7b97\u9ad8\u6548\u3002\u63a8\u5bfc\u4e86\u4f30\u8ba1\u5668\u7684\u6e10\u8fd1\u504f\u5dee\u548c\u534f\u65b9\u5dee\uff0c\u5e76\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u5176\u6027\u80fd\u3002", "conclusion": "MoMET\u63d0\u4f9b\u4e86\u4e00\u79cd\u65e0\u9700\u5148\u9a8c\u5206\u5e03\u77e5\u8bc6\u7684\u4f4e\u590d\u6742\u5ea6DOA\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5bf9\u6269\u6563\u6e90\u7684\u5e73\u5747DOA\u3001\u6269\u5c55\u548c\u529f\u7387\u4f30\u8ba1\u5177\u6709\u9c81\u68d2\u6027\u548c\u6709\u6548\u6027\u3002"}}
{"id": "2512.15290", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15290", "abs": "https://arxiv.org/abs/2512.15290", "authors": ["Jie Zhou", "Junhao Xie"], "title": "On the Asymptotic Performance of Diagonally Loaded Detectors for Large Arrays: To Achieve CFAR and Optimality", "comment": null, "summary": "This paper addresses two critical limitations in diagonally loaded (DL) adaptive matched filter (AMF) detector: (1) the lack of CFAR property with respect to arbitrary covariance matrices, and (2) the absence of selection criteria for optimal loading factor from the perspective of maximizing the detection probability (Pd). We provide solutions to both challenges through a comprehensive analysis for the asymptotic performance of DL-AMF under large dimensional regime (LDR) where the dimension N and sample size K tend to infinity whereas their ratio N/K converges to a constant c\\in(0,1). The analytical results show that any DL detectors constructed by normalizing the random variable |a|2=|sH(R+\u03bbIN)-1y0|2 with a deterministic quantity or a random variable that converges almost surely to a deterministic value will exhibit equivalent performance under LDR. Following this idea, we derive two CFAR DL detectors: CFAR DL semi-clairvoyant matched filter (CFAR-DL-SCMF) detector and CFAR DL adaptive matched filter (CFAR-DL-AMF) detector, by normalizing |a|2 with an appropriate deterministic quantity and its consistent estimate, respectively. The theoretical analysis and simulations show that both CFAR-DL-SCMF and CFAR-DL-AMF achieve CFAR with respect to covariance matrix, target steering vector and loading factor. Furthermore, we derive the asymptotically optimal loading factor \u03bb_opt by maximizing the explicit expression of asymptotic Pd. For practical implementation, we provide a consistent estimator for \u03bb_opt under LDR. Based on \u03bb_opt and its consistent estimate, we establish the optimal CFAR-DL-SCMF (opt-CFAR-DL-SCMF) and the optimal CFAR-DL-AMF (opt-CFAR-DL-AMF). Numerical examples demonstrate that the proposed opt-CFAR-DL-SCMF and opt-CFAR-DL-AMF consistently outperform EL-AMF and persymmetric AMF in both full-rank and low-rank clutter plus noise environments.", "AI": {"tldr": "\u672c\u6587\u89e3\u51b3\u4e86\u5bf9\u89d2\u52a0\u8f7d\u81ea\u9002\u5e94\u5339\u914d\u6ee4\u6ce2\u5668\uff08DL-AMF\uff09\u7684\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff1a\u7f3a\u4e4f\u5bf9\u4efb\u610f\u534f\u65b9\u5dee\u77e9\u9635\u7684CFAR\u7279\u6027\uff0c\u4ee5\u53ca\u4ece\u6700\u5927\u5316\u68c0\u6d4b\u6982\u7387\u89d2\u5ea6\u7f3a\u4e4f\u6700\u4f18\u52a0\u8f7d\u56e0\u5b50\u9009\u62e9\u6807\u51c6\u3002\u901a\u8fc7\u5927\u7ef4\u6e10\u8fd1\u5206\u6790\uff0c\u63d0\u51fa\u4e86\u4e24\u79cdCFAR DL\u68c0\u6d4b\u5668\uff0c\u5e76\u63a8\u5bfc\u4e86\u6e10\u8fd1\u6700\u4f18\u52a0\u8f7d\u56e0\u5b50\u3002", "motivation": "\u4f20\u7edfDL-AMF\u68c0\u6d4b\u5668\u5b58\u5728\u4e24\u4e2a\u4e3b\u8981\u95ee\u9898\uff1a1\uff09\u5bf9\u4e8e\u4efb\u610f\u534f\u65b9\u5dee\u77e9\u9635\u4e0d\u5177\u5907\u6052\u865a\u8b66\u7387\uff08CFAR\uff09\u7279\u6027\uff1b2\uff09\u7f3a\u4e4f\u4ece\u6700\u5927\u5316\u68c0\u6d4b\u6982\u7387\u89d2\u5ea6\u9009\u62e9\u6700\u4f18\u52a0\u8f7d\u56e0\u5b50\u7684\u6807\u51c6\u3002\u8fd9\u4e9b\u95ee\u9898\u9650\u5236\u4e86DL-AMF\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u91c7\u7528\u5927\u7ef4\u6e10\u8fd1\u5206\u6790\u6846\u67b6\uff0c\u5176\u4e2d\u7ef4\u5ea6N\u548c\u6837\u672c\u91cfK\u8d8b\u4e8e\u65e0\u7a77\u5927\uff0c\u5176\u6bd4\u503c\u6536\u655b\u4e8e\u5e38\u6570c\u2208(0,1)\u3002\u901a\u8fc7\u7406\u8bba\u5206\u6790\u8bc1\u660e\uff0c\u4efb\u4f55\u901a\u8fc7\u786e\u5b9a\u6027\u91cf\u6216\u51e0\u4e4e\u5fc5\u7136\u6536\u655b\u4e8e\u786e\u5b9a\u6027\u91cf\u7684\u968f\u673a\u53d8\u91cf\u5f52\u4e00\u5316\u6784\u9020\u7684DL\u68c0\u6d4b\u5668\u5728\u5927\u7ef4\u6e10\u8fd1\u4e0b\u5177\u6709\u7b49\u6548\u6027\u80fd\u3002\u57fa\u4e8e\u6b64\uff0c\u63d0\u51fa\u4e86\u4e24\u79cdCFAR DL\u68c0\u6d4b\u5668\uff1aCFAR-DL-SCMF\u548cCFAR-DL-AMF\uff0c\u5e76\u63a8\u5bfc\u4e86\u6e10\u8fd1\u6700\u4f18\u52a0\u8f7d\u56e0\u5b50\u03bb_opt\u3002", "result": "\u7406\u8bba\u5206\u6790\u548c\u4eff\u771f\u8868\u660e\uff0c\u63d0\u51fa\u7684CFAR-DL-SCMF\u548cCFAR-DL-AMF\u5bf9\u534f\u65b9\u5dee\u77e9\u9635\u3001\u76ee\u6807\u5bfc\u5411\u5411\u91cf\u548c\u52a0\u8f7d\u56e0\u5b50\u5747\u5177\u6709CFAR\u7279\u6027\u3002\u63a8\u5bfc\u51fa\u7684\u6e10\u8fd1\u6700\u4f18\u52a0\u8f7d\u56e0\u5b50\u03bb_opt\u80fd\u6700\u5927\u5316\u68c0\u6d4b\u6982\u7387\u3002\u57fa\u4e8e\u03bb_opt\u53ca\u5176\u4e00\u81f4\u4f30\u8ba1\uff0c\u5efa\u7acb\u4e86\u6700\u4f18CFAR\u68c0\u6d4b\u5668opt-CFAR-DL-SCMF\u548copt-CFAR-DL-AMF\u3002", "conclusion": "\u672c\u6587\u6210\u529f\u89e3\u51b3\u4e86DL-AMF\u7684\u4e24\u4e2a\u5173\u952e\u9650\u5236\uff0c\u63d0\u51fa\u4e86\u5177\u6709CFAR\u7279\u6027\u7684DL\u68c0\u6d4b\u5668\uff0c\u5e76\u63d0\u4f9b\u4e86\u6700\u4f18\u52a0\u8f7d\u56e0\u5b50\u7684\u7406\u8bba\u63a8\u5bfc\u548c\u5b9e\u7528\u4f30\u8ba1\u65b9\u6cd5\u3002\u6570\u503c\u5b9e\u9a8c\u8868\u660e\uff0c\u63d0\u51fa\u7684\u6700\u4f18CFAR\u68c0\u6d4b\u5668\u5728\u6ee1\u79e9\u548c\u4f4e\u79e9\u6742\u6ce2\u52a0\u566a\u58f0\u73af\u5883\u4e2d\u5747\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2512.15441", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15441", "abs": "https://arxiv.org/abs/2512.15441", "authors": ["Gilderlan Tavares de Ara\u00fajo", "Andr\u00e9 L. F. de Almeida Buno Sokal", "Gabor Fodor", "Paulo R. B. Gomes"], "title": "Semi-Blind Joint Channel and Symbol Estimation for Beyond Diagonal Reconfigurable Surfaces", "comment": null, "summary": "The beyond-diagonal reconfigurable intelligent surface (BD-RIS) is a recent architecture in which scattering elements are interconnected to enhance the degrees of freedom for wave control, yielding performance gains over traditional single-connected RISs. For BD-RIS, channel estimation - well-studied for conventional RIS - becomes more challenging due to the complex connections and a larger number of coefficients. Prior works rely on pilot-assisted estimation followed by data decoding. This paper introduces a semi-blind tensor-based approach for joint channel and symbol estimation that eliminates the need for training sequences by leveraging data symbols directly. A practical scenario with time-varying user terminal-RIS channels under mobility is considered. By reformulating the received signal from a tensor decomposition perspective, we develop two semi-blind receivers: a two-stage method transforming the fourth-order PARATUCK model into a third-order PARAFAC model, and a single-stage iterative process based on fourth-order TUCKER decomposition. Identifiability conditions for reliable joint recovery are derived, and numerical results demonstrate the performance advantages and trade-offs of the proposed schemes over existing solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u5f20\u91cf\u5206\u89e3\u7684\u534a\u76f2\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\uff0c\u7528\u4e8eBD-RIS\u7cfb\u7edf\uff0c\u65e0\u9700\u8bad\u7ec3\u5e8f\u5217\uff0c\u901a\u8fc7\u6570\u636e\u7b26\u53f7\u76f4\u63a5\u8fdb\u884c\u8054\u5408\u4fe1\u9053\u548c\u7b26\u53f7\u4f30\u8ba1\u3002", "motivation": "BD-RIS\uff08\u8d85\u5bf9\u89d2\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff09\u901a\u8fc7\u6563\u5c04\u5355\u5143\u4e92\u8fde\u589e\u5f3a\u4e86\u6ce2\u675f\u63a7\u5236\u81ea\u7531\u5ea6\uff0c\u4f46\u590d\u6742\u7684\u8fde\u63a5\u548c\u66f4\u591a\u7cfb\u6570\u4f7f\u5f97\u4fe1\u9053\u4f30\u8ba1\u6bd4\u4f20\u7edfRIS\u66f4\u5177\u6311\u6218\u6027\u3002\u73b0\u6709\u65b9\u6cd5\u4f9d\u8d56\u5bfc\u9891\u8f85\u52a9\u4f30\u8ba1\uff0c\u672c\u6587\u65e8\u5728\u6d88\u9664\u8bad\u7ec3\u5e8f\u5217\u9700\u6c42\u3002", "method": "\u63d0\u51fa\u4e24\u79cd\u534a\u76f2\u63a5\u6536\u5668\uff1a1\uff09\u4e24\u9636\u6bb5\u65b9\u6cd5\uff0c\u5c06\u56db\u9636PARATUCK\u6a21\u578b\u8f6c\u6362\u4e3a\u4e09\u9636PARAFAC\u6a21\u578b\uff1b2\uff09\u5355\u9636\u6bb5\u8fed\u4ee3\u65b9\u6cd5\uff0c\u57fa\u4e8e\u56db\u9636TUCKER\u5206\u89e3\u3002\u4e24\u79cd\u65b9\u6cd5\u90fd\u4ece\u5f20\u91cf\u5206\u89e3\u89d2\u5ea6\u91cd\u6784\u63a5\u6536\u4fe1\u53f7\uff0c\u8003\u8651\u65f6\u53d8\u7528\u6237\u7ec8\u7aef-RIS\u4fe1\u9053\u3002", "result": "\u63a8\u5bfc\u4e86\u53ef\u9760\u8054\u5408\u6062\u590d\u7684\u53ef\u8bc6\u522b\u6027\u6761\u4ef6\uff0c\u6570\u503c\u7ed3\u679c\u8868\u660e\u6240\u63d0\u65b9\u6848\u5728\u6027\u80fd\u4e0a\u4f18\u4e8e\u73b0\u6709\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u5c55\u793a\u4e86\u4e0d\u540c\u65b9\u6848\u95f4\u7684\u6743\u8861\u3002", "conclusion": "\u63d0\u51fa\u7684\u534a\u76f2\u5f20\u91cf\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86BD-RIS\u7cfb\u7edf\u7684\u4fe1\u9053\u4f30\u8ba1\u6311\u6218\uff0c\u65e0\u9700\u8bad\u7ec3\u5e8f\u5217\uff0c\u5728\u79fb\u52a8\u6027\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u8054\u5408\u4fe1\u9053\u548c\u7b26\u53f7\u4f30\u8ba1\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2512.15546", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15546", "abs": "https://arxiv.org/abs/2512.15546", "authors": ["Heedong Do", "Angel Lozano"], "title": "Optimum Discrete Beamforming via Minkowski Sum of Polygons", "comment": null, "summary": "This letter casts the problem of optimum discrete beamforming as the computation of the Minkowski sum of convex polygons, which is itself a convex polygon. The number of vertices of the latter is at most the sum of the number of vertices of the original polygons, enabling its efficient computation. This original and intuitive formulation confirms that the optimum beamforming solution can be found efficiently.", "AI": {"tldr": "\u8be5\u8bba\u6587\u5c06\u6700\u4f18\u79bb\u6563\u6ce2\u675f\u6210\u5f62\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u591a\u8fb9\u5f62Minkowski\u548c\u7684\u8ba1\u7b97\uff0c\u8bc1\u660e\u8be5\u95ee\u9898\u53ef\u9ad8\u6548\u6c42\u89e3\u3002", "motivation": "\u4f20\u7edf\u79bb\u6563\u6ce2\u675f\u6210\u5f62\u4f18\u5316\u95ee\u9898\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u8981\u5bfb\u627e\u66f4\u9ad8\u6548\u76f4\u89c2\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u5c06\u79bb\u6563\u6ce2\u675f\u6210\u5f62\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u4e3a\u51f8\u591a\u8fb9\u5f62\u7684Minkowski\u548c\u8ba1\u7b97\u95ee\u9898\uff0c\u5229\u7528\u51f8\u591a\u8fb9\u5f62Minkowski\u548c\u7684\u6027\u8d28\uff08\u7ed3\u679c\u4ecd\u4e3a\u51f8\u591a\u8fb9\u5f62\u4e14\u9876\u70b9\u6570\u6709\u754c\uff09\u5b9e\u73b0\u9ad8\u6548\u8ba1\u7b97\u3002", "result": "\u8bc1\u660e\u6700\u4f18\u6ce2\u675f\u6210\u5f62\u89e3\u53ef\u4ee5\u901a\u8fc7\u8ba1\u7b97\u51f8\u591a\u8fb9\u5f62\u7684Minkowski\u548c\u9ad8\u6548\u83b7\u5f97\uff0c\u8be5Minkowski\u548c\u672c\u8eab\u4e5f\u662f\u51f8\u591a\u8fb9\u5f62\uff0c\u5176\u9876\u70b9\u6570\u6700\u591a\u4e3a\u539f\u59cb\u591a\u8fb9\u5f62\u9876\u70b9\u6570\u4e4b\u548c\u3002", "conclusion": "\u901a\u8fc7\u5c06\u79bb\u6563\u6ce2\u675f\u6210\u5f62\u95ee\u9898\u8f6c\u5316\u4e3a\u51f8\u591a\u8fb9\u5f62Minkowski\u548c\u8ba1\u7b97\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u539f\u59cb\u4e14\u76f4\u89c2\u7684\u8868\u8ff0\uff0c\u8bc1\u5b9e\u4e86\u6700\u4f18\u6ce2\u675f\u6210\u5f62\u89e3\u53ef\u4ee5\u9ad8\u6548\u627e\u5230\u3002"}}
{"id": "2512.15558", "categories": ["eess.SP", "cs.NI"], "pdf": "https://arxiv.org/pdf/2512.15558", "abs": "https://arxiv.org/abs/2512.15558", "authors": ["Nadia Abdolkhani", "Nada Abdel Khalek", "Walaa Hamouda"], "title": "Deep Reinforcement Learning for EH-Enabled Cognitive-IoT Under Jamming Attacks", "comment": "Published in IEEE Internet of Things Journal. This arXiv version is the authors' accepted manuscript", "summary": "In the evolving landscape of the Internet of Things (IoT), integrating cognitive radio (CR) has become a practical solution to address the challenge of spectrum scarcity, leading to the development of cognitive IoT (CIoT). However, the vulnerability of radio communications makes radio jamming attacks a key concern in CIoT networks. In this paper, we introduce a novel deep reinforcement learning (DRL) approach designed to optimize throughput and extend network lifetime of an energy-constrained CIoT system under jamming attacks. This DRL framework equips a CIoT device with the autonomy to manage energy harvesting (EH) and data transmission, while also regulating its transmit power to respect spectrum-sharing constraints. We formulate the optimization problem under various constraints, and we model the CIoT device's interactions within the channel as a model-free Markov decision process (MDP). The MDP serves as a foundation to develop a double deep Q-network (DDQN), designed to help the CIoT agent learn the optimal communication policy to navigate challenges such as dynamic channel occupancy, jamming attacks, and channel fading while achieving its goal. Additionally, we introduce a variant of the upper confidence bound (UCB) algorithm, named UCB-IA, which enhances the CIoT network's ability to efficiently navigate jamming attacks within the channel. The proposed DRL algorithm does not rely on prior knowledge and uses locally observable information such as channel occupancy, jamming activity, channel gain, and energy arrival to make decisions. Extensive simulations prove that our proposed DRL algorithm that utilizes the UCB-IA strategy surpasses existing benchmarks, allowing for a more adaptive, energy-efficient, and secure spectrum sharing in CIoT networks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u8ba4\u77e5\u7269\u8054\u7f51\u6297\u5e72\u6270\u65b9\u6848\uff0c\u901a\u8fc7DDQN\u548cUCB-IA\u7b97\u6cd5\u4f18\u5316\u541e\u5410\u91cf\u548c\u7f51\u7edc\u5bff\u547d", "motivation": "\u8ba4\u77e5\u7269\u8054\u7f51\u9762\u4e34\u9891\u8c31\u7a00\u7f3a\u548c\u65e0\u7ebf\u7535\u5e72\u6270\u653b\u51fb\u7684\u6311\u6218\uff0c\u9700\u8981\u667a\u80fd\u7684\u6297\u5e72\u6270\u548c\u80fd\u91cf\u7ba1\u7406\u65b9\u6848", "method": "\u91c7\u7528\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u5c06\u95ee\u9898\u5efa\u6a21\u4e3a\u65e0\u6a21\u578b\u9a6c\u5c14\u53ef\u592b\u51b3\u7b56\u8fc7\u7a0b\uff0c\u5f00\u53d1DDQN\u7b97\u6cd5\u548cUCB-IA\u53d8\u4f53\uff0c\u5b9e\u73b0\u81ea\u4e3b\u80fd\u91cf\u6536\u96c6\u3001\u6570\u636e\u4f20\u8f93\u548c\u529f\u7387\u63a7\u5236", "result": "\u4eff\u771f\u8868\u660e\u63d0\u51fa\u7684DRL\u7b97\u6cd5\u4f18\u4e8e\u73b0\u6709\u57fa\u51c6\uff0c\u5b9e\u73b0\u4e86\u66f4\u81ea\u9002\u5e94\u3001\u8282\u80fd\u548c\u5b89\u5168\u7684\u9891\u8c31\u5171\u4eab", "conclusion": "\u63d0\u51fa\u7684DRL\u6846\u67b6\u80fd\u6709\u6548\u5e94\u5bf9\u8ba4\u77e5\u7269\u8054\u7f51\u4e2d\u7684\u5e72\u6270\u653b\u51fb\uff0c\u4f18\u5316\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u5b89\u5168\u9891\u8c31\u5171\u4eab\u63d0\u4f9b\u65b0\u65b9\u6848"}}

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [eess.AS](#eess.AS) [Total: 2]
- [cs.SD](#cs.SD) [Total: 5]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Multiple Source Localization via Local Radio Map Construction in Urban Environments](https://arxiv.org/abs/2512.15724)
*Qilu Zhang,Hongying Tang,Wen Chen,Ziyi Song,Jiang Wang*

Main category: eess.SP

TL;DR: LRM-MSL是一个用于城市环境中多源定位的通用框架，通过构建局部无线电地图、二值化和连通分量分析实现多源分离，再使用坐标回归网络进行单源定位，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么无法有效利用接收信号强度信息，要么缺乏对任意数量源的通用性，而城市环境中的多源定位在认知无线电等领域有重要应用。

Method: 1) 构建仅保留源周围RSS信息的局部无线电地图并二值化；2) 应用连通分量分析实现多源分离，将多源定位问题转化为一系列单源定位任务；3) 设计数值坐标回归网络执行单源定位任务。

Result: 构建了VaryTxLoc数据集进行评估，实验结果表明LRM-MSL是一种准确有效的方法，优于最先进的现有方法。

Conclusion: LRM-MSL是一个通用的多源定位框架，能够处理任意数量的源，在城市环境中具有准确性和有效性，代码和数据集已开源。

Abstract: Accurately and efficiently addressing the multiple source localization (MSL) problem in urban environments, particularly designing a general method adaptable to an arbitrary number of sources, plays a crucial role in various fields such as cognitive radio (CR).
  Existing methods either fail to effectively utilize received signal strength (RSS) information without redundancy or lack generalizability to an arbitrary number of sources.
  In this work, we propose the Local Radio Map-Aided Multiple Source Localization Framework (LRM-MSL), which is a general method capable of handling an arbitrary number of sources.
  First, this framework constructs a local radio map that retains only the RSS information around the sources and binarizes it. Then, the connected component analysis tool is applied to the binarized map, which implements multi-source separation, transforming the MSL problem into a series of single-source localization (SSL) tasks.
  Finally, we design a numerical coordinate regression network to perform the SSL tasks.
  Since there is no publicly available RSS dataset for MSL, we construct the VaryTxLoc dataset to evaluate the performance of LRM-MSL. Experimental results demonstrate that LRM-MSL is an accurate and effective method, outperforming state-of-the-art approaches. Our code and dataset can be downloaded from https://github.com/hereis77/LRM-MSL.

</details>


### [2] [TinyMyo: a Tiny Foundation Model for Flexible EMG Signal Processing at the Edge](https://arxiv.org/abs/2512.15729)
*Matteo Fasulo,Giusy Spacone,Thorir Mar Ingolfsson,Yawei Li,Luca Benini,Andrea Cossettini*

Main category: eess.SP

TL;DR: TinyMyo：一个轻量级表面肌电信号基础模型，基于Transformer编码器架构，仅3.6M参数，通过自监督预训练实现多任务泛化，并在超低功耗微控制器上部署成功。


<details>
  <summary>Details</summary>
Motivation: 表面肌电信号（EMG）在多个领域有广泛应用，但现有技术面临跨主体、跨系统、跨协议的泛化挑战。现有EMG基础模型局限于单一任务且难以在嵌入式平台部署。

Method: 提出TinyMyo轻量级基础模型，基于Transformer编码器架构，使用公开数据集进行自监督预训练。通过最小化的任务特定头部适配，同一骨干网络可处理手势分类、手部运动学回归、语音生成与识别等多种下游任务。

Result: 模型仅3.6M参数，在多个数据集上达到或超越现有最佳性能：NinaPro DB5（89.4±0.16%）、UCI-EMG（97.56±0.32%）、EPN-612（96.74±0.09%）。首次在超低功耗微控制器（GAP9）上部署EMG基础模型，平均功耗仅36.45mW。

Conclusion: TinyMyo提供了一个轻量级、可部署的EMG基础模型，能够跨任务、跨硬件平台泛化，为EMG社区提供了灵活的研究资源，有望加速未来研究和应用开发。

Abstract: Surface electromyography (EMG) is a non-invasive sensing modality used in several domains, including biomechanics, rehabilitation, prosthetic control, and emerging human-machine interaction paradigms. Despite decades of use, significant challenges remain in achieving robust generalization across subjects, recording systems, and acquisition protocols. To tackle these challenges, foundation models (FMs) are gaining traction when targeting end-to-end applications based on EMG signals. Yet, existing EMG FMs remain limited to single downstream tasks and lack deployability on embedded platforms. In this work, we present TinyMyo, a lightweight FM based on a Transformer encoder architecture. The model is pre-trained in a self-supervised manner on publicly available datasets and achieves high reconstruction fidelity with only 3.6M parameters. With minimal task-specific head adaptations, the same backbone is used to tackle multiple downstream tasks, leveraging datasets acquired from diverse sensing locations and hardware platforms. We demonstrate generalization across hand gesture classification, hand kinematic regression, speech production and recognition, with performance comparable to or surpassing the state of the art (SoA), and model size below 5M parameters. We achieve SoA results compared to previous FM-based works on the NinaPro DB5 ($89.4\pm0.16\%$), UCI-EMG ($97.56\pm0.32\%$), and EPN-612 ($96.74\pm0.09\%$) datasets. We report, to the best of our knowledge, the first deployment of an EMG FM on an ultra-low-power microcontroller (GAP9), achieving an average power envelope of 36.45mW. By open-sourcing the pre-trained and the downstream task architectures (https://github.com/pulp-bio/BioFoundation), we aim to provide a flexible resource that can accelerate future research and serve as a common foundation for the EMG community.

</details>


### [3] [HiLTS: Human in the Loop Therapeutic System: A Wireless-enabled Precision Medicine Platform for Brainwave Entrainment](https://arxiv.org/abs/2512.15807)
*Arfan Ghani*

Main category: eess.SP

TL;DR: 研究人员开发了一种最小化数字定制芯片，可产生稳定的6Hz振荡来干扰癫痫发作活动，为低功耗可穿戴癫痫干预设备提供概念验证。


<details>
  <summary>Details</summary>
Motivation: 全球有超过5000万癫痫患者，尽管药物治疗有所进展，但仍有大量患者癫痫发作无法控制。现有神经调节策略大多依赖复杂的模拟电子设备或高功率刺激硬件，需要更简单、低功耗的替代方案。

Method: 使用公开可用的EEG癫痫数据集，提取并平均模拟癫痫波形，将其数字化以模拟神经前端，然后直接与定制设计的数字芯片接口。芯片脉冲序列被重采样和低通重构以产生模拟6Hz波形，进行频域和时域分析。

Result: 芯片施加的窄带6Hz节律能够覆盖癫痫活动的宽带频谱特征，证明数字定制芯片能够有效干扰癫痫发作活动。

Conclusion: 该研究为低功耗数字定制神经调节提供了概念验证，为开发简化的可穿戴癫痫干预设备开辟了潜在途径，适用于精准医疗和未来医疗设备。

Abstract: Epileptic seizures arise from abnormally synchronised neural activity and remain a major global health challenge, affecting more than 50 million people worldwide. Despite advances in pharmacological interventions, a significant proportion of patients continue to experience uncontrolled seizures, underscoring the need for alternative neuromodulation strategies. Rhythmic neural entrainment has recently emerged as a promising mechanism for disrupting pathological synchrony, but most existing systems rely on complex analogue electronics or high-power stimulation hardware. This study investigates a minimal digital custom-designed chip that generates a stable 6 Hz oscillation capable of entraining epileptic seizure activity. Using a publicly available EEG seizure dataset, we extracted and averaged analogue seizure waveforms, digitised them to emulate neural front-ends, and directly interfaced the digitised signals with digital output recordings acquired from the chip using a Saleae Logic analyser. The chip pulse train was resampled and low-pass-reconstructed to produce an analogue 6 Hz waveform, allowing direct comparison between seizure morphology, its digitised representation, and the entrained output. Frequency-domain and time-domain analyses demonstrate that the chip imposes a narrow-band 6 Hz rhythm that overrides the broadband spectral profile of seizure activity. These results provide a proof-of-concept for low-power digital custom-designed entrainment as a potential pathway toward simplified, wearable seizure-interruption devices for precision medicine and future healthcare devices.

</details>


### [4] [Concurrence: A dependence criterion for time series, applied to biological data](https://arxiv.org/abs/2512.16001)
*Evangelos Sariyanidi,John D. Herrington,Lisa Yankowitz,Pratik Chaudhari,Theodore D. Satterthwaite,Casey J. Zampella,Jeffrey S. Morris,Edward Gunning,Robert T. Schultz,Russell T. Shinohara,Birkan Tunc*

Main category: eess.SP

TL;DR: 提出名为"concurrence"的依赖度量标准，通过分类器区分时间对齐与错齐的序列片段来检测信号间的统计依赖关系


<details>
  <summary>Details</summary>
Motivation: 生物系统常表现出复杂的非线性相互作用，现有方法需要先验知识或大数据集才能捕捉这些关系，需要一种无需参数调优或大量数据就能检测广泛信号间依赖关系的方法

Method: 引入concurrence标准：如果能够构建一个分类器来区分从两个时间序列中提取的时间对齐与时间错齐的片段，则认为这两个时间序列是依赖的。该方法理论上与依赖关系相关联

Result: concurrence能够暴露多种信号（fMRI、生理和行为数据）之间的关系，无需特定参数调优或大量数据，可成为跨学科科学分析的标准方法

Conclusion: concurrence为检测复杂非线性相互作用提供了一种通用、无需大量数据的依赖度量方法，有望成为跨学科科学发现的标准工具

Abstract: Measuring the statistical dependence between observed signals is a primary tool for scientific discovery. However, biological systems often exhibit complex non-linear interactions that currently cannot be captured without a priori knowledge or large datasets. We introduce a criterion for dependence, whereby two time series are deemed dependent if one can construct a classifier that distinguishes between temporally aligned vs. misaligned segments extracted from them. We show that this criterion, concurrence, is theoretically linked with dependence, and can become a standard approach for scientific analyses across disciplines, as it can expose relationships across a wide spectrum of signals (fMRI, physiological and behavioral data) without ad-hoc parameter tuning or large amounts of data.

</details>


### [5] [Simultaneous Secrecy and Covert Communications (SSACC) in Mobility-Aware RIS-Aided Networks](https://arxiv.org/abs/2512.16224)
*Yanyu Cheng,Yujian Hu,Haoran Liu,Hua Zhong,Wei Wang,Pan Li,Dusit Niyato*

Main category: eess.SP

TL;DR: 提出一种RIS辅助网络中带协作干扰器的同时保密与隐蔽通信方案，通过最大化保密容量和检测错误概率来增强通信安全，并设计基于生成扩散模型和深度强化学习的算法来平衡性能


<details>
  <summary>Details</summary>
Motivation: 在无线通信中同时实现保密性和隐蔽性具有挑战性。传统方法难以在动态环境中平衡保密容量和检测错误概率，特别是在窃听者可以自适应调整检测阈值的最坏情况下，需要更智能的优化方案来应对用户移动性和资源分配问题。

Method: 提出RIS辅助网络中带协作干扰器的SSACC方案。在窃听者最优调整检测阈值的最坏情况下，推导出平均最小检测错误概率和平均保密容量的闭式表达式。设计基于生成扩散模型和深度强化学习的算法，通过优化功率分配来最大化数据速率，同时确保高AMDEP和ASC。

Result: 仿真结果表明，所提算法相比传统DDPG方法收敛更快且性能更优，有效验证了其在平衡安全性和容量性能方面的有效性。算法在用户移动性条件下仍能保持高性能。

Conclusion: 该研究成功实现了RIS辅助网络中同时保密与隐蔽通信的平衡优化，提出的GDM-DRL算法为动态无线环境中的安全通信提供了有效的解决方案，在安全性和容量性能之间取得了良好权衡。

Abstract: In this paper, we propose a simultaneous secrecy and covert communications (SSACC) scheme in a reconfigurable intelligent surface (RIS)-aided network with a cooperative jammer. The scheme enhances communication security by maximizing the secrecy capacity and the detection error probability (DEP). Under a worst-case scenario for covert communications, we consider that the eavesdropper can optimally adjust the detection threshold to minimize the DEP. Accordingly, we derive closedform expressions for both average minimum DEP (AMDEP) and average secrecy capacity (ASC). To balance AMDEP and ASC, we propose a new performance metric and design an algorithm based on generative diffusion models (GDM) and deep reinforcement learning (DRL). The algorithm maximizes data rates under user mobility while ensuring high AMDEP and ASC by optimizing power allocation. Simulation results demonstrate that the proposed algorithm achieves faster convergence and superior performance compared to conventional deep deterministic policy gradient (DDPG) methods, thereby validating its effectiveness in balancing security and capacity performance.

</details>


### [6] [Fast Collaborative Inference via Distributed Speculative Decoding](https://arxiv.org/abs/2512.16273)
*Ce Zheng,Ke Zhang,Sun Chen,Wenqi Zhang,Qiong Liu,Angesom Ataklity Tesfay*

Main category: eess.SP

TL;DR: 提出TSLT方法，通过传输截断稀疏对数来减少AI-RAN中分布式推测解码的上行通信开销，同时保持接受率和推理性能。


<details>
  <summary>Details</summary>
Motivation: 在AI原生无线接入网络中，设备-边缘协同推理使用推测解码加速LLM推理，但现有分布式方案在每个步骤传输完整词汇表对数，导致显著上行开销。

Method: 提出截断稀疏对数传输策略：先稀疏化再采样，仅传输截断候选集的logits和索引；扩展到多候选情况以提高接受概率；提供理论保证证明接受率在TSLT下得以保持。

Result: 实验表明TSLT显著减少上行通信，同时保持端到端推理延迟和模型质量，证明其在未来AI-RAN系统中实现可扩展、通信高效的分布式LLM推理的有效性。

Conclusion: TSLT为AI-RAN中的分布式LLM推理提供了一种通信高效的解决方案，通过稀疏化传输策略平衡了通信开销和推理性能，支持可扩展的协同推理系统。

Abstract: Speculative decoding accelerates large language model (LLM) inference by allowing a small draft model to predict multiple future tokens for verification by a larger target model. In AI-native radio access networks (AI-RAN), this enables device-edge collaborative inference but introduces significant uplink overhead, as existing distributed speculative decoding schemes transmit full vocabulary logits at every step. We propose a sparsify-then-sample strategy, Truncated Sparse Logits Transmission (TSLT), which transmits only the logits and indices of a truncated candidate set. We provide theoretical guarantees showing that the acceptance rate is preserved under TSLT. TSLT is further extended to multi-candidate case, where multiple draft candidates per step increase acceptance probability. Experiments show that TSLT significantly reduces uplink communication while maintaining end-to-end inference latency and model quality, demonstrating its effectiveness for scalable, communication-efficient distributed LLM inference in future AI-RAN systems.

</details>


### [7] [CPMamba: Selective State Space Models for MIMO Channel Prediction in High-Mobility Environments](https://arxiv.org/abs/2512.16315)
*Sheng Luo,Jiashu Xie,Yueling Che,Junmei Yao,Jian Tian,Daquan Feng,Kaishun Wu*

Main category: eess.SP

TL;DR: CPMamba是一个基于选择性状态空间模型的高效MIMO-OFDM信道预测框架，通过动态调整状态转移来捕捉长期依赖关系，在保持线性计算复杂度的同时，参数减少约50%，在各种场景下达到最先进的预测精度。


<details>
  <summary>Details</summary>
Motivation: 在高移动性场景中，快速时变信道的预测对于抵抗信道老化和保证通信质量至关重要。现有方法存在复杂度高和无法准确建模信道时间变化的问题。

Method: 提出CPMamba框架：1）使用专门设计的特征提取和嵌入网络从历史信道状态信息（CSI）中提取特征；2）采用堆叠的残差Mamba模块进行时间建模；3）利用输入依赖的选择性机制动态调整状态转移，有效捕捉CSI间的长期依赖关系，同时保持线性计算复杂度。

Result: 在3GPP标准信道模型下的仿真结果表明，CPMamba在所有场景下都达到了最先进的预测精度，并具有优异的泛化能力和鲁棒性。与现有基线模型相比，CPMamba参数数量减少约50%，同时达到相当或更好的性能。

Conclusion: CPMamba通过选择性状态空间模型有效解决了高移动性场景下的信道预测问题，显著降低了实际部署的门槛，为MIMO-OFDM系统中的预编码、自适应调制和资源分配等功能提供了高效的信道预测解决方案。

Abstract: Channel prediction is a key technology for improving the performance of various functions such as precoding, adaptive modulation, and resource allocation in MIMO-OFDM systems. Especially in high-mobility scenarios with fast time-varying channels, it is crucial for resisting channel aging and ensuring communication quality. However, existing methods suffer from high complexity and the inability to accurately model the temporal variations of channels. To address this issue, this paper proposes CPMamba -- an efficient channel prediction framework based on the selective state space model. The proposed CPMamba architecture extracts features from historical channel state information (CSI) using a specifically designed feature extraction and embedding network and employs stacked residual Mamba modules for temporal modeling. By leveraging an input-dependent selective mechanism to dynamically adjust state transitions, it can effectively capture the long-range dependencies between the CSIs while maintaining a linear computational complexity. Simulation results under the 3GPP standard channel model demonstrate that CPMamba achieves state-of-the-art prediction accuracy across all scenarios, along with superior generalization and robustness. Compared to existing baseline models, CPMamba reduces the number of parameters by approximately 50 percent while achieving comparable or better performance, thereby significantly lowering the barrier for practical deployment.

</details>


### [8] [An active-set algorithm for spectral unmixing](https://arxiv.org/abs/2512.16432)
*Nils Foix-Colonier,Sébastien Bourguignon*

Main category: eess.SP

TL;DR: 提出一种针对线性光谱解混问题的专用算法，特别适用于监督解混（大字典情况），通过主动集方法处理稀疏性，并扩展非负约束为更广泛的丰度最小约束。


<details>
  <summary>Details</summary>
Motivation: 线性光谱解混在非负和和为1约束下是凸优化问题，已有许多算法。但在实践中，特别是监督解混（大字典）时，由于丰度的非负性，解往往稀疏，这促使使用主动集求解器。鉴于问题特定特征，设计专用算法相比通用求解器可获得更好的计算性能。

Method: 提出一种专用算法，基于主动集方法处理稀疏性，并将非负约束扩展为更广泛的丰度最小约束。

Result: 未在摘要中明确说明具体结果，但暗示该算法相比通用求解器具有计算性能优势。

Conclusion: 针对线性光谱解混问题设计专用算法是可行的，通过主动集方法处理稀疏性并扩展约束条件，可提高计算性能。

Abstract: Linear spectral unmixing under nonnegativity and sum-to-one constraints is a convex optimization problem for which many algorithms were proposed. In practice, especially for supervised unmixing (i.e., with a large dictionary), solutions tend to be sparse due to the nonnegativity of the abundances, thereby motivating the use of an active-set solver. Given the problem specific features, it seems advantageous to design a dedicated algorithm in order to gain computational performance compared to generic solvers. In this paper, we propose to derive such a specific algorithm, while extending the nonnegativity constraints to broader minimum abundance constraints.

</details>


### [9] [Robust 6G OFDM High-Mobility Communications Using Delay-Doppler Superimposed Pilots](https://arxiv.org/abs/2512.16496)
*Mauro Marchese,Pietro Savazzi*

Main category: eess.SP

TL;DR: 提出一种用于6G高速移动场景的OFDM接收机架构，采用延迟-多普勒叠加导频方案进行信道估计，考虑ICI、分数延迟和多普勒频移，实现高达1000km/h的鲁棒通信性能。


<details>
  <summary>Details</summary>
Motivation: 6G高速移动场景（如高铁、无人机）对OFDM系统提出挑战，传统信道估计方法在高速移动下性能下降，需要开发能处理分数延迟、多普勒频移和ICI的鲁棒接收机架构。

Method: 1) 采用延迟-多普勒叠加导频方案，在延迟-多普勒域添加单个导频；2) 推导分离式分数延迟-多普勒估计算法；3) 提出基于Landweber迭代的低复杂度均衡方法，利用信道固有结构。

Result: 仿真结果表明，该接收机架构在各种移动条件下（速度高达1000km/h）实现鲁棒通信性能，相比现有方法提高了有效吞吐量。

Conclusion: 提出的接收机架构有效解决了6G高速移动场景下的OFDM通信挑战，通过创新的导频设计和估计算法，实现了高速移动环境下的可靠通信和吞吐量提升。

Abstract: In this work, a novel receiver architecture for orthogonal frequency division multiplexing (OFDM) communications in 6G high-mobility scenarios is developed. In particular, a delay-Doppler superimposed pilot (SP) scheme is used for channel estimation (CE) by adding a single pilot in the delay-Doppler domain. Unlike previous research on delay-Doppler superimposed pilots in OFDM systems, intercarrier interference (ICI) effects, fractional delays, and Doppler shifts are considered. Consequently, a disjoint fractional delay-Doppler estimation algorithm is derived, and a reduced-complexity equalization method based on the Landweber iteration, which exploits intrinsic channel structure, is proposed. Simulation results reveal that the proposed receiver architecture achieves robust communication performance across various mobility conditions, with speeds of up to 1000 km/h, and increases the effective throughput compared to existing methods.

</details>


### [10] [Efficient Precoding for LEO Satellites: A Low-Complexity Matrix Inversion Method via Woodbury Matrix Identity and arSVD](https://arxiv.org/abs/2512.16543)
*Mohammad Momani,Thomas Delamotte,Andreas Knopp*

Main category: eess.SP

TL;DR: 提出结合Woodbury公式与自适应随机奇异值分解的低复杂度预编码框架，用于LEO卫星大规模天线阵列，相比传统RZF预编码计算复杂度降低61%，仅带来轻微的和速率性能损失。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星大规模有源天线阵列的部署需要计算高效且自适应的预编码技术，以应对动态信道变化并提高频谱效率。传统正则化迫零预编码的实时实现受限于Gram矩阵求逆的高计算复杂度。

Method: 提出WB-arSVD框架：结合Woodbury公式处理低秩扰动以降低求逆复杂度，同时使用自适应随机奇异值分解动态提取主导奇异分量，进一步优化计算效率。

Result: 蒙特卡洛仿真表明，相比传统RZF预编码的完整矩阵求逆，所提方法计算复杂度降低高达61%，仅带来和速率性能的轻微下降。

Conclusion: WB-arSVD为下一代卫星通信提供了可扩展且高效的解决方案，特别适用于功率受限环境中的实时部署。

Abstract: The increasing deployment of massive active antenna arrays in low Earth orbit (LEO) satellites necessitates computationally efficient and adaptive precoding techniques to mitigate dynamic channel variations and enhance spectral efficiency. Regularized zero-forcing (RZF) precoding is widely used in multi-user MIMO systems; however, its real-time implementation is limited by the computationally intensive inversion of the Gram matrix. In this work, we develop a low-complexity framework that integrates the Woodbury (WB) formula with adaptive randomized singular value decomposition (arSVD) to efficiently update the Gram matrix inverse as the satellite moves along its orbit. By leveraging low-rank perturbations, the WB formula reduces inversion complexity, while arSVD dynamically extracts dominant singular components, further enhancing computational efficiency. Monte Carlo simulations demonstrate that the proposed method achieves computational savings of up to 61\% compared to conventional RZF precoding with full matrix inversion, while incurring only a modest degradation in sum-rate performance. These results demonstrate that WB-arSVD offers a scalable and efficient solution for next-generation satellite communications, facilitating real-time deployment in power-constrained environments.

</details>


### [11] [Channel State Information Preprocessing for CSI-based Physical-Layer Authentication Using Reconciliation](https://arxiv.org/abs/2512.16719)
*Atsu Kokuvi Angelo Passah,Rodrigo C. de Lamare,Arsenia Chorti*

Main category: eess.SP

TL;DR: 提出自适应鲁棒主成分分析(A-RPCA)预处理方法，用于增强基于信道状态信息的物理层认证(CSI-PLA)的准确性，通过减轻CSI时域变化和不一致性，结合信息协调框架显著降低错误概率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于信道状态信息(CSI)的物理层认证(PLA)面临CSI在时域上的变化和不一致性问题，这影响了认证的准确性。需要一种有效的预处理方法来减轻这些CSI变化，提高认证系统的鲁棒性。

Method: 提出自适应鲁棒主成分分析(A-RPCA)预处理方法，基于鲁棒主成分分析(RPCA)改进。结合基于信息协调的PLA框架，利用Polar码的高斯近似(GA)设计短码长Slepian Wolf解码器。对提出的A-RPCA方法进行了理论分析。

Result: 仿真结果表明，与没有预处理和协调的基线方案相比，A-RPCA方法显著降低了协调后的错误概率，并将检测概率提高到1（在LOS和NLOS场景下）。在合成和真实数据集上，相比PCA、鲁棒PCA、自编码器和ReProCS等先进预处理方案，验证了所提方法的优越性能。

Conclusion: 自适应鲁棒主成分分析(A-RPCA)预处理方法能有效减轻CSI时域变化和不一致性，显著提高物理层认证系统的准确性和鲁棒性，在多种场景下都表现出优越性能。

Abstract: This paper introduces an adaptive preprocessing technique to enhance the accuracy of channel state information-based physical layer authentication (CSI-PLA) alleviating CSI variations and inconsistencies in the time domain. To this end, we develop an adaptive robust principal component analysis (A-RPCA) preprocessing method based on robust principal component analysis (RPCA). The performance evaluation is then conducted using a PLA framework based on information reconciliation, in which Gaussian approximation (GA) for Polar codes is leveraged for the design of short codelength Slepian Wolf decoders. Furthermore, an analysis of the proposed A-RPCA methods is carried out. Simulation results show that compared to a baseline scheme without preprocessing and without reconciliation, the proposed A-RPCA method substantially reduces the error probability after reconciliation and also substantially increases the detection probabilities that is also 1 in both line-of-sight (LOS) and non-line-of-sight (NLOS) scenarios. We have compared against state-of the-art preprocessing schemes in both synthetic and real datasets, including principal component analysis (PCA) and robust PCA, autoencoders and the recursive projected compressive sensing (ReProCS) framework and we have validated the superior performance of the proposed approach.

</details>


### [12] [Misspecified Crame-Rao Bound for AoA Estimation at a ULA under a Spoofing Attack](https://arxiv.org/abs/2512.16735)
*Sotiris Skaperas,Arsenia Chorti*

Main category: eess.SP

TL;DR: 提出基于误设Cramér-Rao界(MCRB)的框架，分析主动攻击对基于到达角(AoA)的物理层认证的影响，推导闭式表达式并揭示攻击引入的惩罚项特性。


<details>
  <summary>Details</summary>
Motivation: 研究主动攻击对基于到达角的物理层认证系统的影响，传统CRB无法准确评估攻击场景下的性能界限，需要开发考虑攻击者存在的理论分析框架。

Method: 使用误设Cramér-Rao界(MCRB)理论框架，分析单天线用户在M天线ULA验证器下的AoA认证，考虑具有L天线元素的欺骗攻击者，假设确定性导频信号。

Result: 获得了MCRB的闭式表达式，发现攻击引入的惩罚项与信噪比无关，而是取决于攻击者位置、阵列几何结构和攻击者预编码向量。

Conclusion: MCRB框架有效量化了主动攻击对物理层认证性能的影响，揭示了攻击引入的惩罚项特性，为安全认证系统设计提供了理论指导。

Abstract: A framework is presented for analyzing the impact of active attacks to location-based physical layer authentication (PLA) using the machinery of misspecified Cramér--Rao bound (MCRB). In this work, we focus on the MCRB in the angle-of-arrival (AoA) based authentication of a single antenna user when the verifier posseses an $M$ antenna element uniform linear array (ULA), assuming deterministic pilot signals; in our system model the presence of a spoofing adversary with an arbitrary number $L$ of antenna elements is assumed. We obtain a closed-form expression for the MCRB and demonstrate that the attack introduces in it a penalty term compared to the classic CRB, which does not depend on the signal-to-noise ratio (SNR) but on the adversary's location, the array geometry and the attacker precoding vector.

</details>


### [13] [Few-Shot Specific Emitter Identification via Integrated Complex Variational Mode Decomposition and Spatial Attention Transfer](https://arxiv.org/abs/2512.16786)
*Chenyu Zhu,Zeyang Li,Ziyi Xie,Jie Zhang*

Main category: eess.SP

TL;DR: 提出了一种基于集成复数变分模态分解和时空注意力机制的特定发射机识别方法，在少量符号数据下实现96%的准确率


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的SEI方法依赖大量数据或先验信息，在实际场景中标记数据有限的情况下面临挑战

Method: 1) 集成复数变分模态分解算法分解和重构复值信号；2) 使用时序卷积网络建模序列特征；3) 引入空间注意力机制自适应加权信息丰富的信号段；4) 分支网络利用预训练权重减少辅助数据需求

Result: 在公开数据集上仅使用10个符号且无需先验知识的情况下达到96%的准确率，消融实验验证了各模块的有效性

Conclusion: 该方法在有限标记数据场景下实现了高性能的特定发射机识别，为物理层安全提供了有效的解决方案

Abstract: Specific emitter identification (SEI) utilizes passive hardware characteristics to authenticate transmitters, providing a robust physical-layer security solution. However, most deep-learning-based methods rely on extensive data or require prior information, which poses challenges in real-world scenarios with limited labeled data. We propose an integrated complex variational mode decomposition algorithm that decomposes and reconstructs complex-valued signals to approximate the original transmitted signals, thereby enabling more accurate feature extraction. We further utilize a temporal convolutional network to effectively model the sequential signal characteristics, and introduce a spatial attention mechanism to adaptively weight informative signal segments, significantly enhancing identification performance. Additionally, the branch network allows leveraging pre-trained weights from other data while reducing the need for auxiliary datasets. Ablation experiments on the simulated data demonstrate the effectiveness of each component of the model. An accuracy comparison on a public dataset reveals that our method achieves 96% accuracy using only 10 symbols without requiring any prior knowledge.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [14] [Learning Recursive Attenuation Filters Under Noisy Conditions](https://arxiv.org/abs/2512.16318)
*Gloria Dal Santo,Karolina Prawda,Sebastian J. Schlecht,Vesa Välimäki*

Main category: eess.AS

TL;DR: 本文提出一种在噪声条件下优化反馈延迟网络递归衰减滤波器的方法，通过显式建模噪声来恢复正确的损失最小值，提高梯度优化的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有的可微分数字信号处理框架在优化递归系统时，使用基于能量衰减或频谱图差异的损失函数，但这些表示对背景噪声高度敏感。实际测量中普遍存在噪声，会导致虚假的损失最小值和不正确的衰减参数。

Method: 研究不同优化目标的损失函数景观，提出一种在低信噪比条件下确保正确最小值的方法。该方法显式建模噪声，并通过80个独立优化示例进行统计分析验证。

Result: 显式建模噪声能够恢复正确的损失最小值。同时发现衰减滤波器参数调谐对频率无关参数的扰动具有敏感性。

Conclusion: 研究结果为基于梯度的反馈延迟网络优化提供了更鲁棒和可重复的实用指导原则，特别是在噪声目标条件下。

Abstract: Recursion is a fundamental concept in the design of filters and audio systems. In particular, artificial reverberation systems that use delay networks depend on recursive paths to control both echo density and the decay rate of modal components. The differentiable digital signal processing framework has shown promise in automatically tuning both recursive and non-recursive elements given a target room impulse response. This is done by applying gradient descent to loss functions based on energy-decay or spectrogram differences. However, these representations are highly sensitive to background noise, which is ubiquitous in real measurements, producing spurious loss minima and leading to incorrect attenuation. This paper addresses the problem of tuning recursive attenuation filters of a feedback delay network when targets are noisy. We examine the loss landscape associated with different optimization objectives and propose a method that ensures correct minima under low signal-to-noise conditions. We demonstrate the effectiveness of the proposed approach through statistical analysis on 80 individual optimization examples. The results reveal that explicitly modeling the noise restores correct minima. Furthermore, we identify the sensitivity of attenuation filter parameters tuning to perturbations in frequency-independent parameters. These findings provide practical guidelines for more robust and reproducible gradient-based optimization of feedback delay networks.

</details>


### [15] [BEST-STD2.0: Balanced and Efficient Speech Tokenizer for Spoken Term Detection](https://arxiv.org/abs/2512.16395)
*Anup Singh,Kris Demuynck,Vipul Arora*

Main category: eess.AS

TL;DR: 提出一种增强的查询示例语音术语检测方法，通过噪声增强训练和最优传输正则化提高鲁棒性和标记效率，结合TF-IDF搜索加速检索


<details>
  <summary>Details</summary>
Motivation: 基于标记的语音术语检测系统虽然搜索效率高，但对噪声和混响的鲁棒性不足，且标记利用效率低下，需要改进

Method: 1) 噪声和混响增强训练策略提高标记化器的鲁棒性；2) 最优传输正则化确保平衡的标记使用并提高标记效率；3) TF-IDF搜索机制加速检索

Result: 该方法在各种失真水平下都优于基线STD系统，同时保持高搜索效率

Conclusion: 提出的噪声增强训练、最优传输正则化和TF-IDF搜索相结合的方法，有效解决了基于标记的STD系统的鲁棒性和效率问题

Abstract: Fast and accurate spoken content retrieval is vital for applications such as voice search. Query-by-Example Spoken Term Detection (STD) involves retrieving matching segments from an audio database given a spoken query. Token-based STD systems, which use discrete speech representations, enable efficient search but struggle with robustness to noise and reverberation, and with inefficient token utilization. We address these challenges by proposing a noise and reverberation-augmented training strategy to improve tokenizer robustness. In addition, we introduce optimal transport-based regularization to ensure balanced token usage and enhance token efficiency. To further speed up retrieval, we adopt a TF-IDF-based search mechanism. Empirical evaluations demonstrate that the proposed method outperforms STD baselines across various distortion levels while maintaining high search efficiency.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [16] [From Minutes to Days: Scaling Intracranial Speech Decoding with Supervised Pretraining](https://arxiv.org/abs/2512.15830)
*Linnea Evanson,Mingfang,Zhang,Hubert Banville,Saarang Panchavati,Pierre Bourdillon,Jean-Rémi King*

Main category: cs.SD

TL;DR: 利用临床监测患者长达一周的颅内和音频记录，通过对比学习模型显著提升脑活动解码语音的性能，性能随数据量对数线性增长


<details>
  <summary>Details</summary>
Motivation: 传统脑活动解码语音研究依赖短期、高度控制的实验数据，数据量有限。需要利用临床监测中更长时间、更自然的记录来扩展训练数据集

Method: 引入框架利用患者临床监测期间长达一周的颅内和音频记录，将训练数据集扩大两个数量级以上。使用对比学习模型进行预训练

Result: 对比学习模型性能显著优于仅使用传统实验数据训练的模型，性能增益随数据集大小呈对数线性增长。分析发现脑活动表示语音特征，但全局结构随时间漂移

Conclusion: 该方法为在现实生活和受控任务环境中解码和建模脑表征提供了可扩展的路径，需要开发能明确处理跨天变异性的模型

Abstract: Decoding speech from brain activity has typically relied on limited neural recordings collected during short and highly controlled experiments. Here, we introduce a framework to leverage week-long intracranial and audio recordings from patients undergoing clinical monitoring, effectively increasing the training dataset size by over two orders of magnitude. With this pretraining, our contrastive learning model substantially outperforms models trained solely on classic experimental data, with gains that scale log-linearly with dataset size. Analysis of the learned representations reveals that, while brain activity represents speech features, its global structure largely drifts across days, highlighting the need for models that explicitly account for cross-day variability. Overall, our approach opens a scalable path toward decoding and modeling brain representations in both real-life and controlled task settings.

</details>


### [17] [Domain-Agnostic Causal-Aware Audio Transformer for Infant Cry Classification](https://arxiv.org/abs/2512.16271)
*Geofrey Owino,Bernard Shibwabo Kasamani,Ahmed M. Abdelmoniem,Edem Wornyo*

Main category: cs.SD

TL;DR: DACH-TIC：一种用于婴儿哭声分类的领域无关因果感知分层音频Transformer，通过因果注意力、分层表示学习、多任务监督和对抗领域泛化来提高鲁棒性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法依赖相关性驱动的声学表示，容易受到噪声、虚假线索和领域偏移的影响，需要更鲁棒且可解释的婴儿哭声分类方法用于新生儿早期检测和临床决策支持。

Method: 提出DACH-TIC模型，包含：1）结构化Transformer骨干网络，具有局部token级和全局语义编码器；2）因果注意力掩码和受控扰动训练来近似反事实声学变化；3）领域对抗目标促进环境不变表示；4）多任务学习联合优化哭声类型识别、痛苦强度估计和因果相关性预测。

Result: 在Baby Chillanto和Donate-a-Cry数据集上评估，DACH-TIC优于HTS-AT和SE-ResNet Transformer等SOTA基线，准确率提升2.6%，宏F1分数提升2.2分，具有增强的因果保真度。在未见声学环境中泛化效果好，领域性能差距仅2.4%。

Conclusion: DACH-TIC通过集成因果感知、分层表示和领域泛化技术，为现实世界新生儿声学监测系统提供了鲁棒且可解释的婴儿哭声分类解决方案。

Abstract: Accurate and interpretable classification of infant cry paralinguistics is essential for early detection of neonatal distress and clinical decision support. However, many existing deep learning methods rely on correlation-driven acoustic representations, which makes them vulnerable to noise, spurious cues, and domain shifts across recording environments. We propose DACH-TIC, a Domain-Agnostic Causal-Aware Hierarchical Audio Transformer for robust infant cry classification. The model integrates causal attention, hierarchical representation learning, multi-task supervision, and adversarial domain generalization within a unified framework.
  DACH-TIC employs a structured transformer backbone with local token-level and global semantic encoders, augmented by causal attention masking and controlled perturbation training to approximate counterfactual acoustic variations. A domain-adversarial objective promotes environment-invariant representations, while multi-task learning jointly optimizes cry type recognition, distress intensity estimation, and causal relevance prediction. The model is evaluated on the Baby Chillanto and Donate-a-Cry datasets, with ESC-50 environmental noise overlays for domain augmentation.
  Experimental results show that DACH-TIC outperforms state-of-the-art baselines, including HTS-AT and SE-ResNet Transformer, achieving improvements of 2.6 percent in accuracy and 2.2 points in macro-F1 score, alongside enhanced causal fidelity. The model generalizes effectively to unseen acoustic environments, with a domain performance gap of only 2.4 percent, demonstrating its suitability for real-world neonatal acoustic monitoring systems.

</details>


### [18] [Pseudo-Cepstrum: Pitch Modification for Mel-Based Neural Vocoders](https://arxiv.org/abs/2512.16519)
*Nikolaos Ellinas,Alexandra Vioni,Panos Kakoulidis,Georgios Vamvoukakis,Myrsini Christidou,Konstantinos Markopoulos,Junkwang Oh,Gunu Jho,Inchul Hwang,Aimilios Chalamandaris,Pirros Tsiakoulis*

Main category: cs.SD

TL;DR: 提出一种基于倒谱的基频修改方法，可直接应用于任何梅尔频谱图表示，无需额外训练或修改模型。


<details>
  <summary>Details</summary>
Motivation: 现有基频修改方法通常需要特定训练或模型修改，缺乏通用性。本文旨在开发一种与任何基于梅尔的声码器兼容的通用基频修改方法。

Method: 通过伪逆梅尔变换计算频谱幅度，应用DCT转换到倒谱域，在倒谱域直接移动倒谱峰来改变谐波结构，然后通过IDCT和梅尔滤波器组重新计算修改后的梅尔频谱图。

Result: 方法在各种最先进的神经声码器上通过客观和主观指标验证有效，与传统基频修改方法相比表现良好。

Conclusion: 该方法提供了一种通用、无需训练的基频修改解决方案，可与任何基于梅尔的声码器兼容，为语音合成中的基频控制提供了灵活工具。

Abstract: This paper introduces a cepstrum-based pitch modification method that can be applied to any mel-spectrogram representation. As a result, this method is compatible with any mel-based vocoder without requiring any additional training or changes to the model. This is achieved by directly modifying the cepstrum feature space in order to shift the harmonic structure to the desired target. The spectrogram magnitude is computed via the pseudo-inverse mel transform, then converted to the cepstrum by applying DCT. In this domain, the cepstral peak is shifted without having to estimate its position and the modified mel is recomputed by applying IDCT and mel-filterbank. These pitch-shifted mel-spectrogram features can be converted to speech with any compatible vocoder. The proposed method is validated experimentally with objective and subjective metrics on various state-of-the-art neural vocoders as well as in comparison with traditional pitch modification methods.

</details>


### [19] [CogSR: Semantic-Aware Speech Super-Resolution via Chain-of-Thought Guided Flow Matching](https://arxiv.org/abs/2512.16304)
*Jiajun Yuan,Xiaochen Wang,Yuhang Xiao,Yulin Wu,Chenhao Hu,Xueyang Lv*

Main category: cs.SD

TL;DR: CogSR是一个针对严重低采样率音频的语音超分辨率框架，通过认知重建而非简单信号映射，结合大型音频语言模型和链式思维推理，实现高精度离线恢复。


<details>
  <summary>Details</summary>
Motivation: 数字存档和调查性音频恢复中，严重低采样率的录音缺乏基本声学线索，现有生成模型容易产生语音内容幻觉，基于概率而非意义猜测单词，导致恢复失败。

Method: 提出CogSR框架，将重点从简单信号映射转向认知重建。集成大型音频语言模型，使用链式思维推理作为语义锚点，同时利用显式声学先验保持说话人身份一致性，指导Rectified Flow骨干网络合成既真实又语言准确的高频细节。

Result: 评估表明CogSR在严重退化情况下有效消除歧义，成为恢复高价值遗留音频和监控音频的稳健解决方案。

Conclusion: CogSR通过认知重建方法解决了严重低采样率音频恢复的关键挑战，为数字存档和调查性音频恢复提供了高精度、语义准确的解决方案。

Abstract: Applying speech super-resolution (SR) to recordings with severely low sampling rates is a critical challenge in digital archiving and investigative audio recovery. In these scenarios, the input lacks essential acoustic cues. Consequently, existing generative models often fail; without sufficient context, they hallucinate phonetic content, guessing words based on probability rather than meaning.
  To address this, we propose CogSR, a framework designed specifically for high-precision, offline restoration. Our approach shifts the focus from simple signal mapping to cognitive reconstruction. By integrating a Large Audio-Language Model, we employ Chain-of-Thought reasoning to act as a semantic anchor, while explicit acoustic priors ensure the speaker's identity remains consistent. This guides a Rectified Flow backbone to synthesize high-frequency details that are not only realistic but linguistically accurate. Evaluations show that CogSR effectively eliminates ambiguity in severe degradation regimes, making it a robust solution for restoring high-value legacy and surveillance audio.

</details>


### [20] [DPDFNet: Boosting DeepFilterNet2 via Dual-Path RNN](https://arxiv.org/abs/2512.16420)
*Daniel Rika,Nino Sapir,Ido Gus*

Main category: cs.SD

TL;DR: DPDFNet：基于DeepFilterNet2架构的因果单通道语音增强模型，通过双路径块增强长时建模，结合抗过衰减损失和微调策略，在真实场景评估中优于其他开源模型，并在边缘设备上实现实时运行。


<details>
  <summary>Details</summary>
Motivation: 现有因果语音增强模型在长时建模和真实场景适应性方面存在不足，需要开发既能保持高质量增强效果，又能在边缘设备上实时运行的高效模型。

Method: 1. 在DeepFilterNet2编码器中引入双路径块，增强长时时间建模和跨频带建模；2. 添加抗过衰减损失组件；3. 针对"always-on"应用进行微调；4. 创建包含12种语言、低信噪比真实场景的新评估集；5. 提出PRISM综合评估指标；6. 在Ceva-NeuPro-Nano边缘NPU上部署验证。

Result: 1. DPDFNet在新建的真实场景评估集上优于其他因果开源模型，包括一些更大更复杂的模型；2. PRISM指标显示性能随双路径块数量增加而提升；3. DPDFNet-4在NPN32上实现实时性能，在NPN64上运行更快，证明在嵌入式设备上保持SOTA质量的可行性。

Conclusion: DPDFNet通过双路径块架构、抗过衰减损失和针对性微调，实现了在真实场景中优越的语音增强性能，同时在边缘设备上保持实时运行能力，为嵌入式语音增强应用提供了有效解决方案。

Abstract: We present DPDFNet, a causal single-channel speech enhancement model that extends DeepFilterNet2 architecture with dual-path blocks in the encoder, strengthening long-range temporal and cross-band modeling while preserving the original enhancement framework. In addition, we demonstrate that adding a loss component to mitigate over-attenuation in the enhanced speech, combined with a fine-tuning phase tailored for "always-on" applications, leads to substantial improvements in overall model performance. To compare our proposed architecture with a variety of causal open-source models, we created a new evaluation set comprising long, low-SNR recordings in 12 languages across everyday noise scenarios, better reflecting real-world conditions than commonly used benchmarks. On this evaluation set, DPDFNet delivers superior performance to other causal open-source models, including some that are substantially larger and more computationally demanding. We also propose an holistic metric named PRISM, a composite, scale-normalized aggregate of intrusive and non-intrusive metrics, which demonstrates clear scalability with the number of dual-path blocks. We further demonstrate on-device feasibility by deploying DPDFNet on Ceva-NeuPro-Nano edge NPUs. Results indicate that DPDFNet-4, our second-largest model, achieves real-time performance on NPN32 and runs even faster on NPN64, confirming that state-of-the-art quality can be sustained within strict embedded power and latency constraints.

</details>

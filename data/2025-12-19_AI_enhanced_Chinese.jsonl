{"id": "2512.15724", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.15724", "abs": "https://arxiv.org/abs/2512.15724", "authors": ["Qilu Zhang", "Hongying Tang", "Wen Chen", "Ziyi Song", "Jiang Wang"], "title": "Multiple Source Localization via Local Radio Map Construction in Urban Environments", "comment": null, "summary": "Accurately and efficiently addressing the multiple source localization (MSL) problem in urban environments, particularly designing a general method adaptable to an arbitrary number of sources, plays a crucial role in various fields such as cognitive radio (CR).\n  Existing methods either fail to effectively utilize received signal strength (RSS) information without redundancy or lack generalizability to an arbitrary number of sources.\n  In this work, we propose the Local Radio Map-Aided Multiple Source Localization Framework (LRM-MSL), which is a general method capable of handling an arbitrary number of sources.\n  First, this framework constructs a local radio map that retains only the RSS information around the sources and binarizes it. Then, the connected component analysis tool is applied to the binarized map, which implements multi-source separation, transforming the MSL problem into a series of single-source localization (SSL) tasks.\n  Finally, we design a numerical coordinate regression network to perform the SSL tasks.\n  Since there is no publicly available RSS dataset for MSL, we construct the VaryTxLoc dataset to evaluate the performance of LRM-MSL. Experimental results demonstrate that LRM-MSL is an accurate and effective method, outperforming state-of-the-art approaches. Our code and dataset can be downloaded from https://github.com/hereis77/LRM-MSL.", "AI": {"tldr": "LRM-MSL\u662f\u4e00\u4e2a\u7528\u4e8e\u57ce\u5e02\u73af\u5883\u4e2d\u591a\u6e90\u5b9a\u4f4d\u7684\u901a\u7528\u6846\u67b6\uff0c\u901a\u8fc7\u6784\u5efa\u5c40\u90e8\u65e0\u7ebf\u7535\u5730\u56fe\u3001\u4e8c\u503c\u5316\u548c\u8fde\u901a\u5206\u91cf\u5206\u6790\u5b9e\u73b0\u591a\u6e90\u5206\u79bb\uff0c\u518d\u4f7f\u7528\u5750\u6807\u56de\u5f52\u7f51\u7edc\u8fdb\u884c\u5355\u6e90\u5b9a\u4f4d\uff0c\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u8981\u4e48\u65e0\u6cd5\u6709\u6548\u5229\u7528\u63a5\u6536\u4fe1\u53f7\u5f3a\u5ea6\u4fe1\u606f\uff0c\u8981\u4e48\u7f3a\u4e4f\u5bf9\u4efb\u610f\u6570\u91cf\u6e90\u7684\u901a\u7528\u6027\uff0c\u800c\u57ce\u5e02\u73af\u5883\u4e2d\u7684\u591a\u6e90\u5b9a\u4f4d\u5728\u8ba4\u77e5\u65e0\u7ebf\u7535\u7b49\u9886\u57df\u6709\u91cd\u8981\u5e94\u7528\u3002", "method": "1) \u6784\u5efa\u4ec5\u4fdd\u7559\u6e90\u5468\u56f4RSS\u4fe1\u606f\u7684\u5c40\u90e8\u65e0\u7ebf\u7535\u5730\u56fe\u5e76\u4e8c\u503c\u5316\uff1b2) \u5e94\u7528\u8fde\u901a\u5206\u91cf\u5206\u6790\u5b9e\u73b0\u591a\u6e90\u5206\u79bb\uff0c\u5c06\u591a\u6e90\u5b9a\u4f4d\u95ee\u9898\u8f6c\u5316\u4e3a\u4e00\u7cfb\u5217\u5355\u6e90\u5b9a\u4f4d\u4efb\u52a1\uff1b3) \u8bbe\u8ba1\u6570\u503c\u5750\u6807\u56de\u5f52\u7f51\u7edc\u6267\u884c\u5355\u6e90\u5b9a\u4f4d\u4efb\u52a1\u3002", "result": "\u6784\u5efa\u4e86VaryTxLoc\u6570\u636e\u96c6\u8fdb\u884c\u8bc4\u4f30\uff0c\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eLRM-MSL\u662f\u4e00\u79cd\u51c6\u786e\u6709\u6548\u7684\u65b9\u6cd5\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "LRM-MSL\u662f\u4e00\u4e2a\u901a\u7528\u7684\u591a\u6e90\u5b9a\u4f4d\u6846\u67b6\uff0c\u80fd\u591f\u5904\u7406\u4efb\u610f\u6570\u91cf\u7684\u6e90\uff0c\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u5177\u6709\u51c6\u786e\u6027\u548c\u6709\u6548\u6027\uff0c\u4ee3\u7801\u548c\u6570\u636e\u96c6\u5df2\u5f00\u6e90\u3002"}}
{"id": "2512.15729", "categories": ["eess.SP", "cs.AI", "cs.HC", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.15729", "abs": "https://arxiv.org/abs/2512.15729", "authors": ["Matteo Fasulo", "Giusy Spacone", "Thorir Mar Ingolfsson", "Yawei Li", "Luca Benini", "Andrea Cossettini"], "title": "TinyMyo: a Tiny Foundation Model for Flexible EMG Signal Processing at the Edge", "comment": null, "summary": "Surface electromyography (EMG) is a non-invasive sensing modality used in several domains, including biomechanics, rehabilitation, prosthetic control, and emerging human-machine interaction paradigms. Despite decades of use, significant challenges remain in achieving robust generalization across subjects, recording systems, and acquisition protocols. To tackle these challenges, foundation models (FMs) are gaining traction when targeting end-to-end applications based on EMG signals. Yet, existing EMG FMs remain limited to single downstream tasks and lack deployability on embedded platforms. In this work, we present TinyMyo, a lightweight FM based on a Transformer encoder architecture. The model is pre-trained in a self-supervised manner on publicly available datasets and achieves high reconstruction fidelity with only 3.6M parameters. With minimal task-specific head adaptations, the same backbone is used to tackle multiple downstream tasks, leveraging datasets acquired from diverse sensing locations and hardware platforms. We demonstrate generalization across hand gesture classification, hand kinematic regression, speech production and recognition, with performance comparable to or surpassing the state of the art (SoA), and model size below 5M parameters. We achieve SoA results compared to previous FM-based works on the NinaPro DB5 ($89.4\\pm0.16\\%$), UCI-EMG ($97.56\\pm0.32\\%$), and EPN-612 ($96.74\\pm0.09\\%$) datasets. We report, to the best of our knowledge, the first deployment of an EMG FM on an ultra-low-power microcontroller (GAP9), achieving an average power envelope of 36.45mW. By open-sourcing the pre-trained and the downstream task architectures (https://github.com/pulp-bio/BioFoundation), we aim to provide a flexible resource that can accelerate future research and serve as a common foundation for the EMG community.", "AI": {"tldr": "TinyMyo\uff1a\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u8868\u9762\u808c\u7535\u4fe1\u53f7\u57fa\u7840\u6a21\u578b\uff0c\u57fa\u4e8eTransformer\u7f16\u7801\u5668\u67b6\u6784\uff0c\u4ec53.6M\u53c2\u6570\uff0c\u901a\u8fc7\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u5b9e\u73b0\u591a\u4efb\u52a1\u6cdb\u5316\uff0c\u5e76\u5728\u8d85\u4f4e\u529f\u8017\u5fae\u63a7\u5236\u5668\u4e0a\u90e8\u7f72\u6210\u529f\u3002", "motivation": "\u8868\u9762\u808c\u7535\u4fe1\u53f7\uff08EMG\uff09\u5728\u591a\u4e2a\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u73b0\u6709\u6280\u672f\u9762\u4e34\u8de8\u4e3b\u4f53\u3001\u8de8\u7cfb\u7edf\u3001\u8de8\u534f\u8bae\u7684\u6cdb\u5316\u6311\u6218\u3002\u73b0\u6709EMG\u57fa\u7840\u6a21\u578b\u5c40\u9650\u4e8e\u5355\u4e00\u4efb\u52a1\u4e14\u96be\u4ee5\u5728\u5d4c\u5165\u5f0f\u5e73\u53f0\u90e8\u7f72\u3002", "method": "\u63d0\u51faTinyMyo\u8f7b\u91cf\u7ea7\u57fa\u7840\u6a21\u578b\uff0c\u57fa\u4e8eTransformer\u7f16\u7801\u5668\u67b6\u6784\uff0c\u4f7f\u7528\u516c\u5f00\u6570\u636e\u96c6\u8fdb\u884c\u81ea\u76d1\u7763\u9884\u8bad\u7ec3\u3002\u901a\u8fc7\u6700\u5c0f\u5316\u7684\u4efb\u52a1\u7279\u5b9a\u5934\u90e8\u9002\u914d\uff0c\u540c\u4e00\u9aa8\u5e72\u7f51\u7edc\u53ef\u5904\u7406\u624b\u52bf\u5206\u7c7b\u3001\u624b\u90e8\u8fd0\u52a8\u5b66\u56de\u5f52\u3001\u8bed\u97f3\u751f\u6210\u4e0e\u8bc6\u522b\u7b49\u591a\u79cd\u4e0b\u6e38\u4efb\u52a1\u3002", "result": "\u6a21\u578b\u4ec53.6M\u53c2\u6570\uff0c\u5728\u591a\u4e2a\u6570\u636e\u96c6\u4e0a\u8fbe\u5230\u6216\u8d85\u8d8a\u73b0\u6709\u6700\u4f73\u6027\u80fd\uff1aNinaPro DB5\uff0889.4\u00b10.16%\uff09\u3001UCI-EMG\uff0897.56\u00b10.32%\uff09\u3001EPN-612\uff0896.74\u00b10.09%\uff09\u3002\u9996\u6b21\u5728\u8d85\u4f4e\u529f\u8017\u5fae\u63a7\u5236\u5668\uff08GAP9\uff09\u4e0a\u90e8\u7f72EMG\u57fa\u7840\u6a21\u578b\uff0c\u5e73\u5747\u529f\u8017\u4ec536.45mW\u3002", "conclusion": "TinyMyo\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8f7b\u91cf\u7ea7\u3001\u53ef\u90e8\u7f72\u7684EMG\u57fa\u7840\u6a21\u578b\uff0c\u80fd\u591f\u8de8\u4efb\u52a1\u3001\u8de8\u786c\u4ef6\u5e73\u53f0\u6cdb\u5316\uff0c\u4e3aEMG\u793e\u533a\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u7814\u7a76\u8d44\u6e90\uff0c\u6709\u671b\u52a0\u901f\u672a\u6765\u7814\u7a76\u548c\u5e94\u7528\u5f00\u53d1\u3002"}}
{"id": "2512.15807", "categories": ["eess.SP", "cs.ET"], "pdf": "https://arxiv.org/pdf/2512.15807", "abs": "https://arxiv.org/abs/2512.15807", "authors": ["Arfan Ghani"], "title": "HiLTS: Human in the Loop Therapeutic System: A Wireless-enabled Precision Medicine Platform for Brainwave Entrainment", "comment": "precision healthcare, neuro technology, healthcare engineering (24 pages)", "summary": "Epileptic seizures arise from abnormally synchronised neural activity and remain a major global health challenge, affecting more than 50 million people worldwide. Despite advances in pharmacological interventions, a significant proportion of patients continue to experience uncontrolled seizures, underscoring the need for alternative neuromodulation strategies. Rhythmic neural entrainment has recently emerged as a promising mechanism for disrupting pathological synchrony, but most existing systems rely on complex analogue electronics or high-power stimulation hardware. This study investigates a minimal digital custom-designed chip that generates a stable 6 Hz oscillation capable of entraining epileptic seizure activity. Using a publicly available EEG seizure dataset, we extracted and averaged analogue seizure waveforms, digitised them to emulate neural front-ends, and directly interfaced the digitised signals with digital output recordings acquired from the chip using a Saleae Logic analyser. The chip pulse train was resampled and low-pass-reconstructed to produce an analogue 6 Hz waveform, allowing direct comparison between seizure morphology, its digitised representation, and the entrained output. Frequency-domain and time-domain analyses demonstrate that the chip imposes a narrow-band 6 Hz rhythm that overrides the broadband spectral profile of seizure activity. These results provide a proof-of-concept for low-power digital custom-designed entrainment as a potential pathway toward simplified, wearable seizure-interruption devices for precision medicine and future healthcare devices.", "AI": {"tldr": "\u7814\u7a76\u4eba\u5458\u5f00\u53d1\u4e86\u4e00\u79cd\u6700\u5c0f\u5316\u6570\u5b57\u5b9a\u5236\u82af\u7247\uff0c\u53ef\u4ea7\u751f\u7a33\u5b9a\u76846Hz\u632f\u8361\u6765\u5e72\u6270\u766b\u75eb\u53d1\u4f5c\u6d3b\u52a8\uff0c\u4e3a\u4f4e\u529f\u8017\u53ef\u7a7f\u6234\u766b\u75eb\u5e72\u9884\u8bbe\u5907\u63d0\u4f9b\u6982\u5ff5\u9a8c\u8bc1\u3002", "motivation": "\u5168\u7403\u6709\u8d85\u8fc75000\u4e07\u766b\u75eb\u60a3\u8005\uff0c\u5c3d\u7ba1\u836f\u7269\u6cbb\u7597\u6709\u6240\u8fdb\u5c55\uff0c\u4f46\u4ecd\u6709\u5927\u91cf\u60a3\u8005\u766b\u75eb\u53d1\u4f5c\u65e0\u6cd5\u63a7\u5236\u3002\u73b0\u6709\u795e\u7ecf\u8c03\u8282\u7b56\u7565\u5927\u591a\u4f9d\u8d56\u590d\u6742\u7684\u6a21\u62df\u7535\u5b50\u8bbe\u5907\u6216\u9ad8\u529f\u7387\u523a\u6fc0\u786c\u4ef6\uff0c\u9700\u8981\u66f4\u7b80\u5355\u3001\u4f4e\u529f\u8017\u7684\u66ff\u4ee3\u65b9\u6848\u3002", "method": "\u4f7f\u7528\u516c\u5f00\u53ef\u7528\u7684EEG\u766b\u75eb\u6570\u636e\u96c6\uff0c\u63d0\u53d6\u5e76\u5e73\u5747\u6a21\u62df\u766b\u75eb\u6ce2\u5f62\uff0c\u5c06\u5176\u6570\u5b57\u5316\u4ee5\u6a21\u62df\u795e\u7ecf\u524d\u7aef\uff0c\u7136\u540e\u76f4\u63a5\u4e0e\u5b9a\u5236\u8bbe\u8ba1\u7684\u6570\u5b57\u82af\u7247\u63a5\u53e3\u3002\u82af\u7247\u8109\u51b2\u5e8f\u5217\u88ab\u91cd\u91c7\u6837\u548c\u4f4e\u901a\u91cd\u6784\u4ee5\u4ea7\u751f\u6a21\u62df6Hz\u6ce2\u5f62\uff0c\u8fdb\u884c\u9891\u57df\u548c\u65f6\u57df\u5206\u6790\u3002", "result": "\u82af\u7247\u65bd\u52a0\u7684\u7a84\u5e266Hz\u8282\u5f8b\u80fd\u591f\u8986\u76d6\u766b\u75eb\u6d3b\u52a8\u7684\u5bbd\u5e26\u9891\u8c31\u7279\u5f81\uff0c\u8bc1\u660e\u6570\u5b57\u5b9a\u5236\u82af\u7247\u80fd\u591f\u6709\u6548\u5e72\u6270\u766b\u75eb\u53d1\u4f5c\u6d3b\u52a8\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u4f4e\u529f\u8017\u6570\u5b57\u5b9a\u5236\u795e\u7ecf\u8c03\u8282\u63d0\u4f9b\u4e86\u6982\u5ff5\u9a8c\u8bc1\uff0c\u4e3a\u5f00\u53d1\u7b80\u5316\u7684\u53ef\u7a7f\u6234\u766b\u75eb\u5e72\u9884\u8bbe\u5907\u5f00\u8f9f\u4e86\u6f5c\u5728\u9014\u5f84\uff0c\u9002\u7528\u4e8e\u7cbe\u51c6\u533b\u7597\u548c\u672a\u6765\u533b\u7597\u8bbe\u5907\u3002"}}
{"id": "2512.16001", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.16001", "abs": "https://arxiv.org/abs/2512.16001", "authors": ["Evangelos Sariyanidi", "John D. Herrington", "Lisa Yankowitz", "Pratik Chaudhari", "Theodore D. Satterthwaite", "Casey J. Zampella", "Jeffrey S. Morris", "Edward Gunning", "Robert T. Schultz", "Russell T. Shinohara", "Birkan Tunc"], "title": "Concurrence: A dependence criterion for time series, applied to biological data", "comment": null, "summary": "Measuring the statistical dependence between observed signals is a primary tool for scientific discovery. However, biological systems often exhibit complex non-linear interactions that currently cannot be captured without a priori knowledge or large datasets. We introduce a criterion for dependence, whereby two time series are deemed dependent if one can construct a classifier that distinguishes between temporally aligned vs. misaligned segments extracted from them. We show that this criterion, concurrence, is theoretically linked with dependence, and can become a standard approach for scientific analyses across disciplines, as it can expose relationships across a wide spectrum of signals (fMRI, physiological and behavioral data) without ad-hoc parameter tuning or large amounts of data.", "AI": {"tldr": "\u63d0\u51fa\u540d\u4e3a\"concurrence\"\u7684\u4f9d\u8d56\u5ea6\u91cf\u6807\u51c6\uff0c\u901a\u8fc7\u5206\u7c7b\u5668\u533a\u5206\u65f6\u95f4\u5bf9\u9f50\u4e0e\u9519\u9f50\u7684\u5e8f\u5217\u7247\u6bb5\u6765\u68c0\u6d4b\u4fe1\u53f7\u95f4\u7684\u7edf\u8ba1\u4f9d\u8d56\u5173\u7cfb", "motivation": "\u751f\u7269\u7cfb\u7edf\u5e38\u8868\u73b0\u51fa\u590d\u6742\u7684\u975e\u7ebf\u6027\u76f8\u4e92\u4f5c\u7528\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u5148\u9a8c\u77e5\u8bc6\u6216\u5927\u6570\u636e\u96c6\u624d\u80fd\u6355\u6349\u8fd9\u4e9b\u5173\u7cfb\uff0c\u9700\u8981\u4e00\u79cd\u65e0\u9700\u53c2\u6570\u8c03\u4f18\u6216\u5927\u91cf\u6570\u636e\u5c31\u80fd\u68c0\u6d4b\u5e7f\u6cdb\u4fe1\u53f7\u95f4\u4f9d\u8d56\u5173\u7cfb\u7684\u65b9\u6cd5", "method": "\u5f15\u5165concurrence\u6807\u51c6\uff1a\u5982\u679c\u80fd\u591f\u6784\u5efa\u4e00\u4e2a\u5206\u7c7b\u5668\u6765\u533a\u5206\u4ece\u4e24\u4e2a\u65f6\u95f4\u5e8f\u5217\u4e2d\u63d0\u53d6\u7684\u65f6\u95f4\u5bf9\u9f50\u4e0e\u65f6\u95f4\u9519\u9f50\u7684\u7247\u6bb5\uff0c\u5219\u8ba4\u4e3a\u8fd9\u4e24\u4e2a\u65f6\u95f4\u5e8f\u5217\u662f\u4f9d\u8d56\u7684\u3002\u8be5\u65b9\u6cd5\u7406\u8bba\u4e0a\u4e0e\u4f9d\u8d56\u5173\u7cfb\u76f8\u5173\u8054", "result": "concurrence\u80fd\u591f\u66b4\u9732\u591a\u79cd\u4fe1\u53f7\uff08fMRI\u3001\u751f\u7406\u548c\u884c\u4e3a\u6570\u636e\uff09\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u65e0\u9700\u7279\u5b9a\u53c2\u6570\u8c03\u4f18\u6216\u5927\u91cf\u6570\u636e\uff0c\u53ef\u6210\u4e3a\u8de8\u5b66\u79d1\u79d1\u5b66\u5206\u6790\u7684\u6807\u51c6\u65b9\u6cd5", "conclusion": "concurrence\u4e3a\u68c0\u6d4b\u590d\u6742\u975e\u7ebf\u6027\u76f8\u4e92\u4f5c\u7528\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u3001\u65e0\u9700\u5927\u91cf\u6570\u636e\u7684\u4f9d\u8d56\u5ea6\u91cf\u65b9\u6cd5\uff0c\u6709\u671b\u6210\u4e3a\u8de8\u5b66\u79d1\u79d1\u5b66\u53d1\u73b0\u7684\u6807\u51c6\u5de5\u5177"}}
{"id": "2512.16318", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2512.16318", "abs": "https://arxiv.org/abs/2512.16318", "authors": ["Gloria Dal Santo", "Karolina Prawda", "Sebastian J. Schlecht", "Vesa V\u00e4lim\u00e4ki"], "title": "Learning Recursive Attenuation Filters Under Noisy Conditions", "comment": "Submitted to the Journal of Audio Engineering Society", "summary": "Recursion is a fundamental concept in the design of filters and audio systems. In particular, artificial reverberation systems that use delay networks depend on recursive paths to control both echo density and the decay rate of modal components. The differentiable digital signal processing framework has shown promise in automatically tuning both recursive and non-recursive elements given a target room impulse response. This is done by applying gradient descent to loss functions based on energy-decay or spectrogram differences. However, these representations are highly sensitive to background noise, which is ubiquitous in real measurements, producing spurious loss minima and leading to incorrect attenuation. This paper addresses the problem of tuning recursive attenuation filters of a feedback delay network when targets are noisy. We examine the loss landscape associated with different optimization objectives and propose a method that ensures correct minima under low signal-to-noise conditions. We demonstrate the effectiveness of the proposed approach through statistical analysis on 80 individual optimization examples. The results reveal that explicitly modeling the noise restores correct minima. Furthermore, we identify the sensitivity of attenuation filter parameters tuning to perturbations in frequency-independent parameters. These findings provide practical guidelines for more robust and reproducible gradient-based optimization of feedback delay networks.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u4f18\u5316\u53cd\u9988\u5ef6\u8fdf\u7f51\u7edc\u9012\u5f52\u8870\u51cf\u6ee4\u6ce2\u5668\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u5efa\u6a21\u566a\u58f0\u6765\u6062\u590d\u6b63\u786e\u7684\u635f\u5931\u6700\u5c0f\u503c\uff0c\u63d0\u9ad8\u68af\u5ea6\u4f18\u5316\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u73b0\u6709\u7684\u53ef\u5fae\u5206\u6570\u5b57\u4fe1\u53f7\u5904\u7406\u6846\u67b6\u5728\u4f18\u5316\u9012\u5f52\u7cfb\u7edf\u65f6\uff0c\u4f7f\u7528\u57fa\u4e8e\u80fd\u91cf\u8870\u51cf\u6216\u9891\u8c31\u56fe\u5dee\u5f02\u7684\u635f\u5931\u51fd\u6570\uff0c\u4f46\u8fd9\u4e9b\u8868\u793a\u5bf9\u80cc\u666f\u566a\u58f0\u9ad8\u5ea6\u654f\u611f\u3002\u5b9e\u9645\u6d4b\u91cf\u4e2d\u666e\u904d\u5b58\u5728\u566a\u58f0\uff0c\u4f1a\u5bfc\u81f4\u865a\u5047\u7684\u635f\u5931\u6700\u5c0f\u503c\u548c\u4e0d\u6b63\u786e\u7684\u8870\u51cf\u53c2\u6570\u3002", "method": "\u7814\u7a76\u4e0d\u540c\u4f18\u5316\u76ee\u6807\u7684\u635f\u5931\u51fd\u6570\u666f\u89c2\uff0c\u63d0\u51fa\u4e00\u79cd\u5728\u4f4e\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u786e\u4fdd\u6b63\u786e\u6700\u5c0f\u503c\u7684\u65b9\u6cd5\u3002\u8be5\u65b9\u6cd5\u663e\u5f0f\u5efa\u6a21\u566a\u58f0\uff0c\u5e76\u901a\u8fc780\u4e2a\u72ec\u7acb\u4f18\u5316\u793a\u4f8b\u8fdb\u884c\u7edf\u8ba1\u5206\u6790\u9a8c\u8bc1\u3002", "result": "\u663e\u5f0f\u5efa\u6a21\u566a\u58f0\u80fd\u591f\u6062\u590d\u6b63\u786e\u7684\u635f\u5931\u6700\u5c0f\u503c\u3002\u540c\u65f6\u53d1\u73b0\u8870\u51cf\u6ee4\u6ce2\u5668\u53c2\u6570\u8c03\u8c10\u5bf9\u9891\u7387\u65e0\u5173\u53c2\u6570\u7684\u6270\u52a8\u5177\u6709\u654f\u611f\u6027\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u57fa\u4e8e\u68af\u5ea6\u7684\u53cd\u9988\u5ef6\u8fdf\u7f51\u7edc\u4f18\u5316\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u548c\u53ef\u91cd\u590d\u7684\u5b9e\u7528\u6307\u5bfc\u539f\u5219\uff0c\u7279\u522b\u662f\u5728\u566a\u58f0\u76ee\u6807\u6761\u4ef6\u4e0b\u3002"}}
{"id": "2512.15830", "categories": ["cs.SD", "cs.CL", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2512.15830", "abs": "https://arxiv.org/abs/2512.15830", "authors": ["Linnea Evanson", "Mingfang", "Zhang", "Hubert Banville", "Saarang Panchavati", "Pierre Bourdillon", "Jean-R\u00e9mi King"], "title": "From Minutes to Days: Scaling Intracranial Speech Decoding with Supervised Pretraining", "comment": "Linnea Evanson* and Mingfang (Lucy) Zhang* are joint first authors. Pierre Bourdillon** and Jean-R\u00e9mi King** are joint last authors", "summary": "Decoding speech from brain activity has typically relied on limited neural recordings collected during short and highly controlled experiments. Here, we introduce a framework to leverage week-long intracranial and audio recordings from patients undergoing clinical monitoring, effectively increasing the training dataset size by over two orders of magnitude. With this pretraining, our contrastive learning model substantially outperforms models trained solely on classic experimental data, with gains that scale log-linearly with dataset size. Analysis of the learned representations reveals that, while brain activity represents speech features, its global structure largely drifts across days, highlighting the need for models that explicitly account for cross-day variability. Overall, our approach opens a scalable path toward decoding and modeling brain representations in both real-life and controlled task settings.", "AI": {"tldr": "\u5229\u7528\u4e34\u5e8a\u76d1\u6d4b\u60a3\u8005\u957f\u8fbe\u4e00\u5468\u7684\u9885\u5185\u548c\u97f3\u9891\u8bb0\u5f55\uff0c\u901a\u8fc7\u5bf9\u6bd4\u5b66\u4e60\u6a21\u578b\u663e\u8457\u63d0\u5347\u8111\u6d3b\u52a8\u89e3\u7801\u8bed\u97f3\u7684\u6027\u80fd\uff0c\u6027\u80fd\u968f\u6570\u636e\u91cf\u5bf9\u6570\u7ebf\u6027\u589e\u957f", "motivation": "\u4f20\u7edf\u8111\u6d3b\u52a8\u89e3\u7801\u8bed\u97f3\u7814\u7a76\u4f9d\u8d56\u77ed\u671f\u3001\u9ad8\u5ea6\u63a7\u5236\u7684\u5b9e\u9a8c\u6570\u636e\uff0c\u6570\u636e\u91cf\u6709\u9650\u3002\u9700\u8981\u5229\u7528\u4e34\u5e8a\u76d1\u6d4b\u4e2d\u66f4\u957f\u65f6\u95f4\u3001\u66f4\u81ea\u7136\u7684\u8bb0\u5f55\u6765\u6269\u5c55\u8bad\u7ec3\u6570\u636e\u96c6", "method": "\u5f15\u5165\u6846\u67b6\u5229\u7528\u60a3\u8005\u4e34\u5e8a\u76d1\u6d4b\u671f\u95f4\u957f\u8fbe\u4e00\u5468\u7684\u9885\u5185\u548c\u97f3\u9891\u8bb0\u5f55\uff0c\u5c06\u8bad\u7ec3\u6570\u636e\u96c6\u6269\u5927\u4e24\u4e2a\u6570\u91cf\u7ea7\u4ee5\u4e0a\u3002\u4f7f\u7528\u5bf9\u6bd4\u5b66\u4e60\u6a21\u578b\u8fdb\u884c\u9884\u8bad\u7ec3", "result": "\u5bf9\u6bd4\u5b66\u4e60\u6a21\u578b\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u4ec5\u4f7f\u7528\u4f20\u7edf\u5b9e\u9a8c\u6570\u636e\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u6027\u80fd\u589e\u76ca\u968f\u6570\u636e\u96c6\u5927\u5c0f\u5448\u5bf9\u6570\u7ebf\u6027\u589e\u957f\u3002\u5206\u6790\u53d1\u73b0\u8111\u6d3b\u52a8\u8868\u793a\u8bed\u97f3\u7279\u5f81\uff0c\u4f46\u5168\u5c40\u7ed3\u6784\u968f\u65f6\u95f4\u6f02\u79fb", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5728\u73b0\u5b9e\u751f\u6d3b\u548c\u53d7\u63a7\u4efb\u52a1\u73af\u5883\u4e2d\u89e3\u7801\u548c\u5efa\u6a21\u8111\u8868\u5f81\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u5f84\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u660e\u786e\u5904\u7406\u8de8\u5929\u53d8\u5f02\u6027\u7684\u6a21\u578b"}}
{"id": "2512.16224", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.16224", "abs": "https://arxiv.org/abs/2512.16224", "authors": ["Yanyu Cheng", "Yujian Hu", "Haoran Liu", "Hua Zhong", "Wei Wang", "Pan Li", "Dusit Niyato"], "title": "Simultaneous Secrecy and Covert Communications (SSACC) in Mobility-Aware RIS-Aided Networks", "comment": null, "summary": "In this paper, we propose a simultaneous secrecy and covert communications (SSACC) scheme in a reconfigurable intelligent surface (RIS)-aided network with a cooperative jammer. The scheme enhances communication security by maximizing the secrecy capacity and the detection error probability (DEP). Under a worst-case scenario for covert communications, we consider that the eavesdropper can optimally adjust the detection threshold to minimize the DEP. Accordingly, we derive closedform expressions for both average minimum DEP (AMDEP) and average secrecy capacity (ASC). To balance AMDEP and ASC, we propose a new performance metric and design an algorithm based on generative diffusion models (GDM) and deep reinforcement learning (DRL). The algorithm maximizes data rates under user mobility while ensuring high AMDEP and ASC by optimizing power allocation. Simulation results demonstrate that the proposed algorithm achieves faster convergence and superior performance compared to conventional deep deterministic policy gradient (DDPG) methods, thereby validating its effectiveness in balancing security and capacity performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cdRIS\u8f85\u52a9\u7f51\u7edc\u4e2d\u5e26\u534f\u4f5c\u5e72\u6270\u5668\u7684\u540c\u65f6\u4fdd\u5bc6\u4e0e\u9690\u853d\u901a\u4fe1\u65b9\u6848\uff0c\u901a\u8fc7\u6700\u5927\u5316\u4fdd\u5bc6\u5bb9\u91cf\u548c\u68c0\u6d4b\u9519\u8bef\u6982\u7387\u6765\u589e\u5f3a\u901a\u4fe1\u5b89\u5168\uff0c\u5e76\u8bbe\u8ba1\u57fa\u4e8e\u751f\u6210\u6269\u6563\u6a21\u578b\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u7b97\u6cd5\u6765\u5e73\u8861\u6027\u80fd", "motivation": "\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\u540c\u65f6\u5b9e\u73b0\u4fdd\u5bc6\u6027\u548c\u9690\u853d\u6027\u5177\u6709\u6311\u6218\u6027\u3002\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u5728\u52a8\u6001\u73af\u5883\u4e2d\u5e73\u8861\u4fdd\u5bc6\u5bb9\u91cf\u548c\u68c0\u6d4b\u9519\u8bef\u6982\u7387\uff0c\u7279\u522b\u662f\u5728\u7a83\u542c\u8005\u53ef\u4ee5\u81ea\u9002\u5e94\u8c03\u6574\u68c0\u6d4b\u9608\u503c\u7684\u6700\u574f\u60c5\u51b5\u4e0b\uff0c\u9700\u8981\u66f4\u667a\u80fd\u7684\u4f18\u5316\u65b9\u6848\u6765\u5e94\u5bf9\u7528\u6237\u79fb\u52a8\u6027\u548c\u8d44\u6e90\u5206\u914d\u95ee\u9898\u3002", "method": "\u63d0\u51faRIS\u8f85\u52a9\u7f51\u7edc\u4e2d\u5e26\u534f\u4f5c\u5e72\u6270\u5668\u7684SSACC\u65b9\u6848\u3002\u5728\u7a83\u542c\u8005\u6700\u4f18\u8c03\u6574\u68c0\u6d4b\u9608\u503c\u7684\u6700\u574f\u60c5\u51b5\u4e0b\uff0c\u63a8\u5bfc\u51fa\u5e73\u5747\u6700\u5c0f\u68c0\u6d4b\u9519\u8bef\u6982\u7387\u548c\u5e73\u5747\u4fdd\u5bc6\u5bb9\u91cf\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\u3002\u8bbe\u8ba1\u57fa\u4e8e\u751f\u6210\u6269\u6563\u6a21\u578b\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7684\u7b97\u6cd5\uff0c\u901a\u8fc7\u4f18\u5316\u529f\u7387\u5206\u914d\u6765\u6700\u5927\u5316\u6570\u636e\u901f\u7387\uff0c\u540c\u65f6\u786e\u4fdd\u9ad8AMDEP\u548cASC\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u76f8\u6bd4\u4f20\u7edfDDPG\u65b9\u6cd5\u6536\u655b\u66f4\u5feb\u4e14\u6027\u80fd\u66f4\u4f18\uff0c\u6709\u6548\u9a8c\u8bc1\u4e86\u5176\u5728\u5e73\u8861\u5b89\u5168\u6027\u548c\u5bb9\u91cf\u6027\u80fd\u65b9\u9762\u7684\u6709\u6548\u6027\u3002\u7b97\u6cd5\u5728\u7528\u6237\u79fb\u52a8\u6027\u6761\u4ef6\u4e0b\u4ecd\u80fd\u4fdd\u6301\u9ad8\u6027\u80fd\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5b9e\u73b0\u4e86RIS\u8f85\u52a9\u7f51\u7edc\u4e2d\u540c\u65f6\u4fdd\u5bc6\u4e0e\u9690\u853d\u901a\u4fe1\u7684\u5e73\u8861\u4f18\u5316\uff0c\u63d0\u51fa\u7684GDM-DRL\u7b97\u6cd5\u4e3a\u52a8\u6001\u65e0\u7ebf\u73af\u5883\u4e2d\u7684\u5b89\u5168\u901a\u4fe1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u5b89\u5168\u6027\u548c\u5bb9\u91cf\u6027\u80fd\u4e4b\u95f4\u53d6\u5f97\u4e86\u826f\u597d\u6743\u8861\u3002"}}
{"id": "2512.16395", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2512.16395", "abs": "https://arxiv.org/abs/2512.16395", "authors": ["Anup Singh", "Kris Demuynck", "Vipul Arora"], "title": "BEST-STD2.0: Balanced and Efficient Speech Tokenizer for Spoken Term Detection", "comment": "Submitted to ICASSP 2026", "summary": "Fast and accurate spoken content retrieval is vital for applications such as voice search. Query-by-Example Spoken Term Detection (STD) involves retrieving matching segments from an audio database given a spoken query. Token-based STD systems, which use discrete speech representations, enable efficient search but struggle with robustness to noise and reverberation, and with inefficient token utilization. We address these challenges by proposing a noise and reverberation-augmented training strategy to improve tokenizer robustness. In addition, we introduce optimal transport-based regularization to ensure balanced token usage and enhance token efficiency. To further speed up retrieval, we adopt a TF-IDF-based search mechanism. Empirical evaluations demonstrate that the proposed method outperforms STD baselines across various distortion levels while maintaining high search efficiency.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u589e\u5f3a\u7684\u67e5\u8be2\u793a\u4f8b\u8bed\u97f3\u672f\u8bed\u68c0\u6d4b\u65b9\u6cd5\uff0c\u901a\u8fc7\u566a\u58f0\u589e\u5f3a\u8bad\u7ec3\u548c\u6700\u4f18\u4f20\u8f93\u6b63\u5219\u5316\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u6807\u8bb0\u6548\u7387\uff0c\u7ed3\u5408TF-IDF\u641c\u7d22\u52a0\u901f\u68c0\u7d22", "motivation": "\u57fa\u4e8e\u6807\u8bb0\u7684\u8bed\u97f3\u672f\u8bed\u68c0\u6d4b\u7cfb\u7edf\u867d\u7136\u641c\u7d22\u6548\u7387\u9ad8\uff0c\u4f46\u5bf9\u566a\u58f0\u548c\u6df7\u54cd\u7684\u9c81\u68d2\u6027\u4e0d\u8db3\uff0c\u4e14\u6807\u8bb0\u5229\u7528\u6548\u7387\u4f4e\u4e0b\uff0c\u9700\u8981\u6539\u8fdb", "method": "1) \u566a\u58f0\u548c\u6df7\u54cd\u589e\u5f3a\u8bad\u7ec3\u7b56\u7565\u63d0\u9ad8\u6807\u8bb0\u5316\u5668\u7684\u9c81\u68d2\u6027\uff1b2) \u6700\u4f18\u4f20\u8f93\u6b63\u5219\u5316\u786e\u4fdd\u5e73\u8861\u7684\u6807\u8bb0\u4f7f\u7528\u5e76\u63d0\u9ad8\u6807\u8bb0\u6548\u7387\uff1b3) TF-IDF\u641c\u7d22\u673a\u5236\u52a0\u901f\u68c0\u7d22", "result": "\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u5931\u771f\u6c34\u5e73\u4e0b\u90fd\u4f18\u4e8e\u57fa\u7ebfSTD\u7cfb\u7edf\uff0c\u540c\u65f6\u4fdd\u6301\u9ad8\u641c\u7d22\u6548\u7387", "conclusion": "\u63d0\u51fa\u7684\u566a\u58f0\u589e\u5f3a\u8bad\u7ec3\u3001\u6700\u4f18\u4f20\u8f93\u6b63\u5219\u5316\u548cTF-IDF\u641c\u7d22\u76f8\u7ed3\u5408\u7684\u65b9\u6cd5\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u57fa\u4e8e\u6807\u8bb0\u7684STD\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u548c\u6548\u7387\u95ee\u9898"}}
{"id": "2512.16271", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.16271", "abs": "https://arxiv.org/abs/2512.16271", "authors": ["Geofrey Owino", "Bernard Shibwabo Kasamani", "Ahmed M. Abdelmoniem", "Edem Wornyo"], "title": "Domain-Agnostic Causal-Aware Audio Transformer for Infant Cry Classification", "comment": "This paper has been published in the IEEE proceedings of the 8th International Conference of Computer and Informatics Engineering (IC2IE)", "summary": "Accurate and interpretable classification of infant cry paralinguistics is essential for early detection of neonatal distress and clinical decision support. However, many existing deep learning methods rely on correlation-driven acoustic representations, which makes them vulnerable to noise, spurious cues, and domain shifts across recording environments. We propose DACH-TIC, a Domain-Agnostic Causal-Aware Hierarchical Audio Transformer for robust infant cry classification. The model integrates causal attention, hierarchical representation learning, multi-task supervision, and adversarial domain generalization within a unified framework.\n  DACH-TIC employs a structured transformer backbone with local token-level and global semantic encoders, augmented by causal attention masking and controlled perturbation training to approximate counterfactual acoustic variations. A domain-adversarial objective promotes environment-invariant representations, while multi-task learning jointly optimizes cry type recognition, distress intensity estimation, and causal relevance prediction. The model is evaluated on the Baby Chillanto and Donate-a-Cry datasets, with ESC-50 environmental noise overlays for domain augmentation.\n  Experimental results show that DACH-TIC outperforms state-of-the-art baselines, including HTS-AT and SE-ResNet Transformer, achieving improvements of 2.6 percent in accuracy and 2.2 points in macro-F1 score, alongside enhanced causal fidelity. The model generalizes effectively to unseen acoustic environments, with a domain performance gap of only 2.4 percent, demonstrating its suitability for real-world neonatal acoustic monitoring systems.", "AI": {"tldr": "DACH-TIC\uff1a\u4e00\u79cd\u7528\u4e8e\u5a74\u513f\u54ed\u58f0\u5206\u7c7b\u7684\u9886\u57df\u65e0\u5173\u56e0\u679c\u611f\u77e5\u5206\u5c42\u97f3\u9891Transformer\uff0c\u901a\u8fc7\u56e0\u679c\u6ce8\u610f\u529b\u3001\u5206\u5c42\u8868\u793a\u5b66\u4e60\u3001\u591a\u4efb\u52a1\u76d1\u7763\u548c\u5bf9\u6297\u9886\u57df\u6cdb\u5316\u6765\u63d0\u9ad8\u9c81\u68d2\u6027\u548c\u53ef\u89e3\u91ca\u6027\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u4f9d\u8d56\u76f8\u5173\u6027\u9a71\u52a8\u7684\u58f0\u5b66\u8868\u793a\uff0c\u5bb9\u6613\u53d7\u5230\u566a\u58f0\u3001\u865a\u5047\u7ebf\u7d22\u548c\u9886\u57df\u504f\u79fb\u7684\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684\u5a74\u513f\u54ed\u58f0\u5206\u7c7b\u65b9\u6cd5\u7528\u4e8e\u65b0\u751f\u513f\u65e9\u671f\u68c0\u6d4b\u548c\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u3002", "method": "\u63d0\u51faDACH-TIC\u6a21\u578b\uff0c\u5305\u542b\uff1a1\uff09\u7ed3\u6784\u5316Transformer\u9aa8\u5e72\u7f51\u7edc\uff0c\u5177\u6709\u5c40\u90e8token\u7ea7\u548c\u5168\u5c40\u8bed\u4e49\u7f16\u7801\u5668\uff1b2\uff09\u56e0\u679c\u6ce8\u610f\u529b\u63a9\u7801\u548c\u53d7\u63a7\u6270\u52a8\u8bad\u7ec3\u6765\u8fd1\u4f3c\u53cd\u4e8b\u5b9e\u58f0\u5b66\u53d8\u5316\uff1b3\uff09\u9886\u57df\u5bf9\u6297\u76ee\u6807\u4fc3\u8fdb\u73af\u5883\u4e0d\u53d8\u8868\u793a\uff1b4\uff09\u591a\u4efb\u52a1\u5b66\u4e60\u8054\u5408\u4f18\u5316\u54ed\u58f0\u7c7b\u578b\u8bc6\u522b\u3001\u75db\u82e6\u5f3a\u5ea6\u4f30\u8ba1\u548c\u56e0\u679c\u76f8\u5173\u6027\u9884\u6d4b\u3002", "result": "\u5728Baby Chillanto\u548cDonate-a-Cry\u6570\u636e\u96c6\u4e0a\u8bc4\u4f30\uff0cDACH-TIC\u4f18\u4e8eHTS-AT\u548cSE-ResNet Transformer\u7b49SOTA\u57fa\u7ebf\uff0c\u51c6\u786e\u7387\u63d0\u53472.6%\uff0c\u5b8fF1\u5206\u6570\u63d0\u53472.2\u5206\uff0c\u5177\u6709\u589e\u5f3a\u7684\u56e0\u679c\u4fdd\u771f\u5ea6\u3002\u5728\u672a\u89c1\u58f0\u5b66\u73af\u5883\u4e2d\u6cdb\u5316\u6548\u679c\u597d\uff0c\u9886\u57df\u6027\u80fd\u5dee\u8ddd\u4ec52.4%\u3002", "conclusion": "DACH-TIC\u901a\u8fc7\u96c6\u6210\u56e0\u679c\u611f\u77e5\u3001\u5206\u5c42\u8868\u793a\u548c\u9886\u57df\u6cdb\u5316\u6280\u672f\uff0c\u4e3a\u73b0\u5b9e\u4e16\u754c\u65b0\u751f\u513f\u58f0\u5b66\u76d1\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u53ef\u89e3\u91ca\u7684\u5a74\u513f\u54ed\u58f0\u5206\u7c7b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.16273", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.16273", "abs": "https://arxiv.org/abs/2512.16273", "authors": ["Ce Zheng", "Ke Zhang", "Sun Chen", "Wenqi Zhang", "Qiong Liu", "Angesom Ataklity Tesfay"], "title": "Fast Collaborative Inference via Distributed Speculative Decoding", "comment": null, "summary": "Speculative decoding accelerates large language model (LLM) inference by allowing a small draft model to predict multiple future tokens for verification by a larger target model. In AI-native radio access networks (AI-RAN), this enables device-edge collaborative inference but introduces significant uplink overhead, as existing distributed speculative decoding schemes transmit full vocabulary logits at every step. We propose a sparsify-then-sample strategy, Truncated Sparse Logits Transmission (TSLT), which transmits only the logits and indices of a truncated candidate set. We provide theoretical guarantees showing that the acceptance rate is preserved under TSLT. TSLT is further extended to multi-candidate case, where multiple draft candidates per step increase acceptance probability. Experiments show that TSLT significantly reduces uplink communication while maintaining end-to-end inference latency and model quality, demonstrating its effectiveness for scalable, communication-efficient distributed LLM inference in future AI-RAN systems.", "AI": {"tldr": "\u63d0\u51faTSLT\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f20\u8f93\u622a\u65ad\u7a00\u758f\u5bf9\u6570\u6765\u51cf\u5c11AI-RAN\u4e2d\u5206\u5e03\u5f0f\u63a8\u6d4b\u89e3\u7801\u7684\u4e0a\u884c\u901a\u4fe1\u5f00\u9500\uff0c\u540c\u65f6\u4fdd\u6301\u63a5\u53d7\u7387\u548c\u63a8\u7406\u6027\u80fd\u3002", "motivation": "\u5728AI\u539f\u751f\u65e0\u7ebf\u63a5\u5165\u7f51\u7edc\u4e2d\uff0c\u8bbe\u5907-\u8fb9\u7f18\u534f\u540c\u63a8\u7406\u4f7f\u7528\u63a8\u6d4b\u89e3\u7801\u52a0\u901fLLM\u63a8\u7406\uff0c\u4f46\u73b0\u6709\u5206\u5e03\u5f0f\u65b9\u6848\u5728\u6bcf\u4e2a\u6b65\u9aa4\u4f20\u8f93\u5b8c\u6574\u8bcd\u6c47\u8868\u5bf9\u6570\uff0c\u5bfc\u81f4\u663e\u8457\u4e0a\u884c\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u622a\u65ad\u7a00\u758f\u5bf9\u6570\u4f20\u8f93\u7b56\u7565\uff1a\u5148\u7a00\u758f\u5316\u518d\u91c7\u6837\uff0c\u4ec5\u4f20\u8f93\u622a\u65ad\u5019\u9009\u96c6\u7684logits\u548c\u7d22\u5f15\uff1b\u6269\u5c55\u5230\u591a\u5019\u9009\u60c5\u51b5\u4ee5\u63d0\u9ad8\u63a5\u53d7\u6982\u7387\uff1b\u63d0\u4f9b\u7406\u8bba\u4fdd\u8bc1\u8bc1\u660e\u63a5\u53d7\u7387\u5728TSLT\u4e0b\u5f97\u4ee5\u4fdd\u6301\u3002", "result": "\u5b9e\u9a8c\u8868\u660eTSLT\u663e\u8457\u51cf\u5c11\u4e0a\u884c\u901a\u4fe1\uff0c\u540c\u65f6\u4fdd\u6301\u7aef\u5230\u7aef\u63a8\u7406\u5ef6\u8fdf\u548c\u6a21\u578b\u8d28\u91cf\uff0c\u8bc1\u660e\u5176\u5728\u672a\u6765AI-RAN\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u53ef\u6269\u5c55\u3001\u901a\u4fe1\u9ad8\u6548\u7684\u5206\u5e03\u5f0fLLM\u63a8\u7406\u7684\u6709\u6548\u6027\u3002", "conclusion": "TSLT\u4e3aAI-RAN\u4e2d\u7684\u5206\u5e03\u5f0fLLM\u63a8\u7406\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u4fe1\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7a00\u758f\u5316\u4f20\u8f93\u7b56\u7565\u5e73\u8861\u4e86\u901a\u4fe1\u5f00\u9500\u548c\u63a8\u7406\u6027\u80fd\uff0c\u652f\u6301\u53ef\u6269\u5c55\u7684\u534f\u540c\u63a8\u7406\u7cfb\u7edf\u3002"}}
{"id": "2512.16519", "categories": ["cs.SD", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2512.16519", "abs": "https://arxiv.org/abs/2512.16519", "authors": ["Nikolaos Ellinas", "Alexandra Vioni", "Panos Kakoulidis", "Georgios Vamvoukakis", "Myrsini Christidou", "Konstantinos Markopoulos", "Junkwang Oh", "Gunu Jho", "Inchul Hwang", "Aimilios Chalamandaris", "Pirros Tsiakoulis"], "title": "Pseudo-Cepstrum: Pitch Modification for Mel-Based Neural Vocoders", "comment": null, "summary": "This paper introduces a cepstrum-based pitch modification method that can be applied to any mel-spectrogram representation. As a result, this method is compatible with any mel-based vocoder without requiring any additional training or changes to the model. This is achieved by directly modifying the cepstrum feature space in order to shift the harmonic structure to the desired target. The spectrogram magnitude is computed via the pseudo-inverse mel transform, then converted to the cepstrum by applying DCT. In this domain, the cepstral peak is shifted without having to estimate its position and the modified mel is recomputed by applying IDCT and mel-filterbank. These pitch-shifted mel-spectrogram features can be converted to speech with any compatible vocoder. The proposed method is validated experimentally with objective and subjective metrics on various state-of-the-art neural vocoders as well as in comparison with traditional pitch modification methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u5012\u8c31\u7684\u57fa\u9891\u4fee\u6539\u65b9\u6cd5\uff0c\u53ef\u76f4\u63a5\u5e94\u7528\u4e8e\u4efb\u4f55\u6885\u5c14\u9891\u8c31\u56fe\u8868\u793a\uff0c\u65e0\u9700\u989d\u5916\u8bad\u7ec3\u6216\u4fee\u6539\u6a21\u578b\u3002", "motivation": "\u73b0\u6709\u57fa\u9891\u4fee\u6539\u65b9\u6cd5\u901a\u5e38\u9700\u8981\u7279\u5b9a\u8bad\u7ec3\u6216\u6a21\u578b\u4fee\u6539\uff0c\u7f3a\u4e4f\u901a\u7528\u6027\u3002\u672c\u6587\u65e8\u5728\u5f00\u53d1\u4e00\u79cd\u4e0e\u4efb\u4f55\u57fa\u4e8e\u6885\u5c14\u7684\u58f0\u7801\u5668\u517c\u5bb9\u7684\u901a\u7528\u57fa\u9891\u4fee\u6539\u65b9\u6cd5\u3002", "method": "\u901a\u8fc7\u4f2a\u9006\u6885\u5c14\u53d8\u6362\u8ba1\u7b97\u9891\u8c31\u5e45\u5ea6\uff0c\u5e94\u7528DCT\u8f6c\u6362\u5230\u5012\u8c31\u57df\uff0c\u5728\u5012\u8c31\u57df\u76f4\u63a5\u79fb\u52a8\u5012\u8c31\u5cf0\u6765\u6539\u53d8\u8c10\u6ce2\u7ed3\u6784\uff0c\u7136\u540e\u901a\u8fc7IDCT\u548c\u6885\u5c14\u6ee4\u6ce2\u5668\u7ec4\u91cd\u65b0\u8ba1\u7b97\u4fee\u6539\u540e\u7684\u6885\u5c14\u9891\u8c31\u56fe\u3002", "result": "\u65b9\u6cd5\u5728\u5404\u79cd\u6700\u5148\u8fdb\u7684\u795e\u7ecf\u58f0\u7801\u5668\u4e0a\u901a\u8fc7\u5ba2\u89c2\u548c\u4e3b\u89c2\u6307\u6807\u9a8c\u8bc1\u6709\u6548\uff0c\u4e0e\u4f20\u7edf\u57fa\u9891\u4fee\u6539\u65b9\u6cd5\u76f8\u6bd4\u8868\u73b0\u826f\u597d\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u901a\u7528\u3001\u65e0\u9700\u8bad\u7ec3\u7684\u57fa\u9891\u4fee\u6539\u89e3\u51b3\u65b9\u6848\uff0c\u53ef\u4e0e\u4efb\u4f55\u57fa\u4e8e\u6885\u5c14\u7684\u58f0\u7801\u5668\u517c\u5bb9\uff0c\u4e3a\u8bed\u97f3\u5408\u6210\u4e2d\u7684\u57fa\u9891\u63a7\u5236\u63d0\u4f9b\u4e86\u7075\u6d3b\u5de5\u5177\u3002"}}
{"id": "2512.16304", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.16304", "abs": "https://arxiv.org/abs/2512.16304", "authors": ["Jiajun Yuan", "Xiaochen Wang", "Yuhang Xiao", "Yulin Wu", "Chenhao Hu", "Xueyang Lv"], "title": "CogSR: Semantic-Aware Speech Super-Resolution via Chain-of-Thought Guided Flow Matching", "comment": "7 pages", "summary": "Applying speech super-resolution (SR) to recordings with severely low sampling rates is a critical challenge in digital archiving and investigative audio recovery. In these scenarios, the input lacks essential acoustic cues. Consequently, existing generative models often fail; without sufficient context, they hallucinate phonetic content, guessing words based on probability rather than meaning.\n  To address this, we propose CogSR, a framework designed specifically for high-precision, offline restoration. Our approach shifts the focus from simple signal mapping to cognitive reconstruction. By integrating a Large Audio-Language Model, we employ Chain-of-Thought reasoning to act as a semantic anchor, while explicit acoustic priors ensure the speaker's identity remains consistent. This guides a Rectified Flow backbone to synthesize high-frequency details that are not only realistic but linguistically accurate. Evaluations show that CogSR effectively eliminates ambiguity in severe degradation regimes, making it a robust solution for restoring high-value legacy and surveillance audio.", "AI": {"tldr": "CogSR\u662f\u4e00\u4e2a\u9488\u5bf9\u4e25\u91cd\u4f4e\u91c7\u6837\u7387\u97f3\u9891\u7684\u8bed\u97f3\u8d85\u5206\u8fa8\u7387\u6846\u67b6\uff0c\u901a\u8fc7\u8ba4\u77e5\u91cd\u5efa\u800c\u975e\u7b80\u5355\u4fe1\u53f7\u6620\u5c04\uff0c\u7ed3\u5408\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u548c\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u79bb\u7ebf\u6062\u590d\u3002", "motivation": "\u6570\u5b57\u5b58\u6863\u548c\u8c03\u67e5\u6027\u97f3\u9891\u6062\u590d\u4e2d\uff0c\u4e25\u91cd\u4f4e\u91c7\u6837\u7387\u7684\u5f55\u97f3\u7f3a\u4e4f\u57fa\u672c\u58f0\u5b66\u7ebf\u7d22\uff0c\u73b0\u6709\u751f\u6210\u6a21\u578b\u5bb9\u6613\u4ea7\u751f\u8bed\u97f3\u5185\u5bb9\u5e7b\u89c9\uff0c\u57fa\u4e8e\u6982\u7387\u800c\u975e\u610f\u4e49\u731c\u6d4b\u5355\u8bcd\uff0c\u5bfc\u81f4\u6062\u590d\u5931\u8d25\u3002", "method": "\u63d0\u51faCogSR\u6846\u67b6\uff0c\u5c06\u91cd\u70b9\u4ece\u7b80\u5355\u4fe1\u53f7\u6620\u5c04\u8f6c\u5411\u8ba4\u77e5\u91cd\u5efa\u3002\u96c6\u6210\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\uff0c\u4f7f\u7528\u94fe\u5f0f\u601d\u7ef4\u63a8\u7406\u4f5c\u4e3a\u8bed\u4e49\u951a\u70b9\uff0c\u540c\u65f6\u5229\u7528\u663e\u5f0f\u58f0\u5b66\u5148\u9a8c\u4fdd\u6301\u8bf4\u8bdd\u4eba\u8eab\u4efd\u4e00\u81f4\u6027\uff0c\u6307\u5bfcRectified Flow\u9aa8\u5e72\u7f51\u7edc\u5408\u6210\u65e2\u771f\u5b9e\u53c8\u8bed\u8a00\u51c6\u786e\u7684\u9ad8\u9891\u7ec6\u8282\u3002", "result": "\u8bc4\u4f30\u8868\u660eCogSR\u5728\u4e25\u91cd\u9000\u5316\u60c5\u51b5\u4e0b\u6709\u6548\u6d88\u9664\u6b67\u4e49\uff0c\u6210\u4e3a\u6062\u590d\u9ad8\u4ef7\u503c\u9057\u7559\u97f3\u9891\u548c\u76d1\u63a7\u97f3\u9891\u7684\u7a33\u5065\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "CogSR\u901a\u8fc7\u8ba4\u77e5\u91cd\u5efa\u65b9\u6cd5\u89e3\u51b3\u4e86\u4e25\u91cd\u4f4e\u91c7\u6837\u7387\u97f3\u9891\u6062\u590d\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u6570\u5b57\u5b58\u6863\u548c\u8c03\u67e5\u6027\u97f3\u9891\u6062\u590d\u63d0\u4f9b\u4e86\u9ad8\u7cbe\u5ea6\u3001\u8bed\u4e49\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.16315", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.16315", "abs": "https://arxiv.org/abs/2512.16315", "authors": ["Sheng Luo", "Jiashu Xie", "Yueling Che", "Junmei Yao", "Jian Tian", "Daquan Feng", "Kaishun Wu"], "title": "CPMamba: Selective State Space Models for MIMO Channel Prediction in High-Mobility Environments", "comment": null, "summary": "Channel prediction is a key technology for improving the performance of various functions such as precoding, adaptive modulation, and resource allocation in MIMO-OFDM systems. Especially in high-mobility scenarios with fast time-varying channels, it is crucial for resisting channel aging and ensuring communication quality. However, existing methods suffer from high complexity and the inability to accurately model the temporal variations of channels. To address this issue, this paper proposes CPMamba -- an efficient channel prediction framework based on the selective state space model. The proposed CPMamba architecture extracts features from historical channel state information (CSI) using a specifically designed feature extraction and embedding network and employs stacked residual Mamba modules for temporal modeling. By leveraging an input-dependent selective mechanism to dynamically adjust state transitions, it can effectively capture the long-range dependencies between the CSIs while maintaining a linear computational complexity. Simulation results under the 3GPP standard channel model demonstrate that CPMamba achieves state-of-the-art prediction accuracy across all scenarios, along with superior generalization and robustness. Compared to existing baseline models, CPMamba reduces the number of parameters by approximately 50 percent while achieving comparable or better performance, thereby significantly lowering the barrier for practical deployment.", "AI": {"tldr": "CPMamba\u662f\u4e00\u4e2a\u57fa\u4e8e\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684\u9ad8\u6548MIMO-OFDM\u4fe1\u9053\u9884\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u52a8\u6001\u8c03\u6574\u72b6\u6001\u8f6c\u79fb\u6765\u6355\u6349\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\uff0c\u5728\u4fdd\u6301\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u540c\u65f6\uff0c\u53c2\u6570\u51cf\u5c11\u7ea650%\uff0c\u5728\u5404\u79cd\u573a\u666f\u4e0b\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u7cbe\u5ea6\u3002", "motivation": "\u5728\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u4e2d\uff0c\u5feb\u901f\u65f6\u53d8\u4fe1\u9053\u7684\u9884\u6d4b\u5bf9\u4e8e\u62b5\u6297\u4fe1\u9053\u8001\u5316\u548c\u4fdd\u8bc1\u901a\u4fe1\u8d28\u91cf\u81f3\u5173\u91cd\u8981\u3002\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u590d\u6742\u5ea6\u9ad8\u548c\u65e0\u6cd5\u51c6\u786e\u5efa\u6a21\u4fe1\u9053\u65f6\u95f4\u53d8\u5316\u7684\u95ee\u9898\u3002", "method": "\u63d0\u51faCPMamba\u6846\u67b6\uff1a1\uff09\u4f7f\u7528\u4e13\u95e8\u8bbe\u8ba1\u7684\u7279\u5f81\u63d0\u53d6\u548c\u5d4c\u5165\u7f51\u7edc\u4ece\u5386\u53f2\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\uff08CSI\uff09\u4e2d\u63d0\u53d6\u7279\u5f81\uff1b2\uff09\u91c7\u7528\u5806\u53e0\u7684\u6b8b\u5deeMamba\u6a21\u5757\u8fdb\u884c\u65f6\u95f4\u5efa\u6a21\uff1b3\uff09\u5229\u7528\u8f93\u5165\u4f9d\u8d56\u7684\u9009\u62e9\u6027\u673a\u5236\u52a8\u6001\u8c03\u6574\u72b6\u6001\u8f6c\u79fb\uff0c\u6709\u6548\u6355\u6349CSI\u95f4\u7684\u957f\u671f\u4f9d\u8d56\u5173\u7cfb\uff0c\u540c\u65f6\u4fdd\u6301\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u57283GPP\u6807\u51c6\u4fe1\u9053\u6a21\u578b\u4e0b\u7684\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cCPMamba\u5728\u6240\u6709\u573a\u666f\u4e0b\u90fd\u8fbe\u5230\u4e86\u6700\u5148\u8fdb\u7684\u9884\u6d4b\u7cbe\u5ea6\uff0c\u5e76\u5177\u6709\u4f18\u5f02\u7684\u6cdb\u5316\u80fd\u529b\u548c\u9c81\u68d2\u6027\u3002\u4e0e\u73b0\u6709\u57fa\u7ebf\u6a21\u578b\u76f8\u6bd4\uff0cCPMamba\u53c2\u6570\u6570\u91cf\u51cf\u5c11\u7ea650%\uff0c\u540c\u65f6\u8fbe\u5230\u76f8\u5f53\u6216\u66f4\u597d\u7684\u6027\u80fd\u3002", "conclusion": "CPMamba\u901a\u8fc7\u9009\u62e9\u6027\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u6709\u6548\u89e3\u51b3\u4e86\u9ad8\u79fb\u52a8\u6027\u573a\u666f\u4e0b\u7684\u4fe1\u9053\u9884\u6d4b\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5b9e\u9645\u90e8\u7f72\u7684\u95e8\u69db\uff0c\u4e3aMIMO-OFDM\u7cfb\u7edf\u4e2d\u7684\u9884\u7f16\u7801\u3001\u81ea\u9002\u5e94\u8c03\u5236\u548c\u8d44\u6e90\u5206\u914d\u7b49\u529f\u80fd\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u4fe1\u9053\u9884\u6d4b\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.16420", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.16420", "abs": "https://arxiv.org/abs/2512.16420", "authors": ["Daniel Rika", "Nino Sapir", "Ido Gus"], "title": "DPDFNet: Boosting DeepFilterNet2 via Dual-Path RNN", "comment": null, "summary": "We present DPDFNet, a causal single-channel speech enhancement model that extends DeepFilterNet2 architecture with dual-path blocks in the encoder, strengthening long-range temporal and cross-band modeling while preserving the original enhancement framework. In addition, we demonstrate that adding a loss component to mitigate over-attenuation in the enhanced speech, combined with a fine-tuning phase tailored for \"always-on\" applications, leads to substantial improvements in overall model performance. To compare our proposed architecture with a variety of causal open-source models, we created a new evaluation set comprising long, low-SNR recordings in 12 languages across everyday noise scenarios, better reflecting real-world conditions than commonly used benchmarks. On this evaluation set, DPDFNet delivers superior performance to other causal open-source models, including some that are substantially larger and more computationally demanding. We also propose an holistic metric named PRISM, a composite, scale-normalized aggregate of intrusive and non-intrusive metrics, which demonstrates clear scalability with the number of dual-path blocks. We further demonstrate on-device feasibility by deploying DPDFNet on Ceva-NeuPro-Nano edge NPUs. Results indicate that DPDFNet-4, our second-largest model, achieves real-time performance on NPN32 and runs even faster on NPN64, confirming that state-of-the-art quality can be sustained within strict embedded power and latency constraints.", "AI": {"tldr": "DPDFNet\uff1a\u57fa\u4e8eDeepFilterNet2\u67b6\u6784\u7684\u56e0\u679c\u5355\u901a\u9053\u8bed\u97f3\u589e\u5f3a\u6a21\u578b\uff0c\u901a\u8fc7\u53cc\u8def\u5f84\u5757\u589e\u5f3a\u957f\u65f6\u5efa\u6a21\uff0c\u7ed3\u5408\u6297\u8fc7\u8870\u51cf\u635f\u5931\u548c\u5fae\u8c03\u7b56\u7565\uff0c\u5728\u771f\u5b9e\u573a\u666f\u8bc4\u4f30\u4e2d\u4f18\u4e8e\u5176\u4ed6\u5f00\u6e90\u6a21\u578b\uff0c\u5e76\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u8fd0\u884c\u3002", "motivation": "\u73b0\u6709\u56e0\u679c\u8bed\u97f3\u589e\u5f3a\u6a21\u578b\u5728\u957f\u65f6\u5efa\u6a21\u548c\u771f\u5b9e\u573a\u666f\u9002\u5e94\u6027\u65b9\u9762\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u5f00\u53d1\u65e2\u80fd\u4fdd\u6301\u9ad8\u8d28\u91cf\u589e\u5f3a\u6548\u679c\uff0c\u53c8\u80fd\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u5b9e\u65f6\u8fd0\u884c\u7684\u9ad8\u6548\u6a21\u578b\u3002", "method": "1. \u5728DeepFilterNet2\u7f16\u7801\u5668\u4e2d\u5f15\u5165\u53cc\u8def\u5f84\u5757\uff0c\u589e\u5f3a\u957f\u65f6\u65f6\u95f4\u5efa\u6a21\u548c\u8de8\u9891\u5e26\u5efa\u6a21\uff1b2. \u6dfb\u52a0\u6297\u8fc7\u8870\u51cf\u635f\u5931\u7ec4\u4ef6\uff1b3. \u9488\u5bf9\"always-on\"\u5e94\u7528\u8fdb\u884c\u5fae\u8c03\uff1b4. \u521b\u5efa\u5305\u542b12\u79cd\u8bed\u8a00\u3001\u4f4e\u4fe1\u566a\u6bd4\u771f\u5b9e\u573a\u666f\u7684\u65b0\u8bc4\u4f30\u96c6\uff1b5. \u63d0\u51faPRISM\u7efc\u5408\u8bc4\u4f30\u6307\u6807\uff1b6. \u5728Ceva-NeuPro-Nano\u8fb9\u7f18NPU\u4e0a\u90e8\u7f72\u9a8c\u8bc1\u3002", "result": "1. DPDFNet\u5728\u65b0\u5efa\u7684\u771f\u5b9e\u573a\u666f\u8bc4\u4f30\u96c6\u4e0a\u4f18\u4e8e\u5176\u4ed6\u56e0\u679c\u5f00\u6e90\u6a21\u578b\uff0c\u5305\u62ec\u4e00\u4e9b\u66f4\u5927\u66f4\u590d\u6742\u7684\u6a21\u578b\uff1b2. PRISM\u6307\u6807\u663e\u793a\u6027\u80fd\u968f\u53cc\u8def\u5f84\u5757\u6570\u91cf\u589e\u52a0\u800c\u63d0\u5347\uff1b3. DPDFNet-4\u5728NPN32\u4e0a\u5b9e\u73b0\u5b9e\u65f6\u6027\u80fd\uff0c\u5728NPN64\u4e0a\u8fd0\u884c\u66f4\u5feb\uff0c\u8bc1\u660e\u5728\u5d4c\u5165\u5f0f\u8bbe\u5907\u4e0a\u4fdd\u6301SOTA\u8d28\u91cf\u7684\u53ef\u884c\u6027\u3002", "conclusion": "DPDFNet\u901a\u8fc7\u53cc\u8def\u5f84\u5757\u67b6\u6784\u3001\u6297\u8fc7\u8870\u51cf\u635f\u5931\u548c\u9488\u5bf9\u6027\u5fae\u8c03\uff0c\u5b9e\u73b0\u4e86\u5728\u771f\u5b9e\u573a\u666f\u4e2d\u4f18\u8d8a\u7684\u8bed\u97f3\u589e\u5f3a\u6027\u80fd\uff0c\u540c\u65f6\u5728\u8fb9\u7f18\u8bbe\u5907\u4e0a\u4fdd\u6301\u5b9e\u65f6\u8fd0\u884c\u80fd\u529b\uff0c\u4e3a\u5d4c\u5165\u5f0f\u8bed\u97f3\u589e\u5f3a\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.16432", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.16432", "abs": "https://arxiv.org/abs/2512.16432", "authors": ["Nils Foix-Colonier", "S\u00e9bastien Bourguignon"], "title": "An active-set algorithm for spectral unmixing", "comment": null, "summary": "Linear spectral unmixing under nonnegativity and sum-to-one constraints is a convex optimization problem for which many algorithms were proposed. In practice, especially for supervised unmixing (i.e., with a large dictionary), solutions tend to be sparse due to the nonnegativity of the abundances, thereby motivating the use of an active-set solver. Given the problem specific features, it seems advantageous to design a dedicated algorithm in order to gain computational performance compared to generic solvers. In this paper, we propose to derive such a specific algorithm, while extending the nonnegativity constraints to broader minimum abundance constraints.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u7ebf\u6027\u5149\u8c31\u89e3\u6df7\u95ee\u9898\u7684\u4e13\u7528\u7b97\u6cd5\uff0c\u7279\u522b\u9002\u7528\u4e8e\u76d1\u7763\u89e3\u6df7\uff08\u5927\u5b57\u5178\u60c5\u51b5\uff09\uff0c\u901a\u8fc7\u4e3b\u52a8\u96c6\u65b9\u6cd5\u5904\u7406\u7a00\u758f\u6027\uff0c\u5e76\u6269\u5c55\u975e\u8d1f\u7ea6\u675f\u4e3a\u66f4\u5e7f\u6cdb\u7684\u4e30\u5ea6\u6700\u5c0f\u7ea6\u675f\u3002", "motivation": "\u7ebf\u6027\u5149\u8c31\u89e3\u6df7\u5728\u975e\u8d1f\u548c\u548c\u4e3a1\u7ea6\u675f\u4e0b\u662f\u51f8\u4f18\u5316\u95ee\u9898\uff0c\u5df2\u6709\u8bb8\u591a\u7b97\u6cd5\u3002\u4f46\u5728\u5b9e\u8df5\u4e2d\uff0c\u7279\u522b\u662f\u76d1\u7763\u89e3\u6df7\uff08\u5927\u5b57\u5178\uff09\u65f6\uff0c\u7531\u4e8e\u4e30\u5ea6\u7684\u975e\u8d1f\u6027\uff0c\u89e3\u5f80\u5f80\u7a00\u758f\uff0c\u8fd9\u4fc3\u4f7f\u4f7f\u7528\u4e3b\u52a8\u96c6\u6c42\u89e3\u5668\u3002\u9274\u4e8e\u95ee\u9898\u7279\u5b9a\u7279\u5f81\uff0c\u8bbe\u8ba1\u4e13\u7528\u7b97\u6cd5\u76f8\u6bd4\u901a\u7528\u6c42\u89e3\u5668\u53ef\u83b7\u5f97\u66f4\u597d\u7684\u8ba1\u7b97\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u4e13\u7528\u7b97\u6cd5\uff0c\u57fa\u4e8e\u4e3b\u52a8\u96c6\u65b9\u6cd5\u5904\u7406\u7a00\u758f\u6027\uff0c\u5e76\u5c06\u975e\u8d1f\u7ea6\u675f\u6269\u5c55\u4e3a\u66f4\u5e7f\u6cdb\u7684\u4e30\u5ea6\u6700\u5c0f\u7ea6\u675f\u3002", "result": "\u672a\u5728\u6458\u8981\u4e2d\u660e\u786e\u8bf4\u660e\u5177\u4f53\u7ed3\u679c\uff0c\u4f46\u6697\u793a\u8be5\u7b97\u6cd5\u76f8\u6bd4\u901a\u7528\u6c42\u89e3\u5668\u5177\u6709\u8ba1\u7b97\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "\u9488\u5bf9\u7ebf\u6027\u5149\u8c31\u89e3\u6df7\u95ee\u9898\u8bbe\u8ba1\u4e13\u7528\u7b97\u6cd5\u662f\u53ef\u884c\u7684\uff0c\u901a\u8fc7\u4e3b\u52a8\u96c6\u65b9\u6cd5\u5904\u7406\u7a00\u758f\u6027\u5e76\u6269\u5c55\u7ea6\u675f\u6761\u4ef6\uff0c\u53ef\u63d0\u9ad8\u8ba1\u7b97\u6027\u80fd\u3002"}}
{"id": "2512.16496", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.16496", "abs": "https://arxiv.org/abs/2512.16496", "authors": ["Mauro Marchese", "Pietro Savazzi"], "title": "Robust 6G OFDM High-Mobility Communications Using Delay-Doppler Superimposed Pilots", "comment": "Submitted", "summary": "In this work, a novel receiver architecture for orthogonal frequency division multiplexing (OFDM) communications in 6G high-mobility scenarios is developed. In particular, a delay-Doppler superimposed pilot (SP) scheme is used for channel estimation (CE) by adding a single pilot in the delay-Doppler domain. Unlike previous research on delay-Doppler superimposed pilots in OFDM systems, intercarrier interference (ICI) effects, fractional delays, and Doppler shifts are considered. Consequently, a disjoint fractional delay-Doppler estimation algorithm is derived, and a reduced-complexity equalization method based on the Landweber iteration, which exploits intrinsic channel structure, is proposed. Simulation results reveal that the proposed receiver architecture achieves robust communication performance across various mobility conditions, with speeds of up to 1000 km/h, and increases the effective throughput compared to existing methods.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e6G\u9ad8\u901f\u79fb\u52a8\u573a\u666f\u7684OFDM\u63a5\u6536\u673a\u67b6\u6784\uff0c\u91c7\u7528\u5ef6\u8fdf-\u591a\u666e\u52d2\u53e0\u52a0\u5bfc\u9891\u65b9\u6848\u8fdb\u884c\u4fe1\u9053\u4f30\u8ba1\uff0c\u8003\u8651ICI\u3001\u5206\u6570\u5ef6\u8fdf\u548c\u591a\u666e\u52d2\u9891\u79fb\uff0c\u5b9e\u73b0\u9ad8\u8fbe1000km/h\u7684\u9c81\u68d2\u901a\u4fe1\u6027\u80fd\u3002", "motivation": "6G\u9ad8\u901f\u79fb\u52a8\u573a\u666f\uff08\u5982\u9ad8\u94c1\u3001\u65e0\u4eba\u673a\uff09\u5bf9OFDM\u7cfb\u7edf\u63d0\u51fa\u6311\u6218\uff0c\u4f20\u7edf\u4fe1\u9053\u4f30\u8ba1\u65b9\u6cd5\u5728\u9ad8\u901f\u79fb\u52a8\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u5904\u7406\u5206\u6570\u5ef6\u8fdf\u3001\u591a\u666e\u52d2\u9891\u79fb\u548cICI\u7684\u9c81\u68d2\u63a5\u6536\u673a\u67b6\u6784\u3002", "method": "1) \u91c7\u7528\u5ef6\u8fdf-\u591a\u666e\u52d2\u53e0\u52a0\u5bfc\u9891\u65b9\u6848\uff0c\u5728\u5ef6\u8fdf-\u591a\u666e\u52d2\u57df\u6dfb\u52a0\u5355\u4e2a\u5bfc\u9891\uff1b2) \u63a8\u5bfc\u5206\u79bb\u5f0f\u5206\u6570\u5ef6\u8fdf-\u591a\u666e\u52d2\u4f30\u8ba1\u7b97\u6cd5\uff1b3) \u63d0\u51fa\u57fa\u4e8eLandweber\u8fed\u4ee3\u7684\u4f4e\u590d\u6742\u5ea6\u5747\u8861\u65b9\u6cd5\uff0c\u5229\u7528\u4fe1\u9053\u56fa\u6709\u7ed3\u6784\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u63a5\u6536\u673a\u67b6\u6784\u5728\u5404\u79cd\u79fb\u52a8\u6761\u4ef6\u4e0b\uff08\u901f\u5ea6\u9ad8\u8fbe1000km/h\uff09\u5b9e\u73b0\u9c81\u68d2\u901a\u4fe1\u6027\u80fd\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u4e86\u6709\u6548\u541e\u5410\u91cf\u3002", "conclusion": "\u63d0\u51fa\u7684\u63a5\u6536\u673a\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e866G\u9ad8\u901f\u79fb\u52a8\u573a\u666f\u4e0b\u7684OFDM\u901a\u4fe1\u6311\u6218\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u5bfc\u9891\u8bbe\u8ba1\u548c\u4f30\u8ba1\u7b97\u6cd5\uff0c\u5b9e\u73b0\u4e86\u9ad8\u901f\u79fb\u52a8\u73af\u5883\u4e0b\u7684\u53ef\u9760\u901a\u4fe1\u548c\u541e\u5410\u91cf\u63d0\u5347\u3002"}}
{"id": "2512.16543", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.16543", "abs": "https://arxiv.org/abs/2512.16543", "authors": ["Mohammad Momani", "Thomas Delamotte", "Andreas Knopp"], "title": "Efficient Precoding for LEO Satellites: A Low-Complexity Matrix Inversion Method via Woodbury Matrix Identity and arSVD", "comment": null, "summary": "The increasing deployment of massive active antenna arrays in low Earth orbit (LEO) satellites necessitates computationally efficient and adaptive precoding techniques to mitigate dynamic channel variations and enhance spectral efficiency. Regularized zero-forcing (RZF) precoding is widely used in multi-user MIMO systems; however, its real-time implementation is limited by the computationally intensive inversion of the Gram matrix. In this work, we develop a low-complexity framework that integrates the Woodbury (WB) formula with adaptive randomized singular value decomposition (arSVD) to efficiently update the Gram matrix inverse as the satellite moves along its orbit. By leveraging low-rank perturbations, the WB formula reduces inversion complexity, while arSVD dynamically extracts dominant singular components, further enhancing computational efficiency. Monte Carlo simulations demonstrate that the proposed method achieves computational savings of up to 61\\% compared to conventional RZF precoding with full matrix inversion, while incurring only a modest degradation in sum-rate performance. These results demonstrate that WB-arSVD offers a scalable and efficient solution for next-generation satellite communications, facilitating real-time deployment in power-constrained environments.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408Woodbury\u516c\u5f0f\u4e0e\u81ea\u9002\u5e94\u968f\u673a\u5947\u5f02\u503c\u5206\u89e3\u7684\u4f4e\u590d\u6742\u5ea6\u9884\u7f16\u7801\u6846\u67b6\uff0c\u7528\u4e8eLEO\u536b\u661f\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\uff0c\u76f8\u6bd4\u4f20\u7edfRZF\u9884\u7f16\u7801\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e61%\uff0c\u4ec5\u5e26\u6765\u8f7b\u5fae\u7684\u548c\u901f\u7387\u6027\u80fd\u635f\u5931\u3002", "motivation": "\u4f4e\u5730\u7403\u8f68\u9053\u536b\u661f\u5927\u89c4\u6a21\u6709\u6e90\u5929\u7ebf\u9635\u5217\u7684\u90e8\u7f72\u9700\u8981\u8ba1\u7b97\u9ad8\u6548\u4e14\u81ea\u9002\u5e94\u7684\u9884\u7f16\u7801\u6280\u672f\uff0c\u4ee5\u5e94\u5bf9\u52a8\u6001\u4fe1\u9053\u53d8\u5316\u5e76\u63d0\u9ad8\u9891\u8c31\u6548\u7387\u3002\u4f20\u7edf\u6b63\u5219\u5316\u8feb\u96f6\u9884\u7f16\u7801\u7684\u5b9e\u65f6\u5b9e\u73b0\u53d7\u9650\u4e8eGram\u77e9\u9635\u6c42\u9006\u7684\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "method": "\u63d0\u51faWB-arSVD\u6846\u67b6\uff1a\u7ed3\u5408Woodbury\u516c\u5f0f\u5904\u7406\u4f4e\u79e9\u6270\u52a8\u4ee5\u964d\u4f4e\u6c42\u9006\u590d\u6742\u5ea6\uff0c\u540c\u65f6\u4f7f\u7528\u81ea\u9002\u5e94\u968f\u673a\u5947\u5f02\u503c\u5206\u89e3\u52a8\u6001\u63d0\u53d6\u4e3b\u5bfc\u5947\u5f02\u5206\u91cf\uff0c\u8fdb\u4e00\u6b65\u4f18\u5316\u8ba1\u7b97\u6548\u7387\u3002", "result": "\u8499\u7279\u5361\u6d1b\u4eff\u771f\u8868\u660e\uff0c\u76f8\u6bd4\u4f20\u7edfRZF\u9884\u7f16\u7801\u7684\u5b8c\u6574\u77e9\u9635\u6c42\u9006\uff0c\u6240\u63d0\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u964d\u4f4e\u9ad8\u8fbe61%\uff0c\u4ec5\u5e26\u6765\u548c\u901f\u7387\u6027\u80fd\u7684\u8f7b\u5fae\u4e0b\u964d\u3002", "conclusion": "WB-arSVD\u4e3a\u4e0b\u4e00\u4ee3\u536b\u661f\u901a\u4fe1\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7279\u522b\u9002\u7528\u4e8e\u529f\u7387\u53d7\u9650\u73af\u5883\u4e2d\u7684\u5b9e\u65f6\u90e8\u7f72\u3002"}}
{"id": "2512.16719", "categories": ["eess.SP", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.16719", "abs": "https://arxiv.org/abs/2512.16719", "authors": ["Atsu Kokuvi Angelo Passah", "Rodrigo C. de Lamare", "Arsenia Chorti"], "title": "Channel State Information Preprocessing for CSI-based Physical-Layer Authentication Using Reconciliation", "comment": null, "summary": "This paper introduces an adaptive preprocessing technique to enhance the accuracy of channel state information-based physical layer authentication (CSI-PLA) alleviating CSI variations and inconsistencies in the time domain. To this end, we develop an adaptive robust principal component analysis (A-RPCA) preprocessing method based on robust principal component analysis (RPCA). The performance evaluation is then conducted using a PLA framework based on information reconciliation, in which Gaussian approximation (GA) for Polar codes is leveraged for the design of short codelength Slepian Wolf decoders. Furthermore, an analysis of the proposed A-RPCA methods is carried out. Simulation results show that compared to a baseline scheme without preprocessing and without reconciliation, the proposed A-RPCA method substantially reduces the error probability after reconciliation and also substantially increases the detection probabilities that is also 1 in both line-of-sight (LOS) and non-line-of-sight (NLOS) scenarios. We have compared against state-of the-art preprocessing schemes in both synthetic and real datasets, including principal component analysis (PCA) and robust PCA, autoencoders and the recursive projected compressive sensing (ReProCS) framework and we have validated the superior performance of the proposed approach.", "AI": {"tldr": "\u63d0\u51fa\u81ea\u9002\u5e94\u9c81\u68d2\u4e3b\u6210\u5206\u5206\u6790(A-RPCA)\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u7528\u4e8e\u589e\u5f3a\u57fa\u4e8e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u7684\u7269\u7406\u5c42\u8ba4\u8bc1(CSI-PLA)\u7684\u51c6\u786e\u6027\uff0c\u901a\u8fc7\u51cf\u8f7bCSI\u65f6\u57df\u53d8\u5316\u548c\u4e0d\u4e00\u81f4\u6027\uff0c\u7ed3\u5408\u4fe1\u606f\u534f\u8c03\u6846\u67b6\u663e\u8457\u964d\u4f4e\u9519\u8bef\u6982\u7387\u3002", "motivation": "\u73b0\u6709\u7684\u57fa\u4e8e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f(CSI)\u7684\u7269\u7406\u5c42\u8ba4\u8bc1(PLA)\u9762\u4e34CSI\u5728\u65f6\u57df\u4e0a\u7684\u53d8\u5316\u548c\u4e0d\u4e00\u81f4\u6027\u95ee\u9898\uff0c\u8fd9\u5f71\u54cd\u4e86\u8ba4\u8bc1\u7684\u51c6\u786e\u6027\u3002\u9700\u8981\u4e00\u79cd\u6709\u6548\u7684\u9884\u5904\u7406\u65b9\u6cd5\u6765\u51cf\u8f7b\u8fd9\u4e9bCSI\u53d8\u5316\uff0c\u63d0\u9ad8\u8ba4\u8bc1\u7cfb\u7edf\u7684\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u81ea\u9002\u5e94\u9c81\u68d2\u4e3b\u6210\u5206\u5206\u6790(A-RPCA)\u9884\u5904\u7406\u65b9\u6cd5\uff0c\u57fa\u4e8e\u9c81\u68d2\u4e3b\u6210\u5206\u5206\u6790(RPCA)\u6539\u8fdb\u3002\u7ed3\u5408\u57fa\u4e8e\u4fe1\u606f\u534f\u8c03\u7684PLA\u6846\u67b6\uff0c\u5229\u7528Polar\u7801\u7684\u9ad8\u65af\u8fd1\u4f3c(GA)\u8bbe\u8ba1\u77ed\u7801\u957fSlepian Wolf\u89e3\u7801\u5668\u3002\u5bf9\u63d0\u51fa\u7684A-RPCA\u65b9\u6cd5\u8fdb\u884c\u4e86\u7406\u8bba\u5206\u6790\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u4e0e\u6ca1\u6709\u9884\u5904\u7406\u548c\u534f\u8c03\u7684\u57fa\u7ebf\u65b9\u6848\u76f8\u6bd4\uff0cA-RPCA\u65b9\u6cd5\u663e\u8457\u964d\u4f4e\u4e86\u534f\u8c03\u540e\u7684\u9519\u8bef\u6982\u7387\uff0c\u5e76\u5c06\u68c0\u6d4b\u6982\u7387\u63d0\u9ad8\u52301\uff08\u5728LOS\u548cNLOS\u573a\u666f\u4e0b\uff09\u3002\u5728\u5408\u6210\u548c\u771f\u5b9e\u6570\u636e\u96c6\u4e0a\uff0c\u76f8\u6bd4PCA\u3001\u9c81\u68d2PCA\u3001\u81ea\u7f16\u7801\u5668\u548cReProCS\u7b49\u5148\u8fdb\u9884\u5904\u7406\u65b9\u6848\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u65b9\u6cd5\u7684\u4f18\u8d8a\u6027\u80fd\u3002", "conclusion": "\u81ea\u9002\u5e94\u9c81\u68d2\u4e3b\u6210\u5206\u5206\u6790(A-RPCA)\u9884\u5904\u7406\u65b9\u6cd5\u80fd\u6709\u6548\u51cf\u8f7bCSI\u65f6\u57df\u53d8\u5316\u548c\u4e0d\u4e00\u81f4\u6027\uff0c\u663e\u8457\u63d0\u9ad8\u7269\u7406\u5c42\u8ba4\u8bc1\u7cfb\u7edf\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u5728\u591a\u79cd\u573a\u666f\u4e0b\u90fd\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2512.16735", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.16735", "abs": "https://arxiv.org/abs/2512.16735", "authors": ["Sotiris Skaperas", "Arsenia Chorti"], "title": "Misspecified Crame-Rao Bound for AoA Estimation at a ULA under a Spoofing Attack", "comment": null, "summary": "A framework is presented for analyzing the impact of active attacks to location-based physical layer authentication (PLA) using the machinery of misspecified Cram\u00e9r--Rao bound (MCRB). In this work, we focus on the MCRB in the angle-of-arrival (AoA) based authentication of a single antenna user when the verifier posseses an $M$ antenna element uniform linear array (ULA), assuming deterministic pilot signals; in our system model the presence of a spoofing adversary with an arbitrary number $L$ of antenna elements is assumed. We obtain a closed-form expression for the MCRB and demonstrate that the attack introduces in it a penalty term compared to the classic CRB, which does not depend on the signal-to-noise ratio (SNR) but on the adversary's location, the array geometry and the attacker precoding vector.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u8bef\u8bbeCram\u00e9r-Rao\u754c(MCRB)\u7684\u6846\u67b6\uff0c\u5206\u6790\u4e3b\u52a8\u653b\u51fb\u5bf9\u57fa\u4e8e\u5230\u8fbe\u89d2(AoA)\u7684\u7269\u7406\u5c42\u8ba4\u8bc1\u7684\u5f71\u54cd\uff0c\u63a8\u5bfc\u95ed\u5f0f\u8868\u8fbe\u5f0f\u5e76\u63ed\u793a\u653b\u51fb\u5f15\u5165\u7684\u60e9\u7f5a\u9879\u7279\u6027\u3002", "motivation": "\u7814\u7a76\u4e3b\u52a8\u653b\u51fb\u5bf9\u57fa\u4e8e\u5230\u8fbe\u89d2\u7684\u7269\u7406\u5c42\u8ba4\u8bc1\u7cfb\u7edf\u7684\u5f71\u54cd\uff0c\u4f20\u7edfCRB\u65e0\u6cd5\u51c6\u786e\u8bc4\u4f30\u653b\u51fb\u573a\u666f\u4e0b\u7684\u6027\u80fd\u754c\u9650\uff0c\u9700\u8981\u5f00\u53d1\u8003\u8651\u653b\u51fb\u8005\u5b58\u5728\u7684\u7406\u8bba\u5206\u6790\u6846\u67b6\u3002", "method": "\u4f7f\u7528\u8bef\u8bbeCram\u00e9r-Rao\u754c(MCRB)\u7406\u8bba\u6846\u67b6\uff0c\u5206\u6790\u5355\u5929\u7ebf\u7528\u6237\u5728M\u5929\u7ebfULA\u9a8c\u8bc1\u5668\u4e0b\u7684AoA\u8ba4\u8bc1\uff0c\u8003\u8651\u5177\u6709L\u5929\u7ebf\u5143\u7d20\u7684\u6b3a\u9a97\u653b\u51fb\u8005\uff0c\u5047\u8bbe\u786e\u5b9a\u6027\u5bfc\u9891\u4fe1\u53f7\u3002", "result": "\u83b7\u5f97\u4e86MCRB\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u53d1\u73b0\u653b\u51fb\u5f15\u5165\u7684\u60e9\u7f5a\u9879\u4e0e\u4fe1\u566a\u6bd4\u65e0\u5173\uff0c\u800c\u662f\u53d6\u51b3\u4e8e\u653b\u51fb\u8005\u4f4d\u7f6e\u3001\u9635\u5217\u51e0\u4f55\u7ed3\u6784\u548c\u653b\u51fb\u8005\u9884\u7f16\u7801\u5411\u91cf\u3002", "conclusion": "MCRB\u6846\u67b6\u6709\u6548\u91cf\u5316\u4e86\u4e3b\u52a8\u653b\u51fb\u5bf9\u7269\u7406\u5c42\u8ba4\u8bc1\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u63ed\u793a\u4e86\u653b\u51fb\u5f15\u5165\u7684\u60e9\u7f5a\u9879\u7279\u6027\uff0c\u4e3a\u5b89\u5168\u8ba4\u8bc1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2512.16786", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.16786", "abs": "https://arxiv.org/abs/2512.16786", "authors": ["Chenyu Zhu", "Zeyang Li", "Ziyi Xie", "Jie Zhang"], "title": "Few-Shot Specific Emitter Identification via Integrated Complex Variational Mode Decomposition and Spatial Attention Transfer", "comment": "14 pages, 12 Figures, 5 Table", "summary": "Specific emitter identification (SEI) utilizes passive hardware characteristics to authenticate transmitters, providing a robust physical-layer security solution. However, most deep-learning-based methods rely on extensive data or require prior information, which poses challenges in real-world scenarios with limited labeled data. We propose an integrated complex variational mode decomposition algorithm that decomposes and reconstructs complex-valued signals to approximate the original transmitted signals, thereby enabling more accurate feature extraction. We further utilize a temporal convolutional network to effectively model the sequential signal characteristics, and introduce a spatial attention mechanism to adaptively weight informative signal segments, significantly enhancing identification performance. Additionally, the branch network allows leveraging pre-trained weights from other data while reducing the need for auxiliary datasets. Ablation experiments on the simulated data demonstrate the effectiveness of each component of the model. An accuracy comparison on a public dataset reveals that our method achieves 96% accuracy using only 10 symbols without requiring any prior knowledge.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u96c6\u6210\u590d\u6570\u53d8\u5206\u6a21\u6001\u5206\u89e3\u548c\u65f6\u7a7a\u6ce8\u610f\u529b\u673a\u5236\u7684\u7279\u5b9a\u53d1\u5c04\u673a\u8bc6\u522b\u65b9\u6cd5\uff0c\u5728\u5c11\u91cf\u7b26\u53f7\u6570\u636e\u4e0b\u5b9e\u73b096%\u7684\u51c6\u786e\u7387", "motivation": "\u73b0\u6709\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684SEI\u65b9\u6cd5\u4f9d\u8d56\u5927\u91cf\u6570\u636e\u6216\u5148\u9a8c\u4fe1\u606f\uff0c\u5728\u5b9e\u9645\u573a\u666f\u4e2d\u6807\u8bb0\u6570\u636e\u6709\u9650\u7684\u60c5\u51b5\u4e0b\u9762\u4e34\u6311\u6218", "method": "1) \u96c6\u6210\u590d\u6570\u53d8\u5206\u6a21\u6001\u5206\u89e3\u7b97\u6cd5\u5206\u89e3\u548c\u91cd\u6784\u590d\u503c\u4fe1\u53f7\uff1b2) \u4f7f\u7528\u65f6\u5e8f\u5377\u79ef\u7f51\u7edc\u5efa\u6a21\u5e8f\u5217\u7279\u5f81\uff1b3) \u5f15\u5165\u7a7a\u95f4\u6ce8\u610f\u529b\u673a\u5236\u81ea\u9002\u5e94\u52a0\u6743\u4fe1\u606f\u4e30\u5bcc\u7684\u4fe1\u53f7\u6bb5\uff1b4) \u5206\u652f\u7f51\u7edc\u5229\u7528\u9884\u8bad\u7ec3\u6743\u91cd\u51cf\u5c11\u8f85\u52a9\u6570\u636e\u9700\u6c42", "result": "\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u4ec5\u4f7f\u752810\u4e2a\u7b26\u53f7\u4e14\u65e0\u9700\u5148\u9a8c\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\u8fbe\u523096%\u7684\u51c6\u786e\u7387\uff0c\u6d88\u878d\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u5404\u6a21\u5757\u7684\u6709\u6548\u6027", "conclusion": "\u8be5\u65b9\u6cd5\u5728\u6709\u9650\u6807\u8bb0\u6570\u636e\u573a\u666f\u4e0b\u5b9e\u73b0\u4e86\u9ad8\u6027\u80fd\u7684\u7279\u5b9a\u53d1\u5c04\u673a\u8bc6\u522b\uff0c\u4e3a\u7269\u7406\u5c42\u5b89\u5168\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848"}}

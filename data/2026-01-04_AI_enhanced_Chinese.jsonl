{"id": "2512.23725", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.23725", "abs": "https://arxiv.org/abs/2512.23725", "authors": ["Sel Ly", "Rufan Yang", "Ninad Dixit", "Hung Dinh Nguyen"], "title": "RUL-QMoE: Multiple Non-crossing Quantile Mixture-of-Experts for Probabilistic Remaining Useful Life Predictions of Varying Battery Materials", "comment": "This is an extended version of the conference paper at the 38th Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-26)", "summary": "Lithium-ion batteries are the major type of battery used in a variety of everyday applications, including electric vehicles (EVs), mobile devices, and energy storage systems. Predicting the Remaining Useful Life (RUL) of Li-ion batteries is crucial for ensuring their reliability, safety, and cost-effectiveness in battery-powered systems. The materials used for the battery cathodes and their designs play a significant role in determining the degradation rates and RUL, as they lead to distinct electrochemical reactions. Unfortunately, RUL prediction models often overlook the cathode materials and designs to simplify the model-building process, ignoring the effects of these electrochemical reactions. Other reasons are that specifications related to battery materials may not always be readily available, and a battery might consist of a mix of different materials. As a result, the predictive models that are developed often lack generalizability. To tackle these challenges, this paper proposes a novel material-based Mixture-of-Experts (MoE) approach for predicting the RUL of batteries, specifically addressing the complexities associated with heterogeneous battery chemistries. The MoE is integrated into a probabilistic framework, called Multiple Non-crossing Quantile Mixture-of-Experts for Probabilistic Prediction (RUL-QMoE), which accommodates battery operational conditions and enables uncertainty quantification. The RUL-QMoE model integrates specialized expert networks for five battery types: LFP, NCA, NMC, LCO, and NMC-LCO, within a gating mechanism that dynamically assigns relevance based on the battery's input features. Furthermore, by leveraging non-crossing quantile regression, the proposed RUL-QMoE produces coherent and interpretable predictive distributions of the battery's RUL, enabling robust uncertainty quantification in the battery's RUL prediction.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6750\u6599\u7684\u6df7\u5408\u4e13\u5bb6\u6a21\u578bRUL-QMoE\uff0c\u7528\u4e8e\u9884\u6d4b\u9502\u79bb\u5b50\u7535\u6c60\u5269\u4f59\u4f7f\u7528\u5bff\u547d\uff0c\u7279\u522b\u9488\u5bf9\u4e0d\u540c\u9634\u6781\u6750\u6599\u7684\u5f02\u8d28\u7535\u6c60\u5316\u5b66\u7279\u6027\uff0c\u5b9e\u73b0\u6982\u7387\u9884\u6d4b\u548c\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\u3002", "motivation": "\u73b0\u6709RUL\u9884\u6d4b\u6a21\u578b\u901a\u5e38\u5ffd\u7565\u7535\u6c60\u9634\u6781\u6750\u6599\u548c\u8bbe\u8ba1\u7684\u5f71\u54cd\uff0c\u5bfc\u81f4\u6a21\u578b\u7f3a\u4e4f\u6cdb\u5316\u80fd\u529b\u3002\u7535\u6c60\u6750\u6599\u89c4\u683c\u53ef\u80fd\u4e0d\u6613\u83b7\u53d6\uff0c\u4e14\u7535\u6c60\u53ef\u80fd\u5305\u542b\u591a\u79cd\u6750\u6599\u6df7\u5408\uff0c\u9700\u8981\u89e3\u51b3\u5f02\u8d28\u7535\u6c60\u5316\u5b66\u7279\u6027\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faRUL-QMoE\u6a21\u578b\uff0c\u5c06\u6df7\u5408\u4e13\u5bb6\u6846\u67b6\u96c6\u6210\u5230\u6982\u7387\u9884\u6d4b\u4e2d\uff0c\u5305\u542b\u4e94\u4e2a\u7535\u6c60\u7c7b\u578b\u7684\u4e13\u5bb6\u7f51\u7edc\uff08LFP\u3001NCA\u3001NMC\u3001LCO\u3001NMC-LCO\uff09\uff0c\u901a\u8fc7\u95e8\u63a7\u673a\u5236\u52a8\u6001\u5206\u914d\u6743\u91cd\uff0c\u5e76\u5229\u7528\u975e\u4ea4\u53c9\u5206\u4f4d\u6570\u56de\u5f52\u4ea7\u751f\u8fde\u8d2f\u7684\u9884\u6d4b\u5206\u5e03\u3002", "result": "RUL-QMoE\u6a21\u578b\u80fd\u591f\u5904\u7406\u5f02\u8d28\u7535\u6c60\u5316\u5b66\u7279\u6027\uff0c\u8003\u8651\u7535\u6c60\u8fd0\u884c\u6761\u4ef6\uff0c\u5b9e\u73b0\u4e0d\u786e\u5b9a\u6027\u91cf\u5316\uff0c\u4ea7\u751f\u8fde\u8d2f\u4e14\u53ef\u89e3\u91ca\u7684RUL\u9884\u6d4b\u5206\u5e03\u3002", "conclusion": "\u63d0\u51fa\u7684\u57fa\u4e8e\u6750\u6599\u7684\u6df7\u5408\u4e13\u5bb6\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u7535\u6c60RUL\u9884\u6d4b\u4e2d\u6750\u6599\u5f02\u8d28\u6027\u7684\u6311\u6218\uff0c\u901a\u8fc7\u6982\u7387\u6846\u67b6\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u3001\u53ef\u89e3\u91ca\u4e14\u5177\u6709\u6cdb\u5316\u80fd\u529b\u7684\u9884\u6d4b\u6a21\u578b\u3002"}}
{"id": "2512.23902", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.23902", "abs": "https://arxiv.org/abs/2512.23902", "authors": ["Hesam Khoshkbari", "Georges Kaddoum", "Omid Abbasi", "Bassant Selim", "Halim Yanikomeroglu"], "title": "Beamforming for Massive MIMO Aerial Communications: A Robust and Scalable DRL Approach", "comment": null, "summary": "This paper presents a distributed beamforming framework for a constellation of airborne platform stations (APSs) in a massive Multiple-Input and Multiple-Output (MIMO) non-terrestrial network (NTN) that targets the downlink sum-rate maximization under imperfect local channel state information (CSI). We propose a novel entropy-based multi-agent deep reinforcement learning (DRL) approach where each non-terrestrial base station (NTBS) independently computes its beamforming vector using a Fourier Neural Operator (FNO) to capture long-range dependencies in the frequency domain. To ensure scalability and robustness, the proposed framework integrates transfer learning based on a conjugate prior mechanism and a low-rank decomposition (LRD) technique, thus enabling efficient support for large-scale user deployments and aerial layers. Our simulation results demonstrate the superiority of the proposed method over baseline schemes including WMMSE, ZF, MRT, CNN-based DRL, and the deep deterministic policy gradient (DDPG) method in terms of average sum rate, robustness to CSI imperfection, user mobility, and scalability across varying network sizes and user densities. Furthermore, we show that the proposed method achieves significant computational efficiency compared to CNN-based and WMMSE methods, while reducing communication overhead in comparison with shared-critic DRL approaches.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u71b5\u7684\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u5927\u89c4\u6a21MIMO\u975e\u5730\u9762\u7f51\u7edc\u4e2d\u7684\u5206\u5e03\u5f0f\u6ce2\u675f\u6210\u5f62\uff0c\u901a\u8fc7\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\u548c\u4f4e\u79e9\u5206\u89e3\u6280\u672f\u5b9e\u73b0\u9ad8\u53ef\u6269\u5c55\u6027\u548c\u9c81\u68d2\u6027\u3002", "motivation": "\u89e3\u51b3\u5927\u89c4\u6a21MIMO\u975e\u5730\u9762\u7f51\u7edc\u4e2d\uff0c\u5728\u975e\u5b8c\u7f8e\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u6761\u4ef6\u4e0b\uff0c\u5b9e\u73b0\u4e0b\u884c\u94fe\u8def\u548c\u901f\u7387\u6700\u5927\u5316\u7684\u5206\u5e03\u5f0f\u6ce2\u675f\u6210\u5f62\u95ee\u9898\u3002\u4f20\u7edf\u65b9\u6cd5\u5728\u53ef\u6269\u5c55\u6027\u3001\u9c81\u68d2\u6027\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5b58\u5728\u5c40\u9650\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u71b5\u7684\u591a\u667a\u80fd\u4f53\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u65b9\u6cd5\uff0c\u6bcf\u4e2a\u975e\u5730\u9762\u57fa\u7ad9\u4f7f\u7528\u5085\u91cc\u53f6\u795e\u7ecf\u7b97\u5b50\u8ba1\u7b97\u6ce2\u675f\u6210\u5f62\u5411\u91cf\uff0c\u7ed3\u5408\u5171\u8f6d\u5148\u9a8c\u673a\u5236\u7684\u8fc1\u79fb\u5b66\u4e60\u548c\u4f4e\u79e9\u5206\u89e3\u6280\u672f\uff0c\u652f\u6301\u5927\u89c4\u6a21\u7528\u6237\u90e8\u7f72\u548c\u7a7a\u4e2d\u5c42\u3002", "result": "\u5728\u5e73\u5747\u548c\u901f\u7387\u3001\u5bf9CSI\u975e\u5b8c\u7f8e\u6027\u7684\u9c81\u68d2\u6027\u3001\u7528\u6237\u79fb\u52a8\u6027\u3001\u7f51\u7edc\u89c4\u6a21\u548c\u7528\u6237\u5bc6\u5ea6\u53d8\u5316\u4e0b\u7684\u53ef\u6269\u5c55\u6027\u65b9\u9762\uff0c\u5747\u4f18\u4e8eWMMSE\u3001ZF\u3001MRT\u3001CNN-based DRL\u548cDDPG\u7b49\u57fa\u51c6\u65b9\u6cd5\u3002\u540c\u65f6\u5b9e\u73b0\u4e86\u663e\u8457\u7684\u8ba1\u7b97\u6548\u7387\u548c\u901a\u4fe1\u5f00\u9500\u964d\u4f4e\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u5206\u5e03\u5f0f\u6ce2\u675f\u6210\u5f62\u6846\u67b6\u5728\u975e\u5b8c\u7f8eCSI\u6761\u4ef6\u4e0b\uff0c\u80fd\u591f\u6709\u6548\u63d0\u5347\u5927\u89c4\u6a21MIMO\u975e\u5730\u9762\u7f51\u7edc\u7684\u6027\u80fd\uff0c\u5177\u6709\u4f18\u8d8a\u7684\u53ef\u6269\u5c55\u6027\u3001\u9c81\u68d2\u6027\u548c\u8ba1\u7b97\u6548\u7387\uff0c\u4e3a\u672a\u6765\u7a7a\u4e2d\u901a\u4fe1\u7f51\u7edc\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.23906", "categories": ["eess.SP", "cs.AI", "cs.CV", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.23906", "abs": "https://arxiv.org/abs/2512.23906", "authors": ["Wendong Yao", "Binhua Huang", "Soumyabrata Dev"], "title": "A multimodal Transformer for InSAR-based ground deformation forecasting with cross-site generalization across Europe", "comment": "submitted to ISPRS Journal of Photogrammetry and Remote Sensing for review", "summary": "Near-real-time regional-scale monitoring of ground deformation is increasingly required to support urban planning, critical infrastructure management, and natural hazard mitigation. While Interferometric Synthetic Aperture Radar (InSAR) and continental-scale services such as the European Ground Motion Service (EGMS) provide dense observations of past motion, predicting the next observation remains challenging due to the superposition of long-term trends, seasonal cycles, and occasional abrupt discontinuities (e.g., co-seismic steps), together with strong spatial heterogeneity. In this study we propose a multimodal patch-based Transformer for single-step, fixed-interval next-epoch nowcasting of displacement maps from EGMS time series (resampled to a 64x64 grid over 100 km x 100 km tiles). The model ingests recent displacement snapshots together with (i) static kinematic indicators (mean velocity, acceleration, seasonal amplitude) computed in a leakage-safe manner from the training window only, and (ii) harmonic day-of-year encodings. On the eastern Ireland tile (E32N34), the STGCN is strongest in the displacement-only setting, whereas the multimodal Transformer clearly outperforms CNN-LSTM, CNN-LSTM+Attn, and multimodal STGCN when all models receive the same multimodal inputs, achieving RMSE = 0.90 mm and $R^2$ = 0.97 on the test set with the best threshold accuracies.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u591a\u6a21\u6001Transformer\u7684InSAR\u4f4d\u79fb\u56fe\u5355\u6b65\u9884\u6d4b\u6a21\u578b\uff0c\u7528\u4e8e\u5730\u9762\u5f62\u53d8\u7684\u8fd1\u5b9e\u65f6\u76d1\u6d4b", "motivation": "\u8fd1\u5b9e\u65f6\u533a\u57df\u5c3a\u5ea6\u5730\u9762\u5f62\u53d8\u76d1\u6d4b\u5bf9\u57ce\u5e02\u89c4\u5212\u3001\u5173\u952e\u57fa\u7840\u8bbe\u65bd\u7ba1\u7406\u548c\u81ea\u7136\u707e\u5bb3\u7f13\u89e3\u65e5\u76ca\u91cd\u8981\u3002\u73b0\u6709InSAR\u548cEGMS\u670d\u52a1\u80fd\u89c2\u6d4b\u8fc7\u53bb\u8fd0\u52a8\uff0c\u4f46\u9884\u6d4b\u672a\u6765\u89c2\u6d4b\u4ecd\u5177\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u9700\u8981\u5904\u7406\u957f\u671f\u8d8b\u52bf\u3001\u5b63\u8282\u5468\u671f\u3001\u7a81\u53d1\u4e0d\u8fde\u7eed\u6027\uff08\u5982\u5730\u9707\u9636\u8dc3\uff09\u4ee5\u53ca\u5f3a\u7a7a\u95f4\u5f02\u8d28\u6027\u7684\u53e0\u52a0\u6548\u5e94\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u57fa\u4e8e\u5757\u7684Transformer\u6a21\u578b\uff0c\u7528\u4e8eEGMS\u65f6\u95f4\u5e8f\u5217\u7684\u5355\u6b65\u56fa\u5b9a\u95f4\u9694\u4e0b\u4e00\u65f6\u671f\u4f4d\u79fb\u56fe\u9884\u6d4b\u3002\u6a21\u578b\u8f93\u5165\u5305\u62ec\uff1a\u8fd1\u671f\u4f4d\u79fb\u5feb\u7167\u3001\u9759\u6001\u8fd0\u52a8\u5b66\u6307\u6807\uff08\u4ec5\u4ece\u8bad\u7ec3\u7a97\u53e3\u8ba1\u7b97\u7684\u5747\u503c\u901f\u5ea6\u3001\u52a0\u901f\u5ea6\u3001\u5b63\u8282\u632f\u5e45\uff09\u3001\u4ee5\u53ca\u8c10\u6ce2\u65e5\u5386\u5e74\u7f16\u7801\u3002\u5728\u7231\u5c14\u5170\u4e1c\u90e8\u533a\u57df\uff08E32N34\uff09\u8fdb\u884c\u5b9e\u9a8c\u3002", "result": "\u5728\u7231\u5c14\u5170\u4e1c\u90e8\u533a\u57df\uff0cSTGCN\u5728\u4ec5\u4f4d\u79fb\u8f93\u5165\u65f6\u8868\u73b0\u6700\u5f3a\uff0c\u4f46\u5f53\u6240\u6709\u6a21\u578b\u63a5\u6536\u76f8\u540c\u591a\u6a21\u6001\u8f93\u5165\u65f6\uff0c\u591a\u6a21\u6001Transformer\u660e\u663e\u4f18\u4e8eCNN-LSTM\u3001CNN-LSTM+Attn\u548c\u591a\u6a21\u6001STGCN\uff0c\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u5230RMSE = 0.90 mm\u548cR\u00b2 = 0.97\u7684\u6700\u4f73\u9608\u503c\u7cbe\u5ea6\u3002", "conclusion": "\u591a\u6a21\u6001Transformer\u6a21\u578b\u80fd\u591f\u6709\u6548\u9884\u6d4b\u5730\u9762\u5f62\u53d8\u4f4d\u79fb\u56fe\uff0c\u4e3a\u8fd1\u5b9e\u65f6\u533a\u57df\u5c3a\u5ea6\u76d1\u6d4b\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u9884\u6d4b\u7cbe\u5ea6\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2512.24090", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.24090", "abs": "https://arxiv.org/abs/2512.24090", "authors": ["Dong Wang", "Weidong Mei", "Zhi Chen", "Boyu Ning"], "title": "Movable Antenna Enhanced Multi-Region Beam Coverage: A Multi-Notch-Filter-Inspired Design", "comment": "5 pages, 5 figures", "summary": "Movable antenna (MA) has emerged as a promising technology to enhance wireless communication performance by exploiting the new degree of freedom (DoF) via antenna position optimization. In this letter, we investigate the MA-enhanced wide beam coverage over multiple subregions in the spatial domain. Specifically, we aim to maximize the minimum beam gain over the desired subregions by jointly optimizing the transmit beamforming and antenna position vector (APV). Although this problem is non-convex, we propose an efficient algorithm to solve it by leveraging the similarity between the considered multi-region coverage and classical multi-notch filter (MNF) design. In particular, we construct a spatial MNF-based transmit beamforming vector by assuming a continuous amplitude and phase-shift profile within the antenna movement region. Based on this continuous profile, we propose a sequential update algorithm to select an optimal subset of MA positions for multi-region coverage, jointly with a Gibbs sampling (GS) procedure to avoid undesired local optimum. Numerical results show that our proposed algorithm can significantly outperform conventional fixed position antennas (FPAs) and achieve a comparable performance to the alternating optimization (AO) algorithm with dramatically lower complexity.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u53ef\u79fb\u52a8\u5929\u7ebf\uff08MA\uff09\u7684\u591a\u533a\u57df\u6ce2\u675f\u8986\u76d6\u589e\u5f3a\u65b9\u6cd5\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\u548c\u5929\u7ebf\u4f4d\u7f6e\u5411\u91cf\uff0c\u6700\u5927\u5316\u76ee\u6807\u5b50\u533a\u57df\u7684\u6700\u5c0f\u6ce2\u675f\u589e\u76ca\u3002", "motivation": "\u53ef\u79fb\u52a8\u5929\u7ebf\u6280\u672f\u901a\u8fc7\u5929\u7ebf\u4f4d\u7f6e\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u7684\u81ea\u7531\u5ea6\uff0c\u80fd\u591f\u589e\u5f3a\u65e0\u7ebf\u901a\u4fe1\u6027\u80fd\u3002\u672c\u6587\u65e8\u5728\u89e3\u51b3\u591a\u4e2a\u7a7a\u95f4\u5b50\u533a\u57df\u7684\u5bbd\u6ce2\u675f\u8986\u76d6\u95ee\u9898\uff0c\u6700\u5927\u5316\u76ee\u6807\u533a\u57df\u7684\u6700\u5c0f\u6ce2\u675f\u589e\u76ca\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u9ad8\u6548\u7b97\u6cd5\uff0c\u5229\u7528\u591a\u533a\u57df\u8986\u76d6\u4e0e\u7ecf\u5178\u591a\u9677\u6ce2\u6ee4\u6ce2\u5668\uff08MNF\uff09\u8bbe\u8ba1\u7684\u76f8\u4f3c\u6027\u3002\u9996\u5148\u6784\u5efa\u57fa\u4e8e\u7a7a\u95f4MNF\u7684\u53d1\u5c04\u6ce2\u675f\u6210\u5f62\u5411\u91cf\uff0c\u5047\u8bbe\u5929\u7ebf\u79fb\u52a8\u533a\u57df\u5185\u5177\u6709\u8fde\u7eed\u7684\u5e45\u5ea6\u548c\u76f8\u79fb\u5206\u5e03\u3002\u7136\u540e\u63d0\u51fa\u987a\u5e8f\u66f4\u65b0\u7b97\u6cd5\u9009\u62e9MA\u4f4d\u7f6e\u7684\u6700\u4f18\u5b50\u96c6\uff0c\u5e76\u7ed3\u5408Gibbs\u91c7\u6837\uff08GS\uff09\u8fc7\u7a0b\u907f\u514d\u9677\u5165\u5c40\u90e8\u6700\u4f18\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf\uff08FPA\uff09\uff0c\u4e14\u6027\u80fd\u4e0e\u4ea4\u66ff\u4f18\u5316\uff08AO\uff09\u7b97\u6cd5\u76f8\u5f53\uff0c\u4f46\u590d\u6742\u5ea6\u5927\u5e45\u964d\u4f4e\u3002", "conclusion": "MA\u6280\u672f\u901a\u8fc7\u5929\u7ebf\u4f4d\u7f6e\u4f18\u5316\u80fd\u591f\u6709\u6548\u589e\u5f3a\u591a\u533a\u57df\u6ce2\u675f\u8986\u76d6\u6027\u80fd\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u4fdd\u8bc1\u6027\u80fd\u7684\u540c\u65f6\u5927\u5e45\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4e3a\u5b9e\u9645\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2512.23881", "categories": ["cs.SD", "cs.AI", "cs.CR"], "pdf": "https://arxiv.org/pdf/2512.23881", "abs": "https://arxiv.org/abs/2512.23881", "authors": ["Roee Ziv", "Raz Lapid", "Moshe Sipper"], "title": "Breaking Audio Large Language Models by Attacking Only the Encoder: A Universal Targeted Latent-Space Audio Attack", "comment": null, "summary": "Audio-language models combine audio encoders with large language models to enable multimodal reasoning, but they also introduce new security vulnerabilities. We propose a universal targeted latent space attack, an encoder-level adversarial attack that manipulates audio latent representations to induce attacker-specified outputs in downstream language generation. Unlike prior waveform-level or input-specific attacks, our approach learns a universal perturbation that generalizes across inputs and speakers and does not require access to the language model. Experiments on Qwen2-Audio-7B-Instruct demonstrate consistently high attack success rates with minimal perceptual distortion, revealing a critical and previously underexplored attack surface at the encoder level of multimodal systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u7684\u901a\u7528\u76ee\u6807\u6f5c\u5728\u7a7a\u95f4\u653b\u51fb\uff0c\u901a\u8fc7\u5b66\u4e60\u901a\u7528\u6270\u52a8\u64cd\u7eb5\u97f3\u9891\u6f5c\u5728\u8868\u793a\uff0c\u8bf1\u5bfc\u4e0b\u6e38\u8bed\u8a00\u751f\u6210\u4ea7\u751f\u653b\u51fb\u8005\u6307\u5b9a\u7684\u8f93\u51fa", "motivation": "\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u867d\u7136\u5b9e\u73b0\u4e86\u591a\u6a21\u6001\u63a8\u7406\uff0c\u4f46\u4e5f\u5f15\u5165\u4e86\u65b0\u7684\u5b89\u5168\u6f0f\u6d1e\u3002\u73b0\u6709\u653b\u51fb\u591a\u96c6\u4e2d\u5728\u6ce2\u5f62\u7ea7\u6216\u8f93\u5165\u7279\u5b9a\u653b\u51fb\uff0c\u7f3a\u4e4f\u5bf9\u7f16\u7801\u5668\u5c42\u9762\u7684\u901a\u7528\u653b\u51fb\u7814\u7a76", "method": "\u63d0\u51fa\u901a\u7528\u76ee\u6807\u6f5c\u5728\u7a7a\u95f4\u653b\u51fb\uff0c\u8fd9\u662f\u4e00\u79cd\u7f16\u7801\u5668\u7ea7\u7684\u5bf9\u6297\u653b\u51fb\u65b9\u6cd5\u3002\u901a\u8fc7\u5b66\u4e60\u901a\u7528\u6270\u52a8\u6765\u64cd\u7eb5\u97f3\u9891\u6f5c\u5728\u8868\u793a\uff0c\u8be5\u6270\u52a8\u80fd\u591f\u8de8\u8f93\u5165\u548c\u8bf4\u8bdd\u8005\u6cdb\u5316\uff0c\u4e14\u4e0d\u9700\u8981\u8bbf\u95ee\u8bed\u8a00\u6a21\u578b", "result": "\u5728Qwen2-Audio-7B-Instruct\u6a21\u578b\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u6301\u7eed\u9ad8\u653b\u51fb\u6210\u529f\u7387\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u5c0f\u7684\u611f\u77e5\u5931\u771f\uff0c\u63ed\u793a\u4e86\u591a\u6a21\u6001\u7cfb\u7edf\u7f16\u7801\u5668\u5c42\u9762\u7684\u5173\u952e\u653b\u51fb\u9762", "conclusion": "\u8be5\u65b9\u6cd5\u63ed\u793a\u4e86\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u7f16\u7801\u5668\u5c42\u9762\u7684\u5b89\u5168\u6f0f\u6d1e\uff0c\u8fd9\u662f\u4e00\u79cd\u5148\u524d\u672a\u88ab\u5145\u5206\u63a2\u7d22\u7684\u653b\u51fb\u9762\uff0c\u5bf9\u591a\u6a21\u6001\u7cfb\u7edf\u7684\u5b89\u5168\u6027\u63d0\u51fa\u4e86\u91cd\u8981\u8b66\u793a"}}
{"id": "2512.24155", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2512.24155", "abs": "https://arxiv.org/abs/2512.24155", "authors": ["Ashish Patwari", "Sanjeeva Reddy S", "G Ramachandra Reddy"], "title": "Discovering Optimal Robust Minimum Redundancy Arrays (RMRAs) through Exhaustive Search and Algebraic Formulation of a New Sub-Optimal RMRA", "comment": "8 Pages, 2 Figures, IEEE Journal Format", "summary": "Modern sparse arrays are maximally economic in that they retain just as many sensors required to provide a specific aperture while maintaining a hole-free difference coarray. As a result, these are susceptible to the failure of even a single sensor. Contrarily, two-fold redundant sparse arrays (TFRSAs) and robust minimum redundancy arrays (RMRAs) ensure robustness against single-sensor failures due to their inherent redundancy in their coarrays. At present, optimal RMRA configurations are known only for arrays with sensor counts N=6 to N=10. To this end, this paper proposes two objectives: (i) developing a systematic algorithm to discover optimal RMRAs for N>10, and (ii) obtaining a new family of near-/sub-optimal RMRA that can be completely specified using closed-form expressions (CFEs). We solve the combinatorial optimization problem of finding RMRAs using an exhaustive search technique implemented in MATLAB. Optimal RMRAs for N = 11 to 14 were successfully found and near/sub-optimal arrays for N = 15 to 20 were determined using the proposed technique. As a byproduct of the exhaustive search, a large catalogue of valid near- and sub-optimal RMRAs was also obtained. In the second stage, CFEs for a new TFRSA were obtained by applying pattern mining and algebraic generalizations to the arrays obtained through exhaustive search. The proposed family enjoys CFEs for sensor positions, available aperture, and achievable degrees of freedom (DOFs). The CFEs have been thoroughly validated using MATLAB and are found to be valid for $N\\geq8$. Hence, it can be concluded that the novelty of this work is two-fold: extending the catalogue of known optimal RMRAs and formulating a sub-optimal RMRA that abides by CFEs.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u7cfb\u7edf\u7b97\u6cd5\u5bfb\u627eN>10\u7684\u6700\u4f18\u7a33\u5065\u6700\u5c0f\u5197\u4f59\u9635\u5217(RMRA)\uff0c\u5e76\u901a\u8fc7\u95ed\u5f0f\u8868\u8fbe\u5f0f\u83b7\u5f97\u8fd1\u4f18/\u6b21\u4f18RMRA\u65b0\u5bb6\u65cf\u3002", "motivation": "\u73b0\u6709\u7a00\u758f\u9635\u5217\u5bf9\u5355\u4f20\u611f\u5668\u6545\u969c\u654f\u611f\uff0c\u800cTFRSAs\u548cRMRAs\u901a\u8fc7\u5171\u9635\u5217\u5197\u4f59\u63d0\u4f9b\u9c81\u68d2\u6027\u3002\u4f46\u5f53\u524d\u6700\u4f18RMRA\u914d\u7f6e\u4ec5\u77e5N=6\u523010\uff0c\u9700\u8981\u6269\u5c55N>10\u7684\u6700\u4f18\u914d\u7f6e\u5e76\u5f00\u53d1\u95ed\u5f0f\u8868\u8fbe\u5f0f\u9635\u5217\u3002", "method": "\u4f7f\u7528MATLAB\u5b9e\u73b0\u7a77\u4e3e\u641c\u7d22\u6280\u672f\u89e3\u51b3\u7ec4\u5408\u4f18\u5316\u95ee\u9898\u5bfb\u627eRMRAs\uff1b\u901a\u8fc7\u6a21\u5f0f\u6316\u6398\u548c\u4ee3\u6570\u6cdb\u5316\u5bf9\u641c\u7d22\u5f97\u5230\u7684\u9635\u5217\u5e94\u7528\u95ed\u5f0f\u8868\u8fbe\u5f0f\u63a8\u5bfc\u3002", "result": "\u6210\u529f\u627e\u5230N=11\u523014\u7684\u6700\u4f18RMRAs\uff0c\u786e\u5b9a\u4e86N=15\u523020\u7684\u8fd1\u4f18/\u6b21\u4f18\u9635\u5217\uff1b\u83b7\u5f97\u4e86\u5177\u6709\u95ed\u5f0f\u8868\u8fbe\u5f0f\u7684\u65b0TFRSA\u5bb6\u65cf\uff0c\u5305\u542b\u4f20\u611f\u5668\u4f4d\u7f6e\u3001\u53ef\u7528\u5b54\u5f84\u548c\u81ea\u7531\u5ea6\u8868\u8fbe\u5f0f\u3002", "conclusion": "\u672c\u5de5\u4f5c\u7684\u65b0\u9896\u6027\u5728\u4e8e\u6269\u5c55\u5df2\u77e5\u6700\u4f18RMRAs\u76ee\u5f55\uff0c\u5e76\u5236\u5b9a\u4e86\u9075\u5faa\u95ed\u5f0f\u8868\u8fbe\u5f0f\u7684\u6b21\u4f18RMRA\uff0c\u4e3aN\u22658\u7684\u9635\u5217\u63d0\u4f9b\u4e86\u7cfb\u7edf\u8bbe\u8ba1\u65b9\u6cd5\u3002"}}
{"id": "2512.23994", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2512.23994", "abs": "https://arxiv.org/abs/2512.23994", "authors": ["Tianxin Xie", "Wentao Lei", "Guanjie Huang", "Pengfei Zhang", "Kai Jiang", "Chunhui Zhang", "Fengji Ma", "Haoyu He", "Han Zhang", "Jiangshan He", "Jinting Wang", "Linghan Fang", "Lufei Gao", "Orkesh Ablet", "Peihua Zhang", "Ruolin Hu", "Shengyu Li", "Weilin Lin", "Xiaoyang Feng", "Xinyue Yang", "Yan Rong", "Yanyun Wang", "Zihang Shao", "Zelin Zhao", "Chenxing Li", "Shan Yang", "Wenfu Wang", "Meng Yu", "Dong Yu", "Li Liu"], "title": "PhyAVBench: A Challenging Audio Physics-Sensitivity Benchmark for Physically Grounded Text-to-Audio-Video Generation", "comment": "6 major physical dimensions, 50 fine-grained test points, 1,000 groups of variable-controlled test samples", "summary": "Text-to-audio-video (T2AV) generation underpins a wide range of applications demanding realistic audio-visual content, including virtual reality, world modeling, gaming, and filmmaking. However, existing T2AV models remain incapable of generating physically plausible sounds, primarily due to their limited understanding of physical principles. To situate current research progress, we present PhyAVBench, a challenging audio physics-sensitivity benchmark designed to systematically evaluate the audio physics grounding capabilities of existing T2AV models. PhyAVBench comprises 1,000 groups of paired text prompts with controlled physical variables that implicitly induce sound variations, enabling a fine-grained assessment of models' sensitivity to changes in underlying acoustic conditions. We term this evaluation paradigm the Audio-Physics Sensitivity Test (APST). Unlike prior benchmarks that primarily focus on audio-video synchronization, PhyAVBench explicitly evaluates models' understanding of the physical mechanisms underlying sound generation, covering 6 major audio physics dimensions, 4 daily scenarios (music, sound effects, speech, and their mix), and 50 fine-grained test points, ranging from fundamental aspects such as sound diffraction to more complex phenomena, e.g., Helmholtz resonance. Each test point consists of multiple groups of paired prompts, where each prompt is grounded by at least 20 newly recorded or collected real-world videos, thereby minimizing the risk of data leakage during model pre-training. Both prompts and videos are iteratively refined through rigorous human-involved error correction and quality control to ensure high quality. We argue that only models with a genuine grasp of audio-related physical principles can generate physically consistent audio-visual content. We hope PhyAVBench will stimulate future progress in this critical yet largely unexplored domain.", "AI": {"tldr": "\u63d0\u51fa\u4e86PhyAVBench\u57fa\u51c6\u6d4b\u8bd5\uff0c\u7528\u4e8e\u8bc4\u4f30\u6587\u672c\u5230\u97f3\u89c6\u9891\u751f\u6210\u6a21\u578b\u5bf9\u97f3\u9891\u7269\u7406\u539f\u7406\u7684\u7406\u89e3\u80fd\u529b\uff0c\u5305\u542b1000\u7ec4\u914d\u5bf9\u6587\u672c\u63d0\u793a\uff0c\u8986\u76d66\u4e2a\u97f3\u9891\u7269\u7406\u7ef4\u5ea6\u30014\u4e2a\u65e5\u5e38\u573a\u666f\u548c50\u4e2a\u7ec6\u7c92\u5ea6\u6d4b\u8bd5\u70b9\u3002", "motivation": "\u73b0\u6709\u6587\u672c\u5230\u97f3\u89c6\u9891\u751f\u6210\u6a21\u578b\u65e0\u6cd5\u751f\u6210\u7269\u7406\u4e0a\u5408\u7406\u7684\u58f0\u97f3\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u7f3a\u4e4f\u5bf9\u7269\u7406\u539f\u7406\u7684\u7406\u89e3\u3002\u9700\u8981\u5efa\u7acb\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u8bc4\u4f30\u57fa\u51c6\u6765\u63a8\u52a8\u8fd9\u4e00\u5173\u952e\u4f46\u672a\u88ab\u5145\u5206\u63a2\u7d22\u9886\u57df\u7684\u53d1\u5c55\u3002", "method": "\u521b\u5efaPhyAVBench\u57fa\u51c6\uff0c\u5305\u542b1000\u7ec4\u914d\u5bf9\u6587\u672c\u63d0\u793a\uff0c\u901a\u8fc7\u63a7\u5236\u7269\u7406\u53d8\u91cf\u6765\u9690\u542b\u8bf1\u5bfc\u58f0\u97f3\u53d8\u5316\u3002\u91c7\u7528\u97f3\u9891\u7269\u7406\u654f\u611f\u6027\u6d4b\u8bd5\u8303\u5f0f\uff0c\u8986\u76d66\u4e2a\u4e3b\u8981\u97f3\u9891\u7269\u7406\u7ef4\u5ea6\u30014\u4e2a\u65e5\u5e38\u573a\u666f\u548c50\u4e2a\u7ec6\u7c92\u5ea6\u6d4b\u8bd5\u70b9\u3002\u6bcf\u4e2a\u6d4b\u8bd5\u70b9\u57fa\u4e8e\u81f3\u5c1120\u4e2a\u65b0\u5f55\u5236\u6216\u6536\u96c6\u7684\u771f\u5b9e\u4e16\u754c\u89c6\u9891\uff0c\u7ecf\u8fc7\u4e25\u683c\u7684\u4eba\u5de5\u7ea0\u9519\u548c\u8d28\u91cf\u63a7\u5236\u3002", "result": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u6027\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u7cbe\u7ec6\u8bc4\u4f30\u6a21\u578b\u5bf9\u5e95\u5c42\u58f0\u5b66\u6761\u4ef6\u53d8\u5316\u7684\u654f\u611f\u6027\u3002\u8be5\u57fa\u51c6\u901a\u8fc7\u914d\u5bf9\u63d0\u793a\u8bbe\u8ba1\uff0c\u53ef\u4ee5\u6d4b\u8bd5\u6a21\u578b\u662f\u5426\u771f\u6b63\u7406\u89e3\u58f0\u97f3\u751f\u6210\u7684\u7269\u7406\u673a\u5236\uff0c\u800c\u4e0d\u4ec5\u4ec5\u662f\u97f3\u9891-\u89c6\u9891\u540c\u6b65\u3002", "conclusion": "\u53ea\u6709\u771f\u6b63\u638c\u63e1\u97f3\u9891\u76f8\u5173\u7269\u7406\u539f\u7406\u7684\u6a21\u578b\u624d\u80fd\u751f\u6210\u7269\u7406\u4e00\u81f4\u7684\u97f3\u89c6\u9891\u5185\u5bb9\u3002PhyAVBench\u57fa\u51c6\u65e8\u5728\u63a8\u52a8\u8fd9\u4e00\u5173\u952e\u9886\u57df\u7684\u53d1\u5c55\uff0c\u586b\u8865\u73b0\u6709\u7814\u7a76\u5728\u97f3\u9891\u7269\u7406\u57fa\u7840\u7406\u89e3\u65b9\u9762\u7684\u7a7a\u767d\u3002"}}
{"id": "2512.24250", "categories": ["eess.SP", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24250", "abs": "https://arxiv.org/abs/2512.24250", "authors": ["Wenchao Li", "Xuezhi Wang", "Qiang Sun", "Allison N. Kealy", "Andrew D. Greentree"], "title": "Quantifying the advantage of vector over scalar magnetic sensor networks for undersea surveillance", "comment": null, "summary": "Magnetic monitoring of maritime environments is an important problem for monitoring and optimising shipping, as well as national security. New developments in compact, fibre-coupled quantum magnetometers have led to the opportunity to critically evaluate how best to create such a sensor network. Here we explore various magnetic sensor network architectures for target identification. Our modelling compares networks of scalar vs vector magnetometers. We implement an unscented Kalman filter approach to perform target tracking, and we find that vector networks provide a significant improvement in target tracking, specifically tracking accuracy and resilience compared with scalar networks.", "AI": {"tldr": "\u6bd4\u8f83\u6807\u91cf\u548c\u77e2\u91cf\u78c1\u529b\u8ba1\u7f51\u7edc\u5728\u6d77\u4e0a\u76ee\u6807\u8ddf\u8e2a\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u77e2\u91cf\u7f51\u7edc\u5728\u8ddf\u8e2a\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u65b9\u9762\u663e\u8457\u4f18\u4e8e\u6807\u91cf\u7f51\u7edc", "motivation": "\u6d77\u4e0a\u73af\u5883\u7684\u78c1\u76d1\u6d4b\u5bf9\u4e8e\u822a\u8fd0\u76d1\u63a7\u4f18\u5316\u548c\u56fd\u5bb6\u5b89\u5168\u81f3\u5173\u91cd\u8981\uff0c\u65b0\u578b\u7d27\u51d1\u5149\u7ea4\u8026\u5408\u91cf\u5b50\u78c1\u529b\u8ba1\u7684\u53d1\u5c55\u4e3a\u521b\u5efa\u4f20\u611f\u5668\u7f51\u7edc\u63d0\u4f9b\u4e86\u65b0\u673a\u4f1a", "method": "\u63a2\u7d22\u4e0d\u540c\u78c1\u4f20\u611f\u5668\u7f51\u7edc\u67b6\u6784\uff0c\u6bd4\u8f83\u6807\u91cf\u4e0e\u77e2\u91cf\u78c1\u529b\u8ba1\u7f51\u7edc\uff0c\u91c7\u7528\u65e0\u8ff9\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u65b9\u6cd5\u8fdb\u884c\u76ee\u6807\u8ddf\u8e2a", "result": "\u77e2\u91cf\u7f51\u7edc\u5728\u76ee\u6807\u8ddf\u8e2a\u65b9\u9762\u63d0\u4f9b\u663e\u8457\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5728\u8ddf\u8e2a\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u65b9\u9762\u4f18\u4e8e\u6807\u91cf\u7f51\u7edc", "conclusion": "\u77e2\u91cf\u78c1\u529b\u8ba1\u7f51\u7edc\u5728\u6d77\u4e0a\u76ee\u6807\u8bc6\u522b\u548c\u8ddf\u8e2a\u5e94\u7528\u4e2d\u5177\u6709\u660e\u663e\u4f18\u52bf\uff0c\u4e3a\u5b9e\u9645\u4f20\u611f\u5668\u7f51\u7edc\u90e8\u7f72\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc"}}
{"id": "2512.24052", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.MM"], "pdf": "https://arxiv.org/pdf/2512.24052", "abs": "https://arxiv.org/abs/2512.24052", "authors": ["Yanxi Chen", "Wenhui Zhu", "Xiwen Chen", "Zhipeng Wang", "Xin Li", "Peijie Qiu", "Hao Wang", "Xuanzhao Dong", "Yujian Xiong", "Anderson Schneider", "Yuriy Nevmyvaka", "Yalin Wang"], "title": "AHA: Aligning Large Audio-Language Models for Reasoning Hallucinations via Counterfactual Hard Negatives", "comment": null, "summary": "Although Large Audio-Language Models (LALMs) deliver state-of-the-art (SOTA) performance, they frequently suffer from hallucinations, e.g. generating text not grounded in the audio input. We analyze these grounding failures and identify a distinct taxonomy: Event Omission, False Event Identity, Temporal Relation Error, and Quantitative Temporal Error. To address this, we introduce the AHA (Audio Hallucination Alignment) framework. By leveraging counterfactual hard negative mining, our pipeline constructs a high-quality preference dataset that forces models to distinguish strict acoustic evidence from linguistically plausible fabrications. Additionally, we establish AHA-Eval, a diagnostic benchmark designed to rigorously test these fine-grained temporal reasoning capabilities. We apply this data to align Qwen2.5-Omni. The resulting model, Qwen-Audio-AHA, achieves a 13.7% improvement on AHA-Eval. Crucially, this benefit generalizes beyond our diagnostic set. Our model shows substantial gains on public benchmarks, including 1.3% on MMAU-Test and 1.6% on MMAR, outperforming latest SOTA methods.", "AI": {"tldr": "AHA\u6846\u67b6\u901a\u8fc7\u53cd\u4e8b\u5b9e\u8d1f\u6837\u672c\u6316\u6398\u6784\u5efa\u9ad8\u8d28\u91cf\u504f\u597d\u6570\u636e\u96c6\uff0c\u89e3\u51b3\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u53d6\u5f97\u663e\u8457\u63d0\u5347", "motivation": "\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u867d\u7136\u6027\u80fd\u5148\u8fdb\uff0c\u4f46\u7ecf\u5e38\u4ea7\u751f\u5e7b\u89c9\uff08\u751f\u6210\u672a\u57fa\u4e8e\u97f3\u9891\u8f93\u5165\u7684\u5185\u5bb9\uff09\uff0c\u9700\u8981\u89e3\u51b3\u8fd9\u4e9b\u63a5\u5730\u5931\u8d25\u95ee\u9898", "method": "\u63d0\u51faAHA\u6846\u67b6\uff0c\u5229\u7528\u53cd\u4e8b\u5b9e\u786c\u8d1f\u6837\u672c\u6316\u6398\u6784\u5efa\u9ad8\u8d28\u91cf\u504f\u597d\u6570\u636e\u96c6\uff0c\u8feb\u4f7f\u6a21\u578b\u533a\u5206\u4e25\u683c\u7684\u58f0\u5b66\u8bc1\u636e\u548c\u8bed\u8a00\u4e0a\u5408\u7406\u7684\u865a\u6784\uff1b\u5efa\u7acbAHA-Eval\u8bca\u65ad\u57fa\u51c6\u6d4b\u8bd5\u7ec6\u7c92\u5ea6\u65f6\u95f4\u63a8\u7406\u80fd\u529b", "result": "Qwen-Audio-AHA\u6a21\u578b\u5728AHA-Eval\u4e0a\u63d0\u534713.7%\uff0c\u5728\u516c\u5171\u57fa\u51c6\u6d4b\u8bd5MMAUTest\u4e0a\u63d0\u53471.3%\uff0c\u5728MMAR\u4e0a\u63d0\u53471.6%\uff0c\u8d85\u8d8a\u6700\u65b0SOTA\u65b9\u6cd5", "conclusion": "AHA\u6846\u67b6\u6709\u6548\u89e3\u51b3\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u7684\u5e7b\u89c9\u95ee\u9898\uff0c\u901a\u8fc7\u9ad8\u8d28\u91cf\u504f\u597d\u6570\u636e\u5bf9\u9f50\u663e\u8457\u63d0\u5347\u6a21\u578b\u6027\u80fd\uff0c\u4e14\u6539\u8fdb\u6548\u679c\u80fd\u6cdb\u5316\u5230\u8bca\u65ad\u96c6\u4e4b\u5916\u7684\u57fa\u51c6\u6d4b\u8bd5"}}
{"id": "2512.24334", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24334", "abs": "https://arxiv.org/abs/2512.24334", "authors": ["Anbang Zhang", "Chenyuan Feng", "Wai Ho Mow", "Jia Ye", "Shuaishuai Guo", "Geyong Min", "Tony Q. S. Quek"], "title": "OptiVote: Non-Coherent FSO Over-the-Air Majority Vote for Communication-Efficient Distributed Federated Learning in Space Data Centers", "comment": null, "summary": "The rapid deployment of mega-constellations is driving the long-term vision of space data centers (SDCs), where interconnected satellites form in-orbit distributed computing and learning infrastructures. Enabling distributed federated learning in such systems is challenging because iterative training requires frequent aggregation over inter-satellite links that are bandwidth- and energy-constrained, and the link conditions can be highly dynamic. In this work, we exploit over-the-air computation (AirComp) as an in-network aggregation primitive. However, conventional coherent AirComp relies on stringent phase alignment, which is difficult to maintain in space environments due to satellite jitter and Doppler effects. To overcome this limitation, we propose OptiVote, a robust and communication-efficient non-coherent free-space optical (FSO) AirComp framework for federated learning toward Space Data Centers. OptiVote integrates sign stochastic gradient descent (signSGD) with a majority-vote (MV) aggregation principle and pulse-position modulation (PPM), where each satellite conveys local gradient signs by activating orthogonal PPM time slots. The aggregation node performs MV detection via non-coherent energy accumulation, transforming phase-sensitive field superposition into phase-agnostic optical intensity combining, thereby eliminating the need for precise phase synchronization and improving resilience under dynamic impairments. To mitigate aggregation bias induced by heterogeneous FSO channels, we further develop an importance-aware, channel state information (CSI)-free dynamic power control scheme that balances received energies without additional signaling. We provide theoretical analysis by characterizing the aggregate error probability under statistical FSO channels and establishing convergence guarantees for non-convex objectives.", "AI": {"tldr": "OptiVote\uff1a\u4e00\u79cd\u7528\u4e8e\u7a7a\u95f4\u6570\u636e\u4e2d\u5fc3\u8054\u90a6\u5b66\u4e60\u7684\u9c81\u68d2\u975e\u76f8\u5e72\u81ea\u7531\u7a7a\u95f4\u5149\u7a7a\u4e2d\u8ba1\u7b97\u6846\u67b6\uff0c\u901a\u8fc7\u7b26\u53f7SGD\u4e0e\u591a\u6570\u6295\u7968\u805a\u5408\u7ed3\u5408PPM\u8c03\u5236\uff0c\u65e0\u9700\u76f8\u4f4d\u540c\u6b65\uff0c\u63d0\u9ad8\u52a8\u6001\u635f\u4f24\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "motivation": "\u5de8\u578b\u661f\u5ea7\u7684\u5feb\u901f\u90e8\u7f72\u63a8\u52a8\u4e86\u7a7a\u95f4\u6570\u636e\u4e2d\u5fc3\u7684\u53d1\u5c55\uff0c\u4f46\u5728\u8fd9\u79cd\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u5206\u5e03\u5f0f\u8054\u90a6\u5b66\u4e60\u9762\u4e34\u6311\u6218\uff1a\u8fed\u4ee3\u8bad\u7ec3\u9700\u8981\u9891\u7e41\u805a\u5408\uff0c\u800c\u661f\u95f4\u94fe\u8def\u5e26\u5bbd\u548c\u80fd\u91cf\u53d7\u9650\uff0c\u94fe\u8def\u6761\u4ef6\u9ad8\u5ea6\u52a8\u6001\u3002\u4f20\u7edf\u76f8\u5e72\u7a7a\u4e2d\u8ba1\u7b97\u4f9d\u8d56\u4e25\u683c\u7684\u76f8\u4f4d\u5bf9\u9f50\uff0c\u5728\u7a7a\u95f4\u73af\u5883\u4e2d\u96be\u4ee5\u7ef4\u6301\u3002", "method": "\u63d0\u51faOptiVote\u6846\u67b6\uff0c\u5c06\u7b26\u53f7\u968f\u673a\u68af\u5ea6\u4e0b\u964d\u4e0e\u591a\u6570\u6295\u7968\u805a\u5408\u539f\u7406\u548c\u8109\u51b2\u4f4d\u7f6e\u8c03\u5236\u7ed3\u5408\uff0c\u536b\u661f\u901a\u8fc7\u6fc0\u6d3b\u6b63\u4ea4PPM\u65f6\u9699\u4f20\u8f93\u672c\u5730\u68af\u5ea6\u7b26\u53f7\u3002\u805a\u5408\u8282\u70b9\u901a\u8fc7\u975e\u76f8\u5e72\u80fd\u91cf\u7d2f\u79ef\u8fdb\u884c\u591a\u6570\u6295\u7968\u68c0\u6d4b\uff0c\u5c06\u76f8\u4f4d\u654f\u611f\u7684\u573a\u53e0\u52a0\u8f6c\u6362\u4e3a\u76f8\u4f4d\u65e0\u5173\u7684\u5149\u5f3a\u5ea6\u7ec4\u5408\u3002\u8fd8\u5f00\u53d1\u4e86\u91cd\u8981\u6027\u611f\u77e5\u3001\u65e0\u9700\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u7684\u52a8\u6001\u529f\u7387\u63a7\u5236\u65b9\u6848\u6765\u51cf\u8f7b\u5f02\u6784FSO\u4fe1\u9053\u5f15\u8d77\u7684\u805a\u5408\u504f\u5dee\u3002", "result": "\u901a\u8fc7\u7406\u8bba\u5206\u6790\uff0c\u5728\u7edf\u8ba1FSO\u4fe1\u9053\u4e0b\u8868\u5f81\u4e86\u805a\u5408\u9519\u8bef\u6982\u7387\uff0c\u5e76\u4e3a\u975e\u51f8\u76ee\u6807\u5efa\u7acb\u4e86\u6536\u655b\u4fdd\u8bc1\u3002\u8be5\u65b9\u6cd5\u6d88\u9664\u4e86\u7cbe\u786e\u76f8\u4f4d\u540c\u6b65\u7684\u9700\u6c42\uff0c\u63d0\u9ad8\u4e86\u52a8\u6001\u635f\u4f24\u4e0b\u7684\u9c81\u68d2\u6027\u3002", "conclusion": "OptiVote\u4e3a\u7a7a\u95f4\u6570\u636e\u4e2d\u5fc3\u63d0\u4f9b\u4e86\u4e00\u79cd\u9c81\u68d2\u4e14\u901a\u4fe1\u9ad8\u6548\u7684\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u975e\u76f8\u5e72\u5149\u7a7a\u4e2d\u8ba1\u7b97\u89e3\u51b3\u4e86\u7a7a\u95f4\u73af\u5883\u4e2d\u76f8\u4f4d\u540c\u6b65\u56f0\u96be\u7684\u95ee\u9898\uff0c\u540c\u65f6\u901a\u8fc7\u52a8\u6001\u529f\u7387\u63a7\u5236\u51cf\u8f7b\u4e86\u4fe1\u9053\u5f02\u6784\u6027\u7684\u5f71\u54cd\u3002"}}
{"id": "2512.24140", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.24140", "abs": "https://arxiv.org/abs/2512.24140", "authors": ["Han Yin", "Yang Xiao", "Rohan Kumar Das", "Jisheng Bai", "Ting Dang"], "title": "Environmental Sound Deepfake Detection Challenge: An Overview", "comment": null, "summary": "Recent progress in audio generation models has made it possible to create highly realistic and immersive soundscapes, which are now widely used in film and virtual-reality-related applications. However, these audio generators also raise concerns about potential misuse, such as producing deceptive audio for fabricated videos or spreading misleading information. Therefore, it is essential to develop effective methods for detecting fake environmental sounds. Existing datasets for environmental sound deepfake detection (ESDD) remain limited in both scale and the diversity of sound categories they cover. To address this gap, we introduced EnvSDD, the first large-scale curated dataset designed for ESDD. Based on EnvSDD, we launched the ESDD Challenge, recognized as one of the ICASSP 2026 Grand Challenges. This paper presents an overview of the ESDD Challenge, including a detailed analysis of the challenge results.", "AI": {"tldr": "\u672c\u6587\u4ecb\u7ecd\u4e86EnvSDD\u6570\u636e\u96c6\u548cESDD\u6311\u6218\u8d5b\uff0c\u8fd9\u662f\u9996\u4e2a\u9488\u5bf9\u73af\u5883\u58f0\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7684\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548cICASSP 2026\u6311\u6218\u8d5b\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u6570\u636e\u96c6\u89c4\u6a21\u5c0f\u3001\u7c7b\u522b\u5c11\u7684\u95ee\u9898\u3002", "motivation": "\u97f3\u9891\u751f\u6210\u6a21\u578b\u7684\u8fdb\u6b65\u5e26\u6765\u4e86\u903c\u771f\u7684\u58f0\u97f3\u5408\u6210\u80fd\u529b\uff0c\u4f46\u4e5f\u5f15\u53d1\u4e86\u88ab\u6ee5\u7528\u4e8e\u5236\u9020\u6b3a\u9a97\u6027\u97f3\u9891\u7684\u62c5\u5fe7\u3002\u73b0\u6709\u73af\u5883\u58f0\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u6570\u636e\u96c6\u5728\u89c4\u6a21\u548c\u58f0\u97f3\u7c7b\u522b\u591a\u6837\u6027\u65b9\u9762\u90fd\u5f88\u6709\u9650\uff0c\u9700\u8981\u66f4\u597d\u7684\u6570\u636e\u96c6\u6765\u5f00\u53d1\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u4f5c\u8005\u521b\u5efa\u4e86EnvSDD\u6570\u636e\u96c6\uff0c\u8fd9\u662f\u9996\u4e2a\u9488\u5bf9\u73af\u5883\u58f0\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7684\u5927\u89c4\u6a21\u7b56\u5212\u6570\u636e\u96c6\uff0c\u5e76\u57fa\u4e8e\u6b64\u53d1\u8d77\u4e86ESDD\u6311\u6218\u8d5b\uff0c\u8be5\u6311\u6218\u8d5b\u5df2\u88ab\u63a5\u53d7\u4e3aICASSP 2026\u91cd\u5927\u6311\u6218\u4e4b\u4e00\u3002", "result": "\u6210\u529f\u5efa\u7acb\u4e86EnvSDD\u6570\u636e\u96c6\u5e76\u542f\u52a8\u4e86ESDD\u6311\u6218\u8d5b\uff0c\u4e3a\u73af\u5883\u58f0\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7814\u7a76\u63d0\u4f9b\u4e86\u91cd\u8981\u7684\u57fa\u51c6\u5e73\u53f0\uff0c\u8bba\u6587\u8be6\u7ec6\u5206\u6790\u4e86\u6311\u6218\u8d5b\u7684\u7ed3\u679c\u3002", "conclusion": "EnvSDD\u6570\u636e\u96c6\u548cESDD\u6311\u6218\u8d5b\u586b\u8865\u4e86\u73af\u5883\u58f0\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u9886\u57df\u7684\u6570\u636e\u96c6\u7a7a\u767d\uff0c\u4e3a\u5f00\u53d1\u66f4\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u63d0\u4f9b\u4e86\u91cd\u8981\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u5e94\u5bf9\u97f3\u9891\u751f\u6210\u6280\u672f\u53ef\u80fd\u5e26\u6765\u7684\u6ee5\u7528\u98ce\u9669\u3002"}}
{"id": "2512.24412", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.24412", "abs": "https://arxiv.org/abs/2512.24412", "authors": ["Javier Gim\u00e9nez", "Jos\u00e9 A. Cort\u00e9s", "Luis D\u00edez"], "title": "Low-complexity spectral shaping method for OFDM signals with dynamically adaptive emission mask", "comment": "12 pages", "summary": "Orthogonal frequency division multiplexing (OFDM) signals with rectangular pulses exhibit low spectral confinement. Shaping their power spectral density (PSD) is imperative in the increasingly overcrowded spectrum to benefit from the cognitive radio (CR) paradigm. However, since the available spectrum is non-contiguous and its occupancy changes with time, the spectral shaping solution has to be dynamically adapted. This work proposes a framework that allows using a reduced set of preoptimized pulses to shape the spectrum of OFDM signals, irrespective of its spectral width and location, by means of simple transformations. The employed pulses combine active interference cancellation (AIC) and adaptive symbol transition (AST) terms in a transparent way to the receiver. They can be easily adapted online by the communication device to changes in the location or width of the transmission band, which contrasts with existing methods of the same type that require solving NP-hard optimization problems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u4f7f\u7528\u9884\u4f18\u5316\u8109\u51b2\u52a8\u6001\u8c03\u6574OFDM\u4fe1\u53f7\u9891\u8c31\u5f62\u72b6\u7684\u6846\u67b6\uff0c\u65e0\u9700\u89e3\u51b3NP\u96be\u4f18\u5316\u95ee\u9898", "motivation": "OFDM\u4fe1\u53f7\u9891\u8c31\u6cc4\u9732\u4e25\u91cd\uff0c\u5728\u8ba4\u77e5\u65e0\u7ebf\u7535\u4e2d\u9700\u8981\u52a8\u6001\u8c03\u6574\u9891\u8c31\u5f62\u72b6\u4ee5\u9002\u5e94\u975e\u8fde\u7eed\u3001\u65f6\u53d8\u7684\u53ef\u7528\u9891\u8c31", "method": "\u4f7f\u7528\u5c11\u91cf\u9884\u4f18\u5316\u8109\u51b2\uff0c\u901a\u8fc7\u7b80\u5355\u53d8\u6362\u8c03\u6574OFDM\u4fe1\u53f7\u9891\u8c31\u5bbd\u5ea6\u548c\u4f4d\u7f6e\uff0c\u7ed3\u5408\u4e3b\u52a8\u5e72\u6270\u6d88\u9664(AIC)\u548c\u81ea\u9002\u5e94\u7b26\u53f7\u8fc7\u6e21(AST)\u6280\u672f", "result": "\u63d0\u51fa\u7684\u6846\u67b6\u5141\u8bb8\u901a\u4fe1\u8bbe\u5907\u5728\u7ebf\u9002\u5e94\u4f20\u8f93\u9891\u5e26\u4f4d\u7f6e\u6216\u5bbd\u5ea6\u7684\u53d8\u5316\uff0c\u65e0\u9700\u89e3\u51b3NP\u96be\u4f18\u5316\u95ee\u9898", "conclusion": "\u8be5\u65b9\u6cd5\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u3001\u52a8\u6001\u7684\u9891\u8c31\u6574\u5f62\u89e3\u51b3\u65b9\u6848\uff0c\u9002\u7528\u4e8e\u8ba4\u77e5\u65e0\u7ebf\u7535\u73af\u5883\u4e2d\u7684OFDM\u7cfb\u7edf"}}
{"id": "2512.24628", "categories": ["cs.SD", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2512.24628", "abs": "https://arxiv.org/abs/2512.24628", "authors": ["Mohsen Annabestani", "Samira Aghadoost", "Anais Rameau", "Olivier Elemento", "Gloria Chia-Yi Chiang"], "title": "AI-Driven Acoustic Voice Biomarker-Based Hierarchical Classification of Benign Laryngeal Voice Disorders from Sustained Vowels", "comment": null, "summary": "Benign laryngeal voice disorders affect nearly one in five individuals and often manifest as dysphonia, while also serving as non-invasive indicators of broader physiological dysfunction. We introduce a clinically inspired hierarchical machine learning framework for automated classification of eight benign voice disorders alongside healthy controls, using acoustic features extracted from short, sustained vowel phonations. Experiments utilized 15,132 recordings from 1,261 speakers in the Saarbruecken Voice Database, covering vowels /a/, /i/, and /u/ at neutral, high, low, and gliding pitches. Mirroring clinical triage workflows, the framework operates in three sequential stages: Stage 1 performs binary screening of pathological versus non-pathological voices by integrating convolutional neural network-derived mel-spectrogram features with 21 interpretable acoustic biomarkers; Stage 2 stratifies voices into Healthy, Functional or Psychogenic, and Structural or Inflammatory groups using a cubic support vector machine; Stage 3 achieves fine-grained classification by incorporating probabilistic outputs from prior stages, improving discrimination of structural and inflammatory disorders relative to functional conditions. The proposed system consistently outperformed flat multi-class classifiers and pre-trained self-supervised models, including META HuBERT and Google HeAR, whose generic objectives are not optimized for sustained clinical phonation. By combining deep spectral representations with interpretable acoustic features, the framework enhances transparency and clinical alignment. These results highlight the potential of quantitative voice biomarkers as scalable, non-invasive tools for early screening, diagnostic triage, and longitudinal monitoring of vocal health.", "AI": {"tldr": "\u63d0\u51fa\u5206\u5c42\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u58f0\u5b66\u7279\u5f81\u81ea\u52a8\u5206\u7c7b\u516b\u79cd\u826f\u6027\u5589\u90e8\u75be\u75c5\u548c\u5065\u5eb7\u5bf9\u7167\uff0c\u5728\u4e09\u4e2a\u4e34\u5e8a\u9636\u6bb5\u4e2d\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u548c\u53ef\u89e3\u91ca\u7279\u5f81\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u591a\u5206\u7c7b\u5668\u3002", "motivation": "\u826f\u6027\u5589\u90e8\u75be\u75c5\u5f71\u54cd\u8fd1\u4e94\u5206\u4e4b\u4e00\u4eba\u7fa4\uff0c\u8868\u73b0\u4e3a\u53d1\u58f0\u969c\u788d\uff0c\u540c\u65f6\u53ef\u4f5c\u4e3a\u66f4\u5e7f\u6cdb\u751f\u7406\u529f\u80fd\u969c\u788d\u7684\u975e\u4fb5\u5165\u6027\u6307\u6807\u3002\u9700\u8981\u81ea\u52a8\u5316\u5206\u7c7b\u5de5\u5177\u6765\u8f85\u52a9\u4e34\u5e8a\u7b5b\u67e5\u548c\u8bca\u65ad\u3002", "method": "\u91c7\u7528\u4e34\u5e8a\u542f\u53d1\u7684\u5206\u5c42\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff1a\u7b2c\u4e00\u9636\u6bb5\u7ed3\u5408CNN\u63d0\u53d6\u7684\u6885\u5c14\u9891\u8c31\u7279\u5f81\u548c21\u4e2a\u53ef\u89e3\u91ca\u58f0\u5b66\u751f\u7269\u6807\u5fd7\u7269\u8fdb\u884c\u75c5\u7406/\u975e\u75c5\u7406\u4e8c\u5143\u7b5b\u67e5\uff1b\u7b2c\u4e8c\u9636\u6bb5\u4f7f\u7528\u7acb\u65b9\u652f\u6301\u5411\u91cf\u673a\u5c06\u58f0\u97f3\u5206\u4e3a\u5065\u5eb7\u3001\u529f\u80fd\u6027/\u5fc3\u56e0\u6027\u3001\u7ed3\u6784\u6027/\u708e\u75c7\u6027\u4e09\u7ec4\uff1b\u7b2c\u4e09\u9636\u6bb5\u7ed3\u5408\u524d\u4e24\u9636\u6bb5\u7684\u6982\u7387\u8f93\u51fa\u8fdb\u884c\u7ec6\u7c92\u5ea6\u5206\u7c7b\u3002", "result": "\u5728Saarbruecken\u8bed\u97f3\u6570\u636e\u5e93\u768415,132\u4e2a\u5f55\u97f3\u4e0a\u6d4b\u8bd5\uff0c\u6846\u67b6\u6027\u80fd\u4f18\u4e8e\u5e73\u9762\u591a\u5206\u7c7b\u5668\u548c\u9884\u8bad\u7ec3\u81ea\u76d1\u7763\u6a21\u578b\uff08\u5982META HuBERT\u548cGoogle HeAR\uff09\uff0c\u5728\u7ed3\u6784\u6027/\u708e\u75c7\u6027\u75be\u75c5\u4e0e\u529f\u80fd\u6027\u75be\u75c5\u7684\u533a\u5206\u4e0a\u8868\u73b0\u66f4\u597d\u3002", "conclusion": "\u7ed3\u5408\u6df1\u5ea6\u9891\u8c31\u8868\u793a\u548c\u53ef\u89e3\u91ca\u58f0\u5b66\u7279\u5f81\u7684\u5206\u5c42\u6846\u67b6\u589e\u5f3a\u4e86\u900f\u660e\u5ea6\u548c\u4e34\u5e8a\u4e00\u81f4\u6027\uff0c\u5c55\u793a\u4e86\u5b9a\u91cf\u58f0\u5b66\u751f\u7269\u6807\u5fd7\u7269\u4f5c\u4e3a\u53ef\u6269\u5c55\u3001\u975e\u4fb5\u5165\u6027\u5de5\u5177\u5728\u65e9\u671f\u7b5b\u67e5\u3001\u8bca\u65ad\u5206\u8bca\u548c\u58f0\u5e26\u5065\u5eb7\u7eb5\u5411\u76d1\u6d4b\u65b9\u9762\u7684\u6f5c\u529b\u3002"}}
{"id": "2512.24488", "categories": ["eess.SP", "cs.IT", "quant-ph"], "pdf": "https://arxiv.org/pdf/2512.24488", "abs": "https://arxiv.org/abs/2512.24488", "authors": ["Erik Lentz", "Emily Ellwein", "Bill Kay", "Audun Myers", "Cameron Mackenzie"], "title": "The Wigner-Ville Transform as an Information Theoretic Tool in Radio-frequency Signal Analysis", "comment": "12 pages, 11 figures", "summary": "This paper presents novel interpretations to the field of classical signal processing of the Wigner-Ville transform as an information measurement tool. The transform's utility in detecting and localizing information-laden signals amidst noisy and cluttered backgrounds, and further providing measure of their information volumes, are detailed herein using Tsallis' entropy and information and related functionals. Example use cases in radio frequency communications are given, where Wigner-Ville-based detection measures can be seen to provide significant sensitivity advantage, for some shown contexts greater than 15~dB advantage, over energy-based measures and without extensive training routines. Such an advantage is particularly significant for applications which have limitations on observation resources including time/space integration pressures and transient and/or feeble signals, where Wigner-Ville-based methods would improve sensing effectiveness by multiple orders of magnitude. The potential for advancement of several such applications is discussed.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5c06Wigner-Ville\u53d8\u6362\u4f5c\u4e3a\u4fe1\u606f\u6d4b\u91cf\u5de5\u5177\u7684\u65b0\u89e3\u91ca\uff0c\u4f7f\u7528Tsallis\u71b5\u548c\u4fe1\u606f\u6cdb\u51fd\u5728\u566a\u58f0\u548c\u6742\u6ce2\u80cc\u666f\u4e0b\u68c0\u6d4b\u548c\u5b9a\u4f4d\u4fe1\u606f\u4fe1\u53f7\uff0c\u5728\u5c04\u9891\u901a\u4fe1\u4e2d\u76f8\u6bd4\u80fd\u91cf\u68c0\u6d4b\u65b9\u6cd5\u5177\u6709\u8d85\u8fc715dB\u7684\u7075\u654f\u5ea6\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u4fe1\u53f7\u5904\u7406\u4e2d\uff0cWigner-Ville\u53d8\u6362\u4e3b\u8981\u7528\u4e8e\u65f6\u9891\u5206\u6790\uff0c\u4f46\u672c\u6587\u63a2\u7d22\u5176\u4f5c\u4e3a\u4fe1\u606f\u6d4b\u91cf\u5de5\u5177\u7684\u6f5c\u529b\uff0c\u7279\u522b\u662f\u5728\u8d44\u6e90\u53d7\u9650\uff08\u65f6\u95f4/\u7a7a\u95f4\u79ef\u5206\u538b\u529b\uff09\u548c\u77ac\u6001/\u5fae\u5f31\u4fe1\u53f7\u573a\u666f\u4e0b\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u5c06Wigner-Ville\u53d8\u6362\u4e0eTsallis\u71b5\u548c\u4fe1\u606f\u6cdb\u51fd\u76f8\u7ed3\u5408\uff0c\u6784\u5efa\u57fa\u4e8e\u4fe1\u606f\u7406\u8bba\u7684\u68c0\u6d4b\u5ea6\u91cf\uff0c\u7528\u4e8e\u5728\u566a\u58f0\u548c\u6742\u6ce2\u80cc\u666f\u4e0b\u8bc6\u522b\u548c\u5b9a\u4f4d\u4fe1\u606f\u4fe1\u53f7\uff0c\u5e76\u6d4b\u91cf\u5176\u4fe1\u606f\u4f53\u79ef\u3002", "result": "\u5728\u5c04\u9891\u901a\u4fe1\u5e94\u7528\u4e2d\uff0c\u57fa\u4e8eWigner-Ville\u7684\u68c0\u6d4b\u65b9\u6cd5\u76f8\u6bd4\u80fd\u91cf\u68c0\u6d4b\u65b9\u6cd5\u663e\u793a\u51fa\u663e\u8457\u7075\u654f\u5ea6\u4f18\u52bf\uff0c\u5728\u67d0\u4e9b\u573a\u666f\u4e0b\u8d85\u8fc715dB\uff0c\u4e14\u65e0\u9700\u5927\u91cf\u8bad\u7ec3\u8fc7\u7a0b\uff0c\u7279\u522b\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u89c2\u6d4b\u73af\u5883\u3002", "conclusion": "Wigner-Ville\u53d8\u6362\u4f5c\u4e3a\u4fe1\u606f\u6d4b\u91cf\u5de5\u5177\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\uff0c\u80fd\u591f\u663e\u8457\u63d0\u5347\u5728\u566a\u58f0\u548c\u6742\u6ce2\u80cc\u666f\u4e0b\u68c0\u6d4b\u5fae\u5f31\u548c\u77ac\u6001\u4fe1\u53f7\u7684\u80fd\u529b\uff0c\u4e3a\u591a\u4e2a\u5e94\u7528\u9886\u57df\u5e26\u6765\u6570\u91cf\u7ea7\u7684\u6548\u679c\u6539\u8fdb\u3002"}}
{"id": "2512.24645", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.24645", "abs": "https://arxiv.org/abs/2512.24645", "authors": ["Cheng Zhu", "Jing Han", "Qianshuai Xue", "Kehan Wang", "Huan Zhao", "Zixing Zhang"], "title": "AudioFab: Building A General and Intelligent Audio Factory through Tool Learning", "comment": null, "summary": "Currently, artificial intelligence is profoundly transforming the audio domain; however, numerous advanced algorithms and tools remain fragmented, lacking a unified and efficient framework to unlock their full potential. Existing audio agent frameworks often suffer from complex environment configurations and inefficient tool collaboration. To address these limitations, we introduce AudioFab, an open-source agent framework aimed at establishing an open and intelligent audio-processing ecosystem. Compared to existing solutions, AudioFab's modular design resolves dependency conflicts, simplifying tool integration and extension. It also optimizes tool learning through intelligent selection and few-shot learning, improving efficiency and accuracy in complex audio tasks. Furthermore, AudioFab provides a user-friendly natural language interface tailored for non-expert users. As a foundational framework, AudioFab's core contribution lies in offering a stable and extensible platform for future research and development in audio and multimodal AI. The code is available at https://github.com/SmileHnu/AudioFab.", "AI": {"tldr": "AudioFab\u662f\u4e00\u4e2a\u5f00\u6e90\u7684\u97f3\u9891\u4ee3\u7406\u6846\u67b6\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709\u97f3\u9891AI\u5de5\u5177\u788e\u7247\u5316\u3001\u914d\u7f6e\u590d\u6742\u548c\u534f\u4f5c\u6548\u7387\u4f4e\u7684\u95ee\u9898\uff0c\u901a\u8fc7\u6a21\u5757\u5316\u8bbe\u8ba1\u548c\u667a\u80fd\u5de5\u5177\u9009\u62e9\u5efa\u7acb\u7edf\u4e00\u7684\u97f3\u9891\u5904\u7406\u751f\u6001\u7cfb\u7edf\u3002", "motivation": "\u5f53\u524d\u4eba\u5de5\u667a\u80fd\u6b63\u5728\u6df1\u523b\u6539\u53d8\u97f3\u9891\u9886\u57df\uff0c\u4f46\u8bb8\u591a\u5148\u8fdb\u7b97\u6cd5\u548c\u5de5\u5177\u4ecd\u7136\u5206\u6563\uff0c\u7f3a\u4e4f\u7edf\u4e00\u9ad8\u6548\u7684\u6846\u67b6\u6765\u5145\u5206\u53d1\u6325\u5176\u6f5c\u529b\u3002\u73b0\u6709\u7684\u97f3\u9891\u4ee3\u7406\u6846\u67b6\u901a\u5e38\u5b58\u5728\u73af\u5883\u914d\u7f6e\u590d\u6742\u548c\u5de5\u5177\u534f\u4f5c\u6548\u7387\u4f4e\u7684\u95ee\u9898\u3002", "method": "AudioFab\u91c7\u7528\u6a21\u5757\u5316\u8bbe\u8ba1\u89e3\u51b3\u4f9d\u8d56\u51b2\u7a81\uff0c\u7b80\u5316\u5de5\u5177\u96c6\u6210\u548c\u6269\u5c55\uff1b\u901a\u8fc7\u667a\u80fd\u9009\u62e9\u548c\u5c11\u6837\u672c\u5b66\u4e60\u4f18\u5316\u5de5\u5177\u5b66\u4e60\uff1b\u63d0\u4f9b\u9762\u5411\u975e\u4e13\u4e1a\u7528\u6237\u7684\u81ea\u7136\u8bed\u8a00\u53cb\u597d\u754c\u9762\u3002", "result": "AudioFab\u4f5c\u4e3a\u4e00\u4e2a\u57fa\u7840\u6846\u67b6\uff0c\u4e3a\u97f3\u9891\u548c\u591a\u6a21\u6001AI\u7684\u672a\u6765\u7814\u7a76\u548c\u5f00\u53d1\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7a33\u5b9a\u4e14\u53ef\u6269\u5c55\u7684\u5e73\u53f0\uff0c\u4ee3\u7801\u5df2\u5728GitHub\u5f00\u6e90\u3002", "conclusion": "AudioFab\u901a\u8fc7\u5efa\u7acb\u5f00\u653e\u667a\u80fd\u7684\u97f3\u9891\u5904\u7406\u751f\u6001\u7cfb\u7edf\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u97f3\u9891\u4ee3\u7406\u6846\u67b6\u7684\u5c40\u9650\u6027\uff0c\u4e3a\u97f3\u9891AI\u9886\u57df\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7edf\u4e00\u3001\u9ad8\u6548\u4e14\u6613\u4e8e\u4f7f\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.24573", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.24573", "abs": "https://arxiv.org/abs/2512.24573", "authors": ["Lei Li", "Yanqing Xu", "Tenghao Cai", "Tsung-Hui Chang"], "title": "Power Minimization in Pinching-Antenna Systems under Probabilistic LoS Blockage", "comment": null, "summary": "With great flexibility to adjust antenna positions, pinching antennas (PAs) are promising for alleviating large-scale attenuation in wireless networks. In this work, we investigate the antenna positioning and beamforming (AP-BF) design in a multi-PA multi-user system under probabilistic light-of-sight (LoS) blockage and formulate a power minimization problem subject to per-user signal-to-noise ratio (SNR) constraints. For a single PA, we prove the convexity of the simplified problem and obtain its global optimum. For multiple PAs, we derive closed-form BF structures and develop an efficient first-order algorithm to achieve high-quality local solutions. Extensive numerical results validate the efficacy of our proposed designs and the substantial performance advantage of PA systems compared with conventional fixed-antenna systems in a term of power saving.", "AI": {"tldr": "\u7814\u7a76\u591aPinching\u5929\u7ebf\u7cfb\u7edf\u4e2d\u7684\u5929\u7ebf\u5b9a\u4f4d\u4e0e\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\uff0c\u5728\u6982\u7387\u89c6\u8ddd\u963b\u585e\u6761\u4ef6\u4e0b\u6700\u5c0f\u5316\u529f\u7387\uff0c\u76f8\u6bd4\u4f20\u7edf\u56fa\u5b9a\u5929\u7ebf\u7cfb\u7edf\u663e\u8457\u8282\u7701\u529f\u7387", "motivation": "Pinching\u5929\u7ebf\u5177\u6709\u7075\u6d3b\u8c03\u6574\u5929\u7ebf\u4f4d\u7f6e\u7684\u80fd\u529b\uff0c\u6709\u671b\u7f13\u89e3\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u5927\u89c4\u6a21\u8870\u51cf\u95ee\u9898\u3002\u4f20\u7edf\u56fa\u5b9a\u5929\u7ebf\u7cfb\u7edf\u5728\u89c6\u8ddd\u963b\u585e\u60c5\u51b5\u4e0b\u6027\u80fd\u53d7\u9650\uff0c\u9700\u8981\u7814\u7a76\u66f4\u7075\u6d3b\u7684\u5929\u7ebf\u5b9a\u4f4d\u65b9\u6848\u6765\u4f18\u5316\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u9488\u5bf9\u5355\u5929\u7ebf\u7cfb\u7edf\uff0c\u8bc1\u660e\u4e86\u7b80\u5316\u95ee\u9898\u7684\u51f8\u6027\u5e76\u83b7\u5f97\u4e86\u5168\u5c40\u6700\u4f18\u89e3\uff1b\u9488\u5bf9\u591a\u5929\u7ebf\u7cfb\u7edf\uff0c\u63a8\u5bfc\u4e86\u95ed\u5f0f\u6ce2\u675f\u6210\u5f62\u7ed3\u6784\uff0c\u5e76\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u4e00\u9636\u7b97\u6cd5\u6765\u83b7\u5f97\u9ad8\u8d28\u91cf\u7684\u5c40\u90e8\u89e3\u3002", "result": "\u5e7f\u6cdb\u7684\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u8bbe\u8ba1\u7684\u6709\u6548\u6027\uff0c\u5e76\u663e\u793aPinching\u5929\u7ebf\u7cfb\u7edf\u76f8\u6bd4\u4f20\u7edf\u56fa\u5b9a\u5929\u7ebf\u7cfb\u7edf\u5728\u529f\u7387\u8282\u7701\u65b9\u9762\u5177\u6709\u663e\u8457\u6027\u80fd\u4f18\u52bf\u3002", "conclusion": "Pinching\u5929\u7ebf\u7cfb\u7edf\u901a\u8fc7\u7075\u6d3b\u7684\u5929\u7ebf\u5b9a\u4f4d\u548c\u4f18\u5316\u7684\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9\u89c6\u8ddd\u963b\u585e\u95ee\u9898\uff0c\u663e\u8457\u964d\u4f4e\u7cfb\u7edf\u529f\u8017\uff0c\u4e3a\u65e0\u7ebf\u7f51\u7edc\u63d0\u4f9b\u4e86\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.24739", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2512.24739", "abs": "https://arxiv.org/abs/2512.24739", "authors": ["Yuan-Kuei Wu", "Yang Liu", "Yiteng Huang", "Zhaojun Yang", "Haibin Wu", "Ruizhe Huang", "Yi-Te", "Hsu", "Shuyu Kong", "Ming Sun", "Florian Metze", "Li Wan"], "title": "SLM-TTA: A Framework for Test-Time Adaptation of Generative Spoken Language Models", "comment": null, "summary": "Spoken Language Models (SLMs) are increasingly central to modern speech-driven applications, but performance degrades under acoustic shift - real-world noise, reverberation, and microphone variation. Prior solutions rely on offline domain adaptation, which is post-hoc, data-intensive, and slow. We introduce the first test-time adaptation (TTA) framework for generative SLMs that process interleaved audio-text prompts. Our method updates a small, targeted subset of parameters during inference using only the incoming utterance, requiring no source data or labels. This stabilizes token distributions and improves robustness to acoustic variability without degrading core task accuracy. Evaluated on automatic speech recognition, speech translation, and 19 audio understanding tasks from AIR-Bench, our approach yields consistent gains under diverse corruptions. Because adaptation touches only a small fraction of weights, it is both compute- and memory-efficient, supporting deployment on resource-constrained platforms. This work enhances the robustness and adaptability of generative SLMs for real-world speech-driven applications.", "AI": {"tldr": "\u9996\u4e2a\u9488\u5bf9\u751f\u6210\u5f0f\u53e3\u8bed\u8bed\u8a00\u6a21\u578b\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u901a\u8fc7\u4ec5\u66f4\u65b0\u5c11\u91cf\u53c2\u6570\u6765\u63d0\u5347\u58f0\u5b66\u53d8\u5316\u4e0b\u7684\u9c81\u68d2\u6027\uff0c\u65e0\u9700\u6e90\u6570\u636e\u6216\u6807\u7b7e\u3002", "motivation": "\u53e3\u8bed\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u9645\u5e94\u7528\u4e2d\u9762\u4e34\u58f0\u5b66\u53d8\u5316\uff08\u566a\u58f0\u3001\u6df7\u54cd\u3001\u9ea6\u514b\u98ce\u5dee\u5f02\uff09\u5bfc\u81f4\u7684\u6027\u80fd\u4e0b\u964d\u95ee\u9898\uff0c\u73b0\u6709\u79bb\u7ebf\u57df\u81ea\u9002\u5e94\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6570\u636e\u4e14\u901f\u5ea6\u6162\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5b9e\u65f6\u81ea\u9002\u5e94\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u9996\u4e2a\u751f\u6210\u5f0f\u53e3\u8bed\u8bed\u8a00\u6a21\u578b\u7684\u6d4b\u8bd5\u65f6\u81ea\u9002\u5e94\u6846\u67b6\uff0c\u4ec5\u4f7f\u7528\u8f93\u5165\u8bed\u97f3\u66f4\u65b0\u5c11\u91cf\u76ee\u6807\u53c2\u6570\uff0c\u65e0\u9700\u6e90\u6570\u636e\u6216\u6807\u7b7e\uff0c\u7a33\u5b9atoken\u5206\u5e03\u5e76\u63d0\u5347\u58f0\u5b66\u9c81\u68d2\u6027\u3002", "result": "\u5728\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u3001\u8bed\u97f3\u7ffb\u8bd1\u548cAIR-Bench\u768419\u4e2a\u97f3\u9891\u7406\u89e3\u4efb\u52a1\u4e0a\uff0c\u8be5\u65b9\u6cd5\u5728\u5404\u79cd\u58f0\u5b66\u5e72\u6270\u4e0b\u5747\u53d6\u5f97\u4e00\u81f4\u6027\u80fd\u63d0\u5347\uff0c\u4e14\u8ba1\u7b97\u548c\u5185\u5b58\u6548\u7387\u9ad8\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u901a\u8fc7\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u673a\u5236\u589e\u5f3a\u4e86\u751f\u6210\u5f0f\u53e3\u8bed\u8bed\u8a00\u6a21\u578b\u5728\u73b0\u5b9e\u4e16\u754c\u8bed\u97f3\u5e94\u7528\u4e2d\u7684\u9c81\u68d2\u6027\u548c\u9002\u5e94\u6027\uff0c\u652f\u6301\u5728\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u90e8\u7f72\u3002"}}
{"id": "2512.24583", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.24583", "abs": "https://arxiv.org/abs/2512.24583", "authors": ["Rahul Gulia", "Ashish Sheikh", "Feyisayo Favour Popoola", "Serisha Vadlamudi"], "title": "Resource Allocation via Backscatter-Aware Transmit Antenna Selection for Low-PAPR and Ultra-Reliable WSNs", "comment": null, "summary": "This paper addresses a fundamental physical layer conflict in hybrid Wireless Sensor Networks (WSNs) between high-throughput primary communication and the stringent power envelope requirements of passive backscatter sensors. We propose a Backscatter-Constrained Transmit Antenna Selection (BC-TAS) framework, a per-subcarrier selection strategy for multi-antenna illuminators operating within a Multi-Dimensional Orthogonal Frequency Division Multiplexing (MD-OFDM) architecture. Unlike conventional signal-to-noise ratio (SNR) centric selection schemes, BC-TAS employs a multi-objective cost function that jointly maximizes desired link reliability, stabilizes the incident RF energy envelope at passive Surface Acoustic Wave (SAW) sensors, and suppresses interference toward coexisting victim receivers. By exploiting the inherent sparsity of MD-OFDM, the proposed framework enables dual-envelope regulation, simultaneously reducing the transmitter Peak-to-Average Power Ratio (PAPR) and the Backscatter Crest Factor (BCF) observed at the tag. To enhance robustness under imperfect Channel State Information (CSI), a Kalman-based channel smoothing mechanism is incorporated to maintain selection stability in low-SNR regimes. Numerical results using IEEE 802.11be dispersive channel models and a nonlinear Rapp power amplifier demonstrate that BC-TAS achieves orders-of-magnitude improvement in outage probability and significant gains in energy efficiency compared to conventional MU-MIMO baselines, while ensuring spectral mask compliance under reduced power amplifier back-off. These results establish BC-TAS as an effective illuminator-side control mechanism for enabling reliable and energy-stable sensing and communication coexistence in dense, power-constrained wireless environments.", "AI": {"tldr": "\u63d0\u51faBC-TAS\u6846\u67b6\uff0c\u89e3\u51b3\u6df7\u5408WSN\u4e2d\u9ad8\u541e\u5410\u91cf\u901a\u4fe1\u4e0e\u88ab\u52a8\u80cc\u5411\u6563\u5c04\u4f20\u611f\u5668\u529f\u7387\u9650\u5236\u7684\u51b2\u7a81\uff0c\u901a\u8fc7\u591a\u5929\u7ebf\u9009\u62e9\u7b56\u7565\u5b9e\u73b0\u53cc\u5305\u7edc\u8c03\u8282\uff0c\u663e\u8457\u63d0\u5347\u80fd\u6548\u548c\u53ef\u9760\u6027\u3002", "motivation": "\u89e3\u51b3\u6df7\u5408\u65e0\u7ebf\u4f20\u611f\u5668\u7f51\u7edc\u4e2d\u9ad8\u541e\u5410\u91cf\u4e3b\u901a\u4fe1\u4e0e\u88ab\u52a8\u80cc\u5411\u6563\u5c04\u4f20\u611f\u5668\u4e25\u683c\u529f\u7387\u8981\u6c42\u4e4b\u95f4\u7684\u7269\u7406\u5c42\u51b2\u7a81\uff0c\u5b9e\u73b0\u53ef\u9760\u4e14\u80fd\u91cf\u7a33\u5b9a\u7684\u4f20\u611f\u4e0e\u901a\u4fe1\u5171\u5b58\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u80cc\u5411\u6563\u5c04\u7ea6\u675f\u7684\u53d1\u5c04\u5929\u7ebf\u9009\u62e9\uff08BC-TAS\uff09\u6846\u67b6\uff0c\u91c7\u7528\u591a\u76ee\u6807\u6210\u672c\u51fd\u6570\u8054\u5408\u4f18\u5316\u94fe\u8def\u53ef\u9760\u6027\u3001\u7a33\u5b9a\u88ab\u52a8SAW\u4f20\u611f\u5668\u7684\u5165\u5c04RF\u80fd\u91cf\u5305\u7edc\u3001\u6291\u5236\u5e72\u6270\uff0c\u5e76\u5229\u7528MD-OFDM\u7a00\u758f\u6027\u5b9e\u73b0\u53cc\u5305\u7edc\u8c03\u8282\uff0c\u7ed3\u5408\u5361\u5c14\u66fc\u4fe1\u9053\u5e73\u6ed1\u589e\u5f3aCSI\u4e0d\u5b8c\u7f8e\u65f6\u7684\u9c81\u68d2\u6027\u3002", "result": "\u5728IEEE 802.11be\u4fe1\u9053\u6a21\u578b\u548c\u975e\u7ebf\u6027Rapp\u529f\u653e\u4e0b\uff0cBC-TAS\u76f8\u6bd4\u4f20\u7edfMU-MIMO\u57fa\u7ebf\u5b9e\u73b0\u4e86\u6570\u91cf\u7ea7\u7684\u4e2d\u65ad\u6982\u7387\u6539\u8fdb\u548c\u663e\u8457\u7684\u80fd\u6548\u63d0\u5347\uff0c\u540c\u65f6\u786e\u4fdd\u5728\u964d\u4f4e\u529f\u653e\u56de\u9000\u4e0b\u7684\u9891\u8c31\u63a9\u6a21\u5408\u89c4\u6027\u3002", "conclusion": "BC-TAS\u4f5c\u4e3a\u6709\u6548\u7684\u7167\u660e\u5668\u4fa7\u63a7\u5236\u673a\u5236\uff0c\u80fd\u591f\u5728\u5bc6\u96c6\u3001\u529f\u7387\u53d7\u9650\u7684\u65e0\u7ebf\u73af\u5883\u4e2d\u5b9e\u73b0\u53ef\u9760\u4e14\u80fd\u91cf\u7a33\u5b9a\u7684\u4f20\u611f\u4e0e\u901a\u4fe1\u5171\u5b58\u3002"}}
{"id": "2512.24624", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2512.24624", "abs": "https://arxiv.org/abs/2512.24624", "authors": ["Borui Du", "Yumeng Zhang", "Christos Masouros", "Bruno Clerckx"], "title": "A Uniform Pilot and Data Payload Optimization Framework for OTFS-Based ISAC", "comment": null, "summary": "The orthogonal time frequency space (OTFS) signal is considered a promising solution for high-mobility wireless environments. It manages Doppler effects by utilizing delay-Doppler (DD) domain processing. However, the relatively long OTFS frame duration could introduce considerable sensing or communication latency when radar and communication are performed separately. By operating in a dual-functional radar and communication (DFRC) mode, the OTFS system performs sensing and data transmission simultaneously, thereby reducing the resulting latency. Nevertheless, the optimal OTFS DFRC signal strategy remains insufficiently explored. This paper investigates the optimal signal design for OTFS DFRC systems, focusing on pilot symbol design and data symbol power allocation. Specifically, we derive a channel capacity lower bound metric for communication that considers channel estimation errors in OTFS. For sensing, we derive an integrated sidelobe level (ISL), accounting for the randomness of the data symbols alongside the deterministic pilot symbols. Leveraging the above metrics, we formulate an optimization problem that balances radar and communication performance, and then solve it using an alternating optimization framework. We validate the proposed signal through numerical analysis and Monte Carlo simulations. Our analysis shows that OTFS DFRC enforces a deterministic pilot signal that is characterized by a concentrated peak in the DD domain, which furnishes a common structure in the DD domain facilitating sensing and channel estimation, with data multiplexed in other DD grids, thereby unifying sensing and communication within a single OTFS signal. Compared with conventional OTFS signals, the proposed OTFS DFRC signal expands the achievable sensing-communication performance region, delivering at least a 9.45 dB ISL suppression for sensing and a 4.82 dB SINR ratio gain for communication.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76OTFS\u53cc\u529f\u80fd\u96f7\u8fbe\u901a\u4fe1\u7cfb\u7edf\u7684\u6700\u4f18\u4fe1\u53f7\u8bbe\u8ba1\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\u5e73\u8861\u96f7\u8fbe\u4e0e\u901a\u4fe1\u6027\u80fd\uff0c\u76f8\u6bd4\u4f20\u7edfOTFS\u4fe1\u53f7\u663e\u8457\u63d0\u5347\u6027\u80fd\u3002", "motivation": "OTFS\u4fe1\u53f7\u5728\u9ad8\u79fb\u52a8\u6027\u65e0\u7ebf\u73af\u5883\u4e2d\u5177\u6709\u4f18\u52bf\uff0c\u4f46\u957f\u5e27\u6301\u7eed\u65f6\u95f4\u4f1a\u5bfc\u81f4\u611f\u77e5\u6216\u901a\u4fe1\u5ef6\u8fdf\u3002\u901a\u8fc7\u53cc\u529f\u80fd\u96f7\u8fbe\u901a\u4fe1\u6a21\u5f0f\u53ef\u4ee5\u540c\u65f6\u8fdb\u884c\u611f\u77e5\u548c\u6570\u636e\u4f20\u8f93\uff0c\u51cf\u5c11\u5ef6\u8fdf\uff0c\u4f46\u6700\u4f18\u4fe1\u53f7\u8bbe\u8ba1\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51faOTFS DFRC\u7cfb\u7edf\u7684\u6700\u4f18\u4fe1\u53f7\u8bbe\u8ba1\u65b9\u6cd5\uff0c\u5305\u62ec\u5bfc\u9891\u7b26\u53f7\u8bbe\u8ba1\u548c\u6570\u636e\u7b26\u53f7\u529f\u7387\u5206\u914d\u3002\u63a8\u5bfc\u8003\u8651\u4fe1\u9053\u4f30\u8ba1\u8bef\u5dee\u7684\u901a\u4fe1\u5bb9\u91cf\u4e0b\u754c\u6307\u6807\uff0c\u4ee5\u53ca\u8003\u8651\u6570\u636e\u7b26\u53f7\u968f\u673a\u6027\u7684\u96f7\u8fbe\u7efc\u5408\u65c1\u74e3\u6c34\u5e73\u6307\u6807\u3002\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\u89e3\u51b3\u5e73\u8861\u96f7\u8fbe\u4e0e\u901a\u4fe1\u6027\u80fd\u7684\u4f18\u5316\u95ee\u9898\u3002", "result": "OTFS DFRC\u4fe1\u53f7\u5728\u65f6\u5ef6\u591a\u666e\u52d2\u57df\u5177\u6709\u96c6\u4e2d\u5cf0\u503c\u7684\u786e\u5b9a\u6027\u5bfc\u9891\u4fe1\u53f7\uff0c\u4e3a\u611f\u77e5\u548c\u4fe1\u9053\u4f30\u8ba1\u63d0\u4f9b\u5171\u540c\u7ed3\u6784\u3002\u76f8\u6bd4\u4f20\u7edfOTFS\u4fe1\u53f7\uff0c\u81f3\u5c11\u5b9e\u73b09.45 dB\u7684ISL\u6291\u5236\uff08\u611f\u77e5\uff09\u548c4.82 dB\u7684SINR\u589e\u76ca\uff08\u901a\u4fe1\uff09\uff0c\u6269\u5c55\u4e86\u611f\u77e5-\u901a\u4fe1\u6027\u80fd\u533a\u57df\u3002", "conclusion": "OTFS DFRC\u7cfb\u7edf\u901a\u8fc7\u4f18\u5316\u4fe1\u53f7\u8bbe\u8ba1\uff0c\u5728\u5355\u4e00OTFS\u4fe1\u53f7\u4e2d\u7edf\u4e00\u611f\u77e5\u548c\u901a\u4fe1\u529f\u80fd\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u9ad8\u79fb\u52a8\u6027\u73af\u5883\u4e0b\u7684\u53cc\u529f\u80fd\u7cfb\u7edf\u63d0\u4f9b\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2512.24727", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.24727", "abs": "https://arxiv.org/abs/2512.24727", "authors": ["Jaehong Jo", "Jihun Park", "Yo-Seb Jeon", "H. Vincent Poor"], "title": "Beam-Squint-Aided Hierarchical Sensing for Integrated Sensing and Communications with Uniform Planar Arrays", "comment": null, "summary": "In this paper, we propose a novel hierarchical sensing framework for wideband integrated sensing and communications with uniform planar arrays (UPAs). Leveraging the beam-squint effect inherent in wideband orthogonal frequency-division multiplexing (OFDM) systems, the proposed framework enables efficient two-dimensional angle estimation through a structured multi-stage sensing process. Specifically, the sensing procedure first searches over the elevation angle domain, followed by a dedicated search over the azimuth angle domain given the estimated elevation angles. In each stage, true-time-delay lines and phase shifters of the UPA are jointly configured to cover multiple grid points simultaneously across OFDM subcarriers. To enable accurate and efficient target localization, we formulate the angle estimation problem as a sparse signal recovery problem and develop a modified matching pursuit algorithm tailored to the hierarchical sensing architecture. Additionally, we design power allocation strategies that minimize total transmit power while meeting performance requirements for both sensing and communication. Numerical results demonstrate that the proposed framework achieves superior performance over conventional sensing methods with reduced sensing power.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u5bbd\u5e26\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7684\u5c42\u6b21\u5316\u611f\u77e5\u6846\u67b6\uff0c\u5229\u7528\u6ce2\u675f\u503e\u659c\u6548\u5e94\u5b9e\u73b0\u9ad8\u6548\u4e8c\u7ef4\u89d2\u5ea6\u4f30\u8ba1\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u7ed3\u6784\u5316\u611f\u77e5\u8fc7\u7a0b\u964d\u4f4e\u611f\u77e5\u529f\u8017\u3002", "motivation": "\u5bbd\u5e26OFDM\u7cfb\u7edf\u4e2d\u7684\u6ce2\u675f\u503e\u659c\u6548\u5e94\u901a\u5e38\u88ab\u89c6\u4e3a\u4e0d\u5229\u56e0\u7d20\uff0c\u4f46\u672c\u6587\u5229\u7528\u8fd9\u4e00\u6548\u5e94\u5b9e\u73b0\u9ad8\u6548\u7684\u4e8c\u7ef4\u89d2\u5ea6\u4f30\u8ba1\uff0c\u65e8\u5728\u964d\u4f4e\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u7684\u611f\u77e5\u529f\u8017\u5e76\u63d0\u9ad8\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u5c42\u6b21\u5316\u611f\u77e5\u6846\u67b6\uff1a\u5148\u641c\u7d22\u4fef\u4ef0\u89d2\u57df\uff0c\u518d\u57fa\u4e8e\u4f30\u8ba1\u7684\u4fef\u4ef0\u89d2\u641c\u7d22\u65b9\u4f4d\u89d2\u57df\uff1b\u8054\u5408\u914d\u7f6eUPA\u7684\u771f\u65f6\u5ef6\u7ebf\u548c\u79fb\u76f8\u5668\uff0c\u5728OFDM\u5b50\u8f7d\u6ce2\u4e0a\u540c\u65f6\u8986\u76d6\u591a\u4e2a\u7f51\u683c\u70b9\uff1b\u5c06\u89d2\u5ea6\u4f30\u8ba1\u95ee\u9898\u5efa\u6a21\u4e3a\u7a00\u758f\u4fe1\u53f7\u6062\u590d\u95ee\u9898\uff0c\u5f00\u53d1\u4e86\u9488\u5bf9\u5c42\u6b21\u5316\u67b6\u6784\u7684\u6539\u8fdb\u5339\u914d\u8ffd\u8e2a\u7b97\u6cd5\uff1b\u8bbe\u8ba1\u4e86\u6700\u5c0f\u5316\u603b\u53d1\u5c04\u529f\u7387\u7684\u529f\u7387\u5206\u914d\u7b56\u7565\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u6846\u67b6\u76f8\u6bd4\u4f20\u7edf\u611f\u77e5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u6027\u80fd\uff0c\u540c\u65f6\u51cf\u5c11\u4e86\u611f\u77e5\u529f\u8017\u3002", "conclusion": "\u63d0\u51fa\u7684\u5c42\u6b21\u5316\u611f\u77e5\u6846\u67b6\u6709\u6548\u5229\u7528\u4e86\u5bbd\u5e26\u7cfb\u7edf\u4e2d\u7684\u6ce2\u675f\u503e\u659c\u6548\u5e94\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u591a\u9636\u6bb5\u611f\u77e5\u8fc7\u7a0b\u548c\u4f18\u5316\u7684\u529f\u7387\u5206\u914d\uff0c\u5728\u964d\u4f4e\u529f\u8017\u7684\u540c\u65f6\u63d0\u9ad8\u4e86\u4e8c\u7ef4\u89d2\u5ea6\u4f30\u8ba1\u6027\u80fd\u3002"}}
{"id": "2512.24788", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.24788", "abs": "https://arxiv.org/abs/2512.24788", "authors": ["Zhixu Wang", "Jiacheng Yao", "Wei Xu", "Wei Shi", "Kaibin Huang"], "title": "Digitalizing Over-the-Air Computation via The Novel Complement Coded Modulation", "comment": null, "summary": "To overcome inherent limitations of analog signals in over-the-air computation (AirComp), this letter proposes a two's complement-based coding scheme for the AirComp implementation with compatible digital modulations. Specifically, quantized discrete values are encoded into binary sequences using the two's complement and transmitted over multiple subcarriers. At the receiver, we design a decoder that constructs a functional mapping between the superimposed digital modulation signals and the target of computational results, theoretically ensuring asymptotic error free computation with the minimal codeword length. To further mitigate the adverse effects of channel fading, we adopt a truncated inversion strategy for pre-processing. Benefiting from the unified symbol distribution after the proposed encoding, we derive the optimal linear minimum mean squared error (LMMSE) detector in closed form and propose a low complexity algorithm seeking for the optimal truncation selection. Furthermore, the inherent importance differences among the coded outputs motivate an uneven power allocation strategy across subcarriers to improve computational accuracy. Numerical results validate the superiority of the proposed scheme over existing digital AirComp approaches, especially at low signal to-noise ratio (SNR) regimes.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u8865\u7801\u7684\u6570\u5b57\u8c03\u5236AirComp\u7f16\u7801\u65b9\u6848\uff0c\u901a\u8fc7\u591a\u5b50\u8f7d\u6ce2\u4f20\u8f93\uff0c\u8bbe\u8ba1\u89e3\u7801\u5668\u6784\u5efa\u53e0\u52a0\u6570\u5b57\u8c03\u5236\u4fe1\u53f7\u4e0e\u8ba1\u7b97\u76ee\u6807\u4e4b\u95f4\u7684\u51fd\u6570\u6620\u5c04\uff0c\u5b9e\u73b0\u6e10\u8fd1\u65e0\u8bef\u5dee\u8ba1\u7b97\uff0c\u5e76\u91c7\u7528\u622a\u65ad\u53cd\u8f6c\u9884\u5904\u7406\u548c\u4e0d\u7b49\u529f\u7387\u5206\u914d\u7b56\u7565\u63d0\u5347\u6027\u80fd\u3002", "motivation": "\u514b\u670d\u6a21\u62df\u4fe1\u53f7\u5728\u65e0\u7ebf\u7a7a\u4e2d\u8ba1\u7b97\u4e2d\u7684\u56fa\u6709\u5c40\u9650\u6027\uff0c\u63d0\u51fa\u517c\u5bb9\u6570\u5b57\u8c03\u5236\u7684AirComp\u5b9e\u73b0\u65b9\u6848\u3002\u4f20\u7edf\u6a21\u62df\u4fe1\u53f7\u5728AirComp\u4e2d\u53d7\u9650\u4e8e\u566a\u58f0\u548c\u8870\u843d\u5f71\u54cd\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u6570\u5b57\u65b9\u6848\u3002", "method": "1) \u4f7f\u7528\u8865\u7801\u5c06\u91cf\u5316\u79bb\u6563\u503c\u7f16\u7801\u4e3a\u4e8c\u8fdb\u5236\u5e8f\u5217\uff0c\u901a\u8fc7\u591a\u5b50\u8f7d\u6ce2\u4f20\u8f93\uff1b2) \u8bbe\u8ba1\u89e3\u7801\u5668\u6784\u5efa\u53e0\u52a0\u6570\u5b57\u8c03\u5236\u4fe1\u53f7\u4e0e\u8ba1\u7b97\u76ee\u6807\u4e4b\u95f4\u7684\u51fd\u6570\u6620\u5c04\uff1b3) \u91c7\u7528\u622a\u65ad\u53cd\u8f6c\u7b56\u7565\u8fdb\u884c\u9884\u5904\u7406\uff1b4) \u63a8\u5bfc\u95ed\u5f0f\u6700\u4f18LMMSE\u68c0\u6d4b\u5668\u5e76\u63d0\u51fa\u4f4e\u590d\u6742\u5ea6\u622a\u65ad\u9009\u62e9\u7b97\u6cd5\uff1b5) \u57fa\u4e8e\u7f16\u7801\u8f93\u51fa\u91cd\u8981\u6027\u5dee\u5f02\u8bbe\u8ba1\u4e0d\u7b49\u529f\u7387\u5206\u914d\u7b56\u7565\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u65b9\u6848\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u4f18\u4e8e\u73b0\u6709\u6570\u5b57AirComp\u65b9\u6cd5\uff0c\u80fd\u591f\u5b9e\u73b0\u6e10\u8fd1\u65e0\u8bef\u5dee\u8ba1\u7b97\uff0c\u5e76\u901a\u8fc7\u622a\u65ad\u53cd\u8f6c\u548c\u4e0d\u7b49\u529f\u7387\u5206\u914d\u663e\u8457\u63d0\u5347\u8ba1\u7b97\u7cbe\u5ea6\u3002", "conclusion": "\u63d0\u51fa\u7684\u8865\u7801\u7f16\u7801\u65b9\u6848\u4e3a\u6570\u5b57AirComp\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u7f16\u7801\u8bbe\u8ba1\u3001\u622a\u65ad\u53cd\u8f6c\u9884\u5904\u7406\u548c\u4e0d\u7b49\u529f\u7387\u5206\u914d\uff0c\u5728\u4f4e\u4fe1\u566a\u6bd4\u4e0b\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684\u8ba1\u7b97\u6027\u80fd\uff0c\u514b\u670d\u4e86\u6a21\u62df\u4fe1\u53f7\u7684\u5c40\u9650\u6027\u3002"}}
{"id": "2512.24815", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.24815", "abs": "https://arxiv.org/abs/2512.24815", "authors": ["Boyao Li", "Qinwei He", "Boao Zhang", "Xiaopeng Yuan", "Anke Schmeink"], "title": "Efficient Joint Resource Allocation for Wireless Powered ISAC with Target Localization", "comment": null, "summary": "Wireless powered integrated sensing and communication (ISAC) faces a fundamental tradeoff between energy supply, communication throughput, and sensing accuracy. This paper investigates a wireless powered ISAC system with target localization requirements, where users harvest energy from wireless power transfer (WPT) and then conduct ISAC transmissions in a time-division manner. In addition to energy supply, the WPT signal also contributes to target sensing, and the localization accuracy is characterized by Cram\u00e9r-Rao bound (CRB) constraints. Under this setting, we formulate a max-min throughput maximization problem by jointly allocating the WPT duration, ISAC transmission time allocation, and transmit power. Due to the nonconvexity of the resulting problem, a suitable reformulation is developed by exploiting variable substitutions and the monotonicity of logarithmic functions, based on which an efficient successive convex approximation (SCA)-based iterative algorithm is proposed. Simulation results demonstrate convergence and significant performance gains over benchmark schemes, highlighting the importance of coordinated time-power optimization in balancing sensing accuracy and communication performance in wireless powered ISAC systems.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u65e0\u7ebf\u4f9b\u80fd\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316WPT\u65f6\u957f\u3001ISAC\u4f20\u8f93\u65f6\u95f4\u5206\u914d\u548c\u53d1\u5c04\u529f\u7387\uff0c\u5728\u6ee1\u8db3\u76ee\u6807\u5b9a\u4f4d\u7cbe\u5ea6\u7ea6\u675f\u4e0b\u6700\u5927\u5316\u6700\u5dee\u7528\u6237\u541e\u5410\u91cf\u3002", "motivation": "\u65e0\u7ebf\u4f9b\u80fdISAC\u7cfb\u7edf\u9762\u4e34\u80fd\u91cf\u4f9b\u5e94\u3001\u901a\u4fe1\u541e\u5410\u91cf\u548c\u611f\u77e5\u7cbe\u5ea6\u4e4b\u95f4\u7684\u57fa\u672c\u6743\u8861\u3002\u73b0\u6709\u7814\u7a76\u9700\u8981\u89e3\u51b3\u5728\u6ee1\u8db3\u76ee\u6807\u5b9a\u4f4d\u7cbe\u5ea6\u8981\u6c42\u4e0b\uff0c\u5982\u4f55\u534f\u8c03WPT\u548cISAC\u4f20\u8f93\u7684\u8d44\u6e90\u5206\u914d\u95ee\u9898\u3002", "method": "\u63d0\u51fa\u8054\u5408\u4f18\u5316WPT\u6301\u7eed\u65f6\u95f4\u3001ISAC\u4f20\u8f93\u65f6\u95f4\u5206\u914d\u548c\u53d1\u5c04\u529f\u7387\u7684\u6846\u67b6\u3002\u5229\u7528\u53d8\u91cf\u66ff\u6362\u548c\u5bf9\u6570\u51fd\u6570\u5355\u8c03\u6027\u8fdb\u884c\u95ee\u9898\u91cd\u6784\uff0c\u8bbe\u8ba1\u57fa\u4e8e\u9010\u6b21\u51f8\u903c\u8fd1\u7684\u9ad8\u6548\u8fed\u4ee3\u7b97\u6cd5\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u7b97\u6cd5\u6536\u655b\u6027\u597d\uff0c\u76f8\u6bd4\u57fa\u51c6\u65b9\u6848\u83b7\u5f97\u663e\u8457\u6027\u80fd\u589e\u76ca\uff0c\u9a8c\u8bc1\u4e86\u534f\u8c03\u65f6\u95f4-\u529f\u7387\u4f18\u5316\u5728\u5e73\u8861\u611f\u77e5\u7cbe\u5ea6\u548c\u901a\u4fe1\u6027\u80fd\u65b9\u9762\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u65e0\u7ebf\u4f9b\u80fdISAC\u7cfb\u7edf\u9700\u8981\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8d44\u6e90\u5206\u914d\u7b56\u7565\u6765\u5e73\u8861\u80fd\u91cf\u4f9b\u5e94\u3001\u901a\u4fe1\u541e\u5410\u91cf\u548c\u611f\u77e5\u7cbe\u5ea6\uff0c\u63d0\u51fa\u7684\u8054\u5408\u4f18\u5316\u6846\u67b6\u80fd\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002"}}
{"id": "2512.24923", "categories": ["eess.SP", "cs.HC"], "pdf": "https://arxiv.org/pdf/2512.24923", "abs": "https://arxiv.org/abs/2512.24923", "authors": ["Haojin Li", "Dongzhe Li", "Anbang Zhang", "Wenqi Zhang", "Chen Sun", "Haijun Zhang"], "title": "No Vision, No Wearables: 5G-based 2D Human Pose Recognition with Integrated Sensing and Communications", "comment": null, "summary": "With the increasing maturity of contactless human pose recognition (HPR) technology, indoor interactive applications have raised higher demands for natural, controller-free interaction methods. However, current mainstream HPR solutions relying on vision or radio-frequency (RF) (including WiFi, radar) still face various challenges in practical deployment, such as privacy concerns, susceptibility to occlusion, dedicated equipment and functions, and limited sensing resolution and range. 5G-based integrated sensing and communication (ISAC) technology, by merging communication and sensing functions, offers a new approach to address these challenges in contactless HPR. We propose a practical 5G-based ISAC system capable of inferring 2D HPR from uplink sounding reference signals (SRS). Specifically, rich features are extracted from multiple domains and employ an encoder to achieve unified alignment and representation in a latent space. Subsequently, low-dimensional features are fused to output the human pose state. Experimental results demonstrate that in typical indoor environments, our proposed 5G-based ISAC HPR system significantly outperforms current mainstream baseline solutions in HPR performance, providing a solid technical foundation for universal human-computer interaction.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e5G ISAC\u7684\u514d\u63a5\u89e6\u4eba\u4f53\u59ff\u6001\u8bc6\u522b\u7cfb\u7edf\uff0c\u5229\u7528\u4e0a\u884c\u63a2\u6d4b\u53c2\u8003\u4fe1\u53f7\u5b9e\u73b02D\u59ff\u6001\u4f30\u8ba1\uff0c\u5728\u5ba4\u5185\u73af\u5883\u4e2d\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u4e3b\u6d41\u65b9\u6848", "motivation": "\u5f53\u524d\u57fa\u4e8e\u89c6\u89c9\u6216\u5c04\u9891\u7684\u514d\u63a5\u89e6\u4eba\u4f53\u59ff\u6001\u8bc6\u522b\u6280\u672f\u5b58\u5728\u9690\u79c1\u95ee\u9898\u3001\u6613\u53d7\u906e\u6321\u3001\u9700\u8981\u4e13\u7528\u8bbe\u5907\u3001\u611f\u77e5\u5206\u8fa8\u7387\u548c\u8303\u56f4\u6709\u9650\u7b49\u6311\u6218\uff0c5G ISAC\u6280\u672f\u4e3a\u8fd9\u4e9b\u95ee\u9898\u63d0\u4f9b\u4e86\u65b0\u7684\u89e3\u51b3\u9014\u5f84", "method": "\u4ece\u591a\u57df\u63d0\u53d6\u4e30\u5bcc\u7279\u5f81\uff0c\u4f7f\u7528\u7f16\u7801\u5668\u5728\u6f5c\u5728\u7a7a\u95f4\u5b9e\u73b0\u7edf\u4e00\u5bf9\u9f50\u548c\u8868\u793a\uff0c\u7136\u540e\u878d\u5408\u4f4e\u7ef4\u7279\u5f81\u8f93\u51fa\u4eba\u4f53\u59ff\u6001\u72b6\u6001\uff0c\u57fa\u4e8e5G\u4e0a\u884c\u63a2\u6d4b\u53c2\u8003\u4fe1\u53f7\u8fdb\u884c\u63a8\u65ad", "result": "\u5728\u5178\u578b\u5ba4\u5185\u73af\u5883\u4e2d\uff0c\u63d0\u51fa\u76845G ISAC HPR\u7cfb\u7edf\u5728\u59ff\u6001\u8bc6\u522b\u6027\u80fd\u4e0a\u663e\u8457\u4f18\u4e8e\u5f53\u524d\u4e3b\u6d41\u57fa\u7ebf\u89e3\u51b3\u65b9\u6848", "conclusion": "\u8be5\u7cfb\u7edf\u4e3a\u901a\u7528\u4eba\u673a\u4ea4\u4e92\u63d0\u4f9b\u4e86\u575a\u5b9e\u7684\u6280\u672f\u57fa\u7840\uff0c\u5c55\u793a\u4e865G ISAC\u5728\u514d\u63a5\u89e6\u4eba\u4f53\u59ff\u6001\u8bc6\u522b\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c"}}
{"id": "2512.24958", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.24958", "abs": "https://arxiv.org/abs/2512.24958", "authors": ["Tong Wei", "Kumar Vijay Mishra", "Bhavani Shankar M. R.", "Bj\u00f6rn Ottersten"], "title": "Fundamental Limits for Near-Field Sensing -- Part I: Narrow-Band Systems", "comment": null, "summary": "Extremely large-scale antenna arrays (ELAAs) envisioned for 6G enable high-resolution sensing. However, the ELAAs worked in extremely high frequency will push operation into the near-field region, where spherical wavefronts invalidate classical far-field models and alter fundamental estimation limits. The purpose of this and the companion paper (Part II) is to develop the theory of fundamental limits for near-field sensing systems in detail. In this paper (Part I), we develop a unified narrow-band near-field signal model for joint parameter sensing of moving targets using the ELAAs. Leveraging the Slepian--Bangs formulation, we derive closed-form Cram'er--Rao bounds (CRBs) for joint estimation of target position, velocity, and radar cross-section (RCS) under the slow-time sampling model. To obtain interpretable insights, we further establish explicit far-field and near-field approximations that reveal how the bounds scale with array aperture, target range, carrier wavelength, and coherent integration length. The resulting expressions expose the roles of self-information terms and their cross terms, clarifying when Fresnel corrections become non-negligible and providing beamformer and algorithm design guidelines for near-field sensing with ELAAs. Simulation results validate the derived CRBs and their far-field and near-field approximations, demonstrating accurate agreement with the analytical scaling laws across representative array sizes and target ranges.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4e3a6G\u8d85\u5927\u9635\u5217\u5929\u7ebf\u8fd1\u573a\u4f20\u611f\u57fa\u7840\u7406\u8bba\u7684\u7b2c\u4e00\u90e8\u5206\uff0c\u63a8\u5bfc\u4e86\u8fd0\u52a8\u76ee\u6807\u8054\u5408\u53c2\u6570\u4f30\u8ba1\u7684\u514b\u62c9\u7f8e-\u7f57\u4e0b\u754c\u53ca\u5176\u8fd1\u4f3c\u8868\u8fbe\u5f0f\uff0c\u63ed\u793a\u4e86\u9635\u5217\u5b54\u5f84\u3001\u76ee\u6807\u8ddd\u79bb\u7b49\u53c2\u6570\u5bf9\u4f30\u8ba1\u6027\u80fd\u7684\u5f71\u54cd\u89c4\u5f8b\u3002", "motivation": "6G\u8d85\u5927\u9635\u5217\u5929\u7ebf\u5de5\u4f5c\u5728\u6781\u9ad8\u9891\u7387\u4e0b\u5c06\u8fdb\u5165\u8fd1\u573a\u533a\u57df\uff0c\u4f20\u7edf\u8fdc\u573a\u6a21\u578b\u5931\u6548\uff0c\u9700\u8981\u5efa\u7acb\u8fd1\u573a\u4f20\u611f\u7684\u57fa\u7840\u7406\u8bba\u6846\u67b6\u6765\u6307\u5bfc\u7cfb\u7edf\u8bbe\u8ba1\u548c\u7b97\u6cd5\u5f00\u53d1\u3002", "method": "\u5efa\u7acb\u7edf\u4e00\u7684\u7a84\u5e26\u8fd1\u573a\u4fe1\u53f7\u6a21\u578b\uff0c\u5229\u7528Slepian-Bangs\u516c\u5f0f\u63a8\u5bfc\u8fd0\u52a8\u76ee\u6807\u4f4d\u7f6e\u3001\u901f\u5ea6\u548cRCS\u8054\u5408\u4f30\u8ba1\u7684\u95ed\u5f0fCRB\uff0c\u5e76\u5efa\u7acb\u53ef\u89e3\u91ca\u7684\u8fdc\u573a\u548c\u8fd1\u573a\u8fd1\u4f3c\u8868\u8fbe\u5f0f\u3002", "result": "\u63a8\u5bfc\u51fa\u95ed\u5f0fCRB\u53ca\u5176\u8fd1\u4f3c\u8868\u8fbe\u5f0f\uff0c\u63ed\u793a\u4e86\u81ea\u4fe1\u606f\u9879\u548c\u4ea4\u53c9\u9879\u7684\u4f5c\u7528\uff0c\u660e\u786e\u4e86Fresnel\u4fee\u6b63\u4f55\u65f6\u4e0d\u53ef\u5ffd\u7565\uff0c\u4e3a\u8fd1\u573a\u4f20\u611f\u63d0\u4f9b\u4e86\u6ce2\u675f\u5f62\u6210\u548c\u7b97\u6cd5\u8bbe\u8ba1\u6307\u5bfc\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u8fd1\u573a\u4f20\u611f\u5efa\u7acb\u4e86\u7406\u8bba\u57fa\u7840\uff0c\u4eff\u771f\u9a8c\u8bc1\u4e86\u63a8\u5bfc\u7684CRB\u53ca\u5176\u8fd1\u8fdc\u573a\u8fd1\u4f3c\u7684\u51c6\u786e\u6027\uff0c\u4e3a6G\u8d85\u5927\u9635\u5217\u5929\u7ebf\u7684\u8fd1\u573a\u4f20\u611f\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc\u3002"}}
{"id": "2512.24962", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2512.24962", "abs": "https://arxiv.org/abs/2512.24962", "authors": ["Tong Wei", "Kumar Vijay Mishra", "Bhavani Shankar M. R.", "Bj\u00f6rn Ottersten"], "title": "Fundamental Limits for Near-Field Sensing -- Part II: Wide-Band Systems", "comment": null, "summary": "Near-field sensing with extremely large-scale antenna arrays (ELAAs) in practical 6G systems is expected to operate over broad bandwidths, where delay, Doppler, and spatial effects become tightly coupled across frequency. The purpose of this and the companion paper (Part I) is to develop the unified Cram'er--Rao bounds (CRBs) for sensing systems spanning from far-field to near-field, and narrow-band to wide-band. This paper (Part II) derives fundamental estimation limits for a wide-band near-field sensing systems employing orthogonal frequency-division multiplexing signaling over a coherent processing interval. We establish an exact near-field wide-band signal model that captures frequency-dependent propagation, spherical-wave geometry, and the intrinsic coupling between target location and motion parameters across subcarriers and slow time. Similar as Part I using the Slepian--Bangs formulation, we derive the wide-band Fisher information matrix and the CRBs for joint estimation of target position, velocity, and radar cross-section, and we show how wide-band information aggregates across orthogonal subcarriers. We further develop tractable far-field and near-field approximations which provide design-level insights into the roles of bandwidth, coherent integration length, and array aperture, and clarify when wide-band effects. Simulation results validate the derived CRBs and its approximations, demonstrating close agreement with the analytical scaling laws across representative ranges, bandwidths, and array configurations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a8\u5bfc\u4e86\u5bbd\u5e26\u8fd1\u573a\u4f20\u611f\u7cfb\u7edf\u7684CRB\u4e0b\u754c\uff0c\u5efa\u7acb\u4e86\u5305\u542b\u9891\u7387\u76f8\u5173\u4f20\u64ad\u3001\u7403\u9762\u6ce2\u51e0\u4f55\u548c\u53c2\u6570\u8026\u5408\u7684\u7cbe\u786e\u4fe1\u53f7\u6a21\u578b\uff0c\u5e76\u7ed9\u51fa\u4e86\u53ef\u5904\u7406\u7684\u8fdc\u573a/\u8fd1\u573a\u8fd1\u4f3c\u3002", "motivation": "6G\u7cfb\u7edf\u4e2d\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\u7684\u5bbd\u5e26\u8fd1\u573a\u4f20\u611f\u9700\u8981\u5728\u9891\u7387\u4e0a\u8003\u8651\u65f6\u5ef6\u3001\u591a\u666e\u52d2\u548c\u7a7a\u95f4\u6548\u5e94\u7684\u8026\u5408\uff0c\u9700\u8981\u5efa\u7acb\u7edf\u4e00\u7684\u6027\u80fd\u754c\u9650\u7406\u8bba\u6846\u67b6\u3002", "method": "\u5efa\u7acb\u7cbe\u786e\u7684\u5bbd\u5e26\u8fd1\u573a\u4fe1\u53f7\u6a21\u578b\uff0c\u4f7f\u7528Slepian-Bangs\u516c\u5f0f\u63a8\u5bfcFisher\u4fe1\u606f\u77e9\u9635\u548cCRB\u4e0b\u754c\uff0c\u5e76\u5f00\u53d1\u53ef\u5904\u7406\u7684\u8fdc\u573a\u548c\u8fd1\u573a\u8fd1\u4f3c\u3002", "result": "\u63a8\u5bfc\u4e86\u76ee\u6807\u4f4d\u7f6e\u3001\u901f\u5ea6\u548c\u96f7\u8fbe\u622a\u9762\u79ef\u7684\u8054\u5408\u4f30\u8ba1CRB\uff0c\u9610\u660e\u4e86\u5e26\u5bbd\u3001\u76f8\u5e72\u79ef\u5206\u957f\u5ea6\u548c\u9635\u5217\u5b54\u5f84\u7684\u4f5c\u7528\uff0c\u4eff\u771f\u9a8c\u8bc1\u4e86\u7406\u8bba\u754c\u9650\u4e0e\u8fd1\u4f3c\u3002", "conclusion": "\u5efa\u7acb\u4e86\u5bbd\u5e26\u8fd1\u573a\u4f20\u611f\u7684\u5b8c\u6574\u7406\u8bba\u6846\u67b6\uff0c\u4e3a6G\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6027\u80fd\u754c\u9650\u548c\u8bbe\u8ba1\u6307\u5bfc\uff0c\u660e\u786e\u4e86\u5bbd\u5e26\u6548\u5e94\u7684\u91cd\u8981\u6027\u3002"}}

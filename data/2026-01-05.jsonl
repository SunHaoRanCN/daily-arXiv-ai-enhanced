{"id": "2601.00012", "categories": ["eess.SP", "cs.AI", "cs.CV", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.00012", "abs": "https://arxiv.org/abs/2601.00012", "authors": ["Shahar Ain Kedem", "Itamar Zimerman", "Eliya Nachmani"], "title": "Neural Brain Fields: A NeRF-Inspired Approach for Generating Nonexistent EEG Electrodes", "comment": null, "summary": "Electroencephalography (EEG) data present unique modeling challenges because recordings vary in length, exhibit very low signal to noise ratios, differ significantly across participants, drift over time within sessions, and are rarely available in large and clean datasets. Consequently, developing deep learning methods that can effectively process EEG signals remains an open and important research problem. To tackle this problem, this work presents a new method inspired by Neural Radiance Fields (NeRF). In computer vision, NeRF techniques train a neural network to memorize the appearance of a 3D scene and then uses its learned parameters to render and edit the scene from any viewpoint. We draw an analogy between the discrete images captured from different viewpoints used to learn a continuous 3D scene in NeRF, and EEG electrodes positioned at different locations on the scalp, which are used to infer the underlying representation of continuous neural activity. Building on this connection, we show that a neural network can be trained on a single EEG sample in a NeRF style manner to produce a fixed size and informative weight vector that encodes the entire signal. Moreover, via this representation we can render the EEG signal at previously unseen time steps and spatial electrode positions. We demonstrate that this approach enables continuous visualization of brain activity at any desired resolution, including ultra high resolution, and reconstruction of raw EEG signals. Finally, our empirical analysis shows that this method can effectively simulate nonexistent electrodes data in EEG recordings, allowing the reconstructed signal to be fed into standard EEG processing networks to improve performance."}
{"id": "2601.00014", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.00014", "abs": "https://arxiv.org/abs/2601.00014", "authors": ["Eran Zvuloni", "Ronit Almog", "Michael Glikson", "Shany Brimer Biton", "Ilan Green", "Izhar Laufer", "Offer Amir", "Joachim A. Behar"], "title": "Modeling Day-Long ECG Signals to Predict Heart Failure Risk with Explainable AI", "comment": null, "summary": "Heart failure (HF) affects 11.8% of adults aged 65 and older, reducing quality of life and longevity. Preventing HF can reduce morbidity and mortality. We hypothesized that artificial intelligence (AI) applied to 24-hour single-lead electrocardiogram (ECG) data could predict the risk of HF within five years. To research this, the Technion-Leumit Holter ECG (TLHE) dataset, including 69,663 recordings from 47,729 patients, collected over 20 years was used. Our deep learning model, DeepHHF, trained on 24-hour ECG recordings, achieved an area under the receiver operating characteristic curve of 0.80 that outperformed a model using 30-second segments and a clinical score. High-risk individuals identified by DeepHHF had a two-fold chance of hospitalization or death incidents. Explainability analysis showed DeepHHF focused on arrhythmias and heart abnormalities, with key attention between 8 AM and 3 PM. This study highlights the feasibility of deep learning to model 24-hour continuous ECG data, capturing paroxysmal events and circadian variations essential for reliable risk prediction. Artificial intelligence applied to single-lead Holter ECG is non-invasive, inexpensive, and widely accessible, making it a promising tool for HF risk prediction."}
{"id": "2601.00115", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.00115", "abs": "https://arxiv.org/abs/2601.00115", "authors": ["Khalid T. Musri", "Akram Y. Sarhan", "Osamah A. Abdullah", "Hayder Al-Hraishawi"], "title": "Adaptive Pinching Antenna Optimization via Meta-Learning for Physical-Layer Security in Dynamic Wireless Networks", "comment": null, "summary": "This paper develops a gradient-based meta-learning framework for real-time control of waveguided pinching-antenna systems under user-location uncertainty and physical-layer security (PLS) constraints. A probabilistic system model is introduced to capture the impact of imperfect localization on outage performance and secrecy. Based on this model, a joint antenna-positioning and transmit-power optimization problem is formulated to satisfy probabilistic reliability and secrecy requirements. To enable rapid adaptation in highly dynamic environments, the proposed approach employs model-agnostic meta-learning (MAML) to learn a transferable initialization across diverse mobility and channel conditions, allowing few-shot online adaptation using limited pilot feedback. Simulation results demonstrate that the proposed framework significantly outperforms Reptile-based meta-learning, non-meta reinforcement learning, conventional optimization, static antenna placement, and power-only control in terms of outage probability, secrecy performance, and convergence latency. These results establish meta-learning as an effective tool for secure and low-latency control of reconfigurable pinching-antenna systems in non-stationary wireless environments."}
{"id": "2601.00159", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.00159", "abs": "https://arxiv.org/abs/2601.00159", "authors": ["Yuan Gao", "Zichen Lu", "Xinyi Wu", "Wenjun Yu", "Shengli Liu", "Jianbo Du", "Yanliang Jin", "Shunqing Zhang", "Xiaoli Chu", "Shugong Xu"], "title": "AI-Driven Channel State Information (CSI) Extrapolation for 6G: Current Situations, Challenges and Future Research", "comment": "This manuscript has been accepted by IEEE Communications Surveys and Tutorials", "summary": "CSI extrapolation is an effective method for acquiring channel state information (CSI), essential for optimizing performance of sixth-generation (6G) communication systems. Traditional channel estimation methods face scalability challenges due to the surging overhead in emerging high-mobility, extremely large-scale multiple-input multiple-output (EL-MIMO), and multi-band systems. CSI extrapolation techniques mitigate these challenges by using partial CSI to infer complete CSI, significantly reducing overhead. Despite growing interest, a comprehensive review of state-of-the-art (SOTA) CSI extrapolation techniques is lacking. This paper addresses this gap by comprehensively reviewing the current status, challenges, and future directions of CSI extrapolation for the first time. Firstly, we analyze the performance metrics specific to CSI extrapolation in 6G, including extrapolation accuracy, adaption to dynamic scenarios and algorithm costs. We then review both model-driven and artificial intelligence (AI)-driven approaches for time, frequency, antenna, and multi-domain CSI extrapolation. Key insights and takeaways from these methods are summarized. Given the promise of AI-driven methods in meeting performance requirements, we also examine the open-source channel datasets and simulators that could be used to train high-performance AI-driven CSI extrapolation models. Finally, we discuss the critical challenges of the existing research and propose perspective research opportunities."}
{"id": "2601.00100", "categories": ["eess.AS", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.00100", "abs": "https://arxiv.org/abs/2601.00100", "authors": ["Sung-Lin Yeh", "Peter Bell", "Hao Tang"], "title": "Learning Speech Representations with Variational Predictive Coding", "comment": "Accepted to Transactions of the Association for Computational Linguistics (TACL); Pre MIT Press version", "summary": "Despite being the best known objective for learning speech representations, the HuBERT objective has not been further developed and improved. We argue that it is the lack of an underlying principle that stalls the development, and, in this paper, we show that predictive coding under a variational view is the principle behind the HuBERT objective. Due to its generality, our formulation provides opportunities to improve parameterization and optimization, and we show two simple modifications that bring immediate improvements to the HuBERT objective. In addition, the predictive coding formulation has tight connections to various other objectives, such as APC, CPC, wav2vec, and BEST-RQ. Empirically, the improvement in pre-training brings significant improvements to four downstream tasks: phone classification, f0 tracking, speaker recognition, and automatic speech recognition, highlighting the importance of the predictive coding interpretation."}
{"id": "2601.00160", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.00160", "abs": "https://arxiv.org/abs/2601.00160", "authors": ["Zhuoran Zhuang", "Ye Chen", "Chao Luo", "Tian-Hao Zhang", "Xuewei Zhang", "Jian Ma", "Jiatong Shi", "Wei Zhang"], "title": "IKFST: IOO and KOO Algorithms for Accelerated and Precise WFST-based End-to-End Automatic Speech Recognition", "comment": null, "summary": "End-to-end automatic speech recognition has become the dominant paradigm in both academia and industry. To enhance recognition performance, the Weighted Finite-State Transducer (WFST) is widely adopted to integrate acoustic and language models through static graph composition, providing robust decoding and effective error correction. However, WFST decoding relies on a frame-by-frame autoregressive search over CTC posterior probabilities, which severely limits inference efficiency. Motivated by establishing a more principled compatibility between WFST decoding and CTC modeling, we systematically study the two fundamental components of CTC outputs, namely blank and non-blank frames, and identify a key insight: blank frames primarily encode positional information, while non-blank frames carry semantic content. Building on this observation, we introduce Keep-Only-One and Insert-Only-One, two decoding algorithms that explicitly exploit the structural roles of blank and non-blank frames to achieve significantly faster WFST-based inference without compromising recognition accuracy. Experiments on large-scale in-house, AISHELL-1, and LibriSpeech datasets demonstrate state-of-the-art recognition accuracy with substantially reduced decoding latency, enabling truly efficient and high-performance WFST decoding in modern speech recognition systems."}
{"id": "2601.00171", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.00171", "abs": "https://arxiv.org/abs/2601.00171", "authors": ["Lingyun Xu", "Bowen Wang", "Huiyong Li", "Ziyang Cheng"], "title": "Edge AI Inference in ISCC Networks: Sensing Accuracy Analysis and Precoding Design", "comment": null, "summary": "This work explores the relationship between sensing accuracy and precoding coefficients for edge artificial intelligence (AI) inference in integrated sensing, communication and computation (ISCC) networks. We start by constructing a system model of an over-the-air-empowered ISCC network for edge AI inference, involving distributed edge sensors for feature extraction and an edge server for classification. Based on this model, we introduce a discriminant gain (DG) to characterize sensing accuracy and novelly derive an explicit function of the DG about precoding coefficients, giving valuable insights into precoding design. Guided by this, we propose an effective precoding algorithm to solve a non-convex DG-maximization problem. Simulation results verify the effectiveness and feasibility of the proposed design for edge inference in ISCC networks."}
{"id": "2601.00217", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.00217", "abs": "https://arxiv.org/abs/2601.00217", "authors": ["Minhyeok Yun", "Yong-Hoon Choi"], "title": "Latent Flow Matching for Expressive Singing Voice Synthesis", "comment": null, "summary": "Conditional variational autoencoder (cVAE)-based singing voice synthesis provides efficient inference and strong audio quality by learning a score-conditioned prior and a recording-conditioned posterior latent space. However, because synthesis relies on prior samples while training uses posterior latents inferred from real recordings, imperfect distribution matching can cause a prior-posterior mismatch that degrades fine-grained expressiveness such as vibrato and micro-prosody. We propose FM-Singer, which introduces conditional flow matching (CFM) in latent space to learn a continuous vector field transporting prior latents toward posterior latents along an optimal-transport-inspired path. At inference time, the learned latent flow refines a prior sample by solving an ordinary differential equation (ODE) before waveform generation, improving expressiveness while preserving the efficiency of parallel decoding. Experiments on Korean and Chinese singing datasets demonstrate consistent improvements over strong baselines, including lower mel-cepstral distortion and fundamental-frequency error and higher perceptual scores on the Korean dataset. Code, pretrained checkpoints, and audio demos are available at https://github.com/alsgur9368/FM-Singer"}
{"id": "2601.00434", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.00434", "abs": "https://arxiv.org/abs/2601.00434", "authors": ["Dhandeep Challagundla", "Ignatius Bezzam", "Riadul Islam"], "title": "Time--to--Digital Converter (TDC)--Based Resonant Compute--in--Memory for INT8 CNNs with Layer--Optimized SRAM Mapping", "comment": null, "summary": "In recent years, Compute-in-memory (CiM) architectures have emerged as a promising solution for deep neural network (NN) accelerators. Multiply-accumulate~(MAC) is considered a {\\textit de facto} unit operation in NNs. By leveraging the inherent parallel processing capabilities of CiM, NNs that require numerous MAC operations can be executed more efficiently. This is further facilitated by storing the weights in SRAM, reducing the need for extensive data movement and enhancing overall computational speed and efficiency. Traditional CiM architectures execute MAC operations in the analog domain, employing an Analog-to-Digital converter (ADC) to convert the analog MAC values into digital outputs. However, these ADCs introduce significant increase in area and power consumption, as well as introduce non-linearities. This work proposes a resonant time-domain compute-in-memory (TDC-CiM) architecture that eliminates the need for an ADC by using a time-to-digital converter (TDC) to digitize analog MAC results with lower power and area cost. A dedicated 8T SRAM cell enables reliable bitwise MAC operations, while the readout uses a 4-bit TDC with pulse-shrinking delay elements, achieving 1 GS/s sampling with a power consumption of only 1.25 mW. In addition, a weight stationary data mapping strategy combined with an automated SRAM macro selection algorithm enables scalable and energy-efficient deployment across CNN workloads. Evaluation across six CNN models shows that the algorithm reduces inference energy consumption by up to 8x when scaling SRAM size from 32~KB to 256~KB, while maintaining minimal accuracy loss after quantization. The feasibility of the proposed architecture is validated on an 8~KB SRAM memory array using TSMC 28~nm technology. The proposed TDC-CiM architecture demonstrates a throughput of 320~GOPS with an energy efficiency of 38.46~TOPS/W."}
{"id": "2601.00299", "categories": ["cs.SD", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.00299", "abs": "https://arxiv.org/abs/2601.00299", "authors": ["Tzu-Hung Huang", "Yun-En Tsai", "Yun-Ning Hung", "Chih-Wei Wu", "I-Chieh Wei", "Li Su"], "title": "Timed text extraction from Taiwanese Kua-á-hì TV series", "comment": "Accepted to ISMIR 2025 Late-Breaking Demo (LBD)", "summary": "Taiwanese opera (Kua-á-hì), a major form of local theatrical tradition, underwent extensive television adaptation notably by pioneers like Iûnn Lē-hua. These videos, while potentially valuable for in-depth studies of Taiwanese opera, often have low quality and require substantial manual effort during data preparation. To streamline this process, we developed an interactive system for real-time OCR correction and a two-step approach integrating OCR-driven segmentation with Speech and Music Activity Detection (SMAD) to efficiently identify vocal segments from archival episodes with high precision. The resulting dataset, consisting of vocal segments and corresponding lyrics, can potentially supports various MIR tasks such as lyrics identification and tune retrieval. Code is available at https://github.com/z-huang/ocr-subtitle-editor ."}
{"id": "2601.00502", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.00502", "abs": "https://arxiv.org/abs/2601.00502", "authors": ["Zeping Sui", "Zilong Liu", "Leila Musavian", "Yong Liang Guan", "Lie-Liang Yang", "Lajos Hanzo"], "title": "MIMO-AFDM Outperforms MIMO-OFDM in the Face of Hardware Impairments", "comment": "13 pages, 11 figures, submitted to IEEE TCOM", "summary": "The impact of both multiplicative and additive hardware impairments (HWIs) on multiple-input multiple-output affine frequency division multiplexing (MIMO-AFDM) systems is investigated. For small-scale MIMO-AFDM systems, a tight bit error rate (BER) upper bound associated with the maximum likelihood (ML) detector is derived. By contrast, for large-scale systems, a closed-form BER approximation associated with the linear minimum mean squared error (LMMSE) detector is presented, including realistic imperfect channel estimation scenarios. Our first key observation is that the full diversity order of a hardware-impaired AFDM system remains unaffected, which is a unique advantage. Furthermore, our analysis shows that 1) the BER results derived accurately predict the simulated ML performance in moderate-to-high signal-to-noise ratios (SNRs), while the theoretical BER curve of the LMMSE detector closely matches that of the Monte-Carlo based one. 2) MIMO-AFDM is more resilient to multiplicative distortions, such as phase noise and carrier frequency offset, compared to its orthogonal frequency division multiplexing (OFDM) counterparts. This is attributed to its inherent chirp signal characteristics; 3) MIMO-AFDM consistently achieves superior BER performance compared to conventional MIMO-OFDM systems under the same additive HWI conditions, as well as different velocity values. The latter is because MIMO-AFDM is also resilient to the additional inter-carrier interference (ICI) imposed by the nonlinear distortions of additive HWIs. In a nutshell, compared to OFDM, AFDM demonstrates stronger ICI resilience and achieves the maximum full diversity attainable gain even under HWIs, thanks to its intrinsic chirp signalling structure as well as to the beneficial spreading effect of the discrete affine Fourier transform."}
{"id": "2601.00777", "categories": ["cs.SD", "cs.CV"], "pdf": "https://arxiv.org/pdf/2601.00777", "abs": "https://arxiv.org/abs/2601.00777", "authors": ["Akanksha Chuchra", "Shukesh Reddy", "Sudeepta Mishra", "Abhijit Das", "Abhinav Dhall"], "title": "Investigating the Viability of Employing Multi-modal Large Language Models in the Context of Audio Deepfake Detection", "comment": "Accepted at IJCB 2025", "summary": "While Vision-Language Models (VLMs) and Multimodal Large Language Models (MLLMs) have shown strong generalisation in detecting image and video deepfakes, their use for audio deepfake detection remains largely unexplored. In this work, we aim to explore the potential of MLLMs for audio deepfake detection. Combining audio inputs with a range of text prompts as queries to find out the viability of MLLMs to learn robust representations across modalities for audio deepfake detection. Therefore, we attempt to explore text-aware and context-rich, question-answer based prompts with binary decisions. We hypothesise that such a feature-guided reasoning will help in facilitating deeper multimodal understanding and enable robust feature learning for audio deepfake detection. We evaluate the performance of two MLLMs, Qwen2-Audio-7B-Instruct and SALMONN, in two evaluation modes: (a) zero-shot and (b) fine-tuned. Our experiments demonstrate that combining audio with a multi-prompt approach could be a viable way forward for audio deepfake detection. Our experiments show that the models perform poorly without task-specific training and struggle to generalise to out-of-domain data. However, they achieve good performance on in-domain data with minimal supervision, indicating promising potential for audio deepfake detection."}
{"id": "2601.00538", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.00538", "abs": "https://arxiv.org/abs/2601.00538", "authors": ["Chi-Te Kuo", "Li-Hsiang Shen", "Jyun-Jhe Huang"], "title": "Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks", "comment": null, "summary": "Multi-functional reconfigurable intelligent surface (MF-RIS) is conceived to address the communication efficiency thanks to its extended signal coverage from its active RIS capability and self-sustainability from energy harvesting (EH). We investigate the architecture of multi-MF-RISs to assist non-orthogonal multiple access (NOMA) downlink networks. We formulate an energy efficiency (EE) maximization problem by optimizing power allocation, transmit beamforming and MF-RIS configurations of amplitudes, phase-shifts and EH ratios, as well as the position of MF-RISs, while satisfying constraints of available power, user rate requirements, and self-sustainability property. We design a parametrized sharing scheme for multi-agent hybrid deep reinforcement learning (PMHRL), where the multi-agent proximal policy optimization (PPO) and deep-Q network (DQN) handle continuous and discrete variables, respectively. The simulation results have demonstrated that proposed PMHRL has the highest EE compared to other benchmarks, including cases without parametrized sharing, pure PPO and DQN. Moreover, the proposed multi-MF-RISs-aided downlink NOMA achieves the highest EE compared to scenarios of no-EH/amplification, traditional RISs, and deployment without RISs/MF-RISs under different multiple access."}
{"id": "2601.00564", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.00564", "abs": "https://arxiv.org/abs/2601.00564", "authors": ["Jeongwoo Park", "Seongkyu Jung", "Kaiming Shen", "Jeonghun Park"], "title": "Fractional Programming for Kullback-Leibler Divergence in Hypothesis Testing", "comment": null, "summary": "Maximizing the Kullback-Leibler divergence (KLD) is a fundamental problem in waveform design for active sensing and hypothesis testing, as it directly relates to the error exponent of detection probability. However, the associated optimization problem is highly nonconvex due to the intricate coupling of log-determinant and matrix trace terms. Existing solutions often suffer from high computational complexity, typically requiring matrix inversion at every iteration. In this paper, we propose a computationally efficient optimization framework based on fractional programming (FP). Our key idea is to reformulate the KLD maximization problem into a sequence of tractable quadratic subproblems using matrix FP. To further reduce complexity, we introduce a nonhomogeneous relaxation technique that replaces the costly linear system solver with a simple closed-form update, thereby reducing the per-iteration complexity to quadratic order. To compensate for the convergence speed trade-off caused by relaxation, we employ an acceleration method called STEM by interpreting the iterative scheme as a fixed-point mapping. The resulting algorithm achieves significantly faster convergence rates with low per-iteration cost. Numerical results demonstrate that our approach reduces the total runtime by orders of magnitude compared to a state-of-the-art benchmark. Finally, we apply the proposed framework to a multiple random access scenario and a joint integrated sensing and communication scenario, validating the efficacy of our framework in such applications."}
{"id": "2601.00612", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.00612", "abs": "https://arxiv.org/abs/2601.00612", "authors": ["Zonghui Yang", "Shijian Gao", "Xuesong Cai", "Xiang Cheng", "Liuqing Yang"], "title": "WiFo-MUD: Wireless Foundation Model for Heterogeneous Multi-User Demodulator", "comment": "13 pages, 9 figures, 10 tables", "summary": "Multi-user signal demodulation is critical to wireless communications, directly impacting transmission reliability and efficiency. However, existing demodulators underperform in generic multi-user environments: classical demodulators struggle to balance accuracy and complexity, while deep learning-based methods lack adaptability under heterogeneous configurations. Although diffusion models have been introduced for demodulation, their flexibility remains limited for practical use. To address these issues, this work proposes WiFo-MUD, a universal diffusion-based foundation model for multi-user demodulation. The model aligns inter-user signal-to-noise ratio imbalance and performs conditional denoising via a customized backbone. Furthermore, a communication-aware consistency distillation method and a dynamic user-grouping strategy are devised to enhance inference. WiFo-MUD achieves state-of-the-art results on large-scale heterogeneous datasets, demonstrating efficient inference and strong generalization across varying system configurations."}
{"id": "2601.00616", "categories": ["eess.SP", "cs.AR"], "pdf": "https://arxiv.org/pdf/2601.00616", "abs": "https://arxiv.org/abs/2601.00616", "authors": ["Yasaman Khorsandmanesh", "Emil Bjornson", "Joakim Jalden"], "title": "Splitting Precoding with Subspace Selection and Quantized Refinement for Massive MIMO", "comment": null, "summary": "Limited fronthaul capacity is a practical bottleneck in massive multiple-input multiple-output (MIMO) 5G architectures, where a base station (BS) consists of an advanced antenna system (AAS) connected to a baseband unit (BBU). Conventional downlink designs place the entire precoding computation at the BBU and transmit a high-dimensional precoding matrix over the fronthaul, resulting in substantial quantization losses and signaling overhead. This letter proposes a splitting precoding architecture that separates the design between the AAS and BBU. The AAS performs a local subspace selection to reduce the channel dimensionality, while the BBU computes an optimized quantized refinement precoding based on the resulting effective channel. The numerical results show that the proposed splitting precoding strategy achieves higher sum spectral efficiency than conventional one-stage precoding."}
{"id": "2601.00734", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.00734", "abs": "https://arxiv.org/abs/2601.00734", "authors": ["Filippo Pepe", "Ivan Iudice", "Giuseppe Castaldi", "Marco Di Renzo", "Vincenzo Galdi"], "title": "Conformal Reconfigurable Intelligent Surfaces: A Cylindrical Geometry Perspective", "comment": "20 pages, 9 figures", "summary": "Curved reconfigurable intelligent surfaces (RISs) represent a promising frontier for next-generation wireless communication, enabling adaptive wavefront control on nonplanar platforms such as unmanned aerial vehicles and urban infrastructure. This work presents a systematic investigation of cylindrical RISs, progressing from idealized surface-impedance synthesis to practical implementations based on simple one-bit meta-atoms. Exact analytical and geometrical-optics-based models are first developed to explore fundamental design limits, followed by a semi-analytical formulation tailored to discrete, reconfigurable architectures. This model enables efficient beam synthesis using both evolutionary optimization and low-complexity strategies, including the minimum power distortionless response method, and is validated through full-wave simulations. Results confirm that one-bit RISs can achieve directive scattering with manageable sidelobe levels and minimal hardware complexity. These findings establish the viability of cylindrical RISs and open the door to their integration into dual-use wireless platforms for real-world communication scenarios."}
{"id": "2601.00780", "categories": ["eess.SP", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.00780", "abs": "https://arxiv.org/abs/2601.00780", "authors": ["Robert Kuku Fotock", "Alessio Zappone", "Agbotiname Lucky Imoize", "Marco Di Renzo"], "title": "Energy Efficiency Maximization of MIMO Systems through Reconfigurable Holographic Beamforming", "comment": "13 pages, 7 figures", "summary": "This study considers a point-to-point wireless link, in which both the transmitter and receiver are equipped with multiple antennas. In addition, two reconfigurable metasurfaces are deployed, one in the immediate vicinity of the transmit antenna array, and one in the immediate vicinity of the receive antenna array. The resulting architecture implements a holographic beamforming structure at both the transmitter and receiver. In this scenario, the system energy efficiency is optimized with respect to the transmit covariance matrix, and the reflection matrices of the two metasurfaces. A low-complexity algorithm is developed, which is guaranteed to converge to a first-order optimal point of the energy efficiency maximization problem. Moreover, closed-form expressions are derived for the metasurface matrices in the special case of single-antenna or single-stream transmission. The two metasurfaces are considered to be nearly-passive and subject to global reflection constraints. A numerical performance analysis is conducted to assess the performance of the proposed optimization methods, showing, in particular, that the use of holographic beamforming by metasurfaces can provide significant energy efficiency gains compared to fully digital beamforming architectures, even when the latter achieve substantial multiplexing gains."}

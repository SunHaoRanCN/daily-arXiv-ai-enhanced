<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.SD](#cs.SD) [Total: 4]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Neural Brain Fields: A NeRF-Inspired Approach for Generating Nonexistent EEG Electrodes](https://arxiv.org/abs/2601.00012)
*Shahar Ain Kedem,Itamar Zimerman,Eliya Nachmani*

Main category: eess.SP

TL;DR: 提出一种受NeRF启发的EEG信号处理方法，将EEG电极类比为NeRF中的视角，训练神经网络编码整个EEG信号，实现信号重建、超分辨率渲染和虚拟电极生成。


<details>
  <summary>Details</summary>
Motivation: EEG数据具有长度可变、信噪比极低、个体差异大、时间漂移等挑战，且缺乏大规模干净数据集，需要开发有效的深度学习处理方法。

Method: 借鉴NeRF思想，将EEG电极位置类比为NeRF中的不同视角，训练神经网络在单个EEG样本上学习连续神经活动的表示，生成固定大小的权重向量编码整个信号。

Result: 能够实现EEG信号的连续可视化（包括超分辨率）、原始信号重建、虚拟电极数据生成，并能将重建信号输入标准EEG处理网络提升性能。

Conclusion: 该方法为EEG信号处理提供了新的NeRF风格框架，能够有效应对EEG数据的独特挑战，实现信号重建、超分辨率渲染和虚拟电极生成等应用。

Abstract: Electroencephalography (EEG) data present unique modeling challenges because recordings vary in length, exhibit very low signal to noise ratios, differ significantly across participants, drift over time within sessions, and are rarely available in large and clean datasets. Consequently, developing deep learning methods that can effectively process EEG signals remains an open and important research problem. To tackle this problem, this work presents a new method inspired by Neural Radiance Fields (NeRF). In computer vision, NeRF techniques train a neural network to memorize the appearance of a 3D scene and then uses its learned parameters to render and edit the scene from any viewpoint. We draw an analogy between the discrete images captured from different viewpoints used to learn a continuous 3D scene in NeRF, and EEG electrodes positioned at different locations on the scalp, which are used to infer the underlying representation of continuous neural activity. Building on this connection, we show that a neural network can be trained on a single EEG sample in a NeRF style manner to produce a fixed size and informative weight vector that encodes the entire signal. Moreover, via this representation we can render the EEG signal at previously unseen time steps and spatial electrode positions. We demonstrate that this approach enables continuous visualization of brain activity at any desired resolution, including ultra high resolution, and reconstruction of raw EEG signals. Finally, our empirical analysis shows that this method can effectively simulate nonexistent electrodes data in EEG recordings, allowing the reconstructed signal to be fed into standard EEG processing networks to improve performance.

</details>


### [2] [Modeling Day-Long ECG Signals to Predict Heart Failure Risk with Explainable AI](https://arxiv.org/abs/2601.00014)
*Eran Zvuloni,Ronit Almog,Michael Glikson,Shany Brimer Biton,Ilan Green,Izhar Laufer,Offer Amir,Joachim A. Behar*

Main category: eess.SP

TL;DR: 使用深度学习模型DeepHHF分析24小时单导联心电图数据，可在5年内预测心衰风险，性能优于30秒片段模型和临床评分


<details>
  <summary>Details</summary>
Motivation: 心衰影响11.8%的65岁以上成年人，降低生活质量和寿命。预防心衰可减少发病率和死亡率。需要非侵入性、廉价且广泛可及的预测工具

Method: 使用Technion-Leumit Holter ECG数据集（69,663条记录，47,729名患者，20年数据）。开发深度学习模型DeepHHF，训练于24小时心电图记录，并与30秒片段模型和临床评分对比

Result: DeepHHF的AUC为0.80，优于30秒片段模型和临床评分。高风险个体住院或死亡风险增加两倍。可解释性分析显示模型关注心律失常和心脏异常，关键注意力在上午8点至下午3点

Conclusion: 深度学习建模24小时连续心电图数据可行，能捕捉阵发性事件和昼夜节律变化，对可靠风险预测至关重要。基于单导联Holter心电图的人工智能方法非侵入、廉价、广泛可及，是心衰风险预测的有前景工具

Abstract: Heart failure (HF) affects 11.8% of adults aged 65 and older, reducing quality of life and longevity. Preventing HF can reduce morbidity and mortality. We hypothesized that artificial intelligence (AI) applied to 24-hour single-lead electrocardiogram (ECG) data could predict the risk of HF within five years. To research this, the Technion-Leumit Holter ECG (TLHE) dataset, including 69,663 recordings from 47,729 patients, collected over 20 years was used. Our deep learning model, DeepHHF, trained on 24-hour ECG recordings, achieved an area under the receiver operating characteristic curve of 0.80 that outperformed a model using 30-second segments and a clinical score. High-risk individuals identified by DeepHHF had a two-fold chance of hospitalization or death incidents. Explainability analysis showed DeepHHF focused on arrhythmias and heart abnormalities, with key attention between 8 AM and 3 PM. This study highlights the feasibility of deep learning to model 24-hour continuous ECG data, capturing paroxysmal events and circadian variations essential for reliable risk prediction. Artificial intelligence applied to single-lead Holter ECG is non-invasive, inexpensive, and widely accessible, making it a promising tool for HF risk prediction.

</details>


### [3] [Adaptive Pinching Antenna Optimization via Meta-Learning for Physical-Layer Security in Dynamic Wireless Networks](https://arxiv.org/abs/2601.00115)
*Khalid T. Musri,Akram Y. Sarhan,Osamah A. Abdullah,Hayder Al-Hraishawi*

Main category: eess.SP

TL;DR: 基于梯度的元学习框架，用于在用户位置不确定和物理层安全约束下实时控制波导夹持天线系统，通过元学习实现快速适应动态环境。


<details>
  <summary>Details</summary>
Motivation: 在动态无线环境中，用户位置不确定性和物理层安全需求对波导夹持天线系统的实时控制提出了挑战，需要能够快速适应变化的优化方法。

Method: 提出概率系统模型捕捉定位不完美对中断和保密性能的影响，建立联合天线定位和发射功率优化问题，采用模型无关元学习（MAML）学习可迁移的初始化参数，实现基于有限导频反馈的少样本在线适应。

Result: 仿真结果表明，该框架在中断概率、保密性能和收敛延迟方面显著优于基于Reptile的元学习、非元强化学习、传统优化、静态天线放置和仅功率控制方法。

Conclusion: 元学习是控制非平稳无线环境中可重构夹持天线系统实现安全和低延迟控制的有效工具。

Abstract: This paper develops a gradient-based meta-learning framework for real-time control of waveguided pinching-antenna systems under user-location uncertainty and physical-layer security (PLS) constraints. A probabilistic system model is introduced to capture the impact of imperfect localization on outage performance and secrecy. Based on this model, a joint antenna-positioning and transmit-power optimization problem is formulated to satisfy probabilistic reliability and secrecy requirements. To enable rapid adaptation in highly dynamic environments, the proposed approach employs model-agnostic meta-learning (MAML) to learn a transferable initialization across diverse mobility and channel conditions, allowing few-shot online adaptation using limited pilot feedback. Simulation results demonstrate that the proposed framework significantly outperforms Reptile-based meta-learning, non-meta reinforcement learning, conventional optimization, static antenna placement, and power-only control in terms of outage probability, secrecy performance, and convergence latency. These results establish meta-learning as an effective tool for secure and low-latency control of reconfigurable pinching-antenna systems in non-stationary wireless environments.

</details>


### [4] [AI-Driven Channel State Information (CSI) Extrapolation for 6G: Current Situations, Challenges and Future Research](https://arxiv.org/abs/2601.00159)
*Yuan Gao,Zichen Lu,Xinyi Wu,Wenjun Yu,Shengli Liu,Jianbo Du,Yanliang Jin,Shunqing Zhang,Xiaoli Chu,Shugong Xu*

Main category: eess.SP

TL;DR: 该论文首次全面综述了6G通信系统中CSI外推技术的现状、挑战和未来方向，涵盖性能指标、模型驱动和AI驱动方法、数据集以及研究机遇。


<details>
  <summary>Details</summary>
Motivation: 传统信道估计方法在高移动性、超大规模MIMO和多频段系统中面临可扩展性挑战，CSI外推技术通过部分CSI推断完整CSI来显著降低开销，但目前缺乏对该领域SOTA技术的全面综述。

Method: 首先分析6G中CSI外推的特定性能指标（外推精度、动态场景适应性和算法成本），然后综述时间和频域、天线域以及多域CSI外推的模型驱动和AI驱动方法，总结关键见解，并考察可用于训练高性能AI模型的开放数据集和仿真器。

Result: 提供了CSI外推技术的系统性综述，总结了现有方法的优缺点，识别了关键挑战，并提出了未来研究方向。

Conclusion: AI驱动方法在满足6G性能要求方面具有潜力，但需要解决现有研究的挑战并探索新的研究机会，包括更好的数据集、算法优化和实际部署问题。

Abstract: CSI extrapolation is an effective method for acquiring channel state information (CSI), essential for optimizing performance of sixth-generation (6G) communication systems. Traditional channel estimation methods face scalability challenges due to the surging overhead in emerging high-mobility, extremely large-scale multiple-input multiple-output (EL-MIMO), and multi-band systems. CSI extrapolation techniques mitigate these challenges by using partial CSI to infer complete CSI, significantly reducing overhead. Despite growing interest, a comprehensive review of state-of-the-art (SOTA) CSI extrapolation techniques is lacking. This paper addresses this gap by comprehensively reviewing the current status, challenges, and future directions of CSI extrapolation for the first time. Firstly, we analyze the performance metrics specific to CSI extrapolation in 6G, including extrapolation accuracy, adaption to dynamic scenarios and algorithm costs. We then review both model-driven and artificial intelligence (AI)-driven approaches for time, frequency, antenna, and multi-domain CSI extrapolation. Key insights and takeaways from these methods are summarized. Given the promise of AI-driven methods in meeting performance requirements, we also examine the open-source channel datasets and simulators that could be used to train high-performance AI-driven CSI extrapolation models. Finally, we discuss the critical challenges of the existing research and propose perspective research opportunities.

</details>


### [5] [Edge AI Inference in ISCC Networks: Sensing Accuracy Analysis and Precoding Design](https://arxiv.org/abs/2601.00171)
*Lingyun Xu,Bowen Wang,Huiyong Li,Ziyang Cheng*

Main category: eess.SP

TL;DR: 本文研究ISCC网络中边缘AI推理的感知精度与预编码系数关系，提出判别增益指标和有效的预编码算法。


<details>
  <summary>Details</summary>
Motivation: 探索集成感知、通信与计算网络中边缘AI推理的感知精度与预编码系数之间的理论关系，为优化边缘推理性能提供理论基础。

Method: 构建空中赋能ISCC网络的系统模型，提出判别增益指标来表征感知精度，推导DG与预编码系数的显式函数关系，并设计非凸DG最大化问题的预编码算法。

Result: 仿真结果验证了所提设计在ISCC网络中边缘推理的有效性和可行性，为预编码设计提供了有价值的理论指导。

Conclusion: 本文建立了ISCC网络中感知精度与预编码系数的理论联系，提出的判别增益指标和预编码算法为优化边缘AI推理性能提供了有效解决方案。

Abstract: This work explores the relationship between sensing accuracy and precoding coefficients for edge artificial intelligence (AI) inference in integrated sensing, communication and computation (ISCC) networks. We start by constructing a system model of an over-the-air-empowered ISCC network for edge AI inference, involving distributed edge sensors for feature extraction and an edge server for classification. Based on this model, we introduce a discriminant gain (DG) to characterize sensing accuracy and novelly derive an explicit function of the DG about precoding coefficients, giving valuable insights into precoding design. Guided by this, we propose an effective precoding algorithm to solve a non-convex DG-maximization problem. Simulation results verify the effectiveness and feasibility of the proposed design for edge inference in ISCC networks.

</details>


### [6] [Time--to--Digital Converter (TDC)--Based Resonant Compute--in--Memory for INT8 CNNs with Layer--Optimized SRAM Mapping](https://arxiv.org/abs/2601.00434)
*Dhandeep Challagundla,Ignatius Bezzam,Riadul Islam*

Main category: eess.SP

TL;DR: 提出基于时间域计算的存内计算架构，用时间数字转换器替代传统模数转换器，降低功耗和面积，实现高效神经网络加速


<details>
  <summary>Details</summary>
Motivation: 传统存内计算架构使用模数转换器执行MAC操作，导致面积和功耗显著增加并引入非线性误差，需要更高效的解决方案

Method: 提出谐振时间域存内计算架构，使用8T SRAM单元实现可靠的按位MAC操作，采用4位时间数字转换器和脉冲收缩延迟元件进行数字化，结合权重固定的数据映射策略和自动SRAM宏选择算法

Result: 在TSMC 28nm工艺上验证8KB SRAM阵列，吞吐量达320GOPS，能效为38.46TOPS/W，在六个CNN模型中推理能耗降低达8倍，量化后精度损失最小

Conclusion: TDC-CiM架构通过消除ADC需求，显著降低了存内计算的功耗和面积成本，同时保持高性能和能效，为神经网络加速提供了可扩展的解决方案

Abstract: In recent years, Compute-in-memory (CiM) architectures have emerged as a promising solution for deep neural network (NN) accelerators. Multiply-accumulate~(MAC) is considered a {\textit de facto} unit operation in NNs. By leveraging the inherent parallel processing capabilities of CiM, NNs that require numerous MAC operations can be executed more efficiently. This is further facilitated by storing the weights in SRAM, reducing the need for extensive data movement and enhancing overall computational speed and efficiency. Traditional CiM architectures execute MAC operations in the analog domain, employing an Analog-to-Digital converter (ADC) to convert the analog MAC values into digital outputs. However, these ADCs introduce significant increase in area and power consumption, as well as introduce non-linearities. This work proposes a resonant time-domain compute-in-memory (TDC-CiM) architecture that eliminates the need for an ADC by using a time-to-digital converter (TDC) to digitize analog MAC results with lower power and area cost. A dedicated 8T SRAM cell enables reliable bitwise MAC operations, while the readout uses a 4-bit TDC with pulse-shrinking delay elements, achieving 1 GS/s sampling with a power consumption of only 1.25 mW. In addition, a weight stationary data mapping strategy combined with an automated SRAM macro selection algorithm enables scalable and energy-efficient deployment across CNN workloads. Evaluation across six CNN models shows that the algorithm reduces inference energy consumption by up to 8x when scaling SRAM size from 32~KB to 256~KB, while maintaining minimal accuracy loss after quantization. The feasibility of the proposed architecture is validated on an 8~KB SRAM memory array using TSMC 28~nm technology. The proposed TDC-CiM architecture demonstrates a throughput of 320~GOPS with an energy efficiency of 38.46~TOPS/W.

</details>


### [7] [MIMO-AFDM Outperforms MIMO-OFDM in the Face of Hardware Impairments](https://arxiv.org/abs/2601.00502)
*Zeping Sui,Zilong Liu,Leila Musavian,Yong Liang Guan,Lie-Liang Yang,Lajos Hanzo*

Main category: eess.SP

TL;DR: 研究硬件损伤对MIMO-AFDM系统的影响，发现AFDM在硬件损伤下仍能保持完全分集阶数，且比OFDM对乘性和加性损伤更具鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 研究硬件损伤（包括乘性和加性损伤）对MIMO-AFDM系统性能的影响，评估其在现实硬件不完美条件下的表现，并与传统MIMO-OFDM系统进行对比。

Method: 对于小规模MIMO-AFDM系统，推导了与最大似然检测器相关的紧密BER上界；对于大规模系统，提出了与线性最小均方误差检测器相关的闭式BER近似，包括不完美信道估计场景。

Result: 1) 硬件损伤的AFDM系统仍能保持完全分集阶数；2) 推导的BER结果能准确预测中高信噪比下的ML性能；3) MIMO-AFDM比OFDM对乘性失真更具鲁棒性；4) 在相同加性硬件损伤条件下，MIMO-AFDM始终优于MIMO-OFDM。

Conclusion: AFDM凭借其固有的啁啾信号特性和离散仿射傅里叶变换的有益扩展效应，相比OFDM展现出更强的载波间干扰鲁棒性，即使在硬件损伤下也能实现最大完全分集增益。

Abstract: The impact of both multiplicative and additive hardware impairments (HWIs) on multiple-input multiple-output affine frequency division multiplexing (MIMO-AFDM) systems is investigated. For small-scale MIMO-AFDM systems, a tight bit error rate (BER) upper bound associated with the maximum likelihood (ML) detector is derived. By contrast, for large-scale systems, a closed-form BER approximation associated with the linear minimum mean squared error (LMMSE) detector is presented, including realistic imperfect channel estimation scenarios. Our first key observation is that the full diversity order of a hardware-impaired AFDM system remains unaffected, which is a unique advantage. Furthermore, our analysis shows that 1) the BER results derived accurately predict the simulated ML performance in moderate-to-high signal-to-noise ratios (SNRs), while the theoretical BER curve of the LMMSE detector closely matches that of the Monte-Carlo based one. 2) MIMO-AFDM is more resilient to multiplicative distortions, such as phase noise and carrier frequency offset, compared to its orthogonal frequency division multiplexing (OFDM) counterparts. This is attributed to its inherent chirp signal characteristics; 3) MIMO-AFDM consistently achieves superior BER performance compared to conventional MIMO-OFDM systems under the same additive HWI conditions, as well as different velocity values. The latter is because MIMO-AFDM is also resilient to the additional inter-carrier interference (ICI) imposed by the nonlinear distortions of additive HWIs. In a nutshell, compared to OFDM, AFDM demonstrates stronger ICI resilience and achieves the maximum full diversity attainable gain even under HWIs, thanks to its intrinsic chirp signalling structure as well as to the beneficial spreading effect of the discrete affine Fourier transform.

</details>


### [8] [Parametrized Sharing for Multi-Agent Hybrid DRL for Multiple Multi-Functional RISs-Aided Downlink NOMA Networks](https://arxiv.org/abs/2601.00538)
*Chi-Te Kuo,Li-Hsiang Shen,Jyun-Jhe Huang*

Main category: eess.SP

TL;DR: 提出参数化共享的多智能体混合深度强化学习(PMHRL)方法，优化多MF-RIS辅助的NOMA下行网络，实现最高能量效率


<details>
  <summary>Details</summary>
Motivation: 多功能可重构智能表面(MF-RIS)结合了主动RIS的扩展信号覆盖和能量收集的自持能力，但需要有效优化其配置以最大化NOMA网络的能量效率

Method: 提出参数化共享的多智能体混合深度强化学习(PMHRL)，结合PPO处理连续变量(功率分配、波束赋形、MF-RIS配置)和DQN处理离散变量(MF-RIS位置)，优化能量效率最大化问题

Result: PMHRL方法相比其他基准(无参数化共享、纯PPO、纯DQN)获得最高能量效率；多MF-RIS辅助的NOMA下行网络相比无EH/放大、传统RIS、无RIS/MF-RIS部署在不同多址方案下均实现最高能量效率

Conclusion: 提出的PMHRL方法能有效优化多MF-RIS辅助的NOMA网络，显著提升能量效率，验证了MF-RIS架构和参数化共享强化学习方法的优越性

Abstract: Multi-functional reconfigurable intelligent surface (MF-RIS) is conceived to address the communication efficiency thanks to its extended signal coverage from its active RIS capability and self-sustainability from energy harvesting (EH). We investigate the architecture of multi-MF-RISs to assist non-orthogonal multiple access (NOMA) downlink networks. We formulate an energy efficiency (EE) maximization problem by optimizing power allocation, transmit beamforming and MF-RIS configurations of amplitudes, phase-shifts and EH ratios, as well as the position of MF-RISs, while satisfying constraints of available power, user rate requirements, and self-sustainability property. We design a parametrized sharing scheme for multi-agent hybrid deep reinforcement learning (PMHRL), where the multi-agent proximal policy optimization (PPO) and deep-Q network (DQN) handle continuous and discrete variables, respectively. The simulation results have demonstrated that proposed PMHRL has the highest EE compared to other benchmarks, including cases without parametrized sharing, pure PPO and DQN. Moreover, the proposed multi-MF-RISs-aided downlink NOMA achieves the highest EE compared to scenarios of no-EH/amplification, traditional RISs, and deployment without RISs/MF-RISs under different multiple access.

</details>


### [9] [Fractional Programming for Kullback-Leibler Divergence in Hypothesis Testing](https://arxiv.org/abs/2601.00564)
*Jeongwoo Park,Seongkyu Jung,Kaiming Shen,Jeonghun Park*

Main category: eess.SP

TL;DR: 提出基于分数规划的计算高效优化框架，用于最大化Kullback-Leibler散度，显著降低计算复杂度并加速收敛。


<details>
  <summary>Details</summary>
Motivation: KLD最大化在主动感知和假设检验中至关重要，但现有方法计算复杂度高，需要每次迭代进行矩阵求逆，限制了实际应用。

Method: 使用矩阵分数规划将KLD最大化问题转化为一系列可处理的二次子问题；引入非齐次松弛技术用闭式更新替代线性系统求解；采用STEM加速方法提升收敛速度。

Result: 算法将每次迭代复杂度降至二次阶，总运行时间比现有最优基准减少数个数量级，在多个随机接入和联合感知通信场景中验证了有效性。

Conclusion: 提出的计算高效优化框架成功解决了KLD最大化中的非凸优化难题，为主动感知和假设检验中的波形设计提供了实用解决方案。

Abstract: Maximizing the Kullback-Leibler divergence (KLD) is a fundamental problem in waveform design for active sensing and hypothesis testing, as it directly relates to the error exponent of detection probability. However, the associated optimization problem is highly nonconvex due to the intricate coupling of log-determinant and matrix trace terms. Existing solutions often suffer from high computational complexity, typically requiring matrix inversion at every iteration. In this paper, we propose a computationally efficient optimization framework based on fractional programming (FP). Our key idea is to reformulate the KLD maximization problem into a sequence of tractable quadratic subproblems using matrix FP. To further reduce complexity, we introduce a nonhomogeneous relaxation technique that replaces the costly linear system solver with a simple closed-form update, thereby reducing the per-iteration complexity to quadratic order. To compensate for the convergence speed trade-off caused by relaxation, we employ an acceleration method called STEM by interpreting the iterative scheme as a fixed-point mapping. The resulting algorithm achieves significantly faster convergence rates with low per-iteration cost. Numerical results demonstrate that our approach reduces the total runtime by orders of magnitude compared to a state-of-the-art benchmark. Finally, we apply the proposed framework to a multiple random access scenario and a joint integrated sensing and communication scenario, validating the efficacy of our framework in such applications.

</details>


### [10] [WiFo-MUD: Wireless Foundation Model for Heterogeneous Multi-User Demodulator](https://arxiv.org/abs/2601.00612)
*Zonghui Yang,Shijian Gao,Xuesong Cai,Xiang Cheng,Liuqing Yang*

Main category: eess.SP

TL;DR: 提出WiFo-MUD，一种基于扩散模型的通用多用户解调基础模型，通过条件去噪、通信感知一致性蒸馏和动态用户分组策略，在异构配置下实现高效推理和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有解调器在通用多用户环境中表现不佳：经典解调器难以平衡准确性和复杂度，基于深度学习的方法在异构配置下缺乏适应性，扩散模型在实际应用中的灵活性有限。

Method: 提出WiFo-MUD模型，包括：对齐用户间信噪比不平衡、通过定制化骨干网络进行条件去噪、设计通信感知一致性蒸馏方法以增强推理、采用动态用户分组策略。

Result: 在大规模异构数据集上取得最先进结果，展示了高效推理能力和在不同系统配置下的强泛化性能。

Conclusion: WiFo-MUD作为一种通用的扩散基础模型，有效解决了多用户解调中的准确性与复杂性平衡问题，在异构环境中表现出优越的适应性和泛化能力。

Abstract: Multi-user signal demodulation is critical to wireless communications, directly impacting transmission reliability and efficiency. However, existing demodulators underperform in generic multi-user environments: classical demodulators struggle to balance accuracy and complexity, while deep learning-based methods lack adaptability under heterogeneous configurations. Although diffusion models have been introduced for demodulation, their flexibility remains limited for practical use. To address these issues, this work proposes WiFo-MUD, a universal diffusion-based foundation model for multi-user demodulation. The model aligns inter-user signal-to-noise ratio imbalance and performs conditional denoising via a customized backbone. Furthermore, a communication-aware consistency distillation method and a dynamic user-grouping strategy are devised to enhance inference. WiFo-MUD achieves state-of-the-art results on large-scale heterogeneous datasets, demonstrating efficient inference and strong generalization across varying system configurations.

</details>


### [11] [Splitting Precoding with Subspace Selection and Quantized Refinement for Massive MIMO](https://arxiv.org/abs/2601.00616)
*Yasaman Khorsandmanesh,Emil Bjornson,Joakim Jalden*

Main category: eess.SP

TL;DR: 提出一种分割预编码架构，将预编码设计分离到AAS和BBU之间，以解决大规模MIMO中有限前传容量瓶颈问题


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO 5G架构中有限的前传容量是一个实际瓶颈，传统下行设计将整个预编码计算放在BBU，并通过前传传输高维预编码矩阵，导致显著的量化损失和信令开销

Method: 提出分割预编码架构：AAS执行本地子空间选择以降低信道维度，BBU基于得到的有效信道计算优化的量化细化预编码

Result: 数值结果表明，所提出的分割预编码策略比传统单阶段预编码实现了更高的总频谱效率

Conclusion: 通过将预编码设计分离到AAS和BBU之间，有效解决了大规模MIMO中前传容量限制问题，提高了系统性能

Abstract: Limited fronthaul capacity is a practical bottleneck in massive multiple-input multiple-output (MIMO) 5G architectures, where a base station (BS) consists of an advanced antenna system (AAS) connected to a baseband unit (BBU). Conventional downlink designs place the entire precoding computation at the BBU and transmit a high-dimensional precoding matrix over the fronthaul, resulting in substantial quantization losses and signaling overhead. This letter proposes a splitting precoding architecture that separates the design between the AAS and BBU. The AAS performs a local subspace selection to reduce the channel dimensionality, while the BBU computes an optimized quantized refinement precoding based on the resulting effective channel. The numerical results show that the proposed splitting precoding strategy achieves higher sum spectral efficiency than conventional one-stage precoding.

</details>


### [12] [Conformal Reconfigurable Intelligent Surfaces: A Cylindrical Geometry Perspective](https://arxiv.org/abs/2601.00734)
*Filippo Pepe,Ivan Iudice,Giuseppe Castaldi,Marco Di Renzo,Vincenzo Galdi*

Main category: eess.SP

TL;DR: 该论文系统研究了圆柱形可重构智能表面，从理想表面阻抗合成到基于一比特超原子单元的实际实现，建立了分析模型并验证了其波束合成能力。


<details>
  <summary>Details</summary>
Motivation: 研究圆柱形可重构智能表面的动机在于将其应用于下一代无线通信的非平面平台，如无人机和城市基础设施，实现自适应波前控制。

Method: 首先开发了精确解析模型和几何光学模型探索基本设计极限，然后提出了针对离散可重构架构的半解析公式，采用进化优化和低复杂度策略（如最小功率无失真响应方法）进行波束合成，并通过全波仿真验证。

Result: 结果表明，一比特可重构智能表面能够实现定向散射，具有可控的旁瓣水平和最小的硬件复杂度。

Conclusion: 圆柱形可重构智能表面具有可行性，为将其集成到实际通信场景中的双用途无线平台打开了大门。

Abstract: Curved reconfigurable intelligent surfaces (RISs) represent a promising frontier for next-generation wireless communication, enabling adaptive wavefront control on nonplanar platforms such as unmanned aerial vehicles and urban infrastructure. This work presents a systematic investigation of cylindrical RISs, progressing from idealized surface-impedance synthesis to practical implementations based on simple one-bit meta-atoms. Exact analytical and geometrical-optics-based models are first developed to explore fundamental design limits, followed by a semi-analytical formulation tailored to discrete, reconfigurable architectures. This model enables efficient beam synthesis using both evolutionary optimization and low-complexity strategies, including the minimum power distortionless response method, and is validated through full-wave simulations. Results confirm that one-bit RISs can achieve directive scattering with manageable sidelobe levels and minimal hardware complexity. These findings establish the viability of cylindrical RISs and open the door to their integration into dual-use wireless platforms for real-world communication scenarios.

</details>


### [13] [Energy Efficiency Maximization of MIMO Systems through Reconfigurable Holographic Beamforming](https://arxiv.org/abs/2601.00780)
*Robert Kuku Fotock,Alessio Zappone,Agbotiname Lucky Imoize,Marco Di Renzo*

Main category: eess.SP

TL;DR: 论文研究了一种在发射端和接收端都部署可重构超表面的点对点多天线无线链路，通过优化发射协方差矩阵和超表面反射矩阵来最大化系统能量效率，提出了一种低复杂度算法并证明了收敛性。


<details>
  <summary>Details</summary>
Motivation: 传统全数字波束赋形架构虽然能实现多路复用增益，但能耗较高。超表面实现的全息波束赋形有望在保持性能的同时显著提升能量效率。

Method: 在发射和接收天线阵列附近各部署一个可重构超表面，形成全息波束赋形结构。优化发射协方差矩阵和两个超表面的反射矩阵以最大化能量效率。提出低复杂度算法保证收敛到一阶最优点，并在单天线/单流传输情况下推导了超表面矩阵的闭式解。

Result: 数值性能分析表明，基于超表面的全息波束赋形相比全数字波束赋形架构能提供显著的能量效率增益，即使后者实现了可观的多路复用增益。

Conclusion: 超表面实现的全息波束赋形是提升无线通信系统能量效率的有效方法，提出的优化算法具有低复杂度和收敛保证，为实际部署提供了理论支持。

Abstract: This study considers a point-to-point wireless link, in which both the transmitter and receiver are equipped with multiple antennas. In addition, two reconfigurable metasurfaces are deployed, one in the immediate vicinity of the transmit antenna array, and one in the immediate vicinity of the receive antenna array. The resulting architecture implements a holographic beamforming structure at both the transmitter and receiver. In this scenario, the system energy efficiency is optimized with respect to the transmit covariance matrix, and the reflection matrices of the two metasurfaces. A low-complexity algorithm is developed, which is guaranteed to converge to a first-order optimal point of the energy efficiency maximization problem. Moreover, closed-form expressions are derived for the metasurface matrices in the special case of single-antenna or single-stream transmission. The two metasurfaces are considered to be nearly-passive and subject to global reflection constraints. A numerical performance analysis is conducted to assess the performance of the proposed optimization methods, showing, in particular, that the use of holographic beamforming by metasurfaces can provide significant energy efficiency gains compared to fully digital beamforming architectures, even when the latter achieve substantial multiplexing gains.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [14] [Learning Speech Representations with Variational Predictive Coding](https://arxiv.org/abs/2601.00100)
*Sung-Lin Yeh,Peter Bell,Hao Tang*

Main category: eess.AS

TL;DR: 本文揭示了HuBERT目标背后的原理是变分预测编码，并基于此提出了改进方法，在多个下游任务上取得了显著提升。


<details>
  <summary>Details</summary>
Motivation: HuBERT作为学习语音表示的最佳目标，其发展停滞是因为缺乏理论基础。本文旨在揭示HuBERT背后的原理，即变分预测编码，从而为改进提供理论指导。

Method: 提出预测编码的变分视角作为HuBERT的理论基础，基于该理论框架改进了参数化和优化方法，包括两个简单的修改。

Result: 预训练的改进在四个下游任务上带来显著提升：音素分类、基频跟踪、说话人识别和自动语音识别，验证了预测编码解释的重要性。

Conclusion: 预测编码是HuBERT目标的理论基础，该理论框架不仅解释了HuBERT的工作原理，还为改进提供了方向，并建立了与其他目标（如APC、CPC、wav2vec、BEST-RQ）的理论联系。

Abstract: Despite being the best known objective for learning speech representations, the HuBERT objective has not been further developed and improved. We argue that it is the lack of an underlying principle that stalls the development, and, in this paper, we show that predictive coding under a variational view is the principle behind the HuBERT objective. Due to its generality, our formulation provides opportunities to improve parameterization and optimization, and we show two simple modifications that bring immediate improvements to the HuBERT objective. In addition, the predictive coding formulation has tight connections to various other objectives, such as APC, CPC, wav2vec, and BEST-RQ. Empirically, the improvement in pre-training brings significant improvements to four downstream tasks: phone classification, f0 tracking, speaker recognition, and automatic speech recognition, highlighting the importance of the predictive coding interpretation.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [15] [IKFST: IOO and KOO Algorithms for Accelerated and Precise WFST-based End-to-End Automatic Speech Recognition](https://arxiv.org/abs/2601.00160)
*Zhuoran Zhuang,Ye Chen,Chao Luo,Tian-Hao Zhang,Xuewei Zhang,Jian Ma,Jiatong Shi,Wei Zhang*

Main category: cs.SD

TL;DR: 提出两种新的解码算法（Keep-Only-One和Insert-Only-One），利用CTC输出中空白帧和非空白帧的结构特性，显著提升WFST解码效率而不损失识别准确率。


<details>
  <summary>Details</summary>
Motivation: 当前基于WFST的端到端语音识别系统虽然性能优越，但依赖CTC后验概率的逐帧自回归搜索，导致推理效率低下。需要建立WFST解码与CTC建模之间更原则性的兼容性。

Method: 系统分析CTC输出的两个基本组成部分（空白帧和非空白帧），发现空白帧主要编码位置信息，而非空白帧携带语义内容。基于这一观察，提出Keep-Only-One和Insert-Only-One两种解码算法，显式利用空白帧和非空白帧的结构角色来加速WFST推理。

Result: 在大规模内部数据集、AISHELL-1和LibriSpeech数据集上的实验表明，该方法在保持最先进识别准确率的同时，显著降低了解码延迟，实现了真正高效且高性能的WFST解码。

Conclusion: 通过深入理解CTC输出中空白帧和非空白帧的结构角色，提出的两种解码算法为现代语音识别系统提供了高效且高性能的WFST解码解决方案，在准确率和效率之间取得了良好平衡。

Abstract: End-to-end automatic speech recognition has become the dominant paradigm in both academia and industry. To enhance recognition performance, the Weighted Finite-State Transducer (WFST) is widely adopted to integrate acoustic and language models through static graph composition, providing robust decoding and effective error correction. However, WFST decoding relies on a frame-by-frame autoregressive search over CTC posterior probabilities, which severely limits inference efficiency. Motivated by establishing a more principled compatibility between WFST decoding and CTC modeling, we systematically study the two fundamental components of CTC outputs, namely blank and non-blank frames, and identify a key insight: blank frames primarily encode positional information, while non-blank frames carry semantic content. Building on this observation, we introduce Keep-Only-One and Insert-Only-One, two decoding algorithms that explicitly exploit the structural roles of blank and non-blank frames to achieve significantly faster WFST-based inference without compromising recognition accuracy. Experiments on large-scale in-house, AISHELL-1, and LibriSpeech datasets demonstrate state-of-the-art recognition accuracy with substantially reduced decoding latency, enabling truly efficient and high-performance WFST decoding in modern speech recognition systems.

</details>


### [16] [Latent Flow Matching for Expressive Singing Voice Synthesis](https://arxiv.org/abs/2601.00217)
*Minhyeok Yun,Yong-Hoon Choi*

Main category: cs.SD

TL;DR: FM-Singer使用条件流匹配改进歌声合成，通过潜在空间中的连续向量场将先验样本优化为后验样本，提升表现力同时保持并行解码效率。


<details>
  <summary>Details</summary>
Motivation: 基于条件变分自编码器的歌声合成存在先验-后验不匹配问题，导致颤音和微韵律等细粒度表现力下降，需要改进分布匹配质量。

Method: 在潜在空间中引入条件流匹配，学习将先验潜在变量传输到后验潜在变量的连续向量场，沿最优传输路径优化，推理时通过求解常微分方程细化先验样本。

Result: 在韩语和中文歌声数据集上实验显示，相比强基线模型，FM-Singer在梅尔倒谱失真、基频误差和感知评分方面均有显著改进。

Conclusion: FM-Singer通过条件流匹配有效解决了先验-后验不匹配问题，显著提升了歌声合成的表现力，同时保持了高效的并行解码能力。

Abstract: Conditional variational autoencoder (cVAE)-based singing voice synthesis provides efficient inference and strong audio quality by learning a score-conditioned prior and a recording-conditioned posterior latent space. However, because synthesis relies on prior samples while training uses posterior latents inferred from real recordings, imperfect distribution matching can cause a prior-posterior mismatch that degrades fine-grained expressiveness such as vibrato and micro-prosody. We propose FM-Singer, which introduces conditional flow matching (CFM) in latent space to learn a continuous vector field transporting prior latents toward posterior latents along an optimal-transport-inspired path. At inference time, the learned latent flow refines a prior sample by solving an ordinary differential equation (ODE) before waveform generation, improving expressiveness while preserving the efficiency of parallel decoding. Experiments on Korean and Chinese singing datasets demonstrate consistent improvements over strong baselines, including lower mel-cepstral distortion and fundamental-frequency error and higher perceptual scores on the Korean dataset. Code, pretrained checkpoints, and audio demos are available at https://github.com/alsgur9368/FM-Singer

</details>


### [17] [Timed text extraction from Taiwanese Kua-á-hì TV series](https://arxiv.org/abs/2601.00299)
*Tzu-Hung Huang,Yun-En Tsai,Yun-Ning Hung,Chih-Wei Wu,I-Chieh Wei,Li Su*

Main category: cs.SD

TL;DR: 开发交互式OCR校正系统和两步法（OCR分割+语音音乐活动检测），从低质量台湾歌仔戏电视录像中高效提取人声片段和歌词，构建可用于音乐信息检索任务的数据集


<details>
  <summary>Details</summary>
Motivation: 台湾歌仔戏（Kua-á-hì）作为重要的地方戏曲传统，经过电视改编后具有研究价值，但现有录像质量低且数据准备需要大量人工，需要自动化工具来简化处理流程

Method: 1）开发交互式实时OCR校正系统；2）采用两步法：先通过OCR驱动分割，再结合语音和音乐活动检测（SMAD）来精确识别档案剧集中的歌唱片段

Result: 构建了包含人声片段和对应歌词的数据集，能够以高精度从档案剧集中识别歌唱片段，该数据集可支持歌词识别、曲调检索等多种音乐信息检索任务

Conclusion: 提出的系统和方法能够有效处理低质量的台湾歌仔戏电视录像，自动化提取有价值的研究数据，为台湾戏曲的深入研究提供了技术支持和数据资源

Abstract: Taiwanese opera (Kua-á-hì), a major form of local theatrical tradition, underwent extensive television adaptation notably by pioneers like Iûnn Lē-hua. These videos, while potentially valuable for in-depth studies of Taiwanese opera, often have low quality and require substantial manual effort during data preparation. To streamline this process, we developed an interactive system for real-time OCR correction and a two-step approach integrating OCR-driven segmentation with Speech and Music Activity Detection (SMAD) to efficiently identify vocal segments from archival episodes with high precision. The resulting dataset, consisting of vocal segments and corresponding lyrics, can potentially supports various MIR tasks such as lyrics identification and tune retrieval. Code is available at https://github.com/z-huang/ocr-subtitle-editor .

</details>


### [18] [Investigating the Viability of Employing Multi-modal Large Language Models in the Context of Audio Deepfake Detection](https://arxiv.org/abs/2601.00777)
*Akanksha Chuchra,Shukesh Reddy,Sudeepta Mishra,Abhijit Das,Abhinav Dhall*

Main category: cs.SD

TL;DR: 探索多模态大语言模型（MLLMs）在音频深度伪造检测中的应用潜力，通过音频输入与多种文本提示结合，评估模型在零样本和微调模式下的表现。


<details>
  <summary>Details</summary>
Motivation: 虽然视觉语言模型和多模态大语言模型在图像和视频深度伪造检测中表现出色，但它们在音频深度伪造检测中的应用尚未充分探索。本研究旨在填补这一空白，探索MLLMs在音频深度伪造检测中的潜力。

Method: 结合音频输入与多种文本提示作为查询，采用文本感知和上下文丰富的问答式提示进行二元决策。评估Qwen2-Audio-7B-Instruct和SALMONN两种MLLMs在两种模式下的性能：(a) 零样本模式 (b) 微调模式。

Result: 实验表明：1) 模型在没有任务特定训练时表现不佳，难以泛化到域外数据；2) 在域内数据上，只需少量监督就能获得良好性能；3) 音频与多提示结合的方法在音频深度伪造检测中具有可行性。

Conclusion: 多模态大语言模型在音频深度伪造检测中展现出有前景的潜力，特别是通过音频与多提示结合的方法。虽然零样本泛化能力有限，但在少量监督下能在域内数据上取得良好效果，为音频深度伪造检测提供了新的研究方向。

Abstract: While Vision-Language Models (VLMs) and Multimodal Large Language Models (MLLMs) have shown strong generalisation in detecting image and video deepfakes, their use for audio deepfake detection remains largely unexplored. In this work, we aim to explore the potential of MLLMs for audio deepfake detection. Combining audio inputs with a range of text prompts as queries to find out the viability of MLLMs to learn robust representations across modalities for audio deepfake detection. Therefore, we attempt to explore text-aware and context-rich, question-answer based prompts with binary decisions. We hypothesise that such a feature-guided reasoning will help in facilitating deeper multimodal understanding and enable robust feature learning for audio deepfake detection. We evaluate the performance of two MLLMs, Qwen2-Audio-7B-Instruct and SALMONN, in two evaluation modes: (a) zero-shot and (b) fine-tuned. Our experiments demonstrate that combining audio with a multi-prompt approach could be a viable way forward for audio deepfake detection. Our experiments show that the models perform poorly without task-specific training and struggle to generalise to out-of-domain data. However, they achieve good performance on in-domain data with minimal supervision, indicating promising potential for audio deepfake detection.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 16]
- [eess.AS](#eess.AS) [Total: 6]
- [cs.SD](#cs.SD) [Total: 11]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [AFDM for LEO Inter-Satellite Links: Path-Level CSI Prediction and CRLB-Guided Pre-Equalization](https://arxiv.org/abs/2601.00819)
*Houtianfu Wang,Ozgur Akan*

Main category: eess.SP

TL;DR: 提出用于LEO星间链路的AFDM双阶段ISAC框架，包含路径级信道预测和感知增强预均衡器设计，在预测CSI下平衡通信与感知性能


<details>
  <summary>Details</summary>
Motivation: LEO星间链路面临强双选择性信道和过时CSI问题，现有AFDM设计假设理想CSI且仅优化通信性能，需要能处理预测CSI并平衡通信-感知的解决方案

Method: 两阶段框架：第一阶段对少量主导镜面路径进行序列预测，重建AFDM DD域核作为瞬时CSI；第二阶段设计感知增强AFDM预均衡器，在经典MMSE基础上加入CRLB型敏感度度量项

Result: 路径级预测器在AFDM DD域核重建上优于基线，感知增强预均衡器在预测CSI下显著提升感知指标，同时保持接近通信导向MMSE设计的符号错误率

Conclusion: 提出的AFDM双阶段ISAC框架能有效处理LEO星间链路的预测CSI问题，通过路径级预测和感知增强预均衡实现通信与感知的良好权衡

Abstract: Low-Earth-orbit (LEO) inter-satellite links must cope with strongly doubly selective channels and aged channel state information (CSI). In this paper, the term ``sensing'' refers to the receiver-side identifiability of a small set of dominant delay--Doppler path parameters, quantified via CRLB-type proxies, rather than a full-fledged target-sensing pipeline. Affine frequency division multiplexing (AFDM) provides a sparse delay--Doppler (DD) representation well suited to such channels, yet most existing AFDM designs assume ideal CSI, operate on grid-based channel coefficients, and optimize only communication performance. This paper proposes a two-stage AFDM-based ISAC framework for mobile LEO ISLs that explicitly operates under predicted CSI. In Stage~I, we model the channel by a small number of dominant specular paths and perform sequence prediction directly on their complex gains, delays, and Dopplers, from which we reconstruct the AFDM DD-domain kernel used as the sole instantaneous CSI at the transmitter. In Stage~II, we design a sensing-aware AFDM pre-equalizer by augmenting the classical minimum mean-square error (MMSE) solution with a term obtained from Cramér--Rao-type sensitivity measures evaluated under the predicted channel model, leading to a first-order surrogate of a CRLB-regularized pre-equalizer with a single tuning parameter that controls the communication--sensing tradeoff. Simulation results for representative LEO ISL trajectories show that the proposed path-level predictor improves effective-kernel reconstruction over AFDM-unaware baselines, and that, under predicted CSI, the sensing-aware pre-equalizer significantly improves sensing-oriented metrics over outdated-CSI baselines while keeping symbol error rates close to a communication-oriented MMSE design with only modest additional complexity.

</details>


### [2] [Environment-to-Link ISAC with Space-Weather Sensing for Ka-Band LEO Downlinks](https://arxiv.org/abs/2601.00820)
*Houtianfu Wang,Haofan Dong,Hanlin Cai,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 提出一种基于双载波相位观测的GNSS-free预测控制器，用于Ka波段LEO下行链路在电离层扰动期间的可靠通信，通过提前检测和预测VTEC变化来触发自适应调制编码切换，提升链路可靠性。


<details>
  <summary>Details</summary>
Motivation: Ka波段低地球轨道下行链路在太阳耀斑驱动的电离层扰动期间会出现秒级可靠性崩溃，传统的固定衰减裕度和反应式自适应编码调制要么过于保守要么响应太慢，需要更有效的预测性控制方案。

Method: 采用GNSS-free、链路内部的预测控制器，通过10Hz的双载波相位观测感知下行链路，使用高通滤波和模板匹配的起始检测器，结合四状态近恒定速度卡尔曼滤波器估计ΔVTEC及其变化率，通过60秒前瞻预测计算端点中断概率，作为风险门限触发离散调制编码方案降级切换和导频时间更新。

Result: 在60秒压力窗口内，控制器相比无自适应基线将峰值BLER降低了25-30%，吞吐量提升了0.10-0.15 bps/Hz；控制器每0.1秒周期的计算复杂度为O(1)，实测约0.042毫秒，适合星上实现。

Conclusion: 该预测控制器能有效应对电离层扰动，提高Ka波段LEO下行链路的可靠性，计算效率高适合星载实现，并讨论了色散主导事件的范围和部署考虑。

Abstract: Ka-band low-Earth-orbit (LEO) downlinks can suffer second-scale reliability collapses during flare-driven ionospheric disturbances, where fixed fade margins and reactive adaptive coding and modulation (ACM) are either overly conservative or too slow. This paper presents a GNSS-free, link-internal predictive controller that senses the same downlink via a geometry-free dual-carrier phase observable at 10~Hz: a high-pass filter and template-based onset detector, followed by a four-state nearly-constant-velocity Kalman filter, estimate $Δ$VTEC and its rate, and a short look-ahead (60~s) yields an endpoint outage probability used as a risk gate to trigger one-step discrete MCS down-switch and pilot-time update with hysteresis. Evaluation uses physics-informed log replay driven by real GOES X-ray flare morphologies under a disjoint-day frozen-calibration protocol, with uncertainty reported via paired moving-block bootstrap. Across stressed 60~s windows, the controller reduces peak BLER by 25--30\% and increases goodput by 0.10--0.15~bps/Hz versus no-adaptation baselines under a unified link-level abstraction. The loop runs in $\mathcal{O}(1)$ per 0.1~s epoch (about 0.042~ms measured), making on-board implementation feasible, and scope and deployment considerations for dispersion-dominated events are discussed.

</details>


### [3] [Dynamic Accuracy Estimation in a Wi-Fi-based Positioning System](https://arxiv.org/abs/2601.00999)
*Marcin Kolakowski,Vitomir Djaja-Josko*

Main category: eess.SP

TL;DR: 提出了一种动态精度估计方法，通过定位算法使用的测量结果来推导定位误差，在Wi-Fi室内定位系统中验证，随机森林回归获得了最佳误差估计精度（平均绝对误差0.72米）。


<details>
  <summary>Details</summary>
Motivation: 室内定位系统通常无法实时评估定位精度，用户难以了解当前位置估计的可靠性。现有方法往往需要额外硬件或复杂计算，无法在实际应用中动态估计定位误差。

Method: 提出动态精度估计概念，基于定位算法实际使用的测量结果来推导定位误差。在Wi-Fi室内定位系统中，测试了多种回归方法：线性回归、随机森林、k近邻和神经网络，用于误差估计建模。

Result: 随机森林回归在定位误差估计方面表现最佳，平均绝对误差为0.72米。其他方法如线性回归、k近邻和神经网络也进行了测试，但随机森林获得了最高的误差估计精度。

Conclusion: 动态精度估计方法可行且有效，随机森林回归是最适合的误差估计技术。该方法能够为室内定位系统提供实时的精度评估，增强用户对定位结果的信任度。

Abstract: The paper presents a concept of a dynamic accuracy estimation method, in which the localization errors are derived based on the measurement results used by the positioning algorithm. The concept was verified experimentally in a Wi\nobreakdash-Fi based indoor positioning system, where several regression methods were tested (linear regression, random forest, k-nearest neighbors, and neural networks). The highest positioning error estimation accuracy was achieved for random forest regression, with a mean absolute error of 0.72 m.

</details>


### [4] [System-Level Comparison of Multimodal and In-Band mmWave Sensing for Beam Prediction in 6G ISAC](https://arxiv.org/abs/2601.01033)
*Abidemi Orimogunje,Hyunwoo Park,Igbafe Orikumhi,Sunwoo Kim,Dejan Vukobratovic*

Main category: eess.SP

TL;DR: 该论文提出了一个系统级框架，评估多种传感器（相机、LiDAR、雷达、GPS和毫米波功率）在车对基础设施通信中的波束预测性能，通过轻量级神经网络实现低延迟预测，为6G ISAC辅助的V2I系统建立了校准基准。


<details>
  <summary>Details</summary>
Motivation: 毫米波车对基础设施通信中波束训练开销大，集成感知与通信（ISAC）可以通过带内感知减少开销，而外部传感器可以进一步提高预测精度。需要系统评估不同传感器及其融合在波束预测中的性能。

Method: 开发了一个系统级框架，使用DeepSense-6G Scenario-33数据集评估相机、LiDAR、雷达、GPS和毫米波功率的单独及多模态融合性能。采用轻量级卷积神经网络和多层感知机编码器组成的延迟感知神经网络，预测64个波束索引。

Result: 毫米波功率向量是强大的独立预测器，与外部传感器融合保持高性能：毫米波单独及毫米波+LiDAR/GPS/雷达达到98%的Top-5准确率，毫米波+相机达到94%的Top-5准确率。通过频谱效率差距、信噪比差距、速率损失和端到端延迟等指标全面评估性能。

Conclusion: 该框架为6G ISAC辅助的V2I系统波束预测建立了校准基准，证明了毫米波功率作为核心预测器的有效性，以及多传感器融合在保持高性能的同时减少波束训练开销的潜力。

Abstract: Integrated sensing and communication (ISAC) can reduce beam-training overhead in mmWave vehicle-to-infrastructure (V2I) links by enabling in-band sensing-based beam prediction, while exteroceptive sensors can further enhance the prediction accuracy. This work develop a system-level framework that evaluates camera, LiDAR, radar, GPS, and in-band mmWave power, both individually and in multimodal fusion using the DeepSense-6G Scenario-33 dataset. A latency-aware neural network composed of lightweight convolutional (CNN) and multilayer-perceptron (MLP) encoders predict a 64-beam index. We assess performance using Top-k accuracy alongside spectral-efficiency (SE) gap, signal-to-noise-ratio (SNR) gap, rate loss, and end-to-end latency. Results show that the mmWave power vector is a strong standalone predictor, and fusing exteroceptive sensors with it preserves high performance: mmWave alone and mmWave+LiDAR/GPS/Radar achieve 98% Top-5 accuracy, while mmWave+camera achieves 94% Top-5 accuracy. The proposed framework establishes calibrated baselines for 6G ISAC-assisted beam prediction in V2I systems.

</details>


### [5] [Towards a Theoretical Framework for Robust Node Deployment in Cooperative ISAC Networks](https://arxiv.org/abs/2601.01152)
*Haojin Li,Kaiqian Qu,Chen Sun,Anbang Zhang,Xiaoxue Wang,Wenqi Zhang,Haijun Zhang*

Main category: eess.SP

TL;DR: 该论文研究了ISAC网络中多节点协同定位的节点部署策略，通过最小化加权导向矢量相关性来优化节点位置和阵列方向，提升最坏情况下的网络鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在集成感知与通信网络中，不同位置导向矢量的相关性会影响定位性能，需要设计鲁棒的节点部署策略来提升多节点协同定位的可靠性。

Method: 首先分析导向矢量相关性对定位性能的影响，提出距离加权相关性度量；然后建立部署优化框架，同时优化节点位置和阵列方向以最小化最大加权相关性；最后开发遗传算法求解该min-max优化问题。

Result: 通过MUSIC和神经网络定位方法的广泛仿真验证，所提方法显著提升了鲁棒定位性能，证明了优化部署策略的有效性。

Conclusion: 该研究提出的节点部署优化框架能够有效提升ISAC网络中多节点协同定位的鲁棒性，为实际网络部署提供了理论指导和技术方案。

Abstract: This paper investigates node deployment strategies for robust multi-node cooperative localization in integrated sensing and communication (ISAC) networks.We first analyze how steering vector correlation across different positions affects localization performance and introduce a novel distance-weighted correlation metric to characterize this effect. Building upon this insight, we propose a deployment optimization framework that minimizes the maximum weighted steering vector correlation by optimizing simultaneously node positions and array orientations, thereby enhancing worst-case network robustness. Then, a genetic algorithm (GA) is developed to solve this min-max optimization, yielding optimized node positions and array orientations. Extensive simulations using both multiple signal classification (MUSIC) and neural-network (NN)-based localization validate the effectiveness of the proposed methods, demonstrating significant improvements in robust localization performance.

</details>


### [6] [NeuroSSM: Multiscale Differential State-Space Modeling for Context-Aware fMRI Analysis](https://arxiv.org/abs/2601.01229)
*Furkan Genç,Boran İsmet Macun,Sait Sarper Özaslan,Emine U. Saritas,Tolga Çukur*

Main category: eess.SP

TL;DR: NeuroSSM：一种用于原始BOLD信号fMRI时间序列分析的选择性状态空间架构，通过多尺度状态空间骨干网络和并行差分分支，同时捕捉快速瞬态动态和缓慢全局趋势。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在fMRI分析中面临挑战：需要同时捕捉从快速瞬态动态到缓慢大规模波动的多尺度时间结构。Transformer虽然能处理长程依赖但计算成本高，而现有的SSM方法通常基于功能连接表示且采用单尺度处理，无法在单个模型中联合表示快速和缓慢动态。

Method: 提出NeuroSSM架构，包含两个核心组件：1) 多尺度状态空间骨干网络，通过选择性状态空间模型同时捕捉快速和缓慢动态；2) 并行差分分支，增强对瞬态状态变化的敏感性。该架构直接处理原始BOLD信号，实现端到端分析。

Result: 在临床和非临床数据集上的实验表明，NeuroSSM在性能和效率方面均优于现有的fMRI分析方法，能够有效捕捉多尺度时间动态。

Conclusion: NeuroSSM通过多尺度状态空间建模和差分增强机制，解决了现有方法在联合捕捉快速瞬态动态和缓慢全局趋势方面的局限性，为fMRI时间序列分析提供了高效且有效的解决方案。

Abstract: Accurate fMRI analysis requires sensitivity to temporal structure across multiple scales, as BOLD signals encode cognitive processes that emerge from fast transient dynamics to slower, large-scale fluctuations. Existing deep learning (DL) approaches to temporal modeling face challenges in jointly capturing these dynamics over long fMRI time series. Among current DL models, transformers address long-range dependencies by explicitly modeling pairwise interactions through attention, but the associated quadratic computational cost limits effective integration of temporal dependencies across long fMRI sequences. Selective state-space models (SSMs) instead model long-range temporal dependencies implicitly through latent state evolution in a dynamical system, enabling efficient propagation of dependencies over time. However, recent SSM-based approaches for fMRI commonly operate on derived functional connectivity representations and employ single-scale temporal processing. These design choices constrain the ability to jointly represent fast transient dynamics and slower global trends within a single model. We propose NeuroSSM, a selective state-space architecture designed for end-to-end analysis of raw BOLD signals in fMRI time series. NeuroSSM addresses the above limitations through two complementary design components: a multiscale state-space backbone that captures fast and slow dynamics concurrently, and a parallel differencing branch that increases sensitivity to transient state changes. Experiments on clinical and non-clinical datasets demonstrate that NeuroSSM achieves competitive performance and efficiency against state-of-the-art fMRI analysis methods.

</details>


### [7] [A 2.5 $μ$W 30 nV/$\surd$Hz Instrumentation Amplifier for Bioimpedance Sensors with Source Degenerated Current Mirror and DTMOS Transistor](https://arxiv.org/abs/2601.01232)
*Yu Xue,Kwantae Kim*

Main category: eess.SP

TL;DR: 提出一种用于生物阻抗传感的低功耗低噪声仪表放大器，采用增益增强型翻转电压跟随器结构，结合源退化电流镜和动态阈值MOSFET技术降低噪声，在28nm CMOS工艺下实现30nV/√Hz噪声和2.5μW功耗。


<details>
  <summary>Details</summary>
Motivation: 生物阻抗传感应用需要低功耗、低噪声的仪表放大器，传统设计在噪声性能和电压裕度之间存在权衡，需要创新电路技术来优化这一平衡。

Method: 基于增益增强型翻转电压跟随器跨导级，采用两种互补技术：1) 源退化电流镜优化噪声与电压裕度平衡，2) 动态阈值MOSFET方案增强有效跨导。在28nm CMOS工艺中实现。

Result: 输入参考噪声30nV/√Hz，带宽1.44MHz，功耗仅2.5μW（0.8V电源）。相比基准设计，功耗降低32.4%且噪声性能不变。源退化电流镜降低噪声7.95%，动态阈值MOSFET进一步降低11.66%。

Conclusion: 提出的仪表放大器成功实现了生物阻抗传感所需的低功耗低噪声性能，通过创新电路技术优化了噪声与功耗的权衡，设计参数已开源以确保可重复性和促进未来发展。

Abstract: This paper proposes a low-power and low-noise instrumentation amplifier (IA) tailored for bioimpedance sensing applications. The design originates from a gain-boosted flipped voltage follower (FVF) transconductance (TC) stage and integrates two complementary circuit techniques to improve the noise performance. To achieve an optimal balance between input-referred noise and available voltage headroom, a source-degenerated current mirror (SDCM) is adopted, resulting in reducing the input-referred noise by 7.95% compared with a conventional current mirror structure. In addition, a dynamic threshold MOSFET (DTMOS) scheme is employed to enhance the effective transconductance, leading to a further 11.66% reduction in input-referred noise. Simulated in a 28 nm CMOS process demonstrate that the proposed IA achieves an input-referred noise floor of 30 nV/$\surd$Hz and a bandwidth of 1.44 MHz, while consuming only 2.5 $μ$W from a 0.8 V supply. Compared to the baseline design, the proposed approach achieves a 32.4% reduction in power consumption without degrading noise performance. The complete design parameters are open-sourced in this paper, to ensure reproducibility and facilitate future developments.

</details>


### [8] [Pinching Antennas in Blockage-Aware Environments: Modeling, Design, and Optimization](https://arxiv.org/abs/2601.01277)
*Ximing Xie,Fang Fang,Zhiguo Ding,Xianbin Wang*

Main category: eess.SP

TL;DR: 该论文研究了在障碍物丰富的室内环境中夹持天线系统，开发了精确的圆柱形障碍物确定性模型，提出了针对单用户和多用户场景的优化算法，显著提升了系统吞吐量和LoS连接性。


<details>
  <summary>Details</summary>
Motivation: 现有夹持天线系统研究大多假设理想无障碍环境，但实际室内部署常存在丰富障碍物，导致视距链路阻塞严重影响性能。需要研究障碍物感知环境下的夹持天线系统优化。

Method: 1. 开发圆柱形障碍物的确定性模型精确描述LoS条件；2. 单用户场景：使用匈牙利算法进行波导-用户分配，采用代理辅助块坐标搜索优化天线位置；3. 多用户场景：提出WMMSE-DDPG方法联合优化波束成形和天线位置，处理非平滑LoS转换。

Result: 仿真结果表明，所提算法相比基准方法显著提升系统吞吐量和LoS连接性。夹持天线系统能有效利用障碍物抑制同信道干扰，将潜在阻塞转化为性能增益。

Conclusion: 该研究为障碍物丰富的室内环境提供了有效的夹持天线系统优化方案，证明了障碍物在特定条件下可转化为性能优势而非仅仅是限制因素。

Abstract: Pinching-antenna (PA) systems have recently emerged as a promising member of the flexible-antenna family due to their ability to dynamically establish line-of-sight (LoS) links. While most existing studies assume ideal environments without obstacles, practical indoor deployments are often obstacle-rich, where LoS blockage significantly degrades performance. This paper investigates pinching-antenna systems in blockage-aware environments by developing a deterministic model for cylinder-shaped obstacles that precisely characterizes LoS conditions without relying on stochastic approximations. Based on this model, a special case is first studied where each PA serves a single user and can only be deployed at discrete positions along the waveguide. In this case, the waveguide-user assignment is obtained via the Hungarian algorithm, and PA positions are refined using a surrogate-assisted block-coordinate search. Then, a general case is considered where each PA serves all users and can be continuously placed along the waveguide. In this case, beamforming and PA positions are jointly optimized by a weighted minimum mean square error integrated deep deterministic policy gradient (WMMSE-DDPG) approach to address non-smooth LoS transitions. Simulation results demonstrate that the proposed algorithms significantly improve system throughput and LoS connectivity compared with benchmark methods. Moreover, the results reveal that pinching-antenna systems can effectively leverage obstacles to suppress co-channel interference, converting potential blockages into performance gains.

</details>


### [9] [KAN-AE with Non-Linearity Score and Symbolic Regression for Energy-Efficient Channel Coding](https://arxiv.org/abs/2601.01598)
*Anthony Joseph Perre,Parker Huggins,Alphan Sahin*

Main category: eess.SP

TL;DR: KAN-AEs结合符号回归实现能效信道编码，通过符号表达式降低复杂度，比MLP-AE节能1.38倍


<details>
  <summary>Details</summary>
Motivation: 研究如何通过Kolmogorov-Arnold网络和符号回归技术实现能量高效的信道编码，解决传统深度学习模型在无线电设备上计算复杂、能耗高的问题

Method: 使用KAN-AEs结合符号回归，将网络转换为符号表达式；引入非线性评分项在SR过程中选择低复杂度方程；与MLP-AE进行对比实验

Result: KAN-AEs在保持竞争性BLER性能的同时，通过SR实现更高能效；使用提出的非线性度量评估，KAN-AE+SR比MLP-AE节能1.38倍

Conclusion: KAN-AEs结合符号回归是能量高效深度学习信道编码的有前景选择，通过符号表达式实现低复杂度实现和能效提升

Abstract: In this paper, we investigate Kolmogorov-Arnold network-based autoencoders (KAN-AEs) with symbolic regression (SR) for energy-efficient channel coding. By using SR, we convert KAN-AEs into symbolic expressions, which enables low-complexity implementation and improved energy efficiency at the radios. To further enhance the efficiency, we introduce a new non-linearity score term in the SR process to help select lower-complexity equations when possible. Through numerical simulations, we demonstrate that KAN-AEs achieve competitive BLER performance while improving energy efficiency when paired with SR. We score the energy efficiency of a KAN-AE implementation using the proposed non-linearity metric and compare it to a multi-layer perceptron-based autoencoder (MLP-AE). Our experiment shows that the KAN-AE paired with SR uses 1.38 times less energy than the MLP-AE, supporting that KAN-AEs are a promising choice for energy-efficient deep learning-based channel coding.

</details>


### [10] [Joint Sparsity and Beamforming Design for RDARS-Aided Systems](https://arxiv.org/abs/2601.01773)
*Chengwang Ji,Haiquan Lu,Qiaoyan Peng,Jintao Wang,Shaodan Ma*

Main category: eess.SP

TL;DR: 本文研究了RDARS辅助通信系统中连接元件的稀疏阵列设计，通过优化稀疏度、主动和被动波束成形来最大化系统和速率。


<details>
  <summary>Details</summary>
Motivation: RDARS架构在通信和感知性能增强方面具有潜力，但现有方法在动态工作模式选择和低复杂度元件配置方面存在挑战。特别是连接元件的配置复杂度问题尚未得到充分解决。

Method: 提出将连接元件形成均匀稀疏阵列以简化模式配置并扩大物理阵列孔径。通过联合优化主动/被动波束成形矩阵和连接元件阵列的稀疏度来最大化系统和速率。针对单用户和双用户场景推导了闭式最优稀疏设计，针对多用户场景提出了基于加权最小均方误差的交替优化算法。

Result: 数值结果表明优化稀疏度的重要性以及低复杂度稀疏度优化的有效性。提出的方法能够显著提升系统性能。

Conclusion: RDARS辅助通信系统中连接元件的稀疏阵列设计能够有效平衡性能与复杂度，提出的优化方法为实际系统部署提供了可行的解决方案。

Abstract: Reconfigurable distributed antennas and reflecting surface (RDARS) has emerged as a promising architecture for communication and sensing performance enhancement. In particular, the new selection gain can be achieved by leveraging the dynamic working mode selection between connection and reflection modes, whereas low-complexity element configuration remains an open issue. In this paper, we consider a RDARS-assisted communication system, where the connected elements are formed as a uniform sparse array for simplified mode configuration while achieving enlarged physical array aperture. The sum rate maximization problem is then formulated by jointly optimizing the active and passive beamforming matrices and sparsity of connected element array. For the special cases of a single user equipment (UE) and two UEs, the optimal sparsity designs are derived in closed-form. Then, for an arbitrary number of UEs, a weighted minimum mean-square error-based alternating optimization (AO) algorithm is proposed to tackle the non-convex optimization problem. Numerical results demonstrate the importance of optimizing the sparsity and the effectiveness of low-complexity sparsity optimization.

</details>


### [11] [Rethinking Secure Semantic Communications in the Age of Generative and Agentic AI: Threats and Opportunities](https://arxiv.org/abs/2601.01791)
*Shunpu Tang,Yuanyuan Jia,Zijiu Yang,Qianqian Yang,Ruichen Zhang,Jun Du,Jihong Park,Zhiguo Shi,Khaled B. Letaief*

Main category: eess.SP

TL;DR: 本文系统分析了生成式AI和智能体AI时代语义通信系统的安全与隐私问题，既探讨了AI增强的窃听威胁，也提出了AI赋能的隐私保护机会。


<details>
  <summary>Details</summary>
Motivation: 语义通信通过传输任务相关信息而非原始比特来提高通信效率，是6G网络的关键技术。生成式AI进一步增强了语义通信的鲁棒性，但这些效率提升也带来了新的安全和隐私漏洞。由于无线信道的广播特性，窃听者可以使用强大的生成式AI语义解码器从截获信号中恢复私密信息。此外，智能体AI的快速发展使窃听者能够通过整合记忆、外部知识和推理能力进行长期自适应推断，进一步推断用户私密行为和意图。

Method: 1. 提出语义通信系统中窃听威胁模型的系统分类法；2. 分析生成式AI和智能体AI如何增强窃听威胁；3. 探讨利用生成式AI和智能体AI设计隐私保护语义通信系统的潜在机会。

Result: 本文全面重新思考了生成式和智能体AI时代语义通信系统的安全与隐私问题，建立了系统的威胁模型分类框架，揭示了AI技术对窃听威胁的双重影响——既增强了窃听能力，也为隐私保护提供了新工具。

Conclusion: 在生成式和智能体AI快速发展的背景下，语义通信系统面临新的安全与隐私挑战。需要系统性地重新思考安全防护策略，既要认识到AI增强的窃听威胁，也要积极利用AI技术设计更强大的隐私保护机制，实现安全与效率的平衡。

Abstract: Semantic communication (SemCom) improves communication efficiency by transmitting task-relevant information instead of raw bits and is expected to be a key technology for 6G networks. Recent advances in generative AI (GenAI) further enhance SemCom by enabling robust semantic encoding and decoding under limited channel conditions. However, these efficiency gains also introduce new security and privacy vulnerabilities. Due to the broadcast nature of wireless channels, eavesdroppers can also use powerful GenAI-based semantic decoders to recover private information from intercepted signals. Moreover, rapid advances in agentic AI enable eavesdroppers to perform long-term and adaptive inference through the integration of memory, external knowledge, and reasoning capabilities. This allows eavesdroppers to further infer user private behavior and intent beyond the transmitted content. Motivated by these emerging challenges, this paper comprehensively rethinks the security and privacy of SemCom systems in the age of generative and agentic AI. We first present a systematic taxonomy of eavesdropping threat models in SemCom systems. Then, we provide insights into how GenAI and agentic AI can enhance eavesdropping threats. Meanwhile, we also highlight potential opportunities for leveraging GenAI and agentic AI to design privacy-preserving SemCom systems.

</details>


### [12] [On the Performance of Lossless Reciprocal MiLAC Architectures in Multi-User Networks](https://arxiv.org/abs/2601.01834)
*Tianyu Fang,Xiaohua Zhou,Yijie Mao*

Main category: eess.SP

TL;DR: 本文研究了微波线性模拟计算机辅助波束成形在多用户MISO网络中的性能，证明了无损互易MiLAC无法达到数字波束成形的性能，并提出了联合优化功率分配和散射矩阵的框架。


<details>
  <summary>Details</summary>
Motivation: 微波线性模拟计算机辅助波束成形作为全数字和混合波束成形的替代方案，在单用户MIMO网络中能达到与数字波束成形相同的容量，但其在多用户场景下的性能尚不明确。

Method: 基于微波网络理论，首先证明无损互易MiLAC在一般MU-MISO网络中无法达到数字波束成形的性能；然后构建和速率最大化问题，开发联合优化功率分配和MiLAC散射矩阵的高效优化框架。

Result: 数值结果验证了理论分析，表明MiLAC是未来极大规模MIMO系统的有前景架构，但需要适当的优化才能实现良好性能。

Conclusion: MiLAC在多用户MISO网络中无法达到数字波束成形的性能，但通过提出的优化框架可以显著提升性能，为未来大规模MIMO系统提供了有前景的模拟处理方案。

Abstract: Microwave linear analog computer (MiLAC)-aided beamforming, which processes the transmitted symbols fully in the analog domain, has recently emerged as a promising alternative to fully digital and hybrid beamforming architectures for multiple-input multiple-output (MIMO) systems. While prior studies have shown that lossless and reciprocal MiLAC can achieve the same capacity as digital beamforming in a single-user MIMO network, its performance in multi-user scenarios remains unknown. To answer this question, in this work, we establish a downlink multi-user multiple-input single-output (MU-MISO) network with a MiLAC-aided transmitter, and investigate its sum-rate performance. Based on the microwave network theory, we first prove that lossless and reciprocal MiLAC cannot achieve the same performance as digital beamforming in a general MU-MISO network. Then, we formulate a sum-rate maximization problem and develop an efficient optimization framework to jointly optimize the power allocation and the scattering matrix for MiLAC. Numerical results validate our theoretical analysis and demonstrate that MiLAC is a promising architecture for future extremely large-scale MIMO systems.

</details>


### [13] [Doppler-Resilient LEO Satellite OFDM Transmission with Affine Frequency Domain Pilot](https://arxiv.org/abs/2601.01956)
*Tang Shuntian,Wu Xiaomei,Wang Xinyi,Zhao Le,Yang Guang,Liu Zilong,Liu Fan,Fei Zesong*

Main category: eess.SP

TL;DR: 提出一种基于仿射频率域导频的OFDM卫星通信方案，利用LSTM预测器替代传统插值，显著提升高多普勒场景下的性能


<details>
  <summary>Details</summary>
Motivation: LEO卫星OFDM系统面临严重多普勒频移问题，而现有AFDM方案虽然抗多普勒但处理复杂度高，需要寻找更优的解决方案

Method: 提出AF域导频嵌入方案，利用相邻信道的自回归特性，设计LSTM预测器替代传统插值进行信道估计

Result: 仿真结果表明，该方案在高多普勒场景下的误码率性能显著优于传统OFDM方案

Conclusion: 为下一代非地面网络通信系统设计开辟了新途径

Abstract: Orthogonal frequency division multiplexing (OFDM) based low Earth orbit (LEO) satellite communication system suffers from severe Doppler shifts, while {the Doppler-resilient affine frequency-division multiplexing (AFDM) transmission suffers from significantly high processing complexity in data detection}. In this paper, we explore the channel estimation gain of affine frequency (AF) domain pilot to enhance the OFDM transmission under high mobility. Specifically, we propose a novel AF domain pilot embedding scheme for satellite-ground downlink OFDM systems for capturing the channel characteristics. By exploiting the autoregressive (AR) property of adjacent channels, a long short-term memory (LSTM) based predictor is designed to replace conventional interpolation operation in OFDM channel estimation. Simulation results show that the proposed transmission scheme significantly outperforms conventional OFDM scheme in terms of bit error rate (BER) under high Doppler scenarios, thus paving a new way for the design of next generation non-terrestrial network (NTN) communication systems.

</details>


### [14] [Beam-Brainstorm: A Generative Site-Specific Beamforming Approach](https://arxiv.org/abs/2601.02219)
*Zihao Zhou,Zhaolin Wang,Yuanwei Liu*

Main category: eess.SP

TL;DR: 提出GenSSBF框架，通过联合结构建模实现站点特定波束成形，使用定制条件扩散模型生成用户特定波束，显著降低波束扫描开销


<details>
  <summary>Details</summary>
Motivation: 准确理解传播环境是站点特定波束成形（SSBF）的基本挑战。传统非结构化预测方法存在局限性，需要新的联合结构建模方法

Method: 提出GenSSBF统一框架，包含站点剖面、无线提示模块和生成器。具体实现BBS方案：通过DFT将信道数据转换到可逆潜在空间构建站点剖面；使用少量DFT波束测量的RSRP构建无线提示；采用定制条件扩散模型作为生成器

Result: 在精确射线追踪数据集上的仿真结果表明，BBS能够实现接近最优的波束成形增益，同时大幅减少波束扫描开销，即使在低信噪比环境下也能保持性能

Conclusion: GenSSBF框架代表了从传统非结构化预测到联合结构建模的范式转变，BBS作为其实例化方案能够直接生成多样化、高保真的用户特定波束，显著提升波束成形效率

Abstract: Accurately understanding the propagation environment is a fundamental challenge in site-specific beamforming (SSBF). This paper proposes a novel generative SSBF (GenSSBF) solution, which represents a paradigm shift from conventional unstructured prediction to joint-structure modeling. First, considering the fundamental differences between beam generation and conventional image synthesis, a unified GenSSBF framework is proposed, which includes a site profile, a wireless prompting module, and a generator. Second, a beam-brainstorm (BBS) solution is proposed as an instantiation of this GenSSBF framework. Specifically, the site profile is configured by transforming channel data from spatial domain to a reversible latent space via discrete Fourier transform (DFT). To facilitate practical deployment, the wireless prompt is constructed from the reference signal received power (RSRP) measured using a small number of DFT-beams. Finally, the generator is developed using a customized conditional diffusion model. Rather than relying on a meticulously designed global codebook, BBS directly generates diverse and high-fidelity user-specific beams guided by the wireless prompts. Simulation results on accurate ray-tracing datasets demonstrate that BBS can achieve near-optimal beamforming gain while drastically reducing the beam sweeping overhead, even in low signal-to-noise ratio (SNR) environments.

</details>


### [15] [Backscatter-Assisted High-Speed Rail Communications in Straight Tunnel Environments: Effects of Tag Number and Phase Control](https://arxiv.org/abs/2601.02225)
*Yunping Mu,Gongpu Wang,Ruisi He,Theodoros A. Tsiftsis,Saman Atapattu,Chintha Tellambura*

Main category: eess.SP

TL;DR: 研究隧道环境中多标签反向散射通信的信道增益，分析标签数量和相位调整对系统性能的影响


<details>
  <summary>Details</summary>
Motivation: 反向散射通信能增强隧道环境中的信号强度，但标签数量和相位调整对系统性能的影响仍是一个挑战性问题

Method: 通过高斯和伽马近似推导可调相位和随机相位情况下反向散射链路增益大于直接链路的概率，获得可处理的表达式

Result: 可调相位标签相比随机相位显著提高反向散射链路的信道增益；标签数量存在有效部署模式的上限阈值

Conclusion: 研究结果为隧道环境中反向散射通信系统的高效设计提供了有价值的指导原则

Abstract: Backscatter communication is a promising technology to enhance the signal strength received by the receiver in straight tunnel environments. The impact of the number of tags and their phase adjustment on system performance remains a challenging issue though. Therefore, in this paper, we investigate the channel gain of backscatter-assisted communication with multiple tags in straight tunnels. In particular, we derive the probabilities that the backscatter link gain is greater than the direct link under adjustable and random phase assumptions by applying the Gaussian and Gamma approximations to derive tractable expressions. The simulation results show that phaseadjustable tags significantly improve the channel gain of the backscatter links compared to the random phase case. Moreover, the number of tags has an upper threshold for an effective tag deployment pattern. These insights provide valuable guidelines for the efficient design of backscatter communication systems in tunnel environments.

</details>


### [16] [Ultra-low-power Monostatic Backscatter Platform with Phase-Aware Channel Estimation and System-Level Validation](https://arxiv.org/abs/2601.02227)
*Hanyeol Ryu,Sangkil Kim*

Main category: eess.SP

TL;DR: 提出一种用于单天线单站系统的信道估计方法，通过补偿残留相位漂移和优化导频分配，实现超低功耗（320 pJ/bit）的多媒体级反向散射物联网链路


<details>
  <summary>Details</summary>
Motivation: 解决反向散射链路中的残留相位漂移问题，开发硬件-软件协同设计平台，实现超低功耗、多媒体能力的物联网通信

Method: 1) 开发包含半无源标签、SDR阅读器和2x1平面八木天线的硬件平台；2) 建立考虑往返传播和时间相关性的反向散射衰落模型；3) 采用分析推导的资源最优导频分配策略；4) 接收端使用优化的LS和LMMSE信道估计，结合导频辅助CFO补偿，最后通过ZF均衡器抑制ISI

Result: 在1米距离实现500 kbps传输速率，总功耗168 μW（SDR基带158 μW + RF开关10 μW），能量效率达320 pJ/bit。OOK和BPSK调制的EVM分别为2.97%和4.02%，通过BER测量和全彩色图像传输验证性能

Conclusion: 该工作展示了超低功耗、多媒体能力的反向散射物联网链路，为可扩展部署提供了实用的硬件-软件协同设计指导

Abstract: This paper presents a novel channel-estimation (CE) method that mitigates residual phase drifts in backscatter links and a full hardware and signal-processing pipeline for a single-antenna monostatic system. The platform comprises a semi-passive tag, a software-defined radio (SDR) reader, and a 2x1 planar Yagi-Uda array (7 dBi with higher than 30 dB isolation) operating at 2.4 ~ 2.5 GHz. The developed backscatter fading model accounts for round-trip propagation and temporal correlation, and employs an analytically derived resource-optimal pilot allocation strategy. At the receiver, optimized least square (LS) and linear minimum mean square error (LMMSE) CE with pilot-aided carrier frequency offset (CFO) compensation feed a zero-forcing (ZF) equalizer to suppress ISI. The prototype delivers 500 kbps at 1 m with power of 158 uW (SDR baseband) and 10 uW (RF switch), yielding 320 pJ/bit. OOK and BPSK modulations achieve measured EVMs of 2.97 % and 4.02 %, respectively. Performance is validated by BER measurements and successful reconstruction of a full-color image in an over-the-air experiment. The results demonstrate an ultra-low-power, multimedia-capable backscatter IoT link and provide practical hardware-software co-design guidance for scalable deployments.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [17] [Speak the Art: A Direct Speech to Image Generation Framework](https://arxiv.org/abs/2601.00827)
*Mariam Saeed,Manar Amr,Farida Adel,Nada Hassan,Nour Walid,Eman Mohamed,Mohamed Hussein,Marwan Torki*

Main category: eess.AS

TL;DR: STA框架通过结合语音编码网络和VQ-Diffusion网络，实现了直接从语音生成高质量图像，解决了现有方法中语音嵌入信息不足和GAN训练不稳定的问题。


<details>
  <summary>Details</summary>
Motivation: 当前语音到图像生成方法存在两个主要问题：1）语音编码网络生成的嵌入无法充分捕捉语音的语义信息；2）使用GAN存在训练不稳定、模式崩溃和梯度消失等问题，导致样本多样性有限和生成器学习效果不佳。

Method: 提出STA框架，包含语音编码网络和基于语音嵌入的VQ-Diffusion网络。语音编码网络在训练时通过大型预训练图像-文本模型进行监督，以提升语音嵌入质量。用扩散模型替代GAN，实现更稳定的训练和更多样化的图像生成。框架还支持多语言扩展，已用英语和阿拉伯语验证。

Result: STA框架在语音到图像生成任务上大幅超越了现有最先进模型，证明了其有效性。多语言扩展也展示了框架的通用性。

Conclusion: STA框架通过改进语音嵌入质量和采用扩散模型，成功解决了语音到图像生成中的关键问题，实现了更稳定、多样和高质量的图像生成，并具备多语言扩展潜力。

Abstract: Direct speech-to-image generation has recently shown promising results. However, compared to text-to-image generation, there is still a large gap to enclose. Current approaches use two stages to tackle this task: speech encoding network and image generative adversarial network (GAN). The speech encoding networks in these approaches produce embeddings that do not capture sufficient linguistic information to semantically represent the input speech. GANs suffer from issues such as non-convergence, mode collapse, and diminished gradient, which result in unstable model parameters, limited sample diversity, and ineffective generator learning, respectively. To address these weaknesses, we introduce a framework called \textbf{Speak the Art (STA)} which consists of a speech encoding network and a VQ-Diffusion network conditioned on speech embeddings. To improve speech embeddings, the speech encoding network is supervised by a large pre-trained image-text model during training. Replacing GANs with diffusion leads to more stable training and the generation of diverse images. Additionally, we investigate the feasibility of extending our framework to be multilingual. As a proof of concept, we trained our framework with two languages: English and Arabic. Finally, we show that our results surpass state-of-the-art models by a large margin.

</details>


### [18] [Improving Code-Switching Speech Recognition with TTS Data Augmentation](https://arxiv.org/abs/2601.00935)
*Yue Heng Yeo,Yuchen Hu,Shreyas Gopal,Yizhou Peng,Hexin Liu,Eng Siong Chng*

Main category: eess.AS

TL;DR: 使用多语言TTS模型生成中英文语码转换合成语音，有效增强低资源对话ASR系统的训练数据，显著降低错误率


<details>
  <summary>Details</summary>
Motivation: 对话式语码转换语音识别面临高质量标注数据稀缺的挑战，需要有效的数据增强方法来提升ASR系统性能

Method: 在SEAME数据集上微调多语言CosyVoice2 TTS模型，生成合成的中英文语码转换对话语音，增加训练数据量和说话人多样性

Result: 使用合成语音增强真实语音训练后，混合错误率在DevMan上从12.1%降至10.1%，在DevSGE上从17.8%降至16.0%，性能一致提升

Conclusion: 多语言TTS是增强低资源对话语码转换场景下ASR鲁棒性的有效实用工具

Abstract: Automatic speech recognition (ASR) for conversational code-switching speech remains challenging due to the scarcity of realistic, high-quality labeled speech data. This paper explores multilingual text-to-speech (TTS) models as an effective data augmentation technique to address this shortage. Specifically, we fine-tune the multilingual CosyVoice2 TTS model on the SEAME dataset to generate synthetic conversational Chinese-English code-switching speech, significantly increasing the quantity and speaker diversity of available training data. Our experiments demonstrate that augmenting real speech with synthetic speech reduces the mixed error rate (MER) from 12.1 percent to 10.1 percent on DevMan and from 17.8 percent to 16.0 percent on DevSGE, indicating consistent performance gains. These results confirm that multilingual TTS is an effective and practical tool for enhancing ASR robustness in low-resource conversational code-switching scenarios.

</details>


### [19] [Bayesian Negative Binomial Regression of Afrobeats Chart Persistence](https://arxiv.org/abs/2601.01391)
*Ian Jacob Cabansag,Paul Ntegeka*

Main category: eess.AS

TL;DR: 研究使用贝叶斯负二项回归分析尼日利亚Spotify榜单数据，发现合作歌曲在控制总播放量后，比单人歌曲在榜单上停留时间稍短


<details>
  <summary>Details</summary>
Motivation: 在流媒体平台上，歌曲在榜单上的停留时间影响收入和传播效果。本研究旨在探究合作歌曲是否比单人歌曲在榜单上停留更长时间，从而获得更好的曝光和商业成功。

Method: 使用2024年尼日利亚Spotify Top 200每日数据，记录每首歌曲在榜单上的天数和年度总播放量。采用贝叶斯负二项回归模型，以榜单停留天数为因变量，合作状态（单人vs多艺人）和对数总播放量为自变量，使用马尔可夫链蒙特卡洛进行后验推断。

Result: 在控制总播放量后，合作歌曲在榜单上的停留时间比相似播放量的单人歌曲稍短，这一发现与预期相反。

Conclusion: 合作并不一定延长歌曲在榜单上的停留时间，在考虑歌曲整体流行度后，单人歌曲可能具有更强的榜单持久力。

Abstract: Afrobeats songs compete for attention on streaming platforms, where chart visibility can influence both revenue and cultural impact. This paper examines whether collaborations help songs remain on the charts longer, using daily Nigeria Spotify Top 200 data from 2024. Each track is summarized by the number of days it appears in the Top 200 during the year and its total annual streams in Nigeria. A Bayesian negative binomial regression is applied, with days on chart as the outcome and collaboration status (solo versus multi-artist) and log total streams as predictors. This approach is well suited for overdispersed count data and allows the effect of collaboration to be interpreted while controlling for overall popularity. Posterior inference is conducted using Markov chain Monte Carlo, and results are assessed using rate ratios, posterior probabilities, and predictive checks. The findings indicate that, after accounting for total streams, collaboration tracks tend to spend slightly fewer days on the chart than comparable solo tracks.

</details>


### [20] [MORE: Multi-Objective Adversarial Attacks on Speech Recognition](https://arxiv.org/abs/2601.01852)
*Xiaoxue Gao,Zexin Li,Yiming Chen,Nancy F. Chen*

Main category: eess.AS

TL;DR: 提出了MORE攻击方法，同时降低ASR模型的识别准确率和推理效率，通过层次化阶段排斥-锚定机制实现多目标对抗攻击。


<details>
  <summary>Details</summary>
Motivation: 当前ASR模型（如Whisper）在现实应用中广泛使用，但现有研究主要关注对抗攻击下的准确率下降，而忽略了效率方面的鲁棒性。这种局限性导致对ASR模型漏洞的理解不全面。

Method: 提出了MORE（多目标重复加倍鼓励攻击），采用层次化阶段排斥-锚定机制，将多目标对抗优化重新表述为层次化框架。引入新颖的重复鼓励加倍目标（REDO），通过保持准确率下降并周期性地加倍预测序列长度，诱导重复文本生成。

Result: 实验表明，MORE相比现有基线方法，能够持续产生显著更长的转录文本，同时保持较高的词错误率，证明了其在多目标对抗攻击中的有效性。

Conclusion: MORE攻击能够迫使ASR模型在单个对抗输入下产生错误转录，同时显著增加计算成本，为全面理解ASR模型鲁棒性提供了新视角。

Abstract: The emergence of large-scale automatic speech recognition (ASR) models such as Whisper has greatly expanded their adoption across diverse real-world applications. Ensuring robustness against even minor input perturbations is therefore critical for maintaining reliable performance in real-time environments. While prior work has mainly examined accuracy degradation under adversarial attacks, robustness with respect to efficiency remains largely unexplored. This narrow focus provides only a partial understanding of ASR model vulnerabilities. To address this gap, we conduct a comprehensive study of ASR robustness under multiple attack scenarios. We introduce MORE, a multi-objective repetitive doubling encouragement attack, which jointly degrades recognition accuracy and inference efficiency through a hierarchical staged repulsion-anchoring mechanism. Specifically, we reformulate multi-objective adversarial optimization into a hierarchical framework that sequentially achieves the dual objectives. To further amplify effectiveness, we propose a novel repetitive encouragement doubling objective (REDO) that induces duplicative text generation by maintaining accuracy degradation and periodically doubling the predicted sequence length. Overall, MORE compels ASR models to produce incorrect transcriptions at a substantially higher computational cost, triggered by a single adversarial input. Experiments show that MORE consistently yields significantly longer transcriptions while maintaining high word error rates compared to existing baselines, underscoring its effectiveness in multi-objective adversarial attack.

</details>


### [21] [Towards Prosodically Informed Mizo TTS without Explicit Tone Markings](https://arxiv.org/abs/2601.02073)
*Abhijit Mohanta,Remruatpuii,Priyankoo Sarmah,Rohit Sinha,Wendy Lalhminghlui*

Main category: eess.AS

TL;DR: 开发了一个基于仅5.18小时数据的米佐语TTS系统，使用Tacotron2和VITS两种模型，VITS在主观客观评估中表现更优，特别是音调合成错误显著降低。


<details>
  <summary>Details</summary>
Motivation: 为低资源、有声调的藏缅语系语言米佐语开发文本转语音系统，探索在有限数据条件下实现可接受感知质量和可懂度的合成方法。

Method: 使用仅5.18小时的米佐语数据，分别构建基于Tacotron2的基线模型和基于VITS的模型，进行主观和客观评估对比。

Result: VITS模型在主观和客观评估中均优于Tacotron2模型，特别是在音调合成方面错误率显著更低，系统输出在感知上可接受且可懂。

Conclusion: 非自回归端到端框架（如VITS）能够在有限数据条件下实现可接受感知质量和可懂度的有声调语言合成，为低资源语言TTS开发提供了有效途径。

Abstract: This paper reports on the development of a text-to-speech (TTS) system for Mizo, a low-resource, tonal, and Tibeto-Burman language spoken primarily in the Indian state of Mizoram. The TTS was built with only 5.18 hours of data; however, in terms of subjective and objective evaluations, the outputs were considered perceptually acceptable and intelligible. A baseline model using Tacotron2 was built, and then, with the same data, another TTS model was built with VITS. In both subjective and objective evaluations, the VITS model outperformed the Tacotron2 model. In terms of tone synthesis, the VITS model showed significantly lower tone errors than the Tacotron2 model. The paper demonstrates that a non-autoregressive, end-to-end framework can achieve synthesis of acceptable perceptual quality and intelligibility.

</details>


### [22] [On the Role of Spatial Features in Foundation-Model-Based Speaker Diarization](https://arxiv.org/abs/2601.02231)
*Marc Deegen,Tobias Gburrek,Tobias Cord-Landwehr,Thilo von Neumann,Jiangyu Han,Lukáš Burget,Reinhold Haeb-Umbach*

Main category: eess.AS

TL;DR: 研究分析了在多通道录音中引入空间信息对基于WavLM等基础模型的说话人日志系统的影响，发现空间信息能提升性能但改善有限，表明WavLM多层特征已包含足够的说话人区分信息。


<details>
  <summary>Details</summary>
Motivation: 当前基于WavLM等基础模型的说话人日志系统（如DiariZen）仅限于单通道音频，无法利用多通道录音中的空间线索。本研究旨在探索将空间信息融入最先进的单通道日志系统的影响。

Method: 评估了多种将多通道空间特征条件化到模型中的策略，在会议风格数据集上进行实验，分析空间信息对说话人日志性能的影响。

Result: 实验表明空间信息可以改善说话人日志性能，但整体改进幅度小于预期。WavLM所有层聚合的特征已经捕获了准确说话人区分所需的大部分信息，包括重叠语音区域。

Conclusion: 研究揭示了使用空间线索增强基于基础模型的说话人日志系统的潜力和局限性，为未来多通道日志系统设计提供了重要见解。

Abstract: Recent advances in speaker diarization exploit large pretrained foundation models, such as WavLM, to achieve state-of-the-art performance on multiple datasets. Systems like DiariZen leverage these rich single-channel representations, but are limited to single-channel audio, preventing the use of spatial cues available in multi-channel recordings. This work analyzes the impact of incorporating spatial information into a state-of-the-art single-channel diarization system by evaluating several strategies for conditioning the model on multi-channel spatial features. Experiments on meeting-style datasets indicate that spatial information can improve diarization performance, but the overall improvement is smaller than expected for the proposed system, suggesting that the features aggregated over all WavLM layers already capture much of the information needed for accurate speaker discrimination, also in overlapping speech regions. These findings provide insight into the potential and limitations of using spatial cues to enhance foundation model-based diarization.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [23] [Index-ASR Technical Report](https://arxiv.org/abs/2601.00890)
*Zheshu Song,Lu Wang,Wei Deng,Zhuo Yang,Yong Wu,Bin Xia*

Main category: cs.SD

TL;DR: Index-ASR是一个基于大语言模型的自动语音识别系统，通过集成LLM和大规模训练数据来解决现有LLM-ASR系统的幻觉错误和上下文定制支持不足的问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM-ASR系统存在两个关键限制：1）容易产生幻觉错误，生成与声学输入不符的过长重复输出；2）对灵活细粒度的上下文定制支持有限。需要同时增强鲁棒性和支持可定制的热词识别。

Method: 提出Index-ASR系统，核心思想是集成LLM和大规模训练数据，这些数据富含背景噪声和上下文信息，以同时增强鲁棒性和支持可定制的热词识别。

Result: 实验结果显示，Index-ASR在开源基准测试和内部测试集上都表现出色，突显了其在现实世界ASR应用中的鲁棒性和实用性。

Conclusion: Index-ASR通过集成LLM和富含噪声与上下文信息的大规模训练数据，有效解决了现有LLM-ASR系统的幻觉问题和上下文定制限制，为实际ASR应用提供了鲁棒且实用的解决方案。

Abstract: Automatic speech recognition (ASR) has witnessed remarkable progress in recent years, largely driven by the emergence of LLM-based ASR paradigm. Despite their strong performance on a variety of open-source benchmarks, existing LLM-based ASR systems still suffer from two critical limitations. First, they are prone to hallucination errors, often generating excessively long and repetitive outputs that are not well grounded in the acoustic input. Second, they provide limited support for flexible and fine-grained contextual customization. To address these challenges, we propose Index-ASR, a large-scale LLM-based ASR system designed to simultaneously enhance robustness and support customizable hotword recognition. The core idea of Index-ASR lies in the integration of LLM and large-scale training data enriched with background noise and contextual information. Experimental results show that our Index-ASR achieves strong performance on both open-source benchmarks and in-house test sets, highlighting its robustness and practicality for real-world ASR applications.

</details>


### [24] [IO-RAE: Information-Obfuscation Reversible Adversarial Example for Audio Privacy Protection](https://arxiv.org/abs/2601.01239)
*Jiajie Zhu,Xia Du,Xiaoyuan Liu,Jizhe Zhou,Qizhen Xu,Zheng Lin,Chi-Man Pun*

Main category: cs.SD

TL;DR: IO-RAE框架利用可逆对抗样本保护音频隐私，通过LLM生成误导内容防止窃听，同时保持音频质量并实现近乎无损恢复。


<details>
  <summary>Details</summary>
Motivation: 随着语音识别技术的广泛应用，音频数据面临严重的隐私泄露风险，需要在不影响音频质量的前提下保护敏感信息。

Method: 提出IO-RAE框架，利用大语言模型生成上下文连贯的误导内容，结合累积信号攻击技术针对低频信号，生成可逆对抗样本。

Result: 在多个ASR模型上实现96.5%的目标误导率和100%的非目标误导率，恢复音频的PESQ评分达4.45，ASR错误率为0%，近乎无损恢复。

Conclusion: IO-RAE框架能有效保护音频隐私，防止人类和ASR系统窃听，同时保持音频高质量和可恢复性，具有实际应用价值。

Abstract: The rapid advancements in artificial intelligence have significantly accelerated the adoption of speech recognition technology, leading to its widespread integration across various applications. However, this surge in usage also highlights a critical issue: audio data is highly vulnerable to unauthorized exposure and analysis, posing significant privacy risks for businesses and individuals. This paper introduces an Information-Obfuscation Reversible Adversarial Example (IO-RAE) framework, the pioneering method designed to safeguard audio privacy using reversible adversarial examples. IO-RAE leverages large language models to generate misleading yet contextually coherent content, effectively preventing unauthorized eavesdropping by humans and Automatic Speech Recognition (ASR) systems. Additionally, we propose the Cumulative Signal Attack technique, which mitigates high-frequency noise and enhances attack efficacy by targeting low-frequency signals. Our approach ensures the protection of audio data without degrading its quality or our ability. Experimental evaluations demonstrate the superiority of our method, achieving a targeted misguidance rate of 96.5% and a remarkable 100% untargeted misguidance rate in obfuscating target keywords across multiple ASR models, including a commercial black-box system from Google. Furthermore, the quality of the recovered audio, measured by the Perceptual Evaluation of Speech Quality score, reached 4.45, comparable to high-quality original recordings. Notably, the recovered audio processed by ASR systems exhibited an error rate of 0%, indicating nearly lossless recovery. These results highlight the practical applicability and effectiveness of our IO-RAE framework in protecting sensitive audio privacy.

</details>


### [25] [Diffusion Timbre Transfer Via Mutual Information Guided Inpainting](https://arxiv.org/abs/2601.01294)
*Ching Ho Lee,Javier Nistal,Stefan Lattner,Marco Pasini,George Fazekas*

Main category: cs.SD

TL;DR: 无需额外训练，通过推理时编辑实现音色转换：在预训练潜在扩散模型上引入维度噪声注入和早期步长钳制机制


<details>
  <summary>Details</summary>
Motivation: 将音色转换视为音乐音频的推理时编辑问题，利用强大的预训练模型避免额外训练成本

Method: 1) 针对乐器身份信息最丰富的潜在通道进行维度噪声注入；2) 在反向扩散过程中通过早期步长钳制重新施加输入的旋律和节奏结构

Result: 方法直接在音频潜在空间操作，兼容文本/音频条件（如CLAP），通过简单推理时控制有效引导预训练模型实现风格转换

Conclusion: 展示了简单推理时控制能有效引导预训练模型用于风格转换，分析了音色变化与结构保持之间的权衡

Abstract: We study timbre transfer as an inference-time editing problem for music audio. Starting from a strong pre-trained latent diffusion model, we introduce a lightweight procedure that requires no additional training: (i) a dimension-wise noise injection that targets latent channels most informative of instrument identity, and (ii) an early-step clamping mechanism that re-imposes the input's melodic and rhythmic structure during reverse diffusion. The method operates directly on audio latents and is compatible with text/audio conditioning (e.g., CLAP). We discuss design choices,analyze trade-offs between timbral change and structural preservation, and show that simple inference-time controls can meaningfully steer pre-trained models for style-transfer use cases.

</details>


### [26] [UltraEval-Audio: A Unified Framework for Comprehensive Evaluation of Audio Foundation Models](https://arxiv.org/abs/2601.01373)
*Qundong Shi,Jie Zhou,Biyuan Lin,Junbo Cui,Guoyang Zeng,Yixuan Zhou,Ziyang Wang,Xin Liu,Zhen Luo,Yudong Wang,Zhiyuan Liu*

Main category: cs.SD

TL;DR: 本文介绍了UltraEval-Audio，一个统一的音频基础模型评估框架，旨在解决音频评估领域缺乏统一标准、音频编解码器评估方法不完善以及中文语音基准不足三大挑战。


<details>
  <summary>Details</summary>
Motivation: 音频基础模型发展迅速，但缺乏全面的评估体系已成为该领域进一步发展的关键瓶颈。当前音频评估面临三大挑战：1) 缺乏统一框架，数据集和代码分散；2) 音频编解码器缺乏全面评估方法；3) 现有语音基准过度依赖英语，难以客观评估中文性能。

Method: 提出UltraEval-Audio统一评估框架，采用模块化架构，支持10种语言和14个核心任务类别，集成24个主流模型和36个权威基准。针对音频编解码器提出包含语义准确性、音色保真度和声学质量三个维度的综合评估方案。针对中文评估不足问题，提出SpeechCMMLU和SpeechHSK两个新的中文基准。

Result: 开发了一个透明、高效、公平的音频模型比较平台，提供一键评估功能和实时公共排行榜。框架支持多语言、多任务评估，并为音频编解码器提供了全面的评估方法。

Conclusion: UltraEval-Audio为学术界和工业界提供了一个统一的音频模型评估平台，解决了当前音频评估领域的关键瓶颈问题，有望推动音频基础模型的进一步发展。

Abstract: The development of audio foundation models has accelerated rapidly since the emergence of GPT-4o. However, the lack of comprehensive evaluation has become a critical bottleneck for further progress in the field, particularly in audio generation. Current audio evaluation faces three major challenges: (1) audio evaluation lacks a unified framework, with datasets and code scattered across various sources, hindering fair and efficient cross-model comparison;(2) audio codecs, as a key component of audio foundation models, lack a widely accepted and holistic evaluation methodology; (3) existing speech benchmarks are heavily reliant on English, making it challenging to objectively assess models' performance on Chinese. To address the first issue, we introduce UltraEval-Audio, a unified evaluation framework for audio foundation models, specifically designed for both audio understanding and generation tasks. UltraEval-Audio features a modular architecture, supporting 10 languages and 14 core task categories, while seamlessly integrating 24 mainstream models and 36 authoritative benchmarks. To enhance research efficiency, the framework provides a one-command evaluation feature, accompanied by real-time public leaderboards. For the second challenge, UltraEval-Audio adopts a novel comprehensive evaluation scheme for audio codecs, evaluating performance across three key dimensions: semantic accuracy, timbre fidelity, and acoustic quality. To address the third issue, we propose two new Chinese benchmarks, SpeechCMMLU and SpeechHSK, designed to assess Chinese knowledge proficiency and language fluency. We wish that UltraEval-Audio will provide both academia and industry with a transparent, efficient, and fair platform for comparison of audio models. Our code, benchmarks, and leaderboards are available at https://github.com/OpenBMB/UltraEval-Audio.

</details>


### [27] [SAFE-QAQ: End-to-End Slow-Thinking Audio-Text Fraud Detection via Reinforcement Learning](https://arxiv.org/abs/2601.01392)
*Peidong Wang,Zhiming Ma,Xin Dai,Yongkang Liu,Shi Feng,Xiaocui Yang,Wenxing Hu,Zhihao Wang,Mingjun Pan,Li Yuan,Daling Wang*

Main category: cs.SD

TL;DR: SAFE-QAQ是一个端到端的音频欺诈检测框架，通过消除ASR转录错误影响、基于规则的慢思考奖励机制和动态风险评估，显著提升了欺诈检测的准确性和实时处理能力。


<details>
  <summary>Details</summary>
Motivation: 现有欺诈检测方法主要依赖转录文本，容易受到ASR错误影响，且忽略了音频中的关键声学线索（如语音语调、环境背景），这限制了它们应对复杂欺诈策略的能力。

Method: 1. 端到端音频处理框架，消除转录错误影响；2. 提出基于规则的慢思考奖励机制，通过分层推理过程精确捕捉细粒度音频细节；3. 引入动态风险评估框架，在实时通话中实现早期欺诈检测和预防。

Result: 在TeleAntiFraud-Bench上的实验显示，SAFE-QAQ在准确性、推理效率和实时处理能力等多个关键维度上显著优于现有方法。目前已部署并每天分析超过70,000个通话，有效自动化复杂欺诈检测，减少人工工作量和财务损失。

Conclusion: SAFE-QAQ通过直接处理音频信号、引入慢思考推理机制和动态风险评估，成功解决了传统基于文本的欺诈检测方法的局限性，为音频欺诈检测提供了更有效的解决方案。

Abstract: Existing fraud detection methods predominantly rely on transcribed text, suffering from ASR errors and missing crucial acoustic cues like vocal tone and environmental context. This limits their effectiveness against complex deceptive strategies. To address these challenges, we first propose \textbf{SAFE-QAQ}, an end-to-end comprehensive framework for audio-based slow-thinking fraud detection. First, the SAFE-QAQ framework eliminates the impact of transcription errors on detection performance. Secondly, we propose rule-based slow-thinking reward mechanisms that systematically guide the system to identify fraud-indicative patterns by accurately capturing fine-grained audio details, through hierarchical reasoning processes. Besides, our framework introduces a dynamic risk assessment framework during live calls, enabling early detection and prevention of fraud. Experiments on the TeleAntiFraud-Bench demonstrate that SAFE-QAQ achieves dramatic improvements over existing methods in multiple key dimensions, including accuracy, inference efficiency, and real-time processing capabilities. Currently deployed and analyzing over 70,000 calls daily, SAFE-QAQ effectively automates complex fraud detection, reducing human workload and financial losses. Code: https://anonymous.4open.science/r/SAFE-QAQ.

</details>


### [28] [OV-InstructTTS: Towards Open-Vocabulary Instruct Text-to-Speech](https://arxiv.org/abs/2601.01459)
*Yong Ren,Jiangyan Yi,Jianhua Tao,Haiyang Sun,Zhengqi Wen,Hao Gu,Le Xu,Ye Bai*

Main category: cs.SD

TL;DR: OV-InstructTTS提出了一种新的开放词汇指令TTS范式，通过推理驱动框架将高级自然语言指令转换为语音合成控制信号，显著提升了指令跟随能力和语音表现力。


<details>
  <summary>Details</summary>
Motivation: 现有InstructTTS方法主要依赖音频相关标签或其变体，难以处理灵活的高级指令，这种刚性控制无法满足内容创作者等用户希望通过描述性指令引导生成的需求。

Method: 提出了包含新数据集OV-Speech和推理驱动框架的完整解决方案。OV-Speech数据集将语音与开放词汇指令配对，每个指令都带有连接高级指令到声学特征的推理过程。推理驱动框架在合成语音前从开放词汇指令推断情感、声学和副语言信息。

Result: 评估显示这种推理驱动方法显著提高了指令跟随保真度和语音表现力，能够实现更强的泛化能力和实际应用性。

Conclusion: 这项工作可以启发下一代用户友好的InstructTTS系统，具有更强的泛化能力和实际应用价值。数据集和演示已在项目页面公开。

Abstract: Instruct Text-to-Speech (InstructTTS) leverages natural language descriptions as style prompts to guide speech synthesis. However, existing InstructTTS methods mainly rely on a direct combination of audio-related labels or their diverse rephrasings, making it difficult to handle flexible, high-level instructions. Such rigid control is insufficient for users such as content creators who wish to steer generation with descriptive instructions. To address these constraints, we introduce OV-InstructTTS, a new paradigm for open-vocabulary InstructTTS. We propose a comprehensive solution comprising a newly curated dataset, OV-Speech, and a novel reasoning-driven framework. The OV-Speech dataset pairs speech with open-vocabulary instructions, each augmented with a reasoning process that connects high-level instructions to acoustic features. The reasoning-driven framework infers emotional, acoustic, and paralinguistic information from open-vocabulary instructions before synthesizing speech. Evaluations show that this reasoning-driven approach significantly improves instruction-following fidelity and speech expressiveness. We believe this work can inspire the next user-friendly InstructTTS systems with stronger generalization and real-world applicability. The dataset and demos are publicly available on our project page.

</details>


### [29] [MOSS Transcribe Diarize: Accurate Transcription with Speaker Diarization](https://arxiv.org/abs/2601.01554)
*Donghua Yu,Zhengyuan Lin,Chen Yang,Yiyang Zhang,Zhaoye Fei,Hanfu Chen,Jingqi Chen,Ke Chen,Qinyuan Cheng,Liwei Fan,Yi Jiang,Jie Zhu,Muchen Li,Shimin Li,Wenxuan Wang,Yang Wang,Zhe Xu,Yitian Gong,Yuqian Zhang*

Main category: cs.SD

TL;DR: MOSS Transcribe Diarize：一个统一的多模态大语言模型，以端到端方式联合执行说话人归属、时间戳转录任务，在多个基准测试中超越现有商业系统。


<details>
  <summary>Details</summary>
Motivation: 现有SATS系统很少采用端到端框架，且受限于有限的上下文窗口、弱的长距离说话人记忆能力以及无法输出时间戳。需要解决这些限制来改进会议转录质量。

Method: 提出MOSS Transcribe Diarize，一个统一的多模态大语言模型，采用端到端范式联合执行说话人归属和时间戳转录。使用大量真实数据训练，具备128k上下文窗口，支持长达90分钟的输入。

Result: 在全面的评估中，MOSS Transcribe Diarize在多个公开和内部基准测试中超越了最先进的商业系统，表现出良好的扩展性和鲁棒泛化能力。

Conclusion: MOSS Transcribe Diarize通过端到端多模态大语言模型方法，有效解决了现有SATS系统的局限性，在说话人归属和时间戳转录任务上取得了显著改进。

Abstract: Speaker-Attributed, Time-Stamped Transcription (SATS) aims to transcribe what is said and to precisely determine the timing of each speaker, which is particularly valuable for meeting transcription. Existing SATS systems rarely adopt an end-to-end formulation and are further constrained by limited context windows, weak long-range speaker memory, and the inability to output timestamps. To address these limitations, we present MOSS Transcribe Diarize, a unified multimodal large language model that jointly performs Speaker-Attributed, Time-Stamped Transcription in an end-to-end paradigm. Trained on extensive real wild data and equipped with a 128k context window for up to 90-minute inputs, MOSS Transcribe Diarize scales well and generalizes robustly. Across comprehensive evaluations, it outperforms state-of-the-art commercial systems on multiple public and in-house benchmarks.

</details>


### [30] [MM-Sonate: Multimodal Controllable Audio-Video Generation with Zero-Shot Voice Cloning](https://arxiv.org/abs/2601.01568)
*Chunyu Qiang,Jun Wang,Xiaopeng Wang,Kang Yin,Yuxin Guo,Xijuan Zeng,Nan Li,Zihan Li,Yuzhe Liang,Ziyu Zhang,Teng Ma,Yushen Chen,Zhongliang Liu,Feng Deng,Chen Zhang,Pengfei Wan*

Main category: cs.SD

TL;DR: MM-Sonate：统一的多模态流匹配框架，实现可控的音频-视频联合生成与零样本语音克隆，通过指令-音素输入确保时序对齐，引入音色注入机制分离说话人身份与内容，使用噪声负条件策略提升音频保真度。


<details>
  <summary>Details</summary>
Motivation: 当前联合音频-视频生成模型存在两个主要问题：1）由于级联生成导致时序不对齐；2）缺乏在联合合成框架内实现零样本语音克隆的能力。现有方法要么依赖粗粒度语义描述，要么无法在统一框架中实现精确的语音控制。

Method: 提出MM-Sonate多模态流匹配框架，采用统一的指令-音素输入确保语言和时序对齐；引入音色注入机制解耦说话人身份与语言内容；提出基于噪声的负条件策略，利用自然噪声先验增强音频保真度，克服标准无分类器引导在多模态设置中的局限性。

Result: 在联合生成基准测试中达到新的SOTA性能，在唇部同步和语音清晰度方面显著优于基线方法，同时实现了与专业文本到语音系统相当的语音克隆保真度。

Conclusion: MM-Sonate成功统一了可控的音频-视频联合生成与零样本语音克隆功能，通过创新的输入表示、音色解耦机制和噪声条件策略，解决了现有方法在时序对齐和语音控制方面的关键限制。

Abstract: Joint audio-video generation aims to synthesize synchronized multisensory content, yet current unified models struggle with fine-grained acoustic control, particularly for identity-preserving speech. Existing approaches either suffer from temporal misalignment due to cascaded generation or lack the capability to perform zero-shot voice cloning within a joint synthesis framework. In this work, we present MM-Sonate, a multimodal flow-matching framework that unifies controllable audio-video joint generation with zero-shot voice cloning capabilities. Unlike prior works that rely on coarse semantic descriptions, MM-Sonate utilizes a unified instruction-phoneme input to enforce strict linguistic and temporal alignment. To enable zero-shot voice cloning, we introduce a timbre injection mechanism that effectively decouples speaker identity from linguistic content. Furthermore, addressing the limitations of standard classifier-free guidance in multimodal settings, we propose a noise-based negative conditioning strategy that utilizes natural noise priors to significantly enhance acoustic fidelity. Empirical evaluations demonstrate that MM-Sonate establishes new state-of-the-art performance in joint generation benchmarks, significantly outperforming baselines in lip synchronization and speech intelligibility, while achieving voice cloning fidelity comparable to specialized Text-to-Speech systems.

</details>


### [31] [BeatlesFC: Harmonic function annotations of Isophonics' The Beatles dataset](https://arxiv.org/abs/2601.02099)
*Ji Yeoung Sim,Rebecca Moranis,Johanna Devaney*

Main category: cs.SD

TL;DR: BeatlesFC为披头士数据集提供和声功能标注，将和弦标记为稳定（主音）或不稳定（下属、属音），在乐句层面连接和弦标签与更高层次音乐结构。


<details>
  <summary>Details</summary>
Motivation: 现有披头士数据集缺乏和声功能标注，而和声功能分析对于理解音乐结构和连接不同层次音乐信息至关重要。

Method: 为Isophonics披头士数据集创建和声功能标注集，将和弦标签分类为稳定（主音）或不稳定（下属、属音）功能，并在乐句层面进行标注。

Result: 创建了BeatlesFC标注集，提供了披头士歌曲的和声功能分析，填补了现有数据集的空白，为音乐分析和计算音乐学研究提供了新资源。

Conclusion: BeatlesFC标注集为披头士音乐的和声分析提供了重要工具，有助于连接和弦级分析与更高层次音乐形式结构的研究。

Abstract: This paper presents BeatlesFC, a set of harmonic function annotations for Isophonics' The Beatles dataset. Harmonic function annotations characterize chord labels as stable (tonic) or unstable (predominant, dominant). They operate at the level of musical phrases, serving as a link between chord labels and higher-level formal structures.

</details>


### [32] [A Mamba-Based Model for Automatic Chord Recognition](https://arxiv.org/abs/2601.02101)
*Chunyu Yuan,Johanna Devaney*

Main category: cs.SD

TL;DR: 提出BMACE模型，基于双向Mamba层和选择性结构化状态空间模型，用于自动和弦估计，在保持高性能的同时减少参数和计算资源


<details>
  <summary>Details</summary>
Motivation: 现有自动和弦估计模型通常需要大量参数和计算资源，需要开发更高效的解决方案

Method: 使用基于选择性结构化状态空间模型的双向Mamba层来有效建模时间依赖关系

Result: 模型达到与最先进模型相当的预测性能，同时需要更少的参数和更低的计算资源

Conclusion: BMACE模型为自动和弦估计提供了一种高效且性能优越的解决方案

Abstract: In this work, we propose a new efficient solution, which is a Mamba-based model named BMACE (Bidirectional Mamba-based network, for Automatic Chord Estimation), which utilizes selective structured state-space models in a bidirectional Mamba layer to effectively model temporal dependencies. Our model achieves high prediction performance comparable to state-of-the-art models, with the advantage of requiring fewer parameters and lower computational resources

</details>


### [33] [DARC: Drum accompaniment generation with fine-grained rhythm control](https://arxiv.org/abs/2601.02357)
*Trey Brosnan*

Main category: cs.SD

TL;DR: DARC是一个鼓伴奏生成模型，通过参数高效微调增强STAGE模型，实现音乐上下文感知和细粒度节奏控制


<details>
  <summary>Details</summary>
Motivation: 现有音乐生成工具在结构控制和风格灵活性方面存在不足：stem-to-stem生成方法对节奏控制有限，而音色转换方法虽然能指定节奏但无法考虑音乐上下文

Method: 使用参数高效微调技术增强STAGE（最先进的鼓stem生成器），使其既能基于其他stem的音乐上下文，又能接受明确的节奏提示（如beatboxing或敲击音轨）

Result: 开发出DARC模型，在保持音乐上下文感知能力的同时实现了细粒度的节奏控制

Conclusion: DARC通过结合音乐上下文和明确节奏提示，解决了现有方法在结构控制和风格灵活性方面的局限性，为音乐创作提供了更好的快速原型工具

Abstract: In music creation, rapid prototyping is essential for exploring and refining ideas, yet existing generative tools often fall short when users require both structural control and stylistic flexibility. Prior approaches in stem-to-stem generation can condition on other musical stems but offer limited control over rhythm, and timbre-transfer methods allow users to specify specific rhythms, but cannot condition on musical context. We introduce DARC, a generative drum accompaniment model that conditions both on musical context from other stems and explicit rhythm prompts such as beatboxing or tapping tracks. Using parameter-efficient fine-tuning, we augment STAGE, a state-of-the-art drum stem generator, with fine-grained rhythm control while maintaining musical context awareness.

</details>

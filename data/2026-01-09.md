<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 11]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.SD](#cs.SD) [Total: 12]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Towards Radar-Agnostic Gait Analysis Across UWB and FMCW Systems](https://arxiv.org/abs/2601.04415)
*Charalambos Hadjipanayi,Maowen Yin,Alan Bannon,Ziwei Chen,Timothy G. Constandinou*

Main category: eess.SP

TL;DR: 该研究验证了统一处理框架可应用于不同雷达模态的步态分析，IR-UWB和FMCW雷达在相同处理设置下达到85-98%的准确率，模态间差异小于4.1%，支持雷达无关的步态分析系统可行性。


<details>
  <summary>Details</summary>
Motivation: 雷达传感已成为家庭步态监测的有前景方案，但不同雷达模态（如IR-UWB和FMCW）是否需要特定处理框架尚不明确。本研究旨在评估统一处理框架是否可独立于雷达模态应用于时空步态分析。

Method: 使用共置的IR-UWB和FMCW雷达，在相同处理设置下（无模态特定调优），对10名健康参与者进行重复地面行走试验。引入模态无关的自动行走段识别方法，提取步态参数（步幅时间、步幅长度、步行速度、摆动时间、支撑时间）并与运动捕捉金标准比较。

Result: 两种雷达模态在所有参数上均达到85-98%的平均估计准确率，模态间差异低于4.1%，准确率分布高度重叠。相关性、Bland-Altman和组内相关性分析显示最小偏差、可比的协议限度和与参考估计的强一致性。

Conclusion: 使用共享处理框架时，雷达模态不会产生实际有意义的性能差异，这支持了雷达无关步态分析系统的可行性，为不同雷达技术的统一应用提供了依据。

Abstract: Radar sensing has emerged in recent years as a promising solution for unobtrusive and continuous in-home gait monitoring. This study evaluates whether a unified processing framework can be applied to radar-based spatiotemporal gait analysis independent of radar modality. The framework is validated using collocated impulse-radio ultra-wideband (IR-UWB) and frequency-modulated continuous-wave (FMCW) radars under identical processing settings, without modality-specific tuning, during repeated overground walking trials with 10 healthy participants. A modality-independent approach for automatic walking-segment identification is also introduced to ensure fair and reproducible modality performance assessment. Clinically relevant spatiotemporal gait parameters, including stride time, stride length, walking speed, swing time, and stance time, extracted from each modality were compared against gold-standard motion capture reference estimates. Across all parameters, both radar modalities achieved comparably high mean estimation accuracy in the range of 85-98%, with inter-modality differences remaining below 4.1%, resulting in highly overlapping accuracy distributions. Correlation and Bland-Altman analyses revealed minimal bias, comparable limits of agreement, and strong agreement with reference estimates, while intraclass correlation analysis demonstrated high consistency between radar modalities. These findings indicate that no practically meaningful performance differences arise from radar modality when using a shared processing framework, supporting the feasibility of radar-agnostic gait analysis systems.

</details>


### [2] [Prediction of Cellular Malignancy Using Electrical Impedance Signatures and Supervised Machine Learning](https://arxiv.org/abs/2601.04478)
*Shadeeb Hossain*

Main category: eess.SP

TL;DR: 该研究系统综述了33篇学术文章，收集了细胞生物电参数数据集，并评估了其在预测建模中的应用。使用随机森林、支持向量机和K近邻三种机器学习算法进行分类，随机森林在特定参数配置下达到约90%的最高准确率。


<details>
  <summary>Details</summary>
Motivation: 健康细胞和恶性细胞的生物电特性（如相对介电常数、电导率、特征时间常数）在不同频率下存在显著差异，这为诊断和分类应用提供了有前景的基础。研究旨在评估这些生物电参数在预测建模中的效用。

Method: 系统综述33篇学术文章，收集定量生物电参数数据集。实现并调优三种监督机器学习算法：随机森林、支持向量机和K近邻，使用关键超参数评估分类性能。使用准确率和F1分数作为性能指标。

Result: 随机森林在最大深度为4、100个估计器的配置下达到最高的预测准确率约90%。KNN和SVM的F1分数分别达到约78%和76.5%。

Conclusion: 研究结果表明，将生物电特性分析与机器学习相结合具有改善诊断决策的潜力。未来工作将探索纳入更多判别特征、利用增强数据集、优化超参数搜索策略，并开发带有嵌入式微电极和实时控制系统的硬件原型，实现原位细胞分类的实用诊断工具。

Abstract: Bioelectrical properties of cells such as relative permittivity, conductivity, and characteristic time constants vary significantly between healthy and malignant cells across different frequencies. These distinctions provide a promising foundation for diagnostic and classification applications. This study systematically reviewed 33 scholarly articles to compile datasets of quantitative bioelectric parameters and evaluated their utility in predictive modeling. Three supervised machine learning algorithms- Random Forest (RF), Support Vector Machine (SVM), and K-Nearest Neighbor (KNN) were implemented and tuned using key hyperparameters to assess classification performance. Model effectiveness was evaluated using accuracy and F1 score as performance metrics. Results demonstrate that Random Forest achieved the highest predictive accuracy of ~ 90% when configured with a maximum depth of 4 and 100 estimators. These findings highlight the potential of integrating bioelectrical property analysis with machine learning for improved diagnostic decision-making. Similarly, for KNN and SVM, the F1 score peaked at approximately 78% and 76.5%, respectively. Future work will explore incorporating additional discriminative features, leveraging stimulated datasets, and optimizing hyperparameter through advanced search strategies. Ultimately, hardware prototype with embedded micro-electrodes and real-time control systems could pave the path for practical diagnostic tools capable of in-situ cell classification.

</details>


### [3] [Invisible Walls: Privacy-Preserving ISAC Empowered by Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2601.04488)
*Yinghui He,Long Fan,Lei Xie,Dusit Niyato,Chau Yuen,Jun Luo*

Main category: eess.SP

TL;DR: PrivISAC：利用RIS保护ISAC用户隐私的低成本即插即用方案，通过随机激活RIS配置引入扰动来防止窃听，同时保持通信和感知性能


<details>
  <summary>Details</summary>
Motivation: 无线信号（如CSI）携带的环境和目标信息在ISAC中受到关注，但也引发隐私泄露担忧。现有方案要么忽视合法用户需求，要么依赖高复杂度硬件，需要低成本、有效的隐私保护方案

Method: 1) 为RIS每行分配两个不同的波束赋形向量，构建有限配置集；2) 每个时隙随机激活一个配置，引入扰动掩盖敏感信息；3) 设计向量使通信方向响应相似（保持传输稳定），感知方向响应差异大（引入足够扰动）；4) 使用时域掩蔽和去掩蔽方法，让授权接收器关联CSI样本与配置，消除配置差异

Result: 在商用无线设备上实现PrivISAC，实验结果表明：提供强大的隐私保护，同时保持高质量的合法ISAC性能

Conclusion: PrivISAC是一种低成本、即插即用的解决方案，能有效保护ISAC用户隐私，防止窃听，同时不损害合法通信和感知性能，解决了现有方案的局限性

Abstract: The environmental and target-related information inherently carried in wireless signals, such as channel state information (CSI), has brought increasing attention to integrated sensing and communication (ISAC). However, it also raises pressing concerns about privacy leakage through eavesdropping. While existing efforts have attempted to mitigate this issue, they either fail to account for the needs of legitimate communication and sensing users or rely on hardware with high complexity and cost. To overcome these limitations, we propose PrivISAC, a plug-and-play, low-cost solution that leverages RIS to protect user privacy while preserving ISAC performance. At the core of PrivISAC is a novel strategy in which each RIS row is assigned two distinct beamforming vectors, from which we deliberately construct a limited set of RIS configurations. During operation, exactly one configuration is randomly activated at each time slot to introduce additional perturbations, effectively masking sensitive sensing information from unauthorized eavesdroppers. To jointly ensure privacy protection and communication performance, we design the two vectors such that their responses remain nearly identical in the communication direction, thereby preserving stable, high-throughput transmission, while exhibiting pronounced differences in the sensing direction, which introduces sufficient perturbations to thwart eavesdroppers. Additionally, to enable legitimate sensing under such randomized configurations, we introduce a time-domain masking and demasking method that allows the authorized receiver to associate each CSI sample with its underlying configuration and eliminate configuration-induced discrepancies, thereby recovering valid CSI. We implement PrivISAC on commodity wireless devices and experiment results show that PrivISAC provides strong privacy protection while preserving high-quality legitimate ISAC.

</details>


### [4] [Spectral point transformer for significant wave height estimation from sea clutter](https://arxiv.org/abs/2601.04581)
*Yi Zhou,Li Wang,Hang Su,Tian Wang*

Main category: eess.SP

TL;DR: 提出基于Transformer的SPT方法，利用少数强功率谱点估计有效波高，特征学习与物理色散关系一致，计算效率高


<details>
  <summary>Details</summary>
Motivation: 传统方法处理图像序列和全谱数据计算量大，而经验观察发现只有少数强功率谱点对波能有贡献，需要高效准确的波高估计方法

Method: SPT（基于Transformer的谱点方法），整合海洋表面波的几何和谱特征，通过多维特征表示估计有效波高，学习特征与物理色散关系对齐

Result: SPT在波高回归中优于传统视觉网络，计算资源消耗显著减少，在消费级GPU上4分钟完成1080个海杂波图像序列的训练

Conclusion: SPT方法有效整合物理特性，计算效率高，可降低雷达测波系统的部署成本，具有实际应用潜力

Abstract: This paper presents a method for estimating significant wave height (Hs) from sparse S_pectral P_oint using a T_ransformer-based approach (SPT). Based on empirical observations that only a minority of spectral points with strong power contribute to wave energy, the proposed SPT effectively integrates geometric and spectral characteristics of ocean surface waves to estimate Hs through multi-dimensional feature representation. The experiment reveals an intriguing phenomenon: the learned features of SPT align well with physical dispersion relations, where the contribution-score map of selected points is concentrated along dispersion curves. Compared to conventional vision networks that process image sequences and full spectra, SPT demonstrates superior performance in Hs regression while consuming significantly fewer computational resources. On a consumer-grade GPU, SPT completes the training of regression model for 1080 sea clutter image sequences within 4 minutes, showcasing its potential to reduce deployment costs for radar wave-measuring systems. The open-source implementation of SPT will be available at https://github.com/joeyee/spt

</details>


### [5] [MIMO Beam Map Reconstruction via Toeplitz-Structured Matrix-Vector Tensor Decomposition](https://arxiv.org/abs/2601.04599)
*Hao Sun,Junting Chen,Xianghao Yu*

Main category: eess.SP

TL;DR: 提出一种基于张量分解的方法，从稀疏测量中重建MIMO波束图，通过极坐标变换揭示传播条件的矩阵-向量外积结构，利用Toeplitz先验显著提升数据效率。


<details>
  <summary>Details</summary>
Motivation: 随着无线网络向6G发展，理解定向波束覆盖的空间分布对于波束管理和链路优化至关重要。MIMO波束图提供这种空间感知，但在稀疏测量下由于不完整的空间覆盖和强烈的角度变化，准确构建仍然困难。

Method: 将测量从笛卡尔坐标系转换到极坐标系，揭示与不同传播条件相关的矩阵-向量外积结构。数学证明矩阵因子（代表波束空间增益）由于阵列响应的平移不变性具有内在的Toeplitz结构，向量因子捕获距离相关的衰减。利用这些结构先验，制定正则化张量分解问题来联合重建LOS、反射和遮挡传播条件。

Result: 仿真结果表明，该方法显著提高了数据效率，即使在稀疏采样情况下，与最先进的基线相比，归一化均方误差（NMSE）降低了超过20%。

Conclusion: 提出的张量分解方法通过利用波束图的固有结构先验，能够从稀疏测量中有效重建MIMO波束图，为6G网络中的波束管理和链路优化提供了高效解决方案。

Abstract: As wireless networks progress toward sixthgeneration (6G), understanding the spatial distribution of directional beam coverage becomes increasingly important for beam management and link optimization. Multiple-input multipleoutput (MIMO) beam map provides such spatial awareness, yet accurate construction under sparse measurements remains difficult due to incomplete spatial coverage and strong angular variations. This paper presents a tensor decomposition approach for reconstructing MIMO beam map from limited measurements. By transforming measurements from a Cartesian coordinate system into a polar coordinate system, we uncover a matrix-vector outer-product structure associated with different propagation conditions. Specifically, we mathematically demonstrate that the matrix factor, representing beam-space gain, exhibits an intrinsic Toeplitz structure due to the shift-invariant nature of array responses, and the vector factor captures distance-dependent attenuation. Leveraging these structural priors, we formulate a regularized tensor decomposition problem to jointly reconstruct line-of-sight (LOS), reflection, and obstruction propagation conditions. Simulation results confirm that the proposed method significantly enhances data efficiency, achieving a normalized mean square error (NMSE) reduction of over 20% compared to state-of-the-art baselines, even under sparse sampling regimes.

</details>


### [6] [An Ultra-Fast MLE for Low SNR Multi-Reference Alignment](https://arxiv.org/abs/2601.04831)
*Shay Kreymer,Amnon Balanov,Tamir Bendory*

Main category: eess.SP

TL;DR: 提出一种超快速算法用于特殊正交群SO(2)上的多参考对齐问题，通过低信噪比下的泰勒展开和对数似然近似，实现单次数据遍历的高效信号估计。


<details>
  <summary>Details</summary>
Motivation: 受单粒子冷冻电镜技术启发，多参考对齐(MRA)模型需要从多个受随机旋转影响的噪声观测中恢复未知信号。传统期望最大化(EM)方法在低信噪比(SNR)下计算成本过高，需要更高效的替代方案。

Method: 在低信噪比条件下对对数似然进行泰勒展开，通过顺序计算观测数据的数据驱动平均值来估计信号。该方法仅需单次数据遍历，显著降低了计算复杂度。

Result: 数值实验表明，该方法在低信噪比环境下能达到高精度，并为后续EM细化提供了优秀的初始化起点，计算效率远超传统EM方法。

Conclusion: 提出的超快速算法为多参考对齐问题提供了高效解决方案，特别适用于低信噪比场景，可作为EM方法的有效补充和初始化工具。

Abstract: Motivated by single-particle cryo-electron microscopy, multi-reference alignment (MRA) models the task of recovering an unknown signal from multiple noisy observations corrupted by random rotations. The standard approach, expectation-maximization (EM), often becomes computationally prohibitive, particularly in low signal-to-noise ratio (SNR) settings. We introduce an alternative, ultra-fast algorithm for MRA over the special orthogonal group $\mathrm{SO}(2)$. By performing a Taylor expansion of the log-likelihood in the low-SNR regime, we estimate the signal by sequentially computing data-driven averages of observations. Our method requires only one pass over the data, dramatically reducing computational cost compared to EM. Numerical experiments show that the proposed approach achieves high accuracy in low-SNR environments and provides an excellent initialization for subsequent EM refinement.

</details>


### [7] [SE-EE Tradeoff in Pinching-Antenna Systems: Waveguide Multiplexing or Waveguide Switching?](https://arxiv.org/abs/2601.04844)
*Guangyu Zhu,Xidong Mu,Li Guo,Shibiao Xu,Yuanwei Liu,Naofal Al-Dhahir*

Main category: eess.SP

TL;DR: 研究了夹持天线系统中频谱效率和能量效率的权衡，比较了波导复用和波导切换两种协议，通过多目标优化方法进行联合优化。


<details>
  <summary>Details</summary>
Motivation: 传统天线系统在大规模路径损耗方面存在限制，夹持天线系统（PASS）有望通过波导复用和波导切换协议来改善频谱效率和能量效率之间的权衡关系。

Method: 采用多目标优化问题（MOOP）框架，使用ε-约束方法转换为单目标问题。对于波导复用协议，采用交替优化框架，结合逐次凸逼近和粒子群优化；对于波导切换协议，利用时分传输和无干扰特性，先优化夹持波束成形再分配基带功率。

Result: 1) PASS相比传统天线能有效缓解大规模路径损耗；2) 波导切换通过激活单个射频链获得更高的最大能量效率，而波导复用通过同时服务所有用户获得更高的频谱效率上限；3) 增加用户数在波导复用下显著提升频谱效率，而波导切换在低信噪比区域表现更优。

Conclusion: 夹持天线系统在频谱效率和能量效率权衡方面优于传统天线系统，波导复用和波导切换协议在不同应用场景下各有优势，为未来无线通信系统设计提供了有价值的参考。

Abstract: The spectral and energy efficiency (SE-EE) trade-off in pinching-antenna systems (PASS) is investigated in this paper. In particular, two practical operating protocols, namely waveguide multiplexing (WM) and waveguide switching (WS), are considered. A multi-objective optimization problem (MOOP) is formulated to jointly optimize the baseband and pinching beamforming for maximizing the achievable SE and EE, which is then converted into a single-objective problem via the ε-constraint method. For WM, the problem is decomposed within the alternating-optimization framework, where the baseband beamforming is optimized using the successive convex approximation, and the pinching beamforming is updated through the particle swarm optimization. For WS, due to the time-division transmission and interference-free nature, the pinching beamforming in each time slot is first adjusted to maximize the served user channel gain, followed by the baseband power allocation. Simulation results demonstrate that 1) PASS outperforms conventional antennas by mitigating large-scale path losses; 2) WS leads to a higher maximum achievable EE by activating a single RF chain, whereas WM yields a higher SE upper bound by serving all users concurrently; and 3) increasing the number of users substantially enhances SE under WM, whereas WS shows more pronounced benefits in low-signal-to-noise ratio regimes.

</details>


### [8] [6D Movable Antenna Enhanced Cell-free MIMO: Two-timescale Decentralized Beamforming and Antenna Movement Optimization](https://arxiv.org/abs/2601.04969)
*Yichi Zhang,Yuchen Zhang,Wenyan Ma,Lipeng Zhu,Jianquan Wang,Wanbin Tang,Rui Zhang*

Main category: eess.SP

TL;DR: 本文提出了一种6DMA辅助的无蜂窝多用户MIMO系统，采用两时间尺度去中心化优化框架，在短时间尺度进行本地波束成形，长时间尺度优化天线位置和阵列方向，以解决高移动性场景下的实现挑战。


<details>
  <summary>Details</summary>
Motivation: 传统6DMA系统中频繁的天线移动和基于全局瞬时CSI的集中式波束成形会导致极高的信号处理延迟和系统开销，难以在信道相干时间短的高移动性场景中实际实现。

Method: 提出两时间尺度去中心化优化框架：短时间尺度中每个AP基于本地瞬时CSI和全局统计CSI更新接收波束成形器；长时间尺度中中央处理单元基于全局统计CSI优化所有AP的天线位置和阵列方向。开发了约束随机逐次凸逼近算法来解决非凸且变量高度耦合的优化问题。

Result: 数值结果表明，所提出的6DMA辅助无蜂窝系统在去中心化波束成形下，显著优于灵活性较低的其他天线移动方案，甚至实现了与集中式波束成形基准相当的性能。

Conclusion: 提出的两时间尺度去中心化优化框架有效解决了6DMA系统在高移动性场景中的实际实现挑战，通过分离时间尺度优化显著降低了系统开销，同时保持了优异的通信性能。

Abstract: This paper investigates a six-dimensional movable antenna (6DMA)-aided cell-free multi-user multiple-input multiple-output (MIMO) communication system. In this system, each distributed access point (AP) can flexibly adjust its array orientation and antenna positions to adapt to spatial channel variations and enhance communication performance. However, frequent antenna movements and centralized beamforming based on global instantaneous channel state information (CSI) sharing among APs entail extremely high signal processing delay and system overhead, which is difficult to be practically implemented in high-mobility scenarios with short channel coherence time. To address these practical implementation challenges and improve scalability, a two-timescale decentralized optimization framework is proposed in this paper to jointly design the beamformer, antenna positions, and array orientations. In the short timescale, each AP updates its receive beamformer based on local instantaneous CSI and global statistical CSI. In the long timescale, the central processing unit optimizes the antenna positions and array orientations at all APs based on global statistical CSI to maximize the ergodic sum rate of all users. The resulting optimization problem is non-convex and involves highly coupled variables, thus posing significant challenges for obtaining efficient solutions. To address this problem, a constrained stochastic successive convex approximation algorithm is developed. Numerical results demonstrate that the proposed 6DMA-aided cell-free system with decentralized beamforming significantly outperforms other antenna movement schemes with less flexibility and even achieves a performance comparable to that of the centralized beamforming benchmark.

</details>


### [9] [Ultra-Wideband Transmission Systems From an Energy Perspective: Which Band is Next?](https://arxiv.org/abs/2601.05000)
*Ronit Sohanpal,Mindaugus Jarmolovicius,Jiaqian Yang,Eric Sillekens,Romulo Aparecido,Vitaly Mikhailov,Jiawei Luo,David J. DiGiovanni,Ruben S. Luis,Hideaki Furukawa,Robert I. Killey,Polina Bayvel*

Main category: eess.SP

TL;DR: 比较OESCL波段与CL波段放大器的功率效率，发现1000公里OESCL波段系统吞吐量提升2.98倍，但每比特能耗增加48%


<details>
  <summary>Details</summary>
Motivation: 评估和比较不同波段（OESCL-band与CL-band）光纤传输系统的功率效率，为高吞吐量光通信系统设计提供能耗参考

Method: 测量最先进OESCL波段放大器的功率效率，并与CL波段传输进行对比分析

Result: 1000公里OESCL波段系统相比纯CL波段传输，吞吐量提高2.98倍，但每比特能耗增加48%

Conclusion: OESCL波段系统在吞吐量方面具有显著优势，但需要权衡能耗增加的问题，为高容量光通信系统设计提供了重要的能耗性能权衡参考

Abstract: Measuring the power efficiency of the state-of-the-art OESCL-band amplifiers, we show that 1000 km OESCL-band systems can achieve 2.98x greater throughput for +48% higher energy-per-bit compared to CL-band transmission only.

</details>


### [10] [On the Impact of Channel Aging and Doppler-Affected Clutter on OFDM ISAC Systems](https://arxiv.org/abs/2601.05032)
*Steven Rivetti,Gabor Fodor,Emil Björnson,Mikael Skoglund*

Main category: eess.SP

TL;DR: 论文研究了信道老化与杂波对ISAC系统的联合影响，提出了老化感知信道估计器和低复杂度感知流水线，在低中速移动场景下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传播环境的时变演化在ISAC系统中至关重要：慢时演化表现为通信链路的信道老化，快时演化则与具有非零多普勒的结构化杂波相关。然而，这两种现象对ISAC性能的联合影响一直被忽视，本文旨在填补这一研究空白。

Method: 1. 使用OFDM波形的网络，基站同时服务多个UE设备并进行单站感知；2. 通过指数相关衰减的自回归模型捕捉信道老化；3. 将杂波建模为具有非零多普勒的互不相关相干散射体集合，形成Kronecker可分离协方差结构；4. 提出老化感知信道估计器，利用先导观测估计时变UE信道；5. 设计低复杂度感知流水线：从原始数据估计杂波统计量，抑制杂波影响，然后通过距离-角度和距离-速度图提取目标参数。

Result: 1. 评估了帧长度和先导历史对信道估计精度的影响，在低到中等移动性场景下相比块衰落模型获得显著性能提升；2. 在杂波主导环境中实现感知流水线，证明在实际配置下可实现有效杂波抑制；3. 结果表明需要专用感知流，因为通信波束提供的距离分辨率不足。

Conclusion: 本文首次系统研究了信道老化与结构化杂波对ISAC系统的联合影响，提出的老化感知信道估计和低复杂度感知流水线在实际场景中表现优异，为ISAC系统设计提供了重要指导，特别是强调了专用感知流的必要性。

Abstract: The temporal evolution of the propagation environment plays a central role in integrated sensing and communication (ISAC) systems. A slow-time evolution manifests as channel aging in communication links, while a fast-time one is associated with structured clutter with non-zero Doppler. Nevertheless, the joint impact of these two phenomena on ISAC performance has been largely overlooked. This addresses this research gap in a network utilizing orthogonal frequency division multiplexing waveforms. Here, a base station simultaneously serves multiple user equipment (UE) devices and performs monostatic sensing. Channel aging is captured through an autoregressive model with exponential correlation decay. In contrast, clutter is modeled as a collection of uncorrelated, coherent patches with non-zero Doppler, resulting in a Kronecker-separable covariance structure. We propose an aging-aware channel estimator that uses prior pilot observations to estimate the time-varying UE channels, characterized by a non-isotropic multipath fading structure. The clutter's structure enables a novel low-complexity sensing pipeline: clutter statistics are estimated from raw data and subsequently used to suppress the clutter's action, after which target parameters are extracted through range-angle and range-velocity maps. We evaluate the influence of frame length and pilot history on channel estimation accuracy and demonstrate substantial performance gains over block fading in low-to-moderate mobility regimes. The sensing pipeline is implemented in a clutter-dominated environment, demonstrating that effective clutter suppression can be achieved under practical configurations. Furthermore, our results show that dedicated sensing streams are required, as communication beams provide insufficient range resolution.

</details>


### [11] [Multi-band Carrier Phase Positioning toward 6G: Performance Bounds and Efficient Estimators](https://arxiv.org/abs/2601.05178)
*Ehsan Shourezari,Ossi Kaltiokallio,Mehmet C. Ilter,Jukka Talvitie,Gonzalo Seco-Granados,Henk Wymeersch,Mikko Valkama*

Main category: eess.SP

TL;DR: 多频段载波相位定位在5G/6G移动网络中实现高精度定位，通过载波聚合解决整数模糊度问题，仅需两个载波即可显著提升定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着5G向6G演进，载波相位定位在移动网络中受到关注，但面临整数模糊度问题的挑战。需要研究多频段载波聚合方案来提升定位精度并应对实际网络中的时钟偏移等缺陷。

Method: 研究多频段载波相位定位场景，包括FR1、mmWave-FR2和新兴6G FR3频段的载波聚合。推导多频段CPP性能边界，提出两阶段实用估计器，并扩展到基站频段非均匀或完全分离的场景。

Result: 仅需两个载波即可显著解决整数模糊度问题，并大幅增强对网络侧时钟缺陷和多径传播的鲁棒性。提出的估计器在所有实际带宽和发射功率条件下都能达到理论边界，特别适合窄带物联网应用。

Conclusion: 多频段载波相位定位为当前和未来移动网络提供了高精度定位解决方案，通过载波聚合有效解决整数模糊度问题，提出的实用估计器在实际部署中具有灵活性和高效性。

Abstract: In addition to satellite systems, carrier phase positioning (CPP) is gaining attraction also in terrestrial mobile networks, particularly in 5G New Radio evolution toward 6G. One key challenge is to resolve the integer ambiguity problem, as the carrier phase provides only relative position information. This work introduces and studies a multi-band CPP scenario with intra- and inter-band carrier aggregation (CA) opportunities across FR1, mmWave-FR2, and emerging 6G FR3 bands. Specifically, we derive multi-band CPP performance bounds, showcasing the superiority of multi-band CPP for high-precision localization in current and future mobile networks, while noting also practical imperfections such as clock offsets between the user equipment (UE) and the network as well as mutual clock imperfections between the network nodes. A wide collection of numerical results is provided, covering the impacts of the available carrier bandwidth, number of aggregated carriers, transmit power, and the number of network nodes or base stations. The offered results highlight that only two carriers suffice to substantially facilitate resolving the integer ambiguity problem while also largely enhancing the robustness of positioning against imperfections imposed by the network-side clocks and multi-path propagation. In addition, we also propose a two-stage practical estimator that achieves the derived bounds under all realistic bandwidth and transmit power conditions. Furthermore, we show that with an additional search-based refinement step, the proposed estimator becomes particularly suitable for narrowband Internet of Things applications operating efficiently even under narrow carrier bandwidths. Finally, both the derived bounds and the proposed estimators are extended to scenarios where the bands assigned to each base station are nonuniform or fully disjoint, enhancing the practical deployment flexibility.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [12] [Latent-Level Enhancement with Flow Matching for Robust Automatic Speech Recognition](https://arxiv.org/abs/2601.04459)
*Da-Hee Yang,Joon-Hyuk Chang*

Main category: eess.AS

TL;DR: 提出FM-Refiner模块，在ASR编码器的潜在空间进行流匹配精炼，作为传统语音增强的补充策略，提升噪声鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统波形级语音增强在ASR中效果有限，因为残留失真和与ASR编码器潜在空间不匹配。需要一种在ASR推理过程中直接在潜在空间进行精炼的互补策略。

Method: 提出FM-Refiner（流匹配精炼模块），在预训练CTC-ASR编码器的输出潜在表示上操作。训练该模块将不完美的潜在表示（来自噪声输入或增强但不完美的语音）映射到其干净对应物，推理时应用而不需要微调ASR参数。

Result: FM-Refiner能持续降低词错误率，无论是直接应用于噪声输入，还是与传统语音增强前端结合使用。证明潜在级精炼为现有SE方法提供了轻量有效的补充。

Conclusion: 通过流匹配进行潜在级精炼是一种轻量有效的策略，可作为现有语音增强方法的补充，提升噪声鲁棒ASR性能。

Abstract: Noise-robust automatic speech recognition (ASR) has been commonly addressed by applying speech enhancement (SE) at the waveform level before recognition. However, speech-level enhancement does not always translate into consistent recognition improvements due to residual distortions and mismatches with the latent space of the ASR encoder. In this letter, we introduce a complementary strategy termed latent-level enhancement, where distorted representations are refined during ASR inference. Specifically, we propose a plug-and-play Flow Matching Refinement module (FM-Refiner) that operates on the output latents of a pretrained CTC-based ASR encoder. Trained to map imperfect latents-either directly from noisy inputs or from enhanced-but-imperfect speech-toward their clean counterparts, the FM-Refiner is applied only at inference, without fine-tuning ASR parameters. Experiments show that FM-Refiner consistently reduces word error rate, both when directly applied to noisy inputs and when combined with conventional SE front-ends. These results demonstrate that latent-level refinement via flow matching provides a lightweight and effective complement to existing SE approaches for robust ASR.

</details>


### [13] [LLMs-Integrated Automatic Hate Speech Recognition Using Controllable Text Generation Models](https://arxiv.org/abs/2601.04654)
*Ryutaro Oshima,Yuya Hosoda,Youji Iiguni*

Main category: eess.AS

TL;DR: 提出一种结合ASR和LLM的仇恨语音识别模型，通过CoT提示生成训练数据，并采用课程学习逐步训练，实现语音转录和内容审查的双重任务。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨语音识别面临两个挑战：1) 需要同时进行语音转录和有害内容审查；2) 缺乏足够的标注仇恨语音数据集来训练LLM进行指令调优。

Method: 1) 将ASR编码器与LLM解码器集成，实现同步转录和审查；2) 使用CoT提示技术生成文本样本，再通过TTS转换为语音；3) 用文本分类模型过滤样本，确保仇恨内容质量；4) 通过调整正确分类模型数量的阈值控制仇恨程度，采用课程学习逐步训练。

Result: 仇恨相关词语的掩码准确率达到58.6%，超过现有基线方法。课程学习显著提升了转录和审查任务的效率。

Conclusion: 提出的集成ASR-LLM框架能有效处理仇恨语音识别任务，通过数据生成和课程学习策略解决了标注数据不足的问题，在转录和审查双重任务上表现出色。

Abstract: This paper proposes an automatic speech recognition (ASR) model for hate speech using large language models (LLMs). The proposed method integrates the encoder of the ASR model with the decoder of the LLMs, enabling simultaneous transcription and censorship tasks to prevent the exposure of harmful content. Instruction tuning of the LLM to mask hate-related words with specific tokens requires an annotated hate speech dataset, which is limited. We generate text samples using an LLM with the Chain-of-Thought (CoT) prompting technique guided by cultural context and examples and then convert them into speech samples using a text-to-speech (TTS) system. However, some of them contain non-hate speech samples with hate-related words, which degrades the censorship performance. This paper filters the samples which text classification models correctly label as hate content. By adjusting the threshold for the number of correct answer models, we can control the level of hate in the generated dataset, allowing us to train the LLMs through curriculum learning in a gradual manner. Experimental results show that the proposed method achieves a masking accuracy of 58.6\% for hate-related words, surpassing previous baselines. We also confirm that the curriculum training contributes to the efficiency of both transcription and censorship tasks.

</details>


### [14] [Gradient-based Optimisation of Modulation Effects](https://arxiv.org/abs/2601.04867)
*Alistair Carson,Alec Wright,Stefan Bilbao*

Main category: eess.AS

TL;DR: 提出基于可微分数字信号处理的框架，用于建模镶边、合唱和相位效果器，在推理时实现零延迟，并通过低频加权损失函数优化延迟时间学习


<details>
  <summary>Details</summary>
Motivation: 现有的机器学习模拟调制效果方法要么局限于单一效果类型，要么计算成本高、延迟大，需要开发更通用、高效的模拟框架

Method: 基于可微分数字信号处理框架，在时频域训练但在时域推理，使用低频加权损失函数避免延迟时间学习中的局部最优收敛

Result: 模型在某些情况下能产生与模拟效果器感知上无法区分的音频输出，但对于长延迟时间和反馈效果仍存在挑战

Conclusion: 该框架为模拟调制效果提供了有效的零延迟解决方案，但长延迟和反馈效果仍需进一步研究改进

Abstract: Modulation effects such as phasers, flangers and chorus effects are heavily used in conjunction with the electric guitar. Machine learning based emulation of analog modulation units has been investigated in recent years, but most methods have either been limited to one class of effect or suffer from a high computational cost or latency compared to canonical digital implementations. Here, we build on previous work and present a framework for modelling flanger, chorus and phaser effects based on differentiable digital signal processing. The model is trained in the time-frequency domain, but at inference operates in the time-domain, requiring zero latency. We investigate the challenges associated with gradient-based optimisation of such effects, and show that low-frequency weighting of loss functions avoids convergence to local minima when learning delay times. We show that when trained against analog effects units, sound output from the model is in some cases perceptually indistinguishable from the reference, but challenges still remain for effects with long delay times and feedback.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [15] [Predictive Controlled Music](https://arxiv.org/abs/2601.04221)
*Midhun T. Augustine*

Main category: cs.SD

TL;DR: 提出了一种结合模型预测控制与音乐生成的新方法——预测控制音乐，通过优化性能指标来生成音乐音符，采用神经网络评估函数和循环神经网络模型来定义约束条件。


<details>
  <summary>Details</summary>
Motivation: 将控制理论中的模型预测控制方法应用于算法作曲领域，通过动态模型预测和优化音乐生成过程，实现更智能、可控的音乐创作。

Method: 使用前馈神经网络评估函数作为优化目标，循环神经网络模型捕捉音符间关系并定义约束，采用滚动时域方式计算音乐音符，实现反馈控制预测。

Result: 通过数值示例展示了PCM生成方法，验证了该方法在算法作曲中的可行性和有效性。

Conclusion: PCM为算法作曲提供了一种新的控制理论框架，能够通过优化性能指标生成音乐，为音乐创作开辟了新途径。

Abstract: This paper presents a new approach to algorithmic composition, called predictive controlled music (PCM), which combines model predictive control (MPC) with music generation. PCM uses dynamic models to predict and optimize the music generation process, where musical notes are computed in a manner similar to an MPC problem by optimizing a performance measure. A feedforward neural network-based assessment function is used to evaluate the generated musical score, which serves as the objective function of the PCM optimization problem. Furthermore, a recurrent neural network model is employed to capture the relationships among the variables in the musical notes, and this model is then used to define the constraints in the PCM. Similar to MPC, the proposed PCM computes musical notes in a receding-horizon manner, leading to feedback controlled prediction. Numerical examples are presented to illustrate the PCM generation method.

</details>


### [16] [From Imitation to Innovation: The Divergent Paths of Techno in Germany and the USA](https://arxiv.org/abs/2601.04222)
*Tim Ziemer,Simon Linke*

Main category: cs.SD

TL;DR: 通过音频分析验证早期浩室和科技音乐的历史叙述，发现德美风格差异显著，美国风格相对稳定，德国风格演变迅速，这解释了为何科技音乐在德国成为大众现象而在美国保持小众。


<details>
  <summary>Details</summary>
Motivation: 现有关于早期浩室和科技音乐的纪录片和场景参与者描述缺乏音频分析验证，研究界认为这些叙述需要批判性检验，但此前没有基于音频分析的验证尝试。

Method: 分析了德国和美国超过9,000首早期浩室和科技音乐曲目，使用录音室特征、机器学习和推断统计方法进行音频分析。

Result: 1) 德国和美国浩室/科技音乐风格明显不同；2) 美国各风格之间相似度更高；3) 与美国相比，德国浩室/科技音乐在录音室特征方面随时间演变更显著。

Conclusion: 音频分析结果与文献记载一致，为科技音乐在德国成为大众现象而在美国保持小众提供了音频证据，此类分析可帮助音乐产业预测新趋势的发展前景。

Abstract: Many documentaries on early house and techno music exist. Here, protagonists from the scenes describe key elements and events that affected the evolution of the music. In the research community, there is consensus that such descriptions have to be examined critically. Yet, there have not been attempts to validate such statements on the basis of audio analyses. In this study, over 9,000 early house and techno tracks from Germany and the United States of America are analyzed using recording studio features, machine learning and inferential statistics. Three observations can be made: 1.) German and US house/techno music are distinct, 2.) US styles are much more alike, and 3.) scarcely evolved over time compared to German house/techno regarding the recording studio features. These findings are in agreement with documented statements and thus provide an audio-based perspective on why techno became a mass phenomenon in Germany but remained a fringe phenomenon in the USA. Observations like these can help the music industry estimate whether new trends will experience a breakthrough or disappear.

</details>


### [17] [Defense Against Synthetic Speech: Real-Time Detection of RVC Voice Conversion Attacks](https://arxiv.org/abs/2601.04227)
*Prajwal Chinchmalatpure,Suyash Chinchmalatpure,Siddharth Chavan*

Main category: cs.SD

TL;DR: 该研究提出了一种实时检测AI生成语音（特别是基于检索的语音转换RVC）的系统，通过将音频分割为1秒片段，提取时频和倒谱特征，训练监督机器学习模型进行分类，并在嘈杂背景条件下验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 生成式音频技术（如语音克隆和实时语音转换）带来了冒充、欺诈和虚假信息传播的风险，特别是在电话和视频通话等通信渠道中。需要开发能够实时检测AI生成语音的系统来应对这些安全威胁。

Method: 将检测任务构建为流式分类：1）将音频分割为1秒片段；2）提取时频和倒谱特征；3）训练监督机器学习模型对每个片段进行真假分类；4）在DEEP-VOICE数据集上评估，该数据集包含真实和语音转换的样本；5）模拟真实条件：对孤立人声进行深度伪造生成，然后重新加入背景环境音以抑制简单伪影并强调转换特定线索。

Result: 实验结果表明，短窗口声学特征能够可靠地捕捉与RVC语音相关的判别模式，即使在嘈杂背景条件下也有效。该系统支持低延迟推理，可实现片段级决策和通话级聚合。

Conclusion: 研究证明了实用、实时的深度伪造语音检测的可行性，并强调了在真实音频混合条件下进行评估对于稳健部署的重要性。短窗口声学特征能够有效区分真实语音和RVC生成的语音。

Abstract: Generative audio technologies now enable highly realistic voice cloning and real-time voice conversion, increasing the risk of impersonation, fraud, and misinformation in communication channels such as phone and video calls. This study investigates real-time detection of AI-generated speech produced using Retrieval-based Voice Conversion (RVC), evaluated on the DEEP-VOICE dataset, which includes authentic and voice-converted speech samples from multiple well-known speakers. To simulate realistic conditions, deepfake generation is applied to isolated vocal components, followed by the reintroduction of background ambiance to suppress trivial artifacts and emphasize conversion-specific cues. We frame detection as a streaming classification task by dividing audio into one-second segments, extracting time-frequency and cepstral features, and training supervised machine learning models to classify each segment as real or voice-converted. The proposed system enables low-latency inference, supporting both segment-level decisions and call-level aggregation. Experimental results show that short-window acoustic features can reliably capture discriminative patterns associated with RVC speech, even in noisy backgrounds. These findings demonstrate the feasibility of practical, real-time deepfake speech detection and underscore the importance of evaluating under realistic audio mixing conditions for robust deployment.

</details>


### [18] [LEMAS: Large A 150K-Hour Large-scale Extensible Multilingual Audio Suite with Generative Speech Models](https://arxiv.org/abs/2601.04233)
*Zhiyuan Zhao,Lijian Lin,Ye Zhu,Kai Xie,Yunfei Liu,Yu Li*

Main category: cs.SD

TL;DR: LEMAS-Dataset是目前最大的开源多语言语音语料库，包含词级时间戳，覆盖10种主要语言超过15万小时。基于该数据集训练了两个基准模型：非自回归的LEMAS-TTS实现零样本多语言合成，自回归的LEMAS-Edit实现无缝语音编辑。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、高质量、带词级时间戳的多语言语音数据集，这限制了提示式语音生成系统的发展。需要构建一个能够支持多种生成范式的丰富语料库。

Method: 构建了高效的数据处理流水线来创建LEMAS-Dataset。训练了两个不同架构的基准模型：1) LEMAS-TTS：基于非自回归流匹配框架，采用口音对抗训练和CTC损失缓解跨语言口音问题；2) LEMAS-Edit：采用自回归解码器架构，将语音编辑建模为掩码标记填充任务，利用词级对齐构建训练掩码并采用自适应解码策略。

Result: 实验结果表明，基于LEMAS-Dataset训练的模型能够提供高质量的合成和编辑性能，验证了数据集的质量。LEMAS-TTS实现了鲁棒的零样本多语言合成，LEMAS-Edit实现了无缝、平滑边界的语音编辑。

Conclusion: LEMAS-Dataset作为一个丰富的时间戳标注、细粒度的多语言语料库，将推动未来基于提示的语音生成系统的发展。数据集的高质量和多样性使其能够支持不同的生成范式。

Abstract: We present the LEMAS-Dataset, which, to our knowledge, is currently the largest open-source multilingual speech corpus with word-level timestamps. Covering over 150,000 hours across 10 major languages, LEMAS-Dataset is constructed via a efficient data processing pipeline that ensures high-quality data and annotations. To validate the effectiveness of LEMAS-Dataset across diverse generative paradigms, we train two benchmark models with distinct architectures and task specializations on this dataset. LEMAS-TTS, built upon a non-autoregressive flow-matching framework, leverages the dataset's massive scale and linguistic diversity to achieve robust zero-shot multilingual synthesis. Our proposed accent-adversarial training and CTC loss mitigate cross-lingual accent issues, enhancing synthesis stability. Complementarily, LEMAS-Edit employs an autoregressive decoder-only architecture that formulates speech editing as a masked token infilling task. By exploiting precise word-level alignments to construct training masks and adopting adaptive decoding strategies, it achieves seamless, smooth-boundary speech editing with natural transitions. Experimental results demonstrate that models trained on LEMAS-Dataset deliver high-quality synthesis and editing performance, confirming the dataset's quality. We envision that this richly timestamp-annotated, fine-grained multilingual corpus will drive future advances in prompt-based speech generation systems.

</details>


### [19] [SmoothSync: Dual-Stream Diffusion Transformers for Jitter-Robust Beat-Synchronized Gesture Generation from Quantized Audio](https://arxiv.org/abs/2601.04236)
*Yujiao Jiang,Qingmin Liao,Zongqing Lu*

Main category: cs.SD

TL;DR: SmoothSync是一个用于语音同步手势生成的新框架，采用双流扩散Transformer架构，通过音频量化token实现更好的同步性、平滑性和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有语音手势生成方法存在节奏不一致、运动抖动、脚部滑动和多采样多样性有限等问题，需要更好的解决方案。

Method: 提出SmoothSync框架：1) 通过互补的transformer流融合音频-运动特征实现更好的同步；2) 引入抖动抑制损失提高时间平滑性；3) 使用概率音频量化从相同输入生成不同的手势序列；4) 提出Smooth-BC指标可靠评估抖动下的节拍同步。

Result: 在BEAT2和SHOW数据集上，SmoothSync在FGD指标上优于SOTA方法30.6%，Smooth-BC提高10.3%，多样性提高8.4%，抖动减少62.9%，脚部滑动减少17.1%。

Conclusion: SmoothSync通过创新的双流扩散Transformer架构和抖动抑制技术，显著提升了语音手势生成的同步性、平滑性和多样性，为未来研究提供了有力工具。

Abstract: Co-speech gesture generation is a critical area of research aimed at synthesizing speech-synchronized human-like gestures. Existing methods often suffer from issues such as rhythmic inconsistency, motion jitter, foot sliding and limited multi-sampling diversity. In this paper, we present SmoothSync, a novel framework that leverages quantized audio tokens in a novel dual-stream Diffusion Transformer (DiT) architecture to synthesis holistic gestures and enhance sampling variation. Specifically, we (1) fuse audio-motion features via complementary transformer streams to achieve superior synchronization, (2) introduce a jitter-suppression loss to improve temporal smoothness, (3) implement probabilistic audio quantization to generate distinct gesture sequences from identical inputs. To reliably evaluate beat synchronization under jitter, we introduce Smooth-BC, a robust variant of the beat consistency metric less sensitive to motion noise. Comprehensive experiments on the BEAT2 and SHOW datasets demonstrate SmoothSync's superiority, outperforming state-of-the-art methods by -30.6% FGD, 10.3% Smooth-BC, and 8.4% Diversity on BEAT2, while reducing jitter and foot sliding by -62.9% and -17.1% respectively. The code will be released to facilitate future research.

</details>


### [20] [Summary of The Inaugural Music Source Restoration Challenge](https://arxiv.org/abs/2601.04343)
*Yongyi Zang,Jiarui Hai,Wanying Ge,Qiuqiang Kong,Zheqi Dai,Helin Wang,Yuki Mitsufuji,Mark D. Plumbley*

Main category: cs.SD

TL;DR: 首届音乐源修复挑战赛：通过客观和主观评估，研究从专业混音和降质音频中恢复原始乐器音轨的方法，获胜系统在多项指标上显著优于其他参赛系统。


<details>
  <summary>Details</summary>
Motivation: 音乐源修复（MSR）旨在从经过专业混音和实际降质的音频中恢复原始、未经处理的乐器音轨，这需要同时逆转制作效果和现实世界的降质影响。目前缺乏系统性的评估框架和基准。

Method: 举办首届MSR挑战赛，采用客观评估（Multi-Mel-SNR、Zimtohrli、FAD-CLAP）对工作室制作的混音进行评估，同时对真实世界降质录音进行主观评估。五个团队参与挑战，提供数据集、评估协议和基线系统。

Result: 获胜系统获得4.46 dB Multi-Mel-SNR和3.47 MOS-Overall，分别比第二名系统相对提升91%和18%。不同乐器的修复难度差异显著：贝斯平均4.59 dB，而打击乐仅0.29 dB。

Conclusion: MSR挑战赛成功建立了音乐源修复的评估框架，展示了当前技术的性能水平，揭示了不同乐器修复难度的显著差异，为未来研究提供了基准和方向。

Abstract: Music Source Restoration (MSR) aims to recover original, unprocessed instrument stems from professionally mixed and degraded audio, requiring the reversal of both production effects and real-world degradations. We present the inaugural MSR Challenge, which features objective evaluation on studio-produced mixtures using Multi-Mel-SNR, Zimtohrli, and FAD-CLAP, alongside subjective evaluation on real-world degraded recordings. Five teams participated in the challenge. The winning system achieved 4.46 dB Multi-Mel-SNR and 3.47 MOS-Overall, corresponding to relative improvements of 91% and 18% over the second-place system, respectively. Per-stem analysis reveals substantial variation in restoration difficulty across instruments, with bass averaging 4.59 dB across all teams, while percussion averages only 0.29 dB. The dataset, evaluation protocols, and baselines are available at https://msrchallenge.com/.

</details>


### [21] [When Tone and Words Disagree: Towards Robust Speech Emotion Recognition under Acoustic-Semantic Conflict](https://arxiv.org/abs/2601.04564)
*Dawei Huang,Yongjie Lv,Ruijie Xiong,Chunxiang Jin,Xiaojiang Peng*

Main category: cs.SD

TL;DR: 提出FAS框架解决语音情感识别中声学-语义冲突问题，在CASE数据集上达到59.38%准确率


<details>
  <summary>Details</summary>
Motivation: 现有语音情感识别系统假设声学情感与词汇语义一致，但现实场景中声学-语义冲突很常见（语调情感与字面意义矛盾），现有模型因此性能下降

Method: 提出Fusion Acoustic-Semantic (FAS)框架，显式解耦声学和语义路径，通过轻量级基于查询的注意力模块连接两者

Result: FAS在域内和零样本设置中均优于现有方法，在CASE基准测试中达到59.38%准确率，而传统模型表现很差

Conclusion: 声学-语义冲突是语音情感识别的重要挑战，FAS框架通过解耦和融合机制有效解决这一问题，在冲突场景中显著提升性能

Abstract: Speech Emotion Recognition (SER) systems often assume congruence between vocal emotion and lexical semantics. However, in real-world interactions, acoustic-semantic conflict is common yet overlooked, where the emotion conveyed by tone contradicts the literal meaning of spoken words. We show that state-of-the-art SER models, including ASR-based, self-supervised learning (SSL) approaches and Audio Language Models (ALMs), suffer performance degradation under such conflicts due to semantic bias or entangled acoustic-semantic representations. To address this, we propose the Fusion Acoustic-Semantic (FAS) framework, which explicitly disentangles acoustic and semantic pathways and bridges them through a lightweight, query-based attention module. To enable systematic evaluation, we introduce the Conflict in Acoustic-Semantic Emotion (CASE), the first dataset dominated by clear and interpretable acoustic-semantic conflicts in varied scenarios. Extensive experiments demonstrate that FAS consistently outperforms existing methods in both in-domain and zero-shot settings. Notably, on the CASE benchmark, conventional SER models fail dramatically, while FAS sets a new SOTA with 59.38% accuracy. Our code and datasets is available at https://github.com/24DavidHuang/FAS.

</details>


### [22] [FlexiVoice: Enabling Flexible Style Control in Zero-Shot TTS with Natural Language Instructions](https://arxiv.org/abs/2601.04656)
*Dekun Chen,Xueyao Zhang,Yuancheng Wang,Kenan Dai,Li Ma,Zhizheng Wu*

Main category: cs.SD

TL;DR: FlexiVoice是一个基于LLM核心的TTS系统，支持通过自然语言指令控制说话风格，并通过语音参考实现零样本音色克隆，采用渐进式后训练方案实现精确灵活的控制。


<details>
  <summary>Details</summary>
Motivation: 现有TTS系统在同时控制说话风格和音色方面存在局限，特别是需要零样本语音克隆和自然语言指令控制时。FlexiVoice旨在解决这一问题，实现灵活的风格控制和音色克隆。

Method: 1. 基于LLM核心构建TTS系统，输入文本、可选自然语言指令和语音参考；2. 提出渐进式后训练方案：首先使用DPO使系统能同时准确跟随指令和语音参考，然后使用多目标GRPO解耦风格指令、参考音色和文本内容，最后使用指令GRPO增强指令跟随能力。

Result: 实验结果表明FlexiVoice超越竞争基线，在解耦控制因素方面表现出强大能力。人类评估进一步证实了其自然度、可控性和鲁棒性。

Conclusion: FlexiVoice成功实现了灵活的风格控制和零样本音色克隆，通过渐进式后训练方案有效解耦了不同控制因素，为TTS系统提供了更精确和灵活的控制能力。

Abstract: This study proposes FlexiVoice, a text-to-speech (TTS) synthesis system capable of flexible style control with zero-shot voice cloning. The speaking style is controlled by a natural-language instruction and the voice timbre is provided by a speech reference in zero-shot manner. FlexiVoice is built with an LLM core, which takes text as input, and also takes an optional natural language instruction and an optional speech reference to control style and timbre, respectively. FlexiVoice is equipped with a novel Progressive Post-Training (PPT) scheme that progressively unlocks accurate and flexible controllability. In particular, it first employs Direct Preference Optimization (DPO) to enable FlexiVoice to accurately follow both natural language instruction and speech reference simultaneously. It then uses a multi-objective Group Relative Policy Optimization (GRPO) to disentangle style instruction, reference timbre, and textual content. Finally, it adapts instruction GRPO for more advanced instruction following. Experimental results show that FlexiVoice surpasses competing baselines and demonstrates strong capability in decoupling control factors. Human evaluations further confirm its naturalness, controllability, and robustness. Audio samples are available at https://flexi-voice.github.io.

</details>


### [23] [LAMB: LLM-based Audio Captioning with Modality Gap Bridging via Cauchy-Schwarz Divergence](https://arxiv.org/abs/2601.04658)
*Hyeongkeun Lee,Jongmin Choi,KiHyun Nam,Joon Son Chung*

Main category: cs.SD

TL;DR: LAMB：基于LLM的音频描述框架，通过跨模态对齐和双流适配器解决音频特征与LLM文本嵌入空间的模态鸿沟，提升LLM解码器的推理能力，在AudioCaps上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将音频特征投影到LLM嵌入空间时未考虑跨模态对齐，无法充分利用LLM的推理能力。需要弥合音频嵌入与LLM文本嵌入空间之间的模态鸿沟。

Method: 1. 跨模态对齐器：最小化Cauchy-Schwarz散度同时最大化互信息，实现音频与文本在全局和token级别的紧密对齐；2. 双流适配器：提取语义丰富的音频嵌入；3. Token引导器：在LLM文本嵌入空间中直接计算分数来引导生成描述的对数概率。

Result: 实验证实该框架增强了LLM解码器的推理能力，在AudioCaps数据集上实现了最先进的性能。

Conclusion: LAMB通过有效的跨模态对齐机制成功弥合了音频与文本的模态鸿沟，充分利用了LLM的推理能力，为音频描述任务提供了有效的解决方案。

Abstract: Automated Audio Captioning aims to describe the semantic content of input audio. Recent works have employed large language models (LLMs) as a text decoder to leverage their reasoning capabilities. However, prior approaches that project audio features into the LLM embedding space without considering cross-modal alignment fail to fully utilize these capabilities. To address this, we propose LAMB, an LLM-based audio captioning framework that bridges the modality gap between audio embeddings and the LLM text embedding space. LAMB incorporates a Cross-Modal Aligner that minimizes Cauchy-Schwarz divergence while maximizing mutual information, yielding tighter alignment between audio and text at both global and token levels. We further design a Two-Stream Adapter that extracts semantically enriched audio embeddings, thereby delivering richer information to the Cross-Modal Aligner. Finally, leveraging the aligned audio embeddings, a proposed Token Guide directly computes scores within the LLM text embedding space to steer the output logits of generated captions. Experimental results confirm that our framework strengthens the reasoning capabilities of the LLM decoder, achieving state-of-the-art performance on AudioCaps.

</details>


### [24] [Semi-Supervised Diseased Detection from Speech Dialogues with Multi-Level Data Modeling](https://arxiv.org/abs/2601.04744)
*Xingyuan Li,Mengyue Wu*

Main category: cs.SD

TL;DR: 提出一个新颖的音频半监督学习框架，通过联合学习帧级、片段级和会话级表示来检测医疗状况，在数据稀缺情况下实现高效学习


<details>
  <summary>Details</summary>
Motivation: 医疗语音分析面临弱监督学习挑战：单个会话级标签需要关联到长音频中的细微模式，同时面临数据稀缺和临床标注主观性问题。现有方法未能解决病理特征在患者语音中不均匀表达的核心问题

Method: 提出音频半监督学习框架，联合学习未分割临床对话中的帧级、片段级和会话级表示，动态聚合多粒度特征并生成高质量伪标签来有效利用未标注数据

Result: 框架具有模型无关性，跨语言和病症表现稳健，数据效率高——仅用11个标注样本就能达到完全监督性能的90%

Conclusion: 为医疗语音分析中的弱监督、远距离监督学习提供了原则性方法，解决了病理特征在语音中不均匀表达的核心挑战

Abstract: Detecting medical conditions from speech acoustics is fundamentally a weakly-supervised learning problem: a single, often noisy, session-level label must be linked to nuanced patterns within a long, complex audio recording. This task is further hampered by severe data scarcity and the subjective nature of clinical annotations. While semi-supervised learning (SSL) offers a viable path to leverage unlabeled data, existing audio methods often fail to address the core challenge that pathological traits are not uniformly expressed in a patient's speech. We propose a novel, audio-only SSL framework that explicitly models this hierarchy by jointly learning from frame-level, segment-level, and session-level representations within unsegmented clinical dialogues. Our end-to-end approach dynamically aggregates these multi-granularity features and generates high-quality pseudo-labels to efficiently utilize unlabeled data. Extensive experiments show the framework is model-agnostic, robust across languages and conditions, and highly data-efficient-achieving, for instance, 90\% of fully-supervised performance using only 11 labeled samples. This work provides a principled approach to learning from weak, far-end supervision in medical speech analysis.

</details>


### [25] [ChronosAudio: A Comprehensive Long-Audio Benchmark for Evaluating Audio-Large Language Models](https://arxiv.org/abs/2601.04876)
*Kaiwen Luo,Liang Lin,Yibo Zhang,Moayad Aloqaily,Dexian Wang,Zhenhong Zhou,Junwei Zhang,Kun Wang,Li Sun,Qingsong Wen*

Main category: cs.SD

TL;DR: ChronosAudio是首个针对音频大语言模型的长音频理解多任务基准，包含6大类任务、36,000个测试实例（总计200+小时音频），揭示了ALLMs在长上下文中的严重性能退化问题。


<details>
  <summary>Details</summary>
Motivation: 现有音频基准主要关注短片段，缺乏评估音频大语言模型长音频理解能力的共识标准，需要专门针对长音频的评估基准。

Method: 提出ChronosAudio基准，包含6大任务类别，将音频分为短、中、长三类以评估长度泛化能力，在16个最先进模型上进行广泛实验。

Result: 发现三个关键问题：1)长上下文崩溃：从短到长上下文性能下降超过90%；2)注意力结构稀释：注意力机制在后续序列中显著扩散；3)缓解策略恢复上限：当前方法只能恢复50%性能。

Conclusion: 长音频理解面临重大挑战，需要新方法实现稳健的文档级音频推理，ChronosAudio为评估和推进ALLMs的长音频能力提供了重要基准。

Abstract: Although Audio Large Language Models (ALLMs) have witnessed substantial advancements, their long audio understanding capabilities remain unexplored. A plethora of benchmarks have been proposed for general audio tasks, they predominantly focus on short-form clips, leaving without a consensus on evaluating ALLMs over extended durations. This paper proposes ChronosAudio, the first multi-task benchmark tailored for long-audio understanding in ALLMs. It encompasses six major task categories and comprises 36,000 test instances totaling over 200 hours audio, stratified into short, middle, and long-form categories to comprehensively evaluate length generalization. Extensive experiments on 16 state-of-the-art models using ChronosAudio yield three critical findings: 1.Precipitous Long-Context Collapse: ALLMs exhibit a severe inability to sustain performance, with the transition from short to long contexts triggering a staggering performance degradation of over 90% in specific tasks. 2.Structural Attention Dilution: Performance degradation stems from a fundamental failure in maintaining temporal locality; attention mechanisms suffer from significant diffusion in later sequences. 3.Restorative Ceiling of Mitigation: Current strategies only offer 50% recovery. These findings reveal significant challenges in long-audio, underscoring the urgent need for approaches to achieve robust, document-level audio reasoning.

</details>


### [26] [Leveraging Prediction Entropy for Automatic Prompt Weighting in Zero-Shot Audio-Language Classification](https://arxiv.org/abs/2601.05011)
*Karim El Khoury,Maxime Zanella,Tiffanie Godelaine,Christophe De Vleeschouwer,Benoit Macq*

Main category: cs.SD

TL;DR: 提出一种基于熵引导的提示词加权方法，通过最小化预测熵来优化提示词组合，无需额外标注数据即可提升音频分类的零样本性能


<details>
  <summary>Details</summary>
Motivation: 音频-语言模型在零样本分类中表现出色，但对文本提示词的表述非常敏感，微小变化会导致准确率大幅波动。现有方法要么需要标注数据，要么无法处理某些提示词可能对性能产生负面影响的问题

Method: 提出熵引导的提示词加权方法，通过制定专门的目标函数最小化预测熵来获得新的提示词权重，利用低熵作为高置信度的代理。该方法可应用于单个样本或批量音频样本，无需额外标签且计算开销极小

Result: 在涵盖环境、城市和声音的五种音频分类数据集上的实验表明，相比传统的提示词集成方法，在零样本设置下获得了持续的性能提升，在整个基准测试中准确率提高了5倍

Conclusion: 提出的熵引导提示词加权方法能够有效提升音频-语言模型的零样本分类性能，通过最小化预测熵来优化提示词组合，无需额外标注数据且计算效率高

Abstract: Audio-language models have recently demonstrated strong zero-shot capabilities by leveraging natural-language supervision to classify audio events without labeled training data. Yet, their performance is highly sensitive to the wording of text prompts, with small variations leading to large fluctuations in accuracy. Prior work has mitigated this issue through prompt learning or prompt ensembling. However, these strategies either require annotated data or fail to account for the fact that some prompts may negatively impact performance. In this work, we present an entropy-guided prompt weighting approach that aims to find a robust combination of prompt contributions to maximize prediction confidence. To this end, we formulate a tailored objective function that minimizes prediction entropy to yield new prompt weights, utilizing low-entropy as a proxy for high confidence. Our approach can be applied to individual samples or a batch of audio samples, requiring no additional labels and incurring negligible computational overhead. Experiments on five audio classification datasets covering environmental, urban, and vocal sounds, demonstrate consistent gains compared to classical prompt ensembling methods in a zero-shot setting, with accuracy improvements 5-times larger across the whole benchmark.

</details>

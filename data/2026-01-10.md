<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 11]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.SD](#cs.SD) [Total: 12]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Towards Radar-Agnostic Gait Analysis Across UWB and FMCW Systems](https://arxiv.org/abs/2601.04415)
*Charalambos Hadjipanayi,Maowen Yin,Alan Bannon,Ziwei Chen,Timothy G. Constandinou*

Main category: eess.SP

TL;DR: 统一处理框架可应用于不同雷达模态的步态分析，IR-UWB和FMCW雷达在相同设置下达到85-98%的估计精度，模态间差异小于4.1%，支持雷达无关的步态分析系统可行性。


<details>
  <summary>Details</summary>
Motivation: 评估统一处理框架是否能应用于不同雷达模态的步态分析，验证雷达无关处理方法的可行性，解决不同雷达模态需要特定调优的问题。

Method: 使用并置的IR-UWB和FMCW雷达，在相同处理设置下（无模态特定调优），对10名健康参与者进行重复地面行走试验。引入模态无关的自动行走段识别方法，提取临床相关时空步态参数，并与运动捕捉金标准进行比较。

Result: 两种雷达模态在所有参数上都达到85-98%的高平均估计精度，模态间差异小于4.1%，精度分布高度重叠。相关性、Bland-Altman和组内相关性分析显示最小偏差、可比较的一致性限度和与参考估计的强一致性。

Conclusion: 使用共享处理框架时，雷达模态之间没有实际意义的性能差异，支持雷达无关步态分析系统的可行性，为统一处理框架在不同雷达模态中的应用提供了实证支持。

Abstract: Radar sensing has emerged in recent years as a promising solution for unobtrusive and continuous in-home gait monitoring. This study evaluates whether a unified processing framework can be applied to radar-based spatiotemporal gait analysis independent of radar modality. The framework is validated using collocated impulse-radio ultra-wideband (IR-UWB) and frequency-modulated continuous-wave (FMCW) radars under identical processing settings, without modality-specific tuning, during repeated overground walking trials with 10 healthy participants. A modality-independent approach for automatic walking-segment identification is also introduced to ensure fair and reproducible modality performance assessment. Clinically relevant spatiotemporal gait parameters, including stride time, stride length, walking speed, swing time, and stance time, extracted from each modality were compared against gold-standard motion capture reference estimates. Across all parameters, both radar modalities achieved comparably high mean estimation accuracy in the range of 85-98%, with inter-modality differences remaining below 4.1%, resulting in highly overlapping accuracy distributions. Correlation and Bland-Altman analyses revealed minimal bias, comparable limits of agreement, and strong agreement with reference estimates, while intraclass correlation analysis demonstrated high consistency between radar modalities. These findings indicate that no practically meaningful performance differences arise from radar modality when using a shared processing framework, supporting the feasibility of radar-agnostic gait analysis systems.

</details>


### [2] [Prediction of Cellular Malignancy Using Electrical Impedance Signatures and Supervised Machine Learning](https://arxiv.org/abs/2601.04478)
*Shadeeb Hossain*

Main category: eess.SP

TL;DR: 该研究系统综述了33篇文献，收集细胞生物电参数数据，使用随机森林、支持向量机和K近邻三种机器学习算法进行健康与恶性细胞分类，随机森林达到约90%的最高准确率。


<details>
  <summary>Details</summary>
Motivation: 健康细胞与恶性细胞的生物电特性（如相对介电常数、电导率、特征时间常数）在不同频率下存在显著差异，这为诊断和分类应用提供了有前景的基础。

Method: 系统综述33篇学术文献，收集定量生物电参数数据集；实现并调优三种监督机器学习算法（随机森林、支持向量机、K近邻），使用关键超参数评估分类性能；以准确率和F1分数作为性能指标。

Result: 随机森林在最大深度为4、100个估计器配置下达到最高预测准确率约90%；KNN和SVM的F1分数分别达到约78%和76.5%。

Conclusion: 生物电特性分析与机器学习结合具有改善诊断决策的潜力；未来工作将探索加入更多判别特征、利用增强数据集、优化超参数搜索策略，以及开发嵌入式微电极和实时控制系统的硬件原型，实现原位细胞分类的实用诊断工具。

Abstract: Bioelectrical properties of cells such as relative permittivity, conductivity, and characteristic time constants vary significantly between healthy and malignant cells across different frequencies. These distinctions provide a promising foundation for diagnostic and classification applications. This study systematically reviewed 33 scholarly articles to compile datasets of quantitative bioelectric parameters and evaluated their utility in predictive modeling. Three supervised machine learning algorithms- Random Forest (RF), Support Vector Machine (SVM), and K-Nearest Neighbor (KNN) were implemented and tuned using key hyperparameters to assess classification performance. Model effectiveness was evaluated using accuracy and F1 score as performance metrics. Results demonstrate that Random Forest achieved the highest predictive accuracy of ~ 90% when configured with a maximum depth of 4 and 100 estimators. These findings highlight the potential of integrating bioelectrical property analysis with machine learning for improved diagnostic decision-making. Similarly, for KNN and SVM, the F1 score peaked at approximately 78% and 76.5%, respectively. Future work will explore incorporating additional discriminative features, leveraging stimulated datasets, and optimizing hyperparameter through advanced search strategies. Ultimately, hardware prototype with embedded micro-electrodes and real-time control systems could pave the path for practical diagnostic tools capable of in-situ cell classification.

</details>


### [3] [Invisible Walls: Privacy-Preserving ISAC Empowered by Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2601.04488)
*Yinghui He,Long Fan,Lei Xie,Dusit Niyato,Chau Yuen,Jun Luo*

Main category: eess.SP

TL;DR: PrivISAC：一种利用RIS保护用户隐私的即插即用低成本解决方案，通过在RIS行上分配两个不同的波束赋形向量并随机激活配置，既保护隐私又保持ISAC性能


<details>
  <summary>Details</summary>
Motivation: 无线信号（如CSI）携带的环境和目标信息促进了ISAC发展，但也引发了窃听导致的隐私泄露问题。现有解决方案要么未能兼顾合法通信和感知用户需求，要么依赖高复杂度高成本的硬件

Method: 为每个RIS行分配两个不同的波束赋形向量，构建有限的RIS配置集，每个时隙随机激活一个配置以引入扰动；设计两个向量使通信方向响应几乎相同保持传输稳定，感知方向响应差异明显以阻止窃听；使用时域掩蔽和解掩蔽方法让授权接收器消除配置引起的差异

Result: 在商用无线设备上实现PrivISAC，实验结果表明PrivISAC在保持高质量合法ISAC的同时提供了强大的隐私保护

Conclusion: PrivISAC是一种有效的即插即用低成本解决方案，能够保护用户隐私同时保持ISAC性能，解决了现有方法在兼顾合法用户需求和硬件成本方面的不足

Abstract: The environmental and target-related information inherently carried in wireless signals, such as channel state information (CSI), has brought increasing attention to integrated sensing and communication (ISAC). However, it also raises pressing concerns about privacy leakage through eavesdropping. While existing efforts have attempted to mitigate this issue, they either fail to account for the needs of legitimate communication and sensing users or rely on hardware with high complexity and cost. To overcome these limitations, we propose PrivISAC, a plug-and-play, low-cost solution that leverages RIS to protect user privacy while preserving ISAC performance. At the core of PrivISAC is a novel strategy in which each RIS row is assigned two distinct beamforming vectors, from which we deliberately construct a limited set of RIS configurations. During operation, exactly one configuration is randomly activated at each time slot to introduce additional perturbations, effectively masking sensitive sensing information from unauthorized eavesdroppers. To jointly ensure privacy protection and communication performance, we design the two vectors such that their responses remain nearly identical in the communication direction, thereby preserving stable, high-throughput transmission, while exhibiting pronounced differences in the sensing direction, which introduces sufficient perturbations to thwart eavesdroppers. Additionally, to enable legitimate sensing under such randomized configurations, we introduce a time-domain masking and demasking method that allows the authorized receiver to associate each CSI sample with its underlying configuration and eliminate configuration-induced discrepancies, thereby recovering valid CSI. We implement PrivISAC on commodity wireless devices and experiment results show that PrivISAC provides strong privacy protection while preserving high-quality legitimate ISAC.

</details>


### [4] [Spectral point transformer for significant wave height estimation from sea clutter](https://arxiv.org/abs/2601.04581)
*Yi Zhou,Li Wang,Hang Su,Tian Wang*

Main category: eess.SP

TL;DR: 提出SPT方法，利用Transformer从稀疏光谱点估计有效波高，仅需少数强功率点，计算效率高且特征符合物理色散关系


<details>
  <summary>Details</summary>
Motivation: 传统方法处理完整图像序列和光谱计算量大，而实际观测表明只有少数强功率光谱点对波能贡献显著，需要更高效的方法

Method: 基于Transformer的SPT方法，整合海洋表面波的几何和光谱特征，通过多维特征表示估计有效波高，仅处理稀疏光谱点

Result: SPT在有效波高回归中优于传统视觉网络，计算资源消耗显著减少，训练1080个海杂波图像序列仅需4分钟，学习特征符合物理色散关系

Conclusion: SPT方法高效准确，可降低雷达波测量系统部署成本，开源实现可用

Abstract: This paper presents a method for estimating significant wave height (Hs) from sparse S_pectral P_oint using a T_ransformer-based approach (SPT). Based on empirical observations that only a minority of spectral points with strong power contribute to wave energy, the proposed SPT effectively integrates geometric and spectral characteristics of ocean surface waves to estimate Hs through multi-dimensional feature representation. The experiment reveals an intriguing phenomenon: the learned features of SPT align well with physical dispersion relations, where the contribution-score map of selected points is concentrated along dispersion curves. Compared to conventional vision networks that process image sequences and full spectra, SPT demonstrates superior performance in Hs regression while consuming significantly fewer computational resources. On a consumer-grade GPU, SPT completes the training of regression model for 1080 sea clutter image sequences within 4 minutes, showcasing its potential to reduce deployment costs for radar wave-measuring systems. The open-source implementation of SPT will be available at https://github.com/joeyee/spt

</details>


### [5] [MIMO Beam Map Reconstruction via Toeplitz-Structured Matrix-Vector Tensor Decomposition](https://arxiv.org/abs/2601.04599)
*Hao Sun,Junting Chen,Xianghao Yu*

Main category: eess.SP

TL;DR: 提出一种基于张量分解的方法，从稀疏测量中重建MIMO波束图，通过极坐标变换揭示矩阵-向量外积结构，利用Toeplitz先验和距离衰减特性，显著提高数据效率。


<details>
  <summary>Details</summary>
Motivation: 随着无线网络向6G发展，理解定向波束覆盖的空间分布对于波束管理和链路优化至关重要。MIMO波束图能提供这种空间感知，但在稀疏测量下由于空间覆盖不完整和强角度变化，准确构建仍然困难。

Method: 将测量从笛卡尔坐标系转换到极坐标系，揭示与不同传播条件相关的矩阵-向量外积结构。数学证明矩阵因子（表示波束空间增益）由于阵列响应的平移不变性而具有内在Toeplitz结构，向量因子捕获距离相关衰减。利用这些结构先验，构建正则化张量分解问题来联合重建LOS、反射和遮挡传播条件。

Result: 仿真结果表明，该方法显著提高了数据效率，即使在稀疏采样情况下，与最先进的基线相比，归一化均方误差（NMSE）降低了超过20%。

Conclusion: 提出的张量分解方法能够有效从稀疏测量中重建MIMO波束图，通过利用波束空间增益的Toeplitz结构和距离衰减特性，为6G网络中的波束管理提供了高效解决方案。

Abstract: As wireless networks progress toward sixthgeneration (6G), understanding the spatial distribution of directional beam coverage becomes increasingly important for beam management and link optimization. Multiple-input multipleoutput (MIMO) beam map provides such spatial awareness, yet accurate construction under sparse measurements remains difficult due to incomplete spatial coverage and strong angular variations. This paper presents a tensor decomposition approach for reconstructing MIMO beam map from limited measurements. By transforming measurements from a Cartesian coordinate system into a polar coordinate system, we uncover a matrix-vector outer-product structure associated with different propagation conditions. Specifically, we mathematically demonstrate that the matrix factor, representing beam-space gain, exhibits an intrinsic Toeplitz structure due to the shift-invariant nature of array responses, and the vector factor captures distance-dependent attenuation. Leveraging these structural priors, we formulate a regularized tensor decomposition problem to jointly reconstruct line-of-sight (LOS), reflection, and obstruction propagation conditions. Simulation results confirm that the proposed method significantly enhances data efficiency, achieving a normalized mean square error (NMSE) reduction of over 20% compared to state-of-the-art baselines, even under sparse sampling regimes.

</details>


### [6] [An Ultra-Fast MLE for Low SNR Multi-Reference Alignment](https://arxiv.org/abs/2601.04831)
*Shay Kreymer,Amnon Balanov,Tamir Bendory*

Main category: eess.SP

TL;DR: 提出一种超快速算法用于特殊正交群SO(2)上的多参考对齐问题，通过低信噪比下的泰勒展开，单次遍历数据即可估计信号，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 单粒子冷冻电镜中的多参考对齐问题需要从受随机旋转影响的噪声观测中恢复信号。传统期望最大化算法在低信噪比下计算成本过高，需要更高效的替代方法。

Method: 在低信噪比条件下对对数似然进行泰勒展开，通过顺序计算观测数据的数据驱动平均值来估计信号。该方法只需单次遍历数据，无需迭代优化。

Result: 数值实验表明，该方法在低信噪比环境下能达到高精度，且能为后续的期望最大化细化提供优秀的初始化。

Conclusion: 提出的超快速算法显著降低了多参考对齐问题的计算复杂度，特别适用于低信噪比场景，为传统期望最大化算法提供了高效的替代方案和初始化策略。

Abstract: Motivated by single-particle cryo-electron microscopy, multi-reference alignment (MRA) models the task of recovering an unknown signal from multiple noisy observations corrupted by random rotations. The standard approach, expectation-maximization (EM), often becomes computationally prohibitive, particularly in low signal-to-noise ratio (SNR) settings. We introduce an alternative, ultra-fast algorithm for MRA over the special orthogonal group $\mathrm{SO}(2)$. By performing a Taylor expansion of the log-likelihood in the low-SNR regime, we estimate the signal by sequentially computing data-driven averages of observations. Our method requires only one pass over the data, dramatically reducing computational cost compared to EM. Numerical experiments show that the proposed approach achieves high accuracy in low-SNR environments and provides an excellent initialization for subsequent EM refinement.

</details>


### [7] [SE-EE Tradeoff in Pinching-Antenna Systems: Waveguide Multiplexing or Waveguide Switching?](https://arxiv.org/abs/2601.04844)
*Guangyu Zhu,Xidong Mu,Li Guo,Shibiao Xu,Yuanwei Liu,Naofal Al-Dhahir*

Main category: eess.SP

TL;DR: 研究了pinching-antenna系统（PASS）中频谱效率与能量效率的权衡，比较了波导复用（WM）和波导切换（WS）两种协议，通过多目标优化和交替优化方法分别求解，仿真显示PASS优于传统天线，WS在EE方面表现更好，WM在SE方面更优。


<details>
  <summary>Details</summary>
Motivation: 研究pinching-antenna系统（PASS）中频谱效率（SE）和能量效率（EE）之间的权衡关系，因为这两种性能指标在实际通信系统中往往存在冲突，需要找到平衡点。同时比较两种实际工作协议（WM和WS）在不同场景下的性能表现。

Method: 1. 将SE-EE权衡问题建模为多目标优化问题（MOOP），通过ε-约束方法转换为单目标问题；2. 对于WM协议：采用交替优化框架，使用逐次凸逼近优化基带波束成形，使用粒子群优化更新pinching波束成形；3. 对于WS协议：利用时分传输和无干扰特性，首先调整每个时隙的pinching波束成形以最大化服务用户信道增益，然后进行基带功率分配。

Result: 仿真结果表明：1) PASS通过减轻大尺度路径损耗优于传统天线；2) WS通过激活单个RF链实现更高的最大EE，而WM通过同时服务所有用户获得更高的SE上限；3) 增加用户数在WM下显著提升SE，而WS在低信噪比区域表现更优。

Conclusion: PASS系统在SE-EE权衡方面具有优势，WM和WS协议各有适用场景：WM适合高SE需求场景，WS适合高EE需求场景。系统设计应根据具体应用需求选择合适的协议和参数配置。

Abstract: The spectral and energy efficiency (SE-EE) trade-off in pinching-antenna systems (PASS) is investigated in this paper. In particular, two practical operating protocols, namely waveguide multiplexing (WM) and waveguide switching (WS), are considered. A multi-objective optimization problem (MOOP) is formulated to jointly optimize the baseband and pinching beamforming for maximizing the achievable SE and EE, which is then converted into a single-objective problem via the ε-constraint method. For WM, the problem is decomposed within the alternating-optimization framework, where the baseband beamforming is optimized using the successive convex approximation, and the pinching beamforming is updated through the particle swarm optimization. For WS, due to the time-division transmission and interference-free nature, the pinching beamforming in each time slot is first adjusted to maximize the served user channel gain, followed by the baseband power allocation. Simulation results demonstrate that 1) PASS outperforms conventional antennas by mitigating large-scale path losses; 2) WS leads to a higher maximum achievable EE by activating a single RF chain, whereas WM yields a higher SE upper bound by serving all users concurrently; and 3) increasing the number of users substantially enhances SE under WM, whereas WS shows more pronounced benefits in low-signal-to-noise ratio regimes.

</details>


### [8] [6D Movable Antenna Enhanced Cell-free MIMO: Two-timescale Decentralized Beamforming and Antenna Movement Optimization](https://arxiv.org/abs/2601.04969)
*Yichi Zhang,Yuchen Zhang,Wenyan Ma,Lipeng Zhu,Jianquan Wang,Wanbin Tang,Rui Zhang*

Main category: eess.SP

TL;DR: 提出一种6DMA辅助的无蜂窝MIMO系统，采用两时间尺度去中心化优化框架，在短时间尺度基于局部瞬时CSI进行波束成形，在长时间尺度基于全局统计CSI优化天线位置和阵列方向，以降低系统开销并提升可扩展性。


<details>
  <summary>Details</summary>
Motivation: 传统6DMA系统中频繁的天线移动和基于全局瞬时CSI的集中式波束成形会导致极高的信号处理延迟和系统开销，难以在信道相干时间短的高移动性场景中实际部署。需要解决这些实际实现挑战并提高系统可扩展性。

Method: 提出两时间尺度去中心化优化框架：1) 短时间尺度：每个AP基于局部瞬时CSI和全局统计CSI更新接收波束成形器；2) 长时间尺度：中央处理单元基于全局统计CSI优化所有AP的天线位置和阵列方向。为解决非凸且变量高度耦合的优化问题，开发了约束随机逐次凸逼近算法。

Result: 数值结果表明，所提出的6DMA辅助无蜂窝系统结合去中心化波束成形，显著优于灵活性较低的其他天线移动方案，甚至实现了与集中式波束成形基准相当的性能。

Conclusion: 提出的两时间尺度去中心化优化框架有效解决了6DMA辅助无蜂窝MIMO系统的实际实现挑战，在降低系统开销的同时保持了优异的通信性能，为高移动性场景下的实际部署提供了可行方案。

Abstract: This paper investigates a six-dimensional movable antenna (6DMA)-aided cell-free multi-user multiple-input multiple-output (MIMO) communication system. In this system, each distributed access point (AP) can flexibly adjust its array orientation and antenna positions to adapt to spatial channel variations and enhance communication performance. However, frequent antenna movements and centralized beamforming based on global instantaneous channel state information (CSI) sharing among APs entail extremely high signal processing delay and system overhead, which is difficult to be practically implemented in high-mobility scenarios with short channel coherence time. To address these practical implementation challenges and improve scalability, a two-timescale decentralized optimization framework is proposed in this paper to jointly design the beamformer, antenna positions, and array orientations. In the short timescale, each AP updates its receive beamformer based on local instantaneous CSI and global statistical CSI. In the long timescale, the central processing unit optimizes the antenna positions and array orientations at all APs based on global statistical CSI to maximize the ergodic sum rate of all users. The resulting optimization problem is non-convex and involves highly coupled variables, thus posing significant challenges for obtaining efficient solutions. To address this problem, a constrained stochastic successive convex approximation algorithm is developed. Numerical results demonstrate that the proposed 6DMA-aided cell-free system with decentralized beamforming significantly outperforms other antenna movement schemes with less flexibility and even achieves a performance comparable to that of the centralized beamforming benchmark.

</details>


### [9] [Ultra-Wideband Transmission Systems From an Energy Perspective: Which Band is Next?](https://arxiv.org/abs/2601.05000)
*Ronit Sohanpal,Mindaugus Jarmolovicius,Jiaqian Yang,Eric Sillekens,Romulo Aparecido,Vitaly Mikhailov,Jiawei Luo,David J. DiGiovanni,Ruben S. Luis,Hideaki Furukawa,Robert I. Killey,Polina Bayvel*

Main category: eess.SP

TL;DR: 对比OESCL-band与CL-band放大器的能效，发现1000公里OESCL-band系统能实现2.98倍吞吐量，但每比特能耗增加48%


<details>
  <summary>Details</summary>
Motivation: 研究扩展波段（OESCL-band）放大器在长距离传输中的能效表现，评估其相对于传统CL-band的实际性能优势

Method: 测量最先进的OESCL-band放大器的功率效率，比较1000公里OESCL-band系统与仅CL-band传输的性能指标

Result: 1000公里OESCL-band系统相比仅CL-band传输，吞吐量提升2.98倍，但每比特能耗增加48%

Conclusion: OESCL-band系统在长距离传输中能显著提升吞吐量，但需要接受更高的每比特能耗成本

Abstract: Measuring the power efficiency of the state-of-the-art OESCL-band amplifiers, we show that 1000 km OESCL-band systems can achieve 2.98x greater throughput for +48% higher energy-per-bit compared to CL-band transmission only.

</details>


### [10] [On the Impact of Channel Aging and Doppler-Affected Clutter on OFDM ISAC Systems](https://arxiv.org/abs/2601.05032)
*Steven Rivetti,Gabor Fodor,Emil Björnson,Mikael Skoglund*

Main category: eess.SP

TL;DR: 该论文研究了信道老化和杂波对ISAC系统的联合影响，提出了老化感知的信道估计器和低复杂度感知处理流程，在低到中等移动性场景下显著优于块衰落模型。


<details>
  <summary>Details</summary>
Motivation: 传播环境的时变特性在ISAC系统中至关重要：慢时变表现为通信链路的信道老化，快时变则与非零多普勒的结构化杂波相关。然而，这两种现象对ISAC性能的联合影响一直被忽视，本文旨在填补这一研究空白。

Method: 1) 使用具有指数相关衰减的自回归模型捕捉信道老化；2) 将杂波建模为具有非零多普勒的互不相关相干散射体集合，形成Kronecker可分离协方差结构；3) 提出老化感知信道估计器，利用历史导频观测估计时变UE信道；4) 设计低复杂度感知流程：从原始数据估计杂波统计特性，进行杂波抑制，然后通过距离-角度和距离-速度图提取目标参数。

Result: 1) 评估了帧长度和导频历史对信道估计精度的影响，在低到中等移动性场景下相比块衰落模型获得显著性能提升；2) 在杂波主导环境中实现了感知流程，证明在实际配置下可实现有效杂波抑制；3) 发现需要专用感知流，因为通信波束无法提供足够的距离分辨率。

Conclusion: 本文首次系统研究了信道老化和杂波对ISAC系统的联合影响，提出的老化感知信道估计和低复杂度感知处理方案在实际场景中表现优异，为ISAC系统设计提供了重要指导，特别是强调了专用感知流的必要性。

Abstract: The temporal evolution of the propagation environment plays a central role in integrated sensing and communication (ISAC) systems. A slow-time evolution manifests as channel aging in communication links, while a fast-time one is associated with structured clutter with non-zero Doppler. Nevertheless, the joint impact of these two phenomena on ISAC performance has been largely overlooked. This addresses this research gap in a network utilizing orthogonal frequency division multiplexing waveforms. Here, a base station simultaneously serves multiple user equipment (UE) devices and performs monostatic sensing. Channel aging is captured through an autoregressive model with exponential correlation decay. In contrast, clutter is modeled as a collection of uncorrelated, coherent patches with non-zero Doppler, resulting in a Kronecker-separable covariance structure. We propose an aging-aware channel estimator that uses prior pilot observations to estimate the time-varying UE channels, characterized by a non-isotropic multipath fading structure. The clutter's structure enables a novel low-complexity sensing pipeline: clutter statistics are estimated from raw data and subsequently used to suppress the clutter's action, after which target parameters are extracted through range-angle and range-velocity maps. We evaluate the influence of frame length and pilot history on channel estimation accuracy and demonstrate substantial performance gains over block fading in low-to-moderate mobility regimes. The sensing pipeline is implemented in a clutter-dominated environment, demonstrating that effective clutter suppression can be achieved under practical configurations. Furthermore, our results show that dedicated sensing streams are required, as communication beams provide insufficient range resolution.

</details>


### [11] [Multi-band Carrier Phase Positioning toward 6G: Performance Bounds and Efficient Estimators](https://arxiv.org/abs/2601.05178)
*Ehsan Shourezari,Ossi Kaltiokallio,Mehmet C. Ilter,Jukka Talvitie,Gonzalo Seco-Granados,Henk Wymeersch,Mikko Valkama*

Main category: eess.SP

TL;DR: 该论文研究多频段载波相位定位技术，通过聚合FR1、FR2和FR3频段解决整数模糊度问题，提出性能界限和实用估计器，显著提升定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着5G向6G演进，载波相位定位在移动网络中应用面临整数模糊度挑战。现有单频段方法精度受限，需要多频段方案来提升定位性能并应对实际网络中的时钟偏移等不完美因素。

Method: 提出多频段载波相位定位框架，支持FR1、mmWave-FR2和6G FR3频段内及跨频段载波聚合。推导多频段CPP性能界限，设计两阶段实用估计器，并扩展搜索优化步骤以支持窄带物联网应用。同时考虑基站间非均匀频段分配场景。

Result: 研究表明仅需两个载波即可显著缓解整数模糊度问题，并大幅提升定位对网络侧时钟误差和多径传播的鲁棒性。提出的估计器在所有实际带宽和发射功率条件下都能达到理论界限，特别适合窄带物联网应用。

Conclusion: 多频段载波相位定位是当前和未来移动网络中实现高精度定位的有效方案，仅需少量载波聚合即可显著提升性能。提出的估计器框架具有实际部署灵活性，支持非均匀频段分配，为5G/6G网络定位技术发展提供重要参考。

Abstract: In addition to satellite systems, carrier phase positioning (CPP) is gaining attraction also in terrestrial mobile networks, particularly in 5G New Radio evolution toward 6G. One key challenge is to resolve the integer ambiguity problem, as the carrier phase provides only relative position information. This work introduces and studies a multi-band CPP scenario with intra- and inter-band carrier aggregation (CA) opportunities across FR1, mmWave-FR2, and emerging 6G FR3 bands. Specifically, we derive multi-band CPP performance bounds, showcasing the superiority of multi-band CPP for high-precision localization in current and future mobile networks, while noting also practical imperfections such as clock offsets between the user equipment (UE) and the network as well as mutual clock imperfections between the network nodes. A wide collection of numerical results is provided, covering the impacts of the available carrier bandwidth, number of aggregated carriers, transmit power, and the number of network nodes or base stations. The offered results highlight that only two carriers suffice to substantially facilitate resolving the integer ambiguity problem while also largely enhancing the robustness of positioning against imperfections imposed by the network-side clocks and multi-path propagation. In addition, we also propose a two-stage practical estimator that achieves the derived bounds under all realistic bandwidth and transmit power conditions. Furthermore, we show that with an additional search-based refinement step, the proposed estimator becomes particularly suitable for narrowband Internet of Things applications operating efficiently even under narrow carrier bandwidths. Finally, both the derived bounds and the proposed estimators are extended to scenarios where the bands assigned to each base station are nonuniform or fully disjoint, enhancing the practical deployment flexibility.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [12] [Latent-Level Enhancement with Flow Matching for Robust Automatic Speech Recognition](https://arxiv.org/abs/2601.04459)
*Da-Hee Yang,Joon-Hyuk Chang*

Main category: eess.AS

TL;DR: 提出FM-Refiner模块，在潜在空间层面进行语音增强，作为传统波形级语音增强的补充，提升噪声鲁棒性ASR性能


<details>
  <summary>Details</summary>
Motivation: 传统波形级语音增强(SE)并不总能改善ASR性能，因为残留失真和与ASR编码器潜在空间不匹配。需要在潜在空间层面进行增强来补充现有方法。

Method: 提出Flow Matching Refinement模块(FM-Refiner)，在预训练CTC-ASR编码器的输出潜在表示上操作，训练将不完美的潜在表示映射到干净对应物，推理时作为即插即用模块使用，无需微调ASR参数。

Result: FM-Refiner能持续降低词错误率，无论是直接应用于噪声输入还是与传统SE前端结合使用，证明潜在空间精炼是现有SE方法的轻量有效补充。

Conclusion: 通过流匹配在潜在空间层面进行精炼，为鲁棒ASR提供了轻量级且有效的补充策略，可提升噪声环境下的语音识别性能。

Abstract: Noise-robust automatic speech recognition (ASR) has been commonly addressed by applying speech enhancement (SE) at the waveform level before recognition. However, speech-level enhancement does not always translate into consistent recognition improvements due to residual distortions and mismatches with the latent space of the ASR encoder. In this letter, we introduce a complementary strategy termed latent-level enhancement, where distorted representations are refined during ASR inference. Specifically, we propose a plug-and-play Flow Matching Refinement module (FM-Refiner) that operates on the output latents of a pretrained CTC-based ASR encoder. Trained to map imperfect latents-either directly from noisy inputs or from enhanced-but-imperfect speech-toward their clean counterparts, the FM-Refiner is applied only at inference, without fine-tuning ASR parameters. Experiments show that FM-Refiner consistently reduces word error rate, both when directly applied to noisy inputs and when combined with conventional SE front-ends. These results demonstrate that latent-level refinement via flow matching provides a lightweight and effective complement to existing SE approaches for robust ASR.

</details>


### [13] [LLMs-Integrated Automatic Hate Speech Recognition Using Controllable Text Generation Models](https://arxiv.org/abs/2601.04654)
*Ryutaro Oshima,Yuya Hosoda,Youji Iiguni*

Main category: eess.AS

TL;DR: 提出结合ASR编码器和LLM解码器的模型，同时进行语音转录和仇恨内容审查，通过CoT提示生成训练数据并过滤，采用课程学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨语音识别面临标注数据稀缺问题，且传统方法难以同时处理语音转录和内容审查任务，需要开发更有效的解决方案。

Method: 1) 集成ASR编码器和LLM解码器实现同步转录审查；2) 使用CoT提示技术生成文本数据，通过TTS转为语音；3) 用文本分类模型过滤数据；4) 通过阈值控制仇恨程度，采用课程学习训练。

Result: 仇恨相关词掩码准确率达到58.6%，超越先前基线方法，课程学习有效提升了转录和审查任务效率。

Conclusion: 提出的集成框架能有效处理仇恨语音识别和审查，数据生成和课程学习方法解决了标注数据稀缺问题，为实际应用提供了可行方案。

Abstract: This paper proposes an automatic speech recognition (ASR) model for hate speech using large language models (LLMs). The proposed method integrates the encoder of the ASR model with the decoder of the LLMs, enabling simultaneous transcription and censorship tasks to prevent the exposure of harmful content. Instruction tuning of the LLM to mask hate-related words with specific tokens requires an annotated hate speech dataset, which is limited. We generate text samples using an LLM with the Chain-of-Thought (CoT) prompting technique guided by cultural context and examples and then convert them into speech samples using a text-to-speech (TTS) system. However, some of them contain non-hate speech samples with hate-related words, which degrades the censorship performance. This paper filters the samples which text classification models correctly label as hate content. By adjusting the threshold for the number of correct answer models, we can control the level of hate in the generated dataset, allowing us to train the LLMs through curriculum learning in a gradual manner. Experimental results show that the proposed method achieves a masking accuracy of 58.6\% for hate-related words, surpassing previous baselines. We also confirm that the curriculum training contributes to the efficiency of both transcription and censorship tasks.

</details>


### [14] [Gradient-based Optimisation of Modulation Effects](https://arxiv.org/abs/2601.04867)
*Alistair Carson,Alec Wright,Stefan Bilbao*

Main category: eess.AS

TL;DR: 提出基于可微分数字信号处理的框架，用于建模镶边、合唱和相位效果器，实现零延迟推理


<details>
  <summary>Details</summary>
Motivation: 现有机器学习方法在模拟模拟调制效果器时存在局限性：要么只能处理一类效果，要么计算成本高、延迟大，无法与传统数字实现相比

Method: 基于可微分数字信号处理框架，在时频域训练模型，推理时在时域运行实现零延迟；采用低频加权损失函数避免学习延迟时间时陷入局部最小值

Result: 模型在模拟模拟效果器时，某些情况下输出声音与参考在感知上难以区分；但对于长延迟时间和反馈效果仍存在挑战

Conclusion: 提出的框架能够有效建模调制效果器并实现零延迟推理，但在处理复杂调制效果（如长延迟和反馈）方面仍需改进

Abstract: Modulation effects such as phasers, flangers and chorus effects are heavily used in conjunction with the electric guitar. Machine learning based emulation of analog modulation units has been investigated in recent years, but most methods have either been limited to one class of effect or suffer from a high computational cost or latency compared to canonical digital implementations. Here, we build on previous work and present a framework for modelling flanger, chorus and phaser effects based on differentiable digital signal processing. The model is trained in the time-frequency domain, but at inference operates in the time-domain, requiring zero latency. We investigate the challenges associated with gradient-based optimisation of such effects, and show that low-frequency weighting of loss functions avoids convergence to local minima when learning delay times. We show that when trained against analog effects units, sound output from the model is in some cases perceptually indistinguishable from the reference, but challenges still remain for effects with long delay times and feedback.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [15] [Predictive Controlled Music](https://arxiv.org/abs/2601.04221)
*Midhun T. Augustine*

Main category: cs.SD

TL;DR: 提出预测控制音乐（PCM）方法，将模型预测控制（MPC）与音乐生成结合，通过优化性能指标生成音乐音符


<details>
  <summary>Details</summary>
Motivation: 将控制理论中的模型预测控制方法应用于音乐生成领域，实现更结构化和优化的音乐创作过程

Method: 使用前馈神经网络评估函数作为优化目标，循环神经网络模型捕捉音符间关系作为约束，采用滚动时域方式计算音符

Result: 开发了PCM音乐生成框架，通过数值示例验证了该方法的有效性

Conclusion: PCM成功将MPC控制理论应用于音乐生成，实现了反馈控制的预测性音乐创作，为算法作曲提供了新思路

Abstract: This paper presents a new approach to algorithmic composition, called predictive controlled music (PCM), which combines model predictive control (MPC) with music generation. PCM uses dynamic models to predict and optimize the music generation process, where musical notes are computed in a manner similar to an MPC problem by optimizing a performance measure. A feedforward neural network-based assessment function is used to evaluate the generated musical score, which serves as the objective function of the PCM optimization problem. Furthermore, a recurrent neural network model is employed to capture the relationships among the variables in the musical notes, and this model is then used to define the constraints in the PCM. Similar to MPC, the proposed PCM computes musical notes in a receding-horizon manner, leading to feedback controlled prediction. Numerical examples are presented to illustrate the PCM generation method.

</details>


### [16] [From Imitation to Innovation: The Divergent Paths of Techno in Germany and the USA](https://arxiv.org/abs/2601.04222)
*Tim Ziemer,Simon Linke*

Main category: cs.SD

TL;DR: 通过音频分析验证早期house和techno音乐的发展，发现德国与美国风格存在显著差异，解释了为何techno在德国成为大众现象而在美国保持边缘地位。


<details>
  <summary>Details</summary>
Motivation: 现有关于早期house和techno音乐的纪录片和场景参与者描述缺乏音频分析验证，需要基于客观音频数据来检验这些主观叙述的准确性。

Method: 分析了超过9,000首德国和美国的早期house和techno曲目，使用录音室特征、机器学习和推断统计方法进行音频分析。

Result: 1) 德国和美国house/techno音乐风格存在明显差异；2) 美国风格内部更为相似；3) 美国风格随时间演变较少，而德国风格变化较大。这些发现与文献记载一致。

Conclusion: 音频分析验证了历史叙述，解释了techno在德国成为大众现象而在美国保持边缘地位的原因，为音乐产业预测新趋势的突破潜力提供了分析框架。

Abstract: Many documentaries on early house and techno music exist. Here, protagonists from the scenes describe key elements and events that affected the evolution of the music. In the research community, there is consensus that such descriptions have to be examined critically. Yet, there have not been attempts to validate such statements on the basis of audio analyses. In this study, over 9,000 early house and techno tracks from Germany and the United States of America are analyzed using recording studio features, machine learning and inferential statistics. Three observations can be made: 1.) German and US house/techno music are distinct, 2.) US styles are much more alike, and 3.) scarcely evolved over time compared to German house/techno regarding the recording studio features. These findings are in agreement with documented statements and thus provide an audio-based perspective on why techno became a mass phenomenon in Germany but remained a fringe phenomenon in the USA. Observations like these can help the music industry estimate whether new trends will experience a breakthrough or disappear.

</details>


### [17] [Defense Against Synthetic Speech: Real-Time Detection of RVC Voice Conversion Attacks](https://arxiv.org/abs/2601.04227)
*Prajwal Chinchmalatpure,Suyash Chinchmalatpure,Siddharth Chavan*

Main category: cs.SD

TL;DR: 该研究提出了一种实时检测AI生成语音（特别是基于检索的语音转换RVC）的系统，通过将音频分割为1秒片段并提取声学特征，在嘈杂背景条件下实现可靠检测。


<details>
  <summary>Details</summary>
Motivation: 生成式音频技术使得语音克隆和实时语音转换变得高度逼真，增加了通信渠道（如电话和视频通话）中的冒充、欺诈和错误信息风险，因此需要开发实时检测AI生成语音的方法。

Method: 将检测任务构建为流式分类：将音频分割为1秒片段，提取时频和倒谱特征，训练监督机器学习模型对每个片段进行真假分类。系统支持低延迟推理，包括片段级决策和通话级聚合。

Result: 实验结果表明，短窗口声学特征即使在嘈杂背景下也能可靠捕捉RVC语音的判别性模式，证明了实用实时深度伪造语音检测的可行性。

Conclusion: 该研究证明了在现实音频混合条件下评估的重要性，展示了实时深度伪造语音检测系统的实际可行性，为应对AI生成语音带来的安全威胁提供了有效解决方案。

Abstract: Generative audio technologies now enable highly realistic voice cloning and real-time voice conversion, increasing the risk of impersonation, fraud, and misinformation in communication channels such as phone and video calls. This study investigates real-time detection of AI-generated speech produced using Retrieval-based Voice Conversion (RVC), evaluated on the DEEP-VOICE dataset, which includes authentic and voice-converted speech samples from multiple well-known speakers. To simulate realistic conditions, deepfake generation is applied to isolated vocal components, followed by the reintroduction of background ambiance to suppress trivial artifacts and emphasize conversion-specific cues. We frame detection as a streaming classification task by dividing audio into one-second segments, extracting time-frequency and cepstral features, and training supervised machine learning models to classify each segment as real or voice-converted. The proposed system enables low-latency inference, supporting both segment-level decisions and call-level aggregation. Experimental results show that short-window acoustic features can reliably capture discriminative patterns associated with RVC speech, even in noisy backgrounds. These findings demonstrate the feasibility of practical, real-time deepfake speech detection and underscore the importance of evaluating under realistic audio mixing conditions for robust deployment.

</details>


### [18] [LEMAS: Large A 150K-Hour Large-scale Extensible Multilingual Audio Suite with Generative Speech Models](https://arxiv.org/abs/2601.04233)
*Zhiyuan Zhao,Lijian Lin,Ye Zhu,Kai Xie,Yunfei Liu,Yu Li*

Main category: cs.SD

TL;DR: LEMAS-Dataset是目前最大的开源多语言语音语料库，包含词级时间戳，覆盖10种主要语言超过15万小时数据。基于该数据集训练了两个基准模型：LEMAS-TTS用于零样本多语言合成，LEMAS-Edit用于语音编辑任务。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、高质量、带有词级时间戳的开源多语言语音数据集，这限制了基于提示的语音生成系统的发展。需要构建一个能够支持多种生成范式的数据集来推动该领域进步。

Method: 1) 构建LEMAS-Dataset：通过高效数据处理流水线创建包含10种语言超过15万小时数据、带有词级时间戳的多语言语料库。2) 训练两个基准模型：LEMAS-TTS基于非自回归流匹配框架，采用口音对抗训练和CTC损失；LEMAS-Edit基于自回归解码器架构，将语音编辑建模为掩码标记填充任务。

Result: 实验结果表明，基于LEMAS-Dataset训练的模型能够实现高质量的语音合成和编辑性能。LEMAS-TTS实现了稳健的零样本多语言合成，LEMAS-Edit实现了无缝、边界平滑的语音编辑。

Conclusion: LEMAS-Dataset作为一个丰富的时间戳注释、细粒度的多语言语料库，将推动基于提示的语音生成系统的未来发展。数据集的质量通过基准模型的优异性能得到了验证。

Abstract: We present the LEMAS-Dataset, which, to our knowledge, is currently the largest open-source multilingual speech corpus with word-level timestamps. Covering over 150,000 hours across 10 major languages, LEMAS-Dataset is constructed via a efficient data processing pipeline that ensures high-quality data and annotations. To validate the effectiveness of LEMAS-Dataset across diverse generative paradigms, we train two benchmark models with distinct architectures and task specializations on this dataset. LEMAS-TTS, built upon a non-autoregressive flow-matching framework, leverages the dataset's massive scale and linguistic diversity to achieve robust zero-shot multilingual synthesis. Our proposed accent-adversarial training and CTC loss mitigate cross-lingual accent issues, enhancing synthesis stability. Complementarily, LEMAS-Edit employs an autoregressive decoder-only architecture that formulates speech editing as a masked token infilling task. By exploiting precise word-level alignments to construct training masks and adopting adaptive decoding strategies, it achieves seamless, smooth-boundary speech editing with natural transitions. Experimental results demonstrate that models trained on LEMAS-Dataset deliver high-quality synthesis and editing performance, confirming the dataset's quality. We envision that this richly timestamp-annotated, fine-grained multilingual corpus will drive future advances in prompt-based speech generation systems.

</details>


### [19] [SmoothSync: Dual-Stream Diffusion Transformers for Jitter-Robust Beat-Synchronized Gesture Generation from Quantized Audio](https://arxiv.org/abs/2601.04236)
*Yujiao Jiang,Qingmin Liao,Zongqing Lu*

Main category: cs.SD

TL;DR: SmoothSync是一个新颖的语音同步手势生成框架，通过双流Diffusion Transformer架构和音频量化技术，解决了现有方法在节奏一致性、运动抖动、脚部滑动和采样多样性方面的限制。


<details>
  <summary>Details</summary>
Motivation: 现有语音同步手势生成方法存在节奏不一致、运动抖动、脚部滑动和多采样多样性有限等问题，需要开发更鲁棒、平滑且多样化的生成框架。

Method: 提出SmoothSync框架：1) 使用双流Diffusion Transformer架构融合音频-运动特征实现同步；2) 引入抖动抑制损失提升时间平滑性；3) 采用概率音频量化从相同输入生成不同手势序列；4) 提出Smooth-BC指标评估节奏同步性。

Result: 在BEAT2和SHOW数据集上，SmoothSync在FGD指标上优于SOTA方法30.6%，Smooth-BC提升10.3%，多样性提升8.4%，抖动减少62.9%，脚部滑动减少17.1%。

Conclusion: SmoothSync通过创新的双流Diffusion Transformer架构和抖动抑制技术，显著提升了语音同步手势生成的同步性、平滑性和多样性，为未来研究提供了可靠框架。

Abstract: Co-speech gesture generation is a critical area of research aimed at synthesizing speech-synchronized human-like gestures. Existing methods often suffer from issues such as rhythmic inconsistency, motion jitter, foot sliding and limited multi-sampling diversity. In this paper, we present SmoothSync, a novel framework that leverages quantized audio tokens in a novel dual-stream Diffusion Transformer (DiT) architecture to synthesis holistic gestures and enhance sampling variation. Specifically, we (1) fuse audio-motion features via complementary transformer streams to achieve superior synchronization, (2) introduce a jitter-suppression loss to improve temporal smoothness, (3) implement probabilistic audio quantization to generate distinct gesture sequences from identical inputs. To reliably evaluate beat synchronization under jitter, we introduce Smooth-BC, a robust variant of the beat consistency metric less sensitive to motion noise. Comprehensive experiments on the BEAT2 and SHOW datasets demonstrate SmoothSync's superiority, outperforming state-of-the-art methods by -30.6% FGD, 10.3% Smooth-BC, and 8.4% Diversity on BEAT2, while reducing jitter and foot sliding by -62.9% and -17.1% respectively. The code will be released to facilitate future research.

</details>


### [20] [Summary of The Inaugural Music Source Restoration Challenge](https://arxiv.org/abs/2601.04343)
*Yongyi Zang,Jiarui Hai,Wanying Ge,Qiuqiang Kong,Zheqi Dai,Helin Wang,Yuki Mitsufuji,Mark D. Plumbley*

Main category: cs.SD

TL;DR: 首届音乐源修复挑战赛，旨在从专业混音和降质音频中恢复原始乐器音轨，获胜系统在客观和主观评估中均表现优异，不同乐器的修复难度差异显著。


<details>
  <summary>Details</summary>
Motivation: 音乐源修复（MSR）需要同时逆转制作效果和真实世界降质，这是一个具有挑战性的任务。为了推动该领域发展，研究者们举办了首届MSR挑战赛，建立标准化的评估框架。

Method: 挑战赛采用客观评估（Multi-Mel-SNR、Zimtohrli、FAD-CLAP）和主观评估（真实世界降质录音的MOS评分）相结合的方式。共有五个团队参与，使用不同的修复系统。

Result: 获胜系统达到4.46 dB Multi-Mel-SNR和3.47 MOS-Overall，分别比第二名系统提高了91%和18%。不同乐器修复难度差异大：贝斯平均4.59 dB，而打击乐仅0.29 dB。

Conclusion: 首届MSR挑战赛成功建立了音乐源修复的评估基准，展示了当前技术的水平，并揭示了不同乐器修复难度的显著差异，为未来研究提供了重要参考。

Abstract: Music Source Restoration (MSR) aims to recover original, unprocessed instrument stems from professionally mixed and degraded audio, requiring the reversal of both production effects and real-world degradations. We present the inaugural MSR Challenge, which features objective evaluation on studio-produced mixtures using Multi-Mel-SNR, Zimtohrli, and FAD-CLAP, alongside subjective evaluation on real-world degraded recordings. Five teams participated in the challenge. The winning system achieved 4.46 dB Multi-Mel-SNR and 3.47 MOS-Overall, corresponding to relative improvements of 91% and 18% over the second-place system, respectively. Per-stem analysis reveals substantial variation in restoration difficulty across instruments, with bass averaging 4.59 dB across all teams, while percussion averages only 0.29 dB. The dataset, evaluation protocols, and baselines are available at https://msrchallenge.com/.

</details>


### [21] [When Tone and Words Disagree: Towards Robust Speech Emotion Recognition under Acoustic-Semantic Conflict](https://arxiv.org/abs/2601.04564)
*Dawei Huang,Yongjie Lv,Ruijie Xiong,Chunxiang Jin,Xiaojiang Peng*

Main category: cs.SD

TL;DR: 提出FAS框架解决语音情感识别中声学-语义冲突问题，通过解耦声学和语义路径提升模型性能，并在新数据集CASE上取得SOTA结果。


<details>
  <summary>Details</summary>
Motivation: 现实语音交互中常出现声学情感与语义内容冲突的情况，但现有SER模型假设两者一致，导致在冲突场景下性能下降。

Method: 提出Fusion Acoustic-Semantic (FAS)框架，显式解耦声学和语义路径，通过轻量级基于查询的注意力模块连接两者。

Result: FAS在领域内和零样本设置中均优于现有方法，在CASE基准测试上达到59.38%准确率，而传统SER模型表现严重失败。

Conclusion: 声学-语义冲突是SER中的重要挑战，FAS框架通过解耦表示有效解决此问题，为实际应用中的情感识别提供更鲁棒的解决方案。

Abstract: Speech Emotion Recognition (SER) systems often assume congruence between vocal emotion and lexical semantics. However, in real-world interactions, acoustic-semantic conflict is common yet overlooked, where the emotion conveyed by tone contradicts the literal meaning of spoken words. We show that state-of-the-art SER models, including ASR-based, self-supervised learning (SSL) approaches and Audio Language Models (ALMs), suffer performance degradation under such conflicts due to semantic bias or entangled acoustic-semantic representations. To address this, we propose the Fusion Acoustic-Semantic (FAS) framework, which explicitly disentangles acoustic and semantic pathways and bridges them through a lightweight, query-based attention module. To enable systematic evaluation, we introduce the Conflict in Acoustic-Semantic Emotion (CASE), the first dataset dominated by clear and interpretable acoustic-semantic conflicts in varied scenarios. Extensive experiments demonstrate that FAS consistently outperforms existing methods in both in-domain and zero-shot settings. Notably, on the CASE benchmark, conventional SER models fail dramatically, while FAS sets a new SOTA with 59.38% accuracy. Our code and datasets is available at https://github.com/24DavidHuang/FAS.

</details>


### [22] [FlexiVoice: Enabling Flexible Style Control in Zero-Shot TTS with Natural Language Instructions](https://arxiv.org/abs/2601.04656)
*Dekun Chen,Xueyao Zhang,Yuancheng Wang,Kenan Dai,Li Ma,Zhizheng Wu*

Main category: cs.SD

TL;DR: FlexiVoice是一个基于LLM的TTS系统，通过自然语言指令控制说话风格，通过语音参考实现零样本音色克隆，采用渐进式后训练方案实现精确灵活的控制。


<details>
  <summary>Details</summary>
Motivation: 现有的TTS系统在同时控制说话风格和音色方面存在局限性，特别是在零样本场景下难以准确解耦这些控制因素。需要开发一个能够通过自然语言指令灵活控制风格，同时通过语音参考实现零样本音色克隆的系统。

Method: 1. 构建基于LLM核心的TTS系统，输入文本、可选的自然语言指令和语音参考；2. 提出渐进式后训练(PPT)方案：首先使用DPO使系统能同时准确遵循自然语言指令和语音参考，然后使用多目标GRPO解耦风格指令、参考音色和文本内容，最后使用指令GRPO增强指令跟随能力。

Result: FlexiVoice超越了竞争基线，展示了强大的控制因素解耦能力。人类评估进一步证实了其自然度、可控性和鲁棒性。

Conclusion: FlexiVoice通过渐进式后训练方案成功实现了灵活的风格控制和零样本音色克隆，在解耦控制因素方面表现出色，为TTS系统的可控性提供了有效解决方案。

Abstract: This study proposes FlexiVoice, a text-to-speech (TTS) synthesis system capable of flexible style control with zero-shot voice cloning. The speaking style is controlled by a natural-language instruction and the voice timbre is provided by a speech reference in zero-shot manner. FlexiVoice is built with an LLM core, which takes text as input, and also takes an optional natural language instruction and an optional speech reference to control style and timbre, respectively. FlexiVoice is equipped with a novel Progressive Post-Training (PPT) scheme that progressively unlocks accurate and flexible controllability. In particular, it first employs Direct Preference Optimization (DPO) to enable FlexiVoice to accurately follow both natural language instruction and speech reference simultaneously. It then uses a multi-objective Group Relative Policy Optimization (GRPO) to disentangle style instruction, reference timbre, and textual content. Finally, it adapts instruction GRPO for more advanced instruction following. Experimental results show that FlexiVoice surpasses competing baselines and demonstrates strong capability in decoupling control factors. Human evaluations further confirm its naturalness, controllability, and robustness. Audio samples are available at https://flexi-voice.github.io.

</details>


### [23] [LAMB: LLM-based Audio Captioning with Modality Gap Bridging via Cauchy-Schwarz Divergence](https://arxiv.org/abs/2601.04658)
*Hyeongkeun Lee,Jongmin Choi,KiHyun Nam,Joon Son Chung*

Main category: cs.SD

TL;DR: LAMB：基于LLM的音频描述框架，通过跨模态对齐器缩小音频与文本嵌入空间差距，提升LLM推理能力，在AudioCaps上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 现有方法将音频特征投影到LLM嵌入空间时未考虑跨模态对齐，无法充分利用LLM的推理能力，需要解决音频与文本嵌入空间的模态差距问题

Method: 1. 跨模态对齐器：最小化柯西-施瓦茨散度同时最大化互信息，实现全局和token级别的音频-文本对齐；2. 双流适配器：提取语义丰富的音频嵌入；3. 令牌引导：在LLM文本嵌入空间直接计算分数来引导生成描述

Result: 实验证实框架增强了LLM解码器的推理能力，在AudioCaps数据集上实现了最先进的性能

Conclusion: LAMB通过有效的跨模态对齐机制成功缩小了音频与文本嵌入空间的差距，使LLM能够更好地利用其推理能力进行音频描述生成

Abstract: Automated Audio Captioning aims to describe the semantic content of input audio. Recent works have employed large language models (LLMs) as a text decoder to leverage their reasoning capabilities. However, prior approaches that project audio features into the LLM embedding space without considering cross-modal alignment fail to fully utilize these capabilities. To address this, we propose LAMB, an LLM-based audio captioning framework that bridges the modality gap between audio embeddings and the LLM text embedding space. LAMB incorporates a Cross-Modal Aligner that minimizes Cauchy-Schwarz divergence while maximizing mutual information, yielding tighter alignment between audio and text at both global and token levels. We further design a Two-Stream Adapter that extracts semantically enriched audio embeddings, thereby delivering richer information to the Cross-Modal Aligner. Finally, leveraging the aligned audio embeddings, a proposed Token Guide directly computes scores within the LLM text embedding space to steer the output logits of generated captions. Experimental results confirm that our framework strengthens the reasoning capabilities of the LLM decoder, achieving state-of-the-art performance on AudioCaps.

</details>


### [24] [Semi-Supervised Diseased Detection from Speech Dialogues with Multi-Level Data Modeling](https://arxiv.org/abs/2601.04744)
*Xingyuan Li,Mengyue Wu*

Main category: cs.SD

TL;DR: 提出一个新颖的音频半监督学习框架，通过联合学习帧级、段级和会话级表示来检测医疗语音中的病理特征，在数据稀缺情况下实现高效学习。


<details>
  <summary>Details</summary>
Motivation: 医疗语音检测本质上是弱监督学习问题：单个嘈杂的会话级标签需要与长音频中的细微模式关联。现有方法未能解决病理特征在患者语音中不均匀表达的核心挑战，且面临数据稀缺和临床标注主观性的问题。

Method: 提出音频专用的半监督学习框架，在未分割的临床对话中联合学习帧级、段级和会话级表示。端到端方法动态聚合多粒度特征并生成高质量伪标签，有效利用未标记数据。框架是模型无关的。

Result: 框架在跨语言和跨疾病条件下表现稳健且数据高效，例如仅使用11个标记样本就能达到完全监督性能的90%。

Conclusion: 为医疗语音分析中的弱监督学习提供了原则性方法，能有效处理远端监督和病理特征不均匀表达的问题。

Abstract: Detecting medical conditions from speech acoustics is fundamentally a weakly-supervised learning problem: a single, often noisy, session-level label must be linked to nuanced patterns within a long, complex audio recording. This task is further hampered by severe data scarcity and the subjective nature of clinical annotations. While semi-supervised learning (SSL) offers a viable path to leverage unlabeled data, existing audio methods often fail to address the core challenge that pathological traits are not uniformly expressed in a patient's speech. We propose a novel, audio-only SSL framework that explicitly models this hierarchy by jointly learning from frame-level, segment-level, and session-level representations within unsegmented clinical dialogues. Our end-to-end approach dynamically aggregates these multi-granularity features and generates high-quality pseudo-labels to efficiently utilize unlabeled data. Extensive experiments show the framework is model-agnostic, robust across languages and conditions, and highly data-efficient-achieving, for instance, 90\% of fully-supervised performance using only 11 labeled samples. This work provides a principled approach to learning from weak, far-end supervision in medical speech analysis.

</details>


### [25] [ChronosAudio: A Comprehensive Long-Audio Benchmark for Evaluating Audio-Large Language Models](https://arxiv.org/abs/2601.04876)
*Kaiwen Luo,Liang Lin,Yibo Zhang,Moayad Aloqaily,Dexian Wang,Zhenhong Zhou,Junwei Zhang,Kun Wang,Li Sun,Qingsong Wen*

Main category: cs.SD

TL;DR: ChronosAudio是首个针对音频大语言模型长音频理解的多任务基准，包含6大类任务、36,000个测试实例、超过200小时音频，揭示了现有模型在长上下文音频处理中的严重性能退化问题。


<details>
  <summary>Details</summary>
Motivation: 尽管音频大语言模型（ALLMs）取得了显著进展，但其长音频理解能力尚未得到充分探索。现有基准主要关注短音频片段，缺乏评估ALLMs在长音频场景下的共识标准。

Method: 提出ChronosAudio基准，涵盖6个主要任务类别，包含36,000个测试实例（总计超过200小时音频），按短、中、长三种时长分层，用于全面评估长度泛化能力。在16个最先进模型上进行了广泛实验。

Result: 实验发现三个关键问题：1）急剧的长上下文崩溃：从短到长上下文过渡时，特定任务性能下降超过90%；2）结构性注意力稀释：注意力机制在后续序列中显著扩散，无法维持时间局部性；3）缓解策略的恢复上限：当前策略仅能恢复50%性能。

Conclusion: 这些发现揭示了长音频处理中的重大挑战，强调了迫切需要开发能够实现稳健、文档级音频推理的新方法。

Abstract: Although Audio Large Language Models (ALLMs) have witnessed substantial advancements, their long audio understanding capabilities remain unexplored. A plethora of benchmarks have been proposed for general audio tasks, they predominantly focus on short-form clips, leaving without a consensus on evaluating ALLMs over extended durations. This paper proposes ChronosAudio, the first multi-task benchmark tailored for long-audio understanding in ALLMs. It encompasses six major task categories and comprises 36,000 test instances totaling over 200 hours audio, stratified into short, middle, and long-form categories to comprehensively evaluate length generalization. Extensive experiments on 16 state-of-the-art models using ChronosAudio yield three critical findings: 1.Precipitous Long-Context Collapse: ALLMs exhibit a severe inability to sustain performance, with the transition from short to long contexts triggering a staggering performance degradation of over 90% in specific tasks. 2.Structural Attention Dilution: Performance degradation stems from a fundamental failure in maintaining temporal locality; attention mechanisms suffer from significant diffusion in later sequences. 3.Restorative Ceiling of Mitigation: Current strategies only offer 50% recovery. These findings reveal significant challenges in long-audio, underscoring the urgent need for approaches to achieve robust, document-level audio reasoning.

</details>


### [26] [Leveraging Prediction Entropy for Automatic Prompt Weighting in Zero-Shot Audio-Language Classification](https://arxiv.org/abs/2601.05011)
*Karim El Khoury,Maxime Zanella,Tiffanie Godelaine,Christophe De Vleeschouwer,Benoit Macq*

Main category: cs.SD

TL;DR: 提出一种基于熵引导的提示词加权方法，通过最小化预测熵来优化提示词组合，无需额外标注数据即可提升音频分类的零样本性能。


<details>
  <summary>Details</summary>
Motivation: 当前音频-语言模型的零样本性能对文本提示词的措辞非常敏感，微小变化会导致准确率大幅波动。现有方法要么需要标注数据，要么无法处理某些提示词可能对性能产生负面影响的问题。

Method: 提出熵引导的提示词加权方法，通过制定专门的目标函数最小化预测熵来获得新的提示词权重，利用低熵作为高置信度的代理指标。该方法可应用于单个样本或批量音频样本。

Result: 在涵盖环境、城市和人声的五个音频分类数据集上，相比传统提示词集成方法，在零样本设置下获得了一致的性能提升，在整个基准测试中准确率提升达到5倍。

Conclusion: 该方法无需额外标注数据且计算开销极小，通过熵引导的提示词加权有效提升了音频-语言模型的零样本分类性能，解决了提示词敏感性问题。

Abstract: Audio-language models have recently demonstrated strong zero-shot capabilities by leveraging natural-language supervision to classify audio events without labeled training data. Yet, their performance is highly sensitive to the wording of text prompts, with small variations leading to large fluctuations in accuracy. Prior work has mitigated this issue through prompt learning or prompt ensembling. However, these strategies either require annotated data or fail to account for the fact that some prompts may negatively impact performance. In this work, we present an entropy-guided prompt weighting approach that aims to find a robust combination of prompt contributions to maximize prediction confidence. To this end, we formulate a tailored objective function that minimizes prediction entropy to yield new prompt weights, utilizing low-entropy as a proxy for high confidence. Our approach can be applied to individual samples or a batch of audio samples, requiring no additional labels and incurring negligible computational overhead. Experiments on five audio classification datasets covering environmental, urban, and vocal sounds, demonstrate consistent gains compared to classical prompt ensembling methods in a zero-shot setting, with accuracy improvements 5-times larger across the whole benchmark.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 11]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.SD](#cs.SD) [Total: 12]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Towards Radar-Agnostic Gait Analysis Across UWB and FMCW Systems](https://arxiv.org/abs/2601.04415)
*Charalambos Hadjipanayi,Maowen Yin,Alan Bannon,Ziwei Chen,Timothy G. Constandinou*

Main category: eess.SP

TL;DR: 该研究验证了统一处理框架可用于不同雷达模态的步态分析，IR-UWB和FMCW雷达在相同设置下均能达到85-98%的准确率，模态间差异小于4.1%，支持雷达无关的步态分析系统可行性。


<details>
  <summary>Details</summary>
Motivation: 雷达传感已成为家庭步态监测的有前景解决方案，但需要验证是否可以使用统一处理框架进行雷达时空步态分析，而不依赖于特定雷达模态。

Method: 使用并置的IR-UWB和FMCW雷达，在相同处理设置下（无模态特定调优），对10名健康参与者进行重复地面行走试验。引入模态无关的自动行走段识别方法，提取临床相关的时空步态参数，并与金标准运动捕捉参考估计进行比较。

Result: 两种雷达模态在所有参数上都实现了85-98%的高平均估计准确率，模态间差异保持在4.1%以下，准确率分布高度重叠。相关性和Bland-Altman分析显示偏差最小，一致性界限相当，与参考估计有强一致性，ICC分析显示雷达模态间高度一致。

Conclusion: 使用共享处理框架时，雷达模态之间没有实际意义的性能差异，支持雷达无关步态分析系统的可行性。

Abstract: Radar sensing has emerged in recent years as a promising solution for unobtrusive and continuous in-home gait monitoring. This study evaluates whether a unified processing framework can be applied to radar-based spatiotemporal gait analysis independent of radar modality. The framework is validated using collocated impulse-radio ultra-wideband (IR-UWB) and frequency-modulated continuous-wave (FMCW) radars under identical processing settings, without modality-specific tuning, during repeated overground walking trials with 10 healthy participants. A modality-independent approach for automatic walking-segment identification is also introduced to ensure fair and reproducible modality performance assessment. Clinically relevant spatiotemporal gait parameters, including stride time, stride length, walking speed, swing time, and stance time, extracted from each modality were compared against gold-standard motion capture reference estimates. Across all parameters, both radar modalities achieved comparably high mean estimation accuracy in the range of 85-98%, with inter-modality differences remaining below 4.1%, resulting in highly overlapping accuracy distributions. Correlation and Bland-Altman analyses revealed minimal bias, comparable limits of agreement, and strong agreement with reference estimates, while intraclass correlation analysis demonstrated high consistency between radar modalities. These findings indicate that no practically meaningful performance differences arise from radar modality when using a shared processing framework, supporting the feasibility of radar-agnostic gait analysis systems.

</details>


### [2] [Prediction of Cellular Malignancy Using Electrical Impedance Signatures and Supervised Machine Learning](https://arxiv.org/abs/2601.04478)
*Shadeeb Hossain*

Main category: eess.SP

TL;DR: 该研究系统回顾了33篇学术文章，收集细胞生物电参数数据集，并评估其在预测建模中的应用。使用随机森林、支持向量机和K近邻三种机器学习算法进行分类，随机森林在特定参数配置下达到约90%的最高准确率。


<details>
  <summary>Details</summary>
Motivation: 健康细胞和恶性细胞的生物电特性（如相对介电常数、电导率、特征时间常数）在不同频率下存在显著差异，这为诊断和分类应用提供了有前景的基础。研究旨在评估这些生物电参数在预测建模中的效用。

Method: 系统回顾33篇学术文章，收集定量生物电参数数据集。使用三种监督机器学习算法：随机森林(RF)、支持向量机(SVM)和K近邻(KNN)，通过关键超参数调优评估分类性能。使用准确率和F1分数作为性能指标。

Result: 随机森林在最大深度为4、100个估计器的配置下达到最高预测准确率约90%。KNN和SVM的F1分数分别达到约78%和76.5%。结果表明生物电特性分析与机器学习结合具有良好诊断潜力。

Conclusion: 研究证明了整合生物电特性分析与机器学习可改善诊断决策。未来工作将探索加入更多判别特征、利用刺激数据集、优化超参数搜索策略，并开发带有嵌入式微电极和实时控制系统的硬件原型，实现原位细胞分类的实用诊断工具。

Abstract: Bioelectrical properties of cells such as relative permittivity, conductivity, and characteristic time constants vary significantly between healthy and malignant cells across different frequencies. These distinctions provide a promising foundation for diagnostic and classification applications. This study systematically reviewed 33 scholarly articles to compile datasets of quantitative bioelectric parameters and evaluated their utility in predictive modeling. Three supervised machine learning algorithms- Random Forest (RF), Support Vector Machine (SVM), and K-Nearest Neighbor (KNN) were implemented and tuned using key hyperparameters to assess classification performance. Model effectiveness was evaluated using accuracy and F1 score as performance metrics. Results demonstrate that Random Forest achieved the highest predictive accuracy of ~ 90% when configured with a maximum depth of 4 and 100 estimators. These findings highlight the potential of integrating bioelectrical property analysis with machine learning for improved diagnostic decision-making. Similarly, for KNN and SVM, the F1 score peaked at approximately 78% and 76.5%, respectively. Future work will explore incorporating additional discriminative features, leveraging stimulated datasets, and optimizing hyperparameter through advanced search strategies. Ultimately, hardware prototype with embedded micro-electrodes and real-time control systems could pave the path for practical diagnostic tools capable of in-situ cell classification.

</details>


### [3] [Invisible Walls: Privacy-Preserving ISAC Empowered by Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2601.04488)
*Yinghui He,Long Fan,Lei Xie,Dusit Niyato,Chau Yuen,Jun Luo*

Main category: eess.SP

TL;DR: PrivISAC：一种利用RIS保护ISAC用户隐私的即插即用低成本方案，通过随机激活RIS配置来扰动窃听者，同时保持合法通信和感知性能。


<details>
  <summary>Details</summary>
Motivation: 无线信号中的CSI等环境信息虽然支持ISAC，但也带来隐私泄露风险。现有方案要么忽视合法用户需求，要么依赖高复杂度硬件，需要一种低成本、实用的隐私保护方案。

Method: 为RIS每行分配两个不同波束赋形向量，构建有限配置集。每个时隙随机激活一个配置，在通信方向保持稳定，在感知方向引入扰动。同时设计时域掩蔽与解掩蔽方法，让授权接收器能消除配置差异，恢复有效CSI。

Result: 在商用无线设备上实现PrivISAC，实验结果表明该方案能提供强大的隐私保护，同时保持高质量的合法ISAC性能。

Conclusion: PrivISAC成功解决了ISAC中的隐私保护问题，通过RIS的巧妙配置实现了隐私保护与系统性能的平衡，为实际部署提供了可行方案。

Abstract: The environmental and target-related information inherently carried in wireless signals, such as channel state information (CSI), has brought increasing attention to integrated sensing and communication (ISAC). However, it also raises pressing concerns about privacy leakage through eavesdropping. While existing efforts have attempted to mitigate this issue, they either fail to account for the needs of legitimate communication and sensing users or rely on hardware with high complexity and cost. To overcome these limitations, we propose PrivISAC, a plug-and-play, low-cost solution that leverages RIS to protect user privacy while preserving ISAC performance. At the core of PrivISAC is a novel strategy in which each RIS row is assigned two distinct beamforming vectors, from which we deliberately construct a limited set of RIS configurations. During operation, exactly one configuration is randomly activated at each time slot to introduce additional perturbations, effectively masking sensitive sensing information from unauthorized eavesdroppers. To jointly ensure privacy protection and communication performance, we design the two vectors such that their responses remain nearly identical in the communication direction, thereby preserving stable, high-throughput transmission, while exhibiting pronounced differences in the sensing direction, which introduces sufficient perturbations to thwart eavesdroppers. Additionally, to enable legitimate sensing under such randomized configurations, we introduce a time-domain masking and demasking method that allows the authorized receiver to associate each CSI sample with its underlying configuration and eliminate configuration-induced discrepancies, thereby recovering valid CSI. We implement PrivISAC on commodity wireless devices and experiment results show that PrivISAC provides strong privacy protection while preserving high-quality legitimate ISAC.

</details>


### [4] [Spectral point transformer for significant wave height estimation from sea clutter](https://arxiv.org/abs/2601.04581)
*Yi Zhou,Li Wang,Hang Su,Tian Wang*

Main category: eess.SP

TL;DR: 提出SPT方法，通过Transformer从稀疏谱点估计有效波高，仅使用少数强功率谱点，计算效率高且特征学习符合物理色散关系


<details>
  <summary>Details</summary>
Motivation: 传统方法处理图像序列和完整频谱计算成本高，而实际观测表明只有少数强功率谱点对波浪能量有贡献，因此需要一种高效且物理可解释的波高估计方法

Method: 基于Transformer的SPT方法，整合海洋表面波的几何和频谱特征，通过多维特征表示从稀疏谱点估计有效波高，仅选择少数强功率贡献点

Result: SPT在波高回归中表现优于传统视觉网络，计算资源消耗显著减少；在消费级GPU上，1080个海杂波图像序列的回归模型训练仅需4分钟；学习特征与物理色散关系一致，选择点的贡献分数图沿色散曲线集中

Conclusion: SPT方法通过稀疏谱点有效估计波高，计算效率高且具有物理可解释性，有望降低雷达测波系统的部署成本，已开源实现

Abstract: This paper presents a method for estimating significant wave height (Hs) from sparse S_pectral P_oint using a T_ransformer-based approach (SPT). Based on empirical observations that only a minority of spectral points with strong power contribute to wave energy, the proposed SPT effectively integrates geometric and spectral characteristics of ocean surface waves to estimate Hs through multi-dimensional feature representation. The experiment reveals an intriguing phenomenon: the learned features of SPT align well with physical dispersion relations, where the contribution-score map of selected points is concentrated along dispersion curves. Compared to conventional vision networks that process image sequences and full spectra, SPT demonstrates superior performance in Hs regression while consuming significantly fewer computational resources. On a consumer-grade GPU, SPT completes the training of regression model for 1080 sea clutter image sequences within 4 minutes, showcasing its potential to reduce deployment costs for radar wave-measuring systems. The open-source implementation of SPT will be available at https://github.com/joeyee/spt

</details>


### [5] [MIMO Beam Map Reconstruction via Toeplitz-Structured Matrix-Vector Tensor Decomposition](https://arxiv.org/abs/2601.04599)
*Hao Sun,Junting Chen,Xianghao Yu*

Main category: eess.SP

TL;DR: 提出基于张量分解的方法，从稀疏测量中重建MIMO波束图，通过极坐标变换揭示传播条件的矩阵-向量外积结构，利用Toeplitz结构先验显著提升数据效率。


<details>
  <summary>Details</summary>
Motivation: 随着无线网络向6G发展，理解定向波束覆盖的空间分布对于波束管理和链路优化至关重要。MIMO波束图能提供这种空间感知，但在稀疏测量下由于空间覆盖不完整和强角度变化，准确构建仍然困难。

Method: 将测量从笛卡尔坐标系转换到极坐标系，揭示不同传播条件下的矩阵-向量外积结构。数学证明矩阵因子（代表波束空间增益）由于阵列响应的平移不变性具有内在的Toeplitz结构，向量因子捕获距离相关的衰减。利用这些结构先验，制定正则化张量分解问题，联合重建LOS、反射和遮挡传播条件。

Result: 仿真结果表明，该方法显著提高了数据效率，即使在稀疏采样情况下，与最先进的基线相比，归一化均方误差（NMSE）降低了超过20%。

Conclusion: 提出的张量分解方法能够有效利用MIMO波束图的结构特性，从有限测量中准确重建波束覆盖，为6G网络中的波束管理和优化提供了高效解决方案。

Abstract: As wireless networks progress toward sixthgeneration (6G), understanding the spatial distribution of directional beam coverage becomes increasingly important for beam management and link optimization. Multiple-input multipleoutput (MIMO) beam map provides such spatial awareness, yet accurate construction under sparse measurements remains difficult due to incomplete spatial coverage and strong angular variations. This paper presents a tensor decomposition approach for reconstructing MIMO beam map from limited measurements. By transforming measurements from a Cartesian coordinate system into a polar coordinate system, we uncover a matrix-vector outer-product structure associated with different propagation conditions. Specifically, we mathematically demonstrate that the matrix factor, representing beam-space gain, exhibits an intrinsic Toeplitz structure due to the shift-invariant nature of array responses, and the vector factor captures distance-dependent attenuation. Leveraging these structural priors, we formulate a regularized tensor decomposition problem to jointly reconstruct line-of-sight (LOS), reflection, and obstruction propagation conditions. Simulation results confirm that the proposed method significantly enhances data efficiency, achieving a normalized mean square error (NMSE) reduction of over 20% compared to state-of-the-art baselines, even under sparse sampling regimes.

</details>


### [6] [An Ultra-Fast MLE for Low SNR Multi-Reference Alignment](https://arxiv.org/abs/2601.04831)
*Shay Kreymer,Amnon Balanov,Tamir Bendory*

Main category: eess.SP

TL;DR: 提出一种用于特殊正交群SO(2)上多参考对齐的超快速算法，通过低信噪比下的泰勒展开，单次数据遍历即可估计信号，显著降低计算成本


<details>
  <summary>Details</summary>
Motivation: 单粒子冷冻电镜中的多参考对齐问题，标准期望最大化方法在低信噪比下计算成本过高，需要更高效的算法

Method: 在低信噪比条件下对对数似然进行泰勒展开，通过顺序计算观测数据的数据驱动平均值来估计信号，只需单次数据遍历

Result: 数值实验表明该方法在低信噪比环境下实现高精度，为后续EM细化提供优秀初始化，计算成本显著低于EM

Conclusion: 提出的超快速算法为多参考对齐问题提供了高效解决方案，特别适用于低信噪比场景，可作为EM的预处理步骤

Abstract: Motivated by single-particle cryo-electron microscopy, multi-reference alignment (MRA) models the task of recovering an unknown signal from multiple noisy observations corrupted by random rotations. The standard approach, expectation-maximization (EM), often becomes computationally prohibitive, particularly in low signal-to-noise ratio (SNR) settings. We introduce an alternative, ultra-fast algorithm for MRA over the special orthogonal group $\mathrm{SO}(2)$. By performing a Taylor expansion of the log-likelihood in the low-SNR regime, we estimate the signal by sequentially computing data-driven averages of observations. Our method requires only one pass over the data, dramatically reducing computational cost compared to EM. Numerical experiments show that the proposed approach achieves high accuracy in low-SNR environments and provides an excellent initialization for subsequent EM refinement.

</details>


### [7] [SE-EE Tradeoff in Pinching-Antenna Systems: Waveguide Multiplexing or Waveguide Switching?](https://arxiv.org/abs/2601.04844)
*Guangyu Zhu,Xidong Mu,Li Guo,Shibiao Xu,Yuanwei Liu,Naofal Al-Dhahir*

Main category: eess.SP

TL;DR: 研究了pinching-antenna系统（PASS）中的频谱效率和能量效率权衡，比较了波导复用和波导切换两种协议，通过多目标优化框架分别优化基带和pinching波束成形。


<details>
  <summary>Details</summary>
Motivation: 传统天线系统在大规模路径损耗方面存在限制，需要研究新型pinching-antenna系统来同时提升频谱效率和能量效率，探索不同操作协议下的性能权衡。

Method: 采用多目标优化问题（MOOP）框架，通过ε-约束方法转化为单目标问题。对于波导复用（WM）协议，使用交替优化分解问题，基带波束成形采用逐次凸逼近优化，pinching波束成形使用粒子群优化。对于波导切换（WS）协议，由于时分传输和无干扰特性，先优化pinching波束成形最大化用户信道增益，再进行基带功率分配。

Result: 仿真结果表明：1）PASS通过减轻大规模路径损耗优于传统天线；2）WS通过激活单个RF链实现更高的最大可达EE，而WM通过同时服务所有用户实现更高的SE上限；3）增加用户数显著提升WM下的SE，而WS在低信噪比区域表现更优。

Conclusion: PASS系统在SE-EE权衡方面具有显著优势，WM和WS协议在不同场景下各有优势：WM适合高SE需求场景，WS适合高EE需求场景，为未来无线通信系统设计提供了有价值的参考。

Abstract: The spectral and energy efficiency (SE-EE) trade-off in pinching-antenna systems (PASS) is investigated in this paper. In particular, two practical operating protocols, namely waveguide multiplexing (WM) and waveguide switching (WS), are considered. A multi-objective optimization problem (MOOP) is formulated to jointly optimize the baseband and pinching beamforming for maximizing the achievable SE and EE, which is then converted into a single-objective problem via the ε-constraint method. For WM, the problem is decomposed within the alternating-optimization framework, where the baseband beamforming is optimized using the successive convex approximation, and the pinching beamforming is updated through the particle swarm optimization. For WS, due to the time-division transmission and interference-free nature, the pinching beamforming in each time slot is first adjusted to maximize the served user channel gain, followed by the baseband power allocation. Simulation results demonstrate that 1) PASS outperforms conventional antennas by mitigating large-scale path losses; 2) WS leads to a higher maximum achievable EE by activating a single RF chain, whereas WM yields a higher SE upper bound by serving all users concurrently; and 3) increasing the number of users substantially enhances SE under WM, whereas WS shows more pronounced benefits in low-signal-to-noise ratio regimes.

</details>


### [8] [6D Movable Antenna Enhanced Cell-free MIMO: Two-timescale Decentralized Beamforming and Antenna Movement Optimization](https://arxiv.org/abs/2601.04969)
*Yichi Zhang,Yuchen Zhang,Wenyan Ma,Lipeng Zhu,Jianquan Wang,Wanbin Tang,Rui Zhang*

Main category: eess.SP

TL;DR: 本文提出了一种6维可移动天线辅助的无小区MIMO系统，采用两时间尺度去中心化优化框架，在短时间尺度进行本地波束成形，在长时间尺度优化天线位置和阵列方向，以解决传统集中式方法的高延迟和开销问题。


<details>
  <summary>Details</summary>
Motivation: 传统6DMA辅助的无小区MIMO系统中，频繁的天线移动和基于全局瞬时CSI的集中式波束成形会导致极高的信号处理延迟和系统开销，难以在信道相干时间短的高移动性场景中实际部署。

Method: 提出两时间尺度去中心化优化框架：1) 短时间尺度：每个接入点基于本地瞬时CSI和全局统计CSI更新接收波束成形器；2) 长时间尺度：中央处理单元基于全局统计CSI优化所有接入点的天线位置和阵列方向，最大化所有用户的遍历和速率。为解决非凸优化问题，开发了约束随机逐次凸逼近算法。

Result: 数值结果表明，所提出的具有去中心化波束成形的6DMA辅助无小区系统显著优于灵活性较低的其他天线移动方案，甚至实现了与集中式波束成形基准相当的性能。

Conclusion: 所提出的两时间尺度去中心化优化框架有效解决了6DMA辅助无小区MIMO系统的实际部署挑战，在降低系统开销和延迟的同时保持了优异的通信性能，为高移动性场景下的实际应用提供了可行方案。

Abstract: This paper investigates a six-dimensional movable antenna (6DMA)-aided cell-free multi-user multiple-input multiple-output (MIMO) communication system. In this system, each distributed access point (AP) can flexibly adjust its array orientation and antenna positions to adapt to spatial channel variations and enhance communication performance. However, frequent antenna movements and centralized beamforming based on global instantaneous channel state information (CSI) sharing among APs entail extremely high signal processing delay and system overhead, which is difficult to be practically implemented in high-mobility scenarios with short channel coherence time. To address these practical implementation challenges and improve scalability, a two-timescale decentralized optimization framework is proposed in this paper to jointly design the beamformer, antenna positions, and array orientations. In the short timescale, each AP updates its receive beamformer based on local instantaneous CSI and global statistical CSI. In the long timescale, the central processing unit optimizes the antenna positions and array orientations at all APs based on global statistical CSI to maximize the ergodic sum rate of all users. The resulting optimization problem is non-convex and involves highly coupled variables, thus posing significant challenges for obtaining efficient solutions. To address this problem, a constrained stochastic successive convex approximation algorithm is developed. Numerical results demonstrate that the proposed 6DMA-aided cell-free system with decentralized beamforming significantly outperforms other antenna movement schemes with less flexibility and even achieves a performance comparable to that of the centralized beamforming benchmark.

</details>


### [9] [Ultra-Wideband Transmission Systems From an Energy Perspective: Which Band is Next?](https://arxiv.org/abs/2601.05000)
*Ronit Sohanpal,Mindaugus Jarmolovicius,Jiaqian Yang,Eric Sillekens,Romulo Aparecido,Vitaly Mikhailov,Jiawei Luo,David J. DiGiovanni,Ruben S. Luis,Hideaki Furukawa,Robert I. Killey,Polina Bayvel*

Main category: eess.SP

TL;DR: OESCL波段放大器比CL波段传输在1000公里距离上可实现2.98倍吞吐量，但能耗增加48%


<details>
  <summary>Details</summary>
Motivation: 评估OESCL波段放大器在长距离传输中的功率效率和性能优势，为下一代光通信系统提供参考

Method: 测量最先进OESCL波段放大器的功率效率，比较OESCL波段与CL波段在1000公里传输系统中的性能

Result: 1000公里OESCL波段系统相比纯CL波段传输，吞吐量提高2.98倍，但每比特能耗增加48%

Conclusion: OESCL波段系统在长距离传输中具有显著的吞吐量优势，但需要权衡能耗增加的问题

Abstract: Measuring the power efficiency of the state-of-the-art OESCL-band amplifiers, we show that 1000 km OESCL-band systems can achieve 2.98x greater throughput for +48% higher energy-per-bit compared to CL-band transmission only.

</details>


### [10] [On the Impact of Channel Aging and Doppler-Affected Clutter on OFDM ISAC Systems](https://arxiv.org/abs/2601.05032)
*Steven Rivetti,Gabor Fodor,Emil Björnson,Mikael Skoglund*

Main category: eess.SP

TL;DR: 该论文研究了信道老化和杂波对ISAC系统的联合影响，提出了老化感知的信道估计器和低复杂度感知流水线，在低到中等移动性场景中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多忽略了信道老化（慢时演化）和杂波（快时演化）对集成感知与通信（ISAC）系统的联合影响。信道老化导致通信链路性能下降，而具有非零多普勒的结构化杂波则影响感知性能，需要同时解决这两个问题。

Method: 1. 使用具有指数相关衰减的自回归模型建模信道老化；2. 将杂波建模为具有非零多普勒的非相关相干块集合，形成Kronecker可分离协方差结构；3. 提出老化感知信道估计器，利用先导导频观测估计时变UE信道；4. 设计低复杂度感知流水线：从原始数据估计杂波统计量，抑制杂波影响，然后通过距离-角度和距离-速度图提取目标参数。

Result: 1. 评估了帧长度和导频历史对信道估计精度的影响，在低到中等移动性场景中相比块衰落模型获得显著性能提升；2. 在杂波主导环境中实现感知流水线，证明在实际配置下可实现有效杂波抑制；3. 发现专用感知流是必需的，因为通信波束无法提供足够的距离分辨率。

Conclusion: 该研究填补了信道老化和杂波对ISAC系统联合影响的研究空白，提出的老化感知信道估计和低复杂度感知流水线在实际移动性场景中表现出色，同时强调了专用感知流对实现足够距离分辨率的重要性。

Abstract: The temporal evolution of the propagation environment plays a central role in integrated sensing and communication (ISAC) systems. A slow-time evolution manifests as channel aging in communication links, while a fast-time one is associated with structured clutter with non-zero Doppler. Nevertheless, the joint impact of these two phenomena on ISAC performance has been largely overlooked. This addresses this research gap in a network utilizing orthogonal frequency division multiplexing waveforms. Here, a base station simultaneously serves multiple user equipment (UE) devices and performs monostatic sensing. Channel aging is captured through an autoregressive model with exponential correlation decay. In contrast, clutter is modeled as a collection of uncorrelated, coherent patches with non-zero Doppler, resulting in a Kronecker-separable covariance structure. We propose an aging-aware channel estimator that uses prior pilot observations to estimate the time-varying UE channels, characterized by a non-isotropic multipath fading structure. The clutter's structure enables a novel low-complexity sensing pipeline: clutter statistics are estimated from raw data and subsequently used to suppress the clutter's action, after which target parameters are extracted through range-angle and range-velocity maps. We evaluate the influence of frame length and pilot history on channel estimation accuracy and demonstrate substantial performance gains over block fading in low-to-moderate mobility regimes. The sensing pipeline is implemented in a clutter-dominated environment, demonstrating that effective clutter suppression can be achieved under practical configurations. Furthermore, our results show that dedicated sensing streams are required, as communication beams provide insufficient range resolution.

</details>


### [11] [Multi-band Carrier Phase Positioning toward 6G: Performance Bounds and Efficient Estimators](https://arxiv.org/abs/2601.05178)
*Ehsan Shourezari,Ossi Kaltiokallio,Mehmet C. Ilter,Jukka Talvitie,Gonzalo Seco-Granados,Henk Wymeersch,Mikko Valkama*

Main category: eess.SP

TL;DR: 该论文研究多频段载波相位定位(CPP)在5G/6G移动网络中的应用，通过多频段载波聚合解决整数模糊度问题，提出性能界限和实用估计器，显著提升定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着5G向6G演进，载波相位定位在移动网络中受到关注，但面临整数模糊度问题的挑战。需要研究多频段CPP方案，利用FR1、FR2和FR3频段的载波聚合机会，解决时钟偏移等实际缺陷，实现高精度定位。

Method: 推导多频段CPP性能界限，提出两阶段实用估计器（包含搜索优化步骤），扩展到基站频段非均匀或完全分离的场景。分析可用带宽、聚合载波数量、发射功率和基站数量等参数影响。

Result: 仅需两个载波即可显著解决整数模糊度问题，增强对网络侧时钟缺陷和多径传播的鲁棒性。提出的估计器在所有实际带宽和发射功率条件下都能达到理论界限，特别适合窄带物联网应用。

Conclusion: 多频段CPP在当前和未来移动网络中具有优越的高精度定位性能，提出的估计器方案实用性强，支持灵活部署配置，为5G/6G网络定位技术发展提供重要支撑。

Abstract: In addition to satellite systems, carrier phase positioning (CPP) is gaining attraction also in terrestrial mobile networks, particularly in 5G New Radio evolution toward 6G. One key challenge is to resolve the integer ambiguity problem, as the carrier phase provides only relative position information. This work introduces and studies a multi-band CPP scenario with intra- and inter-band carrier aggregation (CA) opportunities across FR1, mmWave-FR2, and emerging 6G FR3 bands. Specifically, we derive multi-band CPP performance bounds, showcasing the superiority of multi-band CPP for high-precision localization in current and future mobile networks, while noting also practical imperfections such as clock offsets between the user equipment (UE) and the network as well as mutual clock imperfections between the network nodes. A wide collection of numerical results is provided, covering the impacts of the available carrier bandwidth, number of aggregated carriers, transmit power, and the number of network nodes or base stations. The offered results highlight that only two carriers suffice to substantially facilitate resolving the integer ambiguity problem while also largely enhancing the robustness of positioning against imperfections imposed by the network-side clocks and multi-path propagation. In addition, we also propose a two-stage practical estimator that achieves the derived bounds under all realistic bandwidth and transmit power conditions. Furthermore, we show that with an additional search-based refinement step, the proposed estimator becomes particularly suitable for narrowband Internet of Things applications operating efficiently even under narrow carrier bandwidths. Finally, both the derived bounds and the proposed estimators are extended to scenarios where the bands assigned to each base station are nonuniform or fully disjoint, enhancing the practical deployment flexibility.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [12] [Latent-Level Enhancement with Flow Matching for Robust Automatic Speech Recognition](https://arxiv.org/abs/2601.04459)
*Da-Hee Yang,Joon-Hyuk Chang*

Main category: eess.AS

TL;DR: 提出FM-Refiner模块，在ASR编码器的潜在空间进行流匹配精炼，提升噪声鲁棒性，无需微调ASR参数。


<details>
  <summary>Details</summary>
Motivation: 传统波形级语音增强（SE）在ASR中效果有限，因为残留失真和与ASR编码器潜在空间不匹配。需要在潜在空间层面进行补充增强。

Method: 提出即插即用的流匹配精炼模块（FM-Refiner），在预训练的CTC-based ASR编码器输出潜在表示上进行操作，将不完美的潜在表示映射到干净版本，仅在推理时使用。

Result: FM-Refiner能持续降低词错误率，无论是直接应用于噪声输入还是与传统SE前端结合使用。

Conclusion: 通过流匹配进行潜在级精炼为现有SE方法提供了轻量有效的补充，提升ASR的噪声鲁棒性。

Abstract: Noise-robust automatic speech recognition (ASR) has been commonly addressed by applying speech enhancement (SE) at the waveform level before recognition. However, speech-level enhancement does not always translate into consistent recognition improvements due to residual distortions and mismatches with the latent space of the ASR encoder. In this letter, we introduce a complementary strategy termed latent-level enhancement, where distorted representations are refined during ASR inference. Specifically, we propose a plug-and-play Flow Matching Refinement module (FM-Refiner) that operates on the output latents of a pretrained CTC-based ASR encoder. Trained to map imperfect latents-either directly from noisy inputs or from enhanced-but-imperfect speech-toward their clean counterparts, the FM-Refiner is applied only at inference, without fine-tuning ASR parameters. Experiments show that FM-Refiner consistently reduces word error rate, both when directly applied to noisy inputs and when combined with conventional SE front-ends. These results demonstrate that latent-level refinement via flow matching provides a lightweight and effective complement to existing SE approaches for robust ASR.

</details>


### [13] [LLMs-Integrated Automatic Hate Speech Recognition Using Controllable Text Generation Models](https://arxiv.org/abs/2601.04654)
*Ryutaro Oshima,Yuya Hosoda,Youji Iiguni*

Main category: eess.AS

TL;DR: 提出结合ASR编码器和LLM解码器的模型，用于同时进行语音转录和仇恨内容审查，通过CoT提示生成训练数据并过滤，采用课程学习提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有仇恨语音识别模型需要标注数据集，但这类数据有限。同时，传统方法难以同时处理语音转录和内容审查任务。

Method: 1) 将ASR编码器与LLM解码器集成，实现转录和审查并行处理；2) 使用CoT提示技术生成文本样本，再通过TTS转为语音；3) 用文本分类模型过滤样本，控制仇恨内容级别；4) 采用课程学习逐步训练模型。

Result: 仇恨相关词汇的掩码准确率达到58.6%，超越现有基线方法。课程学习有效提升了转录和审查任务的效率。

Conclusion: 提出的集成模型能够同时处理语音转录和仇恨内容审查，通过数据生成和过滤方法解决了标注数据不足的问题，课程学习策略进一步优化了模型性能。

Abstract: This paper proposes an automatic speech recognition (ASR) model for hate speech using large language models (LLMs). The proposed method integrates the encoder of the ASR model with the decoder of the LLMs, enabling simultaneous transcription and censorship tasks to prevent the exposure of harmful content. Instruction tuning of the LLM to mask hate-related words with specific tokens requires an annotated hate speech dataset, which is limited. We generate text samples using an LLM with the Chain-of-Thought (CoT) prompting technique guided by cultural context and examples and then convert them into speech samples using a text-to-speech (TTS) system. However, some of them contain non-hate speech samples with hate-related words, which degrades the censorship performance. This paper filters the samples which text classification models correctly label as hate content. By adjusting the threshold for the number of correct answer models, we can control the level of hate in the generated dataset, allowing us to train the LLMs through curriculum learning in a gradual manner. Experimental results show that the proposed method achieves a masking accuracy of 58.6\% for hate-related words, surpassing previous baselines. We also confirm that the curriculum training contributes to the efficiency of both transcription and censorship tasks.

</details>


### [14] [Gradient-based Optimisation of Modulation Effects](https://arxiv.org/abs/2601.04867)
*Alistair Carson,Alec Wright,Stefan Bilbao*

Main category: eess.AS

TL;DR: 基于可微分数字信号处理的吉他调制效果建模框架，可零延迟模拟镶边、合唱和移相效果


<details>
  <summary>Details</summary>
Motivation: 现有机器学习模拟调制效果的方法要么局限于单一效果类型，要么计算成本高、延迟大，需要开发更高效通用的建模框架

Method: 采用可微分数字信号处理框架，在时频域训练但在时域推理实现零延迟，通过低频加权损失函数避免延迟时间优化的局部极小值

Result: 模型在某些情况下能产生与模拟效果单元在感知上无法区分的音频输出，但对于长延迟时间和反馈效果仍存在挑战

Conclusion: 提出的框架成功实现了多种吉他调制效果的高效模拟，零延迟特性使其适合实时应用，但长延迟和反馈效果仍需进一步改进

Abstract: Modulation effects such as phasers, flangers and chorus effects are heavily used in conjunction with the electric guitar. Machine learning based emulation of analog modulation units has been investigated in recent years, but most methods have either been limited to one class of effect or suffer from a high computational cost or latency compared to canonical digital implementations. Here, we build on previous work and present a framework for modelling flanger, chorus and phaser effects based on differentiable digital signal processing. The model is trained in the time-frequency domain, but at inference operates in the time-domain, requiring zero latency. We investigate the challenges associated with gradient-based optimisation of such effects, and show that low-frequency weighting of loss functions avoids convergence to local minima when learning delay times. We show that when trained against analog effects units, sound output from the model is in some cases perceptually indistinguishable from the reference, but challenges still remain for effects with long delay times and feedback.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [15] [Predictive Controlled Music](https://arxiv.org/abs/2601.04221)
*Midhun T. Augustine*

Main category: cs.SD

TL;DR: 提出了一种结合模型预测控制与音乐生成的新方法PCM，使用神经网络评估函数和循环神经网络模型，以滚动时域方式生成音乐


<details>
  <summary>Details</summary>
Motivation: 将控制理论中的模型预测控制方法应用于算法作曲，通过优化性能指标来生成音乐，实现更智能、可控的音乐创作

Method: 结合MPC与音乐生成，使用前馈神经网络评估音乐质量作为目标函数，循环神经网络建模音符关系作为约束，采用滚动时域优化计算音符

Result: 提出了PCM框架，能够通过优化过程生成音乐，并通过数值示例验证了该方法的有效性

Conclusion: PCM为算法作曲提供了一种新的控制理论方法，实现了反馈控制的音乐预测生成，扩展了音乐生成的技术途径

Abstract: This paper presents a new approach to algorithmic composition, called predictive controlled music (PCM), which combines model predictive control (MPC) with music generation. PCM uses dynamic models to predict and optimize the music generation process, where musical notes are computed in a manner similar to an MPC problem by optimizing a performance measure. A feedforward neural network-based assessment function is used to evaluate the generated musical score, which serves as the objective function of the PCM optimization problem. Furthermore, a recurrent neural network model is employed to capture the relationships among the variables in the musical notes, and this model is then used to define the constraints in the PCM. Similar to MPC, the proposed PCM computes musical notes in a receding-horizon manner, leading to feedback controlled prediction. Numerical examples are presented to illustrate the PCM generation method.

</details>


### [16] [From Imitation to Innovation: The Divergent Paths of Techno in Germany and the USA](https://arxiv.org/abs/2601.04222)
*Tim Ziemer,Simon Linke*

Main category: cs.SD

TL;DR: 通过分析9000多首早期浩室和科技舞曲，发现德国和美国音乐在录音室特征上存在显著差异，这解释了为什么科技舞曲在德国成为大众现象而在美国保持小众


<details>
  <summary>Details</summary>
Motivation: 现有关于早期浩室和科技舞曲的纪录片和场景描述缺乏音频分析的验证，需要基于音频数据来检验这些描述的真实性

Method: 分析9000多首德国和美国的早期浩室和科技舞曲，使用录音室特征、机器学习和推断统计方法

Result: 1) 德国和美国浩室/科技舞曲在录音室特征上明显不同；2) 美国风格更加相似；3) 与美国相比，德国浩室/科技舞曲随时间演变更多

Conclusion: 音频分析结果与文献描述一致，为科技舞曲在德国成为大众现象而在美国保持小众提供了音频证据，这些观察可帮助音乐产业预测新趋势的发展

Abstract: Many documentaries on early house and techno music exist. Here, protagonists from the scenes describe key elements and events that affected the evolution of the music. In the research community, there is consensus that such descriptions have to be examined critically. Yet, there have not been attempts to validate such statements on the basis of audio analyses. In this study, over 9,000 early house and techno tracks from Germany and the United States of America are analyzed using recording studio features, machine learning and inferential statistics. Three observations can be made: 1.) German and US house/techno music are distinct, 2.) US styles are much more alike, and 3.) scarcely evolved over time compared to German house/techno regarding the recording studio features. These findings are in agreement with documented statements and thus provide an audio-based perspective on why techno became a mass phenomenon in Germany but remained a fringe phenomenon in the USA. Observations like these can help the music industry estimate whether new trends will experience a breakthrough or disappear.

</details>


### [17] [Defense Against Synthetic Speech: Real-Time Detection of RVC Voice Conversion Attacks](https://arxiv.org/abs/2601.04227)
*Prajwal Chinchmalatpure,Suyash Chinchmalatpure,Siddharth Chavan*

Main category: cs.SD

TL;DR: 该研究提出了一种实时检测AI生成语音（特别是基于检索的语音转换RVC）的系统，通过将音频分割为1秒片段，提取时频和倒谱特征，训练机器学习模型进行分类，并在嘈杂背景中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 生成式音频技术（如语音克隆和实时语音转换）带来了冒充、欺诈和虚假信息的风险，特别是在电话和视频通话中。需要开发能够在真实通信场景中实时检测AI生成语音的方法。

Method: 将检测任务框架化为流式分类：1）将音频分割为1秒片段；2）提取时间频率和倒谱特征；3）训练监督机器学习模型对每个片段进行分类（真实或语音转换）；4）在DEEP-VOICE数据集上评估，该数据集包含真实和语音转换的语音样本；5）模拟真实条件：对孤立人声进行深度伪造生成，然后重新引入背景环境以抑制简单伪影并强调转换特定线索。

Result: 实验结果表明，短窗口声学特征能够可靠地捕捉与RVC语音相关的区分性模式，即使在嘈杂背景中也能有效检测。系统支持低延迟推理，可实现片段级决策和通话级聚合。

Conclusion: 该研究证明了实用、实时的深度伪造语音检测的可行性，并强调了在真实音频混合条件下进行评估对于稳健部署的重要性。短窗口声学特征能够有效检测RVC生成的语音，为通信安全提供了技术解决方案。

Abstract: Generative audio technologies now enable highly realistic voice cloning and real-time voice conversion, increasing the risk of impersonation, fraud, and misinformation in communication channels such as phone and video calls. This study investigates real-time detection of AI-generated speech produced using Retrieval-based Voice Conversion (RVC), evaluated on the DEEP-VOICE dataset, which includes authentic and voice-converted speech samples from multiple well-known speakers. To simulate realistic conditions, deepfake generation is applied to isolated vocal components, followed by the reintroduction of background ambiance to suppress trivial artifacts and emphasize conversion-specific cues. We frame detection as a streaming classification task by dividing audio into one-second segments, extracting time-frequency and cepstral features, and training supervised machine learning models to classify each segment as real or voice-converted. The proposed system enables low-latency inference, supporting both segment-level decisions and call-level aggregation. Experimental results show that short-window acoustic features can reliably capture discriminative patterns associated with RVC speech, even in noisy backgrounds. These findings demonstrate the feasibility of practical, real-time deepfake speech detection and underscore the importance of evaluating under realistic audio mixing conditions for robust deployment.

</details>


### [18] [LEMAS: Large A 150K-Hour Large-scale Extensible Multilingual Audio Suite with Generative Speech Models](https://arxiv.org/abs/2601.04233)
*Zhiyuan Zhao,Lijian Lin,Ye Zhu,Kai Xie,Yunfei Liu,Yu Li*

Main category: cs.SD

TL;DR: LEMAS-Dataset是目前最大的开源多语言语音语料库，包含词级时间戳，覆盖10种主要语言超过15万小时。基于该数据集训练了两个基准模型：LEMAS-TTS用于零样本多语言合成，LEMAS-Edit用于语音编辑。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、高质量、带有词级时间戳的多语言语音数据集，这限制了基于提示的语音生成系统的发展。需要构建一个能够支持多样化生成范式的数据集。

Method: 1. 构建LEMAS-Dataset：通过高效数据处理流水线创建包含词级时间戳的多语言语音语料库；2. 训练LEMAS-TTS：基于非自回归流匹配框架，采用口音对抗训练和CTC损失缓解跨语言口音问题；3. 训练LEMAS-Edit：基于自回归解码器架构，将语音编辑建模为掩码标记填充任务，利用词级对齐构建训练掩码并采用自适应解码策略。

Result: 实验结果表明，基于LEMAS-Dataset训练的模型能够实现高质量的语音合成和编辑性能。LEMAS-TTS实现了鲁棒的零样本多语言合成，LEMAS-Edit实现了无缝、平滑边界的语音编辑，验证了数据集的质量。

Conclusion: LEMAS-Dataset作为一个丰富时间戳标注的细粒度多语言语料库，将推动基于提示的语音生成系统的未来发展。数据集的质量通过两个不同架构的基准模型的有效性得到了验证。

Abstract: We present the LEMAS-Dataset, which, to our knowledge, is currently the largest open-source multilingual speech corpus with word-level timestamps. Covering over 150,000 hours across 10 major languages, LEMAS-Dataset is constructed via a efficient data processing pipeline that ensures high-quality data and annotations. To validate the effectiveness of LEMAS-Dataset across diverse generative paradigms, we train two benchmark models with distinct architectures and task specializations on this dataset. LEMAS-TTS, built upon a non-autoregressive flow-matching framework, leverages the dataset's massive scale and linguistic diversity to achieve robust zero-shot multilingual synthesis. Our proposed accent-adversarial training and CTC loss mitigate cross-lingual accent issues, enhancing synthesis stability. Complementarily, LEMAS-Edit employs an autoregressive decoder-only architecture that formulates speech editing as a masked token infilling task. By exploiting precise word-level alignments to construct training masks and adopting adaptive decoding strategies, it achieves seamless, smooth-boundary speech editing with natural transitions. Experimental results demonstrate that models trained on LEMAS-Dataset deliver high-quality synthesis and editing performance, confirming the dataset's quality. We envision that this richly timestamp-annotated, fine-grained multilingual corpus will drive future advances in prompt-based speech generation systems.

</details>


### [19] [SmoothSync: Dual-Stream Diffusion Transformers for Jitter-Robust Beat-Synchronized Gesture Generation from Quantized Audio](https://arxiv.org/abs/2601.04236)
*Yujiao Jiang,Qingmin Liao,Zongqing Lu*

Main category: cs.SD

TL;DR: SmoothSync是一个新的语音同步手势生成框架，使用双流扩散Transformer架构，通过量化音频token生成更平滑、多样化的手势，解决了现有方法的节奏不一致、运动抖动和脚滑等问题。


<details>
  <summary>Details</summary>
Motivation: 现有语音同步手势生成方法存在节奏不一致、运动抖动、脚滑和采样多样性有限等问题，需要开发更高质量、更平滑、更多样化的手势生成方法。

Method: 提出SmoothSync框架：1）使用双流扩散Transformer架构融合音频-运动特征实现更好的同步；2）引入抖动抑制损失提高时间平滑性；3）采用概率音频量化从相同输入生成不同的手势序列；4）提出Smooth-BC指标更可靠地评估节奏同步性。

Result: 在BEAT2和SHOW数据集上的实验表明，SmoothSync在FGD指标上优于SOTA方法30.6%，Smooth-BC提高10.3%，多样性提高8.4%，同时抖动减少62.9%，脚滑减少17.1%。

Conclusion: SmoothSync通过创新的双流扩散Transformer架构和抖动抑制技术，显著提高了语音同步手势生成的质量、平滑性和多样性，为解决现有方法的局限性提供了有效方案。

Abstract: Co-speech gesture generation is a critical area of research aimed at synthesizing speech-synchronized human-like gestures. Existing methods often suffer from issues such as rhythmic inconsistency, motion jitter, foot sliding and limited multi-sampling diversity. In this paper, we present SmoothSync, a novel framework that leverages quantized audio tokens in a novel dual-stream Diffusion Transformer (DiT) architecture to synthesis holistic gestures and enhance sampling variation. Specifically, we (1) fuse audio-motion features via complementary transformer streams to achieve superior synchronization, (2) introduce a jitter-suppression loss to improve temporal smoothness, (3) implement probabilistic audio quantization to generate distinct gesture sequences from identical inputs. To reliably evaluate beat synchronization under jitter, we introduce Smooth-BC, a robust variant of the beat consistency metric less sensitive to motion noise. Comprehensive experiments on the BEAT2 and SHOW datasets demonstrate SmoothSync's superiority, outperforming state-of-the-art methods by -30.6% FGD, 10.3% Smooth-BC, and 8.4% Diversity on BEAT2, while reducing jitter and foot sliding by -62.9% and -17.1% respectively. The code will be released to facilitate future research.

</details>


### [20] [Summary of The Inaugural Music Source Restoration Challenge](https://arxiv.org/abs/2601.04343)
*Yongyi Zang,Jiarui Hai,Wanying Ge,Qiuqiang Kong,Zheqi Dai,Helin Wang,Yuki Mitsufuji,Mark D. Plumbley*

Main category: cs.SD

TL;DR: 首届音乐源恢复挑战赛：从专业混音和真实世界降质音频中恢复原始乐器音轨，获胜系统在客观和主观评估中均显著优于第二名。


<details>
  <summary>Details</summary>
Motivation: 音乐源恢复（MSR）旨在从经过专业混音和降质的音频中恢复原始、未经处理的乐器音轨，这需要同时逆转制作效果和真实世界的降质影响。目前缺乏标准化的评估框架和基准。

Method: 举办首届MSR挑战赛，采用客观评估（Multi-Mel-SNR、Zimtohrli、FAD-CLAP）和主观评估（MOS-Overall）相结合的方式。评估包括工作室制作的混音和真实世界降质录音。

Result: 五个团队参与挑战，获胜系统达到4.46 dB Multi-Mel-SNR和3.47 MOS-Overall，分别比第二名系统相对提升91%和18%。不同乐器的恢复难度差异显著：贝斯平均4.59 dB，而打击乐仅0.29 dB。

Conclusion: MSR挑战赛建立了首个标准化评估框架，展示了音乐源恢复任务的可行性，但不同乐器的恢复难度差异很大，为未来研究提供了基准和方向。

Abstract: Music Source Restoration (MSR) aims to recover original, unprocessed instrument stems from professionally mixed and degraded audio, requiring the reversal of both production effects and real-world degradations. We present the inaugural MSR Challenge, which features objective evaluation on studio-produced mixtures using Multi-Mel-SNR, Zimtohrli, and FAD-CLAP, alongside subjective evaluation on real-world degraded recordings. Five teams participated in the challenge. The winning system achieved 4.46 dB Multi-Mel-SNR and 3.47 MOS-Overall, corresponding to relative improvements of 91% and 18% over the second-place system, respectively. Per-stem analysis reveals substantial variation in restoration difficulty across instruments, with bass averaging 4.59 dB across all teams, while percussion averages only 0.29 dB. The dataset, evaluation protocols, and baselines are available at https://msrchallenge.com/.

</details>


### [21] [When Tone and Words Disagree: Towards Robust Speech Emotion Recognition under Acoustic-Semantic Conflict](https://arxiv.org/abs/2601.04564)
*Dawei Huang,Yongjie Lv,Ruijie Xiong,Chunxiang Jin,Xiaojiang Peng*

Main category: cs.SD

TL;DR: 提出FAS框架解决语音情感识别中声学-语义冲突问题，在CASE数据集上达到59.38%准确率


<details>
  <summary>Details</summary>
Motivation: 现有语音情感识别系统假设声学情感与语义内容一致，但现实中声学-语义冲突很常见（语调情感与字面含义矛盾），现有模型对此表现不佳

Method: 提出Fusion Acoustic-Semantic (FAS)框架，显式解耦声学和语义路径，通过轻量级基于查询的注意力模块连接两者

Result: FAS在领域内和零样本设置中均优于现有方法，在CASE基准测试中达到59.38%准确率，而传统模型表现很差

Conclusion: FAS框架有效解决了声学-语义冲突问题，在首个以声学-语义冲突为主的CASE数据集上建立了新的SOTA

Abstract: Speech Emotion Recognition (SER) systems often assume congruence between vocal emotion and lexical semantics. However, in real-world interactions, acoustic-semantic conflict is common yet overlooked, where the emotion conveyed by tone contradicts the literal meaning of spoken words. We show that state-of-the-art SER models, including ASR-based, self-supervised learning (SSL) approaches and Audio Language Models (ALMs), suffer performance degradation under such conflicts due to semantic bias or entangled acoustic-semantic representations. To address this, we propose the Fusion Acoustic-Semantic (FAS) framework, which explicitly disentangles acoustic and semantic pathways and bridges them through a lightweight, query-based attention module. To enable systematic evaluation, we introduce the Conflict in Acoustic-Semantic Emotion (CASE), the first dataset dominated by clear and interpretable acoustic-semantic conflicts in varied scenarios. Extensive experiments demonstrate that FAS consistently outperforms existing methods in both in-domain and zero-shot settings. Notably, on the CASE benchmark, conventional SER models fail dramatically, while FAS sets a new SOTA with 59.38% accuracy. Our code and datasets is available at https://github.com/24DavidHuang/FAS.

</details>


### [22] [FlexiVoice: Enabling Flexible Style Control in Zero-Shot TTS with Natural Language Instructions](https://arxiv.org/abs/2601.04656)
*Dekun Chen,Xueyao Zhang,Yuancheng Wang,Kenan Dai,Li Ma,Zhizheng Wu*

Main category: cs.SD

TL;DR: FlexiVoice是一个基于LLM核心的TTS系统，通过自然语言指令和语音参考实现零样本语音克隆和灵活风格控制，采用渐进式后训练方案提升控制精度和解耦能力。


<details>
  <summary>Details</summary>
Motivation: 现有TTS系统在零样本语音克隆和灵活风格控制方面存在局限性，需要同时控制说话风格和音色，并实现控制因素的有效解耦。

Method: 基于LLM核心构建，采用渐进式后训练方案：1) 使用DPO使系统能同时准确遵循自然语言指令和语音参考；2) 使用多目标GRPO解耦风格指令、参考音色和文本内容；3) 使用指令GRPO进行更高级的指令跟随。

Result: 实验结果表明FlexiVoice超越竞争基线，展现出强大的控制因素解耦能力。人工评估进一步证实了其自然度、可控性和鲁棒性。

Conclusion: FlexiVoice成功实现了零样本语音克隆和灵活风格控制，通过渐进式后训练方案有效提升了控制精度和解耦能力，为TTS系统提供了更强大的可控性。

Abstract: This study proposes FlexiVoice, a text-to-speech (TTS) synthesis system capable of flexible style control with zero-shot voice cloning. The speaking style is controlled by a natural-language instruction and the voice timbre is provided by a speech reference in zero-shot manner. FlexiVoice is built with an LLM core, which takes text as input, and also takes an optional natural language instruction and an optional speech reference to control style and timbre, respectively. FlexiVoice is equipped with a novel Progressive Post-Training (PPT) scheme that progressively unlocks accurate and flexible controllability. In particular, it first employs Direct Preference Optimization (DPO) to enable FlexiVoice to accurately follow both natural language instruction and speech reference simultaneously. It then uses a multi-objective Group Relative Policy Optimization (GRPO) to disentangle style instruction, reference timbre, and textual content. Finally, it adapts instruction GRPO for more advanced instruction following. Experimental results show that FlexiVoice surpasses competing baselines and demonstrates strong capability in decoupling control factors. Human evaluations further confirm its naturalness, controllability, and robustness. Audio samples are available at https://flexi-voice.github.io.

</details>


### [23] [LAMB: LLM-based Audio Captioning with Modality Gap Bridging via Cauchy-Schwarz Divergence](https://arxiv.org/abs/2601.04658)
*Hyeongkeun Lee,Jongmin Choi,KiHyun Nam,Joon Son Chung*

Main category: cs.SD

TL;DR: LAMB：基于LLM的音频描述框架，通过跨模态对齐器缩小音频与文本嵌入空间差距，增强LLM推理能力，在AudioCaps上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将音频特征投影到LLM嵌入空间时未考虑跨模态对齐，无法充分利用LLM的推理能力。需要解决音频嵌入与LLM文本嵌入空间之间的模态差距问题。

Method: 1. 跨模态对齐器：最小化柯西-施瓦茨散度同时最大化互信息，实现全局和token级别的音频-文本对齐；2. 双流适配器：提取语义丰富的音频嵌入；3. 令牌引导器：在LLM文本嵌入空间中直接计算分数来引导生成描述的对数概率。

Result: 实验证实框架增强了LLM解码器的推理能力，在AudioCaps数据集上实现了最先进的性能。

Conclusion: LAMB通过有效的跨模态对齐机制，成功缩小了音频与文本嵌入空间的差距，使LLM能够更好地理解和描述音频内容，为音频描述任务提供了新的解决方案。

Abstract: Automated Audio Captioning aims to describe the semantic content of input audio. Recent works have employed large language models (LLMs) as a text decoder to leverage their reasoning capabilities. However, prior approaches that project audio features into the LLM embedding space without considering cross-modal alignment fail to fully utilize these capabilities. To address this, we propose LAMB, an LLM-based audio captioning framework that bridges the modality gap between audio embeddings and the LLM text embedding space. LAMB incorporates a Cross-Modal Aligner that minimizes Cauchy-Schwarz divergence while maximizing mutual information, yielding tighter alignment between audio and text at both global and token levels. We further design a Two-Stream Adapter that extracts semantically enriched audio embeddings, thereby delivering richer information to the Cross-Modal Aligner. Finally, leveraging the aligned audio embeddings, a proposed Token Guide directly computes scores within the LLM text embedding space to steer the output logits of generated captions. Experimental results confirm that our framework strengthens the reasoning capabilities of the LLM decoder, achieving state-of-the-art performance on AudioCaps.

</details>


### [24] [Semi-Supervised Diseased Detection from Speech Dialogues with Multi-Level Data Modeling](https://arxiv.org/abs/2601.04744)
*Xingyuan Li,Mengyue Wu*

Main category: cs.SD

TL;DR: 提出一个音频专用的半监督学习框架，通过联合学习帧级、段级和会话级表示，解决医学语音分析中的弱监督问题，在数据稀缺情况下实现高效学习。


<details>
  <summary>Details</summary>
Motivation: 医学语音分析面临核心挑战：病理特征在患者语音中不均匀表达，且存在数据稀缺、临床标注主观性强的问题。现有音频方法未能有效处理这种层次结构，需要专门针对弱监督学习场景的解决方案。

Method: 提出端到端的音频半监督学习框架，联合学习未分割临床对话中的帧级、段级和会话级表示。动态聚合多粒度特征并生成高质量伪标签，高效利用未标注数据。框架具有模型无关性。

Result: 框架在跨语言和不同医疗条件下表现稳健且数据高效，例如仅使用11个标注样本就能达到全监督性能的90%。证明能够有效处理医学语音分析中的弱监督和远距离监督问题。

Conclusion: 该工作为医学语音分析中的弱监督学习提供了原则性方法，通过显式建模语音特征的层次结构，在数据稀缺情况下实现高效学习，具有实际应用价值。

Abstract: Detecting medical conditions from speech acoustics is fundamentally a weakly-supervised learning problem: a single, often noisy, session-level label must be linked to nuanced patterns within a long, complex audio recording. This task is further hampered by severe data scarcity and the subjective nature of clinical annotations. While semi-supervised learning (SSL) offers a viable path to leverage unlabeled data, existing audio methods often fail to address the core challenge that pathological traits are not uniformly expressed in a patient's speech. We propose a novel, audio-only SSL framework that explicitly models this hierarchy by jointly learning from frame-level, segment-level, and session-level representations within unsegmented clinical dialogues. Our end-to-end approach dynamically aggregates these multi-granularity features and generates high-quality pseudo-labels to efficiently utilize unlabeled data. Extensive experiments show the framework is model-agnostic, robust across languages and conditions, and highly data-efficient-achieving, for instance, 90\% of fully-supervised performance using only 11 labeled samples. This work provides a principled approach to learning from weak, far-end supervision in medical speech analysis.

</details>


### [25] [ChronosAudio: A Comprehensive Long-Audio Benchmark for Evaluating Audio-Large Language Models](https://arxiv.org/abs/2601.04876)
*Kaiwen Luo,Liang Lin,Yibo Zhang,Moayad Aloqaily,Dexian Wang,Zhenhong Zhou,Junwei Zhang,Kun Wang,Li Sun,Qingsong Wen*

Main category: cs.SD

TL;DR: ChronosAudio是首个针对音频大语言模型的长音频理解多任务基准，包含6大类任务、3.6万个测试实例、超过200小时音频，揭示了当前模型在长音频理解上的严重局限性。


<details>
  <summary>Details</summary>
Motivation: 当前音频大语言模型在长音频理解能力方面尚未被充分探索，现有基准主要关注短音频片段，缺乏评估模型在长音频上表现的标准方法。

Method: 提出ChronosAudio基准，包含6个主要任务类别，音频时长分为短、中、长三类，共3.6万个测试实例，总计超过200小时音频，用于全面评估长度泛化能力。

Result: 对16个最先进模型的实验发现：1) 长上下文崩溃现象：从短到长上下文转换时性能下降超过90%；2) 结构注意力稀释：注意力机制在后续序列中显著扩散；3) 缓解策略恢复上限：当前方法只能恢复50%性能。

Conclusion: 研究揭示了音频大语言模型在长音频理解上的重大挑战，迫切需要开发能够实现稳健文档级音频推理的新方法。

Abstract: Although Audio Large Language Models (ALLMs) have witnessed substantial advancements, their long audio understanding capabilities remain unexplored. A plethora of benchmarks have been proposed for general audio tasks, they predominantly focus on short-form clips, leaving without a consensus on evaluating ALLMs over extended durations. This paper proposes ChronosAudio, the first multi-task benchmark tailored for long-audio understanding in ALLMs. It encompasses six major task categories and comprises 36,000 test instances totaling over 200 hours audio, stratified into short, middle, and long-form categories to comprehensively evaluate length generalization. Extensive experiments on 16 state-of-the-art models using ChronosAudio yield three critical findings: 1.Precipitous Long-Context Collapse: ALLMs exhibit a severe inability to sustain performance, with the transition from short to long contexts triggering a staggering performance degradation of over 90% in specific tasks. 2.Structural Attention Dilution: Performance degradation stems from a fundamental failure in maintaining temporal locality; attention mechanisms suffer from significant diffusion in later sequences. 3.Restorative Ceiling of Mitigation: Current strategies only offer 50% recovery. These findings reveal significant challenges in long-audio, underscoring the urgent need for approaches to achieve robust, document-level audio reasoning.

</details>


### [26] [Leveraging Prediction Entropy for Automatic Prompt Weighting in Zero-Shot Audio-Language Classification](https://arxiv.org/abs/2601.05011)
*Karim El Khoury,Maxime Zanella,Tiffanie Godelaine,Christophe De Vleeschouwer,Benoit Macq*

Main category: cs.SD

TL;DR: 提出一种基于熵引导的提示词加权方法，通过最小化预测熵来优化提示词组合，在零样本音频分类中显著提升性能


<details>
  <summary>Details</summary>
Motivation: 音频-语言模型在零样本分类中性能对文本提示词的措辞高度敏感，现有方法要么需要标注数据，要么无法处理某些提示词可能对性能产生负面影响的问题

Method: 提出熵引导的提示词加权方法，设计专门的目标函数最小化预测熵来获得新的提示词权重，将低熵作为高置信度的代理指标

Result: 在涵盖环境、城市和声音的五种音频分类数据集上，相比传统提示词集成方法获得一致提升，在整个基准测试中准确率提升达5倍

Conclusion: 该方法无需额外标签且计算开销可忽略，能有效提升音频-语言模型在零样本分类中的鲁棒性和性能

Abstract: Audio-language models have recently demonstrated strong zero-shot capabilities by leveraging natural-language supervision to classify audio events without labeled training data. Yet, their performance is highly sensitive to the wording of text prompts, with small variations leading to large fluctuations in accuracy. Prior work has mitigated this issue through prompt learning or prompt ensembling. However, these strategies either require annotated data or fail to account for the fact that some prompts may negatively impact performance. In this work, we present an entropy-guided prompt weighting approach that aims to find a robust combination of prompt contributions to maximize prediction confidence. To this end, we formulate a tailored objective function that minimizes prediction entropy to yield new prompt weights, utilizing low-entropy as a proxy for high confidence. Our approach can be applied to individual samples or a batch of audio samples, requiring no additional labels and incurring negligible computational overhead. Experiments on five audio classification datasets covering environmental, urban, and vocal sounds, demonstrate consistent gains compared to classical prompt ensembling methods in a zero-shot setting, with accuracy improvements 5-times larger across the whole benchmark.

</details>

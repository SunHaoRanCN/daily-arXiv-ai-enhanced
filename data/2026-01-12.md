<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 8]
- [eess.AS](#eess.AS) [Total: 1]
- [cs.SD](#cs.SD) [Total: 3]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Channel Selected Stratified Nested Cross Validation for Clinically Relevant EEG Based Parkinsons Disease Detection](https://arxiv.org/abs/2601.05276)
*Nicholas R. Rasmussen,Rodrigue Rizk,Longwei Wang,Arun Singh,KC Santosh*

Main category: eess.SP

TL;DR: 该论文提出一个基于嵌套交叉验证的统一评估框架，用于帕金森病早期检测的EEG分析，通过患者级分层、多层窗口化和内部循环通道选择三个保障措施防止数据泄露，在三个独立数据集上达到80.6%的准确率。


<details>
  <summary>Details</summary>
Motivation: 帕金森病早期检测是临床神经科学的关键挑战，EEG提供非侵入性筛查途径。现有机器学习方法存在方法学缺陷，特别是患者级数据泄露问题，导致性能估计膨胀并限制临床转化。

Method: 提出基于嵌套交叉验证的统一评估框架，包含三个保障措施：1) 患者级分层消除受试者重叠；2) 多层窗口化协调异质EEG记录同时保留时间动态；3) 内部循环通道选择实现无信息泄露的特征降维。使用卷积神经网络在该框架下训练。

Result: 在三个具有异质通道数的独立数据集上，该框架下的CNN达到80.6%的准确率，在保留群体块测试中表现出最先进的性能，与文献中其他方法相当。

Conclusion: 嵌套交叉验证是防止偏差的必要保障，也是选择患者级决策最相关信息的原则性方法。该框架为生物医学信号分析领域提供了可复现的基础，可扩展到其他领域。

Abstract: The early detection of Parkinsons disease remains a critical challenge in clinical neuroscience, with electroencephalography offering a noninvasive and scalable pathway toward population level screening. While machine learning has shown promise in this domain, many reported results suffer from methodological flaws, most notably patient level data leakage, inflating performance estimates and limiting clinical translation. To address these modeling pitfalls, we propose a unified evaluation framework grounded in nested cross validation and incorporating three complementary safeguards: (i) patient level stratification to eliminate subject overlap and ensure unbiased generalization, (ii) multi layered windowing to harmonize heterogeneous EEG recordings while preserving temporal dynamics, and (iii) inner loop channel selection to enable principled feature reduction without information leakage. Applied across three independent datasets with a heterogeneous number of channels, a convolutional neural network trained under this framework achieved 80.6% accuracy and demonstrated state of the art performance under held out population block testing, comparable to other methods in the literature. This performance underscores the necessity of nested cross validation as a safeguard against bias and as a principled means of selecting the most relevant information for patient level decisions, providing a reproducible foundation that can extend to other biomedical signal analysis domains.

</details>


### [2] [Discrete Mode Decomposition Meets Shapley Value: Robust Signal Prediction in Tactile Internet](https://arxiv.org/abs/2601.05323)
*Mohammad Ali Vahedifar,Qi Zhang*

Main category: eess.SP

TL;DR: 提出结合离散模式分解(DMD)和Shapley模式值(SMV)的预测框架，用于触觉互联网中的触觉信号预测，显著提升预测精度并降低推理延迟。


<details>
  <summary>Details</summary>
Motivation: 触觉互联网需要超低延迟和高可靠性，但可变延迟和数据包丢失给沉浸式触觉通信带来挑战，需要准确及时的触觉信号预测方法。

Method: 使用离散模式分解(DMD)将触觉信号分解为可解释的内在模式，结合Shapley模式值(SMV)评估各模式对预测准确性的贡献，并与Transformer架构结合。

Result: DMD+SMV框架在1样本预测中达到98.9%准确率，100样本预测达到92.5%准确率，推理延迟分别为0.056ms和2ms，显著优于基线方法。

Conclusion: 该框架能够缓解触觉互联网对延迟和可靠性的严格要求，同时保持性能，在现实触觉互联网系统中具有实际部署的可行性。

Abstract: Tactile Internet (TI) requires ultra-low latency and high reliability to ensure stability and transparency in touch-enabled teleoperation. However, variable delays and packet loss present significant challenges to maintaining immersive haptic communication. To address this, we propose a predictive framework that integrates Discrete Mode Decomposition (DMD) with Shapley Mode Value (SMV) for accurate and timely haptic signal prediction. DMD decomposes haptic signals into interpretable intrinsic modes, while SMV evaluates each mode's contribution to prediction accuracy, which is well-aligned with the goal-oriented semantic communication. Integrating SMV with DMD further accelerates inference, enabling efficient communication and smooth teleoperation even under adverse network conditions.
  Extensive experiments show that DMD+SMV, combined with a Transformer architecture, outperforms baseline methods significantly. It achieves 98.9% accuracy for 1-sample prediction and 92.5% for 100-sample prediction, as well as extremely low inference latency: 0.056 ms and 2 ms, respectively. These results demonstrate that the proposed framework has strong potential to ease the stringent latency and reliability requirements of TI without compromising performance, highlighting its feasibility for real-world deployment in TI systems.

</details>


### [3] [SPARK: Sparse Parametric Antenna Representation using Kernels](https://arxiv.org/abs/2601.05440)
*William Bjorndahl,Mark O'Hair,Ben Zoghi,Joseph Camp*

Main category: eess.SP

TL;DR: SPARK是一种免训练的压缩模型，将天线/RIS辐射模式分解为平滑的全局基底和稀疏的局部波瓣，实现高维辐射模式的紧凑参数化表示，用于可扩展的波束管理。


<details>
  <summary>Details</summary>
Motivation: 随着天线数量、用户数和报告子带的增加，CSI获取和反馈开销成为瓶颈。硬件感知操作需要天线/RIS响应的显式表示，但高保真测量模式是高维且处理成本高的。

Method: SPARK将辐射模式分解为平滑全局基底和稀疏局部波瓣：对于3D模式使用低阶球谐函数作为全局方向性，各向异性高斯核作为局部特征；对于RIS 1D方位角剖面使用傅里叶级数基底和1D高斯函数。

Result: 在AERPAW测试平台和公共RIS数据集上，SPARK分别实现了2.8倍和10.4倍的重建MSE降低。仿真显示，在固定上行链路预算下，紧凑模式描述和稀疏路径描述符可带来12.65%的平均上行链路良好吞吐量增益。

Conclusion: SPARK将密集辐射模式转换为紧凑的参数化模型，为可扩展的硬件感知波束管理提供了有效解决方案。

Abstract: Channel state information (CSI) acquisition and feedback overhead grows with the number of antennas, users, and reported subbands. This growth becomes a bottleneck for many antenna and reconfigurable intelligent surface (RIS) systems as arrays and user densities scale. Practical CSI feedback and beam management rely on codebooks, where beams are selected via indices rather than explicitly transmitting radiation patterns. Hardware-aware operation requires an explicit representation of the measured antenna/RIS response, yet high-fidelity measured patterns are high-dimensional and costly to handle. We present SPARK (Sparse Parametric Antenna Representation using Kernels), a training-free compression model that decomposes patterns into a smooth global base and sparse localized lobes. For 3D patterns, SPARK uses low-order spherical harmonics for global directivity and anisotropic Gaussian kernels for localized features. For RIS 1D azimuth cuts, it uses a Fourier-series base with 1D Gaussians. On patterns from the AERPAW testbed and a public RIS dataset, SPARK achieves up to 2.8$\times$ and 10.4$\times$ reductions in reconstruction MSE over baselines, respectively. Simulation shows that amortizing a compact pattern description and reporting sparse path descriptors can produce 12.65% mean uplink goodput gain under a fixed uplink budget. Overall, SPARK turns dense patterns into compact, parametric models for scalable, hardware-aware beam management.

</details>


### [4] [Deformation-Aware Observation Modeling for Radar-Based Human Sensing via 3D Scan-Depth Sequence Fusion](https://arxiv.org/abs/2601.05676)
*Guangqi Shi,Kimitaka Sumi,Takuya Sakamoto*

Main category: eess.SP

TL;DR: 提出融合高分辨率3D扫描与深度相机数据的表面形变感知雷达观测模型，通过物理光学近似计算电磁散射，提升呼吸监测的鲁棒性


<details>
  <summary>Details</summary>
Motivation: 传统雷达人体传感常基于简化运动假设，但呼吸引起的非刚性表面形变会影响电磁波散射，降低测量鲁棒性，需要更精确的观测模型

Method: 融合静态高分辨率3D扫描与动态深度相机数据，使用相干点漂移算法进行非刚性配准，采用物理光学近似计算电磁散射，重建中频雷达信号

Result: 在低信号质量条件下，相比仅使用深度序列的模型，提出的模型表现出更高鲁棒性，两位参与者的位移波形皮尔逊相关系数分别达到0.943和0.887

Conclusion: 传感器融合的表面形变感知观测模型能真实再现雷达观测，为雷达测量变化解释提供物理基础，提升非接触人体传感的可靠性

Abstract: Non-contact radar-based human sensing is often interpreted using simplified motion assumptions. However, respiration induces non-rigid surface deformation of the human body that impacts electromagnetic wave scattering and can degrade the robustness of measurements. To address this, we propose a surface-deformation-aware observation model for radar-based human sensing that fuses static high-resolution three-dimensional scanner measurements with temporal depth camera data to represent time-varying human surface geometry. Non-rigid registration using the coherent point drift algorithm is employed to align a static template with dynamic depth frames. Frame-wise electromagnetic scattering is subsequently computed using the physical optics approximation, allowing the reconstruction of intermediate-frequency radar signals that emulate radar observations. Validation against experimental radar data demonstrated that the proposed model exhibited greater robustness than a depth-sequence-only model under low-signal-quality conditions involving complex surface dynamics and multiple reflective sites. For two participants, the proposed model achieved higher Pearson correlation coefficients of 0.943 and 0.887 between model-derived and experimentally measured displacement waveforms, compared with 0.868 and 0.796 for the depth-sequence-only model. Furthermore, in a favorable case characterized by a single relatively-stationary reflective site, the proposed method achieved a correlation coefficient of 0.789 between model-derived and experimentally measured in-phase-quadrature magnitude variations. These results suggest that our sensor-fusion-based deformation-aware observation modeling can realistically reproduce radar observations and provide physically grounded insights into the interpretation of radar measurement variations.

</details>


### [5] [A Novel Deep Learning-Based Coarse-to-Fine Frame Synchronization Method for OTFS Systems](https://arxiv.org/abs/2601.05920)
*Meiwen Men,Tao Zhou,Kaifeng Bao,Zhiyang Guo,Yongning Qi,Liu Liu,Bo Ai*

Main category: eess.SP

TL;DR: 提出基于粗到细深度残差网络的OTFS系统低复杂度同步方法，利用延迟时间域中OTFS导频的周期性特征，将同步问题转化为层次分类问题，显著降低计算复杂度并保持高精度。


<details>
  <summary>Details</summary>
Motivation: OTFS调制是未来无线系统（特别是高移动性场景）的稳健候选波形，能有效缓解快速时变信道的影响。然而，传统算法性能有限，OTFS系统的精确帧同步仍然是一个挑战。

Method: 提出基于粗到细深度残差网络（ResNet）架构的低复杂度同步方法。该方法利用OTFS导频在延迟时间（DT）域中的固有周期性特征，将同步问题表述为层次分类问题。采用两阶段策略：首先缩小搜索空间，然后精确定位符号定时偏移（STO）。

Result: 构建了包含多样化信道模型和随机STO的综合仿真数据集进行验证。广泛的仿真结果表明，该方法实现了稳健的信号起始检测，相比传统基准方法具有更高的精度，特别是在低信噪比（SNR）场景和高移动性场景中表现优异。

Conclusion: 提出的基于深度残差网络的同步方法有效解决了OTFS系统同步难题，在降低计算复杂度的同时保持了高估计精度，为高移动性无线通信系统提供了实用的同步解决方案。

Abstract: Orthogonal time frequency space (OTFS) modulation is a robust candidate waveform for future wireless systems, particularly in high-mobility scenarios, as it effectively mitigates the impact of rapidly time-varying channels by mapping symbols in the delay-Doppler (DD) domain. However, accurate frame synchronization in OTFS systems remains a challenge due to the performance limitations of conventional algorithms. To address this, we propose a low-complexity synchronization method based on a coarse-to-fine deep residual network (ResNet) architecture. Unlike traditional approaches relying on high-overhead preamble structures, our method exploits the intrinsic periodic features of OTFS pilots in the delay-time (DT) domain to formulate synchronization as a hierarchical classification problem. Specifically, the proposed architecture employs a two-stage strategy to first narrow the search space and then pinpoint the precise symbol timing offset (STO), thereby significantly reducing computational complexity while maintaining high estimation accuracy. We construct a comprehensive simulation dataset incorporating diverse channel models and randomized STO to validate the method. Extensive simulation results demonstrate that the proposed method achieves robust signal start detection and superior accuracy compared to conventional benchmarks, particularly in low signal-to-noise ratio (SNR) regimes and high-mobility scenarios.

</details>


### [6] [Cedalion Tutorial: A Python-based framework for comprehensive analysis of multimodal fNIRS & DOT from the lab to the everyday world](https://arxiv.org/abs/2601.05923)
*E. Middell,L. Carlton,S. Moradi,T. Codina,T. Fischer,J. Cutler,S. Kelley,J. Behrendt,T. Dissanayake,N. Harmening,M. A. Yücel,D. A. Boas,A. von Lühmann*

Main category: eess.SP

TL;DR: Cedalion是一个基于Python的开源框架，用于统一fNIRS和DOT数据的模型驱动和数据驱动分析，支持可重复、可扩展的神经影像工作流。


<details>
  <summary>Details</summary>
Motivation: 当前fNIRS和DOT分析工具分散在不同平台，限制了可重复性、互操作性和与现代机器学习工作流的集成，需要一个统一的解决方案。

Method: 开发基于Python的开源框架，集成前向建模、光极配准、信号处理、GLM分析、DOT图像重建和机器学习方法，遵循SNIRF和BIDS标准，支持容器化工作流。

Result: 创建了Cedalion框架，提供七个可执行笔记本演示核心功能，实现了可重复、可扩展、云就绪和ML就绪的fNIRS/DOT工作流。

Conclusion: Cedalion为实验室和真实世界神经影像提供了一个开放、透明、社区可扩展的基础，支持可重复、可扩展的fNIRS/DOT分析工作流。

Abstract: Functional near-infrared spectroscopy (fNIRS) and diffuse optical tomography (DOT) are rapidly evolving toward wearable, multimodal, and data-driven, AI-supported neuroimaging in the everyday world. However, current analytical tools are fragmented across platforms, limiting reproducibility, interoperability, and integration with modern machine learning (ML) workflows. Cedalion is a Python-based open-source framework designed to unify advanced model-based and data-driven analysis of multimodal fNIRS and DOT data within a reproducible, extensible, and community-driven environment. Cedalion integrates forward modelling, photogrammetric optode co-registration, signal processing, GLM Analysis, DOT image reconstruction, and ML-based data-driven methods within a single standardized architecture based on the Python ecosystem. It adheres to SNIRF and BIDS standards, supports cloud-executable Jupyter notebooks, and provides containerized workflows for scalable, fully reproducible analysis pipelines that can be provided alongside original research publications. Cedalion connects established optical-neuroimaging pipelines with ML frameworks such as scikit-learn and PyTorch, enabling seamless multimodal fusion with EEG, MEG, and physiological data. It implements validated algorithms for signal-quality assessment, motion correction, GLM modelling, and DOT reconstruction, complemented by modules for simulation, data augmentation, and multimodal physiology analysis. Automated documentation links each method to its source publication, and continuous-integration testing ensures robustness. This tutorial paper provides seven fully executable notebooks that demonstrate core features. Cedalion offers an open, transparent, and community extensible foundation that supports reproducible, scalable, cloud- and ML-ready fNIRS/DOT workflows for laboratory-based and real-world neuroimaging.

</details>


### [7] [Curving Beam Reflections: Model and Experimental Validation](https://arxiv.org/abs/2601.05998)
*Caroline Jane Spindel,Edward Knightly*

Main category: eess.SP

TL;DR: 提出首个几何框架，用于建模任意凸形亚太赫兹弯曲光束在任意反射面上的反射，通过勒让德变换而非传统光线镜像方法，实现毫米级精度的预测。


<details>
  <summary>Details</summary>
Motivation: 弯曲光束是未来毫米波到亚太赫兹网络中绕过障碍物的有前景方法，但缺乏通用的预测模型来描述其在任意表面上的反射行为。传统的光线光学"镜像"方法在一般情况下会失效。

Method: 将光束分解为一系列切线族，证明该过程等价于勒让德变换。这种方法能够准确考虑任意形状、大小和位置的反射面，同时保留波传播的底层物理特性。通过有限元方法模拟和空中实验进行验证。

Result: 模型验证显示在预测反射方面达到毫米级精度，为未来弯曲光束通信和传感系统提供了理论基础，能够设计反射弯曲链路和弯曲雷达路径。

Conclusion: 提出的几何框架成功解决了弯曲光束在任意反射面上反射的建模问题，为亚太赫兹频段的弯曲光束应用提供了关键的理论和实验基础。

Abstract: Curving beams are a promising new method for bypassing obstacles in future millimeter-wave to sub-terahertz (sub-THz) networks but lack a general predictive model for their reflections from arbitrary surfaces. We show that, unfortunately, attempting to "mirror" the incident beam trajectory across the normal of the reflector, as in ray optics, fails in general. Thus, we introduce the first geometric framework capable of modeling the reflections of arbitrary convex sub-THz curving beams from general reflectors with experimental verification. Rather than "mirroring" the trajectory, we decompose the beam into a family of tangents and demonstrate that this process is equivalent to the Legendre transform. This approach allows us to accurately account for reflectors of any shape, size, and position while preserving the underlying physics of wave propagation. Our model is validated through finite element method simulations and over-the-air experiments, demonstrating millimeter-scale accuracy in predicting reflections. Our model provides a foundation for future curving beam communication and sensing systems, enabling the design of reflected curved links and curving radar paths.

</details>


### [8] [Cooperative Differential GNSS Positioning: Estimators and Bounds](https://arxiv.org/abs/2601.06012)
*Helena Calatrava,Daniel Medina,Pau Closas*

Main category: eess.SP

TL;DR: 该论文研究了大规模用户合作如何缓解传统DGNSS系统中参考站噪声的影响，提出了合作DGNSS和合作RTK的统一估计框架，并通过理论分析和仿真验证了合作在特定条件下可以恢复理想无噪声参考站的精度。


<details>
  <summary>Details</summary>
Motivation: 在差分GNSS定位中，用户与参考站之间的差分测量虽然抑制了共模误差，但引入了参考站噪声，这成为定位精度的根本限制。当使用质量参差不齐的参考基础设施时，这个问题尤为显著。因此需要研究如何通过用户合作来缓解参考站噪声的影响。

Method: 提出了合作DGNSS（C-DGNSS）和合作实时动态（C-RTK）定位的统一估计框架，推导了其Fisher信息矩阵的参数化表达式，该表达式是网络规模、卫星几何构型和参考站噪声的函数。通过这种形式化表达，能够从理论上分析估计性能。

Result: 理论分析确定了合作能够渐进恢复理想（无噪声）参考站DGNSS精度的条件。仿真结果验证了这些理论发现，表明在特定网络规模和几何条件下，用户合作可以有效缓解参考站噪声的影响。

Conclusion: 大规模用户合作能够有效缓解传统DGNSS系统中参考站噪声的限制，特别是在使用质量参差不齐的参考基础设施时。提出的统一框架为分析合作定位性能提供了理论基础，并识别了合作能够恢复理想参考站精度的条件。

Abstract: In Differential GNSS (DGNSS) positioning, differencing measurements between a user and a reference station suppresses common-mode errors but also introduces reference-station noise, which fundamentally limits accuracy. This limitation is minor for high-grade stations but becomes significant when using reference infrastructure of mixed quality. This paper investigates how large-scale user cooperation can mitigate the impact of reference-station noise in conventional (non-cooperative) DGNSS systems. We develop a unified estimation framework for cooperative DGNSS (C-DGNSS) and cooperative real-time kinematic (C-RTK) positioning, and derive parameterized expressions for their Fisher information matrices as functions of network size, satellite geometry, and reference-station noise. This formulation enables theoretical analysis of estimation performance, identifying regimes where cooperation asymptotically restores the accuracy of DGNSS with an ideal (noise-free) reference. Simulations validate these theoretical findings.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [9] [Discriminative-Generative Target Speaker Extraction with Decoder-Only Language Models](https://arxiv.org/abs/2601.06006)
*Bang Zeng,Beilong Tang,Wang Xiang,Ming Li*

Main category: eess.AS

TL;DR: 提出一个结合判别式和生成式模型的TSE框架，前端判别模型提取目标语音，后端生成模型增强音质，实现质量、清晰度和说话人一致性的更好平衡。


<details>
  <summary>Details</summary>
Motivation: 现有TSE方法主要基于判别式模型，虽然能有效抑制干扰说话人，但在语音感知质量和自然度方面表现不足。纯生成式方法又存在幻觉、内容漂移和可控性差等问题。

Method: 提出判别-生成TSE框架：前端判别模型提取目标说话人语音，生成稳定可控的中间表示；后端生成模型在神经音频编解码表示空间中重构细粒度语音细节。探索多种协作训练策略，包括前端冻结/微调、辅助SI-SDR损失、自回归和非自回归推理机制。

Result: 实验结果表明，该框架在语音质量、清晰度和说话人一致性方面实现了更优的权衡。

Conclusion: 判别-生成框架有效结合了判别式模型的鲁棒性、可控性和生成式模型的自然度、质量增强能力，为TSE任务提供了更优的解决方案。

Abstract: Target speaker extraction (TSE) aims to recover the speech signal of a desired speaker from a mixed audio recording, given a short enrollment utterance. Most existing TSE approaches are based on discriminative modeling paradigms. Although effective at suppressing interfering speakers, these methods often struggle to produce speech with high perceptual quality and naturalness. To address this limitation, we first propose LauraTSE, a generative TSE model built upon an auto-regressive decoder-only language model. However, purely generative approaches may suffer from hallucinations, content drift, and limited controllability, which may undermine their reliability in complex acoustic scenarios. To overcome these challenges, we further introduce a discriminative-generative TSE framework. In this framework, a discriminative front-end is employed to robustly extract the target speaker's speech, yielding stable and controllable intermediate representations. A generative back-end then operates in the neural audio codec representation space to reconstruct fine-grained speech details and enhance perceptual quality. This two-stage design effectively combines the robustness and controllability of discriminative models with the superior naturalness and quality enhancement capabilities of generative models. Moreover, we systematically investigate collaborative training strategies for the proposed framework, including freezing or fine-tuning the front-end, incorporating an auxiliary SI-SDR loss, and exploring both auto-regressive and non-auto-regressive inference mechanisms. Experimental results demonstrate that the proposed framework achieves a more favorable trade-off among speech quality, intelligibility, and speaker consistency.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [10] [CosyEdit: Unlocking End-to-End Speech Editing Capability from Zero-Shot Text-to-Speech Models](https://arxiv.org/abs/2601.05329)
*Junyang Chen,Yuhang Jia,Hui Wang,Jiaming Zhou,Yaxin Han,Mengying Feng,Yong Qin*

Main category: cs.SD

TL;DR: CosyEdit是一个端到端的语音编辑模型，通过任务特定微调和优化推理，在仅250小时监督数据上训练，性能优于数十亿参数基线，匹配最先进的级联方法。


<details>
  <summary>Details</summary>
Motivation: 传统级联语音编辑系统存在预处理流程复杂、依赖显式外部时间对齐的问题，需要更高效、端到端的解决方案。

Method: 基于CosyVoice模型，通过任务特定微调和优化推理程序，内部化语音-文本对齐，确保编辑前后语音一致性。使用自建的GigaEdit数据集（250小时监督数据）进行微调。

Result: 在RealEdit基准测试中，400M参数的CosyEdit不仅优于多个数十亿参数的语言模型基线，还匹配了最先进的级联方法的性能。

Conclusion: 通过任务特定微调和推理优化，可以从零样本TTS模型中解锁强大且高效的语音编辑能力，为高质量语音编辑提供新颖且经济高效的端到端解决方案。

Abstract: Automatic speech editing aims to modify spoken content based on textual instructions, yet traditional cascade systems suffer from complex preprocessing pipelines and a reliance on explicit external temporal alignment. Addressing these limitations, we propose CosyEdit, an end-to-end speech editing model adapted from CosyVoice through task-specific fine-tuning and an optimized inference procedure, which internalizes speech-text alignment while ensuring high consistency between the speech before and after editing. By fine-tuning on only 250 hours of supervised data from our curated GigaEdit dataset, our 400M-parameter model achieves reliable speech editing performance. Experiments on the RealEdit benchmark indicate that CosyEdit not only outperforms several billion-parameter language model baselines but also matches the performance of state-of-the-art cascade approaches. These results demonstrate that, with task-specific fine-tuning and inference optimization, robust and efficient speech editing capabilities can be unlocked from a zero-shot TTS model, yielding a novel and cost-effective end-to-end solution for high-quality speech editing.

</details>


### [11] [SPAM: Style Prompt Adherence Metric for Prompt-based TTS](https://arxiv.org/abs/2601.05554)
*Chanhee Cho,Nayeon Kim,Bugeun Kim*

Main category: cs.SD

TL;DR: 提出SPAM自动度量指标，用于评估文本到语音合成中风格提示的忠实度，同时满足合理性和忠实性要求。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的文本到语音系统缺乏既合理又忠实的评估指标，无法确保评估基于提示且符合人类判断。

Method: 受CLAP启发，将语音分解为声学属性并与风格提示对齐；使用监督对比损失训练评分器，以更好区分不同语义。

Result: 合理性实验显示SPAM与平均意见得分有强相关性；忠实性实验表明SPAM能成功基于给定风格提示进行区分，有效辨别不同语义。

Conclusion: SPAM为评估合成语音的风格提示忠实度提供了可行的自动解决方案。

Abstract: Prompt-based text-to-speech (TTS) aims to generate speech that adheres to fine-grained style cues provided in a text prompt. However, most prior works depend on neither plausible nor faithful measures to evaluate prompt adherence. That is, they cannot ensure whether the evaluation is grounded on the prompt and is similar to a human. Thus, we present a new automatic metric, the Style Prompt Adherence Metric, which explicitly satisfies both plausibility and faithfulness. Inspired by the CLAP, our approach factorizes speech into acoustic attributes and aligns them with the style prompt. Also, we trained the scorer with a supervised contrastive loss, which could provide a clearer distinction between different semantics. We conducted two experiments on two perspectives. The plausibility experiment showed that SPAM achieved a strong correlation with the mean opinion score (MOS). Also, the faithfulness experiment demonstrated that SPAM is successfully grounded to the given style prompt, as it can discriminate different semantics of the prompt. We believe that SPAM can provide a viable automatic solution for evaluating style prompt adherence of synthesized speech.

</details>


### [12] [The ICASSP 2026 HumDial Challenge: Benchmarking Human-like Spoken Dialogue Systems in the LLM Era](https://arxiv.org/abs/2601.05564)
*Zhixian Zhao,Shuiyuan Wang,Guojian Li,Hongfei Xue,Chengyou Wang,Shuai Wang,Longshuai Xiao,Zihan Zhang,Hui Bu,Xin Xu,Xinsheng Wang,Hexin Liu,Eng Siong Chng,Hung-yi Lee,Haizhou Li,Lei Xie*

Main category: cs.SD

TL;DR: ICASSP 2026首次举办人类化语音对话系统挑战赛(HumDial)，旨在评估语音对话系统在情感智能和全双工交互两个关键维度的表现，基于真实人类对话数据集建立公平评估平台。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型特别是音频LLM和全能模型的发展，语音对话系统已显著进步，但要实现真正"类人"的交流，需要双重能力：情感智能（感知和共鸣用户情感状态）和强大的交互机制（处理动态自然的对话流，如实时话轮转换）。

Method: 基于真实人类对话构建大规模数据集，设立两个评估赛道：1) 情感智能赛道：专注于长期情感理解和共情生成；2) 全双工交互赛道：系统评估"边听边说"条件下的实时决策能力。

Result: 论文总结了数据集、赛道配置和最终结果，为ICASSP 2026首届人类化语音对话系统挑战赛建立了完整的评估框架。

Conclusion: HumDial挑战赛为评估语音对话系统的类人交流能力提供了首个综合性基准，重点关注情感智能和全双工交互这两个关键维度，推动了语音对话系统向更自然、更人性化的方向发展。

Abstract: Driven by the rapid advancement of Large Language Models (LLMs), particularly Audio-LLMs and Omni-models, spoken dialogue systems have evolved significantly, progressively narrowing the gap between human-machine and human-human interactions. Achieving truly ``human-like'' communication necessitates a dual capability: emotional intelligence to perceive and resonate with users' emotional states, and robust interaction mechanisms to navigate the dynamic, natural flow of conversation, such as real-time turn-taking. Therefore, we launched the first Human-like Spoken Dialogue Systems Challenge (HumDial) at ICASSP 2026 to benchmark these dual capabilities. Anchored by a sizable dataset derived from authentic human conversations, this initiative establishes a fair evaluation platform across two tracks: (1) Emotional Intelligence, targeting long-term emotion understanding and empathetic generation; and (2) Full-Duplex Interaction, systematically evaluating real-time decision-making under `` listening-while-speaking'' conditions. This paper summarizes the dataset, track configurations, and the final results.

</details>

{"id": "2601.06235", "categories": ["cs.SD", "cs.AI", "cs.HC"], "pdf": "https://arxiv.org/pdf/2601.06235", "abs": "https://arxiv.org/abs/2601.06235", "authors": ["Sheng-Kai Chen", "Jyh-Horng Wu", "Ching-Yao Lin", "Yen-Ting Lin"], "title": "An Intelligent AI glasses System with Multi-Agent Architecture for Real-Time Voice Processing and Task Execution", "comment": "Published in NCS 2025 (Paper No. N0180)", "summary": "This paper presents an AI glasses system that integrates real-time voice processing, artificial intelligence(AI) agents, and cross-network streaming capabilities. The system employs dual-agent architecture where Agent 01 handles Automatic Speech Recognition (ASR) and Agent 02 manages AI processing through local Large Language Models (LLMs), Model Context Protocol (MCP) tools, and Retrieval-Augmented Generation (RAG). The system supports real-time RTSP streaming for voice and video data transmission, eye tracking data collection, and remote task execution through RabbitMQ messaging. Implementation demonstrates successful voice command processing with multilingual support and cross-platform task execution capabilities.", "AI": {"tldr": "AI\u773c\u955c\u7cfb\u7edf\u96c6\u6210\u5b9e\u65f6\u8bed\u97f3\u5904\u7406\u3001AI\u4ee3\u7406\u548c\u8de8\u7f51\u7edc\u6d41\u4f20\u8f93\uff0c\u91c7\u7528\u53cc\u4ee3\u7406\u67b6\u6784\u5b9e\u73b0\u8bed\u97f3\u8bc6\u522b\u4e0eAI\u5904\u7406\uff0c\u652f\u6301\u591a\u8bed\u8a00\u8bed\u97f3\u547d\u4ee4\u548c\u8de8\u5e73\u53f0\u4efb\u52a1\u6267\u884c", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u96c6\u6210\u7684AI\u773c\u955c\u7cfb\u7edf\uff0c\u80fd\u591f\u5b9e\u65f6\u5904\u7406\u8bed\u97f3\u547d\u4ee4\u3001\u6267\u884cAI\u4efb\u52a1\u5e76\u5b9e\u73b0\u8de8\u7f51\u7edc\u7684\u6570\u636e\u6d41\u4f20\u8f93\uff0c\u4e3a\u589e\u5f3a\u73b0\u5b9e\u548c\u667a\u80fd\u4ea4\u4e92\u63d0\u4f9b\u5b8c\u6574\u89e3\u51b3\u65b9\u6848", "method": "\u91c7\u7528\u53cc\u4ee3\u7406\u67b6\u6784\uff1aAgent 01\u8d1f\u8d23\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b(ASR)\uff0cAgent 02\u901a\u8fc7\u672c\u5730\u5927\u8bed\u8a00\u6a21\u578b(LLMs)\u3001\u6a21\u578b\u4e0a\u4e0b\u6587\u534f\u8bae(MCP)\u5de5\u5177\u548c\u68c0\u7d22\u589e\u5f3a\u751f\u6210(RAG)\u5904\u7406AI\u4efb\u52a1\uff1b\u7cfb\u7edf\u652f\u6301RTSP\u5b9e\u65f6\u6d41\u4f20\u8f93\u3001\u773c\u52a8\u8ffd\u8e2a\u6570\u636e\u6536\u96c6\u548cRabbitMQ\u8fdc\u7a0b\u4efb\u52a1\u6267\u884c", "result": "\u7cfb\u7edf\u6210\u529f\u5b9e\u73b0\u4e86\u591a\u8bed\u8a00\u8bed\u97f3\u547d\u4ee4\u5904\u7406\u3001\u5b9e\u65f6\u97f3\u89c6\u9891\u6570\u636e\u4f20\u8f93\u3001\u773c\u52a8\u6570\u636e\u6536\u96c6\u548c\u8de8\u5e73\u53f0\u4efb\u52a1\u6267\u884c\u80fd\u529b\uff0c\u5c55\u793a\u4e86\u5b8c\u6574\u7684AI\u773c\u955c\u7cfb\u7edf\u529f\u80fd", "conclusion": "\u8be5AI\u773c\u955c\u7cfb\u7edf\u901a\u8fc7\u521b\u65b0\u7684\u53cc\u4ee3\u7406\u67b6\u6784\u548c\u96c6\u6210\u6280\u672f\uff0c\u4e3a\u667a\u80fd\u53ef\u7a7f\u6234\u8bbe\u5907\u63d0\u4f9b\u4e86\u5f3a\u5927\u7684\u5b9e\u65f6AI\u5904\u7406\u80fd\u529b\uff0c\u5728\u591a\u8bed\u8a00\u652f\u6301\u548c\u8de8\u5e73\u53f0\u4efb\u52a1\u6267\u884c\u65b9\u9762\u8868\u73b0\u4f18\u5f02"}}
{"id": "2601.06406", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2601.06406", "abs": "https://arxiv.org/abs/2601.06406", "authors": ["Linfei Li", "Lin Zhang", "Zhong Wang", "Fengyi Zhang", "Zelin Li", "Ying Shen"], "title": "Representing Sounds as Neural Amplitude Fields: A Benchmark of Coordinate-MLPs and A Fourier Kolmogorov-Arnold Framework", "comment": "Accepted by AAAI 2025. Code: https://github.com/lif314/Fourier-ASR", "summary": "Although Coordinate-MLP-based implicit neural representations have excelled in representing radiance fields, 3D shapes, and images, their application to audio signals remains underexplored. To fill this gap, we investigate existing implicit neural representations, from which we extract 3 types of positional encoding and 16 commonly used activation functions. Through combinatorial design, we establish the first benchmark for Coordinate-MLPs in audio signal representations. Our benchmark reveals that Coordinate-MLPs require complex hyperparameter tuning and frequency-dependent initialization, limiting their robustness. To address these issues, we propose Fourier-ASR, a novel framework based on the Fourier series theorem and the Kolmogorov-Arnold representation theorem. Fourier-ASR introduces Fourier Kolmogorov-Arnold Networks (Fourier-KAN), which leverage periodicity and strong nonlinearity to represent audio signals, eliminating the need for additional positional encoding. Furthermore, a Frequency-adaptive Learning Strategy (FaLS) is proposed to enhance the convergence of Fourier-KAN by capturing high-frequency components and preventing overfitting of low-frequency signals. Extensive experiments conducted on natural speech and music datasets reveal that: (1) well-designed positional encoding and activation functions in Coordinate-MLPs can effectively improve audio representation quality; and (2) Fourier-ASR can robustly represent complex audio signals without extensive hyperparameter tuning. Looking ahead, the continuity and infinite resolution of implicit audio representations make our research highly promising for tasks such as audio compression, synthesis, and generation. The source code will be released publicly to ensure reproducibility. The code is available at https://github.com/lif314/Fourier-ASR.", "AI": {"tldr": "\u672c\u6587\u63d0\u51faFourier-ASR\u6846\u67b6\uff0c\u57fa\u4e8e\u5085\u91cc\u53f6\u7ea7\u6570\u548cKolmogorov-Arnold\u8868\u793a\u5b9a\u7406\uff0c\u7528\u4e8e\u97f3\u9891\u4fe1\u53f7\u7684\u9690\u5f0f\u795e\u7ecf\u8868\u793a\uff0c\u89e3\u51b3\u4e86\u4f20\u7edfCoordinate-MLPs\u9700\u8981\u590d\u6742\u8d85\u53c2\u6570\u8c03\u4f18\u7684\u95ee\u9898\u3002", "motivation": "Coordinate-MLP\u5728\u8f90\u5c04\u573a\u30013D\u5f62\u72b6\u548c\u56fe\u50cf\u8868\u793a\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u4f46\u5728\u97f3\u9891\u4fe1\u53f7\u8868\u793a\u65b9\u9762\u7814\u7a76\u4e0d\u8db3\u3002\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u590d\u6742\u7684\u8d85\u53c2\u6570\u8c03\u4f18\u548c\u9891\u7387\u76f8\u5173\u521d\u59cb\u5316\uff0c\u9650\u5236\u4e86\u5176\u9c81\u68d2\u6027\u3002", "method": "1) \u5efa\u7acbCoordinate-MLPs\u5728\u97f3\u9891\u8868\u793a\u4e2d\u7684\u9996\u4e2a\u57fa\u51c6\u6d4b\u8bd5\uff1b2) \u63d0\u51faFourier-ASR\u6846\u67b6\uff0c\u5305\u542bFourier-KAN\u7f51\u7edc\uff08\u57fa\u4e8e\u5085\u91cc\u53f6\u7ea7\u6570\u548cKolmogorov-Arnold\u5b9a\u7406\uff09\u548c\u9891\u7387\u81ea\u9002\u5e94\u5b66\u4e60\u7b56\u7565(FaLS)\uff1b3) \u65e0\u9700\u989d\u5916\u4f4d\u7f6e\u7f16\u7801\u3002", "result": "1) \u7cbe\u5fc3\u8bbe\u8ba1\u7684\u4f4d\u7f6e\u7f16\u7801\u548c\u6fc0\u6d3b\u51fd\u6570\u80fd\u6709\u6548\u63d0\u5347Coordinate-MLPs\u7684\u97f3\u9891\u8868\u793a\u8d28\u91cf\uff1b2) Fourier-ASR\u80fd\u591f\u9c81\u68d2\u5730\u8868\u793a\u590d\u6742\u97f3\u9891\u4fe1\u53f7\uff0c\u65e0\u9700\u5927\u91cf\u8d85\u53c2\u6570\u8c03\u4f18\uff1b3) \u5728\u81ea\u7136\u8bed\u97f3\u548c\u97f3\u4e50\u6570\u636e\u96c6\u4e0a\u9a8c\u8bc1\u4e86\u6709\u6548\u6027\u3002", "conclusion": "\u9690\u5f0f\u97f3\u9891\u8868\u793a\u7684\u8fde\u7eed\u6027\u548c\u65e0\u9650\u5206\u8fa8\u7387\u7279\u6027\u4f7f\u5176\u5728\u97f3\u9891\u538b\u7f29\u3001\u5408\u6210\u548c\u751f\u6210\u7b49\u4efb\u52a1\u4e2d\u5177\u6709\u5e7f\u9614\u524d\u666f\u3002\u63d0\u51fa\u7684Fourier-ASR\u6846\u67b6\u4e3a\u97f3\u9891\u4fe1\u53f7\u8868\u793a\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.06829", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2601.06829", "abs": "https://arxiv.org/abs/2601.06829", "authors": ["Bochao Sun", "Yang Xiao", "Han Yin"], "title": "MoEScore: Mixture-of-Experts-Based Text-Audio Relevance Score Prediction for Text-to-Audio System Evaluation", "comment": null, "summary": "Recent advances in generative models have enabled modern Text-to-Audio (TTA) systems to synthesize audio with high perceptual quality. However, TTA systems often struggle to maintain semantic consistency with the input text, leading to mismatches in sound events, temporal tructures, or contextual relationships. Evaluating semantic fidelity in TTA remains a significant challenge. Traditional methods primarily rely on subjective human listening tests, which is time-consuming. To solve this, we propose an objective evaluator based on a Mixture of Experts (MoE) architecture with Sequential Cross-Attention (SeqCoAttn). Our model achieves the first rank in the XACLE Challenge, with an SRCC of 0.6402 (an improvement of 30.6% over the challenge baseline) on the test dataset. Code is available at: https://github.com/S-Orion/MOESCORE.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eMoE\u67b6\u6784\u4e0eSeqCoAttn\u7684\u5ba2\u89c2\u8bc4\u4f30\u5668MOESCORE\uff0c\u7528\u4e8e\u8bc4\u4f30TTA\u7cfb\u7edf\u7684\u8bed\u4e49\u4fdd\u771f\u5ea6\uff0c\u5728XACLE\u6311\u6218\u8d5b\u4e2d\u6392\u540d\u7b2c\u4e00\uff0cSRCC\u8fbe0.6402\uff0c\u76f8\u6bd4\u57fa\u7ebf\u63d0\u534730.6%\u3002", "motivation": "\u73b0\u6709TTA\u7cfb\u7edf\u5728\u8bed\u4e49\u4e00\u81f4\u6027\u65b9\u9762\u5b58\u5728\u95ee\u9898\uff0c\u5bfc\u81f4\u58f0\u97f3\u4e8b\u4ef6\u3001\u65f6\u95f4\u7ed3\u6784\u6216\u4e0a\u4e0b\u6587\u5173\u7cfb\u4e0d\u5339\u914d\u3002\u4f20\u7edf\u4e3b\u89c2\u542c\u97f3\u6d4b\u8bd5\u8017\u65f6\u4e14\u4e0d\u5ba2\u89c2\uff0c\u9700\u8981\u5ba2\u89c2\u7684\u8bed\u4e49\u4fdd\u771f\u5ea6\u8bc4\u4f30\u65b9\u6cd5\u3002", "method": "\u91c7\u7528\u6df7\u5408\u4e13\u5bb6\uff08MoE\uff09\u67b6\u6784\u4e0e\u5e8f\u5217\u4ea4\u53c9\u6ce8\u610f\u529b\uff08SeqCoAttn\uff09\u673a\u5236\uff0c\u6784\u5efa\u5ba2\u89c2\u8bc4\u4f30\u6a21\u578bMOESCORE\uff0c\u7528\u4e8e\u91cf\u5316\u8bc4\u4f30TTA\u7cfb\u7edf\u7684\u8bed\u4e49\u4fdd\u771f\u5ea6\u3002", "result": "\u5728XACLE\u6311\u6218\u8d5b\u6d4b\u8bd5\u96c6\u4e0a\u83b7\u5f97SRCC 0.6402\uff0c\u6392\u540d\u7b2c\u4e00\uff0c\u76f8\u6bd4\u57fa\u7ebf\u63d0\u534730.6%\uff0c\u4ee3\u7801\u5df2\u5f00\u6e90\u3002", "conclusion": "MOESCORE\u4e3aTTA\u7cfb\u7edf\u7684\u8bed\u4e49\u4fdd\u771f\u5ea6\u8bc4\u4f30\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5ba2\u89c2\u89e3\u51b3\u65b9\u6848\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u6709\u52a9\u4e8e\u63a8\u52a8TTA\u6280\u672f\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.06981", "categories": ["cs.SD", "eess.AS", "eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06981", "abs": "https://arxiv.org/abs/2601.06981", "authors": ["Boxiang Wang", "Zhengding Luo", "Haowen Li", "Dongyuan Shi", "Junwei Ji", "Ziyi Yang", "Woon-Seng Gan"], "title": "Directional Selective Fixed-Filter Active Noise Control Based on a Convolutional Neural Network in Reverberant Environments", "comment": null, "summary": "Selective fixed-filter active noise control (SFANC) is a novel approach capable of mitigating noise with varying frequency characteristics. It offers faster response and greater computational efficiency compared to traditional adaptive algorithms. However, spatial factors, particularly the influence of the noise source location, are often overlooked. Some existing studies have explored the impact of the direction-of-arrival (DoA) of the noise source on ANC performance, but they are mostly limited to free-field conditions and do not consider the more complex indoor reverberant environments. To address this gap, this paper proposes a learning-based directional SFANC method that incorporates the DoA of the noise source in reverberant environments. In this framework, multiple reference signals are processed by a convolutional neural network (CNN) to estimate the azimuth and elevation angles of the noise source, as well as to identify the most appropriate control filter for effective noise cancellation. Compared to traditional adaptive algorithms, the proposed approach achieves superior noise reduction with shorter response times, even in the presence of reverberations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u5b66\u4e60\u7684\u5b9a\u5411\u9009\u62e9\u6027\u56fa\u5b9a\u6ee4\u6ce2\u5668\u4e3b\u52a8\u566a\u58f0\u63a7\u5236\u65b9\u6cd5\uff0c\u5728\u6df7\u54cd\u73af\u5883\u4e2d\u7ed3\u5408\u566a\u58f0\u6e90\u5230\u8fbe\u65b9\u5411\u4fe1\u606f\uff0c\u5b9e\u73b0\u66f4\u5feb\u7684\u54cd\u5e94\u548c\u66f4\u597d\u7684\u964d\u566a\u6548\u679c\u3002", "motivation": "\u73b0\u6709\u9009\u62e9\u6027\u56fa\u5b9a\u6ee4\u6ce2\u5668\u4e3b\u52a8\u566a\u58f0\u63a7\u5236\u65b9\u6cd5\u867d\u7136\u54cd\u5e94\u5feb\u3001\u8ba1\u7b97\u6548\u7387\u9ad8\uff0c\u4f46\u5f80\u5f80\u5ffd\u7565\u7a7a\u95f4\u56e0\u7d20\uff0c\u7279\u522b\u662f\u566a\u58f0\u6e90\u4f4d\u7f6e\u7684\u5f71\u54cd\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u81ea\u7531\u573a\u6761\u4ef6\u4e0b\u7684\u5230\u8fbe\u65b9\u5411\u5f71\u54cd\uff0c\u7f3a\u4e4f\u5bf9\u66f4\u590d\u6742\u7684\u5ba4\u5185\u6df7\u54cd\u73af\u5883\u7684\u8003\u8651\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u5b66\u4e60\u7684\u5b9a\u5411SFANC\u65b9\u6cd5\uff0c\u4f7f\u7528\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u5904\u7406\u591a\u4e2a\u53c2\u8003\u4fe1\u53f7\uff0c\u540c\u65f6\u4f30\u8ba1\u566a\u58f0\u6e90\u7684\u65b9\u4f4d\u89d2\u548c\u4fef\u4ef0\u89d2\uff0c\u5e76\u9009\u62e9\u6700\u5408\u9002\u7684\u63a7\u5236\u6ee4\u6ce2\u5668\u8fdb\u884c\u6709\u6548\u566a\u58f0\u6d88\u9664\u3002", "result": "\u4e0e\u4f20\u7edf\u81ea\u9002\u5e94\u7b97\u6cd5\u76f8\u6bd4\uff0c\u8be5\u65b9\u6cd5\u5728\u6df7\u54cd\u73af\u5883\u4e0b\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u566a\u58f0\u6291\u5236\u6548\u679c\uff0c\u4e14\u54cd\u5e94\u65f6\u95f4\u66f4\u77ed\u3002", "conclusion": "\u8be5\u7814\u7a76\u6210\u529f\u5c06\u566a\u58f0\u6e90\u5230\u8fbe\u65b9\u5411\u4fe1\u606f\u6574\u5408\u5230\u9009\u62e9\u6027\u56fa\u5b9a\u6ee4\u6ce2\u5668\u4e3b\u52a8\u566a\u58f0\u63a7\u5236\u4e2d\uff0c\u7279\u522b\u662f\u5728\u6df7\u54cd\u73af\u5883\u4e0b\uff0c\u5c55\u793a\u4e86\u57fa\u4e8e\u5b66\u4e60\u7684\u65b9\u6cd5\u5728\u566a\u58f0\u63a7\u5236\u4e2d\u7684\u4f18\u52bf\u3002"}}
{"id": "2601.06094", "categories": ["eess.AS", "cs.SD", "eess.SP", "eess.SY", "q-bio.TO"], "pdf": "https://arxiv.org/pdf/2601.06094", "abs": "https://arxiv.org/abs/2601.06094", "authors": ["Samiya A Alkhairy"], "title": "Auditory Filter Behavior and Updated Estimated Constants", "comment": "19 pages, 36 equations, 10 figures, 2 tables, submitted", "summary": "Filters from the Gammatone family are often used to model auditory signal processing, but the filter constant values used to mimic human hearing are largely set to values based on historical psychoacoustic data collected several decades ago. Here, we move away from this long-standing convention, and estimate filter constants using a range of more recent reported filter characteristics (such as quality factors and ratios between quality factors and peak group delay) within a characteristics-based framework that clarifies how filter behavior is related to the underlying constants. Using a sharp-filter approximation that captures shared peak-region behavior across certain classes of filters, we analyze the range of behaviors accessible when the full degrees of freedom of the filter are utilized rather than fixing the filter order or exponent to historically prescribed values. Filter behavior is characterized using magnitude-based and phase-based characteristics and their ratios, which reveal which characteristics are informative for constraining filter constants and which are only weakly constraining. We show that these insights and estimation methods extend to multiple realizable filter classes from the Gammatone family and apply them, together with recent physiological and psychoacoustic observations, to derive constraints on and estimates for filter constants for human auditory filters. More broadly, this framework supports the design of auditory filters with arbitrary characteristic-level specifications and enables systematic assessment of how variations in filter characteristics influence auditory models, perceptual findings, and technologies that rely on auditory filterbanks.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u7279\u5f81\u6846\u67b6\u4f30\u8ba1Gammatone\u6ee4\u6ce2\u5668\u5e38\u6570\u7684\u65b9\u6cd5\uff0c\u6446\u8131\u5386\u53f2\u6570\u636e\u9650\u5236\uff0c\u5206\u6790\u6ee4\u6ce2\u5668\u884c\u4e3a\u4e0e\u5e38\u6570\u7684\u5173\u7cfb\uff0c\u5e94\u7528\u4e8e\u4eba\u7c7b\u542c\u89c9\u6ee4\u6ce2\u5668\u8bbe\u8ba1", "motivation": "Gammatone\u6ee4\u6ce2\u5668\u5e38\u7528\u4e8e\u6a21\u62df\u542c\u89c9\u4fe1\u53f7\u5904\u7406\uff0c\u4f46\u5176\u5e38\u6570\u8bbe\u7f6e\u57fa\u4e8e\u51e0\u5341\u5e74\u524d\u7684\u5386\u53f2\u5fc3\u7406\u58f0\u5b66\u6570\u636e\uff0c\u9700\u8981\u66f4\u73b0\u4ee3\u7684\u4f30\u8ba1\u65b9\u6cd5", "method": "\u4f7f\u7528\u7279\u5f81\u6846\u67b6\u4f30\u8ba1\u6ee4\u6ce2\u5668\u5e38\u6570\uff0c\u5206\u6790\u6ee4\u6ce2\u5668\u884c\u4e3a\u4e0e\u5e38\u6570\u7684\u5173\u7cfb\uff0c\u91c7\u7528\u9510\u6ee4\u6ce2\u5668\u8fd1\u4f3c\u6cd5\uff0c\u5229\u7528\u5e45\u5ea6\u548c\u76f8\u4f4d\u7279\u5f81\u53ca\u5176\u6bd4\u7387\u6765\u7ea6\u675f\u5e38\u6570", "result": "\u63ed\u793a\u4e86\u54ea\u4e9b\u7279\u5f81\u5bf9\u7ea6\u675f\u6ee4\u6ce2\u5668\u5e38\u6570\u5177\u6709\u4fe1\u606f\u6027\uff0c\u54ea\u4e9b\u7ea6\u675f\u529b\u8f83\u5f31\uff0c\u5c55\u793a\u4e86\u8be5\u65b9\u6cd5\u53ef\u6269\u5c55\u5230Gammatone\u5bb6\u65cf\u7684\u591a\u4e2a\u53ef\u5b9e\u73b0\u6ee4\u6ce2\u5668\u7c7b", "conclusion": "\u8be5\u6846\u67b6\u652f\u6301\u8bbe\u8ba1\u5177\u6709\u4efb\u610f\u7279\u5f81\u89c4\u683c\u7684\u542c\u89c9\u6ee4\u6ce2\u5668\uff0c\u5e76\u80fd\u7cfb\u7edf\u8bc4\u4f30\u6ee4\u6ce2\u5668\u7279\u5f81\u53d8\u5316\u5bf9\u542c\u89c9\u6a21\u578b\u3001\u611f\u77e5\u53d1\u73b0\u548c\u4f9d\u8d56\u542c\u89c9\u6ee4\u6ce2\u5668\u7ec4\u6280\u672f\u7684\u5f71\u54cd"}}
{"id": "2601.06068", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06068", "abs": "https://arxiv.org/abs/2601.06068", "authors": ["Yuan Gao", "Xinyu Wang", "Yifan Ren", "Yuning Zhou", "Ziwei Wang"], "title": "Dual radar-guided glide path error correction based on the Izhikevich neuron model", "comment": null, "summary": "Aiming at the ranging and angle measurement errors caused by target reflection characteristics and system noise in dual radar tracking, this paper proposes a dual radar track error correction method based on the Izhikevich neural model. The network uses the dynamic differential equation of the Izhikevich model to simulate the discharge characteristics of biological neurons. Its input layer integrates the coordinate measurement data of the dual radar, and the output layer represents the error compensation amount through the pulse emission frequency. The spike-timing-dependent plasticity (STDP) is used to adjust the neuron connection weights dynamically, and the trajectory distortion caused by system noise and radar ranging and angle measurement errors can be effectively suppressed.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eIzhikevich\u795e\u7ecf\u6a21\u578b\u7684\u53cc\u96f7\u8fbe\u822a\u8ff9\u8bef\u5dee\u6821\u6b63\u65b9\u6cd5\uff0c\u901a\u8fc7\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u52a8\u6001\u8865\u507f\u6d4b\u91cf\u8bef\u5dee", "motivation": "\u89e3\u51b3\u53cc\u96f7\u8fbe\u8ddf\u8e2a\u4e2d\u76ee\u6807\u53cd\u5c04\u7279\u6027\u548c\u7cfb\u7edf\u566a\u58f0\u5bfc\u81f4\u7684\u6d4b\u8ddd\u548c\u6d4b\u89d2\u8bef\u5dee\u95ee\u9898", "method": "\u4f7f\u7528Izhikevich\u795e\u7ecf\u6a21\u578b\u7684\u52a8\u6001\u5fae\u5206\u65b9\u7a0b\u6a21\u62df\u751f\u7269\u795e\u7ecf\u5143\u653e\u7535\u7279\u6027\uff0c\u8f93\u5165\u5c42\u6574\u5408\u53cc\u96f7\u8fbe\u5750\u6807\u6d4b\u91cf\u6570\u636e\uff0c\u8f93\u51fa\u5c42\u901a\u8fc7\u8109\u51b2\u53d1\u5c04\u9891\u7387\u8868\u793a\u8bef\u5dee\u8865\u507f\u91cf\uff0c\u91c7\u7528STDP\u89c4\u5219\u52a8\u6001\u8c03\u6574\u795e\u7ecf\u5143\u8fde\u63a5\u6743\u91cd", "result": "\u80fd\u591f\u6709\u6548\u6291\u5236\u7cfb\u7edf\u566a\u58f0\u548c\u96f7\u8fbe\u6d4b\u8ddd\u6d4b\u89d2\u8bef\u5dee\u5f15\u8d77\u7684\u8f68\u8ff9\u5931\u771f", "conclusion": "\u57fa\u4e8eIzhikevich\u795e\u7ecf\u6a21\u578b\u7684\u8109\u51b2\u795e\u7ecf\u7f51\u7edc\u65b9\u6cd5\u53ef\u4ee5\u6709\u6548\u6821\u6b63\u53cc\u96f7\u8fbe\u822a\u8ff9\u8bef\u5dee\uff0c\u63d0\u9ad8\u8ddf\u8e2a\u7cbe\u5ea6"}}
{"id": "2601.07303", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2601.07303", "abs": "https://arxiv.org/abs/2601.07303", "authors": ["Xueping Zhang", "Han Yin", "Yang Xiao", "Lin Zhang", "Ting Dang"], "title": "ESDD2: Environment-Aware Speech and Sound Deepfake Detection Challenge Evaluation Plan", "comment": null, "summary": "Audio recorded in real-world environments often contains a mixture of foreground speech and background environmental sounds. With rapid advances in text-to-speech, voice conversion, and other generation models, either component can now be modified independently. Such component-level manipulations are harder to detect, as the remaining unaltered component can mislead the systems designed for whole deepfake audio, and they often sound more natural to human listeners. To address this gap, we have proposed CompSpoofV2 dataset and a separation-enhanced joint learning framework. CompSpoofV2 is a large-scale curated dataset designed for component-level audio anti-spoofing, which contains over 250k audio samples, with a total duration of approximately 283 hours. Based on the CompSpoofV2 and the separation-enhanced joint learning framework, we launch the Environment-Aware Speech and Sound Deepfake Detection Challenge (ESDD2), focusing on component-level spoofing, where both speech and environmental sounds may be manipulated or synthesized, creating a more challenging and realistic detection scenario. The challenge will be held in conjunction with the IEEE International Conference on Multimedia and Expo 2026 (ICME 2026).", "AI": {"tldr": "\u8be5\u8bba\u6587\u9488\u5bf9\u73b0\u5b9e\u97f3\u9891\u4e2d\u8bed\u97f3\u548c\u73af\u5883\u58f0\u53ef\u80fd\u88ab\u72ec\u7acb\u7be1\u6539\u7684\u7ec4\u4ef6\u7ea7\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u96be\u9898\uff0c\u63d0\u51fa\u4e86CompSpoofV2\u6570\u636e\u96c6\u548c\u5206\u79bb\u589e\u5f3a\u8054\u5408\u5b66\u4e60\u6846\u67b6\uff0c\u5e76\u57fa\u4e8e\u6b64\u53d1\u8d77\u4e86ESDD2\u6311\u6218\u8d5b\u3002", "motivation": "\u73b0\u5b9e\u73af\u5883\u4e2d\u7684\u97f3\u9891\u901a\u5e38\u5305\u542b\u524d\u666f\u8bed\u97f3\u548c\u80cc\u666f\u73af\u5883\u58f0\uff0c\u968f\u7740\u6587\u672c\u8f6c\u8bed\u97f3\u3001\u8bed\u97f3\u8f6c\u6362\u7b49\u751f\u6210\u6a21\u578b\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u8fd9\u4e24\u4e2a\u7ec4\u4ef6\u53ef\u4ee5\u88ab\u72ec\u7acb\u7be1\u6539\u3002\u8fd9\u79cd\u7ec4\u4ef6\u7ea7\u64cd\u4f5c\u66f4\u96be\u68c0\u6d4b\uff0c\u56e0\u4e3a\u672a\u7be1\u6539\u7684\u7ec4\u4ef6\u4f1a\u8bef\u5bfc\u4f20\u7edf\u7684\u5b8c\u6574\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7cfb\u7edf\uff0c\u800c\u4e14\u542c\u8d77\u6765\u66f4\u81ea\u7136\u3002", "method": "\u63d0\u51fa\u4e86CompSpoofV2\u6570\u636e\u96c6\uff08\u5305\u542b\u8d85\u8fc725\u4e07\u4e2a\u97f3\u9891\u6837\u672c\uff0c\u603b\u65f6\u957f\u7ea6283\u5c0f\u65f6\uff09\u548c\u5206\u79bb\u589e\u5f3a\u8054\u5408\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u7ec4\u4ef6\u7ea7\u97f3\u9891\u53cd\u6b3a\u9a97\u68c0\u6d4b\u3002", "result": "\u57fa\u4e8eCompSpoofV2\u6570\u636e\u96c6\u548c\u5206\u79bb\u589e\u5f3a\u8054\u5408\u5b66\u4e60\u6846\u67b6\uff0c\u53d1\u8d77\u4e86\u73af\u5883\u611f\u77e5\u8bed\u97f3\u548c\u58f0\u97f3\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u6311\u6218\u8d5b\uff08ESDD2\uff09\uff0c\u4e13\u6ce8\u4e8e\u7ec4\u4ef6\u7ea7\u6b3a\u9a97\u68c0\u6d4b\uff0c\u8be5\u6311\u6218\u8d5b\u5c06\u5728ICME 2026\u4f1a\u8bae\u4e0a\u4e3e\u884c\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u7ec4\u4ef6\u7ea7\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7684\u7a7a\u767d\uff0c\u901a\u8fc7\u5927\u89c4\u6a21\u6570\u636e\u96c6\u548c\u8054\u5408\u5b66\u4e60\u6846\u67b6\uff0c\u4e3a\u66f4\u771f\u5b9e\u548c\u5177\u6709\u6311\u6218\u6027\u7684\u68c0\u6d4b\u573a\u666f\u63d0\u4f9b\u4e86\u89e3\u51b3\u65b9\u6848\uff0c\u5e76\u901a\u8fc7\u6311\u6218\u8d5b\u63a8\u52a8\u8be5\u9886\u57df\u7684\u53d1\u5c55\u3002"}}
{"id": "2601.06199", "categories": ["eess.AS", "cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.06199", "abs": "https://arxiv.org/abs/2601.06199", "authors": ["Junseok Lee", "Sangyong Lee", "Chang-Jae Chun"], "title": "FastSLM: Hierarchical Frame Q-Former for Effective Speech Modality Adaptation", "comment": null, "summary": "Recent advances in large language models (LLMs) have demonstrated human-expert-level capabilities, driving significant interest in their potential for achieving artificial general intelligence (AGI). In particular, there is growing momentum in adapting LLMs to various modalities, including vision, video, and speech, through the development of multimodal LLMs (MLLMs). However, existing speech-language model (SLM) research has largely overlooked cost-effective adaptation strategies for leveraging LLMs in the speech domain. In this paper, we propose FastSLM, a lightweight yet efficient SLM designed for effective understanding and reasoning over long-form speech. To address the challenge of aligning high-frame-rate speech features with LLMs, we introduce the Hierarchical Frame Querying Transformer (HFQ-Former), which compresses frame-level speech features while capturing both local and global context. Furthermore, we present a novel three-stage training strategy that enhances generalization across a wide range of speech-related tasks. Experimental results demonstrate that FastSLM achieves competitive performance compared to existing state-of-the-art models, despite operating with significantly lower FLOPs and parameter counts, while representing speech with only 1.67 tokens per second. The source code and model checkpoints are available at https://huggingface.co/okestro-ai-lab/FastSLM.", "AI": {"tldr": "FastSLM\u63d0\u51fa\u4e86\u4e00\u79cd\u8f7b\u91cf\u9ad8\u6548\u7684\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\uff0c\u901a\u8fc7\u5c42\u6b21\u5316\u5e27\u67e5\u8be2\u53d8\u6362\u5668\u548c\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\uff0c\u5728\u4f4e\u8ba1\u7b97\u6210\u672c\u4e0b\u5b9e\u73b0\u957f\u8bed\u97f3\u7684\u7406\u89e3\u548c\u63a8\u7406\u3002", "motivation": "\u73b0\u6709\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u7814\u7a76\u5ffd\u89c6\u4e86\u6210\u672c\u6548\u76ca\u9ad8\u7684LLM\u9002\u5e94\u7b56\u7565\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u957f\u8bed\u97f3\u65f6\u9762\u4e34\u9ad8\u5e27\u7387\u8bed\u97f3\u7279\u5f81\u4e0eLLM\u5bf9\u9f50\u7684\u6311\u6218\u3002", "method": "\u63d0\u51faHierarchical Frame Querying Transformer\u538b\u7f29\u5e27\u7ea7\u8bed\u97f3\u7279\u5f81\u5e76\u6355\u83b7\u5c40\u90e8\u548c\u5168\u5c40\u4e0a\u4e0b\u6587\uff0c\u91c7\u7528\u4e09\u9636\u6bb5\u8bad\u7ec3\u7b56\u7565\u589e\u5f3a\u6cdb\u5316\u80fd\u529b\u3002", "result": "FastSLM\u5728\u663e\u8457\u964d\u4f4eFLOPs\u548c\u53c2\u6570\u91cf\u7684\u60c5\u51b5\u4e0b\u8fbe\u5230SOTA\u7ade\u4e89\u6027\u80fd\uff0c\u4ec5\u7528\u6bcf\u79d21.67\u4e2atoken\u8868\u793a\u8bed\u97f3\u3002", "conclusion": "FastSLM\u5c55\u793a\u4e86\u8f7b\u91cf\u9ad8\u6548\u7684\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u53ef\u884c\u6027\uff0c\u4e3a\u6210\u672c\u654f\u611f\u7684\u8bed\u97f3\u7406\u89e3\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.06076", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06076", "abs": "https://arxiv.org/abs/2601.06076", "authors": ["Desire Guel", "Justin Pegd-Wind\u00e9 Kouraogo", "Kouka Kouakou Nakoulma"], "title": "Optimizing the 4G--5G Migration: A Simulation-Driven Roadmap for Emerging Markets", "comment": "17 pages, 7 figures, 14 Tables", "summary": "Deploying fifth-generation (5G) networks in emerging markets demands a balance between performance targets and constraints in budget, spectrum, and infrastructure. We use MATLAB simulations to quantify how radio and architectural levers - MIMO (beamforming, diversity, spatial multiplexing), carrier aggregation (CA), targeted spectrum refarming to New Radio (NR), mmWave propagation with blockage/rain, and Non-Standalone (NSA) versus Standalone (SA) cores - affect capacity, coverage, latency, and interference robustness, with D2D and M2M as complements to wide-area access. Beamforming improves cell-edge SNR by about 3-6 dB, while spatial multiplexing dominates at moderate/high SNR via multi-stream gains. Throughput scales strongly with CA: increasing from 1 to 5x20-MHz carriers raises peak rate from about 200 Mb/s to about 1 Gb/s at 30 dB SNR; water-filling adds 5-12% over equal power at mid-SNR. Targeted mid-band refarming to NR increases median throughput by 60-90% in urban and 40-70% in rural scenarios when sub-1-GHz layers preserve coverage. At 28 GHz, rain and human blockage add about 8-30 dB excess loss, so viable mmWave deployment concentrates in LOS hot zones with narrow-beam arrays and short inter-site distances. NSA delivers broader initial coverage than SA by reusing LTE/EPC, while SA becomes attractive as transport improves (e.g., >= 10 Gb/s and < 5 ms RTT) and site density grows. We synthesize these results into a practical roadmap: start NR on NSA, prioritize CA-centric spectrum strategies with focused refarming, densify selectively in demand hotspots, and migrate to SA as backhaul and device ecosystems mature.", "AI": {"tldr": "\u901a\u8fc7MATLAB\u4eff\u771f\u5206\u67905G\u5728\u65b0\u5174\u5e02\u573a\u90e8\u7f72\u7684\u5173\u952e\u6280\u672f\u6760\u6746\uff08MIMO\u3001\u8f7d\u6ce2\u805a\u5408\u3001\u9891\u8c31\u91cd\u8015\u3001\u6beb\u7c73\u6ce2\u3001NSA/SA\u6838\u5fc3\u7f51\uff09\u5bf9\u5bb9\u91cf\u3001\u8986\u76d6\u3001\u65f6\u5ef6\u548c\u5e72\u6270\u9c81\u68d2\u6027\u7684\u5f71\u54cd\uff0c\u63d0\u51fa\u4eceNSA\u8d77\u6b65\u3001\u4f18\u5148\u8f7d\u6ce2\u805a\u5408\u3001\u9009\u62e9\u6027\u5bc6\u96c6\u5316\u3001\u6700\u7ec8\u8fc1\u79fb\u5230SA\u7684\u5b9e\u7528\u8def\u7ebf\u56fe\u3002", "motivation": "\u65b0\u5174\u5e02\u573a\u90e8\u7f725G\u7f51\u7edc\u9700\u8981\u5728\u6027\u80fd\u76ee\u6807\u4e0e\u9884\u7b97\u3001\u9891\u8c31\u548c\u57fa\u7840\u8bbe\u65bd\u9650\u5236\u4e4b\u95f4\u53d6\u5f97\u5e73\u8861\u3002\u9700\u8981\u91cf\u5316\u5206\u6790\u5404\u79cd\u65e0\u7ebf\u7535\u548c\u67b6\u6784\u6760\u6746\u5bf9\u7f51\u7edc\u6027\u80fd\u7684\u5f71\u54cd\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u6307\u5bfc\u3002", "method": "\u4f7f\u7528MATLAB\u4eff\u771f\u91cf\u5316\u5206\u6790\u591a\u79cd\u6280\u672f\uff1aMIMO\uff08\u6ce2\u675f\u8d4b\u5f62\u3001\u5206\u96c6\u3001\u7a7a\u95f4\u590d\u7528\uff09\u3001\u8f7d\u6ce2\u805a\u5408\u3001\u5411\u65b0\u65e0\u7ebf\u7535\u7684\u9891\u8c31\u91cd\u8015\u3001\u6beb\u7c73\u6ce2\u4f20\u64ad\uff08\u8003\u8651\u906e\u6321/\u964d\u96e8\u5f71\u54cd\uff09\u3001NSA\u4e0eSA\u6838\u5fc3\u7f51\u67b6\u6784\uff0c\u4ee5\u53caD2D\u548cM2M\u4f5c\u4e3a\u5e7f\u57df\u63a5\u5165\u7684\u8865\u5145\u3002", "result": "\u6ce2\u675f\u8d4b\u5f62\u6539\u5584\u5c0f\u533a\u8fb9\u7f18SNR\u7ea63-6dB\uff1b\u7a7a\u95f4\u590d\u7528\u5728\u4e2d\u7b49/\u9ad8SNR\u4e0b\u901a\u8fc7\u591a\u6d41\u589e\u76ca\u5360\u4e3b\u5bfc\uff1b\u8f7d\u6ce2\u805a\u5408\u663e\u8457\u63d0\u5347\u541e\u5410\u91cf\uff081\u52305\u4e2a20MHz\u8f7d\u6ce2\u4f7f\u5cf0\u503c\u901f\u7387\u4ece200Mb/s\u63d0\u5347\u52301Gb/s\uff09\uff1b\u4e2d\u9891\u6bb5\u9891\u8c31\u91cd\u8015\u4f7f\u57ce\u5e02\u548c\u519c\u6751\u573a\u666f\u4e2d\u4f4d\u541e\u5410\u91cf\u5206\u522b\u63d0\u534760-90%\u548c40-70%\uff1b28GHz\u6beb\u7c73\u6ce2\u53d7\u964d\u96e8\u548c\u4eba\u4f53\u906e\u6321\u589e\u52a08-30dB\u989d\u5916\u635f\u8017\uff1bNSA\u6bd4SA\u63d0\u4f9b\u66f4\u5e7f\u6cdb\u7684\u521d\u59cb\u8986\u76d6\u3002", "conclusion": "\u63d0\u51fa\u5b9e\u7528\u90e8\u7f72\u8def\u7ebf\u56fe\uff1a\u4eceNSA\u5f00\u59cb\u90e8\u7f72NR\uff0c\u4f18\u5148\u91c7\u7528\u4ee5\u8f7d\u6ce2\u805a\u5408\u4e3a\u4e2d\u5fc3\u7684\u9891\u8c31\u7b56\u7565\u5e76\u8fdb\u884c\u91cd\u70b9\u9891\u8c31\u91cd\u8015\uff0c\u5728\u9700\u6c42\u70ed\u70b9\u533a\u57df\u9009\u62e9\u6027\u5bc6\u96c6\u5316\uff0c\u968f\u7740\u56de\u4f20\u548c\u8bbe\u5907\u751f\u6001\u7cfb\u7edf\u6210\u719f\u9010\u6b65\u8fc1\u79fb\u5230SA\u67b6\u6784\u3002"}}
{"id": "2601.07331", "categories": ["cs.SD", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.07331", "abs": "https://arxiv.org/abs/2601.07331", "authors": ["Yuanhe Zhang", "Jiayu Tian", "Yibo Zhang", "Shilinlu Yan", "Liang Lin", "Zhenhong Zhou", "Li Sun", "Sen Su"], "title": "SEE: Signal Embedding Energy for Quantifying Noise Interference in Large Audio Language Models", "comment": null, "summary": "Large Audio Language Models (LALMs) have been widely applied in real-time scenarios, such as in-car assistants and online meeting comprehension. In practice, audio inputs are often corrupted by device and environmental noise, leading to performance degradation. However, existing LALM studies on noise lack quantitative analysis and rely mainly on intuition and empirical observation, thus failing to understand practical robustness. To address this issue, we introduce Signal Embedding Energy (SEE), a method for quantifying the impact of noise intensity on LALM inputs, enabling the differentiation of LALM robustness in real-world deployments. SEE introduces a perspective based on structured activation subspaces derived from the model's internal representations, which more accurately captures its perception of noise than raw audio features. Across experiments, SEE exhibits a strong correlation with LALM performance, achieving a correlation of 0.98. Surprisingly, traditional audio denoising methods are only marginally effective for LALMs, and, in some cases, even increase SEE and impair performance. This suggests a mismatch between speech-centric denoising objectives and the noise sensitivity of modern LALMs. Therefore, we propose a mitigation strategy derived from SEE to denoise LALM inputs, outperforming existing denoising methods. This paper introduces a novel metric for noise quantification in LALMs, providing guidance for robustness improvements in real-world deployments.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4fe1\u53f7\u5d4c\u5165\u80fd\u91cf\uff08SEE\uff09\u65b9\u6cd5\uff0c\u7528\u4e8e\u91cf\u5316\u566a\u58f0\u5f3a\u5ea6\u5bf9\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\uff08LALM\uff09\u8f93\u5165\u7684\u5f71\u54cd\uff0c\u80fd\u51c6\u786e\u8bc4\u4f30\u6a21\u578b\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u9c81\u68d2\u6027\uff0c\u5e76\u57fa\u4e8eSEE\u63d0\u51fa\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u7684\u53bb\u566a\u7b56\u7565\u3002", "motivation": "\u5927\u578b\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u5728\u5b9e\u65f6\u573a\u666f\uff08\u5982\u8f66\u8f7d\u52a9\u624b\u3001\u5728\u7ebf\u4f1a\u8bae\u7406\u89e3\uff09\u4e2d\u5e7f\u6cdb\u5e94\u7528\uff0c\u4f46\u5b9e\u9645\u97f3\u9891\u8f93\u5165\u5e38\u53d7\u8bbe\u5907\u548c\u73af\u5883\u566a\u58f0\u5e72\u6270\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u3002\u73b0\u6709\u7814\u7a76\u7f3a\u4e4f\u5bf9\u566a\u58f0\u5f71\u54cd\u7684\u5b9a\u91cf\u5206\u6790\uff0c\u4e3b\u8981\u4f9d\u8d56\u76f4\u89c9\u548c\u7ecf\u9a8c\u89c2\u5bdf\uff0c\u65e0\u6cd5\u7406\u89e3\u5b9e\u9645\u9c81\u68d2\u6027\u3002", "method": "\u63d0\u51fa\u4fe1\u53f7\u5d4c\u5165\u80fd\u91cf\uff08SEE\uff09\u65b9\u6cd5\uff0c\u57fa\u4e8e\u6a21\u578b\u5185\u90e8\u8868\u793a\u7684\u7ed3\u6784\u5316\u6fc0\u6d3b\u5b50\u7a7a\u95f4\u6765\u91cf\u5316\u566a\u58f0\u5bf9LALM\u8f93\u5165\u7684\u5f71\u54cd\u3002\u8be5\u65b9\u6cd5\u6bd4\u539f\u59cb\u97f3\u9891\u7279\u5f81\u66f4\u51c6\u786e\u5730\u6355\u6349\u6a21\u578b\u5bf9\u566a\u58f0\u7684\u611f\u77e5\u3002\u57fa\u4e8eSEE\u8fd8\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9LALM\u7684\u53bb\u566a\u7b56\u7565\u3002", "result": "SEE\u4e0eLALM\u6027\u80fd\u8868\u73b0\u51fa\u5f3a\u76f8\u5173\u6027\uff08\u76f8\u5173\u7cfb\u65700.98\uff09\u3002\u4ee4\u4eba\u60ca\u8bb6\u7684\u662f\uff0c\u4f20\u7edf\u97f3\u9891\u53bb\u566a\u65b9\u6cd5\u5bf9LALM\u6548\u679c\u6709\u9650\uff0c\u5728\u67d0\u4e9b\u60c5\u51b5\u4e0b\u751a\u81f3\u4f1a\u589e\u52a0SEE\u5e76\u635f\u5bb3\u6027\u80fd\uff0c\u8868\u660e\u8bed\u97f3\u4e2d\u5fc3\u53bb\u566a\u76ee\u6807\u4e0e\u73b0\u4ee3LALM\u7684\u566a\u58f0\u654f\u611f\u6027\u4e0d\u5339\u914d\u3002\u57fa\u4e8eSEE\u7684\u53bb\u566a\u7b56\u7565\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u4e86LALM\u4e2d\u566a\u58f0\u91cf\u5316\u7684\u65b0\u6307\u6807SEE\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u4e2d\u7684\u9c81\u68d2\u6027\u6539\u8fdb\u63d0\u4f9b\u6307\u5bfc\u3002\u7814\u7a76\u8868\u660e\u4f20\u7edf\u53bb\u566a\u65b9\u6cd5\u4e0eLALM\u566a\u58f0\u654f\u611f\u6027\u5b58\u5728\u4e0d\u5339\u914d\uff0c\u9700\u8981\u9488\u5bf9LALM\u7279\u70b9\u8bbe\u8ba1\u53bb\u566a\u65b9\u6cd5\u3002"}}
{"id": "2601.06560", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.06560", "abs": "https://arxiv.org/abs/2601.06560", "authors": ["K. A. Shahriar"], "title": "Lightweight Resolution-Aware Audio Deepfake Detection via Cross-Scale Attention and Consistency Learning", "comment": null, "summary": "Audio deepfake detection has become increasingly challenging due to rapid advances in speech synthesis and voice conversion technologies, particularly under channel distortions, replay attacks, and real-world recording conditions. This paper proposes a resolution-aware audio deepfake detection framework that explicitly models and aligns multi-resolution spectral representations through cross-scale attention and consistency learning. Unlike conventional single-resolution or implicit feature-fusion approaches, the proposed method enforces agreement across complementary time--frequency scales. The proposed framework is evaluated on three representative benchmarks: ASVspoof 2019 (LA and PA), the Fake-or-Real (FoR) dataset, and the In-the-Wild Audio Deepfake dataset under a speaker-disjoint protocol. The method achieves near-perfect performance on ASVspoof LA (EER 0.16%), strong robustness on ASVspoof PA (EER 5.09%), FoR rerecorded audio (EER 4.54%), and in-the-wild deepfakes (AUC 0.98, EER 4.81%), significantly outperforming single-resolution and non-attention baselines under challenging conditions. The proposed model remains lightweight and efficient, requiring only 159k parameters and less than 1~GFLOP per inference, making it suitable for practical deployment. Comprehensive ablation studies confirm the critical contributions of cross-scale attention and consistency learning, while gradient-based interpretability analysis reveals that the model learns resolution-consistent and semantically meaningful spectral cues across diverse spoofing conditions. These results demonstrate that explicit cross-resolution modeling provides a principled, robust, and scalable foundation for next-generation audio deepfake detection systems.", "AI": {"tldr": "\u63d0\u51fa\u5206\u8fa8\u7387\u611f\u77e5\u7684\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u6846\u67b6\uff0c\u901a\u8fc7\u8de8\u5c3a\u5ea6\u6ce8\u610f\u529b\u548c\u4e00\u81f4\u6027\u5b66\u4e60\u663e\u5f0f\u5efa\u6a21\u591a\u5206\u8fa8\u7387\u9891\u8c31\u8868\u793a\uff0c\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u663e\u8457\u4f18\u4e8e\u5355\u5206\u8fa8\u7387\u65b9\u6cd5\u3002", "motivation": "\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u9762\u4e34\u5408\u6210\u6280\u672f\u5feb\u901f\u53d1\u5c55\u3001\u4fe1\u9053\u5931\u771f\u3001\u91cd\u653e\u653b\u51fb\u548c\u771f\u5b9e\u5f55\u5236\u6761\u4ef6\u7684\u6311\u6218\uff0c\u4f20\u7edf\u5355\u5206\u8fa8\u7387\u6216\u9690\u5f0f\u7279\u5f81\u878d\u5408\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5e94\u5bf9\u3002", "method": "\u63d0\u51fa\u5206\u8fa8\u7387\u611f\u77e5\u6846\u67b6\uff0c\u663e\u5f0f\u5efa\u6a21\u548c\u5bf9\u9f50\u591a\u5206\u8fa8\u7387\u9891\u8c31\u8868\u793a\uff0c\u901a\u8fc7\u8de8\u5c3a\u5ea6\u6ce8\u610f\u529b\u548c\u4e00\u81f4\u6027\u5b66\u4e60\u5f3a\u5236\u4e92\u8865\u65f6\u9891\u5c3a\u5ea6\u95f4\u7684\u4e00\u81f4\u6027\u3002", "result": "\u5728ASVspoof 2019\uff08LA\u548cPA\uff09\u3001FoR\u6570\u636e\u96c6\u548cIn-the-Wild Audio Deepfake\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u4f18\u5f02\u6027\u80fd\uff1aASVspoof LA EER 0.16%\uff0cASVspoof PA EER 5.09%\uff0cFoR\u91cd\u5f55\u97f3\u9891 EER 4.54%\uff0c\u91ce\u5916\u6df1\u5ea6\u4f2a\u9020 AUC 0.98/EER 4.81%\uff0c\u663e\u8457\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\u3002", "conclusion": "\u663e\u5f0f\u8de8\u5206\u8fa8\u7387\u5efa\u6a21\u4e3a\u4e0b\u4e00\u4ee3\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u7cfb\u7edf\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u3001\u9c81\u68d2\u4e14\u53ef\u6269\u5c55\u7684\u57fa\u7840\uff0c\u6a21\u578b\u8f7b\u91cf\u9ad8\u6548\uff08159k\u53c2\u6570\uff0c<1 GFLOP\uff09\uff0c\u9002\u5408\u5b9e\u9645\u90e8\u7f72\u3002"}}
{"id": "2601.06308", "categories": ["eess.SP", "cs.AR", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.06308", "abs": "https://arxiv.org/abs/2601.06308", "authors": ["Mostafa Darvishi"], "title": "Timing Fragility Aware Selective Hardening of RISCV Soft Processors on SRAM Based FPGAs", "comment": "14 pages, 2 tables, 13 figures", "summary": "Selective hardening is widely employed to improve the reliability of FPGA based soft processors while limiting the overhead of full redundancy. However, existing approaches primarily rely on architectural criticality or functional fault analysis, overlooking the impact of routing dependent timing sensitivity on processor robustness. This paper introduces a timing fragility aware selective hardening methodology for RISCV soft processors implemented on SRAM based FPGAs. Building on recent advances in in situ timing observability, the proposed approach quantifies the statistical timing sensitivity of pipeline components under controlled routing perturbations and uses this information to guide hardening decisions. Experimental results on a RISCV processor implemented on a commercial FPGA platform show that components exhibiting higher timing fragility also demonstrate increased vulnerability to routing induced delay effects. Leveraging this correlation, the proposed selective hardening strategy achieves robustness comparable to full hardening while significantly reducing area and timing overhead. These results demonstrate that timing fragility provides a practical and effective metric for reliability aware design optimization in FPGA based processor architectures.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65f6\u5e8f\u8106\u5f31\u6027\u611f\u77e5\u7684\u9009\u62e9\u6027\u52a0\u56fa\u65b9\u6cd5\uff0c\u7528\u4e8eSRAM FPGA\u4e0a\u7684RISC-V\u8f6f\u5904\u7406\u5668\uff0c\u901a\u8fc7\u91cf\u5316\u6d41\u6c34\u7ebf\u7ec4\u4ef6\u7684\u7edf\u8ba1\u65f6\u5e8f\u654f\u611f\u6027\u6765\u6307\u5bfc\u52a0\u56fa\u51b3\u7b56\uff0c\u5728\u4fdd\u6301\u53ef\u9760\u6027\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u5f00\u9500\u3002", "motivation": "\u73b0\u6709\u9009\u62e9\u6027\u52a0\u56fa\u65b9\u6cd5\u4e3b\u8981\u4f9d\u8d56\u67b6\u6784\u5173\u952e\u6027\u6216\u529f\u80fd\u6545\u969c\u5206\u6790\uff0c\u5ffd\u7565\u4e86\u8def\u7531\u76f8\u5173\u7684\u65f6\u5e8f\u654f\u611f\u6027\u5bf9\u5904\u7406\u5668\u9c81\u68d2\u6027\u7684\u5f71\u54cd\u3002\u9700\u8981\u4e00\u79cd\u8003\u8651\u65f6\u5e8f\u8106\u5f31\u6027\u7684\u65b9\u6cd5\u6765\u66f4\u6709\u6548\u5730\u6307\u5bfc\u52a0\u56fa\u51b3\u7b56\u3002", "method": "\u57fa\u4e8e\u539f\u4f4d\u65f6\u5e8f\u53ef\u89c2\u6d4b\u6027\u7684\u6700\u65b0\u8fdb\u5c55\uff0c\u91cf\u5316\u6d41\u6c34\u7ebf\u7ec4\u4ef6\u5728\u53d7\u63a7\u8def\u7531\u6270\u52a8\u4e0b\u7684\u7edf\u8ba1\u65f6\u5e8f\u654f\u611f\u6027\uff0c\u5229\u7528\u8fd9\u4e9b\u4fe1\u606f\u6307\u5bfc\u52a0\u56fa\u51b3\u7b56\u3002\u901a\u8fc7\u5206\u6790\u7ec4\u4ef6\u5bf9\u8def\u7531\u5f15\u8d77\u7684\u5ef6\u8fdf\u6548\u5e94\u7684\u8106\u5f31\u6027\u6765\u8bc6\u522b\u9700\u8981\u52a0\u56fa\u7684\u5173\u952e\u90e8\u5206\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff0c\u65f6\u5e8f\u8106\u5f31\u6027\u8f83\u9ad8\u7684\u7ec4\u4ef6\u5bf9\u8def\u7531\u5f15\u8d77\u7684\u5ef6\u8fdf\u6548\u5e94\u4e5f\u8868\u73b0\u51fa\u66f4\u9ad8\u7684\u8106\u5f31\u6027\u3002\u5229\u7528\u8fd9\u79cd\u76f8\u5173\u6027\uff0c\u63d0\u51fa\u7684\u9009\u62e9\u6027\u52a0\u56fa\u7b56\u7565\u5728\u4fdd\u6301\u4e0e\u5b8c\u5168\u52a0\u56fa\u76f8\u5f53\u7684\u9c81\u68d2\u6027\u7684\u540c\u65f6\uff0c\u663e\u8457\u51cf\u5c11\u4e86\u9762\u79ef\u548c\u65f6\u5e8f\u5f00\u9500\u3002", "conclusion": "\u65f6\u5e8f\u8106\u5f31\u6027\u4e3a\u57fa\u4e8eFPGA\u7684\u5904\u7406\u5668\u67b6\u6784\u4e2d\u7684\u53ef\u9760\u6027\u611f\u77e5\u8bbe\u8ba1\u4f18\u5316\u63d0\u4f9b\u4e86\u4e00\u4e2a\u5b9e\u7528\u4e14\u6709\u6548\u7684\u5ea6\u91cf\u6807\u51c6\uff0c\u80fd\u591f\u5728\u4e0d\u727a\u7272\u53ef\u9760\u6027\u7684\u60c5\u51b5\u4e0b\u4f18\u5316\u8d44\u6e90\u4f7f\u7528\u3002"}}
{"id": "2601.07367", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2601.07367", "abs": "https://arxiv.org/abs/2601.07367", "authors": ["Aditya Choudhary", "Anupam Purwar"], "title": "FOCAL: A Novel Benchmarking Technique for Multi-modal Agents", "comment": "We present a framework for evaluation of Multi-modal Agents consisting of Voice-to-voice model components viz. Text to Speech (TTS), Retrieval Augmented Generation (RAG) and Speech-to-text (STT)", "summary": "With the recent advancements in reasoning capa- bilities, tool calling using MCP servers and Audio Language Models (ALMs), development and integration of multi-modal agents (with voice and text support) has come to the industry forefront. Cascading pipelines for voice agents still play a central role in the industry owing to their superior reasoning capabilities facilitated by LLMs. Although, cascading pipelines often present error propagation through the pipeline. We propose a framework, FOCAL to benchmark end-to-end reasoning, component-wise error propagation and error analysis for automated as well as human-assisted testing of multi-modal agents (voice to voice + text input). We also share two novel metrics viz. Reasoning and Semantic scores to evaluate efficacy of the agent in having meaningful conversations in voice mode.", "AI": {"tldr": "FOCAL\u6846\u67b6\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u8bed\u97f3\u4ee3\u7406\u7684\u7aef\u5230\u7aef\u63a8\u7406\u80fd\u529b\u3001\u7ec4\u4ef6\u7ea7\u9519\u8bef\u4f20\u64ad\u548c\u9519\u8bef\u5206\u6790\uff0c\u652f\u6301\u81ea\u52a8\u5316\u548c\u4eba\u5de5\u8f85\u52a9\u6d4b\u8bd5\uff0c\u5e76\u63d0\u51fa\u4e86\u63a8\u7406\u548c\u8bed\u4e49\u4e24\u4e2a\u65b0\u8bc4\u4f30\u6307\u6807\u3002", "motivation": "\u968f\u7740\u63a8\u7406\u80fd\u529b\u3001MCP\u670d\u52a1\u5668\u5de5\u5177\u8c03\u7528\u548c\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u591a\u6a21\u6001\u8bed\u97f3\u4ee3\u7406\u6210\u4e3a\u884c\u4e1a\u7126\u70b9\u3002\u867d\u7136\u7ea7\u8054\u6d41\u6c34\u7ebf\u56e0\u5176LLM\u589e\u5f3a\u7684\u63a8\u7406\u80fd\u529b\u5728\u884c\u4e1a\u4e2d\u4ecd\u5360\u4e3b\u5bfc\u5730\u4f4d\uff0c\u4f46\u5b58\u5728\u9519\u8bef\u4f20\u64ad\u95ee\u9898\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u7684\u8bc4\u4f30\u6846\u67b6\u3002", "method": "\u63d0\u51fa\u4e86FOCAL\u6846\u67b6\uff0c\u7528\u4e8e\u5bf9\u591a\u6a21\u6001\u4ee3\u7406\uff08\u652f\u6301\u8bed\u97f3\u5230\u8bed\u97f3+\u6587\u672c\u8f93\u5165\uff09\u8fdb\u884c\u7aef\u5230\u7aef\u63a8\u7406\u3001\u7ec4\u4ef6\u7ea7\u9519\u8bef\u4f20\u64ad\u548c\u9519\u8bef\u5206\u6790\u7684\u57fa\u51c6\u6d4b\u8bd5\u3002\u8be5\u6846\u67b6\u652f\u6301\u81ea\u52a8\u5316\u548c\u4eba\u5de5\u8f85\u52a9\u6d4b\u8bd5\uff0c\u5e76\u5f15\u5165\u4e86\u4e24\u4e2a\u65b0\u6307\u6807\uff1a\u63a8\u7406\u5206\u6570\u548c\u8bed\u4e49\u5206\u6570\u3002", "result": "\u5f00\u53d1\u4e86FOCAL\u8bc4\u4f30\u6846\u67b6\uff0c\u80fd\u591f\u7cfb\u7edf\u8bc4\u4f30\u8bed\u97f3\u4ee3\u7406\u5728\u8bed\u97f3\u6a21\u5f0f\u4e0b\u8fdb\u884c\u6709\u610f\u4e49\u5bf9\u8bdd\u7684\u6548\u679c\u3002\u901a\u8fc7\u63a8\u7406\u5206\u6570\u548c\u8bed\u4e49\u5206\u6570\u4e24\u4e2a\u65b0\u6307\u6807\uff0c\u53ef\u4ee5\u91cf\u5316\u8bc4\u4f30\u4ee3\u7406\u7684\u5bf9\u8bdd\u8d28\u91cf\u3002", "conclusion": "FOCAL\u6846\u67b6\u4e3a\u591a\u6a21\u6001\u8bed\u97f3\u4ee3\u7406\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u8bc4\u4f30\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u7ea7\u8054\u6d41\u6c34\u7ebf\u4e2d\u7684\u9519\u8bef\u4f20\u64ad\u95ee\u9898\uff0c\u5e76\u901a\u8fc7\u65b0\u7684\u8bc4\u4f30\u6307\u6807\u63d0\u5347\u4e86\u8bed\u97f3\u5bf9\u8bdd\u8d28\u91cf\u7684\u91cf\u5316\u8bc4\u4f30\u80fd\u529b\u3002"}}
{"id": "2601.06621", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.06621", "abs": "https://arxiv.org/abs/2601.06621", "authors": ["Hao Jiang", "Edgar Choueiri"], "title": "Stereo Audio Rendering for Personal Sound Zones Using a Binaural Spatially Adaptive Neural Network (BSANN)", "comment": "Submitted to IEEE Transactions on Audio, Speech, and Language Processing (TASLP)", "summary": "A binaural rendering framework for personal sound zones (PSZs) is proposed to enable multiple head-tracked listeners to receive fully independent stereo audio programs. Current PSZ systems typically rely on monophonic rendering and therefore cannot control the left and right ears separately, which limits the quality and accuracy of spatial imaging. The proposed method employs a Binaural Spatially Adaptive Neural Network (BSANN) to generate ear-optimized loudspeaker filters that reconstruct the desired acoustic field at each ear of multiple listeners. The framework integrates anechoically measured loudspeaker frequency responses, analytically modeled transducer directivity, and rigid-sphere head-related transfer functions (HRTFs) to enhance acoustic accuracy and spatial rendering fidelity. An explicit active crosstalk cancellation (XTC) stage further improves three-dimensional spatial perception. Experiments show significant gains in measured objective performance metrics, including inter-zone isolation (IZI), inter-program isolation (IPI), and crosstalk cancellation (XTC), with log-frequency-weighted values of 10.23/10.03 dB (IZI), 11.11/9.16 dB (IPI), and 10.55/11.13 dB (XTC), respectively, over 100-20,000 Hz. The combined use of ear-wise control, accurate acoustic modeling, and integrated active XTC produces a unified rendering method that delivers greater isolation performance, increased robustness to room asymmetry, and more faithful spatial reproduction in real acoustic environments.", "AI": {"tldr": "\u63d0\u51fa\u53cc\u8033\u6e32\u67d3\u6846\u67b6\uff0c\u901a\u8fc7\u795e\u7ecf\u7f51\u7edc\u751f\u6210\u626c\u58f0\u5668\u6ee4\u6ce2\u5668\uff0c\u4e3a\u591a\u4e2a\u5934\u90e8\u8ffd\u8e2a\u542c\u4f17\u63d0\u4f9b\u72ec\u7acb\u7acb\u4f53\u58f0\u8282\u76ee\uff0c\u663e\u8457\u63d0\u5347\u9694\u79bb\u6027\u80fd\u548c\u7a7a\u95f4\u518d\u73b0\u8d28\u91cf\u3002", "motivation": "\u5f53\u524d\u4e2a\u4eba\u58f0\u533a\u7cfb\u7edf\u901a\u5e38\u91c7\u7528\u5355\u58f0\u9053\u6e32\u67d3\uff0c\u65e0\u6cd5\u72ec\u7acb\u63a7\u5236\u5de6\u53f3\u8033\uff0c\u9650\u5236\u4e86\u7a7a\u95f4\u6210\u50cf\u7684\u8d28\u91cf\u548c\u51c6\u786e\u6027\u3002\u9700\u8981\u4e3a\u591a\u4e2a\u5934\u90e8\u8ffd\u8e2a\u542c\u4f17\u63d0\u4f9b\u5b8c\u5168\u72ec\u7acb\u7684\u7acb\u4f53\u58f0\u97f3\u9891\u8282\u76ee\u3002", "method": "\u4f7f\u7528\u53cc\u8033\u7a7a\u95f4\u81ea\u9002\u5e94\u795e\u7ecf\u7f51\u7edc\u751f\u6210\u8033\u4f18\u5316\u626c\u58f0\u5668\u6ee4\u6ce2\u5668\uff0c\u6574\u5408\u65e0\u56de\u58f0\u6d4b\u91cf\u7684\u626c\u58f0\u5668\u9891\u7387\u54cd\u5e94\u3001\u5206\u6790\u5efa\u6a21\u7684\u6362\u80fd\u5668\u6307\u5411\u6027\u3001\u521a\u6027\u7403\u5934\u76f8\u5173\u4f20\u9012\u51fd\u6570\uff0c\u5e76\u5305\u542b\u663e\u5f0f\u4e3b\u52a8\u4e32\u6270\u6d88\u9664\u9636\u6bb5\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\u5728\u5ba2\u89c2\u6027\u80fd\u6307\u6807\u4e0a\u663e\u8457\u63d0\u5347\uff1a\u533a\u57df\u95f4\u9694\u79bb10.23/10.03 dB\uff0c\u8282\u76ee\u95f4\u9694\u79bb11.11/9.16 dB\uff0c\u4e32\u6270\u6d88\u966410.55/11.13 dB\uff08100-20,000 Hz\uff09\u3002", "conclusion": "\u7ed3\u5408\u8033\u7ea7\u63a7\u5236\u3001\u7cbe\u786e\u58f0\u5b66\u5efa\u6a21\u548c\u96c6\u6210\u4e3b\u52a8\u4e32\u6270\u6d88\u9664\u7684\u7edf\u4e00\u6e32\u67d3\u65b9\u6cd5\uff0c\u63d0\u4f9b\u66f4\u597d\u7684\u9694\u79bb\u6027\u80fd\u3001\u5bf9\u623f\u95f4\u4e0d\u5bf9\u79f0\u7684\u9c81\u68d2\u6027\u589e\u5f3a\uff0c\u4ee5\u53ca\u5728\u771f\u5b9e\u58f0\u5b66\u73af\u5883\u4e2d\u66f4\u5fe0\u5b9e\u7684\u58f0\u97f3\u7a7a\u95f4\u518d\u73b0\u3002"}}
{"id": "2601.06333", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06333", "abs": "https://arxiv.org/abs/2601.06333", "authors": ["Ahmed Nirjhar Alam", "Wesley Reinhart", "Rebecca Napolitano"], "title": "Building Envelope Inversion by Data-driven Interpretation of Ground Penetrating Radar", "comment": null, "summary": "Ground-penetrating radar (GPR) combines depth resolution, non-destructive operation, and broad material sensitivity, yet it has seen limited use in diagnosing building envelopes. The compact geometry of wall assemblies, where reflections from closely spaced studs, sheathing, and cladding strongly overlap, has made systematic inversion difficult. Recent advances in data-driven interpretation provide an opportunity to revisit this challenge and assess whether machine learning can reliably extract structural information from such complex signals. Here, we develop a GPR-based inversion framework that decomposes wall diagnostics into classification tasks addressing vertical (stud presence) and lateral (wall-type) variations. Alongside model development, we implement multiple feature minimization strategies - including recursive elimination, agglomerative clustering, and L0-based sparsity - to promote fidelity and interpretability. Among these approaches, the L0-based sparse neural network (SparseNN) emerges as particularly effective: it exceeds Random Forest accuracy while relying on only a fraction of the input features, each linked to identifiable dielectric interfaces. SHAP analysis further confirms that the SparseNN learns reflection patterns consistent with physical layer boundaries. In summary, this framework establishes a foundation for physically interpretable and data-efficient inversion of wall assemblies using GPR radargrams. Although defect detection is not addressed here, the ability to reconstruct intact envelope structure and isolate features tied to key elements provides a necessary baseline for future inversion and anomaly-analysis tasks.", "AI": {"tldr": "\u5f00\u53d1\u57fa\u4e8eGPR\u7684\u5899\u4f53\u8bca\u65ad\u6846\u67b6\uff0c\u4f7f\u7528\u673a\u5668\u5b66\u4e60\u5206\u89e3\u5899\u4f53\u7ed3\u6784\u8bc6\u522b\u4efb\u52a1\uff0c\u5176\u4e2dL0\u7a00\u758f\u795e\u7ecf\u7f51\u7edc\u5728\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u7684\u540c\u65f6\u663e\u8457\u51cf\u5c11\u7279\u5f81\u6570\u91cf\uff0c\u5b9e\u73b0\u7269\u7406\u53ef\u89e3\u91ca\u7684\u5899\u4f53\u7ed3\u6784\u91cd\u5efa\u3002", "motivation": "GPR\u5177\u6709\u6df1\u5ea6\u5206\u8fa8\u7387\u9ad8\u3001\u975e\u7834\u574f\u6027\u64cd\u4f5c\u548c\u6750\u6599\u654f\u611f\u6027\u5e7f\u7684\u4f18\u70b9\uff0c\u4f46\u5728\u5efa\u7b51\u56f4\u62a4\u7ed3\u6784\u8bca\u65ad\u4e2d\u5e94\u7528\u6709\u9650\u3002\u5899\u4f53\u7ec4\u4ef6\u7684\u7d27\u51d1\u51e0\u4f55\u7ed3\u6784\u5bfc\u81f4\u6765\u81ea\u7d27\u5bc6\u6392\u5217\u7684\u9f99\u9aa8\u3001\u8986\u677f\u548c\u8986\u5c42\u7684\u53cd\u5c04\u4fe1\u53f7\u4e25\u91cd\u91cd\u53e0\uff0c\u4f7f\u5f97\u7cfb\u7edf\u53cd\u6f14\u56f0\u96be\u3002\u6570\u636e\u9a71\u52a8\u89e3\u91ca\u7684\u6700\u65b0\u8fdb\u5c55\u4e3a\u91cd\u65b0\u5ba1\u89c6\u8fd9\u4e00\u6311\u6218\u63d0\u4f9b\u4e86\u673a\u4f1a\u3002", "method": "\u5f00\u53d1GPR\u53cd\u6f14\u6846\u67b6\uff0c\u5c06\u5899\u4f53\u8bca\u65ad\u5206\u89e3\u4e3a\u5904\u7406\u5782\u76f4\uff08\u9f99\u9aa8\u5b58\u5728\uff09\u548c\u6a2a\u5411\uff08\u5899\u4f53\u7c7b\u578b\uff09\u53d8\u5316\u7684\u5206\u7c7b\u4efb\u52a1\u3002\u5b9e\u65bd\u591a\u79cd\u7279\u5f81\u6700\u5c0f\u5316\u7b56\u7565\uff0c\u5305\u62ec\u9012\u5f52\u6d88\u9664\u3001\u51dd\u805a\u805a\u7c7b\u548cL0\u7a00\u758f\u5316\u3002\u7279\u522b\u5173\u6ce8L0\u7a00\u758f\u795e\u7ecf\u7f51\u7edc\uff08SparseNN\uff09\uff0c\u5b83\u5728\u51cf\u5c11\u8f93\u5165\u7279\u5f81\u7684\u540c\u65f6\u4fdd\u6301\u9ad8\u51c6\u786e\u7387\u3002", "result": "L0\u7a00\u758f\u795e\u7ecf\u7f51\u7edc\u8868\u73b0\u6700\u4f73\uff1a\u8d85\u8fc7\u968f\u673a\u68ee\u6797\u7684\u51c6\u786e\u7387\uff0c\u540c\u65f6\u4ec5\u4f9d\u8d56\u4e00\u5c0f\u90e8\u5206\u8f93\u5165\u7279\u5f81\uff0c\u6bcf\u4e2a\u7279\u5f81\u90fd\u4e0e\u53ef\u8bc6\u522b\u7684\u4ecb\u7535\u754c\u9762\u76f8\u5173\u8054\u3002SHAP\u5206\u6790\u8fdb\u4e00\u6b65\u8bc1\u5b9eSparseNN\u5b66\u4e60\u7684\u53cd\u5c04\u6a21\u5f0f\u4e0e\u7269\u7406\u5c42\u8fb9\u754c\u4e00\u81f4\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u4f7f\u7528GPR\u96f7\u8fbe\u56fe\u8fdb\u884c\u7269\u7406\u53ef\u89e3\u91ca\u548c\u6570\u636e\u9ad8\u6548\u7684\u5899\u4f53\u7ec4\u4ef6\u53cd\u6f14\u5960\u5b9a\u4e86\u57fa\u7840\u3002\u867d\u7136\u672a\u6d89\u53ca\u7f3a\u9677\u68c0\u6d4b\uff0c\u4f46\u91cd\u5efa\u5b8c\u6574\u56f4\u62a4\u7ed3\u6784\u5e76\u9694\u79bb\u4e0e\u5173\u952e\u5143\u7d20\u76f8\u5173\u7279\u5f81\u7684\u80fd\u529b\u4e3a\u672a\u6765\u7684\u53cd\u6f14\u548c\u5f02\u5e38\u5206\u6790\u4efb\u52a1\u63d0\u4f9b\u4e86\u5fc5\u8981\u57fa\u7ebf\u3002"}}
{"id": "2601.06662", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.06662", "abs": "https://arxiv.org/abs/2601.06662", "authors": ["Stefan Ciba"], "title": "Dereverberation Filter by Deconvolution with Frequency Bin Specific Faded Impulse Response", "comment": "8 pages, 3 figures, github repository with code and audio", "summary": "This work introduces a robust single-channel inverse filter for dereverberation of non-ideal recordings, validated on real audio. The developed method focuses on the calculation and modification of a discrete impulse response in order to filter the characteristics from a known digital single channel recording setup and room characteristics such as early reflections and reverberations. The aim is a dryer and clearer signal reconstruction, which ideally would be the direct-path signal. The time domain impulse response is calculated from the cepstral domain and faded by means of frequency bin specific exponential decay in the spectrum. The decay rates are obtained by using the blind estimates of reverberation time ratio between recorded output and test signals for each frequency bin. The modified impulse response does filter a recorded audio-signal by deconvolution. The blind estimation is well known and stands out for its robustness to noise and non-idealities. Estimation of a direct path signal is key to many applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9c81\u68d2\u7684\u5355\u901a\u9053\u9006\u6ee4\u6ce2\u5668\u7528\u4e8e\u975e\u7406\u60f3\u5f55\u97f3\u7684\u53bb\u6df7\u54cd\uff0c\u901a\u8fc7\u8ba1\u7b97\u548c\u4fee\u6539\u79bb\u6563\u8109\u51b2\u54cd\u5e94\u6765\u6d88\u9664\u5df2\u77e5\u5f55\u97f3\u8bbe\u5907\u548c\u623f\u95f4\u7279\u6027\uff08\u5982\u65e9\u671f\u53cd\u5c04\u548c\u6df7\u54cd\uff09\uff0c\u5b9e\u73b0\u66f4\u5e72\u66f4\u6e05\u6670\u7684\u4fe1\u53f7\u91cd\u5efa\u3002", "motivation": "\u5b9e\u9645\u5f55\u97f3\u73af\u5883\u4e2d\u5b58\u5728\u623f\u95f4\u6df7\u54cd\u548c\u65e9\u671f\u53cd\u5c04\u7b49\u975e\u7406\u60f3\u7279\u6027\uff0c\u5f71\u54cd\u4fe1\u53f7\u8d28\u91cf\u3002\u76f4\u63a5\u8def\u5f84\u4fe1\u53f7\u7684\u4f30\u8ba1\u5bf9\u8bb8\u591a\u5e94\u7528\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u4e00\u79cd\u9c81\u68d2\u7684\u65b9\u6cd5\u6765\u53bb\u9664\u8fd9\u4e9b\u6df7\u54cd\u6548\u5e94\u3002", "method": "\u4ece\u5012\u8c31\u57df\u8ba1\u7b97\u65f6\u57df\u8109\u51b2\u54cd\u5e94\uff0c\u901a\u8fc7\u9891\u7387\u4ed3\u7279\u5b9a\u7684\u6307\u6570\u8870\u51cf\u5728\u9891\u8c31\u4e2d\u8fdb\u884c\u8870\u51cf\u5904\u7406\u3002\u8870\u51cf\u7387\u4f7f\u7528\u76f2\u4f30\u8ba1\u7684\u6bcf\u4e2a\u9891\u7387\u4ed3\u7684\u6df7\u54cd\u65f6\u95f4\u6bd4\uff08\u5f55\u97f3\u8f93\u51fa\u4e0e\u6d4b\u8bd5\u4fe1\u53f7\u4e4b\u95f4\uff09\u83b7\u5f97\u3002\u4fee\u6539\u540e\u7684\u8109\u51b2\u54cd\u5e94\u901a\u8fc7\u53cd\u5377\u79ef\u6765\u6ee4\u6ce2\u5f55\u97f3\u97f3\u9891\u4fe1\u53f7\u3002", "result": "\u8be5\u65b9\u6cd5\u5728\u771f\u5b9e\u97f3\u9891\u4e0a\u8fdb\u884c\u4e86\u9a8c\u8bc1\uff0c\u80fd\u591f\u6709\u6548\u53bb\u9664\u6df7\u54cd\u7279\u6027\uff0c\u5b9e\u73b0\u66f4\u5e72\u66f4\u6e05\u6670\u7684\u4fe1\u53f7\u91cd\u5efa\uff0c\u7406\u60f3\u60c5\u51b5\u4e0b\u63a5\u8fd1\u76f4\u63a5\u8def\u5f84\u4fe1\u53f7\u3002", "conclusion": "\u63d0\u51fa\u7684\u5355\u901a\u9053\u9006\u6ee4\u6ce2\u5668\u65b9\u6cd5\u9c81\u68d2\u6027\u5f3a\uff0c\u5bf9\u566a\u58f0\u548c\u975e\u7406\u60f3\u6027\u5177\u6709\u826f\u597d\u9002\u5e94\u6027\uff0c\u4e3a\u53bb\u6df7\u54cd\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u9700\u8981\u76f4\u63a5\u8def\u5f84\u4fe1\u53f7\u4f30\u8ba1\u7684\u5404\u79cd\u5e94\u7528\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.06396", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06396", "abs": "https://arxiv.org/abs/2601.06396", "authors": ["Mengqi Ma", "Aihua Xia"], "title": "Performance Analysis for Wireless Localization with Random Sensor Network", "comment": null, "summary": "Accurate wireless localization underpins applications from autonomous systems to smart infrastructure. We study the mean-squared error (MSE) and conditional MSE (CMSE) of a practical fusion-based estimator in d-dimensional, stationary isotropic (translation- and rotation-invariant) random sensor networks, where a central processor combines received-signal-strength (RSS) and angle-of-arrival (AOA) measurements to infer a target's position. Our contributions are twofold. First, we establish an approximation theorem: when measurement noise is sufficiently large, the joint law of RSS and AOA observations under a broad class of stationary isotropic deployments is, in distribution, indistinguishable from that induced by a homogeneous Poisson point process (PPP). Second, leveraging this equivalence, we investigate a homogeneous PPP-based sensor network. We propose a fusion-based estimator in which a central processor aggregates RSS and AOA measurements from a set of spatially distributed sensors to infer the target position. For this PPP deployment within a finite observation region, we derive tractable analytical upper bounds for both the MSE and CMSE, establishing explicit scaling laws with respect to sensor density, observation radius, and noise variance. The approximation theorem then certifies these PPP-based bounds as reasonable proxies for non-Poisson deployments in noisy regimes. Overall, the results translate deployment and sensing parameters into achievable accuracy targets and provide robust, cost-aware guidance for the design of next-generation location-aware wireless networks.", "AI": {"tldr": "\u8bba\u6587\u7814\u7a76\u4e86\u65e0\u7ebf\u5b9a\u4f4d\u4e2d\u57fa\u4e8eRSS\u548cAOA\u878d\u5408\u4f30\u8ba1\u5668\u7684\u6027\u80fd\u5206\u6790\uff0c\u8bc1\u660e\u4e86\u5728\u566a\u58f0\u8f83\u5927\u65f6\uff0c\u4efb\u610f\u5e73\u7a33\u5404\u5411\u540c\u6027\u4f20\u611f\u5668\u7f51\u7edc\u7684\u89c2\u6d4b\u5206\u5e03\u4e0e\u9f50\u6b21\u6cca\u677e\u70b9\u8fc7\u7a0b\u65e0\u6cd5\u533a\u5206\uff0c\u5e76\u57fa\u4e8ePPP\u63a8\u5bfc\u4e86MSE\u548cCMSE\u7684\u53ef\u89e3\u6790\u4e0a\u754c\u3002", "motivation": "\u65e0\u7ebf\u7cbe\u786e\u5b9a\u4f4d\u662f\u81ea\u52a8\u9a7e\u9a76\u548c\u667a\u80fd\u57fa\u7840\u8bbe\u65bd\u7b49\u5e94\u7528\u7684\u57fa\u7840\uff0c\u9700\u8981\u7406\u89e3\u4f20\u611f\u5668\u90e8\u7f72\u548c\u6d4b\u91cf\u53c2\u6570\u5982\u4f55\u5f71\u54cd\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u4f4d\u7f6e\u611f\u77e5\u65e0\u7ebf\u7f51\u7edc\u63d0\u4f9b\u8bbe\u8ba1\u6307\u5bfc\u3002", "method": "1) \u5efa\u7acb\u8fd1\u4f3c\u5b9a\u7406\uff1a\u8bc1\u660e\u5728\u566a\u58f0\u8db3\u591f\u5927\u65f6\uff0c\u4efb\u610f\u5e73\u7a33\u5404\u5411\u540c\u6027\u4f20\u611f\u5668\u7f51\u7edc\u7684\u89c2\u6d4b\u5206\u5e03\u4e0e\u9f50\u6b21\u6cca\u677e\u70b9\u8fc7\u7a0b(PPP)\u65e0\u6cd5\u533a\u5206\uff1b2) \u57fa\u4e8ePPP\u90e8\u7f72\uff0c\u63d0\u51fa\u878d\u5408RSS\u548cAOA\u6d4b\u91cf\u7684\u96c6\u4e2d\u5f0f\u4f30\u8ba1\u5668\uff0c\u5728\u6709\u9650\u89c2\u6d4b\u533a\u57df\u5185\u63a8\u5bfcMSE\u548cCMSE\u7684\u53ef\u89e3\u6790\u4e0a\u754c\u3002", "result": "\u63a8\u5bfc\u51faPPP\u90e8\u7f72\u4e0bMSE\u548cCMSE\u7684\u663e\u5f0f\u4e0a\u754c\uff0c\u5efa\u7acb\u4e86\u4e0e\u4f20\u611f\u5668\u5bc6\u5ea6\u3001\u89c2\u6d4b\u534a\u5f84\u548c\u566a\u58f0\u65b9\u5dee\u7684\u6807\u5ea6\u5173\u7cfb\u3002\u8fd1\u4f3c\u5b9a\u7406\u8bc1\u660e\u8fd9\u4e9bPPP\u4e0a\u754c\u5728\u566a\u58f0\u8f83\u5927\u65f6\u53ef\u4ee5\u4f5c\u4e3a\u975e\u6cca\u677e\u90e8\u7f72\u7684\u5408\u7406\u4ee3\u7406\u3002", "conclusion": "\u7814\u7a76\u7ed3\u679c\u4e3a\u65e0\u7ebf\u5b9a\u4f4d\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u90e8\u7f72\u548c\u611f\u77e5\u53c2\u6570\u5230\u7cbe\u5ea6\u76ee\u6807\u7684\u8f6c\u6362\u5173\u7cfb\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u4f4d\u7f6e\u611f\u77e5\u7f51\u7edc\u63d0\u4f9b\u4e86\u9c81\u68d2\u4e14\u6210\u672c\u611f\u77e5\u7684\u8bbe\u8ba1\u6307\u5bfc\u3002"}}
{"id": "2601.06896", "categories": ["eess.AS", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.06896", "abs": "https://arxiv.org/abs/2601.06896", "authors": ["Mingyue Huo", "Yiwen Shao", "Yuheng Zhang"], "title": "TagSpeech: End-to-End Multi-Speaker ASR and Diarization with Fine-Grained Temporal Grounding", "comment": null, "summary": "We present TagSpeech, a unified LLM-based framework that utilizes Temporal Anchor Grounding for joint multi-speaker ASR and diarization. The framework is built on two key designs: (1) decoupled semantic and speaker streams fine-tuned via Serialized Output Training (SOT) to learn turn-taking dynamics; and (2) an interleaved time anchor mechanism that not only supports fine-grained timestamp prediction but also acts as a synchronization signal between semantic understanding and speaker tracking. Compared to previous works that primarily focus on speaker-attributed ASR or implicit diarization, TagSpeech addresses the challenge of fine-grained speaker-content alignment and explicitly models \"who spoke what and when\" in an end-to-end manner. Experiments on AMI and AliMeeting benchmarks demonstrate that our method achieves consistent improvements in Diarization Error Rate (DER) over strong end-to-end baselines, including Qwen-Omni and Gemini, particularly in handling complex speech overlaps. Moreover, TagSpeech employs a parameter-efficient training paradigm in which the LLM backbone is frozen and only lightweight projectors are trained, resulting in strong performance with low computational cost.", "AI": {"tldr": "TagSpeech\u662f\u4e00\u4e2a\u57fa\u4e8eLLM\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u901a\u8fc7\u65f6\u95f4\u951a\u70b9\u5b9a\u4f4d\u5b9e\u73b0\u591a\u8bf4\u8bdd\u4ebaASR\u548c\u8bf4\u8bdd\u4eba\u65e5\u5fd7\u7684\u8054\u5408\u5904\u7406\uff0c\u91c7\u7528\u89e3\u8026\u7684\u8bed\u4e49\u548c\u8bf4\u8bdd\u4eba\u6d41\u8bbe\u8ba1\uff0c\u5728\u4fdd\u6301\u53c2\u6570\u9ad8\u6548\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4eDER\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u4e3b\u8981\u5173\u6ce8\u8bf4\u8bdd\u4eba\u5f52\u5c5eASR\u6216\u9690\u5f0f\u65e5\u5fd7\uff0c\u96be\u4ee5\u5b9e\u73b0\u7ec6\u7c92\u5ea6\u7684\u8bf4\u8bdd\u4eba-\u5185\u5bb9\u5bf9\u9f50\u3002TagSpeech\u65e8\u5728\u660e\u786e\u5efa\u6a21\"\u8c01\u5728\u4f55\u65f6\u8bf4\u4e86\u4ec0\u4e48\"\uff0c\u4ee5\u7aef\u5230\u7aef\u65b9\u5f0f\u89e3\u51b3\u590d\u6742\u8bed\u97f3\u91cd\u53e0\u7684\u6311\u6218\u3002", "method": "1) \u901a\u8fc7\u5e8f\u5217\u5316\u8f93\u51fa\u8bad\u7ec3(SOT)\u5fae\u8c03\u89e3\u8026\u7684\u8bed\u4e49\u548c\u8bf4\u8bdd\u4eba\u6d41\uff0c\u5b66\u4e60\u8f6e\u8f6c\u52a8\u6001\uff1b2) \u4ea4\u9519\u65f6\u95f4\u951a\u673a\u5236\u652f\u6301\u7ec6\u7c92\u5ea6\u65f6\u95f4\u6233\u9884\u6d4b\uff0c\u5e76\u4f5c\u4e3a\u8bed\u4e49\u7406\u89e3\u548c\u8bf4\u8bdd\u4eba\u8ddf\u8e2a\u7684\u540c\u6b65\u4fe1\u53f7\uff1b3) \u53c2\u6570\u9ad8\u6548\u8bad\u7ec3\u8303\u5f0f\uff1a\u51bb\u7ed3LLM\u9aa8\u5e72\uff0c\u4ec5\u8bad\u7ec3\u8f7b\u91cf\u7ea7\u6295\u5f71\u5668\u3002", "result": "\u5728AMI\u548cAliMeeting\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4Qwen-Omni\u548cGemini\u7b49\u5f3a\u7aef\u5230\u7aef\u57fa\u7ebf\uff0cTagSpeech\u5728DER\u4e0a\u53d6\u5f97\u4e00\u81f4\u6539\u8fdb\uff0c\u7279\u522b\u662f\u5728\u5904\u7406\u590d\u6742\u8bed\u97f3\u91cd\u53e0\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u540c\u65f6\u8ba1\u7b97\u6210\u672c\u4f4e\u3002", "conclusion": "TagSpeech\u901a\u8fc7\u65f6\u95f4\u951a\u70b9\u5b9a\u4f4d\u548c\u6d41\u89e3\u8026\u8bbe\u8ba1\uff0c\u4e3a\u591a\u8bf4\u8bdd\u4ebaASR\u548c\u65e5\u5fd7\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u5728\u4fdd\u6301\u53c2\u6570\u9ad8\u6548\u7684\u540c\u65f6\u5b9e\u73b0\u4e86\u7ec6\u7c92\u5ea6\u7684\u8bf4\u8bdd\u4eba-\u5185\u5bb9\u5bf9\u9f50\uff0c\u663e\u8457\u63d0\u5347\u4e86\u590d\u6742\u91cd\u53e0\u573a\u666f\u7684\u6027\u80fd\u3002"}}
{"id": "2601.06467", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06467", "abs": "https://arxiv.org/abs/2601.06467", "authors": ["Sijie Ji", "Weiying Hou", "Chenshu Wu"], "title": "Neuro-Wideband WiFi Sensing via Self-Conditioned CSI Extrapolation", "comment": "In Submission", "summary": "WiFi sensing has suffered from the limited bandwidths designated for its original communication purpose, leading to fundamental limits in multipath resolution and thus multi-user sensing. Unfortunately, it is practically prohibitive to obtain large bandwidths on commercial WiFi, considering the conflict between the limited spectrum and the crowded networks. In this paper, we present Neuro-Wideband (NWB), a completely different paradigm that enables wideband WiFi sensing without specialized hardware or extra channel measurements. Our key insight is that any physical measurement of channel state information (CSI) inherently encapsulates multipath parameters, which, while unsolvable in isolation, can be transformed into an expanded form of CSI (eCSI) approximating measurements over a broader bandwidth. To ground this insight, we propose WUKONG to address NWB as a unique self-conditioned learning problem that can be trained by using any existing CSI data as self-labeled samples. WUKONG introduces a novel deep learning framework by integrating Transformer and Diffusion models, which captures sample-specific multipath parameters and transfers this sample-level knowledge to the outcome eCSI. We conduct real-world experiments to evaluate WUKONG on diverse WiFi signals across protocols and bandwidths. The results show the promising effectiveness of NWB, which is further demonstrated through case studies on localization and multi-person breathing monitoring using eCSI. Overall, the proposed NWB promises a practical pathway toward realizing wideband WiFi sensing on commodity hardware, expanding the design space of wireless sensing systems.", "AI": {"tldr": "\u63d0\u51faNeuro-Wideband (NWB)\u65b0\u8303\u5f0f\uff0c\u65e0\u9700\u4e13\u7528\u786c\u4ef6\u6216\u989d\u5916\u4fe1\u9053\u6d4b\u91cf\u5373\u53ef\u5b9e\u73b0\u5bbd\u5e26WiFi\u611f\u77e5\uff0c\u901a\u8fc7\u6df1\u5ea6\u5b66\u4e60\u5c06\u6709\u9650\u5e26\u5bbdCSI\u8f6c\u6362\u4e3a\u6269\u5c55CSI(eCSI)\u8fd1\u4f3c\u5bbd\u5e26\u6d4b\u91cf", "motivation": "\u4f20\u7edfWiFi\u611f\u77e5\u53d7\u9650\u4e8e\u901a\u4fe1\u5e26\u5bbd\uff0c\u5bfc\u81f4\u591a\u5f84\u5206\u8fa8\u7387\u548c\u591a\u7528\u6237\u611f\u77e5\u80fd\u529b\u53d7\u9650\u3002\u5546\u7528WiFi\u96be\u4ee5\u83b7\u5f97\u5927\u5e26\u5bbd\uff0c\u5b58\u5728\u9891\u8c31\u6709\u9650\u4e0e\u7f51\u7edc\u62e5\u6324\u7684\u77db\u76fe", "method": "\u63d0\u51faNWB\u8303\u5f0f\uff0c\u6838\u5fc3\u662fWUKONG\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u5c06CSI\u8f6c\u6362\u4e3a\u6269\u5c55CSI(eCSI)\u3002\u91c7\u7528Transformer\u548cDiffusion\u6a21\u578b\uff0c\u901a\u8fc7\u81ea\u6761\u4ef6\u5b66\u4e60\u5229\u7528\u73b0\u6709CSI\u6570\u636e\u4f5c\u4e3a\u81ea\u6807\u8bb0\u6837\u672c\uff0c\u6355\u83b7\u6837\u672c\u7279\u5b9a\u591a\u5f84\u53c2\u6570\u5e76\u8f6c\u79fb\u5230eCSI", "result": "\u5728\u591a\u79cdWiFi\u4fe1\u53f7\u3001\u534f\u8bae\u548c\u5e26\u5bbd\u4e0b\u8fdb\u884c\u771f\u5b9e\u4e16\u754c\u5b9e\u9a8c\uff0cNWB\u8868\u73b0\u51fa\u826f\u597d\u6548\u679c\u3002\u901a\u8fc7\u5b9a\u4f4d\u548c\u591a\u4eba\u5458\u547c\u5438\u76d1\u6d4b\u6848\u4f8b\u9a8c\u8bc1\u4e86eCSI\u7684\u6709\u6548\u6027", "conclusion": "NWB\u4e3a\u5728\u5546\u7528\u786c\u4ef6\u4e0a\u5b9e\u73b0\u5bbd\u5e26WiFi\u611f\u77e5\u63d0\u4f9b\u4e86\u5b9e\u7528\u9014\u5f84\uff0c\u6269\u5c55\u4e86\u65e0\u7ebf\u611f\u77e5\u7cfb\u7edf\u7684\u8bbe\u8ba1\u7a7a\u95f4"}}
{"id": "2601.07014", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2601.07014", "abs": "https://arxiv.org/abs/2601.07014", "authors": ["Mohd Mujtaba Akhtar", "Girish", "Muskaan Singh"], "title": "DIVINE: Coordinating Multimodal Disentangled Representations for Oro-Facial Neurological Disorder Assessment", "comment": "Accepted to EACL 2026", "summary": "In this study, we present a multimodal framework for predicting neuro-facial disorders by capturing both vocal and facial cues. We hypothesize that explicitly disentangling shared and modality-specific representations within multimodal foundation model embeddings can enhance clinical interpretability and generalization. To validate this hypothesis, we propose DIVINE a fully disentangled multimodal framework that operates on representations extracted from state-of-the-art (SOTA) audio and video foundation models, incorporating hierarchical variational bottlenecks, sparse gated fusion, and learnable symptom tokens. DIVINE operates in a multitask learning setup to jointly predict diagnostic categories (Healthy Control,ALS, Stroke) and severity levels (Mild, Moderate, Severe). The model is trained using synchronized audio and video inputs and evaluated on the Toronto NeuroFace dataset under full (audio-video) as well as single-modality (audio- only and video-only) test conditions. Our proposed approach, DIVINE achieves SOTA result, with the DeepSeek-VL2 and TRILLsson combination reaching 98.26% accuracy and 97.51% F1-score. Under modality-constrained scenarios, the framework performs well, showing strong generalization when tested with video-only or audio-only inputs. It consistently yields superior performance compared to unimodal models and baseline fusion techniques. To the best of our knowledge, DIVINE is the first framework that combines cross-modal disentanglement, adaptive fusion, and multitask learning to comprehensively assess neurological disorders using synchronized speech and facial video.", "AI": {"tldr": "DIVINE\u662f\u4e00\u4e2a\u591a\u6a21\u6001\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u5171\u4eab\u548c\u6a21\u6001\u7279\u5b9a\u8868\u5f81\u6765\u9884\u6d4b\u795e\u7ecf\u9762\u90e8\u75be\u75c5\uff0c\u5728\u97f3\u9891-\u89c6\u9891\u8f93\u5165\u4e0b\u8fbe\u523098.26%\u51c6\u786e\u7387\uff0c\u5728\u5355\u6a21\u6001\u6761\u4ef6\u4e0b\u4e5f\u8868\u73b0\u826f\u597d\u3002", "motivation": "\u73b0\u6709\u65b9\u6cd5\u7f3a\u4e4f\u5bf9\u591a\u6a21\u6001\u8868\u5f81\u4e2d\u5171\u4eab\u548c\u6a21\u6001\u7279\u5b9a\u4fe1\u606f\u7684\u663e\u5f0f\u89e3\u8026\uff0c\u8fd9\u9650\u5236\u4e86\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u548c\u6cdb\u5316\u80fd\u529b\u3002\u4f5c\u8005\u5047\u8bbe\u901a\u8fc7\u89e3\u8026\u8fd9\u4e9b\u8868\u5f81\u53ef\u4ee5\u63d0\u5347\u795e\u7ecf\u9762\u90e8\u75be\u75c5\u9884\u6d4b\u7684\u6027\u80fd\u3002", "method": "\u63d0\u51faDIVINE\u6846\u67b6\uff1a1) \u4eceSOTA\u97f3\u9891\u548c\u89c6\u9891\u57fa\u7840\u6a21\u578b\u4e2d\u63d0\u53d6\u8868\u5f81\uff1b2) \u4f7f\u7528\u5206\u5c42\u53d8\u5206\u74f6\u9888\u8fdb\u884c\u89e3\u8026\uff1b3) \u7a00\u758f\u95e8\u63a7\u878d\u5408\uff1b4) \u53ef\u5b66\u4e60\u75c7\u72b6\u6807\u8bb0\uff1b5) \u591a\u4efb\u52a1\u5b66\u4e60\u540c\u65f6\u9884\u6d4b\u8bca\u65ad\u7c7b\u522b\u548c\u4e25\u91cd\u7a0b\u5ea6\u3002", "result": "\u5728Toronto NeuroFace\u6570\u636e\u96c6\u4e0a\uff0cDeepSeek-VL2\u548cTRILLsson\u7ec4\u5408\u8fbe\u523098.26%\u51c6\u786e\u7387\u548c97.51% F1\u5206\u6570\u3002\u5728\u5355\u6a21\u6001\u6d4b\u8bd5\u6761\u4ef6\u4e0b\uff08\u4ec5\u97f3\u9891\u6216\u4ec5\u89c6\u9891\uff09\u4e5f\u8868\u73b0\u826f\u597d\uff0c\u4f18\u4e8e\u5355\u6a21\u6001\u6a21\u578b\u548c\u57fa\u7ebf\u878d\u5408\u65b9\u6cd5\u3002", "conclusion": "DIVINE\u662f\u9996\u4e2a\u7ed3\u5408\u8de8\u6a21\u6001\u89e3\u8026\u3001\u81ea\u9002\u5e94\u878d\u5408\u548c\u591a\u4efb\u52a1\u5b66\u4e60\u7684\u6846\u67b6\uff0c\u80fd\u5168\u9762\u8bc4\u4f30\u795e\u7ecf\u75be\u75c5\uff0c\u5728\u5b8c\u6574\u548c\u53d7\u9650\u6a21\u6001\u6761\u4ef6\u4e0b\u90fd\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u4e34\u5e8a\u53ef\u89e3\u91ca\u6027\u548c\u5f3a\u6cdb\u5316\u80fd\u529b\u3002"}}
{"id": "2601.06483", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06483", "abs": "https://arxiv.org/abs/2601.06483", "authors": ["\u00d6zlem Tu\u011ffe Demir", "Emil Bj\u00f6rnson"], "title": "Joint Impact of ADC and Fronthaul Quantization in Cell-Free Massive MIMO-OFDM Uplink", "comment": "Presented at Asilomar Conference on Signals, Systems, and Computers, 2025, 5 pages, 2 figures", "summary": "In the uplink of a cell-free massive MIMO system, quantization affects performance in two key domains: the time-domain distortion introduced by finite-resolution analog-to-digital converters (ADCs) at the access points (APs), and the fronthaul quantization of signals sent to the central processing unit (CPU). Although quantizing twice may seem redundant, the ADC quantization in orthogonal frequency-division duplex (OFDM) systems appears in the time domain, and one must then convert to the frequency domain, where quantization can be applied only to the signals at active subcarriers. This reduces fronthaul load and avoids unnecessary distortion, since the ADC output spans all OFDM samples while only a subset of subcarriers carries useful information.\n  While both quantization effects have been extensively studied in narrowband systems, their joint impact in practical wideband OFDM-based cell-free massive MIMO remains largely unexplored. This paper addresses the gap by modeling the joint distortion and proposing a fronthaul strategy in which each AP processes the received signal to reduce quantization artifacts before transmission. We develop an efficient estimation algorithm that reconstructs the unquantized time-domain signal prior to fronthaul transmission and evaluate its effectiveness. The proposed design offers new insights for implementing efficient, quantization-aware uplink transmission in wideband cell-free architectures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u5bbd\u5e26OFDM\u65e0\u5c0f\u533a\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u4e0a\u884c\u94fe\u8def\u7684\u4e24\u7ea7\u91cf\u5316\u95ee\u9898\uff1aADC\u65f6\u57df\u91cf\u5316\u4e0e\u524d\u4f20\u91cf\u5316\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u5728AP\u7aef\u5904\u7406\u63a5\u6536\u4fe1\u53f7\u4ee5\u51cf\u5c11\u91cf\u5316\u5931\u771f\u7684\u524d\u4f20\u7b56\u7565\u3002", "motivation": "\u5728\u65e0\u5c0f\u533a\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u4e0a\u884c\u94fe\u8def\u4e2d\uff0c\u91cf\u5316\u5f71\u54cd\u6027\u80fd\u7684\u4e24\u4e2a\u5173\u952e\u9886\u57df\uff1aAP\u7aef\u6709\u9650\u5206\u8fa8\u7387ADC\u5f15\u5165\u7684\u65f6\u57df\u5931\u771f\uff0c\u4ee5\u53ca\u53d1\u9001\u5230CPU\u7684\u524d\u4f20\u4fe1\u53f7\u91cf\u5316\u3002\u867d\u7136\u91cf\u5316\u4e24\u6b21\u770b\u4f3c\u5197\u4f59\uff0c\u4f46\u5728OFDM\u7cfb\u7edf\u4e2d\uff0cADC\u91cf\u5316\u51fa\u73b0\u5728\u65f6\u57df\uff0c\u7136\u540e\u9700\u8981\u8f6c\u6362\u5230\u9891\u57df\uff0c\u800c\u91cf\u5316\u53ef\u4ee5\u4ec5\u5e94\u7528\u4e8e\u6d3b\u8dc3\u5b50\u8f7d\u6ce2\u7684\u4fe1\u53f7\u3002\u8fd9\u51cf\u5c11\u4e86\u524d\u4f20\u8d1f\u8f7d\u5e76\u907f\u514d\u4e86\u4e0d\u5fc5\u8981\u7684\u5931\u771f\u3002\u7136\u800c\uff0c\u5728\u5bbd\u5e26OFDM\u65e0\u5c0f\u533a\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\uff0c\u8fd9\u4e24\u79cd\u91cf\u5316\u6548\u5e94\u7684\u8054\u5408\u5f71\u54cd\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u8bba\u6587\u901a\u8fc7\u5efa\u6a21\u8054\u5408\u5931\u771f\uff0c\u63d0\u51fa\u4e86\u4e00\u79cd\u524d\u4f20\u7b56\u7565\uff1a\u6bcf\u4e2aAP\u5904\u7406\u63a5\u6536\u4fe1\u53f7\u4ee5\u51cf\u5c11\u91cf\u5316\u4f2a\u5f71\u540e\u518d\u4f20\u8f93\u3002\u5f00\u53d1\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u4f30\u8ba1\u7b97\u6cd5\uff0c\u5728\u53d1\u9001\u5230\u524d\u4f20\u4e4b\u524d\u91cd\u5efa\u672a\u91cf\u5316\u7684\u65f6\u57df\u4fe1\u53f7\u3002", "result": "\u63d0\u51fa\u7684\u8bbe\u8ba1\u4e3a\u5728\u5bbd\u5e26\u65e0\u5c0f\u533a\u67b6\u6784\u4e2d\u5b9e\u73b0\u9ad8\u6548\u3001\u91cf\u5316\u611f\u77e5\u7684\u4e0a\u884c\u94fe\u8def\u4f20\u8f93\u63d0\u4f9b\u4e86\u65b0\u7684\u89c1\u89e3\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u5bbd\u5e26OFDM\u65e0\u5c0f\u533a\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u8054\u5408\u91cf\u5316\u6548\u5e94\u7814\u7a76\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u524d\u4f20\u5904\u7406\u7b56\u7565\u80fd\u591f\u6709\u6548\u51cf\u5c11\u91cf\u5316\u5931\u771f\uff0c\u4e3a\u5b9e\u73b0\u9ad8\u6548\u7684\u4e0a\u884c\u94fe\u8def\u4f20\u8f93\u63d0\u4f9b\u4e86\u91cd\u8981\u6307\u5bfc\u3002"}}
{"id": "2601.07064", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2601.07064", "abs": "https://arxiv.org/abs/2601.07064", "authors": ["Mohd Mujtaba Akhtar", "Girish", "Farhan Sheth", "Muskaan Singh"], "title": "Bridging Attribution and Open-Set Detection using Graph-Augmented Instance Learning in Synthetic Speech", "comment": "Accepted to EACL 2026", "summary": "We propose a unified framework for not only attributing synthetic speech to its source but also for detecting speech generated by synthesizers that were not encountered during training. This requires methods that move beyond simple detection to support both detailed forensic analysis and open-set generalization. To address this, we introduce SIGNAL, a hybrid framework that combines speech foundation models (SFMs) with graph-based modeling and open-set-aware inference. Our framework integrates Graph Neural Networks (GNNs) and a k-Nearest Neighbor (KNN) classifier, allowing it to capture meaningful relationships between utterances and recognize speech that doesn`t belong to any known generator. It constructs a query-conditioned graph over generator class prototypes, enabling the GNN to reason over relationships among candidate generators, while the KNN branch supports open-set detection via confidence-based thresholding. We evaluate SIGNAL using the DiffSSD dataset, which offers a diverse mix of real speech and synthetic audio from both open-source and commercial diffusion-based TTS systems. To further assess generalization, we also test on the SingFake benchmark. Our results show that SIGNAL consistently improves performance across both tasks, with Mamba-based embeddings delivering especially strong results. To the best of our knowledge, this is the first study to unify graph-based learning and open-set detection for tracing synthetic speech back to its origin.", "AI": {"tldr": "\u63d0\u51faSIGNAL\u6846\u67b6\uff0c\u7ed3\u5408\u8bed\u97f3\u57fa\u7840\u6a21\u578b\u3001\u56fe\u795e\u7ecf\u7f51\u7edc\u548cKNN\u5206\u7c7b\u5668\uff0c\u5b9e\u73b0\u5408\u6210\u8bed\u97f3\u6eaf\u6e90\u548c\u672a\u77e5\u5408\u6210\u5668\u68c0\u6d4b\u7684\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u5f53\u524d\u5408\u6210\u8bed\u97f3\u68c0\u6d4b\u65b9\u6cd5\u4e3b\u8981\u5c40\u9650\u4e8e\u5df2\u77e5\u5408\u6210\u5668\u7684\u68c0\u6d4b\uff0c\u7f3a\u4e4f\u5bf9\u672a\u77e5\u5408\u6210\u5668\u7684\u8bc6\u522b\u80fd\u529b\uff0c\u540c\u65f6\u65e0\u6cd5\u63d0\u4f9b\u8be6\u7ec6\u7684\u53d6\u8bc1\u5206\u6790\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u8fdb\u884c\u8be6\u7ec6\u6cd5\u533b\u5206\u6790\u53c8\u80fd\u5b9e\u73b0\u5f00\u653e\u96c6\u6cdb\u5316\u7684\u7edf\u4e00\u6846\u67b6\u3002", "method": "\u63d0\u51faSIGNAL\u6df7\u5408\u6846\u67b6\uff1a1) \u4f7f\u7528\u8bed\u97f3\u57fa\u7840\u6a21\u578b\u63d0\u53d6\u7279\u5f81\uff1b2) \u6784\u5efa\u57fa\u4e8e\u751f\u6210\u5668\u7c7b\u522b\u539f\u578b\u7684\u67e5\u8be2\u6761\u4ef6\u56fe\uff0c\u5229\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u6355\u6349\u8bdd\u8bed\u95f4\u5173\u7cfb\uff1b3) \u7ed3\u5408KNN\u5206\u7c7b\u5668\u8fdb\u884c\u5f00\u653e\u96c6\u68c0\u6d4b\uff0c\u901a\u8fc7\u7f6e\u4fe1\u5ea6\u9608\u503c\u8bc6\u522b\u672a\u77e5\u5408\u6210\u5668\u3002", "result": "\u5728DiffSSD\u6570\u636e\u96c6\uff08\u5305\u542b\u771f\u5b9e\u8bed\u97f3\u548c\u6269\u6563TTS\u7cfb\u7edf\u5408\u6210\u97f3\u9891\uff09\u548cSingFake\u57fa\u51c6\u6d4b\u8bd5\u4e0a\u8bc4\u4f30\uff0cSIGNAL\u5728\u4e24\u4e2a\u4efb\u52a1\u4e0a\u5747\u8868\u73b0\u4f18\u5f02\uff0c\u7279\u522b\u662f\u57fa\u4e8eMamba\u7684\u5d4c\u5165\u65b9\u6cd5\u6548\u679c\u663e\u8457\u3002", "conclusion": "SIGNAL\u9996\u6b21\u5c06\u56fe\u5b66\u4e60\u548c\u5f00\u653e\u96c6\u68c0\u6d4b\u7edf\u4e00\u5e94\u7528\u4e8e\u5408\u6210\u8bed\u97f3\u6eaf\u6e90\uff0c\u4e3a\u5408\u6210\u8bed\u97f3\u7684\u6cd5\u533b\u5206\u6790\u548c\u672a\u77e5\u5408\u6210\u5668\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u91cd\u8981\u7684\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.06486", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.06486", "abs": "https://arxiv.org/abs/2601.06486", "authors": ["\u00d6zlem Tu\u011ffe Demir", "Emil Bj\u00f6rnson"], "title": "Cell-Free Massive MIMO with Hardware-Impaired Wireless Fronthaul", "comment": "Presented at Asilomar Conference on Signals, Systems, and Computers, 2025, 5 pages, 4 figures", "summary": "Cell-free massive MIMO (multiple-input multiple-output) enhances spectral and energy efficiency compared to conventional cellular networks by enabling joint transmission and reception across a large number of distributed access points (APs). Since these APs are envisioned to be low-cost and densely deployed, hardware impairments, stemming from non-ideal radio-frequency (RF) chains, are unavoidable. While existing studies primarily address hardware impairments on the access side, the impact of hardware impairments on the wireless fronthaul link has remained largely unexplored. In this work, we fill this important gap by introducing a novel amplify-and-forward (AF) based wireless fronthauling scheme tailored for cell-free massive MIMO. Focusing on the uplink, we develop an analytical framework that jointly models the hardware impairments at both the APs and the fronthaul transceivers, derives the resulting end-to-end distorted signal expression, and quantifies the individual contribution of each impairment to the spectral efficiency. Furthermore, we design distortion-aware linear combiners that optimally mitigate these effects. Numerical results demonstrate significant performance gains from distortion-aware processing and illustrate the potential of the proposed AF fronthauling scheme as a cost-effective enabler for future cell-free architectures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u9488\u5bf9\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u7684\u65b0\u578b\u653e\u5927\u8f6c\u53d1\u65e0\u7ebf\u524d\u4f20\u65b9\u6848\uff0c\u8054\u5408\u5efa\u6a21AP\u548c\u524d\u4f20\u6536\u53d1\u5668\u7684\u786c\u4ef6\u635f\u4f24\uff0c\u5e76\u8bbe\u8ba1\u4e86\u635f\u4f24\u611f\u77e5\u7684\u7ebf\u6027\u7ec4\u5408\u5668\u6765\u4f18\u5316\u6027\u80fd\u3002", "motivation": "\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u901a\u8fc7\u5206\u5e03\u5f0fAP\u8054\u5408\u4f20\u8f93\u63d0\u5347\u9891\u8c31\u548c\u80fd\u91cf\u6548\u7387\uff0c\u4f46\u4f4e\u6210\u672c\u5bc6\u96c6\u90e8\u7f72\u5bfc\u81f4\u786c\u4ef6\u635f\u4f24\u4e0d\u53ef\u907f\u514d\u3002\u73b0\u6709\u7814\u7a76\u4e3b\u8981\u5173\u6ce8\u63a5\u5165\u4fa7\u635f\u4f24\uff0c\u800c\u65e0\u7ebf\u524d\u4f20\u94fe\u8def\u7684\u786c\u4ef6\u635f\u4f24\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u653e\u5927\u8f6c\u53d1(AF)\u7684\u65e0\u7ebf\u524d\u4f20\u65b9\u6848\uff0c\u5f00\u53d1\u5206\u6790\u6846\u67b6\u8054\u5408\u5efa\u6a21AP\u548c\u524d\u4f20\u6536\u53d1\u5668\u7684\u786c\u4ef6\u635f\u4f24\uff0c\u63a8\u5bfc\u7aef\u5230\u7aef\u5931\u771f\u4fe1\u53f7\u8868\u8fbe\u5f0f\uff0c\u91cf\u5316\u5404\u635f\u4f24\u5bf9\u9891\u8c31\u6548\u7387\u7684\u8d21\u732e\uff0c\u5e76\u8bbe\u8ba1\u635f\u4f24\u611f\u77e5\u7ebf\u6027\u7ec4\u5408\u5668\u6765\u4f18\u5316\u7f13\u89e3\u8fd9\u4e9b\u5f71\u54cd\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u635f\u4f24\u611f\u77e5\u5904\u7406\u5e26\u6765\u663e\u8457\u7684\u6027\u80fd\u589e\u76ca\uff0c\u9a8c\u8bc1\u4e86\u6240\u63d0\u51fa\u7684AF\u524d\u4f20\u65b9\u6848\u4f5c\u4e3a\u672a\u6765\u65e0\u8702\u7a9d\u67b6\u6784\u6210\u672c\u6548\u76ca\u4f7f\u80fd\u5668\u7684\u6f5c\u529b\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u4e2d\u65e0\u7ebf\u524d\u4f20\u94fe\u8def\u786c\u4ef6\u635f\u4f24\u5efa\u6a21\u7684\u91cd\u8981\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u635f\u4f24\u611f\u77e5\u5904\u7406\u65b9\u6848\u80fd\u6709\u6548\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u4f4e\u6210\u672c\u65e0\u8702\u7a9d\u67b6\u6784\u90e8\u7f72\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.07237", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2601.07237", "abs": "https://arxiv.org/abs/2601.07237", "authors": ["Guobin Ma", "Yuxuan Xia", "Jixun Yao", "Huixin Xue", "Hexin Liu", "Shuai Wang", "Hao Liu", "Lei Xie"], "title": "The ICASSP 2026 Automatic Song Aesthetics Evaluation Challenge", "comment": "Official summary paper for the ICASSP 2026 ASAE Challenge", "summary": "This paper summarizes the ICASSP 2026 Automatic Song Aesthetics Evaluation (ASAE) Challenge, which focuses on predicting the subjective aesthetic scores of AI-generated songs. The challenge consists of two tracks: Track 1 targets the prediction of the overall musicality score, while Track 2 focuses on predicting five fine-grained aesthetic scores. The challenge attracted strong interest from the research community and received numerous submissions from both academia and industry. Top-performing systems significantly surpassed the official baseline, demonstrating substantial progress in aligning objective metrics with human aesthetic preferences. The outcomes establish a standardized benchmark and advance human-aligned evaluation methodologies for modern music generation systems.", "AI": {"tldr": "ICASSP 2026 ASAE\u6311\u6218\u8d5b\u603b\u7ed3\uff1a\u4e13\u6ce8\u4e8e\u9884\u6d4bAI\u751f\u6210\u6b4c\u66f2\u7684\u4e3b\u89c2\u7f8e\u5b66\u8bc4\u5206\uff0c\u5305\u542b\u6574\u4f53\u97f3\u4e50\u6027\u8bc4\u5206\u548c\u4e94\u4e2a\u7ec6\u7c92\u5ea6\u7f8e\u5b66\u8bc4\u5206\u4e24\u4e2a\u8d5b\u9053\uff0c\u53c2\u8d5b\u7cfb\u7edf\u663e\u8457\u8d85\u8d8a\u5b98\u65b9\u57fa\u7ebf\uff0c\u5efa\u7acb\u4e86\u6807\u51c6\u5316\u57fa\u51c6\u5e76\u63a8\u8fdb\u4e86\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\u7684\u4eba\u7c7b\u5bf9\u9f50\u8bc4\u4f30\u65b9\u6cd5\u3002", "motivation": "\u968f\u7740AI\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\u7684\u5feb\u901f\u53d1\u5c55\uff0c\u9700\u8981\u5efa\u7acb\u80fd\u591f\u51c6\u786e\u8bc4\u4f30AI\u751f\u6210\u6b4c\u66f2\u7f8e\u5b66\u8d28\u91cf\u7684\u6807\u51c6\u5316\u65b9\u6cd5\uff0c\u4ee5\u66f4\u597d\u5730\u5c06\u5ba2\u89c2\u6307\u6807\u4e0e\u4eba\u7c7b\u7f8e\u5b66\u504f\u597d\u5bf9\u9f50\u3002", "method": "\u6311\u6218\u8d5b\u8bbe\u7f6e\u4e24\u4e2a\u8d5b\u9053\uff1aTrack 1\u9884\u6d4b\u6574\u4f53\u97f3\u4e50\u6027\u8bc4\u5206\uff0cTrack 2\u9884\u6d4b\u4e94\u4e2a\u7ec6\u7c92\u5ea6\u7f8e\u5b66\u8bc4\u5206\u3002\u53c2\u8d5b\u8005\u5f00\u53d1\u7cfb\u7edf\u9884\u6d4bAI\u751f\u6210\u6b4c\u66f2\u7684\u4e3b\u89c2\u7f8e\u5b66\u5206\u6570\u3002", "result": "\u6311\u6218\u8d5b\u5438\u5f15\u4e86\u5b66\u672f\u754c\u548c\u5de5\u4e1a\u754c\u7684\u5e7f\u6cdb\u53c2\u4e0e\uff0c\u63d0\u4ea4\u4e86\u5927\u91cf\u4f5c\u54c1\u3002\u8868\u73b0\u6700\u4f73\u7684\u7cfb\u7edf\u663e\u8457\u8d85\u8d8a\u4e86\u5b98\u65b9\u57fa\u7ebf\uff0c\u5728\u5c06\u5ba2\u89c2\u6307\u6807\u4e0e\u4eba\u7c7b\u7f8e\u5b66\u504f\u597d\u5bf9\u9f50\u65b9\u9762\u53d6\u5f97\u4e86\u5b9e\u8d28\u6027\u8fdb\u5c55\u3002", "conclusion": "\u8be5\u6311\u6218\u8d5b\u4e3a\u73b0\u4ee3\u97f3\u4e50\u751f\u6210\u7cfb\u7edf\u5efa\u7acb\u4e86\u6807\u51c6\u5316\u57fa\u51c6\uff0c\u5e76\u63a8\u8fdb\u4e86\u4eba\u7c7b\u5bf9\u9f50\u7684\u8bc4\u4f30\u65b9\u6cd5\u5b66\u53d1\u5c55\uff0c\u4e3aAI\u751f\u6210\u97f3\u4e50\u7684\u7f8e\u5b66\u8bc4\u4f30\u63d0\u4f9b\u4e86\u91cd\u8981\u53c2\u8003\u6846\u67b6\u3002"}}
{"id": "2601.06645", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06645", "abs": "https://arxiv.org/abs/2601.06645", "authors": ["Juan Miguel L\u00f3pez Alcaraz", "Xicot\u00e9ncatl L\u00f3pez Moran", "Erick D\u00e1vila Zaragoza", "Claas H\u00e4ndel", "Richard Koebe", "Wilhelm Haverkamp", "Nils Strodthoff"], "title": "A Multimodal Deep Learning Framework for Predicting ICU Deterioration: Integrating ECG Waveforms with Clinical Data and Clinician Benchmarking", "comment": "23 pages, 8 figures, source code under https://github.com/AI4HealthUOL/MDS-ICU", "summary": "Artificial intelligence holds strong potential to support clinical decision making in intensive care units where timely and accurate risk assessment is critical. However, many existing models focus on isolated outcomes or limited data types, while clinicians integrate longitudinal history, real time physiology, and heterogeneous clinical information. To address this gap, we developed MDS ICU, a unified multimodal machine learning framework that fuses routinely collected data including demographics, biometrics, vital signs, laboratory values, ECG waveforms, surgical procedures, and medical device usage to provide continuous predictive support during ICU stays. Using 63001 samples from 27062 patients in MIMIC IV, we trained a deep learning architecture that combines structured state space S4 encoders for ECG waveforms with multilayer perceptron RealMLP encoders for tabular data to jointly predict 33 clinically relevant outcomes spanning mortality, organ dysfunction, medication needs, and acute deterioration. The model achieved strong discrimination with AUROCs of 0.90 for 24 hour mortality, 0.92 for sedative administration, 0.97 for invasive mechanical ventilation, and 0.93 for coagulation dysfunction. Calibration analysis showed close agreement between predicted and observed risks, with consistent gains from ECG waveform integration. Comparisons with clinicians and large language models showed that model predictions alone outperformed both, and that providing model outputs as decision support further improved their performance. These results demonstrate that multimodal AI can deliver clinically meaningful risk stratification across diverse ICU outcomes while augmenting rather than replacing clinical expertise, establishing a scalable foundation for precision critical care decision support.", "AI": {"tldr": "MDS ICU\u662f\u4e00\u4e2a\u591a\u6a21\u6001AI\u6846\u67b6\uff0c\u878d\u5408ICU\u5e38\u89c4\u6570\u636e\uff08\u4eba\u53e3\u7edf\u8ba1\u3001\u751f\u547d\u4f53\u5f81\u3001\u5b9e\u9a8c\u5ba4\u503c\u3001ECG\u6ce2\u5f62\u7b49\uff09\u6765\u9884\u6d4b33\u79cd\u4e34\u5e8a\u7ed3\u5c40\uff0c\u5728MIMIC-IV\u6570\u636e\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u80fd\u63d0\u5347\u4e34\u5e8a\u51b3\u7b56\u652f\u6301\u3002", "motivation": "\u73b0\u6709ICU\u98ce\u9669\u9884\u6d4b\u6a21\u578b\u901a\u5e38\u5173\u6ce8\u5355\u4e00\u7ed3\u5c40\u6216\u6709\u9650\u6570\u636e\u7c7b\u578b\uff0c\u800c\u4e34\u5e8a\u533b\u751f\u9700\u8981\u6574\u5408\u7eb5\u5411\u5386\u53f2\u3001\u5b9e\u65f6\u751f\u7406\u6570\u636e\u548c\u5f02\u8d28\u4e34\u5e8a\u4fe1\u606f\u3002\u9700\u8981\u5f00\u53d1\u80fd\u878d\u5408\u591a\u6a21\u6001\u6570\u636e\u7684\u7edf\u4e00\u6846\u67b6\u6765\u652f\u6301ICU\u4e34\u5e8a\u51b3\u7b56\u3002", "method": "\u5f00\u53d1MDS ICU\u591a\u6a21\u6001\u673a\u5668\u5b66\u4e60\u6846\u67b6\uff0c\u878d\u5408\u4eba\u53e3\u7edf\u8ba1\u3001\u751f\u7269\u7279\u5f81\u3001\u751f\u547d\u4f53\u5f81\u3001\u5b9e\u9a8c\u5ba4\u503c\u3001ECG\u6ce2\u5f62\u3001\u624b\u672f\u8fc7\u7a0b\u548c\u533b\u7597\u8bbe\u5907\u4f7f\u7528\u7b49\u5e38\u89c4\u6570\u636e\u3002\u4f7f\u7528MIMIC-IV\u768463001\u4e2a\u6837\u672c\uff0827062\u540d\u60a3\u8005\uff09\uff0c\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u67b6\u6784\uff1aECG\u6ce2\u5f62\u4f7f\u7528\u7ed3\u6784\u5316\u72b6\u6001\u7a7a\u95f4S4\u7f16\u7801\u5668\uff0c\u8868\u683c\u6570\u636e\u4f7f\u7528\u591a\u5c42\u611f\u77e5\u5668RealMLP\u7f16\u7801\u5668\uff0c\u8054\u5408\u9884\u6d4b33\u79cd\u4e34\u5e8a\u76f8\u5173\u7ed3\u5c40\u3002", "result": "\u6a21\u578b\u8868\u73b0\u51fa\u5f3a\u533a\u5206\u80fd\u529b\uff1a24\u5c0f\u65f6\u6b7b\u4ea1\u7387AUROC 0.90\uff0c\u9547\u9759\u5242\u4f7f\u75280.92\uff0c\u6709\u521b\u673a\u68b0\u901a\u6c140.97\uff0c\u51dd\u8840\u529f\u80fd\u969c\u788d0.93\u3002\u6821\u51c6\u5206\u6790\u663e\u793a\u9884\u6d4b\u98ce\u9669\u4e0e\u5b9e\u9645\u98ce\u9669\u9ad8\u5ea6\u4e00\u81f4\uff0cECG\u6ce2\u5f62\u6574\u5408\u5e26\u6765\u6301\u7eed\u589e\u76ca\u3002\u6a21\u578b\u9884\u6d4b\u5355\u72ec\u4f18\u4e8e\u4e34\u5e8a\u533b\u751f\u548c\u5927\u578b\u8bed\u8a00\u6a21\u578b\uff0c\u63d0\u4f9b\u6a21\u578b\u8f93\u51fa\u4f5c\u4e3a\u51b3\u7b56\u652f\u6301\u80fd\u8fdb\u4e00\u6b65\u63d0\u5347\u4e34\u5e8a\u533b\u751f\u8868\u73b0\u3002", "conclusion": "\u591a\u6a21\u6001AI\u80fd\u5728ICU\u4e2d\u63d0\u4f9b\u6709\u4e34\u5e8a\u610f\u4e49\u7684\u98ce\u9669\u5206\u5c42\uff0c\u8986\u76d6\u591a\u79cd\u7ed3\u5c40\uff0c\u540c\u65f6\u589e\u5f3a\u800c\u975e\u66ff\u4ee3\u4e34\u5e8a\u4e13\u4e1a\u77e5\u8bc6\uff0c\u4e3a\u7cbe\u51c6\u91cd\u75c7\u76d1\u62a4\u51b3\u7b56\u652f\u6301\u5efa\u7acb\u4e86\u53ef\u6269\u5c55\u7684\u57fa\u7840\u3002"}}
{"id": "2601.07481", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2601.07481", "abs": "https://arxiv.org/abs/2601.07481", "authors": ["Satoshi Hoshika", "Takahiro Iwami", "Akira Omoto"], "title": "Directional reflection modeling via wavenumber-domain reflection coefficient for 3D acoustic field simulation", "comment": "Submitted to Proceedings of Meetings on Acoustics (PoMA)", "summary": "This study proposes a framework for incorporating wavenumber-domain acoustic reflection coefficients into sound field analysis to characterize direction-dependent material reflection and scattering phenomena. The reflection coefficient is defined as the amplitude ratio between incident and reflected waves for each propagation direction and is estimated from spatial Fourier transforms of the incident and reflected sound fields. The resulting wavenumber-domain reflection coefficients are converted into an acoustic admittance representation that is directly compatible with numerical methods such as the Boundary Element Method (BEM), enabling simulation of reflections beyond simple specular components. Unlike conventional extended reaction models, the proposed approach avoids explicit modeling of the material interior. This significantly reduces computational cost while allowing direct use of measured data, empirical models, or user-defined directional reflection characteristics. The validity of the proposed formulation was previously demonstrated by the authors through two-dimensional sound field simulations, in which accurate reproduction of direction-dependent reflection behavior was confirmed. In the present work, the framework is extended to three-dimensional analysis, demonstrating its applicability to more realistic and complex acoustic environments. The proposed approach provides a practical and flexible tool for simulating direction-dependent acoustic reflections and scattering, with potential applications in architectural acoustics, material characterization, and noise control.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u6ce2\u6570\u57df\u58f0\u53cd\u5c04\u7cfb\u6570\u7eb3\u5165\u58f0\u573a\u5206\u6790\u7684\u6846\u67b6\uff0c\u7528\u4e8e\u8868\u5f81\u65b9\u5411\u76f8\u5173\u7684\u6750\u6599\u53cd\u5c04\u548c\u6563\u5c04\u73b0\u8c61\uff0c\u5e76\u6269\u5c55\u5230\u4e09\u7ef4\u5206\u6790", "motivation": "\u4f20\u7edf\u6269\u5c55\u53cd\u5e94\u6a21\u578b\u9700\u8981\u663e\u5f0f\u5efa\u6a21\u6750\u6599\u5185\u90e8\u7ed3\u6784\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u9700\u8981\u4e00\u79cd\u66f4\u5b9e\u7528\u7075\u6d3b\u7684\u65b9\u6cd5\u6765\u6a21\u62df\u65b9\u5411\u76f8\u5173\u7684\u58f0\u53cd\u5c04\u548c\u6563\u5c04\u73b0\u8c61", "method": "\u901a\u8fc7\u7a7a\u95f4\u5085\u91cc\u53f6\u53d8\u6362\u4ece\u5165\u5c04\u548c\u53cd\u5c04\u58f0\u573a\u4f30\u8ba1\u6bcf\u4e2a\u4f20\u64ad\u65b9\u5411\u7684\u53cd\u5c04\u7cfb\u6570\uff0c\u8f6c\u6362\u4e3a\u4e0e\u8fb9\u754c\u5143\u6cd5\u517c\u5bb9\u7684\u58f0\u5bfc\u7eb3\u8868\u793a\uff0c\u907f\u514d\u663e\u5f0f\u5efa\u6a21\u6750\u6599\u5185\u90e8", "result": "\u6846\u67b6\u5df2\u901a\u8fc7\u4e8c\u7ef4\u58f0\u573a\u4eff\u771f\u9a8c\u8bc1\uff0c\u80fd\u51c6\u786e\u518d\u73b0\u65b9\u5411\u76f8\u5173\u53cd\u5c04\u884c\u4e3a\u3002\u672c\u7814\u7a76\u5c06\u5176\u6269\u5c55\u5230\u4e09\u7ef4\u5206\u6790\uff0c\u8bc1\u660e\u9002\u7528\u4e8e\u66f4\u771f\u5b9e\u590d\u6742\u7684\u58f0\u5b66\u73af\u5883", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u6a21\u62df\u65b9\u5411\u76f8\u5173\u58f0\u53cd\u5c04\u548c\u6563\u5c04\u63d0\u4f9b\u4e86\u5b9e\u7528\u7075\u6d3b\u7684\u5de5\u5177\uff0c\u5728\u5efa\u7b51\u58f0\u5b66\u3001\u6750\u6599\u8868\u5f81\u548c\u566a\u58f0\u63a7\u5236\u4e2d\u5177\u6709\u5e94\u7528\u6f5c\u529b"}}
{"id": "2601.06796", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06796", "abs": "https://arxiv.org/abs/2601.06796", "authors": ["Yasir Ali", "Tayyab Manzoor", "Huan Yang", "Chenhang Yan", "Yuanqing Xia"], "title": "Artificial Intelligence Driven Channel Coding and Resource Optimization for Wireless Networks", "comment": "50 Pages", "summary": "The ongoing evolution of 5G and its enhanced version, 5G+, has significantly transformed the telecommunications landscape, driving an unprecedented demand for ultra-high-speed data transmission, ultra-low latency, and resilient connectivity. These capabilities are essential for enabling mission-critical applications such as the Internet of Things, autonomous vehicles, and smart city infrastructures. This paper investigates the important role of Artificial Intelligence (AI) in addressing the key challenges faced by 5G/5G+ networks, including interference mitigation, dynamic resource allocation, and maintaining seamless network operation. The study particularly focuses on AI-driven innovations in coding theory, which offer advanced solutions to the limitations of conventional error correction and modulation techniques. By employing deep learning, reinforcement learning, and neural network-based approaches, this research demonstrates significant advancements in error correction performance, decoding efficiency, and adaptive transmission strategies. Additionally, the integration of AI with emerging technologies, such as massive multiple-input and multiple-output, intelligent reflecting surfaces, and privacy-enhancing mechanisms, is discussed, highlighting their potential to propel the next generation of wireless networks. This paper also provides insights into the transformative impact of AI on modern wireless communication, establishing a foundation for scalable, adaptive, and more efficient network architectures.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63a2\u8ba8\u4e86\u4eba\u5de5\u667a\u80fd\u57285G/5G+\u7f51\u7edc\u4e2d\u7684\u5173\u952e\u4f5c\u7528\uff0c\u7279\u522b\u662f\u5728\u7f16\u7801\u7406\u8bba\u3001\u5e72\u6270\u7f13\u89e3\u548c\u52a8\u6001\u8d44\u6e90\u5206\u914d\u65b9\u9762\u7684\u521b\u65b0\u5e94\u7528\uff0c\u5c55\u793a\u4e86AI\u5982\u4f55\u63a8\u52a8\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u7684\u53d1\u5c55\u3002", "motivation": "5G/5G+\u7f51\u7edc\u7684\u53d1\u5c55\u5e26\u6765\u4e86\u5bf9\u8d85\u9ad8\u901f\u6570\u636e\u4f20\u8f93\u3001\u8d85\u4f4e\u5ef6\u8fdf\u548c\u5f39\u6027\u8fde\u63a5\u7684\u5de8\u5927\u9700\u6c42\uff0c\u8fd9\u4e9b\u80fd\u529b\u5bf9\u4e8e\u7269\u8054\u7f51\u3001\u81ea\u52a8\u9a7e\u9a76\u6c7d\u8f66\u548c\u667a\u6167\u57ce\u5e02\u7b49\u5173\u952e\u5e94\u7528\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u6280\u672f\u5728\u5904\u7406\u5e72\u6270\u7f13\u89e3\u3001\u52a8\u6001\u8d44\u6e90\u5206\u914d\u548c\u7f51\u7edc\u65e0\u7f1d\u8fd0\u884c\u65b9\u9762\u9762\u4e34\u6311\u6218\uff0c\u9700\u8981AI\u63d0\u4f9b\u521b\u65b0\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u7814\u7a76\u91c7\u7528\u6df1\u5ea6\u5b66\u4e60\u3001\u5f3a\u5316\u5b66\u4e60\u548c\u57fa\u4e8e\u795e\u7ecf\u7f51\u7edc\u7684\u65b9\u6cd5\uff0c\u7279\u522b\u5173\u6ce8AI\u9a71\u52a8\u7684\u7f16\u7801\u7406\u8bba\u521b\u65b0\uff0c\u4ee5\u6539\u8fdb\u4f20\u7edf\u7ea0\u9519\u548c\u8c03\u5236\u6280\u672f\u3002\u540c\u65f6\u63a2\u8ba8\u4e86AI\u4e0e\u5927\u89c4\u6a21MIMO\u3001\u667a\u80fd\u53cd\u5c04\u9762\u3001\u9690\u79c1\u589e\u5f3a\u673a\u5236\u7b49\u65b0\u5174\u6280\u672f\u7684\u96c6\u6210\u3002", "result": "\u7814\u7a76\u8868\u660eAI\u65b9\u6cd5\u5728\u7ea0\u9519\u6027\u80fd\u3001\u89e3\u7801\u6548\u7387\u548c\u81ea\u9002\u5e94\u4f20\u8f93\u7b56\u7565\u65b9\u9762\u53d6\u5f97\u4e86\u663e\u8457\u8fdb\u5c55\u3002AI\u4e0e\u65b0\u5174\u6280\u672f\u7684\u7ed3\u5408\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u3001\u81ea\u9002\u5e94\u548c\u66f4\u9ad8\u6548\u7684\u7f51\u7edc\u67b6\u6784\u57fa\u7840\u3002", "conclusion": "\u4eba\u5de5\u667a\u80fd\u57285G/5G+\u7f51\u7edc\u4e2d\u626e\u6f14\u7740\u53d8\u9769\u6027\u89d2\u8272\uff0c\u901a\u8fc7AI\u9a71\u52a8\u7684\u7f16\u7801\u7406\u8bba\u521b\u65b0\u548c\u6280\u672f\u96c6\u6210\uff0c\u80fd\u591f\u89e3\u51b3\u5f53\u524d\u7f51\u7edc\u9762\u4e34\u7684\u5173\u952e\u6311\u6218\uff0c\u4e3a\u672a\u6765\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u5efa\u7acb\u66f4\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u548c\u53ef\u6269\u5c55\u7684\u67b6\u6784\u57fa\u7840\u3002"}}
{"id": "2601.06809", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06809", "abs": "https://arxiv.org/abs/2601.06809", "authors": ["Hong-Bae Jeon", "Chan-Byoung Chae"], "title": "RIS-aided ISAC with $K$-Rydberg Atomic Receivers", "comment": "13 pages, 5 figures", "summary": "In this paper, we investigate a reconfigurable intelligent surface (RIS)-assisted integrated sensing and communications (ISAC) framework equipped with multiple Rydberg atomic receiver (RAR)-aided users. By leveraging the reference-assisted reception mechanism of RARs, we develop a unified signal model that jointly captures downlink multi-user communication with RARs and monostatic radar sensing. To explicitly balance communication performance and sensing accuracy, we formulate a Cramer-Rao bound (CRB)-constrained utility maximization problem. To address these challenges, we propose a joint optimization framework that combines fractional programming (FP), majorization-minimization (MM), and the alternating direction method of multipliers (ADMM). Simulation results demonstrate that the proposed framework consistently outperforms the conventional approach over a wide range of system environments, thereby highlighting the importance of the proposed framework in unlocking the potential of RARs for 6G.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u8f85\u52a9\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u6846\u67b6\uff0c\u5229\u7528\u91cc\u5fb7\u5821\u539f\u5b50\u63a5\u6536\u5668\u5b9e\u73b0\u591a\u7528\u6237\u901a\u4fe1\u4e0e\u96f7\u8fbe\u611f\u77e5\u7684\u8054\u5408\u4f18\u5316\u3002", "motivation": "\u968f\u77406G\u6280\u672f\u7684\u53d1\u5c55\uff0c\u9700\u8981\u540c\u65f6\u5b9e\u73b0\u9ad8\u6548\u901a\u4fe1\u548c\u7cbe\u786e\u611f\u77e5\u3002\u91cc\u5fb7\u5821\u539f\u5b50\u63a5\u6536\u5668\u5177\u6709\u53c2\u8003\u8f85\u52a9\u63a5\u6536\u673a\u5236\uff0c\u80fd\u591f\u540c\u65f6\u5904\u7406\u901a\u4fe1\u548c\u611f\u77e5\u4fe1\u53f7\uff0c\u4f46\u5982\u4f55\u5e73\u8861\u901a\u4fe1\u6027\u80fd\u548c\u611f\u77e5\u7cbe\u5ea6\u662f\u4e00\u4e2a\u5173\u952e\u6311\u6218\u3002", "method": "\u5f00\u53d1\u4e86\u7edf\u4e00\u7684\u4fe1\u53f7\u6a21\u578b\uff0c\u7ed3\u5408\u4e86FP\u3001MM\u548cADMM\u7b97\u6cd5\uff0c\u63d0\u51fa\u4e86CRB\u7ea6\u675f\u7684\u6548\u7528\u6700\u5927\u5316\u95ee\u9898\u6c42\u89e3\u6846\u67b6\uff0c\u8054\u5408\u4f18\u5316\u901a\u4fe1\u548c\u611f\u77e5\u6027\u80fd\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u6846\u67b6\u5728\u5404\u79cd\u7cfb\u7edf\u73af\u5883\u4e0b\u90fd\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u6709\u6548\u5e73\u8861\u4e86\u901a\u4fe1\u6027\u80fd\u548c\u611f\u77e5\u7cbe\u5ea6\u3002", "conclusion": "\u8be5\u6846\u67b6\u6210\u529f\u89e3\u9501\u4e86\u91cc\u5fb7\u5821\u539f\u5b50\u63a5\u6536\u5668\u57286G\u4e2d\u7684\u6f5c\u529b\uff0c\u4e3aRIS\u8f85\u52a9\u7684ISAC\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8054\u5408\u4f18\u5316\u65b9\u6848\u3002"}}
{"id": "2601.06824", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06824", "abs": "https://arxiv.org/abs/2601.06824", "authors": ["Haruto Kobayashi", "Takuya Sakamoto"], "title": "Radar-Based Identification of Individuals Using Heartbeat Features Extracted from Signal Amplitude and Phase", "comment": "5 pages, 5 figures, and 2 tables. This work is going to be submitted to the IEEE for possible publication", "summary": "This study proposes a non-contact method for identifying individuals through the use of heartbeat features measured with millimeter-wave radar. Although complex-valued radar signal spectrograms are commonly used for this task, little attention has been paid to the choice of signal components, namely, whether to use amplitude, phase, or the complex signal itself. Although spectrograms can be constructed independently from amplitude or phase information, their respective contributions to identification accuracy remain unclear. To address this issue, we first evaluate identification performance using spectrograms derived separately from amplitude, phase, and complex signals. We then propose a feature fusion method that integrates these three representations to enhance identification accuracy. Experiments conducted with a 79-GHz radar system and involving six participants achieved an identification accuracy of 97.67%, demonstrating the effectiveness of the proposed component-wise analysis and integration approach.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6beb\u7c73\u6ce2\u96f7\u8fbe\u5fc3\u8df3\u7279\u5f81\u7684\u975e\u63a5\u89e6\u5f0f\u8eab\u4efd\u8bc6\u522b\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u6790\u5e45\u5ea6\u3001\u76f8\u4f4d\u548c\u590d\u6570\u4fe1\u53f7\u7684\u8d21\u732e\uff0c\u5e76\u878d\u5408\u4e09\u8005\u7279\u5f81\u63d0\u5347\u8bc6\u522b\u51c6\u786e\u7387", "motivation": "\u73b0\u6709\u57fa\u4e8e\u590d\u6570\u96f7\u8fbe\u4fe1\u53f7\u8c31\u56fe\u7684\u5fc3\u8df3\u8eab\u4efd\u8bc6\u522b\u65b9\u6cd5\u5f88\u5c11\u5173\u6ce8\u4fe1\u53f7\u5206\u91cf\u9009\u62e9\uff08\u5e45\u5ea6\u3001\u76f8\u4f4d\u6216\u590d\u6570\u4fe1\u53f7\u672c\u8eab\uff09\uff0c\u8fd9\u4e9b\u5206\u91cf\u5bf9\u8bc6\u522b\u7cbe\u5ea6\u7684\u8d21\u732e\u4e0d\u660e\u786e", "method": "\u9996\u5148\u5206\u522b\u8bc4\u4f30\u5e45\u5ea6\u3001\u76f8\u4f4d\u548c\u590d\u6570\u4fe1\u53f7\u8c31\u56fe\u7684\u8bc6\u522b\u6027\u80fd\uff0c\u7136\u540e\u63d0\u51fa\u7279\u5f81\u878d\u5408\u65b9\u6cd5\u6574\u5408\u8fd9\u4e09\u79cd\u8868\u793a\u4ee5\u63d0\u5347\u8bc6\u522b\u51c6\u786e\u7387", "result": "\u4f7f\u752879GHz\u96f7\u8fbe\u7cfb\u7edf\u5bf96\u540d\u53c2\u4e0e\u8005\u8fdb\u884c\u5b9e\u9a8c\uff0c\u5b9e\u73b0\u4e8697.67%\u7684\u8eab\u4efd\u8bc6\u522b\u51c6\u786e\u7387", "conclusion": "\u63d0\u51fa\u7684\u5206\u91cf\u5206\u6790\u548c\u878d\u5408\u65b9\u6cd5\u6709\u6548\uff0c\u8bc1\u660e\u4e86\u5e45\u5ea6\u3001\u76f8\u4f4d\u548c\u590d\u6570\u4fe1\u53f7\u5206\u91cf\u5728\u5fc3\u8df3\u8eab\u4efd\u8bc6\u522b\u4e2d\u7684\u91cd\u8981\u6027"}}
{"id": "2601.06837", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.06837", "abs": "https://arxiv.org/abs/2601.06837", "authors": ["Shuyue Xu", "Matteo Nerini", "Bruno Clerckx"], "title": "Movable Beyond-Diagonal Reconfigurable Intelligent Surfaces: Moving, Interconnecting, or Both?", "comment": null, "summary": "This letter proposes a movable beyond-diagonal reconfigurable intelligent surfaces (MA-BD-RIS) design, combining inter-element connectivity and movability for channel enhancement. We study a MA-BD-RIS assisted multi-user multiple input single output system where beamforming, BD-RIS configuration, and elements positions are jointly optimized to maximize the sum-rate. An efficient algorithm is developed, incorporating closed-form beamforming, a low-complexity partially proximal alternating direction method of multipliers for BD-RIS design, and successive convex approximation for element placement. Simulations show that the high-movability structure yields superior performance in small-scale RIS and rich scattering scenarios, while the high-connectivity structure dominates in large-scale RIS and massive transmit array configurations.", "AI": {"tldr": "\u63d0\u51fa\u79fb\u52a8\u8d85\u5bf9\u89d2\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u8bbe\u8ba1\uff0c\u7ed3\u5408\u5355\u5143\u95f4\u8fde\u63a5\u6027\u548c\u79fb\u52a8\u6027\u589e\u5f3a\u4fe1\u9053\u6027\u80fd\uff0c\u7528\u4e8e\u591a\u7528\u6237MISO\u7cfb\u7edf\uff0c\u8054\u5408\u4f18\u5316\u6ce2\u675f\u8d4b\u5f62\u3001RIS\u914d\u7f6e\u548c\u5355\u5143\u4f4d\u7f6e\u4ee5\u6700\u5927\u5316\u548c\u901f\u7387\u3002", "motivation": "\u4f20\u7edfRIS\u7684\u56fa\u5b9a\u4f4d\u7f6e\u548c\u6709\u9650\u8fde\u63a5\u6027\u9650\u5236\u4e86\u4fe1\u9053\u589e\u5f3a\u80fd\u529b\uff0c\u9700\u8981\u7ed3\u5408\u79fb\u52a8\u6027\u548c\u8d85\u5bf9\u89d2\u8fde\u63a5\u7ed3\u6784\u6765\u8fdb\u4e00\u6b65\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u63d0\u51fa\u9ad8\u6548\u7b97\u6cd5\uff1a\u95ed\u5f0f\u6ce2\u675f\u8d4b\u5f62\u3001\u4f4e\u590d\u6742\u5ea6\u90e8\u5206\u8fd1\u7aef\u4ea4\u66ff\u65b9\u5411\u4e58\u5b50\u6cd5\u7528\u4e8eBD-RIS\u8bbe\u8ba1\u3001\u8fde\u7eed\u51f8\u903c\u8fd1\u7528\u4e8e\u5355\u5143\u4f4d\u7f6e\u4f18\u5316\u3002", "result": "\u4eff\u771f\u8868\u660e\uff1a\u9ad8\u79fb\u52a8\u6027\u7ed3\u6784\u5728\u5c0f\u89c4\u6a21RIS\u548c\u4e30\u5bcc\u6563\u5c04\u573a\u666f\u4e2d\u6027\u80fd\u4f18\u8d8a\uff0c\u800c\u9ad8\u8fde\u63a5\u6027\u7ed3\u6784\u5728\u5927\u89c4\u6a21RIS\u548c\u5927\u89c4\u6a21\u53d1\u5c04\u9635\u5217\u914d\u7f6e\u4e2d\u5360\u4e3b\u5bfc\u3002", "conclusion": "MA-BD-RIS\u8bbe\u8ba1\u901a\u8fc7\u7ed3\u5408\u79fb\u52a8\u6027\u548c\u8fde\u63a5\u6027\uff0c\u5728\u4e0d\u540c\u573a\u666f\u4e0b\u90fd\u80fd\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a\u672a\u6765RIS\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.06858", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.06858", "abs": "https://arxiv.org/abs/2601.06858", "authors": ["Qikai Xiao", "Kehui Li", "Binggui Zhou", "Shaodan Ma"], "title": "Deep Learning Based Channel Extrapolation for Dual-Band Massive MIMO Systems", "comment": null, "summary": "Future wireless communication systems will increasingly rely on the integration of millimeter wave (mmWave) and sub-6 GHz bands to meet heterogeneous demands on high-speed data transmission and extensive coverage. To fully exploit the benefits of mmWave bands in massive multiple-input multiple-output (MIMO) systems, highly accurate channel state information (CSI) is required. However, directly estimating the mmWave channel demands substantial pilot overhead due to the large CSI dimension and low signal-to-noise ratio (SNR) led by severe path loss and blockage attenuation. In this paper, we propose an efficient \\textbf{M}ulti-\\textbf{D}omain \\textbf{F}usion \\textbf{C}hannel \\textbf{E}xtrapolator (MDFCE) to extrapolate sub-6 GHz band CSI to mmWave band CSI, so as to reduce the pilot overhead for mmWave CSI acquisition in dual band massive MIMO systems. Unlike traditional channel extrapolation methods based on mathematical modeling, the proposed MDFCE combines the mixture-of-experts framework and the multi-head self-attention mechanism to fuse multi-domain features of sub-6 GHz CSI, aiming to characterize the mapping from sub-6 GHz CSI to mmWave CSI effectively and efficiently. The simulation results demonstrate that MDFCE can achieve superior performance with less training pilots compared with existing methods across various antenna array scales and signal-to-noise ratio levels while showing a much higher computational efficiency.", "AI": {"tldr": "\u63d0\u51faMDFCE\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5408\u591a\u57df\u7279\u5f81\u5c06sub-6 GHz CSI\u5916\u63a8\u5230mmWave CSI\uff0c\u51cf\u5c11\u6beb\u7c73\u6ce2\u4fe1\u9053\u4f30\u8ba1\u7684\u5bfc\u9891\u5f00\u9500", "motivation": "\u6beb\u7c73\u6ce2\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u9700\u8981\u9ad8\u7cbe\u5ea6CSI\uff0c\u4f46\u76f4\u63a5\u4f30\u8ba1\u6beb\u7c73\u6ce2\u4fe1\u9053\u9700\u8981\u5927\u91cf\u5bfc\u9891\u5f00\u9500\uff0c\u56e0\u4e3aCSI\u7ef4\u5ea6\u5927\u4e14\u4fe1\u566a\u6bd4\u4f4e", "method": "\u63d0\u51fa\u591a\u57df\u878d\u5408\u4fe1\u9053\u5916\u63a8\u5668(MDFCE)\uff0c\u7ed3\u5408\u4e13\u5bb6\u6df7\u5408\u6846\u67b6\u548c\u591a\u5934\u81ea\u6ce8\u610f\u529b\u673a\u5236\uff0c\u878d\u5408sub-6 GHz CSI\u7684\u591a\u57df\u7279\u5f81\u6765\u5b66\u4e60\u5230mmWave CSI\u7684\u6620\u5c04", "result": "MDFCE\u5728\u5404\u79cd\u5929\u7ebf\u9635\u5217\u89c4\u6a21\u548c\u4fe1\u566a\u6bd4\u6c34\u5e73\u4e0b\u90fd\u80fd\u4ee5\u66f4\u5c11\u7684\u8bad\u7ec3\u5bfc\u9891\u5b9e\u73b0\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\uff0c\u540c\u65f6\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8", "conclusion": "MDFCE\u80fd\u6709\u6548\u51cf\u5c11\u53cc\u9891\u6bb5\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u6beb\u7c73\u6ce2CSI\u83b7\u53d6\u7684\u5bfc\u9891\u5f00\u9500\uff0c\u4e3a\u672a\u6765\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u9ad8\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2601.06991", "categories": ["eess.SP", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2601.06991", "abs": "https://arxiv.org/abs/2601.06991", "authors": ["Triet M. Tran", "Seyed Majid Razavi", "Dee H. Wu", "Sina Khanmohammadi"], "title": "Continuous Energy Landscape Model for Analyzing Brain State Transitions", "comment": null, "summary": "Energy landscape models characterize neural dynamics by assigning energy values to each brain state that reflect their stability or probability of occurrence. The conventional energy landscape models rely on binary brain state representation, where each region is considered either active or inactive based on some signal threshold. However, this binarization leads to significant information loss and an exponential increase in the number of possible brain states, making the calculation of energy values infeasible for large numbers of brain regions. To overcome these limitations, we propose a novel continuous energy landscape framework that employs Graph Neural Networks (GNNs) to learn a continuous precision matrix directly from functional MRI (fMRI) signals, preserving the full range of signal values during energy landscape computation. We validated our approach using both synthetic data and real-world fMRI datasets from brain tumor patients. Our results on synthetic data generated from a switching linear dynamical system (SLDS) and a Kuramoto model show that the continuous energy model achieved higher likelihood and more accurate recovery of basin geometry, state occupancy, and transition dynamics than conventional binary energy landscape models. In addition, results from the fMRI dataset indicate a 0.27 increase in AUC for predicting working memory and executive function, along with a 0.35 improvement in explained variance (R2) for predicting reaction time. These findings highlight the advantages of utilizing the full signal values in energy landscape models for capturing neuronal dynamics, with strong implications for diagnosing and monitoring neurological disorders.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u56fe\u795e\u7ecf\u7f51\u7edc\u7684\u8fde\u7eed\u80fd\u91cf\u666f\u89c2\u6846\u67b6\uff0c\u76f4\u63a5\u5b66\u4e60fMRI\u4fe1\u53f7\u7684\u8fde\u7eed\u7cbe\u5ea6\u77e9\u9635\uff0c\u76f8\u6bd4\u4f20\u7edf\u4e8c\u503c\u5316\u65b9\u6cd5\u80fd\u66f4\u51c6\u786e\u5730\u6355\u6349\u795e\u7ecf\u52a8\u529b\u5b66\uff0c\u5728\u5408\u6210\u6570\u636e\u548c\u8111\u80bf\u7624\u60a3\u8005\u6570\u636e\u4e0a\u9a8c\u8bc1\u4e86\u4f18\u8d8a\u6027\u3002", "motivation": "\u4f20\u7edf\u80fd\u91cf\u666f\u89c2\u6a21\u578b\u4f9d\u8d56\u4e8c\u503c\u5316\u8111\u72b6\u6001\u8868\u793a\uff0c\u5bfc\u81f4\u4fe1\u606f\u635f\u5931\u4e25\u91cd\uff0c\u4e14\u968f\u7740\u8111\u533a\u6570\u91cf\u589e\u52a0\uff0c\u53ef\u80fd\u72b6\u6001\u6570\u5448\u6307\u6570\u589e\u957f\uff0c\u4f7f\u5f97\u80fd\u91cf\u503c\u8ba1\u7b97\u4e0d\u53ef\u884c\u3002\u9700\u8981\u514b\u670d\u8fd9\u4e9b\u9650\u5236\u6765\u66f4\u597d\u5730\u6355\u6349\u795e\u7ecf\u52a8\u529b\u5b66\u3002", "method": "\u63d0\u51fa\u8fde\u7eed\u80fd\u91cf\u666f\u89c2\u6846\u67b6\uff0c\u4f7f\u7528\u56fe\u795e\u7ecf\u7f51\u7edc\u76f4\u63a5\u4ecefMRI\u4fe1\u53f7\u5b66\u4e60\u8fde\u7eed\u7cbe\u5ea6\u77e9\u9635\uff0c\u5728\u80fd\u91cf\u666f\u89c2\u8ba1\u7b97\u4e2d\u4fdd\u7559\u5b8c\u6574\u7684\u4fe1\u53f7\u503c\u8303\u56f4\uff0c\u907f\u514d\u4e86\u4e8c\u503c\u5316\u8fc7\u7a0b\u3002", "result": "\u5728\u5408\u6210\u6570\u636e\uff08\u5207\u6362\u7ebf\u6027\u52a8\u6001\u7cfb\u7edf\u548cKuramoto\u6a21\u578b\uff09\u4e0a\uff0c\u8fde\u7eed\u80fd\u91cf\u6a21\u578b\u6bd4\u4f20\u7edf\u4e8c\u503c\u6a21\u578b\u83b7\u5f97\u66f4\u9ad8\u7684\u4f3c\u7136\u5ea6\uff0c\u66f4\u51c6\u786e\u5730\u6062\u590d\u4e86\u76c6\u5730\u51e0\u4f55\u3001\u72b6\u6001\u5360\u636e\u548c\u8f6c\u79fb\u52a8\u6001\u3002\u5728\u771f\u5b9efMRI\u6570\u636e\u4e0a\uff0c\u5de5\u4f5c\u8bb0\u5fc6\u548c\u6267\u884c\u529f\u80fd\u9884\u6d4b\u7684AUC\u63d0\u9ad80.27\uff0c\u53cd\u5e94\u65f6\u95f4\u9884\u6d4b\u7684\u89e3\u91ca\u65b9\u5dee\u63d0\u9ad80.35\u3002", "conclusion": "\u5229\u7528\u5b8c\u6574\u4fe1\u53f7\u503c\u7684\u8fde\u7eed\u80fd\u91cf\u666f\u89c2\u6a21\u578b\u5728\u6355\u6349\u795e\u7ecf\u52a8\u529b\u5b66\u65b9\u9762\u5177\u6709\u4f18\u52bf\uff0c\u5bf9\u795e\u7ecf\u7cfb\u7edf\u75be\u75c5\u7684\u8bca\u65ad\u548c\u76d1\u6d4b\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2601.07099", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.07099", "abs": "https://arxiv.org/abs/2601.07099", "authors": ["Masaya Kato", "Takuya Sakamoto"], "title": "Autofocus Method for Human-Body Imaging under Respiratory Motion Using Synthetic Aperture Radar", "comment": "8 pages, 7 figures, and 3 tables. This work is going to be submitted to the IEEE for possible publication", "summary": "This study presents an effective autofocusing approach for synthetic aperture radar imaging of the human body under conditions of respiratory motion. The proposed method suppresses respiratory-motion-induced phase errors by separating radar echoes in the spatial- and time-frequency domains and estimating phase errors individually for each separated echo. By compensating for the estimated phase errors, synthetic aperture radar images focused on all scattering points are generated, even when multiple body parts exhibit different motions due to respiration. The performance of the proposed method is evaluated through experiments with four participants in the supine position. Compared with a conventional method, the proposed approach improves image quality by a factor of 5.1 in terms of Muller-Buffington sharpness, and reduces the root-mean-square error with respect to a reference point cloud from 34 mm to 20 mm.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9488\u5bf9\u547c\u5438\u8fd0\u52a8\u6761\u4ef6\u4e0b\u4eba\u4f53\u5408\u6210\u5b54\u5f84\u96f7\u8fbe\u6210\u50cf\u7684\u6709\u6548\u81ea\u805a\u7126\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u79bb\u96f7\u8fbe\u56de\u6ce2\u5e76\u5206\u522b\u4f30\u8ba1\u76f8\u4f4d\u8bef\u5dee\uff0c\u6539\u5584\u56fe\u50cf\u8d28\u91cf\u3002", "motivation": "\u5728\u547c\u5438\u8fd0\u52a8\u6761\u4ef6\u4e0b\uff0c\u4eba\u4f53\u4e0d\u540c\u90e8\u4f4d\u4f1a\u4ea7\u751f\u4e0d\u540c\u7684\u8fd0\u52a8\uff0c\u5bfc\u81f4\u4f20\u7edf\u5408\u6210\u5b54\u5f84\u96f7\u8fbe\u6210\u50cf\u65b9\u6cd5\u4ea7\u751f\u76f8\u4f4d\u8bef\u5dee\uff0c\u5f71\u54cd\u56fe\u50cf\u805a\u7126\u8d28\u91cf\u3002", "method": "\u901a\u8fc7\u7a7a\u95f4-\u65f6\u95f4\u9891\u7387\u57df\u5206\u79bb\u96f7\u8fbe\u56de\u6ce2\uff0c\u5bf9\u6bcf\u4e2a\u5206\u79bb\u7684\u56de\u6ce2\u5355\u72ec\u4f30\u8ba1\u76f8\u4f4d\u8bef\u5dee\uff0c\u7136\u540e\u8865\u507f\u8fd9\u4e9b\u8bef\u5dee\u6765\u751f\u6210\u805a\u7126\u826f\u597d\u7684\u5408\u6210\u5b54\u5f84\u96f7\u8fbe\u56fe\u50cf\u3002", "result": "\u5b9e\u9a8c\u663e\u793a\uff0c\u4e0e\u4f20\u7edf\u65b9\u6cd5\u76f8\u6bd4\uff0cMuller-Buffington\u9510\u5ea6\u6307\u6807\u63d0\u9ad85.1\u500d\uff0c\u76f8\u5bf9\u4e8e\u53c2\u8003\u70b9\u4e91\u7684\u5747\u65b9\u6839\u8bef\u5dee\u4ece34mm\u964d\u4f4e\u523020mm\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u80fd\u6709\u6548\u6291\u5236\u547c\u5438\u8fd0\u52a8\u5f15\u8d77\u7684\u76f8\u4f4d\u8bef\u5dee\uff0c\u663e\u8457\u63d0\u9ad8\u4eba\u4f53\u5408\u6210\u5b54\u5f84\u96f7\u8fbe\u6210\u50cf\u8d28\u91cf\uff0c\u9002\u7528\u4e8e\u591a\u90e8\u4f4d\u4e0d\u540c\u8fd0\u52a8\u7684\u60c5\u51b5\u3002"}}
{"id": "2601.07324", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.07324", "abs": "https://arxiv.org/abs/2601.07324", "authors": ["Yijun Chen", "Shanpu Shen", "Tianrui Qiao", "Hongyu Li", "Kai-Kit Wong", "Ross Murch"], "title": "Antenna Coding Optimization for Pixel Antenna Empowered MIMO Wireless Power Transfer", "comment": null, "summary": "We investigate antenna coding utilizing pixel antennas as a new degree of freedom for enhancing multiple-input multiple-output (MIMO) wireless power transfer (WPT) systems. The objective is to enhance the output direct current (DC) power under RF combining and DC combining schemes by jointly exploiting gains from antenna coding, beamforming, and rectenna nonlinearity. We first propose the MIMO WPT system model with binary and continuous antenna coding using the beamspace channel model and formulate the joint antenna coding and beamforming optimization using a nonlinear rectenna model. We propose two efficient closed-form successive convex approximation algorithms to efficiently optimize the beamforming. To further reduce the computational complexity, we propose codebook-based antenna coding designs for output DC power maximization based on K-means clustering. Results show that the proposed pixel antenna empowered MIMO WPT system with binary antenna coding increases output DC power by more than 15 dB compared with conventional systems with fixed antenna configuration. With continuous antenna coding, the performance improves another 6 dB. Moreover, the proposed codebook design outperforms previous designs by up to 40% and shows good performance with reduced computational complexity. Overall, the significant improvement in output DC power verifies the potential of leveraging antenna coding utilizing pixel antennas to enhance WPT systems.", "AI": {"tldr": "\u63d0\u51fa\u5229\u7528\u50cf\u7d20\u5929\u7ebf\u8fdb\u884c\u5929\u7ebf\u7f16\u7801\uff0c\u589e\u5f3aMIMO\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u7cfb\u7edf\u7684\u8f93\u51fa\u76f4\u6d41\u529f\u7387\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5929\u7ebf\u7f16\u7801\u3001\u6ce2\u675f\u6210\u5f62\u548c\u6574\u6d41\u5668\u975e\u7ebf\u6027\u7279\u6027\uff0c\u5b9e\u73b0\u663e\u8457\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f20\u7edfMIMO\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u7cfb\u7edf\u4f7f\u7528\u56fa\u5b9a\u5929\u7ebf\u914d\u7f6e\uff0c\u9650\u5236\u4e86\u6027\u80fd\u63d0\u5347\u6f5c\u529b\u3002\u50cf\u7d20\u5929\u7ebf\u63d0\u4f9b\u4e86\u65b0\u7684\u81ea\u7531\u5ea6\uff0c\u901a\u8fc7\u5929\u7ebf\u7f16\u7801\u53ef\u4ee5\u8fdb\u4e00\u6b65\u4f18\u5316\u80fd\u91cf\u4f20\u8f93\u6548\u7387\u3002", "method": "1. \u63d0\u51fa\u57fa\u4e8e\u6ce2\u675f\u7a7a\u95f4\u4fe1\u9053\u6a21\u578b\u7684MIMO WPT\u7cfb\u7edf\u6a21\u578b\uff0c\u652f\u6301\u4e8c\u8fdb\u5236\u548c\u8fde\u7eed\u5929\u7ebf\u7f16\u7801\uff1b2. \u4f7f\u7528\u975e\u7ebf\u6027\u6574\u6d41\u5668\u6a21\u578b\u8054\u5408\u4f18\u5316\u5929\u7ebf\u7f16\u7801\u548c\u6ce2\u675f\u6210\u5f62\uff1b3. \u63d0\u51fa\u4e24\u79cd\u9ad8\u6548\u7684\u95ed\u5f0f\u9010\u6b21\u51f8\u903c\u8fd1\u7b97\u6cd5\u4f18\u5316\u6ce2\u675f\u6210\u5f62\uff1b4. \u57fa\u4e8eK-means\u805a\u7c7b\u8bbe\u8ba1\u7801\u672c\u5929\u7ebf\u7f16\u7801\u65b9\u6848\u4ee5\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u4e8c\u8fdb\u5236\u5929\u7ebf\u7f16\u7801\u4f7f\u8f93\u51fa\u76f4\u6d41\u529f\u7387\u76f8\u6bd4\u4f20\u7edf\u56fa\u5b9a\u5929\u7ebf\u914d\u7f6e\u7cfb\u7edf\u63d0\u5347\u8d85\u8fc715dB\uff1b\u8fde\u7eed\u5929\u7ebf\u7f16\u7801\u8fdb\u4e00\u6b65\u6539\u55846dB\u6027\u80fd\uff1b\u63d0\u51fa\u7684\u7801\u672c\u8bbe\u8ba1\u6bd4\u5148\u524d\u8bbe\u8ba1\u6027\u80fd\u63d0\u5347\u8fbe40%\uff0c\u540c\u65f6\u4fdd\u6301\u8f83\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "conclusion": "\u50cf\u7d20\u5929\u7ebf\u8d4b\u80fd\u7684\u5929\u7ebf\u7f16\u7801\u6280\u672f\u663e\u8457\u63d0\u5347\u4e86MIMO\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u7cfb\u7edf\u7684\u8f93\u51fa\u76f4\u6d41\u529f\u7387\uff0c\u9a8c\u8bc1\u4e86\u5229\u7528\u5929\u7ebf\u7f16\u7801\u589e\u5f3aWPT\u7cfb\u7edf\u7684\u5de8\u5927\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u9ad8\u6548\u65e0\u7ebf\u80fd\u91cf\u4f20\u8f93\u63d0\u4f9b\u4e86\u65b0\u65b9\u5411\u3002"}}
{"id": "2601.07436", "categories": ["eess.SP", "cs.LG", "physics.optics"], "pdf": "https://arxiv.org/pdf/2601.07436", "abs": "https://arxiv.org/abs/2601.07436", "authors": ["Zicong Jiang", "Magnus Karlsson", "Erik Agrell", "Christian H\u00e4ger"], "title": "PIDT: Physics-Informed Digital Twin for Optical Fiber Parameter Estimation", "comment": "The paper will be appeared in Optical Fiber Communications Conference and Exhibition (OFC) 2026", "summary": "We propose physics-informed digital twin (PIDT): a fiber parameter estimation approach that combines a parameterized split-step method with a physics-informed loss. PIDT improves accuracy and convergence speed with lower complexity compared to previous neural operators.", "AI": {"tldr": "\u63d0\u51fa\u7269\u7406\u4fe1\u606f\u6570\u5b57\u5b6a\u751f(PIDT)\uff1a\u4e00\u79cd\u7ed3\u5408\u53c2\u6570\u5316\u5206\u6b65\u65b9\u6cd5\u548c\u7269\u7406\u4fe1\u606f\u635f\u5931\u7684\u5149\u7ea4\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u76f8\u6bd4\u4e4b\u524d\u7684\u795e\u7ecf\u7b97\u5b50\u5177\u6709\u66f4\u9ad8\u7cbe\u5ea6\u3001\u66f4\u5feb\u6536\u655b\u901f\u5ea6\u548c\u66f4\u4f4e\u590d\u6742\u5ea6", "motivation": "\u73b0\u6709\u5149\u7ea4\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\u5b58\u5728\u7cbe\u5ea6\u4e0d\u8db3\u3001\u6536\u655b\u901f\u5ea6\u6162\u6216\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u8981\u4e00\u79cd\u66f4\u9ad8\u6548\u51c6\u786e\u7684\u65b9\u6cd5\u6765\u4f30\u8ba1\u5149\u7ea4\u53c2\u6570", "method": "\u7ed3\u5408\u53c2\u6570\u5316\u5206\u6b65\u65b9\u6cd5\u548c\u7269\u7406\u4fe1\u606f\u635f\u5931\u51fd\u6570\uff0c\u521b\u5efa\u7269\u7406\u4fe1\u606f\u6570\u5b57\u5b6a\u751f\u6a21\u578b\u6765\u4f30\u8ba1\u5149\u7ea4\u53c2\u6570", "result": "PIDT\u76f8\u6bd4\u4e4b\u524d\u7684\u795e\u7ecf\u7b97\u5b50\u65b9\u6cd5\uff0c\u5728\u5149\u7ea4\u53c2\u6570\u4f30\u8ba1\u4efb\u52a1\u4e0a\u5b9e\u73b0\u4e86\u66f4\u9ad8\u7684\u7cbe\u5ea6\u3001\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6\u548c\u66f4\u4f4e\u7684\u8ba1\u7b97\u590d\u6742\u5ea6", "conclusion": "\u7269\u7406\u4fe1\u606f\u6570\u5b57\u5b6a\u751f\u662f\u4e00\u79cd\u6709\u6548\u7684\u5149\u7ea4\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u7269\u7406\u5148\u9a8c\u77e5\u8bc6\u548c\u53c2\u6570\u5316\u6a21\u578b\uff0c\u5728\u7cbe\u5ea6\u3001\u901f\u5ea6\u548c\u590d\u6742\u5ea6\u65b9\u9762\u90fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5"}}
{"id": "2601.07584", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.07584", "abs": "https://arxiv.org/abs/2601.07584", "authors": ["Yuhang Ma", "Nan Ma", "Jianqiao Chen", "Wenkai Liu"], "title": "Vector Quantized-Aided XL-MIMO CSI Feedback with Channel Adaptive Transmission", "comment": "5 pages, 4 figures", "summary": "Efficient channel state information (CSI) feedback is critical for 6G extremely large-scale multiple-input multiple-output (XL-MIMO) systems to mitigate channel interference. However, the massive antenna scale imposes a severe burden on feedback overhead. Meanwhile, existing quantized feedback methods face dual challenges of limited quantization precision and insufficient channel robustness when compressing high-dimensional channel features into discrete symbols. To reduce these gaps, guided by the deep joint source-channel coding (DJSCC) framework, we propose a vector quantized (VQ)-aided scheme for CSI feedback in XL-MIMO systems considering the near-field effect, named VQ-DJSCC-F. Firstly, taking advantage of the sparsity of near-field channels in the polar-delay domain, we extract energy-concentrated features to reduce dimensionality. Then, we simultaneously design the Transformer and CNN (convolutional neural network) architectures as the backbones to hierarchically extract CSI features, followed by VQ modules projecting features into a discrete latent space. The entropy loss regularization in synergy with an exponential moving average (EMA) update strategy is introduced to maximize quantization precision. Furthermore, we develop an attention mechanism-driven channel adaptation module to mitigate the impact of wireless channel fading on the transmission of index sequences. Simulation results demonstrate that the proposed scheme achieves superior CSI reconstruction accuracy with lower feedback overheads under varying channel conditions.", "AI": {"tldr": "\u63d0\u51faVQ-DJSCC-F\u65b9\u6848\uff0c\u5229\u7528\u5411\u91cf\u91cf\u5316\u8f85\u52a9\u7684\u6df1\u5ea6\u8054\u5408\u4fe1\u6e90\u4fe1\u9053\u7f16\u7801\u6846\u67b6\uff0c\u89e3\u51b36G XL-MIMO\u7cfb\u7edf\u4e2dCSI\u53cd\u9988\u5f00\u9500\u5927\u3001\u91cf\u5316\u7cbe\u5ea6\u6709\u9650\u548c\u4fe1\u9053\u9c81\u68d2\u6027\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "6G XL-MIMO\u7cfb\u7edf\u7684\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\u5bfc\u81f4CSI\u53cd\u9988\u5f00\u9500\u5de8\u5927\uff0c\u73b0\u6709\u91cf\u5316\u53cd\u9988\u65b9\u6cd5\u9762\u4e34\u91cf\u5316\u7cbe\u5ea6\u6709\u9650\u548c\u4fe1\u9053\u9c81\u68d2\u6027\u4e0d\u8db3\u7684\u53cc\u91cd\u6311\u6218\uff0c\u7279\u522b\u662f\u5728\u538b\u7f29\u9ad8\u7ef4\u4fe1\u9053\u7279\u5f81\u4e3a\u79bb\u6563\u7b26\u53f7\u65f6\u3002", "method": "1) \u5229\u7528\u8fd1\u573a\u4fe1\u9053\u5728\u6781\u5750\u6807-\u5ef6\u8fdf\u57df\u7684\u7a00\u758f\u6027\u63d0\u53d6\u80fd\u91cf\u96c6\u4e2d\u7279\u5f81\u964d\u7ef4\uff1b2) \u540c\u65f6\u8bbe\u8ba1Transformer\u548cCNN\u67b6\u6784\u4f5c\u4e3a\u9aa8\u5e72\u7f51\u7edc\u5206\u5c42\u63d0\u53d6CSI\u7279\u5f81\uff1b3) \u4f7f\u7528VQ\u6a21\u5757\u5c06\u7279\u5f81\u6295\u5f71\u5230\u79bb\u6563\u6f5c\u5728\u7a7a\u95f4\uff1b4) \u5f15\u5165\u71b5\u635f\u5931\u6b63\u5219\u5316\u548cEMA\u66f4\u65b0\u7b56\u7565\u6700\u5927\u5316\u91cf\u5316\u7cbe\u5ea6\uff1b5) \u5f00\u53d1\u6ce8\u610f\u529b\u673a\u5236\u9a71\u52a8\u7684\u4fe1\u9053\u81ea\u9002\u5e94\u6a21\u5757\u51cf\u8f7b\u65e0\u7ebf\u4fe1\u9053\u8870\u843d\u5bf9\u7d22\u5f15\u5e8f\u5217\u4f20\u8f93\u7684\u5f71\u54cd\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u8be5\u65b9\u6848\u5728\u4e0d\u540c\u4fe1\u9053\u6761\u4ef6\u4e0b\u4ee5\u66f4\u4f4e\u7684\u53cd\u9988\u5f00\u9500\u5b9e\u73b0\u4e86\u4f18\u8d8a\u7684CSI\u91cd\u5efa\u7cbe\u5ea6\u3002", "conclusion": "VQ-DJSCC-F\u65b9\u6848\u6709\u6548\u89e3\u51b3\u4e86XL-MIMO\u7cfb\u7edf\u4e2dCSI\u53cd\u9988\u7684\u9ad8\u5f00\u9500\u548c\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u901a\u8fc7\u521b\u65b0\u7684\u7279\u5f81\u63d0\u53d6\u3001\u91cf\u5316\u8bbe\u8ba1\u548c\u4fe1\u9053\u81ea\u9002\u5e94\u673a\u5236\uff0c\u4e3a6G\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684CSI\u53cd\u9988\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.07630", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.07630", "abs": "https://arxiv.org/abs/2601.07630", "authors": ["Zihan Jiao", "Xinping Yi", "Shi Jin"], "title": "Learning to Unfold Fractional Programming for Multi-Cell MU-MIMO Beamforming with Graph Neural Networks", "comment": null, "summary": "In the multi-cell multiuser multi-input multi-output (MU-MIMO) systems, fractional programming (FP) has demonstrated considerable effectiveness in optimizing beamforming vectors, yet it suffers from high computational complexity. Recent improvements demonstrate reduced complexity by avoiding large-dimension matrix inversions (i.e., FastFP) and faster convergence by learning to unfold the FastFP algorithm (i.e., DeepFP).", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u5728MU-MIMO\u7cfb\u7edf\u4e2d\uff0c\u4f20\u7edfFP\u65b9\u6cd5\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0cFastFP\u901a\u8fc7\u907f\u514d\u5927\u7ef4\u5ea6\u77e9\u9635\u6c42\u9006\u964d\u4f4e\u590d\u6742\u5ea6\uff0cDeepFP\u901a\u8fc7\u5b66\u4e60\u5c55\u5f00FastFP\u7b97\u6cd5\u5b9e\u73b0\u66f4\u5feb\u6536\u655b", "motivation": "\u5728\u591a\u5c0f\u533a\u591a\u7528\u6237MIMO\u7cfb\u7edf\u4e2d\uff0c\u5206\u6570\u89c4\u5212\u65b9\u6cd5\u867d\u7136\u80fd\u6709\u6548\u4f18\u5316\u6ce2\u675f\u6210\u5f62\u5411\u91cf\uff0c\u4f46\u5b58\u5728\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51fa\u4e24\u79cd\u6539\u8fdb\u65b9\u6cd5\uff1aFastFP\u901a\u8fc7\u907f\u514d\u5927\u7ef4\u5ea6\u77e9\u9635\u6c42\u9006\u6765\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\uff1bDeepFP\u901a\u8fc7\u5b66\u4e60\u5c55\u5f00FastFP\u7b97\u6cd5\u6765\u52a0\u901f\u6536\u655b", "result": "FastFP\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\uff0cDeepFP\u8fdb\u4e00\u6b65\u5b9e\u73b0\u4e86\u66f4\u5feb\u7684\u6536\u655b\u901f\u5ea6", "conclusion": "\u901a\u8fc7FastFP\u548cDeepFP\u65b9\u6cd5\uff0c\u6210\u529f\u89e3\u51b3\u4e86MU-MIMO\u7cfb\u7edf\u4e2d\u5206\u6570\u89c4\u5212\u65b9\u6cd5\u7684\u9ad8\u8ba1\u7b97\u590d\u6742\u5ea6\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u66f4\u9ad8\u6548\u7684\u6ce2\u675f\u6210\u5f62\u4f18\u5316"}}
{"id": "2601.07721", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07721", "abs": "https://arxiv.org/abs/2601.07721", "authors": ["Jind\u0159ich Dun\u00edk", "Jan Krej\u010d\u00ed", "Jakub Matou\u0161ek", "Marek Brandner", "Yeongkwon Choe"], "title": "Lagrangian Grid-based Estimation of Nonlinear Systems with Invertible Dynamics", "comment": "Under review for IFAC WC 2026 with IFAC Journal of Systems and Control option", "summary": "This paper deals with the state estimation of non-linear and non-Gaussian systems with an emphasis on the numerical solution to the Bayesian recursive relations. In particular, this paper builds upon the Lagrangian grid-based filter (GbF) recently-developed for linear systems and extends it for systems with nonlinear dynamics that are invertible. The proposed nonlinear Lagrangian GbF reduces the computational complexity of the standard GbFs from quadratic to log-linear, while preserving all the strengths of the original GbF such as robustness, accuracy, and deterministic behaviour. The proposed filter is compared with the particle filter in several numerical studies using the publicly available MATLAB\\textregistered\\ implementation\\footnote{https://github.com/pesslovany/Matlab-LagrangianPMF}.", "AI": {"tldr": "\u5c06\u7ebf\u6027\u7cfb\u7edf\u7684\u62c9\u683c\u6717\u65e5\u7f51\u683c\u6ee4\u6ce2\u5668\u6269\u5c55\u5230\u975e\u7ebf\u6027\u53ef\u9006\u7cfb\u7edf\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4ece\u4e8c\u6b21\u964d\u4f4e\u5230\u5bf9\u6570\u7ebf\u6027\uff0c\u4fdd\u6301\u9c81\u68d2\u6027\u3001\u51c6\u786e\u6027\u548c\u786e\u5b9a\u6027\u884c\u4e3a\u3002", "motivation": "\u89e3\u51b3\u975e\u7ebf\u6027\u975e\u9ad8\u65af\u7cfb\u7edf\u7684\u72b6\u6001\u4f30\u8ba1\u95ee\u9898\uff0c\u7279\u522b\u662f\u8d1d\u53f6\u65af\u9012\u5f52\u5173\u7cfb\u7684\u6570\u503c\u89e3\u3002\u73b0\u6709\u7f51\u683c\u6ee4\u6ce2\u5668\u8ba1\u7b97\u590d\u6742\u5ea6\u9ad8\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u7ebf\u6027\u7cfb\u7edf\u7684\u62c9\u683c\u6717\u65e5\u7f51\u683c\u6ee4\u6ce2\u5668\uff0c\u6269\u5c55\u5230\u5177\u6709\u53ef\u9006\u975e\u7ebf\u6027\u52a8\u6001\u7684\u7cfb\u7edf\u3002\u901a\u8fc7\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\u51cf\u5c11\u8ba1\u7b97\u590d\u6742\u5ea6\uff0c\u4ece\u4e8c\u6b21\u964d\u4f4e\u5230\u5bf9\u6570\u7ebf\u6027\u3002", "result": "\u63d0\u51fa\u7684\u975e\u7ebf\u6027\u62c9\u683c\u6717\u65e5\u7f51\u683c\u6ee4\u6ce2\u5668\u5728\u4fdd\u6301\u539f\u59cb\u7f51\u683c\u6ee4\u6ce2\u5668\u9c81\u68d2\u6027\u3001\u51c6\u786e\u6027\u548c\u786e\u5b9a\u6027\u884c\u4e3a\u7684\u540c\u65f6\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u3002\u5728\u591a\u4e2a\u6570\u503c\u7814\u7a76\u4e2d\u4e0e\u7c92\u5b50\u6ee4\u6ce2\u5668\u8fdb\u884c\u4e86\u6bd4\u8f83\u3002", "conclusion": "\u6210\u529f\u5f00\u53d1\u4e86\u9002\u7528\u4e8e\u975e\u7ebf\u6027\u53ef\u9006\u7cfb\u7edf\u7684\u9ad8\u6548\u62c9\u683c\u6717\u65e5\u7f51\u683c\u6ee4\u6ce2\u5668\uff0c\u8ba1\u7b97\u6548\u7387\u663e\u8457\u63d0\u5347\uff0c\u540c\u65f6\u4fdd\u6301\u4e86\u7f51\u683c\u6ee4\u6ce2\u5668\u7684\u4f18\u52bf\u7279\u6027\u3002"}}
{"id": "2601.07728", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.07728", "abs": "https://arxiv.org/abs/2601.07728", "authors": ["J. Matou\u0161ek", "J. Krej\u010d\u00ed", "J. Dun\u00edk", "R. Zanetti"], "title": "Tensor Decompositions for Online Grid-Based Terrain-Aided Navigation", "comment": "In review for FUSION 2026", "summary": "This paper presents a practical and scalable grid-based state estimation method for high-dimensional models with invertible linear dynamics and with highly non-linear measurements, such as the nearly constant velocity model with measurements of e.g. altitude, bearing, and/or range. Unlike previous tensor decomposition-based approaches, which have largely remained at the proof-of-concept stage, the proposed method delivers an efficient and practical solution by exploiting decomposable model structure-specifically, block-diagonal dynamics and sparsely coupled measurement dimensions. The algorithm integrates a Lagrangian formulation for the time update and leverages low-rank tensor decompositions to compactly represent and effectively propagate state densities. This enables real-time estimation for models with large state dimension, significantly extending the practical reach of grid-based filters beyond their traditional low-dimensional use. Although demonstrated in the context of terrain-aided navigation, the method is applicable to a wide range of models with decomposable structure. The computational complexity and estimation accuracy depend on the specific structure of the model. All experiments are fully reproducible, with source code provided alongside this paper (GitHub link: https://github.com/pesslovany/Matlab-LagrangianPMF).", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5b9e\u7528\u7684\u7f51\u683c\u5316\u72b6\u6001\u4f30\u8ba1\u65b9\u6cd5\uff0c\u9002\u7528\u4e8e\u5177\u6709\u53ef\u9006\u7ebf\u6027\u52a8\u529b\u5b66\u548c\u9ad8\u5ea6\u975e\u7ebf\u6027\u6d4b\u91cf\u7684\u9ad8\u7ef4\u6a21\u578b\uff0c\u901a\u8fc7\u5229\u7528\u53ef\u5206\u89e3\u6a21\u578b\u7ed3\u6784\u5b9e\u73b0\u5b9e\u65f6\u4f30\u8ba1\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u5f20\u91cf\u5206\u89e3\u7684\u65b9\u6cd5\u5927\u591a\u505c\u7559\u5728\u6982\u5ff5\u9a8c\u8bc1\u9636\u6bb5\uff0c\u65e0\u6cd5\u5b9e\u9645\u5e94\u7528\u4e8e\u9ad8\u7ef4\u72b6\u6001\u4f30\u8ba1\u3002\u9700\u8981\u5f00\u53d1\u4e00\u79cd\u65e2\u80fd\u5904\u7406\u9ad8\u7ef4\u72b6\u6001\u7a7a\u95f4\uff0c\u53c8\u80fd\u5e94\u5bf9\u975e\u7ebf\u6027\u6d4b\u91cf\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u7684\u5b9e\u7528\u65b9\u6cd5\u3002", "method": "\u5229\u7528\u53ef\u5206\u89e3\u6a21\u578b\u7ed3\u6784\uff08\u5757\u5bf9\u89d2\u52a8\u529b\u5b66\u548c\u7a00\u758f\u8026\u5408\u6d4b\u91cf\u7ef4\u5ea6\uff09\uff0c\u7ed3\u5408\u62c9\u683c\u6717\u65e5\u516c\u5f0f\u8fdb\u884c\u65f6\u95f4\u66f4\u65b0\uff0c\u5e76\u91c7\u7528\u4f4e\u79e9\u5f20\u91cf\u5206\u89e3\u6765\u7d27\u51d1\u8868\u793a\u548c\u6709\u6548\u4f20\u64ad\u72b6\u6001\u5bc6\u5ea6\u3002", "result": "\u8be5\u65b9\u6cd5\u80fd\u591f\u5b9e\u73b0\u5927\u72b6\u6001\u7ef4\u5ea6\u6a21\u578b\u7684\u5b9e\u65f6\u4f30\u8ba1\uff0c\u663e\u8457\u6269\u5c55\u4e86\u7f51\u683c\u5316\u6ee4\u6ce2\u5668\u5728\u4f20\u7edf\u4f4e\u7ef4\u5e94\u7528\u4e4b\u5916\u7684\u5b9e\u9645\u5e94\u7528\u8303\u56f4\u3002\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u4f30\u8ba1\u7cbe\u5ea6\u53d6\u51b3\u4e8e\u6a21\u578b\u7684\u5177\u4f53\u7ed3\u6784\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u4e3a\u5177\u6709\u53ef\u5206\u89e3\u7ed3\u6784\u7684\u9ad8\u7ef4\u975e\u7ebf\u6027\u72b6\u6001\u4f30\u8ba1\u95ee\u9898\u63d0\u4f9b\u4e86\u5b9e\u7528\u4e14\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u867d\u7136\u4ee5\u5730\u5f62\u8f85\u52a9\u5bfc\u822a\u4e3a\u6f14\u793a\u80cc\u666f\uff0c\u4f46\u9002\u7528\u4e8e\u66f4\u5e7f\u6cdb\u7684\u6a21\u578b\u7c7b\u578b\u3002"}}

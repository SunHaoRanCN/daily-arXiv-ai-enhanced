<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 9]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.SD](#cs.SD) [Total: 4]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Modal Parameter Extraction via Propeller-Driven Vibration Testing](https://arxiv.org/abs/2601.08123)
*Gabriele Dessena,Alessandro Pontillo*

Main category: eess.SP

TL;DR: 评估螺旋桨驱动振动测试作为传统地面振动测试的替代方案，通过实验验证其在提取低频模态信息方面的可行性


<details>
  <summary>Details</summary>
Motivation: 传统飞机地面振动测试耗时且成本高昂，需要寻找更高效的替代方法。螺旋桨驱动振动测试作为操作模态分析的一种形式，可能提供更经济便捷的测试方案。

Method: 使用7075-T6铝制悬臂翼梁，安装7个加速度计，通过外置电机和螺旋桨激励。进行7次测试：基准（电机关闭）、5个恒定油门工况和1个手动上下油门扫频。使用自然激励技术与Loewner框架进行模态参数识别。

Result: 螺旋桨激励下主要共振峰仍然可观测，但低油门工况会产生窄带谐波可能掩盖结构峰值；扫频能减少持续重叠。前两阶模态匹配良好（MAC>0.99），第三阶模态重复性较差（MAC=0.827），频率偏移较大，这与螺旋桨引起的弯扭耦合和非理想扫频控制一致。

Conclusion: 螺旋桨驱动振动测试可作为地面振动测试的可行补充，用于提取低频模态信息。未来工作需要关注自动油门调度和考虑耦合效应的测试规划。

Abstract: Ground Vibration Testing (GVT) supports aircraft certification but often requires lengthy and costly campaigns. Propeller-driven Vibration Testing (PVT) is assessed here as an output-only alternative, in line with Operational Modal Analysis approaches such as Taxi Vibration Testing and Flight Vibration Testing. A cantilever Aluminium 7075-T6 wing spar is instrumented with seven accelerometers and excited by an outboard electric motor and propeller. Seven runs are carried out: a motor-off baseline, five constant-throttle cases, and a manual up-down throttle sweep. The acquired spectra indicate that the dominant resonances remain observable under propeller excitation, while low-throttle conditions introduce narrowband harmonics that may mask structural peaks; the sweep reduces persistent overlap. Modal parameters are identified for the baseline and sweep cases using the Natural Excitation Technique with the Loewner Framework (NExT-LF). The first two modes remain closely matched (Modal Assurance Criterion (MAC) > 0.99), whereas the third mode shows reduced repeatability (MAC = 0.827) and a larger frequency shift, consistent with propeller-induced bending--torsion coupling and non-ideal sweep control. Overall, PVT provides a viable complement to GVT for extracting low-frequency modal information and motivates pursuing future work on automated throttle scheduling and coupling-aware test planning.

</details>


### [2] [Variable-Length Wideband CSI Feedback via Loewner Interpolation and Deep Learning](https://arxiv.org/abs/2601.08300)
*Meilin Li,Wei Xu,Zhixiang Hu,An Liu*

Main category: eess.SP

TL;DR: 提出用于U6G频段FDD大规模MIMO系统的变长宽带CSI反馈方案，采用Loewner插值框架和神经网络压缩，支持变长反馈并提高精度


<details>
  <summary>Details</summary>
Motivation: 现有基于压缩感知和深度学习的方案在宽带信道（如U6G）中，由于DFT基的能量泄漏效应更严重，导致恢复精度瓶颈

Method: 引入Loewner插值框架生成动态基在频域高效压缩，再用神经网络在空域进一步压缩；设计无速率自编码器支持变长反馈，采用重要性排序和自适应量化

Result: 仿真结果表明，该方案能以相同或更少的反馈开销获得更高的CSI反馈精度，并提高频谱效率

Conclusion: 提出的方案有效解决了宽带信道中的能量泄漏问题，实现了反馈开销与恢复精度之间的灵活权衡，提升了系统性能

Abstract: In this paper, we propose a variable-length wideband channel state information (CSI) feedback scheme for Frequency Division Duplex (FDD) massive multiple-input multipleoutput (MIMO) systems in U6G band (6425MHz-7125MHz). Existing compressive sensing (CS)-based and deep learning (DL)- based schemes preprocess the channel by truncating it in the angular-delay domain. However, the energy leakage effect caused by the Discrete Fourier Transform (DFT) basis will be more serious and leads to a bottleneck in recovery accuracy when applied to wideband channels such as those in U6G. To solve this problem, we introduce the Loewner Interpolation (LI) framework which generates a set of dynamic bases based on the current CSI matrix, enabling highly efficient compression in the frequency domain. Then, the LI basis is further compressed in the spatial domain through a neural network. To achieve a flexible trade-off between feedback overhead and recovery accuracy, we design a rateless auto-encoder trained with tail dropout and a multi-objective learning schedule, supporting variable-length feedback with a singular model. Meanwhile, the codewords are ranked by importance, ensuring that the base station (BS) can still maintain acceptable reconstruction performance under limited feedback with tail erasures. Furthermore, an adaptive quantization strategy is developed for the feedback framework to enhance robustness. Simulation results demonstrate that the proposed scheme could achieve higher CSI feedback accuracy with less or equal feedback overhead, and improve spectral efficiency compared with baseline schemes.

</details>


### [3] [Meta-Backscatter: Long-Distance Battery-Free Metamaterial-Backscatter Sensing and Communication](https://arxiv.org/abs/2601.08307)
*Taorui Liu,Xu Liu,Zhiquan Xu,Houfeng Chen,Hongliang Zhang,Lingyang Song*

Main category: eess.SP

TL;DR: 本文提出了一种基于超材料标签的元反向散射系统，用于突破传统无电池物联网的通信距离限制，建立了统一的设计框架和研究路线图。


<details>
  <summary>Details</summary>
Motivation: 传统反向散射通信标签由于固有的往返路径损耗，通信范围通常只有几米，这严重限制了无电池物联网的实际部署。需要突破这一关键通信距离障碍。

Method: 利用超材料标签，通过密集铺设的亚波长单元来集中反射信号功率，显著扩展通信范围。建立了超材料标签及其兼容收发器的设计方法论，并实现了原型系统。

Result: 超材料标签相比采用全向天线的传统无电池物联网标签，能够实现显著的通信距离扩展。通过原型系统验证了该方法的可行性。

Conclusion: 元反向散射系统在保持无电池物联网固有优势的同时，突破了关键通信距离障碍。论文最后强调了关键挑战并概述了未来研究的潜在方向。

Abstract: Battery-free Internet of Things (BF-IoT) enabled by backscatter communication is a rapidly evolving technology offering advantages of low cost, ultra-low power consumption, and robustness. However, the practical deployment of BF-IoT is significantly constrained by the limited communication range of common backscatter tags, which typically operate with a range of merely a few meters due to inherent round-trip path loss. Meta-backscatter systems that utilize metamaterial tags present a promising solution, retaining the inherent advantages of BF-IoT while breaking the critical communication range barrier. By leveraging densely paved sub-wavelength units to concentrate the reflected signal power, metamaterial tags enable a significant communication range extension over existing BF-IoT tags that employ omni-directional antennas. In this paper, we synthesize the principles and paradigms of metamaterial sensing to establish a unified design framework and a forward-looking research roadmap. Specifically, we first provide an overview of backscatter communication, encompassing its development history, working principles, and tag classification. We then introduce the design methodology for both metamaterial tags and their compatible transceivers. Moreover, we present the implementation of a meta-backscatter system prototype and report the experimental results based on it. Finally, we conclude by highlighting key challenges and outlining potential avenues for future research.

</details>


### [4] [Bio-RV: Low-Power Resource-Efficient RISC-V Processor for Biomedical Applications](https://arxiv.org/abs/2601.08428)
*Vijay Pratap Sharma,Annu Kumar,Mohd Faisal Khan,Mukul Lokhande,Santosh Kumar Vishvakarma*

Main category: eess.SP

TL;DR: Bio-RV是一款紧凑型RISC-V处理器，专为生物医学控制应用设计，具有低功耗、确定性执行和硬件复杂度低的特点，适用于植入式起搏器等安全关键系统。


<details>
  <summary>Details</summary>
Motivation: 为生物医学控制应用（如加速器基生物医学SoC和植入式起搏器系统）开发一款资源高效、低功耗的处理器，这些系统需要确定性执行、最小硬件复杂度和集成灵活性，而非峰值计算速度。

Method: 设计了一个多周期RV32I核心，提供显式执行控制和外部指令加载功能，支持受控固件部署、ASIC启动和硅后测试。作为轻量级主机控制器，协调加速器配置和数据传输，并处理与起搏、传感、心电、遥测和电池管理模块的接口。

Result: 在FPGA原型上仅需708个LUT和235个触发器，采用180nm CMOS技术，工作频率50MHz，硬件占用小。后布局结果显示架构决策符合最小能耗要求。

Conclusion: Bio-RV通过优先考虑确定性执行、最小硬件复杂度和集成灵活性，成功满足了超低功耗、安全关键生物医学系统的需求，为生物医学控制应用提供了紧凑高效的处理器解决方案。

Abstract: This work presents Bio-RV, a compact and resource-efficient RISC-V processor intended for biomedical control applications, such as accelerator-based biomedical SoCs and implantable pacemaker systems. The proposed Bio-RV is a multi-cycle RV32I core that provides explicit execution control and external instruction loading with capabilities that enable controlled firmware deployment, ASIC bring-up, and post-silicon testing. In addition to coordinating accelerator configuration and data transmission in heterogeneous systems, Bio-RV is designed to function as a lightweight host controller, handling interfaces with pacing, sensing, electrogram (EGM), telemetry, and battery management modules. With 708 LUTs and 235 flip-flops on FPGA prototypes, Bio-RV, implemented in a 180 nm CMOS technology, operate at 50 MHz and feature a compact hardware footprint. According to post-layout results, the proposed architectural decisions align with minimal energy use. Ultimately, Bio-RV prioritises deterministic execution, minimal hardware complexity, and integration flexibility over peak computing speed to meet the demands of ultra-low-power, safety-critical biomedical systems.

</details>


### [5] [Effective outdoor pathloss prediction: A multi-layer segmentation approach with weighting map](https://arxiv.org/abs/2601.08436)
*Yuan Gao,Tao Wen,Wenjing Xie,Jianbo Du,Yong Zeng,Dusit Niyato,Shugong Xu*

Main category: eess.SP

TL;DR: 提出基于ResNet的路径损耗预测模型，通过生成Tx/Rx深度图、距离图和权重图来捕捉环境特征，相比现有方法在精度和计算效率上均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统路径损耗预测方法（如射线追踪和模型方法）存在计算复杂度高、与实际环境差异大的问题。深度学习为准确预测路径损耗提供了有前景的替代方案，但需要更有效的特征提取方法来处理信号反射和衍射带来的衰减。

Method: 提出基于ResNet的深度学习模型，创新性地生成三种特征图：Tx/Rx深度图（捕捉环境几何特征）、距离图（Tx-Rx距离信息）、权重图（强调直接路径相邻区域以处理高频信号反射和衍射衰减）。通过权重图特别关注信号传播关键区域。

Result: 在ITU挑战赛2024和ICASSP 2023数据集上的广泛仿真表明，该模型比PPNet、RPNet和Vision Transformer (ViT)性能提升1.2-3.0 dB。同时，浮点运算量(FLOPs)比基准方法减少60%。消融研究证实权重图的加入显著提升了预测性能。

Conclusion: 提出的ResNet-based模型通过创新的特征图生成方法，特别是权重图的设计，有效提升了路径损耗预测的准确性和计算效率，为无线网络规划提供了更实用的解决方案。

Abstract: Predicting pathloss by considering the physical environment is crucial for effective wireless network planning. Traditional methods, such as ray tracing and model-based approaches, often face challenges due to high computational complexity and discrepancies between models and real-world environments. In contrast, deep learning has emerged as a promising alternative, offering accurate path loss predictions with reduced computational complexity. In our research, we introduce a ResNet-based model designed to enhance path loss prediction. We employ innovative techniques to capture key features of the environment by generating transmission (Tx) and reception (Rx) depth maps, as well as a distance map from the geographic data. Recognizing the significant attenuation caused by signal reflection and diffraction, particularly at high frequencies, we have developed a weighting map that emphasizes the areas adjacent to the direct path between Tx and Rx for path loss prediction. {Extensive simulations demonstrate that our model outperforms PPNet, RPNet, and Vision Transformer (ViT) by 1.2-3.0 dB using dataset of ITU challenge 2024 and ICASSP 2023. In addition, the floating point operations (FLOPs) of the proposed model is 60\% less than those of benchmarks.} Additionally, ablation studies confirm that the inclusion of the weighting map significantly enhances prediction performance.

</details>


### [6] [SDP: A Unified Protocol and Benchmarking Framework for Reproducible Wireless Sensing](https://arxiv.org/abs/2601.08463)
*Di Zhang,Jiawei Huang,Yuanhao Cui,Xiaowen Cao,Tony Xiao Han,Xiaojun Jing,Christos Masouros*

Main category: eess.SP

TL;DR: SDP提出无线感知的统一协议和基准，通过标准化数据处理流程解决硬件异构性带来的可复现性问题


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的无线感知缺乏统一的实验基础，硬件依赖的信道测量表示、预处理流程和评估协议在不同设备和数据集间差异很大，阻碍公平比较和可复现性

Method: 提出Sensing Data Protocol (SDP)，作为协议级抽象和统一基准，包括确定性物理层净化、规范张量构建、标准化训练和评估流程，将学习任务与硬件异构性解耦

Result: SDP在保持竞争力的准确率同时，显著提高了稳定性，在复杂活动识别任务中将种子间性能方差降低了几个数量级；真实世界实验展示了协议在异构硬件间的互操作性

Conclusion: SDP通过提供统一协议和基准，使无线感知研究具有可复现性和可比性，支持从临时实验向可靠工程实践的转变

Abstract: Learning-based wireless sensing has made rapid progress, yet the field still lacks a unified and reproducible experimental foundation. Unlike computer vision, wireless sensing relies on hardware-dependent channel measurements whose representations, preprocessing pipelines, and evaluation protocols vary significantly across devices and datasets, hindering fair comparison and reproducibility.
  This paper proposes the Sensing Data Protocol (SDP), a protocol-level abstraction and unified benchmark for scalable wireless sensing. SDP acts as a standardization layer that decouples learning tasks from hardware heterogeneity. To this end, SDP enforces deterministic physical-layer sanitization, canonical tensor construction, and standardized training and evaluation procedures, decoupling learning performance from hardware-specific artifacts. Rather than introducing task-specific models, SDP establishes a principled protocol foundation for fair evaluation across diverse sensing tasks and platforms. Extensive experiments demonstrate that SDP achieves competitive accuracy while substantially improving stability, reducing inter-seed performance variance by orders of magnitude on complex activity recognition tasks. A real-world experiment using commercial off-the-shelf Wi-Fi hardware further illustrating the protocol's interoperability across heterogeneous hardware. By providing a unified protocol and benchmark, SDP enables reproducible and comparable wireless sensing research and supports the transition from ad hoc experimentation toward reliable engineering practice.

</details>


### [7] [Drone Surveillance via Coordinated Beam Sweeping in MIMO-ISAC Networks](https://arxiv.org/abs/2601.08483)
*Palatip Jopanya,Diana P. M. Osorio,Erik G. Larsson*

Main category: eess.SP

TL;DR: 提出一种结合5G SSB同步信号与无人机监测的方案，通过多基站协同波束扫描，在5G通信的同时实现低空无人机三维网格监测。


<details>
  <summary>Details</summary>
Motivation: 随着5G网络部署和无人机应用增加，需要在不干扰正常通信的情况下实现低空无人机监测。传统方法难以同时满足通信和感知需求，需要一种能协同5G SSB信号进行无人机检测的方案。

Method: 采用多基站配置，基站协同发射感知波束扫描三维监测网格，同时发送5G SSB广播信号。提出预编码器设计，保证感知波束与SSB信号正交性，最大化感知信号SINR，同时确保用户通信质量，并最小化直连链路影响。

Result: 提出的预编码器方案优于非协同预编码器，且对无人机高度变化影响较小，能有效实现通信与感知的协同工作。

Conclusion: 该方案成功实现了5G SSB信号与无人机监测的协同，通过创新的预编码设计解决了通信与感知的干扰问题，为低空无人机监测提供了有效解决方案。

Abstract: This paper introduces a scheme for drone surveillance coordinated with the fifth generation (5G) synchronization signal block (SSB) cell-search procedure to simultaneously detect low-altitude drones within a volumetric surveillance grid. Herein, we consider a multistatic configuration where multiple access points (APs) collaboratively illuminate the volume while independently transmitting SSB broadcast signals. Both tasks are performed through a beam sweeping. In the proposed scheme, coordinated APs send sensing beams toward a grid of voxels within the volumetric surveillance region simultaneously with the 5G SSB burst. To prevent interference between communication and sensing signals, we propose a precoder design that guarantees orthogonality of the sensing beam and the SSB in order to maximize the sensing signal-to-interference-plus-noise ratio (SINR) while ensuring a specified SINR for users, as well as minimizing the impact of the direct link. The results demonstrate that the proposed precoder outperforms the non-coordinated precoder and is minimally affected by variations in drone altitude.

</details>


### [8] [Airborne Particle Communication Through Time-varying Diffusion-Advection Channels](https://arxiv.org/abs/2601.08534)
*Fatih Merdan,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 该论文研究了时变对流条件下的空气粒子通信，建立了线性时变信道模型，推导了信道冲激响应，提出了信道色散时间作为信道记忆度量，并通过仿真验证了波形设计对性能的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有粒子通信研究大多假设恒定流条件，但实际宏观环境（如大气风）表现出时变特性。需要建立更现实的模型来支持复杂流动环境中的粒子通信。

Method: 将时变对流下的空气粒子通信建模为线性时变信道，使用移动坐标系方法推导了时间相关的闭式信道冲激响应。通过功率延迟分布表征信道，定义了信道色散时间作为信道记忆的物理度量。在定向时变风条件下进行系统级仿真。

Result: 建立了时变扩散对流信道的系统模型，信道色散时间为符号持续时间选择提供了指导。仿真表明波形设计对性能至关重要，当色散得到充分控制时，可以使用单一粒子类型实现多符号调制。

Conclusion: 时变扩散对流信道可以使用通信理论工具进行系统建模和工程化，为复杂流动环境中的粒子通信提供了现实基础。

Abstract: Particle based communication using diffusion and advection has emerged as an alternative signaling paradigm recently. While most existing studies assume constant flow conditions, real macro scale environments such as atmospheric winds exhibit time varying behavior. In this work, airborne particle communication under time varying advection is modeled as a linear time varying (LTV) channel, and a closed form, time dependent channel impulse response is derived using the method of moving frames. Based on this formulation, the channel is characterized through its power delay profile, leading to the definition of channel dispersion time as a physically meaningful measure of channel memory and a guideline for symbol duration selection. System level simulations under directed, time varying wind conditions show that waveform design is critical for performance, enabling multi symbol modulation using a single particle type when dispersion is sufficiently controlled. The results demonstrate that time varying diffusion advection channels can be systematically modeled and engineered using communication theoretic tools, providing a realistic foundation for particle based communication in complex flow environments.

</details>


### [9] [Stable Filtering for Efficient Dimensionality Reduction of Streaming Manifold Data](https://arxiv.org/abs/2601.08685)
*Nicholas P. Bertrand,Eva Yezerets,Han Lun Yap,Adam S. Charles,Christopher J. Rozell*

Main category: eess.SP

TL;DR: 本文提出随机化滤波(RF)方法，利用随机化降维技术保持数据流形结构，无需训练且计算高效，适用于大规模科学数据处理。


<details>
  <summary>Details</summary>
Motivation: 现代科学技术产生海量数据，传统数据处理方法面临存储、传输和处理的挑战。需要开发无需昂贵训练、能保持数据底层几何结构（特别是低维吸引子流形）的新型降维工具。

Method: 提出随机化滤波(RF)方法，基于随机化降维理论，通过特定实例化在嵌入空间中可证明地保持非线性流形结构。该方法数据独立且计算高效。

Result: RF方法在实际应用中展现出实用性，通过模拟和真实数据实验验证了其在多种科学应用中的有效性，证明了该方法的实际优势。

Conclusion: 随机化滤波为解决大规模数据处理的挑战提供了实用解决方案，能够在保持数据几何结构的同时实现高效处理，具有广泛的应用前景。

Abstract: Many areas in science and engineering now have access to technologies that enable the rapid collection of overwhelming data volumes. While these datasets are vital for understanding phenomena from physical to biological and social systems, the sheer magnitude of the data makes even simple storage, transmission, and basic processing highly challenging. To enable efficient and accurate execution of these data processing tasks, we require new dimensionality reduction tools that 1) do not need expensive, time-consuming training, and 2) preserve the underlying geometry of the data that has the information required to understand the measured system. Specifically, the geometry to be preserved is that induced by the fact that in many applications, streaming high-dimensional data evolves on a low-dimensional attractor manifold. Importantly, we may not know the exact structure of this manifold a priori. To solve these challenges, we present randomized filtering (RF), which leverages a specific instantiation of randomized dimensionality reduction to provably preserve non-linear manifold structure in the embedded space while remaining data-independent and computationally efficient. In this work we build on the rich theoretical promise of randomized dimensionality reduction to develop RF as a real, practical approach. We introduce novel methods, analysis, and experimental verification to illuminate the practicality of RF in diverse scientific applications, including several simulated and real-data examples that showcase the tangible benefits of RF.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [10] [Tuberculosis Screening from Cough Audio: Baseline Models, Clinical Variables, and Uncertainty Quantification](https://arxiv.org/abs/2601.07969)
*George P. Kafentzis,Efstratios Selisios*

Main category: eess.AS

TL;DR: 提出一个标准化的结核病自动检测框架，使用咳嗽音频和临床数据，旨在解决该领域方法不一致、结果不可比的问题。


<details>
  <summary>Details</summary>
Motivation: 当前基于音频的结核病筛查研究存在数据集、队列定义、特征表示、模型、验证协议和报告指标等方面的巨大差异，导致进展难以衡量，改进是否源于建模进步还是数据/评估差异不明确。

Method: 建立一个端到端可复现的标准化框架，涵盖特征提取、多模态融合、独立于咳嗽者的评估和不确定性量化，使用最近编译的多国数据集，包括咳嗽音频和临床元数据。

Result: 提供了基于咳嗽音频和融合（音频+临床元数据）模型的性能量化，发布了完整的实验协议以促进基准测试，建立了该领域的强基线。

Conclusion: 该标准化框架旨在作为共同参考点，减少阻碍该领域进展的方法学差异，促进公平比较和可复现性。

Abstract: In this paper, we propose a standardized framework for automatic tuberculosis (TB) detection from cough audio and routinely collected clinical data using machine learning. While TB screening from audio has attracted growing interest, progress is difficult to measure because existing studies vary substantially in datasets, cohort definitions, feature representations, model families, validation protocols, and reported metrics. Consequently, reported gains are often not directly comparable, and it remains unclear whether improvements stem from modeling advances or from differences in data and evaluation. We address this gap by establishing a strong, well-documented baseline for TB prediction using cough recordings and accompanying clinical metadata from a recently compiled dataset from several countries. Our pipeline is reproducible end-to-end, covering feature extraction, multimodal fusion, cougher-independent evaluation, and uncertainty quantification, and it reports a consistent suite of clinically relevant metrics to enable fair comparison. We further quantify performance for cough audio-only and fused (audio + clinical metadata) models, and release the full experimental protocol to facilitate benchmarking. This baseline is intended to serve as a common reference point and to reduce methodological variance that currently holds back progress in the field.

</details>


### [11] [Quantitative Analysis of Proxy Tasks for Anomalous Sound Detection](https://arxiv.org/abs/2601.08480)
*Seunghyeon Shin,Seokjin Lee*

Main category: eess.AS

TL;DR: 研究發現代理任務性能與異常聲音檢測性能之間沒有必然正相關，只有源分離任務顯示強正相關，強調任務難度和目標對齊的重要性


<details>
  <summary>Details</summary>
Motivation: 異常聲音檢測通常使用自監督代理任務學習正常聲音特徵，但代理任務性能提升是否必然改善異常檢測性能缺乏系統性研究

Method: 定量分析五種代理任務配置（自編碼器、分類、源分離、對比學習、預訓練模型）的性能與異常檢測關係，使用線性探測和馬氏距離評估特徵表示

Result: 代理任務性能強不一定改善異常檢測：分類任務因難度不足而飽和，對比學習因數據多樣性有限而失敗，只有源分離顯示強正相關

Conclusion: 任務難度和目標對齊對異常聲音檢測至關重要，提出三階段對齊驗證協議指導設計有效的代理任務

Abstract: Anomalous sound detection (ASD) typically involves self-supervised proxy tasks to learn feature representations from normal sound data, owing to the scarcity of anomalous samples. In ASD research, proxy tasks such as AutoEncoders operate under the explicit assumption that models trained on normal data will increase the reconstruction errors related to anomalies. A natural extension suggests that improved proxy task performance should improve ASD capability; however, this relationship has received little systematic attention. This study addresses this research gap by quantitatively analyzing the relationship between proxy task metrics and ASD performance across five configurations, namely, AutoEncoders, classification, source separation, contrastive learning, and pre-trained models. We evaluate the learned representations using linear probe (linear separability) and Mahalanobis distance (distributional compactness). Our experiments reveal that strong proxy performance does not necessarily improve anomalous sound detection performance. Specifically, classification tasks experience performance saturation owing to insufficient task difficulty, whereas contrastive learning fails to learn meaningful features owing to limited data diversity. Notably, source separation is the only task demonstrating a strong positive correlation, such that improved separation consistently improves anomaly detection. Based on these findings, we highlight the critical importance of task difficulty and objective alignment. Finally, we propose a three-stage alignment verification protocol to guide the design of highly effective proxy tasks for ASD systems.

</details>


### [12] [Weakly Supervised Tabla Stroke Transcription via TI-SDRM: A Rhythm-Aware Lattice Rescoring Framework](https://arxiv.org/abs/2601.08537)
*Rahul Bapusaheb Kodag,Vipul Arora*

Main category: eess.AS

TL;DR: 提出弱监督框架用于塔布拉鼓击转录，结合CTC声学模型与节奏重打分，使用节奏模型整合长短时节奏结构，在真实和合成数据集上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 塔布拉鼓击转录对分析印度古典音乐节奏结构至关重要，但现有方法依赖昂贵的时序标注数据，难以大规模应用。需要开发弱监督方法，仅使用符号序列而不需要时间对齐。

Method: 提出结合CTC声学模型与序列级节奏重打分的框架。声学模型生成解码格，通过Tāla独立静态-动态节奏模型(TI-SDRM)进行精炼，该模型通过自适应插值机制整合长时节奏结构与短时自适应动态。

Result: 构建了新的真实世界塔布拉独奏数据集和补充合成数据集，建立了首个弱监督塔布拉鼓击转录基准。实验显示相比纯声学解码，鼓击错误率持续显著降低。

Conclusion: 弱监督方法在塔布拉鼓击转录中有效，显式节奏结构对准确转录至关重要，为印度古典音乐节奏分析提供了实用解决方案。

Abstract: Tabla Stroke Transcription (TST) is central to the analysis of rhythmic structure in Hindustani classical music, yet remains challenging due to complex rhythmic organization and the scarcity of strongly annotated data. Existing approaches largely rely on fully supervised learning with onset-level annotations, which are costly and impractical at scale. This work addresses TST in a weakly supervised setting, using only symbolic stroke sequences without temporal alignment. We propose a framework that combines a CTC-based acoustic model with sequence-level rhythmic rescoring. The acoustic model produces a decoding lattice, which is refined using a \textbf{$T\bar{a}la$}-Independent Static--Dynamic Rhythmic Model (TI-SDRM) that integrates long-term rhythmic structure with short-term adaptive dynamics through an adaptive interpolation mechanism. We curate a new real-world tabla solo dataset and a complementary synthetic dataset, establishing the first benchmark for weakly supervised TST in Hindustani classical music. Experiments demonstrate consistent and substantial reductions in stroke error rate over acoustic-only decoding, confirming the importance of explicit rhythmic structure for accurate transcription.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [13] [LJ-Spoof: A Generatively Varied Corpus for Audio Anti-Spoofing and Synthesis Source Tracing](https://arxiv.org/abs/2601.07958)
*Surya Subramani,Hashim Ali,Hafiz Malik*

Main category: cs.SD

TL;DR: LJ-Spoof是一个专门针对说话人特定音频反欺骗和合成源追踪的数据集，通过系统性地改变语音合成模型的架构、流程和参数，提供了超过300万条语音样本，用于训练和评估反欺骗系统。


<details>
  <summary>Details</summary>
Motivation: 当前音频反欺骗领域面临两个核心挑战：说话人特定的反欺骗和合成源追踪。进展受到缺乏系统变化模型架构、合成流程和生成参数的数据集的限制。

Method: 创建LJ-Spoof数据集，系统性地变化韵律、声码器、生成超参数、真实提示源、训练机制和神经后处理。数据集涵盖1个说话人、30个TTS家族、500个生成变体子集、10个真实神经处理变体。

Result: 构建了包含超过300万条语音的变异密集数据集，支持鲁棒的说话人条件反欺骗和细粒度合成源追踪。该数据集既可作为训练资源，也可作为基准评估套件。

Conclusion: LJ-Spoof填补了音频反欺骗领域的数据空白，通过系统性的生成多样性设计，为说话人特定反欺骗和合成源追踪提供了实用的训练资源和评估基准。

Abstract: Speaker-specific anti-spoofing and synthesis-source tracing are central challenges in audio anti-spoofing. Progress has been hampered by the lack of datasets that systematically vary model architectures, synthesis pipelines, and generative parameters. To address this gap, we introduce LJ-Spoof, a speaker-specific, generatively diverse corpus that systematically varies prosody, vocoders, generative hyperparameters, bona fide prompt sources, training regimes, and neural post-processing. The corpus spans one speakers-including studio-quality recordings-30 TTS families, 500 generatively variant subsets, 10 bona fide neural-processing variants, and more than 3 million utterances. This variation-dense design enables robust speaker-conditioned anti-spoofing and fine-grained synthesis-source tracing. We further position this dataset as both a practical reference training resource and a benchmark evaluation suite for anti-spoofing and source tracing.

</details>


### [14] [VoxCog: Towards End-to-End Multilingual Cognitive Impairment Classification through Dialectal Knowledge](https://arxiv.org/abs/2601.07999)
*Tiantian Feng,Anfeng Xu,Jinkook Lee,Shrikanth Narayanan*

Main category: cs.SD

TL;DR: VoxCog：利用预训练方言模型进行认知障碍分类的端到端框架，通过语音基础模型识别阿尔茨海默病和轻度认知障碍，在多语言数据集上表现优于现有方法


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）和轻度认知障碍（MCI）患者会产生可测量的语音特征（如语速减慢、音长延长），这些特征与方言语音变异相似，因此可以利用方言识别模型来检测认知障碍

Method: 提出VoxCog端到端框架，在语音基础模型上使用预训练方言分类器进行初始化，仅使用语音信号而不依赖文本或图像等多模态信息

Result: 在ADReSS 2020挑战赛上达到87.5%准确率，在ADReSSo 2021挑战赛上达到85.9%准确率，优于使用多模态集成计算或大语言模型的现有解决方案

Conclusion: 方言分类器初始化能持续提升AD/MCI预测性能，纯语音端到端模型可达到或超越多模态集成方法的性能，为认知障碍检测提供了高效的单模态解决方案

Abstract: In this work, we present a novel perspective on cognitive impairment classification from speech by integrating speech foundation models that explicitly recognize speech dialects. Our motivation is based on the observation that individuals with Alzheimer's Disease (AD) or mild cognitive impairment (MCI) often produce measurable speech characteristics, such as slower articulation rate and lengthened sounds, in a manner similar to dialectal phonetic variations seen in speech. Building on this idea, we introduce VoxCog, an end-to-end framework that uses pre-trained dialect models to detect AD or MCI without relying on additional modalities such as text or images. Through experiments on multiple multilingual datasets for AD and MCI detection, we demonstrate that model initialization with a dialect classifier on top of speech foundation models consistently improves the predictive performance of AD or MCI. Our trained models yield similar or often better performance compared to previous approaches that ensembled several computational methods using different signal modalities. Particularly, our end-to-end speech-based model achieves 87.5% and 85.9% accuracy on the ADReSS 2020 challenge and ADReSSo 2021 challenge test sets, outperforming existing solutions that use multimodal ensemble-based computation or LLMs.

</details>


### [15] [Decoding Order Matters in Autoregressive Speech Synthesis](https://arxiv.org/abs/2601.08450)
*Minghui Zhao,Anton Ragni*

Main category: cs.SD

TL;DR: 该研究探索语音合成中的解码顺序，通过掩码扩散框架支持任意解码顺序，发现固定顺序（包括主流左到右）不如自适应顺序，且1比特量化也能支持高质量语音


<details>
  <summary>Details</summary>
Motivation: 自回归语音合成通常采用从左到右的顺序，但解码顺序实际上是一个建模选择。研究者希望探索不同的解码顺序对语音质量的影响，并寻找更优的解码策略

Method: 采用掩码扩散框架，该框架逐步解除位置掩码，允许在训练和推理时使用任意解码顺序。通过身份排列和随机排列之间的插值来研究解码顺序的随机性，比较固定策略（l2r、r2l）和自适应策略（Top-K），并对声学表示进行量化处理

Result: 解码顺序的随机性会影响语音质量；固定顺序解码（包括主流的左到右方法）是次优的，而自适应解码能获得更好的性能；即使1比特量化也能支持相当高质量的语音

Conclusion: 解码顺序是语音合成中的重要建模选择，自适应解码策略优于固定顺序方法，且低比特量化在掩码扩散框架中仍能保持语音质量，为高效语音合成提供了新思路

Abstract: Autoregressive speech synthesis often adopts a left-to-right order, yet generation order is a modelling choice. We investigate decoding order through masked diffusion framework, which progressively unmasks positions and allows arbitrary decoding orders during training and inference. By interpolating between identity and random permutations, we show that randomness in decoding order affects speech quality. We further compare fixed strategies, such as \texttt{l2r} and \texttt{r2l} with adaptive ones, such as Top-$K$, finding that fixed-order decoding, including the dominating left-to-right approach, is suboptimal, while adaptive decoding yields better performance. Finally, since masked diffusion requires discrete inputs, we quantise acoustic representations and find that even 1-bit quantisation can support reasonably high-quality speech.

</details>


### [16] [Robust CAPTCHA Using Audio Illusions in the Era of Large Language Models: from Evaluation to Advances](https://arxiv.org/abs/2601.08516)
*Ziqi Ding,Yunfeng Wan,Wei Song,Yi Liu,Gelei Deng,Nan Sun,Huadong Mo,Jingling Xue,Shidong Pan,Yuekang Li*

Main category: cs.SD

TL;DR: AI-CAPTCHA框架包含评估工具ACEval和新方法IllusionAudio，发现现有音频验证码易被AI攻破，提出基于听觉错觉的新方法能有效防御AI攻击


<details>
  <summary>Details</summary>
Motivation: 音频验证码用于辅助视觉验证码提高可访问性，但其对先进音频大语言模型和语音识别模型的鲁棒性尚不清楚，需要评估现有方法的安全漏洞并设计更安全的方案

Method: 提出AI-CAPTCHA统一框架：1) ACEval评估框架包含先进的LALM和ASR求解器；2) IllusionAudio新方法利用基于人类听觉机制的感知错觉线索

Result: 评估7种广泛部署的音频验证码发现，大多数现有方法能被先进的LALM和ASR模型以高成功率破解，暴露严重安全漏洞；IllusionAudio能击败所有测试的AI攻击，同时实现100%人类通过率

Conclusion: 现有音频验证码存在重大安全风险，基于听觉错觉的IllusionAudio方法能有效防御AI攻击，显著优于现有方法，为音频验证码安全提供了新方向

Abstract: CAPTCHAs are widely used by websites to block bots and spam by presenting challenges that are easy for humans but difficult for automated programs to solve. To improve accessibility, audio CAPTCHAs are designed to complement visual ones. However, the robustness of audio CAPTCHAs against advanced Large Audio Language Models (LALMs) and Automatic Speech Recognition (ASR) models remains unclear.
  In this paper, we introduce AI-CAPTCHA, a unified framework that offers (i) an evaluation framework, ACEval, which includes advanced LALM- and ASR-based solvers, and (ii) a novel audio CAPTCHA approach, IllusionAudio, leveraging audio illusions. Through extensive evaluations of seven widely deployed audio CAPTCHAs, we show that most existing methods can be solved with high success rates by advanced LALMs and ASR models, exposing critical security weaknesses.
  To address these vulnerabilities, we design a new audio CAPTCHA approach, IllusionAudio, which exploits perceptual illusion cues rooted in human auditory mechanisms. Extensive experiments demonstrate that our method defeats all tested LALM- and ASR-based attacks while achieving a 100% human pass rate, significantly outperforming existing audio CAPTCHA methods.

</details>

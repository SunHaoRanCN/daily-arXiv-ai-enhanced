{"id": "2601.08871", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.08871", "abs": "https://arxiv.org/abs/2601.08871", "authors": ["Junhua Huang", "Chao Huang", "Chenliang Xu"], "title": "Semantic visually-guided acoustic highlighting with large vision-language models", "comment": null, "summary": "Balancing dialogue, music, and sound effects with accompanying video is crucial for immersive storytelling, yet current audio mixing workflows remain largely manual and labor-intensive. While recent advancements have introduced the visually guided acoustic highlighting task, which implicitly rebalances audio sources using multimodal guidance, it remains unclear which visual aspects are most effective as conditioning signals.We address this gap through a systematic study of whether deep video understanding improves audio remixing. Using textual descriptions as a proxy for visual analysis, we prompt large vision-language models to extract six types of visual-semantic aspects, including object and character appearance, emotion, camera focus, tone, scene background, and inferred sound-related cues. Through extensive experiments, camera focus, tone, and scene background consistently yield the largest improvements in perceptual mix quality over state-of-the-art baselines. Our findings (i) identify which visual-semantic cues most strongly support coherent and visually aligned audio remixing, and (ii) outline a practical path toward automating cinema-grade sound design using lightweight guidance derived from large vision-language models.", "AI": {"tldr": "\u8be5\u7814\u7a76\u7cfb\u7edf\u63a2\u8ba8\u4e86\u89c6\u89c9\u8bed\u4e49\u7ebf\u7d22\u5bf9\u97f3\u9891\u91cd\u6df7\u7684\u5f71\u54cd\uff0c\u53d1\u73b0\u76f8\u673a\u7126\u70b9\u3001\u8272\u8c03\u548c\u573a\u666f\u80cc\u666f\u5bf9\u63d0\u5347\u611f\u77e5\u6df7\u97f3\u8d28\u91cf\u6700\u6709\u6548\uff0c\u4e3a\u5229\u7528\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u5b9e\u73b0\u7535\u5f71\u7ea7\u58f0\u97f3\u8bbe\u8ba1\u81ea\u52a8\u5316\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002", "motivation": "\u5f53\u524d\u97f3\u9891\u6df7\u97f3\u5de5\u4f5c\u6d41\u7a0b\u4e3b\u8981\u4f9d\u8d56\u624b\u52a8\u64cd\u4f5c\u4e14\u52b3\u52a8\u5bc6\u96c6\uff0c\u867d\u7136\u5df2\u6709\u89c6\u89c9\u5f15\u5bfc\u7684\u58f0\u5b66\u9ad8\u4eae\u4efb\u52a1\uff0c\u4f46\u5c1a\u4e0d\u6e05\u695a\u54ea\u4e9b\u89c6\u89c9\u65b9\u9762\u4f5c\u4e3a\u6761\u4ef6\u4fe1\u53f7\u6700\u6709\u6548\u3002\u672c\u7814\u7a76\u65e8\u5728\u586b\u8865\u8fd9\u4e00\u7a7a\u767d\uff0c\u7cfb\u7edf\u7814\u7a76\u6df1\u5ea6\u89c6\u9891\u7406\u89e3\u662f\u5426\u80fd\u6539\u5584\u97f3\u9891\u91cd\u6df7\u3002", "method": "\u4f7f\u7528\u6587\u672c\u63cf\u8ff0\u4f5c\u4e3a\u89c6\u89c9\u5206\u6790\u7684\u4ee3\u7406\uff0c\u63d0\u793a\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u63d0\u53d6\u516d\u79cd\u89c6\u89c9\u8bed\u4e49\u65b9\u9762\uff1a\u7269\u4f53\u548c\u89d2\u8272\u5916\u89c2\u3001\u60c5\u611f\u3001\u76f8\u673a\u7126\u70b9\u3001\u8272\u8c03\u3001\u573a\u666f\u80cc\u666f\u548c\u63a8\u65ad\u7684\u58f0\u97f3\u76f8\u5173\u7ebf\u7d22\u3002\u901a\u8fc7\u5927\u91cf\u5b9e\u9a8c\u8bc4\u4f30\u8fd9\u4e9b\u7ebf\u7d22\u5bf9\u97f3\u9891\u91cd\u6df7\u8d28\u91cf\u7684\u5f71\u54cd\u3002", "result": "\u76f8\u673a\u7126\u70b9\u3001\u8272\u8c03\u548c\u573a\u666f\u80cc\u666f\u5728\u611f\u77e5\u6df7\u97f3\u8d28\u91cf\u65b9\u9762\u6301\u7eed\u5e26\u6765\u6700\u5927\u6539\u8fdb\uff0c\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u57fa\u7ebf\u65b9\u6cd5\u3002\u8fd9\u4e9b\u89c6\u89c9\u8bed\u4e49\u7ebf\u7d22\u80fd\u6700\u6709\u6548\u5730\u652f\u6301\u8fde\u8d2f\u4e14\u89c6\u89c9\u5bf9\u9f50\u7684\u97f3\u9891\u91cd\u6df7\u3002", "conclusion": "\u7814\u7a76\u786e\u5b9a\u4e86\u6700\u80fd\u652f\u6301\u8fde\u8d2f\u89c6\u89c9\u5bf9\u9f50\u97f3\u9891\u91cd\u6df7\u7684\u89c6\u89c9\u8bed\u4e49\u7ebf\u7d22\uff0c\u5e76\u6982\u8ff0\u4e86\u5229\u7528\u4ece\u5927\u578b\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u884d\u751f\u7684\u8f7b\u91cf\u7ea7\u6307\u5bfc\u5b9e\u73b0\u7535\u5f71\u7ea7\u58f0\u97f3\u8bbe\u8ba1\u81ea\u52a8\u5316\u7684\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2601.08879", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.08879", "abs": "https://arxiv.org/abs/2601.08879", "authors": ["Nicolas Ruth", "Manuel Burghardt"], "title": "Echoes of Ideology: Toward an Audio Analysis Pipeline to Unveil Character Traits in Historical Nazi Propaganda Films", "comment": null, "summary": "This study investigates the use of computational audio analysis to examine ideological narratives in Nazi propaganda films. Employing a three-step pipeline, speaker diarization, audio transcription and psycholinguistic analysis, it reveals ideological patterns in characters. Despite current issues with speaker diarization, the methodology provides insights into character traits and propaganda narratives, suggesting scalable applications.", "AI": {"tldr": "\u4f7f\u7528\u8ba1\u7b97\u97f3\u9891\u5206\u6790\u7814\u7a76\u7eb3\u7cb9\u5ba3\u4f20\u7535\u5f71\u4e2d\u7684\u610f\u8bc6\u5f62\u6001\u53d9\u4e8b\uff0c\u901a\u8fc7\u8bf4\u8bdd\u4eba\u5206\u5272\u3001\u97f3\u9891\u8f6c\u5f55\u548c\u5fc3\u7406\u8bed\u8a00\u5b66\u5206\u6790\u63ed\u793a\u89d2\u8272\u610f\u8bc6\u5f62\u6001\u6a21\u5f0f", "motivation": "\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u8ba1\u7b97\u97f3\u9891\u5206\u6790\u65b9\u6cd5\u7cfb\u7edf\u6027\u5730\u5206\u6790\u7eb3\u7cb9\u5ba3\u4f20\u7535\u5f71\u4e2d\u7684\u610f\u8bc6\u5f62\u6001\u53d9\u4e8b\uff0c\u63a2\u7d22\u5982\u4f55\u901a\u8fc7\u6280\u672f\u624b\u6bb5\u63ed\u793a\u5ba3\u4f20\u7535\u5f71\u4e2d\u7684\u610f\u8bc6\u5f62\u6001\u6a21\u5f0f", "method": "\u91c7\u7528\u4e09\u6b65\u6d41\u6c34\u7ebf\u65b9\u6cd5\uff1a1) \u8bf4\u8bdd\u4eba\u5206\u5272\u8bc6\u522b\u4e0d\u540c\u89d2\u8272\uff1b2) \u97f3\u9891\u8f6c\u5f55\u5c06\u8bed\u97f3\u8f6c\u4e3a\u6587\u672c\uff1b3) \u5fc3\u7406\u8bed\u8a00\u5b66\u5206\u6790\u6587\u672c\u4ee5\u63ed\u793a\u610f\u8bc6\u5f62\u6001\u6a21\u5f0f", "result": "\u6210\u529f\u63ed\u793a\u4e86\u89d2\u8272\u4e2d\u7684\u610f\u8bc6\u5f62\u6001\u6a21\u5f0f\uff0c\u5c3d\u7ba1\u5f53\u524d\u8bf4\u8bdd\u4eba\u5206\u5272\u6280\u672f\u5b58\u5728\u4e00\u4e9b\u95ee\u9898\uff0c\u4f46\u65b9\u6cd5\u4ecd\u80fd\u63d0\u4f9b\u5bf9\u89d2\u8272\u7279\u5f81\u548c\u5ba3\u4f20\u53d9\u4e8b\u7684\u6df1\u5165\u6d1e\u5bdf", "conclusion": "\u8be5\u65b9\u6cd5\u4e3a\u5206\u6790\u5ba3\u4f20\u7535\u5f71\u4e2d\u7684\u610f\u8bc6\u5f62\u6001\u53d9\u4e8b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u6280\u672f\u6846\u67b6\uff0c\u5177\u6709\u5e7f\u6cdb\u7684\u5e94\u7528\u6f5c\u529b"}}
{"id": "2601.09413", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.MA", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.09413", "abs": "https://arxiv.org/abs/2601.09413", "authors": ["Zhen Wan", "Chao-Han Huck Yang", "Jinchuan Tian", "Hanrong Ye", "Ankita Pasad", "Szu-wei Fu", "Arushi Goel", "Ryo Hachiuma", "Shizhe Diao", "Kunal Dhawan", "Sreyan Ghosh", "Yusuke Hirota", "Zhehuai Chen", "Rafael Valle", "Ehsan Hosseini Asl", "Chenhui Chu", "Shinji Watanabe", "Yu-Chiang Frank Wang", "Boris Ginsburg"], "title": "Speech-Hands: A Self-Reflection Voice Agentic Approach to Speech Recognition and Audio Reasoning with Omni Perception", "comment": "Preprint. The version was submitted in October 2025", "summary": "We introduce a voice-agentic framework that learns one critical omni-understanding skill: knowing when to trust itself versus when to consult external audio perception. Our work is motivated by a crucial yet counterintuitive finding: naively fine-tuning an omni-model on both speech recognition and external sound understanding tasks often degrades performance, as the model can be easily misled by noisy hypotheses. To address this, our framework, Speech-Hands, recasts the problem as an explicit self-reflection decision. This learnable reflection primitive proves effective in preventing the model from being derailed by flawed external candidates. We show that this agentic action mechanism generalizes naturally from speech recognition to complex, multiple-choice audio reasoning. Across the OpenASR leaderboard, Speech-Hands consistently outperforms strong baselines by 12.1% WER on seven benchmarks. The model also achieves 77.37% accuracy and high F1 on audio QA decisions, showing robust generalization and reliability across diverse audio question answering datasets. By unifying perception and decision-making, our work offers a practical path toward more reliable and resilient audio intelligence.", "AI": {"tldr": "Speech-Hands\u6846\u67b6\u901a\u8fc7\u53ef\u5b66\u4e60\u7684\u81ea\u6211\u53cd\u601d\u673a\u5236\uff0c\u8ba9\u8bed\u97f3\u4ee3\u7406\u5b66\u4f1a\u5728\u4f55\u65f6\u4fe1\u4efb\u81ea\u8eab\u5224\u65ad\u3001\u4f55\u65f6\u54a8\u8be2\u5916\u90e8\u97f3\u9891\u611f\u77e5\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u5168\u6a21\u578b\u5728\u8bed\u97f3\u8bc6\u522b\u548c\u5916\u90e8\u58f0\u97f3\u7406\u89e3\u4efb\u52a1\u4e0a\u6027\u80fd\u4e0b\u964d\u7684\u95ee\u9898\u3002", "motivation": "\u7814\u7a76\u53d1\u73b0\uff0c\u7b80\u5355\u5730\u5728\u8bed\u97f3\u8bc6\u522b\u548c\u5916\u90e8\u58f0\u97f3\u7406\u89e3\u4efb\u52a1\u4e0a\u5fae\u8c03\u5168\u6a21\u578b\u5f80\u5f80\u4f1a\u964d\u4f4e\u6027\u80fd\uff0c\u56e0\u4e3a\u6a21\u578b\u5bb9\u6613\u88ab\u566a\u58f0\u5047\u8bbe\u8bef\u5bfc\u3002\u9700\u8981\u89e3\u51b3\u6a21\u578b\u5728\u4f55\u65f6\u4fe1\u4efb\u81ea\u8eab\u5224\u65ad\u3001\u4f55\u65f6\u54a8\u8be2\u5916\u90e8\u97f3\u9891\u611f\u77e5\u7684\u51b3\u7b56\u95ee\u9898\u3002", "method": "\u63d0\u51faSpeech-Hands\u6846\u67b6\uff0c\u5c06\u95ee\u9898\u91cd\u65b0\u5b9a\u4e49\u4e3a\u663e\u5f0f\u7684\u81ea\u6211\u53cd\u601d\u51b3\u7b56\uff0c\u5f15\u5165\u53ef\u5b66\u4e60\u7684\u53cd\u601d\u539f\u8bed\uff0c\u9632\u6b62\u6a21\u578b\u88ab\u6709\u7f3a\u9677\u7684\u5916\u90e8\u5019\u9009\u65b9\u6848\u5e26\u504f\u3002\u8be5\u4ee3\u7406\u884c\u52a8\u673a\u5236\u4ece\u8bed\u97f3\u8bc6\u522b\u81ea\u7136\u63a8\u5e7f\u5230\u590d\u6742\u7684\u591a\u9009\u97f3\u9891\u63a8\u7406\u3002", "result": "\u5728OpenASR\u6392\u884c\u699c\u4e0a\uff0cSpeech-Hands\u5728\u4e03\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u6301\u7eed\u4f18\u4e8e\u5f3a\u57fa\u7ebf12.1% WER\u3002\u5728\u97f3\u9891QA\u51b3\u7b56\u4e2d\u8fbe\u523077.37%\u51c6\u786e\u7387\u548c\u9ad8F1\u5206\u6570\uff0c\u5728\u591a\u6837\u5316\u97f3\u9891\u95ee\u7b54\u6570\u636e\u96c6\u4e0a\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b\u548c\u53ef\u9760\u6027\u3002", "conclusion": "\u901a\u8fc7\u7edf\u4e00\u611f\u77e5\u548c\u51b3\u7b56\uff0c\u8fd9\u9879\u5de5\u4f5c\u4e3a\u66f4\u53ef\u9760\u3001\u66f4\u5177\u97e7\u6027\u7684\u97f3\u9891\u667a\u80fd\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002\u53ef\u5b66\u4e60\u7684\u81ea\u6211\u53cd\u601d\u673a\u5236\u80fd\u6709\u6548\u9632\u6b62\u6a21\u578b\u88ab\u6709\u7f3a\u9677\u7684\u5916\u90e8\u4fe1\u606f\u8bef\u5bfc\uff0c\u63d0\u5347\u6574\u4f53\u6027\u80fd\u3002"}}
{"id": "2601.08922", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.08922", "abs": "https://arxiv.org/abs/2601.08922", "authors": ["Ayda Nodel Hokmabadi", "Chadi Assi"], "title": "Joint Beamforming and Position Optimization for Movable-Antenna and Movable-Element RIS-Aided Full-Duplex 6G MISO Systems", "comment": null, "summary": "Full-duplex communication substantially enhances spectral efficiency by enabling simultaneous transmission and reception on the same time-frequency resources. However, its practical deployment remains hindered by strong residual self-interference and inter-user interference, which severely degrade system performance. This work investigates a full-duplex MISO network that leverages movable-antenna base stations (MA-BS) and movable-element reconfigurable intelligent surfaces (ME-RIS) to overcome these limitations in next-generation 6G systems. Unlike conventional fixed-geometry architectures, the proposed framework jointly optimizes antenna and RIS element positions, together with RIS phase shifts, to strengthen desired links while suppressing interference. Our design objective is to maximize the system sum rate through the joint optimization of transmit and receive beamforming vectors, uplink transmit powers, RIS phase shifts, and the spatial locations of both the BS antennas and RIS elements. To solve this challenging nonconvex problem, an alternating optimization algorithm is developed, employing semidefinite relaxation for beamforming design and successive convex approximation for position optimization. Simulation results demonstrate that the proposed ME-RIS-assisted architecture with movable BS antennas offers substantial gains over conventional fixed-position full-duplex networks. These findings highlight the potential of integrating movable antennas with movable RIS elements as a key enabler for high-performance full-duplex operation in future 6G wireless systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7ed3\u5408\u53ef\u79fb\u52a8\u5929\u7ebf\u57fa\u7ad9\u548c\u53ef\u79fb\u52a8\u5143\u4ef6RIS\u7684\u5168\u53cc\u5de5MISO\u7f51\u7edc\u67b6\u6784\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5929\u7ebf/RIS\u4f4d\u7f6e\u548c\u76f8\u4f4d\u504f\u79fb\u6765\u589e\u5f3a\u671f\u671b\u4fe1\u53f7\u5e76\u6291\u5236\u5e72\u6270\uff0c\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u9891\u8c31\u6548\u7387\u3002", "motivation": "\u5168\u53cc\u5de5\u901a\u4fe1\u867d\u7136\u80fd\u63d0\u9ad8\u9891\u8c31\u6548\u7387\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u53d7\u5230\u5f3a\u6b8b\u4f59\u81ea\u5e72\u6270\u548c\u7528\u6237\u95f4\u5e72\u6270\u7684\u9650\u5236\u3002\u4f20\u7edf\u56fa\u5b9a\u51e0\u4f55\u67b6\u6784\u65e0\u6cd5\u6709\u6548\u89e3\u51b3\u8fd9\u4e9b\u95ee\u9898\uff0c\u9700\u8981\u65b0\u7684\u89e3\u51b3\u65b9\u6848\u6765\u63a8\u52a86G\u7cfb\u7edf\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u53ef\u79fb\u52a8\u5929\u7ebf\u57fa\u7ad9(MA-BS)\u548c\u53ef\u79fb\u52a8\u5143\u4ef6RIS(ME-RIS)\u7684\u8054\u5408\u67b6\u6784\uff0c\u901a\u8fc7\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u89e3\u51b3\u975e\u51f8\u95ee\u9898\uff1a\u4f7f\u7528\u534a\u6b63\u5b9a\u677e\u5f1b\u8bbe\u8ba1\u6ce2\u675f\u8d4b\u5f62\uff0c\u7528\u9010\u6b21\u51f8\u903c\u8fd1\u4f18\u5316\u4f4d\u7f6e\u914d\u7f6e\uff0c\u8054\u5408\u4f18\u5316\u53d1\u5c04/\u63a5\u6536\u6ce2\u675f\u8d4b\u5f62\u5411\u91cf\u3001\u4e0a\u884c\u53d1\u5c04\u529f\u7387\u3001RIS\u76f8\u4f4d\u504f\u79fb\u4ee5\u53caBS\u5929\u7ebf\u548cRIS\u5143\u4ef6\u7684\u7a7a\u95f4\u4f4d\u7f6e\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684ME-RIS\u8f85\u52a9\u67b6\u6784\u7ed3\u5408\u53ef\u79fb\u52a8BS\u5929\u7ebf\u76f8\u6bd4\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5168\u53cc\u5de5\u7f51\u7edc\u5e26\u6765\u663e\u8457\u6027\u80fd\u589e\u76ca\uff0c\u9a8c\u8bc1\u4e86\u53ef\u79fb\u52a8\u5929\u7ebf\u4e0e\u53ef\u79fb\u52a8RIS\u5143\u4ef6\u96c6\u6210\u4e3a6G\u5168\u53cc\u5de5\u7cfb\u7edf\u5173\u952e\u4f7f\u80fd\u6280\u672f\u7684\u6f5c\u529b\u3002", "conclusion": "\u96c6\u6210\u53ef\u79fb\u52a8\u5929\u7ebf\u548c\u53ef\u79fb\u52a8RIS\u5143\u4ef6\u662f\u5b9e\u73b0\u672a\u67656G\u65e0\u7ebf\u7cfb\u7edf\u9ad8\u6027\u80fd\u5168\u53cc\u5de5\u64cd\u4f5c\u7684\u5173\u952e\u4f7f\u80fd\u6280\u672f\uff0c\u4e3a\u89e3\u51b3\u5168\u53cc\u5de5\u901a\u4fe1\u4e2d\u7684\u5e72\u6270\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.08946", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.08946", "abs": "https://arxiv.org/abs/2601.08946", "authors": ["Konstantinos D. Katsanos", "George C. Alexandropoulos"], "title": "Robust Consensus-Based Distributed Beamforming for Wideband Cell-free Multi-RIS MISO Systems", "comment": "5 pages, 1 figure, presented in Asilomar 2025", "summary": "The cell-free networking paradigm constitutes a revolutionary architecture for future generations of wireless networks, which has been recently considered in synergy with Reconfigurable Intelligent Surfaces (RISs), a promising physical-layer technology for signal propagation programmability. In this paper, we focus on wideband cell-free multi-RIS-empowered Multiple-Input Single-Output (MISO) systems and present a decentralized cooperative active and passive beamforming scheme, aiming to provide an efficient alternative towards the cooperation overhead of available centralized schemes depending on central processing unit. Considering imperfect channel information availability and realistic frequency selectivity behavior of each RIS's element response, we devise a distributed optimization approach based on consensus updates for the RISs' phase configurations. Our simulation results showcase that the proposed distributed design is superior to centralized schemes that are based on various Lorentzian-type wideband modeling approaches for the RISs.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u5bbd\u5e26\u65e0\u5c0f\u533a\u591aRIS\u8d4b\u80fd\u7684MISO\u7cfb\u7edf\u7684\u5206\u5e03\u5f0f\u534f\u540c\u4e3b\u52a8\u548c\u88ab\u52a8\u6ce2\u675f\u6210\u5f62\u65b9\u6848\uff0c\u4ee5\u964d\u4f4e\u96c6\u4e2d\u5f0f\u65b9\u6848\u7684\u5408\u4f5c\u5f00\u9500\u3002", "motivation": "\u65e0\u5c0f\u533a\u7f51\u7edc\u67b6\u6784\u4e0e\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u7684\u7ed3\u5408\u662f\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u7684\u91cd\u8981\u65b9\u5411\u3002\u73b0\u6709\u96c6\u4e2d\u5f0f\u65b9\u6848\u4f9d\u8d56\u4e2d\u592e\u5904\u7406\u5355\u5143\uff0c\u5b58\u5728\u5408\u4f5c\u5f00\u9500\u5927\u7684\u95ee\u9898\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u5206\u5e03\u5f0f\u65b9\u6848\u3002", "method": "\u57fa\u4e8e\u5171\u8bc6\u66f4\u65b0\u7684\u5206\u5e03\u5f0f\u4f18\u5316\u65b9\u6cd5\uff0c\u8003\u8651\u4e0d\u5b8c\u7f8e\u4fe1\u9053\u4fe1\u606f\u548cRIS\u5143\u4ef6\u54cd\u5e94\u7684\u5b9e\u9645\u9891\u7387\u9009\u62e9\u6027\u884c\u4e3a\uff0c\u8bbe\u8ba1RIS\u76f8\u4f4d\u914d\u7f6e\u7684\u5206\u5e03\u5f0f\u65b9\u6848\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u5206\u5e03\u5f0f\u8bbe\u8ba1\u4f18\u4e8e\u57fa\u4e8e\u5404\u79cd\u6d1b\u4f26\u5179\u578b\u5bbd\u5e26\u5efa\u6a21\u65b9\u6cd5\u7684\u96c6\u4e2d\u5f0fRIS\u65b9\u6848\u3002", "conclusion": "\u5206\u5e03\u5f0f\u534f\u540c\u6ce2\u675f\u6210\u5f62\u65b9\u6848\u4e3a\u5bbd\u5e26\u65e0\u5c0f\u533a\u591aRIS\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u80fd\u591f\u964d\u4f4e\u5408\u4f5c\u5f00\u9500\u5e76\u63d0\u5347\u6027\u80fd\u3002"}}
{"id": "2601.09239", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2601.09239", "abs": "https://arxiv.org/abs/2601.09239", "authors": ["Hanlin Zhang", "Daxin Tan", "Dehua Tao", "Xiao Chen", "Haochen Tan", "Yunhe Li", "Yuchen Cao", "Jianping Wang", "Linqi Song"], "title": "DSA-Tokenizer: Disentangled Semantic-Acoustic Tokenization via Flow Matching-based Hierarchical Fusion", "comment": null, "summary": "Speech tokenizers serve as the cornerstone of discrete Speech Large Language Models (Speech LLMs). Existing tokenizers either prioritize semantic encoding, fuse semantic content with acoustic style inseparably, or achieve incomplete semantic-acoustic disentanglement. To achieve better disentanglement, we propose DSA-Tokenizer, which explicitly disentangles speech into discrete semantic and acoustic tokens via distinct optimization constraints. Specifically, semantic tokens are supervised by ASR to capture linguistic content, while acoustic tokens focus on mel-spectrograms restoration to encode style. To eliminate rigid length constraints between the two sequences, we introduce a hierarchical Flow-Matching decoder that further improve speech generation quality.Furthermore, We employ a joint reconstruction-recombination training strategy to enforce this separation. DSA-Tokenizer enables high fidelity reconstruction and flexible recombination through robust disentanglement, facilitating controllable generation in speech LLMs. Our analysis highlights disentangled tokenization as a pivotal paradigm for future speech modeling. Audio samples are avaialble at https://anonymous.4open.science/w/DSA_Tokenizer_demo/. The code and model will be made publicly available after the paper has been accepted.", "AI": {"tldr": "DSA-Tokenizer\u63d0\u51fa\u4e86\u4e00\u79cd\u663e\u5f0f\u89e3\u8026\u8bed\u97f3\u4e3a\u8bed\u4e49\u548c\u58f0\u5b66token\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u4e0d\u540c\u7684\u4f18\u5316\u7ea6\u675f\u5b9e\u73b0\u66f4\u597d\u7684\u89e3\u8026\uff0c\u652f\u6301\u9ad8\u8d28\u91cf\u91cd\u5efa\u548c\u7075\u6d3b\u91cd\u7ec4\uff0c\u4fc3\u8fdb\u8bed\u97f3LLM\u7684\u53ef\u63a7\u751f\u6210\u3002", "motivation": "\u73b0\u6709\u8bed\u97f3tokenizer\u8981\u4e48\u4f18\u5148\u8003\u8651\u8bed\u4e49\u7f16\u7801\uff0c\u8981\u4e48\u5c06\u8bed\u4e49\u5185\u5bb9\u4e0e\u58f0\u5b66\u98ce\u683c\u4e0d\u53ef\u5206\u5272\u5730\u878d\u5408\uff0c\u6216\u8005\u5b9e\u73b0\u4e0d\u5b8c\u5168\u7684\u8bed\u4e49-\u58f0\u5b66\u89e3\u8026\u3002\u4e3a\u4e86\u83b7\u5f97\u66f4\u597d\u7684\u89e3\u8026\u6548\u679c\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u591f\u660e\u786e\u5206\u79bb\u8bed\u97f3\u4e2d\u8bed\u4e49\u548c\u58f0\u5b66\u6210\u5206\u7684tokenizer\u3002", "method": "1. \u901a\u8fc7\u4e0d\u540c\u7684\u4f18\u5316\u7ea6\u675f\u663e\u5f0f\u89e3\u8026\u8bed\u97f3\u4e3a\u79bb\u6563\u7684\u8bed\u4e49\u548c\u58f0\u5b66token\uff1a\u8bed\u4e49token\u7531ASR\u76d1\u7763\u6355\u6349\u8bed\u8a00\u5185\u5bb9\uff0c\u58f0\u5b66token\u4e13\u6ce8\u4e8emel-spectrograms\u6062\u590d\u4ee5\u7f16\u7801\u98ce\u683c\uff1b2. \u5f15\u5165\u5206\u5c42Flow-Matching\u89e3\u7801\u5668\u6d88\u9664\u4e24\u4e2a\u5e8f\u5217\u4e4b\u95f4\u7684\u521a\u6027\u957f\u5ea6\u7ea6\u675f\uff1b3. \u91c7\u7528\u8054\u5408\u91cd\u5efa-\u91cd\u7ec4\u8bad\u7ec3\u7b56\u7565\u5f3a\u5236\u5206\u79bb\u3002", "result": "DSA-Tokenizer\u901a\u8fc7\u5f3a\u5927\u7684\u89e3\u8026\u80fd\u529b\u5b9e\u73b0\u4e86\u9ad8\u4fdd\u771f\u91cd\u5efa\u548c\u7075\u6d3b\u91cd\u7ec4\uff0c\u4fc3\u8fdb\u4e86\u8bed\u97f3LLM\u4e2d\u7684\u53ef\u63a7\u751f\u6210\u3002\u5206\u6790\u8868\u660e\u89e3\u8026tokenization\u662f\u672a\u6765\u8bed\u97f3\u5efa\u6a21\u7684\u5173\u952e\u8303\u5f0f\u3002", "conclusion": "DSA-Tokenizer\u63d0\u51fa\u4e86\u4e00\u79cd\u6709\u6548\u7684\u8bed\u97f3\u89e3\u8026tokenization\u65b9\u6cd5\uff0c\u901a\u8fc7\u663e\u5f0f\u5206\u79bb\u8bed\u4e49\u548c\u58f0\u5b66\u6210\u5206\uff0c\u4e3a\u8bed\u97f3LLM\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u53ef\u63a7\u751f\u6210\u80fd\u529b\uff0c\u4ee3\u8868\u4e86\u8bed\u97f3\u5efa\u6a21\u7684\u91cd\u8981\u53d1\u5c55\u65b9\u5411\u3002"}}
{"id": "2601.09148", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09148", "abs": "https://arxiv.org/abs/2601.09148", "authors": ["Zihan Shen", "Jiaqi Li", "Xudong Dong", "Xiaofei Zhang"], "title": "Joint DOA and Non-circular Phase Estimation of Non-circular Signals for Antenna Arrays: Block Sparse Bayesian Learning Method", "comment": null, "summary": "This letter proposes a block sparse Bayesian learning (BSBL) algorithm of non-circular (NC) signals for direction-of-arrival (DOA) estimation, which is suitable for arbitrary unknown NC phases. The block sparse NC signal representation model is constructed through a permutation strategy, capturing the available intra-block structure information to enhance recovery performance. After that, we create the sparse probability model and derive the cost function under BSBL framework. Finally, the fast marginal likelihood maximum (FMLM) algorithm is introduced, enabling the rapid implementation of signal recovery by the addition and removal of basis functions. Simulation results demonstrate the effectiveness and the superior performance of our proposed method.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9002\u7528\u4e8e\u4efb\u610f\u672a\u77e5\u975e\u5706\u76f8\u4f4d\u7684\u5757\u7a00\u758f\u8d1d\u53f6\u65af\u5b66\u4e60\u7b97\u6cd5\uff0c\u7528\u4e8e\u975e\u5706\u4fe1\u53f7\u7684DOA\u4f30\u8ba1", "motivation": "\u73b0\u6709\u65b9\u6cd5\u5728\u5904\u7406\u975e\u5706\u4fe1\u53f7\u65f6\uff0c\u7279\u522b\u662f\u5f53\u975e\u5706\u76f8\u4f4d\u672a\u77e5\u65f6\uff0c\u6027\u80fd\u53d7\u9650\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u5229\u7528\u975e\u5706\u4fe1\u53f7\u5757\u7a00\u758f\u7ed3\u6784\u4fe1\u606f\u7684\u65b9\u6cd5\u6765\u63d0\u9ad8DOA\u4f30\u8ba1\u6027\u80fd", "method": "1) \u901a\u8fc7\u7f6e\u6362\u7b56\u7565\u6784\u5efa\u5757\u7a00\u758f\u975e\u5706\u4fe1\u53f7\u8868\u793a\u6a21\u578b\uff1b2) \u5efa\u7acb\u7a00\u758f\u6982\u7387\u6a21\u578b\u5e76\u5728BSBL\u6846\u67b6\u4e0b\u63a8\u5bfc\u4ee3\u4ef7\u51fd\u6570\uff1b3) \u5f15\u5165\u5feb\u901f\u8fb9\u9645\u4f3c\u7136\u6700\u5927\u5316\u7b97\u6cd5\uff0c\u901a\u8fc7\u57fa\u51fd\u6570\u7684\u6dfb\u52a0\u548c\u79fb\u9664\u5b9e\u73b0\u5feb\u901f\u4fe1\u53f7\u6062\u590d", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\u6240\u63d0\u65b9\u6cd5\u6709\u6548\u4e14\u6027\u80fd\u4f18\u8d8a\uff0c\u80fd\u591f\u5229\u7528\u5757\u5185\u7ed3\u6784\u4fe1\u606f\u589e\u5f3a\u6062\u590d\u6027\u80fd", "conclusion": "\u63d0\u51fa\u7684BSBL\u7b97\u6cd5\u80fd\u591f\u5904\u7406\u4efb\u610f\u672a\u77e5\u975e\u5706\u76f8\u4f4d\u7684\u975e\u5706\u4fe1\u53f7\uff0c\u901a\u8fc7\u5757\u7a00\u758f\u5efa\u6a21\u548c\u5feb\u901f\u5b9e\u73b0\u7b97\u6cd5\uff0c\u5728DOA\u4f30\u8ba1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd"}}
{"id": "2601.09333", "categories": ["cs.SD", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.09333", "abs": "https://arxiv.org/abs/2601.09333", "authors": ["Chun-Chieh Hsu", "Tsai-Ling Hsu", "Chen-Chen Yeh", "Shao-Chien Lu", "Cheng-Han Wu", "Bing-Ze Liu", "Timothy K. Shih", "Yu-Cheng Lin"], "title": "Research on Piano Timbre Transformation System Based on Diffusion Model", "comment": null, "summary": "We propose a timbre conversion model based on the Diffusion architecture de-signed to precisely translate music played by various instruments into piano ver-sions. The model employs a Pitch Encoder and Loudness Encoder to extract pitch and loudness features of the music, which serve as conditional inputs to the Dif-fusion Model's decoder, generating high-quality piano timbres. Case analysis re-sults show that the model performs excellently in terms of pitch accuracy and timbral similarity, maintaining stable conversion across different musical styles (classical, jazz, pop) and lengths (from short clips to full pieces). Particularly, the model maintains high sound quality and accuracy even when dealing with rapidly changing notes and complex musical structures, demonstrating good generaliza-tion capability. Additionally, the model has the potential for real-time musical conversion and is suitable for live performances and digital music creation tools. Future research will focus on enhancing the handling of loudness dynamics and incorporating additional musical features (such as timbral variations and rhythmic complexity) to improve the model's adaptability and expressiveness. We plan to explore the model's application potential in other timbre conversion tasks, such as converting vocals to instrumental sounds or integration with MIDI digital pianos, further expanding the application scope of the Diffusion-based timbre conversion model in the field of music generation.", "AI": {"tldr": "\u57fa\u4e8e\u6269\u6563\u67b6\u6784\u7684\u4e50\u5668\u97f3\u8272\u8f6c\u6362\u6a21\u578b\uff0c\u53ef\u5c06\u591a\u79cd\u4e50\u5668\u6f14\u594f\u7684\u97f3\u4e50\u7cbe\u786e\u8f6c\u6362\u4e3a\u94a2\u7434\u7248\u672c\uff0c\u5728\u97f3\u9ad8\u51c6\u786e\u6027\u548c\u97f3\u8272\u76f8\u4f3c\u5ea6\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u9002\u7528\u4e8e\u5b9e\u65f6\u97f3\u4e50\u8f6c\u6362\u548c\u6570\u5b57\u97f3\u4e50\u521b\u4f5c\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u7cbe\u786e\u5c06\u5404\u79cd\u4e50\u5668\u6f14\u594f\u7684\u97f3\u4e50\u8f6c\u6362\u4e3a\u94a2\u7434\u7248\u672c\u7684\u6a21\u578b\uff0c\u89e3\u51b3\u73b0\u6709\u97f3\u8272\u8f6c\u6362\u65b9\u6cd5\u5728\u97f3\u9ad8\u51c6\u786e\u6027\u3001\u97f3\u8272\u76f8\u4f3c\u5ea6\u548c\u590d\u6742\u97f3\u4e50\u7ed3\u6784\u5904\u7406\u65b9\u9762\u7684\u4e0d\u8db3\u3002", "method": "\u91c7\u7528\u6269\u6563\u67b6\u6784\uff0c\u4f7f\u7528\u97f3\u9ad8\u7f16\u7801\u5668\u548c\u54cd\u5ea6\u7f16\u7801\u5668\u63d0\u53d6\u97f3\u4e50\u7684\u97f3\u9ad8\u548c\u54cd\u5ea6\u7279\u5f81\uff0c\u4f5c\u4e3a\u6269\u6563\u6a21\u578b\u89e3\u7801\u5668\u7684\u6761\u4ef6\u8f93\u5165\uff0c\u751f\u6210\u9ad8\u8d28\u91cf\u7684\u94a2\u7434\u97f3\u8272\u3002", "result": "\u6a21\u578b\u5728\u97f3\u9ad8\u51c6\u786e\u6027\u548c\u97f3\u8272\u76f8\u4f3c\u5ea6\u65b9\u9762\u8868\u73b0\u4f18\u5f02\uff0c\u5728\u4e0d\u540c\u97f3\u4e50\u98ce\u683c\uff08\u53e4\u5178\u3001\u7235\u58eb\u3001\u6d41\u884c\uff09\u548c\u957f\u5ea6\uff08\u4ece\u77ed\u7247\u6bb5\u5230\u5b8c\u6574\u66f2\u76ee\uff09\u4e0a\u4fdd\u6301\u7a33\u5b9a\u8f6c\u6362\uff0c\u5bf9\u5feb\u901f\u53d8\u5316\u7684\u97f3\u7b26\u548c\u590d\u6742\u97f3\u4e50\u7ed3\u6784\u5904\u7406\u826f\u597d\uff0c\u5177\u6709\u8f83\u597d\u7684\u6cdb\u5316\u80fd\u529b\u3002", "conclusion": "\u8be5\u6269\u6563\u67b6\u6784\u97f3\u8272\u8f6c\u6362\u6a21\u578b\u5728\u4e50\u5668\u5230\u94a2\u7434\u7684\u8f6c\u6362\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u8272\uff0c\u5177\u6709\u5b9e\u65f6\u8f6c\u6362\u6f5c\u529b\uff0c\u672a\u6765\u5c06\u589e\u5f3a\u54cd\u5ea6\u52a8\u6001\u5904\u7406\u5e76\u6574\u5408\u66f4\u591a\u97f3\u4e50\u7279\u5f81\uff0c\u63a2\u7d22\u5728\u4eba\u58f0\u8f6c\u4e50\u5668\u97f3\u8272\u548cMIDI\u6570\u5b57\u94a2\u7434\u96c6\u6210\u7b49\u9886\u57df\u7684\u5e94\u7528\u3002"}}
{"id": "2601.09168", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09168", "abs": "https://arxiv.org/abs/2601.09168", "authors": ["Sojeong Park", "Yeongjun Kim", "Hyun Jong Yang"], "title": "User-Centric Stream Sensing for Grant-Free Access: Deep Learning with Covariance Differencing", "comment": null, "summary": "Grant-free (GF) access is essential for massive connectivity but faces collision risks due to uncoordinated transmissions. While user-side sensing can mitigate these collisions by enabling autonomous transmission decisions, conventional methods become ineffective in overloaded scenarios where active streams exceed receive antennas. To address this problem, we propose a differential stream sensing framework that reframes the problem from estimating the total stream count to isolating newly activated streams via covariance differencing. We analyze the covariance deviation induced by channel variations to establish a theoretical bound based on channel correlation for determining the sensing window size. To mitigate residual interference from finite sampling, a deep learning (DL) classifier is integrated. Simulations across both independent and identically distributed flat Rayleigh fading and standardized channel environments demonstrate that the proposed method consistently outperforms non-DL baselines and remains robust in overloaded scenarios.", "AI": {"tldr": "\u63d0\u51fa\u5dee\u5206\u6d41\u611f\u77e5\u6846\u67b6\uff0c\u901a\u8fc7\u534f\u65b9\u5dee\u5dee\u5206\u9694\u79bb\u65b0\u6fc0\u6d3b\u6d41\u800c\u975e\u4f30\u8ba1\u603b\u6d41\u6570\uff0c\u7ed3\u5408\u6df1\u5ea6\u5b66\u4e60\u5206\u7c7b\u5668\u5904\u7406\u6709\u9650\u91c7\u6837\u6b8b\u7559\u5e72\u6270\uff0c\u5728\u8fc7\u8f7d\u573a\u666f\u4e0b\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5", "motivation": "\u514d\u6388\u6743\u63a5\u5165\u5bf9\u5927\u89c4\u6a21\u8fde\u63a5\u81f3\u5173\u91cd\u8981\uff0c\u4f46\u9762\u4e34\u65e0\u534f\u8c03\u4f20\u8f93\u7684\u78b0\u649e\u98ce\u9669\u3002\u7528\u6237\u4fa7\u611f\u77e5\u867d\u80fd\u901a\u8fc7\u81ea\u4e3b\u4f20\u8f93\u51b3\u7b56\u7f13\u89e3\u78b0\u649e\uff0c\u4f46\u4f20\u7edf\u65b9\u6cd5\u5728\u6d3b\u8dc3\u6d41\u8d85\u8fc7\u63a5\u6536\u5929\u7ebf\u7684\u8fc7\u8f7d\u573a\u666f\u4e0b\u5931\u6548", "method": "\u63d0\u51fa\u5dee\u5206\u6d41\u611f\u77e5\u6846\u67b6\uff0c\u5c06\u95ee\u9898\u4ece\u4f30\u8ba1\u603b\u6d41\u6570\u91cd\u6784\u4e3a\u901a\u8fc7\u534f\u65b9\u5dee\u5dee\u5206\u9694\u79bb\u65b0\u6fc0\u6d3b\u6d41\u3002\u5206\u6790\u4fe1\u9053\u53d8\u5316\u5f15\u8d77\u7684\u534f\u65b9\u5dee\u504f\u5dee\uff0c\u5efa\u7acb\u57fa\u4e8e\u4fe1\u9053\u76f8\u5173\u7684\u7406\u8bba\u754c\u786e\u5b9a\u611f\u77e5\u7a97\u53e3\u5927\u5c0f\u3002\u96c6\u6210\u6df1\u5ea6\u5b66\u4e60\u5206\u7c7b\u5668\u7f13\u89e3\u6709\u9650\u91c7\u6837\u6b8b\u7559\u5e72\u6270", "result": "\u5728\u72ec\u7acb\u540c\u5206\u5e03\u5e73\u5766\u745e\u5229\u8870\u843d\u548c\u6807\u51c6\u5316\u4fe1\u9053\u73af\u5883\u4e0b\u7684\u4eff\u771f\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u59cb\u7ec8\u4f18\u4e8e\u975e\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\uff0c\u5e76\u5728\u8fc7\u8f7d\u573a\u666f\u4e0b\u4fdd\u6301\u9c81\u68d2\u6027", "conclusion": "\u5dee\u5206\u6d41\u611f\u77e5\u6846\u67b6\u901a\u8fc7\u534f\u65b9\u5dee\u5dee\u5206\u548c\u6df1\u5ea6\u5b66\u4e60\u5206\u7c7b\u5668\u7684\u7ed3\u5408\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u514d\u6388\u6743\u63a5\u5165\u5728\u8fc7\u8f7d\u573a\u666f\u4e0b\u7684\u611f\u77e5\u95ee\u9898\uff0c\u63d0\u5347\u4e86\u5927\u89c4\u6a21\u8fde\u63a5\u7684\u6027\u80fd"}}
{"id": "2601.09385", "categories": ["cs.SD", "cs.CL", "cs.MM"], "pdf": "https://arxiv.org/pdf/2601.09385", "abs": "https://arxiv.org/abs/2601.09385", "authors": ["Ziyang Ma", "Guanrou Yang", "Wenxi Chen", "Zhifu Gao", "Yexing Du", "Xiquan Li", "Zhisheng Zheng", "Haina Zhu", "Jianheng Zhuo", "Zheshu Song", "Ruiyang Xu", "Tiranrui Wang", "Yifan Yang", "Yanqiao Zhu", "Zhikang Niu", "Liumeng Xue", "Yinghao Ma", "Ruibin Yuan", "Shiliang Zhang", "Kai Yu", "Eng Siong Chng", "Xie Chen"], "title": "SLAM-LLM: A Modular, Open-Source Multimodal Large Language Model Framework and Best Practice for Speech, Language, Audio and Music Processing", "comment": "Published in IEEE Journal of Selected Topics in Signal Processing (JSTSP)", "summary": "The recent surge in open-source Multimodal Large Language Models (MLLM) frameworks, such as LLaVA, provides a convenient kickoff for artificial intelligence developers and researchers. However, most of the MLLM frameworks take vision as the main input modality, and provide limited in-depth support for the modality of speech, audio, and music. This situation hinders the development of audio-language models, and forces researchers to spend a lot of effort on code writing and hyperparameter tuning. We present SLAM-LLM, an open-source deep learning framework designed to train customized MLLMs, focused on speech, language, audio, and music processing. SLAM-LLM provides a modular configuration of different encoders, projectors, LLMs, and parameter-efficient fine-tuning plugins. SLAM-LLM also includes detailed training and inference recipes for mainstream tasks, along with high-performance checkpoints like LLM-based Automatic Speech Recognition (ASR), Automated Audio Captioning (AAC), and Music Captioning (MC). Some of these recipes have already reached or are nearing state-of-the-art performance, and some relevant techniques have also been accepted by academic papers. We hope SLAM-LLM will accelerate iteration, development, data engineering, and model training for researchers. We are committed to continually pushing forward audio-based MLLMs through this open-source framework, and call on the community to contribute to the LLM-based speech, audio and music processing.", "AI": {"tldr": "SLAM-LLM\u662f\u4e00\u4e2a\u5f00\u6e90\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u4e13\u95e8\u7528\u4e8e\u8bad\u7ec3\u4e13\u6ce8\u4e8e\u8bed\u97f3\u3001\u8bed\u8a00\u3001\u97f3\u9891\u548c\u97f3\u4e50\u5904\u7406\u7684\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\uff0c\u65e8\u5728\u89e3\u51b3\u73b0\u6709MLLM\u6846\u67b6\u5bf9\u97f3\u9891\u6a21\u6001\u652f\u6301\u4e0d\u8db3\u7684\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u5f00\u6e90\u591a\u6a21\u6001\u5927\u8bed\u8a00\u6a21\u578b\u6846\u67b6\uff08\u5982LLaVA\uff09\u4e3b\u8981\u5173\u6ce8\u89c6\u89c9\u6a21\u6001\uff0c\u5bf9\u8bed\u97f3\u3001\u97f3\u9891\u548c\u97f3\u4e50\u6a21\u6001\u7684\u652f\u6301\u6709\u9650\uff0c\u8fd9\u963b\u788d\u4e86\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u7684\u53d1\u5c55\uff0c\u5e76\u8feb\u4f7f\u7814\u7a76\u4eba\u5458\u82b1\u8d39\u5927\u91cf\u7cbe\u529b\u5728\u4ee3\u7801\u7f16\u5199\u548c\u8d85\u53c2\u6570\u8c03\u4f18\u4e0a\u3002", "method": "SLAM-LLM\u63d0\u4f9b\u6a21\u5757\u5316\u914d\u7f6e\uff0c\u5305\u62ec\u4e0d\u540c\u7f16\u7801\u5668\u3001\u6295\u5f71\u5668\u3001\u5927\u8bed\u8a00\u6a21\u578b\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u63d2\u4ef6\uff0c\u5e76\u63d0\u4f9b\u4e3b\u6d41\u4efb\u52a1\u7684\u8be6\u7ec6\u8bad\u7ec3\u548c\u63a8\u7406\u65b9\u6848\uff0c\u4ee5\u53ca\u9ad8\u6027\u80fd\u68c0\u67e5\u70b9\u3002", "result": "\u6846\u67b6\u5df2\u5b9e\u73b0\u6216\u63a5\u8fd1SOTA\u6027\u80fd\u7684\u4efb\u52a1\u5305\u62ec\u57fa\u4e8eLLM\u7684\u81ea\u52a8\u8bed\u97f3\u8bc6\u522b\u3001\u81ea\u52a8\u97f3\u9891\u63cf\u8ff0\u548c\u97f3\u4e50\u63cf\u8ff0\uff0c\u76f8\u5173\u6280\u672f\u5df2\u88ab\u5b66\u672f\u8bba\u6587\u63a5\u53d7\u3002", "conclusion": "SLAM-LLM\u65e8\u5728\u52a0\u901f\u7814\u7a76\u4eba\u5458\u5728\u97f3\u9891\u57faMLLM\u9886\u57df\u7684\u8fed\u4ee3\u3001\u5f00\u53d1\u3001\u6570\u636e\u5de5\u7a0b\u548c\u6a21\u578b\u8bad\u7ec3\uff0c\u5e76\u547c\u5401\u793e\u533a\u5171\u540c\u63a8\u52a8\u57fa\u4e8eLLM\u7684\u8bed\u97f3\u3001\u97f3\u9891\u548c\u97f3\u4e50\u5904\u7406\u53d1\u5c55\u3002"}}
{"id": "2601.09179", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09179", "abs": "https://arxiv.org/abs/2601.09179", "authors": ["Haotian Zhang", "Shijian Gao", "Xiang Cheng"], "title": "WiFo-M$^2$: Plug-and-Play Multi-Modal Sensing via Foundation Model to Empower Wireless Communications", "comment": "13 pages, 8 figures, 7 tables", "summary": "The growing adoption of sensor-rich intelligent systems has boosted the use of multi-modal sensing to improve wireless communications. However, traditional methods require extensive manual design of data preprocessing, network architecture, and task-specific fine-tuning, which limits both development scalability and real-world deployment. To address this, we propose WiFo-M$^2$, a foundation model that can be easily plugged into existing deep learning-based transceivers for universal performance gains. To extract generalizable out-of-band (OOB) channel features from multi-modal sensing, we introduce ContraSoM, a contrastive pre-training strategy. Once pre-trained, WiFo-M$^2$ infers future OOB channel features from historical sensor data and strengthens feature robustness via modality-specific data augmentation. Experiments show that WiFo-M$^2$ improves performance across multiple transceiver designs and demonstrates strong generalization to unseen scenarios.", "AI": {"tldr": "WiFo-M\u00b2\u662f\u4e00\u4e2a\u53ef\u63d2\u5165\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u6536\u53d1\u5668\u7684\u591a\u6a21\u6001\u4f20\u611f\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u5bf9\u6bd4\u9884\u8bad\u7ec3\u63d0\u53d6\u901a\u7528OOB\u4fe1\u9053\u7279\u5f81\uff0c\u63d0\u5347\u65e0\u7ebf\u901a\u4fe1\u6027\u80fd", "motivation": "\u4f20\u7edf\u591a\u6a21\u6001\u4f20\u611f\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u4eba\u5de5\u8bbe\u8ba1\u6570\u636e\u9884\u5904\u7406\u3001\u7f51\u7edc\u67b6\u6784\u548c\u4efb\u52a1\u7279\u5b9a\u5fae\u8c03\uff0c\u9650\u5236\u4e86\u5f00\u53d1\u53ef\u6269\u5c55\u6027\u548c\u5b9e\u9645\u90e8\u7f72", "method": "\u63d0\u51faWiFo-M\u00b2\u57fa\u7840\u6a21\u578b\uff0c\u5f15\u5165ContraSoM\u5bf9\u6bd4\u9884\u8bad\u7ec3\u7b56\u7565\u63d0\u53d6\u901a\u7528OOB\u4fe1\u9053\u7279\u5f81\uff0c\u901a\u8fc7\u6a21\u6001\u7279\u5b9a\u6570\u636e\u589e\u5f3a\u589e\u5f3a\u7279\u5f81\u9c81\u68d2\u6027", "result": "WiFo-M\u00b2\u5728\u591a\u79cd\u6536\u53d1\u5668\u8bbe\u8ba1\u4e2d\u5747\u80fd\u63d0\u5347\u6027\u80fd\uff0c\u5e76\u5728\u672a\u89c1\u573a\u666f\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b", "conclusion": "WiFo-M\u00b2\u4e3a\u591a\u6a21\u6001\u4f20\u611f\u65e0\u7ebf\u901a\u4fe1\u63d0\u4f9b\u4e86\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u8f7b\u677e\u96c6\u6210\u5230\u73b0\u6709\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u901a\u7528\u6027\u80fd\u63d0\u5347"}}
{"id": "2601.09186", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09186", "abs": "https://arxiv.org/abs/2601.09186", "authors": ["Weibo Wen", "Shijian Gao", "Haotian Zhang", "Xiang Cheng", "Liuqing Yang"], "title": "WiFo-E: A Scalable Wireless Foundation Model for End-to-End FDD Precoding in Communication Networks", "comment": null, "summary": "Accurate precoding in massive multiple-input multiple-output (MIMO) frequency-division duplexing (FDD) systems relies on efficient channel state information (CSI) acquisition. End-to-end learning frameworks improve performance by jointly optimizing this process, but they lack scalability and fail to generalize across different system configurations, such as varying numbers of antennas and users. To overcome this limitation, we introduce WiFo-E, a wireless foundation model designed for scalable end-to-end precoding. WiFo-E employs multi-task pretraining on a diverse set of configurations to learn transferable representations of underlying wireless principles. Central to the model is a sparse Mixture-of-Experts (MoE) Transformer architecture, which mitigates task interference and enhances training efficiency by activating specialized parameter subsets adaptively. Extensive simulations demonstrate that WiFo-E outperforms conventional per-configuration training and shows strong generalization to unseen system configurations, providing a flexible and efficient foundation for adaptive massive MIMO precoding.", "AI": {"tldr": "WiFo-E\uff1a\u7528\u4e8e\u5927\u89c4\u6a21MIMO FDD\u7cfb\u7edf\u7684\u53ef\u6269\u5c55\u7aef\u5230\u7aef\u9884\u7f16\u7801\u65e0\u7ebf\u57fa\u7840\u6a21\u578b\uff0c\u901a\u8fc7\u591a\u4efb\u52a1\u9884\u8bad\u7ec3\u548c\u7a00\u758fMoE Transformer\u67b6\u6784\u5b9e\u73b0\u8de8\u914d\u7f6e\u6cdb\u5316", "motivation": "\u73b0\u6709\u7aef\u5230\u7aef\u5b66\u4e60\u6846\u67b6\u5728\u5927\u89c4\u6a21MIMO FDD\u7cfb\u7edf\u4e2d\u7f3a\u4e4f\u53ef\u6269\u5c55\u6027\uff0c\u65e0\u6cd5\u6cdb\u5316\u5230\u4e0d\u540c\u5929\u7ebf\u6570\u548c\u7528\u6237\u6570\u7684\u7cfb\u7edf\u914d\u7f6e\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u9002\u5e94\u591a\u79cd\u914d\u7f6e\u7684\u901a\u7528\u89e3\u51b3\u65b9\u6848", "method": "\u63d0\u51faWiFo-E\u65e0\u7ebf\u57fa\u7840\u6a21\u578b\uff0c\u91c7\u7528\u591a\u4efb\u52a1\u9884\u8bad\u7ec3\u5b66\u4e60\u65e0\u7ebf\u539f\u7406\u7684\u53ef\u8fc1\u79fb\u8868\u793a\uff0c\u6838\u5fc3\u662f\u7a00\u758f\u6df7\u5408\u4e13\u5bb6(MoE) Transformer\u67b6\u6784\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6fc0\u6d3b\u4e13\u7528\u53c2\u6570\u5b50\u96c6\u51cf\u5c11\u4efb\u52a1\u5e72\u6270\u5e76\u63d0\u9ad8\u8bad\u7ec3\u6548\u7387", "result": "\u5e7f\u6cdb\u4eff\u771f\u8868\u660eWiFo-E\u4f18\u4e8e\u4f20\u7edf\u7684\u6309\u914d\u7f6e\u8bad\u7ec3\u65b9\u6cd5\uff0c\u5728\u672a\u89c1\u8fc7\u7684\u7cfb\u7edf\u914d\u7f6e\u4e0a\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u6cdb\u5316\u80fd\u529b", "conclusion": "WiFo-E\u4e3a\u81ea\u9002\u5e94\u5927\u89c4\u6a21MIMO\u9884\u7f16\u7801\u63d0\u4f9b\u4e86\u4e00\u4e2a\u7075\u6d3b\u9ad8\u6548\u7684\u57fa\u7840\u6a21\u578b\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u7aef\u5230\u7aef\u5b66\u4e60\u6846\u67b6\u7684\u53ef\u6269\u5c55\u6027\u548c\u6cdb\u5316\u6027\u95ee\u9898"}}
{"id": "2601.09448", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09448", "abs": "https://arxiv.org/abs/2601.09448", "authors": ["Ioannis Stylianou", "Jon Francombe", "Pablo Martinez-Nuevo", "Sven Ewan Shepstone", "Zheng-Hua Tan"], "title": "Population-Aligned Audio Reproduction With LLM-Based Equalizers", "comment": "12 pages, 13 figures, 2 tables, IEEE JSTSP journal submission under first revision", "summary": "Conventional audio equalization is a static process that requires manual and cumbersome adjustments to adapt to changing listening contexts (e.g., mood, location, or social setting). In this paper, we introduce a Large Language Model (LLM)-based alternative that maps natural language text prompts to equalization settings. This enables a conversational approach to sound system control. By utilizing data collected from a controlled listening experiment, our models exploit in-context learning and parameter-efficient fine-tuning techniques to reliably align with population-preferred equalization settings. Our evaluation methods, which leverage distributional metrics that capture users' varied preferences, show statistically significant improvements in distributional alignment over random sampling and static preset baselines. These results indicate that LLMs could function as \"artificial equalizers,\" contributing to the development of more accessible, context-aware, and expert-level audio tuning methods.", "AI": {"tldr": "\u4f7f\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u5c06\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u6620\u5c04\u5230\u5747\u8861\u5668\u8bbe\u7f6e\uff0c\u5b9e\u73b0\u5bf9\u8bdd\u5f0f\u97f3\u9891\u7cfb\u7edf\u63a7\u5236\uff0c\u76f8\u6bd4\u4f20\u7edf\u9759\u6001\u5747\u8861\u6709\u663e\u8457\u6539\u8fdb", "motivation": "\u4f20\u7edf\u97f3\u9891\u5747\u8861\u662f\u9759\u6001\u8fc7\u7a0b\uff0c\u9700\u8981\u624b\u52a8\u8c03\u6574\u4ee5\u9002\u5e94\u53d8\u5316\u7684\u8046\u542c\u73af\u5883\uff08\u5982\u60c5\u7eea\u3001\u4f4d\u7f6e\u6216\u793e\u4ea4\u573a\u5408\uff09\uff0c\u8fc7\u7a0b\u7e41\u7410\u4e0d\u4fbf", "method": "\u57fa\u4e8eLLM\u7684\u65b9\u6cd5\uff0c\u5229\u7528\u53d7\u63a7\u542c\u529b\u5b9e\u9a8c\u6536\u96c6\u7684\u6570\u636e\uff0c\u91c7\u7528\u4e0a\u4e0b\u6587\u5b66\u4e60\u548c\u53c2\u6570\u9ad8\u6548\u5fae\u8c03\u6280\u672f\uff0c\u5c06\u81ea\u7136\u8bed\u8a00\u63d0\u793a\u6620\u5c04\u5230\u5747\u8861\u5668\u8bbe\u7f6e", "result": "\u8bc4\u4f30\u663e\u793a\uff0c\u5728\u5206\u5e03\u5bf9\u9f50\u6307\u6807\u4e0a\uff0c\u8be5\u65b9\u6cd5\u76f8\u6bd4\u968f\u673a\u91c7\u6837\u548c\u9759\u6001\u9884\u8bbe\u57fa\u7ebf\u6709\u7edf\u8ba1\u663e\u8457\u6539\u8fdb\uff0c\u80fd\u66f4\u597d\u5730\u5339\u914d\u7528\u6237\u504f\u597d\u5206\u5e03", "conclusion": "LLM\u53ef\u4f5c\u4e3a\"\u4eba\u5de5\u5747\u8861\u5668\"\uff0c\u6709\u52a9\u4e8e\u5f00\u53d1\u66f4\u6613\u7528\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u548c\u4e13\u4e1a\u7ea7\u7684\u97f3\u9891\u8c03\u8c10\u65b9\u6cd5"}}
{"id": "2601.09205", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09205", "abs": "https://arxiv.org/abs/2601.09205", "authors": ["Ruisi He", "Mi Yang", "Zhengyu Zhang", "Bo Ai", "Zhangdui Zhong"], "title": "Artificial Intelligence Empowered Channel Prediction: A New Paradigm for Propagation Channel Modeling", "comment": null, "summary": "This paper proposes a novel paradigm centered on Artificial Intelligence (AI)-empowered propagation channel prediction to address the limitations of traditional channel modeling. We present a comprehensive framework that deeply integrates heterogeneous environmental data and physical propagation knowledge into AI models for site-specific channel prediction, which referred to as channel inference. By leveraging AI to infer site-specific wireless channel states, the proposed paradigm enables accurate prediction of channel characteristics at both link and area levels, capturing spatio-temporal evolution of radio propagation. Some novel strategies to realize the paradigm are introduced and discussed, including AI-native and AI-hybrid inference approaches. This paper also investigates how to enhance model generalization through transfer learning and improve interpretability via explainable AI techniques. Our approach demonstrates significant practical efficacy, achieving an average path loss prediction root mean square error (RMSE) of $\\sim$ 4 dB and reducing training time by 60\\%-75\\%. This new modeling paradigm provides a foundational pathway toward high-fidelity, generalizable, and physically consistent propagation channel prediction for future communication networks.", "AI": {"tldr": "\u63d0\u51faAI\u8d4b\u80fd\u7684\u4f20\u64ad\u4fe1\u9053\u9884\u6d4b\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u6df1\u5ea6\u6574\u5408\u73af\u5883\u6570\u636e\u548c\u7269\u7406\u77e5\u8bc6\u5b9e\u73b0\u7ad9\u70b9\u7279\u5b9a\u4fe1\u9053\u63a8\u65ad\uff0c\u663e\u8457\u63d0\u5347\u9884\u6d4b\u7cbe\u5ea6\u548c\u6548\u7387\u3002", "motivation": "\u4f20\u7edf\u4fe1\u9053\u5efa\u6a21\u65b9\u6cd5\u5b58\u5728\u5c40\u9650\u6027\uff0c\u65e0\u6cd5\u51c6\u786e\u6355\u6349\u65e0\u7ebf\u4fe1\u9053\u7684\u65f6\u7a7a\u6f14\u5316\u7279\u6027\uff0c\u9700\u8981\u65b0\u7684AI\u9a71\u52a8\u65b9\u6cd5\u6765\u5b9e\u73b0\u9ad8\u4fdd\u771f\u3001\u53ef\u6cdb\u5316\u7684\u4fe1\u9053\u9884\u6d4b\u3002", "method": "\u63d0\u51fa\u7efc\u5408\u6846\u67b6\uff0c\u6df1\u5ea6\u6574\u5408\u5f02\u6784\u73af\u5883\u6570\u636e\u548c\u7269\u7406\u4f20\u64ad\u77e5\u8bc6\u5230AI\u6a21\u578b\u4e2d\uff0c\u91c7\u7528AI\u539f\u751f\u548cAI\u6df7\u5408\u63a8\u65ad\u65b9\u6cd5\uff0c\u7ed3\u5408\u8fc1\u79fb\u5b66\u4e60\u548c\u53ef\u89e3\u91caAI\u6280\u672f\u3002", "result": "\u5e73\u5747\u8def\u5f84\u635f\u8017\u9884\u6d4bRMSE\u7ea6\u4e3a4dB\uff0c\u8bad\u7ec3\u65f6\u95f4\u51cf\u5c1160%-75%\uff0c\u5b9e\u73b0\u4e86\u94fe\u8def\u548c\u533a\u57df\u7ea7\u522b\u7684\u51c6\u786e\u4fe1\u9053\u7279\u6027\u9884\u6d4b\u3002", "conclusion": "\u8be5AI\u8d4b\u80fd\u7684\u4fe1\u9053\u63a8\u65ad\u65b0\u8303\u5f0f\u4e3a\u672a\u6765\u901a\u4fe1\u7f51\u7edc\u63d0\u4f9b\u4e86\u9ad8\u4fdd\u771f\u3001\u53ef\u6cdb\u5316\u4e14\u7269\u7406\u4e00\u81f4\u7684\u4f20\u64ad\u4fe1\u9053\u9884\u6d4b\u57fa\u7840\u8def\u5f84\u3002"}}
{"id": "2601.09461", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2601.09461", "abs": "https://arxiv.org/abs/2601.09461", "authors": ["Reemt Hinrichs", "Muhamad Fadli Damara", "Stephan Preihs", "J\u00f6rn Ostermann"], "title": "Analysis of the Maximum Prediction Gain of Short-Term Prediction on Sustained Speech", "comment": "Rejected at Eurasip for practical irrelevancy. Submitted here for reference. Originally accepted at DCC 2020 (Poster) but withdrawn due to page count limit", "summary": "Signal prediction is widely used in, e.g., economic forecasting, echo cancellation and in data compression, particularly in predictive coding of speech and music. Predictive coding algorithms reduce the bit-rate required for data transmission or storage by signal prediction. The prediction gain is a classic measure in applied signal coding of the quality of a predictor, as it links the mean-squared prediction error to the signal-to-quantization-noise of predictive coders. To evaluate predictor models, knowledge about the maximum achievable prediction gain independent of a predictor model is desirable. In this manuscript, Nadaraya-Watson kernel-regression (NWKR) and an information theoretic upper bound are applied to analyze the upper bound of the prediction gain on a newly recorded dataset of sustained speech/phonemes. It was found that for unvoiced speech a linear predictor always achieves the maximum prediction gain within at most 0.3 dB. On voiced speech, the optimum one-tap predictor was found to be linear but starting with two taps, the maximum achievable prediction gain was found to be about 2 dB to 6 dB above the prediction gain of the linear predictor. Significant differences between speakers/subjects were observed.\n  The created dataset as well as the code can be obtained for research purpose upon request.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4f7f\u7528Nadaraya-Watson\u6838\u56de\u5f52\u548c\u4fe1\u606f\u7406\u8bba\u4e0a\u754c\u5206\u6790\u8bed\u97f3\u9884\u6d4b\u589e\u76ca\u7684\u4e0a\u9650\uff0c\u53d1\u73b0\u5728\u6e05\u97f3\u8bed\u97f3\u4e2d\u7ebf\u6027\u9884\u6d4b\u5668\u51e0\u4e4e\u8fbe\u5230\u6700\u5927\u9884\u6d4b\u589e\u76ca\uff0c\u800c\u5728\u6d4a\u97f3\u8bed\u97f3\u4e2d\u591a\u62bd\u5934\u975e\u7ebf\u6027\u9884\u6d4b\u5668\u53ef\u63d0\u4f9b2-6dB\u7684\u989d\u5916\u589e\u76ca\u3002", "motivation": "\u9884\u6d4b\u7f16\u7801\u7b97\u6cd5\u901a\u8fc7\u4fe1\u53f7\u9884\u6d4b\u964d\u4f4e\u6570\u636e\u4f20\u8f93\u6216\u5b58\u50a8\u7684\u6bd4\u7279\u7387\uff0c\u9884\u6d4b\u589e\u76ca\u662f\u8861\u91cf\u9884\u6d4b\u5668\u8d28\u91cf\u7684\u91cd\u8981\u6307\u6807\u3002\u9700\u8981\u4e86\u89e3\u72ec\u7acb\u4e8e\u9884\u6d4b\u5668\u6a21\u578b\u7684\u6700\u5927\u53ef\u8fbe\u5230\u9884\u6d4b\u589e\u76ca\uff0c\u4ee5\u8bc4\u4f30\u9884\u6d4b\u5668\u6a21\u578b\u7684\u6027\u80fd\u3002", "method": "\u5e94\u7528Nadaraya-Watson\u6838\u56de\u5f52\u548c\u4fe1\u606f\u7406\u8bba\u4e0a\u754c\uff0c\u5728\u65b0\u5f55\u5236\u7684\u6301\u7eed\u8bed\u97f3/\u97f3\u7d20\u6570\u636e\u96c6\u4e0a\u5206\u6790\u9884\u6d4b\u589e\u76ca\u7684\u4e0a\u9650\u3002\u6bd4\u8f83\u7ebf\u6027\u9884\u6d4b\u5668\u548c\u975e\u7ebf\u6027\u9884\u6d4b\u5668\u7684\u6027\u80fd\u3002", "result": "\u5bf9\u4e8e\u6e05\u97f3\u8bed\u97f3\uff0c\u7ebf\u6027\u9884\u6d4b\u5668\u59cb\u7ec8\u5728\u6700\u591a0.3dB\u5185\u8fbe\u5230\u6700\u5927\u9884\u6d4b\u589e\u76ca\u3002\u5bf9\u4e8e\u6d4a\u97f3\u8bed\u97f3\uff0c\u6700\u4f18\u5355\u62bd\u5934\u9884\u6d4b\u5668\u662f\u7ebf\u6027\u7684\uff0c\u4f46\u4ece\u4e24\u4e2a\u62bd\u5934\u5f00\u59cb\uff0c\u6700\u5927\u53ef\u8fbe\u5230\u9884\u6d4b\u589e\u76ca\u6bd4\u7ebf\u6027\u9884\u6d4b\u5668\u9ad8\u7ea62-6dB\u3002\u4e0d\u540c\u8bf4\u8bdd\u8005\u4e4b\u95f4\u5b58\u5728\u663e\u8457\u5dee\u5f02\u3002", "conclusion": "\u6e05\u97f3\u8bed\u97f3\u7684\u9884\u6d4b\u589e\u76ca\u57fa\u672c\u53ef\u7531\u7ebf\u6027\u9884\u6d4b\u5668\u5b9e\u73b0\uff0c\u800c\u6d4a\u97f3\u8bed\u97f3\u9700\u8981\u975e\u7ebf\u6027\u9884\u6d4b\u5668\u624d\u80fd\u83b7\u5f97\u663e\u8457\u66f4\u9ad8\u7684\u9884\u6d4b\u589e\u76ca\u3002\u7814\u7a76\u63d0\u4f9b\u4e86\u8bed\u97f3\u9884\u6d4b\u589e\u76ca\u7684\u7406\u8bba\u4e0a\u9650\u5206\u6790\uff0c\u5bf9\u9884\u6d4b\u7f16\u7801\u7b97\u6cd5\u8bbe\u8ba1\u6709\u6307\u5bfc\u610f\u4e49\u3002"}}
{"id": "2601.09317", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09317", "abs": "https://arxiv.org/abs/2601.09317", "authors": ["Nadav Neuberger", "Simon Kollecker", "Martin Kaeske"], "title": "Range-Doppler-Acceleration Estimation for Fast-Moving and Accelerating Targets", "comment": null, "summary": "A central aspect of every pulsed radar signal processor is the targets Range-Doppler estimation within a Coherent Processing Interval. Conventional methods typically rely on simplifying assumptions, such as linear target motion, narrowband operation, or constant velocity, to enable fast computation. However, these assumptions break down in scenarios involving quadratic range-time behavior, high radial velocities or accelerations, or wideband signals, leading to undesired effects such as intra-pulse Doppler shift/stretch and target migration across Range-Doppler cells. This paper presents a generalized waveform-independent Range-Doppler compression approach that compensates for these effects while maintaining minimal Signal-to-Noise-Ratio loss and practical computational efficiency. The performance limits of the proposed method are analyzed and expressed through a unified metric that depends on both scene and system parameters. Comparison with other approaches is presented, showing their estimation bias and performance degradation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u5e7f\u4e49\u6ce2\u5f62\u65e0\u5173\u7684\u8ddd\u79bb-\u591a\u666e\u52d2\u538b\u7f29\u65b9\u6cd5\uff0c\u8865\u507f\u4f20\u7edf\u65b9\u6cd5\u5728\u975e\u7ebf\u6027\u76ee\u6807\u8fd0\u52a8\u3001\u9ad8\u52a0\u901f\u5ea6\u6216\u5bbd\u5e26\u4fe1\u53f7\u573a\u666f\u4e0b\u7684\u6027\u80fd\u9000\u5316\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u96f7\u8fbe\u4fe1\u53f7\u5904\u7406\u65b9\u6cd5\u901a\u5e38\u57fa\u4e8e\u7ebf\u6027\u76ee\u6807\u8fd0\u52a8\u3001\u7a84\u5e26\u64cd\u4f5c\u6216\u6052\u5b9a\u901f\u5ea6\u7b49\u7b80\u5316\u5047\u8bbe\uff0c\u4f46\u5728\u6d89\u53ca\u4e8c\u6b21\u8ddd\u79bb-\u65f6\u95f4\u884c\u4e3a\u3001\u9ad8\u5f84\u5411\u901f\u5ea6/\u52a0\u901f\u5ea6\u6216\u5bbd\u5e26\u4fe1\u53f7\u7684\u5b9e\u9645\u573a\u666f\u4e2d\uff0c\u8fd9\u4e9b\u5047\u8bbe\u4f1a\u5931\u6548\uff0c\u5bfc\u81f4\u8109\u51b2\u5185\u591a\u666e\u52d2\u9891\u79fb/\u62c9\u4f38\u548c\u76ee\u6807\u5728\u8ddd\u79bb-\u591a\u666e\u52d2\u5355\u5143\u95f4\u8fc1\u79fb\u7b49\u4e0d\u826f\u6548\u5e94\u3002", "method": "\u63d0\u51fa\u4e00\u79cd\u5e7f\u4e49\u6ce2\u5f62\u65e0\u5173\u7684\u8ddd\u79bb-\u591a\u666e\u52d2\u538b\u7f29\u65b9\u6cd5\uff0c\u80fd\u591f\u8865\u507f\u4e0a\u8ff0\u6548\u5e94\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u5c0f\u7684\u4fe1\u566a\u6bd4\u635f\u5931\u548c\u5b9e\u9645\u8ba1\u7b97\u6548\u7387\u3002\u5206\u6790\u4e86\u8be5\u65b9\u6cd5\u7684\u6027\u80fd\u6781\u9650\uff0c\u5e76\u901a\u8fc7\u4e00\u4e2a\u4f9d\u8d56\u4e8e\u573a\u666f\u548c\u7cfb\u7edf\u53c2\u6570\u7684\u7edf\u4e00\u5ea6\u91cf\u6765\u8868\u8fbe\u3002", "result": "\u4e0e\u5176\u4ed6\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u5c55\u793a\u4e86\u4f20\u7edf\u65b9\u6cd5\u7684\u4f30\u8ba1\u504f\u5dee\u548c\u6027\u80fd\u9000\u5316\u3002\u63d0\u51fa\u7684\u65b9\u6cd5\u5728\u8865\u507f\u975e\u7ebf\u6027\u6548\u5e94\u65b9\u9762\u8868\u73b0\u66f4\u597d\uff0c\u540c\u65f6\u4fdd\u6301\u8ba1\u7b97\u6548\u7387\u3002", "conclusion": "\u8be5\u5e7f\u4e49\u6ce2\u5f62\u65e0\u5173\u65b9\u6cd5\u80fd\u591f\u6709\u6548\u5904\u7406\u4f20\u7edf\u96f7\u8fbe\u4fe1\u53f7\u5904\u7406\u4e2d\u7b80\u5316\u5047\u8bbe\u5931\u6548\u7684\u573a\u666f\uff0c\u4e3a\u6d89\u53ca\u975e\u7ebf\u6027\u76ee\u6807\u8fd0\u52a8\u3001\u9ad8\u52a0\u901f\u5ea6\u6216\u5bbd\u5e26\u4fe1\u53f7\u7684\u96f7\u8fbe\u7cfb\u7edf\u63d0\u4f9b\u4e86\u66f4\u9c81\u68d2\u7684\u8ddd\u79bb-\u591a\u666e\u52d2\u4f30\u8ba1\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2601.09520", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.09520", "abs": "https://arxiv.org/abs/2601.09520", "authors": ["Pierfrancesco Melucci", "Paolo Merialdo", "Taketo Akama"], "title": "Towards Realistic Synthetic Data for Automatic Drum Transcription", "comment": null, "summary": "Deep learning models define the state-of-the-art in Automatic Drum Transcription (ADT), yet their performance is contingent upon large-scale, paired audio-MIDI datasets, which are scarce. Existing workarounds that use synthetic data often introduce a significant domain gap, as they typically rely on low-fidelity SoundFont libraries that lack acoustic diversity. While high-quality one-shot samples offer a better alternative, they are not available in a standardized, large-scale format suitable for training. This paper introduces a new paradigm for ADT that circumvents the need for paired audio-MIDI training data. Our primary contribution is a semi-supervised method to automatically curate a large and diverse corpus of one-shot drum samples from unlabeled audio sources. We then use this corpus to synthesize a high-quality dataset from MIDI files alone, which we use to train a sequence-to-sequence transcription model. We evaluate our model on the ENST and MDB test sets, where it achieves new state-of-the-art results, significantly outperforming both fully supervised methods and previous synthetic-data approaches. The code for reproducing our experiments is publicly available at https://github.com/pier-maker92/ADT_STR", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u65e0\u9700\u914d\u5bf9\u97f3\u9891-MIDI\u8bad\u7ec3\u6570\u636e\u7684\u81ea\u52a8\u9f13\u8f6c\u5f55\u65b0\u8303\u5f0f\uff0c\u901a\u8fc7\u534a\u76d1\u7763\u65b9\u6cd5\u4ece\u65e0\u6807\u7b7e\u97f3\u9891\u4e2d\u81ea\u52a8\u6536\u96c6\u5927\u91cf\u591a\u6837\u5316\u7684\u5355\u6b21\u9f13\u6837\u672c\uff0c\u5e76\u7528\u5176\u5408\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\u6765\u8bad\u7ec3\u5e8f\u5217\u5230\u5e8f\u5217\u8f6c\u5f55\u6a21\u578b\uff0c\u5728ENST\u548cMDB\u6d4b\u8bd5\u96c6\u4e0a\u8fbe\u5230\u65b0\u7684SOTA\u7ed3\u679c\u3002", "motivation": "\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u9f13\u8f6c\u5f55\u6a21\u578b\u4f9d\u8d56\u5927\u89c4\u6a21\u914d\u5bf9\u97f3\u9891-MIDI\u6570\u636e\u96c6\uff0c\u4f46\u8fd9\u4e9b\u6570\u636e\u7a00\u7f3a\u3002\u73b0\u6709\u4f7f\u7528\u5408\u6210\u6570\u636e\u7684\u89e3\u51b3\u65b9\u6848\u901a\u5e38\u4f9d\u8d56\u4f4e\u4fdd\u771fSoundFont\u5e93\uff0c\u5b58\u5728\u663e\u8457\u9886\u57df\u5dee\u8ddd\u3002\u9ad8\u8d28\u91cf\u5355\u6b21\u6837\u672c\u867d\u66f4\u597d\uff0c\u4f46\u7f3a\u4e4f\u6807\u51c6\u5316\u5927\u89c4\u6a21\u683c\u5f0f\u3002", "method": "\u63d0\u51fa\u534a\u76d1\u7763\u65b9\u6cd5\u81ea\u52a8\u4ece\u65e0\u6807\u7b7e\u97f3\u9891\u6e90\u4e2d\u6536\u96c6\u5927\u89c4\u6a21\u591a\u6837\u5316\u5355\u6b21\u9f13\u6837\u672c\u8bed\u6599\u5e93\uff0c\u7136\u540e\u7528\u8be5\u8bed\u6599\u5e93\u4ec5\u4eceMIDI\u6587\u4ef6\u5408\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u7528\u4e8e\u8bad\u7ec3\u5e8f\u5217\u5230\u5e8f\u5217\u8f6c\u5f55\u6a21\u578b\u3002", "result": "\u5728ENST\u548cMDB\u6d4b\u8bd5\u96c6\u4e0a\u8bc4\u4f30\uff0c\u6a21\u578b\u53d6\u5f97\u65b0\u7684\u6700\u5148\u8fdb\u7ed3\u679c\uff0c\u663e\u8457\u4f18\u4e8e\u5b8c\u5168\u76d1\u7763\u65b9\u6cd5\u548c\u5148\u524d\u5408\u6210\u6570\u636e\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed5\u8fc7\u914d\u5bf9\u97f3\u9891-MIDI\u8bad\u7ec3\u6570\u636e\u9700\u6c42\u7684\u65b0\u9f13\u8f6c\u5f55\u8303\u5f0f\uff0c\u901a\u8fc7\u81ea\u52a8\u6536\u96c6\u5355\u6b21\u9f13\u6837\u672c\u548c\u5408\u6210\u9ad8\u8d28\u91cf\u6570\u636e\u96c6\uff0c\u5b9e\u73b0\u4e86\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u7684\u6027\u80fd\u3002"}}
{"id": "2601.09336", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09336", "abs": "https://arxiv.org/abs/2601.09336", "authors": ["Gabriele Bertoli", "Kai Schroeter", "Rossella Arcucci", "Enrica Caporali"], "title": "A Hybrid Machine Learning Framework for Improved Short-Term Peak-Flow Forecasting", "comment": "Comments: 16 pages, 6 figures. Revised version in preparation for journal submission", "summary": "Reliable river flow forecasting is an essential component of flood risk management and early warning systems. It enables improved emergency response coordination and is critical for protecting infrastructure, communities, and ecosystems from extreme hydrological events. Process-based hydrological models and purely data-driven approaches often underperform during extreme events, particularly in forecasting peak flows. To address this limitation, this study introduces a hybrid forecasting framework that couples Extreme Gradient Boosting (XGBoost) and Random Forest (RF). XGBoost is employed for continuous streamflow forecasting, while RF is specifically trained for peak-flow prediction, and the two outputs are combined into an enhanced forecast. The approach is implemented across 857 catchments of the LamaH-CE dataset, using rainfall and discharge observations at 6-hour resolution. Results demonstrate consistently high skill, with 71% of catchments achieving a Kling-Gupta Efficiency (KGE) greater than 0.90. Peak-flow detection reaches 87%, with a false-alarm rate of 13%. Compared to the European Flood Awareness System (EFAS), the framework achieves lower peak-magnitude errors, fewer false alarms, and improved streamflow and peak-flow forecasting accuracy. The proposed framework is computationally lightweight, scalable, and easily transferable across watersheds, with training times of only seconds on standard CPUs. These findings highlight the potential of integrating hydrological understanding with efficient machine learning to improve the accuracy and reliability of operational flood forecasting, and outline future directions for hybrid hydrological-machine learning model development.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408XGBoost\u548c\u968f\u673a\u68ee\u6797\u7684\u6df7\u5408\u6d2a\u6c34\u9884\u62a5\u6846\u67b6\uff0c\u5728857\u4e2a\u6d41\u57df\u4e0a\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5f84\u6d41\u548c\u5cf0\u503c\u6d41\u91cf\u9884\u6d4b\uff0c\u4f18\u4e8e\u73b0\u6709\u7cfb\u7edf\u3002", "motivation": "\u4f20\u7edf\u8fc7\u7a0b\u6c34\u6587\u6a21\u578b\u548c\u7eaf\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728\u6781\u7aef\u4e8b\u4ef6\uff08\u7279\u522b\u662f\u5cf0\u503c\u6d41\u91cf\uff09\u9884\u6d4b\u4e2d\u8868\u73b0\u4e0d\u4f73\uff0c\u9700\u8981\u66f4\u53ef\u9760\u7684\u6d2a\u6c34\u9884\u62a5\u7cfb\u7edf\u6765\u652f\u6301\u6d2a\u6c34\u98ce\u9669\u7ba1\u7406\u548c\u65e9\u671f\u9884\u8b66\u3002", "method": "\u5f00\u53d1\u6df7\u5408\u9884\u62a5\u6846\u67b6\uff1aXGBoost\u7528\u4e8e\u8fde\u7eed\u5f84\u6d41\u9884\u62a5\uff0c\u968f\u673a\u68ee\u6797\u4e13\u95e8\u8bad\u7ec3\u7528\u4e8e\u5cf0\u503c\u6d41\u91cf\u9884\u6d4b\uff0c\u4e24\u8005\u8f93\u51fa\u7ed3\u5408\u5f62\u6210\u589e\u5f3a\u9884\u62a5\u3002\u4f7f\u7528LamaH-CE\u6570\u636e\u96c6\u7684857\u4e2a\u6d41\u57df\uff0c\u4ee56\u5c0f\u65f6\u5206\u8fa8\u7387\u7684\u964d\u96e8\u548c\u6d41\u91cf\u89c2\u6d4b\u6570\u636e\u5b9e\u65bd\u3002", "result": "71%\u7684\u6d41\u57dfKling-Gupta\u6548\u7387\u5927\u4e8e0.90\uff0c\u5cf0\u503c\u6d41\u91cf\u68c0\u6d4b\u7387\u8fbe\u523087%\uff0c\u8bef\u62a5\u738713%\u3002\u76f8\u6bd4\u6b27\u6d32\u6d2a\u6c34\u9884\u8b66\u7cfb\u7edf\uff0c\u8be5\u6846\u67b6\u5cf0\u503c\u5e45\u5ea6\u8bef\u5dee\u66f4\u4f4e\u3001\u8bef\u62a5\u66f4\u5c11\u3001\u5f84\u6d41\u548c\u5cf0\u503c\u6d41\u91cf\u9884\u62a5\u7cbe\u5ea6\u66f4\u9ad8\uff0c\u5728\u6807\u51c6CPU\u4e0a\u4ec5\u9700\u6570\u79d2\u8bad\u7ec3\u65f6\u95f4\u3002", "conclusion": "\u8be5\u6df7\u5408\u6846\u67b6\u8ba1\u7b97\u8f7b\u91cf\u3001\u53ef\u6269\u5c55\u3001\u6613\u4e8e\u8de8\u6d41\u57df\u8f6c\u79fb\uff0c\u5c55\u793a\u4e86\u6c34\u6587\u7406\u89e3\u4e0e\u9ad8\u6548\u673a\u5668\u5b66\u4e60\u7ed3\u5408\u63d0\u5347\u6d2a\u6c34\u9884\u62a5\u51c6\u786e\u6027\u548c\u53ef\u9760\u6027\u7684\u6f5c\u529b\uff0c\u4e3a\u672a\u6765\u6df7\u5408\u6c34\u6587-\u673a\u5668\u5b66\u4e60\u6a21\u578b\u53d1\u5c55\u6307\u660e\u4e86\u65b9\u5411\u3002"}}
{"id": "2601.09603", "categories": ["cs.SD", "cs.AI", "cs.CL", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.09603", "abs": "https://arxiv.org/abs/2601.09603", "authors": ["Petros Vavaroutsos", "Theodoros Palamas", "Pantelis Vikatos"], "title": "Linear Complexity Self-Supervised Learning for Music Understanding with Random Quantizer", "comment": "accepted by ACM/SIGAPP Symposium on Applied Computing (SAC 2026)", "summary": "In recent years, foundation models have become very popular due to their exceptional performance, mainly in natural language (NLP) tasks where they were first introduced. These models usually consist of hundreds of millions, or even billions, of parameters, making them resource-intensive during training and in production systems, leading to increased costs. This paper focuses on the reduction of a foundation's model size when applied to music information retrieval (MIR) tasks. Our research combines the Branchformer architecture with SummaryMixing, which were first applied in speech recognition, along with a random quantization process. To facilitate reproducibility, we conduct pre-training on publicly available datasets, complemented by a proprietary dataset comparable in scale to other private datasets reported in the literature. We ensure robust evaluation by using a framework consisting of a variety of downstream MIR tasks. Our results show that our architecture achieves competitive performance when compared with other state-of-the-art models that use multi-head self-attention, while reducing the model size from 8.5% up to 12.3%.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7ed3\u5408Branchformer\u67b6\u6784\u3001SummaryMixing\u548c\u968f\u673a\u91cf\u5316\u7684\u65b9\u6cd5\uff0c\u7528\u4e8e\u51cf\u5c0f\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u57fa\u7840\u6a21\u578b\u7684\u89c4\u6a21\uff0c\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u540c\u65f6\u5c06\u6a21\u578b\u5927\u5c0f\u51cf\u5c118.5%\u81f312.3%\u3002", "motivation": "\u57fa\u7840\u6a21\u578b\u867d\u7136\u6027\u80fd\u4f18\u5f02\uff0c\u4f46\u53c2\u6570\u91cf\u5e9e\u5927\uff08\u6570\u4ebf\u81f3\u6570\u5341\u4ebf\uff09\uff0c\u5bfc\u81f4\u8bad\u7ec3\u548c\u90e8\u7f72\u6210\u672c\u9ad8\u6602\u3002\u5728\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u9886\u57df\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6a21\u578b\u6765\u964d\u4f4e\u8d44\u6e90\u6d88\u8017\u3002", "method": "\u7ed3\u5408\u4e86\u6700\u521d\u7528\u4e8e\u8bed\u97f3\u8bc6\u522b\u7684Branchformer\u67b6\u6784\u548cSummaryMixing\u6280\u672f\uff0c\u5e76\u91c7\u7528\u968f\u673a\u91cf\u5316\u8fc7\u7a0b\u3002\u5728\u516c\u5f00\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\uff0c\u8f85\u4ee5\u4e0e\u6587\u732e\u4e2d\u5176\u4ed6\u79c1\u6709\u6570\u636e\u96c6\u89c4\u6a21\u76f8\u5f53\u7684\u81ea\u6709\u6570\u636e\u96c6\u3002", "result": "\u63d0\u51fa\u7684\u67b6\u6784\u5728\u591a\u79cd\u4e0b\u6e38MIR\u4efb\u52a1\u8bc4\u4f30\u4e2d\uff0c\u4e0e\u4f7f\u7528\u591a\u5934\u81ea\u6ce8\u610f\u529b\u7684\u6700\u5148\u8fdb\u6a21\u578b\u76f8\u6bd4\uff0c\u53d6\u5f97\u4e86\u5177\u6709\u7ade\u4e89\u529b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u5c06\u6a21\u578b\u5927\u5c0f\u51cf\u5c11\u4e868.5%\u81f312.3%\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u6210\u529f\u5b9e\u73b0\u4e86\u5728\u97f3\u4e50\u4fe1\u606f\u68c0\u7d22\u4efb\u52a1\u4e2d\u51cf\u5c0f\u57fa\u7840\u6a21\u578b\u89c4\u6a21\u7684\u76ee\u6807\uff0c\u5728\u4fdd\u6301\u6027\u80fd\u7684\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u6a21\u578b\u590d\u6742\u5ea6\uff0c\u4e3a\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e0b\u7684MIR\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2601.09364", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09364", "abs": "https://arxiv.org/abs/2601.09364", "authors": ["Radim Zedka", "Roman Marsalek", "Marek Bobula", "Arman Farhang"], "title": "Unique Word Channel Estimation for Oversampled OTFS", "comment": "17 pages", "summary": "Practical aspects of orthogonal time frequency space (OTFS), such as channel estimation and its performance in fractional delay-Doppler (DD) channels, are a lively topic in the OTFS community. Oversampling and pulse shaping are also discussed in the existing literature, but not in the context of channel estimation. To the best of our knowledge, this paper is the first to address the problem of data-to-pilot and vice versa energy leakage caused by oversampling and pulse shaping in OTFS. Theoretical analysis is performed on an oversampled, pulse-shaped OTFS implementing the embedded pilot channel estimation technique, revealing a trade-off between the amount of energy leakage and excess bandwidth introduced by the pulse shape. Next, a novel variant of OTFS is introduced, called UW-OTFS, which is designed to overcome the leakage problem by placing the pilot in the oversampled time domain instead of the DD domain. The unique structure of UW-OTFS offers 36 percent higher spectral efficiency than the OTFS with embedded pilot. UW-OTFS also outperforms traditional OTFS in terms of bit error ratio and out-of-band emissions.", "AI": {"tldr": "\u672c\u6587\u9996\u6b21\u7814\u7a76OTFS\u4e2d\u8fc7\u91c7\u6837\u548c\u8109\u51b2\u6210\u5f62\u5bfc\u81f4\u7684\u6570\u636e-\u5bfc\u9891\u80fd\u91cf\u6cc4\u6f0f\u95ee\u9898\uff0c\u63d0\u51faUW-OTFS\u65b0\u65b9\u6848\uff0c\u5728\u9891\u8c31\u6548\u7387\u3001\u8bef\u7801\u7387\u548c\u5e26\u5916\u8f90\u5c04\u65b9\u9762\u4f18\u4e8e\u4f20\u7edfOTFS\u3002", "motivation": "OTFS\u4e2d\u8fc7\u91c7\u6837\u548c\u8109\u51b2\u6210\u5f62\u4f1a\u5bfc\u81f4\u6570\u636e\u4e0e\u5bfc\u9891\u4e4b\u95f4\u7684\u80fd\u91cf\u6cc4\u6f0f\uff0c\u5f71\u54cd\u4fe1\u9053\u4f30\u8ba1\u6027\u80fd\uff0c\u73b0\u6709\u6587\u732e\u5c1a\u672a\u5728\u4fe1\u9053\u4f30\u8ba1\u80cc\u666f\u4e0b\u7814\u7a76\u8fd9\u4e00\u95ee\u9898\u3002", "method": "1. \u5bf9\u91c7\u7528\u5d4c\u5165\u5f0f\u5bfc\u9891\u4fe1\u9053\u4f30\u8ba1\u6280\u672f\u7684\u8fc7\u91c7\u6837\u8109\u51b2\u6210\u5f62OTFS\u8fdb\u884c\u7406\u8bba\u5206\u6790\uff1b2. \u63d0\u51faUW-OTFS\u65b0\u65b9\u6848\uff0c\u5c06\u5bfc\u9891\u653e\u7f6e\u5728\u8fc7\u91c7\u6837\u65f6\u57df\u800c\u975eDD\u57df\uff1b3. \u5206\u6790\u80fd\u91cf\u6cc4\u6f0f\u4e0e\u8109\u51b2\u6210\u5f62\u5f15\u5165\u7684\u989d\u5916\u5e26\u5bbd\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002", "result": "1. \u63ed\u793a\u4e86\u80fd\u91cf\u6cc4\u6f0f\u4e0e\u989d\u5916\u5e26\u5bbd\u7684\u6743\u8861\u5173\u7cfb\uff1b2. UW-OTFS\u6bd4\u5d4c\u5165\u5f0f\u5bfc\u9891OTFS\u9891\u8c31\u6548\u7387\u63d0\u9ad836%\uff1b3. UW-OTFS\u5728\u8bef\u7801\u7387\u548c\u5e26\u5916\u8f90\u5c04\u65b9\u9762\u4f18\u4e8e\u4f20\u7edfOTFS\u3002", "conclusion": "UW-OTFS\u901a\u8fc7\u5c06\u5bfc\u9891\u653e\u7f6e\u5728\u8fc7\u91c7\u6837\u65f6\u57df\uff0c\u6709\u6548\u89e3\u51b3\u4e86OTFS\u4e2d\u7684\u80fd\u91cf\u6cc4\u6f0f\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u6027\u80fd\u6307\u6807\u4e0a\u4f18\u4e8e\u4f20\u7edfOTFS\u65b9\u6848\u3002"}}
{"id": "2601.09384", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09384", "abs": "https://arxiv.org/abs/2601.09384", "authors": ["Utku U\u00e7ak", "Fariba Armandoust", "Matthias Mehlhose", "Daniel Sch\u00e4ufele", "Jochen Fink", "Renato L. G. Cavalcante", "S\u0142awomir Sta\u0144czak"], "title": "Uplink Multi-User MIMO Implementation in OpenAirInterface for a Cell-Free O-RAN Testbed", "comment": "7 pages, 7 figures. Submitted to IEEE ICC 2026", "summary": "Cell-Free Multiple-Input Multiple-Output (MIMO) and Open Radio Access Network (O-RAN) have been active research topics in the wireless communication community in recent years. As an open-source software implementation of the 3rd Generation Partnership Project (3GPP) 5th Generation (5G) protocol stack, OpenAirInterface (OAI) has become a valuable tool for deploying and testing new ideas in wireless communication systems. In this paper, we present our OAI based real-time uplink Multi-User MIMO (MU-MIMO) testbed developed at Fraunhofer HHI. As a part of our Cell-Free MIMO testbed development, we built a 2x2 MU-MIMO system using general purpose computers and commercially available software defined radios (SDRs). Using a modified OAI next-Generation Node-B (gNB) and two unmodified OAI user equipment (UE), we show that it is feasible to use Sounding Reference Signal (SRS) channel estimates to compute uplink combiners. Our results verify that this method can be used to separate and decode signals from two users transmitting in nonorthogonal time-frequency resources. This work serves as an important verification step to build a complete Cell-Free MU-MIMO system that leverages time domain duplexing (TDD) reciprocity to do downlink beamforming over multiple cells.", "AI": {"tldr": "\u57fa\u4e8eOpenAirInterface\u7684\u5b9e\u65f6\u4e0a\u884c\u591a\u7528\u6237MIMO\u6d4b\u8bd5\u5e73\u53f0\uff0c\u4f7f\u7528SRS\u4fe1\u9053\u4f30\u8ba1\u5206\u79bb\u548c\u89e3\u7801\u4e24\u4e2a\u7528\u6237\u7684\u975e\u6b63\u4ea4\u4fe1\u53f7", "motivation": "Cell-Free MIMO\u548cO-RAN\u662f\u65e0\u7ebf\u901a\u4fe1\u9886\u57df\u7684\u7814\u7a76\u70ed\u70b9\uff0c\u9700\u8981\u5b9e\u9645\u6d4b\u8bd5\u5e73\u53f0\u6765\u9a8c\u8bc1\u65b0\u60f3\u6cd5\u3002OpenAirInterface\u4f5c\u4e3a\u5f00\u6e90\u76845G\u534f\u8bae\u6808\u5b9e\u73b0\uff0c\u4e3a\u90e8\u7f72\u548c\u6d4b\u8bd5\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u5de5\u5177\u3002", "method": "\u4f7f\u7528\u901a\u7528\u8ba1\u7b97\u673a\u548c\u5546\u7528\u8f6f\u4ef6\u5b9a\u4e49\u65e0\u7ebf\u7535\u6784\u5efa2x2 MU-MIMO\u7cfb\u7edf\uff0c\u901a\u8fc7\u4fee\u6539\u7684OAI gNB\u548c\u4e24\u4e2a\u672a\u4fee\u6539\u7684OAI UE\uff0c\u5229\u7528Sounding Reference Signal\u4fe1\u9053\u4f30\u8ba1\u8ba1\u7b97\u4e0a\u884c\u7ec4\u5408\u5668\u3002", "result": "\u9a8c\u8bc1\u4e86\u8be5\u65b9\u6cd5\u80fd\u591f\u5206\u79bb\u548c\u89e3\u7801\u4e24\u4e2a\u7528\u6237\u5728\u975e\u6b63\u4ea4\u65f6\u9891\u8d44\u6e90\u4e0a\u4f20\u8f93\u7684\u4fe1\u53f7\uff0c\u4e3a\u6784\u5efa\u5b8c\u6574\u7684Cell-Free MU-MIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u91cd\u8981\u9a8c\u8bc1\u3002", "conclusion": "\u8fd9\u9879\u5de5\u4f5c\u4e3a\u5229\u7528TDD\u4e92\u6613\u6027\u5728\u591a\u5c0f\u533a\u8fdb\u884c\u4e0b\u884c\u6ce2\u675f\u6210\u5f62\u7684\u5b8c\u6574Cell-Free MU-MIMO\u7cfb\u7edf\u5f00\u53d1\u5960\u5b9a\u4e86\u57fa\u7840\uff0c\u8bc1\u660e\u4e86\u57fa\u4e8eOAI\u7684\u5b9e\u65f6\u4e0a\u884cMU-MIMO\u6d4b\u8bd5\u5e73\u53f0\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2601.09426", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09426", "abs": "https://arxiv.org/abs/2601.09426", "authors": ["Heedong Do", "Angel Lozano"], "title": "Beamforming Gain with Nonideal Phase Shifters", "comment": null, "summary": "This research sets forth a universal framework to characterize the beamforming gain achievable with arbitrarily nonideal phase shifters. Precisely, the maximum possible shortfall relative to the gain attainable with ideal phase shifters is established. Such shortfall is shown to be fundamentally determined by the perimeter of the convex hull of the set of feasible beamforming coefficients on the complex plane. This result holds regardless of whether the beamforming is at the transmitter, at the receiver, or at a reconfigurable intelligent surface. In i.i.d. fading channels, the shortfall hardens to the maximum possible shortfall as the number of antennas grows.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u901a\u7528\u6846\u67b6\u6765\u91cf\u5316\u975e\u7406\u60f3\u79fb\u76f8\u5668\u4e0b\u7684\u6ce2\u675f\u6210\u5f62\u589e\u76ca\u635f\u5931\uff0c\u8be5\u635f\u5931\u7531\u53ef\u884c\u6ce2\u675f\u6210\u5f62\u7cfb\u6570\u96c6\u5728\u590d\u5e73\u9762\u4e0a\u51f8\u5305\u5468\u957f\u51b3\u5b9a\uff0c\u9002\u7528\u4e8e\u53d1\u5c04\u7aef\u3001\u63a5\u6536\u7aef\u548c\u667a\u80fd\u53cd\u5c04\u9762", "motivation": "\u5b9e\u9645\u7cfb\u7edf\u4e2d\u79fb\u76f8\u5668\u901a\u5e38\u975e\u7406\u60f3\uff0c\u9700\u8981\u91cf\u5316\u8fd9\u79cd\u975e\u7406\u60f3\u6027\u5bf9\u6ce2\u675f\u6210\u5f62\u589e\u76ca\u7684\u5f71\u54cd\uff0c\u4e3a\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u7406\u8bba\u6307\u5bfc", "method": "\u5efa\u7acb\u901a\u7528\u5206\u6790\u6846\u67b6\uff0c\u5c06\u6ce2\u675f\u6210\u5f62\u589e\u76ca\u635f\u5931\u4e0e\u53ef\u884c\u6ce2\u675f\u6210\u5f62\u7cfb\u6570\u96c6\u5728\u590d\u5e73\u9762\u4e0a\u7684\u51f8\u5305\u5468\u957f\u8054\u7cfb\u8d77\u6765\uff0c\u9002\u7528\u4e8e\u5404\u79cd\u6ce2\u675f\u6210\u5f62\u573a\u666f", "result": "\u6ce2\u675f\u6210\u5f62\u589e\u76ca\u635f\u5931\u7531\u51f8\u5305\u5468\u957f\u51b3\u5b9a\uff0c\u5728i.i.d.\u8870\u843d\u4fe1\u9053\u4e2d\uff0c\u5f53\u5929\u7ebf\u6570\u589e\u52a0\u65f6\uff0c\u635f\u5931\u4f1a\u786c\u5316\u5230\u6700\u5927\u53ef\u80fd\u635f\u5931\u503c", "conclusion": "\u975e\u7406\u60f3\u79fb\u76f8\u5668\u7684\u6ce2\u675f\u6210\u5f62\u589e\u76ca\u635f\u5931\u5177\u6709\u666e\u9002\u6027\u7279\u5f81\uff0c\u7531\u51f8\u5305\u5468\u957f\u51b3\u5b9a\uff0c\u8fd9\u4e00\u7ed3\u679c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u91cd\u8981\u7406\u8bba\u4f9d\u636e"}}
{"id": "2601.09463", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.09463", "abs": "https://arxiv.org/abs/2601.09463", "authors": ["Ying Gao", "Qingqing Wu", "Ziyuan Zheng", "Yanze Zhu", "Wen Chen", "Xin Lin", "Shanpu Shen"], "title": "Two-Scale Spatial Deployment for Cost-Effective Wireless Networks via Cooperative IRSs and Movable Antennas", "comment": "13 pages, 7 figures, submitted to an IEEE journal for possible publication", "summary": "This paper proposes a two-scale spatial deployment strategy to ensure reliable coverage for multiple target areas, integrating macroscopic intelligent reflecting surfaces (IRSs) and fine-grained movable antennas (MAs). Specifically, IRSs are selectively deployed from candidate sites to shape the propagation geometry, while MAs are locally repositioned among discretized locations to exploit small-scale channel variations. The objective is to minimize the total deployment cost of MAs and IRSs by jointly optimizing the IRS site selection, MA positions, transmit precoding, and IRS phase shifts, subject to the signal-to-noise ratio (SNR) requirements for all target areas. This leads to a challenging mixed-integer non-convex optimization problem that is intractable to solve directly. To address this, we first formulate an auxiliary problem to verify the feasibility. A penalty-based double-loop algorithm integrating alternating optimization and successive convex approximation (SCA) is developed to solve this feasibility issue, which is subsequently adapted to obtain a suboptimal solution for the original cost minimization problem. Finally, based on the obtained solution, we formulate an element refinement problem to further reduce the deployment cost, which is solved by a penalty-based SCA algorithm. Simulation results demonstrate that the proposed designs consistently outperform benchmarks relying on independent area planning or full IRS deployment in terms of cost-efficiency. Moreover, for cost minimization, MA architectures are preferable in large placement apertures, whereas fully populated FPA architectures excel in compact ones; for worst-case SNR maximization, MA architectures exhibit a lower cost threshold for feasibility, while FPA architectures can attain peak SNR at a lower total cost.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u5c3a\u5ea6\u7a7a\u95f4\u90e8\u7f72\u7b56\u7565\uff0c\u7ed3\u5408\u5b8f\u89c2\u667a\u80fd\u53cd\u5c04\u9762(IRS)\u548c\u7ec6\u7c92\u5ea6\u53ef\u79fb\u52a8\u5929\u7ebf(MA)\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316IRS\u9009\u5740\u3001MA\u4f4d\u7f6e\u3001\u53d1\u5c04\u9884\u7f16\u7801\u548cIRS\u76f8\u79fb\uff0c\u6700\u5c0f\u5316\u90e8\u7f72\u6210\u672c\u540c\u65f6\u6ee1\u8db3\u76ee\u6807\u533a\u57dfSNR\u8981\u6c42\u3002", "motivation": "\u73b0\u6709\u90e8\u7f72\u7b56\u7565\u901a\u5e38\u72ec\u7acb\u89c4\u5212\u5404\u533a\u57df\u6216\u5168\u9762\u90e8\u7f72IRS\uff0c\u7f3a\u4e4f\u6210\u672c\u6548\u76ca\u3002\u9700\u8981\u4e00\u79cd\u96c6\u6210\u5b8f\u89c2\u548c\u5fae\u89c2\u5c3a\u5ea6\u63a7\u5236\u7684\u534f\u540c\u90e8\u7f72\u65b9\u6848\uff0c\u5728\u4fdd\u8bc1\u53ef\u9760\u8986\u76d6\u7684\u540c\u65f6\u6700\u5c0f\u5316\u786c\u4ef6\u6210\u672c\u3002", "method": "1) \u63d0\u51fa\u4e24\u5c3a\u5ea6\u90e8\u7f72\u6846\u67b6\uff1aIRS\u4ece\u5019\u9009\u7ad9\u70b9\u9009\u62e9\u6027\u90e8\u7f72\u4ee5\u5851\u9020\u4f20\u64ad\u51e0\u4f55\uff0cMA\u5728\u79bb\u6563\u4f4d\u7f6e\u5c40\u90e8\u91cd\u5b9a\u4f4d\u4ee5\u5229\u7528\u5c0f\u5c3a\u5ea6\u4fe1\u9053\u53d8\u5316\uff1b2) \u5efa\u7acb\u6df7\u5408\u6574\u6570\u975e\u51f8\u4f18\u5316\u95ee\u9898\uff1b3) \u5f00\u53d1\u57fa\u4e8e\u60e9\u7f5a\u7684\u53cc\u73af\u7b97\u6cd5\uff0c\u7ed3\u5408\u4ea4\u66ff\u4f18\u5316\u548c\u9010\u6b21\u51f8\u903c\u8fd1\u89e3\u51b3\u53ef\u884c\u6027\u9a8c\u8bc1\uff1b4) \u63d0\u51fa\u5143\u7d20\u7ec6\u5316\u95ee\u9898\u8fdb\u4e00\u6b65\u964d\u4f4e\u6210\u672c\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff1a1) \u6240\u63d0\u8bbe\u8ba1\u5728\u6210\u672c\u6548\u76ca\u4e0a\u4f18\u4e8e\u72ec\u7acb\u533a\u57df\u89c4\u5212\u6216\u5168\u9762IRS\u90e8\u7f72\u57fa\u51c6\uff1b2) \u6210\u672c\u6700\u5c0f\u5316\u65f6\uff0c\u5927\u653e\u7f6e\u5b54\u5f84\u4e0bMA\u67b6\u6784\u66f4\u4f18\uff0c\u7d27\u51d1\u5b54\u5f84\u4e0b\u5168FPA\u67b6\u6784\u66f4\u4f18\uff1b3) \u6700\u574f\u60c5\u51b5SNR\u6700\u5927\u5316\u65f6\uff0cMA\u67b6\u6784\u53ef\u884c\u6027\u6210\u672c\u9608\u503c\u66f4\u4f4e\uff0cFPA\u67b6\u6784\u80fd\u4ee5\u66f4\u4f4e\u603b\u6210\u672c\u8fbe\u5230\u5cf0\u503cSNR\u3002", "conclusion": "\u4e24\u5c3a\u5ea6IRS-MA\u534f\u540c\u90e8\u7f72\u7b56\u7565\u80fd\u6709\u6548\u5e73\u8861\u8986\u76d6\u53ef\u9760\u6027\u548c\u6210\u672c\u6548\u76ca\uff0c\u4e3a\u591a\u76ee\u6807\u533a\u57df\u901a\u4fe1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u7075\u6d3b\u7684\u786c\u4ef6\u67b6\u6784\u9009\u62e9\u4f9d\u636e\uff0c\u53ef\u6839\u636e\u5177\u4f53\u90e8\u7f72\u573a\u666f\u5728MA\u548cFPA\u67b6\u6784\u95f4\u505a\u51fa\u6700\u4f18\u9009\u62e9\u3002"}}
{"id": "2601.09484", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.09484", "abs": "https://arxiv.org/abs/2601.09484", "authors": ["Marouan Mizmizi", "Stefano Tebaldini", "Umberto Spagnolini"], "title": "Echo-Side Integrated Sensing and Communication via Space-Time Reconfigurable Intelligent Surfaces", "comment": null, "summary": "This paper presents an echo-side modulation framework for integrated sensing and communication (ISAC) systems. A space-time reconfigurable intelligent surface (ST-RIS) impresses a continuous-phase modulation onto the radar echo, enabling uplink data transmission with a phase modulation of the transmitted radar-like waveform. The received signal is a multiplicative composition of the sensing waveform and the phase for communication. Both functionalities share the same physical signal and perceive each other as impairments.\n  The achievable communication rate is expressed as a function of a coupling parameter that links sensing accuracy to phase error accumulation. Under a fixed bandwidth constraint, the sensing and communication figures of merit define a convex Pareto frontier. The optimal bandwidth allocation satisfying a minimum sensing requirement is derived in closed form. The modified Cramer-Rao bound (MCRB) for range estimation is derived in closed form; this parameter must be estimated to compensate for the frequency offset before data demodulation. Frame synchronization is formulated as a generalized likelihood ratio test (GLRT), and the detection probability is obtained through characteristic function inversion, accounting for residual frequency errors from imperfect range estimation. Numerical results validate the theoretical bounds and characterize the trade-off across the operating range.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8e\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u7684\u56de\u6ce2\u4fa7\u8c03\u5236\u6846\u67b6\uff0c\u5229\u7528\u7a7a\u65f6\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u5728\u96f7\u8fbe\u56de\u6ce2\u4e0a\u65bd\u52a0\u8fde\u7eed\u76f8\u4f4d\u8c03\u5236\uff0c\u5b9e\u73b0\u4e0a\u884c\u6570\u636e\u4f20\u8f93\uff0c\u611f\u77e5\u548c\u901a\u4fe1\u529f\u80fd\u5171\u4eab\u540c\u4e00\u7269\u7406\u4fe1\u53f7\u4f46\u76f8\u4e92\u5e72\u6270\u3002", "motivation": "\u5728\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u4e2d\uff0c\u5982\u4f55\u6709\u6548\u534f\u8c03\u611f\u77e5\u548c\u901a\u4fe1\u529f\u80fd\uff0c\u4f7f\u5b83\u4eec\u5171\u4eab\u540c\u4e00\u7269\u7406\u4fe1\u53f7\u8d44\u6e90\uff0c\u540c\u65f6\u5904\u7406\u4e24\u8005\u4e4b\u95f4\u7684\u76f8\u4e92\u5e72\u6270\uff0c\u5b9e\u73b0\u9891\u8c31\u6548\u7387\u6700\u5927\u5316\u3002", "method": "\u4f7f\u7528\u7a7a\u65f6\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u5728\u96f7\u8fbe\u56de\u6ce2\u4e0a\u65bd\u52a0\u8fde\u7eed\u76f8\u4f4d\u8c03\u5236\uff0c\u5c06\u901a\u4fe1\u6570\u636e\u5d4c\u5165\u611f\u77e5\u4fe1\u53f7\u4e2d\u3002\u63a5\u6536\u4fe1\u53f7\u662f\u611f\u77e5\u6ce2\u5f62\u548c\u901a\u4fe1\u76f8\u4f4d\u7684\u4e58\u79ef\u7ec4\u5408\u3002\u901a\u8fc7\u8026\u5408\u53c2\u6570\u5206\u6790\u611f\u77e5\u7cbe\u5ea6\u4e0e\u76f8\u4f4d\u8bef\u5dee\u79ef\u7d2f\u7684\u5173\u7cfb\uff0c\u5728\u56fa\u5b9a\u5e26\u5bbd\u7ea6\u675f\u4e0b\u4f18\u5316\u8d44\u6e90\u5206\u914d\u3002", "result": "\u5efa\u7acb\u4e86\u611f\u77e5\u4e0e\u901a\u4fe1\u6027\u80fd\u4e4b\u95f4\u7684\u51f8\u5e15\u7d2f\u6258\u524d\u6cbf\uff0c\u63a8\u5bfc\u4e86\u6ee1\u8db3\u6700\u5c0f\u611f\u77e5\u8981\u6c42\u7684\u6700\u4f18\u5e26\u5bbd\u5206\u914d\u95ed\u5f0f\u89e3\u3002\u63a8\u5bfc\u4e86\u8ddd\u79bb\u4f30\u8ba1\u7684\u4fee\u6b63\u514b\u62c9\u7f8e\u7f57\u754c\u95ed\u5f0f\u89e3\uff0c\u5e76\u57fa\u4e8e\u5e7f\u4e49\u4f3c\u7136\u6bd4\u68c0\u9a8c\u6784\u5efa\u4e86\u5e27\u540c\u6b65\u65b9\u6848\u3002", "conclusion": "\u8be5\u56de\u6ce2\u4fa7\u8c03\u5236\u6846\u67b6\u80fd\u591f\u6709\u6548\u5b9e\u73b0\u611f\u77e5\u4e0e\u901a\u4fe1\u7684\u96c6\u6210\uff0c\u7406\u8bba\u5206\u6790\u548c\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u6027\u80fd\u754c\u9650\uff0c\u5e76\u63ed\u793a\u4e86\u611f\u77e5\u7cbe\u5ea6\u4e0e\u901a\u4fe1\u901f\u7387\u4e4b\u95f4\u7684\u6743\u8861\u5173\u7cfb\u3002"}}
{"id": "2601.09701", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09701", "abs": "https://arxiv.org/abs/2601.09701", "authors": ["Fahimeh Orvati Nia", "Shima Salehi", "Joshua Peeples"], "title": "Evaluating GAN-LSTM for Smart Meter Anomaly Detection in Power Systems", "comment": "Accepted to IEEE Texas Power and Energy Conference (TPEC) 2026. 6 pages, 5 figures. Code available at https://github.com/fahimehorvatinia/GAN-LSTM-Smart-Meter-Anomaly-Detection", "summary": "Advanced metering infrastructure (AMI) provides high-resolution electricity consumption data that can enhance monitoring, diagnosis, and decision making in modern power distribution systems. Detecting anomalies in these time-series measurements is challenging due to nonlinear, nonstationary, and multi-scale temporal behavior across diverse building types and operating conditions. This work presents a systematic, power-system-oriented evaluation of a GAN-LSTM framework for smart meter anomaly detection using the Large-scale Energy Anomaly Detection (LEAD) dataset, which contains one year of hourly measurements from 406 buildings. The proposed pipeline applies consistent preprocessing, temporal windowing, and threshold selection across all methods, and compares the GAN-LSTM approach against six widely used baselines, including statistical, kernel-based, reconstruction-based, and GAN-based models. Experimental results demonstrate that the GAN-LSTM significantly improves detection performance, achieving an F1-score of 0.89. These findings highlight the potential of adversarial temporal modeling as a practical tool for supporting asset monitoring, non-technical loss detection, and situational awareness in real-world power distribution networks. The code for this work is publicly available", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eGAN-LSTM\u7684\u667a\u80fd\u7535\u8868\u5f02\u5e38\u68c0\u6d4b\u6846\u67b6\uff0c\u5728LEAD\u6570\u636e\u96c6\u4e0a\u663e\u8457\u4f18\u4e8e\u516d\u79cd\u57fa\u7ebf\u65b9\u6cd5\uff0cF1\u5206\u6570\u8fbe\u52300.89\uff0c\u5c55\u793a\u4e86\u5bf9\u6297\u65f6\u5e8f\u5efa\u6a21\u5728\u7535\u529b\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u4e2d\u7684\u5b9e\u7528\u4ef7\u503c\u3002", "motivation": "\u9ad8\u7ea7\u8ba1\u91cf\u57fa\u7840\u8bbe\u65bd\uff08AMI\uff09\u63d0\u4f9b\u7684\u9ad8\u5206\u8fa8\u7387\u7535\u529b\u6d88\u8d39\u6570\u636e\u53ef\u4ee5\u589e\u5f3a\u73b0\u4ee3\u914d\u7535\u7cfb\u7edf\u7684\u76d1\u63a7\u3001\u8bca\u65ad\u548c\u51b3\u7b56\u80fd\u529b\u3002\u7136\u800c\uff0c\u7531\u4e8e\u4e0d\u540c\u5efa\u7b51\u7c7b\u578b\u548c\u8fd0\u884c\u6761\u4ef6\u4e0b\u5b58\u5728\u975e\u7ebf\u6027\u3001\u975e\u5e73\u7a33\u548c\u591a\u5c3a\u5ea6\u7684\u65f6\u95f4\u884c\u4e3a\uff0c\u5728\u8fd9\u4e9b\u65f6\u95f4\u5e8f\u5217\u6d4b\u91cf\u4e2d\u68c0\u6d4b\u5f02\u5e38\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u7cfb\u7edf\u5316\u7684\u3001\u9762\u5411\u7535\u529b\u7cfb\u7edf\u7684GAN-LSTM\u6846\u67b6\u8bc4\u4f30\u65b9\u6cd5\u3002\u4f7f\u7528\u5305\u542b406\u680b\u5efa\u7b51\u4e00\u5e74\u5c0f\u65f6\u6d4b\u91cf\u6570\u636e\u7684LEAD\u6570\u636e\u96c6\u3002\u91c7\u7528\u4e00\u81f4\u7684\u9884\u5904\u7406\u3001\u65f6\u95f4\u7a97\u53e3\u5316\u548c\u9608\u503c\u9009\u62e9\u6d41\u7a0b\uff0c\u5c06GAN-LSTM\u65b9\u6cd5\u4e0e\u516d\u79cd\u5e7f\u6cdb\u4f7f\u7528\u7684\u57fa\u7ebf\u65b9\u6cd5\u8fdb\u884c\u6bd4\u8f83\uff0c\u5305\u62ec\u7edf\u8ba1\u65b9\u6cd5\u3001\u57fa\u4e8e\u6838\u7684\u65b9\u6cd5\u3001\u57fa\u4e8e\u91cd\u6784\u7684\u65b9\u6cd5\u548c\u57fa\u4e8eGAN\u7684\u6a21\u578b\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0cGAN-LSTM\u663e\u8457\u63d0\u9ad8\u4e86\u68c0\u6d4b\u6027\u80fd\uff0cF1\u5206\u6570\u8fbe\u52300.89\u3002\u8fd9\u7a81\u663e\u4e86\u5bf9\u6297\u65f6\u5e8f\u5efa\u6a21\u4f5c\u4e3a\u652f\u6301\u5b9e\u9645\u914d\u7535\u7f51\u7edc\u4e2d\u8d44\u4ea7\u76d1\u63a7\u3001\u975e\u6280\u672f\u635f\u5931\u68c0\u6d4b\u548c\u6001\u52bf\u611f\u77e5\u7684\u5b9e\u7528\u5de5\u5177\u7684\u6f5c\u529b\u3002", "conclusion": "GAN-LSTM\u6846\u67b6\u5728\u667a\u80fd\u7535\u8868\u5f02\u5e38\u68c0\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u7535\u529b\u7cfb\u7edf\u5f02\u5e38\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8be5\u5de5\u4f5c\u7684\u4ee3\u7801\u5df2\u516c\u5f00\u53ef\u7528\u3002"}}

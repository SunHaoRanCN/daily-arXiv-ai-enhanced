{"id": "2601.09710", "categories": ["eess.AS", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.09710", "abs": "https://arxiv.org/abs/2601.09710", "authors": ["Md. Nazmus Sakib", "Golam Mahmud", "Md. Maruf Bangabashi", "Umme Ara Mahinur Istia", "Md. Jahidul Islam", "Partha Sarker", "Afra Yeamini Prity"], "title": "Multi-Level Embedding Conformer Framework for Bengali Automatic Speech Recognition", "comment": null, "summary": "Bengali, spoken by over 300 million people, is a morphologically rich and lowresource language, posing challenges for automatic speech recognition (ASR). This research presents an end-to-end framework for Bengali ASR, building on a Conformer-CTC backbone with a multi-level embedding fusion mechanism that incorporates phoneme, syllable, and wordpiece representations. By enriching acoustic features with these linguistic embeddings, the model captures fine-grained phonetic cues and higher-level contextual patterns. The architecture employs early and late Conformer stages, with preprocessing steps including silence trimming, resampling, Log-Mel spectrogram extraction, and SpecAugment augmentation. The experimental results demonstrate the strong potential of the model, achieving a word error rate (WER) of 10.01% and a character error rate (CER) of 5.03%. These results demonstrate the effectiveness of combining multi-granular linguistic information with acoustic modeling, providing a scalable approach for low-resource ASR development."}
{"id": "2601.10078", "categories": ["eess.AS", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10078", "abs": "https://arxiv.org/abs/2601.10078", "authors": ["Jianhong Ye", "Haiquan Zhao"], "title": "Nearest Kronecker Product Decomposition Based Subband Adaptive Filter: Algorithms and Applications", "comment": "16 Pages, 19 figures,published to IEEE TASLP", "summary": "Recently, the nearest Kronecker product (NKP) decomposition-based normalized least mean square (NLMS-NKP) algorithm has demonstrated superior convergence performance compared to the conventional NLMS algorithm. However, its convergence rate exhibits significant degradation when processing highly correlated input signals. To address this problem, we propose a type-I NKP-based normalized subband adaptive filter (NSAF) algorithm, namely NSAF-NKP-I. Nevertheless, this algorithm incurs substantially higher computational overhead than the NLMS-NKP algorithm. Remarkably, our enhanced type-II NKP-based NSAF (NSAF-NKP-II) algorithm achieves equivalent convergence performance while substantially reducing computational complexity. Furthermore, to enhance robustness against impulsive noise interference, we develop two robust variants: the maximum correntropy criterion-based robust NSAF-NKP (RNSAF-NKP-MCC) and logarithmic criterion-based robust NSAF-NKP (RNSAF-NKP-LC) algorithms. Additionally, detailed analyses of computational complexity, step-size range, and theoretical steady-state performance are provided for theproposed algorithms. To enhance the practicability of the NSAF-NKP-II algorithm in complex nonlinear environments, we further devise two nonlinear implementations: the trigonometric functional link network-based NKP-NSAF (TFLN-NSAF-NKP) and Volterra series expansion-based NKP-NSAF (Volterra-NKP-NSAF) algorithms. In active noise control (ANC) systems, we further propose the filtered-x NSAF-NKP-II (NKP-FxNSAF) algorithm. Simulation experiments in echo cancellation, sparse system identification, nonlinear processing, and ANC scenarios are conducted to validate the superiority of the proposed algorithms over existing state-of-the-art counterparts."}
{"id": "2601.10629", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2601.10629", "abs": "https://arxiv.org/abs/2601.10629", "authors": ["Jingbin Hu", "Huakang Chen", "Linhan Ma", "Dake Guo", "Qirui Zhan", "Wenhao Li", "Haoyu Zhang", "Kangxiang Xia", "Ziyu Zhang", "Wenjie Tian", "Chengyou Wang", "Jinrui Liang", "Shuhan Guo", "Zihang Yang", "Bengu Wu", "Binbin Zhang", "Pengcheng Zhu", "Pengyuan Xie", "Chuan Xie", "Qiang Zhang", "Jie Liu", "Lei Xie"], "title": "VoiceSculptor: Your Voice, Designed By You", "comment": "13 pages, 4 figures", "summary": "Despite rapid progress in text-to-speech (TTS), open-source systems still lack truly instruction-following, fine-grained control over core speech attributes (e.g., pitch, speaking rate, age, emotion, and style). We present VoiceSculptor, an open-source unified system that bridges this gap by integrating instruction-based voice design and high-fidelity voice cloning in a single framework. It generates controllable speaker timbre directly from natural-language descriptions, supports iterative refinement via Retrieval-Augmented Generation (RAG), and provides attribute-level edits across multiple dimensions. The designed voice is then rendered into a prompt waveform and fed into a cloning model to enable high-fidelity timbre transfer for downstream speech synthesis. VoiceSculptor achieves open-source state-of-the-art (SOTA) on InstructTTSEval-Zh, and is fully open-sourced, including code and pretrained models, to advance reproducible instruction-controlled TTS research."}
{"id": "2601.10453", "categories": ["cs.SD", "cs.LG", "eess.AS", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.10453", "abs": "https://arxiv.org/abs/2601.10453", "authors": ["Victor Zheleznov", "Stefan Bilbao", "Alec Wright", "Simon King"], "title": "Stable Differentiable Modal Synthesis for Learning Nonlinear Dynamics", "comment": "Submitted to the Journal of Audio Engineering Society (December 2025)", "summary": "Modal methods are a long-standing approach to physical modelling synthesis. Extensions to nonlinear problems are possible, including the case of a high-amplitude vibration of a string. A modal decomposition leads to a densely coupled nonlinear system of ordinary differential equations. Recent work in scalar auxiliary variable techniques has enabled construction of explicit and stable numerical solvers for such classes of nonlinear systems. On the other hand, machine learning approaches (in particular neural ordinary differential equations) have been successful in modelling nonlinear systems automatically from data. In this work, we examine how scalar auxiliary variable techniques can be combined with neural ordinary differential equations to yield a stable differentiable model capable of learning nonlinear dynamics. The proposed approach leverages the analytical solution for linear vibration of system's modes so that physical parameters of a system remain easily accessible after the training without the need for a parameter encoder in the model architecture. As a proof of concept, we generate synthetic data for the nonlinear transverse vibration of a string and show that the model can be trained to reproduce the nonlinear dynamics of the system. Sound examples are presented."}
{"id": "2601.09837", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09837", "abs": "https://arxiv.org/abs/2601.09837", "authors": ["Ismaila Salihou Adamou", "Michèle Wigger"], "title": "Distributed Hypothesis Testing Under A Covertness Constraint", "comment": null, "summary": "We study distributed hypothesis testing under a covertness constraint in the non-alert situation, which requires that under the null-hypothesis an external warden be unable to detect whether communication between the sensor and the decision center is taking place. We characterize the achievable Stein exponent of this setup when the channel from the sensor to the decision center is a partially-connected discrete memoryless channel (DMC), i.e., when certain output symbols can only be induced by some of the inputs. The Stein-exponent in this case, does not depend on the specific transition law of the DMC and equals Shalaby and Papamarcou's exponent without a warden but where the sensor can send $k$ noise-free bits to the decision center, for $k$ a function that is sublinear in the observation length $n$. For fully-connected DMCs, we propose an achievable Stein-exponent and show that it can improve over the local exponent at the decision center. All our coding schemes do not require that the sensor and decision center share a common secret key, as commonly assumed in covert communication. Moreover, in our schemes the divergence covertness constraint vanishes (almost) exponentially fast in the obervation length $n$, again, an atypical behaviour for covert communication."}
{"id": "2601.09931", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2601.09931", "abs": "https://arxiv.org/abs/2601.09931", "authors": ["Jean-Eudes Ayilo", "Mostafa Sadeghi", "Romain Serizel", "Xavier Alameda-Pineda"], "title": "Diffusion-based Frameworks for Unsupervised Speech Enhancement", "comment": null, "summary": "This paper addresses $\\textit{unsupervised}$ diffusion-based single-channel speech enhancement (SE). Prior work in this direction combines a score-based diffusion model trained on clean speech with a Gaussian noise model whose covariance is structured by non-negative matrix factorization (NMF). This combination is used within an iterative expectation-maximization (EM) scheme, in which a diffusion-based posterior-sampling E-step estimates the clean speech. We first revisit this framework and propose to explicitly model both speech and acoustic noise as latent variables, jointly sampling them in the E-step instead of sampling speech alone as in previous approaches. We then introduce a new unsupervised SE framework that replaces the NMF noise prior with a diffusion-based noise model, learned jointly with the speech prior in a single conditional score model. Within this framework, we derive two variants: one that implicitly accounts for noise and one that explicitly treats noise as a latent variable. Experiments on WSJ0-QUT and VoiceBank-DEMAND show that explicit noise modeling systematically improves SE performance for both NMF-based and diffusion-based noise priors. Under matched conditions, the diffusion-based noise model attains the best overall quality and intelligibility among unsupervised methods, while under mismatched conditions the proposed NMF-based explicit-noise framework is more robust and suffers less degradation than several supervised baselines. Our code will be publicly available on this $\\href{https://github.com/jeaneudesAyilo/enudiffuse}{URL}$."}
{"id": "2601.09992", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.09992", "abs": "https://arxiv.org/abs/2601.09992", "authors": ["Zhuoran Xiao", "Tao Tao", "Chenhui Ye", "Yunbo Hu", "Yijia Feng", "Tianyu Jiao", "Liyu Cai"], "title": "Towards Native Intelligence: 6G-LLM Trained with Reinforcement Learning from NDT Feedback", "comment": "The paper has been accepted IEEE WCNC 2026", "summary": "Owing to its comprehensive understanding of upper-layer application requirements and the capabilities of practical communication systems, the 6G-LLM (6G domain large language model) offers a promising pathway toward realizing network native intelligence. Serving as the system orchestrator, the 6G-LLM drives a paradigm shift that fundamentally departs from existing rule-based approaches, which primarily rely on modular, experience-driven optimization. By contrast, the 6G-LLM substantially enhances network flexibility and adaptability. Nevertheless, current efforts to construct 6G-LLMs are constrained by their reliance on large-scale, meticulously curated, human-authored corpora, which are impractical to obtain in real-world scenarios. Moreover, purely offline-trained models lack the capacity for continual self-improvement, limiting their ability to adapt to the highly dynamic requirements of wireless communication environments. To overcome these limitations, we propose a novel training paradigm termed RLDTF (Reinforcement Learning from Digital Twin Feedback) for 6G-LLMs. This framework leverages network digital twins to generate reward signals based on orchestration outcomes, while employing reinforcement learning to guide the model toward optimal decision-making dynamically. Furthermore, we introduce a weighted token mechanism to improve output accuracy. Comprehensive experimental results demonstrate that our proposed framework significantly outperforms state-of-the-art baselines in orchestration accuracy and solution optimality."}
{"id": "2601.10345", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2601.10345", "abs": "https://arxiv.org/abs/2601.10345", "authors": ["Yunyi Liu", "Taketo Akama"], "title": "Self-supervised restoration of singing voice degraded by pitch shifting using shallow diffusion", "comment": null, "summary": "Pitch shifting has been an essential feature in singing voice production. However, conventional signal processing approaches exhibit well known trade offs such as formant shifts and robotic coloration that becomes more severe at larger transposition jumps. This paper targets high quality pitch shifting for singing by reframing it as a restoration problem: given an audio track that has been pitch shifted (and thus contaminated by artifacts), we recover a natural sounding performance while preserving its melody and timing. Specifically, we use a lightweight, mel space diffusion model driven by frame level acoustic features such as f0, volume, and content features. We construct training pairs in a self supervised manner by applying pitch shifts and reversing them to simulate realistic artifacts while retaining ground truth. On a curated singing set, the proposed approach substantially reduces pitch shift artifacts compared to representative classical baselines, as measured by both statistical metrics and pairwise acoustic measures. The results suggest that restoration based pitch shifting could be a viable approach towards artifact resistant transposition in vocal production workflows."}
{"id": "2601.10013", "categories": ["eess.SP", "cs.DC"], "pdf": "https://arxiv.org/pdf/2601.10013", "abs": "https://arxiv.org/abs/2601.10013", "authors": ["Ce Zheng", "Shiyao Ma", "Ke Zhang", "Chen Sun", "Wenqi Zhang"], "title": "Clustering-Based User Selection in Federated Learning: Metadata Exploitation for 3GPP Networks", "comment": "accepted in 2026 IEEE Wireless Communications and Networking Conference (WCNC)", "summary": "Federated learning (FL) enables collaborative model training without sharing raw user data, but conventional simulations often rely on unrealistic data partitioning and current user selection methods ignore data correlation among users. To address these challenges, this paper proposes a metadatadriven FL framework. We first introduce a novel data partition model based on a homogeneous Poisson point process (HPPP), capturing both heterogeneity in data quantity and natural overlap among user datasets. Building on this model, we develop a clustering-based user selection strategy that leverages metadata, such as user location, to reduce data correlation and enhance label diversity across training rounds. Extensive experiments on FMNIST and CIFAR-10 demonstrate that the proposed framework improves model performance, stability, and convergence in non-IID scenarios, while maintaining comparable performance under IID settings. Furthermore, the method shows pronounced advantages when the number of selected users per round is small. These findings highlight the framework's potential for enhancing FL performance in realistic deployments and guiding future standardization."}
{"id": "2601.10384", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2601.10384", "abs": "https://arxiv.org/abs/2601.10384", "authors": ["Yibo Zhang", "Liang Lin", "Kaiwen Luo", "Shilinlu Yan", "Jin Wang", "Yaoqi Guo", "Yitian Chen", "Yalan Qin", "Zhenhong Zhou", "Kun Wang", "Li Sun"], "title": "RSA-Bench: Benchmarking Audio Large Models in Real-World Acoustic Scenarios", "comment": null, "summary": "While Audio Large Models (ALMs) have achieved remarkable proficiency, their robustness remains brittle in real-world deployment. Existing evaluations largely rely on synthetic Gaussian noise or simplistic single-source interference, failing to capture the intricate, multi-layered acoustic dynamics -- or ``Acoustic Ecology'' -- that characterize authentic physical environments. To bridge this ecological gap, we introduce \\textbf{RSA-Bench}, a comprehensive robustness benchmark designed to stress-test ALLMs through high-fidelity auditory scene simulations. Unlike traditional methods, we construct evaluation samples by naturally superimposing diverse environmental soundscapes -- spanning \\textit{Pasture}, \\textit{Extreme Weather}, \\textit{Classroom}, and \\textit{Outdoors} -- onto clean speech signals across a spectrum of interference intensities. By evaluating models on six core tasks ranging from fundamental perception to complex reasoning, our study unveils three macro-level insights: \\textbf{(I) The Perception-Cognition Gap:} Models maintain relative resilience in low-level recognition but suffer a \\textbf{functional collapse} in high-order reasoning tasks under stress; \\textbf{(II) Scenario Sensitivity:} ``Vocal-like'' interference (e.g., background laughter) proves significantly more destructive than mechanical noise, challenging the model's auditory attention mechanisms; and \\textbf{(III) The Denoising Paradox:} Standard speech enhancement often exacerbates performance degradation, as ALLMs prove highly sensitive to the semantic distortions introduced by denoising artifacts."}
{"id": "2601.10060", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10060", "abs": "https://arxiv.org/abs/2601.10060", "authors": ["Zheyu Wu", "Matteo Nerini", "Bruno Clerckx"], "title": "Microwave Linear Analog Computer (MiLAC)-aided Multiuser MISO: Fundamental Limits and Beamforming Design", "comment": "13 pages, 7 figures, 1 table. Submitted to IEEE for possible publication", "summary": "As wireless communication systems evolve toward the 6G era, ultra-massive/gigantic MIMO is envisioned as a key enabling technology. Recently, microwave linear analog computer (MiLAC) has emerged as a promising approach to realize beamforming entirely in the analog domain, thereby alleviating the scalability challenges associated with gigantic MIMO. In this paper, we investigate the fundamental beamforming flexibility and design of lossless and reciprocal MiLAC-aided beamforming for MU-MISO systems. We first provide a rigorous characterization of the set of beamforming matrices achievable by MiLAC. Based on this characterization, we prove that MiLAC-aided beamforming does not generally achieve the full flexibility of digital beamforming, while offering greater flexibility than conventional phase-shifter-based analog beamforming. Furthermore, we propose a hybrid digital-MiLAC architecture and show that it achieves digital beamforming flexibility when the number of radio frequency (RF) chains equals the number of data streams, halving that required by conventional hybrid beamforming. We then formulate the MiLAC-aided sum-rate maximization problem for MU-MISO systems. To solve the problem efficiently, we reformulate the MiLAC-related constraints as a convex linear matrix inequality and establish a low-dimensional subspace property that significantly reduces the problem dimension. Leveraging these results, we propose WMMSE-based algorithms for solving the resulting problem. Simulation results demonstrate that MiLAC-aided beamforming achieves performance close to that of digital beamforming in gigantic MIMO systems. Compared with hybrid beamforming, it achieves comparable or superior performance with lower hardware and computational complexity by avoiding symbol-level digital processing and enabling low-resolution digital-to-analog converters (DACs)."}
{"id": "2601.10453", "categories": ["cs.SD", "cs.LG", "eess.AS", "physics.comp-ph"], "pdf": "https://arxiv.org/pdf/2601.10453", "abs": "https://arxiv.org/abs/2601.10453", "authors": ["Victor Zheleznov", "Stefan Bilbao", "Alec Wright", "Simon King"], "title": "Stable Differentiable Modal Synthesis for Learning Nonlinear Dynamics", "comment": "Submitted to the Journal of Audio Engineering Society (December 2025)", "summary": "Modal methods are a long-standing approach to physical modelling synthesis. Extensions to nonlinear problems are possible, including the case of a high-amplitude vibration of a string. A modal decomposition leads to a densely coupled nonlinear system of ordinary differential equations. Recent work in scalar auxiliary variable techniques has enabled construction of explicit and stable numerical solvers for such classes of nonlinear systems. On the other hand, machine learning approaches (in particular neural ordinary differential equations) have been successful in modelling nonlinear systems automatically from data. In this work, we examine how scalar auxiliary variable techniques can be combined with neural ordinary differential equations to yield a stable differentiable model capable of learning nonlinear dynamics. The proposed approach leverages the analytical solution for linear vibration of system's modes so that physical parameters of a system remain easily accessible after the training without the need for a parameter encoder in the model architecture. As a proof of concept, we generate synthetic data for the nonlinear transverse vibration of a string and show that the model can be trained to reproduce the nonlinear dynamics of the system. Sound examples are presented."}
{"id": "2601.10074", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10074", "abs": "https://arxiv.org/abs/2601.10074", "authors": ["Jianhong Ye", "Haiquan Zhao", "Yi Peng"], "title": "P-norm based Fractional-Order Robust Subband Adaptive Filtering Algorithm for Impulsive Noise and Noisy Input", "comment": "5 pages, 4 figures, published to IEEE SPL", "summary": "Building upon the mean p-power error (MPE) criterion, the normalized subband p-norm (NSPN) algorithm demonstrates superior robustness in $α$-stable noise environments ($1 < α\\leq 2$) through effective utilization of low-order moment hidden in robust loss functions. Nevertheless, its performance degrades significantly when processing noise input or additive noise characterized by $α$-stable processes ($0 < α\\leq 1$). To overcome these limitations, we propose a novel fractional-order NSPN (FoNSPN) algorithm that incorporates the fractional-order stochastic gradient descent (FoSGD) method into the MPE framework. Additionally, this paper also analyzes the convergence range of its step-size, the theoretical domain of values for the fractional-order $β$, and establishes the theoretical steady-state mean square deviation (MSD) model. Simulations conducted in diverse impulsive noise environments confirm the superiority of the proposed FoNSPN algorithm against existing state-of-the-art algorithms."}
{"id": "2601.10547", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2601.10547", "abs": "https://arxiv.org/abs/2601.10547", "authors": ["Dongchao Yang", "Yuxin Xie", "Yuguo Yin", "Zheyu Wang", "Xiaoyu Yi", "Gongxi Zhu", "Xiaolong Weng", "Zihan Xiong", "Yingzhe Ma", "Dading Cong", "Jingliang Liu", "Zihang Huang", "Jinghan Ru", "Rongjie Huang", "Haoran Wan", "Peixu Wang", "Kuoxi Yu", "Helin Wang", "Liming Liang", "Xianwei Zhuang", "Yuanyuan Wang", "Haohan Guo", "Junjie Cao", "Zeqian Ju", "Songxiang Liu", "Yuewen Cao", "Heming Weng", "Yuexian Zou"], "title": "HeartMuLa: A Family of Open Sourced Music Foundation Models", "comment": null, "summary": "We present a family of open-source Music Foundation Models designed to advance large-scale music understanding and generation across diverse tasks and modalities. Our framework consists of four major components: (1) HeartCLAP, an audio-text alignment model; (2) HeartTranscriptor, a robust lyric recognition model optimized for real-world music scenarios; and (3) HeartCodec, a low-frame-rate (12.5 Hz) yet high-fidelity music codec tokenizer that captures long-range musical structure while preserving fine-grained acoustic details and enabling efficient autoregressive modeling; (4) HeartMuLa, an LLM-based song generation model capable of synthesizing high-fidelity music under rich, user-controllable conditions (e.g., textual style descriptions, lyrics, and reference audio). In addition, it provides two specialized modes: (i) fine-grained musical attribute control, which allows users to specify the style of different song sections (e.g., intro, verse, chorus) using natural language prompts; and (ii) short, engaging music generation, which is suitable as background music for short videos. Lastly, HeartMuLa improves significantly when scaled to 7B parameters. For the first time, we show that a Suno-level, commercial-grade system can be reproduced using academic-scale data and GPU resources. We expect these foundation models to serve as strong baselines for future research and to facilitate practical applications in multimodal content production."}
{"id": "2601.10179", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10179", "abs": "https://arxiv.org/abs/2601.10179", "authors": ["Senning Wan", "Bin Li", "Hongbin Chen", "Lei Liu"], "title": "Service Provisioning and Path Planning with Obstacle Avoidance for Low-Altitude Wireless Networks", "comment": "12 pages, 11 figures", "summary": "This paper investigates the three-dimensional (3D) deployment of uncrewed aerial vehicles (UAVs) as aerial base stations in heterogeneous communication networks under constraints imposed by diverse ground obstacles. Given the diverse data demands of user equipments (UEs), a user satisfaction model is developed to provide personalized services. In particular, when a UE is located within a ground obstacle, the UAV must approach the obstacle boundary to ensure reliable service quality. Considering constraints such as UAV failures due to battery depletion, heterogeneous UEs, and obstacles, we aim to maximize overall user satisfaction by jointly optimizing the 3D trajectories of UAVs, transmit beamforming vectors, and binary association indicators between UAVs and UEs. To address the complexity and dynamics of the problem, a block coordinate descent method is adopted to decompose it into two subproblems. The beamforming subproblem is efficiently addressed via a bisection-based water-filling algorithm. For the trajectory and association subproblem, we design a deep reinforcement learning algorithm based on proximal policy optimization to learn an adaptive control policy. Simulation results demonstrate that the proposed scheme outperforms baseline schemes in terms of convergence speed and overall system performance. Moreover, it achieves efficient association and accurate obstacle avoidance."}
{"id": "2601.10207", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10207", "abs": "https://arxiv.org/abs/2601.10207", "authors": ["Le Zhao", "Yining Wang", "Xinyi Wang", "Zesong Fei", "Yong Zeng"], "title": "BeamCKMDiff: Beam-Aware Channel Knowledge Map Construction via Diffusion Transformer", "comment": "6 pages, 3 figures", "summary": "Channel knowledge map (CKM) is emerging as a critical enabler for environment-aware 6G networks, offering a site-specific database to significantly reduce pilot overhead. However, existing CKM construction methods typically rely on sparse sampling measurements and are restricted to either omnidirectional maps or discrete codebooks, hindering the exploitation of beamforming gain. To address these limitations, we propose BeamCKMDiff, a generative framework for constructing high-fidelity CKMs conditioned on arbitrary continuous beamforming vectors without site-specific sampling. Specifically, we incorporate a novel adaptive layer normalization (adaLN) mechanism into the noise prediction network of the Diffusion Transformer (DiT). This mechanism injects continuous beam embeddings as {global control parameters}, effectively steering the generative process to capture the complex coupling between beam patterns and environmental geometries. Simulation results demonstrate that BeamCKMDiff significantly outperforms state-of-the-art baselines, achieving superior reconstruction accuracy in capturing main lobes and side lobes."}
{"id": "2601.10264", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10264", "abs": "https://arxiv.org/abs/2601.10264", "authors": ["Jingze Zheng", "Zhiguo Shi", "Shibo He", "Chaojie Gu"], "title": "Sim2Real Deep Transfer for Per-Device CFO Calibration", "comment": "Accepted by Globecom 2025", "summary": "Carrier Frequency Offset (CFO) estimation in Orthogonal Frequency Division Multiplexing (OFDM) systems faces significant performance degradation across heterogeneous software-defined radio (SDR) platforms due to uncalibrated hardware impairments. Existing deep neural network (DNN)-based approaches lack device-level adaptation, limiting their practical deployment. This paper proposes a Sim2Real transfer learning framework for per-device CFO calibration, combining simulation-driven pretraining with lightweight receiver adaptation. A backbone DNN is pre-trained on synthetic OFDM signals incorporating parametric hardware distortions (e.g., phase noise, IQ imbalance), enabling generalized feature learning without costly cross-device data collection. Subsequently, only the regression layers are fine-tuned using $1,000$ real frames per target device, preserving hardware-agnostic knowledge while adapting to device-specific impairments. Experiments across three SDR families (USRP B210, USRP N210, HackRF One) achieve $30\\times$ BER reduction compared to conventional CP-based methods under indoor multipath conditions. The framework bridges the simulation-to-reality gap for robust CFO estimation, enabling cost-effective deployment in heterogeneous wireless systems."}
{"id": "2601.10331", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10331", "abs": "https://arxiv.org/abs/2601.10331", "authors": ["Hanyoung Park", "Ji-Woong Choi"], "title": "Low-Complexity Blind Estimator of SNR and MSE for mmWave Multi-Antenna Communications", "comment": "Presented at 2025 IEEE Globecom Workshops (GC Wkshps)", "summary": "To enhance the robustness and resilience of wireless communication and meet performance requirements, various environment-reflecting metrics, such as the signal-to-noise ratio (SNR), are utilized as the system parameter. To obtain these metrics, training signals such as pilot sequences are generally employed. However, the rapid fluctuations of the millimeter-wave (mmWave) propagation channel often degrade the accuracy of such estimations. To address this challenge, various blind estimators that operate without pilot have been considered as potential solutions. However, these algorithms often involve a training phase for machine learning or a large number of iterations, which implies prohibitive computational complexity, making them difficult to employ for real-time services and the system less resilient to dynamic environment variation. In this paper, we propose blind estimators for average noise power, signal power, SNR, and mean-square error (MSE) that do not require knowledge of the ground-truth signal or involve high computational complexity. The proposed algorithm leverages the inherent sparsity of mmWave channel in beamspace domain, which makes the signal and noise power components more distinguishable."}
{"id": "2601.10576", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10576", "abs": "https://arxiv.org/abs/2601.10576", "authors": ["Shaohua Yue", "Siyu Miao", "Shuhao Zeng", "Fenghan Lin", "Boya Di"], "title": "Achievable Degrees of Freedom Analysis and Optimization in Massive MIMO via Characteristic Mode Analysis", "comment": "12 pages 12 figures", "summary": "Massive multiple-input multiple-output (MIMO) is esteemed as a critical technology in 6G communications, providing large degrees of freedom (DoF) to improve multiplexing gain. This paper introduces characteristic mode analysis (CMA) to derive the achievable DoF. Unlike existing works primarily focusing on the DoF of the wireless channel,the excitation and radiation properties of antennas are also involved in our DoF analysis, which influences the number of independent data streams for communication of a MIMO system. Specifically, we model the excitation and radiation properties of transceiver antennas using CMA to analyze the excitation and radiation properties of antennas. The CMA-based DoF analysis framework is established and the achievable DoF is derived. A characteristic mode optimization problem of antennas is then formulated to maximize the achievable DoF. A case study where the reconfigurable holographic surface (RHS) antennas are deployed at the transceiver is investigated, and a CMA-based genetic algorithm is later proposed to solve the above problem. By changing the characteristic modes electric field and surface current distribution of RHS, the achievable DoF is enhanced. Full-wave simulation verifies the theoretical analysis on the the achievable DoF and shows that, via the reconfiguration of RHS based on the proposed algorithm, the achievable DoF is improved."}

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 22]
- [cs.SD](#cs.SD) [Total: 6]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Zonotope Shadow and Reflection Matching: A Novel GNSS Reflection-Based Framework for Enhanced Positioning Accuracy in Urban Areas](https://arxiv.org/abs/2601.10727)
*Sanghyun Kim,Jiwon Seo*

Main category: eess.SP

TL;DR: 提出ZSRM方法，结合阴影和反射匹配，提升城市GNSS定位精度，相比ZSM方法RMS水平位置误差改善10.0%-53.6%


<details>
  <summary>Details</summary>
Motivation: 城市环境中GNSS信号受建筑物反射影响，传统阴影匹配采用离散网格估计，精度受网格分辨率限制，难以满足保护等级要求。ZSM方法使用集合估计但仍受限于仅依赖GNSS阴影信息

Method: 提出ZSRM方法，结合阴影和反射匹配。通过区分LOS和NLOS卫星，利用GNSS阴影区域（LOS被遮挡区域）和反射信号信息，使用集合论方法估计接收机位置集合

Result: 在城市环境实地测试中，ZSRM相比ZSM：RMS水平位置误差改善10.0%-53.6%，RMS横街位置边界改善18.0%-50.1%，RMS沿街位置边界改善30.7%-59.3%

Conclusion: ZSRM通过结合阴影和反射匹配，显著提升城市GNSS定位精度和边界估计性能，为城市环境提供更可靠的定位解决方案

Abstract: In urban areas, signal reception conditions are often poor due to reflections from buildings, resulting in inaccurate global navigation satellite system (GNSS)-based positioning. Various 3D-mapping-aided (3DMA) GNSS techniques, including shadow matching, have been proposed to address this issue. However, conventional shadow matching estimates positions in a discretized manner. The accuracy of this approach is limited by the resolution of the grid points representing the candidate receiver positions, making it difficult to achieve robust urban positioning and to ensure that the position estimate satisfies user-specified protection levels or safety bounds. To overcome these limitations, zonotope shadow matching (ZSM) has been proposed, which utilizes a set-based position estimate rather than grid-based estimates. ZSM calculates the GNSS shadow--an area on the ground where the line-of-sight (LOS) is blocked and only non-line-of-sight (NLOS) signals can be received--to estimate the receiver's position set. ZSM distinguishes between LOS and NLOS satellites, determining that the receiver is inside the GNSS shadow if the satellite is NLOS and outside if the satellite is LOS. However, relying solely on GNSS shadows limits the ability to sufficiently reduce the size of the receiver position set and to precisely estimate the receiver's location. To address this, we propose zonotope shadow and reflection matching (ZSRM) to enhance positioning accuracy in urban areas. The proposed ZSRM technique is validated through field tests using GNSS signals collected in an urban environment. Consequently, the RMS horizontal position error of ZSRM improved by 10.0% to 53.6% compared with ZSM, while the RMS cross-street and along-street position bounds improved by 18.0% to 50.1% and 30.7% to 59.3%, respectively.

</details>


### [2] [Millimeter-Wave Gesture Recognition in ISAC: Does Reducing Sensing Airtime Hamper Accuracy?](https://arxiv.org/abs/2601.10733)
*Jakob Struye,Nabeel Nisar Bhat,Siddhartha Kumar,Mohammad Hossein Moghaddam,Jeroen Famaey*

Main category: eess.SP

TL;DR: 毫米波ISAC系统中，仅需25%的感知时间即可实现接近全时感知的手势识别精度（仅下降0.15个百分点），同时保持高速通信能力


<details>
  <summary>Details</summary>
Motivation: 现有ISAC系统需要在感知和通信模式间分配时隙，但这种分配决策对感知性能的具体影响尚不明确且研究不足

Method: 使用两个毫米波设备进行连续波束扫描，收集测试对象执行不同手势时的波束对功率数据集，然后训练卷积神经网络手势分类器，并通过子采样模拟减少感知时间

Result: 仅使用25%的感知时间，手势分类准确率仅比全时感知下降0.15个百分点，证明毫米波ISAC能在低感知时间下保持高质量感知性能

Conclusion: 毫米波ISAC系统在低感知时间下仍能提供高质量感知，同时保持极高的数据传输速率，是真正无线扩展现实等应用的关键使能技术

Abstract: Most Integrated Sensing and Communications (ISAC) systems require dividing airtime across their two modes. However, the specific impact of this decision on sensing performance remains unclear and underexplored. In this paper, we therefore investigate the impact on a gesture recognition system using a Millimeter-Wave (mmWave) ISAC system. With our dataset of power per beam pair gathered with two mmWave devices performing constant beam sweeps while test subjects performed distinct gestures, we train a gesture classifier using Convolutional Neural Networks. We then subsample these measurements, emulating reduced sensing airtime, showing that a sensing airtime of 25 % only reduces classification accuracy by 0.15 percentage points from full-time sensing. Alongside this high-quality sensing at low airtime, mmWave systems are known to provide extremely high data throughputs, making mmWave ISAC a prime enabler for applications such as truly wireless Extended Reality.

</details>


### [3] [SSC-UNet: UNet with Self-Supervised Contrastive Learning for Phonocardiography Noise Reduction](https://arxiv.org/abs/2601.10735)
*Lizy Abraham,Siobhan Coughlan,Kritika Rajain,Changhong Li,Saji Philip,Adam James*

Main category: eess.SP

TL;DR: 提出基于Noise2Noise的自监督心音图降噪模型，无需干净数据训练，在10dB医院噪声下达到12.98dB平均信噪比，分类敏感度从27%提升至88%


<details>
  <summary>Details</summary>
Motivation: 先天性心脏病(CHD)影响全球约1%的新生儿，心音图作为经济有效的辅助诊断工具，但其诊断模型性能高度依赖心音图质量。现有监督UNet模型需要干净数据训练，而干净数据获取困难，且心音图复杂的时频特性使得在去除噪声和保留病理特征之间难以平衡

Method: 基于Noise2Noise的自监督心音图降噪模型，无需干净数据训练。采用数据增强和对比学习提升性能，能够在有噪声的环境中有效去除噪声同时保留病理特征

Result: 在10dB医院噪声环境下，滤波后获得平均12.98dB的信噪比。分类敏感度从27%显著提升至88%，表明模型在实际噪声环境中具有良好的病理特征保留能力

Conclusion: 提出的自监督降噪模型有效解决了心音图降噪中干净数据不足的问题，在保持病理特征的同时显著提升了噪声抑制效果，为先天性心脏病的低成本诊断提供了实用工具

Abstract: Congenital Heart Disease (CHD) remains a significant global health concern affecting approximately 1\% of births worldwide. Phonocardiography has emerged as a supplementary tool to diagnose CHD cost-effectively. However, the performance of these diagnostic models highly depends on the quality of the phonocardiography, thus, noise reduction is particularly critical. Supervised UNet effectively improves noise reduction capabilities, but limited clean data hinders its application. The complex time-frequency characteristics of phonocardiography further complicate finding the balance between effectively removing noise and preserving pathological features. In this study, we proposed a self-supervised phonocardiography noise reduction model based on Noise2Noise to enable training without clean data. Augmentation and contrastive learning are applied to enhance its performance. We obtained an average SNR of 12.98 dB after filtering under 10~dB of hospital noise. Classification sensitivity after filtering was improved from 27\% to 88\%, indicating its promising pathological feature retention capabilities in practical noisy environments.

</details>


### [4] [Differentiating through binarized topology changes: Second-order subpixel-smoothed projection](https://arxiv.org/abs/2601.10737)
*Giuseppe Romano,Rodrigo Arrieta,Steven G. Johnson*

Main category: eess.SP

TL;DR: 提出SSP2方法，通过正则化SSP投影的Hessian矩阵，解决拓扑优化中拓扑变化时的不可微问题，保证二阶可微性同时维持二值结构。


<details>
  <summary>Details</summary>
Motivation: 拓扑优化中可制造的二值结构与基于梯度的优化方法存在根本矛盾。现有SSP方法在子像素级别平滑界面，但在拓扑变化（如界面合并）时无法保证可微性，违反了许多梯度优化算法的收敛保证。

Method: 通过正则化SSP投影的Hessian矩阵，提出二阶SSP（SSP2）方法。该方法在拓扑变化时保证投影密度的二阶可微性，同时仍能保证几乎处处二值结构。

Result: 在热学和光子学问题上验证了SSP2的有效性。对于连接性主导（频繁拓扑变化）的情况，SSP2比SSP收敛更快；在其他情况下性能相当。SSP2还能支持更广泛的优化算法（如内点法）。

Conclusion: SSP2解决了拓扑优化中拓扑变化时的可微性问题，改进了收敛保证，支持更广泛的优化算法，且相对于SSP或传统投影方案增加的计算复杂度很小，可作为现有拓扑优化代码的直接替代方案。

Abstract: A key challenge in topology optimization (TopOpt) is that manufacturable structures, being inherently binary, are non-differentiable, creating a fundamental tension with gradient-based optimization. The subpixel-smoothed projection (SSP) method addresses this issue by smoothing sharp interfaces at the subpixel level through a first-order expansion of the filtered field. However, SSP does not guarantee differentiability under topology changes, such as the merging of two interfaces, and therefore violates the convergence guarantees of many popular gradient-based optimization algorithms. We overcome this limitation by regularizing SSP with the Hessian of the filtered field, resulting in a twice-differentiable projected density during such transitions, while still guaranteeing an almost-everywhere binary structure. We demonstrate the effectiveness of our second-order SSP (SSP2) methodology on both thermal and photonic problems, showing that SSP2 has faster convergence than SSP for connectivity-dominant cases -- where frequent topology changes occur -- while exhibiting comparable performance otherwise. Beyond improving convergence guarantees for CCSA optimizers, SSP2 enables the use of a broader class of optimization algorithms with stronger theoretical guarantees, such as interior-point methods. Since SSP2 adds minimal complexity relative to SSP or traditional projection schemes, it can be used as a drop-in replacement in existing TopOpt codes.

</details>


### [5] [UBiGTLoc: A Unified BiLSTM-Graph Transformer Localization Framework for IoT Sensor Networks](https://arxiv.org/abs/2601.10743)
*Ayesh Abu Lehyeh,Anastassia Gharib,Tian Xia,Dryver Huston,Safwan Wshah*

Main category: eess.SP

TL;DR: 提出UBiGTLoc框架，结合双向LSTM和Graph Transformer，用于无线物联网传感器网络中的节点定位，支持有锚点和无锚点场景，仅使用低成本RSSI数据。


<details>
  <summary>Details</summary>
Motivation: 现有传感器节点定位方法严重依赖锚节点，但在实际物联网场景中锚节点可能不可行；同时RSSI波动（特别是在非视距条件下）会损害定位精度。

Method: 提出统一的双向LSTM-Graph Transformer定位框架（UBiGTLoc），利用BiLSTM捕获RSSI数据的时间变化，使用Graph Transformer层建模传感器节点间的空间关系。

Result: 广泛仿真表明，UBiGTLoc在密集和稀疏无线传感器网络中均优于现有方法，提供鲁棒的定位性能，且仅依赖成本效益高的RSSI数据。

Conclusion: UBiGTLoc框架有效解决了锚节点依赖问题和RSSI波动挑战，为物联网传感器网络提供了一种统一、鲁棒的定位解决方案。

Abstract: Sensor nodes localization in wireless Internet of Things (IoT) sensor networks is crucial for the effective operation of diverse applications, such as smart cities and smart agriculture. Existing sensor nodes localization approaches heavily rely on anchor nodes within wireless sensor networks (WSNs). Anchor nodes are sensor nodes equipped with global positioning system (GPS) receivers and thus, have known locations. These anchor nodes operate as references to localize other sensor nodes. However, the presence of anchor nodes may not always be feasible in real-world IoT scenarios. Additionally, localization accuracy can be compromised by fluctuations in Received Signal Strength Indicator (RSSI), particularly under non-line-of-sight (NLOS) conditions. To address these challenges, we propose UBiGTLoc, a Unified Bidirectional Long Short-Term Memory (BiLSTM)-Graph Transformer Localization framework. The proposed UBiGTLoc framework effectively localizes sensor nodes in both anchor-free and anchor-presence WSNs. The framework leverages BiLSTM networks to capture temporal variations in RSSI data and employs Graph Transformer layers to model spatial relationships between sensor nodes. Extensive simulations demonstrate that UBiGTLoc consistently outperforms existing methods and provides robust localization across both dense and sparse WSNs while relying solely on cost-effective RSSI data.

</details>


### [6] [An IoT-Based Controlled Environment Storage for Prevention of Spoilage of Onion (Allium Cepa) During Post-Harvest with UV-C Disinfection](https://arxiv.org/abs/2601.10745)
*Shivam Kumar,Himanshu Singh*

Main category: eess.SP

TL;DR: 本文提出了一种基于物联网的低成本智能洋葱存储系统，旨在将洋葱损耗率从40-45%降低到15-20%，同时保持对小农户的可负担性。


<details>
  <summary>Details</summary>
Motivation: 印度作为世界第二大洋葱生产国，每年产量超过2600万吨，但在储存过程中约有30-40%的洋葱因腐烂、发芽和失重而损失。传统存储方法要么低成本但效果差（传统储存40%损耗），要么高效但价格昂贵（冷库），不适合占印度多数的中小农户。

Method: 开发基于ESP32微控制器的物联网智能洋葱存储系统，使用DHT22传感器监测温湿度，MQ-135气体传感器检测腐败气体，并集成UV-C消毒技术。系统自动调节环境参数，设计为太阳能供电、节能且农民友好。

Result: 系统预计成本为6-7万印度卢比，相比传统存储方法更加经济实惠。目标是将洋葱损耗率从当前的40-45%降低到15-20%，同时保持对小农户的可负担性。

Conclusion: 该物联网智能存储系统为印度中小农户提供了一种经济有效的解决方案，能够显著减少洋葱储存损失，提高农民收入，同时具有成本效益、节能环保的特点。

Abstract: India is the second largest producer of onions in the world, contributing over 26 million tonnes annually. However, during storage, approximately 30-40% of onions are lost due to rotting, sprouting, and weight loss. Despite being a major producer, conventional storage methods are either low-cost but ineffective (traditional storage with 40% spoilage) or highly effective but prohibitively expensive for small farmers (cold storage). This paper presents a low-cost IoT-based smart onion storage system that monitors and automatically regulates environmental parameters including temperature, humidity, and spoilage gases using ESP32 microcontroller, DHT22 sensor, MQ-135 gas sensor, and UV-C disinfection technology. The proposed system aims to reduce onion spoilage to 15-20% from the current 40-45% wastage rate while remaining affordable for small and marginal farmers who constitute the majority in India. The system is designed to be cost-effective (estimated 60k-70k INR), energy-efficient, farmer-friendly, and solar-powered.

</details>


### [7] [On the static and small signal analysis of DAB converter](https://arxiv.org/abs/2601.10746)
*Yuxin Yang,Hang Zhou,Hourong Song,Branislav Hredzak*

Main category: eess.SP

TL;DR: 提出了一种求解双有源桥(DAB)周期性工作点的方法


<details>
  <summary>Details</summary>
Motivation: 双有源桥(DAB)在电力电子转换器中广泛应用，但准确求解其周期性工作点对于系统设计和控制至关重要。现有方法可能计算复杂或不够精确，需要更有效的方法来确定DAB的稳态工作点。

Method: 开发了一种系统性的数学方法来求解DAB的周期性工作点。该方法可能涉及建立DAB的数学模型，考虑开关状态、变压器特性、功率传输等因素，然后通过数值或解析方法求解周期性稳态解。

Result: 该方法能够准确计算DAB在不同工作条件下的周期性工作点，为系统设计和控制提供可靠依据。可能验证了方法的有效性和计算效率。

Conclusion: 提出的方法为DAB周期性工作点的求解提供了有效的工具，有助于改善DAB转换器的设计和控制性能，在电力电子应用中具有实用价值。

Abstract: This document develops a method to solve the periodic operating point of Dual-Active-Bridge (DAB).

</details>


### [8] [Sensor Placement for Urban Traffic Interpolation: A Data-Driven Evaluation to Inform Policy](https://arxiv.org/abs/2601.10747)
*Silke K. Kaiser*

Main category: eess.SP

TL;DR: 本研究通过柏林和曼哈顿的实证数据，比较了多种数据驱动的交通传感器布设策略，发现强调空间均匀覆盖和主动学习的空间布设策略能显著降低预测误差，而时间部署方案可进一步提升性能。


<details>
  <summary>Details</summary>
Motivation: 城市街道交通流量数据对城市规划至关重要，但现有传感器布设通常基于行政优先级而非数据驱动优化，导致覆盖偏差和估计性能下降。本研究旨在通过大规模实证基准测试，评估数据驱动的传感器布设策略效果。

Method: 使用柏林（Strava自行车计数）和曼哈顿（出租车计数）的街道段级数据，比较基于网络中心性、空间覆盖、特征覆盖和主动学习的空间布设策略，并研究临时传感器的时间部署方案。

Result: 强调空间均匀覆盖和采用主动学习的策略表现最佳：仅用10个传感器，在柏林和曼哈顿分别将平均绝对误差降低60%和70%以上。时间部署方案（均匀分布工作日测量）可进一步降低误差7%（柏林）和21%（曼哈顿）。

Conclusion: 城市可通过采用数据驱动的传感器布设策略显著提高数据实用性，同时在临时和永久部署之间保持灵活性。临时部署结合优化的时空策略可接近最优永久部署的性能。

Abstract: Data on citywide street-segment traffic volumes are essential for urban planning and sustainable mobility management. Yet such data are available only for a limited subset of streets due to the high costs of sensor deployment and maintenance. Traffic volumes on the remaining network are therefore interpolated based on existing sensor measurements. However, current sensor locations are often determined by administrative priorities rather than by data-driven optimization, leading to biased coverage and reduced estimation performance. This study provides a large-scale, real-world benchmarking of easily implementable, data-driven strategies for optimizing the placement of permanent and temporary traffic sensors, using segment-level data from Berlin (Strava bicycle counts) and Manhattan (taxi counts). It compares spatial placement strategies based on network centrality, spatial coverage, feature coverage, and active learning. In addition, the study examines temporal deployment schemes for temporary sensors. The findings highlight that spatial placement strategies that emphasize even spatial coverage and employ active learning achieve the lowest prediction errors. With only 10 sensors, they reduce the mean absolute error by over 60% in Berlin and 70% in Manhattan compared to alternatives. Temporal deployment choices further improve performance: distributing measurements evenly across weekdays reduces error by an additional 7% in Berlin and 21% in Manhattan. Together, these spatial and temporal principles allow temporary deployments to closely approximate the performance of optimally placed permanent deployments. From a policy perspective, the results indicate that cities can substantially improve data usefulness by adopting data-driven sensor placement strategies, while retaining flexibility in choosing between temporary and permanent deployments.

</details>


### [9] [AnyECG: Evolved ECG Foundation Model for Holistic Health Profiling](https://arxiv.org/abs/2601.10748)
*Jun Li,Hongling Zhu,Yujie Xiao,Qinghao Zhao,Yalei Ke,Gongzheng Tang,Guangkun Nie,Deyun Zhang,Jin Li,Canqing Yu,Shenda Hong*

Main category: eess.SP

TL;DR: AnyECG是一个基于大规模心电图数据的AI基础模型，能够同时检测1172种疾病，预测未来风险，并识别共病模式，展示了心电图作为系统性健康评估工具的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有AI-ECG模型大多专注于单一疾病识别，忽视了共病和未来风险预测。尽管ECGFounder扩展了心脏疾病覆盖范围，但仍需要一个全面的健康分析模型。

Method: 使用包含1330万份心电图、来自298万患者的多中心大型数据集，通过迁移学习对ECGFounder进行微调，开发出AnyECG基础模型。在外部验证队列和10年纵向队列中评估当前诊断、未来风险预测和共病识别性能。

Result: AnyECG在1172种疾病中展示了系统性预测能力，其中306种疾病的AUROC超过0.7。模型揭示了新的疾病关联、稳健的共病模式和未来疾病风险。代表性示例包括：甲状旁腺功能亢进症(AUROC 0.941)、2型糖尿病(0.803)、克罗恩病(0.817)、淋巴细胞白血病(0.856)和慢性阻塞性肺疾病(0.773)。

Conclusion: AnyECG基础模型提供了重要证据，表明AI-ECG可以作为同时进行疾病检测和长期风险预测的系统性工具。

Abstract: Background: Artificial intelligence enabled electrocardiography (AI-ECG) has demonstrated the ability to detect diverse pathologies, but most existing models focus on single disease identification, neglecting comorbidities and future risk prediction. Although ECGFounder expanded cardiac disease coverage, a holistic health profiling model remains needed.
  Methods: We constructed a large multicenter dataset comprising 13.3 million ECGs from 2.98 million patients. Using transfer learning, ECGFounder was fine-tuned to develop AnyECG, a foundation model for holistic health profiling. Performance was evaluated using external validation cohorts and a 10-year longitudinal cohort for current diagnosis, future risk prediction, and comorbidity identification.
  Results: AnyECG demonstrated systemic predictive capability across 1172 conditions, achieving an AUROC greater than 0.7 for 306 diseases. The model revealed novel disease associations, robust comorbidity patterns, and future disease risks. Representative examples included high diagnostic performance for hyperparathyroidism (AUROC 0.941), type 2 diabetes (0.803), Crohn disease (0.817), lymphoid leukemia (0.856), and chronic obstructive pulmonary disease (0.773).
  Conclusion: The AnyECG foundation model provides substantial evidence that AI-ECG can serve as a systemic tool for concurrent disease detection and long-term risk prediction.

</details>


### [10] [LSR-Net: A Lightweight and Strong Robustness Network for Bearing Fault Diagnosis in Noise Environment](https://arxiv.org/abs/2601.10761)
*Junseok Lee,Jihye Shin,Sangyong Lee,Chang-Jae Chun*

Main category: eess.SP

TL;DR: 提出LSR-Net轻量级强鲁棒网络，用于旋转轴承在噪声环境下的实时故障诊断，具有最佳抗噪能力和最低计算复杂度


<details>
  <summary>Details</summary>
Motivation: 旋转轴承在现代工业中至关重要，但因其高速、高负荷和恶劣运行环境而故障率高。故障诊断延迟可能导致经济损失和生命损失，且振动信号易受环境噪声影响，因此在噪声环境下进行准确诊断非常重要

Method: 1) 设计去噪和特征增强模块(DFEM)，通过基于卷积的去噪(CD)块对特征图施加非线性，生成3通道2D矩阵；2) 采用自适应剪枝增强强噪声下的去噪能力；3) 设计基于卷积的效率混洗(CES)块，使用组卷积、组点卷积和通道分割保持低参数量；4) 使用注意力机制和通道混洗平衡精度与计算复杂度

Result: 在噪声环境下使用振动信号验证，所提模型相比基准模型具有最佳抗噪能力，同时模型计算复杂度最低

Conclusion: LSR-Net能够在噪声环境下实现准确且实时的轴承故障诊断，平衡了诊断精度和计算效率，适用于工业实际应用

Abstract: Rotating bearings play an important role in modern industries, but have a high probability of occurrence of defects because they operate at high speed, high load, and poor operating environments. Therefore, if a delay time occurs when a bearing is diagnosed with a defect, this may cause economic loss and loss of life. Moreover, since the vibration sensor from which the signal is collected is highly affected by the operating environment and surrounding noise, accurate defect diagnosis in a noisy environment is also important. In this paper, we propose a lightweight and strong robustness network (LSR-Net) that is accurate in a noisy environment and enables real-time fault diagnosis. To this end, first, a denoising and feature enhancement module (DFEM) was designed to create a 3-channel 2D matrix by giving several nonlinearity to the feature-map that passed through the denoising module (DM) block composed of convolution-based denoising (CD) blocks. Moreover, adaptive pruning was applied to DM to improve denoising ability when the power of noise is strong. Second, for lightweight model design, a convolution-based efficiency shuffle (CES) block was designed using group convolution (GConv), group pointwise convolution (GPConv) and channel split that can design the model while maintaining low parameters. In addition, the trade-off between the accuracy and model computational complexity that can occur due to the lightweight design of the model was supplemented using attention mechanisms and channel shuffle. In order to verify the defect diagnosis performance of the proposed model, performance verification was conducted in a noisy environment using a vibration signal. As a result, it was confirmed that the proposed model had the best anti-noise ability compared to the benchmark models, and the computational complexity of the model was also the lowest.

</details>


### [11] [Physically constrained unfolded multi-dimensional OMP for large MIMO systems](https://arxiv.org/abs/2601.10771)
*Nay Klaimi,Clément Elvira,Philippe Mary,Luc Le Magoarou*

Main category: eess.SP

TL;DR: MOMPnet：一种基于深度展开的稀疏恢复框架，通过多字典学习和低复杂度算法解决传统方法在信道估计中的模型依赖性和计算复杂度问题


<details>
  <summary>Details</summary>
Motivation: 传统稀疏恢复方法在信道估计和定位中依赖精确的物理模型，但实际中模型往往不完美；同时在大规模MIMO系统中，字典维度的增加导致计算复杂度急剧上升

Method: 提出MOMPnet框架，结合深度展开与数据驱动的字典学习，使用多个独立的小字典替代单个大字典，实现低复杂度的多维正交匹配追踪算法

Result: 在真实信道数据上评估，相比多个基线方法，MOMPnet展现出强大的性能和潜力

Conclusion: MOMPnet通过深度展开和数据驱动字典学习，有效解决了传统稀疏恢复方法的可靠性和复杂度问题，同时保持了可解释性

Abstract: Sparse recovery methods are essential for channel estimation and localization in modern communication systems, but their reliability relies on accurate physical models, which are rarely perfectly known. Their computational complexity also grows rapidly with the dictionary dimensions in large MIMO systems. In this paper, we propose MOMPnet, a novel unfolded sparse recovery framework that addresses both the reliability and complexity challenges of traditional methods. By integrating deep unfolding with data-driven dictionary learning, MOMPnet mitigates hardware impairments while preserving interpretability. Instead of a single large dictionary, multiple smaller, independent dictionaries are employed, enabling a low-complexity multidimensional Orthogonal Matching Pursuit algorithm. The proposed unfolded network is evaluated on realistic channel data against multiple baselines, demonstrating its strong performance and potential.

</details>


### [12] [Adaptive algorithm for microsensor in sustainable environmental monitoring](https://arxiv.org/abs/2601.10780)
*Nursultan Daupayev,Christian Engel,Ricky Bendyk,Soeren Hirsch*

Main category: eess.SP

TL;DR: 基于傅里叶变换的数据采集算法，通过谐波分析提取主频成分，实现事件触发式传感器激活，减少能耗和存储需求


<details>
  <summary>Details</summary>
Motivation: 传统传感器数据采集产生大量数据，导致持续功耗和存储空间需求增加，需要更高效的数据采集方法

Method: 提出基于离散傅里叶变换(DFT)的数据采集与处理方法，利用谐波分析提取主频成分，识别频率峰值，实现事件触发式传感器激活

Result: 算法使传感器仅在事件发生时激活，同时保留检测缺陷所需的关键信息，如建筑表面结构缺陷，确保后续预测的准确性

Conclusion: 该算法能有效减少传感器功耗和存储需求，同时保持对建筑缺陷等关键事件的检测能力，为智能监测系统提供高效解决方案

Abstract: Traditional data collection from sensors produce a lot of data, which lead to constant power consumption and require more storage space. This study proposes an algorithm for a data acquisition and processing method based on Fourier transform (DFT), which extracts dominant frequency components using harmonic analysis (HA) to identify frequency peaks. This algorithm allows sensors to activate only when an event occurs, while preserving critical information for detecting defects, such as those in the surface structures of buildings and ensuring accuracy for further predictions.

</details>


### [13] [RIS-aided Radar Detection Architectures with Application to Low-RCS Targets](https://arxiv.org/abs/2601.10846)
*Fabiola Colone,Filippo Costa,Yiding Gao,Chengpeng Hao,Linjie Yan,Giuliano Manara,Danilo Orlando*

Main category: eess.SP

TL;DR: 提出利用可重构智能表面辅助雷达检测低可观测目标，通过形成联合单/双基地配置来收集目标散射能量，设计五种具有恒虚警特性的检测架构，相比传统方法能有效提升低可观测目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 传统多基地雷达网络用于反隐身目标检测存在同步、成本、相位相干和能耗等问题，需要更有效的低可观测目标检测方案。

Method: 利用可重构智能表面形成联合单/双基地配置，收集目标在不同方向的散射能量并重定向回雷达，设计五种联合处理单/双基地回波的检测架构，并提供RIS设计指南。

Result: 所提策略相比传统检测器能有效提升低可观测目标的检测性能，检测架构至少对杂波功率具有恒虚警率特性。

Conclusion: 利用可重构智能表面辅助雷达检测低可观测目标是有效解决方案，克服了传统多基地雷达网络的局限性，为实际应用提供了可行方案。

Abstract: In this paper, we address the radar detection of low observable targets with the assistance of a reconfigurable intelligent surface (RIS). Instead of using a multistatic radar network as counter-stealth strategy with its synchronization, costs, phase coherence, and energy consumption issues, we exploit a RIS to form a joint monostatic and bistatic configuration that can intercept the energy backscattered by the target along irrelevant directions different from the line-of-sight of the radar. Then, this energy is redirected towards the radar that capitalizes all the backscattered energy to detect the low observable target. To this end, five different detection architectures are devised that jointly process monostatic and bistatic echoes and exhibit the constant false alarm rate property at least with respect to the clutter power. To support the practical implementation, we also provide a guideline for the design of a RIS that satisfies the operating requirements of the considered application. The performance analysis is carried out in comparison with conventional detectors and shows that the proposed strategy leads to effective solutions to the detection of low observable targets.

</details>


### [14] [Large Wireless Foundation Models: Stronger over Bigger](https://arxiv.org/abs/2601.10963)
*Xiang Cheng,Boxun Liu,Xuanyu Liu,Xuesong Cai*

Main category: eess.SP

TL;DR: 提出大型无线基础模型（LWPM）概念，为6G物理层提供基于基础模型的框架，解决现有AI通信系统泛化能力差的问题


<details>
  <summary>Details</summary>
Motivation: 现有基于AI的物理层设计采用任务特定模型，泛化能力差；而通信系统本质上是通用系统，需要支持多样化场景的广泛适用性和鲁棒性。基础模型具有强大的推理和泛化能力，但无线系统约束阻碍了LLM风格模型在无线领域的直接迁移

Method: 引入大型无线基础模型概念，提出两种实现范式：1）利用现有通用基础模型；2）构建新型无线基础模型。提炼两种范式的路线图，在无线约束下制定设计原则，并通过案例研究验证优势

Result: 提出了LWPM框架，通过多维度分析现有工作来定义"大型"概念，为未来研究指明方向。案例研究直观验证了LWPM赋能无线系统的优势

Conclusion: 大型无线基础模型是解决AI通信系统泛化问题的有前景方案，为6G物理层设计提供了新框架，需要在无线约束下探索基础模型的应用潜力

Abstract: AI-communication integration is widely regarded as a core enabling technology for 6G. Most existing AI-based physical-layer designs rely on task-specific models that are separately tailored to individual modules, resulting in poor generalization. In contrast, communication systems are inherently general-purpose and should support broad applicability and robustness across diverse scenarios. Foundation models offer a promising solution through strong reasoning and generalization, yet wireless-system constraints hinder a direct transfer of large language model (LLM)-style success to the wireless domain. Therefore, we introduce the concept of large wireless foundation models (LWFMs) and present a novel framework for empowering the physical layer with foundation models under wireless constraints. Specifically, we propose two paradigms for realizing LWFMs, including leveraging existing general-purpose foundation models and building novel wireless foundation models. Based on recent progress, we distill two roadmaps for each paradigm and formulate design principles under wireless constraints. We further provide case studies of LWFM-empowered wireless systems to intuitively validate their advantages. Finally, we characterize the notion of "large" in LWFMs through a multidimensional analysis of existing work and outline promising directions for future research.

</details>


### [15] [DuTrack: Long-Term Indoor Human Tracking with Dual-Channel Sensing and Inference](https://arxiv.org/abs/2601.10972)
*Mengning Li,Wenye Wang*

Main category: eess.SP

TL;DR: DuTrack：一种融合Wi-Fi和声学传感的多模态人体追踪系统，通过声学信号校正Wi-Fi累积误差，实现稳定长时追踪


<details>
  <summary>Details</summary>
Motivation: 当前基于速度特征的Wi-Fi追踪方法存在累积误差问题，难以实现长时间稳定轨迹追踪。家庭环境中普遍存在的声学信号为校正Wi-Fi误差提供了机会。

Method: 融合电磁波和机械波传感：将Wi-Fi在视距和非视距场景建模为椭圆菲涅尔区和双曲线区，设计声学传感信号建模为双曲线簇，建立优化方程，并设计数据驱动架构求解该方程。

Result: 实验结果显示，该多模态追踪方案性能优越：相比基于模型的方法，中位追踪误差降低89.37%；相比数据驱动方法，误差降低65.02%。

Conclusion: DuTrack通过融合Wi-Fi和声学传感，有效解决了Wi-Fi追踪的累积误差问题，实现了稳定的人体追踪，为智能家居和家庭护理应用提供了可靠解决方案。

Abstract: Wi-Fi tracking technology demonstrates promising potential for future smart home and intelligent family care. Currently, accurate Wi-Fi tracking methods rely primarily on fine-grained velocity features. However, such velocity-based approaches suffer from the problem of accumulative errors, making it challenging to stably track users' trajectories over a long period of time. This paper presents DuTrack, a fusion-based tracking system for stable human tracking. The fundamental idea is to leverage the ubiquitous acoustic signals in households to rectify the accumulative Wi-Fi tracking error. Theoretically, Wi-Fi sensing in line-of-sight (LoS) and non-line-of-sight (NLoS) scenarios can be modeled as elliptical Fresnel zones and hyperbolic zones, respectively. By designing acoustic sensing signals, we are able to model the acoustic sensing zones as a series of hyperbolic clusters. We reveal how to fuse the fields of electromagnetic waves and mechanical waves, and establish the optimization equation. Next, we design a data-driven architecture to solve the aforementioned optimization equation. Experimental results show that the proposed multimodal tracking scheme exhibits superior performance. We achieve a 89.37% reduction in median tracking error compared to model-based methods and a 65.02% reduction compared to data-driven methods.

</details>


### [16] [Delay-Aware Task Offloading for Heterogeneous VLC-RF-based Vehicular Fog Computing](https://arxiv.org/abs/2601.10978)
*Nan An,Hongyi He,Fang Yang,Chang Liu,Jian Song,Zhu Han,Binbin Zhu*

Main category: eess.SP

TL;DR: 提出了一种基于可见光通信(VLC)和射频(RF)的异构架构用于车载雾计算系统，通过动态任务分割和卸载来降低任务处理延迟


<details>
  <summary>Details</summary>
Motivation: 传统车载雾计算依赖RF通信，在密集车辆环境中适应性有限，需要更高效的通信架构来支持延迟敏感服务

Method: 设计了VLC-RF异构架构，将计算任务动态分割并通过VLC和RF链路卸载到空闲车辆；提出基于残差的Majorization-Minimization算法优化任务卸载和计算资源分配

Result: 仿真结果表明，提出的异构VLC-RF架构相比仅使用VLC或RF的系统，平均任务处理延迟降低了15%

Conclusion: VLC-RF异构架构能有效利用VLC的抗干扰性和RF的覆盖优势，显著提升车载雾计算系统的性能

Abstract: Vehicular fog computing (VFC) is a promising paradigm for reducing the computation burden of vehicles, thus supporting delay-sensitive services in next-generation transportation networks. However, traditional VFC schemes rely on radio frequency (RF) communications, which limits their adaptability for dense vehicular environments. In this paper, a heterogeneous visible light communication (VLC)-RF architecture is designed for VFC systems to facilitate efficient task offloading. Specifically, computing tasks are dynamically partitioned and offloaded to idle vehicles via both VLC and RF links, thereby fully exploiting the interference resilience of VLC and the coverage advantage of RF. To minimize the average task processing delay (TPD), an optimization problem of task offloading and computing resource allocation is formulated, and then solved by the developed residual-based majorization-minimization (RBMM) algorithm. Simulation results confirm that the heterogeneous VLC-RF architecture with the proposed algorithm achieves a 15% average TPD reduction compared to VFC systems relying solely on VLC or RF.

</details>


### [17] [Uni-Fi: Integrated Multi-Task Wi-Fi Sensing](https://arxiv.org/abs/2601.10980)
*Mengning Li,Wenye Wang*

Main category: eess.SP

TL;DR: Uni-Fi是一个可扩展的多任务Wi-Fi感知框架，通过统一架构和可扩展流水线解决不同感知任务集成难题，显著提升定位、活动分类和存在检测性能。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi感知技术能实现非侵入式连续监测，但不同感知任务集成面临两大挑战：缺乏统一架构捕捉任务间共享本质，以及缺乏可扩展流水线整合未来研究方法。

Method: 提出Uni-Fi框架：1) 建立统一理论框架揭示单任务与多任务感知的根本差异；2) 开发可扩展感知流水线，自动生成多任务感知求解器，实现多个感知模型的无缝集成。

Result: 实验结果显示Uni-Fi在多任务上表现稳健：定位误差约0.54米，活动分类准确率98.34%，存在检测准确率98.57%。

Conclusion: Uni-Fi通过统一框架和可扩展流水线成功解决了多任务Wi-Fi感知集成问题，为智能家居应用提供了高效、可扩展的解决方案。

Abstract: Wi-Fi sensing technology enables non-intrusive, continuous monitoring of user locations and activities, which supports diverse smart home applications. Since different sensing tasks exhibit contextual relationships, their integration can enhance individual module performance. However, integrating sensing tasks across different research efforts faces challenges due to the absence of two key elements. The first is a unified architecture that captures the fundamental nature shared across diverse sensing tasks. The second is an extensible pipeline that can integrate sensing methodologies proposed in potential future research. This paper presents Uni-Fi, an extensible framework for multi-task Wi-Fi sensing integration. This paper makes the following contributions. First, we propose a unified theoretical framework that reveals the fundamental differences between single-task and multi-task sensing. Second, we develop a scalable sensing pipeline that automatically generates multi-task sensing solvers, enabling seamless integration of multiple sensing models. Experimental results show that Uni-Fi achieves robust performance across tasks, with a localization error of approximately 0.54 meters, 98.34 percent accuracy for activity classification, and 98.57 percent accuracy for presence detection.

</details>


### [18] [Hybrid Resource Allocation Scheme for Bistatic ISAC with Data Channels](https://arxiv.org/abs/2601.11110)
*Marcus Henninger,Lucas Giroto,Ahmed Elkelesh,Silvio Mandelli*

Main category: eess.SP

TL;DR: 提出一种混合资源分配方案，通过在合适的感知网格上放置低调制阶数的伪导频符号，在略微降低通信链路频谱效率的同时，显著提升双基地集成感知与通信的感知性能。


<details>
  <summary>Details</summary>
Motivation: 双基地ISAC能够有效重用现有蜂窝基础设施，在数据信道上使用ISAC相比仅依赖导频可以提升感知性能。但存在资源分配冲突：通信链路希望传输高调制阶数符号以最大化吞吐量，而感知则偏好低调制阶数以在雷达图像中获得更高信噪比。

Method: 提出混合资源分配方案，在合适的感知网格上放置低调制阶数符号作为伪导频，增强双基地感知性能，同时仅略微降低通信链路的频谱效率。

Result: 仿真结果验证了该方法相对于不同基线的有效性，并提供了关于解码错误如何影响感知性能的实际见解。

Conclusion: 通过混合资源分配方案，在双基地ISAC系统中实现了通信与感知性能的良好平衡，为未来感知网络提供了实用解决方案。

Abstract: Bistatic integrated sensing and communication (ISAC) enables efficient reuse of the existing cellular infrastructure and is likely to play an important role in future sensing networks. In this context, ISAC using the data channel is a promising approach to improve the bistatic sensing performance compared to relying solely on pilots. One of the challenges associated with this approach is resource allocation: the communication link aims to transmit higher modulation order (MO) symbols to maximize the throughput, whereas a lower MO is preferable for sensing to achieve a higher signal-to-noise ratio in the radar image. To address this conflict, this paper introduces a hybrid resource allocation scheme. By placing lower MO symbols as pseudo-pilots on a suitable sensing grid, we enhance the bistatic sensing performance while only slightly reducing the spectral efficiency of the communication link. Simulation results validate our approach against different baselines and provide practical insights into how decoding errors affect the sensing performance.

</details>


### [19] [Comprehensive Robust Dynamic Mode Decomposition from Mode Extraction to Dimensional Reduction](https://arxiv.org/abs/2601.11116)
*Yuki Nakamura,Shingo Takemoto,Shunsuke Ono*

Main category: eess.SP

TL;DR: 提出CR-DMD框架，通过两阶段凸优化方法增强DMD对混合噪声的鲁棒性，提高模式提取精度和低维表示保真度


<details>
  <summary>Details</summary>
Motivation: 标准DMD依赖最小二乘估计计算线性时间演化算子，在噪声环境下性能显著下降。现有鲁棒变体通常只修改最小二乘公式，但仍不稳定且无法保证低维表示的保真度。

Method: 1. 基于凸优化的预处理方法，有效去除混合噪声，实现准确稳定的模式提取；2. 新的凸优化维度约简公式，将鲁棒提取的模式与原始噪声观测显式关联，通过模式的稀疏加权和构建原始数据的忠实表示。使用预条件原始-对偶分裂方法高效求解。

Result: 在流体动力学数据集上的实验表明，CR-DMD在噪声条件下，在模式精度和低维表示保真度方面始终优于最先进的鲁棒DMD方法。

Conclusion: CR-DMD通过鲁棒化整个DMD流程，从模式提取到维度约简，有效应对混合噪声，为动态系统分析提供了更可靠的框架。

Abstract: We propose Comprehensive Robust Dynamic Mode Decomposition (CR-DMD), a novel framework that robustifies the entire DMD process - from mode extraction to dimensional reduction - against mixed noise. Although standard DMD widely used for uncovering spatio-temporal patterns and constructing low-dimensional models of dynamical systems, it suffers from significant performance degradation under noise due to its reliance on least-squares estimation for computing the linear time evolution operator. Existing robust variants typically modify the least-squares formulation, but they remain unstable and fail to ensure faithful low-dimensional representations. First, we introduce a convex optimization-based preprocessing method designed to effectively remove mixed noise, achieving accurate and stable mode extraction. Second, we propose a new convex formulation for dimensional reduction that explicitly links the robustly extracted modes to the original noisy observations, constructing a faithful representation of the original data via a sparse weighted sum of the modes. Both stages are efficiently solved by a preconditioned primal-dual splitting method. Experiments on fluid dynamics datasets demonstrate that CR-DMD consistently outperforms state-of-the-art robust DMD methods in terms of mode accuracy and fidelity of low-dimensional representations under noisy conditions.

</details>


### [20] [Scalable mm-Wave Liquid Crystal Reconfigurable Intelligent Surfaces based on the Delay Line Architecture](https://arxiv.org/abs/2601.11307)
*Julia Schwarzbeck,Robin Neuder,Marc Späth,Alejandro Jiménez-Sáez*

Main category: eess.SP

TL;DR: 本文设计、制造并表征了工作在60GHz频段、最多750个辐射单元的宽带液晶可重构智能表面，采用延迟线架构实现宽带宽、连续相位控制和快速响应。


<details>
  <summary>Details</summary>
Motivation: 开发一种可扩展的毫米波可重构智能表面，解决传统液晶RIS的带宽限制和相位控制不足问题，实现高效、低功耗的波束赋形。

Method: 采用延迟线架构，将相位控制层与辐射层解耦，使用4.6微米薄液晶层，实现超过360°的连续相位控制。制造了120和750单元两种原型，采用相同的单元设计和列式偏置。

Result: 测量显示波束可在±60°范围内转向，-3dB带宽超过9%。单元功耗仅为纳瓦级，仿真预测孔径效率超过20%，实测效率为9.2%和2.6%，效率降低归因于实验室技术挑战。

Conclusion: 延迟线架构的液晶RIS相比传统方法具有显著优势，验证了该架构的可扩展性和在毫米波频段的宽带性能，为大规模可重构智能表面提供了有前景的解决方案。

Abstract: This paper presents the design, fabrication, and characterization of broadband liquid crystal (LC) reconfigurable intelligent surfaces (RIS) operating around 60 GHz and scaling up to 750 radiating elements. The RISs employ a delay line architecture (DLA) that decouples the phase shifting and radiating layer, enabling wide bandwidth, continuous phase control exceeding 360°, and fast response times with a micrometer-thin LC layer of 4.6 micrometer. Two prototypes with 120 and 750 elements are realized using identical unit cells and column-wise biasing. Measurements demonstrate beam steering over +-60° and -3 dB bandwidths exceeding 9% for both apertures, confirming the scalability of the proposed architecture. On top of a measured nanowatt power consumption per unit cell, aperture efficiencies above 20% are predicted by simulations. While the measured efficiencies are reduced to 9.2% and 2.6%, a detailed analysis verifies that this reduction can be attributed to technological challenges in a laboratory environment. Finally, a comprehensive comparison between the applied DLA-based LC-RIS and a conventional approach highlights the superior potential of applied architecture.

</details>


### [21] [Modulation, ISI, and Detection for Langmuir Adsorption-Based Microfluidic Molecular Communication](https://arxiv.org/abs/2601.11351)
*Ruifeng Zheng,Pengjie Zhou,Pit Hofmann,Martín Schottlender,Fatima Rani,Juan A. Cabrera,Frank H. P. Fitzek*

Main category: eess.SP

TL;DR: 研究微流控分子通信接收器，采用有限容量Langmuir吸附模型，在反应限制条件下推导脉冲响应和符号率递归，分析信道记忆和码间干扰，提出低复杂度检测器。


<details>
  <summary>Details</summary>
Motivation: 研究微流控分子通信系统中接收器的性能，特别是有限容量Langmuir吸附对信道特性的影响，需要分析信道记忆和码间干扰效应。

Method: 在反应限制条件下推导闭式单脉冲响应核和开关键控符号率递归；提出短脉冲和长脉冲近似；采用有限受体二项计数模型和脉冲结束采样；提出低复杂度中点阈值检测器。

Result: 揭示了长脉冲区域由于饱和导致的干扰不对称性；数值结果验证了所提出的表征方法，并量化了检测性能与脉冲和符号持续时间的关系。

Conclusion: 该研究为微流控分子通信接收器提供了理论框架，揭示了有限容量吸附对信道特性的重要影响，提出的低复杂度检测器在干扰可忽略时可简化为固定阈值检测。

Abstract: This paper studies microfluidic molecular communication receivers with finite-capacity Langmuir adsorption driven by an effective surface concentration. In the reaction-limited regime, we derive a closed-form single-pulse response kernel and a symbol-rate recursion for on-off keying that explicitly exposes channel memory and inter-symbol interference. We further develop short-pulse and long-pulse approximations, revealing an interference asymmetry in the long-pulse regime due to saturation. To account for stochasticity, we adopt a finite-receptor binomial counting model, employ pulse-end sampling, and propose a low-complexity midpoint-threshold detector that reduces to a fixed threshold when interference is negligible. Numerical results corroborate the proposed characterization and quantify detection performance versus pulse and symbol durations.

</details>


### [22] [Channel Estimation in MIMO Systems Aided by Microwave Linear Analog Computers (MiLACs)](https://arxiv.org/abs/2601.11438)
*Qiaosen Zhang,Matteo Nerini,Bruno Clerckx*

Main category: eess.SP

TL;DR: 提出用于微波线性模拟计算机辅助MIMO系统的高效LS和MMSE信道估计方案，通过模拟域实现与传统数字方法相同性能，同时显著降低计算复杂度、硬件要求和PAPR。


<details>
  <summary>Details</summary>
Motivation: 微波线性模拟计算机(MiLACs)为未来大规模MIMO系统提供了有前景的解决方案，但MiLAC辅助系统的信道估计仍是一个未解决的问题。传统的LS和MMSE估计依赖密集数字计算，这削弱了MiLACs带来的优势。

Method: 设计由MiLACs实现的训练预编码器和组合器，使LS和MMSE估计完全在模拟域执行。通过优化训练信号处理架构，实现与数字对应方法相同的性能。

Result: 数值结果验证了所提方案的有效性和优势。提出的方案在保持与传统数字方法相同性能的同时，显著降低了计算复杂度、发射RF链数量、ADC/DAC分辨率要求和PAPR。

Conclusion: 提出的模拟域LS和MMSE信道估计方案为MiLAC辅助MIMO系统提供了高效解决方案，充分发挥了MiLACs的硬件优势，为实现未来大规模MIMO系统的低复杂度实现提供了可行途径。

Abstract: Microwave linear analog computers (MiLACs) have recently emerged as a promising solution for future gigantic multiple-input multiple-output (MIMO) systems, enabling beamforming with greatly reduced hardware and computational cost. However, channel estimation for MiLAC-aided systems remains an open problem. Conventional least squares (LS) and minimum mean square error (MMSE) estimation rely on intensive digital computation, which undermines the benefits offered by MiLACs. In this letter, we propose efficient LS and MMSE channel estimation schemes for MiLAC-aided MIMO systems. By designing training precoders and combiners implemented by MiLACs, both LS and MMSE estimation are performed fully in the analog domain, achieving identical performance to their digital counterparts while significantly reducing computational complexity, transmit RF chains, analog-to-digital/digital-to-analog converters (ADCs/DACs) resolution requirements, and peak-to-average power ratio (PAPR). Numerical results verify the effectiveness and advantages of the proposed schemes.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [23] [DSA-Tokenizer: Disentangled Semantic-Acoustic Tokenization via Flow Matching-based Hierarchical Fusion](https://arxiv.org/abs/2601.09239)
*Hanlin Zhang,Daxin Tan,Dehua Tao,Xiao Chen,Haochen Tan,Yunhe Li,Yuchen Cao,Jianping Wang,Linqi Song*

Main category: cs.SD

TL;DR: DSA-Tokenizer提出了一种显式解耦语音为语义和声学标记的方法，通过不同的优化约束实现更好的解耦，支持高质量重建和灵活重组，促进语音大语言模型的可控生成。


<details>
  <summary>Details</summary>
Motivation: 现有语音标记化方法要么优先考虑语义编码，要么将语义内容与声学风格不可分割地融合，或者实现不完全的语义-声学解耦。为了获得更好的解耦效果，需要一种能够明确分离语音中语义和声学成分的标记化方法。

Method: DSA-Tokenizer通过不同的优化约束显式地将语音解耦为离散的语义和声学标记：语义标记通过ASR监督来捕捉语言内容，声学标记专注于mel频谱图恢复来编码风格。采用分层Flow-Matching解码器消除两个序列之间的刚性长度约束，并使用联合重建-重组训练策略来强化这种分离。

Result: DSA-Tokenizer通过稳健的解耦实现了高保真重建和灵活重组，促进了语音大语言模型中的可控生成。分析表明解耦标记化是未来语音建模的关键范式。

Conclusion: DSA-Tokenizer提供了一种有效的语音解耦标记化方法，能够明确分离语义和声学成分，为语音大语言模型的可控生成提供了重要基础，代表了语音建模的重要发展方向。

Abstract: Speech tokenizers serve as the cornerstone of discrete Speech Large Language Models (Speech LLMs). Existing tokenizers either prioritize semantic encoding, fuse semantic content with acoustic style inseparably, or achieve incomplete semantic-acoustic disentanglement. To achieve better disentanglement, we propose DSA-Tokenizer, which explicitly disentangles speech into discrete semantic and acoustic tokens via distinct optimization constraints. Specifically, semantic tokens are supervised by ASR to capture linguistic content, while acoustic tokens focus on mel-spectrograms restoration to encode style. To eliminate rigid length constraints between the two sequences, we introduce a hierarchical Flow-Matching decoder that further improve speech generation quality. Furthermore, We employ a joint reconstruction-recombination training strategy to enforce this separation. DSA-Tokenizer enables high fidelity reconstruction and flexible recombination through robust disentanglement, facilitating controllable generation in speech LLMs. Our analysis highlights disentangled tokenization as a pivotal paradigm for future speech modeling. Audio samples are avaialble at https://anonymous.4open.science/w/DSA_Tokenizer_demo/. The code and model will be made publicly available after the paper has been accepted.

</details>


### [24] [Unifying Speech Recognition, Synthesis and Conversion with Autoregressive Transformers](https://arxiv.org/abs/2601.10770)
*Runyuan Cai,Yu Lin,Yiming Wang,Chunlin Fu,Xiaodong Zeng*

Main category: cs.SD

TL;DR: GPA是一个统一的音频基础模型，将TTS、ASR和VC等多个语音任务集成在单个LLM架构中，使用共享的离散音频token空间和指令驱动任务诱导，实现高效多任务处理。


<details>
  <summary>Details</summary>
Motivation: 传统语音系统依赖独立的任务特定模型（TTS、ASR、VC），导致碎片化流水线，限制了可扩展性、效率和跨任务泛化能力。

Method: 采用统一的大型语言模型架构，基于共享离散音频token空间，支持指令驱动任务诱导，实现完全自回归的离散语音token建模，并进行跨语音领域的联合多任务训练。

Result: 模型家族支持高效多尺度部署，包括针对边缘和资源受限环境优化的0.3B参数轻量级变体，在多样化语音任务上实现竞争性性能，同时保持低延迟实际部署的可行性。

Conclusion: 统一的自回归架构能够在多样化语音任务上实现竞争性性能，同时保持低延迟实际部署的可行性，为语音处理提供了更高效、可扩展的解决方案。

Abstract: Traditional speech systems typically rely on separate, task-specific models for text-to-speech (TTS), automatic speech recognition (ASR), and voice conversion (VC), resulting in fragmented pipelines that limit scalability, efficiency, and cross-task generalization. In this paper, we present General-Purpose Audio (GPA), a unified audio foundation model that integrates multiple core speech tasks within a single large language model (LLM) architecture. GPA operates on a shared discrete audio token space and supports instruction-driven task induction, enabling a single autoregressive model to flexibly perform TTS, ASR, and VC without architectural modifications. This unified design combines a fully autoregressive formulation over discrete speech tokens, joint multi-task training across speech domains, and a scalable inference pipeline that achieves high concurrency and throughput. The resulting model family supports efficient multi-scale deployment, including a lightweight 0.3B-parameter variant optimized for edge and resource-constrained environments. Together, these design choices demonstrate that a unified autoregressive architecture can achieve competitive performance across diverse speech tasks while remaining viable for low-latency, practical deployment.

</details>


### [25] [WenetSpeech-Wu: Datasets, Benchmarks, and Models for a Unified Chinese Wu Dialect Speech Processing Ecosystem](https://arxiv.org/abs/2601.11027)
*Chengyou Wang,Mingchen Shao,Jingbin Hu,Zeyu Zhu,Hongfei Xue,Bingshen Mu,Xin Xu,Xingyi Duan,Binbin Zhang,Pengcheng Zhu,Chuang Ding,Xiaojun Zhang,Hui Bu,Lei Xie*

Main category: cs.SD

TL;DR: 该论文提出了首个大规模、多维度标注的吴语开源语音语料库WenetSpeech-Wu（约8000小时），并建立了标准化评测基准WenetSpeech-Wu-Bench，同时发布了一系列在多个任务上表现优异的开源模型，为吴语语音处理生态系统奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 吴语作为重要的汉语方言，拥有庞大的使用人群，但在语音技术发展中长期面临三大挑战：缺乏大规模语音数据、标准化评测基准和公开可用模型，这阻碍了包容性语音技术的发展。

Method: 1. 构建WenetSpeech-Wu语料库：收集约8000小时多样化吴语语音数据并进行多维度标注；2. 建立WenetSpeech-Wu-Bench评测基准：覆盖ASR、吴语-普通话翻译、说话人属性预测、语音情感识别、TTS合成和指令跟随TTS等多个任务；3. 训练并发布开源模型套件。

Result: 1. 发布了首个大规模吴语开源语音语料库（8000小时）；2. 建立了首个标准化公开评测基准；3. 发布的模型在多个任务上表现出竞争力，验证了数据集的有效性；4. 为吴语语音处理生态系统奠定了基础。

Conclusion: 该工作通过构建大规模语料库、标准化评测基准和开源模型套件，为吴语语音处理研究提供了完整的基础设施，支持方言语音智能的未来发展，所有资源均已开源。

Abstract: Speech processing for low-resource dialects remains a fundamental challenge in developing inclusive and robust speech technologies. Despite its linguistic significance and large speaker population, the Wu dialect of Chinese has long been hindered by the lack of large-scale speech data, standardized evaluation benchmarks, and publicly available models. In this work, we present WenetSpeech-Wu, the first large-scale, multi-dimensionally annotated open-source speech corpus for the Wu dialect, comprising approximately 8,000 hours of diverse speech data. Building upon this dataset, we introduce WenetSpeech-Wu-Bench, the first standardized and publicly accessible benchmark for systematic evaluation of Wu dialect speech processing, covering automatic speech recognition (ASR), Wu-to-Mandarin translation, speaker attribute prediction, speech emotion recognition, text-to-speech (TTS) synthesis, and instruction-following TTS (instruct TTS). Furthermore, we release a suite of strong open-source models trained on WenetSpeech-Wu, establishing competitive performance across multiple tasks and empirically validating the effectiveness of the proposed dataset. Together, these contributions lay the foundation for a comprehensive Wu dialect speech processing ecosystem, and we open-source proposed datasets, benchmarks, and models to support future research on dialectal speech intelligence.

</details>


### [26] [FlashLabs Chroma 1.0: A Real-Time End-to-End Spoken Dialogue Model with Personalized Voice Cloning](https://arxiv.org/abs/2601.11141)
*Tanyu Chen,Tairan Chen,Kai Shen,Zhenghua Bao,Zhihui Zhang,Man Yuan,Yi Shi*

Main category: cs.SD

TL;DR: Chroma 1.0是首个开源、实时、端到端的语音对话模型，通过交错文本-音频令牌调度（1:2）实现亚秒级延迟，同时在多轮对话中保持高质量个性化语音合成，在说话人相似度上比人类基线提升10.96%。


<details>
  <summary>Details</summary>
Motivation: 现有端到端语音对话系统虽然利用语音分词器和神经音频编解码器让LLM直接处理离散语音表示，但往往说话人身份保持能力有限，阻碍了个性化语音交互的实现。

Method: 采用交错文本-音频令牌调度（1:2）支持流式生成，实现亚秒级端到端延迟，同时保持高质量个性化语音合成能力。

Result: Chroma在说话人相似度上比人类基线相对提升10.96%，实时因子（RTF）为0.43，同时保持强大的推理和对话能力。

Conclusion: Chroma 1.0是首个实现低延迟交互和高保真个性化语音克隆的开源实时端到端语音对话模型，为个性化语音交互提供了有效解决方案。

Abstract: Recent end-to-end spoken dialogue systems leverage speech tokenizers and neural audio codecs to enable LLMs to operate directly on discrete speech representations. However, these models often exhibit limited speaker identity preservation, hindering personalized voice interaction. In this work, we present Chroma 1.0, the first open-source, real-time, end-to-end spoken dialogue model that achieves both low-latency interaction and high-fidelity personalized voice cloning. Chroma achieves sub-second end-to-end latency through an interleaved text-audio token schedule (1:2) that supports streaming generation, while maintaining high-quality personalized voice synthesis across multi-turn conversations. Our experimental results demonstrate that Chroma achieves a 10.96% relative improvement in speaker similarity over the human baseline, with a Real-Time Factor (RTF) of 0.43, while maintaining strong reasoning and dialogue capabilities. Our code and models are publicly available at https://github.com/FlashLabs-AI-Corp/FlashLabs-Chroma and https://huggingface.co/FlashLabs/Chroma-4B .

</details>


### [27] [SonicBench: Dissecting the Physical Perception Bottleneck in Large Audio Language Models](https://arxiv.org/abs/2601.11039)
*Yirong Sun,Yanjun Chen,Xin Qiu,Gang Zhang,Hongyu Chen,Daokuan Wu,Chengming Li,Min Yang,Dawei Zhu,Wei Zhang,Xiaoyu Shen*

Main category: cs.SD

TL;DR: SonicBench基准测试揭示大型音频语言模型在基础物理属性感知方面存在严重缺陷，性能接近随机猜测，且无法有效利用编码器已捕获的感官信号。


<details>
  <summary>Details</summary>
Motivation: 当前大型音频语言模型在语义和副语言任务上表现出色，但对音频基础物理属性（如音高、响度、空间位置）的感知能力研究不足，需要系统评估模型的基础听觉理解能力。

Method: 提出SonicBench基准，使用可控生成工具箱构建刺激材料，涵盖5个感知维度的12个核心物理属性，采用识别（绝对判断）和比较（相对判断）两种互补范式进行评估。

Result: 大多数模型在物理属性感知任务上表现接近随机猜测，与人类模式相反，在比较任务上没有显示出预期优势，显式推理带来的提升有限。但线性探测分析显示冻结音频编码器成功捕获了这些物理线索（准确率至少60%）。

Conclusion: 主要瓶颈在于对齐和解码阶段，模型未能有效利用已捕获的感官信号。这揭示了LALMs在基础听觉理解方面的严重缺陷，为未来改进提供了方向。

Abstract: Large Audio Language Models (LALMs) excel at semantic and paralinguistic tasks, yet their ability to perceive the fundamental physical attributes of audio such as pitch, loudness, and spatial location remains under-explored. To bridge this gap, we introduce SonicBench, a psychophysically grounded benchmark that systematically evaluates 12 core physical attributes across five perceptual dimensions. Unlike previous datasets, SonicBench uses a controllable generation toolbox to construct stimuli for two complementary paradigms: recognition (absolute judgment) and comparison (relative judgment). This design allows us to probe not only sensory precision but also relational reasoning capabilities, a domain where humans typically exhibit greater proficiency. Our evaluation reveals a substantial deficiency in LALMs' foundational auditory understanding; most models perform near random guessing and, contrary to human patterns, fail to show the expected advantage on comparison tasks. Furthermore, explicit reasoning yields minimal gains. However, our linear probing analysis demonstrates crucially that frozen audio encoders do successfully capture these physical cues (accuracy at least 60%), suggesting that the primary bottleneck lies in the alignment and decoding stages, where models fail to leverage the sensory signals they have already captured.

</details>


### [28] [Scalable Music Cover Retrieval Using Lyrics-Aligned Audio Embeddings](https://arxiv.org/abs/2601.11262)
*Joanne Affolter,Benjamin Martin,Elena V. Epure,Gabriel Meseguer-Brocal,Frédéric Kaplan*

Main category: cs.SD

TL;DR: LIVI是一个基于歌词的音乐翻唱检索系统，通过训练时利用转录和文本嵌入模型监督，在推理时去除转录步骤，实现了高准确率和计算效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 现有音乐翻唱检索方法主要依赖和声和旋律特征，需要复杂的音频处理流程和大量计算资源。歌词在翻唱中具有高度不变性，但受限于从多音轨音频中准确提取歌词的困难。早期方法性能有限，近期方法虽然效果好但需要大型模型和复杂多模态架构。

Method: LIVI（Lyrics-Informed Version Identification）方法：1）训练时利用最先进的转录模型和文本嵌入模型进行监督学习；2）推理时去除转录步骤，保持轻量级和高效性；3）挑战传统复杂流程的统治地位。

Result: LIVI在检索准确率上达到或超过了基于和声的系统水平，同时保持了轻量级和计算效率，实现了准确性与效率的良好平衡。

Conclusion: LIVI证明了利用歌词信息进行音乐翻唱检索的可行性，通过创新的训练-推理分离策略，在保持高准确率的同时显著降低了计算复杂度，为音乐检索系统提供了更实用的解决方案。

Abstract: Music Cover Retrieval, also known as Version Identification, aims to recognize distinct renditions of the same underlying musical work, a task central to catalog management, copyright enforcement, and music retrieval. State-of-the-art approaches have largely focused on harmonic and melodic features, employing increasingly complex audio pipelines designed to be invariant to musical attributes that often vary widely across covers. While effective, these methods demand substantial training time and computational resources. By contrast, lyrics constitute a strong invariant across covers, though their use has been limited by the difficulty of extracting them accurately and efficiently from polyphonic audio. Early methods relied on simple frameworks that limited downstream performance, while more recent systems deliver stronger results but require large models integrated within complex multimodal architectures. We introduce LIVI (Lyrics-Informed Version Identification), an approach that seeks to balance retrieval accuracy with computational efficiency. First, LIVI leverages supervision from state-of-the-art transcription and text embedding models during training to achieve retrieval accuracy on par with--or superior to--harmonic-based systems. Second, LIVI remains lightweight and efficient by removing the transcription step at inference, challenging the dominance of complexity-heavy pipelines.

</details>

{"id": "2601.09239", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.09239", "abs": "https://arxiv.org/abs/2601.09239", "authors": ["Hanlin Zhang", "Daxin Tan", "Dehua Tao", "Xiao Chen", "Haochen Tan", "Yunhe Li", "Yuchen Cao", "Jianping Wang", "Linqi Song"], "title": "DSA-Tokenizer: Disentangled Semantic-Acoustic Tokenization via Flow Matching-based Hierarchical Fusion", "comment": "Submit to ACL ARR 2026 Jaunary", "summary": "Speech tokenizers serve as the cornerstone of discrete Speech Large Language Models (Speech LLMs). Existing tokenizers either prioritize semantic encoding, fuse semantic content with acoustic style inseparably, or achieve incomplete semantic-acoustic disentanglement. To achieve better disentanglement, we propose DSA-Tokenizer, which explicitly disentangles speech into discrete semantic and acoustic tokens via distinct optimization constraints. Specifically, semantic tokens are supervised by ASR to capture linguistic content, while acoustic tokens focus on mel-spectrograms restoration to encode style. To eliminate rigid length constraints between the two sequences, we introduce a hierarchical Flow-Matching decoder that further improve speech generation quality. Furthermore, We employ a joint reconstruction-recombination training strategy to enforce this separation. DSA-Tokenizer enables high fidelity reconstruction and flexible recombination through robust disentanglement, facilitating controllable generation in speech LLMs. Our analysis highlights disentangled tokenization as a pivotal paradigm for future speech modeling. Audio samples are avaialble at https://anonymous.4open.science/w/DSA_Tokenizer_demo/. The code and model will be made publicly available after the paper has been accepted."}
{"id": "2601.10770", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.10770", "abs": "https://arxiv.org/abs/2601.10770", "authors": ["Runyuan Cai", "Yu Lin", "Yiming Wang", "Chunlin Fu", "Xiaodong Zeng"], "title": "Unifying Speech Recognition, Synthesis and Conversion with Autoregressive Transformers", "comment": null, "summary": "Traditional speech systems typically rely on separate, task-specific models for text-to-speech (TTS), automatic speech recognition (ASR), and voice conversion (VC), resulting in fragmented pipelines that limit scalability, efficiency, and cross-task generalization. In this paper, we present General-Purpose Audio (GPA), a unified audio foundation model that integrates multiple core speech tasks within a single large language model (LLM) architecture. GPA operates on a shared discrete audio token space and supports instruction-driven task induction, enabling a single autoregressive model to flexibly perform TTS, ASR, and VC without architectural modifications. This unified design combines a fully autoregressive formulation over discrete speech tokens, joint multi-task training across speech domains, and a scalable inference pipeline that achieves high concurrency and throughput. The resulting model family supports efficient multi-scale deployment, including a lightweight 0.3B-parameter variant optimized for edge and resource-constrained environments. Together, these design choices demonstrate that a unified autoregressive architecture can achieve competitive performance across diverse speech tasks while remaining viable for low-latency, practical deployment."}
{"id": "2601.11141", "categories": ["cs.SD", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.11141", "abs": "https://arxiv.org/abs/2601.11141", "authors": ["Tanyu Chen", "Tairan Chen", "Kai Shen", "Zhenghua Bao", "Zhihui Zhang", "Man Yuan", "Yi Shi"], "title": "FlashLabs Chroma 1.0: A Real-Time End-to-End Spoken Dialogue Model with Personalized Voice Cloning", "comment": null, "summary": "Recent end-to-end spoken dialogue systems leverage speech tokenizers and neural audio codecs to enable LLMs to operate directly on discrete speech representations. However, these models often exhibit limited speaker identity preservation, hindering personalized voice interaction. In this work, we present Chroma 1.0, the first open-source, real-time, end-to-end spoken dialogue model that achieves both low-latency interaction and high-fidelity personalized voice cloning. Chroma achieves sub-second end-to-end latency through an interleaved text-audio token schedule (1:2) that supports streaming generation, while maintaining high-quality personalized voice synthesis across multi-turn conversations. Our experimental results demonstrate that Chroma achieves a 10.96% relative improvement in speaker similarity over the human baseline, with a Real-Time Factor (RTF) of 0.43, while maintaining strong reasoning and dialogue capabilities. Our code and models are publicly available at https://github.com/FlashLabs-AI-Corp/FlashLabs-Chroma and https://huggingface.co/FlashLabs/Chroma-4B ."}
{"id": "2601.10770", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.10770", "abs": "https://arxiv.org/abs/2601.10770", "authors": ["Runyuan Cai", "Yu Lin", "Yiming Wang", "Chunlin Fu", "Xiaodong Zeng"], "title": "Unifying Speech Recognition, Synthesis and Conversion with Autoregressive Transformers", "comment": null, "summary": "Traditional speech systems typically rely on separate, task-specific models for text-to-speech (TTS), automatic speech recognition (ASR), and voice conversion (VC), resulting in fragmented pipelines that limit scalability, efficiency, and cross-task generalization. In this paper, we present General-Purpose Audio (GPA), a unified audio foundation model that integrates multiple core speech tasks within a single large language model (LLM) architecture. GPA operates on a shared discrete audio token space and supports instruction-driven task induction, enabling a single autoregressive model to flexibly perform TTS, ASR, and VC without architectural modifications. This unified design combines a fully autoregressive formulation over discrete speech tokens, joint multi-task training across speech domains, and a scalable inference pipeline that achieves high concurrency and throughput. The resulting model family supports efficient multi-scale deployment, including a lightweight 0.3B-parameter variant optimized for edge and resource-constrained environments. Together, these design choices demonstrate that a unified autoregressive architecture can achieve competitive performance across diverse speech tasks while remaining viable for low-latency, practical deployment."}
{"id": "2601.10727", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10727", "abs": "https://arxiv.org/abs/2601.10727", "authors": ["Sanghyun Kim", "Jiwon Seo"], "title": "Zonotope Shadow and Reflection Matching: A Novel GNSS Reflection-Based Framework for Enhanced Positioning Accuracy in Urban Areas", "comment": "Submitted to IEEE T-ITS", "summary": "In urban areas, signal reception conditions are often poor due to reflections from buildings, resulting in inaccurate global navigation satellite system (GNSS)-based positioning. Various 3D-mapping-aided (3DMA) GNSS techniques, including shadow matching, have been proposed to address this issue. However, conventional shadow matching estimates positions in a discretized manner. The accuracy of this approach is limited by the resolution of the grid points representing the candidate receiver positions, making it difficult to achieve robust urban positioning and to ensure that the position estimate satisfies user-specified protection levels or safety bounds. To overcome these limitations, zonotope shadow matching (ZSM) has been proposed, which utilizes a set-based position estimate rather than grid-based estimates. ZSM calculates the GNSS shadow--an area on the ground where the line-of-sight (LOS) is blocked and only non-line-of-sight (NLOS) signals can be received--to estimate the receiver's position set. ZSM distinguishes between LOS and NLOS satellites, determining that the receiver is inside the GNSS shadow if the satellite is NLOS and outside if the satellite is LOS. However, relying solely on GNSS shadows limits the ability to sufficiently reduce the size of the receiver position set and to precisely estimate the receiver's location. To address this, we propose zonotope shadow and reflection matching (ZSRM) to enhance positioning accuracy in urban areas. The proposed ZSRM technique is validated through field tests using GNSS signals collected in an urban environment. Consequently, the RMS horizontal position error of ZSRM improved by 10.0% to 53.6% compared with ZSM, while the RMS cross-street and along-street position bounds improved by 18.0% to 50.1% and 30.7% to 59.3%, respectively."}
{"id": "2601.11027", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2601.11027", "abs": "https://arxiv.org/abs/2601.11027", "authors": ["Chengyou Wang", "Mingchen Shao", "Jingbin Hu", "Zeyu Zhu", "Hongfei Xue", "Bingshen Mu", "Xin Xu", "Xingyi Duan", "Binbin Zhang", "Pengcheng Zhu", "Chuang Ding", "Xiaojun Zhang", "Hui Bu", "Lei Xie"], "title": "WenetSpeech-Wu: Datasets, Benchmarks, and Models for a Unified Chinese Wu Dialect Speech Processing Ecosystem", "comment": null, "summary": "Speech processing for low-resource dialects remains a fundamental challenge in developing inclusive and robust speech technologies. Despite its linguistic significance and large speaker population, the Wu dialect of Chinese has long been hindered by the lack of large-scale speech data, standardized evaluation benchmarks, and publicly available models. In this work, we present WenetSpeech-Wu, the first large-scale, multi-dimensionally annotated open-source speech corpus for the Wu dialect, comprising approximately 8,000 hours of diverse speech data. Building upon this dataset, we introduce WenetSpeech-Wu-Bench, the first standardized and publicly accessible benchmark for systematic evaluation of Wu dialect speech processing, covering automatic speech recognition (ASR), Wu-to-Mandarin translation, speaker attribute prediction, speech emotion recognition, text-to-speech (TTS) synthesis, and instruction-following TTS (instruct TTS). Furthermore, we release a suite of strong open-source models trained on WenetSpeech-Wu, establishing competitive performance across multiple tasks and empirically validating the effectiveness of the proposed dataset. Together, these contributions lay the foundation for a comprehensive Wu dialect speech processing ecosystem, and we open-source proposed datasets, benchmarks, and models to support future research on dialectal speech intelligence."}
{"id": "2601.10733", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2601.10733", "abs": "https://arxiv.org/abs/2601.10733", "authors": ["Jakob Struye", "Nabeel Nisar Bhat", "Siddhartha Kumar", "Mohammad Hossein Moghaddam", "Jeroen Famaey"], "title": "Millimeter-Wave Gesture Recognition in ISAC: Does Reducing Sensing Airtime Hamper Accuracy?", "comment": null, "summary": "Most Integrated Sensing and Communications (ISAC) systems require dividing airtime across their two modes. However, the specific impact of this decision on sensing performance remains unclear and underexplored. In this paper, we therefore investigate the impact on a gesture recognition system using a Millimeter-Wave (mmWave) ISAC system. With our dataset of power per beam pair gathered with two mmWave devices performing constant beam sweeps while test subjects performed distinct gestures, we train a gesture classifier using Convolutional Neural Networks. We then subsample these measurements, emulating reduced sensing airtime, showing that a sensing airtime of 25 % only reduces classification accuracy by 0.15 percentage points from full-time sensing. Alongside this high-quality sensing at low airtime, mmWave systems are known to provide extremely high data throughputs, making mmWave ISAC a prime enabler for applications such as truly wireless Extended Reality."}
{"id": "2601.11039", "categories": ["cs.SD", "cs.CL"], "pdf": "https://arxiv.org/pdf/2601.11039", "abs": "https://arxiv.org/abs/2601.11039", "authors": ["Yirong Sun", "Yanjun Chen", "Xin Qiu", "Gang Zhang", "Hongyu Chen", "Daokuan Wu", "Chengming Li", "Min Yang", "Dawei Zhu", "Wei Zhang", "Xiaoyu Shen"], "title": "SonicBench: Dissecting the Physical Perception Bottleneck in Large Audio Language Models", "comment": null, "summary": "Large Audio Language Models (LALMs) excel at semantic and paralinguistic tasks, yet their ability to perceive the fundamental physical attributes of audio such as pitch, loudness, and spatial location remains under-explored. To bridge this gap, we introduce SonicBench, a psychophysically grounded benchmark that systematically evaluates 12 core physical attributes across five perceptual dimensions. Unlike previous datasets, SonicBench uses a controllable generation toolbox to construct stimuli for two complementary paradigms: recognition (absolute judgment) and comparison (relative judgment). This design allows us to probe not only sensory precision but also relational reasoning capabilities, a domain where humans typically exhibit greater proficiency. Our evaluation reveals a substantial deficiency in LALMs' foundational auditory understanding; most models perform near random guessing and, contrary to human patterns, fail to show the expected advantage on comparison tasks. Furthermore, explicit reasoning yields minimal gains. However, our linear probing analysis demonstrates crucially that frozen audio encoders do successfully capture these physical cues (accuracy at least 60%), suggesting that the primary bottleneck lies in the alignment and decoding stages, where models fail to leverage the sensory signals they have already captured."}
{"id": "2601.10735", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10735", "abs": "https://arxiv.org/abs/2601.10735", "authors": ["Lizy Abraham", "Siobhan Coughlan", "Kritika Rajain", "Changhong Li", "Saji Philip", "Adam James"], "title": "SSC-UNet: UNet with Self-Supervised Contrastive Learning for Phonocardiography Noise Reduction", "comment": "Accepted by IEEE Healthcom 2025", "summary": "Congenital Heart Disease (CHD) remains a significant global health concern affecting approximately 1\\% of births worldwide. Phonocardiography has emerged as a supplementary tool to diagnose CHD cost-effectively. However, the performance of these diagnostic models highly depends on the quality of the phonocardiography, thus, noise reduction is particularly critical. Supervised UNet effectively improves noise reduction capabilities, but limited clean data hinders its application. The complex time-frequency characteristics of phonocardiography further complicate finding the balance between effectively removing noise and preserving pathological features. In this study, we proposed a self-supervised phonocardiography noise reduction model based on Noise2Noise to enable training without clean data. Augmentation and contrastive learning are applied to enhance its performance. We obtained an average SNR of 12.98 dB after filtering under 10~dB of hospital noise. Classification sensitivity after filtering was improved from 27\\% to 88\\%, indicating its promising pathological feature retention capabilities in practical noisy environments."}
{"id": "2601.11141", "categories": ["cs.SD", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2601.11141", "abs": "https://arxiv.org/abs/2601.11141", "authors": ["Tanyu Chen", "Tairan Chen", "Kai Shen", "Zhenghua Bao", "Zhihui Zhang", "Man Yuan", "Yi Shi"], "title": "FlashLabs Chroma 1.0: A Real-Time End-to-End Spoken Dialogue Model with Personalized Voice Cloning", "comment": null, "summary": "Recent end-to-end spoken dialogue systems leverage speech tokenizers and neural audio codecs to enable LLMs to operate directly on discrete speech representations. However, these models often exhibit limited speaker identity preservation, hindering personalized voice interaction. In this work, we present Chroma 1.0, the first open-source, real-time, end-to-end spoken dialogue model that achieves both low-latency interaction and high-fidelity personalized voice cloning. Chroma achieves sub-second end-to-end latency through an interleaved text-audio token schedule (1:2) that supports streaming generation, while maintaining high-quality personalized voice synthesis across multi-turn conversations. Our experimental results demonstrate that Chroma achieves a 10.96% relative improvement in speaker similarity over the human baseline, with a Real-Time Factor (RTF) of 0.43, while maintaining strong reasoning and dialogue capabilities. Our code and models are publicly available at https://github.com/FlashLabs-AI-Corp/FlashLabs-Chroma and https://huggingface.co/FlashLabs/Chroma-4B ."}
{"id": "2601.10737", "categories": ["eess.SP", "cond-mat.mtrl-sci", "cs.CV", "math.OC"], "pdf": "https://arxiv.org/pdf/2601.10737", "abs": "https://arxiv.org/abs/2601.10737", "authors": ["Giuseppe Romano", "Rodrigo Arrieta", "Steven G. Johnson"], "title": "Differentiating through binarized topology changes: Second-order subpixel-smoothed projection", "comment": null, "summary": "A key challenge in topology optimization (TopOpt) is that manufacturable structures, being inherently binary, are non-differentiable, creating a fundamental tension with gradient-based optimization. The subpixel-smoothed projection (SSP) method addresses this issue by smoothing sharp interfaces at the subpixel level through a first-order expansion of the filtered field. However, SSP does not guarantee differentiability under topology changes, such as the merging of two interfaces, and therefore violates the convergence guarantees of many popular gradient-based optimization algorithms. We overcome this limitation by regularizing SSP with the Hessian of the filtered field, resulting in a twice-differentiable projected density during such transitions, while still guaranteeing an almost-everywhere binary structure. We demonstrate the effectiveness of our second-order SSP (SSP2) methodology on both thermal and photonic problems, showing that SSP2 has faster convergence than SSP for connectivity-dominant cases -- where frequent topology changes occur -- while exhibiting comparable performance otherwise. Beyond improving convergence guarantees for CCSA optimizers, SSP2 enables the use of a broader class of optimization algorithms with stronger theoretical guarantees, such as interior-point methods. Since SSP2 adds minimal complexity relative to SSP or traditional projection schemes, it can be used as a drop-in replacement in existing TopOpt codes."}
{"id": "2601.11262", "categories": ["cs.SD", "cs.IR", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11262", "abs": "https://arxiv.org/abs/2601.11262", "authors": ["Joanne Affolter", "Benjamin Martin", "Elena V. Epure", "Gabriel Meseguer-Brocal", "Frédéric Kaplan"], "title": "Scalable Music Cover Retrieval Using Lyrics-Aligned Audio Embeddings", "comment": "Published at ECIR 2026 (European Conference of Information Retrieval)", "summary": "Music Cover Retrieval, also known as Version Identification, aims to recognize distinct renditions of the same underlying musical work, a task central to catalog management, copyright enforcement, and music retrieval. State-of-the-art approaches have largely focused on harmonic and melodic features, employing increasingly complex audio pipelines designed to be invariant to musical attributes that often vary widely across covers. While effective, these methods demand substantial training time and computational resources. By contrast, lyrics constitute a strong invariant across covers, though their use has been limited by the difficulty of extracting them accurately and efficiently from polyphonic audio. Early methods relied on simple frameworks that limited downstream performance, while more recent systems deliver stronger results but require large models integrated within complex multimodal architectures. We introduce LIVI (Lyrics-Informed Version Identification), an approach that seeks to balance retrieval accuracy with computational efficiency. First, LIVI leverages supervision from state-of-the-art transcription and text embedding models during training to achieve retrieval accuracy on par with--or superior to--harmonic-based systems. Second, LIVI remains lightweight and efficient by removing the transcription step at inference, challenging the dominance of complexity-heavy pipelines."}
{"id": "2601.10743", "categories": ["eess.SP", "cs.LG", "cs.NI"], "pdf": "https://arxiv.org/pdf/2601.10743", "abs": "https://arxiv.org/abs/2601.10743", "authors": ["Ayesh Abu Lehyeh", "Anastassia Gharib", "Tian Xia", "Dryver Huston", "Safwan Wshah"], "title": "UBiGTLoc: A Unified BiLSTM-Graph Transformer Localization Framework for IoT Sensor Networks", "comment": "Accepted and published in IEEE Internet of Things Journal", "summary": "Sensor nodes localization in wireless Internet of Things (IoT) sensor networks is crucial for the effective operation of diverse applications, such as smart cities and smart agriculture. Existing sensor nodes localization approaches heavily rely on anchor nodes within wireless sensor networks (WSNs). Anchor nodes are sensor nodes equipped with global positioning system (GPS) receivers and thus, have known locations. These anchor nodes operate as references to localize other sensor nodes. However, the presence of anchor nodes may not always be feasible in real-world IoT scenarios. Additionally, localization accuracy can be compromised by fluctuations in Received Signal Strength Indicator (RSSI), particularly under non-line-of-sight (NLOS) conditions. To address these challenges, we propose UBiGTLoc, a Unified Bidirectional Long Short-Term Memory (BiLSTM)-Graph Transformer Localization framework. The proposed UBiGTLoc framework effectively localizes sensor nodes in both anchor-free and anchor-presence WSNs. The framework leverages BiLSTM networks to capture temporal variations in RSSI data and employs Graph Transformer layers to model spatial relationships between sensor nodes. Extensive simulations demonstrate that UBiGTLoc consistently outperforms existing methods and provides robust localization across both dense and sparse WSNs while relying solely on cost-effective RSSI data."}
{"id": "2601.10745", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10745", "abs": "https://arxiv.org/abs/2601.10745", "authors": ["Shivam Kumar", "Himanshu Singh"], "title": "An IoT-Based Controlled Environment Storage for Prevention of Spoilage of Onion (Allium Cepa) During Post-Harvest with UV-C Disinfection", "comment": "8 pages, 7 figures. Undergraduate Research Project", "summary": "India is the second largest producer of onions in the world, contributing over 26 million tonnes annually. However, during storage, approximately 30-40% of onions are lost due to rotting, sprouting, and weight loss. Despite being a major producer, conventional storage methods are either low-cost but ineffective (traditional storage with 40% spoilage) or highly effective but prohibitively expensive for small farmers (cold storage). This paper presents a low-cost IoT-based smart onion storage system that monitors and automatically regulates environmental parameters including temperature, humidity, and spoilage gases using ESP32 microcontroller, DHT22 sensor, MQ-135 gas sensor, and UV-C disinfection technology. The proposed system aims to reduce onion spoilage to 15-20% from the current 40-45% wastage rate while remaining affordable for small and marginal farmers who constitute the majority in India. The system is designed to be cost-effective (estimated 60k-70k INR), energy-efficient, farmer-friendly, and solar-powered."}
{"id": "2601.10746", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2601.10746", "abs": "https://arxiv.org/abs/2601.10746", "authors": ["Yuxin Yang", "Hang Zhou", "Hourong Song", "Branislav Hredzak"], "title": "On the static and small signal analysis of DAB converter", "comment": null, "summary": "This document develops a method to solve the periodic operating point of Dual-Active-Bridge (DAB)."}
{"id": "2601.10747", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10747", "abs": "https://arxiv.org/abs/2601.10747", "authors": ["Silke K. Kaiser"], "title": "Sensor Placement for Urban Traffic Interpolation: A Data-Driven Evaluation to Inform Policy", "comment": null, "summary": "Data on citywide street-segment traffic volumes are essential for urban planning and sustainable mobility management. Yet such data are available only for a limited subset of streets due to the high costs of sensor deployment and maintenance. Traffic volumes on the remaining network are therefore interpolated based on existing sensor measurements. However, current sensor locations are often determined by administrative priorities rather than by data-driven optimization, leading to biased coverage and reduced estimation performance. This study provides a large-scale, real-world benchmarking of easily implementable, data-driven strategies for optimizing the placement of permanent and temporary traffic sensors, using segment-level data from Berlin (Strava bicycle counts) and Manhattan (taxi counts). It compares spatial placement strategies based on network centrality, spatial coverage, feature coverage, and active learning. In addition, the study examines temporal deployment schemes for temporary sensors. The findings highlight that spatial placement strategies that emphasize even spatial coverage and employ active learning achieve the lowest prediction errors. With only 10 sensors, they reduce the mean absolute error by over 60% in Berlin and 70% in Manhattan compared to alternatives. Temporal deployment choices further improve performance: distributing measurements evenly across weekdays reduces error by an additional 7% in Berlin and 21% in Manhattan. Together, these spatial and temporal principles allow temporary deployments to closely approximate the performance of optimally placed permanent deployments. From a policy perspective, the results indicate that cities can substantially improve data usefulness by adopting data-driven sensor placement strategies, while retaining flexibility in choosing between temporary and permanent deployments."}
{"id": "2601.10748", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10748", "abs": "https://arxiv.org/abs/2601.10748", "authors": ["Jun Li", "Hongling Zhu", "Yujie Xiao", "Qinghao Zhao", "Yalei Ke", "Gongzheng Tang", "Guangkun Nie", "Deyun Zhang", "Jin Li", "Canqing Yu", "Shenda Hong"], "title": "AnyECG: Evolved ECG Foundation Model for Holistic Health Profiling", "comment": "in progress", "summary": "Background: Artificial intelligence enabled electrocardiography (AI-ECG) has demonstrated the ability to detect diverse pathologies, but most existing models focus on single disease identification, neglecting comorbidities and future risk prediction. Although ECGFounder expanded cardiac disease coverage, a holistic health profiling model remains needed.\n  Methods: We constructed a large multicenter dataset comprising 13.3 million ECGs from 2.98 million patients. Using transfer learning, ECGFounder was fine-tuned to develop AnyECG, a foundation model for holistic health profiling. Performance was evaluated using external validation cohorts and a 10-year longitudinal cohort for current diagnosis, future risk prediction, and comorbidity identification.\n  Results: AnyECG demonstrated systemic predictive capability across 1172 conditions, achieving an AUROC greater than 0.7 for 306 diseases. The model revealed novel disease associations, robust comorbidity patterns, and future disease risks. Representative examples included high diagnostic performance for hyperparathyroidism (AUROC 0.941), type 2 diabetes (0.803), Crohn disease (0.817), lymphoid leukemia (0.856), and chronic obstructive pulmonary disease (0.773).\n  Conclusion: The AnyECG foundation model provides substantial evidence that AI-ECG can serve as a systemic tool for concurrent disease detection and long-term risk prediction."}
{"id": "2601.10761", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10761", "abs": "https://arxiv.org/abs/2601.10761", "authors": ["Junseok Lee", "Jihye Shin", "Sangyong Lee", "Chang-Jae Chun"], "title": "LSR-Net: A Lightweight and Strong Robustness Network for Bearing Fault Diagnosis in Noise Environment", "comment": null, "summary": "Rotating bearings play an important role in modern industries, but have a high probability of occurrence of defects because they operate at high speed, high load, and poor operating environments. Therefore, if a delay time occurs when a bearing is diagnosed with a defect, this may cause economic loss and loss of life. Moreover, since the vibration sensor from which the signal is collected is highly affected by the operating environment and surrounding noise, accurate defect diagnosis in a noisy environment is also important. In this paper, we propose a lightweight and strong robustness network (LSR-Net) that is accurate in a noisy environment and enables real-time fault diagnosis. To this end, first, a denoising and feature enhancement module (DFEM) was designed to create a 3-channel 2D matrix by giving several nonlinearity to the feature-map that passed through the denoising module (DM) block composed of convolution-based denoising (CD) blocks. Moreover, adaptive pruning was applied to DM to improve denoising ability when the power of noise is strong. Second, for lightweight model design, a convolution-based efficiency shuffle (CES) block was designed using group convolution (GConv), group pointwise convolution (GPConv) and channel split that can design the model while maintaining low parameters. In addition, the trade-off between the accuracy and model computational complexity that can occur due to the lightweight design of the model was supplemented using attention mechanisms and channel shuffle. In order to verify the defect diagnosis performance of the proposed model, performance verification was conducted in a noisy environment using a vibration signal. As a result, it was confirmed that the proposed model had the best anti-noise ability compared to the benchmark models, and the computational complexity of the model was also the lowest."}
{"id": "2601.10771", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.10771", "abs": "https://arxiv.org/abs/2601.10771", "authors": ["Nay Klaimi", "Clément Elvira", "Philippe Mary", "Luc Le Magoarou"], "title": "Physically constrained unfolded multi-dimensional OMP for large MIMO systems", "comment": null, "summary": "Sparse recovery methods are essential for channel estimation and localization in modern communication systems, but their reliability relies on accurate physical models, which are rarely perfectly known. Their computational complexity also grows rapidly with the dictionary dimensions in large MIMO systems. In this paper, we propose MOMPnet, a novel unfolded sparse recovery framework that addresses both the reliability and complexity challenges of traditional methods. By integrating deep unfolding with data-driven dictionary learning, MOMPnet mitigates hardware impairments while preserving interpretability. Instead of a single large dictionary, multiple smaller, independent dictionaries are employed, enabling a low-complexity multidimensional Orthogonal Matching Pursuit algorithm. The proposed unfolded network is evaluated on realistic channel data against multiple baselines, demonstrating its strong performance and potential."}
{"id": "2601.10780", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.10780", "abs": "https://arxiv.org/abs/2601.10780", "authors": ["Nursultan Daupayev", "Christian Engel", "Ricky Bendyk", "Soeren Hirsch"], "title": "Adaptive algorithm for microsensor in sustainable environmental monitoring", "comment": null, "summary": "Traditional data collection from sensors produce a lot of data, which lead to constant power consumption and require more storage space. This study proposes an algorithm for a data acquisition and processing method based on Fourier transform (DFT), which extracts dominant frequency components using harmonic analysis (HA) to identify frequency peaks. This algorithm allows sensors to activate only when an event occurs, while preserving critical information for detecting defects, such as those in the surface structures of buildings and ensuring accuracy for further predictions."}
{"id": "2601.10846", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10846", "abs": "https://arxiv.org/abs/2601.10846", "authors": ["Fabiola Colone", "Filippo Costa", "Yiding Gao", "Chengpeng Hao", "Linjie Yan", "Giuliano Manara", "Danilo Orlando"], "title": "RIS-aided Radar Detection Architectures with Application to Low-RCS Targets", "comment": null, "summary": "In this paper, we address the radar detection of low observable targets with the assistance of a reconfigurable intelligent surface (RIS). Instead of using a multistatic radar network as counter-stealth strategy with its synchronization, costs, phase coherence, and energy consumption issues, we exploit a RIS to form a joint monostatic and bistatic configuration that can intercept the energy backscattered by the target along irrelevant directions different from the line-of-sight of the radar. Then, this energy is redirected towards the radar that capitalizes all the backscattered energy to detect the low observable target. To this end, five different detection architectures are devised that jointly process monostatic and bistatic echoes and exhibit the constant false alarm rate property at least with respect to the clutter power. To support the practical implementation, we also provide a guideline for the design of a RIS that satisfies the operating requirements of the considered application. The performance analysis is carried out in comparison with conventional detectors and shows that the proposed strategy leads to effective solutions to the detection of low observable targets."}
{"id": "2601.10963", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10963", "abs": "https://arxiv.org/abs/2601.10963", "authors": ["Xiang Cheng", "Boxun Liu", "Xuanyu Liu", "Xuesong Cai"], "title": "Large Wireless Foundation Models: Stronger over Bigger", "comment": null, "summary": "AI-communication integration is widely regarded as a core enabling technology for 6G. Most existing AI-based physical-layer designs rely on task-specific models that are separately tailored to individual modules, resulting in poor generalization. In contrast, communication systems are inherently general-purpose and should support broad applicability and robustness across diverse scenarios. Foundation models offer a promising solution through strong reasoning and generalization, yet wireless-system constraints hinder a direct transfer of large language model (LLM)-style success to the wireless domain. Therefore, we introduce the concept of large wireless foundation models (LWFMs) and present a novel framework for empowering the physical layer with foundation models under wireless constraints. Specifically, we propose two paradigms for realizing LWFMs, including leveraging existing general-purpose foundation models and building novel wireless foundation models. Based on recent progress, we distill two roadmaps for each paradigm and formulate design principles under wireless constraints. We further provide case studies of LWFM-empowered wireless systems to intuitively validate their advantages. Finally, we characterize the notion of \"large\" in LWFMs through a multidimensional analysis of existing work and outline promising directions for future research."}
{"id": "2601.10972", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10972", "abs": "https://arxiv.org/abs/2601.10972", "authors": ["Mengning Li", "Wenye Wang"], "title": "DuTrack: Long-Term Indoor Human Tracking with Dual-Channel Sensing and Inference", "comment": null, "summary": "Wi-Fi tracking technology demonstrates promising potential for future smart home and intelligent family care. Currently, accurate Wi-Fi tracking methods rely primarily on fine-grained velocity features. However, such velocity-based approaches suffer from the problem of accumulative errors, making it challenging to stably track users' trajectories over a long period of time. This paper presents DuTrack, a fusion-based tracking system for stable human tracking. The fundamental idea is to leverage the ubiquitous acoustic signals in households to rectify the accumulative Wi-Fi tracking error. Theoretically, Wi-Fi sensing in line-of-sight (LoS) and non-line-of-sight (NLoS) scenarios can be modeled as elliptical Fresnel zones and hyperbolic zones, respectively. By designing acoustic sensing signals, we are able to model the acoustic sensing zones as a series of hyperbolic clusters. We reveal how to fuse the fields of electromagnetic waves and mechanical waves, and establish the optimization equation. Next, we design a data-driven architecture to solve the aforementioned optimization equation. Experimental results show that the proposed multimodal tracking scheme exhibits superior performance. We achieve a 89.37% reduction in median tracking error compared to model-based methods and a 65.02% reduction compared to data-driven methods."}
{"id": "2601.10978", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10978", "abs": "https://arxiv.org/abs/2601.10978", "authors": ["Nan An", "Hongyi He", "Fang Yang", "Chang Liu", "Jian Song", "Zhu Han", "Binbin Zhu"], "title": "Delay-Aware Task Offloading for Heterogeneous VLC-RF-based Vehicular Fog Computing", "comment": null, "summary": "Vehicular fog computing (VFC) is a promising paradigm for reducing the computation burden of vehicles, thus supporting delay-sensitive services in next-generation transportation networks. However, traditional VFC schemes rely on radio frequency (RF) communications, which limits their adaptability for dense vehicular environments. In this paper, a heterogeneous visible light communication (VLC)-RF architecture is designed for VFC systems to facilitate efficient task offloading. Specifically, computing tasks are dynamically partitioned and offloaded to idle vehicles via both VLC and RF links, thereby fully exploiting the interference resilience of VLC and the coverage advantage of RF. To minimize the average task processing delay (TPD), an optimization problem of task offloading and computing resource allocation is formulated, and then solved by the developed residual-based majorization-minimization (RBMM) algorithm. Simulation results confirm that the heterogeneous VLC-RF architecture with the proposed algorithm achieves a 15% average TPD reduction compared to VFC systems relying solely on VLC or RF."}
{"id": "2601.10980", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.10980", "abs": "https://arxiv.org/abs/2601.10980", "authors": ["Mengning Li", "Wenye Wang"], "title": "Uni-Fi: Integrated Multi-Task Wi-Fi Sensing", "comment": null, "summary": "Wi-Fi sensing technology enables non-intrusive, continuous monitoring of user locations and activities, which supports diverse smart home applications. Since different sensing tasks exhibit contextual relationships, their integration can enhance individual module performance. However, integrating sensing tasks across different research efforts faces challenges due to the absence of two key elements. The first is a unified architecture that captures the fundamental nature shared across diverse sensing tasks. The second is an extensible pipeline that can integrate sensing methodologies proposed in potential future research. This paper presents Uni-Fi, an extensible framework for multi-task Wi-Fi sensing integration. This paper makes the following contributions. First, we propose a unified theoretical framework that reveals the fundamental differences between single-task and multi-task sensing. Second, we develop a scalable sensing pipeline that automatically generates multi-task sensing solvers, enabling seamless integration of multiple sensing models. Experimental results show that Uni-Fi achieves robust performance across tasks, with a localization error of approximately 0.54 meters, 98.34 percent accuracy for activity classification, and 98.57 percent accuracy for presence detection."}
{"id": "2601.11110", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11110", "abs": "https://arxiv.org/abs/2601.11110", "authors": ["Marcus Henninger", "Lucas Giroto", "Ahmed Elkelesh", "Silvio Mandelli"], "title": "Hybrid Resource Allocation Scheme for Bistatic ISAC with Data Channels", "comment": "6 pages, 5 figures. This work has been submitted to the IEEE for possible publication", "summary": "Bistatic integrated sensing and communication (ISAC) enables efficient reuse of the existing cellular infrastructure and is likely to play an important role in future sensing networks. In this context, ISAC using the data channel is a promising approach to improve the bistatic sensing performance compared to relying solely on pilots. One of the challenges associated with this approach is resource allocation: the communication link aims to transmit higher modulation order (MO) symbols to maximize the throughput, whereas a lower MO is preferable for sensing to achieve a higher signal-to-noise ratio in the radar image. To address this conflict, this paper introduces a hybrid resource allocation scheme. By placing lower MO symbols as pseudo-pilots on a suitable sensing grid, we enhance the bistatic sensing performance while only slightly reducing the spectral efficiency of the communication link. Simulation results validate our approach against different baselines and provide practical insights into how decoding errors affect the sensing performance."}
{"id": "2601.11116", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2601.11116", "abs": "https://arxiv.org/abs/2601.11116", "authors": ["Yuki Nakamura", "Shingo Takemoto", "Shunsuke Ono"], "title": "Comprehensive Robust Dynamic Mode Decomposition from Mode Extraction to Dimensional Reduction", "comment": "Submitted to IEEE Transactions on Signal Processing. The source code is available at https://github.com/MDI-TokyoTech/Comprehensive-Robust-Dynamic-Mode-Decomposition. The project page is https://www.mdi.c.titech.ac.jp/publications/cr-dmd", "summary": "We propose Comprehensive Robust Dynamic Mode Decomposition (CR-DMD), a novel framework that robustifies the entire DMD process - from mode extraction to dimensional reduction - against mixed noise. Although standard DMD widely used for uncovering spatio-temporal patterns and constructing low-dimensional models of dynamical systems, it suffers from significant performance degradation under noise due to its reliance on least-squares estimation for computing the linear time evolution operator. Existing robust variants typically modify the least-squares formulation, but they remain unstable and fail to ensure faithful low-dimensional representations. First, we introduce a convex optimization-based preprocessing method designed to effectively remove mixed noise, achieving accurate and stable mode extraction. Second, we propose a new convex formulation for dimensional reduction that explicitly links the robustly extracted modes to the original noisy observations, constructing a faithful representation of the original data via a sparse weighted sum of the modes. Both stages are efficiently solved by a preconditioned primal-dual splitting method. Experiments on fluid dynamics datasets demonstrate that CR-DMD consistently outperforms state-of-the-art robust DMD methods in terms of mode accuracy and fidelity of low-dimensional representations under noisy conditions."}
{"id": "2601.11307", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11307", "abs": "https://arxiv.org/abs/2601.11307", "authors": ["Julia Schwarzbeck", "Robin Neuder", "Marc Späth", "Alejandro Jiménez-Sáez"], "title": "Scalable mm-Wave Liquid Crystal Reconfigurable Intelligent Surfaces based on the Delay Line Architecture", "comment": null, "summary": "This paper presents the design, fabrication, and characterization of broadband liquid crystal (LC) reconfigurable intelligent surfaces (RIS) operating around 60 GHz and scaling up to 750 radiating elements. The RISs employ a delay line architecture (DLA) that decouples the phase shifting and radiating layer, enabling wide bandwidth, continuous phase control exceeding 360°, and fast response times with a micrometer-thin LC layer of 4.6 micrometer. Two prototypes with 120 and 750 elements are realized using identical unit cells and column-wise biasing. Measurements demonstrate beam steering over +-60° and -3 dB bandwidths exceeding 9% for both apertures, confirming the scalability of the proposed architecture. On top of a measured nanowatt power consumption per unit cell, aperture efficiencies above 20% are predicted by simulations. While the measured efficiencies are reduced to 9.2% and 2.6%, a detailed analysis verifies that this reduction can be attributed to technological challenges in a laboratory environment. Finally, a comprehensive comparison between the applied DLA-based LC-RIS and a conventional approach highlights the superior potential of applied architecture."}
{"id": "2601.11351", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2601.11351", "abs": "https://arxiv.org/abs/2601.11351", "authors": ["Ruifeng Zheng", "Pengjie Zhou", "Pit Hofmann", "Martín Schottlender", "Fatima Rani", "Juan A. Cabrera", "Frank H. P. Fitzek"], "title": "Modulation, ISI, and Detection for Langmuir Adsorption-Based Microfluidic Molecular Communication", "comment": "5 pages", "summary": "This paper studies microfluidic molecular communication receivers with finite-capacity Langmuir adsorption driven by an effective surface concentration. In the reaction-limited regime, we derive a closed-form single-pulse response kernel and a symbol-rate recursion for on-off keying that explicitly exposes channel memory and inter-symbol interference. We further develop short-pulse and long-pulse approximations, revealing an interference asymmetry in the long-pulse regime due to saturation. To account for stochasticity, we adopt a finite-receptor binomial counting model, employ pulse-end sampling, and propose a low-complexity midpoint-threshold detector that reduces to a fixed threshold when interference is negligible. Numerical results corroborate the proposed characterization and quantify detection performance versus pulse and symbol durations."}
{"id": "2601.11438", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2601.11438", "abs": "https://arxiv.org/abs/2601.11438", "authors": ["Qiaosen Zhang", "Matteo Nerini", "Bruno Clerckx"], "title": "Channel Estimation in MIMO Systems Aided by Microwave Linear Analog Computers (MiLACs)", "comment": "Submitted to IEEE for publication", "summary": "Microwave linear analog computers (MiLACs) have recently emerged as a promising solution for future gigantic multiple-input multiple-output (MIMO) systems, enabling beamforming with greatly reduced hardware and computational cost. However, channel estimation for MiLAC-aided systems remains an open problem. Conventional least squares (LS) and minimum mean square error (MMSE) estimation rely on intensive digital computation, which undermines the benefits offered by MiLACs. In this letter, we propose efficient LS and MMSE channel estimation schemes for MiLAC-aided MIMO systems. By designing training precoders and combiners implemented by MiLACs, both LS and MMSE estimation are performed fully in the analog domain, achieving identical performance to their digital counterparts while significantly reducing computational complexity, transmit RF chains, analog-to-digital/digital-to-analog converters (ADCs/DACs) resolution requirements, and peak-to-average power ratio (PAPR). Numerical results verify the effectiveness and advantages of the proposed schemes."}

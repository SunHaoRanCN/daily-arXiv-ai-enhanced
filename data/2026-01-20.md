<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 22]
- [cs.SD](#cs.SD) [Total: 6]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Zonotope Shadow and Reflection Matching: A Novel GNSS Reflection-Based Framework for Enhanced Positioning Accuracy in Urban Areas](https://arxiv.org/abs/2601.10727)
*Sanghyun Kim,Jiwon Seo*

Main category: eess.SP

TL;DR: 提出ZSRM方法，结合阴影和反射匹配，改进城市GNSS定位精度


<details>
  <summary>Details</summary>
Motivation: 传统阴影匹配基于离散网格，精度受网格分辨率限制，难以满足用户指定的保护级别要求。现有ZSM方法仅使用GNSS阴影信息，无法充分缩小接收机位置集，定位精度有限。

Method: 提出ZSRM方法，不仅利用GNSS阴影信息（LOS/NLOS卫星区分），还结合反射匹配，通过集合估计而非网格估计来精确定位接收机位置。

Result: 现场测试显示，ZSRM相比ZSM的RMS水平位置误差改善10.0%-53.6%，跨街和沿街位置边界分别改善18.0%-50.1%和30.7%-59.3%。

Conclusion: ZSRM通过结合阴影和反射匹配，显著提高了城市环境中的GNSS定位精度，为满足保护级别要求提供了更可靠的解决方案。

Abstract: In urban areas, signal reception conditions are often poor due to reflections from buildings, resulting in inaccurate global navigation satellite system (GNSS)-based positioning. Various 3D-mapping-aided (3DMA) GNSS techniques, including shadow matching, have been proposed to address this issue. However, conventional shadow matching estimates positions in a discretized manner. The accuracy of this approach is limited by the resolution of the grid points representing the candidate receiver positions, making it difficult to achieve robust urban positioning and to ensure that the position estimate satisfies user-specified protection levels or safety bounds. To overcome these limitations, zonotope shadow matching (ZSM) has been proposed, which utilizes a set-based position estimate rather than grid-based estimates. ZSM calculates the GNSS shadow--an area on the ground where the line-of-sight (LOS) is blocked and only non-line-of-sight (NLOS) signals can be received--to estimate the receiver's position set. ZSM distinguishes between LOS and NLOS satellites, determining that the receiver is inside the GNSS shadow if the satellite is NLOS and outside if the satellite is LOS. However, relying solely on GNSS shadows limits the ability to sufficiently reduce the size of the receiver position set and to precisely estimate the receiver's location. To address this, we propose zonotope shadow and reflection matching (ZSRM) to enhance positioning accuracy in urban areas. The proposed ZSRM technique is validated through field tests using GNSS signals collected in an urban environment. Consequently, the RMS horizontal position error of ZSRM improved by 10.0% to 53.6% compared with ZSM, while the RMS cross-street and along-street position bounds improved by 18.0% to 50.1% and 30.7% to 59.3%, respectively.

</details>


### [2] [Millimeter-Wave Gesture Recognition in ISAC: Does Reducing Sensing Airtime Hamper Accuracy?](https://arxiv.org/abs/2601.10733)
*Jakob Struye,Nabeel Nisar Bhat,Siddhartha Kumar,Mohammad Hossein Moghaddam,Jeroen Famaey*

Main category: eess.SP

TL;DR: 毫米波ISAC系统中，即使将感知时间减少到25%，手势识别准确率仅下降0.15个百分点，证明毫米波ISAC在低感知时间下仍能保持高质量感知性能


<details>
  <summary>Details</summary>
Motivation: 现有ISAC系统需要在感知和通信之间分配时间资源，但这种分配决策对感知性能的具体影响尚不明确，需要深入研究

Method: 使用两个毫米波设备收集手势识别数据集，通过恒定波束扫描获取每对波束的功率数据，训练卷积神经网络分类器，然后通过下采样模拟减少感知时间的效果

Result: 实验显示，将感知时间减少到25%时，手势分类准确率仅从全时感知下降0.15个百分点，表明毫米波ISAC在低感知时间下仍能保持高质量感知

Conclusion: 毫米波ISAC系统能够在极低感知时间下实现高质量感知，同时保持高数据吞吐量，是无线扩展现实等应用的理想使能技术

Abstract: Most Integrated Sensing and Communications (ISAC) systems require dividing airtime across their two modes. However, the specific impact of this decision on sensing performance remains unclear and underexplored. In this paper, we therefore investigate the impact on a gesture recognition system using a Millimeter-Wave (mmWave) ISAC system. With our dataset of power per beam pair gathered with two mmWave devices performing constant beam sweeps while test subjects performed distinct gestures, we train a gesture classifier using Convolutional Neural Networks. We then subsample these measurements, emulating reduced sensing airtime, showing that a sensing airtime of 25 % only reduces classification accuracy by 0.15 percentage points from full-time sensing. Alongside this high-quality sensing at low airtime, mmWave systems are known to provide extremely high data throughputs, making mmWave ISAC a prime enabler for applications such as truly wireless Extended Reality.

</details>


### [3] [SSC-UNet: UNet with Self-Supervised Contrastive Learning for Phonocardiography Noise Reduction](https://arxiv.org/abs/2601.10735)
*Lizy Abraham,Siobhan Coughlan,Kritika Rajain,Changhong Li,Saji Philip,Adam James*

Main category: eess.SP

TL;DR: 提出基于Noise2Noise的自监督心音图降噪模型，无需干净数据训练，在10dB医院噪声下平均SNR达12.98dB，分类灵敏度从27%提升至88%


<details>
  <summary>Details</summary>
Motivation: 先天性心脏病(CHD)影响全球约1%的新生儿，心音图作为经济有效的辅助诊断工具，但其诊断模型性能高度依赖心音图质量。现有监督UNet需要干净数据训练，而干净数据有限；心音图复杂的时频特性使得在有效去噪和保留病理特征之间难以平衡

Method: 提出基于Noise2Noise的自监督心音图降噪模型，无需干净数据训练。采用数据增强和对比学习提升性能，在10dB医院噪声环境下进行测试

Result: 在10dB医院噪声下，滤波后平均信噪比(SNR)达到12.98dB。分类灵敏度从27%大幅提升至88%，表明模型在实际噪声环境中具有良好的病理特征保留能力

Conclusion: 提出的自监督降噪模型有效解决了心音图去噪中干净数据有限的问题，在保持病理特征的同时显著提升噪声抑制能力，为先天性心脏病的心音图诊断提供了实用工具

Abstract: Congenital Heart Disease (CHD) remains a significant global health concern affecting approximately 1\% of births worldwide. Phonocardiography has emerged as a supplementary tool to diagnose CHD cost-effectively. However, the performance of these diagnostic models highly depends on the quality of the phonocardiography, thus, noise reduction is particularly critical. Supervised UNet effectively improves noise reduction capabilities, but limited clean data hinders its application. The complex time-frequency characteristics of phonocardiography further complicate finding the balance between effectively removing noise and preserving pathological features. In this study, we proposed a self-supervised phonocardiography noise reduction model based on Noise2Noise to enable training without clean data. Augmentation and contrastive learning are applied to enhance its performance. We obtained an average SNR of 12.98 dB after filtering under 10~dB of hospital noise. Classification sensitivity after filtering was improved from 27\% to 88\%, indicating its promising pathological feature retention capabilities in practical noisy environments.

</details>


### [4] [Differentiating through binarized topology changes: Second-order subpixel-smoothed projection](https://arxiv.org/abs/2601.10737)
*Giuseppe Romano,Rodrigo Arrieta,Steven G. Johnson*

Main category: eess.SP

TL;DR: 提出SSP2方法，通过Hessian正则化改进SSP投影，确保拓扑变化时的二阶可微性，提升梯度优化算法的收敛性。


<details>
  <summary>Details</summary>
Motivation: 传统拓扑优化中可制造的二值结构具有不可微性，与梯度优化存在根本矛盾。SSP方法虽然通过亚像素平滑解决了界面平滑问题，但在拓扑变化（如界面合并）时无法保证可微性，违反了许多梯度优化算法的收敛保证。

Method: 提出二阶SSP（SSP2）方法，通过对滤波场的Hessian进行正则化，在拓扑变化期间获得二阶可微的投影密度，同时保证几乎处处二值结构。该方法相对于SSP或传统投影方案只增加最小复杂度。

Result: 在热学和光子学问题上验证了SSP2的有效性。对于连接主导（频繁拓扑变化）的情况，SSP2比SSP收敛更快；在其他情况下性能相当。SSP2不仅改进了CCSA优化器的收敛保证，还支持更广泛的优化算法（如内点法）。

Conclusion: SSP2方法解决了拓扑优化中二值结构与梯度优化的根本矛盾，通过二阶可微性保证了优化算法的收敛性，可作为现有拓扑优化代码的直接替代方案，扩展了可用优化算法的范围。

Abstract: A key challenge in topology optimization (TopOpt) is that manufacturable structures, being inherently binary, are non-differentiable, creating a fundamental tension with gradient-based optimization. The subpixel-smoothed projection (SSP) method addresses this issue by smoothing sharp interfaces at the subpixel level through a first-order expansion of the filtered field. However, SSP does not guarantee differentiability under topology changes, such as the merging of two interfaces, and therefore violates the convergence guarantees of many popular gradient-based optimization algorithms. We overcome this limitation by regularizing SSP with the Hessian of the filtered field, resulting in a twice-differentiable projected density during such transitions, while still guaranteeing an almost-everywhere binary structure. We demonstrate the effectiveness of our second-order SSP (SSP2) methodology on both thermal and photonic problems, showing that SSP2 has faster convergence than SSP for connectivity-dominant cases -- where frequent topology changes occur -- while exhibiting comparable performance otherwise. Beyond improving convergence guarantees for CCSA optimizers, SSP2 enables the use of a broader class of optimization algorithms with stronger theoretical guarantees, such as interior-point methods. Since SSP2 adds minimal complexity relative to SSP or traditional projection schemes, it can be used as a drop-in replacement in existing TopOpt codes.

</details>


### [5] [UBiGTLoc: A Unified BiLSTM-Graph Transformer Localization Framework for IoT Sensor Networks](https://arxiv.org/abs/2601.10743)
*Ayesh Abu Lehyeh,Anastassia Gharib,Tian Xia,Dryver Huston,Safwan Wshah*

Main category: eess.SP

TL;DR: 提出UBiGTLoc框架，使用双向LSTM和Graph Transformer结合，在有无锚节点的无线传感器网络中实现鲁棒定位，仅需低成本RSSI数据。


<details>
  <summary>Details</summary>
Motivation: 现有传感器节点定位方法严重依赖锚节点，但在实际IoT场景中锚节点可能不可行；同时RSSI波动（尤其在NLOS条件下）会影响定位精度。

Method: 提出统一的双向LSTM-Graph Transformer定位框架：使用BiLSTM捕捉RSSI数据的时间变化，Graph Transformer层建模传感器节点间的空间关系。

Result: 广泛仿真表明UBiGTLoc始终优于现有方法，在密集和稀疏WSN中都能提供鲁棒定位，仅依赖成本效益高的RSSI数据。

Conclusion: UBiGTLoc框架解决了锚节点依赖和RSSI波动问题，为智能城市、智能农业等应用提供了有效的传感器节点定位解决方案。

Abstract: Sensor nodes localization in wireless Internet of Things (IoT) sensor networks is crucial for the effective operation of diverse applications, such as smart cities and smart agriculture. Existing sensor nodes localization approaches heavily rely on anchor nodes within wireless sensor networks (WSNs). Anchor nodes are sensor nodes equipped with global positioning system (GPS) receivers and thus, have known locations. These anchor nodes operate as references to localize other sensor nodes. However, the presence of anchor nodes may not always be feasible in real-world IoT scenarios. Additionally, localization accuracy can be compromised by fluctuations in Received Signal Strength Indicator (RSSI), particularly under non-line-of-sight (NLOS) conditions. To address these challenges, we propose UBiGTLoc, a Unified Bidirectional Long Short-Term Memory (BiLSTM)-Graph Transformer Localization framework. The proposed UBiGTLoc framework effectively localizes sensor nodes in both anchor-free and anchor-presence WSNs. The framework leverages BiLSTM networks to capture temporal variations in RSSI data and employs Graph Transformer layers to model spatial relationships between sensor nodes. Extensive simulations demonstrate that UBiGTLoc consistently outperforms existing methods and provides robust localization across both dense and sparse WSNs while relying solely on cost-effective RSSI data.

</details>


### [6] [An IoT-Based Controlled Environment Storage for Prevention of Spoilage of Onion (Allium Cepa) During Post-Harvest with UV-C Disinfection](https://arxiv.org/abs/2601.10745)
*Shivam Kumar,Himanshu Singh*

Main category: eess.SP

TL;DR: 印度洋葱储存损失严重（30-40%），传统方法要么效果差要么成本高。本文提出基于物联网的低成本智能洋葱储存系统，通过传感器监测和自动调节环境参数，结合UV-C消毒技术，旨在将损耗率从40-45%降至15-20%，同时保持低成本（6-7万卢比）适合小农户。


<details>
  <summary>Details</summary>
Motivation: 印度作为全球第二大洋葱生产国，年产量超过2600万吨，但在储存过程中有30-40%的洋葱因腐烂、发芽和失重而损失。传统储存方法存在两难：低成本的传统储存效果差（40%损耗），而高效的冷储存对小农户来说成本过高。大多数印度农民是小农户和边缘农户，无法负担昂贵的储存设施。

Method: 开发基于物联网的低成本智能洋葱储存系统，使用ESP32微控制器、DHT22温湿度传感器、MQ-135气体传感器监测环境参数（温度、湿度、腐败气体）。系统自动调节环境条件，并采用UV-C消毒技术控制微生物生长。设计为太阳能供电，成本控制在6-7万卢比，具有能源高效、农民友好的特点。

Result: 提出的系统旨在将洋葱储存损耗率从当前的40-45%降低到15-20%。系统设计成本为6-7万卢比，相比昂贵的冷储存更加经济实惠，适合印度大多数小农户和边缘农户使用。系统还具有能源高效、太阳能供电的特点。

Conclusion: 该物联网智能洋葱储存系统为解决印度洋葱储存损失问题提供了可行的解决方案，在保持低成本的同时显著提高储存效果，特别适合资源有限的小农户，有助于减少粮食浪费并提高农民收入。

Abstract: India is the second largest producer of onions in the world, contributing over 26 million tonnes annually. However, during storage, approximately 30-40% of onions are lost due to rotting, sprouting, and weight loss. Despite being a major producer, conventional storage methods are either low-cost but ineffective (traditional storage with 40% spoilage) or highly effective but prohibitively expensive for small farmers (cold storage). This paper presents a low-cost IoT-based smart onion storage system that monitors and automatically regulates environmental parameters including temperature, humidity, and spoilage gases using ESP32 microcontroller, DHT22 sensor, MQ-135 gas sensor, and UV-C disinfection technology. The proposed system aims to reduce onion spoilage to 15-20% from the current 40-45% wastage rate while remaining affordable for small and marginal farmers who constitute the majority in India. The system is designed to be cost-effective (estimated 60k-70k INR), energy-efficient, farmer-friendly, and solar-powered.

</details>


### [7] [On the static and small signal analysis of DAB converter](https://arxiv.org/abs/2601.10746)
*Yuxin Yang,Hang Zhou,Hourong Song,Branislav Hredzak*

Main category: eess.SP

TL;DR: 提出了一种求解双有源桥变换器周期性工作点的方法


<details>
  <summary>Details</summary>
Motivation: 双有源桥变换器在电力电子应用中需要准确计算周期性工作点，传统方法存在计算复杂或精度不足的问题

Method: 开发了一种系统性的数学方法，通过建立变换器的动态方程并求解周期性边界条件来确定工作点

Result: 该方法能够准确高效地计算DAB变换器的周期性工作点，为设计和控制提供可靠依据

Conclusion: 提出的方法为双有源桥变换器的周期性工作点分析提供了有效的解决方案，具有实际工程应用价值

Abstract: This document develops a method to solve the periodic operating point of Dual-Active-Bridge (DAB).

</details>


### [8] [Sensor Placement for Urban Traffic Interpolation: A Data-Driven Evaluation to Inform Policy](https://arxiv.org/abs/2601.10747)
*Silke K. Kaiser*

Main category: eess.SP

TL;DR: 该研究比较了多种数据驱动的交通传感器布设策略，发现强调均匀空间覆盖和主动学习的策略能显著降低预测误差，临时传感器通过优化时空部署可接近永久传感器的性能。


<details>
  <summary>Details</summary>
Motivation: 城市街道交通流量数据对城市规划至关重要，但现有传感器布设通常基于行政优先级而非数据优化，导致覆盖偏差和估计性能下降。需要评估数据驱动的传感器布设策略以改善数据质量。

Method: 使用柏林（Strava自行车计数）和曼哈顿（出租车计数）的街道段级数据进行大规模实证基准测试，比较基于网络中心性、空间覆盖、特征覆盖和主动学习的空间布设策略，并研究临时传感器的时间部署方案。

Result: 强调均匀空间覆盖和采用主动学习的空间布设策略预测误差最低：仅用10个传感器，在柏林和曼哈顿分别比替代方案降低MAE超过60%和70%。时间部署优化（均匀分布工作日测量）进一步降低误差7%（柏林）和21%（曼哈顿）。

Conclusion: 城市可通过采用数据驱动的传感器布设策略显著提高数据实用性，同时在临时和永久部署之间保持灵活性。优化的临时部署可接近最优永久部署的性能。

Abstract: Data on citywide street-segment traffic volumes are essential for urban planning and sustainable mobility management. Yet such data are available only for a limited subset of streets due to the high costs of sensor deployment and maintenance. Traffic volumes on the remaining network are therefore interpolated based on existing sensor measurements. However, current sensor locations are often determined by administrative priorities rather than by data-driven optimization, leading to biased coverage and reduced estimation performance. This study provides a large-scale, real-world benchmarking of easily implementable, data-driven strategies for optimizing the placement of permanent and temporary traffic sensors, using segment-level data from Berlin (Strava bicycle counts) and Manhattan (taxi counts). It compares spatial placement strategies based on network centrality, spatial coverage, feature coverage, and active learning. In addition, the study examines temporal deployment schemes for temporary sensors. The findings highlight that spatial placement strategies that emphasize even spatial coverage and employ active learning achieve the lowest prediction errors. With only 10 sensors, they reduce the mean absolute error by over 60% in Berlin and 70% in Manhattan compared to alternatives. Temporal deployment choices further improve performance: distributing measurements evenly across weekdays reduces error by an additional 7% in Berlin and 21% in Manhattan. Together, these spatial and temporal principles allow temporary deployments to closely approximate the performance of optimally placed permanent deployments. From a policy perspective, the results indicate that cities can substantially improve data usefulness by adopting data-driven sensor placement strategies, while retaining flexibility in choosing between temporary and permanent deployments.

</details>


### [9] [AnyECG: Evolved ECG Foundation Model for Holistic Health Profiling](https://arxiv.org/abs/2601.10748)
*Jun Li,Hongling Zhu,Yujie Xiao,Qinghao Zhao,Yalei Ke,Gongzheng Tang,Guangkun Nie,Deyun Zhang,Jin Li,Canqing Yu,Shenda Hong*

Main category: eess.SP

TL;DR: AnyECG是一个基于1300万份心电图的AI基础模型，能够同时检测1172种疾病，预测未来风险，并识别共病模式，展示了AI-ECG作为系统性健康评估工具的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有AI-ECG模型大多专注于单一疾病识别，忽视了共病情况和未来风险预测。虽然ECGFounder扩展了心脏疾病覆盖范围，但仍需要一个全面的健康分析模型来提供系统性健康评估。

Method: 使用包含298万患者的1330万份心电图构建大型多中心数据集，通过迁移学习对ECGFounder进行微调，开发出AnyECG基础模型。使用外部验证队列和10年纵向队列评估模型在当前诊断、未来风险预测和共病识别方面的性能。

Result: AnyECG在1172种疾病中展现出系统性预测能力，其中306种疾病的AUROC超过0.7。模型揭示了新的疾病关联、稳健的共病模式和未来疾病风险。代表性示例包括：甲状旁腺功能亢进症(AUROC 0.941)、2型糖尿病(0.803)、克罗恩病(0.817)、淋巴细胞白血病(0.856)和慢性阻塞性肺疾病(0.773)。

Conclusion: AnyECG基础模型提供了有力证据，表明AI-ECG可以作为同时进行疾病检测和长期风险预测的系统性工具，为全面健康分析开辟了新途径。

Abstract: Background: Artificial intelligence enabled electrocardiography (AI-ECG) has demonstrated the ability to detect diverse pathologies, but most existing models focus on single disease identification, neglecting comorbidities and future risk prediction. Although ECGFounder expanded cardiac disease coverage, a holistic health profiling model remains needed.
  Methods: We constructed a large multicenter dataset comprising 13.3 million ECGs from 2.98 million patients. Using transfer learning, ECGFounder was fine-tuned to develop AnyECG, a foundation model for holistic health profiling. Performance was evaluated using external validation cohorts and a 10-year longitudinal cohort for current diagnosis, future risk prediction, and comorbidity identification.
  Results: AnyECG demonstrated systemic predictive capability across 1172 conditions, achieving an AUROC greater than 0.7 for 306 diseases. The model revealed novel disease associations, robust comorbidity patterns, and future disease risks. Representative examples included high diagnostic performance for hyperparathyroidism (AUROC 0.941), type 2 diabetes (0.803), Crohn disease (0.817), lymphoid leukemia (0.856), and chronic obstructive pulmonary disease (0.773).
  Conclusion: The AnyECG foundation model provides substantial evidence that AI-ECG can serve as a systemic tool for concurrent disease detection and long-term risk prediction.

</details>


### [10] [LSR-Net: A Lightweight and Strong Robustness Network for Bearing Fault Diagnosis in Noise Environment](https://arxiv.org/abs/2601.10761)
*Junseok Lee,Jihye Shin,Sangyong Lee,Chang-Jae Chun*

Main category: eess.SP

TL;DR: 提出LSR-Net轻量鲁棒网络，用于轴承故障诊断，在噪声环境下保持高精度并实现实时诊断


<details>
  <summary>Details</summary>
Motivation: 旋转轴承在现代工业中至关重要，但因其高速、高负荷和恶劣运行环境而故障率高。故障诊断延迟可能导致经济损失和人员伤亡，且振动信号易受环境和噪声影响，因此需要在噪声环境下实现准确诊断。

Method: 1. 设计去噪和特征增强模块(DFEM)：通过基于卷积的去噪(CD)块处理特征图，施加非线性变换生成3通道2D矩阵；采用自适应剪枝增强强噪声下的去噪能力。2. 设计基于卷积的效率洗牌(CES)块：使用组卷积(GConv)、组逐点卷积(GPConv)和通道分割来保持低参数量；通过注意力机制和通道洗牌平衡精度与计算复杂度。

Result: 在噪声环境下使用振动信号验证，所提模型相比基准模型具有最佳的抗噪声能力，同时模型计算复杂度最低。

Conclusion: LSR-Net在噪声环境下实现了高精度的轴承故障诊断，同时保持了轻量化和实时性，为工业应用提供了有效的解决方案。

Abstract: Rotating bearings play an important role in modern industries, but have a high probability of occurrence of defects because they operate at high speed, high load, and poor operating environments. Therefore, if a delay time occurs when a bearing is diagnosed with a defect, this may cause economic loss and loss of life. Moreover, since the vibration sensor from which the signal is collected is highly affected by the operating environment and surrounding noise, accurate defect diagnosis in a noisy environment is also important. In this paper, we propose a lightweight and strong robustness network (LSR-Net) that is accurate in a noisy environment and enables real-time fault diagnosis. To this end, first, a denoising and feature enhancement module (DFEM) was designed to create a 3-channel 2D matrix by giving several nonlinearity to the feature-map that passed through the denoising module (DM) block composed of convolution-based denoising (CD) blocks. Moreover, adaptive pruning was applied to DM to improve denoising ability when the power of noise is strong. Second, for lightweight model design, a convolution-based efficiency shuffle (CES) block was designed using group convolution (GConv), group pointwise convolution (GPConv) and channel split that can design the model while maintaining low parameters. In addition, the trade-off between the accuracy and model computational complexity that can occur due to the lightweight design of the model was supplemented using attention mechanisms and channel shuffle. In order to verify the defect diagnosis performance of the proposed model, performance verification was conducted in a noisy environment using a vibration signal. As a result, it was confirmed that the proposed model had the best anti-noise ability compared to the benchmark models, and the computational complexity of the model was also the lowest.

</details>


### [11] [Physically constrained unfolded multi-dimensional OMP for large MIMO systems](https://arxiv.org/abs/2601.10771)
*Nay Klaimi,Clément Elvira,Philippe Mary,Luc Le Magoarou*

Main category: eess.SP

TL;DR: MOMPnet是一个基于深度展开的稀疏恢复框架，通过多字典学习和低复杂度多维OMP算法，解决了传统方法在大型MIMO系统中模型不准确和计算复杂度过高的问题。


<details>
  <summary>Details</summary>
Motivation: 传统稀疏恢复方法在现代通信系统中存在两个主要问题：1）依赖准确的物理模型，但实际中模型很少完美；2）在大型MIMO系统中，字典维度增大导致计算复杂度急剧增加。

Method: 提出MOMPnet框架，结合深度展开和数据驱动的字典学习。使用多个独立的小字典替代单个大字典，实现低复杂度的多维正交匹配追踪算法，同时保持可解释性。

Result: 在真实信道数据上评估，MOMPnet相比多个基线方法表现出强大的性能，验证了其有效性和潜力。

Conclusion: MOMPnet通过深度展开和多字典学习，有效解决了传统稀疏恢复方法的可靠性和复杂度挑战，为大规模MIMO系统中的信道估计和定位提供了有前景的解决方案。

Abstract: Sparse recovery methods are essential for channel estimation and localization in modern communication systems, but their reliability relies on accurate physical models, which are rarely perfectly known. Their computational complexity also grows rapidly with the dictionary dimensions in large MIMO systems. In this paper, we propose MOMPnet, a novel unfolded sparse recovery framework that addresses both the reliability and complexity challenges of traditional methods. By integrating deep unfolding with data-driven dictionary learning, MOMPnet mitigates hardware impairments while preserving interpretability. Instead of a single large dictionary, multiple smaller, independent dictionaries are employed, enabling a low-complexity multidimensional Orthogonal Matching Pursuit algorithm. The proposed unfolded network is evaluated on realistic channel data against multiple baselines, demonstrating its strong performance and potential.

</details>


### [12] [Adaptive algorithm for microsensor in sustainable environmental monitoring](https://arxiv.org/abs/2601.10780)
*Nursultan Daupayev,Christian Engel,Ricky Bendyk,Soeren Hirsch*

Main category: eess.SP

TL;DR: 提出基于傅里叶变换的数据采集处理算法，通过谐波分析提取主导频率成分，实现传感器仅在事件发生时激活，减少功耗和存储需求


<details>
  <summary>Details</summary>
Motivation: 传统传感器数据采集产生大量数据，导致持续功耗和存储空间需求增加，需要更高效的数据采集方法

Method: 基于傅里叶变换(DFT)的数据采集处理算法，利用谐波分析提取主导频率成分，识别频率峰值，实现事件触发式传感器激活

Result: 算法能在事件发生时激活传感器，同时保留检测缺陷所需的关键信息（如建筑物表面结构缺陷），确保预测准确性

Conclusion: 该算法有效解决了传统传感器数据采集的功耗和存储问题，通过智能事件触发机制实现高效数据采集，适用于结构健康监测等应用

Abstract: Traditional data collection from sensors produce a lot of data, which lead to constant power consumption and require more storage space. This study proposes an algorithm for a data acquisition and processing method based on Fourier transform (DFT), which extracts dominant frequency components using harmonic analysis (HA) to identify frequency peaks. This algorithm allows sensors to activate only when an event occurs, while preserving critical information for detecting defects, such as those in the surface structures of buildings and ensuring accuracy for further predictions.

</details>


### [13] [RIS-aided Radar Detection Architectures with Application to Low-RCS Targets](https://arxiv.org/abs/2601.10846)
*Fabiola Colone,Filippo Costa,Yiding Gao,Chengpeng Hao,Linjie Yan,Giuliano Manara,Danilo Orlando*

Main category: eess.SP

TL;DR: 利用可重构智能表面辅助雷达检测低可观测目标，通过联合处理单站和双站回波信号提升检测性能


<details>
  <summary>Details</summary>
Motivation: 传统多基地雷达网络用于反隐身存在同步、成本、相位相干性和能耗等问题，需要更有效的低可观测目标检测方案

Method: 使用RIS形成联合单站和双站配置，截获目标在非视线方向的后向散射能量并重定向给雷达，设计了五种具有恒虚警率特性的联合处理检测架构

Result: 与传统检测器相比，所提策略能有效检测低可观测目标，并提供了满足应用需求的RIS设计指南

Conclusion: 利用RIS辅助的雷达检测策略为解决低可观测目标检测问题提供了有效方案，克服了传统多基地雷达网络的局限性

Abstract: In this paper, we address the radar detection of low observable targets with the assistance of a reconfigurable intelligent surface (RIS). Instead of using a multistatic radar network as counter-stealth strategy with its synchronization, costs, phase coherence, and energy consumption issues, we exploit a RIS to form a joint monostatic and bistatic configuration that can intercept the energy backscattered by the target along irrelevant directions different from the line-of-sight of the radar. Then, this energy is redirected towards the radar that capitalizes all the backscattered energy to detect the low observable target. To this end, five different detection architectures are devised that jointly process monostatic and bistatic echoes and exhibit the constant false alarm rate property at least with respect to the clutter power. To support the practical implementation, we also provide a guideline for the design of a RIS that satisfies the operating requirements of the considered application. The performance analysis is carried out in comparison with conventional detectors and shows that the proposed strategy leads to effective solutions to the detection of low observable targets.

</details>


### [14] [Large Wireless Foundation Models: Stronger over Bigger](https://arxiv.org/abs/2601.10963)
*Xiang Cheng,Boxun Liu,Xuanyu Liu,Xuesong Cai*

Main category: eess.SP

TL;DR: 该论文提出大型无线基础模型（LWMFs）概念，为6G物理层提供基于基础模型的框架，解决现有AI通信模型泛化性差的问题，并提出两种实现范式。


<details>
  <summary>Details</summary>
Motivation: 现有基于AI的物理层设计采用任务特定模型，泛化能力差，而通信系统本质是通用系统，需要支持多样化场景的广泛适用性和鲁棒性。基础模型具有强大的推理和泛化能力，但无线系统约束阻碍了大型语言模型（LLMs）的成功直接迁移到无线领域。

Method: 提出大型无线基础模型（LWFMs）概念，并构建在无线约束下赋能物理层的基础模型框架。提出两种实现范式：1）利用现有通用基础模型；2）构建新型无线基础模型。为每种范式制定路线图，并在无线约束下制定设计原则。

Result: 通过案例研究直观验证LWFM赋能无线系统的优势，通过多维分析现有工作来界定LWFMs中的"大型"概念，并为未来研究指明方向。

Conclusion: 大型无线基础模型（LWFMs）为解决AI通信集成中的泛化问题提供了有前景的解决方案，通过两种实现范式和设计原则，为6G物理层的基础模型应用奠定了基础。

Abstract: AI-communication integration is widely regarded as a core enabling technology for 6G. Most existing AI-based physical-layer designs rely on task-specific models that are separately tailored to individual modules, resulting in poor generalization. In contrast, communication systems are inherently general-purpose and should support broad applicability and robustness across diverse scenarios. Foundation models offer a promising solution through strong reasoning and generalization, yet wireless-system constraints hinder a direct transfer of large language model (LLM)-style success to the wireless domain. Therefore, we introduce the concept of large wireless foundation models (LWFMs) and present a novel framework for empowering the physical layer with foundation models under wireless constraints. Specifically, we propose two paradigms for realizing LWFMs, including leveraging existing general-purpose foundation models and building novel wireless foundation models. Based on recent progress, we distill two roadmaps for each paradigm and formulate design principles under wireless constraints. We further provide case studies of LWFM-empowered wireless systems to intuitively validate their advantages. Finally, we characterize the notion of "large" in LWFMs through a multidimensional analysis of existing work and outline promising directions for future research.

</details>


### [15] [DuTrack: Long-Term Indoor Human Tracking with Dual-Channel Sensing and Inference](https://arxiv.org/abs/2601.10972)
*Mengning Li,Wenye Wang*

Main category: eess.SP

TL;DR: DuTrack是一个融合Wi-Fi和声学传感的多模态人体追踪系统，通过声学信号校正Wi-Fi累积误差，实现稳定长时追踪


<details>
  <summary>Details</summary>
Motivation: 现有Wi-Fi追踪方法依赖速度特征，存在累积误差问题，难以实现长时间稳定追踪。需要一种能校正累积误差的稳定追踪方案

Method: 提出融合Wi-Fi和声学传感的多模态追踪系统。Wi-Fi在视距和非视距场景分别建模为椭圆菲涅尔区和双曲线区，声学传感区建模为双曲线簇。建立电磁波和机械波融合的优化方程，设计数据驱动架构求解

Result: 实验结果显示，相比基于模型的方法，中位追踪误差减少89.37%；相比数据驱动方法，中位追踪误差减少65.02%。多模态追踪方案表现出优越性能

Conclusion: DuTrack通过融合Wi-Fi和声学传感，有效解决了Wi-Fi追踪的累积误差问题，实现了稳定的人体追踪，为智能家居和家庭护理应用提供了可靠解决方案

Abstract: Wi-Fi tracking technology demonstrates promising potential for future smart home and intelligent family care. Currently, accurate Wi-Fi tracking methods rely primarily on fine-grained velocity features. However, such velocity-based approaches suffer from the problem of accumulative errors, making it challenging to stably track users' trajectories over a long period of time. This paper presents DuTrack, a fusion-based tracking system for stable human tracking. The fundamental idea is to leverage the ubiquitous acoustic signals in households to rectify the accumulative Wi-Fi tracking error. Theoretically, Wi-Fi sensing in line-of-sight (LoS) and non-line-of-sight (NLoS) scenarios can be modeled as elliptical Fresnel zones and hyperbolic zones, respectively. By designing acoustic sensing signals, we are able to model the acoustic sensing zones as a series of hyperbolic clusters. We reveal how to fuse the fields of electromagnetic waves and mechanical waves, and establish the optimization equation. Next, we design a data-driven architecture to solve the aforementioned optimization equation. Experimental results show that the proposed multimodal tracking scheme exhibits superior performance. We achieve a 89.37% reduction in median tracking error compared to model-based methods and a 65.02% reduction compared to data-driven methods.

</details>


### [16] [Delay-Aware Task Offloading for Heterogeneous VLC-RF-based Vehicular Fog Computing](https://arxiv.org/abs/2601.10978)
*Nan An,Hongyi He,Fang Yang,Chang Liu,Jian Song,Zhu Han,Binbin Zhu*

Main category: eess.SP

TL;DR: 论文提出了一种基于异构可见光通信-射频架构的车载雾计算系统，通过动态任务分割和双链路卸载，相比单一通信方式平均任务处理延迟降低15%


<details>
  <summary>Details</summary>
Motivation: 传统车载雾计算依赖射频通信，在密集车辆环境中适应性受限。需要利用可见光通信的抗干扰特性和射频的覆盖优势，构建更高效的任务卸载架构

Method: 设计异构VLC-RF架构，将计算任务动态分割并通过VLC和RF链路卸载到空闲车辆。提出基于残差的主化最小化算法优化任务卸载和计算资源分配，最小化平均任务处理延迟

Result: 仿真结果表明，所提异构VLC-RF架构结合RBMM算法，相比仅使用VLC或RF的车载雾计算系统，平均任务处理延迟降低15%

Conclusion: 异构VLC-RF架构能有效结合两种通信技术的优势，显著提升车载雾计算系统的任务处理效率，为下一代交通网络中的延迟敏感服务提供支持

Abstract: Vehicular fog computing (VFC) is a promising paradigm for reducing the computation burden of vehicles, thus supporting delay-sensitive services in next-generation transportation networks. However, traditional VFC schemes rely on radio frequency (RF) communications, which limits their adaptability for dense vehicular environments. In this paper, a heterogeneous visible light communication (VLC)-RF architecture is designed for VFC systems to facilitate efficient task offloading. Specifically, computing tasks are dynamically partitioned and offloaded to idle vehicles via both VLC and RF links, thereby fully exploiting the interference resilience of VLC and the coverage advantage of RF. To minimize the average task processing delay (TPD), an optimization problem of task offloading and computing resource allocation is formulated, and then solved by the developed residual-based majorization-minimization (RBMM) algorithm. Simulation results confirm that the heterogeneous VLC-RF architecture with the proposed algorithm achieves a 15% average TPD reduction compared to VFC systems relying solely on VLC or RF.

</details>


### [17] [Uni-Fi: Integrated Multi-Task Wi-Fi Sensing](https://arxiv.org/abs/2601.10980)
*Mengning Li,Wenye Wang*

Main category: eess.SP

TL;DR: Uni-Fi是一个可扩展的多任务Wi-Fi感知框架，通过统一架构和可扩展流水线解决不同感知任务集成问题，显著提升定位、活动分类和存在检测性能。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi感知技术可实现非侵入式连续监测，但不同感知任务集成面临两大挑战：缺乏统一架构捕捉任务间共性，以及缺乏可扩展流水线集成未来研究方法。

Method: 提出Uni-Fi框架：1）统一理论框架揭示单任务与多任务感知的根本差异；2）可扩展感知流水线自动生成多任务感知求解器，实现多个感知模型的无缝集成。

Result: 实验结果显示Uni-Fi在各任务上表现稳健：定位误差约0.54米，活动分类准确率98.34%，存在检测准确率98.57%。

Conclusion: Uni-Fi成功解决了多任务Wi-Fi感知集成问题，通过统一框架和可扩展流水线实现了高性能的多任务感知系统，为智能家居应用提供了有效解决方案。

Abstract: Wi-Fi sensing technology enables non-intrusive, continuous monitoring of user locations and activities, which supports diverse smart home applications. Since different sensing tasks exhibit contextual relationships, their integration can enhance individual module performance. However, integrating sensing tasks across different research efforts faces challenges due to the absence of two key elements. The first is a unified architecture that captures the fundamental nature shared across diverse sensing tasks. The second is an extensible pipeline that can integrate sensing methodologies proposed in potential future research. This paper presents Uni-Fi, an extensible framework for multi-task Wi-Fi sensing integration. This paper makes the following contributions. First, we propose a unified theoretical framework that reveals the fundamental differences between single-task and multi-task sensing. Second, we develop a scalable sensing pipeline that automatically generates multi-task sensing solvers, enabling seamless integration of multiple sensing models. Experimental results show that Uni-Fi achieves robust performance across tasks, with a localization error of approximately 0.54 meters, 98.34 percent accuracy for activity classification, and 98.57 percent accuracy for presence detection.

</details>


### [18] [Hybrid Resource Allocation Scheme for Bistatic ISAC with Data Channels](https://arxiv.org/abs/2601.11110)
*Marcus Henninger,Lucas Giroto,Ahmed Elkelesh,Silvio Mandelli*

Main category: eess.SP

TL;DR: 提出一种混合资源分配方案，通过在合适的感知网格上放置低调制阶数的伪导频符号，在略微降低通信链路频谱效率的同时，显著提升双基地感知性能。


<details>
  <summary>Details</summary>
Motivation: 双基地集成感知与通信（ISAC）能有效复用现有蜂窝基础设施，在数据信道上使用ISAC相比仅依赖导频能提升感知性能。但存在资源分配冲突：通信链路希望传输高调制阶数符号以最大化吞吐量，而感知则偏好低调制阶数以在雷达图像中获得更高信噪比。

Method: 引入混合资源分配方案，通过在合适的感知网格上放置低调制阶数符号作为伪导频，在略微降低通信链路频谱效率的同时，增强双基地感知性能。

Result: 仿真结果验证了该方法相对于不同基线的有效性，并提供了关于解码错误如何影响感知性能的实际见解。

Conclusion: 该混合资源分配方案能有效解决ISAC中通信与感知的资源分配冲突，在保证通信性能的同时显著提升感知能力，为未来感知网络提供了实用解决方案。

Abstract: Bistatic integrated sensing and communication (ISAC) enables efficient reuse of the existing cellular infrastructure and is likely to play an important role in future sensing networks. In this context, ISAC using the data channel is a promising approach to improve the bistatic sensing performance compared to relying solely on pilots. One of the challenges associated with this approach is resource allocation: the communication link aims to transmit higher modulation order (MO) symbols to maximize the throughput, whereas a lower MO is preferable for sensing to achieve a higher signal-to-noise ratio in the radar image. To address this conflict, this paper introduces a hybrid resource allocation scheme. By placing lower MO symbols as pseudo-pilots on a suitable sensing grid, we enhance the bistatic sensing performance while only slightly reducing the spectral efficiency of the communication link. Simulation results validate our approach against different baselines and provide practical insights into how decoding errors affect the sensing performance.

</details>


### [19] [Comprehensive Robust Dynamic Mode Decomposition from Mode Extraction to Dimensional Reduction](https://arxiv.org/abs/2601.11116)
*Yuki Nakamura,Shingo Takemoto,Shunsuke Ono*

Main category: eess.SP

TL;DR: 提出CR-DMD框架，通过凸优化预处理去除混合噪声实现稳定模式提取，并构建新的凸优化降维方法，在噪声条件下优于现有鲁棒DMD方法。


<details>
  <summary>Details</summary>
Motivation: 标准DMD依赖最小二乘估计计算线性时间演化算子，在噪声条件下性能显著下降。现有鲁棒变体通常修改最小二乘公式，但仍不稳定且无法保证低维表示的真实性。

Method: 1. 基于凸优化的预处理方法有效去除混合噪声，实现准确稳定的模式提取；2. 新的凸优化降维公式，将鲁棒提取的模式与原始噪声观测显式关联，通过模式的稀疏加权和构建原始数据的真实表示；3. 使用预条件原始对偶分裂方法高效求解两个阶段。

Result: 在流体动力学数据集上的实验表明，CR-DMD在噪声条件下的模式准确性和低维表示保真度方面始终优于最先进的鲁棒DMD方法。

Conclusion: CR-DMD通过鲁棒化整个DMD流程（从模式提取到降维），有效应对混合噪声，提供了更稳定和真实的低维表示框架。

Abstract: We propose Comprehensive Robust Dynamic Mode Decomposition (CR-DMD), a novel framework that robustifies the entire DMD process - from mode extraction to dimensional reduction - against mixed noise. Although standard DMD widely used for uncovering spatio-temporal patterns and constructing low-dimensional models of dynamical systems, it suffers from significant performance degradation under noise due to its reliance on least-squares estimation for computing the linear time evolution operator. Existing robust variants typically modify the least-squares formulation, but they remain unstable and fail to ensure faithful low-dimensional representations. First, we introduce a convex optimization-based preprocessing method designed to effectively remove mixed noise, achieving accurate and stable mode extraction. Second, we propose a new convex formulation for dimensional reduction that explicitly links the robustly extracted modes to the original noisy observations, constructing a faithful representation of the original data via a sparse weighted sum of the modes. Both stages are efficiently solved by a preconditioned primal-dual splitting method. Experiments on fluid dynamics datasets demonstrate that CR-DMD consistently outperforms state-of-the-art robust DMD methods in terms of mode accuracy and fidelity of low-dimensional representations under noisy conditions.

</details>


### [20] [Scalable mm-Wave Liquid Crystal Reconfigurable Intelligent Surfaces based on the Delay Line Architecture](https://arxiv.org/abs/2601.11307)
*Julia Schwarzbeck,Robin Neuder,Marc Späth,Alejandro Jiménez-Sáez*

Main category: eess.SP

TL;DR: 本文设计、制造并表征了工作在60GHz频段、最多750个辐射单元的宽带液晶可重构智能表面，采用延迟线架构实现宽带宽、连续相位控制和快速响应。


<details>
  <summary>Details</summary>
Motivation: 传统可重构智能表面在毫米波频段面临带宽限制、相位控制范围不足和响应速度慢等挑战，需要开发新型架构来实现高性能、可扩展的RIS系统。

Method: 采用延迟线架构将相位控制层与辐射层解耦，使用4.6微米厚的液晶层，实现连续360°以上相位控制。制作了120和750单元的两种原型，采用相同单元结构和列式偏置。

Result: 测量显示波束可转向±60°，-3dB带宽超过9%，单元功耗仅为纳瓦级。模拟预测孔径效率超过20%，实测效率为9.2%和2.6%，效率降低归因于实验室环境的技术挑战。

Conclusion: 延迟线架构的液晶RIS相比传统方法具有明显优势，验证了该架构的可扩展性和在毫米波频段的优异性能，为大规模RIS应用奠定了基础。

Abstract: This paper presents the design, fabrication, and characterization of broadband liquid crystal (LC) reconfigurable intelligent surfaces (RIS) operating around 60 GHz and scaling up to 750 radiating elements. The RISs employ a delay line architecture (DLA) that decouples the phase shifting and radiating layer, enabling wide bandwidth, continuous phase control exceeding 360°, and fast response times with a micrometer-thin LC layer of 4.6 micrometer. Two prototypes with 120 and 750 elements are realized using identical unit cells and column-wise biasing. Measurements demonstrate beam steering over +-60° and -3 dB bandwidths exceeding 9% for both apertures, confirming the scalability of the proposed architecture. On top of a measured nanowatt power consumption per unit cell, aperture efficiencies above 20% are predicted by simulations. While the measured efficiencies are reduced to 9.2% and 2.6%, a detailed analysis verifies that this reduction can be attributed to technological challenges in a laboratory environment. Finally, a comprehensive comparison between the applied DLA-based LC-RIS and a conventional approach highlights the superior potential of applied architecture.

</details>


### [21] [Modulation, ISI, and Detection for Langmuir Adsorption-Based Microfluidic Molecular Communication](https://arxiv.org/abs/2601.11351)
*Ruifeng Zheng,Pengjie Zhou,Pit Hofmann,Martín Schottlender,Fatima Rani,Juan A. Cabrera,Frank H. P. Fitzek*

Main category: eess.SP

TL;DR: 研究微流控分子通信接收器，采用有限容量朗缪尔吸附模型，在反应受限条件下推导脉冲响应和符号率递归，分析信道记忆和码间干扰，并提出低复杂度检测器。


<details>
  <summary>Details</summary>
Motivation: 微流控分子通信系统中，接收器的吸附过程对通信性能有重要影响。现有研究需要更精确的模型来描述有限容量吸附、信道记忆和码间干扰，以设计有效的检测方案。

Method: 1) 在反应受限条件下推导闭式单脉冲响应核和符号率递归；2) 开发短脉冲和长脉冲近似；3) 采用有限受体二项计数模型；4) 使用脉冲结束采样；5) 提出低复杂度中点阈值检测器。

Result: 1) 揭示了长脉冲区域由于饱和导致的干扰不对称性；2) 当干扰可忽略时，中点阈值检测器简化为固定阈值；3) 数值结果验证了所提特性描述，并量化了检测性能与脉冲和符号持续时间的关系。

Conclusion: 该研究为微流控分子通信接收器提供了精确的建模框架，揭示了吸附饱和对干扰的影响，并提出了实用的低复杂度检测方案，为系统设计提供了理论指导。

Abstract: This paper studies microfluidic molecular communication receivers with finite-capacity Langmuir adsorption driven by an effective surface concentration. In the reaction-limited regime, we derive a closed-form single-pulse response kernel and a symbol-rate recursion for on-off keying that explicitly exposes channel memory and inter-symbol interference. We further develop short-pulse and long-pulse approximations, revealing an interference asymmetry in the long-pulse regime due to saturation. To account for stochasticity, we adopt a finite-receptor binomial counting model, employ pulse-end sampling, and propose a low-complexity midpoint-threshold detector that reduces to a fixed threshold when interference is negligible. Numerical results corroborate the proposed characterization and quantify detection performance versus pulse and symbol durations.

</details>


### [22] [Channel Estimation in MIMO Systems Aided by Microwave Linear Analog Computers (MiLACs)](https://arxiv.org/abs/2601.11438)
*Qiaosen Zhang,Matteo Nerini,Bruno Clerckx*

Main category: eess.SP

TL;DR: 提出用于微波线性模拟计算机辅助MIMO系统的全模拟域LS和MMSE信道估计方案，通过设计训练预编码器和组合器，在保持与数字方案相同性能的同时大幅降低计算复杂度、硬件需求和功耗。


<details>
  <summary>Details</summary>
Motivation: 微波线性模拟计算机（MiLACs）在大规模MIMO系统中能显著降低硬件和计算成本，但现有的信道估计方法（如LS和MMSE）需要大量数字计算，这削弱了MiLACs的优势。因此需要开发能在模拟域执行的高效信道估计方案。

Method: 设计由MiLACs实现的训练预编码器和组合器，使LS和MMSE信道估计完全在模拟域执行。这种方法避免了传统数字计算的高复杂度，同时保持了与数字方案相同的估计性能。

Result: 提出的全模拟域LS和MMSE估计方案与数字方案性能相同，但显著降低了计算复杂度、发射射频链数量、ADC/DAC分辨率要求和峰均功率比（PAPR）。数值结果验证了方案的有效性和优势。

Conclusion: 该工作解决了MiLAC辅助MIMO系统的信道估计问题，提出的模拟域估计方案在保持性能的同时大幅降低了硬件和计算需求，为未来大规模MIMO系统的实际部署提供了可行的解决方案。

Abstract: Microwave linear analog computers (MiLACs) have recently emerged as a promising solution for future gigantic multiple-input multiple-output (MIMO) systems, enabling beamforming with greatly reduced hardware and computational cost. However, channel estimation for MiLAC-aided systems remains an open problem. Conventional least squares (LS) and minimum mean square error (MMSE) estimation rely on intensive digital computation, which undermines the benefits offered by MiLACs. In this letter, we propose efficient LS and MMSE channel estimation schemes for MiLAC-aided MIMO systems. By designing training precoders and combiners implemented by MiLACs, both LS and MMSE estimation are performed fully in the analog domain, achieving identical performance to their digital counterparts while significantly reducing computational complexity, transmit RF chains, analog-to-digital/digital-to-analog converters (ADCs/DACs) resolution requirements, and peak-to-average power ratio (PAPR). Numerical results verify the effectiveness and advantages of the proposed schemes.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [23] [DSA-Tokenizer: Disentangled Semantic-Acoustic Tokenization via Flow Matching-based Hierarchical Fusion](https://arxiv.org/abs/2601.09239)
*Hanlin Zhang,Daxin Tan,Dehua Tao,Xiao Chen,Haochen Tan,Yunhe Li,Yuchen Cao,Jianping Wang,Linqi Song*

Main category: cs.SD

TL;DR: DSA-Tokenizer是一种新的语音分词器，通过显式地将语音解耦为语义和声学两种离散token，分别用ASR监督和频谱恢复优化，实现更好的语义-声学分离，支持高质量语音重建和可控生成。


<details>
  <summary>Details</summary>
Motivation: 现有语音分词器要么优先编码语义，要么将语义内容和声学风格不可分割地融合，或者只能实现不完整的语义-声学解耦。为了获得更好的解耦效果，需要一种能够明确分离语音中语义和声学成分的分词器。

Method: 提出DSA-Tokenizer，通过不同的优化约束将语音显式解耦为离散的语义token和声学token：语义token通过ASR监督捕捉语言内容，声学token专注于mel频谱图恢复以编码风格。引入分层Flow-Matching解码器消除两个序列之间的刚性长度约束，并采用联合重建-重组训练策略来强制分离。

Result: DSA-Tokenizer通过强大的解耦能力实现了高保真重建和灵活重组，促进了语音大语言模型中的可控生成。分析表明解耦分词是未来语音建模的关键范式。

Conclusion: DSA-Tokenizer通过显式语义-声学解耦，为语音大语言模型提供了更好的可控生成能力，代表了语音建模的重要发展方向。

Abstract: Speech tokenizers serve as the cornerstone of discrete Speech Large Language Models (Speech LLMs). Existing tokenizers either prioritize semantic encoding, fuse semantic content with acoustic style inseparably, or achieve incomplete semantic-acoustic disentanglement. To achieve better disentanglement, we propose DSA-Tokenizer, which explicitly disentangles speech into discrete semantic and acoustic tokens via distinct optimization constraints. Specifically, semantic tokens are supervised by ASR to capture linguistic content, while acoustic tokens focus on mel-spectrograms restoration to encode style. To eliminate rigid length constraints between the two sequences, we introduce a hierarchical Flow-Matching decoder that further improve speech generation quality. Furthermore, We employ a joint reconstruction-recombination training strategy to enforce this separation. DSA-Tokenizer enables high fidelity reconstruction and flexible recombination through robust disentanglement, facilitating controllable generation in speech LLMs. Our analysis highlights disentangled tokenization as a pivotal paradigm for future speech modeling. Audio samples are avaialble at https://anonymous.4open.science/w/DSA_Tokenizer_demo/. The code and model will be made publicly available after the paper has been accepted.

</details>


### [24] [Unifying Speech Recognition, Synthesis and Conversion with Autoregressive Transformers](https://arxiv.org/abs/2601.10770)
*Runyuan Cai,Yu Lin,Yiming Wang,Chunlin Fu,Xiaodong Zeng*

Main category: cs.SD

TL;DR: GPA是一个统一的音频基础模型，将TTS、ASR和VC等多个语音任务集成到单个LLM架构中，使用共享的离散音频token空间和指令驱动任务诱导，实现高效的多任务处理。


<details>
  <summary>Details</summary>
Motivation: 传统语音系统依赖独立的任务特定模型（TTS、ASR、VC），导致碎片化流水线，限制了可扩展性、效率和跨任务泛化能力。

Method: 采用统一的LLM架构，基于共享离散音频token空间，支持指令驱动任务诱导，完全自回归处理离散语音token，进行跨语音领域的联合多任务训练。

Result: 模型家族支持高效多尺度部署，包括针对边缘和资源受限环境优化的0.3B参数轻量级变体，在保持低延迟实用部署的同时，在多样化语音任务上实现竞争性性能。

Conclusion: 统一的自回归架构能够在多样化语音任务上实现竞争性性能，同时保持低延迟实用部署的可行性，为语音处理提供了更高效、可扩展的解决方案。

Abstract: Traditional speech systems typically rely on separate, task-specific models for text-to-speech (TTS), automatic speech recognition (ASR), and voice conversion (VC), resulting in fragmented pipelines that limit scalability, efficiency, and cross-task generalization. In this paper, we present General-Purpose Audio (GPA), a unified audio foundation model that integrates multiple core speech tasks within a single large language model (LLM) architecture. GPA operates on a shared discrete audio token space and supports instruction-driven task induction, enabling a single autoregressive model to flexibly perform TTS, ASR, and VC without architectural modifications. This unified design combines a fully autoregressive formulation over discrete speech tokens, joint multi-task training across speech domains, and a scalable inference pipeline that achieves high concurrency and throughput. The resulting model family supports efficient multi-scale deployment, including a lightweight 0.3B-parameter variant optimized for edge and resource-constrained environments. Together, these design choices demonstrate that a unified autoregressive architecture can achieve competitive performance across diverse speech tasks while remaining viable for low-latency, practical deployment.

</details>


### [25] [FlashLabs Chroma 1.0: A Real-Time End-to-End Spoken Dialogue Model with Personalized Voice Cloning](https://arxiv.org/abs/2601.11141)
*Tanyu Chen,Tairan Chen,Kai Shen,Zhenghua Bao,Zhihui Zhang,Man Yuan,Yi Shi*

Main category: cs.SD

TL;DR: Chroma 1.0是首个开源、实时、端到端的语音对话模型，通过交错文本-音频标记调度实现亚秒级延迟，同时保持高质量个性化语音克隆。


<details>
  <summary>Details</summary>
Motivation: 现有端到端语音对话系统使用语音标记器和神经音频编解码器，但往往在说话人身份保持方面表现有限，阻碍了个性化语音交互的发展。

Method: 采用交错文本-音频标记调度（1:2比例）支持流式生成，实现亚秒级端到端延迟，同时保持高质量个性化语音合成。

Result: Chroma在说话人相似度上相对人类基线提升10.96%，实时因子为0.43，同时保持强大的推理和对话能力。

Conclusion: Chroma 1.0成功实现了低延迟交互和高保真个性化语音克隆，为开源实时端到端语音对话系统提供了有效解决方案。

Abstract: Recent end-to-end spoken dialogue systems leverage speech tokenizers and neural audio codecs to enable LLMs to operate directly on discrete speech representations. However, these models often exhibit limited speaker identity preservation, hindering personalized voice interaction. In this work, we present Chroma 1.0, the first open-source, real-time, end-to-end spoken dialogue model that achieves both low-latency interaction and high-fidelity personalized voice cloning. Chroma achieves sub-second end-to-end latency through an interleaved text-audio token schedule (1:2) that supports streaming generation, while maintaining high-quality personalized voice synthesis across multi-turn conversations. Our experimental results demonstrate that Chroma achieves a 10.96% relative improvement in speaker similarity over the human baseline, with a Real-Time Factor (RTF) of 0.43, while maintaining strong reasoning and dialogue capabilities. Our code and models are publicly available at https://github.com/FlashLabs-AI-Corp/FlashLabs-Chroma and https://huggingface.co/FlashLabs/Chroma-4B .

</details>


### [26] [WenetSpeech-Wu: Datasets, Benchmarks, and Models for a Unified Chinese Wu Dialect Speech Processing Ecosystem](https://arxiv.org/abs/2601.11027)
*Chengyou Wang,Mingchen Shao,Jingbin Hu,Zeyu Zhu,Hongfei Xue,Bingshen Mu,Xin Xu,Xingyi Duan,Binbin Zhang,Pengcheng Zhu,Chuang Ding,Xiaojun Zhang,Hui Bu,Lei Xie*

Main category: cs.SD

TL;DR: 该论文提出了首个大规模、多维度标注的吴语开源语音语料库WenetSpeech-Wu（约8000小时），并建立了首个标准化公开评测基准WenetSpeech-Wu-Bench，同时发布了基于该数据集训练的开源模型套件，为吴语语音处理生态系统奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 吴语作为汉语重要方言，拥有大量使用者，但在语音技术发展中长期面临三大挑战：缺乏大规模语音数据、标准化评测基准和公开可用模型，导致吴语语音处理技术发展滞后。

Method: 1) 构建WenetSpeech-Wu语料库：收集约8000小时多样化吴语语音数据并进行多维度标注；2) 建立WenetSpeech-Wu-Bench评测基准：涵盖ASR、吴语-普通话翻译、说话人属性预测、语音情感识别、TTS合成和指令跟随TTS等任务；3) 训练并开源模型套件：基于WenetSpeech-Wu数据集训练多个任务的强基线模型。

Result: 1) 创建了首个大规模吴语开源语音语料库（8000小时）；2) 建立了首个标准化吴语语音处理评测基准；3) 发布了在多个任务上具有竞争力的开源模型套件；4) 实证验证了所提数据集的有效性。

Conclusion: 该工作为吴语语音处理建立了全面的生态系统基础，通过开源数据集、评测基准和模型套件，支持未来方言语音智能研究，促进低资源方言语音技术的包容性和鲁棒性发展。

Abstract: Speech processing for low-resource dialects remains a fundamental challenge in developing inclusive and robust speech technologies. Despite its linguistic significance and large speaker population, the Wu dialect of Chinese has long been hindered by the lack of large-scale speech data, standardized evaluation benchmarks, and publicly available models. In this work, we present WenetSpeech-Wu, the first large-scale, multi-dimensionally annotated open-source speech corpus for the Wu dialect, comprising approximately 8,000 hours of diverse speech data. Building upon this dataset, we introduce WenetSpeech-Wu-Bench, the first standardized and publicly accessible benchmark for systematic evaluation of Wu dialect speech processing, covering automatic speech recognition (ASR), Wu-to-Mandarin translation, speaker attribute prediction, speech emotion recognition, text-to-speech (TTS) synthesis, and instruction-following TTS (instruct TTS). Furthermore, we release a suite of strong open-source models trained on WenetSpeech-Wu, establishing competitive performance across multiple tasks and empirically validating the effectiveness of the proposed dataset. Together, these contributions lay the foundation for a comprehensive Wu dialect speech processing ecosystem, and we open-source proposed datasets, benchmarks, and models to support future research on dialectal speech intelligence.

</details>


### [27] [SonicBench: Dissecting the Physical Perception Bottleneck in Large Audio Language Models](https://arxiv.org/abs/2601.11039)
*Yirong Sun,Yanjun Chen,Xin Qiu,Gang Zhang,Hongyu Chen,Daokuan Wu,Chengming Li,Min Yang,Dawei Zhu,Wei Zhang,Xiaoyu Shen*

Main category: cs.SD

TL;DR: SonicBench是一个评估大音频语言模型物理属性感知能力的基准，发现模型在音高、响度等基础物理属性识别上表现接近随机猜测，且无法有效利用音频编码器已捕获的感官信号。


<details>
  <summary>Details</summary>
Motivation: 当前大音频语言模型在语义和副语言任务上表现出色，但对音频基础物理属性（如音高、响度、空间位置）的感知能力研究不足，需要系统评估模型在这些基础听觉理解上的能力。

Method: 提出SonicBench基准，通过可控生成工具构建刺激材料，采用识别（绝对判断）和比较（相对判断）两种互补范式，评估12个核心物理属性在五个感知维度上的表现，并进行线性探测分析。

Result: 大多数模型在物理属性识别上表现接近随机猜测，与人类模式相反，在比较任务上没有显示出预期优势，显式推理带来的提升有限。但线性探测显示冻结音频编码器成功捕获了这些物理线索（准确率至少60%）。

Conclusion: 大音频语言模型在基础听觉理解上存在严重缺陷，主要瓶颈在于对齐和解码阶段，模型无法有效利用已捕获的感官信号，而非音频编码器本身的能力问题。

Abstract: Large Audio Language Models (LALMs) excel at semantic and paralinguistic tasks, yet their ability to perceive the fundamental physical attributes of audio such as pitch, loudness, and spatial location remains under-explored. To bridge this gap, we introduce SonicBench, a psychophysically grounded benchmark that systematically evaluates 12 core physical attributes across five perceptual dimensions. Unlike previous datasets, SonicBench uses a controllable generation toolbox to construct stimuli for two complementary paradigms: recognition (absolute judgment) and comparison (relative judgment). This design allows us to probe not only sensory precision but also relational reasoning capabilities, a domain where humans typically exhibit greater proficiency. Our evaluation reveals a substantial deficiency in LALMs' foundational auditory understanding; most models perform near random guessing and, contrary to human patterns, fail to show the expected advantage on comparison tasks. Furthermore, explicit reasoning yields minimal gains. However, our linear probing analysis demonstrates crucially that frozen audio encoders do successfully capture these physical cues (accuracy at least 60%), suggesting that the primary bottleneck lies in the alignment and decoding stages, where models fail to leverage the sensory signals they have already captured.

</details>


### [28] [Scalable Music Cover Retrieval Using Lyrics-Aligned Audio Embeddings](https://arxiv.org/abs/2601.11262)
*Joanne Affolter,Benjamin Martin,Elena V. Epure,Gabriel Meseguer-Brocal,Frédéric Kaplan*

Main category: cs.SD

TL;DR: LIVI是一个基于歌词的音乐翻唱检索系统，通过训练时利用先进转录和文本嵌入模型监督，在推理时去除转录步骤，实现高精度且轻量化的翻唱识别。


<details>
  <summary>Details</summary>
Motivation: 现有基于和声和旋律特征的翻唱检索方法虽然有效，但需要大量训练时间和计算资源。歌词在翻唱中具有强不变性，但之前的方法要么性能有限，要么需要复杂多模态架构。需要平衡检索精度和计算效率的方法。

Method: LIVI在训练阶段利用最先进的转录模型和文本嵌入模型进行监督学习，学习从音频直接提取与歌词相关的特征表示。在推理阶段，系统直接使用训练好的模型处理音频，无需转录步骤，保持轻量化。

Result: LIVI在检索精度上达到或超过了基于和声的系统水平，同时保持了轻量化和高效性，挑战了复杂重型管道的统治地位。

Conclusion: 歌词信息可以作为音乐翻唱检索的有效特征，通过巧妙的设计可以在保持高精度的同时显著降低计算复杂度，为实际应用提供了更实用的解决方案。

Abstract: Music Cover Retrieval, also known as Version Identification, aims to recognize distinct renditions of the same underlying musical work, a task central to catalog management, copyright enforcement, and music retrieval. State-of-the-art approaches have largely focused on harmonic and melodic features, employing increasingly complex audio pipelines designed to be invariant to musical attributes that often vary widely across covers. While effective, these methods demand substantial training time and computational resources. By contrast, lyrics constitute a strong invariant across covers, though their use has been limited by the difficulty of extracting them accurately and efficiently from polyphonic audio. Early methods relied on simple frameworks that limited downstream performance, while more recent systems deliver stronger results but require large models integrated within complex multimodal architectures. We introduce LIVI (Lyrics-Informed Version Identification), an approach that seeks to balance retrieval accuracy with computational efficiency. First, LIVI leverages supervision from state-of-the-art transcription and text embedding models during training to achieve retrieval accuracy on par with--or superior to--harmonic-based systems. Second, LIVI remains lightweight and efficient by removing the transcription step at inference, challenging the dominance of complexity-heavy pipelines.

</details>

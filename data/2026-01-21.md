<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 54]
- [eess.AS](#eess.AS) [Total: 24]
- [cs.SD](#cs.SD) [Total: 28]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Inter-Cell Interference Rejection Based on Ultrawideband Walsh-Domain Wireless Autoencoding](https://arxiv.org/abs/2601.11713)
*Rodney Martinez Alonso,Cel Thys,Cedric Dehos,Yuneisy Esthela Garcia Guzman,Sofie Pollin*

Main category: eess.SP

TL;DR: 提出一种在沃尔什域中利用端到端无线自编码器架构来抑制超宽带系统中部分带内小区间干扰的新方法


<details>
  <summary>Details</summary>
Motivation: 超宽带通信系统中存在与5G基站共存的窄带干扰，这些部分带内小区间干扰严重影响系统性能，需要有效抑制技术

Method: 设计端到端无线自编码器架构，在沃尔什域中联合优化发射机和接收机的编码/解码，利用沃尔什函数的正交性和自逆特性，通过并行沃尔什分支分布和编码比特字

Result: 通过分析和仿真，确定了传输频率与采样率的最佳比例，使自编码器达到最高干扰抑制效果。实验结果显示，在相同基线信道噪声下，所提方法能实现高达12dB的ICI抑制，同时保持低误块率

Conclusion: 基于沃尔什域的端到端自编码器架构能有效抑制超宽带系统中的部分带内小区间干扰，为5G共存环境下的超宽带通信提供了可行的干扰抑制方案

Abstract: This paper proposes a novel technique for rejecting partial-in-band inter-cell interference (ICI) in ultrawideband communication systems. We present the design of an end-to-end wireless autoencoder architecture that jointly optimizes the transmitter and receiver encoding/decoding in the Walsh domain to mitigate interference from coexisting narrower-band 5G base stations. By exploiting the orthogonality and self-inverse properties of Walsh functions, the system distributes and learns to encode bit-words across parallel Walsh branches. Through analytical modeling and simulation, we characterize how 5G CPOFDM interference maps into the Walsh domain and identify optimal ratios of transmission frequencies and sampling rate where the end-to-end autoencoder achieves the highest rejection. Experimental results show that the proposed autoencoder achieves up to 12 dB of ICI rejection while maintaining a low block error rate (BLER) for the same baseline channel noise, i.e., baseline Signal-to-Noise-Ratio (SNR) without the interference.

</details>


### [2] [Sparsity Realization in User-Side Multilayer RIS](https://arxiv.org/abs/2601.11720)
*Hasan M. Boudi,Taissir Y. Elganimi*

Main category: eess.SP

TL;DR: 提出两种稀疏化策略（元素级稀疏和几何稀疏）的多层用户侧可重构智能表面架构，相比现有设计能持续提升可达速率


<details>
  <summary>Details</summary>
Motivation: 解决大规模用户侧天线阵列的高硬件成本和物理尺寸限制问题，用户侧可重构智能表面（US-RIS）成为有前景的解决方案，但需要进一步优化性能

Method: 提出两种稀疏化策略：1）元素级稀疏 - 在多层结构中不规则分布有限数量的有源元件，利用额外的空间自由度；2）几何稀疏 - 提出可折叠RIS架构，通过优化多层结构的折叠拓扑实现性能提升

Result: 仿真结果表明，所提出的稀疏架构相比现有设计能够持续提供更高的可达速率

Conclusion: 首次提出实现多层US-RIS稀疏化的框架，通过元素级稀疏和几何稀疏两种策略，有效提升了系统性能，为解决用户侧大规模天线阵列的硬件限制提供了创新解决方案

Abstract: User-side reconfigurable intelligent surface (US-RIS)-aided communication has recently emerged as a promising solution to overcome the high hardware cost and physical size limitations of large-scale user side antenna arrays. This letter proposes, for the first time, a framework that realizes sparsity in multilayer US-RIS using two strategies, namely element-wise sparsity and geometric sparsity. The element-wise approach distributes a limited number of active elements irregularly across multiple layers, thereby exploiting additional spatial degrees of freedom and boosting the achievable rate. For further performance enhancement, a novel foldable RIS architecture leveraging geometric sparsity is proposed, achieving additional gains by optimizing the folding topology of its multilayer structure. Simulation results show that the proposed sparse architectures provide consistently higher achievable rates than existing designs.

</details>


### [3] [LarS-Net: A Large-Scale Framework for Network-Level Spectrum Sensing](https://arxiv.org/abs/2601.11734)
*Hao Guo,Ruoyu Sun,Amir Hossein Fahim Raouf,Rahil Gandotra,Jiayu Mao,Mark Poletti*

Main category: eess.SP

TL;DR: 设计大规模频谱感知网络(LarS-Net)，通过基站共享基础设施降低成本，分析最小感知基站子集需求，并提出三种网络级性能指标评估大规模感知性能。


<details>
  <summary>Details</summary>
Motivation: 随着无线通信需求增长，频谱资源需要更高效利用，推动从静态频谱分配向频谱共享和动态频谱共享演进。频谱感知是实现共享环境智能决策的关键，但现有研究主要局限于单个或小规模传感器，需要大规模成本效益的解决方案。

Method: 设计大规模频谱感知网络(LarS-Net)，将频谱传感器与基站共址共享基础设施，或直接集成到基站中。以6G候选频段（低7GHz）的固定服务微波链路为例，通过蒙特卡洛模拟确定满足目标检测概率所需的最小感知基站子集，考虑多种传感器天线配置、传播信道模型和占空比。

Result: 提出三种网络级感知性能指标：发射检测概率(EDP)、时间检测概率(TDP)和时间误检概率(TMP)，共同捕捉空间覆盖、时间可检测性和多节点分集效应。分析了LarS-Net站间距、噪声不确定性和感知占空比对大规模感知性能的影响。

Conclusion: LarS-Net提供了一种成本效益的大规模频谱感知解决方案，通过基站基础设施共享降低部署成本。提出的网络级性能指标为评估大规模频谱感知系统提供了全面框架，有助于优化6G及未来无线网络的动态频谱共享。

Abstract: As the demand of wireless communication continues to rise, the radio spectrum (a finite resource) requires increasingly efficient utilization. This trend is driving the evolution from static, stand-alone spectrum allocation toward spectrum sharing and dynamic spectrum sharing. A critical element of this transition is spectrum sensing, which facilitates informed decision-making in shared environments. Previous studies on spectrum sensing and cognitive radio have been largely limited to individual sensors or small sensor groups. In this work, a large-scale spectrum sensing network (LarS-Net) is designed in a cost-effective manner. Spectrum sensors are either co-located with base stations (BSs) to share the tower, backhaul, and power infrastructure, or integrated directly into BSs as a new feature leveraging active BS antenna systems. As an example incumbent system, fixed service microwave link operating in the lower-7 GHz band is investigated. This band is a primary candidate for 6G, being considered by the WRC-23, ITU, and FCC. Based on Monte Carlo simulations, we determine the minimum subset of BSs equipped with sensing capability to guarantee a target incumbent detection probability. The simulations account for various sensor antenna configurations, propagation channel models, and duty cycles for both incumbent transmissions and sensing operations. Building on this framework, we introduce three network-level sensing performance metrics: Emission Detection Probability (EDP), Temporal Detection Probability (TDP), and Temporal Mis-detection Probability (TMP), which jointly capture spatial coverage, temporal detectability, and multi-node diversity effects. Using these metrics, we analyze the impact of LarS-Net inter-site distance, noise uncertainty, and sensing duty-cycle on large-scale sensing performance.

</details>


### [4] [MIMO Array Calibration in Non-stationary Channels with Residual Surfaces and Slepian Spherical Harmonics](https://arxiv.org/abs/2601.11741)
*Oliver Kirkpatrick,Santiago Ozafrain,Christopher Gilliam,Beth Jelfs*

Main category: eess.SP

TL;DR: 提出一种在非平稳信道中通过间接测量和补偿硬件影响的MIMO波束成形校准方法，使用Slepian球谐基表征阵列元素相对模式，实现接近理论最优的波束成形增益。


<details>
  <summary>Details</summary>
Motivation: 在非平稳信道中，到达信号的幅度和相位随时间显著变化，使得直接测量硬件影响变得不可行，需要开发间接测量和补偿硬件影响的校准方法。

Method: 提出一种校准方法，通过Slepian球谐基表征阵列元素相对于参考元素的模式，估计这些相对模式（称为残差表面），从而间接测量和补偿硬件影响。

Result: 仿真结果表明，该校准方法实现的波束成形增益接近理论最优值，同时减少了目标方向估计误差，降低了旁瓣，并提高了零陷导向能力。

Conclusion: 该方法有效解决了非平稳信道中硬件影响校准的挑战，为MIMO系统在动态环境中的性能优化提供了实用解决方案。

Abstract: The fundamental mechanism driving MIMO beamforming is the relative phases of signals departing the transmit array and arriving at the receive array. If a propagation channel affects all transmitted signals equally, the relative phases are a function of the directions of departure and arrival, as well as the transmit and receive hardware. In a non-stationary channel, the amplitudes and phases of arriving signals may vary significantly over time, making it infeasible to directly measure the influence of hardware. In this paper, we present a calibration method for achieving indirect measurement and compensation of hardware influences in non-stationary channels. Our method characterizes the patterns of array elements relative to a reference element and estimates these relative patterns, termed residual surfaces, using a Slepian spherical harmonic basis. Using simulations, we demonstrate that our calibration method achieves beamforming gains that closely match theoretical optimums. Our results also show a reduction in the error in estimating the target direction, lower side lobes, and improve null-steering capabilities.

</details>


### [5] [AI-Driven Spectrum Occupancy Prediction Using Real-World Spectrum Measurements](https://arxiv.org/abs/2601.11742)
*Jiayu Mao,Ruoyu Sun,Mark Poletti,Rahil Gandotra,Hao Guo,Aylin Yener*

Main category: eess.SP

TL;DR: 该论文使用美国真实世界频谱测量数据，研究短时频谱占用预测，比较了随机森林、XGBoost、LSTM等AI方法与马尔可夫链基线的性能，发现学习型方法在动态信道中表现更优。


<details>
  <summary>Details</summary>
Motivation: 频谱占用预测是实现实时和主动动态频谱共享的关键，但现有研究多依赖开源数据集或模拟数据。本文旨在使用真实世界频谱测量数据来研究短时频谱占用预测，为实际部署提供支持。

Method: 使用美国中频段24X7真实世界频谱测量数据，构建多波段信道占用数据集（61天经验数据）。将问题表述为跨所有频率信道的下一分钟信道占用预测任务。比较了随机森林、XGBoost、LSTM等AI驱动方法与传统的马尔可夫链统计基线方法。

Result: 数值结果显示，学习型方法在动态信道中优于统计基线，特别是在固定误报约束下。轻量级学习模型能够有效支持未来面向部署的动态频谱共享系统。

Conclusion: AI驱动的频谱占用预测是有效的，轻量级学习模型可以有效地支持未来面向部署的动态频谱共享系统，为实际应用提供了有前景的解决方案。

Abstract: Spectrum occupancy prediction is a critical enabler for real-time and proactive dynamic spectrum sharing (DSS), as it can provide short-term channel availability information to support more efficient spectrum access decisions in wireless communication systems. Instead of relying on open-source datasets or simulated data, commonly used in the literature, this paper investigates short-horizon spectrum occupancy prediction using mid-band, 24X7 real-world spectrum measurement data collected in the United States. We construct a multi-band channel occupancy dataset through analyzing 61 days of empirical data and formulate a next-minute channel occupancy prediction task across all frequency channels. This study focuses on AI-driven prediction methods, including Random Forest, Extreme Gradient Boosting (XGBoost), and a Long Short-Term Memory (LSTM) network, and compares their performance against a conventional Markov chain-based statistical baseline. Numerical results show that learning-based methods outperform the statistical baseline on dynamic channels, particularly under fixed false-alarm constraints. These results demonstrate the effectiveness of AI-driven spectrum occupancy prediction, indicating that lightweight learning models can effectively support future deployment-oriented DSS systems.

</details>


### [6] [Automated Spectrum Sensing and Analysis Framework](https://arxiv.org/abs/2601.11748)
*Rahil Gandotra,Ruoyu Sun,Mark Poletti,Jiayu Mao,Hao Guo*

Main category: eess.SP

TL;DR: 本文提出并部署了一个用于频谱分析的新型端到端框架，在美国多个地点实施，涵盖数据收集、处理、分析和可视化全流程。


<details>
  <summary>Details</summary>
Motivation: 频谱感知和分析对于监管合规、干扰检测与缓解、频谱资源规划优化至关重要。然而，实时频谱分析面临挑战，需要在资源有限的情况下分析日益复杂动态的环境。大量多站点频谱数据需要复杂的数据分析处理技术，技术难度高且成本昂贵。

Method: 开发并部署了一个端到端的频谱分析框架，包括：远程位置的数据收集和预处理、传输到集中位置、后处理分析、可视化以及长期存储等模块。该框架在美国多个地点实施。

Result: 成功构建了一个稳健的频谱分析框架，能够深入了解全国范围内的频谱使用情况，并为动态频谱共享等附加用例提供支持。

Conclusion: 该框架为解决实时频谱分析挑战提供了有效的解决方案，能够帮助获得对频谱使用的深入洞察，并支持动态频谱共享等应用场景。

Abstract: Spectrum sensing and analysis is crucial for a variety of reasons, including regulatory compliance, interference detection and mitigation, and spectrum resource planning and optimization. Effective, real-time spectrum analysis remains a challenge, stemming from the need to analyse an increasingly complex and dynamic environment with limited resources. The vast amount of data generated from sensing the spectrum at multiple sites requires sophisticated data analysis and processing techniques, which can be technically demanding and expensive. This paper presents a novel, holistic framework developed and deployed at multiple locations across the USA for spectrum analysis and describes the different parts of the end-to-end pipeline. The details of each of the modules of the pipeline, data collection and pre-processing at remote locations, transfer to a centralized location, post-processing analysis, visualization, and long-term storage, are reported. The motivation behind this work is to develop a robust spectrum analysis framework that can help gain greater insights into the spectrum usage across the country and augment additional use cases such as dynamic spectrum sharing.

</details>


### [7] [Necessity of Cooperative Transmissions for Wireless MapReduce](https://arxiv.org/abs/2601.11844)
*Yue Bi,Michèle Wigger*

Main category: eess.SP

TL;DR: 该论文改进了分布式MapReduce系统中归一化传输时间与计算负载之间最优权衡的上界，并提供了非合作方案的下界，证明了在某些参数下需要合作方案才能达到最优权衡。


<details>
  <summary>Details</summary>
Motivation: 研究分布式计算MapReduce系统中归一化传输时间与计算负载之间的最优权衡关系，探索是否需要节点间合作才能达到最优性能。

Method: 结合干扰对齐和迫零技术提出改进的上界方案，同时分析非合作方案（节点独立传输子中间值）的下界。

Result: 在某些参数范围内，新提出的合作方案优于所有非合作方案，证明了合作方案（如迫零）对达到最优NDT-计算权衡的必要性。

Conclusion: 对于分布式MapReduce系统，在某些参数条件下，节点间合作是达到最优归一化传输时间与计算负载权衡的必要条件。

Abstract: The paper presents an improved upper bound (achievability result) on the optimal tradeoff between Normalized Delivery Time (NDT) and computation load for distributed computing MapReduce systems in certain ranges of the parameters. The upper bound is based on interference alignment combined with zero-forcing. The paper further provides a lower bound (converse) on the optimal NDT-computation tradeoff that can be achieved when IVAs are partitioned into sub-IVAs, and these sub-IVAs are then transmitted (in an arbitrary form) by a single node, without cooperation among nodes. For appropriate linear functions (e.g., XORs), such non-cooperative schemes can achieve some of the best NDT-computation tradeoff points so far obtained in the literature. However, as our lower bound shows, any non-cooperative scheme achieves a worse NDT-computation tradeoff than our new proposed scheme for certain parameters, thus proving the necessity of cooperative schemes like zero-forcing to attain the optimal NDT-computation tradeoff.

</details>


### [8] [Delay-Doppler-Domain Channel Estimation and Reduced-Complexity Detection of Faster-than-Nyquist Signaling Aided OTFS](https://arxiv.org/abs/2601.11869)
*Zekun Hong,Shinya Sugiura,Chao Xu,Lajos Hanzo*

Main category: eess.SP

TL;DR: 提出了一种用于OTFS-FTN传输的新型信道估计和数据检测方案，旨在提高频谱效率和抗多普勒能力


<details>
  <summary>Details</summary>
Motivation: 提高频谱效率和增强对多普勒频移的鲁棒性，在双选择性衰落信道中实现更高效的OTFS-FTN传输

Method: 1) 推导OTFS-FTN信号在延迟-多普勒域的输入输出关系；2) 设计基于FTN导频传输的DD域信道估计器；3) 提出支持噪声白化的低复杂度线性最小均方误差均衡器，将FTN引起的ISI矩阵近似为稀疏矩阵

Result: 提出的OTFS-FTN方案能够提高可达信息率，同时获得与奈奎斯特OTFS方案和其他使用相同RRC成形滤波器的FTN传输方案相当的BER性能

Conclusion: 该方案成功实现了频谱效率提升和多普勒鲁棒性增强，在保持良好BER性能的同时提高了信息传输速率

Abstract: We conceive a novel channel estimation and data detection scheme for OTFS-modulated faster-than-Nyquist (FTN) transmission over doubly selective fading channels, aiming for enhancing the spectral efficiency and Doppler resilience. The delay-Doppler (DD) domain's input-output relationship of OTFS-FTN signaling is derived by employing a root-raised cosine (RRC) shaping filter. More specifically, we design our DD-domain channel estimator for FTN-based pilot transmission, where the pilot symbol interval is lower than that defined by the classic Nyquist criterion. Moreover, we propose a reduced-complexity linear minimum mean square error equalizer, supporting noise whitening, where the FTN-induced inter-symbol interference (ISI) matrix is approximated by a sparse one. Our performance results demonstrate that the proposed OTFS-FTN scheme is capable of enhancing the achievable information rate, while attaining a comparable BER performance to both that of its Nyquist-based OTFS counterpart and to other FTN transmission schemes, which employ the same RRC shaping filter.

</details>


### [9] [Accelerated MR Elastography Using Learned Neural Network Representation](https://arxiv.org/abs/2601.11878)
*Xi Peng*

Main category: eess.SP

TL;DR: 提出一种自监督深度学习框架，用于从高度欠采样的k空间数据中重建高分辨率MR弹性成像，无需高质量训练数据集，通过非线性网络扩展线性子空间模型。


<details>
  <summary>Details</summary>
Motivation: 传统MR弹性成像需要多次重复采集以获得足够的空间分辨率，导致扫描时间过长。现有方法需要高质量训练数据集，限制了临床应用。需要开发一种无需高质量训练数据、能从高度欠采样数据快速重建高分辨率MR弹性成像的方法。

Method: 将深度神经网络表示为线性子空间模型的非线性扩展，用于从欠采样k空间数据重建MRE图像重复序列。采用多级k空间一致性损失进行自监督学习，并整合相位对比特定的幅度和相位先验（解剖结构相似性和波诱导谐波位移平滑性）。

Result: 在3D梯度回波螺旋和多层自旋回波螺旋MRE数据集上验证，相比传统线性子空间方法，非线性网络表示方法能从每个MRE重复的单平面螺旋臂（总R=10）产生更优的图像重建，抑制噪声和伪影，获得与全采样数据相当的刚度估计。

Conclusion: 证明了使用深度网络表示从高度欠采样数据建模和重建MRE图像的可行性，这是子空间方法的非线性扩展，为快速高分辨率MR弹性成像提供了新途径。

Abstract: To develop a deep-learning method for achieving fast high-resolution MR elastography from highly undersampled data without the need of high-quality training dataset. We first framed the deep neural network representation as a nonlinear extension of the linear subspace model, then used it to represent and reconstruct MRE image repetitions from undersampled k-space data. The network weights were learned using a multi-level k-space consistent loss in a self-supervised manner. To further enhance reconstruction quality, phase-contrast specific magnitude and phase priors were incorporated, including the similarity of anatomical structures and smoothness of wave-induced harmonic displacement. Experiments were conducted using both 3D gradient-echo spiral and multi-slice spin-echo spiral MRE datasets. Compared to the conventional linear subspace-based approaches, the nonlinear network representation method was able to produce superior image reconstruction with suppressed noise and artifacts from a single in-plane spiral arm per MRE repetition (e.g., total R=10), yielding comparable stiffness estimation to the fully sampled data. This work demonstrated the feasibility of using deep network representations to model and reconstruct MRE images from highly-undersampled data, a nonlinear extension of the subspace-based approaches.

</details>


### [10] [Beyond Target-Level: ISAC-Enabled Event-Level Sensing for Behavioral Intention Prediction](https://arxiv.org/abs/2601.11894)
*Haotian Liu,Zhiqing Wei,Yucong Du,Jiachen Wei,Xingwang Li,Zhiyong Feng*

Main category: eess.SP

TL;DR: 本文提出了一种基于集成感知与通信（ISAC）的行为意图预测框架，用于自动驾驶中的事件级感知，在非视距和恶劣天气条件下优于传统传感器方法。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信（ISAC）在自动驾驶的行为意图预测等事件级感知方面具有巨大潜力，特别是在传统传感器性能下降的非视距或恶劣天气条件下。然而，作为事件级感知的关键实例，基于ISAC的行为意图预测尚未得到探索。

Method: 提出了一个ISAC启用的行为意图预测框架，并通过广泛的仿真验证其可行性和有效性。该框架在安全关键场景中实现鲁棒性能。

Result: 在恶劣天气条件下，该框架相比基于传感器的基线方法将F1分数提高了11.4%，证明了ISAC在智能事件级感知方面的潜力。

Conclusion: ISAC在自动驾驶的行为意图预测等事件级感知方面具有显著优势，特别是在恶劣环境条件下，为智能事件级感知提供了新的可能性。

Abstract: Integrated Sensing and Communication (ISAC) holds great promise for enabling event-level sensing, such as behavioral intention prediction (BIP) in autonomous driving, particularly under non-line-of-sight (NLoS) or adverse weather conditions where conventional sensors degrade. However, as a key instance of event-level sensing, ISAC-based BIP remains unexplored. To address this gap, we propose an ISAC-enabled BIP framework and validate its feasibility and effectiveness through extensive simulations. Our framework achieves robust performance in safety-critical scenarios, improving the F1-score by 11.4% over sensor-based baselines in adverse weather, thereby demonstrating ISAC's potential for intelligent event-level sensing.

</details>


### [11] [Radar-Based Fall Detection for Assisted Living: A Digital-Twin Representation Case Study](https://arxiv.org/abs/2601.11938)
*Sebastian Ratto,Huy Trinh,Ahmed N. Sayed,Abdelrahman Elbadrawy,Arien Sligar,George Shaker*

Main category: eess.SP

TL;DR: 使用FMCW雷达数字孪生研究不同表征方式对跌倒检测性能的影响，发现时频谱图比静态距离-多普勒图有更好的分类准确率


<details>
  <summary>Details</summary>
Motivation: 从老年人获取高风险跌倒数据存在伦理困难，而现有雷达跌倒检测器大多基于年轻志愿者的模拟跌倒训练，缺乏对危险跌倒真实雷达信号的验证

Method: 使用FMCW雷达数字孪生作为模拟测试平台，从相同的模拟距离-多普勒序列中提取三种表征：多普勒-时间频谱图、三通道接收器频谱图堆栈和时间池化的距离-多普勒图，使用相同的紧凑CNN在平衡数据集上进行训练

Result: 时频谱图达到98-99%的测试准确率，两类都有相似的精确率和召回率；而静态距离-多普勒图仅达到89.4%，训练过程更不稳定。合成与实测频谱图的定性比较显示数字孪生能捕捉主要的多普勒-时间结构，但幅度直方图显示分布差异

Conclusion: 数字孪生省略了噪声和硬件损伤，仅与单个实测示例进行定性比较，因此结果提供了受控合成条件下的表征层面指导，而非真实临床环境中的即用性能

Abstract: Obtaining data on high-impact falls from older adults is ethically difficult, yet these rare events cause many fall-related health problems. As a result, most radar-based fall detectors are trained on staged falls from young volunteers, and representation choices are rarely tested against the radar signals from dangerous falls. This paper uses a frequency-modulated continuous-wave (FMCW) radar digital twin as a single simulated room testbed to study how representation choice affects fall/non-fall discrimination. From the same simulated range-Doppler sequence, Doppler-time spectrograms, three-channel per-receiver spectrogram stacks, and time-pooled range-Doppler maps (RDMs) are derived and fed to an identical compact CNN under matched training on a balanced fall/non-fall dataset. In this twin, temporal spectrograms reach 98-99% test accuracy with similar precision and recall for both classes, while static RDMs reach 89.4% and show more variable training despite using the same backbone. A qualitative comparison between synthetic and measured fall spectrograms suggests that the twin captures gross Doppler-time structure, but amplitude histograms reveal differences in the distributions of amplitude values consistent with receiver processing not modeled in the twin. Because the twin omits noise and hardware impairments and is only qualitatively compared to a single measured example, these results provide representation-level guidance under controlled synthetic conditions rather than ready-to-use clinical performance in real settings.

</details>


### [12] [Robust distributed extended Kalman filter based on adaptive multi-kernel mixture maximum correntropy for non-Gaussian systems](https://arxiv.org/abs/2601.11971)
*Duc Viet Nguyen,Haiquan Zhao,Jinhui Hu,Xiaoli Li*

Main category: eess.SP

TL;DR: 提出多核混合相关熵(MKMC)概念，基于学生t-柯西混合核函数，开发自适应多核混合最大相关熵鲁棒分布式扩展卡尔曼滤波器(AMKMMC-RDEKF)，用于多传感器网络状态估计。


<details>
  <summary>Details</summary>
Motivation: 现有多核相关熵方法存在两个主要局限：1) 依赖单一类型的高斯核函数，对参数敏感；2) 需要手动选择自由参数。这些限制影响了算法在处理非高斯噪声（特别是多模态分布）时的鲁棒性和性能。

Method: 1) 提出多核混合相关熵(MKMC)概念，使用两个具有可调非零均值的学生t-柯西函数的混合核函数；2) 基于MKMC开发自适应多核混合最大相关熵鲁棒分布式扩展卡尔曼滤波器(AMKMMC-RDEKF)；3) 引入共识平均策略减少通信开销；4) 设计自适应机制自动调整参数；5) 分析算法计算复杂度和收敛能力。

Result: 在电力系统和陆地车辆状态估计的挑战性场景中验证了算法的有效性。算法表现出对非高斯噪声（特别是多模态分布）的优越处理能力，同时通过自适应机制减少了参数调优需求，共识策略降低了通信开销。

Conclusion: 提出的MKMC框架和AMKMMC-RDEKF算法解决了现有多核相关熵方法的局限性，提供了更灵活、鲁棒和自适应的状态估计解决方案，特别适用于多传感器网络中非高斯噪声环境下的复杂状态估计问题。

Abstract: As one of the most advanced variants in the correntropy family, the multi-kernel correntropy criterion demonstrates superior accuracy in handling non-Gaussian noise, particularly with multimodal distributions. However, current approaches suffer from key limitations-namely, reliance on a single type of sensitive Gaussian kernel and the manual selection of free parameters. To address these issues and further boost robustness, this paper introduces the concept of multi-kernel mixture correntropy (MKMC), along with its key properties. MKMC employs a flexible kernel function composed of a mixture of two Students t-Cauchy functions with adjustable (non-zero) means. Building on this criterion within multi-sensor networks, we propose a robust distributed extended Kalman filter-AMKMMC-RDEKF based on adaptive multi-kernel mixture maximum correntropy. To reduce communication overhead, a consensus averaging strategy is incorporated. Furthermore, an adaptive mechanism is introduced to mitigate the impact of manually tuned free parameters. At the same time, the computational complexity and convergence ability of the proposed algorithm are analyzed. The effectiveness of the proposed algorithm is validated through challenging scenarios involving power system and land vehicle state estimation.

</details>


### [13] [Extended Weighted ABG: A Robust Non-Linear ABG-Based Approach for Optimal Combination of ABG Path-Loss Propagation Models](https://arxiv.org/abs/2601.12110)
*David. Casillas-Pérez,Daniel. Merino-Pérez,Silvia. Jiménez-Fernández,J. Antonio. Portilla-Figueras,Sancho. Salcedo-Sanz*

Main category: eess.SP

TL;DR: 提出EWABG模型，这是首个非线性扩展的ABG路径损耗模型，能整合多个数据集和现有模型，解决5G高低频不均匀性和离群值问题，在噪声环境下表现最优。


<details>
  <summary>Details</summary>
Motivation: 现有5G路径损耗模型存在两个主要问题：1) 高低频测量不均匀（多数测量集中在低频）；2) 缺乏离群值处理机制。需要开发更稳健的模型来整合不同数据集和现有模型。

Method: 提出扩展加权ABG（EWABG）模型，这是首个非线性ABG扩展。采用最小二乘法整合多个路径损耗数据集和现有模型，使用Theil-Sen方法处理离群值，并特别考虑大气气体非线性衰减。

Result: EWABG在5G非视距环境（UMiSC、UMiOS、UMa场景）中表现最佳，特别是在有离群值的噪声环境下，误差率增加可忽略（低于1%），优于ABG和WABG模型。

Conclusion: EWABG是首个非线性ABG扩展模型，能有效整合多个路径损耗数据集和现有模型，解决高低频不均匀性和离群值问题，在5G传播建模中具有优越性能。

Abstract: This paper proposes a robust non-linear generalized path-loss propagation model, the Extended Weighted ABG (EWABG), which efficiently allows generating a path-loss propagation model by combining several available path-loss datasets (from measurements campaigns) and other previously proposed state-of-the-art 5G path-loss propagation models. The EWABG model works by integrating individual path-loss models into one single model in the least-squares sense, allowing to extend knowledge from frequencies and distances covered by path-loss datasets or path-loss propagation models. The proposed EWABG model is the first non-linear extension of the common ABG-based approach, which surpasses the non-uniformity problem between the low and high 5G frequencies (as most measurements campaigns have taken place in low frequencies). The EWABG also addresses the problem of removing outlier measurements, a step not included in previous propagation path-loss models. In this case, we have compared the most recent techniques for avoiding outliers, and we have adopted the Theil-Sen method, due to its strong robustness demonstrated in the experiments carried out. In addition, the proposed model specifically considers non-linear attenuation by atmospheric gases, in order to improve its estimations. The good performance of the proposed EWABG model has been tested and compared against recent 5G propagation path-loss models including the ABG and WABG models. The exhaustive experimentation carried out includes the 5G non-line-of-sight environment in different 5G scenarios, UMiSC, UMiOS and UMa. The proposed EWABG obtains the best accuracy, specially in noisy environments with outliers, reporting negligible increment error rates (with respect to the non-outliers situation), lower than 1%, compared to the ABG and WABG.

</details>


### [14] [Boiling flow estimation for aero-optic phase screen generation](https://arxiv.org/abs/2601.12171)
*Jeffrey W. Utley,Gregery T. Buzzard,Charles A. Bouman,Matthew R. Kemnetz*

Main category: eess.SP

TL;DR: 提出一种改进的沸腾流算法，用于生成匹配实测气动光学数据统计特性的任意长度合成数据，特别针对各向异性相位屏生成。


<details>
  <summary>Details</summary>
Motivation: 气动光学湍流效应会降低光波传输效率，现有湍流数据生成方法（实验、高/低精度CFD、自回归方法）存在成本高、数据量有限、统计不准确等缺点。沸腾流算法虽然简单高效，但未在气动光学中广泛应用，部分参数定义不明确。

Method: 改进标准沸腾流算法，使其能够生成各向异性相位屏，匹配实测气动光学数据的统计特性。该方法可以生成任意长度的合成数据，在时间功率谱和各向异性2D结构函数之间进行权衡匹配。

Result: 改进的沸腾流算法能够生成匹配实测气动光学数据统计特性的合成数据，虽然不能完全捕捉所有统计特性，但能在时间功率谱和各向异性2D结构函数之间实现权衡匹配。

Conclusion: 改进的沸腾流算法为气动光学应用提供了一种简单、计算高效的数据生成方法，能够生成匹配实测数据统计特性的各向异性相位屏，弥补了现有方法的不足。

Abstract: Aero-optic effects due to turbulence can reduce the effectiveness of transmitting light waves to a distant target. Methods to compensate for turbulence typically rely on realistic turbulence data, which can be generated by i) experiment, ii) high-fidelity CFD, iii) low-fidelity CFD, and iv) autoregressive methods. However, each of these methods has significant drawbacks, including monetary and/or computational expense, limited quantity, inaccurate statistics, and overall complexity. In contrast, the boiling flow algorithm is a simple, computationally efficient model that can generate atmospheric phase screen data with only a handful of parameters. However, boiling flow has not been widely used in aero-optic applications, at least in part because some of these parameters, such as r0, are not clearly defined for aero-optic data. In this paper, we demonstrate a method to use the boiling flow algorithm to generate arbitrary length synthetic data to match the statistics of measured aero-optic data. Importantly, we modify the standard boiling flow method to generate anisotropic phase screens. While this model does not fully capture all statistics, it can be used to generate data that matches the temporal power spectrum or the anisotropic 2D structure function, with the ability to trade fidelity to one for fidelity to the other.

</details>


### [15] [Low-Complexity RSS-based Underwater Localization with Unknown Transmit Power](https://arxiv.org/abs/2601.12278)
*Yingquan Li,Jiajie Xu,Bodhibrata Mukhopadhyay,Mohamed-Slim Alouini*

Main category: eess.SP

TL;DR: 提出一种基于加权RSS和广义信任域子问题(GTRS)的水下无线传感器网络定位方法GUTP，无需已知发射功率，可同时估计目标节点位置和发射功率。


<details>
  <summary>Details</summary>
Motivation: 水下无线传感器网络(UWSN)部署成本高且面临挑战，基于接收信号强度(RSS)的定位方法因其硬件要求低和成本效益高而成为可行方案。传统方法需要已知目标节点发射功率，限制了实际应用。

Method: 1) 对RSS测量值分配基于距离的权重，使更近的锚节点具有更高可靠性；2) 使用加权RSS测量和广义信任域子问题(GTRS)提出GUTP方法；3) GUTP通过简单二分法求解，可同时估计目标节点位置和发射功率；4) 推导了已知和未知发射功率情况下的Cramer-Rao下界(CRLB)。

Result: 广泛仿真表明，与现有的基于半定规划(SDP)的技术相比，GUTP在估计目标节点位置和发射功率方面实现了更高的精度和显著更低的计算复杂度。

Conclusion: GUTP方法通过加权RSS和GTRS框架，无需已知发射功率即可实现高效水下定位，具有更高的实用性和更低的计算复杂度，为水下无线传感器网络定位提供了有效解决方案。

Abstract: Underwater wireless sensor networks (UWSNs) have received significant attention due to their various applications, with underwater target localization playing a vital role in enhancing network performance. Given the challenges and high costs associated with UWSN deployments, Received Signal Strength (RSS)-based localization offers a viable solution due to its minimal hardware requirements and cost-effectiveness. In this paper, we assign distance-based weights to RSS measurements, providing higher reliability to closer anchor nodes. Using the weighted RSS measurements and generalized trust region subproblem (GTRS), we propose the GTRS-based localization technique with Unknown Transmit Power (GUTP), which can be solved by a simple bisection method. Unlike conventional localization methods that require prior knowledge of the target node's transmit power, GUTP jointly estimates both the location and transmit power of the target node, broadening its practical use. Additionally, we derive the Cramer-Rao lower bounds (CRLBs) for RSS-based underwater localization with known and unknown transmit power, respectively. Extensive simulations demonstrate that GUTP achieves enhanced accuracy and significantly lower computational complexity in estimating the target node's location and transmit power compared to existing semidefinite programming (SDP)-based techniques.

</details>


### [16] [Overcoming BS Down-Tilt for Air-Ground ISAC Coverage: Antenna Design, Beamforming and User Scheduling](https://arxiv.org/abs/2601.12281)
*Lingyi Zhu,Zhongxiang Wei,Fan Liu,Jianjun Wu,Xiao-Wei Tang,Christos Masouros,Shanpu Shen*

Main category: eess.SP

TL;DR: 提出一种新型天线结构，通过全向转向板与有源阵列协作实现全空间波束成形，解决传统基站无法感知空中目标的问题，并优化用户调度、被动系数和波束成形以最大化感知通信互信息。


<details>
  <summary>Details</summary>
Motivation: 传统下倾基站主要为地面服务提供扇区前向波束，存在后向盲区无法感知空中目标，而低空经济应用需要同时实现全空间感知与通信。

Method: 提出新型天线结构：用全向转向板替代传统反射器，与有源阵列协作实现全向波束成形。将问题分解为两个子问题：1) 在流形上通过黎曼梯度优化被动系数；2) 优化用户调度和有源阵列波束成形。利用感知通信互信息、数据解码MMSE和参数估计MMSE之间的关系，将原问题等价转化为加权MMSE问题。

Result: 仿真表明，所提算法在总互信息和均方误差方面优于基线方法，同时提供360度感知覆盖。波束图分析进一步证明了有效的用户调度和准确的目标对准。

Conclusion: 该研究提出了一种创新的天线结构和优化算法，成功解决了传统基站无法感知空中目标的问题，实现了同时全空间感知与通信，为低空经济应用提供了有效的技术方案。

Abstract: Integrated sensing and communication holds great promise for low-altitude economy applications. However, conventional downtilted base stations primarily provide sectorized forward lobes for ground services, failing to sense air targets due to backward blind zones. In this paper, a novel antenna structure is proposed to enable air-ground beam steering, facilitating simultaneous full-space sensing and communication (S&C). Specifically, instead of inserting a reflector behind the antenna array for backlobe mitigation, an omni-steering plate is introduced to collaborate with the active array for omnidirectional beamforming. Building on this hardware innovation, sum S&C mutual information (MI) is maximized, jointly optimizing user scheduling, passive coefficients of the omni-steering plate, and beamforming of the active array. The problem is decomposed into two subproblems: one for optimizing passive coefficients via Riemannian gradient on the manifold, and the other for optimizing user scheduling and active array beamforming. Exploiting relationships among S&C MI, data decoding MMSE, and parameter estimation MMSE, the original subproblem is equivalently transformed into a sum weighted MMSE problem, rigorously established via the Lagrangian and first-order optimality conditions. Simulations show that the proposed algorithm outperforms baselines in sum-MI and MSE, while providing 360 sensing coverage. Beampattern analysis further demonstrates effective user scheduling and accurate target alignment.

</details>


### [17] [RIS-Enhanced Information-Decoupled Symbiotic Radio Over Broadcasting Signals](https://arxiv.org/abs/2601.12403)
*Shu Cai,Ya-Feng Liu,Jun Zhan,Qi Zhang*

Main category: eess.SP

TL;DR: 本文研究了一种RIS增强的解耦共生无线电系统，其中主发射器向多个主接收器发送公共数据，而基于RIS的反向散射设备向反向散射接收器发送次要数据。与传统SR不同，BRx执行能量检测而不解码主信号，从而消除模糊性并防止主负载暴露给非目标接收器。


<details>
  <summary>Details</summary>
Motivation: 传统共生无线电系统中，反向散射接收器需要解码主信号，这会导致主负载暴露给非目标接收器，存在安全隐患。本文旨在设计一种解耦的RIS增强SR系统，通过能量检测而非信号解码来保护主数据隐私，同时提高系统能效。

Method: 提出RIS增强的解耦共生无线电系统架构，将问题建模为在满足所有PRs的公共广播速率约束和BRx的误码率约束下的发射功率最小化问题。针对非凸的单位模RIS约束和耦合二次形式，采用速率平衡重构和单调BER比表征，开发了基于惩罚的块坐标下降算法，具有闭式更新。

Result: 数值结果表明，所提算法收敛速度快，与传统SR基线相比，所考虑的RIS增强信息解耦SR系统能够显著降低功耗。

Conclusion: 本文提出的RIS增强解耦共生无线电系统通过能量检测而非信号解码，有效保护了主数据隐私，同时通过高效的优化算法实现了功率最小化，为安全高效的无线通信系统设计提供了新思路。

Abstract: This paper studies a reconfigurable intelligent surface (RIS)-enhanced decoupled symbiotic radio (SR) system in which a primary transmitter delivers common data to multiple primary receivers (PRs), while a RIS-based backscatter device sends secondary data to a backscatter receiver (BRx). Unlike conventional SR, the BRx performs energy detection and never decodes the primary signal, thereby removing ambiguity and preventing exposure of the primary payload to unintended receivers. In this paper, we formulate the problem as the minimization of the transmit power subject to a common broadcast rate constraint across all PRs and a bit error rate (BER) constraint at the BRx. The problem is nonconvex due to the unit-modulus RIS constraint and coupled quadratic forms. Leveraging a rate-balanced reformulation and a monotonic BER ratio characterization, we develop a low-complexity penalty-based block coordinate descent algorithm with closed-form updates. Numerical results show fast convergence of the proposed algorithm and reduced power consumption of the considered RIS-enhanced information-decoupled SR system over conventional SR baselines.

</details>


### [18] [Temporal Data and Short-Time Averages Improve Multiphase Mass Flow Metering](https://arxiv.org/abs/2601.12433)
*Amanda Nyholm,Yessica Arellano,Jinyu Liu,Damian Krakowiak,Pierluigi Salvo Rossi*

Main category: eess.SP

TL;DR: 该论文提出通过保留时间信息来改进机器学习模型在科里奥利质量流量计多相流测量中的性能，使用CNN在0.25Hz下获得最佳结果，相对误差低于13%的比例达95%。


<details>
  <summary>Details</summary>
Motivation: 当前流量测量仪器在多相流条件下准确性不足，而科里奥利质量流量计作为广泛使用的单相流量计，结合机器学习算法可以校正多相流测量误差，但现有方法通常将实验数据压缩为单个平均样本，忽略了时间信息的重要性。

Method: 比较了多层感知器、窗口多层感知器和卷积神经网络在342个三相空气-水-油流动实验数据上的性能。不同于传统方法将每个实验压缩为单个平均样本，该方法计算实验内的短时平均值，在多个下采样间隔下保留时间信息进行模型训练。

Result: CNN在0.25Hz下表现最佳：约95%的相对误差低于13%，归一化均方根误差为0.03，平均绝对百分比误差约为4.3%。明显优于最佳单平均模型，证明在单个实验内进行短时平均更优。结果在多个数据分割和随机种子下保持一致，显示了鲁棒性。

Conclusion: 保留时间信息显著提高了机器学习模型在多相流测量中的性能，短时平均方法优于传统的实验整体平均方法，CNN在适当的下采样频率下能够有效校正科里奥利流量计的多相流测量误差。

Abstract: Reliable flow measurements are essential in many industries, but current instruments often fail to accurately estimate multiphase flows, which are frequently encountered in real-world operations. Combining machine learning (ML) algorithms with accurate single-phase flowmeters has therefore received extensive research attention in recent years. The Coriolis mass flowmeter is a widely used single-phase meter that provides direct mass flow measurements, which ML models can be trained to correct, thereby reducing measurement errors in multiphase conditions. This paper demonstrates that preserving temporal information significantly improves model performance in such scenarios. We compare a multilayer perceptron, a windowed multilayer perceptron, and a convolutional neural network (CNN) on three-phase air-water-oil flow data from 342 experiments. Whereas prior work typically compresses each experiment into a single averaged sample, we instead compute short-time averages from within each experiment and train models that preserve temporal information at several downsampling intervals. The CNN performed best at 0.25 Hz with approximately 95 % of relative errors below 13 %, a normalized root mean squared error of 0.03, and a mean absolute percentage error of approximately 4.3 %, clearly outperforming the best single-averaged model and demonstrating that short-time averaging within individual experiments is preferable. Results are consistent across multiple data splits and random seeds, demonstrating robustness.

</details>


### [19] [The Effect of Noise Correlation on MMSE Channel Estimation in One-Bit Quantized Systems](https://arxiv.org/abs/2601.12482)
*Minhua Ding,Prathapasinghe Dharmawansa,Italo Atzeni,Antti Tölli*

Main category: eess.SP

TL;DR: 分析空间相关加性噪声对MIMO信道从1比特量化观测中MMSE估计的影响，推导了通用MMSE估计器表达式，发现噪声相关在特定条件下可改善或恶化估计性能。


<details>
  <summary>Details</summary>
Motivation: 在实际场景中，加性噪声可能由于干扰、杂波或其他外部干扰而具有空间相关性，但这种相关性对1比特量化观测下MIMO信道MMSE估计的影响尚未被充分研究。

Method: 推导了适用于任意信道和噪声相关结构的通用MIMO MMSE信道估计器解析表达式，并针对具有单参数恒定相关结构的信道和噪声，将通用表达式特化为可处理的多天线配置。

Result: 分析揭示了非平凡的噪声相关诱导场景：即使信道和噪声相关参数非零，估计器仍保持线性。在中低信噪比下，当信道不相关时，噪声相关可改善MMSE性能；但当信道强相关时，噪声相关会降低性能。

Conclusion: 噪声空间相关性对1比特量化MIMO信道估计有重要影响，在某些条件下可改善估计性能，而在其他条件下会恶化性能，这为实际系统设计提供了重要指导。

Abstract: This paper analyzes the impact of spatially correlated additive noise on the minimum mean-square error (MMSE) estimation of multiple-input multiple-output (MIMO) channels from one-bit quantized observations. Although additive noise can be correlated in practical scenarios, e.g., due to jamming, clutter, or other external disturbances, the effect of such correlation on the MMSE channel estimator in this setting remains unexplored in prior work. Against this backdrop, we derive a novel analytical expression for the general MIMO MMSE channel estimator, which is inherently nonlinear in one-bit observations, and accommodates arbitrary channel and noise correlation structures. To further characterize the impact of noise correlation, we subsequently specialize the general MMSE expression to certain tractable multi antenna configurations in which both the channel and the noise assume single-parameter constant correlation structures. Our analyses reveal nontrivial, noise-correlation-induced scenarios in which the estimator remains linear despite non-zero channel and noise correlation parameters. Moreover, the results indicate that, at low-to-medium signal-to-noise ratio, noise correlation improves the MMSE performance when channels are uncorrelated, but degrades performance when channels are strongly correlated.

</details>


### [20] [Automated Angular Received-Power Characterization of Embedded mmWave Transmitters Using Geometry-Calibrated Spatial Sampling](https://arxiv.org/abs/2601.12562)
*Maaz Qureshi,Mohammad Omid Bagheri,Abdelrahman Elbadrawy,William Melek,George Shaker*

Main category: eess.SP

TL;DR: 提出RAPTAR系统，使用协作机器人和几何校准的空间采样，实现嵌入式毫米波发射器在真实安装条件下的自动化角度接收功率测量。


<details>
  <summary>Details</summary>
Motivation: 传统探针台技术角度覆盖有限且对准可变性大，而消声室测试对平台安装的主动模块不实用，需要一种能在真实安装约束下进行角度接收功率测量的方法。

Method: 使用协作机器人执行几何校准、碰撞感知的半球轨迹，携带校准接收探针围绕固定被测设备进行可控可重复的空间定位；基于频谱分析仪的接收链在准静态姿态稳定后获取角度和距离相关的幅度接收功率。

Result: 对60GHz雷达模块的实验结果显示，相对于仿真参考的平均绝对接收功率误差低于2dB，比手动探针台测量误差减少36.5%，主要归因于减少了对准可变性和一致的空间采样。

Conclusion: 该方法无需相干场测量和近场变换，实现了嵌入式毫米波模块的实用功率域表征，特别适用于传统消声室测量不切实际的真实平台角度验证。

Abstract: This paper presents an automated measurement methodology for angular received-power characterization of embedded millimeter-wave transmitters using geometry-calibrated spatial sampling. Characterization of integrated mmWave transmitters remains challenging due to limited angular coverage and alignment variability in conventional probe-station techniques, as well as the impracticality of anechoic-chamber testing for platform-mounted active modules. To address these challenges, we introduce RAPTAR, an autonomous measurement system for angular received-power acquisition under realistic installation constraints. A collaborative robot executes geometry-calibrated, collision-aware hemispherical trajectories while carrying a calibrated receive probe, enabling controlled and repeatable spatial positioning around a fixed device under test. A spectrum-analyzer-based receiver chain acquires amplitude-only received power as a function of angle and distance following quasi-static pose stabilization. The proposed framework enables repeatable angular received-power mapping and power-domain comparison against idealized free-space references derived from full-wave simulation. Experimental results for a 60-GHz radar module demonstrate a mean absolute received-power error below 2 dB relative to simulation-derived references and a 36.5 % reduction in error compared to manual probe-station measurements, attributed primarily to reduced alignment variability and consistent spatial sampling. The proposed method eliminates the need for coherent field measurements and near-field transformations, enabling practical power-domain characterization of embedded mmWave modules. It is well suited for angular validation in real-world platforms where conventional anechoic measurements are impractical.

</details>


### [21] [Millimeter-Wave Multi-Radar Tracking System Enabled by a Modified GRIN Luneburg Lens for Real-Time Healthcare Monitoring](https://arxiv.org/abs/2601.12629)
*Mohammad Omid Bagheri,Justin Chow,Josh Visser,Veronica Leong,George Shaker*

Main category: eess.SP

TL;DR: 提出一种基于改进球形梯度折射率Luneburg透镜的同步毫米波多雷达跟踪系统，用于非接触式人体运动监测和跌倒检测，具有140度宽角度覆盖和12dB增益提升。


<details>
  <summary>Details</summary>
Motivation: 在医疗保健环境中，需要非接触式、保护隐私的运动跟踪和生命体征监测系统。传统雷达系统存在角度分辨率有限、相互干扰等问题，需要开发更紧凑、低成本且可扩展的毫米波传感平台。

Method: 采用五个工作在58-63GHz频段的商用FMCW雷达模块，以半圆形配置围绕改进的球形梯度折射率Luneburg透镜排列。透镜的定制折射率剖面适应双静态雷达模块，实现共置的发射和接收天线。通过基于Python的集中采集框架实现时间同步，支持并行数据采集和低延迟运动跟踪。

Result: 10厘米直径3D打印原型显示每个模块增益提升约12dB，显著改善检测范围。全波仿真和测量证实了在五个28度扇区（总计140度角度覆盖）内有效的非接触式人体运动检测。跌倒检测实验验证了可靠的宽角度性能和连续空间跟踪。

Conclusion: 该系统为毫米波传感提供了一个紧凑、低成本、可扩展的平台，适用于环境医疗保健和智能环境应用，具有改进的角分辨率、最小互干扰和隐私保护特性。

Abstract: Multi-beam radar sensing systems are emerging as powerful tools for non-contact motion tracking and vital-sign monitoring in healthcare environments. This paper presents the design and experimental validation of a synchronized millimeter-wave multi-radar tracking system enhanced by a modified spherical gradient-index (GRIN) Luneburg lens. Five commercial FMCW radar modules operating in the 58--63 GHz band are arranged in a semi-circular configuration around the lens, whose tailored refractive-index profile accommodates bistatic radar modules with co-located transmit (TX) and receive (RX) antennas. The resulting architecture generates multiple fixed high-gain beams with improved angular resolution and minimal mutual interference. Each radar operates independently but is temporally synchronized through a centralized Python-based acquisition framework to enable parallel data collection and low-latency motion tracking. A 10-cm-diameter 3D-printed prototype demonstrates a measured gain enhancement of approximately 12 dB for each module, corresponding to a substantial improvement in detection range. Full-wave simulations and measurements confirm effective non-contact, privacy-preserving short-range human-motion detection across five 28-degree sectors, providing 140-degree total angular coverage. Fall-detection experiments further validate reliable wide-angle performance and continuous spatial tracking. The proposed system offers a compact, low-cost, and scalable platform for millimeter-wave sensing in ambient healthcare and smart-environment applications.

</details>


### [22] [Two-Layer Reinforcement Learning-Assisted Joint Beamforming and Trajectory Optimization for Multi-UAV Downlink Communications](https://arxiv.org/abs/2601.12659)
*Ruiqi Wang,Essra M. Ghoura,Omar Alhussein,Yuzhi Yang,Yuhang Sheng,Jing Ren,Shizhong Xu,Sami Muhaidat*

Main category: eess.SP

TL;DR: 本文提出了一种分层解耦框架，结合图神经网络和多智能体强化学习，用于解决无人机网络中波束成形和轨迹设计的复杂耦合优化问题，实现了亚毫秒级推理和显著的系统性能提升。


<details>
  <summary>Details</summary>
Motivation: 无人机在6G非地面网络中至关重要，但其高移动性导致波束成形和轨迹设计形成复杂的耦合优化问题。现有数值方法延迟过高，而标准深度学习方法往往忽略动态干扰拓扑，限制了可扩展性。

Method: 提出分层解耦框架：短时间尺度上，开发基于GraphNorm的拓扑感知GNN波束成形器，将动态无人机-用户关联建模为时变异构图；长时间尺度上，将轨迹规划建模为分散部分可观测马尔可夫决策过程，采用多智能体近端策略优化算法，在集中训练分散执行范式下实现协同行为。

Result: 大量仿真结果表明，所提框架在系统总速率、收敛速度和泛化能力方面显著优于最先进的优化启发式方法和深度学习基线。

Conclusion: 该分层解耦框架成功解决了无人机网络中波束成形和轨迹设计的复杂优化问题，通过GNN和多智能体强化学习的协同，实现了高效、可扩展的解决方案，为未来6G非地面网络提供了有前景的技术路径。

Abstract: Unmanned aerial vehicles (UAVs) are pivotal for future 6G non-terrestrial networks, yet their high mobility creates a complex coupled optimization problem for beamforming and trajectory design. Existing numerical methods suffer from prohibitive latency, while standard deep learning often ignores dynamic interference topology, limiting scalability. To address these issues, this paper proposes a hierarchically decoupled framework synergizing graph neural networks (GNNs) with multi-agent reinforcement learning. Specifically, on the short timescale, we develop a topology-aware GNN beamformer by incorporating GraphNorm. By modeling the dynamic UAV-user association as a time-varying heterogeneous graph, this method explicitly extracts interference patterns to achieve sub-millisecond inference. On the long timescale, trajectory planning is modeled as a decentralized partially observable Markov decision process and solved via the multi-agent proximal policy optimization algorithm under the centralized training with decentralized execution paradigm, facilitating cooperative behaviors. Extensive simulation results demonstrate that the proposed framework significantly outperforms state-of-the-art optimization heuristics and deep learning baselines in terms of system sum rate, convergence speed, and generalization capability.

</details>


### [23] [Energy-Efficient Prediction in Textile Manufacturing: Enhancing Accuracy and Data Efficiency With Ensemble Deep Transfer Learning](https://arxiv.org/abs/2601.12663)
*Yan-Chen Chen,Wei-Yu Chiu,Qun-Yu Wang,Jing-Wei Chen,Hao-Ting Zhao*

Main category: eess.SP

TL;DR: 提出Ensemble Deep Transfer Learning (EDTL)框架，通过集成迁移学习和特征对齐层，在数据有限场景下提升纺织工厂能耗预测精度和数据效率


<details>
  <summary>Details</summary>
Motivation: 传统纺织工厂能耗高，需要节能优化；深度神经网络需要大量历史数据，但传感器部署和数据收集成本高昂，在数据有限场景下效果受限

Method: 提出EDTL框架：1）在数据丰富的生产线（源域）预训练DNN模型；2）通过特征对齐层适应数据有限的生产线（目标域）；3）集成策略提升鲁棒性；减少对大数据集的依赖

Result: 在真实纺织工厂数据集上，EDTL比传统DNN预测精度提升5.66%，模型鲁棒性提升3.96%，在数据有限场景（20%-40%数据可用性）表现尤其突出

Conclusion: EDTL为纺织制造提供了可扩展、成本效益高的智能生产解决方案，通过更少数据需求实现准确预测，促进能源高效生产

Abstract: Traditional textile factories consume substantial energy, making energy-efficient production optimization crucial for sustainability and cost reduction. Meanwhile, deep neural networks (DNNs), which are effective for factory output prediction and operational optimization, require extensive historical data, posing challenges due to high sensor deployment and data collection costs. To address this, we propose Ensemble Deep Transfer Learning (EDTL), a novel framework that enhances prediction accuracy and data efficiency by integrating transfer learning with an ensemble strategy and a feature alignment layer. EDTL pretrains DNN models on data-rich production lines (source domain) and adapts them to data-limited lines (target domain), reducing dependency on large datasets. Experiments on real-world textile factory datasets show that EDTL improves prediction accuracy by 5.66% and enhances model robustness by 3.96% compared to conventional DNNs, particularly in data-limited scenarios (20%-40% data availability). This research contributes to energy-efficient textile manufacturing by enabling accurate predictions with fewer data requirements, providing a scalable and cost-effective solution for smart production systems.

</details>


### [24] [Energy-Based Cell Association in Nonuniform Renewable Energy-Powered Cellular Networks: Analysis and Optimization of Carbon Efficiency](https://arxiv.org/abs/2601.12708)
*Yuxi Zhao,Vicente Casares-Giner,Vicent Pla,Luis Guijarro,Iztok Humar,Yi Zhong,Xiaohu Ge*

Main category: eess.SP

TL;DR: 本文提出了一种基于能量的蜂窝关联方案，通过优化可再生能源利用来平衡碳排放与下行吞吐量，相比最近蜂窝关联方案可减少13.0%碳排放并提高11.3%碳效率。


<details>
  <summary>Details</summary>
Motivation: 全球碳减排需求推动可再生能源在蜂窝网络中的应用，但可再生能源发电的随机性和基站负载分布不均导致其利用率低，需要在网络性能和可持续性之间找到平衡。

Method: 将基站电池的可再生能源状态和占用信道数建模为准生灭过程，基于随机几何构建信道阻塞概率、用户平均成功传输概率、下行吞吐量、碳排放和碳效率模型，提出基于能量的蜂窝关联方案优化碳效率。

Result: 相比最近蜂窝关联方案，基于能量的蜂窝关联方案能够减少网络碳排放13.0%，提高碳效率11.3%。

Conclusion: 基于能量的蜂窝关联方案能有效优化蜂窝网络的碳效率，在保持网络性能的同时显著降低碳排放，为实现可持续蜂窝网络提供了有效方法。

Abstract: The increasing global push for carbon reduction highlights the importance of integrating renewable energy into the supply chain of cellular networks. However, due to the stochastic nature of renewable energy generation and the uneven load distribution across base stations, the utilization rate of renewable energy remains low. To address these challenges, this paper investigates the trade-off between carbon emissions and downlink throughput in cellular networks, offering insights into optimizing both network performance and sustainability. The renewable energy state of base station batteries and the number of occupied channels are modeled as a quasi-birth-death process. We construct models for the probability of channel blocking, average successful transmission probability for users, downlink throughput, carbon emissions, and carbon efficiency based on stochastic geometry. Based on these analyses, an energy-based cell association scheme is proposed to optimize the carbon efficiency of cellular networks. The results show that, compared to the closest cell association scheme, the energy-based cell association scheme is capable of reducing the carbon emissions of the network by 13.0% and improving the carbon efficiency by 11.3%.

</details>


### [25] [Robust Beamforming and Time Allocation for Time-Division Cell-Free Near-Field ISAC](https://arxiv.org/abs/2601.12725)
*Chaedam Son,Si-Hyeon Lee*

Main category: eess.SP

TL;DR: 提出了一种用于无蜂窝MIMO的时分近场集成感知与通信框架，通过感知阶段估计用户位置构建位置感知信道，在通信阶段利用这些信道，并联合优化时间分配比、感知协方差矩阵和鲁棒下行波束成形。


<details>
  <summary>Details</summary>
Motivation: 传统远场和单基地感知系统在定位精度和信道估计方面存在局限，需要一种能够同时优化感知精度和通信吞吐量的集成框架，特别是在近场无蜂窝MIMO场景下。

Method: 采用时分框架分离感知和通信阶段；感知阶段估计用户位置并构建位置感知信道；显式建模定位误差与信道估计误差之间的耦合关系；通过SDP重构和交替优化联合优化时间分配比、感知协方差矩阵和鲁棒下行波束成形；提出两种低复杂度次优方案：误差忽略方案和基于MRT的方案。

Result: 仿真结果表明，所提方案相比远场和单基地设置显著提高了定位精度，减少了信道估计误差，最终提升了可达速率；误差忽略方案在严格感知要求下表现良好，而基于MRT的方案通过自适应调整时间分配比，在广泛的感知要求范围内保持鲁棒性。

Conclusion: 提出的时分近场无蜂窝MIMO ISAC框架有效平衡了感知精度和通信吞吐量，通过联合优化和低复杂度设计方案，为实际系统部署提供了可行的解决方案。

Abstract: In this paper, we propose a time-division near-field integrated sensing and communication (ISAC) framework for cell-free multiple-input multiple-output (MIMO), where sensing and downlink communication are separated in time. During the sensing phase, user locations are estimated and used to construct location-aware channels, which are then exploited in the subsequent communication phase. By explicitly modeling the coupling between sensing-induced localization errors and channel-estimation errors, we capture the tradeoff between sensing accuracy and communication throughput. Based on this model, we jointly optimize the time-allocation ratio, sensing covariance matrix, and robust downlink beamforming under imperfect channel state information (CSI). The resulting non-convex problem is addressed via a semidefinite programming (SDP)-based reformulation within an alternating-optimization framework. To further reduce computational complexity, we also propose two low-complexity suboptimal designs: an error-ignorant scheme and a maximum ratio transmission (MRT)-based scheme. Simulation results show that the proposed scheme significantly improves localization accuracy over far-field and monostatic setups, thereby reducing channel estimation errors and ultimately enhancing the achievable rate. Moreover, the error-ignorant scheme performs well under stringent sensing requirements, whereas the MRT-based scheme remains robust over a wide range of sensing requirements by adapting the time-allocation ratio, albeit with some beamforming loss.

</details>


### [26] [Movable Antenna Enhanced MIMO Communications with Spatial Modulation](https://arxiv.org/abs/2601.12788)
*Kaihe Wang,Ran Yang,Lipeng Zhu,Rongyan Xi,Yue Xiu,Zhongpei Zhang*

Main category: eess.SP

TL;DR: 提出一种基于可移动天线的MIMO空间调制系统，通过联合收发器设计最小化误码率，采用交替优化和逐次凸逼近算法实现高效优化。


<details>
  <summary>Details</summary>
Motivation: 可移动天线能显著提升无线通信性能，但现有系统成本较高。本文旨在利用可移动天线的灵活部署优势，结合空间调制技术，在提升通信性能的同时降低射频链成本。

Method: 提出基于最大最小距离准则的联合收发器设计框架，采用交替优化和逐次凸逼近技术开发高效迭代算法，解决难处理的优化问题。

Result: 仿真结果表明，所提算法收敛速度快，性能显著优于现有基准方案。

Conclusion: 可移动天线与空间调制的结合能有效提升MIMO系统性能并降低成本，所提算法为实际部署提供了有效解决方案。

Abstract: Movable antenna (MA) has demonstrated great potential in enhancing wireless communication performance. In this paper, we investigate an MA-enabled multiple-input multiple-output (MIMO) communication system with spatial modulation (SM), which improves communication performance by utilizing flexible MA placement while reducing the cost of RF chains. To this end, we propose a joint transceiver design framework aimed at minimizing the bit error rate (BER) based on the maximum minimum distance (MMD) criterion. To address the intractable problem, we develop an efficient iterative algorithm based on alternating optimization (AO) and successive convex approximation (SCA) techniques. Simulation results demonstrate that the proposed algorithm achieves rapid convergence performance and significantly outperforms the existing benchmark schemes.

</details>


### [27] [Integrated Sensing and Semantic Communication with Adaptive Source-Channel Coding](https://arxiv.org/abs/2601.12827)
*Haotian Wang,Dan Wang,Xiaodong Xu,Chuan Huang,Hao Chen,Nan Ma*

Main category: eess.SP

TL;DR: 提出自适应源信道编码和波束赋形框架，用于集成感知与语义通信系统，通过联合优化语义通信编码率和感知波束赋形来最小化语义失真


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注感知数据压缩以减少通信开销，但缺乏同时考虑语义通信和感知任务的集成传输框架。需要设计能够同时优化语义通信编码率和感知波束赋形的系统架构

Method: 1) 推导端到端语义失真函数的上界；2) 推导不完美时间同步下的目标位置混合克拉美-罗界；3) 构建考虑HCRB阈值、信道使用和功率预算的失真最小化问题；4) 提出基于逐次凸逼近和分式规划的交替优化算法，将问题分解为编码率和波束赋形两个子问题

Result: 仿真结果表明，所提方案优于传统的深度联合源信道编码-注水-迫零基准方案

Conclusion: 该框架成功实现了集成感知与语义通信系统的联合优化，通过自适应源信道编码和波束赋形设计，在满足感知精度要求的同时最小化语义失真，为6G集成系统提供了有效解决方案

Abstract: Semantic communication has emerged as a new paradigm to facilitate the performance of integrated sensing and communication systems in 6G. However, most of the existing works mainly focus on sensing data compression to reduce the subsequent communication overheads, without considering the integrated transmission framework for both the SemCom and sensing tasks. This paper proposes an adaptive source-channel coding and beamforming design framework for integrated sensing and SemCom systems by jointly optimizing the coding rate for SemCom task and the transmit beamforming for both the SemCom and sensing tasks. Specifically, an end-to-end semantic distortion function is approximated by deriving an upper bound composing of source and channel coding induced components, and then a hybrid Cramér-Rao bound (HCRB) is also derived for target position under imperfect time synchronization. To facilitate the joint optimization, a distortion minimization problem is formulated by considering the HCRB threshold, channel uses, and power budget. Subsequently, an alternative optimization algorithm composed of successive convex approximation and fractional programming is proposed to address this problem by decoupling it into two subproblems for coding rate and beamforming designs, respectively. Simulation results demonstrate that our proposed scheme outperforms the conventional deep joint source-channel coding -water filling-zero forcing benchmark.

</details>


### [28] [Angular Sensing by Highly Reconfigurable Pixel Antennas with Joint Radiating Aperture and Feeding Ports Reconfiguration](https://arxiv.org/abs/2601.12867)
*Zixiang Han,Hanning Wang,Shiwen Tang,Yujie Zhang*

Main category: eess.SP

TL;DR: 提出高度可重构像素天线(HRPA)，通过联合辐射孔径和馈电端口重构实现角度感知能力，相比传统均匀平面阵列将角度估计误差降低50%以上。


<details>
  <summary>Details</summary>
Motivation: 传统像素天线只有固定位置的单个馈电端口，对于角度感知不够高效。需要扩展像素天线的可重构性，同时控制天线几何形状和切换馈电端口，以提升角度感知性能。

Method: 提出高度可重构像素天线(HRPA)，建立包含电路和辐射参数的模型，定义包含像素连接状态和馈电端口位置的码本，开发优化方法最小化克拉美-罗下界(CRLB)以获得最优HRPA几何形状。

Result: HRPA在全三维球面上将角度估计误差降低超过50%，相比相同尺寸的传统均匀平面阵列显著提升了角度感知性能。

Conclusion: HRPA通过联合辐射孔径和馈电端口重构有效提升了角度感知能力，展示了在集成感知和通信系统中的潜力。

Abstract: Angular sensing capability is realized using highly reconfigurable pixel antenna (HRPA) with joint radiating aperture and feeding ports reconfiguration. Pixel antennas represent a general class of reconfigurable antenna designs in which the radiating surface, regardless of its shape or size, is divided into sub-wavelength elements called pixels. Each pixel is connected to its neighboring elements through radio frequency switches. By controlling pixel connections, the pixel antenna topology can be flexibly adjusted so that the resulting radiation pattern can be reconfigured. However, conventional pixel antennas have only a single, fixed-position feeding port, which is not efficient for angular sensing. Therefore, in this work, we further extend the reconfigurability of pixel antennas by introducing the HRPA, which enables both geometry control of the pixel antenna and switching of its feeding ports. The model of the proposed HRPA, including both circuit and radiation parameters, is derived. A codebook is then defined, consisting of pixel connection states and feeding port positions for each sensing area. Based on this codebook, an efficient optimization approach is developed to minimize the Cram\acute{\mathrm{\mathbf{e}}}r-Rao lower bound (CRLB) and obtain the optimal HRPA geometries for angular sensing within a given area. Numerical results show that the HRPA reduces the angle estimation error by more than 50% across the full three-dimensional sphere when compared with a conventional uniform planar array of the same size. This demonstrates the effectiveness of the proposed approach and highlights the potential of HRPA for integrated sensing and communication systems.

</details>


### [29] [Fluid Antenna Relay (FAR)-assisted Communication with Hybrid Relaying Scheme Selection](https://arxiv.org/abs/2601.12924)
*Ruopeng Xu,Songling Zhang,Zhaohui Yang,Mingzhe Chen,Zhaoyang Zhang,Kai-Kit Wong*

Main category: eess.SP

TL;DR: 本文研究了采用混合中继方案选择的流体天线中继通信系统，通过高斯copula方法近似不同中继方案的断线概率，基于OP最小化原则选择转发方案，并解决半双工模式带来的速率损失问题。


<details>
  <summary>Details</summary>
Motivation: 流体天线系统(FAS)具有空间自由度优势，但中继系统中的混合方案选择和半双工模式会引入速率损失，需要优化系统性能。

Method: 利用统计CSI和FAS分布特性，采用高斯copula方法近似断线概率；基于OP最小化原则选择中继方案；通过功率控制优化解决半双工速率损失问题，将非凸问题转化为功率控制优化问题。

Result: 仿真结果验证了所提算法能有效提高系统总速率。

Conclusion: 提出的流体天线中继系统混合方案选择和功率控制优化方法能有效改善系统性能，提高总速率。

Abstract: In this paper, we investigate a fluid antenna relay (FAR)-assisted communication system with hybrid relaying scheme selection. By leveraging statistical channel state information (CSI) and distribution characteristics of fluid antenna system (FAS), we approximate the outage probability (OP) with different relaying schemes utilizing a Gaussian copula-based method. Each relay node follows the OP-minimized principle to choose the forwarding schemes. To reduce self-interference and avoid multi-user interference, half-duplex relays and frequency division multiple access schemes are considered, respectively. On this basis, we formulate a sum-rate maximization problem to mitigate the rate loss introduced by the half-duplex mode. To solve this problem, we first transform the original nonconvex problem into a power control optimization problem by obtaining the closed form of bandwidth allocation and substituting it into the original problem. Then, we solve the power control optimization problem with a low complexity method. Simulation results verify the effectiveness of our proposed algorithm to improve the sum rate of the system.

</details>


### [30] [Monostatic ISAC Without Full Buffers: Revisiting Spatial Trade-Offs Under Bursty Traffic](https://arxiv.org/abs/2601.12963)
*Mauro Marchese,Musa Furkan Keskin,Pietro Savazzi,Henk Wymeersch*

Main category: eess.SP

TL;DR: 研究突发流量下ISAC基站发射波束成形设计中的空间权衡，揭示了三种影响ISAC性能的效应：数据辅助策略的SNR提升、非满缓冲区假设导致的检测概率饱和，以及目标与用户相对位置引起的方向性遮蔽。


<details>
  <summary>Details</summary>
Motivation: 下一代无线系统需要集成通信和感知功能，但在突发流量场景下，基站并不总是有数据可用于传输。这导致ISAC设计面临空间权衡问题，需要研究不同ISAC策略的性能影响。

Method: 研究比较了不同的ISAC策略，分析了在突发流量场景下基站发射波束成形设计。通过仿真验证了三种关键效应：数据辅助策略与导频策略的SNR对比、非满缓冲区假设对检测概率的影响、以及目标与用户相对位置引起的方向性遮蔽。

Result: 仿真结果表明，在不同操作条件下，这三种效应对ISAC权衡的影响程度不同。数据辅助策略相比导频策略具有SNR提升优势，但受限于非满缓冲区假设，检测概率会达到饱和。目标与用户的相对位置会导致方向性遮蔽问题。

Conclusion: 研究揭示了ISAC性能受多种效应影响，这些发现为设计高效的ISAC传输策略提供了指导，特别是在突发流量场景下的波束成形设计需要考虑这些空间权衡因素。

Abstract: This work investigates the spatial trade-offs arising from the design of the transmit beamformer in a monostatic integrated sensing and communication (ISAC) base station (BS) under bursty traffic, a crucial aspect necessitated by the integration of communication and sensing functionalities in next-generation wireless systems. In this setting, the BS does not always have data available for transmission. This study compares different ISAC policies and reveals the presence of multiple effects influencing ISAC performance: signal-to-noise ratio (SNR) boosting of data-aided strategies compared to pilot-based ones, saturation of the probability of detection in data-aided strategies due to the non-full-buffer assumption, and, finally, directional masking of sensing targets due to the relative position between target and user. Simulation results demonstrate varying impact of these effects on ISAC trade-offs under different operating conditions, thus guiding the design of efficient ISAC transmission strategies.

</details>


### [31] [6G OFDM Communications with High Mobility Transceivers and Scatterers via Angle-Domain Processing and Deep Learning](https://arxiv.org/abs/2601.12970)
*Mauro Marchese,Musa Furkan Keskin,Henk Wymeersch,Pietro Savazzi*

Main category: eess.SP

TL;DR: 提出一种利用角度域分离多径的OFDM接收机架构，通过块状导频估计多径参数，采用决策导向方法迭代优化多普勒估计，DL方法在6G最高速度1000 km/h下保持恒定BER性能


<details>
  <summary>Details</summary>
Motivation: 高速移动通信导致OFDM波形因多普勒效应产生强载波间干扰，需要解决高速场景下的ICI问题

Method: 提出新颖接收机架构：1) 使用块状导频估计多径的到达方向、传播延迟和信道增益；2) 采用决策导向方法迭代优化多普勒估计；3) 研究两种初始多普勒估计方法：基于误差矢量幅度的方法和基于深度学习的方法

Result: 仿真结果表明，基于深度学习的方法能够在6G最高速度1000 km/h下保持恒定的误码率性能

Conclusion: 所提出的接收机架构通过角度域多径分离和迭代多普勒估计，有效解决了高速移动场景下的ICI问题，特别是DL方法在极端高速条件下表现出色

Abstract: High-mobility communications, which are crucial for next-generation wireless systems, cause the orthogonal frequency division multiplexing (OFDM) waveform to suffer from strong intercarrier interference (ICI) due to the Doppler effect. In this work, we propose a novel receiver architecture for OFDM that leverages the angular domain to separate multipaths. A block-type pilot is sent to estimate direction-of-arrivals (DoAs), propagation delays, and channel gains of the multipaths. Subsequently, a decision-directed (DD) approach is employed to estimate and iteratively refine the Dopplers. Two different approaches are investigated to provide initial Doppler estimates: an error vector magnitude (EVM)-based method and a deep learning (DL)-based method. Simulation results reveal that the DL-based approach allows for constant bit error rate (BER) performance up to the maximum 6G speed of 1000 km/h.

</details>


### [32] [Physics-Aware RIS Codebook Compilation for Near-Field Beam Focusing under Mutual Coupling and Specular Reflections](https://arxiv.org/abs/2601.12982)
*Alexandros I. Papadopoulos,Maria Anna Pistela,Dimitrios Tyrovolas,Antonios Lalas,Konstantinos Votis,Sotiris Ioannidis,George K. Karagiannidis,Christos Liaskos*

Main category: eess.SP

TL;DR: MATCH算法：基于物理的RIS码本编译方法，考虑单元间电磁耦合和环境反射，实现近场条件下可编程无线环境的高效配置


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络需要在强多径和严重信道变化的环境中实现可靠低延迟连接。可编程无线环境通过RIS实现电磁传播的确定性控制，但在近场条件下，RIS的实时配置面临挑战，特别是单元间互耦和镜面反射会改变预期响应。

Method: 提出MATCH算法，一种基于物理的码本编译方法，明确考虑RIS单元间的电磁耦合以及与环境结构的反射相互作用，确保生成的码本与环境物理特性保持一致。

Result: 在全波仿真框架下评估MATCH，包含互耦和二次反射效应，证明其能够将散射能量集中在焦点区域，验证了基于物理一致码本的优化是实用高效的RIS配置方法。

Conclusion: 基于物理的码本编译算法MATCH能够有效解决RIS在近场条件下的配置瓶颈，为可编程无线环境的实际应用提供了高效可靠的解决方案。

Abstract: Next-generation wireless networks are envisioned to achieve reliable, low-latency connectivity within environments characterized by strong multipath and severe channel variability. Programmable wireless environments (PWEs) address this challenge by enabling deterministic control of electromagnetic (EM) propagation through software-defined reconfigurable intelligent surfaces (RISs). However, effectively configuring RISs in real time remains a major bottleneck, particularly under near-field conditions where mutual coupling and specular reflections alter the intended response. To overcome this limitation, this paper introduces MATCH, a physics-based codebook compilation algorithm that explicitly accounts for the EM coupling among RIS unit cells and the reflective interactions with surrounding structures, ensuring that the resulting codebooks remain consistent with the physical characteristics of the environment. Finally, MATCH is evaluated under a full-wave simulation framework incorporating mutual coupling and secondary reflections, demonstrating its ability to concentrate scattered energy within the focal region, confirming that physics-consistent, codebook-based optimization constitutes an effective approach for practical and efficient RIS configuration.

</details>


### [33] [When Is Distributed Nonlinear Aggregation Private? Optimality and Information-Theoretical Bounds](https://arxiv.org/abs/2601.13001)
*Wenrui Yu,Jaron Skovsted Gundersen,Richard Heusdens,Qiongxiu Li*

Main category: eess.SP

TL;DR: 本文建立了非线性聚合隐私泄露的统一信息论框架，揭示了非线性算子相比线性聚合存在固有的隐私泄露下界，并提出了达到最优边界的隐私保护分布式算法。


<details>
  <summary>Details</summary>
Motivation: 非线性聚合在现代分布式系统中至关重要，但其隐私行为远不如线性聚合被充分理解。非线性算子对隐私保证存在固有的结构限制，特别是当需要精确计算聚合结果时。

Method: 开发了统一的信息论框架来分析分布式非线性聚合中的隐私泄露，涵盖两类非线性聚合：基于顺序的算子（最大值/最小值和top-K）和鲁棒聚合（中位数/分位数和截断均值）。首先推导了不牺牲准确性情况下的基本泄露下界，然后提出了简单有效的隐私保护分布式算法。

Result: 推导出了非线性聚合的最小不可避免信息泄露下界，并提出了能够达到这些最优边界的算法。实验验证了边界的紧致性，并表明网络拓扑和关键算法参数（包括步长）按照理论分析控制观察到的泄露。

Conclusion: 非线性聚合存在固有的隐私泄露限制，但通过适当的随机化初始化和参数选择，可以达到理论最优的隐私保护边界，为隐私保护非线性聚合提供了可操作的指导原则。

Abstract: Nonlinear aggregation is central to modern distributed systems, yet its privacy behavior is far less understood than that of linear aggregation. Unlike linear aggregation where mature mechanisms can often suppress information leakage, nonlinear operators impose inherent structural limits on what privacy guarantees are theoretically achievable when the aggregate must be computed exactly. This paper develops a unified information-theoretic framework to characterize privacy leakage in distributed nonlinear aggregation under a joint adversary that combines passive (honest-but-curious) corruption and eavesdropping over communication channels.
  We cover two broad classes of nonlinear aggregates: order-based operators (maximum/minimum and top-$K$) and robust aggregation (median/quantiles and trimmed mean). We first derive fundamental lower bounds on leakage that hold without sacrificing accuracy, thereby identifying the minimum unavoidable information revealed by the computation and the transcript. We then propose simple yet effective privacy-preserving distributed algorithms, and show that with appropriate randomized initialization and parameter choices, our proposed approaches can attach the derived optimal bounds for the considered operators. Extensive experiments validate the tightness of the bounds and demonstrate that network topology and key algorithmic parameters (including the stepsize) govern the observed leakage in line with the theoretical analysis, yielding actionable guidelines for privacy-preserving nonlinear aggregation.

</details>


### [34] [OTFS-IDMA: An Unsourced Multiple Access Scheme for Doubly-Dispersive Channels](https://arxiv.org/abs/2601.13065)
*Davide Bergamasco,Federico Clazzer,Paolo Casari*

Main category: eess.SP

TL;DR: 提出一种基于OTFS调制和稀疏IDMA的DD域无源多址接入方案，适用于高移动性无线信道，通过压缩感知联合活动检测和信道估计，结合MRC利用多径分集。


<details>
  <summary>Details</summary>
Motivation: 针对高移动性无线信道中的无源多址接入问题，传统方案在双选择性信道中性能受限，需要开发能有效利用延迟-多普勒域特性的新方案。

Method: 采用正交时频空间(OTFS)调制和稀疏交织分多址(IDMA)在延迟-多普勒域构建方案，接收端先进行压缩感知联合活动检测和信道估计，然后通过最大比合并(MRC)利用多径分集的单用户解码器。

Result: 数值结果表明DD域无协调方案在双选择性信道中具有潜力，同时指出了设计权衡和剩余挑战。

Conclusion: 基于OTFS和稀疏IDMA的DD域无源多址接入方案为高移动性无线通信提供了有前景的解决方案，但需要进一步解决设计权衡和挑战。

Abstract: We present an unsourced multiple access (UMAC) scheme tailored to high-mobility wireless channels. The proposed construction is based on orthogonal time frequency space (OTFS) modulation and sparse interleaver division multiple access (IDMA) in the delay-Doppler (DD) domain. The receiver runs a compressive-sensing joint activity-detection and channel estimation process followed by a single-user decoder which harnesses multipath diversity via the maximal-ratio combining (MRC) principle. Numerical results show the potential of DD-based uncoordinated schemes in the presence of double selectivity, while remarking the design tradeoffs and remaining challenges introduced by the proposed design.

</details>


### [35] [Seeing Radio: From Zero RF Priors to Explainable Modulation Recognition with Vision Language Models](https://arxiv.org/abs/2601.13157)
*Hang Zou,Bohao Wang,Yu Tian,Lina Bariah,Chongwen Huang,Samson Lasaulce,Mérouane Debbah*

Main category: eess.SP

TL;DR: 利用视觉语言模型进行射频调制识别：通过将IQ信号转换为图像，使通用VLMs能够分类调制方案，无需专门设计射频接收器。


<details>
  <summary>Details</summary>
Motivation: 随着视觉语言模型的兴起，探索其在射频感知领域的应用潜力，避免为特定任务设计专门的神经接收器，而是利用VLMs的通用能力。

Method: 提出将复杂IQ流转换为视觉可解释输入的实用管道，构建包含57类模拟/数字调制的RF视觉问答基准框架，采用三种互补图像模式：时域IQ段、幅度谱图和联合表示。

Result: 微调后的VLMs达到90%的准确率（基础模型仅10%），在噪声下表现稳健，对未见调制类型具有高泛化能力，无需射频领域先验或专门架构。

Conclusion: RF-to-image转换与可提示VLMs的结合为未来6G网络中的射频感知AI系统提供了可扩展且实用的基础。

Abstract: The rise of vision language models (VLMs) paves a new path for radio frequency (RF) perception. Rather than designing task-specific neural receivers, we ask if VLMs can learn to recognize modulations when RF waveforms are expressed as images. In this work, we find that they can. In specific, in this paper, we introduce a practical pipeline for converting complex IQ streams into visually interpretable inputs, hence, enabling general-purpose VLMs to classify modulation schemes without changing their underlying design. Building on this, we construct an RF visual question answering (VQA) benchmark framework that covers 57 classes across major families of analog/digital modulations with three complementary image modes, namely, (i) short \emph{time-series} IQ segments represented as real/imaginary traces, (ii) magnitude-only \emph{spectrograms}, and (iii) \emph{joint} representations that pair spectrograms with a synchronized time-series waveforms. We design uniform zero-shot and few-shot prompts for both class-level and family-level evaluations. Our finetuned VLMs with these images achieve competitive accuracy of $90\%$ compared to $10\%$ of the base models. Furthermore, the fine-tuned VLMs show robust performance under noise and demonstrate high generalization performance to unseen modulation types, without relying on RF-domain priors or specialized architectures. The obtained results show that combining RF-to-image conversion with promptable VLMs provides a scalable and practical foundation for RF-aware AI systems in future 6G networks.

</details>


### [36] [Decentralized Cooperative Beamforming for BDRIS-Assisted Cell-Free MIMO OFDM Systems](https://arxiv.org/abs/2601.13201)
*Konstantinos D. Katsanos,George C. Alexandropoulos*

Main category: eess.SP

TL;DR: 本文提出了一种针对宽带无小区多流多用户MIMO-OFDM系统的鲁棒去中心化主动与被动波束赋形框架，采用动态组连接BDRIS架构，通过分布式协作减少集中式处理开销，在信道状态不完美情况下实现接近全连接BDRIS性能的和速率提升。


<details>
  <summary>Details</summary>
Motivation: 传统集中式波束赋形方案需要高计算能力中央处理单元，存在较大开销。本文旨在设计一种去中心化框架，在信道状态信息不完美且基站间协作最小化的条件下，通过BDRIS实现鲁棒波束赋形，降低系统开销。

Method: 采用动态组连接BDRIS架构，考虑频率选择性响应；将和速率最大化问题表述为关于BDRIS可调电容、置换矩阵以及基站预编码矩阵的优化问题；通过逐次凹逼近、交替投影和基于共识的BDRIS设计更新算法求解。

Result: 仿真结果表明，所提出的鲁棒去中心化协作方法在不同BDRIS架构下均优于非协作基准方案；动态组连接BDRIS架构能够提供接近更复杂全连接BDRIS结构的和速率性能增益。

Conclusion: 本文提出的去中心化波束赋形框架在降低系统开销的同时，通过BDRIS的智能配置实现了接近全连接架构的性能，为未来智能无线环境中的宽带MIMO-OFDM系统提供了有效的分布式解决方案。

Abstract: In this paper, a wideband cell-free multi-stream multi-user Multiple-Input Multiple-Output (MIMO) Orthogonal Frequency Division Multiplexing (OFDM) system is considered operating within a smart wireless environment enabled by multiple Beyond Diagonal Reconfigurable Intelligent Surfaces (BDRISs). A novel decentralized active and passive beamforming framework, robust to imperfect channel state availability and with minimal cooperation among the system's multiple Base Stations (BSs) for deciding the final configurations of the shared BDRISs, is proposed, which aims to substantially reduce the overhead inherent in centralized solutions necessitating a central processing unit of high computational power. By considering a Dynamic Group-Connected (DGC) BDRIS architecture with frequency-selective responses per unit element, we formulate the system's sum-rate maximization problem with respect to the tunable capacitances and permutation matrices of the BDRISs as well as the precoding matrices of the BSs, which is solved via successive concave approximation and alternating projections as well as consensus-based updates for the BDRISs' design. Through extensive simulation results, it is showcased that the proposed robust decentralized cooperative approach with diverse BDRIS architectures outperforms non-cooperation benchmarks. It is also demonstrated that the considered DGC BDRIS architecture is able to provide sum-rate performance gains sufficiently close to the more complex fully-connected BDRIS structure.

</details>


### [37] [Hierarchical Sparse Vector Transmission for Ultra Reliable and Low Latency Communications](https://arxiv.org/abs/2601.13204)
*Yanfeng Zhang,Xi'an Fan,Jinkai Zheng,Xiaoye Jing,Weiwei Yang,Xu Zhu*

Main category: eess.SP

TL;DR: 提出一种分层稀疏向量传输方案，用于多用户超可靠低延迟通信场景，通过将传输比特分为公共和私有部分来提升性能。


<details>
  <summary>Details</summary>
Motivation: 稀疏向量传输是实现超可靠低延迟通信的有前景技术，但在多用户场景下需要更高效的方案来提升性能。

Method: 分层SVT方案将传输比特分为公共和私有部分：公共信息通过稀疏向量中非零段的索引传递，每个用户的私有信息嵌入到具有特定块长度的非零块中。接收端先检测非零段恢复公共比特，然后根据对应的非零块索引解码用户特定的私有比特。

Result: 仿真结果表明，所提方案在块错误率方面优于现有的最先进SVT方案。

Conclusion: 分层SVT方案为多用户URLLC场景提供了一种有效的通信方案，通过分层结构实现了更好的性能表现。

Abstract: Sparse vector transmission (SVT) is a promising candidate technology for achieving ultra-reliable low-latency communication (URLLC). In this paper, a hierarchical SVT scheme is proposed for multi-user URLLC scenarios. The hierarchical SVT scheme partitions the transmitted bits into common and private parts. The common information is conveyed by the indices of non-zero sections in a sparse vector, while each user's private information is embedded into non-zero blocks with specific block lengths. At the receiver, the common bits are first recovered from the detected non-zero sections, followed by user-specific private bits decoding based on the corresponding non-zero block indices. Simulation results show the proposed scheme outperforms state-of-the-art SVT schemes in terms of block error rate.

</details>


### [38] [Co-Channel Interference Mitigation Using Deep Learning for Drone-Based Large-Scale Antenna Measurements](https://arxiv.org/abs/2601.13205)
*Kadyrzhan Tortayev,Oliver Falkenberg Damborg,Jònas À Hàlvmørk Joensen,Jonas Pedesk,Yifa Li,Fengchun Zhang,Zeliang An,Yubo Wang,Ming Shen*

Main category: eess.SP

TL;DR: 提出轻量级深度卷积神经网络DC-CNN，用于在强同频干扰下估计连续波探针音幅度，适用于无人机天线辐射特性测量


<details>
  <summary>Details</summary>
Motivation: 无人机测量大型天线辐射特性时，相邻天线的同频干扰会严重影响传统FFT估计器的性能，当信干比低于-10dB时无法准确估计连续波幅度

Method: 设计轻量级深度卷积神经网络DC-CNN（参数少于2万），使用真实5GHz测量数据进行训练和评估，覆盖-33.3dB到+46.7dB的信干比范围

Result: DC-CNN在全范围内平均绝对误差为7%，当信干比≥-30dB时误差小于1dB，性能优于传统FFT估计器

Conclusion: DC-CNN具有鲁棒性和高效性，适合部署在嵌入式无人机平台上，实现抗干扰的天线方向图特性测量

Abstract: Unmanned aerial vehicles (UAVs) enable efficient in-situ radiation characterization of large-aperture antennas directly in their deployment environments. In such measurements, a continuous-wave (CW) probe tone is commonly transmitted to characterize the antenna response. However, active co-channel emissions from neighboring antennas often introduce severe in-band interference, where classical FFT-based estimators fail to accurately estimate the CW tone amplitude when the signal-to-interference ratios (SIR) falls below -10 dB. This paper proposes a lightweight deep convolutional neural network (DC-CNN) that estimates the amplitude of the CW tone. The model is trained and evaluated on real 5~GHz measurement bursts spanning an effective SIR range of --33.3 dB to +46.7 dB. Despite its compact size (<20k parameters), the proposed DC-CNN achieves a mean absolute error (MAE) of 7% over the full range, with <1 dB error for SIR >= -30 dB. This robustness and efficiency make DC-CNN suitable for deployment on embedded UAV platforms for interference-resilient antenna pattern characterization.

</details>


### [39] [Semantic Communication in Underwater IoT Networks for Meaning-Driven Connectivity](https://arxiv.org/abs/2601.13289)
*Ruhul Amin Khalil,Asiya Jehangir,Hanane Lamaazi,Sadaf Rubab,Nasir Saeed*

Main category: eess.SP

TL;DR: 本文综述了水下物联网中语义通信的最新进展，探讨了AI驱动的语义压缩、上下文感知优先处理和鲁棒信息重建技术，以解决水下通信的带宽、延迟和能耗限制问题。


<details>
  <summary>Details</summary>
Motivation: 水下物联网(IoUT)在海洋传感、环境监测和水下探索中具有重要应用，但传统数据通信面临带宽窄、延迟高、能耗严格等效率问题，需要新的通信范式来克服这些限制。

Method: 调查了语义通信在水下物联网中的应用，包括基于大语言模型、扩散生成编码器和联邦学习的AI框架，以及混合声学-光学-RF架构和边缘智能语义编码器，实现语义压缩和上下文感知优先处理。

Result: 通过水下考古、海洋生态学和自主水下航行器协调等案例，展示了基于意义的连接的优势，并提出了语义表示标准化、跨域插值和隐私保护方案等未来研究方向。

Conclusion: 语义通信是解决水下物联网通信限制的有前景范式，但需要解决语义表示标准化、跨域互操作和隐私保护等关键问题，才能开发出可信的语义通信使能的水下物联网系统。

Abstract: The Internet of Underwater Things (IoUT) is revolutionizing marine sensing and environmental monitoring, as well as subaquatic exploration, which are enabled by interconnected and intelligent subsystems. Nevertheless, underwater communication is constrained by narrow bandwidth, high latency, and strict energy constraints, which are the source of efficiency problems in traditional data-centric networks. To tackle these problematic issues, this work provides a survey of recent advances in Semantic Communication (SC) for IoUT, a novel communication paradigm that seeks to harness not raw symbol information but rather its meaning and/or contextual significance. In this paper, we investigate the emerging advanced AI-powered frameworks, including large language models (LLMs), diffusion-based generative encoders, and federated learning (FL), that bridge semantic compression with context-aware prioritization and robust information reconstruction over noisy underwater channels. Hybrid acoustic-optical-RF architectures and edge-intelligent semantic encoders are also considered enablers of sustainable, adaptive operations. Examples in underwater archaeology, marine ecology, and autonomous underwater vehicles (AUVs) coordination are provided as a relief to illustrate the merits of meaning-driven connectivity. The paper concludes with some recommendations, including semantic representations standardization, cross-domain interpolation, and privacy-support schemes. These issues must be addressed in the future before trustworthy SC-enabled IoUT systems can be developed for underwater communication.

</details>


### [40] [Autonomous Self-Healing UAV Swarms for Robust 6G Non-Terrestrial Networks](https://arxiv.org/abs/2601.13418)
*Sambrama Hegde,Venkata Srirama Rohit Kantheti,Liang C Chu,Erik Blasch,Shih-Chun Lin*

Main category: eess.SP

TL;DR: 提出RASHND网络设计，通过智能算法选择和分布式信号处理技术，增强无人机网络的可靠性和抗干扰能力


<details>
  <summary>Details</summary>
Motivation: 非地面网络（特别是无人机）在下一代无线网络中提供成本效益的全球连接，但面临动态干扰和对抗性条件，需要提高信号质量和网络韧性

Method: 提出RASHND网络设计，利用节点间通信和智能算法选择过程，结合分布式最大比合并(d-MRC)、分布式线性最小均方误差估计(d-LMMSE)和选择合并(SC)等技术，适应变化的网络条件

Result: 通过软件定义无线电硬件测试平台和AERPAW测试平台的无人机实验验证，RASHND显著提高了无人机网络的可靠性和干扰韧性

Conclusion: RASHND使无人机网络更适合关键通信应用，通过自适应算法选择和分布式信号处理技术增强了网络在动态干扰环境下的性能

Abstract: Recent years have seen an increased interest in the use of Non-terrestrial networks (NTNs), especially the unmanned aerial vehicles (UAVs) to provide cost-effective global connectivity in next-generation wireless networks. We introduce a resilient, adaptive, self-healing network design (RASHND) to optimize signal quality under dynamic interference and adversarial conditions. RASHND leverages inter-node communication and an intelligent algorithm selection process, incorporating combining techniques like distributed-Maximal Ratio Combining (d-MRC), distributed-Linear Minimum Mean Squared Error Estimation(d-LMMSE), and Selection Combining (SC). These algorithms are selected to improve performance by adapting to changing network conditions. To evaluate the effectiveness of the proposed RASHND solutions, a software-defined radio (SDR)-based hardware testbed afforded initial testing and evaluations. Additionally, we present results from UAV tests conducted on the AERPAW testbed to validate our solutions in real-world scenarios. The results demonstrate that RASHND significantly enhances the reliability and interference resilience of UAV networks, making them well-suited for critical communications.

</details>


### [41] [Joint Subarray Selection, User Scheduling, and Pilot Assignment for XL-MIMO](https://arxiv.org/abs/2601.13470)
*Gabriel Avanzi Ubiali,José Carlos Marinello Filho,Taufik Abrão*

Main category: eess.SP

TL;DR: 本文针对XL-MIMO系统提出基于统计CSI的确定性SINR闭式表达式，并开发了联合子阵列选择、用户调度和导频分配的算法，显著提升了系统公平性和吞吐量。


<details>
  <summary>Details</summary>
Motivation: XL-MIMO是6G实现高速连接和均匀服务质量的关键技术，但基于瞬时CSI的资源管理复杂度极高，难以实际部署。需要寻找基于长期信道统计的可行替代方案。

Method: 推导了集中式和分布式上行操作的确定性SINR闭式表达式，适用于Rician衰落信道下的MMSE接收合并和MMSE信道估计。基于这些表达式，开发了统计CSI驱动的联合子阵列选择、用户调度和导频分配算法，利用用户可见区域的空间稀疏性实现更激进的导频复用。

Result: 数值结果表明，推导的SINR近似具有高精度，所提算法在拥挤场景下显著提升了公平性和吞吐量，相比传统大规模MIMO实现了更高效的导频复用。

Conclusion: 本文提出的基于统计CSI的框架为XL-MIMO系统提供了计算可行的资源管理方案，解决了瞬时CSI优化的计算复杂度问题，为6G XL-MIMO的实际部署提供了重要技术支撑。

Abstract: Extra-large scale MIMO (XL-MIMO) is a key technology for meeting sixth-generation (6G) requirements for high-rate connectivity and uniform quality of service (QoS); however, its deployment is challenged by the prohibitive complexity of resource management based on instantaneous channel state information (CSI). To address this intractability, this work derives novel closed-form deterministic signal-to-interference-plus-noise ratio (SINR) expressions for both centralized and distributed uplink operations. Valid for Rician fading channels with minimum mean square error (MMSE) receive combining and MMSE channel estimation, these expressions depend exclusively on long-term channel statistics, providing a tractable alternative to computationally expensive instantaneous CSI-driven optimization. Building on these results, we develop statistical-CSI-based algorithms for joint subarray selection, users scheduling, and pilot assignment, leveraging the derived SINR approximations to maximize the minimum spectral efficiency (SE) among scheduled users while preserving computational tractability. The proposed framework exploits the spatial sparsity of user equipment (UE) visibility regions (VRs) to enable more aggressive pilot reuse than is possible in conventional massive MIMO. Numerical results validate the high accuracy of the derived SINR approximations and demonstrate that the proposed algorithms significantly enhance fairness and throughput in crowded scenarios.

</details>


### [42] [Near-field Physical Layer Security: Robust Beamforming under Location Uncertainty](https://arxiv.org/abs/2601.13549)
*Chao Zhou,Changsheng You,Cong Zhou,Chengwen Xing,Jianhua Zhang*

Main category: eess.SP

TL;DR: 提出了一种针对近场物理层安全系统的鲁棒波束成形方法，在窃听者位置信息不完美的情况下，通过两阶段优化实现安全性与性能的良好权衡。


<details>
  <summary>Details</summary>
Motivation: 现有近场物理层安全研究大多假设窃听者的完美信道状态信息或位置信息，但在实际场景中窃听者位置信息往往不完美。本文针对这一更实际且具有挑战性的场景，研究在窃听者位置不确定情况下的鲁棒波束成形设计。

Method: 首先将笛卡尔坐标误差转换到极坐标域，揭示了近场角度误差放大效应。然后提出两阶段鲁棒波束成形方法：第一阶段将不确定区域划分为多个扇形子区域；第二阶段基于线性矩阵不等式制定和求解优化的鲁棒波束成形问题。该方法可扩展到多合法用户和多窃听者场景。

Result: 数值结果表明，所提方法在速率性能和保密鲁棒性之间实现了优越的权衡，在窃听者位置不确定情况下显著优于现有基准方法。

Conclusion: 本文提出的两阶段鲁棒波束成形方法有效解决了近场物理层安全系统中窃听者位置不确定的问题，通过考虑近场角度误差放大效应和采用区域划分策略，实现了更好的安全性能。

Abstract: In this paper, we study robust beamforming design for near-field physical-layer-security (PLS) systems, where a base station (BS) equipped with an extremely large-scale array (XL-array) serves multiple near-field legitimate users (Bobs) in the presence of multiple near-field eavesdroppers (Eves). Unlike existing works that mostly assume perfect channel state information (CSI) or location information of Eves, we consider a more practical and challenging scenario, where the locations of Bobs are perfectly known, while only imperfect location information of Eves is available at the BS. We first formulate a robust optimization problem to maximize the sum-rate of Bobs while guaranteeing a worst-case limit on the eavesdropping rate under location uncertainty. By transforming Cartesian position errors into the polar domain, we reveal an important near-field angular-error amplification effect: for the same location error, the closer the Eve, the larger the angle error, severely degrading the performance of conventional robust beamforming methods based on imperfect channel state information. To address this issue, we first establish the conditions for which the first-order Taylor approximation of the near-field channel steering vector under location uncertainty is largely accurate. Then, we propose a two-stage robust beamforming method, which first partitions the uncertainty region into multiple fan-shaped sub-regions, followed by the second stage to formulate and solve a refined linear-matrix-inequality (LMI)-based robust beamforming optimization problem. In addition, the proposed method is further extended to scenarios with multiple Bobs and multiple Eves. Finally, numerical results validate that the proposed method achieves a superior trade-off between rate performance and secrecy robustness, hence significantly outperforming existing benchmarks under Eve location uncertainty.

</details>


### [43] [Instant Preliminary Cardiac Analysis from Smartphone Auscultation: A Real-World Canine Heart Sound Dataset and Evaluation](https://arxiv.org/abs/2601.13593)
*Aswin Jose,Roeland P. J. E. Decorte,Laurent Locquet*

Main category: eess.SP

TL;DR: 本研究提出了一个真实世界的犬类心音数据集，并评估了SoNUS 3.2.x算法，该算法使用智能手机麦克风录音进行初步心脏分析，在犬类心音识别中取得了高准确率。


<details>
  <summary>Details</summary>
Motivation: 动机是开发一种基于智能手机录音的兽医心脏病学初步评估工具，支持可扩展的远程医疗应用，利用日常设备进行心脏健康监测。

Method: 方法包括：1）收集来自四大洲100多个犬类心音录音；2）由认证兽医心脏病专家标注38个录音用于定量评估；3）采用多级回退架构和质量感知过滤的SoNUS 3.2.x算法；4）开发60秒主模型和30-40秒快速模型。

Result: 主要结果：60秒模型的心率准确率均值为91.63%，中位数为94.95%；30-40秒快速模型的准确率均值为88.86%，中位数为92.98%。证明从智能手机录音中提取临床相关心脏信息的可行性。

Conclusion: 结论：SoNUS 3.2.x算法能够从机会性智能手机录音中可靠提取心脏信息，支持兽医心脏病学的可扩展初步评估和远程医疗应用，为宠物心脏健康监测提供了实用工具。

Abstract: This study presents a real-world canine heart sound dataset and evaluates SoNUS version 3.2.x, a machine learning algorithm for preliminary cardiac analysis using smartphone microphone recordings. More than one hundred recordings were collected from dogs across four continents, with thirty eight recordings annotated by board certified veterinary cardiologists for quantitative evaluation. SoNUS version 3.2.x employs a multi-stage fallback architecture with quality-aware filtering to ensure reliable output under variable recording conditions. The primary sixty second model achieved mean and median heart rate accuracies of ninety one point six three percent and ninety four point nine five percent, while a fast model optimized for thirty to forty second recordings achieved mean and median accuracies of eighty eight point eight six percent and ninety two point nine eight percent. These results demonstrate the feasibility of extracting clinically relevant cardiac information from opportunistic smartphone recordings, supporting scalable preliminary assessment and telehealth applications in veterinary cardiology.

</details>


### [44] [Deep Learning-Enabled Signal Detection for MIMO-OTFS-Based 6G and Future Wireless Networks](https://arxiv.org/abs/2601.13635)
*Emin Akpinar,Emir Aslandogan,Burak Ahmet Ozden,Haci Ilhan,Erdogan Aydin*

Main category: eess.SP

TL;DR: 该论文提出基于深度学习的低复杂度信号检测方法用于MIMO-OTFS系统，在Nakagami-m信道条件下，使用MLP、CNN和ResNet架构，相比传统MLD方法显著降低计算复杂度同时保持可比的BER性能。


<details>
  <summary>Details</summary>
Motivation: OTFS调制在6G及未来无线通信系统中具有优势，特别是在高移动性和色散信道条件下。传统信号检测方法计算复杂度高，而基于深度学习的检测方法在降低计算复杂度方面表现出潜力，因此需要研究适用于MIMO-OTFS系统的低复杂度DL检测方法。

Method: 针对MIMO-OTFS系统，在Nakagami-m信道条件下，首先使用最大比合并（MRC）将接收天线符号合并，然后采用三种深度学习架构进行信号检测：多层感知器（MLP）、卷积神经网络（CNN）和残差网络（ResNet）。

Result: 复杂度分析表明MLP架构相比CNN、ResNet和传统最大似然检测（MLD）具有显著更低的计算复杂度。数值分析显示，尽管提出的DL检测器复杂度低，但在各种系统条件下能达到与高性能MLD可比的误码率（BER）性能。

Conclusion: 基于深度学习的低复杂度信号检测方法为MIMO-OTFS系统提供了有效的解决方案，特别是MLP架构在计算复杂度和性能之间取得了良好平衡，适合未来6G无线通信系统的高移动性场景。

Abstract: Orthogonal time frequency space (OTFS) modulation stands out as a promising waveform for sixth generation (6G) and beyond wireless communication systems, offering superior performance over conventional methods, particularly in high-mobility scenarios and dispersive channel conditions. Recent research has demonstrated that the reduced computational complexity of deep learning (DL)-based signal detection (SD) methods constitutes a compelling alternative to conventional techniques. In this study, low-complexity DL-based SD methods are proposed for a multiple-input multiple-output (MIMO)-OTFS system and examined under Nakagami-$m$ channel conditions. The symbols obtained from the receiver antennas are combined using maximum ratio combining (MRC) and detected with the help of a DL-based detector implemented with multi-layer perceptron (MLP), convolutional neural network (CNN), and residual network (ResNet). Complexity analysis reveals that the MLP architecture offers significantly lower computational complexity compared to CNN, ResNet, and classical methods such as maximum likelihood detection (MLD). Furthermore, numerical analyses have shown that the proposed DL-based detectors, despite their low complexity, achieve comparable bit error rate (BER) performance to that of a high-performance MLD under various system conditions.

</details>


### [45] [TSN-IoT: A Two-Stage NOMA-Enabled Framework for Prioritized Traffic Handling in Dense IoT Networks](https://arxiv.org/abs/2601.13680)
*Shama Siddiqui,Anwar Ahmed Khan,Nicola Marchetti*

Main category: eess.SP

TL;DR: 提出TSN-IoT框架，结合NOMA技术解决密集IoT环境中的同步和优先级访问问题，相比OFDMA显著提升性能


<details>
  <summary>Details</summary>
Motivation: 随着物联网应用增长，在密集IoT场景中面临同步中断挑战：节点移动远离基站、GNSS信号不可靠（物理障碍、多径衰落、环境干扰）。需要确保连续连接同时提供优先级访问

Method: 提出两阶段NOMA使能框架TSN-IoT，集成传统PTP同步、分布式同步和数据传输机制。设计为四层架构，促进从传感器节点到中心基站的优先级数据交付

Result: 通过医疗用例模拟评估，相比基于优先级的OFDMA，TSN-IoT在同步速度和端到端延迟方面表现显著更好，提供改进的同步机会并支持同一子载波上的并行传输

Conclusion: TSN-IoT框架通过NOMA技术有效解决密集异构IoT环境中的同步和优先级管理问题，在间歇连接和不同数据优先级场景下提供可靠通信解决方案

Abstract: With the growing applications of the Internet of Things (IoT), a major challenge is to ensure continuous connectivity while providing prioritized access. In dense IoT scenarios, synchronization may be disrupted either by the movement of nodes away from base stations or by the unavailability of reliable Global Navigation Satellite System (GNSS) signals, which can be affected by physical obstructions, multipath fading, or environmental interference, such as such as walls, buildings, moving objects, or electromagnetic noise from surrounding devices. In such contexts, distributed synchronization through Non-Orthogonal Multiple Access (NOMA) offers a promising solution, as it enables simultaneous transmission to multiple users with different power levels, supporting efficient synchronization while minimizing the signaling overhead. Moreover, NOMA also plays a vital role for dynamic priority management in dense and heterogeneous IoT environments. In this article, we proposed a Two-Stage NOMA-Enabled Framework "TSN-IoT" that integrates the mechanisms of conventional Precision Time Protocol (PTP) based synchronization, distributed synchronization and data transmission. The framework is designed as a four-tier architecture that facilitates prioritized data delivery from sensor nodes to the central base station. We demonstrated the performance of "TSN-IoT" through a healthcare use case, where intermittent connectivity and varying data priority levels present key challenges for reliable communication. Synchronization speed and end-to-end delay were evaluated through a series of simulations implemented in Python. Results show that, compared to priority-based Orthogonal Frequency Division Multiple Access (OFDMA), TSN-IoT achieves significantly better performance by offering improved synchronization opportunities and enabling parallel transmissions over the same sub-carrier.

</details>


### [46] [Channel Estimation in MIMO Systems Using Flow Matching Models](https://arxiv.org/abs/2601.13827)
*Yongqiang Zhang,Qurrat-Ul-Ain Nadeem*

Main category: eess.SP

TL;DR: 提出基于流匹配的MIMO信道估计器，相比现有扩散模型方法，推理速度提升49倍，GPU内存使用减少20倍


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型和分数模型的深度生成方法虽然有效，但存在计算时间长、需要多次迭代采样的问题，限制了实际应用

Method: 使用深度神经网络学习无线信道的速度场，并将其集成到即插即用近端梯度下降（PnP-PGD）框架中

Result: 提出的方法在性能上优于现有最先进的生成模型估计器，推理速度提升高达49倍，GPU峰值内存使用减少高达20倍

Conclusion: 流匹配方法为MIMO信道估计提供了一种高效准确的解决方案，显著降低了计算开销和内存需求

Abstract: Multiple-input multiple-output (MIMO) systems require efficient and accurate channel estimation with low pilot overhead to unlock their full potential for high spectral and energy efficiency. While deep generative models have emerged as a powerful foundation for the channel estimation task, the existing approaches using diffusion-based and score-based models suffer from high computational runtime due to their stochastic and many-step iterative sampling. In this paper, we introduce a flow matching-based channel estimator to overcome this limitation. The proposed channel estimator is based on a deep neural network trained to learn the velocity field of wireless channels, which we then integrate into a plug-and-play proximal gradient descent (PnP-PGD) framework. Simulation results reveal that our formulated approach consistently outperforms existing state-of-the-art (SOTA) generative model-based estimators, achieves up to 49 times faster inference at test time, and reduces up to 20 times peak graphics processing unit (GPU) memory usage. Our code and models are publicly available to support reproducible research.

</details>


### [47] [Riemannian optimization on the manifold of unitary and symmetric matrices with application to BD-RIS-assisted systems](https://arxiv.org/abs/2601.13877)
*Ignacio Santamaria,Mohammad Soleymani,Eduard Jorswieck,Jesus Gutierrez,Carlos Beltran*

Main category: eess.SP

TL;DR: 本文首次严格刻画了酉矩阵和对称矩阵的流形，推导其切空间和测地线，并基于此提出无需调参的黎曼流形优化算法，应用于BD-RIS辅助的MIMO系统速率最大化问题。


<details>
  <summary>Details</summary>
Motivation: 现有基于Takagi分解的优化方法计算成本高，且需要调整参数。本文旨在开发一种无需调参、计算效率更高的黎曼流形优化算法，特别针对酉矩阵和对称矩阵流形。

Method: 首先严格推导酉矩阵和对称矩阵流形的切空间和测地线，通过实对称矩阵参数化测地线。基于此构建新的黎曼流形优化算法，该算法无需设置任何自适应参数。

Result: 提出的MO算法在BD-RIS辅助的MIMO系统速率最大化问题中，相比基于Takagi分解的先前方法显著降低了计算成本，同时保持对代价函数驻点的全局收敛性。

Conclusion: 本文成功开发了一种无需调参的黎曼流形优化算法，通过严格推导酉矩阵和对称矩阵流形的几何特性，实现了计算效率的显著提升，并在MIMO系统应用中验证了其性能。

Abstract: In this paper, we rigorously characterize for the first time the manifold of unitary and symmetric matrices, deriving its tangent space and its geodesics. The resulting parameterization of the geodesics (through a real and symmetric matrix) allows us to derive a new Riemannian manifold optimization (MO) algorithm whose most remarkable feature is that it does not need to set any adaptation parameter. We apply the proposed MO algorithm to maximize the achievable rate in a multiple-input multiple-output (MIMO) system assisted by a beyond-diagonal reconfigurable intelligent surface (BD-RIS), illustrating the method's performance through simulations. The MO algorithm achieves a significant reduction in computational cost compared to previous alternatives based on Takagi decomposition, while retaining global convergence to a stationary point of the cost function.

</details>


### [48] [Deep Reinforcement Learning-Based Dynamic Resource Allocation in Cell-Free Massive MIMO](https://arxiv.org/abs/2601.13934)
*Phuong Nam Tran,Nhan Thanh Nguyen,Hien Quoc Ngo,Markku Juntti*

Main category: eess.SP

TL;DR: 提出基于深度强化学习的框架，联合优化天线激活和功率控制，以提升无蜂窝大规模MIMO系统的能量效率，相比传统方法实现50%的EE提升和3350倍的运行时间减少。


<details>
  <summary>Details</summary>
Motivation: 无蜂窝大规模MIMO系统需要同时优化功率分配和天线激活来提升能量效率，但这是一个非凸、混合整数的高维优化问题，传统方法难以有效解决。

Method: 提出基于深度强化学习(DRL)的框架，智能体学习将大尺度衰落系数映射到AP激活比例、天线系数和功率系数，然后通过闭式表达式确定每个AP的激活天线数和用户功率因子，将复杂优化转化为低维学习任务。

Result: 在包含40个AP和20个用户的CFmMIMO系统中，相比传统的顺序凸逼近方法，实现了50%的能量效率提升和3350倍的运行时间减少，证明了方法的效率和可扩展性。

Conclusion: 提出的DRL框架成功解决了无蜂窝大规模MIMO系统中天线激活和功率控制的联合优化问题，将高维非凸混合整数优化转化为可处理的学习任务，显著提升了系统性能并大幅降低了计算复杂度。

Abstract: In this paper, we consider power allocation and antenna activation of cell-free massive multiple-input multiple-output (CFmMIMO) systems. We first derive closed-form expressions for the system spectral efficiency (SE) and energy efficiency (EE) as functions of the power allocation coefficients and the number of active antennas at the access points (APs). Then, we aim to enhance the EE through jointly optimizing antenna activation and power control. This task leads to a non-convex and mixed-integer design problem with high-dimensional design variables. To address this, we propose a novel DRL-based framework, in which the agent learns to map large-scale fading coefficients to AP activation ratio, antenna coefficient, and power coefficient. These coefficients are then employed to determine the number of active antennas per AP and the power factors assigned to users based on closed-form expressions. By optimizing these parameters instead of directly controlling antenna selection and power allocation, the proposed method transforms the intractable optimization into a low-dimensional learning task. Our extensive simulations demonstrate the efficiency and scalability of the proposed scheme. Specifically, in a CFmMIMO system with 40 APs and 20 users, it achieves a 50% EE improvement and 3350 times run time reduction compared to the conventional sequential convex approximation method.

</details>


### [49] [Optimal Calibration of the endpoint-corrected Hilbert Transform](https://arxiv.org/abs/2601.13962)
*Eike Osmers,Dorothea Kolossa*

Main category: eess.SP

TL;DR: 论文提出了一种校准端点校正希尔伯特变换(c-ecHT)的方法，通过解析推导端点算子，将输出分解为期望的正频率项和残余泄漏项，从而显著降低相位估计误差。


<details>
  <summary>Details</summary>
Motivation: 在实时神经刺激等闭环应用中，需要准确、低延迟的振荡瞬时相位估计。端点校正希尔伯特变换(ecHT)虽然广泛使用，但其端点失真缺乏系统的理论分析。

Method: 通过解析推导ecHT端点算子，将输出分解为期望的正频率项（产生可校准的幅度/相位偏差）和残余泄漏项。提出了均方误差最优的标量校准方法(c-ecHT)，并建立了窗口长度、带宽/阶数和中心频率失配与残余偏差之间的设计规则。

Result: 校准后的ecHT实现了接近零的平均相位误差，同时保持与实时处理管道的计算兼容性。提供了端点相位/幅度误差的明确表征和界限。

Conclusion: c-ecHT方法为端点校正希尔伯特变换提供了理论分析框架和实用校准方案，显著提高了相位估计的准确性，适用于实时闭环神经刺激等应用。

Abstract: Accurate, low-latency estimates of the instantaneous phase of oscillations are essential for closed-loop sensing and actuation, including (but not limited to) phase-locked neurostimulation and other real-time applications. The endpoint-corrected Hilbert transform (ecHT) reduces boundary artefacts of the Hilbert transform by applying a causal narrow-band filter to the analytic spectrum. This improves the phase estimate at the most recent sample. Despite its widespread empirical use, the systematic endpoint distortions of ecHT have lacked a principled, closed-form analysis. In this study, we derive the ecHT endpoint operator analytically and demonstrate that its output can be decomposed into a desired positive-frequency term (a deterministic complex gain that induces a calibratable amplitude/phase bias) and a residual leakage term setting an irreducible variance floor. This yields (i) an explicit characterisation and bounds for endpoint phase/amplitude error, (ii) a mean-squared-error-optimal scalar calibration (c-ecHT), and (iii) practical design rules relating window length, bandwidth/order, and centre-frequency mismatch to residual bias via an endpoint group delay. The resulting calibrated ecHT achieves near-zero mean phase error and remains computationally compatible with real-time pipelines. Code and analyses are provided at https://github.com/eosmers/cecHT.

</details>


### [50] [Achieving Full Multipath Diversity by Random Constellation Rotation: a Theoretical Perspective](https://arxiv.org/abs/2601.13997)
*Xuehan Wang,Jinhong Yuan,Jintao Wang,Kehan Huang*

Main category: eess.SP

TL;DR: 提出利用随机星座旋转简化全分集调制设计条件，证明线性预编码CP-OFDM系统只要扩展矩阵无零元素即可获得最大多径分集，并推导出一般调制方案的充要条件。


<details>
  <summary>Details</summary>
Motivation: 现有分析框架大多针对特定调制方案，而验证一般调制方案的全多径分集效率仍是一个开放问题。需要填补这一研究空白，简化全分集调制设计的条件。

Method: 采用随机星座旋转技术，推导线性预编码CP-OFDM系统的充分条件（扩展矩阵无零元素），并建立一般调制方案的充要条件验证框架，将验证任务分解为调制矩阵各列的检验。

Result: 理论分析表明，通过随机生成的旋转模式，在时间和双弥散信道中都能以概率1获得最大分集阶数。数值结果验证了理论分析的有效性，随机星座旋转技术能持续提升编码和非编码系统的传输可靠性。

Conclusion: 随机星座旋转简化了全分集调制设计，提出的条件易于验证，显著降低了分集驱动设计和性能分析的复杂度，为新型调制方案在多径信道中的设计提供了有效工具。

Abstract: Diversity is an essential concept associated with communication reliability in multipath channels since it determines the slope of bit error rate performance in the medium to high signal-to-noise ratio regions. However, most of the existing analytical frameworks were developed for specific modulation schemes while the efficient validation of full multipath diversity for general modulation schemes remains an open problem. To fill this research gap, we propose to utilize random constellation rotation to ease the conditions for full-diversity modulation designs. For linearly precoded cyclic-prefix orthogonal frequency division multiplexing (OFDM) systems, we prove that maximum multipath diversity can be attained as long as the spread matrix does not have zero entries, which is a sufficient but easily satisfied condition. Furthermore, we derive the sufficient and necessary condition for general modulation schemes, whose verification can be divided into validation tasks for each column of the modulation matrix. Based on the proposed conditions, maximum diversity order can be attained with the probability of 1 by enabling a randomly generated rotation pattern for both time and doubly dispersive channels. The theoretical analysis in this paper also demonstrates that the diversity evaluation can be concentrated on the pairwise error probability when the number of error symbols is one, which reduces the complexity of diversity-driven design and performance analysis for novel modulation schemes significantly in both time and doubly dispersive channels. Finally, numerical results for various modulation schemes confirm that the theoretical analysis holds in both time and doubly dispersive channels. Furthermore, when employing practical detectors, the random constellation rotation technique consistently enhance the transmission reliability for both coded and uncoded systems.

</details>


### [51] [Background Subtraction with Drift Correction for Bistatic Radar Reflectivity Measurements](https://arxiv.org/abs/2601.14080)
*Alexander Ihlow,Marius Schmidt,Carsten Andrich,Reiner S. Thomä*

Main category: eess.SP

TL;DR: 提出一种用于校正无回波室双基地雷达测量中仪器漂移的模型，通过修正前景与背景测量间的不相干性，将天线串扰抑制提升达40dB。


<details>
  <summary>Details</summary>
Motivation: 双基地雷达反射率研究对6G集成感知与通信(ISAC)至关重要。在无回波室测量中，背景减除技术因前景与背景测量过程间的不相干性而效果受限，需要解决仪器漂移问题。

Method: 提出仪器漂移校正模型，分析2-18GHz频段真实测量数据，使用TU Ilmenau的双基地雷达(BIRA)测量设施，通过修正测量过程中的不相干性来改善背景减除效果。

Result: 应用提出的漂移校正模型后，在消除视距天线串扰方面比现有技术提升了高达40dB的改进效果。

Conclusion: 该漂移校正模型能有效解决双基地雷达测量中的仪器漂移问题，显著提升背景减除性能，对6G ISAC等应用具有重要意义。

Abstract: Fundamental research on bistatic radar reflectivity is highly relevant, e.g., to the upcoming mobile communication standard 6G, which includes integrated sensing and communication (ISAC). We introduce a model for correcting instrumentation drift during bistatic radar measurements in anechoic chambers. Usually, background subtraction is applied with the goal to yield the target reflection signal as best as possible while coherently subtracting all signals which were present in both the foreground and background measurement. However, even slight incoherences between the foreground and background measurement process deteriorate the result. We analyze these effects in real measurements in the frequency range 2-18 GHz, taken with the Bistatic Radar (BIRA) measurement facility at TU Ilmenau. Applying our proposed drift correction model, we demonstrate up to 40 dB improvement for the removal of direct line-of-sight antenna crosstalk over the state of the art.

</details>


### [52] [Bit-Efficient Quantisation for Two-Channel Modulo-Sampling Systems](https://arxiv.org/abs/2601.14220)
*Wenyi Yan,Zeyuan Li,Lu Gan,Honqing Liu,Guoquan Li*

Main category: eess.SP

TL;DR: 提出一种高效的两通道模数转换器量化方案，通过利用通道间差值的整数特性，仅传输一个量化通道输出和紧凑的差值索引，相比传统ADC仅增加1-2比特开销。


<details>
  <summary>Details</summary>
Motivation: 现有两通道模数转换器独立量化两个通道输出，导致比特率冗余。需要在保持高动态范围信号感知的同时，减少比特率开销。

Method: 提出基于整数差值结构的比特高效量化方案：传输一个量化通道输出和紧凑的差值索引，利用通道间差值的整数特性减少比特率。

Result: 理论证明该方法仅需1-2比特/样本的额外开销，仿真验证了理论误差界限和比特率分析，硬件实验显示相比现有模数采样方案显著节省比特率，同时保持可比较的重建精度。

Conclusion: 该方法为比特率受限系统提供了一条实现高分辨率、带宽高效模数转换器的实用路径。

Abstract: Two-channel modulo analog-to-digital converters (ADCs) enable high-dynamic-range signal sensing at the Nyquist rate per channel, but existing designs quantise both channel outputs independently, incurring redundant bitrate costs. This paper proposes a bit-efficient quantisation scheme that exploits the integer-valued structure of inter-channel differences, transmitting one quantised channel output together with a compact difference index. We prove that this approach requires only 1-2 bits per signal sample overhead relative to conventional ADCs, despite operating with a much smaller per-channel dynamic range. Simulations confirm the theoretical error bounds and bitrate analysis, while hardware experiments demonstrate substantial bitrate savings compared with existing modulo sampling schemes, while maintaining comparable reconstruction accuracy. These results highlight a practical path towards high-resolution, bandwidth-efficient modulo ADCs for bitrate-constrained systems.

</details>


### [53] [Burst Aware Forecasting of User Traffic Demand in LEO Satellite Networks](https://arxiv.org/abs/2601.14233)
*Yekta Demirci,Guillaume Mantelet,Stephane Martel,Jean-Francois Frigon,Gunes Karabulut Kurt*

Main category: eess.SP

TL;DR: 提出一种针对低轨卫星网络中波束跳变调度的突发感知预测方法，通过改进Transformer架构来准确预测突发流量，在重负载场景下显著降低预测误差。


<details>
  <summary>Details</summary>
Motivation: 低轨卫星网络中的波束跳变技术需要提前预测用户流量来进行有效调度。在重负载条件下，突发流量与链路质量下降可能导致缓冲区溢出和数据包丢失，因此准确的突发流量预测变得尤为关键。

Method: 在Transformer架构中引入三个关键改进：(1) 添加"距离上次突发嵌入"来捕捉突发接近度；(2) 在解码器中增加两个线性层，分别预测即将到来的突发及其相对影响；(3) 在模型训练中使用非对称成本函数以更好地捕捉突发动态。

Result: 在高流量需求场景下的地球固定单元中，所提模型在一步预测范围内将预测误差降低了94%，并在较长的预测范围内仍能准确捕捉突发流量（基于均方误差指标）。

Conclusion: 提出的突发感知预测解决方案能有效应对低轨卫星网络中的突发流量预测挑战，该方法也适用于其他具有突发流量模式且需要准确需求预测的无线网络场景。

Abstract: In Low Earth Orbit (LEO) satellite networks, Beam Hopping (BH) technology enables the efficient utilization of limited radio resources by adapting to varying user demands and link conditions. Effective BH planning requires prior knowledge of upcoming traffic at the time of scheduling, making forecasting an important sub-task. Forecasting becomes particularly critical under heavy load conditions where an unexpected demand burst combined with link degradation may cause buffer overflows and packet loss. To address this challenge, we propose a burst aware forecasting solution. This challenge may arise in a wide range of wireless networks; therefore, the proposed solution is broadly applicable to settings characterized by bursty traffic patterns where accurate demand forecasting is essential. Our approach introduces three key enhancements to a transformer architecture: (i) a distance from the last burst embedding to capture burst proximity, (ii) two additional linear layers in the decoder to forecast both upcoming bursts and their relative impact, and (iii) use of an asymmetric cost function during model training to better capture burst dynamics. Empirical evaluations in an Earth-fixed cell under high-traffic demand scenario demonstrate that the proposed model reduces prediction error by up to 94% at a one-step horizon and maintains the ability to accurately capture bursts even near the end of longer prediction horizons following Mean Square Error (MSE) metric.

</details>


### [54] [Robust Localization in OFDM-Based Massive MIMO through Phase Offset Calibration](https://arxiv.org/abs/2601.14244)
*Qing Zhang,Adham Sakhnini,Robbert Beerten,Haoqiu Xiong,Zhuangzhuang Cui,Yang Miao,Sofie Pollin*

Main category: eess.SP

TL;DR: 论文研究OFDM大规模MIMO系统中的相位不一致性对定位性能的影响，提出CSI校准框架，将定位误差从5米提升至1.2厘米。


<details>
  <summary>Details</summary>
Motivation: OFDM大规模MIMO系统的定位精度严重依赖于子载波和天线间的相位一致性，但实际系统存在频率相关和天线相关的相位偏移，导致定位性能下降。

Method: 采用两种互补工具：推导Cramér-Rao下界(CRLB)量化相位偏移下的理论极限；建立空间模糊函数(SAF)模型描述模糊模式。提出鲁棒的CSI校准框架，并在实际大规模MIMO测试平台上验证。

Result: 仿真显示空间相位偏移严重降低定位性能，而频率相位偏移影响较小。实验验证校准框架将定位RMSE从5米显著提升至1.2厘米，与理论预测一致。

Conclusion: 相位不一致性特别是空间相位偏移是OFDM大规模MIMO系统定位精度的主要限制因素，提出的CSI校准框架能有效解决此问题，实现厘米级定位精度。

Abstract: Accurate localization in Orthogonal Frequency Division Multiplexing (OFDM)-based massive Multiple-Input Multiple-Output (MIMO) systems depends critically on phase coherence across subcarriers and antennas. However, practical systems suffer from frequency-dependent and (spatial) antenna-dependent phase offsets, degrading localization accuracy. This paper analytically studies the impact of phase incoherence on localization performance under a static User Equipment (UE) and Line-of-Sight (LoS) scenario. We use two complementary tools. First, we derive the Cramér-Rao Lower Bound (CRLB) to quantify the theoretical limits under phase offsets. Then, we develop a Spatial Ambiguity Function (SAF)-based model to characterize ambiguity patterns. Simulation results reveal that spatial phase offsets severely degrade localization performance, while frequency phase offsets have a minor effect in the considered system configuration. To address this, we propose a robust Channel State Information (CSI) calibration framework and validate it using real-world measurements from a practical massive MIMO testbed. The experimental results confirm that the proposed calibration framework significantly improves the localization Root Mean Squared Error (RMSE) from 5 m to 1.2 cm, aligning well with the theoretical predictions.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [55] [Lightweight Self-Supervised Detection of Fundamental Frequency and Accurate Probability of Voicing in Monophonic Music](https://arxiv.org/abs/2601.11768)
*Venkat Suprabath Bitra,Homayoon Beigi*

Main category: eess.AS

TL;DR: 提出一个轻量级、完全自监督的基频估计和发声检测框架，通过转置等变学习和迭代重加权方案，无需大量标注数据即可实现单乐器快速训练。


<details>
  <summary>Details</summary>
Motivation: 现有基频提取器依赖大量标注数据，在真实录音环境下性能下降。需要一种轻量级、自监督的方法，能够在有限音频数据上快速训练，并处理录音伪影问题。

Method: 使用CQT特征进行转置等变学习，引入基于Shift Cross-Entropy一致性的EM风格迭代重加权方案，抑制无信息噪声/无声帧，利用权重作为置信度分数为发声分类器生成伪标签。

Result: 在MedleyDB上训练，MDB-stem-synth真值上评估，获得竞争性的跨语料库性能（RPA 95.84，RCA 96.24），并展示了跨乐器泛化能力。

Conclusion: 该自监督框架在有限数据下实现了可靠的基频估计和发声检测，无需人工标注，具有轻量级和快速训练的优势，适用于实际应用场景。

Abstract: Reliable fundamental frequency (F 0) and voicing estimation is essential for neural synthesis, yet many pitch extractors depend on large labeled corpora and degrade under realistic recording artifacts. We propose a lightweight, fully self-supervised framework for joint F 0 estimation and voicing inference, designed for rapid single-instrument training from limited audio. Using transposition-equivariant learning on CQT features, we introduce an EM-style iterative reweighting scheme that uses Shift Cross-Entropy (SCE) consistency as a reliability signal to suppress uninformative noisy/unvoiced frames. The resulting weights provide confidence scores that enable pseudo-labeling for a separate lightweight voicing classifier without manual annotations. Trained on MedleyDB and evaluated on MDB-stem-synth ground truth, our method achieves competitive cross-corpus performance (RPA 95.84, RCA 96.24) and demonstrates cross-instrument generalization.

</details>


### [56] [Listen, Look, Drive: Coupling Audio Instructions for User-aware VLA-based Autonomous Driving](https://arxiv.org/abs/2601.12142)
*Ziang Guo,Feng Yang,Xuefeng Zhang,Jiaqi Guo,Kun Zhao,Peng Lu,Zufeng Zhang,Sifa Zheng*

Main category: eess.AS

TL;DR: EchoVLA是一个用户感知的视觉语言动作模型，通过实时音频指令增强驾驶决策，结合情感线索实现更细腻的驾驶行为调整。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型将语言视为静态先验，需要仅从像素推断持续变化的目标，导致延迟或过于保守的驾驶操作。需要在线通道让用户通过具体意图影响驾驶。

Method: 1) 在nuScenes数据集上添加时间对齐的意图特定语音指令，将自我运动描述转换为合成音频；2) 将情感语音-轨迹对组合成多模态思维链，基于Qwen2.5-Omni微调多模态大模型；3) 利用语调、音高和语速中的情感线索反映不同用户状态。

Result: 在开环基准测试中，相比仅视觉感知基线，平均L2误差降低59.4%，碰撞率降低74.4%。在nuScenes数据集上的实验验证EchoVLA不仅能通过音频指令引导轨迹，还能根据用户语音中检测到的情感调整驾驶行为。

Conclusion: EchoVLA通过结合实时音频指令和情感理解，实现了更及时、更适应性的驾驶决策，显著提升了VLA模型在自动驾驶中的性能和用户体验。

Abstract: Vision Language Action (VLA) models promise an open-vocabulary interface that can translate perceptual ambiguity into semantically grounded driving decisions, yet they still treat language as a static prior fixed at inference time. As a result, the model must infer continuously shifting objectives from pixels alone, yielding delayed or overly conservative maneuvers. We argue that effective VLAs for autonomous driving need an online channel in which users can influence driving with specific intentions. To this end, we present EchoVLA, a user-aware VLA that couples camera streams with in situ audio instructions. We augment the nuScenes dataset with temporally aligned, intent-specific speech commands generated by converting ego-motion descriptions into synthetic audios. Further, we compose emotional speech-trajectory pairs into a multimodal Chain-of-Thought (CoT) for fine-tuning a Multimodal Large Model (MLM) based on Qwen2.5-Omni. Specifically, we synthesize the audio-augmented dataset with different emotion types paired with corresponding driving behaviors, leveraging the emotional cues embedded in tone, pitch, and speech tempo to reflect varying user states, such as urgent or hesitant intentions, thus enabling our EchoVLA to interpret not only the semantic content but also the emotional context of audio commands for more nuanced and emotionally adaptive driving behavior. In open-loop benchmarks, our approach reduces the average L2 error by $59.4\%$ and the collision rate by $74.4\%$ compared to the baseline of vision-only perception. More experiments on nuScenes dataset validate that EchoVLA not only steers the trajectory through audio instructions, but also modulates driving behavior in response to the emotions detected in the user's speech.

</details>


### [57] [A Survey on 30+ Years of Automatic Singing Assessment and Singing Information Processing](https://arxiv.org/abs/2601.12153)
*Arthur N. dos Santos,Bruno S. Masiero*

Main category: eess.AS

TL;DR: 这篇综述回顾了过去30年自动歌唱评估和歌唱信息处理技术的发展，分析了客观计算评估与主观人工评估之间的差距，指出了标准化框架缺失、信号分离困难等技术挑战，并探讨了如何通过先进信号处理和AI方法提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 该研究的动机是系统梳理自动歌唱评估和歌唱信息处理技术的历史发展，识别当前技术存在的关键差距和挑战，特别是客观计算评估与主观人工评估之间的鸿沟，以推动更准确、更具教学相关性的自动化歌唱评估系统的发展。

Method: 采用文献综述方法，批判性地分析相关研究文献，绘制这些技术的历史演变图景，同时识别和讨论关键技术差距。分析包括实时视觉反馈系统、声学生物反馈、音高跟踪、频谱分析等技术，以及机器学习和深度神经网络架构的应用。

Result: 分析揭示了持续存在的挑战：缺乏标准化评估框架、难以可靠地从各种噪声源中分离声乐信号、以及高级数字信号处理和人工智能方法在捕捉艺术表现力方面的利用不足。同时确认了交互式系统和机器学习集成等技术进步。

Conclusion: 通过解决这些技术限制，可以弥合客观计算评估与主观人工评估之间的差距，最终提升自动化歌唱评估系统的技术准确性和教学相关性，为歌唱教学、表演分析和声乐训练提供更有效的支持工具。

Abstract: Automatic Singing Assessment and Singing Information Processing have evolved over the past three decades to support singing pedagogy, performance analysis, and vocal training. While the first approach objectively evaluates a singer's performance through computational metrics ranging from real-time visual feedback and acoustical biofeedback to sophisticated pitch tracking and spectral analysis, the latter method compares a predictor vocal signal with a target reference to capture nuanced data embedded in the singing voice. Notable advancements include the development of interactive systems that have significantly improved real-time visual feedback, and the integration of machine learning and deep neural network architectures that enhance the precision of vocal signal processing. This survey critically examines the literature to map the historical evolution of these technologies, while identifying and discussing key gaps. The analysis reveals persistent challenges, such as the lack of standardized evaluation frameworks, difficulties in reliably separating vocal signals from various noise sources, and the underutilization of advanced digital signal processing and artificial intelligence methodologies for capturing artistic expressivity. By detailing these limitations and the corresponding technological advances, this review demonstrates how addressing these issues can bridge the gap between objective computational assessments and subjective human-like evaluations of singing performance, ultimately enhancing both the technical accuracy and pedagogical relevance of automated singing evaluation systems.

</details>


### [58] [AQUA-Bench: Beyond Finding Answers to Knowing When There Are None in Audio Question Answering](https://arxiv.org/abs/2601.12248)
*Chun-Yi Kuan,Hung-yi Lee*

Main category: eess.AS

TL;DR: AQUA-Bench：首个专注于音频问题不可回答性评估的基准，系统评估模型在三种不可回答场景下的表现，揭示当前音频语言模型在不可回答问题上的盲区。


<details>
  <summary>Details</summary>
Motivation: 现有音频问答基准主要覆盖可回答问题，忽略了现实世界中常见的不可回答问题（如误导性、不恰当或与音频信息不兼容的问题），这限制了模型在实际应用中的可靠性和鲁棒性。

Method: 提出AQUA-Bench基准，系统评估三种不可回答场景：1) 答案缺失检测（正确答案选项缺失）；2) 不兼容答案集检测（选项与问题类别不匹配）；3) 不兼容音频问题检测（问题与音频无关或缺乏足够依据）。

Result: 实验表明，虽然模型在标准可回答任务上表现优异，但在不可回答问题上面临显著挑战，揭示了当前音频语言理解的一个盲点。

Conclusion: AQUA-Bench为评估模型可靠性提供了严谨的衡量标准，促进了更鲁棒、更可信的音频语言系统的发展，强调了处理不可回答问题能力的重要性。

Abstract: Recent advances in audio-aware large language models have shown strong performance on audio question answering. However, existing benchmarks mainly cover answerable questions and overlook the challenge of unanswerable ones, where no reliable answer can be inferred from the audio. Such cases are common in real-world settings, where questions may be misleading, ill-posed, or incompatible with the information. To address this gap, we present AQUA-Bench, a benchmark for Audio Question Unanswerability Assessment. It systematically evaluates three scenarios: Absent Answer Detection (the correct option is missing), Incompatible Answer Set Detection (choices are categorically mismatched with the question), and Incompatible Audio Question Detection (the question is irrelevant or lacks sufficient grounding in the audio). By assessing these cases, AQUA-Bench offers a rigorous measure of model reliability and promotes the development of audio-language systems that are more robust and trustworthy. Our experiments suggest that while models excel on standard answerable tasks, they often face notable challenges with unanswerable ones, pointing to a blind spot in current audio-language understanding.

</details>


### [59] [Adaptive Rotary Steering with Joint Autoregression for Robust Extraction of Closely Moving Speakers in Dynamic Scenarios](https://arxiv.org/abs/2601.12345)
*Jakob Kienegger,Timo Gerkmann*

Main category: eess.AS

TL;DR: 提出一种联合自回归框架，通过将处理后的录音作为额外引导，结合跟踪算法和空间滤波，显著提升近距离或交叉说话人的跟踪与增强性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度空间滤波方法在静态多说话人场景中表现良好，但在动态声学条件下（如移动说话人）应用受限。当说话人靠近或交叉时，跟踪变得困难，空间线索对增强效果减弱。

Method: 提出联合自回归框架：1) 使用基于目标初始方向的交错跟踪算法自动旋转声场；2) 将处理后的录音作为额外引导输入到跟踪和增强算法中；3) 利用语音的时频相关性解决空间挑战性说话人配置。

Result: 在合成数据集上，该方法显著改善了近距离说话人的跟踪和增强性能，持续优于可比非自回归方法。真实世界录音在复杂场景（多个说话人交叉、不同说话人到阵列距离）中验证了这些发现。

Conclusion: 通过将处理后的录音作为引导并利用语音时频相关性，提出的联合自回归框架能有效解决动态声学条件下近距离或交叉说话人的跟踪与增强挑战，在复杂真实场景中表现优异。

Abstract: Latest advances in deep spatial filtering for Ambisonics demonstrate strong performance in stationary multi-speaker scenarios by rotating the sound field toward a target speaker prior to multi-channel enhancement. For applicability in dynamic acoustic conditions with moving speakers, we propose to automate this rotary steering using an interleaved tracking algorithm conditioned on the target's initial direction. However, for nearby or crossing speakers, robust tracking becomes difficult and spatial cues less effective for enhancement. By incorporating the processed recording as additional guide into both algorithms, our novel joint autoregressive framework leverages temporal-spectral correlations of speech to resolve spatially challenging speaker constellations. Consequently, our proposed method significantly improves tracking and enhancement of closely spaced speakers, consistently outperforming comparable non-autoregressive methods on a synthetic dataset. Real-world recordings complement these findings in complex scenarios with multiple speaker crossings and varying speaker-to-array distances.

</details>


### [60] [Bone-conduction Guided Multimodal Speech Enhancement with Conditional Diffusion Models](https://arxiv.org/abs/2601.12354)
*Sina Khanagha,Bunlong Lay,Timo Gerkmann*

Main category: eess.AS

TL;DR: 提出一种基于条件扩散模型的多模态语音增强框架，结合骨传导传感器和空气传导麦克风，在极端噪声环境下显著提升性能


<details>
  <summary>Details</summary>
Motivation: 单通道语音增强模型在极端噪声环境下性能显著下降，而骨传导语音作为噪声免疫的补充模态可以有效指导增强，但如何有效整合这一模态仍面临挑战

Method: 提出新颖的多模态语音增强框架，使用条件扩散模型整合骨传导传感器和空气传导麦克风

Result: 该模型在广泛的声学条件下显著优于先前建立的多模态技术和强大的基于扩散的单模态基线

Conclusion: 通过条件扩散模型有效整合骨传导和空气传导模态，能够显著提升极端噪声环境下的语音增强性能

Abstract: Single-channel speech enhancement models face significant performance degradation in extremely noisy environments. While prior work has shown that complementary bone-conducted speech can guide enhancement, effective integration of this noise-immune modality remains a challenge. This paper introduces a novel multimodal speech enhancement framework that integrates bone-conduction sensors with air-conducted microphones using a conditional diffusion model. Our proposed model significantly outperforms previously established multimodal techniques and a powerful diffusion-based single-modal baseline across a wide range of acoustic conditions.

</details>


### [61] [Purification Before Fusion: Toward Mask-Free Speech Enhancement for Robust Audio-Visual Speech Recognition](https://arxiv.org/abs/2601.12436)
*Linzhi Wu,Xingyu Zhang,Hao Yuan,Yakun Zhang,Changyan Zheng,Liang Xie,Tiejun Liu,Erwei Yin*

Main category: eess.AS

TL;DR: 提出一种结合语音增强的端到端抗噪声视听语音识别框架，无需显式噪声掩码生成，通过Conformer瓶颈融合模块隐式优化噪声音频特征，在LRS3基准上优于现有基于掩码的方法。


<details>
  <summary>Details</summary>
Motivation: 传统AVSR在噪声环境中通过视觉线索提升识别准确率，但高噪声音频会在特征融合过程中引入不利干扰。现有基于掩码的方法虽然能过滤音频噪声，但可能同时丢弃语义相关信息。

Method: 提出端到端抗噪声AVSR框架，结合语音增强，无需显式噪声掩码生成。使用基于Conformer的瓶颈融合模块，通过视频辅助隐式优化噪声音频特征，减少模态冗余并增强模态间交互。

Result: 在公开LRS3基准上的实验评估表明，该方法在噪声条件下优于先前先进的基于掩码的基线方法。

Conclusion: 该方法通过隐式特征优化而非显式噪声掩码，在保持语音语义完整性的同时实现了鲁棒的识别性能，为噪声环境下的AVSR提供了有效解决方案。

Abstract: Audio-visual speech recognition (AVSR) typically improves recognition accuracy in noisy environments by integrating noise-immune visual cues with audio signals. Nevertheless, high-noise audio inputs are prone to introducing adverse interference into the feature fusion process. To mitigate this, recent AVSR methods often adopt mask-based strategies to filter audio noise during feature interaction and fusion, yet such methods risk discarding semantically relevant information alongside noise. In this work, we propose an end-to-end noise-robust AVSR framework coupled with speech enhancement, eliminating the need for explicit noise mask generation. This framework leverages a Conformer-based bottleneck fusion module to implicitly refine noisy audio features with video assistance. By reducing modality redundancy and enhancing inter-modal interactions, our method preserves speech semantic integrity to achieve robust recognition performance. Experimental evaluations on the public LRS3 benchmark suggest that our method outperforms prior advanced mask-based baselines under noisy conditions.

</details>


### [62] [Robust Online Overdetermined Independent Vector Analysis Based on Bilinear Decomposition](https://arxiv.org/abs/2601.12485)
*Kang Chen,Xianrui Wang,Yichen Yang,Andreas Brendel,Gongping Huang,Zbyněk Koldovský,Jingdong Chen,Jacob Benesty,Shoji Makino*

Main category: eess.AS

TL;DR: 提出一种基于双线性分解的在线盲源分离方法，通过将长分离滤波器分解为两个短滤波器的双线性形式来减少参数数量，提高在线估计精度。


<details>
  <summary>Details</summary>
Motivation: 在线盲源分离在语音通信和人机交互中至关重要。现有方法如过定独立向量分析(OverIVA)虽然性能良好，但在大型麦克风阵列中参数数量快速增长，会降低在线估计精度。

Method: 将每个长分离滤波器分解为两个短滤波器的双线性形式以减少参数数量。由于两个滤波器紧密耦合，设计了交替迭代投影算法来轮流更新它们。

Result: 仿真结果表明，在参数数量大幅减少的情况下，所提方法实现了更好的性能和鲁棒性。

Conclusion: 通过双线性分解减少参数数量的方法有效解决了大型麦克风阵列中在线盲源分离的参数增长问题，提高了估计精度和鲁棒性。

Abstract: Online blind source separation is essential for both speech communication and human-machine interaction. Among existing approaches, overdetermined independent vector analysis (OverIVA) delivers strong performance by exploiting the statistical independence of source signals and the orthogonality between source and noise subspaces. However, when applied to large microphone arrays, the number of parameters grows rapidly, which can degrade online estimation accuracy. To overcome this challenge, we propose decomposing each long separation filter into a bilinear form of two shorter filters, thereby reducing the number of parameters. Because the two filters are closely coupled, we design an alternating iterative projection algorithm to update them in turn. Simulation results show that, with far fewer parameters, the proposed method achieves improved performance and robustness.

</details>


### [63] [SLAP: Scalable Language-Audio Pretraining with Variable-Duration Audio and Multi-Objective Training](https://arxiv.org/abs/2601.12594)
*Xinhao Mei,Gael Le Lan,Haohe Liu,Zhaoheng Ni,Varun Nagaraja,Yang Liu,Yangyang Shi,Vikas Chandra*

Main category: eess.AS

TL;DR: SLAP模型通过扩展到1.09亿音频-文本对、支持可变时长音频、结合多种训练目标，在语言-音频预训练中取得SOTA性能


<details>
  <summary>Details</summary>
Motivation: 当前CLAP模型存在三个主要限制：1) 训练数据集较小（通常仅几百万样本）；2) 仅限于固定短时长音频，无法处理现实世界中可变时长的音频；3) 标准对比训练目标仅关注全局表示，难以学习密集细粒度音频特征

Method: 提出SLAP模型，将语言-音频预训练扩展到1.09亿音频-文本对，支持可变音频时长，并在单阶段训练中统一对比损失与额外的自监督和字幕生成损失

Result: 在音频-文本检索和零样本音频分类任务上取得了新的最先进性能，在多个基准测试中表现出色

Conclusion: SLAP通过大规模数据扩展、支持可变时长音频以及多目标训练，成功解决了现有CLAP模型的局限性，为语言-音频预训练提供了更强大的解决方案

Abstract: Contrastive language-audio pretraining (CLAP) has achieved notable success in learning semantically rich audio representations and is widely adopted for various audio-related tasks. However, current CLAP models face several key limitations. First, they are typically trained on relatively small datasets, often comprising a few million audio samples. Second, existing CLAP models are restricted to short and fixed duration, which constrains their usage in real-world scenarios with variable-duration audio. Third, the standard contrastive training objective operates on global representations, which may hinder the learning of dense, fine-grained audio features. To address these challenges, we introduce Scalable Language-Audio Pretraining (SLAP), which scales language-audio pretraining to 109 million audio-text pairs with variable audio durations and incorporates multiple training objectives. SLAP unifies contrastive loss with additional self-supervised and captioning losses in a single-stage training, facilitating the learning of richer dense audio representations. The proposed SLAP model achieves new state-of-the-art performance on audio-text retrieval and zero-shot audio classification tasks, demonstrating its effectiveness across diverse benchmarks.

</details>


### [64] [Improving Audio Question Answering with Variational Inference](https://arxiv.org/abs/2601.12700)
*Haolin Chen*

Main category: eess.AS

TL;DR: 将改进的变分在线牛顿优化器应用于多模态大语言模型的音频问答任务微调，变分推断不仅提升了预测准确性，还显著改善了校准性，降低了模型过度自信的问题。


<details>
  <summary>Details</summary>
Motivation: 变分推断能够对模型参数的不确定性进行显式建模，从而提升预测的可靠性并产生更好的校准输出。本研究旨在探索变分推断在具有挑战性的多模态理解和推理任务中的优势。

Method: 将改进的变分在线牛顿优化器应用于多模态大语言模型在音频问答任务上的微调。IVON是一种最近的变分推断优化器，用于估计模型参数的后验分布。

Result: 变分推断不仅提高了预测准确性，还显著改善了校准性，减少了模型的过度自信。这些进展进一步支持了风险敏感应用，如选择性预测。

Conclusion: 变分推断在多模态理解和推理任务中具有显著优势，能够同时提升模型性能和校准性，为需要可靠置信度估计的风险敏感应用提供了支持。

Abstract: Variational inference (VI) provides a principled framework for estimating posterior distributions over model parameters, enabling explicit modeling of weight uncertainty during optimization. By capturing this uncertainty, VI improves the reliability of predictions, yielding better calibrated outputs. In this work, we investigate the benefits of VI for challenging multimodal understanding and reasoning by applying the Improved Variational Online Newton (IVON), a recent VI optimizer, to fine-tuning a multimodal large language model on audio question answering tasks. Our results show that VI not only enhances predictive accuracy but also significantly improves calibration, reducing the model's overconfidence. These advances further support risk-sensitive applications such as selective prediction, where reliable confidence estimates are crucial.

</details>


### [65] [CodeSep: Low-Bitrate Codec-Driven Speech Separation with Base-Token Disentanglement and Auxiliary-Token Serial Prediction](https://arxiv.org/abs/2601.12757)
*Hui-Peng Du,Yang Ai,Xiao-Hang Jiang,Rui-Chen Zheng,Zhen-Hua Ling*

Main category: eess.AS

TL;DR: CodeSep：一种将语音分离与低比特率压缩相结合的编解码驱动模型，通过基础令牌解耦和辅助令牌串行预测实现多说话人分离和高效传输


<details>
  <summary>Details</summary>
Motivation: 针对在线会议和对话存档等应用场景，需要同时处理多说话人分离和高效传输/存储的需求，传统方法通常分别处理这两个任务，缺乏一体化解决方案

Method: 提出CodeSep模型，包含基于残差向量量化器的神经语音编解码器、基础令牌解耦模块和并行辅助令牌串行预测模块。基础令牌解耦模块将混合语音梅尔谱图解耦为各说话人的基础令牌，然后通过辅助令牌串行预测模块串行预测辅助令牌，最后通过编解码器解码重建分离波形

Result: 实验结果表明，CodeSep在仅1kbps的比特率下实现了令人满意的分离性能，优于基线方法

Conclusion: CodeSep成功地将语音分离与低比特率压缩相结合，为在线会议和对话存档等应用提供了一体化解决方案，在保持良好分离质量的同时实现了高效传输

Abstract: This paper targets a new scenario that integrates speech separation with speech compression, aiming to disentangle multiple speakers while producing discrete representations for efficient transmission or storage, with applications in online meetings and dialogue archiving. To address this scenario, we propose CodeSep, a codec-driven model that jointly performs speech separation and low-bitrate compression. CodeSep comprises a residual vector quantizer (RVQ)-based plain neural speech codec, a base-token disentanglement (BTD) module, and parallel auxiliary-token serial prediction (ATSP) modules. The BTD module disentangles mixed-speech mel-spectrograms into base tokens for each speaker, which are then refined by ATSP modules to serially predict auxiliary tokens, and finally, all tokens are decoded to reconstruct separated waveforms through the codec decoder. During training, the codec's RVQ provides supervision with permutation-invariant and teacher-forcing-based cross-entropy losses. As only base tokens are transmitted or stored, CodeSep achieves low-bitrate compression. Experimental results show that CodeSep attains satisfactory separation performance at only 1 kbps compared with baseline methods.

</details>


### [66] [Adaptive Speaker Embedding Self-Augmentation for Personal Voice Activity Detection with Short Enrollment Speech](https://arxiv.org/abs/2601.12769)
*Fuyuan Feng,Wenbin Zhang,Yu Gao,Longting Xu,Xiaofeng Mou,Yi Xu*

Main category: eess.AS

TL;DR: 提出自适应说话人嵌入自增强策略，通过混合语音关键帧嵌入增强原始注册嵌入，提升短注册条件下的个人语音活动检测性能


<details>
  <summary>Details</summary>
Motivation: 个人语音活动检测性能严重依赖说话人嵌入质量，而实际应用中注册语音通常很短（如唤醒词），提供的信息有限，需要解决短注册条件下的性能瓶颈

Method: 1）自适应说话人嵌入自增强策略：从混合语音中提取关键帧嵌入，通过加性融合增强原始注册嵌入；2）长期自适应策略：在检测过程中迭代优化嵌入，缓解说话人时变性问题

Result: 在短注册条件下，召回率、精确率和F1分数均有显著提升，经过5次迭代更新后，性能可匹配完整长度注册的效果

Conclusion: 提出的自适应说话人嵌入自增强策略有效解决了短注册条件下的PVAD性能瓶颈，通过迭代优化实现了与完整注册相当的性能，具有实际应用价值

Abstract: Personal Voice Activity Detection (PVAD) is crucial for identifying target speaker segments in the mixture, yet its performance heavily depends on the quality of speaker embeddings. A key practical limitation is the short enrollment speech--such as a wake-up word--which provides limited cues. This paper proposes a novel adaptive speaker embedding self-augmentation strategy that enhances PVAD performance by augmenting the original enrollment embeddings through additive fusion of keyframe embeddings extracted from mixed speech. Furthermore, we introduce a long-term adaptation strategy to iteratively refine embeddings during detection, mitigating speaker temporal variability. Experiments show significant gains in recall, precision, and F1-score under short enrollment conditions, matching full-length enrollment performance after five iterative updates. The source code is available at https://anonymous.4open.science/r/ASE-PVAD-E5D6 .

</details>


### [67] [ImmersiveFlow: Stereo-to-7.1.4 spatial audio generation with flow matching](https://arxiv.org/abs/2601.12950)
*Zining Liang,Runbang Wang,Xuzhou Ye,Qiuqiang Kong*

Main category: eess.AS

TL;DR: ImmersiveFlow：首个端到端生成框架，直接从立体声输入合成7.1.4格式空间音频，显著优于传统上混技术


<details>
  <summary>Details</summary>
Motivation: 现有生成方法局限于双耳音频和一阶Ambisonics等低维格式，前者仅适用于耳机播放，后者存在空间混叠和高频分辨率不足的问题，无法满足AR/VR、家庭娱乐和车载音响等应用对沉浸式空间音频的需求

Method: 利用Flow Matching在预训练VAE潜在空间中学习从立体声输入到多声道空间特征的轨迹，推理时通过Flow Matching模型预测潜在特征，再由VAE解码并转换为最终的7.1.4波形

Result: 综合客观和主观评估表明，该方法能产生感知丰富的声场和增强的外部化效果，显著优于传统上混技术

Conclusion: ImmersiveFlow成功克服了现有空间音频生成方法的局限性，为高质量沉浸式音频合成提供了有效的端到端解决方案

Abstract: Immersive spatial audio has become increasingly critical for applications ranging from AR/VR to home entertainment and automotive sound systems. However, existing generative methods remain constrained to low-dimensional formats such as binaural audio and First-Order Ambisonics (FOA). Binaural rendering is inherently limited to headphone playback, while FOA suffers from spatial aliasing and insufficient resolution for high-frequency. To overcome these limitations, we introduce ImmersiveFlow, the first end-to-end generative framework that directly synthesizes discrete 7.1.4 format spatial audio from stereo input. ImmersiveFlow leverages Flow Matching to learn trajectories from stereo inputs to multichannel spatial features within a pretrained VAE latent space. At inference, the Flow Matching model predicted latent features are decoded by the VAE and converted into the final 7.1.4 waveform. Comprehensive objective and subjective evaluations demonstrate that our method produces perceptually rich sound fields and enhanced externalization, significantly outperforming traditional upmixing techniques. Code implementations and audio samples are provided at: https://github.com/violet-audio/ImmersiveFlow.

</details>


### [68] [VoCodec: An Efficient Lightweight Low-Bitrate Speech Codec](https://arxiv.org/abs/2601.13055)
*Leyan Yang,Ronghui Hu,Yang Xu,Jing Lu*

Main category: eess.AS

TL;DR: VoCodec是一个低复杂度、低延迟的神经语音编解码器，在LRAC挑战赛中排名第四，并在干净语音测试集上获得最高主观评分


<details>
  <summary>Details</summary>
Motivation: 端到端神经语音编解码器虽然能在极低比特率下保持高保真重建，但实时通信需要低计算复杂度和低延迟

Method: 基于Vocos声码器作为骨干网络，设计VoCodec模型，计算复杂度仅349.29M MACs/s，延迟30ms；前端级联轻量级神经网络扩展语音增强能力

Result: 在2025年LRAC挑战赛Track 1中排名第四，在干净语音测试集上获得最高MUSHRA主观评分；两个系统在多个评估指标上均表现优异

Conclusion: VoCodec实现了低复杂度、低延迟的语音编解码，性能优异，并通过级联神经网络扩展了语音增强能力

Abstract: Recent advancements in end-to-end neural speech codecs enable compressing audio at extremely low bitrates while maintaining high-fidelity reconstruction. Meanwhile, low computational complexity and low latency are crucial for real-time communication. In this paper, we propose VoCodec, a speech codec model featuring a computational complexity of only 349.29M multiply-accumulate operations per second (MACs/s) and a latency of 30 ms. With the competitive vocoder Vocos as its backbone, the proposed model ranked fourth on Track 1 in the 2025 LRAC Challenge and achieved the highest subjective evaluation score (MUSHRA) on the clean speech test set. Additionally, we cascade a lightweight neural network at the front end to extend its capability of speech enhancement. Experimental results demonstrate that the two systems achieve competitive performance across multiple evaluation metrics. Speech samples can be found at https://acceleration123.github.io/.

</details>


### [69] [Content Leakage in LibriSpeech and Its Impact on the Privacy Evaluation of Speaker Anonymization](https://arxiv.org/abs/2601.13107)
*Carlos Franzreb,Arnab Das,Tim Polzehl,Sebastian Möller*

Main category: eess.AS

TL;DR: 研究发现Librispeech数据集存在词汇泄露说话人身份的问题，提出EdAcc数据集能更好地评估语音匿名化技术


<details>
  <summary>Details</summary>
Motivation: 当前语音匿名化技术主要关注隐藏说话人的声学特征，但忽略了说话人可能通过其独特的词汇使用模式被识别。Librispeech作为常用的匿名化评估数据集存在缺陷，因为说话人朗读的书籍内容差异很大，导致可以通过词汇特征识别说话人身份。

Method: 通过分析Librispeech数据集中说话人的词汇特征，揭示其身份泄露问题。同时提出EdAcc数据集作为替代方案，该数据集包含更自然的自发语音和更多样化的说话人，减少词汇特征对说话人识别的影响。

Result: Librispeech数据集中说话人可以通过其独特的词汇特征被准确识别，即使使用完美的匿名化技术也无法防止这种身份泄露。相比之下，EdAcc数据集中只有少数说话人能够通过词汇特征被识别，更适用于评估语音匿名化技术的真实效果。

Conclusion: Librispeech不适合用于评估语音匿名化技术，因为其固有的词汇特征会导致说话人身份泄露。EdAcc数据集提供了更合理的评估基准，能够更好地反映匿名化技术的实际效果，并为研究匿名化机制提供更多见解。

Abstract: Speaker anonymization aims to conceal a speaker's identity, without considering the linguistic content. In this study, we reveal a weakness of Librispeech, the dataset that is commonly used to evaluate anonymizers: the books read by the Librispeech speakers are so distinct, that speakers can be identified by their vocabularies. Even perfect anonymizers cannot prevent this identity leakage. The EdAcc dataset is better in this regard: only a few speakers can be identified through their vocabularies, encouraging the attacker to look elsewhere for the identities of the anonymized speakers. EdAcc also comprises spontaneous speech and more diverse speakers, complementing Librispeech and giving more insights into how anonymizers work.

</details>


### [70] [AMDM-SE: Attention-based Multichannel Diffusion Model for Speech Enhancement](https://arxiv.org/abs/2601.13140)
*Renana Opochinsky,Sharon Gannot*

Main category: eess.AS

TL;DR: 提出AMDM-SE模型，将注意力机制融入多通道扩散模型用于语音增强，通过跨通道时频注意力块利用空间信息，在CHiME-3基准上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像重建和单通道语音增强中表现出色，但多通道扩散模型仍处于早期阶段，缺乏对空间建模的高级机制（如注意力）的有效利用。随着多麦克风设备的普及，需要开发能充分利用多通道信息的扩散模型来提升语音增强性能。

Method: 提出AMDM-SE（基于注意力的多通道扩散模型），核心创新是跨通道时频注意力块，该块能够捕捉通道间的空间信息，在生成式扩散框架中实现细粒度信号细节的忠实重建。

Result: 在CHiME-3基准测试中，AMDM-SE优于单通道扩散基线、无注意力的多通道模型以及基于DNN的预测方法。模拟数据实验进一步验证了所提多通道注意力机制的重要性。

Conclusion: 将针对性的多通道注意力机制融入扩散模型能显著提升降噪性能。虽然多通道扩散语音增强仍是新兴领域，但本研究为该方向提供了新的补充方法。

Abstract: Diffusion models have recently achieved impressive results in reconstructing images from noisy inputs, and similar ideas have been applied to speech enhancement by treating time-frequency representations as images. With the ubiquity of multi-microphone devices, we extend state-of-the-art diffusion-based methods to exploit multichannel inputs for improved performance. Multichannel diffusion-based enhancement remains in its infancy, with prior work making limited use of advanced mechanisms such as attention for spatial modeling - a gap addressed in this paper. We propose AMDM-SE, an Attention-based Multichannel Diffusion Model for Speech Enhancement, designed specifically for noise reduction. AMDM-SE leverages spatial inter-channel information through a novel cross-channel time-frequency attention block, enabling faithful reconstruction of fine-grained signal details within a generative diffusion framework. On the CHiME-3 benchmark, AMDM-SE outperforms both a single-channel diffusion baseline and a multichannel model without attention, as well as a strong DNN-based predictive method. Simulated-data experiments further underscore the importance of the proposed multichannel attention mechanism. Overall, our results show that incorporating targeted multichannel attention into diffusion models substantially improves noise reduction. While multichannel diffusion-based speech enhancement is still an emerging field, our work contributes a new and complementary approach to the growing body of research in this direction.

</details>


### [71] [RLBR: Reinforcement Learning with Biasing Rewards for Contextual Speech Large Language Models](https://arxiv.org/abs/2601.13409)
*Bo Ren,Ruchao Fan,Yelong Shen,Weizhu Chen,Jinyu Li*

Main category: eess.AS

TL;DR: 提出RLBR方法，通过偏置词奖励和参考感知机制改进语音LLM对罕见词和领域术语的识别能力，在LibriSpeech上显著提升性能


<details>
  <summary>Details</summary>
Motivation: 当前语音大语言模型在识别罕见词和领域特定术语方面仍存在困难，需要专门的方法来提升这些词汇的识别准确性

Method: 提出RLBR（强化学习与偏置奖励）方法：1）使用专门的偏置词偏好奖励来强调偏置词；2）引入参考感知机制，结合参考转录扩展强化学习的轨迹探索空间

Result: 在LibriSpeech语料库上，RLBR在不同偏置列表大小下均显著优于SFT基线和近期方法，在test-clean/test-other集上，偏置词错误率分别达到0.59%/2.11%（100词）、1.09%/3.24%（500词）、1.36%/4.04%（1000词），且不影响整体WER

Conclusion: RLBR方法有效提升了语音LLM对罕见词和领域术语的识别能力，通过强化学习中的专门奖励设计和参考感知机制实现了显著的性能改进

Abstract: Speech large language models (LLMs) have driven significant progress in end-to-end speech understanding and recognition, yet they continue to struggle with accurately recognizing rare words and domain-specific terminology. This paper presents a novel fine-tuning method, Reinforcement Learning with Biasing Rewards (RLBR), which employs a specialized biasing words preferred reward to explicitly emphasize biasing words in the reward calculation. In addition, we introduce reference-aware mechanisms that extend the reinforcement learning algorithm with reference transcription to strengthen the potential trajectory exploration space. Experiments on the LibriSpeech corpus across various biasing list sizes demonstrate that RLBR delivers substantial performance improvements over a strong supervised fine-tuning (SFT) baseline and consistently outperforms several recently published methods. The proposed approach achieves excellent performance on the LibriSpeech test-clean and test-other sets, reaching Biasing Word Error Rates (BWERs) of 0.59% / 2.11%, 1.09% / 3.24%, and 1.36% / 4.04% for biasing list sizes of 100, 500, and 1000, respectively, without compromising the overall WERs.

</details>


### [72] [ICASSP 2026 URGENT Speech Enhancement Challenge](https://arxiv.org/abs/2601.13531)
*Chenda Li,Wei Wang,Marvin Sach,Wangyou Zhang,Kohei Saijo,Samuele Cornell,Yihui Fu,Zhaoheng Ni,Tim Fingscheidt,Shinji Watanabe,Yanmin Qian*

Main category: eess.AS

TL;DR: ICASSP 2026 URGENT挑战赛聚焦通用语音增强系统，包含两个互补赛道：通用语音增强和增强语音质量评估，吸引了80多个团队注册。


<details>
  <summary>Details</summary>
Motivation: 推动能够处理多种失真、领域和输入条件的通用语音增强系统的发展，解决传统语音增强系统在多样化和复杂场景下的局限性。

Method: 挑战赛分为两个互补赛道：Track 1专注于通用语音增强，Track 2引入增强语音的质量评估。提供基准系统、数据集和评估协议，让参赛团队开发解决方案。

Result: 挑战赛吸引了超过80个团队注册，其中29个团队提交了有效参赛作品，显示出社区对鲁棒语音增强技术的浓厚兴趣。

Conclusion: ICASSP 2026 URGENT挑战赛成功推动了通用语音增强技术的发展，通过双赛道设计促进了语音增强和质量评估的协同进步，为未来研究奠定了基础。

Abstract: The ICASSP 2026 URGENT Challenge advances the series by focusing on universal speech enhancement (SE) systems that handle diverse distortions, domains, and input conditions. This overview paper details the challenge's motivation, task definitions, datasets, baseline systems, evaluation protocols, and results. The challenge is divided into two complementary tracks. Track 1 focuses on universal speech enhancement, while Track 2 introduces speech quality assessment for enhanced speech. The challenge attracted over 80 team registrations, with 29 submitting valid entries, demonstrating significant community interest in robust SE technologies.

</details>


### [73] [S$^2$Voice: Style-Aware Autoregressive Modeling with Enhanced Conditioning for Singing Style Conversion](https://arxiv.org/abs/2601.13629)
*Ziqian Wang,Xianjun Xia,Chuanzeng Huang,Lei Xie*

Main category: eess.AS

TL;DR: S²Voice是SVCC 2025歌唱声音转换挑战赛的获胜系统，基于两阶段Vevo基线，通过风格嵌入、说话人嵌入、数据增强和多阶段训练策略，在风格相似度和音色保真度方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有歌唱声音转换系统在风格控制和鲁棒性方面仍有改进空间，特别是在细粒度风格建模和音色保真度方面需要提升。

Method: 1. 在自回归大语言模型中集成风格嵌入（FiLM风格层归一化条件和风格感知交叉注意力）
2. 在流匹配变换器中引入全局说话人嵌入
3. 通过自动化流水线构建大规模高质量歌唱语料库
4. 采用多阶段训练策略（监督微调+直接偏好优化）

Result: 在SVCC 2025挑战赛中，S²Voice在领域内和零样本歌唱风格转换两个赛道均获胜，在风格相似度、歌手相似度和自然度方面表现最优。

Conclusion: S²Voice通过创新的风格控制机制、音色保真度增强、高质量数据收集和多阶段训练策略，显著提升了歌唱声音转换的性能，特别是在风格保真度和泛化能力方面。

Abstract: We present S$^2$Voice, the winning system of the Singing Voice Conversion Challenge (SVCC) 2025 for both the in-domain and zero-shot singing style conversion tracks. Built on the strong two-stage Vevo baseline, S$^2$Voice advances style control and robustness through several contributions. First, we integrate style embeddings into the autoregressive large language model (AR LLM) via a FiLM-style layer-norm conditioning and a style-aware cross-attention for enhanced fine-grained style modeling. Second, we introduce a global speaker embedding into the flow-matching transformer to improve timbre similarity. Third, we curate a large, high-quality singing corpus via an automated pipeline for web harvesting, vocal separation, and transcript refinement. Finally, we employ a multi-stage training strategy combining supervised fine-tuning (SFT) and direct preference optimization (DPO). Subjective listening tests confirm our system's superior performance: leading in style similarity and singer similarity for Task 1, and across naturalness, style similarity, and singer similarity for Task 2. Ablation studies demonstrate the effectiveness of our contributions in enhancing style fidelity, timbre preservation, and generalization. Audio samples are available~\footnote{https://honee-w.github.io/SVC-Challenge-Demo/}.

</details>


### [74] [Co-Initialization of Control Filter and Secondary Path via Meta-Learning for Active Noise Control](https://arxiv.org/abs/2601.13849)
*Ziyi Yang,Li Rao,Zhengding Luo,Dongyuan Shi,Qirui Huang,Woon-Seng Gan*

Main category: eess.AS

TL;DR: 使用MAML元学习联合初始化FxLMS ANC系统的控制滤波器和次级路径模型，以快速适应声学环境变化


<details>
  <summary>Details</summary>
Motivation: ANC系统在声学环境变化时需要快速适应，但早期性能很大程度上取决于初始化。传统方法在环境变化时性能下降，需要快速启动机制。

Method: 采用模型无关元学习（MAML）联合初始化控制滤波器和次级路径模型，保持运行时算法不变。在少量测量路径上预训练，使用短两阶段内循环模拟识别和残余噪声减少过程。

Result: 在在线次级路径建模FxLMS测试平台上，相比无重新初始化的基线，该方法降低了早期误差、缩短了达到目标时间、减少了辅助噪声能量、加速了路径变化后的恢复。

Conclusion: 该方法为前馈ANC在环境变化下提供了简单快速的启动机制，只需少量路径进行预训练，保持了运行时算法不变。

Abstract: Active noise control (ANC) must adapt quickly when the acoustic environment changes, yet early performance is largely dictated by initialization. We address this with a Model-Agnostic Meta-Learning (MAML) co-initialization that jointly sets the control filter and the secondary-path model for FxLMS-based ANC while keeping the runtime algorithm unchanged. The initializer is pre-trained on a small set of measured paths using short two-phase inner loops that mimic identification followed by residual-noise reduction, and is applied by simply setting the learned initial coefficients. In an online secondary path modeling FxLMS testbed, it yields lower early-stage error, shorter time-to-target, reduced auxiliary-noise energy, and faster recovery after path changes than a baseline without re-initialization. The method provides a simple fast start for feedforward ANC under environment changes, requiring a small set of paths to pre-train.

</details>


### [75] [Synthetic Singers: A Review of Deep-Learning-based Singing Voice Synthesis Approaches](https://arxiv.org/abs/2601.13910)
*Changhao Pan,Dongyu Yao,Yu Zhang,Wenxiang Guo,Jingyu Lu,Zhiyuan Zhu,Zhou Zhao*

Main category: eess.AS

TL;DR: 这是一篇关于歌声合成（SVS）的综述论文，系统分析了基于深度学习的歌声合成系统及其核心技术，包括分类、架构、建模方法、数据集和评估基准。


<details>
  <summary>Details</summary>
Motivation: 尽管歌声合成领域取得了显著进展，但缺乏对深度学习歌声合成系统及其使能技术的系统性综述。本文旨在填补这一空白，为研究者和工程师提供全面的参考。

Method: 首先按任务类型对现有系统进行分类，然后将当前架构组织为两大范式：级联方法和端到端方法。深入分析核心技术，包括歌声建模和控制技术。最后回顾相关数据集、标注工具和评估基准。

Result: 提供了对SVS模型文献的最新综述，包括系统分类、架构分析、核心技术讨论以及相关资源的整理，为领域研究提供了有价值的参考框架。

Conclusion: 这篇综述为歌声合成领域提供了系统性分析框架，涵盖了从系统分类到技术细节的全面内容，有助于推动该领域的进一步发展。相关材料已开源供社区使用。

Abstract: Recent advances in singing voice synthesis (SVS) have attracted substantial attention from both academia and industry. With the advent of large language models and novel generative paradigms, producing controllable, high-fidelity singing voices has become an attainable goal. Yet the field still lacks a comprehensive survey that systematically analyzes deep-learning-based singing voice synthesis systems and their enabling technologies. To address the aforementioned issue, this survey first categorizes existing systems by task type and then organizes current architectures into two major paradigms: cascaded and end-to-end approaches. Moreover, we provide an in-depth analysis of core technologies, covering singing modeling and control techniques. Finally, we review relevant datasets, annotation tools, and evaluation benchmarks that support training and assessment. In appendix, we introduce training strategies and further discussion of SVS. This survey provides an up-to-date review of the literature on SVS models, which would be a useful reference for both researchers and engineers. Related materials are available at https://github.com/David-Pigeon/SyntheticSingers.

</details>


### [76] [Stream-Voice-Anon: Enhancing Utility of Real-Time Speaker Anonymization via Neural Audio Codec and Language Models](https://arxiv.org/abs/2601.13948)
*Nikita Kuzmin,Songting Liu,Kong Aik Lee,Eng Siong Chng*

Main category: eess.AS

TL;DR: Stream-Voice-Anon：基于神经音频编解码器和因果语言模型的流式说话人匿名化系统，在保持低延迟的同时显著提升语音可懂度和情感保留


<details>
  <summary>Details</summary>
Motivation: 在线语音应用中保护说话人身份至关重要，但流式说话人匿名化研究不足。现有基于神经音频编解码器的在线语言模型系统主要用于语音转换而非匿名化，缺乏隐私保护所需的技术

Method: 将现代因果语言模型为基础的神经音频编解码器架构适配于流式说话人匿名化，集成伪说话人表示采样、说话人嵌入混合和多样化提示选择策略，利用量化内容码的解耦特性防止说话人信息泄露

Result: 在VoicePrivacy 2024挑战协议下，相比之前最先进的流式方法DarkStream，可懂度相对提升46%（WER降低），情感保留相对提升28%（UAR），延迟相当（180ms vs 200ms），对懒惰知情攻击者保持可比隐私保护，但对半知情攻击者有15%相对退化

Conclusion: Stream-Voice-Anon成功将因果语言模型为基础的神经音频编解码器架构适配于流式说话人匿名化，在保持低延迟和隐私保护的同时显著改善了语音质量和情感保留，探索了延迟与隐私之间的权衡

Abstract: Protecting speaker identity is crucial for online voice applications, yet streaming speaker anonymization (SA) remains underexplored. Recent research has demonstrated that neural audio codec (NAC) provides superior speaker feature disentanglement and linguistic fidelity. NAC can also be used with causal language models (LM) to enhance linguistic fidelity and prompt control for streaming tasks. However, existing NAC-based online LM systems are designed for voice conversion (VC) rather than anonymization, lacking the techniques required for privacy protection. Building on these advances, we present Stream-Voice-Anon, which adapts modern causal LM-based NAC architectures specifically for streaming SA by integrating anonymization techniques. Our anonymization approach incorporates pseudo-speaker representation sampling, a speaker embedding mixing and diverse prompt selection strategies for LM conditioning that leverage the disentanglement properties of quantized content codes to prevent speaker information leakage. Additionally, we compare dynamic and fixed delay configurations to explore latency-privacy trade-offs in real-time scenarios. Under the VoicePrivacy 2024 Challenge protocol, Stream-Voice-Anon achieves substantial improvements in intelligibility (up to 46% relative WER reduction) and emotion preservation (up to 28% UAR relative) compared to the previous state-of-the-art streaming method DarkStream while maintaining comparable latency (180ms vs 200ms) and privacy protection against lazy-informed attackers, though showing 15% relative degradation against semi-informed attackers.

</details>


### [77] [DAME: Duration-Aware Matryoshka Embedding for Duration-Robust Speaker Verification](https://arxiv.org/abs/2601.13999)
*Youngmoon Jung,Joon-Young Yang,Ju-ho Kim,Jaeyoung Roh,Chang Woo Han,Hoon-Young Cho*

Main category: eess.AS

TL;DR: 提出DAME框架，通过嵌套层次化的子嵌入表示来匹配不同时长的语音，短语音用低维表示，长语音用高维表示，提升短语音说话人验证性能


<details>
  <summary>Details</summary>
Motivation: 短语音说话人验证面临挑战，现有方法使用固定维度的嵌入表示，无法根据语音时长动态调整表示容量，导致信息利用不充分

Method: 提出Duration-Aware Matryoshka Embedding (DAME)框架，构建与语音时长对齐的嵌套层次化子嵌入表示，支持从头训练和微调，作为传统大间隔微调的替代方案

Result: 在VoxCeleb1-O/E/H和VOiCES数据集上，DAME显著降低了1秒等短时语音的等错误率，同时保持全长语音性能，无需额外推理成本

Conclusion: DAME框架通过时长感知的嵌套嵌入表示，有效解决了短语音说话人验证的挑战，在不同编码器架构和训练设置下都具有良好的泛化能力

Abstract: Short-utterance speaker verification remains challenging due to limited speaker-discriminative cues in short speech segments. While existing methods focus on enhancing speaker encoders, the embedding learning strategy still forces a single fixed-dimensional representation reused for utterances of any length, leaving capacity misaligned with the information available at different durations. We propose Duration-Aware Matryoshka Embedding (DAME), a model-agnostic framework that builds a nested hierarchy of sub-embeddings aligned to utterance durations: lower-dimensional representations capture compact speaker traits from short utterances, while higher dimensions encode richer details from longer speech. DAME supports both training from scratch and fine-tuning, and serves as a direct alternative to conventional large-margin fine-tuning, consistently improving performance across durations. On the VoxCeleb1-O/E/H and VOiCES evaluation sets, DAME consistently reduces the equal error rate on 1-s and other short-duration trials, while maintaining full-length performance with no additional inference cost. These gains generalize across various speaker encoder architectures under both general training and fine-tuning setups.

</details>


### [78] [MATE: Matryoshka Audio-Text Embeddings for Open-Vocabulary Keyword Spotting](https://arxiv.org/abs/2601.14012)
*Youngmoon Jung,Myunghun Jung,Joon-Young Yang,Yong-Hyeok Lee,Jaeyoung Roh,Hoon-Young Cho*

Main category: eess.AS

TL;DR: 提出MATE框架，通过嵌套子嵌入实现多粒度音频-文本匹配，在开放词汇关键词检测中达到SOTA效果


<details>
  <summary>Details</summary>
Motivation: 现有基于嵌入学习的语音关键词检测方法通常使用单一固定维度的嵌入表示，限制了匹配的灵活性和效率。需要一种能够同时支持多种粒度匹配的嵌入框架。

Method: 提出Matryoshka Audio-Text Embeddings (MATE)双编码器框架，通过嵌套子嵌入（前缀）在单个向量中编码多个粒度。引入PCA引导的前缀对齐方法，使用PCA压缩的完整文本嵌入作为教师目标来对齐音频和文本前缀。

Result: 在WSJ和LibriPhrase数据集上实现了最先进的性能，无需任何推理开销。这是首次将matryoshka风格嵌入应用于关键词检测任务。

Conclusion: MATE框架通过多粒度嵌入表示显著提升了开放词汇关键词检测的性能，将关键信息集中在低维前缀中，而高维添加细节，实现了高效灵活的匹配。

Abstract: Open-vocabulary keyword spotting (KWS) with text-based enrollment has emerged as a flexible alternative to fixed-phrase triggers. Prior utterance-level matching methods, from an embedding-learning standpoint, learn embeddings at a single fixed dimensionality. We depart from this design and propose Matryoshka Audio-Text Embeddings (MATE), a dual-encoder framework that encodes multiple embedding granularities within a single vector via nested sub-embeddings ("prefixes"). Specifically, we introduce a PCA-guided prefix alignment: PCA-compressed versions of the full text embedding for each prefix size serve as teacher targets to align both audio and text prefixes. This alignment concentrates salient keyword cues in lower-dimensional prefixes, while higher dimensions add detail. MATE is trained with standard deep metric learning objectives for audio-text KWS, and is loss-agnostic. To our knowledge, this is the first application of matryoshka-style embeddings to KWS, achieving state-of-the-art results on WSJ and LibriPhrase without any inference overhead.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [79] [Embryonic Exposure to VPA Influences Chick Vocalisations: A Computational Study](https://arxiv.org/abs/2601.12203)
*Antonella M. C. Torrisi,Inês Nolasco,Paola Sgadò,Elisabetta Versace,Emmanouil Benetos*

Main category: cs.SD

TL;DR: 开发了自动化检测、声学特征提取和无监督学习的计算框架来分析雏鸡鸣叫，发现VPA暴露雏鸡鸣叫特征改变，鸣叫库出现异常。


<details>
  <summary>Details</summary>
Motivation: 传统鸣叫分析方法依赖人工标注和预定义类别，存在偏见、可扩展性有限且无法捕捉鸣叫库的完整复杂性，需要开发自动化计算框架。

Method: 开发了自动化检测、声学特征提取和无监督学习的计算框架，应用于新孵化雏鸡数据集识别主要鸣叫簇，并在VPA暴露实验数据集上验证。

Result: 识别出两个主要鸣叫簇；VPA暴露雏鸡鸣叫库改变，轻柔鸣叫相对增加；VPA对鸣叫簇有差异影响，改变时域、频域和能量域特征；VPA暴露雏鸡鸣叫持续时间更短、音高变异性降低、能量分布改变，最大变化出现在较响亮的鸣叫中。

Conclusion: 该研究提供了分析动物鸣叫的计算框架，推进了对典型和非典型鸣叫发育早期生命交流的理解。

Abstract: In young animals like poultry chicks (Gallus gallus), vocalisations convey information about affective and behavioural states. Traditional approaches to vocalisation analysis, relying on manual annotation and predefined categories, introduce biases, limit scalability, and fail to capture the full complexity of vocal repertoires. We introduce a computational framework for the automated detection, acoustic feature extraction, and unsupervised learning of chick vocalisations. Applying this framework to a dataset of newly hatched chicks, we identified two primary vocal clusters. We then tested our computational framework on an independent dataset of chicks exposed during embryonic development to vehicle or Valproic Acid (VPA), a compound that disrupts neural development and is linked to autistic-like symptoms. Clustering analysis on the experimental dataset confirmed two primary vocal clusters and revealed systematic differences between groups. VPA-exposed chicks showed an altered repertoire, with a relative increase in softer calls. VPA differentially affected call clusters, modulating temporal, frequency, and energy domain features. Overall, VPA-exposed chicks produced vocalisations with shorter duration, reduced pitch variability, and modified energy profiles, with the strongest alterations observed in louder calls. This study provides a computational framework for analysing animal vocalisations, advancing knowledge of early-life communication in typical and atypical vocal development.

</details>


### [80] [Do Neural Codecs Generalize? A Controlled Study Across Unseen Languages and Non-Speech Tasks](https://arxiv.org/abs/2601.12205)
*Shih-Heng Wang,Jiatong Shi,Jinchuan Tian,Haibin Wu,Shinji Watanabe*

Main category: cs.SD

TL;DR: 本文研究了神经音频编解码器（NACs）泛化能力的三个关键但未充分探索的方面：对未见语言的泛化、从语音到非语音任务的泛化，以及非语音数据对预训练的影响。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常使用现成的NACs进行比较，但由于实现差异限制了深入理解。需要从零开始训练NACs，使用严格控制的配置和精心策划的预训练数据，以实现公平比较，探索NACs在语言泛化、跨领域泛化和数据混合方面的能力。

Method: 从零开始训练NACs，使用严格控制的配置和精心策划的预训练数据。通过11个指标对NAC性能进行综合评估，包括信号重建质量和下游应用。

Result: NACs能够在预训练中泛化到未见语言；仅语音预训练的NACs在非语音任务上性能下降；在预训练中加入非语音数据可以改善非语音任务性能，同时在语音任务上保持可比性能。

Conclusion: NACs具有良好的语言泛化能力，但跨领域泛化有限，混合数据预训练可以提升非语音任务性能而不损害语音任务表现，为NACs的设计和应用提供了重要指导。

Abstract: This paper investigates three crucial yet underexplored aspects of the generalization capabilities of neural audio codecs (NACs): (i) whether NACs can generalize to unseen languages during pre-training, (ii) whether speech-only pre-trained NACs can effectively generalize to non-speech applications such as environmental sounds, music, and animal vocalizations, and (iii) whether incorporating non-speech data during pre-training can improve performance on both speech and non-speech tasks. Existing studies typically rely on off-the-shelf NACs for comparison, which limits insight due to variations in implementation. In this work, we train NACs from scratch using strictly controlled configurations and carefully curated pre-training data to enable fair comparisons. We conduct a comprehensive evaluation of NAC performance on both signal reconstruction quality and downstream applications using 11 metrics. Our results show that NACs can generalize to unseen languages during pre-training, speech-only pre-trained NACs exhibit degraded performance on non-speech tasks, and incorporating non-speech data during pre-training improves performance on non-speech tasks while maintaining comparable performance on speech tasks.

</details>


### [81] [Song Aesthetics Evaluation with Multi-Stem Attention and Hierarchical Uncertainty Modeling](https://arxiv.org/abs/2601.12222)
*Yishan Lv,Jing Luo,Boyuan Ju,Yang Zhang,Xinda Wu,Bo Yuan,Xinyu Yang*

Main category: cs.SD

TL;DR: 提出歌曲美学评估框架，包含多声部注意力融合和分层粒度感知区间聚合模块，在AI生成和人工创作歌曲数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 音乐生成AI快速发展导致音乐内容激增，需要自动化歌曲美学评估。现有研究主要关注语音、音频或演唱质量，歌曲美学评估研究不足。传统方法直接预测精确MOS值，难以捕捉人类对歌曲美学感知的细微差别。

Method: 提出歌曲导向的美学评估框架，包含两个新模块：1) 多声部注意力融合(MSAF)：在人声-伴奏混合对之间建立双向交叉注意力，融合复杂音乐特征；2) 分层粒度感知区间聚合(HiGIA)：学习多粒度分数概率分布，聚合为分数区间，在区间内进行回归得到最终分数。

Result: 在两个全长歌曲数据集上评估：SongEval数据集(AI生成)和内部美学数据集(人工创作)。与两个SOTA模型比较，结果显示所提方法在多维歌曲美学评估中表现更强。

Conclusion: 提出的歌曲美学评估框架能有效捕捉人类对歌曲美学的感知，在多维评估任务中优于现有方法，为音乐生成AI的质量评估提供了有效工具。

Abstract: Music generative artificial intelligence (AI) is rapidly expanding music content, necessitating automated song aesthetics evaluation. However, existing studies largely focus on speech, audio or singing quality, leaving song aesthetics underexplored. Moreover, conventional approaches often predict a precise Mean Opinion Score (MOS) value directly, which struggles to capture the nuances of human perception in song aesthetics evaluation. This paper proposes a song-oriented aesthetics evaluation framework, featuring two novel modules: 1) Multi-Stem Attention Fusion (MSAF) builds bidirectional cross-attention between mixture-vocal and mixture-accompaniment pairs, fusing them to capture complex musical features; 2) Hierarchical Granularity-Aware Interval Aggregation (HiGIA) learns multi-granularity score probability distributions, aggregates them into a score interval, and applies a regression within the interval to produce the final score. We evaluated on two datasets of full-length songs: SongEval dataset (AI-generated) and an internal aesthetics dataset (human-created), and compared with two state-of-the-art (SOTA) models. Results show that the proposed method achieves stronger performance for multi-dimensional song aesthetics evaluation.

</details>


### [82] [Confidence-based Filtering for Speech Dataset Curation with Generative Speech Enhancement Using Discrete Tokens](https://arxiv.org/abs/2601.12254)
*Kazuki Yamauchi,Masato Murata,Shogo Seki*

Main category: cs.SD

TL;DR: 提出基于置信度分数的非侵入式方法，用于过滤离散令牌生成式语音增强模型中的幻觉错误，提升TTS数据集质量


<details>
  <summary>Details</summary>
Motivation: 生成式语音增强模型在从噪声输入生成高质量干净语音方面表现出色，但容易产生幻觉错误（如音素遗漏和说话人不一致），传统基于非侵入式语音质量指标的误差过滤方法往往无法检测这些错误

Method: 提出非侵入式方法，利用生成令牌的对数概率作为置信度分数来检测潜在错误，该方法适用于离散令牌生成式语音增强模型

Result: 实验结果显示置信度分数与一系列侵入式语音增强指标强相关，该方法能有效识别传统过滤方法遗漏的幻觉错误；实际应用中，使用置信度过滤方法整理野外TTS数据集能提升后续训练的TTS模型性能

Conclusion: 提出的基于置信度的非侵入式过滤方法能有效检测生成式语音增强模型中的幻觉错误，为高质量语音数据集的构建提供了实用工具

Abstract: Generative speech enhancement (GSE) models show great promise in producing high-quality clean speech from noisy inputs, enabling applications such as curating noisy text-to-speech (TTS) datasets into high-quality ones. However, GSE models are prone to hallucination errors, such as phoneme omissions and speaker inconsistency, which conventional error filtering based on non-intrusive speech quality metrics often fails to detect. To address this issue, we propose a non-intrusive method for filtering hallucination errors from discrete token-based GSE models. Our method leverages the log-probabilities of generated tokens as confidence scores to detect potential errors. Experimental results show that the confidence scores strongly correlate with a suite of intrusive SE metrics, and that our method effectively identifies hallucination errors missed by conventional filtering methods. Furthermore, we demonstrate the practical utility of our method: curating an in-the-wild TTS dataset with our confidence-based filtering improves the performance of subsequently trained TTS models.

</details>


### [83] [ParaMETA: Towards Learning Disentangled Paralinguistic Speaking Styles Representations from Speech](https://arxiv.org/abs/2601.12289)
*Haowei Lou,Hye-young Paik,Wen Hu,Lina Yao*

Main category: cs.SD

TL;DR: ParaMETA是一个统一的框架，通过将语音投影到特定子空间来学习解耦的说话风格嵌入，支持多种副语言任务识别和细粒度风格控制的语音生成。


<details>
  <summary>Details</summary>
Motivation: 学习不同说话风格（如情感、年龄、性别）的代表性嵌入对于识别任务（认知计算、人机交互）和生成任务（风格可控语音生成）都至关重要。现有方法依赖单任务模型或跨模态对齐，存在局限性。

Method: ParaMETA将语音投影到每个风格类型的专用子空间中，学习解耦的、任务特定的嵌入。这种设计减少了任务间干扰，缓解了负迁移，允许单个模型处理多个副语言任务。支持语音和文本提示，在TTS生成模型中实现细粒度风格控制。

Result: 广泛实验表明，ParaMETA在分类准确率上优于强基线，生成更自然、富有表现力的语音，同时保持轻量级和高效，适合实际应用。

Conclusion: ParaMETA提供了一个统一且灵活的框架，能够直接从语音中学习和控制说话风格，在识别和生成任务中都表现出色，具有实际应用价值。

Abstract: Learning representative embeddings for different types of speaking styles, such as emotion, age, and gender, is critical for both recognition tasks (e.g., cognitive computing and human-computer interaction) and generative tasks (e.g., style-controllable speech generation). In this work, we introduce ParaMETA, a unified and flexible framework for learning and controlling speaking styles directly from speech. Unlike existing methods that rely on single-task models or cross-modal alignment, ParaMETA learns disentangled, task-specific embeddings by projecting speech into dedicated subspaces for each type of style. This design reduces inter-task interference, mitigates negative transfer, and allows a single model to handle multiple paralinguistic tasks such as emotion, gender, age, and language classification. Beyond recognition, ParaMETA enables fine-grained style control in Text-To-Speech (TTS) generative models. It supports both speech- and text-based prompting and allows users to modify one speaking styles while preserving others. Extensive experiments demonstrate that ParaMETA outperforms strong baselines in classification accuracy and generates more natural and expressive speech, while maintaining a lightweight and efficient model suitable for real-world applications.

</details>


### [84] [A Similarity Network for Correlating Musical Structure to Military Strategy](https://arxiv.org/abs/2601.12314)
*Yiwen Zhang,Hui Zhang,Fanqin Meng*

Main category: cs.SD

TL;DR: 该研究通过创建音乐片段相关网络(MCCN)，探索音乐结构与军事战略之间的相似性，提出从军事战略和管理角度理解音乐感知和审美教育的新方法。


<details>
  <summary>Details</summary>
Motivation: 音乐感知作为基于联觉效应的多感官过程，是音乐审美教育的重要组成部分。目前从系统操作和信息管理角度评估音乐感知的方法很少。研究者发现音乐结构与军事战略存在相似性（如旋律协调类似军事行动配合），希望通过跨学科研究探索这种联系。

Method: 基于梅尔频率倒谱系数(MFCCs)创建音乐片段相关网络(MCCN)，灵感来源于音乐会指挥的乐谱与军事指挥官沙盘推演的类比。为各类战争电影配乐创建MCCN，然后将军事战术（如《孙子兵法》）和政治制度与军事行动网络相关联。

Result: 研究发现音乐结构与军事战略之间存在一些相似性，表明可以通过军事战略和管理视角来研究音乐感知和审美教育。基于网络分析可以揭示军事谋略艺术与音乐结构艺术之间的相似性。

Conclusion: 这项跨学科研究表明，从军事战略和管理角度研究音乐感知和审美教育是可行的。通过分析音乐结构与军事战略的相似性，有助于理解技术与艺术之间的关系，为音乐教育提供新的视角。

Abstract: Music perception, a multi-sensory process based on the synesthesia effect, is an essential component of music aesthetic education. Understanding music structure helps both perception and aesthetic education. Music structure incorporates a range of information, the coordination of which forms the melody, just as different military actions cooperate to produce a military strategy. However, there are a few ways for assessing music perception from the perspectives of system operation and information management. In this paper, we explore the similarities between music structure and military strategy while creating the Music Clips Correlation Network (MCCN) based on Mel-frequency Cepstral Coefficients (MFCCs). The inspiration comes from the comparison between a concert conductor's musical score and a military war commander's sand table exercise. Specifically, we create MCCNs for various kinds of war movie soundtracks, then relate military tactics (Sun Tzu's Art of War, etc.) and political institutions to military operations networks. Our primary findings suggest a few similarities, implying that music perception and aesthetic education can be approached from a military strategy and management perspective through this interdisciplinary research. Similarly, we can discover similarities between the art of military scheming and the art of musical structure based on network analysis in order to facilitate the understanding of the relationship between technology and art.

</details>


### [85] [A Unified Neural Codec Language Model for Selective Editable Text to Speech Generation](https://arxiv.org/abs/2601.12480)
*Hanchen Pei,Shujie Liu,Yanqing Liu,Jianwei Yu,Yuanhang Qian,Gongping Huang,Sheng Zhao,Yan Lu*

Main category: cs.SD

TL;DR: SpeechEdit是一个统一的编解码语言模型，通过选择性控制机制扩展零样本文本到语音合成，能够保持语音提示的完整声学特征，同时根据显式指令选择性覆盖特定属性。


<details>
  <summary>Details</summary>
Motivation: 现有的神经编解码语言模型在零样本文本到语音合成中能够完全模仿短语音提示的声学特征（音色、韵律、副语言信息），但这种整体模仿限制了它们分离和控制单个属性的能力。

Method: 提出SpeechEdit统一编解码语言模型，通过选择性控制机制实现可控建模。模型基于新构建的LibriEdit数据集进行训练，该数据集从LibriHeavy派生，提供差异感知的训练对。

Result: 实验结果表明，该方法在保持自然性和鲁棒性的同时，提供了对所需属性的灵活和局部控制。

Conclusion: SpeechEdit成功扩展了零样本文本到语音合成的能力，实现了对语音属性的选择性控制，为更精细的语音编辑提供了有效解决方案。

Abstract: Neural codec language models achieve impressive zero-shot Text-to-Speech (TTS) by fully imitating the acoustic characteristics of a short speech prompt, including timbre, prosody, and paralinguistic information. However, such holistic imitation limits their ability to isolate and control individual attributes. In this paper, we present a unified codec language model SpeechEdit that extends zero-shot TTS with a selective control mechanism. By default, SpeechEdit reproduces the complete acoustic profile inferred from the speech prompt, but it selectively overrides only the attributes specified by explicit control instructions. To enable controllable modeling, SpeechEdit is trained on our newly constructed LibriEdit dataset, which provides delta (difference-aware) training pairs derived from LibriHeavy. Experimental results show that our approach maintains naturalness and robustness while offering flexible and localized control over desired attributes. Audio samples are available at https://speech-editing.github.io/speech-editing/.

</details>


### [86] [Harmonizing the Arabic Audio Space with Data Scheduling](https://arxiv.org/abs/2601.12494)
*Hunzalah Hassan Bhatti,Firoj Alam,Shammur Absar Chowdhury*

Main category: cs.SD

TL;DR: 本文首次系统研究了阿拉伯语音频大语言模型的多任务指令微调，提出了任务渐进课程（TPC）和对齐器多样化采样（ADS）策略，发现混合TPC+ADS策略在复杂低资源多模态环境中效果最佳。


<details>
  <summary>Details</summary>
Motivation: 音频大语言模型在统一语音理解和生成方面表现出色，但在语言复杂、方言丰富的环境中的适应能力尚未得到充分探索。本文旨在研究阿拉伯语为中心的音频LLM在多任务指令微调中的表现，填补这一研究空白。

Method: 1) 引入AraMega-SSum阿拉伯语语音摘要数据集；2) 对Qwen2.5-Omni (7B)进行微调；3) 提出任务渐进课程（TPC）策略；4) 提出对齐器多样化采样（ADS）策略，构建信息密集批次；5) 评估混合TPC+ADS策略。

Result: ADS策略能加速初始收敛并提升副语言F1分数，但其梯度波动性在长时间训练下会破坏生成解码的稳定性。TPC策略能稳定核心声学映射，但常在下游任务中引发负迁移。混合TPC+ADS策略效果最佳，先建立稳健表征基础，再通过多样性感知细化捕捉细粒度差异。

Conclusion: 混合TPC+ADS策略为复杂低资源多模态环境中Omni模型的高效适应提供了最优训练"配方"，为音频大语言模型在方言丰富环境中的实际应用提供了实用指导。

Abstract: Audio large language models (LLMs) enable unified speech understanding and generation, yet their adaptation to linguistically complex, dialect-rich settings remains underexplored. This paper presents the first systematic study of multi-task instruction tuning for an Arabic-centric audio LLM, covering a hierarchy of generative tasks (ASR, speech summarization) and discriminative tasks (dialect and emotion identification). To support this study, we introduce AraMega-SSum, a novel dataset for Arabic speech summarization. We fine-tune Qwen2.5-Omni (7B) and propose Task-Progressive Curriculum (TPC) along with Aligner-Based Diverse Sampling (ADS), a strategy that constructs information-dense batches by selecting task- and label-balanced examples. Our results reveal a critical efficiency, robustness trade-off: while ADS accelerates initial convergence and boosts paralinguistic F1-scores, its inherent gradient volatility can destabilize generative decoding under prolonged training. Furthermore, while the TPC stabilizes core acoustic mapping, it often induces negative transfer in downstream tasks. We demonstrate that a Hybrid TPC+ADS Strategy provides an optimal training ``recipe'', first establishing a robust representative foundation before employing diversity-aware refinement to capture fine-grained nuances. These findings offer practical guidance for the efficient adaptation of Omni-models in complex, low-resource multimodal environments.

</details>


### [87] [SmoothCLAP: Soft-Target Enhanced Contrastive Language\--Audio Pretraining for Affective Computing](https://arxiv.org/abs/2601.12591)
*Xin Jing,Jiadong Wang,Andreas Triantafyllopoulos,Maurice Gerczuk,Shahin Amiriparian,Jun Luo,Björn Schuller*

Main category: cs.SD

TL;DR: 提出SmoothCLAP方法，通过引入基于模态内相似性和副语言特征的软化目标，解决传统CLAP在情感识别中忽视情感模糊边界的问题，在多个情感计算任务中取得优越性能。


<details>
  <summary>Details</summary>
Motivation: 人类情感的模糊性给机器学习模型带来挑战，情感之间往往重叠且缺乏清晰边界。传统对比语言-音频预训练（CLAP）强制音频-文本样本间严格的一对一对齐，忽视了模态内相似性，并将所有不匹配对视为同等负面，这与情感间的模糊边界相冲突。

Method: 提出SmoothCLAP方法，结合基于模态内相似性和副语言特征生成的软化目标与传统对比监督。该方法学习尊重情感等级关系的嵌入表示，同时保持与CLAP相同的推理流程。

Result: 在英语和德语的八个情感计算任务上进行实验，SmoothCLAP始终取得优越性能。结果表明，利用软监督是构建情感感知音频-文本模型的有效策略。

Conclusion: 通过引入软化目标处理情感模糊边界，SmoothCLAP在保持传统CLAP推理流程的同时，显著提升了情感识别性能，证明了软监督在情感感知音频-文本模型中的价值。

Abstract: The ambiguity of human emotions poses several challenges for machine learning models, as they often overlap and lack clear delineating boundaries. Contrastive language-audio pretraining (CLAP) has emerged as a key technique for generalisable emotion recognition. However, as conventional CLAP enforces a strict one-to-one alignment between paired audio-text samples, it overlooks intra-modal similarity and treats all non-matching pairs as equally negative. This conflicts with the fuzzy boundaries between different emotions. To address this limitation, we propose SmoothCLAP, which introduces softened targets derived from intra-modal similarity and paralinguistic features. By combining these softened targets with conventional contrastive supervision, SmoothCLAP learns embeddings that respect graded emotional relationships, while retaining the same inference pipeline as CLAP. Experiments on eight affective computing tasks across English and German demonstrate that SmoothCLAP is consistently achieving superior performance. Our results highlight that leveraging soft supervision is a promising strategy for building emotion-aware audio-text models.

</details>


### [88] [SSVD-O: Parameter-Efficient Fine-Tuning with Structured SVD for Speech Recognition](https://arxiv.org/abs/2601.12600)
*Pu Wang,Shinji Watanabe,Hugo Van hamme*

Main category: cs.SD

TL;DR: SSVD-Outer (SSVD-O) 是一种参数高效微调方法，通过结合输入声学特征空间的内变换和输出语义特征空间的外变换，实现语音模型的平衡适应，在ASR任务中缩小与全微调的差距并减少灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法（如LoRA及其变体）通常均匀分配参数到模型子空间，限制了在语音应用中的效率和可扩展性。需要更有效的参数分配策略来平衡适应能力和资源约束。

Method: SSVD-O扩展了结构化SVD引导的微调方法，结合输入声学特征空间的内变换和输出语义特征空间的外变换，实现可扩展的平衡适应。首次系统分析了ASR任务中模型子空间的参数预算分配，研究了有限资源下的学习与遗忘权衡。

Result: 在儿童语音和地区口音等域转移ASR任务中，SSVD-O在0.1B到2B模型规模上均优于LoRA、DoRA、PiSSA和SSVD方法，持续缩小与全微调的性能差距，同时提高泛化能力并减轻灾难性遗忘。

Conclusion: SSVD-O通过平衡的参数分配策略，在语音基础模型的参数高效微调中实现了更好的适应效果，为大规模语音模型的域适应提供了有效的解决方案。

Abstract: Parameter-efficient fine-tuning (PEFT) is a scalable approach for adapting large speech foundation models to new domains. While methods such as LoRA and its state-of-the-art variants reduce adaptation costs, they typically allocate parameters uniformly across model subspaces, which limits their efficiency and scalability in speech applications. Building on our prior work, this paper introduces SSVD-Outer (SSVD-O), an extension of the structured SVD-guided (SSVD) fine-tuning method. SSVD-O combines input acoustic feature space-associated inner transformations with output semantic feature space-associated outer transformations to enable scalable and balanced adaptation. We conduct the first systematic analysis of parameter budget allocation across model subspaces in PEFT for automatic speech recognition (ASR), and investigate the trade-off between learning and forgetting under constrained resources. SSVD-O is benchmarked against LoRA, DoRA, PiSSA, and SSVD on domain-shifted ASR tasks, including child speech and regional accents, across model scales from 0.1B to 2B within the ESPnet framework. Experimental results show that SSVD-O consistently narrows the performance gap to full fine-tuning while improving generalization and mitigating catastrophic forgetting.

</details>


### [89] [Toward Faithful Explanations in Acoustic Anomaly Detection](https://arxiv.org/abs/2601.12660)
*Maab Elrashid,Anthony Deschênes,Cem Subakan,Mirco Ravanelli,Rémi Georges,Michael Morin*

Main category: cs.SD

TL;DR: 比较标准自编码器(AE)与掩码自编码器(MAE)在音频异常检测中的性能和可解释性，发现MAE虽然检测性能略低，但能提供更忠实、时间更精确的解释，表明掩码训练能提升解释质量而不牺牲性能。


<details>
  <summary>Details</summary>
Motivation: 在真实世界的异常检测应用中，可解释性对于用户信任至关重要。深度学习模型虽然性能强大，但往往缺乏透明度。本研究旨在探索音频异常检测中自编码器模型的可解释性。

Method: 比较标准自编码器(AE)与掩码自编码器(MAE)在音频异常检测中的表现。应用多种归因方法：误差图、显著性图、SmoothGrad、积分梯度、GradSHAP和Grad-CAM。提出基于扰动的忠实度度量，通过用重构替换突出区域来模拟正常输入。

Result: MAE虽然检测性能略低于AE，但能提供更忠实、时间更精确的解释，表明其与真实异常有更好的对齐。基于真实工业场景的实验验证了这一发现。

Conclusion: 将可解释性纳入异常检测流程很重要，掩码训练能在不牺牲性能的情况下提升解释质量。MAE在提供可靠解释方面优于标准AE，这对实际应用中的用户信任至关重要。

Abstract: Interpretability is essential for user trust in real-world anomaly detection applications. However, deep learning models, despite their strong performance, often lack transparency. In this work, we study the interpretability of autoencoder-based models for audio anomaly detection, by comparing a standard autoencoder (AE) with a mask autoencoder (MAE) in terms of detection performance and interpretability. We applied several attribution methods, including error maps, saliency maps, SmoothGrad, Integrated Gradients, GradSHAP, and Grad-CAM. Although MAE shows a slightly lower detection, it consistently provides more faithful and temporally precise explanations, suggesting a better alignment with true anomalies. To assess the relevance of the regions highlighted by the explanation method, we propose a perturbation-based faithfulness metric that replaces them with their reconstructions to simulate normal input. Our findings, based on experiments in a real industrial scenario, highlight the importance of incorporating interpretability into anomaly detection pipelines and show that masked training improves explanation quality without compromising performance.

</details>


### [90] [SoundPlot: An Open-Source Framework for Birdsong Acoustic Analysis and Neural Synthesis with Interactive 3D Visualization](https://arxiv.org/abs/2601.12752)
*Naqcho Ali Mehdi,Mohammad Adeel,Aizaz Ali Larik*

Main category: cs.SD

TL;DR: SoundPlot是一个开源框架，用于通过声学特征提取、降维和神经音频合成分析鸟类发声，提供实时3D可视化和音频重建功能。


<details>
  <summary>Details</summary>
Motivation: 为生物声学、音频信号处理和计算行为学研究提供一个完整的分析-合成框架，实现对鸟类发声的深入分析和可视化。

Method: 提取频谱特征（质心、带宽、对比度）、通过概率YIN提取音高轮廓、MFCC系数，映射到统一的音色空间；使用Griffin-Lim相位估计算法从mel频谱图重建音频；基于Three.js的交互式可视化界面。

Result: mel频谱图相关性得分超过0.92，表明高保真地保留了感知声学结构；实现了原始和合成音频轨迹的双视口可视化比较。

Conclusion: SoundPlot是一个功能强大的开源框架，能够有效分析鸟类发声，为相关领域研究提供了实用工具，已发布在MIT许可证下。

Abstract: We present SoundPlot, an open-source framework for analyzing avian vocalizations through acoustic feature extraction, dimensionality reduction, and neural audio synthesis. The system transforms audio signals into a multi-dimensional acoustic feature space, enabling real-time visualization of temporal dynamics in 3D using web-based interactive graphics. Our framework implements a complete analysis-synthesis pipeline that extracts spectral features (centroid, bandwidth, contrast), pitch contours via probabilistic YIN (pYIN), and mel-frequency cepstral coefficients (MFCCs), mapping them to a unified timbre space for visualization. Audio reconstruction employs the Griffin-Lim phase estimation algorithm applied to mel spectrograms. The accompanying Three.js-based interface provides dual-viewport visualization comparing original and synthesized audio trajectories with independent playback controls. We demonstrate the framework's capabilities through comprehensive waveform analysis, spectrogram comparisons, and feature space evaluation using Principal Component Analysis (PCA). Quantitative evaluation shows mel spectrogram correlation scores exceeding 0.92, indicating high-fidelity preservation of perceptual acoustic structure. SoundPlot is released under the MIT License to facilitate research in bioacoustics, audio signal processing, and computational ethology.

</details>


### [91] [UNMIXX: Untangling Highly Correlated Singing Voices Mixtures](https://arxiv.org/abs/2601.12802)
*Jihoo Jung,Ji-Hoon Kim,Doyeop Kwak,Junwon Lee,Juhan Nam,Joon Son Chung*

Main category: cs.SD

TL;DR: UNMIXX是一个用于多人声分离的新框架，通过音乐化混合策略、跨源注意力和幅度惩罚损失来解决数据稀缺和高度相关的人声混合问题，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 多人声分离面临两个主要挑战：数据稀缺（缺乏高质量的多歌手混合数据集）和高度相关性（歌手声音在音高、音色、节奏上相似，比语音更难分离）。

Method: 1. 音乐化混合策略：构建高度相关、音乐化的混合数据；2. 跨源注意力：通过反向注意力机制驱动两个歌手的表示分离；3. 幅度惩罚损失：惩罚错误分配的干扰能量。

Result: UNMIXX显著提升了多人声分离性能，SDRi增益超过2.2 dB，优于先前工作。该框架不仅通过模拟真实训练数据解决了数据稀缺问题，还能有效分离高度相关的混合声音。

Conclusion: UNMIXX通过创新的混合策略、注意力机制和损失函数，成功解决了多人声分离中的数据稀缺和高度相关性挑战，为相关领域提供了有效的解决方案。

Abstract: We introduce UNMIXX, a novel framework for multiple singing voices separation (MSVS). While related to speech separation, MSVS faces unique challenges: data scarcity and the highly correlated nature of singing voices mixture. To address these issues, we propose UNMIXX with three key components: (1) musically informed mixing strategy to construct highly correlated, music-like mixtures, (2) cross-source attention that drives representations of two singers apart via reverse attention, and (3) magnitude penalty loss penalizing erroneously assigned interfering energy. UNMIXX not only addresses data scarcity by simulating realistic training data, but also excels at separating highly correlated mixtures through cross-source interactions at both the architectural and loss levels. Our extensive experiments demonstrate that UNMIXX greatly enhances performance, with SDRi gains exceeding 2.2 dB over prior work.

</details>


### [92] [Supervised Learning for Game Music Segmentation](https://arxiv.org/abs/2601.12961)
*Shangxuan Luo,Joshua Reiss*

Main category: cs.SD

TL;DR: 该研究探索了监督学习方法在音乐结构分割任务中的表现，使用CNN+RNN模型在游戏音乐数据集上取得了与无监督方法相当的性能，但训练资源更少。


<details>
  <summary>Details</summary>
Motivation: 当前基于神经网络的模型（包括Transformer）由于缺乏对音乐结构的理解，难以从统一重复的音乐素材中生成令人难忘且易于理解的音乐，导致游戏行业很少采用这些模型。学者们认为音乐结构建模可能为模型提供更高层次的信息，从而提升音乐生成质量。

Method: 创建了包含309个结构标注的游戏音乐音频数据集，提出了结合卷积神经网络（CNN）和循环神经网络（RNN）的监督学习方法，用于音乐结构分割任务。

Result: 提出的方法在音乐结构分割任务上取得了与最先进的无监督学习方法相当的性能，同时使用了更少的训练资源。

Conclusion: 监督学习方法在音乐结构分割任务中表现良好，为后续的音乐结构建模和高质量音乐生成提供了基础，有助于解决当前神经网络模型在音乐生成中的结构理解不足问题。

Abstract: At present, neural network-based models, including transformers, struggle to generate memorable and readily comprehensible music from unified and repetitive musical material due to a lack of understanding of musical structure. Consequently, these models are rarely employed by the games industry. It is hypothesised by many scholars that the modelling of musical structure may inform models at a higher level, thereby enhancing the quality of music generation. The aim of this study is to explore the performance of supervised learning methods in the task of structural segmentation, which is the initial step in music structure modelling. An audio game music dataset with 309 structural annotations was created to train the proposed method, which combines convolutional neural networks and recurrent neural networks, achieving performance comparable to the state-of-the-art unsupervised learning methods with fewer training resources.

</details>


### [93] [Lombard Speech Synthesis for Any Voice with Controllable Style Embeddings](https://arxiv.org/abs/2601.12966)
*Seymanur Akti,Alexander Waibel*

Main category: cs.SD

TL;DR: 提出一种可控文本转语音系统，无需训练数据即可为任意说话人合成Lombard语音，通过PCA分析风格嵌入并调整相关成分来控制Lombard程度


<details>
  <summary>Details</summary>
Motivation: Lombard效应在嘈杂环境或与听力受损者交流中至关重要，但现有TTS系统难以合成可控的Lombard语音，特别是缺乏Lombard训练数据时

Method: 从大型韵律多样数据集中学习风格嵌入，使用PCA分析其与Lombard属性的相关性，通过调整相关PCA成分来操纵风格嵌入，并集成到TTS模型中生成不同Lombard程度的语音

Result: 方法能保持自然度和说话人身份，在噪声环境下提高可懂度，提供细粒度的韵律控制，为任意说话人提供鲁棒的可控Lombard TTS解决方案

Conclusion: 提出了一种无需Lombard训练数据即可为任意说话人合成可控Lombard语音的有效方法，通过PCA分析实现风格嵌入的精细控制，在保持语音质量的同时提升噪声环境下的可懂度

Abstract: The Lombard effect plays a key role in natural communication, particularly in noisy environments or when addressing hearing-impaired listeners. We present a controllable text-to-speech (TTS) system capable of synthesizing Lombard speech for any speaker without requiring explicit Lombard data during training. Our approach leverages style embeddings learned from a large, prosodically diverse dataset and analyzes their correlation with Lombard attributes using principal component analysis (PCA). By shifting the relevant PCA components, we manipulate the style embeddings and incorporate them into our TTS model to generate speech at desired Lombard levels. Evaluations demonstrate that our method preserves naturalness and speaker identity, enhances intelligibility under noise, and provides fine-grained control over prosody, offering a robust solution for controllable Lombard TTS for any speaker.

</details>


### [94] [The Achilles' Heel of Angular Margins: A Chebyshev Polynomial Fix for Speaker Verification](https://arxiv.org/abs/2601.13198)
*Yang Wang,Yiqi Liu,Chenghao Xiao,Chenghua Lin*

Main category: cs.SD

TL;DR: ChebyAAM提出用切比雪夫多项式近似替换AAM-Softmax中的arccos函数，解决了梯度爆炸问题并增强了对难样本的优化效果。


<details>
  <summary>Details</summary>
Motivation: 当前基于角度的损失函数（如AAM-Softmax）在训练中存在稳定性问题，因为arccos函数在边界处的导数会爆炸，导致梯度峰值，且对难样本的梯度信号不足。

Method: 提出ChebyAAM损失函数，用切比雪夫多项式近似替换原始的arccos操作，消除梯度爆炸，并为难样本提供更强的修正信号。

Result: 在VoxCeleb、SITW和CN-Celeb三个基准测试上，该方法解决了训练不稳定性问题并持续提升性能。

Conclusion: 近似角度操作而非显式计算，为设计未来度量学习损失函数提供了更稳健的路径。

Abstract: Angular margin losses, such as AAM-Softmax, have become the de facto in speaker and face verification. Their success hinges on directly manipulating the angle between features and class prototypes. However, this manipulation relies on the arccos function to recover the angle, introducing a significant yet overlooked source of training instability. The derivative of arccos explodes at its boundaries, causing gradient peaks during optimisation. Furthermore, the formulation fails to generate a sufficiently sharp gradient for hard-to-classify examples. We address these issues by proposing ChebyAAM, a loss that replaces the arccos operation with its Chebyshev polynomial approximation. This substitution eliminates gradient explosion and applies a stronger corrective signal to hard examples, leading to more effective optimisation. Experiments on three benchmarks (VoxCeleb, SITW, and CN-Celeb) demonstrate that our method resolves the instability and consistently improves performance. Our work suggests that approximating angular operations, rather than calculating them explicitly, offers a more robust path for designing future metric learning losses. Code is available at https://github.com/ExtraOrdinaryLab/vibe.

</details>


### [95] [Event Classification by Physics-informed Inpainting for Distributed Multichannel Acoustic Sensor with Partially Degraded Channels](https://arxiv.org/abs/2601.13513)
*Noriyuki Tonami,Wataru Kohno,Yoshiyuki Yajima,Sakiko Mishima,Yumi Arai,Reishi Kondo,Tomoyuki Hino*

Main category: cs.SD

TL;DR: 提出基于逆时偏移的物理信息修复前端，用于分布式多通道声学传感中的声音事件分类，在布局变化和通道严重退化时提升性能


<details>
  <summary>Details</summary>
Motivation: 分布式多通道声学传感在大规模声音事件分类中面临两个主要问题：1）许多通道信号质量下降（SNR低）时性能下降；2）测试时的传感器布局与训练布局不同时性能下降。现有基于学习的方法在这些情况下效果有限。

Method: 提出无需学习的物理信息修复前端，基于逆时偏移技术：1）使用解析格林函数将多通道频谱图反向传播到3D网格形成场景一致图像；2）前向投影重建修复信号；3）提取log-mel特征；4）使用Transformer进行分类。该方法在布局开放配置下有效。

Result: 在ESC-50数据集（50个传感器，三种布局：圆形、线性、直角）上评估，SNR范围-30到0dB。相比AST基线、缩放稀疏最大通道选择和通道交换增强，RTM前端在所有布局上取得最佳或竞争性准确率，在直角布局上准确率从9.7%提升至22.8%（提升13.1个百分点）。相关性分析显示空间权重与SNR的相关性比与通道-源距离的相关性更强，且更高的SNR-权重相关性对应更高的SEC准确率。

Conclusion: 基于物理的"重建-投影"预处理方法有效补充了纯学习方法，在布局开放配置和严重通道退化情况下，为分布式多通道声学传感的声音事件分类提供了鲁棒解决方案。

Abstract: Distributed multichannel acoustic sensing (DMAS) enables large-scale sound event classification (SEC), but performance drops when many channels are degraded and when sensor layouts at test time differ from training layouts. We propose a learning-free, physics-informed inpainting frontend based on reverse time migration (RTM). In this approach, observed multichannel spectrograms are first back-propagated on a 3D grid using an analytic Green's function to form a scene-consistent image, and then forward-projected to reconstruct inpainted signals before log-mel feature extraction and Transformer-based classification. We evaluate the method on ESC-50 with 50 sensors and three layouts (circular, linear, right-angle), where per-channel SNRs are sampled from -30 to 0 dB. Compared with an AST baseline, scaling-sparsemax channel selection, and channel-swap augmentation, the proposed RTM frontend achieves the best or competitive accuracy across all layouts, improving accuracy by 13.1 points on the right-angle layout (from 9.7% to 22.8%). Correlation analyses show that spatial weights align more strongly with SNR than with channel--source distance, and that higher SNR--weight correlation corresponds to higher SEC accuracy. These results demonstrate that a reconstruct-then-project, physics-based preprocessing effectively complements learning-only methods for DMAS under layout-open configurations and severe channel degradation.

</details>


### [96] [LongSpeech: A Scalable Benchmark for Transcription, Translation and Understanding in Long Speech](https://arxiv.org/abs/2601.13539)
*Fei Yang,Xuanfan Ni,Renyi Yang,Jiahui Geng,Qing Li,Chenyang Lyu,Yichao Du,Longyue Wang,Weihua Luo,Kaifu Zhang*

Main category: cs.SD

TL;DR: LongSpeech是一个专门用于评估语音模型处理长音频能力的大规模基准测试，包含超过10万段10分钟长的语音片段，涵盖ASR、翻译、摘要、语言检测、说话人计数、内容分离和问答等任务。


<details>
  <summary>Details</summary>
Motivation: 现有音频-语言模型在短片段语音任务上表现出色，但现实应用（如会议转录、口语文档理解和对话分析）需要能够处理长音频并进行推理的鲁棒模型。目前缺乏专门针对长音频的评估基准。

Method: 提出了LongSpeech基准测试，包含超过10万段约10分钟长的语音片段，具有丰富的标注（ASR、翻译、摘要、语言检测、说话人计数、内容分离、问答）。同时引入了一个可复现的流水线，用于从多样化来源构建长音频基准测试。

Result: 使用最先进模型进行的初步实验显示存在显著性能差距：模型通常在某个任务上表现良好但牺牲其他任务，并且在高级推理任务上表现不佳。这突显了该基准测试的挑战性。

Conclusion: LongSpeech基准测试揭示了当前语音模型在长音频处理方面的局限性，为研究社区提供了一个公开可用的评估工具，有助于推动长音频理解和推理能力的发展。

Abstract: Recent advances in audio-language models have demonstrated remarkable success on short, segment-level speech tasks. However, real-world applications such as meeting transcription, spoken document understanding, and conversational analysis require robust models capable of processing and reasoning over long-form audio. In this work, we present LongSpeech, a large-scale and scalable benchmark specifically designed to evaluate and advance the capabilities of speech models on long-duration audio. LongSpeech comprises over 100,000 speech segments, each approximately 10 minutes long, with rich annotations for ASR, speech translation, summarization, language detection, speaker counting, content separation, and question answering. We introduce a reproducible pipeline for constructing long-form speech benchmarks from diverse sources, enabling future extensions. Our initial experiments with state-of-the-art models reveal significant performance gaps, with models often specializing in one task at the expense of others and struggling with higher-level reasoning. These findings underscore the challenging nature of our benchmark. Our benchmark will be made publicly available to the research community.

</details>


### [97] [Fusion Segment Transformer: Bi-Directional Attention Guided Fusion Network for AI-Generated Music Detection](https://arxiv.org/abs/2601.13647)
*Yumin Kim,Seonghyeon Go*

Main category: cs.SD

TL;DR: 提出Fusion Segment Transformer用于全音频AI生成音乐检测，通过门控融合层整合内容和结构信息，在SONICS和AIME数据集上达到SOTA性能


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI技术的发展，任何人都能轻松创建和部署AI生成的音乐，这增加了解决版权和所有权问题的技术需求。现有工作主要关注短音频检测，而需要建模长期结构和上下文的全音频检测挑战仍未充分探索。

Method: 提出改进的Segment Transformer版本——Fusion Segment Transformer。沿用先前工作，使用多样化特征提取器从短音乐片段提取内容嵌入。通过引入门控融合层有效整合内容和结构信息，增强全音频AI生成音乐检测架构，从而捕捉长期上下文。

Result: 在SONICS和AIME数据集上的实验表明，该方法优于先前模型和近期基线，在AI生成音乐检测任务中取得了最先进的结果。

Conclusion: 提出的Fusion Segment Transformer通过有效整合内容和结构信息，成功解决了全音频AI生成音乐检测的挑战，为音乐版权保护提供了有效的技术解决方案。

Abstract: With the rise of generative AI technology, anyone can now easily create and deploy AI-generated music, which has heightened the need for technical solutions to address copyright and ownership issues. While existing works mainly focused on short-audio, the challenge of full-audio detection, which requires modeling long-term structure and context, remains insufficiently explored. To address this, we propose an improved version of the Segment Transformer, termed the Fusion Segment Transformer. As in our previous work, we extract content embeddings from short music segments using diverse feature extractors. Furthermore, we enhance the architecture for full-audio AI-generated music detection by introducing a Gated Fusion Layer that effectively integrates content and structural information, enabling the capture of long-term context. Experiments on the SONICS and AIME datasets show that our approach outperforms the previous model and recent baselines, achieving state-of-the-art results in AI-generated music detection.

</details>


### [98] [Ultra-Lightweight Network for Ship-Radiated Sound Classification on Embedded Deployment](https://arxiv.org/abs/2601.13679)
*Sangwon Park,Dongjun Kim,Sung-Hoon Byun,Sangwook Park*

Main category: cs.SD

TL;DR: ShuffleFAC是一种轻量级声学模型，用于资源受限的海上监测系统中的船舶辐射声音分类，通过集成频率感知卷积到效率导向的骨干网络中，在保持竞争力的同时大幅降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 针对资源受限的海上监测系统需要实时船舶声音分类的需求，现有模型往往计算复杂度过高，不适合嵌入式设备部署。需要开发轻量级但性能良好的声学模型。

Method: ShuffleFAC将频率感知卷积集成到基于可分离卷积、逐点组卷积和通道混洗的效率导向骨干网络中，实现频率敏感特征提取的同时保持低计算成本。

Result: 在DeepShip数据集上，ShuffleFAC（γ=16）获得71.45±1.18%的宏观F1分数，仅使用39K参数和3.06M MACs，在树莓派上推理延迟为6.05±0.95ms。相比MicroNet0，F1分数提高1.82%，模型大小减少9.7倍，延迟降低2.5倍。

Conclusion: ShuffleFAC在保持竞争力的分类性能的同时，大幅降低了计算复杂度和模型大小，适合实时嵌入式水下声学目标识别系统部署。

Abstract: This letter presents ShuffleFAC, a lightweight acoustic model for ship-radiated sound classification in resource-constrained maritime monitoring systems. ShuffleFAC integrates Frequency-Aware convolution into an efficiency-oriented backbone using separable convolution, point-wise group convolution, and channel shuffle, enabling frequency-sensitive feature extraction with low computational cost. Experiments on the DeepShip dataset show that ShuffleFAC achieves competitive performance with substantially reduced complexity. In particular, ShuffleFAC ($γ=16$) attains a macro F1-score of 71.45 $\pm$ 1.18% using 39K parameters and 3.06M MACs, and achieves an inference latency of 6.05 $\pm$ 0.95ms on a Raspberry Pi. Compared with MicroNet0, it improves macro F1-score by 1.82 % while reducing model size by 9.7x and latency by 2.5x. These results indicate that ShuffleFAC is suitable for real-time embedded UATR.

</details>


### [99] [DistilMOS: Layer-Wise Self-Distillation For Self-Supervised Learning Model-Based MOS Prediction](https://arxiv.org/abs/2601.13700)
*Jianing Yang,Wataru Nakata,Yuki Saito,Hiroshi Saruwatari*

Main category: cs.SD

TL;DR: DistilMOS：一种通过自蒸馏学习预测MOS和SSL模型层表示聚类token ID的方法，提升MOS预测准确性和泛化能力


<details>
  <summary>Details</summary>
Motivation: 现有的基于自监督学习（SSL）的MOS预测模型在微调时存在两个问题：1）灾难性遗忘预训练知识；2）容易过拟合训练集，导致泛化性能差

Method: 提出DistilMOS方法，不仅学习预测MOS，还学习预测通过聚类SSL模型各层隐藏表示得到的token ID。这些分层token目标作为自蒸馏信号，使MOS预测模型能够从SSL模型中提取丰富的内部知识

Result: 实验评估表明，该方法在域内和域外评估中都显著优于标准的基于SSL的MOS预测模型，验证了方法的有效性和实用性

Conclusion: 通过引入层间token ID预测作为自蒸馏信号，DistilMOS能够有效缓解灾难性遗忘和过拟合问题，提升MOS预测的准确性和泛化能力

Abstract: With the advancement of self-supervised learning (SSL), fine-tuning pretrained SSL models for mean opinion score (MOS) prediction has achieved state-of-the-art performance. However, during fine-tuning, these SSL-based MOS prediction models often suffer from catastrophic forgetting of the pretrained knowledge and tend to overfit the training set, resulting in poor generalization performance. In this study, we propose DistilMOS, a novel method that learns to predict not only MOS but also token IDs obtained by clustering the hidden representations of each layer in the pretrained SSL model. These layer-wise token targets serve as self-distillation signals that enables the MOS prediction model to extract rich internal knowledge from SSL models, enhancing both prediction accuracy and generalization capability. Experimental evaluations demonstrate that our method significantly outperforms standard SSL-based MOS prediction models on both in-domain and out-of-domain evaluations, verifying the effectiveness and practicality of the proposed method.

</details>


### [100] [Performance and Complexity Trade-off Optimization of Speech Models During Training](https://arxiv.org/abs/2601.13704)
*Esteban Gómez,Tom Bäckström*

Main category: cs.SD

TL;DR: 提出一种基于特征噪声注入的重参数化技术，能够在训练过程中联合优化模型性能和计算复杂度，无需依赖启发式准则来选择要移除的权重或结构。


<details>
  <summary>Details</summary>
Motivation: 传统神经网络设计中，层大小通常启发式选择，无法保证性能与计算复杂度的最优权衡，需要后处理方法（如量化、剪枝）来降低计算成本。这是因为SGD只能优化可微函数，而影响计算复杂度的因素（如层大小、FLOP/s）是不可微的。

Method: 基于特征噪声注入的重参数化技术，使SGD方法能够在训练过程中联合优化性能和计算复杂度。该方法允许模型大小根据目标性能-复杂度权衡动态优化，无需依赖启发式准则来选择要移除的权重或结构。

Result: 通过三个案例研究验证了方法的有效性：一个合成示例和两个实际应用（语音活动检测和音频反欺骗）。代码已公开以促进进一步研究。

Conclusion: 提出的重参数化技术能够实现性能和计算复杂度的联合优化，为神经网络设计提供了一种更系统的方法，避免了传统后处理方法的局限性。

Abstract: In speech machine learning, neural network models are typically designed by choosing an architecture with fixed layer sizes and structure. These models are then trained to maximize performance on metrics aligned with the task's objective. While the overall architecture is usually guided by prior knowledge of the task, the sizes of individual layers are often chosen heuristically. However, this approach does not guarantee an optimal trade-off between performance and computational complexity; consequently, post hoc methods such as weight quantization or model pruning are typically employed to reduce computational cost. This occurs because stochastic gradient descent (SGD) methods can only optimize differentiable functions, while factors influencing computational complexity, such as layer sizes and floating-point operations per second (FLOP/s), are non-differentiable and require modifying the model structure during training. We propose a reparameterization technique based on feature noise injection that enables joint optimization of performance and computational complexity during training using SGD-based methods. Unlike traditional pruning methods, our approach allows the model size to be dynamically optimized for a target performance-complexity trade-off, without relying on heuristic criteria to select which weights or structures to remove. We demonstrate the effectiveness of our method through three case studies, including a synthetic example and two practical real-world applications: voice activity detection and audio anti-spoofing. The code related to our work is publicly available to encourage further research.

</details>


### [101] [GOMPSNR: Reflourish the Signal-to-Noise Ratio Metric for Audio Generation Tasks](https://arxiv.org/abs/2601.13758)
*Lingling Dai,Andong Li,Cheng Chi,Yifan Liang,Xiaodong Li,Chengshi Zheng*

Main category: cs.SD

TL;DR: 该论文提出GOMPSNR指标，通过改进相位距离测量来解决传统SNR在音频质量评估中的不足，并基于此开发了两种新的损失函数来优化神经声码器性能。


<details>
  <summary>Details</summary>
Motivation: 传统信噪比(SNR)及其变体在音频质量评估中与人类感知相关性不足，需要探究SNR失效的原因并改进其作为客观指标的可靠性。

Method: 识别相位距离测量不足是关键因素，提出重新设计包含专门相位距离项的SNR公式，得到GOMPSNR指标。进一步扩展该公式推导出两类新损失函数：幅度引导的相位优化和联合幅度-相位优化，并通过大量实验确定不同损失函数的最佳组合。

Result: 在先进神经声码器上的实验表明，GOMPSNR比SNR提供更可靠的误差测量。提出的损失函数显著提升了模型性能，精心选择的损失函数组合进一步优化了整体模型能力。

Conclusion: 通过改进相位距离测量，GOMPSNR解决了传统SNR在音频质量评估中的局限性，同时基于该指标开发的损失函数有效提升了神经声码器的生成质量。

Abstract: In the field of audio generation, signal-to-noise ratio (SNR) has long served as an objective metric for evaluating audio quality. Nevertheless, recent studies have shown that SNR and its variants are not always highly correlated with human perception, prompting us to raise the questions: Why does SNR fail in measuring audio quality? And how to improve its reliability as an objective metric? In this paper, we identify the inadequate measurement of phase distance as a pivotal factor and propose to reformulate SNR with specially designed phase-distance terms, yielding an improved metric named GOMPSNR. We further extend the newly proposed formulation to derive two novel categories of loss function, corresponding to magnitude-guided phase refinement and joint magnitude-phase optimization, respectively. Besides, extensive experiments are conducted for an optimal combination of different loss functions. Experimental results on advanced neural vocoders demonstrate that our proposed GOMPSNR exhibits more reliable error measurement than SNR. Meanwhile, our proposed loss functions yield substantial improvements in model performance, and our wellchosen combination of different loss functions further optimizes the overall model capability.

</details>


### [102] [Emotion and Acoustics Should Agree: Cross-Level Inconsistency Analysis for Audio Deepfake Detection](https://arxiv.org/abs/2601.13847)
*Jinhua Zhang,Zhenqi Jia,Rui Liu*

Main category: cs.SD

TL;DR: 提出EAI-ADD方法，通过检测情感与声学特征在不同时间粒度上的不一致性来进行音频深度伪造检测，优于现有基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有音频深度伪造检测方法通常孤立处理声学和情感特征，或依赖相关性度量，忽略了它们之间的细微不同步和突变不连续性，需要更有效的检测信号。

Method: 提出EAI-ADD方法：1) 将情感和声学表示投影到可比空间；2) 渐进整合帧级和话语级情感特征与声学特征，捕捉不同时间粒度上的跨层级情感-声学不一致性。

Result: 在ASVspoof 2019LA和2021LA数据集上的实验结果表明，EAI-ADD方法优于基线方法，为音频反欺骗检测提供了更有效的解决方案。

Conclusion: 将跨层级情感-声学不一致性作为主要检测信号是有效的音频深度伪造检测方法，能够捕捉传统方法忽略的细微不同步和突变不连续性。

Abstract: Audio Deepfake Detection (ADD) aims to detect spoof speech from bonafide speech. Most prior studies assume that stronger correlations within or across acoustic and emotional features imply authenticity, and thus focus on enhancing or measuring such correlations. However, existing methods often treat acoustic and emotional features in isolation or rely on correlation metrics, which overlook subtle desynchronization between them and smooth out abrupt discontinuities. To address these issues, we propose EAI-ADD, which treats cross level emotion acoustic inconsistency as the primary detection signal. We first project emotional and acoustic representations into a comparable space. Then we progressively integrate frame level and utterance level emotion features with acoustic features to capture cross level emotion acoustic inconsistencies across different temporal granularities. Experimental results on the ASVspoof 2019LA and 2021LA datasets demonstrate that the proposed EAI-ADD outperforms baselines, providing a more effective solution for audio anti spoofing detection.

</details>


### [103] [WenetSpeech-Wu: Datasets, Benchmarks, and Models for a Unified Chinese Wu Dialect Speech Processing Ecosystem](https://arxiv.org/abs/2601.11027)
*Chengyou Wang,Mingchen Shao,Jingbin Hu,Zeyu Zhu,Hongfei Xue,Bingshen Mu,Xin Xu,Xingyi Duan,Binbin Zhang,Pengcheng Zhu,Chuang Ding,Xiaojun Zhang,Hui Bu,Lei Xie*

Main category: cs.SD

TL;DR: 该论文提出了首个大规模、多维度标注的吴语开源语音语料库WenetSpeech-Wu（约8000小时），并建立了首个标准化公开评测基准WenetSpeech-Wu-Bench，同时发布了一套在多个任务上表现优异的开源模型，为吴语语音处理生态系统奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 吴语作为汉语的重要方言，虽然使用人口众多且具有重要语言学意义，但长期以来缺乏大规模语音数据、标准化评测基准和公开可用模型，导致低资源方言的语音处理面临根本性挑战。

Method: 1) 构建WenetSpeech-Wu语料库：收集约8000小时多样化吴语语音数据并进行多维度标注；2) 建立WenetSpeech-Wu-Bench评测基准：涵盖ASR、吴语-普通话翻译、说话人属性预测、语音情感识别、TTS合成和指令跟随TTS等任务；3) 训练并发布开源模型套件。

Result: 1) 发布了首个大规模吴语语音语料库（8000小时）；2) 建立了首个标准化吴语语音处理评测基准；3) 发布的模型套件在多个任务上表现出竞争力，实证验证了数据集的有效性；4) 所有数据集、基准和模型均已开源。

Conclusion: 该工作为吴语语音处理建立了全面的生态系统基础，通过开源数据集、评测基准和模型套件，支持未来方言语音智能研究，促进包容性和鲁棒性语音技术的发展。

Abstract: Speech processing for low-resource dialects remains a fundamental challenge in developing inclusive and robust speech technologies. Despite its linguistic significance and large speaker population, the Wu dialect of Chinese has long been hindered by the lack of large-scale speech data, standardized evaluation benchmarks, and publicly available models. In this work, we present WenetSpeech-Wu, the first large-scale, multi-dimensionally annotated open-source speech corpus for the Wu dialect, comprising approximately 8,000 hours of diverse speech data. Building upon this dataset, we introduce WenetSpeech-Wu-Bench, the first standardized and publicly accessible benchmark for systematic evaluation of Wu dialect speech processing, covering automatic speech recognition (ASR), Wu-to-Mandarin translation, speaker attribute prediction, speech emotion recognition, text-to-speech (TTS) synthesis, and instruction-following TTS (instruct TTS). Furthermore, we release a suite of strong open-source models trained on WenetSpeech-Wu, establishing competitive performance across multiple tasks and empirically validating the effectiveness of the proposed dataset. Together, these contributions lay the foundation for a comprehensive Wu dialect speech processing ecosystem, and we open-source proposed datasets, benchmarks, and models to support future research on dialectal speech intelligence.

</details>


### [104] [Towards Effective Negation Modeling in Joint Audio-Text Models for Music](https://arxiv.org/abs/2601.13931)
*Yannis Vasilakis,Rachel Bittner,Johan Pauwels*

Main category: cs.SD

TL;DR: 该论文针对音频-文本联合模型在处理否定语义（如"有/无"人声）时的局限性，提出通过文本增强和对比损失来改进CLAP模型，并在音乐检索任务中验证了有效性。


<details>
  <summary>Details</summary>
Motivation: 当前音频-文本联合模型在音乐检索中广泛使用，但难以可靠处理否定语义现象。否定对于区分音乐元素的存缺（如"有人声"vs"无人声"）至关重要，现有系统在这方面表现不佳。

Method: 1. 在Million Song Dataset上从头训练CLAP模型，使用LP-MusicCaps-MSD字幕；2. 通过文本增强引入否定语义；3. 设计基于差异性的对比损失，在联合嵌入空间中明确分离原始字幕和否定字幕；4. 提出两种评估协议：将否定建模作为检索任务和二元分类任务。

Result: 实验表明，两种方法（单独或组合）都能显著改善否定语义处理能力，同时基本保持了检索性能。提出的评估协议有效衡量了模型在否定语义理解方面的进展。

Conclusion: 通过文本增强和对比损失相结合的方法，能够有效提升音频-文本联合模型对否定语义的理解能力，为解决音乐检索中的语义区分问题提供了可行方案。

Abstract: Joint audio-text models are widely used for music retrieval, yet they struggle with semantic phenomena such as negation. Negation is fundamental for distinguishing the absence (or presence) of musical elements (e.g., "with vocals" vs. "without vocals"), but current systems fail to represent this reliably. In this work, we investigate and mitigate this limitation by training CLAP models from scratch on the Million Song Dataset with LP-MusicCaps-MSD captions. We introduce negation through text augmentation and a dissimilarity-based contrastive loss, designed to explicitly separate original and negated captions in the joint embedding space. To evaluate progress, we propose two protocols that frame negation modeling as retrieval and binary classification tasks. Experiments demonstrate that both methods, individually and combined, improve negation handling while largely preserving retrieval performance.

</details>


### [105] [ConceptCaps -- a Distilled Concept Dataset for Interpretability in Music Models](https://arxiv.org/abs/2601.14157)
*Bruno Sienkiewicz,Łukasz Neumann,Mateusz Modrzejewski*

Main category: cs.SD

TL;DR: ConceptCaps：一个包含23k音乐-描述-音频三元组的数据集，具有明确的200属性分类标签，用于概念可解释性研究


<details>
  <summary>Details</summary>
Motivation: 现有音乐数据集缺乏清晰、分离的概念正负样本，标签稀疏、嘈杂或定义不清，限制了概念可解释性方法（如TCAV）的应用

Method: 采用分离的流水线：VAE学习属性共现模式，微调LLM将属性列表转换为专业描述，MusicGen合成对应音频，而非端到端方法

Result: 通过音频-文本对齐（CLAP）、语言质量指标（BERTScore、MAUVE）和TCAV分析验证，概念探针能恢复音乐上有意义的模式

Conclusion: ConceptCaps数据集解决了音乐概念可解释性研究中数据缺乏的问题，分离的流水线提高了连贯性和可控性，数据集和代码已公开

Abstract: Concept-based interpretability methods like TCAV require clean, well-separated positive and negative examples for each concept. Existing music datasets lack this structure: tags are sparse, noisy, or ill-defined. We introduce ConceptCaps, a dataset of 23k music-caption-audio triplets with explicit labels from a 200-attribute taxonomy. Our pipeline separates semantic modeling from text generation: a VAE learns plausible attribute co-occurrence patterns, a fine-tuned LLM converts attribute lists into professional descriptions, and MusicGen synthesizes corresponding audio. This separation improves coherence and controllability over end-to-end approaches. We validate the dataset through audio-text alignment (CLAP), linguistic quality metrics (BERTScore, MAUVE), and TCAV analysis confirming that concept probes recover musically meaningful patterns. Dataset and code are available online.

</details>


### [106] [Transformer Architectures for Respiratory Sound Analysis and Multimodal Diagnosis](https://arxiv.org/abs/2601.14227)
*Theodore Aptekarev,Vladimir Sokolovsky,Gregory Furman*

Main category: cs.SD

TL;DR: 本文提出使用音频频谱变换器（AST）和多模态视觉语言模型（VLM）进行呼吸音分析，AST在哮喘检测上达到约97%准确率，显著优于传统CNN基线，而VLM则能整合临床上下文信息。


<details>
  <summary>Details</summary>
Motivation: 传统听诊方法主观且依赖经验，需要更客观的呼吸音分析工具来筛查哮喘和其他肺部疾病。先前研究建立了CNN基线，但希望探索更先进的模型来提升性能并整合临床信息。

Method: 1）采用音频频谱变换器（AST），从公开权重初始化并在包含数百个诊断记录的医学数据集上进行微调；2）评估多模态视觉语言模型（VLM），使用紧凑型Moondream架构处理频谱图图像和结构化文本提示（性别、年龄、记录部位），输出JSON格式的诊断结果。

Result: AST在哮喘检测上达到约97%的准确率、F1分数约97%、ROC AUC为0.98，显著优于内部CNN基线和典型外部基准。VLM达到86-87%的准确率，与CNN基线相当，但能整合临床上下文信息进行推理。

Conclusion: 自注意力机制在声学筛查中非常有效，多模态架构在构建整体诊断工具方面具有潜力，能够整合临床上下文信息，为呼吸音分析提供了更全面的解决方案。

Abstract: Respiratory sound analysis is a crucial tool for screening asthma and other pulmonary pathologies, yet traditional auscultation remains subjective and experience-dependent. Our prior research established a CNN baseline using DenseNet201, which demonstrated high sensitivity in classifying respiratory sounds. In this work, we (i) adapt the Audio Spectrogram Transformer (AST) for respiratory sound analysis and (ii) evaluate a multimodal Vision-Language Model (VLM) that integrates spectrograms with structured patient metadata.
  AST is initialized from publicly available weights and fine-tuned on a medical dataset containing hundreds of recordings per diagnosis. The VLM experiment uses a compact Moondream-type model that processes spectrogram images alongside a structured text prompt (sex, age, recording site) to output a JSON-formatted diagnosis. Results indicate that AST achieves approximately 97% accuracy with an F1-score around 97% and ROC AUC of 0.98 for asthma detection, significantly outperforming both the internal CNN baseline and typical external benchmarks. The VLM reaches 86-87% accuracy, performing comparably to the CNN baseline while demonstrating the capability to integrate clinical context into the inference process. These results confirm the effectiveness of self-attention for acoustic screening and highlight the potential of multimodal architectures for holistic diagnostic tools.

</details>

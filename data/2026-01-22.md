<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 12]
- [eess.AS](#eess.AS) [Total: 9]
- [cs.SD](#cs.SD) [Total: 11]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Experimental Performance of Bidirectional Phase Coherent Transmission and Sensing for mmWave Cell-free Massive MIMO Systems with Reciprocity Calibration](https://arxiv.org/abs/2601.14648)
*Qingji Jiang,Jing jin,Qixing Wang,Yuanyuan Tang,Yang Cao,Bin Kuang,Jing Dong,Siying Lv,Dongming Wang,Yongming Huang,Jiangzhou Wang,Xiaohu You*

Main category: eess.SP

TL;DR: 该论文提出了一种毫米波无蜂窝大规模MIMO系统中分布式TRP间相位同步的双向校准方案，通过校准系数估计和相位跟踪方法，实现通信与感知的双向赋能。


<details>
  <summary>Details</summary>
Motivation: 分布式传输接收点（TRP）间的相位同步是实现毫米波无蜂窝大规模MIMO系统中相干联合传输和高精度感知的先决条件。现有方法在动态场景下存在校准开销大、非理想因素影响感知精度等问题。

Method: 提出双向校准方案和校准系数估计方法；利用单向上行/下行信道状态信息进行校准系数相位跟踪；采用互易性校准消除感知中的非理想因素，并利用感知结果在动态场景中实现校准系数相位跟踪。

Result: 仿真结果表明，所提方法能以较低开销有效实现互易性校准，实现相干协作传输，并消除非理想因素以降低感知误差。实验结果显示，在毫米波频段，空中双向校准能为协作TRP和协作UE实现相干协作传输，获得波束成形增益和长时间相干感知能力。

Conclusion: 该研究提出的双向校准方案和相位跟踪方法成功解决了毫米波无蜂窝大规模MIMO系统中分布式TRP间的相位同步问题，实现了通信与感知的双向赋能，为6G系统中的集成通信与感知应用提供了有效解决方案。

Abstract: Phase synchronization among distributed transmission reception points (TRPs) is a prerequisite for enabling coherent joint transmission and high-precision sensing in millimeter wave (mmWave) cell-free massive multiple-input and multiple-output (MIMO) systems. This paper proposes a bidirectional calibration scheme and a calibration coefficient estimation method for phase synchronization, and presents a calibration coefficient phase tracking method using unilateral uplink/downlink channel state information (CSI). Furthermore, this paper introduces the use of reciprocity calibration to eliminate non-ideal factors in sensing and leverages sensing results to achieve calibration coefficient phase tracking in dynamic scenarios, thus enabling bidirectional empowerment of both communication and sensing. Simulation results demonstrate that the proposed method can effectively implement reciprocal calibration with lower overhead, enabling coherent collaborative transmission, and resolving non-ideal factors to acquire lower sensing error in sensing applications. Experimental results show that, in the mmWave band, over-the-air (OTA) bidirectional calibration enables coherent collaborative transmission for both collaborative TRPs and collaborative user equipments (UEs), achieving beamforming gain and long-time coherent sensing capabilities.

</details>


### [2] [Improved GPR-Based CSI Acquisition via Spatial-Correlation Kernel](https://arxiv.org/abs/2601.14759)
*Syed Luqman Shah,Nurul Huda Mahmood,Italo Atzeni*

Main category: eess.SP

TL;DR: 提出一种基于高斯过程回归的信道估计框架，使用新型空间相关核函数，在减少50%导频开销下实现最优MMSE性能


<details>
  <summary>Details</summary>
Motivation: 多天线无线系统中需要低导频开销和低计算复杂度的准确信道估计。随着信道模型从纯统计描述向物理和几何感知传播模型演进，需要将信道信息融入高斯过程回归框架来提高估计精度。

Method: 提出基于高斯过程回归的信道估计框架，设计新型空间相关核函数，显式捕捉信道的二阶统计特性。推导了SC-GPR估计器的闭式表达式，证明其后验均值在相同二阶统计下是最小均方误差最优的。

Result: 在减少50%导频开销的情况下，该方法实现了最低的归一化均方误差、最高的95%经验置信区间覆盖度，以及相比基准估计器更好的频谱效率保持能力，同时计算复杂度低于传统MMSE估计器。

Conclusion: 提出的SC-GPR信道估计框架通过显式建模信道空间相关性，在显著降低导频开销的同时实现了最优MMSE性能，为多天线系统提供了高效准确的信道估计解决方案。

Abstract: Accurate channel estimation with low pilot overhead and computational complexity is key to efficiently utilizing multi-antenna wireless systems. Motivated by the evolution from purely statistical descriptions toward physics- and geometry-aware propagation models, this work focuses on incorporating channel information into a Gaussian process regression (GPR) framework for improving the channel estimation accuracy. In this work, we propose a GPR-based channel estimation framework along with a novel Spatial-correlation (SC) kernel that explicitly captures the channel's second-order statistics. We derive a closed-form expression of the proposed SC-based GPR estimator and prove that its posterior mean is optimal in terms of minimum mean-square error (MMSE) under the same second-order statistics, without requiring the underlying channel distribution to be Gaussian. Our analysis reveals that, with up to 50% pilot overhead reduction, the proposed method achieves the lowest normalized mean-square error, the highest empirical 95% credible-interval coverage, and superior preservation of spectral efficiency compared to benchmark estimators, while maintaining lower computational complexity than the conventional MMSE estimator.

</details>


### [3] [Integrated Sensing, Communication and Control enabled Agile UAV Swarm](https://arxiv.org/abs/2601.14783)
*Zhiqing Wei,Yucong Du,Zhiyong Feng,Haotian Liu,Yanpeng Cui,Tao Zhang,Ying Zhou,Huici Wu*

Main category: eess.SP

TL;DR: 该论文提出了一种无人机群集集成感知、通信与控制（ISCC）的深度耦合方案，通过协同优化打破传统独立设计的局限，提升整体性能。


<details>
  <summary>Details</summary>
Motivation: 无人机群在灾害救援、空中基站和物流运输等应用中至关重要，需要准确的感知、高效的通信和灵活的控制能力。然而传统研究中感知、通信和控制被独立研究，限制了无人机群的整体性能。

Method: 提出ISCC系统范式，通过建立紧密耦合的闭环系统，实现感知、通信和控制的协同优化。具体包括：通信与控制增强的感知、感知与控制增强的通信、感知与通信增强的控制三大使能技术。

Result: 仿真结果验证了所提出的ISCC框架的性能，展示了其在未来应用中的潜力。

Conclusion: ISCC方案通过深度耦合感知、通信和控制，超越了传统的孤立设计，为无人机群在实时可靠任务执行中提供了系统性解决方案，具有广阔的应用前景。

Abstract: Uncrewed aerial vehicle (UAV) swarms are pivotal in the applications such as disaster relief, aerial base station (BS) and logistics transportation. These scenarios require the capabilities in accurate sensing, efficient communication and flexible control for real-time and reliable task execution. However, sensing, communication and control are studied independently in traditional research, which limits the overall performance of UAV swarms. To overcome this disadvantage, we propose a deeply coupled scheme of integrated sensing, communication and control (ISCC) for UAV swarms, which is a systemic paradigm that transcends traditional isolated designs of sensing, communication and control by establishing a tightly-coupled closed-loop through the co-optimization of sensing, communication and control. In this article, we firstly analyze the requirements of scenarios and key performance metrics. Subsequently, the enabling technologies are proposed, including communication-and-control-enhanced sensing, sensing-and-control-enhanced communication, and sensing-and-communication-enhanced control. Simulation results validate the performance of the proposed ISCC framework, demonstrating its application potential in the future.

</details>


### [4] [Absorption mode broadband 2D MS for proteomics and metabolomics](https://arxiv.org/abs/2601.14820)
*Maria A van Agthoven,Marek Polák,Jan Fiala,Claude Nelcy Ounounou,Petr Halada,Michael Palasser,Anne Briot-Dietsch,Alan Kádek,Kathrin Breuker,Petr Novák,Carlos Afonso,Marc-André Delsuc*

Main category: eess.SP

TL;DR: 该论文将吸收模式数据处理扩展到任意尺寸和频率范围的2D质谱，显著提高了信噪比和分辨率，在蛋白质组学和代谢组学应用中表现出优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统2D质谱使用幅度模式处理，信噪比和分辨率有限。吸收模式数据处理在有限数据集上已显示出信噪比和分辨率提升2倍的潜力，但尚未应用于任意尺寸和频率范围的2D质谱。

Method: 将吸收模式数据处理扩展到任意尺寸和频率范围的2D质谱。在傅里叶变换离子回旋共振质谱仪上，发现吸收模式相位校正函数在前体离子维度呈线性，在碎片离子维度呈二次函数。将该方法应用于FPOP产生的氧化泛素蛋白型top-down分析和麦角生物碱提取物分析。

Result: 吸收模式2D MS相比标准幅度模式显著提高了信噪比和分辨率。在top-down蛋白质组学中提高了序列覆盖率，在代谢组学中提高了前体-碎片离子关联的准确性。

Conclusion: 吸收模式数据处理可成功应用于任意尺寸的2D质谱，显著改善2D质谱的性能，为蛋白质组学和代谢组学分析提供了更强大的工具。

Abstract: Two-dimensional mass spectrometry (2D MS) is a method for tandem mass spectrometry that enables the correlation between precursor and fragment ions without the need for ion isolation. On a Fourier transform ion cyclotron resonance mass spectrometer, the phase correction functions for absorption mode data processing were found to be linear in the precursor ion dimension and quadratic in the fragment ion dimension. Absorption mode data processing on limited data sets has previously shown improvements in signal-to-noise ratio and resolving power by a factor of 2. Here, we have expanded absorption mode data processing to 2D mass spectra regardless of size and frequency range. We have applied absorption mode 2D MS to top-down analysis of variously oxidized ubiquitin proteoforms generated by fast photochemical oxidation of proteins (FPOP) and to an extract of ergot alkaloids. We show that absorption mode data processing significantly improves both the signal-to-noise ratio and the resolving power of the 2D mass spectrum compared to standard magnitude mode in terms of sequence coverage in top-down proteomics, as well as the accuracy of precursor-fragment correlation in metabolomics.

</details>


### [5] [Movable Antenna Empowered Covert Dual-Functional Radar-Communication](https://arxiv.org/abs/2601.14868)
*Ran Yang,Ning Wei,Zheng Dong,Lin Zhang,Wanting Lyu,Yue Xiu,Ahmad Bazzi,Chadi Assi*

Main category: eess.SP

TL;DR: 本文研究基于可移动天线的安全双功能雷达通信系统，通过联合优化发射波束成形、接收滤波和天线位置，在满足雷达信噪比和传输隐蔽性约束下最大化通信安全速率。


<details>
  <summary>Details</summary>
Motivation: 可移动天线技术能够通过调整天线位置灵活重构无线信道，为提升通信安全提供了新途径。本文旨在利用可移动天线增强双功能雷达通信系统的安全性，特别是在存在多个窃听者（Willies）的情况下。

Method: 针对非共谋Willies，采用拉格朗日对偶变换将问题重构，开发基于块坐标下降的算法，结合半定松弛、投影梯度下降、Dinkelbach变换和逐次凸逼近技术。针对共谋Willies，推导最小检测错误概率并证明其服从广义Erlang分布，开发基于最小均方误差的算法处理共谋检测问题。

Result: 仿真结果表明，所提方法能显著提高隐蔽和速率，相比现有基准方案，在通信和雷达性能之间实现了更优的平衡。

Conclusion: 基于可移动天线的双功能雷达通信系统设计能有效提升通信安全性，所提出的统一设计框架在不同窃听者工作模式下均能实现性能提升，为未来安全通信系统提供了有前景的解决方案。

Abstract: Movable antenna (MA) has emerged as a promising technology to flexibly reconfigure wireless channels by adjusting antenna placement. In this paper, we study a secured dual-functional radar-communication (DFRC) system aided by movable antennas. To enhance the communication security, we aim to maximize the achievable sum rate by jointly optimizing the transmitter beamforming vectors, receiving filter, and antenna placement, subject to radar signal-to-noise ratio (SINR) and transmission covertness constraints. We consider multiple Willies operating in both non-colluding and colluding modes. For noncolluding Willies, we first employ a Lagrangian dual transformation procedure to reformulate the challenging optimization problem into a more tractable form. Subsequently, we develop an efficient block coordinate descent (BCD) algorithm that integrates semidefinite relaxation (SDR), projected gradient descent (PGD), Dinkelbach transformation, and successive convex approximation (SCA) techniques to tackle the resulting problem. For colluding Willies, we first derive the minimum detection error probability (DEP) by characterizing the optimal detection statistic, which is proven to follow the generalized Erlang distribution. Then, we develop a minimum mean square error (MMSE)-based algorithm to address the colluding detection problem. We further provide a comprehensive complexity analysis on the unified design framework. Simulation results demonstrate that the proposed method can significantly improve the covert sum rate, and achieve a superior balance between communication and radar performance compared with existing benchmark schemes.

</details>


### [6] [Analysis of Sensing in OFDM-based ISAC under the Influence of Sampling Jitter](https://arxiv.org/abs/2601.14881)
*Lucas Giroto,Ândrei Camponogara,Yueheng Li,Jiayi Chen,Lukas Sigg,Thomas Zwick,Benjamin Nuss*

Main category: eess.SP

TL;DR: 该论文分析了采样抖动对OFDM集成感知与通信系统的影响，发现当RMS采样抖动超过10^-11秒时，性能下降变得不可忽视，但现有硬件已能达到飞秒级抖动，足以保证系统鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在蜂窝网络中实现集成感知与通信面临诸多挑战，采样抖动是其中一个关键问题。虽然OFDM通信系统中的采样抖动已有研究，但其对OFDM雷达感知性能的影响尚未得到充分分析，特别是考虑到PLL振荡器产生的有色采样抖动。

Method: 分析了基于PLL振荡器的采样时钟产生的有色采样抖动对OFDM-ISAC系统的影响，比较了基带采样和带通采样两种策略以及不同过采样因子下的性能。研究了采样抖动对数字星座调制和感知性能的失真影响。

Result: 对于单输入单输出OFDM-ISAC系统，当DAC和ADC的RMS采样抖动值超过10^-11秒时，基带采样和带通采样下的性能下降都变得不可忽视。基带采样导致载波间干扰，带通采样则引起载波相位误差和更严重的载波间干扰。

Conclusion: 现有硬件技术能够实现飞秒级的RMS采样抖动，这足以保证OFDM集成感知与通信系统对采样抖动具有足够的鲁棒性，满足通信和感知的性能要求。

Abstract: To enable integrated sensing and communication (ISAC) in cellular networks, a wide range of additional requirements and challenges are either imposed or become more critical. One such impairment is sampling jitter (SJ), which arises due to imperfections in the sampling instants of the clocks of digital-to-analog converters (DACs) and analog-to-digital converters (ADCs). While SJ is already well studied for communication systems based on orthogonal frequency-division multiplexing (OFDM), which is expected to be the waveform of choice for most sixth-generation (6G) scenarios where ISAC could be possible, the implications of SJ on the OFDM-based radar sensing must still be thoroughly analyzed. Considering that phase-locked loop (PLL)-based oscillators are used to derive sampling clocks, which leads to colored SJ, i.e., SJ with non-flat power spectral density, this article analyzes the resulting distortion of the adopted digital constellation modulation and sensing performance in OFDM-based ISAC for both baseband (BB) and bandpass (BP) sampling strategies and different oversampling factors. For BB sampling, it is seen that SJ induces intercarrier interference (ICI), while for BP sampling, it causes carrier phase error and more severe ICI due to a phase noise-like effect at the digital intermediate frequency. Obtained results for a single-input single-output OFDM-based ISAC system with various OFDM signal parameterizations demonstrate that SJ-induced degradation becomes non-negligible for both BB and BP sampling only for root mean square (RMS) SJ values above 10^-11 s at both DAC and ADC, which corresponds to 0.5*10^-2 times the considered critical sampling period without oversampling. Based on the achieved results, it can be concluded that state-of-the-art hardware enables sufficient communication and sensing robustness against SJ, as RMS SJ values in the femtosecond range can be achieved.

</details>


### [7] [Deep Learning assisted Port-Cycling based Channel Sounding for Precoder Estimation in Massive MIMO Arrays](https://arxiv.org/abs/2601.14953)
*Advaith Arun,Shiv Shankar,Dhivagar Baskaran,Klutto Milleth,Bhaskar Ramamurthi*

Main category: eess.SP

TL;DR: 提出基于深度学习的CSI重建框架，通过端口循环机制降低参考信号开销，同时保持信道可观测性


<details>
  <summary>Details</summary>
Motivation: 未来无线系统将使用更多发射端口进行CSI估计，虽然能提高频谱效率，但会增加参考信号传输的资源开销，从而降低数据吞吐量

Method: 提出端口循环机制，在不同时间顺序探测CSI端口的不同部分，降低开销同时保持信道可观测性；设计CsiAdaNet模型利用稀疏测量捕获空间和时间相关性来重建完整端口CSI

Result: 仿真结果显示该方法在保持高CSI重建精度的同时实现了开销降低

Conclusion: 提出的DL-based CSI重建框架可作为未来6G系统中可靠CSI获取的使能技术

Abstract: Future wireless systems are expected to employ a substantially larger number of transmit ports for channel state information (CSI) estimation compared to current specifications. Although scaling ports improves spectral efficiency, it also increases the resource overhead to transmit reference signals across the time-frequency grid, ultimately reducing achievable data throughput. In this work, we propose an deep learning (DL)-based CSI reconstruction framework that serves as an enabler for reliable CSI acquisition in future 6G systems. The proposed solution involves designing a port-cycling mechanism that sequentially sounds different portions of CSI ports across time, thereby lowering the overhead while preserving channel observability. The proposed CSI Adaptive Network (CsiAdaNet) model exploits the resulting sparse measurements and captures both spatial and temporal correlations to accurately reconstruct the full-port CSI. The simulation results show that our method achieves overhead reduction while maintaining high CSI reconstruction accuracy.

</details>


### [8] [Alternative Shapes of Modulation Schemes Detailed Exposition and Simulation Methodology](https://arxiv.org/abs/2601.15004)
*Nipun Agarwal*

Main category: eess.SP

TL;DR: 论文对调制星座设计进行了统一研究，从几何、概率、优化和机器学习角度分析，评估了多种星座方案在AWGN和瑞利衰落信道下的性能，发现SER最优设计不一定能量最优，机器学习方法能灵活联合优化可靠性、鲁棒性和能量效率。


<details>
  <summary>Details</summary>
Motivation: 调制星座设计是数字通信的核心挑战，传统方案如PSK和QAM在分析上易处理，但在实际信道和非线性硬件约束下往往失去最优性。需要从多个角度研究星座设计，同时考虑符号错误率、衰落鲁棒性、峰均功率比和能量效率。

Method: 从几何、概率、优化和机器学习角度统一研究星座设计，通过大规模蒙特卡洛模拟评估经典、基于格点、非对称、概率成形、黄金角、启发式优化和机器学习辅助的星座在AWGN和瑞利衰落信道下的性能，结合PAPR感知和功率放大器模型。

Result: SER最优设计不一定能量最优，小的SER权衡可以带来显著的能量节省。机器学习方法通过将信道和硬件约束嵌入学习目标，能够灵活地联合优化可靠性、鲁棒性和能量效率。

Conclusion: 星座设计需要综合考虑多个性能指标，传统方案在实际约束下可能不是最优的。机器学习方法为联合优化可靠性、鲁棒性和能量效率提供了灵活框架，未来星座设计应考虑实际信道和硬件约束的联合优化。

Abstract: Modulation constellation design is a core challenge in digital communications, especially under stringent demands on spectral efficiency, robustness, and energy consumption. Classical schemes like PSK and QAM, while analytically tractable, often lose optimality under realistic channels and nonlinear hardware constraints. This paper provides a unified study of constellation design from geometric, probabilistic, optimization, and machine learning perspectives, focusing on symbol error rate (SER), fading robustness, peak-to-average power ratio (PAPR), and energy efficiency. We evaluate classical, lattice-based, asymmetric, probabilistically shaped, Golden Angle, heuristic-optimized, and machine learning assisted constellations under AWGN and Rayleigh fading via large-scale Monte Carlo simulations. Incorporating PAPR-aware and power amplifier models reveals that SER-optimal designs are not always energy-optimal; small SER trade-offs can yield substantial energy savings. Machine learning approaches offer flexible joint optimization of reliability, robustness, and energy efficiency by embedding channel and hardware constraints into the learning objective.

</details>


### [9] [Physical Layer Security in Massive MIMO: Challenges and Open Research Directions Against Passive Eavesdroppers](https://arxiv.org/abs/2601.15024)
*Nipun Agarwal*

Main category: eess.SP

TL;DR: 该论文研究了大规模MIMO系统中存在被动窃听者时的物理层安全传输方案性能比较，包括MRT、ZF和AN辅助波束赋形，通过蒙特卡洛仿真评估能量效率、安全中断概率和安全和速率等指标。


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO是5G及未来网络的关键技术，但在存在被动窃听者（基站不知其信道状态信息）时确保安全通信仍具挑战性。物理层安全利用无线信道随机性提供有前景的解决方案，但其在大规模MIMO中的有效性高度依赖于资源分配和传输策略。

Method: 研究比较了三种安全传输方案：最大比传输(MRT)、迫零(ZF)和人工噪声(AN)辅助波束赋形。通过广泛的蒙特卡洛仿真，在不同系统参数（天线数量、信噪比、功率分配等）下评估性能指标。

Result: 仿真结果提供了不同物理层安全策略在能量效率、安全中断概率和安全和速率等关键指标上的比较分析，揭示了各种方案的优缺点。

Conclusion: 研究结果为大规模MIMO系统中的物理层安全策略选择提供了比较性见解，并指出了未来6G网络中设计可扩展、能量高效且鲁棒的安全传输技术的开放研究方向。

Abstract: Massive Multiple-Input Multiple-Output (MIMO) has become a crucial enabling technology for 5G and beyond, providing previously unheard-of increases in energy and spectrum efficiency. It is still difficult to guarantee secure communication in these systems, particularly when it comes to passive eavesdroppers whose base station is unaware of their channel state information. By taking advantage of the inherent randomness of wireless channels, Physical Layer Security (PLS) offers a promising paradigm; however, its efficacy in massive MIMO is heavily reliant on resource allocation and transmission strategies. In this work, the performance of secure transmission schemes, such as Maximum Ratio Transmission (MRT), Zero-Forcing (ZF), and Artificial Noise (AN)-aided beamforming, is examined when passive eavesdroppers are present. This work will use extensive Monte Carlo simulations to assess important performance metrics such as energy efficiency, secrecy outage probability, and secrecy sum rate under different system parameters (e.g., number of antennas, Signal-to-Noise Ratio (SNR), power allocation). The results aim to provide comparative insight into the strengths and limitations of different PLS strategies and to highlight open research directions to design scalable, energy-efficient, and robust secure transmission techniques in future 6G networks.

</details>


### [10] [Neural Tracking of Sustained Attention, Attention Switching, and Natural Conversation in Audiovisual Environments using Mobile EEG](https://arxiv.org/abs/2601.15097)
*Johanna Wilroth,Oskar Keding,Martin A. Skoglund,Maria Sandsten,Martin Enqvist,Emina Alickovic*

Main category: eess.SP

TL;DR: 本研究开发了一个移动EEG数据集，用于在动态多感官环境中追踪选择性注意力，包含三种实验条件，结果显示移动EEG能可靠追踪真实场景中的注意力。


<details>
  <summary>Details</summary>
Motivation: 日常交流是动态、多感官的，涉及注意力转移、重叠语音和视觉线索，但现有神经注意力追踪研究大多局限于高度控制的实验室环境，使用干净的音频刺激并要求持续关注单一说话者。

Method: 使用移动EEG系统（44个头皮电极和20个cEEGrid电极）在视听范式下收集24名正常听力参与者的数据，包含三种条件：双说话者环境中持续关注单一说话者、在两个说话者间切换注意力、以及无脚本的双说话者对话与竞争性单说话者。

Result: 头皮EEG显示各条件下注意与忽略语音的P2峰值存在显著差异；切换与持续注意之间性能无显著变化表明对注意力切换具有鲁棒性；对话条件下的最优滞后分析显示峰值更窄，反映多说话者处理的额外复杂性；选择性注意分类准确率持续高于随机水平（55-70%），而cEEGrid数据相关性较低。

Conclusion: 移动EEG能可靠追踪动态多感官听力场景中的选择性注意力，为设计未来视听范式和真实世界注意力追踪应用提供指导。

Abstract: Everyday communication is dynamic and multisensory, often involving shifting attention, overlapping speech and visual cues. Yet, most neural attention tracking studies are still limited to highly controlled lab settings, using clean, often audio-only stimuli and requiring sustained attention to a single talker. This work addresses that gap by introducing a novel dataset from 24 normal-hearing participants. We used a mobile electroencephalography (EEG) system (44 scalp electrodes and 20 cEEGrid electrodes) in an audiovisual (AV) paradigm with three conditions: sustained attention to a single talker in a two-talker environment, attention switching between two talkers, and unscripted two-talker conversations with a competing single talker. Analysis included temporal response functions (TRFs) modeling, optimal lag analysis, selective attention classification with decision windows ranging from 1.1s to 35s, and comparisons of TRFs for attention to AV conversations versus side audio-only talkers. Key findings show significant differences in the attention-related P2-peak between attended and ignored speech across conditions for scalp EEG. No significant change in performance between switching and sustained attention suggests robustness for attention switches. Optimal lag analysis revealed narrower peak for conversation compared to single-talker AV stimuli, reflecting the additional complexity of multi-talker processing. Classification of selective attention was consistently above chance (55-70% accuracy) for scalp EEG, while cEEGrid data yielded lower correlations, highlighting the need for further methodological improvements. These results demonstrate that mobile EEG can reliably track selective attention in dynamic, multisensory listening scenarios and provide guidance for designing future AV paradigms and real-world attention tracking applications.

</details>


### [11] [Sparse Sensor Arrays for Active Sensing: Models, Configurations and Applications](https://arxiv.org/abs/2601.15126)
*Robin Rajamäki,Visa Koivunen*

Main category: eess.SP

TL;DR: 本章聚焦于使用稀疏阵列进行主动感知，讨论稀疏阵列设计、发射-接收波束形成及其在雷达、声纳等应用中的优势。


<details>
  <summary>Details</summary>
Motivation: 主动感知应用（如雷达、声纳、无线通信、医疗超声）需要传感器阵列发射能量探测环境。稀疏阵列相比传统均匀阵列具有优势：使用更少物理传感器实现更高分辨率，并能识别比传感器数量更多的散射体。通过和共阵列（sum co-array）概念，虚拟传感器数量可远超物理传感器。

Method: 1. 设计低冗余稀疏阵列配置；2. 采用发射-接收（Tx-Rx）波束形成；3. 讨论计算上难以处理的最小冗余阵列和可扩展的对称阵列框架；4. 通过图像加法合成波束形成方法减轻空间欠采样引起的旁瓣；5. 寻找合成期望Tx-Rx波束图的物理波束形成权重；6. 考虑相关的时空权衡。

Result: 提出了将许多著名的被动稀疏阵列几何结构扩展到主动情况的对称阵列框架，讨论了减轻旁瓣的方法，并提供了合成期望波束图的权重设计方法。

Conclusion: 稀疏阵列在主动感知中具有重要应用价值，通过和共阵列概念和有效的波束形成设计，能够以更少的物理传感器实现更好的性能，在雷达、声纳、无线通信和医疗超声等领域有广泛应用前景。

Abstract: This chapter focuses on active sensing using sparse arrays. In active sensing applications, such as radar, sonar, wireless communications, and medical ultrasound, a collection of sensors probes the environment by emitting self-generated energy. A key benefit of such active multi-sensor arrays is their ability to focus and steer energy in desired directions by beamforming on transmit. Sparse sensor arrays offer several advantages over conventional uniform arrays, including improved resolution using fewer physical sensors and the capability to identify more scatterers than sensors. This is facilitated by the effective transmit-receive virtual array known as the sum co-array, which can have many more virtual sensors than the number of physical transmit or receive sensors. Herein, we focus on the design of low-redundancy sparse array configurations and on employing transmit-receive (Tx-Rx) beamforming using sparse arrays. We discuss the optimal, but computationally intractable Minimum-redundancy array, and a scalable symmetric array framework, which extends many well-known passive sparse array geometries to the active case. We also examine mitigating side lobes arising from spatial undersampling by a synthetic beamforming method known as image addition. We briefly present approaches for finding the physical beamforming weights synthesizing a desired Tx-Rx beampattern, and consider related spatio-temporal trade-offs. We conclude by discussing selected applications of sparse arrays in active sensing.

</details>


### [12] [Weather Estimation for Integrated Sensing and Communication](https://arxiv.org/abs/2601.15145)
*Victoria Palhares,Artjom Grudnitsky,Silvio Mandelli*

Main category: eess.SP

TL;DR: 6G基站可用于天气感知，通过卷积神经网络分类和回归降水率与风速，实验准确率达99%以上，误差小于1.5mm/h/km/h。


<details>
  <summary>Details</summary>
Motivation: 6G通信的集成感知与通信（ISAC）技术除了物体检测外，其雷达副产品可用于天气感知。传统天气雷达昂贵且覆盖不足，而6G基站部署密集，可复用进行天气监测。

Method: 使用卷积神经网络实现分类器和回归器，训练数据包含不同降水率和风速的测量值。在ISAC概念验证平台上实施，并进行多周实验。

Result: 降水率分类准确率99.38%，风速分类准确率98.99%；降水率估计误差1.2mm/h，风速估计误差1.5km/h。

Conclusion: 6G ISAC网络可可靠部署天气感知服务，扩展服务组合并提升市场价值。

Abstract: One of the key features of sixth generation (6G) mobile communications will be integrated sensing and communication (ISAC). While the main goal of ISAC in standardization efforts is to detect objects, the byproducts of radar operations can be used to enable new services in 6G, such as weather sensing. Even though weather radars are the most prominent technology for weather detection and monitoring, they are expensive and usually neglect areas in close vicinity. To this end, we propose reusing the dense deployment of 6G base stations for weather sensing purposes by detecting and estimating weather conditions. We implement both a classifier and a regressor as a convolutional neural network trained across measurements with varying precipitation rates and wind speeds. We implement our approach in an ISAC proof-of-concept, and conduct a multi-week experiment campaign. Experimental results show that we are able to jointly and accurately classify weather conditions with accuracies of 99.38% and 98.99% for precipitation rate and wind speed, respectively. For estimation, we obtain errors of 1.2 mm/h and 1.5 km/h, for precipitation rate and wind speed, respectively. These findings indicate that weather sensing services can be reliably deployed in 6G ISAC networks, broadening their service portfolio and boosting their market value.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [13] [Towards noise-robust speech inversion through multi-task learning with speech enhancement](https://arxiv.org/abs/2601.14516)
*Saba Tabatabaee,Carol Espy-Wilson*

Main category: eess.AS

TL;DR: 提出统一框架，结合语音增强和语音反演，通过共享自监督学习表征，在噪声环境下显著提升语音反演性能


<details>
  <summary>Details</summary>
Motivation: 虽然自监督学习语音表征在语音反演中有效，但现实场景中的背景噪声限制了其应用。需要解决噪声环境下的语音反演挑战。

Method: 提出统一框架，整合语音增强和语音反演模型，通过共享自监督学习表征进行联合训练。自监督学习模型既支持语音增强模块抑制噪声，又生成对语音反演任务更具信息量的表征。

Result: 在信噪比-5dB条件下，相比基线方法，在babble噪声下获得80.95%的相对改进，在非babble噪声下获得38.98%的相对改进（基于所有估计参数的平均Pearson相关系数）。

Conclusion: 通过共享自监督学习表征的联合训练框架，能有效提升噪声环境下的语音反演性能，为现实场景应用提供了可行方案。

Abstract: Recent studies demonstrate the effectiveness of Self Supervised Learning (SSL) speech representations for Speech Inversion (SI). However, applying SI in real-world scenarios remains challenging due to the pervasive presence of background noise. We propose a unified framework that integrates Speech Enhancement (SE) and SI models through shared SSL-based speech representations. In this framework, the SSL model is trained not only to support the SE module in suppressing noise but also to produce representations that are more informative for the SI task, allowing both modules to benefit from joint training. At a Signal-to-Noise Ratio of -5 db, our method for the SI task achieves relative improvements over the baseline of 80.95% under babble noise and 38.98% under non-babble noise, as measured by the average Pearson product-moment correlation across all estimated parameters.

</details>


### [14] [Scaling Ambiguity: Augmenting Human Annotation in Speech Emotion Recognition with Audio-Language Models](https://arxiv.org/abs/2601.14620)
*Wenda Zhang,Hongyu Jin,Siyi Wang,Zhiqiang Wei,Ting Dang*

Main category: eess.AS

TL;DR: 本文探索使用大型音频-语言模型生成合成标注来解决模糊情感识别中的标注瓶颈问题，通过合成感知代理增强人类标注，提高情感分布可靠性。


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别模型使用单一分类标签，忽略了人类情感的固有模糊性。模糊情感识别将情感表示为概率分布，但进展受到从稀疏人类标注推断出的不可靠真实分布的限制。

Method: 引入一个框架，利用大型音频-语言模型创建合成感知代理，增强人类标注以提高真实分布可靠性；提出DiME-Aug（分布感知多模态情感增强策略）来解决类别不平衡和实现无偏评估。

Result: 在IEMOCAP和MSP-Podcast数据集上的实验表明，合成标注增强了情感分布，特别是在标注一致性高的低模糊区域。但对于人类分歧较大的高度模糊情感，益处会减少。

Conclusion: 这项工作首次证明大型音频-语言模型可以解决模糊情感识别中的标注稀缺问题，但强调需要更先进的提示或生成策略来处理高度模糊的情况。

Abstract: Speech Emotion Recognition models typically use single categorical labels, overlooking the inherent ambiguity of human emotions. Ambiguous Emotion Recognition addresses this by representing emotions as probability distributions, but progress is limited by unreliable ground-truth distributions inferred from sparse human annotations. This paper explores whether Large Audio-Language Models (ALMs) can mitigate the annotation bottleneck by generating high-quality synthetic annotations. We introduce a framework leveraging ALMs to create Synthetic Perceptual Proxies, augmenting human annotations to improve ground-truth distribution reliability. We validate these proxies through statistical analysis of their alignment with human distributions and evaluate their impact by fine-tuning ALMs with the augmented emotion distributions. Furthermore, to address class imbalance and enable unbiased evaluation, we propose DiME-Aug, a Distribution-aware Multimodal Emotion Augmentation strategy. Experiments on IEMOCAP and MSP-Podcast show that synthetic annotations enhance emotion distribution, especially in low-ambiguity regions where annotation agreement is high. However, benefits diminish for highly ambiguous emotions with greater human disagreement. This work provides the first evidence that ALMs could address annotation scarcity in ambiguous emotion recognition, but highlights the need for more advanced prompting or generation strategies to handle highly ambiguous cases.

</details>


### [15] [Triage knowledge distillation for speaker verification](https://arxiv.org/abs/2601.14699)
*Ju-ho Kim,Youngmoon Jung,Joon-Young Yang,Jaeyoung Roh,Chang Woo Han,Hoon-Young Cho*

Main category: eess.AS

TL;DR: 提出TRKD（分类知识蒸馏）方法，通过累积概率阈值τ将教师后验分为目标类、高概率混淆集和背景集三组，优先蒸馏混淆集条件分布，并采用τ递减的课程学习策略，在VoxCeleb1上实现最低EER。


<details>
  <summary>Details</summary>
Motivation: 在资源受限设备上部署说话人验证面临计算成本挑战，知识蒸馏（KD）是解决方案。但传统KD将目标置信度与非目标结构纠缠在KL项中，限制了关系信息传递；解耦KD虽分离信号但均匀处理非目标，在大类场景中仍受低概率长尾问题影响。

Method: 提出TRKD方法：1）评估：引入累积概率阈值τ，将教师后验分为目标类、高概率混淆集（最易混淆的非目标类）和背景集；2）优先：蒸馏混淆集条件分布，丢弃背景集；3）聚焦：采用τ递减的课程学习策略，从大τ开始传递广泛非目标上下文，逐步减小τ以聚焦最易混淆类。

Result: 在VoxCeleb1数据集上，使用同质和异质师生对进行广泛实验，TRKD始终优于近期KD变体，在所有协议上获得最低的等错误率（EER）。

Conclusion: TRKD通过评估-优先-聚焦的三步策略，有效解决了传统KD和解耦KD的局限性，在说话人验证任务中实现了更优的知识蒸馏效果，特别适合大类场景下的资源受限部署。

Abstract: Deploying speaker verification on resource-constrained devices remains challenging due to the computational cost of high-capacity models; knowledge distillation (KD) offers a remedy. Classical KD entangles target confidence with non-target structure in a Kullback-Leibler term, limiting the transfer of relational information. Decoupled KD separates these signals into target and non-target terms, yet treats non-targets uniformly and remains vulnerable to the long tail of low-probability classes in large-class settings. We introduce Triage KD (TRKD), a distillation scheme that operationalizes assess-prioritize-focus. TRKD introduces a cumulative-probability cutoff $τ$ to assess per-example difficulty and partition the teacher posterior into three groups: the target class, a high-probability non-target confusion-set, and a background-set. To prioritize informative signals, TRKD distills the confusion-set conditional distribution and discards the background. Concurrently, it transfers a three-mass (target/confusion/background) that capture sample difficulty and inter-class confusion. Finally, TRKD focuses learning via a curriculum on $τ$: training begins with a larger $τ$ to convey broad non-target context, then $τ$ is progressively decreased to shrink the confusion-set, concentrating supervision on the most confusable classes. In extensive experiments on VoxCeleb1 with both homogeneous and heterogeneous teacher-student pairs, TRKD was consistently superior to recent KD variants and attained the lowest EER across all protocols.

</details>


### [16] [NLP-Based Review for Toxic Comment Detection Tailored to the Chinese Cyberspace](https://arxiv.org/abs/2601.14721)
*Ruixing Ren,Junhui Zhao,Xiaoke Sun,Qiuping Li*

Main category: eess.AS

TL;DR: 该论文综述了中文网络空间中有毒评论检测的研究进展，分析了中文有毒评论的特点、数据集构建方法、检测模型演化路径，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着移动互联网和社交平台的普及，中文网络空间用户生成内容爆炸式增长，其中有毒评论对个人心理健康、社区氛围和社会信任构成严重挑战。由于中文网络语言的强语境依赖性、文化特异性和快速演变特性，传统检测方法存在明显局限性。

Method: 采用系统性综述方法：1) 定义中文有毒评论的内涵和特征；2) 分析现有公开数据集的构建方法和局限性；3) 提出细粒度可扩展的有毒评论定义分类框架及数据标注策略；4) 总结从传统方法到深度学习的检测模型演化路径；5) 特别强调模型可解释性的重要性。

Result: 系统梳理了中文有毒评论检测领域的研究进展，提出了新的分类框架和评估策略，总结了模型发展历程，特别强调了可解释性在模型设计中的重要性。

Conclusion: 当前研究面临诸多开放挑战，包括中文网络语言的复杂性、文化特异性等。未来需要进一步探索细粒度分类、可解释模型设计、跨平台适应性等方向，以提升中文有毒评论检测的准确性和实用性。

Abstract: With the in-depth integration of mobile Internet and widespread adoption of social platforms, user-generated content in the Chinese cyberspace has witnessed explosive growth. Among this content, the proliferation of toxic comments poses severe challenges to individual mental health, community atmosphere and social trust. Owing to the strong context dependence, cultural specificity and rapid evolution of Chinese cyber language, toxic expressions are often conveyed through complex forms such as homophones and metaphors, imposing notable limitations on traditional detection methods. To address this issue, this review focuses on the core topic of natural language processing based toxic comment detection in the Chinese cyberspace, systematically collating and critically analyzing the research progress and key challenges in this field. This review first defines the connotation and characteristics of Chinese toxic comments, and analyzes the platform ecology and transmission mechanisms they rely on. It then comprehensively reviews the construction methods and limitations of existing public datasets, and proposes a novel fine-grained and scalable framework for toxic comment definition and classification, along with corresponding data annotation and quality assessment strategies. We systematically summarize the evolutionary path of detection models from traditional methods to deep learning, with special emphasis on the importance of interpretability in model design. Finally, we thoroughly discuss the open challenges faced by current research and provide forward-looking suggestions for future research directions.

</details>


### [17] [AQAScore: Evaluating Semantic Alignment in Text-to-Audio Generation via Audio Question Answering](https://arxiv.org/abs/2601.14728)
*Chun-Yi Kuan,Kai-Wei Chang,Hung-yi Lee*

Main category: eess.AS

TL;DR: AQAScore：基于音频感知大语言模型的文本-音频生成评估框架，通过概率语义验证任务评估语义对齐，优于基于嵌入相似度的传统方法


<details>
  <summary>Details</summary>
Motivation: 文本到音频生成在真实性和多样性方面取得了显著进展，但评估指标的发展滞后。广泛采用的基于嵌入相似度的方法（如CLAPScore）能有效衡量一般相关性，但在细粒度语义对齐和组合推理方面存在局限

Method: 引入AQAScore评估框架，利用音频感知大语言模型的推理能力，将评估重新定义为概率语义验证任务。通过计算对目标语义查询回答"Yes"的确切对数概率来估计对齐度，而不是依赖开放式文本生成

Result: 在多个基准测试中评估AQAScore，包括人类评分相关性、成对比较和组合推理任务。实验结果显示，AQAScore始终比基于相似度的指标和生成提示基线方法获得更高的人类判断相关性，能有效捕捉细微的语义不一致性，并随着底层音频感知大语言模型能力的提升而扩展

Conclusion: AQAScore提供了一个有效的文本-音频生成评估框架，通过概率语义验证方法在细粒度语义对齐和组合推理方面优于传统相似度指标，展示了音频感知大语言模型在评估任务中的潜力

Abstract: Although text-to-audio generation has made remarkable progress in realism and diversity, the development of evaluation metrics has not kept pace. Widely-adopted approaches, typically based on embedding similarity like CLAPScore, effectively measure general relevance but remain limited in fine-grained semantic alignment and compositional reasoning. To address this, we introduce AQAScore, a backbone-agnostic evaluation framework that leverages the reasoning capabilities of audio-aware large language models (ALLMs). AQAScore reformulates assessment as a probabilistic semantic verification task; rather than relying on open-ended text generation, it estimates alignment by computing the exact log-probability of a "Yes" answer to targeted semantic queries. We evaluate AQAScore across multiple benchmarks, including human-rated relevance, pairwise comparison, and compositional reasoning tasks. Experimental results show that AQAScore consistently achieves higher correlation with human judgments than similarity-based metrics and generative prompting baselines, showing its effectiveness in capturing subtle semantic inconsistencies and scaling with the capability of underlying ALLMs.

</details>


### [18] [Inverse-Hessian Regularization for Continual Learning in ASR](https://arxiv.org/abs/2601.14751)
*Steven Vander Eeckt,Hugo Van hamme*

Main category: eess.AS

TL;DR: 提出了一种用于语音识别持续学习的无记忆方法IHR，通过引入曲率信息来调整模型合并，减少灾难性遗忘同时保持适应性。


<details>
  <summary>Details</summary>
Motivation: 持续学习中的灾难性遗忘问题严重，现有权重平均方法虽然简单有效但缺乏理论依据，忽略了任务损失曲面的结构信息。

Method: 提出逆Hessian正则化(IHR)，在微调新任务后，利用前一个任务的Kronecker分解逆Hessian近似来调整模型更新方向，使模型主要沿对过去性能影响较小的方向移动。

Result: 在两个持续学习基准测试中，IHR显著优于现有最先进基线方法，减少了遗忘同时提高了适应性。消融研究进一步证实了其有效性。

Conclusion: IHR是一种轻量级的无记忆持续学习方法，通过引入曲率信息有效解决了语音识别中的灾难性遗忘问题，在保持适应性的同时显著减少了遗忘。

Abstract: Catastrophic forgetting remains a major challenge for continual learning (CL) in automatic speech recognition (ASR), where models must adapt to new domains without losing performance on previously learned conditions. Several CL methods have been proposed for ASR, and, recently, weight averaging - where models are averaged in a merging step after fine-tuning - has proven effective as a simple memory-free strategy. However, it is heuristic in nature and ignores the underlying loss landscapes of the tasks, hindering adaptability. In this work, we propose Inverse Hessian Regularization (IHR), a memory-free approach for CL in ASR that incorporates curvature information into the merging step. After fine-tuning on a new task, the adaptation is adjusted through a Kronecker-factored inverse Hessian approximation of the previous task, ensuring that the model moves primarily in directions less harmful to past performance, while keeping the method lightweight. We evaluate IHR on two CL benchmarks and show that it significantly outperforms state-of-the-art baselines, reducing forgetting while improving adaptability. Ablation studies and analyses further confirm its effectiveness.

</details>


### [19] [Test-Time Adaptation For Speech Enhancement Via Mask Polarization](https://arxiv.org/abs/2601.14770)
*Tobias Raichle,Erfan Amini,Bin Yang*

Main category: eess.AS

TL;DR: 提出了一种轻量级测试时自适应方法MPol，通过恢复掩码双峰性来提升语音增强模型在未见环境中的性能，无需额外参数，适合边缘部署。


<details>
  <summary>Details</summary>
Motivation: 语音增强模型在实际部署中需要适应未见环境，但测试时自适应在语音增强领域研究不足，缺乏对模型在域偏移下性能下降机制的理解。

Method: 提出掩码极化方法MPol，基于观察到掩码基语音增强模型在域偏移下失去置信度、掩码变得平坦的洞察，通过Wasserstein距离进行分布比较来恢复掩码的双峰性。

Result: 在不同域偏移和架构上的实验结果表明，MPol能够获得非常一致的性能提升，与更复杂的方法相比具有竞争力。

Conclusion: MPol是一种轻量级、无需额外参数的测试时自适应方法，能够有效提升语音增强模型在未见环境中的性能，适合资源受限的边缘部署场景。

Abstract: Adapting speech enhancement (SE) models to unseen environments is crucial for practical deployments, yet test-time adaptation (TTA) for SE remains largely under-explored due to a lack of understanding of how SE models degrade under domain shifts. We observe that mask-based SE models lose confidence under domain shifts, with predicted masks becoming flattened and losing decisive speech preservation and noise suppression. Based on this insight, we propose mask polarization (MPol), a lightweight TTA method that restores mask bimodality through distribution comparison using the Wasserstein distance. MPol requires no additional parameters beyond the trained model, making it suitable for resource-constrained edge deployments. Experimental results across diverse domain shifts and architectures demonstrate that MPol achieves very consistent gains that are competitive with significantly more complex approaches.

</details>


### [20] [Fast-ULCNet: A fast and ultra low complexity network for single-channel speech enhancement](https://arxiv.org/abs/2601.14925)
*Nicolás Arrieta Larraza,Niels de Koeijer*

Main category: eess.AS

TL;DR: Fast-ULCNet：通过用FastGRNN替换GRU层并引入可训练互补滤波器来解决状态漂移问题，在保持语音增强性能的同时，将模型大小减半、延迟降低34%


<details>
  <summary>Details</summary>
Motivation: 在资源受限的嵌入式设备中，单通道语音增强算法需要低延迟和低复杂度设计。虽然ULCNet是该领域的最先进方法，但其GRU层计算复杂度较高，需要进一步优化。

Method: 1. 将ULCNet中的GRU层替换为FastGRNN以降低计算延迟和复杂度；2. 针对FastGRNN在长音频信号推理时出现的内部状态漂移问题，提出基于可训练互补滤波器的新方法进行缓解

Result: Fast-ULCNet在语音增强任务上的性能与原始ULCNet相当，同时模型大小减少超过一半，平均延迟降低34%

Conclusion: 通过FastGRNN替换和状态漂移缓解技术，成功实现了在保持语音增强性能的同时显著降低模型复杂度和延迟，适用于资源受限的嵌入式设备

Abstract: Single-channel speech enhancement algorithms are often used in resource-constrained embedded devices, where low latency and low complexity designs gain more importance. In recent years, researchers have proposed a wide variety of novel solutions to this problem. In particular, a recent deep learning model named ULCNet is among the state-of-the-art approaches in this domain. This paper proposes an adaptation of ULCNet, by replacing its GRU layers with FastGRNNs, to reduce both computational latency and complexity. Furthermore, this paper shows empirical evidence on the performance decay of FastGRNNs in long audio signals during inference due to internal state drifting, and proposes a novel approach based on a trainable complementary filter to mitigate it. The resulting model, Fast-ULCNet, performs on par with the state-of-the-art original ULCNet architecture on a speech enhancement task, while reducing its model size by more than half and decreasing its latency by 34% on average.

</details>


### [21] [Synthetic Singers: A Review of Deep-Learning-based Singing Voice Synthesis Approaches](https://arxiv.org/abs/2601.13910)
*Changhao Pan,Dongyu Yao,Yu Zhang,Wenxiang Guo,Jingyu Lu,Zhiyuan Zhu,Zhou Zhao*

Main category: eess.AS

TL;DR: 这是一篇关于歌声合成（SVS）的综述论文，系统分析了深度学习歌声合成系统的分类、架构、核心技术、数据集和评估基准。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型和新型生成范式的出现，歌声合成技术取得了显著进展，但缺乏对深度学习歌声合成系统及其使能技术的系统性综述分析。

Method: 首先按任务类型对现有系统进行分类，然后将当前架构组织为两大范式：级联方法和端到端方法，并对核心技术（歌声建模和控制技术）进行深入分析。

Result: 提供了对SVS模型的文献综述，涵盖了相关数据集、标注工具和评估基准，为研究人员和工程师提供了有用的参考资源。

Conclusion: 这篇综述提供了歌声合成领域的最新文献回顾，有助于推动该领域的研究和发展，相关材料已在GitHub上开源。

Abstract: Recent advances in singing voice synthesis (SVS) have attracted substantial attention from both academia and industry. With the advent of large language models and novel generative paradigms, producing controllable, high-fidelity singing voices has become an attainable goal. Yet the field still lacks a comprehensive survey that systematically analyzes deep-learning-based singing voice synthesis systems and their enabling technologies. To address the aforementioned issue, this survey first categorizes existing systems by task type and then organizes current architectures into two major paradigms: cascaded and end-to-end approaches. Moreover, we provide an in-depth analysis of core technologies, covering singing modeling and control techniques. Finally, we review relevant datasets, annotation tools, and evaluation benchmarks that support training and assessment. In appendix, we introduce training strategies and further discussion of SVS. This survey provides an up-to-date review of the literature on SVS models, which would be a useful reference for both researchers and engineers. Related materials are available at https://github.com/David-Pigeon/SyntheticSingers.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [22] [Single-step Controllable Music Bandwidth Extension With Flow Matching](https://arxiv.org/abs/2601.14356)
*Carlos Hernandez-Olivan,Hendrik Vincent Koops,Hao Hao Tan,Elio Quinton*

Main category: cs.SD

TL;DR: 提出使用动态频谱轮廓(DSC)作为控制信号，通过无分类器引导实现带宽扩展，提升音频修复的精细控制能力


<details>
  <summary>Details</summary>
Motivation: 音频修复对于历史音乐档案等珍贵录音非常重要，但现有生成模型在精细控制方面仍面临挑战，需要更好的控制信号来实现更精确的修复操作

Method: 扩展FLowHigh模型，引入动态频谱轮廓(DSC)作为控制信号，通过无分类器引导进行带宽扩展，实现对音频修复的精细条件控制

Result: 实验显示模型性能具有竞争力，DSC被证明是支持细粒度条件控制的promising特征

Conclusion: 动态频谱轮廓(DSC)是一种有效的控制信号，能够提升音频修复生成模型的精细控制能力，为更精确的音频修复操作提供了新的可能性

Abstract: Audio restoration consists in inverting degradations of a digital audio signal to recover what would have been the pristine quality signal before the degradation occurred. This is valuable in contexts such as archives of music recordings, particularly those of precious historical value, for which a clean version may have been lost or simply does not exist. Recent work applied generative models to audio restoration, showing promising improvement over previous methods, and opening the door to the ability to perform restoration operations that were not possible before. However, making these models finely controllable remains a challenge. In this paper, we propose an extension of FLowHigh and introduce the Dynamic Spectral Contour (DSC) as a control signal for bandwidth extension via classifier-free guidance. Our experiments show competitive model performance, and indicate that DSC is a promising feature to support fine-grained conditioning.

</details>


### [23] [Prosody-Guided Harmonic Attention for Phase-Coherent Neural Vocoding in the Complex Spectrum](https://arxiv.org/abs/2601.14472)
*Mohammed Salah Al-Radhi,Riad Larbi,Mátyás Bartalis,Géza Németh*

Main category: cs.SD

TL;DR: 提出一种结合韵律引导谐波注意力和直接复数频谱建模的神经声码器，通过逆STFT合成波形，在音高保真度和相位一致性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有神经声码器在韵律建模和相位重建方面存在局限，大多数基于梅尔频谱的方法无法有效建模相位信息，导致音高保真度不足和相位不连贯问题。

Method: 1) 引入韵律引导谐波注意力增强浊音段编码；2) 通过逆STFT直接预测复数频谱分量合成波形；3) 采用多目标训练策略，结合对抗损失、频谱损失和相位感知损失。

Result: 在基准数据集上优于HiFi-GAN和AutoVocoder：F0 RMSE降低22%，浊音/清音错误率降低18%，MOS评分提高0.15，生成更自然、音高准确且鲁棒的合成语音。

Conclusion: 韵律引导注意力与直接复数频谱建模相结合，为表达性神经声码器奠定了坚实基础，显著提升了合成语音的自然度和音高保真度。

Abstract: Neural vocoders are central to speech synthesis; despite their success, most still suffer from limited prosody modeling and inaccurate phase reconstruction. We propose a vocoder that introduces prosody-guided harmonic attention to enhance voiced segment encoding and directly predicts complex spectral components for waveform synthesis via inverse STFT. Unlike mel-spectrogram-based approaches, our design jointly models magnitude and phase, ensuring phase coherence and improved pitch fidelity. To further align with perceptual quality, we adopt a multi-objective training strategy that integrates adversarial, spectral, and phase-aware losses. Experiments on benchmark datasets demonstrate consistent gains over HiFi-GAN and AutoVocoder: F0 RMSE reduced by 22 percent, voiced/unvoiced error lowered by 18 percent, and MOS scores improved by 0.15. These results show that prosody-guided attention combined with direct complex spectrum modeling yields more natural, pitch-accurate, and robust synthetic speech, setting a strong foundation for expressive neural vocoding.

</details>


### [24] [Dissecting Performance Degradation in Audio Source Separation under Sampling Frequency Mismatch](https://arxiv.org/abs/2601.14684)
*Kanami Imamura,Tomohiko Nakamura,Kohei Yatabe,Hiroshi Saruwatari*

Main category: cs.SD

TL;DR: 该论文研究了音频处理中采样频率不匹配导致的性能下降问题，提出了三种改进的重采样方法，并通过实验验证了噪声核重采样和可训练核重采样的有效性。


<details>
  <summary>Details</summary>
Motivation: 基于深度神经网络的音频处理方法通常在单一采样频率下训练，当处理未训练采样频率时，传统重采样方法（特别是输入采样频率低于训练采样频率时）会导致性能下降。论文旨在探究这种性能下降的原因并寻找改进方案。

Method: 论文提出了两种假设来解释性能下降原因：1）上采样引入的高频分量缺失；2）高频分量的存在比精确表示更重要。基于此，比较了传统重采样与三种替代方法：后重采样噪声添加（在重采样信号中添加高斯噪声）、噪声核重采样（用高斯噪声扰动核以丰富高频分量）、可训练核重采样（通过训练自适应插值核）。

Result: 在音乐源分离任务上的实验表明，噪声核重采样和可训练核重采样能够缓解传统重采样观察到的性能下降。进一步证明噪声核重采样在不同模型中均有效，是一种简单实用的选择。

Conclusion: 论文验证了高频分量缺失是采样频率不匹配导致性能下降的主要原因，并提出了有效的改进重采样方法。噪声核重采样因其简单性和跨模型有效性而被推荐为实用解决方案。

Abstract: Audio processing methods based on deep neural networks are typically trained at a single sampling frequency (SF). To handle untrained SFs, signal resampling is commonly employed, but it can degrade performance, particularly when the input SF is lower than the trained SF. This paper investigates the causes of this degradation through two hypotheses: (i) the lack of high-frequency components introduced by up-sampling, and (ii) the greater importance of their presence than their precise representation. To examine these hypotheses, we compare conventional resampling with three alternatives: post-resampling noise addition, which adds Gaussian noise to the resampled signal; noisy-kernel resampling, which perturbs the kernel with Gaussian noise to enrich high-frequency components; and trainable-kernel resampling, which adapts the interpolation kernel through training. Experiments on music source separation show that noisy-kernel and trainable-kernel resampling alleviate the degradation observed with conventional resampling. We further demonstrate that noisy-kernel resampling is effective across diverse models, highlighting it as a simple yet practical option.

</details>


### [25] [Unlocking Large Audio-Language Models for Interactive Language Learning](https://arxiv.org/abs/2601.14744)
*Hongfu Liu,Zhouying Cui,Xiangming Gu,Ye Wang*

Main category: cs.SD

TL;DR: 该论文提出使用音频语言模型进行发音训练，创建了L2-Arctic-plus数据集，并通过指令微调显著提升了发音错误检测和反馈生成效果。


<details>
  <summary>Details</summary>
Motivation: 传统计算机辅助发音训练系统反馈不够直观且缺乏可操作性指导，限制了其有效性。音频语言模型的发展为提供更用户友好的反馈提供了可能。

Method: 1) 引入L2-Arctic-plus英语数据集，包含详细的错误解释和改进建议；2) 对级联ASR+LLM和现有音频语言模型进行基准测试；3) 在L2-Arctic-plus数据集上对音频语言模型进行指令微调。

Result: 指令微调后的模型在发音错误检测和建议生成方面显著优于现有基线，在客观评估和人工评估中都表现出更好的性能。

Conclusion: 指令微调的音频语言模型能够有效提升发音训练系统的性能，所提出的L2-Arctic-plus数据集具有重要价值，为基于聊天的发音训练提供了更好的解决方案。

Abstract: Achieving pronunciation proficiency in a second language (L2) remains a challenge, despite the development of Computer-Assisted Pronunciation Training (CAPT) systems. Traditional CAPT systems often provide unintuitive feedback that lacks actionable guidance, limiting its effectiveness. Recent advancements in audio-language models (ALMs) offer the potential to enhance these systems by providing more user-friendly feedback. In this work, we investigate ALMs for chat-based pronunciation training by introducing L2-Arctic-plus, an English dataset with detailed error explanations and actionable suggestions for improvement. We benchmark cascaded ASR+LLMs and existing ALMs on this dataset, specifically in detecting mispronunciation and generating actionable feedback. To improve the performance, we further propose to instruction-tune ALMs on L2-Arctic-plus. Experimental results demonstrate that our instruction-tuned models significantly outperform existing baselines on mispronunciation detection and suggestion generation in terms of both objective and human evaluation, highlighting the value of the proposed dataset.

</details>


### [26] [Training-Efficient Text-to-Music Generation with State-Space Modeling](https://arxiv.org/abs/2601.14786)
*Wei-Jaw Lee,Fang-Chih Hsieh,Xuanjun Chen,Fang-Duo Tsai,Yi-Hsuan Yang*

Main category: cs.SD

TL;DR: 本文提出使用状态空间模型(SSMs)替代Transformer作为文本到音乐生成模型的骨干，在保持300M参数规模的同时，显著提升了训练效率和数据效率，仅用9%的计算量和2%的训练数据就达到了与基准模型竞争的性能。


<details>
  <summary>Details</summary>
Motivation: 当前文本到音乐生成模型虽然质量高，但计算成本大且依赖大型专有数据集。为了提升TTM训练的可负担性和开放性，需要更高效的开源生成模型骨干。

Method: 将生成模型的可训练参数限制在300M左右，用状态空间模型(SSMs)替代Transformer骨干。探索了不同的SSM变体，比较了单阶段SSM设计和可分解的两阶段SSM/扩散混合设计。所有模型都在457小时的CC授权公共数据集上从头训练。

Result: 1. SSMs相比Transformer具有更优的训练效率；2. 仅用9%的FLOPs和2%的训练数据，模型在客观指标和主观听测中达到与MusicGen-small基准竞争的性能；3. 缩放实验显示，在相同训练预算下，即使模型尺寸缩小4倍，SSMs仍能保持相对于Transformer基线的竞争性能。

Conclusion: SSMs在文本到音乐生成任务中展现出比Transformer更优的训练和数据效率，为TTM研究的民主化提供了可行的开源解决方案。所有处理后的标注、模型检查点和源代码都已开源。

Abstract: Recent advances in text-to-music generation (TTM) have yielded high-quality results, but often at the cost of extensive compute and the use of large proprietary internal data. To improve the affordability and openness of TTM training, an open-source generative model backbone that is more training- and data-efficient is needed. In this paper, we constrain the number of trainable parameters in the generative model to match that of the MusicGen-small benchmark (with about 300M parameters), and replace its Transformer backbone with the emerging class of state-space models (SSMs). Specifically, we explore different SSM variants for sequence modeling, and compare a single-stage SSM-based design with a decomposable two-stage SSM/diffusion hybrid design. All proposed models are trained from scratch on a purely public dataset comprising 457 hours of CC-licensed music, ensuring full openness. Our experimental findings are three-fold. First, we show that SSMs exhibit superior training efficiency compared to the Transformer counterpart. Second, despite using only 9% of the FLOPs and 2% of the training data size compared to the MusicGen-small benchmark, our model achieves competitive performance in both objective metrics and subjective listening tests based on MusicCaps captions. Finally, our scaling-down experiment demonstrates that SSMs can maintain competitive performance relative to the Transformer baseline even at the same training budget (measured in iterations), when the model size is reduced to four times smaller. To facilitate the democratization of TTM research, the processed captions, model checkpoints, and source code are available on GitHub via the project page: https://lonian6.github.io/ssmttm/.

</details>


### [27] [Multi-Tast Transformer for Explainable Speech Deepfake Detection via Formant Modeling](https://arxiv.org/abs/2601.14850)
*Viola Negroni,Luca Cuccovillo,Paolo Bestagini,Patrick Aichroth,Stefano Tubaro*

Main category: cs.SD

TL;DR: 提出用于语音深度伪造检测的多任务Transformer模型，可预测共振峰轨迹和发声模式，同时分类语音真伪并解释决策依据


<details>
  <summary>Details</summary>
Motivation: 现有语音深度伪造检测模型缺乏可解释性，无法说明决策是基于有声区还是无声区特征，需要更高效且可解释的检测方法

Method: 基于先前的说话人共振峰Transformer架构，改进输入分段策略，重新设计解码过程，集成内置可解释性机制，构建多任务Transformer

Result: 相比基线模型，参数更少、训练更快、可解释性更好，且预测性能未下降

Conclusion: 该多任务Transformer在保持检测性能的同时，提供了更好的可解释性和效率，有助于理解语音伪造检测的决策依据

Abstract: In this work, we introduce a multi-task transformer for speech deepfake detection, capable of predicting formant trajectories and voicing patterns over time, ultimately classifying speech as real or fake, and highlighting whether its decisions rely more on voiced or unvoiced regions. Building on a prior speaker-formant transformer architecture, we streamline the model with an improved input segmentation strategy, redesign the decoding process, and integrate built-in explainability. Compared to the baseline, our model requires fewer parameters, trains faster, and provides better interpretability, without sacrificing prediction performance.

</details>


### [28] [Generative Artificial Intelligence, Musical Heritage and the Construction of Peace Narratives: A Case Study in Mali](https://arxiv.org/abs/2601.14931)
*Nouhoum Coulibaly,Ousmane Ly,Michael Leventhal,Ousmane Goro*

Main category: cs.SD

TL;DR: 研究探索生成式AI在构建马里和平叙事和振兴音乐遗产方面的潜力，通过文化敏感的参与式框架，AI可作为象征性外交的催化剂，但面临语言语料库不足、算法审查和版权伦理等挑战。


<details>
  <summary>Details</summary>
Motivation: 马里面临社区间紧张和社会分裂的政治社会背景，需要寻找新的象征性框架来实现和解。研究旨在探索生成式AI如何帮助构建和平叙事和振兴音乐遗产，以促进社会凝聚力。

Method: 通过实证研究探索三个问题：1) Gen AI如何作为基于民族语言和传统的音乐创作工具；2) Gen AI系统在技术创新与文化真实性之间的平衡程度；3) AI辅助音乐共创如何加强社会凝聚力和文化主权。

Result: 实验结果表明，嵌入文化敏感参与式框架的生成式AI可以作为象征性外交的催化剂，放大而非标准化当地声音。但面临语言语料库可用性、算法审查以及从受版权保护来源生成作品的伦理等挑战。

Conclusion: 生成式AI在文化敏感框架下具有促进和平叙事和音乐遗产振兴的潜力，但需要解决语言资源、算法偏见和伦理问题，才能真正实现技术创新与文化真实性的平衡，并加强社会凝聚力。

Abstract: This study explores the capacity of generative artificial intelligence (Gen AI) to contribute to the construction of peace narratives and the revitalization of musical heritage in Mali. The study has been made in a political and social context where inter-community tensions and social fractures motivate a search for new symbolic frameworks for reconciliation. The study empirically explores three questions: (1) how Gen AI can be used as a tool for musical creation rooted in national languages and traditions; (2) to what extent Gen AI systems enable a balanced hybridization between technological innovation and cultural authenticity; and (3) how AI-assisted musical co-creation can strengthen social cohesion and cultural sovereignty. The experimental results suggest that Gen AI, embedded in a culturally conscious participatory framework, can act as a catalyst for symbolic diplomacy, amplifying local voices instead of standardizing them. However, challenges persist regarding the availability of linguistic corpora, algorithmic censorship, and the ethics of generating compositions derived from copyrighted sources.

</details>


### [29] [VCNAC: A Variable-Channel Neural Audio Codec for Mono, Stereo, and Surround Sound](https://arxiv.org/abs/2601.14960)
*Florian Grötschla,Arunasish Sen,Alessandro Lombardi,Guillermo Cámbara,Andreas Schwarz*

Main category: cs.SD

TL;DR: VCNAC是一个可变通道神经音频编解码器，使用单一编码器-解码器参数化支持从单声道到5.1环绕声的不同通道配置，通过通道兼容性目标保持多通道内容在较少通道解码时的感知质量。


<details>
  <summary>Details</summary>
Motivation: 现有神经音频编解码器通常针对特定通道配置设计，缺乏灵活支持不同通道设置的能力。需要一种统一的方法来处理从单声道语音到影院级5.1环绕声的各种音频配置。

Method: 采用单一编码器和解码器参数化，支持原生推理不同通道设置。引入通道兼容性目标确保多通道内容在解码到较少通道时保持感知质量。共享表示使生成语言模型能够在单一码本集上训练，同时支持跨模态和通道配置的推理时扩展性。

Result: 通过客观空间音频指标和主观听力测试评估，该统一方法在单声道、立体声和环绕声配置下均保持了高质量重建。多通道内容在解码到较少通道时仍保持良好感知质量。

Conclusion: VCNAC成功实现了可变通道神经音频编解码，通过单一参数化支持多种通道配置，同时保持高质量重建。该方法为跨不同音频格式的统一编解码提供了有效解决方案。

Abstract: We present VCNAC, a variable channel neural audio codec. Our approach features a single encoder and decoder parametrization that enables native inference for different channel setups, from mono speech to cinematic 5.1 channel surround audio. Channel compatibility objectives ensure that multi-channel content maintains perceptual quality when decoded to fewer channels. The shared representation enables training of generative language models on a single set of codebooks while supporting inference-time scalability across modalities and channel configurations. Evaluation using objective spatial audio metrics and subjective listening tests demonstrates that our unified approach maintains high reconstruction quality across mono, stereo, and surround audio configurations.

</details>


### [30] [Bangla Music Genre Classification Using Bidirectional LSTMS](https://arxiv.org/abs/2601.15083)
*Muntakimur Rahaman,Md Mahmudul Hoque,Md Mehedi Hassain*

Main category: cs.SD

TL;DR: 本文提出使用LSTM网络和MFCC特征提取方法对孟加拉音乐进行十种流派的自动分类，达到78%的准确率。


<details>
  <summary>Details</summary>
Motivation: 随着孟加拉音乐数量的指数级增长，需要有效的索引和检索系统。自动音乐流派分类对于在庞大而多样的音乐库中高效定位特定作品至关重要。

Method: 使用循环神经网络（RNN）架构，特别是长短期记忆（LSTM）网络进行训练和分类。采用梅尔频率倒谱系数（MFCCs）从原始音频波形中提取紧凑且具有代表性的特征集。

Result: 实验结果显示分类准确率达到78%，表明该系统在增强和简化孟加拉音乐流派组织方面具有强大潜力。

Conclusion: 提出的基于LSTM和MFCC特征的框架能够有效对孟加拉音乐进行流派分类，为音乐库的组织和检索提供了实用解决方案。

Abstract: Bangla music is enrich in its own music cultures. Now a days music genre classification is very significant because of the exponential increase in available music, both in digital and physical formats. It is necessary to index them accordingly to facilitate improved retrieval. Automatically classifying Bangla music by genre is essential for efficiently locating specific pieces within a vast and diverse music library. Prevailing methods for genre classification predominantly employ conventional machine learning or deep learning approaches. This work introduces a novel music dataset comprising ten distinct genres of Bangla music. For the task of audio classification, we utilize a recurrent neural network (RNN) architecture. Specifically, a Long Short-Term Memory (LSTM) network is implemented to train the model and perform the classification. Feature extraction represents a foundational stage in audio data processing. This study utilizes Mel-Frequency Cepstral Coefficients (MFCCs) to transform raw audio waveforms into a compact and representative set of features. The proposed framework facilitates music genre classification by leveraging these extracted features. Experimental results demonstrate a classification accuracy of 78%, indicating the system's strong potential to enhance and streamline the organization of Bangla music genres.

</details>


### [31] [WavLink: Compact Audio--Text Embeddings with a Global Whisper Token](https://arxiv.org/abs/2601.15118)
*Gokul Karthik Kumar,Ludovick Lepauloux,Hakim Hacid*

Main category: cs.SD

TL;DR: WavLink是一个紧凑的音频-文本嵌入模型，通过增强Whisper编码器并加入可学习的全局标记，与文本编码器联合训练，在音频检索任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: Whisper已成为大型音频-语言模型中提取通用音频特征的事实标准编码器，但在音频-文本嵌入模型（如CLAP）中却未得到有效利用。现有模型主要依赖其他音频编码器，因此需要探索如何有效利用Whisper构建更好的音频-文本嵌入模型。

Method: 1. 在Whisper编码器基础上添加可学习的全局标记；2. 与文本编码器联合训练；3. 系统研究设计选择：预训练文本编码器、损失函数、训练模式、数据混合；4. 采用两阶段训练方案；5. 结合Matryoshka风格监督实现可扩展性。

Result: 1. 在音频检索任务上达到最先进的性能；2. 通过Matryoshka监督实现8倍更小的嵌入向量，性能下降最小；3. 在AIR-Bench的多选题和零样本分类任务上表现出竞争力。

Conclusion: WavLink成功展示了如何有效利用Whisper编码器构建紧凑且高性能的音频-文本嵌入模型，通过系统化的设计选择和创新的训练策略，在多个任务上取得了优异表现。

Abstract: Whisper has become the de-facto encoder for extracting general-purpose audio features in large audio-language models, where a 30-second clip is typically represented by 1500 frame features projected into an LLM. In contrast, audio-text embedding models like CLAP-based models have largely relied on alternative audio encoders (e.g., HTS-AT, PaSST), and have not leveraged Whisper effectively. We present WavLink, a compact audio-text embedding model that augments Whisper encoder with a learnable global token, trained jointly with a text encoder. Through a systematic study of design choices, including pretrained text encoders, loss functions, training modes, and data mixtures, we identify configurations that yield state-of-the-art retrieval performance. Our two-stage training recipe across three model sizes, combined with Matryoshka-style supervision, improves scalability, enabling 8x smaller embeddings with minimal performance drop. WavLink also demonstrates competitive performance on AIR-Bench with MCQs and zero-shot classification.

</details>


### [32] [WeDefense: A Toolkit to Defend Against Fake Audio](https://arxiv.org/abs/2601.15240)
*Lin Zhang,Johan Rohdin,Xin Wang,Junyi Peng,Tianchi Liu,You Zhang,Hieu-Thi Luong,Shuai Wang,Chengdong Liang,Anna Silnova,Nicholas Evans*

Main category: cs.SD

TL;DR: WeDefense：首个支持伪造音频检测和定位的开源工具包，提供标准化评估框架


<details>
  <summary>Details</summary>
Motivation: 生成式AI的进步使得合成音频与真实音频难以区分，虽然带来积极应用，但也存在冒充、虚假信息和欺诈等滥用风险。尽管已有许多开源伪造音频检测代码，但大多数针对特定竞赛、数据集或模型，缺乏支持公平基准测试和比较的标准化统一工具包。

Method: 提出WeDefense工具包，支持伪造音频检测和定位。除了模型训练外，强调关键但常被忽视的组件：灵活的输入和增强、校准、分数融合、标准化评估指标，以及用于深入理解和解释的分析工具。

Result: 开发了首个开源工具包WeDefense，支持伪造音频检测和定位，提供交互式演示，代码已在GitHub公开可用。

Conclusion: WeDefense填补了伪造音频检测领域缺乏标准化统一工具包的空白，为研究人员提供了公平基准测试和比较的平台，有助于推动该领域的发展。

Abstract: The advances in generative AI have enabled the creation of synthetic audio which is perceptually indistinguishable from real, genuine audio. Although this stellar progress enables many positive applications, it also raises risks of misuse, such as for impersonation, disinformation and fraud. Despite a growing number of open-source fake audio detection codes released through numerous challenges and initiatives, most are tailored to specific competitions, datasets or models. A standardized and unified toolkit that supports the fair benchmarking and comparison of competing solutions with not just common databases, protocols, metrics, but also a shared codebase, is missing. To address this, we propose WeDefense, the first open-source toolkit to support both fake audio detection and localization. Beyond model training, WeDefense emphasizes critical yet often overlooked components: flexible input and augmentation, calibration, score fusion, standardized evaluation metrics, and analysis tools for deeper understanding and interpretation. The toolkit is publicly available at https://github.com/zlin0/wedefense with interactive demos for fake audio detection and localization.

</details>

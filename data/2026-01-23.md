<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 19]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SD](#cs.SD) [Total: 10]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [ISAC-over-NTN: HAPS-UAV Framework for Post-Disaster Responsive 6G Networks](https://arxiv.org/abs/2601.15422)
*Berk Ciloglu,Ozgun Ersoy,Metin Ozturk,Ali Gorcin*

Main category: eess.SP

TL;DR: 该论文提出了一种基于非地面网络的集成感知与通信架构（ISAC-over-NTN），利用无人机和高空平台站在灾后场景中同时提供可靠通信和用户检测功能。


<details>
  <summary>Details</summary>
Motivation: 在灾难场景中，地面网络可能部分或完全崩溃，导致通信中断和态势感知困难。需要一种能够在灾后条件下维持网络运行并检测被困人员的解决方案。

Method: 提出ISAC-over-NTN架构，整合多个无人机和高空平台站。采用创新的波束成形方法，将多用户MIMO通信和单基地感知集成在同一传输链中，同时传输数据并通过多普勒模型检测用户移动性。

Result: 该框架能够维持可靠的连接性，并在关键位置实现高精度的用户检测，达到90%的运动检测灵敏度和88%的检测准确率。

Conclusion: ISAC-over-NTN架构能够在灾后场景中有效提供通信基础设施和用户检测功能，支持搜救行动和人员连接，具有实际应用价值。

Abstract: In disaster scenarios, ensuring both reliable communication and situational awareness becomes a critical challenge due to the partial or complete collapse of terrestrial networks. This paper proposes an integrated sensing and communication (ISAC) over non-terrestrial networks (NTN) architecture referred to as ISAC-over-NTN that integrates multiple uncrewed aerial vehicles (UAVs) and a high-altitude platform station (HAPS) to maintain resilient and reliable network operations in post-disaster conditions. We aim to achieve two main objectives: i) provide a reliable communication infrastructure, thereby ensuring the continuity of search-and-rescue activities and connecting people to their loved ones, and ii) detect users, such as those trapped under rubble or those who are mobile, using a Doppler-based mobility detection model. We employ an innovative beamforming method that simultaneously transmits data and detects Doppler-based mobility by integrating multi-user multiple-input multiple-output (MU-MIMO) communication and monostatic sensing within the same transmission chain. The results show that the proposed framework maintains reliable connectivity and achieves high detection accuracy of users in critical locations, reaching 90% motion detection sensitivity and 88% detection accuracy.

</details>


### [2] [Achievable Rate Optimization for Large Flexible Intelligent Metasurface Assisted Downlink MISO under Statistical CSI](https://arxiv.org/abs/2601.15471)
*Ling He,Vaibhav Kumar,Anastasios Papazafeiropoulos,Miaowen Wen,Le-Nam Tran,Marwa Chafii*

Main category: eess.SP

TL;DR: 提出基于统计CSI的柔性智能超表面辅助MISO系统优化框架，通过联合优化功率分配和超表面形变最大化平均可达和速率，相比传统刚性天线阵列有显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有柔性智能超表面辅助系统设计通常假设完美的瞬时信道状态信息，这在大规模网络中不切实际，因为需要高训练开销和复杂的信道估计。需要克服这一限制。

Method: 提出基于统计CSI的鲁棒优化框架，用于下行MISO系统。开发基于块坐标上升的迭代算法，联合优化功率分配和柔性智能超表面形变。

Result: 仿真结果表明，所提出的统计CSI驱动的柔性智能超表面设计显著优于传统刚性天线阵列，验证了其有效性和实用性。

Conclusion: 基于统计CSI的柔性智能超表面优化框架为大规模网络提供了实用且有效的解决方案，避免了瞬时CSI假设的不切实际性。

Abstract: The integration of electromagnetic metasurfaces into wireless communications enables intelligent control of the propagation environment. Recently, flexible intelligent metasurfaces (FIMs) have evolved beyond conventional reconfigurable intelligent surfaces (RISs), enabling three-dimensional surface deformation for adaptive wave manipulation. However, most existing FIM-aided system designs assume perfect instantaneous channel state information (CSI), which is impractical in large-scale networks due to the high training overhead and complicated channel estimation. To overcome this limitation, we propose a robust statistical-CSI-based optimization framework for downlink multiple-input single-output (MISO) systems with FIM-assisted transmitters. A block coordinate ascent (BCA)-based iterative algorithm is developed to jointly optimize power allocation and FIM morphing, maximizing the average achievable sum rate. Simulation results show that the proposed statistical-CSI-driven FIM design significantly outperforms conventional rigid antenna arrays (RAAs), validating its effectiveness and practicality.

</details>


### [3] [Applicability and Limitation Analysis of PMU Data and Phasor Concept for Low- and High- Frequency Oscillations](https://arxiv.org/abs/2601.15529)
*Bowen Ou,Bin Wang,Slava Maslennikov,Hanchao Liu,Jim Follum*

Main category: eess.SP

TL;DR: 论文分析了PMU在表示高频振荡信号时的局限性，提出了更通用的信号模型和多步估计方法，揭示了相量概念在高频振荡下的失效问题。


<details>
  <summary>Details</summary>
Motivation: PMU将高速波形数据转换为低速相量数据，广泛应用于电力系统广域监测与控制，特别是振荡检测和定位。然而，PMU相量仅对低频振荡有效，本文旨在探究这种局限性的根本原因。

Method: 提出更通用的信号模型，采用多步估计方法，结合单周期DFT、矩阵铅笔法和最小二乘法，以更好地表示和估计含振荡的波形信号。

Result: 数值实验证明所提信号模型和估计方法的优越性能。研究发现，对于具有不对称次同步和超同步分量的高频振荡信号，不仅PMU相量，甚至相量概念本身都可能失效。

Conclusion: 研究揭示了PMU数据和相量概念的基本局限性，强调在现代电力系统分析高频振荡时需要依赖波形数据而非相量数据。

Abstract: Phasor Measurement Units (PMUs) convert high-speed waveform data into low-speed phasor data, which are fundamental to wide-area monitoring and control in power systems, with oscillation detection and localization among their most prominent applications. However, representing electrical waveform signals with oscillations using PMU phasors is effective only for low-frequency oscillations. This paper investigates the root causes of this limitation, focusing on errors introduced by Discrete Fourier Transform (DFT)-based signal processing, in addition to the attenuation effects of anti-aliasing filters, and the impact of low reporting rates. To better represent and estimate waveform signals with oscillations, we propose a more general signal model and a multi-step estimation method that leverages one-cycle DFT, the Matrix Pencil Method, and the Least Squares Method. Numerical experiments demonstrate the superior performance of the proposed signal model and estimation method. Furthermore, this paper reveals that the phasor concept, let alone PMU phasors, can become invalid for waveform signals with high-frequency oscillations characterized by asymmetric sub- and super-synchronous components. These findings highlight the fundamental limitations of PMU data and phasor concept, and emphasize the need to rely on waveform data for analyzing high-frequency oscillations in modern power systems.

</details>


### [4] [Distributed Uplink Anti-Jamming in LEO Mega-Constellations via Game-Theoretic Beamforming](https://arxiv.org/abs/2601.15557)
*Shizhen Jia,Mingjun Ying,Marco Mezzavilla,Theodore S. Rappaport,Sundeep Rangan*

Main category: eess.SP

TL;DR: 本文提出一种分布式多卫星抗干扰策略，利用LEO巨型星座的密集连接和高速星间链路，通过凸凹博弈建模和高效求解器，显著提升卫星网络在强干扰下的抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: LEO卫星星座在轨道动力学和几何位置上的可预测性使其易受地面干扰，传统单卫星干扰抑制技术难以在空间上分离期望信号和附近干扰源，需要新的抗干扰方法。

Method: 将上行链路干扰场景建模为期望地面发射机与干扰机之间的凸凹博弈，双方优化空间协方差矩阵以最大化或最小化可达速率；提出结合交替最佳响应更新和投影梯度下降的高效min-max求解器，快速收敛到纳什均衡。

Result: 使用真实的Starlink轨道几何和Sionna射线追踪仿真表明，近距离干扰机可严重破坏单卫星链路，而分布式卫星协作显著增强抗干扰能力，在强干扰下将容量分布向上移动。

Conclusion: 分布式多卫星抗干扰策略利用现代LEO巨型星座的密集连接特性，通过博弈论框架和高效求解算法，有效提升了卫星网络对地面干扰的抵御能力。

Abstract: Low-Earth-Orbit (LEO) satellite constellations have become vital in emerging commercial and defense Non-Terrestrial Networks (NTNs). However, their predictable orbital dynamics and exposed geometries make them highly susceptible to ground-based jamming. Traditional single-satellite interference mitigation techniques struggle to spatially separate desired uplink signals from nearby jammers, even with large antenna arrays. This paper explores a distributed multi-satellite anti-jamming strategy leveraging the dense connectivity and high-speed inter-satellite links of modern LEO mega-constellations. We model the uplink interference scenario as a convex-concave game between a desired terrestrial transmitter and a jammer, each optimizing their spatial covariance matrices to maximize or minimize achievable rate. We propose an efficient min-max solver combining alternating best-response updates with projected gradient descent, achieving fast convergence of the beamforming strategy to the Nash equilibrium. Using realistic Starlink orbital geometries and Sionna ray-tracing simulations, we demonstrate that while close-proximity jammers can cripple single-satellite links, distributed satellite cooperation significantly enhances resilience, shifting the capacity distribution upward under strong interference.

</details>


### [5] [An Iterated Hybrid Fast Parallel FIR Filter](https://arxiv.org/abs/2601.15582)
*Keshab K. Parhi*

Main category: eess.SP

TL;DR: 提出一种新型迭代快速并行FIR滤波器——快速混合滤波器，通过在不同层采用不同结构的2-并行快速FIR滤波器，相比现有方法减少了加法运算数量。


<details>
  <summary>Details</summary>
Motivation: 并行FIR滤波通过同时处理多个输入样本来提高数字信号处理的计算效率和吞吐量。现有方法使用相同原始滤波器（如2-并行）迭代设计快速并行滤波器，但仍有优化空间。

Method: 提出快速混合滤波器，在所有内层迭代转置2-并行快速FIR滤波器，在最外层使用直接形式2-并行快速FIR滤波器，从而降低硬件复杂度。

Result: 混合快速并行滤波器相比先前方法需要更少的加法运算，实现了硬件复杂度的降低。

Conclusion: 这种迭代混合方法首次提出，通过在不同层采用不同滤波器结构，有效减少了并行FIR滤波器的计算复杂度。

Abstract: This paper revisits the design and optimization of parallel fast finite impulse response (FIR) filters using polyphase decomposition and iterated fast FIR algorithms (FFAs). Parallel FIR filtering enhances computational efficiency and throughput in digital signal processing (DSP) applications by enabling the simultaneous processing of multiple input samples. We revisit a prior approach to design of fast parallel filter architectures by using the iterated FFA approach where the same primitive filter, such as 2-parallel, is iterated to design the fast parallel filter. In this paper, we present yet another novel iterated fast parallel FIR filter, referred to as the fast hybrid filter. The hybrid filter iterates a transposed 2-parallel fast FIR filter in all the inner layers and a direct-form 2-parallel fast FIR filter in the outermost layer, resulting in reduced hardware complexity. Such an iterated hybrid approach has not been presented before. We show that the hybrid fast parallel filters require less number of additions compared to prior approaches.

</details>


### [6] [Amalgamated CHIRP and OFDM for ISAC](https://arxiv.org/abs/2601.15584)
*Pankaj Kumar,Mohammed El-Hajjar,Ibrahim A. Hemadeh,Yasser Mestrah,Suraj Srivastava,Aditya K. Jagannatham,Lajos Hanzo*

Main category: eess.SP

TL;DR: 提出一种结合OFDM和chirp波形的新型ISAC波形，通过仿射加法降低PAPR，利用chirp进行感知而不占用通信资源，提升通信和感知性能。


<details>
  <summary>Details</summary>
Motivation: ISAC需要能同时高效支持通信和感知的波形。传统OFDM用于感知需要分配资源，这会降低通信性能，且OFDM存在高PAPR问题。

Method: 提出OFDM与chirp波形的仿射融合架构，在传统通信框架基础上利用接收端感知参数增强通信性能。采用时隙级chirp集成技术提升距离估计精度。

Result: 融合chirp的OFDM信号具有更好的自相关特性，改善距离和速度的RMSE，降低PAPR，实现近恒定包络波形，且感知不消耗通信资源。

Conclusion: 提出的仿射融合波形在ISAC框架中有效平衡了通信和感知性能，解决了传统OFDM的高PAPR问题，同时通过chirp波形实现高效感知。

Abstract: Integrated Sensing and Communication (ISAC) requires the development of a waveform capable of efficiently supporting both communication and sensing functionalities. This paper proposes a novel waveform that combines the benefits of both the orthogonal frequency division multiplexing (OFDM) and the chirp waveforms to improve both the communication and sensing performance within an ISAC framework. Hence, a new architecture is proposed that utilizes the conventional communication framework while leveraging the parameters sensed at the receiver (Rx) for enhancing the communication performance. We demonstrate that the affine addition of OFDM and chirp signals results in a near constant-envelope OFDM waveform, which effectively reduces the peak-to-average power ratio (PAPR), a key limitation of traditional OFDM systems. Using the OFDM framework for sensing in the conventional fashion requires the allocation of some resources for sensing, which in turn reduces communication performance. As a remedy, the proposed affine amalgam facilitates sensing through the chirp waveform without consuming communication resources, thereby preserving communication efficiency. Furthermore, a novel technique of integrating the chirp signal into the OFDM framework at the slot-level is proposed to enhance the accuracy of range estimation. The results show that the OFDM signal incorporated with chirp has better autocorrelation properties, improved root mean square error (RMSE) of range and velocity, and lower PAPR. Finally, we characterize the trade-off between communications and sensing performance.

</details>


### [7] [Does 6G Need a New Waveform: Comparing Zak-OTFS with CP-OFDM](https://arxiv.org/abs/2601.15602)
*Imran Ali Khan,Saif Khan Mohammed,Ronny Hadani,Ananthanarayanan Chockalingam,Robert Calderbank,Anton Monk,Shachar Kons,Shlomo Rakib,Yoav Hebron*

Main category: eess.SP

TL;DR: 本文全面比较了CP-OFDM和Zak-OTFS在6G传播环境下的性能，指出波形选择本质上是防止ICI与接受ICI的架构选择，Zak-OTFS在高延迟/多普勒扩展场景中表现更优。


<details>
  <summary>Details</summary>
Motivation: 随着全球对新波形特别是Zak-OTFS的兴趣增长，以及空中实现的开始出现，需要在OFDM和Zak-OTFS之间做出选择。这种选择本质上是防止载波间干扰（ICI）与接受ICI的架构选择，而Zak-OTFS在6G高移动性和大蜂窝场景中表现出优势。

Method: 本文对循环前缀OFDM（CP-OFDM）和Zak-OTFS在完整的6G传播环境范围内进行了全面的性能比较分析。

Result: 性能结果表明，Zak-OTFS在双扩展的6G使用场景中（高延迟/多普勒信道扩展，即高移动性和/或大蜂窝）表现出优越性能。架构选择取决于典型使用场景，而典型场景在一定程度上取决于地理因素，因为大延迟扩展是大蜂窝的特征，在许多重要无线市场中是常态而非例外。

Conclusion: 波形选择本质上是架构选择：OFDM防止ICI但难以处理ICI，Zak-OTFS接受ISI但I/O关系可预测。Zak-OTFS在6G高移动性/大蜂窝场景中具有优势，选择应根据具体使用场景和地理环境决定。

Abstract: Across the world, there is growing interest in new waveforms, Zak-OTFS in particular, and over-the-air implementations are starting to appear. The choice between OFDM and Zak-OTFS is not so much a choice between waveforms as it is an architectural choice between preventing inter-carrier interference (ICI) and embracing ICI. In OFDM, once the Input-Output (I/O) relation is known, equalization is relatively simple, at least when there is no ICI. However, in the presence of ICI the I/O relation is non-predictable and its acquisition is non-trivial. In contrast, equalization is more involved in Zak-OTFS due to inter-symbol-interference (ISI), however the I/O relation is predictable and its acquisition is simple. {Zak-OTFS exhibits superior performance in doubly-spread 6G use cases with high delay/Doppler channel spreads (i.e., high mobility and/or large cells), but architectural choice is governed by the typical use case, today and in the future. What is typical depends to some degree on geography, since large delay spread is a characteristic of large cells which are the rule rather than the exception in many important wireless markets.} This paper provides a comprehensive performance comparison of cyclic prefix OFDM (CP-OFDM) and Zak-OTFS across the full range of 6G propagation environments. The performance results provide insights into the fundamental architectural choice.

</details>


### [8] [Bistatic ISAC: Practical Challenges and Solutions](https://arxiv.org/abs/2601.15733)
*Lucas Giroto,Marcus Henninger,Alexander Felix,Maximilian Bauhofer,Taewon Jeong,Umut Utku Erdem,Stephan ten Brink,Thomas Zwick,Benjamin Nuss,Silvio Mandelli*

Main category: eess.SP

TL;DR: 本文探讨了6G网络中双基地集成感知与通信的实际挑战与解决方案，重点关注OFDM波形下的系统设计、信号处理技术以及5G兼容参数下的仿真验证。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络的发展，集成感知与通信技术面临实际部署的挑战，特别是在双基地配置下需要同时满足感知性能指标并克服硬件损伤影响。

Method: 采用正交频分复用波形，设计系统以平衡感知性能指标和硬件损伤影响；开发空中同步信号处理技术，生成包含距离、多普勒频移和角度信息的周期图；基于5G兼容参数进行仿真验证。

Result: 提出了针对双基地ISAC的系统设计框架和信号处理技术，通过仿真验证了在5G兼容参数下的可行性，为实际部署提供了技术基础。

Conclusion: 本文为6G双基地ISAC的实际部署提供了解决方案，但仍存在开放挑战需要未来研究解决，特别是在实际网络环境中的性能优化和部署策略方面。

Abstract: This article presents and discusses challenges and solutions for practical issues in bistatic integrated sensing and communication (ISAC) in 6G networks. Considering orthogonal frequency-division multiplexing as the adopted waveform, a discussion on system design aiming to achieve both a desired sensing key performance indicators and limit the impact of hardware impairments is presented. In addition, signal processing techniques to enable over-the-air synchronization and generation of periodograms with range, Doppler shift, and angular information are discussed. Simulation results are then presented for a cellular-based ISAC scenario considering system parameterization compliant to current 5G and, finally, a discussion on open challenges for future deployments is presented.

</details>


### [9] [Joint Pilot and Unknown Data-based Localization for OFDM Opportunistic Radar Systems](https://arxiv.org/abs/2601.15785)
*Mathieu Reniers,Martin Willame,Jérôme Louveaux,Luc Vandendorpe*

Main category: eess.SP

TL;DR: 提出一种从通信数据载荷中提取定位信息的新方法，无需解码数据，利用FFT实现高效估计，定位性能优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有ISAC定位方法存在局限：要么仅使用已知导频信号而忽略数据载荷中的雷达信息，要么依赖数据解码导致定位性能受限于通信系统性能。需要一种能利用数据载荷定位信息但不依赖解码的方法。

Method: 提出新颖方法从数据载荷中提取定位信息而无需解码。考虑机会场景：用户通信信号被配备均匀线性阵列天线的机会雷达捕获。利用FFT高效实现估计。

Result: 通过数值仿真证明，该方法在定位性能上优于文献中的现有方法。

Conclusion: 该方法克服了现有ISAC定位方法的局限性，能够有效利用数据载荷中的雷达信息实现高性能定位，且与当前标准兼容，适用于6G和Wi-Fi 7网络。

Abstract: Integrated Sensing and Communications (ISAC) has emerged as a promising paradigm for Sixth Generation (6G) and Wi-Fi 7 networks, with the communication-centric approach being particularly attractive due to its compatibility with current standards. Typical communication signals comprise both deterministic known pilot signals and random unknown data payloads. Most existing approaches either rely solely on pilots for positioning, thereby ignoring the radar information present in the received data symbols that constitute the majority of each frame, or rely on data decisions, which bounds positioning performance to that of the communication system. To overcome these limitations, we propose a novel method that extracts positioning information from data payloads without decoding them. We consider an opportunistic scenario in which communication signals from a user are captured by an opportunistic radar equipped with a Uniform Linear Arrays of antennas. We show that, in this setting, the estimation can be efficiently implemented using Fast Fourier Transforms. Finally, we demonstrate superior localization performance compared to existing methods in the literature through numerical simulations.

</details>


### [10] [Adaptive Non-Uniform Sampling of Bandlimited Signals via Algorithm-Encoder Co-Design](https://arxiv.org/abs/2601.15790)
*Kaluguri Yashaswini,Anshu Arora,Satish Mulleti*

Main category: eess.SP

TL;DR: 提出基于算法-编码器协同设计的自适应非均匀采样框架，通过局部能量条件允许在信号变化缓慢区域稀疏采样，在快速变化区域密集采样，显著降低采样密度。


<details>
  <summary>Details</summary>
Motivation: 传统非均匀采样方法通常对采样间隔施加全局Nyquist型约束，导致在信号变化缓慢区域过度采样。本文旨在开发一种自适应采样框架，能够根据信号局部特性动态调整采样密度，在保证重建精度的同时显著降低总体采样率。

Method: 1) 从迭代重建算法的收敛分析出发，推导出基于信号和导数能量的局部充分条件；2) 设计可变偏置、可变阈值的积分-发放时间编码机(VBT-IF-TEM)，其发放机制专门用于满足局部收敛条件；3) 引入移位信号公式抑制信号幅度接近零区域的过度发放；4) 使用时间编码和信号平均值离散表示模拟信号，通过标准迭代算法实现完美重建。

Result: 在合成信号、超声导波和ECG信号上的仿真和实验表明：相比均匀采样和传统IF-TEM，所提框架显著降低采样密度，同时保持准确重建。结果还展示了采样密度、重建精度和收敛行为之间的可控权衡，可通过自适应参数选择进行调节。

Conclusion: 提出的算法-编码器协同设计框架实现了自适应非均匀采样，通过局部能量条件允许在信号变化缓慢区域稀疏采样，在快速变化区域密集采样，显著降低总体采样率，同时保证重建精度，为高效信号采集提供了新途径。

Abstract: We propose an adaptive non-uniform sampling framework for bandlimited signals based on an algorithm-encoder co-design perspective. By revisiting the convergence analysis of iterative reconstruction algorithms for non-uniform measurements, we derive a local, energy-based sufficient condition that governs reconstruction behavior as a function of the signal and derivative energies within each sampling interval. Unlike classical approaches that impose a global Nyquist-type bound on the inter-sample spacing, the proposed condition permits large gaps in slowly varying regions while enforcing denser sampling only where the signal exhibits rapid temporal variation. Building on this theoretical insight, we design a variable-bias, variable-threshold integrate-and-fire time encoding machine (VBT-IF-TEM) whose firing mechanism is explicitly shaped to enforce the derived local convergence condition. To ensure robustness, a shifted-signal formulation is introduced to suppress excessive firing in regions where the magnitude of the signal amplitude is close to zero or the local signal energy approaches zero. Using the proposed encoder, an analog signal is discretely represented by time encodings and signal averages, enabling perfect reconstruction via a standard iterative algorithm even when the local sampling rate falls below the Nyquist rate. Simulation results on synthetic signals and experiments on ultrasonic guided-wave and ECG signals demonstrate that the proposed framework achieves substantial reductions in sampling density compared to uniform sampling and conventional IF-TEMs, while maintaining accurate reconstruction. The results further highlight a controllable tradeoff between sampling density, reconstruction accuracy, and convergence behavior, which can be navigated through adaptive parameter selection.

</details>


### [11] [Dual-Mapping Sparse Vector Transmission for Short Packet URLLC](https://arxiv.org/abs/2601.15819)
*Yanfeng Zhang,Xu Zhu,Jinkai Zheng,Weiwei Yang,Xianhua Yu,Haiyong Zeng,Yujie Liu,Yong Liang Guan*

Main category: eess.SP

TL;DR: 提出了一种双映射稀疏向量编码方案，通过块稀疏映射和单元素稀疏映射相结合的方式，在保持码长不显著增加的同时提高解码精度，从而提升短包传输性能。


<details>
  <summary>Details</summary>
Motivation: 稀疏向量编码是下一代通信系统中超可靠低延迟通信的有前景的短包传输方法，但现有方案在传输性能方面仍有提升空间，需要进一步提高解码精度和频谱效率。

Method: 提出双映射稀疏向量编码方案，将传输信息比特通过块稀疏映射和单元素稀疏映射两种模式映射到稀疏向量。块稀疏映射将发射功率集中在少量非零块以提高解码精度，单元素稀疏映射确保码长不会随信息比特数急剧增加。接收端采用两阶段解码算法，依次识别非零块索引和单元素非零索引。

Result: 广泛的仿真结果表明，所提出的DM-SVC方案在块错误率和频谱效率方面均优于现有的SVC方案。

Conclusion: 双映射稀疏向量编码方案通过结合两种映射模式的优点，有效提升了短包传输性能，为下一代通信系统中的超可靠低延迟通信提供了更优的解决方案。

Abstract: Sparse vector coding (SVC) is a promising short-packet transmission method for ultra reliable low latency communication (URLLC) in next generation communication systems. In this paper, a dual-mapping SVC (DM-SVC) based short packet transmission scheme is proposed to further enhance the transmission performance of SVC. The core idea behind the proposed scheme lies in mapping the transmitted information bits onto sparse vectors via block and single-element sparse mappings. The block sparse mapping pattern is able to concentrate the transmit power in a small number of non-zero blocks thus improving the decoding accuracy, while the single-element sparse mapping pattern ensures that the code length does not increase dramatically with the number of transmitted information bits. At the receiver, a two-stage decoding algorithm is proposed to sequentially identify non-zero block indexes and single-element non-zero indexes. Extensive simulation results verify that proposed DM-SVC scheme outperforms the existing SVC schemes in terms of block error rate and spectral efficiency.

</details>


### [12] [Separable Delay And Doppler Estimation In Passive Radar](https://arxiv.org/abs/2601.15821)
*Mats Viberg,Daniele Gerosa,Tomas McKelvey,Patrik Dammert,Thomas Eriksson*

Main category: eess.SP

TL;DR: 提出一种用于被动雷达的可分离参数估计方法，将时延和多普勒参数分开估计，避免昂贵的二维搜索，降低计算复杂度和通信开销。


<details>
  <summary>Details</summary>
Motivation: 被动雷达系统中，分布式传感器利用机会照射源信号检测和定位目标。传统方法需要联合估计目标的时延和多普勒参数，这需要进行二维搜索，计算成本高且通信开销大。

Method: 提出可分离估计方法：首先单独估计时延参数（避免二维搜索），然后基于已知时延恢复批次间的相干性来估计多普勒参数。该方法针对慢速移动目标设计。

Result: 时延估计精度与全批次二维方法相当，多普勒参数估计在广泛参数范围内优于传统方法。同时显著降低了计算复杂度和分布式雷达设置中的通信开销。

Conclusion: 提出的可分离参数估计方法为被动雷达提供了一种高效解决方案，在保持时延估计精度的同时，提高了多普勒估计性能，并大幅降低了计算和通信成本。

Abstract: In passive radar, a network of distributed sensors exploit signals from so-called Illuminators-of-Opportunity to detect and localize targets. We consider the case where the IO signal is available at each receiver node through a reference channel, whereas target returns corrupted by interference are collected in a separate surveillance channel. The problem formulation is similar to an active radar that uses a noise-like waveform, or an integrated sensing and communication application. The available data is first split into batches of manageable size. In the direct approach, the target's time-delay and Doppler parameters are estimated jointly by incoherently combining the batch-wise data. We propose a new method to estimate the time-delay separately, thus avoiding a costly 2-D search. Our approach is designed for slowly moving targets, and the accuracy of the time-delay estimate is similar to that of the full batch-wise 2-D method. Given the time-delay, the coherency between batches can be restored when estimating the Doppler parameter. Thereby, the separable approach is found to yield superior Doppler estimates over a wide parameter range. In addition to reducing computational complexity, the proposed separable estimation technique also significantly reduces the communication overhead in a distributed radar setting.

</details>


### [13] [Performance Analysis of Digital Beamforming mmWave MIMO with Low-Resolution DACs/ADCs](https://arxiv.org/abs/2601.15831)
*Faruk Pasic,Mariam Mussbah,Stefan Schwarz,Markus Rupp,Fredrik Tufvesson,Christoph F. Mecklenbräuker*

Main category: eess.SP

TL;DR: 毫米波MIMO系统采用全数字波束成形和低分辨率量化，4位DAC/ADC在能耗和速率间提供最佳权衡


<details>
  <summary>Details</summary>
Motivation: 未来无线通信需要毫米波MIMO波束成形来提供高数据速率。全数字毫米波MIMO需要精确信道估计，但为了保持功率效率必须使用低分辨率DAC/ADC，这些量化器会引入失真并降低系统性能。

Method: 研究毫米波MIMO系统在全数字波束成形和低分辨率量化下的信道估计性能，考虑实际系统约束，评估频谱效率和能量效率。

Result: 仿真结果表明，每个DAC/ADC采用4位中等量化分辨率在能耗和可实现数据速率之间提供了有利的权衡。

Conclusion: 在毫米波MIMO全数字波束成形系统中，4位量化分辨率是实现功率效率和性能平衡的合理选择。

Abstract: Future wireless communications will rely on multiple-input multiple-output (MIMO) beamforming operating at millimeter wave (mmWave) frequency bands to deliver high data rates. To support flexible spatial processing and meet the demands of latency critical applications, it is essential to use fully digital mmWave MIMO beamforming, which relies on accurate channel estimation. However, ensuring power efficiency in fully digital mmWave MIMO systems requires the use of low-resolution digital-to-analog converters (DACs) and analog-to-digital converters (ADCs). The reduced resolution of these quantizers introduces distortion in both transmitted and received signals, ultimately degrading system performance. In this paper, we investigate the channel estimation performance of mmWave MIMO systems employing fully digital beamforming with low-resolution quantization, under practical system constraints. We evaluate the system performance in terms of spectral efficiency (SE) and energy efficiency (EE). Simulation results demonstrate that a moderate quantization resolutions of 4-bit per DAC/ADC offers a favorable trade-off between energy consumption and achievable data rate.

</details>


### [14] [Time-Varying Rician K-factor in Measured Vehicular Channels at cmWave and mmWave Bands](https://arxiv.org/abs/2601.15863)
*Faruk Pasic,Markus Hofer,Thomas Zemen,Andreas F. Molisch,Christoph F. Mecklenbräuker*

Main category: eess.SP

TL;DR: 分析V2I信道在毫米波与厘米波频段的时变莱斯K因子，发现不同频段的K因子相似且与RMS时延扩展相关


<details>
  <summary>Details</summary>
Motivation: 未来车载通信系统将集成毫米波技术以提高数据传输速率，需要研究毫米波与传统厘米波频段的传播效应和小尺度衰落差异，特别是表征小尺度衰落的关键参数莱斯K因子

Method: 在城市街道环境中进行多频段V2I信道测量，分析三个中心频率（3.2 GHz、34.3 GHz、62.35 GHz）的时变K因子，带宽155.5 MHz，探测重复率31.25 μs，并研究K因子与RMS时延扩展的关系

Result: 不同频段的莱斯K因子相似，且与RMS时延扩展存在相关性

Conclusion: 毫米波和厘米波频段的V2I信道在小尺度衰落特性上具有相似性，K因子与时延扩展的关联为信道建模提供了重要参考

Abstract: Future vehicular communication systems will integrate millimeter wave (mmWave) technology to enhance data transmission rates. To investigate the propagation effects and small-scale fading differences between mmWave and conventional centimeter wave (cmWave) bands, multi-band channel measurements have to be conducted. One key parameter to characterize small-scale fading is the Rician K-factor. In this paper, we analyze the time-varying K-factor of vehicle-to-infrastructure (V2I) channels across multiple frequency bands, measured in an urban street environment. Specifically, we investigate three frequency bands with center frequencies of 3.2 GHz, 34.3 GHz and 62.35 GHz using measurement data with 155.5 MHz bandwidth and a sounding repetition rate of 31.25 μs. Furthermore, we analyze the relationship between K-factor and root-mean-square (RMS) delay spread. We show that the Ricean K-factor is similar at different frequency bands and that is correlated with the RMS delay spread.

</details>


### [15] [Reconstructing Patched or Partial Holograms to allow for Whole Slide Imaging with a Self-Referencing Holographic Microscope](https://arxiv.org/abs/2601.15952)
*Philip Groult,Julia D. Sistermanns,Ellen Emken,Oliver Hayden,Wolfgang Utschick*

Main category: eess.SP

TL;DR: 提出一种用于宫颈涂片全玻片成像的重建算法，通过自参考三波数字全息显微镜实现，算法具有适应性，可用于部分全息图和拼接全息图。


<details>
  <summary>Details</summary>
Motivation: WSI和QPI两种成像技术尚未结合，QPI能捕获更丰富的细胞信息且样本制备简单，但尚未应用于全玻片成像。需要开发算法将QPI技术扩展到宫颈涂片的WSI应用。

Method: 使用自参考三波数字全息显微镜，开发自适应重建算法，能够处理单次拍摄的全息图、部分全息图和拼接全息图，构建完整的全玻片图像。

Result: 算法在测试的上皮细胞上表现良好，成功实现了宫颈涂片的全玻片成像，将QPI技术扩展到WSI应用。

Conclusion: 首次将QPI与WSI技术结合，为宫颈细胞学筛查提供了新的计算机辅助诊断工具，算法具有灵活性和适应性，有望改善细胞学筛查的效率和准确性。

Abstract: The last decade has seen significant advances in computer-aided diagnostics for cytological screening, mainly through the improvement and integration of scanning techniques such as whole slide imaging (WSI) and the combination with deep learning. Simultaneously, new imaging techniques such as quantitative phase imaging (QPI) are being developed to capture richer cell information with less sample preparation. So far, the two worlds of WSI and QPI have not been combined. In this work, we present a reconstruction algorithm which makes whole slide imaging of cervical smears possible by using a self-referencing three-wave digital holographic microscope. Since a WSI is constructed by combining multiple patches, the algorithm is adaptive and can be used on partial holograms and patched holograms. We present the algorithm for a single shot hologram, the adaptations to make it flexible to various inputs and show that the algorithm performs well for the tested epithelial cells. This is a preprint of our paper, which has been accepted for publication in 2026 IEEE International Symposium on Biomedical Imaging (ISBI).

</details>


### [16] [Performance Scaling Laws for PD Array-based Receivers in IM/DD Optical Wireless Communication Systems](https://arxiv.org/abs/2601.15973)
*Aravindh Krishnamoorthy,Robert Schober,Harald Haas*

Main category: eess.SP

TL;DR: PD阵列接收机性能分析：研究光电探测器阵列在强度调制直接检测系统中的性能缩放规律，发现阵列仅在窄光束和高于SNR阈值时提供性能增益，单纯增加PD数量无效，需要联合优化光束模式、接收功率和PD位置。


<details>
  <summary>Details</summary>
Motivation: 研究光电探测器阵列接收机在强度调制直接检测系统中的性能缩放规律，为下一代高带宽PD阵列接收机设计提供理论指导和实用准则。

Method: 通过分析模型和数值模拟，比较PD阵列系统与单PD参考接收机在信噪比和可达速率方面的性能，考虑光功率与电功率之间的平方律关系。

Result: PD阵列仅在足够窄的光束和高于SNR阈值时提供性能增益；单纯增加PD数量不会提升性能；需要联合优化光束模式、横向电磁模式、接收功率和PD位置。

Conclusion: PD阵列接收机设计需要综合考虑多个参数优化，不能仅靠增加探测器数量；研究结果为下一代高带宽PD阵列接收机设计提供了实用的设计准则和权衡考虑。

Abstract: We study the performance scaling laws for electrical-domain combining in photodetector (PD) array-based receivers employing intensity modulation and direct detection, taking into account the inherent square-law relationship between the optical and electrical received powers. The performance of PD array-based systems is compared, in terms of signal-to-noise ratio (SNR) and achievable rate, to that of a reference receiver employing a single PD. Analytical and numerical results show that PD arrays provide performance gains for sufficiently narrow beams and above an SNR threshold. Furthermore, increasing the number of PDs alone does not enhance performance, and joint optimization of beam pattern, transverse electromagnetic mode, received power, and PD positions is necessary. Our model and derived insights provide practical guidelines and highlight the trade-offs for the design of next-generation high-bandwidth PD array receivers.

</details>


### [17] [Graph Topology Identification Based on Covariance Matching](https://arxiv.org/abs/2601.15999)
*Yongsheng Han,Raj Thilak Rajan,Geert Leus*

Main category: eess.SP

TL;DR: 提出CovMatch框架，通过匹配经验协方差与图理论协方差来识别图拓扑，无需传统方法的限制性假设，能处理有向/无向、有环/无环图。


<details>
  <summary>Details</summary>
Motivation: 传统图拓扑识别方法依赖概率模型或复杂优化，常面临非凸性、需要无环或正权重等限制性假设。需要一种更通用、假设更少的方法。

Method: 提出协方差匹配(CovMatch)框架：直接对齐观测数据的经验协方差与底层图隐含的理论协方差。通过重新参数化，将图学习问题简化为锥混合整数规划（无向图）或正交矩阵优化（有向图）。

Result: 数值实验表明，即使对于较大图，该方法能高效恢复真实拓扑，在准确性上优于标准基线方法。

Conclusion: CovMatch是图拓扑识别的强大替代方案，为学习复杂网络拓扑开辟了新途径，仅需数据生成过程允许显式协方差表达式这一最小假设。

Abstract: Graph topology identification (GTI) is a central challenge in networked systems, where the underlying structure is often hidden, yet nodal data are available. Conventional solutions to address these challenges rely on probabilistic models or complex optimization formulations, commonly suffering from non-convexity or requiring restrictive assumptions on acyclicity or positivity. In this paper, we propose a novel covariance matching (CovMatch) framework that directly aligns the empirical covariance of the observed data with the theoretical covariance implied by an underlying graph. We show that as long as the data-generating process permits an explicit covariance expression, CovMatch offers a unified route to topology inference.
  We showcase our methodology on linear structural equation models (SEMs), showing that CovMatch naturally handles both undirected and general sparse directed graphs - whether acyclic or positively weighted - without explicit knowledge of these structural constraints. Through appropriate reparameterizations, CovMatch simplifies the graph learning problem to either a conic mixed integer program for undirected graphs or an orthogonal matrix optimization for directed graphs. Numerical results confirm that, even for relatively large graphs, our approach efficiently recovers the true topology and outperforms standard baselines in accuracy. These findings highlight CovMatch as a powerful alternative to log-determinant or Bayesian methods for GTI, paving the way for broader research on learning complex network topologies with minimal assumptions.

</details>


### [18] [Low-Complexity Sparse Superimposed Coding for Ultra Reliable Low Latency Communications](https://arxiv.org/abs/2601.16012)
*Yanfeng Zhang,Xi'an Fan,Xu Zhu,Jinkai Zheng,Hui Liang,Weiwei Yang,Tom H. Luan*

Main category: eess.SP

TL;DR: 提出一种低复杂度稀疏叠加编码方案，通过设计稀疏码本结构降低编码解码复杂度，在BLER性能和计算复杂度之间取得良好平衡


<details>
  <summary>Details</summary>
Motivation: 稀疏叠加编码在超可靠低延迟通信中很有前景，但传统SSC方案使用密集码本矩阵导致编码解码复杂度很高，需要降低复杂度

Method: 设计稀疏码本结构，每个码字只包含少量非零元素，使用传统多径匹配追踪算法进行解码，利用码本稀疏性显著降低整体复杂度

Result: 仿真结果显示，该方案在BLER性能和计算复杂度之间取得良好平衡，在不同传输块长度下表现出强鲁棒性

Conclusion: 提出的低复杂度SSC方案通过稀疏码本设计有效降低了传统SSC的高复杂度问题，为短包传输提供了实用的解决方案

Abstract: Sparse superimposed coding (SSC) has emerged as a promising technique for short-packet transmission in ultra-reliable low-latency communication scenarios. However, conventional SSC schemes often suffer from high encoding and decoding complexity due to the use of dense codebook matrices. In this paper, we propose a low-complexity SSC scheme by designing a sparse codebook structure, where each codeword contains only a small number of non-zero elements. The decoding is performed using the traditional multipath matching pursuit algorithm, and the overall complexity is significantly reduced by exploiting the sparsity of the codebook. Simulation results show that the proposed scheme achieves a favorable trade-off between BLER performance and computational complexity, and exhibits strong robustness across different transmission block lengths.

</details>


### [19] [Hybrid Channel Estimation with Quantized Phase Feedback for Over-the-Air Computation](https://arxiv.org/abs/2601.16054)
*Martin Dahl,Erik G. Larsson*

Main category: eess.SP

TL;DR: 提出混合信道估计方案，结合互易性和反馈机制，降低空中计算的信令开销，重点研究量化相位反馈的影响


<details>
  <summary>Details</summary>
Motivation: 为了降低空中计算（over-the-air computation）的信令开销，需要设计更高效的信道估计方案。传统方法可能产生过多信令，影响系统效率

Method: 提出混合信道估计方案，结合互易性估计和反馈估计。假设幅度精确已知，重点研究量化相位反馈的影响。提出两种变体：第一种仅通过反馈估计相位，第二种通过互易性估计相位并采用最优量化相位反馈

Result: 通过仿真和理论分析表明，第二种变体（互易性估计相位+最优量化相位反馈）在性能上优于第一种变体（仅通过反馈估计相位）。该方案允许根据重要性分别选择幅度和相位的估计精度

Conclusion: 混合信道估计方案能有效降低空中计算的信令开销，其中结合互易性相位估计和最优量化相位反馈的方案性能更优，为信道估计精度选择提供了灵活性

Abstract: To reduce the signaling overhead of over-the-air computation, a hybrid channel estimation scheme is proposed, where reciprocity-based and feedback-based channel estimation are combined. In particular, the impact of quantized phase-feedback is studied while the amplitude is assumed estimated exactly. The scheme enables selecting the estimation precision of amplitude and phase separately, depending on the importance of each. Two variants of the scheme are proposed: As shown through simulations and theory, the second variant with reciprocity-based estimation of the channel phase, and optimal quantization of phase feedback, can outperform the first variant estimating the phase by feedback only.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [20] [DynamicSound simulator for simulating moving sources and microphone arrays](https://arxiv.org/abs/2601.15433)
*Luca Barbisan,Marco Levorato,Fabrizio Riente*

Main category: eess.AS

TL;DR: DynamicSound是一个开源声学仿真框架，用于生成多通道音频，支持三维空间中连续移动的声源和任意配置的麦克风阵列，考虑了声音传播延迟、多普勒效应、距离衰减、空气吸收和一阶反射等物理效应。


<details>
  <summary>Details</summary>
Motivation: 现有声学仿真器大多针对室内环境设计，且仅限于静态声源，无法处理移动声源、移动麦克风或长距离传播场景。开发声音分类、检测和定位算法需要大量灵活且真实的音频数据，特别是利用现代机器学习和波束形成技术时。

Method: 提出DynamicSound开源框架，支持三维空间中连续移动的声源和任意配置的麦克风阵列。模型明确考虑了有限声音传播延迟、多普勒效应、距离相关衰减、空气吸收以及平面表面的一阶反射，生成时间一致的空间音频信号。

Result: 与现有开源工具的比较评估表明，生成的信号在不同声源位置和声学条件下保持了高空间保真度。该系统能够为任意数量的虚拟麦克风合成音频，准确再现麦克风间的时间延迟、电平差异和环境引起的频谱着色。

Conclusion: DynamicSound通过生成受控和可重复条件下的真实多通道音频，为现代空间音频和声源定位算法的开发、训练和评估提供了一个灵活且可复现的工具。

Abstract: Developing algorithms for sound classification, detection, and localization requires large amounts of flexible and realistic audio data, especially when leveraging modern machine learning and beamforming techniques. However, most existing acoustic simulators are tailored for indoor environments and are limited to static sound sources, making them unsuitable for scenarios involving moving sources, moving microphones, or long-distance propagation. This paper presents DynamicSound an open-source acoustic simulation framework for generating multichannel audio from one or more sound sources with the possibility to move them continuously in three-dimensional space and recorded by arbitrarily configured microphone arrays. The proposed model explicitly accounts for finite sound propagation delays, Doppler effects, distance-dependent attenuation, air absorption, and first-order reflections from planar surfaces, yielding temporally consistent spatial audio signals. Unlike conventional mono or stereo simulators, the proposed system synthesizes audio for an arbitrary number of virtual microphones, accurately reproducing inter-microphone time delays, level differences, and spectral coloration induced by the environment. Comparative evaluations with existing open-source tools demonstrate that the generated signals preserve high spatial fidelity across varying source positions and acoustic conditions. By enabling the generation of realistic multichannel audio under controlled and repeatable conditions, the proposed open framework provides a flexible and reproducible tool for the development, training, and evaluation of modern spatial audio and sound-source localization algorithms.

</details>


### [21] [Distributed Multichannel Active Noise Control with Asynchronous Communication](https://arxiv.org/abs/2601.15653)
*Junwei Ji,Dongyuan Shi,Boxiang Wang,Ziyi Yang,Haowen Li,Woon-Seng Gan*

Main category: eess.AS

TL;DR: 提出异步通信分布式多通道有源噪声控制系统，通过节点仅在性能下降时请求通信，显著降低通信开销，同时保持有效降噪效果。


<details>
  <summary>Details</summary>
Motivation: 传统分布式多通道有源噪声控制方法假设同步通信且需要频繁数据交换，导致高通信开销。为提高效率和适应性，需要设计更高效的通信策略。

Method: 采用异步通信策略，每个节点执行权重约束滤波-x LMS算法，仅在本地降噪性能下降时请求通信。其他节点传输本地控制滤波器与中心点的权重差异，用于更新控制滤波器和中心点。

Result: 仿真结果表明，提出的异步通信DMCANC系统在显著降低通信负载的同时保持有效降噪效果，提高了异构网络的可扩展性。

Conclusion: 异步通信策略使节点能够异步运行同时保持协作行为，为分布式有源噪声控制系统提供了更高效、适应性更强的解决方案。

Abstract: Distributed multichannel active noise control (DMCANC) offers effective noise reduction across large spatial areas by distributing the computational load of centralized control to multiple low-cost nodes. Conventional DMCANC methods, however, typically assume synchronous communication and require frequent data exchange, resulting in high communication overhead. To enhance efficiency and adaptability, this work proposes an asynchronous communication strategy where each node executes a weight-constrained filtered-x LMS (WCFxLMS) algorithm and independently requests communication only when its local noise reduction performance degrades. Upon request, other nodes transmit the weight difference between their local control filter and the center point in WCFxLMS, which are then integrated to update both the control filter and the center point. This design enables nodes to operate asynchronously while preserving cooperative behavior. Simulation results demonstrate that the proposed asynchronous communication DMCANC (ACDMCANC) system maintains effective noise reduction with significantly reduced communication load, offering improved scalability for heterogeneous networks.

</details>


### [22] [A Stabilized Hybrid Active Noise Control Algorithm of GFANC and FxNLMS with Online Clustering](https://arxiv.org/abs/2601.15889)
*Zhengding Luo,Haozhe Ma,Boxiang Wang,Ziyi Yang,Dongyuan Shi,Woon-Seng Gan*

Main category: eess.AS

TL;DR: 提出混合GFANC-FxNLMS算法，结合GFANC快速响应和FxNLMS低稳态误差优势，通过在线聚类避免不必要的重新初始化，实现快速响应、低稳态误差和高稳定性。


<details>
  <summary>Details</summary>
Motivation: FxNLMS算法收敛慢且有发散风险，但能达到低稳态误差；GFANC方法响应快但缺乏适应性，稳态误差大。需要结合两者优势，解决各自缺点。

Method: 提出混合GFANC-FxNLMS算法：GFANC提供帧级控制滤波器作为FxNLMS初始化，FxNLMS在采样率下连续自适应。引入在线聚类模块避免不必要的重新初始化，提高系统稳定性。

Result: 仿真结果显示，所提算法实现快速响应、极低稳态误差和高稳定性，仅需一个预训练的宽带滤波器。

Conclusion: 混合GFANC-FxNLMS算法成功结合了两种方法的互补优势，通过在线聚类机制解决了重新初始化问题，在主动噪声控制中表现出优越性能。

Abstract: The Filtered-x Normalized Least Mean Square (FxNLMS) algorithm suffers from slow convergence and a risk of divergence, although it can achieve low steady-state errors after sufficient adaptation. In contrast, the Generative Fixed-Filter Active Noise Control (GFANC) method offers fast response speed, but its lack of adaptability may lead to large steady-state errors. This paper proposes a hybrid GFANC-FxNLMS algorithm to leverage the complementary advantages of both approaches. In the hybrid GFANC-FxNLMS algorithm, GFANC provides a frame-level control filter as an initialization for FxNLMS, while FxNLMS performs continuous adaptation at the sampling rate. Small variations in the GFANC-generated filter may repeatedly reinitialize FxNLMS, interrupting its adaptation process and destabilizing the system. An online clustering module is introduced to avoid unnecessary re-initializations and improve system stability. Simulation results show that the proposed algorithm achieves fast response, very low steady-state error, and high stability, requiring only one pre-trained broadband filter.

</details>


### [23] [Timbre-Aware LLM-based Direct Speech-to-Speech Translation Extendable to Multiple Language Pairs](https://arxiv.org/abs/2601.16023)
*Lalaram Arya,Mrinmoy Bhattacharjee,Adarsh C. R.,S. R. Mahadeva Prasanna*

Main category: eess.AS

TL;DR: DS2ST-LM：基于多语言大语言模型的单阶段直接语音到语音翻译框架，通过合成数据缓解数据稀缺，使用线性投影器获得最佳性能，在多种语言对上超越级联基线，并保持说话人音色。


<details>
  <summary>Details</summary>
Motivation: 现有直接语音到语音翻译系统面临三大挑战：1）平行语音数据稀缺时语义-声学对齐不稳定；2）难以保持说话人身份；3）多语言扩展性有限。需要更稳定、可扩展且能保持说话人特征的解决方案。

Method: 提出DS2ST-LM框架，包含Whisper语音编码器、可学习投影模块、Qwen2-0.5B LLM和音色控制声码器。构建1000小时双语语料库GigaS2S-1000，包含高质量合成目标语音。研究两种语义标记生成策略（S3语音标记和LLM文本标记），评估三种投影架构（线性、Conv1D-线性和Q-Former）。

Result: DS2ST-LM在词汇（BLEU、METEOR）和语义（BLEURT、COMET）指标上均超越传统级联和ST+TTS基线。线性投影器性能最高，虽然高容量投影器收敛更快。系统扩展到法语、西班牙语、德语、印地语、孟加拉语和乌尔都语等多种语言对，在说话人相似度和感知自然度上超越先前直接S2ST系统。

Conclusion: DS2ST-LM证明了基于LLM的单阶段直接语音到语音翻译框架的有效性，通过合成数据缓解数据稀缺，简单线性投影器实现最佳性能，音色感知合成保持说话人特征，为多语言直接S2ST提供了可扩展解决方案。

Abstract: Direct Speech-to-Speech Translation (S2ST) has gained increasing attention for its ability to translate speech from one language to another, while reducing error propagation and latency inherent in traditional cascaded pipelines. However, existing direct S2ST systems continue to face notable challenges, including instability in semantic-acoustic alignment when parallel speech data is scarce, difficulty in preserving speaker identity, and limited multilingual scalability. In this work, we introduce DS2ST-LM, a scalable, single-stage direct S2ST framework leveraging a multilingual Large Language Model (LLM). The architecture integrates a Whisper speech encoder, a learnable projection module, a Qwen2-0.5B LLM, and a timbre-controlled vocoder. We construct GigaS2S-1000, a 1000-hour bilingual corpus by extending the GigaST dataset with high-fidelity synthetic target speech, and show that this synthetic data alleviates data scarcity to some extent. We investigate two semantic token generation strategies: speech-derived S3 tokens and text-derived tokens generated by a pre-trained LLM, and analyze their impact on training stability and semantic consistency. We further evaluate three projection architectures (Linear, Conv1D-Linear, and Q-Former) and observe that while higher-capacity projectors converge faster, the simple Linear projector achieves higher performance. Extensive experiments demonstrate that DS2ST-LM outperforms traditional cascaded and ST (Qwen-Audio) + TTS baselines across both lexical (BLEU, METEOR) and semantic (BLEURT, COMET) metrics, while extending to multiple language pairs, including French, Spanish, German, Hindi, Bengali, and Urdu. Furthermore, we incorporate timbre-aware speech synthesis to preserve speaker information, enabling DS2ST-LM to surpass prior direct S2ST systems in both speaker similarity and perceptual naturalness.

</details>


### [24] [Loose coupling of spectral and spatial models for multi-channel diarization and enhancement of meetings in dynamic environments](https://arxiv.org/abs/2601.16077)
*Adrian Meise,Tobias Cord-Landwehr,Christoph Boeddeker,Marc Delcroix,Tomohiro Nakatani,Reinhold Haeb-Umbach*

Main category: eess.AS

TL;DR: 提出一种新颖的联合空间和频谱混合模型，通过概率建模将说话人和位置索引关联，解决移动说话人的声源分离问题


<details>
  <summary>Details</summary>
Motivation: 麦克风阵列捕获声音可以利用空间和频谱信息进行说话人分离和信号增强，但当说话人移动时，空间位置与说话人之间没有一一对应关系，需要解决这一挑战

Method: 提出联合空间和频谱混合模型，包含两个松散耦合的子模型，通过概率建模说话人和位置索引之间的关系，允许说话人在不同位置说话

Result: 在模拟说话人位置变化的LibriCSS数据集上实验，相比紧密耦合子系统取得了显著改进

Conclusion: 提出的松散耦合模型能够有效联合利用空间和频谱信息，同时处理说话人移动的情况，在说话人分离任务上表现优异

Abstract: Sound capture by microphone arrays opens the possibility to exploit spatial, in addition to spectral, information for diarization and signal enhancement, two important tasks in meeting transcription. However, there is no one-to-one mapping of positions in space to speakers if speakers move. Here, we address this by proposing a novel joint spatial and spectral mixture model, whose two submodels are loosely coupled by modeling the relationship between speaker and position index probabilistically. Thus, spatial and spectral information can be jointly exploited, while at the same time allowing for speakers speaking from different positions. Experiments on the LibriCSS data set with simulated speaker position changes show great improvements over tightly coupled subsystems.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [25] [Abusive music and song transformation using GenAI and LLMs](https://arxiv.org/abs/2601.15348)
*Jiyang Choi,Rohitash Chandra*

Main category: cs.SD

TL;DR: 使用生成式AI和LLM自动转换流行音乐中的辱骂性歌词和演唱方式，通过改变音调、强度和情感来减少攻击性内容，同时保持音乐连贯性。


<details>
  <summary>Details</summary>
Motivation: 音乐中的暴力和辱骂内容可能影响听众情绪和行为，甚至使攻击性行为正常化或强化有害刻板印象。传统的内容审查（如静音或替换单词）可能引发"禁果效应"，使被审查内容因被限制而更具吸引力。

Method: 使用生成式人工智能和大型语言模型自动转换流行音乐中的辱骂性歌词和演唱方式。不是简单地静音或替换单个单词，而是改变音调、强度和情感，从而不仅改变歌词内容，还改变表达方式。对四首英文歌曲及其转换版本进行比较分析，通过声学和情感两个维度进行评估。

Result: 生成式AI显著降低了声乐攻击性：声学分析显示谐噪比、倒谱峰值突出度和抖动等指标均有改善。情感分析显示攻击性减少了63.3-85.6%，副歌部分改善最大（减少达88.6%）。转换后的版本在保持音乐连贯性的同时减轻了有害内容。

Conclusion: 该方法展示了生成式AI在创造更安全聆听体验同时保留艺术表达的潜力，为传统内容审查提供了有前景的替代方案，避免了"禁果效应"。

Abstract: Repeated exposure to violence and abusive content in music and song content can influence listeners' emotions and behaviours, potentially normalising aggression or reinforcing harmful stereotypes. In this study, we explore the use of generative artificial intelligence (GenAI) and Large Language Models (LLMs) to automatically transform abusive words (vocal delivery) and lyrical content in popular music. Rather than simply muting or replacing a single word, our approach transforms the tone, intensity, and sentiment, thus not altering just the lyrics, but how it is expressed. We present a comparative analysis of four selected English songs and their transformed counterparts, evaluating changes through both acoustic and sentiment-based lenses. Our findings indicate that Gen-AI significantly reduces vocal aggressiveness, with acoustic analysis showing improvements in Harmonic to Noise Ratio, Cepstral Peak Prominence, and Shimmer. Sentiment analysis reduced aggression by 63.3-85.6\% across artists, with major improvements in chorus sections (up to 88.6\% reduction). The transformed versions maintained musical coherence while mitigating harmful content, offering a promising alternative to traditional content moderation that avoids triggering the "forbidden fruit" effect, where the censored content becomes more appealing simply because it is restricted. This approach demonstrates the potential for GenAI to create safer listening experiences while preserving artistic expression.

</details>


### [26] [DeepASMR: LLM-Based Zero-Shot ASMR Speech Generation for Anyone of Any Voice](https://arxiv.org/abs/2601.15596)
*Leying Zhang,Tingxiao Zhou,Haiyang Sun,Mengxiao Bi,Yanmin Qian*

Main category: cs.SD

TL;DR: DeepASMR是首个零样本ASMR生成框架，仅需说话者普通朗读语音的短片段即可合成高质量ASMR语音，无需目标说话者的耳语训练数据。


<details>
  <summary>Details</summary>
Motivation: 现有TTS系统在生成ASMR（自主感官经络反应）这种低强度、放松性语音风格时效果不佳，主要挑战包括ASMR的细微特征（常为非浊音）和零样本说话者适应的需求。

Method: 首先发现离散语音标记能软分解ASMR风格和说话者音色；提出两阶段流程：使用LLM进行内容-风格编码，使用流匹配声学解码器进行音色重建。

Result: 构建了DeepASMR-DB（670小时英中多说话者ASMR语料库），提出包含客观指标、人工听测、LLM评分和非浊音分析的新评估协议；实验证明在ASMR生成的自然度和风格保真度上达到SOTA。

Conclusion: DeepASMR实现了对任何声音的零样本高质量ASMR生成，同时在正常语音合成上保持竞争力，为个性化放松语音生成提供了有效解决方案。

Abstract: While modern Text-to-Speech (TTS) systems achieve high fidelity for read-style speech, they struggle to generate Autonomous Sensory Meridian Response (ASMR), a specialized, low-intensity speech style essential for relaxation. The inherent challenges include ASMR's subtle, often unvoiced characteristics and the demand for zero-shot speaker adaptation. In this paper, we introduce DeepASMR, the first framework designed for zero-shot ASMR generation. We demonstrate that a single short snippet of a speaker's ordinary, read-style speech is sufficient to synthesize high-fidelity ASMR in their voice, eliminating the need for whispered training data from the target speaker. Methodologically, we first identify that discrete speech tokens provide a soft factorization of ASMR style from speaker timbre. Leveraging this insight, we propose a two-stage pipeline incorporating a Large Language Model (LLM) for content-style encoding and a flow-matching acoustic decoder for timbre reconstruction. Furthermore, we contribute DeepASMR-DB, a comprehensive 670-hour English-Chinese multi-speaker ASMR speech corpus, and introduce a novel evaluation protocol integrating objective metrics, human listening tests, LLM-based scoring and unvoiced speech analysis. Extensive experiments confirm that DeepASMR achieves state-of-the-art naturalness and style fidelity in ASMR generation for anyone of any voice, while maintaining competitive performance on normal speech synthesis.

</details>


### [27] [Qwen3-TTS Technical Report](https://arxiv.org/abs/2601.15621)
*Hangrui Hu,Xinfa Zhu,Ting He,Dake Guo,Bin Zhang,Xiong Wang,Zhifang Guo,Ziyue Jiang,Hongkun Hao,Zishan Guo,Xinyu Zhang,Pei Zhang,Baosong Yang,Jin Xu,Jingren Zhou,Junyang Lin*

Main category: cs.SD

TL;DR: Qwen3-TTS系列是一个先进的多语言、可控、鲁棒、流式文本转语音模型，支持3秒语音克隆和描述控制，采用双轨LM架构和两种语音分词器，在多项基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个支持多语言、可控性强、鲁棒性好且支持流式合成的文本转语音系统，满足高质量语音生成、实时应用和社区研究需求。

Method: 采用双轨语言模型架构实现实时合成，配合两种语音分词器：1) Qwen-TTS-Tokenizer-25Hz单码本编解码器，强调语义内容，支持流式波形重建；2) Qwen-TTS-Tokenizer-12Hz多码本设计，实现极低比特率和超低延迟流式合成。

Result: 在超过500万小时10种语言的语音数据上训练，支持3秒语音克隆和描述控制，在多项客观和主观基准测试（如TTS多语言测试集、InstructTTSEval等）中达到最先进性能，首包延迟仅97ms。

Conclusion: Qwen3-TTS系列在多语言语音合成、可控性、鲁棒性和流式处理方面表现出色，通过Apache 2.0许可证开源模型和分词器，促进社区研究和开发。

Abstract: In this report, we present the Qwen3-TTS series, a family of advanced multilingual, controllable, robust, and streaming text-to-speech models. Qwen3-TTS supports state-of-the-art 3-second voice cloning and description-based control, allowing both the creation of entirely novel voices and fine-grained manipulation over the output speech. Trained on over 5 million hours of speech data spanning 10 languages, Qwen3-TTS adopts a dual-track LM architecture for real-time synthesis, coupled with two speech tokenizers: 1) Qwen-TTS-Tokenizer-25Hz is a single-codebook codec emphasizing semantic content, which offers seamlessly integration with Qwen-Audio and enables streaming waveform reconstruction via a block-wise DiT. 2) Qwen-TTS-Tokenizer-12Hz achieves extreme bitrate reduction and ultra-low-latency streaming, enabling immediate first-packet emission ($97\,\mathrm{ms}$) through its 12.5 Hz, 16-layer multi-codebook design and a lightweight causal ConvNet. Extensive experiments indicate state-of-the-art performance across diverse objective and subjective benchmark (e.g., TTS multilingual test set, InstructTTSEval, and our long speech test set). To facilitate community research and development, we release both tokenizers and models under the Apache 2.0 license.

</details>


### [28] [EmotionThinker: Prosody-Aware Reinforcement Learning for Explainable Speech Emotion Reasoning](https://arxiv.org/abs/2601.15668)
*Dingdong Wang,Shujie Liu,Tianhua Zhang,Youjun Chen,Jinyu Li,Helen Meng*

Main category: cs.SD

TL;DR: 该论文提出EmotionThinker，将语音情感识别重新定义为深度推理问题，通过强化学习生成可解释的情感预测，并构建了包含35K条思维链标注的数据集。


<details>
  <summary>Details</summary>
Motivation: 当前语音大语言模型和传统语音情感识别系统将情感理解视为简单的分类问题，这限制了预测的可解释性，未能充分利用LLMs的表达和推理能力。

Method: 1) 构建EmotionCoT-35K情感推理数据集；2) 开发增强韵律感知的基础模型EmotionThinker-Base；3) 提出GRPO-PTR强化学习方法，引入渐进式推理奖励和信任权重。

Result: EmotionThinker在情感准确性和解释质量上都优于之前的最先进评估模型，将语音情感识别推向可解释的多模态推理。

Conclusion: 该研究首次通过强化学习将语音情感识别重新定义为深度推理问题，提出的方法在准确性和可解释性方面都取得了显著提升，推动了可解释多模态推理的发展。

Abstract: Emotional information in speech plays a unique role in multimodal perception. However, current Speech Large Language Models (SpeechLLMs), similar to conventional speech emotion recognition (SER) systems, still treat emotion understanding as a simple classification problem. This provides limited interpretability of predictions, while leaving the LLMs' expressive and reasoning capabilities underutilized. In this work, we take the first step to reformulate SER as a deep reasoning problem through reinforcement learning (RL). We propose EmotionThinker, which is designed to generate accurate emotion predictions with interpretable explanations grounded in fine-grained acoustic cues. To achieve this, we first construct EmotionCoT-35K, an emotional reasoning dataset with Chain-of-Thought annotations and detailed captions. Second, we observe that current SpeechLLMs exhibit weak prosody perception, whereas prosodic cues constitute fundamental signals for interpreting emotions. To address this, we develop the prosody-enhanced foundation model EmotionThinker-Base, and demonstrate that prosody enhancement improves emotion understanding. Third, we introduce Group-Relative-Policy-Optimization with Progressive-Trust-aware-Reasoning-Reward (GRPO-PTR) for RL. Different from standard GRPO, which relies only on rule-based outcome rewards, GRPO-PTR progressively introduces reasoning reward, dynamically adjusts it with a trustworthiness weight reflecting the alignment between reasoning and outcome, and evaluates the overall reasoning quality with a reward model based on multi-dimensional criteria. EmotionThinker outperforms previous state-of-the-art evaluation models both in emotion accuracy and explanation quality, advancing SER toward interpretable multimodal reasoning. Project page: https://github.com/dingdongwang/EmotionThinker

</details>


### [29] [Bridging the Perception Gap: A Lightweight Coarse-to-Fine Architecture for Edge Audio Systems](https://arxiv.org/abs/2601.15676)
*Hengfan Zhang,Yueqian Lin,Hai Helen Li,Yiran Chen*

Main category: cs.SD

TL;DR: CoFi-Agent：一种混合边缘-云架构，通过本地快速感知和条件性云端细粒度分析，在保持效率的同时提升音频-语言模型的推理精度。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的轻量级音频-语言模型往往只能进行被动感知（生成通用摘要），而无法捕捉多步音频推理所需的细微证据；完全云端处理则带来不可接受的延迟、带宽成本和隐私风险。需要在感知深度和计算效率之间找到平衡。

Method: 提出CoFi-Agent混合架构，包含：1）本地7B Audio-LLM进行快速单次感知；2）云端控制器检测不确定性并触发条件性细粒度分析；3）设备端工具（如时间重听、本地ASR）执行轻量级计划。采用工具增强的粗到细代理方法。

Result: 在MMAR基准测试中，CoFi-Agent将准确率从27.20%提升至53.60%，同时比持续调查流水线实现了更好的准确率-效率权衡。

Conclusion: CoFi-Agent通过工具增强的条件性边缘-云协作，在实际系统约束下弥合了感知差距，为音频-语言模型部署提供了有效的混合解决方案。

Abstract: Deploying Audio-Language Models (Audio-LLMs) on edge infrastructure exposes a persistent tension between perception depth and computational efficiency. Lightweight local models tend to produce passive perception - generic summaries that miss the subtle evidence required for multi-step audio reasoning - while indiscriminate cloud offloading incurs unacceptable latency, bandwidth cost, and privacy risk. We propose CoFi-Agent (Tool-Augmented Coarse-to-Fine Agent), a hybrid architecture targeting edge servers and gateways. It performs fast local perception and triggers conditional forensic refinement only when uncertainty is detected. CoFi-Agent runs an initial single-pass on a local 7B Audio-LLM, then a cloud controller gates difficult cases and issues lightweight plans for on-device tools such as temporal re-listening and local ASR. On the MMAR benchmark, CoFi-Agent improves accuracy from 27.20% to 53.60%, while achieving a better accuracy-efficiency trade-off than an always-on investigation pipeline. Overall, CoFi-Agent bridges the perception gap via tool-enabled, conditional edge-cloud collaboration under practical system constraints.

</details>


### [30] [U3-xi: Pushing the Boundaries of Speaker Recognition via Incorporating Uncertainty](https://arxiv.org/abs/2601.15719)
*Junjie Li,Kong Aik Lee*

Main category: cs.SD

TL;DR: 提出U3-xi框架，通过估计帧级不确定性并分配自适应权重，为说话人嵌入提供更可靠和可解释的不确定性估计，显著提升说话人验证性能。


<details>
  <summary>Details</summary>
Motivation: 在真实场景中，帧级表示不仅包含说话人相关信息，还包含各种干扰因素，不同帧对最终说话人表示的贡献不均等。现有方法缺乏对帧级不确定性的有效建模，导致说话人嵌入不够可靠。

Method: 提出U3-xi框架，包含三种不确定性监督策略：1) 通过随机方差损失进行说话人级不确定性监督，使用说话人中心距离作为伪真值；2) 全局级不确定性监督，将预测的不确定性注入softmax尺度调整决策边界锐度；3) 重新设计不确定性估计模块，集成Transformer编码器与多视图自注意力机制。

Result: U3-xi是模型无关的，可应用于多种说话人编码器。应用于ECAPA-TDNN时，在VoxCeleb1测试集上EER相对改进21.1%，minDCF相对改进15.57%。

Conclusion: 提出的不确定性感知框架能有效提升说话人验证性能，通过自适应加权机制处理帧级表示的不确定性，为说话人嵌入提供更可靠和可解释的估计。

Abstract: An utterance-level speaker embedding is typically obtained by aggregating a sequence of frame-level representations. However, in real-world scenarios, individual frames encode not only speaker-relevant information but also various nuisance factors. As a result, different frames contribute unequally to the final utterance-level speaker representation for Automatic Speaker Verification systems. To address this issue, we propose to estimate the inherent uncertainty of each frame and assign adaptive weights accordingly, where frames with higher uncertainty receive lower attention. Based on this idea, we present U3-xi, a comprehensive framework designed to produce more reliable and interpretable uncertainty estimates for speaker embeddings. Specifically, we introduce several strategies for uncertainty supervision. First, we propose speaker-level uncertainty supervision via a Stochastic Variance Loss, where the distance between an utterance embedding and its corresponding speaker centroid serves as a pseudo ground truth for uncertainty learning. Second, we incorporate global-level uncertainty supervision by injecting the predicted uncertainty into the sof tmax scale during training. This adaptive scaling mechanism adjusts the sharpness of the decision boundary according to sample difficulty, providing global guidance. Third, we redesign the uncertainty estimation module by integrating a Transformer encoder with multi-view self-attention, enabling the model to capture rich local and long-range temporal dependencies. Comprehensive experiments demonstrate that U3-xi is model-agnostic and can be seamlessly applied to various speaker encoders. In particular, when applied to ECAPA-TDNN, it achieves 21.1% and 15.57% relative improvements on the VoxCeleb1 test sets in terms of EER and minDCF, respectively.

</details>


### [31] [PF-D2M: A Pose-free Diffusion Model for Universal Dance-to-Music Generation](https://arxiv.org/abs/2601.15872)
*Jaekwon Im,Natalia Polouliakh,Taketo Akama*

Main category: cs.SD

TL;DR: PF-D2M是一个基于扩散模型的通用舞蹈到音乐生成模型，通过提取舞蹈视频的视觉特征，采用渐进式训练策略解决数据稀缺问题，在舞蹈-音乐对齐和音乐质量方面达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有舞蹈到音乐生成方法通常依赖单个舞者的身体运动特征和有限的数据集，限制了其在多舞者和非人类舞者等真实场景中的性能和应用。

Method: 提出PF-D2M模型：1) 从舞蹈视频中提取视觉特征；2) 基于扩散模型架构；3) 采用渐进式训练策略解决数据稀缺和泛化问题。

Result: 主客观评估均显示PF-D2M在舞蹈-音乐对齐和音乐质量方面达到最先进的性能水平。

Conclusion: PF-D2M通过视觉特征提取和渐进式训练，成功解决了现有方法的局限性，为舞蹈到音乐生成提供了更通用和有效的解决方案。

Abstract: Dance-to-music generation aims to generate music that is aligned with dance movements. Existing approaches typically rely on body motion features extracted from a single human dancer and limited dance-to-music datasets, which restrict their performance and applicability to real-world scenarios involving multiple dancers and non-human dancers. In this paper, we propose PF-D2M, a universal diffusion-based dance-to-music generation model that incorporates visual features extracted from dance videos. PF-D2M is trained with a progressive training strategy that effectively addresses data scarcity and generalization challenges. Both objective and subjective evaluations show that PF-D2M achieves state-of-the-art performance in dance-music alignment and music quality.

</details>


### [32] [Distillation-based Layer Dropping (DLD) Effective End-to-end Framework for Dynamic Speech Networks](https://arxiv.org/abs/2601.16117)
*Abdul Hannan,Daniele Falavigna,Shah Nawaz,Mubashir Noman,Markus Schedl,Alessio Brutti*

Main category: cs.SD

TL;DR: 提出基于知识蒸馏的层丢弃框架DLD，用于动态语音网络，在边缘设备资源受限场景下实现更好的性能-计算权衡。


<details>
  <summary>Details</summary>
Motivation: 边缘设备在资源受限且变化的环境中运行，需要能适应资源限制的动态架构。现有层丢弃方法在高低丢弃情况下严重影响动态模型性能，恶化性能-计算权衡。

Method: 提出蒸馏基的层丢弃框架DLD，以端到端方式有效结合知识蒸馏和层丢弃能力，用于动态语音网络。

Result: 在三个公共基准测试上使用conformer和WavLM等知名语音识别方法进行综合实验，证明框架有效性：高低丢弃情况下词错误率分别降低9.32%和2.25%，训练时间减少33.3%。

Conclusion: DLD框架在动态语音网络中实现了最先进的性能，显著改善了边缘设备场景下的性能-计算权衡。

Abstract: Edge devices operate in constrained and varying resource settings, requiring dynamic architectures that can adapt to limitations of the available resources. To meet such demands, layer dropping ($\mathcal{LD}$) approach is typically used to transform static models into dynamic ones by skipping parts of the network along with reducing overall computational complexity. However, existing $\mathcal{LD}$ methods greatly impact the dynamic model's performance for low and high dropping cases, deteriorating the performance-computation trade-off. To this end, we propose a distillation-based layer dropping (DLD) framework that effectively combines the capabilities of knowledge distillation and $\mathcal{LD}$ in an end-to-end fashion, thereby achieving state-of-the-art performance for dynamic speech networks. Comprehensive experimentation utilizing well-known speech recognition methods, including conformer and WavLM, on three public benchmarks demonstrates the effectiveness of our framework, reducing the word error rate by $9.32\%$ and $2.25\%$ for high and no dropping cases with $33.3\%$ reduction in training time.

</details>


### [33] [Pay (Cross) Attention to the Melody: Curriculum Masking for Single-Encoder Melodic Harmonization](https://arxiv.org/abs/2601.16150)
*Maximos Kaliakatsos-Papakostas,Dimos Makris,Konstantinos Soiledis,Konstantinos-Theodoros Tsamis,Vassilis Katsouros,Emilios Cambouropoulos*

Main category: cs.SD

TL;DR: 提出FF训练课程，通过保持所有和声标记被遮蔽若干训练步骤，然后逐步解遮蔽整个序列，以增强旋律-和声交互，在单编码器旋律和声化任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于离散扩散的单编码器Transformer方法在旋律和声化任务中，旋律与和声之间的注意力机制较弱，导致对旋律线索的利用不足，特别是在域外情境下表现不佳。

Method: 提出FF（full-to-full）训练课程：在训练初期保持所有和声标记被遮蔽若干步骤，然后逐步解遮蔽整个序列，以强化旋律-和声交互。系统评估了不同时间量化、小节级与时值条件、旋律表示和解遮蔽策略。

Result: FF课程在几乎所有指标上都优于基线方法，特别是在域外评估中表现突出，其中四分之一音符量化、小节标记交织和音级旋律表示在FF设置中效果更佳。

Conclusion: 训练课程对实现有效的旋律条件化至关重要，full-to-full解遮蔽策略为单编码器和声化提供了稳健的方法，能够更好地适应新颖的旋律线索。

Abstract: Melodic harmonization, the task of generating harmonic accompaniments for a given melody, remains a central challenge in computational music generation. Recent single encoder transformer approaches have framed harmonization as a masked sequence modeling problem, but existing training curricula inspired by discrete diffusion often result in weak (cross) attention between melody and harmony. This leads to limited exploitation of melodic cues, particularly in out-of-domain contexts. In this work, we introduce a training curriculum, FF (full-to-full), which keeps all harmony tokens masked for several training steps before progressively unmasking entire sequences during training to strengthen melody-harmony interactions. We systematically evaluate this approach against prior curricula across multiple experimental axes, including temporal quantization (quarter vs. sixteenth note), bar-level vs. time-signature conditioning, melody representation (full range vs. pitch class), and inference-time unmasking strategies. Models are trained on the HookTheory dataset and evaluated both in-domain and on a curated collection of jazz standards, using a comprehensive set of metrics that assess chord progression structure, harmony-melody alignment, and rhythmic coherence. Results demonstrate that the proposed FF curriculum consistently outperforms baselines in nearly all metrics, with particularly strong gains in out-of-domain evaluations where harmonic adaptability to novel melodic queues is crucial. We further find that quarter-note quantization, intertwining of bar tokens, and pitch-class melody representations are advantageous in the FF setting. Our findings highlight the importance of training curricula in enabling effective melody conditioning and suggest that full-to-full unmasking offers a robust strategy for single encoder harmonization.

</details>


### [34] [Domain-Incremental Continual Learning for Robust and Efficient Keyword Spotting in Resource Constrained Systems](https://arxiv.org/abs/2601.16158)
*Prakash Dhungana,Sayed Ahmad Salehi*

Main category: cs.SD

TL;DR: 提出一个用于关键词检测系统的持续学习框架，通过双输入CNN结合多阶段去噪和原型更新机制，使小型模型能在资源受限的边缘设备上适应新领域噪声环境，同时保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的小型关键词检测模型面临噪声和录音条件变化带来的领域偏移问题，导致准确率和鲁棒性下降，需要一种能在资源受限环境下持续适应新领域的方法。

Method: 提出一个综合持续学习框架，包括：1) 双输入CNN同时处理MFCC和梅尔频谱特征；2) 多阶段去噪（离散小波变换和频谱减法）；3) 完整量化模型更新（而非仅特定层）；4) 基于原型和置信度过滤的运行时样本选择；5) 伪标签生成与排练缓冲结合的增量模型重训练。

Result: 在噪声测试数据集上，框架在干净数据上达到99.63%准确率，在多样化噪声环境中（包括-10 dB信噪比）保持超过94%的鲁棒性能，显著优于现有方法。

Conclusion: 高效去噪与基于原型的持续学习相结合，使关键词检测模型能够在资源受限的动态环境中自主、鲁棒地运行，解决了边缘设备上小型模型适应领域偏移的挑战。

Abstract: Keyword Spotting (KWS) systems with small footprint models deployed on edge devices face significant accuracy and robustness challenges due to domain shifts caused by varying noise and recording conditions. To address this, we propose a comprehensive framework for continual learning designed to adapt to new domains while maintaining computational efficiency. The proposed pipeline integrates a dual-input Convolutional Neural Network, utilizing both Mel Frequency Cepstral Coefficients (MFCC) and Mel-spectrogram features, supported by a multi-stage denoising process, involving discrete wavelet transform and spectral subtraction techniques, plus model and prototype update blocks. Unlike prior methods that restrict updates to specific layers, our approach updates the complete quantized model, made possible due to compact model architecture. A subset of input samples are selected during runtime using class prototypes and confidence-driven filtering, which are then pseudo-labeled and combined with rehearsal buffer for incremental model retraining. Experimental results on noisy test dataset demonstrate the framework's effectiveness, achieving 99.63\% accuracy on clean data and maintaining robust performance (exceeding 94\% accuracy) across diverse noisy environments, even at -10 dB Signal-to-Noise Ratio. The proposed framework work confirms that integrating efficient denoising with prototype-based continual learning enables KWS models to operate autonomously and robustly in resource-constrained, dynamic environments.

</details>

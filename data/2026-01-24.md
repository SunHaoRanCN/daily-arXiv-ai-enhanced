<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 19]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SD](#cs.SD) [Total: 10]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [ISAC-over-NTN: HAPS-UAV Framework for Post-Disaster Responsive 6G Networks](https://arxiv.org/abs/2601.15422)
*Berk Ciloglu,Ozgun Ersoy,Metin Ozturk,Ali Gorcin*

Main category: eess.SP

TL;DR: 该论文提出了一种灾后场景下的ISAC-over-NTN架构，通过集成无人机和HAPS平台，同时实现可靠通信和用户检测功能。


<details>
  <summary>Details</summary>
Motivation: 在灾害场景中，地面网络可能部分或完全瘫痪，确保可靠的通信和态势感知成为关键挑战。需要为搜救行动提供通信基础设施，并检测被困或移动的用户。

Method: 提出ISAC-over-NTN架构，集成多个无人机和高空平台站(HAPS)。采用创新的波束赋形方法，将多用户MIMO通信和单站感知集成在同一传输链中，同时传输数据和基于多普勒的移动检测。

Result: 该框架保持了可靠的连接性，并在关键位置实现了高用户检测精度：达到90%的运动检测灵敏度和88%的检测准确率。

Conclusion: ISAC-over-NTN架构能够在灾后条件下提供弹性和可靠的网络操作，同时实现通信和感知功能，有效支持搜救行动。

Abstract: In disaster scenarios, ensuring both reliable communication and situational awareness becomes a critical challenge due to the partial or complete collapse of terrestrial networks. This paper proposes an integrated sensing and communication (ISAC) over non-terrestrial networks (NTN) architecture referred to as ISAC-over-NTN that integrates multiple uncrewed aerial vehicles (UAVs) and a high-altitude platform station (HAPS) to maintain resilient and reliable network operations in post-disaster conditions. We aim to achieve two main objectives: i) provide a reliable communication infrastructure, thereby ensuring the continuity of search-and-rescue activities and connecting people to their loved ones, and ii) detect users, such as those trapped under rubble or those who are mobile, using a Doppler-based mobility detection model. We employ an innovative beamforming method that simultaneously transmits data and detects Doppler-based mobility by integrating multi-user multiple-input multiple-output (MU-MIMO) communication and monostatic sensing within the same transmission chain. The results show that the proposed framework maintains reliable connectivity and achieves high detection accuracy of users in critical locations, reaching 90% motion detection sensitivity and 88% detection accuracy.

</details>


### [2] [Achievable Rate Optimization for Large Flexible Intelligent Metasurface Assisted Downlink MISO under Statistical CSI](https://arxiv.org/abs/2601.15471)
*Ling He,Vaibhav Kumar,Anastasios Papazafeiropoulos,Miaowen Wen,Le-Nam Tran,Marwa Chafii*

Main category: eess.SP

TL;DR: 提出基于统计CSI的FIM辅助MISO系统鲁棒优化框架，通过联合优化功率分配和FIM形变最大化平均可达和速率，相比传统刚性天线阵列有显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有FIM辅助系统设计大多假设完美瞬时CSI，但在大规模网络中由于高训练开销和复杂信道估计而不切实际，需要更实用的解决方案。

Method: 提出基于统计CSI的鲁棒优化框架，采用块坐标上升(BCA)迭代算法联合优化功率分配和FIM形变，最大化平均可达和速率。

Result: 仿真结果表明，所提出的统计CSI驱动的FIM设计显著优于传统刚性天线阵列，验证了其有效性和实用性。

Conclusion: 基于统计CSI的FIM优化框架为大规模网络提供了实用且有效的解决方案，克服了完美瞬时CSI假设的限制，展示了FIM在无线通信中的实际应用潜力。

Abstract: The integration of electromagnetic metasurfaces into wireless communications enables intelligent control of the propagation environment. Recently, flexible intelligent metasurfaces (FIMs) have evolved beyond conventional reconfigurable intelligent surfaces (RISs), enabling three-dimensional surface deformation for adaptive wave manipulation. However, most existing FIM-aided system designs assume perfect instantaneous channel state information (CSI), which is impractical in large-scale networks due to the high training overhead and complicated channel estimation. To overcome this limitation, we propose a robust statistical-CSI-based optimization framework for downlink multiple-input single-output (MISO) systems with FIM-assisted transmitters. A block coordinate ascent (BCA)-based iterative algorithm is developed to jointly optimize power allocation and FIM morphing, maximizing the average achievable sum rate. Simulation results show that the proposed statistical-CSI-driven FIM design significantly outperforms conventional rigid antenna arrays (RAAs), validating its effectiveness and practicality.

</details>


### [3] [Applicability and Limitation Analysis of PMU Data and Phasor Concept for Low- and High- Frequency Oscillations](https://arxiv.org/abs/2601.15529)
*Bowen Ou,Bin Wang,Slava Maslennikov,Hanchao Liu,Jim Follum*

Main category: eess.SP

TL;DR: 该论文揭示了PMU相量数据在高频振荡分析中的根本局限性，提出了更通用的信号模型和多步估计方法，并指出对于高频振荡需要依赖波形数据而非相量概念。


<details>
  <summary>Details</summary>
Motivation: PMU将高速波形数据转换为低速相量数据，广泛应用于电力系统广域监测控制，但在高频振荡检测和定位方面存在局限性。论文旨在探究这种局限性的根本原因，并提出改进方法。

Method: 提出更通用的信号模型和多步估计方法，结合单周期DFT、矩阵铅笔法和最小二乘法，以更好地表示和估计含振荡的波形信号。

Result: 数值实验表明所提出的信号模型和估计方法具有优越性能。研究还揭示了相量概念（特别是PMU相量）对于具有不对称次同步和超同步分量的高频振荡波形信号可能失效。

Conclusion: PMU数据和相量概念存在根本局限性，对于分析现代电力系统中的高频振荡，需要依赖波形数据而非相量数据。

Abstract: Phasor Measurement Units (PMUs) convert high-speed waveform data into low-speed phasor data, which are fundamental to wide-area monitoring and control in power systems, with oscillation detection and localization among their most prominent applications. However, representing electrical waveform signals with oscillations using PMU phasors is effective only for low-frequency oscillations. This paper investigates the root causes of this limitation, focusing on errors introduced by Discrete Fourier Transform (DFT)-based signal processing, in addition to the attenuation effects of anti-aliasing filters, and the impact of low reporting rates. To better represent and estimate waveform signals with oscillations, we propose a more general signal model and a multi-step estimation method that leverages one-cycle DFT, the Matrix Pencil Method, and the Least Squares Method. Numerical experiments demonstrate the superior performance of the proposed signal model and estimation method. Furthermore, this paper reveals that the phasor concept, let alone PMU phasors, can become invalid for waveform signals with high-frequency oscillations characterized by asymmetric sub- and super-synchronous components. These findings highlight the fundamental limitations of PMU data and phasor concept, and emphasize the need to rely on waveform data for analyzing high-frequency oscillations in modern power systems.

</details>


### [4] [Distributed Uplink Anti-Jamming in LEO Mega-Constellations via Game-Theoretic Beamforming](https://arxiv.org/abs/2601.15557)
*Shizhen Jia,Mingjun Ying,Marco Mezzavilla,Theodore S. Rappaport,Sundeep Rangan*

Main category: eess.SP

TL;DR: 本文提出一种利用LEO卫星星座分布式协作的抗干扰策略，通过多卫星协同对抗地面干扰，显著提升通信链路在强干扰下的容量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: LEO卫星星座因其可预测的轨道动力学和暴露的几何结构，极易受到地面干扰攻击。传统单卫星干扰抑制技术难以在空间上分离期望上行链路信号与附近干扰源，即使使用大型天线阵列也效果有限。

Method: 将上行干扰场景建模为期望地面发射器与干扰器之间的凸凹博弈，双方优化空间协方差矩阵以最大化或最小化可达速率。提出结合交替最佳响应更新和投影梯度下降的高效min-max求解器，使波束成形策略快速收敛到纳什均衡。

Result: 基于真实Starlink轨道几何和Sionna射线追踪仿真表明，近距离干扰器可瘫痪单卫星链路，而分布式卫星协作显著增强鲁棒性，在强干扰下将容量分布向上移动。

Conclusion: 分布式多卫星抗干扰策略利用现代LEO巨型星座的密集连接和高速星间链路，为对抗地面干扰提供了有效解决方案，提升了NTN网络的抗干扰能力。

Abstract: Low-Earth-Orbit (LEO) satellite constellations have become vital in emerging commercial and defense Non-Terrestrial Networks (NTNs). However, their predictable orbital dynamics and exposed geometries make them highly susceptible to ground-based jamming. Traditional single-satellite interference mitigation techniques struggle to spatially separate desired uplink signals from nearby jammers, even with large antenna arrays. This paper explores a distributed multi-satellite anti-jamming strategy leveraging the dense connectivity and high-speed inter-satellite links of modern LEO mega-constellations. We model the uplink interference scenario as a convex-concave game between a desired terrestrial transmitter and a jammer, each optimizing their spatial covariance matrices to maximize or minimize achievable rate. We propose an efficient min-max solver combining alternating best-response updates with projected gradient descent, achieving fast convergence of the beamforming strategy to the Nash equilibrium. Using realistic Starlink orbital geometries and Sionna ray-tracing simulations, we demonstrate that while close-proximity jammers can cripple single-satellite links, distributed satellite cooperation significantly enhances resilience, shifting the capacity distribution upward under strong interference.

</details>


### [5] [An Iterated Hybrid Fast Parallel FIR Filter](https://arxiv.org/abs/2601.15582)
*Keshab K. Parhi*

Main category: eess.SP

TL;DR: 提出一种新型迭代快速并行FIR滤波器——快速混合滤波器，通过在不同层采用不同结构（内层用转置2-并行FFA，外层用直接形式2-并行FFA）来降低硬件复杂度。


<details>
  <summary>Details</summary>
Motivation: 并行FIR滤波器能提高数字信号处理的计算效率和吞吐量，但现有设计仍有优化空间。本文旨在通过新的迭代结构设计，进一步减少硬件复杂度，特别是加法操作的数量。

Method: 采用迭代快速FIR算法（FFA）方法，提出混合滤波器结构：在所有内层迭代使用转置2-并行快速FIR滤波器，在最外层使用直接形式2-并行快速FIR滤波器。这种混合迭代方法首次被提出。

Result: 与先前方法相比，混合快速并行滤波器所需的加法操作数量更少，从而降低了硬件复杂度。

Conclusion: 通过混合使用转置和直接形式2-并行FFA的迭代方法，成功设计出硬件复杂度更低的快速并行FIR滤波器，为数字信号处理应用提供了更高效的解决方案。

Abstract: This paper revisits the design and optimization of parallel fast finite impulse response (FIR) filters using polyphase decomposition and iterated fast FIR algorithms (FFAs). Parallel FIR filtering enhances computational efficiency and throughput in digital signal processing (DSP) applications by enabling the simultaneous processing of multiple input samples. We revisit a prior approach to design of fast parallel filter architectures by using the iterated FFA approach where the same primitive filter, such as 2-parallel, is iterated to design the fast parallel filter. In this paper, we present yet another novel iterated fast parallel FIR filter, referred to as the fast hybrid filter. The hybrid filter iterates a transposed 2-parallel fast FIR filter in all the inner layers and a direct-form 2-parallel fast FIR filter in the outermost layer, resulting in reduced hardware complexity. Such an iterated hybrid approach has not been presented before. We show that the hybrid fast parallel filters require less number of additions compared to prior approaches.

</details>


### [6] [Amalgamated CHIRP and OFDM for ISAC](https://arxiv.org/abs/2601.15584)
*Pankaj Kumar,Mohammed El-Hajjar,Ibrahim A. Hemadeh,Yasser Mestrah,Suraj Srivastava,Aditya K. Jagannatham,Lajos Hanzo*

Main category: eess.SP

TL;DR: 提出一种结合OFDM和chirp波形的新型ISAC波形，通过仿射叠加实现低PAPR，利用chirp进行感知而不占用通信资源，在时隙级集成chirp提升测距精度。


<details>
  <summary>Details</summary>
Motivation: ISAC需要能同时高效支持通信和感知的波形。传统OFDM系统存在高PAPR问题，且传统感知方式需要占用通信资源，降低通信性能。

Method: 提出OFDM和chirp波形的仿射叠加，生成近似恒包络OFDM波形。利用chirp进行感知而不消耗通信资源，并在时隙级集成chirp信号以提升测距精度。

Result: 新波形具有更好的自相关特性，改善了距离和速度的RMSE，降低了PAPR。同时保持了通信效率，并量化了通信与感知性能之间的权衡关系。

Conclusion: 提出的仿射融合波形有效解决了OFDM的高PAPR问题，实现了不占用通信资源的感知功能，在ISAC框架下同时提升了通信和感知性能。

Abstract: Integrated Sensing and Communication (ISAC) requires the development of a waveform capable of efficiently supporting both communication and sensing functionalities. This paper proposes a novel waveform that combines the benefits of both the orthogonal frequency division multiplexing (OFDM) and the chirp waveforms to improve both the communication and sensing performance within an ISAC framework. Hence, a new architecture is proposed that utilizes the conventional communication framework while leveraging the parameters sensed at the receiver (Rx) for enhancing the communication performance. We demonstrate that the affine addition of OFDM and chirp signals results in a near constant-envelope OFDM waveform, which effectively reduces the peak-to-average power ratio (PAPR), a key limitation of traditional OFDM systems. Using the OFDM framework for sensing in the conventional fashion requires the allocation of some resources for sensing, which in turn reduces communication performance. As a remedy, the proposed affine amalgam facilitates sensing through the chirp waveform without consuming communication resources, thereby preserving communication efficiency. Furthermore, a novel technique of integrating the chirp signal into the OFDM framework at the slot-level is proposed to enhance the accuracy of range estimation. The results show that the OFDM signal incorporated with chirp has better autocorrelation properties, improved root mean square error (RMSE) of range and velocity, and lower PAPR. Finally, we characterize the trade-off between communications and sensing performance.

</details>


### [7] [Does 6G Need a New Waveform: Comparing Zak-OTFS with CP-OFDM](https://arxiv.org/abs/2601.15602)
*Imran Ali Khan,Saif Khan Mohammed,Ronny Hadani,Ananthanarayanan Chockalingam,Robert Calderbank,Anton Monk,Shachar Kons,Shlomo Rakib,Yoav Hebron*

Main category: eess.SP

TL;DR: 本文全面比较了CP-OFDM和Zak-OTFS在6G传播环境中的性能，揭示了波形选择本质上是防止ICI与接受ICI的架构选择，Zak-OTFS在高延迟/多普勒扩展场景中表现更优。


<details>
  <summary>Details</summary>
Motivation: 随着Zak-OTFS等新波形技术在全球范围内受到关注并开始实际部署，需要在OFDM和Zak-OTFS之间做出选择。这种选择本质上是两种架构的抉择：防止载波间干扰(ICI)与接受ICI。由于不同地理区域（如大蜂窝网络）的典型使用场景不同，需要全面评估两种技术在6G各种传播环境下的性能。

Method: 本文对循环前缀OFDM(CP-OFDM)和Zak-OTFS在完整的6G传播环境范围内进行了全面的性能比较分析。通过系统性的性能评估，深入探讨这两种技术的根本架构差异。

Result: 研究结果表明，Zak-OTFS在具有高延迟/多普勒信道扩展的双扩展6G使用场景（即高移动性和/或大蜂窝）中表现出优越性能。然而，架构选择取决于典型使用场景，而典型场景在一定程度上取决于地理因素，因为大延迟扩展是大蜂窝网络的特性，在许多重要无线市场中是常态而非例外。

Conclusion: 波形选择本质上是防止ICI与接受ICI的架构选择。OFDM在无ICI时均衡简单但ICI存在时难以预测，而Zak-OTFS虽然均衡更复杂但输入输出关系可预测且获取简单。对于未来6G网络，特别是在高移动性和大蜂窝场景下，Zak-OTFS具有明显优势。

Abstract: Across the world, there is growing interest in new waveforms, Zak-OTFS in particular, and over-the-air implementations are starting to appear. The choice between OFDM and Zak-OTFS is not so much a choice between waveforms as it is an architectural choice between preventing inter-carrier interference (ICI) and embracing ICI. In OFDM, once the Input-Output (I/O) relation is known, equalization is relatively simple, at least when there is no ICI. However, in the presence of ICI the I/O relation is non-predictable and its acquisition is non-trivial. In contrast, equalization is more involved in Zak-OTFS due to inter-symbol-interference (ISI), however the I/O relation is predictable and its acquisition is simple. {Zak-OTFS exhibits superior performance in doubly-spread 6G use cases with high delay/Doppler channel spreads (i.e., high mobility and/or large cells), but architectural choice is governed by the typical use case, today and in the future. What is typical depends to some degree on geography, since large delay spread is a characteristic of large cells which are the rule rather than the exception in many important wireless markets.} This paper provides a comprehensive performance comparison of cyclic prefix OFDM (CP-OFDM) and Zak-OTFS across the full range of 6G propagation environments. The performance results provide insights into the fundamental architectural choice.

</details>


### [8] [Bistatic ISAC: Practical Challenges and Solutions](https://arxiv.org/abs/2601.15733)
*Lucas Giroto,Marcus Henninger,Alexander Felix,Maximilian Bauhofer,Taewon Jeong,Umut Utku Erdem,Stephan ten Brink,Thomas Zwick,Benjamin Nuss,Silvio Mandelli*

Main category: eess.SP

TL;DR: 本文探讨6G网络中双基地集成感知与通信的实际挑战与解决方案，聚焦OFDM波形下的系统设计、信号处理技术及5G兼容参数化仿真


<details>
  <summary>Details</summary>
Motivation: 随着6G网络发展，集成感知与通信成为关键技术，但双基地ISAC在实际部署中面临硬件损伤、同步困难等挑战，需要系统化解决方案

Method: 采用OFDM波形，设计兼顾感知性能指标和硬件损伤影响的系统架构，开发空中同步信号处理技术，生成包含距离、多普勒频移和角度信息的周期图

Result: 通过基于当前5G参数化的蜂窝ISAC场景仿真验证了所提方案的有效性，展示了系统设计的可行性

Conclusion: 本文为6G双基地ISAC提供了实用的系统设计和信号处理方案，但未来部署仍面临开放挑战需要进一步研究

Abstract: This article presents and discusses challenges and solutions for practical issues in bistatic integrated sensing and communication (ISAC) in 6G networks. Considering orthogonal frequency-division multiplexing as the adopted waveform, a discussion on system design aiming to achieve both a desired sensing key performance indicators and limit the impact of hardware impairments is presented. In addition, signal processing techniques to enable over-the-air synchronization and generation of periodograms with range, Doppler shift, and angular information are discussed. Simulation results are then presented for a cellular-based ISAC scenario considering system parameterization compliant to current 5G and, finally, a discussion on open challenges for future deployments is presented.

</details>


### [9] [Joint Pilot and Unknown Data-based Localization for OFDM Opportunistic Radar Systems](https://arxiv.org/abs/2601.15785)
*Mathieu Reniers,Martin Willame,Jérôme Louveaux,Luc Vandendorpe*

Main category: eess.SP

TL;DR: 提出一种从通信信号数据载荷中提取定位信息的新方法，无需解码数据，利用FFT实现高效估计，在定位性能上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC方法要么仅依赖导频信号进行定位（忽略了数据符号中的雷达信息），要么依赖数据决策（定位性能受限于通信系统性能），需要一种能充分利用数据载荷中定位信息而不受解码限制的方法。

Method: 提出一种新颖方法，从数据载荷中提取定位信息而无需解码。考虑用户通信信号被配备均匀线性阵列天线的机会雷达捕获的场景，利用快速傅里叶变换实现高效估计。

Result: 通过数值仿真证明，该方法在定位性能上优于文献中的现有方法。

Conclusion: 该方法有效克服了现有ISAC定位方法的局限性，能够充分利用通信信号中的数据载荷信息，实现更优的定位性能，且与现有标准兼容。

Abstract: Integrated Sensing and Communications (ISAC) has emerged as a promising paradigm for Sixth Generation (6G) and Wi-Fi 7 networks, with the communication-centric approach being particularly attractive due to its compatibility with current standards. Typical communication signals comprise both deterministic known pilot signals and random unknown data payloads. Most existing approaches either rely solely on pilots for positioning, thereby ignoring the radar information present in the received data symbols that constitute the majority of each frame, or rely on data decisions, which bounds positioning performance to that of the communication system. To overcome these limitations, we propose a novel method that extracts positioning information from data payloads without decoding them. We consider an opportunistic scenario in which communication signals from a user are captured by an opportunistic radar equipped with a Uniform Linear Arrays of antennas. We show that, in this setting, the estimation can be efficiently implemented using Fast Fourier Transforms. Finally, we demonstrate superior localization performance compared to existing methods in the literature through numerical simulations.

</details>


### [10] [Adaptive Non-Uniform Sampling of Bandlimited Signals via Algorithm-Encoder Co-Design](https://arxiv.org/abs/2601.15790)
*Kaluguri Yashaswini,Anshu Arora,Satish Mulleti*

Main category: eess.SP

TL;DR: 提出基于算法-编码器协同设计的自适应非均匀采样框架，通过局部能量条件而非全局Nyquist约束来指导采样，设计VBT-IF-TEM编码器实现低于Nyquist率的完美重建。


<details>
  <summary>Details</summary>
Motivation: 传统均匀采样和固定阈值IF-TEM需要满足全局Nyquist约束，导致在信号缓慢变化区域过度采样。需要一种能根据信号局部特性自适应调整采样密度的框架，在保持重建精度的同时显著降低采样密度。

Method: 1) 从非均匀测量迭代重建算法的收敛分析出发，推导出基于信号和导数能量的局部充分条件；2) 设计可变偏置、可变阈值的积分-放电时间编码机(VBT-IF-TEM)，其触发机制专门用于满足局部收敛条件；3) 引入移位信号公式抑制在信号幅度接近零区域的过度触发；4) 使用时间编码和信号平均值离散表示模拟信号。

Result: 在合成信号、超声导波和ECG信号上的实验表明：相比均匀采样和传统IF-TEM，该框架能显著降低采样密度(低于Nyquist率)，同时保持准确重建。展示了采样密度、重建精度和收敛行为之间的可控权衡，可通过自适应参数选择进行调整。

Conclusion: 提出的算法-编码器协同设计框架通过局部能量条件实现了自适应非均匀采样，突破了传统全局Nyquist约束的限制。VBT-IF-TEM编码器能够在信号变化缓慢区域稀疏采样，在快速变化区域密集采样，在低于Nyquist率的情况下实现完美重建，为高效信号采样提供了新途径。

Abstract: We propose an adaptive non-uniform sampling framework for bandlimited signals based on an algorithm-encoder co-design perspective. By revisiting the convergence analysis of iterative reconstruction algorithms for non-uniform measurements, we derive a local, energy-based sufficient condition that governs reconstruction behavior as a function of the signal and derivative energies within each sampling interval. Unlike classical approaches that impose a global Nyquist-type bound on the inter-sample spacing, the proposed condition permits large gaps in slowly varying regions while enforcing denser sampling only where the signal exhibits rapid temporal variation. Building on this theoretical insight, we design a variable-bias, variable-threshold integrate-and-fire time encoding machine (VBT-IF-TEM) whose firing mechanism is explicitly shaped to enforce the derived local convergence condition. To ensure robustness, a shifted-signal formulation is introduced to suppress excessive firing in regions where the magnitude of the signal amplitude is close to zero or the local signal energy approaches zero. Using the proposed encoder, an analog signal is discretely represented by time encodings and signal averages, enabling perfect reconstruction via a standard iterative algorithm even when the local sampling rate falls below the Nyquist rate. Simulation results on synthetic signals and experiments on ultrasonic guided-wave and ECG signals demonstrate that the proposed framework achieves substantial reductions in sampling density compared to uniform sampling and conventional IF-TEMs, while maintaining accurate reconstruction. The results further highlight a controllable tradeoff between sampling density, reconstruction accuracy, and convergence behavior, which can be navigated through adaptive parameter selection.

</details>


### [11] [Dual-Mapping Sparse Vector Transmission for Short Packet URLLC](https://arxiv.org/abs/2601.15819)
*Yanfeng Zhang,Xu Zhu,Jinkai Zheng,Weiwei Yang,Xianhua Yu,Haiyong Zeng,Yujie Liu,Yong Liang Guan*

Main category: eess.SP

TL;DR: 提出一种基于双映射稀疏向量编码的短包传输方案，通过块稀疏映射和单元素稀疏映射提升传输性能


<details>
  <summary>Details</summary>
Motivation: 稀疏向量编码是下一代通信系统中超可靠低时延通信的有前景的短包传输方法，需要进一步提升其传输性能

Method: 提出双映射稀疏向量编码方案，将传输信息比特通过块稀疏映射和单元素稀疏映射映射到稀疏向量上，接收端采用两阶段解码算法

Result: 仿真结果表明，提出的DM-SVC方案在块错误率和频谱效率方面优于现有SVC方案

Conclusion: 双映射稀疏向量编码方案能有效提升短包传输性能，为超可靠低时延通信提供更好的解决方案

Abstract: Sparse vector coding (SVC) is a promising short-packet transmission method for ultra reliable low latency communication (URLLC) in next generation communication systems. In this paper, a dual-mapping SVC (DM-SVC) based short packet transmission scheme is proposed to further enhance the transmission performance of SVC. The core idea behind the proposed scheme lies in mapping the transmitted information bits onto sparse vectors via block and single-element sparse mappings. The block sparse mapping pattern is able to concentrate the transmit power in a small number of non-zero blocks thus improving the decoding accuracy, while the single-element sparse mapping pattern ensures that the code length does not increase dramatically with the number of transmitted information bits. At the receiver, a two-stage decoding algorithm is proposed to sequentially identify non-zero block indexes and single-element non-zero indexes. Extensive simulation results verify that proposed DM-SVC scheme outperforms the existing SVC schemes in terms of block error rate and spectral efficiency.

</details>


### [12] [Separable Delay And Doppler Estimation In Passive Radar](https://arxiv.org/abs/2601.15821)
*Mats Viberg,Daniele Gerosa,Tomas McKelvey,Patrik Dammert,Thomas Eriksson*

Main category: eess.SP

TL;DR: 提出一种用于被动雷达的可分离参数估计方法，将时延和多普勒参数分开估计，避免昂贵的二维搜索，降低计算复杂度和通信开销。


<details>
  <summary>Details</summary>
Motivation: 被动雷达系统使用分布式传感器网络，利用机会照射源信号检测和定位目标。传统方法需要联合估计时延和多普勒参数，这需要进行昂贵的二维搜索，计算复杂度高，在分布式雷达设置中通信开销大。

Method: 提出可分离估计方法：首先将数据分成可管理大小的批次，然后单独估计时延参数（避免二维搜索），最后利用恢复的批次间相干性估计多普勒参数。该方法针对慢速移动目标设计。

Result: 时延估计精度与传统全批次二维方法相当，多普勒参数估计在广泛参数范围内优于传统方法。同时显著降低了计算复杂度和分布式雷达设置中的通信开销。

Conclusion: 提出的可分离参数估计方法为被动雷达提供了一种有效的替代方案，在保持时延估计精度的同时，提高了多普勒估计性能，并显著降低了计算和通信成本。

Abstract: In passive radar, a network of distributed sensors exploit signals from so-called Illuminators-of-Opportunity to detect and localize targets. We consider the case where the IO signal is available at each receiver node through a reference channel, whereas target returns corrupted by interference are collected in a separate surveillance channel. The problem formulation is similar to an active radar that uses a noise-like waveform, or an integrated sensing and communication application. The available data is first split into batches of manageable size. In the direct approach, the target's time-delay and Doppler parameters are estimated jointly by incoherently combining the batch-wise data. We propose a new method to estimate the time-delay separately, thus avoiding a costly 2-D search. Our approach is designed for slowly moving targets, and the accuracy of the time-delay estimate is similar to that of the full batch-wise 2-D method. Given the time-delay, the coherency between batches can be restored when estimating the Doppler parameter. Thereby, the separable approach is found to yield superior Doppler estimates over a wide parameter range. In addition to reducing computational complexity, the proposed separable estimation technique also significantly reduces the communication overhead in a distributed radar setting.

</details>


### [13] [Performance Analysis of Digital Beamforming mmWave MIMO with Low-Resolution DACs/ADCs](https://arxiv.org/abs/2601.15831)
*Faruk Pasic,Mariam Mussbah,Stefan Schwarz,Markus Rupp,Fredrik Tufvesson,Christoph F. Mecklenbräuker*

Main category: eess.SP

TL;DR: 毫米波MIMO系统采用全数字波束成形和低分辨率量化时，4位DAC/ADC能在能耗和数据速率之间提供最佳折衷


<details>
  <summary>Details</summary>
Motivation: 未来无线通信需要毫米波MIMO系统提供高数据速率，全数字波束成形对信道估计精度要求高，但为保持功率效率必须使用低分辨率DAC/ADC，这会导致信号失真并降低系统性能

Method: 研究毫米波MIMO系统在全数字波束成形和低分辨率量化下的信道估计性能，评估系统在频谱效率和能量效率方面的表现

Result: 仿真结果表明，每个DAC/ADC采用4位中等量化分辨率能在能耗和可达到的数据速率之间提供有利的折衷

Conclusion: 毫米波MIMO系统中，4位量化分辨率是实现功率效率和系统性能平衡的合理选择

Abstract: Future wireless communications will rely on multiple-input multiple-output (MIMO) beamforming operating at millimeter wave (mmWave) frequency bands to deliver high data rates. To support flexible spatial processing and meet the demands of latency critical applications, it is essential to use fully digital mmWave MIMO beamforming, which relies on accurate channel estimation. However, ensuring power efficiency in fully digital mmWave MIMO systems requires the use of low-resolution digital-to-analog converters (DACs) and analog-to-digital converters (ADCs). The reduced resolution of these quantizers introduces distortion in both transmitted and received signals, ultimately degrading system performance. In this paper, we investigate the channel estimation performance of mmWave MIMO systems employing fully digital beamforming with low-resolution quantization, under practical system constraints. We evaluate the system performance in terms of spectral efficiency (SE) and energy efficiency (EE). Simulation results demonstrate that a moderate quantization resolutions of 4-bit per DAC/ADC offers a favorable trade-off between energy consumption and achievable data rate.

</details>


### [14] [Time-Varying Rician K-factor in Measured Vehicular Channels at cmWave and mmWave Bands](https://arxiv.org/abs/2601.15863)
*Faruk Pasic,Markus Hofer,Thomas Zemen,Andreas F. Molisch,Christoph F. Mecklenbräuker*

Main category: eess.SP

TL;DR: 本文通过多频段信道测量，分析了车对基础设施通信中不同频段（3.2GHz、34.3GHz、62.35GHz）的莱斯K因子特性及其与均方根时延扩展的关系。


<details>
  <summary>Details</summary>
Motivation: 未来车载通信系统将集成毫米波技术以提高数据传输速率。为了研究毫米波与传统厘米波频段之间的传播效应和小尺度衰落差异，需要进行多频段信道测量。莱斯K因子是表征小尺度衰落的关键参数。

Method: 在城区街道环境中进行车对基础设施多频段信道测量，分析三个频段（中心频率3.2GHz、34.3GHz、62.35GHz）的时变K因子。使用155.5MHz带宽和31.25μs的探测重复率测量数据，并分析K因子与均方根时延扩展的关系。

Result: 研究发现不同频段的莱斯K因子相似，且与均方根时延扩展存在相关性。

Conclusion: 毫米波和厘米波频段在车对基础设施通信中的小尺度衰落特性（通过K因子表征）相似，且K因子与时延扩展相关，这为未来多频段车载通信系统设计提供了重要参考。

Abstract: Future vehicular communication systems will integrate millimeter wave (mmWave) technology to enhance data transmission rates. To investigate the propagation effects and small-scale fading differences between mmWave and conventional centimeter wave (cmWave) bands, multi-band channel measurements have to be conducted. One key parameter to characterize small-scale fading is the Rician K-factor. In this paper, we analyze the time-varying K-factor of vehicle-to-infrastructure (V2I) channels across multiple frequency bands, measured in an urban street environment. Specifically, we investigate three frequency bands with center frequencies of 3.2 GHz, 34.3 GHz and 62.35 GHz using measurement data with 155.5 MHz bandwidth and a sounding repetition rate of 31.25 μs. Furthermore, we analyze the relationship between K-factor and root-mean-square (RMS) delay spread. We show that the Ricean K-factor is similar at different frequency bands and that is correlated with the RMS delay spread.

</details>


### [15] [Reconstructing Patched or Partial Holograms to allow for Whole Slide Imaging with a Self-Referencing Holographic Microscope](https://arxiv.org/abs/2601.15952)
*Philip Groult,Julia D. Sistermanns,Ellen Emken,Oliver Hayden,Wolfgang Utschick*

Main category: eess.SP

TL;DR: 提出一种用于宫颈涂片全玻片成像的重建算法，通过自参考三波数字全息显微镜实现，算法具有适应性，可在部分全息图和补丁全息图上工作。


<details>
  <summary>Details</summary>
Motivation: 计算机辅助诊断在细胞学筛查中取得显著进展，但全玻片成像（WSI）和定量相位成像（QPI）这两种技术尚未结合。WSI需要扫描多个补丁，而QPI能捕获更丰富的细胞信息且样本制备更简单，因此需要开发能将两者结合的新方法。

Method: 提出一种重建算法，使用自参考三波数字全息显微镜实现宫颈涂片的全玻片成像。算法具有适应性，可处理单次全息图，并能灵活适应各种输入，包括部分全息图和补丁全息图。

Result: 算法在测试的上皮细胞上表现良好，成功实现了全玻片成像与定量相位成像的结合，为宫颈涂片分析提供了新的成像方法。

Conclusion: 该工作首次将全玻片成像与定量相位成像技术结合，提出的自适应重建算法为宫颈细胞学筛查提供了新的计算机辅助诊断工具，论文已被2026年IEEE ISBI会议接收。

Abstract: The last decade has seen significant advances in computer-aided diagnostics for cytological screening, mainly through the improvement and integration of scanning techniques such as whole slide imaging (WSI) and the combination with deep learning. Simultaneously, new imaging techniques such as quantitative phase imaging (QPI) are being developed to capture richer cell information with less sample preparation. So far, the two worlds of WSI and QPI have not been combined. In this work, we present a reconstruction algorithm which makes whole slide imaging of cervical smears possible by using a self-referencing three-wave digital holographic microscope. Since a WSI is constructed by combining multiple patches, the algorithm is adaptive and can be used on partial holograms and patched holograms. We present the algorithm for a single shot hologram, the adaptations to make it flexible to various inputs and show that the algorithm performs well for the tested epithelial cells. This is a preprint of our paper, which has been accepted for publication in 2026 IEEE International Symposium on Biomedical Imaging (ISBI).

</details>


### [16] [Performance Scaling Laws for PD Array-based Receivers in IM/DD Optical Wireless Communication Systems](https://arxiv.org/abs/2601.15973)
*Aravindh Krishnamoorthy,Robert Schober,Harald Haas*

Main category: eess.SP

TL;DR: 光电探测器阵列接收机通过电域合并实现性能提升，但需要满足窄光束和高信噪比条件，且需联合优化多个参数而非单纯增加探测器数量


<details>
  <summary>Details</summary>
Motivation: 研究光电探测器阵列接收机在强度调制直接检测系统中的性能扩展规律，为下一代高带宽接收机设计提供指导

Method: 分析光电探测器阵列接收机的电域合并性能，考虑光功率与电功率之间的平方律关系，并与单探测器参考接收机进行信噪比和可达速率比较

Result: 光电探测器阵列在足够窄的光束和高于信噪比阈值时能提供性能增益，但单纯增加探测器数量不能提升性能，需要联合优化光束模式、电磁模式、接收功率和探测器位置

Conclusion: 研究模型和推导的见解为下一代高带宽光电探测器阵列接收机设计提供了实用指南，并突出了设计中的权衡取舍

Abstract: We study the performance scaling laws for electrical-domain combining in photodetector (PD) array-based receivers employing intensity modulation and direct detection, taking into account the inherent square-law relationship between the optical and electrical received powers. The performance of PD array-based systems is compared, in terms of signal-to-noise ratio (SNR) and achievable rate, to that of a reference receiver employing a single PD. Analytical and numerical results show that PD arrays provide performance gains for sufficiently narrow beams and above an SNR threshold. Furthermore, increasing the number of PDs alone does not enhance performance, and joint optimization of beam pattern, transverse electromagnetic mode, received power, and PD positions is necessary. Our model and derived insights provide practical guidelines and highlight the trade-offs for the design of next-generation high-bandwidth PD array receivers.

</details>


### [17] [Graph Topology Identification Based on Covariance Matching](https://arxiv.org/abs/2601.15999)
*Yongsheng Han,Raj Thilak Rajan,Geert Leus*

Main category: eess.SP

TL;DR: 提出CovMatch框架，通过匹配经验协方差与图模型理论协方差来推断网络拓扑，无需传统方法的非凸优化或结构限制假设。


<details>
  <summary>Details</summary>
Motivation: 传统图拓扑识别方法依赖概率模型或复杂优化，常面临非凸性问题，或需要无环性、正权重等限制性假设，限制了方法的通用性。

Method: 提出协方差匹配(CovMatch)框架，直接对齐观测数据的经验协方差与底层图模型的理论协方差。通过重新参数化，将图学习问题简化为锥形混合整数规划（无向图）或正交矩阵优化（有向图）。

Result: 数值实验表明，即使对于较大规模的图，该方法能有效恢复真实拓扑，在准确性上优于标准基线方法。

Conclusion: CovMatch为图拓扑识别提供了对数行列式或贝叶斯方法的强大替代方案，为在最小假设下学习复杂网络拓扑开辟了新途径。

Abstract: Graph topology identification (GTI) is a central challenge in networked systems, where the underlying structure is often hidden, yet nodal data are available. Conventional solutions to address these challenges rely on probabilistic models or complex optimization formulations, commonly suffering from non-convexity or requiring restrictive assumptions on acyclicity or positivity. In this paper, we propose a novel covariance matching (CovMatch) framework that directly aligns the empirical covariance of the observed data with the theoretical covariance implied by an underlying graph. We show that as long as the data-generating process permits an explicit covariance expression, CovMatch offers a unified route to topology inference.
  We showcase our methodology on linear structural equation models (SEMs), showing that CovMatch naturally handles both undirected and general sparse directed graphs - whether acyclic or positively weighted - without explicit knowledge of these structural constraints. Through appropriate reparameterizations, CovMatch simplifies the graph learning problem to either a conic mixed integer program for undirected graphs or an orthogonal matrix optimization for directed graphs. Numerical results confirm that, even for relatively large graphs, our approach efficiently recovers the true topology and outperforms standard baselines in accuracy. These findings highlight CovMatch as a powerful alternative to log-determinant or Bayesian methods for GTI, paving the way for broader research on learning complex network topologies with minimal assumptions.

</details>


### [18] [Low-Complexity Sparse Superimposed Coding for Ultra Reliable Low Latency Communications](https://arxiv.org/abs/2601.16012)
*Yanfeng Zhang,Xi'an Fan,Xu Zhu,Jinkai Zheng,Hui Liang,Weiwei Yang,Tom H. Luan*

Main category: eess.SP

TL;DR: 提出一种低复杂度稀疏叠加编码方案，通过设计稀疏码本结构显著降低编码解码复杂度，在BLER性能和计算复杂度之间取得良好平衡


<details>
  <summary>Details</summary>
Motivation: 稀疏叠加编码在超可靠低延迟通信中具有潜力，但传统方案因使用密集码本矩阵导致编码解码复杂度高，需要降低复杂度

Method: 设计稀疏码本结构，每个码字仅包含少量非零元素，使用传统的多径匹配追踪算法进行解码，利用码本稀疏性显著降低整体复杂度

Result: 仿真结果显示，所提方案在BLER性能和计算复杂度之间取得有利平衡，在不同传输块长度下表现出强鲁棒性

Conclusion: 提出的低复杂度稀疏叠加编码方案有效解决了传统方案复杂度高的问题，为超可靠低延迟通信中的短包传输提供了实用解决方案

Abstract: Sparse superimposed coding (SSC) has emerged as a promising technique for short-packet transmission in ultra-reliable low-latency communication scenarios. However, conventional SSC schemes often suffer from high encoding and decoding complexity due to the use of dense codebook matrices. In this paper, we propose a low-complexity SSC scheme by designing a sparse codebook structure, where each codeword contains only a small number of non-zero elements. The decoding is performed using the traditional multipath matching pursuit algorithm, and the overall complexity is significantly reduced by exploiting the sparsity of the codebook. Simulation results show that the proposed scheme achieves a favorable trade-off between BLER performance and computational complexity, and exhibits strong robustness across different transmission block lengths.

</details>


### [19] [Hybrid Channel Estimation with Quantized Phase Feedback for Over-the-Air Computation](https://arxiv.org/abs/2601.16054)
*Martin Dahl,Erik G. Larsson*

Main category: eess.SP

TL;DR: 提出混合信道估计方案，结合基于互易性和基于反馈的信道估计，降低空中计算的信令开销，重点研究量化相位反馈的影响


<details>
  <summary>Details</summary>
Motivation: 为了降低空中计算（over-the-air computation）的信令开销，需要设计更高效的信道估计方案。传统方法可能单独使用互易性或反馈机制，但存在各自的局限性，因此需要结合两者的优势

Method: 提出混合信道估计方案，将基于互易性和基于反馈的信道估计相结合。重点研究量化相位反馈的影响，假设幅度估计准确。提出两种变体：第一种仅通过反馈估计相位，第二种通过互易性估计信道相位，并结合最优量化相位反馈

Result: 通过仿真和理论分析表明，第二种变体（基于互易性估计信道相位，结合最优量化相位反馈）的性能优于第一种变体（仅通过反馈估计相位）。该方案允许根据幅度和相位的重要性分别选择估计精度

Conclusion: 混合信道估计方案能有效降低空中计算的信令开销，结合互易性和反馈机制的优势，特别是采用互易性估计相位并优化量化反馈的策略，能获得更好的性能表现

Abstract: To reduce the signaling overhead of over-the-air computation, a hybrid channel estimation scheme is proposed, where reciprocity-based and feedback-based channel estimation are combined. In particular, the impact of quantized phase-feedback is studied while the amplitude is assumed estimated exactly. The scheme enables selecting the estimation precision of amplitude and phase separately, depending on the importance of each. Two variants of the scheme are proposed: As shown through simulations and theory, the second variant with reciprocity-based estimation of the channel phase, and optimal quantization of phase feedback, can outperform the first variant estimating the phase by feedback only.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [20] [DynamicSound simulator for simulating moving sources and microphone arrays](https://arxiv.org/abs/2601.15433)
*Luca Barbisan,Marco Levorato,Fabrizio Riente*

Main category: eess.AS

TL;DR: DynamicSound是一个开源声学仿真框架，用于生成多通道音频，支持三维空间中连续移动的声源和任意配置的麦克风阵列，考虑了传播延迟、多普勒效应、距离衰减等物理效应。


<details>
  <summary>Details</summary>
Motivation: 现有的声学仿真器大多针对室内环境设计，仅限于静态声源，无法处理移动声源、移动麦克风或长距离传播场景，而现代机器学习算法需要大量灵活且真实的音频数据进行训练。

Method: 开发了一个开源声学仿真框架，支持三维空间中连续移动的声源和任意配置的麦克风阵列，明确考虑了有限声传播延迟、多普勒效应、距离相关衰减、空气吸收和一阶平面反射等物理效应。

Result: 与现有开源工具的比较评估表明，生成的信号在不同声源位置和声学条件下保持了高空间保真度，能够准确再现麦克风间的时间延迟、电平差异和环境引起的频谱着色。

Conclusion: 该开源框架通过生成受控且可重复条件下的真实多通道音频，为现代空间音频和声源定位算法的开发、训练和评估提供了灵活且可复现的工具。

Abstract: Developing algorithms for sound classification, detection, and localization requires large amounts of flexible and realistic audio data, especially when leveraging modern machine learning and beamforming techniques. However, most existing acoustic simulators are tailored for indoor environments and are limited to static sound sources, making them unsuitable for scenarios involving moving sources, moving microphones, or long-distance propagation. This paper presents DynamicSound an open-source acoustic simulation framework for generating multichannel audio from one or more sound sources with the possibility to move them continuously in three-dimensional space and recorded by arbitrarily configured microphone arrays. The proposed model explicitly accounts for finite sound propagation delays, Doppler effects, distance-dependent attenuation, air absorption, and first-order reflections from planar surfaces, yielding temporally consistent spatial audio signals. Unlike conventional mono or stereo simulators, the proposed system synthesizes audio for an arbitrary number of virtual microphones, accurately reproducing inter-microphone time delays, level differences, and spectral coloration induced by the environment. Comparative evaluations with existing open-source tools demonstrate that the generated signals preserve high spatial fidelity across varying source positions and acoustic conditions. By enabling the generation of realistic multichannel audio under controlled and repeatable conditions, the proposed open framework provides a flexible and reproducible tool for the development, training, and evaluation of modern spatial audio and sound-source localization algorithms.

</details>


### [21] [Distributed Multichannel Active Noise Control with Asynchronous Communication](https://arxiv.org/abs/2601.15653)
*Junwei Ji,Dongyuan Shi,Boxiang Wang,Ziyi Yang,Haowen Li,Woon-Seng Gan*

Main category: eess.AS

TL;DR: 提出异步通信分布式多通道主动噪声控制系统，通过节点仅在性能下降时请求通信来减少通信开销，同时保持协同降噪效果。


<details>
  <summary>Details</summary>
Motivation: 传统分布式多通道主动噪声控制方法需要频繁同步通信，导致高通信开销，限制了系统在异构网络中的可扩展性。

Method: 采用异步通信策略，每个节点运行权重约束滤波x LMS算法，仅在本地降噪性能下降时请求通信。其他节点传输本地控制滤波器与中心点之间的权重差异，用于更新控制滤波器和中心点。

Result: 仿真结果表明，提出的异步通信DMCANC系统在显著减少通信负载的同时，仍能保持有效的噪声降低，提高了异构网络的可扩展性。

Conclusion: 异步通信策略使分布式多通道主动噪声控制系统能够在减少通信开销的同时保持协同降噪性能，适用于异构网络环境。

Abstract: Distributed multichannel active noise control (DMCANC) offers effective noise reduction across large spatial areas by distributing the computational load of centralized control to multiple low-cost nodes. Conventional DMCANC methods, however, typically assume synchronous communication and require frequent data exchange, resulting in high communication overhead. To enhance efficiency and adaptability, this work proposes an asynchronous communication strategy where each node executes a weight-constrained filtered-x LMS (WCFxLMS) algorithm and independently requests communication only when its local noise reduction performance degrades. Upon request, other nodes transmit the weight difference between their local control filter and the center point in WCFxLMS, which are then integrated to update both the control filter and the center point. This design enables nodes to operate asynchronously while preserving cooperative behavior. Simulation results demonstrate that the proposed asynchronous communication DMCANC (ACDMCANC) system maintains effective noise reduction with significantly reduced communication load, offering improved scalability for heterogeneous networks.

</details>


### [22] [A Stabilized Hybrid Active Noise Control Algorithm of GFANC and FxNLMS with Online Clustering](https://arxiv.org/abs/2601.15889)
*Zhengding Luo,Haozhe Ma,Boxiang Wang,Ziyi Yang,Dongyuan Shi,Woon-Seng Gan*

Main category: eess.AS

TL;DR: 提出混合GFANC-FxNLMS算法，结合GFANC的快速响应和FxNLMS的低稳态误差优势，通过在线聚类避免不必要的重初始化，实现快速响应、低误差和高稳定性。


<details>
  <summary>Details</summary>
Motivation: FxNLMS算法收敛慢且有发散风险，但能达到低稳态误差；GFANC方法响应快但缺乏适应性，稳态误差大。需要结合两者优势，实现快速响应和低稳态误差的主动噪声控制。

Method: 提出混合GFANC-FxNLMS算法：GFANC提供帧级控制滤波器作为FxNLMS初始化，FxNLMS在采样率下连续自适应。引入在线聚类模块避免GFANC生成滤波器微小变化导致的不必要重初始化，提高系统稳定性。

Result: 仿真结果表明，所提算法实现了快速响应、极低稳态误差和高稳定性，仅需一个预训练的宽带滤波器。

Conclusion: 混合GFANC-FxNLMS算法成功结合了两种方法的互补优势，通过在线聚类机制解决了重初始化导致的稳定性问题，为主动噪声控制提供了高效解决方案。

Abstract: The Filtered-x Normalized Least Mean Square (FxNLMS) algorithm suffers from slow convergence and a risk of divergence, although it can achieve low steady-state errors after sufficient adaptation. In contrast, the Generative Fixed-Filter Active Noise Control (GFANC) method offers fast response speed, but its lack of adaptability may lead to large steady-state errors. This paper proposes a hybrid GFANC-FxNLMS algorithm to leverage the complementary advantages of both approaches. In the hybrid GFANC-FxNLMS algorithm, GFANC provides a frame-level control filter as an initialization for FxNLMS, while FxNLMS performs continuous adaptation at the sampling rate. Small variations in the GFANC-generated filter may repeatedly reinitialize FxNLMS, interrupting its adaptation process and destabilizing the system. An online clustering module is introduced to avoid unnecessary re-initializations and improve system stability. Simulation results show that the proposed algorithm achieves fast response, very low steady-state error, and high stability, requiring only one pre-trained broadband filter.

</details>


### [23] [Timbre-Aware LLM-based Direct Speech-to-Speech Translation Extendable to Multiple Language Pairs](https://arxiv.org/abs/2601.16023)
*Lalaram Arya,Mrinmoy Bhattacharjee,Adarsh C. R.,S. R. Mahadeva Prasanna*

Main category: eess.AS

TL;DR: DS2ST-LM：基于多语言大语言模型的单阶段端到端语音翻译框架，通过合成数据缓解数据稀缺，使用线性投影器实现最佳性能，在多个语言对中超越级联系统


<details>
  <summary>Details</summary>
Motivation: 现有端到端语音翻译系统面临三大挑战：平行语音数据稀缺时语义-声学对齐不稳定、说话人身份难以保留、多语言扩展性有限。需要开发更稳定、可扩展且能保持说话人特征的解决方案。

Method: 提出DS2ST-LM框架，整合Whisper语音编码器、可学习投影模块、Qwen2-0.5B大语言模型和音色控制声码器。构建1000小时双语语料库GigaS2S-1000，研究两种语义标记生成策略（S3标记和文本衍生标记），评估三种投影架构（线性、Conv1D-线性、Q-Former）。

Result: DS2ST-LM在词汇（BLEU、METEOR）和语义（BLEURT、COMET）指标上均超越传统级联系统和ST+TTS基线，扩展到法语、西班牙语、德语、印地语、孟加拉语、乌尔都语等多个语言对。简单线性投影器性能最佳，音色感知合成在说话人相似度和感知自然度上超越先前系统。

Conclusion: DS2ST-LM展示了基于大语言模型的端到端语音翻译框架的有效性，通过合成数据缓解数据稀缺，线性投影器实现最佳性能，音色控制保留说话人特征，为多语言语音翻译提供了可扩展的解决方案。

Abstract: Direct Speech-to-Speech Translation (S2ST) has gained increasing attention for its ability to translate speech from one language to another, while reducing error propagation and latency inherent in traditional cascaded pipelines. However, existing direct S2ST systems continue to face notable challenges, including instability in semantic-acoustic alignment when parallel speech data is scarce, difficulty in preserving speaker identity, and limited multilingual scalability. In this work, we introduce DS2ST-LM, a scalable, single-stage direct S2ST framework leveraging a multilingual Large Language Model (LLM). The architecture integrates a Whisper speech encoder, a learnable projection module, a Qwen2-0.5B LLM, and a timbre-controlled vocoder. We construct GigaS2S-1000, a 1000-hour bilingual corpus by extending the GigaST dataset with high-fidelity synthetic target speech, and show that this synthetic data alleviates data scarcity to some extent. We investigate two semantic token generation strategies: speech-derived S3 tokens and text-derived tokens generated by a pre-trained LLM, and analyze their impact on training stability and semantic consistency. We further evaluate three projection architectures (Linear, Conv1D-Linear, and Q-Former) and observe that while higher-capacity projectors converge faster, the simple Linear projector achieves higher performance. Extensive experiments demonstrate that DS2ST-LM outperforms traditional cascaded and ST (Qwen-Audio) + TTS baselines across both lexical (BLEU, METEOR) and semantic (BLEURT, COMET) metrics, while extending to multiple language pairs, including French, Spanish, German, Hindi, Bengali, and Urdu. Furthermore, we incorporate timbre-aware speech synthesis to preserve speaker information, enabling DS2ST-LM to surpass prior direct S2ST systems in both speaker similarity and perceptual naturalness.

</details>


### [24] [Loose coupling of spectral and spatial models for multi-channel diarization and enhancement of meetings in dynamic environments](https://arxiv.org/abs/2601.16077)
*Adrian Meise,Tobias Cord-Landwehr,Christoph Boeddeker,Marc Delcroix,Tomohiro Nakatani,Reinhold Haeb-Umbach*

Main category: eess.AS

TL;DR: 提出一种新颖的联合空间和频谱混合模型，通过概率建模将说话人和位置索引关联，解决移动说话人的声源分离问题


<details>
  <summary>Details</summary>
Motivation: 麦克风阵列的声音捕捉可以利用空间和频谱信息进行说话人分离和信号增强，但当说话人移动时，空间位置与说话人之间不存在一一对应关系，需要解决这一挑战

Method: 提出联合空间和频谱混合模型，包含两个松散耦合的子模型，通过概率建模说话人和位置索引之间的关系，允许说话人在不同位置说话

Result: 在模拟说话人位置变化的LibriCSS数据集上实验，相比紧密耦合子系统取得了显著改进

Conclusion: 通过概率耦合空间和频谱信息的混合模型能有效处理移动说话人的声源分离问题，为会议转录中的说话人分离和信号增强提供了更好的解决方案

Abstract: Sound capture by microphone arrays opens the possibility to exploit spatial, in addition to spectral, information for diarization and signal enhancement, two important tasks in meeting transcription. However, there is no one-to-one mapping of positions in space to speakers if speakers move. Here, we address this by proposing a novel joint spatial and spectral mixture model, whose two submodels are loosely coupled by modeling the relationship between speaker and position index probabilistically. Thus, spatial and spectral information can be jointly exploited, while at the same time allowing for speakers speaking from different positions. Experiments on the LibriCSS data set with simulated speaker position changes show great improvements over tightly coupled subsystems.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [25] [Abusive music and song transformation using GenAI and LLMs](https://arxiv.org/abs/2601.15348)
*Jiyang Choi,Rohitash Chandra*

Main category: cs.SD

TL;DR: 使用生成式AI和LLM自动转换流行音乐中的辱骂性歌词和演唱方式，通过改变语调、强度和情感表达来减少攻击性内容，同时保持音乐连贯性。


<details>
  <summary>Details</summary>
Motivation: 音乐中的暴力和辱骂内容可能影响听众情绪和行为，甚至使攻击性行为正常化或强化有害刻板印象。传统的内容审查（如静音或替换单个词语）可能引发"禁果效应"，反而让被审查内容更具吸引力。

Method: 使用生成式人工智能和大语言模型自动转换流行音乐中的辱骂性歌词和演唱方式。不是简单地静音或替换单个词语，而是改变语调、强度和情感表达。对四首英文歌曲及其转换版本进行对比分析，通过声学和情感分析评估变化。

Result: 生成式AI显著降低了演唱攻击性：声学分析显示谐噪比、倒谱峰值突出度和抖动指标均有改善；情感分析显示攻击性减少了63.3-85.6%，副歌部分改善最大（减少高达88.6%）。转换后的版本保持了音乐连贯性，同时减少了有害内容。

Conclusion: 该方法展示了生成式AI在创造更安全聆听体验同时保持艺术表达的潜力，为传统内容审查提供了有前景的替代方案，避免了"禁果效应"。

Abstract: Repeated exposure to violence and abusive content in music and song content can influence listeners' emotions and behaviours, potentially normalising aggression or reinforcing harmful stereotypes. In this study, we explore the use of generative artificial intelligence (GenAI) and Large Language Models (LLMs) to automatically transform abusive words (vocal delivery) and lyrical content in popular music. Rather than simply muting or replacing a single word, our approach transforms the tone, intensity, and sentiment, thus not altering just the lyrics, but how it is expressed. We present a comparative analysis of four selected English songs and their transformed counterparts, evaluating changes through both acoustic and sentiment-based lenses. Our findings indicate that Gen-AI significantly reduces vocal aggressiveness, with acoustic analysis showing improvements in Harmonic to Noise Ratio, Cepstral Peak Prominence, and Shimmer. Sentiment analysis reduced aggression by 63.3-85.6\% across artists, with major improvements in chorus sections (up to 88.6\% reduction). The transformed versions maintained musical coherence while mitigating harmful content, offering a promising alternative to traditional content moderation that avoids triggering the "forbidden fruit" effect, where the censored content becomes more appealing simply because it is restricted. This approach demonstrates the potential for GenAI to create safer listening experiences while preserving artistic expression.

</details>


### [26] [DeepASMR: LLM-Based Zero-Shot ASMR Speech Generation for Anyone of Any Voice](https://arxiv.org/abs/2601.15596)
*Leying Zhang,Tingxiao Zhou,Haiyang Sun,Mengxiao Bi,Yanmin Qian*

Main category: cs.SD

TL;DR: DeepASMR是首个零样本ASMR生成框架，仅需说话者普通朗读语音的短片段即可合成其声音的高保真ASMR，无需目标说话者的耳语训练数据。


<details>
  <summary>Details</summary>
Motivation: 现代TTS系统在朗读式语音上已实现高保真，但难以生成ASMR这种用于放松的低强度专业语音风格，主要挑战包括ASMR的细微特征（常为无声音）和零样本说话者适应的需求。

Method: 1) 发现离散语音token可软分解ASMR风格与说话者音色；2) 提出两阶段流程：使用LLM进行内容-风格编码，使用流匹配声学解码器进行音色重建；3) 构建DeepASMR-DB（670小时英中多说话者ASMR语料库）和包含客观指标、人工听测、LLM评分及无声音分析的新评估协议。

Result: DeepASMR在ASMR生成的自然度和风格保真度上达到最先进水平，适用于任何声音，同时在正常语音合成上保持竞争力。

Conclusion: DeepASMR首次实现了零样本ASMR生成，仅需说话者普通语音片段即可合成其声音的高质量ASMR，为个性化放松语音合成提供了有效解决方案。

Abstract: While modern Text-to-Speech (TTS) systems achieve high fidelity for read-style speech, they struggle to generate Autonomous Sensory Meridian Response (ASMR), a specialized, low-intensity speech style essential for relaxation. The inherent challenges include ASMR's subtle, often unvoiced characteristics and the demand for zero-shot speaker adaptation. In this paper, we introduce DeepASMR, the first framework designed for zero-shot ASMR generation. We demonstrate that a single short snippet of a speaker's ordinary, read-style speech is sufficient to synthesize high-fidelity ASMR in their voice, eliminating the need for whispered training data from the target speaker. Methodologically, we first identify that discrete speech tokens provide a soft factorization of ASMR style from speaker timbre. Leveraging this insight, we propose a two-stage pipeline incorporating a Large Language Model (LLM) for content-style encoding and a flow-matching acoustic decoder for timbre reconstruction. Furthermore, we contribute DeepASMR-DB, a comprehensive 670-hour English-Chinese multi-speaker ASMR speech corpus, and introduce a novel evaluation protocol integrating objective metrics, human listening tests, LLM-based scoring and unvoiced speech analysis. Extensive experiments confirm that DeepASMR achieves state-of-the-art naturalness and style fidelity in ASMR generation for anyone of any voice, while maintaining competitive performance on normal speech synthesis.

</details>


### [27] [Qwen3-TTS Technical Report](https://arxiv.org/abs/2601.15621)
*Hangrui Hu,Xinfa Zhu,Ting He,Dake Guo,Bin Zhang,Xiong Wang,Zhifang Guo,Ziyue Jiang,Hongkun Hao,Zishan Guo,Xinyu Zhang,Pei Zhang,Baosong Yang,Jin Xu,Jingren Zhou,Junyang Lin*

Main category: cs.SD

TL;DR: Qwen3-TTS系列是先进的文本转语音模型，支持多语言、可控、鲁棒和流式合成，具有3秒语音克隆和描述控制能力，采用双轨LM架构和两种语音分词器，在多项评测中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够支持多语言、可控性强、鲁棒性好且支持流式合成的先进文本转语音系统，满足实际应用中对语音合成质量、效率和灵活性的需求。

Method: 采用双轨语言模型架构实现实时合成，配合两种语音分词器：1) Qwen-TTS-Tokenizer-25Hz单码本编解码器，强调语义内容，可与Qwen-Audio无缝集成，通过块状DiT实现流式波形重建；2) Qwen-TTS-Tokenizer-12Hz多码本设计，实现极低比特率和超低延迟流式合成，支持97ms的首包发射。

Result: 在超过500万小时10种语言的语音数据上训练，在多项客观和主观评测（如TTS多语言测试集、InstructTTSEval和长语音测试集）中达到最先进的性能水平。

Conclusion: Qwen3-TTS系列在语音合成质量、效率和可控性方面表现出色，通过Apache 2.0许可证开源模型和分词器，促进社区研究和开发。

Abstract: In this report, we present the Qwen3-TTS series, a family of advanced multilingual, controllable, robust, and streaming text-to-speech models. Qwen3-TTS supports state-of-the-art 3-second voice cloning and description-based control, allowing both the creation of entirely novel voices and fine-grained manipulation over the output speech. Trained on over 5 million hours of speech data spanning 10 languages, Qwen3-TTS adopts a dual-track LM architecture for real-time synthesis, coupled with two speech tokenizers: 1) Qwen-TTS-Tokenizer-25Hz is a single-codebook codec emphasizing semantic content, which offers seamlessly integration with Qwen-Audio and enables streaming waveform reconstruction via a block-wise DiT. 2) Qwen-TTS-Tokenizer-12Hz achieves extreme bitrate reduction and ultra-low-latency streaming, enabling immediate first-packet emission ($97\,\mathrm{ms}$) through its 12.5 Hz, 16-layer multi-codebook design and a lightweight causal ConvNet. Extensive experiments indicate state-of-the-art performance across diverse objective and subjective benchmark (e.g., TTS multilingual test set, InstructTTSEval, and our long speech test set). To facilitate community research and development, we release both tokenizers and models under the Apache 2.0 license.

</details>


### [28] [EmotionThinker: Prosody-Aware Reinforcement Learning for Explainable Speech Emotion Reasoning](https://arxiv.org/abs/2601.15668)
*Dingdong Wang,Shujie Liu,Tianhua Zhang,Youjun Chen,Jinyu Li,Helen Meng*

Main category: cs.SD

TL;DR: 该论文提出EmotionThinker，将语音情感识别重新定义为深度推理问题，通过强化学习生成具有可解释性的情感预测，并构建了包含35K条思维链标注的数据集。


<details>
  <summary>Details</summary>
Motivation: 当前语音大语言模型和传统语音情感识别系统将情感理解简单视为分类问题，缺乏预测的可解释性，且未能充分利用大语言模型的表达和推理能力。

Method: 1. 构建EmotionCoT-35K数据集，包含思维链标注和详细描述；2. 开发增强韵律感知的基础模型EmotionThinker-Base；3. 提出GRPO-PTR强化学习方法，结合渐进式推理奖励和信任度权重。

Result: EmotionThinker在情感准确性和解释质量上均优于先前最先进的评估模型，推进了语音情感识别向可解释多模态推理的发展。

Conclusion: 该研究首次将语音情感识别重新定义为深度推理问题，通过强化学习实现了准确且可解释的情感预测，为多模态推理开辟了新方向。

Abstract: Emotional information in speech plays a unique role in multimodal perception. However, current Speech Large Language Models (SpeechLLMs), similar to conventional speech emotion recognition (SER) systems, still treat emotion understanding as a simple classification problem. This provides limited interpretability of predictions, while leaving the LLMs' expressive and reasoning capabilities underutilized. In this work, we take the first step to reformulate SER as a deep reasoning problem through reinforcement learning (RL). We propose EmotionThinker, which is designed to generate accurate emotion predictions with interpretable explanations grounded in fine-grained acoustic cues. To achieve this, we first construct EmotionCoT-35K, an emotional reasoning dataset with Chain-of-Thought annotations and detailed captions. Second, we observe that current SpeechLLMs exhibit weak prosody perception, whereas prosodic cues constitute fundamental signals for interpreting emotions. To address this, we develop the prosody-enhanced foundation model EmotionThinker-Base, and demonstrate that prosody enhancement improves emotion understanding. Third, we introduce Group-Relative-Policy-Optimization with Progressive-Trust-aware-Reasoning-Reward (GRPO-PTR) for RL. Different from standard GRPO, which relies only on rule-based outcome rewards, GRPO-PTR progressively introduces reasoning reward, dynamically adjusts it with a trustworthiness weight reflecting the alignment between reasoning and outcome, and evaluates the overall reasoning quality with a reward model based on multi-dimensional criteria. EmotionThinker outperforms previous state-of-the-art evaluation models both in emotion accuracy and explanation quality, advancing SER toward interpretable multimodal reasoning. Project page: https://github.com/dingdongwang/EmotionThinker

</details>


### [29] [Bridging the Perception Gap: A Lightweight Coarse-to-Fine Architecture for Edge Audio Systems](https://arxiv.org/abs/2601.15676)
*Hengfan Zhang,Yueqian Lin,Hai Helen Li,Yiran Chen*

Main category: cs.SD

TL;DR: CoFi-Agent：一种混合边缘-云架构，通过本地快速感知和条件性云端细粒度推理，在音频-语言模型中平衡感知深度与计算效率。


<details>
  <summary>Details</summary>
Motivation: 边缘部署音频-语言模型面临感知深度与计算效率的矛盾：轻量级本地模型只能生成通用摘要，缺乏多步音频推理所需的细微证据；而全量云端卸载则带来不可接受的延迟、带宽成本和隐私风险。

Method: 提出CoFi-Agent混合架构，在边缘服务器和网关上运行。首先在本地7B音频-语言模型上进行快速单次感知，云端控制器检测不确定性并触发条件性细粒度推理，为设备端工具（如时间重听和本地ASR）生成轻量级计划。

Result: 在MMAR基准测试中，CoFi-Agent将准确率从27.20%提升至53.60%，同时比始终开启的推理管道实现了更好的准确率-效率权衡。

Conclusion: CoFi-Agent通过工具增强的条件性边缘-云协作，在实际系统约束下弥合了感知差距，为音频-语言模型的边缘部署提供了有效解决方案。

Abstract: Deploying Audio-Language Models (Audio-LLMs) on edge infrastructure exposes a persistent tension between perception depth and computational efficiency. Lightweight local models tend to produce passive perception - generic summaries that miss the subtle evidence required for multi-step audio reasoning - while indiscriminate cloud offloading incurs unacceptable latency, bandwidth cost, and privacy risk. We propose CoFi-Agent (Tool-Augmented Coarse-to-Fine Agent), a hybrid architecture targeting edge servers and gateways. It performs fast local perception and triggers conditional forensic refinement only when uncertainty is detected. CoFi-Agent runs an initial single-pass on a local 7B Audio-LLM, then a cloud controller gates difficult cases and issues lightweight plans for on-device tools such as temporal re-listening and local ASR. On the MMAR benchmark, CoFi-Agent improves accuracy from 27.20% to 53.60%, while achieving a better accuracy-efficiency trade-off than an always-on investigation pipeline. Overall, CoFi-Agent bridges the perception gap via tool-enabled, conditional edge-cloud collaboration under practical system constraints.

</details>


### [30] [PF-D2M: A Pose-free Diffusion Model for Universal Dance-to-Music Generation](https://arxiv.org/abs/2601.15872)
*Jaekwon Im,Natalia Polouliakh,Taketo Akama*

Main category: cs.SD

TL;DR: PF-D2M：基于扩散模型的通用舞蹈到音乐生成方法，通过渐进训练策略解决数据稀缺问题，在舞蹈-音乐对齐和音乐质量上达到SOTA


<details>
  <summary>Details</summary>
Motivation: 现有舞蹈到音乐生成方法通常依赖单一人体舞者提取的运动特征和有限的数据集，限制了在真实场景（多舞者、非人类舞者）中的应用性能

Method: 提出PF-D2M，基于扩散模型的通用舞蹈到音乐生成模型，从舞蹈视频中提取视觉特征，采用渐进训练策略解决数据稀缺和泛化问题

Result: 主客观评估均显示PF-D2M在舞蹈-音乐对齐和音乐质量方面达到最先进的性能

Conclusion: PF-D2M通过视觉特征提取和渐进训练策略，有效解决了现有方法的局限性，在通用舞蹈到音乐生成任务上表现出色

Abstract: Dance-to-music generation aims to generate music that is aligned with dance movements. Existing approaches typically rely on body motion features extracted from a single human dancer and limited dance-to-music datasets, which restrict their performance and applicability to real-world scenarios involving multiple dancers and non-human dancers. In this paper, we propose PF-D2M, a universal diffusion-based dance-to-music generation model that incorporates visual features extracted from dance videos. PF-D2M is trained with a progressive training strategy that effectively addresses data scarcity and generalization challenges. Both objective and subjective evaluations show that PF-D2M achieves state-of-the-art performance in dance-music alignment and music quality.

</details>


### [31] [U3-xi: Pushing the Boundaries of Speaker Recognition via Incorporating Uncertainty](https://arxiv.org/abs/2601.15719)
*Junjie Li,Kong Aik Lee*

Main category: cs.SD

TL;DR: 提出U3-xi框架，通过估计帧级不确定性为说话人嵌入分配自适应权重，提升自动说话人验证系统的鲁棒性和可解释性


<details>
  <summary>Details</summary>
Motivation: 现实场景中，帧级表示不仅包含说话人相关信息，还包含各种干扰因素，不同帧对最终说话人表示的贡献不均等，需要更可靠的说话人嵌入不确定性估计方法

Method: 提出U3-xi框架，包含三种不确定性监督策略：1) 说话人级不确定性监督（随机方差损失）；2) 全局级不确定性监督（自适应softmax缩放）；3) 基于Transformer编码器与多视图自注意力的不确定性估计模块

Result: U3-xi是模型无关的，可应用于多种说话人编码器。应用于ECAPA-TDNN时，在VoxCeleb1测试集上EER相对提升21.1%，minDCF相对提升15.57%

Conclusion: U3-xi框架通过不确定性估计为说话人嵌入提供自适应权重分配，显著提升自动说话人验证性能，同时增强模型的可解释性

Abstract: An utterance-level speaker embedding is typically obtained by aggregating a sequence of frame-level representations. However, in real-world scenarios, individual frames encode not only speaker-relevant information but also various nuisance factors. As a result, different frames contribute unequally to the final utterance-level speaker representation for Automatic Speaker Verification systems. To address this issue, we propose to estimate the inherent uncertainty of each frame and assign adaptive weights accordingly, where frames with higher uncertainty receive lower attention. Based on this idea, we present U3-xi, a comprehensive framework designed to produce more reliable and interpretable uncertainty estimates for speaker embeddings. Specifically, we introduce several strategies for uncertainty supervision. First, we propose speaker-level uncertainty supervision via a Stochastic Variance Loss, where the distance between an utterance embedding and its corresponding speaker centroid serves as a pseudo ground truth for uncertainty learning. Second, we incorporate global-level uncertainty supervision by injecting the predicted uncertainty into the sof tmax scale during training. This adaptive scaling mechanism adjusts the sharpness of the decision boundary according to sample difficulty, providing global guidance. Third, we redesign the uncertainty estimation module by integrating a Transformer encoder with multi-view self-attention, enabling the model to capture rich local and long-range temporal dependencies. Comprehensive experiments demonstrate that U3-xi is model-agnostic and can be seamlessly applied to various speaker encoders. In particular, when applied to ECAPA-TDNN, it achieves 21.1% and 15.57% relative improvements on the VoxCeleb1 test sets in terms of EER and minDCF, respectively.

</details>


### [32] [Distillation-based Layer Dropping (DLD) Effective End-to-end Framework for Dynamic Speech Networks](https://arxiv.org/abs/2601.16117)
*Abdul Hannan,Daniele Falavigna,Shah Nawaz,Mubashir Noman,Markus Schedl,Alessio Brutti*

Main category: cs.SD

TL;DR: 提出基于知识蒸馏的层丢弃框架DLD，结合知识蒸馏与层丢弃技术，在动态语音网络中实现最先进的性能，显著降低词错误率并减少训练时间。


<details>
  <summary>Details</summary>
Motivation: 边缘设备在资源受限且变化的环境中运行，需要能够适应可用资源限制的动态架构。现有的层丢弃方法在高低丢弃情况下会严重影响动态模型的性能，恶化性能-计算权衡。

Method: 提出蒸馏基的层丢弃框架DLD，以端到端方式有效结合知识蒸馏和层丢弃技术，通过知识蒸馏提升层丢弃模型的性能。

Result: 在三个公共基准测试上使用conformer和WavLM等知名语音识别方法进行综合实验，在高丢弃和无丢弃情况下分别降低词错误率9.32%和2.25%，同时减少33.3%的训练时间。

Conclusion: DLD框架通过结合知识蒸馏和层丢弃技术，有效解决了动态语音网络中性能-计算权衡问题，在边缘设备资源受限环境中实现了更好的自适应性能。

Abstract: Edge devices operate in constrained and varying resource settings, requiring dynamic architectures that can adapt to limitations of the available resources. To meet such demands, layer dropping ($\mathcal{LD}$) approach is typically used to transform static models into dynamic ones by skipping parts of the network along with reducing overall computational complexity. However, existing $\mathcal{LD}$ methods greatly impact the dynamic model's performance for low and high dropping cases, deteriorating the performance-computation trade-off. To this end, we propose a distillation-based layer dropping (DLD) framework that effectively combines the capabilities of knowledge distillation and $\mathcal{LD}$ in an end-to-end fashion, thereby achieving state-of-the-art performance for dynamic speech networks. Comprehensive experimentation utilizing well-known speech recognition methods, including conformer and WavLM, on three public benchmarks demonstrates the effectiveness of our framework, reducing the word error rate by $9.32\%$ and $2.25\%$ for high and no dropping cases with $33.3\%$ reduction in training time.

</details>


### [33] [Pay (Cross) Attention to the Melody: Curriculum Masking for Single-Encoder Melodic Harmonization](https://arxiv.org/abs/2601.16150)
*Maximos Kaliakatsos-Papakostas,Dimos Makris,Konstantinos Soiledis,Konstantinos-Theodoros Tsamis,Vassilis Katsouros,Emilios Cambouropoulos*

Main category: cs.SD

TL;DR: 提出FF训练课程，通过保持所有和声标记被遮蔽若干训练步，然后逐步完全解蔽来增强旋律-和声交互，在单编码器旋律和声化任务中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有单编码器Transformer方法将和声化视为遮蔽序列建模问题，但受离散扩散启发的训练课程导致旋律与和声之间的注意力较弱，限制了旋律线索的利用，特别是在域外情境下

Method: 提出FF训练课程：保持所有和声标记被遮蔽若干训练步，然后在训练中逐步完全解蔽整个序列以增强旋律-和声交互。系统评估该方法在多个实验轴上的表现

Result: FF课程在几乎所有指标上一致优于基线方法，在域外评估中表现尤为突出。四分音符量化、小节标记交织和音高类别旋律表示在FF设置中具有优势

Conclusion: 训练课程对于实现有效的旋律条件化至关重要，全到全解蔽为单编码器和声化提供了稳健策略

Abstract: Melodic harmonization, the task of generating harmonic accompaniments for a given melody, remains a central challenge in computational music generation. Recent single encoder transformer approaches have framed harmonization as a masked sequence modeling problem, but existing training curricula inspired by discrete diffusion often result in weak (cross) attention between melody and harmony. This leads to limited exploitation of melodic cues, particularly in out-of-domain contexts. In this work, we introduce a training curriculum, FF (full-to-full), which keeps all harmony tokens masked for several training steps before progressively unmasking entire sequences during training to strengthen melody-harmony interactions. We systematically evaluate this approach against prior curricula across multiple experimental axes, including temporal quantization (quarter vs. sixteenth note), bar-level vs. time-signature conditioning, melody representation (full range vs. pitch class), and inference-time unmasking strategies. Models are trained on the HookTheory dataset and evaluated both in-domain and on a curated collection of jazz standards, using a comprehensive set of metrics that assess chord progression structure, harmony-melody alignment, and rhythmic coherence. Results demonstrate that the proposed FF curriculum consistently outperforms baselines in nearly all metrics, with particularly strong gains in out-of-domain evaluations where harmonic adaptability to novel melodic queues is crucial. We further find that quarter-note quantization, intertwining of bar tokens, and pitch-class melody representations are advantageous in the FF setting. Our findings highlight the importance of training curricula in enabling effective melody conditioning and suggest that full-to-full unmasking offers a robust strategy for single encoder harmonization.

</details>


### [34] [Domain-Incremental Continual Learning for Robust and Efficient Keyword Spotting in Resource Constrained Systems](https://arxiv.org/abs/2601.16158)
*Prakash Dhungana,Sayed Ahmad Salehi*

Main category: cs.SD

TL;DR: 提出一个用于关键词检测系统的持续学习框架，通过双输入CNN结合MFCC和Mel频谱特征，集成多阶段去噪和原型更新机制，能在资源受限的边缘设备上适应新领域噪声环境，保持高精度。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的小型关键词检测系统面临准确性和鲁棒性挑战，主要原因是噪声和录音条件变化导致的领域偏移。需要一种能在资源受限环境下持续适应新领域的方法。

Method: 提出综合持续学习框架：1) 双输入CNN同时使用MFCC和Mel频谱特征；2) 多阶段去噪（离散小波变换和谱减法）；3) 完整量化模型更新（而非仅特定层）；4) 运行时样本选择（基于类别原型和置信度过滤）；5) 伪标签和排练缓冲区结合的增量模型重训练。

Result: 在噪声测试数据集上表现优异：干净数据准确率达99.63%，在多样化噪声环境中保持超过94%的准确率，即使在-10dB信噪比下也能保持鲁棒性能。

Conclusion: 高效去噪与基于原型的持续学习相结合，能使关键词检测模型在资源受限的动态环境中自主、鲁棒地运行，为边缘设备上的语音识别系统提供了有效的适应性解决方案。

Abstract: Keyword Spotting (KWS) systems with small footprint models deployed on edge devices face significant accuracy and robustness challenges due to domain shifts caused by varying noise and recording conditions. To address this, we propose a comprehensive framework for continual learning designed to adapt to new domains while maintaining computational efficiency. The proposed pipeline integrates a dual-input Convolutional Neural Network, utilizing both Mel Frequency Cepstral Coefficients (MFCC) and Mel-spectrogram features, supported by a multi-stage denoising process, involving discrete wavelet transform and spectral subtraction techniques, plus model and prototype update blocks. Unlike prior methods that restrict updates to specific layers, our approach updates the complete quantized model, made possible due to compact model architecture. A subset of input samples are selected during runtime using class prototypes and confidence-driven filtering, which are then pseudo-labeled and combined with rehearsal buffer for incremental model retraining. Experimental results on noisy test dataset demonstrate the framework's effectiveness, achieving 99.63\% accuracy on clean data and maintaining robust performance (exceeding 94\% accuracy) across diverse noisy environments, even at -10 dB Signal-to-Noise Ratio. The proposed framework work confirms that integrating efficient denoising with prototype-based continual learning enables KWS models to operate autonomously and robustly in resource-constrained, dynamic environments.

</details>

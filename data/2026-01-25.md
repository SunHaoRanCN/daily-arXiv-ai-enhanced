<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 19]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SD](#cs.SD) [Total: 10]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [ISAC-over-NTN: HAPS-UAV Framework for Post-Disaster Responsive 6G Networks](https://arxiv.org/abs/2601.15422)
*Berk Ciloglu,Ozgun Ersoy,Metin Ozturk,Ali Gorcin*

Main category: eess.SP

TL;DR: 提出ISAC-over-NTN架构，结合无人机和HAPS平台，在灾后场景中实现可靠通信和用户检测


<details>
  <summary>Details</summary>
Motivation: 灾难场景中地面网络可能部分或完全崩溃，需要确保可靠的通信和态势感知能力

Method: 采用创新的波束成形方法，将MU-MIMO通信和单基地感知集成在同一传输链中，同时传输数据并基于多普勒效应检测用户移动性

Result: 框架保持了可靠的连接性，在关键位置实现了90%的运动检测灵敏度和88%的检测准确率

Conclusion: ISAC-over-NTN架构能够在灾后条件下提供可靠的通信基础设施并有效检测用户位置，支持搜救行动

Abstract: In disaster scenarios, ensuring both reliable communication and situational awareness becomes a critical challenge due to the partial or complete collapse of terrestrial networks. This paper proposes an integrated sensing and communication (ISAC) over non-terrestrial networks (NTN) architecture referred to as ISAC-over-NTN that integrates multiple uncrewed aerial vehicles (UAVs) and a high-altitude platform station (HAPS) to maintain resilient and reliable network operations in post-disaster conditions. We aim to achieve two main objectives: i) provide a reliable communication infrastructure, thereby ensuring the continuity of search-and-rescue activities and connecting people to their loved ones, and ii) detect users, such as those trapped under rubble or those who are mobile, using a Doppler-based mobility detection model. We employ an innovative beamforming method that simultaneously transmits data and detects Doppler-based mobility by integrating multi-user multiple-input multiple-output (MU-MIMO) communication and monostatic sensing within the same transmission chain. The results show that the proposed framework maintains reliable connectivity and achieves high detection accuracy of users in critical locations, reaching 90% motion detection sensitivity and 88% detection accuracy.

</details>


### [2] [Achievable Rate Optimization for Large Flexible Intelligent Metasurface Assisted Downlink MISO under Statistical CSI](https://arxiv.org/abs/2601.15471)
*Ling He,Vaibhav Kumar,Anastasios Papazafeiropoulos,Miaowen Wen,Le-Nam Tran,Marwa Chafii*

Main category: eess.SP

TL;DR: 提出基于统计CSI的柔性智能超表面优化框架，用于下行MISO系统，通过联合优化功率分配和超表面形变来最大化平均可达和速率


<details>
  <summary>Details</summary>
Motivation: 现有柔性智能超表面辅助系统设计大多假设完美的瞬时信道状态信息，这在大型网络中不切实际，因为需要高训练开销和复杂的信道估计

Method: 提出基于统计CSI的优化框架，开发基于块坐标上升的迭代算法，联合优化功率分配和柔性智能超表面形变

Result: 仿真结果显示，所提出的统计CSI驱动的柔性智能超表面设计显著优于传统刚性天线阵列，验证了其有效性和实用性

Conclusion: 基于统计CSI的柔性智能超表面优化框架能够克服瞬时CSI假设的局限性，在实际大规模网络中具有更好的实用性和性能表现

Abstract: The integration of electromagnetic metasurfaces into wireless communications enables intelligent control of the propagation environment. Recently, flexible intelligent metasurfaces (FIMs) have evolved beyond conventional reconfigurable intelligent surfaces (RISs), enabling three-dimensional surface deformation for adaptive wave manipulation. However, most existing FIM-aided system designs assume perfect instantaneous channel state information (CSI), which is impractical in large-scale networks due to the high training overhead and complicated channel estimation. To overcome this limitation, we propose a robust statistical-CSI-based optimization framework for downlink multiple-input single-output (MISO) systems with FIM-assisted transmitters. A block coordinate ascent (BCA)-based iterative algorithm is developed to jointly optimize power allocation and FIM morphing, maximizing the average achievable sum rate. Simulation results show that the proposed statistical-CSI-driven FIM design significantly outperforms conventional rigid antenna arrays (RAAs), validating its effectiveness and practicality.

</details>


### [3] [Applicability and Limitation Analysis of PMU Data and Phasor Concept for Low- and High- Frequency Oscillations](https://arxiv.org/abs/2601.15529)
*Bowen Ou,Bin Wang,Slava Maslennikov,Hanchao Liu,Jim Follum*

Main category: eess.SP

TL;DR: 本文分析了PMU在表示高频振荡信号时的局限性，提出了更通用的信号模型和多步估计方法，揭示了相量概念在高频振荡下的失效问题。


<details>
  <summary>Details</summary>
Motivation: PMU将高速波形数据转换为低速相量数据，是电力系统广域监测与控制的基础，但现有PMU相量只能有效表示低频振荡，无法处理高频振荡信号。本文旨在探究这一局限性的根本原因，并提出改进方案。

Method: 提出更通用的信号模型和多步估计方法，结合单周期DFT、矩阵铅笔法和最小二乘法，以更好地表示和估计含振荡的波形信号。

Result: 数值实验表明所提出的信号模型和估计方法性能优越。研究还发现，对于具有不对称次同步和超同步分量的高频振荡信号，相量概念本身可能失效。

Conclusion: PMU数据和相量概念存在根本局限性，分析现代电力系统中的高频振荡需要依赖波形数据而非相量数据。

Abstract: Phasor Measurement Units (PMUs) convert high-speed waveform data into low-speed phasor data, which are fundamental to wide-area monitoring and control in power systems, with oscillation detection and localization among their most prominent applications. However, representing electrical waveform signals with oscillations using PMU phasors is effective only for low-frequency oscillations. This paper investigates the root causes of this limitation, focusing on errors introduced by Discrete Fourier Transform (DFT)-based signal processing, in addition to the attenuation effects of anti-aliasing filters, and the impact of low reporting rates. To better represent and estimate waveform signals with oscillations, we propose a more general signal model and a multi-step estimation method that leverages one-cycle DFT, the Matrix Pencil Method, and the Least Squares Method. Numerical experiments demonstrate the superior performance of the proposed signal model and estimation method. Furthermore, this paper reveals that the phasor concept, let alone PMU phasors, can become invalid for waveform signals with high-frequency oscillations characterized by asymmetric sub- and super-synchronous components. These findings highlight the fundamental limitations of PMU data and phasor concept, and emphasize the need to rely on waveform data for analyzing high-frequency oscillations in modern power systems.

</details>


### [4] [Distributed Uplink Anti-Jamming in LEO Mega-Constellations via Game-Theoretic Beamforming](https://arxiv.org/abs/2601.15557)
*Shizhen Jia,Mingjun Ying,Marco Mezzavilla,Theodore S. Rappaport,Sundeep Rangan*

Main category: eess.SP

TL;DR: 本文提出一种分布式多卫星抗干扰策略，利用LEO巨型星座的高密度连接和高速星间链路，通过凸凹博弈建模和最小最大求解器，显著提升卫星网络在强干扰下的抗干扰能力。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道卫星星座在商业和国防非地面网络中日益重要，但其可预测的轨道动力学和暴露的几何结构使其极易受到地面干扰。传统的单卫星干扰抑制技术难以在空间上分离期望上行信号和附近干扰源，即使使用大型天线阵列也效果有限。

Method: 将上行干扰场景建模为期望地面发射器和干扰器之间的凸凹博弈，双方优化空间协方差矩阵以最大化或最小化可达速率。提出结合交替最佳响应更新和投影梯度下降的高效最小最大求解器，实现波束成形策略快速收敛到纳什均衡。

Result: 使用真实的Starlink轨道几何和Sionna射线追踪仿真表明，虽然近距离干扰器可以瘫痪单卫星链路，但分布式卫星协作显著增强了抗干扰能力，在强干扰下将容量分布向上移动。

Conclusion: 分布式多卫星抗干扰策略利用现代LEO巨型星座的密集连接和高速星间链路，通过博弈论方法和高效求解器，能够有效应对地面干扰威胁，提升卫星网络的抗干扰韧性。

Abstract: Low-Earth-Orbit (LEO) satellite constellations have become vital in emerging commercial and defense Non-Terrestrial Networks (NTNs). However, their predictable orbital dynamics and exposed geometries make them highly susceptible to ground-based jamming. Traditional single-satellite interference mitigation techniques struggle to spatially separate desired uplink signals from nearby jammers, even with large antenna arrays. This paper explores a distributed multi-satellite anti-jamming strategy leveraging the dense connectivity and high-speed inter-satellite links of modern LEO mega-constellations. We model the uplink interference scenario as a convex-concave game between a desired terrestrial transmitter and a jammer, each optimizing their spatial covariance matrices to maximize or minimize achievable rate. We propose an efficient min-max solver combining alternating best-response updates with projected gradient descent, achieving fast convergence of the beamforming strategy to the Nash equilibrium. Using realistic Starlink orbital geometries and Sionna ray-tracing simulations, we demonstrate that while close-proximity jammers can cripple single-satellite links, distributed satellite cooperation significantly enhances resilience, shifting the capacity distribution upward under strong interference.

</details>


### [5] [An Iterated Hybrid Fast Parallel FIR Filter](https://arxiv.org/abs/2601.15582)
*Keshab K. Parhi*

Main category: eess.SP

TL;DR: 提出一种新型迭代快速并行FIR滤波器——快速混合滤波器，通过在不同层采用不同结构的2-并行滤波器来降低硬件复杂度


<details>
  <summary>Details</summary>
Motivation: 并行FIR滤波通过同时处理多个输入样本来提高DSP应用的计算效率和吞吐量。现有方法使用迭代FFA方法设计快速并行滤波器架构，但仍有优化空间

Method: 提出快速混合滤波器：在所有内层迭代转置2-并行快速FIR滤波器，在最外层使用直接形式2-并行快速FIR滤波器。这种混合迭代方法首次提出

Result: 混合快速并行滤波器相比先前方法需要更少的加法运算，降低了硬件复杂度

Conclusion: 提出的快速混合滤波器通过创新的混合迭代架构，在保持并行处理优势的同时，有效减少了硬件资源需求

Abstract: This paper revisits the design and optimization of parallel fast finite impulse response (FIR) filters using polyphase decomposition and iterated fast FIR algorithms (FFAs). Parallel FIR filtering enhances computational efficiency and throughput in digital signal processing (DSP) applications by enabling the simultaneous processing of multiple input samples. We revisit a prior approach to design of fast parallel filter architectures by using the iterated FFA approach where the same primitive filter, such as 2-parallel, is iterated to design the fast parallel filter. In this paper, we present yet another novel iterated fast parallel FIR filter, referred to as the fast hybrid filter. The hybrid filter iterates a transposed 2-parallel fast FIR filter in all the inner layers and a direct-form 2-parallel fast FIR filter in the outermost layer, resulting in reduced hardware complexity. Such an iterated hybrid approach has not been presented before. We show that the hybrid fast parallel filters require less number of additions compared to prior approaches.

</details>


### [6] [Amalgamated CHIRP and OFDM for ISAC](https://arxiv.org/abs/2601.15584)
*Pankaj Kumar,Mohammed El-Hajjar,Ibrahim A. Hemadeh,Yasser Mestrah,Suraj Srivastava,Aditya K. Jagannatham,Lajos Hanzo*

Main category: eess.SP

TL;DR: 提出一种结合OFDM和chirp信号的新型波形，用于集成感知与通信(ISAC)，降低PAPR并提升感知性能


<details>
  <summary>Details</summary>
Motivation: ISAC需要能同时高效支持通信和感知功能的波形。传统OFDM系统存在PAPR高的问题，且传统感知方式需要占用通信资源，降低通信效率

Method: 提出一种新颖的波形架构，通过仿射加法将OFDM和chirp信号结合，形成近似恒包络的OFDM波形。在时隙级别将chirp信号集成到OFDM框架中，利用chirp波形进行感知而不消耗通信资源

Result: 所提波形具有更好的自相关特性，改善了距离和速度的RMSE，降低了PAPR。同时保持了通信效率，并实现了通信与感知性能之间的权衡

Conclusion: 提出的OFDM-chirp混合波形有效解决了传统ISAC系统中的PAPR问题和资源分配矛盾，在通信和感知性能之间取得了良好平衡

Abstract: Integrated Sensing and Communication (ISAC) requires the development of a waveform capable of efficiently supporting both communication and sensing functionalities. This paper proposes a novel waveform that combines the benefits of both the orthogonal frequency division multiplexing (OFDM) and the chirp waveforms to improve both the communication and sensing performance within an ISAC framework. Hence, a new architecture is proposed that utilizes the conventional communication framework while leveraging the parameters sensed at the receiver (Rx) for enhancing the communication performance. We demonstrate that the affine addition of OFDM and chirp signals results in a near constant-envelope OFDM waveform, which effectively reduces the peak-to-average power ratio (PAPR), a key limitation of traditional OFDM systems. Using the OFDM framework for sensing in the conventional fashion requires the allocation of some resources for sensing, which in turn reduces communication performance. As a remedy, the proposed affine amalgam facilitates sensing through the chirp waveform without consuming communication resources, thereby preserving communication efficiency. Furthermore, a novel technique of integrating the chirp signal into the OFDM framework at the slot-level is proposed to enhance the accuracy of range estimation. The results show that the OFDM signal incorporated with chirp has better autocorrelation properties, improved root mean square error (RMSE) of range and velocity, and lower PAPR. Finally, we characterize the trade-off between communications and sensing performance.

</details>


### [7] [Does 6G Need a New Waveform: Comparing Zak-OTFS with CP-OFDM](https://arxiv.org/abs/2601.15602)
*Imran Ali Khan,Saif Khan Mohammed,Ronny Hadani,Ananthanarayanan Chockalingam,Robert Calderbank,Anton Monk,Shachar Kons,Shlomo Rakib,Yoav Hebron*

Main category: eess.SP

TL;DR: 该论文对CP-OFDM和Zak-OTFS在6G传播环境中的性能进行全面比较，分析两种波形在延迟/多普勒扩展信道中的表现差异，为波形选择提供架构层面的指导。


<details>
  <summary>Details</summary>
Motivation: 随着Zak-OTFS等新波形技术在全球范围内受到关注并开始实际部署，需要在OFDM和Zak-OTFS之间做出选择。这不仅是波形选择问题，更是架构选择问题：是预防载波间干扰（ICI）还是接受ICI。特别是在6G双扩展使用场景中，需要明确哪种波形在高速移动和/或大蜂窝环境下表现更优。

Method: 论文对循环前缀OFDM（CP-OFDM）和Zak-OTFS在完整的6G传播环境范围内进行全面的性能比较分析。通过系统性的性能评估，深入探讨两种波形在不同信道条件下的表现差异。

Result: Zak-OTFS在高延迟/多普勒扩展的6G使用场景（即高速移动和/或大蜂窝）中表现出优越性能。而架构选择取决于典型使用场景，这在一定程度上与地理因素相关，因为大延迟扩展是大蜂窝的典型特征，在许多重要无线市场中是常态而非例外。

Conclusion: OFDM和Zak-OTFS的选择本质上是架构选择：OFDM通过预防ICI简化均衡但难以处理ICI，而Zak-OTFS虽然均衡更复杂但I/O关系可预测且获取简单。性能比较结果为6G波形选择提供了重要指导，特别是在双扩展信道环境中。

Abstract: Across the world, there is growing interest in new waveforms, Zak-OTFS in particular, and over-the-air implementations are starting to appear. The choice between OFDM and Zak-OTFS is not so much a choice between waveforms as it is an architectural choice between preventing inter-carrier interference (ICI) and embracing ICI. In OFDM, once the Input-Output (I/O) relation is known, equalization is relatively simple, at least when there is no ICI. However, in the presence of ICI the I/O relation is non-predictable and its acquisition is non-trivial. In contrast, equalization is more involved in Zak-OTFS due to inter-symbol-interference (ISI), however the I/O relation is predictable and its acquisition is simple. {Zak-OTFS exhibits superior performance in doubly-spread 6G use cases with high delay/Doppler channel spreads (i.e., high mobility and/or large cells), but architectural choice is governed by the typical use case, today and in the future. What is typical depends to some degree on geography, since large delay spread is a characteristic of large cells which are the rule rather than the exception in many important wireless markets.} This paper provides a comprehensive performance comparison of cyclic prefix OFDM (CP-OFDM) and Zak-OTFS across the full range of 6G propagation environments. The performance results provide insights into the fundamental architectural choice.

</details>


### [8] [Bistatic ISAC: Practical Challenges and Solutions](https://arxiv.org/abs/2601.15733)
*Lucas Giroto,Marcus Henninger,Alexander Felix,Maximilian Bauhofer,Taewon Jeong,Umut Utku Erdem,Stephan ten Brink,Thomas Zwick,Benjamin Nuss,Silvio Mandelli*

Main category: eess.SP

TL;DR: 本文讨论了6G网络中双基地集成感知与通信的实际挑战和解决方案，重点关注OFDM波形下的系统设计、硬件损伤限制、信号处理技术以及5G兼容场景的仿真验证。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络的发展，集成感知与通信技术面临实际部署挑战。双基地ISAC系统需要解决硬件损伤影响、同步问题和多维度感知信息提取等实际问题，以实现既满足感知性能指标又不影响通信质量的系统设计。

Method: 采用正交频分复用波形，设计系统以平衡感知性能指标和硬件损伤影响。提出空中同步信号处理技术，生成包含距离、多普勒频移和角度信息的周期图。通过符合5G标准的参数设置进行蜂窝ISAC场景仿真验证。

Result: 提出了针对双基地ISAC系统的实际解决方案，包括系统设计方法、信号处理技术和同步机制。仿真结果表明在5G兼容参数下能够实现有效的感知功能，同时识别了未来部署面临的开放挑战。

Conclusion: 双基地ISAC在6G网络中具有实际可行性，但需要综合考虑系统设计、硬件限制和信号处理技术。虽然基于5G参数的仿真验证了基本功能，但未来部署仍面临诸多开放挑战需要进一步研究。

Abstract: This article presents and discusses challenges and solutions for practical issues in bistatic integrated sensing and communication (ISAC) in 6G networks. Considering orthogonal frequency-division multiplexing as the adopted waveform, a discussion on system design aiming to achieve both a desired sensing key performance indicators and limit the impact of hardware impairments is presented. In addition, signal processing techniques to enable over-the-air synchronization and generation of periodograms with range, Doppler shift, and angular information are discussed. Simulation results are then presented for a cellular-based ISAC scenario considering system parameterization compliant to current 5G and, finally, a discussion on open challenges for future deployments is presented.

</details>


### [9] [Joint Pilot and Unknown Data-based Localization for OFDM Opportunistic Radar Systems](https://arxiv.org/abs/2601.15785)
*Mathieu Reniers,Martin Willame,Jérôme Louveaux,Luc Vandendorpe*

Main category: eess.SP

TL;DR: 提出一种从通信信号数据载荷中提取定位信息的新方法，无需解码数据，利用FFT实现高效估计，性能优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有ISAC定位方法要么仅使用已知导频信号（忽略数据符号中的雷达信息），要么依赖数据解码（定位性能受限于通信系统性能），需要克服这些限制

Method: 提出一种从数据载荷中提取定位信息而不解码的新方法，利用机会雷达场景中的均匀线性阵列天线，通过快速傅里叶变换实现高效估计

Result: 数值仿真表明，该方法在定位性能上优于文献中的现有方法

Conclusion: 该方法有效解决了现有ISAC定位方法的局限性，能够从未解码的数据载荷中提取定位信息，实现更优的定位性能

Abstract: Integrated Sensing and Communications (ISAC) has emerged as a promising paradigm for Sixth Generation (6G) and Wi-Fi 7 networks, with the communication-centric approach being particularly attractive due to its compatibility with current standards. Typical communication signals comprise both deterministic known pilot signals and random unknown data payloads. Most existing approaches either rely solely on pilots for positioning, thereby ignoring the radar information present in the received data symbols that constitute the majority of each frame, or rely on data decisions, which bounds positioning performance to that of the communication system. To overcome these limitations, we propose a novel method that extracts positioning information from data payloads without decoding them. We consider an opportunistic scenario in which communication signals from a user are captured by an opportunistic radar equipped with a Uniform Linear Arrays of antennas. We show that, in this setting, the estimation can be efficiently implemented using Fast Fourier Transforms. Finally, we demonstrate superior localization performance compared to existing methods in the literature through numerical simulations.

</details>


### [10] [Adaptive Non-Uniform Sampling of Bandlimited Signals via Algorithm-Encoder Co-Design](https://arxiv.org/abs/2601.15790)
*Kaluguri Yashaswini,Anshu Arora,Satish Mulleti*

Main category: eess.SP

TL;DR: 提出基于算法-编码器协同设计的自适应非均匀采样框架，通过局部能量条件而非全局Nyquist约束来指导采样，设计可变偏置/阈值IF-TEM编码器，在保持精确重建的同时显著降低采样密度。


<details>
  <summary>Details</summary>
Motivation: 传统均匀采样和固定阈值IF-TEM需要满足全局Nyquist条件，导致在信号变化缓慢区域过度采样。希望开发自适应采样方法，只在信号快速变化区域密集采样，从而降低整体采样密度。

Method: 1) 重新分析非均匀测量迭代重建算法的收敛性，推导出基于局部信号和导数能量的充分条件；2) 设计可变偏置和可变阈值的IF-TEM编码器，其触发机制专门满足局部收敛条件；3) 引入移位信号公式抑制信号幅度接近零时的过度触发；4) 使用时间编码和信号平均值离散表示模拟信号。

Result: 仿真和实验（超声导波和ECG信号）表明：相比均匀采样和传统IF-TEM，该方法显著降低采样密度（局部采样率可低于Nyquist率），同时保持精确重建。实现了采样密度、重建精度和收敛行为之间的可控权衡。

Conclusion: 提出的算法-编码器协同设计框架通过局部能量条件实现自适应非均匀采样，打破了传统全局Nyquist约束的限制。VBT-IF-TEM编码器能够根据信号局部特性动态调整采样密度，在保证重建质量的同时大幅减少采样点，为高效信号采集提供了新途径。

Abstract: We propose an adaptive non-uniform sampling framework for bandlimited signals based on an algorithm-encoder co-design perspective. By revisiting the convergence analysis of iterative reconstruction algorithms for non-uniform measurements, we derive a local, energy-based sufficient condition that governs reconstruction behavior as a function of the signal and derivative energies within each sampling interval. Unlike classical approaches that impose a global Nyquist-type bound on the inter-sample spacing, the proposed condition permits large gaps in slowly varying regions while enforcing denser sampling only where the signal exhibits rapid temporal variation. Building on this theoretical insight, we design a variable-bias, variable-threshold integrate-and-fire time encoding machine (VBT-IF-TEM) whose firing mechanism is explicitly shaped to enforce the derived local convergence condition. To ensure robustness, a shifted-signal formulation is introduced to suppress excessive firing in regions where the magnitude of the signal amplitude is close to zero or the local signal energy approaches zero. Using the proposed encoder, an analog signal is discretely represented by time encodings and signal averages, enabling perfect reconstruction via a standard iterative algorithm even when the local sampling rate falls below the Nyquist rate. Simulation results on synthetic signals and experiments on ultrasonic guided-wave and ECG signals demonstrate that the proposed framework achieves substantial reductions in sampling density compared to uniform sampling and conventional IF-TEMs, while maintaining accurate reconstruction. The results further highlight a controllable tradeoff between sampling density, reconstruction accuracy, and convergence behavior, which can be navigated through adaptive parameter selection.

</details>


### [11] [Dual-Mapping Sparse Vector Transmission for Short Packet URLLC](https://arxiv.org/abs/2601.15819)
*Yanfeng Zhang,Xu Zhu,Jinkai Zheng,Weiwei Yang,Xianhua Yu,Haiyong Zeng,Yujie Liu,Yong Liang Guan*

Main category: eess.SP

TL;DR: 提出一种基于双映射稀疏向量编码的短包传输方案，通过块稀疏映射和单元素稀疏映射提升传输性能


<details>
  <summary>Details</summary>
Motivation: 稀疏向量编码是下一代通信系统中超可靠低延迟通信的有前景的短包传输方法，需要进一步提升其传输性能

Method: 提出双映射稀疏向量编码方案，通过块稀疏映射将发射功率集中在少量非零块提高解码精度，同时使用单元素稀疏映射防止码长随信息比特数急剧增加；接收端采用两阶段解码算法依次识别非零块索引和单元素非零索引

Result: 大量仿真结果表明，提出的DM-SVC方案在块错误率和频谱效率方面优于现有SVC方案

Conclusion: 双映射稀疏向量编码方案有效提升了短包传输性能，为超可靠低延迟通信提供了改进的传输方案

Abstract: Sparse vector coding (SVC) is a promising short-packet transmission method for ultra reliable low latency communication (URLLC) in next generation communication systems. In this paper, a dual-mapping SVC (DM-SVC) based short packet transmission scheme is proposed to further enhance the transmission performance of SVC. The core idea behind the proposed scheme lies in mapping the transmitted information bits onto sparse vectors via block and single-element sparse mappings. The block sparse mapping pattern is able to concentrate the transmit power in a small number of non-zero blocks thus improving the decoding accuracy, while the single-element sparse mapping pattern ensures that the code length does not increase dramatically with the number of transmitted information bits. At the receiver, a two-stage decoding algorithm is proposed to sequentially identify non-zero block indexes and single-element non-zero indexes. Extensive simulation results verify that proposed DM-SVC scheme outperforms the existing SVC schemes in terms of block error rate and spectral efficiency.

</details>


### [12] [Separable Delay And Doppler Estimation In Passive Radar](https://arxiv.org/abs/2601.15821)
*Mats Viberg,Daniele Gerosa,Tomas McKelvey,Patrik Dammert,Thomas Eriksson*

Main category: eess.SP

TL;DR: 提出一种用于被动雷达的可分离参数估计方法，将时延和多普勒估计分开处理，避免二维搜索，降低计算复杂度和通信开销


<details>
  <summary>Details</summary>
Motivation: 被动雷达系统利用机会照射源信号进行目标检测和定位，传统方法需要联合估计时延和多普勒参数，计算成本高且通信开销大

Method: 提出可分离估计方法：1) 将数据分成可管理的小批次；2) 先单独估计时延参数，避免二维搜索；3) 基于估计的时延恢复批次间相干性；4) 再估计多普勒参数

Result: 时延估计精度与完整二维方法相当，多普勒估计性能在广泛参数范围内优于传统方法，同时显著降低计算复杂度和分布式雷达系统的通信开销

Conclusion: 提出的可分离参数估计方法为被动雷达系统提供了一种高效解决方案，特别适用于慢速目标，在保持性能的同时大幅降低了计算和通信成本

Abstract: In passive radar, a network of distributed sensors exploit signals from so-called Illuminators-of-Opportunity to detect and localize targets. We consider the case where the IO signal is available at each receiver node through a reference channel, whereas target returns corrupted by interference are collected in a separate surveillance channel. The problem formulation is similar to an active radar that uses a noise-like waveform, or an integrated sensing and communication application. The available data is first split into batches of manageable size. In the direct approach, the target's time-delay and Doppler parameters are estimated jointly by incoherently combining the batch-wise data. We propose a new method to estimate the time-delay separately, thus avoiding a costly 2-D search. Our approach is designed for slowly moving targets, and the accuracy of the time-delay estimate is similar to that of the full batch-wise 2-D method. Given the time-delay, the coherency between batches can be restored when estimating the Doppler parameter. Thereby, the separable approach is found to yield superior Doppler estimates over a wide parameter range. In addition to reducing computational complexity, the proposed separable estimation technique also significantly reduces the communication overhead in a distributed radar setting.

</details>


### [13] [Performance Analysis of Digital Beamforming mmWave MIMO with Low-Resolution DACs/ADCs](https://arxiv.org/abs/2601.15831)
*Faruk Pasic,Mariam Mussbah,Stefan Schwarz,Markus Rupp,Fredrik Tufvesson,Christoph F. Mecklenbräuker*

Main category: eess.SP

TL;DR: 该论文研究了采用低分辨率量化全数字波束成形的毫米波MIMO系统信道估计性能，发现4位DAC/ADC在能耗和速率间提供最佳折衷。


<details>
  <summary>Details</summary>
Motivation: 未来无线通信需要毫米波频段的MIMO波束成形来提供高数据速率。全数字毫米波MIMO系统需要精确信道估计来支持灵活空间处理和低延迟应用，但为了保持功率效率必须使用低分辨率DAC/ADC，这些量化器会引入信号失真并降低系统性能。

Method: 研究采用低分辨率量化的全数字毫米波MIMO波束成形系统的信道估计性能，在实际系统约束下评估系统性能。通过仿真分析不同量化分辨率对系统的影响。

Result: 仿真结果表明，每个DAC/ADC采用4位中等量化分辨率能在能量消耗和可达到的数据速率之间提供有利的折衷平衡。

Conclusion: 在毫米波MIMO全数字波束成形系统中，适度的4位量化分辨率是实现能量效率和频谱效率平衡的合理选择。

Abstract: Future wireless communications will rely on multiple-input multiple-output (MIMO) beamforming operating at millimeter wave (mmWave) frequency bands to deliver high data rates. To support flexible spatial processing and meet the demands of latency critical applications, it is essential to use fully digital mmWave MIMO beamforming, which relies on accurate channel estimation. However, ensuring power efficiency in fully digital mmWave MIMO systems requires the use of low-resolution digital-to-analog converters (DACs) and analog-to-digital converters (ADCs). The reduced resolution of these quantizers introduces distortion in both transmitted and received signals, ultimately degrading system performance. In this paper, we investigate the channel estimation performance of mmWave MIMO systems employing fully digital beamforming with low-resolution quantization, under practical system constraints. We evaluate the system performance in terms of spectral efficiency (SE) and energy efficiency (EE). Simulation results demonstrate that a moderate quantization resolutions of 4-bit per DAC/ADC offers a favorable trade-off between energy consumption and achievable data rate.

</details>


### [14] [Time-Varying Rician K-factor in Measured Vehicular Channels at cmWave and mmWave Bands](https://arxiv.org/abs/2601.15863)
*Faruk Pasic,Markus Hofer,Thomas Zemen,Andreas F. Molisch,Christoph F. Mecklenbräuker*

Main category: eess.SP

TL;DR: 该论文分析了车对基础设施通信中毫米波与厘米波频段的小尺度衰落特性，发现不同频段的莱斯K因子相似且与均方根时延扩展相关。


<details>
  <summary>Details</summary>
Motivation: 未来车载通信系统将集成毫米波技术以提高数据传输速率，需要研究毫米波与传统厘米波频段之间的传播效应和小尺度衰落差异，特别是表征小尺度衰落的关键参数莱斯K因子。

Method: 在城区街道环境中进行多频段车对基础设施信道测量，分析三个中心频率（3.2 GHz、34.3 GHz和62.35 GHz）的时变K因子，使用155.5 MHz带宽和31.25 μs的探测重复率测量数据，并分析K因子与均方根时延扩展的关系。

Result: 研究发现不同频段的莱斯K因子相似，并且K因子与均方根时延扩展存在相关性。

Conclusion: 毫米波和厘米波频段在车对基础设施通信中表现出相似的小尺度衰落特性，K因子与时延扩展的相关性为信道建模提供了重要参考。

Abstract: Future vehicular communication systems will integrate millimeter wave (mmWave) technology to enhance data transmission rates. To investigate the propagation effects and small-scale fading differences between mmWave and conventional centimeter wave (cmWave) bands, multi-band channel measurements have to be conducted. One key parameter to characterize small-scale fading is the Rician K-factor. In this paper, we analyze the time-varying K-factor of vehicle-to-infrastructure (V2I) channels across multiple frequency bands, measured in an urban street environment. Specifically, we investigate three frequency bands with center frequencies of 3.2 GHz, 34.3 GHz and 62.35 GHz using measurement data with 155.5 MHz bandwidth and a sounding repetition rate of 31.25 μs. Furthermore, we analyze the relationship between K-factor and root-mean-square (RMS) delay spread. We show that the Ricean K-factor is similar at different frequency bands and that is correlated with the RMS delay spread.

</details>


### [15] [Reconstructing Patched or Partial Holograms to allow for Whole Slide Imaging with a Self-Referencing Holographic Microscope](https://arxiv.org/abs/2601.15952)
*Philip Groult,Julia D. Sistermanns,Ellen Emken,Oliver Hayden,Wolfgang Utschick*

Main category: eess.SP

TL;DR: 提出一种用于宫颈涂片全玻片成像的重建算法，结合自参考三波数字全息显微镜技术，实现单次全息图重建并适应不同输入格式


<details>
  <summary>Details</summary>
Motivation: 传统全玻片成像（WSI）与定量相位成像（QPI）尚未结合，而QPI能提供更丰富的细胞信息且样本制备更简单。本研究旨在将这两种技术融合，开发适用于宫颈涂片筛查的新型成像方法

Method: 使用自参考三波数字全息显微镜，开发自适应重建算法，能够处理部分全息图和分块全息图，通过组合多个补丁构建全玻片图像

Result: 算法在测试的上皮细胞上表现良好，能够实现宫颈涂片的单次全息图全玻片成像，为WSI和QPI的结合提供了可行方案

Conclusion: 成功开发了将全玻片成像与定量相位成像相结合的重建算法，为计算机辅助细胞学筛查提供了新的技术路径，该工作已被ISBI 2026接收

Abstract: The last decade has seen significant advances in computer-aided diagnostics for cytological screening, mainly through the improvement and integration of scanning techniques such as whole slide imaging (WSI) and the combination with deep learning. Simultaneously, new imaging techniques such as quantitative phase imaging (QPI) are being developed to capture richer cell information with less sample preparation. So far, the two worlds of WSI and QPI have not been combined. In this work, we present a reconstruction algorithm which makes whole slide imaging of cervical smears possible by using a self-referencing three-wave digital holographic microscope. Since a WSI is constructed by combining multiple patches, the algorithm is adaptive and can be used on partial holograms and patched holograms. We present the algorithm for a single shot hologram, the adaptations to make it flexible to various inputs and show that the algorithm performs well for the tested epithelial cells. This is a preprint of our paper, which has been accepted for publication in 2026 IEEE International Symposium on Biomedical Imaging (ISBI).

</details>


### [16] [Performance Scaling Laws for PD Array-based Receivers in IM/DD Optical Wireless Communication Systems](https://arxiv.org/abs/2601.15973)
*Aravindh Krishnamoorthy,Robert Schober,Harald Haas*

Main category: eess.SP

TL;DR: 光电探测器阵列接收机中电域合并的性能缩放规律研究，考虑光功率与电功率之间的平方律关系，分析阵列与单探测器系统的性能差异。


<details>
  <summary>Details</summary>
Motivation: 研究光电探测器阵列接收机在强度调制直接检测系统中的性能缩放规律，为下一代高带宽阵列接收机设计提供理论指导。

Method: 通过分析建模和数值模拟，比较阵列接收机与单探测器参考接收机在信噪比和可达速率方面的性能，考虑光束宽度、信噪比阈值等因素。

Result: 光电探测器阵列在足够窄的光束和高于特定信噪比阈值时能提供性能增益；单纯增加探测器数量不能提升性能，需要联合优化光束模式、电磁模式、接收功率和探测器位置。

Conclusion: 光电探测器阵列接收机的设计需要综合考虑多个参数优化，研究模型为下一代高带宽阵列接收机设计提供了实用指南和权衡考量。

Abstract: We study the performance scaling laws for electrical-domain combining in photodetector (PD) array-based receivers employing intensity modulation and direct detection, taking into account the inherent square-law relationship between the optical and electrical received powers. The performance of PD array-based systems is compared, in terms of signal-to-noise ratio (SNR) and achievable rate, to that of a reference receiver employing a single PD. Analytical and numerical results show that PD arrays provide performance gains for sufficiently narrow beams and above an SNR threshold. Furthermore, increasing the number of PDs alone does not enhance performance, and joint optimization of beam pattern, transverse electromagnetic mode, received power, and PD positions is necessary. Our model and derived insights provide practical guidelines and highlight the trade-offs for the design of next-generation high-bandwidth PD array receivers.

</details>


### [17] [Graph Topology Identification Based on Covariance Matching](https://arxiv.org/abs/2601.15999)
*Yongsheng Han,Raj Thilak Rajan,Geert Leus*

Main category: eess.SP

TL;DR: 提出CovMatch框架，通过匹配经验协方差与理论协方差来推断图拓扑，无需传统方法的限制性假设，适用于有向/无向图。


<details>
  <summary>Details</summary>
Motivation: 传统图拓扑识别方法依赖概率模型或复杂优化，常面临非凸性、需要无环或正权重等限制性假设。需要一种更通用、假设更少的统一方法。

Method: 提出协方差匹配框架：直接对齐观测数据的经验协方差与底层图隐含的理论协方差。通过重新参数化，将图学习问题简化为锥混合整数规划（无向图）或正交矩阵优化（有向图）。

Result: 数值实验表明，即使对于较大图，该方法能高效恢复真实拓扑，在准确性上优于标准基线方法。

Conclusion: CovMatch为图拓扑识别提供了强大的替代方案，相比对数行列式或贝叶斯方法，能以更少假设学习复杂网络拓扑，为更广泛研究铺平道路。

Abstract: Graph topology identification (GTI) is a central challenge in networked systems, where the underlying structure is often hidden, yet nodal data are available. Conventional solutions to address these challenges rely on probabilistic models or complex optimization formulations, commonly suffering from non-convexity or requiring restrictive assumptions on acyclicity or positivity. In this paper, we propose a novel covariance matching (CovMatch) framework that directly aligns the empirical covariance of the observed data with the theoretical covariance implied by an underlying graph. We show that as long as the data-generating process permits an explicit covariance expression, CovMatch offers a unified route to topology inference.
  We showcase our methodology on linear structural equation models (SEMs), showing that CovMatch naturally handles both undirected and general sparse directed graphs - whether acyclic or positively weighted - without explicit knowledge of these structural constraints. Through appropriate reparameterizations, CovMatch simplifies the graph learning problem to either a conic mixed integer program for undirected graphs or an orthogonal matrix optimization for directed graphs. Numerical results confirm that, even for relatively large graphs, our approach efficiently recovers the true topology and outperforms standard baselines in accuracy. These findings highlight CovMatch as a powerful alternative to log-determinant or Bayesian methods for GTI, paving the way for broader research on learning complex network topologies with minimal assumptions.

</details>


### [18] [Low-Complexity Sparse Superimposed Coding for Ultra Reliable Low Latency Communications](https://arxiv.org/abs/2601.16012)
*Yanfeng Zhang,Xi'an Fan,Xu Zhu,Jinkai Zheng,Hui Liang,Weiwei Yang,Tom H. Luan*

Main category: eess.SP

TL;DR: 提出一种基于稀疏码本结构的低复杂度稀疏叠加编码方案，通过设计稀疏码本减少非零元素数量，显著降低编码解码复杂度，在BLER性能和计算复杂度之间取得良好平衡。


<details>
  <summary>Details</summary>
Motivation: 传统稀疏叠加编码方案使用密集码本矩阵，导致编码和解码复杂度较高，限制了其在超可靠低延迟通信场景中的应用。

Method: 设计稀疏码本结构，使每个码字仅包含少量非零元素，采用传统的多径匹配追踪算法进行解码，利用码本的稀疏性显著降低整体复杂度。

Result: 仿真结果表明，所提方案在BLER性能和计算复杂度之间取得了有利的权衡，并在不同传输块长度下表现出强大的鲁棒性。

Conclusion: 通过设计稀疏码本结构，成功实现了低复杂度的稀疏叠加编码方案，为短包传输提供了有效的解决方案。

Abstract: Sparse superimposed coding (SSC) has emerged as a promising technique for short-packet transmission in ultra-reliable low-latency communication scenarios. However, conventional SSC schemes often suffer from high encoding and decoding complexity due to the use of dense codebook matrices. In this paper, we propose a low-complexity SSC scheme by designing a sparse codebook structure, where each codeword contains only a small number of non-zero elements. The decoding is performed using the traditional multipath matching pursuit algorithm, and the overall complexity is significantly reduced by exploiting the sparsity of the codebook. Simulation results show that the proposed scheme achieves a favorable trade-off between BLER performance and computational complexity, and exhibits strong robustness across different transmission block lengths.

</details>


### [19] [Hybrid Channel Estimation with Quantized Phase Feedback for Over-the-Air Computation](https://arxiv.org/abs/2601.16054)
*Martin Dahl,Erik G. Larsson*

Main category: eess.SP

TL;DR: 提出混合信道估计方案，结合互易性和反馈机制，通过量化相位反馈降低空中计算的信令开销，实现幅度和相位估计精度的独立选择。


<details>
  <summary>Details</summary>
Motivation: 为了降低空中计算（over-the-air computation）的信令开销，需要设计更高效的信道估计方案。传统方法可能单独使用互易性或反馈机制，但存在各自局限性。

Method: 提出混合信道估计方案，结合互易性估计和反馈估计。幅度假设精确估计，重点研究量化相位反馈的影响。提出两种变体：第一种仅通过反馈估计相位；第二种通过互易性估计相位，并结合最优量化相位反馈。

Result: 通过仿真和理论分析表明，第二种变体（互易性估计相位+最优量化相位反馈）在性能上优于第一种变体（仅通过反馈估计相位）。

Conclusion: 混合信道估计方案能够有效降低空中计算的信令开销，通过独立选择幅度和相位的估计精度，其中结合互易性相位估计和最优量化反馈的方案性能更优。

Abstract: To reduce the signaling overhead of over-the-air computation, a hybrid channel estimation scheme is proposed, where reciprocity-based and feedback-based channel estimation are combined. In particular, the impact of quantized phase-feedback is studied while the amplitude is assumed estimated exactly. The scheme enables selecting the estimation precision of amplitude and phase separately, depending on the importance of each. Two variants of the scheme are proposed: As shown through simulations and theory, the second variant with reciprocity-based estimation of the channel phase, and optimal quantization of phase feedback, can outperform the first variant estimating the phase by feedback only.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [20] [DynamicSound simulator for simulating moving sources and microphone arrays](https://arxiv.org/abs/2601.15433)
*Luca Barbisan,Marco Levorato,Fabrizio Riente*

Main category: eess.AS

TL;DR: DynamicSound是一个开源声学仿真框架，用于生成多通道音频，支持三维空间中连续移动的声源和任意配置的麦克风阵列，包含传播延迟、多普勒效应、空气吸收等物理效应。


<details>
  <summary>Details</summary>
Motivation: 现有声学仿真器大多针对室内环境且限于静态声源，不适合移动声源、移动麦克风或长距离传播场景。开发声音分类、检测和定位算法需要大量灵活且真实的音频数据。

Method: 提出DynamicSound开源框架，支持三维空间中连续移动的声源和任意配置的麦克风阵列。模型显式考虑有限声传播延迟、多普勒效应、距离相关衰减、空气吸收和一阶平面反射。

Result: 与现有开源工具对比评估表明，生成的信号在不同声源位置和声学条件下保持高空间保真度。能够合成任意数量虚拟麦克风的音频，准确再现麦克风间时间延迟、电平差异和环境引起的频谱着色。

Conclusion: 该开源框架通过生成受控可重复条件下的真实多通道音频，为现代空间音频和声源定位算法的开发、训练和评估提供了灵活且可复现的工具。

Abstract: Developing algorithms for sound classification, detection, and localization requires large amounts of flexible and realistic audio data, especially when leveraging modern machine learning and beamforming techniques. However, most existing acoustic simulators are tailored for indoor environments and are limited to static sound sources, making them unsuitable for scenarios involving moving sources, moving microphones, or long-distance propagation. This paper presents DynamicSound an open-source acoustic simulation framework for generating multichannel audio from one or more sound sources with the possibility to move them continuously in three-dimensional space and recorded by arbitrarily configured microphone arrays. The proposed model explicitly accounts for finite sound propagation delays, Doppler effects, distance-dependent attenuation, air absorption, and first-order reflections from planar surfaces, yielding temporally consistent spatial audio signals. Unlike conventional mono or stereo simulators, the proposed system synthesizes audio for an arbitrary number of virtual microphones, accurately reproducing inter-microphone time delays, level differences, and spectral coloration induced by the environment. Comparative evaluations with existing open-source tools demonstrate that the generated signals preserve high spatial fidelity across varying source positions and acoustic conditions. By enabling the generation of realistic multichannel audio under controlled and repeatable conditions, the proposed open framework provides a flexible and reproducible tool for the development, training, and evaluation of modern spatial audio and sound-source localization algorithms.

</details>


### [21] [Distributed Multichannel Active Noise Control with Asynchronous Communication](https://arxiv.org/abs/2601.15653)
*Junwei Ji,Dongyuan Shi,Boxiang Wang,Ziyi Yang,Haowen Li,Woon-Seng Gan*

Main category: eess.AS

TL;DR: 提出异步通信分布式多通道主动噪声控制系统，通过节点仅在性能下降时请求通信，显著降低通信开销，同时保持有效降噪效果。


<details>
  <summary>Details</summary>
Motivation: 传统分布式多通道主动噪声控制方法假设同步通信且需要频繁数据交换，导致高通信开销。为提升效率和适应性，需要一种更高效的通信策略。

Method: 采用异步通信策略，每个节点执行权重约束滤波x LMS算法，仅在本地降噪性能下降时独立请求通信。通信时其他节点传输本地控制滤波器与中心点的权重差异，用于更新控制滤波器和中心点。

Result: 仿真结果表明，提出的异步通信DMCANC系统在显著降低通信负载的同时，仍能保持有效的噪声降低效果，为异构网络提供更好的可扩展性。

Conclusion: 异步通信策略使分布式多通道主动噪声控制系统能够在保持协作行为的同时，显著降低通信开销，提高系统效率和适应性，特别适合异构网络环境。

Abstract: Distributed multichannel active noise control (DMCANC) offers effective noise reduction across large spatial areas by distributing the computational load of centralized control to multiple low-cost nodes. Conventional DMCANC methods, however, typically assume synchronous communication and require frequent data exchange, resulting in high communication overhead. To enhance efficiency and adaptability, this work proposes an asynchronous communication strategy where each node executes a weight-constrained filtered-x LMS (WCFxLMS) algorithm and independently requests communication only when its local noise reduction performance degrades. Upon request, other nodes transmit the weight difference between their local control filter and the center point in WCFxLMS, which are then integrated to update both the control filter and the center point. This design enables nodes to operate asynchronously while preserving cooperative behavior. Simulation results demonstrate that the proposed asynchronous communication DMCANC (ACDMCANC) system maintains effective noise reduction with significantly reduced communication load, offering improved scalability for heterogeneous networks.

</details>


### [22] [A Stabilized Hybrid Active Noise Control Algorithm of GFANC and FxNLMS with Online Clustering](https://arxiv.org/abs/2601.15889)
*Zhengding Luo,Haozhe Ma,Boxiang Wang,Ziyi Yang,Dongyuan Shi,Woon-Seng Gan*

Main category: eess.AS

TL;DR: 提出混合GFANC-FxNLMS算法，结合GFANC的快速响应和FxNLMS的低稳态误差优势，通过在线聚类模块避免不必要的重新初始化，实现快速响应、低稳态误差和高稳定性。


<details>
  <summary>Details</summary>
Motivation: FxNLMS算法收敛慢且有发散风险，但能达到低稳态误差；GFANC方法响应快但缺乏适应性，可能导致大稳态误差。需要结合两者优势，解决各自缺点。

Method: 提出混合GFANC-FxNLMS算法：GFANC提供帧级控制滤波器作为FxNLMS的初始化，FxNLMS在采样率下进行连续自适应。引入在线聚类模块避免不必要的重新初始化，提高系统稳定性。

Result: 仿真结果表明，所提算法实现了快速响应、极低稳态误差和高稳定性，仅需一个预训练的宽带滤波器。

Conclusion: 混合GFANC-FxNLMS算法成功结合了两种方法的优势，通过在线聚类模块解决了重新初始化问题，在主动噪声控制中表现出优越性能。

Abstract: The Filtered-x Normalized Least Mean Square (FxNLMS) algorithm suffers from slow convergence and a risk of divergence, although it can achieve low steady-state errors after sufficient adaptation. In contrast, the Generative Fixed-Filter Active Noise Control (GFANC) method offers fast response speed, but its lack of adaptability may lead to large steady-state errors. This paper proposes a hybrid GFANC-FxNLMS algorithm to leverage the complementary advantages of both approaches. In the hybrid GFANC-FxNLMS algorithm, GFANC provides a frame-level control filter as an initialization for FxNLMS, while FxNLMS performs continuous adaptation at the sampling rate. Small variations in the GFANC-generated filter may repeatedly reinitialize FxNLMS, interrupting its adaptation process and destabilizing the system. An online clustering module is introduced to avoid unnecessary re-initializations and improve system stability. Simulation results show that the proposed algorithm achieves fast response, very low steady-state error, and high stability, requiring only one pre-trained broadband filter.

</details>


### [23] [Timbre-Aware LLM-based Direct Speech-to-Speech Translation Extendable to Multiple Language Pairs](https://arxiv.org/abs/2601.16023)
*Lalaram Arya,Mrinmoy Bhattacharjee,Adarsh C. R.,S. R. Mahadeva Prasanna*

Main category: eess.AS

TL;DR: DS2ST-LM：基于多语言大语言模型的单阶段直接语音到语音翻译框架，通过合成数据缓解数据稀缺，在多种语言对上超越级联系统，并保持说话人音色


<details>
  <summary>Details</summary>
Motivation: 现有直接语音到语音翻译系统面临语义-声学对齐不稳定（尤其在平行语音数据稀缺时）、说话人身份保持困难以及多语言扩展性有限等挑战

Method: 提出DS2ST-LM框架：集成Whisper语音编码器、可学习投影模块、Qwen2-0.5B大语言模型和音色控制声码器；构建1000小时双语语料库GigaS2S-1000；研究两种语义标记生成策略和三种投影架构

Result: 在法语、西班牙语、德语、印地语、孟加拉语和乌尔都语等多种语言对上，DS2ST-LM在词汇（BLEU、METEOR）和语义（BLEURT、COMET）指标上均超越传统级联系统和ST+TTS基线；在说话人相似度和感知自然度方面优于先前直接S2ST系统

Conclusion: DS2ST-LM展示了基于大语言模型的直接语音到语音翻译框架的有效性，通过合成数据缓解数据稀缺问题，简单线性投影器优于复杂架构，且能有效保持说话人音色，为多语言直接S2ST提供了可扩展解决方案

Abstract: Direct Speech-to-Speech Translation (S2ST) has gained increasing attention for its ability to translate speech from one language to another, while reducing error propagation and latency inherent in traditional cascaded pipelines. However, existing direct S2ST systems continue to face notable challenges, including instability in semantic-acoustic alignment when parallel speech data is scarce, difficulty in preserving speaker identity, and limited multilingual scalability. In this work, we introduce DS2ST-LM, a scalable, single-stage direct S2ST framework leveraging a multilingual Large Language Model (LLM). The architecture integrates a Whisper speech encoder, a learnable projection module, a Qwen2-0.5B LLM, and a timbre-controlled vocoder. We construct GigaS2S-1000, a 1000-hour bilingual corpus by extending the GigaST dataset with high-fidelity synthetic target speech, and show that this synthetic data alleviates data scarcity to some extent. We investigate two semantic token generation strategies: speech-derived S3 tokens and text-derived tokens generated by a pre-trained LLM, and analyze their impact on training stability and semantic consistency. We further evaluate three projection architectures (Linear, Conv1D-Linear, and Q-Former) and observe that while higher-capacity projectors converge faster, the simple Linear projector achieves higher performance. Extensive experiments demonstrate that DS2ST-LM outperforms traditional cascaded and ST (Qwen-Audio) + TTS baselines across both lexical (BLEU, METEOR) and semantic (BLEURT, COMET) metrics, while extending to multiple language pairs, including French, Spanish, German, Hindi, Bengali, and Urdu. Furthermore, we incorporate timbre-aware speech synthesis to preserve speaker information, enabling DS2ST-LM to surpass prior direct S2ST systems in both speaker similarity and perceptual naturalness.

</details>


### [24] [Loose coupling of spectral and spatial models for multi-channel diarization and enhancement of meetings in dynamic environments](https://arxiv.org/abs/2601.16077)
*Adrian Meise,Tobias Cord-Landwehr,Christoph Boeddeker,Marc Delcroix,Tomohiro Nakatani,Reinhold Haeb-Umbach*

Main category: eess.AS

TL;DR: 提出一种新颖的联合空间和频谱混合模型，通过概率建模将说话人和位置索引关联，解决移动说话人场景下的声源分离和说话人日志问题


<details>
  <summary>Details</summary>
Motivation: 麦克风阵列可以同时利用空间和频谱信息进行说话人日志和信号增强，但当说话人移动时，空间位置与说话人之间不存在一一对应关系，现有紧耦合系统无法有效处理这种情况

Method: 提出联合空间和频谱混合模型，包含两个松散耦合的子模型：一个处理空间信息，一个处理频谱信息。通过概率建模说话人和位置索引之间的关系，允许说话人在不同位置说话

Result: 在模拟说话人位置变化的LibriCSS数据集上实验，相比紧耦合子系统取得了显著改进

Conclusion: 提出的松散耦合联合模型能有效处理移动说话人场景，同时利用空间和频谱信息，优于传统紧耦合方法

Abstract: Sound capture by microphone arrays opens the possibility to exploit spatial, in addition to spectral, information for diarization and signal enhancement, two important tasks in meeting transcription. However, there is no one-to-one mapping of positions in space to speakers if speakers move. Here, we address this by proposing a novel joint spatial and spectral mixture model, whose two submodels are loosely coupled by modeling the relationship between speaker and position index probabilistically. Thus, spatial and spectral information can be jointly exploited, while at the same time allowing for speakers speaking from different positions. Experiments on the LibriCSS data set with simulated speaker position changes show great improvements over tightly coupled subsystems.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [25] [Abusive music and song transformation using GenAI and LLMs](https://arxiv.org/abs/2601.15348)
*Jiyang Choi,Rohitash Chandra*

Main category: cs.SD

TL;DR: 使用生成式AI和大型语言模型自动转换流行音乐中的辱骂性歌词和演唱方式，通过改变语调、强度和情感来减少攻击性内容，同时保持音乐连贯性。


<details>
  <summary>Details</summary>
Motivation: 音乐中反复出现的暴力和辱骂内容可能影响听众情绪和行为，甚至正常化攻击行为或强化有害刻板印象。传统的内容审核方法（如静音或替换单个词语）可能引发"禁果效应"，使被审查内容因受限而更具吸引力。

Method: 采用生成式AI和大型语言模型，不仅改变歌词内容，还转换演唱的语调、强度和情感表达。对四首英文歌曲及其转换版本进行比较分析，通过声学分析和情感分析评估变化。

Result: 生成式AI显著降低了声乐攻击性：声学分析显示谐波噪声比、倒谱峰值突出度和振幅微扰有所改善；情感分析显示攻击性减少了63.3-85.6%，副歌部分改善最大（减少达88.6%）。转换后的版本保持了音乐连贯性。

Conclusion: 该方法展示了生成式AI在创造更安全聆听体验方面的潜力，既能减轻有害内容，又能保留艺术表达，为传统内容审核提供了有前景的替代方案，避免了"禁果效应"。

Abstract: Repeated exposure to violence and abusive content in music and song content can influence listeners' emotions and behaviours, potentially normalising aggression or reinforcing harmful stereotypes. In this study, we explore the use of generative artificial intelligence (GenAI) and Large Language Models (LLMs) to automatically transform abusive words (vocal delivery) and lyrical content in popular music. Rather than simply muting or replacing a single word, our approach transforms the tone, intensity, and sentiment, thus not altering just the lyrics, but how it is expressed. We present a comparative analysis of four selected English songs and their transformed counterparts, evaluating changes through both acoustic and sentiment-based lenses. Our findings indicate that Gen-AI significantly reduces vocal aggressiveness, with acoustic analysis showing improvements in Harmonic to Noise Ratio, Cepstral Peak Prominence, and Shimmer. Sentiment analysis reduced aggression by 63.3-85.6\% across artists, with major improvements in chorus sections (up to 88.6\% reduction). The transformed versions maintained musical coherence while mitigating harmful content, offering a promising alternative to traditional content moderation that avoids triggering the "forbidden fruit" effect, where the censored content becomes more appealing simply because it is restricted. This approach demonstrates the potential for GenAI to create safer listening experiences while preserving artistic expression.

</details>


### [26] [DeepASMR: LLM-Based Zero-Shot ASMR Speech Generation for Anyone of Any Voice](https://arxiv.org/abs/2601.15596)
*Leying Zhang,Tingxiao Zhou,Haiyang Sun,Mengxiao Bi,Yanmin Qian*

Main category: cs.SD

TL;DR: DeepASMR是首个零样本ASMR生成框架，仅需目标说话人的普通朗读语音片段即可生成其声音的高保真ASMR，无需ASMR训练数据


<details>
  <summary>Details</summary>
Motivation: 现有TTS系统虽然能生成高质量的朗读式语音，但难以生成ASMR这种低强度、放松式语音风格，主要挑战包括ASMR的细微特征（常为无声音）和零样本说话人适应需求

Method: 1) 发现离散语音token能软分解ASMR风格和说话人音色；2) 提出两阶段流程：使用LLM进行内容-风格编码，使用流匹配声学解码器进行音色重建

Result: DeepASMR在ASMR生成的自然度和风格保真度上达到SOTA，同时保持正常语音合成的竞争力；贡献了DeepASMR-DB（670小时英中多说话人ASMR语料库）和包含客观指标、人工听测、LLM评分、无声音分析的新评估协议

Conclusion: DeepASMR是首个零样本ASMR生成框架，仅需普通朗读语音即可为任何声音生成高质量ASMR，解决了ASMR生成的关键挑战

Abstract: While modern Text-to-Speech (TTS) systems achieve high fidelity for read-style speech, they struggle to generate Autonomous Sensory Meridian Response (ASMR), a specialized, low-intensity speech style essential for relaxation. The inherent challenges include ASMR's subtle, often unvoiced characteristics and the demand for zero-shot speaker adaptation. In this paper, we introduce DeepASMR, the first framework designed for zero-shot ASMR generation. We demonstrate that a single short snippet of a speaker's ordinary, read-style speech is sufficient to synthesize high-fidelity ASMR in their voice, eliminating the need for whispered training data from the target speaker. Methodologically, we first identify that discrete speech tokens provide a soft factorization of ASMR style from speaker timbre. Leveraging this insight, we propose a two-stage pipeline incorporating a Large Language Model (LLM) for content-style encoding and a flow-matching acoustic decoder for timbre reconstruction. Furthermore, we contribute DeepASMR-DB, a comprehensive 670-hour English-Chinese multi-speaker ASMR speech corpus, and introduce a novel evaluation protocol integrating objective metrics, human listening tests, LLM-based scoring and unvoiced speech analysis. Extensive experiments confirm that DeepASMR achieves state-of-the-art naturalness and style fidelity in ASMR generation for anyone of any voice, while maintaining competitive performance on normal speech synthesis.

</details>


### [27] [Qwen3-TTS Technical Report](https://arxiv.org/abs/2601.15621)
*Hangrui Hu,Xinfa Zhu,Ting He,Dake Guo,Bin Zhang,Xiong Wang,Zhifang Guo,Ziyue Jiang,Hongkun Hao,Zishan Guo,Xinyu Zhang,Pei Zhang,Baosong Yang,Jin Xu,Jingren Zhou,Junyang Lin*

Main category: cs.SD

TL;DR: Qwen3-TTS系列是一个先进的多语言、可控、鲁棒且支持流式传输的文本转语音模型，支持3秒语音克隆和基于描述的控制，采用双轨LM架构和两种语音分词器，在多项基准测试中达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个能够支持多语言、高可控性、鲁棒性强且支持实时流式传输的文本转语音系统，满足现代语音合成应用对语音克隆、细粒度控制和低延迟的需求。

Method: 采用双轨语言模型架构实现实时合成，配合两种语音分词器：1) Qwen-TTS-Tokenizer-25Hz：单码本编解码器，强调语义内容，支持流式波形重建；2) Qwen-TTS-Tokenizer-12Hz：12.5Hz、16层多码本设计，实现极低比特率和超低延迟流式传输。

Result: 在超过500万小时、10种语言的语音数据上训练，在TTS多语言测试集、InstructTTSEval和长语音测试集等客观和主观基准测试中均达到最先进的性能，支持97ms的首包发射延迟。

Conclusion: Qwen3-TTS系列在语音合成质量、可控性、多语言支持和实时性能方面均表现出色，通过开源Apache 2.0许可证发布模型和分词器，促进社区研究和开发。

Abstract: In this report, we present the Qwen3-TTS series, a family of advanced multilingual, controllable, robust, and streaming text-to-speech models. Qwen3-TTS supports state-of-the-art 3-second voice cloning and description-based control, allowing both the creation of entirely novel voices and fine-grained manipulation over the output speech. Trained on over 5 million hours of speech data spanning 10 languages, Qwen3-TTS adopts a dual-track LM architecture for real-time synthesis, coupled with two speech tokenizers: 1) Qwen-TTS-Tokenizer-25Hz is a single-codebook codec emphasizing semantic content, which offers seamlessly integration with Qwen-Audio and enables streaming waveform reconstruction via a block-wise DiT. 2) Qwen-TTS-Tokenizer-12Hz achieves extreme bitrate reduction and ultra-low-latency streaming, enabling immediate first-packet emission ($97\,\mathrm{ms}$) through its 12.5 Hz, 16-layer multi-codebook design and a lightweight causal ConvNet. Extensive experiments indicate state-of-the-art performance across diverse objective and subjective benchmark (e.g., TTS multilingual test set, InstructTTSEval, and our long speech test set). To facilitate community research and development, we release both tokenizers and models under the Apache 2.0 license.

</details>


### [28] [EmotionThinker: Prosody-Aware Reinforcement Learning for Explainable Speech Emotion Reasoning](https://arxiv.org/abs/2601.15668)
*Dingdong Wang,Shujie Liu,Tianhua Zhang,Youjun Chen,Jinyu Li,Helen Meng*

Main category: cs.SD

TL;DR: 该论文提出EmotionThinker，将语音情感识别重新定义为深度推理问题，通过强化学习生成带有可解释性解释的准确情感预测，在情感准确性和解释质量上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前语音大语言模型和传统语音情感识别系统将情感理解简单视为分类问题，缺乏预测的可解释性，且未充分利用大语言模型的表达和推理能力。

Method: 1) 构建EmotionCoT-35K情感推理数据集；2) 开发增强韵律感知的基础模型EmotionThinker-Base；3) 提出GRPO-PTR强化学习方法，结合渐进式推理奖励和信任感知机制。

Result: EmotionThinker在情感准确性和解释质量上均超越先前最先进的评估模型，证明韵律增强能提升情感理解能力。

Conclusion: 该工作将语音情感识别推向可解释的多模态推理，通过强化学习框架实现了准确的情感预测与可解释的解释生成。

Abstract: Emotional information in speech plays a unique role in multimodal perception. However, current Speech Large Language Models (SpeechLLMs), similar to conventional speech emotion recognition (SER) systems, still treat emotion understanding as a simple classification problem. This provides limited interpretability of predictions, while leaving the LLMs' expressive and reasoning capabilities underutilized. In this work, we take the first step to reformulate SER as a deep reasoning problem through reinforcement learning (RL). We propose EmotionThinker, which is designed to generate accurate emotion predictions with interpretable explanations grounded in fine-grained acoustic cues. To achieve this, we first construct EmotionCoT-35K, an emotional reasoning dataset with Chain-of-Thought annotations and detailed captions. Second, we observe that current SpeechLLMs exhibit weak prosody perception, whereas prosodic cues constitute fundamental signals for interpreting emotions. To address this, we develop the prosody-enhanced foundation model EmotionThinker-Base, and demonstrate that prosody enhancement improves emotion understanding. Third, we introduce Group-Relative-Policy-Optimization with Progressive-Trust-aware-Reasoning-Reward (GRPO-PTR) for RL. Different from standard GRPO, which relies only on rule-based outcome rewards, GRPO-PTR progressively introduces reasoning reward, dynamically adjusts it with a trustworthiness weight reflecting the alignment between reasoning and outcome, and evaluates the overall reasoning quality with a reward model based on multi-dimensional criteria. EmotionThinker outperforms previous state-of-the-art evaluation models both in emotion accuracy and explanation quality, advancing SER toward interpretable multimodal reasoning. Project page: https://github.com/dingdongwang/EmotionThinker

</details>


### [29] [Bridging the Perception Gap: A Lightweight Coarse-to-Fine Architecture for Edge Audio Systems](https://arxiv.org/abs/2601.15676)
*Hengfan Zhang,Yueqian Lin,Hai Helen Li,Yiran Chen*

Main category: cs.SD

TL;DR: CoFi-Agent是一个混合边缘-云架构，通过本地快速感知和条件性云端细粒度分析，在保持计算效率的同时提升音频语言模型的推理能力。


<details>
  <summary>Details</summary>
Motivation: 在边缘设备上部署音频语言模型面临感知深度与计算效率的矛盾：轻量级本地模型只能生成泛化摘要而缺乏多步推理所需的细微证据，而完全云端处理则带来不可接受的延迟、带宽成本和隐私风险。

Method: 提出CoFi-Agent混合架构，包含本地7B音频语言模型进行快速单次感知，云端控制器检测不确定性并触发条件性细粒度分析，使用本地工具如时间重听和本地ASR进行轻量级规划。

Result: 在MMAR基准测试中，CoFi-Agent将准确率从27.20%提升至53.60%，同时比始终开启的调查流水线实现了更好的准确率-效率权衡。

Conclusion: CoFi-Agent通过工具增强的条件性边缘-云协作，在实际系统约束下弥合了感知差距，为音频推理提供了有效的混合解决方案。

Abstract: Deploying Audio-Language Models (Audio-LLMs) on edge infrastructure exposes a persistent tension between perception depth and computational efficiency. Lightweight local models tend to produce passive perception - generic summaries that miss the subtle evidence required for multi-step audio reasoning - while indiscriminate cloud offloading incurs unacceptable latency, bandwidth cost, and privacy risk. We propose CoFi-Agent (Tool-Augmented Coarse-to-Fine Agent), a hybrid architecture targeting edge servers and gateways. It performs fast local perception and triggers conditional forensic refinement only when uncertainty is detected. CoFi-Agent runs an initial single-pass on a local 7B Audio-LLM, then a cloud controller gates difficult cases and issues lightweight plans for on-device tools such as temporal re-listening and local ASR. On the MMAR benchmark, CoFi-Agent improves accuracy from 27.20% to 53.60%, while achieving a better accuracy-efficiency trade-off than an always-on investigation pipeline. Overall, CoFi-Agent bridges the perception gap via tool-enabled, conditional edge-cloud collaboration under practical system constraints.

</details>


### [30] [U3-xi: Pushing the Boundaries of Speaker Recognition via Incorporating Uncertainty](https://arxiv.org/abs/2601.15719)
*Junjie Li,Kong Aik Lee*

Main category: cs.SD

TL;DR: 提出U3-xi框架，通过估计帧级不确定性并分配自适应权重，提升说话人验证系统中说话人嵌入的可靠性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 在真实场景中，说话人验证系统的帧级表示不仅包含说话人相关信息，还包含各种干扰因素，不同帧对最终说话人表示的贡献不均等，需要解决这一问题。

Method: 提出U3-xi框架，包含三种不确定性监督策略：1）通过随机方差损失进行说话人级不确定性监督；2）通过自适应缩放机制进行全局级不确定性监督；3）重新设计不确定性估计模块，集成Transformer编码器和多视图自注意力机制。

Result: U3-xi是模型无关的，可应用于各种说话人编码器。应用于ECAPA-TDNN时，在VoxCeleb1测试集上EER相对提升21.1%，minDCF相对提升15.57%。

Conclusion: U3-xi框架通过有效估计帧级不确定性并分配自适应权重，显著提升了说话人验证系统的性能，同时增强了说话人嵌入的可靠性和可解释性。

Abstract: An utterance-level speaker embedding is typically obtained by aggregating a sequence of frame-level representations. However, in real-world scenarios, individual frames encode not only speaker-relevant information but also various nuisance factors. As a result, different frames contribute unequally to the final utterance-level speaker representation for Automatic Speaker Verification systems. To address this issue, we propose to estimate the inherent uncertainty of each frame and assign adaptive weights accordingly, where frames with higher uncertainty receive lower attention. Based on this idea, we present U3-xi, a comprehensive framework designed to produce more reliable and interpretable uncertainty estimates for speaker embeddings. Specifically, we introduce several strategies for uncertainty supervision. First, we propose speaker-level uncertainty supervision via a Stochastic Variance Loss, where the distance between an utterance embedding and its corresponding speaker centroid serves as a pseudo ground truth for uncertainty learning. Second, we incorporate global-level uncertainty supervision by injecting the predicted uncertainty into the sof tmax scale during training. This adaptive scaling mechanism adjusts the sharpness of the decision boundary according to sample difficulty, providing global guidance. Third, we redesign the uncertainty estimation module by integrating a Transformer encoder with multi-view self-attention, enabling the model to capture rich local and long-range temporal dependencies. Comprehensive experiments demonstrate that U3-xi is model-agnostic and can be seamlessly applied to various speaker encoders. In particular, when applied to ECAPA-TDNN, it achieves 21.1% and 15.57% relative improvements on the VoxCeleb1 test sets in terms of EER and minDCF, respectively.

</details>


### [31] [PF-D2M: A Pose-free Diffusion Model for Universal Dance-to-Music Generation](https://arxiv.org/abs/2601.15872)
*Jaekwon Im,Natalia Polouliakh,Taketo Akama*

Main category: cs.SD

TL;DR: PF-D2M：基于扩散模型的通用舞蹈到音乐生成方法，通过渐进训练策略解决数据稀缺问题，在舞蹈-音乐对齐和音乐质量上达到SOTA


<details>
  <summary>Details</summary>
Motivation: 现有舞蹈到音乐生成方法通常依赖单个舞者的身体运动特征和有限的数据集，限制了其在多舞者和非人类舞者等真实场景中的应用性能

Method: 提出PF-D2M，一种基于扩散模型的通用舞蹈到音乐生成模型，从舞蹈视频中提取视觉特征，采用渐进训练策略解决数据稀缺和泛化挑战

Result: 主客观评估表明，PF-D2M在舞蹈-音乐对齐和音乐质量方面达到了最先进的性能

Conclusion: PF-D2M通过视觉特征提取和渐进训练策略，有效解决了现有方法的局限性，在舞蹈到音乐生成任务上取得了显著改进

Abstract: Dance-to-music generation aims to generate music that is aligned with dance movements. Existing approaches typically rely on body motion features extracted from a single human dancer and limited dance-to-music datasets, which restrict their performance and applicability to real-world scenarios involving multiple dancers and non-human dancers. In this paper, we propose PF-D2M, a universal diffusion-based dance-to-music generation model that incorporates visual features extracted from dance videos. PF-D2M is trained with a progressive training strategy that effectively addresses data scarcity and generalization challenges. Both objective and subjective evaluations show that PF-D2M achieves state-of-the-art performance in dance-music alignment and music quality.

</details>


### [32] [Distillation-based Layer Dropping (DLD) Effective End-to-end Framework for Dynamic Speech Networks](https://arxiv.org/abs/2601.16117)
*Abdul Hannan,Daniele Falavigna,Shah Nawaz,Mubashir Noman,Markus Schedl,Alessio Brutti*

Main category: cs.SD

TL;DR: 提出基于知识蒸馏的层丢弃框架DLD，用于动态语音网络，在资源受限的边缘设备上实现更好的性能-计算权衡


<details>
  <summary>Details</summary>
Motivation: 边缘设备在资源受限且变化的环境中运行，需要能够适应可用资源限制的动态架构。现有的层丢弃方法在高低丢弃情况下对动态模型性能影响较大，恶化了性能-计算权衡

Method: 提出蒸馏基的层丢弃框架DLD，以端到端方式有效结合知识蒸馏和层丢弃的能力。使用Conformer和WavLM等语音识别方法，在三个公共基准上进行实验

Result: DLD框架在高丢弃和无丢弃情况下分别将词错误率降低9.32%和2.25%，同时减少33.3%的训练时间，实现了动态语音网络的最先进性能

Conclusion: 提出的DLD框架通过结合知识蒸馏和层丢弃，有效解决了现有层丢弃方法在性能-计算权衡方面的不足，为边缘设备上的动态语音网络提供了更好的解决方案

Abstract: Edge devices operate in constrained and varying resource settings, requiring dynamic architectures that can adapt to limitations of the available resources. To meet such demands, layer dropping ($\mathcal{LD}$) approach is typically used to transform static models into dynamic ones by skipping parts of the network along with reducing overall computational complexity. However, existing $\mathcal{LD}$ methods greatly impact the dynamic model's performance for low and high dropping cases, deteriorating the performance-computation trade-off. To this end, we propose a distillation-based layer dropping (DLD) framework that effectively combines the capabilities of knowledge distillation and $\mathcal{LD}$ in an end-to-end fashion, thereby achieving state-of-the-art performance for dynamic speech networks. Comprehensive experimentation utilizing well-known speech recognition methods, including conformer and WavLM, on three public benchmarks demonstrates the effectiveness of our framework, reducing the word error rate by $9.32\%$ and $2.25\%$ for high and no dropping cases with $33.3\%$ reduction in training time.

</details>


### [33] [Pay (Cross) Attention to the Melody: Curriculum Masking for Single-Encoder Melodic Harmonization](https://arxiv.org/abs/2601.16150)
*Maximos Kaliakatsos-Papakostas,Dimos Makris,Konstantinos Soiledis,Konstantinos-Theodoros Tsamis,Vassilis Katsouros,Emilios Cambouropoulos*

Main category: cs.SD

TL;DR: 提出FF训练课程，通过保持所有和声标记被掩码来增强旋律-和声交互，在单编码器旋律和声化任务中优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有基于掩码序列建模的单编码器Transformer方法在旋律和声化任务中，由于训练课程设计问题，导致旋律与和声之间的注意力机制较弱，特别是在域外场景下难以有效利用旋律线索

Method: 提出FF（full-to-full）训练课程：在多个训练步骤中保持所有和声标记被掩码，然后在训练过程中逐步解掩码整个序列，以增强旋律-和声交互。系统评估了不同实验轴：时间量化（四分音符vs十六分音符）、小节级vs拍号条件、旋律表示（全音域vs音高类别）、推理时解掩码策略

Result: FF课程在几乎所有指标上都优于基线方法，特别是在域外评估中表现突出，其中和声对新颖旋律线索的适应性至关重要。发现四分音符量化、小节标记交织和音高类别旋律表示在FF设置中具有优势

Conclusion: 训练课程设计对于实现有效的旋律条件化至关重要，full-to-full解掩码策略为单编码器和声化提供了稳健的方法，能够显著增强旋律-和声交互并提升域外泛化能力

Abstract: Melodic harmonization, the task of generating harmonic accompaniments for a given melody, remains a central challenge in computational music generation. Recent single encoder transformer approaches have framed harmonization as a masked sequence modeling problem, but existing training curricula inspired by discrete diffusion often result in weak (cross) attention between melody and harmony. This leads to limited exploitation of melodic cues, particularly in out-of-domain contexts. In this work, we introduce a training curriculum, FF (full-to-full), which keeps all harmony tokens masked for several training steps before progressively unmasking entire sequences during training to strengthen melody-harmony interactions. We systematically evaluate this approach against prior curricula across multiple experimental axes, including temporal quantization (quarter vs. sixteenth note), bar-level vs. time-signature conditioning, melody representation (full range vs. pitch class), and inference-time unmasking strategies. Models are trained on the HookTheory dataset and evaluated both in-domain and on a curated collection of jazz standards, using a comprehensive set of metrics that assess chord progression structure, harmony-melody alignment, and rhythmic coherence. Results demonstrate that the proposed FF curriculum consistently outperforms baselines in nearly all metrics, with particularly strong gains in out-of-domain evaluations where harmonic adaptability to novel melodic queues is crucial. We further find that quarter-note quantization, intertwining of bar tokens, and pitch-class melody representations are advantageous in the FF setting. Our findings highlight the importance of training curricula in enabling effective melody conditioning and suggest that full-to-full unmasking offers a robust strategy for single encoder harmonization.

</details>


### [34] [Domain-Incremental Continual Learning for Robust and Efficient Keyword Spotting in Resource Constrained Systems](https://arxiv.org/abs/2601.16158)
*Prakash Dhungana,Sayed Ahmad Salehi*

Main category: cs.SD

TL;DR: 提出一个用于关键词检测系统的持续学习框架，通过双输入CNN结合MFCC和Mel谱特征，配合多阶段去噪和原型更新机制，使小型模型能在动态噪声环境中自适应保持高性能。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的小型关键词检测系统面临领域偏移挑战，噪声和录音条件变化严重影响准确性和鲁棒性，需要一种能适应新领域同时保持计算效率的解决方案。

Method: 采用双输入CNN架构，结合MFCC和Mel谱特征；使用离散小波变换和谱减法进行多阶段去噪；通过原型更新和置信度驱动过滤选择样本，结合伪标签和排练缓冲区进行增量模型重训练；完整更新量化模型而非仅特定层。

Result: 在干净数据上达到99.63%准确率，在多样化噪声环境中（包括-10dB信噪比）保持超过94%的准确率，证明了框架在资源受限动态环境中的有效性。

Conclusion: 高效去噪与基于原型的持续学习相结合，使关键词检测模型能够在资源受限的动态环境中自主且鲁棒地运行，解决了小型模型在领域偏移下的适应性问题。

Abstract: Keyword Spotting (KWS) systems with small footprint models deployed on edge devices face significant accuracy and robustness challenges due to domain shifts caused by varying noise and recording conditions. To address this, we propose a comprehensive framework for continual learning designed to adapt to new domains while maintaining computational efficiency. The proposed pipeline integrates a dual-input Convolutional Neural Network, utilizing both Mel Frequency Cepstral Coefficients (MFCC) and Mel-spectrogram features, supported by a multi-stage denoising process, involving discrete wavelet transform and spectral subtraction techniques, plus model and prototype update blocks. Unlike prior methods that restrict updates to specific layers, our approach updates the complete quantized model, made possible due to compact model architecture. A subset of input samples are selected during runtime using class prototypes and confidence-driven filtering, which are then pseudo-labeled and combined with rehearsal buffer for incremental model retraining. Experimental results on noisy test dataset demonstrate the framework's effectiveness, achieving 99.63\% accuracy on clean data and maintaining robust performance (exceeding 94\% accuracy) across diverse noisy environments, even at -10 dB Signal-to-Noise Ratio. The proposed framework work confirms that integrating efficient denoising with prototype-based continual learning enables KWS models to operate autonomously and robustly in resource-constrained, dynamic environments.

</details>

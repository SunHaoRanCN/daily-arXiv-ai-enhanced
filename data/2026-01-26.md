<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 15]
- [eess.AS](#eess.AS) [Total: 6]
- [cs.SD](#cs.SD) [Total: 9]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Gesture Recognition from body-Worn RFID under Missing Data](https://arxiv.org/abs/2601.16301)
*Sahar Golipoor,Richard T. Brophy,Ying Liu,Reza Ghazalian,Stephan Sigg*

Main category: eess.SP

TL;DR: 提出基于被动反射标签的手势识别系统，通过数据插补和图卷积网络处理缺失数据，在21种手势识别上达到98.13%准确率


<details>
  <summary>Details</summary>
Motivation: 探索使用被动身体佩戴反射标签进行手势识别，解决实际应用中常见的缺失数据问题

Method: 提出数据处理流水线：使用线性和指数插值/外推恢复缺失数据；将标签表示为时序图节点，基于RSS和相位相关性构建边；训练基于图自注意力的图卷积神经网络

Result: 系统在21种手势识别上达到98.13%准确率，留一人出交叉验证准确率89.28%；手臂标签比手腕标签对识别贡献更大

Conclusion: 被动反射标签结合图神经网络能有效进行手势识别，手臂位置标签比手腕标签更具表达力，系统性能优于现有方法

Abstract: We explore hand-gesture recognition through the use of passive body-worn reflective tags. A data processing pipeline is proposed to address the issue of missing data. Specifically, missing information is recovered through linear and exponential interpolation and extrapolation. Furthermore, imputation and proximity-based inference are employed. We represent tags as nodes in a temporal graph, with edges formed based on correlations between received signal strength (RSS) and phase values across successive timestamps, and we train a graph-based convolutional neural network that exploits graph-based self-attention. The system outperforms state-of-the-art methods with an accuracy of 98.13% for the recognition of 21 gestures. We achieve 89.28% accuracy under leave-one-person-out cross-validation. We further investigate the contribution of various body locations on the recognition accuracy. Removing tags from the arms reduces accuracy by more than 10%, while removing the wrist tag only reduces accuracy by around 2%. Therefore, tag placements on the arms are more expressive for gesture recognition than on the wrist.

</details>


### [2] [Angle of Arrival Estimation for Gesture Recognition from reflective body-worn tags](https://arxiv.org/abs/2601.16303)
*Sahar Golipoor,Reza Ghazalian,Ines Lobato Mesquita,Stephan Sigg*

Main category: eess.SP

TL;DR: 该论文研究利用被动反射标签进行手势识别，提出使用到达角(AoA)跟踪作为区分特征，相比传统RSS和相位信号能显著提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于接收信号强度(RSS)和相位信号的手势识别方法在区分大量手势时存在局限性，因为这些特征在不同手势间往往相似，难以被学习算法有效捕捉。

Method: 1. 使用MUSIC算法验证AoA估计的可靠性；2. 提出基于卡尔曼平滑的AoA跟踪方法；3. 将AoA特征集成到手势识别系统中进行性能评估。

Result: 实验表明，AoA跟踪能有效区分RSS和相位无法区分的手势数据，将AoA特征集成到手势识别系统中可带来高达15%的性能提升。

Conclusion: AoA作为区分特征在手势识别中具有重要价值，基于AoA跟踪的方法能显著提升手势识别系统的性能，为解决传统信号特征相似性问题提供了有效方案。

Abstract: We investigate hand gesture recognition by leveraging passive reflective tags worn on the body. Considering a large set of gestures, distinct patterns are difficult to be captured by learning algorithms using backscattered received signal strength (RSS) and phase signals. This is because these features often exhibit similarities across signals from different gestures. To address this limitation, we explore the estimation of Angle of Arrival (AoA) as a distinguishing feature, since AoA characteristically varies during body motion. To ensure reliable estimation in our system, which employs Smart Antenna Switching (SAS), we first validate AoA estimation using the Multiple SIgnal Classification (MUSIC) algorithm while the tags are fixed at specific angles. Building on this, we propose an AoA tracking method based on Kalman smoothing. Our analysis demonstrates that, while RSS and phase alone are insufficient for distinguishing certain gesture data, AoA tracking can effectively differentiate them. To evaluate the effectiveness of AoA tracking, we implement gesture recognition system benchmarks and show that incorporating AoA features significantly boosts their performance. Improvements of up to 15% confirm the value of AoA-based enhancement.

</details>


### [3] [TransfoREM: Transformer aided 3D Radio Environment Mapping](https://arxiv.org/abs/2601.16421)
*Gautham Reddy,Ismail Guvenc,Mihail L. Sichitiu,Arupjyoti Bhuyan,Bryton Petersen,Jason Abrahamson*

Main category: eess.SP

TL;DR: TransfoREM：一种基于Transformer的3D无线电环境地图生成方法，用于预测无人机在更高海拔的蜂窝网络覆盖情况，相比传统方法具有更好的插值能力。


<details>
  <summary>Details</summary>
Motivation: 为无人机提供可靠的蜂窝网络连接是一个关键挑战，因为现有的地面网络主要部署在地面覆盖，无人机只能从天线旁瓣获得有限覆盖，且飞行动态会进一步恶化连接质量。

Method: 提出TransfoREM方法，结合确定性信道模型和真实世界数据来生成3D无线电环境地图。核心是使用Transformer模型，将无线电传播映射转化为序列预测任务来构建REM。

Result: TransfoREM在真实世界数据上相比传统的Kriging和其他机器学习技术具有更好的插值能力。该方法设计用于在基站级别集成到蜂窝网络中。

Conclusion: TransfoREM能够构建可用于增强资源分配、干扰管理和空间频谱利用的无线电环境地图，为解决无人机蜂窝网络覆盖问题提供了有效解决方案。

Abstract: Providing reliable cellular connectivity to Unmanned Aerial Vehicles (UAV) is a key challenge, as existing terrestrial networks are deployed mainly for ground-level coverage. The cellular network coverage may be available for a limited range from the antenna side lobes, with poor connectivity further exacerbated by UAV flight dynamics. In this work, we propose TransfoREM, a 3D Radio Environment Map (REM) generation method that combines deterministic channel models and real-world data to map terrestrial network coverage at higher altitudes. At the core of our solution is a transformer model that translates radio propagation mapping into a sequence prediction task to construct REMs. Our results demonstrate that TransfoREM offers improved interpolation capability on real-world data compared against conventional Kriging and other machine learning (ML) techniques. Furthermore, TransfoREM is designed for holistic integration into cellular networks at the base station (BS) level, where it can build REMs, which can then be leveraged for enhanced resource allocation, interference management, and spatial spectrum utilization.

</details>


### [4] [Auditory Attention Decoding without Spatial Information: A Diotic EEG Study](https://arxiv.org/abs/2601.16442)
*Masahiro Yoshino,Haruki Yokota,Junya Hara,Yuichi Tanaka,Hiroshi Higashi*

Main category: eess.SP

TL;DR: 提出一种用于双耳同声环境的听觉注意解码框架，通过将脑电和语音信号映射到共享潜在空间，消除空间线索依赖，在鸡尾酒会等真实场景中实现更准确的注意力解码。


<details>
  <summary>Details</summary>
Motivation: 现有听觉注意解码研究主要依赖双耳分听环境，利用空间方向线索进行分类，这限制了在真实世界场景（如鸡尾酒会）中的应用，因为真实场景中说话者可能重叠或动态移动。

Method: 提出双耳同声环境的AAD框架，使用独立编码器将脑电和语音信号映射到共享潜在空间：用wav2vec 2.0提取语音特征，2层1D CNN编码；用BrainNetwork架构编码脑电信号；通过计算脑电和语音表示之间的余弦相似度来识别注意语音。

Result: 在双耳同声脑电数据集上达到72.70%的准确率，比最先进的方向基AAD方法提高了22.58%。

Conclusion: 该方法消除了对空间线索的依赖，为真实世界听觉场景（如鸡尾酒会）中的听觉注意解码提供了更实用的解决方案，对智能助听器和客观听力测试系统的发展具有重要意义。

Abstract: Auditory attention decoding (AAD) identifies the attended speech stream in multi-speaker environments by decoding brain signals such as electroencephalography (EEG). This technology is essential for realizing smart hearing aids that address the cocktail party problem and for facilitating objective audiometry systems. Existing AAD research mainly utilizes dichotic environments where different speech signals are presented to the left and right ears, enabling models to classify directional attention rather than speech content. However, this spatial reliance limits applicability to real-world scenarios, such as the "cocktail party" situation, where speakers overlap or move dynamically. To address this challenge, we propose an AAD framework for diotic environments where identical speech mixtures are presented to both ears, eliminating spatial cues. Our approach maps EEG and speech signals into a shared latent space using independent encoders. We extract speech features using wav2vec 2.0 and encode them with a 2-layer 1D convolutional neural network (CNN), while employing the BrainNetwork architecture for EEG encoding. The model identifies the attended speech by calculating the cosine similarity between EEG and speech representations. We evaluate our method on a diotic EEG dataset and achieve 72.70% accuracy, which is 22.58% higher than the state-of-the-art direction-based AAD method.

</details>


### [5] [Cell-Free MIMO with Rotatable Antennas: When Macro-Diversity Meets Antenna Directivity](https://arxiv.org/abs/2601.16543)
*Xingxiang Peng,Qingqing Wu,Ziyuan Zheng,Yanze Zhu,Wen Chen,Penghui Huang,Ying Gao,Honghao Wang*

Main category: eess.SP

TL;DR: 论文提出在无蜂窝网络中使用可旋转天线增强最差用户速率，通过联合优化波束成形和天线方向，开发了交替优化算法和高效两阶段方案。


<details>
  <summary>Details</summary>
Motivation: 无蜂窝网络虽然利用分布式接入点实现宏分集，但用户几何位置和障碍物导致的信道质量差异限制了性能。可旋转天线通过调整天线主瓣方向来增强不利链路，从而更好地利用宏分集，提高网络性能和公平性。

Method: 1) 提出联合优化波束成形和天线方向的最大最小速率问题；2) 开发基于交替优化的算法：使用二阶锥规划更新波束成形器，使用逐次凸逼近优化天线方向；3) 提出高效两阶段方案：首先通过流形感知Frank-Wolfe更新最大化比例公平对数效用设计方向，然后使用基于SOCP的设计计算波束成形器。

Result: 仿真结果表明，所提出的方向感知设计相比传统仅波束成形的基准方法，实现了显著更高的最差用户速率。此外，更大的天线方向性在适当定向时能增强公平性，但方向不当反而会降低最差用户性能。

Conclusion: 可旋转天线是无蜂窝网络中增强最差用户性能和公平性的有效硬件自由度。联合优化波束成形和天线方向的设计能够显著提升网络性能，而提出的高效算法为实现这一目标提供了可行的解决方案。

Abstract: Cell-free networks leverage distributed access points (APs) to achieve macro-diversity, yet their performance is often constrained by large disparities in channel quality arising from user geometry and blockages. To address this, rotatable antennas (RAs) add a lightweight hardware degree of freedom by steering the antenna boresight toward dominant propagation directions to strengthen unfavorable links, thereby enabling the network to better exploit macro-diversity for higher and more uniform performance. This paper investigates an RA-enabled cell-free downlink network and formulates a max-min rate problem that jointly optimizes transmit beamforming and antenna orientations. To tackle this challenging problem, we develop an alternating-optimization-based algorithm that iteratively updates the beamformers via a second-order cone program (SOCP) and optimizes the antenna orientations using successive convex approximation. To reduce complexity, we further propose an efficient two-stage scheme that first designs orientations by maximizing a proportional-fair log-utility using manifold-aware Frank-Wolfe updates, and then computes the beamformers using an SOCP-based design. Simulation results demonstrate that the proposed orientation-aware designs achieve a substantially higher worst-user rate than conventional beamforming-only benchmarks. Furthermore, larger antenna directivity enhances fairness with proper orientation but can degrade the worst-user performance otherwise.

</details>


### [6] [Spiking Neural Networks for Communication Systems: Encoding Schemes, Learning Algorithms, and Equalization~Techniques](https://arxiv.org/abs/2601.16550)
*Eike-Manuel Edelmann*

Main category: eess.SP

TL;DR: 该论文研究了基于脉冲神经网络（SNN）的接收机设计，用于非线性时不变频率选择性信道，提出了量化编码和基于强化学习的更新算法，显著降低了能耗和复杂度，性能优于传统人工神经网络接收机。


<details>
  <summary>Details</summary>
Motivation: 现代通信系统复杂度不断增加导致功耗上升，而脉冲神经网络（SNN）受高效人脑启发，具有事件驱动和低功耗特性，有望解决通信系统的能耗问题。然而SNN面临学习规则和神经编码等关键挑战。

Method: 1. 使用带代理梯度的通过时间反向传播作为更新规则；2. 提出新颖的量化编码（QE）作为神经编码方法；3. 比较两种基于强度调制直接检测链路的接收机架构；4. 引入基于强化学习的策略梯度更新算法（PGU）优化编码参数。

Result: 1. 使用决策反馈和量化编码的SNN接收机在均衡性能和脉冲计数方面表现优异；2. SNN接收机显著优于ANN接收机；3. PGU算法大幅减少运行时间、复杂度和每次推理的脉冲数，同时保持性能。

Conclusion: 该论文成功开发了SNN接收机的设计和优化框架，通过解决SNN优化的关键挑战，为未来设计和部署高能效SNN接收机奠定了基础，推动了低功耗实时信号处理的发展。

Abstract: Machine learning with artificial neural networks (ANNs), provides solutions for the growing complexity of modern communication systems. This complexity, however, increases power consumption, making the systems energy-intensive. Spiking neural networks (SNNs) represent a novel generation of neural networks inspired by the highly efficient human brain. By emulating its event-driven and energy-efficient mechanisms, SNNs enable low-power, real-time signal processing. They differ from ANNs in two key ways: they exhibit inherent temporal dynamics and process and transmit information as short binary signals called spikes. Despite their promise, major challenges remain, e.g., identifying optimal learning rules and effective neural encoding. This thesis investigates the design of SNN-based receivers for nonlinear time-invariant frequency-selective channels. Backpropagation through time with surrogate gradients is identified as a promising update rule and the novel quantization encoding (QE) as promising neural encoding. Given the model of the intensity modulation with direct detection link, we compare two different receiver architectures based on equalization performance and spike count. Using decision feedback and QE achieves both strong performance and low spike counts. Notably, SNN-based receivers significantly outperform ANN-based counterparts. We furthermore introduce policy gradient-based update (PGU), an reinforcement learning-based update algorithm that requires no backpropagation. Using PGU, encoding parameters are optimized, drastically reducing runtime, complexity, and spikes per inference while maintaining performance. This thesis contributes a successful design and optimization framework for SNN-based receivers. By addressing key challenges in SNN optimization, it facilitates future advances in the design and deployment of energy-efficient SNN receivers.

</details>


### [7] [Real-Time Evaluation of an Ultra-Tight GNSS/INS Integration Based on Adaptive PLL Bandwidth](https://arxiv.org/abs/2601.16577)
*Gaël Pages,Priot Benoît,Guillaume Beaugendre*

Main category: eess.SP

TL;DR: 提出一种基于向量跟踪环架构的GNSS/INS超紧耦合系统，通过INS信息自适应调整PLL带宽，可在FPGA上实现且占用资源少


<details>
  <summary>Details</summary>
Motivation: 传统向量跟踪解决方案需要并行运行标量环或存储预下载星历数据，增加了FPGA面积和存储资源消耗。需要一种更高效、资源占用更少的GNSS/INS超紧耦合架构

Method: 采用向量跟踪环架构的GNSS接收机，根据惯性导航系统信息自适应调整相位锁定环带宽。在环内解码导航消息，无需并行标量环或预存星历数据。使用GPS L1/C和Galileo E1信号，包含1个捕获模块和16个跟踪通道（8个GPS和8个Galileo），在Zynq-Ultrascale FPGA上实现

Result: 提出的架构易于在FPGA等片上系统组件上实现，对现有GNSS接收机平台只需少量修改。相比传统向量解决方案，不增加FPGA占用面积，不使用额外存储资源

Conclusion: 该GNSS/INS超紧耦合架构提供了一种资源高效、易于实现的解决方案，特别适合在FPGA平台上部署，具有良好的实用性和可扩展性

Abstract: In this contribution, we propose a GNSS/INS ultra-tight coupling in which the GNSS receiver architecture is based on a vector tracking loop type architecture. In the proposed approach, the phase lock loop bandwidth is adapted according to the inertial navigation system information. The latter has the advantage to be easily implementable on a System-on-Chip component such as an FPGA (Field-Programmable Gate Arrays), and can be implemented with minor modifications on an existing GNSS receiver platform. Moreover, compared to classical vector-based solutions, the proposed architecture decodes the navigation message in the loop, without the need to run scalar loops in parallel or having to store pre-downloaded ephemeris data. This architecture therefore does not increase the area occupied on the FPGA and does not use additional resources for storage. The proposed GNSS receiver architecture uses GPS L1/C and Galileo E1 signals and is composed of one acquisition module and 16 tracking channels (8 GPS and 8 Galileo) which are implemented within a FPGA (Zynq-Ultrascale).

</details>


### [8] [Learning Successive Interference Cancellation for Low-Complexity Soft-Output MIMO Detection](https://arxiv.org/abs/2601.16586)
*Benedikt Fesl,Fatih Capar*

Main category: eess.SP

TL;DR: 提出recurSIC——一种轻量级学习型MIMO检测框架，结合SIC结构和学习处理，在低复杂度下实现可靠的硬检测和软信息生成，适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 5G RedCap和IoT设备需要低复杂度MIMO检测，同时要支持高阶调制并生成可靠的软信息用于信道解码，现有方法难以平衡这些需求。

Method: 基于SIC结构设计轻量级学习框架，通过多路径假设跟踪生成软信息，仅需单次前向传播和极少参数，复杂度可调。

Result: 在真实无线场景中，recurSIC在极低复杂度下实现了优异的硬检测和软检测性能。

Conclusion: recurSIC是适合边缘受限MIMO接收器的有效解决方案，平衡了性能、复杂度和内存需求。

Abstract: Low-complexity multiple-input multiple-output (MIMO) detection remains a key challenge in modern wireless systems, particularly for 5G reduced capability (RedCap) and internet-of-things (IoT) devices. In this context, the growing interest in deploying machine learning on edge devices must be balanced against stringent constraints on computational complexity and memory while supporting high-order modulation. Beyond accurate hard detection, reliable soft information is equally critical, as modern receivers rely on soft-input channel decoding, imposing additional requirements on the detector design. In this work, we propose recurSIC, a lightweight learning-based MIMO detection framework that is structurally inspired by successive interference cancellation (SIC) and incorporates learned processing stages. It generates reliable soft information via multi-path hypothesis tracking with a tunable complexity parameter while requiring only a single forward pass and a minimal parameter count. Numerical results in realistic wireless scenarios show that recurSIC achieves strong hard- and soft-detection performance at very low complexity, making it well suited for edge-constrained MIMO receivers.

</details>


### [9] [Assessment of Errors of Fundamental Frequency Estimation Methods in the Presence of Voltage Fluctuations and Distortions](https://arxiv.org/abs/2601.16606)
*Antonio Bracale,Pasquale De Falco,Piotr Kuwałek,Grzegorz Wiczyński*

Main category: eess.SP

TL;DR: 该论文通过数值模拟研究评估了现代电网条件下各种基频估计方法的误差，包括IEC 61000-4-30标准方法，特别关注电压波动和畸变同时存在的情况。


<details>
  <summary>Details</summary>
Motivation: 基频是定义电能质量的关键参数之一。在现代电网条件下正确确定该参数至关重要，特别是诊断目的需要在短时间内窗口内高效估计该参数。

Method: 采用数值模拟研究方法，使用模拟现代电网状态的测试信号（包括电压波动和畸变同时发生的情况），评估各种基频估计方法的误差，包括标准IEC 61000-4-30方法。

Result: 研究提供了各种基频估计方法在模拟现代电网条件下的误差评估结果，包括IEC 61000-4-30标准方法的表现。

Conclusion: 基于研究结果得出结论，为现代电网条件下基频估计方法的选择和应用提供指导。

Abstract: The fundamental frequency is one of the parameters that define power quality. Correctly determining this parameter under the conditions that prevail in modern power grids is crucial. Diagnostic purposes often require an efficient estimation of this parameter within short time windows. Therefore, this article presents the results of numerical simulation studies that allow the assessment of errors in various fundamental frequency estimation methods, including the standard IEC 61000-4-30 method, when the analyzed signal has a form similar to that found in modern power grids. For the purposes of this study, a test signal was adopted recreating the states of the power grid, including the simultaneous occurrence of voltage fluctuations and distortions. Conclusions are presented based on conducted research.

</details>


### [10] [Low-Power On-Device Gesture Recognition with Einsum Networks](https://arxiv.org/abs/2601.16662)
*Sahar Golipoor,Lingyun Yao,Martin Andraud,Stephan Sigg*

Main category: eess.SP

TL;DR: 提出基于Einsum网络的分布式资源受限设备手势识别系统，在低功耗RFID手势识别场景中优于基准模型


<details>
  <summary>Details</summary>
Motivation: 为分布式资源受限设备网络设计高效的手势识别系统，解决传统方法在计算资源、能耗和可解释性方面的限制

Method: 采用Einsum网络作为概率电路，结合RSS/相位处理和AoA估计的特征提取，通过专用硬件处理特征，最后在决策聚合模块融合所有设备输出进行手势预测

Result: 实验结果表明该方法在低功耗、被动RFID手势识别场景中优于基准模型

Conclusion: 基于Einsum网络的分布式手势识别系统在资源受限设备上实现了高效、可解释的手势识别，为边缘计算应用提供了可行方案

Abstract: We design a gesture-recognition pipeline for networks of distributed, resource constrained devices utilising Einsum Networks. Einsum Networks are probabilistic circuits that feature a tractable inference, explainability, and energy efficiency. The system is validated in a scenario of low-power, body-worn, passive Radio Frequency Identification-based gesture recognition. Each constrained device includes task-specific processing units responsible for Received Signal Strength (RSS) and phase processing or Angle of Arrival (AoA) estimation, along with feature extraction, as well as dedicated Einsum hardware that processes the extracted features. The output of all constrained devices is then fused in a decision aggregation module to predict gestures. Experimental results demonstrate that the method outperforms the benchmark models.

</details>


### [11] [OFDM-Based ISAC Imaging of Extended Targets via Inverse Virtual Aperture Processing](https://arxiv.org/abs/2601.16664)
*Michael Negosanti,Lorenzo Pucci,Andrea Giorgetti*

Main category: eess.SP

TL;DR: 该研究探讨了利用逆虚拟孔径(IVA)的集成感知与通信系统在车载场景中对移动扩展目标进行成像的性能，分析了感知精度与通信效率之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 随着下一代无线网络的发展，集成感知与通信(ISAC)系统在车载场景中变得越来越重要。需要研究如何有效利用通信波形同时实现感知功能，特别是对移动扩展目标（如车辆）的成像能力。

Method: 采用MIMO-OFDM波形，基站作为单基地传感器。通过运动补偿技术处理目标反射的回波，形成IVA距离-多普勒（跨距离）图像。使用5G NR波形（中高频段），目标模型基于3GPP Release 19定义，将车辆建模为一组空间分布的散射体。

Result: 通过图像对比度(IC)和目标质心距离估计的均方根误差(RMSE)评估性能。通过改变用于IVA成像的子载波分配，研究了感知精度与通信效率之间的权衡关系。

Conclusion: 该研究为下一代无线网络中设计有效的感知策略提供了见解，展示了利用通信波形实现高质量目标成像的可行性，并揭示了感知精度与通信资源分配之间的重要权衡。

Abstract: This work investigates the performance of an integrated sensing and communication (ISAC) system exploiting inverse virtual aperture (IVA) for imaging moving extended targets in vehicular scenarios. A base station (BS) operates as a monostatic sensor using MIMO-OFDM waveforms. Echoes reflected by the target are processed through motion-compensation techniques to form an IVA range-Doppler (cross-range) image. A case study considers a 5G NR waveform in the upper mid-band, with the target model defined in 3GPP Release 19, representing a vehicle as a set of spatially distributed scatterers. Performance is evaluated in terms of image contrast (IC) and the root mean squared error (RMSE) of the estimated target-centroid range. Finally, the trade-off between sensing accuracy and communication efficiency is examined by varying the subcarrier allocation for IVA imaging. The results provide insights for designing effective sensing strategies in next-generation radio networks.

</details>


### [12] [Precise Low-Current Measurement Techniques for IoT Devices: A Case Study on MoleNet](https://arxiv.org/abs/2601.16727)
*Julian Block,Andreas Könsgen,Jens Dede,Anna Förster*

Main category: eess.SP

TL;DR: 比较专用源测量单元(SMU)在物联网设备微小电流测量中的性能，并以MoleNet传感器板为例进行应用演示


<details>
  <summary>Details</summary>
Motivation: 物联网设备通常需要长时间电池供电，功耗至关重要。传统万用表和示波器难以精确测量设备休眠时的微小电流，需要专用测量工具

Method: 比较多种专用源测量单元(SMU)，这些设备能够以高精度测量微小电流，并以MoleNet物联网传感器板作为应用实例进行电流测量演示

Result: 专用SMU相比传统测量工具更适合物联网设备的微小电流测量，能够提供更高精度的功耗数据

Conclusion: 在物联网设备部署前，使用专用源测量单元进行精确电流测量对于评估功耗和延长电池寿命至关重要

Abstract: Power consumption is a crucial aspect of IoT devices which often have to run on a battery for an extended period of time. Therefore, supply current measurements are crucial before deploying a device in the field. Multimeters and oscilloscopes are not well suited when it comes to measuring very small currents which occur e.g. when an IoT device is in sleep mode. In this report, we compare dedicated source measurement units (SMUs) which allow to measure very small currents with high precision. As an application example, we demonstrate current measurements on our MoleNet IoT sensor board.

</details>


### [13] [A Dynamic Parametric Simulator for Fetal Heart Sounds](https://arxiv.org/abs/2601.16792)
*Yingtong Zhou,Yiang Zhou,Zhengxian Qu,Kang Liu,Ting Tan*

Main category: eess.SP

TL;DR: 开发了一个可重复的胎儿心音图动态参数模拟器，通过合成胎儿S1/S2事件、卷积传输模块和可配置干扰来生成腹部fPCG信号，支持fPCG处理方法评估。


<details>
  <summary>Details</summary>
Motivation: 胎儿心音图研究面临腹部记录数据有限、母体干扰严重、信号衰减明显等问题，导致难以进行可重复的基准测试。

Method: 结合周期级胎儿S1/S2事件合成、卷积传输模块、可配置干扰和背景噪声，从真实腹部记录中逐周期校准模型参数，捕捉心跳间变异性。

Result: 生成的信号在包络时间结构和频域特性方面与真实记录验证一致，模拟器作为开源软件发布。

Conclusion: 该模拟器支持在受控采集条件下快速、可重复地评估fPCG处理方法，解决了胎儿心音图研究中的基准测试挑战。

Abstract: Research on fetal phonocardiogram (fPCG) is challenged by the limited number of abdominal recordings, substantial maternal interference, and marked transmissioninduced signal attenuation that complicate reproducible benchmarking. We present a reproducible dynamic parametric simulator that generates long abdominal fPCG sequences by combining cycle-level fetal S1/S2 event synthesis with a convolutional transmission module and configurable interference and background noise. Model parameters are calibrated cyclewise from real abdominal recordings to capture beat-to-beat variability and to define data-driven admissible ranges for controllable synthesis. The generated signals are validated against real recordings in terms of envelope-based temporal structure and frequency-domain characteristics. The simulator is released as open software to support rapid, reproducible evaluation of fPCG processing methods under controlled acquisition conditions.

</details>


### [14] [Hierarchical Distribution Matcher Design for Probabilistic Constellation Shaping Based on a Novel Semi-Analytical Optimization Approach](https://arxiv.org/abs/2601.16847)
*Pantea Nadimi Goki,Luca Potì*

Main category: eess.SP

TL;DR: 提出一种实用的分层分布匹配器设计方法，用于概率整形星座系统，通过分析优化实现能量损失、速率损失和内存需求的平衡，在16QAM系统中验证了2.8%的整形增益提升。


<details>
  <summary>Details</summary>
Motivation: 现有的分层分布匹配器设计缺乏系统化的优化方法，难以在实际硬件约束下实现最佳性能。需要一种能够平衡能量损失、速率损失和内存需求的设计方法，以适应ASIC和FPGA等实际硬件平台的限制。

Method: 提出半解析优化框架，联合优化速率和能量损失，确定分层层数、内存大小和块长度。通过分析估计能量损失、速率损失和内存需求的下界，特别针对近似Maxwell Boltzmann分布的分层架构。采用概率幅度整形16QAM系统验证方法准确性。

Result: 在AWGN信道中评估优化后的HiDM结构，使用NGMI作为OSNR的函数。在200Gbps净数据速率和25%前向纠错开销下，相比先前方案实现了2.8%的整形增益提升。分析预测与仿真结果吻合良好。

Conclusion: 该设计方法为分层分布匹配器提供了实用的分析工具，能够在硬件约束下优化信道容量，在概率整形系统中实现了显著的性能提升，具有实际应用价值。

Abstract: A novel design procedure for practical hierarchical distribution matchers (HiDMs) in probabilistically shaped constellation systems is presented. The proposed approach enables the determination of optimal parameters for any target distribution matcher rate. Specifically, lower bounds on energy loss, rate loss, and memory requirements are analytically estimated for HiDM architectures approximating the Maxwell Boltzmann (MB) distribution. A semi analytical optimization framework is employed to jointly optimize rate and energy loss, allowing the selection of the number of hierarchical layers, memory size, and block length required to optimize channel capacity. The accuracy of the proposed model is validated through probabilistic amplitude shaping of 16QAM (PAS 16QAM), showing good agreement between analytical predictions and simulated results. The proposed analytical tool facilitates the design of HiDM structures that are compatible with practical hardware and implementation constraints, such as those imposed by state-of-the-art application-specific integrated circuits (ASICs) and field-programmable gate arrays (FPGAs). Furthermore, the performance of the optimized HiDM structure, incorporating layer selection based on lower-bound energy loss, is evaluated over the AWGN channel in terms of normalized generalized mutual information (NGMI) as a function of the optical signal-to-noise ratio (OSNR). At a net data rate of 200 Gbps with 25% forward error correction (FEC) overhead, the proposed scheme achieves a shaping gain improvement of 2.8% compared to previously reported solutions.

</details>


### [15] [IRS Compensation of Hyper-Rayleigh Fading: How Many Elements Are Needed?](https://arxiv.org/abs/2601.16915)
*Aleksey S. Gvozdarev*

Main category: eess.SP

TL;DR: 该论文研究了在超瑞利衰落条件下，智能反射表面(IRS)所需的最小反射单元数量问题，确定了在不同衰落严重程度下补偿信道衰落所需的最小IRS单元数。


<details>
  <summary>Details</summary>
Motivation: 研究动机是确定在严重衰落的多径信道中，需要多少IRS单元才能补偿信道衰落。衰落严重程度用量化的超瑞利机制(HRRs)来衡量，包括完全HRR（最坏情况）、强HRR、弱HRR和无HRR。

Method: 使用逆幂Lomax(IPL)分布作为信道模型，因为它能涵盖所有HRR情况。推导了单IRS单元信道的闭式信道系数包络统计量，包括子信道和总IRS辅助信道的统计量，并为总信道的信道系数和瞬时信噪比(SNR)提供了紧密近似。

Result: 研究结果表明：当源-IRS和IRS-目的地两个单链路都处于完全HRR时，将总IRS辅助链路带出完全HRR所需的最小IRS单元数不少于6个；将总链路带入无HRR所需的最小IRS单元数为14个。

Conclusion: 该研究为IRS系统设计提供了重要指导，确定了在不同衰落严重程度下补偿信道衰落所需的最小IRS单元数量，这对于实际IRS部署具有重要参考价值。

Abstract: The letter introduces and studies the problem of defining the minimum number of Intelligent Reflecting Surface (IRS) elements needed to compensate for heavy fading conditions in multipath fading channels. The fading severity is quantified in terms of Hyper-Rayleigh Regimes (HRRs) (i.e., full-HRR (worst-case conditions), strong-, weak-, and no-HRR), and the channel model used (Inverse Power Lomax (IPL)) was chosen since it can account for all HRRs. The research presents the derived closed-form channel coefficient envelope statistics for the single IRS-element channel with IPL statistics in both subchannels and total IRS-assisted channel, as well as tight approximations for the channel coefficient and instantaneous signal-to-noise ratio (SNR) statistics for the latter. The derived expressions helped estimate channel parameters corresponding to the specific HRRs of the total channel and demonstrate that while both single links (i.e., ''source-IRS'' and ''IRS-destination'') are in full-HRR, the minimum number of IRS elements needed to bring the total IRS-assisted link (''source-IRS-destination'') out of full-HRR is no less than $6$ (for the whole range on the IPL scale parameter corresponding full-HRR). Furthermore, the minimum number of IRS elements required to bring the total IRS-assisted link into no-HRR is $14$ (under the same conditions).

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [16] [ES4R: Speech Encoding Based on Prepositive Affective Modeling for Empathetic Response Generation](https://arxiv.org/abs/2601.16225)
*Zhuoyue Gao,Xiaohui Wang,Xiaocui Yang,Wen Zhang,Daling Wang,Shi Feng,Yifei Zhang*

Main category: eess.AS

TL;DR: ES4R是一个用于语音共情对话生成的框架，通过显式建模结构化情感上下文，结合双级注意力机制和语音引导的跨模态注意力，在语音对话中实现更好的共情响应。


<details>
  <summary>Details</summary>
Motivation: 现有语音对话大模型依赖ASR转录或编码器提取潜在表示，往往削弱了情感信息和多轮对话的上下文连贯性，无法有效感知韵律、语调等副语言信息。

Method: 提出ES4R框架，核心创新是在语音编码前显式建模结构化情感上下文。采用双级注意力机制捕捉轮次级情感状态和对话级情感动态，通过语音引导的跨模态注意力将情感表示与文本语义结合，使用基于能量的策略选择和风格融合实现共情语音合成。

Result: ES4R在自动评估和人工评估中均优于强基线模型，且在不同LLM骨干网络上保持鲁棒性。

Conclusion: 通过显式建模结构化情感上下文，ES4R能够更好地理解和生成共情语音响应，解决了现有语音对话模型在情感信息保留和上下文连贯性方面的不足。

Abstract: Empathetic speech dialogue requires not only understanding linguistic content but also perceiving rich paralinguistic information such as prosody, tone, and emotional intensity for affective understandings. Existing speech-to-speech large language models either rely on ASR transcription or use encoders to extract latent representations, often weakening affective information and contextual coherence in multi-turn dialogues. To address this, we propose \textbf{ES4R}, a framework for speech-based empathetic response generation. Our core innovation lies in explicitly modeling structured affective context before speech encoding, rather than relying on implicit learning by the encoder or explicit emotion supervision. Specifically, we introduce a dual-level attention mechanism to capture turn-level affective states and dialogue-level affective dynamics. The resulting affective representations are then integrated with textual semantics through speech-guided cross-modal attention to generate empathetic responses. For speech output, we employ energy-based strategy selection and style fusion to achieve empathetic speech synthesis. ES4R consistently outperforms strong baselines in both automatic and human evaluations and remains robust across different LLM backbones.

</details>


### [17] [Zero-Shot Speech LLMs for Multi-Aspect Evaluation of L2 Speech: Challenges and Opportunities](https://arxiv.org/abs/2601.16230)
*Aditya Kamlesh Parikh,Cristian Tejedor-Garcia,Catia Cucchiarini,Helmer Strik*

Main category: eess.AS

TL;DR: 评估Qwen2-Audio-7B-Instruct在L2英语发音自动评分中的零样本表现，发现该语音大模型在高质量语音评分上与人工评分高度一致，但在低质量语音评分上存在高估倾向，且错误检测精度不足。


<details>
  <summary>Details</summary>
Motivation: L2英语发音的准确评估对语言学习至关重要，能提供个性化反馈并确保公平评价。然而，由于句子层面的流利度、韵律和完整性等复杂性，自动评分仍然具有挑战性。

Method: 使用指令调优的语音大模型Qwen2-Audio-7B-Instruct，在5,000个Speechocean762语音样本上进行零样本评估。模型生成与评分标准对齐的准确性、流利度、韵律和完整性分数。

Result: 模型评分与人工评分在±2容差范围内表现出强一致性，特别是在高质量语音上。但模型倾向于高估低质量语音的分数，并且在错误检测方面缺乏精度。

Conclusion: 语音大模型在可扩展的发音评估中显示出强大潜力，未来可通过改进提示工程、校准技术和音素集成来推进计算机辅助发音训练的发展。

Abstract: An accurate assessment of L2 English pronunciation is crucial for language learning, as it provides personalized feedback and ensures a fair evaluation of individual progress. However, automated scoring remains challenging due to the complexity of sentence-level fluency, prosody, and completeness. This paper evaluates the zero-shot performance of Qwen2-Audio-7B-Instruct, an instruction-tuned speech-LLM, on 5,000 Speechocean762 utterances. The model generates rubric-aligned scores for accuracy, fluency, prosody, and completeness, showing strong agreement with human ratings within +-2 tolerance, especially for high-quality speech. However, it tends to overpredict low-quality speech scores and lacks precision in error detection. These findings demonstrate the strong potential of speech LLMs in scalable pronunciation assessment and suggest future improvements through enhanced prompting, calibration, and phonetic integration to advance Computer-Assisted Pronunciation Training.

</details>


### [18] [Test-Time Adaptation for Speech Emotion Recognition](https://arxiv.org/abs/2601.16240)
*Jiaheng Dong,Hong Jia,Ting Dang*

Main category: eess.AS

TL;DR: 首次系统评估11种测试时适应方法在语音情感识别中的效果，发现无反向传播方法最有前景，而基于熵最小化和伪标签的方法因情感表达固有模糊性而失效。


<details>
  <summary>Details</summary>
Motivation: 语音情感识别系统在实际应用中面临领域偏移问题（如说话人差异、表演与自然情感差异、跨语料库变化），而传统的领域适应和微调方法需要源数据或标注目标数据，这在SER中往往不可得或存在隐私问题。测试时适应仅需未标注目标数据，但其在SER独特领域偏移中的效果尚未被研究。

Method: 对11种测试时适应方法在三个代表性SER任务上进行首次系统评估和比较，重点关注不同方法处理SER领域偏移的能力。

Result: 无反向传播的TTA方法最有前景；熵最小化和伪标签方法普遍失败，因为这些方法假设单一、确定的真实标签，与情感表达的固有模糊性不兼容；没有单一方法在所有情况下都表现优异，其效果高度依赖于分布偏移和具体任务。

Conclusion: 测试时适应在SER领域偏移缓解中具有潜力，但需要开发专门考虑情感表达模糊性的方法，未来研究应针对SER的独特挑战设计更有效的TTA策略。

Abstract: The practical utility of Speech Emotion Recognition (SER) systems is undermined by their fragility to domain shifts, such as speaker variability, the distinction between acted and naturalistic emotions, and cross-corpus variations. While domain adaptation and fine-tuning are widely studied, they require either source data or labelled target data, which are often unavailable or raise privacy concerns in SER. Test-time adaptation (TTA) bridges this gap by adapting models at inference using only unlabeled target data. Yet, having been predominantly designed for image classification and speech recognition, the efficacy of TTA for mitigating the unique domain shifts in SER has not been investigated. In this paper, we present the first systematic evaluation and comparison covering 11 TTA methods across three representative SER tasks. The results indicate that backpropagation-free TTA methods are the most promising. Conversely, entropy minimization and pseudo-labeling generally fail, as their core assumption of a single, confident ground-truth label is incompatible with the inherent ambiguity of emotional expression. Further, no single method universally excels, and its effectiveness is highly dependent on the distributional shifts and tasks.

</details>


### [19] [EdgeSpot: Efficient and High-Performance Few-Shot Model for Keyword Spotting](https://arxiv.org/abs/2601.16316)
*Oguzhan Buyuksolak,Alican Gok,Osman Erman Okman*

Main category: eess.AS

TL;DR: EdgeSpot：用于边缘设备的高效少样本关键词检测模型，通过优化BC-ResNet声学骨干、可训练PCEN前端和轻量级时序自注意力，结合知识蒸馏和Sub-center ArcFace损失，在固定误报率下实现更高准确率。


<details>
  <summary>Details</summary>
Motivation: 开发适用于边缘设备的高效少样本关键词检测模型，在有限计算资源和参数约束下提升检测准确率，解决传统模型在边缘设备上性能不足的问题。

Method: 1. 优化BC-ResNet声学骨干网络；2. 可训练的每通道能量归一化（PCEN）前端；3. 轻量级时序自注意力机制；4. 使用自监督教师模型进行知识蒸馏；5. 采用Sub-center ArcFace损失优化训练。

Result: EdgeSpot在固定误报率下持续优于强BC-ResNet基线。最大变体EdgeSpot-4在1%误报率下将10-shot准确率从73.7%提升至82.0%，仅需29.4M MACs和128k参数。

Conclusion: EdgeSpot模型为边缘设备提供了一种高效准确的少样本关键词检测解决方案，在有限计算资源下显著提升了检测性能，具有实际部署价值。

Abstract: We introduce an efficient few-shot keyword spotting model for edge devices, EdgeSpot, that pairs an optimized version of a BC-ResNet-based acoustic backbone with a trainable Per-Channel Energy Normalization frontend and lightweight temporal self-attention. Knowledge distillation is utilized during training by employing a self-supervised teacher model, optimized with Sub-center ArcFace loss. This study demonstrates that the EdgeSpot model consistently provides better accuracy at a fixed false-alarm rate (FAR) than strong BC-ResNet baselines. The largest variant, EdgeSpot-4, improves the 10-shot accuracy at 1% FAR from 73.7% to 82.0%, which requires only 29.4M MACs with 128k parameters.

</details>


### [20] [TidyVoice: A Curated Multilingual Dataset for Speaker Verification Derived from Common Voice](https://arxiv.org/abs/2601.16358)
*Aref Farhadipour,Jan Marquenie,Srikanth Madikeri,Eleanor Chodroff*

Main category: eess.AS

TL;DR: 研究者创建了TidyVoice多语言说话人识别数据集，基于Mozilla Common Voice语料库，包含超过21.2万单语说话人和约4500名多语说话人，用于提升说话人识别系统的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、公开可用的多语言说话人识别数据集，特别是针对朗读语音风格的数据，这限制了鲁棒的多语言说话人识别系统的发展。

Method: 从Mozilla Common Voice语料库中提取数据，通过缓解其固有的说话人异质性，构建TidyVoice数据集。使用两种ResNet架构模型，在Tidy-M分区上进行微调。

Result: 在Tidy-M分区上微调后，模型达到0.35%的等错误率（EER）。微调还增强了模型的泛化能力，在未见过的CANDOR语料库的对话访谈数据上表现更好。

Conclusion: TidyVoice数据集为说话人识别社区提供了新的资源，有助于开发更鲁棒的多语言说话人识别系统，特别是在朗读语音风格的应用中。

Abstract: The development of robust, multilingual speaker recognition systems is hindered by a lack of large-scale, publicly available and multilingual datasets, particularly for the read-speech style crucial for applications like anti-spoofing. To address this gap, we introduce the TidyVoice dataset derived from the Mozilla Common Voice corpus after mitigating its inherent speaker heterogeneity within the provided client IDs. TidyVoice currently contains training and test data from over 212,000 monolingual speakers (Tidy-M) and around 4,500 multilingual speakers (Tidy-X) from which we derive two distinct conditions. The Tidy-M condition contains target and non-target trials from monolingual speakers across 81 languages. The Tidy-X condition contains target and non-target trials from multilingual speakers in both same- and cross-language trials. We employ two architectures of ResNet models, achieving a 0.35% EER by fine-tuning on our comprehensive Tidy-M partition. Moreover, we show that this fine-tuning enhances the model's generalization, improving performance on unseen conversational interview data from the CANDOR corpus. The complete dataset, evaluation trials, and our models are publicly released to provide a new resource for the community.

</details>


### [21] [FlowSE-GRPO: Training Flow Matching Speech Enhancement via Online Reinforcement Learning](https://arxiv.org/abs/2601.16483)
*Haoxu Wang,Biao Tian,Yiheng Jiang,Zexu Pan,Shengkui Zhao,Bin Ma,Daren Chen,Xiangang Li*

Main category: eess.AS

TL;DR: 首次成功将在线GRPO集成到流匹配语音增强框架中，通过多指标奖励优化策略平衡竞争目标，减少过拟合并提升整体性能


<details>
  <summary>Details</summary>
Motivation: 生成式语音增强相比传统判别式方法具有优势，但后训练对齐在语音增强领域应用有限，特别是在在线强化学习方面。先前工作主要探索离线方法如DPO，而在线方法如GRPO尚未得到充分研究

Method: 将在线GRPO集成到流匹配语音增强框架中，适应语音的连续时间序列特性和流匹配生成模型的动态特性。提出多指标奖励优化策略来平衡竞争目标，防止奖励黑客攻击

Result: 实验验证了在线GRPO在语音增强中的有效性，优化单一奖励能快速提升指标但会导致音频保真度下降，多指标奖励优化策略能显著减少过拟合并改善整体性能

Conclusion: 成功展示了在线GRPO在语音增强中的应用，为生成式音频模型的基于RL的后训练提供了实用指导，多指标优化策略能有效平衡不同目标

Abstract: Generative speech enhancement offers a promising alternative to traditional discriminative methods by modeling the distribution of clean speech conditioned on noisy inputs. Post-training alignment via reinforcement learning (RL) effectively aligns generative models with human preferences and downstream metrics in domains such as natural language processing, but its use in speech enhancement remains limited, especially for online RL. Prior work explores offline methods like Direct Preference Optimization (DPO); online methods such as Group Relative Policy Optimization (GRPO) remain largely uninvestigated. In this paper, we present the first successful integration of online GRPO into a flow-matching speech enhancement framework, enabling efficient post-training alignment to perceptual and task-oriented metrics with few update steps. Unlike prior GRPO work on Large Language Models, we adapt the algorithm to the continuous, time-series nature of speech and to the dynamics of flow-matching generative models. We show that optimizing a single reward yields rapid metric gains but often induces reward hacking that degrades audio fidelity despite higher scores. To mitigate this, we propose a multi-metric reward optimization strategy that balances competing objectives, substantially reducing overfitting and improving overall performance. Our experiments validate online GRPO for speech enhancement and provide practical guidance for RL-based post-training of generative audio models.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [22] [SoundBreak: A Systematic Study of Audio-Only Adversarial Attacks on Trimodal Models](https://arxiv.org/abs/2601.16231)
*Aafiya Hussain,Gaurav Srivastava,Alvi Ishmam,Zaber Hakim,Chris Thomas*

Main category: cs.SD

TL;DR: 音频对抗攻击可在低感知失真下严重破坏音视频语言多模态模型的性能，攻击成功率高达96%，暴露了多模态系统中被忽视的单模态攻击面。


<details>
  <summary>Details</summary>
Motivation: 虽然音视频语言多模态基础模型在推理和生成任务上表现优异，但其对抗攻击鲁棒性尚未得到充分研究。本文旨在探索一个现实且未被充分研究的威胁模型：针对三模态音频-视频-语言模型的非定向、纯音频对抗攻击。

Method: 分析了六种互补的攻击目标，针对多模态处理的不同阶段：音频编码器表示、跨模态注意力、隐藏状态和输出似然。在三个最先进的模型和多个基准测试上评估音频扰动效果，研究感知失真、优化时长和数据规模的影响，并测试攻击在不同模型和编码器间的可迁移性。

Result: 纯音频扰动可导致严重的多模态故障，攻击成功率高达96%。攻击在低感知失真下仍能成功（LPIPS ≤ 0.08，SI-SNR ≥ 0）。延长优化时间比增加数据规模更有效。攻击在不同模型和编码器间的可迁移性有限，而Whisper等语音识别系统主要受扰动幅度影响，在严重失真下攻击成功率>97%。

Conclusion: 研究揭示了多模态系统中一个先前被忽视的单模态攻击面，表明纯音频对抗攻击可有效破坏多模态系统的性能。这促使需要开发强制跨模态一致性的防御机制来增强多模态系统的安全性。

Abstract: Multimodal foundation models that integrate audio, vision, and language achieve strong performance on reasoning and generation tasks, yet their robustness to adversarial manipulation remains poorly understood. We study a realistic and underexplored threat model: untargeted, audio-only adversarial attacks on trimodal audio-video-language models. We analyze six complementary attack objectives that target different stages of multimodal processing, including audio encoder representations, cross-modal attention, hidden states, and output likelihoods. Across three state-of-the-art models and multiple benchmarks, we show that audio-only perturbations can induce severe multimodal failures, achieving up to 96% attack success rate. We further show that attacks can be successful at low perceptual distortions (LPIPS <= 0.08, SI-SNR >= 0) and benefit more from extended optimization than increased data scale. Transferability across models and encoders remains limited, while speech recognition systems such as Whisper primarily respond to perturbation magnitude, achieving >97% attack success under severe distortion. These results expose a previously overlooked single-modality attack surface in multimodal systems and motivate defenses that enforce cross-modal consistency.

</details>


### [23] [Contrastive Knowledge Distillation for Embedding Refinement in Personalized Speech Enhancement](https://arxiv.org/abs/2601.16235)
*Thomas Serre,Mathieu Fontaine,Éric Benhaim,Slim Essid*

Main category: cs.SD

TL;DR: 提出一种在推理时动态优化说话人嵌入的方法，使用轻量级说话人编码器提升个性化语音增强性能


<details>
  <summary>Details</summary>
Motivation: 现有个性化语音增强系统使用预先提取的说话人嵌入，这些嵌入无法适应推理时目标声音的变化，且上游模型通常很重

Method: 提出在线优化说话人嵌入的方法，使用对比知识蒸馏训练150k参数的轻量编码器，在推理时动态更新嵌入

Result: 该方法显著提升个性化语音增强性能，同时保持低计算负载

Conclusion: 通过轻量级编码器在线优化说话人嵌入是有效的，能适应目标声音变化并提升增强性能

Abstract: Personalized speech enhancement (PSE) has shown convincing results when it comes to extracting a known target voice among interfering ones. The corresponding systems usually incorporate a representation of the target voice within the enhancement system, which is extracted from an enrollment clip of the target voice with upstream models. Those models are generally heavy as the speaker embedding's quality directly affects PSE performances. Yet, embeddings generated beforehand cannot account for the variations of the target voice during inference time. In this paper, we propose to perform on-thefly refinement of the speaker embedding using a tiny speaker encoder. We first introduce a novel contrastive knowledge distillation methodology in order to train a 150k-parameter encoder from complex embeddings. We then use this encoder within the enhancement system during inference and show that the proposed method greatly improves PSE performances while maintaining a low computational load.

</details>


### [24] [The CMU-AIST submission for the ICME 2025 Audio Encoder Challenge](https://arxiv.org/abs/2601.16273)
*Shikhar Bharadwaj,Samuele Cornell,Kwanghee Choi,Hye-jin Shim,Soham Deshmukh,Satoru Fukayama,Shinji Watanabe*

Main category: cs.SD

TL;DR: 基于BEATs音频编码器构建的ICME 2025音频编码挑战赛提交系统，通过74,000小时多领域数据预训练和架构扩展至3亿参数，采用集成方法超越基线模型


<details>
  <summary>Details</summary>
Motivation: 参加ICME 2025音频编码挑战赛，探索不同领域数据（语音、音乐、声音）对音频编码器性能的影响，并开发超越现有基线模型的集成系统

Method: 扩展BEATs模型架构至3亿参数，使用74,000小时多领域数据进行预训练，实验不同数据混合比例，采用Dasheng 12亿模型与两个定制BEATs模型的集成策略

Result: 提出的集成系统超越了基线模型和Dasheng 12亿模型，训练好的检查点已通过HuggingFace公开发布

Conclusion: 通过大规模多领域数据预训练和智能集成策略，成功开发了性能优越的音频编码系统，为音频编码研究提供了有价值的开源资源

Abstract: This technical report describes our submission to the ICME 2025 audio encoder challenge. Our submitted system is built on BEATs, a masked speech token prediction based audio encoder. We extend the BEATs model using 74,000 hours of data derived from various speech, music, and sound corpora and scale its architecture upto 300 million parameters. We experiment with speech-heavy and balanced pre-training mixtures to study the impact of different domains on final performance. Our submitted system consists of an ensemble of the Dasheng 1.2 billion model with two custom scaled-up BEATs models trained on the aforementioned pre-training data mixtures. We also propose a simple ensembling technique that retains the best capabilities of constituent models and surpasses both the baseline and Dasheng 1.2B. For open science, we publicly release our trained checkpoints via huggingface at https://huggingface.co/shikhar7ssu/OpenBEATs-ICME-SOUND and https://huggingface.co/shikhar7ssu/OpenBEATs-ICME.

</details>


### [25] [Do Models Hear Like Us? Probing the Representational Alignment of Audio LLMs and Naturalistic EEG](https://arxiv.org/abs/2601.16540)
*Haoyun Yang,Xin Xiao,Jiang Zhong,Yu Tian,Dong Xiaohua,Yu Mao,Hao Wu,Kaiwen Wei*

Main category: cs.SD

TL;DR: 本文系统研究了12个开源音频大语言模型与人类脑电图信号在自然听觉过程中的表征对齐，发现模型排名随相似度度量变化、存在时空对齐模式（250-500ms窗口与N400神经动态一致）、以及情感解离现象（负性韵律降低几何相似度但增强协方差依赖）。


<details>
  <summary>Details</summary>
Motivation: 音频大语言模型在语音感知和语言理解方面表现出强大能力，但其内部表征是否与人类在自然听觉过程中的神经动态对齐尚未得到充分探索。本研究旨在填补这一空白，通过系统分析音频LLMs与脑电图信号的表征对齐，为理解这些模型的神经生物学基础提供新见解。

Method: 使用12个开源音频大语言模型和2个脑电图数据集，采用8种相似度度量方法（包括基于Spearman的表征相似性分析）来表征句子内的表征几何结构。提出了三模态邻域一致性准则来识别负性韵律。

Result: 发现三个关键结果：1）模型排名随相似度度量方法变化显著；2）存在深度依赖的对齐峰值，在250-500ms时间窗口内RSA显著增加，与N400神经动态一致；3）负性韵律（通过TNC准则识别）降低几何相似度但增强协方差依赖。

Conclusion: 这些发现为音频大语言模型的表征机制提供了新的神经生物学见解，揭示了模型内部表征与人类神经动态之间的复杂对齐模式，特别是在时间窗口和情感处理方面的特异性。

Abstract: Audio Large Language Models (Audio LLMs) have demonstrated strong capabilities in integrating speech perception with language understanding. However, whether their internal representations align with human neural dynamics during naturalistic listening remains largely unexplored. In this work, we systematically examine layer-wise representational alignment between 12 open-source Audio LLMs and Electroencephalogram (EEG) signals across 2 datasets. Specifically, we employ 8 similarity metrics, such as Spearman-based Representational Similarity Analysis (RSA), to characterize within-sentence representational geometry. Our analysis reveals 3 key findings: (1) we observe a rank-dependence split, in which model rankings vary substantially across different similarity metrics; (2) we identify spatio-temporal alignment patterns characterized by depth-dependent alignment peaks and a pronounced increase in RSA within the 250-500 ms time window, consistent with N400-related neural dynamics; (3) we find an affective dissociation whereby negative prosody, identified using a proposed Tri-modal Neighborhood Consistency (TNC) criterion, reduces geometric similarity while enhancing covariance-based dependence. These findings provide new neurobiological insights into the representational mechanisms of Audio LLMs.

</details>


### [26] [CORD: Bridging the Audio-Text Reasoning Gap via Weighted On-policy Cross-modal Distillation](https://arxiv.org/abs/2601.16547)
*Jing Hu,Danxiang Zhu,Xianlong Luo,Dan Zhang,Shuwei He,Yishu Lei,Haitao Zheng,Shikun Feng,Jingzhou He,Yu Sun,Hua Wu,Haifeng Wang*

Main category: cs.SD

TL;DR: CORD是一个统一的跨模态对齐框架，通过在线自蒸馏方法，利用文本模态作为内部教师，在音频推理过程中进行多粒度对齐，显著缩小音频与文本性能差距。


<details>
  <summary>Details</summary>
Motivation: 大型音频语言模型（LALMs）虽然基于文本大语言模型构建，但在知识和推理能力上经常出现退化。作者认为这是因为当前训练范式未能有效弥合特征表示空间中的声学-语义鸿沟。

Method: 提出CORD框架，执行在线跨模态自蒸馏：1）在token级别使用带重要性加权的策略反向KL散度，优先处理早期和语义关键token；2）在序列级别引入基于评判的全局奖励，通过组相对策略优化（GRPO）优化完整推理轨迹。

Result: 在多个基准测试中，CORD持续增强了音频条件推理能力，仅用8万个合成训练样本就显著缩小了音频与文本性能差距，验证了该方法的有效性和数据效率。

Conclusion: CORD通过策略性、多层次的跨模态对齐方法，有效解决了LALMs中的知识退化问题，为音频语言模型的发展提供了高效的对齐框架。

Abstract: Large Audio Language Models (LALMs) have garnered significant research interest. Despite being built upon text-based large language models (LLMs), LALMs frequently exhibit a degradation in knowledge and reasoning capabilities. We hypothesize that this limitation stems from the failure of current training paradigms to effectively bridge the acoustic-semantic gap within the feature representation space. To address this challenge, we propose CORD, a unified alignment framework that performs online cross-modal self-distillation. Specifically, it aligns audio-conditioned reasoning with its text-conditioned counterpart within a unified model. Leveraging the text modality as an internal teacher, CORD performs multi-granularity alignment throughout the audio rollout process. At the token level, it employs on-policy reverse KL divergence with importance-aware weighting to prioritize early and semantically critical tokens. At the sequence level, CORD introduces a judge-based global reward to optimize complete reasoning trajectories via Group Relative Policy Optimization (GRPO). Empirical results across multiple benchmarks demonstrate that CORD consistently enhances audio-conditioned reasoning and substantially bridges the audio-text performance gap with only 80k synthetic training samples, validating the efficacy and data efficiency of our on-policy, multi-level cross-modal alignment approach.

</details>


### [27] [Omni-directional attention mechanism based on Mamba for speech separation](https://arxiv.org/abs/2601.16603)
*Ke Xue,Chang Sun,Rongfei Fan,Jing Wang,Han Hu*

Main category: cs.SD

TL;DR: 提出基于Mamba的高效全向注意力机制，用于语音分离，在保持线性复杂度的同时显著提升性能


<details>
  <summary>Details</summary>
Motivation: 现有基于Mamba的语音分离方法通常将输入分解为短一维序列处理，限制了其在二维频谱图上捕捉全局依赖关系的能力

Method: 基于单向Mamba构建高效全向注意力机制，从频谱图的十个不同方向建模全局依赖关系，并将该机制集成到两个基线分离模型中

Result: 在三个公共数据集上的实验表明，该方法在保持线性复杂度的同时，相比基线模型获得显著性能提升，并超越了现有最先进系统

Conclusion: 提出的全向注意力机制有效扩展了Mamba在语音分离中的应用，实现了对二维频谱图的全局建模，同时保持了计算效率

Abstract: Mamba, a selective state-space model (SSM), has emerged as an efficient alternative to Transformers for speech modeling, enabling long-sequence processing with linear complexity. While effective in speech separation, existing approaches, whether in the time or time-frequency domain, typically decompose the input along a single dimension into short one-dimensional sequences before processing them with Mamba, which restricts it to local 1D modeling and limits its ability to capture global dependencies across the 2D spectrogram. In this work, we propose an efficient omni-directional attention (OA) mechanism built upon unidirectional Mamba, which models global dependencies from ten different directions on the spectrogram. We expand the proposed mechanism into two baseline separation models and evaluate on three public datasets. Experimental results show that our approach consistently achieves significant performance gains over the baselines while preserving linear complexity, outperforming existing state-of-the-art (SOTA) systems.

</details>


### [28] [I Guess That's Why They Call it the Blues: Causal Analysis for Audio Classifiers](https://arxiv.org/abs/2601.16675)
*David A. Kelly,Hana Chockler*

Main category: cs.SD

TL;DR: 论文提出FreqReX工具，使用因果推理发现音频分类器依赖的频率特征，通过微小修改（1/240000频率）即可改变分类结果（58%成功率），揭示音频分类器易受微小频率扰动影响。


<details>
  <summary>Details</summary>
Motivation: 音频分类器通常依赖非音乐相关特征和虚假相关性进行分类，容易被操纵或混淆导致错误分类。虽然诱导误分类不难，但分类器依赖的特征集一直未被充分理解。

Method: 提出新方法使用因果推理发现频率空间中对于给定分类既充分又必要的特征子集，在FreqReX工具中实现该算法，并在多个标准基准数据集上进行实验。

Result: 因果充分必要子集允许通过微小改变输入来操纵模型输出：改变240,000个频率中的1个即可在58%情况下改变分类，且改变小到几乎听不见。证明因果分析有助于理解音频分类器的推理过程。

Conclusion: 因果分析对于理解音频分类器的推理过程很有用，并能成功操纵其输出，揭示了音频分类器对微小频率变化的脆弱性。

Abstract: It is well-known that audio classifiers often rely on non-musically relevant features and spurious correlations to classify audio. Hence audio classifiers are easy to manipulate or confuse, resulting in wrong classifications. While inducing a misclassification is not hard, until now the set of features that the classifiers rely on was not well understood.
  In this paper we introduce a new method that uses causal reasoning to discover features of the frequency space that are sufficient and necessary for a given classification. We describe an implementation of this algorithm in the tool FreqReX and provide experimental results on a number of standard benchmark datasets. Our experiments show that causally sufficient and necessary subsets allow us to manipulate the outputs of the models in a variety of ways by changing the input very slightly. Namely, a change to one out of 240,000 frequencies results in a change in classification 58% of the time, and the change can be so small that it is practically inaudible. These results show that causal analysis is useful for understanding the reasoning process of audio classifiers and can be used to successfully manipulate their outputs.

</details>


### [29] [E2E-AEC: Implementing an end-to-end neural network learning approach for acoustic echo cancellation](https://arxiv.org/abs/2601.16774)
*Yiheng Jiang,Biao Tian,Haoxu Wang,Shengkui Zhao,Bin Ma,Daren Chen,Xiangang Li*

Main category: cs.SD

TL;DR: 提出一种新颖的基于神经网络的端到端声学回声消除方法，支持流式推理，无需依赖传统线性AEC技术和时延估计


<details>
  <summary>Details</summary>
Motivation: 传统线性AEC方法存在局限性，需要时延估计且性能有限。本文旨在开发一种端到端的神经网络方法，能够实现流式推理，同时摆脱对传统线性AEC技术的依赖

Method: 采用四种关键技术：1）渐进式学习逐步增强回声抑制；2）通过预训练的线性AEC模型进行知识迁移；3）优化注意力机制，在注意力权重上应用损失函数以实现精确时间对齐；4）结合语音活动检测，在近端语音缺失时掩码网络输出

Result: 在公开数据集上的实验验证了该方法的有效性，能够有效消除回声并提升语音质量

Conclusion: 提出的端到端声学回声消除方法成功实现了流式推理，无需传统线性AEC技术和时延估计，通过渐进学习、知识迁移、注意力优化和语音活动检测等策略取得了良好效果

Abstract: We propose a novel neural network-based end-to-end acoustic echo cancellation (E2E-AEC) method capable of streaming inference, which operates effectively without reliance on traditional linear AEC (LAEC) techniques and time delay estimation. Our approach includes several key strategies: First, we introduce and refine progressive learning to gradually enhance echo suppression. Second, our model employs knowledge transfer by initializing with a pre-trained LAECbased model, harnessing the insights gained from LAEC training. Third, we optimize the attention mechanism with a loss function applied on attention weights to achieve precise time alignment between the reference and microphone signals. Lastly, we incorporate voice activity detection to enhance speech quality and improve echo removal by masking the network output when near-end speech is absent. The effectiveness of our approach is validated through experiments conducted on public datasets.

</details>


### [30] [A Novel Transfer Learning Approach for Mental Stability Classification from Voice Signal](https://arxiv.org/abs/2601.16793)
*Rafiul Islam,Md. Taimur Ahad*

Main category: cs.SD

TL;DR: 提出结合数据增强和迁移学习的新方法，使用语音信号和CNN进行心理稳定性分类，DenseNet121达到94%准确率和99%AUC


<details>
  <summary>Details</summary>
Motivation: 解决心理稳定性分类中语音信号数据有限的问题，开发非侵入性的心理健康诊断工具

Method: 使用VGG16、InceptionV3和DenseNet121三种CNN架构分析语音频谱图，采用数据增强和迁移学习策略：先在增强数据上预训练，再在原始数据上微调

Result: DenseNet121在迁移学习方法下获得最高性能：94%准确率和99%AUC，显著优于基线方法

Conclusion: 数据增强与迁移学习结合能有效提升基于CNN的心理稳定性分类性能，为心理健康诊断提供了有前景的非侵入性工具

Abstract: This study presents a novel transfer learning approach and data augmentation technique for mental stability classification using human voice signals and addresses the challenges associated with limited data availability. Convolutional neural networks (CNNs) have been employed to analyse spectrogram images generated from voice recordings. Three CNN architectures, VGG16, InceptionV3, and DenseNet121, were evaluated across three experimental phases: training on non-augmented data, augmented data, and transfer learning. This proposed transfer learning approach involves pre-training models on the augmented dataset and fine-tuning them on the non-augmented dataset while ensuring strict data separation to prevent data leakage. The results demonstrate significant improvements in classification performance compared to the baseline approach. Among three CNN architectures, DenseNet121 achieved the highest accuracy of 94% and an AUC score of 99% using the proposed transfer learning approach. This finding highlights the effectiveness of combining data augmentation and transfer learning to enhance CNN-based classification of mental stability using voice spectrograms, offering a promising non-invasive tool for mental health diagnostics.

</details>

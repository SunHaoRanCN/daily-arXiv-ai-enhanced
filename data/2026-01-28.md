<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 18]
- [eess.AS](#eess.AS) [Total: 7]
- [cs.SD](#cs.SD) [Total: 15]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [A Survey of Pinching-Antenna Systems (PASS)](https://arxiv.org/abs/2601.18927)
*Yuanwei Liu,Hao Jiang,Xu Gan,Xiaoxia Xu,Jia Guo,Zhaolin Wang,Chongjun Ouyang,Xidong Mu,Zhiguo Ding,Arumugam Nallanathan,Octavia A. Dobre,George K. Karagiannidis,Robert Schober*

Main category: eess.SP

TL;DR: 本文全面综述了夹持天线系统(PASS)技术，包括其基本原理、新兴设计、无线传感应用、性能分析、优化方法，以及未来挑战。


<details>
  <summary>Details</summary>
Motivation: PASS作为一种柔性天线技术，被认为是解决下一代无线网络中多个挑战的有前景方案，能够提供大规模天线重构、建立稳定视距链路、缓解信号阻塞，并通过其独特架构利用近场优势。

Method: 首先讨论PASS的基本原理，包括硬件架构、电路和物理模型、信号模型；随后介绍几种新兴PASS设计（如分段PASS、中心馈电PASS、多模式PASS）；综述PASS在无线传感中的特性和应用；调查PASS在通信和传感方面的性能分析进展；总结优化和机器学习方面的现有研究贡献。

Result: PASS能够实现大规模天线重构、建立稳定视距链路、缓解信号阻塞，并利用近场优势，在通信和传感方面都展现出性能增益。文章还识别了波束成形和资源分配等实际挑战。

Conclusion: 本文全面概述了PASS技术的最新进展，提出了几种PASS变体，并讨论了未来研究的关键实施挑战，为下一代无线网络中的PASS技术发展提供了重要参考。

Abstract: The pinching-antenna system (PASS), recently proposed as a flexible-antenna technology, has been regarded as a promising solution for several challenges in next-generation wireless networks. It provides large-scale antenna reconfiguration, establishes stable line-of-sight links, mitigates signal blockage, and exploits near-field advantages through its distinctive architecture. This article aims to present a comprehensive overview of the state of the art in PASS. The fundamental principles of PASS are first discussed, including its hardware architecture, circuit and physical models, and signal models. Several emerging PASS designs, such as segmented PASS (S-PASS), center-fed PASS (C-PASS), and multi-mode PASS (M-PASS), are subsequently introduced, and their design features are discussed. In addition, the properties and promising applications of PASS for wireless sensing are reviewed. On this basis, recent progress in the performance analysis of PASS for both communications and sensing is surveyed, and the performance gains achieved by PASS are highlighted. Existing research contributions in optimization and machine learning are also summarized, with the practical challenges of beamforming and resource allocation being identified in relation to the unique transmission structure and propagation characteristics of PASS. Finally, several variants of PASS are presented, and key implementation challenges that remain open for future study are discussed.

</details>


### [2] [SynthRM: A Synthetic Data Platform for Vision-Aided Mobile System Simulation](https://arxiv.org/abs/2601.19173)
*Yingzhe Mao,Chao Zou,Yanqun Tang*

Main category: eess.SP

TL;DR: SynthRM是一个用于6G移动计算的合成数据平台，通过可见对齐表面模拟策略实现视觉语义与电磁响应的像素级一致性，解决跨视图信号推理的几何模糊问题。


<details>
  <summary>Details</summary>
Motivation: 当前视觉辅助无线感知方法在建立视觉数据与无线电传播之间的几何对应关系方面存在挑战，现有方法要么将2D拓扑图与无线电地图关联，要么提供受稀疏无线电数据限制的3D视角视图，这些空间表示简化了复杂的垂直交互（如遮挡和衍射），导致跨视图信号推理在数学上不适定。

Method: SynthRM采用可见对齐表面模拟策略：不探测全局体积网格，而是直接在传感器暴露的几何体上进行光线追踪。这种方法确保视觉语义与电磁响应之间的像素级一致性，将学习目标转化为物理上适定的问题。平台结合高效程序化合成与高保真电磁建模。

Result: 展示了从程序生成环境中获得的城市规模多样化数据集，证明了平台的能力。SynthRM为开发下一代环境感知传感和通信的移动系统提供了透明、可访问的基础。

Conclusion: SynthRM通过解决视觉数据与无线电传播之间的几何对应问题，为6G移动计算中的视觉辅助无线感知提供了可扩展的合成数据平台，将跨视图信号推理转化为物理上适定的学习问题。

Abstract: Vision-aided wireless sensing is emerging as a cornerstone of 6G mobile computing. While data-driven approaches have advanced rapidly, establishing a precise geometric correspondence between ego-centric visual data and radio propagation remains a challenge. Existing paradigms typically either associate 2D topology maps and auxiliary information with radio maps, or provide 3D perspective views limited by sparse radio data. This spatial representation flattens the complex vertical interactions such as occlusion and diffraction that govern signal behavior in urban environments, rendering the task of cross-view signal inference mathematically ill-posed. To resolve this geometric ambiguity, we introduce SynthRM, a scalable synthetic data platform. SynthRM implements a Visible-Aligned-Surface simulation strategy: rather than probing a global volumetric grid, it performs ray-tracing directly onto the geometry exposed to the sensor. This approach ensures pixel-level consistency between visual semantics and electromagnetic response, transforming the learning objective into a physically well-posed problem. We demonstrate the platform's capabilities by presenting a diverse, city-scale dataset derived from procedurally generated environments. By combining efficient procedural synthesis with high-fidelity electromagnetic modeling, SynthRM provides a transparent, accessible foundation for developing next-generation mobile systems for environment-aware sensing and communication.

</details>


### [3] [Exponentially Consistent Low-Complexity Outlier Hypothesis Testing for Continuous Sequences](https://arxiv.org/abs/2601.19248)
*Lina Zhu,Lin Zhou*

Main category: eess.SP

TL;DR: 提出基于MMD度量的指数一致、低复杂度固定长度异常假设检验方法，相比穷举搜索在检测性能和计算复杂度间取得更好权衡，适用于连续值序列和未知异常数量情况。


<details>
  <summary>Details</summary>
Motivation: 现有异常假设检验方法主要针对离散值序列，且多为穷举搜索方法，在检测性能和计算复杂度之间存在权衡问题。需要扩展到连续值序列并开发更高效的检验方法。

Method: 扩展Bu等人(2019)的结果到连续值序列，基于MMD（最大均值差异）度量开发分布无关的固定长度检验方法。处理已知和未知异常数量两种情况，在未知数量情况下分析检测性能边界。

Result: 提出的方法在连续值序列上实现指数一致性，相比现有穷举搜索方法在检测性能和计算复杂度间取得更好权衡。量化了未知异常数量情况下的性能损失，并刻画了三种错误概率指数衰减率之间的权衡关系。

Conclusion: 基于MMD的固定长度检验方法为连续值序列的异常假设检验提供了高效解决方案，特别是在未知异常数量情况下仍能保证性能边界，具有实际应用价值。

Abstract: In this work, we revisit outlier hypothesis testing and propose exponentially consistent, low-complexity fixed-length tests that achieve a better tradeoff between detection performance and computational complexity than existing exhaustive-search methods. In this setting, the goal is to identify outlying sequences from a set of observed sequences, where most sequences are i.i.d. from a nominal distribution and outliers are i.i.d. from a different anomalous distribution. While prior work has primarily focused on discrete-valued sequences, we extend the results of Bu et al. (TSP 2019) to continuous-valued sequences and develop a distribution-free test based on the MMD metric. Our framework handles both known and unknown numbers of outliers. In the unknown-count case, we bound the detection performance and characterize the tradeoff among the exponential decay rates of three types of error probabilities. Finally, we quantify the performance penalty incurred when the number of outliers is unknown.

</details>


### [4] [Stacked Intelligent Metasurfaces-Based Electromagnetic Wave Domain Interference-Free Precoding](https://arxiv.org/abs/2601.19313)
*Hetong Wang,Yashuai Cao,Tiejun Lv,Jintao Wang,Ni Wei,Jiancheng An,Chau Yuen*

Main category: eess.SP

TL;DR: 本文提出了一种基于堆叠智能超表面(SIM)的无干扰多流传输架构，通过波域预编码直接补偿功率放大器非线性失真，并采用递归斜流形算法优化SIM相移，结合天线选择和功率分配策略，在12dB信噪比下相比无策略方案获得20dB性能增益。


<details>
  <summary>Details</summary>
Motivation: 传统干扰利用预编码(IEP)依赖计算硬件电路，而SIM提供了在模拟波域执行预编码操作的新途径。然而，功率放大器引起的非线性失真限制了SIM-enabled IEP的性能，需要开发硬件高效的无干扰发射机架构。

Method: 1) 开发硬件高效的SIM-enabled IEP架构，在波域直接补偿非线性失真；2) 设计帧级SIM配置方案，建立安全裕度函数的maxmin优化问题；3) 提出递归斜流形(ROM)算法优化多层SIM相移；4) 探索灵活自由度驱动的天线选择方案；5) 采用ROM交替优化框架联合优化天线选择、SIM相移设计和功率分配。

Result: 仿真表明，提出的SIM-enabled帧级IEP方案显著优于基准方法。具体而言，在12dB信噪比下，采用天线选择和功率分配策略的方案相比无策略方案可获得20dB性能增益，验证了NLD-aware IEP方案的优越性和所提算法的有效性。

Conclusion: 本文成功开发了基于SIM的无干扰多流传输架构，通过波域预编码直接补偿非线性失真，提出的ROM算法和联合优化框架有效解决了SIM相移的复杂耦合问题，显著提升了系统性能，为下一代无线通信系统提供了有前景的解决方案。

Abstract: This paper introduces an interference-free multi-stream transmission architecture leveraging stacked intelligent metasurfaces (SIMs), from a new perspective of interference exploitation. Unlike traditional interference exploitation precoding (IEP) which relies on computational hardware circuitry, we perform the precoding operations within the analog wave domain provided by SIMs. However, the benefits of SIM-enabled IEP are limited by the nonlinear distortion (NLD) caused by power amplifiers. A hardware-efficient interference-free transmitter architecture is developed to exploit SIM's high and flexible degree of freedom (DoF), where the NLD on modulated symbols can be directly compensated in the wave domain. Moreover, we design a frame-level SIM configuration scheme and formulate a maxmin problem on the safety margin function. With respect to the optimization of SIM phase shifts, we propose a recursive oblique manifold (ROM) algorithm to tackle the complex coupling among phase shifts across multiple layers. A flexible DoF-driven antenna selection (AS) scheme is explored in the SIM-enabled IEP system. Using an ROM-based alternating optimization (ROM-AO) framework, our approach jointly optimizes transmit AS, SIM phase shift design, and power allocation (PA), and develops a greedy safety margin-based AS algorithm. Simulations show that the proposed SIM-enabled frame-level IEP scheme significantly outperforms benchmarks. Specifically, the strategy with AS and PA can achieve a 20 dB performance gain compared to the case without any strategy under the 12 dB signal-to-noise ratio, which confirms the superiority of the NLD-aware IEP scheme and the effectiveness of the proposed algorithm.

</details>


### [5] [Cooperative Double IRS aided Secure Communication for MIMO-OFDM Systems](https://arxiv.org/abs/2601.19366)
*Weijie Xiong,Jingran Lin,Di Jiang,Yuhan Zhang,Kai Zhong,Qiang Li*

Main category: eess.SP

TL;DR: 提出基于流形优化的双IRS协作宽带MIMO-OFDM物理层安全方案，解决传统窄带设计在宽带场景下的耦合问题，显著提升安全速率。


<details>
  <summary>Details</summary>
Motivation: 现有双IRS协作研究局限于窄带场景，无法处理宽带MIMO-OFDM系统。在宽带场景中，频率平坦的IRS相位和级联IRS链路导致严重耦合，使得窄带设计方案失效。

Method: 将功率和恒定模约束视为黎曼流形，将非凸的安全和速率最大化问题重构为乘积流形上的无约束优化。基于此提出乘积黎曼梯度下降(PRGD)算法，保证驻点收敛。

Result: 仿真结果表明，所提方案有效解决了OFDM耦合问题，实现了显著的安全速率增益，相比单IRS和分布式多IRS基准方案分别提升32.0%和22.3%。

Conclusion: 提出的基于流形优化的双IRS协作宽带MIMO-OFDM方案成功解决了宽带场景下的耦合问题，为物理层安全提供了有效的解决方案。

Abstract: Cooperative double intelligent reflecting surface (double-IRS) has emerged as a promising approach for enhancing physical layer security (PLS) in MIMO systems. However, existing studies are limited to narrowband scenarios and fail to address wideband MIMO-OFDM. In this regime, frequency-flat IRS phases and cascaded IRS links cause severe coupling, rendering narrowband designs inapplicable. To overcome this challenge, we introduce cooperative double-IRS-assisted wideband MIMO-OFDM and propose an efficient manifold-based solution. By regarding the power and constant modulus constraints as Riemannian manifolds, we reformulate the non-convex secrecy sum rate maximization as an unconstrained optimization on a product manifold. Building on this formulation, we further develop a product Riemannian gradient descent (PRGD) algorithm with guaranteed stationary convergence. Simulation results demonstrate that the proposed scheme effectively resolves the OFDM coupling issue and achieves significant secrecy rate gains, outperforming single-IRS and distributed multi-IRS benchmarks by 32.0% and 22.3%, respectively.

</details>


### [6] [AoI-Driven Queue Management and Power Control in V2V Networks: A GNN-Enhanced MARL Approach](https://arxiv.org/abs/2601.19372)
*Hao Fang,Xiao Li,Chongtao Guo,Le Liang,Shi Jin*

Main category: eess.SP

TL;DR: 本文提出了一种基于图神经网络和多智能体近端策略优化的V2V网络中AoI感知状态更新方法，通过联合优化主动丢包和发射功率控制，在多种网络条件下显著降低了平均AoI。


<details>
  <summary>Details</summary>
Motivation: 在车联网中，队列管理和资源分配对于实现协同状态感知至关重要。车辆状态通常由多个相互依赖的数据包表示，需要在资源约束下进行细粒度的包级队列管理，同时考虑V2V拓扑中的图结构干扰。

Method: 1. 设计混合动作空间，支持离散丢包决策和连续功率控制；2. 引入图神经网络聚合慢变的大尺度衰落，使智能体能隐式捕获拓扑依赖而无需频繁消息交换；3. 基于多智能体近端策略优化框架，采用集中训练分散执行模式。

Result: 仿真结果表明，所提方法在广泛的网络密度、信道条件和流量负载范围内，平均AoI显著降低，持续优于多个基线方法。

Conclusion: 该方法通过联合优化主动丢包和功率控制，结合GNN处理拓扑依赖，有效解决了V2V网络中AoI感知状态更新的问题，为车联网中的协同状态感知提供了有效的解决方案。

Abstract: Queue management and resource allocation play a critical role in enabling cooperative status awareness in vehicular networks. This paper investigates the problem of age of information (AoI)-aware status updates in vehicle-to-vehicle (V2V) communication, where each vehicle's status is represented by multiple interdependent packets. To enable fine-grained queue management at the packet level under resource constraints, we formulate a joint optimization problem that simultaneously learns active packet dropping and transmit power control strategies. A hybrid action space is designed to support both discrete dropping decisions and continuous power control. To exploit the graph-structured interference inherent in V2V topology, a graph neural network (GNN) is introduced to aggregate slowly varying large-scale fading, allowing agents to capture topological dependencies implicitly without frequent message exchange. The overall framework is built upon multi-agent proximal policy optimization (MAPPO), with centralized training and decentralized execution (CTDE). Simulations demonstrate that the proposed method significantly reduces average AoI across a wide range of network densities, channel conditions, and traffic loads, consistently outperforming several baselines.

</details>


### [7] [ML-Enhanced Digital Backpropagation for Long-Reach Single-Span Systems](https://arxiv.org/abs/2601.19457)
*Dario Cellini,Stella Civelli,Marco Secondini*

Main category: eess.SP

TL;DR: 提出一种数字反向传播方法，通过机器学习联合优化色散步长和非线性相位旋转滤波器，在FFT增强型分裂步傅里叶结构中实现低计算复杂度下的高精度


<details>
  <summary>Details</summary>
Motivation: 传统数字反向传播方法在光纤通信系统中面临计算复杂度与精度之间的权衡问题，需要一种能在低计算成本下提高信号恢复精度的方法

Method: 采用基于FFT的增强型分裂步傅里叶结构，利用机器学习联合优化色散步长和非线性相位旋转滤波器参数

Result: 在保持低计算复杂度的同时，实现了比传统方法更高的信号恢复精度

Conclusion: 该方法为光纤通信系统中的数字信号处理提供了一种高效且精确的解决方案，平衡了计算复杂度和性能需求

Abstract: We propose a digital backpropagation method that employs machine-learning-aided joint optimization of dispersion step lengths and nonlinear phase rotation filters within an FFT-based enhanced split-step Fourier structure, achieving improved accuracy at low computational complexity.

</details>


### [8] [Master-Assisted Distributed Uplink Operation for Cell-Free Massive MIMO Networks](https://arxiv.org/abs/2601.19518)
*Andreas Angelou,Pourya Behmandpoor,Marc Moonen*

Main category: eess.SP

TL;DR: 提出了一种新的无蜂窝大规模MIMO上行链路操作模式MADUO，通过为每个用户分配主AP来平衡前传信令和计算复杂度，性能接近集中式操作。


<details>
  <summary>Details</summary>
Motivation: 无蜂窝大规模MIMO是下一代无线通信网络的关键技术，但现有上行链路操作模式（集中式和分布式）在前传信令和计算复杂度方面存在权衡。集中式操作性能好但前传负载大，分布式操作前传负载小但性能可能受限。需要一种能平衡这两方面的新操作模式。

Method: 提出主辅助分布式上行链路操作(MADUO)：为每个用户设备分配一个主AP，该主AP接收来自其他AP的软数据估计，并结合本地信号进行数据解码。这种方法将信道估计和部分处理分散到AP，同时保持集中式解码的优势。

Result: 数值实验表明，MADUO在性能上与集中式操作相当，同时能够平衡前传信令开销和计算复杂度。该方案提供了集中式和分布式操作之间的良好折衷。

Conclusion: MADUO是一种有前景的无蜂窝大规模MIMO上行链路操作模式，能够在保持接近集中式操作性能的同时，有效管理前传信令和计算资源，为实际部署提供了可行的解决方案。

Abstract: Cell-free massive multiple-input-multiple-output is considered a promising technology for the next generation of wireless communication networks. The main idea is to distribute a large number of access points (APs) in a geographical region to serve the user equipments (UEs) cooperatively. In the uplink, one of two types of operations is often adopted: centralized or distributed. In centralized operation, channel estimation and data decoding are performed at the central processing unit (CPU), whereas in distributed operation, channel estimation occurs at the APs and data detection at the CPU. In this paper, we propose a novel uplink operation, termed Master-Assisted Distributed Uplink Operation (MADUO), where each UE is assigned a master AP, which receives soft data estimates from the other APs and decodes the data using its local signals and the received data estimates. Numerical experiments demonstrate that the proposed operation performs comparably to the centralized operation and balances fronthaul signaling and computational complexity.

</details>


### [9] [Design of RIS-aided mMTC+ Networks for Rate Maximization under the Finite Blocklength Regime with Imperfect Channel Knowledge](https://arxiv.org/abs/2601.19523)
*Sergi Liesegang,Antonio Pascual-Iserte,Olga Muñoz,Alessio Zappone*

Main category: eess.SP

TL;DR: 该论文提出了一种针对大规模机器类型通信中RIS的鲁棒优化方法，在有限块长度和信道估计误差下最大化加权和速率。


<details>
  <summary>Details</summary>
Motivation: 在mMTC场景中，当信道条件较差时，RIS技术可以提升系统性能。然而，由于RIS反射元件数量众多且为被动元件，可能存在信道估计误差，这会影响系统性能，因此需要设计鲁棒的RIS优化方案。

Method: 基于凹界和近似方法，将非凸的加权和速率最大化问题转化为可通过逐次凸优化（SCO）求解的形式，提出了一种鲁棒的RIS响应优化方案。

Result: 数值实验验证了SCO解决方案的性能和复杂度，表明该方法能够有效对抗信道估计误差带来的不利影响。

Conclusion: 在有限块长度和存在信道估计误差的mMTC场景中，提出的鲁棒RIS优化方法能够有效提升系统加权和速率，SCO算法在性能和复杂度之间取得了良好平衡。

Abstract: Within the context of massive machine-type communications+, reconfigurable intelligent surfaces (RISs) represent a promising technology to boost system performance in scenarios with poor channel conditions. Considering single-antenna sensors transmitting short data packets to a multiple-antenna collector node, we introduce and design an RIS to maximize the weighted sum rate (WSR) of the system working in the finite blocklength regime. Due to the large number of reflecting elements and their passive nature, channel estimation errors may occur. In this letter, we then propose a robust RIS optimization to combat such a detrimental issue. Based on concave bounds and approximations, the nonconvex WSR problem for the RIS response is addressed via successive convex optimization (SCO). Numerical experiments validate the performance and complexity of the SCO solutions.

</details>


### [10] [Cramer-Rao Bound for Arbitrarily Constrained Sets](https://arxiv.org/abs/2601.19539)
*Heedong Do,Angel Lozano*

Main category: eess.SP

TL;DR: 提出适用于任意约束集的Cramer-Rao下界，不依赖等式/不等式约束、流形结构或Fisher信息矩阵非奇异性，基于约束集的切锥几何结构


<details>
  <summary>Details</summary>
Motivation: 现有CRB结果通常需要特定约束形式（如等式/不等式约束）、流形结构或Fisher信息矩阵非奇异性，限制了在一般约束参数估计问题中的应用。需要建立适用于任意约束集的统一CRB框架。

Method: 基于约束集的切锥几何结构推导CRB，切锥的跨度决定了约束如何影响估计精度。该方法不依赖特定约束形式，适用于任意约束集、任意估计偏差和任意Fisher信息矩阵。

Result: 推导出适用于任意约束集的通用CRB，该结果包含、统一并推广了已知的特殊情况，为约束估计器的最小均方误差提供了直观且广泛适用的理论框架。

Conclusion: 提出的基于切锥几何的CRB为约束参数估计提供了统一的理论框架，突破了现有方法的局限性，具有广泛的应用价值。

Abstract: This paper presents a Cramer-Rao bound (CRB) for the estimation of parameters confined to an arbitrary set. Unlike existing results that rely on equality or inequality constraints, manifold structures, or the nonsingularity of the Fisher information matrix, the derived CRB applies to any constrained set and holds for any estimation bias and any Fisher information matrix. The key geometric object governing the new CRB is the tangent cone to the constraint set, whose span determines how the constraints affect the estimation accuracy. This CRB subsumes, unifies, and generalizes known special cases, offering an intuitive and broadly applicable framework to characterize the minimum mean-square error of constrained estimators.

</details>


### [11] [Exposure-Aware Beamforming for mmWave Systems: From EM Theory to Thermal Compliance](https://arxiv.org/abs/2601.19587)
*Zihan Zhou,Ang Chen,Yunfei Chen,Weidong Wang,Li Chen*

Main category: eess.SP

TL;DR: 提出基于长期热电磁暴露约束的自适应波束成形设计，通过生物热传导方程建模组织热惯性，将瞬时暴露限制转化为灵活长期热预算约束，显著优于传统瞬时约束方案。


<details>
  <summary>Details</summary>
Motivation: 电磁暴露合规性是通信终端设计的关键方面，但准确评估电磁暴露影响并制定适当设计策略仍然具有挑战性。现有方法通常采用刚性瞬时暴露限制，未能充分考虑组织的热惯性特性。

Method: 1) 基于麦克斯韦辐射方程建立等效信道模型；2) 从Pennes生物热传导方程推导闭式热脉冲响应模型；3) 将刚性瞬时暴露限制转化为灵活长期热预算约束；4) 基于Lyapunov优化理论开发低复杂度在线波束成形算法。

Result: 仿真结果表明，所提算法能有效稳定组织温度在预定义安全阈值附近，在性能上显著优于采用传统瞬时暴露约束的方案。

Conclusion: 该研究提出了一种创新的长期热电磁暴露约束模型和自适应暴露感知波束成形设计，通过考虑组织热惯性，实现了更灵活有效的电磁暴露管理，为毫米波通信系统的安全设计提供了新思路。

Abstract: Electromagnetic (EM) exposure compliance has long been recognized as a crucial aspect of communications terminal designs. However, accurately assessing the impact of EM exposure for proper design strategies remains challenging. In this paper, we develop a long-term thermal EM exposure constraint model and propose a novel adaptive exposure-aware beamforming design for an mmWave uplink system. Specifically, we first establish an equivalent channel model based on Maxwell's radiation equations, which accurately captures the EM physical effects. Then, we derive a closed-form thermal impulse response model from the Pennes bioheat transfer equation (BHTE), characterizing the thermal inertia of tissue. Inspired by this model, we formulate a beamforming optimization problem that translates rigid instantaneous exposure limits into a flexible long-term thermal budget constraint. Furthermore, we develop a low-complexity online beamforming algorithm based on Lyapunov optimization theory, obtaining a closed-form near-optimal solution. Simulation results demonstrate that the proposed algorithm effectively stabilizes tissue temperature near a predefined safety threshold and significantly outperforms the conventional scheme with instantaneous exposure constraints.

</details>


### [12] [Robust Design of Reconfigurable Intelligent Surfaces for Parameter Estimation in MTC](https://arxiv.org/abs/2601.19590)
*Sergi Liesegang,Antonio Pascual-Iserte,Olga Muñoz*

Main category: eess.SP

TL;DR: 论文提出在机器类型通信中利用可重构智能表面支持参数估计，采用MMSE估计和SIC接收，考虑有限块长和信道状态信息获取，通过统计设计RIS配置和SIC解码顺序来最小化估计误差。


<details>
  <summary>Details</summary>
Motivation: 在机器类型通信中，单天线传感器通过非正交多址向多天线收集节点传输空间相关测量时，面临噪声、干扰和有限块长通信的挑战，需要提高参数估计精度。

Method: 提出基于最小均方误差准则的估计方案，集成连续干扰消除接收，探索多种信道状态信息获取方法，统计设计RIS配置和SIC解码顺序，考虑有限块长通信和信道时变特性。

Result: 仿真表明，更大的反射表面能带来更小的均方误差，选择合适的解码顺序对精度和最终性能至关重要，系统能有效应对有限块长和信道状态信息不完美的影响。

Conclusion: 可重构智能表面能有效支持机器类型通信中的参数估计，通过统计设计RIS配置和SIC解码顺序，在有限块长和不完美信道状态信息条件下仍能实现良好的估计性能。

Abstract: This paper introduces a reconfigurable intelligent surface (RIS) to support parameter estimation in machine-type communications (MTC). We focus on a network where single-antenna sensors transmit spatially correlated measurements to a multiple-antenna collector node (CN) via non-orthogonal multiple access. We propose an estimation scheme based on the minimum mean square error (MMSE) criterion. We also integrate successive interference cancelation (SIC) at the receiver to mitigate communication failures in noisy and interference-prone channels under the finite blocklength (FBL) regime. Moreover, recognizing the importance of channel state information (CSI), we explore various methodologies for its acquisition at the CN. We statistically design the RIS configuration and SIC decoding order to minimize estimation error while accounting for channel temporal variations and short packet lengths. To mirror practical systems, we incorporate the detrimental effects of FBL communication and imperfect CSI errors in our analysis. Simulations demonstrate that larger reflecting surfaces lead to smaller MSEs and underscore the importance of selecting an appropriate decoding order for accuracy and ultimate performance.

</details>


### [13] [Initial Characterization of Healthy and Malignant in vivo and ex vivo Human Colon Tissues under Surgery Procedures](https://arxiv.org/abs/2601.19602)
*Sergio Micó-Rosa,Concepcion Garcia-Pardo,Matteo Frasson,Narcis Cardona,Vicente Pons-Beltrán,Pedro López-Muñoz*

Main category: eess.SP

TL;DR: 该研究通过0.5-26.5GHz频段测量健康与恶性结肠组织的介电特性，发现晚期肿瘤组织的介电特性值更高


<details>
  <summary>Details</summary>
Motivation: 人体组织的介电特性表征对开发新型医疗诊断工具至关重要，特别是健康与病理组织的表征能为诊断提供关键信息

Method: 在真实手术中进行小规模测量，频率范围0.5-26.5GHz，外部测量结肠组织（不直接接触肿瘤），考虑不同肿瘤分期

Result: 初步结果显示，与健康组织相比，晚期恶性肿瘤组织的介电特性值更高

Conclusion: 组织介电特性测量有望成为医疗诊断工具，晚期肿瘤表现出更高的介电特性值，为无创诊断提供了可能性

Abstract: The dielectric characterization of human tissues can play a crucial role in the development of new medical diagnostic tools. In particular, the characterization of healthy and pathological tissues can provide vital information for diagnosis. In this paper, preliminary results from a small-scale measurement campaign conducted in 0.5-26.5GHz during real surgeries on healthy and malignant human colon tissues are presented. Those measurements were carried out externally to the colon, without direct contact to the tumor growing inside the colon. Furthermore, different tumor stages are taken into account. Initial findings reveal that advanced tumor stages are related with increased higher values of dielectric properties in malignant tumor tissues compared to the healthy ones.

</details>


### [14] [Robust Covariance-Based DoA Estimation under Weather-Induced Distortion](https://arxiv.org/abs/2601.19623)
*Chenyang Yan,Geert Leus,Mats Bengtsson*

Main category: eess.SP

TL;DR: 提出一种针对恶劣天气条件下传感器阵列的鲁棒波达方向估计方法，通过利用协方差矩阵的Hermitian Toeplitz结构减少参数估计，采用广义最小二乘法进行校准，有效抑制雨引起的失真。


<details>
  <summary>Details</summary>
Motivation: 传感器阵列在恶劣天气条件下工作时，天气引起的失真会降低波达方向估计精度，特别是在降雨条件下，多重散射会导致随机相位和幅度失真，需要开发鲁棒的方法来应对这些挑战。

Method: 基于先前建立的物理S矩阵模型，采用统计方法表征雨引起的随机失真，为均匀线性阵列开发包含这些失真的测量框架，利用协方差矩阵的Hermitian Toeplitz结构减少参数估计数量，然后应用广义最小二乘法进行校准。

Result: 仿真结果表明，所提方法能有效抑制雨引起的失真，提高波达方向估计精度，并增强恶劣天气条件下的雷达传感性能。

Conclusion: 该方法为恶劣天气条件下的传感器阵列提供了有效的波达方向估计解决方案，通过利用协方差矩阵的结构特性和统计校准方法，显著提升了在降雨等挑战性天气条件下的性能表现。

Abstract: We investigate robust direction-of-arrival (DoA) estimation for sensor arrays operating in adverse weather conditions, where weather-induced distortions degrade estimation accuracy. Building on a physics-based $S$-matrix model established in prior work, we adopt a statistical characterization of random phase and amplitude distortions caused by multiple scattering in rain. Based on this model, we develop a measurement framework for uniform linear arrays (ULAs) that explicitly incorporates such distortions. To mitigate their impact, we exploit the Hermitian Toeplitz (HT) structure of the covariance matrix to reduce the number of parameters to be estimated. We then apply a generalized least squares (GLS) approach for calibration. Simulation results show that the proposed method effectively suppresses rain-induced distortions, improves DoA estimation accuracy, and enhances radar sensing performance in challenging weather conditions.

</details>


### [15] [Cell-Free MIMO in Space: Cooperative Satellite Transmission with Multi-Antenna Ground Users](https://arxiv.org/abs/2601.19656)
*Parisa Ramezani,Emil Björnson*

Main category: eess.SP

TL;DR: 提出分布式低轨卫星网络的多用户下行通信框架，采用无小区MIMO概念，多卫星协同传输空间复用数据流，通过统计信道信息优化预编码矩阵以最大化总速率。


<details>
  <summary>Details</summary>
Motivation: 传统卫星通信系统存在覆盖范围有限、容量不足等问题，需要为配备多天线的地面用户提供更高效的多用户下行通信方案。借鉴地面网络的无小区MIMO概念，将其扩展到分布式低轨卫星网络，以提升系统性能。

Method: 1) 提出协调传输方案，多卫星联合向每个用户传输空间复用数据流；2) 推导新的近似可达速率表达式；3) 在每卫星和每天线功率约束下，构建总速率最大化问题；4) 利用总速率最大化与均方误差最小化的经典等价关系，基于统计信道状态信息优化卫星预编码矩阵。

Result: 通过数值模拟在不同设置下检验所提方案性能，与传统预编码设计相比验证了其有效性。结果表明该方案能够显著提升分布式低轨卫星网络的多用户下行通信性能。

Conclusion: 成功将无小区MIMO概念扩展到分布式低轨卫星网络，提出的协调传输方案和基于统计信道信息的预编码优化方法能够有效提升系统总速率，为未来卫星通信系统设计提供了新思路。

Abstract: This paper develops a multi-user downlink communication framework for distributed low Earth orbit satellite networks serving ground users equipped with multiple antennas. Building upon the concept of cell-free multiple-input multiple-output in terrestrial networks, we propose a coordinated transmission scheme where multiple satellites jointly transmit spatially multiplexed data streams to each user. Using a new approximate achievable rate expression, we formulate a sum rate maximization problem under per-satellite and per-antenna power constraints and use the classical equivalence between sum rate maximization and mean square error minimization to optimize the satellites' precoding matrices using statistical channel state information. We numerically examine the performance of the proposed scheme in different settings and validate its effectiveness by comparing it against traditional precoding designs.

</details>


### [16] [Maximum A Posteriori Probability Channel Tracking with an Intelligent Transmitting Surface](https://arxiv.org/abs/2601.19660)
*Parisa Ramezani,Alva Kosasih,Emil Björnson*

Main category: eess.SP

TL;DR: 提出一种用于智能发射表面系统的低开销MAP信道跟踪方法，仅需每个相干块两个导频即可实现精确信道跟踪


<details>
  <summary>Details</summary>
Motivation: 智能发射表面(ITS)集成到基站中需要有效的信道跟踪方法，特别是在ITS与用户设备之间的主导视距链路上，需要低开销且精确的信道跟踪方案

Method: 将每个块的信道建模为三参数模型（信道幅度、相位和到达角），利用时间相关性通过先前块的估计更新先验分布，采用目标波束对准策略，每个相干块仅需两个导频

Result: 所提方法实现了精确的信道跟踪，获得的频谱效率接近完美信道知识下的性能

Conclusion: 该方法为ITS系统提供了一种高效的低开销信道跟踪解决方案，在保持性能的同时显著降低了导频开销

Abstract: This paper considers an intelligent transmitting surface (ITS) integrated into a base station and develops a low-overhead maximum a posteriori (MAP) probability channel tracking method for the dominant line-of-sight link between the ITS and the user equipment. We cast the per-block channel as a three-parameter model consisting of the channel amplitude, channel phase, and angle-of-arrival at the ITS. We exploit temporal correlation by updating the priors using the estimates from the previous block. Using only two pilots per coherence block alongside a targeted beam alignment strategy, the proposed method achieves precise channel tracking and attains spectral efficiency close to that achievable under perfect channel knowledge.

</details>


### [17] [Channel Estimation using 5G Sounding Reference Signals: A Delay-Doppler Domain Approach](https://arxiv.org/abs/2601.19784)
*Danilo Lelin Li,Ramtin Rabiee,Arman Farhang*

Main category: eess.SP

TL;DR: 本文提出了一种在5G NR系统中利用DD域处理提升高移动性场景下信道估计性能的方法，通过SRS信号在DD域进行信道估计和预测，支持无导频检测超过25个OFDM符号。


<details>
  <summary>Details</summary>
Motivation: 虽然DDMC技术在高多普勒信道中具有优势，但5G NR仍采用OFDM和DFT-s-OFDM作为调制方案，无法完全转向DDMC波形。因此，需要探索如何在现有5G NR框架下利用DD域处理来改善高移动性场景的性能。

Method: 1. 使用DFT-s-OFDM接收器，将接收到的OFDM符号转换到延迟-多普勒(DD)域进行信道估计
2. 估计DD信道参数，预测无导频OFDM符号的信道
3. 提出线性联合信道估计和均衡技术，利用每个OFDM符号中检测到的数据顺序更新信道估计

Result: 1. 所提技术在BER和NMSE方面显著优于传统的频域估计技术
2. 仅使用两个时隙的SRS进行初始信道估计，即可支持超过25个后续OFDM符号的无导频检测

Conclusion: 在现有5G NR框架下，通过DD域处理可以有效提升高移动性场景的信道估计性能，实现长时间的无导频检测，为6G系统提供了实用的过渡方案。

Abstract: Delay-Doppler multicarrier modulation (DDMC) techniques have been among the central topics of research for high-Doppler channels. However, a complete transition to DDMC-based waveforms is not yet practically feasible. This is because 5G NR based waveforms, orthogonal frequency division multiplexing (OFDM) and discrete Fourier transform-spread OFDM (DFT-s-OFDM), remain as the modulation schemes for the sixth-generation radio (6GR). Hence, in this paper, we demonstrate how we can still benefit from DD-domain processing in high-mobility scenarios using 5G NR sounding reference signals (SRSs). By considering a DFT-s-OFDM receiver, we transform each received OFDM symbol into the delay-Doppler (DD) domain, where the channel is then estimated. With this approach, we estimate the DD channel parameters, allowing us to predict the aged channel over OFDM symbols without pilots. To improve channel prediction, we propose a linear joint channel estimation and equalization technique, where we use the detected data in each OFDM symbol to sequentially update our channel estimates. Our simulation results show that the proposed technique significantly outperforms the conventional frequency-domain estimation technique in terms of bit error rate (BER) and normalized mean squared error (NMSE). Furthermore, we show that using only two slots with SRS for initial channel estimation, our method supports pilot-free detection for more than 25 subsequent OFDM symbols.

</details>


### [18] [Generative Latent Alignment for Interpretable Radar Based Occupancy Detection in Ambient Assisted Living](https://arxiv.org/abs/2601.19853)
*Huy Trinh*

Main category: eess.SP

TL;DR: 提出GLA框架，结合轻量级卷积VAE和冻结CLIP文本编码器，学习毫米波雷达距离-角度热图的低维潜在表示，通过语义锚点对齐实现可解释的存在检测。


<details>
  <summary>Details</summary>
Motivation: 在环境辅助生活(AAL)场景中，基于摄像头的传感存在隐私问题，需要更可解释的毫米波雷达存在检测方法。

Method: 提出生成潜在对齐(GLA)框架：1) 使用轻量级卷积变分自编码器学习雷达距离-角度热图的潜在表示；2) 结合冻结的CLIP文本编码器；3) 将潜在空间与"空房间"和"有人存在"两个语义锚点进行软对齐；4) 在对齐的潜在空间中应用Grad-CAM可视化支持存在决策的空间区域。

Result: 在毫米波雷达数据集上，观察到"有人存在"类别产生紧凑的Grad-CAM斑点，与强的距离-角度返回信号重合；"空房间"样本产生扩散或无证据。消融研究表明，使用无关文本提示会降低重建和定位性能，表明雷达特定锚点对有意义解释很重要。

Conclusion: GLA框架能够为毫米波雷达存在检测提供可解释的视觉解释，在保护隐私的环境辅助生活应用中具有潜力，雷达特定的语义锚点对生成有意义的解释至关重要。

Abstract: In this work, we study how to make mmWave radar presence detection more interpretable for Ambient Assisted Living (AAL) settings, where camera-based sensing raises privacy concerns. We propose a Generative Latent Alignment (GLA) framework that combines a lightweight convolutional variational autoencoder with a frozen CLIP text encoder to learn a low-dimensional latent representation of radar Range-Angle (RA) heatmaps. The latent space is softly aligned with two semantic anchors corresponding to "empty room" and "person present", and Grad-CAM is applied in this aligned latent space to visualize which spatial regions support each presence decision. On our mmWave radar dataset, we qualitatively observe that the "person present" class produces compact Grad-CAM blobs that coincide with strong RA returns, whereas "empty room" samples yield diffuse or no evidence. We also conduct an ablation study using unrelated text prompts, which degrades both reconstruction and localization, suggesting that radar-specific anchors are important for meaningful explanations in this setting.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [19] [Beyond Lips: Integrating Gesture and Lip Cues for Robust Audio-visual Speaker Extraction](https://arxiv.org/abs/2601.19130)
*Zexu Pan,Xinyuan Qian,Shengkui Zhao,Kun Zhou,Bin Ma*

Main category: eess.AS

TL;DR: SeLG模型整合唇部和上半身手势信息进行说话人提取，通过跨注意力融合机制和对比学习提升性能


<details>
  <summary>Details</summary>
Motivation: 传统音频-视觉说话人提取方法主要依赖唇部同步记录，但在自然交流中，伴随语音的手势也与语音时间对齐，提供互补的视觉线索，尤其在面部或唇部区域被遮挡或距离较远时特别有价值

Method: 提出SeLG模型，整合唇部和手势信息，采用基于交叉注意力的融合机制，让每个视觉模态能够查询并选择性关注混合语音中的相关特征；同时使用对比InfoNCE损失，促使手势嵌入与更接近语音的唇部嵌入对齐

Result: 在YGD数据集（包含TED演讲）上的实验结果表明，对比学习策略显著改善了基于手势的说话人提取性能；SeLG模型通过注意力机制和InfoNCE损失有效融合唇部和手势线索，在完整和部分（即缺失模态）条件下均优于基线方法

Conclusion: 通过超越唇部中心的方法，整合唇部和手势信息，并采用对比学习策略，能够实现更鲁棒的说话人提取，特别是在视觉信息不完整的情况下

Abstract: Most audio-visual speaker extraction methods rely on synchronized lip recording to isolate the speech of a target speaker from a multi-talker mixture. However, in natural human communication, co-speech gestures are also temporally aligned with speech, often emphasizing specific words or syllables. These gestures provide complementary visual cues that can be especially valuable when facial or lip regions are occluded or distant. In this work, we move beyond lip-centric approaches and propose SeLG, a model that integrates both lip and upper-body gesture information for robust speaker extraction. SeLG features a cross-attention-based fusion mechanism that enables each visual modality to query and selectively attend to relevant speech features in the mixture. To improve the alignment of gesture representations with speech dynamics, SeLG also employs a contrastive InfoNCE loss that encourages gesture embeddings to align more closely with corresponding lip embeddings, which are more strongly correlated with speech. Experimental results on the YGD dataset, containing TED talks, demonstrate that the proposed contrastive learning strategy significantly improves gesture-based speaker extraction, and that our proposed SeLG model, by effectively fusing lip and gesture cues with an attention mechanism and InfoNCE loss, achieves superior performance compared to baselines, across both complete and partial (i.e., missing-modality) conditions.

</details>


### [20] [LuSeeL: Language-queried Binaural Universal Sound Event Extraction and Localization](https://arxiv.org/abs/2601.19153)
*Zexu Pan,Shengkui Zhao,Yukun Ma,Haoxu Wang,Yiheng Jiang,Biao Tian,Bin Ma*

Main category: eess.AS

TL;DR: 提出LuSeeL模型，通过语言描述从双耳音频中提取目标声音事件，并联合预测声音到达方向，利用空间线索提升提取性能


<details>
  <summary>Details</summary>
Motivation: 现实世界是三维的，双耳音频能捕捉更丰富的空间信息（包括声源位置），这些空间上下文对于理解和建模复杂听觉场景至关重要。现有通用声音提取算法主要关注单声道音频，忽略了空间信息的重要性。

Method: 提出语言驱动的通用声音提取网络，从双耳混合音频中分离文本描述的声音事件，有效利用双耳信号中的空间线索。同时，利用提取网络的空间特征联合预测目标声音的到达方向（DoA），通过双任务方法利用互补的位置信息。

Result: 在AudioCaps数据集上的实验结果表明，提出的LuSeeL模型显著优于单声道和单任务基线方法。

Conclusion: 通过结合语言描述和双耳空间信息，并采用双任务学习（声音提取+DoA预测），能够有效提升复杂听觉场景中目标声音的提取性能，同时实现准确的声音方向估计。

Abstract: Most universal sound extraction algorithms focus on isolating a target sound event from single-channel audio mixtures. However, the real world is three-dimensional, and binaural audio, which mimics human hearing, can capture richer spatial information, including sound source location. This spatial context is crucial for understanding and modeling complex auditory scenes, as it inherently informs sound detection and extraction. In this work, we propose a language-driven universal sound extraction network that isolates text-described sound events from binaural mixtures by effectively leveraging the spatial cues present in binaural signals. Additionally, we jointly predict the direction of arrival (DoA) of the target sound using spatial features from the extraction network. This dual-task approach exploits complementary location information to improve extraction performance while enabling accurate DoA estimation. Experimental results on the in-the-wild AudioCaps dataset show that our proposed LuSeeL model significantly outperforms single-channel and uni-task baselines.

</details>


### [21] [SE-DiCoW: Self-Enrolled Diarization-Conditioned Whisper](https://arxiv.org/abs/2601.19194)
*Alexander Polok,Dominik Klement,Samuele Cornell,Matthew Wiesner,Jan Černocký,Sanjeev Khudanpur,Lukáš Burget*

Main category: eess.AS

TL;DR: SE-DiCoW改进了DiCoW，通过引入自注册机制解决说话人重叠时的条件模糊问题，显著提升了多说话人ASR性能


<details>
  <summary>Details</summary>
Motivation: 解决多说话人环境中说话人归属ASR的挑战，特别是原DiCoW方法中STNO掩码在说话人完全重叠时的模糊性问题

Method: 提出SE-DiCoW，利用说话人日志输出定位目标说话人最活跃的注册段，通过跨注意力机制作为固定条件；改进数据分割、模型初始化和数据增强

Result: 在EMMA MT-ASR基准测试中，SE-DiCoW相比原DiCoW将宏平均tcpWER相对降低了52.4%

Conclusion: SE-DiCoW通过自注册机制有效解决了说话人重叠时的条件模糊问题，显著提升了多说话人ASR的跨域泛化能力

Abstract: Speaker-attributed automatic speech recognition (ASR) in multi-speaker environments remains a major challenge. While some approaches achieve strong performance when fine-tuned on specific domains, few systems generalize well across out-of-domain datasets. Our prior work, Diarization-Conditioned Whisper (DiCoW), leverages speaker diarization outputs as conditioning information and, with minimal fine-tuning, demonstrated strong multilingual and multi-domain performance. In this paper, we address a key limitation of DiCoW: ambiguity in Silence-Target-Non-target-Overlap (STNO) masks, where two or more fully overlapping speakers may have nearly identical conditioning despite differing transcriptions. We introduce SE-DiCoW (Self-Enrolled Diarization-Conditioned Whisper), which uses diarization output to locate an enrollment segment anywhere in the conversation where the target speaker is most active. This enrollment segment is used as fixed conditioning via cross-attention at each encoder layer. We further refine DiCoW with improved data segmentation, model initialization, and augmentation. Together, these advances yield substantial gains: SE-DiCoW reduces macro-averaged tcpWER by 52.4% relative to the original DiCoW on the EMMA MT-ASR benchmark.

</details>


### [22] [Permutation-Invariant Physics-Informed Neural Network for Region-to-Region Sound Field Reconstruction](https://arxiv.org/abs/2601.19491)
*Xingyu Chen,Sipei Zhao,Fei Ma,Eva Cheng,Ian S. Burnett*

Main category: eess.AS

TL;DR: 提出一种基于物理约束的神经网络方法，用于区域到区域的声场重建，能够处理连续变化的声源和接收器位置。


<details>
  <summary>Details</summary>
Motivation: 现有声场重建方法大多针对固定声源到接收区域的点对区域重建，而实际声学传递函数会随声源和接收区域位置连续变化，限制了这些方法的适用性。

Method: 采用深度集合架构处理接收器和声源位置作为无序集合，保持声学互易性；同时将亥姆霍兹方程作为物理约束融入网络训练，确保预测的物理一致性。

Result: 该方法能够实现区域到区域的声场重建，在连续变化的声源和测量区域之间插值声学传递函数。

Conclusion: 提出的排列不变物理约束神经网络为声场重建提供了更通用的解决方案，能够处理实际应用中声源和接收器位置连续变化的情况。

Abstract: Most existing sound field reconstruction methods target point-to-region reconstruction, interpolating the Acoustic Transfer Functions (ATFs) between a fixed-position sound source and a receiver region. The applicability of these methods is limited because real-world ATFs tend to varying continuously with respect to the positions of sound sources and receiver regions. This paper presents a permutation-invariant physics-informed neural network for region-to-region sound field reconstruction, which aims to interpolate the ATFs across continuously varying sound sources and measurement regions. The proposed method employs a deep set architecture to process the receiver and sound source positions as an unordered set, preserving acoustic reciprocity. Furthermore, it incorporates the Helmholtz equation as a physical constraint to guide network training, ensuring physically consistent predictions.

</details>


### [23] [Audio Deepfake Detection at the First Greeting: "Hi!"](https://arxiv.org/abs/2601.19573)
*Haohan Shi,Xiyu Shi,Safak Dogan,Tianjin Huang,Yunxiao Zhang*

Main category: eess.AS

TL;DR: 提出S-MGAA模型，针对真实通信场景下的音频深度伪造检测，特别优化超短音频输入（0.5-2.0秒），在通信降质条件下仍能有效检测合成语音。


<details>
  <summary>Details</summary>
Motivation: 解决真实通信场景中音频深度伪造检测的挑战：1）超短音频输入（如诈骗电话开场"Hi"）检测困难；2）通信过程中的信号降质（压缩、噪声等）影响检测性能；3）需要轻量化模型以适应实时部署和边缘设备。

Method: 提出Short-MGAA（S-MGAA）模型，基于多粒度自适应时频注意力框架，包含两个核心模块：1）像素通道增强模块（PCEM）放大细粒度时频显著性；2）频率补偿增强模块（FCEM）通过多尺度频率建模和自适应频时交互补充有限的时间证据。

Result: S-MGAA在九个先进基线方法中表现最优，对通信降质具有强鲁棒性，同时实现良好的效率-精度平衡：低实时因子、竞争性的GFLOPs、紧凑参数和低训练成本。

Conclusion: S-MGAA在超短音频深度伪造检测任务中表现出色，对真实通信降质具有强鲁棒性，轻量化设计使其适合通信系统和边缘设备的实时部署，为解决实际应用中的音频伪造检测问题提供了有效方案。

Abstract: This paper focuses on audio deepfake detection under real-world communication degradations, with an emphasis on ultra-short inputs (0.5-2.0s), targeting the capability to detect synthetic speech at a conversation opening, e.g., when a scammer says "Hi." We propose Short-MGAA (S-MGAA), a novel lightweight extension of Multi-Granularity Adaptive Time-Frequency Attention, designed to enhance discriminative representation learning for short, degraded inputs subjected to communication processing and perturbations. The S-MGAA integrates two tailored modules: a Pixel-Channel Enhanced Module (PCEM) that amplifies fine-grained time-frequency saliency, and a Frequency Compensation Enhanced Module (FCEM) to supplement limited temporal evidence via multi-scale frequency modeling and adaptive frequency-temporal interaction. Extensive experiments demonstrate that S-MGAA consistently surpasses nine state-of-the-art baselines while achieving strong robustness to degradations and favorable efficiency-accuracy trade-offs, including low RTF, competitive GFLOPs, compact parameters, and reduced training cost, highlighting its strong potential for real-time deployment in communication systems and edge devices.

</details>


### [24] [SAM Audio Judge: A Unified Multimodal Framework for Perceptual Evaluation of Audio Separation](https://arxiv.org/abs/2601.19702)
*Helin Wang,Bowen Shi,Andros Tjandra,John Hoffman,Yi-Chiao Wu,Apoorv Vyas,Najim Dehak,Ann Lee,Wei-Ning Hsu*

Main category: eess.AS

TL;DR: SAJ是一个无需参考信号的多模态细粒度音频分离评估指标，在语音、音乐和通用声音三个领域与人类感知高度一致，支持文本、视觉和跨度三种提示输入，评估四个维度。


<details>
  <summary>Details</summary>
Motivation: 现有音频分离评估指标存在三大问题：1）与人类感知不一致；2）依赖参考信号（ground truth）；3）粒度较粗。主观听音测试虽准确但昂贵耗时难以扩展。需要自动化评估系统。

Method: 提出SAM Audio Judge (SAJ)，一个多模态细粒度无参考的客观评估指标。支持三个音频领域（语音、音乐、通用声音事件）和三种提示输入（文本、视觉、跨度），评估四个维度（召回率、精确率、忠实度、整体质量）。

Result: SAJ与人类感知高度一致，在三个音频领域都表现出色。该指标在数据过滤、大规模数据集伪标注和音频分离模型重排序方面具有潜在应用价值。

Conclusion: SAJ是一个有效的自动化音频分离评估系统，解决了现有指标与人类感知不一致、依赖参考信号的问题，为音频分离领域提供了可扩展的评估解决方案。

Abstract: The performance evaluation remains a complex challenge in audio separation, and existing evaluation metrics are often misaligned with human perception, course-grained, relying on ground truth signals. On the other hand, subjective listening tests remain the gold standard for real-world evaluation, but they are expensive, time-consuming, and difficult to scale. This paper addresses the growing need for automated systems capable of evaluating audio separation without human intervention. The proposed evaluation metric, SAM Audio Judge (SAJ), is a multimodal fine-grained reference-free objective metric, which shows highly alignment with human perceptions. SAJ supports three audio domains (speech, music and general sound events) and three prompt inputs (text, visual and span), covering four different dimensions of evaluation (recall, percision, faithfulness, and overall). SAM Audio Judge also shows potential applications in data filtering, pseudo-labeling large datasets and reranking in audio separation models. We release our code and pre-trained models at: https://github.com/facebookresearch/sam-audio.

</details>


### [25] [Rethinking Discrete Speech Representation Tokens for Accent Generation](https://arxiv.org/abs/2601.19786)
*Jinzuomu Zhong,Yi Wang,Korin Richmond,Peter Bell*

Main category: eess.AS

TL;DR: 该论文首次系统研究离散语音表示令牌（DSRTs）中的口音信息编码，提出统一评估框架，发现ASR监督会显著减少口音信息，并提出新的内容专用和内容-口音DSRTs设计，在可控口音生成方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 虽然先前研究广泛探讨了DSRTs中的音素和说话人信息，但口音信息在DSRTs中的编码方式仍未被充分探索。口音是语音生成中的重要特征，需要系统研究其编码机制。

Method: 提出统一评估框架：1) 通过新颖的Accent ABX任务测量口音信息的可访问性；2) 通过跨口音语音转换重合成测量可恢复性。使用该框架分析多种语音编码器衍生的DSRTs，并基于发现提出新的内容专用和内容-口音DSRTs设计。

Result: 研究发现：1) 使用ASR监督微调编码器会显著减少口音信息；2) 通过简单的码本大小缩减无法有效分离口音与音素、说话人信息。提出的新DSRTs设计在可控口音生成方面显著优于现有设计。

Conclusion: 该研究强调了口音感知评估的重要性，为设计用于口音控制语音生成的DSRTs提供了实用指导。提出的新DSRTs设计在可控口音生成方面具有优越性能。

Abstract: Discrete Speech Representation Tokens (DSRTs) have become a foundational component in speech generation. While prior work has extensively studied phonetic and speaker information in DSRTs, how accent information is encoded in DSRTs remains largely unexplored. In this paper, we present the first systematic investigation of accent information in DSRTs. We propose a unified evaluation framework that measures both accessibility of accent information via a novel Accent ABX task and recoverability via cross-accent Voice Conversion (VC) resynthesis. Using this framework, we analyse DSRTs derived from a variety of speech encoders. Our results reveal that accent information is substantially reduced when ASR supervision is used to fine-tune the encoder, but cannot be effectively disentangled from phonetic and speaker information through naive codebook size reduction. Based on these findings, we propose new content-only and content-accent DSRTs that significantly outperform existing designs in controllable accent generation. Our work highlights the importance of accent-aware evaluation and provides practical guidance for designing DSRTs for accent-controlled speech generation.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [26] [SICL-AT: Another way to adapt Auditory LLM to low-resource task](https://arxiv.org/abs/2601.18904)
*Haolong Zheng,Siyin Wang,Zengrui Jin,Mark Hasegawa-Johnson*

Main category: cs.SD

TL;DR: 论文提出SICL-AT方法，通过后训练增强听觉大语言模型的上下文学习能力，在低资源场景下优于直接微调


<details>
  <summary>Details</summary>
Motivation: 听觉大语言模型在语音和音频理解任务中表现良好，但在低资源或陌生任务中表现不佳。当标注数据稀缺或与真实测试分布不匹配时，直接微调效果有限。上下文学习提供了一种无需训练、推理时适应的方法。

Method: 首先验证Vanilla ICL在多模态设置中的有效性，然后提出Speech In-Context Learning Adaptation Training (SICL-AT)后训练方法，仅使用高资源语音数据来增强模型的上下文学习能力

Result: 实验表明，提出的方法在低资源场景下持续优于直接微调，且增强效果能泛化到音频理解/推理任务

Conclusion: SICL-AT方法有效增强了听觉大语言模型的上下文学习能力，为低资源场景下的模型适应提供了更好的解决方案

Abstract: Auditory Large Language Models (LLMs) have demonstrated strong performance across a wide range of speech and audio understanding tasks. Nevertheless, they often struggle when applied to low-resource or unfamiliar tasks. In case of labeled in-domain data is scarce or mismatched to the true test distribution, direct fine-tuning can be brittle. In-Context Learning (ICL) provides a training-free, inference-time solution by adapting auditory LLMs through conditioning on a few in-domain demonstrations. In this work, we first show that \emph{Vanilla ICL}, improves zero-shot performance across diverse speech and audio tasks for selected models which suggest this ICL adaptation capability can be generalized to multimodal setting. Building on this, we propose \textbf{Speech In-Context Learning Adaptation Training (SICL-AT)}, a post-training recipe utilizes only high resource speech data intending to strengthen model's in-context learning capability. The enhancement can generalize to audio understanding/reasoning task. Experiments indicate our proposed method consistently outperforms direct fine-tuning in low-resource scenario.

</details>


### [27] [Enhancing Speech Emotion Recognition using Dynamic Spectral Features and Kalman Smoothing](https://arxiv.org/abs/2601.18908)
*Marouane El Hizabri,Abdelfattah Bezzaz,Ismail Hayoukane,Youssef Taki*

Main category: cs.SD

TL;DR: 提出结合动态频谱特征（Deltas和Delta-Deltas）与卡尔曼平滑算法，提升语音情感识别在噪声环境下的准确性和稳定性


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别系统使用静态特征（如MFCC、ZCR、RMSE），在声学噪声存在时容易误分类情感。需要解决噪声干扰问题，并考虑情感随时间变化的动态特性

Method: 在静态特征基础上添加动态频谱特征（Deltas和Delta-Deltas），结合卡尔曼平滑算法来降噪。卡尔曼滤波器还能使分类器输出更稳定，适应情感的时间变化特性

Result: 在RAVDESS数据集上测试，该方法达到了87%的最先进准确率，并减少了具有相似声学特征的情感之间的误分类

Conclusion: 动态特征与卡尔曼平滑的结合有效提升了语音情感识别在噪声环境下的性能，实现了更高的准确率和更好的情感区分能力

Abstract: Speech Emotion Recognition systems often use static features like Mel-Frequency Cepstral Coefficients (MFCCs), Zero Crossing Rate (ZCR), and Root Mean Square Energy (RMSE). Because of this, they can misclassify emotions when there is acoustic noise in vocal signals. To address this, we added dynamic features using Dynamic Spectral features (Deltas and Delta-Deltas) along with the Kalman Smoothing algorithm. This approach reduces noise and improves emotion classification. Since emotion changes over time, the Kalman Smoothing filter also helped make the classifier outputs more stable. Tests on the RAVDESS dataset showed that this method achieved a state-of-the-art accuracy of 87\% and reduced misclassification between emotions with similar acoustic features

</details>


### [28] [A Framework for Evaluating Faithfulness in Explainable AI for Machine Anomalous Sound Detection Using Frequency-Band Perturbation](https://arxiv.org/abs/2601.19017)
*Alexander Buck,Georgina Cosma,Iain Phillips,Paul Conway,Patrick Baker*

Main category: cs.SD

TL;DR: 提出一个量化评估音频异常检测XAI方法忠实性的框架，通过频率带移除直接验证解释方法是否准确识别影响模型预测的关键频域区域。


<details>
  <summary>Details</summary>
Motivation: 当前音频异常检测的XAI方法主要依赖对显著性图的定性检查，缺乏客观评估这些归因是否准确反映模型实际使用的频谱线索的方法。

Method: 提出一个量化评估框架，通过系统性的频率带移除技术，将归因相关性与模型行为直接关联，客观衡量XAI方法是否能正确识别影响ASD模型预测的频率区域。

Result: 评估了四种主流XAI方法（集成梯度、遮挡法、Grad-CAM、SmoothGrad），发现不同方法可靠性差异显著，其中遮挡法表现出最强的模型敏感性对齐，而基于梯度的方法往往无法准确捕捉频谱依赖性。

Conclusion: 提出的框架为音频解释提供了可复现的基准测试方法，能够实现对基于频谱图的ASD系统更可信的解释，促进XAI在音频异常检测领域的可靠应用。

Abstract: Explainable AI (XAI) is commonly applied to anomalous sound detection (ASD) models to identify which time-frequency regions of an audio signal contribute to an anomaly decision. However, most audio explanations rely on qualitative inspection of saliency maps, leaving open the question of whether these attributions accurately reflect the spectral cues the model uses. In this work, we introduce a new quantitative framework for evaluating XAI faithfulness in machine-sound analysis by directly linking attribution relevance to model behaviour through systematic frequency-band removal. This approach provides an objective measure of whether an XAI method for machine ASD correctly identifies frequency regions that influence an ASD model's predictions. By using four widely adopted methods, namely Integrated Gradients, Occlusion, Grad-CAM and SmoothGrad, we show that XAI techniques differ in reliability, with Occlusion demonstrating the strongest alignment with true model sensitivity and gradient-+based methods often failing to accurately capture spectral dependencies. The proposed framework offers a reproducible way to benchmark audio explanations and enables more trustworthy interpretation of spectrogram-based ASD systems.

</details>


### [29] [Audio Foundation Models Outperform Symbolic Representations for Piano Performance Evaluation](https://arxiv.org/abs/2601.19029)
*Jai Dhiman*

Main category: cs.SD

TL;DR: 使用预训练音频基础模型（MuQ和MERT）评估钢琴演奏质量，相比传统MIDI方法提升55%，音频特征足以捕捉演奏表现力，无需与符号特征融合。


<details>
  <summary>Details</summary>
Motivation: 传统钢琴演奏评估依赖MIDI符号表示，但这种方法无法捕捉演奏中的声学细微差别和表现力。需要探索基于音频的方法来更全面地评估演奏质量。

Method: 使用预训练音频基础模型（MuQ和MERT）预测19个钢琴演奏质量感知维度。通过Pianoteq合成PercePiano MIDI文件的音频，在相同源数据下比较音频和符号方法。采用声音字体增强、交叉验证和外部数据集相关性分析。

Result: 最佳模型（MuQ 9-12层+Pianoteq声音字体增强）达到R²=0.537，比符号基线（R²=0.347）提升55%。统计显著（p<10⁻²⁵），音频在所有19个维度上都优于符号方法。验证了跨声音字体泛化能力和外部数据集相关性。

Conclusion: 音频基础模型能有效评估钢琴演奏质量，显著优于传统MIDI方法。音频-符号特征融合效果有限，因为两者误差高度相关，音频表示本身已足够。研究提供了完整的训练流程和预训练模型。

Abstract: Automated piano performance evaluation traditionally relies on symbolic (MIDI) representations, which capture note-level information but miss the acoustic nuances that characterize expressive playing. I propose using pre-trained audio foundation models, specifically MuQ and MERT, to predict 19 perceptual dimensions of piano performance quality. Using synthesized audio from PercePiano MIDI files (rendered via Pianoteq), I compare audio and symbolic approaches under controlled conditions where both derive from identical source data. The best model, MuQ layers 9-12 with Pianoteq soundfont augmentation, achieves R^2 = 0.537 (95% CI: [0.465, 0.575]), representing a 55% improvement over the symbolic baseline (R^2 = 0.347). Statistical analysis confirms significance (p < 10^-25) with audio outperforming symbolic on all 19 dimensions. I validate the approach through cross-soundfont generalization (R^2 = 0.534 +/- 0.075), difficulty correlation with an external dataset (rho = 0.623), and multi-performer consistency analysis. Analysis of audio-symbolic fusion reveals high error correlation (r = 0.738), explaining why fusion provides minimal benefit: audio representations alone are sufficient. I release the complete training pipeline, pretrained models, and inference code.

</details>


### [30] [Interpretable and Perceptually-Aligned Music Similarity with Pretrained Embeddings](https://arxiv.org/abs/2601.19109)
*Arhan Vohra,Taketo Akama*

Main category: cs.SD

TL;DR: 本文提出了一种基于预训练文本-音频嵌入的音乐感知相似性检索方法，通过源分离和线性优化提升性能，提供可解释的乐器权重控制。


<details>
  <summary>Details</summary>
Motivation: 当前基于自监督度量学习的方法虽然与人类判断有较好对齐，但存在可解释性差、泛化能力有限的问题，且受限于数据集可用性。需要一种无需额外微调就能获得可比感知对齐的方法。

Method: 使用预训练的文本-音频嵌入（CLAP和MuQ-MuLan）作为基线，提出新方法：通过源分离和基于ABX偏好数据的线性优化来感知对齐预训练嵌入，提供可解释的乐器权重控制。

Result: 预训练嵌入在相似性任务上获得了与人类判断相当的感知对齐效果，无需额外微调。优化后的模型超越了这一基线，为音乐制作人提供了基于混合参考歌曲检索分轨级别循环和采样的能力。

Conclusion: 预训练文本-音频嵌入为音乐感知相似性检索提供了有效的基线，通过源分离和线性优化的方法进一步提升了性能，同时提供了可解释性和可控性，特别适用于音乐制作场景。

Abstract: Perceptual similarity representations enable music retrieval systems to determine which songs sound most similar to listeners. State-of-the-art approaches based on task-specific training via self-supervised metric learning show promising alignment with human judgment, but are difficult to interpret or generalize due to limited dataset availability. We show that pretrained text-audio embeddings (CLAP and MuQ-MuLan) offer comparable perceptual alignment on similarity tasks without any additional fine-tuning. To surpass this baseline, we introduce a novel method to perceptually align pretrained embeddings with source separation and linear optimization on ABX preference data from listening tests. Our model provides interpretable and controllable instrument-wise weights, allowing music producers to retrieve stem-level loops and samples based on mixed reference songs.

</details>


### [31] [A Hybrid Discriminative and Generative System for Universal Speech Enhancement](https://arxiv.org/abs/2601.19113)
*Yinghao Liu,Chengwei Liu,Xiaotao Liang,Haoyin Yan,Shaofei Xue,Zheng Xue*

Main category: cs.SD

TL;DR: 提出一种结合判别式与生成式建模的混合架构，用于通用语音增强，在ICASSP 2026 URGENT挑战赛中获得第三名


<details>
  <summary>Details</summary>
Motivation: 通用语音增强需要处理各种语音失真和录音条件，现有方法在信号保真度和重建能力方面各有局限，需要结合两者的优势

Method: 1) 使用具有采样频率独立策略的判别式TF-GridNet模型处理可变采样率；2) 结合谱映射建模的自回归模型生成细节丰富的语音并抑制生成伪影；3) 融合网络学习两个输出的自适应权重，在信号级损失和综合语音质量评估损失下优化

Result: 在ICASSP 2026 URGENT挑战赛（Track 1）中获得第三名

Conclusion: 提出的混合架构成功结合了判别式建模的信号保真度和生成式建模的重建能力，在通用语音增强任务中取得了优异性能

Abstract: Universal speech enhancement aims at handling inputs with various speech distortions and recording conditions. In this work, we propose a novel hybrid architecture that synergizes the signal fidelity of discriminative modeling with the reconstruction capabilities of generative modeling. Our system utilizes the discriminative TF-GridNet model with the Sampling-Frequency-Independent strategy to handle variable sampling rates universally. In parallel, an autoregressive model combined with spectral mapping modeling generates detail-rich speech while effectively suppressing generative artifacts. Finally, a fusion network learns adaptive weights of the two outputs under the optimization of signal-level losses and the comprehensive Speech Quality Assessment (SQA) loss. Our proposed system is evaluated in the ICASSP 2026 URGENT Challenge (Track 1) and ranks the third place.

</details>


### [32] [Phase-Retrieval-Based Physics-Informed Neural Networks For Acoustic Magnitude Field Reconstruction](https://arxiv.org/abs/2601.19297)
*Karl Schrader,Shoichi Koyama,Tomohiko Nakamura,Mirco Pezzoli*

Main category: cs.SD

TL;DR: 提出一种基于相位恢复的物理信息神经网络方法，从稀疏幅度测量中估计声场幅度分布，无需相位信息


<details>
  <summary>Details</summary>
Motivation: 在相位测量不可靠或无法获取的情况下，需要从稀疏幅度测量中估计声场幅度分布。传统物理信息神经网络依赖相位信息计算PDE损失，无法应用于无相位场景。

Method: 提出相位恢复基的PINN方法，使用两个独立的神经网络分别表示幅度和相位分布，通过重构的复振幅计算PDE损失，实现无相位测量下的声场估计。

Result: 通过实验评估验证了所提相位恢复基PINN方法的有效性，能够从稀疏幅度测量中准确估计声场幅度分布。

Conclusion: 该方法成功解决了无相位测量场景下的声场估计问题，扩展了PINN在声学领域的应用范围，为相位信息不可靠的实际应用提供了有效解决方案。

Abstract: We propose a method for estimating the magnitude distribution of an acoustic field from spatially sparse magnitude measurements. Such a method is useful when phase measurements are unreliable or inaccessible. Physics-informed neural networks (PINNs) have shown promise for sound field estimation by incorporating constraints derived from governing partial differential equations (PDEs) into neural networks. However, they do not extend to settings where phase measurements are unavailable, as the loss function based on the governing PDE relies on phase information. To remedy this, we propose a phase-retrieval-based PINN for magnitude field estimation. By representing the magnitude and phase distributions with separate networks, the PDE loss can be computed based on the reconstructed complex amplitude. We demonstrate the effectiveness of our phase-retrieval-based PINN through experimental evaluation.

</details>


### [33] [Residual Tokens Enhance Masked Autoencoders for Speech Modeling](https://arxiv.org/abs/2601.19399)
*Samir Sadok,Stéphane Lathuilière,Xavier Alameda-Pineda*

Main category: cs.SD

TL;DR: RT-MAE提出了一种新的掩码自编码器框架，通过可训练的残差token来捕捉语音中超出显式属性（如音高、内容、说话人）的丰富信息，提升重建质量和表达力。


<details>
  <summary>Details</summary>
Motivation: 当前语音建模主要依赖音高、内容和说话人身份等显式属性，但这些属性无法完全捕捉自然语音的丰富性（如音色变化、噪声、情感等）。

Method: RT-MAE采用掩码自编码器框架，在监督的属性建模基础上，引入无监督的可训练残差token，专门编码显式标记因素无法解释的信息。

Result: 实验表明RT-MAE提高了重建质量，在保持内容和说话人相似性的同时增强了表达力。在语音增强任务中，能在推理时去除噪声，同时保持可控性和自然度。

Conclusion: RT-MAE通过结合监督属性建模和无监督残差token，有效捕捉了语音中超出显式属性的丰富信息，在语音重建和增强任务中表现出色。

Abstract: Recent speech modeling relies on explicit attributes such as pitch, content, and speaker identity, but these alone cannot capture the full richness of natural speech. We introduce RT-MAE, a novel masked autoencoder framework that augments the supervised attributes-based modeling with unsupervised residual trainable tokens, designed to encode the information not explained by explicit labeled factors (e.g., timbre variations, noise, emotion etc). Experiments show that RT-MAE improves reconstruction quality, preserving content and speaker similarity while enhancing expressivity. We further demonstrate its applicability to speech enhancement, removing noise at inference while maintaining controllability and naturalness.

</details>


### [34] [Dual-Strategy-Enhanced ConBiMamba for Neural Speaker Diarization](https://arxiv.org/abs/2601.19472)
*Zhen Liao,Gaole Dai,Mengqiao Chen,Wenqing Cheng,Wei Xu*

Main category: cs.SD

TL;DR: 提出DSE-CBM系统，结合Conformer和Mamba优势，通过ConBiMamba模块改进局部特征提取和长序列处理，引入边界增强损失和层级特征聚合，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有Conformer和Mamba在说话人日志任务中存在局限：Mamba处理局部细节和非线性模式能力不足，Conformer的自注意力机制对长语音序列内存开销大且长距离依赖建模不稳定。说话人日志需要精确的局部变化建模和长跨度的说话人一致性。

Method: 1. 提出ConBiMamba模块，结合Conformer的卷积和前馈结构改进局部特征提取，用ExtBiMamba替换自注意力机制降低内存开销；2. 引入边界增强转换损失改进说话人切换点检测；3. 提出层级特征聚合增强多层表示利用；4. 基于Pyannote流水线构建DSE-CBM系统。

Result: 在六个说话人日志数据集上评估，在四个数据集上达到最先进的性能。代码已开源。

Conclusion: DSE-CBM系统有效解决了Conformer和Mamba在说话人日志中的局限性，通过结合两者优势并引入专门优化，实现了更好的局部特征提取和长序列处理能力，显著提升了说话人日志性能。

Abstract: Conformer and Mamba have achieved strong performance in speech modeling but face limitations in speaker diarization. Mamba is efficient but struggles with local details and nonlinear patterns. Conformer's self-attention incurs high memory overhead for long speech sequences and may cause instability in long-range dependency modeling. These limitations are critical for diarization, which requires both precise modeling of local variations and robust speaker consistency over extended spans. To address these challenges, we first apply ConBiMamba for speaker diarization. We follow the Pyannote pipeline and propose the Dual-Strategy-Enhanced ConBiMamba neural speaker diarization system. ConBiMamba integrates the strengths of Conformer and Mamba, where Conformer's convolutional and feed-forward structures are utilized to improve local feature extraction. By replacing Conformer's self-attention with ExtBiMamba, ConBiMamba efficiently handles long audio sequences while alleviating the high memory cost of self-attention. Furthermore, to address the problem of the higher DER around speaker change points, we introduce the Boundary-Enhanced Transition Loss to enhance the detection of speaker change points. We also propose Layer-wise Feature Aggregation to enhance the utilization of multi-layer representations. The system is evaluated on six diarization datasets and achieves state-of-the-art performance on four of them. The source code of our study is available at https://github.com/lz-hust/DSE-CBM.

</details>


### [35] [SLM-SS: Speech Language Model for Generative Speech Separation](https://arxiv.org/abs/2601.19533)
*Tianhua Li,Chenda Li,Wei Wang,Xin Zhou,Xihui Chen,Jianqing Gao,Yanmin Qian*

Main category: cs.SD

TL;DR: 提出SLM-SS方法，将语音语言模型应用于语音分离，通过离散多码本序列生成框架提升分离信号的清晰度和连贯性


<details>
  <summary>Details</summary>
Motivation: 现有神经网络语音分离方法在信号级指标上表现良好，但分离后的语音清晰度不足，影响下游任务（如语音识别）性能

Method: 将语音分离建模为离散多码本序列生成任务，使用编码器-解码器模型将量化语音混合映射到目标标记，同时引入自回归和非自回归模型策略

Result: 在LibriMix数据集上实验显示，该方法显著提升语音清晰度保持能力，在各种下游任务中带来更好的语言一致性

Conclusion: SLM-SS方法通过语音语言模型有效提升语音分离的清晰度和连贯性，改善下游任务性能

Abstract: Speech separation (SS) has advanced significantly with neural network-based methods, showing improved performance on signal-level metrics. However, these methods often struggle to maintain speech intelligibility in the separated signals, which can negatively affect the performance of downstream tasks such as speech recognition. In this work, we propose SLM-SS, a novel approach that applies speech language models to SS, aiming to enhance the intelligibility and coherence of the separated signals. We frame SS as discrete multi-codebook sequence generation, using Encoder-Decoder models to map quantized speech mixtures to target tokens. In addition to the autoregressive modeling strategy, we introduce a non-autoregressive model to improve decoding efficiency for residual tokens. Experimental results on the LibriMix dataset demonstrate that our approach shows significantly better preservation of speech intelligibility, leading to improved linguistic consistency in a variety of downstream tasks compared to existing approaches.

</details>


### [36] [A Benchmark for Audio Reasoning Capabilities of Multimodal Large Language Models](https://arxiv.org/abs/2601.19673)
*Iwona Christop,Mateusz Czyżnikiewicz,Paweł Skórzewski,Łukasz Bondaruk,Jakub Kubiak,Marcin Lewandowski,Marek Kubis*

Main category: cs.SD

TL;DR: 提出Audio Reasoning Tasks (ART)基准，用于评估多模态模型在音频信号上的推理能力，解决现有基准仅测试孤立音频任务的问题


<details>
  <summary>Details</summary>
Motivation: 现有基准仅测试孤立音频任务（如说话人分离、性别识别），无法验证多模态模型能否结合不同类别音频任务进行推理

Method: 提出Audio Reasoning Tasks (ART)新基准，专门设计需要音频信号推理能力的问题

Result: ART基准填补了现有评估体系的空白，能够测试多模态模型在音频领域的综合推理能力

Conclusion: 需要新的基准来评估多模态模型在音频信号上的推理能力，ART基准为此提供了解决方案

Abstract: The present benchmarks for testing the audio modality of multimodal large language models concentrate on testing various audio tasks such as speaker diarization or gender identification in isolation. Whether a multimodal model can answer the questions that require reasoning skills to combine audio tasks of different categories, cannot be verified with their use. To address this issue, we propose Audio Reasoning Tasks (ART), a new benchmark for assessing the ability of multimodal models to solve problems that require reasoning over audio signal.

</details>


### [37] [Hyperbolic Additive Margin Softmax with Hierarchical Information for Speaker Verification](https://arxiv.org/abs/2601.19709)
*Zhihua Fang,Liang He*

Main category: cs.SD

TL;DR: 本文提出基于双曲空间的H-Softmax和HAM-Softmax方法，通过双曲空间的负曲率几何特性更好地建模说话人特征的层次结构信息，显著提升了说话人验证性能。


<details>
  <summary>Details</summary>
Motivation: 传统的欧几里得空间说话人嵌入学习在建模说话人特征的层次信息方面存在不足。双曲空间具有负曲率几何特性，能够在有限体积内高效表示层次信息，更适合说话人嵌入的特征分布。

Method: 提出基于双曲空间的Hyperbolic Softmax (H-Softmax)和Hyperbolic Additive Margin Softmax (HAM-Softmax)。H-Softmax将嵌入向量和说话人中心投影到双曲空间并计算双曲距离来融入层次信息；HAM-Softmax在此基础上引入边界约束以增强类间可分性。

Result: 实验结果显示，H-Softmax相比标准Softmax平均相对EER降低27.84%，HAM-Softmax相比AM-Softmax平均相对EER降低14.23%，表明所提方法能有效提升说话人验证性能并保持层次结构建模能力。

Conclusion: 基于双曲空间的H-Softmax和HAM-Softmax方法能够更好地建模说话人特征的层次结构信息，显著改善说话人验证性能，证明了双曲空间在说话人嵌入学习中的有效性。

Abstract: Speaker embedding learning based on Euclidean space has achieved significant progress, but it is still insufficient in modeling hierarchical information within speaker features. Hyperbolic space, with its negative curvature geometric properties, can efficiently represent hierarchical information within a finite volume, making it more suitable for the feature distribution of speaker embeddings. In this paper, we propose Hyperbolic Softmax (H-Softmax) and Hyperbolic Additive Margin Softmax (HAM-Softmax) based on hyperbolic space. H-Softmax incorporates hierarchical information into speaker embeddings by projecting embeddings and speaker centers into hyperbolic space and computing hyperbolic distances. HAM-Softmax further enhances inter-class separability by introducing margin constraint on this basis. Experimental results show that H-Softmax and HAM-Softmax achieve average relative EER reductions of 27.84% and 14.23% compared with standard Softmax and AM-Softmax, respectively, demonstrating that the proposed methods effectively improve speaker verification performance and at the same time preserve the capability of hierarchical structure modeling. The code will be released at https://github.com/PunkMale/HAM-Softmax.

</details>


### [38] [Physics-Aware Novel-View Acoustic Synthesis with Vision-Language Priors and 3D Acoustic Environment Modeling](https://arxiv.org/abs/2601.19712)
*Congyi Fan,Jian Guan,Youtian Lin,Dongli Xu,Tong Ye,Qiaoxi Zhu,Pengming Feng,Wenwu Wang*

Main category: cs.SD

TL;DR: Phys-NVAS：首个物理感知的新视角音频合成框架，结合空间几何建模与视觉语言语义先验，提升沉浸式音频的真实感和物理一致性


<details>
  <summary>Details</summary>
Motivation: 现有基于单视图或全景输入的方法虽然提高了空间保真度，但无法捕捉全局几何结构和语义线索（如物体布局和材质属性），难以处理反射、衍射和材料吸收等复杂物理现象

Method: 1）从多视图图像和深度图重建全局3D声学环境，估计房间大小和形状；2）使用视觉语言模型提取物体、布局和材质的物理感知先验；3）通过声学特征融合适配器统一这些线索，生成物理感知的表示用于双耳音频生成

Result: 在RWAVS数据集上的实验表明，Phys-NVAS能够生成具有更高真实感和物理一致性的双耳音频

Conclusion: Phys-NVAS通过整合空间几何建模和视觉语言语义先验，首次实现了物理感知的新视角音频合成，显著提升了沉浸式音频体验的质量

Abstract: Spatial audio is essential for immersive experiences, yet novel-view acoustic synthesis (NVAS) remains challenging due to complex physical phenomena such as reflection, diffraction, and material absorption. Existing methods based on single-view or panoramic inputs improve spatial fidelity but fail to capture global geometry and semantic cues such as object layout and material properties. To address this, we propose Phys-NVAS, the first physics-aware NVAS framework that integrates spatial geometry modeling with vision-language semantic priors. A global 3D acoustic environment is reconstructed from multi-view images and depth maps to estimate room size and shape, enhancing spatial awareness of sound propagation. Meanwhile, a vision-language model extracts physics-aware priors of objects, layouts, and materials, capturing absorption and reflection beyond geometry. An acoustic feature fusion adapter unifies these cues into a physics-aware representation for binaural generation. Experiments on RWAVS demonstrate that Phys-NVAS yields binaural audio with improved realism and physical consistency.

</details>


### [39] [Advanced Modeling of Interlanguage Speech Intelligibility Benefit with L1-L2 Multi-Task Learning Using Differentiable K-Means for Accent-Robust Discrete Token-Based ASR](https://arxiv.org/abs/2601.19767)
*Kentaro Onda,Satoru Fukayama,Daisuke Saito,Nobuaki Minematsu*

Main category: cs.SD

TL;DR: 提出一种基于可微分k-means的ISIB建模方法，用于提升ASR系统对外国口音语音的识别性能，相比基线在有限口音数据下取得约20%的相对准确率提升。


<details>
  <summary>Details</summary>
Motivation: 在全球化背景下，构建对外国口音语音具有鲁棒性的ASR系统是一个重要挑战。先前研究探索了通过重现"中介语语音可懂度优势"现象来提升基于音素token的ASR在口音语音上的性能。

Method: 采用可微分k-means技术，并优化整个模块同时用于L1和L2 ASR。相比先前使用说话者母语在SSL特征空间中学习k-means聚类中心点的方法，本方法进行了更先进的ISIB建模。

Result: 提出的方法在仅使用母语语音和额外加入有限数量口音语音两种场景下均优于基线。特别在后者场景中，识别准确率实现了约20%的相对提升。

Conclusion: 通过可微分k-means和端到端优化的先进ISIB建模方法，能够有效提升ASR系统对外国口音语音的识别性能，在有限口音数据下取得显著改进。

Abstract: Building ASR systems robust to foreign-accented speech is an important challenge in today's globalized world. A prior study explored the way to enhance the performance of phonetic token-based ASR on accented speech by reproducing the phenomenon known as interlanguage speech intelligibility benefit (ISIB), where foreign-accented speech is more intelligible to listeners sharing the speaker's native language than to native listeners. ISIB was technically implemented by using the speaker's L1 to learn k-means cluster centroids in an SSL feature space to obtain phonetic tokens. In this study, we propose a more advanced modeling of ISIB. By employing differentiable k-means and optimizing the entire module for both L1 and L2 ASR, the proposed method outperformed the baselines, both when using only native speech and when additionally incorporating a limited amount of accented speech. Notably, in the latter scenario, our method achieved approximately a 20% relative improvement in recognition accuracy.

</details>


### [40] [Phonological Tokenizer: Prosody-Aware Phonetic Token via Multi-Objective Fine-Tuning with Differentiable K-Means](https://arxiv.org/abs/2601.19781)
*Kentaro Onda,Hayato Futami,Yosuke Kashiwagi,Emiru Tsunoo,Shinji Watanabe*

Main category: cs.SD

TL;DR: 提出Phonological Tokenizer方法，通过可微分k-means和多任务目标（ASR和语音重合成）微调语音标记，保留语音学（语言和韵律）信息同时去除说话人身份


<details>
  <summary>Details</summary>
Motivation: 现有语音离散标记分为声学标记（含详细声学信息）和语音标记（主要捕捉语言内容），但都不适合对韵律敏感的任务。人类语音交流中会抽象掉不必要的声学细节（如说话人信息），同时利用语言和韵律信息进行理解和生成

Method: 提出Phonological Tokenizer方法：1）使用可微分k-means对语音标记进行微调；2）采用多任务目标，包括自动语音识别（ASR）和语音重合成；3）旨在保留语音学信息（语言和韵律）同时适当去除说话人身份

Result: 在多样化任务上的实验验证表明，该方法生成的标记能够保留语音学（语言和韵律）信息，同时适当去除说话人身份

Conclusion: Phonological Tokenizer提供了一种更适合对韵律敏感任务（如语音语言模型）的语音表示方法，平衡了语言内容、韵律信息和说话人身份的去除

Abstract: In recent years, there has been growing interest in representing speech with discrete tokens, which serve as pseudo-text for speech language models (speechLMs) and as efficient intermediate representations for downstream tasks. These tokens are typically categorized as acoustic and phonetic tokens: the former holds detailed acoustic information for reconstruction while the latter mainly captures linguistic content. In human speech communication, however, unnecessary acoustic details such as speaker information are abstracted, while both linguistic and prosodic information are utilized for speech comprehension and production. Given this, neither type of token seems an ideal representation for tasks sensitive to prosody, such as speechLMs. In this study, we propose the Phonological Tokenizer, a method that fine-tunes phonetic tokens via differentiable k-means with a multi-task objective of ASR and speech resynthesis. Experimental validation on diverse tasks confirms that our tokens retain phonological (both linguistic and prosodic) information while appropriately discarding speaker identity.

</details>

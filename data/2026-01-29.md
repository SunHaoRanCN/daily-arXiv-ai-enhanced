<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 15]
- [eess.AS](#eess.AS) [Total: 8]
- [cs.SD](#cs.SD) [Total: 8]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Electromagnetically Consistent Bounds on Information Transfer in Real-World RIS-Parametrized Wireless Channels](https://arxiv.org/abs/2601.20017)
*Albert Salmi,Ville Viikari,Philipp del Hougne*

Main category: eess.SP

TL;DR: 本文针对可重构智能表面(RIS)增强的无线信道，基于严格的多端口网络模型，提出了一个电磁一致且考虑硬件约束的SISO信道增益增强基本界限，并通过半定松弛方法推导出理论界限。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注RIS信道优化算法，但缺乏对可实现信息传输的基本界限的研究，特别是既符合电磁一致性（考虑互耦效应）又符合实际硬件约束（如少比特可编程、有损负载）的非平凡界限。

Method: 基于单输入单输出(SISO)信道的严格多端口网络模型，采用半定松弛(SDR)方法推导出可实现SISO信道增益增强的基本界限，并通过香农定理直接得到给定噪声水平下的最大可实现信息传输速率界限。

Result: 提出的SDR界限比电磁一致的基准界限策略（范数不等式界限和理想化超对角负载网络松弛）显著更紧。通过标准离散优化技术，至少能达到SDR界限的64%（通常为100%）。

Conclusion: 该界限适用于具体实验系统，对无线实践者评估RIS硬件设计选择和优化RIS配置算法具有重要价值，为RIS参数化信道及其他可编程波系统的电磁信息理论发展做出贡献。

Abstract: A reconfigurable intelligent surface (RIS) endows a wireless channel with programmability that can be leveraged to optimize wireless information transfer. While many works study algorithms for optimizing such a programmable channel, relatively little is known about fundamental bounds on the achievable information transfer. In particular, non-trivial bounds that are both electromagnetically consistent (e.g., aware of mutual coupling) and in line with realistic hardware constraints (e.g., few-bit-programmable, potentially lossy loads) are missing. Here, based on a rigorous multiport network model of a single-input single-output (SISO) channel parametrized by 1-bit-programmable RIS elements, we apply a semidefinite relaxation (SDR) to derive a fundamental bound on the achievable SISO channel gain enhancement. A bound on the maximum achievable rate of information transfer at a given noise level follows directly from Shannon's theorem. We apply our bound to several numerical and experimental examples of different RIS-parametrized radio environments. Compared to electromagnetically consistent benchmark bounding strategies (a norm-inequality bound and, where applicable, a relaxation to an idealized beyond-diagonal load network for which a global solution exists), we consistently observe that our SDR-based bound is notably tighter. We reach at least 64 % (but often 100 %) of our SDR-based bound with standard discrete optimization techniques. The applicability of our bound to concrete experimental systems makes it valuable to inform wireless practitioners, e.g., to evaluate RIS hardware design choices and algorithms to optimize the RIS configuration. Our work contributes to the development of an electromagnetic information theory for RIS-parametrized channels as well as other programmable wave systems such as dynamic metasurface antennas or real-life beyond-diagonal RISs.

</details>


### [2] [Holographic & Channel-Aware Distributed Detection of a Non-cooperative Target](https://arxiv.org/abs/2601.20124)
*Domenico Ciuonzo,Alessio Zappone,Marco Di Renzo,Ciro D'Elia*

Main category: eess.SP

TL;DR: 该论文研究无线传感器网络中的分布式检测问题，提出了一种基于可重构超表面的全息融合架构，在少量接收天线下实现大孔径增益，并设计了低复杂度联合优化策略。


<details>
  <summary>Details</summary>
Motivation: 无线传感器网络中的分布式检测面临效率和能耗挑战，特别是在物联网场景下需要满足能量高效约束。传统方法需要大量射频硬件，而本文旨在通过全息架构实现可靠检测的同时降低硬件复杂度。

Method: 1. 在少量接收天线近场部署可重构超表面，构建全息融合架构；2. 推导固定超表面设置下的广义似然比检验；3. 提出两种低复杂度联合设计策略，同时优化融合和超表面配置。

Result: 仿真结果验证了所提全息融合架构的有效性，即使在简化设计下也能实现可靠检测。提出的次优方案在性能、复杂度和系统知识需求之间取得了良好平衡。

Conclusion: 基于可重构超表面的全息融合架构为无线传感器网络分布式检测提供了高效解决方案，能够在满足物联网能量约束的同时实现可靠检测，为未来智能感知系统设计提供了新思路。

Abstract: This work investigates Distributed Detection (DD) in Wireless Sensor Networks (WSNs), where spatially distributed sensors transmit binary decisions over a shared flat-fading channel. To enhance fusion efficiency, a reconfigurable metasurface is positioned in the near-field of a few receive antennas, enabling a holographic architecture that harnesses large-aperture gains with minimal RF hardware. A generalized likelihood ratio test is derived for fixed metasurface settings, and two low-complexity joint design strategies are proposed to optimize both fusion and metasurface configuration. These suboptimal schemes achieve a balance between performance, complexity, and system knowledge. The goal is to ensure reliable detection of a localized phenomenon at the fusion center, under energy-efficient constraints aligned with IoT requirements. Simulation results validate the effectiveness of the proposed holographic fusion, even under simplified designs.

</details>


### [3] [Coverage Performance Analysis of FAS-enhanced LoRa Wide Area Networks under both Co-SF and Inter-SF Interference](https://arxiv.org/abs/2601.20178)
*Gaoze Mu,Yanzhao Hou,Mingjie Chen,Yuanyu Hu,Yongan Zheng,Qimei Cui,Xiaofeng Tao*

Main category: eess.SP

TL;DR: 本文提出了一个分析框架来评估流体天线系统增强的LoRa广域网覆盖性能，考虑了大规模路径损耗、FAS表征的小尺度衰落以及随机部署终端设备产生的密集干扰，推导了FAS信道统计近似和覆盖概率理论表达式。


<details>
  <summary>Details</summary>
Motivation: 随着物联网设备数量的快速增长，LoRaWAN网络面临覆盖范围和终端容量限制的挑战。传统固定天线系统在衰落环境下性能受限，需要新的技术方案来提升网络性能。

Method: 提出分析框架，考虑大规模路径损耗、FAS表征的小尺度衰落、同SF和不同SF干扰。使用极值定理推导FAS信道包络和功率的统计近似，基于近似信道表达式推导FAS增强LoRaWAN的理论覆盖概率。

Result: 数值结果验证了分析近似与精确相关模型高度一致。归一化孔径为1×1的FAS能显著提升网络性能，包括终端数量和覆盖范围。

Conclusion: FAS技术能有效增强LoRaWAN网络性能，提出的分析框架为评估FAS增强网络提供了理论基础，归一化孔径为1×1的FAS配置能实现显著的性能提升。

Abstract: This paper presents an analytical framework for evaluating the coverage performance of the fluid antenna system (FAS)-enhanced LoRa wide-area networks (LoRaWANs). We investigate the effects of large-scale pathloss in LoRaWAN, small-scale fading characterized by FAS, and dense interference (i.e., collision in an ALOHA-based mechanism) arising from randomly deployed end devices (EDs). Both co-spreading factor (co-SF) interference (with the same SF) and inter-SF interference (with different SFs) are introduced into the network, and their differences in physical characteristics are also considered in the analysis. Additionally, simple yet accurate statistical approximations of the FAS channel envelope and power are derived using the extreme-value theorem. Based on the approximated channel expression, the theoretical coverage probability of the proposed FAS-enhanced LoRaWAN is derived. Numerical results validate our analytical approximations by exhibiting close agreement with the exact correlation model. Notably, it is revealed that a FAS with a normalized aperture of 1 times 1 can greatly enhance network performance, in terms of both ED numbers and coverage range.

</details>


### [4] [WirelessJEPA: A Multi-Antenna Foundation Model using Spatio-temporal Wireless Latent Predictions](https://arxiv.org/abs/2601.20190)
*Viet Chu,Omar Mashaal,Hatem Abou-Zeid*

Main category: eess.SP

TL;DR: WirelessJEPA是一个基于JEPA架构的无线基础模型，直接从真实多天线IQ数据学习通用表示，通过预测掩码信号区域的潜在表示，支持多种下游任务而无需精心设计的对比增强。


<details>
  <summary>Details</summary>
Motivation: 构建通用的无线基础模型（WFM），能够直接从真实无线信号数据学习通用表示，避免对精心设计的对比增强的依赖，实现跨多种下游任务的泛化能力。

Method: 1. 提出2D天线时间表示，将多天线IQ流重塑为结构化网格，支持卷积处理和块掩码；2. 引入新颖的时空掩码几何结构，编码跨天线和时间的归纳偏置；3. 基于JEPA架构，通过预测掩码信号区域的潜在表示来学习通用表示。

Result: 在六个下游任务上评估WirelessJEPA，展示了其鲁棒性能和强大的任务泛化能力，验证了JEPA学习作为构建可泛化无线基础模型的有前景方向。

Conclusion: JEPA架构为构建通用无线基础模型提供了有前景的方向，WirelessJEPA通过直接从真实无线信号学习通用表示，实现了跨多种下游任务的强大泛化能力。

Abstract: We propose WirelessJEPA, a novel wireless foundation model (WFM) that uses the Joint Embedding Predictive Architecture (JEPA). WirelessJEPA learns general-purpose representations directly from real-world multi-antenna IQ data by predicting latent representations of masked signal regions. This enables multiple diverse downstream tasks without reliance on carefully engineered contrastive augmentations. To adapt JEPA to wireless signals, we introduce a 2D antenna time representation that reshapes multi-antenna IQ streams into structured grids, allowing convolutional processing with block masking and efficient sparse computation over unmasked patches. Building on this representation, we propose novel spatio temporal mask geometries that encode inductive biases across antennas and time. We evaluate WirelessJEPA across six downstream tasks and demonstrate it's robust performance and strong task generalization. Our results establish that JEPA-based learning as a promising direction for building generalizable WFMs.

</details>


### [5] [User Localization via Active Sensing with Electromagnetically Reconfigurable Antennas](https://arxiv.org/abs/2601.20501)
*Ruizhi Zhang,Yuchen Zhang,Ying Zhang*

Main category: eess.SP

TL;DR: 提出基于电磁可重构天线的端到端深度学习用户定位框架，通过主动感知和两时间尺度设计提升定位精度


<details>
  <summary>Details</summary>
Motivation: 传统数字波束成形定位方法精度有限，需要利用电磁可重构天线提供的额外电磁可重构性来多样化接收测量并增强定位信息量

Method: 采用两时间尺度设计：数字组合器每阶段更新，ERA模式通过球谐表示每子阶段重构；集成注意力特征提取和LSTM时序学习，学习优化感知策略并逐步细化用户位置估计

Result: 仿真结果表明，该方法在定位精度上始终优于传统数字波束成形和单阶段感知基线方法

Conclusion: ERA使能的主动感知对于未来无线系统中的用户定位具有显著效果，为高精度定位提供了有效解决方案

Abstract: This paper presents an end-to-end deep learning framework for electromagnetically reconfigurable antenna (ERA)-aided user localization with active sensing, where ERAs provide additional electromagnetic reconfigurability to diversify the received measurements and enhance localization informativeness.
  To balance sensing flexibility and overhead, we adopt a two-timescale design: the digital combiner is updated at each stage, while the ERA patterns are reconfigured at each substage via a spherical-harmonic representation. The proposed mechanism integrates attention-based feature extraction and LSTM-based temporal learning, enabling the system to learn an optimized sensing strategy and progressively refine the UE position estimate from sequential observations. Simulation results show that the proposed approach consistently outperforms conventional digital beamforming-only and single-stage sensing baselines in terms of localization accuracy. These results highlight the effectiveness of ERA-enabled active sensing for user localization in future wireless systems.

</details>


### [6] [Vehicular Wireless Positioning -- A Survey](https://arxiv.org/abs/2601.20547)
*Sharief Saleh,Satyam Dwivedi,Russ Whiton,Peter Hammarberg,Musa Furkan Keskin,Julia Equi,Hui Chen,Florent Munier,Olof Eriksson,Fredrik Gunnarsson,Fredrik Tufvesson,Henk Wymeersch*

Main category: eess.SP

TL;DR: 本文对车联网中的无线定位技术进行了全面综述，涵盖卫星定位、蜂窝定位和IEEE技术，并探讨了与感知和运动传感器的融合方法。


<details>
  <summary>Details</summary>
Motivation: 随着智能网联汽车的快速发展，复杂环境下对高精度可靠定位系统的需求日益增长，需要整合多种定位技术来满足这些需求。

Method: 通过系统性文献综述方法，分析卫星定位（GNSS、LEO）、蜂窝定位（5G及更高版本）和IEEE技术（Wi-Fi、UWB、蓝牙、V2V）的发展历程、标准化进程和算法分类。

Result: 提供了各类车用无线定位技术的详细分类、性能要求分析、现有解决方案评估，并识别了开放挑战和当前趋势。

Conclusion: 该综述为车用无线定位技术提供了历史基础、当前进展和未来方向的整体视角，填补了文献中的关键空白，并强调了传感器融合技术对提升实际环境定位精度和鲁棒性的重要性。

Abstract: The rapid advancement of connected and autonomous vehicles has driven a growing demand for precise and reliable positioning systems capable of operating in complex environments. Meeting these demands requires an integrated approach that combines multiple positioning technologies, including wireless-based systems, perception-based technologies, and motion-based sensors. This paper presents a comprehensive survey of wireless-based positioning for vehicular applications, with a focus on satellite-based positioning (such as global navigation satellite systems (GNSS) and low-Earth-orbit (LEO) satellites), cellular-based positioning (5G and beyond), and IEEE-based technologies (including Wi-Fi, ultrawideband (UWB), Bluetooth, and vehicle-to-vehicle (V2V) communications). First, the survey reviews a wide range of vehicular positioning use cases, outlining their specific performance requirements. Next, it explores the historical development, standardization, and evolution of each wireless positioning technology, providing an in-depth categorization of existing positioning solutions and algorithms, and identifying open challenges and contemporary trends. Finally, the paper examines sensor fusion techniques that integrate these wireless systems with onboard perception and motion sensors to enhance positioning accuracy and resilience in real-world conditions. This survey thus offers a holistic perspective on the historical foundations, current advancements, and future directions of wireless-based positioning for vehicular applications, addressing a critical gap in the literature.

</details>


### [7] [Precoding Design for Multi-User MIMO Joint Communications and Sensing](https://arxiv.org/abs/2601.20647)
*Charlotte Muth,Shrinivas Chimmalgi,Laurent Schmalen*

Main category: eess.SP

TL;DR: 研究多用户MIMO联合通信感知系统中的预编码技术，考虑感知与通信信道间的潜在干扰，推导了检测概率和通信SINR作为性能指标，发现通信信号用于感知可避免通信性能损失，但通信信号的峰度限制了感知性能。


<details>
  <summary>Details</summary>
Motivation: 在多用户MIMO联合通信感知系统中，感知与通信信道之间存在潜在干扰，需要研究如何通过预编码技术来优化系统性能，同时考虑通信信号用于感知时的性能影响。

Method: 推导了感知性能指标（检测概率）和通信性能指标（信号干扰噪声比SINR）用于一般输入信号，分析了通信信号峰度对感知性能的限制，并通过仿真验证了示例设置的结果。

Result: 研究结果表明：当信道干扰发生时，使用通信信号进行感知可以避免通信性能损失；但通信信号传输字母的峰度限制了感知性能，仿真结果验证了这些发现。

Conclusion: 在多用户MIMO联合通信感知系统中，预编码设计需要考虑感知与通信的权衡，通信信号可用于感知以避免通信性能损失，但通信信号的统计特性（特别是峰度）对感知性能有重要限制。

Abstract: We investigate precoding for multi-user (MU) multiple-input multiple-output (MIMO) joint communications and sensing (JCAS) systems, taking into account the potential interference between sensing and communication channels. We derive indicators for the sensing and communication performance, i.e., the detection probability and the communication signal-to-interference-and-noise ratio (SINR) for general input signals. Our results show that the use of the communication signal for sensing can prevent a loss in communication performance if channel interference occurs, while the kurtosis of the transmit alphabet of the communication signal limits the sensing performance. We present simulation results of example setups.

</details>


### [8] [RL based Beamforming Optimization for 3D Pinching Antenna assisted ISAC Systems](https://arxiv.org/abs/2601.20654)
*Qian Gao,Ruikang Zhong,Yue Liu,Hyundong Shin,Yuanwei Liu*

Main category: eess.SP

TL;DR: 提出三维捏合天线阵列部署方案，采用异构图神经网络强化学习算法优化天线位置、时间分配和发射功率，以提升集成感知与通信系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有集成感知与通信（ISAC）系统中，天线阵列通常采用一维或二维部署，限制了系统性能。三维部署能更好地利用空间维度，但需要解决天线位置、时间分配和功率分配的联合优化问题。

Method: 提出三维捏合天线阵列部署方案，建立联合天线定位、时间分配和发射功率优化问题，以最大化总通信速率。为解决该优化问题，设计了基于异构图神经网络的强化学习（HGRL）算法，通过先进的环境观测构建提升性能。

Result: 仿真结果表明，三维捏合天线阵列部署在ISAC系统中优于一维和二维部署。所提出的HGRL算法在性能和收敛速度上均优于其他基线方法。

Conclusion: 三维天线阵列部署能显著提升ISAC系统性能，提出的HGRL算法能有效解决复杂的联合优化问题，为未来ISAC系统设计提供了新思路。

Abstract: In this paper, a three-dimensional (3D) deployment scheme of pinching antenna array is proposed, aiming to enhances the performance of integrated sensing and communication (ISAC) systems. To fully realize the potential of 3D deployment, a joint antenna positioning, time allocation and transmit power optimization problem is formulated to maximize the sum communication rate with the constraints of target sensing rates and system energy. To solve the sum rate maximization problem, we propose a heterogeneous graph neural network based reinforcement learning (HGRL) algorithm. Simulation results prove that 3D deployment of pinching antenna array outperforms 1D and 2D counterparts in ISAC systems. Moreover, the proposed HGRL algorithm surpasses other baselines in both performance and convergence speed due to the advanced observation construction of the environment.

</details>


### [9] [Integrated Sensing and Communication for Segmented Waveguide-Enabled Pinching Antenna Systems](https://arxiv.org/abs/2601.20658)
*Qian Gao,Ruikang Zhong,Hyundong Shin,Yuanwei Liu*

Main category: eess.SP

TL;DR: 提出一种用于分段波导夹持天线阵列系统的集成感知与通信设计，通过混合段选择与复用协议和基于段滞后的强化学习算法优化系统性能


<details>
  <summary>Details</summary>
Motivation: 利用分段波导的低传播损耗特性，在集成感知与通信系统中提高性能，同时降低硬件成本

Method: 提出混合段选择与复用协议，采用基于段滞后的强化学习算法联合优化发射波束成形、段选择和夹持天线位置

Result: 仿真结果表明：1）提出的SWAN-ISAC方案优于其他基线方案；2）提出的SHRL算法比传统RL算法性能更好

Conclusion: 通过分段波导的低传播损耗特性和智能优化算法，成功实现了高性能、低成本的集成感知与通信系统设计

Abstract: In this paper, an integrated sensing and communication (ISAC) design for segmented waveguide-enabled pinching-antenna array (SWAN) systems is proposed to improve the performance of systems by leveraging the low in-waveguide propagation loss of segmented waveguides. The hybrid segment selection and multiplexing (HSSM) protocol is implemented to provide favorable performance with less hardware cost. To achieve this, a joint transmit beamforming optimization, segment selection, and pinching antenna positioning problem is formulated to maximize the sum communication rate with the constraints of sensing performance. To solve the maximization problem, we propose a segment hysteresis based reinforcement learning (SHRL) algorithm to learn segment selection and pinching antenna positions in different progress to explore better strategies. Simulation results demonstrate that 1) the proposed SWAN-ISAC scheme outperforms the other baseline schemes, and 2) the proposed HARL algorithm achieves better performance compared to conventional RL algorithms.

</details>


### [10] [Deep Learning based Three-stage Solution for ISAC Beamforming Optimization](https://arxiv.org/abs/2601.20667)
*Qian Gao,Ruikang Zhong,Yuanwei Liu*

Main category: eess.SP

TL;DR: 本文提出了一种基于深度学习的三阶段ISAC波束赋形优化框架，通过特征提取、波束模式优化和波束赋形重构三个模块，在满足感知速率约束下最大化通信速率。


<details>
  <summary>Details</summary>
Motivation: 在ISAC系统中，基站需要同时与多个用户通信并进行目标检测，这需要在满足感知速率约束的同时最大化通信速率。传统方法难以有效处理可变CSI和复杂约束下的波束赋形优化问题。

Method: 提出三阶段深度学习框架：1) 无监督学习提取CSI的固定大小潜在特征；2) 强化学习搜索最优波束模式；3) 监督学习从波束模式重构波束赋形向量。

Result: 仿真结果表明，所提出的三阶段解决方案优于基线RL算法，通过优化直观的波束模式而非直接优化波束赋形，取得了更好的性能。

Conclusion: 该三阶段深度学习框架为ISAC波束赋形优化提供了有效解决方案，通过分离特征提取、波束模式优化和重构过程，显著提升了系统性能。

Abstract: In this paper, a general ISAC system where the base station (BS) communicates with multiple users and performs target detection is considered. Then, a sum communication rate maximization problem is formulated, subjected to the constraints of transmit power and the minimum sensing rates of users. To solve this problem, we develop a framework that leverages deep learning algorithms to provide a three-stage solution for ISAC beamforming. The three-stage beamforming optimization solution includes three modules: 1) an unsupervised learning based feature extraction algorithm is proposed to extract fixed-size latent features while keeping its essential information from the variable channel state information (CSI); 2) a reinforcement learning (RL) based beampattern optimization algorithm is proposed to search the desired beampattern according to the extracted features; 3) a supervised learning based beamforming reconstruction algorithm is proposed to reconstruct the beamforming vector from beampattern given by the RL agent. Simulation results demonstrate that the proposed three-stage solution outperforms the baseline RL algorithm by optimizing the intuitional beampattern rather than beamforming.

</details>


### [11] [Grover's Search-Inspired Quantum Reinforcement Learning for Massive MIMO User Scheduling](https://arxiv.org/abs/2601.20688)
*Ruining Fan,Xingyu Huang,Mouli Chakraborty,Avishek Nag,Anshu Mukherjee*

Main category: eess.SP

TL;DR: 提出基于Grover搜索的量子强化学习框架，用于解决大规模MIMO用户调度问题，相比传统方法在性能和收敛性上有显著提升


<details>
  <summary>Details</summary>
Motivation: 大规模MIMO系统中的用户调度面临计算复杂度高、可扩展性差和信道状态信息开销大的挑战，传统方法难以有效处理指数级增长的调度空间

Method: 提出Grover搜索启发的量子强化学习框架，使用量子门电路实现强化学习的分层架构，量子操作作为策略更新和决策单元，有效探索指数级调度空间

Result: 仿真结果表明，该方法实现了适当的收敛性，并显著优于传统的卷积神经网络和量子深度学习基准方法

Conclusion: 基于Grover搜索的量子强化学习框架为大规模MIMO用户调度提供了一种高效解决方案，在5G/B5G系统中具有应用潜力

Abstract: The efficient user scheduling policy in the massive Multiple Input Multiple Output (mMIMO) system remains a significant challenge in the field of 5G and Beyond 5G (B5G) due to its high computational complexity, scalability, and Channel State Information (CSI) overhead. This paper proposes a novel Grover's search-inspired Quantum Reinforcement Learning (QRL) framework for mMIMO user scheduling. The QRL agent can explore the exponentially large scheduling space effectively by applying Grover's search to the reinforcement learning process. The model is implemented using our designed quantum-gate-based circuit, which imitates the layered architecture of reinforcement learning, where quantum operations act as policy updates and decision-making units. Moreover, the simulation results demonstrate that the proposed method achieves proper convergence and significantly outperforms classical Convolutional Neural Networks (CNN) and Quantum Deep Learning (QDL) benchmarks.

</details>


### [12] [Sequential Processing Strategies in Fronthaul Constrained Cell-Free Massive MIMO Networks](https://arxiv.org/abs/2601.20721)
*Vida Ranjbar,Robbert Beerten,Marc Moonen,Sofie Pollin*

Main category: eess.SP

TL;DR: 提出两种顺序处理策略来改善链式前传压缩对用户频谱效率总和的负面影响：线性增加前传容量分配和双路径用户信号估计。


<details>
  <summary>Details</summary>
Motivation: 在具有菊花链前传的无蜂窝大规模MIMO网络中，每个接入点需要与链中下一个接入点通信的信息量取决于其在顺序前传中的位置，这导致前传压缩对用户频谱效率总和产生不利影响。

Method: 提出两种顺序处理策略：1) 在接入点之间线性增加前传容量分配；2) 双路径用户信号估计方法。

Result: 两种策略在频谱效率总和方面均优于相等前传容量分配和单路径顺序信号估计方法。

Conclusion: 通过优化前传容量分配和采用双路径信号估计，可以有效缓解链式前传压缩对无蜂窝大规模MIMO网络性能的负面影响。

Abstract: In a cell-free massive MIMO (CFmMIMO) network with a daisy-chain fronthaul, the amount of information that each access point (AP) needs to communicate with the next AP in the chain is determined by the location of the AP in the sequential fronthaul. Therefore, we propose two sequential processing strategies to combat the adverse effect of fronthaul compression on the sum of users' spectral efficiency (SE): 1) linearly increasing fronthaul capacity allocation among APs and 2) Two-Path users' signal estimation. The two strategies show superior performance in terms of sum SE compared to the equal fronthaul capacity allocation and Single-Path sequential signal estimation.

</details>


### [13] [Multi-Mode Pinching Antenna Systems Enabled Multi-User Communications](https://arxiv.org/abs/2601.20780)
*Xiaoxia Xu,Xidong Mu,Yuanwei Liu,Arumugam Nallanathan*

Main category: eess.SP

TL;DR: 提出多模式夹持天线系统(PASS)框架，通过波导中的多个导模实现多用户通信，开发了基于信道正交性和粒子群优化的天线分组与波束成形联合优化方案。


<details>
  <summary>Details</summary>
Motivation: 传统单模PASS系统容量有限，需要开发能够利用波导中多个导模进行多用户通信的高效系统，通过模式域复用提高通信效率。

Method: 1) 建立物理模型揭示夹持天线的模式选择性功率辐射特性；2) 提出PA分组方案，每组匹配特定导模；3) 针对非泄漏和弱泄漏两种机制，分别开发基于信道正交性的牛顿搜索算法和PSO-ZF联合优化算法。

Result: 仿真结果表明，所提出的多模式PASS系统在性能和容量上优于传统单模PASS和固定天线结构，实现了高效的多用户通信。

Conclusion: 多模式PASS框架通过模式域复用显著提升了多用户通信效率，提出的PA分组和联合优化方案有效解决了模式选择性辐射带来的技术挑战。

Abstract: This paper proposes a novel multi-mode pinching-antenna systems (PASS) framework. Multiple data streams can be transmitted within a single waveguide through multiple guided modes, thus facilitating efficient multi-user communications through the mode-domain multiplexing. A physic model is derived, which reveals the mode-selective power radiation feature of pinching antennas (PAs). A two-mode PASS enabled two-user downlink communication system is investigated. Considering the mode selectivity of PA power radiation, a practical PA grouping scheme is proposed, where each PA group matches with one specific guided mode and mainly radiates its signal sequentially. Depending on whether the guided mode leaks power to unmatched PAs or not, the proposed PA grouping scheme operates in either the non-leakage or weak-leakage regime. Based on this, the baseband beamforming and PA locations are jointly optimized for sum rate maximization, subject to each user's minimum rate requirement. 1) A simple two-PA case in non-leakage regime is first considered. To solve the formulated problem, a channel orthogonality based solution is proposed. The channel orthogonality is ensured by large-scale and wavelength-scale equality constraints on PA locations. Thus, the optimal beamforming reduces to maximum-ratio transmission (MRT). Moreover, the optimal PA locations are obtained via a Newton-based one-dimension search algorithm that enforces two-scale PA-location constraints by Newton's method. 2) A general multi-PA case in both non-leakage and weak-leakage regimes is further considered. A low-complexity particle-swarm optimization with zero-forcing beamforming (PSO-ZF) algorithm is developed, thus effectively tackling the high-oscillatory and strong-coupled problem. Simulation results demonstrate the superiority of the proposed multi-mode PASS over conventional single-mode PASS and fixed-antenna structures.

</details>


### [14] [AI-Driven Design of Stacked Intelligent Metasurfaces for Software-Defined Radio Applications](https://arxiv.org/abs/2601.20795)
*Ivan Iudice,Giacinto Gelli,Donatella Darsena*

Main category: eess.SP

TL;DR: 在NVIDIA Sionna框架中实现可堆叠智能超表面模型，用于6G物理层研究，支持GPU加速的端到端训练和自适应波束赋形优化。


<details>
  <summary>Details</summary>
Motivation: 将可重构智能表面集成到未来无线通信系统中，可以动态塑造环境和提高频谱效率。需要一种在AI原生框架中实现SIM模型的方法，以支持6G物理层研究和端到端训练。

Method: 在NVIDIA的AI原生框架Sionna中实现一致的堆叠智能超表面模型，构建完全可微分和GPU加速的仿真环境，集成到TensorFlow流程中，支持闭环学习场景。

Result: 实现了SIM模型在Sionna框架中的集成，展示了在自适应波束赋形和动态重配置等闭环学习场景中的应用，提供了各种部署场景的基准测试结果，特别是在非地面网络传播环境中表现出色。

Conclusion: 这项工作展示了将智能超表面集成到现代AI加速软件定义无线电系统中的可扩展模块化方法，为未来的硬件在环实验铺平了道路。

Abstract: The integration of reconfigurable intelligent surfaces (RIS) into future wireless communication systems offers promising capabilities in dynamic environment shaping and spectrum efficiency. In this work, we present a consistent implementation of a stacked intelligent metasurface (SIM) model within the NVIDIA's AI-native framework Sionna for 6G physical layer research. Our implementation allows simulation and learning-based optimization of SIM-assisted communication channels in fully differentiable and GPU-accelerated environments, enabling end-to-end training for cognitive and software-defined radio (SDR) applications. We describe the architecture of the SIM model, including its integration into the TensorFlow-based pipeline, and showcase its use in closed-loop learning scenarios involving adaptive beamforming and dynamic reconfiguration. Benchmarking results are provided for various deployment scenarios, highlighting the model's effectiveness in enabling intelligent control and signal enhancement in non-terrestrial-network (NTN) propagation environments. This work demonstrates a scalable, modular approach for incorporating intelligent metasurfaces into modern AI-accelerated SDR systems and paves the way for future hardware-in-the-loop experiments.

</details>


### [15] [Statistical Properties of Target Localization Using Passive Radar Systems](https://arxiv.org/abs/2601.20817)
*Mats Viberg,Daniele Gerosa,Tomas McKelvey,Thomas Eriksson*

Main category: eess.SP

TL;DR: 论文分析了被动雷达系统中的扩展消除算法（ECA），推导了其在高信噪比下的统计特性，并给出了实现统计有效估计的参考信道信噪比条件。


<details>
  <summary>Details</summary>
Motivation: 被动雷达系统因其低成本、隐蔽性而备受关注，但需要有效的目标检测和定位算法。扩展消除算法（ECA）作为经典方法，其统计特性尚未得到充分研究，需要理论分析来预测系统性能。

Method: 采用理论推导方法，分析扩展消除算法（ECA）在高信噪比假设下的统计特性。通过参考信道（RC）消除直接路径干扰和杂波，推导参数估计的统计性质，并给出实现统计有效估计的参考信道信噪比条件。

Result: 推导出了ECA参数估计在高信噪比下的统计特性，给出了实现统计有效估计的参考信道信噪比充分条件。计算机仿真验证了理论结果，表明在特定信噪比阈值以上理论与经验结果吻合良好。

Conclusion: 该研究为被动雷达系统性能预测提供了理论基础，可用于可行性研究和系统设计。理论结果与仿真验证表明，在满足特定信噪比条件下，ECA算法能够提供统计有效的参数估计。

Abstract: Passive Radar Systems have received tremendous attention during the past few decades, due to their low cost and ability to remain covert during operation. Such systems do not transmit any energy themselves, but rely on a so-called Illuminator-of-Opportunity (IO), for example a commercial TV station. A network of Receiving Nodes (RN) receive the direct signal as well as reflections from possible targets. The RNs transmit information to a Central Node (CN), that performs the final target detection, localization and tracking. A large number of methods and algorithms for target detection and localization have been proposed in the literature. In the present contribution, the focus is on the seminal Extended Cancelation Algorithm (ECA), in which each RN estimates target parameters after canceling interference from the direct-path as well as clutter from unwanted stationary objects. This is done by exploiting a separate Reference Channel (RC), which captures the IO signal without interference apart from receiver noise. We derive the statistical properties of the ECA parameter estimates under the assumption of a high Signal-to-Noise Ratio (SNR), and we give a sufficient condition for the SNR in the RC to enable statistically efficient estimates. The theoretical results are corroborated through computer simulations, which show that the theory agrees well with empirical results above a certain SNR threshold. The results can be used to predict the performance of passive radar systems in given scenarios, which is useful for feasibility studies as well as system design.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [16] [MK-SGC-SC: Multiple Kernel guided Sparse Graph Construction in Spectral Clustering for Unsupervised Speaker Diarization](https://arxiv.org/abs/2601.19946)
*Nikhil Raghav,Avisek Gupta,Swagatam Das,Md Sahidullah*

Main category: eess.AS

TL;DR: 该论文提出了一种完全无监督的说话人日志方法，通过测量说话人嵌入的多核相似性构建稀疏图，然后进行谱聚类，在多个数据集上取得了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 说话人日志旨在将音频分割为不同说话人的区域。虽然无监督说话人日志具有挑战性，但无需预训练或弱监督就能识别说话人区域的前景，推动了聚类技术的研究。

Method: 提出测量说话人嵌入的多核相似性（包括四个多项式核和一个一级反余弦核），以原则性方式构建稀疏图来强调局部相似性，然后进行谱聚类。

Result: 该方法在DIHARD-III、AMI和VoxConverse等多个具有挑战性的数据集上，在完全无监督设置下取得了最先进的说话人日志性能。

Conclusion: 通过多核相似性测量构建稀疏图并进行谱聚类的方法，能够在完全无监督设置下实现优秀的说话人日志性能，为未来研究提供了有前景的方向。

Abstract: Speaker diarization aims to segment audio recordings into regions corresponding to individual speakers. Although unsupervised speaker diarization is inherently challenging, the prospect of identifying speaker regions without pretraining or weak supervision motivates research on clustering techniques. In this work, we share the notable observation that measuring multiple kernel similarities of speaker embeddings to thereafter craft a sparse graph for spectral clustering in a principled manner is sufficient to achieve state-of-the-art performances in a fully unsupervised setting. Specifically, we consider four polynomial kernels and a degree one arccosine kernel to measure similarities in speaker embeddings, using which sparse graphs are constructed in a principled manner to emphasize local similarities. Experiments show the proposed approach excels in unsupervised speaker diarization over a variety of challenging environments in the DIHARD-III, AMI, and VoxConverse corpora. To encourage further research, our implementations are available at https://github.com/nikhilraghav29/MK-SGC-SC.

</details>


### [17] [RIR-Mega-Speech: A Reverberant Speech Corpus with Comprehensive Acoustic Metadata and Reproducible Evaluation](https://arxiv.org/abs/2601.19949)
*Mandip Goswami*

Main category: eess.AS

TL;DR: RIR-Mega-Speech是一个包含约117.5小时语音的语料库，通过将LibriSpeech与模拟房间脉冲响应卷积创建，提供RT60、DRR和C50等声学标注，旨在为混响语音研究提供标准化可复现的资源。


<details>
  <summary>Details</summary>
Motivation: 现有混响语音语料库大多缺乏每个文件的声学标注或文档不完整，导致方法比较困难且难以复现。需要提供具有透明声学条件和可验证结果的标准化资源。

Method: 将LibriSpeech语音与RIR-Mega集合中约5,000个模拟房间脉冲响应卷积，创建约117.5小时语料库。每个文件包含从源RIR计算的RT60、DRR和C50指标。提供重建数据集和复现评估结果的脚本。

Result: 使用Whisper small在1,500对语音上测试：干净语音WER为5.20%，混响版本为7.70%，相对增加48%。WER随RT60增加而单调增加，随DRR增加而减少，与先前感知研究一致。

Conclusion: 虽然混响损害语音识别已是已知事实，但本文旨在为社区提供声学条件透明、结果可独立验证的标准化资源。包含Windows和Linux环境的一键重建指令，促进可复现研究。

Abstract: Despite decades of research on reverberant speech, comparing methods remains difficult because most corpora lack per-file acoustic annotations or provide limited documentation for reproduction. We present RIR-Mega-Speech, a corpus of approximately 117.5 hours created by convolving LibriSpeech utterances with roughly 5,000 simulated room impulse responses from the RIR-Mega collection. Every file includes RT60, direct-to-reverberant ratio (DRR), and clarity index ($C_{50}$) computed from the source RIR using clearly defined, reproducible procedures. We also provide scripts to rebuild the dataset and reproduce all evaluation results.
  Using Whisper small on 1,500 paired utterances, we measure 5.20% WER (95% CI: 4.69--5.78) on clean speech and 7.70% (7.04--8.35) on reverberant versions, corresponding to a paired increase of 2.50 percentage points (2.06--2.98). This represents a 48% relative degradation. WER increases monotonically with RT60 and decreases with DRR, consistent with prior perceptual studies. While the core finding that reverberation harms recognition is well established, we aim to provide the community with a standardized resource where acoustic conditions are transparent and results can be verified independently. The repository includes one-command rebuild instructions for both Windows and Linux environments.

</details>


### [18] [VoxPrivacy: A Benchmark for Evaluating Interactional Privacy of Speech Language Models](https://arxiv.org/abs/2601.19956)
*Yuxiang Wang,Hongyu Liu,Dekun Chen,Xueyao Zhang,Zhizheng Wu*

Main category: eess.AS

TL;DR: 提出了VoxPrivacy基准测试，用于评估语音语言模型在多用户环境中的交互隐私保护能力，发现现有模型在条件隐私决策上表现不佳，并通过微调展示了改进路径。


<details>
  <summary>Details</summary>
Motivation: 随着语音语言模型从个人设备扩展到多用户共享环境（如智能家居），模型需要区分不同用户以适当管理信息流。现有基准测试存在三个不足：1）对话能力测试忽略说话者身份；2）多说话者基准只关注谁说了什么而不评估模型是否调整响应；3）隐私基准关注全局敏感数据而忽略上下文隐私敏感信息。这导致交互隐私风险，如可能泄露用户的机密日程给他人。

Method: 提出了VoxPrivacy基准测试，包含三个难度递增的层级：从遵循直接保密指令到主动保护隐私。在32小时的双语数据集上评估了9个语音语言模型，并在Real-VoxPrivacy（人工录制子集）上验证结果。通过在新的4,000小时训练集上进行微调，展示了改进隐私保护能力的可行路径。

Result: 评估显示普遍存在的脆弱性：大多数开源模型在条件隐私决策上表现接近随机机会（约50%准确率），即使是强大的闭源系统在主动隐私推理上也表现不足。在Real-VoxPrivacy上的验证确认了合成数据中观察到的失败在真实语音中持续存在。微调实验表明可以显著提升隐私保护能力同时保持鲁棒性。

Conclusion: VoxPrivacy是首个评估语音语言模型交互隐私的基准测试，揭示了现有模型在隐私保护方面的严重不足。通过大规模训练集微调可以显著改进模型性能。作者发布了VoxPrivacy基准测试、大规模训练集和微调模型，以促进更安全、更具上下文感知能力的语音语言模型发展。

Abstract: As Speech Language Models (SLMs) transition from personal devices to shared, multi-user environments such as smart homes, a new challenge emerges: the model is expected to distinguish between users to manage information flow appropriately. Without this capability, an SLM could reveal one user's confidential schedule to another, a privacy failure we term interactional privacy. Thus, the ability to generate speaker-aware responses becomes essential for SLM safe deployment. Current SLM benchmarks test dialogue ability but overlook speaker identity. Multi-speaker benchmarks check who said what without assessing whether SLMs adapt their responses. Privacy benchmarks focus on globally sensitive data (e.g., bank passwords) while neglecting contextual privacy-sensitive information (e.g., a user's private appointment). To address this gap, we introduce VoxPrivacy, the first benchmark designed to evaluate interactional privacy in SLMs. VoxPrivacy spans three tiers of increasing difficulty, from following direct secrecy commands to proactively protecting privacy. Our evaluation of nine SLMs on a 32-hour bilingual dataset reveals a widespread vulnerability: most open-source models perform close to random chance (around 50% accuracy) on conditional privacy decisions, while even strong closed-source systems fall short on proactive privacy inference. We further validate these findings on Real-VoxPrivacy, a human-recorded subset, confirming that failures observed on synthetic data persist in real speech. Finally, we demonstrate a viable path forward: by fine-tuning on a new 4,000-hour training set, we improve privacy-preserving abilities while maintaining robustness. To support future work, we release the VoxPrivacy benchmark, the large-scale training set, and the fine-tuned model to foster the development of safer and more context-aware SLMs.

</details>


### [19] [Do we really need Self-Attention for Streaming Automatic Speech Recognition?](https://arxiv.org/abs/2601.19960)
*Youness Dkhissi,Valentin Vielzeuf,Elys Allesiardo,Anthony Larcher*

Main category: eess.AS

TL;DR: 该论文质疑Transformer在受限任务中的适用性，特别是在流式语音识别场景下，提出使用可变形卷积替代自注意力机制，甚至完全移除自注意力而不显著影响性能。


<details>
  <summary>Details</summary>
Motivation: Transformer架构在深度学习领域广泛应用，但人们可能不加思考地将其直接应用于受限任务。作者质疑Transformer在特定领域（特别是流式应用）的适用性，认为其高计算需求和延迟问题与流式应用的需求不匹配。

Method: 作为初步尝试，研究展示了在流式自动语音识别中，可以使用可变形卷积替代自注意力机制来降低计算成本。更进一步，研究表明自注意力机制可以被完全移除且无需替代，而不会显著影响词错误率。

Result: 研究结果表明，在流式语音识别任务中，自注意力机制可以被可变形卷积替代，甚至完全移除，而不会导致词错误率显著下降，从而显著降低了计算成本。

Conclusion: Transformer架构在受限环境（如流式应用）中可能不是最佳选择，需要寻找替代策略在保持性能的同时提高效率。自注意力机制在流式语音识别中并非必需，可被更轻量的方法替代。

Abstract: Transformer-based architectures are the most used architectures in many deep learning fields like Natural Language Processing, Computer Vision or Speech processing. It may encourage the direct use of Transformers in the constrained tasks, without questioning whether it will yield the same benefits as in standard tasks.  Given specific constraints, it is essential to evaluate the relevance of transformer models. This work questions the suitability of transformers for specific domains. We argue that the high computational requirements and latency issues associated with these models do not align well with streaming applications. Our study promotes the search for alternative strategies to improve efficiency without sacrificing performance.  In light of this observation, our paper critically examines the usefulness of transformer architecture in such constrained environments. As a first attempt, we show that the computational cost for Streaming Automatic Speech Recognition (ASR) can be reduced using deformable convolution instead of Self-Attention. Furthermore, we show that Self-Attention mechanisms can be entirely removed and not replaced, without observing significant degradation in the Word Error Rate.

</details>


### [20] [T-Mimi: A Transformer-based Mimi Decoder for Real-Time On-Phone TTS](https://arxiv.org/abs/2601.20094)
*Haibin Wu,Bach Viet Do,Naveen Suda,Julian Chan,Madhavan C R,Gene-Ping Yang,Yi-Chiao Wu,Naoyuki Kanda,Yossef Adi,Xin Lei,Yue Liu,Florian Metze,Yuzong Liu*

Main category: eess.AS

TL;DR: T-Mimi：将Mimi音频编解码器的卷积解码器替换为纯Transformer架构，显著降低边缘设备TTS延迟（从42.1ms降至4.4ms），并通过量化感知训练发现靠近波形的最后两层Transformer和线性层需保持全精度以维持音质。


<details>
  <summary>Details</summary>
Motivation: Mimi编解码器的混合Transformer-卷积解码器架构在边缘设备上存在显著延迟瓶颈，主要由于反卷积层计算密集且不适用于移动CPU（如XNNPACK框架），需要更高效的解码器设计。

Method: 提出T-Mimi，基于TS3-Codec架构将Mimi的卷积组件替换为纯Transformer解码器，并进行量化感知训练，分析不同层对量化的敏感性。

Result: T-Mimi将设备端TTS延迟从42.1ms大幅降低至4.4ms，同时通过量化感知训练发现：解码器最后两层Transformer和结尾线性层对量化高度敏感，需保持全精度以维持音频质量。

Conclusion: 纯Transformer解码器架构能显著降低边缘设备TTS延迟，同时量化策略需特别关注靠近波形的层，为实时语音合成系统提供了高效且质量可控的解决方案。

Abstract: Neural audio codecs provide promising acoustic features for speech synthesis, with representative streaming codecs like Mimi providing high-quality acoustic features for real-time Text-to-Speech (TTS) applications. However, Mimi's decoder, which employs a hybrid transformer and convolution architecture, introduces significant latency bottlenecks on edge devices due to the the compute intensive nature of deconvolution layers which are not friendly for mobile-CPUs, such as the most representative framework XNNPACK. This paper introduces T-Mimi, a novel modification of the Mimi codec decoder that replaces its convolutional components with a purely transformer-based decoder, inspired by the TS3-Codec architecture. This change dramatically reduces on-device TTS latency from 42.1ms to just 4.4ms. Furthermore, we conduct quantization aware training and derive a crucial finding: the final two transformer layers and the concluding linear layers of the decoder, which are close to the waveform, are highly sensitive to quantization and must be preserved at full precision to maintain audio quality.

</details>


### [21] [ASR for Affective Speech: Investigating Impact of Emotion and Speech Generative Strategy](https://arxiv.org/abs/2601.20319)
*Ya-Tse Wu,Chi-Chun Lee*

Main category: eess.AS

TL;DR: 研究情感语音和生成策略对ASR性能的影响，提出基于转录正确性和情感显著性的生成策略，在情感数据集上取得WER改进


<details>
  <summary>Details</summary>
Motivation: 研究情感语音和生成策略如何影响自动语音识别(ASR)性能，探索如何构建情感感知的ASR系统

Method: 分析三种情感TTS模型的合成语音，发现替换错误占主导；提出两种生成策略：基于转录正确性和基于情感显著性，构建微调子集

Result: 在真实情感数据集上实现一致的WER改进，在干净的LibriSpeech语料上没有明显性能下降；组合策略获得最强增益，特别是对表达性语音

Conclusion: 有针对性的数据增强对于构建情感感知ASR系统至关重要，生成策略能有效提升情感语音识别性能

Abstract: This work investigates how emotional speech and generative strategies affect ASR performance. We analyze speech synthesized from three emotional TTS models and find that substitution errors dominate, with emotional expressiveness varying across models. Based on these insights, we introduce two generative strategies: one using transcription correctness and another using emotional salience, to construct fine-tuning subsets. Results show consistent WER improvements on real emotional datasets without noticeable degradation on clean LibriSpeech utterances. The combined strategy achieves the strongest gains, particularly for expressive speech. These findings highlight the importance of targeted augmentation for building emotion-aware ASR systems.

</details>


### [22] [Erasing Your Voice Before It's Heard: Training-free Speaker Unlearning for Zero-shot Text-to-Speech](https://arxiv.org/abs/2601.20481)
*Myungjin Lee,Eunji Shin,Jiyoung Lee*

Main category: eess.AS

TL;DR: TruS是一个无需训练的说话人遗忘框架，通过推理时控制来防止特定说话人声音的生成，解决了现有方法需要重新训练且只能处理训练集中说话人的限制。


<details>
  <summary>Details</summary>
Motivation: 现代零样本文本转语音模型虽然表达能力强，但存在犯罪风险，可能未经同意合成他人声音。现有说话人遗忘方法依赖重新训练，成本高且只能处理训练集中见过的说话人。

Method: TruS采用训练免费的说话人遗忘框架，将范式从数据删除转向推理时控制。通过引导身份特定的隐藏激活来抑制目标说话人，同时保留其他属性（如韵律和情感）。

Result: 实验结果显示，TruS能有效防止已见和未见选择退出说话人的声音生成，为语音合成建立了可扩展的安全保障。

Conclusion: TruS提供了一个无需训练、可扩展的说话人遗忘解决方案，通过推理时控制有效防止特定说话人声音生成，同时保持其他语音属性。

Abstract: Modern zero-shot text-to-speech (TTS) models offer unprecedented expressivity but also pose serious crime risks, as they can synthesize voices of individuals who never consented. In this context, speaker unlearning aims to prevent the generation of specific speaker identities upon request. Existing approaches, reliant on retraining, are costly and limited to speakers seen in the training set. We present TruS, a training-free speaker unlearning framework that shifts the paradigm from data deletion to inference-time control. TruS steers identity-specific hidden activations to suppress target speakers while preserving other attributes (e.g., prosody and emotion). Experimental results show that TruS effectively prevents voice generation on both seen and unseen opt-out speakers, establishing a scalable safeguard for speech synthesis. The demo and code are available on http://mmai.ewha.ac.kr/trus.

</details>


### [23] [Decoding Speech Envelopes from Electroencephalogram with a Contrastive Pearson Correlation Coefficient Loss](https://arxiv.org/abs/2601.20542)
*Yayun Liang,Yuanming Zhang,Fei Chen,Jing Lu,Zhibin Lin*

Main category: eess.AS

TL;DR: 提出对比性PCC损失函数，通过最大化注意PCC与非注意PCC之间的差异来改进基于EEG的听觉注意解码


<details>
  <summary>Details</summary>
Motivation: 现有基于深度神经网络的语音包络重建模型主要关注最大化注意包络与重建包络之间的皮尔逊相关系数（注意PCC），但听觉注意解码的关键在于注意PCC与非注意PCC之间的差异，现有方法对此关注不足

Method: 提出对比性PCC损失函数，该损失函数直接表示注意PCC与非注意PCC之间的差异，并在三个公开EEG听觉注意解码数据集上使用四种DNN架构进行评估

Result: 在多种设置下，提出的目标函数改善了包络可分离性和听觉注意解码准确率，同时也揭示了数据集和架构相关的失败案例

Conclusion: 对比性PCC损失函数能有效提升基于EEG的听觉注意解码性能，但需要考虑数据集和模型架构的依赖性

Abstract: Recent advances in reconstructing speech envelopes from Electroencephalogram (EEG) signals have enabled continuous auditory attention decoding (AAD) in multi-speaker environments. Most Deep Neural Network (DNN)-based envelope reconstruction models are trained to maximize the Pearson correlation coefficients (PCC) between the attended envelope and the reconstructed envelope (attended PCC). While the difference between the attended PCC and the unattended PCC plays an essential role in auditory attention decoding, existing methods often focus on maximizing the attended PCC. We therefore propose a contrastive PCC loss which represents the difference between the attended PCC and the unattended PCC. The proposed approach is evaluated on three public EEG AAD datasets using four DNN architectures. Across many settings, the proposed objective improves envelope separability and AAD accuracy, while also revealing dataset- and architecture-dependent failure cases.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [24] [Pianoroll-Event: A Novel Score Representation for Symbolic Music](https://arxiv.org/abs/2601.19951)
*Lekai Qian,Haoyu Gu,Dehan Li,Boyu Cao,Qi Liu*

Main category: cs.SD

TL;DR: 提出Pianoroll-Event编码方案，结合网格表示和离散事件表示的优点，通过四种事件类型提高符号音乐表示的编码效率和结构保持能力。


<details>
  <summary>Details</summary>
Motivation: 现有符号音乐表示方法各有局限：网格表示（如pianoroll）能保持音高-时间空间对应关系，但数据稀疏导致编码效率低；离散事件表示编码紧凑，但无法充分捕捉结构不变性和空间局部性。需要结合两者优点的解决方案。

Method: 提出Pianoroll-Event编码方案，将pianoroll表示通过事件描述，包含四种互补事件类型：1) Frame Events用于时间边界，2) Gap Events用于稀疏区域，3) Pattern Events用于音符模式，4) Musical Structure Events用于音乐元数据。该方案在序列长度和词汇量之间取得平衡。

Result: 编码效率比代表性离散序列方法提高1.36倍到7.16倍。在多种自回归架构上的实验表明，使用该表示的模型在定量评估和人工评估中均优于基线方法。

Conclusion: Pianoroll-Event编码方案有效结合了网格表示和离散事件表示的优点，在保持结构特性的同时显著提高了编码效率，为符号音乐表示提供了更优的解决方案。

Abstract: Symbolic music representation is a fundamental challenge in computational musicology. While grid-based representations effectively preserve pitch-time spatial correspondence, their inherent data sparsity leads to low encoding efficiency. Discrete-event representations achieve compact encoding but fail to adequately capture structural invariance and spatial locality. To address these complementary limitations, we propose Pianoroll-Event, a novel encoding scheme that describes pianoroll representations through events, combining structural properties with encoding efficiency while maintaining temporal dependencies and local spatial patterns. Specifically, we design four complementary event types: Frame Events for temporal boundaries, Gap Events for sparse regions, Pattern Events for note patterns, and Musical Structure Events for musical metadata. Pianoroll-Event strikes an effective balance between sequence length and vocabulary size, improving encoding efficiency by 1.36\times to 7.16\times over representative discrete sequence methods. Experiments across multiple autoregressive architectures show models using our representation consistently outperform baselines in both quantitative and human evaluations.

</details>


### [25] [LTS-VoiceAgent: A Listen-Think-Speak Framework for Efficient Streaming Voice Interaction via Semantic Triggering and Incremental Reasoning](https://arxiv.org/abs/2601.19952)
*Wenhao Zou,Yuwei Miao,Zhanyu Ma,Jun Xu,Jiuchong Gao,Jinghua Hao,Renqing He,Jingwen Xu*

Main category: cs.SD

TL;DR: LTS-VoiceAgent是一个Listen-Think-Speak框架，通过动态语义触发器和双角色流协调器实现"边听边思考"，在保持级联架构优势的同时显著降低延迟。


<details>
  <summary>Details</summary>
Motivation: 实时语音代理面临困境：端到端模型缺乏深度推理能力，而级联流水线（ASR→LLM→TTS顺序执行）延迟高，无法像人类对话那样在说话者结束前就开始思考。现有流式策略要么破坏语义单元，要么浪费计算资源。

Method: 提出LTS-VoiceAgent框架，明确分离"何时思考"和"如何增量推理"。包含动态语义触发器检测有意义的语音前缀，双角色流协调器协调后台思考者（状态维护）和前台说话者（推测性求解），实现"边说话边思考"的并行设计。

Result: 在VERA、Spoken-MQA、BigBenchAudio和自建的Pause-and-Repair基准测试中，LTS-VoiceAgent相比串行级联基线和现有流式策略，在准确性-延迟-效率权衡方面表现更优。

Conclusion: LTS-VoiceAgent通过创新的并行架构设计，解决了级联语音代理的延迟问题，实现了更接近人类对话模式的实时交互，为复杂任务提供了更好的解决方案。

Abstract: Real-time voice agents face a dilemma: end-to-end models often lack deep reasoning, while cascaded pipelines incur high latency by executing ASR, LLM reasoning, and TTS strictly in sequence, unlike human conversation where listeners often start thinking before the speaker finishes. Since cascaded architectures remain the dominant choice for complex tasks, existing cascaded streaming strategies attempt to reduce this latency via mechanical segmentation (e.g., fixed chunks, VAD-based splitting) or speculative generation, but they frequently either break semantic units or waste computation on predictions that must be rolled back. To address these challenges, we propose LTS-VoiceAgent, a Listen-Think-Speak framework that explicitly separates when to think from how to reason incrementally. It features a Dynamic Semantic Trigger to detect meaningful prefixes, and a Dual-Role Stream Orchestrator that coordinates a background Thinker (for state maintenance) and a foreground Speaker (for speculative solving). This parallel design enables "thinking while speaking" without blocking responses. We also introduce a Pause-and-Repair benchmark containing natural disfluencies to stress-test streaming robustness. Experiments across VERA, Spoken-MQA, BigBenchAudio, and our benchmark show that LTS-VoiceAgent achieves a stronger accuracy-latency-efficiency trade-off than serial cascaded baselines and existing streaming strategies.

</details>


### [26] [Switchcodec: Adaptive residual-expert sparse quantization for high-fidelity neural audio coding](https://arxiv.org/abs/2601.20362)
*Xiangbo Wang,Wenbin Jiang,Jin Wang,Yubo You,Sheng Fang,Fei Wen*

Main category: cs.SD

TL;DR: SwitchCodec是一种基于残差专家向量量化(REVQ)的神经音频编解码器，通过动态路由专家量化器来适应不同音频内容的复杂度，实现了可变比特率操作而无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 当前神经音频压缩模型通常使用固定数量的每帧码本，这对于音频内容的广泛可变性（特别是对于非常简单或高度复杂的信号）是次优的。需要一种能够根据输入音频动态调整量化资源的方法。

Method: 提出了基于残差专家向量量化(REVQ)的SwitchCodec，结合共享量化器和动态路由的专家量化器，根据输入音频激活不同的专家量化器，将比特率与码本容量解耦。还包含可变比特率机制，在推理时调整活跃专家量化器的数量。

Result: 实验表明，SwitchCodec在客观指标和主观听力测试上都超越了现有基线方法。

Conclusion: SwitchCodec通过REVQ架构有效解决了固定码本数量在音频压缩中的局限性，实现了更高效的压缩和可变比特率操作，在音频质量方面表现优异。

Abstract: Recent neural audio compression models often rely on residual vector quantization for high-fidelity coding, but using a fixed number of per-frame codebooks is suboptimal for the wide variability of audio content-especially for signals that are either very simple or highly complex. To address this limitation, we propose SwitchCodec, a neural audio codec based on Residual Experts Vector Quantization (REVQ). REVQ combines a shared quantizer with dynamically routed expert quantizers that are activated according to the input audio, decoupling bitrate from codebook capacity and improving compression efficiency. This design ensures full training and utilization of each quantizer. In addition, a variable-bitrate mechanism adjusts the number of active expert quantizers at inference, enabling multi-bitrate operation without retraining. Experiments demonstrate that SwitchCodec surpasses existing baselines on both objective metrics and subjective listening tests.

</details>


### [27] [Mix2Morph: Learning Sound Morphing from Noisy Mixes](https://arxiv.org/abs/2601.20426)
*Annie Chu,Hugo Flores García,Oriol Nieto,Justin Salamon,Bryan Pardo,Prem Seetharaman*

Main category: cs.SD

TL;DR: Mix2Morph是一个文本到音频的扩散模型，通过微调实现声音变形，无需专门的变形数据集，专注于声音注入这一特定变形子类。


<details>
  <summary>Details</summary>
Motivation: 开发一种无需专门变形数据集的声音变形方法，特别关注声音注入这一实用且有感知意义的变形子类，其中主声音提供整体结构和时间行为，次声音注入以丰富音色和纹理品质。

Method: 在较高扩散时间步上对噪声替代混合进行微调，使文本到音频扩散模型能够执行声音变形，专注于声音注入这一特定变形类型。

Result: Mix2Morph产生稳定、感知一致的声音变形，令人信服地整合了两个声源的特性，在客观评估和听力测试中优于现有基线，能够跨不同类别生成高质量的声音注入。

Conclusion: Mix2Morph代表了向更可控、概念驱动的声音设计工具迈出的一步，通过扩散模型微调实现了无需专门数据集的高质量声音变形。

Abstract: We introduce Mix2Morph, a text-to-audio diffusion model fine-tuned to perform sound morphing without a dedicated dataset of morphs. By finetuning on noisy surrogate mixes at higher diffusion timesteps, Mix2Morph yields stable, perceptually coherent morphs that convincingly integrate qualities of both sources. We specifically target sound infusions, a practically and perceptually motivated subclass of morphing in which one sound acts as the dominant primary source, providing overall temporal and structural behavior, while a secondary sound is infused throughout, enriching its timbral and textural qualities. Objective evaluations and listening tests show that Mix2Morph outperforms prior baselines and produces high-quality sound infusions across diverse categories, representing a step toward more controllable and concept-driven tools for sound design. Sound examples are available at https://anniejchu.github.io/mix2morph .

</details>


### [28] [Self Voice Conversion as an Attack against Neural Audio Watermarking](https://arxiv.org/abs/2601.20432)
*Yigitcan Özer,Wanying Ge,Zhe Zhang,Xin Wang,Junichi Yamagishi*

Main category: cs.SD

TL;DR: 论文研究自语音转换作为音频水印系统的通用攻击方法，发现这种攻击会严重降低现有先进水印技术的可靠性。


<details>
  <summary>Details</summary>
Motivation: 虽然神经和数字信号处理水印方法在不可感知性和嵌入容量方面有进步，但现有鲁棒性评估主要针对传统失真（压缩、噪声、重采样），而深度学习攻击带来了新的安全威胁。

Method: 研究自语音转换作为攻击方法，通过语音转换模型将说话者声音重映射到同一身份但改变声学特性，从而攻击音频水印系统。

Result: 自语音转换攻击严重降低了最先进水印方法的可靠性，突显了现代音频水印技术面临的安全隐患。

Conclusion: 深度学习攻击（特别是自语音转换）对音频水印安全构成重大威胁，需要重新评估水印系统的鲁棒性标准。

Abstract: Audio watermarking embeds auxiliary information into speech while maintaining speaker identity, linguistic content, and perceptual quality. Although recent advances in neural and digital signal processing-based watermarking methods have improved imperceptibility and embedding capacity, robustness is still primarily assessed against conventional distortions such as compression, additive noise, and resampling. However, the rise of deep learning-based attacks introduces novel and significant threats to watermark security. In this work, we investigate self voice conversion as a universal, content-preserving attack against audio watermarking systems. Self voice conversion remaps a speaker's voice to the same identity while altering acoustic characteristics through a voice conversion model. We demonstrate that this attack severely degrades the reliability of state-of-the-art watermarking approaches and highlight its implications for the security of modern audio watermarking techniques.

</details>


### [29] [On Every Note a Griff: Looking for a Useful Representation of Basso Continuo Performance Style](https://arxiv.org/abs/2601.20478)
*Adam Štefunko,Carlos Eduardo Cancino-Chacón,Jan Hajič*

Main category: cs.SD

TL;DR: 提出griff表示法，用於編碼巴洛克數字低音即興演奏的音高內容和結構，並在ACoRD數據集上進行個體演奏風格分析。


<details>
  <summary>Details</summary>
Motivation: 數字低音是巴洛克時期的一種即興伴奏實踐，至今仍為活躍的演奏傳統。需要一種適當的特徵表示法來分析對齊的數字低音演奏，以研究不同演奏者的個人風格。

Method: 提出griff表示法，受歷史數字低音論著啟發，將對齊到同一樂譜音符的演奏音符分組，以音高不變的方式編碼即興演奏的音高內容和結構。

Result: 從ACoRD數據集的175個MIDI錄音中提取griff特徵，進行統計描述，並通過兩個實驗展示griff如何用於分析不同演奏者的個體演奏風格。

Conclusion: griff能夠保留數字低音即興演奏的結構，為分析個人演奏風格提供有意義的歷史啟發特徵空間，值得更穩健的實證驗證。

Abstract: Basso continuo is a baroque improvisatory accompaniment style which involves improvising multiple parts above a given bass line in a musical score on a harpsichord or organ. Basso continuo is not merely a matter of history; moreover, it is a historically inspired living practice, and The Aligned Continuo Dataset (ACoRD) records the first sample of modern-day basso continuo playing in the symbolic domain. This dataset, containing 175 MIDI recordings of 5 basso continuo scores performed by 7 players, allows us to start observing and analyzing the variety that basso continuo improvisation brings. A recently proposed basso continuo performance-to-score alignment system provides a way of mapping improvised performance notes to score notes. In order to study aligned basso continuo performances, we need an appropriate feature representation. We propose griff, a representation inspired by historical basso continuo treatises. It enables us to encode both pitch content and structure of a basso continuo realization in a transposition-invariant way. Griffs are directly extracted from aligned basso continuo performances by grouping together performance notes aligned to the same score note in a onset-time ordered way, and they provide meaningful tokens that form a feature space in which we can analyze basso continuo performance styles. We statistically describe griffs extracted from the ACoRD dataset recordings, and show in two experiments how griffs can be used for statistical analysis of individuality of different players' basso continuo performance styles. We finally present an argument why it is desirable to preserve the structure of a basso continuo improvisation in order to conduct a refined analysis of personal performance styles of individual basso continuo practitioners, and why griffs can provide a meaningful historically informed feature space worthy of a more robust empirical validation.

</details>


### [30] [Audio Deepfake Detection in the Age of Advanced Text-to-Speech models](https://arxiv.org/abs/2601.20510)
*Robin Singh,Aditya Yogesh Nair,Fabio Palumbo,Florian Barbaro,Anna Dyka,Lohith Rachakonda*

Main category: cs.SD

TL;DR: 该研究比较了三种先进TTS模型（Dia2、Maya1、MeloTTS）生成的音频深度伪造检测效果，发现单一检测方法存在局限性，而多视角检测方法在所有模型上都表现稳健。


<details>
  <summary>Details</summary>
Motivation: 随着TTS系统生成的合成语音越来越逼真，音频深度伪造检测面临新挑战。需要评估不同TTS架构对现有检测方法的影响，并探索更有效的检测策略。

Method: 使用Daily-Dialog数据集生成12,000个合成音频样本，涵盖三种TTS模型（流式、LLM基、非自回归架构）。评估四种检测框架，包括语义、结构和信号级方法，并测试多视角检测方法。

Result: 检测器性能在不同生成机制间存在显著差异：对某些TTS架构有效的模型可能对其他架构失效，特别是对LLM基合成。多视角检测方法结合互补分析层次，在所有评估模型上都表现出稳健性能。

Conclusion: 单一范式检测器存在局限性，需要集成检测策略来应对不断演变的音频深度伪造威胁。多视角检测方法为解决这一挑战提供了有效途径。

Abstract: Recent advances in Text-to-Speech (TTS) systems have substantially increased the realism of synthetic speech, raising new challenges for audio deepfake detection. This work presents a comparative evaluation of three state-of-the-art TTS models--Dia2, Maya1, and MeloTTS--representing streaming, LLM-based, and non-autoregressive architectures. A corpus of 12,000 synthetic audio samples was generated using the Daily-Dialog dataset and evaluated against four detection frameworks, including semantic, structural, and signal-level approaches. The results reveal significant variability in detector performance across generative mechanisms: models effective against one TTS architecture may fail against others, particularly LLM-based synthesis. In contrast, a multi-view detection approach combining complementary analysis levels demonstrates robust performance across all evaluated models. These findings highlight the limitations of single-paradigm detectors and emphasize the necessity of integrated detection strategies to address the evolving landscape of audio deepfake threats.

</details>


### [31] [Gen-SER: When the generative model meets speech emotion recognition](https://arxiv.org/abs/2601.20573)
*Taihui Wang,Jinzheng Zhao,Rilin Chen,Tong Lei,Wenwu Wang,Dong Yu*

Main category: cs.SD

TL;DR: Gen-SER将语音情感识别重构为生成模型中的分布偏移问题，通过将离散标签投影到连续空间，使用正弦分类编码获取终端分布，再通过目标匹配生成模型进行转换，最后通过相似度计算实现分类。


<details>
  <summary>Details</summary>
Motivation: 现有语音情感识别方法主要基于分类模型或大语言模型，本文提出一种新的生成式方法，将SER重新定义为分布偏移问题，旨在提高方法的可扩展性和泛化能力。

Method: 1) 将离散类别标签投影到连续空间；2) 通过正弦分类编码获得终端分布；3) 采用目标匹配生成模型将初始分布高效转换为终端分布；4) 通过计算生成终端分布与真实终端分布的相似度实现分类。

Result: 实验结果表明该方法有效，证明了其在各种语音理解任务中的可扩展性，并显示出在更广泛分类任务中的潜在适用性。

Conclusion: Gen-SER为语音情感识别提供了一种新颖的生成式方法，通过将分类问题重构为分布偏移问题，展示了在语音理解和更广泛分类任务中的良好应用前景。

Abstract: Speech emotion recognition (SER) is crucial in speech understanding and generation. Most approaches are based on either classification models or large language models. Different from previous methods, we propose Gen-SER, a novel approach that reformulates SER as a distribution shift problem via generative models. We propose to project discrete class labels into a continuous space, and obtain the terminal distribution via sinusoidal taxonomy encoding. The target-matching-based generative model is adopted to transform the initial distribution into the terminal distribution efficiently. The classification is achieved by calculating the similarity of the generated terminal distribution and ground truth terminal distribution. The experimental results confirm the efficacy of the proposed method, demonstrating its extensibility to various speech-understanding tasks and suggesting its potential applicability to a broader range of classification tasks.

</details>

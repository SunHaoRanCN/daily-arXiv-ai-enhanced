<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [eess.AS](#eess.AS) [Total: 9]
- [cs.SD](#cs.SD) [Total: 10]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Sparse Grassmannian Design for Noncoherent Codes via Schubert Cell Decomposition](https://arxiv.org/abs/2601.21009)
*Joe Asano,Yuto Hama,Hiroki Iimori,Chandan Pradhan,Szabolcs Malomsoky,Naoki Ishikawa*

Main category: eess.SP

TL;DR: 提出一种用于非相干MIMO系统的稀疏Grassmannian码设计方法，通过修正传统成对错误概率公式处理稀疏配置引起的秩缺陷问题，并推导出最大化非相干平均互信息的闭式度量。


<details>
  <summary>Details</summary>
Motivation: 传统方法在非相关瑞利衰落信道下的成对错误概率公式无法处理稀疏配置引起的秩缺陷问题，需要统一处理这些情况。同时需要设计能有效最大化非相干平均互信息的稀疏码。

Method: 修正传统成对错误概率公式以统一处理稀疏配置；推导最大化非相干平均互信息的闭式度量；利用Grassmann流形的Schubert胞分解提供的数学稀疏特性，建立稀疏非相干码的设计准则。

Result: 提出的稀疏非相干码在符号错误率和平均互信息方面均优于传统方法，在高信噪比下渐近接近最优Grassmannian星座性能，同时降低了时间和空间复杂度（不随发射天线数量增加而增加）。

Conclusion: 该方法成功解决了稀疏配置下的秩缺陷问题，设计的稀疏Grassmannian码在性能和复杂度方面均有显著优势，为实际MIMO系统提供了有效的非相干通信解决方案。

Abstract: In this paper, we propose a method for designing sparse Grassmannian codes for noncoherent multiple-input multiple-output systems. Conventional pairwise error probability formulations under uncorrelated Rayleigh fading channels fail to account for rank deficiency induced by sparse configurations. We revise these formulations to handle such cases in a unified manner. Furthermore, we derive a closed-form metric that effectively maximizes the noncoherent average mutual information (AMI) at a given signal-to-noise ratio. We focus on the fact that the Schubert cell decomposition of the Grassmann manifold provides a mathematically sparse property, and establish design criteria for sparse noncoherent codes based on our analyses. In numerical results, the proposed sparse noncoherent codes outperform conventional methods in terms of both symbol error rate and AMI, and asymptotically approach the performance of the optimal Grassmannian constellations in the high-signal-to-noise ratio regime. Moreover, they reduce the time and space complexity, which does not scale with the number of transmit antennas.

</details>


### [2] [Impact of Pointing Error on Coverage Performance of 3D Indoor Terahertz Communication Systems](https://arxiv.org/abs/2601.21303)
*Zhifeng Tang,Nan Yang,Xiangyun Zhou,Salman Durrani,Markku Juntti,Josep Miquel Jornet*

Main category: eess.SP

TL;DR: 本文开发了一个三维室内太赫兹通信系统的分析框架，评估指向误差对覆盖性能的影响，发现仅增加天线阵列尺寸不足以改善覆盖概率，需要先进的估计技术。


<details>
  <summary>Details</summary>
Motivation: 太赫兹通信系统中，由于波束成形增益和方向不匹配导致的指向误差会严重影响系统性能，需要建立理论框架来量化这种影响，为系统设计提供指导。

Method: 使用泊松点过程建模AP位置，随机圆柱过程建模人体遮挡，布尔直线过程建模墙壁遮挡。基于位置估计不准确性表征指向误差，采用多簇波动双射线分布建模小尺度衰落，推导覆盖概率的解析表达式。

Result: 分析表明指向误差对覆盖概率有显著影响，仅增加天线阵列尺寸不足以改善覆盖性能，需要通过先进的估计技术来缓解指向误差的负面影响。

Conclusion: 太赫兹通信系统中，指向误差是影响覆盖性能的关键因素，系统设计需要结合先进的估计技术而非单纯依赖天线阵列尺寸的增加。

Abstract: In this paper, we develop a tractable analytical framework for a three-dimensional (3D) indoor terahertz (THz) communication system to theoretically assess the impact of the pointing error on its coverage performance. Specifically, we model the locations of access points (APs) using a Poisson point process, human blockages as random cylinder processes, and wall blockages through a Boolean straight line process. A pointing error refers to beamforming gain and direction mismatch between the transmitter and receiver. We characterize it based on the inaccuracy of location estimate. We then analyze the impact of this pointing error on the received signal power and derive a tractable expression for the coverage probability, incorporating the multi-cluster fluctuating two-ray distribution to accurately model small-scale fading in THz communications. Aided by simulation results, we corroborate our analysis and demonstrate that the pointing error has a pronounced impact on the coverage probability. Specifically, we find that merely increasing the antenna array size is insufficient to improve the coverage probability and mitigate the detrimental impact of the pointing error, highlighting the necessity of advanced estimation techniques in THz communication systems.

</details>


### [3] [A Time-Domain Dual-Edge Asynchronous Pipelined SAR ADC Featuring Reset-Free Quantization at Multi-GS/s](https://arxiv.org/abs/2601.21308)
*Richard Zeng,Anthony Chan Carusone,Xilin Liu*

Main category: eess.SP

TL;DR: 提出双沿无复位量化概念，用于异步流水线SAR时域ADC，消除显式复位阶段，扩展有效转换窗口，在3.5 GS/s下实现8位精度。


<details>
  <summary>Details</summary>
Motivation: 传统时域ADC需要在样本间显式复位电压-时间和时域信号路径，这会引入死区时间，从根本上限制分辨率、速度和能效。需要消除复位阶段以改善高速性能。

Method: 提出双沿无复位量化概念，利用上升沿和下降沿信号在单个转换周期内实现无复位量化。采用线性补偿的双沿电压-时间转换器和具有独立可调上升/下降沿延迟的双沿时间-数字转换器。

Result: 在22-nm FD-SOI工艺中实现8位ADC，核心面积0.0089 mm²，连续单通道工作频率3.5 GS/s，间歇工作可达10.5 GS/s。在3.5 GS/s下实现21.6 dB SNDR和32.2 dB SFDR。

Conclusion: 双沿无复位量化概念可行，性能主要受限于实现层面的因素而非架构限制，展示了该技术对高速时域ADC的适用性。

Abstract: Time-domain ADCs are attractive for high-speed wireline receivers, as time resolution scales favorably with advanced CMOS technologies, enabling multi-GS/s single-channel sampling rates. However, conventional time-domain ADCs require explicit reset of voltage-to-time and time-domain signal paths between samples, introducing dead time that fundamentally limits resolution, speed, and energy efficiency. This paper introduces a dual-edge reset-free quantization concept for asynchronous pipelined SAR time-domain ADCs, in which both rising and falling signal edges are exploited to enable reset-free quantization within a single conversion period. By eliminating explicit reset phases, the proposed approach expands the effective conversion window and relaxes the resolution-speed tradeoff at high sampling rates. An 8-bit dual-edge asynchronous pipelined SAR time-domain ADC is implemented in 22-nm FD-SOI, incorporating a linearity-compensated dual-edge voltage-to-time converter and a dual-edge time-to-digital converter with independently tunable rising- and falling-edge delays. The prototype occupies a core area of 0.0089 mm^2 and achieves continuous single-channel operation at 3.5 GS/s, with architectural scalability demonstrated through intermittent operation at 10.5 GS/s and higher. At 3.5 GS/s, the ADC achieves 21.6 dB SNDR and 32.2 dB SFDR. The measured performance is primarily limited by identifiable implementation-level factors rather than by architectural constraints, demonstrating the feasibility of dual-edge reset-free quantization for high-speed time-domain ADCs.

</details>


### [4] [A Linearization of DFT Spectrum for Precision Power Measurement in Presence of Interharmonics](https://arxiv.org/abs/2601.21397)
*Jian Liu,Wei Zhao,Jianting Zhao,Shisong Li*

Main category: eess.SP

TL;DR: 提出基于DFT频谱分析的线性化算法，用于精确测量含间谐波电力系统中的功率，通过构建线性方程组解决异步采样导致的功率测量误差问题。


<details>
  <summary>Details</summary>
Motivation: 电力系统中间谐波的存在会导致异步采样，加上基频偏移，会显著降低功率测量精度。在异步条件下，间谐波与基波和谐波分量失去正交性，产生额外的功率分量，需要新的测量方法来解决这些问题。

Method: 基于DFT频谱分析的线性化算法，从DFT频谱构建线性方程组，通过高效的矩阵运算求解，能够准确提取基波和谐波频率附近（频率间隔≥1 Hz）的间谐波分量。

Result: 测试结果表明，该方法在不同条件下（包括变化的间谐波/基波/谐波间隔、基频偏差和噪声）都能准确计算各种功率分量。相比FFT、加窗插值FFT和矩阵铅笔-奇异值分解等方法，估计误差减少数倍到多倍，鲁棒性更好，处理10个工频周期（200 ms）数据的计算时间仅为7 ms。

Conclusion: 提出的线性化算法能够精确测量含间谐波电力系统中的功率，包括基波、谐波、间谐波和交叉功率带以及总功率，在精度、鲁棒性和计算效率方面优于现有方法。

Abstract: The presence of interharmonics in power systems can lead to asynchronous sampling, a phenomenon further aggravated by shifts in the fundamental frequency, which significantly degrades the accuracy of power measurements. Under such asynchronous conditions, interharmonics lose orthogonality with the fundamental and harmonic components, giving rise to additional power components. To address these challenges, this paper introduces a linearization algorithm based on DFT spectrum analysis for precise power measurement in systems containing interharmonics. The proposed approach constructs a system of linear equations from the DFT spectrum and solves it through efficient matrix operations, enabling accurate extraction of interharmonic components near the fundamental and harmonic frequencies (with a frequency interval $\geq$1 Hz). This allows for precise measurement of power across the fundamental, harmonic, interharmonic, and cross-power bands, as well as total power. Test results demonstrate that the proposed method accurately computes various power components under diverse conditions--including varying interharmonic/fundamental/harmonic intervals, fundamental frequency deviations, and noise. Compared to existing methods such as fast Fourier transform (FFT), Windowed interpolation FFT, and Matrix pencil-Singular value decomposition, the proposed technique reduces estimation error by several times to multiple folds and exhibits improved robustness, while maintaining a computational time of only 7 ms for processing 10-power-line-cycle (200 ms) data.

</details>


### [5] [Interference Detection and Exploitation for Multi-User Radar Sensing](https://arxiv.org/abs/2601.21429)
*Laurits Randers,Martin Voigt Vejling,Petar Popovski*

Main category: eess.SP

TL;DR: 提出一种用于频谱交织OFDM多用户ISAC系统的干扰检测与利用算法，通过统计控制方法检测干扰，并利用干扰估计角度、避开干扰估计时延


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中，多用户ISAC场景下同时传输会在重叠频段产生相互干扰，导致虚假目标检测和感知精度下降，需要有效处理干扰问题

Method: 提出基于频谱交织OFDM的干扰检测与利用算法：1）引入统计严格程序检测干扰并控制族错误率；2）利用干扰估计角度，避开干扰估计时延

Result: 数值实验表明，所提方法能可靠检测干扰，且时延和角度估计误差接近克拉美罗下界

Conclusion: 该算法能有效处理多用户ISAC系统中的干扰问题，通过统计控制检测干扰并巧妙利用干扰提升感知性能，为下一代无线网络提供实用解决方案

Abstract: Integrated sensing and communication is a key feature in next-generation wireless networks, enabling joint data transmission and environmental radar sensing on shared spectrum. In multi-user scenarios, simultaneous transmissions cause mutual interference on overlapping frequencies, leading to spurious target detections and degraded sensing accuracy. This paper proposes an interference detection and exploitation algorithm for sensing using spectrally interleaved orthogonal frequency division multiplexing. A statistically rigorous procedure is introduced to detect interference while controlling the familywise error rate. We propose an algorithm that estimates the angle by exploiting interference, while estimating the delay by avoiding the interference. Numerical experiments demonstrate that the proposed method reliably detects interference, and that the delay and angle estimation error approaches the Cramér-Rao lower bound.

</details>


### [6] [Compressed Sensing-Driven Near-Field Localization Exploiting Array of Subarrays](https://arxiv.org/abs/2601.21481)
*Sai Pavan Deram,Jacopo Pegoraro,Javier Lorca Hernando,Jesus O. Lacruz,Joerg Widmer*

Main category: eess.SP

TL;DR: SHARE是一种用于近场ISAC定位的两阶段稀疏恢复算法，通过分层处理解决稀疏子阵列架构中的栅瓣模糊问题，在保持大孔径高分辨率的同时降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 近场ISAC定位需要大孔径阵列，但全数字实现成本高、复杂度大。稀疏子阵列架构虽然能降低成本，但会引入严重的栅瓣模糊问题。

Method: SHARE采用两阶段方法：第一阶段使用单个子阵列进行粗略、无模糊的角度估计以解决栅瓣模糊；第二阶段利用整个稀疏孔径进行局部联合角度-距离搜索。

Result: SHARE显著优于传统的单次稀疏恢复方法（如OMP），在定位精度和鲁棒性方面都有提升。其总体定位精度与全数字2D-MUSIC算法相当甚至更好，尽管MUSIC使用了完整的未压缩数据。

Conclusion: SHARE为高分辨率近场ISAC系统提供了一条实用路径，能够在保持大孔径高分辨率的同时，通过稀疏架构降低成本和计算复杂度。

Abstract: Near-field localization for ISAC requires large-aperture arrays, making fully-digital implementations prohibitively complex and costly. While sparse subarray architectures can reduce cost, they introduce severe estimation ambiguity from grating lobes. To address both issues, we propose SHARE (Sparse Hierarchical Angle-Range Estimation), a novel two-stage sparse recovery algorithm. SHARE operates in two stages. It first performs coarse, unambiguous angle estimation using individual subarrays to resolve the grating lobe ambiguity. It then leverages the full sparse aperture to perform a localized joint angle-range search. This hierarchical approach avoids an exhaustive and computationally intensive two-dimensional grid search while preserving the high resolution of the large aperture. Simulation results show that SHARE significantly outperforms conventional one-shot sparse recovery methods, such as Orthogonal Matching Pursuit (OMP), in both localization accuracy and robustness. Furthermore, we show that SHARE's overall localization accuracy is comparable to or even surpasses that of the fully-digital 2D-MUSIC algorithm, despite MUSIC having access to the complete, uncompressed data from every antenna element. SHARE therefore provides a practical path for high-resolution near-field ISAC systems.

</details>


### [7] [Channel Extrapolation for MIMO Systems with the Assistance of Multi-path Information Induced from Channel State Information](https://arxiv.org/abs/2601.21524)
*Yuan Gao,Xinyi Wu,Jiang Jun,Zitian Zhang,Zhaohui Yang,Shugong Xu,Cheng-Xiang Wang,Zhu Han*

Main category: eess.SP

TL;DR: 提出基于CSI多径特性的信道外推框架，无需额外模态数据，通过CSI-to-PDP模块提取多径信息，结合MAE架构实现高效信道外推。


<details>
  <summary>Details</summary>
Motivation: 6G网络中传统信道估计开销大，现有基于环境信息的方法需要额外硬件且存在隐私和多模态对齐问题。需要一种仅利用CSI本身多径特性的高效信道外推方法。

Method: 1) CSI-to-PDP模块：基于AE框架训练，将CSI转换为功率延迟分布(PDP)；2) 从PDP提取总功率和功率加权延迟作为多径信息；3) 改进的MAE架构：使用独立编码器提取掩码CSI和多径信息特征，通过交叉注意力模块融合，自监督训练进行信道外推。

Result: 显著提升外推性能，推理时间仅增加约0.1ms。在已知CSI比例较小时表现出强泛化能力，优于现有基准方法。

Conclusion: 提出的框架仅利用CSI内在多径特性，无需额外模态数据，实现了高效且泛化能力强的信道外推，为6G网络信道获取提供了有前景的解决方案。

Abstract: Acquiring channel state information (CSI) through traditional methods, such as channel estimation, is increasingly challenging for the emerging sixth generation (6G) mobile networks due to high overhead. To address this issue, channel extrapolation techniques have been proposed to acquire complete CSI from a limited number of known CSIs. To improve extrapolation accuracy, environmental information, such as visual images or radar data, has been utilized, which poses challenges including additional hardware, privacy and multi-modal alignment concerns. To this end, this paper proposes a novel channel extrapolation framework by leveraging environment-related multi-path characteristics induced directly from CSI without integrating additional modalities. Specifically, we propose utilizing the multi-path characteristics in the form of power-delay profile (PDP), which is acquired using a CSI-to-PDP module. CSI-to-PDP module is trained in an AE-based framework by reconstructing the PDPs and constraining the latent low-dimensional features to represent the CSI. We further extract the total power & power-weighted delay of all the identified paths in PDP as the multi-path information. Building on this, we proposed a MAE architecture trained in a self-supervised manner to perform channel extrapolation. Unlike standard MAE approaches, our method employs separate encoders to extract features from the masked CSI and the multi-path information, which are then fused by a cross-attention module. Extensive simulations demonstrate that this framework improves extrapolation performance dramatically, with a minor increase in inference time (around 0.1 ms). Furthermore, our model shows strong generalization capabilities, particularly when only a small portion of the CSI is known, outperforming existing benchmarks.

</details>


### [8] [Near-Field Positioning for XL-MIMO Uniform Circular Arrays: An Attention-Enhanced Deep Learning Approach](https://arxiv.org/abs/2601.21550)
*Yuan Gao,Xinyu Guo,Han Li,Jianbo Du,Shugong Xu*

Main category: eess.SP

TL;DR: 提出一种基于注意力增强深度学习的XL-MIMO精确定位方法，利用双路径通道注意力和空间注意力机制，在近场条件下实现优于现有方法的定位精度。


<details>
  <summary>Details</summary>
Motivation: 6G移动通信中XL-MIMO系统天线数量激增，扩展了近场范围，传统远场假设不再适用。虽然UCAs阵列具有恒定角度分辨率的优势，但如何利用扩展孔径和近场效应进行精确定位仍需深入研究。

Method: 采用注意力增强的深度学习框架，包含双路径通道注意力机制和空间注意力机制，有效整合通道级和空间级特征。使用输入信号的协方差度量作为模型输入。

Result: 模型在综合仿真中超越了ABPN、NFLnet、CNN和MLP等现有基准方法。协方差度量在定位精度和模型效率方面优于传统的信道状态信息(CSI)。

Conclusion: 提出的注意力增强深度学习模型能够有效利用XL-MIMO系统的扩展孔径和近场效应，实现高精度定位，为6G通信中的定位问题提供了有效解决方案。

Abstract: In the evolving landscape of sixth-generation (6G) mobile communication, multiple-input multiple-output (MIMO) systems are incorporating an unprecedented number of antenna elements, advancing towards Extremely large-scale multiple-input-multiple-output (XL-MIMO) systems. This enhancement significantly increases the spatial degrees of freedom, offering substantial benefits for wireless positioning. However, the expansion of the near-field range in XL-MIMO challenges the traditional far-field assumptions used in previous MIMO models. Among various configurations, uniform circular arrays (UCAs) demonstrate superior performance by maintaining constant angular resolution, unlike linear planar arrays. Addressing how to leverage the expanded aperture and harness the near-field effects in XL-MIMO systems remains an area requiring further investigation. In this paper, we introduce an attention-enhanced deep learning approach for precise positioning. We employ a dual-path channel attention mechanism and a spatial attention mechanism to effectively integrate channel-level and spatial-level features. Our comprehensive simulations show that this model surpasses existing benchmarks such as attention-based positioning networks (ABPN), near-field positioning networks (NFLnet), convolutional neural networks (CNN), and multilayer perceptrons (MLP). The proposed model achieves superior positioning accuracy by utilizing covariance metrics of the input signal. Also, simulation results reveal that covariance metric is advantageous for positioning over channel state information (CSI) in terms of positioning accuracy and model efficiency.

</details>


### [9] [VSE: Variational state estimation of complex model-free process](https://arxiv.org/abs/2601.21887)
*Gustav Norén,Anubhab Ghosh,Fredrik Cumlin,Saikat Chatterjee*

Main category: eess.SP

TL;DR: 提出一种基于变分推理的变分状态估计方法，使用RNN为无模型的复杂动态过程提供闭式高斯后验分布


<details>
  <summary>Details</summary>
Motivation: 针对无合适物理模型的复杂动态过程，需要从非线性测量中进行状态估计。传统方法需要已知系统模型，而数据驱动方法需要有效处理非线性测量噪声

Method: 使用两个相互辅助的RNN：一个提供闭式高斯后验，另一个在训练阶段辅助学习。基于变分推理原理，两个RNN相互促进学习

Result: 在随机Lorenz系统跟踪应用中，VSE表现优于已知系统模型的粒子滤波器和最近提出的数据驱动状态估计方法

Conclusion: 提出的变分状态估计方法能够有效处理无模型复杂动态过程的状态估计问题，在计算简单性和性能方面具有优势

Abstract: We design a variational state estimation (VSE) method that provides a closed-form Gaussian posterior of an underlying complex dynamical process from (noisy) nonlinear measurements. The complex process is model-free. That is, we do not have a suitable physics-based model characterizing the temporal evolution of the process state. The closed-form Gaussian posterior is provided by a recurrent neural network (RNN). The use of RNN is computationally simple in the inference phase. For learning the RNN, an additional RNN is used in the learning phase. Both RNNs help each other learn better based on variational inference principles. The VSE is demonstrated for a tracking application - state estimation of a stochastic Lorenz system (a benchmark process) using a 2-D camera measurement model. The VSE is shown to be competitive against a particle filter that knows the Lorenz system model and a recently proposed data-driven state estimation method that does not know the Lorenz system model.

</details>


### [10] [Joint Laser Inter-Satellite Link Matching and Traffic Flow Routing in LEO Mega-Constellations via Lagrangian Duality](https://arxiv.org/abs/2601.21914)
*Zhouyou Gu,Jihong Park,Jinho Choi*

Main category: eess.SP

TL;DR: 本文提出了一种联合优化激光通信终端连接和流量路由的方法，以最大化低地球轨道巨型星座的网络吞吐量，考虑了实际的LCT机械限制和全球流量分布。


<details>
  <summary>Details</summary>
Motivation: 现有LISL方案往往忽视激光通信终端的机械限制以及由用户和网关分布不均导致的全球流量分布不均匀问题，导致吞吐量不优和LCT/LISL利用率不足，特别是当每颗卫星只携带少量LCT时。

Method: 将问题建模为NP-hard混合整数规划，通过拉格朗日对偶松弛耦合约束，将问题分解为加权图匹配（LCT连接）、加权最短路径路由任务和速率分配的线性规划。使用次梯度下降优化拉格朗日乘子，具有可证明的收敛性。

Result: 使用真实世界星座和地面数据的仿真显示，该方法相比现有非联合方法，网络吞吐量提高了35%到145%。

Conclusion: 通过联合优化LCT连接和流量路由，考虑实际机械限制和全球流量分布，可以显著提高LEO巨型星座的网络吞吐量。

Abstract: Low Earth orbit (LEO) mega-constellations greatly extend the coverage and resilience of future wireless systems. Within the mega-constellations, laser inter-satellite links (LISLs) enable high-capacity, long-range connectivity. Existing LISL schemes often overlook mechanical limitations of laser communication terminals (LCTs) and non-uniform global traffic profiles caused by uneven user and gateway distributions, leading to suboptimal throughput and underused LCTs/LISLs -- especially when each satellite carries only a few LCTs. This paper investigates the joint optimization of LCT connections and traffic routing to maximize the constellation throughput, considering the realistic LCT mechanics and the global traffic profile. The problem is formulated as an NP-hard mixed-integer program coupling LCT connections with flow-rate variables under link capacity constraints. Due to its intractability, we resort to relaxing the coupling constraints via Lagrangian duality, decomposing the problem into a weighted graph-matching for LCT connections, weighted shortest-path routing tasks, and a linear program for rate allocation. Here, Lagrange multipliers reflect congestion weights between satellites, jointly guiding the matching, routing, and rate allocation. Subgradient descent optimizes the multipliers, with provable convergence. Simulations using real-world constellation and terrestrial data show that our methods substantially improve network throughput by up to $35\%$--$145\%$ over existing non-joint approaches.

</details>


### [11] [Duality-Guided Graph Learning for Real-Time Joint Connectivity and Routing in LEO Mega-Constellations](https://arxiv.org/abs/2601.21921)
*Zhouyou Gu,Jinho Choi,Tony Q. S. Quek,Jihong Park*

Main category: eess.SP

TL;DR: DeepLaDu：基于拉格朗日对偶引导的深度学习框架，用于实时优化低轨卫星星座的激光星间链路连接、流量路由和速率分配，相比传统方法提升20%吞吐量，计算时间降低数个数量级。


<details>
  <summary>Details</summary>
Motivation: 低轨巨型星座的激光星间链路（LISL）虽然能提供高容量骨干连接，但其管理面临激光通信终端有限、机械指向约束和网络拓扑快速变化等挑战，需要实时优化连接建立、流量路由和速率分配。

Method: 将问题建模为大规模时变星座图上的混合整数优化，采用拉格朗日对偶分解，将每链路的对偶变量解释为拥塞价格。提出DeepLaDu框架，用图神经网络在单次前向传播中直接从星座状态推断每链路的拥塞价格，使用基于次梯度的边级损失实现可扩展稳定训练。

Result: 在模拟的类星链星座中，DeepLaDu相比非联合或启发式基线实现高达20%的网络吞吐量提升，同时匹配迭代对偶优化的性能，但计算时间降低数个数量级，适合动态低轨网络的实时操作。

Conclusion: DeepLaDu通过深度学习与拉格朗日对偶理论的结合，解决了低轨卫星星座激光星间链路管理的实时优化问题，在保持高性能的同时大幅降低计算复杂度，为动态非地面网络提供了实用的解决方案。

Abstract: Laser inter-satellite links (LISLs) of low Earth orbit (LEO) mega-constellations enable high-capacity backbone connectivity in non-terrestrial networks, but their management is challenged by limited laser communication terminals, mechanical pointing constraints, and rapidly time-varying network topologies. This paper studies the joint problem of LISL connection establishment, traffic routing, and flow-rate allocation under heterogeneous global traffic demand and gateway availability. We formulate the problem as a mixed-integer optimization over large-scale, time-varying constellation graphs and develop a Lagrangian dual decomposition that interprets per-link dual variables as congestion prices coordinating connectivity and routing decisions. To overcome the prohibitive latency of iterative dual updates, we propose DeepLaDu, a Lagrangian duality-guided deep learning framework that trains a graph neural network (GNN) to directly infer per-link (edge-level) congestion prices from the constellation state in a single forward pass. We enable scalable and stable training using a subgradient-based edge-level loss in DeepLaDu. We analyze the convergence and computational complexity of the proposed approach and evaluate it using realistic Starlink-like constellations with optical and traffic constraints. Simulation results show that DeepLaDu achieves up to 20\% higher network throughput than non-joint or heuristic baselines, while matching the performance of iterative dual optimization with orders-of-magnitude lower computation time, suitable for real-time operation in dynamic LEO networks.

</details>


### [12] [Optimal Placement of Movable Antennas for Angle-of-Departure Estimation Under User Location Uncertainty](https://arxiv.org/abs/2601.21997)
*Lucía Pallarés-Rodríguez,Angelo Coluccia,Alessio Fascista,Musa Furkan Keskin,Henk Wymeersch,José A. López-Salcedo,Gonzalo Seco-Granados*

Main category: eess.SP

TL;DR: 该论文研究了在用户设备位置不确定情况下，使用可移动天线阵列进行角度离场估计，通过理论性能分析和天线位置优化，展示了可移动天线系统相比固定阵列的优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统大型天线阵列存在成本和功耗问题，可移动天线能克服这些限制。在用户设备位置不确定的实际场景中，需要研究如何利用可移动天线阵列进行稳健的角度离场估计。

Method: 1) 通过克拉美-罗界推导理论性能极限；2) 在用户设备不确定区域内优化天线位置以确保稳健性能；3) 数值仿真验证优化效果。

Result: 数值结果表明，通过显式考虑不确定区域来动态优化天线布局，其性能优于固定阵列，证明了可移动天线系统能够适应环境变化并超越传统阵列。

Conclusion: 可移动天线阵列在用户设备位置不确定情况下能够通过动态优化天线位置实现稳健的角度离场估计，相比固定阵列具有显著性能优势，为实际通信系统提供了有效的解决方案。

Abstract: Movable antennas (MA) have gained significant attention in recent years to overcome the limitations of extremely large antenna arrays in terms of cost and power consumption. In this paper, we investigate the use of MA arrays at the base station (BS) for angle-of-departure (AoD) estimation under uncertainty in the user equipment (UE) location. Specifically, we (i) derive the theoretical performance limits through the Cramér-Rao bound (CRB) and (ii) optimize the antenna positions to ensure robust performance within the UE's uncertainty region. Numerical results show that dynamically optimizing antenna placement by explicitly considering the uncertainty region yields superior performance compared to fixed arrays, demonstrating the ability of MA systems to adapt and outperform conventional arrays.

</details>


### [13] [Towards Joint Optimization for UAV-Integrated RIS-Assisted Fluid Antenna Systems](https://arxiv.org/abs/2601.22109)
*Ali Reda,Tamer Mekkawy,Theodoros A. Tsiftsis,Chan-Byoung Chae,Kai-Kit Wong*

Main category: eess.SP

TL;DR: 提出一种基于流体天线系统辅助可重构智能表面的无人机下行通信方案，通过联合优化天线端口位置和RIS相位偏移来最大化可达速率，显著提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 无人机集成到蜂窝网络面临严重的空对地干扰挑战，需要有效的解决方案来提升通信质量。

Method: 采用流体天线系统辅助的可重构智能表面技术，通过联合优化FAS端口位置和RIS相位偏移来最大化可达速率。使用基于二阶锥规划的逐次凸逼近方法解决非凸优化问题。

Result: 仿真结果表明，相比传统固定位置天线方案，所提算法显著改善了中断概率和可达速率，特别是在大规模RIS配置下增益尤为明显。算法收敛速度快，适合实时应用。

Conclusion: FAS辅助的RIS系统能有效提升无人机下行通信性能，联合优化算法具有实际应用价值。

Abstract: Unmanned aerial vehicles (UAVs) integrated into cellular networks face significant challenges from air-to-ground interference. To address this, we propose a downlink UAV communication system that leverages a fluid antenna system (FAS)- assisted reconfigurable intelligent surface (RIS) to enhance signal quality. By jointly optimizing the FAS port positions and RIS phase shifts, we maximize the achievable rate. The resulting nonconvex optimization problem is solved using successive convex approximation (SCA) based on second-order cone programming (SOCP), which reformulates the constraints into a tractable form. Simulation results show that the proposed algorithm significantly improves both outage probability and achievable rate over conventional fixed-position antenna (FPA) schemes, with particularly large gains in large-scale RIS configurations. Moreover, the algorithm converges rapidly, making it suitable for real-time applications

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [14] [Reducing Prompt Sensitivity in LLM-based Speech Recognition Through Learnable Projection](https://arxiv.org/abs/2601.20898)
*Sergio Burdisso,Esaú Villatoro-Tello,Shashi Kumar,Srikanth Madikeri,Andrés Carofilis,Pradeep Rangappa,Manjunath K E,Kadri Hacioglu,Petr Motlicek,Andreas Stolcke*

Main category: eess.AS

TL;DR: 本文分析了LLM-based ASR中提示词设计的影响，发现不同提示词对性能有显著影响且不稳定，提出了一种无需修改底层模型的提示词投影器模块来优化提示词嵌入


<details>
  <summary>Details</summary>
Motivation: 现有的LLM-based ASR系统通常使用固定的手动定义提示词，但提示词设计的影响尚未得到充分探索。研究发现提示词选择会显著影响ASR性能并引入不稳定性，且没有单一提示词在所有情况下表现最佳，因此需要一种更优的提示词优化方法。

Method: 受语音到LLM投影器的启发，提出了一个提示词投影器模块。这是一个简单、模型无关的扩展，学习将提示词嵌入投影到LLM输入空间中更有效的区域，而不需要修改底层的LLM-based ASR模型。

Result: 在四个数据集上的实验表明，添加提示词投影器能够：1）持续提升性能；2）减少性能波动；3）超越最佳手动选择的提示词。

Conclusion: 提示词设计对LLM-based ASR性能有显著影响，提出的提示词投影器模块提供了一种有效且模型无关的方法来优化提示词嵌入，从而提升ASR系统的稳定性和性能。

Abstract: LLM-based automatic speech recognition (ASR), a well-established approach, connects speech foundation models to large language models (LLMs) through a speech-to-LLM projector, yielding promising results. A common design choice in these architectures is the use of a fixed, manually defined prompt during both training and inference. This setup not only enables applicability across a range of practical scenarios, but also helps maximize model performance. However, the impact of prompt design remains underexplored. This paper presents a comprehensive analysis of commonly used prompts across diverse datasets, showing that prompt choice significantly affects ASR performance and introduces instability, with no single prompt performing best across all cases. Inspired by the speech-to-LLM projector, we propose a prompt projector module, a simple, model-agnostic extension that learns to project prompt embeddings to more effective regions of the LLM input space, without modifying the underlying LLM-based ASR model. Experiments on four datasets show that the addition of a prompt projector consistently improves performance, reduces variability, and outperforms the best manually selected prompts.

</details>


### [15] [Unseen but not Unknown: Using Dataset Concealment to Robustly Evaluate Speech Quality Estimation Models](https://arxiv.org/abs/2601.21110)
*Jaden Pieper,Stephen D. Voran*

Main category: eess.AS

TL;DR: DSC是一种评估语音质量估计模型的新方法，可量化研究结果与实际应用需求之间的差距，并通过数据集对齐器提升模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前语音质量估计模型的研究结果与实际应用需求存在性能差距，需要一种系统方法来评估和解释这种差距，同时解决多数据集训练时的语料库效应问题。

Method: 提出DSC评估框架，量化模型性能差距并分解原因；使用AlignNet的数据集对齐器处理多数据集训练；在三个模型（MOSNet、NISQA、Wav2Vec2.0）上验证，使用9个训练数据集和9个未见数据集。

Result: DSC能提供模型泛化能力的可解释视图；仅1000参数的数据集对齐器显著提升了9400万参数的Wav2Vec模型对未见数据的语音质量估计能力；允许充分利用所有可用数据进行训练。

Conclusion: DSC为语音质量估计模型提供了系统评估框架，数据集对齐器能有效提升模型泛化性能，为实际应用中的模型选择和优化提供指导。

Abstract: We introduce Dataset Concealment (DSC), a rigorous new procedure for evaluating and interpreting objective speech quality estimation models. DSC quantifies and decomposes the performance gap between research results and real-world application requirements, while offering context and additional insights into model behavior and dataset characteristics. We also show the benefits of addressing the corpus effect by using the dataset Aligner from AlignNet when training models with multiple datasets. We demonstrate DSC and the improvements from the Aligner using nine training datasets and nine unseen datasets with three well-studied models: MOSNet, NISQA, and a Wav2Vec2.0-based model. DSC provides interpretable views of the generalization capabilities and limitations of models, while allowing all available data to be used at training. An additional result is that adding the 1000 parameter dataset Aligner to the 94 million parameter Wav2Vec model during training does significantly improve the resulting model's ability to estimate speech quality for unseen data.

</details>


### [16] [DNN-Based Online Source Counting Based on Spatial Generalized Magnitude Squared Coherence](https://arxiv.org/abs/2601.21114)
*Henri Gode,Simon Doclo*

Main category: eess.AS

TL;DR: 提出一种基于空间相干性的在线声源计数方法，通过检测声源数量变化来实现实时计数


<details>
  <summary>Details</summary>
Motivation: 声源数量是许多声学信号处理任务（如声源定位、分离和多麦克风语音增强）的关键参数，需要在线实时检测方法

Method: 利用空间相干性原理：单个相干源在空间白噪声中产生高空间相干性，而仅有噪声时相干性低。通过空间白化操作将声源计数问题转化为变化检测任务，使用广义幅度平方相干性作为量化指标，训练紧凑神经网络进行帧级变化检测

Result: 在混响声学场景（最多4个说话者和背景噪声）的双耳助听器模拟中，验证了该方法在线声源计数的有效性

Conclusion: 基于空间相干性的变化检测方法能够有效实现在线声源计数，为实时声学信号处理应用提供了实用解决方案

Abstract: The number of active sound sources is a key parameter in many acoustic signal processing tasks, such as source localization, source separation, and multi-microphone speech enhancement. This paper proposes a novel method for online source counting by detecting changes in the number of active sources based on spatial coherence. The proposed method exploits the fact that a single coherent source in spatially white background noise yields high spatial coherence, whereas only noise results in low spatial coherence. By applying a spatial whitening operation, the source counting problem is reformulated as a change detection task, aiming to identify the time frames when the number of active sources changes. The method leverages the generalized magnitude-squared coherence as a measure to quantify spatial coherence, providing features for a compact neural network trained to detect source count changes framewise. Simulation results with binaural hearing aids in reverberant acoustic scenes with up to 4 speakers and background noise demonstrate the effectiveness of the proposed method for online source counting.

</details>


### [17] [Towards Robust Dysarthric Speech Recognition: LLM-Agent Post-ASR Correction Beyond WER](https://arxiv.org/abs/2601.21347)
*Xiuwen Zheng,Sixun Dong,Bornali Phukon,Mark Hasegawa-Johnson,Chang D. Yoo*

Main category: eess.AS

TL;DR: 该论文提出了一种基于大语言模型的ASR后处理代理，用于纠正构音障碍语音识别错误，并发布了最大的构音障碍语音纠正基准SAP-Hypo5，在WER和语义指标上都取得了显著改进。


<details>
  <summary>Details</summary>
Motivation: 传统ASR系统通常使用词错误率(WER)作为评估标准，但实际应用更关注语义保真度。对于构音障碍语音，发音不精确和不流畅会导致严重的语义失真，WER与语义保真度之间的不匹配问题尤为突出。

Method: 提出了基于大语言模型的Judge-Editor代理，对ASR生成的top-k假设进行后处理：保留高置信度片段，重写不确定部分，支持零样本和微调两种模式。同时发布了SAP-Hypo5基准数据集。

Result: 在多视角评估中，该方法实现了14.51%的WER降低，语义指标显著提升：MENLI提高7.59个百分点，Slot Micro F1提高7.66个百分点。分析显示WER对领域转移高度敏感，而语义指标与下游任务性能更相关。

Conclusion: 基于LLM的ASR后处理代理能有效改善构音障碍语音识别的语义保真度，发布的SAP-Hypo5基准为未来研究提供了重要资源。语义指标比WER更能反映实际应用性能。

Abstract: While Automatic Speech Recognition (ASR) is typically benchmarked by word error rate (WER), real-world applications ultimately hinge on semantic fidelity. This mismatch is particularly problematic for dysarthric speech, where articulatory imprecision and disfluencies can cause severe semantic distortions. To bridge this gap, we introduce a Large Language Model (LLM)-based agent for post-ASR correction: a Judge-Editor over the top-k ASR hypotheses that keeps high-confidence spans, rewrites uncertain segments, and operates in both zero-shot and fine-tuned modes. In parallel, we release SAP-Hypo5, the largest benchmark for dysarthric speech correction, to enable reproducibility and future exploration. Under multi-perspective evaluation, our agent achieves a 14.51% WER reduction alongside substantial semantic gains, including a +7.59 pp improvement in MENLI and +7.66 pp in Slot Micro F1 on challenging samples. Our analysis further reveals that WER is highly sensitive to domain shift, whereas semantic metrics correlate more closely with downstream task performance.

</details>


### [18] [SemanticAudio: Audio Generation and Editing in Semantic Space](https://arxiv.org/abs/2601.21402)
*Zheqi Dai,Guangyan Zhang,Haolin He,Xiquan Li,Jingyu Li,Chunyat Wu,Yiwen Guo,Qiuqiang Kong*

Main category: eess.AS

TL;DR: 提出SemanticAudio框架，在高级语义空间进行音频生成和编辑，通过两阶段Flow Matching架构实现更好的语义对齐


<details>
  <summary>Details</summary>
Motivation: 现有文本到音频生成模型主要在声学潜在空间操作，导致生成音频与文本描述的对齐效果不佳，需要更高级的语义控制

Method: 提出两阶段Flow Matching架构：语义规划器生成紧凑语义特征，声学合成器基于语义规划生成高保真声学潜在表示；引入无需训练的文本引导编辑机制

Result: 实验表明SemanticAudio在语义对齐方面超越现有主流方法，能够实现精确的属性级音频编辑

Conclusion: 在高级语义空间进行音频生成和编辑比直接在声学潜在空间操作更有效，能实现更好的语义对齐和精确控制

Abstract: In recent years, Text-to-Audio Generation has achieved remarkable progress, offering sound creators powerful tools to transform textual inspirations into vivid audio. However, existing models predominantly operate directly in the acoustic latent space of a Variational Autoencoder (VAE), often leading to suboptimal alignment between generated audio and textual descriptions. In this paper, we introduce SemanticAudio, a novel framework that conducts both audio generation and editing directly in a high-level semantic space. We define this semantic space as a compact representation capturing the global identity and temporal sequence of sound events, distinct from fine-grained acoustic details. SemanticAudio employs a two-stage Flow Matching architecture: the Semantic Planner first generates these compact semantic features to sketch the global semantic layout, and the Acoustic Synthesizer subsequently produces high-fidelity acoustic latents conditioned on this semantic plan. Leveraging this decoupled design, we further introduce a training-free text-guided editing mechanism that enables precise attribute-level modifications on general audio without retraining. Specifically, this is achieved by steering the semantic generation trajectory via the difference of velocity fields derived from source and target text prompts. Extensive experiments demonstrate that SemanticAudio surpasses existing mainstream approaches in semantic alignment. Demo available at: https://semanticaudio1.github.io/

</details>


### [19] [Representation-Regularized Convolutional Audio Transformer for Audio Understanding](https://arxiv.org/abs/2601.21612)
*Bing Han,Chushu Zhou,Yifan Yang,Wei Wang,Chenda Li,Wangyou Zhang,Yanmin Qian*

Main category: eess.AS

TL;DR: 提出卷积音频变换器(CAT)框架，通过多分辨率块和表示正则化目标，实现高效的自监督音频学习，在AudioSet上达到竞争性性能且收敛速度快5倍。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法通常只在单一粒度上操作，难以建模音频信号中多样的时频结构特征，且从零开始引导表示计算成本高、收敛慢。

Method: 1) 多分辨率块：聚合不同粒度的层次音频特征；2) 表示正则化目标：借鉴生成模型思想，通过将学生模型预测与冻结预训练外部编码器的高质量语义表示对齐来指导训练。

Result: CAT在音频理解基准测试中显著优于基线方法，在AudioSet 20k数据集上达到竞争性性能，且收敛速度比现有方法快5倍。

Conclusion: CAT框架通过多粒度特征建模和表示正则化，有效解决了自监督音频学习中粒度单一和训练效率低的问题，实现了高效且性能优越的音频表示学习。

Abstract: Bootstrap-based Self-Supervised Learning (SSL) has achieved remarkable progress in audio understanding. However, existing methods typically operate at a single level of granularity, limiting their ability to model the diverse temporal and spectral structures inherent in complex audio signals. Furthermore, bootstrapping representations from scratch is computationally expensive, often requiring extensive training to converge. In this work, we propose the Convolutional Audio Transformer (CAT), a unified framework designed to address these challenges. First, to capture hierarchical audio features, CAT incorporates a Multi-resolution Block that aggregates information across varying granularities. Second, to enhance training efficiency, we introduce a Representation Regularization objective. Drawing inspiration from generative modeling, this auxiliary task guides the student model by aligning its predictions with high-quality semantic representations from frozen, pre-trained external encoders. Experimental results demonstrate that CAT significantly outperforms baselines on audio understanding benchmarks. Notably, it achieves competitive performance on the AudioSet 20k dataset with 5 times faster convergence than existing methods. Codes and checkpoints will be released soon at https://github.com/realzhouchushu/CAT.

</details>


### [20] [Speech Quality-Based Localization of Low-Quality Speech and Text-to-Speech Synthesis Artefacts](https://arxiv.org/abs/2601.21886)
*Michael Kuhlmann,Alexander Werning,Thilo von Neumann,Reinhold Haeb-Umbach*

Main category: eess.AS

TL;DR: 提出一种基于片段一致性约束的语音质量评估方法，通过正则化提升帧级分数预测的稳定性，并应用于部分欺骗检测和TTS系统合成伪影识别


<details>
  <summary>Details</summary>
Motivation: 现有语音质量评估方法主要关注语句或系统层面，虽然能判断整体质量但缺乏可解释性；帧级分数能提供更好的可解释性，但训练时缺乏强目标导致模型难以调优和正则化

Method: 提出使用片段一致性约束来正则化语句级语音质量预测器，显著降低帧级随机性；将帧级分数应用于部分欺骗场景和检测最先进TTS系统的合成伪影

Result: 片段一致性约束能有效减少帧级随机性；通过听觉测试验证，听众在低帧级分数定义的片段中更频繁地评定为低质量，相比随机对照组有显著差异

Conclusion: 片段一致性约束是提升帧级语音质量预测器稳定性的有效方法，帧级分数在语音合成质量评估和欺骗检测中具有实用价值

Abstract: A large number of works view the automatic assessment of speech from an utterance- or system-level perspective. While such approaches are good in judging overall quality, they cannot adequately explain why a certain score was assigned to an utterance. frame-level scores can provide better interpretability, but models predicting them are harder to tune and regularize since no strong targets are available during training. In this work, we show that utterance-level speech quality predictors can be regularized with a segment-based consistency constraint which notably reduces frame-level stochasticity. We then demonstrate two applications involving frame-level scores: The partial spoof scenario and the detection of synthesis artefacts in two state-of-the-art text-to-speech systems. For the latter, we perform listening tests and confirm that listeners rate segments to be of poor quality more often in the set defined by low frame-level scores than in a random control set.

</details>


### [21] [DisContSE: Single-Step Diffusion Speech Enhancement Based on Joint Discrete and Continuous Embeddings](https://arxiv.org/abs/2601.21940)
*Yihui Fu,Tim Fingscheidt*

Main category: eess.AS

TL;DR: DisContSE：基于离散音频编解码特征的高效扩散语音增强模型，通过联合离散token和连续嵌入，实现单步推理，在保真度和可懂度上均有优异表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于离散音频编解码特征的扩散语音增强方法存在两个主要问题：1）推理计算复杂度高，需要多次反向过程迭代；2）在非侵入式指标上表现良好，但在侵入式指标（如音素准确性）上表现不佳，难以重建正确的音素。

Method: 提出DisContSE模型，包含三个核心模块：1）离散增强模块，处理离散音频编解码token；2）连续增强模块，处理连续嵌入表示；3）语义增强模块，优化音素准确性。同时提出量化误差掩码初始化策略，实现单步高效推理。

Result: 在URGENT 2024语音增强挑战赛数据集上评估，DisContSE在PESQ、POLQA、UTMOS等客观指标和主观ITU-T P.808听力测试中均优于现有最佳时域和频域扩散基线方法，获得总体最高排名。

Conclusion: DisContSE成功实现了基于音频编解码的单步扩散语音增强，在保持高保真度和可懂度的同时显著降低了计算复杂度，为高效高质量的语音增强提供了新方案。

Abstract: Diffusion speech enhancement on discrete audio codec features gain immense attention due to their improved speech component reconstruction capability. However, they usually suffer from high inference computational complexity due to multiple reverse process iterations. Furthermore, they generally achieve promising results on non-intrusive metrics but show poor performance on intrusive metrics, as they may struggle in reconstructing the correct phones. In this paper, we propose DisContSE, an efficient diffusion-based speech enhancement model on joint discrete codec tokens and continuous embeddings. Our contributions are three-fold. First, we formulate both a discrete and a continuous enhancement module operating on discrete audio codec tokens and continuous embeddings, respectively, to achieve improved fidelity and intelligibility simultaneously. Second, a semantic enhancement module is further adopted to achieve optimal phonetic accuracy. Third, we achieve a single-step efficient reverse process in inference with a novel quantization error mask initialization strategy, which, according to our knowledge, is the first successful single-step diffusion speech enhancement based on an audio codec. Trained and evaluated on URGENT 2024 Speech Enhancement Challenge data splits, the proposed DisContSE excels top-reported time- and frequency-domain diffusion baseline methods in PESQ, POLQA, UTMOS, and in a subjective ITU-T P.808 listening test, clearly achieving an overall top rank.

</details>


### [22] [TidyVoice 2026 Challenge Evaluation Plan](https://arxiv.org/abs/2601.21960)
*Aref Farhadipour,Jan Marquenie,Srikanth Madikeri,Teodora Vukovic,Volker Dellwo,Kathy Reid,Francis M. Tyers,Ingo Siegert,Eleanor Chodroff*

Main category: eess.AS

TL;DR: 提出TidyVoice挑战赛，针对跨语言说话人验证中的语言不匹配问题，使用TidyVoiceX数据集（约40种语言）进行标准化评估，旨在推动更公平、包容的语言无关说话人识别技术。


<details>
  <summary>Details</summary>
Motivation: 说话人验证系统在语言不匹配情况下性能显著下降，而当前领域过度依赖英语中心数据，需要解决跨语言场景下的公平性和包容性问题。

Method: 基于TidyVoice基准测试中的TidyVoiceX数据集（源自Mozilla Common Voice的大规模多语言语料库），专门设计跨语言试验，使用等错误率作为主要评估指标，提供标准化数据、开源基线模型和严格评估协议。

Result: 建立了一个标准化的跨语言说话人验证挑战框架，包含约40种语言的专门数据集和评估协议，为研究社区提供可复现的基准。

Conclusion: TidyVoice挑战赛旨在推动更公平、包容和语言无关的说话人识别技术发展，直接契合Interspeech 2026"Speaking Together"主题，通过标准化评估促进该领域进步。

Abstract: The performance of speaker verification systems degrades significantly under language mismatch, a critical challenge exacerbated by the field's reliance on English-centric data. To address this, we propose the TidyVoice Challenge for cross-lingual speaker verification. The challenge leverages the TidyVoiceX dataset from the novel TidyVoice benchmark, a large-scale, multilingual corpus derived from Mozilla Common Voice, and specifically curated to isolate the effect of language switching across approximately 40 languages. Participants will be tasked with building systems robust to this mismatch, with performance primarily evaluated using the Equal Error Rate on cross-language trials. By providing standardized data, open-source baselines, and a rigorous evaluation protocol, this challenge aims to drive research towards fairer, more inclusive, and language-independent speaker recognition technologies, directly aligning with the Interspeech 2026 theme, "Speaking Together."

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [23] [Generalizable Prompt Tuning for Audio-Language Models via Semantic Expansion](https://arxiv.org/abs/2601.20867)
*Jaehyuk Jang,Wonjun Lee,Kangwook Ko,Changick Kim*

Main category: cs.SD

TL;DR: SEPT提出了一种用于音频语言模型提示调优的语义扩展框架，通过引入大语言模型生成的语义邻居来正则化提示嵌入空间，解决了基类-新类权衡问题，提升了泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统提示调优在音频语言模型中存在基类-新类权衡问题，这是由于嵌入空间的语义结构被破坏导致的。目前ALMs中提示调优的泛化能力尚未得到充分探索。

Method: 提出SEPT框架，通过大语言模型生成语义邻居，引入带有边界约束的语义扩展损失函数，促进类内紧凑性和类间分离性，从而增强提示嵌入空间的语义结构。

Result: 在建立的第一个ALMs提示泛化基准上，SEPT在多个提示调优基线上一致提升了泛化性能，包括基类到新类泛化和跨数据集可迁移性，同时保持推理时的计算成本不变。

Conclusion: SEPT通过语义扩展正则化有效解决了音频语言模型提示调优中的基类-新类权衡问题，显著提升了模型的泛化能力，为ALMs提示调优提供了有效的解决方案。

Abstract: Prompt tuning has achieved remarkable progress in vision-language models (VLMs) and is recently being adopted for audio-language models (ALMs). However, its generalization ability in ALMs remains largely underexplored. We observe that conventional prompt tuning for ALMs also suffers from the Base-New Tradeoff, and we identify that this issue stems from the disrupted semantic structure of the embedding space. To address this issue, we propose Semantically Expanded Prompt Tuning (SEPT)-a plug-and-play framework that explicitly regularizes the prompt embedding space by incorporating semantic neighbors generated by large language models. SEPT introduces a novel semantic expansion loss with margin constraints that promote intra-class compactness and inter-class separability, thereby enhancing the semantic structure of the prompt embedding space. For comprehensive evaluation, we establish the first benchmark setup for prompt generalization in ALMs, covering both base-to-new generalization and cross-dataset transferability. Extensive experiments demonstrate that SEPT consistently improves generalization performance across multiple prompt tuning baselines, while maintaining computational cost during inference. Codes are available in https://github.com/jhyukjang/SEPT.

</details>


### [24] [VoxMorph: Scalable Zero-shot Voice Identity Morphing via Disentangled Embeddings](https://arxiv.org/abs/2601.20883)
*Bharath Krishnamurthy,Ajita Rattani*

Main category: cs.SD

TL;DR: VoxMorph是一个零样本语音变形框架，仅需每人5秒音频即可生成高质量语音变形，无需模型重训练，在语音生物识别系统中实现了67.8%的攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 现有语音变形方法计算成本高、不可扩展、仅限于声学相似的身份对，且现有声音变形方法不适用于语音身份操纵。语音生物识别中的变形攻击漏洞尚未得到充分探索。

Method: 将语音特征解耦为韵律和音色嵌入，通过球面线性插值融合，使用自回归语言模型和条件流匹配网络合成语音，实现零样本变形。

Result: 在自动说话人验证系统中实现了67.8%的变形攻击成功率，音频质量提升2.6倍，可懂度错误减少73%，达到最先进性能。

Conclusion: VoxMorph为语音变形建立了实用且可扩展的范式，对生物识别安全具有重要影响，代码和数据集已公开。

Abstract: Morphing techniques generate artificial biometric samples that combine features from multiple individuals, allowing each contributor to be verified against a single enrolled template. While extensively studied in face recognition, this vulnerability remains largely unexplored in voice biometrics. Prior work on voice morphing is computationally expensive, non-scalable, and limited to acoustically similar identity pairs, constraining practical deployment. Moreover, existing sound-morphing methods target audio textures, music, or environmental sounds and are not transferable to voice identity manipulation. We propose VoxMorph, a zero-shot framework that produces high-fidelity voice morphs from as little as five seconds of audio per subject without model retraining. Our method disentangles vocal traits into prosody and timbre embeddings, enabling fine-grained interpolation of speaking style and identity. These embeddings are fused via Spherical Linear Interpolation (Slerp) and synthesized using an autoregressive language model coupled with a Conditional Flow Matching network. VoxMorph achieves state-of-the-art performance, delivering a 2.6x gain in audio quality, a 73% reduction in intelligibility errors, and a 67.8% morphing attack success rate on automated speaker verification systems under strict security thresholds. This work establishes a practical and scalable paradigm for voice morphing with significant implications for biometric security. The code and dataset are available on our project page: https://vcbsl.github.io/VoxMorph/

</details>


### [25] [SW-ASR: A Context-Aware Hybrid ASR Pipeline for Robust Single Word Speech Recognition](https://arxiv.org/abs/2601.20890)
*Manali Sharma,Riya Naik,Buvaneshwari G*

Main category: cs.SD

TL;DR: 提出模块化框架提升单词语音识别鲁棒性，结合降噪、混合ASR前端和验证层，在噪声和压缩音频上显著提升准确率


<details>
  <summary>Details</summary>
Motivation: 单词语音识别因缺乏语言上下文且对噪声、发音变化和信道伪影敏感而具有挑战性，特别是在医疗和应急响应等低资源、通信关键领域需要更鲁棒的解决方案

Method: 提出模块化框架：结合降噪和归一化处理，使用混合ASR前端（Whisper + Vosk），并设计验证层处理词汇外单词和降质音频，支持嵌入相似度、编辑距离和基于LLM的匹配等多种策略

Result: 在Google Speech Commands数据集和真实世界带宽受限数据集上评估，混合ASR前端在干净音频上表现良好，验证层在噪声和压缩信道上显著提升准确率，上下文引导和LLM匹配效果最佳

Conclusion: 轻量级验证和上下文机制能显著提升单词语音识别鲁棒性，同时满足实时电话应用的低延迟要求，为通信关键领域提供实用解决方案

Abstract: Single-word Automatic Speech Recognition (ASR) is a challenging task due to the lack of linguistic context and sensitivity to noise, pronunciation variation, and channel artifacts, especially in low-resource, communication-critical domains such as healthcare and emergency response. This paper reviews recent deep learning approaches and proposes a modular framework for robust single-word detection. The system combines denoising and normalization with a hybrid ASR front end (Whisper + Vosk) and a verification layer designed to handle out-of-vocabulary words and degraded audio. The verification layer supports multiple matching strategies, including embedding similarity, edit distance, and LLM-based matching with optional contextual guidance. We evaluate the framework on the Google Speech Commands dataset and a curated real-world dataset collected from telephony and messaging platforms under bandwidth-limited conditions. Results show that while the hybrid ASR front end performs well on clean audio, the verification layer significantly improves accuracy on noisy and compressed channels. Context-guided and LLM-based matching yield the largest gains, demonstrating that lightweight verification and context mechanisms can substantially improve single-word ASR robustness without sacrificing latency required for real-time telephony applications.

</details>


### [26] [A Study of Data Selection Strategies for Pre-training Self-Supervised Speech Models](https://arxiv.org/abs/2601.20896)
*Ryan Whetten,Titouan Parcollet,Marco Dinarelli,Yannick Estève*

Main category: cs.SD

TL;DR: 研究发现，在语音自监督学习中，数据长度比数据多样性或总量更重要，优先选择最长话语可减少50%数据量并提升24%训练效率，同时获得更好的ASR性能。


<details>
  <summary>Details</summary>
Motivation: 自监督学习在语音处理中取得了成功，但其依赖大规模预训练数据集成为瓶颈。虽然鲁棒性常归因于数据规模和多样性，但数据分布的具体作用尚不明确。本研究旨在系统探究预训练数据子集如何影响自动语音识别性能。

Method: 系统性地研究不同预训练数据子集对ASR性能的影响。比较了基于声学、说话人和语言多样性进行数据筛选的方法，并与随机采样和优先选择最长话语的策略进行对比。

Result: 令人惊讶的是，优化声学、说话人或语言多样性并未带来明显改进。相反，优先选择最长话语的策略在使用仅一半原始数据集的情况下获得了更好的ASR结果，并在大型语料库上减少了24%的预训练时间。

Conclusion: 对于语音自监督学习模型的预训练，数据长度比数据多样性或总体数据量更为关键，这为SSL语音处理中的数据选择策略提供了新视角，强调应优先考虑话语长度而非传统的数据多样性指标。

Abstract: Self-supervised learning (SSL) has transformed speech processing, yet its reliance on massive pre-training datasets remains a bottleneck. While robustness is often attributed to scale and diversity, the role of the data distribution is less understood. We systematically examine how curated subsets of pre-training data influence Automatic Speech Recognition (ASR) performance. Surprisingly, optimizing for acoustic, speaker, or linguistic diversity yields no clear improvements over random sampling. Instead, we find that prioritizing the longest utterances achieves superior ASR results while using only half the original dataset, reducing pre-training time by 24% on a large corpora. These findings suggest that for pre-training speech SSL models, data length is a more critical factor than either data diversity or overall data quantity for performance and efficiency, offering a new perspective for data selection strategies in SSL speech processing.

</details>


### [27] [Text-only adaptation in LLM-based ASR through text denoising](https://arxiv.org/abs/2601.20900)
*Sergio Burdisso,Esaú Villatoro-Tello,Andrés Carofilis,Shashi Kumar,Kadri Hacioglu,Srikanth Madikeri,Pradeep Rangappa,Manjunath K E,Petr Motlicek,Shankar Venkatesan,Andreas Stolcke*

Main category: cs.SD

TL;DR: 提出一种基于文本去噪任务的轻量级文本适配方法，用于LLM-ASR系统的新领域适配，无需架构修改或额外参数，在保持跨模态对齐的同时实现性能提升


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的ASR系统在新领域的文本适配是一个重要但未被充分探索的挑战。标准的LLM微调会破坏投影器学习的语音-文本模态对齐，导致性能下降

Method: 将音频投影任务模拟为文本去噪任务，训练LLM从噪声输入中恢复干净转录文本。这是一种轻量级方法，无需架构修改或额外参数

Result: 在两个数据集上的广泛评估显示相对改进高达22.1%，优于最近最先进的文本适配方法

Conclusion: 提出的文本去噪适配方法能有效适应目标领域，同时保持跨模态对齐，为LLM-ASR系统的文本适配提供了有效解决方案

Abstract: Adapting automatic speech recognition (ASR) systems based on large language models (LLMs) to new domains using text-only data is a significant yet underexplored challenge. Standard fine-tuning of the LLM on target-domain text often disrupts the critical alignment between speech and text modalities learned by the projector, degrading performance. We introduce a novel text-only adaptation method that emulates the audio projection task by treating it as a text denoising task. Our approach thus trains the LLM to recover clean transcripts from noisy inputs. This process effectively adapts the model to a target domain while preserving cross-modal alignment. Our solution is lightweight, requiring no architectural changes or additional parameters. Extensive evaluation on two datasets demonstrates up to 22.1% relative improvement, outperforming recent state-of-the-art text-only adaptation methods.

</details>


### [28] [PhaseCoder: Microphone Geometry-Agnostic Spatial Audio Understanding for Multimodal LLMs](https://arxiv.org/abs/2601.21124)
*Artem Dementyev,Wazeer Zulfikar,Sinan Hersek,Pascal Getreuer,Anurag Kumar,Vivek Kumar*

Main category: cs.SD

TL;DR: PhaseCoder是一个与麦克风几何无关的空间音频编码器，可将多通道音频转换为空间嵌入，使LLM能够进行空间推理和定向转录


<details>
  <summary>Details</summary>
Motivation: 当前多模态LLM将音频处理为单声道流，忽略了空间信息；现有空间音频模型受限于固定麦克风几何，无法跨设备部署

Method: 提出PhaseCoder，一个仅使用transformer的空间音频编码器，以原始多通道音频和麦克风坐标为输入，执行定位并生成鲁棒的空间嵌入

Result: 在麦克风无关的定位基准测试中达到SOTA；首次使LLM能够从任意麦克风阵列执行复杂空间推理和定向转录任务

Conclusion: PhaseCoder实现了与麦克风几何无关的空间音频编码，为LLM的空间推理能力开辟了新方向

Abstract: Current multimodal LLMs process audio as a mono stream, ignoring the rich spatial information essential for embodied AI. Existing spatial audio models, conversely, are constrained to fixed microphone geometries, preventing deployment across diverse devices. We present PhaseCoder, a transformer-only spatial audio encoder that is agnostic to microphone geometry. PhaseCoder takes raw multichannel audio and microphone coordinates as inputs to perform localization and produces robust spatial embeddings. We demonstrate that Gemma 3n LLM can be fine-tuned to reason over "Spatial Audio Tokens" produced by PhaseCoder. We show our encoder achieves state-of-the-art results on microphone-invariant localization benchmarks and, for the first time, enables an LLM to perform complex spatial reasoning and targeted transcription tasks from an arbitrary microphone array.

</details>


### [29] [Music Plagiarism Detection: Problem Formulation and a Segment-based Solution](https://arxiv.org/abs/2601.21260)
*Seonghyeon Go,Yumin Kim*

Main category: cs.SD

TL;DR: 该论文针对音乐抄袭检测任务缺乏明确定义的问题，提出了任务定义、创建了相似音乐对数据集，并提出了基于片段转录的解决方法。


<details>
  <summary>Details</summary>
Motivation: 音乐抄袭问题日益严重，但现有研究（包括作者先前工作）缺乏对音乐抄袭检测任务的明确定义，这阻碍了研究进展和实际应用。

Method: 1. 明确定义音乐抄袭检测任务，区分其与其他MIR任务的不同；2. 创建Similar Music Pair数据集支持该任务；3. 提出基于片段转录的解决方法。

Result: 建立了音乐抄袭检测的任务框架，提供了公开数据集，并展示了基于片段转录的方法作为解决方案示例。代码和数据集已在GitHub开源。

Conclusion: 通过明确定义音乐抄袭检测任务并提供相应数据集和方法，为后续研究奠定了基础，有助于推动该领域的发展和应用。

Abstract: Recently, the problem of music plagiarism has emerged as an even more pressing social issue. As music information retrieval research advances, there is a growing effort to address issues related to music plagiarism. However, many studies, including our previous work, have conducted research without clearly defining what the music plagiarism detection task actually involves. This lack of a clear definition has slowed research progress and made it hard to apply results to real-world scenarios. To fix this situation, we defined how Music Plagiarism Detection is different from other MIR tasks and explained what problems need to be solved. We introduce the Similar Music Pair dataset to support this newly defined task. In addition, we propose a method based on segment transcription as one way to solve the task. Our demo and dataset are available at https://github.com/Mippia/ICASSP2026-MPD.

</details>


### [30] [Understanding Frechet Speech Distance for Synthetic Speech Quality Evaluation](https://arxiv.org/abs/2601.21386)
*June-Woo Kim,Dhruv Agarwal,Federica Cerina*

Main category: cs.SD

TL;DR: 该论文全面评估了Fréchet Speech Distance (FSD)和Speech Maximum Mean Discrepancy (SMMD)作为合成语音质量客观评估指标的可靠性，发现WavLM Base+特征与人类评分最一致，这些指标可作为主观评估的补充工具。


<details>
  <summary>Details</summary>
Motivation: 合成语音质量的客观评估是一个关键挑战。人类听力测试是黄金标准，但成本高且难以大规模实施。Fréchet Distance已成为有前景的替代方案，但其可靠性严重依赖于嵌入特征选择和实验设置。

Method: 全面评估Fréchet Speech Distance (FSD)及其变体Speech Maximum Mean Discrepancy (SMMD)在不同嵌入特征和条件下的表现。同时结合人类听力评估、TTS可懂度和合成语音训练的ASR词错误率来验证这些指标的感知相关性。

Result: 研究发现WavLM Base+特征能产生与人类评分最稳定的对齐。虽然FSD和SMMD不能完全替代主观评估，但它们可以作为补充性的、成本效益高且可复现的度量标准，特别适用于大规模或直接听力评估不可行的情况。

Conclusion: FSD和SMMD不能完全替代主观评估，但可以作为有价值的补充工具，在无法进行大规模或直接听力评估时提供成本效益高且可复现的合成语音质量度量。

Abstract: Objective evaluation of synthetic speech quality remains a critical challenge. Human listening tests are the gold standard, but costly and impractical at scale. Fréchet Distance has emerged as a promising alternative, yet its reliability depends heavily on the choice of embeddings and experimental settings. In this work, we comprehensively evaluate Fréchet Speech Distance (FSD) and its variant Speech Maximum Mean Discrepancy (SMMD) under varied embeddings and conditions. We further incorporate human listening evaluations alongside TTS intelligibility and synthetic-trained ASR WER to validate the perceptual relevance of these metrics. Our findings show that WavLM Base+ features yield the most stable alignment with human ratings. While FSD and SMMD cannot fully replace subjective evaluation, we show that they can serve as complementary, cost-efficient, and reproducible measures, particularly useful when large-scale or direct listening assessments are infeasible. Code is available at https://github.com/kaen2891/FrechetSpeechDistance.

</details>


### [31] [Unifying Speech Editing Detection and Content Localization via Prior-Enhanced Audio LLMs](https://arxiv.org/abs/2601.21463)
*Jun Xue,Yi Chai,Yanzhen Ren,Jinshen He,Zhiqiang Tang,Zhuolin Yi,Yihuan Huang,Yuankun Xie,Yujie Chen*

Main category: cs.SD

TL;DR: 提出PELM框架，首个统一语音编辑检测与内容定位的大模型方法，通过音频问答任务实现，显著优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有检测方法主要针对手工编辑语音，难以应对端到端神经语音编辑技术，需要高质量数据集和更先进的检测框架

Method: 1) 构建大规模双语数据集AiEdit；2) 提出PELM框架，将检测和定位统一为音频问答任务；3) 引入词级概率先验和质心聚合声学一致性感知损失

Result: 在HumanEdit和AiEdit数据集上显著优于现有方法，定位EER分别达到0.57%和9.28%

Conclusion: PELM框架有效解决了神经语音编辑检测挑战，通过统一任务设计和偏差缓解机制，为语音编辑检测提供了新方向

Abstract: Speech editing achieves semantic inversion by performing fine-grained segment-level manipulation on original utterances, while preserving global perceptual naturalness. Existing detection studies mainly focus on manually edited speech with explicit splicing artifacts, and therefore struggle to cope with emerging end-to-end neural speech editing techniques that generate seamless acoustic transitions. To address this challenge, we first construct a large-scale bilingual dataset, AiEdit, which leverages large language models to drive precise semantic tampering logic and employs multiple advanced neural speech editing methods for data synthesis, thereby filling the gap of high-quality speech editing datasets. Building upon this foundation, we propose PELM (Prior-Enhanced Audio Large Language Model), the first large-model framework that unifies speech editing detection and content localization by formulating them as an audio question answering task. To mitigate the inherent forgery bias and semantic-priority bias observed in existing audio large models, PELM incorporates word-level probability priors to provide explicit acoustic cues, and further designs a centroid-aggregation-based acoustic consistency perception loss to explicitly enforce the modeling of subtle local distribution anomalies. Extensive experimental results demonstrate that PELM significantly outperforms state-of-the-art methods on both the HumanEdit and AiEdit datasets, achieving equal error rates (EER) of 0.57\% and 9.28\% (localization), respectively.

</details>


### [32] [Localizing Speech Deepfakes Beyond Transitions via Segment-Aware Learning](https://arxiv.org/abs/2601.21925)
*Yuchen Mao,Wen Huang,Yanmin Qian*

Main category: cs.SD

TL;DR: 提出Segment-Aware Learning (SAL)框架，通过Segment Positional Labeling和Cross-Segment Mixing技术，让模型关注篡改片段的内部结构而非仅边界特征，提升局部深度伪造音频定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有局部深度伪造音频定位方法主要依赖帧级预测和边界检测，但过度关注边界伪影而忽略篡改内容本身。需要让模型理解整个篡改片段而不仅仅是检测边界过渡。

Method: 提出SAL框架：1) Segment Positional Labeling - 基于片段内相对位置提供细粒度帧监督；2) Cross-Segment Mixing - 数据增强方法，生成多样化的片段模式。

Result: 在多个深度伪造定位数据集上，SAL在域内和跨域设置中均表现优异，在非边界区域有明显提升，减少了对过渡伪影的依赖。

Conclusion: SAL通过让模型关注篡改片段的内部结构而非仅边界特征，有效提升了局部深度伪造音频定位的性能和泛化能力。

Abstract: Localizing partial deepfake audio, where only segments of speech are manipulated, remains challenging due to the subtle and scattered nature of these modifications. Existing approaches typically rely on frame-level predictions to identify spoofed segments, and some recent methods improve performance by concentrating on the transitions between real and fake audio. However, we observe that these models tend to over-rely on boundary artifacts while neglecting the manipulated content that follows. We argue that effective localization requires understanding the entire segments beyond just detecting transitions. Thus, we propose Segment-Aware Learning (SAL), a framework that encourages models to focus on the internal structure of segments. SAL introduces two core techniques: Segment Positional Labeling, which provides fine-grained frame supervision based on relative position within a segment; and Cross-Segment Mixing, a data augmentation method that generates diverse segment patterns. Experiments across multiple deepfake localization datasets show that SAL consistently achieves strong performance in both in-domain and out-of-domain settings, with notable gains in non-boundary regions and reduced reliance on transition artifacts. The code is available at https://github.com/SentryMao/SAL.

</details>

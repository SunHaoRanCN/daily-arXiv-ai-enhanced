<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [eess.AS](#eess.AS) [Total: 9]
- [cs.SD](#cs.SD) [Total: 10]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Sparse Grassmannian Design for Noncoherent Codes via Schubert Cell Decomposition](https://arxiv.org/abs/2601.21009)
*Joe Asano,Yuto Hama,Hiroki Iimori,Chandan Pradhan,Szabolcs Malomsoky,Naoki Ishikawa*

Main category: eess.SP

TL;DR: 提出一种用于非相干MIMO系统的稀疏Grassmannian码设计方法，通过修正传统成对错误概率公式处理稀疏配置引起的秩缺陷问题，并推导出最大化非相干平均互信息的闭式度量。


<details>
  <summary>Details</summary>
Motivation: 传统基于非相关瑞利衰落信道的成对错误概率公式无法处理稀疏配置引起的秩缺陷问题，需要修正这些公式以统一处理此类情况。

Method: 利用Grassmann流形的Schubert胞分解提供的数学稀疏特性，建立稀疏非相干码的设计准则；修正传统成对错误概率公式处理秩缺陷问题；推导最大化非相干平均互信息的闭式度量。

Result: 提出的稀疏非相干码在符号错误率和平均互信息方面均优于传统方法，在高信噪比下渐近逼近最优Grassmannian星座性能；同时降低了时间和空间复杂度，且复杂度不随发射天线数量增加而增加。

Conclusion: 该方法成功解决了稀疏配置下的秩缺陷问题，设计的稀疏Grassmannian码在性能和复杂度方面均有显著优势，为非相干MIMO系统提供了有效的编码方案。

Abstract: In this paper, we propose a method for designing sparse Grassmannian codes for noncoherent multiple-input multiple-output systems. Conventional pairwise error probability formulations under uncorrelated Rayleigh fading channels fail to account for rank deficiency induced by sparse configurations. We revise these formulations to handle such cases in a unified manner. Furthermore, we derive a closed-form metric that effectively maximizes the noncoherent average mutual information (AMI) at a given signal-to-noise ratio. We focus on the fact that the Schubert cell decomposition of the Grassmann manifold provides a mathematically sparse property, and establish design criteria for sparse noncoherent codes based on our analyses. In numerical results, the proposed sparse noncoherent codes outperform conventional methods in terms of both symbol error rate and AMI, and asymptotically approach the performance of the optimal Grassmannian constellations in the high-signal-to-noise ratio regime. Moreover, they reduce the time and space complexity, which does not scale with the number of transmit antennas.

</details>


### [2] [Impact of Pointing Error on Coverage Performance of 3D Indoor Terahertz Communication Systems](https://arxiv.org/abs/2601.21303)
*Zhifeng Tang,Nan Yang,Xiangyun Zhou,Salman Durrani,Markku Juntti,Josep Miquel Jornet*

Main category: eess.SP

TL;DR: 本文开发了一个三维室内太赫兹通信系统的分析框架，评估指向误差对覆盖性能的影响，发现仅增加天线阵列尺寸不足以改善覆盖概率，需要先进的估计技术。


<details>
  <summary>Details</summary>
Motivation: 太赫兹通信系统中，发射机和接收机之间的波束成形增益和方向不匹配（指向误差）会对系统性能产生显著影响，需要建立理论分析框架来量化这种影响。

Method: 使用泊松点过程建模接入点位置，随机圆柱过程建模人体遮挡，布尔直线过程建模墙壁遮挡。基于位置估计不准确性表征指向误差，结合多簇波动双射线分布建模小尺度衰落，推导覆盖概率的解析表达式。

Result: 分析表明指向误差对覆盖概率有显著影响，仅增加天线阵列尺寸不足以改善覆盖性能，需要先进的估计技术来缓解指向误差的负面影响。

Conclusion: 太赫兹通信系统中指向误差是影响覆盖性能的关键因素，仅靠硬件改进（如增加天线阵列）不够，必须结合先进的估计技术才能有效提升系统性能。

Abstract: In this paper, we develop a tractable analytical framework for a three-dimensional (3D) indoor terahertz (THz) communication system to theoretically assess the impact of the pointing error on its coverage performance. Specifically, we model the locations of access points (APs) using a Poisson point process, human blockages as random cylinder processes, and wall blockages through a Boolean straight line process. A pointing error refers to beamforming gain and direction mismatch between the transmitter and receiver. We characterize it based on the inaccuracy of location estimate. We then analyze the impact of this pointing error on the received signal power and derive a tractable expression for the coverage probability, incorporating the multi-cluster fluctuating two-ray distribution to accurately model small-scale fading in THz communications. Aided by simulation results, we corroborate our analysis and demonstrate that the pointing error has a pronounced impact on the coverage probability. Specifically, we find that merely increasing the antenna array size is insufficient to improve the coverage probability and mitigate the detrimental impact of the pointing error, highlighting the necessity of advanced estimation techniques in THz communication systems.

</details>


### [3] [A Time-Domain Dual-Edge Asynchronous Pipelined SAR ADC Featuring Reset-Free Quantization at Multi-GS/s](https://arxiv.org/abs/2601.21308)
*Richard Zeng,Anthony Chan Carusone,Xilin Liu*

Main category: eess.SP

TL;DR: 提出双沿无复位量化技术，消除传统时域ADC的复位死区，提升高速ADC的分辨率、速度和能效


<details>
  <summary>Details</summary>
Motivation: 传统时域ADC需要在样本间进行显式复位，引入死区时间，限制了分辨率、速度和能效。需要消除复位阶段以扩展有效转换窗口

Method: 采用双沿无复位量化概念，利用上升沿和下降沿在单个转换周期内实现无复位量化。包括线性度补偿的双沿电压-时间转换器和可独立调谐上升/下降沿延迟的双沿时间-数字转换器

Result: 在22nm FD-SOI工艺中实现8位双沿异步流水线SAR时域ADC，核心面积0.0089 mm²。连续单通道工作在3.5 GS/s，间歇工作可达10.5 GS/s。在3.5 GS/s下实现21.6 dB SNDR和32.2 dB SFDR

Conclusion: 双沿无复位量化技术可行，性能主要受限于实现层面因素而非架构限制，为高速时域ADC提供了有前景的解决方案

Abstract: Time-domain ADCs are attractive for high-speed wireline receivers, as time resolution scales favorably with advanced CMOS technologies, enabling multi-GS/s single-channel sampling rates. However, conventional time-domain ADCs require explicit reset of voltage-to-time and time-domain signal paths between samples, introducing dead time that fundamentally limits resolution, speed, and energy efficiency. This paper introduces a dual-edge reset-free quantization concept for asynchronous pipelined SAR time-domain ADCs, in which both rising and falling signal edges are exploited to enable reset-free quantization within a single conversion period. By eliminating explicit reset phases, the proposed approach expands the effective conversion window and relaxes the resolution-speed tradeoff at high sampling rates. An 8-bit dual-edge asynchronous pipelined SAR time-domain ADC is implemented in 22-nm FD-SOI, incorporating a linearity-compensated dual-edge voltage-to-time converter and a dual-edge time-to-digital converter with independently tunable rising- and falling-edge delays. The prototype occupies a core area of 0.0089 mm^2 and achieves continuous single-channel operation at 3.5 GS/s, with architectural scalability demonstrated through intermittent operation at 10.5 GS/s and higher. At 3.5 GS/s, the ADC achieves 21.6 dB SNDR and 32.2 dB SFDR. The measured performance is primarily limited by identifiable implementation-level factors rather than by architectural constraints, demonstrating the feasibility of dual-edge reset-free quantization for high-speed time-domain ADCs.

</details>


### [4] [A Linearization of DFT Spectrum for Precision Power Measurement in Presence of Interharmonics](https://arxiv.org/abs/2601.21397)
*Jian Liu,Wei Zhao,Jianting Zhao,Shisong Li*

Main category: eess.SP

TL;DR: 提出基于DFT频谱分析的线性化算法，用于精确测量含间谐波电力系统的功率，通过构建线性方程组并高效求解，能准确提取基波和谐波附近的间谐波分量，显著降低估计误差。


<details>
  <summary>Details</summary>
Motivation: 电力系统中间谐波的存在会导致异步采样，加上基波频率偏移，会显著降低功率测量精度。在异步条件下，间谐波与基波和谐波分量失去正交性，产生额外的功率分量，因此需要开发精确的功率测量方法。

Method: 提出基于DFT频谱分析的线性化算法：从DFT频谱构建线性方程组，通过高效的矩阵运算求解，能够准确提取基波和谐波频率附近（频率间隔≥1Hz）的间谐波分量，从而精确测量基波、谐波、间谐波、交叉功率带以及总功率。

Result: 测试结果表明，该方法在不同条件下（包括变化的间谐波/基波/谐波间隔、基波频率偏差和噪声）都能准确计算各种功率分量。与FFT、加窗插值FFT和矩阵铅笔-奇异值分解等现有方法相比，估计误差降低数倍至多倍，鲁棒性更好，且处理10个工频周期（200ms）数据的计算时间仅为7ms。

Conclusion: 所提出的线性化算法能够有效解决含间谐波电力系统的功率测量问题，在保持计算效率的同时显著提高了测量精度和鲁棒性，为电力系统功率测量提供了一种有效的解决方案。

Abstract: The presence of interharmonics in power systems can lead to asynchronous sampling, a phenomenon further aggravated by shifts in the fundamental frequency, which significantly degrades the accuracy of power measurements. Under such asynchronous conditions, interharmonics lose orthogonality with the fundamental and harmonic components, giving rise to additional power components. To address these challenges, this paper introduces a linearization algorithm based on DFT spectrum analysis for precise power measurement in systems containing interharmonics. The proposed approach constructs a system of linear equations from the DFT spectrum and solves it through efficient matrix operations, enabling accurate extraction of interharmonic components near the fundamental and harmonic frequencies (with a frequency interval $\geq$1 Hz). This allows for precise measurement of power across the fundamental, harmonic, interharmonic, and cross-power bands, as well as total power. Test results demonstrate that the proposed method accurately computes various power components under diverse conditions--including varying interharmonic/fundamental/harmonic intervals, fundamental frequency deviations, and noise. Compared to existing methods such as fast Fourier transform (FFT), Windowed interpolation FFT, and Matrix pencil-Singular value decomposition, the proposed technique reduces estimation error by several times to multiple folds and exhibits improved robustness, while maintaining a computational time of only 7 ms for processing 10-power-line-cycle (200 ms) data.

</details>


### [5] [Interference Detection and Exploitation for Multi-User Radar Sensing](https://arxiv.org/abs/2601.21429)
*Laurits Randers,Martin Voigt Vejling,Petar Popovski*

Main category: eess.SP

TL;DR: 提出一种用于频谱交织OFDM多用户ISAC系统的干扰检测与利用算法，通过统计方法检测干扰并控制族错误率，同时利用干扰估计角度、避免干扰估计时延


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中，多用户场景下同时传输会在重叠频段产生相互干扰，导致虚假目标检测和感知精度下降，需要解决多用户ISAC系统中的干扰问题

Method: 采用频谱交织正交频分复用技术，提出统计严格的干扰检测程序控制族错误率，设计算法利用干扰估计角度，同时避免干扰估计时延

Result: 数值实验表明所提方法能可靠检测干扰，时延和角度估计误差接近克拉美罗下界

Conclusion: 该算法有效解决了多用户ISAC系统中的干扰问题，实现了高精度的感知性能

Abstract: Integrated sensing and communication is a key feature in next-generation wireless networks, enabling joint data transmission and environmental radar sensing on shared spectrum. In multi-user scenarios, simultaneous transmissions cause mutual interference on overlapping frequencies, leading to spurious target detections and degraded sensing accuracy. This paper proposes an interference detection and exploitation algorithm for sensing using spectrally interleaved orthogonal frequency division multiplexing. A statistically rigorous procedure is introduced to detect interference while controlling the familywise error rate. We propose an algorithm that estimates the angle by exploiting interference, while estimating the delay by avoiding the interference. Numerical experiments demonstrate that the proposed method reliably detects interference, and that the delay and angle estimation error approaches the Cramér-Rao lower bound.

</details>


### [6] [Compressed Sensing-Driven Near-Field Localization Exploiting Array of Subarrays](https://arxiv.org/abs/2601.21481)
*Sai Pavan Deram,Jacopo Pegoraro,Javier Lorca Hernando,Jesus O. Lacruz,Joerg Widmer*

Main category: eess.SP

TL;DR: SHARE是一种用于近场ISAC定位的两阶段稀疏恢复算法，通过分层处理解决稀疏子阵列架构中的栅瓣模糊问题，在保持大孔径高分辨率的同时降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 近场ISAC定位需要大孔径阵列，但全数字实现成本高、复杂度大。稀疏子阵列架构虽能降低成本，却会引入严重的栅瓣估计模糊问题。

Method: SHARE采用两阶段方法：第一阶段使用单个子阵列进行粗略、无模糊的角度估计以解决栅瓣模糊；第二阶段利用整个稀疏孔径进行局部化的联合角度-距离搜索。

Result: 仿真结果表明，SHARE在定位精度和鲁棒性方面显著优于传统的一步稀疏恢复方法（如OMP），其整体定位精度与全数字2D-MUSIC算法相当甚至更好，尽管MUSIC能够访问所有天线元素的完整数据。

Conclusion: SHARE为高分辨率近场ISAC系统提供了一条实用路径，在保持大孔径高分辨率优势的同时，通过分层处理解决了稀疏架构的栅瓣模糊问题，降低了计算复杂度。

Abstract: Near-field localization for ISAC requires large-aperture arrays, making fully-digital implementations prohibitively complex and costly. While sparse subarray architectures can reduce cost, they introduce severe estimation ambiguity from grating lobes. To address both issues, we propose SHARE (Sparse Hierarchical Angle-Range Estimation), a novel two-stage sparse recovery algorithm. SHARE operates in two stages. It first performs coarse, unambiguous angle estimation using individual subarrays to resolve the grating lobe ambiguity. It then leverages the full sparse aperture to perform a localized joint angle-range search. This hierarchical approach avoids an exhaustive and computationally intensive two-dimensional grid search while preserving the high resolution of the large aperture. Simulation results show that SHARE significantly outperforms conventional one-shot sparse recovery methods, such as Orthogonal Matching Pursuit (OMP), in both localization accuracy and robustness. Furthermore, we show that SHARE's overall localization accuracy is comparable to or even surpasses that of the fully-digital 2D-MUSIC algorithm, despite MUSIC having access to the complete, uncompressed data from every antenna element. SHARE therefore provides a practical path for high-resolution near-field ISAC systems.

</details>


### [7] [Channel Extrapolation for MIMO Systems with the Assistance of Multi-path Information Induced from Channel State Information](https://arxiv.org/abs/2601.21524)
*Yuan Gao,Xinyi Wu,Jiang Jun,Zitian Zhang,Zhaohui Yang,Shugong Xu,Cheng-Xiang Wang,Zhu Han*

Main category: eess.SP

TL;DR: 提出基于多径特征的CSI外推框架，通过CSI-to-PDP模块提取功率延迟谱特征，采用改进的MAE架构进行自监督学习，显著提升外推性能


<details>
  <summary>Details</summary>
Motivation: 6G网络中传统信道估计开销大，现有环境信息辅助方法存在硬件、隐私和多模态对齐问题，需要不依赖额外模态的CSI外推方案

Method: 1) CSI-to-PDP模块将CSI转换为功率延迟谱；2) 提取总功率和功率加权延迟作为多径特征；3) 改进的MAE架构：分离编码器处理掩码CSI和多径特征，通过交叉注意力融合

Result: 框架显著提升外推性能，推理时间仅增加约0.1ms，在已知CSI比例较小时表现出强泛化能力，优于现有基准方法

Conclusion: 提出的基于多径特征的CSI外推框架有效解决了6G网络中的CSI获取挑战，无需额外硬件且保护隐私，具有实际应用价值

Abstract: Acquiring channel state information (CSI) through traditional methods, such as channel estimation, is increasingly challenging for the emerging sixth generation (6G) mobile networks due to high overhead. To address this issue, channel extrapolation techniques have been proposed to acquire complete CSI from a limited number of known CSIs. To improve extrapolation accuracy, environmental information, such as visual images or radar data, has been utilized, which poses challenges including additional hardware, privacy and multi-modal alignment concerns. To this end, this paper proposes a novel channel extrapolation framework by leveraging environment-related multi-path characteristics induced directly from CSI without integrating additional modalities. Specifically, we propose utilizing the multi-path characteristics in the form of power-delay profile (PDP), which is acquired using a CSI-to-PDP module. CSI-to-PDP module is trained in an AE-based framework by reconstructing the PDPs and constraining the latent low-dimensional features to represent the CSI. We further extract the total power & power-weighted delay of all the identified paths in PDP as the multi-path information. Building on this, we proposed a MAE architecture trained in a self-supervised manner to perform channel extrapolation. Unlike standard MAE approaches, our method employs separate encoders to extract features from the masked CSI and the multi-path information, which are then fused by a cross-attention module. Extensive simulations demonstrate that this framework improves extrapolation performance dramatically, with a minor increase in inference time (around 0.1 ms). Furthermore, our model shows strong generalization capabilities, particularly when only a small portion of the CSI is known, outperforming existing benchmarks.

</details>


### [8] [Near-Field Positioning for XL-MIMO Uniform Circular Arrays: An Attention-Enhanced Deep Learning Approach](https://arxiv.org/abs/2601.21550)
*Yuan Gao,Xinyu Guo,Han Li,Jianbo Du,Shugong Xu*

Main category: eess.SP

TL;DR: 提出一种基于注意力增强深度学习的XL-MIMO精确定位方法，采用双路径通道注意力和空间注意力机制，在定位精度上超越现有基准模型。


<details>
  <summary>Details</summary>
Motivation: 6G移动通信中XL-MIMO系统天线数量激增，扩展了近场范围，挑战了传统远场假设。虽然UCA配置具有恒定角度分辨率优势，但如何利用扩展孔径和近场效应进行精确定位仍需深入研究。

Method: 提出注意力增强深度学习定位方法，采用双路径通道注意力机制和空间注意力机制，有效整合通道级和空间级特征，利用输入信号的协方差度量进行定位。

Result: 模型在综合仿真中超越了ABPN、NFLnet、CNN和MLP等现有基准，实现了更优的定位精度。仿真还显示协方差度量在定位精度和模型效率方面优于信道状态信息。

Conclusion: 提出的注意力增强深度学习模型能有效利用XL-MIMO系统的扩展孔径和近场效应，通过协方差度量实现高精度定位，为6G通信中的定位问题提供了有效解决方案。

Abstract: In the evolving landscape of sixth-generation (6G) mobile communication, multiple-input multiple-output (MIMO) systems are incorporating an unprecedented number of antenna elements, advancing towards Extremely large-scale multiple-input-multiple-output (XL-MIMO) systems. This enhancement significantly increases the spatial degrees of freedom, offering substantial benefits for wireless positioning. However, the expansion of the near-field range in XL-MIMO challenges the traditional far-field assumptions used in previous MIMO models. Among various configurations, uniform circular arrays (UCAs) demonstrate superior performance by maintaining constant angular resolution, unlike linear planar arrays. Addressing how to leverage the expanded aperture and harness the near-field effects in XL-MIMO systems remains an area requiring further investigation. In this paper, we introduce an attention-enhanced deep learning approach for precise positioning. We employ a dual-path channel attention mechanism and a spatial attention mechanism to effectively integrate channel-level and spatial-level features. Our comprehensive simulations show that this model surpasses existing benchmarks such as attention-based positioning networks (ABPN), near-field positioning networks (NFLnet), convolutional neural networks (CNN), and multilayer perceptrons (MLP). The proposed model achieves superior positioning accuracy by utilizing covariance metrics of the input signal. Also, simulation results reveal that covariance metric is advantageous for positioning over channel state information (CSI) in terms of positioning accuracy and model efficiency.

</details>


### [9] [VSE: Variational state estimation of complex model-free process](https://arxiv.org/abs/2601.21887)
*Gustav Norén,Anubhab Ghosh,Fredrik Cumlin,Saikat Chatterjee*

Main category: eess.SP

TL;DR: 提出一种变分状态估计方法，为无模型的复杂动态过程提供闭式高斯后验分布，使用RNN实现，在推理阶段计算简单，学习阶段通过两个RNN相互辅助基于变分推断原理学习。


<details>
  <summary>Details</summary>
Motivation: 针对无合适物理模型描述状态演化的复杂动态过程，需要从非线性测量中估计状态。传统方法需要已知系统模型，而实际应用中往往缺乏准确的物理模型。

Method: 设计变分状态估计方法，使用RNN提供闭式高斯后验分布。学习阶段采用两个RNN相互辅助，基于变分推断原理进行训练。推理阶段仅需单个RNN，计算简单。

Result: 在随机Lorenz系统跟踪应用中，VSE方法性能与已知系统模型的粒子滤波器相当，且优于最近提出的数据驱动状态估计方法。

Conclusion: 提出的变分状态估计方法能够有效处理无模型复杂动态过程的状态估计问题，在推理阶段计算效率高，性能优于现有数据驱动方法。

Abstract: We design a variational state estimation (VSE) method that provides a closed-form Gaussian posterior of an underlying complex dynamical process from (noisy) nonlinear measurements. The complex process is model-free. That is, we do not have a suitable physics-based model characterizing the temporal evolution of the process state. The closed-form Gaussian posterior is provided by a recurrent neural network (RNN). The use of RNN is computationally simple in the inference phase. For learning the RNN, an additional RNN is used in the learning phase. Both RNNs help each other learn better based on variational inference principles. The VSE is demonstrated for a tracking application - state estimation of a stochastic Lorenz system (a benchmark process) using a 2-D camera measurement model. The VSE is shown to be competitive against a particle filter that knows the Lorenz system model and a recently proposed data-driven state estimation method that does not know the Lorenz system model.

</details>


### [10] [Joint Laser Inter-Satellite Link Matching and Traffic Flow Routing in LEO Mega-Constellations via Lagrangian Duality](https://arxiv.org/abs/2601.21914)
*Zhouyou Gu,Jihong Park,Jinho Choi*

Main category: eess.SP

TL;DR: 本文研究了LEO巨型星座中激光星间链路的联合优化问题，考虑激光通信终端的机械限制和全球非均匀流量分布，通过拉格朗日对偶分解方法最大化星座吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有激光星间链路方案往往忽略激光通信终端的机械限制和全球非均匀流量分布（由用户和网关分布不均导致），导致吞吐量次优和激光通信终端/链路利用率不足，特别是当每颗卫星只携带少量激光通信终端时。

Method: 将问题建模为NP难的混合整数规划，通过拉格朗日对偶松弛耦合约束，分解为三个子问题：加权图匹配（用于激光通信终端连接）、加权最短路径路由任务和线性规划（用于速率分配）。使用次梯度下降优化拉格朗日乘子，具有可证明的收敛性。

Result: 使用真实世界星座和地面数据的仿真表明，相比现有非联合方法，本文方法将网络吞吐量提高了35%到145%。

Conclusion: 通过联合优化激光通信终端连接和流量路由，考虑实际机械限制和全球流量分布，可以显著提高LEO巨型星座的吞吐量，拉格朗日对偶分解方法为解决这一复杂优化问题提供了有效途径。

Abstract: Low Earth orbit (LEO) mega-constellations greatly extend the coverage and resilience of future wireless systems. Within the mega-constellations, laser inter-satellite links (LISLs) enable high-capacity, long-range connectivity. Existing LISL schemes often overlook mechanical limitations of laser communication terminals (LCTs) and non-uniform global traffic profiles caused by uneven user and gateway distributions, leading to suboptimal throughput and underused LCTs/LISLs -- especially when each satellite carries only a few LCTs. This paper investigates the joint optimization of LCT connections and traffic routing to maximize the constellation throughput, considering the realistic LCT mechanics and the global traffic profile. The problem is formulated as an NP-hard mixed-integer program coupling LCT connections with flow-rate variables under link capacity constraints. Due to its intractability, we resort to relaxing the coupling constraints via Lagrangian duality, decomposing the problem into a weighted graph-matching for LCT connections, weighted shortest-path routing tasks, and a linear program for rate allocation. Here, Lagrange multipliers reflect congestion weights between satellites, jointly guiding the matching, routing, and rate allocation. Subgradient descent optimizes the multipliers, with provable convergence. Simulations using real-world constellation and terrestrial data show that our methods substantially improve network throughput by up to $35\%$--$145\%$ over existing non-joint approaches.

</details>


### [11] [Duality-Guided Graph Learning for Real-Time Joint Connectivity and Routing in LEO Mega-Constellations](https://arxiv.org/abs/2601.21921)
*Zhouyou Gu,Jinho Choi,Tony Q. S. Quek,Jihong Park*

Main category: eess.SP

TL;DR: DeepLaDu：一种基于拉格朗日对偶引导的深度学习框架，用于实时优化低轨卫星星座中的激光星间链路连接、流量路由和速率分配，相比传统方法显著提升网络吞吐量并降低计算时间。


<details>
  <summary>Details</summary>
Motivation: 低轨巨型星座的激光星间链路（LISL）虽然能提供高容量骨干连接，但其管理面临激光通信终端有限、机械指向约束和网络拓扑快速变化等挑战。现有方法难以在动态环境中实时优化连接建立、流量路由和速率分配。

Method: 将问题建模为大规模时变星座图上的混合整数优化，提出拉格朗日对偶分解方法，将每链路对偶变量解释为协调连接和路由决策的拥塞价格。为克服迭代对偶更新的高延迟，开发了DeepLaDu框架，使用图神经网络通过单次前向传播直接从星座状态推断每链路拥塞价格，并采用基于次梯度的边级损失实现可扩展稳定训练。

Result: 在具有光学和流量约束的类星链星座模拟中，DeepLaDu相比非联合或启发式基线方法实现了高达20%的网络吞吐量提升，同时匹配迭代对偶优化的性能，但计算时间降低了几个数量级，适合动态低轨网络的实时操作。

Conclusion: DeepLaDu通过结合拉格朗日对偶理论和深度学习，为动态低轨卫星网络中的激光星间链路管理提供了一种高效、实时的优化解决方案，显著提升了网络性能并满足了实时操作需求。

Abstract: Laser inter-satellite links (LISLs) of low Earth orbit (LEO) mega-constellations enable high-capacity backbone connectivity in non-terrestrial networks, but their management is challenged by limited laser communication terminals, mechanical pointing constraints, and rapidly time-varying network topologies. This paper studies the joint problem of LISL connection establishment, traffic routing, and flow-rate allocation under heterogeneous global traffic demand and gateway availability. We formulate the problem as a mixed-integer optimization over large-scale, time-varying constellation graphs and develop a Lagrangian dual decomposition that interprets per-link dual variables as congestion prices coordinating connectivity and routing decisions. To overcome the prohibitive latency of iterative dual updates, we propose DeepLaDu, a Lagrangian duality-guided deep learning framework that trains a graph neural network (GNN) to directly infer per-link (edge-level) congestion prices from the constellation state in a single forward pass. We enable scalable and stable training using a subgradient-based edge-level loss in DeepLaDu. We analyze the convergence and computational complexity of the proposed approach and evaluate it using realistic Starlink-like constellations with optical and traffic constraints. Simulation results show that DeepLaDu achieves up to 20\% higher network throughput than non-joint or heuristic baselines, while matching the performance of iterative dual optimization with orders-of-magnitude lower computation time, suitable for real-time operation in dynamic LEO networks.

</details>


### [12] [Optimal Placement of Movable Antennas for Angle-of-Departure Estimation Under User Location Uncertainty](https://arxiv.org/abs/2601.21997)
*Lucía Pallarés-Rodríguez,Angelo Coluccia,Alessio Fascista,Musa Furkan Keskin,Henk Wymeersch,José A. López-Salcedo,Gonzalo Seco-Granados*

Main category: eess.SP

TL;DR: 该论文研究了在用户设备位置不确定情况下，使用基站可移动天线阵列进行出发角估计，通过理论性能分析和天线位置优化，展示了可移动天线系统相比固定阵列的优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统超大天线阵列存在成本和功耗限制，可移动天线（MA）能够克服这些限制。在用户设备（UE）位置不确定的情况下，需要研究如何利用MA阵列进行出发角（AoD）估计。

Method: 1) 通过克拉美-罗界（CRB）推导理论性能极限；2) 在UE不确定性区域内优化天线位置以确保鲁棒性能；3) 通过数值仿真验证优化效果。

Result: 数值结果表明，通过显式考虑不确定性区域来动态优化天线布局，相比固定阵列具有更优越的性能，证明了MA系统能够适应并超越传统阵列。

Conclusion: 可移动天线阵列在用户位置不确定场景下，通过优化天线位置能够显著提升出发角估计性能，展示了MA系统在实际应用中的适应性和优势。

Abstract: Movable antennas (MA) have gained significant attention in recent years to overcome the limitations of extremely large antenna arrays in terms of cost and power consumption. In this paper, we investigate the use of MA arrays at the base station (BS) for angle-of-departure (AoD) estimation under uncertainty in the user equipment (UE) location. Specifically, we (i) derive the theoretical performance limits through the Cramér-Rao bound (CRB) and (ii) optimize the antenna positions to ensure robust performance within the UE's uncertainty region. Numerical results show that dynamically optimizing antenna placement by explicitly considering the uncertainty region yields superior performance compared to fixed arrays, demonstrating the ability of MA systems to adapt and outperform conventional arrays.

</details>


### [13] [Towards Joint Optimization for UAV-Integrated RIS-Assisted Fluid Antenna Systems](https://arxiv.org/abs/2601.22109)
*Ali Reda,Tamer Mekkawy,Theodoros A. Tsiftsis,Chan-Byoung Chae,Kai-Kit Wong*

Main category: eess.SP

TL;DR: 提出了一种基于流体天线系统辅助可重构智能表面的无人机通信方案，通过联合优化天线端口位置和RIS相位偏移来最大化可达速率，显著提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 无人机集成到蜂窝网络中面临严重的空对地干扰问题，需要有效的解决方案来提升通信质量。

Method: 采用流体天线系统辅助的可重构智能表面，通过联合优化FAS端口位置和RIS相位偏移来最大化可达速率。使用基于二阶锥规划的逐次凸逼近方法解决非凸优化问题。

Result: 仿真结果表明，相比传统固定位置天线方案，所提算法显著改善了中断概率和可达速率，特别是在大规模RIS配置下增益更大，且算法收敛速度快，适合实时应用。

Conclusion: FAS辅助的RIS方案能有效提升无人机下行通信性能，为无人机蜂窝网络集成提供了有前景的解决方案。

Abstract: Unmanned aerial vehicles (UAVs) integrated into cellular networks face significant challenges from air-to-ground interference. To address this, we propose a downlink UAV communication system that leverages a fluid antenna system (FAS)- assisted reconfigurable intelligent surface (RIS) to enhance signal quality. By jointly optimizing the FAS port positions and RIS phase shifts, we maximize the achievable rate. The resulting nonconvex optimization problem is solved using successive convex approximation (SCA) based on second-order cone programming (SOCP), which reformulates the constraints into a tractable form. Simulation results show that the proposed algorithm significantly improves both outage probability and achievable rate over conventional fixed-position antenna (FPA) schemes, with particularly large gains in large-scale RIS configurations. Moreover, the algorithm converges rapidly, making it suitable for real-time applications

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [14] [Reducing Prompt Sensitivity in LLM-based Speech Recognition Through Learnable Projection](https://arxiv.org/abs/2601.20898)
*Sergio Burdisso,Esaú Villatoro-Tello,Shashi Kumar,Srikanth Madikeri,Andrés Carofilis,Pradeep Rangappa,Manjunath K E,Kadri Hacioglu,Petr Motlicek,Andreas Stolcke*

Main category: eess.AS

TL;DR: 本文分析了LLM-based ASR中提示词设计的影响，发现现有固定提示词在不同数据集上表现不稳定，提出了一种提示词投影模块来优化提示词嵌入，提升ASR性能并降低变异性。


<details>
  <summary>Details</summary>
Motivation: 当前LLM-based ASR系统通常使用固定的手动定义提示词，虽然适用于多种场景并能最大化模型性能，但提示词设计的影响尚未得到充分研究。不同提示词在不同数据集上的表现差异显著，且没有单一提示词在所有情况下都表现最佳，这导致了ASR性能的不稳定性。

Method: 受speech-to-LLM投影器的启发，提出了一个提示词投影模块。这是一个简单、模型无关的扩展，能够学习将提示词嵌入投影到LLM输入空间中更有效的区域，而不需要修改底层的LLM-based ASR模型。

Result: 在四个数据集上的实验表明，添加提示词投影模块能够：1）持续提升ASR性能；2）减少性能变异性；3）表现优于最佳手动选择的提示词。

Conclusion: 提示词设计对LLM-based ASR性能有显著影响，提出的提示词投影模块提供了一种有效的方法来优化提示词嵌入，提高ASR系统的稳定性和性能，且无需修改基础模型架构。

Abstract: LLM-based automatic speech recognition (ASR), a well-established approach, connects speech foundation models to large language models (LLMs) through a speech-to-LLM projector, yielding promising results. A common design choice in these architectures is the use of a fixed, manually defined prompt during both training and inference. This setup not only enables applicability across a range of practical scenarios, but also helps maximize model performance. However, the impact of prompt design remains underexplored. This paper presents a comprehensive analysis of commonly used prompts across diverse datasets, showing that prompt choice significantly affects ASR performance and introduces instability, with no single prompt performing best across all cases. Inspired by the speech-to-LLM projector, we propose a prompt projector module, a simple, model-agnostic extension that learns to project prompt embeddings to more effective regions of the LLM input space, without modifying the underlying LLM-based ASR model. Experiments on four datasets show that the addition of a prompt projector consistently improves performance, reduces variability, and outperforms the best manually selected prompts.

</details>


### [15] [Unseen but not Unknown: Using Dataset Concealment to Robustly Evaluate Speech Quality Estimation Models](https://arxiv.org/abs/2601.21110)
*Jaden Pieper,Stephen D. Voran*

Main category: eess.AS

TL;DR: DSC是一种评估语音质量估计模型的新方法，能分解研究结果与实际应用需求之间的性能差距，并通过数据集对齐器改善模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有语音质量估计模型在研究和实际应用之间存在性能差距，需要一种更严谨的方法来评估和解释模型性能，同时解决多数据集训练时的语料库效应问题。

Method: 提出数据集隐藏(DSC)评估框架，量化模型性能差距；使用AlignNet中的数据集对齐器处理多数据集训练；在MOSNet、NISQA和Wav2Vec2.0模型上进行验证，使用9个训练数据集和9个未见数据集。

Result: DSC能够提供模型泛化能力的可解释视图；仅1000参数的数据集对齐器显著改善了9400万参数Wav2Vec模型对未见数据的语音质量估计能力；允许充分利用所有可用数据进行训练。

Conclusion: DSC为语音质量估计模型提供了严谨的评估框架，数据集对齐器能有效提升模型泛化性能，为模型在实际应用中的表现提供了更好的理解和改进途径。

Abstract: We introduce Dataset Concealment (DSC), a rigorous new procedure for evaluating and interpreting objective speech quality estimation models. DSC quantifies and decomposes the performance gap between research results and real-world application requirements, while offering context and additional insights into model behavior and dataset characteristics. We also show the benefits of addressing the corpus effect by using the dataset Aligner from AlignNet when training models with multiple datasets. We demonstrate DSC and the improvements from the Aligner using nine training datasets and nine unseen datasets with three well-studied models: MOSNet, NISQA, and a Wav2Vec2.0-based model. DSC provides interpretable views of the generalization capabilities and limitations of models, while allowing all available data to be used at training. An additional result is that adding the 1000 parameter dataset Aligner to the 94 million parameter Wav2Vec model during training does significantly improve the resulting model's ability to estimate speech quality for unseen data.

</details>


### [16] [DNN-Based Online Source Counting Based on Spatial Generalized Magnitude Squared Coherence](https://arxiv.org/abs/2601.21114)
*Henri Gode,Simon Doclo*

Main category: eess.AS

TL;DR: 提出一种基于空间相干性的在线声源计数方法，通过检测声源数量变化来实现实时计数


<details>
  <summary>Details</summary>
Motivation: 声源数量是许多声学信号处理任务的关键参数，如声源定位、分离和多麦克风语音增强，需要在线实时计数方法

Method: 利用空间相干性原理，通过空间白化操作将声源计数问题转化为变化检测任务，使用广义幅度平方相干性作为特征，训练紧凑神经网络进行帧级声源数量变化检测

Result: 在混响场景下对双耳助听器进行仿真，最多4个说话人和背景噪声的实验结果表明该方法对在线声源计数有效

Conclusion: 提出的基于空间相干性的在线声源计数方法能够有效检测声源数量变化，适用于实时声学信号处理应用

Abstract: The number of active sound sources is a key parameter in many acoustic signal processing tasks, such as source localization, source separation, and multi-microphone speech enhancement. This paper proposes a novel method for online source counting by detecting changes in the number of active sources based on spatial coherence. The proposed method exploits the fact that a single coherent source in spatially white background noise yields high spatial coherence, whereas only noise results in low spatial coherence. By applying a spatial whitening operation, the source counting problem is reformulated as a change detection task, aiming to identify the time frames when the number of active sources changes. The method leverages the generalized magnitude-squared coherence as a measure to quantify spatial coherence, providing features for a compact neural network trained to detect source count changes framewise. Simulation results with binaural hearing aids in reverberant acoustic scenes with up to 4 speakers and background noise demonstrate the effectiveness of the proposed method for online source counting.

</details>


### [17] [Towards Robust Dysarthric Speech Recognition: LLM-Agent Post-ASR Correction Beyond WER](https://arxiv.org/abs/2601.21347)
*Xiuwen Zheng,Sixun Dong,Bornali Phukon,Mark Hasegawa-Johnson,Chang D. Yoo*

Main category: eess.AS

TL;DR: 提出基于LLM的法官-编辑代理，用于纠正构音障碍语音的ASR结果，并发布SAP-Hypo5基准测试集，在WER和语义指标上均取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 传统ASR以词错误率(WER)为基准，但实际应用更关注语义保真度。对于构音障碍语音，发音不精确和不流畅会导致严重的语义失真，需要更好的纠正方法。

Method: 设计基于大语言模型(LLM)的法官-编辑代理，对ASR的top-k假设进行后处理：保留高置信度片段，重写不确定部分，支持零样本和微调两种模式。

Result: 在多视角评估中，代理实现14.51%的WER降低，语义指标显著提升：MENLI提高7.59个百分点，Slot Micro F1提高7.66个百分点。分析显示WER对领域转移敏感，而语义指标与下游任务性能更相关。

Conclusion: LLM-based法官-编辑代理能有效纠正构音障碍语音的ASR结果，同时发布SAP-Hypo5基准测试集促进可重复性和未来研究，强调语义保真度比WER更能反映实际应用性能。

Abstract: While Automatic Speech Recognition (ASR) is typically benchmarked by word error rate (WER), real-world applications ultimately hinge on semantic fidelity. This mismatch is particularly problematic for dysarthric speech, where articulatory imprecision and disfluencies can cause severe semantic distortions. To bridge this gap, we introduce a Large Language Model (LLM)-based agent for post-ASR correction: a Judge-Editor over the top-k ASR hypotheses that keeps high-confidence spans, rewrites uncertain segments, and operates in both zero-shot and fine-tuned modes. In parallel, we release SAP-Hypo5, the largest benchmark for dysarthric speech correction, to enable reproducibility and future exploration. Under multi-perspective evaluation, our agent achieves a 14.51% WER reduction alongside substantial semantic gains, including a +7.59 pp improvement in MENLI and +7.66 pp in Slot Micro F1 on challenging samples. Our analysis further reveals that WER is highly sensitive to domain shift, whereas semantic metrics correlate more closely with downstream task performance.

</details>


### [18] [SemanticAudio: Audio Generation and Editing in Semantic Space](https://arxiv.org/abs/2601.21402)
*Zheqi Dai,Guangyan Zhang,Haolin He,Xiquan Li,Jingyu Li,Chunyat Wu,Yiwen Guo,Qiuqiang Kong*

Main category: eess.AS

TL;DR: 提出SemanticAudio框架，在高层语义空间进行音频生成和编辑，通过两阶段Flow Matching架构实现更好的语义对齐


<details>
  <summary>Details</summary>
Motivation: 现有文本到音频生成模型主要在声学潜在空间操作，导致生成音频与文本描述之间的语义对齐不理想

Method: 采用两阶段Flow Matching架构：语义规划器生成紧凑的语义特征（捕捉声音事件的全局身份和时间序列），声学合成器基于语义规划生成高保真声学潜在表示

Result: 实验表明SemanticAudio在语义对齐方面超越现有主流方法，并实现了无需训练的文本引导编辑机制

Conclusion: 在高层语义空间进行音频生成和编辑能显著改善语义对齐，为音频创作提供更精确的控制能力

Abstract: In recent years, Text-to-Audio Generation has achieved remarkable progress, offering sound creators powerful tools to transform textual inspirations into vivid audio. However, existing models predominantly operate directly in the acoustic latent space of a Variational Autoencoder (VAE), often leading to suboptimal alignment between generated audio and textual descriptions. In this paper, we introduce SemanticAudio, a novel framework that conducts both audio generation and editing directly in a high-level semantic space. We define this semantic space as a compact representation capturing the global identity and temporal sequence of sound events, distinct from fine-grained acoustic details. SemanticAudio employs a two-stage Flow Matching architecture: the Semantic Planner first generates these compact semantic features to sketch the global semantic layout, and the Acoustic Synthesizer subsequently produces high-fidelity acoustic latents conditioned on this semantic plan. Leveraging this decoupled design, we further introduce a training-free text-guided editing mechanism that enables precise attribute-level modifications on general audio without retraining. Specifically, this is achieved by steering the semantic generation trajectory via the difference of velocity fields derived from source and target text prompts. Extensive experiments demonstrate that SemanticAudio surpasses existing mainstream approaches in semantic alignment. Demo available at: https://semanticaudio1.github.io/

</details>


### [19] [Representation-Regularized Convolutional Audio Transformer for Audio Understanding](https://arxiv.org/abs/2601.21612)
*Bing Han,Chushu Zhou,Yifan Yang,Wei Wang,Chenda Li,Wangyou Zhang,Yanmin Qian*

Main category: eess.AS

TL;DR: 提出Convolutional Audio Transformer (CAT)框架，通过多分辨率块和表示正则化目标，在音频理解任务中实现更快的收敛和更好的性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法通常只在单一粒度上操作，难以捕捉音频信号中多样的时频结构特征，且从零开始训练表示计算成本高、收敛慢。

Method: 1) 多分辨率块：聚合不同粒度的层次化音频特征；2) 表示正则化目标：利用预训练外部编码器的高质量语义表示来指导学生模型，提升训练效率。

Result: 在音频理解基准测试中显著优于基线方法，在AudioSet 20k数据集上达到竞争性性能，且收敛速度比现有方法快5倍。

Conclusion: CAT框架通过多粒度特征提取和表示正则化，有效解决了音频自监督学习中的粒度单一和训练效率问题，为音频理解任务提供了高效解决方案。

Abstract: Bootstrap-based Self-Supervised Learning (SSL) has achieved remarkable progress in audio understanding. However, existing methods typically operate at a single level of granularity, limiting their ability to model the diverse temporal and spectral structures inherent in complex audio signals. Furthermore, bootstrapping representations from scratch is computationally expensive, often requiring extensive training to converge. In this work, we propose the Convolutional Audio Transformer (CAT), a unified framework designed to address these challenges. First, to capture hierarchical audio features, CAT incorporates a Multi-resolution Block that aggregates information across varying granularities. Second, to enhance training efficiency, we introduce a Representation Regularization objective. Drawing inspiration from generative modeling, this auxiliary task guides the student model by aligning its predictions with high-quality semantic representations from frozen, pre-trained external encoders. Experimental results demonstrate that CAT significantly outperforms baselines on audio understanding benchmarks. Notably, it achieves competitive performance on the AudioSet 20k dataset with 5 times faster convergence than existing methods. Codes and checkpoints will be released soon at https://github.com/realzhouchushu/CAT.

</details>


### [20] [Speech Quality-Based Localization of Low-Quality Speech and Text-to-Speech Synthesis Artefacts](https://arxiv.org/abs/2601.21886)
*Michael Kuhlmann,Alexander Werning,Thilo von Neumann,Reinhold Haeb-Umbach*

Main category: eess.AS

TL;DR: 论文提出使用基于片段的连续性约束来正则化话语级语音质量预测器，减少帧级随机性，并展示了帧级评分在部分欺骗场景和检测TTS系统合成伪影中的应用。


<details>
  <summary>Details</summary>
Motivation: 当前语音质量自动评估主要关注话语级或系统级，虽然能判断整体质量，但无法解释具体评分原因。帧级评分能提供更好的可解释性，但缺乏训练时的强目标，模型难以调优和正则化。

Method: 提出使用基于片段的连续性约束来正则化话语级语音质量预测器，减少帧级随机性。然后展示了帧级评分在两个应用场景中的使用：部分欺骗场景和检测最先进文本转语音系统的合成伪影。

Result: 基于片段的连续性约束显著减少了帧级随机性。在TTS系统合成伪影检测中，听觉测试证实听众在低帧级评分定义的片段中更频繁地评价为低质量，相比随机对照组。

Conclusion: 通过片段连续性约束正则化话语级质量预测器可以有效减少帧级随机性，帧级评分在语音质量评估中具有实际应用价值，特别是在部分欺骗检测和TTS系统伪影识别方面。

Abstract: A large number of works view the automatic assessment of speech from an utterance- or system-level perspective. While such approaches are good in judging overall quality, they cannot adequately explain why a certain score was assigned to an utterance. frame-level scores can provide better interpretability, but models predicting them are harder to tune and regularize since no strong targets are available during training. In this work, we show that utterance-level speech quality predictors can be regularized with a segment-based consistency constraint which notably reduces frame-level stochasticity. We then demonstrate two applications involving frame-level scores: The partial spoof scenario and the detection of synthesis artefacts in two state-of-the-art text-to-speech systems. For the latter, we perform listening tests and confirm that listeners rate segments to be of poor quality more often in the set defined by low frame-level scores than in a random control set.

</details>


### [21] [DisContSE: Single-Step Diffusion Speech Enhancement Based on Joint Discrete and Continuous Embeddings](https://arxiv.org/abs/2601.21940)
*Yihui Fu,Tim Fingscheidt*

Main category: eess.AS

TL;DR: 提出DisContSE模型，结合离散音频编解码器token和连续嵌入的扩散语音增强方法，实现单步高效推理，在多个指标上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于离散音频编解码特征的扩散语音增强方法存在两个主要问题：1）推理计算复杂度高，需要多次反向迭代；2）在非侵入式指标表现好但侵入式指标表现差，难以准确重建音素。

Method: 提出DisContSE模型，包含三个核心模块：1）离散增强模块处理离散音频编解码token；2）连续增强模块处理连续嵌入；3）语义增强模块优化音素准确性。采用量化误差掩码初始化策略实现单步高效反向过程。

Result: 在URGENT 2024语音增强挑战数据集上，DisContSE在PESQ、POLQA、UTMOS等指标和主观ITU-T P.808听力测试中均超越现有时域和频域扩散基线方法，取得总体最佳排名。

Conclusion: DisContSE通过结合离散和连续表示，并引入语义增强模块，在保持高效单步推理的同时，显著提升了语音增强的保真度和可懂度，是首个基于音频编解码的成功单步扩散语音增强方法。

Abstract: Diffusion speech enhancement on discrete audio codec features gain immense attention due to their improved speech component reconstruction capability. However, they usually suffer from high inference computational complexity due to multiple reverse process iterations. Furthermore, they generally achieve promising results on non-intrusive metrics but show poor performance on intrusive metrics, as they may struggle in reconstructing the correct phones. In this paper, we propose DisContSE, an efficient diffusion-based speech enhancement model on joint discrete codec tokens and continuous embeddings. Our contributions are three-fold. First, we formulate both a discrete and a continuous enhancement module operating on discrete audio codec tokens and continuous embeddings, respectively, to achieve improved fidelity and intelligibility simultaneously. Second, a semantic enhancement module is further adopted to achieve optimal phonetic accuracy. Third, we achieve a single-step efficient reverse process in inference with a novel quantization error mask initialization strategy, which, according to our knowledge, is the first successful single-step diffusion speech enhancement based on an audio codec. Trained and evaluated on URGENT 2024 Speech Enhancement Challenge data splits, the proposed DisContSE excels top-reported time- and frequency-domain diffusion baseline methods in PESQ, POLQA, UTMOS, and in a subjective ITU-T P.808 listening test, clearly achieving an overall top rank.

</details>


### [22] [TidyVoice 2026 Challenge Evaluation Plan](https://arxiv.org/abs/2601.21960)
*Aref Farhadipour,Jan Marquenie,Srikanth Madikeri,Teodora Vukovic,Volker Dellwo,Kathy Reid,Francis M. Tyers,Ingo Siegert,Eleanor Chodroff*

Main category: eess.AS

TL;DR: 提出TidyVoice挑战赛，针对跨语言说话人验证中的语言不匹配问题，使用TidyVoiceX数据集在约40种语言上进行评估，旨在推动更公平、包容的语言无关说话人识别技术。


<details>
  <summary>Details</summary>
Motivation: 说话人验证系统在语言不匹配时性能显著下降，而该领域过度依赖英语中心数据，需要解决跨语言场景下的公平性和包容性问题。

Method: 提出TidyVoice挑战赛，使用来自TidyVoice基准测试的TidyVoiceX数据集，这是一个基于Mozilla Common Voice的大规模多语言语料库，专门设计用于隔离约40种语言切换的影响。

Result: 挑战赛提供标准化数据、开源基线系统和严格的评估协议，主要使用跨语言试验的等错误率评估性能，参与者需要构建对语言不匹配鲁棒的系统。

Conclusion: 该挑战赛旨在推动研究朝着更公平、包容和语言无关的说话人识别技术发展，直接契合Interspeech 2026"Speaking Together"主题。

Abstract: The performance of speaker verification systems degrades significantly under language mismatch, a critical challenge exacerbated by the field's reliance on English-centric data. To address this, we propose the TidyVoice Challenge for cross-lingual speaker verification. The challenge leverages the TidyVoiceX dataset from the novel TidyVoice benchmark, a large-scale, multilingual corpus derived from Mozilla Common Voice, and specifically curated to isolate the effect of language switching across approximately 40 languages. Participants will be tasked with building systems robust to this mismatch, with performance primarily evaluated using the Equal Error Rate on cross-language trials. By providing standardized data, open-source baselines, and a rigorous evaluation protocol, this challenge aims to drive research towards fairer, more inclusive, and language-independent speaker recognition technologies, directly aligning with the Interspeech 2026 theme, "Speaking Together."

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [23] [Generalizable Prompt Tuning for Audio-Language Models via Semantic Expansion](https://arxiv.org/abs/2601.20867)
*Jaehyuk Jang,Wonjun Lee,Kangwook Ko,Changick Kim*

Main category: cs.SD

TL;DR: SEPT提出了一种语义扩展提示调优框架，通过引入LLM生成的语义邻居来正则化提示嵌入空间，解决音频语言模型中基类-新类权衡问题，提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统提示调优在音频语言模型（ALMs）中存在基类-新类权衡问题，这源于嵌入空间语义结构的破坏。目前ALMs中提示调优的泛化能力尚未得到充分探索。

Method: 提出SEPT框架：1）使用大语言模型生成语义邻居；2）引入带边界约束的语义扩展损失，促进类内紧凑性和类间分离性；3）建立首个ALMs提示泛化基准，涵盖基类到新类泛化和跨数据集可迁移性。

Result: 实验表明SEPT能持续提升多个提示调优基线的泛化性能，同时保持推理时的计算成本不变。在基类-新类泛化和跨数据集迁移任务上均表现优异。

Conclusion: SEPT通过语义扩展正则化有效解决了ALMs中的基类-新类权衡问题，显著提升了提示调优的泛化能力，为ALMs提示调优研究提供了新的基准框架。

Abstract: Prompt tuning has achieved remarkable progress in vision-language models (VLMs) and is recently being adopted for audio-language models (ALMs). However, its generalization ability in ALMs remains largely underexplored. We observe that conventional prompt tuning for ALMs also suffers from the Base-New Tradeoff, and we identify that this issue stems from the disrupted semantic structure of the embedding space. To address this issue, we propose Semantically Expanded Prompt Tuning (SEPT)-a plug-and-play framework that explicitly regularizes the prompt embedding space by incorporating semantic neighbors generated by large language models. SEPT introduces a novel semantic expansion loss with margin constraints that promote intra-class compactness and inter-class separability, thereby enhancing the semantic structure of the prompt embedding space. For comprehensive evaluation, we establish the first benchmark setup for prompt generalization in ALMs, covering both base-to-new generalization and cross-dataset transferability. Extensive experiments demonstrate that SEPT consistently improves generalization performance across multiple prompt tuning baselines, while maintaining computational cost during inference. Codes are available in https://github.com/jhyukjang/SEPT.

</details>


### [24] [VoxMorph: Scalable Zero-shot Voice Identity Morphing via Disentangled Embeddings](https://arxiv.org/abs/2601.20883)
*Bharath Krishnamurthy,Ajita Rattani*

Main category: cs.SD

TL;DR: VoxMorph是一个零样本语音变形框架，仅需每人5秒音频即可生成高质量语音变形，在语音生物识别系统中实现67.8%的攻击成功率


<details>
  <summary>Details</summary>
Motivation: 语音生物识别中的变形攻击研究不足，现有方法计算成本高、可扩展性差且仅限于声学相似的身份对，缺乏实用的语音身份操纵方法

Method: 将语音特征解耦为韵律和音色嵌入，通过球面线性插值融合，使用自回归语言模型和条件流匹配网络合成语音

Result: 音频质量提升2.6倍，可懂度错误减少73%，在严格安全阈值下对自动说话人验证系统的变形攻击成功率达到67.8%

Conclusion: VoxMorph建立了实用且可扩展的语音变形范式，对生物识别安全有重要影响

Abstract: Morphing techniques generate artificial biometric samples that combine features from multiple individuals, allowing each contributor to be verified against a single enrolled template. While extensively studied in face recognition, this vulnerability remains largely unexplored in voice biometrics. Prior work on voice morphing is computationally expensive, non-scalable, and limited to acoustically similar identity pairs, constraining practical deployment. Moreover, existing sound-morphing methods target audio textures, music, or environmental sounds and are not transferable to voice identity manipulation. We propose VoxMorph, a zero-shot framework that produces high-fidelity voice morphs from as little as five seconds of audio per subject without model retraining. Our method disentangles vocal traits into prosody and timbre embeddings, enabling fine-grained interpolation of speaking style and identity. These embeddings are fused via Spherical Linear Interpolation (Slerp) and synthesized using an autoregressive language model coupled with a Conditional Flow Matching network. VoxMorph achieves state-of-the-art performance, delivering a 2.6x gain in audio quality, a 73% reduction in intelligibility errors, and a 67.8% morphing attack success rate on automated speaker verification systems under strict security thresholds. This work establishes a practical and scalable paradigm for voice morphing with significant implications for biometric security. The code and dataset are available on our project page: https://vcbsl.github.io/VoxMorph/

</details>


### [25] [SW-ASR: A Context-Aware Hybrid ASR Pipeline for Robust Single Word Speech Recognition](https://arxiv.org/abs/2601.20890)
*Manali Sharma,Riya Naik,Buvaneshwari G*

Main category: cs.SD

TL;DR: 提出一个用于鲁棒单词语音识别的模块化框架，结合去噪、混合ASR前端和验证层，在噪声和压缩音频上显著提升准确率。


<details>
  <summary>Details</summary>
Motivation: 单词语音识别因缺乏语言上下文且对噪声、发音变化和信道伪影敏感而具有挑战性，在医疗和应急响应等低资源通信关键领域尤其困难。

Method: 提出模块化框架：结合去噪和归一化、混合ASR前端（Whisper + Vosk）以及验证层。验证层支持多种匹配策略，包括嵌入相似性、编辑距离和基于LLM的匹配（可选上下文引导）。

Result: 在Google Speech Commands数据集和真实世界电话/消息平台数据集上评估。混合ASR前端在干净音频上表现良好，验证层在噪声和压缩信道上显著提升准确率。上下文引导和LLM匹配带来最大增益。

Conclusion: 轻量级验证和上下文机制可在不牺牲实时电话应用延迟的情况下，显著提高单词语音识别的鲁棒性。

Abstract: Single-word Automatic Speech Recognition (ASR) is a challenging task due to the lack of linguistic context and sensitivity to noise, pronunciation variation, and channel artifacts, especially in low-resource, communication-critical domains such as healthcare and emergency response. This paper reviews recent deep learning approaches and proposes a modular framework for robust single-word detection. The system combines denoising and normalization with a hybrid ASR front end (Whisper + Vosk) and a verification layer designed to handle out-of-vocabulary words and degraded audio. The verification layer supports multiple matching strategies, including embedding similarity, edit distance, and LLM-based matching with optional contextual guidance. We evaluate the framework on the Google Speech Commands dataset and a curated real-world dataset collected from telephony and messaging platforms under bandwidth-limited conditions. Results show that while the hybrid ASR front end performs well on clean audio, the verification layer significantly improves accuracy on noisy and compressed channels. Context-guided and LLM-based matching yield the largest gains, demonstrating that lightweight verification and context mechanisms can substantially improve single-word ASR robustness without sacrificing latency required for real-time telephony applications.

</details>


### [26] [A Study of Data Selection Strategies for Pre-training Self-Supervised Speech Models](https://arxiv.org/abs/2601.20896)
*Ryan Whetten,Titouan Parcollet,Marco Dinarelli,Yannick Estève*

Main category: cs.SD

TL;DR: 研究发现，在语音自监督学习中，数据长度比数据多样性或总量更重要，优先选择最长的话语可以仅用一半数据获得更好的ASR性能，减少24%预训练时间


<details>
  <summary>Details</summary>
Motivation: 自监督学习在语音处理中取得了突破，但依赖大规模预训练数据集仍是瓶颈。虽然鲁棒性通常归因于数据规模和多样性，但数据分布的作用尚不清楚。本研究旨在系统探究预训练数据子集如何影响自动语音识别性能

Method: 系统性地研究预训练数据子集对ASR性能的影响，比较了针对声学、说话人或语言多样性的数据选择策略与随机采样的效果

Result: 令人惊讶的是，优化声学、说话人或语言多样性并未带来明显改进。相反，优先选择最长的话语能在仅使用一半原始数据集的情况下获得更好的ASR结果，并在大型语料库上减少24%的预训练时间

Conclusion: 对于语音SSL模型的预训练，数据长度是比数据多样性或总体数据量更关键的因素，为SSL语音处理中的数据选择策略提供了新视角

Abstract: Self-supervised learning (SSL) has transformed speech processing, yet its reliance on massive pre-training datasets remains a bottleneck. While robustness is often attributed to scale and diversity, the role of the data distribution is less understood. We systematically examine how curated subsets of pre-training data influence Automatic Speech Recognition (ASR) performance. Surprisingly, optimizing for acoustic, speaker, or linguistic diversity yields no clear improvements over random sampling. Instead, we find that prioritizing the longest utterances achieves superior ASR results while using only half the original dataset, reducing pre-training time by 24% on a large corpora. These findings suggest that for pre-training speech SSL models, data length is a more critical factor than either data diversity or overall data quantity for performance and efficiency, offering a new perspective for data selection strategies in SSL speech processing.

</details>


### [27] [Text-only adaptation in LLM-based ASR through text denoising](https://arxiv.org/abs/2601.20900)
*Sergio Burdisso,Esaú Villatoro-Tello,Andrés Carofilis,Shashi Kumar,Kadri Hacioglu,Srikanth Madikeri,Pradeep Rangappa,Manjunath K E,Petr Motlicek,Shankar Venkatesan,Andreas Stolcke*

Main category: cs.SD

TL;DR: 提出一种基于文本去噪任务的文本自适应方法，用于LLM-ASR系统的新领域适应，无需修改架构或增加参数，在保持跨模态对齐的同时显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的ASR系统使用纯文本数据进行新领域适应是一个重要但研究不足的挑战。传统的LLM微调会破坏投影器学习到的语音-文本模态对齐，导致性能下降。

Method: 提出新颖的文本自适应方法，将音频投影任务模拟为文本去噪任务。通过训练LLM从噪声输入中恢复干净转录本，在适应目标领域的同时保持跨模态对齐。该方法轻量级，无需架构修改或额外参数。

Result: 在两个数据集上的广泛评估显示相对改进高达22.1%，优于最近最先进的文本自适应方法。

Conclusion: 该方法有效解决了LLM-ASR系统的文本自适应问题，通过文本去噪任务模拟音频投影，在保持模态对齐的同时实现领域适应，为ASR系统的新领域部署提供了实用解决方案。

Abstract: Adapting automatic speech recognition (ASR) systems based on large language models (LLMs) to new domains using text-only data is a significant yet underexplored challenge. Standard fine-tuning of the LLM on target-domain text often disrupts the critical alignment between speech and text modalities learned by the projector, degrading performance. We introduce a novel text-only adaptation method that emulates the audio projection task by treating it as a text denoising task. Our approach thus trains the LLM to recover clean transcripts from noisy inputs. This process effectively adapts the model to a target domain while preserving cross-modal alignment. Our solution is lightweight, requiring no architectural changes or additional parameters. Extensive evaluation on two datasets demonstrates up to 22.1% relative improvement, outperforming recent state-of-the-art text-only adaptation methods.

</details>


### [28] [PhaseCoder: Microphone Geometry-Agnostic Spatial Audio Understanding for Multimodal LLMs](https://arxiv.org/abs/2601.21124)
*Artem Dementyev,Wazeer Zulfikar,Sinan Hersek,Pascal Getreuer,Anurag Kumar,Vivek Kumar*

Main category: cs.SD

TL;DR: PhaseCoder是一个与麦克风几何无关的空间音频编码器，可将多通道音频转换为空间嵌入，使LLM能够进行空间推理


<details>
  <summary>Details</summary>
Motivation: 当前多模态LLM将音频处理为单声道流，忽略了空间信息；现有空间音频模型受限于固定麦克风几何结构，无法跨设备部署

Method: PhaseCoder是一个纯Transformer架构的空间音频编码器，以原始多通道音频和麦克风坐标为输入，执行定位并生成鲁棒的空间嵌入

Result: 在麦克风不变定位基准测试中达到最先进水平，首次使LLM能够从任意麦克风阵列执行复杂空间推理和定向转录任务

Conclusion: PhaseCoder解决了现有方法的局限性，实现了与麦克风几何无关的空间音频编码，为具身AI提供了重要的空间感知能力

Abstract: Current multimodal LLMs process audio as a mono stream, ignoring the rich spatial information essential for embodied AI. Existing spatial audio models, conversely, are constrained to fixed microphone geometries, preventing deployment across diverse devices. We present PhaseCoder, a transformer-only spatial audio encoder that is agnostic to microphone geometry. PhaseCoder takes raw multichannel audio and microphone coordinates as inputs to perform localization and produces robust spatial embeddings. We demonstrate that Gemma 3n LLM can be fine-tuned to reason over "Spatial Audio Tokens" produced by PhaseCoder. We show our encoder achieves state-of-the-art results on microphone-invariant localization benchmarks and, for the first time, enables an LLM to perform complex spatial reasoning and targeted transcription tasks from an arbitrary microphone array.

</details>


### [29] [Music Plagiarism Detection: Problem Formulation and a Segment-based Solution](https://arxiv.org/abs/2601.21260)
*Seonghyeon Go,Yumin Kim*

Main category: cs.SD

TL;DR: 该论文针对音乐抄袭检测任务缺乏明确定义的问题，提出了任务定义、数据集和基于片段转录的解决方案。


<details>
  <summary>Details</summary>
Motivation: 音乐抄袭已成为日益严重的社会问题，但现有研究（包括作者先前工作）对音乐抄袭检测任务缺乏明确定义，这阻碍了研究进展和实际应用。

Method: 1. 明确定义音乐抄袭检测任务，区分其与其他音乐信息检索任务；2. 引入Similar Music Pair数据集支持该任务；3. 提出基于片段转录的解决方案。

Result: 提出了清晰的任务定义和评估框架，创建了支持该任务的数据集，并展示了基于片段转录的方法作为解决方案。

Conclusion: 通过明确定义音乐抄袭检测任务并提供数据集和方法，该研究为后续研究奠定了基础，有助于解决实际音乐抄袭问题。

Abstract: Recently, the problem of music plagiarism has emerged as an even more pressing social issue. As music information retrieval research advances, there is a growing effort to address issues related to music plagiarism. However, many studies, including our previous work, have conducted research without clearly defining what the music plagiarism detection task actually involves. This lack of a clear definition has slowed research progress and made it hard to apply results to real-world scenarios. To fix this situation, we defined how Music Plagiarism Detection is different from other MIR tasks and explained what problems need to be solved. We introduce the Similar Music Pair dataset to support this newly defined task. In addition, we propose a method based on segment transcription as one way to solve the task. Our demo and dataset are available at https://github.com/Mippia/ICASSP2026-MPD.

</details>


### [30] [Understanding Frechet Speech Distance for Synthetic Speech Quality Evaluation](https://arxiv.org/abs/2601.21386)
*June-Woo Kim,Dhruv Agarwal,Federica Cerina*

Main category: cs.SD

TL;DR: 该论文全面评估了Fréchet Speech Distance (FSD)和Speech Maximum Mean Discrepancy (SMMD)作为合成语音质量客观评估指标的可靠性，发现WavLM Base+特征与人类评分最一致，这些指标可作为大规模主观评估的补充工具。


<details>
  <summary>Details</summary>
Motivation: 合成语音质量评估主要依赖昂贵且不具扩展性的人类听力测试，需要寻找可靠、可扩展的客观评估指标。Fréchet Distance虽然前景看好，但其可靠性受嵌入特征和实验设置影响很大。

Method: 全面评估FSD和SMMD在不同嵌入特征和条件下的表现，结合人类听力评估、TTS可懂度和合成语音训练的ASR词错误率来验证这些指标的感知相关性。

Result: WavLM Base+特征产生最稳定的人类评分对齐。FSD和SMMD不能完全替代主观评估，但可作为补充性、成本效益高且可重复的度量标准，特别是在大规模或直接听力评估不可行时。

Conclusion: FSD和SMMD可作为合成语音质量评估的有效补充工具，WavLM Base+是最佳特征选择，这些指标在无法进行大规模主观评估时特别有用。

Abstract: Objective evaluation of synthetic speech quality remains a critical challenge. Human listening tests are the gold standard, but costly and impractical at scale. Fréchet Distance has emerged as a promising alternative, yet its reliability depends heavily on the choice of embeddings and experimental settings. In this work, we comprehensively evaluate Fréchet Speech Distance (FSD) and its variant Speech Maximum Mean Discrepancy (SMMD) under varied embeddings and conditions. We further incorporate human listening evaluations alongside TTS intelligibility and synthetic-trained ASR WER to validate the perceptual relevance of these metrics. Our findings show that WavLM Base+ features yield the most stable alignment with human ratings. While FSD and SMMD cannot fully replace subjective evaluation, we show that they can serve as complementary, cost-efficient, and reproducible measures, particularly useful when large-scale or direct listening assessments are infeasible. Code is available at https://github.com/kaen2891/FrechetSpeechDistance.

</details>


### [31] [Unifying Speech Editing Detection and Content Localization via Prior-Enhanced Audio LLMs](https://arxiv.org/abs/2601.21463)
*Jun Xue,Yi Chai,Yanzhen Ren,Jinshen He,Zhiqiang Tang,Zhuolin Yi,Yihuan Huang,Yuankun Xie,Yujie Chen*

Main category: cs.SD

TL;DR: 提出了PELM框架，首个统一语音编辑检测与内容定位的大模型方法，通过音频问答任务解决神经语音编辑检测难题。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法主要针对手动编辑的语音，难以应对新兴的端到端神经语音编辑技术，这些技术能生成无缝的声学过渡，缺乏高质量数据集。

Method: 首先构建大规模双语数据集AiEdit，利用大语言模型驱动语义篡改逻辑和多种神经语音编辑方法合成数据；提出PELM框架，将检测和定位统一为音频问答任务，引入词级概率先验提供声学线索，设计基于质心聚合的声学一致性感知损失来建模局部分布异常。

Result: PELM在HumanEdit和AiEdit数据集上显著优于现有方法，分别达到0.57%和9.28%的等错误率（定位任务）。

Conclusion: PELM框架有效解决了神经语音编辑检测的挑战，通过统一检测与定位的音频问答方法，结合声学先验和一致性感知损失，在多个数据集上取得了最先进的性能。

Abstract: Speech editing achieves semantic inversion by performing fine-grained segment-level manipulation on original utterances, while preserving global perceptual naturalness. Existing detection studies mainly focus on manually edited speech with explicit splicing artifacts, and therefore struggle to cope with emerging end-to-end neural speech editing techniques that generate seamless acoustic transitions. To address this challenge, we first construct a large-scale bilingual dataset, AiEdit, which leverages large language models to drive precise semantic tampering logic and employs multiple advanced neural speech editing methods for data synthesis, thereby filling the gap of high-quality speech editing datasets. Building upon this foundation, we propose PELM (Prior-Enhanced Audio Large Language Model), the first large-model framework that unifies speech editing detection and content localization by formulating them as an audio question answering task. To mitigate the inherent forgery bias and semantic-priority bias observed in existing audio large models, PELM incorporates word-level probability priors to provide explicit acoustic cues, and further designs a centroid-aggregation-based acoustic consistency perception loss to explicitly enforce the modeling of subtle local distribution anomalies. Extensive experimental results demonstrate that PELM significantly outperforms state-of-the-art methods on both the HumanEdit and AiEdit datasets, achieving equal error rates (EER) of 0.57\% and 9.28\% (localization), respectively.

</details>


### [32] [Localizing Speech Deepfakes Beyond Transitions via Segment-Aware Learning](https://arxiv.org/abs/2601.21925)
*Yuchen Mao,Wen Huang,Yanmin Qian*

Main category: cs.SD

TL;DR: 提出SAL框架，通过分段感知学习改进局部深度伪造音频定位，关注片段内部结构而非仅边界过渡


<details>
  <summary>Details</summary>
Motivation: 现有方法过度依赖边界伪影而忽略伪造内容本身，需要理解整个片段而非仅检测过渡区域

Method: 提出SAL框架，包含分段位置标注（基于片段内相对位置提供细粒度监督）和跨片段混合（数据增强生成多样片段模式）

Result: 在多个深度伪造定位数据集上，SAL在域内和域外设置中均表现优异，非边界区域性能显著提升，减少对过渡伪影的依赖

Conclusion: SAL通过关注片段内部结构有效改进局部深度伪造音频定位，代码已开源

Abstract: Localizing partial deepfake audio, where only segments of speech are manipulated, remains challenging due to the subtle and scattered nature of these modifications. Existing approaches typically rely on frame-level predictions to identify spoofed segments, and some recent methods improve performance by concentrating on the transitions between real and fake audio. However, we observe that these models tend to over-rely on boundary artifacts while neglecting the manipulated content that follows. We argue that effective localization requires understanding the entire segments beyond just detecting transitions. Thus, we propose Segment-Aware Learning (SAL), a framework that encourages models to focus on the internal structure of segments. SAL introduces two core techniques: Segment Positional Labeling, which provides fine-grained frame supervision based on relative position within a segment; and Cross-Segment Mixing, a data augmentation method that generates diverse segment patterns. Experiments across multiple deepfake localization datasets show that SAL consistently achieves strong performance in both in-domain and out-of-domain settings, with notable gains in non-boundary regions and reduced reliance on transition artifacts. The code is available at https://github.com/SentryMao/SAL.

</details>

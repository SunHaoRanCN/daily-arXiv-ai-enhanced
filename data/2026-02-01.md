<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 13]
- [eess.AS](#eess.AS) [Total: 9]
- [cs.SD](#cs.SD) [Total: 10]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Sparse Grassmannian Design for Noncoherent Codes via Schubert Cell Decomposition](https://arxiv.org/abs/2601.21009)
*Joe Asano,Yuto Hama,Hiroki Iimori,Chandan Pradhan,Szabolcs Malomsoky,Naoki Ishikawa*

Main category: eess.SP

TL;DR: 提出一种用于非相干MIMO系统的稀疏Grassmannian码设计方法，通过修正传统成对错误概率公式处理稀疏配置引起的秩缺陷问题，并推导出最大化非相干平均互信息的闭式度量。


<details>
  <summary>Details</summary>
Motivation: 传统基于非相关瑞利衰落信道的成对错误概率公式无法处理稀疏配置引起的秩缺陷问题，需要统一的修正方法。同时，Grassmann流形的Schubert胞分解提供了数学上的稀疏特性，可用于设计稀疏非相干码。

Method: 修正传统成对错误概率公式以统一处理稀疏配置引起的秩缺陷；推导出在给定信噪比下最大化非相干平均互信息的闭式度量；利用Grassmann流形的Schubert胞分解的数学稀疏特性，建立稀疏非相干码的设计准则。

Result: 提出的稀疏非相干码在符号错误率和平均互信息方面均优于传统方法，在高信噪比区域渐近接近最优Grassmannian星座的性能；同时降低了时间和空间复杂度，且复杂度不随发射天线数量增加而增加。

Conclusion: 通过修正传统错误概率公式和利用Grassmann流形的Schubert胞分解，成功设计了性能优越且复杂度低的稀疏非相干码，为MIMO系统提供了一种有效的稀疏编码方案。

Abstract: In this paper, we propose a method for designing sparse Grassmannian codes for noncoherent multiple-input multiple-output systems. Conventional pairwise error probability formulations under uncorrelated Rayleigh fading channels fail to account for rank deficiency induced by sparse configurations. We revise these formulations to handle such cases in a unified manner. Furthermore, we derive a closed-form metric that effectively maximizes the noncoherent average mutual information (AMI) at a given signal-to-noise ratio. We focus on the fact that the Schubert cell decomposition of the Grassmann manifold provides a mathematically sparse property, and establish design criteria for sparse noncoherent codes based on our analyses. In numerical results, the proposed sparse noncoherent codes outperform conventional methods in terms of both symbol error rate and AMI, and asymptotically approach the performance of the optimal Grassmannian constellations in the high-signal-to-noise ratio regime. Moreover, they reduce the time and space complexity, which does not scale with the number of transmit antennas.

</details>


### [2] [Impact of Pointing Error on Coverage Performance of 3D Indoor Terahertz Communication Systems](https://arxiv.org/abs/2601.21303)
*Zhifeng Tang,Nan Yang,Xiangyun Zhou,Salman Durrani,Markku Juntti,Josep Miquel Jornet*

Main category: eess.SP

TL;DR: 本文开发了一个三维室内太赫兹通信系统的分析框架，评估指向误差对覆盖性能的影响，发现仅增加天线阵列尺寸不足以改善覆盖概率，需要先进的估计技术。


<details>
  <summary>Details</summary>
Motivation: 太赫兹通信系统中，发射机和接收机之间的波束成形增益和方向不匹配（指向误差）会对系统性能产生显著影响，需要建立理论框架来量化这种影响。

Method: 使用泊松点过程建模AP位置，随机圆柱过程建模人体遮挡，布尔直线过程建模墙体遮挡；基于位置估计不准确性表征指向误差；采用多簇波动双射线分布建模太赫兹通信的小尺度衰落。

Result: 推导了覆盖概率的可处理表达式，并通过仿真验证了分析结果，发现指向误差对覆盖概率有显著影响，仅增加天线阵列尺寸不足以改善覆盖性能。

Conclusion: 太赫兹通信系统中，指向误差对覆盖性能有重要影响，需要开发先进的估计技术来减轻其负面影响，单纯增加天线阵列尺寸是不够的。

Abstract: In this paper, we develop a tractable analytical framework for a three-dimensional (3D) indoor terahertz (THz) communication system to theoretically assess the impact of the pointing error on its coverage performance. Specifically, we model the locations of access points (APs) using a Poisson point process, human blockages as random cylinder processes, and wall blockages through a Boolean straight line process. A pointing error refers to beamforming gain and direction mismatch between the transmitter and receiver. We characterize it based on the inaccuracy of location estimate. We then analyze the impact of this pointing error on the received signal power and derive a tractable expression for the coverage probability, incorporating the multi-cluster fluctuating two-ray distribution to accurately model small-scale fading in THz communications. Aided by simulation results, we corroborate our analysis and demonstrate that the pointing error has a pronounced impact on the coverage probability. Specifically, we find that merely increasing the antenna array size is insufficient to improve the coverage probability and mitigate the detrimental impact of the pointing error, highlighting the necessity of advanced estimation techniques in THz communication systems.

</details>


### [3] [A Time-Domain Dual-Edge Asynchronous Pipelined SAR ADC Featuring Reset-Free Quantization at Multi-GS/s](https://arxiv.org/abs/2601.21308)
*Richard Zeng,Anthony Chan Carusone,Xilin Liu*

Main category: eess.SP

TL;DR: 提出一种双沿无复位量化技术，用于异步流水线SAR时域ADC，消除传统时域ADC中的复位死区时间，提高转换速度和能效。


<details>
  <summary>Details</summary>
Motivation: 传统时域ADC需要在采样间进行电压-时间和时域信号路径的显式复位，这引入了死区时间，从根本上限制了分辨率、速度和能效。需要一种方法消除复位阶段，扩展有效转换窗口。

Method: 采用双沿无复位量化概念，利用上升沿和下降沿信号实现单周期内无复位量化。包括线性补偿的双沿电压-时间转换器和具有独立可调上升/下降沿延迟的双沿时间-数字转换器。

Result: 在22nm FD-SOI工艺中实现8位ADC，核心面积0.0089 mm²。在3.5 GS/s下实现21.6 dB SNDR和32.2 dB SFDR，并展示架构可扩展性，在10.5 GS/s及更高速度下实现间歇操作。

Conclusion: 双沿无复位量化技术可行，性能限制主要来自实现层面而非架构约束，为高速时域ADC提供了有前景的解决方案。

Abstract: Time-domain ADCs are attractive for high-speed wireline receivers, as time resolution scales favorably with advanced CMOS technologies, enabling multi-GS/s single-channel sampling rates. However, conventional time-domain ADCs require explicit reset of voltage-to-time and time-domain signal paths between samples, introducing dead time that fundamentally limits resolution, speed, and energy efficiency. This paper introduces a dual-edge reset-free quantization concept for asynchronous pipelined SAR time-domain ADCs, in which both rising and falling signal edges are exploited to enable reset-free quantization within a single conversion period. By eliminating explicit reset phases, the proposed approach expands the effective conversion window and relaxes the resolution-speed tradeoff at high sampling rates. An 8-bit dual-edge asynchronous pipelined SAR time-domain ADC is implemented in 22-nm FD-SOI, incorporating a linearity-compensated dual-edge voltage-to-time converter and a dual-edge time-to-digital converter with independently tunable rising- and falling-edge delays. The prototype occupies a core area of 0.0089 mm^2 and achieves continuous single-channel operation at 3.5 GS/s, with architectural scalability demonstrated through intermittent operation at 10.5 GS/s and higher. At 3.5 GS/s, the ADC achieves 21.6 dB SNDR and 32.2 dB SFDR. The measured performance is primarily limited by identifiable implementation-level factors rather than by architectural constraints, demonstrating the feasibility of dual-edge reset-free quantization for high-speed time-domain ADCs.

</details>


### [4] [A Linearization of DFT Spectrum for Precision Power Measurement in Presence of Interharmonics](https://arxiv.org/abs/2601.21397)
*Jian Liu,Wei Zhao,Jianting Zhao,Shisong Li*

Main category: eess.SP

TL;DR: 提出基于DFT频谱分析的线性化算法，用于精确测量含间谐波电力系统中的功率，通过构建线性方程组并矩阵求解，能准确提取基波和谐波附近的间谐波分量，显著降低估计误差。


<details>
  <summary>Details</summary>
Motivation: 电力系统中间谐波的存在会导致异步采样，加上基波频率偏移，会严重降低功率测量精度。在异步条件下，间谐波与基波和谐波分量失去正交性，产生额外的功率分量。

Method: 提出基于DFT频谱分析的线性化算法，从DFT频谱构建线性方程组，通过高效矩阵运算求解，能准确提取基波和谐波频率附近（频率间隔≥1Hz）的间谐波分量。

Result: 测试结果表明，该方法在不同条件下（包括变化的间谐波/基波/谐波间隔、基波频率偏差和噪声）都能准确计算各种功率分量。相比FFT、加窗插值FFT和矩阵铅笔-奇异值分解等方法，估计误差降低数倍到多倍，鲁棒性更好，处理10个工频周期（200ms）数据仅需7ms计算时间。

Conclusion: 该方法能精确测量基波、谐波、间谐波和交叉功率带以及总功率，为含间谐波电力系统的精确功率测量提供了有效解决方案。

Abstract: The presence of interharmonics in power systems can lead to asynchronous sampling, a phenomenon further aggravated by shifts in the fundamental frequency, which significantly degrades the accuracy of power measurements. Under such asynchronous conditions, interharmonics lose orthogonality with the fundamental and harmonic components, giving rise to additional power components. To address these challenges, this paper introduces a linearization algorithm based on DFT spectrum analysis for precise power measurement in systems containing interharmonics. The proposed approach constructs a system of linear equations from the DFT spectrum and solves it through efficient matrix operations, enabling accurate extraction of interharmonic components near the fundamental and harmonic frequencies (with a frequency interval $\geq$1 Hz). This allows for precise measurement of power across the fundamental, harmonic, interharmonic, and cross-power bands, as well as total power. Test results demonstrate that the proposed method accurately computes various power components under diverse conditions--including varying interharmonic/fundamental/harmonic intervals, fundamental frequency deviations, and noise. Compared to existing methods such as fast Fourier transform (FFT), Windowed interpolation FFT, and Matrix pencil-Singular value decomposition, the proposed technique reduces estimation error by several times to multiple folds and exhibits improved robustness, while maintaining a computational time of only 7 ms for processing 10-power-line-cycle (200 ms) data.

</details>


### [5] [Interference Detection and Exploitation for Multi-User Radar Sensing](https://arxiv.org/abs/2601.21429)
*Laurits Randers,Martin Voigt Vejling,Petar Popovski*

Main category: eess.SP

TL;DR: 提出一种用于频谱交织OFDM的干扰检测与利用算法，通过统计方法控制族错误率检测干扰，利用干扰估计角度，避开干扰估计时延，性能接近CRLB下界。


<details>
  <summary>Details</summary>
Motivation: 下一代无线网络中，集成感知与通信需要在共享频谱上同时进行数据传输和环境雷达感知。在多用户场景中，同时传输会在重叠频率上产生相互干扰，导致虚假目标检测和感知精度下降。

Method: 提出基于频谱交织正交频分复用的干扰检测与利用算法。引入统计严谨的程序来检测干扰，同时控制族错误率。算法利用干扰估计角度，同时避开干扰估计时延。

Result: 数值实验表明，所提方法能可靠地检测干扰，且时延和角度估计误差接近克拉美罗下界。

Conclusion: 该算法有效解决了多用户集成感知与通信中的干扰问题，通过智能的干扰检测与利用策略，实现了接近理论最优的感知性能。

Abstract: Integrated sensing and communication is a key feature in next-generation wireless networks, enabling joint data transmission and environmental radar sensing on shared spectrum. In multi-user scenarios, simultaneous transmissions cause mutual interference on overlapping frequencies, leading to spurious target detections and degraded sensing accuracy. This paper proposes an interference detection and exploitation algorithm for sensing using spectrally interleaved orthogonal frequency division multiplexing. A statistically rigorous procedure is introduced to detect interference while controlling the familywise error rate. We propose an algorithm that estimates the angle by exploiting interference, while estimating the delay by avoiding the interference. Numerical experiments demonstrate that the proposed method reliably detects interference, and that the delay and angle estimation error approaches the Cramér-Rao lower bound.

</details>


### [6] [Compressed Sensing-Driven Near-Field Localization Exploiting Array of Subarrays](https://arxiv.org/abs/2601.21481)
*Sai Pavan Deram,Jacopo Pegoraro,Javier Lorca Hernando,Jesus O. Lacruz,Joerg Widmer*

Main category: eess.SP

TL;DR: SHARE是一种用于近场ISAC定位的两阶段稀疏恢复算法，通过分层处理解决稀疏子阵列架构中的栅瓣模糊问题，在保持大孔径高分辨率的同时降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 近场ISAC定位需要大孔径阵列，但全数字实现成本高、复杂度大。稀疏子阵列架构虽能降低成本，却会引入严重的栅瓣估计模糊问题。

Method: SHARE采用两阶段方法：第一阶段使用单个子阵列进行粗略但无模糊的角度估计以解决栅瓣模糊；第二阶段利用整个稀疏孔径进行局部化的联合角度-距离搜索。

Result: SHARE显著优于传统的一次性稀疏恢复方法（如OMP），在定位精度和鲁棒性方面都有提升。其整体定位精度与全数字2D-MUSIC算法相当甚至更好，尽管MUSIC使用了完整的未压缩天线数据。

Conclusion: SHARE为高分辨率近场ISAC系统提供了一条实用路径，能够在保持大孔径高分辨率的同时，通过稀疏架构降低成本和计算复杂度。

Abstract: Near-field localization for ISAC requires large-aperture arrays, making fully-digital implementations prohibitively complex and costly. While sparse subarray architectures can reduce cost, they introduce severe estimation ambiguity from grating lobes. To address both issues, we propose SHARE (Sparse Hierarchical Angle-Range Estimation), a novel two-stage sparse recovery algorithm. SHARE operates in two stages. It first performs coarse, unambiguous angle estimation using individual subarrays to resolve the grating lobe ambiguity. It then leverages the full sparse aperture to perform a localized joint angle-range search. This hierarchical approach avoids an exhaustive and computationally intensive two-dimensional grid search while preserving the high resolution of the large aperture. Simulation results show that SHARE significantly outperforms conventional one-shot sparse recovery methods, such as Orthogonal Matching Pursuit (OMP), in both localization accuracy and robustness. Furthermore, we show that SHARE's overall localization accuracy is comparable to or even surpasses that of the fully-digital 2D-MUSIC algorithm, despite MUSIC having access to the complete, uncompressed data from every antenna element. SHARE therefore provides a practical path for high-resolution near-field ISAC systems.

</details>


### [7] [Channel Extrapolation for MIMO Systems with the Assistance of Multi-path Information Induced from Channel State Information](https://arxiv.org/abs/2601.21524)
*Yuan Gao,Xinyi Wu,Jiang Jun,Zitian Zhang,Zhaohui Yang,Shugong Xu,Cheng-Xiang Wang,Zhu Han*

Main category: eess.SP

TL;DR: 提出一种利用CSI自身多径特性进行信道外推的新框架，无需额外模态数据，通过CSI-to-PDP模块提取多径信息，采用改进的MAE架构实现自监督学习。


<details>
  <summary>Details</summary>
Motivation: 6G网络中传统信道估计开销大，现有基于环境信息（视觉/雷达）的外推方法存在硬件、隐私和多模态对齐问题，需要一种仅利用CSI自身特性的解决方案。

Method: 1) CSI-to-PDP模块：基于AE框架训练，从CSI重构PDP，约束潜在特征表示CSI；2) 从PDP提取总功率和功率加权延迟作为多径信息；3) 改进的MAE架构：使用独立编码器分别提取掩码CSI和多径信息特征，通过交叉注意力模块融合。

Result: 显著提升外推性能，推理时间仅增加约0.1ms，在已知CSI比例较小时表现出强大的泛化能力，优于现有基准方法。

Conclusion: 提出的框架通过利用CSI自身的多径特性，无需额外模态数据即可实现高效信道外推，为6G网络信道获取提供了实用且隐私友好的解决方案。

Abstract: Acquiring channel state information (CSI) through traditional methods, such as channel estimation, is increasingly challenging for the emerging sixth generation (6G) mobile networks due to high overhead. To address this issue, channel extrapolation techniques have been proposed to acquire complete CSI from a limited number of known CSIs. To improve extrapolation accuracy, environmental information, such as visual images or radar data, has been utilized, which poses challenges including additional hardware, privacy and multi-modal alignment concerns. To this end, this paper proposes a novel channel extrapolation framework by leveraging environment-related multi-path characteristics induced directly from CSI without integrating additional modalities. Specifically, we propose utilizing the multi-path characteristics in the form of power-delay profile (PDP), which is acquired using a CSI-to-PDP module. CSI-to-PDP module is trained in an AE-based framework by reconstructing the PDPs and constraining the latent low-dimensional features to represent the CSI. We further extract the total power & power-weighted delay of all the identified paths in PDP as the multi-path information. Building on this, we proposed a MAE architecture trained in a self-supervised manner to perform channel extrapolation. Unlike standard MAE approaches, our method employs separate encoders to extract features from the masked CSI and the multi-path information, which are then fused by a cross-attention module. Extensive simulations demonstrate that this framework improves extrapolation performance dramatically, with a minor increase in inference time (around 0.1 ms). Furthermore, our model shows strong generalization capabilities, particularly when only a small portion of the CSI is known, outperforming existing benchmarks.

</details>


### [8] [Near-Field Positioning for XL-MIMO Uniform Circular Arrays: An Attention-Enhanced Deep Learning Approach](https://arxiv.org/abs/2601.21550)
*Yuan Gao,Xinyu Guo,Han Li,Jianbo Du,Shugong Xu*

Main category: eess.SP

TL;DR: 提出了一种基于注意力增强深度学习的XL-MIMO精确定位方法，利用双路径通道注意力和空间注意力机制，在6G超大规模MIMO系统中实现优于现有方法的定位精度。


<details>
  <summary>Details</summary>
Motivation: 6G移动通信中XL-MIMO系统天线数量激增，增加了空间自由度，为无线定位带来机遇，但近场范围扩大挑战了传统远场假设。均匀圆形阵列(UCA)相比线性平面阵列具有恒定角分辨率优势，如何利用扩展孔径和近场效应需要进一步研究。

Method: 采用注意力增强的深度学习方法，结合双路径通道注意力机制和空间注意力机制，有效整合通道级和空间级特征。使用输入信号的协方差度量作为模型输入。

Result: 模型在综合仿真中超越了ABPN、NFLnet、CNN和MLP等现有基准方法。协方差度量在定位精度和模型效率方面优于信道状态信息(CSI)。

Conclusion: 提出的注意力增强深度学习模型在XL-MIMO系统中实现了精确定位，协方差度量是比CSI更有效的定位输入特征，为6G近场定位提供了有效解决方案。

Abstract: In the evolving landscape of sixth-generation (6G) mobile communication, multiple-input multiple-output (MIMO) systems are incorporating an unprecedented number of antenna elements, advancing towards Extremely large-scale multiple-input-multiple-output (XL-MIMO) systems. This enhancement significantly increases the spatial degrees of freedom, offering substantial benefits for wireless positioning. However, the expansion of the near-field range in XL-MIMO challenges the traditional far-field assumptions used in previous MIMO models. Among various configurations, uniform circular arrays (UCAs) demonstrate superior performance by maintaining constant angular resolution, unlike linear planar arrays. Addressing how to leverage the expanded aperture and harness the near-field effects in XL-MIMO systems remains an area requiring further investigation. In this paper, we introduce an attention-enhanced deep learning approach for precise positioning. We employ a dual-path channel attention mechanism and a spatial attention mechanism to effectively integrate channel-level and spatial-level features. Our comprehensive simulations show that this model surpasses existing benchmarks such as attention-based positioning networks (ABPN), near-field positioning networks (NFLnet), convolutional neural networks (CNN), and multilayer perceptrons (MLP). The proposed model achieves superior positioning accuracy by utilizing covariance metrics of the input signal. Also, simulation results reveal that covariance metric is advantageous for positioning over channel state information (CSI) in terms of positioning accuracy and model efficiency.

</details>


### [9] [VSE: Variational state estimation of complex model-free process](https://arxiv.org/abs/2601.21887)
*Gustav Norén,Anubhab Ghosh,Fredrik Cumlin,Saikat Chatterjee*

Main category: eess.SP

TL;DR: 提出一种变分状态估计方法，通过RNN提供复杂动态过程的闭式高斯后验分布，无需物理模型，在跟踪应用中表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对复杂动态过程的状态估计问题，当缺乏合适的物理模型来描述状态的时间演化时，需要一种数据驱动的方法来从非线性测量中估计状态。

Method: 使用两个相互协作的RNN：一个用于在推理阶段提供闭式高斯后验分布，另一个在学习阶段辅助训练。基于变分推断原理，两个RNN相互促进学习。

Result: 在随机Lorenz系统的跟踪应用中，VSE方法表现优异，与已知Lorenz系统模型的粒子滤波器以及最近提出的数据驱动状态估计方法相比具有竞争力。

Conclusion: VSE方法为无模型复杂动态过程的状态估计提供了一种有效的解决方案，通过RNN实现闭式高斯后验估计，在计算效率和性能上都表现出色。

Abstract: We design a variational state estimation (VSE) method that provides a closed-form Gaussian posterior of an underlying complex dynamical process from (noisy) nonlinear measurements. The complex process is model-free. That is, we do not have a suitable physics-based model characterizing the temporal evolution of the process state. The closed-form Gaussian posterior is provided by a recurrent neural network (RNN). The use of RNN is computationally simple in the inference phase. For learning the RNN, an additional RNN is used in the learning phase. Both RNNs help each other learn better based on variational inference principles. The VSE is demonstrated for a tracking application - state estimation of a stochastic Lorenz system (a benchmark process) using a 2-D camera measurement model. The VSE is shown to be competitive against a particle filter that knows the Lorenz system model and a recently proposed data-driven state estimation method that does not know the Lorenz system model.

</details>


### [10] [Joint Laser Inter-Satellite Link Matching and Traffic Flow Routing in LEO Mega-Constellations via Lagrangian Duality](https://arxiv.org/abs/2601.21914)
*Zhouyou Gu,Jihong Park,Jinho Choi*

Main category: eess.SP

TL;DR: 本文研究了低地球轨道巨型星座中激光星间链路的联合优化问题，考虑激光通信终端的机械限制和全球非均匀流量分布，通过拉格朗日对偶分解方法最大化星座吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有激光星间链路方案通常忽略激光通信终端的机械限制和全球非均匀流量分布（由用户和网关分布不均引起），导致吞吐量次优和激光通信终端/链路利用率不足，特别是在每颗卫星仅携带少量激光通信终端的情况下。

Method: 将问题建模为NP难的混合整数规划，通过拉格朗日对偶松弛耦合约束，将问题分解为：1）加权图匹配问题（用于激光通信终端连接），2）加权最短路径路由任务，3）速率分配的线性规划。使用次梯度下降优化拉格朗日乘子，具有可证明的收敛性。

Result: 使用真实世界星座和地面数据的仿真表明，该方法相比现有非联合方法，网络吞吐量提高了35%-145%。

Conclusion: 通过联合优化激光通信终端连接和流量路由，考虑实际机械限制和全球流量分布，可以显著提高低地球轨道巨型星座的吞吐量，拉格朗日对偶分解方法为此类复杂优化问题提供了有效解决方案。

Abstract: Low Earth orbit (LEO) mega-constellations greatly extend the coverage and resilience of future wireless systems. Within the mega-constellations, laser inter-satellite links (LISLs) enable high-capacity, long-range connectivity. Existing LISL schemes often overlook mechanical limitations of laser communication terminals (LCTs) and non-uniform global traffic profiles caused by uneven user and gateway distributions, leading to suboptimal throughput and underused LCTs/LISLs -- especially when each satellite carries only a few LCTs. This paper investigates the joint optimization of LCT connections and traffic routing to maximize the constellation throughput, considering the realistic LCT mechanics and the global traffic profile. The problem is formulated as an NP-hard mixed-integer program coupling LCT connections with flow-rate variables under link capacity constraints. Due to its intractability, we resort to relaxing the coupling constraints via Lagrangian duality, decomposing the problem into a weighted graph-matching for LCT connections, weighted shortest-path routing tasks, and a linear program for rate allocation. Here, Lagrange multipliers reflect congestion weights between satellites, jointly guiding the matching, routing, and rate allocation. Subgradient descent optimizes the multipliers, with provable convergence. Simulations using real-world constellation and terrestrial data show that our methods substantially improve network throughput by up to $35\%$--$145\%$ over existing non-joint approaches.

</details>


### [11] [Duality-Guided Graph Learning for Real-Time Joint Connectivity and Routing in LEO Mega-Constellations](https://arxiv.org/abs/2601.21921)
*Zhouyou Gu,Jinho Choi,Tony Q. S. Quek,Jihong Park*

Main category: eess.SP

TL;DR: 提出DeepLaDu框架，通过图神经网络单次前向传播预测链路拥塞价格，解决LEO巨型星座激光星间链路的连接建立、流量路由和速率分配联合优化问题，实现实时动态网络管理。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道巨型星座的激光星间链路虽然能提供高容量骨干连接，但面临激光通信终端有限、机械指向约束和网络拓扑快速变化等挑战，需要实时高效的联合优化方案。

Method: 将问题建模为大规模时变星座图上的混合整数优化，采用拉格朗日对偶分解，提出DeepLaDu框架：用图神经网络单次前向传播预测链路级拥塞价格，使用基于次梯度的边级损失实现可扩展稳定训练。

Result: 在类似Starlink的真实星座环境中，DeepLaDu比非联合或启发式基线提高20%网络吞吐量，匹配迭代对偶优化性能但计算时间降低几个数量级，适合LEO网络实时操作。

Conclusion: DeepLaDu框架成功解决了LEO星座激光星间链路的实时联合优化问题，通过深度学习与对偶分解结合，在保证性能的同时大幅降低计算复杂度，为动态非地面网络管理提供了有效解决方案。

Abstract: Laser inter-satellite links (LISLs) of low Earth orbit (LEO) mega-constellations enable high-capacity backbone connectivity in non-terrestrial networks, but their management is challenged by limited laser communication terminals, mechanical pointing constraints, and rapidly time-varying network topologies. This paper studies the joint problem of LISL connection establishment, traffic routing, and flow-rate allocation under heterogeneous global traffic demand and gateway availability. We formulate the problem as a mixed-integer optimization over large-scale, time-varying constellation graphs and develop a Lagrangian dual decomposition that interprets per-link dual variables as congestion prices coordinating connectivity and routing decisions. To overcome the prohibitive latency of iterative dual updates, we propose DeepLaDu, a Lagrangian duality-guided deep learning framework that trains a graph neural network (GNN) to directly infer per-link (edge-level) congestion prices from the constellation state in a single forward pass. We enable scalable and stable training using a subgradient-based edge-level loss in DeepLaDu. We analyze the convergence and computational complexity of the proposed approach and evaluate it using realistic Starlink-like constellations with optical and traffic constraints. Simulation results show that DeepLaDu achieves up to 20\% higher network throughput than non-joint or heuristic baselines, while matching the performance of iterative dual optimization with orders-of-magnitude lower computation time, suitable for real-time operation in dynamic LEO networks.

</details>


### [12] [Optimal Placement of Movable Antennas for Angle-of-Departure Estimation Under User Location Uncertainty](https://arxiv.org/abs/2601.21997)
*Lucía Pallarés-Rodríguez,Angelo Coluccia,Alessio Fascista,Musa Furkan Keskin,Henk Wymeersch,José A. López-Salcedo,Gonzalo Seco-Granados*

Main category: eess.SP

TL;DR: 该论文研究在用户设备位置不确定情况下，使用可移动天线阵列进行角度离开发射估计，通过理论性能分析和天线位置优化，证明可移动天线系统相比固定阵列具有优越性能。


<details>
  <summary>Details</summary>
Motivation: 传统大规模天线阵列存在成本和功耗限制，可移动天线阵列能够克服这些限制。在用户设备位置不确定的实际场景中，需要研究可移动天线阵列的角度离开发射估计性能。

Method: 1) 通过克拉美罗界推导理论性能极限；2) 在用户设备不确定区域内优化天线位置以确保鲁棒性能；3) 通过数值仿真验证优化效果。

Result: 数值结果表明，通过显式考虑不确定区域来动态优化天线布局，相比固定天线阵列能获得更优越的性能，证明可移动天线系统具有适应性和超越传统阵列的能力。

Conclusion: 可移动天线阵列在用户设备位置不确定情况下能够通过优化天线位置实现鲁棒的角度离开发射估计，相比固定阵列具有显著性能优势，展示了可移动天线系统的适应性和潜力。

Abstract: Movable antennas (MA) have gained significant attention in recent years to overcome the limitations of extremely large antenna arrays in terms of cost and power consumption. In this paper, we investigate the use of MA arrays at the base station (BS) for angle-of-departure (AoD) estimation under uncertainty in the user equipment (UE) location. Specifically, we (i) derive the theoretical performance limits through the Cramér-Rao bound (CRB) and (ii) optimize the antenna positions to ensure robust performance within the UE's uncertainty region. Numerical results show that dynamically optimizing antenna placement by explicitly considering the uncertainty region yields superior performance compared to fixed arrays, demonstrating the ability of MA systems to adapt and outperform conventional arrays.

</details>


### [13] [Towards Joint Optimization for UAV-Integrated RIS-Assisted Fluid Antenna Systems](https://arxiv.org/abs/2601.22109)
*Ali Reda,Tamer Mekkawy,Theodoros A. Tsiftsis,Chan-Byoung Chae,Kai-Kit Wong*

Main category: eess.SP

TL;DR: 提出基于流体天线系统辅助可重构智能表面的无人机通信方案，通过联合优化天线端口位置和RIS相位偏移来最大化可达速率，显著提升性能


<details>
  <summary>Details</summary>
Motivation: 无人机集成到蜂窝网络面临空对地干扰挑战，需要增强信号质量

Method: 采用流体天线系统辅助的可重构智能表面，通过连续凸逼近和二阶锥规划联合优化天线端口位置和RIS相位偏移

Result: 相比传统固定位置天线方案，显著改善了中断概率和可达速率，在大规模RIS配置下增益尤其明显，算法收敛快速适合实时应用

Conclusion: FAS辅助RIS方案能有效提升无人机通信性能，为应对空对地干扰提供了有效解决方案

Abstract: Unmanned aerial vehicles (UAVs) integrated into cellular networks face significant challenges from air-to-ground interference. To address this, we propose a downlink UAV communication system that leverages a fluid antenna system (FAS)- assisted reconfigurable intelligent surface (RIS) to enhance signal quality. By jointly optimizing the FAS port positions and RIS phase shifts, we maximize the achievable rate. The resulting nonconvex optimization problem is solved using successive convex approximation (SCA) based on second-order cone programming (SOCP), which reformulates the constraints into a tractable form. Simulation results show that the proposed algorithm significantly improves both outage probability and achievable rate over conventional fixed-position antenna (FPA) schemes, with particularly large gains in large-scale RIS configurations. Moreover, the algorithm converges rapidly, making it suitable for real-time applications

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [14] [Reducing Prompt Sensitivity in LLM-based Speech Recognition Through Learnable Projection](https://arxiv.org/abs/2601.20898)
*Sergio Burdisso,Esaú Villatoro-Tello,Shashi Kumar,Srikanth Madikeri,Andrés Carofilis,Pradeep Rangappa,Manjunath K E,Kadri Hacioglu,Petr Motlicek,Andreas Stolcke*

Main category: eess.AS

TL;DR: 本文分析了LLM-based ASR中提示词设计的影响，发现不同提示词对性能有显著影响且不稳定，提出了一种提示投影器模块来优化提示词嵌入，在四个数据集上取得了一致性改进。


<details>
  <summary>Details</summary>
Motivation: 当前LLM-based ASR系统通常使用固定的手动定义提示词，虽然适用于多种场景并能最大化模型性能，但提示词设计的影响尚未被充分探索。研究发现提示词选择会显著影响ASR性能并引入不稳定性，且没有单一提示词在所有情况下表现最佳。

Method: 受语音到LLM投影器的启发，提出了一个提示投影器模块。这是一个简单、模型无关的扩展，能够学习将提示词嵌入投影到LLM输入空间中更有效的区域，而不需要修改底层的LLM-based ASR模型。

Result: 在四个数据集上的实验表明，添加提示投影器能够：1）一致性地提高性能；2）减少性能变异性；3）超越最佳手动选择的提示词。

Conclusion: 提示词设计对LLM-based ASR性能有重要影响，提出的提示投影器模块能够有效优化提示词嵌入，提高模型性能的稳定性和一致性，为ASR系统提供了简单而有效的改进方案。

Abstract: LLM-based automatic speech recognition (ASR), a well-established approach, connects speech foundation models to large language models (LLMs) through a speech-to-LLM projector, yielding promising results. A common design choice in these architectures is the use of a fixed, manually defined prompt during both training and inference. This setup not only enables applicability across a range of practical scenarios, but also helps maximize model performance. However, the impact of prompt design remains underexplored. This paper presents a comprehensive analysis of commonly used prompts across diverse datasets, showing that prompt choice significantly affects ASR performance and introduces instability, with no single prompt performing best across all cases. Inspired by the speech-to-LLM projector, we propose a prompt projector module, a simple, model-agnostic extension that learns to project prompt embeddings to more effective regions of the LLM input space, without modifying the underlying LLM-based ASR model. Experiments on four datasets show that the addition of a prompt projector consistently improves performance, reduces variability, and outperforms the best manually selected prompts.

</details>


### [15] [Unseen but not Unknown: Using Dataset Concealment to Robustly Evaluate Speech Quality Estimation Models](https://arxiv.org/abs/2601.21110)
*Jaden Pieper,Stephen D. Voran*

Main category: eess.AS

TL;DR: DSC是一种评估语音质量估计模型的新方法，能量化研究结果与实际应用需求之间的性能差距，并通过数据集对齐器提升模型在未见数据上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前语音质量估计模型的研究结果与实际应用需求之间存在性能差距，需要一种系统方法来评估和解释这种差距，同时解决多数据集训练时的语料库效应问题。

Method: 提出Dataset Concealment (DSC)评估框架，结合数据集对齐器(AlignNet)处理多数据集训练，使用MOSNet、NISQA和Wav2Vec2.0三种模型在9个训练数据集和9个未见数据集上进行验证。

Result: DSC能量化模型性能差距并提供可解释的视图，仅添加1000参数的数据集对齐器就能显著提升9400万参数的Wav2Vec模型在未见数据上的语音质量估计能力。

Conclusion: DSC为语音质量估计模型提供了系统评估框架，数据集对齐器能有效解决语料库效应，使模型能充分利用所有可用数据训练并提升泛化能力。

Abstract: We introduce Dataset Concealment (DSC), a rigorous new procedure for evaluating and interpreting objective speech quality estimation models. DSC quantifies and decomposes the performance gap between research results and real-world application requirements, while offering context and additional insights into model behavior and dataset characteristics. We also show the benefits of addressing the corpus effect by using the dataset Aligner from AlignNet when training models with multiple datasets. We demonstrate DSC and the improvements from the Aligner using nine training datasets and nine unseen datasets with three well-studied models: MOSNet, NISQA, and a Wav2Vec2.0-based model. DSC provides interpretable views of the generalization capabilities and limitations of models, while allowing all available data to be used at training. An additional result is that adding the 1000 parameter dataset Aligner to the 94 million parameter Wav2Vec model during training does significantly improve the resulting model's ability to estimate speech quality for unseen data.

</details>


### [16] [DNN-Based Online Source Counting Based on Spatial Generalized Magnitude Squared Coherence](https://arxiv.org/abs/2601.21114)
*Henri Gode,Simon Doclo*

Main category: eess.AS

TL;DR: 提出一种基于空间相干性的在线声源计数方法，通过检测声源数量变化来实现实时计数


<details>
  <summary>Details</summary>
Motivation: 声源数量是声学信号处理中的关键参数，但现有方法在实时在线计数方面存在不足，特别是在混响环境和背景噪声中

Method: 利用空间相干性原理，通过空间白化操作将声源计数问题转化为变化检测任务，使用广义幅度平方相干性作为特征，训练紧凑神经网络进行帧级变化检测

Result: 在双耳助听器场景中，对最多4个说话者和背景噪声的混响环境进行仿真，证明了该方法在线声源计数的有效性

Conclusion: 基于空间相干性的变化检测方法能够有效实现在线声源计数，为声源定位、分离和多麦克风语音增强等任务提供关键参数

Abstract: The number of active sound sources is a key parameter in many acoustic signal processing tasks, such as source localization, source separation, and multi-microphone speech enhancement. This paper proposes a novel method for online source counting by detecting changes in the number of active sources based on spatial coherence. The proposed method exploits the fact that a single coherent source in spatially white background noise yields high spatial coherence, whereas only noise results in low spatial coherence. By applying a spatial whitening operation, the source counting problem is reformulated as a change detection task, aiming to identify the time frames when the number of active sources changes. The method leverages the generalized magnitude-squared coherence as a measure to quantify spatial coherence, providing features for a compact neural network trained to detect source count changes framewise. Simulation results with binaural hearing aids in reverberant acoustic scenes with up to 4 speakers and background noise demonstrate the effectiveness of the proposed method for online source counting.

</details>


### [17] [Towards Robust Dysarthric Speech Recognition: LLM-Agent Post-ASR Correction Beyond WER](https://arxiv.org/abs/2601.21347)
*Xiuwen Zheng,Sixun Dong,Bornali Phukon,Mark Hasegawa-Johnson,Chang D. Yoo*

Main category: eess.AS

TL;DR: 本文提出了一种基于大语言模型的ASR后处理代理，用于改善构音障碍语音识别的语义保真度，并发布了最大的构音障碍语音校正基准SAP-Hypo5。


<details>
  <summary>Details</summary>
Motivation: 传统ASR系统以词错误率(WER)为基准，但实际应用更关注语义保真度。这种不匹配在构音障碍语音中尤为严重，因为发音不精确和不流畅会导致严重的语义失真。

Method: 提出了基于大语言模型的Judge-Editor代理，对ASR的top-k假设进行后处理：保留高置信度片段，重写不确定部分，支持零样本和微调两种模式。

Result: 在多视角评估中，该方法实现了14.51%的WER降低，语义指标显著提升：MENLI提高7.59个百分点，Slot Micro F1提高7.66个百分点。

Conclusion: WER对领域偏移高度敏感，而语义指标与下游任务性能更相关。提出的LLM代理能有效改善构音障碍语音识别的语义保真度，同时发布了SAP-Hypo5基准以支持可复现性研究。

Abstract: While Automatic Speech Recognition (ASR) is typically benchmarked by word error rate (WER), real-world applications ultimately hinge on semantic fidelity. This mismatch is particularly problematic for dysarthric speech, where articulatory imprecision and disfluencies can cause severe semantic distortions. To bridge this gap, we introduce a Large Language Model (LLM)-based agent for post-ASR correction: a Judge-Editor over the top-k ASR hypotheses that keeps high-confidence spans, rewrites uncertain segments, and operates in both zero-shot and fine-tuned modes. In parallel, we release SAP-Hypo5, the largest benchmark for dysarthric speech correction, to enable reproducibility and future exploration. Under multi-perspective evaluation, our agent achieves a 14.51% WER reduction alongside substantial semantic gains, including a +7.59 pp improvement in MENLI and +7.66 pp in Slot Micro F1 on challenging samples. Our analysis further reveals that WER is highly sensitive to domain shift, whereas semantic metrics correlate more closely with downstream task performance.

</details>


### [18] [SemanticAudio: Audio Generation and Editing in Semantic Space](https://arxiv.org/abs/2601.21402)
*Zheqi Dai,Guangyan Zhang,Haolin He,Xiquan Li,Jingyu Li,Chunyat Wu,Yiwen Guo,Qiuqiang Kong*

Main category: eess.AS

TL;DR: SemanticAudio是一个新颖的文本到音频生成框架，通过在高级语义空间而非声学潜在空间操作，实现了更好的语义对齐和无需训练的文本引导编辑。


<details>
  <summary>Details</summary>
Motivation: 现有文本到音频生成模型主要在变分自编码器的声学潜在空间中操作，导致生成的音频与文本描述之间的对齐效果不佳。需要一种能够更好捕捉音频全局语义结构的方法。

Method: 提出两阶段Flow Matching架构：1) 语义规划器生成紧凑的语义特征，捕捉声音事件的全局身份和时序序列；2) 声学合成器基于语义规划生成高保真声学潜在表示。利用解耦设计实现无需训练的文本引导编辑，通过源和目标文本提示的速度场差异来引导语义生成轨迹。

Result: 大量实验表明，SemanticAudio在语义对齐方面超越了现有主流方法，能够生成与文本描述更匹配的音频，并支持精确的属性级编辑。

Conclusion: 通过在高级语义空间进行音频生成和编辑，SemanticAudio实现了更好的语义对齐，为声音创作者提供了更强大的工具，能够将文本灵感转化为生动的音频，并支持灵活的编辑功能。

Abstract: In recent years, Text-to-Audio Generation has achieved remarkable progress, offering sound creators powerful tools to transform textual inspirations into vivid audio. However, existing models predominantly operate directly in the acoustic latent space of a Variational Autoencoder (VAE), often leading to suboptimal alignment between generated audio and textual descriptions. In this paper, we introduce SemanticAudio, a novel framework that conducts both audio generation and editing directly in a high-level semantic space. We define this semantic space as a compact representation capturing the global identity and temporal sequence of sound events, distinct from fine-grained acoustic details. SemanticAudio employs a two-stage Flow Matching architecture: the Semantic Planner first generates these compact semantic features to sketch the global semantic layout, and the Acoustic Synthesizer subsequently produces high-fidelity acoustic latents conditioned on this semantic plan. Leveraging this decoupled design, we further introduce a training-free text-guided editing mechanism that enables precise attribute-level modifications on general audio without retraining. Specifically, this is achieved by steering the semantic generation trajectory via the difference of velocity fields derived from source and target text prompts. Extensive experiments demonstrate that SemanticAudio surpasses existing mainstream approaches in semantic alignment. Demo available at: https://semanticaudio1.github.io/

</details>


### [19] [Representation-Regularized Convolutional Audio Transformer for Audio Understanding](https://arxiv.org/abs/2601.21612)
*Bing Han,Chushu Zhou,Yifan Yang,Wei Wang,Chenda Li,Wangyou Zhang,Yanmin Qian*

Main category: eess.AS

TL;DR: CAT提出了一种多分辨率自监督学习框架，通过多分辨率块和表示正则化目标，在音频理解任务上实现了5倍加速收敛和SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法通常只在单一粒度上操作，难以建模复杂音频信号中多样的时频结构特征，且从零开始的自举表示学习计算成本高、收敛慢。

Method: 提出卷积音频变换器(CAT)：1) 多分辨率块聚合不同粒度的层次音频特征；2) 表示正则化目标，利用预训练外部编码器的高质量语义表示来指导学生模型对齐预测。

Result: 在音频理解基准测试中显著超越基线方法，在AudioSet 20k数据集上达到竞争性性能，且收敛速度比现有方法快5倍。

Conclusion: CAT通过多分辨率特征提取和表示正则化，有效解决了音频自监督学习中的粒度局限性和训练效率问题，为音频理解提供了高效统一的框架。

Abstract: Bootstrap-based Self-Supervised Learning (SSL) has achieved remarkable progress in audio understanding. However, existing methods typically operate at a single level of granularity, limiting their ability to model the diverse temporal and spectral structures inherent in complex audio signals. Furthermore, bootstrapping representations from scratch is computationally expensive, often requiring extensive training to converge. In this work, we propose the Convolutional Audio Transformer (CAT), a unified framework designed to address these challenges. First, to capture hierarchical audio features, CAT incorporates a Multi-resolution Block that aggregates information across varying granularities. Second, to enhance training efficiency, we introduce a Representation Regularization objective. Drawing inspiration from generative modeling, this auxiliary task guides the student model by aligning its predictions with high-quality semantic representations from frozen, pre-trained external encoders. Experimental results demonstrate that CAT significantly outperforms baselines on audio understanding benchmarks. Notably, it achieves competitive performance on the AudioSet 20k dataset with 5 times faster convergence than existing methods. Codes and checkpoints will be released soon at https://github.com/realzhouchushu/CAT.

</details>


### [20] [Speech Quality-Based Localization of Low-Quality Speech and Text-to-Speech Synthesis Artefacts](https://arxiv.org/abs/2601.21886)
*Michael Kuhlmann,Alexander Werning,Thilo von Neumann,Reinhold Haeb-Umbach*

Main category: eess.AS

TL;DR: 论文提出通过段级一致性约束来正则化话语级语音质量预测器，减少帧级随机性，并展示了帧级评分在部分欺骗场景和检测TTS系统合成伪影中的应用。


<details>
  <summary>Details</summary>
Motivation: 现有语音自动评估方法主要关注话语级或系统级，虽然能判断整体质量但缺乏可解释性。帧级评分能提供更好的可解释性，但训练时缺乏强目标，模型难以调优和正则化。

Method: 提出使用段级一致性约束来正则化话语级语音质量预测器，显著减少帧级随机性。然后展示了帧级评分的两个应用：部分欺骗场景和检测先进文本转语音系统中的合成伪影。

Result: 段级一致性约束有效减少了帧级随机性。在合成伪影检测应用中，听力测试证实听众在低帧级评分定义的集合中更频繁地将片段评为质量差，相比随机控制集。

Conclusion: 通过段级一致性约束正则化话语级预测器可以改善帧级评分的可靠性，为语音质量评估提供更好的可解释性，并在检测合成伪影等应用中验证了其有效性。

Abstract: A large number of works view the automatic assessment of speech from an utterance- or system-level perspective. While such approaches are good in judging overall quality, they cannot adequately explain why a certain score was assigned to an utterance. frame-level scores can provide better interpretability, but models predicting them are harder to tune and regularize since no strong targets are available during training. In this work, we show that utterance-level speech quality predictors can be regularized with a segment-based consistency constraint which notably reduces frame-level stochasticity. We then demonstrate two applications involving frame-level scores: The partial spoof scenario and the detection of synthesis artefacts in two state-of-the-art text-to-speech systems. For the latter, we perform listening tests and confirm that listeners rate segments to be of poor quality more often in the set defined by low frame-level scores than in a random control set.

</details>


### [21] [DisContSE: Single-Step Diffusion Speech Enhancement Based on Joint Discrete and Continuous Embeddings](https://arxiv.org/abs/2601.21940)
*Yihui Fu,Tim Fingscheidt*

Main category: eess.AS

TL;DR: DisContSE：基于离散音频编解码特征的扩散语音增强模型，通过联合离散token和连续嵌入，实现高效单步推理，在保真度和可懂度上均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于离散音频编解码特征的扩散语音增强方法存在两个主要问题：1）推理计算复杂度高，需要多次反向过程迭代；2）在非侵入式指标上表现好，但在侵入式指标上表现差，难以准确重建音素。

Method: 提出DisContSE模型，包含三个核心模块：1）离散增强模块处理离散音频编解码token；2）连续增强模块处理连续嵌入；3）语义增强模块优化音素准确性。采用量化误差掩码初始化策略实现单步高效推理。

Result: 在URGENT 2024语音增强挑战赛数据上评估，DisContSE在PESQ、POLQA、UTMOS等客观指标和主观ITU-T P.808听力测试中均优于现有时域和频域扩散基线方法，达到整体最优排名。

Conclusion: DisContSE通过联合离散和连续表示，结合语义增强和单步推理策略，在保持高效计算的同时，显著提升了语音增强的保真度和可懂度，是首个基于音频编解码的单步扩散语音增强成功方案。

Abstract: Diffusion speech enhancement on discrete audio codec features gain immense attention due to their improved speech component reconstruction capability. However, they usually suffer from high inference computational complexity due to multiple reverse process iterations. Furthermore, they generally achieve promising results on non-intrusive metrics but show poor performance on intrusive metrics, as they may struggle in reconstructing the correct phones. In this paper, we propose DisContSE, an efficient diffusion-based speech enhancement model on joint discrete codec tokens and continuous embeddings. Our contributions are three-fold. First, we formulate both a discrete and a continuous enhancement module operating on discrete audio codec tokens and continuous embeddings, respectively, to achieve improved fidelity and intelligibility simultaneously. Second, a semantic enhancement module is further adopted to achieve optimal phonetic accuracy. Third, we achieve a single-step efficient reverse process in inference with a novel quantization error mask initialization strategy, which, according to our knowledge, is the first successful single-step diffusion speech enhancement based on an audio codec. Trained and evaluated on URGENT 2024 Speech Enhancement Challenge data splits, the proposed DisContSE excels top-reported time- and frequency-domain diffusion baseline methods in PESQ, POLQA, UTMOS, and in a subjective ITU-T P.808 listening test, clearly achieving an overall top rank.

</details>


### [22] [TidyVoice 2026 Challenge Evaluation Plan](https://arxiv.org/abs/2601.21960)
*Aref Farhadipour,Jan Marquenie,Srikanth Madikeri,Teodora Vukovic,Volker Dellwo,Kathy Reid,Francis M. Tyers,Ingo Siegert,Eleanor Chodroff*

Main category: eess.AS

TL;DR: 提出TidyVoice挑战赛，针对跨语言说话人验证中的语言不匹配问题，使用TidyVoiceX数据集（约40种语言）进行标准化评估，旨在推动更公平、包容的语言无关说话人识别技术。


<details>
  <summary>Details</summary>
Motivation: 当前说话人验证系统在语言不匹配时性能显著下降，该领域过度依赖英语中心数据，需要解决跨语言场景下的公平性和包容性问题。

Method: 基于TidyVoice基准测试中的TidyVoiceX数据集（源自Mozilla Common Voice的大规模多语言语料库），专门设计跨语言试验，使用等错误率作为主要评估指标，提供标准化数据、开源基准和严格评估协议。

Result: 提出一个标准化的挑战赛框架，为研究人员提供跨语言说话人验证的评估平台，直接对应Interspeech 2026主题"Speaking Together"。

Conclusion: TidyVoice挑战赛旨在推动更公平、包容和语言无关的说话人识别技术发展，通过标准化评估促进该领域研究进步。

Abstract: The performance of speaker verification systems degrades significantly under language mismatch, a critical challenge exacerbated by the field's reliance on English-centric data. To address this, we propose the TidyVoice Challenge for cross-lingual speaker verification. The challenge leverages the TidyVoiceX dataset from the novel TidyVoice benchmark, a large-scale, multilingual corpus derived from Mozilla Common Voice, and specifically curated to isolate the effect of language switching across approximately 40 languages. Participants will be tasked with building systems robust to this mismatch, with performance primarily evaluated using the Equal Error Rate on cross-language trials. By providing standardized data, open-source baselines, and a rigorous evaluation protocol, this challenge aims to drive research towards fairer, more inclusive, and language-independent speaker recognition technologies, directly aligning with the Interspeech 2026 theme, "Speaking Together."

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [23] [Generalizable Prompt Tuning for Audio-Language Models via Semantic Expansion](https://arxiv.org/abs/2601.20867)
*Jaehyuk Jang,Wonjun Lee,Kangwook Ko,Changick Kim*

Main category: cs.SD

TL;DR: SEPT是一种用于音频语言模型的语义扩展提示调优框架，通过引入LLM生成的语义邻居来正则化提示嵌入空间，解决了传统提示调优中的基础-新类别权衡问题。


<details>
  <summary>Details</summary>
Motivation: 传统提示调优在音频语言模型中存在基础-新类别权衡问题，这源于嵌入空间语义结构的破坏。目前ALMs中提示调优的泛化能力尚未得到充分探索。

Method: 提出SEPT框架，使用大语言模型生成语义邻居，通过带有边界约束的新型语义扩展损失来正则化提示嵌入空间，促进类内紧凑性和类间分离性。

Result: 建立了ALMs中提示泛化的首个基准设置，实验表明SEPT在多个提示调优基线上一致提升泛化性能，同时保持推理时的计算成本不变。

Conclusion: SEPT通过语义扩展有效解决了ALMs中提示调优的泛化问题，为音频语言模型的提示调优提供了新的解决方案。

Abstract: Prompt tuning has achieved remarkable progress in vision-language models (VLMs) and is recently being adopted for audio-language models (ALMs). However, its generalization ability in ALMs remains largely underexplored. We observe that conventional prompt tuning for ALMs also suffers from the Base-New Tradeoff, and we identify that this issue stems from the disrupted semantic structure of the embedding space. To address this issue, we propose Semantically Expanded Prompt Tuning (SEPT)-a plug-and-play framework that explicitly regularizes the prompt embedding space by incorporating semantic neighbors generated by large language models. SEPT introduces a novel semantic expansion loss with margin constraints that promote intra-class compactness and inter-class separability, thereby enhancing the semantic structure of the prompt embedding space. For comprehensive evaluation, we establish the first benchmark setup for prompt generalization in ALMs, covering both base-to-new generalization and cross-dataset transferability. Extensive experiments demonstrate that SEPT consistently improves generalization performance across multiple prompt tuning baselines, while maintaining computational cost during inference. Codes are available in https://github.com/jhyukjang/SEPT.

</details>


### [24] [VoxMorph: Scalable Zero-shot Voice Identity Morphing via Disentangled Embeddings](https://arxiv.org/abs/2601.20883)
*Bharath Krishnamurthy,Ajita Rattani*

Main category: cs.SD

TL;DR: VoxMorph是一个零样本语音变形框架，仅需每人5秒音频即可生成高质量语音变形，无需重新训练模型，在语音生物识别安全方面表现出色。


<details>
  <summary>Details</summary>
Motivation: 语音生物识别中的变形攻击研究不足，现有方法计算成本高、可扩展性差且仅限于声学相似的身份对，限制了实际部署。现有音频变形方法也不适用于语音身份操纵。

Method: 将语音特征解耦为韵律和音色嵌入，通过球面线性插值融合，使用自回归语言模型和条件流匹配网络合成语音。

Result: VoxMorph实现最先进性能：音频质量提升2.6倍，可懂度错误减少73%，在严格安全阈值下对自动说话人验证系统的变形攻击成功率达67.8%。

Conclusion: 这项工作为语音变形建立了实用且可扩展的范式，对生物识别安全具有重要意义。

Abstract: Morphing techniques generate artificial biometric samples that combine features from multiple individuals, allowing each contributor to be verified against a single enrolled template. While extensively studied in face recognition, this vulnerability remains largely unexplored in voice biometrics. Prior work on voice morphing is computationally expensive, non-scalable, and limited to acoustically similar identity pairs, constraining practical deployment. Moreover, existing sound-morphing methods target audio textures, music, or environmental sounds and are not transferable to voice identity manipulation. We propose VoxMorph, a zero-shot framework that produces high-fidelity voice morphs from as little as five seconds of audio per subject without model retraining. Our method disentangles vocal traits into prosody and timbre embeddings, enabling fine-grained interpolation of speaking style and identity. These embeddings are fused via Spherical Linear Interpolation (Slerp) and synthesized using an autoregressive language model coupled with a Conditional Flow Matching network. VoxMorph achieves state-of-the-art performance, delivering a 2.6x gain in audio quality, a 73% reduction in intelligibility errors, and a 67.8% morphing attack success rate on automated speaker verification systems under strict security thresholds. This work establishes a practical and scalable paradigm for voice morphing with significant implications for biometric security. The code and dataset are available on our project page: https://vcbsl.github.io/VoxMorph/

</details>


### [25] [SW-ASR: A Context-Aware Hybrid ASR Pipeline for Robust Single Word Speech Recognition](https://arxiv.org/abs/2601.20890)
*Manali Sharma,Riya Naik,Buvaneshwari G*

Main category: cs.SD

TL;DR: 提出用于单词语音识别的模块化框架，结合去噪、混合ASR前端和验证层，在噪声和压缩音频下显著提升准确性


<details>
  <summary>Details</summary>
Motivation: 单词语音识别缺乏语言上下文，对噪声、发音变化和信道伪影敏感，在医疗和应急响应等低资源关键通信领域面临挑战

Method: 模块化框架：去噪和归一化 + 混合ASR前端（Whisper + Vosk）+ 验证层（支持嵌入相似度、编辑距离和基于LLM的匹配，可选上下文引导）

Result: 在Google Speech Commands数据集和真实世界带宽受限数据集上评估，验证层显著提升噪声和压缩信道下的准确性，上下文引导和LLM匹配效果最佳

Conclusion: 轻量级验证和上下文机制可在不牺牲实时电话应用延迟的情况下，显著提高单词语音识别的鲁棒性

Abstract: Single-word Automatic Speech Recognition (ASR) is a challenging task due to the lack of linguistic context and sensitivity to noise, pronunciation variation, and channel artifacts, especially in low-resource, communication-critical domains such as healthcare and emergency response. This paper reviews recent deep learning approaches and proposes a modular framework for robust single-word detection. The system combines denoising and normalization with a hybrid ASR front end (Whisper + Vosk) and a verification layer designed to handle out-of-vocabulary words and degraded audio. The verification layer supports multiple matching strategies, including embedding similarity, edit distance, and LLM-based matching with optional contextual guidance. We evaluate the framework on the Google Speech Commands dataset and a curated real-world dataset collected from telephony and messaging platforms under bandwidth-limited conditions. Results show that while the hybrid ASR front end performs well on clean audio, the verification layer significantly improves accuracy on noisy and compressed channels. Context-guided and LLM-based matching yield the largest gains, demonstrating that lightweight verification and context mechanisms can substantially improve single-word ASR robustness without sacrificing latency required for real-time telephony applications.

</details>


### [26] [A Study of Data Selection Strategies for Pre-training Self-Supervised Speech Models](https://arxiv.org/abs/2601.20896)
*Ryan Whetten,Titouan Parcollet,Marco Dinarelli,Yannick Estève*

Main category: cs.SD

TL;DR: 研究发现，在语音自监督学习中，数据长度比数据多样性或总量更重要，优先选择最长语音片段可将预训练数据减半并提升ASR性能


<details>
  <summary>Details</summary>
Motivation: 自监督学习在语音处理中取得了成功，但其对大规模预训练数据的依赖成为瓶颈。虽然鲁棒性通常归因于数据规模和多样性，但数据分布的具体作用尚不清楚。本研究旨在系统探究预训练数据的精选子集如何影响自动语音识别性能。

Method: 系统性地研究了不同预训练数据子集对ASR性能的影响，比较了基于声学多样性、说话人多样性、语言多样性的数据选择策略，并与随机采样进行对比。特别关注了按语音长度优先选择数据的方法。

Result: 令人惊讶的是，优化声学、说话人或语言多样性并未带来明显改进。相反，优先选择最长语音片段的方法在使用仅一半原始数据集的情况下，获得了更优的ASR结果，并在大型语料库上将预训练时间减少了24%。

Conclusion: 对于语音自监督学习模型的预训练，数据长度是比数据多样性或总体数据量更关键的因素，对性能和效率都有重要影响。这为SSL语音处理中的数据选择策略提供了新的视角。

Abstract: Self-supervised learning (SSL) has transformed speech processing, yet its reliance on massive pre-training datasets remains a bottleneck. While robustness is often attributed to scale and diversity, the role of the data distribution is less understood. We systematically examine how curated subsets of pre-training data influence Automatic Speech Recognition (ASR) performance. Surprisingly, optimizing for acoustic, speaker, or linguistic diversity yields no clear improvements over random sampling. Instead, we find that prioritizing the longest utterances achieves superior ASR results while using only half the original dataset, reducing pre-training time by 24% on a large corpora. These findings suggest that for pre-training speech SSL models, data length is a more critical factor than either data diversity or overall data quantity for performance and efficiency, offering a new perspective for data selection strategies in SSL speech processing.

</details>


### [27] [Text-only adaptation in LLM-based ASR through text denoising](https://arxiv.org/abs/2601.20900)
*Sergio Burdisso,Esaú Villatoro-Tello,Andrés Carofilis,Shashi Kumar,Kadri Hacioglu,Srikanth Madikeri,Pradeep Rangappa,Manjunath K E,Petr Motlicek,Shankar Venkatesan,Andreas Stolcke*

Main category: cs.SD

TL;DR: 提出一种基于文本去噪任务的语音识别大模型文本域适应方法，通过模拟音频投影任务来保持跨模态对齐，无需架构修改或额外参数


<details>
  <summary>Details</summary>
Motivation: 基于大语言模型的语音识别系统在仅使用文本数据进行新领域适应时面临挑战，标准微调会破坏语音和文本模态间的关键对齐，导致性能下降

Method: 将音频投影任务模拟为文本去噪任务，训练大语言模型从噪声输入中恢复干净转录文本，从而在适应目标领域的同时保持跨模态对齐

Result: 在两个数据集上的广泛评估显示，相对改进高达22.1%，优于当前最先进的仅文本适应方法

Conclusion: 提出的轻量级文本去噪适应方法能有效解决语音识别大模型在文本域适应中的跨模态对齐问题，显著提升性能

Abstract: Adapting automatic speech recognition (ASR) systems based on large language models (LLMs) to new domains using text-only data is a significant yet underexplored challenge. Standard fine-tuning of the LLM on target-domain text often disrupts the critical alignment between speech and text modalities learned by the projector, degrading performance. We introduce a novel text-only adaptation method that emulates the audio projection task by treating it as a text denoising task. Our approach thus trains the LLM to recover clean transcripts from noisy inputs. This process effectively adapts the model to a target domain while preserving cross-modal alignment. Our solution is lightweight, requiring no architectural changes or additional parameters. Extensive evaluation on two datasets demonstrates up to 22.1% relative improvement, outperforming recent state-of-the-art text-only adaptation methods.

</details>


### [28] [PhaseCoder: Microphone Geometry-Agnostic Spatial Audio Understanding for Multimodal LLMs](https://arxiv.org/abs/2601.21124)
*Artem Dementyev,Wazeer Zulfikar,Sinan Hersek,Pascal Getreuer,Anurag Kumar,Vivek Kumar*

Main category: cs.SD

TL;DR: PhaseCoder是一个与麦克风几何无关的空间音频编码器，可将多通道音频转换为空间音频令牌，使LLM能够进行空间推理和定向转录


<details>
  <summary>Details</summary>
Motivation: 当前多模态LLM将音频处理为单声道流，忽略了空间信息；现有空间音频模型受限于固定麦克风几何结构，无法在不同设备上部署

Method: PhaseCoder采用纯Transformer架构，以原始多通道音频和麦克风坐标为输入，执行定位并生成鲁棒的空间嵌入；Gemma 3n LLM可微调以处理PhaseCoder产生的"空间音频令牌"

Result: 在麦克风无关定位基准测试中达到最先进水平；首次使LLM能够从任意麦克风阵列执行复杂空间推理和定向转录任务

Conclusion: PhaseCoder解决了空间音频处理中的设备无关性问题，为具身AI提供了重要的空间感知能力，使LLM能够理解和推理音频空间信息

Abstract: Current multimodal LLMs process audio as a mono stream, ignoring the rich spatial information essential for embodied AI. Existing spatial audio models, conversely, are constrained to fixed microphone geometries, preventing deployment across diverse devices. We present PhaseCoder, a transformer-only spatial audio encoder that is agnostic to microphone geometry. PhaseCoder takes raw multichannel audio and microphone coordinates as inputs to perform localization and produces robust spatial embeddings. We demonstrate that Gemma 3n LLM can be fine-tuned to reason over "Spatial Audio Tokens" produced by PhaseCoder. We show our encoder achieves state-of-the-art results on microphone-invariant localization benchmarks and, for the first time, enables an LLM to perform complex spatial reasoning and targeted transcription tasks from an arbitrary microphone array.

</details>


### [29] [Music Plagiarism Detection: Problem Formulation and a Segment-based Solution](https://arxiv.org/abs/2601.21260)
*Seonghyeon Go,Yumin Kim*

Main category: cs.SD

TL;DR: 该论文针对音乐抄袭检测任务缺乏明确定义的问题，提出了任务定义、创建了相似音乐对数据集，并基于片段转录提出了解决方案。


<details>
  <summary>Details</summary>
Motivation: 音乐抄袭问题日益严重，但现有研究缺乏对音乐抄袭检测任务的明确定义，这阻碍了研究进展和实际应用。

Method: 1. 明确定义音乐抄袭检测任务及其与其他MIR任务的区别；2. 创建相似音乐对数据集支持该任务；3. 提出基于片段转录的解决方案。

Result: 建立了清晰的任务定义框架，发布了相似音乐对数据集，并展示了基于片段转录的方法作为可行的解决方案。

Conclusion: 通过明确定义音乐抄袭检测任务并提供数据集和方法，为后续研究奠定了基础，有助于推动该领域的发展和应用。

Abstract: Recently, the problem of music plagiarism has emerged as an even more pressing social issue. As music information retrieval research advances, there is a growing effort to address issues related to music plagiarism. However, many studies, including our previous work, have conducted research without clearly defining what the music plagiarism detection task actually involves. This lack of a clear definition has slowed research progress and made it hard to apply results to real-world scenarios. To fix this situation, we defined how Music Plagiarism Detection is different from other MIR tasks and explained what problems need to be solved. We introduce the Similar Music Pair dataset to support this newly defined task. In addition, we propose a method based on segment transcription as one way to solve the task. Our demo and dataset are available at https://github.com/Mippia/ICASSP2026-MPD.

</details>


### [30] [Understanding Frechet Speech Distance for Synthetic Speech Quality Evaluation](https://arxiv.org/abs/2601.21386)
*June-Woo Kim,Dhruv Agarwal,Federica Cerina*

Main category: cs.SD

TL;DR: 该论文全面评估了Fréchet Speech Distance (FSD)及其变体Speech Maximum Mean Discrepancy (SMMD)作为合成语音质量客观评估指标的可靠性，发现WavLM Base+特征与人类评分最一致，这些指标可作为大规模主观评估的补充工具。


<details>
  <summary>Details</summary>
Motivation: 合成语音质量评估面临挑战：人工听力测试虽为黄金标准但成本高、难以大规模实施。Fréchet距离作为替代方案虽有前景，但其可靠性受嵌入特征和实验设置影响较大，需要系统评估。

Method: 在多种嵌入特征和条件下全面评估FSD和SMMD，结合人类听力评估、TTS可懂度和合成语音训练的ASR词错误率(WER)来验证这些指标的感知相关性。

Result: WavLM Base+特征能产生最稳定的人类评分对齐效果。FSD和SMMD虽不能完全替代主观评估，但可作为成本效益高、可重复的补充指标，特别适用于大规模或直接听力评估不可行的情况。

Conclusion: FSD和SMMD是合成语音质量评估的有效补充工具，WavLM Base+特征是最佳选择。这些指标为大规模评估提供了实用解决方案，但需注意其局限性，不能完全替代人类主观评价。

Abstract: Objective evaluation of synthetic speech quality remains a critical challenge. Human listening tests are the gold standard, but costly and impractical at scale. Fréchet Distance has emerged as a promising alternative, yet its reliability depends heavily on the choice of embeddings and experimental settings. In this work, we comprehensively evaluate Fréchet Speech Distance (FSD) and its variant Speech Maximum Mean Discrepancy (SMMD) under varied embeddings and conditions. We further incorporate human listening evaluations alongside TTS intelligibility and synthetic-trained ASR WER to validate the perceptual relevance of these metrics. Our findings show that WavLM Base+ features yield the most stable alignment with human ratings. While FSD and SMMD cannot fully replace subjective evaluation, we show that they can serve as complementary, cost-efficient, and reproducible measures, particularly useful when large-scale or direct listening assessments are infeasible. Code is available at https://github.com/kaen2891/FrechetSpeechDistance.

</details>


### [31] [Unifying Speech Editing Detection and Content Localization via Prior-Enhanced Audio LLMs](https://arxiv.org/abs/2601.21463)
*Jun Xue,Yi Chai,Yanzhen Ren,Jinshen He,Zhiqiang Tang,Zhuolin Yi,Yihuan Huang,Yuankun Xie,Yujie Chen*

Main category: cs.SD

TL;DR: 提出PELM框架，首个统一语音编辑检测与内容定位的大模型方法，通过音频问答任务形式，在构建的双语数据集AiEdit上显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法主要针对手动编辑的语音，难以应对新兴的端到端神经语音编辑技术，这些技术能生成无缝的声学过渡，缺乏高质量语音编辑数据集。

Method: 1) 构建大规模双语数据集AiEdit，利用大语言模型驱动语义篡改逻辑，采用多种神经语音编辑方法合成数据；2) 提出PELM框架，将检测和定位统一为音频问答任务，引入词级概率先验提供显式声学线索，设计基于质心聚合的声学一致性感知损失来建模局部分布异常。

Result: PELM在HumanEdit和AiEdit数据集上显著优于现有方法，分别达到0.57%和9.28%的等错误率（定位任务）。

Conclusion: PELM是首个统一语音编辑检测与内容定位的大模型框架，通过引入声学先验和一致性感知损失有效解决了现有音频大模型的伪造偏差和语义优先偏差问题，为语音编辑检测提供了新方向。

Abstract: Speech editing achieves semantic inversion by performing fine-grained segment-level manipulation on original utterances, while preserving global perceptual naturalness. Existing detection studies mainly focus on manually edited speech with explicit splicing artifacts, and therefore struggle to cope with emerging end-to-end neural speech editing techniques that generate seamless acoustic transitions. To address this challenge, we first construct a large-scale bilingual dataset, AiEdit, which leverages large language models to drive precise semantic tampering logic and employs multiple advanced neural speech editing methods for data synthesis, thereby filling the gap of high-quality speech editing datasets. Building upon this foundation, we propose PELM (Prior-Enhanced Audio Large Language Model), the first large-model framework that unifies speech editing detection and content localization by formulating them as an audio question answering task. To mitigate the inherent forgery bias and semantic-priority bias observed in existing audio large models, PELM incorporates word-level probability priors to provide explicit acoustic cues, and further designs a centroid-aggregation-based acoustic consistency perception loss to explicitly enforce the modeling of subtle local distribution anomalies. Extensive experimental results demonstrate that PELM significantly outperforms state-of-the-art methods on both the HumanEdit and AiEdit datasets, achieving equal error rates (EER) of 0.57\% and 9.28\% (localization), respectively.

</details>


### [32] [Localizing Speech Deepfakes Beyond Transitions via Segment-Aware Learning](https://arxiv.org/abs/2601.21925)
*Yuchen Mao,Wen Huang,Yanmin Qian*

Main category: cs.SD

TL;DR: 提出Segment-Aware Learning (SAL)框架，通过关注音频片段的内部结构而非仅依赖边界伪影，来改进局部深度伪造音频的定位性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖帧级预测来识别伪造片段，或关注真实与伪造音频之间的过渡区域，但这些模型往往过度依赖边界伪影而忽略后续的伪造内容。有效的定位需要理解整个片段而不仅仅是检测过渡。

Method: 提出SAL框架，包含两个核心技术：1) Segment Positional Labeling - 基于片段内相对位置提供细粒度帧监督；2) Cross-Segment Mixing - 生成多样化片段模式的数据增强方法。

Result: 在多个深度伪造定位数据集上的实验表明，SAL在域内和域外设置下均能取得强劲性能，在非边界区域表现显著提升，并减少了对过渡伪影的依赖。

Conclusion: SAL框架通过关注片段的内部结构，有效提升了局部深度伪造音频的定位能力，特别是在非边界区域，且代码已开源。

Abstract: Localizing partial deepfake audio, where only segments of speech are manipulated, remains challenging due to the subtle and scattered nature of these modifications. Existing approaches typically rely on frame-level predictions to identify spoofed segments, and some recent methods improve performance by concentrating on the transitions between real and fake audio. However, we observe that these models tend to over-rely on boundary artifacts while neglecting the manipulated content that follows. We argue that effective localization requires understanding the entire segments beyond just detecting transitions. Thus, we propose Segment-Aware Learning (SAL), a framework that encourages models to focus on the internal structure of segments. SAL introduces two core techniques: Segment Positional Labeling, which provides fine-grained frame supervision based on relative position within a segment; and Cross-Segment Mixing, a data augmentation method that generates diverse segment patterns. Experiments across multiple deepfake localization datasets show that SAL consistently achieves strong performance in both in-domain and out-of-domain settings, with notable gains in non-boundary regions and reduced reliance on transition artifacts. The code is available at https://github.com/SentryMao/SAL.

</details>

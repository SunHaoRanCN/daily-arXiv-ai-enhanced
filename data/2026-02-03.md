<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 28]
- [eess.AS](#eess.AS) [Total: 8]
- [cs.SD](#cs.SD) [Total: 19]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [JSR-GFNet: Jamming-to-Signal Ratio-Aware Dynamic Gating for Interference Classification in future Cognitive Global Navigation Satellite Systems](https://arxiv.org/abs/2602.00042)
*Zhihan Zeng,Hongyuan Shu,Kaihe Wang,Lu Chen,Amir Hussian,Yanjun Huang,Junchu Zhao,Yue Xiu,Zhongpei Zhang*

Main category: eess.SP

TL;DR: 提出JSR-GFNet多模态网络，结合IQ样本和STFT谱图，通过物理启发的动态门控机制解决低JSR下性能下降和相位信息丢失问题，在GNSS干扰分类中实现更高准确率。


<details>
  <summary>Details</summary>
Motivation: 传统基于时频分析和CNN的方法在低JSR下性能严重下降，且幅度谱图丢失相位信息导致"特征退化"，使频谱相似的信号难以区分。

Method: 提出JSR-GFNet多模态架构，结合相位敏感的复杂IQ样本和STFT谱图，采用物理启发的动态门控机制，基于统计信号描述符估计信号可靠性，动态重新加权复杂值ResNet（IQ流）和EfficientNet骨干（STFT流）的贡献。

Result: 在CGI-21数据集（21种干扰类别）上验证，JSR-GFNet在10-50 dB JSR范围内实现更高准确率。可解释性分析显示模型学习到物理直观策略：在噪声受限时优先频谱能量整合，在高SNR时转向相位精度解决调制模糊。

Conclusion: 该框架为下一代航空航天导航安全提供稳健解决方案，通过多模态融合和自适应门控机制克服传统方法的局限性。

Abstract: The transition toward cognitive global navigation satellite system (GNSS) receivers requires accurate interference classification to trigger adaptive mitigation strategies. However, conventional methods relying on Time-Frequency Analysis (TFA) and Convolutional Neural Networks (CNNs) face two fundamental limitations: severe performance degradation in low Jamming-to-Signal Ratio (JSR) regimes due to noise obscuration, and ``feature degeneracy'' caused by the loss of phase information in magnitude-only spectrograms. Consequently, spectrally similar signals -- such as high-order Quadrature Amplitude Modulation versus Band-Limited Gaussian Noise -- become indistinguishable. To overcome these challenges, this paper proposes the \textbf{JSR-Guided Fusion Network (JSR-GFNet)}. This multi-modal architecture combines phase-sensitive complex In-Phase/Quadrature (IQ) samples with Short-Time Fourier Transform (STFT) spectrograms. Central to this framework is a physics-inspired dynamic gating mechanism driven by statistical signal descriptors. Acting as a conditional controller, it autonomously estimates signal reliability to dynamically reweight the contributions of a Complex-Valued ResNet (IQ stream) and an EfficientNet backbone (STFT stream). To validate the model, we introduce the Comprehensive GNSS Interference (CGI-21) dataset, simulating 21 jamming categories including software-defined waveforms from aerial platforms. Extensive experiments demonstrate that JSR-GFNet achieves higher accuracy across the full 10--50 dB JSR spectrum. Notably, interpretability analysis confirms that the model learns a physically intuitive strategy: prioritizing spectral energy integration in noise-limited regimes while shifting focus to phase precision in high-SNR scenarios to resolve modulation ambiguities. This framework provides a robust solution for next-generation aerospace navigation security.

</details>


### [2] [Experimental Validation of SBFD ISAC in an FR3 Distributed SIMO Testbed](https://arxiv.org/abs/2602.00054)
*Bixing Yan,Kwadwo Mensah Obeng Afrane,Achiel Colpaert,Andre Kokkeler,Sofie Pollin,Yang Miao*

Main category: eess.SP

TL;DR: 本文提出了一种基于子带全双工(SBFD)的集成感知与通信(ISAC)系统，通过OFDM子带分配实现感知与通信的同时运行，在室内测试中验证了可行性，相比多频带基准节省了频谱资源。


<details>
  <summary>Details</summary>
Motivation: 集成感知与通信(ISAC)是未来无线网络的关键使能技术，但传统方法存在频谱资源浪费和相互干扰问题。本文旨在开发一种更高效的SBFD ISAC系统，实现感知与通信的同时运行并减少资源消耗。

Method: 采用子带全双工(SBFD)架构，将2048个OFDM子载波划分为三个非重叠子带：两个用于感知（使用Zadoff-Chu序列），一个用于通信（使用QPSK）。构建分布式测试平台，使用三个USRP X410设备工作在6.8 GHz，每通道20 MHz带宽，每个USRP传输一个子带同时接收所有三个子带，形成1×3 SIMO节点。通过主机-服务器协调实现时间同步，无需外部时钟分发。

Result: 室内测量验证了SBFD ISAC系统的可行性：单基地感知达到0.145 m/s的速度分辨率，非视距条件下的通信误码率为3.63e-3。相比需要三倍频谱的多频带基准，SBFD配置实现了相当的测速精度，同时节省了频谱资源。感知与通信的性能权衡主要取决于子载波分配策略而非相互干扰。

Conclusion: SBFD ISAC系统成功实现了感知与通信的同时运行，通过子带分配有效减少了相互干扰。系统在资源效率方面优于传统多频带方法，为未来ISAC系统的实际部署提供了可行的硬件实现方案。

Abstract: Integrated sensing and communication (ISAC) is a key enabler for future radio networks. This paper presents a sub-band full-duplex (SBFD) ISAC system that assigns non-overlapping OFDM subbands to sensing and communication, enabling simultaneous operation with minimal interference. A distributed testbed with three SIMO nodes is implemented using USRP X410 devices operating at 6.8 GHz with 20 MHz bandwidth per channel. A total of 2048 OFDM subcarriers are partitioned into three subbands: two for sensing using Zadoff-Chu sequences and one for communication using QPSK. Each USRP transmits one subband while receiving signals across all three, forming a 1 x 3 SIMO node. Time synchronization is achieved through host-server coordination without external clock distribution. Indoor measurements, validated against MOCAP ground truth, confirm the feasibility of the SBFD ISAC system. The results demonstrate monostatic sensing with a velocity resolution of 0.145 m/s, and communication under NLoS conditions with a BER of 3.63e-3. Compared with a multiband benchmark requiring three times more spectrum, the SBFD configuration achieves comparable velocity estimation accuracy while conserving resources. The sensing and communication performance trade-off is determined by subcarrier allocation strategy rather than mutual interference.

</details>


### [3] [Dual-Tier IRS-Assisted Mid-Band 6G Mobile Networks: Robust Beamforming and User Association](https://arxiv.org/abs/2602.00431)
*Muddasir Rahim,Soumaya Cherkaoui*

Main category: eess.SP

TL;DR: 提出IRS辅助的6G网络资源分配框架，结合地面和空中IRS解决LoS阻塞问题，针对FR3频段，通过分解问题、迫零波束成形和稳定匹配算法优化性能。


<details>
  <summary>Details</summary>
Motivation: 物联网应用快速增长需要6G网络中的鲁棒资源分配，特别是在7-15GHz的FR3频段。现有研究局限于地面IRS和毫米波/太赫兹频段，而FR3频段被认为是6G的"黄金频段"，需要解决严重视距阻塞下的可靠连接问题。

Method: 提出新颖的智能可重构表面辅助框架，结合地面IRS和低空平台站上的空中IRS。将联合波束成形和用户关联问题建模为混合整数非线性规划，通过问题分解、迫零波束成形和稳定匹配算法求解。

Result: 综合仿真表明，该方法在显著降低复杂度的同时接近穷举搜索的性能，优于现有的贪婪和随机基线方法，为实际6G部署提供了可扩展的蓝图。

Conclusion: 该研究为6G网络中大规模物联网连接提供了有效的资源分配解决方案，特别是在具有挑战性的环境中，通过地面和空中IRS的协同工作确保了可靠连接。

Abstract: The rapid growth of Internet of Things (IoT) applications necessitates robust resource allocation in future sixth-generation (6G) networks, particularly at the upper mid-band (7-15 GHz, FR3). This paper presents a novel intelligent reconfigurable surface (IRS)-assisted framework combining terrestrial IRS (TIRS) and aerial IRS (AIRS) mounted on low-altitude platform stations, to ensure reliable connectivity under severe line-of-sight (LoS) blockages. Distinguishing itself from prior work restricted to terrestrial IRS and mmWave and THz bands, this work targets the FR3 spectrum, the so-called Golden Band for 6G. The joint beamforming and user association (JBUA) problem is formulated as a mixed-integer nonlinear program (MINLP), solved through problem decomposition, zero-forcing beamforming, and a stable matching algorithm. Comprehensive simulations show our method approaches exhaustive search performance with significantly lower complexity, outperforming existing greedy and random baselines. These results provide a scalable blueprint for real-world 6G deployments, supporting massive IoT connectivity in challenging environments.

</details>


### [4] [Reliable IoT Communications in 6G Non-Terrestrial Networks with Dual RIS](https://arxiv.org/abs/2602.00438)
*Muddasir Rahim,Soumaya Cherkaoui*

Main category: eess.SP

TL;DR: 提出了一种基于可重构智能表面的双层RIS辅助6G物联网通信框架，通过联合波束成形、功率分配和设备关联优化来最大化网络总速率


<details>
  <summary>Details</summary>
Motivation: 物联网应用需求增长推动6G网络需要更鲁棒的资源分配方案，特别是在严重视距阻塞情况下确保可靠连接

Method: 采用双层RIS结构（地面RIS和高空平台RIS），将问题建模为MINLP，通过分解方法：ZF技术优化波束成形矩阵、推导功率分配的闭式解、基于可实现数据速率的稳定匹配算法进行设备-RIS关联

Result: 仿真表明所提方案性能接近穷举搜索但复杂度显著降低，优于贪婪搜索和随机搜索基准，收敛速度远快于穷举搜索方案

Conclusion: 提出的双层RIS辅助通信框架和分解优化方法能有效解决6G物联网资源分配问题，在性能和复杂度之间取得良好平衡

Abstract: The increasing demand for Internet of Things (IoT) applications has accelerated the need for robust resource allocation in sixth-generation (6G) networks. In this paper, we propose a reconfigurable intelligent surface (RIS)-assisted upper mid-band communication framework. To ensure robust connectivity under severe line-of-sight (LoS) blockages, we use a two-tier RIS structure comprising terrestrial RISs (TRISs) and high-altitude platform station (HAPS)-mounted RISs (HRISs). To maximize network sum rate, we formulate a joint beamforming, power allocation, and IoT device association (JBPDA) problem as a mixed-integer nonlinear program (MINLP). The formulated MINLP problem is challenging to solve directly; therefore, we tackle it via a decomposition approach. The zero-forcing (ZF) technique is used to optimize the beamforming matrix, a closed-form expression for power allocation is derived, and a stable matching-based algorithm is proposed for device-RIS association based on achievable data rates. Comprehensive simulations demonstrate that the proposed scheme approaches the performance of exhaustive search (ES) while exhibiting substantially lower complexity, and it consistently outperforms greedy search (GS) and random search (RS) baselines. Moreover, the proposed scheme converges much faster than the ES scheme.

</details>


### [5] [Fronthaul-Efficient Distributed Cooperative 3D Positioning with Quantized Latent CSI Embeddings](https://arxiv.org/abs/2602.00664)
*Tong An,Jiwei Zhao,Jiayang Shi,Bin Zheng,Kai Yu,Maged Elkashlan,George K. Karagiannidis,Hongsheng Chen*

Main category: eess.SP

TL;DR: 提出基于学习的边云协同定位框架，在有限容量前传约束下，通过神经网络压缩CSI并量化传输，实现密集城市NLOS环境中的高精度3D定位。


<details>
  <summary>Details</summary>
Motivation: 在密集城市非视距环境中，多基站协同定位需要大量CSI数据传输，导致前传开销过大，限制了实际可扩展性。

Method: 采用边云协同架构：每个基站部署神经网络压缩本地CSI为量化表示（固定前传负载），中央单元联合处理多基站压缩CSI进行协同3D定位。采用两阶段训练策略：基站自监督本地训练和中央单元端到端联合定位训练。

Result: 在3.5GHz 5G NR兼容城市射线追踪场景（6个基站，20MHz带宽）中，平均3D定位误差0.48m，90%分位数误差0.83m，前传负载降至无损CSI传输的6.25%，性能接近全CSI交换的协同定位。

Conclusion: 所提学习型边云协同定位框架在显著降低前传开销的同时，保持了接近全CSI交换的定位精度，为密集城市NLOS环境中的可扩展高精度定位提供了有效解决方案。

Abstract: High-precision three-dimensional (3D) positioning in dense urban non-line-of-sight (NLOS) environments benefits significantly from cooperation among multiple distributed base stations (BSs). However, forwarding raw CSI from multiple BSs to a central unit (CU) incurs prohibitive fronthaul overhead, which limits scalable cooperative positioning in practice. This paper proposes a learning-based edge-cloud cooperative positioning framework under limited-capacity fronthaul constraints. In the proposed architecture, a neural network is deployed at each BS to compress the locally estimated CSI into a quantized representation subject to a fixed fronthaul payload. The quantized CSI is transmitted to the CU, which performs cooperative 3D positioning by jointly processing the compressed CSI received from multiple BSs. The proposed framework adopts a two-stage training strategy consisting of self-supervised local training at the BSs and end-to-end joint training for positioning at the CU. Simulation results based on a 3.5~GHz 5G NR compliant urban ray-tracing scenario with six BSs and 20~MHz bandwidth show that the proposed method achieves a mean 3D positioning error of 0.48~m and a 90th-percentile error of 0.83~m, while reducing the fronthaul payload to 6.25% of lossless CSI forwarding. The achieved performance is close to that of cooperative positioning with full CSI exchange.

</details>


### [6] [CMANet: Channel-Masked Attention Network for Cooperative Multi-Base-Station 3D Positioning](https://arxiv.org/abs/2602.00696)
*Tong An,Huan Lu,Jiayang Shi,Kai Yu,Rongrong Zhu,Bin Zheng,Jiwei Zhao,Haibo Zhou*

Main category: eess.SP

TL;DR: CMANet：一种基于信道掩码注意力机制的多基站协作定位架构，利用原始CSI进行特征级融合，在5G城市环境中实现亚米级定位精度。


<details>
  <summary>Details</summary>
Motivation: 下一代无线系统需要实现无处不在的高精度定位，但在多径丰富的城市环境中仍然具有挑战性。通过利用信道状态信息（CSI）中嵌入的细粒度多径特性，可以实现更可靠和精确的定位。

Method: 提出CMANet多基站协作定位架构，采用信道掩码注意力（CMA）机制进行原始CSI的特征级融合。CMA编码器将物理基础先验（每基站信道增益）注入注意力权重，强调可靠链路并抑制虚假多径。轻量级LSTM解码器将子载波视为序列，将频域证据累积为最终的3D位置估计。

Result: 在典型的5G NR兼容城市仿真中，CMANet实现了小于0.5米的中值误差和1.0米的90%分位数误差，优于最先进的基准方法。消融实验验证了CMA和频率累积的必要性。

Conclusion: CMANet是边缘可部署的，并展示了面向集成感知与通信（ISAC）的多基站CSI定位协作范式。

Abstract: Achieving ubiquitous high-accuracy localization is crucial for next-generation wireless systems, yet remains challenging in multipath-rich urban environments. By exploiting the fine-grained multipath characteristics embedded in channel state information (CSI), more reliable and precise localization can be achieved. To address this, we present CMANet, a multi-BS cooperative positioning architecture that performs feature-level fusion of raw CSI using the proposed Channel Masked Attention (CMA) mechanism. The CMA encoder injects a physically grounded prior--per-BS channel gain--into the attention weights, thus emphasizing reliable links and suppressing spurious multipath. A lightweight LSTM decoder then treats subcarriers as a sequence to accumulate frequency-domain evidence into a final 3D position estimate. In a typical 5G NR-compliant urban simulation, CMANet achieves less than 0.5m median error and 1.0m 90th-percentile error, outperforming state-of-the-art benchmarks. Ablations verify the necessity of CMA and frequency accumulation. CMANet is edge-deployable and exemplifies an Integrated Sensing and Communication (ISAC)-aligned, cooperative paradigm for multi-BS CSI positioning.

</details>


### [7] [Comparative Analysis of Differential and Collision Entropy for Finite-Regime QKD in Hybrid Quantum Noisy Channels](https://arxiv.org/abs/2602.00705)
*Mouli Chakraborty,Subhash Chandra,Avishek Nag,Trung Q. Duong,Merouane Debbah,Anshu Mukherjee*

Main category: eess.SP

TL;DR: 该研究比较了混合量子信道中三种基本熵度量：微分熵、量子Rényi熵和量子碰撞熵，建立了它们之间的理论等价性，并将分析扩展到有限密钥QKD的操作领域。


<details>
  <summary>Details</summary>
Motivation: 研究混合量子通信系统中不确定性量化的统一视角，混合量子噪声同时包含离散和连续变量噪声分量，需要建立不同熵度量之间的理论联系。

Method: 使用高斯混合模型统计建模混合量子噪声，构建并可视化3D概率景观中的逐点熵函数，通过解析和数值评估比较微分熵、量子Rényi熵和量子碰撞熵。

Result: 在特定混合条件下，微分熵趋近于量子碰撞熵，这与α=2的Rényi熵一致，建立了这些度量在混合量子信道框架下的理论和计算等价性。

Conclusion: 该研究为混合量子通信系统的不确定性量化提供了统一视角，并将分析扩展到有限密钥QKD，展示了10%近似阈值对Eve成功概率和安全密钥率的显著影响。

Abstract: In this work, a comparative study between three fundamental entropic measures, differential entropy, quantum Renyi entropy, and quantum collision entropy for a hybrid quantum channel (HQC) was investigated, where hybrid quantum noise (HQN) is characterized by both discrete and continuous variables (CV) noise components. Using a Gaussian mixture model (GMM) to statistically model the HQN, we construct as well as visualize the corresponding pointwise entropic functions in a given 3D probabilistic landscape. When integrated over the relevant state space, these entropic surfaces yield values of the respective global entropy. Through analytical and numerical evaluation, it is demonstrated that the differential entropy approaches the quantum collision entropy under certain mixing conditions, which aligns with the Renyi entropy for order $α= 2$. Within the HQC framework, the results establish a theoretical and computational equivalence between these measures. This provides a unified perspective on quantifying uncertainty in hybrid quantum communication systems. Extending the analysis to the operational domain of finite key QKD, we demonstrated that the same $10\%$ approximation threshold corresponds to an order-of-magnitude change in Eves success probability and a measurable reduction in the secure key rate.

</details>


### [8] [Denoising deterministic networks using iterative Fourier transforms](https://arxiv.org/abs/2602.00790)
*H. Robert Frost*

Main category: eess.SP

TL;DR: 提出了一种基于傅里叶变换的迭代方法(IterativeFT)，用于在存在边剪枝和高斯噪声的情况下识别确定性网络结构，通过交替在实域和频域进行稀疏化操作来去噪。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的网络数据常常受到噪声污染和边缺失的影响，这使得识别网络的确定性结构变得困难。现有的网络去噪方法在处理同时存在噪声边和缺失边的情况时效果有限。

Method: 提出IterativeFT方法：对网络邻接矩阵迭代执行2D离散傅里叶正变换和逆变换，通过在实域和频域表示上应用稀疏化操作实现去噪。算法收敛于实域稀疏模式稳定时。

Result: 在Kautz、格网、树和二分网络等确定性模型上，IterativeFT相比简单的实域/频域阈值化、降秩重建和局部自适应网络稀疏化方法表现最佳。特别在格网和Kautz网络上优势明显，在树和二分网络上也有竞争力。能有效过滤噪声边并恢复缺失的真实边。

Conclusion: IterativeFT方法在存在边剪枝和高斯噪声的情况下，能有效识别确定性网络结构，相比现有方法具有更好的去噪和边恢复性能，为网络结构分析提供了新的工具。

Abstract: We detail a novel Fourier-based approach (IterativeFT) for identifying deterministic network structure in the presence of both edge pruning and Gaussian noise. This technique involves the iterative execution of forward and inverse 2D discrete Fourier transforms on a target network adjacency matrix. The denoising ability of the method is achieved via the application of a sparsification operation to both the real and frequency domain representations of the adjacency matrix with algorithm convergence achieved when the real domain sparsity pattern stabilizes. To demonstrate the effectiveness of the approach, we apply it to noisy versions of several deterministic models including Kautz, lattice, tree and bipartite networks. For contrast, we also evaluate preferential attachment networks to illustrate the behavior on stochastic graphs. We compare the performance of IterativeFT against simple real domain and frequency domain thresholding, reduced rank reconstruction and locally adaptive network sparsification. Relative to the comparison network denoising approaches, the proposed IterativeFT method provides the best overall performance for lattice and Kuatz networks with competitive performance on tree and bipartite networks. Importantly, the InterativeFT technique is effective at both filtering noisy edges and recovering true edges that are missing from the observed network.

</details>


### [9] [Calibration-Free Induced Magnetic Field Indoor and Outdoor Positioning via Data-Driven Modeling](https://arxiv.org/abs/2602.00817)
*Qiushi Guo,Matthias Tschoepe,Mengxi Liu,Sizhen Bian,Paul Lukowicz*

Main category: eess.SP

TL;DR: 提出基于数据驱动的感应磁场定位框架，使用监督学习直接将磁场测量映射到空间坐标，无需环境特定校准，在室内外实现亚米级精度定位。


<details>
  <summary>Details</summary>
Motivation: 现有磁场定位系统依赖解析场反演、手动校准或环境特定指纹识别，限制了系统的可扩展性和可移植性。需要一种更灵活、可扩展的定位方法。

Method: 采用数据驱动的感应磁场定位框架，使用监督学习（随机森林回归器）直接从磁场测量映射到空间坐标，无需显式环境建模。引入方向不变特征表示实现旋转无关部署。

Result: 在多个室内环境和室外部署中评估，随机森林回归器在2D定位中达到亚20厘米精度，3D定位达到亚30厘米精度。跨环境验证显示室内训练的模型无需重新训练即可泛化到室外环境。

Conclusion: 数据驱动的感应磁场定位是一种可扩展且可移植的解决方案，通过部署密度平衡覆盖范围和精度，为实际定位应用提供了新途径。

Abstract: Induced magnetic field (IMF)-based localization offers a robust alternative to wave-based positioning technologies due to its resilience to non-line-of-sight conditions, environmental dynamics, and wireless interference. However, existing magnetic localization systems typically rely on analytical field inversion, manual calibration, or environment-specific fingerprinting, limiting their scalability and transferability. This paper presents a data-driven IMF localization framework that directly maps induced magnetic field measurements to spatial coordinates using supervised learning, eliminating explicit environment-specific calibration. By replacing explicit field modeling with learning-based inference, the proposed approach captures nonlinear field interactions and environmental effects. An orientation-invariant feature representation enables rotation-independent deployment. The system is evaluated across multiple indoor environments and an outdoor deployment. Benchmarking against classical and deep learning baselines shows that a Random Forest regressor achieves sub-20 cm accuracy in 2D and sub-30 cm in 3D localization. Cross-environment validation demonstrates that models trained indoors generalize to outdoor environments without retraining. We further analyze scalability by varying transmitter spacing, showing that coverage and accuracy can be balanced through deployment density. Overall, this work demonstrates that data-driven IMF localization is a scalable and transferable solution for real-world positioning.

</details>


### [10] [mmWave Sensing for Detecting Movement Through Thermoplastic Masks During Radiation Therapy Treatment](https://arxiv.org/abs/2602.00917)
*Ali Kourani,Naveed A. Abbasi,Syeda Narjis Fatima,Katsuyuki Haneda,Andreas F. Molisch*

Main category: eess.SP

TL;DR: 使用毫米波传感技术透过热塑性面罩检测放疗中患者的细微运动，为实时运动跟踪和误差校正提供基础


<details>
  <summary>Details</summary>
Motivation: 放疗精度依赖于固定系统，但热塑性面罩仍无法完全消除患者的细微运动（如下颌移动、深呼吸、眨眼等）。现有运动跟踪方法存在局限：光学系统需要视线且仅检测表面运动，X射线跟踪则引入额外电离辐射。

Method: 研究使用低功率、非电离的毫米波传感进行透过面罩的运动检测。在28-38 GHz范围内表征热塑性面罩材料的射频特性，使用以28 GHz为中心的1 GHz带宽进行运动检测。采用频域系统和喇叭天线在定制消声室中捕获传输RF波在响应细微头面部运动时的幅度和相位变化。

Result: 成功表征了热塑性面罩材料在毫米波频段的射频特性，并展示了通过毫米波传感检测细微头面部运动的能力。

Conclusion: 这些发现为未来实时透过面罩运动跟踪以及与多天线系统和机器学习集成进行放疗误差校正奠定了基础。

Abstract: Precision in radiation therapy relies on immobilization systems that limit patient motion. Thermoplastic masks are commonly used for this purpose, but subtle voluntary and involuntary movements such as jaw shifts, deep breathing, or eye squinting may still compromise treatment accuracy. Existing motion tracking methods are limited: optical systems require a clear line of sight and only detect surface motion, while X-ray-based tracking introduces additional ionizing radiation. This study explores the use of low-power, non-ionizing millimeter-wave (mmWave) sensing for through-mask motion detection. We characterize the RF properties of thermoplastic mask material in the 28-38 GHz range and perform motion detection using a 1 GHz bandwidth centered at 28 GHz. We use a frequency-domain system with horn antennas in a custom-built anechoic chamber to capture changes in the amplitude and phase of transmitted RF waves in response to subtle head and facial movements. These findings lay groundwork for future real-time through-mask motion tracking and future integration with multi-antenna systems and machine learning for error correction during radiotherapy.

</details>


### [11] [Channel Modeling and Experimental Validation of Odor-Based Molecular Communication Systems](https://arxiv.org/abs/2602.01091)
*Ahmet B. Kilic,Fatih E. Bilgen,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 提出有界和无界气味分子通信信道数学模型，并通过实验验证模型准确性


<details>
  <summary>Details</summary>
Motivation: 气味分子通信是实现万物互联愿景的重要技术，但目前缺乏能够准确描述粒子在不同环境中传播的全面信道模型，现有研究缺乏理论建模与实验验证相结合的方法

Method: 提出有界和无界OMC信道的数学框架，开发新型实验测试平台，进行广泛性能分析，验证理论模型与实验数据的一致性

Result: 理论推导与实验数据表现出强相关性，为未来端到端OMC系统的设计和分析提供了坚实基础

Conclusion: 通过理论建模与实验验证相结合的方法，成功建立了准确的气味分子通信信道模型，推动了OMC系统的实际部署

Abstract: Odor-based Molecular Communication (OMC) employs odor molecules to convey information, contributing to the realization of the Internet of Everything (IoE) vision. Despite this, the practical deployment of OMC systems is currently limited by the lack of comprehensive channel models that accurately characterize particle propagation in diverse environments. While existing literature explores various aspects of molecular transport, a holistic approach that integrates theoretical modeling with experimental validation for bounded channels remains underdeveloped. In this paper, we address this gap by proposing mathematical frameworks for both bounded and unbounded OMC channels. To verify the accuracy of the proposed models, we develop a novel experimental testbed and conduct an extensive performance analysis. Our results demonstrate a strong correlation between the theoretical derivations and experimental data, providing a robust foundation for the design and analysis of future end-to-end OMC systems.

</details>


### [12] [Digital and Hybrid Precoding and RF Chain Selection Designs for Energy Efficient Multi-User MIMO-OFDM ISAC Systems](https://arxiv.org/abs/2602.01121)
*Po-Chun Kang,Ming-Chun Lee,Tzu-Chien Chiu,Ting-Yao Kuo,Ta-Sung Lee*

Main category: eess.SP

TL;DR: 该论文研究了多用户MIMO-OFDM ISAC系统的能效优化，通过联合预编码和RF链选择，提出了全数字和混合预编码架构的能效最大化设计。


<details>
  <summary>Details</summary>
Motivation: 现有MIMO-OFDM ISAC研究大多关注性能提升，而忽略了发射功率和射频电路功耗对能效的影响，这一研究空白需要填补。

Method: 首先构建了受感知性能约束的能效最大化问题，然后为全数字和混合预编码架构提出了高效的优化算法，并分析了计算复杂度和收敛性。

Result: 仿真结果表明，相比现有方案，所提方法在ISAC系统的能效-感知权衡方面取得了显著改进。

Conclusion: 该研究通过联合预编码和RF链优化，有效提升了MIMO-OFDM ISAC系统的能效，并提供了频谱效率与功耗的权衡设计。

Abstract: Using multiple-input multiple-output (MIMO) with orthogonal frequency division multiplexing (OFDM) for integrated sensing and communication (ISAC) has attracted considerable attention in recent years. While most existing works focus on improving MIMO-OFDM ISAC performance, the impact of transmit power and radio-frequency (RF) circuit power consumption on energy efficiency (EE) remains relatively underexplored. To address this gap, this paper investigates joint precoding and RF chain selection for multi-user MIMO-OFDM ISAC systems, and develops energy-efficient designs for both fully digital and hybrid precoding architectures through the joint optimization of precoding and RF-chain activation. Specifically, we first formulate a novel EE maximization problem subject to sensing performance constraints. Then, efficient optimization algorithms are proposed for both architectures, together with analyses of their computational complexity and convergence behavior. Building on the proposed approaches, spectral efficiency-power consumption tradeoff designs are also provided. Simulation results demonstrate that, compared with existing schemes, the proposed approaches achieve significant improvements in the EE-sensing tradeoff for ISAC systems.

</details>


### [13] [Generative AI in Signal Processing Education: An Audio Foundation Model Based Approach](https://arxiv.org/abs/2602.01249)
*Muhammad Salman Khan,Ahmad Ullah,Siddique Latif,Junaid Qadir*

Main category: eess.SP

TL;DR: SPEduAFM是一个为信号处理教育设计的音频基础模型概念，旨在通过生成式AI技术将传统信号处理原理与创新应用相结合，提升教学体验。


<details>
  <summary>Details</summary>
Motivation: 传统信号处理教育中抽象概念难以理解，缺乏互动性和实践性。音频基础模型作为生成式AI的专门类别，有潜力通过整合语音增强、降噪、源分离等核心应用，将抽象概念转化为可交互的实践体验，从而革新信号处理教育。

Method: 提出SPEduAFM概念框架，这是一个专门为信号处理教育定制的音频基础模型。通过设想案例研究，展示AFM如何支持自动讲座转录、交互式演示和包容性学习工具等应用，将传统信号处理原理与生成式AI驱动的创新相结合。

Result: 论文展示了AFM在信号处理教育中的多种潜在应用场景，包括自动转录、交互演示和包容性学习工具，能够将抽象概念转化为引人入胜的实践体验。同时识别了伦理、可解释性和定制化等挑战，强调动态实时听觉交互对促进体验式和真实学习的重要性。

Conclusion: SPEduAFM作为一个前瞻性愿景，旨在激发生成式AI在工程教育中的更广泛采用，通过增强课堂内外的可访问性、参与度和创新性，推动信号处理教育的变革。

Abstract: Audio Foundation Models (AFMs), a specialized category of Generative AI (GenAI), have the potential to transform signal processing (SP) education by integrating core applications such as speech and audio enhancement, denoising, source separation, feature extraction, automatic classification, and real-time signal analysis into learning and research. This paper introduces SPEduAFM, a conceptual AFM tailored for SP education, bridging traditional SP principles with GenAI-driven innovations. Through an envisioned case study, we outline how AFMs can enable a range of applications, including automated lecture transcription, interactive demonstrations, and inclusive learning tools, showcasing their potential to transform abstract concepts into engaging, practical experiences. This paper also addresses challenges such as ethics, explainability, and customization by highlighting dynamic, real-time auditory interactions that foster experiential and authentic learning. By presenting SPEduAFM as a forward-looking vision, we aim to inspire broader adoption of GenAI in engineering education, enhancing accessibility, engagement, and innovation in the classroom and beyond.

</details>


### [14] [Mismatch Analysis and Cooperative Calibration of Array Beam Patterns for ISAC Systems](https://arxiv.org/abs/2602.01293)
*Hui Chen,Mengting Li,Alireza Pourafzal,Huiping Huang,Yu Ge,Sigurd Sandor Petersen,Ming Shen,George C. Alexandropoulos,Henk Wymeersch*

Main category: eess.SP

TL;DR: 提出一种用于ISAC系统的阵列波束模式校准方法，通过基于角度估计误差的性能指标和协作校准框架，显著降低了角度估计误差。


<details>
  <summary>Details</summary>
Motivation: ISAC系统中，几何误差和硬件损伤导致的模型失配会降低感知性能，特别是角度估计精度。传统基于波束模式相似性的校准方法无法直接优化感知性能。

Method: 1) 提出基于角度估计误差而非波束模式相似性的新性能指标和可微分损失函数；2) 引入协作校准框架，允许多个用户设备基于本地数据迭代优化波束模式并协作更新全局校准参数。

Result: 在真实波束模式测量数据上验证，2D校准场景中角度估计误差从1.01°降至0.11°，3D校准场景中从5.19°降至0.86°，性能提升显著。

Conclusion: 所提出的校准方法和协作框架有效解决了ISAC系统中的阵列校准问题，显著提升了角度估计精度，为实际部署提供了实用解决方案。

Abstract: Integrated sensing and communication (ISAC) is a key technology for enabling a wide range of applications in future wireless systems. However, the sensing performance is often degraded by model mismatches caused by geometric errors (e.g., position and orientation) and hardware impairments (e.g., mutual coupling and amplifier non-linearity). This paper focuses on the angle estimation performance with antenna arrays and tackles the critical challenge of array beam pattern calibration for ISAC systems. To assess calibration quality from a sensing perspective, a novel performance metric that accounts for angle estimation error, rather than beam pattern similarity, is proposed and incorporated into a differentiable loss function. Additionally, a cooperative calibration framework is introduced, allowing multiple user equipments to iteratively optimize the beam pattern based on the proposed loss functions and local data, and collaboratively update global calibration parameters. The proposed models and algorithms are validated using real-world beam pattern measurements collected in an anechoic chamber. Experimental results show that the angle estimation error can be reduced from {$\textbf{1.01}^\circ$} to $\textbf{0.11}^\circ$ in 2D calibration scenarios, and from $\textbf{5.19}^\circ$ to $\textbf{0.86}^\circ$ in 3D calibration ones.

</details>


### [15] [Approximating Univariate Factored Distributions via Message-Passing Algorithms](https://arxiv.org/abs/2602.01377)
*Zilu Zhao,Dirk Slock*

Main category: eess.SP

TL;DR: 该论文提出了两种结合期望传播(EP)与先前技术的方法，用于近似单变量因子分布，特别是处理非可积信念问题。


<details>
  <summary>Details</summary>
Motivation: 高斯混合模型(GMMs)在通信系统中常见，但因子乘积会导致组件数量指数增长。虽然信念传播(BP)和变量复制高斯信念传播(VDBP)可用于近似，但期望传播(EP)在处理因子分布时可能因非可积信念而失败。

Method: 1. 提出VDBP算法：通过构建多变量测量模型，应用高斯BP将全局推理转化为局部问题；2. 提出两种结合EP与先前处理非可积信念技术的方法，直接近似因子分布。

Result: 论文提出了有效的消息传递算法框架，能够处理GMMs乘积中的指数增长问题，并解决了EP算法中非可积信念导致的失败问题。

Conclusion: 结合EP与处理非可积信念技术的方法为近似单变量因子分布提供了有效解决方案，特别适用于通信系统中的联合估计和检测问题。

Abstract: Gaussian Mixture Models (GMMs) commonly arise in communication systems, particularly in bilinear joint estimation and detection problems. Although the product of GMMs is still a GMM, as the number of factors increases, the number of components in the resulting product GMM grows exponentially. To obtain a tractable approximation for a univariate factored probability density function (PDF), such as a product of GMMs, we investigate iterative message-passing algorithms. Based on Belief Propagation (BP), we propose a Variable Duplication and Gaussian Belief Propagation (VDBP)-based algorithm. The key idea of VDBP is to construct a multivariate measurement model whose marginal posterior is equal to the given univariate factored PDF. We then apply Gaussian BP (GaBP) to transform the global inference problem into local ones. Expectation propagation (EP) is another branch of message passing algorithms. In addition to converting the global approximation problem into local ones, it features a projection operation that ensures the intermediate functions (messages) belong to a desired family. Due to this projection, EP can be used to approximate the factored PDF directly. However, even if every factor is integrable, the division operation in EP may still cause the algorithm to fail when the mean and variance of a non-integrable belief are required. Therefore, this paper proposes two methods that combine EP with our previously proposed techniques for handling non-integrable beliefs to approximate univariate factored distributions.

</details>


### [16] [Visible Light Positioning With Lamé Curve LEDs: A Generic Approach for Camera Pose Estimation](https://arxiv.org/abs/2602.01577)
*Wenxuan Pan,Yang Yang,Dong Wei,Zhiyu Zhu,Jintao Wang,Huan Wu,Yao Nie*

Main category: eess.SP

TL;DR: 提出LC-VLP算法，利用Lamé曲线统一表示不同LED形状，实现异构LED场景下的相机姿态估计，相比现有方法显著降低定位误差。


<details>
  <summary>Details</summary>
Motivation: 现有基于LED形状的可见光定位方法通常局限于单一LED几何形状，在异构LED形状场景中会失效。需要一种能够处理不同LED形状的统一表示方法。

Method: 使用Lamé曲线作为常见LED形状的统一表示；通过可见光通信传输曲线参数；构建离线LED数据库；将在线定位建模为非线性最小二乘问题；开发FreePnP算法提供可靠初始化。

Result: 仿真显示LC-VLP在圆形和矩形LED场景中均优于现有方法，位置误差降低超过40%，旋转误差降低超过25%；实验验证平均定位精度小于4厘米。

Conclusion: LC-VLP算法通过Lamé曲线统一表示LED形状，成功解决了异构LED形状场景下的相机姿态估计问题，实现了高精度定位。

Abstract: Camera-based visible light positioning (VLP) is a promising technique for accurate and low-cost indoor camera pose estimation (CPE). To reduce the number of required light-emitting diodes (LEDs), advanced methods commonly exploit LED shape features for positioning. Although interesting, they are typically restricted to a single LED geometry, leading to failure in heterogeneous LED-shape scenarios. To address this challenge, this paper investigates Lamé curves as a unified representation of common LED shapes and proposes a generic VLP algorithm using Lamé curve-shaped LEDs, termed LC-VLP. In the considered system, multiple ceiling-mounted Lamé curve-shaped LEDs periodically broadcast their curve parameters via visible light communication, which are captured by a camera-equipped receiver. Based on the received LED images and curve parameters, the receiver can estimate the camera pose using LC-VLP. Specifically, an LED database is constructed offline to store the curve parameters, while online positioning is formulated as a nonlinear least-squares problem and solved iteratively. To provide a reliable initialization, a correspondence-free perspective-\textit{n}-points (FreeP\textit{n}P) algorithm is further developed, enabling approximate CPE without any pre-calibrated reference points. The performance of LC-VLP is verified by both simulations and experiments. Simulations show that LC-VLP outperforms state-of-the-art methods in both circular- and rectangular-LED scenarios, achieving reductions of over 40% in position error and 25% in rotation error. Experiments further show that LC-VLP can achieve an average position accuracy of less than 4 cm.

</details>


### [17] [Synthesized-Isotropic Narrowband Channel Parameter Extraction from Angle-Resolved Wideband Channel Measurements](https://arxiv.org/abs/2602.01646)
*Minseok Kim,Masato Yomoda*

Main category: eess.SP

TL;DR: 该论文重新审视了从角度分辨宽带测量中计算路径增益的技术挑战，提出了波束累积校正因子来补偿非正交扫描波束导致的功率估计偏差。


<details>
  <summary>Details</summary>
Motivation: 在毫米波和太赫兹频段，使用天线阵列或机械转向高增益天线进行角度分辨信道探测时，需要补偿测量响应中嵌入的辐射方向图效应，以提取天线无关的大尺度信道参数（如路径损耗、延迟扩展和角度扩展）。

Method: 首先将合成各向同性窄带功率统一表示为矩阵形式，然后引入波束累积校正因子，包括偏移平均变体以减轻离网角度引起的扇形效应。

Result: 通过使用信道模型的仿真和154GHz走廊测量验证了所提出的框架。

Conclusion: 该研究为从角度分辨宽带测量中准确计算路径增益提供了系统框架，解决了非正交扫描波束导致的功率估计偏差问题。

Abstract: Angle-resolved channel sounding using antenna arrays or mechanically steered high-gain antennas is widely employed at millimeter-wave and terahertz bands. To extract antenna-independent large-scale channel parameters such as path loss, delay spread, and angular spread, the radiation-pattern effects embedded in the measured responses must be properly compensated. This paper revisits the technical challenges of path-gain calculation from angle-resolved wideband measurements, with emphasis on angular-domain power integration where the scan beams are inherently non-orthogonal and simple power summation leads to biased omni-equivalent power estimates. We first formulate the synthesized-isotropic narrowband power in a unified matrix form and introduce a beam-accumulation correction factor, including an offset-averaged variant to mitigate scalloping due to off-grid angles. The proposed framework is validated through simulations using channel models and 154~GHz corridor measurements.

</details>


### [18] [Resolution-Aliasing Trade-off in Near-Field Localisation](https://arxiv.org/abs/2602.01947)
*Baptiste Sambon,Gilles Monnoyer,Luc Vandendorpe,Claude Oestges*

Main category: eess.SP

TL;DR: 该论文提出了一个统一框架来分析近场定位中的分辨率与混叠折衷，通过局部啁啾空间频率概念和几何工具（CAEs和NCZ）来指导XL-MIMO阵列设计。


<details>
  <summary>Details</summary>
Motivation: XL-MIMO系统在近场操作下为精确定位提供了新自由度，但密集阵列不切实际。稀疏或分布式阵列能降低硬件复杂度，但亚奈奎斯特空间采样会引入混叠伪影，需要研究分辨率与混叠之间的折衷关系。

Method: 提出统一框架，利用局部啁啾空间频率概念推导阵列几何与采样密度对接收场空间带宽的解析表达式，引入关键天线单元（CAEs）和非贡献区（NCZ）两个几何工具来分析天线对分辨率和混叠的贡献。

Result: 分析表明分辨率与混叠并非严格耦合，例如增加阵列孔径可以提高分辨率而不一定加剧混叠。这些结果为设计平衡分辨率与混叠的近场阵列提供了实用指导。

Conclusion: 该框架为XL-MIMO系统部署提供了优化阵列设计的理论基础，支持在近场定位中实现分辨率与混叠的最佳平衡，促进高效XL-MIMO部署。

Abstract: Extremely Large-scale MIMO (XL-MIMO) systems operating in Near-Field (NF) introduce new degrees of freedom for accurate source localisation, but make dense arrays impractical. Sparse or distributed arrays can reduce hardware complexity while maintaining high resolution, yet sub-Nyquist spatial sampling introduces aliasing artefacts in the localisation ambiguity function. This paper presents a unified framework to jointly characterise resolution and aliasing in NF localisation and study the trade-off between the two. Leveraging the concept of local chirp spatial frequency, we derive analytical expressions linking array geometry and sampling density to the spatial bandwidth of the received field. We introduce two geometric tools--Critical Antenna Elements (CAEs) and the Non-Contributive Zone (NCZ)--to intuitively identify how individual antennas contribute to resolution and/or aliasing. Our analysis reveals that resolution and aliasing are not always strictly coupled, e.g., increasing the array aperture can improve resolution without necessarily aggravating aliasing. These results provide practical guidelines for designing NF arrays that optimally balance resolution and aliasing, supporting efficient XL-MIMO deployment.

</details>


### [19] [Uncertainty-Weighted Multi-Task CNN for Joint DoA and Rain-Rate Estimation Under Rain-Induced Array Distortions](https://arxiv.org/abs/2602.01961)
*Chenyang Yan,Ruonan Yang,Shunqiao Sun,Mats Bengtsson*

Main category: eess.SP

TL;DR: 提出一种基于多任务深度CNN的方法，用于联合估计到达方向和降雨率，通过共享特征提取器和任务特定头，在降雨引起的乘性失真下实现准确估计。


<details>
  <summary>Details</summary>
Motivation: 研究在降雨引起的乘性失真条件下，均匀线性阵列的联合到达方向和降雨率估计问题。降雨会导致波前波动，影响阵列性能，需要同时估计这两个参数。

Method: 基于波前波动模型推导角度相关协方差公式，生成训练数据。将DoA估计建模为离散角度网格上的多标签分类问题，降雨率估计为多类分类任务。提出多任务深度CNN，包含共享特征提取器和两个任务特定头，使用不确定性加权目标自动平衡两个损失。

Result: 在双源场景的数值实验中，所提网络在中等至高信噪比下，相比经典基线方法获得更低的DoA均方根误差，并能提供准确的降雨率分类。

Conclusion: 多任务深度学习框架能有效处理降雨引起的乘性失真，实现联合DoA和降雨率估计，在恶劣天气条件下优于传统方法。

Abstract: We investigate joint direction-of-arrival (DoA) and rain-rate estimation for a uniform linear array operating under rain-induced multiplicative distortions. Building on a wavefront fluctuation model whose spatial correlation is governed by the rain-rate, we derive an angle-dependent covariance formulation and use it to synthesize training data. DoA estimation is cast as a multi-label classification problem on a discretized angular grid, while rain-rate estimation is formulated as a multi-class classification task. We then propose a multi-task deep CNN with a shared feature extractor and two task-specific heads, trained using an uncertainty-weighted objective to automatically balance the two losses. Numerical results in a two-source scenario show that the proposed network achieves lower DoA RMSE than classical baselines and provides accurate rain-rate classification at moderate-to-high SNRs.

</details>


### [20] [Obstacle Detection at Level Crossings under Adverse Weather Conditions -- A Survey](https://arxiv.org/abs/2602.01974)
*Chenyang Yan,Mats Bengtsson*

Main category: eess.SP

TL;DR: 本文综述了铁路平交道口障碍物检测的传感器技术与融合策略，重点分析不同传感器在恶劣天气下的性能局限及多传感器融合方法，旨在提升检测系统的鲁棒性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 铁路平交道口事故仍是现代铁路系统的重大安全隐患，特别是在恶劣天气条件下传感器性能下降时。需要研究更可靠的障碍物检测技术来提升铁路安全。

Method: 综述了多种传感器技术（感应线圈、摄像头、雷达、激光雷达）的工作原理、天气脆弱性和缓解策略，并分析了数据级、特征级和决策级三种多传感器融合架构。

Result: 不同传感器各有优缺点：感应线圈依赖材料、摄像头在低能见度下性能下降、雷达分辨率有限、激光雷达在恶劣天气中受限。多传感器融合能整合互补信息，提高可靠性和容错能力。

Conclusion: 未来研究方向包括自适应融合算法、实时处理流水线和天气弹性数据集，以支持部署智能、故障安全的检测系统，最终提升铁路平交道口的安全性。

Abstract: Level crossing accidents remain a significant safety concern in modern railway systems, particularly under adverse weather conditions that degrade sensor performance. This review surveys state-of-the-art sensor technologies and fusion strategies for obstacle detection at railway level crossings, with a focus on robustness, detection accuracy, and environmental resilience. Individual sensors such as inductive loops, cameras, radar, and LiDAR offer complementary strengths but involve trade-offs, including material dependence, reduced visibility, and limited resolution in harsh environments. We analyze each modality's working principles, weather-induced vulnerabilities, and mitigation strategies, including signal enhancement and machine-learning-based denoising. We further review multi-sensor fusion approaches, categorized as data-level, feature-level, and decision-level architectures, that integrate complementary information to improve reliability and fault tolerance. The survey concludes with future research directions, including adaptive fusion algorithms, real-time processing pipelines, and weather-resilient datasets to support the deployment of intelligent, fail-safe detection systems for railway safety.

</details>


### [21] [Silhouette Score Efficient Radio Frequency Fingerprint Feature Extraction](https://arxiv.org/abs/2602.02065)
*Xuan Yang,Dongming Li,Yi Lou,Xianglin Fan*

Main category: eess.SP

TL;DR: 本文提出了一个基于预编码的信道鲁棒射频指纹特征提取方法，并建立了使用轮廓分数作为评估指标的统一理论分析框架。


<details>
  <summary>Details</summary>
Motivation: 射频指纹识别技术容易受信道效应影响，现有方法主要依赖实验比较而非理论分析，缺乏理论指导阻碍了信道鲁棒特征提取方法的发展。

Method: 1) 使用轮廓分数作为评估指标，通过泰勒级数展开获得各种RFF特征提取方法的理论性能；2) 在认证设备处计算频域接收信号的倒数来减轻信道效应；3) 在确定性信道、i.i.d.随机信道和非i.i.d.随机信道三种场景下比较不同方法。

Result: 仿真和实验结果表明：轮廓分数是评估分类准确性的有效指标；提出的基于预编码的信道鲁棒RFF特征提取方法在信道变化下实现了最高的轮廓分数和分类准确率。

Conclusion: 本文建立了信道鲁棒RFF特征提取的理论分析框架，提出的预编码方法能有效对抗信道变化，为RFF特征提取提供了理论指导。

Abstract: Radio frequency fingerprint (RFF) identification technology, which exploits relatively stable hardware imperfections, is highly susceptible to constantly changing channel effects. Although various channel-robust RFF feature extraction methods have been proposed, they predominantly rely on experimental comparisons rather than theoretical analyses. This limitation hinders the progress of channel-robust RFF feature extraction and impedes the establishment of theoretical guidance for its design. In this paper, we establish a unified theoretical performance analysis framework for different RFF feature extraction methods using the silhouette score as an evaluation metric, and propose a precoding-based channel-robust RFF feature extraction method that enhances the silhouette score without requiring channel estimation. First, we employ the silhouette score as an evaluation metric and obtain the theoretical performance of various RFF feature extraction methods using the Taylor series expansion. Next, we mitigate channel effects by computing the reciprocal of the received signal in the frequency domain at the device under authentication. We then compare these methods across three different scenarios: the deterministic channel scenario, the independent and identically distributed (i.i.d.) stochastic channel scenario, and the non-i.i.d. stochastic channel scenario. Finally, simulation and experimental results demonstrate that the silhouette score is an efficient metric to evaluate classification accuracy. Furthermore, the results indicate that the proposed precoding-based channel-robust RFF feature extraction method achieves the highest silhouette score and classification accuracy under channel variations.

</details>


### [22] [Neurophysiological effects of museum modalities on emotional engagement with real artworks](https://arxiv.org/abs/2602.02086)
*Chen Feng,Sébastien Lugan,Karine Lasaracina,Midori Sugaya,Benoît Macq*

Main category: eess.SP

TL;DR: EEG研究显示不同数字解说形式（沉浸式投影、显示屏视频、原作观看）在艺术欣赏中引发不同的情感参与模式，而非参与程度差异。


<details>
  <summary>Details</summary>
Motivation: 博物馆越来越多地使用数字内容帮助观众理解艺术品，但人们对这些形式如何影响艺术体验中的情感参与知之甚少，需要研究数字解说内容如何调节艺术观看时的参与度。

Method: 在博物馆现场进行EEG研究，参与者体验三种模式：直接观看勃鲁盖尔画作、180°沉浸式解说投影、常规显示屏解说视频。使用睁眼基线法和Z标准化对比提取前额EEG标记，测量动机取向、内部参与、感知驱动和唤醒度。

Result: 不同模式产生特定的参与特征：显示屏解说视频引发高唤醒度和快速波段活动；沉浸式投影促进平静、存在导向的专注；原作观看反映内部调节的参与。数字解说内容影响参与风格而非参与量。

Conclusion: 在运营文化环境中使用轻量级EEG传感的研究表明，数字解说内容影响参与风格而非数量，这为新的多模态传感方法铺平道路，使博物馆能够优化解说媒体的形式和内容。

Abstract: Museums increasingly rely on digital content to support visitors' understanding of artworks, yet little is known about how these formats shape the emotional engagement that underlies meaningful art experiences. This research presents an in-situ EEG study on how digital interpretive content modulate engagement during art viewing. Participants experienced three modalities: direct viewing of a Bruegel painting, a 180° immersive interpretive projection, and a regular, display-based interpretive video. Frontal EEG markers of motivational orientation, internal involvement, perceptual drive, and arousal were extracted using eyes-open baselines and Z-normalized contrasts. Results show modality-specific engagement profiles: display-based interpretive video induced high arousal and fast-band activity, immersive projections promoted calm, presence-oriented absorption, and original artworks reflected internally regulated engagement. These findings, relying on lightweight EEG sensing in an operational cultural environment, suggest that digital interpretive content affects engagement style rather than quantity. This paves the way for new multimodal sensing approaches and enables museums to optimize the modalities and content of their interpretive media.

</details>


### [23] [RIS-Aided Wireless Amodal Sensing for Single-View 3D Reconstruction](https://arxiv.org/abs/2602.02148)
*Yuhan Wang,Haobo Zhang,Qingyu Liu,Hongliang Zhang,Lingyang Song*

Main category: eess.SP

TL;DR: 提出RIS辅助的无线非模态感知方案，通过大规模可重构智能表面增强空间分辨率并绕过障碍物，结合生成学习模型重建完整形状，利用误差预测模型优化RIS相移。


<details>
  <summary>Details</summary>
Motivation: 无线非模态感知在复杂环境中面临空间分辨率低、数据稀疏的问题，尤其是在遮挡环境下。需要一种能够增强空间分辨率并绕过障碍物的解决方案。

Method: 1) 提出RIS辅助的无线非模态感知方案，利用大规模RIS增强空间分辨率并创建绕过障碍物的反射路径；2) 使用生成学习模型从RIS视角重建完整形状；3) 开发误差预测模型学习RIS相移与非模态感知精度之间的映射关系，并基于此优化RIS相移。

Result: 在基准数据集上的实验结果显示，与传统方案相比，在相同RIS配置数量下，该方法至少减少了56.73%的重建误差。

Conclusion: RIS辅助的无线非模态感知方案能有效解决无线系统中数据稀疏和遮挡问题，通过优化RIS相移显著提高形状重建精度，为复杂环境下的非模态感知提供了有前景的解决方案。

Abstract: Amodal sensing is critical for various real-world sensing applications because it can recover the complete shapes of partially occluded objects in complex environments. Among various amodal sensing paradigms, wireless amodal sensing is a potential solution due to its advantages of environmental robustness, privacy preservation, and low cost. However, the sensing data obtained by wireless system is sparse for shape reconstruction because of the low spatial resolution, and this issue is further intensified in complex environments with occlusion. To address this issue, we propose a Reconfigurable Intelligent Surface (RIS)-aided wireless amodal sensing scheme that leverages a large-scale RIS to enhance the spatial resolution and create reflection paths that can bypass the obstacles. A generative learning model is also employed to reconstruct the complete shape based on the sensing data captured from the viewpoint of the RIS. In such a system, it is challenging to optimize the RIS phase shifts because the relationship between RIS phase shifts and amodal sensing accuracy is complex and the closed-form expression is unknown. To tackle this challenge, we develop an error prediction model that learns the mapping from RIS phase shifts to amodal sensing accuracy, and optimizes RIS phase shifts based on this mapping. Experimental results on the benchmark dataset show that our method achieves at least a 56.73% reduction in reconstruction error compared to conventional schemes under the same number of RIS configurations.

</details>


### [24] [Real-Time 2D LiDAR Object Detection Using Three-Frame RGB Scan Encoding](https://arxiv.org/abs/2602.02167)
*Soheil Behnam Roudsari,Alexandre S. Brandão,Felipe N. Martins*

Main category: eess.SP

TL;DR: 提出一种基于2D LiDAR的物体检测方法，通过堆叠连续三帧扫描数据作为RGB通道输入YOLOv8n，在嵌入式设备上实现实时高精度检测，无需构建占用栅格图。


<details>
  <summary>Details</summary>
Motivation: 室内服务机器人需要鲁棒、隐私友好且能在嵌入式硬件上运行的感知系统。传统RGB摄像头存在隐私问题，而现有LiDAR方法计算成本高。

Method: 将连续三帧2D LiDAR扫描数据堆叠为RGB通道，直接输入YOLOv8n网络，保留角度结构和运动线索，避免构建占用栅格图。

Result: 在Webots模拟的160个随机室内场景中，达到98.4% mAP@0.5（0.778 mAP@0.5:0.95），精确率94.9%，召回率94.7%。在树莓派5上实时运行，平均端到端延迟47.8ms。

Conclusion: 轻量级时间编码方法能在嵌入式设备上实现准确、实时的纯LiDAR检测，为室内机器人提供隐私友好、计算高效的感知方案。

Abstract: Indoor service robots need perception that is robust, more privacy-friendly than RGB video, and feasible on embedded hardware. We present a camera-free 2D LiDAR object detection pipeline that encodes short-term temporal context by stacking three consecutive scans as RGB channels, yielding a compact YOLOv8n input without occupancy-grid construction while preserving angular structure and motion cues. Evaluated in Webots across 160 randomized indoor scenarios with strict scenario-level holdout, the method achieves 98.4% mAP@0.5 (0.778 mAP@0.5:0.95) with 94.9% precision and 94.7% recall on four object classes. On a Raspberry Pi 5, it runs in real time with a mean post-warm-up end-to-end latency of 47.8ms per frame, including scan encoding and postprocessing. Relative to a closely related occupancy-grid LiDAR-YOLO pipeline reported on the same platform, the proposed representation is associated with substantially lower reported end-to-end latency. Although results are simulation-based, they suggest that lightweight temporal encoding can enable accurate and real-time LiDAR-only detection for embedded indoor robotics without capturing RGB appearance.

</details>


### [25] [Sampling-Free Diffusion Transformers for Low-Complexity MIMO Channel Estimation](https://arxiv.org/abs/2602.02202)
*Zhixiong Chen,Hyundong Shin,Arumugam Nallanathan*

Main category: eess.SP

TL;DR: 提出SF-DiT-CE：一种基于采样自由扩散Transformer的低复杂度MIMO信道估计方法，通过单次前向传播实现高精度估计，避免迭代采样


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的信道估计方法虽然性能优秀，但依赖迭代反向采样导致计算复杂度高，需要开发低复杂度的替代方案

Method: 利用MIMO信道的角度域稀疏性，训练轻量级扩散Transformer直接从扰动观测和噪声水平预测干净信道；推理时使用最小二乘估计和估计噪声作为条件，通过单次前向传播恢复信道

Result: 数值结果表明，该方法在显著降低复杂度的同时，实现了优于最先进基线的估计精度和鲁棒性

Conclusion: SF-DiT-CE通过消除迭代采样过程，为MIMO信道估计提供了高效且高性能的解决方案，平衡了计算复杂度和估计精度

Abstract: Diffusion model-based channel estimators have shown impressive performance but suffer from high computational complexity because they rely on iterative reverse sampling. This paper proposes a sampling-free diffusion transformer (DiT) for low-complexity MIMO channel estimation, termed SF-DiT-CE. Exploiting angular-domain sparsity of MIMO channels, we train a lightweight DiT to directly predict the clean channels from their perturbed observations and noise levels. At inference, the least square (LS) estimate and estimation noise condition the DiT to recover the channel in a single forward pass, eliminating iterative sampling. Numerical results demonstrate that our method achieves superior estimation accuracy and robustness with significantly lower complexity than state-of-the-art baselines.

</details>


### [26] [A Novel ISAC Waveform Based on Orthogonal Delay-Doppler Division Multiplexing with FMCW](https://arxiv.org/abs/2602.02248)
*Kehan Huang,Akram Shafie,Min Qiu,Elias Aboutanios,Jinhong Yuan*

Main category: eess.SP

TL;DR: 提出ODDM-FMCW波形，将正交延迟多普勒复用调制与调频连续波结合，用于低PAPR的集成感知与通信系统


<details>
  <summary>Details</summary>
Motivation: 传统线性FMCW波形在ISAC系统中存在局限性，需要开发既能实现低峰均功率比，又能同时优化感知与通信性能的波形设计

Method: 1. 提出平方根奈奎斯特滤波FMCW波形；2. 在延迟多普勒域嵌入符号生成DD-SRN-FMCW帧；3. 设计DD啁啾压缩接收机；4. 将DD-SRN-FMCW帧叠加到ODDM数据帧上构建ODDM-FMCW波形

Result: 数值结果表明，ODDM-FMCW波形在感知的均方根误差和通信的误码率方面都表现出优异的ISAC性能

Conclusion: ODDM-FMCW波形为集成感知与通信系统提供了一种有效的低PAPR解决方案，在感知精度和通信可靠性方面均表现优越

Abstract: In this work, we propose the orthogonal delay-Doppler (DD) division multiplexing (ODDM) modulation with frequency modulated continuous wave (FMCW) (ODDM-FMCW) waveform to enable integrated sensing and communication (ISAC) with a low peak-to-average power ratio (PAPR). We first propose a square-root-Nyquist-filtered FMCW (SRN-FMCW) waveform to address limitations of conventional linear FMCW waveforms in ISAC systems. To better integrate with ODDM, we generate SRN-FMCW by embedding symbols in the DD domain, referred to as a DD-SRN-FMCW frame. A DD chirp compression receiver is designed to obtain the channel response efficiently. Next, we construct the proposed ODDM-FMCW waveform for ISAC by superimposing a DD-SRN-FMCW frame onto an ODDM data frame. A comprehensive performance analysis of the ODDM-FMCW waveform is presented, covering peak-to-average power ratio, spectrum, ambiguity function, and Cramer-Rao bound for delay and Doppler estimation. Numerical results show that the proposed ODDM-FMCW waveform delivers excellent ISAC performance in terms of root mean square error for sensing and bit error rate for communications.

</details>


### [27] [Flexible laboratory setup for DAC experimentation](https://arxiv.org/abs/2602.02312)
*Alfredo Pérez Vega-Leal,Manuel G. Satué*

Main category: eess.SP

TL;DR: 本文回顾了多种DAC方案，重点研究模拟多路复用技术，并基于商用FPGA系统开发了时间交织Σ-Δ调制DAC原型


<details>
  <summary>Details</summary>
Motivation: 在现代发射机中，速度是主要限制因素，模拟多路复用技术有望成为解决方案。目标是开发低成本方案来比较不同的数模转换方案

Method: 回顾了模拟多路复用技术、高速单DAC、Σ-Δ调制和动态元件匹配等技术，并基于商用FPGA系统开发了时间交织Σ-Δ调制DAC原型

Result: 提出了一个基于商用FPGA系统的时间交织Σ-Δ调制DAC原型实现

Conclusion: 模拟多路复用技术在现代高速发射机中具有应用潜力，通过时间交织Σ-Δ调制DAC原型验证了该技术的可行性

Abstract: Analog multiplexing appears to be a promising solution for modern transmitters, where speed is the primary limitation. The objective is the development of a low-cost solution to compare different digital to analog (DAC) schemes. In particular, analog multiplexing techniques, high-speed single-DAC, Sigma-delta modulation, Dynamic element matching are considered. The work presents a review of these techniques and shows a prototype of a time interleaved sigma delta modulation based DAC based on a commercially available Field Programmable Gate Array system.

</details>


### [28] [A Track-Before-Detect Trajectory Multi-Bernoulli Filter for Generalised Superpositional Measurements](https://arxiv.org/abs/2602.02365)
*Sion Lynch,Ángel F. García-Fernández,Lee Devlin*

Main category: eess.SP

TL;DR: 提出T-IEMB滤波器用于轨迹估计，采用高斯实现降低计算成本，在非高斯雷达跟踪场景中优于粒子滤波方法


<details>
  <summary>Details</summary>
Motivation: 针对轨迹检测前跟踪应用中的轨迹估计问题，需要处理广义叠加测量模型，现有粒子滤波方法计算成本高，需要更高效的解决方案

Method: 提出轨迹信息交换多伯努利滤波器，采用高斯实现通过近似测量模型的条件矩来执行更新，支持叠加隐藏变量映射到测量条件均值和协方差

Result: 在非高斯雷达跟踪场景中，两种高斯T-IEMB实现相比最先进的粒子滤波方法提供更好的跟踪性能，同时计算成本更低

Conclusion: T-IEMB滤波器能够有效处理广义叠加测量模型，高斯实现提供计算轻量化的滤波解决方案，在轨迹检测前跟踪应用中具有优越性能

Abstract: This paper proposes the Trajectory-Information Exchange Multi-Bernoulli (T-IEMB) filter to estimate sets of alive and all trajectories in track-before-detect applications with generalised superpositional measurements. This measurement model has superpositional hidden variables which are mapped to the conditional mean and covariance of the measurement, enabling it to describe a broad range of measurement models. This paper also presents a Gaussian implementation of the T-IEMB filter, which performs the update by approximating the conditional moments of the measurement model, and admits a computationally light filtering solution. Simulation results for a non-Gaussian radar-based tracking scenario demonstrate the performance of two Gaussian T-IEMB implementations, which provide improved tracking performance compared to a state-of-the-art particle filter based solution for track-before-detect, at a reduced computational cost.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [29] [High-Fidelity Generative Audio Compression at 0.275kbps](https://arxiv.org/abs/2602.00648)
*Hao Ma,Ruihao Jing,Shansong Liu,Cheng Gong,Chi Zhang,Xiao-Lei Zhang,Xuelong Li*

Main category: eess.AS

TL;DR: 提出生成式音频压缩(GAC)新范式，通过语义理解+生成合成实现超低码率(0.275kbps)下的高保真音频重建，相比传统波形重建方法有显著优势


<details>
  <summary>Details</summary>
Motivation: 传统音频压缩方法和现代神经编解码器基于波形重建设计，在超低码率下性能急剧下降，产生严重声学伪影和语义失真。需要从信号保真度转向任务导向有效性的新范式。

Method: 提出生成式音频压缩(GAC)框架，基于信息容量定律理论，在发送端进行语义理解，在接收端进行可扩展的生成合成，利用强大模型先验来分担信息负担，实现"更多计算，更少带宽"理念。

Result: 1.8B参数模型在32kHz通用音频上实现0.275kbps码率的高保真重建，在0.175kbps下仍保持强可懂音频传输能力，压缩比约3000倍，显著优于当前最先进的神经编解码器。

Conclusion: GAC代表了从信号保真度到任务导向有效性的范式转变，通过语义理解与生成合成的结合，在超低码率下实现了卓越的感知质量和语义一致性，为低带宽通信和生成音频-语言建模开辟了新途径。

Abstract: High-fidelity general audio compression at ultra-low bitrates is crucial for applications ranging from low-bandwidth communication to generative audio-language modeling. Traditional audio compression methods and contemporary neural codecs are fundamentally designed for waveform reconstruction. As a result, when operating at ultra-low bitrates, these methods degrade rapidly and often fail to preserve essential information, leading to severe acoustic artifacts and pronounced semantic distortion. To overcome these limitations, we introduce Generative Audio Compression (GAC), a novel paradigm shift from signal fidelity to task-oriented effectiveness. Implemented within the AI Flow framework, GAC is theoretically grounded in the Law of Information Capacity. These foundations posit that abundant computational power can be leveraged at the receiver to offset extreme communication bottlenecks--exemplifying the More Computation, Less Bandwidth philosophy. By integrating semantic understanding at the transmitter with scalable generative synthesis at the receiver, GAC offloads the information burden to powerful model priors. Our 1.8B-parameter model achieves high-fidelity reconstruction of 32kHz general audio at an unprecedented bitrate of 0.275kbps. Even at 0.175kbps, it still preserves a strong intelligible audio transmission capability, which represents an about 3000x compression ratio, significantly outperforming current state-of-the-art neural codecs in maintaining both perceptual quality and semantic consistency.

</details>


### [30] [Solving Room Impulse Response Inverse Problems Using Flow Matching with Analytic Wiener Denoiser](https://arxiv.org/abs/2602.00652)
*Kyung Yun Lee,Nils Meyer-Kahlen,Vesa Välimäki,Sebastian J. Schlecht*

Main category: eess.AS

TL;DR: RIRFlow：一种基于流匹配的无训练贝叶斯框架，用于房间脉冲响应逆问题，结合经典RIR统计模型与流生成推理。


<details>
  <summary>Details</summary>
Motivation: 现有RIR估计方法通常依赖监督学习或生成先验，需要大量训练数据且泛化能力有限。需要一种无需训练、基于RIR统计特性的鲁棒方法。

Method: 提出RIRFlow框架：1）从RIR统计结构推导流一致解析先验，将RIR建模为方差指数衰减的高斯过程；2）得到闭式MMSE维纳降噪器；3）将解析降噪器作为先验集成到基于流的逆求解器中，通过引导后验采样解决逆问题；4）通过引导后验的局部高斯近似扩展到非线性和非高斯逆问题。

Result: 在真实RIR数据上的实验表明，该方法在不同逆问题中表现鲁棒，验证了经典RIR模型与流生成推理结合的有效性。

Conclusion: RIRFlow通过结合经典RIR统计模型与流匹配生成推理，实现了无需训练、泛化能力强的RIR逆问题求解框架，为逆问题提供了新的贝叶斯解决方案。

Abstract: Room impulse response (RIR) estimation naturally arises as a class of inverse problems, including denoising and deconvolution. While recent approaches often rely on supervised learning or learned generative priors, such methods require large amounts of training data and may generalize poorly outside the training distribution. In this work, we present RIRFlow, a training-free Bayesian framework for RIR inverse problems using flow matching. We derive a flow-consistent analytic prior from the statistical structure of RIRs, eliminating the need for data-driven priors. Specifically, we model RIR as a Gaussian process with exponentially decaying variance, which yields a closed-form minimum mean squared error (MMSE) Wiener denoiser. This analytic denoiser is integrated as a prior in an existing flow-based inverse solver, where inverse problems are solved via guided posterior sampling. Furthermore, we extend the solver to nonlinear and non-Gaussian inverse problems via a local Gaussian approximation of the guided posterior, and empirically demonstrate that this approximation remains effective in practice. Experiments on real RIRs across different inverse problems demonstrate robust performance, highlighting the effectiveness of combining a classic RIR model with the recent flow-based generative inference.

</details>


### [31] [Adapting Where It Matters: Depth-Aware Adaptation for Efficient Multilingual Speech Recognition in Low-Resource Languages](https://arxiv.org/abs/2602.01008)
*Yang Xiao,Eun-Jung Holden,Ting Dang*

Main category: eess.AS

TL;DR: DAMA：一种深度感知模型适配框架，针对多语言ASR模型提出U形适配模式，通过SVD初始化和冻结中间层，在低资源语言上实现高效适配


<details>
  <summary>Details</summary>
Motivation: 现有语音基础模型在高资源语言上表现优异，但适配到低资源语言面临数据稀缺和效率限制。全模型微调计算成本高且容易过拟合，而参数高效方法如LoRA均匀适配各层，忽略了内部表示差异，影响效果和效率

Method: 分析多语言ASR模型发现U形适配模式：早期和晚期层是语言特定的需要更多适配，中间层保留共享语义需要较少适配。基于此提出DAMA框架，根据每层角色分配适配容量，引入SVD初始化约束适配并保持U形模式，以及冻结中间层基座进一步提高效率

Result: 在两个基准数据集的18种低资源语言上评估，DAMA在仅使用80%更少可训练参数的情况下达到或超过最先进准确率，在极端数据稀缺下实现29%错误率降低，并在内存、训练时间和计算效率上显著优于基线方法

Conclusion: 结构感知适配对高效、可扩展的多语言ASR具有重要价值，DAMA框架通过深度感知的适配策略在低资源语言场景下实现了更好的效果和效率平衡

Abstract: Recent speech foundation models excel at multilingual automatic speech recognition (ASR) for high-resource languages, but adapting them to low-resource languages remains challenging due to data scarcity and efficiency constraints. Full-model fine-tuning is computationally expensive and prone to overfitting, while parameter-efficient methods like LoRA apply adaptation uniformly across layers, overlooking internal representations thus compromising effectiveness and efficiency. We analyze multilingual ASR models and reveal a U-shaped adaptability pattern: early and late layers are language-specific and require more adaptation, while intermediate layers retain shared semantics and need less. Building on this observation, we propose DAMA, a Depth-Aware Model Adaptation framework that allocates adaptation capacity according to each layer's role. DAMA also introduces Singular Value Decomposition (SVD)-based initialization to constrain adaptation and preserve the U-shaped pattern, as well as a frozen middle-layer basis for further efficiency. Evaluated on 18 low-resource languages across two benchmark datasets, DAMA matches or surpasses state-of-the-art accuracy with 80% fewer trainable parameters, achieves a 29% error reduction under extreme data scarcity, and significantly improves memory, training time, and computational efficiency over baselines. These results highlight the benefits of structure-aware adaptation for efficient, scalable multilingual ASR.

</details>


### [32] [SSNAPS: Audio-Visual Separation of Speech and Background Noise with Diffusion Inverse Sampling](https://arxiv.org/abs/2602.01394)
*Yochai Yemini,Yoav Ellinson,Rami Ben-Ari,Sharon Gannot,Ethan Fetaya*

Main category: eess.AS

TL;DR: 提出基于生成逆采样的音频-视觉单麦克风语音分离与增强方法，在真实环境噪声下有效分离多个说话人并恢复噪声成分，无需监督训练即可超越监督基线。


<details>
  <summary>Details</summary>
Motivation: 解决真实环境噪声下的音频-视觉单麦克风语音分离与增强问题，传统方法通常需要监督训练且难以同时处理噪声和多个说话人。

Method: 采用生成逆采样框架，为干净语音和环境噪声分别建立扩散先验模型，通过联合利用这些先验来恢复所有底层声源，并扩展处理屏幕外说话人分离。

Result: 在1、2、3个说话人加噪声的混合音频上评估，尽管完全无监督，但在所有条件下的WER指标均一致优于领先的监督基线方法，分离的噪声成分保真度高，适用于下游声学场景检测。

Conclusion: 提出的生成逆采样方法在无监督设置下实现了优于监督方法的语音分离性能，并能有效处理屏幕外说话人分离，分离的高保真噪声可用于声学场景分析。

Abstract: This paper addresses the challenge of audio-visual single-microphone speech separation and enhancement in the presence of real-world environmental noise. Our approach is based on generative inverse sampling, where we model clean speech and ambient noise with dedicated diffusion priors and jointly leverage them to recover all underlying sources. To achieve this, we reformulate a recent inverse sampler to match our setting. We evaluate on mixtures of 1, 2, and 3 speakers with noise and show that, despite being entirely unsupervised, our method consistently outperforms leading supervised baselines in \ac{WER} across all conditions. We further extend our framework to handle off-screen speaker separation. Moreover, the high fidelity of the separated noise component makes it suitable for downstream acoustic scene detection. Demo page: https://ssnapsicml.github.io/ssnapsicml2026/

</details>


### [33] [HuPER: A Human-Inspired Framework for Phonetic Perception](https://arxiv.org/abs/2602.01634)
*Chenxu Guo,Jiachen Lian,Yisi Liu,Baihe Huang,Shriyaa Narayanan,Cheol Jun Cho,Gopala Anumanchipalli*

Main category: eess.AS

TL;DR: HuPER是一个受人类启发的语音感知框架，通过自适应推理结合声学-语音证据和语言知识，在少量数据下实现SOTA性能，并具备强大的零样本跨语言能力。


<details>
  <summary>Details</summary>
Motivation: 现有语音感知系统通常需要大量训练数据，且难以适应不同的声学条件和跨语言场景。受人类语音感知能力的启发，需要开发一个能够像人类一样自适应地结合声学和语言知识进行语音识别的框架。

Method: 提出HuPER框架，将语音感知建模为基于声学-语音证据和语言知识的自适应推理过程。该框架能够实现自适应、多路径的语音感知，适应不同的声学条件。

Result: 仅用100小时训练数据，在5个英语基准测试中达到最先进的语音错误率；在95种未见语言上实现强大的零样本迁移；首次实现不同声学条件下的自适应多路径语音感知。

Conclusion: HuPER展示了受人类启发的语音感知框架的有效性，能够在少量数据下实现高性能，并具备优秀的跨语言适应能力。所有训练数据、模型和代码均已开源。

Abstract: We propose HuPER, a human-inspired framework that models phonetic perception as adaptive inference over acoustic-phonetics evidence and linguistic knowledge. With only 100 hours of training data, HuPER achieves state-of-the-art phonetic error rates on five English benchmarks and strong zero-shot transfer to 95 unseen languages. HuPER is also the first framework to enable adaptive, multi-path phonetic perception under diverse acoustic conditions. All training data, models, and code are open-sourced. Code and demo avaliable at https://github.com/HuPER29/HuPER.

</details>


### [34] [Joint Optimization of ASV and CM tasks: BTUEF Team's Submission for WildSpoof Challenge](https://arxiv.org/abs/2602.01722)
*Oguzhan Kurnaz,Jagabandhu Mishra,Tomi Kinnunen,Cemal Hanilci*

Main category: eess.AS

TL;DR: 提出模組化SASV框架，結合ASV和CM系統，通過非線性融合和可訓練a-DCF損失優化，在WildSpoof數據集上取得最佳性能


<details>
  <summary>Details</summary>
Motivation: 傳統的說話人驗證系統容易受到欺騙攻擊，需要同時處理說話人驗證和反欺騙檢測，以提高對抗攻擊的魯棒性

Method: 採用模組化SASV框架，重用公開可用的ASV和CM系統，通過非線性融合建模它們的交互，使用操作條件相關的可訓練a-DCF損失進行優化

Result: 最佳性能來自ReDimNet-based ASV嵌入與微調SSL-AASIST表示的組合，在進展評估集上a-DCF為0.0515，最終評估集為0.2163

Conclusion: 模組化SASV框架能有效結合現有ASV和CM系統，通過非線性融合和特定損失優化，顯著提升對抗欺騙攻擊的魯棒性

Abstract: Spoofing-aware speaker verification (SASV) jointly addresses automatic speaker verification and spoofing countermeasures to improve robustness against adversarial attacks. In this paper, we investigate our recently proposed modular SASV framework that enables effective reuse of publicly available ASV and CM systems through non-linear fusion, explicitly modeling their interaction, and optimization with an operating-condition-dependent trainable a-DCF loss. The framework is evaluated using ECAPA-TDNN and ReDimNet as ASV embedding extractors and SSL-AASIST as the CM model, with experiments conducted both with and without fine-tuning on the WildSpoof SASV training data. Results show that the best performance is achieved by combining ReDimNet-based ASV embeddings with fine-tuned SSL-AASIST representations, yielding an a-DCF of 0.0515 on the progress evaluation set and 0.2163 on the final evaluation set.

</details>


### [35] [Short-wave admittance correction for a time-domain cochlear transmission line model](https://arxiv.org/abs/2602.01758)
*François Deloche,Morgan Thienpont,Sarah Verhulst*

Main category: eess.AS

TL;DR: 提出一种在时域TL模型中通过自回归滤波和回归技术校正BM导纳的方法，以考虑2D效应，改善小动物耳蜗模型的压缩特性和频率选择性解耦。


<details>
  <summary>Details</summary>
Motivation: 传统时域传输线模型能有效模拟基底膜位移，但仅考虑一维效应，而实际耳蜗存在二维效应（如压力聚焦和横向粘性阻尼），尤其在短波区域更显著。这些效应在频率域更容易表达，需要在时域模型中加以校正。

Method: 采用自回归滤波和回归技术对BM导纳进行数值校正，考虑二维效应。在校正因子中引入反馈回路使其具有电平依赖性，结合解析方法和回归方法表征BM导纳，整合瞬时和非瞬时非线性。

Result: 更新后的沙鼠耳蜗模型实现了频率选择性和增益的部分解耦，提供了额外5dB增益，并将压缩机制的声音电平范围扩展了10dB。

Conclusion: 通过整合解析和回归方法表征BM导纳，结合瞬时和非瞬时非线性，成功在时域TL模型中考虑了二维效应，改善了小动物耳蜗模型的性能，为理解耳蜗非线性机制提供了新方法。

Abstract: Transmission line (TL) models implemented in the time domain can efficiently simulate basilar-membrane (BM) displacement in response to transient or non-stationary sounds. By design, a TL model is well-suited for an one-dimensional (1-D) characterization of the traveling wave, but the real configuration of the cochlea also introduces higher-dimensional effects. Such effects include the focusing of the pressure around the BM and transverse viscous damping, both of which are magnified in the short-wave region. The two effects depend on the wavelength and are more readily expressed in the frequency domain. In this paper, we introduce a numerical correction for the BM admittance to account for 2-D effects in the time domain using autoregressive filtering and regression techniques. The correction was required for the implementation of a TL model tailored to the gerbil cochlear physiology. The model, which includes instantaneous nonlinearities in the form of variable damping, initially presented insufficient compression with increasing sound levels. This limitation was explained by the strong coupling between gain and frequency selectivity assumed in the 1-D nonlinear TL model, whereas cochlear frequency selectivity shows only a moderate dependence on sound level in small mammals. The correction factor was implemented in the gerbil model and made level-dependent using a feedback loop. The updated model achieved some decoupling between frequency selectivity and gain, providing 5 dB of additional gain and extending the range of sound levels of the compressive regime by 10 dB. We discuss the relevance of this work through two key features: the integration of both analytical and regression methods for characterizing BM admittance, and the combination of instantaneous and non-instantaneous nonlinearities.

</details>


### [36] [RIR-Former: Coordinate-Guided Transformer for Continuous Reconstruction of Room Impulse Responses](https://arxiv.org/abs/2602.01861)
*Shaoheng Xu,Chunyi Sun,Jihui,Zhang,Prasanga N. Samarasinghe,Thushara D. Abhayapala*

Main category: eess.AS

TL;DR: RIR-Former：基于Transformer的网格无关单步前馈模型，用于从稀疏测量中重建房间脉冲响应，通过正弦编码整合麦克风位置信息，分段多分支解码器分别处理早期反射和晚期混响。


<details>
  <summary>Details</summary>
Motivation: 房间脉冲响应(RIRs)对许多声学信号处理任务至关重要，但在空间中密集测量通常不切实际。需要一种能够从稀疏测量中准确重建RIR的方法。

Method: 提出RIR-Former模型：1) 基于Transformer架构；2) 引入正弦编码模块整合麦克风位置信息；3) 设计分段多分支解码器分别处理早期反射和晚期混响；4) 支持任意阵列位置的插值。

Result: 在多种模拟声学环境中的实验表明，RIR-Former在归一化均方误差(NMSE)和余弦距离(CD)方面始终优于现有基线方法，在不同缺失率和阵列配置下均表现优异。

Conclusion: 该方法具有实际部署潜力，未来工作可扩展到复杂阵列几何结构、动态声学场景和真实世界环境，以及从随机间距线性阵列到更复杂配置的扩展。

Abstract: Room impulse responses (RIRs) are essential for many acoustic signal processing tasks, yet measuring them densely across space is often impractical. In this work, we propose RIR-Former, a grid-free, one-step feed-forward model for RIR reconstruction. By introducing a sinusoidal encoding module into a transformer backbone, our method effectively incorporates microphone position information, enabling interpolation at arbitrary array locations. Furthermore, a segmented multi-branch decoder is designed to separately handle early reflections and late reverberation, improving reconstruction across the entire RIR. Experiments on diverse simulated acoustic environments demonstrate that RIR-Former consistently outperforms state-of-the-art baselines in terms of normalized mean square error (NMSE) and cosine distance (CD), under varying missing rates and array configurations. These results highlight the potential of our approach for practical deployment and motivate future work on scaling from randomly spaced linear arrays to complex array geometries, dynamic acoustic scenes, and real-world environments.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [37] [LPIPS-AttnWav2Lip: Generic Audio-Driven lip synchronization for Talking Head Generation in the Wild](https://arxiv.org/abs/2602.00189)
*Zhipeng Chen,Xinheng Wang,Lun Xie,Haijie Yuan,Hang Pan*

Main category: cs.SD

TL;DR: 提出LPIPS-AttnWav2Lip方法，通过改进的U-Net架构和语义对齐模块实现音频驱动的说话头生成，在唇部同步准确性和视觉质量上表现优异。


<details>
  <summary>Details</summary>
Motivation: 音频驱动的说话头生成研究中，实现唇部与音频的视听一致性（唇部同步）是主要挑战。现有方法在唇部同步准确性和生成图像质量方面仍有改进空间。

Method: 使用基于残差CBAM的U-Net架构编码和融合音频与视觉模态信息；引入语义对齐模块扩展生成器网络的感受野，匹配视觉特征与音频潜在向量的统计信息；采用LPIPS损失函数模拟人类对图像质量的判断，提高训练稳定性。

Result: 在主观和客观评估中，该方法在唇部同步准确性和视觉质量方面表现出色，代码已开源。

Conclusion: LPIPS-AttnWav2Lip方法有效解决了音频驱动说话头生成中的唇部同步问题，生成高质量图像，为相关研究提供了实用解决方案。

Abstract: Researchers have shown a growing interest in Audio-driven Talking Head Generation. The primary challenge in talking head generation is achieving audio-visual coherence between the lips and the audio, known as lip synchronization. This paper proposes a generic method, LPIPS-AttnWav2Lip, for reconstructing face images of any speaker based on audio. We used the U-Net architecture based on residual CBAM to better encode and fuse audio and visual modal information. Additionally, the semantic alignment module extends the receptive field of the generator network to obtain the spatial and channel information of the visual features efficiently; and match statistical information of visual features with audio latent vector to achieve the adjustment and injection of the audio content information to the visual information. To achieve exact lip synchronization and to generate realistic high-quality images, our approach adopts LPIPS Loss, which simulates human judgment of image quality and reduces instability possibility during the training process. The proposed method achieves outstanding performance in terms of lip synchronization accuracy and visual quality as demonstrated by subjective and objective evaluation results. The code for the paper is available at the following link: https://github.com/FelixChan9527/LPIPS-AttnWav2Lip

</details>


### [38] [Multi-Speaker Conversational Audio Deepfake: Taxonomy, Dataset and Pilot Study](https://arxiv.org/abs/2602.00295)
*Alabi Ahmed,Vandana Janeja,Sanjay Purushotham*

Main category: cs.SD

TL;DR: 该论文针对多说话人对话音频深度伪造检测这一未充分探索的威胁，提出了首个多说话人对话音频深度伪造数据集MsCADD，并评估了三种基线模型的检测性能，为未来研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注单说话人音频深度伪造检测，但现实世界中多说话人对话场景的恶意应用正在成为主要威胁，这一领域尚未得到充分探索。

Method: 提出了多说话人对话音频深度伪造的概念分类法，创建了包含2830个音频片段的MsCADD数据集（使用VITS和SoundStorm-based NotebookLM生成），并评估了LFCC-LCNN、RawNet2和Wav2Vec 2.0三种基线模型。

Result: 基线模型提供了有用的基准，但结果显示在多说话人深度伪造检测方面存在显著差距，特别是在不同对话动态下可靠检测合成语音方面表现不足。

Conclusion: 对话场景的深度伪造检测是高度未探索但威胁巨大的研究领域，MsCADD数据集和基准测试为未来研究提供了基础，数据集已公开以支持可重复性和基准测试。

Abstract: The rapid advances in text-to-speech (TTS) technologies have made audio deepfakes increasingly realistic and accessible, raising significant security and trust concerns. While existing research has largely focused on detecting single-speaker audio deepfakes, real-world malicious applications with multi-speaker conversational settings is also emerging as a major underexplored threat. To address this gap, we propose a conceptual taxonomy of multi-speaker conversational audio deepfakes, distinguishing between partial manipulations (one or multiple speakers altered) and full manipulations (entire conversations synthesized). As a first step, we introduce a new Multi-speaker Conversational Audio Deepfakes Dataset (MsCADD) of 2,830 audio clips containing real and fully synthetic two-speaker conversations, generated using VITS and SoundStorm-based NotebookLM models to simulate natural dialogue with variations in speaker gender, and conversational spontaneity. MsCADD is limited to text-to-speech (TTS) types of deepfake. We benchmark three neural baseline models; LFCC-LCNN, RawNet2, and Wav2Vec 2.0 on this dataset and report performance in terms of F1 score, accuracy, true positive rate (TPR), and true negative rate (TNR). Results show that these baseline models provided a useful benchmark, however, the results also highlight that there is a significant gap in multi-speaker deepfake research in reliably detecting synthetic voices under varied conversational dynamics. Our dataset and benchmarks provide a foundation for future research on deepfake detection in conversational scenarios, which is a highly underexplored area of research but also a major area of threat to trustworthy information in audio settings. The MsCADD dataset is publicly available to support reproducibility and benchmarking by the research community.

</details>


### [39] [RVCBench: Benchmarking the Robustness of Voice Cloning Across Modern Audio Generation Models](https://arxiv.org/abs/2602.00443)
*Xinting Liao,Ruinan Jin,Hanlin Yu,Deval Pandya,Xiaoxiao Li*

Main category: cs.SD

TL;DR: RVCBench是一个全面的语音克隆鲁棒性基准测试，评估了11个代表性VC模型在10个鲁棒性任务上的表现，揭示了当前模型在实际部署中存在的显著鲁棒性差距。


<details>
  <summary>Details</summary>
Motivation: 现代语音克隆技术虽然能够从少量参考音频合成与目标说话人高度相似的语音，但在实际部署中不可避免地会遇到噪声参考音频、不完美的文本提示和多样化的下游处理，这些因素会显著影响鲁棒性。目前对于现实部署场景下的鲁棒性研究仍然不足。

Method: 提出了RVCBench基准测试，全面评估语音克隆在整个生成流程中的鲁棒性，包括输入变化、生成挑战、输出后处理和对抗性扰动，涵盖10个鲁棒性任务、225个说话人、14,370个话语和11个代表性的现代VC模型。

Result: 评估揭示了VC模型存在显著的鲁棒性差距：在常见输入变化和后处理下性能急剧下降；长上下文和跨语言场景进一步暴露了稳定性限制；被动噪声和主动扰动都会影响生成鲁棒性。

Conclusion: 这些发现为当前VC模型在实际应用中的失败提供了统一视角，并引入了一个标准化的开源测试平台，支持开发更鲁棒、可部署的VC模型。项目已在GitHub开源。

Abstract: Modern voice cloning (VC) can synthesize speech that closely matches a target speaker from only seconds of reference audio, enabling applications such as personalized speech interfaces and dubbing. In practical deployments, modern audio generation models inevitably encounter noisy reference audios, imperfect text prompts, and diverse downstream processing, which can significantly hurt robustness. Despite rapid progress in VC driven by autoregressive codec-token language models and diffusion-based models, robustness under realistic deployment shifts remains underexplored. This paper introduces RVCBench, a comprehensive benchmark that evaluates Robustness in VC across the full generation pipeline, including input variation, generation challenges, output post-processing, and adversarial perturbations, covering 10 robustness tasks, 225 speakers, 14,370 utterances, and 11 representative modern VC models. Our evaluation uncovers substantial robustness gaps in VC: performance can deteriorate sharply under common input shifts and post-processing; long-context and cross-lingual scenarios further expose stability limitations; and both passive noise and proactive perturbation influence generation robustness. Collectively, these findings provide a unified picture of how current VC models fail in practice and introduce a standardized, open-source testbed to support the development of more robust and deployable VC models. We open-source our project at https://github.com/Nanboy-Ronan/RVCBench.

</details>


### [40] [Edit Content, Preserve Acoustics: Imperceptible Text-Based Speech Editing via Self-Consistency Rewards](https://arxiv.org/abs/2602.00560)
*Yong Ren,Jiangyan Yi,Jianhua Tao,Zhengqi Wen,Tao Wang*

Main category: cs.SD

TL;DR: 提出基于"编辑内容、保持声学"原则的文本语音编辑框架，通过结构解耦和感知对齐实现无缝编辑，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于声学空间的文本语音编辑方法存在内容-风格纠缠问题，导致生成不稳定和边界伪影，需要更稳定的编辑框架。

Method: 采用"编辑内容、保持声学"原则，包含两个核心组件：1) 结构基础：在语义空间解耦编辑，用Flow Matching解码器重建声学；2) 感知对齐：使用新颖的Self-Consistency Rewards Group Relative Policy Optimization，利用预训练TTS模型作为隐式评判器，配合可懂度和时长约束。

Result: 经验评估表明，该方法显著优于最先进的自回归和非自回归基线，在可懂度、鲁棒性和感知质量方面表现优异。

Conclusion: 提出的框架通过解耦编辑过程并利用感知对齐，实现了稳定、高质量的文本语音编辑，解决了现有方法的内容-风格纠缠问题。

Abstract: Imperceptible text-based speech editing allows users to modify spoken content by altering the transcript. It demands that modified segments fuse seamlessly with the surrounding context. Prevalent methods operating in the acoustic space suffer from inherent content-style entanglement, leading to generation instability and boundary artifacts. In this paper, we propose a novel framework grounded in the principle of "Edit Content, Preserve Acoustics". Our approach relies on two core components: (1) Structural Foundations, which decouples editing into a stable semantic space while delegating acoustic reconstruction to a Flow Matching decoder; and (2) Perceptual Alignment, which employs a novel Self-Consistency Rewards Group Relative Policy Optimization. By leveraging a pre-trained Text-to-Speech model as an implicit critic -- complemented by strict intelligibility and duration constraints -- we effectively align the edited semantic token sequence with the original context. Empirical evaluations demonstrate that our method significantly outperforms state-of-the-art autoregressive and non-autoregressive baselines, achieving superior intelligibility, robustness, and perceptual quality.

</details>


### [41] [Dual-View Predictive Diffusion: Lightweight Speech Enhancement via Spectrogram-Image Synergy](https://arxiv.org/abs/2602.00568)
*Ke Xue,Rongfei Fan,Kai Li,Shanping Yu,Puning Zhao,Jianping An*

Main category: cs.SD

TL;DR: DVPD是一种极轻量级的双视图预测扩散模型，通过利用频谱图的视觉纹理和物理频域双重特性，在保持高性能的同时大幅降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型将语音频谱图视为普通2D图像进行均匀处理，忽略了音频固有的结构稀疏性，导致频谱表示效率低下和计算复杂度过高。

Method: 提出DVPD模型，包含：1）训练阶段使用频率自适应非均匀压缩编码器优化频谱利用，保留关键低频谐波同时剪枝高频冗余；2）轻量级图像频谱感知模块从视觉角度捕获特征；3）推理阶段使用无需训练的无损提升策略利用双视图先验提升生成质量。

Result: DVPD在多个基准测试中达到最先进性能，仅需SOTA轻量模型PGUSE的35%参数和40%推理MACs，在保持高保真语音质量的同时实现极高的架构效率。

Conclusion: DVPD通过利用频谱图的双重特性，成功平衡了高质量语音增强与极低计算复杂度，为轻量级语音增强模型提供了新思路。

Abstract: Diffusion models have recently set new benchmarks in Speech Enhancement (SE). However, most existing score-based models treat speech spectrograms merely as generic 2D images, applying uniform processing that ignores the intrinsic structural sparsity of audio, which results in inefficient spectral representation and prohibitive computational complexity. To bridge this gap, we propose DVPD, an extremely lightweight Dual-View Predictive Diffusion model, which uniquely exploits the dual nature of spectrograms as both visual textures and physical frequency-domain representations across both training and inference stages. Specifically, during training, we optimize spectral utilization via the Frequency-Adaptive Non-uniform Compression (FANC) encoder, which preserves critical low-frequency harmonics while pruning high-frequency redundancies. Simultaneously, we introduce a Lightweight Image-based Spectro-Awareness (LISA) module to capture features from a visual perspective with minimal overhead. During inference, we propose a Training-free Lossless Boost (TLB) strategy that leverages the same dual-view priors to refine generation quality without any additional fine-tuning. Extensive experiments across various benchmarks demonstrate that DVPD achieves state-of-the-art performance while requiring only 35% of the parameters and 40% of the inference MACs compared to SOTA lightweight model, PGUSE. These results highlight DVPD's superior ability to balance high-fidelity speech quality with extreme architectural efficiency. Code and audio samples are available at the anonymous website: {https://anonymous.4open.science/r/dvpd_demo-E630}

</details>


### [42] [The TMU System for the XACLE Challenge: Training Large Audio Language Models with CLAP Pseudo-Labels](https://arxiv.org/abs/2602.00604)
*Ayuto Tsutsumi,Kohei Tanaka,Sayaka Shiota*

Main category: cs.SD

TL;DR: 提出基于大型音频语言模型的x-to-audio对齐系统，通过三阶段训练在XACLE挑战赛中获得第三名


<details>
  <summary>Details</summary>
Motivation: 解决通用音频与文本对的语义对齐预测问题，参与XACLE挑战赛

Method: 基于大型音频语言模型架构，采用三阶段训练流程：自动音频描述预训练、CLAP伪标签预训练、XACLE数据集微调

Result: 在XACLE测试集上获得SRCC 0.632，显著优于基线系统（0.334），在挑战赛团队排名中位列第三

Conclusion: CLAP伪标签预训练是性能提升的主要驱动力，提出的三阶段训练方法有效提升了音频文本对齐性能

Abstract: In this paper, we propose a submission to the x-to-audio alignment (XACLE) challenge. The goal is to predict semantic alignment of a given general audio and text pair. The proposed system is based on a large audio language model (LALM) architecture. We employ a three-stage training pipeline: automated audio captioning pretraining, pretraining with CLAP pseudo-labels, and fine-tuning on the XACLE dataset. Our experiments show that pretraining with CLAP pseudo-labels is the primary performance driver. On the XACLE test set, our system reaches an SRCC of 0.632, significantly outperforming the baseline system (0.334) and securing third place in the challenge team ranking. Code and models can be found at https://github.com/shiotalab-tmu/tmu-xacle2026

</details>


### [43] [Audio-to-Image Bird Species Retrieval without Audio-Image Pairs via Text Distillation](https://arxiv.org/abs/2602.00681)
*Ilyass Moummad,Marius Miron,Lukas Rauch,David Robinson,Alexis Joly,Olivier Pietquin,Emmanuel Chemla,Matthieu Geist*

Main category: cs.SD

TL;DR: 通过文本作为语义中介，将预训练图像-文本模型的文本嵌入空间蒸馏到音频-文本模型中，实现无需音频-图像监督的音频到图像检索


<details>
  <summary>Details</summary>
Motivation: 音频到图像检索为生物声学物种识别提供了可解释的替代方案，但由于配对音频-图像数据稀缺，学习对齐的音频-图像表示具有挑战性

Method: 使用文本作为语义中介，将预训练图像-文本模型（BioCLIP-2）的文本嵌入空间蒸馏到预训练音频-文本模型（BioLingual）中，通过对比目标微调音频编码器

Result: 蒸馏后的音频编码器保持了音频判别能力，同时在焦点录音和声景数据集上显著改善了音频-文本对齐；在SSW60基准测试中，音频到图像检索性能超过基于零样本模型组合或学习文本嵌入映射的基线方法

Conclusion: 通过文本的间接语义传递足以诱导有意义的音频-图像对齐，为数据稀缺的生物声学环境中基于视觉的物种识别提供了实用解决方案

Abstract: Audio-to-image retrieval offers an interpretable alternative to audio-only classification for bioacoustic species recognition, but learning aligned audio-image representations is challenging due to the scarcity of paired audio-image data. We propose a simple and data-efficient approach that enables audio-to-image retrieval without any audio-image supervision. Our proposed method uses text as a semantic intermediary: we distill the text embedding space of a pretrained image-text model (BioCLIP-2), which encodes rich visual and taxonomic structure, into a pretrained audio-text model (BioLingual) by fine-tuning its audio encoder with a contrastive objective. This distillation transfers visually grounded semantics into the audio representation, inducing emergent alignment between audio and image embeddings without using images during training. We evaluate the resulting model on multiple bioacoustic benchmarks. The distilled audio encoder preserves audio discriminative power while substantially improving audio-text alignment on focal recordings and soundscape datasets. Most importantly, on the SSW60 benchmark, the proposed approach achieves strong audio-to-image retrieval performance exceeding baselines based on zero-shot model combinations or learned mappings between text embeddings, despite not training on paired audio-image data. These results demonstrate that indirect semantic transfer through text is sufficient to induce meaningful audio-image alignment, providing a practical solution for visually grounded species recognition in data-scarce bioacoustic settings.

</details>


### [44] [ACE-Step 1.5: Pushing the Boundaries of Open-Source Music Generation](https://arxiv.org/abs/2602.00744)
*Junmin Gong,Yulin Song,Wenxiao Zhao,Sen Wang,Shengyuan Xu,Jing Guo*

Main category: cs.SD

TL;DR: ACE-Step v1.5是一个高效的开源音乐基础模型，能在消费级硬件上实现商业级音乐生成，2秒内生成完整歌曲，支持50+语言，具备风格控制和编辑功能。


<details>
  <summary>Details</summary>
Motivation: 开发一个能在消费级硬件上运行的高质量音乐生成模型，消除对外部奖励模型或人类偏好的依赖，为音乐创作者提供强大的创作工具。

Method: 采用新颖的混合架构：语言模型作为全能规划器，将简单查询转换为完整歌曲蓝图；扩散变换器负责生成；通过内在强化学习实现对齐，无需外部奖励模型。

Result: 在常用评估指标上超越大多数商业音乐模型，A100上2秒内生成完整歌曲，RTX 3090上10秒内，仅需不到4GB显存，支持从几首歌训练LoRA进行个性化。

Conclusion: ACE-Step v1.5为音乐艺术家、制作人和内容创作者提供了强大的创作工具，实现了高质量音乐生成与消费级硬件的完美结合，推动了开源音乐AI的发展。

Abstract: We present ACE-Step v1.5, a highly efficient open-source music foundation model that brings commercial-grade generation to consumer hardware. On commonly used evaluation metrics, ACE-Step v1.5 achieves quality beyond most commercial music models while remaining extremely fast -- under 2 seconds per full song on an A100 and under 10 seconds on an RTX 3090. The model runs locally with less than 4GB of VRAM, and supports lightweight personalization: users can train a LoRA from just a few songs to capture their own style. At its core lies a novel hybrid architecture where the Language Model (LM) functions as an omni-capable planner: it transforms simple user queries into comprehensive song blueprints -- scaling from short loops to 10-minute compositions -- while synthesizing metadata, lyrics, and captions via Chain-of-Thought to guide the Diffusion Transformer (DiT). Uniquely, this alignment is achieved through intrinsic reinforcement learning relying solely on the model's internal mechanisms, thereby eliminating the biases inherent in external reward models or human preferences. Beyond standard synthesis, ACE-Step v1.5 unifies precise stylistic control with versatile editing capabilities -- such as cover generation, repainting, and vocal-to-BGM conversion -- while maintaining strict adherence to prompts across 50+ languages. This paves the way for powerful tools that seamlessly integrate into the creative workflows of music artists, producers, and content creators. The code, the model weights and the demo are available at: https://ace-step.github.io/ace-step-v1.5.github.io/

</details>


### [45] [HierCon: Hierarchical Contrastive Attention for Audio Deepfake Detection](https://arxiv.org/abs/2602.01032)
*Zhili Nicholas Liang,Soyeon Caren Han,Qizhou Wang,Christopher Leckie*

Main category: cs.SD

TL;DR: HierCon：基于分层注意力与对比学习的音频深度伪造检测框架，通过建模跨时间帧、相邻层和层组的依赖关系，显著提升检测性能


<details>
  <summary>Details</summary>
Motivation: 现代TTS和语音转换系统生成的音频深度伪造越来越难以与真实语音区分，对安全和在线信任构成严重风险。现有检测器将自监督模型的各层表示独立处理，忽略了识别合成伪影至关重要的时间和层次依赖关系。

Method: 提出HierCon框架，结合分层注意力机制和基于边界的对比学习，建模跨时间帧、相邻层和层组的依赖关系，同时鼓励领域不变嵌入表示。

Result: 在ASVspoof 2021 DF和In-the-Wild数据集上取得最先进性能（EER分别为1.93%和6.87%），相比独立层加权方法分别提升36.6%和22.5%。

Conclusion: 分层建模增强了跨领域生成技术和录音条件的泛化能力，注意力可视化证实了该方法在捕捉层次依赖关系方面的有效性。

Abstract: Audio deepfakes generated by modern TTS and voice conversion systems are increasingly difficult to distinguish from real speech, raising serious risks for security and online trust. While state-of-the-art self-supervised models provide rich multi-layer representations, existing detectors treat layers independently and overlook temporal and hierarchical dependencies critical for identifying synthetic artefacts. We propose HierCon, a hierarchical layer attention framework combined with margin-based contrastive learning that models dependencies across temporal frames, neighbouring layers, and layer groups, while encouraging domain-invariant embeddings. Evaluated on ASVspoof 2021 DF and In-the-Wild datasets, our method achieves state-of-the-art performance (1.93% and 6.87% EER), improving over independent layer weighting by 36.6% and 22.5% respectively. The results and attention visualisations confirm that hierarchical modelling enhances generalisation to cross-domain generation techniques and recording conditions.

</details>


### [46] [TLDiffGAN: A Latent Diffusion-GAN Framework with Temporal Information Fusion for Anomalous Sound Detection](https://arxiv.org/abs/2602.01060)
*Chengyuan Ma,Peng Jia,Hongyue Guo,Wenming Yang*

Main category: cs.SD

TL;DR: TLDiffGAN：结合潜在扩散模型与GAN的异常声音检测框架，通过双分支结构从原始音频和梅尔频谱图捕捉正常声音特征，引入TMixup增强对局部时间模式的敏感性，在DCASE 2020数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有无监督异常声音检测生成模型难以完全捕捉正常声音的复杂特征分布，而强大的扩散模型在该领域潜力尚未充分探索。

Method: 提出TLDiffGAN双分支框架：1) 将潜在扩散模型集成到GAN生成器中进行对抗训练，提高判别器难度和生成质量；2) 使用预训练音频模型编码器从原始音频波形提取特征进行辅助判别；3) 引入TMixup频谱图增强技术提升对细微局部时间模式的敏感性。

Result: 在DCASE 2020 Challenge Task 2数据集上的大量实验表明，TLDiffGAN具有优越的检测性能，同时在异常时频定位方面表现出强大能力。

Conclusion: TLDiffGAN通过结合扩散模型和GAN的优势，有效捕捉正常声音特征分布，在异常声音检测和定位方面取得显著改进，为无监督异常检测提供了新思路。

Abstract: Existing generative models for unsupervised anomalous sound detection are limited by their inability to fully capture the complex feature distribution of normal sounds, while the potential of powerful diffusion models in this domain remains largely unexplored. To address this challenge, we propose a novel framework, TLDiffGAN, which consists of two complementary branches. One branch incorporates a latent diffusion model into the GAN generator for adversarial training, thereby making the discriminator's task more challenging and improving the quality of generated samples. The other branch leverages pretrained audio model encoders to extract features directly from raw audio waveforms for auxiliary discrimination. This framework effectively captures feature representations of normal sounds from both raw audio and Mel spectrograms. Moreover, we introduce a TMixup spectrogram augmentation technique to enhance sensitivity to subtle and localized temporal patterns that are often overlooked. Extensive experiments on the DCASE 2020 Challenge Task 2 dataset demonstrate the superior detection performance of TLDiffGAN, as well as its strong capability in anomalous time-frequency localization.

</details>


### [47] [Causally Disentangled Contrastive Learning for Multilingual Speaker Embeddings](https://arxiv.org/abs/2602.01363)
*Mariëtte Olijslager,Seyed Sahand Mohammadi Ziabari,Ali Mohammed Mansoor Alsahag*

Main category: cs.SD

TL;DR: 本文研究了自监督说话人嵌入中人口统计信息（性别、年龄、口音）的泄露问题，评估了两种去偏方法的效果和性能权衡。


<details>
  <summary>Details</summary>
Motivation: 自监督说话人嵌入在说话人验证系统中广泛应用，但现有研究表明这些嵌入经常编码敏感的人口统计属性，引发了公平性和隐私担忧。需要研究人口统计信息泄露的程度以及如何在不严重降低说话人验证性能的情况下缓解这种泄露。

Method: 研究基于SimCLR训练的说话人嵌入，采用两种去偏策略：1）通过梯度反转进行对抗训练；2）因果瓶颈架构，明确分离人口统计信息和残差信息。使用线性和非线性探测分类器量化人口统计泄露，使用ROC-AUC和EER评估说话人验证性能。

Result: 性别信息在基线嵌入中强烈且线性编码，而年龄和口音信息较弱且主要非线性表示。对抗去偏减少了性别泄露但对年龄和口音效果有限，且与验证准确性存在明显权衡。因果瓶颈进一步抑制了人口统计信息（特别是在残差表示中），但导致显著的性能下降。

Conclusion: 研究揭示了缓解自监督说话人嵌入中人口统计泄露的基本局限性，阐明了当前去偏方法固有的权衡关系。需要在保护隐私/公平性与保持说话人验证性能之间找到平衡。

Abstract: Self-supervised speaker embeddings are widely used in speaker verification systems, but prior work has shown that they often encode sensitive demographic attributes, raising fairness and privacy concerns. This paper investigates the extent to which demographic information, specifically gender, age, and accent, is present in SimCLR-trained speaker embeddings and whether such leakage can be mitigated without severely degrading speaker verification performance. We study two debiasing strategies: adversarial training through gradient reversal and a causal bottleneck architecture that explicitly separates demographic and residual information. Demographic leakage is quantified using both linear and nonlinear probing classifiers, while speaker verification performance is evaluated using ROC-AUC and EER. Our results show that gender information is strongly and linearly encoded in baseline embeddings, whereas age and accent are weaker and primarily nonlinearly represented. Adversarial debiasing reduces gender leakage but has limited effect on age and accent and introduces a clear trade-off with verification accuracy. The causal bottleneck further suppresses demographic information, particularly in the residual representation, but incurs substantial performance degradation. These findings highlight fundamental limitations in mitigating demographic leakage in self-supervised speaker embeddings and clarify the trade-offs inherent in current debiasing approaches.

</details>


### [48] [Attention-weighted Centered Kernel Alignment for Knowledge Distillation in Large Audio-Language Models Applied to Speech Emotion Recognition](https://arxiv.org/abs/2602.01547)
*Qingran Yang,Botao Zhao,Zuheng Kang,Xue Li,Yayun He,Chuhang Liu,Xulong Zhang,Xiaoyang Qu,Junqing Peng,Jianzong Wang*

Main category: cs.SD

TL;DR: PL-Distill：一种用于大型音频-语言模型压缩的知识蒸馏框架，通过投影器级和逻辑级蒸馏解决跨模态对齐问题，在保持性能的同时大幅减小模型规模。


<details>
  <summary>Details</summary>
Motivation: 大型音频-语言模型在语音情感识别方面表现出色，但模型规模过大限制了在资源受限环境中的部署。现有知识蒸馏方法在压缩跨模态投影模块方面探索不足，且常因特征维度差异而难以对齐。

Method: 提出PL-Distill框架，结合投影器级蒸馏（PDist）和对数级蒸馏（LDist）。PDist引入注意力加权的中心核对齐方法，突出重要时间步并解决维度不匹配问题；LDist通过最小化KL散度来对齐音频和文本模态的输出对数。

Result: 在IEMOCAP、RAVDESS和SAVEE数据集上，PL-Distill将84亿参数的教师模型压缩为11亿参数的学生模型，在所有指标上均优于教师模型、最先进的预训练模型和其他知识蒸馏基线。

Conclusion: PL-Distill通过创新的投影器级和对数级蒸馏方法，有效解决了大型音频-语言模型压缩中的跨模态对齐问题，实现了在保持甚至提升性能的同时大幅减小模型规模，为资源受限环境中的部署提供了可行方案。

Abstract: The emergence of Large Audio-Language Models (LALMs) has advanced Speech Emotion Recognition (SER), but their size limits deployment in resource-constrained environments. While Knowledge Distillation is effective for LALM compression, existing methods remain underexplored in distilling the cross-modal projection module (Projector), and often struggle with alignment due to differences in feature dimensions. We propose PL-Distill, a KD framework that combines Projector-Level Distillation (PDist) to align audio embeddings and Logits-Level Distillation (LDist) to align output logits. PDist introduces Attention-weighted Centered Kernel Alignment, a novel approach we propose to highlight important time steps and address dimension mismatches. Meanwhile, LDist minimizes the Kullback-Leibler divergence between teacher and student logits from audio and text modalities. On IEMOCAP, RAVDESS, and SAVEE, PL-Distill compresses an 8.4B-parameter teacher to a compact 1.1B-parameter student, consistently outperforming the teacher, state-of-the-art pretrained models, and other KD baselines across all metrics.

</details>


### [49] [Membership Inference Attack Against Music Diffusion Models via Generative Manifold Perturbation](https://arxiv.org/abs/2602.01645)
*Yuxuan Liu,Peihong Zhang,Rui Sang,Zhixin Li,Yizhou Tan,Yiqiang Cai,Shengchen Li*

Main category: cs.SD

TL;DR: 提出LSA-Probe方法，通过测量逆向扩散过程中的几何特性来改进音频生成模型的成员推理攻击，显著提升在低误报率下的可分离性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于损失信号的成员推理攻击在音频生成模型中效果不佳，特别是在需要低误报率的法证场景下，因为损失信号与人类感知对齐度弱。

Method: 提出Latent Stability Adversarial Probe (LSA-Probe)白盒方法，测量逆向扩散的几何特性：在中间扩散状态下，达到固定感知退化阈值所需的最小时间归一化扰动预算。

Result: 训练成员位于更稳定的区域，表现出显著更高的退化成本，从而提高了成员推理攻击的可分离性。

Conclusion: LSA-Probe通过利用扩散模型的几何特性，显著改善了音频生成模型的成员推理攻击效果，特别是在低误报率要求下。

Abstract: Membership inference attacks (MIAs) test whether a specific audio clip was used to train a model, making them a key tool for auditing generative music models for copyright compliance. However, loss-based signals (e.g., reconstruction error) are weakly aligned with human perception in practice, yielding poor separability at the low false-positive rates (FPRs) required for forensics. We propose the Latent Stability Adversarial Probe (LSA-Probe), a white-box method that measures a geometric property of the reverse diffusion: the minimal time-normalized perturbation budget needed to cross a fixed perceptual degradation threshold at an intermediate diffusion state. We show that training members, residing in more stable regions, exhibit a significantly higher degradation cost.

</details>


### [50] [Voting-based Pitch Estimation with Temporal and Frequential Alignment and Correlation Aware Selection](https://arxiv.org/abs/2602.01727)
*Junya Koguchi,Tomoki Koriyama*

Main category: cs.SD

TL;DR: 本文对投票法这一基频估计的集成方法进行了理论分析和改进，提出了预投票对齐和贪心算法选择子集，在多种音频数据上取得了更好的性能。


<details>
  <summary>Details</summary>
Motivation: 投票法作为一种基频估计的集成方法，虽然经验上已知其鲁棒性，但缺乏深入的理论研究和系统性分析。本文旨在填补这一空白，为投票法提供理论基础，并解决其实际应用中的局限性。

Method: 1) 为投票法提供理论基础，解释其在基频估计中降低误差方差的原因，并引用孔多塞陪审团定理分析其清浊音检测的准确性；2) 提出预投票对齐程序，校正不同估计器之间的时间和频率偏差；3) 提出基于误差相关性的贪心算法，选择紧凑而有效的估计器子集。

Result: 在包含语音、歌唱和音乐的多样化数据集上的实验表明，采用对齐的改进方法在干净条件下优于单个最先进的估计器，在噪声环境中保持鲁棒的清浊音检测性能。

Conclusion: 本文为投票法提供了理论依据，并通过预投票对齐和贪心选择算法显著提升了其性能，使其在基频估计任务中更加可靠和有效。

Abstract: The voting method, an ensemble approach for fundamental frequency estimation, is empirically known for its robustness but lacks thorough investigation. This paper provides a principled analysis and improvement of this technique. First, we offer a theoretical basis for its effectiveness, explaining the error variance reduction for fundamental frequency estimation and invoking Condorcet's jury theorem for voiced/unvoiced detection accuracy. To address its practical limitations, we propose two key improvements: 1) a pre-voting alignment procedure to correct temporal and frequential biases among estimators, and 2) a greedy algorithm to select a compact yet effective subset of estimators based on error correlation. Experiments on a diverse dataset of speech, singing, and music show that our proposed method with alignment outperforms individual state-of-the-art estimators in clean conditions and maintains robust voiced/unvoiced detection in noisy environments.

</details>


### [51] [ParaGSE: Parallel Generative Speech Enhancement with Group-Vector-Quantization-based Neural Speech Codec](https://arxiv.org/abs/2602.01793)
*Fei Liu,Yang Ai*

Main category: cs.SD

TL;DR: 提出ParaGSE并行生成语音增强框架，利用GVQ神经编解码器实现并行token预测，在多种失真条件下优于现有方法，CPU效率提升约1.5倍。


<details>
  <summary>Details</summary>
Motivation: 现有生成式语音增强方法存在复杂度高、效率低、语音质量不理想的问题，需要更高效优质的解决方案。

Method: 基于GVQ神经编解码器的并行生成语音增强框架：1) 用GVQ编码器将降质语音编码为独立token；2) 通过并行分支预测干净token；3) 用解码器重建干净语音。

Result: ParaGSE在噪声、混响、带宽限制及其混合等多种失真条件下，均优于判别式和生成式基线方法，且在CPU上生成效率比串行方法提升约1.5倍。

Conclusion: ParaGSE框架通过并行token预测实现了高效高质量的语音增强，为生成式语音增强提供了新的有效解决方案。

Abstract: Recently, generative speech enhancement has garnered considerable interest; however, existing approaches are hindered by excessive complexity, limited efficiency, and suboptimal speech quality. To overcome these challenges, this paper proposes a novel parallel generative speech enhancement (ParaGSE) framework that leverages a group vector quantization (GVQ)-based neural speech codec. The GVQ-based codec adopts separate VQs to produce mutually independent tokens, enabling efficient parallel token prediction in ParaGSE. Specifically, ParaGSE leverages the GVQ-based codec to encode degraded speech into distinct tokens, predicts the corresponding clean tokens through parallel branches conditioned on degraded spectral features, and ultimately reconstructs clean speech via the codec decoder. Experimental results demonstrate that ParaGSE consistently produces superior enhanced speech compared to both discriminative and generative baselines, under a wide range of distortions including noise, reverberation, band-limiting, and their mixtures. Furthermore, empowered by parallel computation in token prediction, ParaGSE attains about a 1.5-fold improvement in generation efficiency on CPU compared with serial generative speech enhancement approaches.

</details>


### [52] [Speaking Without Sound: Multi-speaker Silent Speech Voicing with Facial Inputs Only](https://arxiv.org/abs/2602.01879)
*Jaejun Lee,Yoori Oh,Kyogu Lee*

Main category: cs.SD

TL;DR: 提出基于肌电信号和面部图像的无声音输入多说话人语音生成框架


<details>
  <summary>Details</summary>
Motivation: 传统语音生成需要可听输入，本文旨在开发无需任何可听输入的多说话人语音生成方法

Method: 使用无声肌电信号捕获语言内容，面部图像匹配目标说话人声纹，提出音高解耦内容嵌入增强肌电信号语言内容提取

Result: 方法能够无需任何可听输入生成多说话人语音，验证了音高解耦方法的有效性

Conclusion: 成功实现了基于肌电信号和面部图像的无声音输入多说话人语音生成，音高解耦技术显著提升性能

Abstract: In this paper, we introduce a novel framework for generating multi-speaker speech without relying on any audible inputs. Our approach leverages silent electromyography (EMG) signals to capture linguistic content, while facial images are used to match with the vocal identity of the target speaker. Notably, we present a pitch-disentangled content embedding that enhances the extraction of linguistic content from EMG signals. Extensive analysis demonstrates that our method can generate multi-speaker speech without any audible inputs and confirms the effectiveness of the proposed pitch-disentanglement approach.

</details>


### [53] [LipSody: Lip-to-Speech Synthesis with Enhanced Prosody Consistency](https://arxiv.org/abs/2602.01908)
*Jaejun Lee,Yoori Oh,Kyogu Lee*

Main category: cs.SD

TL;DR: LipSody：一种增强韵律一致性的唇语转语音框架，通过引入说话人身份、语言内容和情感上下文三种互补线索来改善韵律生成


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的唇语转语音模型（如LipVoicer）在重建语言内容方面表现出色，但缺乏韵律一致性，这限制了生成语音的自然度和表现力

Method: 提出LipSody框架，采用韵律引导策略，利用三种互补线索：从面部图像提取的说话人身份、从唇部动作推导的语言内容、以及从面部视频推断的情感上下文

Result: 实验结果表明，LipSody在韵律相关指标上显著优于先前方法，包括全局和局部音高偏差、能量一致性和说话人相似度

Conclusion: LipSody通过多线索韵律引导策略有效提升了唇语转语音系统的韵律一致性，为音频不可用或受损场景提供了更自然、表现力更强的语音生成方案

Abstract: Lip-to-speech synthesis aims to generate speech audio directly from silent facial video by reconstructing linguistic content from lip movements, providing valuable applications in situations where audio signals are unavailable or degraded. While recent diffusion-based models such as LipVoicer have demonstrated impressive performance in reconstructing linguistic content, they often lack prosodic consistency. In this work, we propose LipSody, a lip-to-speech framework enhanced for prosody consistency. LipSody introduces a prosody-guiding strategy that leverages three complementary cues: speaker identity extracted from facial images, linguistic content derived from lip movements, and emotional context inferred from face video. Experimental results demonstrate that LipSody substantially improves prosody-related metrics, including global and local pitch deviations, energy consistency, and speaker similarity, compared to prior approaches.

</details>


### [54] [DFKI-Speech System for WildSpoof Challenge: A robust framework for SASV In-the-Wild](https://arxiv.org/abs/2602.02286)
*Arnab Das,Yassine El Kheir,Enes Erdem Erdogan,Feidi Kallel,Tim Polzehl,Sebastian Moeller*

Main category: cs.SD

TL;DR: DFKI团队为WildSpoof挑战赛SASV赛道开发的系统，结合了反欺骗检测和说话人验证，采用自监督语音嵌入提取器与图神经网络的反欺骗前端，以及多尺度特征融合的低复杂度CNN说话人验证网络。


<details>
  <summary>Details</summary>
Motivation: 针对SASV（欺骗感知的自动说话人验证）任务，需要同时处理说话人验证和反欺骗检测，以构建更安全可靠的说话人识别系统，防止语音欺骗攻击。

Method: 1. 反欺骗检测器：使用自监督语音嵌入提取器作为前端，结合图神经网络后端，采用top-3层混合专家机制融合高低层特征；2. 说话人验证：采用低复杂度CNN融合2D和1D多尺度特征，使用SphereFace损失训练，并应用对比性圆损失自适应加权正负样本对；3. 系统增强：使用固定冒名者队列的AS Norm分数归一化和模型集成。

Result: 开发了一个完整的SASV框架，在WildSpoof挑战赛中展示了反欺骗检测和说话人验证的协同工作能力，通过多种技术手段提升了系统的判别性能。

Conclusion: 提出的SASV框架通过创新的反欺骗检测器和说话人验证网络设计，结合先进的训练策略和系统增强技术，为语音欺骗攻击下的说话人验证提供了有效的解决方案。

Abstract: This paper presents the DFKI-Speech system developed for the WildSpoof Challenge under the Spoofing aware Automatic Speaker Verification (SASV) track. We propose a robust SASV framework in which a spoofing detector and a speaker verification (SV) network operate in tandem. The spoofing detector employs a self-supervised speech embedding extractor as the frontend, combined with a state-of-the-art graph neural network backend. In addition, a top-3 layer based mixture-of-experts (MoE) is used to fuse high-level and low-level features for effective spoofed utterance detection. For speaker verification, we adapt a low-complexity convolutional neural network that fuses 2D and 1D features at multiple scales, trained with the SphereFace loss. Additionally, contrastive circle loss is applied to adaptively weight positive and negative pairs within each training batch, enabling the network to better distinguish between hard and easy sample pairs. Finally, fixed imposter cohort based AS Norm score normalization and model ensembling are used to further enhance the discriminative capability of the speaker verification system.

</details>


### [55] [Masked Autoencoders as Universal Speech Enhancer](https://arxiv.org/abs/2602.02413)
*Rajalaxmi Rajagopalan,Ritwik Giri,Zhiqiang Tang,Kyu Han*

Main category: cs.SD

TL;DR: 提出基于掩码自编码器的通用语音增强器，采用自监督预训练，能处理多种失真类型，通过微调适配下游任务，在去噪和去混响任务上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 实际场景中缺乏干净语音数据，需要能与监督方法性能相当且能应用于下游任务的自监督语音增强方法。

Method: 使用掩码自编码器架构，通过增强堆栈向噪声输入添加额外失真，模型在预训练中学习去除添加的失真并重建掩码区域，然后使用少量配对数据微调适配下游任务。

Result: 方法不仅优于基线，在领域内和领域外评估数据集上都达到了最先进的性能。

Conclusion: 提出的自监督掩码自编码器方法能有效处理多种失真，通过预训练和微调框架在语音增强任务上表现优异。

Abstract: Supervised speech enhancement methods have been very successful. However, in practical scenarios, there is a lack of clean speech, and self-supervised learning-based (SSL) speech enhancement methods that offer comparable enhancement performance and can be applied to other speech-related downstream applications are desired. In this work, we develop a masked autoencoder based universal speech enhancer that is agnostic to the type of distortion affecting speech, can handle multiple distortions simultaneously, and is trained in a self-supervised manner. An augmentation stack adds further distortions to the noisy input data. The masked autoencoder model learns to remove the added distortions along with reconstructing the masked regions of the spectrogram during pre-training. The pre-trained embeddings are then used by fine-tuning models trained on a small amount of paired data for specific downstream tasks. We evaluate the pre-trained features for denoising and dereverberation downstream tasks. We explore different augmentations (like single or multi-speaker) in the pre-training augmentation stack and the effect of different noisy input feature representations (like $log1p$ compression) on pre-trained embeddings and downstream fine-tuning enhancement performance. We show that the proposed method not only outperforms the baseline but also achieves state-of-the-art performance for both in-domain and out-of-domain evaluation datasets.

</details>

<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 25]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.SD](#cs.SD) [Total: 9]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Majorization-Minimization Networks for Inverse Problems: An Application to EEG Imaging](https://arxiv.org/abs/2602.03855)
*Le Minh Triet Tran,Sarah Reynaud,Ronan Fablet,Adrien Merlini,François Rousseau,Mai Quyen Pham*

Main category: eess.SP

TL;DR: 提出一种基于双层优化的学习型Majorization-Minimization框架，通过轻量级RNN学习结构化曲率上界，在保持传统MM下降保证的同时提升逆问题的求解性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法（如深度展开和元学习）虽然经验性能强，但缺乏对下降和曲率的显式控制，限制了鲁棒性。需要一种既保持理论保证又能提升性能的优化框架。

Method: 提出学习型MM框架：1）不学习完整优化器，而是学习结构化曲率上界；2）使用轻量级RNN参数化上界，并显式约束满足有效MM条件；3）对余弦相似度损失推导显式曲率边界得到对角上界；4）对无法解析推导的情况，使用基于Hessian-向量积的谱估计自动上界局部曲率。

Result: 在EEG源成像实验中，相比深度展开和元学习基线，该方法在准确性、稳定性和跨数据集泛化能力方面均有提升。

Conclusion: 学习型MM框架成功结合了学习方法的经验优势和传统优化方法的理论保证，为逆问题提供了更稳健高效的解决方案。

Abstract: Inverse problems are often ill-posed and require optimization schemes with strong stability and convergence guarantees. While learning-based approaches such as deep unrolling and meta-learning achieve strong empirical performance, they typically lack explicit control over descent and curvature, limiting robustness. We propose a learned Majorization-Minimization (MM) framework for inverse problems within a bilevel optimization setting. Instead of learning a full optimizer, we learn a structured curvature majorant that governs each MM step while preserving classical MM descent guarantees. The majorant is parameterized by a lightweight recurrent neural network and explicitly constrained to satisfy valid MM conditions. For cosine-similarity losses, we derive explicit curvature bounds yielding diagonal majorants. When analytic bounds are unavailable, we rely on efficient Hessian-vector product-based spectral estimation to automatically upper-bound local curvature without forming the Hessian explicitly. Experiments on EEG source imaging demonstrate improved accuracy, stability, and cross-dataset generalization over deep-unrolled and meta-learning baselines.

</details>


### [2] [The Turing Synthetic Radar Dataset: A dataset for pulse deinterleaving](https://arxiv.org/abs/2602.03856)
*Edward Gunn,Adam Hosford,Robert Jones,Leo Zeitler,Ian Groves,Victoria Nockles*

Main category: eess.SP

TL;DR: 提出了Turing合成雷达数据集，包含6000个脉冲序列，总计近30亿个脉冲，用于雷达脉冲解交织研究和基准测试，并配套了Turing解交织挑战赛


<details>
  <summary>Details</summary>
Motivation: 解决电子战和信号情报中多个未知发射器交织雷达脉冲分离的关键问题，为雷达脉冲解交织研究提供基准数据集并促进新研究方法的发展

Method: 创建了包含6000个脉冲序列的综合合成雷达数据集，涵盖两种接收器配置，模拟了最多110个发射器的真实场景，具有显著的参数空间重叠

Result: 建立了包含近30亿个脉冲的全面数据集，支持最多110个发射器的复杂场景，并推出了配套的Turing解交织挑战赛以促进数据集采用和标准化评估

Conclusion: Turing合成雷达数据集是首批公开可用的综合模拟脉冲序列数据集之一，旨在促进电子战社区中复杂模型的发展，为雷达脉冲解交织研究提供重要资源

Abstract: We present the Turing Synthetic Radar Dataset, a comprehensive dataset to serve both as a benchmark for radar pulse deinterleaving research and as an enabler of new research methods. The dataset addresses the critical problem of separating interleaved radar pulses from multiple unknown emitters for electronic warfare applications and signal intelligence. Our dataset contains a total of 6000 pulse trains over two receiver configurations, totalling to almost 3 billion pulses, featuring realistic scenarios with up to 110 emitters and significant parameter space overlap. To encourage dataset adoption and establish standardised evaluation procedures, we have launched an accompanying Turing Deinterleaving Challenge, for which models need to associate pulses in interleaved pulse trains to the correct emitter by clustering and maximising metrics such as the V-measure. The Turing Synthetic Radar Dataset is one of the first publicly available, comprehensively simulated pulse train datasets aimed to facilitate sophisticated model development in the electronic warfare community

</details>


### [3] [PENGUIN: General Vital Sign Reconstruction from PPG with Flow Matching State Space Model](https://arxiv.org/abs/2602.03858)
*Shuntaro Suzuki,Shuitsu Koyama,Shinnosuke Hirano,Shunya Nagashima*

Main category: eess.SP

TL;DR: PENGUIN是一个基于生成流匹配的框架，通过扩展深度状态空间模型，从PPG信号中重建多种生命体征的连续波形，在多个任务和数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: PPG信号易受运动伪影和噪声影响，现有方法要么局限于单一任务或环境，要么依赖多秒间隔预测而丢弃形态特征，缺乏跨不同PPG解码场景的通用性。

Method: 提出PENGUIN框架，结合生成流匹配和深度状态空间模型，实现对PPG信号的细粒度条件化，重建多种生命体征的连续波形。

Result: 在6个真实世界PPG数据集和3个生命体征重建任务（心电图重建、呼吸监测、动脉血压监测）上，PENGUIN始终优于任务专用和通用基线方法。

Conclusion: PENGUIN作为一个通用框架，能够从PPG信号中稳健地重建生命体征，解决了现有方法的局限性。

Abstract: Photoplethysmography (PPG) plays a crucial role in continuous cardiovascular health monitoring as a non-invasive and cost-effective modality. However, PPG signals are susceptible to motion artifacts and noise, making accurate estimation of vital signs such as arterial blood pressure (ABP) challenging. Existing estimation methods are often restricted to a single-task or environment, limiting their generalizability across diverse PPG decoding scenarios. Moreover, recent general-purpose approaches typically rely on predictions over multi-second intervals, discarding the morphological characteristics of vital signs. To address these challenges, we propose PENGUIN, a generative flow-matching framework that extends deep state space models, enabling fine-grained conditioning on PPG for reconstructing multiple vital signs as continuous waveforms. We evaluate PENGUIN using six real-world PPG datasets across three distinct vital sign reconstruction tasks (electrocardiogram reconstruction, respiratory monitoring, and ABP monitoring). Our method consistently outperformed both task-specific and general-purpose baselines, demonstrating PENGUIN as a general framework for robust vital sign reconstruction from PPG.

</details>


### [4] [Polynomial Closed-Form Model for Evaluating Nonlinear Interference in Any Island](https://arxiv.org/abs/2602.03860)
*Yanchao Jiang,Pierluigi Poggiolini*

Main category: eess.SP

TL;DR: 提出多项式闭式GN模型，通过将每个信道在光纤跨段内的空间功率分布表示为多项式，推导出所有自干扰、交叉干扰和多信道干扰的通用闭式表达式。


<details>
  <summary>Details</summary>
Motivation: 传统GN模型计算复杂，需要数值积分，难以实时应用。需要一种更高效、解析形式的模型来准确评估光纤通信系统中的非线性干扰。

Method: 将每个信道沿光纤跨段的空间功率分布建模为多项式函数，基于此推导非线性干扰的通用闭式表达式，包括自干扰、交叉干扰和多信道干扰的完整数学推导。

Result: 获得了所有类型非线性干扰的通用闭式表达式，避免了数值积分，显著降低了计算复杂度，为光纤通信系统性能评估提供了高效解析工具。

Conclusion: 多项式闭式GN模型为光纤非线性干扰分析提供了精确且计算高效的解析框架，适用于实时系统设计和性能优化。

Abstract: Polynomial closed-form GN model is proposed by expressing the spatial power profile of each channel along a span as a polynomial. In this paper, we present the generic closed-form expression for all contributions of self-, cross-, and multi-channel interference. The full derivation is provided.

</details>


### [5] [A Multi-Modal Foundational Model for Wireless Communication and Sensing](https://arxiv.org/abs/2602.04016)
*Vahid Yazdnian,Yasaman Ghasempour*

Main category: eess.SP

TL;DR: 提出一种任务无关、多模态的无线物理层基础模型，通过物理引导的自监督预训练学习可迁移的物理感知表示，实现跨任务和环境的鲁棒泛化。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的无线技术泛化能力差：大多数模型是任务特定、环境依赖且局限于狭窄感知模态，在新场景部署时需要昂贵的重新训练。

Method: 采用物理引导的自监督预训练策略，引入专用物理令牌来捕获电磁传播支配的跨模态物理对应关系，学习可迁移的物理感知表示。

Result: 该模型在多种下游任务（大规模多天线优化、无线信道估计、设备定位）上表现出优越的泛化能力、对部署变化的鲁棒性，并减少数据需求。

Conclusion: 提出的任务无关多模态基础模型能够学习跨异构模态的可迁移物理表示，为下一代无线通信和感知系统提供了强大的泛化能力。

Abstract: Artificial intelligence is a key enabler for next-generation wireless communication and sensing. Yet, today's learning-based wireless techniques do not generalize well: most models are task-specific, environment-dependent, and limited to narrow sensing modalities, requiring costly retraining when deployed in new scenarios. This work introduces a task-agnostic, multi-modal foundational model for physical-layer wireless systems that learns transferable, physics-aware representations across heterogeneous modalities, enabling robust generalization across tasks and environments. Our framework employs a physics-guided self-supervised pretraining strategy incorporating a dedicated physical token to capture cross-modal physical correspondences governed by electromagnetic propagation. The learned representations enable efficient adaptation to diverse downstream tasks, including massive multi-antenna optimization, wireless channel estimation, and device localization, using limited labeled data. Our extensive evaluations demonstrate superior generalization, robustness to deployment shifts, and reduced data requirements compared to task-specific baselines.

</details>


### [6] [Cross-Frequency Bispectral EEG Analysis of Reach-to-Grasp Planning and Execution](https://arxiv.org/abs/2602.04018)
*Sima Ghafoori,Anna Cetera,Ali Rabiee,MH Farhadi,Rahul Singh,Mariusz Furmanek,Yalda Shahriari,Reza Abiri*

Main category: eess.SP

TL;DR: 该研究通过高阶交叉频率双谱分析发现，运动执行阶段比计划阶段具有更强的非线性脑电耦合特征，而抓握类型表征在计划阶段已形成并持续到执行阶段。


<details>
  <summary>Details</summary>
Motivation: 传统脑电运动解码主要依赖线性二阶频谱特征，但神经抓握控制源于多个脑节律的非线性相互作用。本研究旨在探索高阶交叉频率动态是否能区分自然抓握行为中的运动计划与执行阶段。

Method: 采用线索提示范式记录执行精确抓握和力量抓握时的脑电信号，使用交叉频率双谱分析计算标准频带对的双相干矩阵，提取幅度和相位特征，通过分类、基于排列的特征选择和受试者内统计测试进行分析。

Result: 运动执行阶段表现出比计划阶段显著更强、更具区分性的非线性耦合，主要由β和γ频带驱动。精确抓握与力量抓握的解码在计划和执行阶段表现相当，表明抓握类型表征在计划阶段已形成并持续到执行。信息性双谱特征反映了前额叶、中央区和枕叶区域的协调活动。

Conclusion: 非线性交叉频率耦合为运动计划和执行提供了可解释且稳健的神经标记，将双谱脑电分析扩展到生态有效的抓握行为，支持其在脑机接口和神经假肢控制中的应用价值。

Abstract: Neural control of grasping arises from nonlinear interactions across multiple brain rhythms, yet EEG-based motor decoding has largely relied on linear, second-order spectral features. Here, we examine whether higher-order cross-frequency dynamics distinguish motor planning from execution during natural reach-to-grasp behavior. EEG was recorded in a cue-based paradigm during executed precision and power grips, enabling stage-resolved analysis of preparatory and execution-related neural activity.
  Cross-frequency bispectral analysis was used to compute bicoherence matrices across canonical frequency band pairs, from which magnitude- and phase-based features were extracted. Classification, permutation-based feature selection, and within-subject statistical testing showed that execution is characterized by substantially stronger and more discriminative nonlinear coupling than planning, with dominant contributions from beta- and gamma-driven interactions. In contrast, decoding of precision versus power grips achieved comparable performance during planning and execution, indicating that grasp-type representations emerge during planning and persist into execution.
  Spatial and spectral analyses further revealed that informative bispectral features reflect coordinated activity across prefrontal, central, and occipital regions. Despite substantial feature redundancy, effective dimensionality reduction preserved decoding performance. Together, these findings demonstrate that nonlinear cross-frequency coupling provides an interpretable and robust marker of motor planning and execution, extending bispectral EEG analysis to ecologically valid grasping and supporting its relevance for brain-computer interfaces and neuroprosthetic control.

</details>


### [7] [Ultra-Fast Device-Free Visible Light Sensing and Localization via Reflection-Based ΔRSS and Deep Learning](https://arxiv.org/abs/2602.04062)
*Helena Serpi,Christina,Politi*

Main category: eess.SP

TL;DR: 提出了一种超快速、无设备的可见光传感与定位系统，利用天花板安装的光电探测器捕获单LED VLC信道响应的时空变化，通过光学信号反射建模非侵入式推断人员存在与位置。


<details>
  <summary>Details</summary>
Motivation: 传统人员感知与定位系统通常需要用户携带设备或安装复杂传感器，存在侵入性和部署成本问题。需要一种无需用户设备、非侵入式、高适应性且能快速响应的解决方案。

Method: 使用天花板安装的光电探测器捕获单LED可见光通信信道的时空变化，通过光学信号反射建模分析信号特征。系统采用多架构深度神经网络集成库，包含多种机器学习模型，可根据不同场景选择合适模型。

Result: 系统能够准确、非侵入式地推断人员存在和位置，具有高度适应性，可服务于不同的现实世界传感和定位场景，且响应速度极快。

Conclusion: 该系统为人员感知与定位提供了一种创新的无设备、非侵入式解决方案，通过可见光传感和先进的机器学习模型实现了高精度和快速响应，具有广泛的实际应用前景。

Abstract: We propose an Ultra-Fast, Device-Free Visible Light Sensing and Positioning system that captures spatiotemporal variations in single-LED VLC channel responses, using ceiling-mounted photodetectors, to accurately and non-intrusively infer human presence and position through optical signal reflection modeling. The system is highly adaptive and ready to serve different real-world sensing and positioning scenarios using one or more ML based models from the library of multi-architecture deep neural network ensembles we have developed.

</details>


### [8] [Structure-Informed Estimation for Pilot-Limited MIMO Channels via Tensor Decomposition](https://arxiv.org/abs/2602.04083)
*Alexandre Barbosa de Lima*

Main category: eess.SP

TL;DR: 提出混合张量-神经网络架构，通过低秩张量补全解决宽带MIMO系统导频受限的信道估计问题，相比传统方法显著降低NMSE


<details>
  <summary>Details</summary>
Motivation: 宽带MIMO系统在5G/6G高维场景下面临导频开销限制，传统信道估计方法性能受限，需要新方法在稀疏观测下实现高效信道估计

Method: 混合张量-神经网络架构：1) 基于CP和Tucker分解的低秩张量补全作为基础；2) 轻量级3D U-Net学习低秩结构之外的残差分量；3) 将信道估计建模为稀疏观测下的张量补全问题

Result: 1) 样本复杂度与内在模型维度L(Nr+Nt+Nf)成正比而非环境张量大小NrNtNf；2) 合成信道：5-10%导频密度下NMSE比LS和OMP提升10-20dB；3) DeepMIMO射线追踪信道：比纯张量方法额外降低24-44% NMSE

Conclusion: 混合张量-神经网络架构能有效解决导频受限的宽带MIMO信道估计问题，结合代数模型和实际传播效应，在稀疏观测下实现高性能信道恢复

Abstract: Channel estimation in wideband multiple-input multiple-output (MIMO) systems faces fundamental pilot overhead limitations in high-dimensional beyond-5G and sixth-generation (6G) scenarios. This paper presents a hybrid tensor-neural architecture that formulates pilot-limited channel estimation as low-rank tensor completion from sparse observations -- a fundamentally different setting from prior tensor methods that assume fully observed received signal tensors. A canonical polyadic (CP) baseline implemented via a projection-based scheme (Tucker completion under partial observations) and Tucker decompositions are compared under varying signal-to-noise ratio (SNR) and scattering conditions: CP performs well for specular channels matching the multipath model, while Tucker provides greater robustness under model mismatch. A lightweight three-dimensional (3D) U-Net learns residual components beyond the low-rank structure, bridging algebraic models and realistic propagation effects. Empirical recovery threshold analysis shows that sample complexity scales approximately with intrinsic model dimensionality $L(N_r + N_t + N_f)$ rather than ambient tensor size $N_r N_t N_f$, where $L$ denotes the number of dominant propagation paths. Experiments on synthetic channels demonstrate 10-20\,dB normalized mean-square error (NMSE) improvement over least-squares (LS) and orthogonal matching pursuit (OMP) baselines at 5-10\% pilot density, while evaluations on DeepMIMO ray-tracing channels show 24-44\% additional NMSE reduction over pure tensor-based methods.

</details>


### [9] [Uncertainty Principle for Vertex-Time Graph Signal Processing](https://arxiv.org/abs/2602.04084)
*Yanan Zhao,Xingchao Jian,Feng Ji,Wee Peng Tay,Antonio Ortega*

Main category: eess.SP

TL;DR: 提出图信号在顶点-时域的不确定性原理，统一经典时频和图不确定性原理，定义顶点-时域和谱-频域扩展，识别最大浓度信号作为新字典原子，并基于此提出图拓扑推断方法。


<details>
  <summary>Details</summary>
Motivation: 传统不确定性原理分别处理时频域和图域，缺乏统一框架。传感器网络和社交网络中常遇到间歇性数据，需要更有效的信号表示和重构方法，同时图拓扑推断也是重要问题。

Method: 定义顶点-时域和谱-频域的信号扩展度量，推导统一的不确定性原理。识别在空间和时间域同时达到最大浓度的信号类，构建顶点-时域字典。基于不确定性原理提出新的图拓扑推断方法。

Result: 在合成和真实数据集上的数值实验验证了方法的有效性：提高了信号重构精度，增强了对噪声的鲁棒性，相比现有方法获得了更好的图学习性能。

Conclusion: 提出的顶点-时域不确定性原理成功统一了经典时频和图不确定性原理，为图信号处理提供了新框架，在信号重构和图拓扑推断方面表现出优越性能。

Abstract: We present an uncertainty principle for graph signals in the vertex-time domain, unifying the classical time-frequency and graph uncertainty principles within a single framework. By defining vertex-time and spectral-frequency spreads, we quantify signal localization across these domains. Our framework identifies a class of signals that achieve maximum concentration in both the spatial and temporal domains. These signals serve as fundamental atoms for a new vertex-time dictionary, enhancing signal reconstruction under practical constraints, such as intermittent data commonly encountered in sensor and social networks. Furthermore, we introduce a novel graph topology inference method leveraging the uncertainty principle. Numerical experiments on synthetic and real datasets validate the effectiveness of our approach, demonstrating improved reconstruction accuracy, greater robustness to noise, and enhanced graph learning performance compared to existing methods.

</details>


### [10] [Semantic Pilot Design for Data-Aided Channel Estimation Using a Large Language Model](https://arxiv.org/abs/2602.04126)
*Sojeong Park,Hyun Jong Yang*

Main category: eess.SP

TL;DR: 提出一种基于大语言模型（LLM）的语义导频设计，用于文本数据传输中的信道估计，通过LLM纠正解码文本中的错误来识别可靠符号作为额外导频。


<details>
  <summary>Details</summary>
Motivation: 在包含文本的数据传输中，信道损伤通常表现为解码文本中的拼写错误。传统导频估计方法可能不够高效，需要利用语义信息来提高信道估计的可靠性。

Method: 使用LLM纠正初始解码文本中的错误，将纠正前后的文本进行比较来识别可靠解码符号，选择这些可靠符号作为"语义导频"用于数据辅助的信道估计。

Result: 仿真结果显示，该方案优于传统的仅使用导频的估计方法，在估计信道的归一化均方误差、相位误差以及比特误码率方面都有显著降低。

Conclusion: 这是首次利用语义信息进行可靠符号选择的工作，证明了语义导频设计能有效提高数据辅助信道估计的性能，为通信系统设计提供了新思路。

Abstract: This paper proposes a semantic pilot design for data-aided channel estimation in text-inclusive data transmission, using a large language model (LLM). In this scenario, channel impairments often appear as typographical errors in the decoded text, which can be corrected using an LLM. The proposed method compares the initially decoded text with the LLM-corrected version to identify reliable decoded symbols. A set of selected symbols, referred to as a semantic pilot, is used as an additional pilot for data-aided channel estimation. To the best of our knowledge, this work is the first to leverage semantic information for reliable symbol selection. Simulation results demonstrate that the proposed scheme outperforms conventional pilot-only estimation, achieving lower normalized mean squared error and phase error of the estimated channel, as well as reduced bit error rate.

</details>


### [11] [Spatial Angular Pseudo-Derivative Searching: A Single Snapshot Super-resolution Sparse DOA Scheme with Potential for Practical Application](https://arxiv.org/abs/2602.04169)
*Longxin Bai,Jingchao Zhang,Liyan Qiao*

Main category: eess.SP

TL;DR: 提出一种基于空间角度伪导数约束的稀疏DOA估计算法SAPD，针对汽车雷达的计算资源有限、阵列孔径受限、单快拍等限制，实现实时高效的高精度超分辨DOA估计。


<details>
  <summary>Details</summary>
Motivation: 汽车雷达系统需要准确、高分辨率、实时的DOA估计，但现有稀疏信号恢复方法虽然能提供超分辨和高精度估计，其计算复杂度过高，难以在实际汽车雷达系统中部署。

Method: 提出空间角度伪导数概念，将其作为约束条件融入标准的L0范数最小化问题，构建更符合DOA问题物理特性的目标函数。相应的求解器SAPD搜索算法将高维优化任务转化为高效的网格搜索方案，避免高阶矩阵求逆和计算密集的迭代过程。

Result: SAPD算法在计算复杂度和收敛性方面表现优异，数值仿真表明该方法在实时效率、高精度和超分辨率之间实现了优越的平衡，非常适合下一代汽车雷达应用。

Conclusion: SAPD方法通过引入空间角度伪导数约束，有效解决了稀疏DOA估计在汽车雷达系统中的计算复杂度问题，为实际部署提供了可行的解决方案。

Abstract: Accurate, high-resolution, and real-time DOA estimation is a cornerstone of environmental perception in automotive radar systems. While sparse signal recovery techniques offer super-resolution and high-precision estimation, their prohibitive computational complexity remains a primary bottleneck for practical deployment. This paper proposes a sparse DOA estimation scheme specifically tailored for the stringent requirements of automotive radar such as limited computational resources, restricted array apertures, and a single snapshot. By introducing the concept of the spatial angular pseudo-derivative and incorporating this property as a constraint into a standard L0-norm minimization problem, we formulate an objective function that more faithfully characterizes the physical properties of the DOA problem. The associated solver, designated as the SAPD search algorithm, naturally transforms the high-dimensional optimization task into an efficient grid-search scheme. The SAPD algorithm circumvents high-order matrix inversions and computationally intensive iterations. We provide an analysis of the computational complexity and convergence properties of the proposed algorithm. Extensive numerical simulations demonstrate that the SAPD method achieves a superior balance of real-time efficiency, high precision, and super-resolution, making it highly suitable for next-generation automotive radar applications.

</details>


### [12] [GPINND: A deep-learning-based state of health estimation for Lithium-ion battery](https://arxiv.org/abs/2602.04187)
*Yuzhu Lei,Guanding Yu*

Main category: eess.SP

TL;DR: 提出一种结合深度学习与电化学机制的电池健康状态估计方法，通过构建混合驱动代理模型、自监督参数识别网络和残差修正网络，实现非迭代式老化参数识别和高精度SOH估计。


<details>
  <summary>Details</summary>
Motivation: 电化学模型在电池退化诊断中具有优越的可解释性和可靠性，但迭代参数识别的高计算成本严重阻碍了电化学信息健康状态估计在实际实时系统中的实施。

Method: 1. 构建混合驱动代理模型，融合高保真仿真数据和物理约束学习内部电化学动力学；2. 开发自监督框架训练参数识别网络，最小化电压重构误差；3. 利用识别参数作为物理化学健康指标，建立高精度SOH估计网络，采用数据驱动残差修正补偿识别偏差；4. 采用顺序训练策略解决收敛问题。

Result: 实验结果表明，该方法平均电压重构均方根误差为0.0198V，SOH估计均方根误差为0.0014，实现了高精度估计。

Conclusion: 该方法成功解决了电化学模型实时应用的挑战，通过深度学习与物理机制的结合，实现了高效、准确的电池健康状态估计，为实时电池管理系统提供了可行方案。

Abstract: Electrochemical models offer superior interpretability and reliability for battery degradation diagnosis. However, the high computational cost of iterative parameter identification severely hinders the practical implementation of electrochemically informed state of health (SOH) estimation in real-time systems. To address this challenge, this paper proposes an SOH estimation method that integrates deep learning with electrochemical mechanisms and adopts a sequential training strategy. First, we construct a hybrid-driven surrogate model to learn internal electrochemical dynamics by fusing high-fidelity simulation data with physical constraints. This model subsequently serves as an accurate and differentiable physical kernel for voltage reconstruction. Then, we develop a self-supervised framework to train a parameter identification network by minimizing the voltage reconstruction error. The resulting model enables the non-iterative identification of aging parameters from external measurements. Finally, utilizing the identified parameters as physicochemical health indicators, we establish a high-precision SOH estimation network that leverages data-driven residual correction to compensate for identification deviations. Crucially, a sequential training strategy is applied across these modules to effectively mitigate convergence issues and improve the accuracy of each module. Experimental results demonstrate that the proposed method achieves an average voltage reconstruction root mean square error (RMSE) of 0.0198 V and an SOH estimation RMSE of 0.0014.

</details>


### [13] [Maneuverable-Jamming-Aided Secure Communication and Sensing in A2G-ISAC Systems](https://arxiv.org/abs/2602.04209)
*Libiao Lou,Yuan Liu,Fotis Foukalas,Hongjiang Lei,Gaofeng Pan,Theodoros A. Tsiftsis,Hongwu Liu*

Main category: eess.SP

TL;DR: 提出一种用于空对地集成感知与通信系统的可机动干扰辅助安全通信与感知方案，通过双无人机协同工作在混合单基地-双基地雷达配置中，优化轨迹和波束成形以最大化平均保密率。


<details>
  <summary>Details</summary>
Motivation: 在空对地集成感知与通信系统中，安全通信和感知在资源分配上存在根本冲突，难以同时实现最优性能。同时，不完美的连续干扰消除产生的残余干扰会降低系统性能，需要解决这些挑战。

Method: 采用两阶段设计：安全通信阶段使用块坐标下降算法结合信任域逐次凸逼近和半定松弛优化双无人机轨迹和波束成形；安全通信与感知阶段通过加权距离最小化问题确定合适的双无人机感知位置，然后联合优化源波束成形和干扰波束成形。

Result: 仿真结果表明，所提方案在基准方法中实现了最高的平均保密率，同时保持了鲁棒的感知性能，并证实了连续干扰消除残余干扰对安全通信和感知的影响。

Conclusion: 提出的可机动干扰辅助安全通信与感知方案通过两阶段设计和联合优化，有效解决了空对地集成感知与通信系统中安全通信与感知的资源冲突问题，在保证感知性能的同时显著提升了通信安全性。

Abstract: In this paper, we propose a maneuverablejamming-aided secure communication and sensing (SCS) scheme for an air-to-ground integrated sensing and communication (A2G-ISAC) system, where a dual-functional source UAV and a maneuverable jamming UAV operate collaboratively in a hybrid monostatic-bistatic radar configuration. The maneuverable jamming UAV emits artificial noise to assist the source UAV in detecting multiple ground targets while interfering with an eavesdropper. The effects of residual interference caused by imperfect successive interference cancellation on the received signal-to-interference-plus-noise ratio are considered, which degrades the system performance. To maximize the average secrecy rate (ASR) under transmit power budget, UAV maneuvering constraints, and sensing requirements, the dual-UAV trajectory and beamforming are jointly optimized. Given that secure communication and sensing fundamentally conflict in terms of resource allocation, making it difficult to achieve optimal performance for both simultaneously, we adopt a two-phase design to address this challenge. By dividing the mission into the secure communication (SC) phase and the SCS phase, the A2G-ISAC system can focus on optimizing distinct objectives separately. In the SC phase, a block coordinate descent algorithm employing the trust-region successive convex approximation and semidefinite relaxation iteratively optimizes dual-UAV trajectory and beamforming. For the SCS phase, a weighted distance minimization problem determines the suitable dual-UAV sensing positions by a greedy algorithm, followed by the joint optimization of source beamforming and jamming beamforming. Simulation results demonstrate that the proposed scheme achieves the highest ASR among benchmarks while maintaining robust sensing performance, and confirm the impact of the SIC residual interference on both secure communication and sensing.

</details>


### [14] [Aortic Valve Disease Detection from PPG via Physiology-Informed Self-Supervised Learning](https://arxiv.org/abs/2602.04266)
*Jiaze Wang,Qinghao Zhao,Zizheng Chen,Zhejun Sun,Deyun Zhang,Yuxi Zhou,Shenda Hong*

Main category: eess.SP

TL;DR: 提出生理学引导的自监督学习框架，利用大规模无标签PPG数据解决主动脉瓣膜疾病筛查中的标签稀缺问题，显著提升筛查性能。


<details>
  <summary>Details</summary>
Motivation: 传统超声心动图诊断主动脉瓣膜疾病成本高且需要专业知识，难以用于大规模早期筛查。PPG作为可穿戴设备广泛使用的技术具有筛查潜力，但金标准标签数据极度稀缺限制了数据驱动方法的有效性。

Method: 提出生理学引导的自监督学习框架：1) 将临床知识形式化为PPG形态表型；2) 构建脉搏模式识别代理任务进行自监督预训练；3) 使用双分支门控融合架构在小规模标签数据上进行高效微调。

Result: 在超过17万个无标签PPG样本上训练，主动脉狭窄和主动脉反流筛查的AUC分别达到0.765和0.776，显著优于基于有限标签数据的监督基线。多变量分析验证模型输出作为独立数字生物标志物具有持续预后价值。

Conclusion: PG-SSL为医学人工智能中的标签稀缺问题提供了有效的领域知识驱动解决方案，展示了实现低成本、大规模主动脉瓣膜疾病早期筛查的强大潜力。

Abstract: Traditional diagnosis of aortic valve disease relies on echocardiography, but its cost and required expertise limit its use in large-scale early screening. Photoplethysmography (PPG) has emerged as a promising screening modality due to its widespread availability in wearable devices and its ability to reflect underlying hemodynamic dynamics. However, the extreme scarcity of gold-standard labeled PPG data severely constrains the effectiveness of data-driven approaches. To address this challenge, we propose and validate a new paradigm, Physiology-Guided Self-Supervised Learning (PG-SSL), aimed at unlocking the value of large-scale unlabeled PPG data for efficient screening of Aortic Stenosis (AS) and Aortic Regurgitation (AR). Using over 170,000 unlabeled PPG samples from the UK Biobank, we formalize clinical knowledge into a set of PPG morphological phenotypes and construct a pulse pattern recognition proxy task for self-supervised pre-training. A dual-branch, gated-fusion architecture is then employed for efficient fine-tuning on a small labeled subset. The proposed PG-SSL framework achieves AUCs of 0.765 and 0.776 for AS and AR screening, respectively, significantly outperforming supervised baselines trained on limited labeled data. Multivariable analysis further validates the model output as an independent digital biomarker with sustained prognostic value after adjustment for standard clinical risk factors. This study demonstrates that PG-SSL provides an effective, domain knowledge-driven solution to label scarcity in medical artificial intelligence and shows strong potential for enabling low-cost, large-scale early screening of aortic valve disease.

</details>


### [15] [Joint Fractional Delay and Doppler Frequency Estimator Under Spectrum Wrapping Phenomenon for LEO-ICAN AFDM Signals](https://arxiv.org/abs/2602.04316)
*Zhenyu Chen,Ke Xiao,Xiaomei Tang,Jing Lei,Muzi Yuan,Guangfu Sun*

Main category: eess.SP

TL;DR: 本文针对LEO卫星ICAN信号中的AFDM波形，解决了分数延迟和多普勒频率估计问题，提出了基于PSPR检测和ELG的联合估计算法，在复杂度和精度上优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 随着低地球轨道卫星的快速发展，集成通信导航信号设计在车联网领域受到关注。AFDM作为新一代波形具有抗多普勒效应强、调制结构简单、导频开销低等优点，适合高动态LEO卫星场景。然而，LEO-ICAN AFDM信号面临分数延迟和多普勒频率估计的挑战，现有研究忽略其固有的频谱折叠现象可能导致模型构建偏差。

Method: 本文深入推导了AFDM在分数情况下的输入输出关系，揭示了其等效信道的包络特性，提出了基于峰值旁瓣功率比检测和早晚门限的联合估计算法来估计分数多普勒频率和延迟。

Result: 仿真结果表明，与传统方法相比，该算法具有低复杂度、低保护间隔开销和高精度的优势。

Conclusion: 本文提出的联合估计算法有效解决了AFDM在LEO-ICAN场景中的分数延迟和多普勒频率估计问题，为高动态卫星通信导航一体化信号设计提供了实用解决方案。

Abstract: With the rapid development of low earth orbit (LEO) satellites, the design of integrated communication and navigation (ICAN) signals has attracted increasing attention, especially in the field of vehicle-to-everything (V2X). As a new-generation waveform, Affine Frequency Division Multiplexing (AFDM) features high robustness against Doppler effects, a simple modulation structure, and low pilot overhead, making it a promising candidate for high-dynamic LEO satellite scenarios. However, LEO-ICAN AFDM signals face challenges in fractional delay and Doppler frequency estimation. Existing studies that ignore its inherent spectrum wrapping phenomenon may lead to deviations of varying degrees in model construction. This paper conducts an in-depth derivation of AFDM's input-output relationship under fractional cases, reveals the envelope characteristics of its equivalent channel, and proposes a joint estimation algorithm based on peak-to-sidelobe power ratio (PSPR) detection and early-late gate (ELG) to estimate fractional Doppler frequency and delay. Simulations show that the algorithm has low complexity, low guard interval overhead, and high precision compared with traditional methods.

</details>


### [16] [An Enhanced Polar-Domain Dictionary Design for Elevated BSs in Near-Field U-MIMO](https://arxiv.org/abs/2602.04331)
*Luca Antonelli,Antonio Alberto D'Amico,Luca Sanguinetti*

Main category: eess.SP

TL;DR: 提出一种适用于任意基站位置的三维近场U-MIMO采样网格设计框架，相比传统方法显著提升信道估计精度和频谱效率


<details>
  <summary>Details</summary>
Motivation: 现有近场U-MIMO网格设计方法大多假设基站位于地面，忽略了基站高度的影响，这与实际部署情况不符，限制了系统性能

Method: 提出广义网格设计框架，基于最优归一化均方误差最小化原则优化网格，而非传统相关性方法，适用于任意基站位置

Result: 在sub-THz频段的混合U-MIMO系统中，使用P-SOMP算法进行信道估计，分析表明所提设计相比现有方案显著提升信道估计精度和频谱效率

Conclusion: 考虑基站高度的三维网格设计对近场U-MIMO通信至关重要，所提框架能更准确地表示信道，为实际部署提供更优性能

Abstract: Near-field U-MIMO communications require carefully optimized sampling grids in both angular and distance domains. However, most existing grid design methods neglect the influence of base station height, assuming instead that the base station is positioned at ground level - a simplification that rarely reflects real-world deployments. To overcome this limitation, we propose a generalized grid design framework that accommodates arbitrary base station locations. Unlike conventional correlation-based approaches, our method optimizes the grid based on the minimization of the optimal normalized mean squared error, leading to more accurate channel representation. We evaluate the performance of a hybrid U-MIMO system operating at sub-THz frequencies, considering the P-SOMP algorithm for channel estimation. Analytical and numerical results show that the proposed design enhances both channel estimation accuracy and spectral efficiency compared to existing alternatives.

</details>


### [17] [Rigid Body Localization via Gaussian Belief Propagation with Quadratic Angle Approximation](https://arxiv.org/abs/2602.04410)
*Niclas Führling,Hyeon Seok Rou,Giuseppe Abreu,David González G.,Osvaldo Gonsa*

Main category: eess.SP

TL;DR: 提出一种基于高斯置信传播的刚性体定位新方法，通过二次角度近似消除对目标方向先验的依赖，实现高精度旋转角度估计


<details>
  <summary>Details</summary>
Motivation: 现有基于高斯置信传播的刚性体定位方法需要准确的目标方向先验信息，这限制了其实际应用。本文旨在消除这一限制，开发一种无需精确方向先验的定位方案。

Method: 采用二次角度近似来线性化先验与目标刚性体之间的相对方向，即使在大偏差情况下也能实现高精度旋转角度估计。基于线性化模型推导出相应的消息传递规则，用于估计目标刚性体相对于先验参考系的平移向量和旋转矩阵。

Result: 数值结果表明，所提出的角度近似方法本身性能良好，刚性体定位在均方根误差方面优于现有技术，同时保持了较低的计算复杂度。

Conclusion: 成功开发了一种无需精确方向先验的基于高斯置信传播的刚性体定位方案，通过二次角度近似实现了高精度估计，在性能和计算效率方面均优于现有方法。

Abstract: Gaussian belief propagation (GaBP) is a technique that relies on linearized error and input-output models to yield low-complexity solutions to complex estimation problems, which has been recently shown to be effective in the design of range-based GaBP schemes for stationary and moving rigid body localization (RBL) in three-dimensional (3D) space, as long as an accurate prior on the orientation of the target rigid body is available. In this article we present a novel range-based RBL scheme via GaBP that removes the latter limitation. To this end, the proposed method incorporates a quadratic angle approximation to linearize the relative orientation between the prior and the target rigid body, enabling high precision estimates of corresponding rotation angles even for large deviations. Leveraging the resulting linearized model, we derive the corresponding message-passing (MP) rules to obtain estimates of the translation vector and rotation matrix of the target rigid body, relative to a prior reference frame. Numerical results corroborate the good performance of the proposed angle approximation itself, as well as the consequent RBL performance in terms of root mean square errors (RMSEs) in comparison to the state-of-the-art (SotA), while maintaining a low computational complexity

</details>


### [18] [An Information-Theoretic Detector for Multiple Scatterers in SAR Tomography](https://arxiv.org/abs/2602.04465)
*Pia Addabbo,Diego Reale,Antonio Pauciullo,Gianfranco Fornaro,Danilo Orlando*

Main category: eess.SP

TL;DR: 提出一种基于信息理论和压缩感知的SAR层析成像多假设检验自适应架构，用于解决城市区域叠掩问题中的多散射体检测与参数估计。


<details>
  <summary>Details</summary>
Motivation: 在城市SAR层析成像中，叠掩现象导致同一像素包含来自不同高度的多个散射体贡献，需要有效方法检测和分离这些多散射体。

Method: 采用信息理论框架，设计单阶段自适应多假设检验架构，结合压缩感知方法估计各假设下的未知参数。

Result: 该架构在模拟和真实数据上进行了验证，并与合适的对比方法进行了比较，证明了其有效性。

Conclusion: 基于信息理论和压缩感知的自适应多假设检验架构能够有效解决SAR层析成像中的多散射体检测问题，适用于城市区域叠掩场景。

Abstract: Persistent scatterer interferometry and Synthetic Aperture Radar (SAR) Tomography are powerful tools for the detection and time monitoring of persistent scatterers. They have been proven to be effective in urban scenarios, especially for buildings and infrastructures 3-D reconstruction and monitoring of deformation. In urban areas, occurrence of layover leads to the presence of multiple contributions within the same image pixel from scatterers located at different heights. In the context of SAR Tomography, this problem can be addressed by considering a multiple hypothesis test to detect the presence of feasible multiple scatterers [1][2]. In the present paper, we consider this problem in the framework of the information theory and exploit the theoretical tool, developed in [3], to design a one-stage adaptive architecture for multiple hypothesis testing problems in the context of SAR Tomography. Moreover, we resort to the compressive sensing approach for the estimation of the unknown parameters under each hypothesis. This architecture has been verified on both simulated as well as real data also in comparison with suitable counterparts.

</details>


### [19] [Total Variation Sparse Bayesian Learning for Block Sparsity via Majorization-Minimization](https://arxiv.org/abs/2602.04623)
*Yanbin He,Geethu Joseph*

Main category: eess.SP

TL;DR: 提出一种新的优化框架，用于解决具有差异对数总变分正则化的稀疏贝叶斯学习问题，通过指数重参数化实现高效求解，在合成数据和DOA估计中表现优于基准方法。


<details>
  <summary>Details</summary>
Motivation: 块稀疏性在稀疏恢复中被广泛利用，但当信号块边界未知且存在孤立非零值时，传统方法面临挑战。差异对数总变分正则化的稀疏贝叶斯学习能处理复杂稀疏模式，但其优化问题因复杂形式而难以求解。

Method: 通过引入SBL超参数的指数重参数化，揭示新的结构，采用主优化-最小化框架，并自然扩展到未知噪声方差估计。

Result: 在合成数据和扩展源方向到达估计中的稀疏恢复结果表明，相比基准方法，该方法在准确性和运行时间性能上都有改进。

Conclusion: 提出的优化框架有效解决了DoL-TV SBL成本函数的求解难题，通过指数重参数化和主优化-最小化方法实现了高效稀疏恢复，适用于具有未知块边界和孤立非零值的复杂稀疏模式。

Abstract: Block sparsity is a widely exploited structure in sparse recovery, offering significant gains when signal blocks are known. Yet, practical signals often exhibit unknown block boundaries and isolated non-zero entries, which challenge traditional approaches. A promising method to handle such complex sparsity patterns is the difference-of-logs total variation (DoL-TV) regularized sparse Bayesian learning (SBL). However, due to the complex form of DoL-TV term, the resulting optimization problem is hard to solve. This paper develops a new optimization framework for the DoL-TV SBL cost function. By introducing an exponential reparameterization of the SBL hyperparameters, we reveal a novel structure that admits a majorization-minimization formulation and naturally extends to unknown noise variance estimation. Sparse recovery results on both synthetic data and extended source direction-of-arrival estimation demonstrate improved accuracy and runtime performance compared to benchmark methods.

</details>


### [20] [Learning to Separate RF Signals Under Uncertainty: Detect-Then-Separate vs. Unified Joint Models](https://arxiv.org/abs/2602.04650)
*Ariel Rodrigez,Alejandro Lancho,Amir Weiss*

Main category: eess.SP

TL;DR: 提出统一联合模型(UJM)用于单通道射频信号干扰检测与分离，相比传统检测-分离策略(DTS)具有更好的可扩展性，在多种干扰类型和信噪比条件下匹配最优性能。


<details>
  <summary>Details</summary>
Motivation: 射频频谱日益拥挤导致异构干扰增多，现有数据驱动方法通常假设干扰类型已知，导致专用模型集合难以扩展。检测-分离策略(DTS)虽有理论依据但依赖多个类型特定模型，限制了可扩展性。

Method: 提出统一联合模型(UJM)，使用单一深度神经网络架构直接对接收信号进行联合检测和分离。采用针对基带(复值)射频信号定制的UNet架构，并与DTS策略进行比较。

Result: 在合成和记录的干扰类型上，容量匹配的UJM能够在不同信干噪比、干扰类型和星座阶数下匹配oracle辅助DTS的性能，包括训练和测试中类型不确定性比例不匹配的情况。

Conclusion: UJM作为DTS的可扩展实用替代方案，为更广泛机制下的统一分离开辟了新方向，展示了单一模型处理多种干扰类型的潜力。

Abstract: The increasingly crowded radio frequency (RF) spectrum forces communication signals to coexist, creating heterogeneous interferers whose structure often departs from Gaussian models. Recovering the interference-contaminated signal of interest in such settings is a central challenge, especially in single-channel RF processing. Existing data-driven methods often assume that the interference type is known, yielding ensembles of specialized models that scale poorly with the number of interferers. We show that detect-then-separate (DTS) strategies admit an analytical justification: within a Gaussian mixture framework, a plug-in maximum a posteriori detector followed by type-conditioned optimal estimation achieves asymptotic minimum mean-square error optimality under a mild temporal-diversity condition. This makes DTS a principled benchmark, but its reliance on multiple type-specific models limits scalability. Motivated by this, we propose a unified joint model (UJM), in which a single deep neural architecture learns to jointly detect and separate when applied directly to the received signal. Using tailored UNet architectures for baseband (complex-valued) RF signals, we compare DTS and UJM on synthetic and recorded interference types, showing that a capacity-matched UJM can match oracle-aided DTS performance across diverse signal-to-interference-and-noise ratios, interference types, and constellation orders, including mismatched training and testing type-uncertainty proportions. These findings highlight UJM as a scalable and practical alternative to DTS, while opening new directions for unified separation under broader regimes.

</details>


### [21] [HFMCA: Orthonormal Feature Learning for EEG-based Brain Decoding](https://arxiv.org/abs/2602.04681)
*Yinghao Wang,Lintao Xu,Shujian Yu,Enzo Tartaglione,Van-Tam Nguyen*

Main category: eess.SP

TL;DR: 提出基于分层功能最大相关算法（HFMCA）的自监督框架，学习正交归一化的EEG表征，通过特征去相关和冗余减少来捕捉脑动力学，在SEED和BCIC-2A数据集上超越基线方法。


<details>
  <summary>Details</summary>
Motivation: EEG信号存在固有噪声和高维度特性，阻碍了有效特征学习，需要开发能够提取稳健表征的方法来改进脑机接口和神经科学研究。

Method: 提出分层功能最大相关算法（HFMCA）的自监督框架，通过强制特征去相关和减少冗余来学习正交归一化的EEG表征，从而捕捉本质的脑动力学。

Result: 在SEED和BCIC-2A基准数据集上，HFMCA预训练始终优于竞争的自监督基线方法，在SEED情绪识别上提升2.71%，在BCIC-2A运动想象分类上提升2.57%，在跨被试泛化方面表现优异。

Conclusion: HFMCA框架能够有效学习稳健的EEG表征，在多种EEG识别任务中实现卓越的跨被试泛化能力，推动了脑机接口和神经科学研究的进展。

Abstract: Electroencephalography (EEG) analysis is critical for brain-computer interfaces and neuroscience, but the intrinsic noise and high dimensionality of EEG signals hinder effective feature learning. We propose a self-supervised framework based on the Hierarchical Functional Maximal Correlation Algorithm (HFMCA), which learns orthonormal EEG representations by enforcing feature decorrelation and reducing redundancy. This design enables robust capture of essential brain dynamics for various EEG recognition tasks. We validate HFMCA on two benchmark datasets, SEED and BCIC-2A, where pretraining with HFMCA consistently outperforms competitive self-supervised baselines, achieving notable gains in classification accuracy. Across diverse EEG tasks, our method demonstrates superior cross-subject generalization under leave-one-subject-out validation, advancing state-of-the-art by 2.71\% on SEED emotion recognition and 2.57\% on BCIC-2A motor imagery classification.

</details>


### [22] [Knowledge Distillation for mmWave Beam Prediction Using Sub-6 GHz Channels](https://arxiv.org/abs/2602.04703)
*Sina Tavakolian,Nhan Thanh Nguyen,Ahmed Alkhateeb,Markku Juntti*

Main category: eess.SP

TL;DR: 提出基于知识蒸馏的高效毫米波波束成形框架，使用紧凑学生模型在保持性能的同时大幅降低计算复杂度


<details>
  <summary>Details</summary>
Motivation: 毫米波高移动性环境中的波束成形通常需要大量训练开销，现有基于sub-6 GHz信道预测毫米波波束的方法依赖大型深度学习模型，计算和内存需求过高

Method: 基于知识蒸馏技术开发高效框架，设计两种紧凑学生DL架构（个体蒸馏和关系蒸馏策略），仅保留少量隐藏层但能模拟大型教师模型的性能

Result: 学生模型达到教师模型的波束预测精度和频谱效率，同时将可训练参数和计算复杂度降低99%

Conclusion: 提出的知识蒸馏框架能有效解决毫米波波束成形中的计算效率问题，为高移动性环境提供实用的解决方案

Abstract: Beamforming in millimeter-wave (mmWave) high-mobility environments typically incurs substantial training overhead. While prior studies suggest that sub-6 GHz channels can be exploited to predict optimal mmWave beams, existing methods depend on large deep learning (DL) models with prohibitive computational and memory requirements. In this paper, we propose a computationally efficient framework for sub-6 GHz channel-mmWave beam mapping based on the knowledge distillation (KD) technique. We develop two compact student DL architectures based on individual and relational distillation strategies, which retain only a few hidden layers yet closely mimic the performance of large teacher DL models. Extensive simulations demonstrate that the proposed student models achieve the teacher's beam prediction accuracy and spectral efficiency while reducing trainable parameters and computational complexity by 99%.

</details>


### [23] [Resilient Channel Charting Under Varying Radio Link Availability](https://arxiv.org/abs/2602.04704)
*Jonas Pirkl,Jonathan Ott,Maximilian Stahlke,George Yammine,Tobias Feigl,Christopher Mutschler*

Main category: eess.SP

TL;DR: AdaPos是一种自适应定位架构，通过结合卷积特征提取和基于transformer的编码器，能够原生处理可变数量的信道测量，解决了传统信道图表技术中固定输入尺寸的限制问题。


<details>
  <summary>Details</summary>
Motivation: 传统信道图表技术假设固定尺寸输入（如恒定天线数量），但在实际系统中天线可能故障、信号可能被阻挡或天线配置可能在切换时改变，导致固定输入架构脆弱。现有方法需要为每种天线配置训练单独模型，训练工作量随阵列尺寸呈指数增长。

Method: AdaPos结合卷积特征提取和基于transformer的编码器，使用可学习的天线标识符和自注意力机制来融合任意子集的CSI输入。通过新颖的训练策略，提供对单个天线故障和全阵列中断的弹性。

Result: 在两个公开真实世界数据集（SISO和MIMO）上的实验表明，AdaPos在缺失天线条件下保持最先进的精度，用单个统一模型替代了约57个配置特定模型。

Conclusion: AdaPos提供了一种能够原生处理可变数量信道测量的自适应定位架构，解决了实际系统中天线配置变化的挑战，显著减少了模型训练工作量并提高了系统弹性。

Abstract: Channel charting (CC) has become a key technology for RF-based localization, enabling unsupervised radio fingerprinting, even in non line of sight scenarios, with a minimum of reference position labels. However, most CC models assume fixed-size inputs, such as a constant number of antennas or channel measurements. In practical systems, antennas may fail, signals may be blocked, or antenna sets may change during handovers, making fixed-input architectures fragile. Existing radio-fingerprinting approaches address this by training separate models for each antenna configuration, but the resulting training effort scales prohibitively with the array size. We propose Adaptive Positioning (AdaPos), a CC architecture that natively handles variable numbers of channel measurements. AdaPos combines convolutional feature extraction with a transformer-based encoder using learnable antenna identifiers and self-attention to fuse arbitrary subsets of CSI inputs. Experiments on two public real-world datasets (SISO and MIMO) show that AdaPos maintains state-of-the-art accuracy under missing-antenna conditions and replaces roughly 57 configuration-specific models with a single unified model. With AdaPos and our novel training strategies, we provide resilience to both individual antenna failures and full-array outages.

</details>


### [24] [Cross-Attention Transformer for Joint Multi-Receiver Uplink Neural Decoding](https://arxiv.org/abs/2602.04728)
*Xavier Tardy,Grégoire Lefebvre,Apostolos Kountouris,Haïfa Fares,Amor Nafkha*

Main category: eess.SP

TL;DR: 提出一种跨注意力Transformer，用于联合解码多个协调接入点接收的上行OFDM信号，无需显式信道估计，通过比特度量目标训练，在Wi-Fi信道中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统Wi-Fi接收器需要显式的每接收器信道估计，这在导频稀疏或信道条件复杂时性能受限。需要一种能够自适应融合多个接收器信号、容忍链路退化、且计算高效的联合解码方法。

Method: 使用跨注意力Transformer架构：1）共享的每接收器编码器学习每个接收网格的时频结构；2）基于token的跨注意力模块融合多个接收器信息；3）输出软对数似然比供标准信道解码器使用；4）使用比特度量目标进行端到端训练。

Result: 在真实Wi-Fi信道中，该方法持续优于传统流水线和强卷积基线，经常匹配（某些情况下超越）假设完美信道知识的强大基线。模型紧凑、计算成本低（低GFLOPs）、在GPU上延迟低。

Conclusion: 提出的跨注意力Transformer是一种实用的下一代Wi-Fi接收器构建块，能够自适应融合多接收器信号、容忍链路退化、在导频稀疏时保持鲁棒性，且计算效率高。

Abstract: We propose a cross-attention Transformer for joint decoding of uplink OFDM signals received by multiple coordinated access points. A shared per-receiver encoder learns time-frequency structure within each received grid, and a token-wise cross-attention module fuses the receivers to produce soft log-likelihood ratios for a standard channel decoder, without requiring explicit per-receiver channel estimates. Trained with a bit-metric objective, the model adapts its fusion to per-receiver reliability, tolerates missing or degraded links, and remains robust when pilots are sparse. Across realistic Wi-Fi channels, it consistently outperforms classical pipelines and strong convolutional baselines, frequently matching (and in some cases surpassing) a powerful baseline that assumes perfect channel knowledge per access point. Despite its expressiveness, the architecture is compact, has low computational cost (low GFLOPs), and achieves low latency on GPUs, making it a practical building block for next-generation Wi-Fi receivers.

</details>


### [25] [Safe-NEureka: a Hybrid Modular Redundant DNN Accelerator for On-board Satellite AI Processing](https://arxiv.org/abs/2602.04803)
*Riccardo Tedeschi,Luigi Ghionda,Alessandro Nadalini,Yvan Tortorella,Arpan Suravi Prasad,Luca Benini,Davide Rossi,Francesco Conti*

Main category: eess.SP

TL;DR: Safe-NEureka是一个用于卫星的混合模块冗余DNN加速器，支持冗余模式（DMR硬件恢复）和性能模式（最大化并行吞吐），在辐射防护和性能间取得平衡。


<details>
  <summary>Details</summary>
Motivation: LEO星座卫星需要AI加速器来处理安全关键（如自主GNC）和性能关键（如传感器数据处理）任务。这些加速器必须同时具备辐射故障防护和高吞吐能力。

Method: 提出Safe-NEureka混合模块冗余DNN加速器，采用异构RISC-V系统。包含两种模式：冗余模式使用DMR加硬件恢复；性能模式重用冗余数据路径最大化并行吞吐。内存接口用ECC保护，控制器用TMR保护。

Result: 在GlobalFoundries 12nm技术中实现：冗余模式下故障执行减少96倍，面积开销15%；性能模式下3x3密集卷积接近基线速度，吞吐量降低5%，效率降低11%（冗余模式下分别为48%和53%）。

Conclusion: Safe-NEureka通过灵活的混合冗余设计，在关键任务中提供高可靠性，在非关键任务中保持高性能，成为太空应用的通用解决方案。

Abstract: Low Earth Orbit (LEO) constellations are revolutionizing the space sector, with on-board Artificial Intelligence (AI) becoming pivotal for next-generation satellites. AI acceleration is essential for safety-critical functions such as autonomous Guidance, Navigation, and Control (GNC), where errors cannot be tolerated, and performance-critical processing of high-bandwidth sensor data, where occasional errors are tolerable. Consequently, AI accelerators for satellites must combine robust protection against radiation-induced faults with high throughput. This paper presents Safe-NEureka, a Hybrid Modular Redundant Deep Neural Network (DNN) accelerator for heterogeneous RISC-V systems. It operates in two modes: a redundancy mode utilizing Dual Modular Redundancy (DMR) with hardware-based recovery, and a performance mode repurposing redundant datapaths to maximize parallel throughput. Furthermore, its memory interface is protected by Error Correction Codes (ECCs), and the controller by Triple Modular Redundancy (TMR). Implementation in GlobalFoundries 12nm technology shows a 96 reduction in faulty executions in redundancy mode, with a manageable 15 area overhead. In performance mode, the architecture achieves near-baseline speeds on 3x3 dense convolutions with a 5 throughput and 11 efficiency reduction, compared to 48 and 53 in redundancy mode. This flexibility ensures high overheads are limited to critical tasks, establishing Safe-NEureka as a versatile solution for space applications.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [26] [Benchmarking Automatic Speech Recognition for Indian Languages in Agricultural Contexts](https://arxiv.org/abs/2602.03868)
*Chandrashekar M S,Vineet Singh,Lakshmi Pedapudi*

Main category: eess.AS

TL;DR: 该论文提出了一个评估印度农业领域多语言自动语音识别（ASR）性能的基准框架，涵盖印地语、泰卢固语和奥里亚语，引入了农业加权词错误率等新指标，分析了10,934条农业录音，发现印地语表现最佳，奥里亚语挑战最大，并证明说话人分离技术能显著提升多说话人录音的识别准确率。


<details>
  <summary>Details</summary>
Motivation: 印度农业咨询服务的数字化需要能够准确转录多种印度语言中农业领域专业术语的ASR系统。目前缺乏针对农业领域、特别是低资源语言的有效评估框架和基准，这阻碍了农业ASR系统的开发和应用。

Method: 1. 建立包含印地语、泰卢固语和奥里亚语三种语言的农业ASR评估框架；2. 引入农业加权词错误率（AWWER）和领域特定效用评分等新指标；3. 收集并分析10,934条农业音频录音；4. 使用最多10个ASR模型进行转录评估；5. 分析音频质量挑战和错误模式；6. 评估说话人分离技术对多说话人录音的效果。

Result: 1. 印地语表现最佳（WER：16.2%），奥里亚语挑战最大（最佳WER：35.1%，仅在使用说话人分离时达到）；2. 说话人分离结合最佳说话人选择能显著降低多说话人录音的WER（最高可达66%）；3. 识别出农业术语中的常见错误模式；4. 建立了农业ASR的基准性能数据。

Conclusion: 该研究为农业领域的ASR系统开发建立了重要的基准框架，揭示了不同语言和模型在农业语境下的性能差异，证明了说话人分离技术对提升多说话人录音识别准确性的有效性，并为改进低资源农业领域的ASR系统提供了实用建议。

Abstract: The digitization of agricultural advisory services in India requires robust Automatic Speech Recognition (ASR) systems capable of accurately transcribing domain-specific terminology in multiple Indian languages. This paper presents a benchmarking framework for evaluating ASR performance in agricultural contexts across Hindi, Telugu, and Odia languages. We introduce evaluation metrics including Agriculture Weighted Word Error Rate (AWWER) and domain-specific utility scoring to complement traditional metrics. Our evaluation of 10,934 audio recordings, each transcribed by up to 10 ASR models, reveals performance variations across languages and models, with Hindi achieving the best overall performance (WER: 16.2%) while Odia presents the greatest challenges (best WER: 35.1%, achieved only with speaker diarization). We characterize audio quality challenges inherent to real-world agricultural field recordings and demonstrate that speaker diarization with best-speaker selection can substantially reduce WER for multi-speaker recordings (upto 66% depending on the proportion of multi-speaker audio). We identify recurring error patterns in agricultural terminology and provide practical recommendations for improving ASR systems in low-resource agricultural domains. The study establishes baseline benchmarks for future agricultural ASR development.

</details>


### [27] [Sounding Highlights: Dual-Pathway Audio Encoders for Audio-Visual Video Highlight Detection](https://arxiv.org/abs/2602.03891)
*Seohyun Joo,Yoori Oh*

Main category: eess.AS

TL;DR: 提出DAViHD框架，通过双路径音频编码器（语义路径和动态路径）增强音视频高光检测，在Mr.HiSum基准上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有音视频高光检测模型对音频模态利用不足，主要关注高层语义特征，未能充分利用声音的丰富动态特性。

Method: 提出双路径音频编码器：语义路径提取音频内容（如语音、音乐、特定声音事件）的高层信息；动态路径采用频率自适应机制建模时频动态特性，通过显著频谱带和快速能量变化识别瞬态声学事件。

Result: 在大规模Mr.HiSum基准上取得了新的最先进性能。

Conclusion: 复杂、双方面的音频表示是推进高光检测领域发展的关键。

Abstract: Audio-visual video highlight detection aims to automatically identify the most salient moments in videos by leveraging both visual and auditory cues. However, existing models often underutilize the audio modality, focusing on high-level semantic features while failing to fully leverage the rich, dynamic characteristics of sound. To address this limitation, we propose a novel framework, Dual-Pathway Audio Encoders for Video Highlight Detection (DAViHD). The dual-pathway audio encoder is composed of a semantic pathway for content understanding and a dynamic pathway that captures spectro-temporal dynamics. The semantic pathway extracts high-level information by identifying the content within the audio, such as speech, music, or specific sound events. The dynamic pathway employs a frequency-adaptive mechanism as time evolves to jointly model these dynamics, enabling it to identify transient acoustic events via salient spectral bands and rapid energy changes. We integrate the novel audio encoder into a full audio-visual framework and achieve new state-of-the-art performance on the large-scale Mr.HiSum benchmark. Our results demonstrate that a sophisticated, dual-faceted audio representation is key to advancing the field of highlight detection.

</details>


### [28] [Universal Robust Speech Adaptation for Cross-Domain Speech Recognition and Enhancement](https://arxiv.org/abs/2602.04307)
*Chien-Chun Wang,Hung-Shin Lee,Hsin-Min Wang,Berlin Chen*

Main category: eess.AS

TL;DR: URSA-GAN是一个统一的领域感知生成框架，通过双嵌入架构（噪声编码器和通道编码器）和动态随机扰动技术，解决ASR和语音增强在噪声和通道失配条件下的性能下降问题。


<details>
  <summary>Details</summary>
Motivation: 预训练的ASR和语音增强模型在匹配的噪声和通道条件下表现优异，但在面对领域转移（特别是未见过的噪声和通道失真）时性能严重下降，需要解决这种失配问题。

Method: 提出URSA-GAN框架：1）使用噪声编码器和通道编码器组成的双嵌入架构，每个编码器用有限的领域内数据预训练以捕获领域相关表示；2）这些嵌入条件化基于GAN的语音生成器，合成与目标领域声学对齐的语音；3）提出动态随机扰动技术，在生成过程中向嵌入引入受控变异性，增强对未见领域的鲁棒性。

Result: URSA-GAN在多种噪声和失配通道场景中有效降低了ASR的字符错误率，改善了语音增强的感知指标。在同时包含通道和噪声退化的复合测试条件下，ASR性能相对提升16.16%，语音增强指标相对提升15.58%。

Conclusion: URSA-GAN通过统一的领域感知生成框架，成功缓解了噪声和通道条件失配问题，在ASR和语音增强任务中展现出良好的泛化能力，特别是在未见领域条件下表现优异。

Abstract: Pre-trained models for automatic speech recognition (ASR) and speech enhancement (SE) have exhibited remarkable capabilities under matched noise and channel conditions. However, these models often suffer from severe performance degradation when confronted with domain shifts, particularly in the presence of unseen noise and channel distortions. In view of this, we in this paper present URSA-GAN, a unified and domain-aware generative framework specifically designed to mitigate mismatches in both noise and channel conditions. URSA-GAN leverages a dual-embedding architecture that consists of a noise encoder and a channel encoder, each pre-trained with limited in-domain data to capture domain-relevant representations. These embeddings condition a GAN-based speech generator, facilitating the synthesis of speech that is acoustically aligned with the target domain while preserving phonetic content. To enhance generalization further, we propose dynamic stochastic perturbation, a novel regularization technique that introduces controlled variability into the embeddings during generation, promoting robustness to unseen domains. Empirical results demonstrate that URSA-GAN effectively reduces character error rates in ASR and improves perceptual metrics in SE across diverse noisy and mismatched channel scenarios. Notably, evaluations on compound test conditions with both channel and noise degradations confirm the generalization ability of URSA-GAN, yielding relative improvements of 16.16% in ASR performance and 15.58% in SE metrics.

</details>


### [29] [LALM-as-a-Judge: Benchmarking Large Audio-Language Models for Safety Evaluation in Multi-Turn Spoken Dialogues](https://arxiv.org/abs/2602.04796)
*Amir Ivry,Shinji Watanabe*

Main category: eess.AS

TL;DR: 首个系统研究大型音频语言模型作为多轮口语对话安全评估器的基准测试，揭示了架构和模态间的权衡：最敏感的模型稳定性最差，而稳定配置会牺牲对轻度有害内容的检测。


<details>
  <summary>Details</summary>
Motivation: 当前语音对话安全评估主要基于文本，忽略了音频特定线索和转录错误，需要开发能够处理多轮口语对话的音频语言模型安全评估方法。

Method: 创建包含24,000个英语合成语音对话的基准数据集，涵盖8种有害类别和5个严重程度等级。评估三种开源LALM作为零样本安全评估器，比较音频、转录和多模态输入模式，并与纯文本LLaMA基线对比。

Result: 发现架构和模态依赖的权衡：最敏感的评估器在对话轮次间最不稳定，而稳定配置会牺牲对轻度有害内容的检测。转录质量是关键瓶颈，音频模态在副语言线索或转录保真度关键时至关重要。

Conclusion: 为从业者提供实用指导，强调需要平衡敏感性、稳定性和模态选择，音频模态在特定有害类别评估中具有不可替代的价值。

Abstract: Spoken dialogues with and between voice agents are becoming increasingly common, yet assessing them for their socially harmful content such as violence, harassment, and hate remains text-centric and fails to account for audio-specific cues and transcription errors. We present LALM-as-a-Judge, the first controlled benchmark and systematic study of large audio-language models (LALMs) as safety judges for multi-turn spoken dialogues. We generate 24,000 unsafe and synthetic spoken dialogues in English that consist of 3-10 turns, by having a single dialogue turn including content with one of 8 harmful categories (e.g., violence) and on one of 5 grades, from very mild to severe. On 160 dialogues, 5 human raters confirmed reliable unsafe detection and a meaningful severity scale. We benchmark three open-source LALMs: Qwen2-Audio, Audio Flamingo 3, and MERaLiON as zero-shot judges that output a scalar safety score in [0,1] across audio-only, transcription-only, or multimodal inputs, along with a transcription-only LLaMA baseline. We measure the judges' sensitivity to detecting unsafe content, the specificity in ordering severity levels, and the stability of the score in dialogue turns. Results reveal architecture- and modality-dependent trade-offs: the most sensitive judge is also the least stable across turns, while stable configurations sacrifice detection of mild harmful content. Transcription quality is a key bottleneck: Whisper-Large may significantly reduce sensitivity for transcription-only modes, while largely preserving severity ordering. Audio becomes crucial when paralinguistic cues or transcription fidelity are category-critical. We summarize all findings and provide actionable guidance for practitioners.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [30] [Decoding Ambiguous Emotions with Test-Time Scaling in Audio-Language Models](https://arxiv.org/abs/2602.03873)
*Hong Jia,Weibin Li,Jingyao Wu,Xiaofeng Yu,Yan Gao,Jintao Cheng,Xiaoyu Tang,Feng Xia,Ting Dang*

Main category: cs.SD

TL;DR: 该论文提出了首个在测试时缩放条件下使用音频语言模型进行模糊语音情感识别的基准测试，系统评估了8个先进ALM和5种TTS策略，分析了模型容量、TTS与情感模糊性之间的相互作用。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的情感状态往往是模糊、重叠且依赖语境的，而传统的情感识别方法通常将其视为分类问题，这在实际应用中面临挑战。同时，虽然大型音频语言模型为无需显式情感监督的细致情感推理提供了新机会，但其处理模糊情感的能力尚未充分探索。测试时缩放技术在NLP任务中显示出潜力，但在情感计算中的应用仍未知。

Method: 创建了首个在测试时缩放条件下使用音频语言模型进行模糊语音情感识别的基准测试。系统比较了8个最先进的音频语言模型和5种测试时缩放策略，在三个著名的语音情感数据集上进行评估。深入分析了模型容量、测试时缩放和情感模糊性之间的相互作用。

Result: 建立了模糊语音情感识别的基准框架，提供了关于模型容量、测试时缩放和情感模糊性相互作用的深入分析，揭示了模糊情感理解的计算和表征挑战。

Conclusion: 该基准为开发更鲁棒、上下文感知和情感智能的语音AI系统奠定了基础，突出了弥合模型假设与现实世界人类情感复杂性之间差距的关键未来方向。

Abstract: Emotion recognition from human speech is a critical enabler for socially aware conversational AI. However, while most prior work frames emotion recognition as a categorical classification problem, real-world affective states are often ambiguous, overlapping, and context-dependent, posing significant challenges for both annotation and automatic modeling. Recent large-scale audio language models (ALMs) offer new opportunities for nuanced affective reasoning without explicit emotion supervision, but their capacity to handle ambiguous emotions remains underexplored. At the same time, advances in inference-time techniques such as test-time scaling (TTS) have shown promise for improving generalization and adaptability in hard NLP tasks, but their relevance to affective computing is still largely unknown. In this work, we introduce the first benchmark for ambiguous emotion recognition in speech with ALMs under test-time scaling. Our evaluation systematically compares eight state-of-the-art ALMs and five TTS strategies across three prominent speech emotion datasets. We further provide an in-depth analysis of the interaction between model capacity, TTS, and affective ambiguity, offering new insights into the computational and representational challenges of ambiguous emotion understanding. Our benchmark establishes a foundation for developing more robust, context-aware, and emotionally intelligent speech-based AI systems, and highlights key future directions for bridging the gap between model assumptions and the complexity of real-world human emotion.

</details>


### [31] [Frontend Token Enhancement for Token-Based Speech Recognition](https://arxiv.org/abs/2602.04217)
*Takanori Ashihara,Shota Horiguchi,Kohei Matsuura,Tsubasa Ochiai,Marc Delcroix*

Main category: cs.SD

TL;DR: 提出一种前端系统，用于从带噪语音中估计干净语音token，并在使用语义token的ASR后端上进行评估，其中wave-to-token增强方法表现最佳。


<details>
  <summary>Details</summary>
Motivation: 语音信号的离散化表示（如语义或音素token）是语音应用的高效替代方案，但这些表示容易受到环境噪声影响，从而降低后端任务性能。

Method: 提出前端增强系统，考虑四种输入/输出域模型：wave-to-wave、token-to-token、continuous SSL features-to-token和wave-to-token，这些模型独立于ASR后端进行训练。

Result: 在CHiME-4数据集上的实验表明，wave-to-token增强在前端中表现最佳，并且大多优于基于连续SSL特征的ASR系统。

Conclusion: wave-to-token增强方法能有效提升带噪环境下基于离散token的ASR系统性能，展示了前端增强对离散语音表示的重要性。

Abstract: Discretized representations of speech signals are efficient alternatives to continuous features for various speech applications, including automatic speech recognition (ASR) and speech language models. However, these representations, such as semantic or phonetic tokens derived from clustering outputs of self-supervised learning (SSL) speech models, are susceptible to environmental noise, which can degrade backend task performance. In this work, we introduce a frontend system that estimates clean speech tokens from noisy speech and evaluate it on an ASR backend using semantic tokens. We consider four types of enhancement models based on their input/output domains: wave-to-wave, token-to-token, continuous SSL features-to-token, and wave-to-token. These models are trained independently of ASR backends. Experiments on the CHiME-4 dataset demonstrate that wave-to-token enhancement achieves the best performance among the frontends. Moreover, it mostly outperforms the ASR system based on continuous SSL features.

</details>


### [32] [Speaker-Aware Simulation Improves Conversational Speech Recognition](https://arxiv.org/abs/2602.04776)
*Máté Gedeon,Péter Mihajlik*

Main category: cs.SD

TL;DR: 将说话人感知模拟对话（SASC）框架应用于匈牙利语对话ASR，并提出带暂停建模的C-SASC变体，通过合成对话数据增强提升识别性能。


<details>
  <summary>Details</summary>
Motivation: 对话语音识别面临多说话人对话数据稀缺的挑战，现有SASC方法主要针对英语，需要验证其在低资源语言（如匈牙利语）中的适用性。

Method: 将SASC框架适配匈牙利语，提出C-SASC变体（基于话语时长的暂停建模），从BEA-Large语料生成合成对话，结合真实对话数据进行ASR训练。

Result: 说话人感知对话模拟相比简单拼接增强显著提升识别性能，C-SASC在字符级错误率上带来适度但系统的改进，效果取决于源对话统计与目标域的匹配度。

Conclusion: SASC框架对匈牙利语ASR具有鲁棒性，更精细的时间建模在合成对话生成中既有益处也有局限性，需考虑统计匹配问题。

Abstract: Automatic speech recognition (ASR) for conversational speech remains challenging due to the limited availability of large-scale, well-annotated multi-speaker dialogue data and the complex temporal dynamics of natural interactions. Speaker-aware simulated conversations (SASC) offer an effective data augmentation strategy by transforming single-speaker recordings into realistic multi-speaker dialogues. However, prior work has primarily focused on English data, leaving questions about the applicability to lower-resource languages. In this paper, we adapt and implement the SASC framework for Hungarian conversational ASR. We further propose C-SASC, an extended variant that incorporates pause modeling conditioned on utterance duration, enabling a more faithful representation of local temporal dependencies observed in human conversation while retaining the simplicity and efficiency of the original approach. We generate synthetic Hungarian dialogues from the BEA-Large corpus and combine them with real conversational data for ASR training. Both SASC and C-SASC are evaluated extensively under a wide range of simulation configurations, using conversational statistics derived from CallHome, BEA-Dialogue, and GRASS corpora. Experimental results show that speaker-aware conversational simulation consistently improves recognition performance over naive concatenation-based augmentation. While the additional duration conditioning in C-SASC yields modest but systematic gains--most notably in character-level error rates--its effectiveness depends on the match between source conversational statistics and the target domain. Overall, our findings confirm the robustness of speaker-aware conversational simulation for Hungarian ASR and highlight the benefits and limitations of increasingly detailed temporal modeling in synthetic dialogue generation.

</details>


### [33] [BASS: Benchmarking Audio LMs for Musical Structure and Semantic Reasoning](https://arxiv.org/abs/2602.04085)
*Min Jang,Orevaoghene Ahia,Nazif Tamer,Sachin Kumar,Yulia Tsvetkov,Noah A. Smith*

Main category: cs.SD

TL;DR: BASS是一个评估音频语言模型音乐理解与推理能力的基准，包含2658个问题、12个任务，涵盖1993首歌曲，发现当前模型在歌词转录表现最好，但在高层次推理任务如结构分割和艺术家合作方面仍有困难。


<details>
  <summary>Details</summary>
Motivation: 音乐理解需要同时处理音频的结构和语义元素，但当前缺乏系统评估音频语言模型音乐理解与推理能力的基准。

Method: 开发BASS基准，包含四个大类：结构分割、歌词转录、音乐学分析、艺术家合作，共12个任务、2658个问题，覆盖1993首独特歌曲、138小时音乐，涵盖多种流派。

Result: 评估了14个开源和前沿多模态语言模型，发现即使最先进的模型在结构分割和艺术家合作等高层次推理任务上仍困难，在歌词转录上表现最好。模型能有效利用语言先验，但在音乐结构、人声和音乐学属性推理方面有限。

Conclusion: BASS为音乐理解和推理提供了全面的评估框架，在音乐推荐和搜索中有广泛应用潜力，并能指导音频语言模型的未来发展。

Abstract: Music understanding is a complex task that often requires reasoning over both structural and semantic elements of audio. We introduce BASS, designed to evaluate music understanding and reasoning in audio language models across four broad categories: structural segmentation, lyric transcription, musicological analysis, and artist collaboration. BASS comprises 2658 questions spanning 12 tasks, 1993 unique songs and covering over 138 hours of music from a wide range of genres and tracks, crafted to assess musicological knowledge and reasoning in real-world scenarios. We evaluate 14 open-source and frontier multimodal LMs, finding that even state-of-the-art models struggle on higher-level reasoning tasks such as structural segmentation and artist collaboration, while performing best on lyric transcription. Our analysis reveals that current models leverage linguistic priors effectively but remain limited in reasoning over musical structure, vocal, and musicological attributes. BASS provides an evaluation framework with widespread applications in music recommendation and search and has the potential to guide the development of audio LMs.

</details>


### [34] [PFluxTTS: Hybrid Flow-Matching TTS with Robust Cross-Lingual Voice Cloning and Inference-Time Model Fusion](https://arxiv.org/abs/2602.04160)
*Vikentii Pankov,Artem Gribul,Oktai Tatanov,Vladislav Proskurov,Yuliya Korotkova,Darima Mylzenova,Dmitrii Vypirailenko*

Main category: cs.SD

TL;DR: PFluxTTS是一个混合文本转语音系统，通过双解码器设计、鲁棒的跨语言语音克隆和高质量声码器，解决了流匹配TTS在稳定性-自然度权衡、跨语言语音克隆和音频质量方面的三个关键问题。


<details>
  <summary>Details</summary>
Motivation: 解决流匹配TTS中的三个关键问题：1) 稳定性与自然度的权衡问题；2) 跨语言语音克隆能力弱；3) 低速率梅尔特征导致的音频质量受限。

Method: 1) 双解码器设计：结合时长引导模型和对齐自由模型，通过推理时向量场融合；2) 鲁棒克隆：在FLUX-based解码器中使用语音提示嵌入序列，无需提示文本即可跨语言保持说话人特征；3) 改进的PeriodWave声码器：支持48kHz超分辨率。

Result: 在跨语言野外数据上，PFluxTTS明显优于F5-TTS、FishSpeech和SparkTTS，在自然度上与ChatterBox相当（MOS 4.11），同时WER降低23%（6.9% vs. 9.0%），在说话人相似度上超过ElevenLabs（+0.32 SMOS）。系统在大多数开源模型失败的挑战性场景中保持鲁棒性。

Conclusion: PFluxTTS通过创新的混合架构解决了流匹配TTS的关键限制，实现了高质量的跨语言语音合成，仅需短参考音频且无需额外训练，在自然度、准确性和说话人相似度方面均表现出色。

Abstract: We present PFluxTTS, a hybrid text-to-speech system addressing three gaps in flow-matching TTS: the stability-naturalness trade-off, weak cross-lingual voice cloning, and limited audio quality from low-rate mel features. Our contributions are: (1) a dual-decoder design combining duration-guided and alignment-free models through inference-time vector-field fusion; (2) robust cloning using a sequence of speech-prompt embeddings in a FLUX-based decoder, preserving speaker traits across languages without prompt transcripts; and (3) a modified PeriodWave vocoder with super-resolution to 48 kHz. On cross-lingual in-the-wild data, PFluxTTS clearly outperforms F5-TTS, FishSpeech, and SparkTTS, matches ChatterBox in naturalness (MOS 4.11) while achieving 23% lower WER (6.9% vs. 9.0%), and surpasses ElevenLabs in speaker similarity (+0.32 SMOS). The system remains robust in challenging scenarios where most open-source models fail, while requiring only short reference audio and no extra training. Audio demos are available at https://braskai.github.io/pfluxtts/

</details>


### [35] [HoliAntiSpoof: Audio LLM for Holistic Speech Anti-Spoofing](https://arxiv.org/abs/2602.04535)
*Xuenan Xu,Yiming Ren,Liwei Liu,Wen Wu,Baoxiang Li,Chaochao Lu,Shuai Wang,Chao Zhang*

Main category: cs.SD

TL;DR: HoliAntiSpoof：首个用于整体语音反欺骗分析的音频大语言模型框架，将欺骗分析重新定义为统一的文本生成任务，能够联合推理欺骗方法、受影响的语音属性及其语义影响。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多将语音欺骗视为二元分类问题，忽略了多样化的欺骗技术会操纵多个耦合的语音属性及其语义效果。需要更全面的分析方法来理解欺骗行为的语义影响。

Method: 提出HoliAntiSpoof框架，将欺骗分析重新定义为统一的文本生成任务。引入DailyTalkEdit新基准，模拟真实对话操纵并提供语义影响标注。支持联合推理欺骗方法、受影响的语音属性和语义影响。

Result: HoliAntiSpoof在多种设置下优于传统基线方法。初步结果显示上下文学习进一步提高了域外泛化能力。模型不仅提升了欺骗检测性能，还能对欺骗行为及其语义效果进行可解释分析。

Conclusion: 音频大语言模型不仅能提升语音欺骗检测性能，还能实现对欺骗行为及其语义效果的可解释分析，为更可信、可解释的语音安全指明了方向。数据和代码已公开。

Abstract: Recent advances in speech synthesis and editing have made speech spoofing increasingly challenging. However, most existing methods treat spoofing as binary classification, overlooking that diverse spoofing techniques manipulate multiple, coupled speech attributes and their semantic effects. In this paper, we introduce HoliAntiSpoof, the first audio large language model (ALLM) framework for holistic speech anti-spoofing analysis. HoliAntiSpoof reformulates spoofing analysis as a unified text generation task, enabling joint reasoning over spoofing methods, affected speech attributes, and their semantic impacts. To support semantic-level analysis, we introduce DailyTalkEdit, a new anti-spoofing benchmark that simulates realistic conversational manipulations and provides annotations of semantic influence. Extensive experiments demonstrate that HoliAntiSpoof outperforms conventional baselines across multiple settings, while preliminary results show that in-context learning further improves out-of-domain generalization. These findings indicate that ALLMs not only enhance speech spoofing detection performance but also enable interpretable analysis of spoofing behaviors and their semantic effects, pointing towards more trustworthy and explainable speech security. Data and code are publicly available.

</details>


### [36] [Audio ControlNet for Fine-Grained Audio Generation and Editing](https://arxiv.org/abs/2602.04680)
*Haina Zhu,Yao Xiao,Xiquan Li,Ziyang Ma,Jianwei Yu,Bowen Zhang,Mingqi Yang,Xie Chen*

Main category: cs.SD

TL;DR: 提出T2A-Adapter方法，通过仅增加3800万参数实现文本到音频生成中的精确控制（响度、音高、事件），并在AudioSet-Strong上达到SOTA性能，同时扩展至音频编辑任务。


<details>
  <summary>Details</summary>
Motivation: 现有文本到音频生成模型虽然能合成高质量音频，但缺乏对响度、音高和声音事件等属性的精确控制。传统方法需要为每种控制类型重新训练模型，效率低下。

Method: 在预训练的T2A骨干模型上训练ControlNet模型，提出T2A-ControlNet和T2A-Adapter两种设计。T2A-Adapter采用更高效的结构，仅增加3800万参数即可实现强控制能力。

Result: T2A-Adapter在AudioSet-Strong数据集上，在事件级别和片段级别的F1分数均达到最先进水平。进一步扩展框架提出T2A-Editor，实现基于指令的音频事件移除和插入编辑。

Conclusion: 提出的T2A-Adapter方法通过轻量级适配器实现了文本到音频生成的精确控制，为可控音频生成和编辑提供了高效解决方案，相关资源将开源以支持未来研究。

Abstract: We study the fine-grained text-to-audio (T2A) generation task. While recent models can synthesize high-quality audio from text descriptions, they often lack precise control over attributes such as loudness, pitch, and sound events. Unlike prior approaches that retrain models for specific control types, we propose to train ControlNet models on top of pre-trained T2A backbones to achieve controllable generation over loudness, pitch, and event roll. We introduce two designs, T2A-ControlNet and T2A-Adapter, and show that the T2A-Adapter model offers a more efficient structure with strong control ability. With only 38M additional parameters, T2A-Adapter achieves state-of-the-art performance on the AudioSet-Strong in both event-level and segment-level F1 scores. We further extend this framework to audio editing, proposing T2A-Editor for removing and inserting audio events at time locations specified by instructions. Models, code, dataset pipelines, and benchmarks will be released to support future research on controllable audio generation and editing.

</details>


### [37] [UniAudio 2.0: A Unified Audio Language Model with Text-Aligned Factorized Audio Tokenization](https://arxiv.org/abs/2602.04683)
*Dongchao Yang,Yuanyuan Wang,Dading Chong,Songxiang Liu,Xixin Wu,Helen Meng*

Main category: cs.SD

TL;DR: 提出ReasoningCodec音频分词器和UniAudio 2.0统一音频语言模型，解决音频理解与生成的统一表示问题，在多种音频任务上实现强大的少样本和零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决音频语言模型的两个基础问题：1) 设计既能用于理解又能用于生成的音频分词器；2) 构建类似大语言模型的音频基础模型，实现少样本和零样本泛化。

Method: 提出ReasoningCodec离散音频编解码器，将音频分解为推理token（文本对齐的高层分析规划）和重建token（语义丰富的声学线索）。采用统一自回归架构，多阶段训练和多任务数据构建，在100B文本token和60B音频token上训练UniAudio 2.0。

Result: ReasoningCodec在理解性能上与强连续表示相当，同时提高了生成质量和重建保真度。UniAudio 2.0在语音、声音和音乐任务上表现优异，在领域内评估中具有竞争力，并在未见任务上展现出强大的少样本和零样本泛化能力。

Conclusion: 通过ReasoningCodec和UniAudio 2.0的统一框架，成功解决了音频理解与生成的统一表示问题，为实现类似大语言模型的音频基础模型提供了有效途径，在多种音频任务上展现出强大的泛化能力。

Abstract: We study two foundational problems in audio language models: (1) how to design an audio tokenizer that can serve as an intermediate representation for both understanding and generation; and (2) how to build an audio foundation model that generalizes in few-shot and zero-shot settings, analogous to large language models. To this end, we make the following two contributions. First, we propose ReasoningCodec, a discrete audio codec that factorizes audio into (i) reasoning tokens, which encode text-aligned, high-level analysis and planning representations for audio understanding and hierarchical generation, and (ii) reconstruction tokens, which encode semantic-rich acoustic cues for high-fidelity waveform reconstruction. This design achieves understanding performance comparable to strong continuous representations while improving generation quality and reconstruction fidelity over prior discrete tokenizers. Second, we introduce a unified autoregressive architecture for text and audio, together with multi-stage training and multi-task data construction. Using this framework, we train UniAudio 2.0 on 100B text tokens and 60B audio tokens. Across a wide range of speech, sound, and music tasks, UniAudio 2.0 performs competitively on in-domain evaluations and demonstrates strong few-shot and zero-shot generalization to unseen tasks. Demo, code, and checkpoints will be available at \href{https://dongchaoyang.top/UniAudio2Demo/}{https://dongchaoyang.top/UniAudio2Demo/}.

</details>


### [38] [Fine-Grained Frame Modeling in Multi-head Self-Attention for Speech Deepfake Detection](https://arxiv.org/abs/2602.04702)
*Tuan Dat Phuong,Duc-Tuan Truong,Long-Vu Hoang,Trang Nguyen Thi Thu*

Main category: cs.SD

TL;DR: 提出FGFM方法，通过多头投票选择信息量最大的帧，再通过跨层精炼增强模型学习细微伪造线索的能力，在多个数据集上优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 基于Transformer的模型在语音深度伪造检测中表现出色，主要得益于多头自注意力机制。MHSA提供帧级注意力分数，这对于检测语音时间维度上小范围局部区域的伪造痕迹特别有价值，因此细粒度帧建模对于准确检测细微伪造线索至关重要。

Method: 提出细粒度帧建模方法，包含两个核心模块：1）多头投票模块：选择信息量最大的帧；2）跨层精炼模块：精炼所选帧以增强模型学习细微伪造线索的能力。

Result: 在LA21、DF21和ITW数据集上分别达到0.90%、1.88%和6.64%的等错误率，优于基线模型，在多个基准测试中表现一致改进。

Conclusion: 提出的细粒度建模方法在语音深度伪造检测中表现出有效性，通过选择信息量最大的帧并进行精炼，能够更好地学习细微伪造线索，实现鲁棒的检测性能。

Abstract: Transformer-based models have shown strong performance in speech deepfake detection, largely due to the effectiveness of the multi-head self-attention (MHSA) mechanism. MHSA provides frame-level attention scores, which are particularly valuable because deepfake artifacts often occur in small, localized regions along the temporal dimension of speech. This makes fine-grained frame modeling essential for accurately detecting subtle spoofing cues. In this work, we propose fine-grained frame modeling (FGFM) for MHSA-based speech deepfake detection, where the most informative frames are first selected through a multi-head voting (MHV) module. These selected frames are then refined via a cross-layer refinement (CLR) module to enhance the model's ability to learn subtle spoofing cues. Experimental results demonstrate that our method outperforms the baseline model and achieves Equal Error Rate (EER) of 0.90%, 1.88%, and 6.64% on the LA21, DF21, and ITW datasets, respectively. These consistent improvements across multiple benchmarks highlight the effectiveness of our fine-grained modeling for robust speech deepfake detection.

</details>

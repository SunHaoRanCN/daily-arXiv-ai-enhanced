{"id": "2602.05027", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05027", "abs": "https://arxiv.org/abs/2602.05027", "authors": ["Georgii Aparin", "Tasnima Sadekova", "Alexey Rukhovich", "Assel Yermekova", "Laida Kushnareva", "Vadim Popov", "Kristian Kuznetsov", "Irina Piontkovskaya"], "title": "AudioSAE: Towards Understanding of Audio-Processing Models with Sparse AutoEncoders", "comment": null, "summary": "Sparse Autoencoders (SAEs) are powerful tools for interpreting neural representations, yet their use in audio remains underexplored. We train SAEs across all encoder layers of Whisper and HuBERT, provide an extensive evaluation of their stability, interpretability, and show their practical utility. Over 50% of the features remain consistent across random seeds, and reconstruction quality is preserved. SAE features capture general acoustic and semantic information as well as specific events, including environmental noises and paralinguistic sounds (e.g. laughter, whispering) and disentangle them effectively, requiring removal of only 19-27% of features to erase a concept. Feature steering reduces Whisper's false speech detections by 70% with negligible WER increase, demonstrating real-world applicability. Finally, we find SAE features correlated with human EEG activity during speech perception, indicating alignment with human neural processing. The code and checkpoints are available at https://github.com/audiosae/audiosae_demo.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5728\u97f3\u9891\u9886\u57df\u5e94\u7528\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff08SAEs\uff09\uff0c\u5728Whisper\u548cHuBERT\u6a21\u578b\u4e0a\u8fdb\u884c\u8bad\u7ec3\uff0c\u8bc4\u4f30\u5176\u7a33\u5b9a\u6027\u3001\u53ef\u89e3\u91ca\u6027\u548c\u5b9e\u7528\u6027\uff0c\u53d1\u73b0SAE\u7279\u5f81\u80fd\u6709\u6548\u6355\u6349\u97f3\u9891\u4fe1\u606f\u5e76\u4e0e\u4eba\u7c7b\u795e\u7ecf\u5904\u7406\u5bf9\u9f50\u3002", "motivation": "\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5728\u795e\u7ecf\u8868\u793a\u89e3\u91ca\u4e2d\u662f\u5f3a\u5927\u5de5\u5177\uff0c\u4f46\u5728\u97f3\u9891\u9886\u57df\u7684\u5e94\u7528\u5c1a\u672a\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u8bc4\u4f30\u5176\u5728\u97f3\u9891\u6a21\u578b\u4e2d\u7684\u6548\u679c\u548c\u5b9e\u7528\u6027\u3002", "method": "\u5728Whisper\u548cHuBERT\u7684\u6240\u6709\u7f16\u7801\u5668\u5c42\u4e0a\u8bad\u7ec3\u7a00\u758f\u81ea\u7f16\u7801\u5668\uff0c\u8fdb\u884c\u7a33\u5b9a\u6027\u3001\u53ef\u89e3\u91ca\u6027\u8bc4\u4f30\uff0c\u5e76\u6d4b\u8bd5\u7279\u5f81\u64cd\u63a7\u7684\u5b9e\u9645\u5e94\u7528\u6548\u679c\u3002", "result": "\u8d85\u8fc750%\u7684\u7279\u5f81\u5728\u4e0d\u540c\u968f\u673a\u79cd\u5b50\u4e0b\u4fdd\u6301\u7a33\u5b9a\uff1bSAE\u7279\u5f81\u80fd\u6355\u6349\u4e00\u822c\u58f0\u5b66\u548c\u8bed\u4e49\u4fe1\u606f\u4ee5\u53ca\u7279\u5b9a\u4e8b\u4ef6\uff1b\u7279\u5f81\u64cd\u63a7\u53ef\u5c06Whisper\u7684\u865a\u5047\u8bed\u97f3\u68c0\u6d4b\u51cf\u5c1170%\uff1bSAE\u7279\u5f81\u4e0e\u4eba\u7c7b\u8111\u7535\u56fe\u6d3b\u52a8\u76f8\u5173\u3002", "conclusion": "\u7a00\u758f\u81ea\u7f16\u7801\u5668\u5728\u97f3\u9891\u9886\u57df\u5177\u6709\u826f\u597d\u6548\u679c\uff0c\u80fd\u7a33\u5b9a\u6355\u6349\u97f3\u9891\u7279\u5f81\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\uff0c\u4e14\u4e0e\u4eba\u7c7b\u795e\u7ecf\u5904\u7406\u673a\u5236\u5b58\u5728\u5bf9\u9f50\uff0c\u4e3a\u97f3\u9891\u6a21\u578b\u89e3\u91ca\u63d0\u4f9b\u4e86\u6709\u6548\u5de5\u5177\u3002"}}
{"id": "2602.05373", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2602.05373", "abs": "https://arxiv.org/abs/2602.05373", "authors": ["Haoqin Sun", "Chenyang Lyu", "Shiwan Zhao", "Xuanfan Ni", "Xiangyu Kong", "Longyue Wang", "Weihua Luo", "Yong Qin"], "title": "Speech-XL: Towards Long-Form Speech Understanding in Large Speech Language Models", "comment": null, "summary": "Despite the growing success of Large Speech Language Models (LSLMs) in processing short-term acoustic signals, their extension to long-form audio understanding is severely bottlenecked. This limitation stems from the limited context length and the exorbitant memory footprints required for long-form inference. In this work, we propose Speech-XL, a new model that capitalizes on the intrinsic key-value (KV) sparsification capacity of Large Language Models (LLMs) to achieve high-ratio speech input compression. Specifically, we introduce a novel special token, the Speech Summarization Token (SST), for each speech interval to encapsulate the intra-interval speech information into its associated KV pairs. The SST module is trained via instruction fine-tuning, employing a curriculum learning strategy where the SST learns to compress information in a progressive manner--advancing from low-ratio (simple) to high-ratio (challenging) compression. Despite utilizing significantly less training data than other baselines, our model achieves highly competitive performance on major benchmarks, including LongSpeech and AUDIOMARATHON. By addressing the long-standing bottlenecks in long-form audio modeling, our approach offers a novel perspective on the condensation of extensive acoustic sequences.", "AI": {"tldr": "Speech-XL\uff1a\u5229\u7528\u5927\u578b\u8bed\u8a00\u6a21\u578b\u7684KV\u7a00\u758f\u5316\u80fd\u529b\uff0c\u901a\u8fc7Speech Summarization Token\u5bf9\u957f\u97f3\u9891\u8fdb\u884c\u9ad8\u6bd4\u4f8b\u538b\u7f29\uff0c\u89e3\u51b3\u957f\u97f3\u9891\u7406\u89e3\u4e2d\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u548c\u5185\u5b58\u9650\u5236\u95ee\u9898", "motivation": "\u5927\u578b\u8bed\u97f3\u8bed\u8a00\u6a21\u578b\u5728\u5904\u7406\u77ed\u65f6\u97f3\u9891\u4fe1\u53f7\u65b9\u9762\u53d6\u5f97\u4e86\u6210\u529f\uff0c\u4f46\u5728\u957f\u97f3\u9891\u7406\u89e3\u65b9\u9762\u53d7\u5230\u4e25\u91cd\u9650\u5236\u3002\u4e3b\u8981\u74f6\u9888\u5305\u62ec\u6709\u9650\u7684\u4e0a\u4e0b\u6587\u957f\u5ea6\u548c\u957f\u97f3\u9891\u63a8\u7406\u6240\u9700\u7684\u9ad8\u6602\u5185\u5b58\u5360\u7528\u3002", "method": "\u63d0\u51faSpeech-XL\u6a21\u578b\uff0c\u5229\u7528LLM\u56fa\u6709\u7684\u952e\u503c\u5bf9\u7a00\u758f\u5316\u80fd\u529b\u5b9e\u73b0\u9ad8\u6bd4\u4f8b\u8bed\u97f3\u8f93\u5165\u538b\u7f29\u3002\u5f15\u5165Speech Summarization Token\uff08SST\uff09\u7279\u6b8a\u4ee4\u724c\uff0c\u5c06\u6bcf\u4e2a\u8bed\u97f3\u533a\u95f4\u5185\u7684\u4fe1\u606f\u5c01\u88c5\u5230\u5176\u5173\u8054\u7684KV\u5bf9\u4e2d\u3002\u901a\u8fc7\u6307\u4ee4\u5fae\u8c03\u8bad\u7ec3SST\u6a21\u5757\uff0c\u91c7\u7528\u8bfe\u7a0b\u5b66\u4e60\u7b56\u7565\uff0c\u4ece\u4f4e\u6bd4\u4f8b\uff08\u7b80\u5355\uff09\u5230\u9ad8\u6bd4\u4f8b\uff08\u6311\u6218\u6027\uff09\u538b\u7f29\u9010\u6b65\u5b66\u4e60\u4fe1\u606f\u538b\u7f29\u3002", "result": "\u5c3d\u7ba1\u4f7f\u7528\u7684\u8bad\u7ec3\u6570\u636e\u663e\u8457\u5c11\u4e8e\u5176\u4ed6\u57fa\u7ebf\u6a21\u578b\uff0c\u4f46\u5728LongSpeech\u548cAUDIOMARATHON\u7b49\u4e3b\u8981\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u53d6\u5f97\u4e86\u6781\u5177\u7ade\u4e89\u529b\u7684\u6027\u80fd\u8868\u73b0\u3002", "conclusion": "\u901a\u8fc7\u89e3\u51b3\u957f\u97f3\u9891\u5efa\u6a21\u4e2d\u957f\u671f\u5b58\u5728\u7684\u74f6\u9888\u95ee\u9898\uff0c\u8be5\u65b9\u6cd5\u4e3a\u5e7f\u6cdb\u58f0\u5b66\u5e8f\u5217\u7684\u538b\u7f29\u63d0\u4f9b\u4e86\u65b0\u7684\u89c6\u89d2\uff0c\u6210\u529f\u5b9e\u73b0\u4e86\u957f\u97f3\u9891\u7684\u9ad8\u6548\u7406\u89e3\u548c\u5904\u7406\u3002"}}
{"id": "2602.05406", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05406", "abs": "https://arxiv.org/abs/2602.05406", "authors": ["Isaac Wiafe", "Akon Obu Ekpezu", "Sumaya Ahmed Salihs", "Elikem Doe Atsakpo", "Fiifi Baffoe Payin Winful", "Jamal-Deen Abdulai"], "title": "Enabling Automatic Disordered Speech Recognition: An Impaired Speech Dataset in the Akan Language", "comment": null, "summary": "The lack of impaired speech data hinders advancements in the development of inclusive speech technologies, particularly in low-resource languages such as Akan. To address this gap, this study presents a curated corpus of speech samples from native Akan speakers with speech impairment. The dataset comprises of 50.01 hours of audio recordings cutting across four classes of impaired speech namely stammering, cerebral palsy, cleft palate, and stroke induced speech disorder. Recordings were done in controlled supervised environments were participants described pre-selected images in their own words. The resulting dataset is a collection of audio recordings, transcriptions, and associated metadata on speaker demographics, class of impairment, recording environment and device. The dataset is intended to support research in low-resource automatic disordered speech recognition systems and assistive speech technology.", "AI": {"tldr": "\u6784\u5efa\u4e86\u4e00\u4e2a\u5305\u542b50.01\u5c0f\u65f6\u97f3\u9891\u7684Akan\u8bed\u8a00\u969c\u788d\u8bed\u97f3\u8bed\u6599\u5e93\uff0c\u6db5\u76d6\u53e3\u5403\u3001\u8111\u762b\u3001\u816d\u88c2\u548c\u4e2d\u98ce\u540e\u8a00\u8bed\u969c\u788d\u56db\u7c7b\uff0c\u7528\u4e8e\u652f\u6301\u4f4e\u8d44\u6e90\u8bed\u8a00\u969c\u788d\u8bed\u97f3\u8bc6\u522b\u7814\u7a76\u3002", "motivation": "\u7f3a\u4e4f\u969c\u788d\u8bed\u97f3\u6570\u636e\u963b\u788d\u4e86\u5305\u5bb9\u6027\u8bed\u97f3\u6280\u672f\u7684\u53d1\u5c55\uff0c\u7279\u522b\u662f\u5728Akan\u7b49\u4f4e\u8d44\u6e90\u8bed\u8a00\u4e2d\u3002\u73b0\u6709\u6570\u636e\u96c6\u4e0d\u8db3\u9650\u5236\u4e86\u969c\u788d\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u548c\u8f85\u52a9\u8bed\u97f3\u6280\u672f\u7684\u8fdb\u6b65\u3002", "method": "\u6536\u96c6\u4e86\u6bcd\u8bed\u4e3aAkan\u7684\u969c\u788d\u4eba\u58eb\u7684\u8bed\u97f3\u6837\u672c\uff0c\u5728\u53d7\u63a7\u76d1\u7763\u73af\u5883\u4e0b\u5f55\u5236\uff0c\u53c2\u4e0e\u8005\u7528\u81ea\u5df1\u8bed\u8a00\u63cf\u8ff0\u9884\u9009\u56fe\u7247\u3002\u6570\u636e\u96c6\u5305\u542b50.01\u5c0f\u65f6\u97f3\u9891\uff0c\u6db5\u76d6\u56db\u7c7b\u969c\u788d\u8bed\u97f3\uff1a\u53e3\u5403\u3001\u8111\u762b\u3001\u816d\u88c2\u548c\u4e2d\u98ce\u540e\u8a00\u8bed\u969c\u788d\u3002", "result": "\u521b\u5efa\u4e86\u4e00\u4e2a\u5305\u542b\u97f3\u9891\u5f55\u97f3\u3001\u8f6c\u5f55\u6587\u672c\u548c\u76f8\u5173\u5143\u6570\u636e\uff08\u8bf4\u8bdd\u8005\u4eba\u53e3\u7edf\u8ba1\u3001\u969c\u788d\u7c7b\u522b\u3001\u5f55\u97f3\u73af\u5883\u548c\u8bbe\u5907\uff09\u7684\u6570\u636e\u96c6\uff0c\u603b\u65f6\u957f50.01\u5c0f\u65f6\u3002", "conclusion": "\u8be5\u6570\u636e\u96c6\u586b\u8865\u4e86Akan\u8bed\u8a00\u969c\u788d\u8bed\u97f3\u6570\u636e\u7684\u7a7a\u767d\uff0c\u65e8\u5728\u652f\u6301\u4f4e\u8d44\u6e90\u81ea\u52a8\u969c\u788d\u8bed\u97f3\u8bc6\u522b\u7cfb\u7edf\u548c\u8f85\u52a9\u8bed\u97f3\u6280\u672f\u7684\u7814\u7a76\u4e0e\u53d1\u5c55\u3002"}}
{"id": "2602.05670", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.05670", "abs": "https://arxiv.org/abs/2602.05670", "authors": ["Qing Wen", "Haohao Li", "Zhongjie Ba", "Peng Cheng", "Miao He", "Li Lu", "Kui Ren"], "title": "HyperPotter: Spell the Charm of High-Order Interactions in Audio Deepfake Detection", "comment": "20 pages, 8 figures", "summary": "Advances in AIGC technologies have enabled the synthesis of highly realistic audio deepfakes capable of deceiving human auditory perception. Although numerous audio deepfake detection (ADD) methods have been developed, most rely on local temporal/spectral features or pairwise relations, overlooking high-order interactions (HOIs). HOIs capture discriminative patterns that emerge from multiple feature components beyond their individual contributions. We propose HyperPotter, a hypergraph-based framework that explicitly models these synergistic HOIs through clustering-based hyperedges with class-aware prototype initialization. Extensive experiments demonstrate that HyperPotter surpasses its baseline by an average relative gain of 22.15% across 11 datasets and outperforms state-of-the-art methods by 13.96% on 4 challenging cross-domain datasets, demonstrating superior generalization to diverse attacks and speakers.", "AI": {"tldr": "\u63d0\u51faHyperPotter\u6846\u67b6\uff0c\u901a\u8fc7\u8d85\u56fe\u5efa\u6a21\u9ad8\u9636\u4ea4\u4e92\u6765\u63d0\u5347\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u6027\u80fd", "motivation": "\u73b0\u6709\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u65b9\u6cd5\u5927\u591a\u4f9d\u8d56\u5c40\u90e8\u65f6\u9891\u7279\u5f81\u6216\u6210\u5bf9\u5173\u7cfb\uff0c\u5ffd\u7565\u4e86\u9ad8\u9636\u4ea4\u4e92\uff0c\u800c\u9ad8\u9636\u4ea4\u4e92\u80fd\u6355\u6349\u591a\u4e2a\u7279\u5f81\u7ec4\u4ef6\u534f\u540c\u4ea7\u751f\u7684\u5224\u522b\u6027\u6a21\u5f0f", "method": "\u63d0\u51fa\u57fa\u4e8e\u8d85\u56fe\u7684HyperPotter\u6846\u67b6\uff0c\u901a\u8fc7\u805a\u7c7b\u6784\u5efa\u8d85\u8fb9\uff0c\u5e76\u91c7\u7528\u7c7b\u611f\u77e5\u539f\u578b\u521d\u59cb\u5316\u6765\u663e\u5f0f\u5efa\u6a21\u9ad8\u9636\u4ea4\u4e92", "result": "\u572811\u4e2a\u6570\u636e\u96c6\u4e0a\u76f8\u6bd4\u57fa\u7ebf\u5e73\u5747\u76f8\u5bf9\u63d0\u534722.15%\uff0c\u57284\u4e2a\u8de8\u57df\u6570\u636e\u96c6\u4e0a\u8d85\u8d8aSOTA\u65b9\u6cd513.96%\uff0c\u5c55\u73b0\u51fa\u5bf9\u591a\u6837\u5316\u653b\u51fb\u548c\u8bf4\u8bdd\u8005\u7684\u4f18\u8d8a\u6cdb\u5316\u80fd\u529b", "conclusion": "\u663e\u5f0f\u5efa\u6a21\u9ad8\u9636\u4ea4\u4e92\u80fd\u663e\u8457\u63d0\u5347\u97f3\u9891\u6df1\u5ea6\u4f2a\u9020\u68c0\u6d4b\u6027\u80fd\uff0c\u7279\u522b\u662f\u5728\u8de8\u57df\u573a\u666f\u4e0b\u5177\u6709\u4f18\u8d8a\u7684\u6cdb\u5316\u80fd\u529b"}}
{"id": "2602.05207", "categories": ["eess.AS", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.05207", "abs": "https://arxiv.org/abs/2602.05207", "authors": ["Chunyat Wu", "Jiajun Deng", "Zhengxi Liu", "Zheqi Dai", "Haolin He", "Qiuqiang Kong"], "title": "ARCHI-TTS: A flow-matching-based Text-to-Speech Model with Self-supervised Semantic Aligner and Accelerated Inference", "comment": "Accepted by ICASSP 2026", "summary": "Although diffusion-based, non-autoregressive text-to-speech (TTS) systems have demonstrated impressive zero-shot synthesis capabilities, their efficacy is still hindered by two key challenges: the difficulty of text-speech alignment modeling and the high computational overhead of the iterative denoising process. To address these limitations, we propose ARCHI-TTS that features a dedicated semantic aligner to ensure robust temporal and semantic consistency between text and audio. To overcome high computational inference costs, ARCHI-TTS employs an efficient inference strategy that reuses encoder features across denoising steps, drastically accelerating synthesis without performance degradation. An auxiliary CTC loss applied to the condition encoder further enhances the semantic understanding. Experimental results demonstrate that ARCHI-TTS achieves a WER of 1.98% on LibriSpeech-PC test-clean, and 1.47%/1.42% on SeedTTS test-en/test-zh with a high inference efficiency, consistently outperforming recent state-of-the-art TTS systems.", "AI": {"tldr": "ARCHI-TTS\uff1a\u4e00\u79cd\u9ad8\u6548\u7684\u6269\u6563\u5f0f\u975e\u81ea\u56de\u5f52TTS\u7cfb\u7edf\uff0c\u901a\u8fc7\u4e13\u7528\u8bed\u4e49\u5bf9\u9f50\u5668\u548c\u7279\u5f81\u590d\u7528\u7b56\u7565\u89e3\u51b3\u6587\u672c-\u8bed\u97f3\u5bf9\u9f50\u548c\u8ba1\u7b97\u5f00\u9500\u95ee\u9898", "motivation": "\u5f53\u524d\u57fa\u4e8e\u6269\u6563\u7684\u975e\u81ea\u56de\u5f52TTS\u7cfb\u7edf\u9762\u4e34\u4e24\u4e2a\u4e3b\u8981\u6311\u6218\uff1a\u6587\u672c-\u8bed\u97f3\u5bf9\u9f50\u5efa\u6a21\u56f0\u96be\uff0c\u4ee5\u53ca\u8fed\u4ee3\u53bb\u566a\u8fc7\u7a0b\u8ba1\u7b97\u5f00\u9500\u5927\u3002\u8fd9\u4e9b\u9650\u5236\u5f71\u54cd\u4e86\u7cfb\u7edf\u7684\u5b9e\u7528\u6027\u548c\u6548\u7387\u3002", "method": "1. \u5f15\u5165\u4e13\u7528\u8bed\u4e49\u5bf9\u9f50\u5668\u786e\u4fdd\u6587\u672c\u548c\u97f3\u9891\u7684\u65f6\u5e8f\u4e0e\u8bed\u4e49\u4e00\u81f4\u6027\uff1b2. \u91c7\u7528\u9ad8\u6548\u63a8\u7406\u7b56\u7565\uff0c\u5728\u53bb\u566a\u6b65\u9aa4\u95f4\u590d\u7528\u7f16\u7801\u5668\u7279\u5f81\uff0c\u5927\u5e45\u52a0\u901f\u5408\u6210\uff1b3. \u5728\u6761\u4ef6\u7f16\u7801\u5668\u4e0a\u5e94\u7528\u8f85\u52a9CTC\u635f\u5931\u589e\u5f3a\u8bed\u4e49\u7406\u89e3\u3002", "result": "\u5728LibriSpeech-PC test-clean\u4e0aWER\u8fbe\u52301.98%\uff0c\u5728SeedTTS test-en/test-zh\u4e0a\u5206\u522b\u8fbe\u52301.47%/1.42%\uff0c\u63a8\u7406\u6548\u7387\u9ad8\uff0c\u4e00\u81f4\u4f18\u4e8e\u8fd1\u671f\u6700\u5148\u8fdb\u7684TTS\u7cfb\u7edf\u3002", "conclusion": "ARCHI-TTS\u901a\u8fc7\u521b\u65b0\u7684\u8bed\u4e49\u5bf9\u9f50\u673a\u5236\u548c\u9ad8\u6548\u63a8\u7406\u7b56\u7565\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u6269\u6563\u5f0fTTS\u7cfb\u7edf\u7684\u5bf9\u9f50\u95ee\u9898\u548c\u8ba1\u7b97\u5f00\u9500\uff0c\u5728\u4fdd\u6301\u9ad8\u8d28\u91cf\u5408\u6210\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u4e86\u6548\u7387\u3002"}}
{"id": "2602.05034", "categories": ["eess.SP", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.05034", "abs": "https://arxiv.org/abs/2602.05034", "authors": ["Fatih Ayten", "Musa Furkan Keskin", "Akshay Jain", "Mehmet C. Ilter", "Ossi Kaltiokallio", "Jukka Talvitie", "Elena Simona Lohan", "Mikko Valkama"], "title": "Phase-Only Positioning in Distributed MIMO Under Phase Impairments: AP Selection Using Deep Learning", "comment": null, "summary": "Carrier phase positioning (CPP) can enable cm-level accuracy in next-generation wireless systems, while recent literature shows that accuracy remains high using phase-only measurements in distributed MIMO (D-MIMO). However, the impact of phase synchronization errors on such systems remains insufficiently explored. To address this gap, we first show that the proposed hyperbola intersection method achieves highly accurate positioning even in the presence of phase synchronization errors, when trained on appropriate data reflecting such impairments. We then introduce a deep learning (DL)-based D-MIMO antenna point (AP) selection framework that ensures high-precision localization under phase synchronization errors. Simulation results show that the proposed framework improves positioning accuracy compared to prior-art methods, while reducing inference complexity by approximately 19.7%.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5929\u7ebf\u70b9\u9009\u62e9\u6846\u67b6\uff0c\u5728\u5b58\u5728\u76f8\u4f4d\u540c\u6b65\u8bef\u5dee\u7684\u5206\u5e03\u5f0fMIMO\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\uff0c\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u5347\u7cbe\u5ea6\u5e76\u964d\u4f4e\u7ea619.7%\u7684\u63a8\u7406\u590d\u6742\u5ea6\u3002", "motivation": "\u8f7d\u6ce2\u76f8\u4f4d\u5b9a\u4f4d\u80fd\u5728\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u5398\u7c73\u7ea7\u7cbe\u5ea6\uff0c\u73b0\u6709\u7814\u7a76\u8868\u660e\u5728\u5206\u5e03\u5f0fMIMO\u4e2d\u4f7f\u7528\u7eaf\u76f8\u4f4d\u6d4b\u91cf\u4ecd\u80fd\u4fdd\u6301\u9ad8\u7cbe\u5ea6\uff0c\u4f46\u76f8\u4f4d\u540c\u6b65\u8bef\u5dee\u5bf9\u8fd9\u7c7b\u7cfb\u7edf\u7684\u5f71\u54cd\u5c1a\u672a\u5145\u5206\u63a2\u7d22\u3002", "method": "\u9996\u5148\u63d0\u51fa\u53cc\u66f2\u7ebf\u4ea4\u70b9\u65b9\u6cd5\uff0c\u5728\u5b58\u5728\u76f8\u4f4d\u540c\u6b65\u8bef\u5dee\u65f6\u901a\u8fc7\u9002\u5f53\u8bad\u7ec3\u6570\u636e\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\uff1b\u7136\u540e\u5f15\u5165\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u5206\u5e03\u5f0fMIMO\u5929\u7ebf\u70b9\u9009\u62e9\u6846\u67b6\uff0c\u786e\u4fdd\u5728\u76f8\u4f4d\u540c\u6b65\u8bef\u5dee\u4e0b\u7684\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u663e\u793a\uff0c\u6240\u63d0\u6846\u67b6\u76f8\u6bd4\u73b0\u6709\u65b9\u6cd5\u63d0\u9ad8\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\uff0c\u540c\u65f6\u5c06\u63a8\u7406\u590d\u6742\u5ea6\u964d\u4f4e\u4e86\u7ea619.7%\u3002", "conclusion": "\u8be5\u7814\u7a76\u586b\u8865\u4e86\u76f8\u4f4d\u540c\u6b65\u8bef\u5dee\u5bf9\u5206\u5e03\u5f0fMIMO\u8f7d\u6ce2\u76f8\u4f4d\u5b9a\u4f4d\u7cfb\u7edf\u5f71\u54cd\u7684\u7a7a\u767d\uff0c\u63d0\u51fa\u7684\u6df1\u5ea6\u5b66\u4e60\u5929\u7ebf\u70b9\u9009\u62e9\u6846\u67b6\u80fd\u6709\u6548\u5e94\u5bf9\u76f8\u4f4d\u540c\u6b65\u8bef\u5dee\uff0c\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u5e76\u964d\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u3002"}}
{"id": "2602.05443", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.05443", "abs": "https://arxiv.org/abs/2602.05443", "authors": ["Hien Ohnaka", "Yuma Shirahata", "Masaya Kawamura"], "title": "Wave-Trainer-Fit: Neural Vocoder with Trainable Prior and Fixed-Point Iteration towards High-Quality Speech Generation from SSL features", "comment": "Accepted by IEEE ICASSP 2026. 5 pages, 3 figures, and 2 tables", "summary": "We propose WaveTrainerFit, a neural vocoder that performs high-quality waveform generation from data-driven features such as SSL features. WaveTrainerFit builds upon the WaveFit vocoder, which integrates diffusion model and generative adversarial network. Furthermore, the proposed method incorporates the following key improvements: 1. By introducing trainable priors, the inference process starts from noise close to the target speech instead of Gaussian noise. 2. Reference-aware gain adjustment is performed by imposing constraints on the trainable prior to matching the speech energy. These improvements are expected to reduce the complexity of waveform modeling from data-driven features, enabling high-quality waveform generation with fewer inference steps. Through experiments, we showed that WaveTrainerFit can generate highly natural waveforms with improved speaker similarity from data-driven features, while requiring fewer iterations than WaveFit. Moreover, we showed that the proposed method works robustly with respect to the depth at which SSL features are extracted. Code and pre-trained models are available from https://github.com/line/WaveTrainerFit.", "AI": {"tldr": "WaveTrainerFit\u662f\u57fa\u4e8eWaveFit\u7684\u795e\u7ecf\u58f0\u7801\u5668\uff0c\u901a\u8fc7\u5f15\u5165\u53ef\u8bad\u7ec3\u5148\u9a8c\u548c\u53c2\u8003\u611f\u77e5\u589e\u76ca\u8c03\u6574\uff0c\u4eceSSL\u7b49\u6570\u636e\u9a71\u52a8\u7279\u5f81\u751f\u6210\u9ad8\u8d28\u91cf\u6ce2\u5f62\uff0c\u51cf\u5c11\u63a8\u7406\u6b65\u9aa4", "motivation": "\u4ece\u6570\u636e\u9a71\u52a8\u7279\u5f81\uff08\u5982SSL\u7279\u5f81\uff09\u751f\u6210\u9ad8\u8d28\u91cf\u6ce2\u5f62\u5177\u6709\u6311\u6218\u6027\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u8f83\u591a\u63a8\u7406\u6b65\u9aa4\u4e14\u8d28\u91cf\u6709\u5f85\u63d0\u5347", "method": "\u57fa\u4e8eWaveFit\uff08\u6269\u6563\u6a21\u578b+GAN\uff09\uff0c\u5f15\u5165\u53ef\u8bad\u7ec3\u5148\u9a8c\u4f7f\u63a8\u7406\u4ece\u63a5\u8fd1\u76ee\u6807\u8bed\u97f3\u7684\u566a\u58f0\u5f00\u59cb\uff0c\u5e76\u901a\u8fc7\u53c2\u8003\u611f\u77e5\u589e\u76ca\u8c03\u6574\u7ea6\u675f\u5148\u9a8c\u5339\u914d\u8bed\u97f3\u80fd\u91cf", "result": "\u76f8\u6bd4WaveFit\uff0cWaveTrainerFit\u80fd\u7528\u66f4\u5c11\u8fed\u4ee3\u6b65\u9aa4\u751f\u6210\u66f4\u81ea\u7136\u3001\u8bf4\u8bdd\u4eba\u76f8\u4f3c\u5ea6\u66f4\u9ad8\u7684\u6ce2\u5f62\uff0c\u4e14\u5bf9SSL\u7279\u5f81\u63d0\u53d6\u6df1\u5ea6\u5177\u6709\u9c81\u68d2\u6027", "conclusion": "WaveTrainerFit\u901a\u8fc7\u53ef\u8bad\u7ec3\u5148\u9a8c\u548c\u80fd\u91cf\u5339\u914d\u7ea6\u675f\uff0c\u6709\u6548\u7b80\u5316\u4e86\u4ece\u6570\u636e\u9a71\u52a8\u7279\u5f81\u7684\u6ce2\u5f62\u5efa\u6a21\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8d28\u91cf\u3001\u9ad8\u6548\u7387\u7684\u8bed\u97f3\u751f\u6210"}}
{"id": "2602.05236", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2602.05236", "abs": "https://arxiv.org/abs/2602.05236", "authors": ["Juliano G. C. Ribeiro", "Ryo Matsuda", "Jorge Trevino"], "title": "Exterior sound field estimation based on physics-constrained kernel", "comment": "This paper has been accepted to the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP) 2026", "summary": "Exterior sound field interpolation is a challenging problem that often requires specific array configurations and prior knowledge on the source conditions. We propose an interpolation method based on Gaussian processes using a point source reproducing kernel with a trainable inner product formulation made to fit exterior sound fields. While this estimation does not have a closed formula, it allows for the definition of a flexible estimator that is not restricted by microphone distribution and attenuates higher harmonic orders automatically with parameters directly optimized from the recordings, meaning an arbitrary distribution of microphones can be used. The proposed kernel estimator is compared in simulated experiments to the conventional method using spherical wave functions and an established physics-informed machine learning model, achieving lower interpolation error by approximately 2 dB on average within the analyzed frequencies of 100 Hz and 2.5 kHz and reconstructing the ground truth sound field more consistently within the target region.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u7684\u5916\u58f0\u573a\u63d2\u503c\u65b9\u6cd5\uff0c\u4f7f\u7528\u53ef\u8bad\u7ec3\u5185\u79ef\u7684\u70b9\u6e90\u518d\u751f\u6838\uff0c\u65e0\u9700\u7279\u5b9a\u9ea6\u514b\u98ce\u9635\u5217\u914d\u7f6e\uff0c\u81ea\u52a8\u8870\u51cf\u9ad8\u6b21\u8c10\u6ce2\uff0c\u76f8\u6bd4\u4f20\u7edf\u65b9\u6cd5\u5e73\u5747\u964d\u4f4e2dB\u63d2\u503c\u8bef\u5dee\u3002", "motivation": "\u5916\u58f0\u573a\u63d2\u503c\u901a\u5e38\u9700\u8981\u7279\u5b9a\u9635\u5217\u914d\u7f6e\u548c\u6e90\u6761\u4ef6\u5148\u9a8c\u77e5\u8bc6\uff0c\u9650\u5236\u4e86\u65b9\u6cd5\u7684\u7075\u6d3b\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u57fa\u4e8e\u9ad8\u65af\u8fc7\u7a0b\u7684\u63d2\u503c\u65b9\u6cd5\uff0c\u4f7f\u7528\u70b9\u6e90\u518d\u751f\u6838\u548c\u53ef\u8bad\u7ec3\u5185\u79ef\u516c\u5f0f\uff0c\u53c2\u6570\u76f4\u63a5\u4ece\u5f55\u97f3\u4e2d\u4f18\u5316\uff0c\u4e0d\u4f9d\u8d56\u9ea6\u514b\u98ce\u5206\u5e03\uff0c\u81ea\u52a8\u8870\u51cf\u9ad8\u6b21\u8c10\u6ce2\u3002", "result": "\u5728100Hz-2.5kHz\u9891\u7387\u8303\u56f4\u5185\uff0c\u76f8\u6bd4\u4f20\u7edf\u7403\u9762\u6ce2\u51fd\u6570\u65b9\u6cd5\u548c\u5df2\u5efa\u7acb\u7684\u7269\u7406\u4fe1\u606f\u673a\u5668\u5b66\u4e60\u6a21\u578b\uff0c\u5e73\u5747\u964d\u4f4e\u7ea62dB\u63d2\u503c\u8bef\u5dee\uff0c\u5728\u76ee\u6807\u533a\u57df\u5185\u66f4\u4e00\u81f4\u5730\u91cd\u5efa\u771f\u5b9e\u58f0\u573a\u3002", "conclusion": "\u63d0\u51fa\u7684\u6838\u4f30\u8ba1\u5668\u4e3a\u5916\u58f0\u573a\u63d2\u503c\u63d0\u4f9b\u4e86\u7075\u6d3b\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u7a81\u7834\u4e86\u4f20\u7edf\u65b9\u6cd5\u5bf9\u9ea6\u514b\u98ce\u9635\u5217\u914d\u7f6e\u7684\u9650\u5236\uff0c\u5b9e\u73b0\u4e86\u66f4\u597d\u7684\u63d2\u503c\u6027\u80fd\u3002"}}
{"id": "2602.05209", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.05209", "abs": "https://arxiv.org/abs/2602.05209", "authors": ["Zhiyu Chen", "Ming-Min Zhao", "Songfu Cai", "Ming Lei", "Min-Jian Zhao"], "title": "Integrated Sensing, Communication, and Control for UAV-Assisted Mobile Target Tracking", "comment": "13 pages, 10 figures", "summary": "Unmanned aerial vehicles (UAVs) are increasingly deployed in mission-critical applications such as target tracking, where they must simultaneously sense dynamic environments, ensure reliable communication, and achieve precise control. A key challenge here is to jointly guarantee tracking accuracy, communication reliability, and control stability within a unified framework. To address this issue, we propose an integrated sensing, communication, and control (ISCC) framework for UAV-assisted target tracking, where the considered tracking system is modeled as a discrete-time linear control process, with the objective of driving the deviation between the UAV and target states toward zero. We formulate a stochastic model predictive control (MPC) optimization problem for joint control and beamforming design, which is highly non-convex and intractable in its original form. To overcome this difficulty, the target state is first estimated using an extended Kalman filter (EKF). Then, by deriving the closed-form optimal beamforming solution under a given control input, the original problem is equivalently reformulated into a tractable control-oriented form. Finally, we convexify the remaining non-convex constraints via a relaxation-based convex approximation, yielding a computationally tractable convex optimization problem that admits efficient global solution. Numerical results show that the proposed ISCC framework achieves tracking accuracy comparable to a non-causal benchmark while maintaining stable communication, and it significantly outperforms the conventional control and tracking method.", "AI": {"tldr": "\u63d0\u51fa\u65e0\u4eba\u673a\u8f85\u52a9\u76ee\u6807\u8ddf\u8e2a\u7684\u96c6\u6210\u611f\u77e5\u3001\u901a\u4fe1\u4e0e\u63a7\u5236\u6846\u67b6\uff0c\u901a\u8fc7\u968f\u673a\u6a21\u578b\u9884\u6d4b\u63a7\u5236\u548c\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\uff0c\u5728\u4fdd\u8bc1\u8ddf\u8e2a\u7cbe\u5ea6\u548c\u901a\u4fe1\u53ef\u9760\u6027\u7684\u540c\u65f6\u5b9e\u73b0\u63a7\u5236\u7a33\u5b9a\u6027\u3002", "motivation": "\u65e0\u4eba\u673a\u5728\u5173\u952e\u4efb\u52a1\u5e94\u7528\u4e2d\u9700\u8981\u540c\u65f6\u611f\u77e5\u52a8\u6001\u73af\u5883\u3001\u786e\u4fdd\u53ef\u9760\u901a\u4fe1\u5e76\u5b9e\u73b0\u7cbe\u786e\u63a7\u5236\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u5728\u7edf\u4e00\u6846\u67b6\u5185\u8054\u5408\u4fdd\u8bc1\u8ddf\u8e2a\u7cbe\u5ea6\u3001\u901a\u4fe1\u53ef\u9760\u6027\u548c\u63a7\u5236\u7a33\u5b9a\u6027\u3002", "method": "\u63d0\u51faISCC\u6846\u67b6\uff0c\u5c06\u8ddf\u8e2a\u7cfb\u7edf\u5efa\u6a21\u4e3a\u79bb\u6563\u65f6\u95f4\u7ebf\u6027\u63a7\u5236\u8fc7\u7a0b\uff1b\u4f7f\u7528\u6269\u5c55\u5361\u5c14\u66fc\u6ee4\u6ce2\u5668\u4f30\u8ba1\u76ee\u6807\u72b6\u6001\uff1b\u63a8\u5bfc\u7ed9\u5b9a\u63a7\u5236\u8f93\u5165\u4e0b\u7684\u6700\u4f18\u6ce2\u675f\u6210\u5f62\u95ed\u5f0f\u89e3\uff1b\u901a\u8fc7\u677e\u5f1b\u51f8\u8fd1\u4f3c\u5c06\u975e\u51f8\u7ea6\u675f\u8f6c\u5316\u4e3a\u53ef\u8ba1\u7b97\u7684\u51f8\u4f18\u5316\u95ee\u9898\u3002", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0ISCC\u6846\u67b6\u7684\u8ddf\u8e2a\u7cbe\u5ea6\u63a5\u8fd1\u975e\u56e0\u679c\u57fa\u51c6\uff0c\u540c\u65f6\u4fdd\u6301\u7a33\u5b9a\u901a\u4fe1\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u63a7\u5236\u548c\u8ddf\u8e2a\u65b9\u6cd5\u3002", "conclusion": "ISCC\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u65e0\u4eba\u673a\u76ee\u6807\u8ddf\u8e2a\u4e2d\u611f\u77e5\u3001\u901a\u4fe1\u4e0e\u63a7\u5236\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u4e3a\u5173\u952e\u4efb\u52a1\u5e94\u7528\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u7edf\u4e00\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05308", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.05308", "abs": "https://arxiv.org/abs/2602.05308", "authors": ["Jiwei Qian", "Yee Hui Lee", "Kaixuan Cheng", "Qiqi Dai", "Arda Yalcinkaya", "Mohamed Lokman Mohd Yusof", "James Wang", "Abdulkadir C. Yucel"], "title": "A Migration-Assisted Deep Learning Scheme for Imaging Defects Inside Cylindrical Structures via GPR: A Case Study for Tree Trunks", "comment": null, "summary": "Ground-penetrating radar (GPR) has emerged as a prominent tool for imaging internal defects in cylindrical structures, such as columns, utility poles, and tree trunks. However, accurately reconstructing both the shape and permittivity of the defects inside cylindrical structures remains challenging due to complex wave scattering phenomena and the limited accuracy of the existing signal processing and deep learning techniques. To address these issues, this study proposes a migration-assisted deep learning scheme for reconstructing the shape and permittivity of defects within cylindrical structures. The proposed scheme involves three stages of GPR data processing. First, a dual-permittivity estimation network extracts the permittivity values of the defect and the cylindrical structure, the latter of which is estimated with the help of a novel structural similarity index measure-based autofocusing technique. Second, a modified Kirchhoff migration incorporating the extracted permittivity of the cylindrical structure maps the signals reflected from the defect to the imaging domain. Third, a shape reconstruction network processes the migrated image to recover the precise shape of the defect. The image of the interior defect is finally obtained by combining the reconstructed shape and extracted permittivity of the defect. The proposed scheme is validated using both synthetic and experimental data from a laboratory trunk model and real tree trunk samples. Comparative results show superior performance over existing deep learning methods, while generalization tests on live trees confirm its feasibility for in-field deployment. The underlying principle can further be applied to other circumferential GPR imaging scenarios. The code and database are available at: https://github.com/jwqian54/Migration-Assisted-DL.", "AI": {"tldr": "\u63d0\u51fa\u8fc1\u79fb\u8f85\u52a9\u6df1\u5ea6\u5b66\u4e60\u65b9\u6848\uff0c\u7528\u4e8e\u91cd\u5efa\u5706\u67f1\u7ed3\u6784\u5185\u90e8\u7f3a\u9677\u7684\u5f62\u72b6\u548c\u4ecb\u7535\u5e38\u6570\uff0c\u901a\u8fc7\u4e09\u9636\u6bb5GPR\u6570\u636e\u5904\u7406\u5b9e\u73b0", "motivation": "\u73b0\u6709\u65b9\u6cd5\u96be\u4ee5\u51c6\u786e\u91cd\u5efa\u5706\u67f1\u7ed3\u6784\u5185\u90e8\u7f3a\u9677\u7684\u5f62\u72b6\u548c\u4ecb\u7535\u5e38\u6570\uff0c\u4e3b\u8981\u53d7\u590d\u6742\u6ce2\u6563\u5c04\u73b0\u8c61\u548c\u73b0\u6709\u4fe1\u53f7\u5904\u7406/\u6df1\u5ea6\u5b66\u4e60\u6280\u672f\u7cbe\u5ea6\u9650\u5236", "method": "\u4e09\u9636\u6bb5\u65b9\u6848\uff1a1) \u53cc\u4ecb\u7535\u5e38\u6570\u4f30\u8ba1\u7f51\u7edc\u63d0\u53d6\u7f3a\u9677\u548c\u5706\u67f1\u7ed3\u6784\u4ecb\u7535\u5e38\u6570\uff1b2) \u6539\u8fdb\u7684Kirchhoff\u8fc1\u79fb\u5c06\u7f3a\u9677\u53cd\u5c04\u4fe1\u53f7\u6620\u5c04\u5230\u6210\u50cf\u57df\uff1b3) \u5f62\u72b6\u91cd\u5efa\u7f51\u7edc\u5904\u7406\u8fc1\u79fb\u56fe\u50cf\u6062\u590d\u7f3a\u9677\u7cbe\u786e\u5f62\u72b6", "result": "\u5728\u5408\u6210\u6570\u636e\u3001\u5b9e\u9a8c\u5ba4\u6811\u5e72\u6a21\u578b\u548c\u771f\u5b9e\u6811\u5e72\u6837\u672c\u4e0a\u9a8c\u8bc1\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\uff0c\u73b0\u573a\u6811\u6728\u6d4b\u8bd5\u786e\u8ba4\u5176\u53ef\u884c\u6027", "conclusion": "\u63d0\u51fa\u7684\u8fc1\u79fb\u8f85\u52a9\u6df1\u5ea6\u5b66\u4e60\u65b9\u6848\u80fd\u6709\u6548\u91cd\u5efa\u5706\u67f1\u7ed3\u6784\u5185\u90e8\u7f3a\u9677\u7684\u5f62\u72b6\u548c\u4ecb\u7535\u5e38\u6570\uff0c\u539f\u7406\u53ef\u5e94\u7528\u4e8e\u5176\u4ed6\u5706\u5468GPR\u6210\u50cf\u573a\u666f"}}
{"id": "2602.05770", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2602.05770", "abs": "https://arxiv.org/abs/2602.05770", "authors": ["Jose Giraldo", "Alex Peir\u00f3-Lilja", "Rodolfo Zevallos", "Cristina Espa\u00f1a-Bonet"], "title": "Zero-Shot TTS With Enhanced Audio Prompts: Bsc Submission For The 2026 Wildspoof Challenge TTS Track", "comment": "Accepted to ICASSP 2026", "summary": "We evaluate two non-autoregressive architectures, StyleTTS2 and F5-TTS, to address the spontaneous nature of in-the-wild speech. Our models utilize flexible duration modeling to improve prosodic naturalness. To handle acoustic noise, we implement a multi-stage enhancement pipeline using the Sidon model, which significantly outperforms standard Demucs in signal quality. Experimental results show that finetuning enhanced audios yields superior robustness, achieving up to 4.21 UTMOS and 3.47 DNSMOS. Furthermore, we analyze the impact of reference prompt quality and length on zero-shot synthesis performance, demonstrating the effectiveness of our approach for realistic speech generation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8bc4\u4f30\u4e86StyleTTS2\u548cF5-TTS\u4e24\u79cd\u975e\u81ea\u56de\u5f52\u67b6\u6784\uff0c\u901a\u8fc7\u7075\u6d3b\u65f6\u957f\u5efa\u6a21\u63d0\u5347\u97f5\u5f8b\u81ea\u7136\u5ea6\uff0c\u91c7\u7528Sidon\u6a21\u578b\u7684\u591a\u9636\u6bb5\u589e\u5f3a\u7ba1\u9053\u5904\u7406\u58f0\u5b66\u566a\u58f0\uff0c\u5fae\u8c03\u540e\u97f3\u9891\u5728UTMOS\u548cDNSMOS\u6307\u6807\u4e0a\u8868\u73b0\u4f18\u5f02\uff0c\u5e76\u5206\u6790\u4e86\u53c2\u8003\u63d0\u793a\u8d28\u91cf\u5bf9\u96f6\u6837\u672c\u5408\u6210\u7684\u5f71\u54cd\u3002", "motivation": "\u89e3\u51b3\u91ce\u5916\u81ea\u53d1\u8bed\u97f3\u7684\u81ea\u7136\u751f\u6210\u95ee\u9898\uff0c\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u81ea\u53d1\u8bed\u97f3\u7684\u97f5\u5f8b\u81ea\u7136\u5ea6\u548c\u58f0\u5b66\u566a\u58f0\u65b9\u9762\u5b58\u5728\u5c40\u9650\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u8bed\u97f3\u5408\u6210\u7cfb\u7edf\u3002", "method": "1. \u8bc4\u4f30\u4e24\u79cd\u975e\u81ea\u56de\u5f52\u67b6\u6784\uff08StyleTTS2\u548cF5-TTS\uff09\uff1b2. \u91c7\u7528\u7075\u6d3b\u65f6\u957f\u5efa\u6a21\u6539\u5584\u97f5\u5f8b\u81ea\u7136\u5ea6\uff1b3. \u4f7f\u7528Sidon\u6a21\u578b\u6784\u5efa\u591a\u9636\u6bb5\u589e\u5f3a\u7ba1\u9053\u5904\u7406\u58f0\u5b66\u566a\u58f0\uff1b4. \u5bf9\u589e\u5f3a\u97f3\u9891\u8fdb\u884c\u5fae\u8c03\uff1b5. \u5206\u6790\u53c2\u8003\u63d0\u793a\u8d28\u91cf\u548c\u957f\u5ea6\u5bf9\u96f6\u6837\u672c\u5408\u6210\u7684\u5f71\u54cd\u3002", "result": "1. Sidon\u6a21\u578b\u5728\u4fe1\u53f7\u8d28\u91cf\u4e0a\u663e\u8457\u4f18\u4e8e\u6807\u51c6Demucs\uff1b2. \u5fae\u8c03\u589e\u5f3a\u97f3\u9891\u83b7\u5f97\u66f4\u597d\u7684\u9c81\u68d2\u6027\uff0c\u8fbe\u52304.21 UTMOS\u548c3.47 DNSMOS\uff1b3. \u53c2\u8003\u63d0\u793a\u8d28\u91cf\u5bf9\u96f6\u6837\u672c\u5408\u6210\u6027\u80fd\u6709\u91cd\u8981\u5f71\u54cd\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u7684\u65b9\u6cd5\u80fd\u6709\u6548\u751f\u6210\u66f4\u81ea\u7136\u7684\u81ea\u53d1\u8bed\u97f3\uff0c\u901a\u8fc7\u591a\u9636\u6bb5\u589e\u5f3a\u7ba1\u9053\u548c\u7075\u6d3b\u65f6\u957f\u5efa\u6a21\u663e\u8457\u63d0\u5347\u4e86\u8bed\u97f3\u5408\u6210\u7684\u81ea\u7136\u5ea6\u548c\u9c81\u68d2\u6027\uff0c\u4e3a\u96f6\u6837\u672c\u8bed\u97f3\u5408\u6210\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.05342", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.05342", "abs": "https://arxiv.org/abs/2602.05342", "authors": ["Zitong Wang", "Cheng Zhang", "Wen Wang", "Shuigen Yang", "Haiming Wang", "Yongming Huang"], "title": "Joint Optimization of Latency and Accuracy for Split Federated Learning in User-Centric Cell-Free MIMO Networks", "comment": null, "summary": "This paper proposes a user-centric split federated learning (UCSFL) framework for user-centric cell-free multiple-input multiple-output (CF-MIMO) networks to support split federated learning (SFL). In the proposed UCSFL framework, users deploy split sub-models locally, while complete models are maintained and updated at access point (AP)-side distributed processing units (DPUs), followed by a two-level aggregation procedure across DPUs and the central processing unit (CPU). Under standard machine learning (ML) assumptions, we provide a theoretical convergence analysis for UCSFL, which reveals that the AP-cluster size is a key factor influencing model training accuracy. Motivated by this result, we introduce a new performance metric, termed the latency-to-accuracy ratio, defined as the ratio of a user's per-iteration training latency to the weighted size of its AP cluster. Based on this metric, we formulate a joint optimization problem to minimize the maximum latency-to-accuracy ratio by jointly optimizing uplink power control, downlink beamforming, model splitting, and AP clustering. The resulting problem is decomposed into two sub-problems operating on different time scales, for which dedicated algorithms are developed to handle the short-term and long-term optimizations, respectively. Simulation results verify the convergence of the proposed algorithms and demonstrate that UCSFL effectively reduces the latency-to-accuracy ratio of the VGG16 model compared with baseline schemes. Moreover, the proposed framework adaptively adjusts splitting and clustering strategies in response to varying communication and computation resources. An MNIST-based handwritten digit classification example further shows that UCSFL significantly accelerates the convergence of the VGG16 model.", "AI": {"tldr": "\u63d0\u51fa\u7528\u6237\u4e2d\u5fc3\u5316\u7684\u5206\u5272\u8054\u90a6\u5b66\u4e60\u6846\u67b6\uff0c\u7528\u4e8e\u7528\u6237\u4e2d\u5fc3\u7684CF-MIMO\u7f51\u7edc\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u529f\u7387\u63a7\u5236\u3001\u6ce2\u675f\u6210\u5f62\u3001\u6a21\u578b\u5206\u5272\u548cAP\u805a\u7c7b\u6765\u6700\u5c0f\u5316\u5ef6\u8fdf-\u51c6\u786e\u7387\u6bd4\u3002", "motivation": "\u5728\u7528\u6237\u4e2d\u5fc3\u7684CF-MIMO\u7f51\u7edc\u4e2d\u652f\u6301\u5206\u5272\u8054\u90a6\u5b66\u4e60\uff0c\u9700\u8981\u89e3\u51b3\u901a\u4fe1\u548c\u8ba1\u7b97\u8d44\u6e90\u7ea6\u675f\u4e0b\u7684\u6a21\u578b\u8bad\u7ec3\u6548\u7387\u95ee\u9898\uff0c\u7279\u522b\u662f\u5982\u4f55\u5e73\u8861\u8bad\u7ec3\u5ef6\u8fdf\u548c\u6a21\u578b\u51c6\u786e\u6027\u3002", "method": "\u63d0\u51faUCSFL\u6846\u67b6\uff0c\u7528\u6237\u5728\u672c\u5730\u90e8\u7f72\u5206\u5272\u5b50\u6a21\u578b\uff0cAP\u7aefDPU\u7ef4\u62a4\u5b8c\u6574\u6a21\u578b\uff0c\u91c7\u7528\u4e24\u7ea7\u805a\u5408\u3002\u7406\u8bba\u5206\u6790\u53d1\u73b0AP\u7c07\u5927\u5c0f\u662f\u5173\u952e\u56e0\u7d20\uff0c\u63d0\u51fa\u5ef6\u8fdf-\u51c6\u786e\u7387\u6bd4\u6307\u6807\uff0c\u5e76\u5206\u89e3\u4e3a\u77ed\u65f6\u548c\u957f\u65f6\u4f18\u5316\u95ee\u9898\u5206\u522b\u8bbe\u8ba1\u7b97\u6cd5\u3002", "result": "\u4eff\u771f\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u6536\u655b\u6027\uff0cUCSFL\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6848\u663e\u8457\u964d\u4f4eVGG16\u6a21\u578b\u7684\u5ef6\u8fdf-\u51c6\u786e\u7387\u6bd4\uff0c\u5e76\u80fd\u81ea\u9002\u5e94\u8c03\u6574\u5206\u5272\u548c\u805a\u7c7b\u7b56\u7565\u3002MNIST\u624b\u5199\u6570\u5b57\u5206\u7c7b\u793a\u4f8b\u663e\u793aUCSFL\u663e\u8457\u52a0\u901fVGG16\u6a21\u578b\u6536\u655b\u3002", "conclusion": "UCSFL\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u7528\u6237\u4e2d\u5fc3CF-MIMO\u7f51\u7edc\u4e2d\u5206\u5272\u8054\u90a6\u5b66\u4e60\u7684\u6548\u7387\u95ee\u9898\uff0c\u901a\u8fc7\u8054\u5408\u4f18\u5316\u5b9e\u73b0\u4e86\u5ef6\u8fdf\u548c\u51c6\u786e\u6027\u7684\u826f\u597d\u5e73\u8861\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.05554", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.05554", "abs": "https://arxiv.org/abs/2602.05554", "authors": ["Mohammad Shamsesalehi", "Mahmoud Ahmadian Attari", "Mohammad Amin Maleki Sadr", "Benoit Champagne"], "title": "Beamformed Fingerprint-Based Transformer Network for Trajectory Estimation and Path Determination in Outdoor mmWave MIMO Systems", "comment": "14 pages, 11 figures", "summary": "Radio transmissions in millimeter wave (mmWave) bands have gained significant interest for applications demanding precise device localization and trajectory estimation. This paper explores novel neural network (NN) architectures suitable for trajectory estimation and path determination in a mmWave multiple-input multiple-output (MIMO) outdoor system based on localization data from beamformed fingerprint (BFF). The NN architecture captures sequences of BFF signals from different users, and through the application of learning mechanisms, subsequently estimate their trajectories. In turn, this information is employed to find the shortest path to the target, thereby enabling more efficient navigation. Specifically, we propose a two-stage procedure for trajectory estimation and optimal path finding. In the first stage, a transformer network (TN) based on attention mechanisms is developed to predict trajectories of wireless devices using BFF sequences captured in a mmWave MIMO outdoor system. In the second stage, a novel algorithm based on Informed Rapidly-exploring Random Trees (iRRT*) is employed to determine the optimal path to target locations using trajectory estimates derived in the first stage. The effectiveness of the proposed schemes is validated through numerical experiments, using a comprehensive dataset of radio measurements, generated using ray tracing simulations to model outdoor propagation at 28 GHz. We show that our proposed TN-based trajectory estimator outperforms other methods from the recent literature and can successfully generalize to new trajectories outside the training set. Furthermore, our proposed iRRT* algorithm is able to consistently provide the shortest path to the target.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u7684\u4e24\u9636\u6bb5\u8f68\u8ff9\u4f30\u8ba1\u4e0e\u6700\u4f18\u8def\u5f84\u89c4\u5212\u65b9\u6cd5\uff1a\u7b2c\u4e00\u9636\u6bb5\u4f7f\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684Transformer\u7f51\u7edc\u4ece\u6ce2\u675f\u8d4b\u5f62\u6307\u7eb9\u5e8f\u5217\u9884\u6d4b\u8bbe\u5907\u8f68\u8ff9\uff1b\u7b2c\u4e8c\u9636\u6bb5\u91c7\u7528\u6539\u8fdb\u7684iRRT*\u7b97\u6cd5\u6839\u636e\u8f68\u8ff9\u4f30\u8ba1\u5bfb\u627e\u6700\u77ed\u8def\u5f84\u3002", "motivation": "\u6beb\u7c73\u6ce2\u9891\u6bb5\u7684\u65e0\u7ebf\u7535\u4f20\u8f93\u5728\u9700\u8981\u7cbe\u786e\u5b9a\u4f4d\u548c\u8f68\u8ff9\u4f30\u8ba1\u7684\u5e94\u7528\u4e2d\u53d7\u5230\u5e7f\u6cdb\u5173\u6ce8\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u5ba4\u5916\u6beb\u7c73\u6ce2MIMO\u7cfb\u7edf\u4e2d\u5bf9\u8bbe\u5907\u8f68\u8ff9\u4f30\u8ba1\u548c\u8def\u5f84\u89c4\u5212\u7684\u6548\u7387\u548c\u51c6\u786e\u6027\u6709\u5f85\u63d0\u9ad8\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u65b9\u6cd5\uff1a1) \u4f7f\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u673a\u5236\u7684Transformer\u7f51\u7edc\u5904\u7406\u6ce2\u675f\u8d4b\u5f62\u6307\u7eb9\u5e8f\u5217\uff0c\u9884\u6d4b\u65e0\u7ebf\u8bbe\u5907\u8f68\u8ff9\uff1b2) \u91c7\u7528\u6539\u8fdb\u7684Informed Rapidly-exploring Random Trees (iRRT*)\u7b97\u6cd5\uff0c\u5229\u7528\u7b2c\u4e00\u9636\u6bb5\u4f30\u8ba1\u7684\u8f68\u8ff9\u4fe1\u606f\u5bfb\u627e\u6700\u4f18\u8def\u5f84\u3002", "result": "\u901a\u8fc7\u57fa\u4e8e28GHz\u5c04\u7ebf\u8ffd\u8e2a\u4eff\u771f\u7684\u65e0\u7ebf\u7535\u6d4b\u91cf\u6570\u636e\u96c6\u8fdb\u884c\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\uff1a1) Transformer\u7f51\u7edc\u8f68\u8ff9\u4f30\u8ba1\u5668\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u5e76\u80fd\u6cdb\u5316\u5230\u8bad\u7ec3\u96c6\u5916\u7684\u65b0\u8f68\u8ff9\uff1b2) iRRT*\u7b97\u6cd5\u80fd\u6301\u7eed\u63d0\u4f9b\u6700\u77ed\u8def\u5f84\u3002", "conclusion": "\u63d0\u51fa\u7684\u4e24\u9636\u6bb5\u65b9\u6cd5\u5728\u6beb\u7c73\u6ce2MIMO\u5ba4\u5916\u7cfb\u7edf\u4e2d\u6709\u6548\u5b9e\u73b0\u4e86\u8bbe\u5907\u8f68\u8ff9\u4f30\u8ba1\u548c\u6700\u4f18\u8def\u5f84\u89c4\u5212\uff0cTransformer\u7f51\u7edc\u5728\u8f68\u8ff9\u9884\u6d4b\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0ciRRT*\u7b97\u6cd5\u80fd\u53ef\u9760\u627e\u5230\u6700\u77ed\u8def\u5f84\u3002"}}
{"id": "2602.05560", "categories": ["eess.SP", "physics.ao-ph"], "pdf": "https://arxiv.org/pdf/2602.05560", "abs": "https://arxiv.org/abs/2602.05560", "authors": ["Yangjin Xu", "Wei Gao", "Xiaolei Li", "Qinghang Zeng"], "title": "Depth estimation of a monoharmonic source using a vertical linear array at fixed distance", "comment": null, "summary": "Estimating the depth of a monoharmonic sound source at a fixed range using a vertical linear array (VLA) is challenging in the absence of seabed environmental parameters, and relevant research remains scarce. The orthogonality constrained modal search based depth estimation (OCMS-D) method is proposed in this paper, which enables the estimation of the depth of a monoharmonic source at a fixed range using a VLA under unknown seabed parameters. Using the sparsity of propagating normal modes and the orthogonality of mode depth functions, OCMS-D estimates the normal mode parameters under a fixed source-array distance at first. The estimated normal mode parameters are then used to estimate the source depth. To ensure the precision of the source depth estimation, the method utilizes information on both the amplitude distribution and the sign (positive/negative) patterns of the estimated mode depth functions at the inferred source depth. Numerical simulations evaluate the performance of OCMS-D under different conditions. The effectiveness of OCMS-D is also verified by the Yellow Sea experiment and the SWellEx-96 experiment. In the Yellow Sea experiment, the depth estimation absolute errors by OCMS-D with a 4-second time window are less than 2.4 m. And the depth estimation absolute errors in the SWellEx-96 experiment with a 10-second time window are less than 5.4 m for the shallow source and less than 10.8 m for the deep source.", "AI": {"tldr": "\u63d0\u51faOCMS-D\u65b9\u6cd5\uff0c\u5229\u7528\u5782\u76f4\u7ebf\u6027\u9635\u5217\u5728\u672a\u77e5\u6d77\u5e95\u53c2\u6570\u6761\u4ef6\u4e0b\u4f30\u8ba1\u5355\u9891\u58f0\u6e90\u6df1\u5ea6\uff0c\u901a\u8fc7\u6a21\u6001\u6b63\u4ea4\u6027\u7ea6\u675f\u5b9e\u73b0\u6df1\u5ea6\u4f30\u8ba1", "motivation": "\u5728\u672a\u77e5\u6d77\u5e95\u73af\u5883\u53c2\u6570\u60c5\u51b5\u4e0b\uff0c\u4f7f\u7528\u5782\u76f4\u7ebf\u6027\u9635\u5217\u4f30\u8ba1\u56fa\u5b9a\u8ddd\u79bb\u5355\u9891\u58f0\u6e90\u6df1\u5ea6\u5177\u6709\u6311\u6218\u6027\uff0c\u76f8\u5173\u7814\u7a76\u8f83\u5c11", "method": "\u57fa\u4e8e\u6b63\u4ea4\u6027\u7ea6\u675f\u7684\u6a21\u6001\u641c\u7d22\u6df1\u5ea6\u4f30\u8ba1\u65b9\u6cd5\uff0c\u5229\u7528\u4f20\u64ad\u6a21\u6001\u7684\u7a00\u758f\u6027\u548c\u6a21\u6001\u6df1\u5ea6\u51fd\u6570\u7684\u6b63\u4ea4\u6027\uff0c\u5148\u4f30\u8ba1\u6b63\u5e38\u6a21\u6001\u53c2\u6570\uff0c\u518d\u4f30\u8ba1\u58f0\u6e90\u6df1\u5ea6\uff0c\u540c\u65f6\u5229\u7528\u5e45\u5ea6\u5206\u5e03\u548c\u7b26\u53f7\u6a21\u5f0f\u4fe1\u606f", "result": "\u6570\u503c\u6a21\u62df\u9a8c\u8bc1\u65b9\u6cd5\u6027\u80fd\uff0c\u9ec4\u6d77\u5b9e\u9a8c\u4e2d4\u79d2\u65f6\u95f4\u7a97\u53e3\u6df1\u5ea6\u4f30\u8ba1\u7edd\u5bf9\u8bef\u5dee\u5c0f\u4e8e2.4\u7c73\uff0cSWellEx-96\u5b9e\u9a8c\u4e2d10\u79d2\u65f6\u95f4\u7a97\u53e3\u6d45\u6e90\u8bef\u5dee\u5c0f\u4e8e5.4\u7c73\uff0c\u6df1\u6e90\u8bef\u5dee\u5c0f\u4e8e10.8\u7c73", "conclusion": "OCMS-D\u65b9\u6cd5\u5728\u672a\u77e5\u6d77\u5e95\u53c2\u6570\u6761\u4ef6\u4e0b\u80fd\u6709\u6548\u4f30\u8ba1\u5355\u9891\u58f0\u6e90\u6df1\u5ea6\uff0c\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u65b9\u6cd5\u7684\u6709\u6548\u6027"}}
{"id": "2602.05579", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.05579", "abs": "https://arxiv.org/abs/2602.05579", "authors": ["Mu Jia", "Hao Sun", "Junting Chen", "Pooi-Yuen Kam"], "title": "Physics-Aware Tensor Reconstruction for Radio Maps in Pixel-Based Fluid Antenna Systems", "comment": null, "summary": "The deployment of pixel-based antennas and fluid antenna systems (FAS) is hindered by prohibitive channel state information (CSI) acquisition overhead. While radio maps enable proactive mode selection, reconstructing high-fidelity maps from sparse measurements is challenging. Existing physics-agnostic or data-driven methods often fail to recover fine-grained shadowing details under extreme sparsity. We propose a Physics-Regularized Low-Rank Tensor Completion (PR-LRTC) framework for radio map reconstruction. By modeling the signal field as a three-way tensor, we integrate environmental low-rankness with deterministic antenna physics. Specifically, we leverage Effective Aerial Degrees-of-Freedom (EADoF) theory to derive a differential gain topology map as a physical prior for regularization. The resulting optimization problem is solved via an efficient Alternating Direction Method of Multipliers (ADMM)-based algorithm. Simulations show that PR-LRTC achieves a 4 dB gain over baselines at a 10% sampling ratio. It effectively preserves sharp shadowing edges, providing a robust, physics-compliant solution for low-overhead beam management.", "AI": {"tldr": "\u63d0\u51faPR-LRTC\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u5408\u73af\u5883\u4f4e\u79e9\u6027\u548c\u786e\u5b9a\u6027\u5929\u7ebf\u7269\u7406\u5148\u9a8c\uff0c\u89e3\u51b3\u7a00\u758f\u6d4b\u91cf\u4e0b\u7684\u9ad8\u4fdd\u771f\u65e0\u7ebf\u5730\u56fe\u91cd\u5efa\u95ee\u9898\uff0c\u572810%\u91c7\u6837\u7387\u4e0b\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u53474dB\u6027\u80fd\u3002", "motivation": "\u50cf\u7d20\u5929\u7ebf\u548c\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u9762\u4e34\u8fc7\u9ad8\u7684\u4fe1\u9053\u72b6\u6001\u4fe1\u606f\u83b7\u53d6\u5f00\u9500\uff0c\u73b0\u6709\u7269\u7406\u65e0\u5173\u6216\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u5728\u6781\u7aef\u7a00\u758f\u6761\u4ef6\u4e0b\u96be\u4ee5\u6062\u590d\u7cbe\u7ec6\u7684\u9634\u5f71\u7ec6\u8282\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u6709\u6548\u91cd\u5efa\u9ad8\u4fdd\u771f\u65e0\u7ebf\u5730\u56fe\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u7269\u7406\u6b63\u5219\u5316\u4f4e\u79e9\u5f20\u91cf\u5b8c\u6210\u6846\u67b6\uff0c\u5c06\u4fe1\u53f7\u573a\u5efa\u6a21\u4e3a\u4e09\u8def\u5f20\u91cf\uff0c\u7ed3\u5408\u73af\u5883\u4f4e\u79e9\u6027\u548c\u5929\u7ebf\u7269\u7406\u5148\u9a8c\uff0c\u5229\u7528\u6709\u6548\u7a7a\u4e2d\u81ea\u7531\u5ea6\u7406\u8bba\u63a8\u5bfc\u5dee\u5206\u589e\u76ca\u62d3\u6251\u56fe\u4f5c\u4e3a\u7269\u7406\u6b63\u5219\u5316\u9879\uff0c\u91c7\u7528ADMM\u7b97\u6cd5\u6c42\u89e3\u4f18\u5316\u95ee\u9898\u3002", "result": "\u4eff\u771f\u663e\u793aPR-LRTC\u572810%\u91c7\u6837\u7387\u4e0b\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u83b7\u5f974dB\u589e\u76ca\uff0c\u80fd\u6709\u6548\u4fdd\u7559\u5c16\u9510\u7684\u9634\u5f71\u8fb9\u7f18\uff0c\u4e3a\u4f4e\u5f00\u9500\u6ce2\u675f\u7ba1\u7406\u63d0\u4f9b\u7a33\u5065\u7684\u7269\u7406\u5408\u89c4\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "PR-LRTC\u6846\u67b6\u901a\u8fc7\u6574\u5408\u7269\u7406\u5148\u9a8c\u548c\u73af\u5883\u4f4e\u79e9\u6027\uff0c\u6210\u529f\u89e3\u51b3\u4e86\u7a00\u758f\u6d4b\u91cf\u4e0b\u7684\u65e0\u7ebf\u5730\u56fe\u91cd\u5efa\u96be\u9898\uff0c\u4e3a\u50cf\u7d20\u5929\u7ebf\u548c\u6d41\u4f53\u5929\u7ebf\u7cfb\u7edf\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u4f4e\u5f00\u9500\u4fe1\u9053\u4fe1\u606f\u83b7\u53d6\u65b9\u6848\u3002"}}
{"id": "2602.05581", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.05581", "abs": "https://arxiv.org/abs/2602.05581", "authors": ["Ziqing Xing", "Zhaoyang Zhang", "Xin Tong", "Zhaohui Yang", "Chongwen Huang"], "title": "Physics-Inspired Target Shape Detection and Reconstruction in mmWave Communication Systems", "comment": "Accepted by GLOBECOM 2023", "summary": "The integration of sensing and communication (ISAC) is an essential function of future wireless systems. Due to its large available bandwidth, millimeter-wave (mmWave) ISAC systems are able to achieve high sensing accuracy. In this paper, we consider the multiple base-station (BS) collaborative sensing problem in a multi-input multi-output (MIMO) orthogonal frequency division multiplexing (OFDM) mmWave communication system. Our aim is to sense a remote target shape with the collected signals which consist of both the reflection and scattering signals. We first characterize the mmWave's scattering and reflection effects based on the Lambertian scattering model. Then we apply the periodogram technique to obtain rough scattering point detection, and further incorporate the subspace method to achieve more precise scattering and reflection point detection. Based on these, a reconstruction algorithm based on Hough Transform and principal component analysis (PCA) is designed for a single convex polygon target scenario. To improve the accuracy and completeness of the reconstruction results, we propose a method to further fuse the scattering and reflection points. Extensive simulation results validate the effectiveness of the proposed algorithms.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6beb\u7c73\u6ce2ISAC\u7cfb\u7edf\u4e2d\u591a\u57fa\u7ad9\u534f\u4f5c\u611f\u77e5\u76ee\u6807\u5f62\u72b6\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7\u878d\u5408\u6563\u5c04\u548c\u53cd\u5c04\u4fe1\u53f7\uff0c\u5229\u7528Hough\u53d8\u6362\u548cPCA\u8fdb\u884c\u76ee\u6807\u91cd\u5efa\u3002", "motivation": "\u6beb\u7c73\u6ce2ISAC\u7cfb\u7edf\u5177\u6709\u5927\u5e26\u5bbd\u4f18\u52bf\uff0c\u53ef\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u611f\u77e5\u3002\u5728\u591a\u57fa\u7ad9MIMO-OFDM\u6beb\u7c73\u6ce2\u7cfb\u7edf\u4e2d\uff0c\u5982\u4f55\u5229\u7528\u6563\u5c04\u548c\u53cd\u5c04\u4fe1\u53f7\u534f\u4f5c\u611f\u77e5\u8fdc\u7a0b\u76ee\u6807\u5f62\u72b6\u662f\u4e00\u4e2a\u91cd\u8981\u95ee\u9898\u3002", "method": "1. \u57fa\u4e8eLambertian\u6563\u5c04\u6a21\u578b\u8868\u5f81\u6beb\u7c73\u6ce2\u6563\u5c04\u548c\u53cd\u5c04\u6548\u5e94\uff1b2. \u4f7f\u7528\u5468\u671f\u56fe\u6280\u672f\u8fdb\u884c\u7c97\u7565\u6563\u5c04\u70b9\u68c0\u6d4b\uff1b3. \u7ed3\u5408\u5b50\u7a7a\u95f4\u65b9\u6cd5\u5b9e\u73b0\u66f4\u7cbe\u786e\u7684\u6563\u5c04\u548c\u53cd\u5c04\u70b9\u68c0\u6d4b\uff1b4. \u9488\u5bf9\u5355\u4e2a\u51f8\u591a\u8fb9\u5f62\u76ee\u6807\u573a\u666f\uff0c\u8bbe\u8ba1\u57fa\u4e8eHough\u53d8\u6362\u548cPCA\u7684\u91cd\u5efa\u7b97\u6cd5\uff1b5. \u63d0\u51fa\u878d\u5408\u6563\u5c04\u548c\u53cd\u5c04\u70b9\u7684\u65b9\u6cd5\u4ee5\u63d0\u9ad8\u91cd\u5efa\u7cbe\u5ea6\u548c\u5b8c\u6574\u6027\u3002", "result": "\u5e7f\u6cdb\u7684\u4eff\u771f\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u7b97\u6cd5\u7684\u6709\u6548\u6027\uff0c\u80fd\u591f\u5b9e\u73b0\u76ee\u6807\u5f62\u72b6\u7684\u51c6\u786e\u91cd\u5efa\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6beb\u7c73\u6ce2ISAC\u7cfb\u7edf\u4e2d\u7684\u591a\u57fa\u7ad9\u534f\u4f5c\u76ee\u6807\u5f62\u72b6\u611f\u77e5\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u878d\u5408\u6563\u5c04\u548c\u53cd\u5c04\u4fe1\u53f7\u63d0\u9ad8\u4e86\u91cd\u5efa\u7cbe\u5ea6\u3002"}}
{"id": "2602.05715", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.05715", "abs": "https://arxiv.org/abs/2602.05715", "authors": ["Yuyang Liu", "Johan Karlsson", "Filip Elvander"], "title": "Sound Field Estimation Using Optimal Transport Barycenters in the Presence of Phase Errors", "comment": null, "summary": "This study introduces a novel approach for estimating plane-wave coefficients in sound field reconstruction, specifically addressing challenges posed by error-in-variable phase perturbations. Such systematic errors typically arise from sensor mis-calibration, including uncertainties in sensor positions and response characteristics, leading to measurement-induced phase shifts in plane wave coefficients. Traditional methods often result in biased estimates or non-convex solutions. To overcome these issues, we propose an optimal transport (OT) framework. This framework operates on a set of lifted non-negative measures that correspond to observation-dependent shifted coefficients relative to the unperturbed ones. By applying OT, the supports of the measures are transported toward an optimal average in the phase space, effectively morphing them into an indistinguishable state. This optimal average, known as barycenter, is linked to the estimated plane-wave coefficients using the same lifting rule. The framework addresses the ill-posed nature of the problem, due to the large number of plane waves, by adding a constant to the ground cost, ensuring the sparsity of the transport matrix. Convex consistency of the solution is maintained. Simulation results confirm that our proposed method provides more accurate coefficient estimations compared to baseline approaches in scenarios with both additive noise and phase perturbations.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6700\u4f18\u4f20\u8f93(OT)\u6846\u67b6\u7684\u58f0\u573a\u91cd\u5efa\u65b9\u6cd5\uff0c\u89e3\u51b3\u76f8\u4f4d\u6270\u52a8\u4e0b\u7684\u5e73\u9762\u6ce2\u7cfb\u6570\u4f30\u8ba1\u95ee\u9898", "motivation": "\u4f20\u7edf\u65b9\u6cd5\u5728\u5904\u7406\u4f20\u611f\u5668\u6807\u5b9a\u8bef\u5dee\uff08\u4f4d\u7f6e\u548c\u54cd\u5e94\u7279\u6027\u4e0d\u786e\u5b9a\u6027\uff09\u5bfc\u81f4\u7684\u76f8\u4f4d\u6270\u52a8\u65f6\uff0c\u4f1a\u4ea7\u751f\u6709\u504f\u4f30\u8ba1\u6216\u975e\u51f8\u89e3\uff0c\u9700\u8981\u66f4\u9c81\u68d2\u7684\u4f30\u8ba1\u65b9\u6cd5", "method": "\u91c7\u7528\u6700\u4f18\u4f20\u8f93\u6846\u67b6\uff0c\u5c06\u89c2\u6d4b\u76f8\u5173\u7684\u79fb\u4f4d\u7cfb\u6570\u8868\u793a\u4e3a\u975e\u8d1f\u6d4b\u5ea6\uff0c\u901a\u8fc7OT\u5c06\u8fd9\u4e9b\u6d4b\u5ea6\u5728\u76f8\u4f4d\u7a7a\u95f4\u4e2d\u4f20\u8f93\u5230\u6700\u4f18\u5e73\u5747\uff08\u91cd\u5fc3\uff09\uff0c\u8be5\u91cd\u5fc3\u901a\u8fc7\u76f8\u540c\u7684\u63d0\u5347\u89c4\u5219\u4e0e\u4f30\u8ba1\u7684\u5e73\u9762\u6ce2\u7cfb\u6570\u5173\u8054", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u5728\u540c\u65f6\u5b58\u5728\u52a0\u6027\u566a\u58f0\u548c\u76f8\u4f4d\u6270\u52a8\u7684\u60c5\u51b5\u4e0b\uff0c\u8be5\u65b9\u6cd5\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u63d0\u4f9b\u66f4\u51c6\u786e\u7684\u7cfb\u6570\u4f30\u8ba1", "conclusion": "\u63d0\u51fa\u7684OT\u6846\u67b6\u80fd\u6709\u6548\u5904\u7406\u76f8\u4f4d\u6270\u52a8\u95ee\u9898\uff0c\u901a\u8fc7\u6dfb\u52a0\u5e38\u6570\u5230\u5730\u9762\u6210\u672c\u786e\u4fdd\u4f20\u8f93\u77e9\u9635\u7a00\u758f\u6027\uff0c\u4fdd\u6301\u89e3\u7684\u51f8\u4e00\u81f4\u6027\uff0c\u4e3a\u58f0\u573a\u91cd\u5efa\u4e2d\u7684\u8bef\u5dee\u53d8\u91cf\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.05724", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.05724", "abs": "https://arxiv.org/abs/2602.05724", "authors": ["Shoma Hara", "Takumi Takahashi", "Hiroki Iimori", "Hideki Ochiai", "Erik G. Larsson"], "title": "Reciprocity Calibration of Dual-Antenna Repeaters via MMSE Estimation", "comment": "13 pages, 9 figures", "summary": "This paper proposes a novel Bayesian reciprocity calibration method that consistently ensures uplink and downlink channel reciprocity in repeater-assisted multiple-input multiple-output (MIMO) systems. The proposed algorithm is formulated under the minimum mean-square error (MMSE) criterion. Its Bayesian framework incorporates complete statistical knowledge of the signal model, noise, and prior distributions, enabling a coherent design that achieves both low computational complexity and high calibration accuracy. To further enhance phase alignment accuracy, which is critical for calibration tasks, we develop a von Mises denoiser that exploits the fact that the target parameters lie on the circle in the complex plane. Simulation results demonstrate that the proposed MMSE algorithm achieves substantially improved estimation accuracy compared with conventional deterministic non-linear least-squares (NLS) methods, while maintaining comparable computational complexity. Furthermore, the proposed method exhibits remarkably fast convergence, making it well suited for practical implementation.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u8d1d\u53f6\u65af\u4e92\u6613\u6027\u6821\u51c6\u65b9\u6cd5\uff0c\u7528\u4e8e\u4e2d\u7ee7\u8f85\u52a9MIMO\u7cfb\u7edf\uff0c\u786e\u4fdd\u4e0a\u4e0b\u884c\u4fe1\u9053\u4e92\u6613\u6027\uff0c\u5177\u6709\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u9ad8\u6821\u51c6\u7cbe\u5ea6\u3002", "motivation": "\u5728\u4e2d\u7ee7\u8f85\u52a9MIMO\u7cfb\u7edf\u4e2d\uff0c\u786e\u4fdd\u4e0a\u4e0b\u884c\u4fe1\u9053\u4e92\u6613\u6027\u5bf9\u4e8e\u7cfb\u7edf\u6027\u80fd\u81f3\u5173\u91cd\u8981\u3002\u4f20\u7edf\u786e\u5b9a\u6027\u975e\u7ebf\u6027\u6700\u5c0f\u4e8c\u4e58\u6cd5\u5728\u4f30\u8ba1\u7cbe\u5ea6\u4e0a\u6709\u9650\u5236\uff0c\u9700\u8981\u66f4\u51c6\u786e\u4e14\u8ba1\u7b97\u9ad8\u6548\u7684\u6821\u51c6\u65b9\u6cd5\u3002", "method": "\u57fa\u4e8e\u6700\u5c0f\u5747\u65b9\u8bef\u5dee\u51c6\u5219\u7684\u8d1d\u53f6\u65af\u4e92\u6613\u6027\u6821\u51c6\u65b9\u6cd5\uff0c\u5229\u7528\u4fe1\u53f7\u6a21\u578b\u3001\u566a\u58f0\u548c\u5148\u9a8c\u5206\u5e03\u7684\u5b8c\u6574\u7edf\u8ba1\u77e5\u8bc6\u3002\u5f00\u53d1\u4e86\u51af\u00b7\u7c73\u585e\u65af\u53bb\u566a\u5668\u6765\u63d0\u5347\u76f8\u4f4d\u5bf9\u9f50\u7cbe\u5ea6\uff0c\u8be5\u53bb\u566a\u5668\u5229\u7528\u4e86\u76ee\u6807\u53c2\u6570\u4f4d\u4e8e\u590d\u5e73\u9762\u5706\u4e0a\u7684\u7279\u6027\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684MMSE\u7b97\u6cd5\u76f8\u6bd4\u4f20\u7edf\u786e\u5b9a\u6027NLS\u65b9\u6cd5\u663e\u8457\u63d0\u9ad8\u4e86\u4f30\u8ba1\u7cbe\u5ea6\uff0c\u540c\u65f6\u4fdd\u6301\u76f8\u5f53\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002\u8be5\u65b9\u6cd5\u8fd8\u8868\u73b0\u51fa\u6781\u5feb\u7684\u6536\u655b\u901f\u5ea6\uff0c\u9002\u5408\u5b9e\u9645\u5e94\u7528\u3002", "conclusion": "\u63d0\u51fa\u7684\u8d1d\u53f6\u65af\u4e92\u6613\u6027\u6821\u51c6\u65b9\u6cd5\u4e3a\u4e2d\u7ee7\u8f85\u52a9MIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u51c6\u786e\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728\u4fdd\u6301\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u540c\u65f6\u663e\u8457\u63d0\u5347\u6821\u51c6\u6027\u80fd\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.05802", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.05802", "abs": "https://arxiv.org/abs/2602.05802", "authors": ["Niclas F\u00fchrling", "Getuar Rexhepi", "Giuseppe Abreu"], "title": "Discrete Aware Tensor Completion via Convexized $\\ell_0$-Norm Approximation", "comment": null, "summary": "We consider a novel algorithm, for the completion of partially observed low-rank tensors, where each entry of the tensor can be chosen from a discrete finite alphabet set, such as in common image processing problems, where the entries represent the RGB values. The proposed low-rank tensor completion (TC) method builds on the conventional nuclear norm (NN) minimization-based low-rank TC paradigm, through the addition of a discrete-aware regularizer, which enforces discreteness in the objective of the problem, by an $\\ell_0$-norm regularizer that is approximated by a continuous and differentiable function normalized via fractional programming (FP) under a proximal gradient (PG) framework, in order to solve the proposed problem. Simulation results demonstrate the superior performance of the new method both in terms of normalized mean square error (NMSE) and convergence, compared to the conventional state of-the-art (SotA) techniques, including NN minimization approaches, as well as a mixture of the latter with a matrix factorization approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u79bb\u6563\u5b57\u6bcd\u96c6\u4f4e\u79e9\u5f20\u91cf\u8865\u5168\u7684\u65b0\u7b97\u6cd5\uff0c\u901a\u8fc7\u6dfb\u52a0\u79bb\u6563\u611f\u77e5\u6b63\u5219\u5316\u5668\u589e\u5f3a\u4f20\u7edf\u6838\u8303\u6570\u6700\u5c0f\u5316\u65b9\u6cd5", "motivation": "\u4f20\u7edf\u4f4e\u79e9\u5f20\u91cf\u8865\u5168\u65b9\u6cd5\u5728\u5904\u7406\u79bb\u6563\u503c\uff08\u5982RGB\u56fe\u50cf\u50cf\u7d20\u503c\uff09\u65f6\u6548\u679c\u6709\u9650\uff0c\u9700\u8981\u5f00\u53d1\u80fd\u591f\u540c\u65f6\u5904\u7406\u4f4e\u79e9\u6027\u548c\u79bb\u6563\u6027\u7684\u7b97\u6cd5", "method": "\u5728\u4f20\u7edf\u6838\u8303\u6570\u6700\u5c0f\u5316\u6846\u67b6\u57fa\u7840\u4e0a\uff0c\u6dfb\u52a0\u2113\u2080\u8303\u6570\u6b63\u5219\u5316\u5668\u6765\u5f3a\u5236\u79bb\u6563\u6027\uff0c\u901a\u8fc7\u5206\u6570\u89c4\u5212\u8fd1\u4f3c\u2113\u2080\u8303\u6570\uff0c\u5e76\u5728\u8fd1\u7aef\u68af\u5ea6\u6846\u67b6\u4e0b\u6c42\u89e3", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u65b0\u65b9\u6cd5\u5728\u5f52\u4e00\u5316\u5747\u65b9\u8bef\u5dee\u548c\u6536\u655b\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u73b0\u6709\u6280\u672f\uff0c\u5305\u62ec\u6838\u8303\u6570\u6700\u5c0f\u5316\u65b9\u6cd5\u548c\u77e9\u9635\u5206\u89e3\u6df7\u5408\u65b9\u6cd5", "conclusion": "\u63d0\u51fa\u7684\u79bb\u6563\u611f\u77e5\u4f4e\u79e9\u5f20\u91cf\u8865\u5168\u7b97\u6cd5\u80fd\u6709\u6548\u5904\u7406\u79bb\u6563\u503c\u5f20\u91cf\u8865\u5168\u95ee\u9898\uff0c\u5728\u56fe\u50cf\u5904\u7406\u7b49\u5e94\u7528\u4e2d\u5177\u6709\u4f18\u8d8a\u6027\u80fd"}}
{"id": "2602.05876", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.05876", "abs": "https://arxiv.org/abs/2602.05876", "authors": ["Chenyang Yan", "Mats Bengtsson"], "title": "IDSOR: Intensity- and Distance-Aware Statistical Outlier Removal for Weather-Robust LiDAR Point Clouds", "comment": null, "summary": "LiDAR point clouds captured in rain or snow are often corrupted by weather-induced returns, which can degrade perception and safety-critical scene understanding. This paper proposes Intensity- and Distance-Aware Statistical Outlier Removal (IDSOR), a range-adaptive filtering method that jointly exploits intensity cues and neighborhood sparsity. By incorporating an empirical, range-dependent distribution of weather returns into the threshold design, IDSOR suppresses weather-induced points while preserving fine structural details without cumbersome manual parameter tuning. We also propose a variant that uses a previously proposed method to estimate the weather return distribution from data, and integrates it into IDSOR. Experiments on simulation-augmented level-crossing measurements and on the Winter Adverse Driving dataset (WADS) demonstrate that IDSOR achieves a favorable precision-recall trade-off, maintaining both precision and recall above 90% on WADS.", "AI": {"tldr": "\u63d0\u51faIDSOR\u65b9\u6cd5\uff0c\u5229\u7528\u5f3a\u5ea6\u548c\u8ddd\u79bb\u4fe1\u606f\u81ea\u9002\u5e94\u8fc7\u6ee4\u96e8\u96ea\u5929\u6c14\u4e2d\u7684LiDAR\u566a\u58f0\u70b9\uff0c\u4fdd\u6301\u7ed3\u6784\u7ec6\u8282", "motivation": "\u96e8\u96ea\u5929\u6c14\u4e2d\u7684LiDAR\u70b9\u4e91\u5e38\u53d7\u5929\u6c14\u5f15\u8d77\u7684\u566a\u58f0\u70b9\u6c61\u67d3\uff0c\u8fd9\u4f1a\u964d\u4f4e\u611f\u77e5\u6027\u80fd\u548c\u5173\u952e\u573a\u666f\u7406\u89e3\u7684\u5b89\u5168\u6027", "method": "\u63d0\u51fa\u5f3a\u5ea6-\u8ddd\u79bb\u611f\u77e5\u7edf\u8ba1\u79bb\u7fa4\u70b9\u53bb\u9664(IDSOR)\u65b9\u6cd5\uff0c\u7ed3\u5408\u5f3a\u5ea6\u7ebf\u7d22\u548c\u90bb\u57df\u7a00\u758f\u6027\uff0c\u901a\u8fc7\u7ecf\u9a8c\u6027\u7684\u8ddd\u79bb\u4f9d\u8d56\u5929\u6c14\u8fd4\u56de\u5206\u5e03\u8bbe\u8ba1\u9608\u503c\uff0c\u81ea\u9002\u5e94\u8fc7\u6ee4\u566a\u58f0", "result": "\u5728\u6a21\u62df\u589e\u5f3a\u7684\u6c34\u5e73\u4ea4\u53c9\u6d4b\u91cf\u548cWinter Adverse Driving\u6570\u636e\u96c6(WADS)\u4e0a\u5b9e\u9a8c\uff0cIDSOR\u5728WADS\u4e0a\u4fdd\u6301\u7cbe\u5ea6\u548c\u53ec\u56de\u7387\u5747\u8d85\u8fc790%\uff0c\u8fbe\u5230\u826f\u597d\u7684\u7cbe\u5ea6-\u53ec\u56de\u6743\u8861", "conclusion": "IDSOR\u80fd\u6709\u6548\u6291\u5236\u5929\u6c14\u5f15\u8d77\u7684\u566a\u58f0\u70b9\uff0c\u540c\u65f6\u4fdd\u6301\u7cbe\u7ec6\u7ed3\u6784\u7ec6\u8282\uff0c\u65e0\u9700\u7e41\u7410\u7684\u624b\u52a8\u53c2\u6570\u8c03\u6574"}}

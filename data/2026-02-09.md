<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 8]
- [eess.AS](#eess.AS) [Total: 5]
- [cs.SD](#cs.SD) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [PAPR Reduction in OFDM Systems Using Neural Networks: A Case Study on the Importance of Dataset Generalization](https://arxiv.org/abs/2602.06156)
*Bianca S. de C. da Silva,Pedro H. C. de Souza,Luciano L. Mendes*

Main category: eess.SP

TL;DR: 该研究对先前提出的降低OFDM系统PAPR的神经网络进行了泛化能力测试，验证了模型在未见数据上的有效性，确认了其在实际应用中的稳健性。


<details>
  <summary>Details</summary>
Motivation: 原始研究虽然提出了降低OFDM系统PAPR的神经网络，但缺乏对模型泛化能力的系统评估，无法全面评估模型在不同场景下的鲁棒性和适用性。

Method: 对先前提出的神经网络进行额外的泛化评估测试，使用未见数据验证模型性能，补充和完善原始分析。

Result: 泛化测试结果表明，神经网络仍能将PAPR降低到期望的参考值，且计算成本更低，验证了模型在更广泛场景下的有效性。

Conclusion: 原始研究的主要结论仍然成立：提出的神经网络方法在泛化设置下依然有效，具有实际应用价值，且计算成本更低。

Abstract: In [1], we introduced a NN designed to reduce the PAPR in OFDM systems. However, the original study did not include explicit generalization tests to assess how well the NN would perform on previously unseen data, which prevented a comprehensive evaluation of the model's robustness and applicability in diverse scenarios. To address this gap, we conducted additional generalization assessments, the results of which are presented in this case study. These results serve both to complement and to refine the original analysis reported in [1]. Most importantly, the overall conclusions of the initial study remain valid: the NN is still able to reduce the PAPR level to a desired reference value, also with a lower computational cost, confirming the effectiveness and practical applicability of the proposed method across a more generalized setting.

</details>


### [2] [Hybrid-Field Joint Channel and Visible Region Estimation for RIS-Assisted Communications](https://arxiv.org/abs/2602.06313)
*Xiaokun Tuo,Ming-Min Zhao,Xiang Wang,Changsheng You,Min-Jian Zhao*

Main category: eess.SP

TL;DR: 该论文提出了一种用于RIS辅助毫米波通信系统中非平稳级联信道估计的Turbo结构联合贝叶斯估计方法，解决了混合场传播和部分可见性带来的挑战。


<details>
  <summary>Details</summary>
Motivation: 在RIS辅助的毫米波通信系统中，大规模RIS引入显著的几何效应，导致远场和近场传播共存。随机遮挡引起RIS阵列的空间非平稳性，使得来自不同散射体的信号仅照射部分区域（可见区域），传统信道模型不再适用，信道估计变得特别困难。

Method: 提出了一种降维稀疏双线性表示方法，利用级联信道的结构特性。具体包括：1）字典压缩技术，用低维极域字典加权可见性矩阵表示高维耦合字典；2）Turbo结构联合贝叶斯估计方法，同时估计信道增益、可见区域和离网参数。

Result: 仿真结果表明，所提出的方法相比现有方法显著提高了估计精度。

Conclusion: 该研究解决了RIS辅助毫米波系统中混合场传播和部分可见性带来的信道估计挑战，提出的联合贝叶斯估计方法避免了现有顺序方法的误差传播问题，为实际系统部署提供了有效的解决方案。

Abstract: In reconfigurable intelligent surface (RIS)-assisted millimeter-wave (mmWave) communication systems, the large-scale RIS introduces pronounced geometric effects that lead to the coexistence of far-field and near-field propagation. Furthermore, random blockages induce spatial non-stationarity across the RIS array, causing signals from different scatterers to illuminate only partial regions, referred to as visible regions (VRs). This renders conventional far-field and fully visible array-based channel models inadequate and makes channel estimation particularly challenging. In this paper, we investigate the non-stationary cascaded channel estimation problem in a hybrid-field propagation environment, where the RIS-base station (BS) link operates in the far-field, while the user-RIS link exhibits near-field characteristics with partial visibility. To address the resulting high-dimensional and coupled estimation problem, a reduced-dimensional sparse bilinear representation is developed by exploiting the structural characteristics of the cascaded channel. In particular, a dictionary compression technique is proposed to represent the high-dimensional coupled dictionary using a low-dimensional polar-domain dictionary weighted by a visibility matrix, thereby significantly reducing the problem scale. Based on this representation, a turbo-structured joint Bayesian estimation (TS-JBE) approach is proposed to simultaneously estimate the channel gains, VRs, and off-grid parameters, thereby avoiding error propagation inherent in existing sequential methods. Simulation results demonstrate that the proposed method significantly improves the estimation accuracy compared with existing approaches.

</details>


### [3] [Xona Pulsar Single-Satellite Positioning: System Perspective and Experimental Validation](https://arxiv.org/abs/2602.06376)
*Thyagaraja Marathe,Tyler G. R. Reid,Srinivas Tantry,Michael O'Meara*

Main category: eess.SP

TL;DR: Xona的Pulsar LEO导航系统利用单颗卫星实现定位，特别适用于IoT设备在受限环境中的导航需求，无需外部辅助即可达到米级精度。


<details>
  <summary>Details</summary>
Motivation: 传统导航系统在室内、城市峡谷等受限环境中性能下降，而IoT设备通常受限于尺寸、重量和功耗，无法支持复杂的多传感器架构。需要一种能在卫星可见性极低情况下仍能工作的导航解决方案。

Method: 提出单卫星定位（SSP）概念，利用Pulsar LEO卫星的动态特性和信号强度，仅使用一颗卫星的测量数据来估计用户位置和接收机时钟状态，无需外部辅助。通过高保真星座模拟和实际在轨卫星（Pulsar-0）进行验证。

Result: 仿真和实际测试显示，即使在室内和室外受限环境中，单卫星定位也能达到米级精度。初步测试证明了在各种接收条件下的潜在性能。

Conclusion: Pulsar系统的单卫星定位技术能够在卫星可见性极低的情况下提供可靠的导航能力，特别适合资源受限的IoT平台，为传统导航系统无法覆盖的环境提供了新的解决方案。

Abstract: Xona is deploying Pulsar, a low Earth orbit (LEO) commercial navigation system designed to deliver resilient positioning, navigation, and timing (PNT) where traditional solutions fall short. Pulsar satellites broadcast dedicated signals optimized for commercial users. This brings rapid geometry change, strong Doppler observability, and robust timing, enabling new approaches to positioning even when only one satellite is visible. Internet of Things (IoT) applications often prioritize availability over sub-meter accuracy in urban canyons, semi-indoor spaces, and other constrained environments. Many platforms are battery-powered, have strict size, weight, and power (SWaP) limits, and cannot support complex multi-sensor architectures. Leveraging LEO dynamics and signal strength, Pulsar can maintain navigation capability under these conditions without specialized user hardware.
  Here we present a single-satellite positioning (SSP) concept that uses available Pulsar measurements to estimate user position and receiver clock states without external aiding. Early in Pulsar deployment, only one or two satellites may be in view, yet this still benefits stationary or near-stationary users, including in semi-indoor and indoor settings. We discuss algorithmic details and system implications: SSP enables positioning with minimal satellite visibility, reduces reliance on dense constellations, and supports integration into resource-constrained platforms. We present simulation and live sky results. High-fidelity constellation simulations configured for Pulsar provide controlled performance assessment. We also present early findings from a Pulsar-enabled receiver using observations from the Pulsar-0 satellite on orbit. Preliminary tests demonstrate meter-level accuracy outdoors and indoors, highlighting potential under varied reception conditions.

</details>


### [4] [ARIS-RSMA Enhanced ISAC System: Joint Rate Splitting and Beamforming Design](https://arxiv.org/abs/2602.06399)
*Xin Jin,Tiejun Lv,Yashuai Cao,Jie Zeng,Mugen Peng*

Main category: eess.SP

TL;DR: 提出主动可重构智能表面辅助的速率分割多址接入集成感知通信系统，解决遮挡环境下多目标感知的公平性问题


<details>
  <summary>Details</summary>
Motivation: 在视线被遮挡的环境中，多目标感知存在公平性瓶颈，需要新的系统设计来提升感知性能

Method: 优化收发器和ARIS的波束成形以及速率分割，使用MM和SROCR算法将非凸问题分解为三个子问题迭代求解

Result: 仿真显示该方案优于非正交多址、空分多址和被动RIS基线，接近纯感知的上界

Conclusion: ARIS辅助的RSMA ISAC系统能有效提升遮挡环境下多目标感知的公平性和性能

Abstract: This letter proposes an active reconfigurable intelligent surface (ARIS) assisted rate-splitting multiple access (RSMA) integrated sensing and communication (ISAC) system to overcome the fairness bottleneck in multi-target sensing under obstructed line-of-sight environments. Beamforming at the transceiver and ARIS, along with rate splitting, are optimized to maximize the minimum multi-target echo signal-to-interference-plus-noise ratio under multi-user rate and power constraints. The intricate non-convex problem is decoupled into three subproblems and solved iteratively by majorization-minimization (MM) and sequential rank-one constraint relaxation (SROCR) algorithms. Simulations show our scheme outperforms nonorthogonal multiple access, space-division multiple access, and passive RIS baselines, approaching sensing-only upper bounds.

</details>


### [5] [Lightweight Pilot Estimation on LEO Satellite Signals for Enhanced SOP Navigation](https://arxiv.org/abs/2602.06682)
*Francesco Zanirato,Alessio Curzio,Francesco Ardizzon,Elisa Sbalchiero,Luca Canzian,Stefano Tomasin,Nicola Laurenti,Jaron Samson*

Main category: eess.SP

TL;DR: 该论文提出了一种利用低地球轨道卫星（如Starlink和OneWeb）的宽带下行Ku波段信号作为机会信号进行定位、导航和定时测量的接收机实现指南，能够识别重复符号并计算位置解。


<details>
  <summary>Details</summary>
Motivation: 机会信号（如5G、Wi-Fi、DVB-S）因其普遍性和频谱特性被用于PNT计算，但面临信号调制知识有限和需要识别重复序列进行相关处理的挑战。本文旨在解决利用LEO卫星宽带下行信号进行SOP测量的实现问题。

Method: 整合文献中的最新方法，提出接收机实现指南，能够在前端增益和带宽受限条件下捕获LEO卫星的宽带下行Ku波段信号，识别传输中的重复符号，并利用这些符号收集多普勒频移测量值。

Result: 使用所提模型成功识别了Starlink卫星传输的重复符号，并在600秒时间间隔内收集了多普勒频移测量值。通过最小二乘法计算的位置、速度和时间解，经过后拟合细化后实现了约268米的定位误差。

Conclusion: 该研究为利用LEO卫星机会信号进行PNT测量提供了可行的实现方案，即使在硬件限制条件下也能有效工作，展示了利用商业通信信号进行导航定位的潜力。

Abstract: The computation of positioning, navigation and timing (PNT) via signal of opportunity (SOP), where signals originally transmitted for communication, such as 5G, Wi-Fi, or DVB-S, are exploited due to their ubiquity and spectral characteristics, is an emerging research field. However, relying on these signals presents challenges, including limited knowledge of the signal modulation and the need to identify recurring sequences for correlation. We offer a guide to implement a receiver capable of capturing broadband downlink Ku-band signals from low Earth orbit (LEO) satellites (e.g., Starlink and OneWeb) and estimating the recurring symbols for SOP measurements. The methodology integrates recent approaches in the literature, highlighting the most effective aspects while guiding the replication of experiments even under limitations on the front-end gain and bandwidth. Using the proposed model, we can identify recurring symbols transmitted by Starlink satellites, which are then used to collect Doppler shift measurements over a 600 s interval. A position, velocity, and time (PVT) solution is also computed via least squares (LS), which achieves a positioning error of approximately 268 m after a post-fit refinement.

</details>


### [6] [Multi-Functional RIS-enabled Radar and Communication Coexistence: Channel Modeling and a Sub-6 GHz Indoor Measurement Campaign](https://arxiv.org/abs/2602.06755)
*Anton Tishchenko,Demos Serghiou,Hamidreza Taghvaee,Arman Shojaeifard,Ahmed Elzanaty,Gabriele Gradoni,Mohsen Khalily,Rahim Tafazolli*

Main category: eess.SP

TL;DR: 本文提出了一种多功能可重构智能表面（MF-RIS）支持的雷达通信共存系统，通过DBSCAN聚类和卡尔曼滤波实现实时用户跟踪，建立了3GPP兼容的信道模型，实验显示在5G NR SU-MIMO系统中吞吐量方差降低74%，和速率提升12.5%。


<details>
  <summary>Details</summary>
Motivation: 研究多功能可重构智能表面在雷达通信共存系统中的应用，解决室内Sub-6 GHz传播中的盲点问题，通过创建虚拟视距路径来硬化无线MIMO信道，提高系统性能。

Method: 1) 设计MF-RIS支持的RCC系统架构；2) 开发相位合成码本生成方法；3) 基于DBSCAN聚类和卡尔曼滤波实现实时用户跟踪定位算法；4) 推导3GPP兼容的RCS和再辐射模式信道模型；5) 进行信道测量获取大尺度和小尺度特性参数。

Result: 1) Sub-6 GHz室内传播基本无盲点，即使视距路径被遮挡；2) 在5G NR SU-MIMO系统中，MF-RIS近场区域相比无RIS设置，吞吐量方差降低74%，和速率提升12.5%；3) MF-RIS能减少延迟扩展，增加相干带宽，通过为移动用户创建虚拟视距路径有效硬化无线MIMO信道。

Conclusion: MF-RIS在雷达通信共存系统中能有效改善信道特性，减少盲区，提高系统吞吐量和稳定性，为未来无线通信系统提供了有前景的技术方案。

Abstract: In this work, we analyze a multi-functional reconfigurable intelligent surface (MF-RIS)-enabled radar and communication coexistence (RCC) system, detailing the key aspects of its phase synthesis codebook generation and the implemented localization algorithm for real-time user tracking based on density-based spatial clustering of applications with noise (DBSCAN), which features a Kalman filter for the prediction of user mobility. We derived a 3GPP-compatible radar cross-section (RCS) and re-radiation pattern-based channel model for the described MF-RIS system, supplementing it with channel measurements. We obtained large and small-scale characteristics, including path loss, shadow fading, Rician K-factor, cluster powers, and RMS delay spread. The study finds that Sub-6 GHz indoor propagation is largely free of blind spots, even with a blocked line-of-sight (LoS) path. Therefore, the proposed channel model includes non-line-of-sight (NLoS) paths, including the ones created by the MF-RIS. We also performed an experimental evaluation of the channel throughput in a fifth generation (5G) new radio (NR) single user multiple-input-multiple-output (SU-MIMO) system, reporting a 74\% reduction in throughput variance and a 12.5\% sum-rate improvement within the MF-RIS near-field compared to the no-RIS setup. This result shows that the MF-RIS can minimize delay spread and increase the coherence bandwidth by creating virtual-LoS (vLoS) path for the moving user, thereby effectively hardening wireless MIMO channels.

</details>


### [7] [On the Design of an Optimal Multi-Tone Jammer Against the Wiener Interpolation Filter](https://arxiv.org/abs/2602.06816)
*Corentin Fonteneau*

Main category: eess.SP

TL;DR: 论文质疑传统Wiener插值滤波器抗干扰方法的有效性，设计了一种K音干扰波形，通过优化使干扰难以被估计，证明L/2+1个音调即可使Wiener滤波器抗干扰模块完全失效。


<details>
  <summary>Details</summary>
Motivation: 在军民通信中，抗干扰技术对保障信息完整性至关重要。传统时域方法依赖Wiener插值滤波器估计和抑制干扰波形，广泛认为对宽带系统抗窄带干扰有效。本文质疑这一范式，旨在设计一种难以被Wiener滤波器估计的干扰波形。

Method: 设计K音干扰波形，通过优化程序最大化干扰波形估计的贝叶斯均方误差。提供理论证明：由L/2+1个音调组成的多音干扰波形足以使基于Wiener滤波器的抗干扰模块完全失效。

Result: 理论分析表明，精心设计的K音干扰波形能够有效对抗传统Wiener滤波器抗干扰方法。通过蒙特卡洛仿真验证了理论结果，包括完美已知和实际估计接收信号相关函数两种情况。

Conclusion: 传统Wiener插值滤波器抗干扰方法存在固有弱点，特定设计的K音干扰波形能够使其失效。这挑战了传统抗干扰范式的有效性，对通信安全设计具有重要意义。

Abstract: In the context of civilian and military communications, anti-jamming techniques are essential to ensure information integrity in the presence of malicious interference. A conventional time-domain approach relies on computing the Wiener interpolation filter to estimate and suppress the jamming waveform from the received samples. It is widely acknowledged that this method is effective for protecting wideband systems against narrowband interference. In this work, this paradigm is questioned through the design of a $K$-tone jamming waveform that is intrinsically difficult to estimate assuming a $L$-tap Wiener interpolation filter. This design relies on an optimization procedure that maximizes the analytical Bayesian mean squared error associated with the jamming waveform estimate. Additionally, an analytical proof is provided showing that a multi-tone jamming waveform composed of $L/2+1$ tones is sufficient to render the Wiener-filter-based anti-jamming module completely ineffective. The analytical results are validated through Monte Carlo simulations assuming both perfect knowledge and practical estimates of the correlation functions of the received signal.

</details>


### [8] [Bridging 6G IoT and AI: LLM-Based Efficient Approach for Physical Layer's Optimization Tasks](https://arxiv.org/abs/2602.06819)
*Ahsan Mehmood,Naveed Ul Hassan,Ghassan M. Kraidy*

Main category: eess.SP

TL;DR: 提出基于提示工程的实时反馈验证框架PE-RTFV，利用大语言模型在6G物联网中实现无需重新训练的物理层优化


<details>
  <summary>Details</summary>
Motivation: 探索大语言模型在6G物联网网络中的作用，解决物理层优化任务需要模型重新训练的问题，利用无线通信系统固有的闭环反馈实现实时优化

Method: 提出PE-RTFV框架：使用优化LLM生成任务特定的结构化提示，提供给代理LLM产生解决方案；利用实时系统反馈，优化LLM迭代改进提示，以梯度下降式过程引导代理LLM获得更好解

Result: 在无线供电物联网测试平台上进行用户目标驱动的星座设计案例研究，通过语义解决速率-能量区域优化问题，PE-RTFV在仅几次迭代内达到接近遗传算法的性能

Conclusion: PE-RTFV框架有效解决了资源受限物联网网络中复杂物理层优化任务，无需模型重新训练，实现了实时优化

Abstract: This paper investigates the role of large language models (LLMs) in sixth-generation (6G) Internet of Things (IoT) networks and proposes a prompt-engineering-based real-time feedback and verification (PE-RTFV) framework that perform physical-layer's optimization tasks through an iteratively process. By leveraging the naturally available closed-loop feedback inherent in wireless communication systems, PE-RTFV enables real-time physical-layer optimization without requiring model retraining. The proposed framework employs an optimization LLM (O-LLM) to generate task-specific structured prompts, which are provided to an agent LLM (A-LLM) to produce task-specific solutions. Utilizing real-time system feedback, the O-LLM iteratively refines the prompts to guide the A-LLM toward improved solutions in a gradient-descent-like optimization process. We test PE-RTFV approach on wireless-powered IoT testbed case study on user-goal-driven constellation design through semantically solving rate-energy (RE)-region optimization problem which demonstrates that PE-RTFV achieves near-genetic-algorithm performance within only a few iterations, validating its effectiveness for complex physical-layer optimization tasks in resource-constrained IoT networks.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [9] [STACodec: Semantic Token Assignment for Balancing Acoustic Fidelity and Semantic Information in Audio Codecs](https://arxiv.org/abs/2602.06180)
*Kaiyuan Zhang,Mohan Shi,Eray Eren,Natarajan Balaji Shankar,Zilai Wang,Abeer Alwan*

Main category: eess.AS

TL;DR: STACodec是一个统一的音频编解码器，通过语义令牌分配将自监督学习的语义信息集成到残差向量量化的第一层，实现了声学保真度和语义能力的更好平衡。


<details>
  <summary>Details</summary>
Motivation: 传统神经音频编解码器能很好地保留声学细节但缺乏语义信息，而现有的混合编解码器通过蒸馏整合语义信息时往往会降低重建性能，难以同时实现声学保真和语义能力。

Method: 1. 通过语义令牌分配将自监督学习模型的语义信息集成到RVQ-1层；2. 提出语义预蒸馏模块，在推理时直接预测语义令牌分配给第一RVQ层，消除对SSL语义分词器的依赖并提高效率。

Result: 实验结果表明，STACodec在音频重建和下游语义任务上都优于现有的混合编解码器，在声学保真度和语义能力之间取得了更好的平衡。

Conclusion: STACodec成功解决了传统编解码器缺乏语义信息和混合编解码器重建性能下降的问题，实现了声学保真与语义能力的统一，为音频压缩和基于令牌的语言模型集成提供了更好的解决方案。

Abstract: Neural audio codecs are widely used for audio compression and can be integrated into token-based language models. Traditional codecs preserve acoustic details well but lack semantic information. Recent hybrid codecs attempt to incorporate semantic information through distillation, but this often degrades reconstruction performance, making it difficult to achieve both. To address this limitation, we introduce STACodec, a unified codec that integrates semantic information from self-supervised learning (SSL) models into the first layer of residual vector quantization (RVQ-1) via semantic token assignment (STA). To further eliminate reliance on SSL-based semantic tokenizers and improve efficiency during inference, we propose a semantic pre-distillation (SPD) module, which predicts semantic tokens directly for assignment to the first RVQ layer during inference. Experimental results show that STACodec outperforms existing hybrid codecs in both audio reconstruction and downstream semantic tasks, demonstrating a better balance between acoustic fidelity and semantic capability.

</details>


### [10] [From Hallucination to Articulation: Language Model-Driven Losses for Ultra Low-Bitrate Neural Speech Coding](https://arxiv.org/abs/2602.06213)
*Jayeon Yi,Minje Kim*

Main category: eess.AS

TL;DR: 该论文提出使用语言模型驱动的损失函数来缓解低比特率语音编解码器中的音素幻觉问题，相比语义蒸馏目标在极低比特率下效果更好。


<details>
  <summary>Details</summary>
Motivation: 低比特率DNN编解码器中常出现"音素幻觉"现象，这是生成式解码器在语义信息过度压缩丢失时尝试合成合理输出的结果。需要更好的方法来缓解这一问题。

Method: 提出两种语言模型驱动的损失函数：1）当无真实文本时，修改Whisper ASR模型比较解码语音与ASR推断的文本；2）使用定时文本正则化器比较解码语音的WavLM表示与真实文本的BERT表示。这些方法基于预训练的语言模型来关联语音与文本。

Result: 主观和客观评估表明，语言模型损失比语义蒸馏目标能提供更强的指导，从自监督语音表示中提取语义信息，提升人类感知的语义一致性，同时保持整体输出质量。

Conclusion: 语言模型驱动的损失函数在极低比特率设置下能有效缓解音素幻觉问题，比语义蒸馏方法更有效，增强了语义信息的提取能力。

Abstract: ``Phoneme Hallucinations (PH)'' commonly occur in low-bitrate DNN-based codecs. It is the generative decoder's attempt to synthesize plausible outputs from excessively compressed tokens missing some semantic information. In this work, we propose language model-driven losses (LM loss) and show they may alleviate PHs better than a semantic distillation (SD) objective in very-low-bitrate settings. The proposed LM losses build upon language models pretrained to associate speech with text. When ground-truth transcripts are unavailable, we propose to modify a popular automatic speech recognition (ASR) model, Whisper, to compare the decoded utterance against the ASR-inferred transcriptions of the input speech. Else, we propose to use the timed-text regularizer (TTR) to compare WavLM representations of the decoded utterance against BERT representations of the ground-truth transcriptions. We test and compare LM losses against an SD objective, using a reference codec whose three-stage training regimen was designed after several popular codecs. Subjective and objective evaluations conclude that LM losses may provide stronger guidance to extract semantic information from self-supervised speech representations, boosting human-perceived semantic adherence while preserving overall output quality. Demo samples, code, and checkpoints are available online.

</details>


### [11] [B-GRPO: Unsupervised Speech Emotion Recognition based on Batched-Group Relative Policy Optimization](https://arxiv.org/abs/2602.06290)
*Yingying Gao,Shilei Zhang,Runyan Yang,Zihao Cui,Junlan Feng*

Main category: eess.AS

TL;DR: 本文提出一种基于强化学习的无监督语音情感识别方法，通过改进的GRPO算法和自奖励/教师奖励函数来评估样本质量，提升模型性能19.8%


<details>
  <summary>Details</summary>
Motivation: 解决语音情感识别中数据稀疏和标注偏差的问题，传统监督方法依赖人工标注，成本高且存在偏差，需要无监督或弱监督的解决方案

Method: 将样本选择过程建模为长期决策问题，使用强化学习评估样本质量；提出改进的GRPO算法适应分类任务，采用批次样本作为组计算优势；设计自奖励函数和教师奖励函数鼓励模型产生高置信度输出

Result: 实验表明，提出的方法相比无强化学习的基线模型，性能提升了19.8%

Conclusion: 强化学习可以有效应用于无监督语音情感识别，通过合理的奖励函数设计和GRPO改进，能够显著提升模型性能，为解决数据标注问题提供新思路

Abstract: Unsupervised speech emotion recognition (SER) focuses on addressing the problem of data sparsity and annotation bias of emotional speech. Reinforcement learning (RL) is a promising method which enhances the performance through rule-based or model-based verification functions rather than human annotations. We treat the sample selection during the learning process as a long-term procedure and whether to select a sample as the action to make policy, thus achieving the application of RL to measure sample quality in SER. We propose a modified Group Relative Policy Optimization (GRPO) to adapt it to classification problems, which takes the samples in a batch as a group and uses the average reward of these samples as the baseline to calculate the advantage. And rather than using a verifiable reward function as in GRPO, we put forward self-reward functions and teacher-reward functions to encourage the model to produce high-confidence outputs. Experiments indicate that the proposed method improves the performance of baseline without RL by 19.8%.

</details>


### [12] [Automatic Detection and Analysis of Singing Mistakes for Music Pedagogy](https://arxiv.org/abs/2602.06917)
*Sumit Kumar,Suraj Jaiswal,Parampreet Singh,Vipul Arora*

Main category: eess.AS

TL;DR: 提出一个基于深度学习的自动歌唱错误检测框架，包含新标注的数据集和评估方法，在音乐教育中优于基于规则的方法。


<details>
  <summary>Details</summary>
Motivation: 机器学习在音频分析中的发展为技术增强的音乐教育提供了新可能。当前需要自动化的歌唱错误检测系统来辅助音乐教学。

Method: 1) 构建包含教师-学习者同步录音的新数据集，标注学习者错误类型；2) 开发多种深度学习模型进行错误检测；3) 提出新的评估方法比较错误检测系统效果。

Result: 实验表明，提出的基于学习的方法优于基于规则的方法。通过系统错误分析和跨教师研究，揭示了音乐教学法的见解，可用于各种音乐应用。

Conclusion: 这项工作为音乐教学法研究设定了新方向，代码和数据集已公开，有助于推动技术增强的音乐教育发展。

Abstract: The advancement of machine learning in audio analysis has opened new possibilities for technology-enhanced music education. This paper introduces a framework for automatic singing mistake detection in the context of music pedagogy, supported by a newly curated dataset. The dataset comprises synchronized teacher learner vocal recordings, with annotations marking different types of mistakes made by learners. Using this dataset, we develop different deep learning models for mistake detection and benchmark them. To compare the efficacy of mistake detection systems, a new evaluation methodology is proposed. Experiments indicate that the proposed learning-based methods are superior to rule-based methods. A systematic study of errors and a cross-teacher study reveal insights into music pedagogy that can be utilised for various music applications. This work sets out new directions of research in music pedagogy. The codes and dataset are publicly available.

</details>


### [13] [The Combination of Several Decorrelation Methods to Improve Acoustic Feedback Cancellation](https://arxiv.org/abs/2602.06921)
*Klaus Linhard,Philipp Bulling*

Main category: eess.AS

TL;DR: 本文扩展了基于频域卡尔曼滤波器的声学反馈消除系统，通过整合多种去相关方法（可变时延线、预测、失真补偿和简化混响模型）来提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有文献通常只关注单一扩展方法（如预测）来构建最优系统，但本文认为每个扩展都能独立贡献性能提升，且组合所有扩展能获得更优的系统性能。

Method: 在基于多延迟结构的频域卡尔曼滤波器基础上，引入了四种扩展：可变时延线、预测、失真补偿和简化混响模型，并对每个扩展进行了分析并定义了实用参数范围。

Result: 评估使用公开数据集，通过系统距离度量和客观语音质量指标PSEQ进行性能评估。结果表明每个扩展都能独立提升性能，且所有扩展组合后能获得最优的系统性能。

Conclusion: 通过整合多种去相关方法扩展声学反馈消除系统，每个扩展都有独立贡献，组合所有扩展能获得最佳性能，为实际系统设计提供了实用参数指导。

Abstract: This paper extends an acoustic feedback cancellation system by incorporating multiple decorrelation methods. The baseline system is based on a frequency-domain Kalman filter implemented in a multi-delay structure. The proposed extensions include a variable time delay line, prediction, distortion compensation, and a simplified reverberation model. Each extension is analyzed, and a practical parameter range is defined.
  While existing literature often focuses on a single extension, such as prediction, to describe an optimal system, this work demonstrates that each individual extension contributes to performance improvements. Furthermore, the combination of all proposed extensions results in a superior system. The evaluation is conducted using publicly available datasets, with performance assessed through system distance metrics and the objective speech quality measure PSEQ.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [14] [Misophonia Trigger Sound Detection on Synthetic Soundscapes Using a Hybrid Model with a Frozen Pre-Trained CNN and a Time-Series Module](https://arxiv.org/abs/2602.06271)
*Kurumi Sashida,Gouhei Tanaka*

Main category: cs.SD

TL;DR: 研究开发了针对恐音症触发声音的合成音景生成和检测系统，使用混合CNN模型结合不同时序模块，双向GRU表现最佳，双向ESN参数更少但性能接近，在个性化检测任务中表现稳定。


<details>
  <summary>Details</summary>
Motivation: 恐音症患者对特定日常声音（触发声音）产生强烈负面情绪反应，严重影响生活质量。由于真实世界恐音症数据稀缺，需要开发能够选择性检测触发声音的辅助技术来帮助患者减轻痛苦。

Method: 1. 使用音频合成技术生成针对恐音症触发声音检测的合成音景；2. 采用混合CNN模型，结合冻结的预训练CNN骨干网络进行特征提取，以及可训练的时间序列模块（GRU、LSTM、ESN及其双向变体）；3. 在多类触发声音检测任务中评估性能；4. 通过少量样本的"进食声音"检测任务模拟用户个性化需求。

Result: 在多类触发声音检测任务中，双向时序建模持续提升检测性能，双向GRU（BiGRU）获得最佳整体准确率。双向ESN（BiESN）仅需数量级更少的可训练参数（仅优化读出层）即达到竞争性性能。在个性化检测任务中，BiESN表现出稳健稳定的性能。

Conclusion: 轻量级时序模块（特别是双向ESN）对于个性化的恐音症触发声音检测具有前景，能够在参数效率高的同时保持良好性能，适合实际应用中的个性化需求。

Abstract: Misophonia is a disorder characterized by a decreased tolerance to specific everyday sounds (trigger sounds) that can evoke intense negative emotional responses such as anger, panic, or anxiety. These reactions can substantially impair daily functioning and quality of life. Assistive technologies that selectively detect trigger sounds could help reduce distress and improve well-being. In this study, we investigate sound event detection (SED) to localize intervals of trigger sounds in continuous environmental audio as a foundational step toward such assistive support. Motivated by the scarcity of real-world misophonia data, we generate synthetic soundscapes tailored to misophonia trigger sound detection using audio synthesis techniques. Then, we perform trigger sound detection tasks using hybrid CNN-based models. The models combine feature extraction using a frozen pre-trained CNN backbone with a trainable time-series module such as gated recurrent units (GRUs), long short-term memories (LSTMs), echo state networks (ESNs), and their bidirectional variants. The detection performance is evaluated using common SED metrics, including Polyphonic Sound Detection Score 1 (PSDS1). On the multi-class trigger SED task, bidirectional temporal modeling consistently improves detection performance, with Bidirectional GRU (BiGRU) achieving the best overall accuracy. Notably, the Bidirectional ESN (BiESN) attains competitive performance while requiring orders of magnitude fewer trainable parameters by optimizing only the readout. We further simulate user personalization via a few-shot "eating sound" detection task with at most five support clips, in which BiGRU and BiESN are compared. In this strict adaptation setting, BiESN shows robust and stable performance, suggesting that lightweight temporal modules are promising for personalized misophonia trigger SED.

</details>


### [15] [EMG-to-Speech with Fewer Channels](https://arxiv.org/abs/2602.06460)
*Injune Hwang,Jaejun Lee,Kyogu Lee*

Main category: cs.SD

TL;DR: 该研究探讨了表面肌电图（EMG）通道对无声语音重建性能的影响，发现互补通道组合性能最佳，并提出通过预训练和通道感知设计缓解传感器减少带来的性能下降。


<details>
  <summary>Details</summary>
Motivation: 表面肌电图（EMG）是无声语音接口的有前景的模态，但其效果严重依赖于传感器放置和通道可用性。研究旨在了解单个和组合EMG通道对语音重建性能的贡献，以支持轻量级实用EMG无声语音系统的开发。

Method: 研究分析了单个和组合EMG通道对语音重建性能的影响，包括音素分类准确性在通道消融下的表现。为应对通道减少导致的性能下降，采用在完整8通道数据上预训练模型（使用随机通道丢弃）并在减少通道子集上微调的方法。

Result: 研究发现某些EMG通道单独更具信息性，但最高性能来自利用通道间互补关系的子集。音素分类准确性在通道消融下显示出反映底层肌肉解剖作用的可解释模式。微调在4-6通道设置中始终优于从头训练，最佳丢弃策略取决于通道数量。

Conclusion: 通过预训练和通道感知设计可以缓解传感器减少带来的性能下降，这支持了轻量级实用EMG无声语音系统的开发。研究结果为优化EMG传感器配置提供了指导。

Abstract: Surface electromyography (EMG) is a promising modality for silent speech interfaces, but its effectiveness depends heavily on sensor placement and channel availability. In this work, we investigate the contribution of individual and combined EMG channels to speech reconstruction performance. Our findings reveal that while certain EMG channels are individually more informative, the highest performance arises from subsets that leverage complementary relationships among channels. We also analyzed phoneme classification accuracy under channel ablations and observed interpretable patterns reflecting the anatomical roles of the underlying muscles. To address performance degradation from channel reduction, we pretrained models on full 8-channel data using random channel dropout and fine-tuned them on reduced-channel subsets. Fine-tuning consistently outperformed training from scratch for 4 - 6 channel settings, with the best dropout strategy depending on the number of channels. These results suggest that performance degradation from sensor reduction can be mitigated through pretraining and channel-aware design, supporting the development of lightweight and practical EMG-based silent speech systems.

</details>


### [16] [Scaling Speech Tokenizers with Diffusion Autoencoders](https://arxiv.org/abs/2602.06602)
*Yuancheng Wang,Zhenyu Tang,Yun Wang,Arthur Hinsvark,Yingru Liu,Yinghao Li,Kainan Peng,Junyi Ao,Mingbo Ma,Mike Seltzer,Qing He,Xubo Liu*

Main category: cs.SD

TL;DR: Speech Diffusion Tokenizer (SiTok) 是一种扩散自编码器，通过监督学习联合学习语义丰富的表示，同时利用扩散实现高保真音频重建，在极低的12.5Hz令牌率和200bps比特率下，在理解、重建和生成任务上超越现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有语音分词器面临两大挑战：1）在编码语义（用于理解）和声学（用于重建）之间的权衡；2）实现低比特率和低令牌率。需要一种能同时解决这两个问题的语音分词方法。

Method: 提出Speech Diffusion Tokenizer (SiTok)，一种扩散自编码器，通过监督学习联合学习语义丰富的表示，并利用扩散实现高保真音频重建。将模型扩展到16亿参数，在200万小时的语音数据上进行训练。

Result: SiTok在理解、重建和生成任务上均优于强基线模型，同时实现了极低的12.5Hz令牌率和200bps比特率，在语义编码和声学重建之间取得了良好平衡。

Conclusion: SiTok通过扩散自编码器框架成功解决了语音分词器在语义-声学权衡和低速率方面的挑战，为语音语言模型提供了高质量的语音表示基础。

Abstract: Speech tokenizers are foundational to speech language models, yet existing approaches face two major challenges: (1) balancing trade-offs between encoding semantics for understanding and acoustics for reconstruction, and (2) achieving low bit rates and low token rates. We propose Speech Diffusion Tokenizer (SiTok), a diffusion autoencoder that jointly learns semantic-rich representations through supervised learning and enables high-fidelity audio reconstruction with diffusion. We scale SiTok to 1.6B parameters and train it on 2 million hours of speech. Experiments show that SiTok outperforms strong baselines on understanding, reconstruction and generation tasks, at an extremely low token rate of $12.5$ Hz and a bit-rate of 200 bits-per-second.

</details>


### [17] [Hierarchical Activity Recognition and Captioning from Long-Form Audio](https://arxiv.org/abs/2602.06765)
*Peng Zhang,Qingyu Luo,Philip J. B. Jackson,Wenwu Wang*

Main category: cs.SD

TL;DR: MultiAct：用于长音频多级结构化理解的新数据集和基准，包含厨房录音的三级语义标注（活动、子活动、事件），并提出统一层次模型进行多任务学习。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的复杂音频活动持续时间长且具有层次结构，但现有研究大多关注短片段和孤立事件。需要填补这一研究空白，实现对长音频的多层次结构化理解。

Method: 引入MultiAct数据集，包含长时间厨房录音，标注了三个语义层次（活动、子活动、事件），并配有细粒度描述和高层摘要。提出统一的层次模型，联合执行分类、检测、序列预测和多分辨率描述生成。

Result: 在MultiAct上建立了强基线，揭示了建模长音频层次和组合结构的关键挑战。实验表明需要更好的方法来捕捉长音频中的复杂长程关系。

Conclusion: MultiAct为长音频多层次理解提供了新的数据集和基准，未来研究方向是探索更适合捕捉长音频中复杂长程关系的方法。

Abstract: Complex activities in real-world audio unfold over extended durations and exhibit hierarchical structure, yet most prior work focuses on short clips and isolated events. To bridge this gap, we introduce MultiAct, a new dataset and benchmark for multi-level structured understanding of human activities from long-form audio. MultiAct comprises long-duration kitchen recordings annotated at three semantic levels (activities, sub-activities and events) and paired with fine-grained captions and high-level summaries. We further propose a unified hierarchical model that jointly performs classification, detection, sequence prediction and multi-resolution captioning. Experiments on MultiAct establish strong baselines and reveal key challenges in modelling hierarchical and compositional structure of long-form audio. A promising direction for future work is the exploration of methods better suited to capturing the complex, long-range relationships in long-form audio.

</details>


### [18] [AI-Generated Music Detection in Broadcast Monitoring](https://arxiv.org/abs/2602.06823)
*David Lopez-Ayala,Asier Cabello,Pablo Zinemanas,Emilio Molina,Martin Rocamora*

Main category: cs.SD

TL;DR: AI-OpenBMAT是首个针对广播音频场景的AI音乐检测数据集，包含3294个一分钟音频片段，模拟真实电视音频的时长模式和响度关系，用于评估AI音乐检测器在广播环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有AI音乐检测方法主要在音乐流媒体场景中设计和验证，使用干净、完整的音轨。但广播音频中音乐通常以短片段出现，且常被主导语音掩盖，现有检测器在这些条件下表现不佳。

Method: 创建AI-OpenBMAT数据集，包含3294个一分钟音频片段（54.9小时），模拟真实电视音频的时长模式和响度关系。数据集结合人工制作的制作音乐和使用Suno v3.5生成的风格匹配的延续音乐。使用CNN基线和最先进的SpectTTTra模型进行基准测试，评估信噪比和时长鲁棒性。

Result: 在流媒体场景中表现优异的模型在广播场景中性能显著下降，当音乐处于背景或时长较短时，F1分数降至60%以下。语音掩盖和短音乐长度成为AI音乐检测的关键挑战。

Conclusion: AI-OpenBMAT为开发满足工业广播要求的检测器提供了基准，突出了广播环境中AI音乐检测的特殊挑战，特别是语音掩盖和短音乐片段问题。

Abstract: AI music generators have advanced to the point where their outputs are often indistinguishable from human compositions. While detection methods have emerged, they are typically designed and validated in music streaming contexts with clean, full-length tracks. Broadcast audio, however, poses a different challenge: music appears as short excerpts, often masked by dominant speech, conditions under which existing detectors fail. In this work, we introduce AI-OpenBMAT, the first dataset tailored to broadcast-style AI-music detection. It contains 3,294 one-minute audio excerpts (54.9 hours) that follow the duration patterns and loudness relations of real television audio, combining human-made production music with stylistically matched continuations generated with Suno v3.5. We benchmark a CNN baseline and state-of-the-art SpectTTTra models to assess SNR and duration robustness, and evaluate on a full broadcast scenario. Across all settings, models that excel in streaming scenarios suffer substantial degradation, with F1-scores dropping below 60% when music is in the background or has a short duration. These results highlight speech masking and short music length as critical open challenges for AI music detection, and position AI-OpenBMAT as a benchmark for developing detectors capable of meeting industrial broadcast requirements.

</details>


### [19] [DynFOA: Generating First-Order Ambisonics with Conditional Diffusion for Dynamic and Acoustically Complex 360-Degree Videos](https://arxiv.org/abs/2602.06846)
*Ziyu Luo,Lin Chen,Qiang Qu,Xiaoming Chen,Yiran Shen*

Main category: cs.SD

TL;DR: DynFOA：基于动态声学感知和条件扩散的框架，从360度视频生成高保真一阶Ambisonics空间音频，解决了复杂声学场景中的动态声源和环境效应问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成360度视频的空间音频时存在局限性：忽视场景的动态性和声学复杂性，未能充分考虑动态声源，忽略由场景几何和材料影响的遮挡、反射、混响等环境效应。

Method: DynFOA首先通过视频编码器进行视觉处理，检测和定位多个动态声源，估计其深度和语义，使用3D高斯溅射重建场景几何和材料。音频编码器捕捉空间运动和时间4D声源轨迹，微调基于扩散的FOA生成器，实时调整空间线索。

Result: 广泛评估表明，DynFOA在空间精度、声学保真度和分布匹配等指标上持续优于现有方法，同时改善了用户体验。

Conclusion: DynFOA为VR和沉浸式媒体应用提供了强大且可扩展的渲染真实动态空间音频的方法。

Abstract: Spatial audio is crucial for creating compelling immersive 360-degree video experiences. However, generating realistic spatial audio, such as first-order ambisonics (FOA), from 360-degree videos in complex acoustic scenes remains challenging. Existing methods often overlook the dynamic nature and acoustic complexity of 360-degree scenes, fail to fully account for dynamic sound sources, and neglect complex environmental effects such as occlusion, reflections, and reverberation, which are influenced by scene geometries and materials. We propose DynFOA, a framework based on dynamic acoustic perception and conditional diffusion, for generating high-fidelity FOA from 360-degree videos. DynFOA first performs visual processing via a video encoder, which detects and localizes multiple dynamic sound sources, estimates their depth and semantics, and reconstructs the scene geometry and materials using a 3D Gaussian Splatting. This reconstruction technique accurately models occlusion, reflections, and reverberation based on the geometries and materials of the reconstructed 3D scene and the listener's viewpoint. The audio encoder then captures the spatial motion and temporal 4D sound source trajectories to fine-tune the diffusion-based FOA generator. The fine-tuned FOA generator adjusts spatial cues in real time, ensuring consistent directional fidelity during listener head rotation and complex environmental changes. Extensive evaluations demonstrate that DynFOA consistently outperforms existing methods across metrics such as spatial accuracy, acoustic fidelity, and distribution matching, while also improving the user experience. Therefore, DynFOA provides a robust and scalable approach to rendering realistic dynamic spatial audio for VR and immersive media applications.

</details>


### [20] [Reciprocal Latent Fields for Precomputed Sound Propagation](https://arxiv.org/abs/2602.06937)
*Hugo Seuté,Pranai Vasudev,Etienne Richan,Louis-Xavier Buffoni*

Main category: cs.SD

TL;DR: RLF框架使用可训练的潜在嵌入体网格和对称解码函数，通过Riemannian度量学习高效编码声学参数，大幅减少内存占用，同时保持感知上无法区分的音质。


<details>
  <summary>Details</summary>
Motivation: 基于波的声传播模拟计算成本高，而现有的波编码方法在大型场景中会产生难以管理的参数规模，需要更高效的内存编码方案。

Method: 提出Reciprocal Latent Fields (RLF)框架，使用可训练的潜在嵌入体网格，通过对称解码函数确保声学互易性，并利用Riemannian度量学习来更好地复现复杂场景中的声学现象。

Result: RLF在保持复制质量的同时，将内存占用减少了数个数量级。主观听力测试表明，通过RLF渲染的声音在感知上与真实模拟无法区分。

Conclusion: RLF为实时虚拟场景中的逼真声传播提供了一种内存高效且感知准确的解决方案，解决了现有波编码方法在大型环境中的可扩展性问题。

Abstract: Realistic sound propagation is essential for immersion in a virtual scene, yet physically accurate wave-based simulations remain computationally prohibitive for real-time applications. Wave coding methods address this limitation by precomputing and compressing impulse responses of a given scene into a set of scalar acoustic parameters, which can reach unmanageable sizes in large environments with many source-receiver pairs. We introduce Reciprocal Latent Fields (RLF), a memory-efficient framework for encoding and predicting these acoustic parameters. The RLF framework employs a volumetric grid of trainable latent embeddings decoded with a symmetric function, ensuring acoustic reciprocity. We study a variety of decoders and show that leveraging Riemannian metric learning leads to a better reproduction of acoustic phenomena in complex scenes. Experimental validation demonstrates that RLF maintains replication quality while reducing the memory footprint by several orders of magnitude. Furthermore, a MUSHRA-like subjective listening test indicates that sound rendered via RLF is perceptually indistinguishable from ground-truth simulations.

</details>

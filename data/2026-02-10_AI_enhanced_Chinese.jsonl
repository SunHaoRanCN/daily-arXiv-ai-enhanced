{"id": "2602.07803", "categories": ["eess.AS", "cs.AI", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.07803", "abs": "https://arxiv.org/abs/2602.07803", "authors": ["Jiale Qian", "Hao Meng", "Tian Zheng", "Pengcheng Zhu", "Haopeng Lin", "Yuhang Dai", "Hanke Xie", "Wenxiao Cao", "Ruixuan Shang", "Jun Wu", "Hongmei Liu", "Hanlin Wen", "Jian Zhao", "Zhonglin Jiang", "Yong Chen", "Shunshun Yin", "Ming Tao", "Jianguo Wei", "Lei Xie", "Xinsheng Wang"], "title": "SoulX-Singer: Towards High-Quality Zero-Shot Singing Voice Synthesis", "comment": "Technical Report", "summary": "While recent years have witnessed rapid progress in speech synthesis, open-source singing voice synthesis (SVS) systems still face significant barriers to industrial deployment, particularly in terms of robustness and zero-shot generalization. In this report, we introduce SoulX-Singer, a high-quality open-source SVS system designed with practical deployment considerations in mind. SoulX-Singer supports controllable singing generation conditioned on either symbolic musical scores (MIDI) or melodic representations, enabling flexible and expressive control in real-world production workflows. Trained on more than 42,000 hours of vocal data, the system supports Mandarin Chinese, English, and Cantonese and consistently achieves state-of-the-art synthesis quality across languages under diverse musical conditions. Furthermore, to enable reliable evaluation of zero-shot SVS performance in practical scenarios, we construct SoulX-Singer-Eval, a dedicated benchmark with strict training-test disentanglement, facilitating systematic assessment in zero-shot settings.", "AI": {"tldr": "SoulX-Singer\u662f\u4e00\u4e2a\u9ad8\u8d28\u91cf\u5f00\u6e90\u6b4c\u5531\u58f0\u97f3\u5408\u6210\u7cfb\u7edf\uff0c\u652f\u6301\u591a\u8bed\u8a00\uff0c\u57fa\u4e8e42000\u5c0f\u65f6\u6570\u636e\u8bad\u7ec3\uff0c\u5728\u96f6\u6837\u672c\u573a\u666f\u4e0b\u8868\u73b0\u4f18\u5f02", "motivation": "\u5f53\u524d\u5f00\u6e90\u6b4c\u5531\u58f0\u97f3\u5408\u6210\u7cfb\u7edf\u5728\u5de5\u4e1a\u90e8\u7f72\u4e2d\u9762\u4e34\u9c81\u68d2\u6027\u548c\u96f6\u6837\u672c\u6cdb\u5316\u65b9\u9762\u7684\u6311\u6218\uff0c\u9700\u8981\u66f4\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u5f00\u53d1\u652f\u6301\u7b26\u53f7\u4e50\u8c31\uff08MIDI\uff09\u6216\u65cb\u5f8b\u8868\u793a\u6761\u4ef6\u63a7\u5236\u7684SVS\u7cfb\u7edf\uff0c\u8bad\u7ec3\u4e8e42000\u5c0f\u65f6\u4eba\u58f0\u6570\u636e\uff0c\u652f\u6301\u666e\u901a\u8bdd\u3001\u82f1\u8bed\u548c\u7ca4\u8bed", "result": "\u7cfb\u7edf\u5728\u4e0d\u540c\u8bed\u8a00\u548c\u97f3\u4e50\u6761\u4ef6\u4e0b\u5747\u8fbe\u5230\u6700\u5148\u8fdb\u7684\u5408\u6210\u8d28\u91cf\uff0c\u5e76\u6784\u5efa\u4e86\u4e13\u95e8\u7684\u96f6\u6837\u672c\u8bc4\u4f30\u57fa\u51c6SoulX-Singer-Eval", "conclusion": "SoulX-Singer\u4e3a\u5de5\u4e1a\u90e8\u7f72\u63d0\u4f9b\u4e86\u9ad8\u8d28\u91cf\u3001\u53ef\u63a7\u7684\u5f00\u6e90\u6b4c\u5531\u58f0\u97f3\u5408\u6210\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u96f6\u6837\u672c\u6cdb\u5316\u8bc4\u4f30\u7684\u6311\u6218"}}
{"id": "2602.07977", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2602.07977", "abs": "https://arxiv.org/abs/2602.07977", "authors": ["Haoyu Li", "Yu Xi", "Yidi Jiang", "Shuai Wang", "Kate Knill", "Mark Gales", "Haizhou Li", "Kai Yu"], "title": "Detect, Attend and Extract: Keyword Guided Target Speaker Extraction", "comment": "4 figures, 4 tables. Submitted to IJCAI-ECAI 2026", "summary": "Target speaker extraction (TSE) aims to extract the speech of a target speaker from mixtures containing multiple competing speakers. Conventional TSE systems predominantly rely on speaker cues, such as pre-enrolled speech, to identify and isolate the target speaker. However, in many practical scenarios, clean enrollment utterances are unavailable, limiting the applicability of existing approaches. In this work, we propose DAE-TSE, a keyword-guided TSE framework that specifies the target speaker through distinct keywords they utter. By leveraging keywords (i.e., partial transcriptions) as cues, our approach provides a flexible and practical alternative to enrollment-based TSE. DAE-TSE follows the Detect-Attend-Extract (DAE) paradigm: it first detects the presence of the given keywords, then attends to the corresponding speaker based on the keyword content, and finally extracts the target speech. Experimental results demonstrate that DAE-TSE outperforms standard TSE systems that rely on clean enrollment speech. To the best of our knowledge, this is the first study to utilize partial transcription as a cue for specifying the target speaker in TSE, offering a flexible and practical solution for real-world scenarios. Our code and demo page are now publicly available.", "AI": {"tldr": "\u63d0\u51faDAE-TSE\u6846\u67b6\uff0c\u4f7f\u7528\u5173\u952e\u8bcd\u800c\u975e\u9884\u6ce8\u518c\u8bed\u97f3\u4f5c\u4e3a\u76ee\u6807\u8bf4\u8bdd\u4eba\u63d0\u53d6\u7684\u7ebf\u7d22\uff0c\u89e3\u51b3\u5b9e\u9645\u573a\u666f\u4e2d\u5e72\u51c0\u6ce8\u518c\u8bed\u97f3\u4e0d\u53ef\u7528\u7684\u95ee\u9898", "motivation": "\u4f20\u7edf\u76ee\u6807\u8bf4\u8bdd\u4eba\u63d0\u53d6\u7cfb\u7edf\u4f9d\u8d56\u9884\u6ce8\u518c\u8bed\u97f3\u4f5c\u4e3a\u7ebf\u7d22\uff0c\u4f46\u5728\u8bb8\u591a\u5b9e\u9645\u573a\u666f\u4e2d\u5e72\u51c0\u6ce8\u518c\u8bed\u97f3\u4e0d\u53ef\u7528\uff0c\u9650\u5236\u4e86\u73b0\u6709\u65b9\u6cd5\u7684\u9002\u7528\u6027", "method": "\u91c7\u7528\u68c0\u6d4b-\u5173\u6ce8-\u63d0\u53d6\uff08DAE\uff09\u8303\u5f0f\uff1a\u9996\u5148\u68c0\u6d4b\u7ed9\u5b9a\u5173\u952e\u8bcd\u7684\u5b58\u5728\uff0c\u7136\u540e\u57fa\u4e8e\u5173\u952e\u8bcd\u5185\u5bb9\u5173\u6ce8\u5bf9\u5e94\u8bf4\u8bdd\u4eba\uff0c\u6700\u540e\u63d0\u53d6\u76ee\u6807\u8bed\u97f3", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660eDAE-TSE\u4f18\u4e8e\u4f9d\u8d56\u5e72\u51c0\u6ce8\u518c\u8bed\u97f3\u7684\u6807\u51c6TSE\u7cfb\u7edf\uff0c\u8fd9\u662f\u9996\u6b21\u5229\u7528\u90e8\u5206\u8f6c\u5f55\u4f5c\u4e3aTSE\u4e2d\u76ee\u6807\u8bf4\u8bdd\u4eba\u6307\u5b9a\u7ebf\u7d22\u7684\u7814\u7a76", "conclusion": "\u5173\u952e\u8bcd\u5f15\u5bfc\u7684TSE\u6846\u67b6\u4e3a\u73b0\u5b9e\u573a\u666f\u63d0\u4f9b\u4e86\u7075\u6d3b\u5b9e\u7528\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u4ee3\u7801\u548c\u6f14\u793a\u9875\u9762\u5df2\u516c\u5f00\u53ef\u7528"}}
{"id": "2602.08293", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2602.08293", "abs": "https://arxiv.org/abs/2602.08293", "authors": ["Seaone Ok", "Min Jun Choi", "Eungbeom Kim", "Seungu Han", "Kyogu Lee"], "title": "Cross-Modal Bottleneck Fusion For Noise Robust Audio-Visual Speech Recognition", "comment": "5 pages, 3 figures, ICASSP 2026 Accepted", "summary": "Audio-Visual Speech Recognition (AVSR) leverages both acoustic and visual cues to improve speech recognition under noisy conditions. A central question is how to design a fusion mechanism that allows the model to effectively exploit visual information when the audio signal is degraded, while maintaining strong performance on clean speech. We propose CoBRA (Cross-modal Bottleneck for Robust AVSR), a bottleneck-based fusion framework that introduces a compact set of learnable tokens to mediate cross-modal exchange. By regulating information flow through these tokens, the audio stream can reliably access essential visual cues even under adverse or out-of-domain noise. Despite limited training data, our model surpasses comparable baselines and remains competitive with large-scale systems through noise-adaptive fusion, demonstrating both efficiency and robustness. Ablation studies highlight that the depth of fusion is the most critical factor, underscoring its importance in designing robust AVSR systems.", "AI": {"tldr": "CoBRA\u63d0\u51fa\u57fa\u4e8e\u74f6\u9888\u7684\u8de8\u6a21\u6001\u878d\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60token\u8c03\u8282\u4fe1\u606f\u6d41\uff0c\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u63d0\u5347\u89c6\u542c\u8bed\u97f3\u8bc6\u522b\u6027\u80fd", "motivation": "\u4f20\u7edf\u89c6\u542c\u8bed\u97f3\u8bc6\u522b\u5728\u566a\u58f0\u6761\u4ef6\u4e0b\u96be\u4ee5\u6709\u6548\u5229\u7528\u89c6\u89c9\u4fe1\u606f\uff0c\u9700\u8981\u8bbe\u8ba1\u65e2\u80fd\u5904\u7406\u566a\u58f0\u97f3\u9891\u53c8\u80fd\u4fdd\u6301\u5e72\u51c0\u8bed\u97f3\u6027\u80fd\u7684\u878d\u5408\u673a\u5236", "method": "\u63d0\u51faCoBRA\u6846\u67b6\uff0c\u4f7f\u7528\u7d27\u51d1\u7684\u53ef\u5b66\u4e60token\u4f5c\u4e3a\u8de8\u6a21\u6001\u4ea4\u6362\u7684\u4e2d\u4ecb\uff0c\u901a\u8fc7\u74f6\u9888\u673a\u5236\u8c03\u8282\u4fe1\u606f\u6d41\uff0c\u5b9e\u73b0\u566a\u58f0\u81ea\u9002\u5e94\u878d\u5408", "result": "\u5728\u6709\u9650\u8bad\u7ec3\u6570\u636e\u4e0b\u8d85\u8d8a\u53ef\u6bd4\u57fa\u7ebf\uff0c\u4e0e\u5927\u89c4\u6a21\u7cfb\u7edf\u4fdd\u6301\u7ade\u4e89\u529b\uff0c\u6d88\u878d\u7814\u7a76\u8868\u660e\u878d\u5408\u6df1\u5ea6\u662f\u6700\u5173\u952e\u56e0\u7d20", "conclusion": "CoBRA\u901a\u8fc7\u74f6\u9888\u878d\u5408\u673a\u5236\u5b9e\u73b0\u4e86\u9ad8\u6548\u4e14\u9c81\u68d2\u7684\u89c6\u542c\u8bed\u97f3\u8bc6\u522b\uff0c\u878d\u5408\u6df1\u5ea6\u5bf9\u7cfb\u7edf\u9c81\u68d2\u6027\u81f3\u5173\u91cd\u8981"}}
{"id": "2602.08484", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2602.08484", "abs": "https://arxiv.org/abs/2602.08484", "authors": ["Luan Vin\u00edcius Fiorio", "Ivana Nikoloska", "Bruno Defraene", "Alex Young", "Johan David", "Ronald M. Aarts"], "title": "Physics-Guided Variational Model for Unsupervised Sound Source Tracking", "comment": "This work has been submitted to the IEEE for possible publication", "summary": "Sound source tracking is often performed using classical array-processing algorithms. Alternative methods, such as machine learning, rely on ground truth position labels, which are costly to obtain. We propose a variational model that can perform single-source unsupervised sound source tracking in latent space, aided by a physics-based decoder. Our experiments demonstrate that the proposed method surpasses traditional baselines and achieves performance and computational complexity comparable to state-of-the-art supervised models. We also show that the method presents substantial robustness to altered microphone array geometries and corrupted microphone position metadata. Finally, the method is extended to multi-source sound tracking and the basic theoretical changes are proposed.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u53d8\u5206\u6a21\u578b\uff0c\u53ef\u5728\u6f5c\u7a7a\u95f4\u4e2d\u8fdb\u884c\u5355\u6e90\u65e0\u76d1\u7763\u58f0\u6e90\u8ddf\u8e2a\uff0c\u501f\u52a9\u7269\u7406\u9a71\u52a8\u7684\u89e3\u7801\u5668\uff0c\u6027\u80fd\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\uff0c\u4e0e\u76d1\u7763\u6a21\u578b\u76f8\u5f53\uff0c\u4e14\u5bf9\u9ea6\u514b\u98ce\u9635\u5217\u51e0\u4f55\u53d8\u5316\u548c\u4f4d\u7f6e\u5143\u6570\u636e\u635f\u574f\u5177\u6709\u9c81\u68d2\u6027\u3002", "motivation": "\u4f20\u7edf\u58f0\u6e90\u8ddf\u8e2a\u4f7f\u7528\u7ecf\u5178\u9635\u5217\u5904\u7406\u7b97\u6cd5\uff0c\u800c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u9700\u8981\u6602\u8d35\u7684\u4f4d\u7f6e\u6807\u7b7e\u6570\u636e\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u5730\u9762\u771f\u503c\u6807\u7b7e\u7684\u65e0\u76d1\u7763\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u53d8\u5206\u6a21\u578b\uff0c\u5728\u6f5c\u7a7a\u95f4\u8fdb\u884c\u5355\u6e90\u65e0\u76d1\u7763\u58f0\u6e90\u8ddf\u8e2a\uff0c\u4f7f\u7528\u7269\u7406\u9a71\u52a8\u7684\u89e3\u7801\u5668\u8f85\u52a9\u3002\u6a21\u578b\u53ef\u6269\u5c55\u5230\u591a\u6e90\u8ddf\u8e2a\uff0c\u5e76\u63d0\u51fa\u4e86\u57fa\u672c\u7406\u8bba\u4fee\u6539\u3002", "result": "\u65b9\u6cd5\u8d85\u8d8a\u4f20\u7edf\u57fa\u7ebf\uff0c\u6027\u80fd\u4e0e\u8ba1\u7b97\u590d\u6742\u5ea6\u4e0e\u6700\u5148\u8fdb\u7684\u76d1\u7763\u6a21\u578b\u76f8\u5f53\u3002\u5bf9\u9ea6\u514b\u98ce\u9635\u5217\u51e0\u4f55\u53d8\u5316\u548c\u635f\u574f\u7684\u9ea6\u514b\u98ce\u4f4d\u7f6e\u5143\u6570\u636e\u5177\u6709\u663e\u8457\u9c81\u68d2\u6027\u3002", "conclusion": "\u63d0\u51fa\u7684\u53d8\u5206\u6a21\u578b\u4e3a\u65e0\u76d1\u7763\u58f0\u6e90\u8ddf\u8e2a\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u6027\u80fd\u4f18\u8d8a\u4e14\u9c81\u68d2\u6027\u5f3a\uff0c\u53ef\u6269\u5c55\u5230\u591a\u6e90\u573a\u666f\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.07036", "categories": ["cs.SD", "cs.AI", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.07036", "abs": "https://arxiv.org/abs/2602.07036", "authors": ["Zien Sheikh Ali", "Hunzalah Hassan Bhatti", "Rabindra Nath Nandi", "Shammur Absar Chowdhury", "Firoj Alam"], "title": "MENASpeechBank: A Reference Voice Bank with Persona-Conditioned Multi-Turn Conversations for AudioLLMs", "comment": "Foundation Models, Large Language Models, Native, Speech Models, Arabic, AI-persona, Persona-conditioned-conversations", "summary": "Audio large language models (AudioLLMs) enable instruction-following over speech and general audio, but progress is increasingly limited by the lack of diverse, conversational, instruction-aligned speech-text data. This bottleneck is especially acute for persona-grounded interactions and dialectal coverage, where collecting and releasing real multi-speaker recordings is costly and slow. We introduce MENASpeechBank, a reference speech bank comprising about 18K high-quality utterances from 124 speakers spanning multiple MENA countries, covering English, Modern Standard Arabic (MSA), and regional Arabic varieties. Building on this resource, we develop a controllable synthetic data pipeline that: (i) constructs persona profiles enriched with World Values Survey-inspired attributes, (ii) defines a taxonomy of about 5K conversational scenarios, (iii) matches personas to scenarios via semantic similarity, (iv) generates about 417K role-play conversations with an LLM where the user speaks as the persona and the assistant behaves as a helpful agent, and (v) synthesizes the user turns by conditioning on reference speaker audio to preserve speaker identity and diversity. We evaluate both synthetic and human-recorded conversations and provide detailed analysis. We will release MENASpeechBank and the generated conversations publicly for the community.", "AI": {"tldr": "\u63d0\u51faMENASpeechBank\u8bed\u97f3\u6570\u636e\u5e93\u548c\u53ef\u63a7\u5408\u6210\u6570\u636e\u6d41\u6c34\u7ebf\uff0c\u7528\u4e8e\u89e3\u51b3AudioLLMs\u8bad\u7ec3\u6570\u636e\u4e0d\u8db3\u95ee\u9898\uff0c\u7279\u522b\u9488\u5bf9\u4e2d\u4e1c\u5730\u533a\u591a\u65b9\u8a00\u8986\u76d6\u548c\u89d2\u8272\u5316\u4ea4\u4e92\u3002", "motivation": "\u97f3\u9891\u5927\u8bed\u8a00\u6a21\u578b(AudioLLMs)\u7684\u53d1\u5c55\u53d7\u5230\u7f3a\u4e4f\u591a\u6837\u5316\u3001\u5bf9\u8bdd\u5f0f\u3001\u6307\u4ee4\u5bf9\u9f50\u7684\u8bed\u97f3-\u6587\u672c\u6570\u636e\u7684\u9650\u5236\uff0c\u7279\u522b\u662f\u5728\u89d2\u8272\u5316\u4ea4\u4e92\u548c\u65b9\u8a00\u8986\u76d6\u65b9\u9762\u3002\u6536\u96c6\u548c\u53d1\u5e03\u771f\u5b9e\u7684\u591a\u8bf4\u8bdd\u8005\u5f55\u97f3\u6210\u672c\u9ad8\u3001\u901f\u5ea6\u6162\u3002", "method": "1) \u6784\u5efaMENASpeechBank\u53c2\u8003\u8bed\u97f3\u5e93(18K\u9ad8\u8d28\u91cf\u8bdd\u8bed\uff0c124\u4e2a\u8bf4\u8bdd\u8005\uff0c\u8986\u76d6\u4e2d\u4e1c\u591a\u56fd\u3001\u82f1\u8bed\u3001\u73b0\u4ee3\u6807\u51c6\u963f\u62c9\u4f2f\u8bed\u548c\u5730\u533a\u963f\u62c9\u4f2f\u8bed\u53d8\u4f53)\uff1b2) \u5f00\u53d1\u53ef\u63a7\u5408\u6210\u6570\u636e\u6d41\u6c34\u7ebf\uff1a\u6784\u5efa\u89d2\u8272\u6863\u6848\u3001\u5b9a\u4e495K\u5bf9\u8bdd\u573a\u666f\u5206\u7c7b\u3001\u901a\u8fc7\u8bed\u4e49\u76f8\u4f3c\u5ea6\u5339\u914d\u89d2\u8272\u4e0e\u573a\u666f\u3001\u4f7f\u7528LLM\u751f\u6210417K\u89d2\u8272\u626e\u6f14\u5bf9\u8bdd\u3001\u57fa\u4e8e\u53c2\u8003\u8bed\u97f3\u5408\u6210\u7528\u6237\u8bdd\u8bed\u4ee5\u4fdd\u6301\u8bf4\u8bdd\u8005\u8eab\u4efd\u548c\u591a\u6837\u6027\u3002", "result": "\u521b\u5efa\u4e86\u5305\u542b\u7ea618K\u9ad8\u8d28\u91cf\u8bdd\u8bed\u7684MENASpeechBank\u8bed\u97f3\u5e93\uff0c\u5e76\u901a\u8fc7\u5408\u6210\u6570\u636e\u6d41\u6c34\u7ebf\u751f\u6210\u4e86\u7ea6417K\u89d2\u8272\u626e\u6f14\u5bf9\u8bdd\u3002\u5bf9\u5408\u6210\u548c\u4eba\u5de5\u5f55\u5236\u5bf9\u8bdd\u8fdb\u884c\u4e86\u8bc4\u4f30\u548c\u5206\u6790\u3002", "conclusion": "MENASpeechBank\u548c\u751f\u6210\u7684\u5bf9\u8bdd\u5c06\u516c\u5f00\u53d1\u5e03\uff0c\u4e3a\u793e\u533a\u63d0\u4f9b\u89e3\u51b3AudioLLMs\u6570\u636e\u74f6\u9888\u7684\u8d44\u6e90\uff0c\u7279\u522b\u6709\u52a9\u4e8e\u4e2d\u4e1c\u5730\u533a\u591a\u65b9\u8a00\u548c\u89d2\u8272\u5316\u4ea4\u4e92\u7684\u7814\u7a76\u3002"}}
{"id": "2602.06982", "categories": ["eess.SP", "cs.AI", "cs.IT", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06982", "abs": "https://arxiv.org/abs/2602.06982", "authors": ["Pujitha Mamillapalli", "Shikhar Verma", "Tiago Koketsu Rodrigues", "Abhinav Kumar"], "title": "Deep Reinforcement Learning for Interference Suppression in RIS-Aided Space-Air-Ground Integrated Networks", "comment": null, "summary": "Future 6G networks envision ubiquitous connectivity through space-air-ground integrated networks (SAGINs), where high-altitude platform stations (HAPSs) and satellites complement terrestrial systems to provide wide-area, low-latency coverage. However, the rapid growth of terrestrial devices intensifies spectrum sharing between terrestrial and non-terrestrial segments, resulting in severe cross-tier interference. In particular, frequency sharing between the HAPS satellite uplink and HAPS ground downlink improves spectrum efficiency but suffers from interference caused by the HAPS antenna back-lobe. Existing approaches relying on zero-forcing (ZF) codebooks have limited performance under highly dynamic channel conditions. To overcome this limitation, we employ a reconfigurable intelligent surface (RIS)-aided HAPS-based SAGIN framework with a deep deterministic policy gradient (DDPG) algorithm. The proposed DDPG framework optimizes the HAPS beamforming weights to form spatial nulls toward interference sources while maintaining robust links to the desired signals. Simulation results demonstrate that the DDPG framework consistently outperforms conventional ZF beamforming among different RIS configurations, achieving up to \\(11.3\\%\\) throughput improvement for a \\(4\\times4\\) RIS configuration, validating its adaptive capability to enhance spectral efficiency in dynamic HAPS-based SAGINs.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08DDPG\uff09\u7684RIS\u8f85\u52a9HAPS-SAGIN\u6846\u67b6\uff0c\u4f18\u5316\u6ce2\u675f\u8d4b\u5f62\u4ee5\u6291\u5236\u8de8\u5c42\u5e72\u6270\uff0c\u76f8\u6bd4\u4f20\u7edfZF\u6ce2\u675f\u8d4b\u5f62\u63d0\u5347\u541e\u5410\u91cf\u8fbe11.3%\u3002", "motivation": "6G\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc\uff08SAGIN\uff09\u4e2d\uff0c\u9ad8\u7a7a\u5e73\u53f0\uff08HAPS\uff09\u4e0e\u5730\u9762\u7cfb\u7edf\u9891\u8c31\u5171\u4eab\u5bfc\u81f4\u4e25\u91cd\u7684\u8de8\u5c42\u5e72\u6270\uff0c\u7279\u522b\u662fHAPS\u536b\u661f\u4e0a\u884c\u4e0e\u5730\u9762\u4e0b\u884c\u4e4b\u95f4\u7684\u9891\u7387\u5171\u4eab\u53d7\u5929\u7ebf\u540e\u74e3\u5e72\u6270\u5f71\u54cd\u3002\u4f20\u7edfZF\u7801\u4e66\u5728\u52a8\u6001\u4fe1\u9053\u6761\u4ef6\u4e0b\u6027\u80fd\u6709\u9650\u3002", "method": "\u91c7\u7528\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u8f85\u52a9\u7684HAPS-SAGIN\u6846\u67b6\uff0c\u7ed3\u5408\u6df1\u5ea6\u786e\u5b9a\u6027\u7b56\u7565\u68af\u5ea6\uff08DDPG\uff09\u7b97\u6cd5\uff0c\u4f18\u5316HAPS\u6ce2\u675f\u8d4b\u5f62\u6743\u91cd\uff0c\u5728\u5e72\u6270\u6e90\u65b9\u5411\u5f62\u6210\u7a7a\u95f4\u96f6\u9677\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u671f\u671b\u4fe1\u53f7\u7684\u9c81\u68d2\u94fe\u8def\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cDDPG\u6846\u67b6\u5728\u4e0d\u540cRIS\u914d\u7f6e\u4e0b\u5747\u4f18\u4e8e\u4f20\u7edfZF\u6ce2\u675f\u8d4b\u5f62\uff0c\u57284\u00d74 RIS\u914d\u7f6e\u4e0b\u5b9e\u73b0\u9ad8\u8fbe11.3%\u7684\u541e\u5410\u91cf\u63d0\u5347\uff0c\u9a8c\u8bc1\u4e86\u5176\u5728\u52a8\u6001HAPS-SAGIN\u4e2d\u589e\u5f3a\u9891\u8c31\u6548\u7387\u7684\u81ea\u9002\u5e94\u80fd\u529b\u3002", "conclusion": "DDPG\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3HAPS-SAGIN\u4e2d\u7684\u8de8\u5c42\u5e72\u6270\u95ee\u9898\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u6ce2\u675f\u8d4b\u5f62\u4f18\u5316\u663e\u8457\u63d0\u5347\u7cfb\u7edf\u6027\u80fd\uff0c\u4e3a6G\u5929\u5730\u4e00\u4f53\u5316\u7f51\u7edc\u7684\u9891\u8c31\u9ad8\u6548\u5229\u7528\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08671", "categories": ["eess.AS"], "pdf": "https://arxiv.org/pdf/2602.08671", "abs": "https://arxiv.org/abs/2602.08671", "authors": ["Kohei Saijo", "Yoshiaki Bando"], "title": "Input-Adaptive Spectral Feature Compression by Sequence Modeling for Source Separation", "comment": "Accepted by IEEE TASLP. \\c{opyright} 2026 IEEE. Personal use of this material is permitted. Permission from IEEE must be obtained for all other uses", "summary": "Time-frequency domain dual-path models have demonstrated strong performance and are widely used in source separation. Because their computational cost grows with the number of frequency bins, these models often use the band-split (BS) module in high-sampling-rate tasks such as music source separation (MSS) and cinematic audio source separation (CASS). The BS encoder compresses frequency information by encoding features for each predefined subband. It achieves effective compression by introducing an inductive bias that places greater emphasis on low-frequency parts. Despite its success, the BS module has two inherent limitations: (i) it is not input-adaptive, preventing the use of input-dependent information, and (ii) the parameter count is large, since each subband requires a dedicated module. To address these issues, we propose Spectral Feature Compression (SFC). SFC compresses the input using a single sequence modeling module, making it both input-adaptive and parameter-efficient. We investigate two variants of SFC, one based on cross-attention and the other on Mamba, and introduce inductive biases inspired by the BS module to make them suitable for frequency information compression. Experiments on MSS and CASS tasks demonstrate that the SFC module consistently outperforms the BS module across different separator sizes and compression ratios. We also provide an analysis showing that SFC adaptively captures frequency patterns from the input.", "AI": {"tldr": "\u63d0\u51faSpectral Feature Compression (SFC)\u6a21\u5757\u66ff\u4ee3band-split (BS)\u6a21\u5757\uff0c\u7528\u4e8e\u65f6\u9891\u57df\u53cc\u8def\u5f84\u6a21\u578b\u7684\u9891\u7387\u4fe1\u606f\u538b\u7f29\u3002SFC\u4f7f\u7528\u5355\u4e00\u5e8f\u5217\u5efa\u6a21\u6a21\u5757\uff0c\u5177\u6709\u8f93\u5165\u81ea\u9002\u5e94\u6027\u548c\u53c2\u6570\u6548\u7387\uff0c\u5728\u97f3\u4e50\u548c\u7535\u5f71\u97f3\u9891\u6e90\u5206\u79bb\u4efb\u52a1\u4e2d\u8868\u73b0\u4f18\u4e8eBS\u6a21\u5757\u3002", "motivation": "\u73b0\u6709band-split (BS)\u6a21\u5757\u5b58\u5728\u4e24\u4e2a\u56fa\u6709\u5c40\u9650\u6027\uff1a(1) \u975e\u8f93\u5165\u81ea\u9002\u5e94\uff0c\u65e0\u6cd5\u5229\u7528\u8f93\u5165\u76f8\u5173\u4fe1\u606f\uff1b(2) \u53c2\u6570\u6570\u91cf\u5927\uff0c\u6bcf\u4e2a\u5b50\u5e26\u9700\u8981\u4e13\u7528\u6a21\u5757\u3002\u9700\u8981\u66f4\u9ad8\u6548\u3001\u81ea\u9002\u5e94\u7684\u9891\u7387\u4fe1\u606f\u538b\u7f29\u65b9\u6cd5\u3002", "method": "\u63d0\u51faSpectral Feature Compression (SFC)\u6a21\u5757\uff0c\u4f7f\u7528\u5355\u4e00\u5e8f\u5217\u5efa\u6a21\u6a21\u5757\u538b\u7f29\u8f93\u5165\u3002\u7814\u7a76\u4e24\u79cd\u53d8\u4f53\uff1a\u57fa\u4e8e\u4ea4\u53c9\u6ce8\u610f\u529b\u548c\u57fa\u4e8eMamba\u7684\u7248\u672c\uff0c\u5e76\u5f15\u5165\u53d7BS\u6a21\u5757\u542f\u53d1\u7684\u5f52\u7eb3\u504f\u7f6e\uff0c\u4f7f\u5176\u9002\u5408\u9891\u7387\u4fe1\u606f\u538b\u7f29\u3002", "result": "\u5728\u97f3\u4e50\u6e90\u5206\u79bb(MSS)\u548c\u7535\u5f71\u97f3\u9891\u6e90\u5206\u79bb(CASS)\u4efb\u52a1\u4e2d\uff0cSFC\u6a21\u5757\u5728\u4e0d\u540c\u5206\u79bb\u5668\u5927\u5c0f\u548c\u538b\u7f29\u6bd4\u4e0b\u59cb\u7ec8\u4f18\u4e8eBS\u6a21\u5757\u3002\u5206\u6790\u663e\u793aSFC\u80fd\u591f\u81ea\u9002\u5e94\u5730\u6355\u6349\u8f93\u5165\u4e2d\u7684\u9891\u7387\u6a21\u5f0f\u3002", "conclusion": "SFC\u6a21\u5757\u89e3\u51b3\u4e86BS\u6a21\u5757\u7684\u5c40\u9650\u6027\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8f93\u5165\u81ea\u9002\u5e94\u4e14\u53c2\u6570\u9ad8\u6548\u7684\u9891\u7387\u4fe1\u606f\u538b\u7f29\u65b9\u6cd5\uff0c\u5728\u97f3\u9891\u6e90\u5206\u79bb\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.07077", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.07077", "abs": "https://arxiv.org/abs/2602.07077", "authors": ["Videet Mehta", "Liming Wang", "Hilde Kuehne", "Rogerio Feris", "James R. Glass", "M. Jehanzeb Mirza"], "title": "CALM: Class-Conditional Sparse Attention Vectors for Large Audio-Language Models", "comment": "11 pages, 6 figures", "summary": "Large audio-language models (LALMs) exhibit strong zero-shot capabilities in multiple downstream tasks, such as audio question answering (AQA) and abstract reasoning; however, these models still lag behind specialized models for certain discriminative tasks (e.g., audio classification). Recent studies show that sparse subsets of attention heads within an LALM can serve as strong discriminative feature extractors for downstream tasks such as classification via simple voting schemes. However, these methods assign uniform weights to all selected heads, implicitly assuming that each head contributes equally across all semantic categories. In this work, we propose Class-Conditional Sparse Attention Vectors for Large Audio-Language Models, a few-shot classification method that learns class-dependent importance weights over attention heads. This formulation allows individual heads to specialize in distinct semantic categories and to contribute to ensemble predictions proportionally to their estimated reliability. Experiments on multiple few-shot audio and audiovisual classification benchmarks and tasks demonstrate that our method consistently outperforms state-of-the-art uniform voting-based approaches by up to 14.52%, 1.53%, 8.35% absolute gains for audio classification, audio-visual classification, and spoofing detection respectively.", "AI": {"tldr": "\u63d0\u51faClass-Conditional Sparse Attention Vectors\u65b9\u6cd5\uff0c\u901a\u8fc7\u5b66\u4e60\u7c7b\u522b\u4f9d\u8d56\u7684\u91cd\u8981\u6027\u6743\u91cd\u6539\u8fdb\u5927\u578b\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u7684\u6ce8\u610f\u529b\u5934\u9009\u62e9\uff0c\u5728\u5c11\u6837\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u4f18\u4e8e\u73b0\u6709\u5747\u5300\u6295\u7968\u65b9\u6cd5\u3002", "motivation": "\u5927\u578b\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u5728\u5224\u522b\u4efb\u52a1\uff08\u5982\u97f3\u9891\u5206\u7c7b\uff09\u4e0a\u4ecd\u843d\u540e\u4e8e\u4e13\u7528\u6a21\u578b\u3002\u73b0\u6709\u65b9\u6cd5\u5747\u5300\u52a0\u6743\u6240\u6709\u6ce8\u610f\u529b\u5934\uff0c\u5ffd\u7565\u4e86\u4e0d\u540c\u6ce8\u610f\u529b\u5934\u5728\u4e0d\u540c\u8bed\u4e49\u7c7b\u522b\u4e2d\u7684\u8d21\u732e\u5dee\u5f02\u3002", "method": "\u63d0\u51fa\u7c7b\u522b\u6761\u4ef6\u7a00\u758f\u6ce8\u610f\u529b\u5411\u91cf\u65b9\u6cd5\uff0c\u5b66\u4e60\u7c7b\u522b\u4f9d\u8d56\u7684\u91cd\u8981\u6027\u6743\u91cd\uff0c\u4f7f\u4e0d\u540c\u6ce8\u610f\u529b\u5934\u80fd\u591f\u4e13\u6ce8\u4e8e\u4e0d\u540c\u8bed\u4e49\u7c7b\u522b\uff0c\u5e76\u6839\u636e\u5176\u53ef\u9760\u6027\u6309\u6bd4\u4f8b\u8d21\u732e\u4e8e\u96c6\u6210\u9884\u6d4b\u3002", "result": "\u5728\u591a\u4e2a\u5c11\u6837\u672c\u97f3\u9891\u548c\u89c6\u542c\u5206\u7c7b\u57fa\u51c6\u6d4b\u8bd5\u4e2d\uff0c\u76f8\u6bd4\u6700\u5148\u8fdb\u7684\u5747\u5300\u6295\u7968\u65b9\u6cd5\uff0c\u97f3\u9891\u5206\u7c7b\u63d0\u534714.52%\uff0c\u89c6\u542c\u5206\u7c7b\u63d0\u53471.53%\uff0c\u6b3a\u9a97\u68c0\u6d4b\u63d0\u53478.35%\u3002", "conclusion": "\u901a\u8fc7\u5f15\u5165\u7c7b\u522b\u4f9d\u8d56\u7684\u6ce8\u610f\u529b\u5934\u6743\u91cd\uff0c\u663e\u8457\u63d0\u5347\u4e86\u5927\u578b\u97f3\u9891-\u8bed\u8a00\u6a21\u578b\u5728\u5c11\u6837\u672c\u5206\u7c7b\u4efb\u52a1\u4e2d\u7684\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u6ce8\u610f\u529b\u5934\u5728\u4e0d\u540c\u8bed\u4e49\u7c7b\u522b\u4e2d\u7684\u4e13\u4e1a\u5316\u7279\u6027\u3002"}}
{"id": "2602.06983", "categories": ["eess.SP", "cs.AI", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.06983", "abs": "https://arxiv.org/abs/2602.06983", "authors": ["Alison M. Fernandes", "Hermes I. Del Monego", "Bruno S. Chang", "Anelise Munaretto", "H\u00e9lder M. Fontes", "Rui Campos"], "title": "Hybrid Deep Learning Framework for CSI-Based Activity Recognition in Bandwidth-Constrained Wi-Fi Sensing", "comment": "6 pages, 6 figures", "summary": "This paper presents a novel hybrid deep learning framework designed to enhance the robustness of CSI-based Human Activity Recognition (HAR) within bandwidth-constrained Wi-Fi sensing environments. The core of our proposed methodology is a preliminary Doppler trace extraction stage, implemented to amplify salient motion-related signal features before classification. Subsequently, these enhanced inputs are processed by a hybrid neural architecture, which integrates Inception networks responsible for hierarchical spatial feature extraction and Bidirectional Long Short-Term Memory (BiLSTM) networks that capture temporal dependencies. A Support Vector Machine (SVM) is then utilized as the final classification layer to optimize decision boundaries. The framework's efficacy was systematically validated using a public dataset across 20, 40, and 80 MHz bandwidth configurations. The model yielded accuracies of 89.27% (20 MHz), 94.13% (40 MHz), and 95.30% (80 MHz), respectively. These results confirm a marked superiority over standalone deep learning baselines, especially in the most constrained low-bandwidth scenarios. This study underscores the utility of combining Doppler-based feature engineering with a hybrid learning architecture for reliable HAR in bandwidth-limited wireless sensing applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u6df7\u5408\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u591a\u666e\u52d2\u8f68\u8ff9\u63d0\u53d6\u589e\u5f3a\u7279\u5f81\uff0c\u7ed3\u5408Inception\u3001BiLSTM\u548cSVM\uff0c\u5728\u5e26\u5bbd\u53d7\u9650Wi-Fi\u73af\u5883\u4e2d\u663e\u8457\u63d0\u5347CSI\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u6027\u80fd", "motivation": "\u89e3\u51b3\u5e26\u5bbd\u53d7\u9650Wi-Fi\u611f\u77e5\u73af\u5883\u4e2d\u57fa\u4e8eCSI\u7684\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b\u9c81\u68d2\u6027\u95ee\u9898\uff0c\u7279\u522b\u662f\u5728\u4f4e\u5e26\u5bbd\u573a\u666f\u4e0b\u4f20\u7edf\u6df1\u5ea6\u5b66\u4e60\u65b9\u6cd5\u6027\u80fd\u53d7\u9650\u7684\u6311\u6218", "method": "1. \u591a\u666e\u52d2\u8f68\u8ff9\u63d0\u53d6\u9636\u6bb5\u589e\u5f3a\u8fd0\u52a8\u76f8\u5173\u4fe1\u53f7\u7279\u5f81\uff1b2. \u6df7\u5408\u795e\u7ecf\u7f51\u7edc\u67b6\u6784\uff1aInception\u7f51\u7edc\u63d0\u53d6\u5c42\u6b21\u7a7a\u95f4\u7279\u5f81\uff0cBiLSTM\u6355\u6349\u65f6\u95f4\u4f9d\u8d56\u6027\uff1b3. SVM\u4f5c\u4e3a\u6700\u7ec8\u5206\u7c7b\u5c42\u4f18\u5316\u51b3\u7b56\u8fb9\u754c", "result": "\u572820/40/80 MHz\u5e26\u5bbd\u914d\u7f6e\u4e0b\u5206\u522b\u8fbe\u523089.27%\u300194.13%\u300195.30%\u7684\u51c6\u786e\u7387\uff0c\u663e\u8457\u4f18\u4e8e\u72ec\u7acb\u6df1\u5ea6\u5b66\u4e60\u57fa\u7ebf\uff0c\u5c24\u5176\u5728\u4f4e\u5e26\u5bbd\u573a\u666f\u4f18\u52bf\u660e\u663e", "conclusion": "\u7ed3\u5408\u591a\u666e\u52d2\u7279\u5f81\u5de5\u7a0b\u4e0e\u6df7\u5408\u5b66\u4e60\u67b6\u6784\uff0c\u53ef\u5728\u5e26\u5bbd\u53d7\u9650\u7684\u65e0\u7ebf\u611f\u77e5\u5e94\u7528\u4e2d\u5b9e\u73b0\u53ef\u9760\u7684\u4eba\u4f53\u6d3b\u52a8\u8bc6\u522b"}}
{"id": "2602.07143", "categories": ["cs.SD", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.07143", "abs": "https://arxiv.org/abs/2602.07143", "authors": ["Georg Heigold", "Ehsan Variani", "Tom Bagby", "Cyril Allauzen", "Ji Ma", "Shankar Kumar", "Michael Riley"], "title": "Massive Sound Embedding Benchmark (MSEB)", "comment": null, "summary": "Audio is a critical component of multimodal perception, and any truly intelligent system must demonstrate a wide range of auditory capabilities. These capabilities include transcription, classification, retrieval, reasoning, segmentation, clustering, reranking, and reconstruction. Fundamentally, each task involves transforming a raw audio signal into a meaningful 'embedding' - be it a single vector, a sequence of continuous or discrete representations, or another structured form - which then serves as the basis for generating the task's final response. To accelerate progress towards robust machine auditory intelligence, we present the Massive Sound Embedding Benchmark (MSEB): an extensible framework designed to evaluate the auditory components of any multimodal system. In its first release, MSEB offers a comprehensive suite of eight core tasks, with more planned for the future, supported by diverse datasets, including the new, large-scale Simple Voice Questions (SVQ) dataset. Our initial experiments establish clear performance headrooms, highlighting the significant opportunity to improve real-world multimodal experiences where audio is a core signal. We encourage the research community to use MSEB to assess their algorithms and contribute to its growth. The library is publicly hosted at github.", "AI": {"tldr": "MSEB\u662f\u4e00\u4e2a\u7528\u4e8e\u8bc4\u4f30\u591a\u6a21\u6001\u7cfb\u7edf\u4e2d\u542c\u89c9\u7ec4\u4ef6\u6027\u80fd\u7684\u53ef\u6269\u5c55\u57fa\u51c6\u6846\u67b6\uff0c\u5305\u542b8\u4e2a\u6838\u5fc3\u4efb\u52a1\uff0c\u65e8\u5728\u52a0\u901f\u673a\u5668\u542c\u89c9\u667a\u80fd\u7684\u53d1\u5c55\u3002", "motivation": "\u97f3\u9891\u662f\u591a\u6a21\u6001\u611f\u77e5\u7684\u5173\u952e\u7ec4\u6210\u90e8\u5206\uff0c\u4efb\u4f55\u771f\u6b63\u7684\u667a\u80fd\u7cfb\u7edf\u90fd\u9700\u8981\u5177\u5907\u5e7f\u6cdb\u7684\u542c\u89c9\u80fd\u529b\uff08\u5982\u8f6c\u5f55\u3001\u5206\u7c7b\u3001\u68c0\u7d22\u3001\u63a8\u7406\u7b49\uff09\u3002\u76ee\u524d\u7f3a\u4e4f\u4e00\u4e2a\u5168\u9762\u7684\u57fa\u51c6\u6765\u8bc4\u4f30\u8fd9\u4e9b\u542c\u89c9\u80fd\u529b\uff0c\u963b\u788d\u4e86\u673a\u5668\u542c\u89c9\u667a\u80fd\u7684\u53d1\u5c55\u3002", "method": "\u63d0\u51fa\u4e86\u5927\u89c4\u6a21\u58f0\u97f3\u5d4c\u5165\u57fa\u51c6\uff08MSEB\uff09\u6846\u67b6\uff0c\u5305\u542b8\u4e2a\u6838\u5fc3\u4efb\u52a1\uff0c\u4f7f\u7528\u591a\u6837\u5316\u6570\u636e\u96c6\uff08\u5305\u62ec\u65b0\u7684\u5927\u89c4\u6a21Simple Voice Questions\u6570\u636e\u96c6\uff09\uff0c\u5c06\u539f\u59cb\u97f3\u9891\u4fe1\u53f7\u8f6c\u6362\u4e3a\u6709\u610f\u4e49\u7684\u5d4c\u5165\u8868\u793a\uff08\u5411\u91cf\u3001\u5e8f\u5217\u7b49\uff09\uff0c\u4f5c\u4e3a\u4efb\u52a1\u54cd\u5e94\u7684\u57fa\u7840\u3002", "result": "\u5efa\u7acb\u4e86\u6e05\u6670\u7684\u6027\u80fd\u4e0a\u9650\uff0c\u5c55\u793a\u4e86\u5728\u97f3\u9891\u4f5c\u4e3a\u6838\u5fc3\u4fe1\u53f7\u7684\u771f\u5b9e\u591a\u6a21\u6001\u4f53\u9a8c\u4e2d\u4ecd\u6709\u663e\u8457\u6539\u8fdb\u7a7a\u95f4\u3002\u57fa\u51c6\u6846\u67b6\u5df2\u516c\u5f00\u5728GitHub\u4e0a\u4f9b\u7814\u7a76\u793e\u533a\u4f7f\u7528\u3002", "conclusion": "MSEB\u4e3a\u8bc4\u4f30\u591a\u6a21\u6001\u7cfb\u7edf\u7684\u542c\u89c9\u80fd\u529b\u63d0\u4f9b\u4e86\u6807\u51c6\u5316\u6846\u67b6\uff0c\u9f13\u52b1\u7814\u7a76\u793e\u533a\u4f7f\u7528\u8be5\u57fa\u51c6\u8bc4\u4f30\u7b97\u6cd5\u5e76\u4e3a\u5176\u53d1\u5c55\u505a\u51fa\u8d21\u732e\uff0c\u4ee5\u52a0\u901f\u5b9e\u73b0\u9c81\u68d2\u7684\u673a\u5668\u542c\u89c9\u667a\u80fd\u3002"}}
{"id": "2602.06990", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.06990", "abs": "https://arxiv.org/abs/2602.06990", "authors": ["Zhuo Li", "Shuqiang Wang"], "title": "A Pre-trained EEG-to-MEG Generative Framework for Enhancing BCI Decoding", "comment": null, "summary": "Electroencephalography (EEG) and magnetoencephalography (MEG) play important and complementary roles in non-invasive brain-computer interface (BCI) decoding. However, compared to the low cost and portability of EEG, MEG is more expensive and less portable, which severely limits the practical application of MEG in BCI systems. To overcome this limitation, this study proposes the first cross-modal generation framework based on EEG-MEG spatiotemporal coupled representations to synthesize MEG signals cost-effectively. The framework first extracts general neural activity representations through a pre-trained EEG model. Building upon these representations, the framework effectively learns the lower spatial dispersion and higher high-frequency sensitivity of MEG via the spatial focus mapping module and the broadband spectral calibration module. Experimental results demonstrate that the synthesized MEG signals show high consistency with the real MEG in both time-frequency characteristics and source space activation patterns. More importantly, downstream BCI decoding experiments demonstrate that using synthesized MEG leads to performance enhancements not only on paired EEG-MEG datasets but also on independent EEG-only datasets. Overall, this framework opens a new avenue for overcoming data bottlenecks in BCI.", "AI": {"tldr": "\u63d0\u51fa\u9996\u4e2a\u57fa\u4e8eEEG-MEG\u65f6\u7a7a\u8026\u5408\u8868\u793a\u7684\u8de8\u6a21\u6001\u751f\u6210\u6846\u67b6\uff0c\u7528\u4e8e\u4f4e\u6210\u672c\u5408\u6210MEG\u4fe1\u53f7\uff0c\u89e3\u51b3MEG\u8bbe\u5907\u6602\u8d35\u4e0d\u4fbf\u643a\u7684\u95ee\u9898\u3002", "motivation": "EEG\u548cMEG\u5728\u975e\u4fb5\u5165\u5f0f\u8111\u673a\u63a5\u53e3\u89e3\u7801\u4e2d\u5177\u6709\u4e92\u8865\u4f5c\u7528\uff0c\u4f46MEG\u8bbe\u5907\u6602\u8d35\u4e14\u4e0d\u4fbf\u643a\uff0c\u4e25\u91cd\u9650\u5236\u4e86\u5176\u5728BCI\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002", "method": "\u6846\u67b6\u9996\u5148\u901a\u8fc7\u9884\u8bad\u7ec3\u7684EEG\u6a21\u578b\u63d0\u53d6\u901a\u7528\u795e\u7ecf\u6d3b\u52a8\u8868\u793a\uff0c\u7136\u540e\u901a\u8fc7\u7a7a\u95f4\u805a\u7126\u6620\u5c04\u6a21\u5757\u548c\u5bbd\u5e26\u9891\u8c31\u6821\u51c6\u6a21\u5757\u5b66\u4e60MEG\u7684\u4f4e\u7a7a\u95f4\u5206\u6563\u6027\u548c\u9ad8\u9ad8\u9891\u654f\u611f\u6027\uff0c\u6700\u7ec8\u5408\u6210MEG\u4fe1\u53f7\u3002", "result": "\u5408\u6210\u7684MEG\u4fe1\u53f7\u5728\u65f6\u9891\u7279\u6027\u548c\u6e90\u7a7a\u95f4\u6fc0\u6d3b\u6a21\u5f0f\u4e0a\u4e0e\u771f\u5b9eMEG\u9ad8\u5ea6\u4e00\u81f4\u3002\u4e0b\u6e38BCI\u89e3\u7801\u5b9e\u9a8c\u8868\u660e\uff0c\u4f7f\u7528\u5408\u6210MEG\u4e0d\u4ec5\u80fd\u5728\u914d\u5bf9EEG-MEG\u6570\u636e\u96c6\u4e0a\u63d0\u5347\u6027\u80fd\uff0c\u4e5f\u80fd\u5728\u72ec\u7acbEEG-only\u6570\u636e\u96c6\u4e0a\u5e26\u6765\u6027\u80fd\u589e\u5f3a\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a\u514b\u670dBCI\u4e2d\u7684\u6570\u636e\u74f6\u9888\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\uff0c\u901a\u8fc7\u4f4e\u6210\u672c\u5408\u6210\u9ad8\u8d28\u91cf\u7684MEG\u4fe1\u53f7\uff0c\u4fc3\u8fdb\u4e86MEG\u5728BCI\u7cfb\u7edf\u4e2d\u7684\u5b9e\u9645\u5e94\u7528\u3002"}}
{"id": "2602.08148", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.08148", "abs": "https://arxiv.org/abs/2602.08148", "authors": ["Shaad Sufi"], "title": "SNC: A Stem-Native Codec for Efficient Lossless Audio Storage with Adaptive Playback Capabilities", "comment": null, "summary": "Current audio formats present a fundamental trade-off between file size and functionality: lossless formats like FLAC preserve quality but lack adaptability, while lossy formats reduce size at the cost of fidelity and offer no stem-level access.We introduce the Stem-Native Codec (SNC), a novel audio container format that stores music as independently encoded stems plus a low-energy mastering residual. By exploiting the lower information entropy of separated stems compared to mixed audio, SNC achieves a 38.2% file size reduction versus FLAC (7.76 MB vs. 12.55 MB for a 2:18 test track) while maintaining perceptual transparency (STOI = 0.996). Unlike existing formats, SNC enables context-aware adaptive playback, spatial audio rendering, and user-controlled remixing without requiring additional storage. Our experimental validation demonstrates that the stems-plus residual architecture successfully decouples the conflicting requirements of compression efficiency and feature richness, offering a practical path toward next-generation audio distribution systems.", "AI": {"tldr": "SNC\u662f\u4e00\u79cd\u65b0\u578b\u97f3\u9891\u5bb9\u5668\u683c\u5f0f\uff0c\u5c06\u97f3\u4e50\u5b58\u50a8\u4e3a\u72ec\u7acb\u7f16\u7801\u7684\u97f3\u8f68\uff08stems\uff09\u52a0\u4e0a\u4f4e\u80fd\u91cf\u6bcd\u5e26\u6b8b\u5dee\uff0c\u76f8\u6bd4FLAC\u51cf\u5c1138.2%\u6587\u4ef6\u5927\u5c0f\uff0c\u540c\u65f6\u4fdd\u6301\u611f\u77e5\u900f\u660e\u6027\uff0c\u5e76\u652f\u6301\u81ea\u9002\u5e94\u64ad\u653e\u3001\u7a7a\u95f4\u97f3\u9891\u6e32\u67d3\u548c\u7528\u6237\u63a7\u5236\u6df7\u97f3\u7b49\u529f\u80fd\u3002", "motivation": "\u5f53\u524d\u97f3\u9891\u683c\u5f0f\u5b58\u5728\u57fa\u672c\u6743\u8861\uff1a\u65e0\u635f\u683c\u5f0f\uff08\u5982FLAC\uff09\u4fdd\u7559\u8d28\u91cf\u4f46\u7f3a\u4e4f\u9002\u5e94\u6027\uff0c\u800c\u6709\u635f\u683c\u5f0f\u51cf\u5c0f\u6587\u4ef6\u5927\u5c0f\u4f46\u727a\u7272\u4fdd\u771f\u5ea6\u4e14\u65e0\u6cd5\u63d0\u4f9b\u97f3\u8f68\u7ea7\u8bbf\u95ee\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u9ad8\u6548\u538b\u7f29\u53c8\u652f\u6301\u4e30\u5bcc\u529f\u80fd\u7684\u97f3\u9891\u683c\u5f0f\u3002", "method": "\u63d0\u51faStem-Native Codec\uff08SNC\uff09\uff0c\u5c06\u97f3\u4e50\u5b58\u50a8\u4e3a\u72ec\u7acb\u7f16\u7801\u7684\u97f3\u8f68\uff08stems\uff09\u52a0\u4e0a\u4f4e\u80fd\u91cf\u6bcd\u5e26\u6b8b\u5dee\u3002\u5229\u7528\u5206\u79bb\u97f3\u8f68\u76f8\u6bd4\u6df7\u5408\u97f3\u9891\u5177\u6709\u66f4\u4f4e\u4fe1\u606f\u71b5\u7684\u7279\u6027\uff0c\u5b9e\u73b0\u9ad8\u6548\u538b\u7f29\u3002", "result": "SNC\u76f8\u6bd4FLAC\u5b9e\u73b038.2%\u7684\u6587\u4ef6\u5927\u5c0f\u51cf\u5c11\uff08\u6d4b\u8bd5\u66f2\u76ee2\u520618\u79d2\uff1a7.76 MB vs 12.55 MB\uff09\uff0c\u540c\u65f6\u4fdd\u6301\u611f\u77e5\u900f\u660e\u6027\uff08STOI = 0.996\uff09\u3002\u652f\u6301\u4e0a\u4e0b\u6587\u611f\u77e5\u81ea\u9002\u5e94\u64ad\u653e\u3001\u7a7a\u95f4\u97f3\u9891\u6e32\u67d3\u548c\u7528\u6237\u63a7\u5236\u6df7\u97f3\u7b49\u529f\u80fd\u3002", "conclusion": "\u97f3\u8f68\u52a0\u6b8b\u5dee\u67b6\u6784\u6210\u529f\u89e3\u8026\u4e86\u538b\u7f29\u6548\u7387\u548c\u529f\u80fd\u4e30\u5bcc\u6027\u4e4b\u95f4\u7684\u51b2\u7a81\u8981\u6c42\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u97f3\u9891\u5206\u53d1\u7cfb\u7edf\u63d0\u4f9b\u4e86\u5b9e\u7528\u8def\u5f84\u3002"}}
{"id": "2602.06997", "categories": ["eess.SP", "cs.AI", "cs.LG", "cs.NE"], "pdf": "https://arxiv.org/pdf/2602.06997", "abs": "https://arxiv.org/abs/2602.06997", "authors": ["Anindya Bhattacharjee", "Nittya Ananda Biswas", "K. A. Shahriar", "Adib Rahman"], "title": "Adaptive Temporal Dynamics for Personalized Emotion Recognition: A Liquid Neural Network Approach", "comment": null, "summary": "Emotion recognition from physiological signals remains challenging due to their non-stationary, noisy, and subject-dependent characteristics. This work presents, to the best of our knowledge, the first comprehensive application of liquid neural networks for EEG-based emotion recognition. The proposed multimodal framework combines convolutional feature extraction, liquid neural networks with learnable time constants, and attention-guided fusion to model temporal EEG dynamics with complementary peripheral physiological and personality features. Dedicated subnetworks are used to process EEG features and auxiliary modalities, and a shared autoencoder-based fusion module is used to learn discriminative latent representations before classification. Subject-dependent experiments conducted on the PhyMER dataset across seven emotional classes achieve an accuracy of 95.45%, surpassing previously reported results. Furthermore, temporal attention analysis provides interpretable insights into emotion-specific temporal relevance, and t-SNE visualizations demonstrate enhanced class separability, highlighting the effectiveness of the proposed approach. Finally, statistical analysis of temporal dynamics confirms that the network self-organizes into distinct functional groups with specialized fast and slow neurons, proving it independently tunes learnable time constants and memory dominance to effectively capture complex emotion artifacts.", "AI": {"tldr": "\u9996\u6b21\u5c06\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u5e94\u7528\u4e8eEEG\u60c5\u7eea\u8bc6\u522b\uff0c\u901a\u8fc7\u591a\u6a21\u6001\u878d\u5408\u6846\u67b6\u5728PhyMER\u6570\u636e\u96c6\u4e0a\u8fbe\u523095.45%\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u5148\u524d\u65b9\u6cd5\u3002", "motivation": "\u751f\u7406\u4fe1\u53f7\uff08\u5982EEG\uff09\u5177\u6709\u975e\u5e73\u7a33\u3001\u566a\u58f0\u5927\u3001\u4e2a\u4f53\u4f9d\u8d56\u6027\u5f3a\u7684\u7279\u70b9\uff0c\u4f20\u7edf\u65b9\u6cd5\u96be\u4ee5\u6709\u6548\u5904\u7406\u3002\u9700\u8981\u5f00\u53d1\u80fd\u591f\u66f4\u597d\u5efa\u6a21\u65f6\u5e8f\u52a8\u6001\u548c\u4e2a\u4f53\u5dee\u5f02\u7684\u65b0\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u591a\u6a21\u6001\u6846\u67b6\uff1a\u5377\u79ef\u7279\u5f81\u63d0\u53d6 + \u53ef\u5b66\u4e60\u65f6\u95f4\u5e38\u6570\u7684\u6db2\u6001\u795e\u7ecf\u7f51\u7edc + \u6ce8\u610f\u529b\u5f15\u5bfc\u878d\u5408\u3002\u4f7f\u7528\u4e13\u7528\u5b50\u7f51\u7edc\u5904\u7406EEG\u7279\u5f81\u548c\u8f85\u52a9\u6a21\u6001\uff08\u5916\u5468\u751f\u7406\u548c\u4eba\u683c\u7279\u5f81\uff09\uff0c\u901a\u8fc7\u5171\u4eab\u81ea\u7f16\u7801\u5668\u878d\u5408\u6a21\u5757\u5b66\u4e60\u5224\u522b\u6027\u6f5c\u5728\u8868\u793a\u3002", "result": "\u5728PhyMER\u6570\u636e\u96c67\u7c7b\u60c5\u7eea\u8bc6\u522b\u4efb\u52a1\u4e2d\u8fbe\u523095.45%\u51c6\u786e\u7387\uff0c\u8d85\u8d8a\u5148\u524d\u7ed3\u679c\u3002\u65f6\u95f4\u6ce8\u610f\u529b\u5206\u6790\u63d0\u4f9b\u53ef\u89e3\u91ca\u6027\u6d1e\u5bdf\uff0ct-SNE\u53ef\u89c6\u5316\u663e\u793a\u589e\u5f3a\u7684\u7c7b\u522b\u53ef\u5206\u6027\u3002\u7edf\u8ba1\u5206\u6790\u8bc1\u5b9e\u7f51\u7edc\u81ea\u7ec4\u7ec7\u4e3a\u5177\u6709\u4e13\u95e8\u5feb\u6162\u795e\u7ecf\u5143\u7684\u529f\u80fd\u7ec4\u3002", "conclusion": "\u6db2\u6001\u795e\u7ecf\u7f51\u7edc\u80fd\u6709\u6548\u5efa\u6a21EEG\u65f6\u5e8f\u52a8\u6001\uff0c\u901a\u8fc7\u53ef\u5b66\u4e60\u65f6\u95f4\u5e38\u6570\u548c\u8bb0\u5fc6\u4f18\u52bf\u72ec\u7acb\u8c03\u8282\uff0c\u6210\u529f\u6355\u83b7\u590d\u6742\u60c5\u7eea\u7279\u5f81\u3002\u591a\u6a21\u6001\u878d\u5408\u6846\u67b6\u5728\u60c5\u7eea\u8bc6\u522b\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\u3002"}}
{"id": "2602.08233", "categories": ["cs.SD", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.08233", "abs": "https://arxiv.org/abs/2602.08233", "authors": ["Jiatao Chen", "Xing Tang", "Xiaoyue Duan", "Yutang Feng", "Jinchao Zhang", "Jie Zhou"], "title": "Tutti: Expressive Multi-Singer Synthesis via Structure-Level Timbre Control and Vocal Texture Modeling", "comment": null, "summary": "While existing Singing Voice Synthesis systems achieve high-fidelity solo performances, they are constrained by global timbre control, failing to address dynamic multi-singer arrangement and vocal texture within a single song. To address this, we propose Tutti, a unified framework designed for structured multi-singer generation. Specifically, we introduce a Structure-Aware Singer Prompt to enable flexible singer scheduling evolving with musical structure, and propose Complementary Texture Learning via Condition-Guided VAE to capture implicit acoustic textures (e.g., spatial reverberation and spectral fusion) that are complementary to explicit controls. Experiments demonstrate that Tutti excels in precise multi-singer scheduling and significantly enhances the acoustic realism of choral generation, offering a novel paradigm for complex multi-singer arrangement. Audio samples are available at https://annoauth123-ctrl.github.io/Tutii_Demo/.", "AI": {"tldr": "Tutti\u662f\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u6b4c\u624b\u6b4c\u5531\u5408\u6210\u6846\u67b6\uff0c\u901a\u8fc7\u7ed3\u6784\u5316\u6b4c\u624b\u8c03\u5ea6\u548c\u4e92\u8865\u7eb9\u7406\u5b66\u4e60\u5b9e\u73b0\u52a8\u6001\u591a\u6b4c\u624b\u7f16\u6392\u548c\u58f0\u5b66\u771f\u5b9e\u611f", "motivation": "\u73b0\u6709\u6b4c\u5531\u5408\u6210\u7cfb\u7edf\u867d\u7136\u80fd\u5b9e\u73b0\u9ad8\u4fdd\u771f\u72ec\u5531\uff0c\u4f46\u53d7\u9650\u4e8e\u5168\u5c40\u97f3\u8272\u63a7\u5236\uff0c\u65e0\u6cd5\u5728\u5355\u66f2\u4e2d\u5904\u7406\u52a8\u6001\u591a\u6b4c\u624b\u7f16\u6392\u548c\u58f0\u5b66\u7eb9\u7406\u53d8\u5316", "method": "\u63d0\u51fa\u7ed3\u6784\u611f\u77e5\u6b4c\u624b\u63d0\u793a\u5b9e\u73b0\u7075\u6d3b\u6b4c\u624b\u8c03\u5ea6\uff0c\u91c7\u7528\u6761\u4ef6\u5f15\u5bfcVAE\u7684\u4e92\u8865\u7eb9\u7406\u5b66\u4e60\u6355\u83b7\u9690\u5f0f\u58f0\u5b66\u7eb9\u7406\uff08\u5982\u7a7a\u95f4\u6df7\u54cd\u548c\u9891\u8c31\u878d\u5408\uff09", "result": "\u5b9e\u9a8c\u8bc1\u660eTutti\u5728\u7cbe\u786e\u591a\u6b4c\u624b\u8c03\u5ea6\u65b9\u9762\u8868\u73b0\u51fa\u8272\uff0c\u663e\u8457\u63d0\u5347\u5408\u5531\u751f\u6210\u7684\u58f0\u5b66\u771f\u5b9e\u611f", "conclusion": "Tutti\u4e3a\u590d\u6742\u591a\u6b4c\u624b\u7f16\u6392\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\uff0c\u5b9e\u73b0\u4e86\u7ed3\u6784\u5316\u591a\u6b4c\u624b\u751f\u6210"}}
{"id": "2602.07001", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.07001", "abs": "https://arxiv.org/abs/2602.07001", "authors": ["Yueyi Yang", "Zeping Sui", "Zilong Liu", "Leila Musavian"], "title": "OTFS-based Integrated Positioning and Communication Systems with Low-Resolution ADCs", "comment": "6 pages, 6 figures, submitted to ICC Workshop", "summary": "This paper proposes a two-phase orthogonal time frequency space (OTFS)-based integrated positioning and communication (IPAC) framework under realistic low-resolution analog-to-digital converters (ADCs). In the uplink phase, the positioning signal is used to estimate channel parameters, which are subsequently used to determine the user's position. The spatial smoothing-multiple signal classification algorithm is introduced to estimate the angle-of-arrival, whereas an iterative interference cancellation scheme is conceived for the remaining parameters' estimation. The corresponding Cramer-Rao lower bounds of channel parameters and user position are also derived. During the downlink communication phase, the estimated parameters are exploited to improve beamforming at the base station. Simulation results evaluate the impact of ADC quantizer resolutions. Specifically, it is shown that enhanced downlink bit error rate performance can be achieved with improved uplink positioning, while the use of low-resolution ADCs induces noticeable performance degradation in the OTFS-IPAC system.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8eOTFS\u7684\u4e24\u9636\u6bb5IPAC\u6846\u67b6\uff0c\u5728\u4f4e\u5206\u8fa8\u7387ADC\u4e0b\u5b9e\u73b0\u5b9a\u4f4d\u4e0e\u901a\u4fe1\u96c6\u6210\uff0c\u901a\u8fc7\u4e0a\u884c\u5b9a\u4f4d\u4f30\u8ba1\u4fe1\u9053\u53c2\u6570\uff0c\u4e0b\u884c\u5229\u7528\u53c2\u6570\u6539\u8fdb\u6ce2\u675f\u6210\u5f62\uff0c\u5206\u6790\u4e86ADC\u5206\u8fa8\u7387\u5bf9\u6027\u80fd\u7684\u5f71\u54cd\u3002", "motivation": "\u5728\u73b0\u5b9e\u4f4e\u5206\u8fa8\u7387ADC\u7ea6\u675f\u4e0b\uff0c\u9700\u8981\u8bbe\u8ba1\u6709\u6548\u7684\u96c6\u6210\u5b9a\u4f4d\u4e0e\u901a\u4fe1\u7cfb\u7edf\uff0c\u5229\u7528OTFS\u6ce2\u5f62\u7279\u6027\u540c\u65f6\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\u548c\u53ef\u9760\u901a\u4fe1\u3002", "method": "\u91c7\u7528\u4e24\u9636\u6bb5OTFS-IPAC\u6846\u67b6\uff1a\u4e0a\u884c\u9636\u6bb5\u4f7f\u7528\u7a7a\u95f4\u5e73\u6ed1-MUSIC\u7b97\u6cd5\u4f30\u8ba1\u5230\u8fbe\u89d2\uff0c\u8fed\u4ee3\u5e72\u6270\u6d88\u9664\u65b9\u6848\u4f30\u8ba1\u5176\u4ed6\u53c2\u6570\uff1b\u4e0b\u884c\u9636\u6bb5\u5229\u7528\u4f30\u8ba1\u53c2\u6570\u6539\u8fdb\u57fa\u7ad9\u6ce2\u675f\u6210\u5f62\u3002", "result": "\u63a8\u5bfc\u4e86\u4fe1\u9053\u53c2\u6570\u548c\u7528\u6237\u4f4d\u7f6e\u7684CRLB\uff0c\u4eff\u771f\u8868\u660e\uff1a\u4e0a\u884c\u5b9a\u4f4d\u7cbe\u5ea6\u63d0\u5347\u53ef\u6539\u5584\u4e0b\u884c\u8bef\u7801\u7387\u6027\u80fd\uff0c\u4f46\u4f4e\u5206\u8fa8\u7387ADC\u4f1a\u5bfc\u81f4OTFS-IPAC\u7cfb\u7edf\u6027\u80fd\u663e\u8457\u4e0b\u964d\u3002", "conclusion": "\u6240\u63d0\u6846\u67b6\u5728\u4f4e\u5206\u8fa8\u7387ADC\u4e0b\u6709\u6548\u5b9e\u73b0OTFS-IPAC\uff0c\u5b9a\u4f4d\u7cbe\u5ea6\u4e0e\u901a\u4fe1\u6027\u80fd\u76f8\u4e92\u4fc3\u8fdb\uff0c\u4f46ADC\u5206\u8fa8\u7387\u662f\u7cfb\u7edf\u6027\u80fd\u7684\u5173\u952e\u9650\u5236\u56e0\u7d20\u3002"}}
{"id": "2602.08556", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2602.08556", "abs": "https://arxiv.org/abs/2602.08556", "authors": ["Chengzhong Wang", "Andong Li", "Dingding Yao", "Junfeng Li"], "title": "Global Rotation Equivariant Phase Modeling for Speech Enhancement with Deep Magnitude-Phase Interaction", "comment": "Submitted to IEEE TASLP", "summary": "While deep learning has advanced speech enhancement (SE), effective phase modeling remains challenging, as conventional networks typically operate within a flat Euclidean feature space, which is not easy to model the underlying circular topology of the phase. To address this, we propose a manifold-aware magnitude-phase dual-stream framework that aligns the phase stream with its intrinsic circular geometry by enforcing Global Rotation Equivariance (GRE) characteristic. Specifically, we introduce a Magnitude-Phase Interactive Convolutional Module (MPICM) for modulus-based information exchange and a Hybrid-Attention Dual-FFN (HADF) bottleneck for unified feature fusion, both of which are designed to preserve GRE in the phase stream. Comprehensive evaluations are conducted across phase retrieval, denoising, dereverberation, and bandwidth extension tasks to validate the superiority of the proposed method over multiple advanced baselines. Notably, the proposed architecture reduces Phase Distance by over 20\\% in the phase retrieval task and improves PESQ by more than 0.1 in zero-shot cross-corpus denoising evaluations. The overall superiority is also established in universal SE tasks involving mixed distortions. Qualitative analysis further reveals that the learned phase features exhibit distinct periodic patterns, which are consistent with the intrinsic circular nature of the phase. The source code is available at https://github.com/wangchengzhong/RENet.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6d41\u5f62\u611f\u77e5\u7684\u5e45\u5ea6-\u76f8\u4f4d\u53cc\u6d41\u6846\u67b6\uff0c\u901a\u8fc7\u5168\u5c40\u65cb\u8f6c\u7b49\u53d8\u6027\uff08GRE\uff09\u7279\u6027\u5c06\u76f8\u4f4d\u6d41\u4e0e\u5176\u5185\u5728\u5706\u5f62\u51e0\u4f55\u5bf9\u9f50\uff0c\u89e3\u51b3\u4e86\u76f8\u4f4d\u5efa\u6a21\u7684\u6311\u6218\u3002", "motivation": "\u6df1\u5ea6\u5b66\u4e60\u5728\u8bed\u97f3\u589e\u5f3a\u65b9\u9762\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u6709\u6548\u7684\u76f8\u4f4d\u5efa\u6a21\u4ecd\u7136\u5177\u6709\u6311\u6218\u6027\u3002\u4f20\u7edf\u7f51\u7edc\u901a\u5e38\u5728\u5e73\u5766\u7684\u6b27\u51e0\u91cc\u5f97\u7279\u5f81\u7a7a\u95f4\u4e2d\u64cd\u4f5c\uff0c\u96be\u4ee5\u5efa\u6a21\u76f8\u4f4d\u56fa\u6709\u7684\u5706\u5f62\u62d3\u6251\u7ed3\u6784\u3002", "method": "\u63d0\u51fa\u4e86\u4e00\u4e2a\u6d41\u5f62\u611f\u77e5\u7684\u5e45\u5ea6-\u76f8\u4f4d\u53cc\u6d41\u6846\u67b6\uff0c\u901a\u8fc7\u5f3a\u5236\u5168\u5c40\u65cb\u8f6c\u7b49\u53d8\u6027\uff08GRE\uff09\u7279\u6027\u4f7f\u76f8\u4f4d\u6d41\u4e0e\u5176\u5185\u5728\u5706\u5f62\u51e0\u4f55\u5bf9\u9f50\u3002\u5177\u4f53\u5305\u62ec\uff1a\u5e45\u5ea6-\u76f8\u4f4d\u4ea4\u4e92\u5377\u79ef\u6a21\u5757\uff08MPICM\uff09\u7528\u4e8e\u57fa\u4e8e\u6a21\u7684\u4fe1\u606f\u4ea4\u6362\uff0c\u4ee5\u53ca\u6df7\u5408\u6ce8\u610f\u529b\u53ccFFN\uff08HADF\uff09\u74f6\u9888\u7528\u4e8e\u7edf\u4e00\u7279\u5f81\u878d\u5408\uff0c\u4e24\u8005\u90fd\u8bbe\u8ba1\u7528\u4e8e\u5728\u76f8\u4f4d\u6d41\u4e2d\u4fdd\u6301GRE\u3002", "result": "\u5728\u76f8\u4f4d\u6062\u590d\u3001\u53bb\u566a\u3001\u53bb\u6df7\u54cd\u548c\u5e26\u5bbd\u6269\u5c55\u4efb\u52a1\u4e0a\u8fdb\u884c\u4e86\u5168\u9762\u8bc4\u4f30\u3002\u5728\u76f8\u4f4d\u6062\u590d\u4efb\u52a1\u4e2d\uff0c\u76f8\u4f4d\u8ddd\u79bb\u51cf\u5c11\u4e86\u8d85\u8fc720%\uff1b\u5728\u96f6\u6837\u672c\u8de8\u8bed\u6599\u5e93\u53bb\u566a\u8bc4\u4f30\u4e2d\uff0cPESQ\u63d0\u9ad8\u4e860.1\u4ee5\u4e0a\u3002\u5728\u6d89\u53ca\u6df7\u5408\u5931\u771f\u7684\u901a\u7528\u8bed\u97f3\u589e\u5f3a\u4efb\u52a1\u4e2d\u4e5f\u5efa\u7acb\u4e86\u6574\u4f53\u4f18\u52bf\u3002\u5b9a\u6027\u5206\u6790\u663e\u793a\u5b66\u4e60\u7684\u76f8\u4f4d\u7279\u5f81\u8868\u73b0\u51fa\u660e\u663e\u7684\u5468\u671f\u6027\u6a21\u5f0f\uff0c\u4e0e\u76f8\u4f4d\u56fa\u6709\u7684\u5706\u5f62\u6027\u8d28\u4e00\u81f4\u3002", "conclusion": "\u63d0\u51fa\u7684\u65b9\u6cd5\u901a\u8fc7\u5c06\u76f8\u4f4d\u6d41\u4e0e\u5176\u5185\u5728\u5706\u5f62\u51e0\u4f55\u5bf9\u9f50\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u76f8\u4f4d\u5efa\u6a21\u7684\u6311\u6218\uff0c\u5728\u591a\u4e2a\u8bed\u97f3\u589e\u5f3a\u4efb\u52a1\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u8bc1\u660e\u4e86\u6d41\u5f62\u611f\u77e5\u6846\u67b6\u7684\u6709\u6548\u6027\u3002"}}
{"id": "2602.07131", "categories": ["eess.SP", "q-bio.NC"], "pdf": "https://arxiv.org/pdf/2602.07131", "abs": "https://arxiv.org/abs/2602.07131", "authors": ["Javier Salazar Cavazos", "Maximillian Egan", "Krisanne Litinas", "Benjamin Hampstead", "Scott Peltier"], "title": "Behavior Score Prediction in Resting-State Functional MRI by Deep State Space Modeling", "comment": null, "summary": "Early clinical assessment of Alzheimer's disease relies on behavior scores that measure a subject's language, memory, and cognitive skills. On the medical imaging side, functional magnetic resonance imaging has provided invaluable insights into the neural pathways underlying Alzheimer's disease. While prior studies have used resting-state functional MRI by extracting functional connectivity matrices, these approaches neglect the temporal dynamics inherent in functional data. In this work, we present a deep state space modeling framework that directly leverages the blood-oxygenation-level-dependent time series to learn a sparse collection of brain regions to predict behavior scores. Our model extracts temporal features that encapsulate nuanced patterns of intrinsic brain activity, thereby enhancing predictive performance compared to traditional connectivity methods. We identify specific brain regions that are most predictive of cognitive impairment through experiments on data provided by the Michigan Alzheimer's Disease Research Center, providing new insights into the neural substrates of early Alzheimer's pathology. These findings have important implications for the possible development of risk monitoring and intervention strategies in Alzheimer's disease.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u57fa\u4e8e\u6df1\u5ea6\u72b6\u6001\u7a7a\u95f4\u6a21\u578b\u7684\u6846\u67b6\uff0c\u76f4\u63a5\u5229\u7528BOLD\u65f6\u95f4\u5e8f\u5217\u9884\u6d4b\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u884c\u4e3a\u8bc4\u5206\uff0c\u76f8\u6bd4\u4f20\u7edf\u529f\u80fd\u8fde\u63a5\u65b9\u6cd5\u80fd\u66f4\u597d\u5730\u6355\u6349\u65f6\u95f4\u52a8\u6001\u7279\u5f81\u3002", "motivation": "\u4f20\u7edf\u57fa\u4e8e\u9759\u606f\u6001fMRI\u7684\u529f\u80fd\u8fde\u63a5\u77e9\u9635\u65b9\u6cd5\u5ffd\u7565\u4e86\u529f\u80fd\u6570\u636e\u56fa\u6709\u7684\u65f6\u95f4\u52a8\u6001\u7279\u5f81\uff0c\u800c\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7684\u65e9\u671f\u4e34\u5e8a\u8bc4\u4f30\u9700\u8981\u66f4\u51c6\u786e\u5730\u6355\u6349\u5927\u8111\u6d3b\u52a8\u7684\u7ec6\u5fae\u6a21\u5f0f\u3002", "method": "\u5f00\u53d1\u4e86\u4e00\u4e2a\u6df1\u5ea6\u72b6\u6001\u7a7a\u95f4\u5efa\u6a21\u6846\u67b6\uff0c\u76f4\u63a5\u5904\u7406\u8840\u6c27\u6c34\u5e73\u4f9d\u8d56\uff08BOLD\uff09\u65f6\u95f4\u5e8f\u5217\uff0c\u5b66\u4e60\u7a00\u758f\u7684\u5927\u8111\u533a\u57df\u96c6\u5408\u6765\u9884\u6d4b\u884c\u4e3a\u8bc4\u5206\uff0c\u63d0\u53d6\u5c01\u88c5\u5185\u5728\u5927\u8111\u6d3b\u52a8\u7ec6\u5fae\u6a21\u5f0f\u7684\u65f6\u95f4\u7279\u5f81\u3002", "result": "\u76f8\u6bd4\u4f20\u7edf\u8fde\u63a5\u65b9\u6cd5\uff0c\u8be5\u6a21\u578b\u63d0\u9ad8\u4e86\u9884\u6d4b\u6027\u80fd\uff0c\u5e76\u901a\u8fc7\u5bc6\u6b47\u6839\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u7814\u7a76\u4e2d\u5fc3\u7684\u5b9e\u9a8c\u6570\u636e\u8bc6\u522b\u51fa\u6700\u80fd\u9884\u6d4b\u8ba4\u77e5\u969c\u788d\u7684\u7279\u5b9a\u5927\u8111\u533a\u57df\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u65e9\u671f\u963f\u5c14\u8328\u6d77\u9ed8\u75c5\u75c5\u7406\u7684\u795e\u7ecf\u57fa\u8d28\u63d0\u4f9b\u4e86\u65b0\u89c1\u89e3\uff0c\u5bf9\u5f00\u53d1\u98ce\u9669\u76d1\u6d4b\u548c\u5e72\u9884\u7b56\u7565\u5177\u6709\u91cd\u8981\u4e34\u5e8a\u610f\u4e49\u3002"}}
{"id": "2602.08696", "categories": ["cs.SD", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08696", "abs": "https://arxiv.org/abs/2602.08696", "authors": ["Haoshen Wang", "Xueli Zhong", "Bingbing Lin", "Jia Huang", "Xingduo Pan", "Shengxiang Liang", "Nizhuan Wang", "Wai Ting Siok"], "title": "Prototype-Based Disentanglement for Controllable Dysarthric Speech Synthesis", "comment": null, "summary": "Dysarthric speech exhibits high variability and limited labeled data, posing major challenges for both automatic speech recognition (ASR) and assistive speech technologies. Existing approaches rely on synthetic data augmentation or speech reconstruction, yet often entangle speaker identity with pathological articulation, limiting controllability and robustness.\n  In this paper, we propose ProtoDisent-TTS, a prototype-based disentanglement TTS framework built on a pre-trained text-to-speech backbone that factorizes speaker timbre and dysarthric articulation within a unified latent space. A pathology prototype codebook provides interpretable and controllable representations of healthy and dysarthric speech patterns, while a dual-classifier objective with a gradient reversal layer enforces invariance of speaker embeddings to pathological attributes. Experiments on the TORGO dataset demonstrate that this design enables bidirectional transformation between healthy and dysarthric speech, leading to consistent ASR performance gains and robust, speaker-aware speech reconstruction.", "AI": {"tldr": "ProtoDisent-TTS\uff1a\u57fa\u4e8e\u539f\u578b\u89e3\u8026\u7684TTS\u6846\u67b6\uff0c\u5728\u9884\u8bad\u7ec3TTS\u9aa8\u5e72\u4e0a\u5206\u79bb\u8bf4\u8bdd\u4eba\u97f3\u8272\u548c\u6784\u97f3\u969c\u788d\u7279\u5f81\uff0c\u5b9e\u73b0\u5065\u5eb7\u4e0e\u6784\u97f3\u969c\u788d\u8bed\u97f3\u7684\u53cc\u5411\u8f6c\u6362\uff0c\u63d0\u5347ASR\u6027\u80fd\u548c\u8bed\u97f3\u91cd\u5efa\u8d28\u91cf\u3002", "motivation": "\u6784\u97f3\u969c\u788d\u8bed\u97f3\u5b58\u5728\u9ad8\u53d8\u5f02\u6027\u548c\u6807\u6ce8\u6570\u636e\u6709\u9650\u7684\u95ee\u9898\uff0c\u73b0\u6709\u65b9\u6cd5\u901a\u5e38\u4f9d\u8d56\u5408\u6210\u6570\u636e\u589e\u5f3a\u6216\u8bed\u97f3\u91cd\u5efa\uff0c\u4f46\u5f80\u5f80\u5c06\u8bf4\u8bdd\u4eba\u8eab\u4efd\u4e0e\u75c5\u7406\u7279\u5f81\u7ea0\u7f20\u5728\u4e00\u8d77\uff0c\u9650\u5236\u4e86\u53ef\u63a7\u6027\u548c\u9c81\u68d2\u6027\u3002", "method": "1. \u57fa\u4e8e\u9884\u8bad\u7ec3TTS\u9aa8\u5e72\u6784\u5efa\u539f\u578b\u89e3\u8026\u6846\u67b6\uff1b2. \u4f7f\u7528\u75c5\u7406\u539f\u578b\u7801\u672c\u63d0\u4f9b\u5065\u5eb7\u4e0e\u6784\u97f3\u969c\u788d\u8bed\u97f3\u6a21\u5f0f\u7684\u53ef\u89e3\u91ca\u53ef\u63a7\u8868\u793a\uff1b3. \u91c7\u7528\u5e26\u68af\u5ea6\u53cd\u8f6c\u5c42\u7684\u53cc\u5206\u7c7b\u5668\u76ee\u6807\uff0c\u5f3a\u5236\u8bf4\u8bdd\u4eba\u5d4c\u5165\u5bf9\u75c5\u7406\u5c5e\u6027\u4fdd\u6301\u4e0d\u53d8\u3002", "result": "\u5728TORGO\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u8bbe\u8ba1\u80fd\u591f\u5b9e\u73b0\u5065\u5eb7\u4e0e\u6784\u97f3\u969c\u788d\u8bed\u97f3\u4e4b\u95f4\u7684\u53cc\u5411\u8f6c\u6362\uff0c\u5e26\u6765\u4e00\u81f4\u7684ASR\u6027\u80fd\u63d0\u5347\uff0c\u5e76\u5b9e\u73b0\u9c81\u68d2\u7684\u3001\u8bf4\u8bdd\u4eba\u611f\u77e5\u7684\u8bed\u97f3\u91cd\u5efa\u3002", "conclusion": "ProtoDisent-TTS\u901a\u8fc7\u89e3\u8026\u8bf4\u8bdd\u4eba\u97f3\u8272\u548c\u6784\u97f3\u969c\u788d\u7279\u5f81\uff0c\u4e3a\u6784\u97f3\u969c\u788d\u8bed\u97f3\u5904\u7406\u63d0\u4f9b\u4e86\u66f4\u53ef\u63a7\u3001\u9c81\u68d2\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5728ASR\u548c\u8f85\u52a9\u8bed\u97f3\u6280\u672f\u65b9\u9762\u5177\u6709\u5e94\u7528\u6f5c\u529b\u3002"}}
{"id": "2602.07169", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07169", "abs": "https://arxiv.org/abs/2602.07169", "authors": ["Paul Anthony Haigh"], "title": "ML-Enabled Deformable Matched Filters for Bandlimitation Compensation in Free-Space Optics", "comment": null, "summary": "This paper proposes a neural-network-assisted deformable matched filtering framework for carrier-less amplitude and phase (CAP) modulation operating under bandwidth-limited channel conditions. Instead of replacing the analytically derived CAP matched filter, the proposed receiver learns a residual deformation of the nominal matched filter based on a compact set of physically motivated signal features extracted from the received waveform. A total of 16 time-domain, frequency-domain, and memory-related features are used to provide a low-dimensional representation of bandwidth-induced pulse distortion. These features are mapped by a fully connected neural network to complex-valued matched filter coefficients, enabling adaptive pulse-shape compensation prior to symbol-rate sampling. The network is trained end-to-end using a differentiable loss function based on error vector magnitude (EVM). Experimental results obtained using a hardware-in-the-loop CAP transmission system demonstrate that the proposed deformable matched filter significantly outperforms conventional fixed matched filtering under severe bandwidth constraints, without requiring decision feedback or increasing receiver latency.", "AI": {"tldr": "\u63d0\u51fa\u795e\u7ecf\u8f85\u52a9\u53ef\u53d8\u5f62\u5339\u914d\u6ee4\u6ce2\u6846\u67b6\uff0c\u7528\u4e8e\u5e26\u5bbd\u53d7\u9650\u4e0b\u7684CAP\u8c03\u5236\uff0c\u901a\u8fc7\u5b66\u4e60\u6b8b\u5dee\u53d8\u5f62\u800c\u975e\u66ff\u6362\u4f20\u7edf\u5339\u914d\u6ee4\u6ce2\u5668\uff0c\u5b9e\u73b0\u81ea\u9002\u5e94\u8109\u51b2\u5f62\u72b6\u8865\u507f\u3002", "motivation": "\u5728\u5e26\u5bbd\u53d7\u9650\u4fe1\u9053\u6761\u4ef6\u4e0b\uff0cCAP\u8c03\u5236\u4f1a\u906d\u53d7\u8109\u51b2\u5931\u771f\uff0c\u4f20\u7edf\u56fa\u5b9a\u5339\u914d\u6ee4\u6ce2\u5668\u6027\u80fd\u4e0b\u964d\u3002\u9700\u8981\u4e00\u79cd\u80fd\u81ea\u9002\u5e94\u8865\u507f\u8109\u51b2\u5f62\u72b6\u5931\u771f\u3001\u4e0d\u589e\u52a0\u5ef6\u8fdf\u4e14\u65e0\u9700\u5224\u51b3\u53cd\u9988\u7684\u63a5\u6536\u673a\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u795e\u7ecf\u8f85\u52a9\u53ef\u53d8\u5f62\u5339\u914d\u6ee4\u6ce2\u6846\u67b6\uff1a1) \u4ece\u63a5\u6536\u6ce2\u5f62\u63d0\u53d616\u4e2a\u65f6\u57df\u3001\u9891\u57df\u548c\u8bb0\u5fc6\u76f8\u5173\u7279\u5f81\uff1b2) \u7528\u5168\u8fde\u63a5\u795e\u7ecf\u7f51\u7edc\u5c06\u8fd9\u4e9b\u7279\u5f81\u6620\u5c04\u5230\u590d\u6570\u5339\u914d\u6ee4\u6ce2\u5668\u7cfb\u6570\uff1b3) \u57fa\u4e8e\u8bef\u5dee\u77e2\u91cf\u5e45\u5ea6(EVM)\u7684\u53ef\u5fae\u635f\u5931\u51fd\u6570\u8fdb\u884c\u7aef\u5230\u7aef\u8bad\u7ec3\uff1b4) \u5728\u7b26\u53f7\u7387\u91c7\u6837\u524d\u5b9e\u73b0\u81ea\u9002\u5e94\u8109\u51b2\u5f62\u72b6\u8865\u507f\u3002", "result": "\u786c\u4ef6\u5728\u73afCAP\u4f20\u8f93\u7cfb\u7edf\u5b9e\u9a8c\u8868\u660e\uff0c\u5728\u4e25\u91cd\u5e26\u5bbd\u7ea6\u675f\u4e0b\uff0c\u6240\u63d0\u53ef\u53d8\u5f62\u5339\u914d\u6ee4\u6ce2\u5668\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u56fa\u5b9a\u5339\u914d\u6ee4\u6ce2\uff0c\u4e14\u65e0\u9700\u5224\u51b3\u53cd\u9988\u6216\u4e0d\u589e\u52a0\u63a5\u6536\u673a\u5ef6\u8fdf\u3002", "conclusion": "\u795e\u7ecf\u8f85\u52a9\u53ef\u53d8\u5f62\u5339\u914d\u6ee4\u6ce2\u6846\u67b6\u80fd\u6709\u6548\u8865\u507f\u5e26\u5bbd\u5f15\u8d77\u7684\u8109\u51b2\u5931\u771f\uff0c\u63d0\u5347CAP\u8c03\u5236\u5728\u53d7\u9650\u4fe1\u9053\u4e0b\u7684\u6027\u80fd\uff0c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u81ea\u9002\u5e94\u63a5\u6536\u65b9\u6848\u3002"}}
{"id": "2602.08930", "categories": ["cs.SD"], "pdf": "https://arxiv.org/pdf/2602.08930", "abs": "https://arxiv.org/abs/2602.08930", "authors": ["Yi Liu", "Chuan-Che", "Huang", "Xiao Quan"], "title": "No Word Left Behind: Mitigating Prefix Bias in Open-Vocabulary Keyword Spotting", "comment": "Published in ICASSP 2026", "summary": "Open-vocabulary keyword spotting (OV-KWS) enables personalized device control via arbitrary voice commands. Recently, researchers have explored using audio-text joint embeddings, allowing users to enroll phrases with text, and proposed techniques to disambiguate similar utterances. We find that existing OV-KWS solutions often overly bias the beginning phonemes of an enrollment, causing false triggers when negative enrollment-query-pairs share a prefix (``turn the volume up'' vs. ``turn the volume down''). We trace this to two factors: training data bias and position-biased cross-modal scoring. To address these limitations, we introduce the Partial Overlap Benchmark (POB) with two datasets, POB-Spark and POB-LibriPhrase (POB-LP), containing mismatched audio-text pairs with shared prefixes, and propose Equal-weighting Position Scoring (EPS), a lightweight decision layer. Using EPS alone reduces EER on POB-Spark from 64.4\\% to 29.3\\% and improves POB-LP accuracy from 87.6\\% to 96.8\\%, while maintaining performance on LibriPhrase and Google Speech Commands (GSC). With POB data added in training, our work achieves the best POB benchmark results while incurring the least amount of degradation on prior metrics among baselines. This degradation is most pronounced in GSC, which contains only one-word commands. We surface mitigating this trade-off as future work.", "AI": {"tldr": "\u672c\u6587\u9488\u5bf9\u5f00\u653e\u8bcd\u6c47\u5173\u952e\u8bcd\u68c0\u6d4b\u4e2d\u5b58\u5728\u7684\"\u524d\u7f00\u504f\u89c1\"\u95ee\u9898\uff0c\u63d0\u51fa\u4e86\u90e8\u5206\u91cd\u53e0\u57fa\u51c6(POB)\u548c\u7b49\u6743\u91cd\u4f4d\u7f6e\u8bc4\u5206(EPS)\u65b9\u6cd5\uff0c\u663e\u8457\u6539\u5584\u4e86\u76f8\u4f3c\u524d\u7f00\u77ed\u8bed\u7684\u533a\u5206\u80fd\u529b\u3002", "motivation": "\u73b0\u6709\u5f00\u653e\u8bcd\u6c47\u5173\u952e\u8bcd\u68c0\u6d4b\u7cfb\u7edf\u5bf9\u6ce8\u518c\u77ed\u8bed\u7684\u5f00\u5934\u53d1\u97f3\u5b58\u5728\u8fc7\u5ea6\u504f\u89c1\uff0c\u5bfc\u81f4\u5171\u4eab\u524d\u7f00\u7684\u8d1f\u6837\u672c\u5bf9\uff08\u5982\"turn the volume up\" vs \"turn the volume down\"\uff09\u4ea7\u751f\u8bef\u89e6\u53d1\u3002\u8fd9\u6e90\u4e8e\u8bad\u7ec3\u6570\u636e\u504f\u89c1\u548c\u4f4d\u7f6e\u504f\u89c1\u7684\u8de8\u6a21\u6001\u8bc4\u5206\u3002", "method": "1) \u5f15\u5165\u90e8\u5206\u91cd\u53e0\u57fa\u51c6(POB)\uff0c\u5305\u542bPOB-Spark\u548cPOB-LibriPhrase\u4e24\u4e2a\u6570\u636e\u96c6\uff0c\u4e13\u95e8\u6d4b\u8bd5\u5171\u4eab\u524d\u7f00\u7684\u97f3\u9891-\u6587\u672c\u5bf9\uff1b2) \u63d0\u51fa\u7b49\u6743\u91cd\u4f4d\u7f6e\u8bc4\u5206(EPS)\uff0c\u4e00\u79cd\u8f7b\u91cf\u7ea7\u51b3\u7b56\u5c42\uff0c\u7f13\u89e3\u4f4d\u7f6e\u504f\u89c1\u3002", "result": "\u4ec5\u4f7f\u7528EPS\u5373\u53ef\u5c06POB-Spark\u7684EER\u4ece64.4%\u964d\u81f329.3%\uff0cPOB-LP\u51c6\u786e\u7387\u4ece87.6%\u63d0\u5347\u81f396.8%\u3002\u52a0\u5165POB\u6570\u636e\u8bad\u7ec3\u540e\uff0c\u5728\u4fdd\u6301LibriPhrase\u548cGSC\u6027\u80fd\u7684\u540c\u65f6\uff0c\u53d6\u5f97\u4e86\u6700\u4f73\u7684POB\u57fa\u51c6\u7ed3\u679c\u3002", "conclusion": "\u672c\u6587\u63d0\u51fa\u7684POB\u57fa\u51c6\u548cEPS\u65b9\u6cd5\u6709\u6548\u89e3\u51b3\u4e86\u5f00\u653e\u8bcd\u6c47\u5173\u952e\u8bcd\u68c0\u6d4b\u4e2d\u7684\u524d\u7f00\u504f\u89c1\u95ee\u9898\uff0c\u4f46\u5728\u5355\u8bcd\u8bed\u4ee4\u7684GSC\u6570\u636e\u96c6\u4e0a\u5b58\u5728\u6027\u80fd\u6743\u8861\uff0c\u7f13\u89e3\u8fd9\u4e00\u6743\u8861\u662f\u672a\u6765\u7684\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2602.07270", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07270", "abs": "https://arxiv.org/abs/2602.07270", "authors": ["Siminfar Samakoush Galougah"], "title": "Spectrum Coexistence, Network Dimensioning, and Cell-Free Architectures in 5G and 5G-Advanced Wireless Networks", "comment": null, "summary": "Fifth-generation (5G) wireless networks introduce new architectural paradigms, spectrum usage models, and optimization challenges to support enhanced mobile broadband, massive machine-type communications, and ultra-reliable low-latency communications. This survey provides a comprehensive overview of key technologies and design challenges in 5G systems, with a focus on spectrum coexistence and interference management, network dimensioning and planning, cell-free massive MIMO architectures, fronthaul-aware user management, and power allocation strategies. Representative analytical, simulation-based, and optimization-driven approaches are reviewed, fundamental trade-offs are highlighted, and open research challenges relevant to 5G-Advanced and beyond are identified.", "AI": {"tldr": "\u8fd9\u7bc7\u7efc\u8ff0\u8bba\u6587\u5168\u9762\u6982\u8ff0\u4e865G\u65e0\u7ebf\u7f51\u7edc\u7684\u5173\u952e\u6280\u672f\u3001\u8bbe\u8ba1\u6311\u6218\u548c\u89e3\u51b3\u65b9\u6848\uff0c\u91cd\u70b9\u5173\u6ce8\u9891\u8c31\u5171\u5b58\u3001\u5e72\u6270\u7ba1\u7406\u3001\u7f51\u7edc\u89c4\u5212\u3001\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u67b6\u6784\u7b49\u6838\u5fc3\u95ee\u9898\u3002", "motivation": "5G\u7f51\u7edc\u5f15\u5165\u4e86\u65b0\u7684\u67b6\u6784\u8303\u5f0f\u3001\u9891\u8c31\u4f7f\u7528\u6a21\u578b\u548c\u4f18\u5316\u6311\u6218\uff0c\u9700\u8981\u652f\u6301\u589e\u5f3a\u79fb\u52a8\u5bbd\u5e26\u3001\u5927\u89c4\u6a21\u673a\u5668\u7c7b\u578b\u901a\u4fe1\u548c\u8d85\u53ef\u9760\u4f4e\u5ef6\u8fdf\u901a\u4fe1\u3002\u73b0\u6709\u7814\u7a76\u9700\u8981\u7cfb\u7edf\u6027\u7684\u68b3\u7406\u548c\u603b\u7ed3\uff0c\u4ee5\u6307\u5bfc5G\u53ca\u540e\u7eed\u6f14\u8fdb\u6280\u672f\u7684\u53d1\u5c55\u3002", "method": "\u91c7\u7528\u7efc\u8ff0\u7814\u7a76\u65b9\u6cd5\uff0c\u7cfb\u7edf\u56de\u987e\u4e86\u4ee3\u8868\u6027\u7684\u5206\u6790\u65b9\u6cd5\u3001\u57fa\u4e8e\u4eff\u771f\u7684\u65b9\u6cd5\u548c\u4f18\u5316\u9a71\u52a8\u65b9\u6cd5\uff0c\u91cd\u70b9\u5173\u6ce8\u9891\u8c31\u5171\u5b58\u4e0e\u5e72\u6270\u7ba1\u7406\u3001\u7f51\u7edc\u7ef4\u5ea6\u89c4\u5212\u3001\u65e0\u8702\u7a9d\u5927\u89c4\u6a21MIMO\u67b6\u6784\u3001\u524d\u4f20\u611f\u77e5\u7528\u6237\u7ba1\u7406\u548c\u529f\u7387\u5206\u914d\u7b56\u7565\u7b49\u5173\u952e\u6280\u672f\u3002", "result": "\u8bba\u6587\u603b\u7ed3\u4e865G\u7cfb\u7edf\u7684\u5173\u952e\u6280\u672f\u89e3\u51b3\u65b9\u6848\uff0c\u7a81\u51fa\u4e86\u57fa\u672c\u6743\u8861\u5173\u7cfb\uff0c\u8bc6\u522b\u4e865G-Advanced\u53ca\u672a\u6765\u7f51\u7edc\u9762\u4e34\u7684\u6838\u5fc3\u7814\u7a76\u6311\u6218\uff0c\u4e3a\u540e\u7eed\u7814\u7a76\u63d0\u4f9b\u4e86\u7cfb\u7edf\u6027\u53c2\u8003\u6846\u67b6\u3002", "conclusion": "5G\u7f51\u7edc\u9762\u4e34\u590d\u6742\u7684\u6280\u672f\u6311\u6218\uff0c\u9700\u8981\u591a\u65b9\u9762\u7684\u534f\u540c\u4f18\u5316\u3002\u8be5\u7efc\u8ff0\u4e3a\u7406\u89e35G\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u5168\u9762\u89c6\u89d2\uff0c\u5e76\u4e3a5G-Advanced\u53ca\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u7684\u6f14\u8fdb\u6307\u660e\u4e86\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2602.08979", "categories": ["cs.SD", "cs.CL"], "pdf": "https://arxiv.org/pdf/2602.08979", "abs": "https://arxiv.org/abs/2602.08979", "authors": ["Fabian Retkowski", "Maike Z\u00fcfle", "Thai Binh Nguyen", "Jan Niehues", "Alexander Waibel"], "title": "Beyond Transcripts: A Renewed Perspective on Audio Chaptering", "comment": null, "summary": "Audio chaptering, the task of automatically segmenting long-form audio into coherent sections, is increasingly important for navigating podcasts, lectures, and videos. Despite its relevance, research remains limited and text-based, leaving key questions unresolved about leveraging audio information, handling ASR errors, and transcript-free evaluation. We address these gaps through three contributions: (1) a systematic comparison between text-based models with acoustic features, a novel audio-only architecture (AudioSeg) operating on learned audio representations, and multimodal LLMs; (2) empirical analysis of factors affecting performance, including transcript quality, acoustic features, duration, and speaker composition; and (3) formalized evaluation protocols contrasting transcript-dependent text-space protocols with transcript-invariant time-space protocols. Our experiments on YTSeg reveal that AudioSeg substantially outperforms text-based approaches, pauses provide the largest acoustic gains, and MLLMs remain limited by context length and weak instruction following, yet MLLMs are promising on shorter audio.", "AI": {"tldr": "\u672c\u6587\u7cfb\u7edf\u7814\u7a76\u4e86\u97f3\u9891\u7ae0\u8282\u5212\u5206\u4efb\u52a1\uff0c\u6bd4\u8f83\u4e86\u6587\u672c\u6a21\u578b\u3001\u97f3\u9891\u6a21\u578b\u548c\u591a\u6a21\u6001\u5927\u6a21\u578b\uff0c\u53d1\u73b0\u97f3\u9891\u6a21\u578bAudioSeg\u6027\u80fd\u6700\u4f73\uff0c\u505c\u987f\u4fe1\u606f\u8d21\u732e\u6700\u5927\uff0c\u591a\u6a21\u6001\u5927\u6a21\u578b\u53d7\u9650\u4e8e\u4e0a\u4e0b\u6587\u957f\u5ea6\u4f46\u5728\u77ed\u97f3\u9891\u4e0a\u6709\u6f5c\u529b\u3002", "motivation": "\u97f3\u9891\u7ae0\u8282\u5212\u5206\u5bf9\u4e8e\u64ad\u5ba2\u3001\u8bb2\u5ea7\u548c\u89c6\u9891\u5bfc\u822a\u8d8a\u6765\u8d8a\u91cd\u8981\uff0c\u4f46\u73b0\u6709\u7814\u7a76\u6709\u9650\u4e14\u4e3b\u8981\u57fa\u4e8e\u6587\u672c\uff0c\u672a\u89e3\u51b3\u5982\u4f55\u5229\u7528\u97f3\u9891\u4fe1\u606f\u3001\u5904\u7406ASR\u9519\u8bef\u4ee5\u53ca\u65e0\u8f6c\u5f55\u672c\u8bc4\u4f30\u7b49\u5173\u952e\u95ee\u9898\u3002", "method": "\u901a\u8fc7\u4e09\u4e2a\u8d21\u732e\uff1a(1) \u7cfb\u7edf\u6bd4\u8f83\u6587\u672c\u6a21\u578b\uff08\u52a0\u5165\u58f0\u5b66\u7279\u5f81\uff09\u3001\u65b0\u9896\u7684\u7eaf\u97f3\u9891\u67b6\u6784AudioSeg\uff08\u57fa\u4e8e\u5b66\u4e60\u97f3\u9891\u8868\u793a\uff09\u548c\u591a\u6a21\u6001LLM\uff1b(2) \u5b9e\u8bc1\u5206\u6790\u5f71\u54cd\u6027\u80fd\u7684\u56e0\u7d20\uff0c\u5305\u62ec\u8f6c\u5f55\u8d28\u91cf\u3001\u58f0\u5b66\u7279\u5f81\u3001\u65f6\u957f\u548c\u8bf4\u8bdd\u4eba\u7ec4\u6210\uff1b(3) \u5f62\u5f0f\u5316\u8bc4\u4f30\u534f\u8bae\uff0c\u5bf9\u6bd4\u4f9d\u8d56\u8f6c\u5f55\u672c\u7684\u6587\u672c\u7a7a\u95f4\u534f\u8bae\u548c\u4e0d\u4f9d\u8d56\u8f6c\u5f55\u672c\u7684\u65f6\u95f4\u7a7a\u95f4\u534f\u8bae\u3002", "result": "\u5728YTSeg\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff1aAudioSeg\u663e\u8457\u4f18\u4e8e\u6587\u672c\u65b9\u6cd5\uff1b\u505c\u987f\u4fe1\u606f\u5e26\u6765\u6700\u5927\u7684\u58f0\u5b66\u589e\u76ca\uff1b\u591a\u6a21\u6001LLM\u53d7\u9650\u4e8e\u4e0a\u4e0b\u6587\u957f\u5ea6\u548c\u5f31\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\uff0c\u4f46\u5728\u8f83\u77ed\u97f3\u9891\u4e0a\u8868\u73b0\u6709\u6f5c\u529b\u3002", "conclusion": "\u97f3\u9891\u4fe1\u606f\u5bf9\u7ae0\u8282\u5212\u5206\u81f3\u5173\u91cd\u8981\uff0c\u7eaf\u97f3\u9891\u6a21\u578bAudioSeg\u8868\u73b0\u6700\u4f73\uff0c\u505c\u987f\u662f\u5173\u952e\u58f0\u5b66\u7279\u5f81\uff0c\u591a\u6a21\u6001\u5927\u6a21\u578b\u5728\u77ed\u97f3\u9891\u4e0a\u6709\u5e94\u7528\u524d\u666f\uff0c\u9700\u8981\u6539\u8fdb\u4e0a\u4e0b\u6587\u5904\u7406\u548c\u6307\u4ee4\u8ddf\u968f\u80fd\u529b\u3002"}}
{"id": "2602.07321", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07321", "abs": "https://arxiv.org/abs/2602.07321", "authors": ["Changyuan Zhao", "Jiacheng Wang", "Yunting Xu", "Geng Sun", "Dusit Niyato", "Zan Li", "Abbas Jamalipour", "Dong In Kim"], "title": "Wireless Context Engineering for Efficient Mobile Agentic AI and Edge General Intelligence", "comment": "7 pages, 4 figures", "summary": "Future wireless networks demand increasingly powerful intelligence to support sensing, communication, and autonomous decision-making. While scaling laws suggest improving performance by enlarging model capacity, practical edge deployments are fundamentally constrained by latency, energy, and memory, making unlimited model scaling infeasible. This creates a critical need to maximize the utility of limited inference-time inputs by filtering redundant observations and focusing on high-impact data. In large language models and generative artificial intelligence (AI), context engineering has emerged as a key paradigm to guide inference by selectively structuring and injecting task-relevant information. Inspired by this success, we extend context engineering to wireless systems, providing a systematic way to enhance edge AI performance without increasing model complexity. In dynamic environments, for example, beam prediction can benefit from augmenting instantaneous channel measurements with contextual cues such as user mobility trends or environment-aware propagation priors. We formally introduce wireless context engineering and propose a Wireless Context Communication Framework (WCCF) to adaptively orchestrate wireless context under inference-time constraints. This work provides researchers with a foundational perspective and practical design dimensions to manage the wireless context of wireless edge intelligence. An ISAC-enabled beam prediction case study illustrates the effectiveness of the proposed paradigm under constrained sensing budgets.", "AI": {"tldr": "\u5c06\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4e0a\u4e0b\u6587\u5de5\u7a0b\u6982\u5ff5\u6269\u5c55\u5230\u65e0\u7ebf\u7cfb\u7edf\uff0c\u63d0\u51fa\u65e0\u7ebf\u4e0a\u4e0b\u6587\u5de5\u7a0b\u6846\u67b6\uff0c\u5728\u6709\u9650\u63a8\u7406\u8d44\u6e90\u4e0b\u901a\u8fc7\u9009\u62e9\u6027\u7ed3\u6784\u5316\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u6765\u63d0\u5347\u8fb9\u7f18AI\u6027\u80fd\u3002", "motivation": "\u672a\u6765\u65e0\u7ebf\u7f51\u7edc\u9700\u8981\u5f3a\u5927\u7684\u667a\u80fd\u652f\u6301\u611f\u77e5\u3001\u901a\u4fe1\u548c\u81ea\u4e3b\u51b3\u7b56\uff0c\u4f46\u8fb9\u7f18\u90e8\u7f72\u53d7\u5ef6\u8fdf\u3001\u80fd\u8017\u548c\u5185\u5b58\u9650\u5236\uff0c\u65e0\u6cd5\u65e0\u9650\u6269\u5c55\u6a21\u578b\u5bb9\u91cf\u3002\u9700\u8981\u6700\u5927\u5316\u6709\u9650\u63a8\u7406\u8f93\u5165\u7684\u6709\u6548\u6027\uff0c\u8fc7\u6ee4\u5197\u4f59\u89c2\u6d4b\uff0c\u805a\u7126\u9ad8\u5f71\u54cd\u6570\u636e\u3002", "method": "\u5f15\u5165\u65e0\u7ebf\u4e0a\u4e0b\u6587\u5de5\u7a0b\u6982\u5ff5\uff0c\u63d0\u51fa\u65e0\u7ebf\u4e0a\u4e0b\u6587\u901a\u4fe1\u6846\u67b6\uff08WCCF\uff09\uff0c\u5728\u63a8\u7406\u65f6\u95f4\u7ea6\u675f\u4e0b\u81ea\u9002\u5e94\u7f16\u6392\u65e0\u7ebf\u4e0a\u4e0b\u6587\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\uff08ISAC\u4f7f\u80fd\u7684\u6ce2\u675f\u9884\u6d4b\uff09\u5c55\u793a\u5728\u6709\u9650\u611f\u77e5\u9884\u7b97\u4e0b\u7684\u6709\u6548\u6027\u3002", "result": "\u8be5\u5de5\u4f5c\u4e3a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u7ba1\u7406\u65e0\u7ebf\u8fb9\u7f18\u667a\u80fd\u4e0a\u4e0b\u6587\u7684\u57fa\u7840\u89c6\u89d2\u548c\u5b9e\u7528\u8bbe\u8ba1\u7ef4\u5ea6\uff0c\u901a\u8fc7\u9009\u62e9\u6027\u7ed3\u6784\u5316\u4efb\u52a1\u76f8\u5173\u4fe1\u606f\u6765\u589e\u5f3a\u8fb9\u7f18AI\u6027\u80fd\uff0c\u800c\u65e0\u9700\u589e\u52a0\u6a21\u578b\u590d\u6742\u6027\u3002", "conclusion": "\u65e0\u7ebf\u4e0a\u4e0b\u6587\u5de5\u7a0b\u4e3a\u5728\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u73af\u5883\u4e2d\u63d0\u5347AI\u6027\u80fd\u63d0\u4f9b\u4e86\u7cfb\u7edf\u5316\u65b9\u6cd5\uff0c\u901a\u8fc7\u501f\u9274\u5927\u8bed\u8a00\u6a21\u578b\u4e2d\u7684\u4e0a\u4e0b\u6587\u5de5\u7a0b\u8303\u5f0f\uff0c\u5728\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u9ad8\u6548\u7684\u4fe1\u606f\u7b5b\u9009\u548c\u4efb\u52a1\u5bfc\u5411\u63a8\u7406\u3002"}}
{"id": "2602.07350", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07350", "abs": "https://arxiv.org/abs/2602.07350", "authors": ["Kecheng Zhang", "Weijie Yuan", "Yonghui Li"], "title": "Pulse Shaping Filter Design for Zak-OTFS", "comment": "Submitted to IEEE for possible publication", "summary": "The Zak-transform-based Orthogonal Time Frequency Space (Zak-OTFS), offers a robust framework for high-mobility communications by simplifying the input-output (I/O) relation to a twisted convolution. While this structure theoretically enables accurate channel estimation by sampling the response from one pilot symbol, practical implementation is constrained by the spreading of effective channel response induced by pulse shaping filters. To address this, we first derive the I/O relationship for discrete-time oversampled Zak-OTFS, which closely approximates the continuous-time system and facilitates analysis and numerical simulation. We show that every delay-Doppler domain symbol undergoes the same effective channel response under the discrete oversampled Zak-OTFS. We then analyze the impact of window ambiguity functions, and reveal that high sidelobes lead to wide channel spreading and degrade estimation accuracy. Building on this insight, we propose a novel pulse shaping filter design that synthesizes Prolate Spheroidal Wave Functions (PSWFs) within the Isotropic Orthogonal Transform Algorithm (IOTA) framework. Numerical simulations confirm that the proposed design achieves superior channel estimation accuracy and bit error rate (BER) performance compared to conventional root-raised-cosine and rectangular windowing schemes in the high-SNR regime.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8eZak\u53d8\u6362\u7684\u6b63\u4ea4\u65f6\u9891\u7a7a\u95f4(Zak-OTFS)\u7cfb\u7edf\uff0c\u901a\u8fc7\u8bbe\u8ba1\u65b0\u7684\u8109\u51b2\u6210\u5f62\u6ee4\u6ce2\u5668\u6765\u6539\u5584\u9ad8\u79fb\u52a8\u6027\u901a\u4fe1\u4e2d\u7684\u4fe1\u9053\u4f30\u8ba1\u6027\u80fd\u3002", "motivation": "Zak-OTFS\u867d\u7136\u7406\u8bba\u4e0a\u80fd\u901a\u8fc7\u4e00\u4e2a\u5bfc\u9891\u7b26\u53f7\u5b9e\u73b0\u51c6\u786e\u4fe1\u9053\u4f30\u8ba1\uff0c\u4f46\u5b9e\u9645\u4e2d\u8109\u51b2\u6210\u5f62\u6ee4\u6ce2\u5668\u4f1a\u5bfc\u81f4\u6709\u6548\u4fe1\u9053\u54cd\u5e94\u6269\u6563\uff0c\u9650\u5236\u4e86\u7cfb\u7edf\u6027\u80fd\u3002", "method": "\u9996\u5148\u63a8\u5bfc\u79bb\u6563\u65f6\u95f4\u8fc7\u91c7\u6837Zak-OTFS\u7684\u8f93\u5165\u8f93\u51fa\u5173\u7cfb\uff0c\u5206\u6790\u7a97\u53e3\u6a21\u7cca\u51fd\u6570\u7684\u5f71\u54cd\uff0c\u7136\u540e\u63d0\u51fa\u5728IOTA\u6846\u67b6\u5185\u5408\u6210PSWF\u7684\u65b0\u578b\u8109\u51b2\u6210\u5f62\u6ee4\u6ce2\u5668\u8bbe\u8ba1\u3002", "result": "\u6570\u503c\u4eff\u771f\u8868\u660e\uff0c\u76f8\u6bd4\u4f20\u7edf\u7684\u6839\u5347\u4f59\u5f26\u548c\u77e9\u5f62\u7a97\u65b9\u6848\uff0c\u6240\u63d0\u8bbe\u8ba1\u5728\u9ad8\u4fe1\u566a\u6bd4\u4e0b\u5b9e\u73b0\u4e86\u66f4\u4f18\u7684\u4fe1\u9053\u4f30\u8ba1\u7cbe\u5ea6\u548c\u8bef\u7801\u7387\u6027\u80fd\u3002", "conclusion": "\u901a\u8fc7\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8109\u51b2\u6210\u5f62\u6ee4\u6ce2\u5668\uff0c\u53ef\u4ee5\u6709\u6548\u6291\u5236\u4fe1\u9053\u54cd\u5e94\u6269\u6563\uff0c\u63d0\u5347Zak-OTFS\u7cfb\u7edf\u5728\u9ad8\u79fb\u52a8\u6027\u901a\u4fe1\u4e2d\u7684\u5b9e\u9645\u6027\u80fd\u3002"}}
{"id": "2602.07365", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07365", "abs": "https://arxiv.org/abs/2602.07365", "authors": ["Xiaohan Lv", "Rang Liu", "Yi Chen", "Qian Liu", "Ming Li"], "title": "Message Passing based Parameter Estimation in Cooperative MIMO-OFDM ISAC Systems", "comment": null, "summary": "In integrated sensing and communication (ISAC) networks, multiple base stations (BSs) collaboratively sense a common target, leveraging diversity from multiple observation perspectives and joint signal processing to enhance sensing performance. This paper introduces a novel message-passing (MP)-based parameter estimation framework for collaborative MIMO-OFDM ISAC systems, which jointly estimates the target's position and velocity. First, a signal propagation model is established based on geometric relationships, and a factor graph is constructed to represent the unknown parameters. The sum-product algorithm (SPA) is then applied to this factor graph to jointly estimate the multi-dimensional parameter vector. To reduce communication overhead and computational complexity, we employ a hierarchical message-passing scheme with Gaussian approximation. By adopting parameterized message distributions and layered processing, the proposed method significantly reduces both computational complexity and inter-BS communication overhead. Simulation results demonstrate the effectiveness of the proposed MP-based parameter estimation algorithm and highlight the benefits of multi-perspective observations and joint signal processing for cooperative sensing in MIMO-OFDM ISAC systems.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u57fa\u4e8e\u6d88\u606f\u4f20\u9012\u7684\u534f\u4f5cMIMO-OFDM ISAC\u7cfb\u7edf\u53c2\u6570\u4f30\u8ba1\u6846\u67b6\uff0c\u8054\u5408\u4f30\u8ba1\u76ee\u6807\u4f4d\u7f6e\u548c\u901f\u5ea6\uff0c\u901a\u8fc7\u5206\u5c42\u6d88\u606f\u4f20\u9012\u964d\u4f4e\u901a\u4fe1\u5f00\u9500\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "motivation": "\u5728ISAC\u7f51\u7edc\u4e2d\uff0c\u591a\u4e2a\u57fa\u7ad9\u534f\u4f5c\u611f\u77e5\u5171\u540c\u76ee\u6807\uff0c\u5229\u7528\u591a\u89c6\u89d2\u89c2\u6d4b\u548c\u8054\u5408\u4fe1\u53f7\u5904\u7406\u63d0\u5347\u611f\u77e5\u6027\u80fd\u3002\u73b0\u6709\u65b9\u6cd5\u5728\u901a\u4fe1\u5f00\u9500\u548c\u8ba1\u7b97\u590d\u6742\u5ea6\u65b9\u9762\u5b58\u5728\u6311\u6218\uff0c\u9700\u8981\u9ad8\u6548\u7684\u591a\u57fa\u7ad9\u534f\u4f5c\u53c2\u6570\u4f30\u8ba1\u7b97\u6cd5\u3002", "method": "1. \u57fa\u4e8e\u51e0\u4f55\u5173\u7cfb\u5efa\u7acb\u4fe1\u53f7\u4f20\u64ad\u6a21\u578b\uff1b2. \u6784\u5efa\u8868\u793a\u672a\u77e5\u53c2\u6570\u7684\u56e0\u5b50\u56fe\uff1b3. \u5e94\u7528\u548c\u79ef\u7b97\u6cd5\u8054\u5408\u4f30\u8ba1\u591a\u7ef4\u53c2\u6570\u5411\u91cf\uff1b4. \u91c7\u7528\u9ad8\u65af\u8fd1\u4f3c\u7684\u5206\u5c42\u6d88\u606f\u4f20\u9012\u65b9\u6848\uff0c\u901a\u8fc7\u53c2\u6570\u5316\u6d88\u606f\u5206\u5e03\u548c\u5206\u5c42\u5904\u7406\u964d\u4f4e\u590d\u6742\u5ea6\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684MP\u53c2\u6570\u4f30\u8ba1\u7b97\u6cd5\u6709\u6548\uff0c\u591a\u89c6\u89d2\u89c2\u6d4b\u548c\u8054\u5408\u4fe1\u53f7\u5904\u7406\u5728\u534f\u4f5c\u611f\u77e5\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\uff0c\u540c\u65f6\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u590d\u6742\u5ea6\u548c\u57fa\u7ad9\u95f4\u901a\u4fe1\u5f00\u9500\u3002", "conclusion": "\u63d0\u51fa\u7684\u6d88\u606f\u4f20\u9012\u6846\u67b6\u4e3a\u534f\u4f5cMIMO-OFDM ISAC\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u9ad8\u6548\u7684\u53c2\u6570\u4f30\u8ba1\u65b9\u6cd5\uff0c\u901a\u8fc7\u5206\u5c42\u6d88\u606f\u4f20\u9012\u673a\u5236\u5e73\u8861\u4e86\u6027\u80fd\u4e0e\u590d\u6742\u5ea6\uff0c\u9a8c\u8bc1\u4e86\u591a\u57fa\u7ad9\u534f\u4f5c\u611f\u77e5\u7684\u4ef7\u503c\u3002"}}
{"id": "2602.07502", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07502", "abs": "https://arxiv.org/abs/2602.07502", "authors": ["Xiaotong Zhao", "Mian Li", "Ya-Feng Liu", "Qingjiang Shi", "Anthony Man-Cho So"], "title": "Optimal Low-Dimensional Structures of ISAC Beamforming: Theory and Efficient Algorithms", "comment": null, "summary": "Transmit beamforming design is a fundamental problem in integrated sensing and communication (ISAC) systems. Numerous methods have been proposed to jointly optimize key performance metrics such as the signal-to-interference-plus-noise ratio and Cram\u00e9r-Rao bound. However, the computational complexity of these methods often grows rapidly with the number of transmit antennas at the base station (BS). To tackle this challenge, we prove a fundamental structural property of the ISAC beamforming problem, i.e., there exists an optimal solution exhibiting a low-dimensional structure. This leads to an equivalent reformulation of the problem with dimension related to the number of users rather than the number of BS antennas, thereby enabling the development of low-complexity algorithms. When applying the interior-point method to the reformulated problem, we achieve up to six orders of magnitude in complexity reduction when the number of antennas exceeds the number of users by an order of magnitude. To further reduce the complexity, we develop a balanced augmented Lagrangian method to solve the reformulated problem. The proposed algorithm maintains optimality while achieving a computational complexity that scales quartically with the number of users. Our simulation results demonstrate that the proposed R-BAL method can achieve a speedup of more than 10000$\\times$ over the conventional IPM in massive MIMO scenarios.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u7528\u4e8eISAC\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u7684\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\uff0c\u901a\u8fc7\u8bc1\u660e\u6700\u4f18\u89e3\u5177\u6709\u4f4e\u7ef4\u7ed3\u6784\u7279\u6027\uff0c\u5c06\u95ee\u9898\u7ef4\u5ea6\u4ece\u5929\u7ebf\u6570\u964d\u4f4e\u5230\u7528\u6237\u6570\uff0c\u5b9e\u73b0\u4e86\u9ad8\u8fbe6\u4e2a\u6570\u91cf\u7ea7\u7684\u590d\u6742\u5ea6\u964d\u4f4e\u3002", "motivation": "ISAC\u7cfb\u7edf\u4e2d\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u968f\u7740\u57fa\u7ad9\u5929\u7ebf\u6570\u91cf\u7684\u589e\u52a0\u800c\u6025\u5267\u589e\u957f\uff0c\u8fd9\u5728\u5927\u89c4\u6a21MIMO\u573a\u666f\u4e2d\u6210\u4e3a\u4e00\u4e2a\u4e25\u91cd\u6311\u6218\u3002\u73b0\u6709\u65b9\u6cd5\u867d\u7136\u80fd\u8054\u5408\u4f18\u5316\u5173\u952e\u6027\u80fd\u6307\u6807\uff0c\u4f46\u8ba1\u7b97\u8d1f\u62c5\u8fc7\u91cd\u3002", "method": "\u9996\u5148\u8bc1\u660e\u4e86ISAC\u6ce2\u675f\u6210\u5f62\u95ee\u9898\u7684\u6700\u4f18\u89e3\u5177\u6709\u4f4e\u7ef4\u7ed3\u6784\u7279\u6027\uff0c\u57fa\u4e8e\u6b64\u5c06\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u4e3a\u7ef4\u5ea6\u4e0e\u7528\u6237\u6570\u76f8\u5173\u7684\u7b49\u4ef7\u5f62\u5f0f\u3002\u7136\u540e\u5f00\u53d1\u4e86\u4e24\u79cd\u7b97\u6cd5\uff1a1\uff09\u5c06\u5185\u70b9\u6cd5\u5e94\u7528\u4e8e\u91cd\u65b0\u8868\u8ff0\u7684\u95ee\u9898\uff1b2\uff09\u63d0\u51fa\u5e73\u8861\u589e\u5e7f\u62c9\u683c\u6717\u65e5\u65b9\u6cd5\u8fdb\u4e00\u6b65\u964d\u4f4e\u590d\u6742\u5ea6\u3002", "result": "\u5f53\u5929\u7ebf\u6570\u8d85\u8fc7\u7528\u6237\u6570\u4e00\u4e2a\u6570\u91cf\u7ea7\u65f6\uff0c\u5185\u70b9\u6cd5\u53ef\u5b9e\u73b0\u9ad8\u8fbe6\u4e2a\u6570\u91cf\u7ea7\u7684\u590d\u6742\u5ea6\u964d\u4f4e\u3002\u63d0\u51fa\u7684R-BAL\u65b9\u6cd5\u5728\u5927\u89c4\u6a21MIMO\u573a\u666f\u4e2d\u6bd4\u4f20\u7edf\u5185\u70b9\u6cd5\u5feb10000\u500d\u4ee5\u4e0a\uff0c\u540c\u65f6\u4fdd\u6301\u6700\u4f18\u6027\uff0c\u8ba1\u7b97\u590d\u6742\u5ea6\u4ec5\u4e0e\u7528\u6237\u6570\u7684\u56db\u6b21\u65b9\u6210\u6b63\u6bd4\u3002", "conclusion": "\u901a\u8fc7\u63ed\u793aISAC\u6ce2\u675f\u6210\u5f62\u95ee\u9898\u7684\u4f4e\u7ef4\u7ed3\u6784\u7279\u6027\uff0c\u672c\u6587\u6210\u529f\u5f00\u53d1\u4e86\u9ad8\u6548\u7684\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u7684\u8ba1\u7b97\u8d1f\u62c5\uff0c\u4e3a\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07515", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07515", "abs": "https://arxiv.org/abs/2602.07515", "authors": ["Hua Chen", "Zhenhao Yu", "Tuo Wu", "Wei Liu", "Maged Elkashlan", "Hyundong Shin", "Matthew C. Valenti", "Robert Schober"], "title": "Beyond $\u03bb/2$: Can Arbitrary EMVS Arrays Achieve Unambiguous NLOS Localization?", "comment": null, "summary": "Conventional radar array design mandates interelement spacing not exceeding half a wavelength ($\u03bb/2$) to avoid spatial ambiguity, fundamentally limiting array aperture and angular resolution. This paper addresses the fundamental question: Can arbitrary electromagnetic vector sensor (EMVS) arrays achieve unambiguous reconfigurable intelligent surface (RIS)-aided localization when element spacing exceeds $\u03bb/2$? We provide an affirmative answer by exploiting the multi-component structure of EMVS measurements and developing a synergistic estimation and optimization framework for non-line-of-sight (NLOS) bistatic multiple input multiple output (MIMO) radar. A third-order parallel factor (PARAFAC) model is constructed from EMVS observations, enabling natural separation of spatial, polarimetric, and propagation effects via the trilinear alternating least squares (TALS) algorithm. A novel phase-disambiguation procedure leverages rotational invariance across the six electromagnetic components of EMVSs to resolve $2\u03c0$ phase wrapping in arbitrary array geometries, allowing unambiguous joint estimation of two-dimensional (2-D) direction of departure (DOD), two-dimensional direction of arrival (DOA), and polarization parameters with automatic pairing. To support localization in NLOS environments and enhance estimation robustness, a reconfigurable intelligent surface (RIS) is incorporated and its phase shifts are optimized via semidefinite programming (SDP) relaxation to maximize received signal power, improving signal-to-noise ratio (SNR) and further suppressing spatial ambiguities through iterative refinement.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u5229\u7528\u7535\u78c1\u77e2\u91cf\u4f20\u611f\u5668\uff08EMVS\uff09\u9635\u5217\u548c\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u5b9e\u73b0\u8d85\u534a\u6ce2\u957f\u95f4\u8ddd\u65e0\u6a21\u7cca\u5b9a\u4f4d\u7684\u65b9\u6cd5\uff0c\u901a\u8fc7PARAFAC\u6a21\u578b\u548c\u76f8\u4f4d\u89e3\u6a21\u7cca\u6280\u672f\u89e3\u51b3\u4e86\u4f20\u7edf\u9635\u5217\u8bbe\u8ba1\u7684\u5b54\u5f84\u9650\u5236\u95ee\u9898\u3002", "motivation": "\u4f20\u7edf\u96f7\u8fbe\u9635\u5217\u8bbe\u8ba1\u8981\u6c42\u9635\u5143\u95f4\u8ddd\u4e0d\u8d85\u8fc7\u534a\u6ce2\u957f\u4ee5\u907f\u514d\u7a7a\u95f4\u6a21\u7cca\uff0c\u8fd9\u4ece\u6839\u672c\u4e0a\u9650\u5236\u4e86\u9635\u5217\u5b54\u5f84\u548c\u89d2\u5ea6\u5206\u8fa8\u7387\u3002\u8bba\u6587\u65e8\u5728\u63a2\u7d22\u5f53EMVS\u9635\u5217\u95f4\u8ddd\u8d85\u8fc7\u03bb/2\u65f6\uff0c\u662f\u5426\u4ecd\u80fd\u5b9e\u73b0\u65e0\u6a21\u7cca\u7684RIS\u8f85\u52a9\u5b9a\u4f4d\u3002", "method": "1. \u6784\u5efa\u57fa\u4e8eEMVS\u89c2\u6d4b\u7684\u4e09\u9636PARAFAC\u6a21\u578b\uff0c\u5229\u7528\u4e09\u7ebf\u6027\u4ea4\u66ff\u6700\u5c0f\u4e8c\u4e58\uff08TALS\uff09\u7b97\u6cd5\u5206\u79bb\u7a7a\u95f4\u3001\u6781\u5316\u548c\u4f20\u64ad\u6548\u5e94\n2. \u63d0\u51fa\u65b0\u9896\u7684\u76f8\u4f4d\u89e3\u6a21\u7cca\u7a0b\u5e8f\uff0c\u5229\u7528EMVS\u516d\u4e2a\u7535\u78c1\u5206\u91cf\u7684\u65cb\u8f6c\u4e0d\u53d8\u6027\u89e3\u51b3\u4efb\u610f\u9635\u5217\u51e0\u4f55\u4e2d\u76842\u03c0\u76f8\u4f4d\u7f20\u7ed5\u95ee\u9898\n3. \u901a\u8fc7\u534a\u5b9a\u89c4\u5212\uff08SDP\uff09\u677e\u5f1b\u4f18\u5316RIS\u76f8\u4f4d\u504f\u79fb\uff0c\u6700\u5927\u5316\u63a5\u6536\u4fe1\u53f7\u529f\u7387\uff0c\u63d0\u9ad8\u4fe1\u566a\u6bd4\u5e76\u6291\u5236\u7a7a\u95f4\u6a21\u7cca", "result": "\u6210\u529f\u8bc1\u660e\u4e86EMVS\u9635\u5217\u5728\u95f4\u8ddd\u8d85\u8fc7\u03bb/2\u65f6\u4ecd\u80fd\u5b9e\u73b0\u65e0\u6a21\u7cca\u5b9a\u4f4d\uff0c\u80fd\u591f\u8054\u5408\u4f30\u8ba1\u4e8c\u7ef4\u53d1\u5c04\u65b9\u5411\uff08DOD\uff09\u3001\u4e8c\u7ef4\u5230\u8fbe\u65b9\u5411\uff08DOA\uff09\u548c\u6781\u5316\u53c2\u6570\uff0c\u5e76\u5b9e\u73b0\u81ea\u52a8\u914d\u5bf9\u3002RIS\u7684\u4f18\u5316\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u5b9a\u4f4d\u7cbe\u5ea6\u548c\u9c81\u68d2\u6027\u3002", "conclusion": "\u8be5\u7814\u7a76\u7a81\u7834\u4e86\u4f20\u7edf\u9635\u5217\u8bbe\u8ba1\u7684\u534a\u6ce2\u957f\u95f4\u8ddd\u9650\u5236\uff0c\u4e3a\u9ad8\u5206\u8fa8\u7387\u5b9a\u4f4d\u7cfb\u7edf\u63d0\u4f9b\u4e86\u65b0\u8303\u5f0f\u3002\u901a\u8fc7\u7ed3\u5408EMVS\u7684\u591a\u5206\u91cf\u7279\u6027\u548cRIS\u4f18\u5316\uff0c\u5b9e\u73b0\u4e86\u5728\u975e\u89c6\u8ddd\u73af\u5883\u4e0b\u7684\u65e0\u6a21\u7cca\u9ad8\u7cbe\u5ea6\u5b9a\u4f4d\uff0c\u5177\u6709\u91cd\u8981\u7684\u7406\u8bba\u548c\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.07527", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07527", "abs": "https://arxiv.org/abs/2602.07527", "authors": ["Yaakoub Berrouche"], "title": "Fractional Filtering and Anomaly-Guided Diagnostics: The Local Damage Mode Extractor (LDME) for Early Gear Fault Detection", "comment": null, "summary": "Early and reliable detection of gear faults in complex drivetrain systems is critical for aviation safety and operational availability. We present the Local Damage Mode Extractor (LDME), a structured, physics-informed signal processing framework that combines dual-path denoising, multiscale decomposition, fractional-domain enhancement, and statistically principled anomaly scoring to produce interpretable condition indicators without supervision. LDME is organized in three layers: (i) dual-path denoising (DWT with adaptive Savitzky-Golay smoothing) to suppress broadband noise while preserving transient fault structure; (ii) multi-scale damage enhancement using a Teager-Kaiser pre-amplifier followed by a Hadamard-Caputo fractional operator that accentuates non-sinusoidal, low-frequency fault signatures; and (iii) decision fusion, where harmonics-aware Fourier indicators are combined and scored by an unsupervised anomaly detector. Evaluation using the Case Western Reserve University (CWRU) bearing dataset, the HUMS 2023 planetary gearbox benchmark, and a controlled simulated dataset shows that LDME consistently distinguishes nominal, early-crack, and propagated-crack stages under various operating conditions. LDME identifies the primary detection event earlier (198 cycles) than HT-TSA (284 cycles) and advances maintenance recommendation time from 383 to 365 cycles. We discuss its relation to prior art, limitations, and future theoretical directions. All code and experimental configurations are documented for reproducibility.", "AI": {"tldr": "LDME\u662f\u4e00\u4e2a\u65e0\u76d1\u7763\u7684\u7269\u7406\u4fe1\u606f\u4fe1\u53f7\u5904\u7406\u6846\u67b6\uff0c\u901a\u8fc7\u53cc\u8def\u5f84\u53bb\u566a\u3001\u591a\u5c3a\u5ea6\u5206\u89e3\u3001\u5206\u6570\u57df\u589e\u5f3a\u548c\u7edf\u8ba1\u5f02\u5e38\u8bc4\u5206\uff0c\u5b9e\u73b0\u9f7f\u8f6e\u6545\u969c\u7684\u65e9\u671f\u53ef\u9760\u68c0\u6d4b\u3002", "motivation": "\u5728\u590d\u6742\u4f20\u52a8\u7cfb\u7edf\u4e2d\uff0c\u9f7f\u8f6e\u6545\u969c\u7684\u65e9\u671f\u53ef\u9760\u68c0\u6d4b\u5bf9\u822a\u7a7a\u5b89\u5168\u548c\u8fd0\u884c\u53ef\u7528\u6027\u81f3\u5173\u91cd\u8981\u3002\u9700\u8981\u4e00\u79cd\u65e0\u9700\u76d1\u7763\u3001\u53ef\u89e3\u91ca\u7684\u6545\u969c\u68c0\u6d4b\u65b9\u6cd5\u3002", "method": "\u4e09\u5c42\u7ed3\u6784\uff1a1) \u53cc\u8def\u5f84\u53bb\u566a\uff08DWT+\u81ea\u9002\u5e94Savitzky-Golay\u5e73\u6ed1\uff09\uff1b2) \u591a\u5c3a\u5ea6\u635f\u4f24\u589e\u5f3a\uff08Teager-Kaiser\u9884\u653e\u5927\u5668+Hadamard-Caputo\u5206\u6570\u7b97\u5b50\uff09\uff1b3) \u51b3\u7b56\u878d\u5408\uff08\u8c10\u6ce2\u611f\u77e5\u5085\u91cc\u53f6\u6307\u6807+\u65e0\u76d1\u7763\u5f02\u5e38\u68c0\u6d4b\u5668\uff09\u3002", "result": "\u5728CWRU\u8f74\u627f\u6570\u636e\u96c6\u3001HUMS 2023\u884c\u661f\u9f7f\u8f6e\u7bb1\u57fa\u51c6\u548c\u6a21\u62df\u6570\u636e\u96c6\u4e0a\uff0cLDME\u80fd\u4e00\u81f4\u533a\u5206\u6b63\u5e38\u3001\u65e9\u671f\u88c2\u7eb9\u548c\u6269\u5c55\u88c2\u7eb9\u9636\u6bb5\uff0c\u6bd4HT-TSA\u66f4\u65e9\u68c0\u6d4b\u5230\u6545\u969c\uff08198 vs 284\u5468\u671f\uff09\uff0c\u7ef4\u62a4\u5efa\u8bae\u65f6\u95f4\u4ece383\u63d0\u524d\u5230365\u5468\u671f\u3002", "conclusion": "LDME\u662f\u4e00\u4e2a\u6709\u6548\u7684\u65e0\u76d1\u7763\u6545\u969c\u68c0\u6d4b\u6846\u67b6\uff0c\u80fd\u5b9e\u73b0\u65e9\u671f\u6545\u969c\u68c0\u6d4b\uff0c\u4ee3\u7801\u548c\u5b9e\u9a8c\u914d\u7f6e\u5df2\u5f00\u6e90\u4ee5\u786e\u4fdd\u53ef\u590d\u73b0\u6027\u3002"}}
{"id": "2602.07586", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07586", "abs": "https://arxiv.org/abs/2602.07586", "authors": ["Sixu Xiao", "Yong Zeng", "Haotian Rong", "Yanqun Tang"], "title": "A Scalable Cloud-Edge Collaborative CKM Construction Framework Enabled by a Foundation Prior Model", "comment": "13 pages, 11 figures", "summary": "Channel knowledge maps (CKMs) provide a site-specific, location-indexed knowledge base that supports environment-aware communications and sensing in 6G networks. In practical deployments, CKM observations are often noisy and irregular due to coverage-induced sparsity and hardware-induced linear/nonlinear degradations. Conventional end-to-end algorithms couple CKM prior information with task- and device-specific observations, and require labeled data and separate training for each construction configuration, which is expensive and therefore incompatible with scalable edge deployments. Motivated by the trends toward cloud-edge collaboration and the Artificial Intelligence - Radio Access Network (AI-RAN) paradigm, we develop a cloud-edge collaborative framework for scalable CKM construction, which enables knowledge sharing across tasks, devices, and regions by explicitly decoupling a generalizable CKM prior from the information provided by local observations. A foundation model is trained once in the cloud using unlabeled data to learn a generalizable CKM prior. During inference, edge nodes combine the shared prior with local observations. Experiments on the CKMImageNet dataset show that the proposed method achieves competitive construction accuracy while substantially reducing training cost and data requirements, mitigating negative transfer, and offering clear advantages in generalization and deployment scalability.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u4e91\u8fb9\u534f\u540c\u7684CKM\u6784\u5efa\u6846\u67b6\uff0c\u901a\u8fc7\u89e3\u8026\u901a\u7528CKM\u5148\u9a8c\u4e0e\u672c\u5730\u89c2\u6d4b\u4fe1\u606f\uff0c\u5b9e\u73b0\u8de8\u4efb\u52a1\u3001\u8bbe\u5907\u548c\u533a\u57df\u7684\u77e5\u8bc6\u5171\u4eab\uff0c\u663e\u8457\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u5e76\u63d0\u5347\u90e8\u7f72\u53ef\u6269\u5c55\u6027\u3002", "motivation": "\u5b9e\u9645\u90e8\u7f72\u4e2dCKM\u89c2\u6d4b\u6570\u636e\u5e38\u56e0\u8986\u76d6\u7a00\u758f\u6027\u548c\u786c\u4ef6\u9000\u5316\u800c\u5b58\u5728\u566a\u58f0\u548c\u4e0d\u89c4\u5219\u6027\u3002\u4f20\u7edf\u7aef\u5230\u7aef\u7b97\u6cd5\u5c06CKM\u5148\u9a8c\u4e0e\u4efb\u52a1\u8bbe\u5907\u7279\u5b9a\u89c2\u6d4b\u8026\u5408\uff0c\u9700\u8981\u6807\u6ce8\u6570\u636e\u548c\u9488\u5bf9\u6bcf\u79cd\u914d\u7f6e\u5355\u72ec\u8bad\u7ec3\uff0c\u6210\u672c\u9ad8\u6602\u4e14\u4e0d\u9002\u7528\u4e8e\u53ef\u6269\u5c55\u7684\u8fb9\u7f18\u90e8\u7f72\u3002", "method": "\u5f00\u53d1\u4e91\u8fb9\u534f\u540c\u6846\u67b6\uff0c\u5728\u4e91\u7aef\u4f7f\u7528\u65e0\u6807\u7b7e\u6570\u636e\u8bad\u7ec3\u57fa\u7840\u6a21\u578b\u5b66\u4e60\u901a\u7528CKM\u5148\u9a8c\uff0c\u63a8\u7406\u65f6\u8fb9\u7f18\u8282\u70b9\u5c06\u5171\u4eab\u5148\u9a8c\u4e0e\u672c\u5730\u89c2\u6d4b\u7ed3\u5408\uff0c\u5b9e\u73b0\u77e5\u8bc6\u89e3\u8026\u4e0e\u5171\u4eab\u3002", "result": "\u5728CKMImageNet\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u8be5\u65b9\u6cd5\u5728\u4fdd\u6301\u7ade\u4e89\u529b\u7684\u6784\u5efa\u7cbe\u5ea6\u540c\u65f6\uff0c\u5927\u5e45\u964d\u4f4e\u8bad\u7ec3\u6210\u672c\u548c\u6570\u636e\u9700\u6c42\uff0c\u51cf\u8f7b\u8d1f\u8fc1\u79fb\uff0c\u5728\u6cdb\u5316\u80fd\u529b\u548c\u90e8\u7f72\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5177\u6709\u660e\u663e\u4f18\u52bf\u3002", "conclusion": "\u4e91\u8fb9\u534f\u540c\u6846\u67b6\u901a\u8fc7\u89e3\u8026\u901a\u7528CKM\u5148\u9a8c\u4e0e\u672c\u5730\u89c2\u6d4b\u4fe1\u606f\uff0c\u5b9e\u73b0\u4e86\u53ef\u6269\u5c55\u7684CKM\u6784\u5efa\uff0c\u4e3a6G\u7f51\u7edc\u4e2d\u73af\u5883\u611f\u77e5\u901a\u4fe1\u548c\u611f\u77e5\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.07623", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07623", "abs": "https://arxiv.org/abs/2602.07623", "authors": ["Pan Tang", "Huixin Xu", "Jianhua Zhang", "Ximan Liu", "Enrui Liu", "Haiyang Miao", "Xiaodong Sun", "Wei Jiang", "Guangyi Liu"], "title": "A Tutorial on 3GPP Rel-19 Channel Modeling for 6G FR3 (7-24 GHz): From Standard Specification to Simulation Implementation", "comment": null, "summary": "The upper-mid band (7-24 GHz), designated as Frequency Range 3 (FR3), has emerged as a definitive ``golden band\" for 6G networks, strategically balancing the wide coverage of sub-6 GHz with the high capacity of mmWave. To compensate for the severe path loss inherent to this band, the deployment of Extremely Large Aperture Arrays (ELAA) is indispensable. However, the legacy 3GPP TR 38.901 channel model faces critical validity challenges when applied to 6G FR3, stemming from both the distinct propagation characteristics of this frequency band and the fundamental physical paradigm shift induced by ELAA. In response, 3GPP Release 19 (Rel-19) has validated the model through extensive new measurements and introduced significant enhancements. This tutorial provides a comprehensive guide to the Rel-19 channel model for 6G FR3, bridging the gap between standardization specifications and practical simulation implementation. First, we provide a high-level overview of the fundamental principles of the 3GPP channel modeling framework. Second, we detail the specific enhancements and modifications introduced in Rel-19, including the rationale behind the new Suburban Macro (SMa) scenario, the mathematical modeling of ELAA-driven features such as near-field and spatial non-stationarity, and the recalibration of large-scale parameters. Overall, this tutorial serves as an essential guide for researchers and engineers to master the latest 3GPP channel modeling methodology, laying a solid foundation for the accurate design and performance evaluation of future 6G FR3 networks.", "AI": {"tldr": "3GPP Release 19\u66f4\u65b0\u4e866G FR3\u9891\u6bb5\uff087-24GHz\uff09\u7684\u4fe1\u9053\u6a21\u578b\uff0c\u9488\u5bf9ELAA\u90e8\u7f72\u5e26\u6765\u7684\u8fd1\u573a\u6548\u5e94\u548c\u7a7a\u95f4\u975e\u5e73\u7a33\u6027\u8fdb\u884c\u4e86\u589e\u5f3a\uff0c\u4e3a6G\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u51c6\u786e\u7684\u4fe1\u9053\u5efa\u6a21\u57fa\u7840\u3002", "motivation": "\u4f20\u7edf\u76843GPP TR 38.901\u4fe1\u9053\u6a21\u578b\u5728\u5e94\u7528\u4e8e6G FR3\u9891\u6bb5\u65f6\u9762\u4e34\u6709\u6548\u6027\u6311\u6218\uff0c\u4e3b\u8981\u539f\u56e0\u662f\u8be5\u9891\u6bb5\u72ec\u7279\u7684\u4f20\u64ad\u7279\u6027\u4ee5\u53caELAA\u90e8\u7f72\u5e26\u6765\u7684\u7269\u7406\u8303\u5f0f\u8f6c\u53d8\uff0c\u9700\u8981\u66f4\u65b0\u6a21\u578b\u6765\u51c6\u786e\u652f\u6301\u672a\u67656G\u7f51\u7edc\u7684\u8bbe\u8ba1\u548c\u8bc4\u4f30\u3002", "method": "\u901a\u8fc7\u5e7f\u6cdb\u7684\u6d4b\u91cf\u9a8c\u8bc1\uff0c\u57283GPP Release 19\u4e2d\u5f15\u5165\u591a\u9879\u589e\u5f3a\uff1a1\uff09\u65b0\u589e\u90ca\u533a\u5b8f\u7ad9\uff08SMa\uff09\u573a\u666f\uff1b2\uff09\u5bf9ELAA\u9a71\u52a8\u7684\u8fd1\u573a\u6548\u5e94\u548c\u7a7a\u95f4\u975e\u5e73\u7a33\u6027\u8fdb\u884c\u6570\u5b66\u5efa\u6a21\uff1b3\uff09\u91cd\u65b0\u6821\u51c6\u5927\u5c3a\u5ea6\u53c2\u6570\uff1b4\uff09\u63d0\u4f9b\u4ece\u6807\u51c6\u5316\u89c4\u8303\u5230\u5b9e\u9645\u4eff\u771f\u5b9e\u73b0\u7684\u5b8c\u6574\u6307\u5bfc\u3002", "result": "Rel-19\u4fe1\u9053\u6a21\u578b\u4e3a6G FR3\u9891\u6bb5\u63d0\u4f9b\u4e86\u7ecf\u8fc7\u9a8c\u8bc1\u7684\u51c6\u786e\u4fe1\u9053\u5efa\u6a21\u6846\u67b6\uff0c\u80fd\u591f\u6709\u6548\u5e94\u5bf9ELAA\u90e8\u7f72\u5e26\u6765\u7684\u6311\u6218\uff0c\u5305\u62ec\u8fd1\u573a\u6548\u5e94\u548c\u7a7a\u95f4\u975e\u5e73\u7a33\u6027\u7b49\u7279\u5f81\u3002", "conclusion": "\u672c\u6559\u7a0b\u4e3a\u7814\u7a76\u4eba\u5458\u548c\u5de5\u7a0b\u5e08\u63d0\u4f9b\u4e86\u638c\u63e1\u6700\u65b03GPP\u4fe1\u9053\u5efa\u6a21\u65b9\u6cd5\u7684\u5168\u9762\u6307\u5357\uff0c\u4e3a\u672a\u67656G FR3\u7f51\u7edc\u7684\u51c6\u786e\u8bbe\u8ba1\u548c\u6027\u80fd\u8bc4\u4f30\u5960\u5b9a\u4e86\u575a\u5b9e\u57fa\u7840\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u6a21\u578b\u57286G\u65b0\u9891\u6bb5\u548c\u65b0\u5929\u7ebf\u67b6\u6784\u4e0b\u7684\u5c40\u9650\u6027\u95ee\u9898\u3002"}}
{"id": "2602.07714", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07714", "abs": "https://arxiv.org/abs/2602.07714", "authors": ["Haofan Dong", "Ozgur B. Akan"], "title": "MI-ISAC: Magneto-Inductive Integrated Sensing and Communication in the Reactive Near-Field for RF-Denied Environments", "comment": null, "summary": "Radio-frequency integrated sensing and communication (RF-ISAC) is ineffective inunderground, underwater, and in-body environments where conductive media attenuate electromagnetic waves by tens of dB per meter. This article presents magneto-inductive ISAC (MI-ISAC), a paradigm that exploits the reactive near-field quasi-static coupling inherent to MI links, enabling a fundamentally different approach to ISAC in these RF-denied environments. Five foundational results are established: (i)~tri-axial coils are necessary and sufficient for identifiable joint range-and-angle estimation; (ii)~coupling strength changes sharply with range, enabling theoretical sub-millimeter accuracy at typical MI distances despite kHz-level bandwidth; (iii)~time-of-flight is ineffective under such narrow bandwidth, but the coupling gradient provides approximately six orders of magnitude finer resolution; (iv)~MI-ISAC can provide 4--10+\\,dB sensing gain over time-division baselines; and (v)~the MI-MIMO channel is geometry-invariant and well-conditioned across all orientations. Applications and a research roadmap are discussed.", "AI": {"tldr": "MI-ISAC\u5229\u7528\u78c1\u611f\u5e94\u8fd1\u573a\u51c6\u9759\u6001\u8026\u5408\uff0c\u5728RF\u53d7\u9650\u73af\u5883\u4e2d\u5b9e\u73b0\u4f20\u611f\u901a\u4fe1\u4e00\u4f53\u5316\uff0c\u76f8\u6bd4\u4f20\u7edfRF-ISAC\u5728\u5bfc\u7535\u4ecb\u8d28\u4e2d\u5177\u6709\u663e\u8457\u4f18\u52bf\u3002", "motivation": "\u4f20\u7edf\u5c04\u9891\u96c6\u6210\u4f20\u611f\u4e0e\u901a\u4fe1\u5728\u5bfc\u7535\u4ecb\u8d28\u73af\u5883\u4e2d\u6548\u679c\u5dee\uff0c\u56e0\u4e3a\u7535\u78c1\u6ce2\u8870\u51cf\u4e25\u91cd\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5728\u6c34\u4e0b\u3001\u5730\u4e0b\u3001\u4f53\u5185\u7b49RF\u53d7\u9650\u73af\u5883\u4e2d\u5de5\u4f5c\u7684ISAC\u65b0\u8303\u5f0f\u3002", "method": "\u63d0\u51fa\u78c1\u611f\u5e94ISAC\uff0c\u5229\u7528\u78c1\u611f\u5e94\u94fe\u8def\u7684\u8fd1\u573a\u51c6\u9759\u6001\u8026\u5408\u7279\u6027\uff0c\u901a\u8fc7\u4e09\u8f74\u7ebf\u5708\u5b9e\u73b0\u53ef\u8bc6\u522b\u7684\u8054\u5408\u8ddd\u79bb-\u89d2\u5ea6\u4f30\u8ba1\uff0c\u5229\u7528\u8026\u5408\u68af\u5ea6\u63d0\u4f9b\u9ad8\u5206\u8fa8\u7387\u3002", "result": "1)\u4e09\u8f74\u7ebf\u5708\u53ef\u5b9e\u73b0\u8ddd\u79bb\u89d2\u5ea6\u8054\u5408\u4f30\u8ba1\uff1b2)\u8026\u5408\u5f3a\u5ea6\u968f\u8ddd\u79bb\u6025\u5267\u53d8\u5316\uff0ckHz\u5e26\u5bbd\u4e0b\u53ef\u8fbe\u4e9a\u6beb\u7c73\u7cbe\u5ea6\uff1b3)\u8026\u5408\u68af\u5ea6\u5206\u8fa8\u7387\u6bd4\u65f6\u5ef6\u9ad86\u4e2a\u6570\u91cf\u7ea7\uff1b4)\u6bd4\u65f6\u5206\u57fa\u7ebf\u63d0\u4f9b4-10+dB\u4f20\u611f\u589e\u76ca\uff1b5)MI-MIMO\u4fe1\u9053\u51e0\u4f55\u4e0d\u53d8\u4e14\u826f\u6761\u4ef6\u3002", "conclusion": "MI-ISAC\u4e3aRF\u53d7\u9650\u73af\u5883\u63d0\u4f9b\u4e86\u4e00\u79cd\u6709\u6548\u7684ISAC\u89e3\u51b3\u65b9\u6848\uff0c\u5177\u6709\u9ad8\u7cbe\u5ea6\u3001\u9ad8\u589e\u76ca\u548c\u51e0\u4f55\u4e0d\u53d8\u6027\u7b49\u4f18\u52bf\uff0c\u4e3a\u6c34\u4e0b\u3001\u5730\u4e0b\u3001\u4f53\u5185\u5e94\u7528\u5f00\u8f9f\u4e86\u65b0\u9014\u5f84\u3002"}}
{"id": "2602.07896", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.07896", "abs": "https://arxiv.org/abs/2602.07896", "authors": ["Varun Sarathchandran", "Geert Leus"], "title": "Joint Simplicial Complex Learning via Binary Linear Programming", "comment": null, "summary": "Learning the topology of higher-order networks from data is a fundamental challenge in many signal processing and machine learning applications. Simplicial complexes provide a principled framework for modeling multi-way interactions, yet learning their structure is challenging due to the strong coupling across different simplicial levels imposed by the inclusion property. In this work, we propose a joint framework for simplicial complex learning that enforces the inclusion property through a linear constraint, enabling the formulation of the problem as a binary linear program. The objective function consists of a combination of smoothness measures across all considered simplicial levels, allowing for the incorporation of arbitrary smoothness criteria. This formulation enables the simultaneous estimation of edges and higher-order simplices within a single optimization problem. Experiments on simulated and real-world data demonstrate that the proposed joint approach outperforms hierarchical and greedy baselines, while more faithfully enforcing higher-order structural priors.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u8054\u5408\u6846\u67b6\uff0c\u901a\u8fc7\u7ebf\u6027\u7ea6\u675f\u5f3a\u5236\u5305\u542b\u5c5e\u6027\uff0c\u5c06\u5355\u7eaf\u590d\u5f62\u5b66\u4e60\u95ee\u9898\u8868\u8ff0\u4e3a\u4e8c\u5143\u7ebf\u6027\u89c4\u5212\uff0c\u540c\u65f6\u4f30\u8ba1\u8fb9\u548c\u9ad8\u9636\u5355\u7eaf\u5f62\u3002", "motivation": "\u4ece\u6570\u636e\u4e2d\u5b66\u4e60\u9ad8\u9636\u7f51\u7edc\u7684\u62d3\u6251\u7ed3\u6784\u662f\u4fe1\u53f7\u5904\u7406\u548c\u673a\u5668\u5b66\u4e60\u4e2d\u7684\u57fa\u672c\u6311\u6218\u3002\u5355\u7eaf\u590d\u5f62\u4e3a\u5efa\u6a21\u591a\u5411\u4ea4\u4e92\u63d0\u4f9b\u4e86\u539f\u5219\u6027\u6846\u67b6\uff0c\u4f46\u7531\u4e8e\u5305\u542b\u5c5e\u6027\u5728\u4e0d\u540c\u5355\u7eaf\u5c42\u6b21\u4e4b\u95f4\u65bd\u52a0\u7684\u5f3a\u8026\u5408\uff0c\u5b66\u4e60\u5176\u7ed3\u6784\u5177\u6709\u6311\u6218\u6027\u3002", "method": "\u63d0\u51fa\u4e00\u4e2a\u8054\u5408\u5355\u7eaf\u590d\u5f62\u5b66\u4e60\u6846\u67b6\uff0c\u901a\u8fc7\u7ebf\u6027\u7ea6\u675f\u5f3a\u5236\u5305\u542b\u5c5e\u6027\uff0c\u5c06\u95ee\u9898\u8868\u8ff0\u4e3a\u4e8c\u5143\u7ebf\u6027\u89c4\u5212\u3002\u76ee\u6807\u51fd\u6570\u7ed3\u5408\u6240\u6709\u8003\u8651\u5355\u7eaf\u5c42\u6b21\u7684\u5e73\u6ed1\u6027\u5ea6\u91cf\uff0c\u5141\u8bb8\u7eb3\u5165\u4efb\u610f\u5e73\u6ed1\u6027\u51c6\u5219\u3002", "result": "\u5728\u6a21\u62df\u548c\u771f\u5b9e\u4e16\u754c\u6570\u636e\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u8054\u5408\u65b9\u6cd5\u4f18\u4e8e\u5206\u5c42\u548c\u8d2a\u5a6a\u57fa\u7ebf\uff0c\u540c\u65f6\u66f4\u5fe0\u5b9e\u5730\u5f3a\u5236\u6267\u884c\u9ad8\u9636\u7ed3\u6784\u5148\u9a8c\u3002", "conclusion": "\u8be5\u8054\u5408\u6846\u67b6\u80fd\u591f\u5728\u4e00\u4e2a\u4f18\u5316\u95ee\u9898\u4e2d\u540c\u65f6\u4f30\u8ba1\u8fb9\u548c\u9ad8\u9636\u5355\u7eaf\u5f62\uff0c\u6709\u6548\u89e3\u51b3\u4e86\u5355\u7eaf\u590d\u5f62\u5b66\u4e60\u4e2d\u5305\u542b\u5c5e\u6027\u7684\u7ea6\u675f\u95ee\u9898\uff0c\u4e3a\u9ad8\u9636\u7f51\u7edc\u62d3\u6251\u5b66\u4e60\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6cd5\u3002"}}
{"id": "2602.07959", "categories": ["eess.SP", "eess.SY"], "pdf": "https://arxiv.org/pdf/2602.07959", "abs": "https://arxiv.org/abs/2602.07959", "authors": ["Hyeonsu Lyu", "Yumin Kim", "Hyun Jong Yang"], "title": "End-to-End Secure Connection Probability in MultiLayer Networks with Heterogeneous Rician Fading", "comment": null, "summary": "Ensuring physical-layer security in non-terrestrial networks (NTNs) is challenging due to their global coverage and multi-hop relaying across heterogeneous network layers, where the locations and channels of potential eavesdroppers are typically unknown. In this work, we derive a tractable closedform expression of the end-to-end secure connection probability (SCP) of multi-hop relay routes under heterogeneous Rician fading. The resulting formula shares the same functional form as prior Rayleigh-based approximations but for the coefficients, thereby providing analytical support for the effectiveness of heuristic posterior coefficient calibration adopted in prior work. Numerical experiments under various conditions show that the proposed scheme estimates the SCP with an 1%p error in most cases; and doubles the accuracy compared with the conventional scheme even in the worst case. As a case study, we apply the proposed framework to real-world space-air-groundsea integrated network dataset, showing that the derived SCP accurately captures observed security trends in practical settings.", "AI": {"tldr": "\u672c\u6587\u63a8\u5bfc\u4e86\u5f02\u6784Rician\u8870\u843d\u4e0b\u591a\u8df3\u4e2d\u7ee7\u8def\u7531\u7aef\u5230\u7aef\u5b89\u5168\u8fde\u63a5\u6982\u7387\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u9a8c\u8bc1\u4e86\u5148\u524dRayleigh\u8fd1\u4f3c\u4e2d\u542f\u53d1\u5f0f\u7cfb\u6570\u6821\u51c6\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u5b9e\u9645\u5929\u5730\u6d77\u4e00\u4f53\u5316\u7f51\u7edc\u4e2d\u9a8c\u8bc1\u4e86\u51c6\u786e\u6027\u3002", "motivation": "\u975e\u5730\u9762\u7f51\u7edc(NTNs)\u56e0\u5176\u5168\u7403\u8986\u76d6\u548c\u591a\u8df3\u4e2d\u7ee7\u7279\u6027\uff0c\u7269\u7406\u5c42\u5b89\u5168\u9762\u4e34\u6311\u6218\uff0c\u7a83\u542c\u8005\u4f4d\u7f6e\u548c\u4fe1\u9053\u901a\u5e38\u672a\u77e5\uff0c\u9700\u8981\u51c6\u786e\u8bc4\u4f30\u7aef\u5230\u7aef\u5b89\u5168\u8fde\u63a5\u6982\u7387\u3002", "method": "\u63a8\u5bfc\u5f02\u6784Rician\u8870\u843d\u4e0b\u591a\u8df3\u4e2d\u7ee7\u8def\u7531\u7aef\u5230\u7aef\u5b89\u5168\u8fde\u63a5\u6982\u7387\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u8be5\u8868\u8fbe\u5f0f\u4e0e\u5148\u524dRayleigh\u8fd1\u4f3c\u5177\u6709\u76f8\u540c\u51fd\u6570\u5f62\u5f0f\u4f46\u7cfb\u6570\u4e0d\u540c\uff0c\u4e3a\u542f\u53d1\u5f0f\u540e\u9a8c\u7cfb\u6570\u6821\u51c6\u63d0\u4f9b\u7406\u8bba\u652f\u6301\u3002", "result": "\u6570\u503c\u5b9e\u9a8c\u663e\u793a\uff0c\u6240\u63d0\u65b9\u6848\u5728\u591a\u6570\u60c5\u51b5\u4e0b\u80fd\u4ee51%\u8bef\u5dee\u4f30\u8ba1\u5b89\u5168\u8fde\u63a5\u6982\u7387\uff0c\u5728\u6700\u574f\u60c5\u51b5\u4e0b\u4e5f\u6bd4\u4f20\u7edf\u65b9\u6848\u7cbe\u5ea6\u63d0\u9ad8\u4e00\u500d\u3002\u5728\u5b9e\u9645\u5929\u5730\u6d77\u4e00\u4f53\u5316\u7f51\u7edc\u6570\u636e\u96c6\u4e0a\u7684\u6848\u4f8b\u7814\u7a76\u8868\u660e\uff0c\u63a8\u5bfc\u7684\u5b89\u5168\u8fde\u63a5\u6982\u7387\u80fd\u51c6\u786e\u6355\u6349\u5b9e\u9645\u73af\u5883\u4e2d\u7684\u5b89\u5168\u8d8b\u52bf\u3002", "conclusion": "\u672c\u6587\u4e3a\u5f02\u6784Rician\u8870\u843d\u4e0b\u7684\u591a\u8df3\u4e2d\u7ee7\u7f51\u7edc\u63d0\u4f9b\u4e86\u51c6\u786e\u7684\u5b89\u5168\u8fde\u63a5\u6982\u7387\u5206\u6790\u6846\u67b6\uff0c\u9a8c\u8bc1\u4e86\u5148\u524d\u542f\u53d1\u5f0f\u7cfb\u6570\u6821\u51c6\u65b9\u6cd5\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u5b9e\u9645NTN\u573a\u666f\u4e2d\u5c55\u793a\u4e86\u826f\u597d\u7684\u5e94\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.08129", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08129", "abs": "https://arxiv.org/abs/2602.08129", "authors": ["Hanjun Park", "Aleksandr D. Kuznetsov", "Ville Viikari"], "title": "Adjustment of Cluster-Then-Predict Framework for Multiport Scatterer Load Prediction", "comment": null, "summary": "Predicting interdependent load values in multiport scatterers is challenging due to high dimensionality and complex dependence between impedance and scattering ability, yet this prediction remains crucial for the design of communication and measurement systems. In this paper, we propose a two-stage cluster-then-predict framework for multiple load values prediction task in multiport scatterers. The proposed cluster-then-predict approach effectively captures the underlying functional relation between S-parameters and corresponding load impedances, achieving up to a 46% reduction in Root Mean Square Error (RMSE) compared to the baseline when applied to gradient boosting (GB). This improvement is consistent across various clustering and regression methods. Furthermore, we introduce the Real-world Unified Index (RUI), a metric for quantitative analysis of trade-offs among multiple metrics with conflicting objectives and different scales, suitable for performance assessment in realistic scenarios. Based on RUI, the combination of K-means clustering and k-nearest neighbors (KNN) is identified as the optimal setup for the analyzed multiport scatterer.", "AI": {"tldr": "\u63d0\u51fa\u4e24\u9636\u6bb5\u805a\u7c7b-\u9884\u6d4b\u6846\u67b6\u7528\u4e8e\u591a\u7aef\u53e3\u6563\u5c04\u4f53\u8d1f\u8f7d\u503c\u9884\u6d4b\uff0c\u76f8\u6bd4\u57fa\u7ebf\u65b9\u6cd5\u5728\u68af\u5ea6\u63d0\u5347\u4e0a\u964d\u4f4e46% RMSE\uff0c\u5e76\u5f15\u5165RUI\u6307\u6807\u8bc4\u4f30\u591a\u76ee\u6807\u6743\u8861\u3002", "motivation": "\u591a\u7aef\u53e3\u6563\u5c04\u4f53\u4e2d\u8d1f\u8f7d\u503c\u7684\u9884\u6d4b\u5177\u6709\u6311\u6218\u6027\uff0c\u56e0\u4e3a\u5b58\u5728\u9ad8\u7ef4\u5ea6\u548c\u963b\u6297\u4e0e\u6563\u5c04\u80fd\u529b\u4e4b\u95f4\u7684\u590d\u6742\u4f9d\u8d56\u5173\u7cfb\uff0c\u4f46\u8fd9\u5bf9\u901a\u4fe1\u548c\u6d4b\u91cf\u7cfb\u7edf\u8bbe\u8ba1\u81f3\u5173\u91cd\u8981\u3002", "method": "\u63d0\u51fa\u4e24\u9636\u6bb5\u805a\u7c7b-\u9884\u6d4b\u6846\u67b6\uff1a\u5148\u805a\u7c7b\u540e\u9884\u6d4b\uff0c\u6709\u6548\u6355\u6349S\u53c2\u6570\u4e0e\u5bf9\u5e94\u8d1f\u8f7d\u963b\u6297\u4e4b\u95f4\u7684\u51fd\u6570\u5173\u7cfb\u3002\u5f15\u5165RUI\u6307\u6807\u8fdb\u884c\u591a\u76ee\u6807\u6743\u8861\u5206\u6790\u3002", "result": "\u5728\u68af\u5ea6\u63d0\u5347\u65b9\u6cd5\u4e0a\u5b9e\u73b0\u9ad8\u8fbe46%\u7684RMSE\u964d\u4f4e\uff0c\u6539\u8fdb\u5728\u5404\u79cd\u805a\u7c7b\u548c\u56de\u5f52\u65b9\u6cd5\u4e2d\u4fdd\u6301\u4e00\u81f4\u3002\u57fa\u4e8eRUI\u5206\u6790\uff0cK-means\u805a\u7c7b\u4e0eKNN\u7ec4\u5408\u88ab\u786e\u5b9a\u4e3a\u6700\u4f18\u914d\u7f6e\u3002", "conclusion": "\u63d0\u51fa\u7684\u805a\u7c7b-\u9884\u6d4b\u6846\u67b6\u80fd\u6709\u6548\u9884\u6d4b\u591a\u7aef\u53e3\u6563\u5c04\u4f53\u7684\u8d1f\u8f7d\u503c\uff0cRUI\u6307\u6807\u4e3a\u5b9e\u9645\u573a\u666f\u4e2d\u7684\u591a\u76ee\u6807\u6027\u80fd\u8bc4\u4f30\u63d0\u4f9b\u4e86\u5408\u9002\u7684\u5ea6\u91cf\u6807\u51c6\u3002"}}
{"id": "2602.08163", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08163", "abs": "https://arxiv.org/abs/2602.08163", "authors": ["Hyeon Seok Rou", "Vincent Savaux", "Zeping Sui", "Giuseppe Thadeu Freitas de Abreu", "Zilong Liu"], "title": "AFDM: Evolving OFDM Towards 6G+", "comment": "Submitted to IEEE", "summary": "As the standardization of sixth generation (6G) wireless systems accelerates, there is a growing consensus in favor of evolutionary waveforms that offer new features while maximizing compatibility with orthogonal frequency division multiplexing (OFDM), which underpins the 4G and 5G systems. This article presents affine frequency division multiplexing (AFDM) as a premier candidate for 6G, offering intrinsic robustness for both high-mobility communications and integrated sensing and communication (ISAC) in doubly dispersive channels, while maintaining a high degree of synergy with the legacy OFDM. To this end, we provide a comprehensive analysis of AFDM, starting with a generalized fractional-delay-fractional-Doppler (FDFD) channel model that accounts for practical pulse shaping filters and inter-sample coupling. We then detail the AFDM transceiver architecture, demonstrating that it reuses nearly the entire OFDM pipeline and requires only lightweight digital pre- and post-processing. We also analyze the impact of hardware impairments, such as phase noise and carrier frequency offset, and explore advanced functionalities enabled by the chirp-parameter domain, including index modulation and physical-layer security. By evaluating the reusability across the radio-frequency, physical, and higher layers, the article demonstrates that AFDM provides a low-risk, feature-rich, and efficient path toward achieving high-fidelity communications in the later versions of 6G and beyond (6G+).", "AI": {"tldr": "AFDM\uff08\u4eff\u5c04\u9891\u5206\u590d\u7528\uff09\u4f5c\u4e3a6G\u5019\u9009\u6ce2\u5f62\uff0c\u5728\u4fdd\u6301\u4e0eOFDM\u9ad8\u5ea6\u517c\u5bb9\u7684\u540c\u65f6\uff0c\u4e3a\u9ad8\u79fb\u52a8\u6027\u901a\u4fe1\u548cISAC\u63d0\u4f9b\u5185\u5728\u9c81\u68d2\u6027\uff0c\u4e3a6G+\u63d0\u4f9b\u4f4e\u98ce\u9669\u3001\u529f\u80fd\u4e30\u5bcc\u7684\u6f14\u8fdb\u8def\u5f84\u3002", "motivation": "\u968f\u77406G\u6807\u51c6\u5316\u52a0\u901f\uff0c\u4e1a\u754c\u503e\u5411\u4e8e\u9009\u62e9\u65e2\u80fd\u63d0\u4f9b\u65b0\u529f\u80fd\u53c8\u80fd\u6700\u5927\u5316\u4e0e\u73b0\u6709OFDM\u517c\u5bb9\u6027\u7684\u6f14\u8fdb\u6ce2\u5f62\u3002\u9700\u8981\u4e00\u79cd\u80fd\u5728\u53cc\u5f25\u6563\u4fe1\u9053\u4e2d\u4e3a\u9ad8\u79fb\u52a8\u6027\u901a\u4fe1\u548cISAC\u63d0\u4f9b\u5185\u5728\u9c81\u68d2\u6027\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51faAFDM\u6ce2\u5f62\uff0c\u91c7\u7528\u5e7f\u4e49\u5206\u6570\u5ef6\u8fdf-\u5206\u6570\u591a\u666e\u52d2\u4fe1\u9053\u6a21\u578b\uff0c\u8003\u8651\u5b9e\u9645\u8109\u51b2\u6574\u5f62\u6ee4\u6ce2\u5668\u548c\u6837\u672c\u95f4\u8026\u5408\u3002AFDM\u6536\u53d1\u5668\u67b6\u6784\u91cd\u7528\u5927\u90e8\u5206OFDM\u6d41\u6c34\u7ebf\uff0c\u4ec5\u9700\u8f7b\u91cf\u7ea7\u6570\u5b57\u524d\u540e\u5904\u7406\u3002\u5206\u6790\u786c\u4ef6\u635f\u4f24\u5f71\u54cd\uff0c\u63a2\u7d22\u5541\u557e\u53c2\u6570\u57df\u652f\u6301\u7684\u9ad8\u7ea7\u529f\u80fd\u3002", "result": "AFDM\u5728\u5c04\u9891\u3001\u7269\u7406\u5c42\u548c\u66f4\u9ad8\u5c42\u5177\u6709\u9ad8\u5ea6\u53ef\u91cd\u7528\u6027\uff0c\u4e3a6G+\u63d0\u4f9b\u4f4e\u98ce\u9669\u3001\u529f\u80fd\u4e30\u5bcc\u4e14\u9ad8\u6548\u7684\u8def\u5f84\uff0c\u5b9e\u73b0\u9ad8\u4fdd\u771f\u901a\u4fe1\u3002\u5b83\u91cd\u7528\u8fd1\u6574\u4e2aOFDM\u6d41\u6c34\u7ebf\uff0c\u4ec5\u9700\u8f7b\u91cf\u7ea7\u6570\u5b57\u5904\u7406\u3002", "conclusion": "AFDM\u662f6G\u7684\u4f18\u9009\u5019\u9009\u6ce2\u5f62\uff0c\u5728\u4fdd\u6301\u4e0eOFDM\u9ad8\u5ea6\u517c\u5bb9\u7684\u540c\u65f6\uff0c\u4e3a\u9ad8\u79fb\u52a8\u6027\u901a\u4fe1\u548cISAC\u63d0\u4f9b\u5185\u5728\u9c81\u68d2\u6027\uff0c\u4e3a6G+\u6f14\u8fdb\u63d0\u4f9b\u4f4e\u98ce\u9669\u3001\u529f\u80fd\u4e30\u5bcc\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08203", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08203", "abs": "https://arxiv.org/abs/2602.08203", "authors": ["Chenqing Ji", "Jiahong Liu", "Qionghui Liu", "Yifei Sun", "Chao Yu", "Rui Wang"], "title": "An Experimental Study on Fine-Grained Bistatic Sensing of UAV Trajectory via Cellular Downlink Signals", "comment": "Accepted by IEEE Wireless Communications Letters (WCL2026-0128)", "summary": "In this letter, a dual-bistatic unmanned aerial vehicles (UAVs) tracking system utilizing downlink Long-Term Evolution (LTE) signals is proposed and demonstrated. Particularly, two LTE base stations (BSs) are exploited as illumination sources. Two passive sensing receivers are deployed at different locations to detect the bistatic Doppler frequencies of the target UAV at different directions according to downlink signals transmitted from their corresponding BSs, such that the velocities of the UAV versus time can be estimated. Hence, the trajectories of the target UAV can be reconstructed. Although both the target UAV and the sensing receivers are around 200 meters away from the illuminating BSs, it is demonstrated by experiments that the tracking errors are below 50 centimeters for 90% of the complicated trajectories, when the distances between the UAV and sensing receivers are less than 30 meters. Note this accuracy is significantly better than the ranging resolution of LTE signals, high-accuracy trajectory tracking for UAV might be feasible via multi-angle bistatic Doppler measurements if the receivers are deployed with a sufficient density.", "AI": {"tldr": "\u63d0\u51fa\u5e76\u6f14\u793a\u4e86\u4e00\u79cd\u5229\u7528LTE\u4e0b\u884c\u4fe1\u53f7\u7684\u53cc\u53cc\u57fa\u5730\u65e0\u4eba\u673a\u8ddf\u8e2a\u7cfb\u7edf\uff0c\u901a\u8fc7\u6d4b\u91cf\u4e0d\u540c\u65b9\u5411\u7684\u53cc\u57fa\u5730\u591a\u666e\u52d2\u9891\u7387\u6765\u4f30\u8ba1\u65e0\u4eba\u673a\u901f\u5ea6\u5e76\u91cd\u5efa\u8f68\u8ff9\uff0c\u5b9e\u9a8c\u663e\u793a\u572830\u7c73\u8ddd\u79bb\u518590%\u590d\u6742\u8f68\u8ff9\u7684\u8ddf\u8e2a\u8bef\u5dee\u4f4e\u4e8e50\u5398\u7c73\u3002", "motivation": "\u4f20\u7edf\u65e0\u4eba\u673a\u8ddf\u8e2a\u7cfb\u7edf\u901a\u5e38\u9700\u8981\u4e13\u7528\u96f7\u8fbe\u6216GPS\uff0c\u6210\u672c\u8f83\u9ad8\u4e14\u53ef\u80fd\u53d7\u5e72\u6270\u3002\u5229\u7528\u5e7f\u6cdb\u90e8\u7f72\u7684LTE\u57fa\u7ad9\u4f5c\u4e3a\u7167\u5c04\u6e90\uff0c\u53ef\u4ee5\u6784\u5efa\u4f4e\u6210\u672c\u3001\u88ab\u52a8\u5f0f\u7684\u65e0\u4eba\u673a\u8ddf\u8e2a\u7cfb\u7edf\uff0c\u5177\u6709\u5b9e\u9645\u5e94\u7528\u4ef7\u503c\u3002", "method": "\u4f7f\u7528\u4e24\u4e2aLTE\u57fa\u7ad9\u4f5c\u4e3a\u7167\u5c04\u6e90\uff0c\u5728\u4e0d\u540c\u4f4d\u7f6e\u90e8\u7f72\u4e24\u4e2a\u88ab\u52a8\u4f20\u611f\u63a5\u6536\u5668\u3002\u63a5\u6536\u5668\u68c0\u6d4b\u76ee\u6807\u65e0\u4eba\u673a\u5728\u4e0d\u540c\u65b9\u5411\u4e0a\u7684\u53cc\u57fa\u5730\u591a\u666e\u52d2\u9891\u7387\uff0c\u901a\u8fc7\u6d4b\u91cf\u9891\u7387\u53d8\u5316\u4f30\u8ba1\u65e0\u4eba\u673a\u901f\u5ea6\u968f\u65f6\u95f4\u7684\u53d8\u5316\uff0c\u4ece\u800c\u91cd\u5efa\u65e0\u4eba\u673a\u8f68\u8ff9\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u867d\u7136\u76ee\u6807\u65e0\u4eba\u673a\u548c\u4f20\u611f\u63a5\u6536\u5668\u8ddd\u79bb\u7167\u5c04\u57fa\u7ad9\u7ea6200\u7c73\uff0c\u4f46\u5f53\u65e0\u4eba\u673a\u4e0e\u63a5\u6536\u5668\u8ddd\u79bb\u5c0f\u4e8e30\u7c73\u65f6\uff0c90%\u590d\u6742\u8f68\u8ff9\u7684\u8ddf\u8e2a\u8bef\u5dee\u4f4e\u4e8e50\u5398\u7c73\u3002\u8fd9\u4e00\u7cbe\u5ea6\u663e\u8457\u4f18\u4e8eLTE\u4fe1\u53f7\u7684\u6d4b\u8ddd\u5206\u8fa8\u7387\u3002", "conclusion": "\u901a\u8fc7\u591a\u89d2\u5ea6\u53cc\u57fa\u5730\u591a\u666e\u52d2\u6d4b\u91cf\uff0c\u5982\u679c\u63a5\u6536\u5668\u90e8\u7f72\u5bc6\u5ea6\u8db3\u591f\uff0c\u53ef\u4ee5\u5b9e\u73b0\u9ad8\u7cbe\u5ea6\u65e0\u4eba\u673a\u8f68\u8ff9\u8ddf\u8e2a\u3002\u8be5\u65b9\u6cd5\u5229\u7528\u73b0\u6709LTE\u57fa\u7840\u8bbe\u65bd\uff0c\u4e3a\u4f4e\u6210\u672c\u3001\u88ab\u52a8\u5f0f\u65e0\u4eba\u673a\u76d1\u63a7\u63d0\u4f9b\u4e86\u53ef\u884c\u65b9\u6848\u3002"}}
{"id": "2602.08204", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08204", "abs": "https://arxiv.org/abs/2602.08204", "authors": ["Geng Wang", "Zhouyou Gu", "Shenghong Li", "Peng Cheng", "Jihong Park", "Branka Vucetic", "Yonghui Li"], "title": "LocDreamer: World Model-Based Learning for Joint Indoor Tracking and Anchor Scheduling", "comment": null, "summary": "Accurate, resource-efficient localization and tracking enables numerous location-aware services in next-generation wireless networks. However, existing machine learning-based methods often require large labeled datasets while overlooking spectrum and energy efficiencies. To fill this gap, we propose LocDreamer, a world model (WM)-based framework for joint target tracking and scheduling of localization anchors. LocDreamer learns a WM that captures the latent representation of the target motion and localization environment, thereby generating synthetic measurements to imagine arbitrary anchor deployments. These measurements enable imagination-driven training of both the tracking model and the reinforcement learning (RL)-based anchor scheduler that activates only the most informative anchors, which significantly reduce energy and signaling costs while preserving high tracking accuracy. Experiments on a real-world indoor dataset demonstrate that LocDreamer substantially improves data efficiency and generalization, outperforming conventional Bayesian filter with random scheduling by 37% in tracking accuracy, and achieving 86% of the accuracy of same model trained directly on real data.", "AI": {"tldr": "LocDreamer\uff1a\u57fa\u4e8e\u4e16\u754c\u6a21\u578b\u7684\u8054\u5408\u76ee\u6807\u8ddf\u8e2a\u4e0e\u5b9a\u4f4d\u951a\u70b9\u8c03\u5ea6\u6846\u67b6\uff0c\u901a\u8fc7\u751f\u6210\u5408\u6210\u6d4b\u91cf\u6570\u636e\u5b9e\u73b0\u9ad8\u6548\u8bad\u7ec3\uff0c\u663e\u8457\u964d\u4f4e\u80fd\u8017\u5e76\u4fdd\u6301\u9ad8\u8ddf\u8e2a\u7cbe\u5ea6", "motivation": "\u73b0\u6709\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u6807\u6ce8\u6570\u636e\uff0c\u4e14\u5ffd\u89c6\u9891\u8c31\u548c\u80fd\u6e90\u6548\u7387\u3002\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u5b9a\u4f4d\u611f\u77e5\u670d\u52a1\u9700\u8981\u51c6\u786e\u3001\u8d44\u6e90\u9ad8\u6548\u7684\u5b9a\u4f4d\u8ddf\u8e2a\u65b9\u6848\u3002", "method": "\u63d0\u51faLocDreamer\u6846\u67b6\uff0c\u5b66\u4e60\u6355\u83b7\u76ee\u6807\u8fd0\u52a8\u548c\u5b9a\u4f4d\u73af\u5883\u6f5c\u5728\u8868\u793a\u7684\u4e16\u754c\u6a21\u578b\uff0c\u751f\u6210\u5408\u6210\u6d4b\u91cf\u6570\u636e\u6765\u6a21\u62df\u4efb\u610f\u951a\u70b9\u90e8\u7f72\u3002\u4f7f\u7528\u8fd9\u4e9b\u6570\u636e\u8fdb\u884c\u8ddf\u8e2a\u6a21\u578b\u548c\u57fa\u4e8e\u5f3a\u5316\u5b66\u4e60\u7684\u951a\u70b9\u8c03\u5ea6\u5668\u7684\u60f3\u8c61\u9a71\u52a8\u8bad\u7ec3\uff0c\u4ec5\u6fc0\u6d3b\u6700\u5177\u4fe1\u606f\u91cf\u7684\u951a\u70b9\u3002", "result": "\u5728\u771f\u5b9e\u5ba4\u5185\u6570\u636e\u96c6\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cLocDreamer\u663e\u8457\u63d0\u9ad8\u4e86\u6570\u636e\u6548\u7387\u548c\u6cdb\u5316\u80fd\u529b\uff1a\u76f8\u6bd4\u4f20\u7edf\u8d1d\u53f6\u65af\u6ee4\u6ce2\u5668\u52a0\u968f\u673a\u8c03\u5ea6\uff0c\u8ddf\u8e2a\u7cbe\u5ea6\u63d0\u534737%\uff1b\u8fbe\u5230\u76f4\u63a5\u4f7f\u7528\u771f\u5b9e\u6570\u636e\u8bad\u7ec3\u6a21\u578b86%\u7684\u7cbe\u5ea6\u3002", "conclusion": "LocDreamer\u901a\u8fc7\u4e16\u754c\u6a21\u578b\u751f\u6210\u5408\u6210\u6d4b\u91cf\u6570\u636e\uff0c\u5b9e\u73b0\u4e86\u9ad8\u6548\u7684\u8054\u5408\u76ee\u6807\u8ddf\u8e2a\u4e0e\u951a\u70b9\u8c03\u5ea6\uff0c\u5728\u964d\u4f4e\u80fd\u8017\u548c\u4fe1\u53f7\u6210\u672c\u7684\u540c\u65f6\u4fdd\u6301\u9ad8\u8ddf\u8e2a\u7cbe\u5ea6\uff0c\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\u7684\u5b9a\u4f4d\u670d\u52a1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08225", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08225", "abs": "https://arxiv.org/abs/2602.08225", "authors": ["Siwen Li", "Jiacheng Chen", "Yunting Xu", "Shaofeng Li", "Le Yao", "Jieling Wang", "Dusit Niyato"], "title": "Riemannian Manifold Optimization for Advanced Wireless Communications: Fundamentals and Applications", "comment": null, "summary": "Next-generation wireless communications promise transformative technologies such as massive multiple-input multiple-output (MIMO), reconfigurable intelligent surfaces (RIS), integrated sensing and communication (ISAC), and fluid antenna systems (FAS). However, deploying these technologies is hindered by large-scale optimization problems with nonconvex constraints. Conventional Euclidean-space methods rely on approximations or relaxations, which degrade performance and incur substantial computational costs. Riemannian manifold optimization (RMO) offers a powerful alternative that directly operates on the manifold defined by the geometric constraints. This approach inherently satisfies the constraints at every optimization step, thereby avoiding the performance degradation and substantial computational costs. In this paper, we first elaborate on the principles of RMO, including the fundamental concepts, tools, and methods, emphasizing its effectiveness for nonconvex problems. We then introduce its applications in advanced wireless communications, showing how constrained problems are reformulated on their natural manifolds and solved using tailored RMO algorithms. Furthermore, we present a case study on secure beamforming in an FAS-assisted non-orthogonal multiple access (NOMA) system, demonstrating RMO's superiority over conventional methods in terms of both performance and computational efficiency.", "AI": {"tldr": "\u672c\u6587\u7efc\u8ff0\u4e86\u9ece\u66fc\u6d41\u5f62\u4f18\u5316\u5728\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u901a\u4fe1\u4e2d\u7684\u5e94\u7528\uff0c\u901a\u8fc7\u5c06\u975e\u51f8\u7ea6\u675f\u95ee\u9898\u6620\u5c04\u5230\u81ea\u7136\u6d41\u5f62\u4e0a\u76f4\u63a5\u6c42\u89e3\uff0c\u907f\u514d\u4e86\u4f20\u7edf\u6b27\u6c0f\u7a7a\u95f4\u65b9\u6cd5\u7684\u8fd1\u4f3c\u548c\u677e\u5f1b\uff0c\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u4e0a\u5747\u6709\u4f18\u52bf\u3002", "motivation": "\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u901a\u4fe1\u6280\u672f\uff08\u5982\u5927\u89c4\u6a21MIMO\u3001RIS\u3001ISAC\u3001FAS\uff09\u9762\u4e34\u5927\u89c4\u6a21\u975e\u51f8\u7ea6\u675f\u4f18\u5316\u95ee\u9898\uff0c\u4f20\u7edf\u6b27\u6c0f\u7a7a\u95f4\u65b9\u6cd5\u4f9d\u8d56\u8fd1\u4f3c\u6216\u677e\u5f1b\uff0c\u5bfc\u81f4\u6027\u80fd\u4e0b\u964d\u548c\u8ba1\u7b97\u6210\u672c\u9ad8\u6602\u3002", "method": "\u91c7\u7528\u9ece\u66fc\u6d41\u5f62\u4f18\u5316\u65b9\u6cd5\uff0c\u5c06\u7ea6\u675f\u95ee\u9898\u91cd\u65b0\u8868\u8ff0\u5728\u5176\u81ea\u7136\u6d41\u5f62\u4e0a\uff0c\u5229\u7528\u4e13\u95e8\u7684RMO\u7b97\u6cd5\u76f4\u63a5\u64cd\u4f5c\u4e8e\u6d41\u5f62\u5b9a\u4e49\u7684\u51e0\u4f55\u7ea6\u675f\uff0c\u786e\u4fdd\u6bcf\u4e2a\u4f18\u5316\u6b65\u9aa4\u90fd\u6ee1\u8db3\u7ea6\u675f\u6761\u4ef6\u3002", "result": "\u901a\u8fc7FAS\u8f85\u52a9NOMA\u7cfb\u7edf\u4e2d\u7684\u5b89\u5168\u6ce2\u675f\u6210\u5f62\u6848\u4f8b\u7814\u7a76\uff0c\u8bc1\u660e\u4e86RMO\u5728\u6027\u80fd\u548c\u8ba1\u7b97\u6548\u7387\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\u3002", "conclusion": "\u9ece\u66fc\u6d41\u5f62\u4f18\u5316\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u901a\u4fe1\u4e2d\u7684\u975e\u51f8\u7ea6\u675f\u4f18\u5316\u95ee\u9898\u63d0\u4f9b\u4e86\u5f3a\u5927\u4e14\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u76f4\u63a5\u5904\u7406\u51e0\u4f55\u7ea6\u675f\uff0c\u907f\u514d\u4f20\u7edf\u65b9\u6cd5\u7684\u6027\u80fd\u635f\u5931\u548c\u8ba1\u7b97\u8d1f\u62c5\u3002"}}
{"id": "2602.08260", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08260", "abs": "https://arxiv.org/abs/2602.08260", "authors": ["Yongjeong Oh", "Jihong Park", "Jinho Choi", "Yo-Seb Jeon"], "title": "Towards Optimal Semantic Communications: Reconsidering the Role of Semantic Feature Channels", "comment": null, "summary": "This paper investigates the optimization of transmitting the encoder outputs, termed semantic features (SFs), in semantic communication (SC). We begin by modeling the entire communication process from the encoder output to the decoder input, encompassing the physical channel and all transceiver operations, as the SF channel, thereby establishing an encoder-SF channel-decoder pipeline. In contrast to prior studies that assume a fixed SF channel, we note that the SF channel is configurable, as its characteristics are shaped by various transmission and reception strategies, such as power allocation. Based on this observation, we formulate the SF channel optimization problem under a mutual information constraint between the SFs and their reconstructions, and analytically derive the optimal SF channel under a linear encoder-decoder structure and Gaussian source assumption. Building upon this theoretical foundation, we propose a joint optimization framework for the encoder-decoder and SF channel, applicable to both analog and digital SCs. To realize the optimized SF channel, we also propose a physical-layer calibration strategy that enables real-time power control and adaptation to varying channel conditions. Simulation results demonstrate that the proposed SF channel optimization achieves superior task performance under various communication environments.", "AI": {"tldr": "\u672c\u6587\u7814\u7a76\u8bed\u4e49\u901a\u4fe1\u4e2d\u8bed\u4e49\u7279\u5f81\u4f20\u8f93\u7684\u4f18\u5316\uff0c\u63d0\u51fa\u53ef\u914d\u7f6e\u7684\u8bed\u4e49\u7279\u5f81\u4fe1\u9053\u6a21\u578b\uff0c\u63a8\u5bfc\u6700\u4f18\u4fe1\u9053\u914d\u7f6e\uff0c\u5e76\u8bbe\u8ba1\u8054\u5408\u4f18\u5316\u6846\u67b6\u548c\u7269\u7406\u5c42\u6821\u51c6\u7b56\u7565\uff0c\u663e\u8457\u63d0\u5347\u4efb\u52a1\u6027\u80fd\u3002", "motivation": "\u73b0\u6709\u8bed\u4e49\u901a\u4fe1\u7814\u7a76\u901a\u5e38\u5047\u8bbe\u8bed\u4e49\u7279\u5f81\u4fe1\u9053\u56fa\u5b9a\uff0c\u4f46\u5b9e\u9645\u4e2d\u8be5\u4fe1\u9053\u53ef\u901a\u8fc7\u529f\u7387\u5206\u914d\u7b49\u7b56\u7565\u8fdb\u884c\u914d\u7f6e\u3002\u672c\u6587\u65e8\u5728\u63a2\u7d22\u5982\u4f55\u4f18\u5316\u8bed\u4e49\u7279\u5f81\u4fe1\u9053\u4ee5\u63d0\u5347\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u7684\u6574\u4f53\u6027\u80fd\u3002", "method": "1) \u5efa\u7acb\u4ece\u7f16\u7801\u5668\u8f93\u51fa\u5230\u89e3\u7801\u5668\u8f93\u5165\u7684\u8bed\u4e49\u7279\u5f81\u4fe1\u9053\u6a21\u578b\uff1b2) \u5728\u7ebf\u6027\u7f16\u7801\u5668-\u89e3\u7801\u5668\u7ed3\u6784\u548c\u9ad8\u65af\u6e90\u5047\u8bbe\u4e0b\uff0c\u63a8\u5bfc\u6700\u4f18\u8bed\u4e49\u7279\u5f81\u4fe1\u9053\uff1b3) \u63d0\u51fa\u7f16\u7801\u5668-\u89e3\u7801\u5668\u4e0e\u8bed\u4e49\u7279\u5f81\u4fe1\u9053\u7684\u8054\u5408\u4f18\u5316\u6846\u67b6\uff1b4) \u8bbe\u8ba1\u652f\u6301\u5b9e\u65f6\u529f\u7387\u63a7\u5236\u548c\u4fe1\u9053\u9002\u5e94\u7684\u7269\u7406\u5c42\u6821\u51c6\u7b56\u7565\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u8bed\u4e49\u7279\u5f81\u4fe1\u9053\u4f18\u5316\u65b9\u6cd5\u5728\u5404\u79cd\u901a\u4fe1\u73af\u5883\u4e0b\u90fd\u80fd\u5b9e\u73b0\u4f18\u8d8a\u7684\u4efb\u52a1\u6027\u80fd\uff0c\u9a8c\u8bc1\u4e86\u4f18\u5316\u8bed\u4e49\u7279\u5f81\u4fe1\u9053\u5bf9\u63d0\u5347\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u6548\u679c\u7684\u91cd\u8981\u6027\u3002", "conclusion": "\u8bed\u4e49\u7279\u5f81\u4fe1\u9053\u662f\u53ef\u914d\u7f6e\u7684\uff0c\u5176\u4f18\u5316\u80fd\u663e\u8457\u63d0\u5347\u8bed\u4e49\u901a\u4fe1\u6027\u80fd\u3002\u672c\u6587\u63d0\u51fa\u7684\u7406\u8bba\u6846\u67b6\u548c\u5b9e\u73b0\u7b56\u7565\u4e3a\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u7684\u4f18\u5316\u63d0\u4f9b\u4e86\u65b0\u601d\u8def\uff0c\u9002\u7528\u4e8e\u6a21\u62df\u548c\u6570\u5b57\u8bed\u4e49\u901a\u4fe1\u7cfb\u7edf\u3002"}}
{"id": "2602.08380", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08380", "abs": "https://arxiv.org/abs/2602.08380", "authors": ["Akanksha Sneh", "Shobha Sundar Ram", "Sumit J Darak", "Aakanksha Tewari"], "title": "Beam Alignment in Multipath Environments for Integrated Sensing and Communication using Bandit Learning", "comment": "15 pages, 10 figures and 7 tables", "summary": "Prior works have explored multi-armed bandit (MAB) algorithms for the selection of optimal beams for millimeter-wave (mmW) communications between base station and mobile users. However, when the number of beams is large, the existing MAB algorithms are characterized by long exploration times, resulting in poor overall communication throughput. In this work, we propose augmenting the upper confidence bound (UCB) based MAB with integrated sensing and communication (ISAC) to address this limitation. The premise of the work is that the radar and communication functionalities share the same field-of-view and that communication mobile users are detected by the radar as mobile targets. The radar information is used for significantly reducing the number of candidate beams for the UCB, resulting in an overall reduction in the exploration time. Further, the radar information is used to estimate the realignment time in quasi-stationary scenarios. We have realized the MAB and radar signal processing algorithms on the system on chip (SoC) via hardware-software co-design (HSCD) and fixed-point analysis. We demonstrate the significant gain in execution time using accelerators. The simulations consider complex propagation channels involving direct and multipath, with simple and extended radar targets in the presence of significant static clutter. The resulting experiments show that the proposed ISAC-based MAB achieves a 35% reduction in the overall exploration time and 1.4 factor higher throughput as compared to the conventional MAB that is based only on communications.", "AI": {"tldr": "\u63d0\u51fa\u7ed3\u5408\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1(ISAC)\u7684\u4e0a\u7f6e\u4fe1\u754c(UCB)\u591a\u81c2\u8001\u864e\u673a\u7b97\u6cd5\uff0c\u901a\u8fc7\u96f7\u8fbe\u4fe1\u606f\u51cf\u5c11\u5019\u9009\u6ce2\u675f\u6570\u91cf\uff0c\u663e\u8457\u964d\u4f4e\u6beb\u7c73\u6ce2\u901a\u4fe1\u7684\u6ce2\u675f\u63a2\u7d22\u65f6\u95f4", "motivation": "\u4f20\u7edfMAB\u7b97\u6cd5\u5728\u6beb\u7c73\u6ce2\u901a\u4fe1\u4e2d\u6ce2\u675f\u6570\u91cf\u5927\u65f6\u63a2\u7d22\u65f6\u95f4\u957f\uff0c\u5bfc\u81f4\u6574\u4f53\u901a\u4fe1\u541e\u5410\u91cf\u5dee\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u6ce2\u675f\u9009\u62e9\u65b9\u6cd5", "method": "\u5c06\u96f7\u8fbe\u611f\u77e5\u4fe1\u606f\u96c6\u6210\u5230UCB-MAB\u7b97\u6cd5\u4e2d\uff0c\u5229\u7528\u96f7\u8fbe\u68c0\u6d4b\u79fb\u52a8\u7528\u6237\u5e76\u51cf\u5c11\u5019\u9009\u6ce2\u675f\u6570\u91cf\uff1b\u901a\u8fc7\u786c\u4ef6-\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u5728SoC\u4e0a\u5b9e\u73b0\u7b97\u6cd5\uff0c\u4f7f\u7528\u52a0\u901f\u5668\u63d0\u9ad8\u6267\u884c\u6548\u7387", "result": "\u4e0e\u4f20\u7edf\u4ec5\u57fa\u4e8e\u901a\u4fe1\u7684MAB\u76f8\u6bd4\uff0cISAC-based MAB\u51cf\u5c1135%\u7684\u63a2\u7d22\u65f6\u95f4\uff0c\u541e\u5410\u91cf\u63d0\u9ad81.4\u500d\uff1b\u5728\u5305\u542b\u76f4\u63a5\u8def\u5f84\u3001\u591a\u5f84\u548c\u9759\u6001\u6742\u6ce2\u7684\u590d\u6742\u4f20\u64ad\u73af\u5883\u4e2d\u9a8c\u8bc1\u6709\u6548", "conclusion": "ISAC\u4e0eMAB\u7684\u7ed3\u5408\u80fd\u663e\u8457\u63d0\u5347\u6beb\u7c73\u6ce2\u901a\u4fe1\u7684\u6ce2\u675f\u9009\u62e9\u6548\u7387\uff0c\u786c\u4ef6\u52a0\u901f\u5b9e\u73b0\u8fdb\u4e00\u6b65\u63d0\u9ad8\u4e86\u7b97\u6cd5\u6267\u884c\u6027\u80fd\uff0c\u4e3a\u5927\u89c4\u6a21\u6ce2\u675f\u9009\u62e9\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.08396", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08396", "abs": "https://arxiv.org/abs/2602.08396", "authors": ["Akanksha Sneh", "Shobha Sundar Ram", "Kumar Vijay Mishra"], "title": "IEEE 802.11ad-Aided 5-D Sensing with a UAV Swarm in Urban Environment", "comment": "5 pages and 4 figures", "summary": "Aerial base stations mounted on unmanned aerial vehicles (UAVs) support next-generation wireless networks in challenging environments such as urban areas, disaster zones, and remote locations. Further, UAV swarms overcome the challenges of limited battery life and other operational constraints of a single UAV. However, tracking mobile users on the ground by each UAV and the corresponding synchronization between the UAVs is a significant issue that must be addressed before this framework can be deployed in reality. Incorporating additional sensing capabilities to facilitate this additional requirement would introduce significant overhead in terms of hardware, cost, and power to each UAV. Instead, we propose an integrated sensing and communications-enabled swarm UAV system, based on the millimeter-wave IEEE 802.11ad protocol. Further, we show that our proposed system is capable of five-dimensional (5-D) ground target sensing (range, Doppler velocity, azimuth, elevation, and polarization) in an urban environment. Numerical experiments using realistic models demonstrate and validate the performance of 5-D sensing using our proposed 802-11ad-aided UAV system.", "AI": {"tldr": "\u57fa\u4e8e\u6beb\u7c73\u6ce2802.11ad\u534f\u8bae\u7684\u65e0\u4eba\u673a\u7fa4\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\uff0c\u53ef\u5b9e\u73b0\u79fb\u52a8\u5730\u9762\u7528\u6237\u7684\u4e94\u7ef4\uff08\u8ddd\u79bb\u3001\u591a\u666e\u52d2\u901f\u5ea6\u3001\u65b9\u4f4d\u89d2\u3001\u4ef0\u89d2\u3001\u6781\u5316\uff09\u611f\u77e5", "motivation": "\u65e0\u4eba\u673a\u57fa\u7ad9\u652f\u6301\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u7f51\u7edc\uff0c\u4f46\u65e0\u4eba\u673a\u7fa4\u9700\u8981\u89e3\u51b3\u8ddf\u8e2a\u79fb\u52a8\u7528\u6237\u548c\u65e0\u4eba\u673a\u95f4\u540c\u6b65\u7684\u95ee\u9898\u3002\u4f20\u7edf\u65b9\u6cd5\u589e\u52a0\u989d\u5916\u611f\u77e5\u80fd\u529b\u4f1a\u5e26\u6765\u786c\u4ef6\u3001\u6210\u672c\u548c\u529f\u8017\u7684\u663e\u8457\u5f00\u9500\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u6beb\u7c73\u6ce2IEEE 802.11ad\u534f\u8bae\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u65e0\u4eba\u673a\u7fa4\u7cfb\u7edf\uff0c\u5229\u7528\u73b0\u6709\u901a\u4fe1\u534f\u8bae\u5b9e\u73b0\u4e94\u7ef4\u5730\u9762\u76ee\u6807\u611f\u77e5\uff0c\u907f\u514d\u989d\u5916\u786c\u4ef6\u5f00\u9500\u3002", "result": "\u901a\u8fc7\u6570\u503c\u5b9e\u9a8c\u9a8c\u8bc1\uff0c\u8be5\u7cfb\u7edf\u80fd\u591f\u5728\u57ce\u5e02\u73af\u5883\u4e2d\u5b9e\u73b0\u4e94\u7ef4\u5730\u9762\u76ee\u6807\u611f\u77e5\uff08\u8ddd\u79bb\u3001\u591a\u666e\u52d2\u901f\u5ea6\u3001\u65b9\u4f4d\u89d2\u3001\u4ef0\u89d2\u3001\u6781\u5316\uff09\uff0c\u6027\u80fd\u5f97\u5230\u9a8c\u8bc1\u3002", "conclusion": "\u57fa\u4e8e802.11ad\u534f\u8bae\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u65e0\u4eba\u673a\u7fa4\u7cfb\u7edf\u4e3a\u89e3\u51b3\u65e0\u4eba\u673a\u8ddf\u8e2a\u79fb\u52a8\u7528\u6237\u548c\u540c\u6b65\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u6548\u65b9\u6848\uff0c\u907f\u514d\u4e86\u989d\u5916\u786c\u4ef6\u5f00\u9500\uff0c\u5177\u6709\u5b9e\u9645\u90e8\u7f72\u6f5c\u529b\u3002"}}
{"id": "2602.08409", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08409", "abs": "https://arxiv.org/abs/2602.08409", "authors": ["Hongyun Jin", "Wenchi Cheng", "Jingqing Wang"], "title": "Movable Antenna Enabled Reconfigurable Array Topologies for Structured Beam Communications", "comment": "13 pages", "summary": "Spatially structured beams have emerged as a promising technology for enhancing spectrum efficiency (SE) in sixth-generation (6G) networks. However, structured beam schemes based on fixed-position antennas (FPAs) fail to fully exploit the array aperture, thereby limiting their topological reconfigurability and adaptability to diverse communication scenarios. To overcome these limitations, this paper proposes a novel structured beam communication framework exploiting movable antennas (MAs) to achieve reconfigurable array topologies. Specifically, we develop an MA-based geometric modeling framework to construct a variety of practical array topologies, thereby enabling the realization of diverse array configurations utilizing a unified hardware platform. Furthermore, we investigate the joint design of the array topology and the structured beamforming vector to efficiently exploit the array aperture and facilitate the multiplexing of orthogonal spatial modes. Accordingly, we formulate the corresponding beam generation and demodulation schemes and derive the channel gains under varying array topologies. We also propose an alternating optimization algorithm to jointly optimize the array topology configuration, the antenna element positions, and the structured beamforming vector, with the aim of maximizing the system SE. Numerical results demonstrate that the proposed joint design significantly enhances the SE compared to conventional FPA schemes. By synergizing the spatial multiplexing degrees of freedom (DoFs) of structured beams with the mobility DoFs of MAs within 2D planar regions, this work establishes a reconfigurable and practical framework for structured beam-based wireless communications.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u53ef\u79fb\u52a8\u5929\u7ebf(MA)\u7684\u7ed3\u6784\u5316\u6ce2\u675f\u901a\u4fe1\u6846\u67b6\uff0c\u901a\u8fc7\u53ef\u91cd\u6784\u9635\u5217\u62d3\u6251\u63d0\u53476G\u7f51\u7edc\u9891\u8c31\u6548\u7387", "motivation": "\u4f20\u7edf\u56fa\u5b9a\u4f4d\u7f6e\u5929\u7ebf(FPA)\u7684\u7ed3\u6784\u5316\u6ce2\u675f\u65b9\u6848\u65e0\u6cd5\u5145\u5206\u5229\u7528\u9635\u5217\u5b54\u5f84\uff0c\u9650\u5236\u4e86\u62d3\u6251\u53ef\u91cd\u6784\u6027\u548c\u5bf9\u4e0d\u540c\u901a\u4fe1\u573a\u666f\u7684\u9002\u5e94\u6027", "method": "\u5f00\u53d1\u57fa\u4e8eMA\u7684\u51e0\u4f55\u5efa\u6a21\u6846\u67b6\u6784\u5efa\u591a\u79cd\u9635\u5217\u62d3\u6251\uff1b\u8054\u5408\u4f18\u5316\u9635\u5217\u62d3\u6251\u3001\u5929\u7ebf\u4f4d\u7f6e\u548c\u7ed3\u6784\u5316\u6ce2\u675f\u5f62\u6210\u5411\u91cf\uff1b\u63d0\u51fa\u4ea4\u66ff\u4f18\u5316\u7b97\u6cd5\u6700\u5927\u5316\u7cfb\u7edf\u9891\u8c31\u6548\u7387", "result": "\u6570\u503c\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684\u8054\u5408\u8bbe\u8ba1\u76f8\u6bd4\u4f20\u7edfFPA\u65b9\u6848\u663e\u8457\u63d0\u5347\u4e86\u9891\u8c31\u6548\u7387", "conclusion": "\u901a\u8fc7\u5c06\u7ed3\u6784\u5316\u6ce2\u675f\u7684\u7a7a\u95f4\u590d\u7528\u81ea\u7531\u5ea6\u4e0eMA\u57282D\u5e73\u9762\u533a\u57df\u7684\u79fb\u52a8\u81ea\u7531\u5ea6\u76f8\u7ed3\u5408\uff0c\u5efa\u7acb\u4e86\u53ef\u91cd\u6784\u4e14\u5b9e\u7528\u7684\u7ed3\u6784\u5316\u6ce2\u675f\u65e0\u7ebf\u901a\u4fe1\u6846\u67b6"}}
{"id": "2602.08415", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08415", "abs": "https://arxiv.org/abs/2602.08415", "authors": ["Aakanksha Tewari", "Samarth Sharma Bhardwaj", "Sumit J Darak", "Shobha Sundar Ram"], "title": "Reconfigurable Low-Complexity Architecture for High Resolution Doppler Velocity Estimation in Integrated Sensing and Communication System", "comment": null, "summary": "In millimeter wave integrated sensing and communication (ISAC) systems for intelligent transportation, radar and communication share spectrum and hardware in a time division manner. Radar rapidly detects and localizes mobile users (MUs), after which communication proceeds through narrow beams identified by radar. Achieving fine Doppler resolution for MU clutter discrimination requires long coherent processing intervals, reducing communication time and throughput. To address this, we propose a reconfigurable architecture for Doppler estimation realized on a system on chip using hardware software codesign. The architecture supports algorithm level reconfiguration, dynamically switching between low-complexity, high-speed FFT-based coarse estimation and high complexity ESPRIT based fine estimation. We introduce modifications to ESPRIT that achieve 6.7 times faster execution while reducing memory and multiplier usage by 79% and 63%, respectively, compared to state of the art approaches, without compromising accuracy. Additionally, the reconfigurable architecture can switch to lower slow time packets under high SNR conditions, improving latency further by 2 times with no loss in performance.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7528\u4e8e\u6beb\u7c73\u6ce2ISAC\u7cfb\u7edf\u7684\u53ef\u91cd\u6784\u591a\u666e\u52d2\u4f30\u8ba1\u67b6\u6784\uff0c\u901a\u8fc7\u786c\u4ef6\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u5b9e\u73b0\u7b97\u6cd5\u7ea7\u91cd\u6784\uff0c\u5728FFT\u7c97\u4f30\u8ba1\u548cESPRIT\u7cbe\u4f30\u8ba1\u95f4\u52a8\u6001\u5207\u6362\uff0c\u663e\u8457\u63d0\u5347\u901f\u5ea6\u548c\u8d44\u6e90\u6548\u7387\u3002", "motivation": "\u5728\u6beb\u7c73\u6ce2\u667a\u80fd\u4ea4\u901aISAC\u7cfb\u7edf\u4e2d\uff0c\u96f7\u8fbe\u548c\u901a\u4fe1\u65f6\u5206\u5171\u4eab\u9891\u8c31\u548c\u786c\u4ef6\u3002\u96f7\u8fbe\u9700\u8981\u957f\u76f8\u5e72\u5904\u7406\u95f4\u9694\u5b9e\u73b0\u7cbe\u7ec6\u591a\u666e\u52d2\u5206\u8fa8\u7387\u4ee5\u533a\u5206\u79fb\u52a8\u7528\u6237\u6742\u6ce2\uff0c\u4f46\u8fd9\u4f1a\u51cf\u5c11\u901a\u4fe1\u65f6\u95f4\u5e76\u964d\u4f4e\u541e\u5410\u91cf\u3002\u9700\u8981\u89e3\u51b3\u8fd9\u4e00\u77db\u76fe\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u7247\u4e0a\u7cfb\u7edf\u7684\u53ef\u91cd\u6784\u591a\u666e\u52d2\u4f30\u8ba1\u67b6\u6784\uff0c\u91c7\u7528\u786c\u4ef6\u8f6f\u4ef6\u534f\u540c\u8bbe\u8ba1\u3002\u652f\u6301\u7b97\u6cd5\u7ea7\u91cd\u6784\uff0c\u52a8\u6001\u5207\u6362\u4f4e\u590d\u6742\u5ea6FFT\u7c97\u4f30\u8ba1\u548c\u9ad8\u590d\u6742\u5ea6ESPRIT\u7cbe\u4f30\u8ba1\u3002\u5bf9ESPRIT\u7b97\u6cd5\u8fdb\u884c\u6539\u8fdb\uff0c\u63d0\u5347\u6267\u884c\u901f\u5ea6\u5e76\u51cf\u5c11\u8d44\u6e90\u4f7f\u7528\u3002", "result": "\u6539\u8fdb\u7684ESPRIT\u7b97\u6cd5\u6267\u884c\u901f\u5ea6\u63d0\u53476.7\u500d\uff0c\u5185\u5b58\u4f7f\u7528\u51cf\u5c1179%\uff0c\u4e58\u6cd5\u5668\u4f7f\u7528\u51cf\u5c1163%\uff0c\u4e14\u4e0d\u635f\u5931\u7cbe\u5ea6\u3002\u5728\u9ad8\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\uff0c\u53ef\u5207\u6362\u5230\u66f4\u5c11\u7684\u6162\u65f6\u95f4\u5305\uff0c\u8fdb\u4e00\u6b65\u5c06\u5ef6\u8fdf\u964d\u4f4e2\u500d\u4e14\u6027\u80fd\u4e0d\u53d8\u3002", "conclusion": "\u6240\u63d0\u51fa\u7684\u53ef\u91cd\u6784\u67b6\u6784\u6709\u6548\u89e3\u51b3\u4e86\u6beb\u7c73\u6ce2ISAC\u7cfb\u7edf\u4e2d\u591a\u666e\u52d2\u4f30\u8ba1\u7cbe\u5ea6\u4e0e\u901a\u4fe1\u541e\u5410\u91cf\u4e4b\u95f4\u7684\u77db\u76fe\uff0c\u901a\u8fc7\u7b97\u6cd5\u7ea7\u91cd\u6784\u548c\u4f18\u5316\u5b9e\u73b0\u4e86\u6027\u80fd\u4e0e\u6548\u7387\u7684\u5e73\u8861\uff0c\u9002\u7528\u4e8e\u667a\u80fd\u4ea4\u901a\u7b49\u5b9e\u65f6\u5e94\u7528\u573a\u666f\u3002"}}
{"id": "2602.08474", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08474", "abs": "https://arxiv.org/abs/2602.08474", "authors": ["Xinyu Zhang", "Alexis A. Dowhuszko", "Miguel R\u00eago", "Pedro Fonseca", "Lu\u00eds Nero Alves", "Jyri H\u00e4m\u00e4l\u00e4inen", "Risto Wichman"], "title": "Symbol Rate Maximization in Rolling-Shutter OCC: Design and Implementation Considerations", "comment": "6 pages, 8 figures, Submitted to IEEE International Conference on Communications", "summary": "Optical Camera Communication (OCC) systems can take advantage of the row-by-row scanning process of rolling-shutter cameras to capture the fast variations of light intensity coming from Visible Light Communication (VLC) LED-based transmitters. In order to study the maximum data rate that is feasible in such kind of OCC systems, this paper presents its equivalent digital communication system model in which the rolling-shutter camera is modeled as a rectangular matched-filter whose time width is equal to the exposure time of the camera, followed by a sampling process at the pixel row sweep rate of the camera. Based on the proposed rolling-shutter camera model, the maximum symbol rate that such OCC systems can support is experimentally demonstrated, and the impact of imperfect time synchronization between the VLC transmitter and the rolling-shutter OCC receiver is characterized in the form of Inter-Symbol Interference (ISI). The equivalent three-tap channel model that results from this process is experimentally validated and the generated ISI is compensated with the use of linear equalization in reception. Simulation and experimental results show a strong correlation between them, demonstrating that the proposed approach can be used to make the OCC system work at the Nyquist sampling rate, which is equivalent to the pixel row sweep rate of the rolling-shutter camera used in reception.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u6eda\u52a8\u5feb\u95e8\u76f8\u673a\u7684\u7b49\u6548\u6570\u5b57\u901a\u4fe1\u7cfb\u7edf\u6a21\u578b\uff0c\u5c06\u5176\u5efa\u6a21\u4e3a\u77e9\u5f62\u5339\u914d\u6ee4\u6ce2\u5668\uff0c\u7528\u4e8e\u7814\u7a76\u5149\u5b66\u76f8\u673a\u901a\u4fe1\u7cfb\u7edf\u7684\u6700\u5927\u6570\u636e\u901f\u7387\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u80fd\u5728\u5948\u594e\u65af\u7279\u91c7\u6837\u7387\u4e0b\u5de5\u4f5c\u3002", "motivation": "\u7814\u7a76\u6eda\u52a8\u5feb\u95e8\u76f8\u673a\u5728\u5149\u5b66\u76f8\u673a\u901a\u4fe1\u7cfb\u7edf\u4e2d\u7684\u6700\u5927\u6570\u636e\u901f\u7387\uff0c\u5efa\u7acb\u51c6\u786e\u7684\u7cfb\u7edf\u6a21\u578b\u4ee5\u5206\u6790\u65f6\u95f4\u540c\u6b65\u4e0d\u5b8c\u7f8e\u5e26\u6765\u7684\u7b26\u53f7\u95f4\u5e72\u6270\u95ee\u9898\u3002", "method": "\u5c06\u6eda\u52a8\u5feb\u95e8\u76f8\u673a\u5efa\u6a21\u4e3a\u65f6\u95f4\u5bbd\u5ea6\u7b49\u4e8e\u76f8\u673a\u66dd\u5149\u65f6\u95f4\u7684\u77e9\u5f62\u5339\u914d\u6ee4\u6ce2\u5668\uff0c\u540e\u63a5\u50cf\u7d20\u884c\u626b\u63cf\u901f\u7387\u7684\u91c7\u6837\u8fc7\u7a0b\u3002\u57fa\u4e8e\u6b64\u6a21\u578b\u5206\u6790\u6700\u5927\u7b26\u53f7\u7387\uff0c\u5efa\u7acb\u7b49\u6548\u4e09\u62bd\u5934\u4fe1\u9053\u6a21\u578b\uff0c\u5e76\u4f7f\u7528\u7ebf\u6027\u5747\u8861\u8865\u507f\u7b26\u53f7\u95f4\u5e72\u6270\u3002", "result": "\u5b9e\u9a8c\u9a8c\u8bc1\u4e86\u6700\u5927\u7b26\u53f7\u7387\u53ef\u8fbe\u5948\u594e\u65af\u7279\u91c7\u6837\u7387\uff08\u5373\u76f8\u673a\u50cf\u7d20\u884c\u626b\u63cf\u901f\u7387\uff09\uff0c\u4eff\u771f\u4e0e\u5b9e\u9a8c\u7ed3\u679c\u9ad8\u5ea6\u76f8\u5173\uff0c\u8bc1\u660e\u4e86\u6240\u63d0\u65b9\u6cd5\u80fd\u4f7fOCC\u7cfb\u7edf\u5728\u5948\u594e\u65af\u7279\u91c7\u6837\u7387\u4e0b\u5de5\u4f5c\u3002", "conclusion": "\u63d0\u51fa\u7684\u6eda\u52a8\u5feb\u95e8\u76f8\u673a\u6a21\u578b\u80fd\u51c6\u786e\u63cf\u8ff0OCC\u7cfb\u7edf\u6027\u80fd\uff0c\u901a\u8fc7\u7ebf\u6027\u5747\u8861\u53ef\u6709\u6548\u8865\u507f\u65f6\u95f4\u540c\u6b65\u4e0d\u5b8c\u7f8e\u5bfc\u81f4\u7684\u7b26\u53f7\u95f4\u5e72\u6270\uff0c\u4f7f\u7cfb\u7edf\u80fd\u5728\u7406\u8bba\u6700\u5927\u6570\u636e\u901f\u7387\u4e0b\u5de5\u4f5c\u3002"}}
{"id": "2602.08495", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08495", "abs": "https://arxiv.org/abs/2602.08495", "authors": ["Akanksha Sneh", "Shobha Sundar Ram"], "title": "Radar Operating Metrics and Network Throughput for Integrated Sensing and Communications in Millimeter-wave Urban Environments", "comment": "6 pages, 7 figures", "summary": "Millimeter wave integrated sensing and communication (ISAC) systems are being researched for next-generation intelligent transportation systems. Here, radar and communication functionalities share a common spectrum and hardware resources in a time-multiplexed manner. The objective of the radar is to first scan the angular search space and detect and localize mobile users/targets in the presence of discrete clutter scatterers. Subsequently, this information is used to direct highly directional beams toward these mobile users for communication service. The choice of radar parameters such as the radar duty cycle and the corresponding beamwidth are critical for realizing high communication throughput. In this work, we use the stochastic geometry-based mathematical framework to analyze the radar operating metrics as a function of diverse radar, target, and clutter parameters and subsequently use these results to study the network throughput of the ISAC system. The results are validated through Monte Carlo simulations.", "AI": {"tldr": "\u5206\u6790\u6beb\u7c73\u6ce2ISAC\u7cfb\u7edf\u4e2d\u96f7\u8fbe\u53c2\u6570\uff08\u5360\u7a7a\u6bd4\u3001\u6ce2\u675f\u5bbd\u5ea6\uff09\u5bf9\u901a\u4fe1\u541e\u5410\u91cf\u7684\u5f71\u54cd\uff0c\u4f7f\u7528\u968f\u673a\u51e0\u4f55\u6846\u67b6\u5efa\u6a21\u96f7\u8fbe\u6027\u80fd\u6307\u6807\uff0c\u5e76\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u4eff\u771f\u9a8c\u8bc1", "motivation": "\u4e0b\u4e00\u4ee3\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u9700\u8981\u6beb\u7c73\u6ce2\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u6280\u672f\uff0c\u96f7\u8fbe\u548c\u901a\u4fe1\u529f\u80fd\u5171\u4eab\u9891\u8c31\u548c\u786c\u4ef6\u8d44\u6e90\uff0c\u4f46\u96f7\u8fbe\u53c2\u6570\u9009\u62e9\u5bf9\u901a\u4fe1\u541e\u5410\u91cf\u81f3\u5173\u91cd\u8981\uff0c\u9700\u8981\u7cfb\u7edf\u5316\u5206\u6790", "method": "\u91c7\u7528\u57fa\u4e8e\u968f\u673a\u51e0\u4f55\u7684\u6570\u5b66\u6846\u67b6\u5206\u6790\u96f7\u8fbe\u6027\u80fd\u6307\u6807\u4e0e\u96f7\u8fbe\u3001\u76ee\u6807\u3001\u6742\u6ce2\u53c2\u6570\u7684\u5173\u7cfb\uff0c\u7136\u540e\u5229\u7528\u8fd9\u4e9b\u7ed3\u679c\u7814\u7a76ISAC\u7cfb\u7edf\u7684\u7f51\u7edc\u541e\u5410\u91cf\uff0c\u5e76\u901a\u8fc7\u8499\u7279\u5361\u6d1b\u4eff\u771f\u9a8c\u8bc1", "result": "\u5efa\u7acb\u4e86\u96f7\u8fbe\u6027\u80fd\u6307\u6807\u4e0e\u7cfb\u7edf\u53c2\u6570\u7684\u6570\u5b66\u5173\u7cfb\uff0c\u5e76\u5206\u6790\u4e86\u8fd9\u4e9b\u6307\u6807\u5982\u4f55\u5f71\u54cdISAC\u7cfb\u7edf\u7684\u7f51\u7edc\u541e\u5410\u91cf\uff0c\u8499\u7279\u5361\u6d1b\u4eff\u771f\u9a8c\u8bc1\u4e86\u7406\u8bba\u5206\u6790\u7684\u6709\u6548\u6027", "conclusion": "\u6beb\u7c73\u6ce2ISAC\u7cfb\u7edf\u4e2d\u96f7\u8fbe\u53c2\u6570\uff08\u5982\u5360\u7a7a\u6bd4\u548c\u6ce2\u675f\u5bbd\u5ea6\uff09\u7684\u9009\u62e9\u5bf9\u901a\u4fe1\u541e\u5410\u91cf\u6709\u91cd\u8981\u5f71\u54cd\uff0c\u968f\u673a\u51e0\u4f55\u6846\u67b6\u4e3a\u7cfb\u7edf\u6027\u80fd\u5206\u6790\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u6570\u5b66\u5de5\u5177"}}
{"id": "2602.08560", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.08560", "abs": "https://arxiv.org/abs/2602.08560", "authors": ["Fredrik Cumlin", "Anubhab Ghosh", "Saikat Chatterjee"], "title": "DNS: Data-driven Nonlinear Smoother for Complex Model-free Process", "comment": null, "summary": "We propose data-driven nonlinear smoother (DNS) to estimate a hidden state sequence of a complex dynamical process from a noisy, linear measurement sequence. The dynamical process is model-free, that is, we do not have any knowledge of the nonlinear dynamics of the complex process. There is no state-transition model (STM) of the process available. The proposed DNS uses a recurrent architecture that helps to provide a closed-form posterior of the hidden state sequence given the measurement sequence. DNS learns in an unsupervised manner, meaning the training dataset consists of only measurement data and no state data. We demonstrate DNS using simulations for smoothing of several stochastic dynamical processes, including a benchmark Lorenz system. Experimental results show that the DNS is significantly better than a deep Kalman smoother (DKS) and an iterative data-driven nonlinear state estimation (iDANSE) smoother.", "AI": {"tldr": "\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u7684\u975e\u7ebf\u6027\u5e73\u6ed1\u5668(DNS)\uff0c\u7528\u4e8e\u4ece\u542b\u566a\u58f0\u7684\u7ebf\u6027\u6d4b\u91cf\u5e8f\u5217\u4e2d\u4f30\u8ba1\u590d\u6742\u52a8\u6001\u8fc7\u7a0b\u7684\u9690\u85cf\u72b6\u6001\u5e8f\u5217\uff0c\u65e0\u9700\u7cfb\u7edf\u52a8\u6001\u6a21\u578b\uff0c\u91c7\u7528\u65e0\u76d1\u7763\u5b66\u4e60\uff0c\u6027\u80fd\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\u3002", "motivation": "\u5bf9\u4e8e\u590d\u6742\u7684\u52a8\u6001\u8fc7\u7a0b\uff0c\u901a\u5e38\u7f3a\u4e4f\u72b6\u6001\u8f6c\u79fb\u6a21\u578b\u7684\u77e5\u8bc6\uff0c\u800c\u4f20\u7edf\u7684\u72b6\u6001\u4f30\u8ba1\u65b9\u6cd5\u9700\u8981\u6a21\u578b\u4fe1\u606f\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u76f4\u63a5\u4ece\u6d4b\u91cf\u6570\u636e\u4e2d\u5b66\u4e60\u5e76\u4f30\u8ba1\u9690\u85cf\u72b6\u6001\u5e8f\u5217\u7684\u6570\u636e\u9a71\u52a8\u65b9\u6cd5\u3002", "method": "\u63d0\u51fa\u6570\u636e\u9a71\u52a8\u7684\u975e\u7ebf\u6027\u5e73\u6ed1\u5668(DNS)\uff0c\u91c7\u7528\u5faa\u73af\u67b6\u6784\uff0c\u80fd\u591f\u5728\u65e0\u72b6\u6001\u8f6c\u79fb\u6a21\u578b\u7684\u60c5\u51b5\u4e0b\u63d0\u4f9b\u9690\u85cf\u72b6\u6001\u5e8f\u5217\u7684\u540e\u9a8c\u5206\u5e03\u95ed\u5f0f\u89e3\u3002\u901a\u8fc7\u65e0\u76d1\u7763\u5b66\u4e60\uff0c\u4ec5\u4f7f\u7528\u6d4b\u91cf\u6570\u636e\u8fdb\u884c\u8bad\u7ec3\u3002", "result": "\u5728\u591a\u4e2a\u968f\u673a\u52a8\u6001\u8fc7\u7a0b\uff08\u5305\u62ec\u57fa\u51c6Lorenz\u7cfb\u7edf\uff09\u7684\u4eff\u771f\u5b9e\u9a8c\u4e2d\uff0cDNS\u7684\u6027\u80fd\u663e\u8457\u4f18\u4e8e\u6df1\u5ea6\u5361\u5c14\u66fc\u5e73\u6ed1\u5668(DKS)\u548c\u8fed\u4ee3\u6570\u636e\u9a71\u52a8\u975e\u7ebf\u6027\u72b6\u6001\u4f30\u8ba1(iDANSE)\u5e73\u6ed1\u5668\u3002", "conclusion": "DNS\u662f\u4e00\u79cd\u6709\u6548\u7684\u65e0\u6a21\u578b\u72b6\u6001\u4f30\u8ba1\u65b9\u6cd5\uff0c\u80fd\u591f\u5728\u7f3a\u4e4f\u7cfb\u7edf\u52a8\u6001\u77e5\u8bc6\u7684\u60c5\u51b5\u4e0b\uff0c\u4ec5\u901a\u8fc7\u6d4b\u91cf\u6570\u636e\u5b9e\u73b0\u51c6\u786e\u7684\u72b6\u6001\u5e8f\u5217\u5e73\u6ed1\u4f30\u8ba1\uff0c\u4e3a\u590d\u6742\u52a8\u6001\u7cfb\u7edf\u7684\u72b6\u6001\u4f30\u8ba1\u63d0\u4f9b\u4e86\u65b0\u7684\u6570\u636e\u9a71\u52a8\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.08596", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08596", "abs": "https://arxiv.org/abs/2602.08596", "authors": ["Riya Sachdeva", "Aakanksha Tewari", "Sumit J. Darak", "Shobha Sundar Ram", "Sanat K. Biswas"], "title": "RFSoC-Based Integrated Navigation and Sensing Using NavIC", "comment": null, "summary": "Prior art has proposed a secondary application for Global Navigation Satellite System (GNSS) infrastructure for remote sensing of ground-based and maritime targets. Here, a passive radar receiver is deployed to detect uncooperative targets on Earth's surface by capturing ground-reflected satellite signals. This work demonstrates a hardware prototype of an L-band Navigation with Indian Constellation (NavIC) satellite-based remote sensing receiver system mounted on an AMD Zynq radio frequency system-on-chip (RFSoC) platform. Two synchronized receiver channels are introduced for capturing the direct signal (DS) from the satellite and ground-reflected signal (GRS) returns from targets. These signals are processed on the ARM processor and field programmable gate array (FPGA) of the RFSoC to generate delay-Doppler maps of the ground-based targets. The performance is first validated in a loop-back configuration of the RFSoC. Next, the DS and GRS signals are emulated by the output from two ports of the Keysight Arbitrary Waveform Generator (AWG) and interfaced with the RFSoC where the signals are subsequently processed to obtain the delay-Doppler maps. The performance is validated for different signal-to-noise ratios (SNR).", "AI": {"tldr": "\u57fa\u4e8eNavIC\u536b\u661f\u7684\u88ab\u52a8\u96f7\u8fbe\u63a5\u6536\u5668\u539f\u578b\uff0c\u5229\u7528\u5730\u9762\u53cd\u5c04\u4fe1\u53f7\u8fdb\u884c\u76ee\u6807\u63a2\u6d4b", "motivation": "\u5229\u7528\u73b0\u6709GNSS\u57fa\u7840\u8bbe\u65bd\u8fdb\u884c\u4e8c\u6b21\u5e94\u7528\uff0c\u5f00\u53d1\u88ab\u52a8\u96f7\u8fbe\u7cfb\u7edf\u7528\u4e8e\u5730\u9762\u548c\u6d77\u4e0a\u76ee\u6807\u7684\u9065\u611f\u63a2\u6d4b", "method": "\u5728AMD Zynq RFSoC\u5e73\u53f0\u4e0a\u90e8\u7f72\u53cc\u901a\u9053\u63a5\u6536\u5668\u539f\u578b\uff0c\u5206\u522b\u6355\u83b7\u536b\u661f\u76f4\u5c04\u4fe1\u53f7\u548c\u5730\u9762\u53cd\u5c04\u4fe1\u53f7\uff0c\u901a\u8fc7ARM\u5904\u7406\u5668\u548cFPGA\u5904\u7406\u751f\u6210\u76ee\u6807\u7684\u5ef6\u8fdf-\u591a\u666e\u52d2\u56fe", "result": "\u6210\u529f\u9a8c\u8bc1\u4e86\u7cfb\u7edf\u6027\u80fd\uff1a\u9996\u5148\u5728RFSoC\u56de\u73af\u914d\u7f6e\u4e2d\u9a8c\u8bc1\uff0c\u7136\u540e\u901a\u8fc7Keysight AWG\u6a21\u62df\u4fe1\u53f7\u8fdb\u884c\u6d4b\u8bd5\uff0c\u5728\u4e0d\u540c\u4fe1\u566a\u6bd4\u6761\u4ef6\u4e0b\u5747\u80fd\u83b7\u5f97\u6709\u6548\u7684\u5ef6\u8fdf-\u591a\u666e\u52d2\u56fe", "conclusion": "\u8bc1\u660e\u4e86\u57fa\u4e8eNavIC\u536b\u661f\u7684\u88ab\u52a8\u96f7\u8fbe\u63a5\u6536\u5668\u539f\u578b\u7cfb\u7edf\u7684\u53ef\u884c\u6027\uff0c\u4e3a\u5229\u7528GNSS\u57fa\u7840\u8bbe\u65bd\u8fdb\u884c\u65e0\u6e90\u9065\u611f\u63a2\u6d4b\u63d0\u4f9b\u4e86\u786c\u4ef6\u5b9e\u73b0\u65b9\u6848"}}
{"id": "2602.08609", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08609", "abs": "https://arxiv.org/abs/2602.08609", "authors": ["Nicol\u00f2 Decarli", "Davide Dardari"], "title": "Ziv-Zakai Bound for Near-Field Localization and Sensing", "comment": null, "summary": "The increasing carrier frequencies and growing physical dimensions of antenna arrays in modern wireless systems are driving renewed interest in localization and sensing under near-field conditions. In this paper, we analyze the Ziv-Zakai Bound (ZZB) for near-field localization and sensing operated with large antenna arrays, which offers a tighter characterization of estimation accuracy compared to traditional bounds such as the Cram\u00e9r-Rao Bound (CRB), especially in low signal-to-noise ratio or threshold regions. Leveraging spherical wavefront and array geometry in the signal model, we evaluate the ZZB for distance and angle estimation, investigating the dependence of the accuracy on key signal and system parameters such as array geometry, wavelength, and target position. Our analysis highlights the transition behavior of the ZZB and underscores the fundamental limitations and opportunities for accurate near-field sensing.", "AI": {"tldr": "\u5206\u6790\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\u8fd1\u573a\u5b9a\u4f4d\u7684Ziv-Zakai\u754c\uff0c\u76f8\u6bd4\u4f20\u7edfCram\u00e9r-Rao\u754c\u63d0\u4f9b\u66f4\u7d27\u7684\u7cbe\u5ea6\u8868\u5f81\uff0c\u7279\u522b\u9002\u7528\u4e8e\u4f4e\u4fe1\u566a\u6bd4\u6216\u9608\u503c\u533a\u57df", "motivation": "\u73b0\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u65e5\u76ca\u589e\u52a0\u7684\u8f7d\u6ce2\u9891\u7387\u548c\u5929\u7ebf\u9635\u5217\u7269\u7406\u5c3a\u5bf8\uff0c\u63a8\u52a8\u4e86\u5bf9\u8fd1\u573a\u6761\u4ef6\u4e0b\u5b9a\u4f4d\u4e0e\u611f\u77e5\u7684\u65b0\u5174\u8da3", "method": "\u5229\u7528\u7403\u9762\u6ce2\u524d\u548c\u9635\u5217\u51e0\u4f55\u7684\u4fe1\u53f7\u6a21\u578b\uff0c\u8bc4\u4f30\u8ddd\u79bb\u548c\u89d2\u5ea6\u4f30\u8ba1\u7684ZZB\uff0c\u5206\u6790\u7cbe\u5ea6\u5bf9\u5173\u952e\u4fe1\u53f7\u548c\u7cfb\u7edf\u53c2\u6570\u7684\u4f9d\u8d56\u6027", "result": "ZZB\u5206\u6790\u63ed\u793a\u4e86\u7cbe\u5ea6\u5bf9\u9635\u5217\u51e0\u4f55\u3001\u6ce2\u957f\u548c\u76ee\u6807\u4f4d\u7f6e\u7b49\u53c2\u6570\u7684\u4f9d\u8d56\u6027\uff0c\u7a81\u51fa\u4e86ZZB\u7684\u8fc7\u6e21\u884c\u4e3a", "conclusion": "\u8be5\u7814\u7a76\u9610\u660e\u4e86\u7cbe\u786e\u8fd1\u573a\u611f\u77e5\u7684\u57fa\u672c\u9650\u5236\u548c\u673a\u4f1a\uff0c\u4e3a\u5927\u89c4\u6a21\u5929\u7ebf\u9635\u5217\u8fd1\u573a\u5b9a\u4f4d\u63d0\u4f9b\u4e86\u7406\u8bba\u6307\u5bfc"}}
{"id": "2602.08697", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08697", "abs": "https://arxiv.org/abs/2602.08697", "authors": ["Nikos G. Evgenidis", "Sotiris A. Tegos", "Panagiotis D. Diamantoulakis", "Ioannis Krikidis", "George K. Karagiannidis"], "title": "Improving Reliability of Hybrid Bit-Semantic Communications for Cellular Networks", "comment": null, "summary": "Semantic communications (SemComs) have been considered as a promising solution to reduce the amount of transmitted information, thus paving the way for more energy-and spectrum-efficient wireless networks. Nevertheless, SemComs rely heavily on the utilization of deep neural networks (DNNs) at the transceivers, which limit the accuracy between the original and reconstructed data and are challenging to implement in practice due to increased architecture complexity. Thus, hybrid cellular networks that utilize both conventional bit communications (BitComs) and SemComs have been introduced to bridge the gap between required and existing infrastructure. To facilitate such networks, in this work, we investigate reliability by deriving closed-form expressions for the outage probability of the network. Additionally, we propose a generalized outage probability through which the cell radius that achieves a desired outage threshold for a specific range of users is calculated in closed form. Additionally, to consider the practical limitations caused by the specialized dedicated hardware and the increased memory and computational resources that are required to support SemCom, a semantic utilization metric is proposed. Based on this metric, we express the probability that a specific number of users select SemCom transmission and calculate the optimal cell radius for that number in closed form. Simulation results validate the derived analytical expressions and the characterized design properties of the cell radius found through the proposed metrics, providing useful insights.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u6df7\u5408\u8702\u7a9d\u7f51\u7edc\u4e2d\u8bed\u4e49\u901a\u4fe1\u4e0e\u4f20\u7edf\u6bd4\u7279\u901a\u4fe1\u7684\u53ef\u9760\u6027\uff0c\u63a8\u5bfc\u4e86\u4e2d\u65ad\u6982\u7387\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff0c\u5e76\u63d0\u51fa\u4e86\u8bed\u4e49\u5229\u7528\u7387\u6307\u6807\u6765\u4f18\u5316\u7f51\u7edc\u8bbe\u8ba1\u3002", "motivation": "\u8bed\u4e49\u901a\u4fe1\u867d\u7136\u80fd\u63d0\u9ad8\u80fd\u6548\u548c\u9891\u8c31\u6548\u7387\uff0c\u4f46\u4f9d\u8d56\u590d\u6742\u7684\u6df1\u5ea6\u795e\u7ecf\u7f51\u7edc\uff0c\u5728\u5b9e\u9645\u90e8\u7f72\u4e2d\u5b58\u5728\u51c6\u786e\u6027\u548c\u5b9e\u73b0\u96be\u5ea6\u95ee\u9898\u3002\u6df7\u5408\u7f51\u7edc\u7ed3\u5408\u4f20\u7edf\u6bd4\u7279\u901a\u4fe1\u548c\u8bed\u4e49\u901a\u4fe1\u53ef\u4ee5\u5f25\u8865\u73b0\u6709\u57fa\u7840\u8bbe\u65bd\u7684\u4e0d\u8db3\u3002", "method": "1) \u63a8\u5bfc\u6df7\u5408\u7f51\u7edc\u4e2d\u65ad\u6982\u7387\u7684\u95ed\u5f0f\u8868\u8fbe\u5f0f\uff1b2) \u63d0\u51fa\u5e7f\u4e49\u4e2d\u65ad\u6982\u7387\u6765\u8ba1\u7b97\u7279\u5b9a\u7528\u6237\u8303\u56f4\u4e0b\u8fbe\u5230\u671f\u671b\u4e2d\u65ad\u9608\u503c\u7684\u8702\u7a9d\u534a\u5f84\uff1b3) \u5f15\u5165\u8bed\u4e49\u5229\u7528\u7387\u6307\u6807\uff0c\u8003\u8651\u8bed\u4e49\u901a\u4fe1\u7684\u786c\u4ef6\u548c\u8d44\u6e90\u9650\u5236\uff1b4) \u8ba1\u7b97\u9009\u62e9\u8bed\u4e49\u901a\u4fe1\u7684\u7528\u6237\u6570\u91cf\u6982\u7387\u548c\u6700\u4f18\u8702\u7a9d\u534a\u5f84\u3002", "result": "\u901a\u8fc7\u4eff\u771f\u9a8c\u8bc1\u4e86\u63a8\u5bfc\u7684\u89e3\u6790\u8868\u8fbe\u5f0f\uff0c\u5e76\u5c55\u793a\u4e86\u57fa\u4e8e\u6240\u63d0\u6307\u6807\u5f97\u5230\u7684\u8702\u7a9d\u534a\u5f84\u8bbe\u8ba1\u7279\u6027\uff0c\u4e3a\u6df7\u5408\u7f51\u7edc\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u7528\u89c1\u89e3\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3a\u6df7\u5408\u8bed\u4e49\u901a\u4fe1-\u6bd4\u7279\u901a\u4fe1\u7f51\u7edc\u63d0\u4f9b\u4e86\u53ef\u9760\u7684\u7406\u8bba\u5206\u6790\u6846\u67b6\uff0c\u901a\u8fc7\u95ed\u5f0f\u8868\u8fbe\u5f0f\u548c\u5b9e\u7528\u6307\u6807\u4f18\u5316\u4e86\u7f51\u7edc\u8bbe\u8ba1\uff0c\u5e73\u8861\u4e86\u8bed\u4e49\u901a\u4fe1\u7684\u4f18\u52bf\u4e0e\u5b9e\u9645\u90e8\u7f72\u9650\u5236\u3002"}}
{"id": "2602.08795", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.08795", "abs": "https://arxiv.org/abs/2602.08795", "authors": ["Hao Jiang", "Xiaojun Yuan", "Qinghua Guo"], "title": "Joint Channel Sounding and Source-Channel Coding for MIMO-OFDM Systems: Deep Unified Encoding and Parallel Flow-Matching Decoding", "comment": null, "summary": "In this work, we propose a deep unified (DU) encoder that embeds source information in a codeword that contains sufficient redundancy to handle both channel and source uncertainties, without enforcing an explicit pilot-data separation. At the receiver, we design a parallel flow-matching (PFM) decoder that leverages flow-based generative priors to jointly estimate the channel and the source, yielding much more efficient inference than the existing diffusion-based approaches. To benchmark performance limits, we derive the Bayesian Cram\u00e9r-Rao bound (BCRB) for the joint channel and source estimation problem. Extensive simulations over block-fading MIMO-OFDM channels demonstrate that the proposed DU-PFM approach drastically outperforms the state-of-the-art methods in both channel estimation accuracy and source reconstruction quality.", "AI": {"tldr": "\u63d0\u51fa\u4e86\u4e00\u79cd\u6df1\u5ea6\u7edf\u4e00\u7f16\u7801\u5668\uff0c\u5c06\u6e90\u4fe1\u606f\u5d4c\u5165\u5230\u5305\u542b\u8db3\u591f\u5197\u4f59\u7684\u7801\u5b57\u4e2d\uff0c\u4ee5\u540c\u65f6\u5904\u7406\u4fe1\u9053\u548c\u6e90\u7684\u4e0d\u786e\u5b9a\u6027\uff0c\u65e0\u9700\u663e\u5f0f\u7684\u5bfc\u9891-\u6570\u636e\u5206\u79bb\u3002\u63a5\u6536\u7aef\u8bbe\u8ba1\u4e86\u5e76\u884c\u6d41\u5339\u914d\u89e3\u7801\u5668\uff0c\u5229\u7528\u57fa\u4e8e\u6d41\u7684\u751f\u6210\u5148\u9a8c\u8054\u5408\u4f30\u8ba1\u4fe1\u9053\u548c\u6e90\uff0c\u6bd4\u73b0\u6709\u57fa\u4e8e\u6269\u6563\u7684\u65b9\u6cd5\u63a8\u7406\u6548\u7387\u66f4\u9ad8\u3002", "motivation": "\u4f20\u7edf\u901a\u4fe1\u7cfb\u7edf\u4e2d\u901a\u5e38\u9700\u8981\u663e\u5f0f\u5206\u79bb\u5bfc\u9891\u548c\u6570\u636e\u6765\u5206\u522b\u5904\u7406\u4fe1\u9053\u4f30\u8ba1\u548c\u6e90\u91cd\u5efa\u95ee\u9898\uff0c\u8fd9\u79cd\u65b9\u6cd5\u6548\u7387\u8f83\u4f4e\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u8054\u5408\u5904\u7406\u4fe1\u9053\u548c\u6e90\u4e0d\u786e\u5b9a\u6027\u7684\u7edf\u4e00\u6846\u67b6\uff0c\u63d0\u9ad8\u901a\u4fe1\u7cfb\u7edf\u7684\u6574\u4f53\u6027\u80fd\u3002", "method": "1. \u6df1\u5ea6\u7edf\u4e00\u7f16\u7801\u5668\uff1a\u8bbe\u8ba1\u7aef\u5230\u7aef\u7f16\u7801\u5668\uff0c\u5c06\u6e90\u4fe1\u606f\u5d4c\u5165\u5230\u5305\u542b\u8db3\u591f\u5197\u4f59\u7684\u7801\u5b57\u4e2d\uff0c\u65e0\u9700\u663e\u5f0f\u5bfc\u9891-\u6570\u636e\u5206\u79bb\u30022. \u5e76\u884c\u6d41\u5339\u914d\u89e3\u7801\u5668\uff1a\u5229\u7528\u57fa\u4e8e\u6d41\u7684\u751f\u6210\u5148\u9a8c\uff0c\u8054\u5408\u4f30\u8ba1\u4fe1\u9053\u548c\u6e90\uff0c\u6bd4\u6269\u6563\u65b9\u6cd5\u66f4\u9ad8\u6548\u30023. \u8d1d\u53f6\u65af\u514b\u62c9\u7f8e-\u7f57\u754c\uff1a\u63a8\u5bfc\u4e86\u8054\u5408\u4fe1\u9053\u548c\u6e90\u4f30\u8ba1\u95ee\u9898\u7684\u6027\u80fd\u7406\u8bba\u754c\u9650\u3002", "result": "\u5728\u5757\u8870\u843dMIMO-OFDM\u4fe1\u9053\u4e0a\u7684\u5927\u91cf\u4eff\u771f\u8868\u660e\uff0c\u6240\u63d0\u51fa\u7684DU-PFM\u65b9\u6cd5\u5728\u4fe1\u9053\u4f30\u8ba1\u7cbe\u5ea6\u548c\u6e90\u91cd\u5efa\u8d28\u91cf\u65b9\u9762\u90fd\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u6700\u5148\u8fdb\u65b9\u6cd5\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df1\u5ea6\u7edf\u4e00\u7f16\u7801\u5668\u548c\u5e76\u884c\u6d41\u5339\u914d\u89e3\u7801\u5668\u6846\u67b6\u4e3a\u8054\u5408\u4fe1\u9053\u548c\u6e90\u4f30\u8ba1\u95ee\u9898\u63d0\u4f9b\u4e86\u9ad8\u6548\u89e3\u51b3\u65b9\u6848\uff0c\u65e0\u9700\u663e\u5f0f\u5bfc\u9891-\u6570\u636e\u5206\u79bb\uff0c\u5728\u6027\u80fd\u548c\u6548\u7387\u65b9\u9762\u90fd\u8d85\u8d8a\u4e86\u73b0\u6709\u65b9\u6cd5\u3002"}}
{"id": "2602.08904", "categories": ["eess.SP", "physics.app-ph", "physics.bio-ph"], "pdf": "https://arxiv.org/pdf/2602.08904", "abs": "https://arxiv.org/abs/2602.08904", "authors": ["Xingdi Tong", "Chenyu Wen"], "title": "Denoise Stepwise Signals by Diffusion Model Based Approach", "comment": null, "summary": "Stepwise signals are ubiquitous in single-molecule detections, where abrupt changes in signal levels typically correspond to molecular conformational changes or state transitions. However, these features are inevitably obscured by noise, leading to uncertainty in estimating both signal levels and transition points. Traditional frequency-domain filtering is ineffective for denoising stepwise signals, as edge-related high-frequency components strongly overlap with noise. Although Hidden Markov Model-based approaches are widely used, they rely on stationarity assumptions and are not specifically designed for signal denoising. Here, we propose a diffusion model-based algorithm for stepwise signal denoising, named the Stepwise Signal Diffusion Model (SSDM). During training, SSDM learns the statistical structure of stepwise signals via a forward diffusion process that progressively adds noise. In the following reverse process, the model reconstructs clean signals from noisy observations, integrating a multi-scale convolutional network with an attention mechanism. Training data are generated by simulating stepwise signals through a Markov process with additive Gaussian noise. Across a broad range of signal-to-noise ratios, SSDM consistently outperforms traditional methods in both signal level reconstruction and transition point detection. Its effectiveness is further demonstrated on experimental data from single-molecule Forster Resonance Energy Transfer and nanopore DNA translocation measurements. Overall, SSDM provides a general and robust framework for recovering stepwise signals in various single-molecule detections and other physical systems exhibiting discrete state transitions.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6269\u6563\u6a21\u578b\u7684\u9636\u8dc3\u4fe1\u53f7\u53bb\u566a\u7b97\u6cd5SSDM\uff0c\u5728\u5355\u5206\u5b50\u68c0\u6d4b\u4e2d\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5", "motivation": "\u5355\u5206\u5b50\u68c0\u6d4b\u4e2d\u7684\u9636\u8dc3\u4fe1\u53f7\u5e38\u88ab\u566a\u58f0\u5e72\u6270\uff0c\u4f20\u7edf\u9891\u57df\u6ee4\u6ce2\u65e0\u6548\uff0cHMM\u65b9\u6cd5\u4f9d\u8d56\u5e73\u7a33\u6027\u5047\u8bbe\u4e14\u975e\u4e13\u95e8\u7528\u4e8e\u53bb\u566a", "method": "\u63d0\u51faSSDM\u7b97\u6cd5\uff1a\u901a\u8fc7\u524d\u5411\u6269\u6563\u8fc7\u7a0b\u5b66\u4e60\u9636\u8dc3\u4fe1\u53f7\u7edf\u8ba1\u7ed3\u6784\uff0c\u53cd\u5411\u8fc7\u7a0b\u91cd\u5efa\u5e72\u51c0\u4fe1\u53f7\uff0c\u7ed3\u5408\u591a\u5c3a\u5ea6\u5377\u79ef\u7f51\u7edc\u548c\u6ce8\u610f\u529b\u673a\u5236", "result": "\u5728\u5bbd\u8303\u56f4\u4fe1\u566a\u6bd4\u4e0b\uff0cSSDM\u5728\u4fe1\u53f7\u6c34\u5e73\u91cd\u5efa\u548c\u8dc3\u8fc1\u70b9\u68c0\u6d4b\u65b9\u9762\u5747\u4f18\u4e8e\u4f20\u7edf\u65b9\u6cd5\uff0c\u5728\u5355\u5206\u5b50FRET\u548c\u7eb3\u7c73\u5b54DNA\u6613\u4f4d\u5b9e\u9a8c\u4e2d\u9a8c\u8bc1\u6709\u6548", "conclusion": "SSDM\u4e3a\u5404\u79cd\u5355\u5206\u5b50\u68c0\u6d4b\u548c\u5176\u4ed6\u79bb\u6563\u72b6\u6001\u8dc3\u8fc1\u7269\u7406\u7cfb\u7edf\u63d0\u4f9b\u4e86\u901a\u7528\u4e14\u9c81\u68d2\u7684\u9636\u8dc3\u4fe1\u53f7\u6062\u590d\u6846\u67b6"}}

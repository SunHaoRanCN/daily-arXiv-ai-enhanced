<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 21]
- [eess.AS](#eess.AS) [Total: 7]
- [cs.SD](#cs.SD) [Total: 7]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [E2CAR: An Efficient 2D-CNN Framework for Real-Time EEG Artifact Removal on Edge Devices](https://arxiv.org/abs/2602.09035)
*Haoliang Liu,Chengkun Cai,Xu Zhao,Lei Li*

Main category: eess.SP

TL;DR: 提出E2CAR框架，用2D-CNN替换1D-CNN降低计算成本，在Edge TPU上实现推理时间减少90%，功耗降低18.98%，同时保持EEG伪迹去除性能


<details>
  <summary>Details</summary>
Motivation: 传统EEG伪迹去除方法计算成本高，不适合边缘设备的实时应用，需要更高效的解决方案

Method: 用2D-CNN替换现有CNN中的1D-CNN，部署在Edge TPU硬件加速器上，提出E2CAR框架

Result: 在TPU上推理时间减少90%，功耗降低18.98%，同时保持与现有方法相当的伪迹去除性能

Conclusion: 该方法促进了边缘设备上高效的EEG信号处理，为实时应用提供了可行的解决方案

Abstract: Electroencephalography (EEG) signals are frequently contaminated by artifacts, affecting the accuracy of subsequent analysis. Traditional artifact removal methods are often computationally expensive and inefficient for real-time applications in edge devices. This paper presents a method to reduce the computational cost of most existing convolutional neural networks (CNN) by replacing one-dimensional (1-D) CNNs with two-dimensional (2-D) CNNs and deploys them on Edge Tensor Processing Unit (TPU), which is an open-resource hardware accelerator widely used in edge devices for low-latency, low-power operation. A new Efficient 2D-CNN Artifact Removal (E2CAR) framework is also represented using the method above, and it achieves a 90\% reduction in inference time on the TPU and decreases power consumption by 18.98\%, while maintaining comparable artifact removal performance to existing methods. This approach facilitates efficient EEG signal processing on edge devices.

</details>


### [2] [WiLoc: Massive Measured Dataset of Wi-Fi Channel State Information with Application to Machine-Learning Based Localization](https://arxiv.org/abs/2602.09115)
*Yuning Zhang,Lei Chu,Omer Gokalp Serbetci,Jorge Gomez-Ponce,Andreas F. Molisch*

Main category: eess.SP

TL;DR: 本文提出了一个名为WiLoc的大规模CSI数据集，包含超过1200万个UE位置、3000多个AP，覆盖16栋室内建筑和30多条室外街道，旨在为基于机器学习的定位研究提供标准资源。


<details>
  <summary>Details</summary>
Motivation: 基于机器学习的定位方法需要大量训练数据来保证准确性和鲁棒性，这些数据需要覆盖多种用户设备位置、接入点位置和环境类型。目前缺乏这样大规模、全面的数据集来支持相关研究。

Method: 通过为期三个月的精确测量活动收集数据，构建了WiLoc数据集。该数据集在三个维度上都具有大规模特性：用户位置数量、接入点数量和环境多样性。论文详细描述了数据集结构、测量环境、测量协议和验证方法。

Result: WiLoc是目前同类数据集中规模最大的，包含超过1200万个UE位置、3000多个AP，覆盖16栋室内建筑和30多条室外街道。通过案例研究验证了大数据集在标准机器学习和迁移学习定位策略中的优势。

Conclusion: WiLoc数据集为基于机器学习的定位研究提供了宝贵的标准资源，其大规模特性有助于提高定位算法的准确性和鲁棒性，特别是在标准机器学习和迁移学习场景中。

Abstract: Localization is a key component of the wireless ecosystem. Machine learning (ML)-based localization using channel state information (CSI) is one of the most popular methods for achieving high-accuracy localization with low cost. However, to be accurate and robust, ML-based algorithms need to be trained and tested with large amounts of data, covering not only many user equipment (UE)/target locations, but also many different access points (APs) locations to which the UEs connect, in a variety of different environment types. This paper presents a massive-sized CSI dataset, WiLoc (Wi-Fi Localization), and makes it publicly available. WiLoc is obtained by a series of precision measurement campaigns that span three months, and it is massive in all the above-mentioned three dimensions: > 12 million UE locations, > 3,000 APs, covering 16 buildings for indoor localization, and > 30 streets for outdoor use. The paper describes the dataset structure, measurement environments, measurement protocols, and the dataset validations. Comprehensive case studies validate the advantages of large datasets in ML-driven localization strategies for both "standard" and transfer learning. We envision this dataset, which is by far the largest of its kind, to become a standard resource for researchers in the field of ML-based localization.

</details>


### [3] [Foundation Model-Aided Hierarchical Deep Reinforcement Learning for Blockage-Aware Link in RIS-Assisted Networks](https://arxiv.org/abs/2602.09157)
*Mohammad Ghassemi,Han Zhang,Ali Afana,Akram Bin Sediq,Melike Erol-Kantarci*

Main category: eess.SP

TL;DR: 提出FM-HDRL框架，结合基础模型与分层深度强化学习，用于RIS辅助无线网络中的联合波束成形和相移优化，显著提升频谱效率。


<details>
  <summary>Details</summary>
Motivation: 可重构智能表面(RIS)技术能显著提升6G网络的频谱效率，但实际部署面临动态条件下精确信道估计和控制优化的挑战，需要更有效的优化框架。

Method: 首先微调预训练的大型无线模型(LWM)，将原始信道数据转换为低维、上下文感知的CSI嵌入；结合用户位置和阻塞状态选择最优通信路径；然后将特征输入HDRL模型，在集中控制器中联合优化基站波束成形向量和RIS相移配置以最大化频谱效率。

Result: 仿真结果表明，FM-HDRL框架在收敛速度、频谱效率和可扩展性方面均优于基线方法，相比FM-DRL方法提升7.82%频谱效率，相比波束扫描方法提升约48.66%。

Conclusion: 提出的FM-HDRL框架通过结合基础模型和分层深度强化学习，有效解决了RIS辅助无线网络中的联合优化问题，为6G网络的实际部署提供了有前景的解决方案。

Abstract: Reconfigurable intelligent surface (RIS) technology has the potential to significantly enhance the spectral efficiency (SE) of 6G wireless networks. However, practical deployment remains constrained by challenges in accurate channel estimation and control optimization under dynamic conditions. This paper presents a foundation model-aided hierarchical deep reinforcement learning (FM-HDRL) framework designed for joint beamforming and phase-shift optimization in RIS-assisted wireless networks. To implement this, we first fine-tune a pre-trained large wireless model (LWM) to translate raw channel data into low-dimensional, context-aware channel state information (CSI) embeddings. Next, these embeddings are combined with user location information and blockage status to select the optimal communication path. The resulting features are then fed into an HDRL model, assumed to be implemented at a centralized controller, which jointly optimizes the base station (BS) beamforming vectors and the RIS phase-shift configurations to maximize SE. Simulation results demonstrate that the proposed FM-HDRL framework consistently outperforms baseline methods in terms of convergence speed, spectral efficiency, and scalability. According to the simulation results, our proposed method improves 7.82% SE compared to the FM-aided deep reinforcement learning (FM-DRL) approach and a substantial enhancement of about 48.66% relative to the beam sweeping approach.

</details>


### [4] [Digital-Twin-Aided Dynamic Spectrum Sharing and Resource Management in Integrated Satellite-Terrestrial Networks](https://arxiv.org/abs/2602.09191)
*Hung Nguyen-Kha,Vu Nguyen Ha,Ti Nguyen,Eva Lagunas,Joel Grotz,Symeon Chatzinotas,Björn Ottersten*

Main category: eess.SP

TL;DR: 本文提出了一种基于数字孪生(DT)的动态频谱共享框架，用于集成卫星-地面网络(ISTN)，通过联合长短期资源决策来减少系统拥塞，并设计了压缩感知和逐次凸逼近算法来优化资源管理。


<details>
  <summary>Details</summary>
Motivation: 无线服务需求爆炸式增长促使集成卫星-地面网络(ISTN)发展，以克服传统地面网络在覆盖范围、频谱效率和部署成本方面的限制。然而，ISTN面临多样化地面环境、用户和卫星移动性以及长传播距离等挑战，需要有效的资源管理解决方案。

Method: 提出基于时间窗口的数字孪生辅助动态频谱共享框架，建立两个优化问题：1)利用DT信息优化资源管理；2)利用实际实时信息细化解决方案。采用基于压缩感知和逐次凸逼近的算法高效求解这些问题。

Result: 使用实际流量数据和伦敦3D地图的仿真结果表明，所提算法在拥塞最小化方面优于基准方法，同时展示了解决方案的适应能力和实际可行性。

Conclusion: 数字孪生辅助的动态频谱共享框架能有效解决集成卫星-地面网络的资源管理挑战，提出的算法在减少系统拥塞方面表现出优越性能，并具备实际部署的可行性。

Abstract: The explosive growth in wireless service demand has prompted the evolution of integrated satellite-terrestrial networks (ISTNs) to overcome the limitations of traditional terrestrial networks (TNs) in terms of coverage, spectrum efficiency, and deployment cost. Particularly, leveraging LEO satellites and dynamic spectrum sharing (DSS), ISTNs offer promising solutions but face significant challenges due to diverse terrestrial environments, user and satellite mobility, and long propagation LEO-to-ground distance. To address these challenges, digitial-twin (DT) has emerged as a promising technology to offer virtual replicas of real-world systems, facilitating prediction for resource management. In this work, we study a time-window-based DT-aided DSS framework for ISTNs, enabling joint long-term and short-term resource decisions to reduce system congestion. Based on that, two optimization problems are formulated, which aim to optimize resource management using DT information and to refine obtained solutions with actual real-time information, respectively. To efficiently solve these problems, we proposed algorithms using compressed-sensing-based and successive convex approximation techniques. Simulation results using actual traffic data and the London 3D map demonstrate the superiority in terms of congestion minimization of our proposed algorithms compared to benchmarks. Additionally, it shows the adaptation ability and practical feasibility of our proposed solutions.

</details>


### [5] [AI-Driven Cardiorespiratory Signal Processing: Separation, Clustering, and Anomaly Detection](https://arxiv.org/abs/2602.09210)
*Yasaman Torabi*

Main category: eess.SP

TL;DR: 该研究应用多种AI技术分析心肺音，包括生成式AI、可解释AI、变分自编码器、非负矩阵分解和量子卷积神经网络，同时回顾了生物传感技术发展，展示了AI与新一代传感器如何支持未来医疗的智能诊断系统。


<details>
  <summary>Details</summary>
Motivation: 开发更智能的心肺音诊断系统，结合先进AI技术和下一代生物传感技术，提高心肺疾病的检测和分析能力。

Method: 1. 收集新数据集HLS-CMDS；2. 开发多种AI模型：基于大语言模型的生成式AI用于引导分离、可解释AI技术解释潜在表示、变分自编码器用于波形分离、化学启发的非负矩阵分解算法用于聚类、量子卷积神经网络检测异常生理模式；3. 回顾生物传感技术：MEMS声学传感器、量子生物传感器、从电子集成电路到光子集成电路的过渡、集成量子光子学进展。

Result: 展示了多种AI模型在心肺音分析中的应用潜力，强调了信号质量对AI性能的重要性，总结了生物传感技术的最新发展，为未来智能诊断系统提供了技术基础。

Conclusion: AI技术与下一代生物传感技术的结合能够支持更智能的医疗诊断系统，为未来医疗保健提供新的技术路径。

Abstract: This research applies artificial intelligence (AI) to separate, cluster, and analyze cardiorespiratory sounds. We recorded a new dataset (HLS-CMDS) and developed several AI models, including generative AI methods based on large language models (LLMs) for guided separation, explainable AI (XAI) techniques to interpret latent representations, variational autoencoders (VAEs) for waveform separation, a chemistry-inspired non-negative matrix factorization (NMF) algorithm for clustering, and a quantum convolutional neural network (QCNN) designed to detect abnormal physiological patterns. The performance of these AI models depends on the quality of the recorded signals. Therefore, this thesis also reviews the biosensing technologies used to capture biomedical data. It summarizes developments in microelectromechanical systems (MEMS) acoustic sensors and quantum biosensors, such as quantum dots and nitrogen-vacancy centers. It further outlines the transition from electronic integrated circuits (EICs) to photonic integrated circuits (PICs) and early progress toward integrated quantum photonics (IQP) for chip-based biosensing. Together, these studies show how AI and next-generation sensors can support more intelligent diagnostic systems for future healthcare.

</details>


### [6] [When Movable Antennas Meet RSMA and RIS: Robust Beamforming Design With Channel Uncertainty](https://arxiv.org/abs/2602.09419)
*Muhammad Asif,Asim Ihsan,Zhongliang Wang,Manzoor Ahmed,Xingwang Li,Arumugam Nallanathan,Symeon Chatzinotas*

Main category: eess.SP

TL;DR: 提出一个集成可移动天线和可重构智能表面的多用户通信系统智能优化框架，在RSMA协议下通过联合优化发射预编码、RIS反射矩阵、公共速率分配和MA位置来最大化系统和速率，考虑不完美CSI和互耦约束。


<details>
  <summary>Details</summary>
Motivation: 为了提升多用户通信系统的性能，需要充分利用可移动天线和可重构智能表面的协同优势，在RSMA协议下实现更高效的资源分配，同时考虑实际系统中的信道不确定性约束。

Method: 采用交替优化框架解决非凸问题：1) 预编码子问题通过S-procedure转化为半定规划问题；2) RIS反射矩阵优化使用逐次凸逼近方法；3) MA位置优化结合逐次凸逼近和块坐标下降法。

Result: 数值结果验证了所提框架的有效性，并展示了快速收敛特性，表明该方案能够在考虑不完美CSI和互耦约束的情况下实现系统和速率最大化。

Conclusion: 该研究提出了一个鲁棒的优化框架，成功解决了MA-RIS-RSMA系统中的联合资源分配问题，为未来智能通信系统设计提供了有效解决方案。

Abstract: In this work, we propose an intelligent optimization framework for a multi-user communication system integrating movable antennas (MAs) and a reconfigurable intelligent surface (RIS) under the rate-splitting multiple access (RSMA) protocol. The system sum-rate is maximized through joint optimization of transmit precoding vectors, RIS reflection matrix, common-rate allocation, and MA positions, subject to quality-of-service (QoS), power-budget, common-rate decoding, and mutual coupling constraints. Imperfect channel state information (CSI) is considered for all links, where robustness is ensured by modeling channel estimation errors within a bounded uncertainty region, guaranteeing worst-case performance reliability. The resulting non-convex problem is solved using an alternating optimization framework. The precoding subproblem is reformulated as a semidefinite programming (SDP) problem via linear matrix inequalities derived using the S-procedure. The RIS reflection matrix is optimized using successive convex approximation (SCA), yielding an equivalent SDP formulation. The MA position optimization is addressed through SCA combined with block coordinate descent (BCD) method. Numerical results validate the effectiveness of the proposed framework and demonstrate fast convergence.

</details>


### [7] [Orthogonal Circular Polarized Transmitter and Receiver Antennas for Mitigation of Mutual Coupling in Monostatic Radars](https://arxiv.org/abs/2602.09450)
*Shobha Sundar Ram,Akanksha Sneh*

Main category: eess.SP

TL;DR: 该论文提出使用正交圆极化的四臂螺旋天线来减少穿墙雷达中发射机和接收机之间的直接耦合，同时保留目标的一次反射信号。


<details>
  <summary>Details</summary>
Motivation: 穿墙雷达系统需要紧凑、宽带、高增益的天线来探测目标。建筑墙壁会对雷达信号造成显著衰减。当提高发射功率以补偿穿墙衰减时，发射机和接收机之间的直接耦合会使接收机饱和，导致来自目标的较弱反射信号无法被检测到。

Method: 提出使用正交圆极化的发射和接收天线来减少直接耦合，同时保留目标的一次反射。选择四臂螺旋天线作为候选方案，因为它具有尺寸小、工作频带宽、增益高、在宽视场内轴比低等优点。将正交极化QHA天线与常用的穿墙雷达天线（如Vivaldi天线和喇叭天线）在互耦减少方面进行比较。

Result: 论文展示了正交圆极化QHA天线在减少发射机和接收机之间互耦方面的有效性，并在穿墙条件下对系统进行了测试验证。

Conclusion: 四臂螺旋天线是穿墙雷达系统的良好选择，通过正交圆极化设计可以有效减少直接耦合问题，同时保持对目标反射信号的检测能力。

Abstract: Through-wall radar systems require compact, wideband and high gain antennas for detecting targets. Building walls introduce considerable attenuation on the radar signals. When the transmitted power is raised to compensate the through-wall attenuation, the direct coupling between the transmitter and receiver can saturate the receiver because of which weaker reflections off the target may remain undetected. In this paper, we propose using transmitter and receiver antennas of orthogonal circular polarization to reduce the direct coupling between the transmitter and receiver while retaining the first bounce off the target. In our paper, we demonstrate that the quadrafilar helical antenna (QHA) is a good candidate for this operation since it is characterized by a small size, wide frequency band of operation, high gain and low axial ratio over a wide field of view. We compare the reduced mutual coupling between the transmitter and receiver elements for the oppositely polarized QHA antennas with other commonly used through-wall radar antennas such as the Vivaldi and horn antennas. The system is tested in through-wall conditions.

</details>


### [8] [Performance Analysis of Millimeter Wave Radar Waveforms for Integrated Sensing and Communication](https://arxiv.org/abs/2602.09451)
*Akanksha Sneh,Aakanksha Tewari,Shobha Sundar Ram,Sumit J Darak*

Main category: eess.SP

TL;DR: 该论文比较了传统雷达波形和通信波形在集成感知与通信（ISAC）中的性能，发现IEEE 802.11ad雷达在检测单点和扩展目标方面优于PMCW和FMCW雷达，并在Zynq SoC上通过软硬件协同设计实现了雷达信号处理算法。


<details>
  <summary>Details</summary>
Motivation: 下一代智能交通系统需要同时实现感知和通信功能，但部署单独的雷达和通信设备会占用独立的频段和硬件平台。ISAC通过共享波形、硬件和频谱来解决频谱拥塞问题，需要评估不同波形在ISAC中的性能。

Method: 比较了传统雷达波形（PMCW和FMCW）和通信候选波形（IEEE 802.11ad）在ISAC中检测单点和扩展目标的性能。在Zynq系统级芯片上通过软硬件协同设计和定点分析实现了雷达信号处理算法，评估其在实际实现中的计算复杂度。

Result: FMCW对移动目标的响应比PMCW差，但IEEE 802.11ad雷达在性能上优于PMCW雷达和FMCW雷达。通过硬件实现验证了算法的可行性。

Conclusion: IEEE 802.11ad波形在ISAC应用中表现出优越性能，为智能交通系统的集成感知与通信提供了有效的解决方案。软硬件协同设计方法验证了算法在实际硬件平台上的可实现性。

Abstract: Next-generation intelligent transportation systems require both sensing and communication between road users. However, deploying separate radars and communication devices involves the allocation of individual frequency bands and hardware platforms. Integrated sensing and communication (ISAC) offers a robust solution to the challenges of spectral congestion by utilizing a shared waveform, hardware, and spectrum for both localization of mobile users and communication. Various waveforms, including phase-modulated continuous waves (PMCW) and frequency-modulated continuous waves (FMCW), have been explored for target localization using traditional radar. On the other hand, new protocols such as the IEEE 802.11ad have been proposed to support wideband communication between vehicles. This paper compares both traditional radar and communication candidate waveforms for ISAC to detect single-point and extended targets. We show that the response of FMCW to mobile targets is poorer than that of PMCW. However, the IEEE 802.11ad radar outperforms PMCW radar and FMCW radar. Additionally, the radar signal processing algorithms are implemented on Zynq system-on-chip through hardware-software co-design and fixed-point analysis to evaluate their computational complexity in real-world implementations.

</details>


### [9] [Motion Compensation for Multiple-Input-Multiple-Output Inverse Synthetic Aperture Imaging of Automotive Targets](https://arxiv.org/abs/2602.09452)
*Devansh Mathur,Akanksha Sneh,Debojyoti Sarkar,Shobha Sundar Ram*

Main category: eess.SP

TL;DR: 本文分析了三种运动补偿算法（熵最小化、互相关和相位梯度自聚焦）在MIMO-ISAR成像中的性能，发现互相关算法在MIMO配置下表现最佳，整体性能提升36%。


<details>
  <summary>Details</summary>
Motivation: 车载雷达生成的ISAR图像质量受道路杂波和目标复杂运动影响而下降。虽然MIMO框架可提升信杂噪比，但现有单通道ISAR运动补偿方法在MIMO-ISAR中的有效性尚未得到充分研究。

Method: 分析三种主流运动补偿技术：熵最小化、互相关和相位梯度自聚焦在MIMO-ISAR中的性能。使用德州仪器毫米波MIMO雷达采集的实测数据进行算法评估。

Result: 实验结果表明，在MIMO配置下，互相关运动补偿算法表现优于其他两种算法，整体性能提升达到36%。

Conclusion: 互相关运动补偿算法在MIMO-ISAR系统中具有最佳性能，为车载雷达目标成像提供了有效的运动补偿解决方案。

Abstract: Inverse synthetic aperture radar (ISAR) images generated from single-channel automotive radar data provide critical information about the shape and size of automotive targets. However, the quality of ISAR images degrades due to road clutter and when translational and higher order rotational motions of the targets are not suitably compensated. One method to enhance the signal-to-clutter-and-noise ratio (SCNR) of the systems is to leverage the advantages of the multiple-input-multiple-output (MIMO) framework available in commercial automotive radars to generate MIMO-ISAR images. While substantial research has been devoted to motion compensation of single-channel ISAR images, the effectiveness of these methods for MIMO-ISAR has not been studied extensively. This paper analyzes the performance of three popular motion compensation techniques - entropy minimization, cross-correlation, and phase gradient autofocus - on MIMO-ISAR. The algorithms are evaluated on the measurement data collected using Texas Instruments millimeter-wave MIMO radar. The results indicate that the cross-correlation MOCOMP performs better than the other two MOCOMP algorithms in the MIMO configuration, with an overall improvement of 36%.

</details>


### [10] [A Survey on STAR-RIS Enabled Joint Communications and Sensing: Fundamentals, Recent Advances and Research Challenges](https://arxiv.org/abs/2602.09589)
*Wali Ullah Khan,Chandan Kumar Sheemar,Syed Tariq Shah,Manzoor Ahmed,Symeon Chatzinotas*

Main category: eess.SP

TL;DR: STAR-RIS技术赋能通信感知一体化系统，通过全空间可编程电磁波操控解决通信与感知之间的固有权衡问题，为6G网络提供智能、灵活、感知能力。


<details>
  <summary>Details</summary>
Motivation: 通信感知一体化（JCAS）是6G网络的核心能力，能提高频谱效率、降低系统复杂性和硬件成本，但面临通信与感知目标间的固有权衡、无线传播可控性有限以及硬件设计约束等挑战。

Method: 采用同时透射反射可重构智能表面（STAR-RIS）技术，通过全空间可编程电磁波操控来解决JCAS的挑战。论文从系统架构、波形与波束成形设计、资源分配、优化框架和基于学习的控制等多个角度对STAR-RIS辅助的JCAS研究进行分类和综述。

Result: STAR-RIS技术为JCAS系统提供了有前景的解决方案，能够实现全空间电磁波的可编程操控，有助于解决通信与感知之间的权衡问题，并为6G网络带来新的应用场景。

Conclusion: STAR-RIS赋能的JCAS系统是6G网络发展的关键技术方向，但仍存在未解决的关键挑战，需要进一步研究以实现智能、灵活、感知的6G无线网络。

Abstract: The joint communications and sensing (JCAS) paradigm is envisioned as a core capability of sixth-generation (6G) wireless networks, enabling the integration of data communication and environmental sensing within a unified system. By reusing spectrum, waveforms, and hardware resources, JCAS improves spectral efficiency, reduces system complexity, and hardware cost, while enabling new use cases. Nevertheless, the realization of JCAS is hindered by inherent trade-offs between communication and sensing objectives, limited controllability of wireless propagation, and stringent hardware and design constraints. Simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS) have recently emerged as a promising technology to address these challenges by enabling full-space programmable manipulation of electromagnetic waves. This survey provides a systematic and in-depth review of STAR-RIS-enabled JCAS systems. Specifically, we first introduce the fundamental principles of JCAS and STAR-RIS. We then classify and review the state-of-the-art research on STAR-RIS-assisted JCAS from multiple perspectives, encompassing system architectures, waveform and beamforming design, resource allocation, optimization frameworks, and learning-based control. Finally, we identify key open challenges that remain unsolved and outline promising future research directions toward intelligent, flexible, and perceptive 6G wireless networks.

</details>


### [11] [Collaborative Spectrum Sensing in Cognitive and Intelligent Wireless Networks: An Artificial Intelligence Perspective](https://arxiv.org/abs/2602.09615)
*Peng Yi,Ying-Chang Liang*

Main category: eess.SP

TL;DR: 该论文综述了人工智能在无线通信中的应用，特别聚焦于认知智能无线网络中的协作频谱感知，从AI视角分类总结了深度学习、生成模型和深度强化学习等方法，并探讨了语义通信作为降低报告开销的解决方案。


<details>
  <summary>Details</summary>
Motivation: 现代无线环境日益复杂、动态和异构，人工智能成为下一代无线通信系统的关键赋能技术。论文以协作频谱感知作为代表性应用，旨在系统梳理AI在无线通信中的角色和影响。

Method: 首先介绍协作频谱感知的基础框架、经典检测器设计和融合策略；然后从AI视角分类综述最新研究：判别式深度学习模型、生成式深度学习模型和深度强化学习；进一步探索语义通信作为CSS的解决方案，通过交换面向任务的表示来降低报告开销。

Result: 论文系统性地总结了AI驱动的协作频谱感知研究现状，将现有方法分为三大类，并提出了语义通信作为降低报告开销的创新方案。为AI与无线通信交叉领域的研究提供了全面的技术路线图。

Conclusion: 人工智能在无线通信中具有重要应用价值，特别是在协作频谱感知等复杂场景中。语义通信为解决报告开销问题提供了有前景的方向。未来需要进一步解决该交叉领域的局限性、开放挑战和研究方向。

Abstract: Artificial intelligence (AI) has become a key enabler for next-generation wireless communication systems, offering powerful tools to cope with the increasing complexity, dynamics, and heterogeneity of modern wireless environments. To illustrate the role and impact of AI in wireless communications, this paper takes collaborative spectrum sensing (CSS) in cognitive and intelligent wireless networks as a representative application and surveys recent advances from an AI perspective. We first introduce the fundamentals of CSS, including the general framework, classical detector design, and fusion strategies. Then, we present an overview of the state-of-the-art research on AI-driven CSS, classified into three categories: discriminative deep learning (DL) models, generative DL models, and deep reinforcement learning (DRL). Furthermore, we explore semantic communication (SemCom) as a promising solution for CSS, in which task-oriented representations are exchanged to reduce reporting overhead while preserving decision-critical information. Finally, we discuss limitations, open challenges, and future research directions at the intersection of AI and wireless communication.

</details>


### [12] [Generalizable and Robust Beam Prediction for 6G Networks: An Deep-Learning Framework with Positioning Feature Fusion](https://arxiv.org/abs/2602.09685)
*Yanliang Jin,Yunfan Li,Jiang Jun,Yuan Gao,Shengli Liu,Jianbo Du,Zhaohui Yang,Shugong Xu*

Main category: eess.SP

TL;DR: 提出基于深度学习的波束预测框架，利用位置感知特征提高预测精度并降低训练开销，在超大规模MIMO系统中优于传统基线方法。


<details>
  <summary>Details</summary>
Motivation: 5G及超大规模MIMO系统中的波束训练开销巨大，需要减少训练成本同时提高波束预测准确性。

Method: 采用双分支RegNet架构，通过位置提取分支学习位置特征，与波束域特征融合；提出自适应融合和对抗融合两种策略进行特征整合。

Result: 在DeepMIMO模拟器生成的四个城市场景数据集上，在分布内和分布外设置下均优于传统基线，实现了更准确和鲁棒的波束预测。

Conclusion: 提出的深度学习框架通过有效整合定位信息，显著提高了波束预测性能，为5G及超大规模MIMO系统提供了高效的波束训练解决方案。

Abstract: Beamforming (BF) is essential for enhancing system capacity in fifth generation (5G) and beyond wireless networks, yet exhaustive beam training in ultra-massive multiple-input multiple-output (MIMO) systems incurs substantial overhead. To address this challenge, we propose a deep learning based framework that leverages position-aware features to improve beam prediction accuracy while reducing training costs. The proposed approach uses spatial coordinate labels to supervise a position extraction branch and integrates the resulting representations with beam-domain features through a feature fusion module. A dual-branch RegNet architecture is adopted to jointly learn location related and communication features for beam prediction. Two fusion strategies, namely adaptive fusion and adversarial fusion, are introduced to enable efficient feature integration. The proposed framework is evaluated on datasets generated by the DeepMIMO simulator across four urban scenarios at 3.5 GHz following 3GPP specifications, where both reference signal received power and user equipment location information are available. Simulation results under both in-distribution and out-of-distribution settings demonstrate that the proposed approach consistently outperforms traditional baselines and achieves more accurate and robust beam prediction by effectively incorporating positioning information.

</details>


### [13] [Rolling Element Bearing Fault Detection and Diagnosis with One-Dimensional Convolutional Neural Network](https://arxiv.org/abs/2602.09699)
*Barathan Pubalan,Muhammad Arif Aiman Jidin,Mohd Syahril Ramadhan Mohd Saufi,Mohd Salman Leong,Muhammad Danial bin Abu Hasan*

Main category: eess.SP

TL;DR: 提出一种紧凑的一维卷积神经网络，使用原始振动数据进行轴承故障诊断，在CWRU和PU数据集上取得高准确率，验证了模型在不同工况下的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 滚动轴承是旋转机械的关键部件，传统诊断方法依赖人工特征提取和浅层分类器，难以捕捉原始振动信号中的复杂模式，需要自动化、更准确的故障诊断方法。

Method: 开发紧凑的一维卷积神经网络，直接使用原始时域振动数据，无需人工特征工程。在CWRU和PU两个基准数据集上进行训练和评估，CWRU数据按四种不同电机负载条件（0-3 HP）分别训练测试。

Result: 在CWRU数据集上，模型在0 HP、1 HP、2 HP、3 HP负载下分别达到99.14%、98.85%、97.42%、95.14%的平均测试准确率。在PU数据集上达到95.63%的平均测试准确率。通过超参数调优（窗口长度和训练轮数）进一步提升了性能。

Conclusion: 该方法证明了1D CNN在实时、数据驱动的轴承故障诊断中的有效性和可扩展性，为工业应用中的状态监测提供了可靠基础，能够泛化到不同数据集和变化的工作条件。

Abstract: Rolling element bearings are critical components in rotating machinery, and their condition significantly influences system performance, reliability, and operational lifespan. Timely and accurate fault detection is essential to prevent unexpected failures and reduce maintenance costs. Traditional diagnostic methods often rely on manual feature extraction and shallow classifiers, which may be inadequate for capturing the complex patterns embedded in raw vibration signals. In this study, a compact one-dimensional convolutional neural network (1D CNN) is developed for automated bearing fault diagnosis using raw time-domain vibration data, eliminating the need for manual feature engineering. The model is trained and evaluated on two established benchmark datasets: the Case Western Reserve University (CWRU) dataset and the Paderborn University (PU) dataset. The CWRU data were segmented based on four distinct motor load conditions (0 HP to 3 HP), with each load scenario trained and tested independently to ensure strict separation and prevent data leakage. The CNN achieved high average test accuracies of 99.14%, 98.85%, 97.42%, and 95.14% for 0 HP, 1 HP, 2 HP, and 3 HP, respectively. On the PU dataset, known for its naturally induced faults and greater operational variability the model achieved a robust average testing accuracy of 95.63%. These results affirm the model ability to generalize across datasets and varying operating conditions. Further improvements were observed through hyperparameter tuning, particularly window length and training epochs, underscoring the importance of tailored configurations for specific datasets and load conditions. Overall, the proposed method demonstrates the effectiveness and scalability of 1D CNNs for real-time, data-driven bearing fault diagnosis, offering a reliable foundation for condition monitoring in industrial applications.

</details>


### [14] [A Dual Belief-Driven Bayesian-Stackelberg Framework for Low-Complexity and Secure Near-Field ISAC Systems](https://arxiv.org/abs/2602.09754)
*Mehzabien Iqbal,Ahmad Y Javaid*

Main category: eess.SP

TL;DR: 提出贝叶斯-斯塔克尔伯格框架，联合优化近场ISAC系统的感知、波束成形和通信，通过自适应节点角色切换和信念驱动资源分配，显著提升安全性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 近场ISAC系统面临动态信道条件、多窃听者威胁以及毫米波/太赫兹频段实时优化的高计算负担等安全挑战，需要一种既能保证安全性又具有低计算复杂度的解决方案。

Method: 提出贝叶斯-斯塔克尔伯格框架，包含两个核心算法：1) 自适应混合节点角色切换（在安全传输和协作干扰之间切换）；2) 信念驱动的感知与波束成形（基于置信度的资源分配）。该框架保持线性计算复杂度。

Result: 在28-410 GHz频段的仿真中，该方法实现了高达35%的保密率提升，成功率超过98%，且运行时开销最小，显著优于传统通信系统。

Conclusion: 信念驱动的ISAC安全解决方案具有可扩展性，适合下一代通信系统的低复杂度部署，为近场ISAC系统提供了有效的安全保障框架。

Abstract: Ensuring robust security in near-field Integrated Sensing and Communication (ISAC) systems remains a critical challenge due to dynamic channel conditions, multi-eavesdropper threats, and the high computational burden of real-time optimization at mmWave and THz frequencies. To address these challenges, this paper introduces a novel Bayesian-Stackelberg framework that jointly optimizes sensing, beamforming, and communication. The dual-algorithm design integrates (i) Adaptive Hybrid Node Role Switching between secure transmission and cooperative jamming (ii) Belief-Driven Sensing and Beamforming for confidence based resource allocation. The proposed unified framework significantly improves robustness against attacks while preserving linear computational complexity. Simulation results across carrier frequencies ranging from 28 to 410 GHz demonstrate that the method achieves up to a 35% increase in secrecy rates and a success rate exceeding 98%, outperforming conventional communication systems with minimal runtime overhead. These findings underscore the scalability of belief-driven ISAC security solutions for low-complexity deployment in next generation communications.

</details>


### [15] [An Unsupervised Normalizing Flow-Based Neyman-Pearson Detector for Covert Communications in the Presence of Disco Reconfigurable Intelligent Surfaces](https://arxiv.org/abs/2602.09763)
*Luyao Sun,Sitian Li,Huan Huang,Hongliang Zhang,Weidong Mei,Dongdong Zou,Jun Li,Gangxiang Shen,Yi Cai*

Main category: eess.SP

TL;DR: 论文提出了一种基于无监督掩码自回归流的NP检测框架，用于应对DRIS存在下的隐蔽通信检测挑战，该框架无需标记训练数据即可达到接近监督方法的性能。


<details>
  <summary>Details</summary>
Motivation: 隐蔽通信提供比加密和物理层安全更高级别的隐私保护，但DRIS的引入使得传统NP检测器难以构建，因为测试统计量的概率密度函数在Alice-Bob传输假设下解析不可解，且Willie无法获得标记训练数据集。

Method: 提出无监督掩码自回归流(MAF)为基础的NP检测框架，利用隐蔽通信中的先验知识；定义FAR和MDR作为Willie的监控性能指标，SJNR作为Alice-Bob通信性能指标；推导SJNR的理论表达式并揭示DRIS存在下隐蔽通信的独特性质。

Result: 仿真验证了理论推导，表明提出的无监督MAF-based NP检测器性能可与监督对应方法相媲美。

Conclusion: 该研究为DRIS存在下的隐蔽通信检测提供了有效的无监督解决方案，解决了传统方法面临的解析不可解和缺乏标记数据的问题。

Abstract: Covert communications, also known as low probability of detection (LPD) communications, offer a higher level of privacy protection compared to cryptography and physical-layer security (PLS) by hiding the transmission within ambient environments. Here, we investigate covert communications in the presence of a disco reconfigurable intelligent surface (DRIS) deployed by the warden Willie, which simultaneously reduces his detection error probabilities and degrades the communication performance between Alice and Bob, without relying on either channel state information (CSI) or additional jamming power. However, the introduction of the DRIS renders it intractable for Willie to construct a Neyman-Pearson (NP) detector, since the probability density function (PDF) of the test statistic is analytically intractable under the Alice-Bob transmission hypothesis. Moreover, given the adversarial relationship between Willie and Alice/Bob, it is unrealistic to assume that Willie has access to a labeled training dataset. To address these challenges, we propose an unsupervised masked autoregressive flow (MAF)-based NP detection framework that exploits prior knowledge inherent in covert communications. We further define the false alarm rate (FAR) and the missed detection rate (MDR) as monitoring performance metrics for Willie, and the signal-to-jamming-plus-noise ratio (SJNR) as a communication performance metric for Alice-Bob transmissions. Furthermore, we derive theoretical expressions for SJNR and uncover unique properties of covert communications in the presence of a DRIS. Simulations validate the theory and show that the proposed unsupervised MAF-based NP detector achieves performance comparable to its supervised counterpart.

</details>


### [16] [Analysis of Edge Mismatch and Output Power Degradation in Cascoded Class-D Power Amplifiers Using Dual-Range Voltage Level Shifters](https://arxiv.org/abs/2602.09820)
*Behdad Jamadi,Meysam Sohani Darban,Jeffrey S. Walling*

Main category: eess.SP

TL;DR: 提出一种适用于高速应用的低抖动混合电压电平移位器，采用交叉耦合反馈同时生成两个电压域信号，工作频率达12.4GHz，在22nm FD-SOI工艺中实现，抖动小于150fs-rms。


<details>
  <summary>Details</summary>
Motivation: 高速应用中需要低抖动的电压电平移位器，传统电平移位器在高频下性能受限，需要一种能在高频下保持低抖动、小面积和低功耗的解决方案。

Method: 采用混合架构，利用交叉耦合反馈同时生成两个电压域信号（标称电源电压及其两倍电压），配合阻抗匹配和驱动电路实现高速片外测试。

Result: 在22nm FD-SOI工艺中实现，工作频率达12.4GHz，抖动小于150fs-rms，功耗4.43μW/周期，电平移位器有效面积仅2×3.26μm²。

Conclusion: 提出的混合电压电平移位器在高速应用中表现出优异的低抖动性能，同时具有小面积和低功耗特性，适用于高频集成电路设计。

Abstract: This paper presents a low-jitter hybrid voltage level shifter (HVLS) suitable for high-speed applications. The proposed architecture offers the advantage of cross-coupled feedback to simultaneously generate two voltage domain signals with available swings equal to the nominal supply and its double, which operate up to 12.4 GHz. A prototype HVLS circuit, along with impedance matching and a driver to enable high-speed off-chip testing, was fabricated in a 22-nm FD-SOI process technology. The prototype consumes a total die area, including the interface circuitry, of 477 x 462 um^2, while the active area of the level-shifter is 2 x 3.26 um^2. The average power consumption of the circuit is measured to be 4.43 uW per cycle, and the jitter is less than 150 fs-rms.

</details>


### [17] [Robust Processing and Learning: Principles, Methods, and Wireless Applications](https://arxiv.org/abs/2602.09848)
*Shixiong Wang,Wei Dai,Li-Chun Wang,Geoffrey Ye Li*

Main category: eess.SP

TL;DR: 这篇教程式综述文章以无线感知与通信为框架，系统性地探讨了鲁棒性的基本原理和方法，包括鲁棒统计、优化和机器学习，并展示了如何将这些方法应用于解决WSC系统中的不确定性问题。


<details>
  <summary>Details</summary>
Motivation: 本文旨在向信号处理社区介绍鲁棒性理论的经典发展和最新进展，展示鲁棒统计、优化和机器学习方法如何解决无线感知与通信系统中固有的不确定性问题，如模型失配、数据稀缺、对抗扰动和分布偏移等挑战。

Method: 首先形式化鲁棒性的概念和数学基础，阐述鲁棒统计、优化和机器学习之间的解释和关系。然后研究关键技术，包括鲁棒估计与测试、分布鲁棒优化、正则化和对抗训练。最后以无线感知与通信为具体框架，回顾针对模型失配、数据稀缺等问题的鲁棒信号处理解决方案。

Result: 文章系统性地介绍了鲁棒性理论的发展脉络，展示了鲁棒方法在无线感知与通信中的具体应用，包括鲁棒测距定位、模态感知、信道估计、接收合并、波形设计和联邦学习等，同时讨论了鲁棒性在系统设计中的代价，如名义性能妥协和额外计算负担。

Conclusion: 通过以无线感知与通信为叙事框架，本文成功地将鲁棒性理论引入信号处理社区，展示了鲁棒统计、优化和机器学习方法在应对现实世界不确定性问题中的价值和潜力，为相关领域的研究和应用提供了系统的理论指导和实践参考。

Abstract: This tutorial-style overview article examines the fundamental principles and methods of robustness, using wireless sensing and communication (WSC) as the narrative and exemplifying framework. First, we formalize the conceptual and mathematical foundations of robustness, highlighting the interpretations and relations across robust statistics, optimization, and machine learning. Key techniques, such as robust estimation and testing, distributionally robust optimization, and regularized and adversary training, are investigated. Together, the costs of robustness in system design, for example, the compromised nominal performances and the extra computational burdens, are discussed. Second, we review recent robust signal processing solutions for WSC that address model mismatch, data scarcity, adversarial perturbation, and distributional shift. Specific applications include robust ranging-based localization, modality sensing, channel estimation, receive combining, waveform design, and federated learning. Through this effort, we aim to introduce the classical developments and recent advances in robustness theory to the general signal processing community, exemplifying how robust statistical, optimization, and machine learning approaches can address the uncertainties inherent in WSC systems.

</details>


### [18] [Geometric Analysis of Blind User Identification for Massive MIMO Networks](https://arxiv.org/abs/2602.09910)
*Levi Bohnacker,Ralf R. Müller*

Main category: eess.SP

TL;DR: 提出将最近凸包分类器应用于大规模MIMO系统中的盲用户识别，仅需未知数据符号的训练序列，无需信道、调制、编码或噪声功率信息。


<details>
  <summary>Details</summary>
Motivation: 在大规模MIMO系统中实现盲用户识别，减少对系统参数的依赖，仅基于用户发送的未知数据符号进行识别，提高系统的灵活性和实用性。

Method: 采用最近凸包分类器，假设高斯发射信号，使用非严格的复本方法分析，通过算子值自由傅里叶变换简化计算，在大但有限系统中应用鞍点积分，通过高斯近似和矩匹配估计分类器准确率。

Result: 通过复本计算和蒙特卡洛模拟验证了算子值自由傅里叶变换的存在性，并估计了分类器的识别准确率。

Conclusion: 最近凸包分类器可用于大规模MIMO系统的盲用户识别，仅需未知数据符号的训练序列，为实际系统提供了一种灵活的用户识别方案。

Abstract: Applying Nearest Convex Hull Classification (NCHC) to blind user identification in a massive Multiple Input Multiple Output (MIMO) communications system is proposed. The method is blind in the way that the Base Station (BS) only requires a training sequence containing unknown data symbols obtained from the user without further knowledge on the channel, modulation, coding or even noise power. We evaluate the algorithm under the assumption of gaussian transmit signals using the non-rigorous replica method. To facilitate the computations the existence of an Operator Valued Free Fourier Transform is postulated, which is verified by Monte Carlo simulation. The replica computations are conducted in the large but finite system by applying saddle-point integration with inverse temperature $β$ as the large parameter. The classifier accuracy is estimated by gaussian approximation through moment-matching.

</details>


### [19] [Doppler Effect: Analyses and Applications in Wireless Sensing and Communications](https://arxiv.org/abs/2602.09955)
*Lie-Liang Yang*

Main category: eess.SP

TL;DR: 该章节对电磁和声学信号在现代应用中的多普勒效应进行了全面理论分析，涵盖移动通信、物联网、雷达卫星系统等场景，建立了统一的理论框架。


<details>
  <summary>Details</summary>
Motivation: 现代无线传感和通信系统（包括移动通信、物联网、机器类型通信、雷达卫星导航以及新兴的集成传感与通信）中，信号频率偏移现象日益复杂，需要建立严谨全面的多普勒效应理论分析框架。

Method: 系统研究多种运动学剖面（从匀速运动、匀加速运动到更复杂的一般运动），并详细分析影响多普勒频移的多方面因素，包括经典运动学、狭义与广义相对论、大气动力学和传播介质特性。

Result: 建立了适用于现代无线传感和通信系统的多普勒效应确定性理论基础，为从普通爱好者到专业研究人员提供了掌握信号频率偏移复杂性的完整理论框架。

Conclusion: 该工作为现代无线系统中的多普勒效应分析提供了全面、严谨的理论基础，有助于更好地理解和处理各种应用场景中的信号频率偏移问题。

Abstract: This chapter is motivated by the need for a rigorous and comprehensive analysis of the Doppler effects encountered by electromagnetic and acoustic signals across a diverse spectrum of modern applications. These include land mobile communications, various Internet of Things (IoT) networks, machine-type communications (MTC), and various radar and satellite-based systems for navigation and sensing, as well as the emerging regime of integrated sensing and communications (ISAC). A wide array of kinematic profiles is investigated, ranging from uniform motion and constant acceleration to more complex general motion. Consequently, the multi-faceted factors influencing the Doppler shift are addressed in detail, encompassing classical kinematics, special and general relativity, atmospheric dynamics, and the properties of the propagation medium. This work is intended to establish a definitive theoretical foundation for both the general enthusiast and the specialized researcher seeking to master the complexities of signal frequency shifts in modern wireless sensing and communications systems.

</details>


### [20] [HAPS-RIS and UAV Integrated Networks: A Unified Joint Multi-objective Framework](https://arxiv.org/abs/2602.09960)
*Arman Azizi,Mostafa Rahmani Ghourtani,Mustafa A. Kishk,Hamed Ahmadi,Arman Farhang*

Main category: eess.SP

TL;DR: 提出一个统一的多目标框架，将无人机和配备RIS的HAPS集成，以最大化覆盖用户数、最小化无人机部署数量和总路径损耗，并通过低复杂度算法实现动态优化。


<details>
  <summary>Details</summary>
Motivation: 未来6G非地面网络需要为偏远地区提供泛在连接，但无人机基站面临数量和功率限制。配备可重构智能表面的高空平台站(HAPS-RIS)是解决这些挑战的有前景方案。

Method: 提出联合多目标优化框架，通过证明总平均路径损耗上界最小化与k-means聚类的等价性、推导实用的RIS相移闭式设计、引入映射技术将组合分配简化为区域半径和带宽分配因子，并采用动态帕累托优化技术。

Result: 仿真表明该框架能自适应不同工作场景：低数据速率时HAPS-RIS单独即可实现全覆盖，高速率需求时无人机辅助变得必要。通过调整单个带宽分配因子，模型可恢复为无人机专用、HAPS-RIS专用和等带宽分配基线，并在各种速率要求下超越它们。

Conclusion: 该框架为6G非地面网络提供了一种灵活高效的解决方案，量化了RIS规模与无人机部署之间的权衡，使设计者能够根据服务需求变化在增加RIS元素和减少无人机之间进行权衡。

Abstract: Future 6G non-terrestrial networks aim to deliver ubiquitous connectivity to remote and undeserved regions, but unmanned aerial vehicle (UAV) base stations face fundamental challenges such as limited numbers and power budgets. To overcome these obstacles, high-altitude platform station (HAPS) equipped with a reconfigurable intelligent surface (RIS), so-called HAPS-RIS, is a promising candidate. We propose a novel unified joint multi-objective framework where UAVs and HAPS-RIS are fully integrated to extend coverage and enhance network performance. This joint multi-objective design maximizes the number of users served by the HAPS-RIS, minimizes the number of UAVs deployed and minimizes the total average UAV path loss subject to quality-of-service (QoS) and resource constraints. We propose a novel low-complexity solution strategy by proving the equivalence between minimizing the total average UAV path loss upper bound and k-means clustering, deriving a practical closed-form RIS phase-shift design, and introducing a mapping technique that collapses the combinatorial assignments into a zone radius and a bandwidth-portioning factor. Then, we propose a dynamic Pareto optimization technique to solve the transformed optimization problem. Extensive simulation results demonstrate that the proposed framework adapts seamlessly across operating regimes. A HAPS-RIS-only setup achieves full coverage at low data rates, but UAV assistance becomes indispensable as rate demands increase. By tuning a single bandwidth portioning factor, the model recovers UAV-only, HAPS-RIS-only and equal bandwidth portioning baselines within one formulation and consistently surpasses them across diverse rate requirements. The simulations also quantify a tangible trade-off between RIS scale and UAV deployment, enabling designers to trade increased RIS elements for fewer UAVs as service demands evolve.

</details>


### [21] [RIS-Assisted Rank Enhancement With Commodity WiFi Transceivers: Real-World Experiments](https://arxiv.org/abs/2602.10025)
*Aymen Khaleel,Aydin Sezgin*

Main category: eess.SP

TL;DR: 实验证明RIS可显著提升MIMO信道有效秩，在低秩信道中提升112%（1.5个秩），中等秩信道中提升61%（1个秩），使用商用WiFi硬件验证了RIS对空间复用能力的增强效果。


<details>
  <summary>Details</summary>
Motivation: 可重构智能表面（RIS）是6G无线通信的关键使能技术，能够重塑无线信道以提供有利的传播条件。本研究旨在通过实验验证RIS是否能够增强MIMO信道的有效秩，从而提升空间复用能力。

Method: 使用商用WiFi收发器构建实际MIMO系统，提出被动波束聚焦技术来操纵每个发射-接收天线对之间的传播信道，实现有利于秩提升的传播条件。在低秩和中等秩两种不同信道场景下测试算法。

Result: 实验结果显示：当信道秩不足时，RIS可将秩从默认值（无RIS时）提升112%，相当于秩增加1.5；当信道具有中等秩时，最大可实现61%的增强，对应秩增加1。这是首次使用现成WiFi硬件提供的RIS驱动秩操纵实验证据。

Conclusion: RIS能够显著增强MIMO信道的有效秩，从而提升空间复用能力。该研究为RIS部署以实现空间复用增益提供了实用见解，证明了RIS在实际无线系统中的有效性。

Abstract: Reconfigurable intelligent surfaces (RISs) are a promising enabling technology for the sixth-generation ($6$G) of wireless communications. RISs, thanks to their intelligent design, can reshape the wireless channel to provide favorable propagation conditions for information transfer. In this work, we experimentally investigate the potential of RISs to enhance the effective rank of multiple-input multiple-output (MIMO) channels, thereby improving spatial multiplexing capabilities. In our experiment, commodity WiFi transceivers are used, representing a practical MIMO system. In this context, we propose a passive beam-focusing technique to manipulate the propagation channel between each transmit-receive antenna pair and achieve a favorable propagation condition for rank improvement. The proposed algorithm is tested in two different channel scenarios: low and medium ranks. Experimental results show that, when the channel is rank-deficient, the RIS can significantly increase the rank by $112\%$ from its default value without the RIS, providing a rank increment of $1.5$. When the rank has a medium value, a maximum of $61\%$ enhancement can be achieved, corresponding to a rank increment of $1$. These results provide the first experimental evidence of RIS-driven rank manipulation with off-the-shelf WiFi hardware, offering practical insights into RIS deployment for spatial multiplexing gains.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [22] [Soft Clustering Anchors for Self-Supervised Speech Representation Learning in Joint Embedding Prediction Architectures](https://arxiv.org/abs/2602.09040)
*Georgios Ioannides,Adrian Kieback,Judah Goldfeder,Linsey Pang,Aman Chadha,Aaron Elkins,Yann LeCun,Ravid Shwartz-Ziv*

Main category: eess.AS

TL;DR: 提出GMM-Anchored JEPA方法，通过使用冻结的GMM软后验作为辅助目标，解决JEPA在语音表示学习中的表示坍缩问题，无需迭代重新聚类。


<details>
  <summary>Details</summary>
Motivation: Joint Embedding Predictive Architectures (JEPA)在自监督语音表示学习中很有前景，但存在表示坍缩问题，需要显式的基础来避免。现有方法如HuBERT和WavLM需要迭代重新聚类，计算成本高。

Method: 1. 在log-mel频谱图上拟合高斯混合模型(GMM)一次；2. 使用冻结的软后验作为整个训练过程中的辅助目标；3. 采用衰减监督调度，让GMM正则化主导早期训练，逐渐让位于JEPA目标。

Result: 在约50k小时语音数据上，相比WavLM风格基线：ASR错误率从33.22%降至28.68%；情感识别准确率从65.46%提升至67.76%；槽填充F1分数从59.1%提升至64.7%。聚类分析显示表示熵达到98%（WavLM风格仅31%），表明更均匀的聚类利用。

Conclusion: GMM-Anchored JEPA通过一次性软聚类和衰减监督调度，有效解决了JEPA的表示坍缩问题，在多个下游任务上显著优于现有方法，且计算效率更高。

Abstract: Joint Embedding Predictive Architectures (JEPA) offer a promising approach to self-supervised speech representation learning, but suffer from representation collapse without explicit grounding. We propose GMM-Anchored JEPA, which fits a Gaussian Mixture Model once on log-mel spectrograms and uses its frozen soft posteriors as auxiliary targets throughout training. A decaying supervision schedule allows GMM regularization to dominate early training before gradually yielding to the JEPA objective. Unlike HuBERT and WavLM, which require iterative re-clustering, our approach clusters input features once with soft rather than hard assignments. On ~50k hours of speech, GMM anchoring improves ASR (28.68% vs. 33.22% WER), emotion recognition (67.76% vs. 65.46%), and slot filling (64.7% vs. 59.1% F1) compared to a WavLM-style baseline with matched compute. Cluster analysis shows GMM-anchored representations achieve up to 98% entropy compared to 31% for WavLM-style, indicating substantially more uniform cluster utilization. Code is made available at https://github.com/gioannides/clustering-anchored-jepa.

</details>


### [23] [Windowed SummaryMixing: An Efficient Fine-Tuning of Self-Supervised Learning Models for Low-resource Speech Recognition](https://arxiv.org/abs/2602.09043)
*Aditya Srinivas Menon,Kumud Tripathi,Raj Gohil,Pankaj Wasnik*

Main category: eess.AS

TL;DR: 提出Windowed SummaryMixing (WSM)方法，通过结合局部邻域摘要和全局摘要来增强SummaryMixing，保持线性时间复杂度同时改善时间依赖关系，并引入选择性微调方法，在低资源语音识别中显著降低计算和内存需求。


<details>
  <summary>Details</summary>
Motivation: 自监督学习在语音处理中取得了进展，但由于自注意力机制导致二次复杂度。现有的SummaryMixing方法虽然具有线性时间复杂度，但缺乏足够的局部上下文信息，需要改进。

Method: 提出Windowed SummaryMixing (WSM)，在全局摘要基础上集成局部邻域摘要，增强时间依赖关系。同时引入选择性微调方法，在SSL模型中用WSM块替换自注意力层，并在低资源设置下仅微调这些块。

Result: WSM方法提高了ASR性能，同时将SSL模型的峰值VRAM使用降低了40%。WSM块具有线性时间复杂度并增强了上下文感知能力。选择性替换注意力层减少了计算、内存和延迟。

Conclusion: WSM通过结合局部和全局摘要，在保持线性时间复杂度的同时改善了时间依赖关系，选择性微调方法使其特别适合低资源语音识别应用，显著降低了计算和内存需求。

Abstract: Self-supervised learning (SSL) has advanced speech processing but suffers from quadratic complexity due to self-attention. To address this, SummaryMixing (SM) has been proposed as a linear-time alternative that summarizes entire utterances using mean pooling but lacks sufficient local context. In this work, we introduce Windowed SummaryMixing (WSM), which enhances SM by integrating local neighborhood summaries alongside the global summary, maintaining efficiency while improving temporal dependencies. Additionally, we introduce a selective fine-tuning approach, replacing self-attention layers in SSL models with WSM blocks and fine-tuning only these blocks in low-resource settings. Our approach improves ASR performance while reducing peak VRAM usage by 40\% in the SSL models. WSM blocks have linear-time complexity with enhanced context awareness. Selectively replacing some attention layers reduces compute, memory, and latency, making it ideal for low-resource speech recognition.

</details>


### [24] [Beyond the Utterance: An Empirical Study of Very Long Context Speech Recognition](https://arxiv.org/abs/2602.09044)
*Robert Flynn,Anton Ragni*

Main category: eess.AS

TL;DR: 该研究表明，通过算法和硬件进步，现在可以训练处理超过1小时长序列的ASR模型，使用长达21.8分钟的上下文可获得14.2%的相对性能提升。


<details>
  <summary>Details</summary>
Motivation: 传统ASR模型通常处理短于30秒的单个话语，这基于计算限制和话语独立同分布的假设。当有长格式音频时，需要先分割再处理。本研究旨在探索是否可以利用现代技术直接处理长序列音频。

Method: 使用基于注意力的方法训练ASR系统，在大规模数据上测试10种不同序列长度（从10秒到1小时）。通过修改位置编码方式和模型宽度/深度等架构组件，分析长序列处理的关键因素。还使用合成数据进行评估分析模型对上下文的使用。

Result: 结果显示，使用长达21.8分钟的上下文可获得最佳性能，相比短上下文基线有14.2%的相对改进。位置编码方法和模型的宽度/深度是处理长序列的重要因素。合成数据评估表明模型同时利用了远距离上下文的语言学和声学信息。

Conclusion: 由于算法和硬件进步，现在可以训练处理超长序列的ASR模型。使用更长上下文能显著提升性能，位置编码和模型架构是成功处理长序列的关键。模型能够有效利用远距离的上下文信息。

Abstract: Automatic speech recognition (ASR) models are normally trained to operate over single utterances, with a short duration of less than 30 seconds. This choice has been made in part due to computational constraints, but also reflects a common, but often inaccurate, modelling assumption that treats utterances as independent and identically distributed samples. When long-format audio recordings are available, to work with such systems, these recordings must first be segmented into short utterances and processed independently. In this work, we show that due to recent algorithmic and hardware advances, this is no longer necessary, and current attention-based approaches can be used to train ASR systems that operate on sequences of over an hour in length. Therefore, to gain a better understanding of the relationship between the training/evaluation sequence length and performance, we train ASR models on large-scale data using 10 different sequence lengths from 10 seconds up to 1 hour. The results show a benefit from using up to 21.8 minutes of context, with up to a 14.2% relative improvement from a short context baseline in our primary experiments. Through modifying various architectural components, we find that the method of encoding positional information and the model's width/depth are important factors when working with long sequences. Finally, a series of evaluations using synthetic data are constructed to help analyse the model's use of context. From these results, it is clear that both linguistic and acoustic aspects of the distant context are being used by the model.

</details>


### [25] [Performance Comparison of CNN and AST Models with Stacked Features for Environmental Sound Classification](https://arxiv.org/abs/2602.09321)
*Parinaz Binandeh Dehaghania,Danilo Penab,A. Pedro Aguiar*

Main category: eess.AS

TL;DR: 该论文研究了环境声音分类中特征堆叠CNN与Transformer模型的比较，发现特征堆叠CNN在计算和数据效率方面更具优势，适合资源受限的边缘计算场景。


<details>
  <summary>Details</summary>
Motivation: 环境声音分类在智慧城市监控、故障检测等领域有广泛应用。虽然CNN性能良好，但需要探索特征堆叠技术来聚合互补的声学描述符，以提升输入表示的质量。同时需要比较特征堆叠CNN与基于Transformer的模型在不同训练数据量下的表现。

Method: 研究采用基于CNN的模型，使用多种堆叠特征组合：Log-Mel谱图、频谱对比度、色度特征、Tonnetz、MFCC和Gammatone倒谱系数。在ESC-50和UrbanSound8K数据集上进行实验，采用不同训练策略：在ESC-50上预训练、在UrbanSound8K上微调，并与在AudioSet等大规模语料库上预训练的Audio Spectrogram Transformer模型进行比较。

Result: 实验结果表明，特征堆叠CNN在计算和数据效率方面优于Transformer模型，特别是在大规模预训练或大量训练数据不可用的情况下。特征堆叠CNN为资源受限和边缘级声音分类场景提供了更合适的解决方案。

Conclusion: 特征堆叠CNN为环境声音分类提供了一个计算和数据效率更高的替代方案，特别适合缺乏大规模预训练数据或计算资源的应用场景，在边缘计算和资源受限环境中具有实用价值。

Abstract: Environmental sound classification (ESC) has gained significant attention due to its diverse applications in smart city monitoring, fault detection, acoustic surveillance, and manufacturing quality control. To enhance CNN performance, feature stacking techniques have been explored to aggregate complementary acoustic descriptors into richer input representations. In this paper, we investigate CNN-based models employing various stacked feature combinations, including Log-Mel Spectrogram (LM), Spectral Contrast (SPC), Chroma (CH), Tonnetz (TZ), Mel-Frequency Cepstral Coefficients (MFCCs), and Gammatone Cepstral Coefficients (GTCC). Experiments are conducted on the widely used ESC-50 and UrbanSound8K datasets under different training regimes, including pretraining on ESC-50, fine-tuning on UrbanSound8K, and comparison with Audio Spectrogram Transformer (AST) models pretrained on large-scale corpora such as AudioSet. This experimental design enables an analysis of how feature-stacked CNNs compare with transformer-based models under varying levels of training data and pretraining diversity. The results indicate that feature-stacked CNNs offer a more computationally and data-efficient alternative when large-scale pretraining or extensive training data are unavailable, making them particularly well suited for resource-constrained and edge-level sound classification scenarios.

</details>


### [26] [TVTSyn: Content-Synchronous Time-Varying Timbre for Streaming Voice Conversion and Anonymization](https://arxiv.org/abs/2602.09389)
*Waris Quamer,Mu-Ruei Tseng,Ghady Nasrallah,Ricardo Gutierrez-Osuna*

Main category: eess.AS

TL;DR: 提出TVT（时变音色）表示法，通过内容同步的音色变化实现可流式语音合成，在<80ms延迟下提升自然度、说话人转换和匿名化效果


<details>
  <summary>Details</summary>
Motivation: 实时语音转换和说话人匿名化需要因果、低延迟的合成系统，但现有系统存在表示不匹配问题：内容是时变的，而说话人身份却作为静态全局嵌入注入

Method: 引入可流式语音合成器，通过内容同步的时变音色（TVT）表示对齐身份和内容的时间粒度。使用全局音色记忆将全局音色实例扩展为多个紧凑方面，帧级内容关注该记忆，门控调节变化，球面插值保持身份几何同时实现平滑局部变化。此外，使用因子化向量量化瓶颈正则化内容以减少残留说话人泄漏

Result: 系统可实现端到端流式处理，GPU延迟<80ms。实验显示在自然度、说话人转换和匿名化方面优于最先进的流式基线方法

Conclusion: TVT是一种可扩展的方法，可在严格延迟预算下实现隐私保护和富有表现力的语音合成

Abstract: Real-time voice conversion and speaker anonymization require causal, low-latency synthesis without sacrificing intelligibility or naturalness. Current systems have a core representational mismatch: content is time-varying, while speaker identity is injected as a static global embedding. We introduce a streamable speech synthesizer that aligns the temporal granularity of identity and content via a content-synchronous, time-varying timbre (TVT) representation. A Global Timbre Memory expands a global timbre instance into multiple compact facets; frame-level content attends to this memory, a gate regulates variation, and spherical interpolation preserves identity geometry while enabling smooth local changes. In addition, a factorized vector-quantized bottleneck regularizes content to reduce residual speaker leakage. The resulting system is streamable end-to-end, with <80 ms GPU latency. Experiments show improvements in naturalness, speaker transfer, and anonymization compared to SOTA streaming baselines, establishing TVT as a scalable approach for privacy-preserving and expressive speech synthesis under strict latency budgets.

</details>


### [27] [Evaluation of acoustic Green's function in rectangular rooms with general surface impedance walls](https://arxiv.org/abs/2602.09594)
*Matteo Calafà,Yuanxin Xia,Jonas Brunskog,Cheol-Ho Jeong*

Main category: eess.AS

TL;DR: 提出一种半解析方法计算矩形房间格林函数，适用于一般边界条件（包括软壁），通过高阶截断实现可忽略误差，可作为数值模拟基准。


<details>
  <summary>Details</summary>
Motivation: 现有分析方法仅适用于完美反射或近似刚性边界，无法处理吸收显著的一般边界条件（如软壁），需要更通用的解决方案。

Method: 扩展一阶渐近分析以包含软壁边界，提出半解析、高效可靠的格林函数计算方法，通过数值测试验证，并讨论谱基正交性和完备性。

Result: 方法在足够大截断阶数下误差可忽略，适合作为数值模拟基准，建立了处理一般边界条件的通用框架。

Conclusion: 该研究提供了处理矩形房间一般边界条件的综合分析方法，提出的半解析方法既高效又可靠，为声学模拟提供了有价值的基准工具。

Abstract: Acoustic room modes and the Green's function mode expansion are well-known for rectangular rooms with perfectly reflecting walls. First-order approximations also exist for nearly rigid boundaries; however, current analytical methods fail to accommodate more general boundary conditions, e.g., when wall absorption is significant. In this work, we present a comprehensive analysis that extends previous studies by including additional first-order asymptotics that account for soft-wall boundaries. In addition, we introduce a semi-analytical, efficient, and reliable method for computing the Green's function in rectangular rooms, which is described and validated through numerical tests. With a sufficiently large truncation order, the resulting error becomes negligible, making the method suitable as a benchmark for numerical simulations. Additional aspects regarding the spectral basis orthogonality and completeness are also addressed, providing a general framework for the validity of the proposed approach.

</details>


### [28] [BioME: A Resource-Efficient Bioacoustic Foundational Model for IoT Applications](https://arxiv.org/abs/2602.09970)
*Heitor R. Guimarães,Abhishek Tiwari,Mahsa Abdollahi,Anderson R. Avila,Tiago H. Falk*

Main category: eess.AS

TL;DR: BioME是一个资源高效的生物声学音频编码器，通过层到层蒸馏和多领域预训练实现高性能，同时参数减少75%，适合物联网部署。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习音频编码器（如BEATs和AVES）在生物声学任务中表现良好，但计算成本高且对未见环境的鲁棒性有限，难以部署在资源受限的物联网平台上。

Method: 1. 通过层到层蒸馏从高容量教师模型转移表示能力；2. 在多领域数据（语音、环境声音、动物发声）上进行预训练以提高生态泛化能力；3. 通过FiLM条件注入调制感知声学特征，增强低容量情况下的特征解耦。

Result: BioME在多个生物声学任务中匹配或超越了包括其教师模型在内的更大模型的性能，同时参数减少了75%，适合资源受限的物联网部署。

Conclusion: BioME通过高效的蒸馏策略、多领域预训练和调制感知特征集成，实现了在资源受限平台上部署高性能生物声学编码器的目标，为生态监测提供了实用解决方案。

Abstract: Passive acoustic monitoring has become a key strategy in biodiversity assessment, conservation, and behavioral ecology, especially as Internet-of-Things (IoT) devices enable continuous in situ audio collection at scale. While recent self-supervised learning (SSL)-based audio encoders, such as BEATs and AVES, have shown strong performance in bioacoustic tasks, their computational cost and limited robustness to unseen environments hinder deployment on resource-constrained platforms. In this work, we introduce BioME, a resource-efficient audio encoder designed for bioacoustic applications. BioME is trained via layer-to-layer distillation from a high-capacity teacher model, enabling strong representational transfer while reducing the parameter count by 75%. To further improve ecological generalization, the model is pretrained on multi-domain data spanning speech, environmental sounds, and animal vocalizations. A key contribution is the integration of modulation-aware acoustic features via FiLM conditioning, injecting a DSP-inspired inductive bias that enhances feature disentanglement in low-capacity regimes. Across multiple bioacoustic tasks, BioME matches or surpasses the performance of larger models, including its teacher, while being suitable for resource-constrained IoT deployments. For reproducibility, code and pretrained checkpoints are publicly available.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [29] [DSFlow: Dual Supervision and Step-Aware Architecture for One-Step Flow Matching Speech Synthesis](https://arxiv.org/abs/2602.09041)
*Bin Lin,Peng Yang,Chao Yan,Xiaochen Liu,Wei Wang,Boyong Wu,Pengfei Tan,Xuerui Yang*

Main category: cs.SD

TL;DR: DSFlow：一种用于少步和单步语音合成的模块化蒸馏框架，通过离散预测任务重构生成过程，采用双重监督策略提高训练稳定性，并用轻量级步感知标记替代连续时间步条件，提升参数效率。


<details>
  <summary>Details</summary>
Motivation: 现有流匹配模型在推理时需要迭代采样，计算成本高。虽然蒸馏可以减少推理步数，但现有方法存在端点误差累积导致的过程方差问题，且直接重用连续时间架构进行离散固定步生成会导致结构参数效率低下。

Method: 1. 将生成重构为离散预测任务，使学生模型适应目标推理机制；2. 采用双重监督策略：结合端点匹配和确定性平均速度对齐，确保不同推理步数下生成轨迹的一致性；3. 用轻量级步感知标记替代连续时间步条件，提高参数效率。

Result: 在多种基于流的文本到语音架构上的实验表明，DSFlow始终优于标准蒸馏方法，在减少模型参数和推理成本的同时，实现了强大的少步和单步合成质量。

Conclusion: DSFlow通过模块化蒸馏框架有效解决了流匹配模型推理计算成本高的问题，在训练稳定性、参数效率和合成质量方面均有显著提升，为高效语音合成提供了实用解决方案。

Abstract: Flow-matching models have enabled high-quality text-to-speech synthesis, but their iterative sampling process during inference incurs substantial computational cost. Although distillation is widely used to reduce the number of inference steps, existing methods often suffer from process variance due to endpoint error accumulation. Moreover, directly reusing continuous-time architectures for discrete, fixed-step generation introduces structural parameter inefficiencies. To address these challenges, we introduce DSFlow, a modular distillation framework for few-step and one-step synthesis. DSFlow reformulates generation as a discrete prediction task and explicitly adapts the student model to the target inference regime. It improves training stability through a dual supervision strategy that combines endpoint matching with deterministic mean-velocity alignment, enforcing consistent generation trajectories across inference steps. In addition, DSFlow improves parameter efficiency by replacing continuous-time timestep conditioning with lightweight step-aware tokens, aligning model capacity with the significantly reduced timestep space of the discrete task. Extensive experiments across diverse flow-based text-to-speech architectures demonstrate that DSFlow consistently outperforms standard distillation approaches, achieving strong few-step and one-step synthesis quality while reducing model parameters and inference cost.

</details>


### [30] [The SJTU X-LANCE Lab System for MSR Challenge 2025](https://arxiv.org/abs/2602.09042)
*Jinxuan Zhu,Hao Qiu,Haina Zhu,Jianwei Yu,Kai Yu,Xie Chen*

Main category: cs.SD

TL;DR: 该论文介绍了一个在MSR 2025挑战赛中排名第一的音乐源恢复系统，采用基于BS-RoFormer的序列化处理流程，通过数据增强和模型微调策略实现了8种乐器的分离、去噪和去混响。


<details>
  <summary>Details</summary>
Motivation: MSR挑战赛需要处理音乐源分离、去噪和去混响等多个任务，现有方法需要同时处理这些复杂问题。作者旨在开发一个能够有效处理8种乐器、在主观和客观评价中都表现优异的系统。

Method: 使用序列化的BS-RoFormer模型，每个模型专门处理单一任务（音乐源分离、去噪、去混响）。采用预训练模型微调策略，包括：数据集混合与清洗、随机音乐片段混合的数据增强、音频长度扩展等训练方案。

Result: 在所有三项主观和三项客观评价指标中均获得第一名，MMSNR得分4.4623，FAD得分0.1988，表现优异。

Conclusion: 提出的序列化BS-RoFormer架构结合精心设计的训练策略，在MSR 2025挑战赛中取得了最佳性能，所有代码和检查点已开源。

Abstract: This report describes the system submitted to the music source restoration (MSR) Challenge 2025. Our approach is composed of sequential BS-RoFormers, each dealing with a single task including music source separation (MSS), denoise and dereverb. To support 8 instruments given in the task, we utilize pretrained checkpoints from MSS community and finetune the MSS model with several training schemes, including (1) mixing and cleaning of datasets; (2) random mixture of music pieces for data augmentation; (3) scale-up of audio length. Our system achieved the first rank in all three subjective and three objective evaluation metrics, including an MMSNR score of 4.4623 and an FAD score of 0.1988. We have open-sourced all the code and checkpoints at https://github.com/ModistAndrew/xlance-msr.

</details>


### [31] [NarraScore: Bridging Visual Narrative and Musical Dynamics via Hierarchical Affective Control](https://arxiv.org/abs/2602.09070)
*Yufan Wen,Zhaocheng Liu,YeGuo Hua,Ziyi Guo,Lihua Zhang,Chun Yuan,Jian Wu*

Main category: cs.SD

TL;DR: NarraScore是一个用于生成长视频配乐的分层框架，通过情感作为叙事逻辑的高密度压缩，利用冻结的视觉语言模型作为连续情感传感器，实现叙事对齐的配乐生成。


<details>
  <summary>Details</summary>
Motivation: 当前长视频配乐合成面临三个关键障碍：计算可扩展性、时间连贯性，以及最重要的对演化叙事逻辑的语义盲视。需要一种能够理解叙事逻辑并生成连贯配乐的方法。

Method: 提出NarraScore分层框架，核心是将情感视为叙事逻辑的高密度压缩。利用冻结的视觉语言模型作为连续情感传感器，将高维视觉流蒸馏为密集的效价-唤醒轨迹。采用双分支注入策略：全局语义锚确保风格稳定性，令牌级情感适配器通过元素级残差注入调节局部张力。

Result: NarraScore在保持状态一致性和叙事对齐方面达到最先进水平，同时计算开销可忽略不计，为长视频配乐生成建立了完全自主的范式。

Conclusion: 通过将情感作为叙事代理，NarraScore成功解决了长视频配乐合成的关键挑战，提供了一种计算高效且语义感知的解决方案，实现了完全自主的长视频配乐生成。

Abstract: Synthesizing coherent soundtracks for long-form videos remains a formidable challenge, currently stalled by three critical impediments: computational scalability, temporal coherence, and, most critically, a pervasive semantic blindness to evolving narrative logic. To bridge these gaps, we propose NarraScore, a hierarchical framework predicated on the core insight that emotion serves as a high-density compression of narrative logic. Uniquely, we repurpose frozen Vision-Language Models (VLMs) as continuous affective sensors, distilling high-dimensional visual streams into dense, narrative-aware Valence-Arousal trajectories. Mechanistically, NarraScore employs a Dual-Branch Injection strategy to reconcile global structure with local dynamism: a \textit{Global Semantic Anchor} ensures stylistic stability, while a surgical \textit{Token-Level Affective Adapter} modulates local tension via direct element-wise residual injection. This minimalist design bypasses the bottlenecks of dense attention and architectural cloning, effectively mitigating the overfitting risks associated with data scarcity. Experiments demonstrate that NarraScore achieves state-of-the-art consistency and narrative alignment with negligible computational overhead, establishing a fully autonomous paradigm for long-video soundtrack generation.

</details>


### [32] [Gencho: Room Impulse Response Generation from Reverberant Speech and Text via Diffusion Transformers](https://arxiv.org/abs/2602.09233)
*Jackie Lin,Jiaqi Su,Nishit Anand,Zeyu Jin,Minje Kim,Paris Smaragdis*

Main category: cs.SD

TL;DR: Gencho是一个基于扩散变换器的模型，从混响语音预测复杂频谱图房间脉冲响应，支持可控声学模拟和生成音频任务。


<details>
  <summary>Details</summary>
Motivation: 现有盲房间脉冲响应估计方法建模能力有限，在未见条件下性能下降，且新兴生成音频应用需要更灵活的脉冲响应生成方法。

Method: 使用结构感知编码器利用早期和晚期反射的隔离性编码输入音频为鲁棒表示，扩散解码器从中生成多样且感知真实的脉冲响应，可与标准语音处理管道模块化集成。

Result: 相比非生成基线生成更丰富的RIR，同时在标准RIR指标上保持强性能，并展示了文本条件RIR生成的应用。

Conclusion: Gencho在可控声学模拟和生成音频任务中展现出多功能性，为声学属性捕获和传递提供了有效的生成解决方案。

Abstract: Blind room impulse response (RIR) estimation is a core task for capturing and transferring acoustic properties; yet existing methods often suffer from limited modeling capability and degraded performance under unseen conditions. Moreover, emerging generative audio applications call for more flexible impulse response generation methods. We propose Gencho, a diffusion-transformer-based model that predicts complex spectrogram RIRs from reverberant speech. A structure-aware encoder leverages isolation between early and late reflections to encode the input audio into a robust representation for conditioning, while the diffusion decoder generates diverse and perceptually realistic impulse responses from it. Gencho integrates modularly with standard speech processing pipelines for acoustic matching. Results show richer generated RIRs than non-generative baselines while maintaining strong performance in standard RIR metrics. We further demonstrate its application to text-conditioned RIR generation, highlighting Gencho's versatility for controllable acoustic simulation and generative audio tasks.

</details>


### [33] [Covo-Audio Technical Report](https://arxiv.org/abs/2602.09823)
*Wenfu Wang,Chenxing Li,Liqiang Zhang,Yiyang Zhao,Yuxiang Zou,Hanzhao Li,Mingyu Cui,Hao Zhang,Kun Wei,Le Xu,Zikang Huang,Jiajun Xu,Jiliang Hu,Xiang He,Zeyu Xie,Jiawen Kang,Youjun Chen,Meng Yu,Dong Yu,Rilin Chen,Linlin Di,Shulin Feng,Na Hu,Yang Liu,Bang Wang,Shan Yang*

Main category: cs.SD

TL;DR: Covo-Audio是一个70亿参数的端到端语言音频语言模型，能够直接处理连续音频输入并生成音频输出，在多种音频任务上达到SOTA或竞争性性能。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的架构来处理音频输入和输出，实现语音-文本建模、口语对话、语音理解、音频理解和全双工语音交互等多种任务，同时降低部署成本。

Method: 采用大规模预训练和针对性后训练，提出智能-说话者解耦策略，将对话智能与语音渲染分离，实现灵活的语音定制，同时保持对话性能。

Result: 在多个基准测试中表现出强大的语音-文本理解和语义推理能力，优于同规模的开源模型；对话变体展现出强大的口语对话能力；全双工模型在对话能力和交互行为上表现优异。

Conclusion: 70亿规模模型在集成复杂音频智能与高级语义推理方面具有强大潜力，为开发更强大、更通用的语言音频语言模型提供了可扩展的路径。

Abstract: In this work, we present Covo-Audio, a 7B-parameter end-to-end LALM that directly processes continuous audio inputs and generates audio outputs within a single unified architecture. Through large-scale curated pretraining and targeted post-training, Covo-Audio achieves state-of-the-art or competitive performance among models of comparable scale across a broad spectrum of tasks, including speech-text modeling, spoken dialogue, speech understanding, audio understanding, and full-duplex voice interaction. Extensive evaluations demonstrate that the pretrained foundation model exhibits strong speech-text comprehension and semantic reasoning capabilities on multiple benchmarks, outperforming representative open-source models of comparable scale. Furthermore, Covo-Audio-Chat, the dialogue-oriented variant, demonstrates strong spoken conversational abilities, including understanding, contextual reasoning, instruction following, and generating contextually appropriate and empathetic responses, validating its applicability to real-world conversational assistant scenarios. Covo-Audio-Chat-FD, the evolved full-duplex model, achieves substantially superior performance on both spoken dialogue capabilities and full-duplex interaction behaviors, demonstrating its competence in practical robustness. To mitigate the high cost of deploying end-to-end LALMs for natural conversational systems, we propose an intelligence-speaker decoupling strategy that separates dialogue intelligence from voice rendering, enabling flexible voice customization with minimal text-to-speech (TTS) data while preserving dialogue performance. Overall, our results highlight the strong potential of 7B-scale models to integrate sophisticated audio intelligence with high-level semantic reasoning, and suggest a scalable path toward more capable and versatile LALMs.

</details>


### [34] [Stemphonic: All-at-once Flexible Multi-stem Music Generation](https://arxiv.org/abs/2602.09891)
*Shih-Lun Wu,Ge Zhu,Juan-Pablo Caceres,Cheng-Zhi Anna Huang,Nicholas J. Bryan*

Main category: cs.SD

TL;DR: Stemphonic是一个基于扩散/流模型的音乐声部生成框架，能够单次推理生成可变数量的同步音乐声部，解决了现有方法在灵活性和速度之间的权衡问题。


<details>
  <summary>Details</summary>
Motivation: 现有音乐声部生成方法要么使用固定架构并行输出预定义声部，要么一次只生成一个声部导致推理缓慢。需要一种既能灵活生成可变声部组合，又能保持高效推理速度的方法。

Method: 将每个声部视为批次元素，在训练时将同步声部分组，对每组应用共享噪声潜在变量。推理时使用共享初始噪声潜在变量和声部特定文本输入，单次生成同步多声部输出。还支持条件多声部生成和声部活动控制。

Result: 在多个开源声部评估集上，Stemphonic生成更高质量的音频输出，同时将完整混音生成过程加速25%到50%。

Conclusion: Stemphonic框架成功解决了音乐声部生成中灵活性与速度的权衡问题，实现了可变声部组合的单次推理生成，为用户提供了更好的控制和更符合音乐家工作流程的体验。

Abstract: Music stem generation, the task of producing musically-synchronized and isolated instrument audio clips, offers the potential of greater user control and better alignment with musician workflows compared to conventional text-to-music models. Existing stem generation approaches, however, either rely on fixed architectures that output a predefined set of stems in parallel, or generate only one stem at a time, resulting in slow inference despite flexibility in stem combination. We propose Stemphonic, a diffusion-/flow-based framework that overcomes this trade-off and generates a variable set of synchronized stems in one inference pass. During training, we treat each stem as a batch element, group synchronized stems in a batch, and apply a shared noise latent to each group. At inference-time, we use a shared initial noise latent and stem-specific text inputs to generate synchronized multi-stem outputs in one pass. We further expand our approach to enable one-pass conditional multi-stem generation and stem-wise activity controls to empower users to iteratively generate and orchestrate the temporal layering of a mix. We benchmark our results on multiple open-source stem evaluation sets and show that Stemphonic produces higher-quality outputs while accelerating the full mix generation process by 25 to 50%. Demos at: https://stemphonic-demo.vercel.app.

</details>


### [35] [Evaluating Disentangled Representations for Controllable Music Generation](https://arxiv.org/abs/2602.10058)
*Laura Ibáñez-Martínez,Chukwuemeka Nkama,Andrea Poltronieri,Xavier Serra,Martín Rocamora*

Main category: cs.SD

TL;DR: 该研究通过系统评估发现，当前音乐生成模型中的解耦表示方法未能真正实现语义解耦，嵌入的实际语义与设计意图存在不一致


<details>
  <summary>Details</summary>
Motivation: 当前音乐生成模型依赖解耦表示（如结构/音色、局部/全局）来实现可控合成，但这些嵌入的底层特性尚未得到充分探索，需要系统评估其实际效果

Method: 采用基于探测的评估框架，超越标准下游任务，选择多种无监督解耦策略模型（归纳偏置、数据增强、对抗目标、分阶段训练），在四个关键维度（信息性、等变性、不变性、解耦性）上进行跨数据集、任务和控制变换的分析

Result: 研究发现嵌入的实际语义与预期语义存在不一致，表明当前策略未能产生真正解耦的表示，揭示了可控性方法的局限性

Conclusion: 当前音乐生成中的解耦表示策略存在不足，需要重新审视可控性方法，以更准确地实现语义解耦和可控合成

Abstract: Recent approaches in music generation rely on disentangled representations, often labeled as structure and timbre or local and global, to enable controllable synthesis. Yet the underlying properties of these embeddings remain underexplored. In this work, we evaluate such disentangled representations in a set of music audio models for controllable generation using a probing-based framework that goes beyond standard downstream tasks. The selected models reflect diverse unsupervised disentanglement strategies, including inductive biases, data augmentations, adversarial objectives, and staged training procedures. We further isolate specific strategies to analyze their effect. Our analysis spans four key axes: informativeness, equivariance, invariance, and disentanglement, which are assessed across datasets, tasks, and controlled transformations. Our findings reveal inconsistencies between intended and actual semantics of the embeddings, suggesting that current strategies fall short of producing truly disentangled representations, and prompting a re-examination of how controllability is approached in music generation.

</details>

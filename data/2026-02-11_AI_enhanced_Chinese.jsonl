{"id": "2602.09041", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.09041", "abs": "https://arxiv.org/abs/2602.09041", "authors": ["Bin Lin", "Peng Yang", "Chao Yan", "Xiaochen Liu", "Wei Wang", "Boyong Wu", "Pengfei Tan", "Xuerui Yang"], "title": "DSFlow: Dual Supervision and Step-Aware Architecture for One-Step Flow Matching Speech Synthesis", "comment": null, "summary": "Flow-matching models have enabled high-quality text-to-speech synthesis, but their iterative sampling process during inference incurs substantial computational cost. Although distillation is widely used to reduce the number of inference steps, existing methods often suffer from process variance due to endpoint error accumulation. Moreover, directly reusing continuous-time architectures for discrete, fixed-step generation introduces structural parameter inefficiencies. To address these challenges, we introduce DSFlow, a modular distillation framework for few-step and one-step synthesis. DSFlow reformulates generation as a discrete prediction task and explicitly adapts the student model to the target inference regime. It improves training stability through a dual supervision strategy that combines endpoint matching with deterministic mean-velocity alignment, enforcing consistent generation trajectories across inference steps. In addition, DSFlow improves parameter efficiency by replacing continuous-time timestep conditioning with lightweight step-aware tokens, aligning model capacity with the significantly reduced timestep space of the discrete task. Extensive experiments across diverse flow-based text-to-speech architectures demonstrate that DSFlow consistently outperforms standard distillation approaches, achieving strong few-step and one-step synthesis quality while reducing model parameters and inference cost.", "AI": {"tldr": "DSFlow\uff1a\u4e00\u79cd\u7528\u4e8e\u5c11\u6b65\u548c\u5355\u6b65\u8bed\u97f3\u5408\u6210\u7684\u6a21\u5757\u5316\u84b8\u998f\u6846\u67b6\uff0c\u901a\u8fc7\u79bb\u6563\u9884\u6d4b\u4efb\u52a1\u91cd\u6784\u751f\u6210\u8fc7\u7a0b\uff0c\u91c7\u7528\u53cc\u91cd\u76d1\u7763\u7b56\u7565\u63d0\u9ad8\u8bad\u7ec3\u7a33\u5b9a\u6027\uff0c\u5e76\u7528\u8f7b\u91cf\u7ea7\u6b65\u611f\u77e5\u6807\u8bb0\u66ff\u4ee3\u8fde\u7eed\u65f6\u95f4\u6b65\u6761\u4ef6\uff0c\u63d0\u5347\u53c2\u6570\u6548\u7387\u3002", "motivation": "\u73b0\u6709\u6d41\u5339\u914d\u6a21\u578b\u5728\u63a8\u7406\u65f6\u9700\u8981\u8fed\u4ee3\u91c7\u6837\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002\u867d\u7136\u84b8\u998f\u53ef\u4ee5\u51cf\u5c11\u63a8\u7406\u6b65\u6570\uff0c\u4f46\u73b0\u6709\u65b9\u6cd5\u5b58\u5728\u7aef\u70b9\u8bef\u5dee\u7d2f\u79ef\u5bfc\u81f4\u7684\u8fc7\u7a0b\u65b9\u5dee\u95ee\u9898\uff0c\u4e14\u76f4\u63a5\u91cd\u7528\u8fde\u7eed\u65f6\u95f4\u67b6\u6784\u8fdb\u884c\u79bb\u6563\u56fa\u5b9a\u6b65\u751f\u6210\u4f1a\u5bfc\u81f4\u7ed3\u6784\u53c2\u6570\u6548\u7387\u4f4e\u4e0b\u3002", "method": "1. \u5c06\u751f\u6210\u91cd\u6784\u4e3a\u79bb\u6563\u9884\u6d4b\u4efb\u52a1\uff0c\u4f7f\u5b66\u751f\u6a21\u578b\u9002\u5e94\u76ee\u6807\u63a8\u7406\u673a\u5236\uff1b2. \u91c7\u7528\u53cc\u91cd\u76d1\u7763\u7b56\u7565\uff1a\u7ed3\u5408\u7aef\u70b9\u5339\u914d\u548c\u786e\u5b9a\u6027\u5e73\u5747\u901f\u5ea6\u5bf9\u9f50\uff0c\u786e\u4fdd\u4e0d\u540c\u63a8\u7406\u6b65\u6570\u4e0b\u751f\u6210\u8f68\u8ff9\u7684\u4e00\u81f4\u6027\uff1b3. \u7528\u8f7b\u91cf\u7ea7\u6b65\u611f\u77e5\u6807\u8bb0\u66ff\u4ee3\u8fde\u7eed\u65f6\u95f4\u6b65\u6761\u4ef6\uff0c\u63d0\u9ad8\u53c2\u6570\u6548\u7387\u3002", "result": "\u5728\u591a\u79cd\u57fa\u4e8e\u6d41\u7684\u6587\u672c\u5230\u8bed\u97f3\u67b6\u6784\u4e0a\u7684\u5b9e\u9a8c\u8868\u660e\uff0cDSFlow\u59cb\u7ec8\u4f18\u4e8e\u6807\u51c6\u84b8\u998f\u65b9\u6cd5\uff0c\u5728\u51cf\u5c11\u6a21\u578b\u53c2\u6570\u548c\u63a8\u7406\u6210\u672c\u7684\u540c\u65f6\uff0c\u5b9e\u73b0\u4e86\u5f3a\u5927\u7684\u5c11\u6b65\u548c\u5355\u6b65\u5408\u6210\u8d28\u91cf\u3002", "conclusion": "DSFlow\u901a\u8fc7\u6a21\u5757\u5316\u84b8\u998f\u6846\u67b6\u6709\u6548\u89e3\u51b3\u4e86\u6d41\u5339\u914d\u6a21\u578b\u63a8\u7406\u8ba1\u7b97\u6210\u672c\u9ad8\u7684\u95ee\u9898\uff0c\u5728\u8bad\u7ec3\u7a33\u5b9a\u6027\u3001\u53c2\u6570\u6548\u7387\u548c\u5408\u6210\u8d28\u91cf\u65b9\u9762\u5747\u6709\u663e\u8457\u63d0\u5347\uff0c\u4e3a\u9ad8\u6548\u8bed\u97f3\u5408\u6210\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.09042", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.09042", "abs": "https://arxiv.org/abs/2602.09042", "authors": ["Jinxuan Zhu", "Hao Qiu", "Haina Zhu", "Jianwei Yu", "Kai Yu", "Xie Chen"], "title": "The SJTU X-LANCE Lab System for MSR Challenge 2025", "comment": null, "summary": "This report describes the system submitted to the music source restoration (MSR) Challenge 2025. Our approach is composed of sequential BS-RoFormers, each dealing with a single task including music source separation (MSS), denoise and dereverb. To support 8 instruments given in the task, we utilize pretrained checkpoints from MSS community and finetune the MSS model with several training schemes, including (1) mixing and cleaning of datasets; (2) random mixture of music pieces for data augmentation; (3) scale-up of audio length. Our system achieved the first rank in all three subjective and three objective evaluation metrics, including an MMSNR score of 4.4623 and an FAD score of 0.1988. We have open-sourced all the code and checkpoints at https://github.com/ModistAndrew/xlance-msr.", "AI": {"tldr": "\u8be5\u8bba\u6587\u4ecb\u7ecd\u4e86\u4e00\u4e2a\u5728MSR 2025\u6311\u6218\u8d5b\u4e2d\u6392\u540d\u7b2c\u4e00\u7684\u97f3\u4e50\u6e90\u6062\u590d\u7cfb\u7edf\uff0c\u91c7\u7528\u57fa\u4e8eBS-RoFormer\u7684\u5e8f\u5217\u5316\u5904\u7406\u6d41\u7a0b\uff0c\u901a\u8fc7\u6570\u636e\u589e\u5f3a\u548c\u6a21\u578b\u5fae\u8c03\u7b56\u7565\u5b9e\u73b0\u4e868\u79cd\u4e50\u5668\u7684\u5206\u79bb\u3001\u53bb\u566a\u548c\u53bb\u6df7\u54cd\u3002", "motivation": "MSR\u6311\u6218\u8d5b\u9700\u8981\u5904\u7406\u97f3\u4e50\u6e90\u5206\u79bb\u3001\u53bb\u566a\u548c\u53bb\u6df7\u54cd\u7b49\u591a\u4e2a\u4efb\u52a1\uff0c\u73b0\u6709\u65b9\u6cd5\u9700\u8981\u540c\u65f6\u5904\u7406\u8fd9\u4e9b\u590d\u6742\u95ee\u9898\u3002\u4f5c\u8005\u65e8\u5728\u5f00\u53d1\u4e00\u4e2a\u80fd\u591f\u6709\u6548\u5904\u74068\u79cd\u4e50\u5668\u3001\u5728\u4e3b\u89c2\u548c\u5ba2\u89c2\u8bc4\u4ef7\u4e2d\u90fd\u8868\u73b0\u4f18\u5f02\u7684\u7cfb\u7edf\u3002", "method": "\u4f7f\u7528\u5e8f\u5217\u5316\u7684BS-RoFormer\u6a21\u578b\uff0c\u6bcf\u4e2a\u6a21\u578b\u4e13\u95e8\u5904\u7406\u5355\u4e00\u4efb\u52a1\uff08\u97f3\u4e50\u6e90\u5206\u79bb\u3001\u53bb\u566a\u3001\u53bb\u6df7\u54cd\uff09\u3002\u91c7\u7528\u9884\u8bad\u7ec3\u6a21\u578b\u5fae\u8c03\u7b56\u7565\uff0c\u5305\u62ec\uff1a\u6570\u636e\u96c6\u6df7\u5408\u4e0e\u6e05\u6d17\u3001\u968f\u673a\u97f3\u4e50\u7247\u6bb5\u6df7\u5408\u7684\u6570\u636e\u589e\u5f3a\u3001\u97f3\u9891\u957f\u5ea6\u6269\u5c55\u7b49\u8bad\u7ec3\u65b9\u6848\u3002", "result": "\u5728\u6240\u6709\u4e09\u9879\u4e3b\u89c2\u548c\u4e09\u9879\u5ba2\u89c2\u8bc4\u4ef7\u6307\u6807\u4e2d\u5747\u83b7\u5f97\u7b2c\u4e00\u540d\uff0cMMSNR\u5f97\u52064.4623\uff0cFAD\u5f97\u52060.1988\uff0c\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "\u63d0\u51fa\u7684\u5e8f\u5217\u5316BS-RoFormer\u67b6\u6784\u7ed3\u5408\u7cbe\u5fc3\u8bbe\u8ba1\u7684\u8bad\u7ec3\u7b56\u7565\uff0c\u5728MSR 2025\u6311\u6218\u8d5b\u4e2d\u53d6\u5f97\u4e86\u6700\u4f73\u6027\u80fd\uff0c\u6240\u6709\u4ee3\u7801\u548c\u68c0\u67e5\u70b9\u5df2\u5f00\u6e90\u3002"}}
{"id": "2602.09070", "categories": ["cs.SD", "cs.AI", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.09070", "abs": "https://arxiv.org/abs/2602.09070", "authors": ["Yufan Wen", "Zhaocheng Liu", "YeGuo Hua", "Ziyi Guo", "Lihua Zhang", "Chun Yuan", "Jian Wu"], "title": "NarraScore: Bridging Visual Narrative and Musical Dynamics via Hierarchical Affective Control", "comment": null, "summary": "Synthesizing coherent soundtracks for long-form videos remains a formidable challenge, currently stalled by three critical impediments: computational scalability, temporal coherence, and, most critically, a pervasive semantic blindness to evolving narrative logic. To bridge these gaps, we propose NarraScore, a hierarchical framework predicated on the core insight that emotion serves as a high-density compression of narrative logic. Uniquely, we repurpose frozen Vision-Language Models (VLMs) as continuous affective sensors, distilling high-dimensional visual streams into dense, narrative-aware Valence-Arousal trajectories. Mechanistically, NarraScore employs a Dual-Branch Injection strategy to reconcile global structure with local dynamism: a \\textit{Global Semantic Anchor} ensures stylistic stability, while a surgical \\textit{Token-Level Affective Adapter} modulates local tension via direct element-wise residual injection. This minimalist design bypasses the bottlenecks of dense attention and architectural cloning, effectively mitigating the overfitting risks associated with data scarcity. Experiments demonstrate that NarraScore achieves state-of-the-art consistency and narrative alignment with negligible computational overhead, establishing a fully autonomous paradigm for long-video soundtrack generation.", "AI": {"tldr": "NarraScore\u662f\u4e00\u4e2a\u7528\u4e8e\u751f\u6210\u957f\u89c6\u9891\u914d\u4e50\u7684\u5206\u5c42\u6846\u67b6\uff0c\u901a\u8fc7\u60c5\u611f\u4f5c\u4e3a\u53d9\u4e8b\u903b\u8f91\u7684\u9ad8\u5bc6\u5ea6\u538b\u7f29\uff0c\u5229\u7528\u51bb\u7ed3\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8fde\u7eed\u60c5\u611f\u4f20\u611f\u5668\uff0c\u5b9e\u73b0\u53d9\u4e8b\u5bf9\u9f50\u7684\u914d\u4e50\u751f\u6210\u3002", "motivation": "\u5f53\u524d\u957f\u89c6\u9891\u914d\u4e50\u5408\u6210\u9762\u4e34\u4e09\u4e2a\u5173\u952e\u969c\u788d\uff1a\u8ba1\u7b97\u53ef\u6269\u5c55\u6027\u3001\u65f6\u95f4\u8fde\u8d2f\u6027\uff0c\u4ee5\u53ca\u6700\u91cd\u8981\u7684\u5bf9\u6f14\u5316\u53d9\u4e8b\u903b\u8f91\u7684\u8bed\u4e49\u76f2\u89c6\u3002\u9700\u8981\u4e00\u79cd\u80fd\u591f\u7406\u89e3\u53d9\u4e8b\u903b\u8f91\u5e76\u751f\u6210\u8fde\u8d2f\u914d\u4e50\u7684\u65b9\u6cd5\u3002", "method": "\u63d0\u51faNarraScore\u5206\u5c42\u6846\u67b6\uff0c\u6838\u5fc3\u662f\u5c06\u60c5\u611f\u89c6\u4e3a\u53d9\u4e8b\u903b\u8f91\u7684\u9ad8\u5bc6\u5ea6\u538b\u7f29\u3002\u5229\u7528\u51bb\u7ed3\u7684\u89c6\u89c9\u8bed\u8a00\u6a21\u578b\u4f5c\u4e3a\u8fde\u7eed\u60c5\u611f\u4f20\u611f\u5668\uff0c\u5c06\u9ad8\u7ef4\u89c6\u89c9\u6d41\u84b8\u998f\u4e3a\u5bc6\u96c6\u7684\u6548\u4ef7-\u5524\u9192\u8f68\u8ff9\u3002\u91c7\u7528\u53cc\u5206\u652f\u6ce8\u5165\u7b56\u7565\uff1a\u5168\u5c40\u8bed\u4e49\u951a\u786e\u4fdd\u98ce\u683c\u7a33\u5b9a\u6027\uff0c\u4ee4\u724c\u7ea7\u60c5\u611f\u9002\u914d\u5668\u901a\u8fc7\u5143\u7d20\u7ea7\u6b8b\u5dee\u6ce8\u5165\u8c03\u8282\u5c40\u90e8\u5f20\u529b\u3002", "result": "NarraScore\u5728\u4fdd\u6301\u72b6\u6001\u4e00\u81f4\u6027\u548c\u53d9\u4e8b\u5bf9\u9f50\u65b9\u9762\u8fbe\u5230\u6700\u5148\u8fdb\u6c34\u5e73\uff0c\u540c\u65f6\u8ba1\u7b97\u5f00\u9500\u53ef\u5ffd\u7565\u4e0d\u8ba1\uff0c\u4e3a\u957f\u89c6\u9891\u914d\u4e50\u751f\u6210\u5efa\u7acb\u4e86\u5b8c\u5168\u81ea\u4e3b\u7684\u8303\u5f0f\u3002", "conclusion": "\u901a\u8fc7\u5c06\u60c5\u611f\u4f5c\u4e3a\u53d9\u4e8b\u4ee3\u7406\uff0cNarraScore\u6210\u529f\u89e3\u51b3\u4e86\u957f\u89c6\u9891\u914d\u4e50\u5408\u6210\u7684\u5173\u952e\u6311\u6218\uff0c\u63d0\u4f9b\u4e86\u4e00\u79cd\u8ba1\u7b97\u9ad8\u6548\u4e14\u8bed\u4e49\u611f\u77e5\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u5b9e\u73b0\u4e86\u5b8c\u5168\u81ea\u4e3b\u7684\u957f\u89c6\u9891\u914d\u4e50\u751f\u6210\u3002"}}
{"id": "2602.09233", "categories": ["cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.09233", "abs": "https://arxiv.org/abs/2602.09233", "authors": ["Jackie Lin", "Jiaqi Su", "Nishit Anand", "Zeyu Jin", "Minje Kim", "Paris Smaragdis"], "title": "Gencho: Room Impulse Response Generation from Reverberant Speech and Text via Diffusion Transformers", "comment": "In Proc. of the IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP) 2026. Audio examples available at https://linjac.github.io/Gencho/", "summary": "Blind room impulse response (RIR) estimation is a core task for capturing and transferring acoustic properties; yet existing methods often suffer from limited modeling capability and degraded performance under unseen conditions. Moreover, emerging generative audio applications call for more flexible impulse response generation methods. We propose Gencho, a diffusion-transformer-based model that predicts complex spectrogram RIRs from reverberant speech. A structure-aware encoder leverages isolation between early and late reflections to encode the input audio into a robust representation for conditioning, while the diffusion decoder generates diverse and perceptually realistic impulse responses from it. Gencho integrates modularly with standard speech processing pipelines for acoustic matching. Results show richer generated RIRs than non-generative baselines while maintaining strong performance in standard RIR metrics. We further demonstrate its application to text-conditioned RIR generation, highlighting Gencho's versatility for controllable acoustic simulation and generative audio tasks.", "AI": {"tldr": "Gencho\u662f\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563\u53d8\u6362\u5668\u7684\u6a21\u578b\uff0c\u4ece\u6df7\u54cd\u8bed\u97f3\u9884\u6d4b\u590d\u6742\u9891\u8c31\u56fe\u623f\u95f4\u8109\u51b2\u54cd\u5e94\uff0c\u652f\u6301\u53ef\u63a7\u58f0\u5b66\u6a21\u62df\u548c\u751f\u6210\u97f3\u9891\u4efb\u52a1\u3002", "motivation": "\u73b0\u6709\u76f2\u623f\u95f4\u8109\u51b2\u54cd\u5e94\u4f30\u8ba1\u65b9\u6cd5\u5efa\u6a21\u80fd\u529b\u6709\u9650\uff0c\u5728\u672a\u89c1\u6761\u4ef6\u4e0b\u6027\u80fd\u4e0b\u964d\uff0c\u4e14\u65b0\u5174\u751f\u6210\u97f3\u9891\u5e94\u7528\u9700\u8981\u66f4\u7075\u6d3b\u7684\u8109\u51b2\u54cd\u5e94\u751f\u6210\u65b9\u6cd5\u3002", "method": "\u4f7f\u7528\u7ed3\u6784\u611f\u77e5\u7f16\u7801\u5668\u5229\u7528\u65e9\u671f\u548c\u665a\u671f\u53cd\u5c04\u7684\u9694\u79bb\u6027\u7f16\u7801\u8f93\u5165\u97f3\u9891\u4e3a\u9c81\u68d2\u8868\u793a\uff0c\u6269\u6563\u89e3\u7801\u5668\u4ece\u4e2d\u751f\u6210\u591a\u6837\u4e14\u611f\u77e5\u771f\u5b9e\u7684\u8109\u51b2\u54cd\u5e94\uff0c\u53ef\u4e0e\u6807\u51c6\u8bed\u97f3\u5904\u7406\u7ba1\u9053\u6a21\u5757\u5316\u96c6\u6210\u3002", "result": "\u76f8\u6bd4\u975e\u751f\u6210\u57fa\u7ebf\u751f\u6210\u66f4\u4e30\u5bcc\u7684RIR\uff0c\u540c\u65f6\u5728\u6807\u51c6RIR\u6307\u6807\u4e0a\u4fdd\u6301\u5f3a\u6027\u80fd\uff0c\u5e76\u5c55\u793a\u4e86\u6587\u672c\u6761\u4ef6RIR\u751f\u6210\u7684\u5e94\u7528\u3002", "conclusion": "Gencho\u5728\u53ef\u63a7\u58f0\u5b66\u6a21\u62df\u548c\u751f\u6210\u97f3\u9891\u4efb\u52a1\u4e2d\u5c55\u73b0\u51fa\u591a\u529f\u80fd\u6027\uff0c\u4e3a\u58f0\u5b66\u5c5e\u6027\u6355\u83b7\u548c\u4f20\u9012\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u751f\u6210\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.09035", "categories": ["eess.SP", "cs.AI"], "pdf": "https://arxiv.org/pdf/2602.09035", "abs": "https://arxiv.org/abs/2602.09035", "authors": ["Haoliang Liu", "Chengkun Cai", "Xu Zhao", "Lei Li"], "title": "E2CAR: An Efficient 2D-CNN Framework for Real-Time EEG Artifact Removal on Edge Devices", "comment": null, "summary": "Electroencephalography (EEG) signals are frequently contaminated by artifacts, affecting the accuracy of subsequent analysis. Traditional artifact removal methods are often computationally expensive and inefficient for real-time applications in edge devices. This paper presents a method to reduce the computational cost of most existing convolutional neural networks (CNN) by replacing one-dimensional (1-D) CNNs with two-dimensional (2-D) CNNs and deploys them on Edge Tensor Processing Unit (TPU), which is an open-resource hardware accelerator widely used in edge devices for low-latency, low-power operation. A new Efficient 2D-CNN Artifact Removal (E2CAR) framework is also represented using the method above, and it achieves a 90\\% reduction in inference time on the TPU and decreases power consumption by 18.98\\%, while maintaining comparable artifact removal performance to existing methods. This approach facilitates efficient EEG signal processing on edge devices.", "AI": {"tldr": "\u63d0\u51faE2CAR\u6846\u67b6\uff0c\u75282D-CNN\u66ff\u63621D-CNN\u964d\u4f4e\u8ba1\u7b97\u6210\u672c\uff0c\u5728Edge TPU\u4e0a\u5b9e\u73b0\u63a8\u7406\u65f6\u95f4\u51cf\u5c1190%\uff0c\u529f\u8017\u964d\u4f4e18.98%\uff0c\u540c\u65f6\u4fdd\u6301EEG\u4f2a\u8ff9\u53bb\u9664\u6027\u80fd", "motivation": "\u4f20\u7edfEEG\u4f2a\u8ff9\u53bb\u9664\u65b9\u6cd5\u8ba1\u7b97\u6210\u672c\u9ad8\uff0c\u4e0d\u9002\u5408\u8fb9\u7f18\u8bbe\u5907\u7684\u5b9e\u65f6\u5e94\u7528\uff0c\u9700\u8981\u66f4\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848", "method": "\u75282D-CNN\u66ff\u6362\u73b0\u6709CNN\u4e2d\u76841D-CNN\uff0c\u90e8\u7f72\u5728Edge TPU\u786c\u4ef6\u52a0\u901f\u5668\u4e0a\uff0c\u63d0\u51faE2CAR\u6846\u67b6", "result": "\u5728TPU\u4e0a\u63a8\u7406\u65f6\u95f4\u51cf\u5c1190%\uff0c\u529f\u8017\u964d\u4f4e18.98%\uff0c\u540c\u65f6\u4fdd\u6301\u4e0e\u73b0\u6709\u65b9\u6cd5\u76f8\u5f53\u7684\u4f2a\u8ff9\u53bb\u9664\u6027\u80fd", "conclusion": "\u8be5\u65b9\u6cd5\u4fc3\u8fdb\u4e86\u8fb9\u7f18\u8bbe\u5907\u4e0a\u9ad8\u6548\u7684EEG\u4fe1\u53f7\u5904\u7406\uff0c\u4e3a\u5b9e\u65f6\u5e94\u7528\u63d0\u4f9b\u4e86\u53ef\u884c\u7684\u89e3\u51b3\u65b9\u6848"}}
{"id": "2602.09040", "categories": ["eess.AS", "cs.AI", "cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.09040", "abs": "https://arxiv.org/abs/2602.09040", "authors": ["Georgios Ioannides", "Adrian Kieback", "Judah Goldfeder", "Linsey Pang", "Aman Chadha", "Aaron Elkins", "Yann LeCun", "Ravid Shwartz-Ziv"], "title": "Soft Clustering Anchors for Self-Supervised Speech Representation Learning in Joint Embedding Prediction Architectures", "comment": "15 pages, 5 figures. Code: github.com/gioannides/clustering-anchored-jepa", "summary": "Joint Embedding Predictive Architectures (JEPA) offer a promising approach to self-supervised speech representation learning, but suffer from representation collapse without explicit grounding. We propose GMM-Anchored JEPA, which fits a Gaussian Mixture Model once on log-mel spectrograms and uses its frozen soft posteriors as auxiliary targets throughout training. A decaying supervision schedule allows GMM regularization to dominate early training before gradually yielding to the JEPA objective. Unlike HuBERT and WavLM, which require iterative re-clustering, our approach clusters input features once with soft rather than hard assignments. On ~50k hours of speech, GMM anchoring improves ASR (28.68% vs. 33.22% WER), emotion recognition (67.76% vs. 65.46%), and slot filling (64.7% vs. 59.1% F1) compared to a WavLM-style baseline with matched compute. Cluster analysis shows GMM-anchored representations achieve up to 98% entropy compared to 31% for WavLM-style, indicating substantially more uniform cluster utilization. Code is made available at https://github.com/gioannides/clustering-anchored-jepa.", "AI": {"tldr": "\u63d0\u51faGMM-Anchored JEPA\u65b9\u6cd5\uff0c\u901a\u8fc7\u4f7f\u7528\u51bb\u7ed3\u7684GMM\u8f6f\u540e\u9a8c\u4f5c\u4e3a\u8f85\u52a9\u76ee\u6807\uff0c\u89e3\u51b3JEPA\u5728\u8bed\u97f3\u8868\u793a\u5b66\u4e60\u4e2d\u7684\u8868\u793a\u574d\u7f29\u95ee\u9898\uff0c\u65e0\u9700\u8fed\u4ee3\u91cd\u65b0\u805a\u7c7b\u3002", "motivation": "Joint Embedding Predictive Architectures (JEPA)\u5728\u81ea\u76d1\u7763\u8bed\u97f3\u8868\u793a\u5b66\u4e60\u4e2d\u5f88\u6709\u524d\u666f\uff0c\u4f46\u5b58\u5728\u8868\u793a\u574d\u7f29\u95ee\u9898\uff0c\u9700\u8981\u663e\u5f0f\u7684\u57fa\u7840\u6765\u907f\u514d\u3002\u73b0\u6709\u65b9\u6cd5\u5982HuBERT\u548cWavLM\u9700\u8981\u8fed\u4ee3\u91cd\u65b0\u805a\u7c7b\uff0c\u8ba1\u7b97\u6210\u672c\u9ad8\u3002", "method": "1. \u5728log-mel\u9891\u8c31\u56fe\u4e0a\u62df\u5408\u9ad8\u65af\u6df7\u5408\u6a21\u578b(GMM)\u4e00\u6b21\uff1b2. \u4f7f\u7528\u51bb\u7ed3\u7684\u8f6f\u540e\u9a8c\u4f5c\u4e3a\u6574\u4e2a\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\u7684\u8f85\u52a9\u76ee\u6807\uff1b3. \u91c7\u7528\u8870\u51cf\u76d1\u7763\u8c03\u5ea6\uff0c\u8ba9GMM\u6b63\u5219\u5316\u4e3b\u5bfc\u65e9\u671f\u8bad\u7ec3\uff0c\u9010\u6e10\u8ba9\u4f4d\u4e8eJEPA\u76ee\u6807\u3002", "result": "\u5728\u7ea650k\u5c0f\u65f6\u8bed\u97f3\u6570\u636e\u4e0a\uff0c\u76f8\u6bd4WavLM\u98ce\u683c\u57fa\u7ebf\uff1aASR\u9519\u8bef\u7387\u4ece33.22%\u964d\u81f328.68%\uff1b\u60c5\u611f\u8bc6\u522b\u51c6\u786e\u7387\u4ece65.46%\u63d0\u5347\u81f367.76%\uff1b\u69fd\u586b\u5145F1\u5206\u6570\u4ece59.1%\u63d0\u5347\u81f364.7%\u3002\u805a\u7c7b\u5206\u6790\u663e\u793a\u8868\u793a\u71b5\u8fbe\u523098%\uff08WavLM\u98ce\u683c\u4ec531%\uff09\uff0c\u8868\u660e\u66f4\u5747\u5300\u7684\u805a\u7c7b\u5229\u7528\u3002", "conclusion": "GMM-Anchored JEPA\u901a\u8fc7\u4e00\u6b21\u6027\u8f6f\u805a\u7c7b\u548c\u8870\u51cf\u76d1\u7763\u8c03\u5ea6\uff0c\u6709\u6548\u89e3\u51b3\u4e86JEPA\u7684\u8868\u793a\u574d\u7f29\u95ee\u9898\uff0c\u5728\u591a\u4e2a\u4e0b\u6e38\u4efb\u52a1\u4e0a\u663e\u8457\u4f18\u4e8e\u73b0\u6709\u65b9\u6cd5\uff0c\u4e14\u8ba1\u7b97\u6548\u7387\u66f4\u9ad8\u3002"}}
{"id": "2602.09823", "categories": ["cs.SD", "cs.CL", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.09823", "abs": "https://arxiv.org/abs/2602.09823", "authors": ["Wenfu Wang", "Chenxing Li", "Liqiang Zhang", "Yiyang Zhao", "Yuxiang Zou", "Hanzhao Li", "Mingyu Cui", "Hao Zhang", "Kun Wei", "Le Xu", "Zikang Huang", "Jiajun Xu", "Jiliang Hu", "Xiang He", "Zeyu Xie", "Jiawen Kang", "Youjun Chen", "Meng Yu", "Dong Yu", "Rilin Chen", "Linlin Di", "Shulin Feng", "Na Hu", "Yang Liu", "Bang Wang", "Shan Yang"], "title": "Covo-Audio Technical Report", "comment": "Technical Report", "summary": "In this work, we present Covo-Audio, a 7B-parameter end-to-end LALM that directly processes continuous audio inputs and generates audio outputs within a single unified architecture. Through large-scale curated pretraining and targeted post-training, Covo-Audio achieves state-of-the-art or competitive performance among models of comparable scale across a broad spectrum of tasks, including speech-text modeling, spoken dialogue, speech understanding, audio understanding, and full-duplex voice interaction. Extensive evaluations demonstrate that the pretrained foundation model exhibits strong speech-text comprehension and semantic reasoning capabilities on multiple benchmarks, outperforming representative open-source models of comparable scale. Furthermore, Covo-Audio-Chat, the dialogue-oriented variant, demonstrates strong spoken conversational abilities, including understanding, contextual reasoning, instruction following, and generating contextually appropriate and empathetic responses, validating its applicability to real-world conversational assistant scenarios. Covo-Audio-Chat-FD, the evolved full-duplex model, achieves substantially superior performance on both spoken dialogue capabilities and full-duplex interaction behaviors, demonstrating its competence in practical robustness. To mitigate the high cost of deploying end-to-end LALMs for natural conversational systems, we propose an intelligence-speaker decoupling strategy that separates dialogue intelligence from voice rendering, enabling flexible voice customization with minimal text-to-speech (TTS) data while preserving dialogue performance. Overall, our results highlight the strong potential of 7B-scale models to integrate sophisticated audio intelligence with high-level semantic reasoning, and suggest a scalable path toward more capable and versatile LALMs.", "AI": {"tldr": "Covo-Audio\u662f\u4e00\u4e2a70\u4ebf\u53c2\u6570\u7684\u7aef\u5230\u7aef\u8bed\u8a00\u97f3\u9891\u8bed\u8a00\u6a21\u578b\uff0c\u80fd\u591f\u76f4\u63a5\u5904\u7406\u8fde\u7eed\u97f3\u9891\u8f93\u5165\u5e76\u751f\u6210\u97f3\u9891\u8f93\u51fa\uff0c\u5728\u591a\u79cd\u97f3\u9891\u4efb\u52a1\u4e0a\u8fbe\u5230SOTA\u6216\u7ade\u4e89\u6027\u6027\u80fd\u3002", "motivation": "\u5f00\u53d1\u4e00\u4e2a\u7edf\u4e00\u7684\u67b6\u6784\u6765\u5904\u7406\u97f3\u9891\u8f93\u5165\u548c\u8f93\u51fa\uff0c\u5b9e\u73b0\u8bed\u97f3-\u6587\u672c\u5efa\u6a21\u3001\u53e3\u8bed\u5bf9\u8bdd\u3001\u8bed\u97f3\u7406\u89e3\u3001\u97f3\u9891\u7406\u89e3\u548c\u5168\u53cc\u5de5\u8bed\u97f3\u4ea4\u4e92\u7b49\u591a\u79cd\u4efb\u52a1\uff0c\u540c\u65f6\u964d\u4f4e\u90e8\u7f72\u6210\u672c\u3002", "method": "\u91c7\u7528\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u548c\u9488\u5bf9\u6027\u540e\u8bad\u7ec3\uff0c\u63d0\u51fa\u667a\u80fd-\u8bf4\u8bdd\u8005\u89e3\u8026\u7b56\u7565\uff0c\u5c06\u5bf9\u8bdd\u667a\u80fd\u4e0e\u8bed\u97f3\u6e32\u67d3\u5206\u79bb\uff0c\u5b9e\u73b0\u7075\u6d3b\u7684\u8bed\u97f3\u5b9a\u5236\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u8bdd\u6027\u80fd\u3002", "result": "\u5728\u591a\u4e2a\u57fa\u51c6\u6d4b\u8bd5\u4e2d\u8868\u73b0\u51fa\u5f3a\u5927\u7684\u8bed\u97f3-\u6587\u672c\u7406\u89e3\u548c\u8bed\u4e49\u63a8\u7406\u80fd\u529b\uff0c\u4f18\u4e8e\u540c\u89c4\u6a21\u7684\u5f00\u6e90\u6a21\u578b\uff1b\u5bf9\u8bdd\u53d8\u4f53\u5c55\u73b0\u51fa\u5f3a\u5927\u7684\u53e3\u8bed\u5bf9\u8bdd\u80fd\u529b\uff1b\u5168\u53cc\u5de5\u6a21\u578b\u5728\u5bf9\u8bdd\u80fd\u529b\u548c\u4ea4\u4e92\u884c\u4e3a\u4e0a\u8868\u73b0\u4f18\u5f02\u3002", "conclusion": "70\u4ebf\u89c4\u6a21\u6a21\u578b\u5728\u96c6\u6210\u590d\u6742\u97f3\u9891\u667a\u80fd\u4e0e\u9ad8\u7ea7\u8bed\u4e49\u63a8\u7406\u65b9\u9762\u5177\u6709\u5f3a\u5927\u6f5c\u529b\uff0c\u4e3a\u5f00\u53d1\u66f4\u5f3a\u5927\u3001\u66f4\u901a\u7528\u7684\u8bed\u8a00\u97f3\u9891\u8bed\u8a00\u6a21\u578b\u63d0\u4f9b\u4e86\u53ef\u6269\u5c55\u7684\u8def\u5f84\u3002"}}
{"id": "2602.09115", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09115", "abs": "https://arxiv.org/abs/2602.09115", "authors": ["Yuning Zhang", "Lei Chu", "Omer Gokalp Serbetci", "Jorge Gomez-Ponce", "Andreas F. Molisch"], "title": "WiLoc: Massive Measured Dataset of Wi-Fi Channel State Information with Application to Machine-Learning Based Localization", "comment": "Accepted by Incofom 2026. 9 pages without reference", "summary": "Localization is a key component of the wireless ecosystem. Machine learning (ML)-based localization using channel state information (CSI) is one of the most popular methods for achieving high-accuracy localization with low cost. However, to be accurate and robust, ML-based algorithms need to be trained and tested with large amounts of data, covering not only many user equipment (UE)/target locations, but also many different access points (APs) locations to which the UEs connect, in a variety of different environment types. This paper presents a massive-sized CSI dataset, WiLoc (Wi-Fi Localization), and makes it publicly available. WiLoc is obtained by a series of precision measurement campaigns that span three months, and it is massive in all the above-mentioned three dimensions: > 12 million UE locations, > 3,000 APs, covering 16 buildings for indoor localization, and > 30 streets for outdoor use. The paper describes the dataset structure, measurement environments, measurement protocols, and the dataset validations. Comprehensive case studies validate the advantages of large datasets in ML-driven localization strategies for both \"standard\" and transfer learning. We envision this dataset, which is by far the largest of its kind, to become a standard resource for researchers in the field of ML-based localization.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u4e2a\u540d\u4e3aWiLoc\u7684\u5927\u89c4\u6a21CSI\u6570\u636e\u96c6\uff0c\u5305\u542b\u8d85\u8fc71200\u4e07\u4e2aUE\u4f4d\u7f6e\u30013000\u591a\u4e2aAP\uff0c\u8986\u76d616\u680b\u5ba4\u5185\u5efa\u7b51\u548c30\u591a\u6761\u5ba4\u5916\u8857\u9053\uff0c\u65e8\u5728\u4e3a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5b9a\u4f4d\u7814\u7a76\u63d0\u4f9b\u6807\u51c6\u8d44\u6e90\u3002", "motivation": "\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5b9a\u4f4d\u65b9\u6cd5\u9700\u8981\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u6765\u4fdd\u8bc1\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u8fd9\u4e9b\u6570\u636e\u9700\u8981\u8986\u76d6\u591a\u79cd\u7528\u6237\u8bbe\u5907\u4f4d\u7f6e\u3001\u63a5\u5165\u70b9\u4f4d\u7f6e\u548c\u73af\u5883\u7c7b\u578b\u3002\u76ee\u524d\u7f3a\u4e4f\u8fd9\u6837\u5927\u89c4\u6a21\u3001\u5168\u9762\u7684\u6570\u636e\u96c6\u6765\u652f\u6301\u76f8\u5173\u7814\u7a76\u3002", "method": "\u901a\u8fc7\u4e3a\u671f\u4e09\u4e2a\u6708\u7684\u7cbe\u786e\u6d4b\u91cf\u6d3b\u52a8\u6536\u96c6\u6570\u636e\uff0c\u6784\u5efa\u4e86WiLoc\u6570\u636e\u96c6\u3002\u8be5\u6570\u636e\u96c6\u5728\u4e09\u4e2a\u7ef4\u5ea6\u4e0a\u90fd\u5177\u6709\u5927\u89c4\u6a21\u7279\u6027\uff1a\u7528\u6237\u4f4d\u7f6e\u6570\u91cf\u3001\u63a5\u5165\u70b9\u6570\u91cf\u548c\u73af\u5883\u591a\u6837\u6027\u3002\u8bba\u6587\u8be6\u7ec6\u63cf\u8ff0\u4e86\u6570\u636e\u96c6\u7ed3\u6784\u3001\u6d4b\u91cf\u73af\u5883\u3001\u6d4b\u91cf\u534f\u8bae\u548c\u9a8c\u8bc1\u65b9\u6cd5\u3002", "result": "WiLoc\u662f\u76ee\u524d\u540c\u7c7b\u6570\u636e\u96c6\u4e2d\u89c4\u6a21\u6700\u5927\u7684\uff0c\u5305\u542b\u8d85\u8fc71200\u4e07\u4e2aUE\u4f4d\u7f6e\u30013000\u591a\u4e2aAP\uff0c\u8986\u76d616\u680b\u5ba4\u5185\u5efa\u7b51\u548c30\u591a\u6761\u5ba4\u5916\u8857\u9053\u3002\u901a\u8fc7\u6848\u4f8b\u7814\u7a76\u9a8c\u8bc1\u4e86\u5927\u6570\u636e\u96c6\u5728\u6807\u51c6\u673a\u5668\u5b66\u4e60\u548c\u8fc1\u79fb\u5b66\u4e60\u5b9a\u4f4d\u7b56\u7565\u4e2d\u7684\u4f18\u52bf\u3002", "conclusion": "WiLoc\u6570\u636e\u96c6\u4e3a\u57fa\u4e8e\u673a\u5668\u5b66\u4e60\u7684\u5b9a\u4f4d\u7814\u7a76\u63d0\u4f9b\u4e86\u5b9d\u8d35\u7684\u6807\u51c6\u8d44\u6e90\uff0c\u5176\u5927\u89c4\u6a21\u7279\u6027\u6709\u52a9\u4e8e\u63d0\u9ad8\u5b9a\u4f4d\u7b97\u6cd5\u7684\u51c6\u786e\u6027\u548c\u9c81\u68d2\u6027\uff0c\u7279\u522b\u662f\u5728\u6807\u51c6\u673a\u5668\u5b66\u4e60\u548c\u8fc1\u79fb\u5b66\u4e60\u573a\u666f\u4e2d\u3002"}}
{"id": "2602.09043", "categories": ["eess.AS", "cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.09043", "abs": "https://arxiv.org/abs/2602.09043", "authors": ["Aditya Srinivas Menon", "Kumud Tripathi", "Raj Gohil", "Pankaj Wasnik"], "title": "Windowed SummaryMixing: An Efficient Fine-Tuning of Self-Supervised Learning Models for Low-resource Speech Recognition", "comment": "The paper has been accepted at ICASSP 2026, Barcelona, Spain", "summary": "Self-supervised learning (SSL) has advanced speech processing but suffers from quadratic complexity due to self-attention. To address this, SummaryMixing (SM) has been proposed as a linear-time alternative that summarizes entire utterances using mean pooling but lacks sufficient local context. In this work, we introduce Windowed SummaryMixing (WSM), which enhances SM by integrating local neighborhood summaries alongside the global summary, maintaining efficiency while improving temporal dependencies. Additionally, we introduce a selective fine-tuning approach, replacing self-attention layers in SSL models with WSM blocks and fine-tuning only these blocks in low-resource settings. Our approach improves ASR performance while reducing peak VRAM usage by 40\\% in the SSL models. WSM blocks have linear-time complexity with enhanced context awareness. Selectively replacing some attention layers reduces compute, memory, and latency, making it ideal for low-resource speech recognition.", "AI": {"tldr": "\u63d0\u51faWindowed SummaryMixing (WSM)\u65b9\u6cd5\uff0c\u901a\u8fc7\u7ed3\u5408\u5c40\u90e8\u90bb\u57df\u6458\u8981\u548c\u5168\u5c40\u6458\u8981\u6765\u589e\u5f3aSummaryMixing\uff0c\u4fdd\u6301\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u540c\u65f6\u6539\u5584\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u5e76\u5f15\u5165\u9009\u62e9\u6027\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728\u4f4e\u8d44\u6e90\u8bed\u97f3\u8bc6\u522b\u4e2d\u663e\u8457\u964d\u4f4e\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u3002", "motivation": "\u81ea\u76d1\u7763\u5b66\u4e60\u5728\u8bed\u97f3\u5904\u7406\u4e2d\u53d6\u5f97\u4e86\u8fdb\u5c55\uff0c\u4f46\u7531\u4e8e\u81ea\u6ce8\u610f\u529b\u673a\u5236\u5bfc\u81f4\u4e8c\u6b21\u590d\u6742\u5ea6\u3002\u73b0\u6709\u7684SummaryMixing\u65b9\u6cd5\u867d\u7136\u5177\u6709\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\uff0c\u4f46\u7f3a\u4e4f\u8db3\u591f\u7684\u5c40\u90e8\u4e0a\u4e0b\u6587\u4fe1\u606f\uff0c\u9700\u8981\u6539\u8fdb\u3002", "method": "\u63d0\u51faWindowed SummaryMixing (WSM)\uff0c\u5728\u5168\u5c40\u6458\u8981\u57fa\u7840\u4e0a\u96c6\u6210\u5c40\u90e8\u90bb\u57df\u6458\u8981\uff0c\u589e\u5f3a\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\u3002\u540c\u65f6\u5f15\u5165\u9009\u62e9\u6027\u5fae\u8c03\u65b9\u6cd5\uff0c\u5728SSL\u6a21\u578b\u4e2d\u7528WSM\u5757\u66ff\u6362\u81ea\u6ce8\u610f\u529b\u5c42\uff0c\u5e76\u5728\u4f4e\u8d44\u6e90\u8bbe\u7f6e\u4e0b\u4ec5\u5fae\u8c03\u8fd9\u4e9b\u5757\u3002", "result": "WSM\u65b9\u6cd5\u63d0\u9ad8\u4e86ASR\u6027\u80fd\uff0c\u540c\u65f6\u5c06SSL\u6a21\u578b\u7684\u5cf0\u503cVRAM\u4f7f\u7528\u964d\u4f4e\u4e8640%\u3002WSM\u5757\u5177\u6709\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u5e76\u589e\u5f3a\u4e86\u4e0a\u4e0b\u6587\u611f\u77e5\u80fd\u529b\u3002\u9009\u62e9\u6027\u66ff\u6362\u6ce8\u610f\u529b\u5c42\u51cf\u5c11\u4e86\u8ba1\u7b97\u3001\u5185\u5b58\u548c\u5ef6\u8fdf\u3002", "conclusion": "WSM\u901a\u8fc7\u7ed3\u5408\u5c40\u90e8\u548c\u5168\u5c40\u6458\u8981\uff0c\u5728\u4fdd\u6301\u7ebf\u6027\u65f6\u95f4\u590d\u6742\u5ea6\u7684\u540c\u65f6\u6539\u5584\u4e86\u65f6\u95f4\u4f9d\u8d56\u5173\u7cfb\uff0c\u9009\u62e9\u6027\u5fae\u8c03\u65b9\u6cd5\u4f7f\u5176\u7279\u522b\u9002\u5408\u4f4e\u8d44\u6e90\u8bed\u97f3\u8bc6\u522b\u5e94\u7528\uff0c\u663e\u8457\u964d\u4f4e\u4e86\u8ba1\u7b97\u548c\u5185\u5b58\u9700\u6c42\u3002"}}
{"id": "2602.09891", "categories": ["cs.SD", "cs.LG", "cs.MM"], "pdf": "https://arxiv.org/pdf/2602.09891", "abs": "https://arxiv.org/abs/2602.09891", "authors": ["Shih-Lun Wu", "Ge Zhu", "Juan-Pablo Caceres", "Cheng-Zhi Anna Huang", "Nicholas J. Bryan"], "title": "Stemphonic: All-at-once Flexible Multi-stem Music Generation", "comment": "Accepted for publication at Int. Conf. on Acoustics, Speech, and Signal Processing (ICASSP) 2026", "summary": "Music stem generation, the task of producing musically-synchronized and isolated instrument audio clips, offers the potential of greater user control and better alignment with musician workflows compared to conventional text-to-music models. Existing stem generation approaches, however, either rely on fixed architectures that output a predefined set of stems in parallel, or generate only one stem at a time, resulting in slow inference despite flexibility in stem combination. We propose Stemphonic, a diffusion-/flow-based framework that overcomes this trade-off and generates a variable set of synchronized stems in one inference pass. During training, we treat each stem as a batch element, group synchronized stems in a batch, and apply a shared noise latent to each group. At inference-time, we use a shared initial noise latent and stem-specific text inputs to generate synchronized multi-stem outputs in one pass. We further expand our approach to enable one-pass conditional multi-stem generation and stem-wise activity controls to empower users to iteratively generate and orchestrate the temporal layering of a mix. We benchmark our results on multiple open-source stem evaluation sets and show that Stemphonic produces higher-quality outputs while accelerating the full mix generation process by 25 to 50%. Demos at: https://stemphonic-demo.vercel.app.", "AI": {"tldr": "Stemphonic\u662f\u4e00\u4e2a\u57fa\u4e8e\u6269\u6563/\u6d41\u6a21\u578b\u7684\u97f3\u4e50\u58f0\u90e8\u751f\u6210\u6846\u67b6\uff0c\u80fd\u591f\u5355\u6b21\u63a8\u7406\u751f\u6210\u53ef\u53d8\u6570\u91cf\u7684\u540c\u6b65\u97f3\u4e50\u58f0\u90e8\uff0c\u89e3\u51b3\u4e86\u73b0\u6709\u65b9\u6cd5\u5728\u7075\u6d3b\u6027\u548c\u901f\u5ea6\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\u3002", "motivation": "\u73b0\u6709\u97f3\u4e50\u58f0\u90e8\u751f\u6210\u65b9\u6cd5\u8981\u4e48\u4f7f\u7528\u56fa\u5b9a\u67b6\u6784\u5e76\u884c\u8f93\u51fa\u9884\u5b9a\u4e49\u58f0\u90e8\uff0c\u8981\u4e48\u4e00\u6b21\u53ea\u751f\u6210\u4e00\u4e2a\u58f0\u90e8\u5bfc\u81f4\u63a8\u7406\u7f13\u6162\u3002\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u7075\u6d3b\u751f\u6210\u53ef\u53d8\u58f0\u90e8\u7ec4\u5408\uff0c\u53c8\u80fd\u4fdd\u6301\u9ad8\u6548\u63a8\u7406\u901f\u5ea6\u7684\u65b9\u6cd5\u3002", "method": "\u5c06\u6bcf\u4e2a\u58f0\u90e8\u89c6\u4e3a\u6279\u6b21\u5143\u7d20\uff0c\u5728\u8bad\u7ec3\u65f6\u5c06\u540c\u6b65\u58f0\u90e8\u5206\u7ec4\uff0c\u5bf9\u6bcf\u7ec4\u5e94\u7528\u5171\u4eab\u566a\u58f0\u6f5c\u5728\u53d8\u91cf\u3002\u63a8\u7406\u65f6\u4f7f\u7528\u5171\u4eab\u521d\u59cb\u566a\u58f0\u6f5c\u5728\u53d8\u91cf\u548c\u58f0\u90e8\u7279\u5b9a\u6587\u672c\u8f93\u5165\uff0c\u5355\u6b21\u751f\u6210\u540c\u6b65\u591a\u58f0\u90e8\u8f93\u51fa\u3002\u8fd8\u652f\u6301\u6761\u4ef6\u591a\u58f0\u90e8\u751f\u6210\u548c\u58f0\u90e8\u6d3b\u52a8\u63a7\u5236\u3002", "result": "\u5728\u591a\u4e2a\u5f00\u6e90\u58f0\u90e8\u8bc4\u4f30\u96c6\u4e0a\uff0cStemphonic\u751f\u6210\u66f4\u9ad8\u8d28\u91cf\u7684\u97f3\u9891\u8f93\u51fa\uff0c\u540c\u65f6\u5c06\u5b8c\u6574\u6df7\u97f3\u751f\u6210\u8fc7\u7a0b\u52a0\u901f25%\u523050%\u3002", "conclusion": "Stemphonic\u6846\u67b6\u6210\u529f\u89e3\u51b3\u4e86\u97f3\u4e50\u58f0\u90e8\u751f\u6210\u4e2d\u7075\u6d3b\u6027\u4e0e\u901f\u5ea6\u7684\u6743\u8861\u95ee\u9898\uff0c\u5b9e\u73b0\u4e86\u53ef\u53d8\u58f0\u90e8\u7ec4\u5408\u7684\u5355\u6b21\u63a8\u7406\u751f\u6210\uff0c\u4e3a\u7528\u6237\u63d0\u4f9b\u4e86\u66f4\u597d\u7684\u63a7\u5236\u548c\u66f4\u7b26\u5408\u97f3\u4e50\u5bb6\u5de5\u4f5c\u6d41\u7a0b\u7684\u4f53\u9a8c\u3002"}}
{"id": "2602.09157", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09157", "abs": "https://arxiv.org/abs/2602.09157", "authors": ["Mohammad Ghassemi", "Han Zhang", "Ali Afana", "Akram Bin Sediq", "Melike Erol-Kantarci"], "title": "Foundation Model-Aided Hierarchical Deep Reinforcement Learning for Blockage-Aware Link in RIS-Assisted Networks", "comment": "6 pages, 6 figures, ICC2026", "summary": "Reconfigurable intelligent surface (RIS) technology has the potential to significantly enhance the spectral efficiency (SE) of 6G wireless networks. However, practical deployment remains constrained by challenges in accurate channel estimation and control optimization under dynamic conditions. This paper presents a foundation model-aided hierarchical deep reinforcement learning (FM-HDRL) framework designed for joint beamforming and phase-shift optimization in RIS-assisted wireless networks. To implement this, we first fine-tune a pre-trained large wireless model (LWM) to translate raw channel data into low-dimensional, context-aware channel state information (CSI) embeddings. Next, these embeddings are combined with user location information and blockage status to select the optimal communication path. The resulting features are then fed into an HDRL model, assumed to be implemented at a centralized controller, which jointly optimizes the base station (BS) beamforming vectors and the RIS phase-shift configurations to maximize SE. Simulation results demonstrate that the proposed FM-HDRL framework consistently outperforms baseline methods in terms of convergence speed, spectral efficiency, and scalability. According to the simulation results, our proposed method improves 7.82% SE compared to the FM-aided deep reinforcement learning (FM-DRL) approach and a substantial enhancement of about 48.66% relative to the beam sweeping approach.", "AI": {"tldr": "\u63d0\u51faFM-HDRL\u6846\u67b6\uff0c\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u4e0e\u5206\u5c42\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff0c\u7528\u4e8eRIS\u8f85\u52a9\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u8054\u5408\u6ce2\u675f\u6210\u5f62\u548c\u76f8\u79fb\u4f18\u5316\uff0c\u663e\u8457\u63d0\u5347\u9891\u8c31\u6548\u7387\u3002", "motivation": "\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762(RIS)\u6280\u672f\u80fd\u663e\u8457\u63d0\u53476G\u7f51\u7edc\u7684\u9891\u8c31\u6548\u7387\uff0c\u4f46\u5b9e\u9645\u90e8\u7f72\u9762\u4e34\u52a8\u6001\u6761\u4ef6\u4e0b\u7cbe\u786e\u4fe1\u9053\u4f30\u8ba1\u548c\u63a7\u5236\u4f18\u5316\u7684\u6311\u6218\uff0c\u9700\u8981\u66f4\u6709\u6548\u7684\u4f18\u5316\u6846\u67b6\u3002", "method": "\u9996\u5148\u5fae\u8c03\u9884\u8bad\u7ec3\u7684\u5927\u578b\u65e0\u7ebf\u6a21\u578b(LWM)\uff0c\u5c06\u539f\u59cb\u4fe1\u9053\u6570\u636e\u8f6c\u6362\u4e3a\u4f4e\u7ef4\u3001\u4e0a\u4e0b\u6587\u611f\u77e5\u7684CSI\u5d4c\u5165\uff1b\u7ed3\u5408\u7528\u6237\u4f4d\u7f6e\u548c\u963b\u585e\u72b6\u6001\u9009\u62e9\u6700\u4f18\u901a\u4fe1\u8def\u5f84\uff1b\u7136\u540e\u5c06\u7279\u5f81\u8f93\u5165HDRL\u6a21\u578b\uff0c\u5728\u96c6\u4e2d\u63a7\u5236\u5668\u4e2d\u8054\u5408\u4f18\u5316\u57fa\u7ad9\u6ce2\u675f\u6210\u5f62\u5411\u91cf\u548cRIS\u76f8\u79fb\u914d\u7f6e\u4ee5\u6700\u5927\u5316\u9891\u8c31\u6548\u7387\u3002", "result": "\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0cFM-HDRL\u6846\u67b6\u5728\u6536\u655b\u901f\u5ea6\u3001\u9891\u8c31\u6548\u7387\u548c\u53ef\u6269\u5c55\u6027\u65b9\u9762\u5747\u4f18\u4e8e\u57fa\u7ebf\u65b9\u6cd5\uff0c\u76f8\u6bd4FM-DRL\u65b9\u6cd5\u63d0\u53477.82%\u9891\u8c31\u6548\u7387\uff0c\u76f8\u6bd4\u6ce2\u675f\u626b\u63cf\u65b9\u6cd5\u63d0\u5347\u7ea648.66%\u3002", "conclusion": "\u63d0\u51fa\u7684FM-HDRL\u6846\u67b6\u901a\u8fc7\u7ed3\u5408\u57fa\u7840\u6a21\u578b\u548c\u5206\u5c42\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff0c\u6709\u6548\u89e3\u51b3\u4e86RIS\u8f85\u52a9\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u8054\u5408\u4f18\u5316\u95ee\u9898\uff0c\u4e3a6G\u7f51\u7edc\u7684\u5b9e\u9645\u90e8\u7f72\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.09044", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.09044", "abs": "https://arxiv.org/abs/2602.09044", "authors": ["Robert Flynn", "Anton Ragni"], "title": "Beyond the Utterance: An Empirical Study of Very Long Context Speech Recognition", "comment": "Accepted to IEEE/ACM Transactions on Audio, Speech, and Language Processing (TASLP), 2026. doi: 10.1109/TASLPRO.2026.3658246", "summary": "Automatic speech recognition (ASR) models are normally trained to operate over single utterances, with a short duration of less than 30 seconds. This choice has been made in part due to computational constraints, but also reflects a common, but often inaccurate, modelling assumption that treats utterances as independent and identically distributed samples. When long-format audio recordings are available, to work with such systems, these recordings must first be segmented into short utterances and processed independently. In this work, we show that due to recent algorithmic and hardware advances, this is no longer necessary, and current attention-based approaches can be used to train ASR systems that operate on sequences of over an hour in length. Therefore, to gain a better understanding of the relationship between the training/evaluation sequence length and performance, we train ASR models on large-scale data using 10 different sequence lengths from 10 seconds up to 1 hour. The results show a benefit from using up to 21.8 minutes of context, with up to a 14.2% relative improvement from a short context baseline in our primary experiments. Through modifying various architectural components, we find that the method of encoding positional information and the model's width/depth are important factors when working with long sequences. Finally, a series of evaluations using synthetic data are constructed to help analyse the model's use of context. From these results, it is clear that both linguistic and acoustic aspects of the distant context are being used by the model.", "AI": {"tldr": "\u8be5\u7814\u7a76\u8868\u660e\uff0c\u901a\u8fc7\u7b97\u6cd5\u548c\u786c\u4ef6\u8fdb\u6b65\uff0c\u73b0\u5728\u53ef\u4ee5\u8bad\u7ec3\u5904\u7406\u8d85\u8fc71\u5c0f\u65f6\u957f\u5e8f\u5217\u7684ASR\u6a21\u578b\uff0c\u4f7f\u7528\u957f\u8fbe21.8\u5206\u949f\u7684\u4e0a\u4e0b\u6587\u53ef\u83b7\u5f9714.2%\u7684\u76f8\u5bf9\u6027\u80fd\u63d0\u5347\u3002", "motivation": "\u4f20\u7edfASR\u6a21\u578b\u901a\u5e38\u5904\u7406\u77ed\u4e8e30\u79d2\u7684\u5355\u4e2a\u8bdd\u8bed\uff0c\u8fd9\u57fa\u4e8e\u8ba1\u7b97\u9650\u5236\u548c\u8bdd\u8bed\u72ec\u7acb\u540c\u5206\u5e03\u7684\u5047\u8bbe\u3002\u5f53\u6709\u957f\u683c\u5f0f\u97f3\u9891\u65f6\uff0c\u9700\u8981\u5148\u5206\u5272\u518d\u5904\u7406\u3002\u672c\u7814\u7a76\u65e8\u5728\u63a2\u7d22\u662f\u5426\u53ef\u4ee5\u5229\u7528\u73b0\u4ee3\u6280\u672f\u76f4\u63a5\u5904\u7406\u957f\u5e8f\u5217\u97f3\u9891\u3002", "method": "\u4f7f\u7528\u57fa\u4e8e\u6ce8\u610f\u529b\u7684\u65b9\u6cd5\u8bad\u7ec3ASR\u7cfb\u7edf\uff0c\u5728\u5927\u89c4\u6a21\u6570\u636e\u4e0a\u6d4b\u8bd510\u79cd\u4e0d\u540c\u5e8f\u5217\u957f\u5ea6\uff08\u4ece10\u79d2\u52301\u5c0f\u65f6\uff09\u3002\u901a\u8fc7\u4fee\u6539\u4f4d\u7f6e\u7f16\u7801\u65b9\u5f0f\u548c\u6a21\u578b\u5bbd\u5ea6/\u6df1\u5ea6\u7b49\u67b6\u6784\u7ec4\u4ef6\uff0c\u5206\u6790\u957f\u5e8f\u5217\u5904\u7406\u7684\u5173\u952e\u56e0\u7d20\u3002\u8fd8\u4f7f\u7528\u5408\u6210\u6570\u636e\u8fdb\u884c\u8bc4\u4f30\u5206\u6790\u6a21\u578b\u5bf9\u4e0a\u4e0b\u6587\u7684\u4f7f\u7528\u3002", "result": "\u7ed3\u679c\u663e\u793a\uff0c\u4f7f\u7528\u957f\u8fbe21.8\u5206\u949f\u7684\u4e0a\u4e0b\u6587\u53ef\u83b7\u5f97\u6700\u4f73\u6027\u80fd\uff0c\u76f8\u6bd4\u77ed\u4e0a\u4e0b\u6587\u57fa\u7ebf\u670914.2%\u7684\u76f8\u5bf9\u6539\u8fdb\u3002\u4f4d\u7f6e\u7f16\u7801\u65b9\u6cd5\u548c\u6a21\u578b\u7684\u5bbd\u5ea6/\u6df1\u5ea6\u662f\u5904\u7406\u957f\u5e8f\u5217\u7684\u91cd\u8981\u56e0\u7d20\u3002\u5408\u6210\u6570\u636e\u8bc4\u4f30\u8868\u660e\u6a21\u578b\u540c\u65f6\u5229\u7528\u4e86\u8fdc\u8ddd\u79bb\u4e0a\u4e0b\u6587\u7684\u8bed\u8a00\u5b66\u548c\u58f0\u5b66\u4fe1\u606f\u3002", "conclusion": "\u7531\u4e8e\u7b97\u6cd5\u548c\u786c\u4ef6\u8fdb\u6b65\uff0c\u73b0\u5728\u53ef\u4ee5\u8bad\u7ec3\u5904\u7406\u8d85\u957f\u5e8f\u5217\u7684ASR\u6a21\u578b\u3002\u4f7f\u7528\u66f4\u957f\u4e0a\u4e0b\u6587\u80fd\u663e\u8457\u63d0\u5347\u6027\u80fd\uff0c\u4f4d\u7f6e\u7f16\u7801\u548c\u6a21\u578b\u67b6\u6784\u662f\u6210\u529f\u5904\u7406\u957f\u5e8f\u5217\u7684\u5173\u952e\u3002\u6a21\u578b\u80fd\u591f\u6709\u6548\u5229\u7528\u8fdc\u8ddd\u79bb\u7684\u4e0a\u4e0b\u6587\u4fe1\u606f\u3002"}}
{"id": "2602.10058", "categories": ["cs.SD", "cs.LG", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.10058", "abs": "https://arxiv.org/abs/2602.10058", "authors": ["Laura Ib\u00e1\u00f1ez-Mart\u00ednez", "Chukwuemeka Nkama", "Andrea Poltronieri", "Xavier Serra", "Mart\u00edn Rocamora"], "title": "Evaluating Disentangled Representations for Controllable Music Generation", "comment": "Accepted at ICASSP 2026", "summary": "Recent approaches in music generation rely on disentangled representations, often labeled as structure and timbre or local and global, to enable controllable synthesis. Yet the underlying properties of these embeddings remain underexplored. In this work, we evaluate such disentangled representations in a set of music audio models for controllable generation using a probing-based framework that goes beyond standard downstream tasks. The selected models reflect diverse unsupervised disentanglement strategies, including inductive biases, data augmentations, adversarial objectives, and staged training procedures. We further isolate specific strategies to analyze their effect. Our analysis spans four key axes: informativeness, equivariance, invariance, and disentanglement, which are assessed across datasets, tasks, and controlled transformations. Our findings reveal inconsistencies between intended and actual semantics of the embeddings, suggesting that current strategies fall short of producing truly disentangled representations, and prompting a re-examination of how controllability is approached in music generation.", "AI": {"tldr": "\u8be5\u7814\u7a76\u901a\u8fc7\u7cfb\u7edf\u8bc4\u4f30\u53d1\u73b0\uff0c\u5f53\u524d\u97f3\u4e50\u751f\u6210\u6a21\u578b\u4e2d\u7684\u89e3\u8026\u8868\u793a\u65b9\u6cd5\u672a\u80fd\u771f\u6b63\u5b9e\u73b0\u8bed\u4e49\u89e3\u8026\uff0c\u5d4c\u5165\u7684\u5b9e\u9645\u8bed\u4e49\u4e0e\u8bbe\u8ba1\u610f\u56fe\u5b58\u5728\u4e0d\u4e00\u81f4", "motivation": "\u5f53\u524d\u97f3\u4e50\u751f\u6210\u6a21\u578b\u4f9d\u8d56\u89e3\u8026\u8868\u793a\uff08\u5982\u7ed3\u6784/\u97f3\u8272\u3001\u5c40\u90e8/\u5168\u5c40\uff09\u6765\u5b9e\u73b0\u53ef\u63a7\u5408\u6210\uff0c\u4f46\u8fd9\u4e9b\u5d4c\u5165\u7684\u5e95\u5c42\u7279\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u63a2\u7d22\uff0c\u9700\u8981\u7cfb\u7edf\u8bc4\u4f30\u5176\u5b9e\u9645\u6548\u679c", "method": "\u91c7\u7528\u57fa\u4e8e\u63a2\u6d4b\u7684\u8bc4\u4f30\u6846\u67b6\uff0c\u8d85\u8d8a\u6807\u51c6\u4e0b\u6e38\u4efb\u52a1\uff0c\u9009\u62e9\u591a\u79cd\u65e0\u76d1\u7763\u89e3\u8026\u7b56\u7565\u6a21\u578b\uff08\u5f52\u7eb3\u504f\u7f6e\u3001\u6570\u636e\u589e\u5f3a\u3001\u5bf9\u6297\u76ee\u6807\u3001\u5206\u9636\u6bb5\u8bad\u7ec3\uff09\uff0c\u5728\u56db\u4e2a\u5173\u952e\u7ef4\u5ea6\uff08\u4fe1\u606f\u6027\u3001\u7b49\u53d8\u6027\u3001\u4e0d\u53d8\u6027\u3001\u89e3\u8026\u6027\uff09\u4e0a\u8fdb\u884c\u8de8\u6570\u636e\u96c6\u3001\u4efb\u52a1\u548c\u63a7\u5236\u53d8\u6362\u7684\u5206\u6790", "result": "\u7814\u7a76\u53d1\u73b0\u5d4c\u5165\u7684\u5b9e\u9645\u8bed\u4e49\u4e0e\u9884\u671f\u8bed\u4e49\u5b58\u5728\u4e0d\u4e00\u81f4\uff0c\u8868\u660e\u5f53\u524d\u7b56\u7565\u672a\u80fd\u4ea7\u751f\u771f\u6b63\u89e3\u8026\u7684\u8868\u793a\uff0c\u63ed\u793a\u4e86\u53ef\u63a7\u6027\u65b9\u6cd5\u7684\u5c40\u9650\u6027", "conclusion": "\u5f53\u524d\u97f3\u4e50\u751f\u6210\u4e2d\u7684\u89e3\u8026\u8868\u793a\u7b56\u7565\u5b58\u5728\u4e0d\u8db3\uff0c\u9700\u8981\u91cd\u65b0\u5ba1\u89c6\u53ef\u63a7\u6027\u65b9\u6cd5\uff0c\u4ee5\u66f4\u51c6\u786e\u5730\u5b9e\u73b0\u8bed\u4e49\u89e3\u8026\u548c\u53ef\u63a7\u5408\u6210"}}
{"id": "2602.09191", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09191", "abs": "https://arxiv.org/abs/2602.09191", "authors": ["Hung Nguyen-Kha", "Vu Nguyen Ha", "Ti Nguyen", "Eva Lagunas", "Joel Grotz", "Symeon Chatzinotas", "Bj\u00f6rn Ottersten"], "title": "Digital-Twin-Aided Dynamic Spectrum Sharing and Resource Management in Integrated Satellite-Terrestrial Networks", "comment": "Submitted to IEEE Transactions on Wireless Communications", "summary": "The explosive growth in wireless service demand has prompted the evolution of integrated satellite-terrestrial networks (ISTNs) to overcome the limitations of traditional terrestrial networks (TNs) in terms of coverage, spectrum efficiency, and deployment cost. Particularly, leveraging LEO satellites and dynamic spectrum sharing (DSS), ISTNs offer promising solutions but face significant challenges due to diverse terrestrial environments, user and satellite mobility, and long propagation LEO-to-ground distance. To address these challenges, digitial-twin (DT) has emerged as a promising technology to offer virtual replicas of real-world systems, facilitating prediction for resource management. In this work, we study a time-window-based DT-aided DSS framework for ISTNs, enabling joint long-term and short-term resource decisions to reduce system congestion. Based on that, two optimization problems are formulated, which aim to optimize resource management using DT information and to refine obtained solutions with actual real-time information, respectively. To efficiently solve these problems, we proposed algorithms using compressed-sensing-based and successive convex approximation techniques. Simulation results using actual traffic data and the London 3D map demonstrate the superiority in terms of congestion minimization of our proposed algorithms compared to benchmarks. Additionally, it shows the adaptation ability and practical feasibility of our proposed solutions.", "AI": {"tldr": "\u672c\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u6570\u5b57\u5b6a\u751f(DT)\u7684\u52a8\u6001\u9891\u8c31\u5171\u4eab\u6846\u67b6\uff0c\u7528\u4e8e\u96c6\u6210\u536b\u661f-\u5730\u9762\u7f51\u7edc(ISTN)\uff0c\u901a\u8fc7\u8054\u5408\u957f\u77ed\u671f\u8d44\u6e90\u51b3\u7b56\u6765\u51cf\u5c11\u7cfb\u7edf\u62e5\u585e\uff0c\u5e76\u8bbe\u8ba1\u4e86\u538b\u7f29\u611f\u77e5\u548c\u9010\u6b21\u51f8\u903c\u8fd1\u7b97\u6cd5\u6765\u4f18\u5316\u8d44\u6e90\u7ba1\u7406\u3002", "motivation": "\u65e0\u7ebf\u670d\u52a1\u9700\u6c42\u7206\u70b8\u5f0f\u589e\u957f\u4fc3\u4f7f\u96c6\u6210\u536b\u661f-\u5730\u9762\u7f51\u7edc(ISTN)\u53d1\u5c55\uff0c\u4ee5\u514b\u670d\u4f20\u7edf\u5730\u9762\u7f51\u7edc\u5728\u8986\u76d6\u8303\u56f4\u3001\u9891\u8c31\u6548\u7387\u548c\u90e8\u7f72\u6210\u672c\u65b9\u9762\u7684\u9650\u5236\u3002\u7136\u800c\uff0cISTN\u9762\u4e34\u591a\u6837\u5316\u5730\u9762\u73af\u5883\u3001\u7528\u6237\u548c\u536b\u661f\u79fb\u52a8\u6027\u4ee5\u53ca\u957f\u4f20\u64ad\u8ddd\u79bb\u7b49\u6311\u6218\uff0c\u9700\u8981\u6709\u6548\u7684\u8d44\u6e90\u7ba1\u7406\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u57fa\u4e8e\u65f6\u95f4\u7a97\u53e3\u7684\u6570\u5b57\u5b6a\u751f\u8f85\u52a9\u52a8\u6001\u9891\u8c31\u5171\u4eab\u6846\u67b6\uff0c\u5efa\u7acb\u4e24\u4e2a\u4f18\u5316\u95ee\u9898\uff1a1)\u5229\u7528DT\u4fe1\u606f\u4f18\u5316\u8d44\u6e90\u7ba1\u7406\uff1b2)\u5229\u7528\u5b9e\u9645\u5b9e\u65f6\u4fe1\u606f\u7ec6\u5316\u89e3\u51b3\u65b9\u6848\u3002\u91c7\u7528\u57fa\u4e8e\u538b\u7f29\u611f\u77e5\u548c\u9010\u6b21\u51f8\u903c\u8fd1\u7684\u7b97\u6cd5\u9ad8\u6548\u6c42\u89e3\u8fd9\u4e9b\u95ee\u9898\u3002", "result": "\u4f7f\u7528\u5b9e\u9645\u6d41\u91cf\u6570\u636e\u548c\u4f26\u65663D\u5730\u56fe\u7684\u4eff\u771f\u7ed3\u679c\u8868\u660e\uff0c\u6240\u63d0\u7b97\u6cd5\u5728\u62e5\u585e\u6700\u5c0f\u5316\u65b9\u9762\u4f18\u4e8e\u57fa\u51c6\u65b9\u6cd5\uff0c\u540c\u65f6\u5c55\u793a\u4e86\u89e3\u51b3\u65b9\u6848\u7684\u9002\u5e94\u80fd\u529b\u548c\u5b9e\u9645\u53ef\u884c\u6027\u3002", "conclusion": "\u6570\u5b57\u5b6a\u751f\u8f85\u52a9\u7684\u52a8\u6001\u9891\u8c31\u5171\u4eab\u6846\u67b6\u80fd\u6709\u6548\u89e3\u51b3\u96c6\u6210\u536b\u661f-\u5730\u9762\u7f51\u7edc\u7684\u8d44\u6e90\u7ba1\u7406\u6311\u6218\uff0c\u63d0\u51fa\u7684\u7b97\u6cd5\u5728\u51cf\u5c11\u7cfb\u7edf\u62e5\u585e\u65b9\u9762\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u5e76\u5177\u5907\u5b9e\u9645\u90e8\u7f72\u7684\u53ef\u884c\u6027\u3002"}}
{"id": "2602.09321", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.09321", "abs": "https://arxiv.org/abs/2602.09321", "authors": ["Parinaz Binandeh Dehaghania", "Danilo Penab", "A. Pedro Aguiar"], "title": "Performance Comparison of CNN and AST Models with Stacked Features for Environmental Sound Classification", "comment": "7 pages, 1 figure", "summary": "Environmental sound classification (ESC) has gained significant attention due to its diverse applications in smart city monitoring, fault detection, acoustic surveillance, and manufacturing quality control. To enhance CNN performance, feature stacking techniques have been explored to aggregate complementary acoustic descriptors into richer input representations. In this paper, we investigate CNN-based models employing various stacked feature combinations, including Log-Mel Spectrogram (LM), Spectral Contrast (SPC), Chroma (CH), Tonnetz (TZ), Mel-Frequency Cepstral Coefficients (MFCCs), and Gammatone Cepstral Coefficients (GTCC). Experiments are conducted on the widely used ESC-50 and UrbanSound8K datasets under different training regimes, including pretraining on ESC-50, fine-tuning on UrbanSound8K, and comparison with Audio Spectrogram Transformer (AST) models pretrained on large-scale corpora such as AudioSet. This experimental design enables an analysis of how feature-stacked CNNs compare with transformer-based models under varying levels of training data and pretraining diversity. The results indicate that feature-stacked CNNs offer a more computationally and data-efficient alternative when large-scale pretraining or extensive training data are unavailable, making them particularly well suited for resource-constrained and edge-level sound classification scenarios.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7814\u7a76\u4e86\u73af\u5883\u58f0\u97f3\u5206\u7c7b\u4e2d\u7279\u5f81\u5806\u53e0CNN\u4e0eTransformer\u6a21\u578b\u7684\u6bd4\u8f83\uff0c\u53d1\u73b0\u7279\u5f81\u5806\u53e0CNN\u5728\u8ba1\u7b97\u548c\u6570\u636e\u6548\u7387\u65b9\u9762\u66f4\u5177\u4f18\u52bf\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u8fb9\u7f18\u8ba1\u7b97\u573a\u666f\u3002", "motivation": "\u73af\u5883\u58f0\u97f3\u5206\u7c7b\u5728\u667a\u6167\u57ce\u5e02\u76d1\u63a7\u3001\u6545\u969c\u68c0\u6d4b\u7b49\u9886\u57df\u6709\u5e7f\u6cdb\u5e94\u7528\u3002\u867d\u7136CNN\u6027\u80fd\u826f\u597d\uff0c\u4f46\u9700\u8981\u63a2\u7d22\u7279\u5f81\u5806\u53e0\u6280\u672f\u6765\u805a\u5408\u4e92\u8865\u7684\u58f0\u5b66\u63cf\u8ff0\u7b26\uff0c\u4ee5\u63d0\u5347\u8f93\u5165\u8868\u793a\u7684\u8d28\u91cf\u3002\u540c\u65f6\u9700\u8981\u6bd4\u8f83\u7279\u5f81\u5806\u53e0CNN\u4e0e\u57fa\u4e8eTransformer\u7684\u6a21\u578b\u5728\u4e0d\u540c\u8bad\u7ec3\u6570\u636e\u91cf\u4e0b\u7684\u8868\u73b0\u3002", "method": "\u7814\u7a76\u91c7\u7528\u57fa\u4e8eCNN\u7684\u6a21\u578b\uff0c\u4f7f\u7528\u591a\u79cd\u5806\u53e0\u7279\u5f81\u7ec4\u5408\uff1aLog-Mel\u8c31\u56fe\u3001\u9891\u8c31\u5bf9\u6bd4\u5ea6\u3001\u8272\u5ea6\u7279\u5f81\u3001Tonnetz\u3001MFCC\u548cGammatone\u5012\u8c31\u7cfb\u6570\u3002\u5728ESC-50\u548cUrbanSound8K\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u5b9e\u9a8c\uff0c\u91c7\u7528\u4e0d\u540c\u8bad\u7ec3\u7b56\u7565\uff1a\u5728ESC-50\u4e0a\u9884\u8bad\u7ec3\u3001\u5728UrbanSound8K\u4e0a\u5fae\u8c03\uff0c\u5e76\u4e0e\u5728AudioSet\u7b49\u5927\u89c4\u6a21\u8bed\u6599\u5e93\u4e0a\u9884\u8bad\u7ec3\u7684Audio Spectrogram Transformer\u6a21\u578b\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u7279\u5f81\u5806\u53e0CNN\u5728\u8ba1\u7b97\u548c\u6570\u636e\u6548\u7387\u65b9\u9762\u4f18\u4e8eTransformer\u6a21\u578b\uff0c\u7279\u522b\u662f\u5728\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6216\u5927\u91cf\u8bad\u7ec3\u6570\u636e\u4e0d\u53ef\u7528\u7684\u60c5\u51b5\u4e0b\u3002\u7279\u5f81\u5806\u53e0CNN\u4e3a\u8d44\u6e90\u53d7\u9650\u548c\u8fb9\u7f18\u7ea7\u58f0\u97f3\u5206\u7c7b\u573a\u666f\u63d0\u4f9b\u4e86\u66f4\u5408\u9002\u7684\u89e3\u51b3\u65b9\u6848\u3002", "conclusion": "\u7279\u5f81\u5806\u53e0CNN\u4e3a\u73af\u5883\u58f0\u97f3\u5206\u7c7b\u63d0\u4f9b\u4e86\u4e00\u4e2a\u8ba1\u7b97\u548c\u6570\u636e\u6548\u7387\u66f4\u9ad8\u7684\u66ff\u4ee3\u65b9\u6848\uff0c\u7279\u522b\u9002\u5408\u7f3a\u4e4f\u5927\u89c4\u6a21\u9884\u8bad\u7ec3\u6570\u636e\u6216\u8ba1\u7b97\u8d44\u6e90\u7684\u5e94\u7528\u573a\u666f\uff0c\u5728\u8fb9\u7f18\u8ba1\u7b97\u548c\u8d44\u6e90\u53d7\u9650\u73af\u5883\u4e2d\u5177\u6709\u5b9e\u7528\u4ef7\u503c\u3002"}}
{"id": "2602.09210", "categories": ["eess.SP", "cs.SD", "eess.AS"], "pdf": "https://arxiv.org/pdf/2602.09210", "abs": "https://arxiv.org/abs/2602.09210", "authors": ["Yasaman Torabi"], "title": "AI-Driven Cardiorespiratory Signal Processing: Separation, Clustering, and Anomaly Detection", "comment": "PhD thesis", "summary": "This research applies artificial intelligence (AI) to separate, cluster, and analyze cardiorespiratory sounds. We recorded a new dataset (HLS-CMDS) and developed several AI models, including generative AI methods based on large language models (LLMs) for guided separation, explainable AI (XAI) techniques to interpret latent representations, variational autoencoders (VAEs) for waveform separation, a chemistry-inspired non-negative matrix factorization (NMF) algorithm for clustering, and a quantum convolutional neural network (QCNN) designed to detect abnormal physiological patterns. The performance of these AI models depends on the quality of the recorded signals. Therefore, this thesis also reviews the biosensing technologies used to capture biomedical data. It summarizes developments in microelectromechanical systems (MEMS) acoustic sensors and quantum biosensors, such as quantum dots and nitrogen-vacancy centers. It further outlines the transition from electronic integrated circuits (EICs) to photonic integrated circuits (PICs) and early progress toward integrated quantum photonics (IQP) for chip-based biosensing. Together, these studies show how AI and next-generation sensors can support more intelligent diagnostic systems for future healthcare.", "AI": {"tldr": "\u8be5\u7814\u7a76\u5e94\u7528\u591a\u79cdAI\u6280\u672f\u5206\u6790\u5fc3\u80ba\u97f3\uff0c\u5305\u62ec\u751f\u6210\u5f0fAI\u3001\u53ef\u89e3\u91caAI\u3001\u53d8\u5206\u81ea\u7f16\u7801\u5668\u3001\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u548c\u91cf\u5b50\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u540c\u65f6\u56de\u987e\u4e86\u751f\u7269\u4f20\u611f\u6280\u672f\u53d1\u5c55\uff0c\u5c55\u793a\u4e86AI\u4e0e\u65b0\u4e00\u4ee3\u4f20\u611f\u5668\u5982\u4f55\u652f\u6301\u672a\u6765\u533b\u7597\u7684\u667a\u80fd\u8bca\u65ad\u7cfb\u7edf\u3002", "motivation": "\u5f00\u53d1\u66f4\u667a\u80fd\u7684\u5fc3\u80ba\u97f3\u8bca\u65ad\u7cfb\u7edf\uff0c\u7ed3\u5408\u5148\u8fdbAI\u6280\u672f\u548c\u4e0b\u4e00\u4ee3\u751f\u7269\u4f20\u611f\u6280\u672f\uff0c\u63d0\u9ad8\u5fc3\u80ba\u75be\u75c5\u7684\u68c0\u6d4b\u548c\u5206\u6790\u80fd\u529b\u3002", "method": "1. \u6536\u96c6\u65b0\u6570\u636e\u96c6HLS-CMDS\uff1b2. \u5f00\u53d1\u591a\u79cdAI\u6a21\u578b\uff1a\u57fa\u4e8e\u5927\u8bed\u8a00\u6a21\u578b\u7684\u751f\u6210\u5f0fAI\u7528\u4e8e\u5f15\u5bfc\u5206\u79bb\u3001\u53ef\u89e3\u91caAI\u6280\u672f\u89e3\u91ca\u6f5c\u5728\u8868\u793a\u3001\u53d8\u5206\u81ea\u7f16\u7801\u5668\u7528\u4e8e\u6ce2\u5f62\u5206\u79bb\u3001\u5316\u5b66\u542f\u53d1\u7684\u975e\u8d1f\u77e9\u9635\u5206\u89e3\u7b97\u6cd5\u7528\u4e8e\u805a\u7c7b\u3001\u91cf\u5b50\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\u68c0\u6d4b\u5f02\u5e38\u751f\u7406\u6a21\u5f0f\uff1b3. \u56de\u987e\u751f\u7269\u4f20\u611f\u6280\u672f\uff1aMEMS\u58f0\u5b66\u4f20\u611f\u5668\u3001\u91cf\u5b50\u751f\u7269\u4f20\u611f\u5668\u3001\u4ece\u7535\u5b50\u96c6\u6210\u7535\u8def\u5230\u5149\u5b50\u96c6\u6210\u7535\u8def\u7684\u8fc7\u6e21\u3001\u96c6\u6210\u91cf\u5b50\u5149\u5b50\u5b66\u8fdb\u5c55\u3002", "result": "\u5c55\u793a\u4e86\u591a\u79cdAI\u6a21\u578b\u5728\u5fc3\u80ba\u97f3\u5206\u6790\u4e2d\u7684\u5e94\u7528\u6f5c\u529b\uff0c\u5f3a\u8c03\u4e86\u4fe1\u53f7\u8d28\u91cf\u5bf9AI\u6027\u80fd\u7684\u91cd\u8981\u6027\uff0c\u603b\u7ed3\u4e86\u751f\u7269\u4f20\u611f\u6280\u672f\u7684\u6700\u65b0\u53d1\u5c55\uff0c\u4e3a\u672a\u6765\u667a\u80fd\u8bca\u65ad\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6280\u672f\u57fa\u7840\u3002", "conclusion": "AI\u6280\u672f\u4e0e\u4e0b\u4e00\u4ee3\u751f\u7269\u4f20\u611f\u6280\u672f\u7684\u7ed3\u5408\u80fd\u591f\u652f\u6301\u66f4\u667a\u80fd\u7684\u533b\u7597\u8bca\u65ad\u7cfb\u7edf\uff0c\u4e3a\u672a\u6765\u533b\u7597\u4fdd\u5065\u63d0\u4f9b\u65b0\u7684\u6280\u672f\u8def\u5f84\u3002"}}
{"id": "2602.09389", "categories": ["eess.AS", "cs.CL", "cs.LG", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.09389", "abs": "https://arxiv.org/abs/2602.09389", "authors": ["Waris Quamer", "Mu-Ruei Tseng", "Ghady Nasrallah", "Ricardo Gutierrez-Osuna"], "title": "TVTSyn: Content-Synchronous Time-Varying Timbre for Streaming Voice Conversion and Anonymization", "comment": null, "summary": "Real-time voice conversion and speaker anonymization require causal, low-latency synthesis without sacrificing intelligibility or naturalness. Current systems have a core representational mismatch: content is time-varying, while speaker identity is injected as a static global embedding. We introduce a streamable speech synthesizer that aligns the temporal granularity of identity and content via a content-synchronous, time-varying timbre (TVT) representation. A Global Timbre Memory expands a global timbre instance into multiple compact facets; frame-level content attends to this memory, a gate regulates variation, and spherical interpolation preserves identity geometry while enabling smooth local changes. In addition, a factorized vector-quantized bottleneck regularizes content to reduce residual speaker leakage. The resulting system is streamable end-to-end, with <80 ms GPU latency. Experiments show improvements in naturalness, speaker transfer, and anonymization compared to SOTA streaming baselines, establishing TVT as a scalable approach for privacy-preserving and expressive speech synthesis under strict latency budgets.", "AI": {"tldr": "\u63d0\u51faTVT\uff08\u65f6\u53d8\u97f3\u8272\uff09\u8868\u793a\u6cd5\uff0c\u901a\u8fc7\u5185\u5bb9\u540c\u6b65\u7684\u97f3\u8272\u53d8\u5316\u5b9e\u73b0\u53ef\u6d41\u5f0f\u8bed\u97f3\u5408\u6210\uff0c\u5728<80ms\u5ef6\u8fdf\u4e0b\u63d0\u5347\u81ea\u7136\u5ea6\u3001\u8bf4\u8bdd\u4eba\u8f6c\u6362\u548c\u533f\u540d\u5316\u6548\u679c", "motivation": "\u5b9e\u65f6\u8bed\u97f3\u8f6c\u6362\u548c\u8bf4\u8bdd\u4eba\u533f\u540d\u5316\u9700\u8981\u56e0\u679c\u3001\u4f4e\u5ef6\u8fdf\u7684\u5408\u6210\u7cfb\u7edf\uff0c\u4f46\u73b0\u6709\u7cfb\u7edf\u5b58\u5728\u8868\u793a\u4e0d\u5339\u914d\u95ee\u9898\uff1a\u5185\u5bb9\u662f\u65f6\u53d8\u7684\uff0c\u800c\u8bf4\u8bdd\u4eba\u8eab\u4efd\u5374\u4f5c\u4e3a\u9759\u6001\u5168\u5c40\u5d4c\u5165\u6ce8\u5165", "method": "\u5f15\u5165\u53ef\u6d41\u5f0f\u8bed\u97f3\u5408\u6210\u5668\uff0c\u901a\u8fc7\u5185\u5bb9\u540c\u6b65\u7684\u65f6\u53d8\u97f3\u8272\uff08TVT\uff09\u8868\u793a\u5bf9\u9f50\u8eab\u4efd\u548c\u5185\u5bb9\u7684\u65f6\u95f4\u7c92\u5ea6\u3002\u4f7f\u7528\u5168\u5c40\u97f3\u8272\u8bb0\u5fc6\u5c06\u5168\u5c40\u97f3\u8272\u5b9e\u4f8b\u6269\u5c55\u4e3a\u591a\u4e2a\u7d27\u51d1\u65b9\u9762\uff0c\u5e27\u7ea7\u5185\u5bb9\u5173\u6ce8\u8be5\u8bb0\u5fc6\uff0c\u95e8\u63a7\u8c03\u8282\u53d8\u5316\uff0c\u7403\u9762\u63d2\u503c\u4fdd\u6301\u8eab\u4efd\u51e0\u4f55\u540c\u65f6\u5b9e\u73b0\u5e73\u6ed1\u5c40\u90e8\u53d8\u5316\u3002\u6b64\u5916\uff0c\u4f7f\u7528\u56e0\u5b50\u5316\u5411\u91cf\u91cf\u5316\u74f6\u9888\u6b63\u5219\u5316\u5185\u5bb9\u4ee5\u51cf\u5c11\u6b8b\u7559\u8bf4\u8bdd\u4eba\u6cc4\u6f0f", "result": "\u7cfb\u7edf\u53ef\u5b9e\u73b0\u7aef\u5230\u7aef\u6d41\u5f0f\u5904\u7406\uff0cGPU\u5ef6\u8fdf<80ms\u3002\u5b9e\u9a8c\u663e\u793a\u5728\u81ea\u7136\u5ea6\u3001\u8bf4\u8bdd\u4eba\u8f6c\u6362\u548c\u533f\u540d\u5316\u65b9\u9762\u4f18\u4e8e\u6700\u5148\u8fdb\u7684\u6d41\u5f0f\u57fa\u7ebf\u65b9\u6cd5", "conclusion": "TVT\u662f\u4e00\u79cd\u53ef\u6269\u5c55\u7684\u65b9\u6cd5\uff0c\u53ef\u5728\u4e25\u683c\u5ef6\u8fdf\u9884\u7b97\u4e0b\u5b9e\u73b0\u9690\u79c1\u4fdd\u62a4\u548c\u5bcc\u6709\u8868\u73b0\u529b\u7684\u8bed\u97f3\u5408\u6210"}}
{"id": "2602.09419", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09419", "abs": "https://arxiv.org/abs/2602.09419", "authors": ["Muhammad Asif", "Asim Ihsan", "Zhongliang Wang", "Manzoor Ahmed", "Xingwang Li", "Arumugam Nallanathan", "Symeon Chatzinotas"], "title": "When Movable Antennas Meet RSMA and RIS: Robust Beamforming Design With Channel Uncertainty", "comment": "12 pages, and 10 figures. Submitted to IEEE", "summary": "In this work, we propose an intelligent optimization framework for a multi-user communication system integrating movable antennas (MAs) and a reconfigurable intelligent surface (RIS) under the rate-splitting multiple access (RSMA) protocol. The system sum-rate is maximized through joint optimization of transmit precoding vectors, RIS reflection matrix, common-rate allocation, and MA positions, subject to quality-of-service (QoS), power-budget, common-rate decoding, and mutual coupling constraints. Imperfect channel state information (CSI) is considered for all links, where robustness is ensured by modeling channel estimation errors within a bounded uncertainty region, guaranteeing worst-case performance reliability. The resulting non-convex problem is solved using an alternating optimization framework. The precoding subproblem is reformulated as a semidefinite programming (SDP) problem via linear matrix inequalities derived using the S-procedure. The RIS reflection matrix is optimized using successive convex approximation (SCA), yielding an equivalent SDP formulation. The MA position optimization is addressed through SCA combined with block coordinate descent (BCD) method. Numerical results validate the effectiveness of the proposed framework and demonstrate fast convergence.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u96c6\u6210\u53ef\u79fb\u52a8\u5929\u7ebf\u548c\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u7684\u591a\u7528\u6237\u901a\u4fe1\u7cfb\u7edf\u667a\u80fd\u4f18\u5316\u6846\u67b6\uff0c\u5728RSMA\u534f\u8bae\u4e0b\u901a\u8fc7\u8054\u5408\u4f18\u5316\u53d1\u5c04\u9884\u7f16\u7801\u3001RIS\u53cd\u5c04\u77e9\u9635\u3001\u516c\u5171\u901f\u7387\u5206\u914d\u548cMA\u4f4d\u7f6e\u6765\u6700\u5927\u5316\u7cfb\u7edf\u548c\u901f\u7387\uff0c\u8003\u8651\u4e0d\u5b8c\u7f8eCSI\u548c\u4e92\u8026\u7ea6\u675f\u3002", "motivation": "\u4e3a\u4e86\u63d0\u5347\u591a\u7528\u6237\u901a\u4fe1\u7cfb\u7edf\u7684\u6027\u80fd\uff0c\u9700\u8981\u5145\u5206\u5229\u7528\u53ef\u79fb\u52a8\u5929\u7ebf\u548c\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u7684\u534f\u540c\u4f18\u52bf\uff0c\u5728RSMA\u534f\u8bae\u4e0b\u5b9e\u73b0\u66f4\u9ad8\u6548\u7684\u8d44\u6e90\u5206\u914d\uff0c\u540c\u65f6\u8003\u8651\u5b9e\u9645\u7cfb\u7edf\u4e2d\u7684\u4fe1\u9053\u4e0d\u786e\u5b9a\u6027\u7ea6\u675f\u3002", "method": "\u91c7\u7528\u4ea4\u66ff\u4f18\u5316\u6846\u67b6\u89e3\u51b3\u975e\u51f8\u95ee\u9898\uff1a1) \u9884\u7f16\u7801\u5b50\u95ee\u9898\u901a\u8fc7S-procedure\u8f6c\u5316\u4e3a\u534a\u5b9a\u89c4\u5212\u95ee\u9898\uff1b2) RIS\u53cd\u5c04\u77e9\u9635\u4f18\u5316\u4f7f\u7528\u9010\u6b21\u51f8\u903c\u8fd1\u65b9\u6cd5\uff1b3) MA\u4f4d\u7f6e\u4f18\u5316\u7ed3\u5408\u9010\u6b21\u51f8\u903c\u8fd1\u548c\u5757\u5750\u6807\u4e0b\u964d\u6cd5\u3002", "result": "\u6570\u503c\u7ed3\u679c\u9a8c\u8bc1\u4e86\u6240\u63d0\u6846\u67b6\u7684\u6709\u6548\u6027\uff0c\u5e76\u5c55\u793a\u4e86\u5feb\u901f\u6536\u655b\u7279\u6027\uff0c\u8868\u660e\u8be5\u65b9\u6848\u80fd\u591f\u5728\u8003\u8651\u4e0d\u5b8c\u7f8eCSI\u548c\u4e92\u8026\u7ea6\u675f\u7684\u60c5\u51b5\u4e0b\u5b9e\u73b0\u7cfb\u7edf\u548c\u901f\u7387\u6700\u5927\u5316\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u51fa\u4e86\u4e00\u4e2a\u9c81\u68d2\u7684\u4f18\u5316\u6846\u67b6\uff0c\u6210\u529f\u89e3\u51b3\u4e86MA-RIS-RSMA\u7cfb\u7edf\u4e2d\u7684\u8054\u5408\u8d44\u6e90\u5206\u914d\u95ee\u9898\uff0c\u4e3a\u672a\u6765\u667a\u80fd\u901a\u4fe1\u7cfb\u7edf\u8bbe\u8ba1\u63d0\u4f9b\u4e86\u6709\u6548\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.09594", "categories": ["eess.AS", "cs.CE", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.09594", "abs": "https://arxiv.org/abs/2602.09594", "authors": ["Matteo Calaf\u00e0", "Yuanxin Xia", "Jonas Brunskog", "Cheol-Ho Jeong"], "title": "Evaluation of acoustic Green's function in rectangular rooms with general surface impedance walls", "comment": null, "summary": "Acoustic room modes and the Green's function mode expansion are well-known for rectangular rooms with perfectly reflecting walls. First-order approximations also exist for nearly rigid boundaries; however, current analytical methods fail to accommodate more general boundary conditions, e.g., when wall absorption is significant. In this work, we present a comprehensive analysis that extends previous studies by including additional first-order asymptotics that account for soft-wall boundaries. In addition, we introduce a semi-analytical, efficient, and reliable method for computing the Green's function in rectangular rooms, which is described and validated through numerical tests. With a sufficiently large truncation order, the resulting error becomes negligible, making the method suitable as a benchmark for numerical simulations. Additional aspects regarding the spectral basis orthogonality and completeness are also addressed, providing a general framework for the validity of the proposed approach.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u534a\u89e3\u6790\u65b9\u6cd5\u8ba1\u7b97\u77e9\u5f62\u623f\u95f4\u683c\u6797\u51fd\u6570\uff0c\u9002\u7528\u4e8e\u4e00\u822c\u8fb9\u754c\u6761\u4ef6\uff08\u5305\u62ec\u8f6f\u58c1\uff09\uff0c\u901a\u8fc7\u9ad8\u9636\u622a\u65ad\u5b9e\u73b0\u53ef\u5ffd\u7565\u8bef\u5dee\uff0c\u53ef\u4f5c\u4e3a\u6570\u503c\u6a21\u62df\u57fa\u51c6\u3002", "motivation": "\u73b0\u6709\u5206\u6790\u65b9\u6cd5\u4ec5\u9002\u7528\u4e8e\u5b8c\u7f8e\u53cd\u5c04\u6216\u8fd1\u4f3c\u521a\u6027\u8fb9\u754c\uff0c\u65e0\u6cd5\u5904\u7406\u5438\u6536\u663e\u8457\u7684\u4e00\u822c\u8fb9\u754c\u6761\u4ef6\uff08\u5982\u8f6f\u58c1\uff09\uff0c\u9700\u8981\u66f4\u901a\u7528\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u6269\u5c55\u4e00\u9636\u6e10\u8fd1\u5206\u6790\u4ee5\u5305\u542b\u8f6f\u58c1\u8fb9\u754c\uff0c\u63d0\u51fa\u534a\u89e3\u6790\u3001\u9ad8\u6548\u53ef\u9760\u7684\u683c\u6797\u51fd\u6570\u8ba1\u7b97\u65b9\u6cd5\uff0c\u901a\u8fc7\u6570\u503c\u6d4b\u8bd5\u9a8c\u8bc1\uff0c\u5e76\u8ba8\u8bba\u8c31\u57fa\u6b63\u4ea4\u6027\u548c\u5b8c\u5907\u6027\u3002", "result": "\u65b9\u6cd5\u5728\u8db3\u591f\u5927\u622a\u65ad\u9636\u6570\u4e0b\u8bef\u5dee\u53ef\u5ffd\u7565\uff0c\u9002\u5408\u4f5c\u4e3a\u6570\u503c\u6a21\u62df\u57fa\u51c6\uff0c\u5efa\u7acb\u4e86\u5904\u7406\u4e00\u822c\u8fb9\u754c\u6761\u4ef6\u7684\u901a\u7528\u6846\u67b6\u3002", "conclusion": "\u8be5\u7814\u7a76\u63d0\u4f9b\u4e86\u5904\u7406\u77e9\u5f62\u623f\u95f4\u4e00\u822c\u8fb9\u754c\u6761\u4ef6\u7684\u7efc\u5408\u5206\u6790\u65b9\u6cd5\uff0c\u63d0\u51fa\u7684\u534a\u89e3\u6790\u65b9\u6cd5\u65e2\u9ad8\u6548\u53c8\u53ef\u9760\uff0c\u4e3a\u58f0\u5b66\u6a21\u62df\u63d0\u4f9b\u4e86\u6709\u4ef7\u503c\u7684\u57fa\u51c6\u5de5\u5177\u3002"}}
{"id": "2602.09450", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09450", "abs": "https://arxiv.org/abs/2602.09450", "authors": ["Shobha Sundar Ram", "Akanksha Sneh"], "title": "Orthogonal Circular Polarized Transmitter and Receiver Antennas for Mitigation of Mutual Coupling in Monostatic Radars", "comment": null, "summary": "Through-wall radar systems require compact, wideband and high gain antennas for detecting targets. Building walls introduce considerable attenuation on the radar signals. When the transmitted power is raised to compensate the through-wall attenuation, the direct coupling between the transmitter and receiver can saturate the receiver because of which weaker reflections off the target may remain undetected. In this paper, we propose using transmitter and receiver antennas of orthogonal circular polarization to reduce the direct coupling between the transmitter and receiver while retaining the first bounce off the target. In our paper, we demonstrate that the quadrafilar helical antenna (QHA) is a good candidate for this operation since it is characterized by a small size, wide frequency band of operation, high gain and low axial ratio over a wide field of view. We compare the reduced mutual coupling between the transmitter and receiver elements for the oppositely polarized QHA antennas with other commonly used through-wall radar antennas such as the Vivaldi and horn antennas. The system is tested in through-wall conditions.", "AI": {"tldr": "\u8be5\u8bba\u6587\u63d0\u51fa\u4f7f\u7528\u6b63\u4ea4\u5706\u6781\u5316\u7684\u56db\u81c2\u87ba\u65cb\u5929\u7ebf\u6765\u51cf\u5c11\u7a7f\u5899\u96f7\u8fbe\u4e2d\u53d1\u5c04\u673a\u548c\u63a5\u6536\u673a\u4e4b\u95f4\u7684\u76f4\u63a5\u8026\u5408\uff0c\u540c\u65f6\u4fdd\u7559\u76ee\u6807\u7684\u4e00\u6b21\u53cd\u5c04\u4fe1\u53f7\u3002", "motivation": "\u7a7f\u5899\u96f7\u8fbe\u7cfb\u7edf\u9700\u8981\u7d27\u51d1\u3001\u5bbd\u5e26\u3001\u9ad8\u589e\u76ca\u7684\u5929\u7ebf\u6765\u63a2\u6d4b\u76ee\u6807\u3002\u5efa\u7b51\u5899\u58c1\u4f1a\u5bf9\u96f7\u8fbe\u4fe1\u53f7\u9020\u6210\u663e\u8457\u8870\u51cf\u3002\u5f53\u63d0\u9ad8\u53d1\u5c04\u529f\u7387\u4ee5\u8865\u507f\u7a7f\u5899\u8870\u51cf\u65f6\uff0c\u53d1\u5c04\u673a\u548c\u63a5\u6536\u673a\u4e4b\u95f4\u7684\u76f4\u63a5\u8026\u5408\u4f1a\u4f7f\u63a5\u6536\u673a\u9971\u548c\uff0c\u5bfc\u81f4\u6765\u81ea\u76ee\u6807\u7684\u8f83\u5f31\u53cd\u5c04\u4fe1\u53f7\u65e0\u6cd5\u88ab\u68c0\u6d4b\u5230\u3002", "method": "\u63d0\u51fa\u4f7f\u7528\u6b63\u4ea4\u5706\u6781\u5316\u7684\u53d1\u5c04\u548c\u63a5\u6536\u5929\u7ebf\u6765\u51cf\u5c11\u76f4\u63a5\u8026\u5408\uff0c\u540c\u65f6\u4fdd\u7559\u76ee\u6807\u7684\u4e00\u6b21\u53cd\u5c04\u3002\u9009\u62e9\u56db\u81c2\u87ba\u65cb\u5929\u7ebf\u4f5c\u4e3a\u5019\u9009\u65b9\u6848\uff0c\u56e0\u4e3a\u5b83\u5177\u6709\u5c3a\u5bf8\u5c0f\u3001\u5de5\u4f5c\u9891\u5e26\u5bbd\u3001\u589e\u76ca\u9ad8\u3001\u5728\u5bbd\u89c6\u573a\u5185\u8f74\u6bd4\u4f4e\u7b49\u4f18\u70b9\u3002\u5c06\u6b63\u4ea4\u6781\u5316QHA\u5929\u7ebf\u4e0e\u5e38\u7528\u7684\u7a7f\u5899\u96f7\u8fbe\u5929\u7ebf\uff08\u5982Vivaldi\u5929\u7ebf\u548c\u5587\u53ed\u5929\u7ebf\uff09\u5728\u4e92\u8026\u51cf\u5c11\u65b9\u9762\u8fdb\u884c\u6bd4\u8f83\u3002", "result": "\u8bba\u6587\u5c55\u793a\u4e86\u6b63\u4ea4\u5706\u6781\u5316QHA\u5929\u7ebf\u5728\u51cf\u5c11\u53d1\u5c04\u673a\u548c\u63a5\u6536\u673a\u4e4b\u95f4\u4e92\u8026\u65b9\u9762\u7684\u6709\u6548\u6027\uff0c\u5e76\u5728\u7a7f\u5899\u6761\u4ef6\u4e0b\u5bf9\u7cfb\u7edf\u8fdb\u884c\u4e86\u6d4b\u8bd5\u9a8c\u8bc1\u3002", "conclusion": "\u56db\u81c2\u87ba\u65cb\u5929\u7ebf\u662f\u7a7f\u5899\u96f7\u8fbe\u7cfb\u7edf\u7684\u826f\u597d\u9009\u62e9\uff0c\u901a\u8fc7\u6b63\u4ea4\u5706\u6781\u5316\u8bbe\u8ba1\u53ef\u4ee5\u6709\u6548\u51cf\u5c11\u76f4\u63a5\u8026\u5408\u95ee\u9898\uff0c\u540c\u65f6\u4fdd\u6301\u5bf9\u76ee\u6807\u53cd\u5c04\u4fe1\u53f7\u7684\u68c0\u6d4b\u80fd\u529b\u3002"}}
{"id": "2602.09970", "categories": ["eess.AS", "cs.SD"], "pdf": "https://arxiv.org/pdf/2602.09970", "abs": "https://arxiv.org/abs/2602.09970", "authors": ["Heitor R. Guimar\u00e3es", "Abhishek Tiwari", "Mahsa Abdollahi", "Anderson R. Avila", "Tiago H. Falk"], "title": "BioME: A Resource-Efficient Bioacoustic Foundational Model for IoT Applications", "comment": null, "summary": "Passive acoustic monitoring has become a key strategy in biodiversity assessment, conservation, and behavioral ecology, especially as Internet-of-Things (IoT) devices enable continuous in situ audio collection at scale. While recent self-supervised learning (SSL)-based audio encoders, such as BEATs and AVES, have shown strong performance in bioacoustic tasks, their computational cost and limited robustness to unseen environments hinder deployment on resource-constrained platforms. In this work, we introduce BioME, a resource-efficient audio encoder designed for bioacoustic applications. BioME is trained via layer-to-layer distillation from a high-capacity teacher model, enabling strong representational transfer while reducing the parameter count by 75%. To further improve ecological generalization, the model is pretrained on multi-domain data spanning speech, environmental sounds, and animal vocalizations. A key contribution is the integration of modulation-aware acoustic features via FiLM conditioning, injecting a DSP-inspired inductive bias that enhances feature disentanglement in low-capacity regimes. Across multiple bioacoustic tasks, BioME matches or surpasses the performance of larger models, including its teacher, while being suitable for resource-constrained IoT deployments. For reproducibility, code and pretrained checkpoints are publicly available.", "AI": {"tldr": "BioME\u662f\u4e00\u4e2a\u8d44\u6e90\u9ad8\u6548\u7684\u751f\u7269\u58f0\u5b66\u97f3\u9891\u7f16\u7801\u5668\uff0c\u901a\u8fc7\u5c42\u5230\u5c42\u84b8\u998f\u548c\u591a\u9886\u57df\u9884\u8bad\u7ec3\u5b9e\u73b0\u9ad8\u6027\u80fd\uff0c\u540c\u65f6\u53c2\u6570\u51cf\u5c1175%\uff0c\u9002\u5408\u7269\u8054\u7f51\u90e8\u7f72\u3002", "motivation": "\u73b0\u6709\u7684\u81ea\u76d1\u7763\u5b66\u4e60\u97f3\u9891\u7f16\u7801\u5668\uff08\u5982BEATs\u548cAVES\uff09\u5728\u751f\u7269\u58f0\u5b66\u4efb\u52a1\u4e2d\u8868\u73b0\u826f\u597d\uff0c\u4f46\u8ba1\u7b97\u6210\u672c\u9ad8\u4e14\u5bf9\u672a\u89c1\u73af\u5883\u7684\u9c81\u68d2\u6027\u6709\u9650\uff0c\u96be\u4ee5\u90e8\u7f72\u5728\u8d44\u6e90\u53d7\u9650\u7684\u7269\u8054\u7f51\u5e73\u53f0\u4e0a\u3002", "method": "1. \u901a\u8fc7\u5c42\u5230\u5c42\u84b8\u998f\u4ece\u9ad8\u5bb9\u91cf\u6559\u5e08\u6a21\u578b\u8f6c\u79fb\u8868\u793a\u80fd\u529b\uff1b2. \u5728\u591a\u9886\u57df\u6570\u636e\uff08\u8bed\u97f3\u3001\u73af\u5883\u58f0\u97f3\u3001\u52a8\u7269\u53d1\u58f0\uff09\u4e0a\u8fdb\u884c\u9884\u8bad\u7ec3\u4ee5\u63d0\u9ad8\u751f\u6001\u6cdb\u5316\u80fd\u529b\uff1b3. \u901a\u8fc7FiLM\u6761\u4ef6\u6ce8\u5165\u8c03\u5236\u611f\u77e5\u58f0\u5b66\u7279\u5f81\uff0c\u589e\u5f3a\u4f4e\u5bb9\u91cf\u60c5\u51b5\u4e0b\u7684\u7279\u5f81\u89e3\u8026\u3002", "result": "BioME\u5728\u591a\u4e2a\u751f\u7269\u58f0\u5b66\u4efb\u52a1\u4e2d\u5339\u914d\u6216\u8d85\u8d8a\u4e86\u5305\u62ec\u5176\u6559\u5e08\u6a21\u578b\u5728\u5185\u7684\u66f4\u5927\u6a21\u578b\u7684\u6027\u80fd\uff0c\u540c\u65f6\u53c2\u6570\u51cf\u5c11\u4e8675%\uff0c\u9002\u5408\u8d44\u6e90\u53d7\u9650\u7684\u7269\u8054\u7f51\u90e8\u7f72\u3002", "conclusion": "BioME\u901a\u8fc7\u9ad8\u6548\u7684\u84b8\u998f\u7b56\u7565\u3001\u591a\u9886\u57df\u9884\u8bad\u7ec3\u548c\u8c03\u5236\u611f\u77e5\u7279\u5f81\u96c6\u6210\uff0c\u5b9e\u73b0\u4e86\u5728\u8d44\u6e90\u53d7\u9650\u5e73\u53f0\u4e0a\u90e8\u7f72\u9ad8\u6027\u80fd\u751f\u7269\u58f0\u5b66\u7f16\u7801\u5668\u7684\u76ee\u6807\uff0c\u4e3a\u751f\u6001\u76d1\u6d4b\u63d0\u4f9b\u4e86\u5b9e\u7528\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.09451", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09451", "abs": "https://arxiv.org/abs/2602.09451", "authors": ["Akanksha Sneh", "Aakanksha Tewari", "Shobha Sundar Ram", "Sumit J Darak"], "title": "Performance Analysis of Millimeter Wave Radar Waveforms for Integrated Sensing and Communication", "comment": null, "summary": "Next-generation intelligent transportation systems require both sensing and communication between road users. However, deploying separate radars and communication devices involves the allocation of individual frequency bands and hardware platforms. Integrated sensing and communication (ISAC) offers a robust solution to the challenges of spectral congestion by utilizing a shared waveform, hardware, and spectrum for both localization of mobile users and communication. Various waveforms, including phase-modulated continuous waves (PMCW) and frequency-modulated continuous waves (FMCW), have been explored for target localization using traditional radar. On the other hand, new protocols such as the IEEE 802.11ad have been proposed to support wideband communication between vehicles. This paper compares both traditional radar and communication candidate waveforms for ISAC to detect single-point and extended targets. We show that the response of FMCW to mobile targets is poorer than that of PMCW. However, the IEEE 802.11ad radar outperforms PMCW radar and FMCW radar. Additionally, the radar signal processing algorithms are implemented on Zynq system-on-chip through hardware-software co-design and fixed-point analysis to evaluate their computational complexity in real-world implementations.", "AI": {"tldr": "\u8be5\u8bba\u6587\u6bd4\u8f83\u4e86\u4f20\u7edf\u96f7\u8fbe\u6ce2\u5f62\u548c\u901a\u4fe1\u6ce2\u5f62\u5728\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\uff08ISAC\uff09\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0IEEE 802.11ad\u96f7\u8fbe\u5728\u68c0\u6d4b\u5355\u70b9\u548c\u6269\u5c55\u76ee\u6807\u65b9\u9762\u4f18\u4e8ePMCW\u548cFMCW\u96f7\u8fbe\uff0c\u5e76\u5728Zynq SoC\u4e0a\u901a\u8fc7\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u5b9e\u73b0\u4e86\u96f7\u8fbe\u4fe1\u53f7\u5904\u7406\u7b97\u6cd5\u3002", "motivation": "\u4e0b\u4e00\u4ee3\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u9700\u8981\u540c\u65f6\u5b9e\u73b0\u611f\u77e5\u548c\u901a\u4fe1\u529f\u80fd\uff0c\u4f46\u90e8\u7f72\u5355\u72ec\u7684\u96f7\u8fbe\u548c\u901a\u4fe1\u8bbe\u5907\u4f1a\u5360\u7528\u72ec\u7acb\u7684\u9891\u6bb5\u548c\u786c\u4ef6\u5e73\u53f0\u3002ISAC\u901a\u8fc7\u5171\u4eab\u6ce2\u5f62\u3001\u786c\u4ef6\u548c\u9891\u8c31\u6765\u89e3\u51b3\u9891\u8c31\u62e5\u585e\u95ee\u9898\uff0c\u9700\u8981\u8bc4\u4f30\u4e0d\u540c\u6ce2\u5f62\u5728ISAC\u4e2d\u7684\u6027\u80fd\u3002", "method": "\u6bd4\u8f83\u4e86\u4f20\u7edf\u96f7\u8fbe\u6ce2\u5f62\uff08PMCW\u548cFMCW\uff09\u548c\u901a\u4fe1\u5019\u9009\u6ce2\u5f62\uff08IEEE 802.11ad\uff09\u5728ISAC\u4e2d\u68c0\u6d4b\u5355\u70b9\u548c\u6269\u5c55\u76ee\u6807\u7684\u6027\u80fd\u3002\u5728Zynq\u7cfb\u7edf\u7ea7\u82af\u7247\u4e0a\u901a\u8fc7\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u548c\u5b9a\u70b9\u5206\u6790\u5b9e\u73b0\u4e86\u96f7\u8fbe\u4fe1\u53f7\u5904\u7406\u7b97\u6cd5\uff0c\u8bc4\u4f30\u5176\u5728\u5b9e\u9645\u5b9e\u73b0\u4e2d\u7684\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "FMCW\u5bf9\u79fb\u52a8\u76ee\u6807\u7684\u54cd\u5e94\u6bd4PMCW\u5dee\uff0c\u4f46IEEE 802.11ad\u96f7\u8fbe\u5728\u6027\u80fd\u4e0a\u4f18\u4e8ePMCW\u96f7\u8fbe\u548cFMCW\u96f7\u8fbe\u3002\u901a\u8fc7\u786c\u4ef6\u5b9e\u73b0\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u7684\u53ef\u884c\u6027\u3002", "conclusion": "IEEE 802.11ad\u6ce2\u5f62\u5728ISAC\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u4f18\u8d8a\u6027\u80fd\uff0c\u4e3a\u667a\u80fd\u4ea4\u901a\u7cfb\u7edf\u7684\u96c6\u6210\u611f\u77e5\u4e0e\u901a\u4fe1\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u89e3\u51b3\u65b9\u6848\u3002\u8f6f\u786c\u4ef6\u534f\u540c\u8bbe\u8ba1\u65b9\u6cd5\u9a8c\u8bc1\u4e86\u7b97\u6cd5\u5728\u5b9e\u9645\u786c\u4ef6\u5e73\u53f0\u4e0a\u7684\u53ef\u5b9e\u73b0\u6027\u3002"}}
{"id": "2602.09452", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09452", "abs": "https://arxiv.org/abs/2602.09452", "authors": ["Devansh Mathur", "Akanksha Sneh", "Debojyoti Sarkar", "Shobha Sundar Ram"], "title": "Motion Compensation for Multiple-Input-Multiple-Output Inverse Synthetic Aperture Imaging of Automotive Targets", "comment": null, "summary": "Inverse synthetic aperture radar (ISAR) images generated from single-channel automotive radar data provide critical information about the shape and size of automotive targets. However, the quality of ISAR images degrades due to road clutter and when translational and higher order rotational motions of the targets are not suitably compensated. One method to enhance the signal-to-clutter-and-noise ratio (SCNR) of the systems is to leverage the advantages of the multiple-input-multiple-output (MIMO) framework available in commercial automotive radars to generate MIMO-ISAR images. While substantial research has been devoted to motion compensation of single-channel ISAR images, the effectiveness of these methods for MIMO-ISAR has not been studied extensively. This paper analyzes the performance of three popular motion compensation techniques - entropy minimization, cross-correlation, and phase gradient autofocus - on MIMO-ISAR. The algorithms are evaluated on the measurement data collected using Texas Instruments millimeter-wave MIMO radar. The results indicate that the cross-correlation MOCOMP performs better than the other two MOCOMP algorithms in the MIMO configuration, with an overall improvement of 36%.", "AI": {"tldr": "\u672c\u6587\u5206\u6790\u4e86\u4e09\u79cd\u8fd0\u52a8\u8865\u507f\u7b97\u6cd5\uff08\u71b5\u6700\u5c0f\u5316\u3001\u4e92\u76f8\u5173\u548c\u76f8\u4f4d\u68af\u5ea6\u81ea\u805a\u7126\uff09\u5728MIMO-ISAR\u6210\u50cf\u4e2d\u7684\u6027\u80fd\uff0c\u53d1\u73b0\u4e92\u76f8\u5173\u7b97\u6cd5\u5728MIMO\u914d\u7f6e\u4e0b\u8868\u73b0\u6700\u4f73\uff0c\u6574\u4f53\u6027\u80fd\u63d0\u534736%\u3002", "motivation": "\u8f66\u8f7d\u96f7\u8fbe\u751f\u6210\u7684ISAR\u56fe\u50cf\u8d28\u91cf\u53d7\u9053\u8def\u6742\u6ce2\u548c\u76ee\u6807\u590d\u6742\u8fd0\u52a8\u5f71\u54cd\u800c\u4e0b\u964d\u3002\u867d\u7136MIMO\u6846\u67b6\u53ef\u63d0\u5347\u4fe1\u6742\u566a\u6bd4\uff0c\u4f46\u73b0\u6709\u5355\u901a\u9053ISAR\u8fd0\u52a8\u8865\u507f\u65b9\u6cd5\u5728MIMO-ISAR\u4e2d\u7684\u6709\u6548\u6027\u5c1a\u672a\u5f97\u5230\u5145\u5206\u7814\u7a76\u3002", "method": "\u5206\u6790\u4e09\u79cd\u4e3b\u6d41\u8fd0\u52a8\u8865\u507f\u6280\u672f\uff1a\u71b5\u6700\u5c0f\u5316\u3001\u4e92\u76f8\u5173\u548c\u76f8\u4f4d\u68af\u5ea6\u81ea\u805a\u7126\u5728MIMO-ISAR\u4e2d\u7684\u6027\u80fd\u3002\u4f7f\u7528\u5fb7\u5dde\u4eea\u5668\u6beb\u7c73\u6ce2MIMO\u96f7\u8fbe\u91c7\u96c6\u7684\u5b9e\u6d4b\u6570\u636e\u8fdb\u884c\u7b97\u6cd5\u8bc4\u4f30\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u8868\u660e\uff0c\u5728MIMO\u914d\u7f6e\u4e0b\uff0c\u4e92\u76f8\u5173\u8fd0\u52a8\u8865\u507f\u7b97\u6cd5\u8868\u73b0\u4f18\u4e8e\u5176\u4ed6\u4e24\u79cd\u7b97\u6cd5\uff0c\u6574\u4f53\u6027\u80fd\u63d0\u5347\u8fbe\u523036%\u3002", "conclusion": "\u4e92\u76f8\u5173\u8fd0\u52a8\u8865\u507f\u7b97\u6cd5\u5728MIMO-ISAR\u7cfb\u7edf\u4e2d\u5177\u6709\u6700\u4f73\u6027\u80fd\uff0c\u4e3a\u8f66\u8f7d\u96f7\u8fbe\u76ee\u6807\u6210\u50cf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u8fd0\u52a8\u8865\u507f\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.09589", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09589", "abs": "https://arxiv.org/abs/2602.09589", "authors": ["Wali Ullah Khan", "Chandan Kumar Sheemar", "Syed Tariq Shah", "Manzoor Ahmed", "Symeon Chatzinotas"], "title": "A Survey on STAR-RIS Enabled Joint Communications and Sensing: Fundamentals, Recent Advances and Research Challenges", "comment": null, "summary": "The joint communications and sensing (JCAS) paradigm is envisioned as a core capability of sixth-generation (6G) wireless networks, enabling the integration of data communication and environmental sensing within a unified system. By reusing spectrum, waveforms, and hardware resources, JCAS improves spectral efficiency, reduces system complexity, and hardware cost, while enabling new use cases. Nevertheless, the realization of JCAS is hindered by inherent trade-offs between communication and sensing objectives, limited controllability of wireless propagation, and stringent hardware and design constraints. Simultaneously transmitting and reflecting reconfigurable intelligent surfaces (STAR-RIS) have recently emerged as a promising technology to address these challenges by enabling full-space programmable manipulation of electromagnetic waves. This survey provides a systematic and in-depth review of STAR-RIS-enabled JCAS systems. Specifically, we first introduce the fundamental principles of JCAS and STAR-RIS. We then classify and review the state-of-the-art research on STAR-RIS-assisted JCAS from multiple perspectives, encompassing system architectures, waveform and beamforming design, resource allocation, optimization frameworks, and learning-based control. Finally, we identify key open challenges that remain unsolved and outline promising future research directions toward intelligent, flexible, and perceptive 6G wireless networks.", "AI": {"tldr": "STAR-RIS\u6280\u672f\u8d4b\u80fd\u901a\u4fe1\u611f\u77e5\u4e00\u4f53\u5316\u7cfb\u7edf\uff0c\u901a\u8fc7\u5168\u7a7a\u95f4\u53ef\u7f16\u7a0b\u7535\u78c1\u6ce2\u64cd\u63a7\u89e3\u51b3\u901a\u4fe1\u4e0e\u611f\u77e5\u4e4b\u95f4\u7684\u56fa\u6709\u6743\u8861\u95ee\u9898\uff0c\u4e3a6G\u7f51\u7edc\u63d0\u4f9b\u667a\u80fd\u3001\u7075\u6d3b\u3001\u611f\u77e5\u80fd\u529b\u3002", "motivation": "\u901a\u4fe1\u611f\u77e5\u4e00\u4f53\u5316\uff08JCAS\uff09\u662f6G\u7f51\u7edc\u7684\u6838\u5fc3\u80fd\u529b\uff0c\u80fd\u63d0\u9ad8\u9891\u8c31\u6548\u7387\u3001\u964d\u4f4e\u7cfb\u7edf\u590d\u6742\u6027\u548c\u786c\u4ef6\u6210\u672c\uff0c\u4f46\u9762\u4e34\u901a\u4fe1\u4e0e\u611f\u77e5\u76ee\u6807\u95f4\u7684\u56fa\u6709\u6743\u8861\u3001\u65e0\u7ebf\u4f20\u64ad\u53ef\u63a7\u6027\u6709\u9650\u4ee5\u53ca\u786c\u4ef6\u8bbe\u8ba1\u7ea6\u675f\u7b49\u6311\u6218\u3002", "method": "\u91c7\u7528\u540c\u65f6\u900f\u5c04\u53cd\u5c04\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08STAR-RIS\uff09\u6280\u672f\uff0c\u901a\u8fc7\u5168\u7a7a\u95f4\u53ef\u7f16\u7a0b\u7535\u78c1\u6ce2\u64cd\u63a7\u6765\u89e3\u51b3JCAS\u7684\u6311\u6218\u3002\u8bba\u6587\u4ece\u7cfb\u7edf\u67b6\u6784\u3001\u6ce2\u5f62\u4e0e\u6ce2\u675f\u6210\u5f62\u8bbe\u8ba1\u3001\u8d44\u6e90\u5206\u914d\u3001\u4f18\u5316\u6846\u67b6\u548c\u57fa\u4e8e\u5b66\u4e60\u7684\u63a7\u5236\u7b49\u591a\u4e2a\u89d2\u5ea6\u5bf9STAR-RIS\u8f85\u52a9\u7684JCAS\u7814\u7a76\u8fdb\u884c\u5206\u7c7b\u548c\u7efc\u8ff0\u3002", "result": "STAR-RIS\u6280\u672f\u4e3aJCAS\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u80fd\u591f\u5b9e\u73b0\u5168\u7a7a\u95f4\u7535\u78c1\u6ce2\u7684\u53ef\u7f16\u7a0b\u64cd\u63a7\uff0c\u6709\u52a9\u4e8e\u89e3\u51b3\u901a\u4fe1\u4e0e\u611f\u77e5\u4e4b\u95f4\u7684\u6743\u8861\u95ee\u9898\uff0c\u5e76\u4e3a6G\u7f51\u7edc\u5e26\u6765\u65b0\u7684\u5e94\u7528\u573a\u666f\u3002", "conclusion": "STAR-RIS\u8d4b\u80fd\u7684JCAS\u7cfb\u7edf\u662f6G\u7f51\u7edc\u53d1\u5c55\u7684\u5173\u952e\u6280\u672f\u65b9\u5411\uff0c\u4f46\u4ecd\u5b58\u5728\u672a\u89e3\u51b3\u7684\u5173\u952e\u6311\u6218\uff0c\u9700\u8981\u8fdb\u4e00\u6b65\u7814\u7a76\u4ee5\u5b9e\u73b0\u667a\u80fd\u3001\u7075\u6d3b\u3001\u611f\u77e5\u76846G\u65e0\u7ebf\u7f51\u7edc\u3002"}}
{"id": "2602.09615", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09615", "abs": "https://arxiv.org/abs/2602.09615", "authors": ["Peng Yi", "Ying-Chang Liang"], "title": "Collaborative Spectrum Sensing in Cognitive and Intelligent Wireless Networks: An Artificial Intelligence Perspective", "comment": null, "summary": "Artificial intelligence (AI) has become a key enabler for next-generation wireless communication systems, offering powerful tools to cope with the increasing complexity, dynamics, and heterogeneity of modern wireless environments. To illustrate the role and impact of AI in wireless communications, this paper takes collaborative spectrum sensing (CSS) in cognitive and intelligent wireless networks as a representative application and surveys recent advances from an AI perspective. We first introduce the fundamentals of CSS, including the general framework, classical detector design, and fusion strategies. Then, we present an overview of the state-of-the-art research on AI-driven CSS, classified into three categories: discriminative deep learning (DL) models, generative DL models, and deep reinforcement learning (DRL). Furthermore, we explore semantic communication (SemCom) as a promising solution for CSS, in which task-oriented representations are exchanged to reduce reporting overhead while preserving decision-critical information. Finally, we discuss limitations, open challenges, and future research directions at the intersection of AI and wireless communication.", "AI": {"tldr": "\u8be5\u8bba\u6587\u7efc\u8ff0\u4e86\u4eba\u5de5\u667a\u80fd\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\u7684\u5e94\u7528\uff0c\u7279\u522b\u805a\u7126\u4e8e\u8ba4\u77e5\u667a\u80fd\u65e0\u7ebf\u7f51\u7edc\u4e2d\u7684\u534f\u4f5c\u9891\u8c31\u611f\u77e5\uff0c\u4eceAI\u89c6\u89d2\u5206\u7c7b\u603b\u7ed3\u4e86\u6df1\u5ea6\u5b66\u4e60\u3001\u751f\u6210\u6a21\u578b\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\u7b49\u65b9\u6cd5\uff0c\u5e76\u63a2\u8ba8\u4e86\u8bed\u4e49\u901a\u4fe1\u4f5c\u4e3a\u964d\u4f4e\u62a5\u544a\u5f00\u9500\u7684\u89e3\u51b3\u65b9\u6848\u3002", "motivation": "\u73b0\u4ee3\u65e0\u7ebf\u73af\u5883\u65e5\u76ca\u590d\u6742\u3001\u52a8\u6001\u548c\u5f02\u6784\uff0c\u4eba\u5de5\u667a\u80fd\u6210\u4e3a\u4e0b\u4e00\u4ee3\u65e0\u7ebf\u901a\u4fe1\u7cfb\u7edf\u7684\u5173\u952e\u8d4b\u80fd\u6280\u672f\u3002\u8bba\u6587\u4ee5\u534f\u4f5c\u9891\u8c31\u611f\u77e5\u4f5c\u4e3a\u4ee3\u8868\u6027\u5e94\u7528\uff0c\u65e8\u5728\u7cfb\u7edf\u68b3\u7406AI\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\u7684\u89d2\u8272\u548c\u5f71\u54cd\u3002", "method": "\u9996\u5148\u4ecb\u7ecd\u534f\u4f5c\u9891\u8c31\u611f\u77e5\u7684\u57fa\u7840\u6846\u67b6\u3001\u7ecf\u5178\u68c0\u6d4b\u5668\u8bbe\u8ba1\u548c\u878d\u5408\u7b56\u7565\uff1b\u7136\u540e\u4eceAI\u89c6\u89d2\u5206\u7c7b\u7efc\u8ff0\u6700\u65b0\u7814\u7a76\uff1a\u5224\u522b\u5f0f\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u3001\u751f\u6210\u5f0f\u6df1\u5ea6\u5b66\u4e60\u6a21\u578b\u548c\u6df1\u5ea6\u5f3a\u5316\u5b66\u4e60\uff1b\u8fdb\u4e00\u6b65\u63a2\u7d22\u8bed\u4e49\u901a\u4fe1\u4f5c\u4e3aCSS\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u901a\u8fc7\u4ea4\u6362\u9762\u5411\u4efb\u52a1\u7684\u8868\u793a\u6765\u964d\u4f4e\u62a5\u544a\u5f00\u9500\u3002", "result": "\u8bba\u6587\u7cfb\u7edf\u6027\u5730\u603b\u7ed3\u4e86AI\u9a71\u52a8\u7684\u534f\u4f5c\u9891\u8c31\u611f\u77e5\u7814\u7a76\u73b0\u72b6\uff0c\u5c06\u73b0\u6709\u65b9\u6cd5\u5206\u4e3a\u4e09\u5927\u7c7b\uff0c\u5e76\u63d0\u51fa\u4e86\u8bed\u4e49\u901a\u4fe1\u4f5c\u4e3a\u964d\u4f4e\u62a5\u544a\u5f00\u9500\u7684\u521b\u65b0\u65b9\u6848\u3002\u4e3aAI\u4e0e\u65e0\u7ebf\u901a\u4fe1\u4ea4\u53c9\u9886\u57df\u7684\u7814\u7a76\u63d0\u4f9b\u4e86\u5168\u9762\u7684\u6280\u672f\u8def\u7ebf\u56fe\u3002", "conclusion": "\u4eba\u5de5\u667a\u80fd\u5728\u65e0\u7ebf\u901a\u4fe1\u4e2d\u5177\u6709\u91cd\u8981\u5e94\u7528\u4ef7\u503c\uff0c\u7279\u522b\u662f\u5728\u534f\u4f5c\u9891\u8c31\u611f\u77e5\u7b49\u590d\u6742\u573a\u666f\u4e2d\u3002\u8bed\u4e49\u901a\u4fe1\u4e3a\u89e3\u51b3\u62a5\u544a\u5f00\u9500\u95ee\u9898\u63d0\u4f9b\u4e86\u6709\u524d\u666f\u7684\u65b9\u5411\u3002\u672a\u6765\u9700\u8981\u8fdb\u4e00\u6b65\u89e3\u51b3\u8be5\u4ea4\u53c9\u9886\u57df\u7684\u5c40\u9650\u6027\u3001\u5f00\u653e\u6311\u6218\u548c\u7814\u7a76\u65b9\u5411\u3002"}}
{"id": "2602.09685", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09685", "abs": "https://arxiv.org/abs/2602.09685", "authors": ["Yanliang Jin", "Yunfan Li", "Jiang Jun", "Yuan Gao", "Shengli Liu", "Jianbo Du", "Zhaohui Yang", "Shugong Xu"], "title": "Generalizable and Robust Beam Prediction for 6G Networks: An Deep-Learning Framework with Positioning Feature Fusion", "comment": null, "summary": "Beamforming (BF) is essential for enhancing system capacity in fifth generation (5G) and beyond wireless networks, yet exhaustive beam training in ultra-massive multiple-input multiple-output (MIMO) systems incurs substantial overhead. To address this challenge, we propose a deep learning based framework that leverages position-aware features to improve beam prediction accuracy while reducing training costs. The proposed approach uses spatial coordinate labels to supervise a position extraction branch and integrates the resulting representations with beam-domain features through a feature fusion module. A dual-branch RegNet architecture is adopted to jointly learn location related and communication features for beam prediction. Two fusion strategies, namely adaptive fusion and adversarial fusion, are introduced to enable efficient feature integration. The proposed framework is evaluated on datasets generated by the DeepMIMO simulator across four urban scenarios at 3.5 GHz following 3GPP specifications, where both reference signal received power and user equipment location information are available. Simulation results under both in-distribution and out-of-distribution settings demonstrate that the proposed approach consistently outperforms traditional baselines and achieves more accurate and robust beam prediction by effectively incorporating positioning information.", "AI": {"tldr": "\u63d0\u51fa\u57fa\u4e8e\u6df1\u5ea6\u5b66\u4e60\u7684\u6ce2\u675f\u9884\u6d4b\u6846\u67b6\uff0c\u5229\u7528\u4f4d\u7f6e\u611f\u77e5\u7279\u5f81\u63d0\u9ad8\u9884\u6d4b\u7cbe\u5ea6\u5e76\u964d\u4f4e\u8bad\u7ec3\u5f00\u9500\uff0c\u5728\u8d85\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\u65b9\u6cd5\u3002", "motivation": "5G\u53ca\u8d85\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u7684\u6ce2\u675f\u8bad\u7ec3\u5f00\u9500\u5de8\u5927\uff0c\u9700\u8981\u51cf\u5c11\u8bad\u7ec3\u6210\u672c\u540c\u65f6\u63d0\u9ad8\u6ce2\u675f\u9884\u6d4b\u51c6\u786e\u6027\u3002", "method": "\u91c7\u7528\u53cc\u5206\u652fRegNet\u67b6\u6784\uff0c\u901a\u8fc7\u4f4d\u7f6e\u63d0\u53d6\u5206\u652f\u5b66\u4e60\u4f4d\u7f6e\u7279\u5f81\uff0c\u4e0e\u6ce2\u675f\u57df\u7279\u5f81\u878d\u5408\uff1b\u63d0\u51fa\u81ea\u9002\u5e94\u878d\u5408\u548c\u5bf9\u6297\u878d\u5408\u4e24\u79cd\u7b56\u7565\u8fdb\u884c\u7279\u5f81\u6574\u5408\u3002", "result": "\u5728DeepMIMO\u6a21\u62df\u5668\u751f\u6210\u7684\u56db\u4e2a\u57ce\u5e02\u573a\u666f\u6570\u636e\u96c6\u4e0a\uff0c\u5728\u5206\u5e03\u5185\u548c\u5206\u5e03\u5916\u8bbe\u7f6e\u4e0b\u5747\u4f18\u4e8e\u4f20\u7edf\u57fa\u7ebf\uff0c\u5b9e\u73b0\u4e86\u66f4\u51c6\u786e\u548c\u9c81\u68d2\u7684\u6ce2\u675f\u9884\u6d4b\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df1\u5ea6\u5b66\u4e60\u6846\u67b6\u901a\u8fc7\u6709\u6548\u6574\u5408\u5b9a\u4f4d\u4fe1\u606f\uff0c\u663e\u8457\u63d0\u9ad8\u4e86\u6ce2\u675f\u9884\u6d4b\u6027\u80fd\uff0c\u4e3a5G\u53ca\u8d85\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u63d0\u4f9b\u4e86\u9ad8\u6548\u7684\u6ce2\u675f\u8bad\u7ec3\u89e3\u51b3\u65b9\u6848\u3002"}}
{"id": "2602.09699", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09699", "abs": "https://arxiv.org/abs/2602.09699", "authors": ["Barathan Pubalan", "Muhammad Arif Aiman Jidin", "Mohd Syahril Ramadhan Mohd Saufi", "Mohd Salman Leong", "Muhammad Danial bin Abu Hasan"], "title": "Rolling Element Bearing Fault Detection and Diagnosis with One-Dimensional Convolutional Neural Network", "comment": "Published in International Journal of Business and Technology Management, Vol. 7, No. 9, pp. 485-498, 2025. Special issue: 13th International Conference on Engineering Business Management 2025. Author version", "summary": "Rolling element bearings are critical components in rotating machinery, and their condition significantly influences system performance, reliability, and operational lifespan. Timely and accurate fault detection is essential to prevent unexpected failures and reduce maintenance costs. Traditional diagnostic methods often rely on manual feature extraction and shallow classifiers, which may be inadequate for capturing the complex patterns embedded in raw vibration signals. In this study, a compact one-dimensional convolutional neural network (1D CNN) is developed for automated bearing fault diagnosis using raw time-domain vibration data, eliminating the need for manual feature engineering. The model is trained and evaluated on two established benchmark datasets: the Case Western Reserve University (CWRU) dataset and the Paderborn University (PU) dataset. The CWRU data were segmented based on four distinct motor load conditions (0 HP to 3 HP), with each load scenario trained and tested independently to ensure strict separation and prevent data leakage. The CNN achieved high average test accuracies of 99.14%, 98.85%, 97.42%, and 95.14% for 0 HP, 1 HP, 2 HP, and 3 HP, respectively. On the PU dataset, known for its naturally induced faults and greater operational variability the model achieved a robust average testing accuracy of 95.63%. These results affirm the model ability to generalize across datasets and varying operating conditions. Further improvements were observed through hyperparameter tuning, particularly window length and training epochs, underscoring the importance of tailored configurations for specific datasets and load conditions. Overall, the proposed method demonstrates the effectiveness and scalability of 1D CNNs for real-time, data-driven bearing fault diagnosis, offering a reliable foundation for condition monitoring in industrial applications.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u7d27\u51d1\u7684\u4e00\u7ef4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u4f7f\u7528\u539f\u59cb\u632f\u52a8\u6570\u636e\u8fdb\u884c\u8f74\u627f\u6545\u969c\u8bca\u65ad\uff0c\u5728CWRU\u548cPU\u6570\u636e\u96c6\u4e0a\u53d6\u5f97\u9ad8\u51c6\u786e\u7387\uff0c\u9a8c\u8bc1\u4e86\u6a21\u578b\u5728\u4e0d\u540c\u5de5\u51b5\u4e0b\u7684\u6cdb\u5316\u80fd\u529b\u3002", "motivation": "\u6eda\u52a8\u8f74\u627f\u662f\u65cb\u8f6c\u673a\u68b0\u7684\u5173\u952e\u90e8\u4ef6\uff0c\u4f20\u7edf\u8bca\u65ad\u65b9\u6cd5\u4f9d\u8d56\u4eba\u5de5\u7279\u5f81\u63d0\u53d6\u548c\u6d45\u5c42\u5206\u7c7b\u5668\uff0c\u96be\u4ee5\u6355\u6349\u539f\u59cb\u632f\u52a8\u4fe1\u53f7\u4e2d\u7684\u590d\u6742\u6a21\u5f0f\uff0c\u9700\u8981\u81ea\u52a8\u5316\u3001\u66f4\u51c6\u786e\u7684\u6545\u969c\u8bca\u65ad\u65b9\u6cd5\u3002", "method": "\u5f00\u53d1\u7d27\u51d1\u7684\u4e00\u7ef4\u5377\u79ef\u795e\u7ecf\u7f51\u7edc\uff0c\u76f4\u63a5\u4f7f\u7528\u539f\u59cb\u65f6\u57df\u632f\u52a8\u6570\u636e\uff0c\u65e0\u9700\u4eba\u5de5\u7279\u5f81\u5de5\u7a0b\u3002\u5728CWRU\u548cPU\u4e24\u4e2a\u57fa\u51c6\u6570\u636e\u96c6\u4e0a\u8fdb\u884c\u8bad\u7ec3\u548c\u8bc4\u4f30\uff0cCWRU\u6570\u636e\u6309\u56db\u79cd\u4e0d\u540c\u7535\u673a\u8d1f\u8f7d\u6761\u4ef6\uff080-3 HP\uff09\u5206\u522b\u8bad\u7ec3\u6d4b\u8bd5\u3002", "result": "\u5728CWRU\u6570\u636e\u96c6\u4e0a\uff0c\u6a21\u578b\u57280 HP\u30011 HP\u30012 HP\u30013 HP\u8d1f\u8f7d\u4e0b\u5206\u522b\u8fbe\u523099.14%\u300198.85%\u300197.42%\u300195.14%\u7684\u5e73\u5747\u6d4b\u8bd5\u51c6\u786e\u7387\u3002\u5728PU\u6570\u636e\u96c6\u4e0a\u8fbe\u523095.63%\u7684\u5e73\u5747\u6d4b\u8bd5\u51c6\u786e\u7387\u3002\u901a\u8fc7\u8d85\u53c2\u6570\u8c03\u4f18\uff08\u7a97\u53e3\u957f\u5ea6\u548c\u8bad\u7ec3\u8f6e\u6570\uff09\u8fdb\u4e00\u6b65\u63d0\u5347\u4e86\u6027\u80fd\u3002", "conclusion": "\u8be5\u65b9\u6cd5\u8bc1\u660e\u4e861D CNN\u5728\u5b9e\u65f6\u3001\u6570\u636e\u9a71\u52a8\u7684\u8f74\u627f\u6545\u969c\u8bca\u65ad\u4e2d\u7684\u6709\u6548\u6027\u548c\u53ef\u6269\u5c55\u6027\uff0c\u4e3a\u5de5\u4e1a\u5e94\u7528\u4e2d\u7684\u72b6\u6001\u76d1\u6d4b\u63d0\u4f9b\u4e86\u53ef\u9760\u57fa\u7840\uff0c\u80fd\u591f\u6cdb\u5316\u5230\u4e0d\u540c\u6570\u636e\u96c6\u548c\u53d8\u5316\u7684\u5de5\u4f5c\u6761\u4ef6\u3002"}}
{"id": "2602.09754", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09754", "abs": "https://arxiv.org/abs/2602.09754", "authors": ["Mehzabien Iqbal", "Ahmad Y Javaid"], "title": "A Dual Belief-Driven Bayesian-Stackelberg Framework for Low-Complexity and Secure Near-Field ISAC Systems", "comment": "Accepted for publication in IEEE International Conference on Communications (ICC) 2026, Communication and Information Systems Security Symposium", "summary": "Ensuring robust security in near-field Integrated Sensing and Communication (ISAC) systems remains a critical challenge due to dynamic channel conditions, multi-eavesdropper threats, and the high computational burden of real-time optimization at mmWave and THz frequencies. To address these challenges, this paper introduces a novel Bayesian-Stackelberg framework that jointly optimizes sensing, beamforming, and communication. The dual-algorithm design integrates (i) Adaptive Hybrid Node Role Switching between secure transmission and cooperative jamming (ii) Belief-Driven Sensing and Beamforming for confidence based resource allocation. The proposed unified framework significantly improves robustness against attacks while preserving linear computational complexity. Simulation results across carrier frequencies ranging from 28 to 410 GHz demonstrate that the method achieves up to a 35% increase in secrecy rates and a success rate exceeding 98%, outperforming conventional communication systems with minimal runtime overhead. These findings underscore the scalability of belief-driven ISAC security solutions for low-complexity deployment in next generation communications.", "AI": {"tldr": "\u63d0\u51fa\u8d1d\u53f6\u65af-\u65af\u5854\u514b\u5c14\u4f2f\u683c\u6846\u67b6\uff0c\u8054\u5408\u4f18\u5316\u8fd1\u573aISAC\u7cfb\u7edf\u7684\u611f\u77e5\u3001\u6ce2\u675f\u6210\u5f62\u548c\u901a\u4fe1\uff0c\u901a\u8fc7\u81ea\u9002\u5e94\u8282\u70b9\u89d2\u8272\u5207\u6362\u548c\u4fe1\u5ff5\u9a71\u52a8\u8d44\u6e90\u5206\u914d\uff0c\u663e\u8457\u63d0\u5347\u5b89\u5168\u6027\u548c\u8ba1\u7b97\u6548\u7387\u3002", "motivation": "\u8fd1\u573aISAC\u7cfb\u7edf\u9762\u4e34\u52a8\u6001\u4fe1\u9053\u6761\u4ef6\u3001\u591a\u7a83\u542c\u8005\u5a01\u80c1\u4ee5\u53ca\u6beb\u7c73\u6ce2/\u592a\u8d6b\u5179\u9891\u6bb5\u5b9e\u65f6\u4f18\u5316\u7684\u9ad8\u8ba1\u7b97\u8d1f\u62c5\u7b49\u5b89\u5168\u6311\u6218\uff0c\u9700\u8981\u4e00\u79cd\u65e2\u80fd\u4fdd\u8bc1\u5b89\u5168\u6027\u53c8\u5177\u6709\u4f4e\u8ba1\u7b97\u590d\u6742\u5ea6\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u8d1d\u53f6\u65af-\u65af\u5854\u514b\u5c14\u4f2f\u683c\u6846\u67b6\uff0c\u5305\u542b\u4e24\u4e2a\u6838\u5fc3\u7b97\u6cd5\uff1a1) \u81ea\u9002\u5e94\u6df7\u5408\u8282\u70b9\u89d2\u8272\u5207\u6362\uff08\u5728\u5b89\u5168\u4f20\u8f93\u548c\u534f\u4f5c\u5e72\u6270\u4e4b\u95f4\u5207\u6362\uff09\uff1b2) \u4fe1\u5ff5\u9a71\u52a8\u7684\u611f\u77e5\u4e0e\u6ce2\u675f\u6210\u5f62\uff08\u57fa\u4e8e\u7f6e\u4fe1\u5ea6\u7684\u8d44\u6e90\u5206\u914d\uff09\u3002\u8be5\u6846\u67b6\u4fdd\u6301\u7ebf\u6027\u8ba1\u7b97\u590d\u6742\u5ea6\u3002", "result": "\u572828-410 GHz\u9891\u6bb5\u7684\u4eff\u771f\u4e2d\uff0c\u8be5\u65b9\u6cd5\u5b9e\u73b0\u4e86\u9ad8\u8fbe35%\u7684\u4fdd\u5bc6\u7387\u63d0\u5347\uff0c\u6210\u529f\u7387\u8d85\u8fc798%\uff0c\u4e14\u8fd0\u884c\u65f6\u5f00\u9500\u6700\u5c0f\uff0c\u663e\u8457\u4f18\u4e8e\u4f20\u7edf\u901a\u4fe1\u7cfb\u7edf\u3002", "conclusion": "\u4fe1\u5ff5\u9a71\u52a8\u7684ISAC\u5b89\u5168\u89e3\u51b3\u65b9\u6848\u5177\u6709\u53ef\u6269\u5c55\u6027\uff0c\u9002\u5408\u4e0b\u4e00\u4ee3\u901a\u4fe1\u7cfb\u7edf\u7684\u4f4e\u590d\u6742\u5ea6\u90e8\u7f72\uff0c\u4e3a\u8fd1\u573aISAC\u7cfb\u7edf\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u5b89\u5168\u4fdd\u969c\u6846\u67b6\u3002"}}
{"id": "2602.09763", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09763", "abs": "https://arxiv.org/abs/2602.09763", "authors": ["Luyao Sun", "Sitian Li", "Huan Huang", "Hongliang Zhang", "Weidong Mei", "Dongdong Zou", "Jun Li", "Gangxiang Shen", "Yi Cai"], "title": "An Unsupervised Normalizing Flow-Based Neyman-Pearson Detector for Covert Communications in the Presence of Disco Reconfigurable Intelligent Surfaces", "comment": null, "summary": "Covert communications, also known as low probability of detection (LPD) communications, offer a higher level of privacy protection compared to cryptography and physical-layer security (PLS) by hiding the transmission within ambient environments. Here, we investigate covert communications in the presence of a disco reconfigurable intelligent surface (DRIS) deployed by the warden Willie, which simultaneously reduces his detection error probabilities and degrades the communication performance between Alice and Bob, without relying on either channel state information (CSI) or additional jamming power. However, the introduction of the DRIS renders it intractable for Willie to construct a Neyman-Pearson (NP) detector, since the probability density function (PDF) of the test statistic is analytically intractable under the Alice-Bob transmission hypothesis. Moreover, given the adversarial relationship between Willie and Alice/Bob, it is unrealistic to assume that Willie has access to a labeled training dataset. To address these challenges, we propose an unsupervised masked autoregressive flow (MAF)-based NP detection framework that exploits prior knowledge inherent in covert communications. We further define the false alarm rate (FAR) and the missed detection rate (MDR) as monitoring performance metrics for Willie, and the signal-to-jamming-plus-noise ratio (SJNR) as a communication performance metric for Alice-Bob transmissions. Furthermore, we derive theoretical expressions for SJNR and uncover unique properties of covert communications in the presence of a DRIS. Simulations validate the theory and show that the proposed unsupervised MAF-based NP detector achieves performance comparable to its supervised counterpart.", "AI": {"tldr": "\u8bba\u6587\u63d0\u51fa\u4e86\u4e00\u79cd\u57fa\u4e8e\u65e0\u76d1\u7763\u63a9\u7801\u81ea\u56de\u5f52\u6d41\u7684NP\u68c0\u6d4b\u6846\u67b6\uff0c\u7528\u4e8e\u5e94\u5bf9DRIS\u5b58\u5728\u4e0b\u7684\u9690\u853d\u901a\u4fe1\u68c0\u6d4b\u6311\u6218\uff0c\u8be5\u6846\u67b6\u65e0\u9700\u6807\u8bb0\u8bad\u7ec3\u6570\u636e\u5373\u53ef\u8fbe\u5230\u63a5\u8fd1\u76d1\u7763\u65b9\u6cd5\u7684\u6027\u80fd\u3002", "motivation": "\u9690\u853d\u901a\u4fe1\u63d0\u4f9b\u6bd4\u52a0\u5bc6\u548c\u7269\u7406\u5c42\u5b89\u5168\u66f4\u9ad8\u7ea7\u522b\u7684\u9690\u79c1\u4fdd\u62a4\uff0c\u4f46DRIS\u7684\u5f15\u5165\u4f7f\u5f97\u4f20\u7edfNP\u68c0\u6d4b\u5668\u96be\u4ee5\u6784\u5efa\uff0c\u56e0\u4e3a\u6d4b\u8bd5\u7edf\u8ba1\u91cf\u7684\u6982\u7387\u5bc6\u5ea6\u51fd\u6570\u5728Alice-Bob\u4f20\u8f93\u5047\u8bbe\u4e0b\u89e3\u6790\u4e0d\u53ef\u89e3\uff0c\u4e14Willie\u65e0\u6cd5\u83b7\u5f97\u6807\u8bb0\u8bad\u7ec3\u6570\u636e\u96c6\u3002", "method": "\u63d0\u51fa\u65e0\u76d1\u7763\u63a9\u7801\u81ea\u56de\u5f52\u6d41(MAF)\u4e3a\u57fa\u7840\u7684NP\u68c0\u6d4b\u6846\u67b6\uff0c\u5229\u7528\u9690\u853d\u901a\u4fe1\u4e2d\u7684\u5148\u9a8c\u77e5\u8bc6\uff1b\u5b9a\u4e49FAR\u548cMDR\u4f5c\u4e3aWillie\u7684\u76d1\u63a7\u6027\u80fd\u6307\u6807\uff0cSJNR\u4f5c\u4e3aAlice-Bob\u901a\u4fe1\u6027\u80fd\u6307\u6807\uff1b\u63a8\u5bfcSJNR\u7684\u7406\u8bba\u8868\u8fbe\u5f0f\u5e76\u63ed\u793aDRIS\u5b58\u5728\u4e0b\u9690\u853d\u901a\u4fe1\u7684\u72ec\u7279\u6027\u8d28\u3002", "result": "\u4eff\u771f\u9a8c\u8bc1\u4e86\u7406\u8bba\u63a8\u5bfc\uff0c\u8868\u660e\u63d0\u51fa\u7684\u65e0\u76d1\u7763MAF-based NP\u68c0\u6d4b\u5668\u6027\u80fd\u53ef\u4e0e\u76d1\u7763\u5bf9\u5e94\u65b9\u6cd5\u76f8\u5ab2\u7f8e\u3002", "conclusion": "\u8be5\u7814\u7a76\u4e3aDRIS\u5b58\u5728\u4e0b\u7684\u9690\u853d\u901a\u4fe1\u68c0\u6d4b\u63d0\u4f9b\u4e86\u6709\u6548\u7684\u65e0\u76d1\u7763\u89e3\u51b3\u65b9\u6848\uff0c\u89e3\u51b3\u4e86\u4f20\u7edf\u65b9\u6cd5\u9762\u4e34\u7684\u89e3\u6790\u4e0d\u53ef\u89e3\u548c\u7f3a\u4e4f\u6807\u8bb0\u6570\u636e\u7684\u95ee\u9898\u3002"}}
{"id": "2602.09820", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09820", "abs": "https://arxiv.org/abs/2602.09820", "authors": ["Behdad Jamadi", "Meysam Sohani Darban", "Jeffrey S. Walling"], "title": "Analysis of Edge Mismatch and Output Power Degradation in Cascoded Class-D Power Amplifiers Using Dual-Range Voltage Level Shifters", "comment": "10 pages, 20 figures", "summary": "This paper presents a low-jitter hybrid voltage level shifter (HVLS) suitable for high-speed applications. The proposed architecture offers the advantage of cross-coupled feedback to simultaneously generate two voltage domain signals with available swings equal to the nominal supply and its double, which operate up to 12.4 GHz. A prototype HVLS circuit, along with impedance matching and a driver to enable high-speed off-chip testing, was fabricated in a 22-nm FD-SOI process technology. The prototype consumes a total die area, including the interface circuitry, of 477 x 462 um^2, while the active area of the level-shifter is 2 x 3.26 um^2. The average power consumption of the circuit is measured to be 4.43 uW per cycle, and the jitter is less than 150 fs-rms.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u79cd\u9002\u7528\u4e8e\u9ad8\u901f\u5e94\u7528\u7684\u4f4e\u6296\u52a8\u6df7\u5408\u7535\u538b\u7535\u5e73\u79fb\u4f4d\u5668\uff0c\u91c7\u7528\u4ea4\u53c9\u8026\u5408\u53cd\u9988\u540c\u65f6\u751f\u6210\u4e24\u4e2a\u7535\u538b\u57df\u4fe1\u53f7\uff0c\u5de5\u4f5c\u9891\u7387\u8fbe12.4GHz\uff0c\u572822nm FD-SOI\u5de5\u827a\u4e2d\u5b9e\u73b0\uff0c\u6296\u52a8\u5c0f\u4e8e150fs-rms\u3002", "motivation": "\u9ad8\u901f\u5e94\u7528\u4e2d\u9700\u8981\u4f4e\u6296\u52a8\u7684\u7535\u538b\u7535\u5e73\u79fb\u4f4d\u5668\uff0c\u4f20\u7edf\u7535\u5e73\u79fb\u4f4d\u5668\u5728\u9ad8\u9891\u4e0b\u6027\u80fd\u53d7\u9650\uff0c\u9700\u8981\u4e00\u79cd\u80fd\u5728\u9ad8\u9891\u4e0b\u4fdd\u6301\u4f4e\u6296\u52a8\u3001\u5c0f\u9762\u79ef\u548c\u4f4e\u529f\u8017\u7684\u89e3\u51b3\u65b9\u6848\u3002", "method": "\u91c7\u7528\u6df7\u5408\u67b6\u6784\uff0c\u5229\u7528\u4ea4\u53c9\u8026\u5408\u53cd\u9988\u540c\u65f6\u751f\u6210\u4e24\u4e2a\u7535\u538b\u57df\u4fe1\u53f7\uff08\u6807\u79f0\u7535\u6e90\u7535\u538b\u53ca\u5176\u4e24\u500d\u7535\u538b\uff09\uff0c\u914d\u5408\u963b\u6297\u5339\u914d\u548c\u9a71\u52a8\u7535\u8def\u5b9e\u73b0\u9ad8\u901f\u7247\u5916\u6d4b\u8bd5\u3002", "result": "\u572822nm FD-SOI\u5de5\u827a\u4e2d\u5b9e\u73b0\uff0c\u5de5\u4f5c\u9891\u7387\u8fbe12.4GHz\uff0c\u6296\u52a8\u5c0f\u4e8e150fs-rms\uff0c\u529f\u80174.43\u03bcW/\u5468\u671f\uff0c\u7535\u5e73\u79fb\u4f4d\u5668\u6709\u6548\u9762\u79ef\u4ec52\u00d73.26\u03bcm\u00b2\u3002", "conclusion": "\u63d0\u51fa\u7684\u6df7\u5408\u7535\u538b\u7535\u5e73\u79fb\u4f4d\u5668\u5728\u9ad8\u901f\u5e94\u7528\u4e2d\u8868\u73b0\u51fa\u4f18\u5f02\u7684\u4f4e\u6296\u52a8\u6027\u80fd\uff0c\u540c\u65f6\u5177\u6709\u5c0f\u9762\u79ef\u548c\u4f4e\u529f\u8017\u7279\u6027\uff0c\u9002\u7528\u4e8e\u9ad8\u9891\u96c6\u6210\u7535\u8def\u8bbe\u8ba1\u3002"}}
{"id": "2602.09848", "categories": ["eess.SP", "cs.LG"], "pdf": "https://arxiv.org/pdf/2602.09848", "abs": "https://arxiv.org/abs/2602.09848", "authors": ["Shixiong Wang", "Wei Dai", "Li-Chun Wang", "Geoffrey Ye Li"], "title": "Robust Processing and Learning: Principles, Methods, and Wireless Applications", "comment": null, "summary": "This tutorial-style overview article examines the fundamental principles and methods of robustness, using wireless sensing and communication (WSC) as the narrative and exemplifying framework. First, we formalize the conceptual and mathematical foundations of robustness, highlighting the interpretations and relations across robust statistics, optimization, and machine learning. Key techniques, such as robust estimation and testing, distributionally robust optimization, and regularized and adversary training, are investigated. Together, the costs of robustness in system design, for example, the compromised nominal performances and the extra computational burdens, are discussed. Second, we review recent robust signal processing solutions for WSC that address model mismatch, data scarcity, adversarial perturbation, and distributional shift. Specific applications include robust ranging-based localization, modality sensing, channel estimation, receive combining, waveform design, and federated learning. Through this effort, we aim to introduce the classical developments and recent advances in robustness theory to the general signal processing community, exemplifying how robust statistical, optimization, and machine learning approaches can address the uncertainties inherent in WSC systems.", "AI": {"tldr": "\u8fd9\u7bc7\u6559\u7a0b\u5f0f\u7efc\u8ff0\u6587\u7ae0\u4ee5\u65e0\u7ebf\u611f\u77e5\u4e0e\u901a\u4fe1\u4e3a\u6846\u67b6\uff0c\u7cfb\u7edf\u6027\u5730\u63a2\u8ba8\u4e86\u9c81\u68d2\u6027\u7684\u57fa\u672c\u539f\u7406\u548c\u65b9\u6cd5\uff0c\u5305\u62ec\u9c81\u68d2\u7edf\u8ba1\u3001\u4f18\u5316\u548c\u673a\u5668\u5b66\u4e60\uff0c\u5e76\u5c55\u793a\u4e86\u5982\u4f55\u5c06\u8fd9\u4e9b\u65b9\u6cd5\u5e94\u7528\u4e8e\u89e3\u51b3WSC\u7cfb\u7edf\u4e2d\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u3002", "motivation": "\u672c\u6587\u65e8\u5728\u5411\u4fe1\u53f7\u5904\u7406\u793e\u533a\u4ecb\u7ecd\u9c81\u68d2\u6027\u7406\u8bba\u7684\u7ecf\u5178\u53d1\u5c55\u548c\u6700\u65b0\u8fdb\u5c55\uff0c\u5c55\u793a\u9c81\u68d2\u7edf\u8ba1\u3001\u4f18\u5316\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5982\u4f55\u89e3\u51b3\u65e0\u7ebf\u611f\u77e5\u4e0e\u901a\u4fe1\u7cfb\u7edf\u4e2d\u56fa\u6709\u7684\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\uff0c\u5982\u6a21\u578b\u5931\u914d\u3001\u6570\u636e\u7a00\u7f3a\u3001\u5bf9\u6297\u6270\u52a8\u548c\u5206\u5e03\u504f\u79fb\u7b49\u6311\u6218\u3002", "method": "\u9996\u5148\u5f62\u5f0f\u5316\u9c81\u68d2\u6027\u7684\u6982\u5ff5\u548c\u6570\u5b66\u57fa\u7840\uff0c\u9610\u8ff0\u9c81\u68d2\u7edf\u8ba1\u3001\u4f18\u5316\u548c\u673a\u5668\u5b66\u4e60\u4e4b\u95f4\u7684\u89e3\u91ca\u548c\u5173\u7cfb\u3002\u7136\u540e\u7814\u7a76\u5173\u952e\u6280\u672f\uff0c\u5305\u62ec\u9c81\u68d2\u4f30\u8ba1\u4e0e\u6d4b\u8bd5\u3001\u5206\u5e03\u9c81\u68d2\u4f18\u5316\u3001\u6b63\u5219\u5316\u548c\u5bf9\u6297\u8bad\u7ec3\u3002\u6700\u540e\u4ee5\u65e0\u7ebf\u611f\u77e5\u4e0e\u901a\u4fe1\u4e3a\u5177\u4f53\u6846\u67b6\uff0c\u56de\u987e\u9488\u5bf9\u6a21\u578b\u5931\u914d\u3001\u6570\u636e\u7a00\u7f3a\u7b49\u95ee\u9898\u7684\u9c81\u68d2\u4fe1\u53f7\u5904\u7406\u89e3\u51b3\u65b9\u6848\u3002", "result": "\u6587\u7ae0\u7cfb\u7edf\u6027\u5730\u4ecb\u7ecd\u4e86\u9c81\u68d2\u6027\u7406\u8bba\u7684\u53d1\u5c55\u8109\u7edc\uff0c\u5c55\u793a\u4e86\u9c81\u68d2\u65b9\u6cd5\u5728\u65e0\u7ebf\u611f\u77e5\u4e0e\u901a\u4fe1\u4e2d\u7684\u5177\u4f53\u5e94\u7528\uff0c\u5305\u62ec\u9c81\u68d2\u6d4b\u8ddd\u5b9a\u4f4d\u3001\u6a21\u6001\u611f\u77e5\u3001\u4fe1\u9053\u4f30\u8ba1\u3001\u63a5\u6536\u5408\u5e76\u3001\u6ce2\u5f62\u8bbe\u8ba1\u548c\u8054\u90a6\u5b66\u4e60\u7b49\uff0c\u540c\u65f6\u8ba8\u8bba\u4e86\u9c81\u68d2\u6027\u5728\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\u7684\u4ee3\u4ef7\uff0c\u5982\u540d\u4e49\u6027\u80fd\u59a5\u534f\u548c\u989d\u5916\u8ba1\u7b97\u8d1f\u62c5\u3002", "conclusion": "\u901a\u8fc7\u4ee5\u65e0\u7ebf\u611f\u77e5\u4e0e\u901a\u4fe1\u4e3a\u53d9\u4e8b\u6846\u67b6\uff0c\u672c\u6587\u6210\u529f\u5730\u5c06\u9c81\u68d2\u6027\u7406\u8bba\u5f15\u5165\u4fe1\u53f7\u5904\u7406\u793e\u533a\uff0c\u5c55\u793a\u4e86\u9c81\u68d2\u7edf\u8ba1\u3001\u4f18\u5316\u548c\u673a\u5668\u5b66\u4e60\u65b9\u6cd5\u5728\u5e94\u5bf9\u73b0\u5b9e\u4e16\u754c\u4e0d\u786e\u5b9a\u6027\u95ee\u9898\u4e2d\u7684\u4ef7\u503c\u548c\u6f5c\u529b\uff0c\u4e3a\u76f8\u5173\u9886\u57df\u7684\u7814\u7a76\u548c\u5e94\u7528\u63d0\u4f9b\u4e86\u7cfb\u7edf\u7684\u7406\u8bba\u6307\u5bfc\u548c\u5b9e\u8df5\u53c2\u8003\u3002"}}
{"id": "2602.09910", "categories": ["eess.SP", "cs.IT"], "pdf": "https://arxiv.org/pdf/2602.09910", "abs": "https://arxiv.org/abs/2602.09910", "authors": ["Levi Bohnacker", "Ralf R. M\u00fcller"], "title": "Geometric Analysis of Blind User Identification for Massive MIMO Networks", "comment": null, "summary": "Applying Nearest Convex Hull Classification (NCHC) to blind user identification in a massive Multiple Input Multiple Output (MIMO) communications system is proposed. The method is blind in the way that the Base Station (BS) only requires a training sequence containing unknown data symbols obtained from the user without further knowledge on the channel, modulation, coding or even noise power. We evaluate the algorithm under the assumption of gaussian transmit signals using the non-rigorous replica method. To facilitate the computations the existence of an Operator Valued Free Fourier Transform is postulated, which is verified by Monte Carlo simulation. The replica computations are conducted in the large but finite system by applying saddle-point integration with inverse temperature $\u03b2$ as the large parameter. The classifier accuracy is estimated by gaussian approximation through moment-matching.", "AI": {"tldr": "\u63d0\u51fa\u5c06\u6700\u8fd1\u51f8\u5305\u5206\u7c7b\u5668\u5e94\u7528\u4e8e\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u7684\u76f2\u7528\u6237\u8bc6\u522b\uff0c\u4ec5\u9700\u672a\u77e5\u6570\u636e\u7b26\u53f7\u7684\u8bad\u7ec3\u5e8f\u5217\uff0c\u65e0\u9700\u4fe1\u9053\u3001\u8c03\u5236\u3001\u7f16\u7801\u6216\u566a\u58f0\u529f\u7387\u4fe1\u606f\u3002", "motivation": "\u5728\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u4e2d\u5b9e\u73b0\u76f2\u7528\u6237\u8bc6\u522b\uff0c\u51cf\u5c11\u5bf9\u7cfb\u7edf\u53c2\u6570\u7684\u4f9d\u8d56\uff0c\u4ec5\u57fa\u4e8e\u7528\u6237\u53d1\u9001\u7684\u672a\u77e5\u6570\u636e\u7b26\u53f7\u8fdb\u884c\u8bc6\u522b\uff0c\u63d0\u9ad8\u7cfb\u7edf\u7684\u7075\u6d3b\u6027\u548c\u5b9e\u7528\u6027\u3002", "method": "\u91c7\u7528\u6700\u8fd1\u51f8\u5305\u5206\u7c7b\u5668\uff0c\u5047\u8bbe\u9ad8\u65af\u53d1\u5c04\u4fe1\u53f7\uff0c\u4f7f\u7528\u975e\u4e25\u683c\u7684\u590d\u672c\u65b9\u6cd5\u5206\u6790\uff0c\u901a\u8fc7\u7b97\u5b50\u503c\u81ea\u7531\u5085\u91cc\u53f6\u53d8\u6362\u7b80\u5316\u8ba1\u7b97\uff0c\u5728\u5927\u4f46\u6709\u9650\u7cfb\u7edf\u4e2d\u5e94\u7528\u978d\u70b9\u79ef\u5206\uff0c\u901a\u8fc7\u9ad8\u65af\u8fd1\u4f3c\u548c\u77e9\u5339\u914d\u4f30\u8ba1\u5206\u7c7b\u5668\u51c6\u786e\u7387\u3002", "result": "\u901a\u8fc7\u590d\u672c\u8ba1\u7b97\u548c\u8499\u7279\u5361\u6d1b\u6a21\u62df\u9a8c\u8bc1\u4e86\u7b97\u5b50\u503c\u81ea\u7531\u5085\u91cc\u53f6\u53d8\u6362\u7684\u5b58\u5728\u6027\uff0c\u5e76\u4f30\u8ba1\u4e86\u5206\u7c7b\u5668\u7684\u8bc6\u522b\u51c6\u786e\u7387\u3002", "conclusion": "\u6700\u8fd1\u51f8\u5305\u5206\u7c7b\u5668\u53ef\u7528\u4e8e\u5927\u89c4\u6a21MIMO\u7cfb\u7edf\u7684\u76f2\u7528\u6237\u8bc6\u522b\uff0c\u4ec5\u9700\u672a\u77e5\u6570\u636e\u7b26\u53f7\u7684\u8bad\u7ec3\u5e8f\u5217\uff0c\u4e3a\u5b9e\u9645\u7cfb\u7edf\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u7684\u7528\u6237\u8bc6\u522b\u65b9\u6848\u3002"}}
{"id": "2602.09955", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09955", "abs": "https://arxiv.org/abs/2602.09955", "authors": ["Lie-Liang Yang"], "title": "Doppler Effect: Analyses and Applications in Wireless Sensing and Communications", "comment": "This document is a chapter of my next book to be published. If you have any comments, please email: lly@ecs.soton.ac.uk, which is highly appreciated", "summary": "This chapter is motivated by the need for a rigorous and comprehensive analysis of the Doppler effects encountered by electromagnetic and acoustic signals across a diverse spectrum of modern applications. These include land mobile communications, various Internet of Things (IoT) networks, machine-type communications (MTC), and various radar and satellite-based systems for navigation and sensing, as well as the emerging regime of integrated sensing and communications (ISAC). A wide array of kinematic profiles is investigated, ranging from uniform motion and constant acceleration to more complex general motion. Consequently, the multi-faceted factors influencing the Doppler shift are addressed in detail, encompassing classical kinematics, special and general relativity, atmospheric dynamics, and the properties of the propagation medium. This work is intended to establish a definitive theoretical foundation for both the general enthusiast and the specialized researcher seeking to master the complexities of signal frequency shifts in modern wireless sensing and communications systems.", "AI": {"tldr": "\u8be5\u7ae0\u8282\u5bf9\u7535\u78c1\u548c\u58f0\u5b66\u4fe1\u53f7\u5728\u73b0\u4ee3\u5e94\u7528\u4e2d\u7684\u591a\u666e\u52d2\u6548\u5e94\u8fdb\u884c\u4e86\u5168\u9762\u7406\u8bba\u5206\u6790\uff0c\u6db5\u76d6\u79fb\u52a8\u901a\u4fe1\u3001\u7269\u8054\u7f51\u3001\u96f7\u8fbe\u536b\u661f\u7cfb\u7edf\u7b49\u573a\u666f\uff0c\u5efa\u7acb\u4e86\u7edf\u4e00\u7684\u7406\u8bba\u6846\u67b6\u3002", "motivation": "\u73b0\u4ee3\u65e0\u7ebf\u4f20\u611f\u548c\u901a\u4fe1\u7cfb\u7edf\uff08\u5305\u62ec\u79fb\u52a8\u901a\u4fe1\u3001\u7269\u8054\u7f51\u3001\u673a\u5668\u7c7b\u578b\u901a\u4fe1\u3001\u96f7\u8fbe\u536b\u661f\u5bfc\u822a\u4ee5\u53ca\u65b0\u5174\u7684\u96c6\u6210\u4f20\u611f\u4e0e\u901a\u4fe1\uff09\u4e2d\uff0c\u4fe1\u53f7\u9891\u7387\u504f\u79fb\u73b0\u8c61\u65e5\u76ca\u590d\u6742\uff0c\u9700\u8981\u5efa\u7acb\u4e25\u8c28\u5168\u9762\u7684\u591a\u666e\u52d2\u6548\u5e94\u7406\u8bba\u5206\u6790\u6846\u67b6\u3002", "method": "\u7cfb\u7edf\u7814\u7a76\u591a\u79cd\u8fd0\u52a8\u5b66\u5256\u9762\uff08\u4ece\u5300\u901f\u8fd0\u52a8\u3001\u5300\u52a0\u901f\u8fd0\u52a8\u5230\u66f4\u590d\u6742\u7684\u4e00\u822c\u8fd0\u52a8\uff09\uff0c\u5e76\u8be6\u7ec6\u5206\u6790\u5f71\u54cd\u591a\u666e\u52d2\u9891\u79fb\u7684\u591a\u65b9\u9762\u56e0\u7d20\uff0c\u5305\u62ec\u7ecf\u5178\u8fd0\u52a8\u5b66\u3001\u72ed\u4e49\u4e0e\u5e7f\u4e49\u76f8\u5bf9\u8bba\u3001\u5927\u6c14\u52a8\u529b\u5b66\u548c\u4f20\u64ad\u4ecb\u8d28\u7279\u6027\u3002", "result": "\u5efa\u7acb\u4e86\u9002\u7528\u4e8e\u73b0\u4ee3\u65e0\u7ebf\u4f20\u611f\u548c\u901a\u4fe1\u7cfb\u7edf\u7684\u591a\u666e\u52d2\u6548\u5e94\u786e\u5b9a\u6027\u7406\u8bba\u57fa\u7840\uff0c\u4e3a\u4ece\u666e\u901a\u7231\u597d\u8005\u5230\u4e13\u4e1a\u7814\u7a76\u4eba\u5458\u63d0\u4f9b\u4e86\u638c\u63e1\u4fe1\u53f7\u9891\u7387\u504f\u79fb\u590d\u6742\u6027\u7684\u5b8c\u6574\u7406\u8bba\u6846\u67b6\u3002", "conclusion": "\u8be5\u5de5\u4f5c\u4e3a\u73b0\u4ee3\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u7684\u591a\u666e\u52d2\u6548\u5e94\u5206\u6790\u63d0\u4f9b\u4e86\u5168\u9762\u3001\u4e25\u8c28\u7684\u7406\u8bba\u57fa\u7840\uff0c\u6709\u52a9\u4e8e\u66f4\u597d\u5730\u7406\u89e3\u548c\u5904\u7406\u5404\u79cd\u5e94\u7528\u573a\u666f\u4e2d\u7684\u4fe1\u53f7\u9891\u7387\u504f\u79fb\u95ee\u9898\u3002"}}
{"id": "2602.09960", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.09960", "abs": "https://arxiv.org/abs/2602.09960", "authors": ["Arman Azizi", "Mostafa Rahmani Ghourtani", "Mustafa A. Kishk", "Hamed Ahmadi", "Arman Farhang"], "title": "HAPS-RIS and UAV Integrated Networks: A Unified Joint Multi-objective Framework", "comment": null, "summary": "Future 6G non-terrestrial networks aim to deliver ubiquitous connectivity to remote and undeserved regions, but unmanned aerial vehicle (UAV) base stations face fundamental challenges such as limited numbers and power budgets. To overcome these obstacles, high-altitude platform station (HAPS) equipped with a reconfigurable intelligent surface (RIS), so-called HAPS-RIS, is a promising candidate. We propose a novel unified joint multi-objective framework where UAVs and HAPS-RIS are fully integrated to extend coverage and enhance network performance. This joint multi-objective design maximizes the number of users served by the HAPS-RIS, minimizes the number of UAVs deployed and minimizes the total average UAV path loss subject to quality-of-service (QoS) and resource constraints. We propose a novel low-complexity solution strategy by proving the equivalence between minimizing the total average UAV path loss upper bound and k-means clustering, deriving a practical closed-form RIS phase-shift design, and introducing a mapping technique that collapses the combinatorial assignments into a zone radius and a bandwidth-portioning factor. Then, we propose a dynamic Pareto optimization technique to solve the transformed optimization problem. Extensive simulation results demonstrate that the proposed framework adapts seamlessly across operating regimes. A HAPS-RIS-only setup achieves full coverage at low data rates, but UAV assistance becomes indispensable as rate demands increase. By tuning a single bandwidth portioning factor, the model recovers UAV-only, HAPS-RIS-only and equal bandwidth portioning baselines within one formulation and consistently surpasses them across diverse rate requirements. The simulations also quantify a tangible trade-off between RIS scale and UAV deployment, enabling designers to trade increased RIS elements for fewer UAVs as service demands evolve.", "AI": {"tldr": "\u63d0\u51fa\u4e00\u4e2a\u7edf\u4e00\u7684\u591a\u76ee\u6807\u6846\u67b6\uff0c\u5c06\u65e0\u4eba\u673a\u548c\u914d\u5907RIS\u7684HAPS\u96c6\u6210\uff0c\u4ee5\u6700\u5927\u5316\u8986\u76d6\u7528\u6237\u6570\u3001\u6700\u5c0f\u5316\u65e0\u4eba\u673a\u90e8\u7f72\u6570\u91cf\u548c\u603b\u8def\u5f84\u635f\u8017\uff0c\u5e76\u901a\u8fc7\u4f4e\u590d\u6742\u5ea6\u7b97\u6cd5\u5b9e\u73b0\u52a8\u6001\u4f18\u5316\u3002", "motivation": "\u672a\u67656G\u975e\u5730\u9762\u7f51\u7edc\u9700\u8981\u4e3a\u504f\u8fdc\u5730\u533a\u63d0\u4f9b\u6cdb\u5728\u8fde\u63a5\uff0c\u4f46\u65e0\u4eba\u673a\u57fa\u7ad9\u9762\u4e34\u6570\u91cf\u548c\u529f\u7387\u9650\u5236\u3002\u914d\u5907\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\u7684\u9ad8\u7a7a\u5e73\u53f0\u7ad9(HAPS-RIS)\u662f\u89e3\u51b3\u8fd9\u4e9b\u6311\u6218\u7684\u6709\u524d\u666f\u65b9\u6848\u3002", "method": "\u63d0\u51fa\u8054\u5408\u591a\u76ee\u6807\u4f18\u5316\u6846\u67b6\uff0c\u901a\u8fc7\u8bc1\u660e\u603b\u5e73\u5747\u8def\u5f84\u635f\u8017\u4e0a\u754c\u6700\u5c0f\u5316\u4e0ek-means\u805a\u7c7b\u7684\u7b49\u4ef7\u6027\u3001\u63a8\u5bfc\u5b9e\u7528\u7684RIS\u76f8\u79fb\u95ed\u5f0f\u8bbe\u8ba1\u3001\u5f15\u5165\u6620\u5c04\u6280\u672f\u5c06\u7ec4\u5408\u5206\u914d\u7b80\u5316\u4e3a\u533a\u57df\u534a\u5f84\u548c\u5e26\u5bbd\u5206\u914d\u56e0\u5b50\uff0c\u5e76\u91c7\u7528\u52a8\u6001\u5e15\u7d2f\u6258\u4f18\u5316\u6280\u672f\u3002", "result": "\u4eff\u771f\u8868\u660e\u8be5\u6846\u67b6\u80fd\u81ea\u9002\u5e94\u4e0d\u540c\u5de5\u4f5c\u573a\u666f\uff1a\u4f4e\u6570\u636e\u901f\u7387\u65f6HAPS-RIS\u5355\u72ec\u5373\u53ef\u5b9e\u73b0\u5168\u8986\u76d6\uff0c\u9ad8\u901f\u7387\u9700\u6c42\u65f6\u65e0\u4eba\u673a\u8f85\u52a9\u53d8\u5f97\u5fc5\u8981\u3002\u901a\u8fc7\u8c03\u6574\u5355\u4e2a\u5e26\u5bbd\u5206\u914d\u56e0\u5b50\uff0c\u6a21\u578b\u53ef\u6062\u590d\u4e3a\u65e0\u4eba\u673a\u4e13\u7528\u3001HAPS-RIS\u4e13\u7528\u548c\u7b49\u5e26\u5bbd\u5206\u914d\u57fa\u7ebf\uff0c\u5e76\u5728\u5404\u79cd\u901f\u7387\u8981\u6c42\u4e0b\u8d85\u8d8a\u5b83\u4eec\u3002", "conclusion": "\u8be5\u6846\u67b6\u4e3a6G\u975e\u5730\u9762\u7f51\u7edc\u63d0\u4f9b\u4e86\u4e00\u79cd\u7075\u6d3b\u9ad8\u6548\u7684\u89e3\u51b3\u65b9\u6848\uff0c\u91cf\u5316\u4e86RIS\u89c4\u6a21\u4e0e\u65e0\u4eba\u673a\u90e8\u7f72\u4e4b\u95f4\u7684\u6743\u8861\uff0c\u4f7f\u8bbe\u8ba1\u8005\u80fd\u591f\u6839\u636e\u670d\u52a1\u9700\u6c42\u53d8\u5316\u5728\u589e\u52a0RIS\u5143\u7d20\u548c\u51cf\u5c11\u65e0\u4eba\u673a\u4e4b\u95f4\u8fdb\u884c\u6743\u8861\u3002"}}
{"id": "2602.10025", "categories": ["eess.SP"], "pdf": "https://arxiv.org/pdf/2602.10025", "abs": "https://arxiv.org/abs/2602.10025", "authors": ["Aymen Khaleel", "Aydin Sezgin"], "title": "RIS-Assisted Rank Enhancement With Commodity WiFi Transceivers: Real-World Experiments", "comment": "5 pages, 3 figures, 2 tables, submitted for publication", "summary": "Reconfigurable intelligent surfaces (RISs) are a promising enabling technology for the sixth-generation ($6$G) of wireless communications. RISs, thanks to their intelligent design, can reshape the wireless channel to provide favorable propagation conditions for information transfer. In this work, we experimentally investigate the potential of RISs to enhance the effective rank of multiple-input multiple-output (MIMO) channels, thereby improving spatial multiplexing capabilities. In our experiment, commodity WiFi transceivers are used, representing a practical MIMO system. In this context, we propose a passive beam-focusing technique to manipulate the propagation channel between each transmit-receive antenna pair and achieve a favorable propagation condition for rank improvement. The proposed algorithm is tested in two different channel scenarios: low and medium ranks. Experimental results show that, when the channel is rank-deficient, the RIS can significantly increase the rank by $112\\%$ from its default value without the RIS, providing a rank increment of $1.5$. When the rank has a medium value, a maximum of $61\\%$ enhancement can be achieved, corresponding to a rank increment of $1$. These results provide the first experimental evidence of RIS-driven rank manipulation with off-the-shelf WiFi hardware, offering practical insights into RIS deployment for spatial multiplexing gains.", "AI": {"tldr": "\u5b9e\u9a8c\u8bc1\u660eRIS\u53ef\u663e\u8457\u63d0\u5347MIMO\u4fe1\u9053\u6709\u6548\u79e9\uff0c\u5728\u4f4e\u79e9\u4fe1\u9053\u4e2d\u63d0\u5347112%\uff081.5\u4e2a\u79e9\uff09\uff0c\u4e2d\u7b49\u79e9\u4fe1\u9053\u4e2d\u63d0\u534761%\uff081\u4e2a\u79e9\uff09\uff0c\u4f7f\u7528\u5546\u7528WiFi\u786c\u4ef6\u9a8c\u8bc1\u4e86RIS\u5bf9\u7a7a\u95f4\u590d\u7528\u80fd\u529b\u7684\u589e\u5f3a\u6548\u679c\u3002", "motivation": "\u53ef\u91cd\u6784\u667a\u80fd\u8868\u9762\uff08RIS\uff09\u662f6G\u65e0\u7ebf\u901a\u4fe1\u7684\u5173\u952e\u4f7f\u80fd\u6280\u672f\uff0c\u80fd\u591f\u91cd\u5851\u65e0\u7ebf\u4fe1\u9053\u4ee5\u63d0\u4f9b\u6709\u5229\u7684\u4f20\u64ad\u6761\u4ef6\u3002\u672c\u7814\u7a76\u65e8\u5728\u901a\u8fc7\u5b9e\u9a8c\u9a8c\u8bc1RIS\u662f\u5426\u80fd\u591f\u589e\u5f3aMIMO\u4fe1\u9053\u7684\u6709\u6548\u79e9\uff0c\u4ece\u800c\u63d0\u5347\u7a7a\u95f4\u590d\u7528\u80fd\u529b\u3002", "method": "\u4f7f\u7528\u5546\u7528WiFi\u6536\u53d1\u5668\u6784\u5efa\u5b9e\u9645MIMO\u7cfb\u7edf\uff0c\u63d0\u51fa\u88ab\u52a8\u6ce2\u675f\u805a\u7126\u6280\u672f\u6765\u64cd\u7eb5\u6bcf\u4e2a\u53d1\u5c04-\u63a5\u6536\u5929\u7ebf\u5bf9\u4e4b\u95f4\u7684\u4f20\u64ad\u4fe1\u9053\uff0c\u5b9e\u73b0\u6709\u5229\u4e8e\u79e9\u63d0\u5347\u7684\u4f20\u64ad\u6761\u4ef6\u3002\u5728\u4f4e\u79e9\u548c\u4e2d\u7b49\u79e9\u4e24\u79cd\u4e0d\u540c\u4fe1\u9053\u573a\u666f\u4e0b\u6d4b\u8bd5\u7b97\u6cd5\u3002", "result": "\u5b9e\u9a8c\u7ed3\u679c\u663e\u793a\uff1a\u5f53\u4fe1\u9053\u79e9\u4e0d\u8db3\u65f6\uff0cRIS\u53ef\u5c06\u79e9\u4ece\u9ed8\u8ba4\u503c\uff08\u65e0RIS\u65f6\uff09\u63d0\u5347112%\uff0c\u76f8\u5f53\u4e8e\u79e9\u589e\u52a01.5\uff1b\u5f53\u4fe1\u9053\u5177\u6709\u4e2d\u7b49\u79e9\u65f6\uff0c\u6700\u5927\u53ef\u5b9e\u73b061%\u7684\u589e\u5f3a\uff0c\u5bf9\u5e94\u79e9\u589e\u52a01\u3002\u8fd9\u662f\u9996\u6b21\u4f7f\u7528\u73b0\u6210WiFi\u786c\u4ef6\u63d0\u4f9b\u7684RIS\u9a71\u52a8\u79e9\u64cd\u7eb5\u5b9e\u9a8c\u8bc1\u636e\u3002", "conclusion": "RIS\u80fd\u591f\u663e\u8457\u589e\u5f3aMIMO\u4fe1\u9053\u7684\u6709\u6548\u79e9\uff0c\u4ece\u800c\u63d0\u5347\u7a7a\u95f4\u590d\u7528\u80fd\u529b\u3002\u8be5\u7814\u7a76\u4e3aRIS\u90e8\u7f72\u4ee5\u5b9e\u73b0\u7a7a\u95f4\u590d\u7528\u589e\u76ca\u63d0\u4f9b\u4e86\u5b9e\u7528\u89c1\u89e3\uff0c\u8bc1\u660e\u4e86RIS\u5728\u5b9e\u9645\u65e0\u7ebf\u7cfb\u7edf\u4e2d\u7684\u6709\u6548\u6027\u3002"}}

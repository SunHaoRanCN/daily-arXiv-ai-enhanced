<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 11]
- [eess.AS](#eess.AS) [Total: 4]
- [cs.SD](#cs.SD) [Total: 5]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Boiling flow parameter estimation from boundary layer data](https://arxiv.org/abs/2602.10394)
*Jeffrey W. Utley,Gregery T. Buzzard,Charles A. Bouman,Matthew R. Kemnetz*

Main category: eess.SP

TL;DR: 提出一种从实测气动光学相位畸变数据估计沸腾流模拟参数的方法，能较好拟合时间统计特性但空间统计特性拟合不佳


<details>
  <summary>Details</summary>
Motivation: 大气湍流和气动光学效应导致光波相位畸变，降低飞机相干光传输接收效果。现有物理实验昂贵耗时，需要替代的模拟方法。沸腾流算法可生成合成相位畸变数据，但依赖Fried相干长度等物理参数，这些参数对气动光学效应定义不明确。

Method: 提出一种从实测气动光学相位畸变数据估计沸腾流参数的方法。算法通过拟合测量数据的空间和时间统计特性来估计参数。该方法计算效率高。

Result: 实验表明，合成相位屏斜率的时间功率谱密度与两个湍流边界层数据集的测量相位畸变合理匹配，误差在8-9%之间。但相位屏的Kolmogorov空间结构函数与测量相位畸变不匹配，误差超过28%。

Conclusion: 沸腾流参数可以合理拟合高度对流数据的时间统计特性，但无法拟合气动光学相位畸变的复杂空间统计特性。这表明沸腾流模型在空间统计特性方面存在局限性。

Abstract: Atmospheric turbulence and aero-optic effects cause phase aberrations in propagating light waves, thereby reducing effectiveness in transmitting and receiving coherent light from an aircraft. Existing optical sensors can measure the resulting phase aberrations, but the physical experiments required to induce these aberrations are expensive and time-intensive. Simulation methods could provide a less expensive alternative. For example, an existing simulation algorithm called boiling flow, which generalizes the Taylor frozen-flow method, can generate synthetic phase aberration data (i.e., phase screens) induced by atmospheric turbulence. However, boiling flow depends on physical parameters, such as the Fried coherence length r0, which are not well-defined for aero-optic effects. In this paper, we introduce a method to estimate the parameters of boiling flow from measured aero-optic phase aberration data. Our algorithm estimates these parameters to fit the spatial and temporal statistics of the measured data. This method is computationally efficient and our experiments show that the temporal power spectral density of the slopes of the synthetic phase screens reasonably matches that of the measured phase aberrations from two turbulent boundary layer data sets, with errors between 8-9%. However, the Kolmogorov spatial structure function of the phase screens does not match that of the measured phase aberrations, with errors above 28%. This suggests that, while the parameters of boiling flow can reasonably fit the temporal statistics of highly convective data, they cannot fit the complex spatial statistics of aero-optic phase aberrations.

</details>


### [2] [RadarEye: Robust Liquid Level Tracking Using mmWave Radar in Robotic Pouring](https://arxiv.org/abs/2602.10417)
*Hongyu Deng,He Chen*

Main category: eess.SP

TL;DR: RadarEye：基于毫米波雷达的实时液体液位估计系统，用于机器人倒水任务，在复杂光照和反射条件下优于视觉和超声波基线方法。


<details>
  <summary>Details</summary>
Motivation: 机器人倒水任务中，透明液体的感知面临挑战：镜面反射/折射效应和光照变化会降低视觉线索的可靠性，影响液位估计的准确性。

Method: RadarEye采用毫米波雷达信号处理流水线，包含两个核心模块：(1)高分辨率距离-角度波束成形模块用于液位感知；(2)基于物理模型的中途跟踪器，抑制多径效应，在倒水过程中保持对液体表面的锁定。

Result: 在真实机器人倒水实验中，RadarEye实现了0.35厘米的中位绝对高度误差，每次更新仅需0.62毫秒，显著优于视觉和超声波基线方法。

Conclusion: RadarEye为机器人倒水任务提供了一种鲁棒、低延迟的液位估计解决方案，能够有效应对视觉系统难以处理的复杂光学效应。

Abstract: Transparent liquid manipulation in robotic pouring remains challenging for perception systems: specular/refraction effects and lighting variability degrade visual cues, undermining reliable level estimation. To address this challenge, we introduce RadarEye, a real-time mmWave radar signal processing pipeline for robust liquid level estimation and tracking during the whole pouring process. RadarEye integrates (i) a high-resolution range-angle beamforming module for liquid level sensing and (ii) a physics-informed mid-pour tracker that suppresses multipath to maintain lock on the liquid surface despite stream-induced clutter and source container reflections. The pipeline delivers sub-millisecond latency. In real-robot water-pouring experiments, RadarEye achieves a 0.35 cm median absolute height error at 0.62 ms per update, substantially outperforming vision and ultrasound baselines.

</details>


### [3] [Nonparametric Variational Bayesian Learning for Channel Estimation with OTFS Modulation](https://arxiv.org/abs/2602.10438)
*Chong Cao,Zhuyu Liu,Zheng Dong,Yong Zhou,He Chen*

Main category: eess.SP

TL;DR: 提出一种基于非参数贝叶斯学习的OTFS信道估计框架，利用棍棒过程自动推断多径分量数量并分配簇，通过高斯混合分布建模簇内信道系数，设计有效剪枝准则消除虚假多径分量。


<details>
  <summary>Details</summary>
Motivation: 现有OTFS信道估计方法忽视了实际CDL信道中的结构化稀疏性和聚类特性，导致在实际系统中性能下降。需要一种能够自动推断多径分量数量并捕获复杂衰落统计特性的方法。

Method: 提出非参数贝叶斯学习框架：1）引入棍棒过程自动推断多径分量数量并将每条路径分配到相应簇；2）使用高斯混合分布建模每个簇内的信道系数以捕获复杂衰落统计；3）设计有效剪枝准则消除虚假多径分量。

Result: 仿真结果表明，所提方法在归一化均方误差方面优于现有方法，同时提高了估计精度并降低了计算复杂度。

Conclusion: 该NPBL框架能够有效处理OTFS系统中的CDL信道估计问题，通过自动推断多径结构和建模复杂衰落统计，在实际高移动性场景中展现出优越性能。

Abstract: Orthogonal time frequency space (OTFS) modulation has demonstrated significant advantages in high-mobility scenarios in future 6G networks. However, existing channel estimation methods often overlook the structured sparsity and clustering characteristics inherent in realistic clustered delay line (CDL) channels, leading to degraded performance in practical systems. To address this issue, we propose a novel nonparametric Bayesian learning (NPBL) framework for OTFS channel estimation. Specifically, a stick-breaking process is introduced to automatically infer the number of multipath components and assign each path to its corresponding cluster. The channel coefficients within each cluster are modeled by a Gaussian mixture distribution to capture complex fading statistics. Furthermore, an effective pruning criterion is designed to eliminate spurious multipath components, thereby enhancing estimation accuracy and reducing computational complexity. Simulation results demonstrate that the proposed method achieves superior performance in terms of normalized mean squared error compared to existing methods.

</details>


### [4] [Clutter-Aware Integrated Sensing and Communication: Models, Methods, and Future Directions](https://arxiv.org/abs/2602.10537)
*Rang Liu,Peishi Li,Ming Li,A. Lee Swindlehurst*

Main category: eess.SP

TL;DR: 该论文综述了宽带MIMO-OFDM ISAC系统中的杂波问题，包括冷热杂波建模、统计特性分析、接收端抑制方法以及收发器协同设计，旨在提升下一代网络的杂波适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在宽带散射丰富的ISAC环境中，杂波（包括环境反射的"冷杂波"和外部干扰引起的"热杂波"）往往主导弱目标反射，成为可靠感知的基本瓶颈，需要系统性的解决方案。

Method: 建立统一的宽带MIMO-OFDM信号模型捕获时空频域的杂波特性；采用多级杂波表征（幅度统计、鲁棒SIRV建模、结构化协方差表示）；总结时域和空域抑制方法（STAP/SFTAP扩展）；提出基于通信QoS约束的波束赋形和波形优化协同设计。

Result: 提供了全面的杂波建模框架和抑制技术综述，为不同波形和干扰条件下的技术选择提供指导，并展示了通过收发器协同设计实现主动杂波规避的可行性。

Conclusion: 需要进一步研究环境自适应和杂波鲁棒的ISAC技术，以应对下一代网络中的挑战，包括更智能的杂波感知和主动规避策略。

Abstract: Integrated sensing and communication (ISAC) can substantially improve spectral, hardware, and energy efficiency by unifying radar sensing and data communications. In wideband and scattering-rich environments, clutter often dominates weak target reflections and becomes a fundamental bottleneck for reliable sensing. Practical ISAC clutter includes "cold" clutter arising from environmental backscatter of the probing waveform, and "hot" clutter induced by external interference and reflections from the environment whose statistics can vary rapidly over time. In this article, we develop a unified wideband multiple-input multiple-output orthogonal frequency-division multiplexing (MIMO-OFDM) signal model that captures both clutter types across the space, time, and frequency domains. Building on this model, we review clutter characterization at multiple levels, including amplitude statistics, robust spherically invariant random vector (SIRV) modeling, and structured covariance representations suitable for limited-snapshot regimes. We then summarize receiver-side suppression methods in the temporal and spatial domains, together with extensions to space-time adaptive processing (STAP) and space-frequency-time adaptive processing (SFTAP), and we provide guidance on selecting techniques under different waveform and interference conditions. To move beyond reactive suppression, we discuss clutter-aware transceiver co-design that couples beamforming and waveform optimization with practical communication quality-of-service (QoS) constraints to enable proactive clutter avoidance. We conclude with open challenges and research directions toward environment-adaptive and clutter-resilient ISAC for next-generation networks.

</details>


### [5] [Transfer to Sky: Unveil Low-Altitude Route-Level Radio Maps via Ground Crowdsourced Data](https://arxiv.org/abs/2602.10736)
*Wenlihan Lu,Huacong Chen,Ruiyang Duan,Weijie Yuan,Shijian Gao*

Main category: eess.SP

TL;DR: 提出基于迁移学习的高保真路线级无线电地图预测框架，利用地面众包信号作为辅助监督，通过仿真学习传播先验、对抗对齐特征空间，在真实无人机测量上微调，显著提升路线RSRP预测精度。


<details>
  <summary>Details</summary>
Motivation: 低空经济发展依赖无人机可靠蜂窝连接，但预飞行规划中预测通信链路质量面临挑战，现有无线电地图方法因测量稀疏而效果不佳。

Method: 提出迁移学习框架：1) 从仿真中学习通用传播先验；2) 使用对抗对齐缩小地面与空中数据特征空间差距；3) 在有限的真实无人机测量上进行微调。

Result: 在美团真实数据集上的实验表明，该方法在预测路线RSRP方面比最先进基线方法准确率提高50%以上。

Conclusion: 该框架通过利用丰富的地面众包信号作为辅助监督，有效解决了无人机通信链路质量预测中的测量稀疏问题，为低空经济提供了可靠的通信规划工具。

Abstract: The expansion of the low-altitude economy is contingent on reliable cellular connectivity for unmanned aerial vehicles (UAVs). A key challenge in pre-flight planning is predicting communication link quality along proposed and pre-defined routes, a task hampered by sparse measurements that render existing radio map methods ineffective. This paper introduces a transfer learning framework for high-fidelity route-level radio map prediction. Our key insight is to leverage abundant crowdsourced ground signals as auxiliary supervision. To bridge the significant domain gap between ground and aerial data and address spatial sparsity, our framework learns general propagation priors from simulation, performs adversarial alignment of the feature spaces, and is fine-tuned on limited real UAV measurements. Extensive experiments on a real-world dataset from Meituan show that our method achieves over 50% higher accuracy in predicting Route RSRP compared to state-of-the-art baselines.

</details>


### [6] [Stochastic Design of Active RIS-Assisted Satellite Downlinks under Interference, Folded Noise, and EIRP Constraints](https://arxiv.org/abs/2602.10742)
*Muhammad Khalil,Ke Wang,Jinho Choi*

Main category: eess.SP

TL;DR: 本文为主动可重构智能表面(RIS)辅助的卫星下行链路开发了一个随机可靠性框架，通过联合优化RIS配置和放大增益来保证目标中断概率，同时考虑硬件约束和干扰影响。


<details>
  <summary>Details</summary>
Motivation: 主动RIS可以缓解卫星下行链路中被动反射的双重衰落损耗，但其性能受到随机同信道干扰、增益相关放大器噪声和监管发射约束的限制。需要一种能够保证可靠性的设计方法。

Method: 1) 建立随机可靠性框架，将期望信道、干扰信道、接收机噪声和RIS放大器噪声建模为随机变量；2) 提出机会约束最大SINR设计，联合优化二进制RIS配置和公共放大增益；3) 使用样本平均近似(SAA)处理机会约束，通过混合整数二阶锥规划(MISOCP)和二分搜索求解；4) 基于特征值和l1-范数界推导SINR包络，提供可解释的性能限制。

Result: 1) 揭示了主动RIS存在有限高增益SINR上限；2) 提出的设计方法能够在硬件约束下保证目标中断概率；3) 推导的SINR包络紧密地界定了模拟SINR，再现了预测的饱和行为；4) 蒙特卡洛验证了方法在现实随机性和硬件约束下的可靠性。

Conclusion: 本文提供了一个可直接求解的、以可靠性为目标的设计方法，能够在实际干扰和硬件约束下保证卫星下行链路的性能可靠性，为主动RIS系统设计提供了实用工具。

Abstract: Active reconfigurable intelligent surfaces (RISs) can mitigate the double-fading loss of passive reflection in satellite downlinks. However, their gains are limited by random co-channel interference, gain-dependent amplifier noise, and regulatory emission constraints. This paper develops a stochastic reliability framework for active RIS-assisted satellite downlinks by modeling the desired and interfering channels, receiver noise, and RIS amplifier noise as random variables. The resulting instantaneous signal-to-interference-plus-noise ratio (SINR) model explicitly captures folded cascaded amplifier noise and reveals a finite high-gain SINR ceiling.
  To guarantee a target outage level, we formulate a chance-constrained max-SINR design that jointly optimizes the binary RIS configuration and a common amplification gain. The chance constraint is handled using a sample-average approximation (SAA) with a violation budget. The resulting feasibility problem is solved as a mixed-integer second-order cone program (MISOCP) within a bisection search over the SINR threshold. Practical implementation is enforced by restricting the gain to an admissible range determined by small-signal stability and effective isotropic radiated power (EIRP) limits.
  We also derive realization-wise SINR envelopes based on eigenvalue and l1-norm bounds, which provide interpretable performance limits and fast diagnostics. Monte Carlo results show that these envelopes tightly bound the simulated SINR, reproduce the predicted saturation behavior, and quantify performance degradation as interference increases. Overall, the paper provides a solver-ready, reliability-targeting design methodology whose achieved reliability is validated through out-of-sample Monte Carlo testing under realistic randomness and hardware constraints.

</details>


### [7] [Constellation Design for Robust Interference Mitigation](https://arxiv.org/abs/2602.10767)
*Athanasios T. Papadopoulos,Thrassos K. Oikonomou,Dimitrios Tyrovolas,Sotiris A. Tegos,Panagiotis D. Diamantoulakis,Panagiotis Sarigiannidis,George K. Karagiannidis*

Main category: eess.SP

TL;DR: 论文研究了Nakagami-m干扰下的单载波通信系统符号检测，提出了ML-G检测器并优化了星座设计，相比传统方法显著降低了误码率。


<details>
  <summary>Details</summary>
Motivation: 传统基于高斯噪声模型的检测方法不适用于具有Nakagami-m统计特性的加性干扰环境，这种干扰的随机幅度和非均匀相位会改变最优判决区域结构，导致传统欧氏距离检测器性能下降。

Method: 提出了最大似然高斯相位近似（ML-G）检测器，这是一种低复杂度检测规则，能准确近似最大似然检测；并在此基础上研究了干扰感知检测下的星座设计，通过优化问题寻找最小化误码率的符号布局。

Result: ML-G检测器能显著降低误码率，特别是在强干扰场景下；优化得到的星座具有非标准和非对称结构，能自适应干扰环境；仿真结果显示相比基准方案有明显性能增益。

Conclusion: 针对Nakagami-m干扰环境，ML-G检测器和干扰感知星座设计能有效提升单载波通信系统的符号检测性能，为实际系统提供了可行的解决方案。

Abstract: This paper investigates symbol detection for single-carrier communication systems operating in the presence of additive interference with Nakagami-m statistics. Such interference departs from the assumptions underlying conventional detection methods based on Gaussian noise models and leads to detection mismatch that fundamentally affects symbol-level performance. In particular, the presence of random interference amplitude and non-uniform phase alters the structure of the optimal decision regions and renders standard Euclidean distance-based detectors suboptimal. To address this challenge, we develop the maximum-likelihood Gaussian-phase approximate (ML-G) detector, a low-complexity detection rule that accurately approximates maximum-likelihood detection while remaining suitable for practical implementation. The proposed detector explicitly incorporates the statistical properties of the interference and induces decision regions that differ significantly from those arising under conventional metrics. Building on the ML-G framework, we further investigate constellation design under interference-aware detection and formulate an optimization problem that seeks symbol placements that minimize the symbol error probability subject to an average energy constraint. The resulting constellations are obtained numerically and adapt to the interference environment, exhibiting non-standard and asymmetric structures as interference strength increases. Simulation results demonstrate clear symbol error probability gains over established benchmark schemes across a range of interference conditions, particularly in scenarios with dominant additive interference.

</details>


### [8] [Bayesian Signal Component Decomposition via Diffusion-within-Gibbs Sampling](https://arxiv.org/abs/2602.10792)
*Yi Zhang,Rui Guo,Yonina C. Eldar*

Main category: eess.SP

TL;DR: 提出DiG采样器：结合Gibbs采样与PnP扩散先验的贝叶斯信号分量分解框架，支持模型驱动与数据驱动先验的统一融合，无需重新训练即可灵活组合分量先验。


<details>
  <summary>Details</summary>
Motivation: 信号处理中，传感器数据通常是多个分量的噪声线性叠加，准确估计感兴趣分量是关键的预处理步骤。现有方法在融合模型驱动和数据驱动先验知识方面存在局限。

Method: 开发贝叶斯信号分量分解框架，结合Gibbs采样与PnP扩散先验，从后验分布中抽取分量样本。支持模型驱动和数据驱动先验的统一融合，允许分量先验分别学习后灵活组合。

Result: 在适当假设下，DiG采样器可证明从后验分布产生样本。数值实验表明，该方法在性能上优于现有方法，特别在利用测量模型结构方面表现更好。

Conclusion: DiG框架为信号分量分解提供了灵活强大的贝叶斯解决方案，统一了模型驱动和数据驱动先验，支持分量先验的分离学习和灵活组合，在理论和实验上均表现出优越性。

Abstract: In signal processing, the data collected from sensing devices is often a noisy linear superposition of multiple components, and the estimation of components of interest constitutes a crucial pre-processing step. In this work, we develop a Bayesian framework for signal component decomposition, which combines Gibbs sampling with plug-and-play (PnP) diffusion priors to draw component samples from the posterior distribution. Unlike many existing methods, our framework supports incorporating model-driven and data-driven prior knowledge into the diffusion prior in a unified manner. Moreover, the proposed posterior sampler allows component priors to be learned separately and flexibly combined without retraining. Under suitable assumptions, the proposed DiG sampler provably produces samples from the posterior distribution. We also show that DiG can be interpreted as an extension of a class of recently proposed diffusion-based samplers, and that, for suitable classes of sensing operators, DiG better exploits the structure of the measurement model. Numerical experiments demonstrate the superior performance of our method over existing approaches.

</details>


### [9] [Fluid-Antenna-Enabled Integrated Bistatic Sensing and Backscatter Communication Systems](https://arxiv.org/abs/2602.10958)
*A. Abdelaziz Salem,Saeed Abdallah,Khawla Alnajjar,Mahmoud A. Albreem,Mohamed Saad,Hayssam Dahrouj,Hesham Elsawy*

Main category: eess.SP

TL;DR: 该论文研究了一种基于流体天线的集成双基地传感与反向散射通信系统，通过联合优化基站波束成形、传感协方差矩阵、读取器接收波束成形、标签反射系数和流体天线位置，在满足通信、反向散射、传感、能量收集和天线几何约束的同时最小化发射功率。


<details>
  <summary>Details</summary>
Motivation: 未来网络需要同时支持连接性、能量传输和环境感知，但现有系统面临强自干扰、远近效应和多信号干扰等问题。流体天线提供的额外空间自由度可以重塑多跳信道，为解决这些挑战提供了新途径。

Method: 提出交替优化块坐标框架，将非凸问题分解为四个可处理的子问题，分别使用半定松弛、主最小化和逐次凸逼近等方法求解，联合优化基站信息波束成形器、传感协方差矩阵、读取器接收波束成形器、标签反射系数和流体天线位置。

Result: 数值结果显示，相比固定位置天线和零迫基线，所提方法分别实现了约13.7%和54.5%的发射功率节省，显著提升了系统性能。

Conclusion: 流体天线通过提供额外的空间自由度，有效解决了集成双基地传感与反向散射通信系统中的远近效应和多信号干扰问题，在满足多样化服务质量约束的同时显著降低了发射功率需求。

Abstract: This paper studies a fluid-antenna-enabled integrated bistatic sensing and backscatter communication system for future networks where connectivity, power delivery, and environmental awareness are jointly supported by the same infrastructure. A multi-antenna base station (BS) with transmitting fluid antennas serves downlink users, energizes passive tags, and illuminates radar targets, while a spatially separated multi-antenna reader decodes tag backscatter and processes radar echoes to avoid the strong self-interference that would otherwise obscure weak returns at the BS. The coexistence of tags and targets, however, induces severe near--far disparities and multi-signal interference, which can be mitigated by fluid antennas through additional spatial degrees of freedom that reshape the multi-hop channels. We formulate a transmit-power minimization problem that jointly optimizes the BS information beamformers, sensing covariance matrix, reader receive beamformers, tag reflection coefficients, and fluid-antenna (FA) positions under heterogeneous quality of service constraints for communication, backscatter, and sensing, as well as energy-harvesting and FA geometry requirements. To tackle the resulting non-convex problem, we develop an alternating-optimization block-coordinate framework that solves four tractable subproblems using semidefinite relaxation, majorization--minimization, and successive convex approximation. Numerical results show consistent transmit-power savings over fixed-position antennas and zero-forcing baselines, achieving about 13.7% and 54.5% reductions, respectively.

</details>


### [10] [Physically Consistent Evaluation of Commonly Used Near-Field Models](https://arxiv.org/abs/2602.10976)
*Georg Schwan,Alexander Stutz-Tirri,Christoph Studer*

Main category: eess.SP

TL;DR: 论文提出了一种物理一致的近场模型，用于评估现有简化模型的有效性，发现常用模型对基本波束聚焦足够，但无法准确预测反射结构的旁瓣和频率依赖性。


<details>
  <summary>Details</summary>
Motivation: 当前近场多天线无线通信研究中，大多数文献使用的天线和反射结构模型过于简化，这些简化模型在实际系统中的有效性尚不明确。

Method: 引入了一种物理一致的近场模型，并使用该模型来评估常用的简化模型。

Result: 结果表明，常用模型对于基本的波束聚焦是足够的，但无法准确预测反射结构的旁瓣和频率依赖性。

Conclusion: 需要更精确的物理模型来准确预测近场通信中反射结构的旁瓣特性和频率响应。

Abstract: Near-field multi-antenna wireless communication has attracted growing research interest in recent years. Despite this development, most of the current literature on antennas and reflecting structures relies on simplified models, whose validity for real systems remains unclear. In this paper, we introduce a physically consistent near-field model, which we use to evaluate commonly used models. Our results indicate that common models are sufficient for basic beamfocusing, but fail to accurately predict the sidelobes and frequency dependence of reflecting structures.

</details>


### [11] [Reed-Muller Error-Correction Code Encoder for SFQ-to-CMOS Interface Circuits](https://arxiv.org/abs/2602.11140)
*Yerzhan Mustafa,Berker Peköz,Selçuk Köse*

Main category: eess.SP

TL;DR: 设计并分析了一种基于SFQ逻辑的轻量级硬件高效RM(1,3)编码器，用于超导数字电子到CMOS电路的数据传输错误校正


<details>
  <summary>Details</summary>
Motivation: 超导数字电子（如SFQ逻辑）到半导体（CMOS）电路的数据传输容易因磁通捕获、工艺参数变化和制造缺陷而产生比特错误，需要高效的错误校正方案

Method: 采用Reed-Muller码RM(1,3)编码器，将4位消息转换为8位码字，使用MIT-LL SFQ5ee工艺和SuperTools/ColdFlux RSFQ单元库设计，建立JoSIM模拟器和MATLAB脚本集成的仿真框架

Result: 在±20%工艺参数变化下，编码器将无错误概率提高6.7%；在±15%及以下工艺变化时，能以至少99.1%概率校正所有错误；同时研究了开路故障等制造缺陷的影响

Conclusion: 提出的RM(1,3)编码器为SFQ到CMOS数据传输提供了有效的错误校正解决方案，显著提高了系统可靠性，特别是在工艺参数变化环境下表现优异

Abstract: Data transmission from superconducting digital electronics such as single flux quantum (SFQ) logic to semiconductor (CMOS) circuits is subject to bit errors due to, e.g., flux trapping, process parameter variations (PPV), and fabrication defects. In this paper, a lightweight hardware-efficient error-correction code encoder is designed and analyzed. Particularly, a Reed-Muller code RM(1,3) encoder is implemented with SFQ digital logic. The proposed RM(1,3) encoder converts a 4-bit message into an 8-bit codeword and can detect and correct up to 3- and 1-bit errors, respectively. This encoder circuit is designed using MIT-LL SFQ5ee process and SuperTools/ColdFlux RSFQ cell library. A simulation framework integrating JoSIM simulator and MATLAB script for automated data collection and analysis, is proposed to study the performance of RM(1,3) encoder. The proposed encoder improves the probability of having no bit errors by 6.7% as compared to an encoder-less design under $\pm20\%$ PPV. With $\pm15\%$ and lower PPV, the proposed encoder could correct all errors with at least 99.1% probability. The impact of fabrication defects such as open circuit faults on the encoder circuit is also studied using the proposed framework.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [12] [AudioRAG: A Challenging Benchmark for Audio Reasoning and Information Retrieval](https://arxiv.org/abs/2602.10656)
*Jingru Lin,Chen Zhang,Tianrui Wang,Haizhou Li*

Main category: eess.AS

TL;DR: 提出AudioRAG基准测试，评估音频语言模型在真实网络环境中的信息检索增强推理能力，发现现有模型表现不佳，并提出代理式增强基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有音频语言模型基准主要关注内部知识推理，忽略了需要外部信息接地的真实场景。需要填补这一空白，评估模型在真实网络环境中的检索增强音频推理能力。

Method: 提出AudioRAG基准，包含LLM生成和人工标注的问答对，用于评估音频推理与信息检索的结合。同时提出集成音频推理与检索增强生成的代理式流程作为基线方法。

Result: 评估显示即使最先进的音频语言模型也难以回答这些需要外部信息的问题。提出的代理式流程为未来研究提供了更强的基线。

Conclusion: AudioRAG基准填补了现有评估的空白，揭示了音频语言模型在真实世界检索增强推理方面的不足，提出的代理式方法为改进提供了方向。

Abstract: Due to recent advancements in Large Audio-Language Models (LALMs) that demonstrate remarkable performance across a range of sound-, speech- and music-related tasks, there is a growing interest in proposing benchmarks to assess these models. Existing benchmarks generally focus only on reasoning with internal knowledge, neglecting real-world scenarios that require external information grounding. To bridge this gap, we introduce AudioRAG, a novel benchmark designed to evaluate audio-based reasoning augmented by information retrieval in realistic web environments. This benchmark comprises both LLM-generated and manually curated question-answer pairs. Our evaluations reveal that even the state-of-the-art LALMs struggle to answer these questions. We therefore propose an agentic pipeline that integrates audio reasoning with retrieval-augmented generation, providing a stronger baseline for future research.

</details>


### [13] [From Diet to Free Lunch: Estimating Auxiliary Signal Properties using Dynamic Pruning Masks in Speech Enhancement Networks](https://arxiv.org/abs/2602.10666)
*Riccardo Miccini,Clément Laroche,Tobias Piechowiak,Xenofon Fafoutis,Luca Pezzarossa*

Main category: eess.AS

TL;DR: 利用动态通道剪枝(DynCP)模型的内部剪枝掩码来估计语音信号属性，无需额外模型，实现高效语音增强与多任务预测


<details>
  <summary>Details</summary>
Motivation: 语音增强设备通常需要辅助模块（如VAD、SNR估计、声学场景分类）来实现上下文感知，但部署额外模型计算成本高，云端推理又存在延迟和隐私问题。现有DynCP方法已用于降低计算量，本研究探索是否可以从其内部剪枝掩码中提取有用信号属性，从而消除对单独模型的需求。

Method: 利用动态通道剪枝(DynCP)模型的内部剪枝掩码作为特征，构建简单可解释的预测器来估计语音信号属性。通过分析DynCP模型在剪枝过程中产生的掩码模式，提取可用于下游任务的信息。

Result: 使用简单预测器实现了：VAD准确率93%，噪声分类准确率84%，F0估计R²为0.86。二进制掩码预测可简化为加权求和，计算开销极小。

Conclusion: 本研究通过下游预测任务揭示了DynCP模型的学习行为，同时将DynCP重新定位为高效语音增强和信号属性估计的综合解决方案，无需额外模型即可实现多任务处理。

Abstract: Speech Enhancement (SE) in audio devices is often supported by auxiliary modules for Voice Activity Detection (VAD), SNR estimation, or Acoustic Scene Classification to ensure robust context-aware behavior and seamless user experience. Just like SE, these tasks often employ deep learning; however, deploying additional models on-device is computationally impractical, whereas cloud-based inference would introduce additional latency and compromise privacy. Prior work on SE employed Dynamic Channel Pruning (DynCP) to reduce computation by adaptively disabling specific channels based on the current input. In this work, we investigate whether useful signal properties can be estimated from these internal pruning masks, thus removing the need for separate models. We show that simple, interpretable predictors achieve up to 93% accuracy on VAD, 84% on noise classification, and an R2 of 0.86 on F0 estimation. With binary masks, predictions reduce to weighted sums, inducing negligible overhead. Our contribution is twofold: on one hand, we examine the emergent behavior of DynCP models through the lens of downstream prediction tasks, to reveal what they are learning; on the other, we repurpose and re-propose DynCP as a holistic solution for efficient SE and simultaneous estimation of signal properties.

</details>


### [14] [RE-LLM: Refining Empathetic Speech-LLM Responses by Integrating Emotion Nuance](https://arxiv.org/abs/2602.10716)
*Jing-Han Chen,Bo-Hao Su,Ya-Tse Wu,Chi-Chun Lee*

Main category: eess.AS

TL;DR: RE-LLM是一种融合语音和维度情感嵌入的语音大语言模型，通过辅助学习显著提升了AI的共情能力和情感探索能力，在多个数据集上取得了显著的情感理解和共情响应生成改进。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的发展，人机交互中的共情变得至关重要。现有研究主要关注情感反射，但情感探索这一更深层次互动的关键要素却被忽视。传统LLM仅依赖文本，无法捕捉丰富的情感细微差别，因此需要整合语音信息来提升情感理解能力。

Method: 提出RE-LLM（语音大语言模型），整合维度情感嵌入和辅助学习。该方法将语音信息与LLM结合，通过维度情感表示来捕捉更丰富的情感细微差别，采用辅助学习策略来增强模型的情感探索能力。

Result: 在三个数据集（ESD、IEMOCAP、MSP-PODCAST）上均取得显著改进：情感反应分数相对提升14.79%（相比文本基线）和6.76%（相比语音基线）；情感探索分数大幅提升（最高达139.28%）；语音情感识别准确率提升2.3%-6.9%。所有改进均具有统计显著性。

Conclusion: RE-LLM通过整合语音信息和维度情感嵌入，显著增强了AI的情感理解和共情响应生成能力，特别是在情感探索方面取得了突破性进展，为人机交互中的深度情感互动提供了有效解决方案。

Abstract: With generative AI advancing, empathy in human-AI interaction is essential. While prior work focuses on emotional reflection, emotional exploration, key to deeper engagement, remains overlooked. Existing LLMs rely on text which captures limited emotion nuances. To address this, we propose RE-LLM, a speech-LLM integrating dimensional emotion embeddings and auxiliary learning. Experiments show statistically significant gains in empathy metrics across three datasets. RE-LLM relatively improves the Emotional Reaction score by 14.79% and 6.76% compared to text-only and speech-LLM baselines on ESD. Notably, it raises the Exploration score by 35.42% and 3.91% on IEMOCAP, 139.28% and 9.83% on ESD, and 60.95% and 22.64% on MSP-PODCAST. It also boosts unweighted accuracy by 5.4% on IEMOCAP, 2.3% on ESD, and 6.9% on MSP-PODCAST in speech emotion recognition. These results highlight the enriched emotional understanding and improved empathetic response generation of RE-LLM.

</details>


### [15] [Self-Supervised Learning for Speaker Recognition: A study and review](https://arxiv.org/abs/2602.10829)
*Theo Lepage,Reda Dehak*

Main category: eess.AS

TL;DR: 该论文系统综述了自监督学习在说话人识别中的应用，对比了SimCLR、MoCo、DINO等框架，发现DINO性能最佳但超参数敏感，SimCLR和MoCo更稳健。


<details>
  <summary>Details</summary>
Motivation: 监督学习依赖大量人工标注数据，成本高且泛化能力有限。自监督学习利用无标注数据学习表征，在语音识别中已有广泛应用，但在说话人识别领域研究仍处于早期阶段，需要系统性的评估和比较。

Method: 1) 描述计算机视觉中发展的SSL框架（SimCLR、MoCo、DINO）及其在说话人识别中的适配；2) 综述文献中基于这些框架的SSL方法；3) 系统性评估：研究SSL主要超参数影响、分析SSL组件作用（数据增强、投影器、正样本采样）、在域内和域外数据上评估性能。

Result: DINO在下游任务中表现最佳，能有效建模说话人内部变异性，但对超参数和训练条件高度敏感；SimCLR和MoCo提供了稳健的替代方案，能有效捕捉说话人间变异性，且不易崩溃。提供了文献中SSL方法的全面比较。

Conclusion: 自监督学习在说话人识别中具有巨大潜力，DINO虽性能优越但需精细调参，SimCLR和MoCo更实用稳健。该工作旨在突出该领域的最新趋势和进展，识别当前挑战，为未来研究提供指导。

Abstract: Deep learning models trained in a supervised setting have revolutionized audio and speech processing. However, their performance inherently depends on the quantity of human-annotated data, making them costly to scale and prone to poor generalization under unseen conditions. To address these challenges, Self-Supervised Learning (SSL) has emerged as a promising paradigm, leveraging vast amounts of unlabeled data to learn relevant representations. The application of SSL for Automatic Speech Recognition (ASR) has been extensively studied, but research on other downstream tasks, notably Speaker Recognition (SR), remains in its early stages. This work describes major SSL instance-invariance frameworks (e.g., SimCLR, MoCo, and DINO), initially developed for computer vision, along with their adaptation to SR. Various SSL methods for SR, proposed in the literature and built upon these frameworks, are also presented. An extensive review of these approaches is then conducted: (1) the effect of the main hyperparameters of SSL frameworks is investigated; (2) the role of SSL components is studied (e.g., data-augmentation, projector, positive sampling); and (3) SSL frameworks are evaluated on SR with in-domain and out-of-domain data, using a consistent experimental setup, and a comprehensive comparison of SSL methods from the literature is provided. Specifically, DINO achieves the best downstream performance and effectively models intra-speaker variability, although it is highly sensitive to hyperparameters and training conditions, while SimCLR and MoCo provide robust alternatives that effectively capture inter-speaker variability and are less prone to collapse. This work aims to highlight recent trends and advancements, identifying current challenges in the field.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [16] [Emotion-Coherent Speech Data Augmentation and Self-Supervised Contrastive Style Training for Enhancing Kids's Story Speech Synthesis](https://arxiv.org/abs/2602.10164)
*Raymond Chung*

Main category: cs.SD

TL;DR: 提出通过合并情感一致文本的音频来增强小数据集，训练表达性端到端TTS模型，学习自然停顿并改进说话风格嵌入


<details>
  <summary>Details</summary>
Motivation: 表达性语音合成需要生动的韵律和适时的停顿，但小数据集训练表达性端到端TTS模型效果有限

Method: 1. 使用文本情感识别器合并情感一致文本的音频，创建增强的表达性语音数据；2. 用双句音频训练模型学习自然停顿；3. 应用自监督对比训练改进从语音中提取说话风格嵌入

Result: 1. 相比基线模型，合成语音的句间停顿分布更接近真实语音；2. 主观评估显示在自然度和风格适宜性上得分更高

Conclusion: 提出的数据增强和训练策略能有效提升表达性TTS模型的性能，特别是在学习自然停顿和说话风格方面

Abstract: Expressive speech synthesis requires vibrant prosody and well-timed pauses. We propose an effective strategy to augment a small dataset to train an expressive end-to-end Text-to-Speech model. We merge audios of emotionally congruent text using a text emotion recognizer, creating augmented expressive speech data. By training with two-sentence audio, our model learns natural breaks between lines. We further apply self-supervised contrastive training to improve the speaking style embedding extraction from speech. During inference, our model produces multi-sentence speech in one step, guided by the text-predicted speaking style. Evaluations showcase the effectiveness of our proposed approach when compared to a baseline model trained with consecutive two-sentence audio. Our synthesized speeches give a closer inter-sentence pause distribution to the ground truth speech. Subjective evaluations reveal our synthesized speech scored higher in naturalness and style suitability than the baseline.

</details>


### [17] [AudioRouter: Data Efficient Audio Understanding via RL based Dual Reasoning](https://arxiv.org/abs/2602.10439)
*Liyang Chen,Hongkai Chen,Yujun Cai,Sifan Li,Qingwen Ye,Yiwei Wang*

Main category: cs.SD

TL;DR: AudioRouter：通过强化学习框架让大型音频语言模型学习何时及如何使用外部音频工具，以提升音频理解能力，相比传统训练方法数据需求减少600倍。


<details>
  <summary>Details</summary>
Motivation: 大型音频语言模型在音频理解和推理方面表现出色，但在细粒度听觉感知方面仍不可靠，现有方法主要依赖数据密集型训练来内化感知能力。

Method: 提出AudioRouter强化学习框架，将工具使用明确制定为决策问题，优化轻量级路由策略，同时保持底层推理模型冻结，学习何时及如何使用外部音频工具。

Result: 在标准音频理解基准测试中取得显著改进，学习工具使用所需训练数据比传统训练范式减少高达600倍。

Conclusion: 学习有效的工具使用为大型音频语言模型提供了一种数据高效且可扩展的替代方案，避免了内化感知能力的需求。

Abstract: Large Audio Language Models (LALMs) have demonstrated strong capabilities in audio understanding and reasoning. However, their performance on fine grained auditory perception remains unreliable, and existing approaches largely rely on data intensive training to internalize perceptual abilities. We propose AudioRouter, a reinforcement learning framework that enables LALMs to improve audio understanding by learning when and how to use external audio tools. Rather than tightly coupling tool usage with audio reasoning, AudioRouter formulates tool use as an explicit decision making problem and optimizes a lightweight routing policy while keeping the underlying reasoning model frozen. Experimental results show that AudioRouter achieves substantial improvements on standard audio understanding benchmarks while requiring up to 600x less training data to learn tool usage compared with conventional training paradigms. These findings suggest that learning effective tool usage offers a data efficient and scalable alternative to internalizing perceptual abilities in LALMs.

</details>


### [18] [Calliope: A TTS-based Narrated E-book Creator Ensuring Exact Synchronization, Privacy, and Layout Fidelity](https://arxiv.org/abs/2602.10735)
*Hugo L. Hammer,Vajira Thambawita,Pål Halvorsen*

Main category: cs.SD

TL;DR: Calliope是一个开源框架，利用最先进的开源TTS技术将文本电子书转换为EPUB 3 Media Overlay格式的有声电子书，提供精确的音频-文本同步，并完全离线运行。


<details>
  <summary>Details</summary>
Motivation: 有声电子书结合音频和数字文本，支持早期识字和阅读困难者，但目前没有开源解决方案将标准文本电子书转换为高质量有声电子书。商业服务存在API成本、隐私和版权问题。

Method: 利用最先进的开源TTS系统（XTTS-v2和Chatterbox），在TTS过程中直接捕获音频时间戳，确保旁白和文本高亮的精确同步。严格保留原始排版、样式和嵌入媒体，整个流程离线运行。

Result: 开发了Calliope开源框架，支持精确的音频-文本同步，避免了强制对齐方法带来的漂移问题。实验表明强制对齐会导致显著的音频-文本漂移，影响阅读体验。

Conclusion: Calliope填补了开源有声电子书创建工具的空白，提供精确同步、离线运行、无API成本、隐私保护和版权合规的解决方案，优于基于强制对齐的方法。

Abstract: A narrated e-book combines synchronized audio with digital text, highlighting the currently spoken word or sentence during playback. This format supports early literacy and assists individuals with reading challenges, while also allowing general readers to seamlessly switch between reading and listening. With the emergence of natural-sounding neural Text-to-Speech (TTS) technology, several commercial services have been developed to leverage these technology for converting standard text e-books into high-quality narrated e-books. However, no open-source solutions currently exist to perform this task. In this paper, we present Calliope, an open-source framework designed to fill this gap. Our method leverages state-of-the-art open-source TTS to convert a text e-book into a narrated e-book in the EPUB 3 Media Overlay format. The method offers several innovative steps: audio timestamps are captured directly during TTS, ensuring exact synchronization between narration and text highlighting; the publisher's original typography, styling, and embedded media are strictly preserved; and the entire pipeline operates offline. This offline capability eliminates recurring API costs, mitigates privacy concerns, and avoids copyright compliance issues associated with cloud-based services. The framework currently supports the state-of-the-art open-source TTS systems XTTS-v2 and Chatterbox. A potential alternative approach involves first generating narration via TTS and subsequently synchronizing it with the text using forced alignment. However, while our method ensures exact synchronization, our experiments show that forced alignment introduces drift between the audio and text highlighting significant enough to degrade the reading experience. Source code and usage instructions are available at https://github.com/hugohammer/TTS-Narrated-Ebook-Creator.git.

</details>


### [19] [MOSS-Audio-Tokenizer: Scaling Audio Tokenizers for Future Audio Foundation Models](https://arxiv.org/abs/2602.10934)
*Yitian Gong,Kuangwei Chen,Zhaoye Fei,Xiaogui Yang,Ke Chen,Yang Wang,Kexin Huang,Mingshu Chen,Ruixiao Li,Qingyuan Cheng,Shimin Li,Xipeng Qiu*

Main category: cs.SD

TL;DR: 提出CAT架构和MOSS-Audio-Tokenizer，一个完全端到端、基于Transformer的音频分词器，在3百万小时音频数据上训练，支持高质量音频重建和多种音频任务。


<details>
  <summary>Details</summary>
Motivation: 现有离散音频分词器依赖预训练编码器、语义蒸馏或异质CNN架构，这些设计引入固定归纳偏置，限制了重建保真度和有效扩展能力。

Method: 提出CAT（Causal Audio Tokenizer with Transformer）架构，完全基于Transformer，端到端联合优化编码器、量化器和解码器。在此基础上开发MOSS-Audio-Tokenizer，16亿参数，在3百万小时多样化音频数据上预训练。

Result: 在语音、声音和音乐领域，MOSS-Audio-Tokenizer在广泛比特率范围内优于现有编解码器，且随着规模增加表现出可预测的改进。基于其离散token，开发了首个纯自回归TTS模型，超越先前非自回归和级联系统，同时支持无需辅助编码器的竞争性ASR性能。

Conclusion: CAT架构作为统一、可扩展的接口，为下一代原生音频基础模型奠定了基础。

Abstract: Discrete audio tokenizers are fundamental to empowering large language models with native audio processing and generation capabilities. Despite recent progress, existing approaches often rely on pretrained encoders, semantic distillation, or heterogeneous CNN-based architectures. These designs introduce fixed inductive biases that limit reconstruction fidelity and hinder effective scaling. In this paper, we argue that discrete audio tokenization should be learned fully end-to-end using a homogeneous and scalable architecture. To this end, we first propose CAT (Causal Audio Tokenizer with Transformer), a purely Transformer-based architecture that jointly optimizes the encoder, quantizer, and decoder from scratch for high-fidelity reconstruction. Building on the CAT architecture, we develop MOSS-Audio-Tokenizer, a large-scale audio tokenizer featuring 1.6 billion parameters, pre-trained on 3 million hours of diverse, general audio data. We show that this simple, fully end-to-end approach built from homogeneous, causal Transformer blocks scales gracefully and supports high-fidelity reconstruction across diverse audio domains. Across speech, sound, and music, MOSS-Audio-Tokenizer consistently outperforms prior codecs over a wide range of bitrates, while exhibiting predictable improvements with increased scale. Notably, leveraging the discrete tokens from our model, we develop the first purely autoregressive TTS model that surpasses prior non-autoregressive and cascaded systems. Furthermore, MOSS-Audio-Tokenizer enables competitive ASR performance without auxiliary encoders. Our findings position the CAT architecture as a unified, scalable interface for the next generation of native audio foundation models.

</details>


### [20] [SCRAPL: Scattering Transform with Random Paths for Machine Learning](https://arxiv.org/abs/2602.11145)
*Christopher Mitcheltree,Vincent Lostanlen,Emmanouil Benetos,Mathieu Lagrange*

Main category: cs.SD

TL;DR: 提出SCRAPL方法，通过随机路径采样高效计算小波散射变换，用于机器学习的可微分损失函数，显著降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 小波散射变换在感知质量评估中提供信息丰富的梯度，但计算成本高昂，限制了其在神经网络训练中的应用。

Method: 提出SCRAPL随机优化方案，通过随机路径采样高效评估多变量散射变换，并基于重要性采样提出初始化启发式方法。

Result: 将SCRAPL应用于JTFS变换和DDSP任务，实现了颗粒合成器和TR-808鼓机的无监督声音匹配，提高了神经网络收敛性和评估性能。

Conclusion: SCRAPL通过随机路径采样显著降低了散射变换的计算成本，使其适用于神经网络训练，并提供了Python实现包。

Abstract: The Euclidean distance between wavelet scattering transform coefficients (known as paths) provides informative gradients for perceptual quality assessment of deep inverse problems in computer vision, speech, and audio processing. However, these transforms are computationally expensive when employed as differentiable loss functions for stochastic gradient descent due to their numerous paths, which significantly limits their use in neural network training. Against this problem, we propose "Scattering transform with Random Paths for machine Learning" (SCRAPL): a stochastic optimization scheme for efficient evaluation of multivariable scattering transforms. We implement SCRAPL for the joint time-frequency scattering transform (JTFS) which demodulates spectrotemporal patterns at multiple scales and rates, allowing a fine characterization of intermittent auditory textures. We apply SCRAPL to differentiable digital signal processing (DDSP), specifically, unsupervised sound matching of a granular synthesizer and the Roland TR-808 drum machine. We also propose an initialization heuristic based on importance sampling, which adapts SCRAPL to the perceptual content of the dataset, improving neural network convergence and evaluation performance. We make our code and audio samples available and provide SCRAPL as a Python package.

</details>

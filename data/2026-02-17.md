<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 28]
- [eess.AS](#eess.AS) [Total: 6]
- [cs.SD](#cs.SD) [Total: 14]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [SIM-assisted Secure Mobile Communications via Enhanced Proximal Policy Optimization Algorithm](https://arxiv.org/abs/2602.13265)
*Wenxuan Ma,Bin Lin,Hongyang Pan,Geng Sun,Enyu Shi,Jiancheng An,Chau Yuen*

Main category: eess.SP

TL;DR: 本文提出了一种基于堆叠智能超表面(SIM)的6G移动用户安全通信系统，针对窃听威胁、信道不确定性、多用户干扰和硬件损伤等问题，开发了PPO-BOP强化学习算法来联合优化功率和相位偏移，显著提升了可达保密率。


<details>
  <summary>Details</summary>
Motivation: 随着6G无线通信网络的发展，移动用户面临日益突出的安全挑战。物理层安全技术利用无线信道固有特性提供安全保障，而堆叠智能超表面通过多层结构直接操控电磁波，为高效能物理层安全提供了新途径。

Method: 提出PPO-BOP算法：增强的近端策略优化算法，包含双向LSTM机制（捕捉短期信道衰落和长期用户移动性）、离策略数据利用机制（提高样本利用率）和策略反馈机制（增强探索能力），用于联合优化功率和相位偏移。

Result: 大量仿真结果表明，PPO-BOP算法在可达保密率方面显著优于基准策略和其他深度强化学习算法。

Conclusion: SIM辅助的安全通信系统结合PPO-BOP算法能有效应对移动环境中的实际挑战，为6G网络中的移动用户提供高效的安全保障。

Abstract: With the development of sixth-generation (6G) wireless communication networks, the security challenges are becoming increasingly prominent, especially for mobile users (MUs). As a promising solution, physical layer security (PLS) technology leverages the inherent characteristics of wireless channels to provide security assurance. Particularly, stacked intelligent metasurface (SIM) directly manipulates electromagnetic waves through their multilayer structures, offering significant potential for enhancing PLS performance in an energy efficient manner. Thus, in this work, we investigate an SIM-assisted secure communication system for MUs under the threat of an eavesdropper, addressing practical challenges such as channel uncertainty in mobile environments, multiple MU interference, and residual hardware impairments. Consequently, we formulate a joint power and phase shift optimization problem (JPPSOP), aiming at maximizing the achievable secrecy rate (ASR) of all MUs. Given the non-convexity and dynamic nature of this optimization problem, we propose an enhanced proximal policy optimization algorithm with a bidirectional long short-term memory mechanism, an off-policy data utilization mechanism, and a policy feedback mechanism (PPO-BOP). Through these mechanisms, the proposed algorithm can effectively capture short-term channel fading and long-term MU mobility, improve sample utilization efficiency, and enhance exploration capabilities. Extensive simulation results demonstrate that PPO-BOP significantly outperforms benchmark strategies and other deep reinforcement learning algorithms in terms of ASR.10.1109/TWC.2026.3658332

</details>


### [2] [Sample-level EEG-based Selective Auditory Attention Decoding with Markov Switching Models](https://arxiv.org/abs/2602.13447)
*Yuanyuan Yao,Simon Geirnaert,Tinne Tuytelaars,Alexander Bertrand*

Main category: eess.SP

TL;DR: 提出基于马尔可夫切换模型（MSM）的集成框架，用于选择性听觉注意解码，将解码和平滑整合到单一概率框架中，实现样本级解码并提高注意切换检测速度。


<details>
  <summary>Details</summary>
Motivation: 现有选择性听觉注意解码方法多在窗口级别操作，面临时间分辨率与解码精度之间的权衡。虽然HMM后处理可以平滑窗口级输出以改善这一权衡，但需要单独的平滑步骤。本文旨在将解码和平滑组件集成到单一概率框架中。

Method: 提出马尔可夫切换模型（MSM），直接建模每个注意状态下EEG与语音包络之间的关系，同时纳入注意的时间动态特性。该框架通过期望最大化算法联合估计模型参数和注意状态，实现样本级注意解码。

Result: 实验结果表明，集成的MSM框架在解码精度上与HMM后处理相当，同时提供了更快的注意切换检测速度。

Conclusion: MSM框架成功地将解码和平滑整合到单一概率模型中，实现了样本级选择性听觉注意解码，在保持解码精度的同时提高了注意切换的检测速度。

Abstract: Selective auditory attention decoding aims to identify the speaker of interest from listeners' neural signals, such as electroencephalography (EEG), in the presence of multiple concurrent speakers. Most existing methods operate at the window level, facing a trade-off between temporal resolution and decoding accuracy. Recent work has shown that hidden Markov model (HMM)-based post-processing can smooth window-level decoder outputs to improve this trade-off. Instead of using a separate smoothing step, we propose to integrate the decoding and smoothing components into a single probabilistic framework using a Markov switching model (MSM). It directly models the relationship between the EEG and speech envelopes under each attention state while incorporating the temporal dynamics of attention. This formulation enables sample-level attention decoding, with model parameters and attention states jointly estimated via the expectation-maximization algorithm. Experimental results demonstrate that this integrated MSM formulation achieves comparable decoding accuracy to HMM post-processing while providing faster attention switch detection. The code for the proposed method is available at https://github.com/YYao-42/MSM.

</details>


### [3] [Towards Causality-Aware Modeling for Multimodal Brain-Muscle Interactions](https://arxiv.org/abs/2602.13459)
*Farwa Abbas,Wei Dai,Zoran Cvetkovic,Verity McClelland*

Main category: eess.SP

TL;DR: 提出了一种结合动态贝叶斯网络和收敛交叉映射的因果推理框架，用于分析多模态生物医学信号中的动态因果交互


<details>
  <summary>Details</summary>
Motivation: 传统方法如动态贝叶斯网络通常假设线性或简单统计依赖，而流形方法如收敛交叉映射能捕捉非线性滞后交互但缺乏概率量化和干预建模。需要一种能同时处理非线性交互并提供概率量化和干预模拟的方法。

Method: 提出DBN-informed CCM框架，将几何流形重建与概率时序建模相结合。应用于肌张力障碍和正常儿童的多模态EEG-EMG记录，量化不确定性，支持干预模拟，揭示肌张力障碍中皮质肌肉通路的频率特异性重组。

Result: 实验结果显示，与基线方法相比，在预测一致性和因果稳定性方面有显著改进。该方法能够揭示肌张力障碍中皮质肌肉通路的频率特异性重组模式。

Conclusion: 该因果感知的多模态建模方法具有开发定量生物标志物和指导靶向神经调节干预的潜力，为生物医学信号分析提供了更强大的因果推理工具。

Abstract: Robust characterization of dynamic causal interactions in multivariate biomedical signals is essential for advancing computational and algorithmic methods in biomedical imaging. Conventional approaches, such as Dynamic Bayesian Networks (DBNs), often assume linear or simple statistical dependencies, while manifold based techniques like Convergent Cross Mapping (CCM) capture nonlinear, lagged interactions but lack probabilistic quantification and interventional modeling. We introduce a DBN informed CCM framework that integrates geometric manifold reconstruction with probabilistic temporal modeling. Applied to multimodal EEG-EMG recordings from dystonic and neurotypical children, the method quantifies uncertainty, supports interventional simulation, and reveals distinct frequency specific reorganization of corticomuscular pathways in dystonia. Experimental results show marked improvements in predictive consistency and causal stability as compared to baseline approaches, demonstrating the potential of causality aware multimodal modeling for developing quantitative biomarkers and guiding targeted neuromodulatory interventions.

</details>


### [4] [Blind Deconvolution Demixing using Modulated Inputs](https://arxiv.org/abs/2602.13481)
*Humera Hameed,Ali Ahmed*

Main category: eess.SP

TL;DR: 该论文提出了一种解决涉及调制输入的盲解卷积分离问题的方法，通过使用确定性子空间假设和梯度下降算法，在满足调制速率和采样复杂度条件下，可以从混合信号中恢复所有输入信号和信道响应。


<details>
  <summary>Details</summary>
Motivation: 解决盲解卷积分离中的挑战性问题，特别是当多个带限输入信号被已知随机序列调制后，通过不同信道卷积并混合接收的情况。传统方法难以从这种复杂的混合信号中分离出原始信号和信道响应。

Method: 采用确定性子空间假设处理输入信号，保持信道脉冲响应任意。当调制序列变化速率满足Q ≥ N²(B+M)且采样复杂度条件满足时，使用梯度下降算法从观测混合信号y(t)中估计所有信号和信道{s_n(t), h_n(t)}。

Result: 通过大量仿真验证了算法的鲁棒性，并使用相变图数值研究了算法的理论保证。结果表明在满足条件的情况下，可以从混合信号中成功恢复所有输入信号和信道响应。

Conclusion: 该方法为盲解卷积分离问题提供了一种有效的解决方案，特别是在调制输入场景下，通过合理的调制速率和采样复杂度设计，能够使用梯度下降算法实现信号和信道的准确恢复。

Abstract: This paper focuses on solving a challenging problem of blind deconvolution demixing involving modulated inputs. Specifically, multiple input signals $s_n(t)$, each bandlimited to $B$ Hz, are modulated with known random sequences $r_n(t)$ that alter at rate $Q$. Each modulated signal is convolved with a different M tap channel of impulse response $h_n(t)$, and the outputs of each channel are added at a common receiver to give the observed signal $y(t)=\sum_{n=1}^N (r_n(t)\odot s_n(t))\circledast h_n(t)$, where $\odot$ is the point wise multiplication, and $\circledast$ is circular convolution. Given this observed signal $y(t)$, we are concerned with recovering $s_n(t)$ and $h_n(t)$. We employ deterministic subspace assumption for the input signal $s_n(t)$ and keep the channel impulse response $h_n(t)$ arbitrary. We show that if modulating sequence is altered at a rate $Q \geq N^2 (B+M)$ and sample complexity bound is obeyed then all the signals and the channels, $\{s_n(t),h_n(t)\}_{n=1}^N$, can be estimated from the observed mixture $y(t)$ using gradient descent algorithm. We have performed extensive simulations that show the robustness of our algorithm and used phase transitions to numerically investigate the theoretical guarantees provided by our algorithm.

</details>


### [5] [Feasibility of simultaneous EEG-fMRI at 0.55 T: Recording, Denoising, and Functional Mapping](https://arxiv.org/abs/2602.13489)
*Parsa Razmara,Takfarinas Medani,Majid Abbasi Sisara,Anand A. Joshi,Rui Chen,Woojae Jeong,Ye Tian,Krishna S. Nayak,Richard M. Leahy*

Main category: eess.SP

TL;DR: 在0.55T低场强下实现同步EEG-fMRI的可行性验证，显示BCG伪影减少，保留alpha节律，支持神经血管耦合测量


<details>
  <summary>Details</summary>
Motivation: 传统高场强（≥3T）EEG-fMRI存在多种技术限制：EEG信号伪影、金属植入物兼容性差、高噪声、高磁化率区域伪影。需要探索低场强方案来克服这些限制。

Method: 在0.55T磁场下进行概念验证研究，使用视觉任务，分析梯度伪影和心搏伪影（BCG），测试多模态整合流程，比较EEG功率包络与BOLD响应关系。

Result: BCG伪影幅度降低（与静态磁场强度预期一致），alpha节律和信号完整性得以保留，EEG功率包络与血流动力学BOLD响应对应，支持神经血管耦合测量。

Conclusion: 0.55T低场强下的同步EEG-fMRI是可行的，为多模态神经成像提供了有前景的环境，特别是在减少伪影和保持信号质量方面具有优势。

Abstract: Simultaneous recording of electroencephalography (EEG) and functional MRI (fMRI) can provide a more complete view of brain function by merging high temporal and spatial resolutions. High-field ($\geq$3T) systems are standard, and require technical trade-offs, including artifacts in the EEG signal, reduced compatibility with metallic implants, high acoustic noise, and artifacts around high-susceptibility areas such as the optic nerve and nasal sinus. This proof-of-concept study demonstrates the feasibility of simultaneous EEG-fMRI at 0.55T in a visual task. We characterize the gradient and ballistocardiogram (BCG) artifacts inherent to this environment and observe reduced BCG magnitude consistent with the expected scaling of pulse-related artifacts with static magnetic field strength. This reduction shows promise for facilitating effective denoising while preserving the alpha rhythm and signal integrity. Furthermore, we tested a multimodal integration pipeline and demonstrated that the EEG power envelope corresponds with the hemodynamic BOLD response, supporting the potential to measure neurovascular coupling in this environment. We demonstrate that combined EEG-fMRI at 0.55T is feasible and represents a promising environment for multimodal neuroimaging.

</details>


### [6] [Sub Specie Aeternitatis: Fourier Transforms from the Theory of Heat to Musical Signals](https://arxiv.org/abs/2602.13520)
*Victor Lazzarini*

Main category: eess.SP

TL;DR: 论文追溯傅里叶定理从热传导物理到现代音乐信号理论的发展历程，探讨时间与频率的固有对偶性。


<details>
  <summary>Details</summary>
Motivation: 本文旨在通过原始文献追溯傅里叶定理的发展历程，展示傅里叶在1822年《热的解析理论》中提出的两个核心思想如何从热传导物理演变为现代音乐信号理论的基础，并探讨时间与频率的固有对偶性。

Method: 采用历史研究方法，完全依赖原始文献（傅里叶1822年著作、欧姆和亥姆霍兹的工作、德摩根1842年著作、狄拉克的见解），系统梳理傅里叶定理从热传导物理到音乐信号理论的发展脉络。

Result: 论文展示了傅里叶的两个核心思想（三角级数系数求解方法和傅里叶二重积分）如何分别成为音乐音调理论和处理不连续函数中无穷大的基础，最终形成现代傅里叶定理，并揭示了时间与频率的固有对偶性。

Conclusion: 傅里叶定理的发展历程体现了数学思想的跨学科迁移，从热传导物理到音乐信号理论，最终揭示了时间与频率的固有对偶性，这一对偶性成为现代信号处理的理论基础。

Abstract: J. B. Fourier in his \emph{Théorie Analytique de la Chaleur} of 1822 introduced, amongst other things, two ideas that have made a fundamental impact in fields as diverse as Mathematical Physics, Electrical Engineering, Computer Science, and Music. The first one of these, a method to find the coefficients for a trigonometric series describing an arbitrary function, was very early on picked up by G. Ohm and H. Helmholtz as the foundation for a theory of \emph{musical tones}. The second one, which is described by Fourier's double integral, became the basis for treating certain kinds of infinity in discontinuous functions, as shown by A. De Morgan in his 1842 \emph{The Differential and Integral Calculus}. Both make up the fundamental basis for what is now commonly known as the \emph{Fourier theorem}. With the help of P. A. M. Dirac's insights into the nature of these infinities, we can have a compact description of the frequency spectrum of a function of time, or conversely of a waveform corresponding to a given function of frequency. This paper, using solely primary sources, takes us from the physics of heat propagation to the modern theory of musical signals. It concludes with some considerations on the inherent duality of time and frequency emerging from Fourier's theorem.

</details>


### [7] [DopplerGLRTNet for Radar Off-Grid Detection](https://arxiv.org/abs/2602.13546)
*Yadang Alexis Rouzoumka,Jean Pinsolle,Eugénie Terreaux,Christèle Morisseau,Jean-Philippe Ovarlez,Chengfang Ren*

Main category: eess.SP

TL;DR: 提出DopplerGLRTNet，一种摊销的离网格GLRT检测器，通过轻量级回归器预测连续多普勒频率，解决传统NMF检测器在离网格目标检测中的性能饱和问题。


<details>
  <summary>Details</summary>
Motivation: 传统归一化匹配滤波器(NMF)检测器在处理离网格目标（多普勒或角度不在离散处理网格上）时性能严重下降，即使在高信噪比下，检测概率在低虚警率下也会饱和。连续参数GLRT虽然理论上更好，但密集扫描会增加计算成本，且对协方差失配敏感。

Method: 提出DopplerGLRTNet：一个摊销的离网格GLRT检测器。使用轻量级回归器从白化观测中预测分辨率单元内的连续多普勒频率，然后检测器输出单个GLRT/NMF类得分，该得分由预测多普勒处的归一化匹配滤波器能量给出。

Result: 蒙特卡洛仿真在高斯和复合高斯杂波中显示：DopplerGLRTNet缓解了离网格饱和问题，以密集扫描性能的一小部分成本接近其性能，并在相同经验校准的虚警率下提高了对协方差估计的鲁棒性。

Conclusion: DopplerGLRTNet提供了一种高效且鲁棒的离网格目标检测解决方案，通过摊销计算成本并提高对协方差失配的鲁棒性，解决了传统检测器的性能限制问题。

Abstract: Off-grid targets whose Doppler (or angle) does not lie on the discrete processing grid can severely degrade classical normalized matched-filter (NMF) detectors: even at high SNR, the detection probability may saturate at operationally relevant low false-alarm rates. A principled remedy is the continuous-parameter GLRT, which maximizes a normalized correlation over the parameter domain; however, dense scanning increases test-time cost and remains sensitive to covariance mismatch through whitening. We propose DopplerGLRTNet, an amortized off-grid GLRT: a lightweight regressor predicts the continuous Doppler within a resolution cell from the whitened observation, and the detector outputs a single GLRT/NMF-like score given by the normalized matched-filter energy at the predicted Doppler. Monte Carlo simulations in Gaussian and compound-Gaussian clutter show that DopplerGLRTNet mitigates off-grid saturation, approaches dense-scan performance at a fraction of its cost, and improves robustness to covariance estimation at the same empirically calibrated Pfa.

</details>


### [8] [Twenty-five years of J-DSP Online Labs for Signal Processing Classes and Workforce Development Programs](https://arxiv.org/abs/2602.13863)
*Andreas Spanias*

Main category: eess.SP

TL;DR: J-DSP是一个在线DSP仿真程序，最初用Java开发，后转为HTML5，支持数字滤波器设计、FFT频谱分析、机器学习信号分类和量子傅里叶变换等实验，已在多所大学使用20多年。


<details>
  <summary>Details</summary>
Motivation: 开发在线仿真程序来支持DSP课程的在线实验室教学，最初于2000年在ASU的DSP课程中部署，旨在提供便捷的DSP实验环境。

Method: 使用Java开发web-based软件，后来过渡到更安全的HTML5环境，开发了移动版本（iOS和Android），支持多种DSP实验功能。

Result: J-DSP已成功部署并在多所大学持续使用20多年，支持了NSF REU、IRES、RET等人才培养项目和高中的推广活动，功能不断扩展。

Conclusion: J-DSP作为一个成熟的在线DSP仿真平台，成功支持了DSP教育20多年，证明了其教学价值和持续发展的可行性。

Abstract: This paper presents the history of the online simulation program Java-DSP (J-DSP) and the most recent function development and deployment. J-DSP was created to support online laboratories in DSP classes and was first deployed in our ASU DSP class in 2000. The development of the program and its extensions was supported by several NSF grants including CCLI and IUSE. The web-based software was developed by our team in Java and later transitioned to the more secure HTML5 environment. J-DSP supports laboratory exercises on: digital filters and their design, the FFT and its utility in spectral analysis, machine learning for signal classification, and more recently online simulations with the Quantum Fourier Transform. Throughout the J-DSP development and deployment of this tool and its associated laboratory exercises, we documented evaluations. Mobile versions of the program for iOS and Android were also developed. J-DSP is used to this day in several universities, and specific functions of the program have been used in NSF REU, IRES and RET workforce development and high school outreach.

</details>


### [9] [Efficient Off-Grid Near-Field Cascade Channel Estimation for XL-IRS Systems via Tucker Decomposition](https://arxiv.org/abs/2602.13988)
*Wenzhou Cao,Yashuai Cao,Tiejun Lv,Mugen Peng*

Main category: eess.SP

TL;DR: 提出基于稀疏Tucker分解的离网格级联信道估计框架，用于解决XL-IRS近场效应下的信道估计问题，相比传统方法在NMSE上提升13.6dB且显著降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: XL-IRS的大孔径导致近场球面波传播效应，使级联信道估计复杂化。传统基于字典的方法存在累积量化误差和高复杂度问题，特别是在UPA系统中。

Method: 1) 提出UPA结构BS和IRS的水平和垂直响应向量张量积的NF级联信道张量建模方法；2) 基于稀疏Tucker分解的离网格级联信道估计框架，将接收信号建模为Tucker张量，稀疏核心张量捕获路径增益-延迟项；3) 采用高阶奇异值分解预处理，结合majorization-minimization和定制张量超松弛快速迭代收缩阈值技术加速。

Result: 仿真显示所提方案在归一化均方误差上比基准方法提升13.6dB，同时显著减少运行时间。推导了Cramér-Rao下界并进行了收敛性分析。

Conclusion: 提出的张量建模和稀疏Tucker分解框架有效解决了XL-IRS近场级联信道估计中的量化误差和复杂度问题，实现了高精度和高效的信道估计。

Abstract: Accurate cascaded channel state information is pivotal for extremely large-scale intelligent reflecting surfaces (XL-IRS) in next-generation wireless networks. However, the large XL-IRS aperture induces spherical wavefront propagation due to near-field (NF) effects, complicating cascaded channel estimation. Conventional dictionary-based methods suffer from cumulative quantization errors and high complexity, especially in uniform planar array (UPA) systems. To address these issues, we first propose a tensor modelization method for NF cascaded channels by exploiting the tensor product among the horizontal and vertical response vectors of the UPA-structured base station (BS) and the incident-reflective array response vector of the IRS. This structure leverages spatial characteristics, enabling independent estimation of factor matrices to improve efficiency. Meanwhile, to avoid quantization errors, we propose an off-grid cascaded channel estimation framework based on sparse Tucker decomposition. Specifically, we model the received signal as a Tucker tensor, where the sparse core tensor captures path gain-delay terms and three factor matrices are spanned by BS and NF IRS array responses. We then formulate a sparse core tensor minimization problem with tri-modal log-sum sparsity constraints to tackle the NP-hard challenge. Finally, the method is accelerated via higher-order singular value decomposition preprocessing, combined with majorization-minimization and a tailored tensor over-relaxation fast iterative shrinkage-thresholding technique. We derive the Cramér-Rao lower bound and conduct convergence analysis. Simulations show the proposed scheme achieves a 13.6 dB improvement in normalized mean square error over benchmarks with significantly reduced runtime.

</details>


### [10] [Lightweight Range-Angle Imaging Based Algorithm for Quasi-Static Human Detection on Low-Cost FMCW Radar](https://arxiv.org/abs/2602.14001)
*Huy Trinh,George Shaker*

Main category: eess.SP

TL;DR: 提出基于60GHz FMCW雷达的轻量级非视觉图像方法，用于检测准静态人体活动，相比传统CFAR检测器显著提升准确率和速度


<details>
  <summary>Details</summary>
Motivation: 准静态人体活动（如躺、站、坐）产生的多普勒频移极低且雷达特征高度扩散，传统CFAR检测器难以检测；同时隐私问题和低光照条件限制了摄像头在长期护理设施中的使用

Method: 使用低成本60GHz FMCW雷达，提出轻量级非视觉图像处理方法，采用共享的距离-角度（RA）预处理流水线，在树莓派4B上实现

Result: 相比CA-CFAR和OS-CFAR，检测准确率显著提升（从51.3-78.8%提升至92.3-94.82%）；处理速度达到平均8.2ms/帧（120+FPS），比OS-CFAR快74倍

Conclusion: 简单的图像处理方法能够在杂乱室内环境中提供鲁棒且可部署的准静态人体感知，解决了隐私和低光照条件下的监测需求

Abstract: Quasi-static human activities such as lying, standing or sitting produce very low Doppler shifts and highly spread radar signatures, making them difficult to detect with conventional constant-false-alarm rate (CFAR) detectors tuned for point targets. Moreover, privacy concerns and low lighting conditions limit the use of cameras in long-term care (LTC) facilities. This paper proposes a lightweight, non-visual image-based method for robust quasi-static human presence detection using a low-cost 60 GHz FMCW radar. On a dataset covering five semi-static activities, the proposed method improves average detection accuracy from 68.3% for Cell-Averaging CFAR (CA-CFAR) and 78.8% for Order-Statistics CFAR (OS-CFAR) to 93.24% for Subject 1, from 51.3%, 68.3% to 92.3% for Subject 2, and 57.72%, 69.94% to 94.82% for Subject 3, respectively. Finally, we benchmarked all three detectors across all activities on a Raspberry Pi 4B using a shared Range-Angle (RA) preprocessing pipeline. The proposed algorithm obtains an average 8.2 ms per frame, resulting in over 120 frames per second (FPS) and a 74 times speed-up over OS-CFAR. These results demonstrate that simple image-based processing can provide robust and deployable quasi-static human sensing in cluttered indoor environments.

</details>


### [11] [Rethinking RSSI for WiFi Sensing](https://arxiv.org/abs/2602.14004)
*Zhongqin Wang,J. Andrew Zhang,Kai Wu,Y. Jay Guo*

Main category: eess.SP

TL;DR: WiRSSI：仅使用RSSI测量的双基地WiFi被动人体追踪框架，证明RSSI虽分辨率较低但仍可用于实际感知


<details>
  <summary>Details</summary>
Motivation: RSSI在商用WiFi设备上广泛可用，但通常被认为过于粗糙，不适合细粒度感知。本文重新审视其感知潜力，探索仅使用RSSI测量进行被动人体追踪的可能性。

Method: 采用1Tx-3Rx配置，可扩展至MIMO部署。首先揭示CSI功率如何隐式编码相位相关信息，以及这种关系如何延续到RSSI。然后通过2D快速傅里叶变换提取多普勒-AoA特征，从仅振幅信息中推断延迟。最后将估计的AoA和延迟映射到笛卡尔坐标并进行去噪以恢复运动轨迹。

Result: 在实际环境实验中，WiRSSI对椭圆、线性和矩形轨迹的中位XY定位误差分别为0.905米、0.784米和0.785米。相比之下，基于CSI的代表性方法的中位误差为0.574米、0.599米和0.514米，平均精度差距为0.26米。

Conclusion: 尽管分辨率较低，RSSI仍能支持实用的被动感知，并为基于CSI的WiFi感知提供了低成本替代方案。

Abstract: The Received Signal Strength Indicator (RSSI) is widely available on commodity WiFi devices but is commonly regarded as too coarse for fine-grained sensing. This paper revisits its sensing potential and presents WiRSSI, a bistatic WiFi sensing framework for passive human tracking using only RSSI measurements. WiRSSI adopts a 1Tx-3Rx configuration and is readily extensible to Multiple-Input Multiple-Output (MIMO) deployments. We first reveal how CSI power implicitly encodes phase-related information and how this relationship carries over to RSSI, showing that RSSI preserves exploitable Doppler, Angle-of-Arrival (AoA), and delay cues associated with human motion. WiRSSI then extracts Doppler-AoA features via a 2D Fast Fourier Transform and infers delay from amplitude-only information in the absence of subcarrier-level phase. The estimated AoA and delay are then mapped to Cartesian coordinates and denoised to recover motion trajectories. Experiments in practical environments show that WiRSSI achieves median XY localization errors of 0.905 m, 0.784 m, and 0.785 m for elliptical, linear, and rectangular trajectories, respectively. In comparison, a representative CSI-based method attains median errors of 0.574 m, 0.599 m, and 0.514 m, corresponding to an average accuracy gap of 0.26 m. These results demonstrate that, despite its lower resolution, RSSI can support practical passive sensing and offers a low-cost alternative to CSI-based WiFi sensing.

</details>


### [12] [Extended Universal Joint Source-Channel Coding for Digital Semantic Communications: Improving Channel-Adaptability](https://arxiv.org/abs/2602.14018)
*Eunsoo Kim,Yoon Huh,Wan Choi*

Main category: eess.SP

TL;DR: 提出euJSCC框架，通过超网络归一化和动态码本生成实现SNR和调制自适应传输，在块衰落信道下优于现有JSCC方案。


<details>
  <summary>Details</summary>
Motivation: 现有VQ-based JSCC方法（如uJSCC）使用固定的调制特定编码器、解码器和码本，无法适应细粒度SNR变化，限制了在动态无线环境中的适应性。

Method: 1) 超网络归一化层实现细粒度特征向量归一化；2) 动态码本生成网络根据块级SNR优化调制特定基础码本；3) 内外编码器-解码器架构处理块衰落信道；4) 两阶段训练策略（AWGN预训练+块衰落微调）。

Result: 图像传输实验表明，euJSCC在块衰落和AWGN信道下均优于最先进的信道自适应数字JSCC方案。

Conclusion: euJSCC框架成功实现了SNR和调制自适应传输，通过动态码本生成和超网络归一化显著提升了语义通信在动态无线环境中的性能。

Abstract: Recent advances in deep learning (DL)-based joint source-channel coding (JSCC) have enabled efficient semantic communication in dynamic wireless environments. Among these approaches, vector quantization (VQ)-based JSCC effectively maps high-dimensional semantic feature vectors into compact codeword indices for digital modulation. However, existing methods, including universal JSCC (uJSCC), rely on fixed, modulation-specific encoders, decoders, and codebooks, limiting adaptability to fine-grained SNR variations. We propose an extended universal JSCC (euJSCC) framework that achieves SNR- and modulation-adaptive transmission within a single model. euJSCC employs a hypernetwork-based normalization layer for fine-grained feature vector normalization and a dynamic codebook generation (DCG) network that refines modulation-specific base codebooks according to block-wise SNR. To handle block fading channels, which consist of multiple coherence blocks, an inner-outer encoder-decoder architecture is adopted, where the outer encoder and decoder capture long-term channel statistics, and the inner encoder and decoder refine feature vectors to align with block-wise codebooks. A two-phase training strategy, i.e., pretraining on AWGN channels followed by finetuning on block fading channels, ensures stable convergence. Experiments on image transmission demonstrate that euJSCC consistently outperforms state-of-the-art channel-adaptive digital JSCC schemes under both block fading and AWGN channels.

</details>


### [13] [Convexity Meets Curvature: Lifted Near-Field Super-Resolution](https://arxiv.org/abs/2602.14063)
*Sajad Daei,Gábor Fodor,Mikael Skoglund*

Main category: eess.SP

TL;DR: 提出一种基于凸优化的无网格超分辨率框架，用于近场测量中的联合角度-距离估计，特别适用于混合前端系统


<details>
  <summary>Details</summary>
Motivation: 超大孔径、高频载波和ISAC技术推动阵列处理进入菲涅尔区域，球面波前导致孔径上的距离相关相位变化，破坏了经典子空间方法的傅里叶/范德蒙结构，特别是在混合前端测量有限的情况下，需要连续角度分辨率和联合角度-距离推断

Method: 通过Bessel-Vandermonde分解菲涅尔相位流形，暴露角度中的隐藏范德蒙结构，同时将距离依赖隔离到紧凑系数图中；引入提升映射将每个距离仓和连续角度映射到结构化秩一原子，将非线性近场模型转化为行稀疏矩阵的线性逆问题；通过原子范数最小化和有界三角多项式的对偶表征实现基于证书的定位

Result: 在强欠采样的混合观测条件下，验证了可靠的联合角度-距离恢复性能，适用于下一代无线和ISAC系统

Conclusion: 通过凸优化框架成功解决了近场测量中的联合角度-距离估计问题，实现了无网格超分辨率定位，克服了传统方法对二维网格的依赖

Abstract: Extra-large apertures, high carrier frequencies, and integrated sensing and communications (ISAC) are pushing array processing into the Fresnel region, where spherical wavefronts induce a range-dependent phase across the aperture. This curvature breaks the Fourier/Vandermonde structure behind classical subspace methods, and it is especially limiting with hybrid front-ends that provide only a small number of pilot measurements. Consequently, practical systems need continuous angle resolution and joint angle-range inference where many near-field approaches still rely on costly 2D gridding. We show that convexity can meet curvature via a lifted, gridless superresolution framework for near-field measurements. The key is a Bessel-Vandermonde factorization of the Fresnel-phase manifold that exposes a hidden Vandermonde structure in angle while isolating the range dependence into a compact coefficient map. Building on this, we introduce a lifting that maps each range bin and continuous angle to a structured rank-one atom, converting the nonlinear near-field model into a linear inverse problem over a row-sparse matrix. Recovery is posed as atomic-norm minimization and an explicit dual characterization via bounded trigonometric polynomials yields certificate-based localization that super-resolves off-grid angles and identifies active range bins. Simulations with strongly undersampled hybrid observations validate reliable joint angle-range recovery for next-generation wireless and ISAC systems.

</details>


### [14] [Wireless Physical Neural Networks (WPNNs): Opportunities and Challenges](https://arxiv.org/abs/2602.14094)
*Meng Hua,Itsik Bergel,Tolga Girici,Marco Di Renzo,Deniz Gunduz*

Main category: eess.SP

TL;DR: 论文提出无线物理神经网络（WPNNs）概念，将无线网络组件视为神经网络的计算层，利用无线传播环境作为可微分算子进行端到端优化。


<details>
  <summary>Details</summary>
Motivation: 无线通信系统与神经网络在结构和功能上具有相似性：信号通过级联元件传播、与环境交互并经历变换。这种相似性启发我们将无线网络重新构想为学习架构。

Method: 提出WPNNs统一范式，将收发器、中继器、反向散射和智能表面等无线组件解释为学习架构中的计算层。将无线传播环境和网络元素视为可微分算子，通过基于学习的方法直接对物理网络进行系统优化。

Result: 通过数值示例展示了在处理、适应性、效率和端到端优化方面的潜在性能增益，证明了将无线系统重新配置为学习网络在下一代通信框架中的前景。

Conclusion: 无线物理神经网络为联合通信-计算设计提供了新机会，无线介质可作为计算资源，与传统的数字神经层协同工作，实现混合通信学习管道。

Abstract: Wireless communication systems exhibit structural and functional similarities to neural networks: signals propagate through cascaded elements, interact with the environment, and undergo transformations. Building upon this perspective, we introduce a unified paradigm, termed \textit{wireless physical neural networks (WPNNs)}, in which components of a wireless network, such as transceivers, relays, backscatter, and intelligent surfaces, are interpreted as computational layers within a learning architecture. By treating the wireless propagation environment and network elements as differentiable operators, new opportunities arise for joint communication-computation designs, where system optimization can be achieved through learning-based methods applied directly to the physical network. This approach may operate independently of, or in conjunction with, conventional digital neural layers, enabling hybrid communication learning pipelines. In the article, we outline representative architectures that embody this viewpoint and discuss the algorithmic and training considerations required to leverage the wireless medium as a computational resource. Through numerical examples, we highlight the potential performance gains in processing, adaptability, efficiency, and end-to-end optimization, demonstrating the promise of reconfiguring wireless systems as learning networks in next-generation communication frameworks.

</details>


### [15] [Electromagnetic Bounds on Realizing Targeted MIMO Transfer Functions in Real-World Systems with Wave-Domain Programmability](https://arxiv.org/abs/2602.14152)
*Philipp del Hougne*

Main category: eess.SP

TL;DR: 该论文推导了可重构波系统中实现期望线性算子的电磁一致性保真度上界，考虑了元件间互耦和硬件约束，并应用于三种实验设置验证。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏电磁一致性边界来评估可重构波系统实现期望线性算子的准确性，而这个问题对混合MIMO模拟组合器、计算元成像器和可编程波域信号处理等应用至关重要。

Method: 基于电磁一致性多端口网络模型（考虑可调元件间的互耦）和实际硬件约束（有损耗、1位可编程元件），将算子合成任务表述为二次约束分数二次问题，并通过半定松弛计算严格的保真度上界。

Result: 应用于三种实验设置：2.45 GHz自由空间和富散射4×4 MIMO信道（100个1位可编程RIS元件），以及19 GHz 4×4 MIMO信道（动态超表面天线）。研究发现可调元件数量对可实现保真度的影响，以及元件间耦合强度对保真度边界的显著影响。对于两种RIS设置，边界表明波域灵活性不足。

Conclusion: 该研究首次推导了可重构波系统中实现期望线性算子的电磁一致性保真度上界，为评估实际系统性能提供了理论基础，并揭示了元件间耦合对系统灵活性的重要影响。

Abstract: A key question for most applications involving reconfigurable linear wave systems is how accurately a desired linear operator can be realized by configuring the system's tunable elements. The relevance of this question spans from hybrid-MIMO analog combiners via computational meta-imagers to programmable wave-domain signal processing. Yet, no electromagnetically consistent bounds have been derived for the fidelity with which a desired operator can be realized in a real-world reconfigurable wave system. Here, we derive such bounds based on an electromagnetically consistent multiport-network model (capturing mutual coupling between tunable elements) and accounting for real-world hardware constraints (lossy, 1-bit-programmable elements). Specifically, we formulate the operator-synthesis task as a quadratically constrained fractional-quadratic problem and compute rigorous fidelity upper bounds based on semidefinite relaxation. We apply our technique to three distinct experimental setups. The first two setups are, respectively, a free-space and a rich-scattering $4\times 4$ MIMO channel at 2.45 GHz parameterized by a reconfigurable intelligent surface (RIS) comprising 100 1-bit-programmable elements. The third setup is a $4\times 4$ MIMO channel at 19 GHz from four feeds of a dynamic metasurface antenna (DMA) to four users. We systematically study how the achievable fidelity scales with the number of tunable elements, and we probe the tightness of our bounds by trying to find optimized configurations approaching the bounds with standard discrete-optimization techniques. We observe a strong influence of the coupling strength between tunable elements on our fidelity bound. For the two RIS-based setups, our bound attests to insufficient wave-domain flexibility for the considered operator synthesis.

</details>


### [16] [Explainable Interictal Epileptiform Discharge Detection Method Based on Scalp EEG and Retrieval-Augmented Generation](https://arxiv.org/abs/2602.14170)
*Yu Zhu,Jiayang Guo,Jun Jiang,Peipei Gu,Xin Shu,Duo Chen*

Main category: eess.SP

TL;DR: 提出IED-RAG框架，通过检索显式证据实现可解释的癫痫样放电检测和报告生成，在公开和私有数据集上均取得良好效果。


<details>
  <summary>Details</summary>
Motivation: 癫痫样放电检测对癫痫诊断至关重要，但现有自动化方法缺乏可解释性，需要开发既能准确检测又能生成解释性报告的框架。

Method: 使用双编码器提取电生理和语义特征，通过对比学习在共享的EEG-文本嵌入空间中对齐。推理时从向量数据库中检索临床相关的EEG-文本对作为显式证据，条件化大语言模型生成基于证据的报告。

Result: 在武汉儿童医院私有数据集和公开的TUEV数据集上，分别达到89.17%和71.38%的平衡准确率，以及89.61%和64.14%的BLEU分数，优于标准黑盒方法。

Conclusion: 检索显式证据的方法不仅提高了诊断性能，还增强了临床可解释性，为癫痫诊断提供了更透明和可信的自动化解决方案。

Abstract: The detection of interictal epileptiform discharge (IED) is crucial for the diagnosis of epilepsy, but automated methods often lack interpretability. This study proposes IED-RAG, an explainable multimodal framework for joint IED detection and report generation. Our approach employs a dual-encoder to extract electrophysiological and semantic features, aligned via contrastive learning in a shared EEG-text embedding space. During inference, clinically relevant EEG-text pairs are retrieved from a vector database as explicit evidence to condition a large language model (LLM) for the generation of evidence-based reports. Evaluated on a private dataset from Wuhan Children's Hospital and the public TUH EEG Events Corpus (TUEV), the framework achieved balanced accuracies of 89.17\% and 71.38\%, with BLEU scores of 89.61\% and 64.14\%, respectively. The results demonstrate that retrieval of explicit evidence enhances both diagnostic performance and clinical interpretability compared to standard black-box methods.

</details>


### [17] [Localization Exploiting Spatial Variations in the Magnetic Field: Principles and Challenges](https://arxiv.org/abs/2602.14181)
*Isaac Skog,Manon Kok,Christophe Prieur,Gustaf Hendeby*

Main category: eess.SP

TL;DR: 该论文综述了利用地球磁场空间变化进行定位的信号处理原理、现有技术和研究挑战，旨在从统计信号处理角度统一现有技术框架。


<details>
  <summary>Details</summary>
Motivation: 信号处理在现代定位技术发展中起基础作用，磁场定位也不例外。当前基于磁场空间变化的定位技术已能达到分米级室内精度和战略级惯性导航系统的室外精度，需要从信号处理角度系统梳理现有技术和挑战。

Method: 采用统一的参数化信号模型框架，将现有关键技术纳入与成熟统计推断方法兼容的体系，从统计信号处理角度分析不同技术的相似性和差异性。

Result: 建立了磁场定位技术的统一信号处理框架，明确了统计状态推断、磁场建模和传感器校准等核心信号处理方法，识别了当前的研究挑战。

Conclusion: 磁场定位技术已取得显著进展，但需要进一步从信号处理角度统一技术框架，解决现有挑战，推动该领域的发展和应用。

Abstract: Signal processing has played, and continues to play, a fundamental role in the evolution of modern localization technologies. Localization using spatial variations in the Earth's magnetic field is no exception. It relies on signal-processing methods for statistical state inference, magnetic-field modeling, and sensor calibration. Contemporary localization techniques based on spatial variations in the magnetic field can provide decimeter-level indoor localization accuracy and outdoor localization accuracy on par with strategic-grade inertial navigation systems. This article provides a broad, high-level overview of current signal-processing principles and open research challenges in localization using spatial variations in the Earth's magnetic field. The aim is to provide the reader with an understanding of the similarities and differences among existing key technologies from a statistical signal-processing perspective. To that end, existing key technologies will be presented within a common parametric signal-model framework compatible with well-established statistical inference methods.

</details>


### [18] [Robust SAC-Enabled UAV-RIS Assisted Secure MISO Systems With Untrusted EH Receivers](https://arxiv.org/abs/2602.14191)
*Hamid Reza Hashempour,Le-Nam Tran,Duy H. N. Nguyen,Hien Quoc Ngo*

Main category: eess.SP

TL;DR: 该论文研究无人机辅助RIS多用户MISO网络中的安全下行传输，联合优化无人机位置、RIS相移和功率分配，在CSI不完美下最大化最坏情况保密能效，提出基于SAC的深度强化学习方法。


<details>
  <summary>Details</summary>
Motivation: 在无人机辅助RIS多用户网络中，存在不可信能量收集接收器可能窃听合法信息，且由于有限反馈导致CSI不完美，需要解决最坏情况保密能效最大化问题。

Method: 提出基于软演员-评论家(SAC)的深度强化学习框架，通过与环境交互学习最优策略；同时为完美CSI情况开发了连续凸近似(SCA)基准方法。

Result: SAC方法相比SCA和DDPG基线分别实现28%和16%的保密能效增益，对CSI不确定性表现出优越鲁棒性，在不同发射功率和RIS尺寸下性能稳定。

Conclusion: SAC深度强化学习框架能有效解决无人机-RIS网络中非凸的WCSEE最大化问题，在CSI不完美情况下仍能保持高性能和鲁棒性。

Abstract: This paper investigates secure downlink transmission in a UAV-assisted reconfigurable intelligent surface (RIS)-enabled multiuser multiple-input single-output network, where legitimate information-harvesting receivers coexist with untrusted energy-harvesting receivers (UEHRs) capable of eavesdropping. A UAV-mounted RIS provides blockage mitigation and passive beamforming, while the base station employs zero-forcing precoding for multiuser interference suppression. Due to limited feedback from UEHRs, their channel state information (CSI) is imperfect, leading to a worst-case secrecy energy efficiency (WCSEE) maximization problem. We jointly optimize the UAV horizontal position, RIS phase shifts, and transmit power allocation under both perfect and imperfect CSI, considering discrete RIS phases, UAV mobility, and energy-harvesting constraints. The resulting problem is highly nonconvex due to coupled channel geometry, robustness requirements, and discrete variables. To address this challenge, we propose a soft actor-critic (SAC)-based deep reinforcement learning framework that learns WCSEE-maximizing policies through interaction with the wireless environment. As a structured benchmark, a successive convex approximation (SCA) approach is developed for the perfect CSI case with continuous RIS phases. Simulation results show that the proposed SAC method achieves up to 28% and 16% secrecy energy efficiency gains over SCA and deep deterministic policy gradient baselines, respectively, while demonstrating superior robustness to CSI uncertainty and stable performance across varying transmit power levels and RIS sizes.

</details>


### [19] [Low-Cost Physical-Layer Security Design for IRS-Assisted mMIMO Systems with One-Bit DACs](https://arxiv.org/abs/2602.14292)
*Weijie Xiong,Jian Yang,Jingran Lin,Hongli Liu,Zhiling Xiao,Qiang Li*

Main category: eess.SP

TL;DR: 本文提出了一种使用1位DAC的IRS辅助mMIMO系统物理层安全设计方案，通过优化1位量化预编码和IRS相位偏移来最大化保密率，并提出了WMMSE-PDD和EPPRGD两种高效算法。


<details>
  <summary>Details</summary>
Motivation: mMIMO系统与IRS结合可增强无线通信的物理层安全，但大规模mMIMO阵列和高分辨率量化器导致硬件复杂度高。为解决这一问题，本文采用1位DAC来降低硬件成本。

Method: 提出两种算法：1) WMMSE-PDD算法，将保密率最大化问题转化为带辅助变量的非分数规划序列，使用惩罚对偶分解求解；2) EPPRGD算法，将问题转化为乘积黎曼流形上的无约束优化，无需辅助变量，收敛更快。

Result: 仿真结果验证了两种算法的有效性：WMMSE-PDD算法具有优越的保密性能，EPPRGD算法收敛速度更快但保密性能略有折衷。两种算法都能收敛到KKT点。

Conclusion: 本文提出的基于1位DAC的IRS辅助mMIMO系统物理层安全设计方案是可行的，两种算法各有优势，为低成本高安全性的无线通信系统提供了有效解决方案。

Abstract: Integrating massive multiple-input multiple-output (mMIMO) systems with intelligent reflecting surfaces (IRS) presents a promising paradigm for enhancing physical-layer security (PLS) in wireless communications. However, deploying high-resolution quantizers in large-scale mMIMO arrays, along with numerous IRS elements, leads to substantial hardware complexity. To address these challenges, this paper proposes a cost-effective PLS design for IRS-assisted mMIMO systems by employing one-bit digital-to-analog converters (DACs). The focus is on jointly optimizing one-bit quantized precoding at the transmitter and constant-modulus phase shifts at the IRS to maximize the secrecy rate. This leads to a highly non-convex fractional secrecy rate maximization (SRM) problem. To efficiently solve this problem, two algorithms are proposed: (1) the WMMSE-PDD algorithm, which reformulates the SRM problem into a sequence of non-fractional programs with auxiliary variables using the weighted minimum mean-square error (WMMSE) method and solves them via the penalty dual decomposition (PDD) approach, achieving superior secrecy performance; and (2) the exact penalty product Riemannian gradient descent (EPPRGD) algorithm, which transforms the SRM problem into an unconstrained optimization over a product Riemannian manifold, eliminating auxiliary variables and enabling faster convergence with a slight trade-off in secrecy performance. Both algorithms provide analytical solutions at each iteration and are proven to converge to Karush-Kuhn-Tucker (KKT) points. Simulation results confirm the effectiveness of the proposed methods and highlight their respective advantages.

</details>


### [20] [Online Architecture Search for Compressed Sensing based on Hypergradient Descent](https://arxiv.org/abs/2602.14411)
*Ayano Nakai-Kasai,Yusuke Nakane,Tadashi Wadayama*

Main category: eess.SP

TL;DR: 提出HGD-AS-ISTA和HGD-AS-FISTA算法，使用超梯度下降在线优化结构参数，避免传统深度展开方法需要训练数据和大量训练时间的问题。


<details>
  <summary>Details</summary>
Motivation: AS-ISTA和AS-FISTA算法通过引入结构参数实现架构搜索，但使用深度展开方法确定这些参数需要训练数据和大量训练时间，且当环境变化时需要重新训练。

Method: 提出HGD-AS-ISTA和HGD-AS-FISTA算法，采用超梯度下降（一种在线超参数优化方法）来确定结构参数，避免了传统深度展开方法的训练需求。

Result: 实验结果表明，所提方法在提升传统ISTA/FISTA性能的同时，避免了环境变化时需要重新训练的问题。

Conclusion: 超梯度下降方法能够有效在线优化AS-ISTA和AS-FISTA的结构参数，既提升了压缩感知算法的性能，又解决了传统方法需要训练数据和重新训练的问题。

Abstract: AS-ISTA (Architecture Searched-Iterative Shrinkage Thresholding Algorithm) and AS-FISTA (AS-Fast ISTA) are compressed sensing algorithms introducing structural parameters to ISTA and FISTA to enable architecture search within the iterative process. The structural parameters are determined using deep unfolding, but this approach requires training data and the large overhead of training time. In this paper, we propose HGD-AS-ISTA (Hypergradient Descent-AS-ISTA) and HGD-AS-FISTA that use hypergradient descent, which is an online hyperparameter optimization method, to determine the structural parameters. Experimental results show that the proposed method improves performance of the conventional ISTA/FISTA while avoiding the need for re-training when the environment changes.

</details>


### [21] [Reconfigurable Intelligent Surfaces-assisted Positioning in Integrated Sensing and Communication Systems](https://arxiv.org/abs/2602.14415)
*Huyen-Trang Ta,Ngoc-Son Duong,Trung-Hieu Nguyen,Van-Linh Nguyen,Thai-Mai Dinh*

Main category: eess.SP

TL;DR: 提出一种用于RIS辅助ISAC系统的高精度目标定位方法，通过粗估计和快速迭代优化实现高精度低复杂度定位


<details>
  <summary>Details</summary>
Motivation: 在集成感知与通信系统中，通过直接路径和RIS反射路径进行目标定位时，需要解决高精度定位与计算复杂度之间的矛盾

Method: 1) 使用顺序匹配滤波器估计粗角度参数；2) 基于子载波相位差恢复距离；3) 将定位问题建模为非线性最小二乘优化；4) 提出快速迭代优化算法，利用可分离最小二乘结构解耦参数；5) 采用改进的Levenberg算法和近似策略降低计算成本

Result: 仿真结果表明，所提出的优化方法在达到与传统方法相当的定位精度的同时，显著降低了算法复杂度

Conclusion: 提出的RIS辅助ISAC目标定位框架通过粗估计初始化结合快速迭代优化，实现了高精度定位与低计算复杂度的平衡，为实际系统部署提供了有效解决方案

Abstract: This paper investigates the problem of high-precision target localization in integrated sensing and communication (ISAC) systems, where the target is sensed via both a direct path and a reconfigurable intelligent surface (RIS)-assisted reflection path. We first develop a sequential matched-filter estimator to acquire coarse angular parameters, followed by a range recovery process based on subcarrier phase differences. Subsequently, we formulate the target localization problem as a non-linear least squares optimization, using the coarse estimates to initialize the target's position coordinates. To solve this efficiently, we introduce a fast iterative refinement algorithm tailored for RIS-aided ISAC environments. Recognizing that the signal model involves both linear path gains and non-linear geometric dependencies, we exploit the separable least-squares structure to decouple these parameters. Furthermore, we propose a modified Levenberg algorithm with an approximation strategy, which enables low-cost parameter updates without necessitating repeated evaluations of the full non-linear model. Simulation results show that the proposed refinement method achieves accuracy comparable to conventional approaches, while significantly reducing algorithmic complexity.

</details>


### [22] [Cramer--Rao Bounds for Magneto-Inductive Integrated Sensing and Communications](https://arxiv.org/abs/2602.14453)
*Haofan Dong,Ozgur B. Akan*

Main category: eess.SP

TL;DR: 该论文推导了磁感应通信中联合估计距离和介质电导率的克拉美-罗界，发现在近场区域联合估计仅带来3dB精度损失。


<details>
  <summary>Details</summary>
Motivation: 磁感应通信在射频受限环境（地下、水下、体内）中具有应用潜力，介质电导率对信道产生确定性影响。需要研究在集成感知与通信框架下，如何联合估计距离和介质电导率，并评估这种联合估计对测距精度的影响。

Method: 推导了磁感应通信中基于导频观测的联合距离和介质电导率估计的闭式克拉美-罗界，分析了费舍尔信息矩阵，并通过蒙特卡洛最大似然仿真验证理论结果。

Result: 费舍尔信息矩阵分析表明，在近场区域，联合估计的精度损失收敛到3dB，意味着电导率感知最多使测距精度降低2倍。蒙特卡洛仿真证实了在实际操作条件下可以达到克拉美-罗界。

Conclusion: 磁感应通信中联合估计距离和介质电导率是可行的，在近场区域仅带来有限的精度损失（3dB），为集成感知与通信系统设计提供了理论依据。

Abstract: Magnetic induction (MI) enables communication in RF-denied environments (underground, underwater, in-body), where the medium conductivity imprints a deterministic signature on the channel. This letter derives a closed-form Cramér--Rao bound (CRB) for the joint estimation of range and medium conductivity from MI pilot observations in an integrated sensing and communication (ISAC) framework. The Fisher information matrix reveals that the joint estimation penalty converges to 3\,dB in the near-field regime, meaning conductivity sensing adds at most a factor-of-two loss in ranging precision. Monte Carlo maximum-likelihood simulations confirm that the CRB is achievable under practical operating conditions.

</details>


### [23] [All-pole centroids in the Wasserstein metric with applications to clustering of spectral densities](https://arxiv.org/abs/2602.14583)
*Rumeshika Pallewela,Filip Elvander*

Main category: eess.SP

TL;DR: 提出一种在谱Wasserstein-2度量下计算功率谱密度集合质心的方法，质心被限制为特定阶数的全极点谱，可视为寻找二阶平稳高斯过程的自回归代表。


<details>
  <summary>Details</summary>
Motivation: 现有Wasserstein质心方法在谱估计和聚类中虽然成功，但得到的质心是非参数的，其表示和存储复杂度依赖于离散化网格的选择。需要一种紧凑、低维且可解释的谱质心方法用于下游任务。

Method: 将全极点质心计算转化为模型参数的非凸优化问题，提出梯度下降方案求解。虽然不能保证全局最优，但可以量化所得质心的次优性。

Result: 该方法能够产生紧凑、低维且可解释的谱质心，在音素分类问题上进行了验证。

Conclusion: 提出的方法为谱Wasserstein-2度量下的全极点质心计算提供了有效解决方案，得到的质心具有更好的可解释性和存储效率。

Abstract: In this work, we propose a method for computing centroids, or barycenters, in the spectral Wasserstein-2 metric for sets of power spectral densities, where the barycenters are restricted to belong to the set of all-pole spectra with a certain model order. This may be interpreted as finding an autoregressive representative for sets of second-order stationary Gaussian processes. While Wasserstein, or optimal transport, barycenters have been successfully used earlier in problems of spectral estimation and clustering, the resulting barycenters are non-parametric and the complexity of representing and storing them depends on, e.g., the choice of discretization grid. In contrast, the herein proposed method yields compact, low-dimensional, and interpretable spectral centroids that can be used in downstream tasks. Computing the all-pole centroids corresponds to solving a non-convex optimization problem in the model parameters, and we present a gradient descent scheme for addressing this. Although convergence to a globally optimal point cannot be guaranteed, the sub-optimality of the obtained centroids can be quantified. The proposed method is illustrated on a problem of phoneme classification.

</details>


### [24] [Learning Dirac Spectral Transforms for Topological Signals](https://arxiv.org/abs/2602.14590)
*Leonardo Di Nino,Tiziana Cattai,Sergio Barbarossa,Ginestra Bianconi,Paolo Di Lorenzo*

Main category: eess.SP

TL;DR: 比较Dirac算子与Hodge-Laplacian在信号处理中的性能，提出结合两者的过完备基，并设计带质量参数的非冗余变换，通过学习质量参数实现最佳失真-稀疏度权衡。


<details>
  <summary>Details</summary>
Motivation: Dirac算子为不同阶拓扑域（如节点和边信号）的信号处理提供了统一框架，其本征模式能捕获跨域交互，而传统Hodge-Laplacian本征模式仅在同一拓扑维度内操作。需要比较这两种方法的性能并探索更好的解决方案。

Method: 1) 比较Dirac算子与Hodge-Laplacian在失真/稀疏度权衡方面的性能；2) 构建连接两个字典的过完备基；3) 提出参数化非冗余变换，其本征模式包含捕获节点和边模式相互作用的质量参数；4) 从数据中学习质量参数。

Result: 过完备基相比单一方法提供更好性能；通过学习质量参数，提出的变换能够实现比完整基和过完备基都更好的失真-稀疏度权衡。

Conclusion: Dirac算子为拓扑信号处理提供有前景的框架，通过结合Dirac和Hodge-Laplacian基并学习质量参数，可以显著改善信号表示的失真-稀疏度权衡性能。

Abstract: The Dirac operator provides a unified framework for processing signals defined over different order topological domains, such as node and edge signals. Its eigenmodes define a spectral representation that inherently captures cross-domain interactions, in contrast to conventional Hodge-Laplacian eigenmodes that operate within a single topological dimension. In this paper, we compare the two alternatives in terms of the distortion/sparsity trade-off and we show how an overcomplete basis built concatenating the two dictionaries can provide better performance with respect to each approach. Then, we propose a parameterized nonredundant transform whose eigenmodes incorporate a mode-specific mass parameter that captures the interplay between node and edge modes. Interestingly, we show that learning the mass parameters from data makes the proposed transform able to achieve the best distortion-sparsity tradeoff with respect to both complete and overcomplete bases.

</details>


### [25] [Synthetic Aperture Communication: Principles and Application to Massive IoT Satellite Uplink](https://arxiv.org/abs/2602.14629)
*Lucas Giroto,Marcus Henninger,Silvio Mandelli*

Main category: eess.SP

TL;DR: 本文提出相干合成孔径通信(SAC)技术，用于卫星直连设备上行链路，通过合成孔径处理实现精确波达方向估计、空间信号分离和定位，解决物联网设备在非地面网络中的互干扰和功率限制问题。


<details>
  <summary>Details</summary>
Motivation: 虽然合成孔径雷达已广泛用于远距离高分辨率成像，但相干合成孔径通信的概念尚未被探索。物联网设备在非地面网络中面临严格的功率限制和相互干扰问题，需要新的通信方案来解决这些挑战。

Method: 提出相干合成孔径通信(SAC)原理，应用于卫星直连设备上行链路。通过卫星运动形成合成孔径，实现精确的波达方向估计，从而进行空间信号分离和定位。采用正交频分复用传输和极化编码技术，在3.5GHz频段进行仿真验证。

Result: 在600公里低地球轨道卫星和两个用户设备的仿真中，即使传输功率低至-10dBm，且在强干扰条件下（当用户设备被解析但落在彼此最强的角度旁瓣上），块错误率仍低于0.1。这验证了该方案处理互干扰和严格功率限制的能力。

Conclusion: 相干合成孔径通信技术能够有效解决物联网设备在非地面网络中的互干扰和功率限制问题，为大规模物联网连接在非地面网络中的应用铺平了道路。

Abstract: While synthetic aperture radar is widely adopted to provide high-resolution imaging at long distances using small arrays, the concept of coherent synthetic aperture communication (SAC) has not yet been explored. This article introduces the principles of SAC for direct satellite-to-device uplink, showcasing precise direction-of-arrival estimation for user equipment (UE) devices, facilitating spatial signal separation, localization, and easing link budget constraints. Simulations for a low Earth orbit satellite at 600 km orbit and two UE devices performing orthogonal frequency-division multiplexing-based transmission with polar coding at 3.5 GHz demonstrate block error rates below 0.1 with transmission powers as low as -10 dBm, even under strong interference when UE devices are resolved but fall on each other's strongest angular sidelobe. These results validate the ability of the proposed scheme to address mutual interference and stringent power limitations, paving the way for massive Internet of Things connectivity in non-terrestrial networks.

</details>


### [26] [RF-GPT: Teaching AI to See the Wireless World](https://arxiv.org/abs/2602.14833)
*Hang Zou,Yu Tian,Bohao Wang,Lina Bariah,Samson Lasaulce,Chongwen Huang,Mérouane Debbah*

Main category: eess.SP

TL;DR: RF-GPT：首个将射频信号处理与大型语言模型推理能力结合的射频语言模型，通过视觉编码器处理射频频谱图，实现多任务射频理解


<details>
  <summary>Details</summary>
Motivation: 当前LLMs和多模态模型在无线通信领域存在明显局限——它们无法原生处理射频信号。现有方法要么只处理文本和结构化数据，要么是专门针对特定信号处理任务的深度学习模型，缺乏射频感知与高级推理能力的结合

Method: 1) 将复杂IQ波形映射到时频频谱图；2) 使用预训练视觉编码器处理频谱图；3) 将得到的表示作为RF tokens注入仅解码器LLM；4) 通过全合成RF语料库进行监督指令微调；5) 使用标准兼容波形生成器创建六种无线技术的宽带场景

Result: 在宽带调制分类、重叠分析、无线技术识别、WLAN用户计数和5G NR信息提取等多个基准测试中，RF-GPT表现出强大的多任务性能，而通用视觉语言模型因缺乏射频基础而基本失败

Conclusion: RF-GPT成功填补了射频感知与高级推理之间的空白，通过将射频信号转换为视觉表示并利用多模态LLMs的能力，实现了对射频信号的深度理解和多任务处理，为无线通信领域的智能分析提供了新范式

Abstract: Large language models (LLMs) and multimodal models have become powerful general-purpose reasoning systems. However, radio-frequency (RF) signals, which underpin wireless systems, are still not natively supported by these models. Existing LLM-based approaches for telecom focus mainly on text and structured data, while conventional RF deep-learning models are built separately for specific signal-processing tasks, highlighting a clear gap between RF perception and high-level reasoning. To bridge this gap, we introduce RF-GPT, a radio-frequency language model (RFLM) that utilizes the visual encoders of multimodal LLMs to process and understand RF spectrograms. In this framework, complex in-phase/quadrature (IQ) waveforms are mapped to time-frequency spectrograms and then passed to pretrained visual encoders. The resulting representations are injected as RF tokens into a decoder-only LLM, which generates RF-grounded answers, explanations, and structured outputs. To train RF-GPT, we perform supervised instruction fine-tuning of a pretrained multimodal LLM using a fully synthetic RF corpus. Standards-compliant waveform generators produce wideband scenes for six wireless technologies, from which we derive time-frequency spectrograms, exact configuration metadata, and dense captions. A text-only LLM then converts these captions into RF-grounded instruction-answer pairs, yielding roughly 12,000 RF scenes and 0.625 million instruction examples without any manual labeling. Across benchmarks for wideband modulation classification, overlap analysis, wireless-technology recognition, WLAN user counting, and 5G NR information extraction, RF-GPT achieves strong multi-task performance, whereas general-purpose VLMs with no RF grounding largely fail.

</details>


### [27] [Lattice XBAR Filters in Thin-Film Lithium Niobate](https://arxiv.org/abs/2602.14937)
*Taran Anusorn,Byeongjin Kim,Ian Anderson,Ziqian Yao,Ruochen Lu*

Main category: eess.SP

TL;DR: 基于横向激发体声波谐振器(XBAR)的晶格滤波器演示，在P3F TFLN上实现27.42%和39.11%的3dB分数带宽，插入损耗低于1dB，面积小于1.3mm²。


<details>
  <summary>Details</summary>
Motivation: 开发用于下一代无线通信和传感系统的高性能RF前端，需要紧凑、低损耗、宽带声学滤波器。XBAR在P3F TFLN中具有强机电耦合特性，结合晶格拓扑的宽带特性，有望实现这一目标。

Method: 采用横向激发体声波谐振器(XBAR)和晶格滤波器拓扑结构，在周期性极化压电薄膜(P3F)薄层铌酸锂(TFLN)上设计并制造了两种滤波器：直接晶格和布局平衡晶格拓扑。

Result: 在约20GHz频率下，直接晶格滤波器实现27.42%的3dB分数带宽和0.88dB插入损耗；布局平衡晶格滤波器实现39.11%的3dB分数带宽和0.96dB插入损耗。所有原型芯片面积均小于1.3mm²。

Conclusion: XBAR基晶格架构在实现低损耗、宽带声学滤波器方面具有巨大潜力，适用于紧凑型高性能RF前端，同时指出了进一步优化的关键挑战和方向。

Abstract: This work presents the demonstration of lattice filters based on laterally excited bulk acoustic resonators (XBARs). Two filter implementations, namely direct lattice and layout-balanced lattice topologies, are designed and fabricated in periodically poled piezoelectric film (P3F) thin-film lithium niobate (TFLN). By leveraging the strong electromechanical coupling of XBARs in P3F TFLN together with the inherently wideband nature of the lattice topology, 3-dB fractional bandwidths (FBWs) of 27.42\% and 39.11\% and low insertion losses (ILs) of 0.88 dB and 0.96 dB are achieved at approximately 20 GHz for the direct and layout-balanced lattice filters, respectively, under conjugate matching. Notably, all prototypes feature compact footprints smaller than 1.3 mm\textsuperscript{2}. These results highlight the potential of XBAR-based lattice architectures to enable low-loss, wideband acoustic filters for compact, high-performance RF front ends in next-generation wireless communication and sensing systems, while also identifying key challenges and directions for further optimization.

</details>


### [28] [Real-time Range-Angle Estimation and Tag Localization for Multi-static Backscatter Systems](https://arxiv.org/abs/2602.14985)
*Tara Esmaeilbeig,Kartik Patel,Traian E. Abrudan,John Kimionis,Eleftherios Kampianakis,Michael S. Eggleston*

Main category: eess.SP

TL;DR: 提出两种低复杂度算法JRAC和SRAE用于多静态反向散射网络的实时定位，在保持精度的同时大幅降低计算复杂度，在真实测试中实现3米中值定位误差


<details>
  <summary>Details</summary>
Motivation: 6G环境物联网中，大规模多静态部署需要高效的实时定位算法，现有方法计算复杂度高，难以扩展到数千设备

Method: 提出两种低复杂度算法：联合距离-角度聚类(JRAC)和分阶段距离-角度估计(SRAE)；以及两种实时定位算法：基于梯度搜索的最大似然法和迭代重加权最小二乘法(IRLS)

Result: JRAC和SRAE将运行时间减少40倍，IRLS比暴力搜索ML方法减少500倍复杂度，在4个发射器、1个多天线接收器、100个标签的真实测试中实现3米中值定位误差

Conclusion: 提出的多静态距离-角度估计和定位算法使实时、可扩展的反向散射定位在下一代环境物联网网络中变得实用可行

Abstract: Multi-static backscatter networks (BNs) are strong candidates for joint communication and localization in the ambient IoT paradigm for 6G. Enabling real-time localization in large-scale multi-static deployments with thousands of devices require highly efficient algorithms for estimating key parameters such as range and angle of arrival (AoA), and for fusing these parameters into location estimates. We propose two low-complexity algorithms, Joint Range-Angle Clustering (JRAC) and Stage-wise Range-Angle Estimation (SRAE). Both deliver range and angle estimation accuracy comparable to FFT- and subspace-based baselines while significantly reducing the computation. We then introduce two real-time localization algorithms that fuse the estimated ranges and AoAs: a maximum-likelihood (ML) method solved via gradient search and an iterative re-weighted least squares (IRLS) method. Both achieve localization accuracy comparable to ML-based brute force search albeit with far lower complexity. Experiments on a real-world large-scale multi-static testbed with 4 illuminators, 1 multi-antenna receiver, and 100 tags show that JRAC and SRAE reduce runtime by up to 40X and IRLS achieves up to 500X reduction over ML-based brute force search without degrading localization accuracy. The proposed methods achieve 3 m median localization error across all 100 tags in a sub-6GHz band with 40 MHz bandwidth. These results demonstrate that multi-static range-angle estimation and localization algorithms can make real-time, scalable backscatter localization practical for next-generation ambient IoT networks.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [29] [ELEAT-SAGA: Early & Late Integration with Evading Alternating Training for Spoof-Robust Speaker Verification](https://arxiv.org/abs/2602.13761)
*Amro Asali,Yehuda Ben-Shimol,Itshak Lapidot*

Main category: eess.AS

TL;DR: 提出SASV-SAGA架构，通过分数感知门控注意力动态调制说话人嵌入，结合ECAPA-TDNN和AASIST模型，在ASVspoof 2019数据集上取得优异性能。


<details>
  <summary>Details</summary>
Motivation: 传统自动说话人验证系统容易受到零努力冒名攻击和语音转换、文本转语音等欺骗攻击，需要构建同时抵御这两种攻击的鲁棒系统。

Method: 提出SASV-SAGA架构，引入分数感知门控注意力机制，动态调制基于反欺骗分数的说话人嵌入。集成预训练的ECAPA-TDNN和AASIST模型，探索早期、晚期和完全集成策略。提出交替训练多模块和规避交替训练方法。

Result: 在ASVspoof 2019 LA和Spoofceleb数据集上显著超越基线，SASV-EER达到1.22%，最小归一化不可知检测代价函数为0.0304。

Conclusion: 分数感知注意力机制和交替训练策略能有效增强SASV系统的鲁棒性，为欺骗鲁棒的说话人验证提供了有效解决方案。

Abstract: Spoofing-robust automatic speaker verification (SASV) seeks to build automatic speaker verification systems that are robust against both zero-effort impostor attacks and sophisticated spoofing techniques such as voice conversion (VC) and text-to-speech (TTS). In this work, we propose a novel SASV architecture that introduces score-aware gated attention (SAGA), SASV-SAGA, enabling dynamic modulation of speaker embeddings based on countermeasure (CM) scores. By integrating speaker embeddings and CM scores from pre-trained ECAPA-TDNN and AASIST models respectively, we explore several integration strategies including early, late, and full integration. We further introduce alternating training for multi-module (ATMM) and a refined variant, evading alternating training (EAT). Experimental results on the ASVspoof 2019 Logical Access (LA) and Spoofceleb datasets demonstrate significant improvements over baselines, achieving a spoofing aware speaker verification equal error rate (SASV-EER) of 1.22% and minimum normalized agnostic detection cost function (min a-DCF) of 0.0304 on the ASVspoof 2019 evaluation set. These results confirm the effectiveness of score-aware attention mechanisms and alternating training strategies in enhancing the robustness of SASV systems.

</details>


### [30] [CLAP-Based Automatic Word Naming Recognition in Post-Stroke Aphasia](https://arxiv.org/abs/2602.14584)
*Yacouba Kaloga,Marina Laganaro,Ina Kodrasi*

Main category: eess.AS

TL;DR: 提出基于对比语言-音频预训练(CLAP)的方法，用于失语症患者的自动单词命名识别，通过音频-文本对齐解决发音不流畅和错误问题。


<details>
  <summary>Details</summary>
Motivation: 传统的自动单词命名识别系统难以识别中风后失语症患者的发音，因为存在不流畅和错误发音问题，限制了该人群的可靠自动化评估。

Method: 采用对比语言-音频预训练(CLAP)方法，将单词命名识别视为音频-文本匹配问题，将语音信号和文本提示投影到共享嵌入空间，即使在困难录音中也能识别目标单词。

Result: 在法国中风后失语症患者的两个语音数据集上评估，该方法达到高达90%的准确率，优于现有的基于分类和自动语音识别的基线方法。

Conclusion: 基于CLAP的音频-文本匹配方法能够有效识别失语症患者的单词命名，为这一人群的自动化评估提供了可靠解决方案。

Abstract: Conventional automatic word-naming recognition systems struggle to recognize words from post-stroke patients with aphasia because of disfluencies and mispronunciations, limiting reliable automated assessment in this population. In this paper, we propose a Contrastive Language-Audio Pretraining (CLAP) based approach for automatic word-naming recognition to address this challenge by leveraging text-audio alignment. Our approach treats word-naming recognition as an audio-text matching problem, projecting speech signals and textual prompts into a shared embedding space to identify intended words even in challenging recordings. Evaluated on two speech datasets of French post-stroke patients with aphasia, our approach achieves up to 90% accuracy, outperforming existing classification-based and automatic speech recognition-based baselines.

</details>


### [31] [LongAudio-RAG: Event-Grounded Question Answering over Multi-Hour Long Audio](https://arxiv.org/abs/2602.14612)
*Naveen Vakada,Kartik Hegde,Arvind Krishna Sridhar,Yinyi Guo,Erik Visser*

Main category: eess.AS

TL;DR: LA-RAG是一个针对长音频问答的混合框架，通过将音频转换为结构化事件记录存储在SQL数据库中，结合检索增强生成技术，在边缘设备进行事件检测，云端进行语言推理，显著提高了长音频问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 工业和个人场景中长音频内容日益增多，但人工审阅多小时录音不现实。现有音频语言模型受限于上下文长度，难以处理长音频问答任务，需要能够精确时间定位且幻觉最小化的系统。

Method: 提出LongAudio-RAG混合框架：将多小时音频流转换为带时间戳的声学事件检测记录，存储在SQL数据库中；推理时解析自然语言时间引用、分类意图、检索相关事件，基于约束证据生成答案。采用边缘-云混合部署，边缘设备运行音频基础模型，云端运行LLM。

Result: 实验表明，结构化的事件级检索相比传统RAG或text-to-SQL方法显著提高了准确性。通过合成长音频基准测试验证了系统在检测、计数和总结任务上的性能。

Conclusion: LA-RAG通过将音频转换为结构化事件记录并采用混合检索增强生成方法，有效解决了长音频问答的挑战。边缘-云架构实现了低延迟事件提取和高质量语言推理的平衡，为实际部署提供了可行性。

Abstract: Long-duration audio is increasingly common in industrial and consumer settings, yet reviewing multi-hour recordings is impractical, motivating systems that answer natural-language queries with precise temporal grounding and minimal hallucination. Existing audio-language models show promise, but long-audio question answering remains difficult due to context-length limits. We introduce LongAudio-RAG (LA-RAG), a hybrid framework that grounds Large Language Model (LLM) outputs in retrieved, timestamped acoustic event detections rather than raw audio. Multi-hour streams are converted into structured event records stored in an SQL database, and at inference time the system resolves natural-language time references, classifies intent, retrieves only the relevant events, and generates answers using this constrained evidence. To evaluate performance, we construct a synthetic long-audio benchmark by concatenating recordings with preserved timestamps and generating template-based question-answer pairs for detection, counting, and summarization tasks. Finally, we demonstrate the practicality of our approach by deploying it in a hybrid edge-cloud environment, where the audio grounding model runs on-device on IoT-class hardware while the LLM is hosted on a GPU-backed server. This architecture enables low-latency event extraction at the edge and high-quality language reasoning in the cloud. Experiments show that structured, event-level retrieval significantly improves accuracy compared to vanilla Retrieval-Augmented Generation (RAG) or text-to-SQL approaches.

</details>


### [32] [Data Augmentation for Pathological Speech Enhancement](https://arxiv.org/abs/2602.14671)
*Mingchi Hou,Enno Hermann,Ina Kodrasi*

Main category: eess.AS

TL;DR: 研究系统评估了三种数据增强策略（变换增强、生成增强、噪声增强）对病理语音增强模型性能的影响，发现噪声增强效果最佳，生成增强效果有限甚至有害，且数据增强对预测性模型更有效。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的语音增强模型在病理语音上性能显著下降，主要由于病理语音具有非典型声学特征和训练数据有限。需要研究数据增强策略来改善病理语音的增强性能。

Method: 系统研究了三种数据增强类别：变换增强（transformative）、生成增强（generative）和噪声增强（noise augmentation）。使用客观SE指标评估这些增强策略对预测性和生成性语音增强模型的影响。

Result: 噪声增强带来最大且最稳健的性能提升；变换增强提供中等改进；生成增强效果有限，随着合成数据增加甚至可能损害性能。数据增强对预测性SE模型更有效，但病理语音与正常语音之间仍存在性能差距。

Conclusion: 数据增强能改善病理语音的增强性能，但需要针对病理语音开发更专门的数据增强策略，以缩小病理语音与正常语音之间的性能差距。

Abstract: The performance of state-of-the-art speech enhancement (SE) models considerably degrades for pathological speech due to atypical acoustic characteristics and limited data availability. This paper systematically investigates data augmentation (DA) strategies to improve SE performance for pathological speakers, evaluating both predictive and generative SE models. We examine three DA categories, i.e., transformative, generative, and noise augmentation, assessing their impact with objective SE metrics. Experimental results show that noise augmentation consistently delivers the largest and most robust gains, transformative augmentations provide moderate improvements, while generative augmentation yields limited benefits and can harm performance as the amount of synthetic data increases. Furthermore, we show that the effectiveness of DA varies depending on the SE model, with DA being more beneficial for predictive SE models. While our results demonstrate that DA improves SE performance for pathological speakers, a performance gap between neurotypical and pathological speech persists, highlighting the need for future research on targeted DA strategies for pathological speech.

</details>


### [33] [Disentangling Pitch and Creak for Speaker Identity Preservation in Speech Synthesis](https://arxiv.org/abs/2602.14686)
*Frederik Rautenberg,Jana Wiechmann,Petra Wagner,Reinhold Haeb-Umbach*

Main category: eess.AS

TL;DR: 提出一个能够忠实修改语音中creak（吱吱声）感知质量同时保持说话人身份感知的系统，通过条件连续归一化流实现音高与creak的解耦。


<details>
  <summary>Details</summary>
Motivation: 虽然高creak概率通常与低音高相关，但这只是群体统计特性，并不适用于所有情况。需要开发能够独立控制creak而不影响说话人身份和音高的系统。

Method: 通过在语音合成系统的训练数据集中添加基于条件连续归一化流（conditional continuous normalizing flow）的说话人操作模块，实现音高与creak的解耦。

Result: 实验显示，在各种creak操作强度下，说话人验证性能都得到了显著改善，表明系统能够有效修改creak感知质量而不损害说话人身份识别。

Conclusion: 提出的系统成功实现了creak感知质量的忠实修改，同时保持了说话人身份的感知，为语音质量控制和说话人身份保护提供了有效解决方案。

Abstract: We introduce a system capable of faithfully modifying the perceptual voice quality of creak while preserving the speaker's perceived identity. While it is well known that high creak probability is typically correlated with low pitch, it is important to note that this is a property observed on a population of speakers but does not necessarily hold across all situations. Disentanglement of pitch from creak is achieved by augmentation of the training dataset of a speech synthesis system with a speaker manipulation block based on conditional continuous normalizing flow. The experiments show greatly improved speaker verification performance over a range of creak manipulation strengths.

</details>


### [34] [SA-SSL-MOS: Self-supervised Learning MOS Prediction with Spectral Augmentation for Generalized Multi-Rate Speech Assessment](https://arxiv.org/abs/2602.14785)
*Fengyuan Cao,Xinyu Liang,Fredrik Cumlin,Victor Ungureanu,Chandan K. A. Reddy,Christian Schuldt,Saikat Chatterjee*

Main category: eess.AS

TL;DR: 提出一种频谱图增强的自监督学习方法，通过并行分支架构整合高频特征（最高48kHz采样率），并采用两步训练方案，显著提升多速率语音质量评估的准确性。


<details>
  <summary>Details</summary>
Motivation: 多速率语音质量评估面临挑战，因为现有自监督学习模型主要在16kHz语音上预训练，丢弃了更高采样率（16-48kHz）中的高频信息，且多速率MOS标注数据有限。

Method: 提出频谱图增强的自监督学习方法，采用并行分支架构整合高频特征（最高48kHz），并设计两步训练方案：先在大型48kHz数据集上预训练，然后在较小的多速率数据集上微调。

Result: 实验结果表明，利用自监督学习特征忽略的高频信息对准确的多速率语音质量评估至关重要，提出的两步训练方案在有限多速率数据下显著提升了模型的泛化能力。

Conclusion: 通过整合高频特征和两步训练策略，有效解决了多速率语音质量评估中自监督学习模型对高频信息利用不足的问题，提升了模型在有限多速率数据下的性能。

Abstract: Designing a speech quality assessment (SQA) system for estimating mean-opinion-score (MOS) of multi-rate speech with varying sampling frequency (16-48 kHz) is a challenging task. The challenge arises due to the limited availability of a MOS-labeled training dataset comprising multi-rate speech samples. While self-supervised learning (SSL) models have been widely adopted in SQA to boost performance, a key limitation is that they are pretrained on 16 kHz speech and therefore discard high-frequency information present in higher sampling rates. To address this issue, we propose a spectrogram-augmented SSL method that incorporates high-frequency features (up to 48 kHz sampling rate) through a parallel-branch architecture. We further introduce a two-step training scheme: the model is first pre-trained on a large 48 kHz dataset and then fine-tuned on a smaller multi-rate dataset. Experimental results show that leveraging high-frequency information overlooked by SSL features is crucial for accurate multi-rate SQA, and that the proposed two-step training substantially improves generalization when multi-rate data is limited.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [35] [Learning Physiology-Informed Vocal Spectrotemporal Representations for Speech Emotion Recognition](https://arxiv.org/abs/2602.13259)
*Xu Zhang,Longbing Cao,Runze Yang,Zhangkai Wu*

Main category: cs.SD

TL;DR: 提出PhysioSER方法，通过生理学信息的声音谱时表示学习，结合声带解剖生理学特征与自监督学习模型，实现可解释且高效的语音情感识别。


<details>
  <summary>Details</summary>
Motivation: 现有深度语音情感识别模型缺乏可解释性，未能充分建模情感声学信号的核心生理机制，特别是忽略了声带振幅与相位的生理耦合特征。

Method: PhysioSER包含两个并行分支：1) 基于声带解剖生理学的特征表示分支，将声音信号分解并嵌入四元数域，使用Hamilton结构四元数卷积建模动态交互；2) 基于冻结自监督学习的潜在表示分支。通过对比投影对齐框架融合两个分支的特征，最后使用浅层注意力融合头进行分类。

Result: 在14个数据集、10种语言、6种骨干网络上进行了广泛评估，证明PhysioSER具有可解释性和高效性，并在人形机器人平台上验证了实时部署的实用性。

Conclusion: PhysioSER通过整合生理学知识，提供了一种紧凑、即插即用的语音情感识别方法，在保持模型效率的同时增强了可解释性，适用于人形机器人等需要安全性和性能的应用场景。

Abstract: Speech emotion recognition (SER) is essential for humanoid robot tasks such as social robotic interactions and robotic psychological diagnosis, where interpretable and efficient models are critical for safety and performance. Existing deep models trained on large datasets remain largely uninterpretable, often insufficiently modeling underlying emotional acoustic signals and failing to capture and analyze the core physiology of emotional vocal behaviors. Physiological research on human voices shows that the dynamics of vocal amplitude and phase correlate with emotions through the vocal tract filter and the glottal source. However, most existing deep models solely involve amplitude but fail to couple the physiological features of and between amplitude and phase. Here, we propose PhysioSER, a physiology-informed vocal spectrotemporal representation learning method, to address these issues with a compact, plug-and-play design. PhysioSER constructs amplitude and phase views informed by voice anatomy and physiology (VAP) to complement SSL models for SER. This VAP-informed framework incorporates two parallel workflows: a vocal feature representation branch to decompose vocal signals based on VAP, embed them into a quaternion field, and use Hamilton-structured quaternion convolutions for modeling their dynamic interactions; and a latent representation branch based on a frozen SSL backbone. Then, utterance-level features from both workflows are aligned by a Contrastive Projection and Alignment framework, followed by a shallow attention fusion head for SER classification. PhysioSER is shown to be interpretable and efficient for SER through extensive evaluations across 14 datasets, 10 languages, and 6 backbones, and its practical efficacy is validated by real-time deployment on a humanoid robotic platform.

</details>


### [36] [BreathNet: Generalizable Audio Deepfake Detection via Breath-Cue-Guided Feature Refinement](https://arxiv.org/abs/2602.13596)
*Zhe Ye,Xiangui Kang,Jiayi He,Chengxin Chen,Wei Zhu,Kai Wu,Yin Yang,Jiwu Huang*

Main category: cs.SD

TL;DR: BreathNet：一种集成细粒度呼吸信息的新型音频深度伪造检测框架，通过BreathFiLM机制选择性放大呼吸声相关的时序表征，结合频谱特征融合，在多个基准测试中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 随着深度伪造音频变得更加逼真和多样化，开发泛化性强的检测系统变得至关重要。现有方法主要依赖XLS-R前端特征，但性能仍然有限，部分原因是对生理线索或频域特征等细粒度信息关注不足。

Method: 提出BreathNet框架：1) 设计BreathFiLM特征线性调制机制，基于呼吸声存在选择性放大时序表征；2) 使用频率前端提取频谱特征，与时序特征融合；3) 提出特征损失组（PSCL、中心损失、对比损失）增强判别能力。

Result: 在五个基准数据集上实现SOTA：使用ASVspoof 2019 LA训练集，在四个相关评估基准上平均EER为1.99%，在In-the-Wild数据集上达到4.70% EER；在ASVspoof5评估协议下，最新基准上EER为4.94%。

Conclusion: BreathNet通过整合细粒度呼吸信息有效提升了音频深度伪造检测的泛化能力，BreathFiLM机制和特征损失组的联合优化策略显著增强了模型的判别性能，在多个挑战性场景下均表现出色。

Abstract: As deepfake audio becomes more realistic and diverse, developing generalizable countermeasure systems has become crucial. Existing detection methods primarily depend on XLS-R front-end features to improve generalization. Nonetheless, their performance remains limited, partly due to insufficient attention to fine-grained information, such as physiological cues or frequency-domain features. In this paper, we propose BreathNet, a novel audio deepfake detection framework that integrates fine-grained breath information to improve generalization. Specifically, we design BreathFiLM, a feature-wise linear modulation mechanism that selectively amplifies temporal representations based on the presence of breathing sounds. BreathFiLM is trained jointly with the XLS-R extractor, in turn encouraging the extractor to learn and encode breath-related cues into the temporal features. Then, we use the frequency front-end to extract spectral features, which are then fused with temporal features to provide complementary information introduced by vocoders or compression artifacts. Additionally, we propose a group of feature losses comprising Positive-only Supervised Contrastive Loss (PSCL), center loss, and contrast loss. These losses jointly enhance the discriminative ability, encouraging the model to separate bona fide and deepfake samples more effectively in the feature space. Extensive experiments on five benchmark datasets demonstrate state-of-the-art (SOTA) performance. Using the ASVspoof 2019 LA training set, our method attains 1.99% average EER across four related eval benchmarks, with particularly strong performance on the In-the-Wild dataset, where it achieves 4.70% EER. Moreover, under the ASVspoof5 evaluation protocol, our method achieves an EER of 4.94% on this latest benchmark.

</details>


### [37] [AuTAgent: A Reinforcement Learning Framework for Tool-Augmented Audio Reasoning](https://arxiv.org/abs/2602.13685)
*Siqian Tong,Xuan Li,Yiwei Wang,Baolong Bi,Yujun Cai,Shenghua Liu,Yuchen He,Chengpeng Hao*

Main category: cs.SD

TL;DR: AuTAgent是一个强化学习框架，通过智能调用外部音频工具来增强大型音频语言模型的推理能力，解决了信息过载和工具选择难题。


<details>
  <summary>Details</summary>
Motivation: 大型音频语言模型在感知方面表现优异，但在需要精确声学测量的复杂推理任务上存在困难。虽然外部工具可以提取细粒度特征，但如何有效集成这些工具面临挑战：盲目使用所有工具会导致信息过载，而基于提示的选择方法无法评估工具在特定上下文中的效用。

Method: 提出AuTAgent（音频工具代理），一个强化学习框架，学习何时以及调用哪些工具。采用稀疏反馈训练策略和新型差分奖励机制，使代理能够过滤无关工具，仅在外部辅助能带来净性能提升时调用。

Result: 在MMAU Test-mini和MMAR基准测试中，对开源和闭源骨干模型的准确率分别提升了4.20%/6.20%和9.80%/8.00%。实验还展示了出色的可迁移性，证明了外部工具在增强音频模型推理中的补充作用。

Conclusion: AuTAgent通过提供可验证的声学证据，弥补了大型音频语言模型的表示瓶颈，突出了外部工具在增强音频模型推理能力中的互补作用。

Abstract: Large Audio Language Models (LALMs) excel at perception but struggle with complex reasoning requiring precise acoustic measurements. While external tools can extract fine-grained features like exact tempo or pitch, effective integration remains challenging: naively using all tools causes information overload, while prompt-based selection fails to assess context-dependent utility. To address this, we propose AuTAgent (Audio Tool Agent), a reinforcement learning framework that learns when and which tools to invoke. By employing a sparse-feedback training strategy with a novel Differential Reward mechanism, the agent learns to filter out irrelevant tools and invokes external assistance only when it yields a net performance gain over the base model. Experimental results confirm that AuTAgent complements the representation bottleneck of LALMs by providing verifiable acoustic evidence. It improves accuracy by 4.20% / 6.20% and 9.80% / 8.00% for open-source and closed-source backbones on the MMAU Test-mini and the MMAR benchmarks, respectively. In addition, further experiments demonstrate exceptional transferability. We highlight the complementary role of external tools in augmenting audio model reasoning.

</details>


### [38] [Enhancing spatial hearing with cochlear implants: exploring the role of AI, multimodal interaction and perceptual training](https://arxiv.org/abs/2602.13787)
*Lorenzo Picinali,Robert Baumgartner,Valerie Gaveau,Antonino Greco,Stefanie Liebe,Paul Oomen,Christoph Braun*

Main category: cs.SD

TL;DR: 提出多学科研究框架，改善人工耳蜗使用者的空间听觉能力


<details>
  <summary>Details</summary>
Motivation: 虽然人工耳蜗在恢复听力和言语理解方面取得了显著进展，但空间听觉这一对注意力控制和嘈杂环境中言语理解至关重要的功能在过去被忽视。空间听觉对人工耳蜗使用者的生活质量有重要影响。

Method: 提出多学科协作研究框架，整合医生、心理学家和工程师的专业知识，共同研究改善人工耳蜗使用者的空间听觉能力。

Result: 论文提出了一个研究框架，但未提供具体实验结果。该框架旨在通过跨学科合作来解决人工耳蜗使用者空间听觉能力不足的问题。

Conclusion: 需要建立多学科研究框架来改善人工耳蜗使用者的空间听觉能力，这对提升他们在嘈杂环境中的言语理解和整体生活质量至关重要。

Abstract: Cochlear implants (CIs) have been developed to the point where they can restore hearing and speech understanding in a large proportion of patients. Although spatial hearing is central to controlling and directing attention and to enabling speech understanding in noisy environments, it has been largely neglected in the past. We propose here a multi-disciplinary research framework in which physicians, psychologists and engineers collaborate to improve spatial hearing for CI users.

</details>


### [39] [Learning Vocal-Tract Area and Radiation with a Physics-Informed Webster Model](https://arxiv.org/abs/2602.13834)
*Minhui Lu,Joshua D. Reiss*

Main category: cs.SD

TL;DR: 提出了一种基于物理的语音合成后端渲染器，使用Webster模型作为物理信息神经网络来估计可解释的声道面积函数和开放端辐射系数，推理过程完全基于物理原理。


<details>
  <summary>Details</summary>
Motivation: 当前语音合成系统通常使用黑盒模型，缺乏物理可解释性。本文旨在开发一个基于物理原理的语音合成后端渲染器，能够提供可解释的声道参数估计，同时保持合成质量。

Method: 使用Webster模型作为物理信息神经网络，在时域中训练以估计声道面积函数和开放端辐射系数。训练过程强制满足偏微分方程和边界一致性，使用轻量级DDSP路径来稳定学习，但推理过程完全基于物理原理。

Result: 在持续元音（/a/, /i/, /u/）上，通过独立有限差分时域Webster求解器渲染的参数能够与紧凑DDSP基线竞争性地重现频谱包络，并且在离散化变化、适度源变化和约10%音高偏移下保持稳定。

Conclusion: 提出的物理信息语音后端渲染器能够提供可解释的声道参数估计，同时保持合成质量。当前波形比参考信号更呼吸声，未来工作需要周期性感知目标和显式声门先验来改进。

Abstract: We present a physics-informed voiced backend renderer for singing-voice synthesis. Given synthetic single-channel audio and a fund-amental--frequency trajectory, we train a time-domain Webster model as a physics-informed neural network to estimate an interpretable vocal-tract area function and an open-end radiation coefficient. Training enforces partial differential equation and boundary consistency; a lightweight DDSP path is used only to stabilize learning, while inference is purely physics-based. On sustained vowels (/a/, /i/, /u/), parameters rendered by an independent finite-difference time-domain Webster solver reproduce spectral envelopes competitively with a compact DDSP baseline and remain stable under changes in discretization, moderate source variations, and about ten percent pitch shifts. The in-graph waveform remains breathier than the reference, motivating periodicity-aware objectives and explicit glottal priors in future work.

</details>


### [40] [Audiocards: Structured Metadata Improves Audio Language Models For Sound Design](https://arxiv.org/abs/2602.13835)
*Sripathi Sridhar,Prem Seetharaman,Oriol Nieto,Mark Cartwright,Justin Salamon*

Main category: cs.SD

TL;DR: 提出audiocards结构化元数据方法，利用LLM世界知识生成声学属性和声音描述符，改善音效库的文本-音频检索、描述性字幕和元数据生成


<details>
  <summary>Details</summary>
Motivation: 音效设计师需要基于声音类别或视觉上下文搜索大型音效库，但所需元数据常常缺失或不完整，手动添加工作量巨大。现有自动化解决方案（字幕生成和文本-音频检索）未针对音效设计特有的结构和信息进行训练

Method: 提出audiocards结构化元数据框架，利用大型语言模型的世界知识，生成基于声学属性和声音描述符的元数据。通过训练模型使用这种结构化元数据来改进音效库的相关任务

Result: 训练使用audiocards能显著改善下游任务：文本-音频检索、描述性字幕生成和专业音效库的元数据生成。同时，在通用音频字幕和检索任务上也优于传统的单句字幕方法

Conclusion: audiocards为音效设计提供了有效的结构化元数据解决方案，利用LLM知识改善了音频-语言建模任务。发布了音效audiocards数据集以促进音效设计领域的音频语言建模研究

Abstract: Sound designers search for sounds in large sound effects libraries using aspects such as sound class or visual context. However, the metadata needed for such search is often missing or incomplete, and requires significant manual effort to add. Existing solutions to automate this task by generating metadata, i.e. captioning, and search using learned embeddings, i.e. text-audio retrieval, are not trained on metadata with the structure and information pertinent to sound design. To this end we propose audiocards, structured metadata grounded in acoustic attributes and sonic descriptors, by exploiting the world knowledge of LLMs. We show that training on audiocards improves downstream text-audio retrieval, descriptive captioning, and metadata generation on professional sound effects libraries. Moreover, audiocards also improve performance on general audio captioning and retrieval over the baseline single-sentence captioning approach. We release a curated dataset of sound effects audiocards to invite further research in audio language modeling for sound design.

</details>


### [41] [GSRM: Generative Speech Reward Model for Speech RLHF](https://arxiv.org/abs/2602.13891)
*Maohao Shen,Tejas Jayashankar,Osama Hanna,Naoyuki Kanda,Yancheng Wang,Kateřina Žmolíková,Ruiming Xie,Niko Moritz,Anfeng Xu,Yashesh Gaur,Gregory Wornell,Qing He,Jilong Wu*

Main category: cs.SD

TL;DR: 提出GSRM生成式语音奖励模型，通过可解释的声学特征提取和特征驱动的思维链推理来评估语音自然度，显著超越现有方法并接近人类评分一致性。


<details>
  <summary>Details</summary>
Motivation: 当前语音语言模型（如GPT-4o Voice Mode和Gemini Live）的生成质量虽有进步，但合成音频的美学自然度仍不及真人语音。提升生成质量需要可靠的语音自然度评估器，而现有评估器通常将原始音频回归为标量分数，解释性有限且难以泛化到不同分类的语音。

Method: 提出生成式语音奖励模型（GSRM），采用推理中心的奖励建模方法。模型将语音自然度评估分解为两个阶段：1）可解释的声学特征提取；2）基于特征的思维链推理，实现可解释的判断。为此构建了大规模人类反馈数据集，包含31k专家评分和真实世界用户-助手语音交互的域外基准。

Result: 实验表明GSRM显著优于现有语音自然度预测器，在自然度分数预测上达到接近人类评分者一致性的模型-人类相关性。进一步展示GSRM可通过作为在线RLHF的有效验证器来提升语音LLM生成的自然度。

Conclusion: GSRM通过可解释的声学特征提取和特征驱动的思维链推理，为语音自然度评估提供了更可靠、可解释的解决方案，能够有效提升语音语言模型的生成质量。

Abstract: Recent advances in speech language models, such as GPT-4o Voice Mode and Gemini Live, have demonstrated promising speech generation capabilities. Nevertheless, the aesthetic naturalness of the synthesized audio still lags behind that of human speech. Enhancing generation quality requires a reliable evaluator of speech naturalness. However, existing naturalness evaluators typically regress raw audio to scalar scores, offering limited interpretability of the evaluation and moreover fail to generalize to speech across different taxonomies. Inspired by recent advances in generative reward modeling, we propose the Generative Speech Reward Model (GSRM), a reasoning-centric reward model tailored for speech. The GSRM is trained to decompose speech naturalness evaluation into an interpretable acoustic feature extraction stage followed by feature-grounded chain-of-thought reasoning, enabling explainable judgments. To achieve this, we curated a large-scale human feedback dataset comprising 31k expert ratings and an out-of-domain benchmark of real-world user-assistant speech interactions. Experiments show that GSRM substantially outperforms existing speech naturalness predictors, achieving model-human correlation of naturalness score prediction that approaches human inter-rater consistency. We further show how GSRM can improve the naturalness of speech LLM generations by serving as an effective verifier for online RLHF.

</details>


### [42] [voice2mode: Phonation Mode Classification in Singing using Self-Supervised Speech Models](https://arxiv.org/abs/2602.13928)
*Aju Ani Justus,Ruchit Agrawal,Sudarsana Reddy Kadiri,Shrikanth Narayanan*

Main category: cs.SD

TL;DR: voice2mode使用自监督语音模型的嵌入来分类四种歌唱发声模式（气声、中性、流动、挤压），在女高音数据集上达到95.7%准确率，比传统声谱特征提升12-15%。


<details>
  <summary>Details</summary>
Motivation: 现有歌唱发声分类研究依赖手工特征或任务特定神经网络，本文旨在评估语音基础模型在歌唱发声分类任务上的可迁移性。

Method: 从HuBERT和wav2vec2变体中提取层级表示，应用全局时序池化，使用轻量级分类器（SVM、XGBoost）对池化后的嵌入进行分类。

Result: 基础模型特征显著优于传统声谱基线，HuBERT早期层嵌入获得最佳结果（约95.7%准确率），比最佳传统基线绝对提升12-15%。

Conclusion: 语音基础模型可有效迁移到歌唱发声分类任务，早期层保留声学/语音细节，比专门用于ASR的顶层更有效。

Abstract: We present voice2mode, a method for classification of four singing phonation modes (breathy, neutral (modal), flow, and pressed) using embeddings extracted from large self-supervised speech models. Prior work on singing phonation has relied on handcrafted signal features or task-specific neural nets; this work evaluates the transferability of speech foundation models to singing phonation classification. voice2mode extracts layer-wise representations from HuBERT and two wav2vec2 variants, applies global temporal pooling, and classifies the pooled embeddings with lightweight classifiers (SVM, XGBoost). Experiments on a publicly available soprano dataset (763 sustained vowel recordings, four labels) show that foundation-model features substantially outperform conventional spectral baselines (spectrogram, mel-spectrogram, MFCC). HuBERT embeddings obtained from early layers yield the best result (~95.7% accuracy with SVM), an absolute improvement of ~12-15% over the best traditional baseline. We also show layer-wise behaviour: lower layers, which retain acoustic/phonetic detail, are more effective than top layers specialized for Automatic Speech Recognition (ASR).

</details>


### [43] [Eureka-Audio: Triggering Audio Intelligence in Compact Language Models](https://arxiv.org/abs/2602.13954)
*Dan Zhang,Yishu Lei,Jing Hu,Shuwei He,Songhe Deng,Xianlong Luo,Danxiang Zhu,Shikun Feng,Rui Liu,Jingzhou He,Yu Sun,Hua Wu,Haifeng Wang*

Main category: cs.SD

TL;DR: Eureka-Audio是一个仅1.7B参数的高性能音频语言模型，在多项音频理解任务上表现优于4-18倍大的模型，采用统一端到端架构和MoE适配器，并通过DataFlux数据合成管道增强推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前音频语言模型通常需要大量参数才能达到高性能，导致计算成本高昂。需要开发轻量级但性能优异的模型，以在有限计算资源下实现高效的音频理解能力。

Method: 1. 采用统一端到端架构：轻量级语言主干 + Whisper音频编码器 + 稀疏激活的MoE适配器（处理音频异质性，缓解跨模态优化冲突）
2. 引入DataFlux：闭环音频指令数据合成与验证管道，从原始音频构建高质量、逻辑一致的监督数据

Result: 在ASR、音频理解、密集音频描述等任务上，仅1.7B参数的Eureka-Audio匹配或超越了多个7B到30B的音频和全模态基线模型，在知识推理、安全性、指令跟随和副语言推理基准测试中表现出色。

Conclusion: Eureka-Audio在计算成本和性能之间实现了高效平衡，为轻量级音频理解模型建立了强大而实用的基准，证明了通过精心设计的架构和数据策略，小模型也能达到大模型的性能水平。

Abstract: We present Eureka-Audio, a compact yet high-performance audio language model that achieves competitive performance against models that are 4 to 18 times larger across a broad range of audio understanding benchmarks. Despite containing only 1.7B parameters, Eureka-Audio demonstrates strong performance on automatic speech recognition (ASR), audio understanding, and dense audio captioning, matching or surpassing multiple 7B to 30B audio and omni-modal baselines. The model adopts a unified end-to-end architecture composed of a lightweight language backbone, a Whisper-based audio encoder, and a sparsely activated Mixture-of-Experts (MoE) adapter that explicitly accounts for audio heterogeneity and alleviates cross-modal optimization conflicts under limited capacity. To further enhance paralinguistic reasoning, we introduce DataFlux, a closed loop audio instruction data synthesis and verification pipeline that constructs high quality, logically consistent supervision from raw audio. Extensive evaluations across ASR, knowledge reasoning, safety, instruction following, and paralinguistic benchmarks, demonstrate that Eureka-Audio achieves an efficient balance between computational cost and performance. These results establish Eureka Audio as a strong and practical baseline for lightweight audio understanding models.

</details>


### [44] [MUKA: Multi Kernel Audio Adaptation Of Audio-Language Models](https://arxiv.org/abs/2602.14127)
*Reda Bensaid,Amine Ouasfi,Yassir Bendou,Ilyass Moummad,Vincent Gripon,François Leduc-Primeau,Adnane Boukhayma*

Main category: cs.SD

TL;DR: MUKA：一种多核适应框架，通过结合指令调优模型的细粒度表示和对比预训练模型的全局语义表示，实现大型音频语言模型的高效少样本适应，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 多模态基础模型在少样本场景下高效适应新任务仍是一个关键挑战。现有方法要么需要训练（计算成本高），要么性能有限。需要一种既能保持理论保证又无需额外训练的高效适应方法。

Method: 提出MUKA多核适应框架，结合Pengi等指令调优模型的细粒度上下文相关表示和CLAP等对比预训练方法的全局语义表示。通过构建乘积核来对齐局部相似性和全局语义，增强表示能力。

Result: 在11个多样化音频数据集上的实验表明，MUKA在无需训练的方法中达到最先进性能，在多个场景中甚至超过基于训练的适配器方法，在适应性和效率之间取得了良好平衡。

Conclusion: MUKA为大型音频语言模型的少样本适应提供了一种高效解决方案，通过多核融合实现了细粒度与全局表示的互补优势，在保持理论保证的同时取得了优异的性能表现。

Abstract: Multimodal foundation models have demonstrated impressive generalization capabilities, yet efficiently adapting them to new tasks in a few-shot setting remains a critical challenge. In this work, we investigate the few-shot adaptation of Large Audio-Language Models (ALMs) through both training-based and training-free approaches. We introduce MUKA, a multi-kernel adaptation framework that combines the fine-grained, context-dependent representations of instruction-tuning based models like Pengi with the global semantic representations of contrastive pretraining methods like CLAP. By constructing a product kernel that aligns local similarity with global semantics, MUKA enhances representational power while preserving the theoretical guarantees of kernel methods and avoiding additional training. Extensive experiments across 11 diverse audio datasets demonstrate that MUKA achieves state-of-the-art performance among training-free methods and even surpasses training-based adapters in several scenarios, offering a compelling balance between adaptability and efficiency.

</details>


### [45] [Bengali-Loop: Community Benchmarks for Long-Form Bangla ASR and Speaker Diarization](https://arxiv.org/abs/2602.14291)
*H. M. Shadman Tabib,Istiak Ahmmed Rifti,Abdullah Muhammed Amimul Ehsan,Somik Dasgupta,Md Zim Mim Siddiqee Sowdha,Abrar Jahin Sarker,Md. Rafiul Islam Nijamy,Tanvir Hossain,Mst. Metaly Khatun,Munzer Mahmood,Rakesh Debnath,Gourab Biswas,Asif Karim,Wahid Al Azad Navid,Masnoon Muztahid,Fuad Ahmed Udoy,Shahad Shahriar Rahman,Md. Tashdiqur Rahman Shifat,Most. Sonia Khatun,Mushfiqur Rahman,Md. Miraj Hasan,Anik Saha,Mohammad Ninad Mahmud Nobo,Soumik Bhattacharjee,Tusher Bhomik,Ahmmad Nur Swapnil,Shahriar Kabir*

Main category: cs.SD

TL;DR: 本文介绍了Bengali-Loop，这是两个针对孟加拉语长语音处理的社区基准：一个长语音ASR语料库（158.6小时）和一个说话人日志语料库（22小时），旨在解决孟加拉语长语音技术资源不足的问题。


<details>
  <summary>Details</summary>
Motivation: 孟加拉语在长语音技术方面仍然资源不足，尽管其使用广泛。需要建立标准化的基准来支持孟加拉语长语音ASR和说话人日志的研究与发展。

Method: 通过可重复的字幕提取流程和人工循环转录验证，从11个YouTube频道收集191个录音（158.6小时）构建ASR语料库；同时构建包含24个录音（22小时）的说话人日志语料库，采用完全手动标注的说话人转换标签。

Result: 建立了两个基准：长语音ASR语料库（158.6小时，792k词）和说话人日志语料库（22小时，5,744个标注片段）。设置了基线性能（Tugstugi: 34.07% WER; pyannote.audio: 40.08% DER），并提供了标准化的评估协议。

Conclusion: Bengali-Loop基准填补了孟加拉语长语音技术的资源空白，提供了可重复的评估框架，支持未来孟加拉语长语音ASR和说话人日志模型的开发与研究。

Abstract: Bengali (Bangla) remains under-resourced in long-form speech technology despite its wide use. We present Bengali-Loop, two community benchmarks to address this gap: (1) a long-form ASR corpus of 191 recordings (158.6 hours, 792k words) from 11 YouTube channels, collected via a reproducible subtitle-extraction pipeline and human-in-the-loop transcript verification; and (2) a speaker diarization corpus of 24 recordings (22 hours, 5,744 annotated segments) with fully manual speaker-turn labels in CSV format. Both benchmarks target realistic multi-speaker, long-duration content (e.g., Bangla drama/natok). We establish baselines (Tugstugi: 34.07% WER; pyannote.audio: 40.08% DER) and provide standardized evaluation protocols (WER/CER, DER), annotation rules, and data formats to support reproducible benchmarking and future model development for Bangla long-form ASR and diarization.

</details>


### [46] [Investigation for Relative Voice Impression Estimation](https://arxiv.org/abs/2602.14172)
*Keinichi Fujita,Yusuke Ijima*

Main category: cs.SD

TL;DR: 本文研究相对语音印象估计(RIE)，通过对比同一说话者两个话语的感知差异，发现自监督语音表示优于传统声学特征，而当前多模态大语言模型在此细粒度任务上不可靠。


<details>
  <summary>Details</summary>
Motivation: 传统研究主要关注绝对印象评分，但相对语音印象估计(RIE)能更精确地量化同一说话者不同话语间的感知差异，这对于理解语音表达变化对听者印象的影响具有重要意义。

Method: 使用专业说话者以不同风格朗读同一文本的录音，比较三种建模方法：1) 传统声学特征；2) 自监督语音表示；3) 多模态大语言模型(MLLMs)。通过低维向量量化第二个话语相对于第一个话语在反义轴(如"暗-亮")上的感知偏移。

Result: 自监督语音表示模型优于传统声学特征方法，特别是在捕捉复杂动态印象(如"冷-暖")方面，而传统特征方法在这些任务上失败。当前MLLMs在此细粒度成对任务上不可靠。

Conclusion: 这是对相对语音印象估计(RIE)的首次系统研究，证明了自监督语音模型在捕捉细微感知变化方面的优势，为语音表达分析提供了新框架。

Abstract: Paralinguistic and non-linguistic aspects of speech strongly influence listener impressions. While most research focuses on absolute impression scoring, this study investigates relative voice impression estimation (RIE), a framework for predicting the perceptual difference between two utterances from the same speaker. The estimation target is a low-dimensional vector derived from subjective evaluations, quantifying the perceptual shift of the second utterance relative to the first along an antonymic axis (e.g., ``Dark--Bright''). To isolate expressive and prosodic variation, we used recordings of a professional speaker reading a text in various styles. We compare three modeling approaches: classical acoustic features commonly used for speech emotion recognition, self-supervised speech representations, and multimodal large language models (MLLMs). Our results demonstrate that models using self-supervised representations outperform methods with classical acoustic features, particularly in capturing complex and dynamic impressions (e.g., ``Cold--Warm'') where classical features fail. In contrast, current MLLMs prove unreliable for this fine-grained pairwise task. This study provides the first systematic investigation of RIE and demonstrates the strength of self-supervised speech models in capturing subtle perceptual variations.

</details>


### [47] [The Interspeech 2026 Audio Reasoning Challenge: Evaluating Reasoning Process Quality for Audio Reasoning Models and Agents](https://arxiv.org/abs/2602.14224)
*Ziyang Ma,Ruiyang Xu,Yinghao Ma,Chao-Han Huck Yang,Bohan Li,Jaeyeon Kim,Jin Xu,Jinyu Li,Carlos Busso,Kai Yu,Eng Siong Chng,Xie Chen*

Main category: cs.SD

TL;DR: Interspeech 2026音频推理挑战赛首次评估音频领域的思维链质量，引入MMAR-Rubrics评估框架，吸引了全球156支团队参与，结果显示智能体系统在推理质量上领先。


<details>
  <summary>Details</summary>
Motivation: 当前大型音频语言模型在理解能力上表现出色，但缺乏透明的推理过程，存在"黑箱"限制。为了解决这一问题，需要评估和改进音频领域的思维链质量。

Method: 组织Interspeech 2026音频推理挑战赛，引入MMAR-Rubrics实例级评估协议来评估推理链的事实性和逻辑性。设置单模型和智能体两个赛道，吸引全球团队参与。

Result: 挑战赛吸引了来自18个国家和地区的156支团队参与。结果显示智能体系统在推理质量上领先，通过迭代工具编排和跨模态分析实现；单模型通过强化学习和复杂数据管道也在快速进步。

Conclusion: 该挑战赛为可解释音频智能提供了新的见解，智能体系统目前表现最佳，但单模型也在快速追赶。MMAR-Rubrics评估框架为音频推理质量评估提供了重要工具。

Abstract: Recent Large Audio Language Models (LALMs) excel in understanding but often lack transparent reasoning. To address this "black-box" limitation, we organized the Audio Reasoning Challenge at Interspeech 2026, the first shared task dedicated to evaluating Chain-of-Thought (CoT) quality in the audio domain. The challenge introduced MMAR-Rubrics, a novel instance-level protocol assessing the factuality and logic of reasoning chains. Featured Single Model and Agent tracks, the competition attracting 156 teams from 18 countries and regions. Results show agent systems currently lead in reasoning quality, utilizing iterative tool orchestration and cross-modal analysis. Besides, single models are rapidly advancing via reinforcement learning and sophisticated data pipeline. We details the challenge design, methodology, and a comprehensive analysis of state-of-the-art systems, providing new insights for explainable audio intelligence.

</details>


### [48] [Probing Human Articulatory Constraints in End-to-End TTS with Reverse and Mismatched Speech-Text Directions](https://arxiv.org/abs/2602.14664)
*Parth Khadse,Sunil Kumar Kopparapu*

Main category: cs.SD

TL;DR: 研究探索人类解剖约束对端到端TTS系统训练的影响，通过对比正向/反向文本-语音组合，发现反向TTS系统能生成质量更好的语音


<details>
  <summary>Details</summary>
Motivation: 人类语音产生受解剖结构约束，某些发音配置难以模仿或转换。本研究旨在探究这些解剖约束是否会影响端到端TTS系统的训练效果

Method: 使用两种端到端TTS架构（Tacotron-2自回归模型和VITS-TTS非自回归模型），构建三种系统：(a)正向文本-正向语音（传统e2e-TTS），(b)反向文本-反向语音（r-e2e-TTS），(c)反向文本-正向语音（rtfs-e2e-TTS）

Result: 实验表明端到端TTS系统是纯数据驱动的。有趣的是，反向e2e-TTS系统生成的语音表现出更好的保真度、感知可懂度和自然度

Conclusion: 人类解剖约束确实影响TTS系统训练，反向训练策略能提升语音合成质量，为改进TTS系统提供了新思路

Abstract: An end-to-end (e2e) text-to-speech (TTS) system is a deep architecture that learns to associate a text string with acoustic speech patterns from a curated dataset. It is expected that all aspects associated with speech production, such as phone duration, speaker characteristics, and intonation among other things are captured in the trained TTS model to enable the synthesized speech to be natural and intelligible. Human speech is complex, involving smooth transitions between articulatory configurations (ACs). Due to anatomical constraints, some ACs are challenging to mimic or transition between. In this paper, we experimentally study if the constraints imposed by human anatomy have an implication on training an e2e-TTS systems. We experiment with two e2e-TTS architectures, namely, Tacotron-2 an autoregressive model and VITS-TTS a non-autoregressive model. In this study, we build TTS systems using (a) forward text, forward speech (conventional, e2e-TTS), (b) reverse text, reverse speech (r-e2e-TTS), and (c) reverse text, forward speech (rtfs-e2e-TTS). Experiments demonstrate that e2e-TTS systems are purely data-driven. Interestingly, the generated speech by r-e2e-TTS systems exhibits better fidelity, better perceptual intelligibility, and better naturalness

</details>

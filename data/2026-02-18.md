<div id=toc></div>

# Table of Contents

- [eess.SP](#eess.SP) [Total: 14]
- [eess.AS](#eess.AS) [Total: 3]
- [cs.SD](#cs.SD) [Total: 6]


<div id='eess.SP'></div>

# eess.SP [[Back]](#toc)

### [1] [Transforming Computational Lithography with AC and AI -- Faster, More Accurate, and Energy-efficient](https://arxiv.org/abs/2602.15036)
*Saumyadip Mukhopadhyay,Kiho Yang,Kasyap Thottasserymana Vasudevan,Mounica Jyothi Divvela,Selim Dogru,Dilip Krishnamurthy,Fergo Treska,Werner Gillijns,Ryan Ryoung han Kim,Kumara Sastry,Vivek Singh*

Main category: eess.SP

TL;DR: NVIDIA cuLitho利用加速计算和AI技术革新计算光刻，实现57倍端到端加速，并在硅实验中展示35%工艺窗口改善和19%边缘放置误差改善


<details>
  <summary>Details</summary>
Motivation: 科学计算需求激增远超晶体管缩放速度，导致成本、能耗和排放不可持续增长。计算光刻作为半导体制造最大工作负载，在埃米时代变得异常复杂，需要更准确建模、精细校正和更广泛解空间探索

Method: 重新设计软件栈，革新计算光刻核心原语（衍射光学、计算几何、多变量优化、数据处理），结合加速计算和AI技术，将AI作为计算密集型步骤的高保真替代模型

Result: 实现57倍端到端加速，在IMEC的硅实验中展示35%工艺窗口改善和19%边缘放置误差改善，首次在芯片尺度量化展示加速计算和AI对光刻的益处

Conclusion: 加速计算和AI共同构成可持续的下一代科学计算平台，cuLitho的成功证明该范式能显著提升计算光刻性能，支持更严格的解决方案如曲线掩模、高NA EUV光刻和亚原子建模

Abstract: From climate science to drug discovery, scientific computing demands have surged dramatically in recent years -- driven by larger datasets, more sophisticated models, and higher simulation fidelity. This growth rate far outpaces transistor scaling, leading to unsustainably rising costs, energy consumption, and emissions. Semiconductor manufacturing is no exception. Computational lithography -- involving transferring circuitry to silicon in diffraction-limited conditions -- is the largest workload in semiconductor manufacturing. It has also grown exceptionally complex as miniaturization has advanced in the angstrom-era, requiring more accurate modeling, intricate corrections, and broader solution-space exploration. Accelerated computing (AC) offers a solution by dramatically freeing up the compute and power envelope. AI augments these gains by serving as high-fidelity surrogates for compute-intensive steps. Together, they present a sustainable, next-generation computing platform for scientific workloads. This new paradigm needs a fundamental redesign of the software stack. For computational lithography, NVIDIA cuLitho reinvents the core primitives -- diffractive optics, computational geometry, multi-variant optimization, data processing -- to achieve a transformative 57X end-to-end acceleration. Beyond dramatically faster cycles, this expanded compute envelope enables more rigorous solutions, including curvilinear masks, high-numerical aperture extreme ultraviolet (high-NA EUV) lithography, and subatomic modeling. We reinvest a small fraction of the freed-up compute to include through-focus correction for better process resilience. Silicon experiments at IMEC show significant benefits compared to conventional methods -- 35% better process window and 19% better edge placement error. This is the first quantified chip-scale demonstration of the lithography benefits of AC and AI in silicon.

</details>


### [2] [Combining scEEG and PPG for reliable sleep staging using lightweight wearables](https://arxiv.org/abs/2602.15042)
*Jiawei Wang,Liang Xu,Shuntian Zheng,Yu Guan,Kaichen Wang,Ziqing Zhang,Chen Chen,Laurence T. Yang,Sai Gu*

Main category: eess.SP

TL;DR: 该研究探索了单通道脑电图与光电容积描记术融合在短时间窗口约束下进行4类睡眠分期，通过Mamba增强融合策略显著提升了浅睡眠分类性能。


<details>
  <summary>Details</summary>
Motivation: 轻量级可穿戴设备（如单通道脑电图或光电容积描记术）进行可靠睡眠分期仍具挑战。单通道脑电图虽能直接测量皮层活动，但在浅睡眠分期上表现有限；光电容积描记术能捕捉自主神经特征有效检测浅睡眠，但现有方法需要整夜记录作为输入，不利于及时睡眠干预反馈。

Method: 研究首先评估了每种模态所需的时间上下文，以了解睡眠分期性能与监测窗口的关系。然后研究了三种融合策略：分数级融合、支持特征级交互的交叉注意力融合，以及结合时间上下文建模的Mamba增强融合。在MESA数据集上训练评估，并在CFS和ABC数据集上进行跨数据集验证。

Result: Mamba增强融合在MESA数据集上获得最佳性能（Cohen's Kappa κ = 0.798，准确率86.9%），在浅睡眠分类上提升显著（F1分数：85.63% vs. 77.76%，召回率：82.85% vs. 69.95%），并在CFS和ABC数据集上表现出良好的泛化能力。

Conclusion: 单通道脑电图与光电容积描记术融合是轻量级可穿戴睡眠监测的有前景方法，为更易获得的睡眠健康评估提供了途径。

Abstract: Reliable sleep staging remains challenging for lightweight wearable devices such as single-channel electroencephalography (scEEG) or photoplethysmography (PPG). scEEG offers direct measurement of cortical activity and serves as the foundation for sleep staging, yet exhibits limited performance on light sleep stages. PPG provides a low-cost complement that captures autonomic signatures effective for detecting light sleep. However, prior PPG-based methods rely on full night recordings (8 - 10 hours) as input context, which is less practical to provide timely feedback for sleep intervention. In this work, we investigate scEEG-PPG fusion for 4-class sleep staging under short-window (30 s - 30 min) constraints. First, we evaluate the temporal context required for each modality, to better understand the relationship of sleep staging performance with respect to monitoring window. Second, we investigate three fusion strategies: score-level fusion, cross-attention fusion enabling feature-level interactions, and Mamba-enhanced fusion incorporating temporal context modeling. Third, we train and evaluate on the Multi-Ethnic Study of Atherosclerosis (MESA) dataset and perform cross-dataset validation on the Cleveland Family Study (CFS) and the Apnea, Bariatric surgery, and CPAP (ABC) datasets. The Mamba-enhanced fusion achieves the best performance on MESA (Cohen's Kappa $κ$ = 0.798, Acc = 86.9%), with particularly notable improvement in light sleep classification (F1-score: 85.63% vs. 77.76%, recall: 82.85% vs. 69.95% for scEEG alone), and generalizes well to CFS and ABC datasets with different populations. These findings suggest that scEEG-PPG fusion is a promising approach for lightweight wearable based sleep monitoring, offering a pathway toward more accessible sleep health assessment. Source code of this project can be found at: https://github.com/DavyWJW/scEEG-PPGFusion

</details>


### [3] [Large elements and advanced beamformers for increased field of view in 2-D ultrasound matrix arrays](https://arxiv.org/abs/2602.15174)
*Mick Gardner,Michael L. Oelze*

Main category: eess.SP

TL;DR: 通过增大阵元尺寸并使用先进波束形成器，在保持图像质量的同时扩大三维超声矩阵阵列的视场，NSI波束形成器表现最佳


<details>
  <summary>Details</summary>
Motivation: 三维超声在腹部、产科和心血管成像中有广泛应用前景，但传统矩阵阵列阵元数量极高，限制了视场范围。本研究旨在通过减少阵元数量的阵列设计来扩大视场。

Method: 采用增大阵元尺寸的策略，并使用先进波束形成器（DAS、NSI、DCF、MV）来保持图像质量。通过K-wave仿真比较三维点扩散函数，并在Verasonics 256系统上使用1024元矩阵阵列进行实验，通过电子耦合模拟更大阵元间距，利用定位系统创建虚拟大孔径。

Result: 仿真显示NSI、DCF和MV相比DAS具有更低的旁瓣和更窄的主瓣。实验中使用耦合因子为2时，在保持与原始矩阵阵列相同阵元数量的虚拟大孔径中，成功将视场扩大一倍并获得高质量图像。NSI波束形成器在仿真和大孔径实验中表现最佳，在耦合因子高达4时仍能保持与未耦合DAS相同的分辨率。

Conclusion: 研究表明可以通过使用更大阵元尺寸构建更大的矩阵阵列，并通过先进波束形成器来保持分辨率，这为扩大三维超声视场提供了可行方案。

Abstract: Three-dimensional (3D) ultrasound promises various medical applications for abdominal, obstetrics, and cardiovascular imaging. However, ultrasound matrix arrays have extremely high element counts limiting their field of view (FOV). This work seeks to demonstrate an increased field-of-view using a reduced element count array design. The approach is to increase the element size and use advanced beamformers to maintain image quality. The delay and sum (DAS), Null Subtraction Imaging (NSI), directional coherence factor (DCF), and Minimum Variance (MV) beamformers were compared. K-wave simulations of the 3D point-spread functions (PSF) of NSI, DCF, and MV display reduced side lobes and narrowed main lobes compared to DAS. Experiments were conducted using a multiplexed 1024-element matrix array on a Verasonics 256 system. Elements were electronically coupled to imitate a larger pitch and element size. Then, a virtual large aperture was created by using a positioning system to collect data in sections with the matrix array. High-quality images were obtained using a coupling factor of two, doubling the FOV while maintaining the same element count in the virtual large aperture as the original matrix array. The NSI beamformer demonstrated the best resolution performance in simulations and on the large aperture, maintaining the same resolution as uncoupled DAS for coupling factors up to 4. Our results demonstrate how larger matrix arrays could be constructed with larger elements, with resolution maintained by advanced beamformers.

</details>


### [4] [Secure High-Resolution ISAC via Multi-Layer Intelligent Metasurfaces: A Layered Optimization Framework](https://arxiv.org/abs/2602.15209)
*Amirhossein Taherpour,Abbas Taherpour,Tamer Khattab*

Main category: eess.SP

TL;DR: 该论文提出了一种基于堆叠智能超表面(SIM)的集成感知与通信(ISAC)系统，通过分层优化框架同时提升感知精度和通信安全性，相比传统方法在感知精度上提升32-61%，在保密速率上提升15-35%。


<details>
  <summary>Details</summary>
Motivation: 现有ISAC系统在实现高分辨率感知的同时保持通信安全性和频谱效率方面存在根本性限制，需要新的技术方案来克服这些挑战。

Method: 提出基于堆叠智能超表面(SIM)的多功能系统，采用分层优化框架联合优化通信保密性和感知精度，使用多目标优化公式在硬件约束下平衡保密率最大化和感知误差最小化，并设计了分层块坐标下降算法。

Result: 仿真结果显示，相比传统方法，在感知精度上提升32-61%，在保密速率上提升15-35%，同时保持计算效率。

Conclusion: 该工作为安全和高效的多功能无线系统建立了新范式，通过SIM技术实现了感知精度和通信安全性的显著提升。

Abstract: Integrated sensing and communication (ISAC) has emerged as a pivotal technology for next-generation wireless networks, enabling simultaneous data transmission and environmental sensing. However, existing ISAC systems face fundamental limitations in achieving high-resolution sensing while maintaining robust communication security and spectral efficiency. This paper introduces a transformative approach leveraging stacked intelligent metasurfaces (SIM) to overcome these challenges. We propose a multi-functional SIM-assisted system that jointly optimizes communication secrecy and sensing accuracy through a novel layered optimization framework. Our solution employs a multi-objective optimization formulation that balances secrecy rate maximization with sensing error minimization under practical hardware constraints. The proposed layered block coordinate descent algorithm efficiently coordinates sensing configuration, secure beamforming, communication metasurface optimization, and resource allocation while ensuring robustness to channel uncertainties. Extensive simulations demonstrate significant performance gains over conventional approaches, achieving 32-61\% improvement in sensing accuracy and 15-35\% enhancement in secrecy rates while maintaining computational efficiency. This work establishes a new paradigm for secure and high-precision multi-functional wireless systems.

</details>


### [5] [Multiplierless DFT Approximation Based on the Prime Factor Algorithm](https://arxiv.org/abs/2602.15218)
*L. Portella,F. M. Bayer,R. J. Cintra*

Main category: eess.SP

TL;DR: 提出基于小素数长度DFT近似的完全无乘法器DFT近似方法，消除中间乘法步骤和误差传播，设计1023点DFT近似并优于现有方法


<details>
  <summary>Details</summary>
Motivation: 现有DFT近似方法要么在小块长度（如8、16、32）工作，要么在大块长度（如1024）通过Cooley-Tukey方法依赖小块长度近似变换。Cooley-Tukey方法继承的中间旋转因子乘法通常不被近似，否则误差传播会影响整体性能。需要开发完全无乘法器的DFT近似方法。

Method: 提出基于素数因子算法的框架，利用小素数长度DFT近似推导完全无乘法器的DFT近似。该方法基于3点、11点和31点DFT近似，设计完全无乘法器的1023点DFT近似，完全消除中间乘法步骤，防止内部误差传播。

Result: 提出的1023点DFT近似不仅具有显著更低的算术复杂度，而且与竞争方法相比，产生了更小的近似误差测量值。性能评估显示该方法在流行指标上表现优越。

Conclusion: 素数因子算法为推导完全无乘法器DFT近似提供了必要框架，基于小素数长度DFT近似的近似方法能够有效消除中间乘法步骤并防止误差传播，在复杂度和精度方面均优于现有方法。

Abstract: Matrix approximation methods have successfully produced efficient, low-complexity approximate transforms for the discrete cosine transforms and the discrete Fourier transforms. For the DFT case, literature archives approximations operating at small power-of-two blocklenghts, such as \{8, 16, 32\}, or at large blocklengths, such as 1024, which are obtained by means of the Cooley-Tukey-based approximation relying on the small-blocklength approximate transforms. Cooley-Tukey-based approximations inherit the intermediate multiplications by twiddled factors which are usually not approximated; otherwise the effected error propagation would prevent the overall good performance of the approximation. In this context, the prime factor algorithm can furnish the necessary framework for deriving fully multiplierless DFT approximations. We introduced an approximation method based on small prime-sized DFT approximations which entirely eliminates intermediate multiplication steps and prevents internal error propagation. To demonstrate the proposed method, we design a fully multiplierless 1023-point DFT approximation based on 3-, 11- and 31-point DFT approximations. The performance evaluation according to popular metrics showed that the proposed approximations not only presented a significantly lower arithmetic complexity but also resulted in smaller approximation error measurements when compared to competing methods.

</details>


### [6] [SCENE OTA-FD: Self-Centering Noncoherent Estimator for Over-the-Air Federated Distillation](https://arxiv.org/abs/2602.15326)
*Hao Chen,Zavareh Bozorgasl*

Main category: eess.SP

TL;DR: SCENE是一种用于空中联邦蒸馏的无导频、相位不变的聚合原语，通过能量估计实现无偏软标签平均，适用于短相干时间和硬件受限场景。


<details>
  <summary>Details</summary>
Motivation: 针对空中联邦蒸馏中需要避免每轮信道状态信息获取的场景，特别是在短相干时间和硬件受限环境下，传统相干设计需要大量导频开销，SCENE旨在提供无导频的解决方案。

Method: 设备将软标签向量映射到非负发射能量，采用恒定每轮功率和恒包络信号；服务器使用自中心能量估计器去除噪声能量偏移，得到加权软标签平均的无偏估计；还开发了无导频比率归一化变体以消除未知大尺度增益。

Result: SCENE的估计方差随接收天线数M和重复因子S按1/(SM)衰减；提供了与相干OTA-FD分析一致的收敛边界；在导频开销不可忽略时，SCENE可以超越相干设计。

Conclusion: SCENE通过适度的非相干方差常数换取零上行导频、无偏聚合和硬件友好传输，特别适用于需要避免每轮CSI的短相干时间和硬件受限场景。

Abstract: We propose SCENE (Self-Centering Noncoherent Estimator), a pilot-free and phase-invariant aggregation primitive for over-the-air federated distillation (OTA-FD). Each device maps its soft-label (class-probability) vector to nonnegative transmit energies under constant per-round power and constant-envelope signaling (PAPR near 1). At the server, a self-centering energy estimator removes the noise-energy offset and yields an unbiased estimate of the weighted soft-label average, with variance decaying on the order of 1/(SM) in the number of receive antennas M and repetition factor S. We also develop a pilot-free ratio-normalized variant that cancels unknown large-scale gains, provide a convergence bound consistent with coherent OTA-FD analyses, and present an overhead-based crossover comparison. SCENE targets short-coherence and hardware-constrained regimes, where avoiding per-round CSI is essential: it trades a modest noncoherent variance constant for zero uplink pilots, unbiased aggregation, and hardware-friendly transmission, and can outperform coherent designs when pilot overhead is non-negligible.

</details>


### [7] [Adaptive Selection of Codebook Using Assistance Information and Artificial Intelligence for 6G Systems](https://arxiv.org/abs/2602.15530)
*Denis Esiunin,Alexei Davydov*

Main category: eess.SP

TL;DR: 提出一种基于用户设备辅助的码本选择方法，通过神经网络预测不同码本的量化精度，在保证系统吞吐量的同时降低CSI报告开销。


<details>
  <summary>Details</summary>
Motivation: 下行预编码器量化精度受传播条件影响，需要为每个用户设备独立调整参数。传统方法难以实现最优码本选择，导致CSI报告开销大且性能不佳。

Method: 用户设备向基站报告时域、频域和空域的统计信道特性作为辅助信息。基站使用神经网络预测各种码本类型对每个用户的量化精度，综合考虑CSI报告开销和预编码性能选择最优码本。

Result: 系统级仿真表明，该方法在保持目标系统吞吐量性能的同时，显著降低了总的CSI开销。

Conclusion: 提出的用户设备辅助码本选择方案能够有效优化CSI报告系统，通过智能码本选择实现开销与性能的最佳平衡。

Abstract: This paper addresses the problem of adaptive codebook (CB) selection for downlink (DL) precoder quantization in channel state information (CSI) reporting. The accuracy of precoder quantization depends on propagation conditions, requiring independent parameter adaptation for each user equipment (UE). To enable optimal CB selection, this paper proposes UE-assisted CB selection at the base station (BS) using reported by the UE statistical channel properties across time, frequency, and spatial domains. The reported assistance information serves as input to a neural network (NN), which predicts the quantization accuracy of various CB types for each served user. The predicted accuracy is then used to select the optimal CB while considering the associated CSI reporting overhead and precoding performance. System-level simulations demonstrate that the proposed approach reduces total CSI overhead while maintaining the target system throughput performance.

</details>


### [8] [Waveform Design for ISAC System: A Consensus ADMM Approach](https://arxiv.org/abs/2602.15544)
*Ngoc-Son Duong,Huyen-Trang Ta,Quang-Tang Ngo,Thi-Hue Duong,Van-Lap Nguyen,Cong-Minh Nguyen,Minh-Tran Nguyen,Thai-Mai Dinh*

Main category: eess.SP

TL;DR: 提出一种用于多用户下行链路ISAC系统的联合发射波形和接收滤波器设计方法，在恒模和相似性约束下平衡通信和感知性能


<details>
  <summary>Details</summary>
Motivation: 在集成感知与通信系统中，需要在通信和感知性能之间取得平衡。现有方法在恒模和相似性约束下难以有效优化通信和感知的权衡，需要开发高效的联合设计算法

Method: 采用共识交替方向乘子法框架，将设计问题转化为统一的多目标优化问题，交替更新发射波形和雷达滤波器，有效处理非凸的感知SINR分数形式

Result: 仿真结果表明，所提方法相比现有基准方案，在通信和速率与感知SINR之间实现了更好的权衡

Conclusion: 提出的基于共识ADMM的联合设计算法能够有效处理ISAC系统中的非凸优化问题，在满足实际约束条件下实现通信和感知性能的良好平衡

Abstract: We study joint transmit-waveform and receive-filter design for a multi-user downlink integrated sensing and communication (ISAC) system under practical constant-modulus and similarity constraints. We cast the design as a unified multi-objective program that balances communication sum rate and sensing signal-to-interference-plus-noise ratio (SINR). To address this, we introduce an efficient algorithm that use consensus alternating direction method of multipliers (ADMM) framework to alternately update the transmit waveform and radar filter. The proposed method effectively handles the non-convex fractional sensing's SINR formulation and ensures fast convergence. Simulation results demonstrate that the proposed approach achieves better trade-offs between communication sum rate and sensing's SINR compared to existing benchmark schemes.

</details>


### [9] [Tracking Time-Varying Multipath Channels forActive Sonar Applications](https://arxiv.org/abs/2602.15555)
*Ashwani Koul,Gustaf Hendeby,Isaac Skog*

Main category: eess.SP

TL;DR: 提出在原始测量域直接学习和跟踪多径背景的框架，使用扩展卡尔曼滤波进行信道跟踪，通过边缘似然学习未知参数，并集成到目标检测的序贯似然比检验中


<details>
  <summary>Details</summary>
Motivation: 传统方法在距离-多普勒域进行背景学习计算成本高，且可能掩盖相位相干结构。需要直接在原始测量域学习和跟踪多径背景，以更准确捕捉信道动态

Method: 从宽带多普勒线性化的时变多径信道冲激响应出发，推导具有异方差测量方程的状态空间模型，使用扩展卡尔曼滤波进行信道跟踪，通过边缘似然学习未知参数，并集成到序贯似然比检验的目标检测中

Result: BELLHOP仿真显示，所提模型能更好地捕捉海面波动和收发器漂移引起的信道动态，在时变浅水环境中实现更可靠的检测

Conclusion: 直接在原始测量域学习和跟踪多径背景的方法比传统距离-多普勒域方法更有效，能更好地捕捉信道动态，提高主动声纳在时变浅水环境中的检测可靠性

Abstract: Reliable detection and tracking in active sonar require accurate and efficient learning of the acoustic multipath background environment. Conventionally, background learning is performed after transforming measurements into the range-Doppler domain, a step that is computationally expensive and can obscure phase-coherent structure useful for monitoring and tracking. This paper proposes a framework for learning and tracking the multipath background directly in the raw measurement domain. Starting from a wideband Doppler linearization of the impulse response of a time-varying multipath channel, a state-space model with a heteroscedastic measurement equation is derived. This model enables channel tracking using an extended Kalman filter (EKF), and unknown model parameters are learned from the marginalized likelihood. The statistical adequacy of the proposed models is assessed via a p-value significance test. Finally, this paper integrates the learned channel model into a sequential likelihood-ratio test for target detection. BELLHOP-based simulations show that the proposed model better captures channel dynamics induced by sea-surface fluctuations and transmitter and receiver drift, yielding more reliable detection in time-varying shallow-water environments

</details>


### [10] [Physics-Informed Anomaly Detection of Terrain Material Change in Radar Imagery](https://arxiv.org/abs/2602.15618)
*Abdel Hakiem Mohamed Abbas Mohamed Ahmed,Beth Jelfs,Airlie Chapman,Eric Schoof,Christopher Gilliam*

Main category: eess.SP

TL;DR: 该论文提出了一种基于物理信息的雷达图像地形材料变化检测方法，通过轻量级电磁前向模型生成双时相SLC图像，并评估多种无监督检测器在材料变化检测中的性能。


<details>
  <summary>Details</summary>
Motivation: 雷达图像中地形材料变化（如介电常数、粗糙度或湿度变化）的检测对许多应用至关重要。传统方法往往缺乏物理基础，需要开发结合电磁物理原理的检测方法以提高准确性。

Method: 1. 提出轻量级电磁前向模型，从标注的材料图中模拟双时相单视复图像；2. 推导物理感知特征堆栈，包括干涉相干性；3. 评估多种无监督检测器：Reed-Xiaoli/Local-RX（使用Tyler's M估计器）、相干变化检测和紧凑卷积自编码器；4. 通过蒙特卡洛实验扫描介电常数/粗糙度/湿度变化、视数和杂波环境。

Result: 在合成但物理基础真实的场景中，相干性和鲁棒协方差显著改善了材料变化的异常检测性能；在重尾杂波环境下，简单的分数级融合方法取得了最佳的F1分数。

Conclusion: 结合电磁物理原理的检测方法能够有效识别雷达图像中的地形材料变化，相干性和鲁棒协方差估计是关键改进因素，分数级融合策略在复杂杂波环境下表现最优。

Abstract: In this paper we consider physics-informed detection of terrain material change in radar imagery (e.g., shifts in permittivity, roughness or moisture). We propose a lightweight electromagnetic (EM) forward model to simulate bi-temporal single-look complex (SLC) images from labelled material maps. On these data, we derive physics-aware feature stacks that include interferometric coherence, and evaluate unsupervised detectors: Reed-Xiaoli (RX)/Local-RX with robust scatter (Tyler's M-estimator), Coherent Change Detection (CCD), and a compact convolutional auto-encoder. Monte Carlo experiments sweep dielectric/roughness/moisture changes, number of looks and clutter regimes (gamma vs K-family) at fixed probability of false alarm. Results on synthetic but physically grounded scenes show that coherence and robust covariance markedly improve anomaly detection of material changes; a simple score-level fusion achieves the best F1 in heavy-tailed clutter.

</details>


### [11] [Passive Imaging with Ambient Noise Under Wave Speed Mismatch: Mathematical Analysis and Wave Speed Estimation](https://arxiv.org/abs/2602.15623)
*Zetao Fei,Josselin Garnier*

Main category: eess.SP

TL;DR: 该论文研究被动相关成像中的波速估计问题，通过分析均匀和随机介质中波速不匹配引起的偏移和散焦效应，提出基于虚拟导星的有效波速估计方法。


<details>
  <summary>Details</summary>
Motivation: 在被动成像中，当背景波速未知时，从部分边界测量中重建介质反射率仍然是一个具有挑战性的问题。特别是在日光配置下，只有不受控制的噪声源照射介质，传感器阵列仅记录环境场。

Method: 首先分析均匀背景中嵌入点反射器的日光偏移成像，通过引入搜索波速到偏移泛函中，推导波速不匹配引起的确定性偏移和散焦效应的显式表征。然后将分析扩展到相关长度小于波长的随机介质，利用均匀情况下的偏移公式引入虚拟导星，该导星在不同搜索波速的偏移下保持固定。

Result: 证明了所得泛函包络的最大值提供了真实波速的可靠估计器。对于随机介质，基于虚拟导星周围的空间平均提出了有效的波速估计策略。为两种介质建立了所提波速估计器的分辨率分析。

Conclusion: 提出的方法能够有效估计未知背景波速，为被动相关成像中的波速估计问题提供了理论框架和实用策略，数值实验验证了理论结果。

Abstract: It is known that waves generated by ambient noise sources and recorded by passive receivers can be used to image the reflectivities of an unknown medium. However, reconstructing the reflectivity of the medium from partial boundary measurements remains a challenging problem, particularly when the background wave speed is unknown. In this paper, we investigate passive correlation-based imaging in the daylight configuration, where uncontrolled noise sources illuminate the medium and only ambient fields are recorded by a sensor array. We first analyze daylight migration for a point reflector embedded in a homogeneous background. By introducing a searching wave speed into the migration functional, we derive an explicit characterization of the deterministic shift and defocusing effects induced by wave-speed mismatch. We show that the maximum of the envelope of the resulting functional provides a reliable estimator of the true wave speed. We then extend the analysis to a random medium with correlation length smaller than the wavelength. Leveraging the shift formula obtained in the homogeneous case, we introduce a virtual guide star that remains fixed under migration with different searching speeds. This property enables an effective wave-speed estimation strategy based on spatial averaging around the virtual guide star. For both homogeneous and random media, we establish resolution analyses for the proposed wave-speed estimators. Numerical experiments are conducted to validate the theoretical result.

</details>


### [12] [Latency-aware Human-in-the-Loop Reinforcement Learning for Semantic Communications](https://arxiv.org/abs/2602.15640)
*Peizheng Li,Xinyi Lin,Adnan Aijaz*

Main category: eess.SP

TL;DR: 提出TC-HITL-RL框架，通过人机协同强化学习在语义通信中平衡语义保真度与延迟约束，在语义感知Open RAN架构中实现任务对齐传输。


<details>
  <summary>Details</summary>
Motivation: 语义通信需要在沉浸式和关键安全服务中同时保证语义保真度和严格的延迟要求，现有方法难以在两者间取得平衡。

Method: 提出时间约束的人机协同强化学习框架，将人类反馈、语义效用和延迟控制整合到语义感知Open RAN架构中，使用约束MDP建模并通过原始-对偶近端策略优化算法求解，结合动作屏蔽和延迟感知奖励塑造。

Result: 在具有异构截止时间的点对多点链路仿真中，TC-HITL-RL始终满足每个用户的时序约束，在奖励方面优于基线调度器，并稳定资源消耗。

Conclusion: 该框架为延迟感知的语义自适应提供了实用蓝图，能够在保持语义奖励的同时严格控制接口处理和RAN智能控制器处理的延迟变异性。

Abstract: Semantic communication promises task-aligned transmission but must reconcile semantic fidelity with stringent latency guarantees in immersive and safety-critical services. This paper introduces a time-constrained human-in-the-loop reinforcement learning (TC-HITL-RL) framework that embeds human feedback, semantic utility, and latency control within a semantic-aware Open radio access network (RAN) architecture. We formulate semantic adaptation driven by human feedback as a constrained Markov decision process (CMDP) whose state captures semantic quality, human preferences, queue slack, and channel dynamics, and solve it via a primal--dual proximal policy optimization algorithm with action shielding and latency-aware reward shaping. The resulting policy preserves PPO-level semantic rewards while tightening the variability of both air-interface and near-real-time RAN intelligent controller processing budgets. Simulations over point-to-multipoint links with heterogeneous deadlines show that TC-HITL-RL consistently meets per-user timing constraints, outperforms baseline schedulers in reward, and stabilizes resource consumption, providing a practical blueprint for latency-aware semantic adaptation.

</details>


### [13] [NYUSIM: A Roadmap to AI-Enabled Statistical Channel Modeling and Simulation](https://arxiv.org/abs/2602.15737)
*Isha Jariwala,Xinquan Wang,Bridget Meier,Guanyue Qian,Dipankar Shakya,Mingjun Ying,Homa Nikbakht,Daniel Abraham,Theodore S. Rappaport*

Main category: eess.SP

TL;DR: NYUSIM从MATLAB迁移到Python，支持6G研究，整合了新的统计模型生成能力和3D天线数据格式，为AI驱动的无线信道建模提供可扩展基础。


<details>
  <summary>Details</summary>
Motivation: 将人工智能集成到无线信道建模需要大量准确且物理一致的真实测量数据集。现有MATLAB版本的NYUSIM在可扩展性和与现代AI工作流程集成方面存在限制，需要迁移到Python以支持6G研究和大规模并行数据生成。

Method: 将完整的NYUSIM框架从MATLAB迁移到Python，整合了6.75GHz和16.95GHz频段的新统计模型生成能力，引入了标准化的3D天线数据格式(Ant3D)，并通过Kolmogorov-Smirnov检验、矩分析和端到端测试进行严格验证。

Result: 迁移后的NYUSIM Python版本保持了与MATLAB v4.0的统计一致性，能够复现时空信道统计特性，包括空间一致性。该版本支持大规模并行数据生成，并与现代AI工作流程集成。

Conclusion: NYUSIM Python版本为未来AI驱动的信道建模建立了稳健、可验证且可扩展的基础，支持6G研究和无线信道建模的进一步发展。

Abstract: Integrating artificial intelligence (AI) into wireless channel modeling requires large, accurate, and physically consistent datasets derived from real measurements. Such datasets are essential for training and validating models that learn spatio-temporal channel behavior across frequencies and environments. NYUSIM, introduced by NYU WIRELESS in 2016, generates realistic spatio-temporal channel data using extensive outdoor and indoor measurements between 28 and 142 GHz. To improve scalability and support 6G research, we migrated the complete NYUSIM framework from MATLAB to Python, and are incorporating new statistical model generation capabilities from extensive field measurements in the new 6G upper mid-band spectrum at 6.75 GHz (FR1(C)) and 16.95 GHz (FR3) [1]. The NYUSIM Python also incorporates a 3D antenna data format, referred to as Ant3D, which is a standardized, full-sphere format for defining canonical, commercial, or measured antenna patterns for any statistical or site-specific ray tracing modeling tool. Migration from MATLAB to Python was rigorously validated through Kolmogorov-Smirnov (K-S) tests, moment analysis, and end-to-end testing with unified randomness control, confirming statistical consistency and reproduction of spatio-temporal channel statistics, including spatial consistency with the open-source MATLAB NYUSIM v4.0 implementation. The NYUSIM Python version is designed to integrate with modern AI workflows and enable large-scale parallel data generation, establishing a robust, verified, and extensible foundation for future AI-enabled channel modeling.

</details>


### [14] [Measurement-Based Validation of Geometry-Driven RIS Beam Steering in Industrial Environments](https://arxiv.org/abs/2602.15808)
*Adam Umra,Simon Tewes,Niklas Beckmann,Niels König,Aydin Sezgin,Robert Schmitt*

Main category: eess.SP

TL;DR: 在工业环境中评估几何驱动RIS波束赋形的可行性，通过5GHz RIS原型在大型工业厂房进行测量验证，展示了空间选择性聚焦能力


<details>
  <summary>Details</summary>
Motivation: 可重构智能表面(RIS)为未来无线系统提供可编程的无线电传播控制。几何驱动分析方法因其简单性和实时操作而具有吸引力，但在具有密集多径和金属散射的工业厂房等挑战性环境中的性能尚未得到充分验证。

Method: 提出了一种新颖的RIS配置，在RIS前方近距离安装四个贴片天线来引导入射场并实现可控反射。使用5GHz RIS原型在大型工业厂房进行测量，实现分析计算和量化配置，生成二维接收功率图。

Result: 测量结果显示了一致的空间选择性聚焦。在接收器附近优化的配置产生清晰的功率最大值，而向偏移位置转向则触发20-30dB的快速功率下降。随着RIS-接收器距离增加，由于有限孔径和几何约束，仰角选择性变宽，而方位角转向保持稳健。

Conclusion: 这些结果证实了几何驱动RIS波束赋形在工业环境中的实际可行性，并支持其在非理想传播条件下用于空间场控制和定位。

Abstract: Reconfigurable intelligent surfaces (RISs) offer programmable control of radio propagation for future wireless systems. For configuration, geometry-driven analytical approaches are appealing for their simplicity and real-time operation, but their performance in challenging environments such as industrial halls with dense multipath and metallic scattering is not well established. To this end, we present a measurement-based evaluation of geometry-driven RIS beam steering in a large industrial hall using a 5 GHz RIS prototype. A novel RIS configuration is proposed in which four patch antennas are mounted in close proximity in front of the RIS to steer the incident field and enable controlled reflection. For this setup, analytically computed, quantized configurations are implemented. Two-dimensional received power maps from two measurement areas reveal consistent, spatially selective focusing. Configurations optimized near the receiver produce clear power maxima, while steering to offset locations triggers a rapid 20-30 dB reduction. With increasing RIS-receiver distance, elevation selectivity broadens due to finite-aperture and geometric constraints, while azimuth steering remains robust. These results confirm the practical viability of geometry-driven RIS beam steering in industrial environments and support its use for spatial field control and localization under non-ideal propagation.

</details>


<div id='eess.AS'></div>

# eess.AS [[Back]](#toc)

### [15] [What Do Neurons Listen To? A Neuron-level Dissection of a General-purpose Audio Model](https://arxiv.org/abs/2602.15307)
*Takao Kawamura,Daisuke Niizumi,Nobutaka Ono*

Main category: eess.AS

TL;DR: 首次对通用音频自监督学习模型进行神经元级分析，发现模型涌现出类别特异性神经元，这些神经元在不同语义类别和声学特征间共享响应，对分类性能有功能影响。


<details>
  <summary>Details</summary>
Motivation: 尽管音频自监督学习模型作为特征提取器表现出强大的实证性能，但其实现稳健泛化的内部机制仍不清楚。研究者希望从神经元层面理解这些模型的内部表示。

Method: 采用机制可解释性框架，通过分析不同任务中的条件激活模式来识别和检查类别特异性神经元。

Result: 自监督学习模型促进了类别特异性神经元的涌现，这些神经元能广泛覆盖新任务类别，在语音属性和音乐音高等不同语义类别和声学相似性间表现出共享响应，且对分类性能有功能影响。

Conclusion: 这是首次对通用音频自监督学习模型进行系统性的神经元级分析，为理解其内部表示提供了新见解。

Abstract: In this paper, we analyze the internal representations of a general-purpose audio self-supervised learning (SSL) model from a neuron-level perspective. Despite their strong empirical performance as feature extractors, the internal mechanisms underlying the robust generalization of SSL audio models remain unclear. Drawing on the framework of mechanistic interpretability, we identify and examine class-specific neurons by analyzing conditional activation patterns across diverse tasks. Our analysis reveals that SSL models foster the emergence of class-specific neurons that provide extensive coverage across novel task classes. These neurons exhibit shared responses across different semantic categories and acoustic similarities, such as speech attributes and musical pitch. We also confirm that these neurons have a functional impact on classification performance. To our knowledge, this is the first systematic neuron-level analysis of a general-purpose audio SSL model, providing new insights into its internal representation.

</details>


### [16] [Bottleneck Transformer-Based Approach for Improved Automatic STOI Score Prediction](https://arxiv.org/abs/2602.15484)
*Amartyaveer,Murali Kadambi,Chandra Mohan Sharma,Anupam Mondal,Prasanta Kumar Ghosh*

Main category: eess.AS

TL;DR: 提出使用瓶颈变换器架构预测STOI指标，相比传统需要干净参考语音的方法，该非侵入式模型在真实场景中更具应用性，性能优于现有基于自监督学习和频谱特征的方法。


<details>
  <summary>Details</summary>
Motivation: 传统STOI计算需要干净参考语音，限制了实际应用。虽然已有深度学习非侵入式语音评估模型取得不错效果，但仍有改进空间。

Method: 使用瓶颈变换器架构，包含卷积块学习帧级特征和多头自注意力层聚合信息，使变换器能关注输入数据的关键方面。

Result: 模型在已见和未见场景下均表现出更高的相关性和更低的均方误差，优于使用自监督学习和频谱特征输入的最先进模型。

Conclusion: 提出的瓶颈变换器架构能有效预测STOI指标，在非侵入式语音质量评估方面具有优越性能。

Abstract: In this study, we have presented a novel approach to predict the Short-Time Objective Intelligibility (STOI) metric using a bottleneck transformer architecture. Traditional methods for calculating STOI typically requires clean reference speech, which limits their applicability in the real world. To address this, numerous deep learning-based nonintrusive speech assessment models have garnered significant interest. Many studies have achieved commendable performance, but there is room for further improvement.
  We propose the use of bottleneck transformer, incorporating convolution blocks for learning frame-level features and a multi-head self-attention (MHSA) layer to aggregate the information. These components enable the transformer to focus on the key aspects of the input data. Our model has shown higher correlation and lower mean squared error for both seen and unseen scenarios compared to the state-of-the-art model using self-supervised learning (SSL) and spectral features as inputs.

</details>


### [17] [Enroll-on-Wakeup: A First Comparative Study of Target Speech Extraction for Seamless Interaction in Real Noisy Human-Machine Dialogue Scenarios](https://arxiv.org/abs/2602.15519)
*Yiming Yang,Guangyong Wang,Haixin Guan,Yanhua Long*

Main category: eess.AS

TL;DR: 提出Enroll-on-Wakeup框架，利用唤醒词片段作为注册参考，无需预录音频，实现无缝语音提取体验。


<details>
  <summary>Details</summary>
Motivation: 传统目标语音提取依赖预录的高质量注册语音，这破坏用户体验且在自发交互中不可行，需要更自然的解决方案。

Method: 提出EoW框架，自动利用人机交互中自然捕获的唤醒词片段作为注册参考；研究使用LLM-based TTS进行注册增强以应对唤醒词片段短且嘈杂的问题。

Result: 当前TSE模型在EoW-TSE中面临性能下降，但TTS辅助显著改善了听觉体验；在语音识别准确性方面仍存在差距。

Conclusion: EoW框架消除了预录音频需求，TTS增强改善了体验，但需要进一步研究以提升语音识别准确性。

Abstract: Target speech extraction (TSE) typically relies on pre-recorded high-quality enrollment speech, which disrupts user experience and limits feasibility in spontaneous interaction. In this paper, we propose Enroll-on-Wakeup (EoW), a novel framework where the wake-word segment, captured naturally during human-machine interaction, is automatically utilized as the enrollment reference. This eliminates the need for pre-collected speech to enable a seamless experience. We perform the first systematic study of EoW-TSE, evaluating advanced discriminative and generative models under real diverse acoustic conditions. Given the short and noisy nature of wake-word segments, we investigate enrollment augmentation using LLM-based TTS. Results show that while current TSE models face performance degradation in EoW-TSE, TTS-based assistance significantly enhances the listening experience, though gaps remain in speech recognition accuracy.

</details>


<div id='cs.SD'></div>

# cs.SD [[Back]](#toc)

### [18] [UniTAF: A Modular Framework for Joint Text-to-Speech and Audio-to-Face Modeling](https://arxiv.org/abs/2602.15651)
*Qiangong Zhou,Nagasaka Tomohiro*

Main category: cs.SD

TL;DR: 将独立的TTS和A2F模型合并为统一模型，通过内部特征迁移提升文本到音频和面部表情生成的一致性，验证了TTS中间表示在语音表情联合建模中的可行性。


<details>
  <summary>Details</summary>
Motivation: 从系统设计角度出发，探索通过重用TTS中间表示来实现语音和面部表情的联合建模，为后续语音表情协同设计提供工程实践参考。

Method: 将独立的文本到语音(TTS)和音频到面部(A2F)模型合并为统一模型，实现内部特征迁移，并将TTS的情感控制机制扩展到联合模型中。

Result: 验证了重用TTS中间表示进行语音和面部表情联合建模的可行性，为相关系统设计提供了工程实践参考。

Conclusion: 该工作从系统设计角度证明了TTS中间表示在语音表情联合建模中的可重用性，为后续的协同设计提供了有价值的工程参考。

Abstract: This work considers merging two independent models, TTS and A2F, into a unified model to enable internal feature transfer, thereby improving the consistency between audio and facial expressions generated from text. We also discuss the extension of the emotion control mechanism from TTS to the joint model. This work does not aim to showcase generation quality; instead, from a system design perspective, it validates the feasibility of reusing intermediate representations from TTS for joint modeling of speech and facial expressions, and provides engineering practice references for subsequent speech expression co-design. The project code has been open source at: https://github.com/GoldenFishes/UniTAF

</details>


### [19] [Structure-Aware Piano Accompaniment via Style Planning and Dataset-Aligned Pattern Retrieval](https://arxiv.org/abs/2602.15074)
*Wanyu Zang,Yang Yu,Meng Yu*

Main category: cs.SD

TL;DR: 提出一种结构感知的钢琴伴奏生成方法，通过解耦高层规划与音符级实现，使用Transformer预测可解释的每小节风格计划，并通过检索器选择和重新和声人类演奏的钢琴模式。


<details>
  <summary>Details</summary>
Motivation: 传统钢琴伴奏生成方法往往缺乏对音乐结构的考虑，难以生成具有连贯结构和风格一致性的长篇幅伴奏。需要一种能够同时考虑高层音乐结构（段落/乐句结构、功能和声）和音符级细节的方法。

Method: 1. 使用轻量级Transformer预测每小节的可解释风格计划，条件于段落/乐句结构和功能和声；2. 设计检索器从语料库中选择并重新和声人类演奏的钢琴模式；3. 将检索建模为在显式能量函数下的模式匹配，考虑和声可行性、结构角色兼容性、声部进行连续性、风格偏好和重复控制。

Result: Transformer风格规划器引导的检索能够生成多样化的长篇幅钢琴伴奏，具有强烈的风格实现效果。消融实验分析了规划器的作用，并量化了不同风格之间的隔离度。实验结果表明该推理时方法在钢琴伴奏生成中的有效性。

Conclusion: 该结构感知方法成功地将高层音乐规划与音符级实现解耦，通过结合Transformer风格规划和基于能量的模式检索，能够生成具有良好结构连贯性和风格一致性的钢琴伴奏，为符号音乐生成提供了有效的解决方案。

Abstract: We introduce a structure-aware approach for symbolic piano accompaniment that decouples high-level planning from note-level realization. A lightweight transformer predicts an interpretable, per-measure style plan conditioned on section/phrase structure and functional harmony, and a retriever then selects and reharmonizes human-performed piano patterns from a corpus. We formulate retrieval as pattern matching under an explicit energy with terms for harmonic feasibility, structural-role compatibility, voice-leading continuity, style preferences, and repetition control. Given a structured lead sheet and optional keyword prompts, the system generates piano-accompaniment MIDI. In our experiments, transformer style-planner-guided retrieval produces diverse long-form accompaniments with strong style realization. We further analyze planner ablations and quantify inter-style isolation. Experimental results demonstrate the effectiveness of our inference-time approach for piano accompaniment generation.

</details>


### [20] [A Generative-First Neural Audio Autoencoder](https://arxiv.org/abs/2602.15749)
*Jonah Casebeer,Ge Zhu,Zhepei Wang,Nicholas J. Bryan*

Main category: cs.SD

TL;DR: 提出一种生成优先的音频自编码器架构，实现3360倍时间下采样，支持连续和离散表示，统一处理不同音频通道格式，相比现有方法编码速度快10倍、码率低1.6倍。


<details>
  <summary>Details</summary>
Motivation: 现有神经自编码器在生成建模中存在三个主要问题：高码率、编码速度慢、需要为离散/连续潜在变量和不同音频通道格式分别设计模型，这阻碍了从预处理到推理条件的工作流程。

Method: 提出生成优先的音频自编码器架构，大幅增加时间下采样倍数（从2048倍到3360倍），在单一模型中同时支持连续和离散表示以及常见音频通道格式，平衡压缩率、质量和速度。

Result: 实现10倍更快的编码速度，1.6倍更低的码率，消除了通道格式特定变体，同时保持竞争力的重建质量。60秒单声道信号可压缩到788个token，使生成建模更加可行。

Conclusion: 该生成优先架构解决了现有自编码器在生成建模中的关键限制，显著降低了处理成本，为之前受计算约束的应用开辟了可能性。

Abstract: Neural autoencoders underpin generative models. Practical, large-scale use of neural autoencoders for generative modeling necessitates fast encoding, low latent rates, and a single model across representations. Existing approaches are reconstruction-first: they incur high latent rates, slow encoding, and separate architectures for discrete vs. continuous latents and for different audio channel formats, hindering workflows from preprocessing to inference conditioning. We introduce a generative-first architecture for audio autoencoding that increases temporal downsampling from 2048x to 3360x and supports continuous and discrete representations and common audio channel formats in one model. By balancing compression, quality, and speed, it delivers 10x faster encoding, 1.6x lower rates, and eliminates channel-format-specific variants while maintaining competitive reconstruction quality. This enables applications previously constrained by processing costs: a 60-second mono signal compresses to 788 tokens, making generative modeling more tractable.

</details>


### [21] [S-PRESSO: Ultra Low Bitrate Sound Effect Compression With Diffusion Autoencoders And Offline Quantization](https://arxiv.org/abs/2602.15082)
*Zineb Lahrichi,Gaëtan Hadjeres,Gaël Richard,Geoffroy Peeters*

Main category: cs.SD

TL;DR: S-PRESSO：一种48kHz音效压缩模型，通过离线量化和预训练潜在扩散模型，在极低比特率（最低0.096 kbps）下实现连续和离散嵌入，在1Hz帧率下仍能产生逼真重建。


<details>
  <summary>Details</summary>
Motivation: 现有神经音频压缩模型在极低比特率下表现不佳，特别是在高分辨率音频中会产生明显听觉伪影。需要开发能够在超低比特率下保持音频质量的压缩方法。

Method: 使用预训练的潜在扩散模型解码由潜在编码器学习的压缩音频嵌入。通过离线量化实现连续和离散嵌入，利用扩散解码器的生成先验实现极低帧率（最低1Hz）。

Result: S-PRESSO在0.096 kbps的超低比特率下，实现了750倍压缩率，在音频质量、声学相似度和重建指标上均优于连续和离散基线方法。

Conclusion: 该模型证明了利用生成先验可以在极低比特率下实现逼真的音频重建，虽然牺牲了精确保真度，但在超低比特率压缩方面取得了显著进展。

Abstract: Neural audio compression models have recently achieved extreme compression rates, enabling efficient latent generative modeling. Conversely, latent generative models have been applied to compression, pushing the limits of continuous and discrete approaches. However, existing methods remain constrained to low-resolution audio and degrade substantially at very low bitrates, where audible artifacts are prominent. In this paper, we present S-PRESSO, a 48kHz sound effect compression model that produces both continuous and discrete embeddings at ultra-low bitrates, down to 0.096 kbps, via offline quantization. Our model relies on a pretrained latent diffusion model to decode compressed audio embeddings learned by a latent encoder. Leveraging the generative priors of the diffusion decoder, we achieve extremely low frame rates, down to 1Hz (750x compression rate), producing convincing and realistic reconstructions at the cost of exact fidelity. Despite operating at high compression rates, we demonstrate that S-PRESSO outperforms both continuous and discrete baselines in audio quality, acoustic similarity and reconstruction metrics.

</details>


### [22] [The Equalizer: Introducing Shape-Gain Decomposition in Neural Audio Codecs](https://arxiv.org/abs/2602.15491)
*Samir Sadok,Laurent Girin,Xavier Alameda-Pineda*

Main category: cs.SD

TL;DR: 将传统语音编码中的形状-增益分解引入神经音频编解码器，通过分离处理增益和形状来提升性能


<details>
  <summary>Details</summary>
Motivation: 传统神经音频编解码器将短时能量（增益）和归一化结构（形状）联合编码在同一潜在空间中，导致对输入信号全局电平变化鲁棒性差，编码效率低下，存在码本冗余和比特率-失真性能不佳的问题

Method: 提出Equalizer方法：在NAC编码器前对输入信号进行短时形状-增益分解，形状向量由NAC处理，增益使用标量量化单独传输，解码时从NAC输出和量化增益重建信号

Result: 在语音信号上的实验表明，该方法能显著提升比特率-失真性能，并大幅降低复杂度，且可轻松应用于任何NAC

Conclusion: 将传统语音编码的形状-增益分解思想引入神经音频编解码器框架，是一种有效提升编码效率和鲁棒性的通用方法

Abstract: Neural audio codecs (NACs) typically encode the short-term energy (gain) and normalized structure (shape) of speech/audio signals jointly within the same latent space. As a result, they are poorly robust to a global variation of the input signal level in the sense that such variation has strong influence on the embedding vectors at the output of the encoder and their quantization. This methodology is inherently inefficient, leading to codebook redundancy and suboptimal bitrate-distortion performance. To address these limitations, we propose to introduce shape-gain decomposition, widely used in classical speech/audio coding, into the NAC framework. The principle of the proposed Equalizer methodology is to decompose the input signal -- before the NAC encoder -- into gain and normalized shape vector on a short-term basis. The shape vector is processed by the NAC, while the gain is quantized with scalar quantization and transmitted separately. The output (decoded) signal is reconstructed from the normalized output of the NAC and the quantized gain. Our experiments conducted on speech signals show that this general methodology, easily applicable to any NAC, enables a substantial gain in bitrate-distortion performance, as well as a massive reduction in complexity.

</details>


### [23] [TAC: Timestamped Audio Captioning](https://arxiv.org/abs/2602.15766)
*Sonal Kumar,Prem Seetharaman,Ke Chen,Oriol Nieto,Jiaqi Su,Zhepei Wang,Rithesh Kumar,Dinesh Manocha,Nicholas J. Bryan,Zeyu Jin,Justin Salamon*

Main category: cs.SD

TL;DR: TAC模型通过时间戳音频描述解决多声源场景下的音频理解问题，减少幻觉并提升时间定位精度，还能与LLM结合实现音频-视觉理解SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有大型音频语言模型在处理复杂声学场景中的重叠事件时存在困难，会产生时间不一致的描述和频繁的幻觉，需要更精确的时间定位能力。

Method: 提出Timestamped Audio Captioner (TAC)模型，使用合成数据管道从真实音频源构建动态混合训练数据，并扩展为TAC-V音频-视觉管道，最后与LLM级联形成语义桥梁。

Result: TAC在事件检测和密集描述任务上超越所有竞争方法，幻觉率低且时间定位准确；TAC→LLM和TAC-V→LLM级联在音频和音频-视觉理解推理基准上达到SOTA。

Conclusion: TAC模型通过时间戳描述有效解决复杂声学场景理解问题，与LLM的级联架构为音频和跨模态理解提供了强大的语义桥梁，实现了显著性能提升。

Abstract: Large Audio Language Models struggle to disentangle overlapping events in complex acoustic scenes, yielding temporally inconsistent captions and frequent hallucinations. We introduce Timestamped Audio Captioner (TAC), a model that produces temporally grounded audio descriptions at varying degrees of detail and resolution. TAC is trained with a synthetic data pipeline that constructs challenging and dynamic mixtures from real-world audio sources, enabling robust learning under realistic polyphonic conditions. Across event detection and dense captioning, TAC outperforms all competing methods, with a low hallucination rate and accurate temporal grounding. We also introduce TAC-V, an audio-visual pipeline to generate semantically rich audio-visual descriptions. We then show that TAC and TAC-V serves as a "semantic bridge" for a text-only reasoner: a simple TAC$\rightarrow$LLM and TAC-V$\rightarrow$LLM cascade achieves state-of-the-art scores on benchmarks for both audio (MMAU-Pro, MMSU, MMAR) and audio-visual (DailyOmni, VideoHolmes) understanding and reasoning respectively.

</details>
